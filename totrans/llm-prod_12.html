<html><head></head><body>
<div id="sbo-rt-content"><div class="readable-text" id="p1">
<h1 class="readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">appendix A</span></span> <span class="chapter-title-text">History of linguistics</span></h1>
</div>
<div class="readable-text" id="p2">
<p>As all good stories start with “Once upon a time,” we too wanted to start with the history. Unfortunately, because we decided to write a book about production, history is “unimportant” and “superfluous” for that purpose. We agree with this, so we’ve put it to the side, here in the back of the book. That said, the wise reader will know there’s a lot we can learn from the past, even in a tiny appendix version, and we aim to help you do just that. We promise to make it worth your while.</p>
</div>
<div class="readable-text intended-text" id="p3">
<p>Of course, for language, there isn’t a clear place to start, and even the question “What is a language?” is still in the same boat as “What is a sandwich?” Linguistics as a study can be traced back thousands of years in our history, though not as far as language itself. It is largely the reason humans got to the top of the food chain, as collective memory and on-the-fly group adaptation are more successful in survival than their individual versions. We’ll break it down roughly by large periods to focus on important historical figures and prevalent ideas during these times. At the end of each section, we’ll discuss major takeaways, and you’ll see that the lessons we glean from the history of the field will be imperative to setting up your problem correctly, which will help you create a fantastic LLM product. </p>
</div>
<div class="readable-text" id="p4">
<h2 class="readable-text-h2" id="sigil_toc_id_193"><span class="num-string">A.1</span> Ancient linguistics</h2>
</div>
<div class="readable-text" id="p5">
<p>Our discussion of ancient linguistics starts in the 4th century BCE in India, China, and Greece. One of the first linguists of note was Daks.iputra Pa<sup>–</sup>n.ini in India, whose study is the first example of descriptive linguistics that’s formalized in a modern way. Pa<sup>–</sup>n.ini was attempting to codify Sanskrit without getting into any of the implications or ethics of trying to keep a language “free of corruption.” Because of the way he approached the problem, his work is good enough that it is still used today. </p>
</div>
<div class="readable-text intended-text" id="p6">
<p>In China, Confucius examined language as it relates to ethics and politics, exploring its function. In the <em>Analects of Confucius</em>, we find various thoughts such as “Words are the voice,” “In speeches, all that matters is to convey the meaning,” and “For one word, a superior man may be set down as wise, and for one word he is deemed to be not wise.” Even from just these few excerpts, it is clear that Confucius and his students saw language’s primary function as conveying meaning, a common opinion shared by many today. Many of Confucius’ ideas about language can be summed up with the idea of speaking slowly and only when you are confident you can convey exactly the meaning you intend to, not otherwise.</p>
</div>
<div class="readable-text intended-text" id="p7">
<p>In Greece, the study of linguistics flourished, with Socrates, Plato, and Aristotle studying the nature of meaning and reality using dialogues as a tool for teaching. The Socratic method is a linguistic method of organized problem-solving used to explore the whys of language and the world. </p>
</div>
<div class="readable-text intended-text" id="p8">
<p>There are some takeaways from ancient linguistics, the first being that language needs a sort of metalanguage to describe it to avoid recursive ambiguity. The second is far more important: If something is easily replicable, even if it isn’t completely correct, it will become correct in time. All of these works were done during a time of oral tradition, and instead of making sure that everything they were claiming was correct, provable, and repeatable, Pa<sup>–</sup>n.ini, for example, opted to have his whole work able to be recited in 2 hours. Due to its concise nature, it spread quickly, and some things that may not have been correct before became correct in part because of Pa<sup>–</sup>n.ini’s explanation.</p>
</div>
<div class="readable-text intended-text" id="p9">
<p>Confucius and the Greeks can be summed up much the same because they offered concise explanations for complex problems; they created misconceptions that have lasted thousands of years because the explanations prioritize being short and intuitive when the real answers are often larger and harder to understand. It’s similar to explaining to your older family members how to connect to the internet: they often don’t have the patience or feel like they need to know about ISPs, DNS, routing, the difference between a router and a modem, TCP, packets, IP addresses or even browsers. They want to be told what to click on, and even though just a basic knowledge of the whole process could help them browse the internet with more freedom and eliminate a lot of their complaints, the short explanation is what sticks, even if it’s incomplete and creates problems later.</p>
</div>
<div class="readable-text intended-text" id="p10">
<p>When designing LLM interfaces or finetuning models, consider creating a clear “metalanguage” for user interactions. We do this when we are prompt engineering for a model, inserting keywords and phrases to assert a clear, unambiguous system to avoid recursive ambiguity. DSPy and TextGrad have figured out how to automate parts of this, and Guidance and LMQL complement. Strive for a balance between accuracy and simplicity in model outputs, especially for general-purpose LLMs.</p>
</div>
<div class="readable-text" id="p11">
<h2 class="readable-text-h2" id="sigil_toc_id_194"><span class="num-string">A.2</span> Medieval linguistics</h2>
</div>
<div class="readable-text" id="p12">
<p>Moving on from ancient times, we see the main contributions to medieval linguistic development come from Western and Central Asia, starting with Al-Farabi, who formalized logic into two separate categories: hypothesis and proof. He laid the groundwork for studying syntax and rhetoric in the future by showcasing a link between grammar and logic, which intuitively leads to predicting grammar using logic. Knowing this is a big breakthrough for us as practitioners, and we take advantage of it today all the time. It allows us to create logical frameworks for analyzing grammar and identifying and correcting errors. </p>
</div>
<div class="readable-text intended-text" id="p13">
<p>Later, Al-Jahiz contributed mainly to rhetoric, penning over 200 books, but he also contributed to grammar in his suggested overhaul of the Arabic language. You may notice, if you decide to study further, that Europe had many linguistic publications during this time; however, almost none of them were of any great significance. Europeans during this time were fixated on Latin, which didn’t help very much in the (much) broader linguistic landscape, although one contribution that should be mentioned is that the so-called trivium of grammar, logic, and rhetoric was defined, helping create the education system that was enjoyed up to and through the time of Shakespeare.</p>
</div>
<div class="readable-text intended-text" id="p14">
<p>Incorporating logical frameworks into language models, such as knowledge graphs, improves grammatical accuracy and coherence. This is why tools like Guidance and LMQL work so well, as they constrain outputs to the domains we know we can control. Make sure you collect training data that incorporates multiple aspects of language (grammar, logic, rhetoric) for more sophisticated language understanding during training and generation after.</p>
</div>
<div class="readable-text" id="p15">
<h2 class="readable-text-h2" id="sigil_toc_id_195"><span class="num-string">A.3</span> Renaissance and early modern linguistics</h2>
</div>
<div class="readable-text" id="p16">
<p>Building off of Medieval linguistics, the Renaissance saw a renewed interest in classical Latin and Greek, leading to the emergence of humanist grammar. Lorenzo Valla is one of the most important scholars of this time; in the 15th century in Italy, he wrote a comprehensive textbook on Latin grammar and style, <em>Elegantiae Linguae Latinae</em>, which is a large contribution to linguistics on its own but, more importantly, began using linguistic style critically to prove an important document being used as a claim to papal authority as a forgery, founding critical linguistic scholarship by comparing a previous Bible translation against the original Greek and arguing against the prevailing Aristotelian thought that philosophy did not need to conform to common sense or common language usage.</p>
</div>
<div class="readable-text intended-text" id="p17">
<p>The critical Bible notes from Valla inspired Erasmus, who has both religious and linguistic significance–although his linguistic significance ends at his synchronous and multilingual translations of the New Testament and the cultivation of both Latin and Greek style and education. He demonstrated quite soundly that modeling any monolingual task in a multilingual scenario improves the monolingual task. Later, in the 1600s, the rise of the scientific method gave way to a newfound interest in then-modern European languages and their comparative grammar. Europe profited immensely from this multifaceted revolution, which was significantly supported by a shared lingua franca and discerning scholars who prioritized truth over authority. Consider figure A.1 to see a truncated etymology of some English words. Understand where they came from and the many changes our language has gone through over the years, and see that this time in history was yet another awakening for both thought and language change.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p18">
<img alt="figure" height="334" src="../Images/A-1.png" width="842"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure A.1</span> Incomprehensive evolution of some English words. Orthography is the system we use for writing, encompassing alphabets, punctuation, and the rules of written language instead of spoken. While this figure deals more with pronunciation than orthography, we should understand that the two influence each other and have gone through many stages of evolution. Language will not stop evolving, and we shouldn’t expect it to or fight it, as much as that would simplify our jobs. Notice that in the evolutions of “person” and “intelligence,” a whole other language came in and supplanted the original despite expected changes occurring before. All of these still happen.</h5>
</div>
<div class="readable-text" id="p19">
<p>In the same vein, the Early Modern period in the 18th century unlocked a large change by essentially birthing linguistics as its own study, unconnected to religion or philosophy. Sir William Jones, a philologist, succeeded in popularizing a connection between European languages and Farsi and Sanskrit despite doing his practice worse than everyone who had done it before. We say <em>worse</em> because this idea had already been floating around for hundreds of years, with several scholars positing the correct idea. Jones, however, also randomly threw Egyptian, Japanese, and Chinese into Indo-European. It seemed that needing correction was good for the theory.</p>
</div>
<div class="readable-text intended-text" id="p20">
<p>Comparative and historical linguistics both seemed to spawn all at once in reaction to it, with many other scholars contributing quickly and meaningfully, like Franz Bopp, who developed a language analysis as a system for comparing what had been noticed. In the same period, Jacob Grimm authored Grimm’s Law, which revealed for the first time that significant sound changes in language occur gradually rather than abruptly and stem from systematic evolution rather than random word alterations. Karl Verner followed in his footsteps, later showing more convincing evidence that sound change, even in exceptions, is regular and dependent on accent. </p>
</div>
<div class="readable-text intended-text" id="p21">
<p>Much like many other fields of study, this timeframe is where linguistics took off and became more scientific, attempting to break down the underpinnings of language and even trying to come up with the “most efficient structure” for a constructed language. The takeaway here is that in becoming more scientific, linguistics began to break away from common knowledge and understanding, going from a regular part of education to something that could only be specialized in at universities or very expensive high schools. Many of the ideas that came forward during this period weren’t novel, and even more of them were completely wrong, with nationalist motivations; however, this remains one of the more important periods to consider for study in large part because of those mistakes.</p>
</div>
<div class="readable-text intended-text" id="p22">
<p>From this time period, we can see that developing multilingual models will improve overall language understanding and generation. Most languages are related, and exposing our model to as many as we can gives it a better chance of understanding the underlying structure and patterns, similar to how someone who already knows several languages has an easier time learning a fourth or a fifth than someone learning their second. Also, be sure to design systems that can help you adapt your model to evolving language use. Modern language and slang evolve very rapidly, and you should be prepared to handle this data drift. Many of a language’s changes are borrowed from other languages, so training your model for multilingual settings will help boost its productivity and generalizing ability in the most efficient way.</p>
</div>
<div class="readable-text" id="p23">
<h2 class="readable-text-h2" id="sigil_toc_id_196"><span class="num-string">A.4</span> Early 20th-century linguistics</h2>
</div>
<div class="readable-text" id="p24">
<p>The early 20th century saw the emergence of structural linguistics, which aimed to describe languages in terms of their structure. Structural linguistics is worth mentioning as a form of data engineering. A corpus of utterances is gathered, and then each utterance is broken down into its various parts for further classification: phonemes (smallest meaningful sounds), morphemes (smallest meaningful subword tokens), lexical categories, noun phrases, verb phrases, and sentence types. </p>
</div>
<div class="readable-text intended-text" id="p25">
<p>The Swiss linguist Ferdinand de Saussure introduced key concepts during this time, such as langue and parole, signifier versus signified, and synchronic versus diachronic analysis, all as part of his opposition theory–the idea that meaning in language cannot be created or destroyed, only separated and absorbed. This is a harder concept to grasp, so if it doesn’t feel intuitive, don’t panic, but anytime you have a concept in a language, for example, <em>freedom</em>, that concept has parts that change based on pragmatic context. That concept also has overlap with synonyms and not-so-synonyms, too—for example, <em>freedom</em> versus <em>liberty</em> versus <em>agency</em> versus <em>choice</em> versus <em>ability</em>. All these words overlap in parts of their meaning at different percentages, where <em>freedom</em> and <em>liberty</em> are almost completely the same. Many would struggle to articulate the difference, but <em>freedom</em> and <em>ability</em> are only partly similar. If, for example, the word <em>agency</em> vanished from English, its meaning and usage would be absorbed by the other words that are contained in the set of words with overlapping meanings; therefore, its meaning wouldn’t be lost, only no longer separate. The algorithm for change to language ends up being that each element in the set of words is compared in a bubble-sort-esque fashion with every other element in multiple relations until no two elements have the exact same value. </p>
</div>
<div class="callout-container sidebar-container">
<div class="readable-text" id="p26">
<h5 class="callout-container-h5 readable-text-h5 sigil_not_in_toc">Definitions for Saussure </h5>
</div>
<ul>
<li class="readable-text" id="p27"> <em>Langue and parole</em>—The difference between a language as a whole versus the usage of that language. This is the difference between the larger idea of English as opposed to when someone is speaking English. </li>
<li class="readable-text" id="p28"> <em>Signifier versus signified</em>—An acknowledgment of the arbitrariness of the sounds/spellings of most words compared to the things they’re referencing. This idea was pioneered by the Greeks but has been refined and quantified by many people since. Take the word <em>cat</em> in English. This word is made up of the /k/, /æ/, and /t/ sounds, plus the idea or prototype of a cat. None of those sounds has anything to do with a cat in reality, as opposed to the word <em>pop</em>, which is an onomatopoeia. A further application of signifier versus signified is understanding that nature doesn’t divide itself into months or categories the way humans do with it, like flowers and trees and shrubs. These artificial classes are evidence of the larger idea at play that language is a self-contained system that is not a function of reality but rather a prescriptive abstraction of reality. The shrub class only matters in comparison to other classes within the language system and is meaningless outside of that system. This should feel similar to object-oriented programming. </li>
<li class="readable-text" id="p29"> <em>Synchronic versus diachronic analysis</em>—A description of how far you are zooming out when analyzing a language. Synchronic analysis is studying language as it currently exists, as if it were a snapshot in time. Diachronic analysis is studying the larger history of a language. An example of synchronic analysis would be going to dictionary.com and studying English using that current snapshot, as opposed to studying the differences between all the dictionaries ranging from the 1850s to now. </li>
</ul>
</div>
<div class="readable-text" id="p30">
<p>A good example of why this change shouldn’t be threatening to anyone deals with the colors red and blue. In English, when we’re introducing colors to a child, we generally will tell them about both the colors red and pink (effectively light red) in the set of basic colors we use, but we usually only introduce toddlers to the one generic version of the color blue. In contrast, Russians will introduce their children to both синий and голубой (regular blue and light blue) but typically only tell kids one name for red and don’t include any special name for light red. Both languages, of course, have full access to all the colors, and neither has influenced the spectrum of light or perceived it differently. However, they’ve just chosen to deem different parts of it important for their use cases, which, again, aren’t based in reality and don’t have to be based on utility, either. Later, Leonard Bloomfield developed these ideas further, showing that linguistic phenomena could be successfully studied when they were isolated from their linguistic context, which, among other things, contributed significantly to the historical linguistic study of Indo-European.</p>
</div>
<div class="readable-text intended-text" id="p31">
<p>There’s a lot that we can take from this time period to improve our LLMs. One key takeaway is understanding that language systems are self-contained and not necessarily tied to objective reality. We don’t need to worry about whether our model actually understands what a “cat” is in the real world to make proper use of it in the textual one. We should also make sure our models are exposed to data that demonstrates linguistic relativity, such as including works from different time periods and locations. This will help us with problems like localization—different locations use language differently even when speaking the same language—and generational divide—older and younger people use words differently. </p>
</div>
<div class="readable-text" id="p32">
<h2 class="readable-text-h2" id="sigil_toc_id_197"><span class="num-string">A.5</span> Mid-20th century and modern linguistics</h2>
</div>
<div class="readable-text" id="p33">
<p>The emphasis on the scientific method during early 20th-century linguistics helped set the stage for computational linguistics (CompLing) and natural language processing (NLP) to begin. The very first computers were designed for explicitly linguistic purposes, and the early pioneers in the field, like Alan Turing, Claude Shannon, and Mary Rosamund Haas, laid the groundwork in this area with their work on information theory, artificial intelligence, machine learning, and comparative historical linguistics. Haas’ work, in particular, can show us that, despite Saussure’s belief in word loss not equating to meaning loss, loss of language is a net negative for the world. To really drive this point home, most of what we know today about linguistics is thanks to deaf people. </p>
</div>
<div class="readable-text intended-text" id="p34">
<p>The nature of comparative linguistics is literally comparison. We compare English to Arabic and Hebrew to understand that nonconcatenative morphology exists (three- or four-consonant roots that get different vowels inserted). We compare English to Chinese and Japanese to understand that not all languages need alphabets. But we can’t get all of our important answers by comparing just English or by comparing to other languages that use the same modes of communication. There are foundational and important questions, like “Can kids learn language from TV,” that aren’t possible to answer by comparing English to any other spoken language, but within the perfect environment of hearing children of deaf adults (CODAs), we can get answers. </p>
</div>
<div class="readable-text intended-text" id="p35">
<p>Sign languages are the closest thing we have to nonhuman languages, not because they aren’t made or spoken by humans but because they don’t have exactly the same expression of syntax or morphology as spoken languages do. Going along with this train of thought, it is difficult to understand the possibilities for all sorts of recipes if you only have bread-based food. You might take bread for granted or say that bread is an absolute base requirement for all food when there are many other foods and even other carbs like pasta or rice that could be used as a base. </p>
</div>
<div class="readable-text intended-text" id="p36">
<p>Sign languages, and deaf people in general, have had societal stigma attached to them for almost all of their existence (until about the 1970s), but that’s not to say that they don’t face any now. Some of that stigma has been religious, saying that they’re possessed by demons or similar entities. Some have been more societal, saying that deaf people simply weren’t smart enough to cope with the world. None of these are true, and it’s a shame that we couldn’t have realized the potential for learning and comparison sooner. Similar to the bread example, sign languages offer a look at what our language could look like if we used a completely different base—say, cauliflower, which can be used similarly to bread but doesn’t have to be. It’s hard to even imagine what a language that is the cauliflower to English’s bread would look like until you actually see it and study it. </p>
</div>
<div class="readable-text intended-text" id="p37">
<p>One of the greatest examples of what we can learn from sign languages is looking at what is similar between sign and spoken languages, which helps us understand what is absolutely essential for a language versus what things we take for granted because we have nothing different to compare it against. We learned, for example, that sign languages have phonetics. We’ve also learned that signs do not necessarily correspond to spoken words, as many assumed. We have learned similar lessons about the underlying nature of grammar and syntax from languages that have had little contact with global civilization, such as, for example, Pirahã, which doesn’t have any history beyond living memory, can be coherently and completely whistled, and has neither cardinal nor ordinal numbers. Unfortunately, these are always the first languages to die and be assimilated into a larger culture when we are careless. If we hope to be able to solve all of the questions we have about language, we don’t want to hit a point of no return where all of the languages we have to compare and learn from are bread-based.</p>
</div>
<div class="readable-text intended-text" id="p38">
<p>In the interest of never hitting that point of no return, the first application of CompLing and NLP was machine translation, but in the 1950s, it hardly resembled today’s systems. Systems like the Georgetown–IBM experiment and R.E.T. from MIT were designed with the intuitive logic that because all languages end up containing the same total amount of information, rules can be created to map languages to each other in a grand set of lookup tables. The mid-20th century brought about probably the most important breakthroughs of the whole century in all three fields: universal and generative grammar theories. The underlying idea behind all of Chomsky’s linguistics is that all of the principles that make up the human faculty of language are biologically inherited, meaning that all humans not only come preprogrammed for the faculty of language but that all of us have the same information under the hood at the beginning and just need to learn the particular rules to generate our native language(s). Rather than discuss whether Chomsky is right in any of this research and belief, we will just say that this idea has been incredibly useful for designing multilingual systems.</p>
</div>
<div class="readable-text intended-text" id="p39">
<p>Chomsky’s work was groundbreaking because subsequent research spawned several other fields, including psycholinguistics, sociolinguistics, and cognitive linguistics, and had a significant effect on other fields. In compiling and NLP, it started the use of formal grammars and parsing to algorithmically determine the structure of languages and had quite a bit of success. Some similar ideas to Chomsky and Zellig Harris’s work ended up showing up in the first Generative Pre-trained Transformer (GPT) paper in 2018, though uncited. Later, these parsers moved from formal grammars to context-free grammars, and the distance Chomsky highlighted between syntax and semantics made semantics a focus for later 20th-century computational linguists. Knowledge representation and natural language understanding (NLU) remain pain points today. </p>
</div>
</div></body></html>