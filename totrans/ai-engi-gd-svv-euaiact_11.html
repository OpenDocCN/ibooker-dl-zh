<html><head></head><body><section data-pdf-bookmark="Appendix D. Emerging Roles in Organizations for EU AI Act Compliance" data-type="appendix" epub:type="appendix"><div class="appendix" id="appendix_d_emerging_roles_in_organizations_for_eu_ai_act_comp_1748539915764930">
<h1><span class="label">Appendix D. </span>Emerging Roles in Organizations for <span class="keep-together">EU AI Act Compliance</span></h1>

<p>Compliance with the EU AI Act is operationalized<a contenteditable="false" data-primary="emerging roles (for compliance)" data-type="indexterm" id="er-c-1"/> on two levels: the organizational level and the individual AI system level. As organizations increasingly adopt AI technologies, new roles are emerging to support compliance efforts and manage associated risks. This appendix explores those roles and common team topologies.</p>

<section data-pdf-bookmark="Emerging Roles" data-type="sect1"><div class="sect1" id="appendix_d_emerging_roles_1748539915765054">
<h1>Emerging Roles</h1>

<p>The <em>AI ethics specialist</em> plays<a contenteditable="false" data-primary="emerging roles (for compliance)" data-secondary="AI ethics specialist" data-type="indexterm" id="id689"/> a crucial role in ensuring that AI systems are designed and implemented in alignment with ethical principles. Their responsibilities include developing AI ethics values, guidelines, and frameworks (see the <a href="https://oreil.ly/c79Xu">Values Canvas</a>), as well as conducting ethical impact assessments for AI projects. They address concerns related to bias, fairness, and transparency in AI systems and work closely with legal, compliance, and AI development teams. Staying up-to-date with AI ethics research and best practices is also a key part of their role.</p>

<p>The <em>AI internal auditor</em> is <a contenteditable="false" data-primary="emerging roles (for compliance)" data-secondary="AI internal auditor" data-type="indexterm" id="id690"/>responsible for independently assessing AI systems to ensure compliance with ethical and regulatory standards. This involves conducting audits to evaluate the fairness, transparency, and accountability of AI systems and benchmarking them against organizational policies and external regulations. The auditor provides recommendations for improving the compliance of AI systems and develops AI-specific audit frameworks and methodologies. Collaboration with AI ethics specialists and compliance officers is a vital aspect of this role.</p>

<p class="pagebreak-before">The role of a <em>legal AI compliance officer</em> or <em>AI regulatory affairs specialist</em> <a contenteditable="false" data-primary="emerging roles (for compliance)" data-secondary="legal AI compliance officer" data-type="indexterm" id="id691"/>is to ensure that AI systems comply with applicable laws and regulations. This requires staying informed about evolving AI legislation, developing compliance strategies for AI initiatives, conducting legal risk assessments, and providing guidance on data privacy and AI transparency. They work closely with legal teams, AI development teams, and AI ethics specialists.</p>

<p>The <em>data and AI governance specialist</em> develops<a contenteditable="false" data-primary="emerging roles (for compliance)" data-secondary="data and AI governance specialist" data-type="indexterm" id="id692"/> and implements policies that ensure responsible management of data and AI assets. This includes creating data and AI governance frameworks, enforcing compliance with data protection regulations (such as GDPR and CCPA), establishing data quality and metadata management practices, and developing policies for AI model versioning and lifecycle management. They collaborate closely with data engineers, AI teams, and compliance officers to ensure the effective implementation of these policies.</p>

<p>The <em>AI risk management specialist</em><strong> </strong>is <a contenteditable="false" data-primary="emerging roles (for compliance)" data-secondary="AI risk management specialist" data-type="indexterm" id="id693"/>responsible for identifying, assessing, and mitigating risks associated with AI systems. This includes conducting risk assessments for AI projects and deployments, developing risk mitigation strategies, and continuously monitoring AI systems for potential risks and vulnerabilities. They collaborate with AI security specialists and compliance officers and provide risk-related insights to leadership to inform decision making.</p>

<p>The <em>AI security specialist</em><strong> </strong>ensures<a contenteditable="false" data-primary="emerging roles (for compliance)" data-secondary="AI security specialist" data-type="indexterm" id="id694"/> that AI systems are protected against threats and vulnerabilities. They implement security best practices in AI development and deployment, conduct security assessments of AI models and systems, and develop defenses against AI-specific threats such as model poisoning and adversarial attacks. They also monitor AI systems for security anomalies and collaborate closely with cybersecurity teams and MLOps engineers to maintain the security of AI systems.</p>

<p>These roles are embedded with broader organizational structures such as cross-functional teams or governance boards.</p>

<p>In the next section, we’ll explore <a href="https://oreil.ly/ZW6OJ">Team Topologies</a>, a framework for organizing and structuring software development teams to optimize workflow and delivery. We’ll extend this concept to ML teams and examine how the emerging roles related to EU AI Act compliance can be integrated effectively.</p>
</div></section>

<section class="pagebreak-before" data-pdf-bookmark="EU AI Compliance for ML Teams" data-type="sect1"><div class="sect1" id="appendix_d_eu_ai_compliance_for_ml_teams_1748539915765127">
<h1 class="less_space">EU AI Compliance for ML Teams</h1>

<p>Matthew Skelton and Manuel Pais developed the core concept of Team Topologies<a contenteditable="false" data-primary="Team Topologies" data-type="indexterm" id="tt-1"/> and introduced it in their 2019 book of the same name. The framework defines four fundamental team types<a contenteditable="false" data-primary="Team Topologies" data-secondary="team types in" data-type="indexterm" id="id695"/> (see Figures <a data-type="xref" data-xrefstyle="select:labelnumber" href="#appendix_d_figure_1_1748539915761325">D-1</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href="#appendix_d_figure_2_1748539915761360">D-2</a>):</p>

<ul>
	<li>
	<p><em>Stream-aligned teams</em> are the primary team type, focused on delivering value directly to customers or users. They work on a specific product, service, or feature set aligned with a business domain.</p>
	</li>
	<li>
	<p><em>Platform teams</em> provide internal services and tools to support and accelerate stream-aligned teams. By offering self-service capabilities, they aim to reduce the cognitive load for other teams.</p>
	</li>
	<li>
	<p><em>Complicated subsystem teams</em> handle complex components or areas that require specialized expertise, which stream-aligned teams may not possess.</p>
	</li>
	<li>
	<p><em>Enabling teams</em> assist other teams in adopting new technologies or overcoming obstacles. They provide specialized knowledge and coaching.</p>
	</li>
</ul>

<p>Team Topologies also defines three core interaction modes between teams (see <a data-type="xref" href="#appendix_d_figure_1_1748539915761325">Figure D-1</a>):</p>

<ul>
	<li>
	<p><em>Collaboration</em>, where teams work together closely for a defined period</p>
	</li>
	<li>
	<p><em>X-as-a-service</em>, where one team provides a service that another team consumes</p>
	</li>
	<li>
	<p><em>Facilitating</em>, where one team helps another team learn or develop a new capability</p>
	</li>
</ul>

<figure><div class="figure" id="appendix_d_figure_1_1748539915761325"><img src="assets/taie_d001.png"/>
<h6 class="fix_tracking"><span class="label">Figure D-1. </span>The four team types and three interaction modes. Image from the book <span class="plain">Team Topologies</span> by Matthew Skelton and Manuel Pais (IT Revolution). Used with permission.</h6>
</div></figure>

<figure><div class="figure" id="appendix_d_figure_2_1748539915761360"><img src="assets/taie_d002.png"/>
<h6><span class="label">Figure D-2. </span>Primary interaction modes for the four fundamental Team Topologies. Image from the book <span class="plain">Team Topologies</span> by Matthew Skelton and Manuel Pais (IT Revolution). Used with permission.</h6>
</div></figure>

<p>The core principles of Team Topologies guide effective team organization and dynamics. A key principle is Conway’s law<a contenteditable="false" data-primary="Team Topologies" data-secondary="Conway's law and" data-type="indexterm" id="id696"/>, which states that “organizations design systems that mirror their communication structures”—in other words, the structure of those systems tends to reflect the way teams are organized and interact. This highlights the importance of designing team structures intentionally to support desired system architectures.</p>

<p>The Team Topologies framework also emphasizes the need for teams to handle only as much complexity as they can effectively manage, to avoid excessive cognitive load. Prioritizing collective intelligence over individual capacities encourages a team-first mindset. Team Topologies also promotes defining natural boundaries for team responsibilities and ensuring team encapsulation, with clear, well-defined interfaces. Finally, evolving team structures are essential to adapt to changes in technologies and organizational needs.</p>

<section data-pdf-bookmark="Team Topologies for ML Teams" data-type="sect2"><div class="sect2" id="appendix_d_team_topologies_for_ml_teams_1748539915765208">
<h2>Team Topologies for ML Teams</h2>

<p>With the<a contenteditable="false" data-primary="Team Topologies" data-secondary="for ML teams" data-secondary-sortas="ML teams" data-type="indexterm" id="tt-fml-1"/> rapid adoption of ML/AI technologies, it has become clear that data science and ML teams don’t all fit neatly into the complicated subsystem team category. In practice, they often span multiple team types. David Tan, Ada Leung, and David Colls explore this idea in their book <a href="https://oreil.ly/zK4s0"><em>Effective Machine Learning Teams</em></a> (O’Reilly), where they distinguish between four types of teams in the ML space:</p>

<ul>
	<li>
	<p><em>ML product teams</em> (stream-aligned) deliver user-facing ML features with minimal dependencies on other teams.</p>
	</li>
	<li>
	<p><em>ML domain teams</em> (complicated subsystem) focus on complex ML applications tailored to specific domains.</p>
	</li>
	<li>
	<p><em>ML and data platform teams</em> provide foundational ML and data capabilities to support other teams and reduce duplication of effort.</p>
	</li>
	<li>
	<p><em>Enabling ML teams</em> specialize in particular aspects of ML product development and provide assistance to other teams.</p>
	</li>
</ul>

<p>As visualized in <a data-type="xref" href="#appendix_d_figure_3_1748539915761387">Figure D-3</a>, the ML domain team’s interaction modes<a contenteditable="false" data-primary="Team Topologies" data-secondary="interaction modes" data-type="indexterm" id="id697"/> range from collaboration to as-a-service delivery of ML solutions. With its expertise in advanced ML models and domain-specific tasks (e.g., retail forecasting, content recommendation, churn prediction), it operates as a collaborative unit within the organization. It also provides ML models and capabilities as a service to multiple stream-aligned teams, ensuring that teams across the organization can leverage ML expertise without duplicating effort.</p>

<figure><div class="figure" id="appendix_d_figure_3_1748539915761387"><img src="assets/taie_d003.png"/>
<h6><span class="label">Figure D-3. </span>Visualization of typical topologies for ML domain teams. Image from the book <span class="plain">Effective Machine Learning Teams</span> by David Tan, Ada Leung, and David Colls (O’Reilly). Used with permission.</h6>
</div></figure>
</div></section>

<section class="pagebreak-before" data-pdf-bookmark="Aligning Team Topologies with Ethics, Compliance, and Governance Roles" data-type="sect2"><div class="sect2" id="appendix_d_aligning_team_topologies_with_ethics_compliance_1748539915765267">
<h2 class="less_space">Aligning Team Topologies with Ethics, Compliance, <span class="keep-together">and Governance Roles</span></h2>

<p>Now that you have a sense of the core team topologies and how they relate to AI teams, let’s see how this ties in with the EU AI Act. Team structures in AI teams are not static; they evolve based on the organization’s needs, scale, and maturity. As discussed earlier, ensuring compliance with AI regulations and supporting the development of trustworthy AI systems requires the introduction of new, specialized roles. The following subsections give a few examples of how these emerging ethics, compliance, and governance roles can be integrated into the Team Topologies framework as enabling teams or complicated subsystem teams.</p>

<section data-pdf-bookmark="Enabling team: AI ethics and governance" data-type="sect3"><div class="sect3" id="appendix_d_enabling_team_ai_ethics_and_governance_1748539915765341">
<h3>Enabling team: AI ethics and governance</h3>

<p>This team functions as an enabling team in the Team Topologies model, focusing on AI ethics, compliance, and governance. It might include roles such as:</p>

<ul>
	<li>
	<p>AI ethics specialist</p>
	</li>
	<li>
	<p>Legal AI compliance officer or AI regulatory affairs specialist</p>
	</li>
	<li>
	<p>Data and AI governance specialist</p>
	</li>
	<li>
	<p>AI risk management specialist</p>
	</li>
</ul>

<p>The AI ethics and governance team will support other teams (such as ML product or domain teams) through facilitation and collaboration. Its goal is to help these teams navigate ethical considerations, ensure compliance with the EU AI Act and other data and AI regulations, and implement effective governance practices.</p>

<p>The organization’s data and ML platform team could incorporate some of these governance and compliance capabilities into its offerings, for example by embedding ethical AI guidelines and checklists into ML development workflows, implementing automated compliance checks in ML pipelines, or providing preapproved, regulation-compliant data sources and model architectures.</p>
</div></section>

<section data-pdf-bookmark="Complicated subsystem team: Data and AI security and auditing" data-type="sect3"><div class="sect3" id="appendix_d_complicated_subsystem_team_data_and_ai_security_a_1748539915765399">
<h3>Complicated subsystem team: Data and AI security and auditing</h3>

<p>This team handles the complex and specialized aspects of AI security and auditing. It will include roles such as:</p>

<ul>
	<li>
	<p>Data and AI security specialist</p>
	</li>
	<li>
	<p>AI internal auditor</p>
	</li>
</ul>

<p>The team primarily operates in the X-as-a-service interaction mode, providing security and auditing capabilities to ML teams across the organization.</p>

<p>By integrating the emerging ethics, compliance, and governance roles described here into the Team Topologies for ML teams framework, organizations can embed proper data and AI governance directly into their development workflows. This approach supports compliance with the EU AI Act and related regulations while preserving the benefits of fast flow, clear ownership, and reduced cognitive<a contenteditable="false" data-primary="Team Topologies" data-secondary="for ML teams" data-secondary-sortas="ML teams" data-startref="tt-fml-1" data-type="indexterm" id="id698"/> load that Team Topologies is designed<a contenteditable="false" data-primary="Team Topologies" data-startref="tt-1" data-type="indexterm" id="id699"/> to enable<a contenteditable="false" data-primary="emerging roles (for compliance)" data-startref="er-c-1" data-type="indexterm" id="id700"/>.</p>
</div></section>
</div></section>
</div></section>
</div></section></body></html>