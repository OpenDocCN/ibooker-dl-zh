- en: 11 Contextualizing prompts with retrieval-augmented generation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 11 使用检索增强生成来上下文化提示
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: How RAG works
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAG是如何工作的
- en: Using tooling to create a basic RAG setup
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用工具创建基本的RAG设置
- en: Integrating vector databases into a RAG setup
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将向量数据库集成到RAG设置中
- en: As we learned in the previous chapter, one of the challenges of working with
    large language models (LLMs) is that they lack visibility of our context. In the
    second part of this book, we saw different ways in which we can arrange our prompts
    to help provide small insights into our context. However, these types of prompts
    are only useful before the lack of extra context leads to less valuable responses.
    Therefore, to increase the value of an LLM’s response, we need to place more contextual
    detail into our prompt. In this chapter, we’ll explore how to do this through
    retrieval-augmented generation, or RAG. We’ll learn how RAG works, why it’s beneficial,
    and how it’s not a big jump from prompt engineering to building our own RAG framework
    examples to establish our understanding of how they can help us in a testing context.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在上一章所学，与大型语言模型（LLMs）一起工作的一个挑战是它们缺乏对我们上下文的可见性。在这本书的第二部分，我们看到了不同的方法，我们可以安排我们的提示来帮助我们提供对我们上下文的小洞察。然而，这类提示只有在缺乏额外上下文导致响应价值降低之前才有用。因此，为了提高LLM响应的价值，我们需要在我们的提示中放入更多的上下文细节。在本章中，我们将探讨如何通过检索增强生成（RAG）来实现这一点。我们将学习RAG是如何工作的，为什么它是有益的，以及它从提示工程到构建我们自己的RAG框架示例的跳跃并不大，以建立我们对它们如何在测试上下文中帮助我们理解。
- en: 11.1 Extending prompts with RAG
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.1 使用RAG扩展提示
- en: To recap, RAG is an approach to improving the quality of an LLM’s response by
    combining existing corpus of data with a prompt. Although this broadly explains
    how RAG works, we need to dig a little deeper to better grasp how this combination
    of data is achieved. The process of a RAG system is relatively straightforward
    and can be summarized as shown in figure 11.1.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾一下，RAG是一种通过结合现有数据集和提示来提高LLM响应质量的方法。尽管这广泛地解释了RAG是如何工作的，但我们还需要深入挖掘，以更好地理解这种数据组合是如何实现的。RAG系统的过程相对简单，可以总结如图11.1所示。
- en: '![](../../OEBPS/Images/CH11_F01_Winteringham2.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH11_F01_Winteringham2.png)'
- en: Figure 11.1 A visualization of how a basic RAG system works
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1 基本RAG系统工作原理的可视化
- en: 'We start with a user input, which would be some sort of query. For example,
    we might send to our RAG system a query such as “I want to test ideas for deleting
    bookings.” This query is then sent to a library or tool that will examine our
    corpus of data for items within the data relevant to our query. In our example,
    this might be a collection of user stories that define each feature in the system.
    The library or tool would determine which user stories are most relevant and then
    return them to be added to a prompt:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从用户输入开始，这可能是某种查询。例如，我们可能会向我们的RAG系统发送一个查询，比如“我想测试删除预订的想法。”这个查询随后会被发送到一个库或工具，它会检查我们的数据集中与查询相关的项目。在我们的例子中，这可能是一系列定义系统中每个特性的用户故事集合。库或工具将确定哪些用户故事最相关，然后将它们返回以添加到提示中：
- en: '|'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-MW.png)'
- en: '| You are a bot that makes recommendations for testing ideas. You answer with
    suggested risks to test for, based on the provided user story.This is the user
    story: `{relevant_document}`The user input is: `{user_input}`Compile a list of
    suggested risks to test for, based on the user story and the user input. |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| 你是一个为测试想法提供建议的机器人。你根据提供的用户故事回答建议的风险测试。这是用户故事：`{relevant_document}`用户输入是：`{user_input}`根据用户故事和用户输入，编制一个建议的风险测试列表。|'
- en: The LLM will then consume both the user query and the relevant documents to
    return a response that is more accurate than if we sent the query “I want test
    ideas for deleting bookings” directly to an LLM.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，LLM将消费用户查询和相关的文档，以返回一个比如果我们直接将查询“我想测试删除预订的想法”发送给LLM更准确的响应。
- en: By providing data at the `{relevant_document}` point within a prompt relevant
    to the initial query at the `{user_input}` point, we get a response that has increased
    accuracy and value. But it does raise a question of why it would go about finding
    relevant data in the first place. Can’t we just send the data we have in each
    prompt and remove the need to do a relevancy check? Targeting what documents we
    add to a prompt is important for a few reasons. First, consider the size of the
    prompt we can create. The size of a prompt we can send to an LLM depends on its
    maximum sequence length or context window. A context window defines how many words,
    or tokens, can be processed by an LLM. If we add more tokens than the context
    window allows, then the LLM will either cut off the excess tokens at the end of
    the prompt (resulting in a partially completed prompt) or return an error. To
    put this in real terms, Llama-2, Meta’s open-source LLM, has a default context
    window of 4096 tokens, which is about the average equivalent of 10 pages in a
    book. This might feel like a lot initially, but it’s not unusual for our testing
    and development artifacts (for example, user stories, test scripts, code) to be
    much larger.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在提示中的`{relevant_document}`点提供与初始查询在`{user_input}`点相关的数据，我们得到一个准确性和价值都提高的响应。但这确实提出了一个问题：为什么一开始就要寻找相关数据呢？我们难道不能只发送每个提示中已有的数据，从而消除进行相关性检查的需要吗？选择添加到提示中的文档很重要，原因有几个。首先，考虑我们可以创建的提示大小。我们可以发送给LLM的提示大小取决于其最大序列长度或上下文窗口。上下文窗口定义了一个LLM可以处理多少个单词或token。如果我们添加的token超过了上下文窗口允许的数量，那么LLM将要么在提示末尾截断多余的token（导致提示部分完成），要么返回错误。用实际的话来说，Meta的开源LLM
    Llama-2默认的上下文窗口为4096个token，这大约相当于一本书的10页的平均等效长度。这最初可能感觉很多，但我们的测试和开发工件（例如，用户故事、测试脚本、代码）通常要大得多。
- en: Tokens and enterprise AI costs
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: Token和企业AI成本
- en: How many tokens we send in a prompt is an important consideration if we’re working
    with models that charge based on the number of tokens that are sent. For example,
    at the time of writing, the gpt-4 turbo model, which has a context window of 128k,
    charges $10 per 1 million tokens. So, if we were attempting to max out the context
    window for each prompt, we would be paying approximately $1.28 per prompt, which
    would drain our budget fast. Therefore, efficient RAG prompting can be as much
    about keeping the bills down as it is about getting the most accurate response
    back from an LLM.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们使用按发送的token数量收费的模型时，我们在提示中发送了多少token是一个重要的考虑因素。例如，在撰写本文时，具有128k上下文窗口的gpt-4
    turbo模型，每100万个token收费10美元。因此，如果我们试图为每个提示最大化上下文窗口，我们将大约为每个提示支付1.28美元，这会迅速耗尽我们的预算。因此，高效的RAG提示不仅关乎从LLM获得最准确的响应，还关乎降低账单。
- en: New LLMs appear with much larger context windows that could potentially solve
    the problem of a prompt size. However, this leads us to our next reason for using
    relevancy searches—accuracy. If we were to use a larger context window, such as
    the 128k context window of gpt-4, we might be tempted to add more contextual data.
    But it runs the risk of diluting the quality of the response from an LLM. The
    more data we provide, the more potential noise we add to the prompt for the LLM
    to parse, which may lead to more generalized or unwanted responses. It can also
    make debugging of prompts and responses harder. As we’ve explored multiple times
    in previous chapters, we want to create the right type of prompts that maximize
    the chances of a desirable response. Therefore, targeting specific information
    to provide in a prompt can increase that chance, which means striking a balance
    between not too much context as to water down a response and not too little context
    as to miss out on important details.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 新的LLM出现了，它们具有更大的上下文窗口，这可能会解决提示大小的问题。然而，这让我们想到了使用相关性搜索的下一个原因——准确性。如果我们使用更大的上下文窗口，例如gpt-4的128k上下文窗口，我们可能会倾向于添加更多的上下文数据。但这会降低LLM响应的质量。我们提供的数据越多，我们向LLM的提示中添加的潜在噪声就越多，这可能导致更普遍或不受欢迎的响应。这也会使提示和响应的调试变得更加困难。正如我们在前几章多次探讨的那样，我们希望创建正确的提示类型，以最大化获得期望响应的机会。因此，在提示中提供特定的信息可以提高这种机会，这意味着在不过度稀释响应和遗漏重要细节之间取得平衡。
- en: Finally, by storing the corpus of data separately from our prompt generation
    and LLM, we have better control over said data, which allows us to update the
    stored data as required. Although vector databases (something we’ll explore in
    detail later in the chapter) have become a tool that is synonymous with RAG platforms,
    we can use any source of data we like. As long as we can find the relevant data
    to be added to our prompt, RAG offers a lot of freedom in accessing data for additional
    context.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，通过将数据语料库与我们的提示生成和LLM分开存储，我们更好地控制了这些数据，这使我们能够根据需要更新存储的数据。尽管向量数据库（我们将在本章后面详细探讨）已成为与RAG平台同义的工具，但我们可以使用我们喜欢的任何数据源。只要我们能找到要添加到我们的提示中的相关数据，RAG在访问数据以获取额外上下文方面提供了很多自由度。
- en: 11.2 Building a RAG setup
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.2 构建RAG设置
- en: 'Now that we learned how RAG frameworks work, to better appreciate the parts,
    let’s see how to build a basic RAG setup. We’ll do this by creating a framework
    that will execute the following steps:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了RAG框架的工作原理，为了更好地理解各个部分，让我们看看如何构建一个基本的RAG设置。我们将通过创建一个将执行以下步骤的框架来实现这一点：
- en: Ingest a collection of text documents containing user stories.
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 摄入包含用户故事的文本文档集合。
- en: Query the collection of user stories and find the most relevant document based
    on a user query.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查询用户故事集合，并根据用户查询找到最相关的文档。
- en: Add the relevant document and user query to a prompt and send it to gpt-3.5-turbo
    via the OpenAI platform.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将相关文档和用户查询添加到提示中，并通过OpenAI平台将其发送到gpt-3.5-turbo。
- en: Parse the response and output the details of what the LLM returned.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解析响应并输出LLM返回的详细信息。
- en: Activity 11.1
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 活动11.1
- en: In this part of the chapter, we’ll go through the steps required to build a
    basic example of a RAG system. If you would like to follow along with the example
    and build your own, download the initial code required for this framework from
    [https://mng.bz/gAlR](https://mng.bz/gAlR). All the necessary supporting code
    can be found in the repository, as well as a completed version of the RAG framework
    stored in `CompletedRAGDemo` for reference.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的这一部分，我们将介绍构建RAG系统基本示例所需的步骤。如果您想跟随示例并构建自己的系统，请从[https://mng.bz/gAlR](https://mng.bz/gAlR)下载此框架所需的初始代码。所有必要的支持代码都可以在存储库中找到，以及存储在`CompletedRAGDemo`中的RAG框架的完整版本供参考。
- en: 11.2.1 Building our RAG framework
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2.1 构建我们的RAG框架
- en: 'We’ll begin with a partially completed project that can also be found in the
    example framework code on GitHub. The project contains the following info to help
    us get started:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从GitHub上示例框架代码中可以找到的未完成项目开始。该项目包含以下信息以帮助我们开始：
- en: A corpus of data that can be found in `resources/data`
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储在`resources/data`中的数据语料库
- en: The necessary dependencies required to build and run our RAG framework in `pom.xml`
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在`pom.xml`中构建和运行我们的RAG框架所需的必要依赖项
- en: '`ActivityRAGDemo`, which contains an empty `main` method where we’ll add our
    framework'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ActivityRAGDemo`，其中包含一个空的`main`方法，我们将在此处添加我们的框架'
- en: 'Before we begin building our RAG framework, let’s review the dependencies stored
    in our `pom.xml` file we’ll be using. These libraries will help us parse our documents
    and send our prompt to the OpenAI platform:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始构建我们的RAG框架之前，让我们回顾一下我们将在其中使用的`pom.xml`文件中存储的依赖项。这些库将帮助我们解析我们的文档并将我们的提示发送到OpenAI平台：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: ❶ Adds all the user story text files into a string collection
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将所有用户故事文本文件添加到字符串集合中
- en: ❷ Provides the functionality to do a similarity check on string collection
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 提供在字符串集合上进行相似性检查的功能
- en: ❸ Sends our prompt to the OpenAI platform
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 将我们的提示发送到OpenAI平台
- en: 'With our dependencies in place, we now need to import the collection of user
    stories stored in each text file. Each user story focuses on a specific API endpoint
    for the sandbox application restful-booker-platform ([https://mng.bz/5Oy1](https://mng.bz/5Oy1)).
    Here’s an example:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的依赖项就绪后，我们现在需要导入存储在每个文本文件中的用户故事集合。每个用户故事都关注沙盒应用程序restful-booker-platform（[https://mng.bz/5Oy1](https://mng.bz/5Oy1)）的特定API端点。以下是一个示例：
- en: As a guest in order to cancel my booking I want to be able to send a DELETE
    request with the booking ID.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为客人，为了取消我的预订，我想要能够发送带有预订ID的DELETE请求。
- en: 'Acceptance Criteria:'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接受标准：
- en: The endpoint should accept a booking ID as a parameter in the path.
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 端点应接受预订ID作为路径中的参数。
- en: If a valid booking ID is provided, the server should cancel the booking and
    respond with a status of “OK” (200).
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果提供了有效的预订ID，服务器应取消预订并响应状态为“OK”（200）。
- en: If the booking ID is invalid or missing, the server should respond with a “Bad
    Request” error (400).
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果预订 ID 无效或缺失，服务器应响应一个“Bad Request”错误（400）。
- en: Optionally, a token can be provided in the cookie for authentication.
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可选地，可以在 cookie 中提供一个令牌进行身份验证。
- en: These user stories have been synthetically generated for this project’s purpose,
    but we could imagine that this data could have been extracted from a project management
    platform, a test management tool, or any type of structured data that we feel
    is relevant, from monitoring metrics to wiki entries.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这些用户故事是为了这个项目的目的而合成的，但我们可以想象这些数据可能已经被从项目管理平台、测试管理工具或任何我们认为相关的结构化数据中提取出来，从监控指标到维基条目。
- en: 'To pull in our user stories, we first need to add the following method to our
    `ActivityRAGDemo` class:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了引入我们的用户故事，我们首先需要将以下方法添加到我们的 `ActivityRAGDemo` 类中：
- en: '[PRE1]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ❶ Takes the folder location as a parameter
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 以文件夹位置作为参数
- en: ❷ Locates the folder within resources
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 在资源中定位文件夹
- en: ❸ Iterates through each file in the folder and its contents to a list
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 遍历文件夹中的每个文件及其内容到列表中
- en: ❹ Returns the list of file contents for further use
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 返回文件内容列表以供进一步使用
- en: 'The method `loadFilesFromResources` gives us the ability to load all the user
    story files into a list of strings that we can later query. To test whether this
    has worked, we create a `main` method that we can execute to run our RAG setup:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 方法 `loadFilesFromResources` 给我们提供了将所有用户故事文件加载到字符串列表中的能力，我们可以稍后查询这些文件。为了测试这是否有效，我们创建了一个
    `main` 方法，我们可以执行它来运行我们的 RAG 设置：
- en: '[PRE2]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: ❶ Loads files from the data folder inside of resources
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从资源文件夹内的数据文件夹加载文件
- en: ❷ Prints out the first file in the collection
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 打印出集合中的第一个文件
- en: 'After running this code within our IDE, we’ll see the following result output
    to confirm that our user stories are indeed being added to a list for future querying:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的 IDE 中运行此代码后，我们将看到以下结果输出以确认我们的用户故事确实被添加到列表中以便将来查询：
- en: As a guest in order to update branding information I want to be able to send
    a PUT request to /branding/ with necessary parameters.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为访客，为了更新品牌信息，我希望能够发送一个包含必要参数的 PUT 请求到 /branding/。
- en: Acceptance criteria
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接受标准
- en: I should be able to send a PUT request to /branding/ with the necessary parameters
    including the branding information in the request body and an optional token in
    the cookie.
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我应该能够发送一个包含请求体中的必要参数（包括品牌信息）和可选令牌的 cookie 的 PUT 请求到 /branding/。
- en: If the request is successful, the response status should be 200 OK.
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果请求成功，响应状态应为 200 OK。
- en: If the request is unsuccessful due to bad parameters or missing data, the response
    status should be 400 Bad Request.
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果请求由于参数错误或数据缺失而失败，响应状态应为 400 错误请求。
- en: The request body should contain valid JSON data conforming to the schema defined
    in the Swagger JSON.
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请求体应包含符合 Swagger JSON 中定义的模式的有效 JSON 数据。
- en: 'Next, we want to consider the prompt that we’ll be sending to gpt3.5-turbo.
    We’ll utilize some of the tactics that should now feel comfortable to us in the
    following prompt:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们想要考虑我们将发送给 gpt3.5-turbo 的提示。我们将在以下提示中利用一些我们现在应该感到熟悉的策略：
- en: '|'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-MW.png)'
- en: '| You are an expert software tester that makes recommendations for testing
    ideas and risks. You answer with suggested risks to test for, based on the provided
    user story delimited by three hashes and user input that is delimited by three
    backticks.Compile a list of suggested risks to test for, based on the user story
    and the user input.###{relevant_document}###[PRE3] |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 你是一位专家软件测试员，负责提出测试想法和风险建议。你根据提供的三哈希分隔的用户故事和三反引号分隔的用户输入回答，提出建议的风险进行测试。编译基于用户故事和用户输入的建议风险列表。###{relevant_document}###[PRE3]
    |'
- en: 'Notice how we’ve parameterized the relevant document and user input sections.
    Eventually, our code will be replacing these two sections with the relevant documentation
    and our initial query for processing. We’ll come to that shortly, but first, we
    need to add the prompt to our code base:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们如何参数化了相关的文档和用户输入部分。最终，我们的代码将用相关的文档和我们的初始查询来替换这两个部分。我们很快就会做到这一点，但首先，我们需要将提示添加到我们的代码库中：
- en: '[PRE4]                                                                 ❷'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE4]                                                                 ❷'
- en: '{user_input}                                                        ❷'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '{user_input}                                                        ❷'
- en: '[PRE5]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ❶ Loads files from the resources folder
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 从资源文件夹加载文件
- en: ❷ Defines the prompt to send to OpenAI
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 定义发送给 OpenAI 的提示
- en: 'Our next step is to work out which of our user stories is most relevant to
    the query that we will eventually be inputting. For this, we’ll be using the Apache
    `commons-text` library, which offers a range of different relevancy tools such
    as Levenshtein distance, Jaccard similarity, and the one we’ll be using—Cosine
    distance. How these different similarity tools work is beyond the scope of this
    book, but it’s worth noting that this area of RAG can influence what data is returned.
    Various similarity algorithms work in different ways and can become quite complex
    in production-ready RAG systems. Still, it’s worthwhile experimenting with basic
    approaches to gain a sense of how this part of a RAG system works, so we’ll create
    our similarity-matching method and add it into our class:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的下一步是确定我们的用户故事中哪一个与我们最终要输入的查询最相关。为此，我们将使用 Apache `commons-text` 库，它提供了一系列不同的相关性工具，例如
    Levenshtein 距离、Jaccard 相似度和我们将要使用的——余弦距离。这些不同的相似性工具是如何工作的超出了本书的范围，但值得注意的是，RAG
    的这个领域可以影响返回的数据。各种相似性算法以不同的方式工作，并且在生产就绪的 RAG 系统中可能会变得相当复杂。尽管如此，尝试基本方法以了解 RAG 系统的这一部分是如何工作的还是值得的，因此我们将创建我们的相似性匹配方法并将其添加到我们的类中：
- en: '[PRE6]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ❶ Takes the list of user stories and the user query as params
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 将用户故事列表和用户查询作为参数
- en: ❷ Uses cosineDistance to generate a similarity score
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 使用余弦距离生成相似度分数
- en: ❸ Checks whether the current score is lower than the currently most relevant
    score
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 检查当前分数是否低于当前最相关的分数
- en: ❹ Returns the entry in the list that is the closest match
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 返回列表中最接近的匹配项
- en: The method loops through each document and uses `cosineDistance` to work out
    a similarity score. The lower the score, the more similar the document is to the
    query. The lowest-scoring document is eventually the one that is returned to us
    for use in our prompt.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 该方法遍历每个文档，并使用 `cosineDistance` 计算相似度分数。分数越低，文档与查询的相似度越高。最终得分最低的文档是我们返回用于提示的文档。
- en: Working with different types of relevancy algorithms
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 与不同类型的相关性算法一起工作
- en: '`cosineDistance` is just one of many different tools we can use to determine
    relevancy, and each has its own pros and cons. We’ll look at further tools later
    in this chapter to improve the relevancy search, but for now, `cosineDistance`
    will help us build a working prototype that we can iterate on.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '`cosineDistance` 只是我们可以用来确定相关性的许多不同工具之一，每个都有自己的优缺点。我们将在本章后面进一步探讨其他工具以改进相关性搜索，但就目前而言，`cosineDistance`
    将帮助我们构建一个可以迭代的可工作原型。'
- en: 'Now we can create the necessary code to complete our prompt generation. To
    do this, we expand our `main` method to first allow a user to enter their query
    and then do a similarity check before adding it all into a prompt:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以创建必要的代码来完成我们的提示生成。为此，我们扩展了 `main` 方法，首先允许用户输入他们的查询，然后在进行相似性检查之前将其全部添加到提示中：
- en: '[PRE7]                                                               ❷'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE7]                                                               ❷'
- en: '{user_input}                                                      ❷'
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '{user_input}                                                      ❷'
- en: '[PRE8]'
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: ❶ Waits for a user to input their query via the command line
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 等待用户通过命令行输入他们的查询
- en: ❷ Loads files from the resources folder
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 从资源文件夹加载文件
- en: ❸ Finds the closest match to the user input in the loaded files
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 在加载的文件中找到与用户输入最接近的匹配项
- en: ❹ Replaces the placeholder parameters in the prompt
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 替换提示中的占位符参数
- en: 'We can now run this method, and when asked to add in a query, we can test out
    the generation of our prompt by submitting a query such as:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以运行这个方法，当被要求添加查询时，我们可以通过提交一个查询来测试我们的提示生成，例如：
- en: '|'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-MW.png)'
- en: '| I want test ideas for the GET room endpoint |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 我想要测试 GET 房间端点的测试想法 |'
- en: 'Sending this results in the following prompt being built:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 发送此查询将构建以下提示：
- en: '|'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-MW.png)'
- en: '| You are an expert software tester that makes recommendations for testing
    ideas and risks. You answer with suggested risks to test for, based on the provided
    user story delimited by three hashes and user input that is delimited by three
    backticks.Compile a list of suggested risks to test for, based on the user story
    and the user input.###As a guestIn order to browse available roomsI want to be
    able to retrieve a list of all available roomsAcceptance Criteria:   *   I should
    receive a response containing a list of available rooms   *   If there are no
    available rooms, I should receive an empty list   *   If there’s an error retrieving
    the room list, I should receive a 400 Bad Request errorHTTP Payload Contract'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '| 你是一位专家软件测试员，负责提出测试想法和风险建议。你将根据提供的三哈希分隔的用户故事和三反引号分隔的用户输入回答。根据用户故事和用户输入，编制一个建议的风险测试列表。###作为访客，为了浏览可用的房间，我希望能够检索所有可用房间的列表验收标准：  
    *   我应该收到包含可用房间列表的响应   *   如果没有可用房间，我应该收到一个空列表   *   如果在检索房间列表时发生错误，我应该收到一个 400
    Bad Request 错误HTTP有效载荷合约'
- en: '[PRE9]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10] |'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE10] |'
- en: 'As we can see, the user query has been added to the bottom of the prompt, and
    the user story that has been injected is the one that our `findClosestMatch` method
    has deemed the most relevant. It’s at this point that we’ll start to see limitations
    with our implementation. Trying out different queries will likely result in the
    selection of a less relevant user story. For example, using this query:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，用户查询已被添加到提示的底部，而注入的用户故事是我们 `findClosestMatch` 方法认为最相关的那个。正是在这一点上，我们将开始看到我们实现的局限性。尝试不同的查询可能会选择一个不那么相关的用户故事。例如，使用以下查询：
- en: '|'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-MW.png)'
- en: '| I want a list of risks to test for the delete booking endpoint |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 我想要一个用于测试删除预订端点的风险列表 |'
- en: 'results in the following user story being selected:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 导致以下用户故事被选中：
- en: '|'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-MW.png)'
- en: '| As a guestIn order to retrieve information about a bookingI want to be able
    to send a GET request with the booking ID |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 作为访客，为了检索预订信息，我希望能够使用预订 ID 发送 GET 请求 |'
- en: This is because the `cosineDistance` method is limited in how well it can determine
    relevancy. We’ll explore how this can be handled later in the chapter, but it
    does highlight a limitation or risk of working with RAG frameworks.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为 `cosineDistance` 方法在确定相关性方面存在局限性。我们将在本章后面探讨如何处理这个问题，但它确实突显了与 RAG 框架一起工作的局限性或风险。
- en: 'Nevertheless, let’s complete our RAG framework so that it can send the prompt
    to OpenAI’s GPT model to get a response. For this, we’ll be using LangChain again
    to send our prompt to OpenAI and output a response:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，让我们完成我们的 RAG 框架，以便它可以向 OpenAI 的 GPT 模型发送提示以获取响应。为此，我们将再次使用 LangChain 将我们的提示发送到
    OpenAI 并输出响应：
- en: '[PRE11]                                                                  ❸'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[PRE11]                                                                  ❸'
- en: '{user_input}                                                         ❸'
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '{user_input}                                                         ❸'
- en: '[PRE12]'
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ❶ Receives the user’s query for RAG
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: ❶ 接收用户对 RAG 的查询
- en: ❷ Loads files from the resources folder
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ❷ 从资源文件夹中加载文件
- en: ❸ Defines the prompt to be sent to OpenAI
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: ❸ 定义要发送给 OpenAI 的提示
- en: ❹ Finds the closest match to the user query in the loaded files
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: ❹ 在加载的文件中找到与用户查询最接近的匹配项
- en: ❺ Replaces placeholders in the prompt with the user query and file
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: ❺ 将提示中的占位符替换为用户查询和文件
- en: ❻ Instantiates a new GPT client using an Open AI key
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: ❻ 使用 Open AI 密钥实例化一个新的 GPT 客户端
- en: ❼ Sends the prompt to gpt3.5-turbo and prints the response
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: ❼ 将提示发送到 gpt3.5-turbo 并打印响应
- en: Providing an OPEN_AI_KEY
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 提供一个 OPEN_AI_KEY
- en: To send a request to OpenAI, a Project API key must be provided, which can be
    generated at [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys).
    You will need to create either a new account with the OpenAI platform or, depending
    on whether your credits have expired, add credit to your account, which can be
    done via [https://mng.bz/6YMD](https://mng.bz/6YMD). Once it’s set up, you will
    need to either add your Project API key directly in the code, replacing `System.getenv("OPEN_AI_KEY"),`
    or store your key as an environmental variable under the title `OPEN_AI_KEY`.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 要向OpenAI发送请求，必须提供项目API密钥，该密钥可以在[https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)生成。您需要创建一个新账户或根据您的信用是否已过期，向账户添加信用，这可以通过[https://mng.bz/6YMD](https://mng.bz/6YMD)完成。一旦设置好，您需要直接在代码中添加您的项目API密钥，替换`System.getenv("OPEN_AI_KEY")`，或者将密钥作为标题为`OPEN_AI_KEY`的环境变量存储。
- en: 'With our GPT implementation in place, we should now have a class to run that
    looks similar to this example:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的GPT实现到位后，我们现在应该有一个运行类，其外观类似于以下示例：
- en: '[PRE13]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '{user_input}'
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '{user_input}'
- en: '[PRE14]'
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'To recap, we’ve created the necessary code to:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我们已经创建了必要的代码来：
- en: Load in a corpus of documents (in this instance, user stories)
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加载文档集合（在这个例子中，是用户故事）
- en: Take in a user query via the command line
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过命令行接收用户查询
- en: Use the query to find the most relevant document
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用查询找到最相关的文档
- en: Add both the query and the document to our prompt
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将查询和文档添加到我们的提示中
- en: Send the prompt to OpenAI and return a response
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将提示发送到OpenAI并返回响应
- en: With everything in place, we’re ready to start up our RAG framework and test
    it out.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 一切准备就绪，我们现在可以启动我们的RAG框架并进行测试。
- en: 11.2.2 Testing our RAG framework
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2.2 测试我们的RAG框架
- en: 'Once our RAG framework is up and running, we should be asked what query we
    would like to input. To test out our RAG framework, we can try inputting the following
    query:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的RAG框架启动并运行，我们应该会被询问我们想要输入什么查询。为了测试我们的RAG框架，我们可以尝试输入以下查询：
- en: '|'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/logo-openai.png)'
- en: '| What would you like help with? |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 你需要帮助什么？ |'
- en: '|'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/logo-MW.png)'
- en: '| I want test ideas for the payload portion of the PUT branding endpoint |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 我想要测试PUT品牌端点负载部分的测试想法 |'
- en: 'Our query retrieves the following user story from our corpus:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的查询从我们的文档集合中检索以下用户故事：
- en: '|'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/logo-MW.png)'
- en: '| As a guestIn order to update branding informationI want to be able to send
    a PUT request to /branding/ with necessary parametersAcceptance criteria   *  
    I should be able to send a PUT request to /branding/ with the necessary parameters
    including the branding information in the request body and an optional token in
    the cookie.   *   If the request is successful, the response status should be
    200 OK.   *   If the request is unsuccessful due to bad parameters or missing
    data, the response status should be 400 Bad Request.   *   The request body should
    contain valid JSON data conforming to the schema defined in the Swagger JSON.HTTP
    Payload contract'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '| 作为访客，为了更新品牌信息，我希望能够向/branding/发送带有必要参数的PUT请求。验收标准   *   我应该能够向/branding/发送带有请求体中的品牌信息和可选令牌的cookie的PUT请求。  
    *   如果请求成功，响应状态应该是200 OK。   *   如果请求因参数错误或数据缺失而失败，响应状态应该是400 Bad Request。   *  
    请求体应包含符合Swagger JSON定义的模式的有效JSON数据.HTTP有效负载合同'
- en: '[PRE15]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '|'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'The resulting response from gpt3.5-turbo will look something like the response
    I received:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: gpt3.5-turbo生成的响应将类似于我收到的响应：
- en: '|'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/logo-openai.png)'
- en: '| Based on the user input, here are some suggested risks to test for:   1. 
    Missing required parameters in the request body, such as name, map (latitude and
    longitude), logoUrl, description, contact information (name, address, phone, email)
    - Risk based on the user story mentioning necessary parameters in the request
    body.   2.  Sending invalid data types for parameters in the request body, such
    as sending a number instead of a string for the name field - Risk based on the
    HTTP Payload contract defined in the user story.   3.  Sending invalid JSON data
    that does not conform to the defined schema in the Swagger JSON - Risk based on
    the acceptance criteria specifying valid JSON data conforming to the schema.  
    4.  Not including the optional token in the cookie when sending the PUT request
    - Risk based on the acceptance criteria mentioning an optional token in the cookie.  
    5.  Sending a PUT request to the wrong endpoint or with incorrect formatting -
    Risk based on the user story requiring the PUT request to be sent to /branding/
    with necessary parameters. |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 基于用户输入，以下是一些建议测试的风险：   1. 请求体中缺少必要的参数，例如名称、地图（纬度和经度）、logoUrl、描述、联系方式（姓名、地址、电话、电子邮件）
    - 基于用户故事中提到的请求体中必要的参数。   2. 在请求体中发送无效的数据类型，例如将名称字段发送为数字而不是字符串 - 基于用户故事中定义的HTTP有效载荷合同。  
    3. 发送不符合Swagger JSON中定义的模式的无效JSON数据 - 基于接受标准中指定符合模式的有效JSON数据。   4. 在发送PUT请求时，未在cookie中包含可选的令牌
    - 基于接受标准中提到的cookie中可选令牌。   5. 向错误的端点发送PUT请求或格式不正确 - 基于用户故事要求将PUT请求发送到/branding/并带有必要的参数。
    |'
- en: As expected, the response contains the list of risks we asked for, but what
    is notable is how it has returned context-specific details. For example, for the
    first risk that is focused on missing required parameters, we can see that it
    calls out specific parameters that exist in the HTTP payload example within the
    user story. We can also see that other risks refer to content written in the acceptance
    criteria, such as the use of an optional token stored within cookies (mentioned
    in risk 4).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，响应包含了我们请求的风险列表，但值得注意的是它返回了特定上下文的详细信息。例如，对于专注于缺少必要参数的第一个风险，我们可以看到它指出了用户故事中HTTP有效载荷示例中存在的特定参数。我们还可以看到其他风险引用了接受标准中编写的内容，例如在cookie中存储的可选令牌的使用（如风险4中所述）。
- en: 'The context-specific information provided in the response exists because of
    the additional details we provided within the prompt in the form of our user story.
    To demonstrate how important this additional information is to the quality of
    an LLM response, here is an example of a response I received using the same prompt
    without the user story added:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 响应中提供的特定上下文信息是因为我们在提示中提供的额外细节，这些细节以我们的用户故事的形式存在。为了展示这些额外信息对于LLM响应质量的重要性，以下是一个使用相同提示但未添加用户故事的响应示例：
- en: '|'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-openai.png)'
- en: '|    1.  Data validation: Test that the payload accepts only the allowed data
    types and formats as specified in the API documentation. This could help ensure
    that invalid data does not cause unexpected behavior in the system. (Based on
    the need to test the payload portion of the PUT branding endpoint)   2.  Boundary
    testing: Test the system’s behavior when the payload includes data at the upper
    and lower limits of allowed values. This could help uncover any edge cases where
    the system may not handle extreme values correctly. (Based on the need to test
    the payload portion of the PUT branding endpoint)   3.  Performance testing: Test
    the system’s response time and resource usage when handling large payloads. This
    could reveal any performance bottlenecks or issues with scalability. (Based on
    the need to test the payload portion of the PUT branding endpoint)   4.  Security
    testing: Test for any vulnerabilities related to the payload input, such as SQL
    injection or cross-site scripting attacks. This could help ensure that the system
    is secure against malicious input. (Based on the need to test the payload portion
    of the PUT branding endpoint) |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '|   1.  数据验证：测试负载只接受API文档中指定的允许的数据类型和格式。这有助于确保无效数据不会导致系统出现意外行为。（基于测试PUT品牌端点的负载部分的需求）  
    2.  边界测试：测试当负载包含允许值的上下限数据时系统的行为。这有助于揭示系统可能无法正确处理极端值的任何边缘情况。（基于测试PUT品牌端点的负载部分的需求）  
    3.  性能测试：测试系统处理大量负载时的响应时间和资源使用情况。这可能揭示任何性能瓶颈或可扩展性问题。（基于测试PUT品牌端点的负载部分的需求）   4.  安全测试：测试与负载输入相关的任何漏洞，如SQL注入或跨站脚本攻击。这有助于确保系统对恶意输入的安全性。（基于测试PUT品牌端点的负载部分的需求）
    |'
- en: As we can see, the items returned are more generic and shallow because our prompt
    lacks that additional context information, thus demonstrating the value of a RAG
    system in prompting LLMs.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，返回的项目更加通用和浅显，因为我们的提示缺少额外的上下文信息，从而证明了RAG系统在提示LLM中的价值。
- en: 'However, RAG frameworks do have limitations, and our basic framework is no
    different. For example, if we were to send this query:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，RAG框架确实存在局限性，我们的基本框架也不例外。例如，如果我们发送以下查询：
- en: '|'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-MW.png)'
- en: '| What risks should I consider for the Auth API? |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 我应该考虑哪些风险因素用于Auth API？ |'
- en: 'we might get a response like the following, which is returning information
    that is of no use to us:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能会收到如下类似的回复，其中返回的信息对我们来说没有用处：
- en: '|'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-openai.png)'
- en: '|    1.  Risk: Unable to successfully delete a room by providing a valid room
    ID   •   This risk is based on the acceptance criteria of being able to successfully
    delete a room by providing a valid room ID.   2.  Risk: Incorrect error handling
    for invalid room ID   •   This risk is based on the acceptance criteria of receiving
    a 400 Bad Request error when providing an invalid room ID.   3.  Risk: Confirmation
    message not displayed upon successful deletion   •   This risk is based on the
    acceptance criteria of receiving a confirmation message upon successful deletion.
    |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '|   1.  风险：无法通过提供有效的房间ID成功删除房间   •   此风险基于能够通过提供有效的房间ID成功删除房间的验收标准。   2.  风险：对无效房间ID的错误处理不正确  
    •   此风险基于在提供无效房间ID时收到400 Bad Request错误的验收标准。   3.  风险：成功删除后未显示确认消息   •   此风险基于在成功删除后收到确认消息的验收标准。
    |'
- en: Although this might feel like our LLM is hallucinating, the problem lies in
    our relevancy checking. Our query is focused on the Auth API, which includes login,
    logout, and validate endpoints, but the mention of `room ID` in the response implies
    that a room-based user story was deemed the most relevant. Once again, we see
    the challenge of finding the most relevant data to provide in a RAG framework
    when we start to consider pulling relevant data from multiple data sources at
    once. Therefore, to progress, we need to consider more advanced tooling to help
    us improve the performance of our relevancy searches to optimize the LLM’s responses.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这可能会感觉我们的LLM在产生幻觉，但问题在于我们的相关性检查。我们的查询集中在Auth API上，包括登录、登出和验证端点，但响应中提到的`房间ID`暗示了一个基于房间的用户故事被认为是最相关的。再次，我们看到在从多个数据源同时提取相关数据时，在RAG框架中找到最相关数据的挑战。因此，为了进步，我们需要考虑更高级的工具来帮助我们改进相关性搜索的性能，以优化LLM的响应。
- en: Activity 11.2
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 活动第11.2节
- en: Try out different types of queries based on the user stories found in the project.
    See which queries returned desired results and which didn’t. Consider what tweaks
    we could make to improve the erroneous queries.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试基于项目中发现的用户故事的不同类型的查询。看看哪些查询返回了期望的结果，哪些没有。考虑我们可以对错误的查询进行哪些调整以改进它们。
- en: 11.3 Enhancing data storage for RAG
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.3 增强RAG的数据存储
- en: Now that we have a deeper understanding of how RAG works, we can begin to explore
    the types of tools in the market that allow us to quickly implement a framework
    with our data. The process of finding the right type of data to bolster our prompts
    can be tricky, but there are some tools and platforms on the market that make
    setting up RAG frameworks easier through the use of SaaS platforms and vector
    databases. So, let’s conclude our exploration into RAG by discussing briefly what
    vector databases are, how they help, and how we can use one for our needs.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对 RAG 的工作原理有了更深入的了解，我们可以开始探索市场上允许我们快速使用我们的数据实现框架的工具类型。寻找合适的类型的数据来增强我们的提示的过程可能很棘手，但市场上有一些工具和平台通过使用
    SaaS 平台和向量数据库，使设置 RAG 框架变得更加容易。因此，让我们通过简要讨论向量数据库是什么，它们如何帮助，以及我们如何根据我们的需求使用它们来结束我们对
    RAG 的探索。
- en: 11.3.1 Working with Vector databases
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.1 与向量数据库一起工作
- en: Unlike a SQL database, in which data is stored as different data types within
    rows inside tables, *vector* databases store data in the form of mathematical
    representations. Specifically, they are stored as *vectors,* which is a collection
    of numbers that represent an entity’s location across multiple dimensions.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 与存储在表格行内的不同数据类型中的 SQL 数据库不同，*向量*数据库以数学表示的形式存储数据。具体来说，它们以*向量*的形式存储，即表示一个实体在多个维度上的位置的数字集合。
- en: To give an example of how vectors work and why they are useful, let’s consider
    another area of software development that uses vectors—game development. Let’s
    say we have a character and two other entities in a 2D world and we want to know
    which of the entities is nearest to our character. We would use a vector that
    contains an X and Y position to determine the location of both. For example, if
    our character was in a central position on a map, their vector would be `(0,0)`.
    Now let’s say our entities were in X/Y positions (our vector dimensions) of `(5,5)`
    and `(10,10)`, as shown in figure 11.2.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 为了举例说明向量是如何工作的以及为什么它们是有用的，让我们考虑另一个使用向量的软件开发领域——游戏开发。假设我们在一个 2D 世界中有一个角色和两个其他实体，我们想知道哪个实体离我们的角色最近。我们会使用包含
    X 和 Y 位置的向量来确定两者的位置。例如，如果我们的角色在地图上的中心位置，他们的向量将是 `(0,0)`。现在假设我们的实体在 X/Y 位置（我们的向量维度）为
    `(5,5)` 和 `(10,10)`，如图 11.2 所示。
- en: We can see that the later entity with the position of `(10,10)` is farther away.
    But we can also calculate the distance of vectors mathematically by comparing
    them. So `(0,0)` to `(5,5)` generates a distance score of `7.071068`, and `(0,0)`
    to `(10,10)` has a distance score of `14.14214` (calculated using [https://mng.bz/o0lr](https://mng.bz/o0lr)).
    This, of course, is a basic example, but with vector databases, an entity may
    have vectors that contain many different dimensions, which makes the distance
    calculation much more complex.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，位置为 `(10,10)` 的后续实体距离更远。但我们可以通过比较它们来数学地计算向量的距离。因此 `(0,0)` 到 `(5,5)` 生成距离分数为
    `7.071068`，而 `(0,0)` 到 `(10,10)` 的距离分数为 `14.14214`（使用[https://mng.bz/o0lr](https://mng.bz/o0lr)计算）。这当然是一个基本示例，但使用向量数据库，一个实体可能包含包含许多不同维度的向量，这使得距离计算变得更加复杂。
- en: '![](../../OEBPS/Images/CH11_F02_Winteringham2.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH11_F02_Winteringham2.png)'
- en: Figure 11.2 Graph showing vectors of a character and entities
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.2 显示角色和实体的向量图
- en: How these vectors and the related dimensions for our documents are calculated
    is beyond the scope of this book, but it is important to recognize that the purpose
    of using a vector database is to allow us to programmatically work out how close
    an item of data we’re interested in is in relation to our query. In other words,
    we use vector databases to work out relevancy just like we did in our basic RAG
    framework. However, instead of doing it across one dimension, we can compare it
    against many different dimensions at once—meaning in the context of the work we’ve
    done so far, increasing the accuracy of which user stories are deemed relevant
    to our query. Because it also allows support for multiple relevancy, we can extract
    more than one entity or document to add to our prompt if it is within a range
    of relevancy.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这些向量以及我们文档的相关维度是如何计算的，这超出了本书的范围，但重要的是要认识到，使用向量数据库的目的是让我们能够编程地计算出我们感兴趣的数据项与我们的查询有多接近。换句话说，我们使用向量数据库来计算相关性，就像我们在基本的RAG框架中所做的那样。然而，我们不是在一维上这样做，而是可以同时与许多不同的维度进行比较——这意味着在我们迄今为止的工作中，这可以增加我们认为与我们的查询相关的用户故事准确性。因为它还支持多个相关性，所以如果我们感兴趣的数据项在相关性范围内，我们可以提取多个实体或文档添加到我们的提示中。
- en: 11.3.2 Setting up a vector-database-backed RAG
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.2 设置基于向量数据库的RAG
- en: There has been massive growth in the vector-database-backed RAG market, with
    tools such as LlamaIndex ([https://www.llamaindex.ai/](https://www.llamaindex.ai/))
    and Weviate ([https://weaviate.io/](https://weaviate.io/)). However, to get set
    up quickly with minimal setup and coding, we’ll be looking at a tool called Canopy,
    which is built by the company Pinecone ([https://www.pinecone.io/](https://www.pinecone.io/)).
    Pinecone offers the ability to create vector databases in the cloud, which are
    known as indexes on their platform. They have also created Canopy, a RAG framework
    that integrates with their cloud setup. Canopy is a great choice for a trial RAG
    framework because, unlike our earlier RAG framework, most of the work is taken
    care of by the framework. This means we can get started with a vector database-backed
    RAG framework much faster than if we were to build our own. This of course sacrifices
    control for convenience, but it will give us what we need to try out a vector-database-backed
    RAG. You can learn more about the different parts of Canopy in their README ([https://github.com/pinecone-io/canopy](https://github.com/pinecone-io/canopy)).
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 基于向量数据库的RAG市场已经经历了巨大的增长，例如LlamaIndex ([https://www.llamaindex.ai/](https://www.llamaindex.ai/))
    和 Weviate ([https://weaviate.io/](https://weaviate.io/))。然而，为了快速设置并尽可能减少设置和编码，我们将关注一个名为Canopy的工具，该工具由Pinecone公司
    ([https://www.pinecone.io/](https://www.pinecone.io/)) 构建。Pinecone提供在云中创建向量数据库的能力，在其平台上称为索引。他们还创建了Canopy，这是一个与他们的云设置集成的RAG框架。Canopy是一个很好的试验RAG框架选择，因为它与我们的早期RAG框架不同，框架处理了大部分工作。这意味着我们可以比我们自己构建时更快地开始使用基于向量数据库的RAG框架。当然，这牺牲了控制以换取便利，但它将为我们尝试基于向量数据库的RAG提供所需的一切。您可以在他们的README
    ([https://github.com/pinecone-io/canopy](https://github.com/pinecone-io/canopy))
    中了解更多关于Canopy的不同部分。
- en: Canopy prerequisites
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: Canopy先决条件
- en: To run Canopy, you will need Python 3.11 installed on your machine. This is
    only required to install Canopy. Once installed, we’ll exclusively use the Canopy
    SLI to set up our framework.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行Canopy，您需要在您的机器上安装Python 3.11。这只是为了安装Canopy。一旦安装，我们将独家使用Canopy SLI来设置我们的框架。
- en: To get us started, we’ll first need to install Canopy on our machine, which
    we do by running the `pip3 install canopy-sdk` command.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让我们开始，我们首先需要在我们的机器上安装Canopy，我们可以通过运行`pip3 install canopy-sdk`命令来实现。
- en: 'Once it’s installed, we then require a few API keys to get ourselves set up.
    First, we will need our OpenAI key, which can be found at [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys).
    Next, we’ll need to set up an account on Pinecone and extract the API key from
    it for Canopy to use to create our vector database. To do this, we need to sign
    up to Pinecone, which can be done here: [https://app.pinecone.io/?sessionType=login](https://app.pinecone.io/?sessionType=login).
    During the setup, you will be asked to provide a card for billing details to upgrade
    the free account to a standard one. We need to upgrade to a standard account to
    allow Canopy to create the necessary vector database. Failure to do so will cause
    Canopy to error when we begin to build our index for our RAG framework. At the
    time of writing the standard account is free, but it is unfortunately necessary
    to provide our account details to get access to the features we require.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦安装完成，我们还需要一些 API 密钥来设置我们的环境。首先，我们需要我们的 OpenAI 密钥，可以在 [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)
    找到。接下来，我们需要在 Pinecone 上设置一个账户并从中提取 API 密钥，以便 Canopy 使用它来创建我们的向量数据库。为此，我们需要在 Pinecone
    上注册，这可以通过以下链接完成：[https://app.pinecone.io/?sessionType=login](https://app.pinecone.io/?sessionType=login)。在设置过程中，您将被要求提供一张卡片以提供账单详细信息，以便将免费账户升级为标准账户。我们需要升级到标准账户，以便
    Canopy 能够创建必要的向量数据库。如果我们不这样做，当开始为我们的 RAG 框架构建索引时，Canopy 将会出错。撰写本文时，标准账户是免费的，但不幸的是，我们需要提供我们的账户详细信息才能访问我们所需的功能。
- en: 'Once we have created our Pinecone account and upgraded it to a standard one,
    we can start working with Canopy to create our RAG framework. To do this, we need
    to set some environmental variables:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们创建了 Pinecone 账户并将其升级为标准账户，我们就可以开始使用 Canopy 创建我们的 RAG 框架。为此，我们需要设置一些环境变量：
- en: '[PRE16]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Or alternatively, if you are using windows:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果你使用的是 Windows 系统：
- en: '[PRE17]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The API keys for Pinecone and OpenAI are straightforward and can be found in
    the respective admin sections for each platform. The third variable, though, will
    set the name of the index that will be created on Pinecone’s platform, so we need
    to pick a name for our index, such as `test-index`. Once we have these variables
    in place, we can start Canopy by running the `canopy new` command.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: Pinecone 和 OpenAI 的 API 密钥非常简单，可以在每个平台的相应管理部分找到。然而，第三个变量将设置在 Pinecone 平台上创建的索引的名称，因此我们需要为我们的索引选择一个名称，例如
    `test-index`。一旦我们设置了这些变量，我们就可以通过运行 `canopy new` 命令来启动 Canopy。
- en: Assuming our API keys are all correct and our Pinecone account is correctly
    upgraded, Canopy will set up a new index in Pinecone (see figure 11.3) that we
    can use to upload our documents when we’re ready.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们的 API 密钥都是正确的，并且我们的 Pinecone 账户已经正确升级，Canopy 将在 Pinecone 中设置一个新的索引（见图 11.3），我们可以用它来上传我们的文档，当我们准备好时。
- en: '![](../../OEBPS/Images/CH11_F03_Winteringham2.png)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH11_F03_Winteringham2.png)'
- en: Figure 11.3 Pinecone indexes after a Canopy run
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.3 Canopy 运行后的 Pinecone 索引
- en: 'With our index ready, we can begin uploading our user story documents (which
    can be found in the supporting repository at [https://mng.bz/n0dg](https://mng.bz/n0dg)).
    We do this by running Canopy’s `upsert` command and providing the root folder
    for our user stories:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们的索引准备就绪后，我们可以开始上传我们的用户故事文档（这些文档可以在支持库的 [https://mng.bz/n0dg](https://mng.bz/n0dg)
    找到）。我们通过运行 Canopy 的 `upsert` 命令并指定我们的用户故事根目录来完成此操作：
- en: '[PRE18]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This will kick off a process in which our user stories are uploaded into the
    index, and once the upload is completed, we can head back into Pinecone and confirm
    that they are present in our index, as shown in figure 11.4.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这将启动一个过程，我们的用户故事将被上传到索引中，一旦上传完成，我们就可以回到 Pinecone 并确认它们存在于我们的索引中，如图 11.4 所示。
- en: We now have everything loaded into our index and are ready to start up our RAG
    framework by running the `canopy start` command.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将所有内容加载到我们的索引中，并准备好通过运行 `canopy start` 命令启动我们的 RAG 框架。
- en: This starts the Canopy server, which we can now access to send our queries to.
    To access it, we open a new terminal/command prompt and run the `canopy` `chat`
    `--no-rag` command. (Be sure to export your `OPENAI_API_KEY` again if you start
    a new terminal window.)
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这将启动 Canopy 服务器，我们现在可以访问它来发送我们的查询。要访问它，我们打开一个新的终端/命令提示符并运行 `canopy chat --no-rag`
    命令。（如果启动了新的终端窗口，请务必再次导出您的 `OPENAI_API_KEY`。）
- en: 'Notice how we provide a flag of `--no-rag`. This enables Canopy to show, for
    comparison, both an output that uses RAG and an output that doesn’t. Upon starting
    up the chat feature, we’ll receive the following message to confirm that we’re
    ready to begin testing out our RAG framework:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们提供了`--no-rag`标志。这使Canopy能够显示，用于比较，使用RAG和不使用RAG的输出。在启动聊天功能后，我们会收到以下消息以确认我们已经准备好开始测试我们的RAG框架：
- en: '|'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![OpenAI标志](../../OEBPS/Images/logo-openai.png)'
- en: '| Let’s Chat!User message: ([Esc] followed by [Enter] to accept input) |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| 让我们聊天！用户消息：（按[Esc]后跟[Enter]接受输入） |'
- en: '![](../../OEBPS/Images/CH11_F04_Winteringham2.png)'
  id: totrans-200
  prefs: []
  type: TYPE_IMG
  zh: '![第11章第4图](../../OEBPS/Images/CH11_F04_Winteringham2.png)'
- en: Figure 11.4 An index uploaded with user stories
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.4 使用用户故事上传的索引
- en: 11.3.3 Testing a Vector-database-backed RAG framework
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.3 测试基于向量数据库的RAG框架
- en: 'With Canopy now ready to receive our queries, we can begin testing it out with
    queries and comparing the performance of our RAG framework. For example, sending
    the following query:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，Canopy已经准备好接收我们的查询，我们可以开始通过查询测试它，并比较我们的RAG框架的性能。例如，发送以下查询：
- en: '|'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![文档标志](../../OEBPS/Images/logo-MW.png)'
- en: '| List different types of tests for each JSON parameter in the PUT branding
    endpoint |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| 列出PUT品牌端点中每个JSON参数的不同类型测试 |'
- en: 'returned the following response (edited in size to make it easier to read):'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 返回了以下响应（已编辑以方便阅读）：
- en: '|'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![OpenAI标志](../../OEBPS/Images/logo-openai.png)'
- en: '| The different types of tests for each JSON parameter in the PUT branding
    endpoint include:   1.  **Name**:   •   Test for providing a valid string value
    for the name parameter.   2.  **Map (Latitude and Longitude)**:   •   Test for
    providing valid integer values for latitude and longitude parameters.   3.  **LogoUrl**:  
    •   Test for providing a valid string URL for the logoUrl parameter.   4.  **Description**:  
    •   Test for providing a valid string value for the description parameter.   5. 
    **Contact (Name, Address, Phone, Email)**:   •   Test for providing valid string
    values for name, address, phone, and email parameters in the contact object.These
    tests ensure that the JSON data provided in the request body of the PUT request
    to the branding endpoint conforms to the specified schema defined in the Swagger
    JSON.(Source: src/main/resources/data/put-branding.txt) |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| 在PUT品牌端点的PUT请求中，每个JSON参数的不同类型测试包括：   1.  **名称**：   •   测试为名称参数提供有效的字符串值。  
    2.  **地图（纬度和经度）**：   •   测试为纬度和经度参数提供有效的整数值。   3.  **LogoUrl**：   •   测试为logoUrl参数提供有效的字符串URL。  
    4.  **描述**：   •   测试为描述参数提供有效的字符串值。   5.  **联系（姓名、地址、电话、电子邮件）**：   •   测试在联系对象中为姓名、地址、电话和电子邮件参数提供有效的字符串值。这些测试确保在PUT请求的品牌端点的请求体中提供的JSON数据符合在Swagger
    JSON中定义的指定模式。（来源：src/main/resources/data/put-branding.txt） |'
- en: 'The response has a few notable points. First, the response has been structured
    around the different JSON parameters that have been defined within the user story.
    Second, we can see that Canopy has provided a reference at the bottom of the output
    (Source: src/main/resources/data/put-branding.txt) to indicate which sources have
    been deemed most relevant from the vector database. This means that, similar to
    the basic RAG framework we built earlier, this RAG framework is working as expected,
    which is even more striking when compared to how our query performed without RAG:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 响应有几个值得注意的点。首先，响应是围绕用户故事中定义的不同JSON参数来构建的。其次，我们可以看到Canopy在输出底部提供了一个参考（来源：src/main/resources/data/put-branding.txt），以表明哪些来源被认为与向量数据库中最相关。这意味着，与我们在前面构建的基本RAG框架类似，这个RAG框架正在按预期工作，与我们的查询在没有RAG时的表现相比，这一点更加引人注目：
- en: '|'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![OpenAI标志](../../OEBPS/Images/logo-openai.png)'
- en: '|    1.  Name:   −   Test for presence of name parameter   −   Test for invalid
    values (e.g. empty string, special characters)   2.  Logo:   −   Test for presence
    of logo parameter   −   Test for valid file format (e.g. PNG, JPEG)   −   Test
    for size limit (e.g. file size less than 5MB)   3.  Color:   −   Test for presence
    of color parameter   −   Test for valid color code format (e.g. hex code)   −  
    Test for invalid color values (e.g. ‘purple’ instead of ‘#123456’)   4.  Font:  
    −   Test for presence of font parameter   −   Test for valid font name or family  
    −   Test for invalid font values (e.g. empty string, special characters)   5. 
    Description:   −   Test for presence of description parameter   −   Test for valid
    length limit (e.g. less than 100 characters)   −   Test for invalid values (e.g.
    special characters, long strings)   6.  Website:   −   Test for presence of website
    parameter   −   Test for valid URL format   −   Test for invalid values (e.g.
    invalid domain, special characters) |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| 1. 名称：   −   测试名称参数的存在   −   测试无效值（例如空字符串，特殊字符）   2. 徽标：   −   测试徽标参数的存在  
    −   测试有效的文件格式（例如PNG，JPEG）   −   测试大小限制（例如文件大小小于5MB）   3. 颜色：   −   测试颜色参数的存在  
    −   测试有效的颜色代码格式（例如十六进制代码）   −   测试无效的颜色值（例如用‘purple’代替‘#123456’）   4. 字体：   −  
    测试字体参数的存在   −   测试有效的字体名称或系列   −   测试无效的字体值（例如空字符串，特殊字符）   5. 描述：   −   测试描述参数的存在  
    −   测试有效的长度限制（例如小于100个字符）   −   测试无效值（例如特殊字符，长字符串）   6. 网站：   −   测试网站参数的存在  
    −   测试有效的URL格式   −   测试无效值（例如无效域名，特殊字符） |'
- en: 'In this response, we can see that there is little connection to the context
    of our branding JSON payload. Again, this demonstrates the challenge we face when
    using LLMs and ensuring they have access to our context. But what about our previous
    problem with the basic RAG framework we created and its inability to bring in
    multiple user stories into a query? With Canopy backed with a vector database,
    we can test out how it performs with a query that has the potential to draw on
    multiple user stories in one single prompt:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个响应中，我们可以看到它与我们的品牌JSON负载的上下文几乎没有关联。再次，这证明了我们在使用LLMs并确保它们能够访问我们的上下文时所面临的挑战。但关于我们之前遇到的基本RAG框架及其无法将多个用户故事带入查询的问题怎么办？有了Canopy和向量数据库的支持，我们可以测试它在一个查询中的表现，这个查询有可能在一个单独的提示中调用多个用户故事：
- en: '|'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![文档徽标](../../OEBPS/Images/logo-MW.png)'
- en: '| List different types of tests for each Booking endpoint |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| 列出针对每个预订端点的不同测试类型 |'
- en: 'Sending this to Canopy returned the following response (again, edited in size
    for readability):'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 将此发送到Canopy返回了以下响应（同样，为了可读性进行了编辑）：
- en: '|'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![OpenAI徽标](../../OEBPS/Images/logo-openai.png)'
- en: '|    1.  **GET Booking Endpoint:**   •   Functional Tests:   −   Verify that
    the endpoint returns a list of all bookings.   −   Test the functionality of filtering
    bookings by providing a room ID as a query parameter.   2.  **POST Booking Endpoint:**  
    •   Functional Tests:   −   Ensure the endpoint accepts booking details in JSON
    format and creates a new booking successfully.   −   Test the response and status
    code when the booking request is invalid.   3.  **GET Booking ID Endpoint:**  
    •   Functional Tests:   −   Confirm the endpoint retrieves the correct details
    for a provided booking ID.   −   Test the response when an invalid or missing
    booking ID is provided.   4.  **PUT Booking ID Endpoint:**   •   Functional Tests:  
    −   Ensure the endpoint updates the booking information correctly for a given
    booking ID.   −   Test the response and status code when the booking ID is missing
    or invalid.   5.  **GET Booking Summary Endpoint:**   •   Functional Tests:  
    −   Verify that the server responds with a summary of bookings for a specified
    room ID.   −   Test the response when the room ID is missing or invalid.(Source:
    src/main/resources/data) |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| 1. **获取预订端点：**   •   功能测试：   −   验证端点返回所有预订的列表。   −   通过提供房间ID作为查询参数来测试按房间ID过滤预订的功能。  
    2. **POST预订端点：**   •   功能测试：   −   确保端点接受JSON格式的预订详情并成功创建新的预订。   −   测试当预订请求无效时的响应和状态码。  
    3. **获取预订ID端点：**   •   功能测试：   −   确认端点检索提供的预订ID的正确详情。   −   测试当提供无效或缺失的预订ID时的响应。  
    4. **PUT预订ID端点：**   •   功能测试：   −   确保端点正确更新给定预订ID的预订信息。   −   测试当预订ID缺失或无效时的响应和状态码。  
    5. **获取预订摘要端点：**   •   功能测试：   −   验证服务器对指定房间ID的预订摘要做出响应。   −   测试当房间ID缺失或无效时的响应。（来源：src/main/resources/data）
    |'
- en: 'Reviewing this response, we can see that the source at the bottom of the prompt
    is referencing the root folder of our data (Source: src/main/resources/data),
    indicating that multiple files have been pulled into our query. This is confirmed
    by how each endpoint has been mentioned in the response as well. We can correlate
    each entry in the response to a booking-based user story stored within our data
    set.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 通过审查这个响应，我们可以看到提示底部的来源正在引用我们的数据根目录（来源：src/main/resources/data），这表明已经将多个文件拉入我们的查询中。这一点也通过响应中提到的每个端点得到了证实。我们可以将响应中的每个条目与我们数据集中存储的基于预订的用户故事相关联。
- en: Activity 11.3
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 活动 11.3
- en: Using Canopy and Pinecone, prepare and upload your own custom set of data to
    an index. Try out different queries with your custom data to see how a RAG framework
    would perform in your context.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Canopy 和 Pinecone，准备并上传您自己的自定义数据集到一个索引。尝试使用您的自定义数据执行不同的查询，以查看 RAG 框架在您的上下文中如何表现。
- en: 11.3.4 Going forward with RAG frameworks
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.4 使用 RAG 框架向前推进
- en: By building our RAG framework before trying out existing platforms for RAG,
    we’ve now developed a deeper understanding of how RAG works and how it can be
    of benefit. However, what we’ve learned simply serves as an introduction to an
    area of LLM use that has lots of practical applications. What type of data we
    can store in RAG frameworks, whether we use vector databases or not, offers a
    lot of scope. Combined with what we’ve learned about writing effective prompts,
    RAG frameworks can be used to provide live analytics, production data, stored
    user content, and much more to help us create prompts that are more attuned to
    our context, which ultimately will help increase LLM use in our testing and elsewhere.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试现有的 RAG 平台之前，我们构建了自己的 RAG 框架，现在我们对 RAG 的工作原理及其如何带来益处有了更深入的理解。然而，我们所学的知识仅仅是对
    LLM 应用领域的一个介绍，这个领域有很多实际应用。我们可以在 RAG 框架中存储哪些类型的数据，是否使用向量数据库，这些都提供了很大的空间。结合我们关于编写有效提示的知识，RAG
    框架可以用来提供实时分析、生产数据、存储的用户内容等等，帮助我们创建更符合我们上下文的提示，这最终将有助于增加我们在测试和其他地方对 LLM 的使用。
- en: Summary
  id: totrans-228
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Retrieval-augmented generation (RAG) is an approach that combines contextual
    data and user queries in a prompt to an LLM.
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检索增强生成（RAG）是一种将上下文数据和用户查询结合到 LLM 提示中的方法。
- en: The selection of contextual data is based on its relevancy to the initial user
    query that has been provided.
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 上下文数据的选取基于其与已提供的初始用户查询的相关性。
- en: Providing selected data improves accuracy and ensures that errors around context
    windows are avoided.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供选定的数据可以提高准确性，并确保避免上下文窗口周围的错误。
- en: Having contextual data separate from an LLM makes the process of selecting and
    updating data sources easier.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将上下文数据与 LLM 分离，使得选择和更新数据源的过程更加容易。
- en: For RAG systems to work, we need the ability to upload and store data.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了使 RAG 系统能够工作，我们需要上传和存储数据的能力。
- en: RAG systems use similarity algorithms and tools to determine which data is most
    relevant to a query.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAG 系统使用相似性算法和工具来确定哪些数据与查询最相关。
- en: Building prompts that lack contextual data results in responses that are more
    generic and shallow.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏上下文数据的提示会导致更通用和肤浅的响应。
- en: An LLM can return incorrect responses if the similarity algorithm returns inaccurate
    data.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果相似性算法返回不准确的数据，LLM 可能会返回错误的响应。
- en: Finding relevant data becomes complex when queries are broad or multiple data
    sources need to be added to a prompt at once.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当查询范围较广或需要一次性将多个数据源添加到提示中时，查找相关数据会变得复杂。
- en: Vector databases store vectors based on multiple dimensions, which are used
    to determine relevancy to a query.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量数据库根据多个维度存储向量，这些维度用于确定查询的相关性。
- en: Some frameworks and tools offer the ability to quickly set up a RAG framework
    using vector databases.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些框架和工具提供了使用向量数据库快速设置 RAG 框架的能力。
- en: Utilizing vector databases and related tools and platforms makes it easier for
    us to query them.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用向量数据库和相关工具和平台，使我们查询它们变得更加容易。
- en: Vector databases allow us to pull multiple relevant files into a query at once.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量数据库允许我们一次性将多个相关文件拉入查询中。
- en: RAG frameworks can provide a wide range of types of data that has multiple applications
    for testing and software development as a whole.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAG 框架可以提供多种类型的数据，这些数据在测试和软件开发的整体过程中具有多种应用。
