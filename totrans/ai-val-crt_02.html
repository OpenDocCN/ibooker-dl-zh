<html><head></head><body><section data-pdf-bookmark="Chapter 2. Oh, to Be an AI Value Creator" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch02_oh_to_be_an_ai_value_creator_1740182046162988">&#13;
<h1><span class="label">Chapter 2. </span>Oh, to Be an AI Value Creator</h1>&#13;
&#13;
<p>In the previous chapter, we gave a set of imperatives that can instantly improve the odds of success for any AI journey. This all comes from our countless collective experiences, which range from thousands of customer engagements to TV shows such as <em>60 Minutes</em>, to the US White House, NATO, senior management, and even the <span class="keep-together">Vatican!</span> (The Vatican houses priceless artifacts in nitrogen vaults, and we—well, the broader IBM team—helped open those artifacts up to scholars to safely scale knowledge and history. While we can’t share with you the details of that deal, we’re confident in the afterlife.)</p>&#13;
&#13;
<p>You also learned about the Netscape moment of today and how it’s a tsunami of change that will wash across your personal and professional shores. You now understand that just as electricity was once deemed magical even though it wasn’t, AI is not magic either. We nudged (OK, two-hand shoved) you into a +AI to AI+ mindset and gave you a rebooted for this moment AI Ladder to climb for AI success. Finally, we gave you some operational frameworks to classify AI budgets, pick use cases, and envision outcomes that either shift left or shift right your business.</p>&#13;
&#13;
<p>We think <a data-type="xref" href="ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974">Chapter 1</a> and this chapter are important because they are both about defining the right details to pay attention to on your AI journeys. Why? Details will matter, details will differentiate, and details will earn (or keep) trust. We’ll use the history of the Statue of Liberty<a contenteditable="false" data-primary="Statue of Liberty" data-type="indexterm" id="id387"/> as an analogy of what you’re doing in the first part of this book. She stands tall and green in the iconic New York harbor. Her patina (the green chemical reaction to copper that occurs over the course of time) helps her stand strong against the elements—but it really must have been something for immigrants to see her copper glow on the horizon as they sailed into New York’s port, way back when. If you get a chance, take a moment to look at her hair. If you search for an up-close photo, you will see intricate braiding and precisely styled curls on the back of her head. It is perfect hair on top of a perfect statue. Interestingly enough, the Statue of Liberty was built 10 years before the first airplane. Her sculptor, Frédéric Auguste Bartholdi, had no reason to believe anyone would ever see her hair—yet the details mattered because sculpture was his craft, and his reputation depended on those details. What does this have to do with AI? The decisions you make over the next few years—and how you make them—may never be seen in isolation or explicitly, but the details of them will matter because they will stand for who you are and who your team, company, and you want to be. Remember that.</p>&#13;
&#13;
<p>In this chapter, we want to introduce you to perhaps the most important AI destination you should have in your own personal navigation systems: <em>the AI Value Creator</em>. Remember, this part of the book is on the business side, so while we’ll give you some more insights into large language models (LLMs) with a technology point of view later on, we’ve got some more AI business-related stuff we want to ensure you think about so that you’ll have a bigger set of skills to draw from than those who don’t read this book.</p>&#13;
&#13;
<section data-pdf-bookmark="AI Through the Years: The AI “Time Lapse” Section" data-type="sect1"><div class="sect1" id="ch02_ai_through_the_years_the_ai_time_lapse_section_1740182046163171">&#13;
<h1>AI Through the Years: The AI “Time Lapse” Section</h1>&#13;
&#13;
<p>The term <em>AI</em> was first coined in 1956, and various generations<a contenteditable="false" data-primary="AI (artificial intelligence)" data-secondary="historical perspective" data-type="indexterm" id="xi_AIartificialintelligencehistoricalperspective2982"/> of this technology (though none like this GenAI and agentic moment) have progressed and disappointed ever since. Some would say that AI has disappointed more than it’s delighted, which has caused “AI winters” from which AI has reemerged after some breakthroughs. If you look at the history of invention (take electricity, for example), it should come as no surprise that the path to AI breakthroughs has run through mass experimentation. While many AI experiments have failed, successful ones have had a substantial impact, and those successes have come from solving the problems that caused failures.</p>&#13;
&#13;
<p>People have long been speculating about the possibility that machines would someday be able to think like a human, on their own. This has been going on since the late 1800s, but the idea really took root with Alan<a contenteditable="false" data-primary="Turing, Alan" data-type="indexterm" id="id388"/> Turing’s 1950 seminal paper, “Computing Machinery and Intelligence.”<sup><a data-type="noteref" href="ch02.html#id389" id="id389-marker">1</a></sup> Historians call Turing the father of AI because of this very paper. In it, he theorized that society could create computers that would play chess, described how those computers would surpass human players, and said we would make them proficient in natural language. He theorized that machines would eventually think.</p>&#13;
&#13;
<p class="pagebreak-before">Over the course of our careers at IBM, we’ve seen (and been a part of achieving) many of the milestones that Turing identified on the way to a “thinking” machine. These have included evolutions and variants of AI playing games like chess (with Deep Blue), <em>Jeopardy!</em>, and the board game Go, as well as debating systems. But Turing was just the <span class="keep-together">beginning</span>.</p>&#13;
&#13;
<p>If Turing’s paper was the spark, then the big bang came just six years later at Dartmouth College in its Summer Research Project on Artificial Intelligence workshop. There, a couple of young academics got together with a couple of senior scientists from Bell Labs and IBM and proposed an extended summer workshop with just a small handful of the top people in adjacent fields to intensively consider artificial intelligence. That’s where the term <em>AI</em> was first used, and it marks the point at which AI was established as a field of research.</p>&#13;
&#13;
<p>In extensive detail, this team laid out many of the challenges that researchers have been working on ever since to develop machines that could think. Neural networks, self-directed learning, creativity, and more are all still relevant today.</p>&#13;
&#13;
<p>For perspective, this was 1956, the same year the invention of the transistor won the Nobel Prize. Today, we can put over 100 billion transistors in a graphics processing unit (GPU) and provision legions of interconnected GPUs to provide the computing power needed for GenAI. Throughout the years, AI theories, techniques, and ideas have been developed in parallel with progress in hardware that have come together to dramatically reduce computing and storage costs. All of this is converging now to make AI very real and practical.</p>&#13;
&#13;
<p>But we want to make this critical point: it’s not just about powerful hardware and clever algorithms. <em>Maybe the most important ingredient of generative AI</em>—particularly when it comes to your business getting the most value from it—is <em>your </em>data. <em>You can’t talk about generative AI without talking about data</em>. This makes hardware, algorithms, and data the three legs of the AI<a contenteditable="false" data-primary="AI (artificial intelligence)" data-secondary="hardware, algorithms, and data legs of AI stool" data-type="indexterm" id="id390"/> stool.</p>&#13;
<!--former pull quote removed from book
        <blockquote class="pull">
          <p>AI stool legs = model architecture + compute + data</p>
        </blockquote>
        -->&#13;
&#13;
<section data-pdf-bookmark="A Quick Bit on Foundation Models" data-type="sect2"><div class="sect2" id="ch02_a_quick_bit_on_foundation_models_1740182046163250">&#13;
<h2>A Quick Bit on Foundation Models</h2>&#13;
&#13;
<p>In the GenAI world, you’ll often hear about how LLMs are powering GenAI<a contenteditable="false" data-primary="foundation models (FMs)" data-type="indexterm" id="xi_foundationmodelsFMs22185"/>. But what are they? At a basic level, LLMs are new ways of representing language in a high-dimensional space with a large number of parameters—representations created by training on massive quantities of text.</p>&#13;
&#13;
<aside class="pagebreak-before less_space" data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="ch02_jargon_break_1740182046163310">&#13;
<h1>Jargon Break</h1>&#13;
&#13;
<p>We interrupt this book to put some jargon in easy speak that will serve you well for the rest of this book and at the water cooler (virtual or physical). Here are the common terms you’ll hear in GenAI parlance:</p>&#13;
&#13;
<dl>&#13;
	<dt>LLMs</dt>&#13;
	<dd>&#13;
	<p>This is likely the most ubiquitous type of GenAI model<a contenteditable="false" data-primary="large language models (LLMs)" data-type="indexterm" id="id391"/>. For the most part, when we are talking GenAI in this book, you should assume we mean LLMs (unless we say otherwise). When you hear about OpenAI ChatGPT, Google Gemini, Meta Llama, IBM Granite, DeepSeek, and Mistral AI, be aware that they are all LLMs.</p>&#13;
	</dd>&#13;
	<dd>&#13;
	<p>There are other kinds of GenAI models, such as diffusion<em> </em>models. These models<a contenteditable="false" data-primary="diffusion models" data-type="indexterm" id="id392"/><a contenteditable="false" data-primary="models" data-secondary="diffusion" data-type="indexterm" id="id393"/> can generate high-quality data. (Think of generating an image from a prompt using Stable Diffusion or Midjourney AI.) Diffusion models<a contenteditable="false" data-primary="noise, diffusion models" data-type="indexterm" id="id394"/> add <em>noise</em> to an input dataset.<sup><a data-type="noteref" href="ch02.html#id395" id="id395-marker">2</a></sup> For example, the input dataset could be a cat (for some reason, the world of AI is hyper-focused on cats). More noise gets iteratively added again and again in multiple rounds of training, which in AI-speak<a contenteditable="false" data-primary="epochs, machine learning" data-type="indexterm" id="id396"/> are called <em>epochs</em>. AI models get trained using multiple epochs to build an algorithm, and this process runs until you can’t really see anything. (Think of an old TV that has so much static interference that you can no longer see the program you were watching.) This AI then learns how to reverse engineer that noise back to the original input (in this case, a cat).</p>&#13;
	</dd>&#13;
	<dt>Parameters</dt>&#13;
	<dd>&#13;
	<p>You’ll often hear about an LLM<a contenteditable="false" data-primary="parameters" data-type="indexterm" id="id397"/> along with its size—for example, Llama-3-70B. The <em>70B</em> here means 70 billion, which is the number of parameters in the model. In this context (at a high level), you can think of the number of parameters as representing the overall capacity of the LLM. (Throughout this book, you’ll frequently see us refer to <em>model parameters</em> and <em>model weights</em>. In most cases, these terms are interchangeable. They both describe the collection of numerical <span class="keep-together">values—the</span> “bag of numbers”—that constitute the LLM, encoding the learned relationships from the training data.) The more parameters a model has, the more tasks it can generally perform—but bigger is not always better or more capable, and as you will find out in <a data-type="xref" href="ch07.html#ch07_where_this_technology_is_headed_one_model_will_not_1740182051667482">Chapter 7</a>; there are some pretty big things going on that have the world thinking about the size of the models they’re going to be using for business. Think of it this way: if your business is using an LLM to write past due notices to overdue accounts, does it need to know how to write with the personality of Joey Tribbiani from the TV show <em>Friends</em>? We can see it now: “How <em>you</em> doin’?” followed by the amount owed. What about Michael Scott from <em>The Office</em>?</p>&#13;
	</dd>&#13;
	<dt>High-dimensional space</dt>&#13;
	<dd>&#13;
	<p>This can be tricky, but we’ll keep it simple<a contenteditable="false" data-primary="high-dimensional space" data-type="indexterm" id="id398"/>. Think of a song and describe it in three dimensions (3D). Easy right? Perhaps you cue up “Shake It Off” by Taylor Swift. (Let’s be honest. It doesn’t matter whether you love her or not—you still know all the words, so don’t even....) We’d describe this song as {pop, empowering, resilient}, and of course, as you learned in <a data-type="xref" href="ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974">Chapter 1</a>, these are all numbers to an AI.</p>&#13;
	</dd>&#13;
	<dd>&#13;
	<p>Now, think of describing this song in 10 dimensions (10D). We came up with {pop, catchy, empowering, defiant, fun, anthemic, resilient, joyful, vibrant, playful}. But now, try to visualize these 10 dimensions on a graph, and you’ll end up with blank space, baby. (We hope you can appreciate the irony.) If you don’t have a headache yet, try to describe this song using one hundred dimensions and then try one thousand dimensions. Quite simply, when algorithm wranglers refer to data in a high-dimensional space, they are referring to when you have so many dimensions that it’s hard to visualize.</p>&#13;
	</dd>&#13;
	<dd>&#13;
	<p>It’s impossible for humans to think in a high-dimensional space, but AI can think in a very high number of dimensions. For example, a song on Spotify is encoded (meaning, represented in numbers) with hundreds, if not thousands, of dimensions that numerically represent a song. Data in the high-dimensional space gives many opportunities for AI to perform its magic. Consider a recommendation engine from Spotify. A user’s playlist is like a sentence that has thousands of dimensions that represent that user’s listening preferences. Perhaps this user’s playlist has strong representations of opera, classical music, and pop. Spotify might make a recommendation like Queen’s “Bohemian Rhapsody” (a fine choice, if we do say so ourselves) because of the operatic dimensions of that song. This could lead to further opera-like preferences, and suddenly, you’re listening to System of a Down’s “B.Y.O.B.” Why? Somewhere in the thousands of dimensions that represent these songs are likely dimensions that speak to how opera-like a song is, the number of classical undertones, or how a song tells a story. (“Bohemian Rhapsody” is actually about a young man who killed someone and sold his soul to the devil). This is all possible because while to us, a song may have single-digit dimensions, to Spotify’s AI, it’s like thousands of them. And while you can’t keep thousands of dimensions in your head, AI can—and that lets you enjoy a curated playlist while walking, say, in London’s Camden Market in the afternoon (oh the irony).</p>&#13;
	</dd>&#13;
</dl>&#13;
</div></aside>&#13;
&#13;
<p>From this perspective, much of the history of computing has been about coming up with new ways to represent data and extract value from it. For a long time, we’ve put data in tables<a contenteditable="false" data-primary="data" data-secondary="evolution of organizing" data-type="indexterm" id="id399"/><a contenteditable="false" data-primary="databases versus graphs as data representation" data-type="indexterm" id="id400"/><a contenteditable="false" data-primary="graphs versus databases as data representation" data-type="indexterm" id="id401"/>. For example, we put employees or customers in the rows of a database and put their attributes in the columns. This is great for things like online transaction processing (OLTP) or writing checks for payments to individuals.</p>&#13;
&#13;
<p>Then, the world started representing data with graphs, and this helped us discover and appreciate relationships between data points like never before; for example, this person, business, or place was connected to these other people, businesses, or places. Data represented this way starts to reveal patterns. For example, companies use graphs to map a social network or spot anomalous purchases to help them detect credit card fraud. This technology is a combination of many data analysis approaches using various types of data repositories (a graph database is included here), and this is also how the People You May Know (PYMK) feature works on Facebook (as just one example).</p>&#13;
&#13;
<p>Today, with LLMs, we’re taking lots of data that’s represented in neural networks that simulate (very loosely) an abstract version of brain cells. There are layers and layers of connections with millions, tens of billions, hundreds of billions, or even trillions of parameters—and suddenly, you can do some fascinating things. You can discover patterns so detailed that you can predict relationships with a lot more confidence. For example, you can predict that this word is most likely connected to this next word, and these two words are most likely followed by a specific third word—meaning you can build up, reassess, and predict again and again until something new is created or <em>generated</em>. Hence<a contenteditable="false" data-primary="generative AI (GenAI)" data-seealso="agentic systems; assistants" data-type="indexterm" id="id402"/>, the term <em>generative AI</em>.</p>&#13;
&#13;
<p>That’s what GenAI is: the ability to look at data, discover relationships, and predict the likelihood of sequences with enough confidence to create or generate something that didn’t exist before. Text, images, videos, sounds, and really all types of data can be represented in a model.</p>&#13;
&#13;
<p>We could do a limited version of all of this before with deep learning<a contenteditable="false" data-primary="deep learning" data-type="indexterm" id="id403"/>, which was an AI milestone in its own right. With <em>deep learning</em>, we started representing a massive amount of data using very large neural networks with many layers, but training had to happen with annotated data that humans had to manually label; for example, looking at a picture and noting it as a “cat” and another picture as a “dog.” This is<a contenteditable="false" data-primary="supervised learning" data-type="indexterm" id="id404"/> called <em>supervised learning</em>. So, what was the problem? As you can see in <a data-type="xref" href="#ch02_figure_1_1740182046144175">Figure 2-1</a>, supervised learning is expensive, laborious, and time consuming, so only large institutions did that work and only for specific tasks. If you wanted AI to summarize and translate text, you needed to label two very large datasets...manually (more on this in a moment).</p>&#13;
&#13;
<p>Around 2017, a new approach appeared that was powered by an architecture<a contenteditable="false" data-primary="transformers" data-type="indexterm" id="id405"/> called <em>transformers </em>(we lightly detail these in <a data-type="xref" href="ch09.html#ch09_generative_computing_a_new_style_of_computing_1740182052619664">Chapter 9</a>). With this approach, AI could perform a new kind of frictionless learning<a contenteditable="false" data-primary="self-supervised learning" data-type="indexterm" id="id406"/> called <em>self-supervised learning</em>, in which a language model could be trained on large amounts of unlabeled data by hiding certain sections of the text (words, sentences, etc.) and asking the model to fill in the blanks (the AI lingo<a contenteditable="false" data-primary="masked words" data-type="indexterm" id="id407"/> for this is <em>masking</em>). For example, if we said, “May the force,” you’d likely guess that the next three words are “be with you” from <em>Star Wars</em>. Although an <span class="keep-together">oversimplification</span>, this amazing process, when done at scale, results in the powerful data representations that today we call LLMs.</p>&#13;
&#13;
<figure><div class="figure" id="ch02_figure_1_1740182046144175"><img alt="A screen shot of a computer  Description automatically generated" src="assets/aivc_0201.png"/>&#13;
<h6><span class="label">Figure 2-1. </span>Comparing the activation energy of getting started with supervised learning versus self-supervised learning</h6>&#13;
</div></figure>&#13;
&#13;
<p>This is where something truly magical happened. Researchers found that instead of building AI models that were only suited to narrow use cases and areas of expertise (for example, building and painstakingly curating one dataset for summarization and another for translation), they could have AI that was more broadly applicable. Basically, these LLMs could be trained on huge volumes of internet data (today’s most popular LLMs are really just highly compressed representations of everything on the internet—which is good and bad) and thus acquire a humanlike <em>set</em> of natural language capabilities.</p>&#13;
&#13;
<p>Self-supervision<a contenteditable="false" data-primary="self-supervision" data-type="indexterm" id="xi_selfsupervision26030"/> at scale, combined with massive data and compute, gave the world AI that is generalizable and adaptable. We define these terms as follows:</p>&#13;
&#13;
<dl>&#13;
	<dt>Generalizable</dt>&#13;
	<dd>&#13;
	<p>This means the AI<a contenteditable="false" data-primary="generalizability, GenAI" data-type="indexterm" id="id408"/> has the ability to perform well across a wide range of tasks and domains, often with little to no task-specific tuning. In other words, the same LLM that classifies the sentiment of a text document can extract people and places from text—an action referred to as named-entity recognition (NER)<a contenteditable="false" data-primary="named-entity recognition (NER)" data-type="indexterm" id="id409"/>—and can translate, summarize, and more.</p>&#13;
	</dd>&#13;
	<dt>Adaptable</dt>&#13;
	<dd>&#13;
	<p>This means that the AI can not only do multiple tasks<a contenteditable="false" data-primary="adaptability" data-secondary="GenAI" data-type="indexterm" id="id410"/> but can also handle different use cases it wasn’t originally trained for. AI that is adaptable<a contenteditable="false" data-primary="emergent AI" data-type="indexterm" id="id411"/> is also <em>emergent</em>, meaning it has capabilities that it was not explicitly programmed to have and that arise unexpectedly; for example, an LLM can answer riddles or solve logic puzzles it has never been trained on simply by recognizing patterns. The bottom line is that being able to use the same model for multiple use cases and discovering new capabilities in them is a powerful tool (though you are still going to want to steer it to become an AI Value Creator; more on that in a bit).</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<p>Over the last decade, there’s been an explosion of applications for AI. (Our bet is that you’ve used many of them, even without knowing it. Have you used Siri or Alexa? Have you changed a gray sky to a sunny sky to create a picture-perfect moment? Have you used a translation app?) In that time, we’ve seen AI go from being a purely academic endeavor to being a major force that powers actions across a myriad of industries and affects the lives of billions each day.</p>&#13;
&#13;
<p>In recent years, we’ve managed to build AI systems that can learn from thousands or millions of examples to help us better understand our world and find new solutions to difficult problems. These large-scale models have led to the development of systems that can understand us when we talk or write. These include the natural language processing (NLP)<a contenteditable="false" data-primary="natural language processing (NLP)" data-type="indexterm" id="id412"/><a contenteditable="false" data-primary="NLP (natural language processing)" data-type="indexterm" id="id413"/> and natural language understanding (NLU)<a contenteditable="false" data-primary="natural language understanding (NLU)" data-type="indexterm" id="id414"/><a contenteditable="false" data-primary="NLU (natural language understanding)" data-type="indexterm" id="id415"/> programs we use every day, from digital assistants to speech-to-text programs. Other systems, which are trained on things like the entire bodies of work of famous artists or every chemistry textbook in existence, have allowed us to build generative models that can create new works of art based on those artists’ styles or new compound formulation and docking combinations based on the history of chemical research.</p>&#13;
&#13;
<p>While today many new AI systems are helping to solve all sorts of real-world problems, before GenAI, creating and deploying an AI for each new system using traditional methods required a considerable amount of time and resources. For each new application, you had to ensure that there was a large, well-labeled dataset for the specific task you wanted to tackle. If a dataset didn’t exist for that task, you had people taking hundreds or thousands of hours (perhaps more) to find and label appropriate images, text, or graphs for the training and validation datasets.</p>&#13;
&#13;
<p>What does all this mean? You can take a large, pretrained LLM—if you’re using it for business, you’ll want to ensure you’re starting with a model that is trustworthy—and add <em>your</em> institutional knowledge to turbocharge the model to <em>excel at your specific use cases</em> with your specific data. (We get into the ills, wills, and thrills of this topic in <a data-type="xref" href="ch08.html#ch08_using_your_data_as_a_differentiator_1740182052172518">Chapter 8</a>.)</p>&#13;
&#13;
<p>Now, if you’re feeling a bit disheartened because you’re one of those businesses<a contenteditable="false" data-primary="business considerations" data-secondary="steering LLM to tailor data to business needs" data-type="indexterm" id="id416"/> we talked about that spent enormous amounts of time collecting and labeling data for your AI projects, only to have them fail because you didn’t label enough data (that is how it went with traditional AI), fear not! That work is not throwaway in this GenAI world because that proprietary industry-specific data we just mentioned is what you’re going to use to tailor an LLM for your business needs. It’s what you need to do in order to become an AI Value Creator. In fact, you’re literally going to take those failed AI projects from two years ago and look like a hero when you bring forth to your bosses how you want to steer whatever LLM you land on for your business. How so? First, today’s LLMs don’t contain much enterprise data at all (about 1%), let alone your proprietary data. In <a data-type="xref" href="ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974">Chapter 1</a>, we told you how your data is a competitive advantage, and now it’s time to put that data to work.</p>&#13;
&#13;
<p>Quite simply, when you bring together the data representations<a contenteditable="false" data-primary="data representations" data-seealso="foundation models" data-type="indexterm" id="id417"/> of an LLM and steer it with your labeled data (which now, you need much less of), you end up with something that is tailored to your business. Think of it this way: let’s assume you know Spanish, and today, you’re trying to learn French. On this journey, there is a lot of <em>foundational</em> knowledge you already have about how language works, like how to conjugate verbs. Just as it’s likely easier to learn French if you have Spanish as a foundation, as you’ll find out in <a data-type="xref" href="ch08.html#ch08_using_your_data_as_a_differentiator_1740182052172518">Chapter 8</a>, there’s a new open source approach (called InstructLab) that makes it easier than ever to fold your data into your company’s private LLM and not share it with the world, and that’s bound to give some ooh la la to your final results.</p>&#13;
&#13;
<p>The current thinking is usually that you can apply LLMs (hence, their name) to language. But this should spark the question, what is a language? Signals in a piece of industrial equipment are talking to you, in their own language; there are programming languages, which consist of communication verbiage from humans to instruct machines; and there are the clicks of a user navigating a website, software code, chemistry, and diagrammatic representations of chemicals. We’ve even worked with a company using AI to model taste and smell. If you squint, <em>everything starts looking like a language</em>, and if it’s a language, it can be learned, deciphered, and understood.</p>&#13;
&#13;
<p>The takeaway is that AI can be specialized to do all kinds of things that boost productivity in any language. That means that AI can stretch horizontally across your business to HR processes, customer service, self-service, cybersecurity, code writing, application modernization, and so many other things that we’ll share with you in <a data-type="xref" href="ch04.html#ch04_the_use_case_chapter_1740182047877425">Chapter 4</a><a contenteditable="false" data-primary="" data-startref="xi_foundationmodelsFMs22185" data-type="indexterm" id="id418"/><a contenteditable="false" data-primary="" data-startref="xi_selfsupervision26030" data-type="indexterm" id="id419"/>.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Going a Little Deeper: The Evolution of Large Language Models and Comparing Supervised Learning with Self-Supervised Learning" data-type="sect2"><div class="sect2" id="ch02_going_a_little_deeper_the_evolution_of_foundation_1740182046163370">&#13;
<h2>Going a Little Deeper: The Evolution of Large Language Models and Comparing Supervised Learning with Self-Supervised Learning</h2>&#13;
&#13;
<p>Large language models aren’t built the same way as traditional AI<a contenteditable="false" data-primary="large language models (LLMs)" data-secondary="evolution of" data-type="indexterm" id="xi_largelanguagemodelsLLMsevolutionof28286"/>. They are trained using self-supervised learning<a contenteditable="false" data-primary="self-supervised learning" data-type="indexterm" id="xi_selfsupervisedlearning282135"/>, which means you don’t have to manually annotate a massive amount of data. Basically, you train a model by telling it to go read enormous amounts of data (for example, text) and when it’s done you end up with a large but versatile model with more humanlike language capabilities. AI uses mathematical models to represent the relationships in the data (like words) it ingests. If you give the model a few words in a prompt, it can mathematically predict the likelihood of words coming up in the sequence of the <em>Star Wars</em> phrase we shared in the last section.</p>&#13;
&#13;
<p>Two of the biggest things that excite us about GenAI<a contenteditable="false" data-primary="generative AI (GenAI)" data-secondary="versus traditional AI" data-secondary-sortas="traditional AI" data-type="indexterm" id="xi_generativeAIGenAIversustraditionalAI28366"/> are just how fast you can now build these same use cases for all the reasons summarized in <a data-type="xref" href="#ch02_figure_1_1740182046144175">Figure 2-1</a> and the fact that these models (as we noted in the previous section) are generalizable and adaptable. The best way to appreciate how GenAI flattens the time-to-value curve for AI projects is to go beyond labeling data and contrast GenAI with the traditional way in which AI use cases were brought into production.</p>&#13;
&#13;
<p>Many of you who have been around AI for a while may feel that you’re seeing many use cases from the traditional AI era repeat themselves in this new GenAI era—and you’re right. That said, we’d be remiss if we didn’t note that while the initial set of GenAI use cases might be repeating themselves, there are new ones, and agentic AI brings plenty more. In the last decade, with the advent of deep learning, the world demonstrated (as a community) that you could bring incredible accuracy to specific tasks if you gathered enough data, labeled that data, trained models, and deployed them. This traditional methodology is what you see in <a data-type="xref" href="#ch02_figure_2_1740182046144214">Figure 2-2</a>.</p>&#13;
&#13;
<p>Notice in <a data-type="xref" href="#ch02_figure_2_1740182046144214">Figure 2-2</a> how each model is built for a specific AI use case. In this example, the use cases are summarization, tone analysis, and entity extraction. To build these models with the traditional approach to AI, your company would have created a separate team for each task, and each team would have built a separate model to anchor the task. All those teams would have gone through the same painstaking process of data selection and curation, labeling, model development, training, validation, and so on—perhaps even duplicating the same data!</p>&#13;
&#13;
<figure><div class="figure" id="ch02_figure_2_1740182046144214"><img alt="A diagram of a diagram  Description automatically generated" src="assets/aivc_0202.png"/>&#13;
<h6><span class="label">Figure 2-2. </span>The traditional way to build AI, by assembling many data science teams and getting them to do as many projects as they can</h6>&#13;
</div></figure>&#13;
&#13;
<p>Different teams collecting data, curating it for their own use case, and going through the same steps other teams go through can only be described as long, hard, tedious, and expensive. In fact, we’d humbly suggest that how much your company could scale AI was really the answer to the questions: how many data science teams could you assemble, and how many projects could those teams carry out?</p>&#13;
&#13;
<p>Now contrast the new approach to AI<a contenteditable="false" data-primary="large language models (LLMs)" data-secondary="versus traditional AI model" data-secondary-sortas="traditional AI model" data-type="indexterm" id="xi_largelanguagemodelsLLMsversustraditionalAImodel29149"/> (on the left side of <a data-type="xref" href="#ch02_figure_3_1740182046144239">Figure 2-3</a>) with the traditional path to AI (on the right side of the figure). As you can see, instead of needing to build one AI model for each specific task (as in <a data-type="xref" href="#ch02_figure_2_1740182046144214">Figure 2-2</a>), you take an LLM that is likely trained by someone else (like IBM, Google, DeepSeek, OpenAI, or Anthropic; truth be told, few companies will build their own—rather, they will steer existing ones) and adapt it to many varied downstream tasks. Also, notice how a single LLM fuels the three use cases in <a data-type="xref" href="#ch02_figure_3_1740182046144239">Figure 2-3</a>.</p>&#13;
&#13;
<figure><div class="figure" id="ch02_figure_3_1740182046144239"><img alt="A diagram of a model  Description automatically generated" src="assets/aivc_0203.png"/>&#13;
<h6><span class="label">Figure 2-3. </span>GenAI scales AI, reducing skill requirements, data, time, administration, and up-front costs</h6>&#13;
</div></figure>&#13;
&#13;
<p>Given the versatility of an LLM, companies can now use the same model to implement multiple business use cases. They could never really do that using traditional AI.</p>&#13;
&#13;
<p>We really want you to spend some time committing <a data-type="xref" href="#ch02_figure_3_1740182046144239">Figure 2-3</a> to memory because it illustrates why LLMs are becoming essential ingredients of the new AI workflow. Modern AI takes a very focused effort<a contenteditable="false" data-primary="base model, LLM-based AI" data-type="indexterm" id="id420"/> to create a <em>base model</em> (meaning a general-purpose LLM) and getting economies of scale from that investment. Creating an LLM on your own is quite a sophisticated endeavor, which is why we’re confident that most of you will choose one to start with and then steer it with your data to match your business and use case (which we tell you how to do later in this book).</p>&#13;
&#13;
<p>We’re hoping you’ve gotten a good grasp of this methodology shift, because the next wave of AI looks to replace the task-specific models that have dominated the AI landscape to date with LLMs as their core. These models are trained on a broad set of data that can be used for different tasks, and what’s more, with their self-ideation to achieve defined goals, agentic AI will follow this path too.</p>&#13;
&#13;
<p>That’s the takeaway. What makes LLMs so versatile is that they, as their name suggests, can be the foundation of many AI and agentic applications. Using self-supervised learning and transfer learning<a contenteditable="false" data-primary="transfer learning" data-type="indexterm" id="id421"/>, these AI models can apply information they have learned about in one situation to another situation<a contenteditable="false" data-primary="" data-startref="xi_selfsupervisedlearning282135" data-type="indexterm" id="id422"/>.</p>&#13;
&#13;
<p>The easiest way to understand transfer learning is with a traditional computer vision example of AI being used to identify a cat. (Again, AI and cats seem to go hand-in-paw—it’s like some feline aficionado felt their deep learning needed some deep purring.) If you taught an AI how to identify a cat, that AI would start with shapes and edges and gradually build layers in its neural network to identify a cat. At its base levels, this AI would likely be able to detect triangles (combinations of edges). If you think about a cat, triangles form its ears and nose and other parts, and once the AI could find triangles, it could go on to discover other cat features as it used more and more layers in its neural network to ultimately define the object it sees as a cat. Now, imagine you wanted to identify a sailboat. An AI trained to identify sailboats would start at the same place: finding edges and shapes. So, you could take the levels of the AI that know what triangles look like and transfer it for boats, you could do the same thing for potentially thousands of layers—and now you understand transfer learning. Whether the AI was identifying a cat or a sailboat, that identification of a triangle would be critical.</p>&#13;
&#13;
<p>Most of us can relate to the versatility of LLMs supporting multiple use cases in our everyday lives. For example, once you’ve learned how to drive a car, you’ve got some serious skills you can transfer to drive other cars. Sure, there are some nuances to get used to (like where to find the windshield wiper controls), and you could even run into major issues (try driving with a manual transmission if you’ve only ever driven an automatic), but there are still a bunch of base skills that transfer. Today, no one builds a convolutional neural network (CNN) or uses a vision transformer (ViT) for computer vision without some sort of transfer learning—it’s like the ultimate computer vision cheat code!</p>&#13;
&#13;
<p>The takeaway? It’s simple: instead of needing to build one AI model for each specific task, you can train one model and adapt it to many varied downstream tasks. This means that companies now have the opportunity to go from a modus operandi of <em>one task: one model</em> to <em>one model: many tasks</em>. For example, your IT support chatbot and your HR self-service initiatives can use the same base model as the new app that will write your marketing emails and summarize contract documents.</p>&#13;
&#13;
<p>As shown in <a data-type="xref" href="#ch02_figure_3_1740182046144239">Figure 2-3</a>, there is still work to do! While the data engineering and labeling chores are now minuscule, you’re still going to want to use your data to steer the model toward your business domain and its brand, style, social norms, and so on. There are many ways to do this, using techniques such as prompt tuning, prompt engineering, fine-tuning with parameter-efficient fine-tuning (PEFT) methods, and InstructLab. You’ll learn more about this in <a data-type="xref" href="ch08.html#ch08_using_your_data_as_a_differentiator_1740182052172518">Chapter 8</a>, but all the preparatory work you must do before you put your data to work has greatly decreased because of LLMs.</p>&#13;
&#13;
<p>Of course, the eye opener here shouldn’t be the power of a model with billions or even trillions of parameters. Hopefully, it’s jumping off the page at you, but if isn’t: the productivity associated with LLMs means that businesses can finally scale their AI initiatives with <em>less </em>time, <em>less </em>data, <em>less </em>up-front money, and <em>less </em>administration. For example, in IBM’s own experience, it took 7 years to support 12 languages using AI the traditional way—but once it adopted GenAI, the languages it supported jumped to 25 in just a year<a contenteditable="false" data-primary="" data-startref="xi_AIartificialintelligencehistoricalperspective2982" data-type="indexterm" id="id423"/><a contenteditable="false" data-primary="" data-startref="xi_largelanguagemodelsLLMsevolutionof28286" data-type="indexterm" id="id424"/><a contenteditable="false" data-primary="" data-startref="xi_generativeAIGenAIversustraditionalAI28366" data-type="indexterm" id="id425"/><a contenteditable="false" data-primary="" data-startref="xi_largelanguagemodelsLLMsversustraditionalAImodel29149" data-type="indexterm" id="id426"/>.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="AI Value Creation Should Be Your Destination" data-type="sect1"><div class="sect1" id="ch02_ai_value_creation_should_be_your_destination_1740182046163435">&#13;
<h1>AI Value Creation Should Be Your Destination</h1>&#13;
&#13;
<p>When oxygen, heat, and fuel combine<a contenteditable="false" data-primary="value creation versus value consumption" data-type="indexterm" id="xi_valuecreationversusvalueconsumption211047"/>, we get fire. It’s basic, it’s primal, and it’s the key that unlocked human progress. Think about it: fire provided light, heat, and protection, and our ancestors used it to move to new climates and eat new foods. Pottery, metallurgy, chemistry, rapid transportation, and many other technologies all started with fire.</p>&#13;
&#13;
<p>But imagine if fire had been proprietary? What if the knowledge of how to make fire hadn’t been shared, and what if there had been just a few keepers of the fire? Where would we be?</p>&#13;
&#13;
<p>Remember what we told you in the Preface: we’re in a lift, shift, rift, or cliff moment with GenAI, and especially with agents, it’s going to shape our society for generations to come. This section (and the rest of the book) is going to show you how to become your own AI fire starter, how to take control of your AI destiny, and why it’s so important to see yourself as an AI Value Creator and not just an AI User. Finally, we’ll detail why the future of AI needs an open innovation ecosystem.</p>&#13;
&#13;
<section data-pdf-bookmark="How Do You Consume AI: Be Ye a Value Creator or a Value User?" data-type="sect2"><div class="sect2" id="ch02_how_do_you_consume_ai_be_ye_a_value_creator_or_a_1740182046163502">&#13;
<h2>How Do You Consume AI: Be Ye a Value Creator or a Value User?</h2>&#13;
&#13;
<p>When it comes to using AI<a contenteditable="false" data-primary="AI Value Creator" data-secondary="versus AI user" data-secondary-sortas="AI user" data-type="indexterm" id="xi_AIValueCreatorversusAIuser211539"/>, there are three modes of consumption:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>It’s baked into the software.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>You use someone else’s model.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>You use an AI platform.</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<section data-pdf-bookmark="AI User: Shake (embed) and bake (into the product) the AI" data-type="sect3"><div class="sect3" id="ch02_ai_user_shake_embed_and_bake_into_the_product_1740182046163564">&#13;
<h3>AI User: Shake (embed) and bake (into the product) the AI</h3>&#13;
&#13;
<p>The first way to consume AI<a contenteditable="false" data-primary="shake and bake use of AI" data-type="indexterm" id="id427"/> is when it’s “baked into” off-the-shelf software<a contenteditable="false" data-primary="off-the-shelf software, consuming AI through" data-type="indexterm" id="id428"/>. In this approach, a software vendor creates the AI, and you put it to use. (We’re going to assume you’re only working with real AI in products and not “fake and bake” AI, since everyone claims to have AI in their products these days.) Whether it’s a writing assistant (like Grammarly or Jasper) that can help you strike the right tone in your email, or image editing software (like Adobe Photoshop or Topaz Photo AI) that can automatically enhance the quality of your images and videos, with this consumption pattern, you, as an AI User, get access to some great functionality that can make you more productive. Who doesn’t want that?</p>&#13;
&#13;
<p>But there’s a caveat! <em>You and everyone else get access to this same “magic,”</em> which means that while this form of AI might help you do your work faster and with better results (that’s a good thing), <em>it can (and will) do the same for anyone else</em> who invests time in getting skilled up in that software. In other words, these AI capabilities and productivity opportunities don’t become differentiators—<em>but</em> they do set a new, higher baseline for everyone, including your competition.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="AI User: Don’t fall when you make the service call (the even bigger but)" data-type="sect3"><div class="sect3" id="ch02_ai_user_don_t_fall_when_you_make_the_service_call_1740182046163627">&#13;
<h3>AI User: Don’t fall when you make the service call (the even bigger <em>but</em>)</h3>&#13;
&#13;
<p>The second model of AI consumption<a contenteditable="false" data-primary="service call use of AI" data-type="indexterm" id="xi_servicecalluseofAI213450"/> is when you prompt someone else’s model<a contenteditable="false" data-primary="prompting someone else’s model as AI user" data-type="indexterm" id="xi_promptingsomeoneelsesmodelasAIuser213490"/>, either directly in a chat interface or through an API call. Quite simply, as you develop custom AI apps for your business, these apps can call out to another company’s GenAI service, use that company’s models, and get results. This also is a viable way of consuming AI.</p>&#13;
&#13;
<p>The truth is, just about every single one of us has been using GenAI this way, and that makes us all a bunch of AI Users. But think about being an AI User for a moment: you are mostly limited to simply prompting someone else’s AI model (not your model), you have no control over the model or the data used to train it, and you, in almost every case, have absolutely no idea what data was used to build it.</p>&#13;
&#13;
<p>Depending on how cleverly you use the model, you can <em>start</em> to differentiate how you put AI to work relative to your competitors. <em>But</em> there are still more caveats that you need to consider—<em>especially</em> if you’re trying to be an AI Value Creator.</p>&#13;
&#13;
<p>The first consideration is that, like with our software example, those models and services you tap into are available to everyone, so are you really differentiated? Sure, perhaps you can prompt the same model better than someone else. <em>But</em> you’re still accessing the same model as everyone else.</p>&#13;
&#13;
<p>There’s something else <em>you need to be even more concerned about </em>when your app makes that call and it goes off to work some magic—it’s connecting to something opaque (meaning you can’t see inside it). You don’t necessarily know what’s happening on the other end, what the AI model is doing with your data (learning from it, storing it, or just looking at it), or the provenance and governance of the data used to build the LLM the service is built on. Depending on the use case, this should make you somewhat nervous because your business is still accountable for the final outcomes (either socially or, more and more, by law—which we get into in <a data-type="xref" href="ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635">Chapter 5</a>). And if you’re talking about AI for business—as opposed to just personal use—we think that should make you nervous.</p>&#13;
&#13;
<p>We want to give you something to think about as a second word of caution whenever you use someone else’s proprietary AI<a contenteditable="false" data-primary="proprietary data" data-secondary="disadvantages of using others’" data-type="indexterm" id="id429"/>: what of the creation and accrual of value over the long term? In the past, we’ve seen a lot of value-extractive business models—if you’re on social media, you’re a part of one. Quite simply, we always tell people if you’re not paying for it, make no mistake about it, you’re more than likely the product being sold. But even if you’re paying for the service, indeed, you’ll get value from that service (or you wouldn’t be paying for it). <em>But</em> that other company is likely extracting value from your usage and from your data, accumulating more and more over time. It’s not our intent to call any of these companies by name in this book, but there is a plethora of examples of companies (including paid services) that benefit from your strategic data. Ironically, this is the very method with which those LLMs were made (scraping data on the internet, be that data copyrighted or not).</p>&#13;
&#13;
<p>This brings up yet another question we want you to think about: if you’re an AI User making a call to someone else’s AI service, how much faster is their value growing than yours? (Hint: check out the stock price and valuation multiples of some of these companies we’re not naming.) Quite simply, there’s likely an imbalance in the relationship, and <em>that can have long term consequences</em> for your specific business, the overall economy, and the progress of technology.</p>&#13;
&#13;
<p>A final <em>but</em>: Do we, as a society, really want to have just a few keepers of the AI “fire” upon which we are all dependent? Is that what’s best for your individual business and for your shareholders? We think no<a contenteditable="false" data-primary="" data-startref="xi_servicecalluseofAI213450" data-type="indexterm" id="id430"/>.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Fire starter: Becoming an AI Value Creator" data-type="sect3"><div class="sect3" id="ch02_fire_starter_becoming_an_ai_value_creator_1740182046163687">&#13;
<h3>Fire starter: Becoming an AI Value Creator</h3>&#13;
&#13;
<p>The third model of AI consumption is the platform model<a contenteditable="false" data-primary="platform model of AI" data-type="indexterm" id="xi_platformmodelofAI214571"/>, which is the most comprehensive. This is how you become your own AI fire starter, and when it comes to becoming an AI Value Creator, we want to be clear about something up front: it<em> does not mean </em>you’re doing it alone or reinventing AI from scratch. You’re not taking years and spending millions to build your own LLMs. Of course, you can do that with a platform, but that will be in a very small minority of cases.</p>&#13;
&#13;
<p>With an AI value creation platform, you have all the elements and ingredients (data, governance, and LLMs) in place to build your own AI solutions. You have access to a vast number of GenAI models (both open source and proprietary), or you can bring your own models into the platform. You have tools to improve and customize models to fold in your proprietary knowledge of your business without concerns about sharing some of your most valuable assets (your data). You can fine-tune the models, prompt-tune them, tailor them with InstructLab—whatever techniques we detail in <a data-type="xref" href="ch08.html#ch08_using_your_data_as_a_differentiator_1740182052172518">Chapter 8</a> you want to use to build your own tailored AI solutions. At its core, the AI Value Creator approach allows you to create and accrue value that is unique to your business. A great example of an AI Value Creator is L’Oréal, one of the world’s leading beauty companies. Imagine the corpus of formulation, material science, and preference data L’Oréal has accumulated as it nears its 120th birthday. In essence, L’Oréal possesses data that defines the language of makeup. It wants to be an AI Value Creator, so it set out to create a private AI model (in collaboration with IBM) to accelerate tasks like the formulation of new products, reformulation of existing cosmetics, and optimizations to scale-up production. If L’Oréal was just an AI User, it would give this data away, but instead it views its data as a competitive advantage and decided to put it to work to better equip L’Oréal’s 4,000 researchers worldwide over the next several years. We think L’Oréal isn’t just applying AI to beauty—it’s giving it a makeover of its own. With data as rich as its foundations and as bold as its lipsticks, who knew AI could have such a great eye for color matching<a contenteditable="false" data-primary="" data-startref="xi_promptingsomeoneelsesmodelasAIuser213490" data-type="indexterm" id="id431"/>?</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="The path forward: How to create value with AI" data-type="sect3"><div class="sect3" id="ch02_the_path_forward_how_to_create_value_with_ai_1740182046163768">&#13;
<h3>The path forward: How to create value with AI</h3>&#13;
&#13;
<p>Ultimately, we believe that most businesses should end up with a mix of all three models of AI consumption. You’ll use third-party software with AI embedded, and <em>sometimes</em> it will be totally appropriate to use someone else’s AI User to do something you’re trying to do. For example, perhaps you are a real estate agent and want a quick description of a kitchen for a new listing based on photos you’ve been handed. Unless you have some kind of proprietary description magic, this is likely a situation in which you might want to use some of the more famous models you’ve heard about without concern. But what if you’re classifying sentiment on a purchase based on thousands of sentiments you’ve gotten from three decades of selling houses? To fully realize the value of AI and differentiate yourself from competitors, you’ll want to use a platform approach (just like L’Oréal) to create value by using your own AI tuned to your business, and you’ll want to add the other AI consumption patterns where appropriate. Let’s go a bit deeper into AI value creation, starting with LLMs.</p>&#13;
&#13;
<p>Recall that LLMs are large-scale, deep neural networks trained with lots of data and subsequently adapted to many downstream tasks. They might be broad, general <span class="keep-together">models</span> or narrower, deeper models, but the key is that they’re pretrained with the <em>expectation that you can further enhance them with your own proprietary data if you’re looking to become an AI Value Creator</em>. It’s just like when a new employee joins your business: they come in with some general skills as a foundation and the ability to learn. The more they learn about your business, the more they add institutional knowledge and expertise, and the more value they deliver (and likewise, the more hurtful it might be if they went to a competitor). The same is basically true of LLMs. You use your AI platform to tune them with your specific business data, proprietary knowledge, and expertise—and then they become more like experts about your business and more valuable to your business over time. You don’t want that sales employee you trained with insights into your accounts to start working for someone else, and AI Value Creators feel the same way about their data!</p>&#13;
&#13;
<p>And because AI Value Creators are in control of the platform, processes, and data, they accrue ever larger amounts of value over time. With some of the consumer AI on the market, we’ve already seen some of what happens when you surrender that control. You can get bad data that leads to bad outcomes, as well as confabulations or hallucinations. You could also get into some trouble for inadvertently using someone else’s rights-managed content (that’s what all the copyright lawsuits going on are about), and we’ve even seen proprietary or sensitive data being inadvertently leaked back into public spaces. These are just some of the reasons why, when it comes to AI for business, you need to know how your LLM was built, what data was used to train it, and the recipe used to put it all together. And this is also why you should prioritize exercising tight control over your sensitive data<a contenteditable="false" data-primary="governance" data-secondary="and AI Value Creator approach" data-secondary-sortas="AI Value Creator approach" data-type="indexterm" id="id432"/>. <em>Strong AI governance is absolutely critical</em>.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Look before you leap" data-type="sect3"><div class="sect3" id="ch02_look_before_you_leap_1740182046163823">&#13;
<h3>Look before you leap</h3>&#13;
&#13;
<p>Yes, now is the time to jump into AI, but look before you leap, and ensure that you’re investing in a smart, safe, and sustainable approach in which your business and customers are the primary beneficiaries. We think this approach starts with an AI Value Creator persona using a trusted platform and expands from there<a contenteditable="false" data-primary="" data-startref="xi_valuecreationversusvalueconsumption211047" data-type="indexterm" id="id433"/><a contenteditable="false" data-primary="" data-startref="xi_AIValueCreatorversusAIuser211539" data-type="indexterm" id="id434"/><a contenteditable="false" data-primary="" data-startref="xi_platformmodelofAI214571" data-type="indexterm" id="id435"/>.</p>&#13;
</div></section>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Planning Your AI Future: A Future with Many GenAI Models" data-type="sect1"><div class="sect1" id="ch02_planning_your_ai_future_a_future_with_many_genai_1740182046163895">&#13;
<h1>Planning Your AI Future: A Future with <span class="keep-together">Many GenAI Models</span></h1>&#13;
&#13;
<p>We think there is an AI myth<a contenteditable="false" data-primary="AI (artificial intelligence)" data-secondary="future of" data-type="indexterm" id="xi_AIartificialintelligencefutureof216240"/><a contenteditable="false" data-primary="multimodel AI" data-type="indexterm" id="xi_multimodelAI216240"/><a contenteditable="false" data-primary="multimodal AI" data-type="indexterm" id="xi_multimodalAI216240"/> out there right now, or at minimum, a basic misunderstanding. For the general public, GenAI has seemingly come out of nowhere. A lot of people think that there’s just a handful of consumer-oriented AI experiences out there and that one model is going to win (there will be “one model to rule them all,” in Tolkien-speak).</p>&#13;
&#13;
<p><em>We don’t think that’s going to happen</em>. The future of AI is not about one model. It’s about many models (you’ll sometimes hear this referred to as <em>multimodel</em>), and it’s multimodal (can work on images, text, video, sound, and so on) too. Your business will be using multiple fine-tuned models to achieve the best results when you apply them to specific use cases. Some will be off-the-shelf, some will be steered with your data, some will be used to judge<a contenteditable="false" data-primary="judge models" data-type="indexterm" id="id436"/> an AI’s output (they’re called <em>judge models</em>), some will be used as is to ensure safety, some will be used for tasks that require complex reasoning, and some will be used to power agents. That’s why the platform approach is so important—and it’s also why we introduced you to the Hugging Face community in <a data-type="xref" href="ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974">Chapter 1</a>.</p>&#13;
&#13;
<p>And as we’ve insinuated (well, we’ve outright told you, but we’re just being polite)—<em>bet on community</em> because the future of AI is less about proprietary models and more about being powered by open science and open source<a contenteditable="false" data-primary="open source AI" data-secondary="multimodel environment of" data-type="indexterm" id="id437"/>. Proprietary models will surely play a part, but so much of what is going to happen in the future will <em>not</em> (and should not) happen behind closed doors. It needs to (and will) play out in plain view, with full transparency and accountability in open source.</p>&#13;
&#13;
<p>Again, the energy around GenAI and agents in the open source community right now is phenomenal. There are distributed projects, university projects, and corporate efforts—all driving innovation and producing LLMs that you can tune and deploy for your use cases.</p>&#13;
&#13;
<p>Many people are saying, “Big tech AI is the problem.” <em>We disagree</em> (and not because we work for a big technology company). We’d rather you widened the aperture<a contenteditable="false" data-primary="proprietary data" data-type="indexterm" id="id438"/> and said, “Proprietary and closed AI is a potentially serious problem.” That, we agree with. Why are we making this point? It’s because there are vendors big and small (we won’t mention them by name here...we’re not trying to pick a fight) that are closed and proprietary, and there are companies that are large (like IBM and Meta) and small (like Mistral AI and DeepSeek, among others) that are open.</p>&#13;
&#13;
<p>For the good of society in the long term, we don’t want just one or a few winners—a few companies that can define what AI is and dictate how it’s used. From what we can see, we don’t think that’s going to happen—and that’s a good thing for you, your business, and society in general.</p>&#13;
&#13;
<section data-pdf-bookmark="It’s Time to Demystify and Apply AI" data-type="sect2"><div class="sect2" id="ch02_it_s_time_to_demystify_and_apply_ai_1740182046163977">&#13;
<h2>It’s Time to Demystify and Apply AI</h2>&#13;
&#13;
<p>As sure as it’s been said that data is the “new oil,” many have dubbed AI the world’s “new electricity.” In addition to GenAI making today’s AI ubiquitous and increasingly accessible (thanks to the prompt), AI can (and <em>will</em>, if done right) enhance and alter the way business is conducted around the world. Today, AI can be used to enable predictions with supreme accuracy, and automate business processes and decision making. The impact is vast, ranging from frictionless customer experiences to intelligent products to more efficient services. In the end, the result will be economic impact for companies, countries, and societies.</p>&#13;
&#13;
<p>To be sure, organizations that drive mass experimentation in AI will win the next decade of market opportunity. To break down and help demystify AI, you need to consider two key elements of the category: <em>the componentry</em> and <em>the process</em>. In other words, you need to identify what’s behind it and how it can be adopted.</p>&#13;
&#13;
<section data-pdf-bookmark="The componentry" data-type="sect3"><div class="sect3" id="ch02_the_componentry_1740182046164049">&#13;
<h3>The componentry</h3>&#13;
&#13;
<p>Much like how the development of the use of electricity was driven by basic components<a contenteditable="false" data-primary="componentry of AI" data-type="indexterm" id="xi_componentryofAI2174102"/> such as resistors, capacitors, diodes, and so on, the development of AI is being driven by modern software componentry that includes the components outlined in this section.</p>&#13;
&#13;
<section data-pdf-bookmark="A unified, modern data fabric with an accompanying data-as-a-product point of view" data-type="sect4"><div class="sect4" id="ch02_a_unified_modern_data_fabric_with_an_accompanying_1740182046164113">&#13;
<h4>A unified, modern data fabric with an accompanying data-as-a-product point of view<a contenteditable="false" data-primary="data fabric" data-type="indexterm" id="xi_datafabric2176101"/><a contenteditable="false" data-primary="data as a product" data-type="indexterm" id="xi_dataasaproduct2176101"/></h4>&#13;
&#13;
<p>You’ve heard us already say it several times in this book: your AI needs an IA. Why? Because AI feeds on data, and therefore, your data must be prepared for AI. (This is why it’s first on our list.) This goes beyond garbage in, garbage out (GIGO), although that’s even more of an issue with AI since all AI does is find those numerical patterns we alluded to in <a data-type="xref" href="ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974">Chapter 1</a>. This will be a problem unless you think everything on the internet is real, there’s no fake news, and there isn’t hate, abuse, or profanity that goes on there. In other words, this is a problem.</p>&#13;
&#13;
<p>A <em>data fabric</em> (when done right) covers all enterprise data with governed searchability and connectivity. It removes the complexity of connecting to data and understanding the details of the underlying technology using data intelligence. You’ll often hear us shout out, “Cloud is a capability, not a destination!” (Hybrid cloud is an approach pretty much settled on by all businesses.) In the same way, you use a data fabric to apply a parallel best thought process to your IA: the “data isn’t just in one place” mindset, which has benefits that are applicable everywhere.</p>&#13;
&#13;
<p>A data fabric acts as a logical representation of all data assets on any cloud (public, private, or on premises). It auto-organizes and auto-labels data across an enterprise (and outside the enterprise, if needed), no matter where it resides. It empowers shipping function to data, as opposed to data to function, and this optimizes compute cycles. In plain speak, that means it takes the operations you want to apply to data and sends them to where the data is, as opposed to getting all the data and pulling it into a single place to do the computations. In this big-data world, you can imagine how the latter won’t scale.</p>&#13;
&#13;
<p>Perhaps most importantly, it provides a company’s employees with governed and seamless access to all available data through virtualization, from the firewall to the edge. When you think about data fabric, think <em>self-service</em>,<em> ease of access</em>,<em> </em>and<em> data <span class="keep-together">protection</span>. </em></p>&#13;
&#13;
<p>Ultimately, a data fabric transforms data utilization into a process of knitting together data across your business—and externally, if appropriate.</p>&#13;
&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="ch02_data_as_a_product_1740182046164174">&#13;
<h1>Data as a Product</h1>&#13;
&#13;
<p>While it’s outside the scope of this book, we’d be remiss if we didn’t mention <em>data as a product</em> because it goes with a data fabric. (You may have heard<a contenteditable="false" data-primary="data mesh" data-type="indexterm" id="id439"/> of <em>data mesh </em>before, so think of that as the seedling of data as a product.) Data mesh is all about looking at data as a product. This architecture is as much cultural as it is technological in that it shifts responsibility for data veracity from IT teams to business teams that own and curate the data.</p>&#13;
&#13;
<p><em>Data as a product</em> means that data is treated as an API, with each business unit (sometimes referred to as a <em>domain</em>) held responsible for ensuring that what’s behind their API is high-quality data and that it’s made available to other business units. When you think about data as a product, you stumble upon another key principle of a great IA that will help<a contenteditable="false" data-primary="domain ownership" data-type="indexterm" id="id440"/> your AI: <em>domain ownership</em>, which means business units taking responsibility for their data.</p>&#13;
&#13;
<p>Another data-as-a-product component<a contenteditable="false" data-primary="federated data governance" data-type="indexterm" id="id441"/> is <em>federated data governance</em>, which is about having consistent governance of data across all sources—and a hefty dose of automation to support this task —with the help of AI. This is why we think data as a product goes so well with a data fabric. Many companies try to build this component themselves as opposed to using a data fabric, and that results in a lot of wasted time, money, and missed project delivery dates<a contenteditable="false" data-primary="" data-startref="xi_datafabric2176101" data-type="indexterm" id="id442"/><a contenteditable="false" data-primary="" data-startref="xi_dataasaproduct2176101" data-type="indexterm" id="id443"/>.</p>&#13;
&#13;
<p>When you think of data as a product, think <em>curation</em>,<em> governance</em> (with the help of data fabric),<em> </em>and<em> lineage.</em></p>&#13;
</div></aside>&#13;
&#13;
<p>A great IA strategy includes more than the things we just mentioned, but they are the levers to pull—and from there, tasks like collecting data, organizing it, governing it, infusing it into existing AI (and non-AI) business processes, and more all fall into place.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="A development environment and an engine" data-type="sect4"><div class="sect4" id="ch02_a_development_environment_and_an_engine_1740182046164236">&#13;
<h4>A development environment and an engine</h4>&#13;
&#13;
<p>A business needs a place to build, upskill, train, and run its AI models<a contenteditable="false" data-primary="componentry of AI" data-secondary="development environment and engine" data-type="indexterm" id="id444"/><a contenteditable="false" data-primary="AI Value Creation" data-secondary="development environment and engine" data-type="indexterm" id="id445"/><a contenteditable="false" data-primary="models" data-secondary="development environment and engine" data-type="indexterm" id="id446"/>. Ideally, the componentry is integrated with your <span class="keep-together">strategic decisions</span> for data persistence (like a data lakehouse) and a governance framework—and it’s all integrated with shared metadata across the ecosystem. This approach also helps organizations <a contenteditable="false" data-primary="development environment and engine for AI" data-type="indexterm" id="id447"/>come together on a common mission, language, and design process—from input to output. By the time you have both components in hand, your company’s data strategy will start to feel like magic. And while we’ve dismissed the magic myth, turbocharging a plan and having momentum at your back <em>will</em> feel amazing.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="The modality of human features" data-type="sect4"><div class="sect4" id="ch02_the_modality_of_human_features_1740182046164297">&#13;
<h4>The modality of human features</h4>&#13;
&#13;
<p>A mechanism<a contenteditable="false" data-primary="human features modality for AI" data-type="indexterm" id="xi_humanfeaturesmodalityforAI219729"/> for bringing AI models “to life” involves connecting those models and applications to human features<a contenteditable="false" data-primary="componentry of AI" data-secondary="human features, modality for" data-type="indexterm" id="xi_componentryofAIhumanfeaturesmodalityfor2197130"/><a contenteditable="false" data-primary="AI Value Creation" data-secondary="human features, modality for" data-type="indexterm" id="xi_AIValueCreationhumanfeaturesmodalityfor2197130"/> like voice, language, vision, and reasoning. GenAI, and especially agents, is included in a lot of frictionless customer experience discussions that typically land on the topic of chatbots<a contenteditable="false" data-primary="chatbots" data-type="indexterm" id="id448"/>. But the term <em>chatbot </em>often invokes visions of typing—and while that is one modality, a natural-sounding voice behind an interactive voice response (IVR)<a contenteditable="false" data-primary="interactive voice response (IVR)" data-type="indexterm" id="id449"/><a contenteditable="false" data-primary="IVR (interactive voice response)" data-type="indexterm" id="id450"/> is a bot, too. We’ve all interacted with IVRs that don’t sound human at all, but with AI, you can bring real human sound <em>and </em>expression to the<em> </em>experience. For example, try uploading something into Google’s NotebookLM and asking it to generate a podcast for you—impressive stuff! Using AI helps turbocharge IVRs with expressive voices that let you welcome your customers with humanlike speech, emotions, word emphasis, and interjections.</p>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>While we cover agentic AI<a contenteditable="false" data-primary="agentic systems" data-secondary="in modality of interaction" data-secondary-sortas="modality of interaction" data-type="indexterm" id="id451"/> in this book, we don’t specifically cover the impact of agents on the modality of interaction, specifically the user experience (UX). The designs of tomorrow will have to consider two kinds of users: humans and agents. The agent experience (AX)<a contenteditable="false" data-primary="agent experience (AX)" data-type="indexterm" id="id452"/><a contenteditable="false" data-primary="AX (agent experience)" data-type="indexterm" id="id453"/> will be using APIs to compose workflows <em>but </em>now includes desktop interactions.</p>&#13;
</div>&#13;
&#13;
<p>This capability is important because whether we realize it or not, as humans, we convey emotions in the words we speak. We may sound empathetic when apologizing to one another, uncertain when we don’t know the answer to something, and cheerful when we convey good news. This ability to convey emotion is what makes our voices human, and using AI to do this can ultimately reduce customer frustration when dealing with today’s phone experiences.</p>&#13;
&#13;
<p>But here’s the big point we want you to understand (and why upskilling<a contenteditable="false" data-primary="upskilling" data-type="indexterm" id="id454"/> is such a hot topic): customized brand voices (even yours)<a contenteditable="false" data-primary="customized brand voices, generating" data-type="indexterm" id="id455"/> can be generated in minutes, with no technical expertise required! Quite simply, expressive voices make customers feel like they are talking to a real human and not a robot, but your company will get the benefits of shifting left (deflecting) those costs from a live agent (who costs about $5 per interaction) to an AI-assisted agent (which costs about $0.25 per interaction) for “the easy stuff.” This is such a great example of those problems we walk by every day that we can solve or make better with technology. If you own a support channel with an IVR and have no idea how easy it is to build out human-sounding natural interactions, you’re settling for a maze of “Press 1 to...,” where instead of finding the prize at the end, your clients find themselves yelling “Talk to someone!” into the void.</p>&#13;
&#13;
<p>This really leads to multimodal AI, where human features become more and more apparent in the AI. For example, Google’s Gemini, Apple’s FERRET, Meta’s Llama, DeepSeek’s Janus-Pro, IBM’s Granite, and various OpenAI models all allow you to include a picture in a prompt<a contenteditable="false" data-primary="prompts" data-secondary="images used in" data-type="indexterm" id="id456"/>, and they’ll tell you what they see. Imagine that you’ve been sent a picture of a package at your door from a delivery service, and it came with an AI-generated description that might notify you, “The corner of this box is damaged.” Also imagine that same package came with a prefilled form to submit if<em> </em>the package’s contents are damaged once you get home and open it. If you open your package and all is fine, great, nothing to do. And if something is wrong with the shipped item, the return will be as frictionless as possible—this is agentic<a contenteditable="false" data-primary="agentic systems" data-secondary="image identification and frictionless package return" data-type="indexterm" id="id457"/> AI at work! We really want you to put yourself in the picture in this example. While it’s true no one wants something to go wrong (like getting shipped a damaged item, receiving the wrong item, or having to reset a password), the <em>bigger basic truth </em>is that when things do go wrong, you shouldn’t present your customers with friction (like transferring them three times, asking them to reauthenticate their identity, and all the stuff that could be summarized as the WTF moments we seem to live weekly these days). Ironically, studies show that truly good customer experiences are <em>not just </em>about a business getting it right. In fact, as a business, you’re probably allowed to get stuff wrong (depending on the use case—if your business is heart surgery and you get it wrong, then there may not be a customer to complain, but we’re sure some lawyers will). But keeping things frictionless is critical, and it buys your company customer patience, understanding, loyalty, and more when things don’t go as planned<a contenteditable="false" data-primary="" data-startref="xi_componentryofAIhumanfeaturesmodalityfor2197130" data-type="indexterm" id="id458"/><a contenteditable="false" data-primary="" data-startref="xi_humanfeaturesmodalityforAI219729" data-type="indexterm" id="id459"/><a contenteditable="false" data-primary="" data-startref="xi_AIValueCreationhumanfeaturesmodalityfor2197130" data-type="indexterm" id="id460"/>.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="AI management and exploitation" data-type="sect4"><div class="sect4" id="ch02_ai_management_and_exploitation_1740182046164355">&#13;
<h4>AI management and exploitation</h4>&#13;
&#13;
<p>This enables you to confidently insert AI<a contenteditable="false" data-primary="management and exploitation, AI" data-type="indexterm" id="id461"/><a contenteditable="false" data-primary="componentry of AI" data-secondary="management and exploitation" data-type="indexterm" id="id462"/><a contenteditable="false" data-primary="AI Value Creation" data-secondary="management and exploitation, AI" data-type="indexterm" id="id463"/> into any application or business process, but to do that, you need to understand how the model was built, what data was used, how to improve a model’s impact, what has changed, drift, bias, and variance. This is where your models live for exploitation and enable lifecycle management of all AI. Lastly, this component offers proof of and explainability for decisions made by your AI.</p>&#13;
&#13;
<p>Think of it this way: if we were to tell you the amount of data generated every minute in the world, that number would be out of date the moment we saved the first draft of this chapter. Every time we updated this chapter, it would be instantly out of date. Your models are not much different, and this is referred<a contenteditable="false" data-primary="drift, model" data-type="indexterm" id="id464"/><a contenteditable="false" data-primary="model drift" data-type="indexterm" id="id465"/> to as <em>drift</em>. You need to know that AI models can start to drift the moment they go into production. And if your data history (the data you used to train the model) doesn’t “rhyme” with the data of today, that model is really going to drift away from what it was intended to do (like pick an opportunity) and/or start to do bad things (like pick up bias).</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Agents and assistants for the masses" data-type="sect4"><div class="sect4" id="ch02_agents_and_assistants_for_the_masses_1740182046164415">&#13;
<h4>Agents and assistants for the masses</h4>&#13;
&#13;
<p>As you work AI into your business’s nervous system, classify the AI, and attach it to workflows (this is +AI), you should know that agents and assistants<a contenteditable="false" data-primary="agentic systems" data-secondary="AI role of" data-type="indexterm" id="id466"/><a contenteditable="false" data-primary="componentry of AI" data-secondary="agents and assistants" data-type="indexterm" id="id467"/><a contenteditable="false" data-primary="agentic systems" data-secondary="benefits to business" data-type="indexterm" id="id468"/><a contenteditable="false" data-primary="AI Value Creation" data-secondary="agents and assistants, AI" data-type="indexterm" id="id469"/><a contenteditable="false" data-primary="assistants" data-secondary="benefits to business" data-type="indexterm" id="id470"/><a contenteditable="false" data-primary="assistants" data-secondary="AI role of" data-type="indexterm" id="id471"/><a contenteditable="false" data-primary="business considerations" data-secondary="agentic system benefits" data-type="indexterm" id="id472"/> <em>really</em> help you deliver serious benefits to the business. We think agents and assistants are where you can really democratize AI in your company (in many cases, you will see them integrated). Yes, it’s important to have an AI platform that lets you collect, organize, and store data, build GenAI models, and govern them. Super important. But assistants and agents are the chassis to use the power of your models to lift the enterprise. For example, development teams can use Microsoft Copilot or a flavor of IBM’s watsonx Code Assistant to power up their development process. Perhaps you’re designing a frictionless experience for customers using <span class="keep-together">watsonx</span> Assistant or Kore.ai, or perhaps you’re even orchestrating workflows using Aisera or watsonx Orchestrate<a contenteditable="false" data-primary="watsonx Code Assistant" data-secondary="Orchestrate" data-type="indexterm" id="id473"/> with its library of AI agents. All of these are examples of real AI boosting the productivity of people in your business. We think that’s a critical piece of any successful AI strategy because it gives detailed answers to the questions: who is going to use the AI and how is it going to help them? Depending on your job, you’d be well served to know the answers to these questions—or know to ask them.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="The process: Cake ingredients without a recipe do not make a cake" data-type="sect3"><div class="sect3" id="ch02_the_process_cake_ingredients_without_a_recipe_do_1740182046164479">&#13;
<h3>The process<a contenteditable="false" data-primary="AI Value Creation" data-secondary="process of" data-type="indexterm" id="xi_AIValueCreationprocessof221628"/>: Cake ingredients without a recipe do not make a cake</h3>&#13;
&#13;
<p>With these components in hand<a contenteditable="false" data-primary="business considerations" data-secondary="AI usage analysis" data-type="indexterm" id="xi_businessconsiderationsAIusageanalysis221745"/><a contenteditable="false" data-primary="AI (artificial intelligence)" data-secondary="business analysis for AI use" data-type="indexterm" id="xi_AIartificialintelligencebusinessanalysisforAIuse221745"/>, more organizations will be able to unlock the value that lies within their data. But to fully leverage AI, you must also understand how to adopt and implement this technology. Here’s some quick advice on some fundamental steps to put AI for business to work (again, you’ll get more details as you read this book).</p>&#13;
&#13;
<section data-pdf-bookmark="Step 1: Identify the right business opportunities for AI" data-type="sect4"><div class="sect4" id="ch02_step_1_identify_the_right_business_opportunities_1740182046164547">&#13;
<h4>Step 1: Identify the right business opportunities for AI</h4>&#13;
&#13;
<p>The potential areas for adoption are vast: customer service, employee and company productivity, manufacturing defects, supply chain spending, and many more. Anything that can be easily described can be programmed, and once it’s programmed, AI will make it better. As you learned in <a data-type="xref" href="ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974">Chapter 1</a> (and it will really come at you in <a data-type="xref" href="ch04.html#ch04_the_use_case_chapter_1740182047877425">Chapter 4</a>), the opportunities are endless, <em>but </em>it’s important that you make all your efforts about business opportunities and outcomes, and <em>not </em>data science projects. During the Hadoop big-data frenzy, we saw too many clients invest massive amounts of budget and time into projects that didn’t deliver value to the business or weren’t consumable by the business. This is why GenAI is so different: it makes building use cases faster than ever before, and it’s consumable by the masses. Just remember, choose wisely.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Step 2: Prepare the organization for AI" data-type="sect4"><div class="sect4" id="ch02_step_2_prepare_the_organization_for_ai_1740182046164612">&#13;
<h4>Step 2: Prepare the organization for AI</h4>&#13;
&#13;
<p>Organizations will require greater capacity and expertise in many areas, from having the obvious data science teams all the way to having a broadened aperture on just what GenAI can do for your business (to avoid that whole “walking by problems every day that can be solved or made better with the technology” thing we keep talking about in this book).</p>&#13;
&#13;
<p>You’re going to need to do a massive upskilling around GenAI, LLMs, and agents. This effort isn’t about pop-quizzing your marketing copy editor on what least absolute shrinkage and selection operator (Lasso) regression is or what AUC stands for (area under the receiver operating characteristic [ROC] curve) and so on. Having a general base knowledge of the benefits and cautions around AI will be critical to getting AI to work for your company. We can’t stress this piece enough: you must have a plan to upskill all employees to distribute the benefits of AI across your company; and that’s why we dedicated a whole chapter to it—<a data-type="xref" href="ch06.html#ch06_skills_that_thrill_1740182050334297">Chapter 6</a>.</p>&#13;
&#13;
<p>Why is this so important? Many of today’s repetitive and manual tasks will be automated (shifted left)<a contenteditable="false" data-primary="automation" data-secondary="and limitations of AI" data-type="indexterm" id="id474"/><a contenteditable="false" data-primary="upskilling" data-secondary="and automation limitations of AI" data-secondary-sortas="automation limitations of AI" data-type="indexterm" id="id475"/>, which will evolve the role of many employees. <em>It’s rare that an entire role can be done by AI, and it’s also rare that no roles could be enhanced by AI.</em> All technology is useless without the talent to put it to use, so you must build a team of experts who will inspire and train others—but you must ensure that other employees’ skills are constantly evolving. After all, while technology years are typically akin to dog years (1 dog year equals 7 human years), GenAI and agents are progressing like mouse years (1 mouse year equals 30 human years)—you need a plan to keep up.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Step 3: Select technology and partners" data-type="sect4"><div class="sect4" id="ch02_step_3_select_technology_and_partners_1740182046164677">&#13;
<h4>Step 3: Select technology and partners</h4>&#13;
&#13;
<p>While it’s unlikely a CEO would personally select a company’s GenAI technology<a contenteditable="false" data-primary="technology partners, selecting" data-type="indexterm" id="id476"/> stack (or stacks)<a contenteditable="false" data-primary="technology stack (or stacks), choosing" data-type="indexterm" id="id477"/>, the implication here is more of a cultural one. An organization should adopt many technologies and compare, contrast, and learn through that process.</p>&#13;
&#13;
<p>We’ll give you a good tip that will save you a lot of pain: don’t fall into the common trap of thinking the cloud will be one place from one provider. Looking in the rearview mirror, it’s easy to see how that notion has been proven wrong. Now, we’re not saying you should have hundreds of AI vendors in your shop (they are popping up everywhere), but we are reminding you here that one AI model will not rule them all. Organizations should choose a handful of <em>trustworthy</em> partners that have both the skills and the technology to deliver AI. Also, we’ve italicized <em>trustworthy</em> here for a reason. We don’t need to get into the details here, but especially in tech, you’re likely familiar with good actors (upstanders) and bad actors (which are at best bystanders and at worst well-known malefactors). Again, we think trust will be the ultimate operating license, and we’ll let you think about who you trust from here.</p>&#13;
&#13;
<p>At the end of the day, we think most success comes from partnerships<a contenteditable="false" data-primary="partnerships, business value in GenAI" data-type="indexterm" id="id478"/>—be they personal or professional. Think about it: Batman partnered with Robin, Bert had Ernie, Sherlock was nothing without Watson, and even Snooki had The Situation. (That last bit is for anyone who still speaks the <em>Jersey Shore</em> parlance—we’re hoping there aren’t many of you left, and we’re even happier if you have no idea what we’re talking about.)</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Accept failures but do so in a safe manner" data-type="sect4"><div class="sect4" id="ch02_accept_failures_but_do_so_in_a_safe_manner_1740182046164744">&#13;
<h4>Accept failures but do so in a safe manner</h4>&#13;
&#13;
<p>Do you know that over 80% of traditional AI projects<a contenteditable="false" data-primary="failure of project, handling" data-type="indexterm" id="id479"/> never made it to production? As you’ve read about in this chapter, GenAI should improve on those numbers because of the simplicity of getting it going, but you’re still going to encounter friction and failures (wrong completions, legislation, and so on). Perhaps you’ll try 40 AI projects and 30 of them fail, but the 10 that work will more than compensate for the failures, <em>if</em> you pick the right use cases, which is why we wrote <a data-type="xref" href="ch04.html#ch04_the_use_case_chapter_1740182047877425">Chapter 4</a>.</p>&#13;
&#13;
<p>Lots of people like to say, “Fail fast and fail forward.” This implies that teams should quickly recognize when stuff isn’t working, learn from their mistakes, and move on. We think that’s too shallow when it comes to GenAI (and especially agents) advice for many use cases. Think about it this way: would you tell your university kid (for whom you are footing the bill) the same thing? We highly doubt it. We’d propose thinking, “Fail fast, fail forward, and fail safe,” and advise your kid to do that instead. This is why we think governments shouldn’t necessarily regulate AI (the default position for many governments) but regulate the use cases for AI. We think the AI behind a criminal justice sentencing system (fail fast, fail forward, fail safe) should be held to a much higher account and have more regulatory oversight than an AI that recommends what TV series you should binge-watch next because you loved the <em>Young Sheldon</em> show (fail fast, fail forward—no one is truly going to get hurt from watching <em>The Real Housewives of New Jersey</em>...well, perhaps a few). This is exactly why in <a data-type="xref" href="ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974">Chapter 1</a> we said the safest place to start is with an internal automation use case.</p>&#13;
&#13;
<p>The culture<a contenteditable="false" data-primary="company culture" data-secondary="shifting to GenAI" data-type="indexterm" id="id480"/> you create has to change too. It must be ready and willing to accept safe failures<a contenteditable="false" data-primary="safe failures, need to accept" data-type="indexterm" id="id481"/>, learn from them, and move on to the next one. For those of you who are leading your company’s AI projects (again, some of which are bound to fail), we have this great piece of advice that we came up with by hybridizing quotes from Michael Hyatt and Forrest Gump: on your greatest days, you’re probably not as smart as you think you are, but on your worst days, you’re probably not as dumb as you think you are either<a contenteditable="false" data-primary="" data-startref="xi_AIartificialintelligencefutureof216240" data-type="indexterm" id="id482"/><a contenteditable="false" data-primary="" data-startref="xi_componentryofAI2174102" data-type="indexterm" id="id483"/><a contenteditable="false" data-primary="" data-startref="xi_businessconsiderationsAIusageanalysis221745" data-type="indexterm" id="id484"/><a contenteditable="false" data-primary="" data-startref="xi_AIValueCreationprocessof221628" data-type="indexterm" id="id485"/><a contenteditable="false" data-primary="" data-startref="xi_AIartificialintelligencebusinessanalysisforAIuse221745" data-type="indexterm" id="id486"/><a contenteditable="false" data-primary="" data-startref="xi_multimodelAI216240" data-type="indexterm" id="id487"/><a contenteditable="false" data-primary="" data-startref="xi_multimodalAI216240" data-type="indexterm" id="id488"/>.</p>&#13;
</div></section>&#13;
</div></section>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="The Future of AI" data-type="sect1"><div class="sect1" id="ch02_the_future_of_ai_1740182046164806">&#13;
<h1>The Future of AI</h1>&#13;
&#13;
<p>With all the advances achieved in the last few years, the ambition of the 1950s has come full circle. Today’s models <em>do not</em> constitute true general intelligence<a contenteditable="false" data-primary="artificial general intelligence (AGI)" data-type="indexterm" id="id489"/><a contenteditable="false" data-primary="AGI (artificial general intelligence)" data-type="indexterm" id="id490"/> (although reasoning models are getting us closer), but some of them can pass<a contenteditable="false" data-primary="Turing test" data-type="indexterm" id="id491"/> the <em>Turing test</em> (originally referred to as the <em>imitation game</em>), which is a test of a machine’s ability to exhibit intelligent behavior equivalent to or indistinguishable from that of a human.</p>&#13;
&#13;
<p>So, what does this mean for all of us? Some people encounter GenAI and agents and think we’re at the dawn of a bright utopian age, while others think this is a prelude to dystopian misery. We take a moderate but positively slanted view: <em>a technology doesn’t have to be world ending to be world changing</em>. Like we said in <a data-type="xref" href="ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974">Chapter 1</a>, we don’t think it should be a surprise to anyone that technological innovations can help and/or hurt us (social media is a great example of this). We want you to know that we think both optimism and anxiety are valid, and that society has questioned every major innovation milestone from the Industrial Revolution onward (and in many cases, gotten it wrong).</p>&#13;
&#13;
<p>AI isn’t just going to be about our digital world. It’s also about our physical world; and applied properly, imagine what AI can do for the pace of discovery and innovation. It’s not just makeup; imagine what it can do for new materials discovery for medicine, energy, climate, and all the other pressing challenges we face as a species—these are the same challenges of makeup, just described with a different “language.” And as quantum computing evolves, we’re bound to see a synergy of these innovations that we can use to tackle these problem domains and more. Finally, what of a new kind of computing around GenAI—we’ll save that for <a data-type="xref" href="ch09.html#ch09_generative_computing_a_new_style_of_computing_1740182052619664">Chapter 9</a>.</p>&#13;
&#13;
<p>Ultimately, our success and that of all humanity depends on how we and the rest of the world approach AI.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Let’s Get into It" data-type="sect1"><div class="sect1" id="ch02_let_s_get_into_it_1740182046164866">&#13;
<h1>Let’s Get into It</h1>&#13;
&#13;
<p>We’ve covered a lot of topics (at a high level) so far in this book, but we’ve basically told you that you have to do a lot of non-techie work to be great at AI. Maybe that feels overwhelming. It’s not our intention to make you feel that way, but you do need to feel a bit unsettled to move faster—to move with intent so that you don’t miss out. The goal of the rest of this book is to <em>remove barriers to your participation, not <span class="keep-together">construct</span> them</em>.</p>&#13;
&#13;
<p>Make no mistake about it, if you’re feeling a sense of urgency <a contenteditable="false" data-primary="AI Value Creation" data-secondary="rewards of GenAI platform" data-type="indexterm" id="id492"/>and fear about waiting too long and missing the moment, that’s OK. We can assure you that almost every other company is in the same situation, and lots of people are feeling the very same emotions that you are feeling right now. And trust us, we’ve heard many fishing stories of individuals and companies talking about their AI or how their products are built with AI, and like most fishing stories, many are exaggerated or untrue. We want to tell those people not to go telling fishing stories to those who know the real size of the fish, but we just smile and carry on with our day. That said, by reading this book, you’ll be in a position to do the same, and we’ll let you decide if you just smile or not.</p>&#13;
&#13;
<p>We can promise you (and your business) this: if you can show some restraint and not carelessly check the “I put AI in the business” box using fast and easy options (or be pressured to do so); if instead, you are thoughtful, deliberate, and strategic about using a platform that considers all the components you need (AI, data intelligence, data integration, and governance); and <em>most importantly, if you set your GPS to a <span class="keep-together">destination</span> of “AI Value Creator,”</em> then you’re going to be in a position to succeed over the long term. What’s more, like so many before you, your company won’t have to start over every time the winds of AI change direction.</p>&#13;
&#13;
<p>Personally, we’re very excited about this new chapter in technology. We, all of us together, are going to use GenAI and agents to reshape not just our digital world but also our physical world. We’re going to use it to help tackle some of our toughest social, medical, and environmental problems, and more. We’ll do it through science, but also by empowering businesses—like the ones you work for and the one we work for—to do more faster and more responsibly. Whatever thing it is that your company does, AI is going to be a powerful new tool to help you do it better.</p>&#13;
&#13;
<p>We’re quite certain of this: <em>the AI Value Creators will be the ones who make the biggest impact</em>. They will take the amazing foundational technology that is GenAI and use it to build entirely new solutions and workflows. That’s why it’s our goal to make AI accessible to everyone and put it in your hands, which is what this book is all about.</p>&#13;
</div></section>&#13;
<div data-type="footnotes"><p data-type="footnote" id="id389"><sup><a href="ch02.html#id389-marker">1</a></sup> Alan Turing, “Computing Machinery and Intelligence,” <em>Mind</em> 49, no. 236 (October 1950): 433‒460, <a href="https://doi.org/10.1093/mind/LIX.236.433"><em>https://doi.org/10.1093/mind/LIX.236.433</em></a>. </p><p data-type="footnote" id="id395"><sup><a href="ch02.html#id395-marker">2</a></sup> Noise in training data is any kind of irrelevant or random information, errors, or variations that do not reflect the true underlying patterns or relationships in the data. </p></div></div></section></body></html>