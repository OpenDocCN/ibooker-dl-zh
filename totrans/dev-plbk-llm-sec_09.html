<html><head></head><body><section data-pdf-bookmark="Chapter 9. Find the Weakest Link" data-type="chapter" epub:type="chapter"><div class="chapter" id="find_the_weakest_link">
      <h1><span class="label">Chapter 9. </span>Find the Weakest Link</h1>
      <blockquote data-type="epigraph" epub:type="epigraph">
        <p><a contenteditable="false" data-primary="supply chains (for LLM application development)" data-type="indexterm" id="ch09.html0"/>You are the weakest link. Goodbye!</p>
        <p data-type="attribution">Every episode of <em>The Weakest Link</em> game show (BBC/NBC)</p>
      </blockquote>
      <p>On the morning of December 10th, 2021, I woke up to an overnight message from David Linder, my company’s Chief Information Security Officer (CISO). It said, “Call me as soon as you’re up. It’s important.” I knew this wasn’t going to be good news. Your CISO calling in the middle of the night is the last thing an executive wants.</p>
      <p>Once I got ahold of David, he told me that in the past 24 hours, major corporations worldwide were being hacked. The problem had been traced back to a single, open source library embedded into <em>millions</em> of applications. <em>Wired</em> magazine published a story about the incident that cried, <a href="https://oreil.ly/I26Ux">“The Internet Is on Fire!”</a></p>
      <p>Later in this chapter, I’ll tell you more about that story. I give that snippet now to impress upon you how critical the issue of <em>software supply chain security</em> has become for software development today. Some readers of this book may be coming from an application security (AppSec) background and are reading this chapter for specific guidance about securing LLMs. However, I’m sure other readers are coming here already understanding LLMs and looking for guidance on security best practices. Knowing this, I will set up this chapter to cover both.</p>
      <p>We’ll start by covering the basic concepts of supply chain security. Then, we will examine the unique structure and challenges of an LLM application’s supply chain. We’ll discuss some best practices, but we must also acknowledge this is a fast-moving part of the LLM security landscape. So, we’ll wrap up with a discussion about the future of the space.</p>
      <section data-pdf-bookmark="Supply Chain Basics" data-type="sect1"><div class="sect1" id="supply_chain_basics">
        <h1>Supply Chain Basics</h1>
        <p><a contenteditable="false" data-primary="supply chains (for LLM application development)" data-secondary="basics" data-type="indexterm" id="ch09.html1"/>For readers who may be well-versed in AI but newer to AppSec concepts, I will start by setting up some basics around the supply chain and discussing some well-known case studies involving failure to properly manage supply chain security. </p>
        <p>I wasn’t a computer science major in college. I studied business. I could go on about how lessons about business have often offered me unique insights into software development. The supply chain is one of these cases. It’s a concept thoroughly studied by business researchers for decades.</p>
        <div data-type="note" epub:type="note"><h6>Note</h6>
          <p>The term <em>supply chain</em> refers to the entire process of producing and delivering a product or service, from sourcing raw materials to distribution to the end user. It encompasses various steps, such as <span class="keep-together">procurement,</span> manufacturing, transportation, and distribution, involving a network of entities, including suppliers, manufacturers, and retailers. Effective supply chain management is crucial for businesses to ensure efficiency, cost-effectiveness, and timely delivery of products and services.</p>
        </div>
        <p>As the world industrialized, our economic model transitioned from a craftsman-based system to a mass production–dominated system. This shift led to extensive global supply chains, replacing the earlier practice of individuals or small groups producing goods with locally sourced materials. In these complex global networks, manufacturers rely on suppliers from various countries to provide specific components needed for their products. For example, a single delay or quality issue in one part of the world, such as a shortage of a specific semiconductor in China, can halt iPhone production, leading to widespread shortages. Similarly, if a seat belt component sourced from a third-party supplier fails to meet safety standards, it can compel a company like Ford to issue a massive safety recall. These scenarios illustrate how modern supply chains’ intricate interdependencies and logistical challenges can significantly impact product availability and quality.</p>
        <div data-type="note" epub:type="note"><h6>Note</h6>
          <p>The proverb “a chain is only as strong as its weakest link” is used to convey that a system or organization is vulnerable due to its weakest component. It emphasizes the importance of ensuring every part is solid and reliable because even one weak point can lead to the failure of the entire system. This concept is often applied in various contexts, including security, teamwork, and quality assurance.</p>
        </div>
        <section class="pagebreak-before" data-pdf-bookmark="Software Supply Chain Security" data-type="sect2"><div class="sect2" id="software_supply_chain_security">
          <h2>Software Supply Chain Security</h2>
          <p><a contenteditable="false" data-primary="software supply chain security" data-type="indexterm" id="id523"/><a contenteditable="false" data-primary="supply chain management (for software)" data-type="indexterm" id="id524"/><a contenteditable="false" data-primary="supply chains (for LLM application development)" data-secondary="basics" data-tertiary="software supply chain security" data-type="indexterm" id="id525"/>Today, large software development teams are often referred to as software factories because of the increasing similarities in modern, large-scale software development methodologies to traditional mass production, making the concept of the supply chain highly relevant. </p>
          <p>Software supply chain security is an increasingly pivotal aspect of cybersecurity. It involves a series of measures designed to ensure the integrity and security of software throughout its lifecycle, from development to deployment. The field includes scrutinizing third-party components, such as libraries and packages, for vulnerabilities; ensuring the security of code repositories; and safeguarding continuous integration and delivery processes.</p>
          <p>The essence of software supply chain security is to identify, manage, and mitigate risks that might compromise software at any stage of its development or deployment. Tight management is crucial because any breach in the supply chain can lead to severe data breaches, loss of customer trust, and significant financial and reputational damage. Recent high-profile breaches have shown that vulnerabilities in the  <span class="keep-together">supply chain can</span> have far-reaching effects, impacting countless users and multiple <span class="keep-together">organizations.</span></p>
          <p>As organizations increasingly rely on open source components and third-party software, the complexity and interconnectedness of the software supply chain grow. Consequently, developers, security professionals, and business leaders must understand the risks and implement strategies to safeguard their software supply chains. This includes rigorous vetting of third-party components, maintaining an up-to-date inventory of all elements used in the software (often through a software bill of materials), regular scanning for vulnerabilities, and adopting a comprehensive, proactive approach to security.</p>
          <p>Now, let’s look at a few examples of serious breaches, their consequences, and lessons learned from them. </p>
        </div></section>
        <section data-pdf-bookmark="The Equifax Breach " data-type="sect2"><div class="sect2" id="the_equifax_breach">
          <h2>The Equifax Breach </h2>
          <p><a contenteditable="false" data-primary="Equifax data breach" data-type="indexterm" id="ch09.html2"/><a contenteditable="false" data-primary="supply chains (for LLM application development)" data-secondary="basics" data-tertiary="Equifax breach" data-type="indexterm" id="ch09.html3"/>In March 2017, researchers disclosed a serious vulnerability (<a href="https://oreil.ly/k4KTx">CVE-2017-5638</a>) in the popular Apache Struts web framework. The vulnerability allowed remote code execution via malicious input, and the MITRE Corporation (which we’ll learn more about later in this chapter) assigned it a maximum severity score of 10. Equifax, one of the largest consumer credit reporting agencies, used Struts in one of its public web portals. However, the company failed to patch the disclosed vulnerability for over two months, exposing their systems.</p>
          <p class="pagebreak-before">In May 2017, hackers exploited the unpatched Struts flaw to breach Equifax systems and exfiltrate sensitive personal and financial data related to 148 million consumers. Equifax did not discover the breach until July 2017. This massive breach resulted in over $1 billion in losses for Equifax.</p>
          <section data-pdf-bookmark="Impact " data-type="sect3"><div class="sect3" id="impact_idbLRvzl">
            <h3>Impact </h3>
            <p>The Equifax breach affected nearly half the US population and had enormous <span class="keep-together">consequences:</span></p>
            <ul>
              <li>
                <p>Sensitive PII, such as SSNs, addresses, and birth dates, was stolen, enabling identity theft.</p>
              </li>
              <li>
                <p>Multiple class-action lawsuits were filed against Equifax.</p>
              </li>
              <li>
                <p>Hundreds of millions of dollars in settlement money was paid for damages to affected consumers.</p>
              </li>
              <li>
                <p>Equifax senior executives were fired and suffered major reputation damage.</p>
              </li>
            </ul>
          </div></section>
          <section data-pdf-bookmark="Lessons learned " data-type="sect3"><div class="sect3" id="lessons_learned">
            <h3>Lessons learned </h3>
            <p>The incident highlighted critical software security issues:</p>
            <ul>
              <li>
                <p>Patch open source components quickly, especially if they are internet facing.</p>
              </li>
              <li>
                <p>Understand your external attack surface and third-party risks.</p>
              </li>
              <li>
                <p>Use multilayer security controls to limit breach impacts.</p>
              </li>
              <li>
                <p>Implement incident response planning for “when,” not “if.”</p>
              </li>
            </ul>
            <p>The Equifax breach was a seminal event that demonstrated the immense risks unpatched software posed to companies and private citizens. Key lessons include quickly applying patches, restricting component access, monitoring systems, and planning incident responses.<a contenteditable="false" data-primary="" data-startref="ch09.html3" data-type="indexterm" id="id526"/><a contenteditable="false" data-primary="" data-startref="ch09.html2" data-type="indexterm" id="id527"/></p>
          </div></section>
        </div></section>
        <section data-pdf-bookmark="The SolarWinds Hack " data-type="sect2"><div class="sect2" id="the_solarwinds_hack">
          <h2>The SolarWinds Hack </h2>
          <p><a contenteditable="false" data-primary="SolarWinds hack" data-type="indexterm" id="ch09.html4"/><a contenteditable="false" data-primary="supply chains (for LLM application development)" data-secondary="basics" data-tertiary="SolarWinds hack" data-type="indexterm" id="ch09.html5"/>In December 2020, a major cyberattack was uncovered targeting SolarWinds, a software company that provides IT management tools used by thousands of organizations globally. Hackers had inserted malicious code into the SolarWinds Orion network monitoring software, which was then distributed unknowingly to SolarWinds’s customers as software updates between March and June 2020.</p>
          <p>This supply chain attack took advantage of the widespread use of SolarWinds software to infiltrate the networks and systems of high-profile targets like US government agencies, major technology companies including Microsoft and FireEye, and other large corporations and organizations. The hackers, suspected to be part of a sophisticated Russian cyber espionage operation, managed to avoid detection for almost a year through stealthy techniques to impersonate legitimate user activity and blend in with normal network traffic.</p>
          <div data-type="note" epub:type="note"><h6>Note</h6>
            <p>Attackers compromised SolarWinds’s build pipeline to insert the malicious code. Securing your build pipelines is crucial to the overall security of your software. Failure to do so can impact your <span class="keep-together">customers—not</span> just you!</p>
          </div>
          <section data-pdf-bookmark="Impact " data-type="sect3"><div class="sect3" id="impact_idig1EiV">
            <h3>Impact </h3>
            <p>The SolarWinds hack had an unprecedented impact in terms of scale and number of affected victims. By infiltrating the software supply chain, the attackers gained far-reaching access to thousands of downstream customers. Beyond SolarWinds, the access enabled by the compromised Orion software also opened pathways to breach the networks of their customers and partners. Estimates indicate that over one hundred US companies and government agencies were affected.</p>
            <p>The full impact is still being uncovered, but consequences include:</p>
            <ul>
              <li>
                <p>Sensitive government and corporate data theft</p>
              </li>
              <li>
                <p>Access to core infrastructure and internal communications</p>
              </li>
              <li>
                <p>Cascading breaches across interconnected partners and supply chains</p>
              </li>
              <li>
                <p>Significant costs for incident response and remediation</p>
              </li>
            </ul>
          </div></section>
          <section data-pdf-bookmark="Lessons learned " data-type="sect3"><div class="sect3" id="lessons_learned_6">
            <h3>Lessons learned </h3>
            <p>The SolarWinds attack highlighted major risks in increasingly interconnected software supply chains and the need for better security practices, including:</p>
            <ul>
              <li>
                <p>Multifactor authentication, privileged access management, and logging to help detect unusual access</p>
              </li>
              <li>
                <p>Software verification, code audits, and enhanced supply chain controls by <span class="keep-together">vendors</span></p>
              </li>
              <li>
                <p>Improved compartmentalization between systems to limit lateral movement</p>
              </li>
              <li>
                <p>Assuming breach and engaging in more proactive threat hunting</p>
              </li>
              <li>
                <p>Faster coordination and information sharing across the public and private sector</p>
              </li>
            </ul>
            <p>The SolarWinds hack demonstrates the potential scale and impact of supply chain cyberattacks by leveraging trusted third-party software to breach countless downstream targets. More vigilance and collaboration on software supply chain security will be crucial.<a contenteditable="false" data-primary="" data-startref="ch09.html5" data-type="indexterm" id="id528"/><a contenteditable="false" data-primary="" data-startref="ch09.html4" data-type="indexterm" id="id529"/></p>
          </div></section>
        </div></section>
        <section data-pdf-bookmark="The Log4Shell Vulnerability " data-type="sect2"><div class="sect2" id="the_log4shell_vulnerability">
          <h2>The Log4Shell Vulnerability </h2>
          <p><a contenteditable="false" data-primary="Log4Shell vulnerability" data-type="indexterm" id="ch09.html6"/><a contenteditable="false" data-primary="supply chains (for LLM application development)" data-secondary="basics" data-tertiary="Log4Shell vulnerability" data-type="indexterm" id="ch09.html7"/>At the start of this chapter, I shared a story about my CISO calling in the middle of the night and filling me in on a major problem. That quickly ballooned into one of the biggest stories in supply chain security ever. These are the details of that story.</p>
          <p>In November 2021, a critical zero-day remote code execution vulnerability was discovered in Log4j, a Java logging library used by an incredible number of applications and services. Tracked as <a href="https://oreil.ly/7sGbm">CVE-2021-44228</a> and dubbed “Log4Shell,” this vulnerability allowed attackers to gain full control and remote access to vulnerable servers. </p>
          <div data-type="warning" epub:type="warning"><h6>Warning</h6>
            <p><a contenteditable="false" data-primary="zero-day vulnerabilities" data-type="indexterm" id="id530"/>Zero-day vulnerabilities are unknown software flaws that come to light before developers can create a patch (i.e., they have zero days to prepare). They pose a significant security risk because attackers can exploit these vulnerabilities before a fix is available. The urgency and potential impact of zero-day exploits make them a critical concern in cybersecurity, requiring immediate attention to protect systems and data from compromise. Zero-day vulnerabilities are a favored target for sophisticated cyberattacks, including espionage and cyber warfare.</p>
          </div>
          <p>The Log4j library allows data logging from many sources, including untrusted data from users. The vulnerability arose from improper input validation, enabling crafted requests to trigger malicious Java code execution on the server. Attackers could send payloads over the internet, SMS, and chat apps. When such untrusted inputs were innocently written to Log4j, it could allow remote code execution, allowing the attacker to gain full shell access to the server—thus the name Log4Shell.</p>
          <section data-pdf-bookmark="Impact " data-type="sect3"><div class="sect3" id="impact_idXFMZiD">
            <h3>Impact </h3>
            <p>Due to Log4j’s ubiquitous use, Log4Shell’s impact was massive. Within days of the disclosure, millions of internet-facing systems were nefariously scanned for the flaw. Successful exploits surged, with botnets, cryptominers, ransomware groups, and state-sponsored hackers all leveraging Log4Shell. </p>
            <p>Consequences included:</p>
            <ul>
              <li>
                <p>Data theft from compromised servers</p>
              </li>
              <li>
                <p>Installation of malware, backdoors, and cryptominers</p>
              </li>
              <li>
                <p>Ransomware attacks shutting down operations</p>
              </li>
              <li>
                <p>Cascading supply chain breaches as access opened networks of partners</p>
              </li>
              <li>
                <p>Burdensome, urgent, out-of-cycle patching exercises across cloud and on-prem infrastructure</p>
              </li>
            </ul>
          </div></section>
          <section data-pdf-bookmark="Lessons learned" data-type="sect3"><div class="sect3" id="lessons_learned_7">
            <h3>Lessons learned</h3>
            <p> Log4Shell carries several key lessons:</p>
            <ul>
              <li>
                <p>Open source components can pose massive systemic risks despite their benefits.</p>
              </li>
              <li>
                <p>More attention is needed to input validation and security hygiene in libraries.</p>
              </li>
              <li>
                <p>More importance needs to be paid to rapid coordination and disclosure of vulnerabilities.</p>
              </li>
              <li>
                <p>A software bill of materials can aid in understanding component risks.</p>
              </li>
              <li>
                <p>Suppliers should assume breaches and hunt for intrusions rather than just preventing exploits.</p>
              </li>
            </ul>
            <p>The scale of the Log4Shell fallout showed just how much interconnectedness amplifies supply chain threats. In the aftermath, software integrity and knowing the provenance of components have become vital to managing risk<a contenteditable="false" data-primary="" data-startref="ch09.html7" data-type="indexterm" id="id531"/><a contenteditable="false" data-primary="" data-startref="ch09.html6" data-type="indexterm" id="id532"/>.<a contenteditable="false" data-primary="" data-startref="ch09.html1" data-type="indexterm" id="id533"/></p>
          </div></section>
        </div></section>
      </div></section>
      <section data-pdf-bookmark="Understanding the LLM Supply Chain" data-type="sect1"><div class="sect1" id="understanding_the_llm_supply_chain">
        <h1>Understanding the LLM Supply Chain</h1>
        <p><a contenteditable="false" data-primary="supply chains (for LLM application development)" data-secondary="understanding" data-type="indexterm" id="ch09.html8"/>Now that you’re familiar with the basics of supply chain security and have seen classic examples of the price of failure to manage it correctly, let’s look into what makes the LLM software supply chain unique. The distinctiveness of LLM supply chains primarily stems from their reliance on massive and diverse datasets for training and their often intricate interplay with various external data sources and services.</p>
        <p>Integrating a third-party foundation model introduces a critical dependency into your application’s supply chain. This dependency extends beyond just the software component; it also encompasses the data used in the model’s development. Keeping track of updates, patches, and changes to the model becomes crucial, as they can significantly affect your application’s performance and security. Even if you start from a pretrained foundation model, you may decide to fine-tune the model. In this case, you’ll need to consider any training data you use in your supply chain.</p>
        <p>LLMs, especially those using techniques like RAG, frequently interact with external APIs, databases, and online resources. This integration is pivotal for models to access real-time information or specific datasets necessary for certain applications. However, it also opens up additional vectors for potential security vulnerabilities, data privacy concerns, and compliance issues. Ensuring secure and ethical integration with these external systems is another critical aspect of LLM supply chain management.</p>
        <p>To understand the landscape better, let’s look at some examples of LLM-specific supply chain risks.</p>
        <section data-pdf-bookmark="Open Source Model Risk" data-type="sect2"><div class="sect2" id="open_source_model_risk">
          <h2>Open Source Model Risk</h2>
          <p><a contenteditable="false" data-primary="open source model risk" data-type="indexterm" id="ch09.html9"/><a contenteditable="false" data-primary="supply chains (for LLM application development)" data-secondary="understanding" data-tertiary="open source model risk" data-type="indexterm" id="ch09.html10"/>While many development teams choose to use a proprietary, hosted LLM foundation model such as OpenAI’s GPT series, more and more teams are experimenting with open source foundation models. If you choose to manage and host a model, the version and configuration of your model must be tracked as part of your supply chain. Recent events have shown that the supply chain for open source model software is highly immature and could leave users open to accidentally acquiring models tainted by malicious actors. Let’s look at how this might happen so you can understand the risk.</p>
          <div data-type="note" epub:type="note"><h6>Note</h6>
            <p>As of this writing, the most popular place to exchange LLM models is called <a href="https://huggingface.co">Hugging Face</a>. It describes itself as “The AI community building the future. The platform where the machine learning community collaborates on models, datasets, and applications.” </p>
          </div>
          <p>In 2023, multiple incidents related to Hugging Face raised the consciousness around blindly trusting models acquired from sites like this. In July 2023, the <a href="https://oreil.ly/iWC2X">Hugging Face Twitter account posted</a>, “We are looking into an incident where a malicious user took control over the Hub organizations of Meta/Facebook &amp; Intel via reused employee passwords that were compromised in a data breach on another site. We will keep you updated.” </p>
          <p>While the full impact of that incident remains unclear, it brought to light the possibility that a malicious actor could insert itself into the supply chain and change components thought to have come from a trusted source, in this case Meta or Intel. It triggered an expanded set of serious discussions in the AI community about supply chain security.</p>
          <p>While that first incident wasn’t widely reported and seemed isolated, in December 2023, the team at Lasso Security published research showing that over 1,600 Hugging Face API tokens were exposed. The team could use these tokens to access the Hugging Face accounts of over 700 organizations, including major players such as Meta, Microsoft, Google, and VMware. This demonstrated a clear risk that a malicious third party could swap a well-known, well-trusted model for one with its own modifications—a massive risk to any application that might download and use such a model.</p>
          <div data-type="warning" epub:type="warning"><h6>Warning</h6>
            <p>Pickle, commonly used for serialization in machine learning, is the default format for model weights in the popular PyTorch ML toolkit. Hugging Face’s documentation warns that loading tainted Pickle files could lead to arbitrary code execution attacks. To address these vulnerabilities, Hugging Face is developing a project called Safetensors. This project is in its early stages, but is an important development to follow to enhance your security posture. </p>
          </div>
          <p>While this was a case of an ethical hacker research group responsibly disclosing this risk, this incident further cements the idea that the supply chain for models is crucial. Later in this chapter, we’ll discuss how to track the source and provenance of your models so that if issues come to light, you are prepared to handle them quickly.<a contenteditable="false" data-primary="" data-startref="ch09.html10" data-type="indexterm" id="id534"/><a contenteditable="false" data-primary="" data-startref="ch09.html9" data-type="indexterm" id="id535"/></p>
        </div></section>
        <section data-pdf-bookmark="Training Data Poisoning" data-type="sect2"><div class="sect2" id="training_data_poisoning">
          <h2>Training Data Poisoning</h2>
          <p><a contenteditable="false" data-primary="data poisoning" data-type="indexterm" id="id536"/><a contenteditable="false" data-primary="supply chains (for LLM application development)" data-secondary="understanding" data-tertiary="training data poisoning" data-type="indexterm" id="id537"/><a contenteditable="false" data-primary="training data" data-secondary="data poisoning" data-type="indexterm" id="id538"/><em>Data poisoning</em> is a manipulation of training data that can introduce vulnerabilities into an LLM. This can be done in various ways, such as injecting falsified information, biasing the data, or creating adversarial examples. Data poisoning aims to make the LLM produce inaccurate or harmful outputs.</p>
          <p>Training data poisoning is a topic that’s been studied in AI circles for many years. Classic examples have involved repeated attempts by spammers to poison the data used to train Google’s Gmail spam filters. More recently, research has shown this can be a big issue for any LLM application. In early 2023, <a href="https://oreil.ly/J2fMz">researchers from Google, ETH Zurich, Nvidia, and Robust Intelligence</a> showed that for as little as $60, the researchers could insert data into resources like Wikipedia that could influence training results even against such internet-scale resources. </p>
          <p>The Hugging Face API token leak mentioned in the last section exposed models and datasets. Hugging Face hosts over 250,000 prebuilt datasets that developers can use to train or fine-tune their models, and those datasets are targets for manipulation in the same way as models. That means managing datasets you use for fine-tuning is as important as tracking your foundation model.</p>
        </div></section>
        <section data-pdf-bookmark="Accidentally Unsafe Training Data" data-type="sect2"><div class="sect2" id="accidentally_unsafe_training_data">
          <h2>Accidentally Unsafe Training Data</h2>
          <p><a contenteditable="false" data-primary="accidentally unsafe training data" data-type="indexterm" id="id539"/><a contenteditable="false" data-primary="supply chains (for LLM application development)" data-secondary="understanding" data-tertiary="accidentally unsafe training data" data-type="indexterm" id="id540"/><a contenteditable="false" data-primary="training data" data-secondary="accidentally unsafe data" data-type="indexterm" id="id541"/>While data poisoning implies that a malicious actor is actively working to contaminate your model, it’s quite possible this could happen by mistake, especially with training datasets distilled from public internet sources.</p>
          <p>We talked about the idea that your model could “know too much” in <a data-type="xref" href="ch05.html#can_your_llm_know_too_much">Chapter 5</a>. In those cases, we looked at the possibility of the model regurgitating information on which it was trained or to which it had access. In December 2023, researchers from Stanford University showed that a highly popular dataset (LAION-5B) used to train image generation algorithms such as Stable Diffusion contained over three thousand images related to “child sexual abuse material.” </p>
          <p>This example sent developers of AI image generation tools scrambling to determine if their models used this training data and what impact that might have on their applications. If a development team for a particular application hadn’t carefully documented the training data they’d used, they wouldn’t know if they were exposed to risks that their models could generate inappropriate and illegal images.</p>
        </div></section>
        <section data-pdf-bookmark="Unsafe Plug-ins" data-type="sect2"><div class="sect2" id="unsafe_plug_ins">
          <h2>Unsafe Plug-ins</h2>
          <p><a contenteditable="false" data-primary="plug-ins, unsafe" data-type="indexterm" id="id542"/><a contenteditable="false" data-primary="supply chains (for LLM application development)" data-secondary="understanding" data-tertiary="unsafe plug-ins" data-type="indexterm" id="id543"/>In March 2023, OpenAI introduced a significant expansion of functionality to its platform through plug-ins. These plug-ins brought in functionalities from third-party providers including Expedia, Zillow, Kayak, Instacart, and OpenTable, enabling users to perform diverse tasks such as job searching, real estate listing, product recommendations, shopping, gaming, and recipe retrieval. This expansion dramatically enhanced the utility and user engagement on the platform.</p>
          <p>However, this innovation was not without its risks. Researchers quickly identified security concerns, such as the potential for using plug-ins as vectors for injecting malicious code into ChatGPT sessions. Such vulnerabilities could lead to severe consequences, including data theft, malware installation, or even full control over a user’s computer.</p>
          <p>Additionally, there was the risk of plug-ins being used for unauthorized data collection. A plug-in, for instance, could track a user’s browsing activities or record conversations with ChatGPT without the user’s knowledge or consent, raising significant privacy concerns.</p>
          <p>Creating a secure plug-in architecture is a complex and challenging task. If your application leverages plug-ins, tracking their sources and versions meticulously is crucial. Ensuring the security of these third-party components involves continuous monitoring for vulnerabilities, regular updates, and comprehensive security audits. This vigilance is vital to safeguard against potential security breaches and maintain the users’ trust and safety.<a contenteditable="false" data-primary="" data-startref="ch09.html8" data-type="indexterm" id="id544"/> </p>
        </div></section>
      </div></section>
      <section data-pdf-bookmark="Creating Artifacts to Track Your Supply Chain" data-type="sect1"><div class="sect1" id="creating_artifacts_to_track_your_supply_chain">
        <h1>Creating Artifacts to Track Your Supply Chain</h1>
        <p><a contenteditable="false" data-primary="supply chains (for LLM application development)" data-secondary="artifacts for tracking" data-type="indexterm" id="ch09.html11"/>As we’ve seen, tracking the components that go into your application is critical. The Equifax, SolarWinds, and Log4Shell examples we saw earlier in the chapter drove forward the importance of software supply chain security and led to the idea that you must track any artifacts going into your software. In particular, they gave rise to the popularity of the software bill of materials (SBOM). In this chapter, we’ll review the concept of SBOMs, and also related artifacts such as model cards and ML-BOMs that will be important to our LLM supply chain.</p>
        <section data-pdf-bookmark="Importance of SBOMs" data-type="sect2"><div class="sect2" id="importance_of_sboms">
          <h2>Importance of SBOMs</h2>
          <p><a contenteditable="false" data-primary="artifacts tracking, for supply chains" data-secondary="SBOMs" data-type="indexterm" id="id545"/><a contenteditable="false" data-primary="software bill of materials (SBOM)" data-type="indexterm" id="id546"/>A <em>software bill of materials</em> is a comprehensive inventory or a detailed list of all components, libraries, and modules that comprise a piece of software. Think of it as a manifest or an ingredient list for software, detailing every element in the final product. This includes code written by the software development team and any open source or third-party components integrated into the software. </p>
          <div data-type="note" epub:type="note"><h6>Note</h6>
            <p>The software bill of materials derives from the manufacturing term “bill of materials” (BOM), a comprehensive inventory that lists all the materials, components, and sub-assemblies needed to manufacture a product. It typically includes part names, numbers, quantities, and other descriptive information.</p>
          </div>
          <p>The purpose of an SBOM is to provide clear visibility into the software’s composition, which is crucial for security, compliance, and management. By understanding precisely what’s in their software, organizations can better monitor for vulnerabilities, comply with legal and licensing requirements, and manage updates and patches more effectively. In supply chain security, an SBOM is a vital tool for identifying potential risks and ensuring the integrity of software components.</p>
          <p>The information tracking in your SBOM is essential for rapid response and remediation, reducing the window of opportunity for attackers. Furthermore, an SBOM helps your company comply with security standards and regulations, as it provides proof of due diligence in using secure and licensed components. In the increasingly complex software development landscape, where dependencies are deeply intertwined, an SBOM acts as a map, guiding the way to a more secure and resilient software <span class="keep-together">infrastructure.</span></p>
          <p>Let’s see how we might apply and extend SBOM concepts to our LLM models and applications.</p>
        </div></section>
        <section data-pdf-bookmark="Model Cards" data-type="sect2"><div class="sect2" id="model_cards">
          <h2>Model Cards</h2>
          <p><a contenteditable="false" data-primary="artifacts tracking, for supply chains" data-secondary="model cards" data-type="indexterm" id="ch09.html12"/><a contenteditable="false" data-primary="model cards" data-secondary="in supply chains" data-type="indexterm" id="ch09.html13"/><a contenteditable="false" data-primary="supply chains (for LLM application development)" data-secondary="artifacts for tracking" data-tertiary="model cards" data-type="indexterm" id="ch09.html14"/>Earlier in this chapter, we learned that Hugging Face has become the de facto place to trade machine learning models and training sets. With a need to track important model information and dependencies, the company developed a standardized artifact called a <em>model card</em>.</p>
          <p>Hugging Face’s model cards are designed to provide comprehensive information about each AI model hosted on its platform. The goal is to offer users—whether developers, researchers, or end users—a clear understanding of a model’s capabilities, limitations, and intended use cases. This approach aligns with broader efforts in the AI community to ensure that AI models are used ethically and effectively.</p>
          <p>Here are some key aspects of Hugging Face model cards:</p>
          <dl>
            <dt>Model description</dt>
            <dd>
              <p>Each model card typically starts with a description of the model, including its purpose, architecture, and training data. This gives users a high-level understanding of what the model is designed to do and how it works.</p>
            </dd>
            <dt>Training data</dt>
            <dd>
              <p><a contenteditable="false" data-primary="training data" data-secondary="Hugging Face model cards and" data-type="indexterm" id="id547"/>The model cards often detail the datasets used to train the model. Understanding the model’s potential biases and limitations is crucial, as the nature of the training data can significantly influence the model’s performance and behavior.</p>
            </dd>
            <dt>Intended use</dt>
            <dd>
              <p>Model cards include information about the model’s intended use, which helps users understand the contexts in which the model is expected to perform well. This section may also include recommendations or guidelines for use.</p>
            </dd>
            <dt>Ethical considerations</dt>
            <dd>
              <p>Many model cards address ethical considerations, such as potential biases in the model and the impact of its deployment on various stakeholders. This reflects a growing recognition of the need to consider the broader societal and sustainability implications of AI technologies.</p>
            </dd>
            <dt>Performance metrics</dt>
            <dd>
              <p>The cards often include various performance metrics to show users how well the model performs. These metrics are typically based on the model’s performance on benchmark datasets or specific tasks for which it is designed.</p>
            </dd>
            <dt>Limitations</dt>
            <dd>
              <p>A critical component of model cards is a discussion of the model’s limitations. This includes areas where the model may not perform as expected, potential risks in certain applications, or areas where the model should be used with caution.</p>
            </dd>
            <dt>Usage examples and tutorials</dt>
            <dd>
              <p>Many model cards provide examples of using the model, along with code snippets or links to notebooks. This is particularly helpful for developers who want to integrate the model into their applications.</p>
            </dd>
          </dl>
          <div data-type="note" epub:type="note"><h6>Note</h6>
            <p>Other LLM vendors, such as AWS, have started developing their own model card formats. There will be fragmentation in this space, so you’ll want to consider which to use for a given project. However, conceptually, you should find them similar to what’s discussed here.<a contenteditable="false" data-primary="" data-startref="ch09.html14" data-type="indexterm" id="id548"/><a contenteditable="false" data-primary="" data-startref="ch09.html13" data-type="indexterm" id="id549"/><a contenteditable="false" data-primary="" data-startref="ch09.html12" data-type="indexterm" id="id550"/></p>
          </div>
        </div></section>
        <section data-pdf-bookmark="Model Cards Versus SBOMs" data-type="sect2"><div class="sect2" id="model_cards_versus_sboms">
          <h2>Model Cards Versus SBOMs</h2>
          <p><a contenteditable="false" data-primary="artifacts tracking, for supply chains" data-secondary="model cards versus SBOMs" data-type="indexterm" id="ch09.html15"/><a contenteditable="false" data-primary="model cards" data-secondary="SBOMs versus" data-type="indexterm" id="ch09.html16"/><a contenteditable="false" data-primary="software bill of materials (SBOM)" data-secondary="model cards versus" data-type="indexterm" id="ch09.html17"/><a contenteditable="false" data-primary="supply chains (for LLM application development)" data-secondary="artifacts for tracking" data-tertiary="model cards versus SBOMS" data-type="indexterm" id="ch09.html18"/>Model cards and SBOMs are tools designed to increase transparency and understanding of complex software systems, including AI models. Still, they serve different purposes and contain different types of information.</p>
          <section data-pdf-bookmark="Purpose and focus" data-type="sect3"><div class="sect3" id="purpose_and_focus">
            <h3>Purpose and focus</h3>
            <p>The primary purpose of model cards is to provide a clear, understandable description of a machine learning model’s capabilities, behavior, and limitations. They focus on the performance, ethical considerations, use cases, and data used in training the model. Model cards are handy for end users and developers who need to understand an ML model’s operational characteristics and ethical implications.</p>
            <p>An SBOM is essentially a detailed inventory of all software product components. SBOMs focus on listing and detailing every piece of third-party and open source software included in a software product. They are critical for understanding the software’s composition, especially for tracking vulnerabilities, licenses, and dependencies. Note that AI-specific SBOMs are being developed; we’ll cover that later in the chapter.</p>
          </div></section>
          <section data-pdf-bookmark="Content" data-type="sect3"><div class="sect3" id="content_idKdXQ9s">
            <h3>Content</h3>
            <p>Model cards typically include information such as model architecture, training data, performance metrics, intended use, ethical considerations, and limitations. They might also provide insights into the model’s development process and any potential biases in the model.</p>
            <p>SBOMs contain detailed lists of every software component, version, patch status, licenses, and sometimes the origin of each component. This information is vital for vulnerability management, compliance checks, and software maintenance.</p>
          </div></section>
          <section data-pdf-bookmark="&#10;              Use in security and compliance&#10;            " data-type="sect3"><div class="sect3" id="use_in_security_and_compliance">
            <h3>
              Use in security and compliance
            </h3>
            <p>While they do not directly address security vulnerabilities, model cards can indirectly indicate the robustness and reliability of a model, which are crucial aspects of security in AI systems. They can also highlight ethical risks or biases that might have security implications.</p>
            <p>SBOMs are directly used in contexts of security and compliance. They are crucial for vulnerability management, as they allow security teams to quickly identify whether newly discovered vulnerabilities in third-party components impact their software. They are also used for license compliance and risk management.</p>
          </div></section>
          <section data-pdf-bookmark="&#10;              Industry application&#10;            " data-type="sect3"><div class="sect3" id="industry_application">
            <h3>
              Industry application
            </h3>
            <p>Model cards are specific to AI and machine learning and are part of the broader movement toward responsible AI.</p>
            <p>SBOMs are broadly applicable across all software development and are increasingly becoming a standard part of software documentation, especially in industries where security and compliance are paramount.<a contenteditable="false" data-primary="" data-startref="ch09.html18" data-type="indexterm" id="id551"/><a contenteditable="false" data-primary="" data-startref="ch09.html17" data-type="indexterm" id="id552"/><a contenteditable="false" data-primary="" data-startref="ch09.html16" data-type="indexterm" id="id553"/><a contenteditable="false" data-primary="" data-startref="ch09.html15" data-type="indexterm" id="id554"/></p>
          </div></section>
        </div></section>
        <section data-pdf-bookmark="CycloneDX: The SBOM Standard" data-type="sect2"><div class="sect2" id="cyclonedx_the_sbom_standard">
          <h2>CycloneDX: The SBOM Standard</h2>
          <p><a contenteditable="false" data-primary="artifacts tracking, for supply chains" data-secondary="CycloneDX" data-type="indexterm" id="id555"/><a contenteditable="false" data-primary="CycloneDX" data-type="indexterm" id="id556"/><a contenteditable="false" data-primary="software bill of materials (SBOM)" data-secondary="CycloneDX" data-type="indexterm" id="id557"/><a contenteditable="false" data-primary="supply chains (for LLM application development)" data-secondary="artifacts for tracking" data-tertiary="CycloneDX" data-type="indexterm" id="id558"/>CycloneDX, managed by the OWASP Foundation, has become the most powerful standard for SBOMs. It’s a standardized format that offers a structured, machine-readable inventory of all software components in a project or system, complete with details about their relationships and dependencies. Think of CycloneDX as a comprehensive ingredient list for software, but far more detailed and insightful.</p>
          <p>The creation of CycloneDX was driven by the need for transparency and security in the increasingly complex web of software dependencies. This complexity posed significant security and compliance challenges. By clearly outlining software composition, CycloneDX enhances the ability to identify vulnerabilities and manage risks effectively. Another pivotal factor in its development was the need for standardization. Before CycloneDX, the diversity of SBOM formats used by different tools hindered sharing and interoperability. CycloneDX addresses this by providing a unified language for describing software components, fostering seamless integration across various tools and platforms.</p>
          <p>As an open source project under the stewardship of OWASP, CycloneDX benefits from a community-driven approach. This ensures that it continually evolves to meet the industry’s changing needs and remains accessible to everyone. A clear understanding of your system’s software components is paramount for effective vulnerability management and patching. CycloneDX simplifies the process of identifying and addressing vulnerabilities, thus bolstering the overall security posture. </p>
          <p>From a compliance perspective, especially with regulations like the US Executive Order on Improving the Nation’s Cybersecurity mandating SBOMs for government software, CycloneDX is instrumental in meeting these requirements. Additionally, CycloneDX plays a crucial role in license management by storing license information for each component, helping organizations comply with software licenses and avoid legal entanglements.</p>
          <p>Incorporating CycloneDX into DevOps and continuous integration processes automates SBOM generation, providing ongoing insights into software composition throughout the development lifecycle. This integration enhances transparency and fosters trust among users or customers when organizations share their CycloneDX SBOMs.</p>
        </div></section>
        <section data-pdf-bookmark="The Rise of the ML-BOM" data-type="sect2"><div class="sect2" id="the_rise_of_the_ml_bom">
          <h2>The Rise of the ML-BOM</h2>
          <p><a contenteditable="false" data-primary="artifacts tracking, for supply chains" data-secondary="ML-BOM" data-type="indexterm" id="ch09.html19"/><a contenteditable="false" data-primary="ML-BOMs" data-type="indexterm" id="ch09.html20"/><a contenteditable="false" data-primary="supply chains (for LLM application development)" data-secondary="artifacts for tracking" data-tertiary="ML-BOM" data-type="indexterm" id="ch09.html21"/>CycloneDX 1.5, <a contenteditable="false" data-primary="ML-BOMs" data-secondary="rise of" data-type="indexterm" id="ch09.html22"/>released in June 2023, represents a significant advancement in the CycloneDX standard. This update is particularly significant for applications using machine learning, such as LLM applications, introducing notable transparency, security, and compliance enhancements.</p>
          <p>A key innovation in CycloneDX 1.5 is the <em>ML-BOM</em> (machine learning bill of materials), a game changer for ML applications. This feature allows for the comprehensive listing of ML models, algorithms, datasets, training pipelines, and frameworks within an SBOM. It captures essential details such as model provenance, versioning, dependencies, and performance metrics, facilitating reproducibility, governance, risk assessment, and compliance for ML systems.</p>
          <p>In terms of transparency and understanding, the ML-BOM provides clear visibility into the components and processes involved in ML development and deployment. This helps stakeholders grasp the composition of ML systems, identify potential risks, and consider ethical implications. In the security domain, it enables the identification and remedying of vulnerabilities in ML components and dependencies. This feature is essential for conducting security audits and risk assessments, contributing significantly to developing secure and trustworthy ML systems.</p>
          <p>Compliance is another critical area where the ML-BOM has significant impact. It supports adherence to regulatory requirements, such as GDPR and CCPA, by ensuring transparency and governance of the system. This facility is crucial for compliance audits and to demonstrate responsible AI practices.</p>
          <p>Beyond these core areas, the ML-BOM offers additional benefits. It enhances reproducibility, allowing replication of experiments and results, which is vital for scientific rigor and trust in ML systems. Collaboration is also simplified, as the ML-BOM enables easier sharing and collaboration across teams and organizations on projects. Lastly, it is an effective tool for knowledge management, preserving critical information about systems for future maintenance, updates, and audits.</p>
          <p><a data-type="xref" href="#fig_1_the_cyclone_dx_1_5_object_model_by_owasp">Figure 9-1</a> shows the high-level object model defined by the spec. This shows the various fields and options, which should give you an idea of how entities and their properties are defined. This model will define the structure of the SBOM/ML-BOM documents you’ll be creating. In the next section, we’ll dive into an example of building a simple version of such a document for an LLM application.</p>
          <figure><div class="figure" id="fig_1_the_cyclone_dx_1_5_object_model_by_owasp">
            <img alt="" src="assets/dpls_0901.png"/>
            <h6><span class="label">Figure 9-1. </span>The CycloneDX 1.5 object model (by OWASP)</h6>
          </div></figure>
          <p>CycloneDX 1.5 will advance transparency, security, and compliance in developing and deploying ML applications. It empowers organizations to build more responsible, trustworthy, and secure AI systems.<a contenteditable="false" data-primary="" data-startref="ch09.html22" data-type="indexterm" id="id559"/></p>
        </div></section>
        <section data-pdf-bookmark="Building a Sample ML-BOM" data-type="sect2"><div class="sect2" id="building_a_sample_ml_bom">
          <h2>Building a Sample ML-BOM</h2>
          <p><a contenteditable="false" data-primary="ML-BOMs" data-secondary="building" data-type="indexterm" id="ch09.html23"/>In this section, we’ll use the CycloneDX standard to create a simple ML-BOM for a sample application. We will show how to represent the application’s pretrained foundation model and the dataset used to fine-tune the model for our application’s needs. </p>
          <p>As we saw in the last section, ML-BOM artifacts can be quite extensive! To give you an idea about how they work, we’ll create a simplified ML-BOM for an LLM-based application called Customer Service Bot. It is based on the <a href="https://oreil.ly/juffo">Mixtral-8x7B-v0.1 foundation model</a> downloaded from Hugging Face. The model was then fine-tuned using an open source dataset for customer service applications we grabbed from <a href="https://oreil.ly/sc5jT">GitHub</a>. <a data-type="xref" href="#table-9-1">Table 9-1</a> shows a simple ML-BOM covering just these components.</p>
          <table id="table-9-1">
            <caption><span class="label">Table 9-1. </span>Machine learning bill of materials (ML-BOM) for Customer Service Bot; BOM format: CycloneDX; spec version: 1.5; BOM version: 1</caption>
            <thead>
              <tr>
                <th/>
                <th>Application: Customer Service Bot</th>
                <th>Component: Customer Support LLM Chatbot Training Dataset</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Type</td>
                <td>Application</td>
                <td>Dataset</td>
              </tr>
              <tr>
                <td>Name</td>
                <td>Customer Service Bot</td>
                <td>Customer Support LLM Chatbot Training Dataset</td>
              </tr>
              <tr>
                <td>Version</td>
                <td>1.0.0</td>
                <td>1.0.0</td>
              </tr>
              <tr>
                <td>Description</td>
                <td>A customer service bot built for company XYZ</td>
                <td/>
              </tr>
              <tr>
                <td>Licenses</td>
                <td/>
                <td>ID: CDLA-Sharing-1.0<br/> Name: Apache 2.0<br/> URL: <a href="https://choosealicense.com/licenses/apache-2.0"><em class="hyperlink">https://choosealicense.com/licenses/apache-2.0</em></a></td>
              </tr>
              <tr>
                <td>External references</td>
                <td>VCS: <a href="https://huggingface.co/mistralai/Mixtral-8x7B-v0.1"><em class="hyperlink">https://huggingface.co/mistralai/Mixtral-8x7B-v0.1</em></a><br/> The Mixtral-8x7B LLM is a pretrained generative sparse mixture of experts.</td>
                <td>VCS:<br/> 
                <a href="https://github.com/bitext/customer-support-llm-chatbot-training-dataset"><em class="hyperlink">https://github.com/bitext/customer-support-llm-chatbot-training-dataset</em></a><br/> Bitext: Customer service tagged training dataset for LLM-based virtual assistants<br/> License file: <a href="https://github.com/bitext/customer-support-llm-chatbot-training-dataset/blob/main/LICENSE.txt"><em class="hyperlink">https://github.com/bitext/customer-support-llm-chatbot-training-dataset/blob/main/LICENSE.txt</em></a>; direct link to the license text for the dataset</td>
              </tr>
            </tbody>
          </table>
          <p>While this version of our ML-BOM is human readable, and thus illustrates the concepts, one of the significant features of an SBOM/ML-BOM is to have it be highly structured and machine readable. That’s why CycloneDX provides a standard JSON format for your BOM. Here’s what this would look like in JSON:</p>
            <pre data-type="programlisting">{
  "bomFormat": "CycloneDX",
  "specVersion": "1.5",
  "version": 1,
  "components": [
    {
      "type": "application",
      "name": "Customer Service Bot",
      "version": "1.0.0",
      "description": "A customer service bot built for company XYZ",
      "externalReferences": [
        {
          "type": "vcs",
          "url": "https://huggingface.co/mistralai/Mixtral-8x7B-v0.1"
        }
      ]
    },
    {
      "type": "dataset",
      "name": "Customer Support LLM Chatbot Training Dataset",
      "version": "1.0.0",
      "licenses": [
        {
          "license": {
            "name": "Apache 2.0",
            "url": "https://choosealicense.com/licenses/apache-2.0/"
          }
        }
      ],
      "externalReferences": [
        {
          "type": "vcs",
          "url": "https://github.com/bitext/customer-support-dataset"
        },
        {
          "type": "license",
          "url": "https://github.com/bitext/customer-support-dataset/LICENSE.txt"
        }
      ]
    }
  ]
}</pre>
          <p>The <code>dataset</code> section details the training data used for fine-tuning the model, pointing to the specific dataset on GitHub. It’s important to populate the <code>components</code> and <code>externalReferences</code> sections with accurate details about your specific use case, including any other dependencies, services, or training data used. </p>
          <p>In the ML-BOM, the tag VCS refers to a version control system. The URL provided is related to a version control repository where the component’s source code, model, or related data is managed and stored.</p>
          <p>To sum up, model cards and ML-BOMs share some similarities, but there is a substantial difference in their details, as summarized in <a data-type="xref" href="#table-9-2">Table 9-2</a>. You may need to use both in many situations until someone develops a single, comprehensive structure. </p>
          <table id="table-9-2">
            <caption><span class="label">Table 9-2. </span>Similarities and differences between model cards and ML-BOMs</caption>
            <thead>
              <tr>
                <th>Feature</th>
                <th>Model card</th>
                <th>ML-BOM</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Purpose</td>
                <td>Document an ML model’s ethical considerations, intended use, and performance</td>
                <td>List all components used in an ML system to manage and secure the application</td>
              </tr>
              <tr>
                <td>Components listed</td>
                <td>Model details, performance metrics, and ethical considerations</td>
                <td>ML models, algorithms, datasets, training pipelines, and frameworks</td>
              </tr>
              <tr>
                <td>Security details</td>
                <td>General ethical considerations and use case limitations</td>
                <td>Detailed security vulnerabilities, dependencies, and versioning</td>
              </tr>
              <tr>
                <td>Usage context</td>
                <td>Ethical and responsible AI development</td>
                <td>Securing ML applications throughout their lifecycle</td>
              </tr>
              <tr>
                <td>Focus on transparency</td>
                <td>High, with a focus on ethical transparency</td>
                <td>High, with a focus on security and compliance</td>
              </tr>
              <tr>
                <td>Legal and compliance</td>
                <td>Ethical usage guidelines</td>
                <td>Regulatory compliance, vulnerability management</td>
              </tr>
              <tr>
                <td>Integration in development lifecycle</td>
                <td>Primarily at model evaluation and deployment stages</td>
                <td>Throughout the entire development and deployment <a contenteditable="false" data-primary="" data-startref="ch09.html23" data-type="indexterm" id="id560"/>process<a contenteditable="false" data-primary="" data-startref="ch09.html21" data-type="indexterm" id="id561"/><a contenteditable="false" data-primary="" data-startref="ch09.html20" data-type="indexterm" id="id562"/><a contenteditable="false" data-primary="" data-startref="ch09.html19" data-type="indexterm" id="id563"/>.<a contenteditable="false" data-primary="" data-startref="ch09.html11" data-type="indexterm" id="id564"/></td>
              </tr>
            </tbody>
          </table>
        </div></section>
      </div></section>
      <section data-pdf-bookmark="The Future of LLM Supply Chain Security" data-type="sect1"><div class="sect1" id="the_future_of_llm_supply_chain_security">
        <h1>The Future of LLM Supply Chain Security</h1>
        <p><a contenteditable="false" data-primary="software supply chain security" data-type="indexterm" id="ch09.html24"/><a contenteditable="false" data-primary="supply chain management (for software)" data-type="indexterm" id="ch09.html25"/><a contenteditable="false" data-primary="supply chains (for LLM application development)" data-secondary="security" data-type="indexterm" id="ch09.html26"/>Supply chain security is a mature field for web applications, but is still relatively immature for AI and LLM applications. Given all the attention this area has attracted recently, I expect we’ll see a lot of innovation and expansion in the near future. To prepare you for that, this section will review some of the early movements in this area and point you to places to look for future enhancements and innovations in LLM supply chain security.</p>
        <section data-pdf-bookmark="Digital Signing and Watermarking" data-type="sect2"><div class="sect2" id="digital_signing_and_watermarking">
          <h2>Digital Signing and Watermarking</h2>
          <p><a contenteditable="false" data-primary="digital signing" data-type="indexterm" id="id565"/><a contenteditable="false" data-primary="supply chains (for LLM application development)" data-secondary="security" data-tertiary="digital signing/watermarking" data-type="indexterm" id="id566"/><a contenteditable="false" data-primary="watermarking" data-type="indexterm" id="id567"/>Establishing robust model authenticity and integrity methods has become critical as large language models proliferate. Validating that a model originated from the expected source and has not been tampered with is essential for accountability and security. Two primary techniques have emerged for this: digital signing and <span class="keep-together">watermarking.</span></p>
          <p><em>Digital signatures</em> allow the cryptographic signing of a model with a private key to mark it as authentic. Any party can then use the corresponding public key to verify that the signature matches the model, proving provenance and integrity. This technique is important for supply chain security as models are distributed or deployed through cloud services. Signing ensures models can be authenticated as they move between systems.</p>
          <p><em>Watermarking</em> embeds identifying information directly in the model’s weights or architecture. A watermark inserts a unique fingerprint that indicates the model’s origin by subtly altering parameters. Watermarks survive duplication, so cloned or stolen models still contain the markup, allowing detection with an extraction tool, which confirms that the watermark matches the expected signature for a model. Signatures validate origin and prevent tampering via cryptography. </p>
          <div data-type="tip"><h6>Tip</h6>
            <p>Because this technology evolves quickly, consider visiting the <a href="https://c2pa.org">Coalition for Content Provenance and Authenticity (C2PA)</a>, a leader in developing standards for content authenticity, for the latest resources and standards.</p>
          </div>
          <p>Both digital signing and watermarking should be techniques in your arsenal for securing LLMs. Together, these techniques can uniquely authenticate models throughout their lifecycle and use. As models grow more powerful, establishing authenticity and preventing interference becomes critical. Embedding signatures and watermarked fingerprints provides the needed controls for model integrity across supply chains. </p>
          <div data-type="tip"><h6>Tip</h6>
            <p>Some Google researchers have been promoting a combination of a tool called <a href="https://oreil.ly/9EX-q">Sigstore and a management framework called Supply-chain Levels for Software Artifacts (SLSA)</a> to sign and manage ML models. There aren’t many standardized approaches yet, so you may want to monitor how this combination evolves.</p>
          </div>
        </div></section>
        <section data-pdf-bookmark="Vulnerability Classifications and Databases" data-type="sect2"><div class="sect2" id="vulnerability_classifications_and_databases">
          <h2>Vulnerability Classifications and Databases</h2>
          <p><a contenteditable="false" data-primary="supply chains (for LLM application development)" data-secondary="security" data-tertiary="vulnerability classifications/databases" data-type="indexterm" id="ch09.html31"/><a contenteditable="false" data-primary="vulnerability databases" data-type="indexterm" id="ch09.html32"/><em>Vulnerability classifications</em> refer to categorizing security weaknesses in software components based on their characteristics, impact, and exploitability. These classifications provide a standardized framework for identifying and describing vulnerabilities, facilitating a common understanding among stakeholders. Examples include the Common Weakness Enumeration (CWE) for software weaknesses and the <span class="keep-together">Common Vulnerability</span> Scoring System (CVSS) for assessing the severity of security <span class="keep-together">vulnerabilities.</span></p>
          <p><a contenteditable="false" data-primary="vulnerability databases" data-secondary="defined" data-type="indexterm" id="id568"/>Vulnerability databases are essential repositories that gather and document identified vulnerabilities within software components. These databases are vital for monitoring and referencing known vulnerabilities, furnishing users with in-depth information, including descriptions of the vulnerability, its potential impact, suggested mitigation strategies, and related references. <a contenteditable="false" data-primary="National Vulnerability Database (NVD)" data-type="indexterm" id="id569"/>A notable example of such a database is the National Vulnerability Database (NVD), a comprehensive catalog of security vulnerabilities. <a contenteditable="false" data-primary="Common Vulnerabilities and Exposures (CVE) system" data-seealso="MITRE CVE" data-type="indexterm" id="id570"/>The NVD integrates with the Common Vulnerabilities and Exposures (CVE) system, providing each listed vulnerability with a unique CVE identifier that facilitates easy reference and cross-linking between databases. </p>
          <p>Vulnerability classifications and databases are crucial in supply chain security for several key reasons:</p>
          <dl>
            <dt>Identification and awareness</dt>
            <dd>
              <p>They provide a systematic way to identify and catalog known vulnerabilities in software components. This awareness is the first step in protecting against potential exploits.</p>
            </dd>
            <dt>Standardized communication</dt>
            <dd>
              <p>Vulnerability classifications offer a standardized language for describing security weaknesses, which is essential for clear communication among developers, security professionals, and other stakeholders.</p>
            </dd>
            <dt>Risk assessment and prioritization</dt>
            <dd>
              <p>By classifying vulnerabilities, organizations can assess their potential impact and prioritize mitigation efforts accordingly. This helps allocate resources more effectively to address the most critical vulnerabilities first.</p>
            </dd>
            <dt>Tracking and monitoring</dt>
            <dd>
              <p>Vulnerability databases enable organizations to continuously track new and existing vulnerabilities. Regularly monitoring these databases helps organizations stay updated with the latest security threats and take proactive measures.</p>
            </dd>
            <dt>Compliance and reporting</dt>
            <dd>
              <p>Many regulatory frameworks require organizations to manage known vulnerabilities effectively. Access to a comprehensive vulnerability database aids in compliance and can be critical for audit and reporting purposes.</p>
            </dd>
            <dt>Facilitating patch management</dt>
            <dd>
              <p>By keeping an up-to-date record of vulnerabilities, these databases help in the timely patching of software components, which is a critical aspect of maintaining secure systems.</p>
            </dd>
            <dt>Enhancing overall security posture</dt>
            <dd>
              <p>Regularly referring to vulnerability classifications and databases helps organizations develop a more robust security posture by enabling them to anticipate, prepare for, and respond to various security threats promptly and effectively.</p>
            </dd>
          </dl>
          <p>In the context of supply chain security, where various components and dependencies can introduce vulnerabilities, vulnerability classifications and databases are invaluable for maintaining the integrity and security of the entire chain.</p>
          <section data-pdf-bookmark="MITRE CVE" data-type="sect3"><div class="sect3" id="mitre_cve_iddlvkCO">
            <h3>MITRE CVE</h3>
            <p><a contenteditable="false" data-primary="MITRE CVE" data-type="indexterm" id="id571"/><a contenteditable="false" data-primary="vulnerability databases" data-secondary="MITRE CVE" data-type="indexterm" id="id572"/><em>MITRE.org</em> is the online presence of the MITRE Corporation, a not-for-profit organization that operates multiple federally funded research and development centers in the United States. MITRE’s work primarily supports various US government <span class="keep-together">agencies,</span> and its mission is to solve problems for a safer world. It manages the CVE program and has developed several key frameworks and models, such as the ATT&amp;CK framework, which provides a comprehensive matrix of tactics and techniques used by threat actors in cyberattacks.</p>
            <p>The MITRE CVE database is a public online repository of reported security vulnerabilities and exposures. It’s a linchpin in cybersecurity, serving as a reference point for identifying and classifying vulnerabilities in software and firmware.</p>
            <p>Here’s a breakdown of CVE’s key features:</p>
            <dl>
              <dt>Standardized identifiers</dt>
              <dd>
                <p>Each entry in the CVE database is uniquely identified by a CVE ID. This standardization enables security professionals and software developers to speak the same language when discussing security vulnerabilities.</p>
              </dd>
              <dt>Wide range of sources</dt>
              <dd>
                <p>The database includes vulnerabilities reported by vendors, researchers, and users. This broad source base ensures a comprehensive collection of known issues.</p>
              </dd>
              <dt>Detailed descriptions</dt>
              <dd>
                <p>Entries typically include detailed descriptions of the vulnerabilities, providing insights into how malicious actors might exploit them, their potential impact, and, sometimes, suggested mitigations.</p>
              </dd>
              <dt>Vulnerability scoring</dt>
              <dd>
                <p>Many CVE entries include a CVSS score, which gives a quantitative measure of the vulnerability’s severity and aids in prioritization for patching or mitigation.</p>
              </dd>
              <dt>Free and open access</dt>
              <dd>
                <p>The CVE database is accessible to everyone, promoting transparency and widespread vulnerability information sharing. This open approach is crucial for timely and effective responses to security threats.</p>
              </dd>
              <dt>Integration with other tools</dt>
              <dd>
                <p>The database is often integrated with various security tools and platforms, enhancing vulnerability management and threat assessment capabilities.</p>
              </dd>
            </dl>
            <p>The MITRE CVE database primarily focuses on software and firmware vulnerabilities, emphasizing traditional cybersecurity concerns like network security, application security, and operating system flaws. The database includes vulnerabilities in various software products and systems, including those you might use in AI or LLM applications, like server software, databases, and operating systems.</p>
            <p>However, the database wasn’t designed to capture vulnerabilities unique to AI systems or LLMs. AI-specific vulnerabilities often require a different approach than conventional software vulnerabilities.</p>
          </div></section>
          <section data-pdf-bookmark="MITRE ATLAS" data-type="sect3"><div class="sect3" id="mitre_atlas">
            <h3>MITRE ATLAS</h3>
            <p><a contenteditable="false" data-primary="MITRE ATLAS" data-type="indexterm" id="id573"/><a contenteditable="false" data-primary="vulnerability databases" data-secondary="MITRE ATLAS" data-type="indexterm" id="id574"/>MITRE ATLAS (Adversarial Threat Landscape for Artificial Intelligence Systems) is an initiative focused on the specific vulnerabilities and threats associated with AI systems, particularly in the context of national security. It represents a significant step toward understanding and mitigating the unique risks that AI technologies pose.</p>
            <p>Here are some important aspects of MITRE ATLAS:</p>
            <dl>
              <dt>Focus on AI security</dt>
              <dd>
                <p>Unlike traditional vulnerability databases like CVE, which cover a broad range of software and hardware vulnerabilities, ATLAS is dedicated exclusively to AI. ATLAS includes threats like adversarial attacks, where intentionally crafted inputs manipulate or deceive AI models.</p>
              </dd>
              <dt>Comprehensive threat modeling</dt>
              <dd>
                <p>ATLAS provides detailed models of potential adversarial tactics, techniques, and procedures (TTPs) specific to AI systems. This threat modeling is crucial for understanding how AI systems can be exploited and for developing robust defense mechanisms.</p>
              </dd>
              <dt>Collaborative effort</dt>
              <dd>
                <p>MITRE ATLAS is a collaborative effort involving various stakeholders in the AI and cybersecurity communities, including researchers, industry experts, and government agencies. This collaboration ensures diverse perspectives and expertise, which is vital for tackling complex AI security challenges.</p>
              </dd>
              <dt>Educational resource</dt>
              <dd>
                <p>ATLAS is an educational resource for AI and cybersecurity professionals. It offers insights into the nature of AI threats and guidance on protecting against them. This guidance is valuable for developing training programs and security protocols for AI systems.</p>
              </dd>
              <dt>Guidance for policy and standards</dt>
              <dd>
                <p>By providing a detailed understanding of AI threats, ATLAS can inform policymaking and the development of security standards for AI technologies. This is increasingly important as AI becomes more integral to critical infrastructures and national security.</p>
              </dd>
            </dl>
            <p>As of the writing of this book, there isn’t an authoritative source of AI or LLM-specific security incident or vulnerability information, despite several projects that have been started. In the coming years, we’ll see organizations like MITRE, OWASP, and Hugging Face push forward to create more standard classifications of AI and LLM vulnerabilities and allow for the creation or extension of databases to track vulnerabilities. The growth of such databases will be critical in maturing supply chain security for LLMs<a contenteditable="false" data-primary="" data-startref="ch09.html32" data-type="indexterm" id="id575"/><a contenteditable="false" data-primary="" data-startref="ch09.html31" data-type="indexterm" id="id576"/>.<a contenteditable="false" data-primary="" data-startref="ch09.html26" data-type="indexterm" id="id577"/><a contenteditable="false" data-primary="" data-startref="ch09.html25" data-type="indexterm" id="id578"/><a contenteditable="false" data-primary="" data-startref="ch09.html24" data-type="indexterm" id="id579"/></p>
          </div></section>
        </div></section>
      </div></section>
      <section data-pdf-bookmark="Conclusion" data-type="sect1"><div class="sect1" id="conclusion_8">
        <h1>Conclusion</h1>
        <p>Examples of real exploits of vulnerabilities, such as data poisoning, are far more challenging to find than other vulnerabilities like prompt injection. However, lessons learned from web software and a growing body of research specific to AI and LLMs tell us we must take supply chain security seriously in our LLM applications.</p>
        <p>Your models, training data, and even data you access via techniques such as RAG may all become part of your software supply chain. You should be careful to track each dependency so that you can quickly take action if vulnerabilities are discovered in your application’s supply chain. Consider using a standardized format such as <span class="keep-together">CycloneDX</span> to do this, as it will allow you to take advantage of the growing ecosystem of tooling around that standard.</p>
        <p>Lastly, watch developments in this space closely. Supply chain security challenges are the least understood but most complex to solve in the LLM vulnerabilities I’ve studied. Watch for developments in areas such as watermarking and digital signing to track the provenance of your assets. Also watch for how the ecosystem around LLM-specific vulnerability and incident tracking evolves, as this will give you access to far greater information resources over time.<a contenteditable="false" data-primary="" data-startref="ch09.html0" data-type="indexterm" id="id580"/></p>
      </div></section>
    </div></section></body></html>