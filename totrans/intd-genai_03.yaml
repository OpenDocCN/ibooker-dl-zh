- en: 4 The evolution of created content
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 4 创建内容的演变
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Creating and detecting synthetic media
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建和检测合成媒体
- en: Using generative AI for content creation
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用生成式AI进行内容创作
- en: Introducing the ongoing debates around the use of copyrighted content
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍关于使用版权内容的持续辩论
- en: In an image that was circulated widely on Twitter, Pope Francis is walking down
    a street, wearing a cross around his neck and his typical white zucchetto. More
    unusually, the octogenarian is sporting an eye-catching white puffer coat that
    bears a strong resemblance to one sold by the designer brand Balenciaga (for $3,350
    retail). The pope’s “drip,” or style, was the talk of the internet. The only problem?
    The image wasn’t real—it was created by a construction worker in Chicago, who
    was tripping on shrooms while using the AI image-generation tool Midjourney, and
    thought it would be funny to see Pope Francis dripped out [[1]](https://www.buzzfeednews.com/article/chrisstokelwalker/pope-puffy-jacket-ai-midjourney-image-creator-interview).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在推特上广泛传播的一张图片中，教皇方济各正在街道上行走，脖子上挂着十字架，戴着典型的白色罗马式便帽。更不寻常的是，这位八旬老人穿着一件引人注目的白色羽绒服，与设计师品牌巴尔曼加亚（Balenciaga）出售的款式非常相似（零售价3350美元）。教皇的“风格”，或者说造型，成为了互联网上的热门话题。唯一的问题是？这张图片并不是真实的——它是由一位在芝加哥的建筑工人创造的，他在使用AI图像生成工具Midjourney时吸食了蘑菇，并认为看到教皇方济各“风格化”出来会很有趣
    [[1]](https://www.buzzfeednews.com/article/chrisstokelwalker/pope-puffy-jacket-ai-midjourney-image-creator-interview)。
- en: Although the “Balenciaga Pope” meme was harmless fun, it fooled many users.
    Model and author Chrissy Teigen tweeted, “I thought the pope’s puffer jacket was
    real and didn’t give it a second thought. no way am I surviving the future of
    technology” [[2]](https://twitter.com/chrissyteigen/status/1639802312632975360).
    But the future of technology is here, and AI-generated media is quickly becoming
    indistinguishable from the forms it imitates. In this chapter, we’ll discuss the
    methods, risks, opportunities, and legal landscape of synthetic media, one of
    the foremost applications for LLMs and other types of generative AI.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管所谓的“巴尔曼加亚教皇”梗是无害的乐趣，但它欺骗了许多用户。模特和作者克里斯蒂·泰根（Chrissy Teigen）在推特上写道，“我以为教皇的羽绒服是真的，没有多想。我无法想象我会如何适应未来的技术”
    [[2]](https://twitter.com/chrissyteigen/status/1639802312632975360)。但技术的未来已经到来，AI生成的媒体正迅速变得与它模仿的形式难以区分。在本章中，我们将讨论合成媒体的方法、风险、机遇和法律环境，这是LLM和其他类型生成式AI的主要应用之一。
- en: The rise of synthetic media
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 合成媒体的出现
- en: Synthetic media, or more specifically, AI-generated media, is an umbrella term
    for content that has been created or altered with the help of AI. It’s sometimes
    used synonymously with “deepfake” visual technology, but synthetic content (as
    shown in figure 4.1) is much broader and can span text, image, video, voice, and
    data. The term *deepfak**e*—a portmanteau of “deep learning” and “fake”—was coined
    by a Reddit user in 2017 who used face-swapping technology to alter pornographic
    videos [[3]](https://mitsloan.mit.edu/ideas-made-to-matter/deepfakes-explained).
    Deepfakes narrowly refer to faking a particular person’s physical characteristics
    or voice, most often to “fake” others into believing an event happened.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 合成媒体，或更具体地说，AI生成的媒体，是一个涵盖使用AI创建或修改的内容的通用术语。它有时与“深度伪造”视觉技术同义，但合成内容（如图4.1所示）更为广泛，可以包括文本、图像、视频、声音和数据。术语*深度伪造*（deepfake）是由一位Reddit用户在2017年创造的，他使用面部交换技术修改了色情视频
    [[3]](https://mitsloan.mit.edu/ideas-made-to-matter/deepfakes-explained)。深度伪造狭义上指的是伪造某人的特定身体特征或声音，最常见的是“伪造”他人相信某个事件发生了。
- en: Synthetic media or, more specifically, AI-generated media, is an umbrella term
    for content that has been created or altered with the help of AI, which spans
    text, image, video, voice, and data.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 合成媒体，或更具体地说，AI生成的媒体，是一个涵盖使用AI创建或修改的内容的通用术语，它包括文本、图像、视频、声音和数据。
- en: '![](../../OEBPS/Images/CH04_F01_Dhamani.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH04_F01_Dhamani.png)'
- en: Figure 4.1 The landscape of synthetic media
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1 合成媒体景观
- en: Initially, deepfakes referred to a form of synthetic media in which a person
    in an image or video is replaced with someone else, but it has since expanded
    to include synthetic media applications, such as realistic-looking images of people
    who don’t exist, synthetic audio or video recordings that mimic a target, or targeted
    propaganda that resemble real news articles. Deepfakes have generally had a negative
    connotation, with prominent examples including a fake video of President Biden
    announcing a draft to send American soldiers to Ukraine (see [http://mng.bz/p1Q2](http://mng.bz/p1Q2));
    Mark Zuckerberg saying “whoever controls the data, controls the future” in an
    edited video (see [http://mng.bz/OPVo](http://mng.bz/OPVo)); or Donald Trump’s
    viral deepfake asking Belgium to exit the Paris climate agreement (see [http://mng.bz/YR8K](http://mng.bz/YR8K)).
    In fact, 9 out of 10 Americans believe that deepfakes could cause more harm than
    good [[4]](https://thesentinel.ai/media/Deepfakes%202020:%20The%20Tipping%20Point,%20Sentinel.pdf).
    As we’ll discuss, there are a number of potentially beneficial applications and
    use cases, so people in the space have been increasingly using the term *AI-generated
    media*, or *AI-generated synthetic media*, to move away from the negative connotation
    of the term *deepfakes*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，deepfakes指的是一种合成媒体形式，其中图像或视频中的人被替换成另一个人，但后来它已经扩展到包括合成媒体应用，如看起来真实但不存在的人的图像，模仿目标的合成音频或视频录制，或者类似于真实新闻文章的有针对性的宣传。deepfakes通常带有负面含义，突出的例子包括拜登总统宣布向乌克兰派遣美国士兵的虚假视频（见[http://mng.bz/p1Q2](http://mng.bz/p1Q2)）；马克·扎克伯格在编辑视频中声称“谁控制数据，谁就控制未来”（见[http://mng.bz/OPVo](http://mng.bz/OPVo)）；以及唐纳德·特朗普在病毒式deepfake中要求比利时退出巴黎气候协议（见[http://mng.bz/YR8K](http://mng.bz/YR8K)）。事实上，有9/10的美国人认为deepfakes可能带来的危害大于好处[[4]](https://thesentinel.ai/media/Deepfakes%202020:%20The%20Tipping%20Point,%20Sentinel.pdf)。正如我们将讨论的，有许多潜在的有益应用和用例，因此该领域的人们越来越多地使用术语*AI生成媒体*或*AI生成合成媒体*来摆脱*deepfakes*这一术语的负面含义。
- en: Popular techniques for creating synthetic media
  id: totrans-13
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建合成媒体的流行技术
- en: We’ve previously discussed how large language models (LLMs) are used to generate
    text. Here, we’ll explore two commonly used techniques to alter or create images
    and videos (since videos are just sequences of images). The first technique, autoencoders,
    uses neural networks to compress and decompress images. You may remember the encoder-decoder
    framework from chapter 1, where text is encoded into a numeric representation
    for use by the model and then decoded back into a readable output. Similarly,
    an image can be fed into an encoder, which creates a compressed version of the
    same file. This compressed version of the file, also referred to as latent features
    or latent representation, contains a set of patterns that represent the characteristics
    of the original image.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前讨论了如何使用大型语言模型（LLMs）生成文本。在这里，我们将探讨两种常用的技术来改变或创建图像和视频（因为视频只是图像的序列）。第一种技术，自编码器，使用神经网络来压缩和解压缩图像。你可能还记得第一章中提到的编码器-解码器框架，其中文本被编码成数字表示，以便模型使用，然后解码回可读的输出。同样，图像可以被输入到一个编码器中，它创建该文件的压缩版本。这个文件的压缩版本，也被称为潜在特征或潜在表示，包含一组代表原始图像特征的图案。
- en: Let’s say that we passed an image of someone’s face through the encoder. Then,
    the latent features could include facial characteristic patterns such as expression,
    face angle, skin tone, and so on. These features are then passed into a decoder,
    which reconstructs the image based on the latent features. Autoencoders are often
    used in face-swapping technology, where the same encoder is used to create latent
    features from both faces, and then separate decoders are used to create the images
    from the latent features to best rebuild the original image. In figure 4.2, the
    same encoder creates the latent representations of Original Face A and Original
    Face B. Then, the decoder trained to rebuild Face B is fed the facial latent features
    of Face A (same encoder) to generate a seamless blend of the two faces. For example,
    the decoder can map characteristics such as the eyes, nose, mouth, and lighting
    to mix the two faces.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们通过编码器传递了某人的面部图像。然后，潜在特征可能包括面部特征模式，如表情、面部角度、肤色等。这些特征随后被传递到一个解码器，解码器根据潜在特征重建图像。自动编码器通常用于人脸交换技术，其中相同的编码器用于从两个面部创建潜在特征，然后使用单独的解码器从潜在特征创建图像，以最好地重建原始图像。在图4.2中，相同的编码器创建了原始面部A和原始面部B的潜在表示。然后，训练用于重建面部B的解码器接收面部A（相同编码器）的面部潜在特征以生成两个面部的无缝融合。例如，解码器可以将眼睛、鼻子、嘴巴和照明等特征映射到混合两个面部。
- en: '![](../../OEBPS/Images/CH04_F02_Dhamani.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH04_F02_Dhamani.png)'
- en: Figure 4.2 Deepfake creation through the use of autoencoders with a single encoder
    and two decoders
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2 通过使用具有单个编码器和两个解码器的自动编码器进行深度伪造创建
- en: The second technique for generating synthetic media is Generative Adversarial
    Networks (GANs), which consist of two neural networks—a generator and a discriminator.
    For example, suppose there is a shop that buys authentic artworks that they later
    resell. But there is a criminal who sells fake artworks to make money. Initially,
    the criminal might make mistakes when trying to sell fake artworks, so the shop
    owner might be able to identify that it’s not an authentic artwork. Then, the
    criminal will likely learn what characteristics of the artwork the shop owner
    is looking at to determine if it’s real or not, so the criminal can use that knowledge
    to improve the process by which artworks can be sold as fake to eventually be
    successful. At the same time, when the shop owner accidentally buys and tries
    to resell some of the fake artworks, they would get feedback from customers or
    experts that some of their art pieces are counterfeit, so the shop owner also
    has to learn how to better distinguish between the fake and real artworks.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 生成合成媒体的第二种技术是生成对抗网络（GANs），它由两个神经网络组成——一个生成器和一个判别器。例如，假设有一个商店购买真艺术品，然后再次转售。但有一个犯罪分子出售假艺术品以赚钱。最初，犯罪分子在尝试出售假艺术品时可能会犯错误，所以店主可能能够识别出这不是真艺术品。然后，犯罪分子可能会学习店主在判断艺术品真伪时关注的特征，以便犯罪分子可以使用这些知识改进将艺术品作为假品出售的过程，最终取得成功。同时，当店主意外购买并尝试转售一些假艺术品时，他们将从客户或专家那里得到反馈，表明他们的一些艺术品是伪造的，因此店主也必须学习如何更好地区分假艺术品和真艺术品。
- en: As shown in figure 4.3, the goal of the criminal (generator) is to create fake
    artworks that are indistinguishable from real ones, while the goal of the shop
    owner (discriminator) is to be able to distinguish between real and fake artworks—this
    competitive feedback loop is the main idea behind GANs. The generator exists to
    create new data, such as images, and the discriminator verifies the authenticity
    of an image by comparing it to the training dataset to determine the difference
    between a fake and a real image. The ultimate goal of a generative network is
    to create images that are indistinguishable from authentic images.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 如图4.3所示，犯罪分子（生成器）的目标是创造出与真品无法区分的假艺术品，而店主（判别器）的目标是能够区分真伪艺术品——这种竞争性反馈循环是生成对抗网络（GANs）背后的主要思想。生成器存在是为了创建新的数据，例如图像，判别器通过将其与训练数据集进行比较来验证图像的真实性，以确定假图像和真图像之间的差异。生成网络的最终目标是创建与真品无法区分的图像。
- en: '![](../../OEBPS/Images/CH04_F03_Dhamani.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH04_F03_Dhamani.png)'
- en: Figure 4.3 Creation of GANs using a generator and discriminator
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3 使用生成器和判别器创建GANs
- en: The good and the bad of synthetic media
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 合成媒体的好与坏
- en: In Samsung NEXT’s “Synthetic Media Landscape” report, they argue that “this
    technology will transform the way we produce, consume, and distribute media.”
    They claim that synthetic media is the third evolutionary stage of media. The
    first, old media, made possible through broadcasting, enabled *mass distribution*
    for a select few through TV, radio, and print. The second, new media, made possible
    through the internet, enabled *democratized distribution* for everyone through
    social media. The third, synthetic media, made possible through AI and deep learning,
    will *democratize media creation* and creativity for everyone. Samsung’s report
    highlights an important point here—synthetic media will democratize content creation
    [[5]](https://www.syntheticmedialandscape.com/). Now, anyone can produce high-quality
    content at low costs. This could democratize small-scale creators who could use
    synthetic media technology in the image/video synthesis space to bring their imagination
    to life without access to large film budgets. As we’ll discuss in the next section,
    we believe that synthetic media will usher in a new wave of creativity and art.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在三星NEXT的“合成媒体景观”报告中，他们认为“这项技术将改变我们生产、消费和分发媒体的方式。”他们声称合成媒体是媒体的第三个进化阶段。第一个，旧媒体，通过广播实现，通过电视、广播和印刷为少数人提供了*大规模分发*的可能。第二个，新媒体，通过互联网实现，通过社交媒体为每个人提供了*民主化分发*的可能。第三个，合成媒体，通过人工智能和深度学习实现，将为每个人*民主化媒体创作*和创造力。三星的报告在这里强调了重要的一点——合成媒体将民主化内容创作[[5]](https://www.syntheticmedialandscape.com/)。现在，任何人都可以以低廉的成本制作高质量的内容。这可能会为使用合成媒体技术的小规模创作者提供民主化，他们可以在图像/视频合成空间中使用这项技术，将他们的想象力变为现实，而无需大电影预算。正如我们将在下一节讨论的，我们相信合成媒体将引领新一波的创造力和艺术。
- en: Another potential benefit of synthetic media is its ability to anonymize photos
    and videos to enhance privacy. In an HBO documentary about anti-gay and lesbian
    purges, *Welcome to Chechnya*, the film uses deepfake technology to guard the
    identities of the volunteers who told their stories to protect them from prosecution
    [[6]](https://www.nytimes.com/2020/07/01/movies/deepfakes-documentary-welcome-to-chechnya.xhtml).
    Similarly, we could also use synthetic media technology to anonymize our faces
    in images and videos on cameras in public spaces, retail stores, and social media
    accounts. Face anonymization can be used for privacy protection while preserving
    data utility.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个合成媒体的可能好处是它能够匿名化照片和视频以增强隐私。在HBO关于反同性恋和女同性恋清洗的纪录片《欢迎来到车臣》中，电影使用深度伪造技术来保护讲述故事以保护他们免受起诉的志愿者的身份[[6]](https://www.nytimes.com/2020/07/01/movies/deepfakes-documentary-welcome-to-chechnya.xhtml)。同样，我们也可以使用合成媒体技术来匿名化公共场所、零售店和社交媒体账户中的图像和视频中的我们的面孔。面部匿名化可以用于隐私保护，同时保留数据效用。
- en: 'On the other hand, AI-generated media can also be a cause for concern. We can
    use the same technology to generate content (text, video, image, or speech) that
    is adversarial in nature. Malicious actors can disseminate intentionally misleading
    and adversarial narratives, which can disrupt discourse, create divisions, and
    undermine our trust in scientific, social, political, and economic institutions.
    The phenomenon of “seeing is believing” can also enable altered or inauthentic
    images and videos to spread more quickly. In this vein, in an article titled,
    “Deep Fakes: A Looming Challenge for Privacy, Democracy, and Social Security,”
    researchers identify a notable danger that they have termed *the liar’s dividend*.
    Here, the idea is that as the general public becomes more aware of how convincingly
    synthetic media can be generated, they may become more skeptical of the authenticity
    of traditional real documentary evidence [[7]](https://doi.org/10.2139/ssrn.3213954).
    We’ll discuss dis/misinformation, and its implications on individuals and society,
    in detail in chapter 5\.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，AI生成的媒体也可能引起担忧。我们可以使用相同的技术生成具有对抗性的内容（文本、视频、图像或语音）。恶意行为者可以传播故意误导和对抗性的叙述，这可能会破坏话语，造成分裂，并削弱我们对科学、社会、政治和经济机构的信任。现象“眼见为实”也可能使篡改或非真实的图像和视频传播得更快。在这方面，在一篇题为“深度伪造：对隐私、民主和社会安全的潜在挑战”的文章中，研究人员确定了一个他们称之为*说谎者的红利*的显著危险。在这里，想法是随着公众越来越意识到合成媒体可以多么令人信服地生成，他们可能会对传统真实纪录片证据的真实性更加怀疑[[7]](https://doi.org/10.2139/ssrn.3213954)。我们将在第5章详细讨论虚假/错误信息及其对个人和社会的影响。
- en: Synthetic media has also infamously been used for celebrity pornographic videos,
    revenge porn or cybersexual harassment, and fraud and espionage. Deepfakes can
    be used to impersonate an authorized decision-maker for financial transactions
    and various cybersecurity problems, such as showing an executive committing a
    crime or creating fake financial statements. Finally, celebrities can also be
    synthetically generated for brand advertisements, which can result in a loss of
    intellectual property (IP) revenue. Later in this chapter, we’ll talk about IP
    and copyright problems related to LLMs.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 合成媒体也臭名昭著地被用于名人色情视频、报复色情或网络性骚扰、欺诈和间谍活动。深度伪造可以用来冒充授权决策者进行金融交易和多种网络安全问题，例如展示高管犯罪或创建虚假财务报表。最后，名人也可以通过合成方式生成用于品牌广告，这可能导致知识产权（IP）收入的损失。在本章的后面部分，我们将讨论与LLMs相关的IP和版权问题。
- en: 'AI or genuine: Detecting synthetic media'
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AI还是真实：检测合成媒体
- en: There are various ongoing efforts to detect AI-generated media. In early 2023,
    OpenAI released a work-in-progress classifier to distinguish between machine-generated
    and human-written text to help mitigate concerns about running automated misinformation
    campaigns, among other problems. They acknowledged that their “classifier is not
    fully reliable” by correctly identifying AI-written text 26% of the time (true
    positives) and incorrectly labeling the human-written text as AI-written text
    9% of the time (false positives). As of July 20, 2023, the classifier was taken
    down due to its low accuracy rate [[8]](https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 目前有各种正在进行中的努力来检测AI生成的媒体。2023年初，OpenAI发布了一个正在开发中的分类器，用于区分机器生成文本和人工撰写的文本，以帮助缓解关于运行自动化虚假信息运动等问题的担忧。他们承认他们的“分类器并不完全可靠”，因为在26%的时间里正确地识别了AI撰写的文本（真阳性）和9%的时间里错误地将人工撰写的文本标记为AI撰写的文本（假阳性）。截至2023年7月20日，由于准确率低，该分类器已被下线
    [[8]](https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text)。
- en: Researchers have explored various techniques to detect machine-generated or
    manipulated images, videos, and speech, including digital, physical, and semantic
    analysis. In the Media Forensics (MediFor) program from the Defense Advanced Research
    Projects Agency (DARPA), researchers produced manipulation indicators by looking
    for inconsistencies in pixel representation and the physical environment, in combination
    with the semantic interpretation of the media [[9]](https://www.darpa.mil/program/media-forensics).
    Are there any pixel-level errors? That is, are there blurred edges or replicated
    pixels? For the physical environment, they look to see if the laws of physics
    are violated—are the shadows, reflections, lighting, and so on consistent with
    the laws of nature? Finally, they look at semantic integrity, which helps determine
    if the contextual information related to the piece of content is contradictory
    or inconsistent. So, they look for whether the image has been placed out of context
    or repurposed, and whether there are any date and time inaccuracies [[10]](https://www.youtube.com/watch?v=Crfm3vGoBsM).
    This program was followed by DARPA’s Semantic Forensics (SemaFor) with the goal
    of not only detecting manipulated media but also characterizing if the media was
    generated or manipulated for malicious purposes, and attributing the origination
    of the content to an individual or organization [[11]](https://www.darpa.mil/news-events/2021-03-02).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员已经探索了各种技术来检测机器生成的或被操纵的图像、视频和语音，包括数字、物理和语义分析。在国防高级研究计划局（DARPA）的媒体取证（MediFor）项目中，研究人员通过寻找像素表示和物理环境中的不一致性，结合对媒体内容的语义解释来产生操纵指标
    [[9]](https://www.darpa.mil/program/media-forensics)。是否存在像素级别的错误？也就是说，是否存在模糊的边缘或重复的像素？对于物理环境，他们检查物理定律是否被违反——阴影、反射、照明等是否与自然定律一致？最后，他们检查语义完整性，这有助于确定与内容相关的上下文信息是否矛盾或不一致。因此，他们检查图像是否被置于不相关的上下文中或被重新利用，以及是否存在任何日期和时间不准确的情况
    [[10]](https://www.youtube.com/watch?v=Crfm3vGoBsM)。此项目之后，DARPA的语义取证（SemaFor）项目旨在不仅检测被操纵的媒体，而且还确定媒体是否是为了恶意目的而生成或操纵的，并将内容的来源归因于个人或组织
    [[11]](https://www.darpa.mil/news-events/2021-03-02)。
- en: Similarly, there have been numerous studies on detecting face swapping by analyzing
    photo response nonuniformity (PRNU) [[12]](https://www.researchgate.net/profile/Zeno-Geradts/publication/329814168_Detection_of_Deepfake_Video_Manipulation/links/5c1bdf7da6fdccfc705da03e/Detection-of-Deepfake-Video-Manipulation.pdf)
    and inconsistent artifacts in images and videos, such as facial characteristics
    or physiological signals [[13]](https://arxiv.org/pdf/1806.02877.pdf) and image
    quality [[14]](https://ieeexplore.ieee.org/abstract/document/8987375). These techniques
    are promising but often limited, with solutions consisting of only detecting facial
    manipulations in a curated dataset. One study showed that entire generated faces
    can be detected via irregular pupil shapes, but the assumption of pupil shape
    regularity doesn’t always hold [[15]](https://arxiv.org/pdf/2109.00162.pdf). Other
    techniques to detect deepfakes include physiological analysis in videos to estimate
    whether the individual’s breathing and heart rate are normal [[16]](https://doi.org/10.1007/978-3-030-87664-7_12),
    and biometric analysis to analyze a specific individual’s mannerisms, including
    movement and style of speech, which can then be compared to distinguish fake from
    real [[17]](https://doi.org/10.3390/jimaging9010018). Biometric analysis has also
    been applied to deepfake audio detection, where audio analysis has proven to be
    effective in detecting deepfakes [[18]](https://arxiv.org/pdf/2209.14098.pdf).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，已有许多研究通过分析照片响应非均匀性（PRNU）[[12]](https://www.researchgate.net/profile/Zeno-Geradts/publication/329814168_Detection_of_Deepfake_Video_Manipulation/links/5c1bdf7da6fdccfc705da03e/Detection-of-Deepfake-Video-Manipulation.pdf)以及图像和视频中的不一致性伪影，如面部特征或生理信号[[13]](https://arxiv.org/pdf/1806.02877.pdf)和图像质量[[14]](https://ieeexplore.ieee.org/abstract/document/8987375)。这些技术很有前景，但通常有限，解决方案仅限于在精选数据集中检测面部操纵。一项研究表明，可以通过不规则的眼瞳形状检测整个生成的面部，但眼瞳形状规则性的假设并不总是成立[[15]](https://arxiv.org/pdf/2109.00162.pdf)。其他检测深度伪造的技术包括在视频中进行生理分析以估计个体的呼吸和心率是否正常[[16]](https://doi.org/10.1007/978-3-030-87664-7_12)，以及生物识别分析来分析特定个体的行为方式，包括动作和说话风格，然后可以将其与真实情况进行比较以区分伪造和真实[[17]](https://doi.org/10.3390/jimaging9010018)。生物识别分析也应用于深度伪造音频检测，其中音频分析已被证明在检测深度伪造方面非常有效[[18]](https://arxiv.org/pdf/2209.14098.pdf)。
- en: Because of their adversarial nature, no single magic bullet can detect *all*
    the deepfakes *all* the time, and a majority of detection techniques tend to have
    a low generalization capability—if they encounter a novel manipulation type that
    hasn’t been seen in the training dataset, then their performances drop significantly
    [[17]](https://doi.org/10.3390/jimaging9010018). While there has been significant
    progress in deepfake detection and notable solutions for addressing certain artifacts
    of synthetic media generation, we hope that efforts to raise awareness will motivate
    researchers to solve the shortcomings of current datasets used for testing these
    techniques, as well as developing techniques to perform well across various kinds
    of deepfake manipulation and generation. At some point, it will likely become
    extremely difficult, perhaps impossible, to confidently detect manipulated media
    at scale purely based on specific image characteristics.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其对抗性本质，没有单一的万能药可以始终检测到所有的深度伪造，而且大多数检测技术往往具有较低的一般化能力——如果它们遇到训练数据集中未见过的新的操纵类型，那么它们的性能会显著下降[[17]](https://doi.org/10.3390/jimaging9010018)。尽管在深度伪造检测和解决合成媒体生成某些伪影方面取得了显著进展和显著的解决方案，但我们希望提高意识的努力将激励研究人员解决当前用于测试这些技术的数据集的不足，以及开发能够在各种深度伪造操纵和生成中表现良好的技术。在某个时候，仅基于特定的图像特征大规模自信地检测操纵媒体可能会变得极其困难，甚至可能不可能。
- en: While technical solutions are certainly crucial to countering AI-generated and
    manipulated media, they don’t solve the problem in its entirety. Media literacy
    efforts to educate and inform the public are also essential steps to effectively
    respond to this problem. For visual deepfakes, such as images and videos, we can
    use artifacts of the generated images to help distinguish them from real images.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管技术解决方案在应对AI生成和操纵的媒体方面至关重要，但它们并不能完全解决问题。媒体素养的努力，即教育和告知公众，也是有效应对这一问题的必要步骤。对于视觉深度伪造，如图像和视频，我们可以利用生成的图像的伪影来帮助区分它们与真实图像。
- en: 'While there isn’t a single tell-tale sign, image manipulations often use facial
    transformations, where we can pay attention to cheeks, forehead, eyes, eyebrows,
    lips, and facial hair. We can ask questions like these: Is the agedness of the
    skin consistent with the agedness of other facial features? Is the skin tone uneven?
    Are the shadows expected? Do facial hair transformations look natural? Is there
    not enough or too much glare with glasses? Does the person blink enough or too
    much? Do lip movements look natural? AI-generated images have also historically
    generated too many fingers on hands, given that hands are less visible than faces
    in many human images, which is what these models are trained on. In videos, the
    facial expressions or movements may not exactly line up with the voice. Generally,
    we’re looking for distortions with visual deepfakes. Additionally, media literacy
    efforts should emphasize understanding the source and context behind the content
    shared. Understanding the content’s origination, credibility, and context can
    help us decipher how much attention it should receive.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然没有明显的迹象，但图像处理通常使用面部变换，我们可以关注脸颊、额头、眼睛、眉毛、嘴唇和面部毛发。我们可以提出以下问题：皮肤的衰老程度是否与其他面部特征一致？肤色是否不均匀？阴影是否预期？面部毛发的变换看起来自然吗？戴眼镜时是否有足够的或过多的反光？这个人眨眼是否足够或过多？唇部动作看起来自然吗？由于手在许多人类图像中不如面部明显，而这些模型是在这些图像上训练的，因此AI生成的图像在历史上也经常在手上生成过多的手指。在视频中，面部表情或动作可能与声音不完全一致。一般来说，我们寻找的是视觉深度伪造的扭曲。此外，媒体素养的努力应强调理解共享内容背后的来源和背景。了解内容的起源、可信度和背景可以帮助我们判断它应该得到多少关注。
- en: Finally, as discussed in chapter 3, appropriate legislation to govern the use
    of the technology and how it’s distributed will be fundamental to the responsible
    use and dissemination of synthetic media. The United States alone has introduced
    several synthetic media bills, especially concerning pornographic content and
    manipulation of the democratic process [[19]](https://www.malwarebytes.com/blog/news/2020/01/deepfakes-laws-and-proposals-flood-us).
    In parallel, social media companies, including Facebook, Twitter, Reddit, YouTube,
    and TikTok, have developed content-moderation policies to ban any deepfakes with
    malicious intent on their platforms.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，正如第3章所讨论的，制定适当的立法来规范技术的使用及其分发方式，对于合成媒体负责任的使用和传播将是至关重要的。仅美国就推出了几项合成媒体法案，特别是关于色情内容和操纵民主进程[[19](https://www.malwarebytes.com/blog/news/2020/01/deepfakes-laws-and-proposals-flood-us)]。同时，包括Facebook、Twitter、Reddit、YouTube和TikTok在内的社交媒体公司已经制定了内容监管政策，禁止在其平台上发布任何具有恶意意图的深度伪造内容。
- en: 'Generative AI: Transforming creative workflows'
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成式AI：改变创意工作流程
- en: In June 2022, *Cosmopolitan* fashion magazine unveiled the first cover made
    entirely by generative AI [[20]](https://www.cosmopolitan.com/lifestyle/a40314356/dall-e-2-artificial-intelligence-cover/).
    Synthetic media has opened up a new realm of possibilities for content creators.
    It has transformed creative work by eliminating monotonous tasks, increasing productivity
    and efficiency, and enabling people to express their creativity in new and unprecedented
    ways. From marketing and virtual influencers to art and film, we’ll unpack several
    creative applications of synthetic media in this section.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 2022年6月，**《大都会》**时尚杂志揭幕了第一本完全由生成式AI制作的封面[[20](https://www.cosmopolitan.com/lifestyle/a40314356/dall-e-2-artificial-intelligence-cover/)]。合成媒体为内容创作者开辟了一个新的可能性领域。它通过消除单调的任务，提高生产力和效率，以及使人们能够以前所未有的方式表达他们的创造力，从而改变了创意工作。在本节中，我们将探讨合成媒体在营销、虚拟网红、艺术和电影等领域的几个创意应用。
- en: Marketing applications
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 营销应用
- en: Marketing applications are perhaps the most common commercial use case for generative
    AI. There are countless examples of how individuals and brands are using synthetic
    media to create content for marketing purposes, accelerating the delivery of personalized
    content while adhering to a brand’s style and tone. They range from creating social
    media and blog posts to developing marketing videos and visual branding. Jasper
    (see [www.jasper.ai/](https://www.jasper.ai/)), an AI content platform based on
    a collection of third-party models (including OpenAI’s GPT-3.5) and their own,
    is focused on content creation for businesses. It can produce various types of
    customer-facing content, including social media posts, website copy, emails, blogs,
    ads, and imagery. Jasper also can move between different formats, tones, and languages.
    The Jasper website boasts that they are “trusted by 100,000+ teams globally at
    innovative companies.”
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 营销应用可能是生成式AI最常见的企业用例。有无数例子说明了个人和品牌如何使用合成媒体来创建营销内容，在遵守品牌风格和调性的同时加速个性化内容的交付。这些内容从创建社交媒体和博客文章到开发营销视频和视觉品牌设计。Jasper（参见[www.jasper.ai/](https://www.jasper.ai/）），一个基于第三方模型集合（包括OpenAI的GPT-3.5）及其自身的AI内容平台，专注于为商业创造内容。它可以生成各种面向客户的内容，包括社交媒体帖子、网站文案、电子邮件、博客、广告和图像。Jasper还可以在不同格式、语气和语言之间转换。Jasper网站宣称他们“在全球创新公司中被超过10万个团队信任。”
- en: Some brands are using DALL-E 2 and other image-generation tools for advertising.
    DALL-E 2 is an OpenAI model that can generate realistic images and art given a
    natural language description [[21]](https://openai.com/product/dall-e-2). Heinz
    put together a marketing campaign, “AI Ketchup,” based on OpenAI’s DALL-E 2—*EVEN
    A.I. KNOWS THAT KETCHUP IS HEINZ* [[22]](https://www.youtube.com/watch?v=LFmpVy6eGXs).
    As shown in figure 4.4, when we asked DALL-E 2 to create a series of generic ketchup-inspired
    pieces, the pictures overwhelmingly represented elements of Heinz’s signature
    branding.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一些品牌正在使用DALL-E 2和其他图像生成工具进行广告宣传。DALL-E 2是一个OpenAI模型，可以根据自然语言描述生成逼真的图像和艺术作品 [[21]](https://openai.com/product/dall-e-2)。海因茨公司推出了一项基于OpenAI的DALL-E
    2的营销活动，“AI番茄酱”，*甚至人工智能都知道番茄酱是海因茨的* [[22]](https://www.youtube.com/watch?v=LFmpVy6eGXs)。如图4.4所示，当我们要求DALL-E
    2创建一系列受番茄酱启发的通用作品时，图片几乎全部代表了海因茨标志性品牌元素。
- en: '![](../../OEBPS/Images/CH04_F04_Dhamani.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH04_F04_Dhamani.png)'
- en: 'Figure 4.4 From left to right, prompts to DALL-E 2: an impressionist painting
    of a ketchup bottle, a five-year-old’s drawing of a ketchup bottle, and an astronaut
    in space holding a ketchup bottle'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.4 从左到右，对DALL-E 2的提示：一瓶番茄酱的印象派画作、一个五岁孩子画的番茄酱瓶，以及一个在太空中手持番茄酱瓶的宇航员
- en: Nestlé used DALL-E’s Outpainting feature, which helps users extend an image
    beyond its original borders by adding visual elements in the same style (see [http://mng.bz/z0JX](http://mng.bz/z0JX)).
    They advertised an extended version of Johannes Vermeer’s famous painting, *The
    Milkmaid*, generated by DALL-E’s Outpainting feature, which was used to help sell
    Nestlé’s yogurt and dessert brand, La Laitière. The ad, created by Ogilvy Paris
    (see [http://mng.bz/G98R](http://mng.bz/G98R)), a creative communications agency,
    extends the world of the original painting to show the kitchen maid preparing
    La Laitière–inspired treats [[23]](https://www.adweek.com/creativity/nestle-brand-is-latest-to-venture-into-brave-new-world-of-ai-art-direction/).
    Going back to the earlier example of an astronaut holding a ketchup bottle, we
    asked DALL-E Outpainting to extend the image, as shown in figure 4.5.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 雀巢公司使用了DALL-E的Outpainting功能，该功能可以帮助用户通过添加相同风格的视觉元素来扩展图像超出其原始边界（参见[http://mng.bz/z0JX](http://mng.bz/z0JX)）。他们宣传了一幅由DALL-E的Outpainting功能生成的扩展版本的名画《牛奶女》，这幅画被用来帮助销售雀巢的酸奶和甜品品牌La
    Laitière。该广告由Ogilvy Paris（参见[http://mng.bz/G98R](http://mng.bz/G98R)）创意传播机构制作，将原画的世界扩展到展示厨房女工准备受La
    Laitière启发的美食 [[23]](https://www.adweek.com/creativity/nestle-brand-is-latest-to-venture-into-brave-new-world-of-ai-art-direction/)。回到之前提到的宇航员手持番茄酱瓶的例子，我们要求DALL-E
    Outpainting扩展图像，如图4.5所示。
- en: '![](../../OEBPS/Images/CH04_F05_Dhamani.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH04_F05_Dhamani.png)'
- en: Figure 4.5 The result of DALL-E’s Outpainting feature given the prompt “a burger
    in outer space without ketchup”
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.5 根据提示“外太空的汉堡没有番茄酱”使用DALL-E的Outpainting功能的结果
- en: Creative agencies aren’t the only ones using generative AI for marketing applications—Ryan
    Reynolds, a Canadian American actor, asked ChatGPT to write a commercial for Mint
    Mobile in his voice using a joke, a curse word, and a callout to Mint’s holiday
    promo [[24]](https://www.fastcompany.com/90833253/ryan-reynolds-used-chatgpt-to-make-a-mint-mobile-ad-and-the-results-were-mildly-terrifying).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 创意机构并非唯一使用生成式AI进行营销应用的——加拿大美国演员莱恩·雷诺兹要求ChatGPT用他的声音写一个Mint Mobile的商业广告，其中包含一个笑话、一个脏话和一个对Mint假日促销活动的呼吁
    [[24]](https://www.fastcompany.com/90833253/ryan-reynolds-used-ChatGPT-to-make-a-mint-mobile-ad-and-the-results-were-mildly-terrifying)。
- en: As of May 2023, 19-year-old Miquela Sousa has 2.8 million followers on Instagram
    and 3.6 million followers on TikTok. More famously known as Lil Miquela, she is
    one of *TIME Magazine*’s 25 Most Influential People on the Internet and is known
    to support Black Lives Matter, reproductive rights, and LGBTQ+ causes. She has
    also appeared in Calvin Klein ads, alongside American model Bella Hadid [[25]](https://www.elle.com/uk/fashion/a27492073/bella-hadid-calvin-klein-lil-miquela/).
    But Lil Miquela isn’t real—she is the most famous example of a virtual influencer,
    created by LA-based startup, Brud. Lil Miquela’s creators closed a $125 million
    Series B round in 2019 taking a bet on virtual influencers becoming the future
    of ads, fashion, and commerce [[26]](https://techcrunch.com/2019/01/14/more-investors-are-betting-on-virtual-influencers-like-lil-miquela/).
    Generative AI has increased the creation of virtual influencers, quickly being
    adopted in the workflows of their content production pipeline. Esther Olofsson,
    a Swedish virtual influencer, uses four AI tools, including Stable Diffusion (a
    text-to-image model) to generate 3D images of Esther, and ChatGPT to generate
    her captions on Instagram. Creators of virtual influencers believe that synthetic
    media can scale their creative output and earning power, with the ability to generate
    a boundless amount of content without the real-world constraints of human influencers.
    Yet, virtual influencers also raise ethical questions for their creators, specifically
    around cultural appropriation and representation for creators who create virtual
    influencers with different demographic characteristics than their own. Virtual
    dark-skinned influencer, Shudu Gram, has been critiqued as “contrived by a white
    man who has noticed the ‘movement’ of dark-skinned women” by social theorist Patricia
    Hill Collins [[27]](https://journals.sagepub.com/doi/full/10.1177/1527476420983745)
    [[28]](https://www.newyorker.com/culture/culture-desk/shudu-gram-is-a-white-mans-digital-projection-of-real-life-black-womanhood).
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 截至2023年5月，19岁的米奎拉·索萨在Instagram上有280万粉丝，在TikTok上有360万粉丝。更为人所知的是，她被称为Lil Miquela，是《时代》杂志评选的互联网上25位最具影响力人物之一，并且她支持黑人的命也是命、生育权利和LGBTQ+事业。她还出现在了Calvin
    Klein的广告中，与美国模特贝拉·哈迪德一起 [[25]](https://www.elle.com/uk/fashion/a27492073/bella-hadid-calvin-klein-lil-miquela/)。但Lil
    Miquela并非真人——她是虚拟网红中最著名的例子，由洛杉矶初创公司Brud创建。Lil Miquela的创造者在2019年完成了一轮1.25亿美元的B轮融资，押注虚拟网红将成为广告、时尚和商业的未来
    [[26]](https://techcrunch.com/2019/01/14/more-investors-are-betting-on-virtual-influencers-like-lil-miquela/)。生成式AI增加了虚拟网红的创造，迅速被纳入其内容生产流程的工作流程中。瑞典虚拟网红Esther
    Olofsson使用四种AI工具，包括Stable Diffusion（一种文本到图像的模型）来生成Esther的3D图像，以及ChatGPT来生成她在Instagram上的标题。虚拟网红的创造者认为，合成媒体可以扩大他们的创意产出和盈利能力，能够生成无限量的内容，而不受真人网红现实世界限制。然而，虚拟网红也引发了其创造者的伦理问题，特别是关于文化挪用和代表问题，对于创建具有与其自身不同人口特征的虚拟网红的创造者来说尤其如此。虚拟深色皮肤网红Shudu
    Gram被社会理论家帕特里夏·希尔·柯林斯批评为“由一个注意到深色皮肤女性‘运动’的白人男性所策划” [[27]](https://journals.sagepub.com/doi/full/10.1177/1527476420983745)
    [[28]](https://www.newyorker.com/culture/culture-desk/shudu-gram-is-a-white-mans-digital-projection-of-real-life-black-womanhood)。
- en: Artwork creation
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 艺术作品创作
- en: Artistic creation is another area that has been disrupted by generative AI.
    In 2018, the *Portrait of Edmond Belamy* was the first widely covered sale of
    an AI-generated artwork. The fictional portrait, created by Obvious, a Paris-based
    collective, was sold for a whopping $432,500 [[29]](https://news.artnet.com/market/first-ever-artificial-intelligence-portrait-painting-sells-at-christies-1379902).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 艺术创作是另一个被生成式AI颠覆的领域。2018年，*埃德蒙·贝拉米的肖像*是首个广泛报道的AI生成艺术品的销售。由巴黎集体Obvious创作的虚构肖像以惊人的43.25万美元的价格售出
    [[29]](https://news.artnet.com/market/first-ever-artificial-intelligence-portrait-painting-sells-at-christies-1379902)。
- en: While algorithms have been used to generate art since the 1960s [[30]](https://www.researchgate.net/publication/311104742_Algorithmic_Art_and_Its_Art-Historical_Relationships),
    AI-generated art can produce art (image, film/video, and music) without an explicit
    set of programming instructions that have been provided by human artists. AI tools
    such as DALL-E 2, Stable Diffusion, Midjourney, and WOMBO Dream can be used to
    quickly create artworks given any descriptive text input. Although some artists
    have expressed concerns about copyright problems with these tools (explored later
    in section 4.3), they have also been a source of creative inspiration for many.
    Creators have used DALL-E to create fan art, comic books, and design sneakers
    (someone made a pair for Sam Altman, cofounder of OpenAI, after he tweeted them
    [[31]](https://twitter.com/sama/status/1539670012536844289)). Tattoo artists are
    using DALL-E to generate tattoo designs together with their clients, while animation
    studios are using DALL-E to design characters and environments [[32]](https://www.technologyreview.com/2022/12/16/1065005/generative-ai-revolution-art/).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 自从20世纪60年代以来，算法已经被用来生成艺术 [[30](https://www.researchgate.net/publication/311104742_Algorithmic_Art_and_Its_Art-Historical_Relationships)]，但AI生成的艺术可以产生艺术（图像、电影/视频和音乐），而不需要人类艺术家提供的明确编程指令。DALL-E
    2、Stable Diffusion、Midjourney和WOMBO Dream等AI工具可以用于根据任何描述性文本输入快速创建艺术品。尽管一些艺术家对这些工具的版权问题表示了担忧（将在第4.3节中探讨），但它们也为许多艺术家提供了创意灵感。创作者们使用DALL-E来创作粉丝艺术、漫画和设计运动鞋（有人为OpenAI的联合创始人山姆·奥尔特曼制作了一双，在他推文后
    [[31](https://twitter.com/sama/status/1539670012536844289)]）。纹身艺术家正在使用DALL-E与客户一起生成纹身设计，而动画工作室则使用DALL-E来设计角色和环境
    [[32](https://www.technologyreview.com/2022/12/16/1065005/generative-ai-revolution-art/)]。
- en: 'Another well-known AI art generator tool is Google’s DeepDream, which takes
    an image as an input and outputs abstract, psychedelic art. The core idea behind
    generating these psychedelic images is to ask the network: “whatever you see there,
    I want more of it!” (see [http://mng.bz/0lYl](http://mng.bz/0lYl)). In practice,
    this means that the model amplifies any patterns that it sees in the image. Figure
    4.6 illustrates this idea by using the example image from DALL-E Outpainting (refer
    to figure 4.5) as a base image for DeepDream.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个知名的AI艺术生成工具是谷歌的DeepDream，它将图像作为输入，输出抽象、迷幻的艺术作品。生成这些迷幻图像的核心思想是向网络提问：“无论你在那里看到什么，我都想要更多！”（见[http://mng.bz/0lYl](http://mng.bz/0lYl)）。在实践中，这意味着模型放大了它在图像中看到的任何模式。图4.6通过使用DALL-E
    Outpainting的示例图像（参见图4.5）作为DeepDream的基础图像来说明这一思想。
- en: '![](../../OEBPS/Images/CH04_F06_Dhamani.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH04_F06_Dhamani.png)'
- en: Figure 4.6 DeepDream applied to figure 4.5 with the input prompt, “a portrait
    of a beautiful female knight in silver armor with intricate golden details”
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.6 将DeepDream应用于图4.5，输入提示为“一位穿着银色盔甲、细节复杂的金色装饰的美丽女骑士的肖像”
- en: Filmmakers have also been provided with new tools for creative possibilities.
    Generative AI is changing the way films are conceptualized, developed, and produced.
    The Writers Guild of America (WGA) is the first labor organization to take on
    generative AI—“The challenge is we want to make sure that these technologies are
    tools used by writers and not tools used to replace writers,” says John August,
    a member of the WGA’s 2023 negotiating committee [[33]](https://www.hollywoodreporter.com/business/business-news/writers-strike-ai-chatgpt-1235478681/).
    Filmmakers can generate scripts, storyboards, and scenes—as previously discussed,
    independent filmmakers can use generative AI to create compelling stories and
    visual elements without the need for a large budget, while studios can draw inspiration
    from these tools and use them to streamline content. Generative AI can also be
    used for improved visual effects by creating enhanced characters and environments
    without a manual labor-intensive process.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 电影制作者们也获得了新的工具来拓展创意可能性。生成式AI正在改变电影的概念化、开发和制作方式。美国编剧工会（WGA）是第一个承担生成式AI挑战的劳工组织——“我们的挑战是确保这些技术是作家使用的工具，而不是用来取代作家的工具，”美国编剧工会2023年谈判委员会成员约翰·奥古斯特说
    [[33](https://www.hollywoodreporter.com/business/business-news/writers-strike-ai-ChatGPT-1235478681/)]。电影制作者可以生成剧本、分镜脚本和场景——正如之前所讨论的，独立电影制作者可以使用生成式AI来创作引人入胜的故事和视觉元素，而无需大量预算，而电影制片厂则可以从这些工具中汲取灵感，并利用它们来简化内容。生成式AI还可以通过创建增强的角色和环境来提高视觉效果，而不需要繁琐的手动劳动过程。
- en: 'A controversial application is the ability to render the dead digitally. In
    the 2016 film, *Rogue One: A Star Wars Story*, filmmakers used face-swapping technology
    to digitally recreate the character played by the late Peter Cushing, who died
    in 1994 [[34]](https://www.polygon.com/2016/12/27/14092060/rogue-one-star-wars-grand-moff-tarkin-princess-leia).
    As for the ethics of digitally resurrecting dead actors, John Knoll, *Rogue One:
    A Star Wars Story*’s visual effects supervisor, said, “We weren’t doing anything
    that I think Peter Cushing would’ve objected to. I think this work was done with
    a great deal of affection and care. We know that Peter Cushing was very proud
    of his involvement in Star Wars and had said as much, and that he regretted that
    he never got a chance to be in another Star Wars film because George [Lucas] had
    killed off his character” [[35]](https://www.theguardian.com/film/2017/jan/16/rogue-one-vfx-jon-knoll-peter-cushing-ethics-of-digital-resurrections).
    Filmmakers are also using generative AI to accelerate the postproduction workflow
    with assistance in editing footage, applying visual effects, sound design, and
    more. Finally, as with every industry, filmmakers can use generative AI for creative
    inspiration.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 一个有争议的应用是能够以数字方式重现死者。在2016年的电影《侠盗一号：星球大战外传》中，电影制作者们使用了面部交换技术来数字重现已故演员彼得·库欣扮演的角色，他于1994年去世
    [[34]](https://www.polygon.com/2016/12/27/14092060/rogue-one-star-wars-grand-moff-tarkin-princess-leia)。至于数字复活已故演员的伦理问题，电影《侠盗一号：星球大战外传》的视觉效果总监约翰·诺尔表示：“我们并没有做任何我认为彼得·库欣会反对的事情。我认为这项工作是在极大的关爱和细致的关怀下完成的。我们知道彼得·库欣非常自豪地参与了《星球大战》，并且说过这样的话，他后悔自己从未有机会在另一部《星球大战》电影中出演，因为乔治·卢卡斯杀死了他的角色”
    [[35]](https://www.theguardian.com/film/2017/jan/16/rogue-one-vfx-jon-knoll-peter-cushing-ethics-of-digital-resurrections)。电影制作者们还在使用生成式AI来加速后期制作工作流程，包括剪辑素材、应用视觉效果、音效设计等。最后，正如每个行业一样，电影制作者们可以利用生成式AI进行创意灵感激发。
- en: Generative AI has also been a source of inspiration for architects and designers—one
    such example is the project, *This House Does Not Exist* (see [https://thishousedoesnotexist.org](https://thishousedoesnotexist.org)),
    which generates AI renderings of homes and buildings that don’t currently exist.
    AI-generated tools are making strides in architecture, with designers using them
    to rapidly iterate solutions that can then be augmented and tested using existing
    tools [[36]](https://www.elledecor.com/life-culture/a42711299/generative-ai-design-architecture/).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI也为建筑师和设计师提供了灵感——一个这样的例子是项目“这所房子不存在”（见[https://thishousedoesnotexist.org](https://thishousedoesnotexist.org)），该项目生成不存在于现实中的房屋和建筑的AI渲染图。AI生成的工具在建筑领域取得了进展，设计师们使用它们快速迭代解决方案，然后可以使用现有工具进行增强和测试
    [[36]](https://www.elledecor.com/life-culture/a42711299/generative-ai-design-architecture/)。
- en: In a similar vein, musicians are also exploring how humans and machines can
    collaborate, rather than compete. Pianist David Dolan performed with a semiautonomous
    AI system at the Stockholm University of the Arts, showing how generative AI may
    creatively supplement music [[37]](https://www.youtube.com/watch?v=sIFbvgmYBA0).
    The AI system was designed and overseen by Kingston University researcher Oded
    Ben-Tal, who says that musicians can use AI with pianists to improvise outside
    of their skillset or draw inspiration from AI compositions, for now [[38]](https://www.wired.co.uk/article/generative-ai-music).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在类似的方向上，音乐家们也在探索人类和机器如何协作，而不是竞争。钢琴家大卫·多兰在斯德哥尔摩艺术大学与一个半自动AI系统合作演出，展示了生成式AI如何创造性地补充音乐
    [[37]](https://www.youtube.com/watch?v=sIFbvgmYBA0)。该AI系统由金斯顿大学研究员奥德·本-塔尔设计和监督，他表示，音乐家们可以使用AI与钢琴家一起即兴创作超出他们技能范围的作品，或者从AI创作的作品中获得灵感，目前是这样的
    [[38]](https://www.wired.co.uk/article/generative-ai-music)。
- en: Musician Holly Herndon also used AI to clone her voice, dubbed Holly+, which
    she uses to sing in languages and styles she is unable to [[39]](https://www.youtube.com/watch?v=5cbCYwgQkTE).
    Holly+ is free to use by anyone, with Herndon and her team developing tools for
    anyone to be able to make art with her image and voice (see [https://holly.plus/](https://holly.plus/)).
    Sir Paul McCartney and The Beatles released a new tune, “Now and Then,” in November
    2023, by using generative AI to resurrect the voice of fellow bandmate, John Lennon
    [[40]](https://www.cnn.com/2023/06/13/entertainment/paul-mccartney-ai-beatles-song/index.xhtml).
    While these tools present an opportunity for musicians, some are worried about
    AI-generated music flooding streaming platforms and competing with real musicians.
    There are, of course, copyright concerns as well, which we’ll discuss in the next
    section. Universal Media Group, which backs superstars such as Taylor Swift and
    Nicki Minaj, urged Spotify and Apple Music to prohibit AI tools from scraping
    copyrighted songs [[41]](https://www.ft.com/content/aec1679b-5a34-4dad-9fc9-f4d8cdd124b9).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 音乐家霍莉·赫尔登也使用了AI克隆她的声音，命名为Holly+，她用它来演唱她无法使用的语言和风格。[39](https://www.youtube.com/watch?v=5cbCYwgQkTE)。Holly+对任何人都是免费的，赫尔登及其团队开发了工具，使任何人都能使用她的形象和声音进行艺术创作（见[https://holly.plus/](https://holly.plus/))。2023年11月，保罗·麦卡特尼和披头士乐队通过使用生成AI复活了乐队成员约翰·列侬的声音，发布了一首新歌“Now
    and Then”。[40](https://www.cnn.com/2023/06/13/entertainment/paul-mccartney-ai-beatles-song/index.xhtml)。虽然这些工具为音乐家提供了机会，但一些人担心AI生成的音乐会充斥流媒体平台，与真正的音乐家竞争。当然，也存在版权问题，我们将在下一节中讨论。支持泰勒·斯威夫特和妮琪·米娜等超级巨星的环球媒体集团敦促Spotify和Apple
    Music禁止AI工具抓取受版权保护的歌曲。[41](https://www.ft.com/content/aec1679b-5a34-4dad-9fc9-f4d8cdd124b9)。
- en: 'There is an ongoing debate about whether AI-generated art should be considered
    art in the same way that human-generated art is, whether artists will be replaced,
    and, more broadly, what this means for creativity. In defense of AI-generated
    art, artists argue that the AI tool is a medium of conveying the significance
    or meaning that lies in the human mind, similar to a brush and a palette or a
    camera. Anna Ridler, an artist known for her work with GANs, believes that the
    idea of replacing artists comes from undermining the artistic process—she says:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 关于AI生成的艺术是否应该像人类生成的艺术一样被视为艺术，艺术家是否会被取代，以及更广泛地说，这对创造力意味着什么，目前存在持续的争论。为了捍卫AI生成的艺术，艺术家们认为AI工具是传达人类心中所蕴含的意义或重要性的媒介，类似于画笔和调色板或相机。GANs艺术家安娜·里德勒认为，取代艺术家的想法源于对艺术过程的贬低——她说：
- en: 'AI can’t handle concepts: collapsing moments in time, memory, thoughts, emotions—all
    of that is a real human skill, that makes a piece of art rather than something
    that visually looks pretty. [[42]](https://www.theguardian.com/technology/2022/nov/12/when-ai-can-make-art-what-does-it-mean-for-creativity-dall-e-midjourney)'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: AI无法处理概念：时间、记忆、思维、情感等所有这些都是真正的人类技能，它们使艺术品成为不仅仅是视觉上看起来漂亮的东西。[42](https://www.theguardian.com/technology/2022/nov/12/when-ai-can-make-art-what-does-it-mean-for-creativity-dall-e-midjourney)
- en: Instead of replacing artists, AI-generated art can be understood as a collaboration
    between humans and machines.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的艺术不是取代艺术家，而可以理解为人类与机器之间的合作。
- en: Intellectual property in the LLM era
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLM时代的知识产权
- en: While synthetic media pushes the boundaries of art, the tools and models used
    to create it are testing the boundaries of the legal system. In the following
    section, we’ll take a look at the relevant policy governing the collection of
    open web data, including text and images, and the generation of synthetic media
    using models trained on those collections.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 当合成媒体推动艺术的边界时，用于创造它的工具和模型正在测试法律系统的边界。在下一节中，我们将探讨有关收集开放网络数据（包括文本和图像）以及使用这些集合训练的模型生成合成媒体的相关政策。
- en: Copyright law and fair use
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 著作权法和合理使用
- en: Pablo Picasso, one of the most renowned painters of the 20th century, allegedly
    said, “Good artists copy; great artists steal” [[43]](https://www.bbc.com/culture/article/20141112-great-artists-steal).
    It’s common practice in the literary and fine arts to imitate the styles of others,
    and it’s often seen as a prerequisite for creative success. Of course, such imitation
    has its limits, which are encoded into law as intellectual property (IP). The
    conception of IP as a type of property over which one could claim legal ownership
    dates back to England in the 17th century [[44]](https://www.eff.org/issues/intellectual-property/the-term).
    In the United States, Section 8 of Article I of the Constitution reads that Congress
    shall have the power
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 20世纪最著名的画家之一巴勃罗·毕加索据说曾说过，“好艺术家模仿；伟大的艺术家窃取” [[43]](https://www.bbc.com/culture/article/20141112-great-artists-steal)。在文学和美术领域，模仿他人的风格是一种常见的做法，并且通常被视为创造性成功的先决条件。当然，这种模仿有其界限，这些界限被编码进法律中，作为知识产权（IP）。知识产权作为一种可以主张法律所有权的财产的概念，可以追溯到17世纪的英国
    [[44]](https://www.eff.org/issues/intellectual-property/the-term)。在美国，宪法第一篇第八节规定，国会应拥有权力
- en: to promote the progress of science and useful arts, by securing for limited
    times to authors and inventors the exclusive right to their respective writings
    and discoveries. [[45]](https://www.archives.gov/founding-docs/constitution-transcript)
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了促进科学和实用艺术的进步，通过为作者和发明家在一定时间内对其各自的作品和发现享有专有权利来确保。[[45]](https://www.archives.gov/founding-docs/constitution-transcript)
- en: While there are several different types of IP protections—patents for inventions,
    trademarks for corporate logos and symbols, trade secrets for proprietary information
    such as the formula for Coca-Cola—the most contentious legal questions for generative
    AI are about the potential copyright infringements in model training and model
    generations.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然存在几种不同的知识产权保护类型——发明专利、公司标志和符号的商标、专有信息的商业秘密，如可口可乐的配方——但对于生成式AI最具争议的法律问题，是关于模型训练和模型生成中潜在的版权侵权。
- en: Copyrights are exclusive rights to a work of creative expression, whether that’s
    an image, a text, a movie, or a song. Typically, the owner of the copyright is
    the only one authorized to copy, distribute, display, or perform the work for
    a limited period of time, after which the work enters the public domain (in the
    United States, the copyright dates from the time that the work is created, and
    the standard term lasts until 70 years after the death of the creator) [[46]](https://www.copyright.gov/help/faq/faq-duration.xhtml).
    The US Copyright Office has stated their policy to be that text, images, and other
    media generated by AI aren’t eligible for copyright protections, although works
    by humans that have AI-generated elements might be, as long as there is sufficient
    human creativity involved [[47]](https://www.federalregister.gov/documents/2023/03/16/2023-05321/copyright-registration-guidance-works-containing-material-generated-by-artificial-intelligence).
    The most pressing current legal question around LLMs, as well as generative image
    models, isn’t whether their work is copyrightable, but whether they are actually
    violating existing copyrights of artists and writers whose works comprise their
    training data.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 版权是对创造性表达作品的专有权利，无论是图像、文本、电影还是歌曲。通常，版权所有者是唯一被授权在一定时间内复制、分发、展示或表演该作品的人，之后作品进入公共领域（在美国，版权从作品创作时开始计算，标准期限为创作者去世后70年）
    [[46]](https://www.copyright.gov/help/faq/faq-duration.xhtml)。美国版权局已声明其政策是，由AI生成的文本、图像和其他媒体不符合版权保护资格，尽管只要涉及足够的人类创造力，包含AI生成元素的人类作品可能符合，[[47]](https://www.federalregister.gov/documents/2023/03/16/2023-05321/copyright-registration-guidance-works-containing-material-generated-by-artificial-intelligence)。围绕大型语言模型以及生成式图像模型的最紧迫的法律问题，并不是它们的作品是否受版权保护，而是它们是否实际上侵犯了构成其训练数据的艺术家和作家的现有版权。
- en: Copyrights are exclusive rights to a work of creative expression, whether that’s
    an image, a text, a movie, or a song.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 版权是对创造性表达作品的专有权利，无论是图像、文本、电影还是歌曲。
- en: Despite copyrights offering exclusive rights for use, these rights are by no
    means absolute. *Fair use* is the legal doctrine that outlines when it’s acceptable
    to use copyrighted material without requiring the permission of the holder of
    the copyright [[48]](https://www.copyright.gov/fair-use/). For example, courts
    have typically considered parody to be fair use, which is why “Weird Al” Yankovic
    can commercially sell melodic duplicates (e.g., “Eat It” and “Like a Surgeon”)
    of copyrighted songs with his own comical lyrics (though Yankovic states on his
    website that he gets permission from the original writers anyway to maintain relationships
    he has built over the years). [[49]](https://www.weirdal.com/archives/faq/) As
    defined in the US Copyright Act of 1976, fair use hinges on four factors, as shown
    in figure 4.7.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管版权为使用提供了专有权利，但这些权利绝不是绝对的。“合理使用”是一项法律原则，它概述了在无需获得版权持有者许可的情况下使用受版权保护材料何时是可接受的
    [[48]](https://www.copyright.gov/fair-use/)。例如，法院通常认为讽刺作品是合理使用，这就是为什么“怪诞阿尔”·扬科维克可以商业化销售带有他自己的滑稽歌词的受版权保护歌曲的旋律副本（例如，“Eat
    It”和“Like a Surgeon”）。尽管扬科维克在他的网站上表示，他仍然会从原始作者那里获得许可以维持多年来建立的关系 [[49]](https://www.weirdal.com/archives/faq/)。根据1976年美国版权法的规定，合理使用取决于四个因素，如图4.7所示。
- en: '![](../../OEBPS/Images/CH04_F07_Dhamani.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH04_F07_Dhamani.png)'
- en: Figure 4.7 The four factors that determine fair use of copyrighted materials
    [[50]](https://www.law.cornell.edu/uscode/text/17/107)
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.7 确定受版权保护材料合理使用的四个因素 [[50]](https://www.law.cornell.edu/uscode/text/17/107)
- en: The first factor, “the purpose and character of the use,” refers to how and
    why the copyrighted material is used. Commercial use is less likely to be deemed
    fair as compared to nonprofit or educational purposes—for example, a college professor
    could distribute printouts of a painting for an art history lecture, but you might
    get in trouble for selling T-shirts with that same painting printed on them. “Transformative
    use” is another case that falls under this first factor. Essentially, US courts
    have found that when the character of the use is *transformative*, adding a new
    element that fundamentally changes the work, that isn’t a copyright violation.
    Transformative use also hinges on the derivate work being used for a purpose that
    is different from the consumption or enjoyment of the original work and is an
    important defense for companies that develop LLMs.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个因素，“使用的目的和性质”，指的是如何以及为什么使用受版权保护的材料。与非营利或教育目的相比，商业用途不太可能被视为合理使用——例如，一位大学教授可以为艺术史讲座分发一幅画的打印件，但如果你出售印有同样画作的T恤，可能会遇到麻烦。“转换性使用”也是属于这个第一个因素的一个案例。本质上，美国法院发现，当使用的性质是*转换性*的，即添加一个从根本上改变作品的新元素，那么这并不构成版权侵犯。转换性使用还取决于所使用的衍生作品的目的与原作品的消费或享受不同，这对于开发大型语言模型的公司来说是一个重要的辩护。
- en: The second factor, “the nature of the copyrighted work,” refers to the varying
    degrees of protection that different types of materials enjoy. Because the original
    intent of copyright was to incentivize free and creative expression, the use of
    more “creative” works, such as songs, plays, and novels, is more likely to be
    deemed fair use as compared to factual or technical copyrighted works. In other
    words, you could argue that referencing lines of poetry in a new verse is fair
    use, but it’d be harder to do the same for a piece of investigative reporting.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个因素，“受版权保护作品的性质”，指的是不同类型材料所享受的不同程度的保护。因为版权的原始意图是激励自由和创造性的表达，所以使用更多“创造性”的作品，如歌曲、戏剧和小说，与事实或技术性受版权保护的作品相比，更有可能被视为合理使用。换句话说，你可以争论在新的诗句中引用诗句是合理使用，但对于一篇调查报道来说，这样做可能更困难。
- en: The third factor assesses how much of the original source material was reused.
    If it’s a substantial portion or nearly all of it, that is less likely to be deemed
    fair use than a small amount.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个因素评估了多少原始素材被重新使用。如果是大量或几乎全部，那么与少量相比，这不太可能被视为合理使用。
- en: The fourth and final factor refers to if and how the use of copyrighted material
    will affect the market for that work. If an unauthorized seller is distributing
    a new movie online, for example, that would pose a serious threat to the digital
    sales or streaming revenue for that movie. Uses that hurt the market for the original
    work are unlikely to be considered fair [[48]](https://www.copyright.gov/fair-use/).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 第四个也是最后一个因素是关于版权材料的使用是否以及如何影响该作品的市场。例如，如果未经授权的卖家在网上分发新电影，这将对该电影的数字销售或流媒体收入构成严重威胁。那些损害原创作品市场的使用不太可能被认为是合理的
    [[48]](https://www.copyright.gov/fair-use/)。
- en: 'If all of this seems a little blurry, that’s because it is—none of these single
    factors are hard-and-fast rules, and they are all weighed against each other if
    a copyright suit is brought. Before turning to the lawsuits that have been brought
    already against developers of LLMs, though, let’s first examine a case that hinges
    similarly on the use of vast amounts of copyrighted text from the internet: *Authors
    Guild v. Google* [[51]](https://www.copyright.gov/fair-use/summaries/authorsguild-google-2dcir2015.pdf).'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这一切看起来有些模糊，那是因为它确实是——如果提起版权诉讼，这些单一因素都不是铁的规则，它们都会被权衡。在转向已经对LLMs开发者提起的诉讼之前，让我们首先考察一个类似地基于使用大量互联网版权文本的案例：*Authors
    Guild v. Google* [[51]](https://www.copyright.gov/fair-use/summaries/authorsguild-google-2dcir2015.pdf)。
- en: In 2015, Google collaborated with several major research libraries to digitize
    their collections of books—some 20 million volumes. The tech giant accessed the
    books through partnerships, scanned them, and allowed people to search them for
    text snippets, all without the permission of the copyright owners, and without
    paying licensing fees. The case made it to the Second Circuit Court of Appeals,
    which concurred with a lower court’s opinion that Google’s digitization efforts
    constituted fair use because the search functionality gave the public access to
    information *about* the books that they wouldn’t otherwise have, and because even
    though Google used the full text of the books, they only returned the snippets
    of matching text, rather than making the entire books available. This concept
    of using the entirety of source material for a fundamentally different tool is
    analogous to the training of LLMs.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 2015年，谷歌与几家主要研究图书馆合作，将他们的藏书数字化——大约有2000万卷。这家科技巨头通过合作伙伴关系访问这些书籍，扫描它们，并允许人们搜索文本片段，所有这些都是在没有版权所有者许可的情况下，也没有支付版税。这个案件上诉到了第二巡回上诉法院，该法院同意了下级法院的意见，即谷歌的数字化努力构成了合理使用，因为搜索功能使公众能够访问他们否则无法获得的书本信息，并且尽管谷歌使用了书籍的全文，但他们只返回了匹配文本的片段，而不是使整本书可用。这种使用全部源材料为基本不同的工具的概念与LLMs的训练类似。
- en: In general, the LLMs we’ve discussed thus far would seem to be protected by
    fair use because the model is a very different work than any of the documents,
    and thus the use of the materials is transformative. Complicating matters, users
    have shown that it’s occasionally possible to get LLMs to regurgitate text verbatim.
    It’s difficult to show examples of “memorizing” source material consistently,
    due to the probabilistic nature of LLMs. Because of the lack of understanding
    as to exactly what LLMs learn, even their developers are unlikely to be able to
    say for sure when the model will reproduce phrases or texts word for word. Still,
    under the precedent of *Authors Guild v. Google*, the odds seem considerably in
    favor of LLMs being considered fair use.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 通常来说，我们迄今为止讨论的LLMs（大型语言模型）似乎受到合理使用的保护，因为模型与任何文档都非常不同，因此使用这些材料是具有变革性的。然而，问题复杂化了，用户已经证明有时可以让LLMs逐字逐句地重复文本。由于LLMs的概率性质，很难一致地展示“记忆”源材料的例子。由于对LLMs确切学习内容的理解不足，即使是它们的开发者也不太可能确切地说出模型何时会逐字逐句地复制短语或文本。尽管如此，根据*Authors
    Guild v. Google*的先例，LLMs被认为合理使用的可能性似乎相当大。
- en: 'LLMs aren’t the only generative models making a splash in copyright—as mentioned
    previously, there are impressive generative models capable of creating all types
    of synthetic media, including images, audio, and videos. Some of the most popular
    models, including Midjourney and Stable Diffusion, are text-to-image models: users
    can describe what they want their picture to look like, and the model will generate
    it for them.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）并不是唯一在版权方面引起轰动的生成模型——如前所述，还有令人印象深刻的生成模型能够创建所有类型的合成媒体，包括图像、音频和视频。其中一些最受欢迎的模型，包括Midjourney和Stable
    Diffusion，是文本到图像的模型：用户可以描述他们想要的图片外观，模型将为他们生成。
- en: Just like LLMs, generative image models train on huge amounts of data collected
    from the internet. As with text datasets such as Common Crawl, there are common
    image datasets, such as LAION-5B, a dataset of 5.8 billion images compiled by
    the nonprofit Large-scale Artificial Intelligence Open Network (LAION). LAION-5B
    is used by Stability AI, the developer of Stable Diffusion, and other companies;
    it’s made up of images that are publicly available online, including stock photos
    and editorial photography. One German photographer, upon discovering that some
    of his stock images were used in LAION-5B, requested that they be removed; LAION
    responded that to fulfill such a request would be impossible because the database
    contained only links to images, so nothing was stored, and they could not readily
    identify which images were from his portfolio. German copyright law—like in many
    countries—does allow data mining if the data is “lawfully accessible” and deleted
    later, but the emergence of generative models has brought the problem under greater
    scrutiny [[52]](https://www.vice.com/en/article/pkapb7/a-photographer-tried-to-get-his-photos-removed-from-an-ai-dataset-he-got-an-invoice-instead).
    Stability AI later announced that they would honor opt-out requests from artists
    whose work was included in the LAION dataset [[53]](https://arstechnica.com/information-technology/2022/12/stability-ai-plans-to-let-artists-opt-out-of-stable-diffusion-3-image-training/).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 就像大型语言模型（LLMs）一样，生成式图像模型在从互联网收集的大量数据上进行训练。与像Common Crawl这样的文本数据集一样，也存在常见的图像数据集，例如由非营利组织大规模人工智能开放网络（LAION）编纂的包含58亿张图像的LAION-5B数据集。LAION-5B被Stability
    AI（Stable Diffusion的开发者）和其他公司使用；它由公开在线可用的图像组成，包括股票照片和编辑摄影。一位德国摄影师在发现他的部分股票照片被用于LAION-5B后，要求将其删除；LAION回应称，满足此类请求是不可能的，因为数据库中只包含图像链接，没有存储任何内容，他们无法轻易识别出哪些图像来自他的作品集。德国版权法——像许多国家一样——允许在数据“合法可访问”且之后删除的情况下进行数据挖掘，但生成模型的兴起使得这个问题受到了更多的审查[[52](https://www.vice.com/en/article/pkapb7/a-photographer-tried-to-get-his-photos-removed-from-an-ai-dataset-he-got-an-invoice-instead)]。Stability
    AI后来宣布，他们将尊重包括在LAION数据集中的艺术家的工作中的退出请求[[53](https://arstechnica.com/information-technology/2022/12/stability-ai-plans-to-let-artists-opt-out-of-stable-diffusion-3-image-training/)]。
- en: 'Stability is also currently being sued by Getty Images for using more than
    12 million photographs from the Getty collection [[52]](https://www.vice.com/en/article/pkapb7/a-photographer-tried-to-get-his-photos-removed-from-an-ai-dataset-he-got-an-invoice-instead),
    [[54]](https://fingfx.thomsonreuters.com/gfx/legaldocs/byvrlkmwnve/GETTY%20IMAGES%20AI%20LAWSUIT%20complaint.pdf).
    In the complaint, the plaintiffs write:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Stability AI目前正在因使用Getty收藏中的超过1200万张照片而受到Getty Images的起诉[[52](https://www.vice.com/en/article/pkapb7/a-photographer-tried-to-get-his-photos-removed-from-an-ai-dataset-he-got-an-invoice-instead)]，[[54](https://fingfx.thomsonreuters.com/gfx/legaldocs/byvrlkmwnve/GETTY%20IMAGES%20AI%20LAWSUIT%20complaint.pdf)]。在诉状中，原告写道：
- en: At great expense, over the course of nearly three decades, Getty Images has
    curated a collection of hundreds of millions of premium quality visual assets . . . Many
    of these images were created by Getty Images staff photographers as works made-for-hire,
    others have been acquired by Getty Images from third parties with an assignment
    of its associated copyrights, and the remainder have been licensed to Getty Images
    by its hundreds of content partners or hundreds of thousands of contributing photographers,
    who rely on the licensing income Getty Images generates for them. [[55]](https://fingfx.thomsonreuters.com/gfx/legaldocs/byvrlkmwnve/GETTY%20IMAGES%20AI%20LAWSUIT%20complaint.pdf)
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: Getty Images在近三十年的时间里，以巨大的成本精心挑选了数亿个高质量的视觉资产……其中许多图像是由Getty Images的摄影师作为雇佣作品创作的，其他则是由Getty
    Images从第三方获得，并转让了其相关的版权，剩余的则是由 Getty Images的数百个内容合作伙伴或数十万贡献摄影师许可的，他们依赖Getty Images为他们产生的许可收入。[55](https://fingfx.thomsonreuters.com/gfx/legaldocs/byvrlkmwnve/GETTY%20IMAGES%20AI%20LAWSUIT%20complaint.pdf)
- en: 'The subtext is clear: generative AI models pose an existential threat to Getty
    and stock photography as an industry. Getty hopes to be compensated for their
    contributions and perceived copyright infringement, but as with the large text
    datasets, it’s difficult to ascertain how much information the model retains from
    any single image, and, again, the use by Stability AI would seem to be transformative.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 其隐含意义很明确：生成式AI模型对Getty和作为行业的股票摄影构成了生存威胁。Getty希望得到对其贡献和感知到的版权侵权的赔偿，但正如大型文本数据集一样，很难确定模型从任何单一图像中保留了多少信息，而且，再次强调，Stability
    AI的使用似乎具有变革性。
- en: 'Amusingly, Getty might have a stronger case due to an artifact of the training
    data: the complaint further alleges the following:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，由于训练数据中的一个瑕疵，Getty可能拥有更强的诉讼理由：投诉进一步指控以下内容：
- en: Often, the output generated by Stable Diffusion contains a modified version
    of a Getty Images watermark, creating confusion as to the source of the images
    and falsely implying an association with Getty Images. While some of the output
    generated through the use of Stable Diffusion is aesthetically pleasing, other
    output is of much lower quality and at times ranges from the bizarre to the grotesque.
    Stability AI’s incorporation of Getty Images’ marks into low quality, unappealing,
    or offensive images dilutes those marks in further violation of federal and state
    trademark laws. [[55]](https://fingfx.thomsonreuters.com/gfx/legaldocs/byvrlkmwnve/GETTY%20IMAGES%20AI%20LAWSUIT%20complaint.pdf)
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，Stable Diffusion生成的输出包含Getty Images水印的修改版本，这导致了对图像来源的混淆，并错误地暗示与Getty Images有关联。虽然通过使用Stable
    Diffusion生成的一些输出在美学上令人愉悦，但其他输出质量较低，有时从奇异到丑陋不等。Stability AI将Getty Images的标志融入低质量、不吸引人或有冒犯性的图像中，进一步违反了联邦和州商标法。[55](https://fingfx.thomsonreuters.com/gfx/legaldocs/byvrlkmwnve/GETTY%20IMAGES%20AI%20LAWSUIT%20complaint.pdf)
- en: Stable Diffusion or possibly its users could be found in violation of trademarks
    if the Getty Images watermark appears on images, although Stability AI will undoubtedly
    move quickly to address this behavior. Altogether, this is a relatively untested
    area of law.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果图像上出现Getty Images的水印，那么Stable Diffusion或其用户可能会被发现在侵犯商标权，尽管Stability AI无疑会迅速采取措施解决这个问题。总的来说，这是一个相对未经验证的法律法规领域。
- en: Things get even dicier when a model has not only learned an image captured by
    a human artist but also encoded the style of that artist. In addition to generating
    photorealistic renderings, generative models such as Midjourney and Stable Diffusion
    are also capable of producing artwork in particular styles, as discussed in section
    Generative AI in Creative Workflows. Style isn’t generally copyrightable, but
    it’s easy to see how artists might think such imitation could devalue or diminish
    their work. Sarah Andersen, a prominent cartoonist who publishes webcomics under
    the “Sarah’s Scribbles” collection, wrote a *New York Times* opinion essay about
    her experience of alt-right internet trolls co-opting her comics by editing the
    words and frames to change their meaning. Figure 4.8 shows an example of artwork
    generated by an AI tool in her artistic style—with clearly garbled text, but some
    visual elements of Andersen’s work present. “When I checked the website [https://haveibeentrained.com](https://haveibeentrained.com),
    a site created to allow people to search LAION data sets, so much of my work was
    on there that it filled up my entire desktop screen,” Andersen attested, and worried
    that the AI tools would be used to twist her creations again [[56]](https://www.nytimes.com/2022/12/31/opinion/sarah-andersen-how-algorithim-took-my-work.xhtml).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个模型不仅学会了人类艺术家捕捉的图像，而且还编码了该艺术家的风格时，事情变得更加复杂。除了生成逼真的渲染效果外，像Midjourney和Stable
    Diffusion这样的生成模型还能够以特定风格创作艺术品，如第“生成AI在创意工作流程”节所述。风格通常不受版权保护，但很容易理解艺术家们可能会认为这种模仿会贬低或削弱他们的作品。Sarah
    Andersen是一位著名的漫画家，她在“Sarah’s Scribbles”系列中发布网络漫画，她写了一篇关于她经历另类右翼网络暴民通过编辑文字和帧来改变其意义的《纽约时报》观点文章。图4.8展示了由AI工具以她的艺术风格生成的艺术品示例——文字明显混乱，但Andersen的一些视觉元素仍然存在。“当我检查了[https://haveibeentrained.com](https://haveibeentrained.com)网站时，这是一个允许人们搜索LAION数据集的网站，我的许多作品都在那里，以至于填满了我的整个桌面屏幕，”Andersen证实，并担心AI工具会被用来再次扭曲她的创作[[56](https://www.nytimes.com/2022/12/31/opinion/sarah-andersen-how-algorithim-took-my-work.xhtml)]。
- en: Andersen is one of three plaintiffs, with Karla Ortiz and Kelly McKernan, in
    a class-action lawsuit brought against Midjourney, Stability AI, and DeviantArt.
    Like Andersen, McKernan and Ortiz similarly found that the tools could generate
    images in their styles in a way that felt personally invasive. “They trained these
    models with our work. They took away our right to decide whether they wanted to
    be a part of this or not,” said Ortiz [[56]](https://www.nytimes.com/2022/12/31/opinion/sarah-andersen-how-algorithim-took-my-work.xhtml)
    [[57]](https://www.buzzfeednews.com/article/pranavdixit/ai-art-generators-lawsuit-stable-diffusion-midjourney).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Andersen是三位原告之一，与Karla Ortiz和Kelly McKernan一起，对Midjourney、Stability AI和DeviantArt提起了集体诉讼。像Andersen一样，Ortiz和McKernan同样发现这些工具能够以令人感到个人侵犯的方式生成他们风格的图像。“他们用我们的作品训练了这些模型。他们剥夺了我们决定是否想成为其中一部分的权利，”Ortiz说[[56](https://www.nytimes.com/2022/12/31/opinion/sarah-andersen-how-algorithim-took-my-work.xhtml)]
    [[57](https://www.buzzfeednews.com/article/pranavdixit/ai-art-generators-lawsuit-stable-diffusion-midjourney)]。
- en: '![](../../OEBPS/Images/CH04_F08_Dhamani.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH04_F08_Dhamani.png)'
- en: Figure 4.8 An AI-created image using an open source image-generation model with
    the prompt “Sarah Andersen webcomic”
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.8 使用开源图像生成模型并以提示“Sarah Andersen网络漫画”创建的AI图像
- en: While it remains to be seen how Andersen, Ortiz, and McKernen’s suit will play
    out, these tools continue to be used by people around the world to generate and
    experiment with novel art forms. The permissive structure of fair use means that
    any substantial changes to the status quo would require a new precedent for use
    in training AI models. Yet, at the same time, many of the datasets and models
    that we’re talking about are already open source, meaning that anyone can either
    train their own model or make a new version of an existing one. Regardless of
    whether any particular company changes its dataset construction procedure, or
    ends up paying damages or licensing fees, AI-generated art, from comics to music
    to poetry, is here to stay.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Andersen、Ortiz和McKernen的诉讼结果尚待观察，但这些工具仍在世界各地被用来生成和实验新的艺术形式。公平使用的宽容结构意味着，对现状的任何重大改变都需要为在训练AI模型中使用树立新的先例。然而，与此同时，我们谈论的许多数据集和模型已经是开源的，这意味着任何人都可以训练自己的模型或创建现有模型的新版本。无论任何特定公司是否改变其数据集构建程序，或者最终支付损害赔偿金或许可费，从漫画到音乐到诗歌，AI生成的艺术都将持续存在。
- en: Open source and licenses
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开源和许可
- en: We’ve mentioned already that due to the enormous scale of data and compute required
    to produce LLMs, the exercise has thus far largely been left to a few major tech
    companies and some well-funded startups. That is already changing due to the open
    source community. *Open source* refers to the source code of software being open
    and available to the public for reuse and modification. More than that, open source
    is a movement, whose advocates believe that open source software is a public good
    and leads to better software through more collaboration and participation, as
    well as lower barriers to entry. Similarly, the open data movement proponents
    suggest that when data is widely accessible, the public will be more informed,
    so data collected or produced by government and nonprofit organizations, scientific
    research, and other entities should be freely available to use and build on.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经提到，由于生产LLMs需要巨大的数据和计算规模，这项工作到目前为止主要留给了一些主要的技术公司和一些资金充足的初创公司。然而，由于开源社区的出现，这种情况正在改变。“开源”指的是软件的源代码对公众开放并可重用和修改。更重要的是，开源是一种运动，其倡导者认为开源软件是公共产品，通过更多的协作和参与以及降低进入门槛，可以产生更好的软件。同样，开放数据运动的倡导者建议，当数据广泛可访问时，公众将更加知情，因此政府和非营利组织、科学研究以及其他实体收集或产生的数据应该可以自由使用和构建。
- en: Open source refers to the source code of software being open and available to
    the public for reuse and modification.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: “开源”指的是软件的源代码对公众开放并可重用和修改。
- en: 'If anything, generative image models have been ahead of LLMs in this respect.
    Because of a keen interest in computer vision models, academics have compiled
    large image datasets since Fei-Fei Li, a professor of computer science at Stanford
    University, began a project called ImageNet. In 2006, Li had the prophetic idea
    that the biggest gains to be made in computer vision weren’t necessarily from
    new, better algorithms, but from better (and bigger) data. She began creating
    a database, ImageNet, that would eventually be composed of millions of images
    depicting hundreds of things: animals, household objects, land formations, and
    many other categories. After much initial skepticism, ImageNet became a standard
    against which all computer vision models measured their results. Not only did
    it kick-start the object detection problem (which is now considered “solved” on
    ImageNet, as state-of-the-art models can perform nearly perfectly), but it ushered
    in an era of sharing benchmark datasets for training and testing models. Of ImageNet’s
    influence, Li said, “There is a lot of mushrooming and blossoming of all kinds
    of datasets, from videos to speech to games to everything.” Of course, it was
    also a proof point for her original hypothesis, which was later also borne out
    by the success of LLMs [[58]](https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world).'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有什么的话，生成式图像模型在这方面已经领先于LLMs。由于对计算机视觉模型的高度兴趣，自从斯坦福大学计算机科学教授Fei-Fei Li开始了一个名为ImageNet的项目以来，学者们就已经编制了大量的图像数据集。2006年，Li有一个先见之明的想法，即计算机视觉的最大进步不一定来自新的、更好的算法，而是来自更好的（以及更大的）数据。她开始创建一个数据库，ImageNet，它最终将包含数百万张描绘数百种事物的图片：动物、家庭用品、地形，以及许多其他类别。经过最初的许多怀疑之后，ImageNet成为所有计算机视觉模型衡量其结果的标准。它不仅启动了目标检测问题（现在在ImageNet上被认为已经“解决”，因为最先进的模型可以近乎完美地执行），而且还迎来了一个为训练和测试模型共享基准数据集的时代。关于ImageNet的影响，Li说：“现在有各种各样的数据集如雨后春笋般涌现和绽放，从视频到语音、游戏到一切。”当然，这也证实了她最初假设的证明点，后来LLMs的成功也证实了这一点
    [[58]](https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world)。
- en: Across problem domains from natural language to images and videos, then, it
    pays to be greedy for data. Like later datasets, ImageNet was assembled from pictures
    from the internet and then labeled by workers on Amazon Mechanical Turk, a crowdsourcing
    platform. By writing a minimal amount of code, people can compile text and image
    data by programmatically accessing web pages and copying their contents. This
    practice is called *web scraping*, which has been repeatedly found to be legal
    [[59]](https://techcrunch.com/2022/04/18/web-scraping-legal-court/) as long as
    the data is publicly available—so almost anything that you would see by browsing
    online. Any website that is indexed by search engines, for example, is scraped
    by bots. Some of the companies that operate websites that are frequent data sources
    for LLMs, including Reddit, Twitter, and Stack Overflow, have publicly stated
    plans to charge AI developers to use that data, though it’s unclear what this
    would look like in practice—most likely, they would sell datasets that obviate
    the need for scraping [[60]](https://www.zdnet.com/article/stack-overflow-joins-reddit-and-twitter-in-charging-ai-companies-for-training-data/).
    People who maintain websites can add a robots.txt file, which is essentially a
    set of instructions for a bot, to tell the bot which pages it can scrape and which
    it shouldn’t. In practice, robots.txt files are only advisories, and malicious
    programs can easily ignore them.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从自然语言到图像和视频等各个问题领域，对数据的贪婪是有益的。像后来的数据集一样，ImageNet是由互联网上的图片组成的，然后由Amazon Mechanical
    Turk（一个众包平台）上的工人进行标注。通过编写少量代码，人们可以通过程序访问网页并复制其内容来编译文本和图像数据。这种做法被称为*网络爬虫*，只要数据是公开可用的，就被反复发现是合法的[[59](https://techcrunch.com/2022/04/18/web-scraping-legal-court/)]——因此几乎任何你在网上浏览到的内容都可以。例如，任何被搜索引擎索引的网站都会被爬虫抓取。一些运营网站的公司，包括Reddit、Twitter和Stack
    Overflow，这些网站是大型语言模型（LLM）频繁的数据来源，已经公开表示计划向AI开发者收费以使用这些数据，尽管在实践中的具体形式尚不清楚——最有可能的是，他们会出售无需爬取的数据集[[60](https://www.zdnet.com/article/stack-overflow-joins-reddit-and-twitter-in-charging-ai-companies-for-training-data/)]。维护网站的人可以添加一个robots.txt文件，这本质上是一组针对爬虫的指令，告诉爬虫它可以抓取哪些页面以及哪些页面不应该抓取。在实践中，robots.txt文件只是建议性的，恶意程序可以轻易地忽略它们。
- en: Although there are few legal restrictions for publicly available web content,
    both code and data have licenses. Some open source licenses explicitly allow all
    types of derivative uses. The MIT License, for example, is a permissive software
    license—in fact, the most popular license on GitHub—that allows for reuse within
    proprietary software [[61]](https://github.blog/2015-03-09-open-source-license-usage-on-github-com/).
    Other licenses allow reuse only for noncommercial purposes; still others might
    allow reuse with attribution, or several other conditions. Code and data licenses
    are legally enforceable [[62]](https://www.nytimes.com/2008/08/14/technology/14commons.xhtml).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管公开可用的网络内容法律限制不多，但代码和数据都有相应的许可。一些开源许可明确允许所有类型的衍生使用。例如，麻省理工学院许可证（MIT License）是一种宽松的软件许可证——实际上，这是GitHub上最受欢迎的许可证之一——允许在专有软件中重用[[61](https://github.blog/2015-03-09-open-source-license-usage-on-github-com/)]。其他许可证仅允许非商业用途的重用；还有一些许可证可能允许在注明出处的情况下重用，或者满足其他条件。代码和数据许可证在法律上是可执行的[[62](https://www.nytimes.com/2008/08/14/technology/14commons.xhtml)]。
- en: Code licenses are a central question in a class-action lawsuit brought by software
    developers against Microsoft, GitHub, and OpenAI over the LLM tool Copilot. Copilot
    is based on a variant of OpenAI’s GPT-3 model that is tailored especially for
    writing code, and it’s trained on thousands of GitHub repositories. Like the copyright
    question, there is litigation over the use of this code for training LLMs; it’s
    unclear how relying on licensing instead of fair use would work. The plaintiffs
    in the case argue that the use amounts to “software piracy on an unprecedented
    scale,” while the defendants say that it’s the plaintiffs who are undermining
    the principles of open source by requesting “an injunction and multi-billion dollar
    windfall” for “software that they willingly share” [[63]](https://www.theverge.com/2023/1/28/23575919/microsoft-openai-github-dismiss-copilot-ai-copyright-lawsuit).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 代码许可证是软件开发商对微软、GitHub和OpenAI提起的集体诉讼中的核心问题，该诉讼涉及LLM工具Copilot。Copilot基于OpenAI的GPT-3模型的变体，特别适用于编写代码，并且是在数千个GitHub仓库上训练的。与版权问题一样，关于使用此代码进行LLM训练的诉讼正在进行中；不清楚依赖许可而不是合理使用将如何运作。该案的原告认为这种使用相当于“前所未有的软件盗版”，而被告则表示，原告通过要求“禁令和数十亿美元的意外之财”来“分享他们自愿分享的软件”，正在破坏开源的原则。[63](https://www.theverge.com/2023/1/28/23575919/microsoft-openai-github-dismiss-copilot-ai-copyright-lawsuit)
- en: Meanwhile, companies such as Hugging Face are bullish on open source principles,
    building and hosting models and datasets that are free to use [[64]](https://huggingface.co/).
    People unaffiliated with any of the prestigious AI labs are nonetheless able to
    access and, in some cases, improve upon state-of-the-art results in this ecosystem
    of rapid iteration and sharing. This carries with it certain risks because any
    limits put in to reduce certain harms can be removed by downstream users. It will
    be harder to prevent the creation of copycat content or enforce existing copyrights.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，像Hugging Face这样的公司对开源原则持乐观态度，它们构建和托管免费使用的模型和数据集。[64](https://huggingface.co/)。与任何著名AI实验室无关的人也能够访问这个快速迭代和共享的生态系统，并在某些情况下改进最先进的结果。这伴随着一定的风险，因为任何旨在减少某些危害的限制都可能被下游用户移除。这将更难防止复制内容的创作或执行现有的版权。
- en: 'Still, there are reasons to be hopeful that these problems won’t stifle creativity,
    but foster it. Cory Doctorow, an internet activist and author, has long been critical
    of copyright, pointing out that while the terms of these rights have gotten longer
    and broader over time, creators haven’t reaped the profits—companies that purchase
    their copyrights have [[65]](https://doctorow.medium.com/copyright-wont-solve-creators-generative-ai-problem-92d7adbcc6e6).
    Skeptical of broadening copyright even further to prevent generative models from
    accessing those works for their training, Doctorow wrote:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我们有理由相信这些问题不会扼杀创造力，反而会促进它。互联网活动家和作家Cory Doctorow长期以来一直批评版权，指出尽管这些权利的条款随着时间的推移而变得更长、更广泛，但创作者并没有从中获利——购买他们版权的公司[65](https://doctorow.medium.com/copyright-wont-solve-creators-generative-ai-problem-92d7adbcc6e6)。Doctorow对进一步扩大版权以防止生成模型访问这些作品进行训练持怀疑态度，他写道：
- en: 'Fundamentally, machine learning systems ingest a lot of works, analyze them,
    find statistical correlations between them, and then use those to make new works.
    It’s a math-heavy version of what every creator does: analyze how the works they
    admire are made, so they can make their own new works. If you go through the pages
    of an art-book analyzing the color schemes or ratios of noses to foreheads in
    paintings you like, you are not infringing copyright. We should not create a new
    right to decide who is allowed to think hard about your creative works and learn
    from them—such a right would make it impossible for the next generation of creators
    to (lawfully) learn their craft. [[65]](https://doctorow.medium.com/copyright-wont-solve-creators-generative-ai-problem-92d7adbcc6e6)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，机器学习系统会摄入大量的作品，分析它们，找出它们之间的统计相关性，然后利用这些相关性来创作新的作品。这就像是每个创作者都会做的事情的数学化版本：分析他们所钦佩的作品是如何制作的，以便他们可以创作出自己的新作品。如果你翻阅一本艺术书籍，分析你喜欢的画作中的色彩方案或鼻与额头之间的比例，你并没有侵犯版权。我们不应该创造一个新的权利来决定谁有权深入思考你的创意作品并从中学习——这样的权利将使下一代创作者无法（合法地）学习他们的技艺。[65](https://doctorow.medium.com/copyright-wont-solve-creators-generative-ai-problem-92d7adbcc6e6)
- en: People may reasonably disagree over whether and how large-scale models should
    be trained on copyrighted data. It’s certain that we’ll get more clarity from
    a legal perspective as these cases continue to progress and as precedents are
    established. But earlier artists also worried over the invention of photography
    that no one would continue to paint or purchase paintings because they could no
    longer compete with the camera in the depiction of reality. Instead, artists continued
    to paint, but they conveyed scenes with their own interpretations and expressions
    [[66]](https://www.thecollector.com/how-photography-transformed-art/). It seems
    possible that generative models will become another medium, without ever entirely
    fulfilling the human need for beauty nor replacing the human impulse toward creativity.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 人们可能合理地就是否以及如何在大规模模型上使用受版权保护的数据存在分歧。可以肯定的是，随着这些案件的继续发展和先例的建立，我们将从法律角度获得更多的清晰度。但早期的艺术家也对摄影的发明感到担忧，因为没有人会继续绘画或购买画作，因为他们无法在描绘现实方面与相机竞争。相反，艺术家继续绘画，但他们通过自己的解释和表达来传达场景
    [[66]](https://www.thecollector.com/how-photography-transformed-art/)。似乎生成模型将成为另一种媒介，而永远不会完全满足人类对美的需求，也不会取代人类对创造力的冲动。
- en: Summary
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Synthetic media, or more specifically, AI-generated media, is an umbrella term
    for content that has been created or altered with the help of AI, which spans
    text, image, video, voice, and data.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 综合媒体，或更具体地说，AI生成媒体，是一个涵盖使用AI创建或修改的内容的总称，这些内容包括文本、图像、视频、声音和数据。
- en: The term *deepfak**e*—a portmanteau of “deep learning” and “fake”—is sometimes
    used synonymously with visual synthetic media, but it often has a negative connotation.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 术语*深度伪造*——由“深度学习”和“伪造”组合而成——有时与视觉合成媒体同义使用，但它通常带有负面含义。
- en: Autoencoders use neural networks to compress and decompress images, and they
    are often used in face-swapping technology.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动编码器使用神经网络来压缩和解压缩图像，它们通常用于人脸交换技术。
- en: GANs consist of two neural networks—a generator and a discriminator. The generator
    exists to create new data, such as images, and the discriminator verifies the
    authenticity of an image by comparing it to the training dataset to determine
    the difference between a fake and a real image.
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GANs由两个神经网络组成——一个生成器和一个人工智能判别器。生成器存在是为了创建新的数据，例如图像，判别器通过将图像与训练数据集进行比较来验证图像的真实性，以确定虚假图像和真实图像之间的差异。
- en: Synthetic media is democratizing content creation and creativity for everyone
    while ushering in a new wave of creativity and art.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 综合媒体正在使内容创作和创意对每个人来说都更加民主化，同时引领新一波创意和艺术。
- en: Generative AI has also infamously been used to create mis/disinformation content,
    celebrity pornographic videos, revenge porn or cybersexual harassment, and fraud
    and espionage.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式AI也臭名昭著地被用于创建虚假/错误信息内容、名人色情视频、报复色情或网络性骚扰、欺诈和间谍活动。
- en: A holistic approach to detect AI-generated media encompassing technical solutions,
    media literacy and education, and appropriate legislation to govern the use of
    the technology is essential to countering deepfakes.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了对抗深度伪造，采用一种综合方法来检测AI生成媒体，包括技术解决方案、媒体素养和教育，以及适当的立法来规范技术的使用是至关重要的。
- en: Generative AI tools have transformed creative work by eliminating monotonous
    tasks, increasing productivity and efficiency, and enabling people to express
    their creativity in new and unprecedented ways.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式AI工具通过消除单调的任务、提高生产力和效率，以及使人们能够以前所未有的方式表达他们的创造力，从而改变了创意工作。
- en: Companies that develop LLMs have been accused of infringing on others’ intellectual
    property, specifically copyrights, via the training process.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发大型语言模型的公司被指控在训练过程中侵犯了他人的知识产权，特别是版权。
- en: In the United States, fair use of copyrighted material is allowed without permission,
    and fair use is determined by four factors as established in the Copyright Act
    of 1976.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在美国，未经许可即可允许公平使用受版权保护的材料，公平使用由1976年版权法确立的四个因素确定。
- en: Although there are pending lawsuits, it seems that most of the activity in the
    generative AI space would be considered fair use under current precedent.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然有悬而未决的诉讼，但似乎在生成式AI领域的多数活动在当前先例下会被认为是公平使用。
- en: '*Open source* refers to the practice of making the source code of software
    accessible to the public to modify and reuse.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*开源*是指使软件源代码可供公众修改和重用的实践。'
- en: The open source and open data movements have accelerated developments and continue
    to drive progress in AI.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开源和开放数据运动加速了发展，并持续推动人工智能的进步。
