- en: Chapter 1\. Introduction to Large Language Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章\. 大型语言模型简介
- en: The rise in popularity of large language models (LLMs) is no accident; they’re
    transforming how we interact with technology and pushing the boundaries of what
    machine learning models can do.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLMs）的流行并非偶然；它们正在改变我们与技术互动的方式，并推动机器学习模型能做什么的边界。
- en: 'But here’s the catch: while these models are impressive, scaling them up and
    managing them in production is no walk in the park. The leap from a research project
    to a fully fledged, reliable tool is filled with obstacles. We’re talking about
    meeting enormous computational requirements, managing complex data, and ensuring
    that everything runs smoothly and securely whether you are self-hosting or using
    proprietary models.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 但这里有个问题：虽然这些模型令人印象深刻，但将它们扩展并管理起来在生产中并非易事。从研究项目到完全成熟、可靠的工具的转变充满了障碍。我们谈论的是满足巨大的计算需求、管理复杂的数据，并确保无论你是自托管还是使用专有模型，一切都能平稳、安全地运行。
- en: Before we dive into the nitty-gritty of LLM operations, it’s important to understand
    why and how these models came to be. Knowing their origins and trajectory helps
    us appreciate the challenges we face when predicting their behaviors in production.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨LLM操作的细节之前，了解这些模型为何以及如何产生是很重要的。了解它们的起源和轨迹有助于我们欣赏在预测它们在生产中的行为时面临的挑战。
- en: The evolution of LLMs reflects a series of incremental innovations, each addressing
    specific limitations of previous models. Early models were limited in scope and
    required extensive human input for even basic tasks. With advancements in architecture,
    such as the shift from recurrent neural networks (RNNs) to transformers, and the
    scaling of model sizes, LLMs have become more sophisticated. This evolution has
    brought about new challenges, such as managing massive amounts of data and ensuring
    efficient training processes.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs的演变反映了一系列渐进式创新，每一项都针对先前模型的特定局限性。早期的模型在范围上有限，即使是基本任务也需要大量的人类输入。随着架构的进步，例如从循环神经网络（RNNs）到转换器的转变，以及模型规模的扩展，LLMs变得更加复杂。这种演变带来了新的挑战，例如管理大量数据并确保高效的训练过程。
- en: So, let’s get into it.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，让我们开始吧。
- en: Some Key Terms
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一些关键术语
- en: 'There are three terms we should clarify before going any further:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，有三个术语我们需要澄清：
- en: Foundation models
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 基座模型
- en: '*Foundation models* are advanced ML architectures that serve as the foundational
    building blocks for creating specialized models. They are pretrained on massive
    datasets, often consisting of text and recently including other data types such
    as code, images, audio, and video to develop general language comprehension and
    pattern recognition capabilities. These models encode statistical relationships
    and linguistic structures from their training data, forming a robust starting
    point for further fine-tuning. This fine-tuning tailors the models to specific
    tasks or applications, such as powering LLMs or other AI-driven solutions.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*基座模型*是高级机器学习架构，是创建专用模型的基础构建块。它们在大量数据集上预训练，通常包括文本，最近还包括代码、图像、音频和视频等其他数据类型，以开发通用的语言理解和模式识别能力。这些模型从其训练数据中编码统计关系和语言结构，形成一个稳健的起点，用于进一步的微调。这种微调使模型针对特定任务或应用进行了定制，例如为LLMs或其他AI驱动解决方案提供动力。'
- en: Large language models
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型
- en: '*Large language models* are specialized implementations of foundation models
    that have undergone additional training or fine-tuning to excel in specific language-based
    tasks. These models are designed to predict and generate human-like text by analyzing
    and emulating natural language patterns. LLMs are highly versatile, supporting
    several natural language processing (NLP) applications such as text generation,
    sentiment analysis, language translation, question answering, and more. Popular
    use cases include chatbots, content creation, multilingual communication, data
    analysis, code generation, recommendation systems, and virtual assistants. [“Enterprise
    Use Cases for LLMs”](#ch01_enterprise_use_cases_for_llms_1748895465616095) will
    look at these applications in more detail.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '*大型语言模型*是经过额外训练或微调的基座模型，旨在在特定的基于语言的任务中表现出色。这些模型通过分析和模拟自然语言模式来预测和生成类似人类的文本。LLMs非常灵活，支持多种自然语言处理（NLP）应用，如文本生成、情感分析、语言翻译、问答等。流行的用例包括聊天机器人、内容创作、多语言交流、数据分析、代码生成、推荐系统和虚拟助手。[“LLMs的企业用例”](#ch01_enterprise_use_cases_for_llms_1748895465616095)将更详细地探讨这些应用。'
- en: Generative AI models
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI模型
- en: '*Generative AI*, or *GenAI*, refers to foundation models that have been trained
    specifically to generate content (images, text, audio, or video) based on the
    patterns and information they have learned. Some of the earliest generative AI
    models were generative adversarial networks (GANs), introduced in 2018; more recently,
    diffusion models, LLMs, and multimodal models like Gemini have become available.
    Given their generative nature, LLMs are considered a subset of generative AI models.
    In the context of LLMs, generative AI can generate text responses, creative stories,
    product descriptions, and more, based on input and learned patterns.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '*生成式AI*，或称*GenAI*，指的是那些专门训练以生成内容（图像、文本、音频或视频）的基础模型，这些内容基于它们所学习的模式和信息。一些最早的生成式AI模型是生成对抗网络（GANs），于2018年提出；最近，扩散模型、LLMs以及像Gemini这样的多模态模型也变得可用。鉴于其生成特性，LLMs被视为生成式AI模型的一个子集。在LLMs的背景下，生成式AI可以根据输入和学习的模式生成文本回复、创意故事、产品描述等。'
- en: Confusingly, these three terms are frequently used interchangeably and loosely.
    For example, a popular image generation model, DALL-E, is better categorized as
    a generative AI model than as a large language model. Recently, however, the DALL-E
    image generation functionality has been integrated into the ChatGPT chatbot, one
    of the most popular LLM applications. Therefore, a user can ask an LLM like ChatGPT
    to generate images. Over time, the language seems to be evolving toward calling
    all of these *AI models,* for simplicity.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 令人困惑的是，这三个术语经常被互换和松散地使用。例如，一个流行的图像生成模型DALL-E，更准确地归类为生成式AI模型，而不是大型语言模型。然而，最近，DALL-E的图像生成功能已被集成到ChatGPT聊天机器人中，这是最受欢迎的LLM应用之一。因此，用户可以向ChatGPT这样的LLM请求生成图像。随着时间的推移，语言似乎正在演变，趋向于将所有这些*AI模型*统称为，以简化。
- en: Transformer Models
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Transformer模型
- en: The transformer model, introduced by the paper [“Attention Is All You Need,”](https://oreil.ly/J8MBW)
    marked one of the biggest shifts in how we approach sequence-based tasks. Transformers
    have set new standards in how to handle language data.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 由论文[“Attention Is All You Need,”](https://oreil.ly/J8MBW)引入的transformer模型，标志着我们在处理基于序列的任务方面的一次重大转变。Transformers在处理语言数据方面设定了新的标准。
- en: 'Before transformers, the most popular solution for NLP tasks was *recurrent
    neural networks*. RNNs process data sequentially, one step at a time, which makes
    them suitable for handling time-dependent data such as text. However, this sequential
    processing introduces a significant drawback: RNNs often struggle to retain information
    from earlier steps as they move forward in the sequence, especially over long
    inputs.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在Transformer出现之前，NLP任务中最受欢迎的解决方案是*循环神经网络*。RNN按顺序逐个处理数据，这使得它们适合处理如文本这样的时间依赖性数据。然而，这种顺序处理引入了一个显著的缺点：当RNN在序列中向前移动时，它们往往难以保留早期步骤的信息，尤其是在处理长输入时。
- en: 'During neural network training, the model processes input data and generates
    predictions. These predictions are compared to the correct answers using a loss
    function, which calculates the error (how far the predictions are from the correct
    answers). An algorithm, such as *backpropagation*, calculates *gradients*: values
    that indicate how the model’s parameters (weights and biases) should be adjusted
    to reduce the error and improve accuracy.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在神经网络训练过程中，模型处理输入数据并生成预测。这些预测通过损失函数与正确答案进行比较，损失函数计算误差（预测与正确答案之间的距离）。一种算法，如*反向传播*，计算*梯度*：指示模型参数（权重和偏差）应该如何调整以减少误差并提高准确性的值。
- en: However, in long sequences like those handled by RNNs, gradients can become
    very small as they are repeatedly multiplied during backpropagation. Over time,
    these small values may shrink so much that computers treat them as zero, effectively
    stopping the model from learning. This issue is known as the *vanishing gradient
    problem*, and it prevents the model from learning long-term dependencies in the
    data.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在像RNN处理的长序列中，梯度在反向传播过程中反复相乘时可能会变得非常小。随着时间的推移，这些小值可能会缩小到如此程度，以至于计算机将它们视为零，从而有效地阻止模型学习。这个问题被称为*梯度消失问题*，它阻止模型在数据中学习长期依赖关系。
- en: '*Transformers*, on the other hand, overcome this limitation by using self-attention
    and parallel processing, allowing them to handle sequences more efficiently and
    capture long-range dependencies effectively. Instead of processing data one step
    at a time, transformers analyze all input tokens (e.g., words in a sentence) simultaneously.
    *Self-attention* is a mechanism that allows each word or token in a sequence to
    focus on other words in the same sequence, regardless of their position. This
    is achieved by calculating a set of attention weights that measure the relevance
    of each token in the sequence to every other token. For instance, in a sentence,
    self-attention can help a word like *it* to align itself with its correct reference,
    even if that reference is several words away. Thus, self-attention allows the
    model to weigh the importance of each token relative to others in the input, enabling
    it to capture relationships across the entire input sequence efficiently. This
    parallel processing not only speeds up computation but also eliminates the issues
    associated with sequential processing, like the vanishing gradient problem.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，*Transformer* 通过使用自注意力机制和并行处理来克服这一限制，使它们能够更有效地处理序列并有效地捕捉长距离依赖关系。Transformer
    不是逐个步骤处理数据，而是同时分析所有输入标记（例如，句子中的单词）。*自注意力* 是一种机制，允许序列中的每个单词或标记关注同一序列中的其他单词，无论它们的位置如何。这是通过计算一组注意力权重来实现的，这些权重衡量序列中每个标记相对于其他标记的相关性。例如，在一个句子中，自注意力可以帮助像
    *it* 这样的单词与其正确的参考对齐，即使那个参考相隔几个单词。因此，自注意力允许模型相对于输入中的其他标记权衡每个标记的重要性，使其能够有效地捕捉整个输入序列中的关系。这种并行处理不仅加快了计算速度，还消除了与顺序处理相关的问题，如梯度消失问题。
- en: Thanks to their ability to manage long-range dependencies and handle vast amounts
    of data, transformer-based models excel in various NLP tasks, including translation,
    summarization, and question answering. Their ability to focus on different parts
    of the sequence regardless of their relative distance, along with positional encoding
    to retain sequence order, allows transformers to handle long sequences without
    losing context.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 由于它们能够管理长距离依赖关系并处理大量数据，基于 Transformer 的模型在翻译、摘要和问答等 NLP 任务中表现出色。它们能够关注序列的不同部分，而不管它们的相对距离如何，加上位置编码以保留序列顺序，使
    Transformer 能够处理长序列而不会丢失上下文。
- en: Some people wondered, “Well, since they can be scaled much better now, how about
    we throw more computing power and a lot more data at these models to see what
    happens?” Models like GPT-3, LLaMA, and their successors demonstrated that increasing
    the number of parameters can significantly improve the performance of transformer
    models.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 有些人想知道：“既然它们现在可以更好地扩展，我们为什么不把这些计算能力和大量数据投入到这些模型中，看看会发生什么？” GPT-3、LLaMA 及其继任者表明，增加参数数量可以显著提高
    Transformer 模型的性能。
- en: Transformers have extended their influence beyond NLP into image processing
    with innovations like the *vision transformer* (ViT), which treats image patches
    as sequences and applies transformer models to them. ViT has shown promising results
    in image classification, offering a viable alternative to the previous solution,
    convolutional neural networks (CNNs). Additionally, in recommender systems, transformers’
    ability to model complex patterns and dependencies enhances accuracy and personalization.
    [Table 1-1](#ch01_table_1_1748895465606161) compares the abilities of the neural
    network models we’ve discussed.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer 通过像 *视觉Transformer* (ViT) 这样的创新扩展了其影响力，将图像块视为序列并应用 Transformer 模型。ViT
    在图像分类中显示出有希望的结果，为之前的解决方案——卷积神经网络 (CNNs) 提供了可行的替代方案。此外，在推荐系统中，Transformer 模型建模复杂模式和依赖关系的能力提高了准确性和个性化。[表
    1-1](#ch01_table_1_1748895465606161) 比较了我们讨论的神经网络模型的能力。
- en: Table 1-1\. The evolution of different neural network models
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1-1\. 不同神经网络模型的演变
- en: '|   | CNNs | RNNs | Transformers |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '|   | CNNs | RNNs | Transformers |'
- en: '| --- | --- | --- | --- |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Application | Best suited for spatial-based tasks (e.g., images) | Well suited
    for sequence-based tasks (e.g., NLP) | Well suited for capturing all three modalities:
    images, NLP, and speech |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 应用 | 最适合基于空间的任务（例如，图像） | 适合基于序列的任务（例如，NLP） | 适合捕捉所有三种模态：图像、NLP 和语音 |'
- en: '| Computation | Highly parallelizable input processing | Sequential processing
    | Parallel processing of inputs |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 计算 | 高度可并行化的输入处理 | 顺序处理 | 输入的并行处理 |'
- en: '| Performance on language-specific tasks | Need large number of stacked convolution
    blocks for handling long-range dependencies | Can handle long-range dependencies
    much better than CNNs but can handle the dependencies well only to a given length
    | Can handle long- to very-long-range dependencies much better than other architectures
    such as RNNs or LSTMs |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 语言特定任务的性能 | 需要大量堆叠的卷积块来处理长距离依赖 | 比卷积神经网络（CNNs）更好地处理长距离依赖，但只能很好地处理到一定长度的依赖
    | 比其他架构（如 RNNs 或 LSTMs）更好地处理长到非常长的距离依赖 |'
- en: '| Scalability | Scalable | Limited scalability | Highly scalable |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 可扩展性 | 可扩展 | 扩展性有限 | 高度可扩展 |'
- en: '| Data requirements | Work well even on small datasets | Work well even on
    small datasets | Don’t work well on small datasets |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 数据需求 | 即使在小型数据集上也能表现良好 | 即使在小型数据集上也能表现良好 | 在小型数据集上表现不佳 |'
- en: '| Ease of training | Easy to train and tune | Require more tuning than CNNs
    | Difficult to train and tune |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 训练的简便性 | 容易训练和调整 | 需要更多的调整比 CNNs | 难以训练和调整 |'
- en: '| Interpretability | Easy to debug | Difficult to debug | Difficult to debug
    |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 可解释性 | 容易调试 | 调试困难 | 调试困难 |'
- en: '| Deployment | Easy to deploy | Easy to deploy | Difficult to deploy |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 部署 | 容易部署 | 容易部署 | 部署困难 |'
- en: '| Small edge devices | Works well on edge devices | Works well on edge devices
    | Limited support for edge devices |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 小型边缘设备 | 在边缘设备上表现良好 | 在边缘设备上表现良好 | 对边缘设备的支持有限 |'
- en: '| Explainability | Supports wide variety of explainability | Limited explainability
    | Very limited explainability |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 可解释性 | 支持广泛的解释性 | 解释性有限 | 解释性非常有限 |'
- en: This trend of throwing more compute and data at transformers is what sparked
    the evolution of LLMs, as well as the shift from an architecture that can do well
    on a single modality to one that generalizes on most modalities. Understanding
    this evolution can help you appreciate the differences in model architectures.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 将更多的计算和数据投入到 Transformer 中这一趋势引发了 LLMs 的演变，以及从单一模态上表现良好的架构向在大多数模态上泛化的架构的转变。理解这一演变可以帮助你欣赏模型架构之间的差异。
- en: Large Language Models
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大型语言模型
- en: LLMs excel at understanding context and making associations among words, phrases,
    and concepts to provide relevant information based on the input query or prompt.
    While structured knowledge bases rely on human-curated data, LLMs can automatically
    extract knowledge from unstructured text. When trained on diverse textual sources,
    they can process a vast amount of information without explicit human intervention.
    However, this also introduces a challenge, as the model can learn biased or incorrect
    information from the training data.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 在理解上下文和根据输入查询或提示在单词、短语和概念之间建立关联以提供相关信息方面表现出色。虽然结构化知识库依赖于人工整理的数据，但 LLMs
    可以自动从非结构化文本中提取知识。当在多样化的文本源上进行训练时，它们可以处理大量信息，而无需明确的人类干预。然而，这也带来了一定的挑战，因为模型可能会从训练数据中学习到有偏见或不正确的信息。
- en: LLMs are also designed to understand and generate human-like text and to be
    accessible through natural language queries in conversational, interactive settings.
    This makes them convenient and user-friendly for retrieving information and obtaining
    responses.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 还被设计成能够理解和生成类似人类的文本，并通过自然语言查询在对话和交互环境中进行访问。这使得它们在检索信息和获取响应时既方便又用户友好。
- en: These models are “large” not just because of the amount of data they’re trained
    on but also because of their number of parameters. Think of *parameters* as being
    like “knobs” inside the models that may be adjusted during training to help the
    models learn better. In neural networks, parameters are weights and biases. When
    an input like a prompt is presented to a model, it first transforms the input
    into a numerical representation, and then the numbers are processed through the
    neural network. Each node in the neural network contains a bias, adding or subtracting
    to the input value, and each connection between nodes contains a weight that will
    multiply the value of the input as it passes through nodes. Using more parameters
    greatly extends the capabilities of traditional transformer models, but not without
    massive trade-offs in cost and evaluation complexity.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型之所以“大”，不仅是因为它们训练的数据量，还因为它们的参数数量。将*参数*想象成模型内部的“旋钮”，在训练过程中可以调整以帮助模型更好地学习。在神经网络中，参数是权重和偏差。当将类似提示的输入呈现给模型时，它首先将输入转换为数值表示，然后这些数字通过神经网络进行处理。神经网络中的每个节点都包含一个偏差，它会向输入值添加或减去，而节点之间的每个连接都包含一个权重，该权重会在节点传递过程中乘以输入值。使用更多的参数极大地扩展了传统Transformer模型的能力，但这也带来了成本和评估复杂性的巨大权衡。
- en: There are two basic categories of LLMs, discriminative and generative. *Discriminative
    models*, such as ​BERT (Bidirectional Encoder Representations from Transformers),
    which was introduced in 2018, learn the boundary between classes in a classification
    problem. They’re concerned with the conditional probability *P*(*y*|*x*), which
    is the probability of the output given the input. Discriminative transformer models
    are typically used for tasks like text classification, sentiment analysis, and
    named-entity recognition, where the goal is to predict a label or category given
    some input ​text.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: LLM有两种基本类别：判别型和生成型。*判别模型*，如2018年推出的BERT（来自Transformer的双向编码器表示），学习分类问题中类别的边界。它们关注的是条件概率*P*(*y*|*x*)，即给定输入的输出概率。判别型Transformer模型通常用于文本分类、情感分析和命名实体识别等任务，其目标是根据某些输入文本预测标签或类别。
- en: '*Generative models*, such as GPT-3 and GPT-4, learn the joint probability distribution
    of the input and the output, or *P*(*x*, *y*), and can generate new data points
    similar to the training data. Generative models are used for tasks like text generation,
    where the goal is to generate new text similar to the text the model was trained
    on. Not all LLMs need to be generative, although most are. Throughout this book,
    when we refer to “LLMs,” we mean generative LLMs.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*生成模型*，如GPT-3和GPT-4，学习输入和输出的联合概率分布，即*P*(*x*, *y*)，并可以生成与训练数据相似的新数据点。生成模型用于文本生成等任务，其目标是生成与模型训练文本相似的新文本。虽然大多数LLM都需要是生成性的，但并非所有LLM都需要。在这本书中，当我们提到“LLMs”时，我们指的是生成型LLM。'
- en: LLM Architectures
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM架构
- en: 'There are two main types of architecture for language models: encoders and
    decoders. Encoders and decoders can also be combined, and there is ongoing research
    on new architectures.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型主要有两种架构：编码器和解码器。编码器和解码器也可以组合使用，并且正在研究新的架构。
- en: Encoder-Only LLMs
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 仅编码器型LLM
- en: '*Encoder-only models* are designed​ to process and comprehend input text, transforming
    it into a meaningful representation or embedding. *Embeddings* are numerical representations
    of data, such as words, phrases, or sentences, in a high-dimensional vector space.
    Embeddings capture meaning and context in a way that results in words with similar
    meanings or contexts being placed close together in this vector space. This representation
    captures the essence of the input, making it suitable for tasks where understanding
    the context is needed.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*仅编码器模型*旨在处理和理解输入文本，将其转换为有意义的表示或嵌入。*嵌入*是数据（如单词、短语或句子）在多维向量空间中的数值表示。嵌入以捕捉意义和上下文的方式，使得具有相似意义或上下文的单词在这个向量空间中彼此靠近。这种表示捕捉了输入的本质，使其适用于需要理解上下文的任务。'
- en: One of the most notable examples of an encoder-only model is [BERT](https://oreil.ly/f2AL4).
    During its pretraining phase, BERT uses *masked language modeling*, a technique
    where random words in the text are masked and the model learns to predict these
    masked words based on the surrounding context. BERT is also trained using next-sentence
    prediction, where it determines whether one sentence follows another ​logically.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 最显著的仅编码器模型例子之一是[BERT](https://oreil.ly/f2AL4)。在其预训练阶段，BERT使用*掩码语言建模*技术，其中文本中的随机单词被掩码，模型学习根据周围上下文预测这些掩码单词。BERT还使用下一句预测进行训练，其中它确定一个句子是否逻辑上跟随另一个句子。
- en: The primary advantage of encoder-only models lies in their syntactic understanding
    of text; i.e., their ability to capture the intricate relationships between words
    and their contexts. These models excel in tasks such as sentiment analysis, named-entity
    recognition, and question answering.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 仅编码器模型的主要优势在于其对文本的句法理解；即，它们捕捉单词及其上下文之间复杂关系的本领。这些模型在情感分析、命名实体识别和问答等任务上表现出色。
- en: However, encoder-only models have their limitations. They are not designed for
    generating new text; their focus is solely on understanding and analyzing the
    input. This limitation can be restrictive when using them in applications requiring
    text generation or completion.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，仅编码器模型有其局限性。它们并非为生成新文本而设计；它们的重点是理解和分析输入。当用于需要文本生成或补全的应用时，这种局限性可能会受到限制。
- en: Decoder-Only LLMs
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 仅解码器LLM
- en: '*Decoder-only models* are good​ at generating coherent and contextually relevant
    text based on an input or prompt. Examples of this architecture are the generative
    pretrained transformer (GPT) series, including GPT-2, GPT-3, and the most recent
    GPT-4.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '*仅解码器模型*擅长根据输入或提示生成连贯且与上下文相关的文本。这类架构的例子包括生成预训练的Transformer系列，包括GPT-2、GPT-3以及最新的GPT-4。'
- en: These models are pretrained using a *language modeling objective*. With this
    technique, they learn to predict the next word in a sequence given the preceding
    context, allowing them to generate text that flows naturally and maintains coherence
    over longer passages.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模型使用*语言建模目标*进行预训练。通过这种技术，它们学习根据先前的上下文预测序列中的下一个单词，从而使它们能够生成自然流畅且在较长的段落中保持连贯性的文本。
- en: The key advantage of decoder-only models is their ability to generate high-quality
    text. This makes them extremely effective for tasks such as text completion, summarization,
    and creative writing. They also exhibit *emergent properties*, meaning that they
    can perform tasks beyond their initial training objective, such as translation
    and question answering, without additional fine-tuning.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 仅解码器模型的关键优势在于其生成高质量文本的能力。这使得它们在文本补全、摘要和创意写作等任务上极为有效。它们还展现出*涌现特性*，意味着它们可以执行超出其初始训练目标的任务，如翻译和问答，而无需额外的微调。
- en: However, their focus on text generation can be a limitation in tasks requiring
    deep understanding of the input text. Decoder-only models generate text based
    on patterns learned during training, which may not always align with the specific
    nuances of the input.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，它们对文本生成的关注可能会成为需要深入理解输入文本的任务中的局限性。仅解码器模型根据训练期间学习的模式生成文本，这些模式可能并不总是与输入的具体细微差别相一致。
- en: Encoder–Decoder LLMs
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编码器-解码器LLM
- en: '*Encoder–decoder models* combine​ the strengths of both encoder and decoder
    architectures, making them suitable for tasks involving complex mappings between
    input and output sequences.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*编码器-解码器模型*结合了编码器和解码器架构的优点，使它们适合涉及输入和输出序列之间复杂映射的任务。'
- en: In this setup, the encoder processes the input text to create an embedding,
    which the decoder then uses to generate the output text. Notable examples include
    Bidirectional and Auto-Regressive Transformer (BART) and Text-To-Text Transfer
    Transformer (T5). BART, introduced in 2019, is trained using *denoising auto-encoding*,
    where parts of the input text are corrupted and the model learns to reconstruct
    the original text.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种设置中，编码器处理输入文本以创建嵌入，然后解码器使用这些嵌入来生成输出文本。显著的例子包括双向和自回归Transformer（BART）以及文本到文本迁移Transformer（T5）。BART于2019年推出，使用*去噪自编码*进行训练，其中输入文本的部分被损坏，模型学习重建原始文本。
- en: The encoder–decoder architecture excels at tasks where the input and output
    are different in structure and length, such as machine translation and text summarization.
    However, the complexity of training and the computational resources these models
    require can be a drawback. Their dual architecture means they must effectively
    integrate both components, which can be demanding in terms of both data and processing
    power.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 编码器-解码器架构在输入和输出在结构和长度上不同的情况下表现优异，例如机器翻译和文本摘要。然而，这些模型的训练复杂性和所需的计算资源可能是一个缺点。它们的双架构意味着它们必须有效地整合这两个组件，这在数据和处理能力方面可能要求很高。
- en: State Space Architectures
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 状态空间架构
- en: A new approach tries to solve one of the problems with transformers, which is
    that the self-attention mechanism has *quadratic complexity*. This means that
    the number of computations required for inferencing grows with the square of input
    size, since the relationship between each pair of tokens needs to be modeled.
    Mathematically, it is often represented as *O*(*n*²), where *n* is the number
    of tokens (words or subwords in a sentence). Quadratic complexity is generally
    a hard computational problem, especially when using larger datasets.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 一种新的方法试图解决转换器的一个问题，即自注意力机制具有*二次复杂度*。这意味着推理所需的计算量随着输入大小的平方增长，因为需要为每一对标记建模关系。从数学上讲，它通常表示为*O*(*n*²)，其中*n*是标记（句子中的单词或子词）的数量。二次复杂度通常是一个难以解决的计算问题，尤其是在使用大型数据集时。
- en: The *state space architecture* replaces the transformer approach by incorporating
    *state space representations*, which model the state of the system instead of
    recording it at each step. This compression allows for linear computational complexity,
    improving computational performance and reducing memory requirements, but it increases
    the rate of error.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '*状态空间架构*通过采用*状态空间表示*来取代转换器方法，这些表示模型系统的状态而不是在每一步记录它。这种压缩允许线性计算复杂度，提高了计算性能并减少了内存需求，但会增加错误率。'
- en: Researchers are trying to solve the error problem. Recent examples are [Mamba
    and Mamba-2](https://oreil.ly/p3rqX), which create a state representation that
    dynamically attempts to determine the important parts of the prompt by modeling
    importance as a state space parameter. In experimental settings, Mamba performs
    as well as a transformer-based model that has double the number of parameters
    for small and medium prompts but still has not delivered on the promise of low
    error rates for larger prompts.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员正在尝试解决错误问题。最近的例子是[Mamba和Mamba-2](https://oreil.ly/p3rqX)，它们创建了一个状态表示，通过将重要性建模为状态空间参数，动态地尝试确定提示中的重要部分。在实验设置中，Mamba对于小型和中型提示的表现与具有双倍参数数量的基于转换器的模型相当，但仍然没有实现对于大型提示的低错误率承诺。
- en: Each LLM architectural design has its own sets of strengths and limitations.
    Encoder-only models like BERT are highly effective for understanding and analyzing
    text but fall short in generating new content. Decoder-only models, exemplified
    by the GPT series, excel in generating coherent and contextually relevant text
    but are nondeterministic, which can be problematic for some applications like
    text classification. Emerging architectures like state space models, which promise
    enhancements in performance and applicability, should be monitored, but they haven’t
    been proven yet.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 每个大型语言模型（LLM）的架构设计都有其自身的优势和局限性。仅编码器模型，如BERT，在理解和分析文本方面非常有效，但在生成新内容方面表现不足。仅解码器模型，以GPT系列为例，在生成连贯且上下文相关的文本方面表现优异，但它们是非确定性的，这可能会对某些应用，如文本分类，造成问题。新兴的架构，如状态空间模型，承诺在性能和适用性方面有所提升，应该受到关注，但它们尚未得到证实。
- en: Small Language Models
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 小型语言模型
- en: Another recent development is *small language models* (SLMs), which are compact,
    efficient language models designed to perform NLP tasks while using fewer computational
    resources than LLMs.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 另一项最近的发展是*小型语言模型*（SLMs），这些模型紧凑高效，旨在执行NLP任务，同时使用的计算资源比大型语言模型（LLMs）少。
- en: Unlike LLMs, which contain billions of parameters and require substantial memory
    and processing power, SLMs are often designed to have millions or even just hundreds
    of thousands of parameters. The trade-off is that they must focus on specific
    tasks or subjects. This makes them lightweight, cost-effective, and deployable
    on a wider range of devices, including mobile phones, IoT edge devices, and in
    environments with limited computational resources. The development of SLMs has
    been driven by the demand for efficient, accessible AI solutions that can operate
    in real time and offline, providing functionality without relying on cloud-based
    infrastructure.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 与包含数十亿参数且需要大量内存和处理能力的LLMs不同，SLMs通常设计为具有数百万甚至只有数十万参数。这种权衡是它们必须专注于特定任务或主题。这使得它们轻量级、成本效益高，并且可以在更广泛的设备上部署，包括移动电话、物联网边缘设备和计算资源有限的环境中。SLMs的发展是由对高效、易于访问的AI解决方案的需求所驱动的，这些解决方案可以在实时和离线环境中运行，提供功能而不依赖于基于云的基础设施。
- en: SLMs do not perform well on tasks that require contextual understanding, extensive
    memory, or reasoning abilities. They are not intended for more general problem-solving
    and need to be fine-tuned on specific datasets to perform well on particular tasks,
    maximizing efficiency while maintaining accuracy within a defined scope. While
    LLMs tend to perform several NLP tasks reasonably well in a large number of domains,
    SLMs need to be specifically trained. For instance, an LLM might be able to perform
    moderately well at summarizing legal documents as well as medical articles, while
    an SLM would excel in one and perform poorly at the other.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: SLMs在需要上下文理解、广泛记忆或推理能力的任务上表现不佳。它们不是为了更通用的问题解决而设计的，并且需要在特定数据集上进行微调以在特定任务上表现良好，从而在定义的范围内最大化效率并保持准确性。虽然LLMs在大量领域内倾向于合理地执行多个NLP任务，但SLMs需要专门训练。例如，一个LLM可能在总结法律文件和医学文章方面表现中等，而一个SLM可能在其中一个方面表现出色，而在另一个方面表现不佳。
- en: Choosing an LLM
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择LLM
- en: In the LLM world, it’s easy to get swept up in the excitement of the latest
    breakthroughs and cutting-edge technologies. New models pop up all the time. The
    truth is, selecting the right LLM is more than just a technical decision; it’s
    a strategic choice with far-reaching implications.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLM的世界里，很容易被最新的突破和尖端技术的兴奋所席卷。新的模型不断涌现。事实是，选择正确的LLM不仅仅是一个技术决策；它是一个具有深远影响的战略选择。
- en: Considerations in the Selection of an LLM
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选择大型语言模型（LLM）时的考虑因素
- en: 'Here are five reasons why the model you choose can make all the difference:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是五个为什么你选择的模型可以产生重大差异的原因：
- en: Alignment with objectives
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 与目标的一致性
- en: Are you looking for a model that excels at generating human-like text? Or do
    you need one that can understand complex queries and provide accurate responses?
    The specific capabilities of different models can vary significantly. Some are
    designed with a focus on conversational abilities, while others are optimized
    for tasks like summarization or translation. Choosing a model that aligns with
    your objectives ensures that you’re investing in a tool that will deliver the
    results you need.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 你是否在寻找擅长生成类似人类文本的模型？或者你需要一个能够理解复杂查询并提供准确响应的模型？不同模型的具体能力可能存在显著差异。有些模型设计时侧重于对话能力，而其他模型则针对摘要或翻译等任务进行了优化。选择与你的目标一致的模型可以确保你投资的是一个能够提供所需结果的工具。
- en: Performance and efficiency
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 性能和效率
- en: Not all LLMs are created equal. Larger models might offer impressive performance
    and efficiency, but they often come with high computational costs and slower response
    times. Smaller, more optimized models tend to provide faster results and be more
    cost-effective, but rarely do they match the performance of their larger counterparts.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有LLM都是同等创建的。较大的模型可能提供令人印象深刻的性能和效率，但它们通常伴随着高昂的计算成本和较慢的响应时间。较小、更优化的模型往往能提供更快的成果，并且更具成本效益，但很少能匹配其大型同行的性能。
- en: Training data and bias
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据和偏差
- en: The training data used to develop an LLM shapes its behavior and outputs. Variations
    in the datasets on which models are trained can lead to variations in how they
    handle specific topics or issues. Some models exhibit biases based on their training
    data, which can impact the accuracy and fairness of their responses. Choosing
    a model with a diverse and representative training dataset can help mitigate these
    risks and ensure more reliable and equitable outcomes.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 用于开发LLM的训练数据塑造了其行为和输出。模型训练数据集的差异可能导致它们在处理特定主题或问题时出现差异。一些模型基于其训练数据表现出偏见，这可能影响其响应的准确性和公平性。选择具有多样化和代表性训练数据集的模型可以帮助减轻这些风险，并确保更可靠和公平的结果。
- en: Customization and adaptability
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 定制化和适应性
- en: Your needs might not fit neatly into the one-size-fits-all approach of a generic
    LLM. Some models offer greater flexibility and can be fine-tuned or customized
    to better suit your specific requirements. If that’s what you need, choose one
    with strong customization capabilities so that you can mold it to better fit your
    use case.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 您的需求可能无法完美地适应通用LLM的“一刀切”方法。一些模型提供了更大的灵活性，可以被微调或定制以更好地满足您的特定需求。如果您需要这样的模型，请选择具有强大定制能力的模型，以便您可以根据自己的使用场景对其进行调整。
- en: Integration and support
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 集成和支持
- en: The practical aspects of integrating an LLM into your existing systems and workflows
    cannot be overlooked. Some models come with robust support and documentation,
    making integration smoother and less time-consuming. Others require more effort
    to set up and maintain. Considering how well a model integrates with your infrastructure
    and the level of support available can save you time and reduce headaches over
    the long run.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 将LLM集成到现有系统和工作流程中的实际方面不容忽视。一些模型附带强大的支持和文档，使集成更加顺畅且耗时更少。其他模型则需要更多努力来设置和维护。考虑模型与您的基础设施集成的情况以及可用的支持水平，可以在长期内节省您的时间和减少头痛。
- en: 'Overall, the LLM model you choose is not just a technical decision; it’s a
    strategic one that impacts the effectiveness, efficiency, and overall success
    of your AI initiatives. Remember: the model you choose matters. By carefully evaluating
    your needs and understanding the strengths and limitations of different models,
    you can make an informed choice that aligns with your goals and sets you up for
    success.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，您选择的LLM模型不仅仅是一个技术决策；它是一个战略决策，它影响着您AI项目的有效性、效率和整体成功。记住：您选择的模型很重要。通过仔细评估您的需求并了解不同模型的优势和局限性，您可以做出明智的选择，与您的目标保持一致，并为您成功奠定基础。
- en: 'The Big Debate: Open Source Versus Proprietary LLMs'
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大辩论：开源与专有LLM
- en: Companies must navigate a complex landscape when choosing among open source,
    closed-source, and open weight LLMs. [Figure 1-1](#ch01_figure_1_1748895465600862)
    shows the choices of a sample of companies today. This section looks at each option’s
    limitations and benefits.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 当公司在选择开源、闭源和开放权重LLM时，必须在一个复杂的环境中导航。[图1-1](#ch01_figure_1_1748895465600862)展示了今天一些公司的选择。本节将探讨每个选项的局限性和优点。
- en: '![](assets/llmo_0101.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/llmo_0101.png)'
- en: 'Figure 1-1\. Enterprise adoption of different proprietary LLMs (source: [Andreessen
    Horowitz](https://oreil.ly/lqXYT))'
  id: totrans-87
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1\. 企业对不同专有LLM的采用（来源：[Andreessen Horowitz](https://oreil.ly/lqXYT)）
- en: Open source and open weight LLMs
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开源和开放权重LLM
- en: Open source and open weight are two types of publicly accessible LLMs that have
    gained traction in the AI community as of this writing, particularly among those
    looking to customize, deploy, or study advanced AI without relying on proprietary
    solutions.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 开源和开放权重是两种公开可访问的LLM类型，截至本文撰写时，在AI社区中获得了广泛关注，尤其是那些希望在不依赖专有解决方案的情况下定制、部署或研究高级AI的人。
- en: '*Open source* LLMs are models with freely available underlying source code.
    Anyone can inspect, modify, and potentially redistribute the model and its architecture.
    These models typically include details about the architecture, training methods,
    and source code for the framework. Using open source models provides technical
    transparency and adaptability and fosters a community of collaboration. However,
    open source LLMs may or may not come with pretrained weights, the trained parameters
    that make the model functional and useful for specific tasks. These weights are
    the model’s “knowledge” gained from its training on large datasets and are essential
    for the model to perform effectively without retraining from scratch. Companies
    that want to take advantage of such models may need to acquire the training data
    themselves.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '*开源* LLM 是具有免费可用底层源代码的模型。任何人都可以检查、修改，并可能重新分发模型及其架构。这些模型通常包括关于架构、训练方法和框架源代码的详细信息。使用开源模型提供了技术透明度和适应性，并促进了协作社区的形成。然而，开源
    LLM 可能包含或不包含预训练权重，这些权重是模型从大型数据集训练中获得的知识，对于模型在没有从头开始重新训练的情况下有效地执行特定任务至关重要。希望利用此类模型的公司可能需要自行获取训练数据。'
- en: With *open weight* LLMs, the weights are publicly accessible. Having access
    to the weights means that users can directly deploy the model for real-world applications
    like text generation, summarization, and translation or fine-tune it on their
    own data. While many open weight models are also open source, some restrict use
    for commercial applications or require adherence to specific licensing terms,
    as seen with models like Meta’s Llama series.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 *开放权重* LLM，权重是公开可访问的。有权访问权重意味着用户可以直接将模型部署到现实世界的应用中，如文本生成、摘要和翻译，或者在自己的数据上对其进行微调。虽然许多开放权重模型也是开源的，但一些模型限制了商业应用的使用或要求遵守特定的许可条款，例如
    Meta 的 Llama 系列模型。
- en: The distinction between open source and open weight LLMs is crucial in determining
    how accessible and useful a model is “out of the box.” Open source models without
    weights can still allow for architectural experimentation and model-training setups,
    but they lack immediate functionality for practical applications until they are
    trained, and training requires substantial computational resources. In contrast,
    open weight models provide ready-to-use capabilities, making them more accessible
    to developers who do not have the resources for large-scale model training but
    want to fine-tune or deploy a pretrained model.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 开源模型与开放权重 LLM 之间的区别对于确定模型“开箱即用”时的可访问性和实用性至关重要。没有权重的开源模型仍然可以进行架构实验和模型训练设置，但在训练之前它们缺乏实际应用的功能，而训练则需要大量的计算资源。相比之下，开放权重模型提供了现成的功能，使得那些没有大规模模型训练资源但希望微调或部署预训练模型的开发者更容易访问。
- en: By leveraging open source and/or open weight models such as Llama or Mistral,
    companies can deploy models on existing hardware. This can be more cost-effective
    than using cloud-based proprietary solutions, which involve renting hardware.
    Such an approach can be particularly advantageous for startups or small to medium
    enterprises (SMEs) operating under tight budget constraints. For these companies,
    the financial savings can free up resources for other needs, like fine-tuning.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用开源和/或开放权重模型，如 Llama 或 Mistral，公司可以在现有硬件上部署模型。这比使用涉及租赁硬件的基于云的专有解决方案更经济高效。这种方法对于在预算紧张的情况下运营的初创公司或小型至中型企业（SMEs）尤其有利。对于这些公司，财务节省可以释放资源用于其他需求，如微调。
- en: A company may have requirements besides financial concerns, such as wanting
    to ensure that the training data includes or excludes specific datasets. In these
    cases, an open weight model is not sufficient; the business really needs an open
    source model. For example, a company may want to guarantee that a model has never
    seen a specific data point; an open weight model whose training dataset is not
    shared can’t offer such a guarantee.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 一家公司可能除了财务问题外还有其他要求，例如希望确保训练数据包括或排除特定的数据集。在这些情况下，开放权重模型是不够的；企业真正需要的是开源模型。例如，一家公司可能希望保证模型从未见过特定的数据点；一个训练数据集未公开共享的开放权重模型无法提供这样的保证。
- en: Community support is another potential advantage of open source LLMs. The collaborative
    nature of the open source ecosystem means that developers, researchers, and organizations
    continuously contribute to improving these models, and newly fine-tuned models
    are easily available via Hugging Face. Companies benefit not only from this collective
    intelligence but also from access to a wider range of resources, tools, and best
    practices. This community-driven development is dynamic and evolving, and it’s
    often where new developments begin.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 社区支持是开源大型语言模型的另一个潜在优势。开源生态系统的协作性质意味着开发者、研究人员和组织持续地为改进这些模型做出贡献，并且通过Hugging Face可以轻松地获得新微调的模型。公司不仅从这种集体智慧中受益，还从更广泛资源、工具和最佳实践的访问中受益。这种由社区驱动的开发是动态和不断演变的，并且通常是新发展的起点。
- en: However, the open source/open weight approach is not without its challenges.
    Maintenance and support can be significant hurdles. Data privacy and security
    also emerge as big concerns. Transparency can be a double-edged sword, exposing
    a company to potential risks even as it demands significant effort to safeguard
    sensitive information and comply with data protection regulations. Ensuring that
    these models do not become a vector for security breaches requires meticulous
    attention and proactive measures.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，开源/开放权重方法并非没有挑战。维护和支持可能成为重大的障碍。数据隐私和安全也成为一大关注点。透明度可能是一把双刃剑，它要求公司付出巨大的努力来保护敏感信息并遵守数据保护法规，同时它也使公司面临潜在的风险。确保这些模型不会成为安全漏洞的传播途径需要细致的注意和积极的措施。
- en: Scalability and performance are additional considerations. Open source LLMs
    aren’t always optimized for large-scale deployments. Companies with substantial
    operational demands might face performance bottlenecks or scalability challenges.
    The customization required to adapt open source models for enterprise-grade applications
    can be resource intensive and require significant engineering efforts.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展性和性能也是需要考虑的额外因素。开源大型语言模型并不总是针对大规模部署进行优化。对于有大量运营需求的公司来说，可能会面临性能瓶颈或可扩展性挑战。为了适应企业级应用而进行的开源模型定制可能需要大量资源，并需要显著的工程努力。
- en: Open source and open weight language models also introduce security concerns.
    Anyone can immediately use, fine-tune, or modify pretrained open weight models
    and potentially apply them in harmful ways, such as generating misinformation,
    creating realistic fake content, or deploying automated tools for phishing and
    social engineering. Since open weight models’ training data often includes both
    public and proprietary datasets, they can also sometimes unintentionally generate
    or reveal sensitive or biased information embedded in the training data, posing
    privacy risks.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 开源和开放权重语言模型也带来了安全方面的担忧。任何人都可以立即使用、微调或修改预训练的开放权重模型，并可能以有害的方式应用它们，例如生成虚假信息、创建逼真的虚假内容，或部署用于网络钓鱼和社会工程的自动化工具。由于开放权重模型的训练数据通常包括公共和专有数据集，它们有时也可能无意中生成或揭示训练数据中嵌入的敏感或偏见信息，从而带来隐私风险。
- en: Furthermore, open source models, which include the code and architectural blueprints,
    are vulnerable to manipulation and exploitation. Malicious actors can introduce
    harmful code or adjust models to bypass safety mechanisms, then distribute these
    altered versions under the guise of legitimate software. This can lead to scenarios
    where organizations unknowingly adopt models that include backdoors or biased,
    harmful outputs. The decentralized nature of open source development means that
    code modifications don’t always go through rigorous security checks, leaving room
    for vulnerabilities that could be exploited. Addressing these security challenges
    requires adopting responsible AI practices, including rigorous code reviews, security
    audits, and clear usage policies to mitigate risks while promoting open collaboration.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，包括代码和架构蓝图在内的开源模型容易受到操纵和利用。恶意行为者可以引入有害代码或调整模型以绕过安全机制，然后以合法软件的名义分发这些修改后的版本。这可能导致组织在不知情的情况下采用包含后门或偏见、有害输出的模型。开源开发的去中心化性质意味着代码修改并不总是经过严格的安全检查，这留下了可能被利用的漏洞。解决这些安全挑战需要采用负责任的AI实践，包括严格的代码审查、安全审计和明确的用法政策，以减轻风险并促进开放合作。
- en: Carefully review any contractual restrictions on usage before adopting a model.
    You don’t want to build a whole commercial application around an open source LLM
    only to find out that it does not allow commercial usage.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在采用模型之前，仔细审查任何关于使用的合同限制。你不想围绕一个开源LLM构建整个商业应用程序，最后发现它不允许商业使用。
- en: Closed-source LLMs
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 封闭源LLMs
- en: On the other side of the spectrum are *closed-source*, or *proprietary*, LLMs
    such as those developed by leading tech giants. These models often come with robust
    support and maintenance, including dedicated assistance for troubleshooting and
    optimizing performance. This support infrastructure ensures that any issues encountered
    are addressed promptly, allowing companies to focus on their core activities without
    getting sidetracked by technical difficulties.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在光谱的另一端是*封闭源*或*专有*的LLM，例如由领先的科技巨头开发的那些。这些模型通常附带强大的支持和维护，包括专门的故障排除和性能优化协助。这个支持基础设施确保任何遇到的问题都能得到及时解决，使公司能够专注于核心活动，而不会被技术难题所分散。
- en: Closed-source LLMs are generally optimized for large-scale deployments, making
    sure that they can scale with operational loads effectively, so they often come
    with performance guarantees. Their performance benchmarks often reflect their
    ability to deliver consistent and reliable results—a critical factor for companies
    with high operational demands.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 封闭源LLMs通常针对大规模部署进行优化，确保它们能够有效地与运营负载扩展，因此它们通常附带性能保证。它们的性能基准通常反映了它们提供一致和可靠结果的能力——这对于有高运营需求的公司来说是一个关键因素。
- en: One of the primary limitations of the closed-source approach is the high cost.
    Another is the lack of transparency, which means that companies have limited visibility
    into the internal workings of these models. While this concern may seem unusual,
    consider a scenario in which a commercial LLM provider inadvertently consumes
    private data during training. You use this LLM provider for your own application,
    and some of your users realize how to get your application to reveal the private
    data. The people whose data was revealed sue you. We recommend that you fully
    understand what legal protections are in place when using information services
    like third-party LLMs.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 封闭源方法的主要局限性之一是成本高昂。另一个局限性是缺乏透明度，这意味着公司对这些模型的内部运作了解有限。虽然这种担忧可能看起来很奇怪，但考虑一下这种情况：一个商业LLM提供商在训练过程中意外地消耗了私人数据。你使用这个LLM提供商为自己的应用程序服务，而一些用户意识到如何让你的应用程序泄露私人数据。泄露数据的人起诉你。我们建议在使用第三方LLM等信息服务时，你完全了解现有的法律保护措施。
- en: Regardless of these drawbacks, companies are willing to make expensive bets
    right now, hoping for excellent returns in the future from investing in GenAI
    applications.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 无论这些缺点如何，公司现在都愿意下重注，希望从投资GenAI应用中获得未来的丰厚回报。
- en: Enterprise Use Cases for LLMs
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLMs的企业用例
- en: LLMs are transforming enterprise operations in many industries, from changing
    how we retrieve knowledge to enhancing autonomous agents. They do this through
    a handful of applications, including knowledge retrieval, translation, audio–speech
    synthesis, recommender systems, and autonomous agents.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs正在许多行业的业务运营中发挥变革性作用，从改变我们获取知识的方式到增强自主代理。他们通过一系列应用来实现这一点，包括知识检索、翻译、音频-语音合成、推荐系统和自主代理。
- en: Knowledge Retrieval
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 知识检索
- en: People have long used search engines to discover information, but the limitations
    of these tools’ have become more apparent as data volumes and complexity grow.
    LLMs offer a new paradigm for accessing and using information. Unlike conventional
    systems, which rely heavily on keyword matching and ranking algorithms, LLMs bring
    a conversational, personalized approach to information retrieval.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 人们长期以来一直使用搜索引擎来发现信息，但随着数据量和复杂性的增长，这些工具的限制变得更加明显。LLMs为获取和使用信息提供了一种新的范式。与依赖关键字匹配和排名算法的传统系统不同，LLMs将对话和个性化的方法引入信息检索。
- en: Users can engage in long conversations with LLMs. Instead of simply receiving
    a list of links or documents, they can set parameters for the tone, intent, and
    structure of the information they need. This capability transforms the search
    experience from a transactional process into a dynamic dialogue. For example,
    an LLM can interpret a request like “Explain this concept as if I were a beginner,”
    and provide a tailored explanation that’s both accessible and relevant.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 用户可以与LLM进行长时间对话。他们不仅可以收到链接或文档列表，还可以为所需信息的语气、意图和结构设置参数。这种能力将搜索体验从交易过程转变为动态对话。例如，LLM可以解释请求“像初学者一样解释这个概念”，并提供既易于理解又相关的定制解释。
- en: On the data retrieval side, LLMs can enhance productivity tools, for example
    through integrations with office software suites like those from Google and Microsoft.
    Imagine querying a spreadsheet with natural language to extract insights or asking
    a document to summarize key points. This simplifies data management and makes
    complex information more accessible. Furthermore, LLMs can integrate with internal
    systems to automate routine tasks and create knowledge graphs, streamlining workflows
    and enhancing organizational efficiency. However, while LLMs improve the accuracy
    and relevance of information retrieval, they also require meticulous handling
    to ensure data privacy and system security.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据检索方面，LLM可以增强生产力工具，例如通过集成Google和Microsoft等办公软件套件。想象一下用自然语言查询电子表格以提取见解，或者要求文档总结关键点。这简化了数据管理，使复杂信息更容易获取。此外，LLM可以与内部系统集成来自动化常规任务和创建知识图谱，简化工作流程并提高组织效率。然而，尽管LLM提高了信息检索的准确性和相关性，但它们也需要细致的处理以确保数据隐私和系统安全。
- en: Translation
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 翻译
- en: Translation is another domain where LLMs are being used heavily. Traditional
    machine translation systems often struggled with languages for which they had
    limited datasets, as they had to rely on statistical methods. LLMs are changing
    this by offering zero-shot and few-shot translation capabilities. *Zero-shot*
    refers to the model’s ability to translate languages without prior examples, a
    feat that was previously challenging. *Few-shot*, on the other hand, allows LLMs
    to perform well with minimal data.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 翻译是另一个LLM被大量使用的领域。传统的机器翻译系统往往在数据集有限的语种上遇到困难，因为它们必须依赖统计方法。LLM通过提供零样本和少样本翻译能力来改变这一点。*零样本*指的是模型在没有先前示例的情况下翻译语言的能力，这在以前是一个挑战。*少样本*则允许LLM在最少数据的情况下表现良好。
- en: This is particularly advantageous for translating languages that are underrepresented
    in training datasets. For companies involved in global operations or content creation,
    this is a major selling point. It eases localization of content, such as subtitling
    films or translating marketing materials, without extensive data requirements,
    allowing companies to expand into new markets without investing too many resources
    up front.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于在训练数据集中代表性不足的语言进行翻译特别有利。对于参与全球运营或内容创作的公司来说，这是一个重要的卖点。它简化了内容本地化，例如电影字幕或营销材料的翻译，无需大量数据需求，使公司能够在不投入过多前期资源的情况下进入新市场。
- en: LLMs trained on multilingual datasets can easily adapt to new languages, allowing
    translations across a broader spectrum of languages, including those with sparse
    resources. The applications for this extend to literature, film, and even real-time
    communication, where accurate and contextually appropriate translation can be
    helpful.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在多语言数据集上训练的LLM（大型语言模型）可以轻松适应新的语言，允许跨越更广泛的语言范围进行翻译，包括那些资源稀少的语言。这种应用范围扩展到文学、电影甚至实时通信，其中准确和语境适当的翻译可能非常有帮助。
- en: Yet, while LLMs offer significant improvements over traditional translation
    methods, maintaining accuracy and handling idioms still remain open challenges.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，尽管LLM在传统翻译方法上提供了显著的改进，但保持准确性和处理习语仍然是一些开放性的挑战。
- en: Speech Synthesis
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 语音合成
- en: 'The ability to generate speech that resonates with human listeners can significantly
    enhance user experience and interaction. *Speech synthesis*, generating audio
    that mimics human speech from text, is another area where LLMs are making remarkable
    progress. Historically, speech synthesis systems have struggled with creating
    natural and engaging audio outputs: the sound generated sounded clearly “robotic.”
    LLMs, however, have the potential to revolutionize this field by generating human-like
    speech with impressive fidelity. With training on text and audio datasets, LLMs
    can understand and replicate the subtleties of human speech, such as intonation,
    rhythm, and stress.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 能够生成与人类听众产生共鸣的语音可以显著提升用户体验和互动。*语音合成*，从文本生成模仿人类语音的音频，是LLMs取得显著进展的另一个领域。历史上，语音合成系统在创建自然和引人入胜的音频输出方面一直存在困难：生成的声音听起来明显“机械”。然而，LLMs有潜力通过生成具有令人印象深刻保真度的类似人类语音来彻底改变这一领域。通过在文本和音频数据集上进行训练，LLMs可以理解和复制人类语音的细微差别，如语调、节奏和重音。
- en: This is useful for applications like virtual assistants, realistic voice-overs
    for characters in video games, or engaging audio content for educational materials.
    Using LLMs to automate the creation of speech content makes it easy for businesses
    to produce large volumes of content without the time and costs of extensive manual
    recording. However, audio–speech synthesis still has room to improve, especially
    with regard to recognizing accents and other variations in speech.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这对于虚拟助手、视频游戏角色逼真的配音或教育材料引人入胜的音频内容等应用很有用。使用LLMs自动创建语音内容，使企业能够轻松生产大量内容，而无需花费大量时间和成本进行手动录制。然而，音频-语音合成仍有改进的空间，特别是在识别口音和其他语音变化方面。
- en: Recommender Systems
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 推荐系统
- en: Recommender systems are at the heart of many digital platforms, from ecommerce
    to streaming services. LLMs enhance these systems by incorporating a deeper understanding
    of users’ preferences and contextual factors. Earlier recommender systems relied
    on historical user data and predefined algorithms, which often led to limited
    or repetitive suggestions. LLMs, with their ability to process and interpret diverse
    data sources, offer a more nuanced approach.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统是许多数字平台的核心，从电子商务到流媒体服务。大型语言模型（LLMs）通过结合对用户偏好和上下文因素的更深入理解来增强这些系统。早期的推荐系统依赖于历史用户数据和预定义的算法，这通常导致建议有限或重复。LLMs凭借其处理和解释多种数据源的能力，提供了一种更细腻的方法。
- en: LLM-powered recommender systems can analyze user interactions, preferences,
    and even conversational cues, including audio and video inputs, to deliver personalized
    recommendations in real time. For example, if a user describes a product in natural
    language and provides an image, the LLM can integrate both modalities to offer
    more relevant suggestions, even in response to ambiguous or vague requests.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 由LLM驱动的推荐系统可以分析用户互动、偏好，甚至包括音频和视频输入的对话线索，以实时提供个性化推荐。例如，如果用户用自然语言描述一个产品并提供一张图片，LLM可以整合这两种模态，提供更相关的建议，即使在应对模糊或含糊不清的请求时也是如此。
- en: Despite these advantages, many challenges remain unsolved. For example, maintaining
    user trust requires careful attention to the model’s transparency and reasoning.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有这些优势，许多挑战仍未解决。例如，维护用户信任需要仔细关注模型的透明度和推理能力。
- en: Autonomous AI Agents
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自主人工智能代理
- en: '*AI agents* are designed to perform specific tasks autonomously, leveraging
    LLMs to execute complex operations that would otherwise require human intervention.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '*人工智能代理*被设计来自主执行特定任务，利用LLMs执行原本需要人类干预的复杂操作。'
- en: For example, in a customer service environment, traditional automated agent
    systems might follow rigid scripts or rely on basic rule-based logic. LLM-powered
    AI agents, however, can engage in dynamic, context-aware conversations. They understand
    user queries more deeply, interpret intent more accurately, and generate responses
    that are more natural and engaging.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在客户服务环境中，传统的自动化代理系统可能会遵循严格的脚本或依赖于基本的基于规则的逻辑。然而，由LLM驱动的AI代理可以进行动态、上下文感知的对话。它们对用户查询的理解更深入，对意图的解释更准确，生成的回复更自然、更吸引人。
- en: In project management, LLMs can power intelligent project assistants that manage
    schedules, set reminders, and even draft project reports. These AI agents can
    interact with team members, understand project requirements, and adapt their responses
    to ongoing developments.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在项目管理中，大型语言模型（LLMs）可以驱动智能项目助手，管理日程安排、设置提醒，甚至起草项目报告。这些人工智能代理可以与团队成员互动，理解项目需求，并根据持续的发展调整他们的响应。
- en: Agentic Systems
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代理式系统
- en: '*Agentic systems* represent a more novel application of LLMs, where AI agents
    not only perform tasks but also make strategic decisions. These systems leverage
    LLMs’ data processing and analysis capabilities to discern patterns and make informed
    decisions in real time. This is particularly helpful in environments where decisions
    need to be based on complex, multifaceted information (as shown by the example
    workflow in [Figure 1-2](#ch01_figure_2_1748895465600898)).'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '*代理式系统*代表了 LLMs 的一种更新颖的应用，其中人工智能代理不仅执行任务，还做出战略决策。这些系统利用 LLMs 的数据处理和分析能力来识别模式，并在实时做出明智的决策。这在需要基于复杂、多方面的信息做出决策的环境中尤其有用（如图
    1-2 中的示例工作流程所示）。'
- en: '![](assets/llmo_0102.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![LLM 图 1-2](assets/llmo_0102.png)'
- en: 'Figure 1-2\. Agentic AI in the enterprise (source: [Haptik](https://oreil.ly/NapOi))'
  id: totrans-131
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-2\. 企业中的代理式人工智能（来源：[Haptik](https://oreil.ly/NapOi))
- en: In finance, agentic systems can digest data from financial reports, news articles,
    and market analytics, then use it to analyze market trends, assess risk factors,
    and make investment recommendations that align with investment strategies.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在金融领域，代理式系统可以消化来自财务报告、新闻文章和市场分析的数据，然后利用这些数据来分析市场趋势、评估风险因素，并做出与投资策略相一致的投资建议。
- en: Similarly, in supply chain management, agentic systems can optimize inventory
    levels, predict demand fluctuations, and coordinate logistics based on data from
    various sources—such as sales forecasts, supply chain disruptions, and production
    schedules.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在供应链管理中，代理式系统可以根据来自各种来源的数据——如销售预测、供应链中断和生产计划——优化库存水平、预测需求波动，并协调物流。
- en: However, these systems aren’t always reliable. Integrating them into existing
    workflows requires careful planning. Companies must consider how AI agents and
    agentic systems will interact with human teams, how they will be managed, and
    how their outputs will be monitored. Clear guidelines and oversight mechanisms
    are essential to ensure that these systems complement rather than disrupt existing
    operations. These issues are discussed in [Chapter 8](ch08.html#ch08_governance_monitoring_privacy_and_security_1748896766177413).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这些系统并不总是可靠的。将它们集成到现有工作流程中需要周密的规划。公司必须考虑人工智能代理和代理式系统将如何与人类团队互动，如何管理它们，以及如何监控它们的输出。明确的指导和监督机制对于确保这些系统能够补充而不是破坏现有操作至关重要。这些问题在[第
    8 章](ch08.html#ch08_governance_monitoring_privacy_and_security_1748896766177413)中进行了讨论。
- en: Data security and privacy are also big concerns. LLMs handle vast amounts of
    sensitive information, and protecting it from breaches or misuse is key. You need
    to establish strong data governance policies and invest in security measures to
    safeguard against potential risks. These issues, too, are discussed in [Chapter 8](ch08.html#ch08_governance_monitoring_privacy_and_security_1748896766177413).
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 数据安全和隐私也是一大关注点。LLMs 处理大量敏感信息，保护这些信息不受泄露或滥用至关重要。您需要建立强大的数据治理政策，并投资于安全措施以防范潜在风险。这些问题也在[第
    8 章](ch08.html#ch08_governance_monitoring_privacy_and_security_1748896766177413)中进行了讨论。
- en: Ten Challenges of Building with LLMs
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 LLM 构建的十大挑战
- en: LLMs introduce several new challenges, which can be amplified by the enormous
    scale of LLMs and their numerous applications. Addressing these challenges is
    important for integrating and deploying LLMs in production. Following is a list
    of 10 challenges with pointers to the chapters in this book where they are addressed.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs 引入了许多新的挑战，这些挑战可能会因 LLMs 的巨大规模和众多应用而放大。解决这些挑战对于在生产和部署 LLMs 至关重要。以下是一份包含
    10 个挑战及其在本书中讨论的章节的清单。
- en: 1\. Size and Complexity
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1. 尺度和复杂性
- en: LLMs generally have millions or even billions of parameters. This makes training,
    monitoring, and evaluating them extremely complex. Moreover, being generative
    models, they can fail silently, producing hallucinations and inaccurate information.
    Addressing this requires a structured approach that not only includes benchmarks
    commonly used for machine learning but also adds several other techniques; [Chapter 7](ch07.html#ch07_evaluation_for_llms_1748896751667823)
    explores this topic further.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: LLM通常有数百万甚至数十亿个参数。这使得训练、监控和评估它们变得极其复杂。此外，作为生成模型，它们可能会无声地失败，产生幻觉和不准确的信息。解决这个问题需要一种结构化的方法，不仅包括机器学习中常用的基准，还增加了其他几种技术；[第7章](ch07.html#ch07_evaluation_for_llms_1748896751667823)进一步探讨了这一主题。
- en: 2\. Training Scale and Duration
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2. 训练规模和持续时间
- en: Training LLMs requires processing large datasets. This is difficult not only
    from the data management perspective but also in terms of the memory and computational
    resources required for training the models. We discuss this in [Chapter 3](ch03.html#ch03_llm_based_applications_1748895493844515).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 训练LLM需要处理大量数据集。这不仅从数据管理角度来看困难，而且在训练模型所需的内存和计算资源方面也很困难。我们在[第3章](ch03.html#ch03_llm_based_applications_1748895493844515)中讨论了这一点。
- en: Training LLMs can take days, weeks, or even months, and managing parallel and
    distributed training across large clusters of GPUs and TPUs requires specialized
    hardware and organizational skills. This means that hardware represents a major
    dependency on external organizations and market availability, one that requires
    careful, systematic planning. We discuss this in [Chapter 9](ch09.html#ch09_scaling_hardware_infrastructure_and_resource_ma_1748896826216961).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 训练LLM可能需要几天、几周甚至几个月，管理跨大型GPU和TPU集群的并行和分布式训练需要专门的硬件和组织技能。这意味着硬件代表了对外部组织和市场可用性的重大依赖，这需要仔细的系统规划。我们在[第9章](ch09.html#ch09_scaling_hardware_infrastructure_and_resource_ma_1748896826216961)中讨论了这一点。
- en: Handling large, potentially sensitive training datasets requires careful security
    measures and anonymization, as discussed in [Chapter 2](ch02.html#ch02_introduction_to_llmops_1748895480208948).
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 处理大型、可能敏感的训练数据集需要仔细的安全措施和匿名化，如[第2章](ch02.html#ch02_introduction_to_llmops_1748895480208948)中所述。
- en: 3\. Prompt Engineering
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3. 提示工程
- en: One of the most common ways to make an LLM work better for a specific problem
    is prompt engineering, the science and art of crafting the text inputs that are
    sent to the models. Prompt updates can significantly improve or degrade the user
    experience. But prompt engineering is iterative and can be difficult to master
    and document, especially with closed-source LLMs. You’ll find a discussion of
    this in [Chapter 5](ch05.html#ch05_model_domain_adaptation_for_llm_based_applications_1748896666813361).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 让LLM针对特定问题工作得更好最常见的方法之一是提示工程，这是制作发送给模型的文本输入的科学和艺术。提示更新可以显著改善或降低用户体验。但提示工程是迭代的，并且可能难以掌握和记录，尤其是在闭源LLM的情况下。你可以在[第5章](ch05.html#ch05_model_domain_adaptation_for_llm_based_applications_1748896666813361)中找到对此的讨论。
- en: Updates of proprietary models, like OpenAI’s GPT-4, can result in significant
    *model drift*, where the same inputs suddenly provide a different output due to
    a model update. Model drift requires effort and financial commitment to fix. This
    becomes additionally complex when there are many interdependent prompts connected
    to each other, such as in an *orchestration framework* (i.e., a structured platform
    used to automate, coordinate, and manage complex tasks and services) and there’s
    a change in the underlying model, as the entire complex prompt chain can break
    in unexpected and hard-to-detect ways. If your infrastructure relies heavily on
    prompt-engineering pipelines, monitoring is crucial; [Chapter 7](ch07.html#ch07_evaluation_for_llms_1748896751667823)
    goes into this in more depth.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 专有模型的更新，如OpenAI的GPT-4，可能导致显著的*模型漂移*，即由于模型更新，相同的输入突然产生不同的输出。模型漂移需要付出努力和财务投入来修复。当存在许多相互关联的提示相互连接时，例如在*编排框架*（即用于自动化、协调和管理复杂任务和服务的结构化平台）中，以及底层模型发生变化时，这会变得更加复杂，因为整个复杂的提示链可能会以意外和难以检测的方式断裂。如果你的基础设施严重依赖提示工程管道，监控至关重要；[第7章](ch07.html#ch07_evaluation_for_llms_1748896751667823)更深入地探讨了这一点。
- en: 4\. Inference Latency and Throughput
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4. 推理延迟和吞吐量
- en: Responses provided by LLMs are also called *inferences*. LLMs are often deployed
    in applications that require real-time or near-real-time responses, which means
    that optimizing for speed becomes important. This can be especially complex with
    dynamic models like LLMs. Also, maintaining high throughput without having access
    to model parameters can add complexity for LLMOps teams. Edge devices used in
    IoT applications introduce even more challenges related to limited computational
    resources and varying network conditions. These issues are discussed in [Chapter 9](ch09.html#ch09_scaling_hardware_infrastructure_and_resource_ma_1748896826216961).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs提供的响应也被称为*推理*。LLMs通常部署在需要实时或近实时响应的应用中，这意味着优化速度变得很重要。这对于像LLMs这样的动态模型来说可能特别复杂。此外，在没有访问模型参数的情况下保持高吞吐量可能会为LLMOps团队增加复杂性。在物联网应用中使用的边缘设备引入了更多与有限的计算资源和变化的网络条件相关的问题。这些问题在第9章（ch09.html#ch09_scaling_hardware_infrastructure_and_resource_ma_1748896826216961）中进行了讨论。
- en: 5\. Ethical Considerations
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5. 道德考量
- en: Like any other machine learning model, LLMs generate outputs based on the data
    that they have been trained on. LLMs applications are frequently designed to create
    the experience of chatting with a human instead of a machine, making them accessible
    to a much larger user base than specialized machine learning systems and greatly
    increasing the impact of potential biases introduced by the training data.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 与任何其他机器学习模型一样，LLMs根据它们训练的数据生成输出。LLMs应用通常被设计成创造与人类而非机器聊天的体验，这使得它们比专门的机器学习系统更容易被更广泛的用户群体所接受，并大大增加了由训练数据引入的潜在偏差的影响。
- en: '[Chapter 7](ch07.html#ch07_evaluation_for_llms_1748896751667823) discusses
    techniques for monitoring LLM outputs, and the privacy and ethical implications
    of their use are explained in [Chapter 8](ch08.html#ch08_governance_monitoring_privacy_and_security_1748896766177413).'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 第7章（ch07.html#ch07_evaluation_for_llms_1748896751667823）讨论了监控LLM输出的技术，以及它们的使用在隐私和道德方面的含义，在第8章（ch08.html#ch08_governance_monitoring_privacy_and_security_1748896766177413）中进行了解释。
- en: 6\. Resource Scaling and Orchestration
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6. 资源扩展和编排
- en: The scale at which LLMs operate often requires load balancing and dynamic resource
    scaling. Different proprietary models can also behave very differently based on
    the use case, and constant scenario modeling is expensive and time intensive.
    [Chapter 5](ch05.html#ch05_model_domain_adaptation_for_llm_based_applications_1748896666813361)
    explores how to manage dependencies across various components in distributed multi-model
    environments, ensuring reliability and scalability.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs运行的范围通常需要负载均衡和动态资源扩展。不同的专有模型根据用例的不同也可能表现出非常不同的行为，而持续的情景建模既昂贵又耗时。[第5章](ch05.html#ch05_model_domain_adaptation_for_llm_based_applications_1748896666813361)探讨了如何在分布式多模型环境中管理各个组件之间的依赖关系，以确保可靠性和可扩展性。
- en: 7\. Integrations and Toolkits
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7. 集成和工具包
- en: LLMs require several new integrations and toolkits that are adapted to both
    generative as well as discriminative use cases and involve communicating with
    various APIs. Integrating these LLMs into existing systems requires robust security
    protocols to prevent vulnerabilities and potential misuse. Changes in LLMs and
    version management, discussed in [Chapter 8](ch08.html#ch08_governance_monitoring_privacy_and_security_1748896766177413),
    can also lead to compatibility issues across the stack.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs需要集成多个新的集成和工具包，这些工具包适用于生成性以及判别性用例，并涉及与各种API的通信。将这些LLMs集成到现有系统中需要强大的安全协议来防止漏洞和潜在的滥用。第8章（ch08.html#ch08_governance_monitoring_privacy_and_security_1748896766177413）中讨论的LLMs和版本管理的变化也可能导致整个堆栈的兼容性问题。
- en: 8\. Broad Applicability
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8. 广泛适用性
- en: LLMs are adaptable and easy to use, which means that they can be applied to
    numerous consumer-facing applications, as we will see in [Chapter 3](ch03.html#ch03_llm_based_applications_1748895493844515).
    This makes them more likely to be exposed to untested scenarios than traditional
    machine learning systems, and thus they require a faster feedback loop to monitor
    and improve their performance. [Chapter 7](ch07.html#ch07_evaluation_for_llms_1748896751667823)
    addresses monitoring techniques.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs易于适应和使用，这意味着它们可以应用于众多面向消费者的应用，正如我们在第3章（ch03.html#ch03_llm_based_applications_1748895493844515）中将会看到的。这使得它们比传统的机器学习系统更容易暴露于未经测试的场景中，因此它们需要更快的反馈循环来监控和改进其性能。第7章（ch07.html#ch07_evaluation_for_llms_1748896751667823）讨论了监控技术。
- en: 9\. Privacy and Security
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9. 隐私和安全
- en: Collecting real-time information involves handling user data, sometimes including
    personally identifying information (PII). This means that security and privacy
    become the cornerstone of maintaining trust and regulatory compliance. This challenge
    extends well beyond inference monitoring, touching the domain of cybersecurity.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 收集实时信息涉及处理用户数据，有时包括个人身份信息（PII）。这意味着安全和隐私成为维护信任和符合监管要求的基石。这一挑战远远超出了推理监控，触及了网络安全领域。
- en: Even companies such as OpenAI have [received reports about database leaks](https://oreil.ly/yqPpG)
    into user accounts that made chat interactions visible to unauthorized users.
    We talk more about privacy and security in [Chapter 8](ch08.html#ch08_governance_monitoring_privacy_and_security_1748896766177413).
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 即使是像OpenAI这样的公司也收到了关于数据库泄露到用户账户的报告，这使得聊天交互对未经授权的用户可见。[第8章](ch08.html#ch08_governance_monitoring_privacy_and_security_1748896766177413)中我们更多地讨论了隐私和安全问题。
- en: Regularly auditing your data management processes, both internally and externally,
    is also vital for enhancing user trust and complying with legal requirements.
    Best practices for data management are discussed in [Chapter 4](ch04.html#ch04_data_engineering_for_llms_1748895507364914).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 定期审计您的数据管理流程，无论是内部还是外部，对于增强用户信任和遵守法律要求也至关重要。数据管理的最佳实践在[第4章](ch04.html#ch04_data_engineering_for_llms_1748895507364914)中进行了讨论。
- en: 10\. Costs
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10. 成本
- en: One of the biggest considerations for LLMs is cost, both immediate and long-term.
    While most transformer models require expensive training, maintaining and scaling
    LLMs incurs the highest costs, especially in the inference stages. You could end
    up paying even for failed requests, so experimenting with model performance can
    become very expensive very quickly for companies building on closed and proprietary
    models.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大型语言模型（LLM）来说，最大的考虑因素是成本，包括短期和长期成本。虽然大多数转换器模型需要昂贵的训练，但维护和扩展LLM的成本最高，尤其是在推理阶段。你甚至可能为失败的请求付费，因此对于基于封闭和专有模型的公司的模型性能实验可能会变得非常昂贵。
- en: Even in open source models, excessive fine-tuning can quickly lead to a phenomenon
    called *overfitting*, where the model appears to perform extremely well because
    it learns the training dataset but does not generalize to the unseen data that
    will be presented to it by real users. There are always trade-offs between generalization
    ability and cost; these are explored in [Chapter 5](ch05.html#ch05_model_domain_adaptation_for_llm_based_applications_1748896666813361).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在开源模型中，过度的微调也会迅速导致一种称为“过拟合”的现象，即模型似乎表现极好，因为它学会了训练数据集，但不能推广到真实用户将呈现给它的未见数据。在泛化能力和成本之间总是存在权衡；这些内容在[第5章](ch05.html#ch05_model_domain_adaptation_for_llm_based_applications_1748896666813361)中进行了探讨。
- en: Conclusion
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: Adopting LLMs requires careful consideration and strategic planning to navigate
    these intricate challenges, and organizations require a new discipline and a set
    of new tools to succeed. We call this discipline LLMOps, and we start our journey
    by defining it in the next ​chapter.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 采用LLM需要仔细考虑和战略规划，以应对这些复杂的挑战，组织需要新的学科和一套新的工具才能成功。我们将这种学科称为LLMOps，并在下一章中定义它。
- en: References
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Dao, Tri, and Albert Gu. [“Transformers Are SSMs: Generalized Models and Efficient
    Algorithms Through Structured State Space Duality”](https://oreil.ly/POlHU), arXiv,
    May 31, 2024.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 'Dao, Tri和Albert Gu。“Transformers Are SSMs: Generalized Models and Efficient
    Algorithms Through Structured State Space Duality”，arXiv，2024年5月31日。'
- en: 'Devlin, Jacob, et al. [“BERT: Pre-Training of Deep Bidirectional Transformers
    for Language Understanding”](https://oreil.ly/84NM2), arXiv, May 24, 2019.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Devlin, Jacob，等人。“BERT：用于语言理解的深度双向转换器预训练”，arXiv，2019年5月24日。
- en: Haptik. n.d. [“A Comprehensive Guide to Agentic AI”](https://oreil.ly/CO7uA),
    Accessed May 21, 2025.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: Haptik. n.d. [“全面指南：代理人工智能”](https://oreil.ly/CO7uA)，访问日期：2025年5月21日。
- en: 'OpenAI. [“March 20 ChatGPT Outage: Here’s What Happened”](https://oreil.ly/5kdkr),
    March 24, 2023.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI. [“3月20日ChatGPT故障：发生了什么”](https://oreil.ly/5kdkr), 2023年3月24日。
- en: 'Vaswani, Ashish, et al. “Attention Is All You Need”, In [*NIPS’17: Proceedings
    of the 31st International Conference on Neural Information Processing Systems*](https://oreil.ly/hfTxe),
    edited by Ulrike von Luxburg, Isabelle Guyon, Samy Bengio, Hanna Wallach, and
    Rob Fergus (Curran Associates, 2017).'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 'Vaswani, Ashish, 等人。“Attention Is All You Need”，载于[*NIPS’17: 第31届国际神经网络信息处理系统会议论文集*](https://oreil.ly/hfTxe)，由Ulrike
    von Luxburg, Isabelle Guyon, Samy Bengio, Hanna Wallach和Rob Fergus（Curran Associates）编辑（2017年）。'
- en: Wang, Sarah, and Shangda Xu. [“16 Changes to the Way Enterprises Are Building
    and Buying Generative AI”](https://oreil.ly/yRrmR), Andreessen Horowitz, March
    21, 2024.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 王莎拉，徐尚达. [“企业构建和购买生成式AI的16项变革”](https://oreil.ly/yRrmR), 安德森·霍洛维茨，2024年3月21日。
