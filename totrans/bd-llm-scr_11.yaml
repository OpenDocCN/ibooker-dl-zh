- en: appendix E Parameter-efficient fine-tuning with LoRA
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录E：使用LoRA进行参数高效的微调
- en: '*Low-rank adaptation* (*LoRA*) is one of the most widely used techniques for
    *parameter-efficient fine-tuning*. The following discussion is based on the spam
    classification fine-tuning example given in chapter 6\. However, LoRA fine-tuning
    is also applicable to the supervised *instruction fine-tuning* discussed in chapter
    7.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '*低秩适应*（LoRA）是参数高效微调中最广泛使用的技术之一。以下讨论基于第6章中给出的垃圾邮件分类微调示例。然而，LoRA微调也适用于第7章中讨论的监督*指令微调*。'
- en: E.1 Introduction to LoRA
  id: totrans-2
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: E.1 LoRA简介
- en: LoRA is a technique that adapts a pretrained model to better suit a specific,
    often smaller dataset by adjusting only a small subset of the model’s weight parameters.
    The “low-rank” aspect refers to the mathematical concept of limiting model adjustments
    to a smaller dimensional subspace of the total weight parameter space. This effectively
    captures the most influential directions of the weight parameter changes during
    training. The LoRA method is useful and popular because it enables efficient fine-tuning
    of large models on task-specific data, significantly cutting down on the computational
    costs and resources usually required for fine-tuning.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: LoRA是一种技术，通过仅调整模型权重参数的小子集，将预训练模型调整以更好地适应特定（通常是较小的）数据集。其中“低秩”方面指的是将模型调整限制在总权重参数空间的一个较小维度的子空间中的数学概念。这有效地捕捉了训练过程中权重参数变化的最有影响力的方向。LoRA方法因其能够使大型模型在特定任务数据上高效微调而有用且受欢迎，显著降低了微调通常所需的计算成本和资源。
- en: Suppose a large weight matrix *W* is associated with a specific layer. LoRA
    can be applied to all linear layers in an LLM. However, we focus on a single layer
    for illustration purposes.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 假设一个大的权重矩阵*W*与一个特定的层相关联。LoRA可以应用于LLM中的所有线性层。然而，为了说明目的，我们专注于单个层。
- en: When training deep neural networks, during backpropagation, we learn a D*W*
    matrix, which contains information on how much we want to update the original
    weight parameters to minimize the loss function during training. Hereafter, I
    use the term “weight” as shorthand for the model’s weight parameters.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练深度神经网络时，在反向传播过程中，我们学习一个D*W*矩阵，它包含了我们在训练过程中希望更新原始权重参数以最小化损失函数的信息。此后，我使用“权重”一词作为模型权重参数的简称。
- en: 'In regular training and fine-tuning, the weight update is defined as follows:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在常规训练和微调中，权重更新定义为如下：
- en: '![figure](../Images/Equation-eqs-E-1.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/Equation-eqs-E-1.png)'
- en: 'The LoRA method, proposed by Hu et al. ([https://arxiv.org/abs/2106.09685](https://arxiv.org/abs/2106.09685)),
    offers a more efficient alternative to computing the weight updates D*W* by learning
    an approximation of it:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 由胡等人提出的LoRA方法([https://arxiv.org/abs/2106.09685](https://arxiv.org/abs/2106.09685))，为计算权重更新D*W*提供了一个更高效的替代方案，通过学习其近似值：
- en: '![figure](../Images/Equation-eqs-E-2.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/Equation-eqs-E-2.png)'
- en: where *A* and *B* are two matrices much smaller than *W*, and *AB* represents
    the matrix multiplication product between *A* and *B*.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 其中*A*和*B*是两个比*W*小得多的矩阵，*AB*表示*A*和*B*之间的矩阵乘积。
- en: 'Using LoRA, we can then reformulate the weight update we defined earlier:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LoRA，我们可以重新表述我们之前定义的权重更新：
- en: '![figure](../Images/Equation-eqs-E-3.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/Equation-eqs-E-3.png)'
- en: Figure E.1 illustrates the weight update formulas for full fine-tuning and LoRA
    side by side.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 图E.1展示了全微调和LoRA的权重更新公式并排比较。
- en: '![figure](../Images/E-1.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/E-1.png)'
- en: 'Figure E.1 A comparison between weight update methods: regular fine-tuning
    and LoRA. Regular fine-tuning involves updating the pretrained weight matrix W
    directly with DW (left). LoRA uses two smaller matrices, A and B, to approximate
    DW, where the product AB is added to W, and r denotes the inner dimension, a tunable
    hyperparameter (right).'
  id: totrans-15
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图E.1 比较了权重更新方法：常规微调和LoRA。常规微调直接使用DW更新预训练权重矩阵W（左）。LoRA使用两个较小的矩阵A和B来近似DW，其中AB的乘积被加到W上，r表示内维，一个可调的超参数（右）。
- en: If you paid close attention, you might have noticed that the visual representations
    of full fine-tuning and LoRA in figure E.1 differ slightly from the earlier presented
    formulas. This variation is attributed to the distributive law of matrix multiplication,
    which allows us to separate the original and updated weights rather than combine
    them. For example, in the case of regular fine-tuning with *x* as the input data,
    we can express the computation as
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仔细观察，你可能会注意到图 E.1 中全微调和 LoRA 的视觉表示与之前展示的公式略有不同。这种变化归因于矩阵乘法的分配律，它允许我们分离原始和更新的权重而不是将它们组合。例如，在以
    *x* 作为输入数据的常规微调情况下，我们可以将计算表示为
- en: '![figure](../Images/Equation-eqs-E-4.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/Equation-eqs-E-4.png)'
- en: 'Similarly, we can write the following for LoRA:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们可以为 LoRA 编写以下内容：
- en: '![figure](../Images/Equation-eqs-E-5.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/Equation-eqs-E-5.png)'
- en: Besides reducing the number of weights to update during training, the ability
    to keep the LoRA weight matrices separate from the original model weights makes
    LoRA even more useful in practice. Practically, this allows for the pretrained
    model weights to remain unchanged, with the LoRA matrices being applied dynamically
    after training when using the model.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 除了减少训练期间需要更新的权重数量外，将 LoRA 权重矩阵与原始模型权重分开的能力使 LoRA 在实践中更加有用。实际上，这允许预训练模型权重保持不变，在训练后使用模型时，LoRA
    矩阵会动态应用。
- en: Keeping the LoRA weights separate is very useful in practice because it enables
    model customization without needing to store multiple complete versions of an
    LLM. This reduces storage requirements and improves scalability, as only the smaller
    LoRA matrices need to be adjusted and saved when we customize LLMs for each specific
    customer or application.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中保持 LoRA 权重分离非常有用，因为它允许在不存储多个完整的 LLM 版本的情况下进行模型定制。这减少了存储需求并提高了可扩展性，因为当我们为每个特定的客户或应用程序定制
    LLM 时，只需要调整和保存较小的 LoRA 矩阵。
- en: Next, let’s see how LoRA can be used to fine-tune an LLM for spam classification,
    similar to the fine-tuning example in chapter 6.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看 LoRA 如何用于微调 LLM 以进行垃圾邮件分类，类似于第 6 章中的微调示例。
- en: E.2 Preparing the dataset
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: E.2 准备数据集
- en: Before applying LoRA to the spam classification example, we must load the dataset
    and pretrained model we will work with. The code here repeats the data preparation
    from chapter 6\. (Instead of repeating the code, we could open and run the chapter
    6 notebook and insert the LoRA code from section E.4 there.)
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用 LoRA 到垃圾邮件分类示例之前，我们必须加载我们将要使用的数据集和预训练模型。这里的代码重复了第 6 章的数据准备。（我们也可以打开并运行第
    6 章的笔记本，并在其中插入 E.4 节的 LoRA 代码。）
- en: First, we download the dataset and save it as CSV files.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们下载数据集并将其保存为 CSV 文件。
- en: Listing E.1 Downloading and preparing the dataset
  id: totrans-26
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 E.1 下载和准备数据集
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Next, we create the `SpamDataset` instances.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建 `SpamDataset` 实例。
- en: Listing E.2 Instantiating PyTorch datasets
  id: totrans-29
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 E.2 实例化 PyTorch 数据集
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: After creating the PyTorch dataset objects, we instantiate the data loaders.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建 PyTorch 数据集对象之后，我们实例化数据加载器。
- en: Listing E.3 Creating PyTorch data loaders
  id: totrans-32
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 E.3 创建 PyTorch 数据加载器
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As a verification step, we iterate through the data loaders and check that
    the batches contain eight training examples each, where each training example
    consists of 120 tokens:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 作为验证步骤，我们遍历数据加载器，并检查每个批次包含八个训练示例，每个训练示例由 120 个标记组成：
- en: '[PRE3]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The output is
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 输出如下
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Lastly, we print the total number of batches in each dataset:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们打印每个数据集的总批次数：
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In this case, we have the following number of batches per dataset:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们每个数据集有以下批次数：
- en: '[PRE6]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: E.3 Initializing the model
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: E.3 初始化模型
- en: We repeat the code from chapter 6 to load and prepare the pretrained GPT model.
    We begin by downloading the model weights and loading them into the `GPTModel`
    class.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们重复第 6 章的代码来加载和准备预训练的 GPT 模型。我们首先下载模型权重并将它们加载到 `GPTModel` 类中。
- en: Listing E.4 Loading a pretrained GPT model
  id: totrans-44
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 E.4 加载预训练的 GPT 模型
- en: '[PRE7]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '#1 Vocabulary size'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 词汇量大小'
- en: '#2 Context length'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 上下文长度'
- en: '#3 Dropout rate'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 Dropout 率'
- en: '#4 Query-key-value bias'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 查询键值偏差'
- en: 'To ensure that the model was loaded corrected, let’s double-check that it generates
    coherent text:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保模型正确加载，让我们再次检查它是否生成连贯的文本：
- en: '[PRE8]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following output shows that the model generates coherent text, which is
    an indicator that the model weights are loaded correctly:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出显示，模型生成了连贯的文本，这是模型权重加载正确的指标：
- en: '[PRE9]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Next, we prepare the model for classification fine-tuning, similar to chapter
    6, where we replace the output layer:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们为分类微调准备模型，类似于第6章，我们替换输出层：
- en: '[PRE10]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Lastly, we calculate the initial classification accuracy of the not-fine-tuned
    model (we expect this to be around 50%, which means that the model is not able
    to distinguish between spam and nonspam messages yet reliably):'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们计算未微调模型的初始分类准确率（我们预计这个值约为50%，这意味着模型还不能可靠地区分垃圾邮件和非垃圾邮件）：
- en: '[PRE11]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The initial prediction accuracies are
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 初始预测准确率如下
- en: '[PRE12]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: E.4 Parameter-efficient fine-tuning with LoRA
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: E.4 使用LoRA进行参数高效的微调
- en: Next, we modify and fine-tune the LLM using LoRA. We begin by initializing a
    LoRALayer that creates the matrices *A* and *B*, along with the `alpha` scaling
    factor and the `rank` (*r*) setting. This layer can accept an input and compute
    the corresponding output, as illustrated in figure E.2.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用LoRA修改和微调LLM。我们首先初始化一个LoRALayer，它创建矩阵*A*和*B*，以及`alpha`缩放因子和`rank`（*r*）设置。这个层可以接受输入并计算相应的输出，如图E.2所示。
- en: '![figure](../Images/E-2.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/E-2.png)'
- en: Figure E.2 The LoRA matrices A and B are applied to the layer inputs and are
    involved in computing the model outputs. The inner dimension r of these matrices
    serves as a setting that adjusts the number of trainable parameters by varying
    the sizes of A and B.
  id: totrans-63
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图E.2 LoRA矩阵A和B应用于层输入，并参与计算模型输出。这些矩阵的内维r作为一个设置，通过改变A和B的大小来调整可训练参数的数量。
- en: In code, this LoRA layer can be implemented as follows.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，这个LoRA层可以如下实现。
- en: Listing E.5 Implementing a LoRA layer
  id: totrans-65
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表E.5 实现LoRA层
- en: '[PRE13]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '#1 The same initialization used for Linear layers in PyTorch'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 与PyTorch中线性层的相同初始化'
- en: The `rank` governs the inner dimension of matrices *A* and *B*. Essentially,
    this setting determines the number of extra parameters introduced by LoRA, which
    creates balance between the adaptability of the model and its efficiency via the
    number of parameters used.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`rank`控制矩阵*A*和*B*的内维。本质上，这个设置决定了LoRA引入的额外参数数量，通过参数数量来平衡模型的适应性和效率。'
- en: The other important setting, `alpha`, functions as a scaling factor for the
    output from the low-rank adaptation. It primarily dictates the degree to which
    the output from the adapted layer can affect the original layer’s output. This
    can be seen as a way to regulate the effect of the low-rank adaptation on the
    layer’s output. The `LoRALayer` class we have implemented so far enables us to
    transform the inputs of a layer.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要的设置，`alpha`，作为低秩适应输出的缩放因子。它主要决定了适应层输出对原始层输出的影响程度。这可以看作是一种调节低秩适应对层输出影响的方法。我们迄今为止实现的`LoRALayer`类使我们能够转换层的输入。
- en: In LoRA, the typical goal is to substitute existing `Linear` layers, allowing
    weight updates to be applied directly to the pre-existing pretrained weights,
    as illustrated in figure E.3.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在LoRA中，典型的目标是用现有的`线性`层进行替换，允许直接将权重更新应用于预训练的现有权重，如图E.3所示。
- en: '![figure](../Images/E-3.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/E-3.png)'
- en: Figure E.3 The integration of LoRA into a model layer. The original pretrained
    weights (W) of a layer are combined with the outputs from LoRA matrices (A and
    B), which approximate the weight update matrix (DW). The final output is calculated
    by adding the output of the adapted layer (using LoRA weights) to the original
    output.
  id: totrans-72
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图E.3 LoRA集成到模型层中。层的原始预训练权重（W）与LoRA矩阵（A和B）的输出相结合，这些输出近似权重更新矩阵（DW）。最终输出是通过将适应层（使用LoRA权重）的输出与原始输出相加来计算的。
- en: To integrate the original `Linear` layer weights, we now create a `LinearWithLoRA`
    layer. This layer utilizes the previously implemented `LoRALayer` and is designed
    to replace existing `Linear` layers within a neural network, such as the self-attention
    modules or feed-forward modules in the `GPTModel`.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 为了整合原始的`线性`层权重，我们现在创建一个`LinearWithLoRA`层。这个层利用之前实现的`LoRALayer`，并设计用来替换神经网络中的现有`线性`层，例如`GPTModel`中的自注意力模块或前馈模块。
- en: Listing E.6 Replacing `Linear` layers with `LinearWithLora` layers
  id: totrans-74
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表E.6 使用`LinearWithLora`层替换`线性`层
- en: '[PRE14]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This code combines a standard `Linear` layer with the `LoRALayer`. The `forward`
    method computes the output by adding the results from the original linear layer
    and the LoRA layer.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码结合了一个标准的`线性`层和`LoRALayer`。`forward`方法通过添加原始线性层和LoRA层的结果来计算输出。
- en: Since the weight matrix *B* (`self.B` in `LoRALayer`) is initialized with zero
    values, the product of matrices *A* and *B* results in a zero matrix. This ensures
    that the multiplication does not alter the original weights, as adding zero does
    not change them.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 由于权重矩阵*B*（`LoRALayer`中的`self.B`）是用零值初始化的，矩阵*A*和*B*的乘积结果是一个零矩阵。这确保了乘法不会改变原始权重，因为添加零不会改变它们。
- en: 'To apply LoRA to the earlier defined `GPTModel`, we introduce a `replace_linear_
    with_lora` function. This function will swap all existing `Linear` layers in the
    model with the newly created `LinearWithLoRA` layers:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将LoRA应用于先前定义的`GPTModel`，我们引入了一个`replace_linear_with_lora`函数。这个函数将模型中所有现有的`Linear`层与新创建的`LinearWithLoRA`层进行交换：
- en: '[PRE15]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '#1 Replaces the Linear layer with LinearWithLoRA'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 将线性层替换为LinearWithLoRA'
- en: '#2 Recursively applies the same function to child modules'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 递归地应用于子模块'
- en: We have now implemented all the necessary code to replace the `Linear` layers
    in the `GPTModel` with the newly developed `LinearWithLoRA` layers for parameter-efficient
    fine-tuning. Next, we will apply the `LinearWithLoRA` upgrade to all `Linear`
    layers found in the multihead attention, feed-forward modules, and the output
    layer of the `GPTModel`, as shown in figure E.4.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经实现了替换`GPTModel`中`Linear`层为新开发的`LinearWithLoRA`层以进行参数高效微调的所有必要代码。接下来，我们将应用`LinearWithLoRA`升级到`GPTModel`中所有`Linear`层，包括多头注意力、前馈模块和输出层，如图E.4所示。
- en: '![figure](../Images/E-4.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/E-4.png)'
- en: Figure E.4 The architecture of the GPT model. It highlights the parts of the
    model where `Linear` layers are upgraded to `LinearWithLoRA` layers for parameter-efficient
    fine-tuning.
  id: totrans-84
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图E.4 GPT模型的架构。它突出了模型中`Linear`层升级为`LinearWithLoRA`层以进行参数高效微调的部分。
- en: 'Before we apply the `LinearWithLoRA` layer upgrades, we first freeze the original
    model parameters:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用`LinearWithLoRA`层升级之前，我们首先冻结原始模型参数：
- en: '[PRE16]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, we can see that none of the 124 million model parameters are trainable:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以看到，在1.24亿个模型参数中，没有任何一个是可训练的：
- en: '[PRE17]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Next, we use the `replace_linear_with_lora` to replace the `Linear` layers:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用`replace_linear_with_lora`来替换`Linear`层：
- en: '[PRE18]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'After adding the LoRA layers, the number of trainable parameters is as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 添加LoRA层后，可训练参数的数量如下：
- en: '[PRE19]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As we can see, we reduced the number of trainable parameters by almost 50× when
    using LoRA. A `rank` and `alpha` of 16 are good default choices, but it is also
    common to increase the rank parameter, which in turn increases the number of trainable
    parameters. Alpha is usually chosen to be half, double, or equal to the rank.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，使用LoRA时，我们将可训练参数的数量减少了近50倍。16的`rank`和`alpha`是良好的默认选择，但也很常见增加rank参数，这反过来又增加了可训练参数的数量。`alpha`通常选择为rank的一半、两倍或与rank相等。
- en: 'Let’s verify that the layers have been modified as intended by printing the
    model architecture:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过打印模型架构来验证层是否已按预期修改：
- en: '[PRE20]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The output is
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 输出是
- en: '[PRE21]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The model now includes the new `LinearWithLoRA` layers, which themselves consist
    of the original `Linear` layers, set to nontrainable, and the new LoRA layers,
    which we will fine-tune.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 模型现在包括了新的`LinearWithLoRA`层，这些层本身由设置为不可训练的原始`Linear`层和新LoRA层组成，我们将对这些层进行微调。
- en: 'Before we begin fine-tuning the model, let’s calculate the initial classification
    accuracy:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始微调模型之前，让我们计算初始分类准确度：
- en: '[PRE22]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The resulting accuracy values are
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的准确度值是
- en: '[PRE23]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: These accuracy values are identical to the values from chapter 6\. This result
    occurs because we initialized the LoRA matrix *B* with zeros. Consequently, the
    product of matrices *AB* results in a zero matrix. This ensures that the multiplication
    does not alter the original weights since adding zero does not change them.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这些准确度值与第6章中的值相同。这种结果发生是因为我们用零初始化了LoRA矩阵*B*。因此，矩阵*A*和*B*的乘积结果是一个零矩阵。这确保了乘法不会改变原始权重，因为添加零不会改变它们。
- en: Now let’s move on to the exciting part—fine-tuning the model using the training
    function from chapter 6\. The training takes about 15 minutes on an M3 MacBook
    Air laptop and less than half a minute on a V100 or A100 GPU.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续到令人兴奋的部分——使用第6章中的训练函数微调模型。在M3 MacBook Air笔记本电脑上训练大约需要15分钟，在V100或A100
    GPU上不到半分钟。
- en: Listing E.7 Fine-tuning a model with LoRA layers
  id: totrans-105
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表E.7 使用LoRA层微调模型
- en: '[PRE24]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The output we see during the training is
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程中我们看到的输出是
- en: '[PRE25]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Training the model with LoRA took longer than training it without LoRA (see
    chapter 6) because the LoRA layers introduce an additional computation during
    the forward pass. However, for larger models, where backpropagation becomes more
    costly, models typically train faster with LoRA than without it.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LoRA训练模型比不使用LoRA训练模型花费的时间更长（见第6章），因为LoRA层在正向传播过程中引入了额外的计算。然而，对于更大的模型，反向传播变得成本更高，模型在有LoRA的情况下通常比没有LoRA时训练得更快。
- en: 'As we can see, the model received perfect training and very high validation
    accuracy. Let’s also visualize the loss curves to better see whether the training
    has converged:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，该模型接受了完美的训练，并且验证准确度非常高。让我们也可视化损失曲线，以便更好地观察训练是否收敛：
- en: '[PRE26]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Figure E.5 plots the results.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图E.5绘制了结果。
- en: '![figure](../Images/E-5.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/E-5.png)'
- en: Figure E.5 The training and validation loss curves over six epochs for a machine
    learning model. Initially, both training and validation loss decrease sharply
    and then they level off, indicating the model is converging, which means that
    it is not expected to improve noticeably with further training.
  id: totrans-114
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图E.5展示了机器学习模型在六个epoch上的训练和验证损失曲线。最初，训练和验证损失急剧下降，然后趋于平稳，表明模型正在收敛，这意味着它不会因为进一步的训练而有明显改进。
- en: 'In addition to evaluating the model based on the loss curves, let’s also calculate
    the accuracies on the full training, validation, and test set (during the training,
    we approximated the training and validation set accuracies from five batches via
    the `eval_iter=5` setting):'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 除了根据损失曲线评估模型外，我们还可以计算整个训练、验证和测试集上的准确率（在训练过程中，我们通过`eval_iter=5`设置从五个批次中近似训练和验证集准确率）：
- en: '[PRE27]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: The resulting accuracy values are
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 得到的准确率值是
- en: '[PRE28]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: These results show that the model performs well across training, validation,
    and test datasets. With a training accuracy of 100%, the model has perfectly learned
    the training data. However, the slightly lower validation and test accuracies
    (96.64% and 97.33%, respectively) suggest a small degree of overfitting, as the
    model does not generalize quite as well on unseen data compared to the training
    set. Overall, the results are very impressive, considering we fine-tuned only
    a relatively small number of model weights (2.7 million LoRA weights instead of
    the original 124 million model weights).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这些结果表明，该模型在训练、验证和测试数据集上表现良好。训练准确率达到100%，模型完美地学习了训练数据。然而，验证和测试准确度（分别为96.64%和97.33%）略低，表明模型存在一定程度过拟合，因为与训练集相比，模型在未见数据上的泛化能力较差。总体而言，考虑到我们仅微调了相对较少的模型权重（270万LoRA权重而不是原始的1240万模型权重），结果非常令人印象深刻。
- en: index
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 索引
- en: SYMBOLS
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 符号
- en: '[124M parameter](../Text/chapter-5.html#p263)'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '[124M参数](../Text/chapter-5.html#p263)'
- en: '[\[EOS] (end of sequence) token](../Text/chapter-2.html#p126)'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '[\[EOS\] (序列结束)标记](../Text/chapter-2.html#p126)'
- en: '[.reshape method](../Text/appendix-a.html#p93), [2nd](../Text/appendix-a.html#p101)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '[reshape方法](../Text/appendix-a.html#p93), [第2次](../Text/appendix-a.html#p101)'
- en: '[.to() method](../Text/appendix-a.html#p78), [2nd](../Text/appendix-a.html#p293)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[.to()方法](../Text/appendix-a.html#p78), [第2次](../Text/appendix-a.html#p293)'
- en: '[.weight attribute](../Text/chapter-5.html#p254)'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[.weight属性](../Text/chapter-5.html#p254)'
- en: '[.eval() mode](../Text/chapter-4.html#p221)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[.eval()模式](../Text/chapter-4.html#p221)'
- en: '[__getitem__ method](../Text/appendix-a.html#p201)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '[__getitem__方法](../Text/appendix-a.html#p201)'
- en: '[\[PAD] (padding) token](../Text/chapter-2.html#p127)'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[\[PAD\] (填充)标记](../Text/chapter-2.html#p127)'
- en: '[.T method](../Text/appendix-a.html#p102)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '[.T方法](../Text/appendix-a.html#p102)'
- en: '[.backward() method](../Text/chapter-4.html#p130), [2nd](../Text/appendix-d.html#p45)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[.backward()方法](../Text/chapter-4.html#p130), [第2次](../Text/appendix-d.html#p45)'
- en: '[%timeit command](../Text/appendix-a.html#p317)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[%timeit命令](../Text/appendix-a.html#p317)'
- en: '[.matmul method](../Text/appendix-a.html#p106)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[.matmul方法](../Text/appendix-a.html#p106)'
- en: '[04_preference-tuning-with-dpo folder](../Text/chapter-7.html#p264)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[04_preference-tuning-with-dpo文件夹](../Text/chapter-7.html#p264)'
- en: '[355M parameter](../Text/chapter-7.html#p131)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[355M参数](../Text/chapter-7.html#p131)'
- en: '[\[BOS] (beginning of sequence) token](../Text/chapter-2.html#p125)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[\[BOS\] (序列开始)标记](../Text/chapter-2.html#p125)'
- en: '[\<|unk|> tokens](../Text/chapter-2.html#p96), [2nd](../Text/chapter-2.html#p98),
    [3rd](../Text/chapter-2.html#p100), [4th](../Text/chapter-2.html#p109), [5th](../Text/chapter-2.html#p147)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '[\</unk\>标记](../Text/chapter-2.html#p96), [第2次](../Text/chapter-2.html#p98),
    [第3次](../Text/chapter-2.html#p100), [第4次](../Text/chapter-2.html#p109), [第5次](../Text/chapter-2.html#p147)'
- en: '[.view method](../Text/chapter-3.html#p293), [2nd](../Text/chapter-3.html#p294)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[.view方法](../Text/chapter-3.html#p293), [第2次](../Text/chapter-3.html#p294)'
- en: '[__init__ constructor](../Text/chapter-3.html#p172), [2nd](../Text/chapter-4.html#p170),
    [3rd](../Text/appendix-a.html#p144)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '[.shape attribute](../Text/appendix-a.html#p89)'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '[@ operator](../Text/appendix-a.html#p110)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '[__len__ method](../Text/appendix-a.html#p202)'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '[\<|endoftext|> token](../Text/chapter-2.html#p146)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '[.pth extension](../Text/chapter-5.html#p242)'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: <i>Dolma\
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '[An Open Corpus of Three Trillion Tokens for LLM Pretraining Research</> (Soldaini
    et al.)](../Text/chapter-1.html#p64)'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '[== comparison operator](../Text/appendix-a.html#p253)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: A
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[arXiv](../Text/chapter-7.html#p267)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '[Alpaca dataset](../Text/chapter-7.html#p172), [2nd](../Text/appendix-b.html#p88)'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '[argmax function](../Text/chapter-5.html#p43), [2nd](../Text/chapter-5.html#p45),
    [3rd](../Text/chapter-5.html#p189), [4th](../Text/chapter-5.html#p195), [5th](../Text/chapter-6.html#p146),
    [6th](../Text/appendix-a.html#p245), [7th](../Text/appendix-a.html#p249)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: attention mechanisms
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '[coding](../Text/chapter-3.html#p1), [2nd](../Text/chapter-3.html#p23)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '[problem with modeling long sequences](../Text/chapter-3.html#p13)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '[attention scores](../Text/chapter-3.html#p46)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '[AI (artificial intelligence)](../Text/appendix-a.html#p14)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '[autograd engine](../Text/appendix-a.html#p129)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '[alpha scaling factor](../Text/appendix-e.html#p54)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '[autoregressive model](../Text/chapter-1.html#p72)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '[attention weights, computing step by step](../Text/chapter-3.html#p116), [2nd](../Text/chapter-3.html#p163)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '[attn_scores](../Text/chapter-3.html#p173)'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '[Axolotl](../Text/chapter-7.html#p270)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '[allowed_max_length](../Text/appendix-c.html#p114)'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '[AdamW optimizer](../Text/chapter-5.html#p156), [2nd](../Text/appendix-b.html#p59)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: B
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '[Bahdanau attention mechanism](../Text/chapter-3.html#p24)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '[backpropagation](../Text/chapter-5.html#p63)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '[BERT (bidirectional encoder representations from transformers)](../Text/chapter-1.html#p48)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '[BPE (byte pair encoding)](../Text/chapter-2.html#p129)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: '[batch_size](../Text/chapter-7.html#p173)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: C
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '[compute_accuracy function](../Text/appendix-a.html#p262), [2nd](../Text/appendix-a.html#p264)'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '[causal attention mask](../Text/chapter-6.html#p137)'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '[clip_grad_norm_ function](../Text/appendix-d.html#p34)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '[calc_loss_loader function](../Text/chapter-5.html#p130)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '[cross_entropy function](../Text/chapter-5.html#p77), [2nd](../Text/chapter-5.html#p80),
    [3rd](../Text/chapter-5.html#p91)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '[conversational performance](../Text/chapter-7.html#p187)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '[custom_collate_draft_1](../Text/chapter-7.html#p67)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '[custom_collate_draft_2](../Text/chapter-7.html#p78)'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: '[calc_accuracy_loader function](../Text/chapter-6.html#p157)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '[calc_loss_batch function](../Text/chapter-5.html#p132), [2nd](../Text/chapter-6.html#p165),
    [3rd](../Text/chapter-6.html#p167)'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: classification
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '[tasks](../Text/chapter-1.html#p41)'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: '[custom_collate_fn function](../Text/chapter-7.html#p112), [2nd](../Text/appendix-c.html#p104)'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '[classify_review function](../Text/chapter-6.html#p202)'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '[context_length](../Text/chapter-4.html#p23)'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '[cfg dictionary](../Text/chapter-4.html#p150)'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '[computing gradients](../Text/appendix-a.html#p62)'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '[context vectors](../Text/chapter-3.html#p41), [2nd](../Text/chapter-3.html#p106),
    [3rd](../Text/chapter-3.html#p280)'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '[CausalAttention class](../Text/chapter-3.html#p250), [2nd](../Text/chapter-3.html#p258)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: D
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '[DistributedSampler](../Text/appendix-a.html#p325)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '[dim parameter](../Text/chapter-4.html#p65), [2nd](../Text/chapter-4.html#p65)'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: '[Dataset class](../Text/chapter-2.html#p181), [2nd](../Text/chapter-6.html#p59),
    [3rd](../Text/appendix-a.html#p193), [4th](../Text/appendix-a.html#p194), [5th](../Text/appendix-a.html#p200),
    [6th](../Text/appendix-a.html#p206), [7th](../Text/appendix-a.html#p223)'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '[DataLoader class](../Text/chapter-7.html#p53), [2nd](../Text/chapter-7.html#p118)'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: datasets
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '[downloading](../Text/chapter-7.html#p19)'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '[download_and_load_gpt2 function](../Text/chapter-5.html#p261), [2nd](../Text/chapter-5.html#p274),
    [3rd](../Text/chapter-6.html#p88)'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '[DummyGPTClass](../Text/chapter-4.html#p37)'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '[DistributedDataParallel class](../Text/appendix-a.html#p333)'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '[DummyLayerNorm](../Text/chapter-4.html#p35), [2nd](../Text/chapter-4.html#p48)'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '[placeholder](../Text/chapter-4.html#p52)'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '[DummyGPTModel](../Text/chapter-4.html#p29), [2nd](../Text/chapter-4.html#p31),
    [3rd](../Text/chapter-4.html#p33), [4th](../Text/chapter-4.html#p42)'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '[deep learning](../Text/appendix-a.html#p18)'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '[dot products](../Text/chapter-3.html#p53)'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '[DDP (DistributedDataParallel) strategy](../Text/appendix-a.html#p322)'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '[device variable](../Text/chapter-7.html#p115)'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '[decode method](../Text/chapter-2.html#p142), [2nd](../Text/chapter-2.html#p152)'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '[data loaders](../Text/chapter-6.html#p49), [2nd](../Text/chapter-6.html#p82)'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: '[code for](../Text/appendix-c.html#p14)'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: dropout
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: '[defined](../Text/chapter-3.html#p234)'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: '[drop_rate](../Text/chapter-4.html#p27)'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '[drop_last parameter](../Text/appendix-a.html#p213)'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '[DummyTransformerBlock](../Text/chapter-4.html#p163)'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '[data list](../Text/chapter-7.html#p22)'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '[ddp_setup function](../Text/appendix-a.html#p340)'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '[d_out argument](../Text/chapter-3.html#p312), [2nd](../Text/appendix-c.html#p27)'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '[DataFrame](../Text/chapter-6.html#p26)'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: E
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '[eps variable](../Text/chapter-4.html#p78)'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '[evaluate_model function](../Text/chapter-5.html#p150), [2nd](../Text/chapter-5.html#p150),
    [3rd](../Text/chapter-5.html#p154), [4th](../Text/chapter-6.html#p179)'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '[embedding size](../Text/chapter-2.html#p239)'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '[emergent behavior](../Text/chapter-1.html#p77)'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '[encoder](../Text/chapter-3.html#p15)'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '[encode method](../Text/chapter-2.html#p76), [2nd](../Text/chapter-2.html#p138),
    [3rd](../Text/chapter-2.html#p175)'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '[emb_dim](../Text/chapter-4.html#p24)'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '[eval_iter value](../Text/chapter-6.html#p196)'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: F
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '[find_highest_gradient function](../Text/appendix-d.html#p46)'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '[first_batch variable](../Text/chapter-2.html#p188)'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '[FeedForward module](../Text/chapter-4.html#p106), [2nd](../Text/chapter-4.html#p108),
    [3rd](../Text/chapter-4.html#p112), [4th](../Text/chapter-4.html#p146)'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '[format_input function](../Text/chapter-7.html#p35), [2nd](../Text/chapter-7.html#p37),
    [3rd](../Text/chapter-7.html#p41), [4th](../Text/chapter-7.html#p230), [5th](../Text/appendix-c.html#p94),
    [6th](../Text/appendix-c.html#p96)'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: fine-tuning
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '[LLMs, to follow instructions](../Text/chapter-7.html#p1)'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '[categories of](../Text/chapter-6.html#p11)'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '[for classification](../Text/chapter-6.html#p1)'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '[forward method](../Text/chapter-4.html#p34), [2nd](../Text/chapter-4.html#p121)'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: G
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '[generate_and_print_sample function](../Text/chapter-5.html#p152)'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: '[GELU (Gaussian error linear unit)](../Text/appendix-b.html#p41)'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: '[activation function](../Text/chapter-4.html#p85), [2nd](../Text/chapter-4.html#p123)'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '[GPTModel](../Text/chapter-4.html#p169), [2nd](../Text/chapter-4.html#p192),
    [3rd](../Text/chapter-4.html#p195), [4th](../Text/chapter-4.html#p199), [5th](../Text/chapter-5.html#p31),
    [6th](../Text/appendix-e.html#p66)'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: '[class](../Text/chapter-4.html#p202), [2nd](../Text/chapter-6.html#p90)'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: '[code](../Text/chapter-5.html#p114)'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: '[instance](../Text/chapter-5.html#p18), [2nd](../Text/chapter-5.html#p238),
    [3rd](../Text/chapter-5.html#p286), [4th](../Text/chapter-5.html#p300)'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '[GPT (Generative Pre-trained Transformer)](../Text/chapter-1.html#p48)'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '[architecture](../Text/chapter-1.html#p69)'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: '[coding](../Text/chapter-4.html#p162), [2nd](../Text/chapter-4.html#p200)'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '[implementing from scratch to generate text](../Text/chapter-4.html#p1)'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '[grad_fn value](../Text/appendix-a.html#p180)'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: '[gpt_download.py Python module](../Text/chapter-5.html#p258)'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '[GPT_CONFIG_124M dictionary](../Text/chapter-4.html#p21), [2nd](../Text/chapter-4.html#p153),
    [3rd](../Text/chapter-4.html#p164), [4th](../Text/chapter-4.html#p173), [5th](../Text/chapter-4.html#p231),
    [6th](../Text/chapter-5.html#p16)'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '[generative text models, evaluating](../Text/chapter-5.html#p11)'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: '[GenAI (generative AI)](../Text/chapter-1.html#p16)'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '[gpt2-medium355M-sft.pth file](../Text/chapter-7.html#p200)'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: '[GPTDatasetV1 class](../Text/chapter-2.html#p180), [2nd](../Text/chapter-2.html#p182),
    [3rd](../Text/chapter-2.html#p184)'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: '[generate_text_simple function](../Text/chapter-4.html#p213), [2nd](../Text/chapter-4.html#p215),
    [3rd](../Text/chapter-4.html#p217), [4th](../Text/chapter-5.html#p42), [5th](../Text/chapter-5.html#p181),
    [6th](../Text/chapter-5.html#p186)'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '[GPT-4](../Text/chapter-7.html#p209)'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '[GPT-2](../Text/chapter-4.html#p18)'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '[model](../Text/chapter-7.html#p158)'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: '[tokenizer](../Text/chapter-6.html#p54)'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: '[GPT-3](../Text/chapter-1.html#p62)'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '[generate_model_scores function](../Text/chapter-7.html#p244), [2nd](../Text/chapter-7.html#p246)'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: '[Google Colab](../Text/appendix-a.html#p48)'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '[generate function](../Text/chapter-5.html#p235), [2nd](../Text/chapter-5.html#p294),
    [3rd](../Text/chapter-7.html#p142), [4th](../Text/chapter-7.html#p177), [5th](../Text/chapter-7.html#p179),
    [6th](../Text/chapter-7.html#p192), [7th](../Text/appendix-c.html#p60)'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: I
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: '[init_process_group function](../Text/appendix-a.html#p335)'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: '[instruction dataset](../Text/chapter-7.html#p10)'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '[information leakage](../Text/chapter-3.html#p216)'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '[input_embeddings](../Text/chapter-2.html#p261)'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '[InstructionDataset class](../Text/chapter-7.html#p55), [2nd](../Text/appendix-c.html#p102)'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '[instruction fine-tuning](../Text/chapter-1.html#p41)'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: '[instruction following, creating data loaders for instruction dataset](../Text/chapter-7.html#p110),
    [2nd](../Text/chapter-7.html#p126)'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '[overview](../Text/chapter-7.html#p12)'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '[’instruction’ object](../Text/chapter-7.html#p26)'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: K
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '[keepdim parameter](../Text/chapter-4.html#p64)'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: L
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '[logits tensor](../Text/chapter-5.html#p85)'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: '[LinearWithLoRA layer](../Text/appendix-e.html#p70), [2nd](../Text/appendix-e.html#p83)'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '[LoRALayer class](../Text/appendix-e.html#p59), [2nd](../Text/appendix-e.html#p64)'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '[loss metric](../Text/chapter-5.html#p26)'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '[LLMs (large language models)](../Text/chapter-2.html#p7), [2nd](../Text/chapter-2.html#p10)'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '[applications of](../Text/chapter-1.html#p24)'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '[building and using](../Text/chapter-1.html#p31), [2nd](../Text/chapter-1.html#p42),
    [3rd](../Text/chapter-1.html#p79)'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: '[coding architecture](../Text/chapter-4.html#p11)'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: '[coding attention mechanisms, causal attention mechanism](../Text/chapter-3.html#p194),
    [2nd](../Text/chapter-3.html#p262)'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '[fine-tuning](../Text/chapter-7.html#p149), [2nd](../Text/chapter-7.html#p204),
    [3rd](../Text/appendix-b.html#p72)'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: '[fine-tuning for classification](../Text/chapter-6.html#p100), [2nd](../Text/chapter-6.html#p140),
    [3rd](../Text/chapter-6.html#p144), [4th](../Text/chapter-6.html#p173), [5th](../Text/chapter-6.html#p202)'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: '[instruction fine-tuning, loading pretrained LLMs](../Text/chapter-7.html#p128),
    [2nd](../Text/chapter-7.html#p147)'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '[overview of](../Text/chapter-1.html#p1), [2nd](../Text/chapter-1.html#p13),
    [3rd](../Text/chapter-1.html#p22)'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: '[utilizing large datasets](../Text/chapter-1.html#p57)'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: '[Linear layers](../Text/appendix-e.html#p60), [2nd](../Text/appendix-e.html#p68)'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: '[LayerNorm](../Text/chapter-4.html#p81), [2nd](../Text/chapter-4.html#p151),
    [3rd](../Text/chapter-4.html#p171)'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: '[LIMA dataset](../Text/appendix-b.html#p90)'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '[layer normalization](../Text/chapter-4.html#p51), [2nd](../Text/chapter-4.html#p88)'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '[load_state_dict method](../Text/chapter-5.html#p248)'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: '[load_weights_into_gpt function](../Text/chapter-5.html#p288), [2nd](../Text/chapter-5.html#p290),
    [3rd](../Text/chapter-5.html#p291), [4th](../Text/chapter-5.html#p292)'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: '[loss.backward() function](../Text/chapter-4.html#p128)'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: '[Linear layer weights](../Text/appendix-e.html#p62)'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: '[Llama 3 model](../Text/chapter-7.html#p206)'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: '[LLama 2 model](../Text/chapter-5.html#p107)'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: '[LoRA (low-rank adaptation)](../Text/chapter-7.html#p259), [2nd](../Text/appendix-e.html#p2),
    [3rd](../Text/appendix-e.html#p4)'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: '[parameter-efficient fine-tuning](../Text/appendix-e.html#p25), [2nd](../Text/appendix-e.html#p41)'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: M
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: '[main function](../Text/appendix-a.html#p338)'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: '[max_length](../Text/chapter-5.html#p115), [2nd](../Text/chapter-6.html#p62),
    [3rd](../Text/appendix-c.html#p82)'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: '[model.eval() function](../Text/chapter-5.html#p245)'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: '[MultiHeadAttention class](../Text/chapter-3.html#p290), [2nd](../Text/chapter-3.html#p309),
    [3rd](../Text/chapter-3.html#p310), [4th](../Text/chapter-3.html#p314), [5th](../Text/chapter-3.html#p317),
    [6th](../Text/appendix-b.html#p32)'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: '[model.train() setting](../Text/appendix-a.html#p233)'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: '[MultiHeadAttentionWrapper class](../Text/chapter-3.html#p272), [2nd](../Text/chapter-3.html#p274),
    [3rd](../Text/chapter-3.html#p282), [4th](../Text/chapter-3.html#p283), [5th](../Text/chapter-3.html#p286),
    [6th](../Text/chapter-3.html#p287), [7th](../Text/chapter-3.html#p291)'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: '[machine learning](../Text/appendix-a.html#p15)'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: '[multi-head attention](../Text/chapter-3.html#p249), [2nd](../Text/chapter-3.html#p265)'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: '[Module base class](../Text/appendix-a.html#p143)'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: '[multiprocessing submodule](../Text/appendix-a.html#p334)'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '[masked attention](../Text/chapter-3.html#p194)'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: '[multinomial function](../Text/chapter-5.html#p191), [2nd](../Text/chapter-5.html#p202),
    [3rd](../Text/chapter-5.html#p203)'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: '[macOS](../Text/appendix-a.html#p312)'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: '[model_response](../Text/chapter-7.html#p198)'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: '[minbpe repository](../Text/appendix-b.html#p21)'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: '[model_configs table](../Text/chapter-5.html#p278)'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: '[mps device](../Text/chapter-7.html#p113)'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: N
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: '[NEW_CONFIG dictionary](../Text/chapter-5.html#p284)'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: neural networks
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: '[implementing feed forward network with GELU activations](../Text/chapter-4.html#p92),
    [2nd](../Text/chapter-4.html#p115)'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: '[nn.Linear layers](../Text/chapter-3.html#p181)'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: '[n_heads](../Text/chapter-4.html#p25)'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: '[numel() method](../Text/chapter-4.html#p178)'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: '[num_heads dimension](../Text/chapter-3.html#p295)'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: O
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: '[output layer nodes](../Text/chapter-6.html#p103)'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: '[ollama run llama3 command](../Text/chapter-7.html#p216), [2nd](../Text/chapter-7.html#p220),
    [3rd](../Text/chapter-7.html#p225)'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: '[ollama serve command](../Text/chapter-7.html#p213), [2nd](../Text/chapter-7.html#p214),
    [3rd](../Text/chapter-7.html#p215), [4th](../Text/chapter-7.html#p228)'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: '[optimizer.zero_grad() method](../Text/appendix-a.html#p235)'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: '[Ollama application](../Text/chapter-7.html#p207), [2nd](../Text/chapter-7.html#p219)'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: '[Ollama Llama 3 method](../Text/appendix-c.html#p106)'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: '[ollama run command](../Text/chapter-7.html#p232)'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: P
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: '[and Torch](../Text/appendix-a.html#p41)'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: '[automatic differentiation](../Text/appendix-a.html#p124), [2nd](../Text/appendix-a.html#p139)'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: '[computation graphs](../Text/appendix-a.html#p116)'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: '[data loaders](../Text/chapter-7.html#p45)'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: '[dataset objects](../Text/appendix-e.html#p30)'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: '[efficient data loaders](../Text/appendix-a.html#p192)'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: '[implementing multilayer neural networks](../Text/appendix-a.html#p141), [2nd](../Text/appendix-a.html#p190)'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: '[installing](../Text/appendix-a.html#p24), [2nd](../Text/appendix-a.html#p51)'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: '[loading and saving model weights in](../Text/chapter-5.html#p237)'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: '[optimizing training performance with GPUs](../Text/appendix-a.html#p282)'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: '[overview](../Text/appendix-a.html#p2), [2nd](../Text/appendix-a.html#p6)'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: '[with a NumPy-like API](../Text/appendix-a.html#p59)'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: '[pip installer](../Text/chapter-2.html#p132)'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: '[Phi-3 model](../Text/appendix-b.html#p93)'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: '[print_gradients function](../Text/chapter-4.html#p131), [2nd](../Text/chapter-4.html#p135)'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: '[plot_values function](../Text/chapter-6.html#p192)'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: parameters
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: '[calculating](../Text/appendix-c.html#p34)'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: '[perplexity](../Text/chapter-5.html#p96)'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: '[partial derivatives](../Text/appendix-a.html#p127)'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: '[print statement](../Text/chapter-2.html#p59)'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: '[plot_losses function](../Text/chapter-7.html#p166)'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: '[Python version](../Text/appendix-a.html#p26)'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: '[Prometheus model](../Text/appendix-b.html#p96)'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: '[prompt styles](../Text/chapter-7.html#p30)'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: '[pretraining](../Text/chapter-1.html#p39)'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: '[calculating training and validation set losses](../Text/chapter-5.html#p102)'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: '[on unlabeled data](../Text/chapter-5.html#p1)'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: '[training LLMs](../Text/chapter-5.html#p143), [2nd](../Text/chapter-5.html#p170)'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
- en: '[print_sampled_tokens function](../Text/chapter-5.html#p205), [2nd](../Text/appendix-c.html#p51)'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: '[pos_embeddings](../Text/chapter-2.html#p254), [2nd](../Text/chapter-2.html#p257)'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: '[preference fine-tuning](../Text/appendix-b.html#p101)'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: Q
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: '[qkv_bias](../Text/chapter-4.html#p28)'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: '[query_llama function](../Text/chapter-7.html#p235)'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: '[query_model function](../Text/chapter-7.html#p239)'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: R
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: '[responses, extracting and saving](../Text/chapter-7.html#p175), [2nd](../Text/chapter-7.html#p202)'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: '[re library](../Text/chapter-2.html#p36)'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: '[RMSNorm](../Text/appendix-b.html#p40)'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: '[ReLU (rectified linear unit)](../Text/chapter-4.html#p58), [2nd](../Text/chapter-4.html#p93)'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: '[re.split command](../Text/chapter-2.html#p37)'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: '[replace_linear_with_lora function](../Text/appendix-e.html#p74)'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: '[raw text](../Text/chapter-1.html#p37)'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: '[retrieval-augmented generation](../Text/chapter-2.html#p17)'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: '[RNNs (recurrent neural networks)](../Text/chapter-3.html#p16)'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: '[random_split function](../Text/chapter-6.html#p43)'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: S
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: '[shortcut connections](../Text/chapter-4.html#p118), [2nd](../Text/chapter-4.html#p142)'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: '[saving and loading models](../Text/appendix-a.html#p274)'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: '[SimpleTokenizerV1 class](../Text/chapter-2.html#p78), [2nd](../Text/chapter-2.html#p80)'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: '[spawn function](../Text/appendix-a.html#p337)'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: '[Sequential class](../Text/appendix-a.html#p152)'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: '[SelfAttention_v2 class](../Text/chapter-3.html#p183), [2nd](../Text/chapter-3.html#p189),
    [3rd](../Text/chapter-3.html#p190)'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: '[softmax_naive function](../Text/chapter-3.html#p68), [2nd](../Text/chapter-3.html#p70)'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
- en: '[sci_mode parameter](../Text/chapter-4.html#p72)'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: '[set_printoptions method](../Text/appendix-a.html#p244)'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: '[SGD (stochastic gradient descent)](../Text/appendix-a.html#p229)'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: '[SelfAttention_v1 class](../Text/chapter-3.html#p171), [2nd](../Text/chapter-3.html#p187)'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
- en: '[softmax function](../Text/appendix-a.html#p186), [2nd](../Text/appendix-a.html#p234),
    [3rd](../Text/appendix-a.html#p240)'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: '[self.register_buffer() call](../Text/chapter-3.html#p257)'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
- en: '[state_dict](../Text/chapter-5.html#p246), [2nd](../Text/appendix-a.html#p276)'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: '[SpamDataset class](../Text/chapter-6.html#p58), [2nd](../Text/chapter-6.html#p60),
    [3rd](../Text/chapter-6.html#p65)'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: '[special context tokens](../Text/chapter-2.html#p118)'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: '[stride setting](../Text/chapter-2.html#p193)'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
- en: '[self.out_proj layer](../Text/chapter-3.html#p308)'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: '[supervised learning](../Text/appendix-a.html#p19)'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
- en: '[supervised data, fine-tuning model on](../Text/chapter-6.html#p175)'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: '[strip() function](../Text/chapter-7.html#p145)'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: supervised instruction fine-tuning
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: '[preparing dataset for](../Text/chapter-7.html#p17), [2nd](../Text/chapter-7.html#p49)'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: '[settings dictionary](../Text/chapter-5.html#p270), [2nd](../Text/chapter-5.html#p276)'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
- en: '[self-attention mechanism](../Text/chapter-3.html#p31)'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: '[computing attention weights for all input tokens](../Text/chapter-3.html#p79),
    [2nd](../Text/chapter-3.html#p108)'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: '[implementing with trainable weights](../Text/chapter-3.html#p110), [2nd](../Text/chapter-3.html#p192)'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
- en: '[without trainable weights](../Text/chapter-3.html#p37), [2nd](../Text/chapter-3.html#p77)'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: '[single-head attention, stacking multiple layers](../Text/chapter-3.html#p269)'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: '[SimpleTokenizerV2 class](../Text/chapter-2.html#p96), [2nd](../Text/chapter-2.html#p109)'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: T
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
- en: '[text generation function, modifying](../Text/chapter-5.html#p225)'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
- en: '[train_ratio](../Text/chapter-5.html#p118)'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: '[text data](../Text/chapter-2.html#p1)'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
- en: '[adding special context tokens](../Text/chapter-2.html#p96), [2nd](../Text/chapter-2.html#p128)'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: '[creating token embeddings](../Text/chapter-2.html#p208)'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: '[sliding window](../Text/chapter-2.html#p155), [2nd](../Text/chapter-2.html#p202)'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: '[tokenization, byte pair encoding](../Text/chapter-2.html#p131), [2nd](../Text/chapter-2.html#p153)'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: '[torch.save function](../Text/chapter-5.html#p240)'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: '[token IDs](../Text/chapter-2.html#p64), [2nd](../Text/chapter-2.html#p94)'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
- en: '[tensor library](../Text/appendix-a.html#p11)'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
- en: '[TransformerBlock class](../Text/chapter-4.html#p149)'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
- en: '[token_embedding_layer](../Text/chapter-2.html#p241), [2nd](../Text/chapter-2.html#p252)'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
- en: '[token embeddings](../Text/chapter-2.html#p204), [2nd](../Text/chapter-2.html#p229)'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: '[train_simple_function](../Text/appendix-c.html#p66)'
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
- en: '[ToyDataset class](../Text/appendix-a.html#p197), [2nd](../Text/appendix-a.html#p199)'
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: training function
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: '[enhancing](../Text/appendix-d.html#p2)'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
- en: '[modified](../Text/appendix-d.html#p55), [2nd](../Text/appendix-d.html#p63)'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
- en: '[train_data subset](../Text/chapter-5.html#p120)'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
- en: '[tril function](../Text/chapter-3.html#p204)'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
- en: '[tokenizing text](../Text/chapter-2.html#p25), [2nd](../Text/chapter-2.html#p61)'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
- en: training, optimizing performance with GPUs
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
- en: '[PyTorch computations on GPU devices](../Text/appendix-a.html#p284)'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
- en: '[selecting available GPUs on multi-GPU machine](../Text/appendix-a.html#p342),
    [2nd](../Text/appendix-a.html#p357)'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
- en: '[single-GPU training](../Text/appendix-a.html#p304)'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
- en: '[training with multiple GPUs](../Text/appendix-a.html#p320)'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
- en: '[test_loader](../Text/appendix-a.html#p208)'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
- en: '[train_loader](../Text/appendix-a.html#p212)'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
- en: '[torch.sum method](../Text/appendix-a.html#p257)'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: '[training loops](../Text/appendix-a.html#p225), [2nd](../Text/appendix-a.html#p271)'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
- en: '[cosine decay](../Text/appendix-d.html#p24)'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
- en: '[gradient clipping](../Text/appendix-d.html#p33)'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
- en: '[learning rate warmup](../Text/appendix-d.html#p10)'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
- en: '[train_classifier_simple function](../Text/chapter-6.html#p181), [2nd](../Text/chapter-6.html#p194)'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
- en: '[training batches, organizing data into](../Text/chapter-7.html#p51), [2nd](../Text/chapter-7.html#p108)'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
- en: '[text generation](../Text/chapter-4.html#p204)'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
- en: '[using GPT to generate text](../Text/chapter-5.html#p14)'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
- en: '[top-k sampling](../Text/chapter-5.html#p207), [2nd](../Text/chapter-5.html#p208)'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
- en: '[text_data](../Text/appendix-d.html#p7)'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
- en: '[transformer architecture](../Text/chapter-1.html#p15), [2nd](../Text/chapter-1.html#p44),
    [3rd](../Text/chapter-1.html#p55), [4th](../Text/chapter-3.html#p26)'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
- en: '[temperature scaling](../Text/chapter-5.html#p181), [2nd](../Text/chapter-5.html#p196)'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
- en: '[train_model_simple function](../Text/chapter-5.html#p147), [2nd](../Text/chapter-5.html#p149),
    [3rd](../Text/chapter-5.html#p157), [4th](../Text/chapter-5.html#p245), [5th](../Text/chapter-5.html#p251),
    [6th](../Text/chapter-6.html#p177)'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
- en: '[tensor2d](../Text/appendix-a.html#p67)'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
- en: '[tensor3d](../Text/appendix-a.html#p67)'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: '[torch.no_grad() context manager](../Text/appendix-a.html#p182)'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
- en: '[test_set dictionary](../Text/chapter-7.html#p191), [2nd](../Text/chapter-7.html#p196)'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
- en: '[tensors](../Text/appendix-a.html#p59)'
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
- en: '[common tensor operations](../Text/appendix-a.html#p84)'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
- en: '[tensor data types](../Text/appendix-a.html#p69)'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
- en: '[torch.nn.Linear layers](../Text/appendix-a.html#p158)'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
- en: '[transformer blocks](../Text/chapter-4.html#p13), [2nd](../Text/chapter-6.html#p106)'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
- en: '[connecting attention and linear layers in](../Text/chapter-4.html#p144), [2nd](../Text/chapter-4.html#p159)'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
- en: '[text generation loss](../Text/chapter-5.html#p29)'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
- en: '[torchvision library](../Text/appendix-a.html#p31)'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
- en: U
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
- en: '[unbiased parameter](../Text/chapter-4.html#p80)'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
- en: '[unlabeled data, decoding strategies to control randomness](../Text/chapter-5.html#p172)'
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
- en: V
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
- en: '[variable-length inputs](../Text/chapter-5.html#p117)'
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
- en: '[vocab_size](../Text/chapter-4.html#p22)'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
- en: '[v vector](../Text/appendix-d.html#p35)'
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
- en: '[vectors](../Text/appendix-a.html#p66), [2nd](../Text/appendix-a.html#p114)'
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
- en: W
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
- en: '[W<.Subscript>q</> matrix](../Text/chapter-3.html#p292)'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
- en: '[weight parameters](../Text/chapter-3.html#p131), [2nd](../Text/chapter-5.html#p9)'
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
- en: '[word embeddings](../Text/chapter-2.html#p13), [2nd](../Text/chapter-2.html#p23)'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
- en: '[weight_decay parameter](../Text/chapter-6.html#p200)'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
- en: '[Word2Vec](../Text/chapter-2.html#p18)'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
- en: weights
  id: totrans-489
  prefs: []
  type: TYPE_NORMAL
- en: '[initializing model with pretrained weights](../Text/chapter-6.html#p84)'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
- en: '[loading pretrained weights from OpenAI](../Text/chapter-5.html#p253), [2nd](../Text/chapter-5.html#p302)'
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
- en: '[word positions, encoding](../Text/chapter-2.html#p231)'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
- en: '[weight splits](../Text/chapter-3.html#p285)'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
- en: X
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
- en: '[X training example](../Text/appendix-a.html#p178)'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
