- en: Part 3\. Deep learning for tabular data
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3部分：表格数据的深度学习
- en: Part 3 is your guide to the know-how and practical insights needed to apply
    deep learning to tabular data problems. As a stand-alone solution or integrated
    with gradient boosting, deep learning can get good results with tabular data when
    you know how to use its unique way of finding solutions to predictive tasks.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 第3部分是您应用深度学习解决表格数据问题的知识和实用见解指南。作为一个独立的解决方案或与梯度提升集成，当您知道如何使用其独特的解决预测任务的方法时，深度学习可以针对表格数据获得良好的结果。
- en: Chapter 8 explores various deep learning stacks and frameworks for working with
    tabular data, including low-level frameworks like TensorFlow and PyTorch and high-level
    APIs like fastai and Lightning Flash. It introduces several libraries specifically
    designed for tabular deep learning tasks, such as TabNet, PyTorch Tabular, SAINT,
    and DeepTables. We compare the different stacks and discuss each one’s strengths
    and weaknesses. Chapter 9 extends the discussion to best practices. We use the
    Kuala Lumpur real estate dataset to illustrate these best practices for deep learning
    with tabular data, including data preparation, model architecture design, and
    model training. A Keras-based project, the example emphasizes easy, understandable,
    and effective data pipelines, along with a modular approach that promotes code
    reuse.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 第8章探讨了用于处理表格数据的各种深度学习堆栈和框架，包括像TensorFlow和PyTorch这样的低级框架，以及像fastai和Lightning
    Flash这样的高级API。它介绍了几个专门为表格深度学习任务设计的库，例如TabNet、PyTorch Tabular、SAINT和DeepTables。我们比较了不同的堆栈，并讨论了每个堆栈的优缺点。第9章将讨论扩展到最佳实践。我们使用吉隆坡房地产数据集来说明这些表格数据深度学习的最佳实践，包括数据准备、模型架构设计和模型训练。一个基于Keras的项目，该示例强调简单、易懂和有效的数据管道，以及促进代码重用的模块化方法。
- en: Chapter 10 explores how to make a trained deep learning model available for
    use in a real-world environment using Flask, a Python framework that excels in
    web interfaces and API serving. Chapter 11 extends the discussion by guiding you
    through the steps to define a pipeline for training and deploying a model using
    the Vertex AI environment in Google Cloud, including creating Docker containers
    to encapsulate the model code and dependencies, defining pipeline steps, and running
    the pipeline on Vertex AI. We then proceed to discuss Gemini’s capabilities for
    Google Cloud, such as answering questions about Google Cloud, generating code
    from text, interpreting code, and summarizing log entries. All these capabilities
    can be applied to your workflow to create your own machine learning pipeline.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 第10章探讨了如何使用Flask（一个在Web界面和API服务方面表现卓越的Python框架）使训练好的深度学习模型在现实世界环境中可用。第11章通过指导您在Google
    Cloud的Vertex AI环境中定义用于训练和部署模型的管道步骤，扩展了讨论，包括创建Docker容器来封装模型代码和依赖项，定义管道步骤，并在Vertex
    AI上运行管道。然后我们继续讨论Gemini在Google Cloud中的功能，例如回答有关Google Cloud的问题、从文本生成代码、解释代码和总结日志条目。所有这些功能都可以应用于您的流程，以创建您自己的机器学习管道。
- en: The book concludes with chapter 12, where you will learn how to combine deep
    learning with machine learning to achieve state-of-the-art results in predictive
    tasks. After you read this book, model design, training, deployment, and interpretability
    will no longer hold any secrets for you!
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本书以第12章结束，你将学习如何将深度学习与机器学习相结合，以在预测任务中实现最先进的结果。阅读完这本书后，模型设计、训练、部署和可解释性将不再对你有任何秘密！
