["```py\nimport numpy as np\nweights = sess.run(W)\nnp.savez(os.path.join(path, 'weight_storage'), weights)\n```", "```py\nloaded_w = np.load(path + 'weight_storage.npz')\nloaded_w = loaded_w.items()[0][1]\n\nx = tf.placeholder(tf.float32, [None, 784])\nW = tf.Variable(tf.zeros([784, 10]))\ny_true = tf.placeholder(tf.float32, [None, 10])\ny_pred = tf.matmul(x, W)\ncross_entropy = tf.reduce_mean(\n            tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, \n                                                    labels=y_true))\ngd_step = tf.train.GradientDescentOptimizer(0.5)\\\n                                            .minimize(cross_entropy)\ncorrect_mask = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_mask, tf.float32))\n\nwith tf.Session() as sess:\n    # Assigning loaded weights\n  sess.run(W.assign(loaded_w))\n  acc = sess.run(accuracy, feed_dict={x: data.test.images, \n                                       y_true: data.test.labels})\n\nprint(\"Accuracy: {}\".format(acc))\n\nOut: \nAccuracy: 0.9199\n\n```", "```py\nif weights is not None and sess is not None:\n  self.load_weights(weights, sess)\n```", "```py\ndef load_weights(self, weights, sess):\n  for i,w in enumerate(weights):\n    print(\"Weight index: {}\".format(i), \n                           \"Weight shape: {}\".format(w.shape))\n    sess.run(self.parameters[i].assign(w))\n```", "```py\nclass simple_cnn:\n  def __init__(self, x_image,keep_prob, weights=None, sess=None):\n\n    self.parameters = []\n    self.x_image = x_image\n\n    conv1 = self.conv_layer(x_image, shape=[5, 5, 1, 32])\n    conv1_pool = self.max_pool_2x2(conv1)\n\n    conv2 = self.conv_layer(conv1_pool, shape=[5, 5, 32, 64])\n    conv2_pool = self.max_pool_2x2(conv2)\n\n    conv2_flat = tf.reshape(conv2_pool, [-1, 7*7*64])\n    full_1 = tf.nn.relu(self.full_layer(conv2_flat, 1024))\n\n    full1_drop = tf.nn.dropout(full_1, keep_prob=keep_prob)\n\n    self.y_conv = self.full_layer(full1_drop, 10)\n\n    if weights is not None and sess is not None:\n      self.load_weights(weights, sess)\n\n  def weight_variable(self,shape):\n    initial = tf.truncated_normal(shape, stddev=0.1)\n    return tf.Variable(initial,name='weights')\n\n  def bias_variable(self,shape):\n    initial = tf.constant(0.1, shape=shape)\n    return tf.Variable(initial,name='biases')\n\n  def conv2d(self,x, W):\n    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], \n                                      padding='SAME')\n\n  def max_pool_2x2(self,x):\n    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n               strides=[1, 2, 2, 1], padding='SAME')\n\n  def conv_layer(self,input, shape):\n    W = self.weight_variable(shape)\n    b = self.bias_variable([shape[3]])\n    self.parameters += [W, b]\n\n    return tf.nn.relu(self.conv2d(input, W) + b)\n\n  def full_layer(self,input, size):\n    in_size = int(input.get_shape()[1])\n    W = self.weight_variable([in_size, size])\n    b = self.bias_variable([size])\n    self.parameters += [W, b]\n    return tf.matmul(input, W) + b\n\n  def load_weights(self, weights, sess):\n    for i,w in enumerate(weights):\n      print(\"Weight index: {}\".format(i), \n                              \"Weight shape: {}\".format(w.shape))\n      sess.run(self.parameters[i].assign(w))\n\n```", "```py\nx = tf.placeholder(tf.float32, shape=[None, 784])\nx_image = tf.reshape(x, [-1, 28, 28, 1])\ny_ = tf.placeholder(tf.float32, shape=[None, 10])\nkeep_prob = tf.placeholder(tf.float32)\n\nsess = tf.Session()\n\nweights = np.load(path + 'cnn_weight_storage.npz')\nweights = weights.items()[0][1]\ncnn = simple_cnn(x_image, keep_prob, weights, sess)\n\ncross_entropy = tf.reduce_mean(\n           tf.nn.softmax_cross_entropy_with_logits(\n                                                logits=cnn.y_conv,\n                                                 labels=y_))\ntrain_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n\ncorrect_prediction = tf.equal(tf.argmax(cnn.y_conv, 1), \n                                     tf.argmax(y_, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n\nX = data.test.images.reshape(10, 1000, 784)\nY = data.test.labels.reshape(10, 1000, 10)\ntest_accuracy = np.mean([sess.run(accuracy,\n            feed_dict={x:X[i], y_:Y[i],keep_prob:1.0})\n            for i in range(10)])\n\nsess.close()\n\nprint(\"test accuracy: {}\".format(test_accuracy))\n\nOut: \nWeight index: 0 Weight shape: (5, 5, 1, 32)\nWeight index: 1 Weight shape: (32,)\nWeight index: 2 Weight shape: (5, 5, 32, 64)\nWeight index: 3 Weight shape: (64,)\nWeight index: 4 Weight shape: (3136, 1024)\nWeight index: 5 Weight shape: (1024,)\nWeight index: 6 Weight shape: (1024, 10)\nWeight index: 7 Weight shape: (10,)\n\ntest accuracy: 0.990100026131\n\n```", "```py\nsaver = tf.train.Saver(max_to_keep=7, \n                      keep_checkpoint_every_n_hours=0.5)\n\n```", "```py\nDIR=\"*`path/to/model`*\"withtf.Session()assess:forstepinrange(1,NUM_STEPS+1):batch_xs,batch_ys=data.train.next_batch(MINIBATCH_SIZE)sess.run(gd_step,feed_dict={x:batch_xs,y_true:batch_ys})ifstep%50==0:saver.save(sess,os.path.join(DIR,\"model\"),global_step=step)\n```", "```py\nmodel_checkpoint_path: \"model_ckpt-1000\"\n\nall_model_checkpoint_paths: \"model_ckpt-700\"\n\nall_model_checkpoint_paths: \"model_ckpt-750\"\n\nall_model_checkpoint_paths: \"model_ckpt-800\"\n\nall_model_checkpoint_paths: \"model_ckpt-850\"\n\nall_model_checkpoint_paths: \"model_ckpt-900\"\n\nall_model_checkpoint_paths: \"model_ckpt-950\"\n\nall_model_checkpoint_paths: \"model_ckpt-1000\"\n```", "```py\nfromtensorflow.examples.tutorials.mnistimportinput_dataDATA_DIR='/tmp/data'data=input_data.read_data_sets(DATA_DIR,one_hot=True)NUM_STEPS=1000MINIBATCH_SIZE=100DIR=\"*`path/to/model`*\"x=tf.placeholder(tf.float32,[None,784],name='x')W=tf.Variable(tf.zeros([784,10]),name='W')y_true=tf.placeholder(tf.float32,[None,10])y_pred=tf.matmul(x,W)cross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred,labels=y_true))gd_step=tf.train.GradientDescentOptimizer(0.5)\\ .minimize(cross_entropy)correct_mask=tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))accuracy=tf.reduce_mean(tf.cast(correct_mask,tf.float32))saver=tf.train.Saver(max_to_keep=7,keep_checkpoint_every_n_hours=1)withtf.Session()assess:sess.run(tf.global_variables_initializer())forstepinrange(1,NUM_STEPS+1):batch_xs,batch_ys=data.train.next_batch(MINIBATCH_SIZE)sess.run(gd_step,feed_dict={x:batch_xs,y_true:batch_ys})ifstep%50==0:saver.save(sess,os.path.join(DIR,\"model_ckpt\"),global_step=step)ans=sess.run(accuracy,feed_dict={x:data.test.images,y_true:data.test.labels})print(\"Accuracy: {:.4}%\".format(ans*100))Out:Accuracy:90.87%\n```", "```py\ntf.reset_default_graph()\nx = tf.placeholder(tf.float32, [None, 784],name='x')\nW = tf.Variable(tf.zeros([784, 10]),name='W')\ny_true = tf.placeholder(tf.float32, [None, 10])\ny_pred = tf.matmul(x, W)\ncross_entropy = tf.reduce_mean(\n            tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, \n                                                    labels=y_true))\ngd_step = tf.train.GradientDescentOptimizer(0.5)\\\n                                            .minimize(cross_entropy)\ncorrect_mask = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\naccuracy = tf.reduce_mean(tf.cast(correct_mask, tf.float32))\n\nsaver = tf.train.Saver()\n\nwith tf.Session() as sess:\n\n  saver.restore(sess, os.path.join(DIR,\"model_ckpt-1000\"))\n  ans = sess.run(accuracy, feed_dict={x: data.test.images, \n                                       y_true: data.test.labels})\n\nprint(\"Accuracy: {:.4}%\".format(ans*100))\n\nOut:\nAccuracy: 90.87% \n\n```", "```py\nNotFoundError: Key W_1 not found in checkpoint\n\t [[Node: save/RestoreV2_2 = RestoreV2[\n   dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0\n   /task:0/cpu:0\"](_recv_save/Const_1_0, save/RestoreV2_2\n   /tensor_names, save/RestoreV2_2/shape_and_slices)]]\n```", "```py\nmeta_info_def {\n\u00a0 stripped_op_list {\n\u00a0 \u00a0 op {\n\u00a0 \u00a0 \u00a0 name: \"ApplyGradientDescent\"\n\u00a0 \u00a0 \u00a0 input_arg {\n\u00a0 \u00a0 \u00a0 \u00a0 name: \"var\"\n\u00a0 \u00a0 \u00a0 \u00a0 type_attr: \"T\"\n\u00a0 \u00a0 \u00a0 \u00a0 is_ref: true\n\u00a0 \u00a0 \u00a0 }\n\u00a0 \u00a0 \u00a0 input_arg {\n\u00a0 \u00a0 \u00a0 \u00a0 name: \"alpha\"\n\u00a0 \u00a0 \u00a0 \u00a0 type_attr: \"T\"\n\u00a0 \u00a0 \u00a0 }...\n\ngraph_def {\n\u00a0 node {\n\u00a0 \u00a0 name: \"Placeholder\"\n\u00a0 \u00a0 op: \"Placeholder\"\n\u00a0 \u00a0 attr {\n\u00a0 \u00a0 \u00a0 key: \"_output_shapes\"\n\u00a0 \u00a0 \u00a0 value {\n\u00a0 \u00a0 \u00a0 \u00a0 list {\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 shape {\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 dim {\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 size: -1\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 dim {\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 size: 784\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }\n\u00a0 \u00a0 \u00a0 \u00a0 }\n\u00a0 \u00a0 \u00a0 }\n\u00a0 \u00a0 }...\n\n```", "```py\ntf.reset_default_graph()DIR=\"*`path/to/model`*\"withtf.Session()assess:saver=tf.train.import_meta_graph(os.path.join(DIR,\"model_ckpt-1000.meta\"))saver.restore(sess,os.path.join(DIR,\"model_ckpt-1000\"))ans=sess.run(accuracy,feed_dict={x:data.test.images,y_true:data.test.labels})print(\"Accuracy: {:.4}%\".format(ans*100))\n```", "```py\ntrain_var = [x,y_true,accuracy]\ntf.add_to_collection('train_var', train_var[0])\ntf.add_to_collection('train_var', train_var[1])\ntf.add_to_collection('train_var', train_var[2])\n\n```", "```py\ntrain_var = [x,y_true,accuracy]\ntf.add_to_collection('train_var', train_var[0])\ntf.add_to_collection('train_var', train_var[1])\ntf.add_to_collection('train_var', train_var[2]) \n\nsaver = tf.train.Saver(max_to_keep=7,\n           keep_checkpoint_every_n_hours=1)\nsaver.export_meta_graph(os.path.join(DIR,\"model_ckpt.meta\")\n            ,collection_list=['train_var'])\n\n```", "```py\ntf.reset_default_graph()DIR=\"*`path/to/model`*\"withtf.Session()assess:sess.run(tf.global_variables_initializer())saver=tf.train.import_meta_graph(os.path.join(DIR,\"model_ckpt.meta\")saver.restore(sess,os.path.join(DIR,\"model_ckpt-1000\"))x=tf.get_collection('train_var')[0]y_true=tf.get_collection('train_var')[1]accuracy=tf.get_collection('train_var')[2]ans=sess.run(accuracy,feed_dict={x:data.test.images,y_true:data.test.labels})print(\"Accuracy: {:.4}%\".format(ans*100))Out:Accuracy:91.4%\n```", "```py\ndocker build --pull -t $USER/tensorflow-serving-devel -f \n\u00a0                                                 Dockerfile.devel .\n\n```", "```py\ndocker run -v $HOME/docker_files:/host_files \n\u00a0                        -p 80:80 -it $USER/tensorflow-serving-devel\n```", "```py\ngit clone --recurse-submodules https://github.com/tensorflow/serving\ncd serving/tensorflow\n./configure\n```", "```py\nbuilder = saved_model_builder.SavedModelBuilder(export_path)\n\n```", "```py\nexport_path_base = sys.argv[-1]\nexport_path = os.path.join(\n compat.as_bytes(export_path_base),\n compat.as_bytes(str(FLAGS.model_version)))\n```", "```py\nbuilder.add_meta_graph_and_variables(\n sess, [tag_constants.SERVING],\n signature_def_map={\n   'predict_images':\n     prediction_signature,\n   signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n     classification_signature,\n },\n legacy_init_op=legacy_init_op)\n```", "```py\nprediction_signature = signature_def_utils.build_signature_def(\n inputs={'images': tensor_info_x},\n outputs={'scores': tensor_info_y},\n method_name=signature_constants.PREDICT_METHOD_NAME)\n```", "```py\ntensor_info_x = utils.build_tensor_info(x)\ntensor_info_y = utils.build_tensor_info(y_conv)\n\n```", "```py\n# Build the signature_def_map\nclassification_inputs = utils.build_tensor_info(\n                                           serialized_tf_example)\nclassification_outputs_classes = utils.build_tensor_info(\n                                           prediction_classes)\nclassification_outputs_scores = utils.build_tensor_info(values)\n\n```", "```py\nclassification_signature = signature_def_utils.build_signature_def(\n inputs={signature_constants.CLASSIFY_INPUTS: \n                             classification_inputs},\n outputs={\n   signature_constants.CLASSIFY_OUTPUT_CLASSES:\n     classification_outputs_classes,\n   signature_constants.CLASSIFY_OUTPUT_SCORES:\n     classification_outputs_scores\n },\n method_name=signature_constants.CLASSIFY_METHOD_NAME)\n```", "```py\nbuilder.save()\n\n```", "```py\nimport os\nimport sys\nimport tensorflow as tf\nfrom tensorflow.python.saved_model import builder \n                                          as saved_model_builder\nfrom tensorflow.python.saved_model import signature_constants\nfrom tensorflow.python.saved_model import signature_def_utils\nfrom tensorflow.python.saved_model import tag_constants\nfrom tensorflow.python.saved_model import utils\nfrom tensorflow.python.util import compat\nfrom tensorflow_serving.example import mnist_input_data\n\ntf.app.flags.DEFINE_integer('training_iteration', 10,\n              'number of training iterations.')\ntf.app.flags.DEFINE_integer(\n                'model_version', 1, 'version number of the model.')\ntf.app.flags.DEFINE_string('work_dir', '/tmp', 'Working directory.')\nFLAGS = tf.app.flags.FLAGS\n\ndef weight_variable(shape):\n initial = tf.truncated_normal(shape, stddev=0.1)\n return tf.Variable(initial,dtype='float')\n\ndef bias_variable(shape):\n initial = tf.constant(0.1, shape=shape)\n return tf.Variable(initial,dtype='float')\n\ndef conv2d(x, W):\n return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n\ndef max_pool_2x2(x):\n return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n            strides=[1, 2, 2, 1], padding='SAME')\n\ndef main(_):\n  if len(sys.argv) < 2 or sys.argv[-1].startswith('-'):\n    print('Usage: mnist_export.py [--training_iteration=x] '\n       '[--model_version=y] export_dir')\n    sys.exit(-1)\n  if FLAGS.training_iteration <= 0:\n    print('Please specify a positive \n                                value for training iteration.')\n    sys.exit(-1)\n  if FLAGS.model_version <= 0:\n    print ('Please specify a positive \n                                    value for version number.')\n    sys.exit(-1)\n\n  print('Training...')\n  mnist = mnist_input_data.read_data_sets(\n                                 FLAGS.work_dir, one_hot=True)\n  sess = tf.InteractiveSession()\n  serialized_tf_example = tf.placeholder(\n                                 tf.string, name='tf_example')\n  feature_configs = {'x': tf.FixedLenFeature(shape=[784], \n                                           dtype=tf.float32),}\n  tf_example = tf.parse_example(serialized_tf_example, \n                                               feature_configs)\n\n  x = tf.identity(tf_example['x'], name='x') \n  y_ = tf.placeholder('float', shape=[None, 10])\n\n  W_conv1 = weight_variable([5, 5, 1, 32])\n  b_conv1 = bias_variable([32])\n  x_image = tf.reshape(x, [-1,28,28,1])\n\n  h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n  h_pool1 = max_pool_2x2(h_conv1)\n\n  W_conv2 = weight_variable([5, 5, 32, 64])\n  b_conv2 = bias_variable([64])\n\n  h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n  h_pool2 = max_pool_2x2(h_conv2)\n\n  W_fc1 = weight_variable([7 * 7 * 64, 1024])\n  b_fc1 = bias_variable([1024])\n\n  h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n  h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n\n  keep_prob = tf.placeholder(tf.float32)\n  h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n\n  W_fc2 = weight_variable([1024, 10])\n  b_fc2 = bias_variable([10])\n\n  y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n\n  y = tf.nn.softmax(y_conv, name='y')\n  cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))\n  train_step = tf.train.AdamOptimizer(1e-4)\\\n                                         .minimize(cross_entropy)\n\n  values, indices = tf.nn.top_k(y_conv, 10)\n  prediction_classes = tf.contrib.lookup.index_to_string(\n   tf.to_int64(indices), \n     mapping=tf.constant([str(i) for i in xrange(10)]))\n\n  sess.run(tf.global_variables_initializer())\n\n  for _ in range(FLAGS.training_iteration):\n    batch = mnist.train.next_batch(50)\n\n    train_step.run(feed_dict={x: batch[0], \n                                 y_: batch[1], keep_prob: 0.5})\n    print(_)\n    correct_prediction = tf.equal(tf.argmax(y_conv,1), \n                                        tf.argmax(y_,1))\n\n  accuracy = tf.reduce_mean(tf.cast(correct_prediction, 'float'))\n           y_: mnist.test.labels})\n\n  print('training accuracy %g' % accuracy.eval(feed_dict={\n    x: mnist.test.images, \n       y_: mnist.test.labels, keep_prob: 1.0}))\n\n  print('training is finished!')\n\n  export_path_base = sys.argv[-1]\n  export_path = os.path.join(\n   compat.as_bytes(export_path_base),\n   compat.as_bytes(str(FLAGS.model_version)))\n  print 'Exporting trained model to', export_path\n  builder = saved_model_builder.SavedModelBuilder(export_path)\n\n  classification_inputs = utils.build_tensor_info(\n                                            serialized_tf_example)\n  classification_outputs_classes = utils.build_tensor_info(\n                                            prediction_classes)\n  classification_outputs_scores = utils.build_tensor_info(values)\n\n  classification_signature = signature_def_utils.build_signature_def(\n   inputs={signature_constants.CLASSIFY_INPUTS: \n                          classification_inputs},\n   outputs={\n     signature_constants.CLASSIFY_OUTPUT_CLASSES:\n       classification_outputs_classes,\n     signature_constants.CLASSIFY_OUTPUT_SCORES:\n       classification_outputs_scores\n   },\n   method_name=signature_constants.CLASSIFY_METHOD_NAME)\n\n  tensor_info_x = utils.build_tensor_info(x)\n  tensor_info_y = utils.build_tensor_info(y_conv)\n\n  prediction_signature = signature_def_utils.build_signature_def(\n   inputs={'images': tensor_info_x},\n   outputs={'scores': tensor_info_y},\n   method_name=signature_constants.PREDICT_METHOD_NAME)\n\n  legacy_init_op = tf.group(tf.initialize_all_tables(), \n                                  name='legacy_init_op')\n  builder.add_meta_graph_and_variables(\n   sess, [tag_constants.SERVING],\n   signature_def_map={\n     'predict_images':\n       prediction_signature,\n     signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n       classification_signature,\n   },\n   legacy_init_op=legacy_init_op)\n\n  builder.save()\n\n  print('new model exported!')\n\nif __name__ == '__main__':\n  tf.app.run()\n\n```", "```py\npy_binary(\n\u00a0 \u00a0 name = \"serving_model_ch4\",\n\u00a0 \u00a0 srcs = [\n\u00a0 \u00a0 \u00a0 \u00a0 \"serving_model_ch4.py\",\n\u00a0 \u00a0 ],\n\u00a0 \u00a0 deps = [\n\u00a0 \u00a0 \u00a0 \u00a0 \":mnist_input_data\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"@org_tensorflow//tensorflow:tensorflow_py\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"@org_tensorflow//tensorflow/python/saved_model:builder\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"@org_tensorflow//tensorflow/python/saved_model:constants\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"@org_tensorflow//tensorflow/python/saved_model:loader\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"@org_tensorflow//tensorflow/python/saved_model:\n                                              signature_constants\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"@org_tensorflow//tensorflow/python/saved_model:\n                                              signature_def_utils\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"@org_tensorflow//tensorflow/python/saved_model:\n\u00a0                                             tag_constants\",\n\u00a0 \u00a0 \u00a0 \u00a0 \"@org_tensorflow//tensorflow/python/saved_model:utils\",\n\u00a0 \u00a0 ],\n)\n```", "```py\nbazel build //tensorflow_serving/example:serving_model_ch4\nbazel-bin/tensorflow_serving/example/serving_model_ch4 \n\u00a0       --training_iteration=1000 --model_version=1 /tmp/mnist_model\n\n```", "```py\n--model_version=2\n```", "```py\nbazel build //tensorflow_serving/model_servers:\n\u00a0                                          tensorflow_model_server\nbazel-bin/tensorflow_serving/model_servers/tensorflow_model_server \n\u00a0                 --port=8000 --model_name=mnist \n\u00a0                 --model_base_path=/tmp/mnist_model/ --logtostderr\n```", "```py\nbazel build //tensorflow_serving/example:mnist_client\nbazel-bin/tensorflow_serving/example/mnist_client \n\u00a0                         --num_tests=1000 --server=localhost:8000\n\n```"]