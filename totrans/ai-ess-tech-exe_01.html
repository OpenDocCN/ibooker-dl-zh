<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" class="pagenumrestart" data-pdf-bookmark="Chapter 1. 99% of Executives Are Misled by AI Advice"><div class="chapter" id="ch_intro">
<h1><span class="label">Chapter 1. </span>99% of Executives Are Misled <span class="keep-together">by AI Advice</span></h1>


<p>As an executive, you’re bombarded with articles and advice on
building AI products.</p>
<p>The problem is, a lot of this “advice” comes from other executives
who rarely interact with the practitioners actually working with AI.
This disconnect leads to misunderstandings, misconceptions, and wasted
resources.</p>

<section data-type="sect1" data-pdf-bookmark="A Case Study in Misleading AI Advice"><div class="sect1" id="id36">
<h1>A Case Study in Misleading AI Advice</h1>
<p>An example of this disconnect in action comes from an <a href="https://oreil.ly/7OZOA">interview</a> with
Jake Heller, CEO of Casetext.</p>


<p>During the interview, Jake made a statement about
AI testing that was widely shared:</p>

<blockquote>
<p>One of the things we learned is that after it passes 100 tests, the
odds that it will pass a random distribution of 100k user inputs with
<em>100% accuracy</em> is very high. (emphasis added)</p>
</blockquote>

<p>This claim was then amplified by influential figures like <a href="https://oreil.ly/gdL7o">Jared
Friedman</a> and <a href="https://oreil.ly/j_uwY">Garry Tan</a>
of Y Combinator, reaching countless founders and executives:</p>

<img src="assets/aete_01in01.png" width="1244" height="881"/>

<p>The morning after this advice was shared, I received numerous emails
from founders asking if they should aim for 100% test-pass rates.</p>
<p>If you’re not hands-on with AI, this advice might sound reasonable.
But any practitioner would know it’s deeply flawed.</p>

</div></section>

<section data-type="sect1" data-pdf-bookmark="“Perfect” Is Flawed"><div class="sect1" id="id37">
<h1>“Perfect” Is Flawed</h1>
<p>In AI, a perfect score is a red flag. This happens when a model has
inadvertently been trained on data or prompts that are too similar to
tests. Like a student who was given the answers before an exam, the model will look
good on paper but be unlikely to perform well in the real world.</p>
<p>If you are sure your data is clean but you’re still getting 100%
accuracy, chances are your test is too weak or not measuring what
matters. Tests that always pass don’t help you improve; they’re just
giving you a false sense of security.</p>
<p>Most importantly, when all your models have perfect scores, you lose the
ability to differentiate between them. You won’t be able to identify why
one model is better than another, or strategize about how to make further
improvements.</p>
<p><em>The goal of evaluations isn’t to pat yourself on the back for
a perfect score.</em></p>
<p>It’s to uncover areas for improvement and ensure your AI is truly
solving the problems it’s meant to address. By focusing on real-world
performance and continuous improvement, you’ll be much better positioned
to create AI that delivers genuine value. Evals are a big topic, and
we’ll dive into them more in a future chapter.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Moving Forward"><div class="sect1" id="id38">
<h1>Moving Forward</h1>
<p>When you’re not hands-on with AI, it’s hard to separate hype from
reality. Here are some key takeaways to keep in mind:</p>
<ul>
<li>Be skeptical of advice or metrics that sound too good to be
true.</li>
<li>Focus on real-world performance and continuous <span class="keep-together">improvement</span>.</li>
<li>Seek advice from experienced AI practitioners who can communicate
effectively with executives. (<em>You’ve come to the right
place!</em>)</li>
</ul>
<p>We’ll dive deeper into how to test AI, along with a data review
toolkit in a future chapter. First, we’ll look at the biggest mistake
executives make when investing in AI.</p>

</div></section>

</div></section></div>
</div>
</body></html>