- en: Appendix A. Designing AI-Powered Applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This appendix explores a general approach to designing *AI-powered applications*—software
    applications that incorporate machine learning models to power one or more of
    their core features.
  prefs: []
  type: TYPE_NORMAL
- en: 'In recent years, there has been growing interest in the concept of “AI products”
    and the application of [“product thinking”](https://oreil.ly/NKBgD) to ML- and
    AI-enabled systems. This approach focuses on AI capabilities not just as technical
    components, but as integral features that solve real user problems. [Figure A-1](#appendix_a_figure_1_1748539915146872)
    shows an example of an AI product: the O’Reilly Learning Platform’s generative
    AI assistant, *Answers*. This assistant is designed to help users interact with
    book content and conduct research across the publisher’s book corpus using natural
    language queries.'
  prefs: []
  type: TYPE_NORMAL
- en: 'I define an AI product as a software solution that:'
  prefs: []
  type: TYPE_NORMAL
- en: Delivers value
  prefs: []
  type: TYPE_NORMAL
- en: AI products provide meaningful value to users, stakeholders, or systems, whether
    by automating tasks, enabling new capabilities, improving efficiency, reducing
    costs, enhancing user experience and interactivity, boosting productivity, or
    generating new content.
  prefs: []
  type: TYPE_NORMAL
- en: Incorporates AI technologies
  prefs: []
  type: TYPE_NORMAL
- en: AI products utilize technologies such as machine learning, deep learning, natural
    language processing (NLP), and computer vision to enable or enhance functionality.
  prefs: []
  type: TYPE_NORMAL
- en: Interacts and adapts
  prefs: []
  type: TYPE_NORMAL
- en: AI systems can interpret and respond to inputs (such as data, user interactions,
    or other systems) in a way that is perceived as intelligent, and often they can
    learn from those interactions and adapt and improve over time.
  prefs: []
  type: TYPE_NORMAL
- en: Integrates operationally
  prefs: []
  type: TYPE_NORMAL
- en: AI systems can be integrated into broader systems or processes, whether software
    systems (like mobile or web apps) or real-world processes (e.g., in manufacturing
    or customer service).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/taie_a001.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure A-1\. An example of an AI product
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In general, AI enhances software products, but it is seldom the product itself.
    Next, we’ll turn our attention to the design process for AI products. Note that
    in this context, I use the terms *AI products* and *AI systems* interchangeably.
  prefs: []
  type: TYPE_NORMAL
- en: Backward Thinking for Designing AI Systems
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It’s important to start an AI endeavor with the business goal in mind, because
    only about [10% of AI PoCs](https://oreil.ly/Ha6oK) succeed in production. Often,
    alignment to the business problem—[solving real users’ pain points](https://oreil.ly/MRKCZ)—is
    the reason for this success.
  prefs: []
  type: TYPE_NORMAL
- en: '*Backward thinking* provides a strategic framework for scoping, planning, and
    executing ML projects. [Starting with the end in mind](https://oreil.ly/Si4EX)
    helps maximize the chances of delivering a useful solution while avoiding common
    pitfalls like poorly defined objectives, irrelevant features, and misaligned architectures.'
  prefs: []
  type: TYPE_NORMAL
- en: It does, however, require a clear and accurate vision of the end goal, making
    it less suitable for exploratory research where the exact objectives are uncertain
    or in cases where problem decomposition is particularly complex.
  prefs: []
  type: TYPE_NORMAL
- en: 'Key benefits of a backward-thinking approach include:'
  prefs: []
  type: TYPE_NORMAL
- en: Clear scope up front
  prefs: []
  type: TYPE_NORMAL
- en: Starting with the desired outcome and working backward helps to define project
    requirements, feasibility, and success metrics. This prevents scope creep and
    keeps development focused.
  prefs: []
  type: TYPE_NORMAL
- en: Business-aligned AI products
  prefs: []
  type: TYPE_NORMAL
- en: By tying AI development to concrete goals, backward thinking ensures that the
    end product delivers real value and solves the original business problem.
  prefs: []
  type: TYPE_NORMAL
- en: Minimum viable data
  prefs: []
  type: TYPE_NORMAL
- en: Working backward from the desired output helps clarify which input features
    and datasets are needed.
  prefs: []
  type: TYPE_NORMAL
- en: Narrowed solution space
  prefs: []
  type: TYPE_NORMAL
- en: With a well-defined end goal, developers can research and select among model
    architectures that have been proven to work well for similar problems in the past.
  prefs: []
  type: TYPE_NORMAL
- en: Iterative-incremental development
  prefs: []
  type: TYPE_NORMAL
- en: Backward thinking encourages starting with simple prototypes, rapidly testing
    ideas, and incrementally increasing complexity. This agile approach surfaces issues
    early and allows for faster iterations.
  prefs: []
  type: TYPE_NORMAL
- en: The Machine Learning Canvas
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To apply the backward-thinking approach in practice, teams can use a strategic
    planning tool such as the [Machine Learning Canvas](https://oreil.ly/32fj3) (see
    [Figure A-2](#appendix_a_figure_2_1748539915146912)). This framework helps anticipate
    hidden costs, identify bottlenecks, specify requirements, and create a clear roadmap
    for an ML project.
  prefs: []
  type: TYPE_NORMAL
- en: By aligning stakeholders on the end goal and value proposition from the outset,
    the Machine Learning Canvas helps ensure that the ML solution is designed to address
    user needs, rather than being solely technology-driven.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout the planning process, the canvas keeps the focus on end-user value,
    placing the user and their needs and the overall software architecture requirements
    at the center of all decision making and technology choices. One of its key benefits
    is its structured approach to defining the ML task and prediction requirements.
    In addition, the canvas prompts early identification of data requirements and
    constraints, helping teams assess feasibility and start planning for data collection
    and labeling. Crucially, filling it out helps teams to consider how models will
    be used, monitored, and updated over time. This holistic view encourages a more
    thorough, forward-looking approach to ML project planning and execution.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/taie_a002.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure A-2\. The Machine Learning Canvas, developed by Louis Dorard (source:
    [*https://oreil.ly/32fj3*](https://oreil.ly/32fj3))'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The canvas also serves as a tool for collaboration between different roles,
    such as data scientists, software engineers, and AI product managers. Its visual
    format enables a shared understanding of the project and its requirements, facilitating
    teamwork and communication.
  prefs: []
  type: TYPE_NORMAL
- en: Importantly, the canvas supports rapid iteration, enabling teams to update it
    easily as they gain a better understanding of the problem space or encounter new
    constraints. Finally, it serves as a useful documentation artifact, offering a
    high-level overview that preserves institutional knowledge for current and future
    team members.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s go through the 10 building blocks of the Machine Learning Canvas, starting
    with the Value Proposition section.
  prefs: []
  type: TYPE_NORMAL
- en: Value Proposition
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In accordance with backward thinking, we start with the business question.
    When creating an AI product with a business- and human-centered approach, the
    most important considerations are: Who are our users? What values do they hold?
    What problems are we solving for them?'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Value Proposition section of the Machine Learning Canvas is where these
    questions are addressed. It should emphasize the importance of understanding and
    addressing critical user needs or business objectives, identifying the target
    audience, and articulating the specific value that the system will provide. A
    clear value proposition should define the target audience, address their significant
    need or challenge, articulate the offered value, and highlight what sets the offering
    apart from competitors. Here’s a suggested template for an effective value proposition
    statement:'
  prefs: []
  type: TYPE_NORMAL
- en: '**For** [target customer]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**w****ho** [statement of the need or opportunity].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The** [product name] is a [product category]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**t****hat** [statement of key benefit—compelling reason to buy or use].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unlike** [primary competitive alternative]'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**o****ur AI product** [statement of primary differentiation].'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using this template helps to clearly outline the target audience, the main problems
    the product solves, its competitive edge, and the unique benefits it offers. This
    structured approach enables effective communication of the value proposition to
    potential users.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s an illustrative example to demonstrate how the template can be implemented
    for a hypothetical AI-powered personal finance app, SmartFinance, indicating who
    the target audience is, how it satisfies those users’ needs, and its unique benefits/how
    it distinguishes itself from traditional solutions:'
  prefs: []
  type: TYPE_NORMAL
- en: '**For** individuals seeking to optimize their finances'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**w****ho** need a simple, effective way to track spending, budget, and save
    money.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The** SmartFinance app is an AI-powered personal finance app'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**t****hat** provides personalized budgeting and saving recommendations based
    on your spending habits and financial goals.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unlike** traditional banking apps or manual budgeting methods'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**o****ur AI product** uses advanced AI algorithms to analyze your financial
    data and offers actionable insights to improve your financial health, tailored
    to your unique circumstances.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s worth putting in the time to deeply understand the user or business problem—otherwise,
    you risk jumping to solutions without thoroughly grasping the challenge. To craft
    a compelling value proposition statement, spend some time with the Value Proposition
    Canvas, shown in [Figure A-3](#appendix_a_figure_3_1748539915146937).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/taie_a003.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure A-3\. The Value Proposition Canvas (source: [*https://oreil.ly/4pA9C*](https://oreil.ly/4pA9C))'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The Value Proposition Canvas is designed to help organizations create products
    and services that align with customer needs. It enables teams to better understand
    user pain points and address them effectively by comparing identified needs and
    challenges with the value being offered, ensuring a strong fit between what customers
    want and what is delivered. Developed by Alexander Osterwalder as an extension
    of his [Business Model Canvas](https://oreil.ly/bhN5J), it places a specific focus
    on understanding customers and crafting compelling value propositions. The Value
    Proposition Canvas has two sides: the Customer Profile on the right outlines customer
    jobs, challenges (pains), and benefits (gains), while the Value Map on the left
    illustrates how the proposed products or services create value by generating benefits
    and reducing challenges. The objective is to align the Customer Profile with the
    Value Map, guaranteeing that the value proposition meaningfully addresses key
    customer needs.'
  prefs: []
  type: TYPE_NORMAL
- en: 'After clarifying the target audience, their problems, and that AI is the most
    suitable solution, the next step is to identify the success criteria. Let’s transition
    to the Machine Learning Canvas’s next building block: Monitoring.'
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Monitoring section of the canvas should outline the metrics that are important
    for assessing value creation and determining the impact of the ML system in production.
    Since the model will function as a component within a broader software system,
    taking a holistic perspective on the success of the AI product is essential. This
    calls for a diverse set of metrics, which can be categorized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Business metrics
  prefs: []
  type: TYPE_NORMAL
- en: Assess the business value generated from decisions influenced by the ML model’s
    predictions. Ultimately, value is created through decision making, with predictions
    serving as inputs to improve those decisions. Examples of business metrics include
    conversion rate, revenue growth, and cost reduction. For instance, in financial
    operations involving extensive cloud usage, infrastructure cost is a key efficiency
    metric for technical teams.
  prefs: []
  type: TYPE_NORMAL
- en: AI product health metrics
  prefs: []
  type: TYPE_NORMAL
- en: Vital for managing an AI product’s effectiveness and long-term viability. A
    key focus area is measuring user engagement—for example, frequency and depth of
    interactions with AI features, as well as daily and monthly active users (DAU
    and MAU). Retention metrics, such as churn rate and cohort analysis, are essential
    for gauging user commitment and product stickiness over time. Another important
    metric is net promoter score (NPS), which measures customer loyalty and satisfaction
    by asking users how likely they are to recommend the AI product to others on a
    scale of 0–10.
  prefs: []
  type: TYPE_NORMAL
- en: AI technical metrics
  prefs: []
  type: TYPE_NORMAL
- en: Evaluate the effectiveness of the AI model. Important metrics include model
    degradation, data drift, concept drift, accuracy, and standard performance measures
    like F1 score, precision, and recall.
  prefs: []
  type: TYPE_NORMAL
- en: System technical metrics
  prefs: []
  type: TYPE_NORMAL
- en: Provide insights into the overall behavior of the system. Metrics such as robustness,
    scalability, and throughput are essential for understanding the system’s technical
    health.
  prefs: []
  type: TYPE_NORMAL
- en: Including metrics from all of these categories in the Monitoring section of
    the canvas enables a comprehensive analysis of the AI product’s success, capturing
    business impact, user engagement, and technical performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The remaining parts of the Machine Learning Canvas reflect the two main phases
    of every ML project: the training and prediction phases. Let’s begin with the
    latter.'
  prefs: []
  type: TYPE_NORMAL
- en: The Prediction Phase
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Following the backward thinking strategy, start by planning how the machine
    learning model will be integrated into the larger software system. The Prediction
    section of the Machine Learning Canvas should reflect how the model will be used,
    even before it has been trained. The objective is to prototype and evaluate how
    the AI system will solve the business problem defined earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Prediction Task
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When working on a machine learning task, you need to define the input, output,
    and problem type. Inputs represent real-world objects or features, and outputs
    are the answers to specific questions the model aims to predict. In supervised
    learning, the system learns from example inputs paired with known outputs. The
    output is usually provided after a certain time delay, and predictive models are
    trained to predict it in advance.
  prefs: []
  type: TYPE_NORMAL
- en: When defining a prediction task, consider existing human baselines and alternative
    prediction methods. These can provide valuable insights for data preparation and
    model building. When creating a new model without an existing production method,
    start by establishing a basic benchmark—something intuitive and easy to calculate.
    This “heuristic” benchmark might be based on constants, rules of thumb, or aggregate
    statistics.
  prefs: []
  type: TYPE_NORMAL
- en: Avoid using a simple machine learning model, such as linear regression, as your
    benchmark; instead, opt for a more interpretable and easily explainable approach.
    For example, for anomaly detection, you might decide to use the 99th percentile
    value calculated from the training dataset as a heuristic benchmark. In a recommendation
    system, you could suggest the most popular item in the category of the customer’s
    last purchase.
  prefs: []
  type: TYPE_NORMAL
- en: Decisions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In any prediction-based system, value is ultimately delivered through the decisions
    it informs. AI’s successful alignment with business goals depends on how well
    the ML model integrates into the complete workflow—the model provides predictions
    or probabilities, but the real impact comes from how those predictions are used.
  prefs: []
  type: TYPE_NORMAL
- en: To connect the work in the Prediction Task part of the canvas to actionable
    outcomes, you need to consider how the predictions will influence decisions. How
    will those predictions generate the intended business value? Asking, “What if
    I had perfect predictions?” can make it easier to reflect on this before investing
    a significant amount of time in model building.
  prefs: []
  type: TYPE_NORMAL
- en: '[Table A-1](#appendix_a_table_1_1748539915151631) provides examples that clarify
    the distinction between predictions and decisions. Prediction generally involves
    estimating or forecasting unknown values based on data, while decision making
    involves taking actions informed by those predictions.'
  prefs: []
  type: TYPE_NORMAL
- en: Table A-1\. The distinction between predictions and decisions in machine learning
    contexts
  prefs: []
  type: TYPE_NORMAL
- en: '| Use case | Prediction | Illustrative decision |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Credit scoring | Probability that a customer will default on a loan | If
    the probability of defaulting is greater than 20%, reject the loan application.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Healthcare | Probability that a patient has a particular disease based on
    symptoms and test results | If the probability exceeds a defined threshold, recommend
    a specific treatment plan or further diagnostic testing. |'
  prefs: []
  type: TYPE_TB
- en: '| Retail inventory management | Forecasted demand for a product in the next
    month | If the predicted demand exceeds current inventory levels by 10%, order
    additional stock. |'
  prefs: []
  type: TYPE_TB
- en: '| Automated trading | Forecasted price movement of a stock in the next 10 minutes
    based on market data | If the stock is predicted to rise by more than 2%, buy
    a specified number of shares. |'
  prefs: []
  type: TYPE_TB
- en: Decisions always follow predictions. In this way, prediction results and subsequent
    actions are integrated into the broader workflow. Simply put, you can describe
    how the ML model is embedded into business processes by defining the upstream
    tasks, identifying the ML-driven solution, and specifying the downstream tasks.
    See [Figure A-4](#appendix_a_figure_4_1748539915146963) for a visualization of
    workflow integration.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/taie_a004.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure A-4\. Workflow integration canvas to specify the upstream and downstream
    tasks or processes and the usage of the ML model output (source: idalab.de)'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Making Predictions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Filling out the Decisions part of the canvas helped you determine how predictions
    and decisions should be made. This section specifies the requirements for prediction
    serving. *Serving* refers to the process of deploying a trained machine learning
    model into a production environment, where it can receive input data and generate
    predictions or outputs. The goal of any serving architecture is to meet requirements
    for consistent and efficient outputs (considering performance, availability, and
    operational SLAs, as well as prediction volume), while minimizing unnecessary
    features, complexity, and cost.
  prefs: []
  type: TYPE_NORMAL
- en: The information you provide in this part of the canvas serves as the foundation
    for designing the serving architecture, which is always use case–specific. What
    is the expected frequency and volume of predictions? Are there constraints related
    to data recency or the time required to compute features?
  prefs: []
  type: TYPE_NORMAL
- en: Answering the question of how predictions should be computed will clarify the
    preferred prediction consumption paradigm, such as batch or real-time. Batch model
    serving processes data in batches periodically, while real-time serving generates
    predictions on individual data points as they arrive. For example, batch serving
    might be used for demand forecasting, where a model periodically analyzes historical
    sales data to predict future product demand for inventory planning. Real-time
    model serving might be used in anomaly detection, where IoT sensor data streams
    are monitored continuously to identify issues as they arise. Real-time serving
    is necessary when low-latency responses are needed to trigger actions or immediately
    enhance user experiences.
  prefs: []
  type: TYPE_NORMAL
- en: The appropriate serving architecture—whether batch, real-time, or hybrid—depends
    on latency, throughput, and scalability needs. It may also require optimizing
    the model for efficient inference using techniques such as quantization, pruning,
    or distillation. Compute resources (e.g., CPU/GPU) must be provisioned, and scaling
    strategies may need to be implemented to meet performance demands. Serving mechanisms
    might include exposing models via REST APIs, Kubernetes deployments, or serverless
    functions, depending on the infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s crucial to understand these technical aspects to ensure robust and reliable
    machine learning model deployment and serving in production environments. To that
    end, you should answer questions such as:'
  prefs: []
  type: TYPE_NORMAL
- en: When do we need to generate predictions?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What latency and frequency constraints do we have?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Where will predictions be generated?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does the prediction generation (serving) pipeline look like?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By completing this part of the canvas, you will determine whether you need real-time
    or batch predictions and identify the serving metrics to monitor in production.
    Next, you’ll outline your strategy for deploying the model into production.
  prefs: []
  type: TYPE_NORMAL
- en: Impact Simulation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This part of the canvas focuses on establishing methods and metrics to evaluate
    the system before deployment. The goal is to answer the question, “How well would
    the system perform on these test cases?” It’s important for the simulation to
    be reliable, which means it should be tested on scenarios that are representative
    of real-world use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, during training, the data should accurately reflect the conditions
    the system will face in production. However, you shouldn’t give the system too
    much prior information about what it will be tested on. When selecting a test
    set, it is crucial to ensure that it produces meaningful, interpretable results
    within the AI system’s domain. A common approach is to use the most recent data
    as a test set, to assess how well the system would have performed if it had been
    deployed days, weeks, or months earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the Impact Simulation section of the Machine Learning Canvas, you should
    answer the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: How will we evaluate system performance pre-deployment?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What metrics best reflect value generation?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What should the model audit pipeline look like?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What model governance steps are needed?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What model guards need to be implemented?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It’s essential to evaluate the system’s performance prior to deploying it into
    production. You should use both offline metrics (accuracy, precision, recall,
    F1 score, etc.) and online metrics (conversion rate, latency, availability, etc.)
    for this. These metrics will help you determine how the model performs in real-world
    scenarios and whether it meets the desired business objectives.
  prefs: []
  type: TYPE_NORMAL
- en: The Training Phase
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As mentioned previously, every ML project consists of two main phases: training
    and prediction. We covered the prediction phase in the previous section; now it’s
    time to consider training. This phase includes all the tasks involved in building
    an ML model: data preparation, new data collection, feature engineering, and training
    (and retraining) the model itself. Following the backward thinking process, you
    have finally arrived at the true origin of any ML system—data.'
  prefs: []
  type: TYPE_NORMAL
- en: Data Sources
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: AI systems fundamentally rely on data. Creating an inventory of all possible
    data sources is one of the most critical steps in an ML project, because data
    availability often determines the project’s feasibility and success.
  prefs: []
  type: TYPE_NORMAL
- en: 'Key questions to address about data sources include:'
  prefs: []
  type: TYPE_NORMAL
- en: What internal and external data sources can we leverage?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can we access and collect this data?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What will the data ingestion pipeline look like?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The output of this step should be a list of potential data sources, relevant
    APIs, and access methods. If the required data isn’t currently accessible, this
    may signal the need for a separate data engineering project to enable model development.
    This stage often reveals hidden costs that may make an ML project unfeasible.
  prefs: []
  type: TYPE_NORMAL
- en: The [Data Landscape Canvas](https://oreil.ly/hsXsZ) by Datentreiber is a useful
    tool for conducting a data inventory in your organization. It might also be used
    as part of the workshop for AI product design.
  prefs: []
  type: TYPE_NORMAL
- en: Data Collection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data usually mirrors the world. As the world changes, ML models need to be updated
    to reflect these changes. This is done by collecting and incorporating new data.
    Retraining a model involves both gathering and labeling this new data. In this
    section of the Machine Learning Canvas, you should clarify how data will be continuously
    gathered and labeled.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following questions are essential for ensuring a reliable retraining process:'
  prefs: []
  type: TYPE_NORMAL
- en: How is new data for model rebuilding collected?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the labeling process?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does the data collection pipeline look like?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does the data preprocessing pipeline look like?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Completing this section increases the project’s feasibility and helps you anticipate
    the cost of building the necessary data infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Building Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section of the Machine Learning Canvas, you reflect on architectural
    decisions for the model training subsystem (in addition to the model serving subsystem).
    Here, you should answer the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: How frequently do we need to update models?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How many models do we need in production?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What time and computing constraints do we have for model training?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does the ML model retraining pipeline look like?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The output should be a clear set of requirements for the model-building process.
    It’s important to recognize that the frequency and approach to model training
    depend on several factors. Different strategies can be used depending on the use
    case, data velocity, and business needs:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Ad hoc model building* involves training models on demand to answer specific
    business questions or address unexpected issues. For example, a retailer might
    analyze recent sales data using clustering to identify emerging customer segments
    for a targeted marketing campaign. Ad hoc analysis allows organizations to quickly
    gain insights from data to adapt to changing circumstances. These models are typically
    one-off and not put into regular production.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Scheduled model building* involves updating ML models at regular intervals
    to ensure continued accuracy as new data becomes available, without the need for
    manual intervention. The update frequency depends on the rate of data change and
    business requirements. For example, for an ecommerce demand forecasting model,
    weekly updates might be sufficient for business needs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In *event-driven model building*, models are automatically trained in response
    to triggers such as data volume thresholds or drops in accuracy. For example,
    a fraud detection model might be retrained when the percentage of flagged transactions
    exceeds a specified threshold, indicating model drift. Event-based approaches
    require robust MLOps infrastructure to monitor performance and orchestrate retraining
    workflows.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Outlining the complexity and frequency of model training helps guide the design
    and implementation of the training subsystem and ensures alignment with the operational
    requirements of the ML system.
  prefs: []
  type: TYPE_NORMAL
- en: Features
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The final building block of the ML project is feature engineering. This part
    focuses on creating input representations from raw data sources that will be available
    at prediction time. Key questions to consider include:'
  prefs: []
  type: TYPE_NORMAL
- en: What attributes of the input data are useful for the ML task?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Will we need additional features that are not present in the raw sources?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can we represent the raw data as features?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What strategies can we implement to handle sensitive data such as PII?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How are sensitive attributes (race, color, gender, religion, origin, age, pregnancy,
    family status) protected?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To what extent might features become discriminatory in the AI product?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does the feature engineering pipeline look like?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The output should be a list of potential features to extract from the raw data
    or obtain from elsewhere. You should also consider aspects such as data preprocessing,
    feature creation complexity, feature selection and dimensionality reduction, and
    evaluation routines, because all of these impact the architecture of the feature
    engineering subsystem.
  prefs: []
  type: TYPE_NORMAL
- en: Domain knowledge plays a crucial role in feature engineering for machine learning
    projects, as it guides the selection and transformation of meaningful features.
    Involving subject matter experts in the feature design process increases the likelihood
    of building a reliable and effective AI product.
  prefs: []
  type: TYPE_NORMAL
