# 第5章 超参数优化

训练一个深度模型和训练一个好的深度模型是非常不同的事情。虽然从互联网上复制粘贴一些TensorFlow代码以运行第一个原型是很容易的，但要将该原型转变为高质量模型则更加困难。将原型转变为高质量模型的过程涉及许多步骤。我们将在本章的其余部分探讨其中一个步骤，即超参数优化。

首次近似地说，超参数优化是调整模型中所有不是通过梯度下降学习的参数的过程。这些量被称为“超参数”。考虑一下前一章中的全连接网络。虽然全连接网络的权重可以从数据中学习，但网络的其他设置不能。这些超参数包括隐藏层的数量、每个隐藏层的神经元数量、学习率等。如何系统地找到这些量的良好值？超参数优化方法为我们提供了这个问题的答案。

回想一下我们之前提到过，模型性能是在一个保留的“验证”集上进行跟踪的。超参数优化方法系统地在验证集上尝试多种超参数选择。表现最佳的超参数值集合然后在第二个保留的“测试”集上进行评估，以衡量真实的模型性能。不同的超参数优化方法在它们用来提出新的超参数设置的算法上有所不同。这些算法从显而易见的到相当复杂的不等。在这些章节中，我们只会涵盖一些较简单的方法，因为更复杂的超参数优化技术往往需要大量的计算能力。

作为一个案例研究，我们将调整[第4章](ch04.html#fully_connected_networks)中介绍的Tox21毒性全连接网络，以获得良好的性能。我们强烈鼓励您（一如既往）使用与本书相关的[GitHub存储库](https://github.com/matroid/dlwithtf)中的代码自行运行超参数优化方法。

# 超参数优化不仅适用于深度网络！

值得强调的是，超参数优化不仅适用于深度网络。大多数形式的机器学习算法都有无法通过默认学习方法学习的参数。这些参数也被称为超参数。在本章的后面部分，您将看到随机森林（另一种常见的机器学习方法）的一些超参数示例。

然而值得注意的是，深度网络往往对超参数选择更为敏感，而不同于其他算法。虽然随机森林可能会因为超参数的默认选择而表现稍差，但深度网络可能完全无法学习。因此，掌握超参数优化是一名潜在的深度学习者的关键技能。

# 模型评估和超参数优化

在之前的章节中，我们只是简要地讨论了如何判断一个机器学习模型是否好。任何模型性能的测量都必须评估模型的泛化能力。也就是说，模型能否对它从未见过的数据点进行预测？模型性能的最佳测试是创建一个模型，然后在模型构建之后可用的数据上进行*前瞻性*评估。然而，这种测试方式通常难以定期进行。在设计阶段，一名实践数据科学家可能希望评估许多不同类型的模型或学习算法，以找到最佳的那个。

解决这一困境的方法是将可用数据集的一部分作为验证集“保留”。这个验证集将用于衡量不同模型的性能（具有不同的超参数选择）。最好还要有第二个保留集，即测试集，用于评估超参数选择方法选择的最终模型的性能。

假设您有一百个数据点。一个简单的程序是使用其中80个数据点来训练潜在模型，使用20个保留的数据点来验证模型选择。然后可以通过模型在保留的20个数据点上的“分数”来跟踪所提出模型的“好坏”。通过提出新设计并仅接受那些在保留集上表现更好的模型，可以逐步改进模型。

然而，在实践中，这个过程会导致*过拟合*。从业者很快会了解保留集的特殊性，并调整模型结构以在保留集上人为提高分数。为了应对这一问题，从业者通常将保留集分为两部分：一部分用于超参数验证，另一部分用于最终模型验证。在这种情况下，假设您保留了10个数据点用于验证，另外10个用于最终测试。这将被称为80/10/10数据分割。

# 为什么测试集是必要的？

值得注意的一个重要观点是，超参数优化方法本身就是一种学习算法形式。特别是，它们是一种用于设置不易通过基于微积分的分析处理的不可微量的学习算法。超参数学习算法的“训练集”就是保留的验证集。

总的来说，在训练集上衡量模型性能并没有太多意义。与往常一样，学到的量必须具有泛化性，因此有必要在不同的集合上测试性能。由于训练集用于基于梯度的学习，验证集用于超参数学习，因此测试集是必要的，以评估学到的超参数在新数据上的泛化能力。

# 黑盒学习算法

黑盒学习算法假设它们试图优化的系统没有结构信息。大多数超参数方法都是黑盒的；它们适用于任何类型的深度学习或机器学习算法。

总的来说，黑盒方法不像白盒方法（如梯度下降）那样具有良好的可扩展性，因为它们往往会在高维空间中迷失。由于黑盒方法缺乏来自梯度的方向信息，它们甚至可能在50维空间中迷失（在实践中优化50个超参数是相当具有挑战性的）。

要理解为什么，假设有50个超参数，每个超参数有3个潜在值。那么黑盒算法必须盲目搜索一个大小为<math alttext="3 Superscript 50"><msup><mn>3</mn> <mn>50</mn></msup></math>的空间。这是可以做到的，但通常需要大量的计算能力。

# 度量，度量，度量。

在选择超参数时，您希望选择那些使您设计的模型更准确的超参数。在机器学习中，*度量*是一个函数，用于衡量经过训练模型的预测准确性。超参数优化是为了优化使度量在验证集上最大化（或最小化）的超参数。虽然这一听起来很简单，但准确性的概念实际上可能相当微妙。假设您有一个二元分类器。是更重要的是永远不要将假样本误标为真样本，还是永远不要将真样本误标为假样本？如何选择满足应用需求的模型超参数？

答案是选择正确的指标。在本节中，我们将讨论许多不同的分类和回归问题的指标。我们将评论每个指标强调的特点。没有最佳指标，但对于不同的应用程序，有更合适和不太合适的指标。

# 指标不能替代常识！

指标是非常盲目的。它们只优化一个数量。因此，盲目优化指标可能导致完全不合适的结果。在网络上，媒体网站经常选择优化“用户点击”这一指标。然后，一些有抱负的年轻记者或广告商意识到像“当X发生时，您绝对不会相信发生了什么”这样的标题会导致用户点击的比例更高。于是，点击诱饵诞生了。虽然点击诱饵标题确实会诱使读者点击，但它们也会让读者失去兴趣，并导致他们避免在充斥着点击诱饵的网站上花费时间。优化用户点击导致用户参与度和信任度下降。

这里的教训是普遍的。优化一个指标往往会以另一个数量为代价。确保您希望优化的数量确实是“正确”的数量。机器学习似乎仍然需要人类判断，这是不是很有趣呢？

## 二元分类指标

在介绍二元分类模型的指标之前，我们认为您会发现学习一些辅助量是有用的。当二元分类器对一组数据点进行预测时，您可以将所有这些预测分为四类之一（[表5-1](#ch5-table1)）。

表5-1. 预测类别

| 类别 | 含义 |
| --- | --- |
| 真阳性（TP） | 预测为真，标签为真 |
| 假阳性（FP） | 预测为真，标签为假 |
| 真阴性（TN） | 预测为假，标签为假 |
| 假阴性（FN） | 预测为假，标签为真 |

我们还将介绍[表5-2](#ch5-table2)中显示的符号。

表5-2. 正负

| 类别 | 含义 |
| --- | --- |
| P | 正标签的数量 |
| N | 负标签的数量 |

一般来说，最小化假阳性和假阴性的数量是非常可取的。然而，对于任何给定的数据集，通常由于信号的限制，往往不可能同时最小化假阳性和假阴性。因此，有各种指标提供假阳性和假阴性之间的各种权衡。这些权衡对于应用程序可能非常重要。假设您正在设计乳腺癌的医学诊断。那么，将一个健康患者标记为患有乳腺癌将是一个假阳性。将一个乳腺癌患者标记为没有这种疾病将是一个假阴性。这两种结果都是不可取的，设计正确的平衡是生物伦理学中一个棘手的问题。

我们将展示一些不同的指标，平衡不同比例的假阳性和假阴性（[表5-3](#ch5-table3)）。每个比例都优化了不同的平衡，我们将更详细地探讨其中一些。

表5-3. 二元指标表

| 指标 | 定义 |
| --- | --- |
| 准确率 | (TP + TN)/(P + N) |
| 精确率 | TP/(TP + FP) |
| 召回率 | TP/(TP + FN) = TP/P |
| 特异性 | TN/(FP + TN) = TN/N |
| 假阳性率（FPR） | FP/(FP + TN) = FP/N |
| 假阴性率（FNR） | FN/(TP + FN) = FN/P |

*准确率*是最简单的指标。它简单地计算分类器正确预测的比例。在简单的应用中，准确率应该是从业者首选的指标。在准确率之后，*精确度*和*召回率*是最常测量的指标。精确度简单地衡量了被预测为正类的数据点实际上是正类的比例。召回率则衡量了分类器标记为正类的正类标记数据点的比例。*特异度*衡量了被正确分类的负类标记数据点的比例。假阳率衡量了被错误分类为正类的负类标记数据点的比例。假阴率是被错误标记为负类的正类标记数据点的比例。

这些指标强调分类器性能的不同方面。它们还可以用于构建一些更复杂的二元分类器性能测量。例如，假设您的二元分类器输出类别概率，而不仅仅是原始预测。那么，就会出现选择*截断*的问题。也就是说，在什么正类概率下您将输出标记为实际正类？最常见的答案是0.5，但通过选择更高或更低的截断，通常可以手动调整精确度、召回率、FPR和TPR之间的平衡。这些权衡通常以图形方式表示。

接收器操作特征曲线（ROC）绘制了真正率和假正率之间的权衡，随着截断概率的变化（参见[图5-1](#ch5-roc)）。

![roc_intro3.png](assets/tfdl_0501.png)

###### 图5-1。接收器操作特征曲线（ROC）。

接收器操作特征曲线（ROC-AUC）下的曲线下面积（AUC）是一个常用的指标。ROC-AUC指标很有用，因为它提供了二元分类器在所有截断选择下的全局图像。一个完美的指标将具有ROC-AUC 1.0，因为真正率将始终被最大化。作为比较，一个随机分类器将具有ROC-AUC 0.5。ROC-AUC在不平衡数据集中通常很有用，因为全局视图部分考虑了数据集中的不平衡。

## 多类别分类指标

许多常见的机器学习任务需要模型输出不仅仅是二元分类标签。例如，ImageNet挑战（ILSVRC）要求参赛者构建能够识别提供图像中的一千个潜在对象类别中的哪一个的模型。或者在一个更简单的例子中，也许您想要预测明天的天气，提供的类别是“晴天”、“下雨”和“多云”。如何衡量这种模型的性能？

最简单的方法是使用准确率的直接泛化，它衡量了被分类器正确标记的数据点的比例([表5-4](#ch5-table4))。

表5-4。多类别分类指标

| 指标 | 定义 |
| --- | --- |
| 准确率 | 正确标记的数量/数据点数量 |

我们注意到确实存在诸如精确度、召回率和ROC-AUC等数量的多类别泛化，并鼓励您在感兴趣的情况下查阅这些定义。在实践中，有一个更简单的可视化方法，即*混淆矩阵*，它效果很好。对于一个具有*k*个类别的多类别问题，混淆矩阵是一个*k*×*k*的矩阵。(*i*, *j*)-th单元格表示被标记为类别*i*且真实标签为类别*j*的数据点的数量。[图5-2](#ch5-confmat)展示了一个混淆矩阵。

![confusion_matrix.png](assets/tfdl_0502.png)

###### 图5-2。一个10类分类器的混淆矩阵。

不要低估人眼从简单可视化中捕捉到系统性失败模式的能力！查看混淆矩阵可以快速理解许多更复杂的多类别指标可能忽略的内容。

## 回归指标

您在几章前学习了回归指标。简要回顾一下，皮尔逊*R*²和RMSE（均方根误差）是很好的默认值。

我们之前只简要介绍了* R *²的数学定义，但现在将更深入地探讨它。让<msub><mi>x</mi> <mi>i</mi></msub>代表预测值，<msub><mi>y</mi> <mi>i</mi></msub>代表标签。让<mover accent="true"><mi>x</mi> <mo>¯</mo></mover>和<mover accent="true"><mi>y</mi> <mo>¯</mo></mover>分别代表预测值和标签的平均值。那么皮尔逊*R*（注意没有平方）是

R = ∑（（xi - <mover accent="true"><mi>x</mi> <mo>¯</mo></mover>）（yi - <mover accent="true"><mi>y</mi> <mo>¯</mo></mover>））/（√（∑（xi - <mover accent="true"><mi>x</mi> <mo>¯</mo></mover>）^2）√（∑（yi - <mover accent="true"><mi>y</mi> <mo>¯</mo></mover>）^2））

这个方程可以重写为

R = cov（x，y）/（σ（x）σ（y））

其中cov代表协方差，σ代表标准差。直观地说，皮尔逊*R*度量了预测值和标签从它们的平均值归一化的联合波动。如果预测值和标签不同，这些波动将发生在不同点，并且倾向于抵消，使*R*²变小。如果预测值和标签趋于一致，波动将一起发生，并使*R*²变大。我们注意到*R*²限制在0到1之间的范围。

RMSE度量了预测值和真实值之间的误差的绝对量。它代表均方根误差，大致类似于真实数量和预测数量之间的误差的绝对值。从数学上讲，RMSE定义如下（使用与之前相同的符号）： 

均方根误差（RMSE）= √（∑（xi - yi）^2 / N）

# 超参数优化算法

正如我们在本章前面提到的，超参数优化方法是用于在验证集上找到优化所选指标的超参数值的学习算法。一般来说，这个目标函数是不可微分的，因此任何优化方法必须是一个黑盒。在本节中，我们将向您展示一些简单的黑盒学习算法，用于选择超参数值。我们将使用来自[第4章](ch04.html#fully_connected_networks)的Tox21数据集作为案例研究，以演示这些黑盒优化方法。Tox21数据集足够小，使实验变得容易，但足够复杂，使超参数优化并不是微不足道的。

在启动之前，我们注意到这些黑盒算法都不是完美的。很快你会看到，在实践中，需要大量人为输入来优化超参数。

# 超参数优化不能自动化吗？

机器学习的一个长期梦想是自动选择模型的超参数。诸如“自动统计学家”等项目一直致力于消除超参数选择过程中的一些繁琐工作，并使模型构建更容易为非专家所掌握。然而，在实践中，通常为了增加便利性而付出了性能的巨大代价。

近年来，有大量的工作集中在改进模型调整的算法基础上。高斯过程、进化算法和强化学习都被用来学习模型的超参数和架构，几乎没有人为输入。最近的研究表明，借助大量的计算能力，这些算法可以超越专家在模型调整方面的表现！但是开销很大，需要数十到数百倍的计算能力。

目前，自动模型调整仍然不太实用。本节中涵盖的所有算法都需要大量手动调整。然而，随着硬件质量的提高，我们预计超参数学习将变得越来越自动化。在短期内，我们强烈建议所有从业者掌握超参数调整的复杂性。精通超参数调整是区分专家和新手的技能。

## 建立一个基准线

超参数调整的第一步是找到一个*基准线*。基准线是由一个强大的（通常非深度学习）算法可以实现的性能。一般来说，随机森林是设置基准线的绝佳选择。如[图5-3](#ch5-rf)所示，随机森林是一种集成方法，它在输入数据和输入特征的子集上训练许多决策树模型。这些个体树然后对结果进行投票。

![random_forest_new2.png](assets/tfdl_0503.png)

###### 图5-3。随机森林的示意图。这里v是输入特征向量。

随机森林往往是相当强大的模型。它们对噪声具有容忍性，不担心其输入特征的规模。（虽然对于Tox21我们不必担心这一点，因为我们所有的特征都是二进制的，但一般来说，深度网络对其输入范围非常敏感。为了获得良好的性能，最好对输入范围进行归一化或缩放。我们将在后面的章节中回到这一点。）它们还倾向于具有强大的泛化能力，不需要太多的超参数调整。对于某些数据集，要想用深度网络超越随机森林的性能可能需要相当大的复杂性。

我们如何创建和训练一个随机森林？幸运的是，在Python中，scikit-learn库提供了一个高质量的随机森林实现。有许多关于scikit-learn的教程和介绍，所以我们只会展示构建Tox21随机森林模型所需的训练和预测代码（[示例5-1](#ch5-tox21rf)）。

##### 示例5-1。在Tox21数据集上定义和训练一个随机森林

```py
from sklearn.ensemble import RandomForestClassifier

# Generate tensorflow graph
sklearn_model = RandomForestClassifier(
    class_weight="balanced", n_estimators=50)
print("About to fit model on training set.")
sklearn_model.fit(train_X, train_y)

train_y_pred = sklearn_model.predict(train_X)
valid_y_pred = sklearn_model.predict(valid_X)
test_y_pred = sklearn_model.predict(test_X)

weighted_score = accuracy_score(train_y, train_y_pred, sample_weight=train_w)
print("Weighted train Classification Accuracy: %f" % weighted_score)
weighted_score = accuracy_score(valid_y, valid_y_pred, sample_weight=valid_w)
print("Weighted valid Classification Accuracy: %f" % weighted_score)
weighted_score = accuracy_score(test_y, test_y_pred, sample_weight=test_w)
print("Weighted test Classification Accuracy: %f" % weighted_score)
```

这里的`train_X`，`train_y`等是在上一章中定义的Tox21数据集。回想一下，所有这些量都是NumPy数组。`n_estimators`指的是我们森林中的决策树数量。设置50或100棵树通常会提供良好的性能。Scikit-learn提供了一个简单的面向对象的API，具有`fit(X, y)`和`predict(X)`方法。该模型根据我们的加权准确性指标实现了以下准确性：

```py
Weighted train Classification Accuracy: 0.989845
Weighted valid Classification Accuracy: 0.681413
```

回想一下，来自[第4章](ch04.html#fully_connected_networks)的全连接网络取得了良好的性能：

```py
Train Weighted Classification Accuracy: 0.742045
Valid Weighted Classification Accuracy: 0.648828
```

看起来我们的基线比我们的深度学习模型获得了更高的准确性！是时候卷起袖子开始工作了。

## 研究生下降

尝试好的超参数的最简单方法是手动尝试多种不同的超参数变体，看看哪种有效。这种策略可能会出奇地有效和有教育意义。深度学习从业者需要建立对深度网络结构的直觉。鉴于理论的非常薄弱，经验性工作是学习如何构建深度学习模型的最佳方法。我们强烈建议尝试许多不同的全连接模型变体。要有系统性；在电子表格中记录您的选择和结果，并系统地探索空间。尝试理解各种超参数的影响。哪些使网络训练进行得更快，哪些使其变慢？哪些设置范围完全破坏了学习？（这些很容易找到，不幸的是。）

有一些软件工程技巧可以使这种搜索更容易。创建一个函数，其参数是您希望探索的超参数，并让其打印出准确性。然后尝试新的超参数组合只需要一个函数调用。[示例5-2](#ch5-tox21fcnetfun)展示了这个函数签名在Tox21案例研究中的全连接网络中会是什么样子。

##### 示例5-2。将超参数映射到不同的Tox21全连接网络的函数

```py
def eval_tox21_hyperparams(n_hidden=50, n_layers=1, learning_rate=.001,
                           dropout_prob=0.5, n_epochs=45, batch_size=100,
                           weight_positives=True):
```

让我们逐个讨论这些超参数。`n_hidden`控制网络中每个隐藏层中的神经元数量。`n_layers`控制隐藏层的数量。`learning_rate`控制梯度下降中使用的学习率，`dropout_prob`是训练步骤中不丢弃神经元的概率。`n_epochs`控制通过总数据的次数，`batch_size`控制每个批次中的数据点数量。

`weight_positives`是这里唯一的新超参数。对于不平衡的数据集，通常有助于对两类示例进行加权，使它们具有相等的权重。对于Tox21数据集，DeepChem为我们提供了要使用的权重。我们只需将每个示例的交叉熵项乘以权重以执行此加权（[示例5-3](#ch5-tox21weight)）。

##### 示例5-3。对Tox21加权正样本

```py
entropy = tf.nn.sigmoid_cross_entropy_with_logits(logits=y_logit, labels=y_expand)
# Multiply by weights
if weight_positives:
  w_expand = tf.expand_dims(w, 1)
  entropy = w_expand * entropy
```

为什么选择超参数值的方法被称为研究生下降？直到最近，机器学习一直是一个主要的学术领域。设计新的机器学习算法的经过考验的方法是描述所需的方法给一个新的研究生，并要求他们解决细节。这个过程有点像一种仪式，通常需要学生痛苦地尝试许多设计替代方案。总的来说，这是一个非常有教育意义的经历，因为获得设计美学的唯一方法是建立起一个记忆工作和不工作的设置。

## 网格搜索

在尝试了一些超参数的手动设置之后，这个过程将开始变得非常乏味。有经验的程序员往往会诱惑简单地编写一个`for`循环，迭代所需的超参数选择。这个过程更多或少是网格搜索方法。对于每个超参数，选择一个可能是好的超参数的值列表。编写一个嵌套的`for`循环，尝试所有这些值的组合以找到它们的验证准确性，并跟踪最佳表现者。

然而，这个过程中有一个微妙之处。深度网络对用于初始化网络的随机种子的选择非常敏感。因此，值得重复每个超参数设置的选择多次，并对结果进行平均以减少方差。

如[示例5-4](#ch5-tox21grid)所示，执行此操作的代码很简单。

##### 示例5-4。对Tox21完全连接网络超参数进行网格搜索

```py
scores = {}
n_reps = 3
hidden_sizes = [50]
epochs = [10]
dropouts = [.5, 1.0]
num_layers = [1, 2]

for rep in range(n_reps):
  for n_epochs in epochs:
    for hidden_size in hidden_sizes:
      for dropout in dropouts:
        for n_layers in num_layers:
          score = eval_tox21_hyperparams(n_hidden=hidden_size, n_epochs=n_epochs,
                                         dropout_prob=dropout, n_layers=n_layers)
          if (hidden_size, n_epochs, dropout, n_layers) not in scores:
            scores[(hidden_size, n_epochs, dropout, n_layers)] = []
          scores[(hidden_size, n_epochs, dropout, n_layers)].append(score)
print("All Scores")
print(scores)

avg_scores = {}
for params, param_scores in scores.iteritems():
  avg_scores[params] = np.mean(np.array(param_scores))
print("Scores Averaged over %d repetitions" % n_reps)
```

## 随机超参数搜索

对于有经验的从业者来说，往往会很诱人地重复使用在以前的应用中有效的神奇超参数设置或搜索网格。这些设置可能很有价值，但也可能导致我们走入歧途。每个机器学习问题都略有不同，最佳设置可能位于我们以前未考虑的参数空间的某个区域。因此，尝试超参数的随机设置（其中随机值是从一个合理范围内选择的）通常是值得的。

尝试随机搜索还有一个更深层次的原因。在高维空间中，常规网格可能会错过很多信息，特别是如果网格点之间的间距不大的话。选择网格点的随机选择可以帮助我们避免陷入松散网格的陷阱。[图5-4](#ch5-tox21gridvsrandom)说明了这一事实。

![random_grid.png](assets/tfdl_0504.png)

###### 图5-4。说明为什么随机超参数搜索可能优于网格搜索。

我们如何在软件中实现随机超参数搜索？一个巧妙的软件技巧是预先抽样所需的随机值并将其存储在列表中。然后，随机超参数搜索简单地变成了对这些随机抽样列表进行网格搜索。这里有一个例子。对于学习率，通常很有用的是尝试从.1到.000001等范围内的广泛范围。[示例5-5](#ch5-tox21randsamp)使用NumPy来抽样一些随机学习率。

##### 示例5-5。对学习率进行随机抽样

```py
n_rates = 5
learning_rates = 10**(-np.random.uniform(low=1, high=6, size=n_rates))
```

我们在这里使用了一个数学技巧。请注意，.1 = 10^（-1），.000001 = 10^（-6）。使用`np.random.uniform`在1和6之间对实值进行抽样很容易。我们可以将这些抽样值提升到一个幂以恢复我们的学习率。然后`learning_rates`保存了一个值列表，我们可以将其输入到前一节的网格搜索代码中。

## 读者的挑战

在本章中，我们只涵盖了超参数调整的基础知识，但所涵盖的工具非常强大。作为挑战，尝试调整完全连接的深度网络，以实现高于随机森林的验证性能。这可能需要一些工作，但这个经验是非常值得的。

# 回顾

在本章中，我们介绍了超参数优化的基础知识，即选择模型参数的值，这些值无法在训练数据上自动学习。特别是，我们介绍了随机和网格超参数搜索，并演示了在上一章中介绍的Tox21数据集上优化模型的代码的使用。

在[第6章](ch06.html#convolutional_neural_networks)中，我们将回顾深度架构，并向您介绍卷积神经网络，这是现代深度架构的基本构建块之一。
