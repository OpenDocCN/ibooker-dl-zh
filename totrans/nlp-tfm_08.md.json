["```py\nfrom datasets import get_dataset_config_names\n\ndomains = get_dataset_config_names(\"subjqa\")\ndomains\n```", "```py\n['books', 'electronics', 'grocery', 'movies', 'restaurants', 'tripadvisor']\n```", "```py\nfrom datasets import load_dataset\n\nsubjqa = load_dataset(\"subjqa\", name=\"electronics\")\n```", "```py\nprint(subjqa[\"train\"][\"answers\"][1])\n```", "```py\n{'text': ['Bass is weak as expected', 'Bass is weak as expected, even with EQ\nadjusted up'], 'answer_start': [1302, 1302], 'answer_subj_level': [1, 1],\n'ans_subj_score': [0.5083333253860474, 0.5083333253860474], 'is_ans_subjective':\n[True, True]}\n```", "```py\nimport pandas as pd\n\ndfs = {split: dset.to_pandas() for split, dset in subjqa.flatten().items()}\n\nfor split, df in dfs.items():\n    print(f\"Number of questions in {split}: {df['id'].nunique()}\")\n```", "```py\nNumber of questions in train: 1295\nNumber of questions in test: 358\nNumber of questions in validation: 255\n```", "```py\nqa_cols = [\"title\", \"question\", \"answers.text\",\n           \"answers.answer_start\", \"context\"]\nsample_df = dfs[\"train\"][qa_cols].sample(2, random_state=7)\nsample_df\n```", "```py\nstart_idx = sample_df[\"answers.answer_start\"].iloc[0][0]\nend_idx = start_idx + len(sample_df[\"answers.text\"].iloc[0][0])\nsample_df[\"context\"].iloc[0][start_idx:end_idx]\n```", "```py\n'this keyboard is compact'\n```", "```py\ncounts = {}\nquestion_types = [\"What\", \"How\", \"Is\", \"Does\", \"Do\", \"Was\", \"Where\", \"Why\"]\n\nfor q in question_types:\n    counts[q] = dfs[\"train\"][\"question\"].str.startswith(q).value_counts()[True]\n\npd.Series(counts).sort_values().plot.barh()\nplt.title(\"Frequency of Question Types\")\nplt.show()\n```", "```py\nfor question_type in [\"How\", \"What\", \"Is\"]:\n    for question in (\n        dfs[\"train\"][dfs[\"train\"].question.str.startswith(question_type)]\n        .sample(n=3, random_state=42)['question']):\n        print(question)\n```", "```py\nHow is the camera?\nHow do you like the control?\nHow fast is the charger?\nWhat is direction?\nWhat is the quality of the construction of the bag?\nWhat is your impression of the product?\nIs this how zoom works?\nIs sound clear?\nIs it a wireless keyboard?\n```", "```py\nfrom transformers import AutoTokenizer\n\nmodel_ckpt = \"deepset/minilm-uncased-squad2\"\ntokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n```", "```py\nquestion = \"How much music can this hold?\"\ncontext = \"\"\"An MP3 is about 1 MB/minute, so about 6000 hours depending on \\\nfile size.\"\"\"\ninputs = tokenizer(question, context, return_tensors=\"pt\")\n```", "```py\nprint(tokenizer.decode(inputs[\"input_ids\"][0]))\n```", "```py\n[CLS] how much music can this hold? [SEP] an mp3 is about 1 mb / minute, so\nabout 6000 hours depending on file size. [SEP]\n```", "```py\n[CLS] question tokens [SEP] context tokens [SEP]\n```", "```py\nimport torch\nfrom transformers import AutoModelForQuestionAnswering\n\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_ckpt)\n\nwith torch.no_grad():\n    outputs = model(**inputs)\nprint(outputs)\n```", "```py\nQuestionAnsweringModelOutput(loss=None, start_logits=tensor([[-0.9862, -4.7750,\n         -5.4025, -5.2378, -5.2863, -5.5117, -4.9819, -6.1880,\n         -0.9862,  0.2596, -0.2144, -1.7136,  3.7806,  4.8561, -1.0546, -3.9097,\n         -1.7374, -4.5944, -1.4278,  3.9949,  5.0390, -0.2018, -3.0193, -4.8549,\n         -2.3107, -3.5110, -3.5713, -0.9862]]), end_logits=tensor([[-0.9623,\n         -5.4733, -5.0326, -5.1639, -5.4278, -5.5151, -5.1749, -4.6233,\n         -0.9623, -3.7855, -0.8715, -3.7745, -3.0161, -1.1780,  0.1758, -2.7365,\n          4.8934,  0.3046, -3.1761, -3.2762,  0.8937,  5.6606, -0.3623, -4.9554,\n         -3.2531, -0.0914,  1.6211, -0.9623]]), hidden_states=None,\nattentions=None)\n```", "```py\nstart_logits = outputs.start_logits\nend_logits = outputs.end_logits\n```", "```py\nprint(f\"Input IDs shape: {inputs.input_ids.size()}\")\nprint(f\"Start logits shape: {start_logits.size()}\")\nprint(f\"End logits shape: {end_logits.size()}\")\n```", "```py\nInput IDs shape: torch.Size([1, 28])\nStart logits shape: torch.Size([1, 28])\nEnd logits shape: torch.Size([1, 28])\n```", "```py\nimport torch\n\nstart_idx = torch.argmax(start_logits)\nend_idx = torch.argmax(end_logits) + 1\nanswer_span = inputs[\"input_ids\"][0][start_idx:end_idx]\nanswer = tokenizer.decode(answer_span)\nprint(f\"Question: {question}\")\nprint(f\"Answer: {answer}\")\n```", "```py\nQuestion: How much music can this hold?\nAnswer: 6000 hours\n```", "```py\nfrom transformers import pipeline\n\npipe = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\npipe(question=question, context=context, topk=3)\n```", "```py\n[{'score': 0.26516005396842957,\n  'start': 38,\n  'end': 48,\n  'answer': '6000 hours'},\n {'score': 0.2208300083875656,\n  'start': 16,\n  'end': 48,\n  'answer': '1 MB/minute, so about 6000 hours'},\n {'score': 0.10253632068634033,\n  'start': 16,\n  'end': 27,\n  'answer': '1 MB/minute'}]\n```", "```py\npipe(question=\"Why is there no data?\", context=context,\n     handle_impossible_answer=True)\n```", "```py\n{'score': 0.9068416357040405, 'start': 0, 'end': 0, 'answer': ''}\n```", "```py\nexample = dfs[\"train\"].iloc[0][[\"question\", \"context\"]]\ntokenized_example = tokenizer(example[\"question\"], example[\"context\"],\n                              return_overflowing_tokens=True, max_length=100,\n                              stride=25)\n```", "```py\nfor idx, window in enumerate(tokenized_example[\"input_ids\"]):\n    print(f\"Window #{idx} has {len(window)} tokens\")\n```", "```py\nWindow #0 has 100 tokens\nWindow #1 has 88 tokens\n```", "```py\nfor window in tokenized_example[\"input_ids\"]:\n    print(f\"{tokenizer.decode(window)} \\n\")\n```", "```py\n[CLS] how is the bass? [SEP] i have had koss headphones in the past, pro 4aa and\nqz - 99\\. the koss portapro is portable and has great bass response. the work\ngreat with my android phone and can be \" rolled up \" to be carried in my\nmotorcycle jacket or computer bag without getting crunched. they are very light\nand don't feel heavy or bear down on your ears even after listening to music\nwith them on all day. the sound is [SEP]\n\n[CLS] how is the bass? [SEP] and don't feel heavy or bear down on your ears even\nafter listening to music with them on all day. the sound is night and day better\nthan any ear - bud could be and are almost as good as the pro 4aa. they are \"\nopen air \" headphones so you cannot match the bass to the sealed types, but it\ncomes close. for $ 32, you cannot go wrong. [SEP]\n```", "```py\nurl = \"\"\"https://artifacts.elastic.co/downloads/elasticsearch/\\\nelasticsearch-7.9.2-linux-x86_64.tar.gz\"\"\"\n!wget -nc -q {url}\n!tar -xzf elasticsearch-7.9.2-linux-x86_64.tar.gz\n```", "```py\nimport os\nfrom subprocess import Popen, PIPE, STDOUT\n\n# Run Elasticsearch as a background process\n!chown -R daemon:daemon elasticsearch-7.9.2\nes_server = Popen(args=['elasticsearch-7.9.2/bin/elasticsearch'],\n                  stdout=PIPE, stderr=STDOUT, preexec_fn=lambda: os.setuid(1))\n# Wait until Elasticsearch has started\n!sleep 30\n```", "```py\n!curl -X GET \"localhost:9200/?pretty\"\n```", "```py\n{\n  \"name\" : \"96938eee37cd\",\n  \"cluster_name\" : \"docker-cluster\",\n  \"cluster_uuid\" : \"ABGDdvbbRWmMb9Umz79HbA\",\n  \"version\" : {\n    \"number\" : \"7.9.2\",\n    \"build_flavor\" : \"default\",\n    \"build_type\" : \"docker\",\n    \"build_hash\" : \"d34da0ea4a966c4e49417f2da2f244e3e97b4e6e\",\n    \"build_date\" : \"2020-09-23T00:45:33.626720Z\",\n    \"build_snapshot\" : false,\n    \"lucene_version\" : \"8.6.2\",\n    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n  },\n  \"tagline\" : \"You Know, for Search\"\n}\n```", "```py\nfrom haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n\n# Return the document embedding for later use with dense retriever\ndocument_store = ElasticsearchDocumentStore(return_embedding=True)\n```", "```py\n{\n    \"text\": \"<the-context>\",\n    \"meta\": {\n        \"field_01\": \"<additional-metadata>\",\n        \"field_02\": \"<additional-metadata>\",\n        ...\n    }\n}\n```", "```py\nfor split, df in dfs.items():\n    # Exclude duplicate reviews\n    docs = [{\"text\": row[\"context\"],\n             \"meta\":{\"item_id\": row[\"title\"], \"question_id\": row[\"id\"],\n                     \"split\": split}}\n        for _,row in df.drop_duplicates(subset=\"context\").iterrows()]\n    document_store.write_documents(docs, index=\"document\")\n\nprint(f\"Loaded {document_store.get_document_count()} documents\")\n```", "```py\nLoaded 1615 documents\n```", "```py\nfrom haystack.retriever.sparse import ElasticsearchRetriever\n\nes_retriever = ElasticsearchRetriever(document_store=document_store)\n```", "```py\nitem_id = \"B0074BW614\"\nquery = \"Is it good for reading?\"\nretrieved_docs = es_retriever.retrieve(\n    query=query, top_k=3, filters={\"item_id\":[item_id], \"split\":[\"train\"]})\n```", "```py\nprint(retrieved_docs[0])\n```", "```py\n{'text': 'This is a gift to myself.  I have been a kindle user for 4 years and\nthis is my third one.  I never thought I would want a fire for I mainly use it\nfor book reading.  I decided to try the fire for when I travel I take my laptop,\nmy phone and my iPod classic.  I love my iPod but watching movies on the plane\nwith it can be challenging because it is so small. Laptops battery life is not\nas good as the Kindle.  So the Fire combines for me what I needed all three to\ndo. So far so good.', 'score': 6.243799, 'probability': 0.6857824513476455,\n'question': None, 'meta': {'item_id': 'B0074BW614', 'question_id':\n'868e311275e26dbafe5af70774a300f3', 'split': 'train'}, 'embedding': None, 'id':\n'252e83e25d52df7311d597dc89eef9f6'}\n```", "```py\nfrom haystack.reader.farm import FARMReader\n\nmodel_ckpt = \"deepset/minilm-uncased-squad2\"\nmax_seq_length, doc_stride = 384, 128\nreader = FARMReader(model_name_or_path=model_ckpt, progress_bar=False,\n                    max_seq_len=max_seq_length, doc_stride=doc_stride,\n                    return_no_answer=True)\n```", "```py\nprint(reader.predict_on_texts(question=question, texts=[context], top_k=1))\n```", "```py\n{'query': 'How much music can this hold?', 'no_ans_gap': 12.648084878921509,\n'answers': [{'answer': '6000 hours', 'score': 10.69961929321289, 'probability':\n0.3988136053085327, 'context': 'An MP3 is about 1 MB/minute, so about 6000 hours\ndepending on file size.', 'offset_start': 38, 'offset_end': 48,\n'offset_start_in_doc': 38, 'offset_end_in_doc': 48, 'document_id':\n'e344757014e804eff50faa3ecf1c9c75'}]}\n```", "```py\nfrom haystack.pipeline import ExtractiveQAPipeline\n\npipe = ExtractiveQAPipeline(reader, es_retriever)\n```", "```py\nn_answers = 3\npreds = pipe.run(query=query, top_k_retriever=3, top_k_reader=n_answers,\n                 filters={\"item_id\": [item_id], \"split\":[\"train\"]})\n\nprint(f\"Question: {preds['query']} \\n\")\nfor idx in range(n_answers):\n    print(f\"Answer {idx+1}: {preds['answers'][idx]['answer']}\")\n    print(f\"Review snippet: ...{preds['answers'][idx]['context']}...\")\n    print(\"\\n\\n\")\n```", "```py\nQuestion: Is it good for reading?\n\nAnswer 1: I mainly use it for book reading\nReview snippet: ... is my third one.  I never thought I would want a fire for I\nmainly use it for book reading.  I decided to try the fire for when I travel I\ntake my la...\n\nAnswer 2: the larger screen compared to the Kindle makes for easier reading\nReview snippet: ...ght enough that I can hold it to read, but the larger screen\ncompared to the Kindle makes for easier reading. I love the color, something I\nnever thou...\n\nAnswer 3: it is great for reading books when no light is available\nReview snippet: ...ecoming addicted to hers! Our son LOVES it and it is great\nfor reading books when no light is available. Amazing sound but I suggest good\nheadphones t...\n```", "```py\nclass PipelineNode:\n    def __init__(self):\n        self.outgoing_edges = 1\n\n    def run(self, **kwargs):\n        ...\n        return (outputs, \"outgoing_edge_name\")\n```", "```py\nfrom haystack.pipeline import Pipeline\nfrom haystack.eval import EvalDocuments\n\nclass EvalRetrieverPipeline:\n    def __init__(self, retriever):\n        self.retriever = retriever\n        self.eval_retriever = EvalDocuments()\n        pipe = Pipeline()\n        pipe.add_node(component=self.retriever, name=\"ESRetriever\",\n                      inputs=[\"Query\"])\n        pipe.add_node(component=self.eval_retriever, name=\"EvalRetriever\",\n                      inputs=[\"ESRetriever\"])\n        self.pipeline = pipe\n\npipe = EvalRetrieverPipeline(es_retriever)\n```", "```py\nfrom haystack import Label\n\nlabels = []\nfor i, row in dfs[\"test\"].iterrows():\n    # Metadata used for filtering in the Retriever\n    meta = {\"item_id\": row[\"title\"], \"question_id\": row[\"id\"]}\n    # Populate labels for questions with answers\n    if len(row[\"answers.text\"]):\n        for answer in row[\"answers.text\"]:\n            label = Label(\n                question=row[\"question\"], answer=answer, id=i, origin=row[\"id\"],\n                meta=meta, is_correct_answer=True, is_correct_document=True,\n                no_answer=False)\n            labels.append(label)\n    # Populate labels for questions without answers\n    else:\n        label = Label(\n            question=row[\"question\"], answer=\"\", id=i, origin=row[\"id\"],\n            meta=meta, is_correct_answer=True, is_correct_document=True,\n            no_answer=True)\n        labels.append(label)\n```", "```py\nprint(labels[0])\n```", "```py\n{'id': 'e28f5e62-85e8-41b2-8a34-fbff63b7a466', 'created_at': None, 'updated_at':\nNone, 'question': 'What is the tonal balance of these headphones?', 'answer': 'I\nhave been a headphone fanatic for thirty years', 'is_correct_answer': True,\n'is_correct_document': True, 'origin': 'd0781d13200014aa25860e44da9d5ea7',\n'document_id': None, 'offset_start_in_doc': None, 'no_answer': False,\n'model_id': None, 'meta': {'item_id': 'B00001WRSJ', 'question_id':\n'd0781d13200014aa25860e44da9d5ea7'}}\n```", "```py\ndocument_store.write_labels(labels, index=\"label\")\nprint(f\"\"\"Loaded {document_store.get_label_count(index=\"label\")} \\\nquestion-answer pairs\"\"\")\n```", "```py\nLoaded 358 question-answer pairs\n```", "```py\nlabels_agg = document_store.get_all_labels_aggregated(\n    index=\"label\",\n    open_domain=True,\n    aggregate_by_meta=[\"item_id\"]\n)\nprint(len(labels_agg))\n```", "```py\n330\n```", "```py\nprint(labels_agg[109])\n```", "```py\n{'question': 'How does the fan work?', 'multiple_answers': ['the fan is really\nreally good', \"the fan itself isn't super loud. There is an adjustable dial to\nchange fan speed\"], 'is_correct_answer': True, 'is_correct_document': True,\n'origin': '5a9b7616541f700f103d21f8ad41bc4b', 'multiple_document_ids': [None,\nNone], 'multiple_offset_start_in_docs': [None, None], 'no_answer': False,\n'model_id': None, 'meta': {'item_id': 'B002MU1ZRS'}}\n```", "```py\ndef run_pipeline(pipeline, top_k_retriever=10, top_k_reader=4):\n    for l in labels_agg:\n        _ = pipeline.pipeline.run(\n            query=l.question,\n            top_k_retriever=top_k_retriever,\n            top_k_reader=top_k_reader,\n            top_k_eval_documents=top_k_retriever,\n            labels=l,\n            filters={\"item_id\": [l.meta[\"item_id\"]], \"split\": [\"test\"]})\n```", "```py\nrun_pipeline(pipe, top_k_retriever=3)\nprint(f\"Recall@3: {pipe.eval_retriever.recall:.2f}\")\n```", "```py\nRecall@3: 0.95\n```", "```py\ndef evaluate_retriever(retriever, topk_values = [1,3,5,10,20]):\n    topk_results = {}\n\n    for topk in topk_values:\n        # Create Pipeline\n        p = EvalRetrieverPipeline(retriever)\n        # Loop over each question-answers pair in test set\n        run_pipeline(p, top_k_retriever=topk)\n        # Get metrics\n        topk_results[topk] = {\"recall\": p.eval_retriever.recall}\n\n    return pd.DataFrame.from_dict(topk_results, orient=\"index\")\n\nes_topk_df = evaluate_retriever(es_retriever)\n```", "```py\ndef plot_retriever_eval(dfs, retriever_names):\n    fig, ax = plt.subplots()\n    for df, retriever_name in zip(dfs, retriever_names):\n        df.plot(y=\"recall\", ax=ax, label=retriever_name)\n    plt.xticks(df.index)\n    plt.ylabel(\"Top-k Recall\")\n    plt.xlabel(\"k\")\n    plt.show()\n\nplot_retriever_eval([es_topk_df], [\"BM25\"])\n```", "```py\nfrom haystack.retriever.dense import DensePassageRetriever\n\ndpr_retriever = DensePassageRetriever(document_store=document_store,\n    query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n    passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n    embed_title=False)\n```", "```py\ndocument_store.update_embeddings(retriever=dpr_retriever)\n```", "```py\ndpr_topk_df = evaluate_retriever(dpr_retriever)\nplot_retriever_eval([es_topk_df, dpr_topk_df], [\"BM25\", \"DPR\"])\n```", "```py\nfrom farm.evaluation.squad_evaluation import compute_f1, compute_exact\n\npred = \"about 6000 hours\"\nlabel = \"6000 hours\"\nprint(f\"EM: {compute_exact(label, pred)}\")\nprint(f\"F1: {compute_f1(label, pred)}\")\n```", "```py\nEM: 0\nF1: 0.8\n```", "```py\npred = \"about 6000 dollars\"\nprint(f\"EM: {compute_exact(label, pred)}\")\nprint(f\"F1: {compute_f1(label, pred)}\")\n```", "```py\nEM: 0\nF1: 0.4\n```", "```py\nfrom haystack.eval import EvalAnswers\n\ndef evaluate_reader(reader):\n    score_keys = ['top_1_em', 'top_1_f1']\n    eval_reader = EvalAnswers(skip_incorrect_retrieval=False)\n    pipe = Pipeline()\n    pipe.add_node(component=reader, name=\"QAReader\", inputs=[\"Query\"])\n    pipe.add_node(component=eval_reader, name=\"EvalReader\", inputs=[\"QAReader\"])\n\n    for l in labels_agg:\n        doc = document_store.query(l.question,\n                                   filters={\"question_id\":[l.origin]})\n        _ = pipe.run(query=l.question, documents=doc, labels=l)\n\n    return {k:v for k,v in eval_reader.__dict__.items() if k in score_keys}\n\nreader_eval = {}\nreader_eval[\"Fine-tune on SQuAD\"] = evaluate_reader(reader)\n```", "```py\ndef plot_reader_eval(reader_eval):\n    fig, ax = plt.subplots()\n    df = pd.DataFrame.from_dict(reader_eval)\n    df.plot(kind=\"bar\", ylabel=\"Score\", rot=0, ax=ax)\n    ax.set_xticklabels([\"EM\", \"F1\"])\n    plt.legend(loc='upper left')\n    plt.show()\n\nplot_reader_eval(reader_eval)\n```", "```py\ndef create_paragraphs(df):\n    paragraphs = []\n    id2context = dict(zip(df[\"review_id\"], df[\"context\"]))\n    for review_id, review in id2context.items():\n        qas = []\n        # Filter for all question-answer pairs about a specific context\n        review_df = df.query(f\"review_id == '{review_id}'\")\n        id2question = dict(zip(review_df[\"id\"], review_df[\"question\"]))\n        # Build up the qas array\n        for qid, question in id2question.items():\n            # Filter for a single question ID\n            question_df = df.query(f\"id == '{qid}'\").to_dict(orient=\"list\")\n            ans_start_idxs = question_df[\"answers.answer_start\"][0].tolist()\n            ans_text = question_df[\"answers.text\"][0].tolist()\n            # Fill answerable questions\n            if len(ans_start_idxs):\n                answers = [\n                    {\"text\": text, \"answer_start\": answer_start}\n                    for text, answer_start in zip(ans_text, ans_start_idxs)]\n                is_impossible = False\n            else:\n                answers = []\n                is_impossible = True\n            # Add question-answer pairs to qas\n            qas.append({\"question\": question, \"id\": qid,\n                        \"is_impossible\": is_impossible, \"answers\": answers})\n        # Add context and question-answer pairs to paragraphs\n        paragraphs.append({\"qas\": qas, \"context\": review})\n    return paragraphs\n```", "```py\nproduct = dfs[\"train\"].query(\"title == 'B00001P4ZH'\")\ncreate_paragraphs(product)\n```", "```py\n[{'qas': [{'question': 'How is the bass?',\n    'id': '2543d296da9766d8d17d040ecc781699',\n    'is_impossible': True,\n    'answers': []}],\n  'context': 'I have had Koss headphones ...',\n    'id': 'd476830bf9282e2b9033e2bb44bbb995',\n    'is_impossible': False,\n    'answers': [{'text': 'Bass is weak as expected', 'answer_start': 1302},\n     {'text': 'Bass is weak as expected, even with EQ adjusted up',\n      'answer_start': 1302}]}],\n  'context': 'To anyone who hasn\\'t tried all ...'},\n {'qas': [{'question': 'How is the bass?',\n    'id': '455575557886d6dfeea5aa19577e5de4',\n    'is_impossible': False,\n    'answers': [{'text': 'The only fault in the sound is the bass',\n      'answer_start': 650}]}],\n  'context': \"I have had many sub-$100 headphones ...\"}]\n```", "```py\nimport json\n\ndef convert_to_squad(dfs):\n    for split, df in dfs.items():\n        subjqa_data = {}\n        # Create `paragraphs` for each product ID\n        groups = (df.groupby(\"title\").apply(create_paragraphs)\n            .to_frame(name=\"paragraphs\").reset_index())\n        subjqa_data[\"data\"] = groups.to_dict(orient=\"records\")\n        # Save the result to disk\n        with open(f\"electronics-{split}.json\", \"w+\", encoding=\"utf-8\") as f:\n            json.dump(subjqa_data, f)\n\nconvert_to_squad(dfs)\n```", "```py\ntrain_filename = \"electronics-train.json\"\ndev_filename = \"electronics-validation.json\"\n\nreader.train(data_dir=\".\", use_gpu=True, n_epochs=1, batch_size=16,\n             train_filename=train_filename, dev_filename=dev_filename)\n```", "```py\nreader_eval[\"Fine-tune on SQuAD + SubjQA\"] = evaluate_reader(reader)\nplot_reader_eval(reader_eval)\n```", "```py\nminilm_ckpt = \"microsoft/MiniLM-L12-H384-uncased\"\nminilm_reader = FARMReader(model_name_or_path=minilm_ckpt, progress_bar=False,\n                           max_seq_len=max_seq_length, doc_stride=doc_stride,\n                           return_no_answer=True)\n```", "```py\nminilm_reader.train(data_dir=\".\", use_gpu=True, n_epochs=1, batch_size=16,\n             train_filename=train_filename, dev_filename=dev_filename)\n```", "```py\nreader_eval[\"Fine-tune on SubjQA\"] = evaluate_reader(minilm_reader)\nplot_reader_eval(reader_eval)\n```", "```py\n# Initialize retriever pipeline\npipe = EvalRetrieverPipeline(es_retriever)\n# Add nodes for reader\neval_reader = EvalAnswers()\npipe.pipeline.add_node(component=reader, name=\"QAReader\",\n              inputs=[\"EvalRetriever\"])\npipe.pipeline.add_node(component=eval_reader, name=\"EvalReader\",\n              inputs=[\"QAReader\"])\n# Evaluate!\nrun_pipeline(pipe)\n# Extract metrics from reader\nreader_eval[\"QA Pipeline (top-1)\"] = {\n    k:v for k,v in eval_reader.__dict__.items()\n    if k in [\"top_1_em\", \"top_1_f1\"]}\n```", "```py\nfrom haystack.generator.transformers import RAGenerator\n\ngenerator = RAGenerator(model_name_or_path=\"facebook/rag-token-nq\",\n                        embed_title=False, num_beams=5)\n```", "```py\nfrom haystack.pipeline import GenerativeQAPipeline\n\npipe = GenerativeQAPipeline(generator=generator, retriever=dpr_retriever)\n```", "```py\ndef generate_answers(query, top_k_generator=3):\n    preds = pipe.run(query=query, top_k_generator=top_k_generator,\n                     top_k_retriever=5, filters={\"item_id\":[\"B0074BW614\"]})\n    print(f\"Question: {preds['query']} \\n\")\n    for idx in range(top_k_generator):\n        print(f\"Answer {idx+1}: {preds['answers'][idx]['answer']}\")\n```", "```py\ngenerate_answers(query)\n```", "```py\nQuestion: Is it good for reading?\n\nAnswer 1:  the screen is absolutely beautiful\nAnswer 2:  the Screen is absolutely beautiful\nAnswer 3:  Kindle fire\n```", "```py\ngenerate_answers(\"What is the main drawback?\")\n```", "```py\nQuestion: What is the main drawback?\n\nAnswer 1:  the price\nAnswer 2:  no flash support\nAnswer 3:  the cost\n```"]