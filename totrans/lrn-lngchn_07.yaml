- en: Chapter 7\. Agents II
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Chapter 6](ch06.html#ch06_agent_architecture_1736545671750341) introduced
    the *agent* architecture, the most powerful of the LLM architectures we have seen
    up until now. It is hard to overstate the potential of this combination of chain-of-thought
    prompting, tool use, and looping.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter discusses two extensions to the agent architecture that improve
    performance for some use cases:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Reflection
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: Taking another page out of the repertoire of human thought patterns, this is
    about giving your LLM app the opportunity to analyze its past output and choices,
    together with the ability to remember reflections from past iterations.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: Multi-agent
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Much the same way as a team can accomplish more than a single person, there
    are problems that can be best tackled by teams of LLM agents.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with reflection.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Reflection
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One prompting technique we haven’t covered yet is *reflection* (also known as
    *self-critique*). *Reflection* is the creation of a loop between a creator prompt
    and a reviser prompt. This mirrors the creation process for many human-created
    artifacts, such as this chapter you’re reading now, which is the result of a back
    and forth between the authors, reviewers, and editor until all are happy with
    the final product.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: As with many of the prompting techniques we have seen so far, reflection can
    be combined with other techniques, such as chain-of-thought and tool calling.
    In this section, we’ll look at reflection in isolation.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: A parallel can be drawn to the modes of human thinking known as *System 1* (reactive
    or instinctive) and *System 2* (methodical and reflective), first introduced by
    Daniel Kahneman in the book *Thinking, Fast and Slow* (Farrar, Straus and Giroux,
    2011). When applied correctly, self-critique can help LLM applications get closer
    to something that resembles System 2 behavior ([Figure 7-1](#ch07_figure_1_1736545673018473)).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: '![System 1 and System 2 thinking](assets/lelc_0701.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
- en: Figure 7-1\. System 1 and System 2 thinking
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We’ll implement reflection as a graph with two nodes: `generate` and `reflect`.
    This graph will be tasked with writing three-paragraph essays, with the `generate`
    node writing or revising drafts of the essay, and `reflect` writing a critique
    to inform the next revision. We’ll run the loop a fixed number of times, but a
    variation on this technique would be to have the `reflect` node decide when to
    finish. Let’s see what it looks like:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '*Python*'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '*JavaScript*'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The visual representation of the graph is shown in [Figure 7-2](#ch07_figure_2_1736545673018506).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '![The Reflection architecture](assets/lelc_0702.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
- en: Figure 7-2\. The reflection architecture
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Notice how the `reflect` node tricks the LLM into thinking it is critiquing
    essays written by the user. And in tandem, the `generate` node is made to think
    that the critique comes from the user. This subterfuge is required because dialogue-tuned
    LLMs are trained on pairs of human-AI messages, so a sequence of many messages
    from the same participant would result in poor performance.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 注意`reflect`节点如何欺骗LLM（大型语言模型）认为它正在批评用户撰写的文章。同时，`generate`节点被设计成认为批评来自用户。这种诡计是必要的，因为对话调优的LLM是在人类-人工智能消息对上训练的，因此来自同一参与者的许多消息序列会导致性能下降。
- en: 'One more thing to note: you might, at first glance, expect the end to come
    after a revise step, but in this architecture we have a fixed number of iterations
    of the `generate-reflect` loop; therefore we terminate after `generate` (so that
    the last set of revisions requested are dealt with). A variation on this architecture
    would instead have the `reflect` step make the decision to end the process (once
    it had no more comments).'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 另一件事需要注意：你可能会首先期望在修订步骤之后结束，但在这个架构中，我们有固定次数的`generate-reflect`循环迭代；因此，我们在`generate`之后终止（这样就可以处理最后一组请求的修订）。这种架构的变体将使`reflect`步骤做出结束过程的决策（一旦没有更多评论）。
- en: 'Let’s see what one of the critiques looks like:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一个批评示例看起来像什么：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'And the final output:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 最终输出：
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This simple type of reflection can sometimes improve performance by giving the
    LLM multiple attempts at refining its output and by letting the reflection node
    adopt a different persona while critiquing the output.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这种简单的反思类型有时可以通过让LLM多次尝试改进其输出，并允许反思节点在批评输出时采用不同的角色来提高性能。
- en: There are several possible variations of this architecture. For one, we could
    combine the reflection step with the agent architecture of [Chapter 6](ch06.html#ch06_agent_architecture_1736545671750341),
    adding it as the last node right before sending output to the user. This would
    make the critique appear to come from the user, and give the application a chance
    to improve its final output without direct user intervention. Obviously this approach
    would come at the expense of higher latency.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这种架构有几种可能的变体。例如，我们可以将反思步骤与第6章中讨论的智能体架构结合，将其作为发送输出到用户之前的最后一个节点添加。这将使批评看起来像来自用户，并给应用程序一个机会在不直接干预用户的情况下改进其最终输出。显然，这种方法将以更高的延迟为代价。
- en: In certain use cases, it could be helpful to ground the critique with external
    information. For instance, if you were writing a code-generation agent, you could
    have a step before `reflect` that would run the code through a linter or compiler
    and report any errors as input to `reflect`.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些用例中，使用外部信息来具体化批评可能很有帮助。例如，如果你正在编写一个代码生成代理，你可以在`reflect`之前添加一个步骤，该步骤将代码通过代码检查器或编译器运行，并将任何错误作为`reflect`的输入。
- en: Tip
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Whenever this approach is possible, we strongly recommend giving it a try, as
    it’s likely to increase the quality of the final output.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 当这种方法可行时，我们强烈建议尝试它，因为它很可能会提高最终输出的质量。
- en: Subgraphs in LangGraph
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LangGraph中的子图
- en: 'Before we dive into multi-agent architectures, let’s look at an important technical
    concept in LangGraph that enables it. *Subgraphs* are graphs that are used as
    part of another graph. Here are some use cases for subgraphs:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨多智能体架构之前，让我们看看LangGraph中的一个重要技术概念，它使得多智能体架构成为可能。*子图*是作为另一个图的一部分使用的图。以下是子图的一些用例：
- en: Building multi-agent systems (discussed in the next section).
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建多智能体系统（下一节讨论）。
- en: When you want to reuse a set of nodes in multiple graphs, you can define them
    once in a subgraph and then use them in multiple parent graphs.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你想要在多个图中重用一组节点时，你可以在子图中定义一次，然后在使用时在多个父图中调用它们。
- en: When you want different teams to work on different parts of the graph independently,
    you can define each part as a subgraph, and as long as the subgraph interface
    (the input and output schemas) is respected, the parent graph can be built without
    knowing any details of the subgraph.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你希望不同的团队独立地工作在图的各个部分时，你可以将每个部分定义为子图，只要尊重子图接口（输入和输出模式），父图就可以构建，而不需要了解子图的任何细节。
- en: 'There are two ways to add subgraph nodes to a parent graph:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 向父图中添加子图节点有两种方式：
- en: Add a node that calls the subgraph directly
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 添加一个直接调用子图的节点
- en: This is useful when the parent graph and the subgraph share state keys, and
    you don’t need to transform state on the way in or out.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当父图和子图共享状态键，并且你不需要在输入或输出过程中转换状态时，这很有用。
- en: Add a node with a function that invokes the subgraph
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: This is useful when the parent graph and the subgraph have different state schemas,
    and you need to transform state before or after calling the subgraph.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at each in turn.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: Calling a Subgraph Directly
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The simplest way to create subgraph nodes is to attach a subgraph directly as
    a node. When doing so, it is important that the parent graph and the subgraph
    share state keys, because those shared keys will be used to communicate. (If your
    graph and subgraph do not share any keys, see the next section.)
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-46
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If you pass extra keys to the subgraph node (that is, in addition to the shared
    keys), they will be ignored by the subgraph node. Similarly, if you return extra
    keys from the subgraph, they will be ignored by the parent graph.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see what it looks like in action:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: '*Python*'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '*JavaScript*'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Calling a Subgraph with a Function
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You might want to define a subgraph with a completely different schema. In that
    case, you can create a node with a function that invokes the subgraph. This function
    will need to transform the input (parent) state to the subgraph state before invoking
    the subgraph and transform the results back to the parent state before returning
    the state update from the node.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see what it looks like:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '*Python*'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '*JavaScript*'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now that we know how to use subgraphs, let’s take a look at one of the big
    use cases for them: multi-agent architectures.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: Multi-Agent Architectures
  id: totrans-61
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As LLM agents grow in size, scope, or complexity, several issues can show up
    and impact their performance, such as the following:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: The agent is given too many tools to choose from and makes poor decisions about
    which tool to call next ([Chapter 6](ch06.html#ch06_agent_architecture_1736545671750341)
    discussed some approaches to this problem).
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The context grows too complex for a single agent to keep track of; that is,
    the size of the prompts and the number of things they mention grows beyond the
    capability of the model you’re using.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You want to use a specialized subsystem for a particular area, for instance,
    planning, research, solving math problems, and so on.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To tackle these problems, you might consider breaking your application into
    multiple smaller, independent agents and composing them into a multi-agent system.
    These independent agents can be as simple as a prompt and an LLM call or as complex
    as a ReAct agent (introduced in [Chapter 6](ch06.html#ch06_agent_architecture_1736545671750341)).
    [Figure 7-3](#ch07_figure_3_1736545673018556) illustrates several ways to connect
    agents in a multi-agent system.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '![A diagram of a network  Description automatically generated](assets/lelc_0703.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
- en: Figure 7-3\. Multiple strategies for coordinating multiple agents
  id: totrans-68
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let’s look at [Figure 7-3](#ch07_figure_3_1736545673018556) in more detail:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: Network
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: Each agent can communicate with every other agent. Any agent can decide which
    other agent is to be executed next.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Supervisor
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: Each agent communicates with a single agent, called the *supervisor*. The supervisor
    agent makes decisions on which agent (or agents) should be called next. A special
    case of this architecture implements the supervisor agent as an LLM call with
    tools, as covered in [Chapter 6](ch06.html#ch06_agent_architecture_1736545671750341).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 每个代理与一个称为监督者的单个代理进行通信。监督者代理决定下一个应该调用哪个代理（或代理组）。这种架构的特殊情况将监督者代理实现为一个带有工具的LLM调用，如第6章（ch06.html#ch06_agent_architecture_1736545671750341）所述。
- en: Hierarchical
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 层次结构
- en: You can define a multi-agent system with a supervisor of supervisors. This is
    a generalization of the supervisor architecture and allows for more complex control
    flows.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用具有监督者监督者的多代理系统。这是监督者架构的推广，允许更复杂的控制流。
- en: Custom multi-agent workflow
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义多代理工作流程
- en: Each agent communicates with only a subset of agents. Parts of the flow are
    deterministic, and only select agents can decide which other agents to call next.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 每个代理只与代理子集进行通信。流程的一部分是确定性的，只有选择性的代理可以决定下一个调用哪个代理。
- en: The next section dives deeper into the supervisor architecture, which we think
    has a good balance of capability and ease of use.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 下一节将更深入地探讨监督者架构，我们认为它在功能和易用性之间取得了良好的平衡。
- en: Supervisor Architecture
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监督者架构
- en: In this architecture, we add each agent to the graph as a node and also add
    a supervisor node, which decides which agents should be called next. We use conditional
    edges to route execution to the appropriate agent node based on the supervisor’s
    decision. Refer back to [Chapter 5](ch05.html#ch05_cognitive_architectures_with_langgraph_1736545670030774)
    for an introduction to LangGraph, which goes over the concepts of nodes, edges,
    and more.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个架构中，我们将每个代理作为节点添加到图中，并添加一个监督者节点，该节点决定下一个应该调用哪个代理。我们使用条件边根据监督者的决策将执行路由到适当的代理节点。请参阅[第5章](ch05.html#ch05_cognitive_architectures_with_langgraph_1736545670030774)以了解LangGraph的介绍，其中介绍了节点、边等概念。
- en: 'Let’s first see what the supervisor node looks like:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先看看监督者节点是什么样的：
- en: '*Python*'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE8]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '*JavaScript*'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE9]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Note
  id: totrans-86
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The code in the prompt requires the names of your subagents to be self-explanatory
    and distinct. For instance, if they were simply called `agent_1` and `agent_2`,
    the LLM would have no information to decide which one is appropriate for each
    task. If needed, you could modify the prompt to add a description of each agent,
    which could help the LLM in picking an agent for each query.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 提示中的代码要求您的子代理名称具有自解释性和独特性。例如，如果它们只是简单地称为`agent_1`和`agent_2`，LLM将没有信息来决定哪个适合每个任务。如果需要，您可以修改提示以添加每个代理的描述，这可以帮助LLM为每个查询选择代理。
- en: 'Now let’s see how to integrate this supervisor node into a larger graph that
    includes two other subagents, which we will call researcher and coder. Our overall
    goal with this graph is to handle queries that can be answered either by the researcher
    by itself or the coder by itself, or even both of them in succession. This example
    doesn’t include implementations for either the researcher or coder—the key idea
    is they could be any other LangGraph graph or node:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看如何将这个监督节点整合到一个更大的图中，这个图包括另外两个子代理，我们将它们称为研究员和程序员。我们使用这个图的整体目标是处理可以由研究员单独回答或程序员单独回答，或者甚至两者依次回答的查询。这个例子不包括研究员或程序员的实现——关键思想是它们可以是任何其他LangGraph图或节点：
- en: '*Python*'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*Python*'
- en: '[PRE10]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '*JavaScript*'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '*JavaScript*'
- en: '[PRE11]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'A few things to notice: In this example, both subagents (researcher and coder)
    can see each other’s work, as all progress is recorded in the messages list. This
    isn’t the only way to organize this. Each of the subagents could be more complex.
    For instance, a subagent could be its own graph that maintains internal state
    and only outputs a summary of the work it did.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 有几点需要注意：在这个例子中，两个子代理（研究员和程序员）都可以看到对方的工作，因为所有进度都记录在消息列表中。这不是组织这种结构的唯一方式。每个子代理可能更复杂。例如，一个子代理可能是一个维护内部状态的自己的图，并且只输出它所做工作的摘要。
- en: After each agent executes, we route back to the supervisor node, which decides
    if there is more work to be done and which agent to delegate that to if so. This
    routing isn’t a hard requirement for this architecture; we could have each subagent
    make a decision as to whether its output should be returned directly to the user.
    To do that, we’d replace the hard edge between, say, researcher and supervisor,
    with a conditional edge (which would read some state key updated by researcher).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个代理执行完毕后，我们返回到管理节点，该节点决定是否还有更多工作要做，如果有，则将任务委托给哪个代理。这种路由对于这种架构并不是一个硬性要求；我们可以让每个子代理决定其输出是否应该直接返回给用户。为此，我们需要用条件边替换，比如说，研究员和管理员之间的硬边（该条件边将读取由研究员更新的某些状态键）。
- en: Summary
  id: totrans-95
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'This chapter covered two important extensions to the agent architecture: reflection
    and multi-agent architectures. The chapter also looked at how to work with subgraphs
    in LangGraph, which are a key building block for multi-agent systems.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了对代理架构的两个重要扩展：反思和多代理架构。本章还探讨了如何在LangGraph中处理子图，这些子图是多代理系统的一个关键构建块。
- en: These extensions add more power to the LLM agent architecture, but they shouldn’t
    be the first thing you reach for when creating a new agent. The best place to
    start is usually the straightforward architecture we discussed in [Chapter 6](ch06.html#ch06_agent_architecture_1736545671750341).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这些扩展增强了LLM代理架构的功能，但在创建新代理时，它们不应该是您首先考虑的事情。通常，从我们在[第6章](ch06.html#ch06_agent_architecture_1736545671750341)中讨论的直接架构开始是最好的选择。
- en: '[Chapter 8](ch08.html#ch08_patterns_to_make_the_most_of_llms_1736545674143600)
    returns to the trade-off between reliability and agency, which is the key design
    decision when building LLM apps today. This is especially important when using
    the agent or multi-agent architectures, as their power comes at the expense of
    reliability if left unchecked. After diving deeper into why this trade-off exists,
    [Chapter 8](ch08.html#ch08_patterns_to_make_the_most_of_llms_1736545674143600)
    will cover the most important techniques at your disposal to navigate that decision,
    and ultimately improve your LLM applications and agents.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[第8章](ch08.html#ch08_patterns_to_make_the_most_of_llms_1736545674143600) 回顾了可靠性和自主性之间的权衡，这是今天构建LLM应用时的关键设计决策。当使用代理或多代理架构时，这一点尤为重要，因为如果不加以控制，它们的强大功能是以可靠性为代价的。在深入探讨这种权衡存在的原因之后，[第8章](ch08.html#ch08_patterns_to_make_the_most_of_llms_1736545674143600)
    将介绍您可利用的最重要技术来导航这一决策，并最终改善您的LLM应用和代理。'
