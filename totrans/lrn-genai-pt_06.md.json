["```py\n!pip install pandas\nimport pandas as pd\n\ntrain=pd.read_csv('files/train.csv')               ①\ntrain.set_index('id', inplace=True)                ②\n```", "```py\nimport os, shutil\n\nG='files/glasses/G/'\nNoG='files/glasses/NoG/'\nos.makedirs(G, exist_ok=True)                       ①\nos.makedirs(NoG, exist_ok=True)                     ②\nfolder='files/faces-spring-2020/faces-spring-2020/'\nfor i in range(1,4501):\n    oldpath=f\"{folder}face-{i}.png\"\n    if train.loc[i]['glasses']==0:                  ③\n        newpath=f\"{NoG}face-{i}.png\"\n    elif train.loc[i]['glasses']==1:                ④\n        newpath=f\"{G}face-{i}.png\"\n    shutil.move(oldpath, newpath)\n```", "```py\nimport random\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\nimgs=os.listdir(G)\nrandom.seed(42)\nsamples=random.sample(imgs,16)               ①\nfig=plt.figure(dpi=200, figsize=(8,2))\nfor i in range(16):                          ②\n    ax = plt.subplot(2, 8, i + 1)\n    img=Image.open(f\"{G}{samples[i]}\")\n    plt.imshow(img)\n    plt.xticks([])\n    plt.yticks([])\nplt.subplots_adjust(wspace=-0.01,hspace=-0.01)\nplt.show()\n```", "```py\nclass Critic(nn.Module):\n    def __init__(self, img_channels, features):\n        super().__init__()\n        self.net = nn.Sequential(                              ①\n            nn.Conv2d(img_channels, features, \n                      kernel_size=4, stride=2, padding=1),\n            nn.LeakyReLU(0.2),\n            self.block(features, features * 2, 4, 2, 1),\n            self.block(features * 2, features * 4, 4, 2, 1),\n            self.block(features * 4, features * 8, 4, 2, 1),\n            self.block(features * 8, features * 16, 4, 2, 1),\n            self.block(features * 16, features * 32, 4, 2, 1),\n            nn.Conv2d(features * 32, 1, kernel_size=4,\n                      stride=2, padding=0))                    ②\n    def block(self, in_channels, out_channels, \n              kernel_size, stride, padding):\n        return nn.Sequential(                                  ③\n            nn.Conv2d(in_channels,out_channels,\n                kernel_size,stride,padding,bias=False,),\n            nn.InstanceNorm2d(out_channels, affine=True),\n            nn.LeakyReLU(0.2))\n    def forward(self, x):\n        return self.net(x)\n```", "```py\nclass Generator(nn.Module):\n    def __init__(self, noise_channels, img_channels, features):\n        super(Generator, self).__init__()\n        self.net = nn.Sequential(                             ①\n            self.block(noise_channels, features *64, 4, 1, 0),\n            self.block(features * 64, features * 32, 4, 2, 1),\n            self.block(features * 32, features * 16, 4, 2, 1),\n            self.block(features * 16, features * 8, 4, 2, 1),\n            self.block(features * 8, features * 4, 4, 2, 1),\n            self.block(features * 4, features * 2, 4, 2, 1),\n            nn.ConvTranspose2d(\n                features * 2, img_channels, kernel_size=4,\n                stride=2, padding=1),    \n            nn.Tanh())                                        ②\n    def block(self, in_channels, out_channels, \n              kernel_size, stride, padding):\n        return nn.Sequential(                                 ③\n            nn.ConvTranspose2d(in_channels,out_channels,\n                kernel_size,stride,padding,bias=False,),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),)\n    def forward(self, x):\n        return self.net(x)\n```", "```py\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        nn.init.normal_(m.weight.data, 1.0, 0.02)\n        nn.init.constant_(m.bias.data, 0)   \n```", "```py\nz_dim=100\nimg_channels=3\nfeatures=16\ngen=Generator(z_dim+2,img_channels,features).to(device)\ncritic=Critic(img_channels+2,features).to(device)\nweights_init(gen)\nweights_init(critic)\n```", "```py\nlr = 0.0001\nopt_gen = torch.optim.Adam(gen.parameters(), \n                         lr = lr, betas=(0.0, 0.9))\nopt_critic = torch.optim.Adam(critic.parameters(), \n                         lr = lr, betas=(0.0, 0.9))\n```", "```py\ndef GP(critic, real, fake):\n    B, C, H, W = real.shape    \n    alpha=torch.rand((B,1,1,1)).repeat(1,C,H,W).to(device)    \n    interpolated_images = real*alpha+fake*(1-alpha)         ①\n    critic_scores = critic(interpolated_images)             ②\n    gradient = torch.autograd.grad(    \n        inputs=interpolated_images,\n        outputs=critic_scores,\n        grad_outputs=torch.ones_like(critic_scores),\n        create_graph=True,\n        retain_graph=True)[0]                               ③\n    gradient = gradient.view(gradient.shape[0], -1)\n    gradient_norm = gradient.norm(2, dim=1)\n    gp = torch.mean((gradient_norm - 1) ** 2)               ④\n    return gp\n```", "```py\nimport torchvision.transforms as T\nimport torchvision\n\nbatch_size=16\nimgsz=256\ntransform=T.Compose([\n    T.Resize((imgsz,imgsz)),\n    T.ToTensor(),\n    T.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5])])      \ndata_set=torchvision.datasets.ImageFolder(\n    root=r\"files/glasses\",\n    transform=transform) \n```", "```py\nnewdata=[]    \nfor i,(img,label) in enumerate(data_set):\n    onehot=torch.zeros((2))\n    onehot[label]=1\n    channels=torch.zeros((2,imgsz,imgsz))                   ①\n    if label==0:\n        channels[0,:,:]=1                                   ②\n    else:\n        channels[1,:,:]=1                                   ③\n    img_and_label=torch.cat([img,channels],dim=0)           ④\n    newdata.append((img,label,onehot,img_and_label))\n```", "```py\ndata_loader=torch.utils.data.DataLoader(\n    newdata,batch_size=batch_size,shuffle=True)\n```", "```py\ndef plot_epoch(epoch):\n    noise = torch.randn(32, z_dim, 1, 1)\n    labels = torch.zeros(32, 2, 1, 1)\n    labels[:,0,:,:]=1                                            ①\n    noise_and_labels=torch.cat([noise,labels],dim=1).to(device)\n    fake=gen(noise_and_labels).cpu().detach()                    ②\n    fig=plt.figure(figsize=(20,10),dpi=100)\n    for i in range(32):                                          ③\n        ax = plt.subplot(4, 8, i + 1)\n        img=(fake.cpu().detach()[i]/2+0.5).permute(1,2,0)\n        plt.imshow(img)\n        plt.xticks([])\n        plt.yticks([])\n    plt.subplots_adjust(hspace=-0.6)\n    plt.savefig(f\"files/glasses/G{epoch}.png\")\n    plt.show() \n    noise = torch.randn(32, z_dim, 1, 1)\n    labels = torch.zeros(32, 2, 1, 1)\n    labels[:,1,:,:]=1                                            ④\n    … (code omitted)\n```", "```py\ndef train_batch(onehots,img_and_labels,epoch):\n    real = img_and_labels.to(device)                            ①\n    B = real.shape[0]\n    for _ in range(5):    \n        noise = torch.randn(B, z_dim, 1, 1)\n        onehots=onehots.reshape(B,2,1,1)\n        noise_and_labels=torch.cat([noise,onehots],dim=1).to(device)\n        fake_img = gen(noise_and_labels).to(device)\n        fakelabels=img_and_labels[:,3:,:,:].to(device)\n        fake=torch.cat([fake_img,fakelabels],dim=1).to(device)  ②\n        critic_real = critic(real).reshape(-1)\n        critic_fake = critic(fake).reshape(-1)\n        gp = GP(critic, real, fake)    \n        loss_critic=(-(torch.mean(critic_real) - \n           torch.mean(critic_fake)) + 10 * gp)                  ③\n        critic.zero_grad()\n        loss_critic.backward(retain_graph=True)\n        opt_critic.step()\n    gen_fake = critic(fake).reshape(-1)\n    loss_gen = -torch.mean(gen_fake)                            ④\n    gen.zero_grad()\n    loss_gen.backward()\n    opt_gen.step()\n    return loss_critic, loss_gen\n```", "```py\nfor epoch in range(1,101):\n    closs=0\n    gloss=0\n    for _,_,onehots,img_and_labels in data_loader:              ①\n        loss_critic, loss_gen = train_batch(onehots,\\\n                                img_and_labels,epoch)           ②\n        closs+=loss_critic.detach()/len(data_loader)\n        gloss+=loss_gen.detach()/len(data_loader)\n    print(f\"at epoch {epoch},\\\n    critic loss: {closs}, generator loss {gloss}\")\n    plot_epoch(epoch)\ntorch.save(gen.state_dict(),'files/cgan.pth')                   ③\n```", "```py\ntorch.manual_seed(0)                                            ①\n\ngenerator=Generator(z_dim+2,img_channels,features).to(device)\ngenerator.load_state_dict(torch.load(\"files/cgan.pth\",\n    map_location=device))                                       ②\ngenerator.eval()\n\nnoise_g=torch.randn(32, z_dim, 1, 1)                            ③\nlabels_g=torch.zeros(32, 2, 1, 1)\nlabels_g[:,0,:,:]=1                                             ④\nnoise_and_labels=torch.cat([noise_g,labels_g],dim=1).to(device)\nfake=generator(noise_and_labels)\nplt.figure(figsize=(20,10),dpi=50)\nfor i in range(32):\n    ax = plt.subplot(4, 8, i + 1)\n    img=(fake.cpu().detach()[i]/2+0.5).permute(1,2,0)\n    plt.imshow(img.numpy())\n    plt.xticks([])\n    plt.yticks([])\nplt.subplots_adjust(wspace=-0.08,hspace=-0.01)\nplt.show()\n```", "```py\nz_male_g=noise_g[0]\nz_female_g=noise_g[14]\n```", "```py\nnoise_ng = torch.randn(32, z_dim, 1, 1)\nlabels_ng = torch.zeros(32, 2, 1, 1)\nlabels_ng[:,1,:,:]=1\n```", "```py\nz_male_ng=noise_ng[8]\nz_female_ng=noise_ng[31]\n```", "```py\nweights=[0,0.25,0.5,0.75,1]                                     ①\nplt.figure(figsize=(20,4),dpi=300)\nfor i in range(5):\n    ax = plt.subplot(1, 5, i + 1)\n    # change the value of z\n    label=weights[i]*labels_ng[0]+(1-weights[i])*labels_g[0]    ②\n    noise_and_labels=torch.cat(\n        [z_female_g.reshape(1, z_dim, 1, 1),\n         label.reshape(1, 2, 1, 1)],dim=1).to(device)\n    fake=generator(noise_and_labels).cpu().detach()             ③\n    img=(fake[0]/2+0.5).permute(1,2,0)\n    plt.imshow(img)\n    plt.xticks([])\n    plt.yticks([])\nplt.subplots_adjust(wspace=-0.08,hspace=-0.01)\nplt.show()\n```", "```py\nweights=[0,0.25,0.5,0.75,1]                                 ①\nplt.figure(figsize=(20,4),dpi=50)\nfor i in range(5):\n    ax = plt.subplot(1, 5, i + 1)\n    # change the value of z\n    z=weights[i]*z_female_ng+(1-weights[i])*z_male_ng       ②  \n    noise_and_labels=torch.cat(\n        [z.reshape(1, z_dim, 1, 1),\n         labels_ng[0].reshape(1, 2, 1, 1)],dim=1).to(device)    \n    fake=generator(noise_and_labels).cpu().detach()         ③\n    img=(fake[0]/2+0.5).permute(1,2,0)\n    plt.imshow(img)\n    plt.xticks([])\n    plt.yticks([])\nplt.subplots_adjust(wspace=-0.08,hspace=-0.01)\nplt.show()\n```", "```py\nplt.figure(figsize=(20,5),dpi=50)\nfor i in range(4):                                          ①\n    ax = plt.subplot(1, 4, i + 1)\n    p=i//2    \n    q=i%2    \n    z=z_female_g*p+z_male_g*(1-p)                           ②\n    label=labels_ng[0]*q+labels_g[0]*(1-q)                  ③\n    noise_and_labels=torch.cat(\n        [z.reshape(1, z_dim, 1, 1),\n         label.reshape(1, 2, 1, 1)],dim=1).to(device)       ④\n    fake=generator(noise_and_labels)\n    img=(fake.cpu().detach()[0]/2+0.5).permute(1,2,0)\n    plt.imshow(img.numpy())\n    plt.xticks([])\n    plt.yticks([])\nplt.subplots_adjust(wspace=-0.08,hspace=-0.01)\nplt.show()\n```", "```py\nplt.figure(figsize=(20,20),dpi=50)\nfor i in range(36):\n    ax = plt.subplot(6,6, i + 1)\n    p=i//6\n    q=i%6 \n    z=z_female_ng*p/5+z_male_ng*(1-p/5)\n    label=labels_ng[0]*q/5+labels_g[0]*(1-q/5)\n    noise_and_labels=torch.cat(\n        [z.reshape(1, z_dim, 1, 1),\n         label.reshape(1, 2, 1, 1)],dim=1).to(device)\n    fake=generator(noise_and_labels)\n    img=(fake.cpu().detach()[0]/2+0.5).permute(1,2,0)\n    plt.imshow(img.numpy())\n    plt.xticks([])\n    plt.yticks([])\nplt.subplots_adjust(wspace=-0.08,hspace=-0.01)\nplt.show()\n```"]