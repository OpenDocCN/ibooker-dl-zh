# 前言

# 当今世界的深度学习

你好，欢迎！本书将通过 PyTorch 这个由 Facebook 于 2017 年发布的开源库来介绍深度学习。除非你过去几年一直把头埋在地里，否则你一定会注意到神经网络如今无处不在。它们已经从*计算机科学中人们学习后却不做任何事情的非常酷的部分*，变成了我们每天随身携带的手机中，用来改善我们的图片或听取我们的语音指令。我们的电子邮件软件读取我们的邮件并生成上下文相关的回复，我们的扬声器倾听我们，汽车自动驾驶，计算机终于在围棋上战胜了人类。我们还看到这项技术被用于更邪恶的目的，在威权国家，神经网络支持的哨兵可以从人群中识别出面孔，并决定是否应该逮捕他们。

尽管感觉一切发生得如此迅速，但神经网络和深度学习的概念早已存在很久。证明这样一个网络可以作为一种以近似方式替代*任何*数学函数的方式运行的证据，这是神经网络可以被训练用于许多不同任务的基础，可以追溯到 1989 年，而卷积神经网络在 90 年代后期就被用来识别支票上的数字了。这一切时间里一直在建立坚实的基础，那么为什么感觉在过去的 10 年里发生了爆炸呢？

有很多原因，但其中最主要的原因必须是*图形处理单元*（GPU）性能的激增以及它们日益可负担的价格。最初设计用于游戏的 GPU 需要每秒执行数以百万计的矩阵运算，以便在您的游戏机或 PC 上渲染所有多边形，这些操作是标准 CPU 无法优化的。2009 年的一篇论文，“使用图形处理器进行大规模深度无监督学习”由 Rajat Raina 等人指出，训练神经网络也是基于执行大量矩阵运算，因此这些附加的图形卡可以用于加速训练，同时使更大、*更深*的神经网络架构首次变得可行。其他重要技术，如*Dropout*（我们将在第三章中讨论），也在过去的十年中被引入，作为不仅加速训练而且使训练更*泛化*的方法（这样网络不仅学会识别训练数据，还会遇到我们将在下一章中遇到的*过拟合*问题）。在过去几年里，公司们已经将这种基于 GPU 的方法推向了一个新的水平，谷歌创建了他们所描述的*张量处理单元*（TPUs），这些设备专门用于尽可能快地执行深度学习，并且甚至作为谷歌云生态系统的一部分向普通公众提供。

过去十年来，追踪深度学习的进展的另一种方式是通过 ImageNet 竞赛。ImageNet 是一个包含超过 1400 万张图片的庞大数据库，手动标记为 20000 个类别，对于机器学习目的来说，ImageNet 是一个标记数据的宝库。自 2010 年以来，每年的 ImageNet 大规模视觉识别挑战赛一直试图测试所有参与者对数据库的 1000 个类别子集的处理能力，直到 2012 年，挑战的错误率一直在 25%左右。然而，那一年，一个深度卷积神经网络以 16%的错误率赢得了比赛，远远超过了所有其他参赛者。随着接下来的几年，错误率不断下降，直到 2015 年，ResNet 架构获得了 3.6%的结果，超过了 ImageNet 上的平均人类表现（5%）。我们被超越了。

# 但深度学习究竟是什么，我需要博士学位才能理解吗？

深度学习的定义通常比启发性更令人困惑。一种定义深度学习的方式是说，深度学习是一种利用多个和众多层的非线性变换逐渐从原始输入中提取特征的机器学习技术。这是正确的，但并没有真正帮助，对吧？我更喜欢将其描述为一种通过提供输入和期望输出来解决问题的技术，并让计算机找到解决方案，通常使用神经网络。

深度学习中吓倒很多人的一件事是数学。看看这个领域的任何论文，你将会看到几乎无法理解的大量符号，到处都是希腊字母，你可能会吓得四处奔跑。事实是：在大多数情况下，你不需要成为数学天才来使用深度学习技术。实际上，对于技术的大多数日常基本用途，你根本不需要了解太多，要真正理解正在发生的事情（正如你将在第二章中看到的那样），你只需要稍微努力一下，理解你可能在高中学到的概念。所以不要太害怕数学。到第三章结束时，你将能够用几行代码组建一个图像分类器，与 2015 年最优秀的人才所能提供的相媲美。

# PyTorch

正如我在开头提到的，PyTorch 是 Facebook 提供的一个开源工具，可以在 Python 中编写深度学习代码。它有两个来源。首先，也许并不奇怪，鉴于其名称，它从 Torch 中获得了许多功能和概念，Torch 是一个基于 Lua 的神经网络库，可以追溯到 2002 年。它的另一个主要来源是 Chainer，于 2015 年在日本创建。Chainer 是最早提供了一种急切的差异化方法而不是定义静态图的神经网络库之一，这种方法允许在创建、训练和操作网络时具有更大的灵活性。Torch 的遗产加上 Chainer 的思想使得 PyTorch 在过去几年中变得流行。

该库还配备了一些模块，可帮助处理文本、图像和音频（`torchtext`、`torchvision`和`torchaudio`），以及流行架构的内置变体，如 ResNet（可下载权重以提供对*迁移学习*等技术的帮助，你将在第四章中看到）。

除了 Facebook 之外，PyTorch 在工业界得到了快速的接受，包括 Twitter、Salesforce、Uber 和 NVIDIA 等公司在其深度学习工作中以各种方式使用它。啊，但我感觉到有一个问题要来了……

## 那么 TensorFlow 呢？

是的，让我们来谈谈那只角落里的相当大的、带有 Google 标志的大象。PyTorch 提供了什么，TensorFlow 没有的？为什么你应该学习 PyTorch 呢？

答案是传统的 TensorFlow 与 PyTorch 的工作方式不同，这对于代码和调试有重大影响。在 TensorFlow 中，您使用库来构建神经网络架构的图表示，然后在该图上执行操作，这发生在 TensorFlow 库内部。这种声明式编程方法与 Python 更为命令式的范式有些不符，这意味着 Python TensorFlow 程序可能看起来和感觉有些奇怪和难以理解。另一个问题是静态图声明可能会使在训练和推断时动态修改架构变得更加复杂和充满样板代码，而不像 PyTorch 的方法那样简单。

出于这些原因，PyTorch 在面向研究的社区中变得流行。在过去一年中，提交给国际学习表示会议的论文中提到*PyTorch*的数量增加了 200%，提到*TensorFlow*的论文数量几乎同样增加。PyTorch 绝对会持续存在。

然而，在更近期的 TensorFlow 版本中，一项名为*eager execution*的新功能已被添加到库中，使其能够类似于 PyTorch 工作，并且将是 TensorFlow 2.0 中推广的范式。但由于在谷歌之外的资源帮助您学习这种与 PyTorch 类似的工作方法的资源稀缺，再加上您需要多年的工作经验来理解另一种范式，以便充分利用该库。

但这一切都不应让您对 TensorFlow 产生负面看法；它仍然是一个经过行业验证的库，得到了全球最大公司之一的支持。PyTorch（当然，由全球另一家最大公司支持）是我会说，更简化和专注于深度学习和微分编程的方法。因为它不必继续支持旧的、陈旧的 API，所以在 PyTorch 中教学和变得高效比在 TensorFlow 中更容易。

Keras 在其中的位置如何？有很多好问题！Keras 是一个高级深度学习库，最初支持 Theano 和 TensorFlow，现在也支持某些其他框架，如 Apache MXNet。它提供了一些功能，如训练、验证和测试循环，这些功能在低级框架中留给开发人员自己实现，以及构建神经网络架构的简单方法。它对 TensorFlow 的推广做出了巨大贡献，现在已经成为 TensorFlow 本身的一部分（作为`tf.keras`），同时仍然是一个独立的项目。相比之下，PyTorch 在原始 TensorFlow 和 Keras 之间有些中间地带；我们将不得不编写自己的训练和推断例程，但创建神经网络几乎和 Keras 一样简单（我会说 PyTorch 的创建和重用架构方法对于 Python 开发人员来说比某些 Keras 的魔法更合乎逻辑）。

正如您在本书中所看到的，尽管 PyTorch 在更多面向研究的职位中很常见，但随着 PyTorch 1.0 的出现，它完全适用于生产用例。

# 本书使用的约定

本书使用以下排版约定：

*斜体*

指示新术语、URL、电子邮件地址、文件名和文件扩展名。

`等宽`

用于程序清单，以及在段落中引用程序元素，如变量或函数名称、数据库、数据类型、环境变量、语句和关键字。

**`等宽粗体`**

显示用户应该按照字面输入的命令或其他文本。

*`等宽斜体`*

显示应由用户提供值或由上下文确定值替换的文本。

###### 提示

此元素表示提示或建议。

###### 注意

此元素表示一般说明。

###### 警告

此元素表示警告或注意事项。

# 使用代码示例

可下载补充材料（包括代码示例和练习）请访问[*https://oreil.ly/pytorch-github*](https://oreil.ly/pytorch-github)。

这本书旨在帮助您完成工作。一般来说，如果本书提供示例代码，您可以在程序和文档中使用它。除非您复制了代码的大部分内容，否则无需联系我们以获得许可。例如，编写一个程序使用本书中的几个代码块不需要许可。出售或分发包含 O'Reilly 图书示例的 CD-ROM 需要许可。引用本书并引用示例代码回答问题不需要许可。将本书中大量示例代码整合到产品文档中需要许可。

我们感谢但不要求署名。署名通常包括标题、作者、出版商和 ISBN。例如：“Ian Pointer（O'Reilly）的《深度学习 PyTorch 编程》。2019 年 Ian Pointer 著，978-1-492-04535-9。”

如果您认为您使用的代码示例超出了合理使用范围或上述许可，请随时通过*permissions@oreilly.com*与我们联系。

# O'Reilly 在线学习

###### 注意

近 40 年来，[*O'Reilly Media*](http://oreilly.com)提供技术和商业培训、知识和见解，帮助公司取得成功。

我们独特的专家和创新者网络通过图书、文章、会议和我们的在线学习平台分享他们的知识和专长。O'Reilly 的在线学习平台为您提供按需访问实时培训课程、深入学习路径、交互式编码环境以及来自 O'Reilly 和其他 200 多家出版商的大量文本和视频。有关更多信息，请访问[*http://oreilly.com*](http://oreilly.com)。

# 如何联系我们

请将有关本书的评论和问题发送给出版商：

+   O'Reilly Media, Inc.

+   1005 Gravenstein Highway North

+   Sebastopol, CA 95472

+   800-998-9938（美国或加拿大）

+   707-829-0515（国际或本地）

+   707-829-0104（传真）

我们为这本书创建了一个网页，列出勘误、示例和任何其他信息。您可以访问[*https://oreil.ly/prgrming-pytorch-for-dl*](https://oreil.ly/prgrming-pytorch-for-dl)。

发送电子邮件至*bookquestions@oreilly.com*以评论或提出有关本书的技术问题。

有关我们的图书、课程、会议和新闻的更多信息，请访问我们的网站[*http://www.oreilly.com*](http://www.oreilly.com)。

在 Facebook 上找到我们：[*http://facebook.com/oreilly*](http://facebook.com/oreilly)

在 Twitter 上关注我们：[*http://twitter.com/oreillymedia*](http://twitter.com/oreillymedia)

在 YouTube 上观看我们：[*http://www.youtube.com/oreillymedia*](http://www.youtube.com/oreillymedia)

# 致谢

衷心感谢我的编辑 Melissa Potter，我的家人和 Tammy Edlund 在使这本书成为可能的过程中提供的所有帮助。还要感谢在写作过程中提供宝贵反馈的技术审阅人员，包括 Phil Rhodes、David Mertz、Charles Givre、Dominic Monn、Ankur Patel 和 Sarah Nagy。

请参见 George Cybenko（1989）的“由 Sigmoidal 函数的叠加逼近”。

请注意，PyTorch 从 Chainer 借鉴了一些想法，但没有实际代码。
