# 前言

# 当今世界的深度学习

你好，欢迎！本书将通过PyTorch这个由Facebook于2017年发布的开源库来介绍深度学习。除非你过去几年一直把头埋在地里，否则你一定会注意到神经网络如今无处不在。它们已经从*计算机科学中人们学习后却不做任何事情的非常酷的部分*，变成了我们每天随身携带的手机中，用来改善我们的图片或听取我们的语音指令。我们的电子邮件软件读取我们的邮件并生成上下文相关的回复，我们的扬声器倾听我们，汽车自动驾驶，计算机终于在围棋上战胜了人类。我们还看到这项技术被用于更邪恶的目的，在威权国家，神经网络支持的哨兵可以从人群中识别出面孔，并决定是否应该逮捕他们。

尽管感觉一切发生得如此迅速，但神经网络和深度学习的概念早已存在很久。证明这样一个网络可以作为一种以近似方式替代*任何*数学函数的方式运行的证据，这是神经网络可以被训练用于许多不同任务的基础，可以追溯到1989年，而卷积神经网络在90年代后期就被用来识别支票上的数字了。这一切时间里一直在建立坚实的基础，那么为什么感觉在过去的10年里发生了爆炸呢？

有很多原因，但其中最主要的原因必须是*图形处理单元*（GPU）性能的激增以及它们日益可负担的价格。最初设计用于游戏的GPU需要每秒执行数以百万计的矩阵运算，以便在您的游戏机或PC上渲染所有多边形，这些操作是标准CPU无法优化的。2009年的一篇论文，“使用图形处理器进行大规模深度无监督学习”由Rajat Raina等人指出，训练神经网络也是基于执行大量矩阵运算，因此这些附加的图形卡可以用于加速训练，同时使更大、*更深*的神经网络架构首次变得可行。其他重要技术，如*Dropout*（我们将在[第3章](ch03.html#convolutional-neural-networks)中讨论），也在过去的十年中被引入，作为不仅加速训练而且使训练更*泛化*的方法（这样网络不仅学会识别训练数据，还会遇到我们将在下一章中遇到的*过拟合*问题）。在过去几年里，公司们已经将这种基于GPU的方法推向了一个新的水平，谷歌创建了他们所描述的*张量处理单元*（TPUs），这些设备专门用于尽可能快地执行深度学习，并且甚至作为谷歌云生态系统的一部分向普通公众提供。

过去十年来，追踪深度学习的进展的另一种方式是通过ImageNet竞赛。ImageNet是一个包含超过1400万张图片的庞大数据库，手动标记为20000个类别，对于机器学习目的来说，ImageNet是一个标记数据的宝库。自2010年以来，每年的ImageNet大规模视觉识别挑战赛一直试图测试所有参与者对数据库的1000个类别子集的处理能力，直到2012年，挑战的错误率一直在25%左右。然而，那一年，一个深度卷积神经网络以16%的错误率赢得了比赛，远远超过了所有其他参赛者。随着接下来的几年，错误率不断下降，直到2015年，ResNet架构获得了3.6%的结果，超过了ImageNet上的平均人类表现（5%）。我们被超越了。

# 但深度学习究竟是什么，我需要博士学位才能理解吗？

深度学习的定义通常比启发性更令人困惑。一种定义深度学习的方式是说，深度学习是一种利用多个和众多层的非线性变换逐渐从原始输入中提取特征的机器学习技术。这是正确的，但并没有真正帮助，对吧？我更喜欢将其描述为一种通过提供输入和期望输出来解决问题的技术，并让计算机找到解决方案，通常使用神经网络。

深度学习中吓倒很多人的一件事是数学。看看这个领域的任何论文，你将会看到几乎无法理解的大量符号，到处都是希腊字母，你可能会吓得四处奔跑。事实是：在大多数情况下，你不需要成为数学天才来使用深度学习技术。实际上，对于技术的大多数日常基本用途，你根本不需要了解太多，要真正理解正在发生的事情（正如你将在[第2章](ch02.html#image-classification-with-pytorch)中看到的那样），你只需要稍微努力一下，理解你可能在高中学到的概念。所以不要太害怕数学。到[第3章](ch03.html#convolutional-neural-networks)结束时，你将能够用几行代码组建一个图像分类器，与2015年最优秀的人才所能提供的相媲美。

# PyTorch

正如我在开头提到的，PyTorch是Facebook提供的一个开源工具，可以在Python中编写深度学习代码。它有两个来源。首先，也许并不奇怪，鉴于其名称，它从Torch中获得了许多功能和概念，Torch是一个基于Lua的神经网络库，可以追溯到2002年。它的另一个主要来源是Chainer，于2015年在日本创建。Chainer是最早提供了一种急切的差异化方法而不是定义静态图的神经网络库之一，这种方法允许在创建、训练和操作网络时具有更大的灵活性。Torch的遗产加上Chainer的思想使得PyTorch在过去几年中变得流行。

该库还配备了一些模块，可帮助处理文本、图像和音频（`torchtext`、`torchvision`和`torchaudio`），以及流行架构的内置变体，如ResNet（可下载权重以提供对*迁移学习*等技术的帮助，你将在[第4章](ch04.html#transfer-learning-and-other-tricks)中看到）。

除了Facebook之外，PyTorch在工业界得到了快速的接受，包括Twitter、Salesforce、Uber和NVIDIA等公司在其深度学习工作中以各种方式使用它。啊，但我感觉到有一个问题要来了……

## 那么TensorFlow呢？

是的，让我们来谈谈那只角落里的相当大的、带有Google标志的大象。PyTorch提供了什么，TensorFlow没有的？为什么你应该学习PyTorch呢？

答案是传统的TensorFlow与PyTorch的工作方式不同，这对于代码和调试有重大影响。在TensorFlow中，您使用库来构建神经网络架构的图表示，然后在该图上执行操作，这发生在TensorFlow库内部。这种声明式编程方法与Python更为命令式的范式有些不符，这意味着Python TensorFlow程序可能看起来和感觉有些奇怪和难以理解。另一个问题是静态图声明可能会使在训练和推断时动态修改架构变得更加复杂和充满样板代码，而不像PyTorch的方法那样简单。

出于这些原因，PyTorch在面向研究的社区中变得流行。在过去一年中，提交给国际学习表示会议的论文中提到*PyTorch*的数量增加了200%，提到*TensorFlow*的论文数量几乎同样增加。PyTorch绝对会持续存在。

然而，在更近期的TensorFlow版本中，一项名为*eager execution*的新功能已被添加到库中，使其能够类似于PyTorch工作，并且将是TensorFlow 2.0中推广的范式。但由于在谷歌之外的资源帮助您学习这种与PyTorch类似的工作方法的资源稀缺，再加上您需要多年的工作经验来理解另一种范式，以便充分利用该库。

但这一切都不应让您对TensorFlow产生负面看法；它仍然是一个经过行业验证的库，得到了全球最大公司之一的支持。PyTorch（当然，由全球另一家最大公司支持）是我会说，更简化和专注于深度学习和微分编程的方法。因为它不必继续支持旧的、陈旧的API，所以在PyTorch中教学和变得高效比在TensorFlow中更容易。

Keras在其中的位置如何？有很多好问题！Keras是一个高级深度学习库，最初支持Theano和TensorFlow，现在也支持某些其他框架，如Apache MXNet。它提供了一些功能，如训练、验证和测试循环，这些功能在低级框架中留给开发人员自己实现，以及构建神经网络架构的简单方法。它对TensorFlow的推广做出了巨大贡献，现在已经成为TensorFlow本身的一部分（作为`tf.keras`），同时仍然是一个独立的项目。相比之下，PyTorch在原始TensorFlow和Keras之间有些中间地带；我们将不得不编写自己的训练和推断例程，但创建神经网络几乎和Keras一样简单（我会说PyTorch的创建和重用架构方法对于Python开发人员来说比某些Keras的魔法更合乎逻辑）。

正如您在本书中所看到的，尽管PyTorch在更多面向研究的职位中很常见，但随着PyTorch 1.0的出现，它完全适用于生产用例。

# 本书使用的约定

本书使用以下排版约定：

*斜体*

指示新术语、URL、电子邮件地址、文件名和文件扩展名。

`等宽`

用于程序清单，以及在段落中引用程序元素，如变量或函数名称、数据库、数据类型、环境变量、语句和关键字。

**`等宽粗体`**

显示用户应该按照字面输入的命令或其他文本。

*`等宽斜体`*

显示应由用户提供值或由上下文确定值替换的文本。

###### 提示

此元素表示提示或建议。

###### 注意

此元素表示一般说明。

###### 警告

此元素表示警告或注意事项。

# 使用代码示例

可下载补充材料（包括代码示例和练习）请访问[*https://oreil.ly/pytorch-github*](https://oreil.ly/pytorch-github)。

这本书旨在帮助您完成工作。一般来说，如果本书提供示例代码，您可以在程序和文档中使用它。除非您复制了代码的大部分内容，否则无需联系我们以获得许可。例如，编写一个程序使用本书中的几个代码块不需要许可。出售或分发包含O'Reilly图书示例的CD-ROM需要许可。引用本书并引用示例代码回答问题不需要许可。将本书中大量示例代码整合到产品文档中需要许可。

我们感谢但不要求署名。署名通常包括标题、作者、出版商和ISBN。例如：“Ian Pointer（O'Reilly）的《深度学习PyTorch编程》。2019年Ian Pointer著，978-1-492-04535-9。”

如果您认为您使用的代码示例超出了合理使用范围或上述许可，请随时通过[*permissions@oreilly.com*](mailto:permissions@oreilly.com)与我们联系。

# O'Reilly在线学习

###### 注意

近40年来，[*O'Reilly Media*](http://oreilly.com)提供技术和商业培训、知识和见解，帮助公司取得成功。

我们独特的专家和创新者网络通过图书、文章、会议和我们的在线学习平台分享他们的知识和专长。O'Reilly的在线学习平台为您提供按需访问实时培训课程、深入学习路径、交互式编码环境以及来自O'Reilly和其他200多家出版商的大量文本和视频。有关更多信息，请访问[*http://oreilly.com*](http://oreilly.com)。

# 如何联系我们

请将有关本书的评论和问题发送给出版商：

+   O'Reilly Media, Inc.

+   1005 Gravenstein Highway North

+   Sebastopol, CA 95472

+   800-998-9938（美国或加拿大）

+   707-829-0515（国际或本地）

+   707-829-0104（传真）

我们为这本书创建了一个网页，列出勘误、示例和任何其他信息。您可以访问[*https://oreil.ly/prgrming-pytorch-for-dl*](https://oreil.ly/prgrming-pytorch-for-dl)。

发送电子邮件至[*bookquestions@oreilly.com*](mailto:bookquestions@oreilly.com)以评论或提出有关本书的技术问题。

有关我们的图书、课程、会议和新闻的更多信息，请访问我们的网站[*http://www.oreilly.com*](http://www.oreilly.com)。

在Facebook上找到我们：[*http://facebook.com/oreilly*](http://facebook.com/oreilly)

在Twitter上关注我们：[*http://twitter.com/oreillymedia*](http://twitter.com/oreillymedia)

在YouTube上观看我们：[*http://www.youtube.com/oreillymedia*](http://www.youtube.com/oreillymedia)

# 致谢

衷心感谢我的编辑Melissa Potter，我的家人和Tammy Edlund在使这本书成为可能的过程中提供的所有帮助。还要感谢在写作过程中提供宝贵反馈的技术审阅人员，包括Phil Rhodes、David Mertz、Charles Givre、Dominic Monn、Ankur Patel和Sarah Nagy。

请参见George Cybenko（1989）的“由Sigmoidal函数的叠加逼近”。

请注意，PyTorch从Chainer借鉴了一些想法，但没有实际代码。
