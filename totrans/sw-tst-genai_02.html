<html><head></head><body>
<div class="calibre1" id="sbo-rt-content"><h1 class="tochead" id="heading_id_2">2 <a id="idTextAnchor000"/>Large language models and prompt engineering</h1>
<p class="co-summary-head">This chapter covers<a id="idIndexMarker000"/><a id="marker-15"/></p>
<ul class="calibre5">
<li class="co-summary-bullet">The fundamentals of how large language models work</li>
<li class="co-summary-bullet">The risks of using large language models</li>
<li class="co-summary-bullet">A definition of prompt engineering</li>
<li class="co-summary-bullet">Experimenting with prompt engineering to return various outputs</li>
<li class="co-summary-bullet">How to solve problems using prompt engineering</li>
</ul>
<p class="body">In the previous chapter, we learned that it’s important to take time and familiarize ourselves with new tools, and it’s the very same mindset we’ll be adopting in this chapter. Throughout this book, we’ll be exploring how to use generative AI tools such as Open AI’s ChatGPT and GitHub Copilot, which are built on large language models, or LLMs. There are many ways in which AI can be employed in testing, but what makes LLMs so interesting is their adaptability to different situations—hence, their rise in popularity. So, before we look at how we can incorporate LLM tools into our everyday testing, let’s first learn a bit about what LLMs are, how they work, and how to get the most out of them by learning about the concept of prompt engineering.<a id="idIndexMarker001"/></p>
<p class="body">What has made LLMs such as ChatGPT dominate tech headlines throughout 2023? Consider this sample interaction with ChatGPT that I had:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Hello ChatGPT, can you introduce yourself briefly?</p>
</td>
</tr>
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Of course! I’m ChatGPT, an AI language model developed by OpenAI. I’m based on the GPT-3.5 architecture, which means I’m designed to understand and generate human-like text based on the prompts I receive. I’ve been trained on a diverse range of data sources, including books, articles, websites, and other text documents, up until September 2021. I can assist you with a wide array of topics, including answering questions, providing explanations, creative writing, and much more. Just let me know how I can help you!</p>
</td>
</tr>
</tbody>
</table>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Nice to meet you.</p>
</td>
</tr>
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Nice to meet you too! I’m here to assist you with any questions or tasks you have. How may I help you today?</p>
</td>
</tr>
</tbody>
</table>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">I’m just getting to know you.</p>
</td>
</tr>
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">That’s perfectly fine! Feel free to ask me anything you’d like to know, whether it’s about my capabilities, how I work, or anything else you’re curious about. I’m here to provide information and help you out to the best of my abilities. Fire away with your questions!</p>
</td>
</tr>
</tbody>
</table>
<p class="body"><a id="marker-16"/>Based on this quick conversation, we can see that</p>
<ul class="calibre5">
<li class="fm-list-bullet">
<p class="list">It is possible to interact with ChatGPT using natural language. No traditional programming experience was required to get results from ChatGPT in this example.</p>
</li>
<li class="fm-list-bullet">
<p class="list">The output from ChatGPT is also in natural language. It’s easy to understand and react to.</p>
</li>
</ul>
<p class="body">Advocates of LLMs are celebrating that these types of AI tools have democratized the use of AI, allowing anyone to use it to get results. However, this democratization is a double-edged sword. The nature in which we interact with LLMs can give us the illusion that we’re talking with a machine that reasons in the same way we humans do. But making that assumption can affect our ability to get the most out of an LLM. So, to get the best results out of tools such as ChatGPT, we should know how they work (at least in general terms) to better understand how they can fit into our testing activities and how to extract the most value from them.</p>
<h2 class="fm-head" id="heading_id_3">2.1 LLMs explained</h2>
<p class="body">How does a person with relatively little experience in building AI systems explain how a complex LLM system works? Fortunately, in the Computerphile video “AI Language Models &amp; Transformers” (<a class="url" href="https://www.youtube.com/watch?v=rURRYI66E54">www.youtube.com/watch?v=rURRYI66E54</a>), Rob Miles offers an example that can help us gain a fundamental grasp on what LLMs do. (I strongly recommend watching all his videos on AI.)<a id="idIndexMarker002"/></p>
<p class="body">Take out your phone and open a messaging app, or any other app that makes your keyboard appear. Above the keyboard, you’ll likely see a range of suggested words to insert into your message. For example, my keyboard offers the following suggestions: <i class="fm-italics">I,</i> <i class="fm-italics">I am,</i> and <i class="fm-italics">The.</i> Selecting one of these options, such as <i class="fm-italics">I am,</i> causes the suggestions to update. For me, it offered the options <i class="fm-italics">away,</i> <i class="fm-italics">away for,</i> and <i class="fm-italics">now.</i> Selecting the option <i class="fm-italics">away</i> <i class="fm-italics">for</i> once again updates the available options. So, how does the keyboard know which options to show?</p>
<p class="body">In your keyboard, there is an AI model that behaves in a manner resembling LLMs. This description is an oversimplification, but at its core, the keyboard on your phone is applying the same machine learning approach as an LLM by using probability. Language is a complex and fluid set of rules, meaning any attempt to codify relationships explicitly is almost impossible. So instead, a model is trained on massive data sets to implicitly learn the relationships in language and create a probability distribution that is used to predict what the next word might be. This can best be described by visualizing the options available from the keyboard example, as shown in figure 2.1</p>
<div class="figure">
<p class="figure1"><img alt="" class="calibre10" src="../../OEBPS/Images/CH02_F01_Winteringham2.png"/></p>
<p class="figurecaption">Figure 2.1 Probability distribution in action</p>
</div>
<p class="body">As we can see, when we select the term <i class="fm-italics">I am,</i> the model in our keyboard has been trained to assign probabilities to a vast range of words. Some of these will have a high probability of coming after <i class="fm-italics">I am</i>, such as <i class="fm-italics">away</i>, and some will have a low probability, such as <i class="fm-italics">sandalwood</i>. As mentioned before, these probabilities come from a model that has completed a training process, known as unsupervised learning, in which vast amounts of data have been sent to an algorithm for processing. It’s from that training process that a model is created with complex weights and balances that provide the model with its predictive abilities.<a id="marker-17"/><a id="idIndexMarker003"/></p>
<div class="fm-sidebar-block">
<p class="fm-sidebar-title">Supervised learning and unsupervised learning</p>
<p class="fm-sidebar-text">When training AI, two of the more dominant techniques to use are supervised and unsupervised learning. Which learning approach is used will determine how data has been structured and sent to an algorithm. <i class="fm-italics">Supervised</i> learning uses data that has been organized, labeled, and paired with an output. For example, a medical data set might contain labeled data that includes BMI, age, and sex, for example, which is paired with a labeled outcome about whether an individual suffered a specific illness—say, a heart attack or stroke. <i class="fm-italics">Unsupervised</i> learning, conversely, uses data that isn’t labeled, and it has no output data. The idea is that when an algorithm is trained on this type of data, it learns the implicit patterns within the data.<a id="idIndexMarker004"/><a id="idIndexMarker005"/></p>
</div>
<p class="body">Chances are good that if you play around with the predictive function on your keyboard, the output will differ from mine—even if we have the same phone and operating system. This is because once the model has been trained and is utilized in our phones, it’s still being fine-tuned by what we type into our phones. I travel for work, so I must let people know when I am away and when I’m available. (It is perhaps a damning indictment of my work–life balance!) So, words such as <i class="fm-italics">I am</i> and <i class="fm-italics">away</i> have an increased probability as they are words I use more regularly. This is known as Reinforcement Learning with Human Feedback, or RLHF.<a id="idIndexMarker006"/></p>
<p class="body">Again, comparing predictive messaging on a phone to an LLM is an oversimplification, but the comparison holds true. LLMs also use unsupervised learning and RLHF. The difference, however, is that although an AI model on a phone can look at perhaps the last five words typed to predict the next, LLMs use cutting-edge techniques, such as</p>
<ul class="calibre5">
<li class="fm-list-bullet">
<p class="list">Generative pretrained transformers (which is what makes the GPT abbreviation in ChatGPT)<a id="marker-18"/><a id="idIndexMarker007"/></p>
</li>
<li class="fm-list-bullet">
<p class="list">Powerful hardware infrastructure using thousands of servers</p>
</li>
<li class="fm-list-bullet">
<p class="list">Training data on a scale that would dwarf what our humble keyboard model will have been trained on</p>
</li>
</ul>
<p class="body">Do we need to know the intricacies of each of these points? Not really, but it helps us appreciate a key aspect of LLMs. The output of LLMs, no matter how powerful, is probabilistic. LLMs are not a repository of information—there is structured knowledge stored within them like we would see on the wider internet. This means that how it comes to conclusions differs from how we humans do (probability rather than experience), which is what makes them so powerful but also risky to use if we aren’t vigilant about how we use them.<a id="idIndexMarker008"/></p>
<h2 class="fm-head" id="heading_id_4">2.2 Avoiding the risks of using LLMs</h2>
<p class="body">Having an AI predict what word goes after another isn’t an easy task, and although current LLMs have seen an explosion in ability, there are risks we need to be aware of. Let’s take a look at a few of them.<a id="idIndexMarker009"/></p>
<h3 class="fm-head1" id="heading_id_5">2.2.1 Hallucinations</h3>
<p class="body">The challenge with text prediction is to ensure that the output of an LLM makes sense and is rooted in reality. For example, back in chapter 1, when I asked ChatGPT to write an introduction to this book, it shared the following:<a id="idIndexMarker010"/><a id="idIndexMarker011"/><a id="marker-19"/></p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Regarding<a id="idTextAnchor001"/> the book, “How AI can be used to help support various software testing activities,” I would recommend “AI-Driven Testing: Adding Intelligence to Your Software Testing Practice” by Julian Harty and Mahesh Sharma.</p>
</td>
</tr>
</tbody>
</table>
<p class="body">Initially, when LLMs were being developed, their output didn’t make much sense. The text would be readable, but it lacked structure or grammatical sense. If we read this example, it parses perfectly well, and it makes sense. However, as I mentioned, the book that ChatGPT describes doesn’t exist. In the context of an LLM, this is known as a <i class="fm-italics">hallucination.</i> The LLM is able to output a clear statement in a way that grants it some authority, but what has been written is false.</p>
<p class="body">LLM hallucinations can be caused by a range of factors, such as the quality of the data it was trained on, the degree to which a model has been trained on data (overfitting), or a model’s propensity for giving an answer regardless of whether it is correct. One of the challenges of working with LLMs is that they act like a black box. It’s difficult to monitor how an LLM reached a specific conclusion, which is compounded by its indeterminate nature. Just because I got an output that contained a hallucination doesn’t mean that others will do the same in the future. (This is where the RLHF helps combat hallucinations: we can inform the model whether its output is false, and it will learn from that.)</p>
<p class="body">The risk of hallucinations means we must always maintain an element of skepticism when interpreting the output of an LLM. We need to be mindful that what is being returned from an LLM is predictive and not always correct. We can’t turn off our critical thinking just because a tool appears to be behaving in a way that mimics human behavior.</p>
<h3 class="fm-head1" id="heading_id_6">2.2.2 Data provenance</h3>
<p class="body">For most LLM users, it’s not just how the model works precisely that is a black box to us, but also the data it has been trained on. Since ChatGPT’s explosion in popularity, the conversation around data ownership and copyright has intensified. Companies such as X (formerly known as Twitter) and Reddit have accused OpenAI of stealing their data wholesale, and at the time of writing, a class action lawsuit against OpenAI has been filed by a collection of authors who accuse the company of breaching copyright law by training models on their works (<a class="url" href="https://mng.bz/1aBZ">https://mng.bz/1aBZ</a>).<a id="idIndexMarker012"/><a id="idIndexMarker013"/></p>
<p class="body">The results from these debates are yet to be seen, but if we bring this topic back to the world of software development, we must be mindful of what material an LLM has been trained on. For example, ChatGPT, at one point, would return nonsensical responses when specific phrases were sent to it, all because it had been trained on data from the subreddit r/counting, which is full of data that is seemingly nonsensical itself. You can learn more about this weird behavior from Computerphile at <a class="url" href="https://www.youtube.com/watch?v=WO2X3oZEJOA">www.youtube.com/watch?v=WO2X3oZEJOA</a>). If an LLM has been trained on garbage, it will output garbage.</p>
<p class="body">This becomes important when we consider tools such as GitHub Copilot, which uses the same GPT model that ChatGPT uses. Copilot has been fine-tuned differently, using the billions of lines of code stored in GitHub so that it can act as an assistant and suggest code snippets as we develop our codebase. We’ll explore in later chapters how we can put Copilot to good use, but again, we should be critical of what it suggests and not blindly accept everything it offers as a suggestion. Why? Ask yourself, are you happy with the code you’ve created in the past? Do you trust all the code others have created? If a large population of engineers is prone to implementing bad patterns, then that is what tools like Copilot will have been trained on. The point is a little hyperbolic because a lot of good developers and testers out there do good work—good work that Copilot is trained on. But it’s a thought exercise worth considering every now and then just to ensure that we remember who is in the driver’s seat when building applications with LLMs.</p>
<h3 class="fm-head1" id="heading_id_7">2.2.3 Data privacy</h3>
<p class="body">Just as we need to be mindful of what an LLM outputs, we also have to consider what we enter into it. The temptation to share material with LLMs to find answers to problems we’re facing will be strong. But we have to ask ourselves, where is the data we send being stored? As mentioned earlier, LLMs are being tweaked continuously through the RLFH feedback. Companies such as OpenAI and GitHub will take the information we share, store it, and use it for future model training (GitHub does offer some privacy controls over what it can store, though).<a id="idIndexMarker014"/><a id="idIndexMarker015"/><a id="marker-20"/></p>
<p class="body">This can be problematic when working for companies (or for ourselves) who want to keep their intellectual property private. Take Samsung, for example, whose employees accidentally leaked confidential material through the use of ChatGPT, as described here by TechRadar (you can read about it at <a class="url" href="https://mng.bz/PN52">https://mng.bz/PN52</a>):</p>
<p class="fm-quote">The company allowed engineers at its semiconductor arm to use the AI writer to help fix problems with their source code. But in doing so, the workers entered confidential data, such as the source code itself for a new program and internal meeting notes data relating to their hardware.</p>
<p class="body">As the adoption of LLMs begins to increase across organizations, we may begin to see an increase in policies that restrict what we can and can’t use LLMs for. Some may ban the use of third-party LLMs, and some organizations will opt to train and deploy their own internal LLMs for internal use (a topic we will explore in part 3). The result of those decisions will be highly contextual, but they will affect what type of LLMs we use and what data we can and cannot send, underlying our need to be mindful of what we send to LLMs.</p>
<p class="body">It’s also important to keep customer privacy in mind as we have an obligation not only to the companies we work for (especially for those who sign nondisclosure agreements) but also to our users. We have a legal and moral duty to protect user data from being spread into the wild, where we have no oversight.</p>
<p class="body">In conclusion, although LLMs provide a wealth of opportunities, we must avoid the trap of anthropomorphizing them. Treating LLMs as if they have come to conclusions in the same way as we humans do is a fallacy. It can entrench a level of trust in the output that is dangerous and likely means that we aren’t getting the most benefit out of them. However, if we learn to use the probabilistic nature of LLMs when we instruct them, we can increase our chances of creating outputs that can help us improve efficiency—which is where prompt engineering can help us.<a id="idIndexMarker016"/></p>
<h2 class="fm-head" id="heading_id_8">2.3 Improving results with prompt engineering</h2>
<p class="body">We use natural language to prompt an LLM to return a desired outcome, but because they are probabilistic, we can communicate with them in a way that differs from normal interaction with humans. As LLMs have developed, a new field of engineering has appeared known as <i class="fm-italics">prompt engineering,</i> which contains a collection of patterns and techniques that we can use to increase the likelihood of getting a desired output from an LLM.<a id="idIndexMarker017"/><a id="idIndexMarker018"/><a id="marker-21"/></p>
<div class="fm-sidebar-block">
<p class="fm-sidebar-title">What is a prompt?</p>
<p class="fm-sidebar-text">In this book, we’ll use the term <i class="fm-italics">prompt</i> regularly as this will be our primary means of communicating with LLMs. When we use this term, we are simply referring to the natural language input that is sent to an LLM. For example, in the first example of this chapter, I sent the following prompt:</p>
<p class="fm-sidebar-text-list"><span class="infigure"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></span>   Hello ChatGPT, can you introduce yourself briefly?</p>
<p class="fm-sidebar-text">which prompted the LLM to return this response to me:</p>
<p class="fm-sidebar-text-list"><span class="infigure"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></span>   Hello! I’m ChatGPT, an AI language model developed by OpenAI. I can help with answering questions, providing information, brainstorming ideas, and more. Feel free to ask me anything!</p>
</div>
<p class="body">In the coming chapters, we will use prompt engineering heavily to trigger LLMs to deliver a range of useful content for various testing activities. But before we begin, it’s worthwhile learning the fundamentals of prompt engineering so that we can see how prompts are built to maximize output from LLMs.</p>
<p class="body">To help us better understand what prompt engineering is, consider these two prompts sent to an LLM. The first is a general question:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">What risks should I test for when testing a Contact Us form?</p>
</td>
</tr>
</tbody>
</table>
<p class="body">The second is a more detailed prompt:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Assume the role of a professional software tester and suggest a list of risks for a Contact Us form using the following constraints:</p>
<p class="body-table"># Focus on the quality characteristics of accessibility, compliance and usability</p>
<p class="body-table"># Number each risk</p>
<p class="body-table"># Provide which quality characteristic the risk relates to</p>
<p class="body-table"># Use no more than 30 words to describe each risk</p>
<p class="body-table">For example:</p>
<p class="body-table-list-a">   1.  Semantic structure - Accessibility - The HTML structure of the form should follow WCAG A standards</p>
</td>
</tr>
</tbody>
</table>
<p class="body">Comparing the two, we can see that the second example is more detailed, with explicit requests and examples to outline what we might expect the LLM to return. Although the intention is similar, the output from each is drastically different.<a id="marker-22"/></p>
<p class="body">Compare the output from the first example:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Validation and Error Handling: Verify that the form correctly validates user input, such as email addresses, phone numbers, and required fields. Test for appropriate error messages when users submit incorrect or incomplete information.</p>
<p class="body-table">Security: Ensure that the contact form is secure and protected against common vulnerabilities such as cross-site scripting (XSS) and SQL injection attacks. Validate that the form sanitizes or escapes user input to prevent malicious code execution.<a id="idIndexMarker019"/></p>
<p class="body-table">Usability: Test the form’s usability by evaluating factors such as the clarity of form fields, user instructions, and overall user experience. Make sure the form is intuitive, easy to navigate, and visually appealing.</p>
</td>
</tr>
</tbody>
</table>
<p class="body">against the second example:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table-list-a">   1.  Keyboard accessibility - Accessibility - Ensure the form can be easily navigated and filled out using only a keyboard.</p>
<p class="body-table-ind-a">...</p>
<p class="body-table-list-a">   6.  Consistent design - Usability - Verify that the form follows a consistent design pattern and matches the overall website design.</p>
<p class="body-table-ind-a">...</p>
<p class="body-table-list-a"> 13.  Consent checkboxes - Compliance - Ensure any consent checkboxes or privacy policy links are clearly presented and function correctly.</p>
</td>
</tr>
</tbody>
</table>
<p class="body">Imagine that we want to use the proposed risks in each example to guide our testing. The first example has output suggestions that are vague and abstract. We would still need to do a fair bit of work to break down the large topics, such as security risks, whereas, with the second example, we have specific, actionable risks that we could use easily. And the goal of using tools such as LLM is to <i class="fm-italics">reduce</i> the workload, not increase it.</p>
<p class="body">Our second prompt yields better results because the instructions it gives have been considered and are detailed and clear, which is what prompt engineering is essentially about. Although both prompts use natural language, with prompt engineering, we are aware of how an LLM works and what we want it to return to understand how to write a prompt so that we maximize the chances of a desired outcome. When using prompt engineering, we can see that although an LLM communicates in plain language, how it processes our request differs from how a human might do so, so we can adopt specific techniques to steer an LLM in the direction we want.<a id="idIndexMarker020"/><a id="idIndexMarker021"/></p>
<h2 class="fm-head" id="heading_id_9">2.4 Examining the principles of prompt engineering</h2>
<p class="body">As LLMs have developed, so have the patterns and techniques of prompt engineering. Many courses and blog posts have been written around prompt engineering, but one notable collection of principles, which we’ll explore shortly, has been created by Isa Fulford and Andrew Ng and their respective teams. A collaboration between OpenAI’s LLM knowledge and Deeplearning.ai’s teaching platform has created a course called ChatGPT Prompt Engineering for Developers, which features a series of principles and tactics that can be used in prompts to get the most out of LLMs. If you have the time, I encourage you to take the short course available at <a class="url" href="https://mng.bz/JNGp">https://mng.bz/JNGp</a> (<a class="url" href="https://www.promptingguide.ai/">https://www.promptingguide.ai/</a> is also a useful reference.) Although the course references ChatGPT specifically, the principles taught there can be applied across many LLMs. So let’s explore these principles and tactics to get comfortable with prompting LLMs.<a id="idIndexMarker022"/><a id="marker-23"/><a id="idIndexMarker023"/></p>
<h3 class="fm-head1" id="heading_id_10">2.4.1 Principle 1: Write clear and specific instructions</h3>
<p class="body">This first principle might seem obvious at first glance—it’s always sensible to provide instructions to others that are clear and specific. However, what this principle suggests is that we write prompts that are clear and specific <i class="fm-italics">for an LLM.</i> And that means something different from what might be clear and specific to a human. To implement this concept, Fulford and Ng teach four tactics to achieve clear and specific prompts: use delimiters, ask for structured output, check for assumptions, and use few-shot prompting. In the next few sections, we’ll examine each one in more detail.<a id="idIndexMarker024"/><a id="idIndexMarker025"/></p>
<h3 class="fm-head1" id="heading_id_11">2.4.2 Tactic 1: Use delimiters</h3>
<p class="body">When writing prompts, we may need to provide different content and data that serve different purposes. For example, the start of our prompt might include instructions on what we want an LLM to produce, whereas the end of our prompt might include raw data that we want to process. LLMs can guess our intentions for different sections of our prompts, but because our goal is to be as clear as possible, we can aid the process by using <i class="fm-italics">delimiters,</i> which are characters used to separate strings, to state our intentions for different parts of our prompt. Take this prompt as an example. We open the prompt with a message that sets expectations:<a id="idIndexMarker026"/><a id="idIndexMarker027"/><a id="idIndexMarker028"/></p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">You are a SQL data generator. Generate five rows of SQL for a MySQL database.</p>
</td>
</tr>
</tbody>
</table>
<p class="body">We use the * character to delimit rules:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table-list-a">   *   The table name is identified with a # sign.</p>
<p class="body-table-list-a">   *   Each table column is identified with a % sign</p>
<p class="body-table-list-a">   *   Each column is described in order of name, data type and data options using the | sign</p>
<p class="body-table-list-a">   *   If a column data option says random, randomize data based on the suggested format and column name</p>
</td>
</tr>
</tbody>
</table>
<p class="body">We then use the #, %, and | delimiters that we set in rules to provide instructions:<a id="marker-24"/></p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Here are the instructions:</p>
<pre class="programlisting"># rooms
% room_name | string | random
% type | string |  'single' or 'double'
% beds | integer | 1 to 6
% accessible | boolean | true or false
% image | string | random url
% description | string | random max 20 characters
% features | array[string] | 'Wifi', 'TV' or 'Safe'
% roomPrice |  integer | 100 to 200</pre>
</td>
</tr>
</tbody>
</table>
<p class="body">When running this prompt within ChatGPT, I received the following output:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<pre class="programlisting">INSERT INTO rooms (room_name, type, beds, accessible, image,
 description, features, roomPrice) VALUES
    ('Room 1', 'single', 3, true, 'https://example.com/image1.jpg',
 'Lorem ipsum dolor', '["Wifi", "TV"]', 150),
    ('Room 2', 'double', 2, false, 'https://example.com/image2.jpg',
 'Lorem ipsum dolor', '["TV", "Safe"]', 180),
    ('Room 3', 'double', 4, true, 'https://example.com/image3.jpg',
 'Lorem ipsum dolor', '["Wifi", "Safe"]', 160),
    ('Room 4', 'single', 1, true, 'https://example.com/image4.jpg',
 'Lorem ipsum dolor', '["Wifi", "TV"]', 120),
    ('Room 5', 'double', 3, false, 'https://example.com/image5.jpg',
 'Lorem ipsum dolor', '["TV"]', 170);</pre>
</td>
</tr>
</tbody>
</table>
<p class="body">As we can see, through the use of delimiters the correct table name <code class="fm-code-in-text">rooms</code> has been added, and the column names, formats, and ranges have been correctly randomized. This is made possible by the clear expectations and rules we set that are distinguished by various delimiters throughout the prompt.</p>
<p class="body">The delimiters help to make the prompt clearer, but they also make it easy to modify. For example, if we want to reconfigure the generated data, we could enter another line, such as</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<pre class="programlisting">% room_size | string | 20m2 to 50m2</pre>
</td>
</tr>
</tbody>
</table>
<p class="body">So, when writing prompts that contain a large amount of data that changes context, we can use delimiters to make clear what is being provided in a prompt at a specific point.</p>
<div class="fm-sidebar-block">
<p class="fm-sidebar-title">Activity 2.1</p>
<p class="fm-sidebar-text">Using the delimiter prompt example, we create new instructions—this time, for a booking that would include information about who made the booking, contact details, and check-in and check-out dates.</p>
</div>
<h3 class="fm-head1" id="heading_id_12">2.4.3 Tactic 2: Ask for structured output</h3>
<p class="body">One facet of LLMs that makes them useful is that they have the ability to provide outputs in structured formats. As we make our way through this book, we’ll explore just how useful this ability is, but as a rule, we must always remember that we need to be clear in a prompt about what structured format we want to see used. Take this prompt as an example:<a id="idIndexMarker029"/><a id="marker-25"/><a id="idIndexMarker030"/></p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Create a JSON object with random data that contains the following fields: firstname, lastname, totalprice, deposit paid. Also, include an object called booking dates that contains checkin and checkout dates.</p>
</td>
</tr>
</tbody>
</table>
<p class="body">We begin the prompt by clearly stating what format we want to see our object in, in this case, JSON, before we start outlining the structure of the object. When I sent this prompt to ChatGPT, the following result was returned:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<pre class="programlisting">{
  "firstname": "John",
  "lastname": "Doe",
  "totalprice": 150.50,
  "deposit_paid": true,
  "booking_dates": {
    "checkin": "2023-08-01",
    "checkout": "2023-08-10"
  }
}</pre>
</td>
</tr>
</tbody>
</table>
<p class="body">As the prompt clearly states, the expected format and structure are two distinct instructions, meaning we can modify our instructions to quickly change the format by sending an additional prompt, such as</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Create this in a YAML format</p>
</td>
</tr>
</tbody>
</table>
<p class="body">Sending this prompt to ChatGPT returned the following output:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<pre class="programlisting">firstname: John
lastname: Doe
totalprice: 150.50
deposit_paid: true
booking_dates:
  checkin: 2023-08-01
  checkout: 2023-08-10</pre>
</td>
</tr>
</tbody>
</table>
<p class="body">Notice the structure is the same (as well as the randomized data). By explicitly stating what format we desire, we can instruct an LLM with exactly what format we want at a given time and then alternate formats with ease.</p>
<div class="fm-sidebar-block">
<p class="fm-sidebar-title">Activity 2.2</p>
<p class="fm-sidebar-text">Attempt to create an object that contains multiple parameters with different data types in different formats. Try prompting an LLM to convert your object from one format to another—for example, from JSON to XML.</p>
</div>
<h3 class="fm-head1" id="heading_id_13">2.4.4 Tactic 3: Check for assumptions</h3>
<p class="body">As we learned earlier, LLMs can hallucinate by generating output that contains information that is incorrect or disconnected from reality. It goes without saying that we want to reduce the risk of producing hallucinations, which is where our third tactic, checking for assumptions, can help. LLMs are more likely to hallucinate if they are provided with prompts that are focused on edge cases around a problem we want to solve. If an LLM is not properly instructed, it’s more likely to make a guess at an answer than to outright inform us that it cannot provide a useful answer. So, if we want to avoid guesswork, we need to provide instructions in our prompt to allow the LLM to bail out if it cannot execute our request. Consider the following example. It provides initial instructions for the prompt, which includes a delimiter:<a id="marker-26"/><a id="idIndexMarker031"/></p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">You will be provided with a JSON object delimited by three hashes. Extract all emails that end with .com and write them out as a list.</p>
</td>
</tr>
</tbody>
</table>
<p class="body">We then check for assumptions and allow the LLM to bail:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">If no email addresses with a .com email address exist, simply write “No .com emails found”</p>
</td>
</tr>
</tbody>
</table>
<p class="body">Finally, we provide the data to process using ### as a delimiter:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<pre class="programlisting">###
[{
  "firstname": "Bret",
  "lastname": "Averay",
  "email": "baveray0@apple.com"
}, {
  "firstname": "Annabel",
  "lastname": "Biswell",
  "email": "abiswell2@nsw.gov.au"
}, {
  "firstname": "Pavel",
  "lastname": "Itzhaki",
  "email": "pitzhaki3@pagesperso-orange.fr"
}, {
  "firstname": "Pail",
  "lastname": "Yandell",
  "email": "pyandell4@ning.com"
}, {
  "firstname": "Glennis",
  "lastname": "Pentecost",
  "email": "gpentecost6@yelp.com"
}]
###</pre>
</td>
</tr>
</tbody>
</table>
<p class="body"><a id="marker-27"/>Running this prompt with a collection of email addresses that can be extracted returned the following output:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Here are the email addresses that end with “.com”:</p>
<p class="body-table-list-a">   *   baveray0@apple.com</p>
<p class="body-table-list-a">   *   pyandell4@ning.com</p>
<p class="body-table-list-a">   *   gpentecost6@yelp.com</p>
</td>
</tr>
</tbody>
</table>
<p class="body">But here’s what happened when I ran the prompt again without email addresses:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">You will be provided with a JSON object delimited by three hashes. Extract all emails that end with .com and write them out as a list.</p>
<p class="body-table">If no email addresses with a .com email address exist, simply write “No .com emails found”</p>
<pre class="programlisting">###
[{
  "firstname": "Bret",
  "lastname": "Averay"
}, {
  "firstname": "Annabel",
  "lastname": "Biswell"
}, {
  "firstname": "Pavel",
  "lastname": "Itzhaki"
}, {
  "firstname": "Pail",
  "lastname": "Yandell"
}, {
  "firstname": "Glennis",
  "lastname": "Pentecost"
}]
###</pre>
</td>
</tr>
</tbody>
</table>
<p class="body">I received the following:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Here is the list of email addresses that end with .com extracted from the provided JSON object:</p>
<p class="body-table">No .com emails found</p>
</td>
</tr>
</tbody>
</table>
<p class="body">This response from the LLM was a direct reference to this section of the prompt:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">If no email addresses with a .com email address exist, simply write “No .com emails found.”</p>
</td>
</tr>
</tbody>
</table>
<p class="body">which prevented the LLM from providing an output that was incorrect. For example, when I ran the prompt without the assumption check, the following was returned:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Sure! I can help you with that. Here are the email addresses that end with “.com” from the provided JSON object:</p>
<pre class="programlisting">`
["bret@example.com", "annabel@example.com", "pavel@example.com", "pail@example.com", "glennis@example.com"]
`</pre>
<p class="body-table">Please note that I have used example.com as a placeholder domain for all the email addresses. Replace it with the appropriate domain if you have the actual email addresses.</p>
</td>
</tr>
</tbody>
</table>
<p class="body">This is an excellent example of an LLM hallucination. The object we provided contained no email addresses, so the LLM used guesswork and incorrectly started generating new email addresses based on existing data. However, with the assumption check in place, we prevented the hallucination from occurring.</p>
<div class="fm-sidebar-block">
<p class="fm-sidebar-title">Activity 2.3</p>
<p class="fm-sidebar-text">Create a prompt that filters specific data out of a list of raw data and then outputs the results (for example, filter fruit from a list of different foodstuffs). Next, modify the data to include an edge case (for example, incorrect or missing data). Observe what the LLM outputs, and then attempt to correct the output by adding to the prompt some instructions that follow the check-for-assumptions prompt.</p>
</div>
<h3 class="fm-head1" id="heading_id_14">2.4.5 Tactic 4: Few-shot prompting</h3>
<p class="body">As we’ve progressed through this chapter and learned new concepts about LLMs and prompting, key points have been clarified using examples. They are essential tools when it comes to not just teaching but also communicating with one another. This is no different for LLMs. <i class="fm-italics">Few-shot prompting</i> basically means providing explicit examples to clarify instructions (The word <i class="fm-italics">few</i> in this context indicates how many examples you share. A prompt with no examples would be a <i class="fm-italics">zero-shot prompt</i>). What follows is a prompt using examples. First, we provide the instructions in the prompt outlining the output format:<a id="idIndexMarker032"/><a id="idIndexMarker033"/><a id="marker-28"/><a id="idIndexMarker034"/><a id="idIndexMarker035"/></p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">You are an expert exploratory tester. Create three test charters for a booking system that focus on the risks around booking dates. The format should follow: Explore &lt;Target&gt; using &lt;Resource&gt; to discover &lt;Information&gt;</p>
</td>
</tr>
</tbody>
</table>
<p class="body">We provide examples to clarify the output format for the LLM:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">For example:</p>
<p class="body-table-list-a">   *   Explore user permissions using different users to discover permission risks</p>
<p class="body-table-list-a">   *   Explore browser animations using different devices to discover how animations render</p>
</td>
</tr>
</tbody>
</table>
<p class="body">Sending this prompt to ChatGPT returned the following output:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Explore date validation using various date formats to discover potential input errors.</p>
<p class="body-table">Explore time zone handling using different geographical locations to discover discrepancies in booking times.</p>
<p class="body-table">Explore booking conflicts using overlapping reservation requests to discover potential double-booking risks.</p>
</td>
</tr>
</tbody>
</table>
<p class="body">Consider the format of “Explore &lt;Target&gt; using &lt;Resource&gt; to discover &lt;Information&gt;.” It is rule based, but it leans heavily on natural language to communicate the rules (unlike JSON or XML structures that rely on explicit delimiter rules). By providing examples in our prompt, we can help contextualize what we mean by <code class="fm-code-in-text">&lt;Target&gt;</code>, <code class="fm-code-in-text">&lt;Resource&gt;</code>, and <code class="fm-code-in-text">&lt;Information&gt;</code> and reduce the risk of the LLM guessing what that means.</p>
<div class="fm-sidebar-block">
<p class="fm-sidebar-title">Activity 2.4</p>
<p class="fm-sidebar-text">Create a prompt that uses the few-shot tactic. In your prompt, provide the instructions you expect the LLM to follow and then add at least two examples to help guide it in providing a desired outcome.</p>
</div>
<h3 class="fm-head1" id="heading_id_15">2.4.6 Principle 2: Give the model time to “think”</h3>
<p class="body"><a id="marker-29"/>It may seem a little unusual, given that we’ve been considering LLMs as probabilistic machines and not entities that can think, to see a principle that encourages us to give a model time to think. However, the best way to understand this principle is that we’re not actually giving an LLM time to think but rather emulating how we would give someone time to think about a task in our prompt. In the ChatGPT Prompt Engineering for Developers course, Fulford gives a useful analogy as she introduces this principle: “If you give a model a task that’s too complex to do in a short amount of time, . . . it may make up a guess which is likely to be incorrect.”<a id="idIndexMarker036"/><a id="idIndexMarker037"/></p>
<p class="body">She explains that the same situation would happen if humans were given a complex task with limited time to respond. We’d rely on educated guesswork and likely come up with a less-than-satisfactory answer. Thus, principle 2 offers tactics to help us write prompts that break down tasks and encourage LLMs to evaluate output to once again maximize the chances of a desired response.</p>
<h3 class="fm-head1" id="heading_id_16">2.4.7 Tactic 1: Specify the steps to complete the task</h3>
<p class="body">The first tactic is relatively straightforward once we are confident about using the tactics of principle 1 (write clear and specific instructions). By using delimiters, we can break a complex task into individual steps for an LLM to take to solve the larger task. Take a look at this prompt, where we first notify the LLM that a set of instructions is coming, followed by delimited data:<a id="marker-30"/><a id="idIndexMarker038"/></p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">You are going to be given a list of instructions to follow.</p>
</td>
</tr>
</tbody>
</table>
<p class="body">We then list each subtask clearly to instruct the LLM on what to do:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table-list-a">   1.  Identify functional risks that might impact the text delimited by three hashes</p>
<p class="body-table-list-a">   2.  Convert the risks into test charters</p>
<p class="body-table-list-a">   3.  Format each charter into a Discover &lt;feature&gt; using &lt;resource&gt; to discover &lt;information&gt; format</p>
</td>
</tr>
</tbody>
</table>
<p class="body">Finally, we provide the data we would like to see processed:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">###</p>
<p class="body-table">As a user</p>
<p class="body-table">I want to be able to calculate my tax</p>
<p class="body-table">So I know what tax I have to pay</p>
<p class="body-table">###</p>
</td>
</tr>
</tbody>
</table>
<p class="body">When sent to ChatGPT, it returned this result:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">Functional risks:</p>
<p class="body-table-list-a">   •   Calculation accuracy: There is a risk that the tax calculation may be inaccurate, leading to incorrect tax amounts being calculated.</p>
<p class="body-table">Test charters based on the identified risks:</p>
<p class="body-table-list-a">   •   Test Charter 1: Validate the accuracy of tax calculations by inputting different test scenarios with known tax amounts and verifying that the calculated tax matches the expected values.</p>
<p class="body-table">Formatting the charters into a “Discover &lt;feature&gt; using &lt;resource&gt; to discover &lt;information&gt;” format:</p>
<p class="body-table-list-a">   •   Discover tax calculation accuracy using test scenarios with known tax amounts to validate the accuracy of the calculated tax.</p>
</td>
</tr>
</tbody>
</table>
<p class="body">This is a snippet from the output I received. It created many more risks and charters, but the first example from each section demonstrates the LLM responding to each subtask, one by one, to create an output.</p>
<div class="fm-sidebar-block">
<p class="fm-sidebar-title">Activity 2.5</p>
<p class="fm-sidebar-text">Create a prompt that requires a complex task to be carried out. Attempt to break out the complex task into multiple subtasks that the LLM can carry out.</p>
</div>
<h3 class="fm-head1" id="heading_id_17">2.4.8 Tactic 2: Instruct the model to work out its own solution first</h3>
<p class="body">Our final tactic focuses not on the process of creating an output, but rather on evaluating the output itself. Similar to checking for assumptions, ask an LLM to evaluate the output to confirm that it aligns with what it has been instructed to produce. Let’s check out an example to gain a better understanding of how this would work. First, take a look at a prompt that doesn’t ask an LLM to work out its solution first but sets out the instructions for the LLM to follow:<a id="marker-31"/><a id="idIndexMarker039"/></p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">You are a software developer in test that is experienced in writing Java. Create a unit test for the following method:</p>
</td>
</tr>
</tbody>
</table>
<p class="body">We then provide the code it needs to provide unit tests for:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<pre class="programlisting">public class AuthService {

   public HttpStatus deleteToken(Token token) throws SQLException {
        Boolean successfulDeletion = authDB.deleteToken(token);
 
        if(successfulDeletion){
            return HttpStatus.OK;
        } else {
            return HttpStatus.NOT_FOUND;
        }
    }
}</pre>
</td>
</tr>
</tbody>
</table>
<p class="body">Sending this to ChatGPT, the following result was returned:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<pre class="programlisting">import org.junit.jupiter.api.Test;
import static org.junit.jupiter.api.Assertions.*;

class TokenManagerTest {

    @Test
    void deleteToken_SuccessfulDeletion_ReturnsOK() throws SQLException {
        // Arrange
        TokenManager tokenManager = new TokenManager();
        Token token = new Token();

        // Act
        HttpStatus result = tokenManager.deleteToken(token);

        // Assert
        assertEquals(HttpStatus.OK, result);
    }
}</pre>
</td>
</tr>
</tbody>
</table>
<p class="body">This looks like reasonable Java code for a unit test, but if this were added to a suite of unit checks, it would fail because the method <code class="fm-code-in-text">authDB.deleteToken</code> in the production code provided has not been handled correctly. Specifically, if we wanted this unit check to work, we would need to mock <code class="fm-code-in-text">authDB.deleteToken</code>.<a id="marker-32"/><a id="idIndexMarker040"/></p>
<p class="body">Now, if we run the prompt again but this time have it evaluate its solution before outputting a final answer, we get a different result. So first we change the prompt to a new prompt that asks the LLM to confirm that the result of the check works:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<p class="body-table">You are a software developer in test that is experienced in writing Java. Create a unit test for the following method that will be shared. Before outputting the unit tests, check to see that the assertion of each unit check will return a deterministic result.</p>
</td>
</tr>
</tbody>
</table>
<p class="body">We then provide the code for which a unit test will be written:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-MW.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<pre class="programlisting">public class AuthService {

   public HttpStatus deleteToken(Token token) throws SQLException {
        Boolean successfulDeletion = authDB.deleteToken(token);

        if(successfulDeletion){
            return HttpStatus.OK;
        } else {
            return HttpStatus.NOT_FOUND;
        }
    }

}</pre>
</td>
</tr>
</tbody>
</table>
<p class="body">Sending this to ChatGPT returned this result:</p>
<table border="0" class="contenttable-0-table" width="100%">
<colgroup class="contenttable-0-colgroup">
<col class="contenttable-0-col" span="1" width="7%"/>
<col class="contenttable-0-col" span="1" width="93%"/>
</colgroup>
<tbody class="contenttable-0-tbody">
<tr class="contenttable-0-tr">
<td class="contenttable-0-td">
<div class="figure2">
<p class="figure1"><img alt="" class="calibre7" height="40" src="../../OEBPS/Images/logo-openai.png" width="40"/></p>
</div>
</td>
<td class="contenttable-0-td">
<pre class="programlisting">import org.junit.jupiter.api.Assertions;
import org.junit.jupiter.api.Test;
import org.mockito.Mockito;

import java.sql.SQLException;

public class TokenDeletionTest {

    @Mock
    private AuthDB authDB;

    @Test
    public void testDeleteToken_SuccessfulDeletion() throws SQLException {

        // Mocking the behavior of authDB.deleteToken() to return true
        Token token = new Token();
        Mockito.when(authDB.deleteToken(token)).thenReturn(true);
        AuthService authService = new AuthService(authDB);
        HttpStatus result = authService.deleteToken(token);

        // Assertion: The method should return HttpStatus.OK
        Assertions.assertEquals(HttpStatus.OK, result);
    }
}</pre>
</td>
</tr>
</tbody>
</table>
<p class="body">This time, we can see that because we asked the LLM to evaluate its solution before returning a result, the output unit check uses <code class="fm-code-in-text">Mockito</code> to mock the <code class="fm-code-in-text">authDB.deleteToken</code>. So, if we observe problems with LLMs outputting erroneous solutions or they start hallucinating, we can add an instruction to evaluate solutions first to minimize the occurrence of hallucinations.</p>
<div class="fm-sidebar-block">
<p class="fm-sidebar-title">Activity 2.6</p>
<p class="fm-sidebar-text">Create a prompt that requires an LLM to work out a solution to a problem. Observe its output and see if the solution it produces is correct. Then add instructions to have the LLM evaluate the solution. What happens? Does the solution change? Is it an improvement?</p>
</div>
<h2 class="fm-head" id="heading_id_18">2.5 Working with various LLMs</h2>
<p class="body">So far, we’ve talked about LLMs in a broad sense while using OpenAI’s ChatGPT in the previous examples to demonstrate how they work in general. However, ChatGPT is just one of the many different LLMs that we can use. So, before we conclude the chapter, let’s familiarize ourselves with the ways in which LLMs differ from one another and learn about some of the currently popular models and communities so that we can increase our chances of finding the right LLM for the job.<a id="marker-33"/><a id="idIndexMarker041"/></p>
<h3 class="fm-head1" id="heading_id_19">2.5.1 Comparing LLMs</h3>
<p class="body">What makes an LLM good? How do we determine whether a model is worth using? These are not easy questions to answer. The complex nature of LLMs, how they’re trained, and what data was used close these systems off to deep analysis, compromising an area that some researchers are trying to improve or shed light upon. However, that doesn’t mean we shouldn’t educate ourselves on some of the key aspects of LLMs and how they affect them. We might not all be AI researchers attempting to explore the deep inner workings of LLMs, but we are or will be their users and will want to know that what we spend resources on is giving us value. So, to help us break down some of the jargon and give us some grounding on how LLMs differ, let’s go through some key attributes discussed in the world of LLMs.<a id="idIndexMarker042"/></p>
<p class="fm-head2">Parameter count</p>
<p class="body">If you take a look at different LLMs, you’ll likely see talk of LLMs having a 175-billion- or 1-trillion-parameter count. It can sometimes feel like marketing speak, but parameter count does not affect LLMs’ performance. The parameter count essentially refers to the amount of statistical weights that exist in a model. Each individual weight provides a piece of the statistical puzzle that makes up an LLM. So, roughly speaking, the more parameters an LLM has, the better it will perform. The parameter count can also give us a sense of cost. The higher the parameter count, the more expensive it is to run, and there is a cost that may be, in part, handed down to users.<a id="idIndexMarker043"/><a id="idIndexMarker044"/></p>
<p class="fm-head2">Training data</p>
<p class="body">LLMs require huge quantities of data to be trained on, so the size and quality of data will have an effect on the quality of an LLM. If we want an LLM to be accurate in how it responds to requests, it’s not enough to just throw as much data as possible. It needs to be data that can help influence the probability of a model in a sensible manner. For example, the Reddit example we explored earlier in this chapter, in which the subreddit r/counting used to train ChatGPT caused it to hallucinate in strange ways, demonstrates that more isn’t necessarily better. Still, similar to parameter count, the more high-quality data an LLM has been trained on, the better it will likely perform. The challenge is in knowing what data an LLM has been trained on—something that corporate creators of AI are keen on keeping a secret.<a id="marker-34"/><a id="idIndexMarker045"/><a id="idIndexMarker046"/></p>
<p class="fm-head2">Extensibility and integration</p>
<p class="body">Just like with any other tool, the value of an LLM can be increased further if it can offer other features beyond its core abilities, such as integrating into existing systems or training models further for our specific needs. What features are available to integrate and extend LLMs depends largely on who was responsible for training.<a id="idIndexMarker047"/></p>
<p class="body">For example, OpenAI offers paid-for API access to their models. But beyond an instruction feature that allows you to tweak output with a simple prompt, there is no ability to further fine-tune and deploy one of their GPT models for private use. Compare this to Meta’s LlaMa model, which has been open sourced, allowing the AI community to download and further train to their own requirements, although they must build their own infrastructure to deploy the model.</p>
<p class="body">As LLM platforms grow, we will see advances in not just their ability to respond to prompts but also the features around them and their access. Thus, it’s necessary to keep said features in mind when evaluating what to work with.</p>
<p class="fm-head2">Quality of responses</p>
<p class="body">Arguably, the most important factor to consider is whether an LLM provides responses that are legible, useful, and free (or as close to free) of hallucination as possible. Although criteria such as parameter count and training data are useful indicators of an LLM’s performance, it’s up to us to understand what we want to use an LLM for and then determine how each responds to our prompts and helps solve our specific problems. Not all challenges we face need the largest, most expensive LLM in the market. Thus, it’s important that we take time to try out different models, compare their outputs, and then make a judgment for ourselves. For example, GPT models from OpenAI are found to perform better with code examples than Google Gemini. These details have been discovered through experimentation and observation.<a id="idIndexMarker048"/></p>
<p class="body">The criteria we’ve explored are by no means an exhaustive list, but they demonstrate that there is more to consider about LLMs once we get past the initial glamour of how they respond. Different LLMs perform differently, helping us with various challenges. So let’s take a look at some of the more popular currently available models and platforms.<a id="idIndexMarker049"/></p>
<h3 class="fm-head1" id="heading_id_20">2.5.2 Examining popular LLMs</h3>
<p class="body">Since OpenAI’s launch of ChatGPT, there has been an explosion in releases of LLMs from various organizations. It’s not to say that these models and related work weren’t around before ChatGPT’s release, but the public focus has certainly intensified, and an increasing number of marketing and release announcements have focused on companies releasing their LLM offerings. Here are some of the more common/popular LLMs that have been released since the end of 2022.<a id="marker-35"/><a id="idIndexMarker050"/></p>
<div class="fm-sidebar-block">
<p class="fm-sidebar-title">Keeping up with LLMs</p>
<p class="fm-sidebar-text">It’s worth noting that the situation with the launch of LLMs and their related features is extremely fluid and has grown at quite a fast pace. Therefore, it’s likely that some of what we’ll explore will differ from the time of writing in mid-2024 to the time you are reading this book. Fortunately, sites such as LLM Models (<a class="url" href="https://llmmodels.org/">https://llmmodels.org/</a>) share up-to-date lists to review. However, this list demonstrates that some of the bigger names in the LLM space are worth exploring.</p>
</div>
<p class="fm-head2">OpenAI</p>
<p class="body">At the time of writing, OpenAI is the most ubiquitous of organizations offering LLMs for use. Although OpenAI has been working on LLM models for quite some time, releasing their GPT-3 model in 2020, it was their release of ChatGPT in November 2022 that kick-started the popular wave of interest and use of LLMs.<a id="idIndexMarker051"/></p>
<p class="body">OpenAI offers a range of different LLM models, but the two that stand out are GPT-3.5-Turbo and GPT-4o, which you can learn about more at <a class="url" href="https://platform.openai.com/docs/models/overview">https://platform.openai.com/docs/models/overview</a>. These two models are used as <i class="fm-italics">foundation</i> models or models that can be trained further for specific purposes, for a range of products such as ChatGPT, GitHub Copilot, and Microsoft Bing AI.</p>
<p class="body">In addition to their models, OpenAI has offered a range of features such as API access to their direct GPT-3.5-Turbo and GPT-4 models and a collection of apps that integrate with ChatGPT (if you subscribe to their plus membership). It’s by far the most popular LLM (for now) and has kick-started a race with organizations to release their own LLMs. Although we’ve already explored some prompts with ChatGPT, you can always access and experiment with ChatGPT at <a class="url" href="https://chatgpt.com/">https://chatgpt.com/</a>.</p>
<div class="fm-sidebar-block">
<p class="fm-sidebar-title">Sticking with OpenAI</p>
<p class="fm-sidebar-text">Although there are many different LLMs that I encourage you to use, for the sake of consistency, we will stick with ChatGPT-3.5-Turbo. It’s not necessarily the most powerful LLM at this time, but it is the most ubiquitous—and free. That said, if you want to try out these prompts with other LLM models, feel free to do so. However, keep in mind that their responses will likely differ from what is shared in this book.</p>
</div>
<p class="fm-head2">Gemini</p>
<p class="body">Unsurprisingly, Google also has a stake in the Generative AI market with their own range of LLM models known as Gemini. Currently at the time of writing their most powerful model is Gemini 1.5 Pro, but they also offer other versions of their models such as Gemini 1.5 Flash and Gemini 1.0 Pro. Given it's Google the parameter counts for each model is not public knowledge, but they are relatively comparable in performance to other LLM models.</p>
<p class="body">Similar to OpenAI, Google offers access to their Gemini models via their Google Cloud platform (<a class="url" href="https://ai.google.dev/">https://ai.google.dev/</a>) and has recently started offering apps that work similarly to OpenAI’s ChatGPT apps, with the added integration into other Google Suite tools such as Google Drive and Gmail. You can access and experiment with Gemini at <a class="url" href="https://gemini.google.com/app">https://gemini.google.com/app</a>.</p>
<p class="fm-head2">LLaMa</p>
<p class="body">LLaMa, which is the name for a collection of models, was first released by Meta in July 2023. What sets LLaMa apart from OpenAI’s GPT models and Google’s Gemini is that LLaMa is open source. In addition to the open source license, LLaMa comes in a range of sizes: 8 and 70 billion parameters, respectively. The combination of these sizes and their access means that LLaMa has been adopted by the AI community as a popular foundational model. The flip side of this access, though, is that Meta doesn’t provide a public platform to train and run versions of LLaMa. So, data sets and infrastructure must be personally sourced for use.<a id="idIndexMarker052"/><a id="marker-36"/></p>
<p class="body">More details on LLaMa can be found at the following links:</p>
<ul class="calibre5">
<li class="fm-list-bullet">
<p class="list"><a class="url" href="https://ai.meta.com/blog/meta-llama-3/">https://ai.meta.com/blog/meta-llama-3/</a></p>
</li>
<li class="fm-list-bullet">
<p class="list"><a class="url" href="https://www.llama.com/llama-downloads/">https://www.llama.com/llama-downloads/</a></p>
</li>
</ul>
<p class="fm-head2">Hugging Face</p>
<p class="body">Unlike the other entries in our list, Hugging Face offers no proprietary model but instead facilitates an AI community that contains a wide variety of different models, most of which are open source. Looking at their index page of models available at <a class="url" href="https://huggingface.co/models">https://huggingface.co/models</a>, we can see hundreds of thousands of differently trained models that have come from different companies and research labs. Hugging Face also offers datasets for training, apps, and documentation that allows the reader to dive deeper into how models are built. All of these resources are available so that the AI community can access pretrained models, tweak them, and further train them for a specific use, which is something that we’ll be exploring further in part 3 of this book.<a id="idIndexMarker053"/></p>
<p class="body">The marketplace for LLMs has sizably grown in a short amount of time, both commercially and in open source, and similar to other areas of software development, being proactive in what new LLMs are appearing can be beneficial. However, it can also be overwhelming and not necessarily feasible to keep up with everything that is happening at once. So, instead of attempting to keep abreast of all the comings and goings in the AI community, we can opt to explore LLMs when we want to use LLMs to solve specific problems. Having a problem can help frame our criteria around which tools work best for us.<a id="idIndexMarker054"/><a id="idIndexMarker055"/></p>
<div class="fm-sidebar-block">
<p class="fm-sidebar-title">Activity 2.7</p>
<p class="fm-sidebar-text">Either select an earlier prompt from this chapter or create one of your own and submit it to different LLMs. Note how each responds and compares. Do some of them feel more conversational? How do they handle receiving or sending code examples? Which ones provide the best response in your opinion?</p>
</div>
<h2 class="fm-head" id="heading_id_21">2.6 Creating a library of prompts</h2>
<p class="body">One of the benefits of prompts is that once created, they can be used repeatedly. Consequently, a lot of collections of prompts for different roles and tasks are appearing online. For example, here are a few collections that I’<a id="idTextAnchor002"/>ve seen shared recently:<a id="idIndexMarker056"/><a id="marker-37"/></p>
<ul class="calibre5">
<li class="fm-list-bullet">
<p class="list">Awesome ChatGPT Prompts, GitHub (<a class="url" href="https://github.com/f/awesome-chatgpt-prompts">https://github.com/f/awesome-chatgpt-prompts</a>)</p>
</li>
<li class="fm-list-bullet">
<p class="list">50 ChatGPT Prompts for Developers, Dev.to (<a class="url" href="https://mng.bz/w5D7">https://mng.bz/w5D7</a>)</p>
</li>
<li class="fm-list-bullet">
<p class="list">ChatGPT Cheat Sheet, Hackr.io (<a class="url" href="https://mng.bz/q0PK">https://mng.bz/q0PK</a>)</p>
</li>
</ul>
<p class="body">This list is not at all exhaustive, and the sample collections aren’t necessarily related to testing, but they are worth looking through to learn how others have created prompts, as well as giving us the opportunity to determine which prompts would be effective and which wouldn’t.</p>
<p class="body">Although prompt collections shared publicly can be useful, it’s likely we’ll end up creating prompts that are used for specific contexts. So, it’s worthwhile getting into the habit of storing prompts that prove to be beneficial in some sort of repository for us and others to quickly use. Where you store these will depend on what and who they are used for. If they’re for public use, then sharing a repository of prompts or adding to existing collections might be valuable. If we’re creating and using them while developing company products, then we need to treat them in the same way as our production code and store them somewhere private so that we don’t violate any policies around intellectual property. Finally, we may also consider version control so that we can tweak and track prompts as we learn more about working with LLMs and as the LLMs themselves evolve.</p>
<p class="body">Wherever they are stored, the idea is to create a repository of prompts that are quick and easy to access so that once a prompt has been created for a specific activity, it can be reused multiple times rapidly so that we can get as much value from them to improve our productivity.</p>
<div class="fm-sidebar-block">
<p class="fm-sidebar-title">Activity 2.8</p>
<p class="fm-sidebar-text">Create a space where you can store future prompts for you and your team to use.</p>
</div>
<div class="fm-sidebar-block">
<p class="fm-sidebar-title">Using prompts from this book</p>
<p class="fm-sidebar-text">In the spirit of storing prompts for future use and to help you, the reader, with trying out the prompt examples in this book, you can find each prompt example at <a class="url" href="https://mng.bz/75mx">https://mng.bz/75mx</a>.</p>
<p class="fm-sidebar-text">This will enable you to quickly copy and paste the prompts into your chosen LLM as we go through each chapter, saving you the task of having to type the whole prompt manually. There will be sections in certain prompts where you will need to add your own custom content or context to use them. To make them clear, instructions on what is required to add to the prompt are provided in the prompt and will be formatted in all caps and inside square brackets.</p>
</div>
<h2 class="fm-head" id="heading_id_22">2.7 Solving problems by using prompts</h2>
<p class="body">The tactics and tooling we’ve learned about in this chapter help provide us with a framework to use LLMs and design specific prompts for specific testing activities. We should be mindful, though, that although these tactics improve our chances of getting desired results, they are not foolproof. For example, when we ask an LLM to evaluate its output, the LLM isn’t evaluating its output like a traditional application might. It’s simply moving the predictive needle further toward an output that aligns with our requirements.<a id="marker-38"/><a id="idIndexMarker057"/><a id="idIndexMarker058"/></p>
<div class="fm-sidebar-block">
<p class="fm-sidebar-title">Single prompting vs. multi-prompting</p>
<p class="fm-sidebar-text">Throughout this chapter, we’ve explored how to use principles and tactics to create individual prompts that are as effective as possible at maximizing desired output from an LLM. However, tools such as ChatGPT, Gemini, and Claude allow us to conduct conversations with LLMs, and the history of the conversations influences the output of future responses in said conversation. This raises the question of whether it would be easier to try multiple prompts in a conversation to tweak output. Although this can be effective, we do run the risk that the longer a conversation progresses, the higher the risk of hallucinations occurring as an LLM attempts to overfit responses to our requests. This is why tools such as BingAI are limited in the number of responses they can give in a conversation. However, more importantly, more doesn’t necessarily mean better. The garbage in, garbage out rule is valid for both single and multiple prompts. Relying on multiple prompts in one conversation means we become less clear and precise in what we are asking for, which adds delays and increases hallucination, thus negating the value of using an LLM in the first place. In conclusion, whether we want to send a single prompt to get what we want or send multiple prompts, adopting the principles and tactics created by Isa Fulford and Andrew Ng will increase our productivity with LLMs.<a id="idIndexMarker059"/><a id="idIndexMarker060"/><a id="idIndexMarker061"/><a id="idIndexMarker062"/><a id="idIndexMarker063"/><a id="idIndexMarker064"/><a id="idIndexMarker065"/><a id="idIndexMarker066"/></p>
</div>
<p class="body">Therefore, it is necessary to develop the skills to write prompts that help us solve our problems effectively and in a way that doesn’t diminish the time saved using LLMs (for example, we don’t want to spend hours tweaking prompts). This means being able to identify specific problems that LLMs can help with and then utilizing prompt engineering to maximize the chances of extracting valuable information from an LLM. This is what we’ll explore throughout the rest of this book—when and how to use LLMs.</p>
<p class="body">As we progress, we’ll also learn that prompts come in many shapes and sizes. Throughout this chapter, we’ve looked at prompts that are manually written by us humans. But, as we’ll learn, tools such as GitHub Copilot auto-generate prompts as we write our code. That doesn’t mean we can’t still infuse the principles and tactics into our ways of working, but it does take time, awareness, and practice to develop.<a id="idIndexMarker067"/><a id="marker-39"/></p>
<div class="fm-sidebar-block">
<p class="fm-sidebar-title">Activity 2.9</p>
<p class="fm-sidebar-text">Before you continue reading this book and learn about different types of prompts for different testing activities, use the knowledge from chapters 1 and 2, consider a specific testing task that you do, and try to build a prompt that can help you with your work.</p>
</div>
<h2 class="fm-head" id="heading_id_23">Summary</h2>
<ul class="calibre5">
<li class="fm-list-bullet">
<p class="list">LLMs are trained on vast amounts of data using sophisticated algorithms to analyze our requests and predict an output.</p>
</li>
<li class="fm-list-bullet">
<p class="list">The predictive nature of LLMs makes them quite adaptable but also means they come with some risks.</p>
</li>
<li class="fm-list-bullet">
<p class="list">LLMs can sometimes output <i class="fm-italics">hallucinations,</i> or text that sounds authoritative and correct when, in fact, it is false.</p>
</li>
<li class="fm-list-bullet">
<p class="list">The data that LLMs are trained on may contain errors, gaps, and assumptions, and we must keep this in mind when using them.</p>
</li>
<li class="fm-list-bullet">
<p class="list">We must also be mindful of the data we share with LLMs so as not to cause unauthorized leaks of business or user information.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Prompt engineering is a collection of principles and tactics used to maximize the chances of an LLM returning a desired output.</p>
</li>
<li class="fm-list-bullet">
<p class="list">We can use the knowledge that LLMs are predictive in nature and benefit from it by implementing prompt engineering.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Using delimiters can help us clarify instructions and parameters in a prompt.</p>
</li>
<li class="fm-list-bullet">
<p class="list">An LLM can output data in various formats, but it requires us to explicitly state which structure format we want in a prompt.</p>
</li>
<li class="fm-list-bullet">
<p class="list">We can reduce hallucinations from LLMs by using the check-for-assumption tactic.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Providing examples in a prompt can help ensure that an LLM provides an output in a desired format or context.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Specifying specific subtasks in a prompt can help an LLM process complex tasks successfully.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Asking LLMs to evaluate solutions to problems can also reduce errors and maximize outcomes.</p>
</li>
<li class="fm-list-bullet">
<p class="list">Knowing when to use LLMs and developing skills with prompt engineering is the key to success, regardless of the tool we use.<a id="marker-40"/></p>
</li>
</ul>
</div></body></html>