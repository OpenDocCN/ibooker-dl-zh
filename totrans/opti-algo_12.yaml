- en: 9 Particle swarm optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs: []
  type: TYPE_NORMAL
- en: Introducing swarm intelligence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the continuous particle swarm optimization algorithm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding binary particle swarm optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding permutation-based particle swarm optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adapting particle swarm optimization for a better trade-off between exploration
    and exploitation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solving continuous and discrete problems using particle swarm optimization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the treasure-hunting mission I introduced in chapter 2, suppose you want
    to collaborate and share information with your friends instead of doing the treasure-
    hunting alone. However, you do not want to follow a competitive approach in which
    you only keep better-performing hunters and recruit new hunters to replace poorer-performing
    ones, like in the genetic algorithm (GA) explained in the previous chapters. You
    want to adopt a more cooperative approach and keep all the hunters, without replacing
    any, but you want to give more weight to the better-performing hunters and try
    to emulate their success. This scenario uses *swarm intelligence* and corresponds
    to population-based optimization algorithms such as *particle swarm optimization*
    (PSO), *ant colony optimization* (ACO), and *artificial bee colony* (ABC) algorithms,
    which will be explained in this fourth part of the book.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll focus on different variants of PSO algorithms and apply
    them to solve continuous and discrete optimization problems. These variants include
    continuous PSO, binary PSO, permutation-based PSO, and adaptive PSO. Function
    optimization, the traveling salesman problem, neural network training, trilateration,
    coffee shop planning, and the doctor scheduling problem are discussed in this
    chapter and its supplementary exercises included in appendix C. The next chapter
    will cover the ACO and ABC algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 9.1 Introducing swarm intelligence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Life on this planet is full of astonishing examples of collective behavior.
    Individual species depend upon one another for sustenance, often forming surprising
    alliances to achieve a common goal: the continuance of the species. The majority
    of living things also display amazing altruism in order to protect and provide
    the best care for their offspring, comparable to any form of sacrifice shown by
    human beings. They can cooperatively perform complex tasks such as foraging for
    food, dividing up labor, constructing nests, brood sorting, protecting, herding,
    schooling, and flocking, to name just a few. These complex collective behaviors
    emerge from individual interactions between spatially distributed and simple entities
    without a centralized controller or coordinator and without a script or access
    to global information. Various cooperation patterns, communication mechanisms,
    and adaptation strategies are employed to enable such complex collective behaviors.'
  prefs: []
  type: TYPE_NORMAL
- en: Swarm intelligence
  prefs: []
  type: TYPE_NORMAL
- en: Swarm intelligence is a subfield of artificial intelligence that explores how
    large groups of relatively simple and spatially distributed agents can interact
    with each other and with their environment in a decentralized and self-organized
    manner to collectively achieve complex goals.
  prefs: []
  type: TYPE_NORMAL
- en: Several efficient population-based algorithms have been designed to exploit
    the power of collective intelligence by mimicking the collective behaviors observed
    in nature to solve complex optimization problems. Table 9.1 provides a non-exhaustive
    list of swarm intelligence algorithms and their sources of inspiration from unicellular
    and multicellular living organisms.
  prefs: []
  type: TYPE_NORMAL
- en: Table 9.1 Examples of swarm intelligence algorithms and their sources of inspiration
  prefs: []
  type: TYPE_NORMAL
- en: '| Organisms | Class | Source of inspiration | Algorithms |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Unicellular organisms | Bacteria | Bacterial swarm foraging | Bacterial foraging
    optimization algorithm (BFO)Bacterial swarming algorithm (BSA) |'
  prefs: []
  type: TYPE_TB
- en: '| Multicellular organisms | Bird/fish | Bird flocking and fish schooling |
    Particle swarm optimization (PSO) |'
  prefs: []
  type: TYPE_TB
- en: '| Ant | Ant foraging behaviors | Ant colony optimization (ACO) |'
  prefs: []
  type: TYPE_TB
- en: '| Bees | Foraging behavior of honeybees | Artificial bee colony (ABC) |'
  prefs: []
  type: TYPE_TB
- en: '| Bats | Echolocation behavior of bats | Bat algorithm (BA) |'
  prefs: []
  type: TYPE_TB
- en: '| Fireflies | Flashing behavior of fireflies | Firefly algorithm (FA) |'
  prefs: []
  type: TYPE_TB
- en: '| Butterflies | Foraging behavior of butterflies | Butterfly optimization algorithm
    (BOA) |'
  prefs: []
  type: TYPE_TB
- en: '| Dragonflies | Static and dynamic swarming behaviors of dragonflies | Dragonfly
    algorithm (DA) |'
  prefs: []
  type: TYPE_TB
- en: '| Spiders | Cooperative behavior of the social spiders | Social spider optimization
    (SSO) |'
  prefs: []
  type: TYPE_TB
- en: '| Krill | Herding behavior of krill | Krill herd (KH) |'
  prefs: []
  type: TYPE_TB
- en: '| Frogs | Frog cooperative search for food | Shuffled frog leaping algorithm
    (SFLA) |'
  prefs: []
  type: TYPE_TB
- en: '| Fish | Gregarious behavior of fish | Fish school search (FSS) |'
  prefs: []
  type: TYPE_TB
- en: '| Dolphins | Dolphins’ behavior in detecting, chasing after, and preying on
    swarms of sardines | Dolphin partner optimization (DPO)Dolphin swarm optimization
    algorithm (DSOA) |'
  prefs: []
  type: TYPE_TB
- en: '| Cats | Resting and tracing behaviors of cats | Cat swarm optimization (CSO)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Monkeys | Search for food | Monkey search algorithm (MSA) |'
  prefs: []
  type: TYPE_TB
- en: '| Lions | Solitary and cooperative behaviors of lions | Lion optimization algorithm
    (LOA) |'
  prefs: []
  type: TYPE_TB
- en: '| Cuckoos | Reproduction strategy of cuckoos | Cuckoo search (CS)Cuckoo optimization
    algorithm (COA) |'
  prefs: []
  type: TYPE_TB
- en: '| Wolves | Leadership hierarchy and hunting mechanism of gray wolves | Wolf
    search algorithm (WSA)Grey wolf optimizer (GWO) |'
  prefs: []
  type: TYPE_TB
- en: For example, bacteria, which are single-celled organisms, possess underlying
    social intelligence allowing them to cooperate to solve challenges. Bacteria develop
    intricate communication capabilities like chemotactic signaling to cooperatively
    self-organize into highly structured colonies with elevated environmental adaptability.
    Bacterial chemotaxis is the process by which bacterial cells migrate through concentration
    gradients of chemical attractants and repellents. The E. coli bacterium uses this
    bacterial chemotaxis during the foraging process. This collective behavior provides
    the basis for optimization algorithms such as the bacterial foraging optimization
    algorithm (BFO) and bacterial swarming algorithm (BSA).
  prefs: []
  type: TYPE_NORMAL
- en: 'Ethology, the study of animal behavior, is the main source of inspiration for
    swarm intelligence algorithms such as particle swarm optimization (PSO), ant colony
    optimization (ACO), artificial bee colony (ABC), bat algorithm (BA), firefly algorithm
    (FA), and social spider optimization (SSO). For example, honeybees are highly
    cooperative social insects that cooperatively construct hives in which about 30,000
    bees can live and work together. They differentiate their work: some make wax,
    some make honey, some make bee-bread, some shape and mold combs, and some bring
    water to the cells and mingle it with the honey. Young bees engage in out-of-door
    work while the elder bees do the indoor work. During the foraging process, rather
    than expending energy searching in all directions, honeybee colonies use individual
    foragers to reduce the cost/ benefit ratio. Additionally, colonies concentrate
    their foraging efforts on the most lucrative patches and disregard those of lesser
    quality. It has been observed that when a colony’s food resources are scarce,
    foragers recruit more nestmates to food sources they have found, and changes in
    their dance patterns upon returning to the hive facilitate this increased recruitment.'
  prefs: []
  type: TYPE_NORMAL
- en: The fundamental components of swarm intelligence algorithms typically involve
    numerous decentralized processing agents that operate without central supervision.
    These agents communicate with neighboring agents and adapt their behavior based
    on received information. Furthermore, the majority of the research carried out
    on swarm intelligence algorithms is primarily based on experimental observations
    of collective behavior exhibited by living organisms. These observations are translated
    into models, which are then tested through simulations in order to derive the
    metaheuristics that form the basis of swarm intelligence algorithms, as illustrated
    in figure 9.1\. This experimental approach enables researchers to gain a deeper
    understanding of the complex interactions between individual agents and how they
    give rise to collective behavior. By simulating these interactions and testing
    various scenarios, researchers can refine the algorithms and improve their effectiveness.
    As an example of such experimental research, you can watch the “The Waggle Dance
    of the Honeybee” video of the experiment conducted by Georgia Tech College of
    Computing to understand how honeybees communicate the location of new food sources
    (www.youtube.com/watch?v=bFDGPgXtK-U).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F01_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 Derivation process for swarm intelligence algorithms
  prefs: []
  type: TYPE_NORMAL
- en: 'Algorithm 9.1 shows the common steps in a swarm intelligence algorithm. The
    algorithm starts by initializing the algorithm parameters, such as the number
    of individuals in the swarm, the maximum number of iterations, and the termination
    criteria. A swarm of initial candidate solutions is then sampled (the different
    sampling methods were explained in section 7.1). The algorithm then iterates over
    all the individuals in the swarm, performing the following operations: finding
    the best so far, finding the best neighbor, and updating the individual.'
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 9.1 Swarm intelligence algorithm
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The individual and the neighbor are evaluated using the defined objective/fitness
    function. The neighborhood structure and update mechanism depend on the algorithm
    being used. This loop over all the individuals is repeated until the termination
    criterion is met, which could be a maximum number of iterations or reaching a
    satisfactory fitness level. At this point, the algorithm stops and returns the
    best solution found during the optimization process. In the following sections,
    we’ll dive deep into the PSO algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2 Continuous PSO
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Particle swarm optimization (PSO) is a population-based stochastic optimization
    technique developed by Russell Eberhart and James Kennedy in 1995\. Since then,
    PSO has gained popularity and has been applied to various real-world applications
    in different domains. This algorithm is inspired by the conduct of social organisms
    such as birds, fish, ants, termites, wasps, and bees. PSO emulates the actions
    of these creatures, with each member of the swarm being referred to as a *particle*,
    akin to a bird in a flock, a fish in a school, or a bee in a colony. Eberhart
    and Kennedy opted to use the term “particle” to refer to an individual or candidate
    solution in the context of optimization, as they believed it was more suitable
    for describing the particle’s velocity and acceleration.
  prefs: []
  type: TYPE_NORMAL
- en: Bird flocking
  prefs: []
  type: TYPE_NORMAL
- en: 'Bird flocking is a behavior controlled by three simple rules, as illustrated
    in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Separation*—Prevent getting too close to nearby birds to avoid overcrowding.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Alignment*—Adjust the heading to correspond to the average direction of neighboring
    birds.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Coherence*—Move toward the average position of neighboring birds.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F01_UN01_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Bird flocking rules: separation, alignment, and coherence'
  prefs: []
  type: TYPE_NORMAL
- en: When birds—spatially distributed agents interacting with each other and with
    their environment in a decentralized and self-organized manner without access
    to global information—apply these three simple rules, the outcome is the emergent
    behavior of bird flocking.
  prefs: []
  type: TYPE_NORMAL
- en: 'The particles (candidate solutions) move, or fly, through the feasible search
    space by following the current best particles. Thus, PSO is guided by a straightforward
    principle: emulate the success of neighboring individuals. Each particle in the
    swarm operates in a decentralized manner by utilizing both its own intelligence
    and the collective intelligence of the group. Therefore, if one particle uncovers
    a favorable route to food, the remaining members of the swarm can immediately
    adopt the same path.'
  prefs: []
  type: TYPE_NORMAL
- en: The PSO algorithm
  prefs: []
  type: TYPE_NORMAL
- en: “This [PSO] algorithm belongs ideologically to that philosophical school that
    allows wisdom to emerge rather than trying to impose it, that emulates nature
    rather than trying to control it, and that seeks to make things simpler rather
    than more complex.” J. Kennedy and R. Eberhart, inventors of PSO [1].
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.2 shows the PSO flowchart. We start by initializing the algorithm parameters
    and creating an initial swarm of particles. These particles represent the candidate
    solutions. Each particle in the search space holds the current position *x^i*
    and current velocity *v^i*. The fitness of each particle is then evaluated based
    on the fitness/objective function to be optimized. The best position each particle
    has achieved so far is known as the personal best or *pbest*. The best position
    achieved by the particles in its neighborhood is known as *nbest*. If the neighborhood
    is restricted to a few particles, the best is called the local best, *lbest*.
    If the neighborhood is the whole swarm, the best achieved by the whole swarm is
    called the global best, *gbest*. We’ll discuss neighborhood structures in PSO
    further in section 9.2.3.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F02_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 The PSO algorithm
  prefs: []
  type: TYPE_NORMAL
- en: After evaluating the fitness of each particle, PSO updates each particle’s personal
    best position if the current fitness is superior, identifies the global best position
    based on the best fitness in the entire swarm, and adjusts particle velocities
    and positions using a combination of personal and global information. These steps
    guide the swarm toward optimal or near-optimal solutions by balancing individual
    and collective learning, promoting exploration and exploitation in the search
    space. The process iterates until termination criteria are met.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.1 Motion equations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The velocity (*v*) and position (*x*) of each particle are updated using the
    following equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F02_Khamis-EQ01.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 9.1 |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F02_Khamis-EQ02.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 9.2 |'
  prefs: []
  type: TYPE_TB
- en: where
  prefs: []
  type: TYPE_NORMAL
- en: '*k* is the iteration number.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*i* and *d* are the particle number and the dimension. For example, dimension
    = 1 in the case of a univariate optimization problem with a single decision variable,
    dimension = 2 in the case of a bivariate problem, etc.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ω* is the inertia weight.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*c*1, *c*2 are the acceleration coefficients.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*r*1, *r*2 are random numbers between 0 and 1 and are generated in each iteration
    for each dimension, and not for each particle.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*pbest* is the best position achieved by the particle.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*gbest* is the best position achieved by the whole swarm. *gbest* should be
    replaced by *nbest or lbest* if you are dividing the swarm into multiple neighborhoods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see in these two equations, we start by updating the velocity *v*[(]*[k]*
    [+ 1)]*^(id)*. The position is then updated to *x*[(]*[k]* [+ 1)]*^(id)* by taking
    the current position *x[k]^(id)* and adding to it the new displacement *v*[(]*[k]*
    [+ 1)]*^(id)* × *timestamp* where *timestamp* = 1, which represents a single iteration.
  prefs: []
  type: TYPE_NORMAL
- en: 'To understand these motion update equations, let’s visualize these equations
    using vectors in the 2D Cartesian coordinate system, as shown in figure 9.3\.
    As you can see, the velocity update equation consists of three primary components,
    each contributing to the movement of particles in the search space:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Inertia component*—The first part of the velocity update equation represents
    the influence of a particle’s inertia, taking into account that a particle (like
    a fish in a school or a bird in a flock) cannot abruptly change its direction.
    As you will see later, this inertia component is crucial, as it allows the algorithm
    to be more adaptive and helps maintain a balance between exploration and exploitation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Cognitive component*—The second part of the equation, referred to as the cognitive
    component, represents the particle’s attraction toward its personal best position,
    or individual proximity (*i*-proximity). This component reflects the degree of
    trust a particle places in its own past experiences, without considering the experiences
    of its neighbors or the swarm as a whole. The cognitive component encourages particles
    to explore the areas around their personal best positions, allowing them to fine-tune
    their search in promising regions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Social component*—The third part of the velocity update equation is the social
    component, which represents the particle’s attraction to the swarm’s collective
    knowledge or group proximity (*g*-proximity). This component takes into account
    the experiences of neighboring particles and the swarm as a whole, guiding the
    particles toward the global best position found so far. The social component fosters
    collaboration among particles, helping them converge toward an optimal solution
    more effectively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F03_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 Visualizing the motion equation for a particle in the swarm
  prefs: []
  type: TYPE_NORMAL
- en: To better understand the meaning of each component, imagine a group of friends
    visiting a large amusement park for the first time. Their goal is to visit the
    most thrilling rides in the park as efficiently as possible. The friends can be
    thought of as particles in the PSO algorithm, with each person’s enjoyment of
    the rides serving as the objective function to optimize. Each person has a preferred
    way of exploring the available rides, like walking through certain parts of the
    park or trying specific rides like roller coasters or water slides. This is similar
    to the inertia component in PSO, where particles maintain their current velocity
    and direction, ensuring they don’t change their exploration pattern too abruptly.
  prefs: []
  type: TYPE_NORMAL
- en: Each friend relies on their own personal experiences to find the most thrilling
    rides. For instance, one friend might have had a great time on a roller coaster
    earlier in the day. They’re more likely to return to their favorite one or want
    to find more similar rides, knowing it was a good choice. They trust their judgment
    and focus on exploring the areas around the roller coaster, seeking out rides
    that they think they’ll enjoy based on their personal experience. This is the
    cognitive component, where particles in PSO are attracted to their personal best
    positions, following their past experiences and individual preferences.
  prefs: []
  type: TYPE_NORMAL
- en: The friends then collaborate to find the most thrilling ride based on their
    shared experiences. Imagine one of the friends has just ridden the most exciting
    roller coaster and can’t wait to tell the others about it. As they share their
    excitement, the group collectively becomes more attracted to that ride, influencing
    their individual choices. This is the social component, where particles in PSO
    are influenced by the global best position or the collective knowledge of the
    swarm.
  prefs: []
  type: TYPE_NORMAL
- en: The following subsections dive into more detail about the different PSO parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.2 Fitness update
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'After moving, each particle updates its own personal best using the following
    equation, assuming a minimization problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F03_Khamis-EQ03.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 9.3 |'
  prefs: []
  type: TYPE_TB
- en: 'After that, each neighborhood updates its best as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F03_Khamis-EQ04.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 9.4 |'
  prefs: []
  type: TYPE_TB
- en: The neighborhood best (*nbest*) is the same as the global best (*gbest*) if
    the neighborhood is the whole swarm.
  prefs: []
  type: TYPE_NORMAL
- en: 'PSO has two main variants based on how particles’ positions and velocities
    are updated—synchronous and asynchronous PSO:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Synchronous PSO (S-PSO)*—All particles in the swarm update their positions
    and velocities simultaneously in a global manner. The local and global best are
    then updated. This synchronous approach ensures that all particles have access
    to the same global best position when updating their velocities and positions,
    promoting global exploration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Asynchronous PSO (A-PSO)*—Particles are updated based on the current state
    of the swarm. This asynchronous approach allows the particles to update their
    positions and velocities based on the most recent information available.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figure 9.4 shows the difference between S-PSO and A-PSO. As you’ll notice, in
    A-PSO, the neighborhood best update is moved into the particle’s update loop.
    This allows particles to evaluate their fitness and update their positions and
    velocities independently and asynchronously.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F04_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 Synchronous and asynchronous PSO
  prefs: []
  type: TYPE_NORMAL
- en: Although both synchronous and asynchronous PSO strategies can be employed to
    handle optimization problems, the asynchronous version is generally more effective,
    as it allows particles to take advantage of the most recent neighbor information.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.3 Initialization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'PSO initialization includes initializing the particle position, velocity, and
    personal best, and initializing the algorithm’s parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Particle position initialization*—Particle positions represent candidate solutions
    to the problem, and they can be sampled using different sampling methods, as explained
    in section 7.1\. For example, the initial positions of the particles can be randomly
    assigned within the defined feasible search space.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Particle velocity initialization*—The velocities of the particles can be set
    to zero or small values initially. Initializing them with small velocities ensures
    that the particles’ updates are gradual, preventing them from moving too far away
    from their starting positions. In contrast, large initial velocities may lead
    to significant updates, which can potentially cause divergence and hinder the
    convergence of the algorithm.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Personal best position initialization*—The personal best position of each
    particle, which represents the best solution found by the particle so far, should
    be initialized to its initial position. This allows the particles to begin their
    search with their starting points as a reference and to update their personal
    bests as they discover better solutions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As shown in equation 9.1, PSO has three primary parameters that play a critical
    role in controlling the search algorithm’s behavior: the inertia weight (*ω*)
    and the acceleration coefficients (*c*1, *c*2). These parameters influence the
    balance between exploration and exploitation within the optimization process:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Inertia weight*—Large values of *ω* encourage exploration, while small values
    promote exploitation, allowing the cognitive and social components to exert greater
    control. A widely adopted value for *ω* is 0.792.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Acceleration coefficients*—Setting *c*1 to 0 reduces the PSO algorithm to
    a *social-only* or *selfless PSO* model. In this case, particles are solely attracted
    to the group best and ignore their personal bests. This leads to an emphasis on
    global exploration based on the swarm’s collective knowledge. Setting *c*2 to
    0 results in a *cognition-only model*, where particles act as independent hill
    climbers, relying only on their personal bests. In this scenario, the particles
    do not consider the experiences of other swarm members, focusing on local exploitation
    based on their individual experiences. In many applications, *c*1 and *c*2 are
    set to 1.49\. Although there is no theoretical justification for this specific
    value, it has been empirically found to work well in various optimization problems.
    Generally, the sum of *c*1 and *c*2 should be less than or equal to 4 to maintain
    the algorithm’s stability and convergence properties.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Other parameters to consider include swarm size and neighborhood size. There
    is no one-size-fits-all solution, as the optimal values depend on the specific
    problem being solved. However, some best practices and guidelines can help inform
    your choices:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Swarm size*—A large swarm size can promote global exploration and prevent
    premature convergence, but at the cost of increased computational effort. A small
    swarm size can lead to faster convergence and reduced computational effort but
    may increase the risk of premature convergence. For many problems, a swarm size
    between 20 and 100 particles has been found to yield good results. It is advisable
    to conduct experiments with different swarm sizes to determine the best trade-off
    between exploration, exploitation, and computational complexity for the problem
    at hand.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Neighborhood size*—A large neighborhood size can encourage global exploration
    and information sharing among particles but may reduce the ability to exploit
    local optima. A small neighborhood size can promote local exploitation and convergence
    speed but may limit global exploration. You can use different neighborhood structures,
    as you’ll see in the next subsection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generally speaking, selecting the best algorithm parameters requires experimentation
    and fine-tuning based on the specific problem you are trying to solve. It is often
    beneficial to perform a sensitivity analysis or use a parameter-tuning technique
    to find the optimal parameter values for your problem. We’ll look at this in more
    detail in section 9.5.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.4 Neighborhoods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the PSO algorithm, particles within a specific vicinity engage in mutual
    communication by sharing details about each other’s success within that local
    region. Subsequently, all particles gravitate toward a position that is considered
    to be an improvement based on a key performance indicator. The efficacy of the
    PSO algorithm is heavily reliant on the social network structure it employs. Choosing
    an appropriate neighborhood topology plays a crucial role in ensuring the algorithm’s
    convergence and in preventing it from becoming trapped in local minima.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the prevalent neighborhood topologies utilized in PSO include the star
    social structure, the ring topology, the Von Neumann model, and the wheel topology:'
  prefs: []
  type: TYPE_NORMAL
- en: '*The star social structure, also known as the global best (gbest) PSO*—This
    is a neighborhood topology where all particles are connected, as shown in figure
    9.5a. This structure allows access to global information within the swarm, with
    the result that each particle is drawn toward the optimal solution discovered
    by the entire swarm. The *gbest* PSO has been demonstrated to converge more rapidly
    than other network structures. However, it is more prone to becoming ensnared
    in local minima without fully exploring the search space. This topology excels
    when applied to unimodal problems, as it allows for efficient and effective optimization
    in such cases.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Ring topology, also known as the local best (lbest) PSO*—Following this topology,
    a particle interacts exclusively with its immediately adjacent neighbors (figure
    9.5b). Each particle endeavors to emulate its most successful neighbor by gravitating
    toward the optimal solution discovered within the local vicinity. Although convergence
    occurs at a slower pace than with the star structure, the ring topology explores
    a more extensive portion of the search space. This topology is recommended for
    multimodal problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Von Neumann model*—In this topology, particles are arranged in a grid-like
    structure or square topology where each particle is connected with four other
    particles (the neighbors above, below, and to the right and left), as shown in
    figure 9.5c.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Wheel topology*—In this topology, the particles are isolated from each other,
    and one particle is randomly selected as the focal point or hub for all information
    flow, as illustrated in figure 9.5d.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The choice of neighborhood topology depends on the problem’s characteristics
    and the desired balance between exploration and exploitation. Experiment with
    different topologies to find the best fit for your problem.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F05_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.5 PSO neighborhood topologies: a) the star social structure, b) the
    ring topology, c) the Von Neumann model, and d) the wheel topology'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now look at how to solve a continuous optimization problem using PSO.
    The Michalewicz function is a nonconvex mathematical function commonly used as
    a test problem for optimization algorithms. This function is given by the following
    formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F05_Khamis-EQ05.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 9.5 |'
  prefs: []
  type: TYPE_TB
- en: where *d* is the dimension of the problem and *m* is a constant (usually *m*
    = 10). This function has *d* local minima. For *d* = 2, the minimum value is –1.8013
    at (2.20, 1.57).
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by defining the Michalewicz function as shown in listing 9.1\. This
    function can accept size-1 arrays with single or multiple rows. If the input position
    is a size-1 array with a single row, we reshape it to a 2D array with a single
    row using the `reshape()` function. A *size-1 array*, also known as a *singleton
    array*, is an array data structure that contains only one element. This reshaping
    enables uniform handling of both single-row size-1 arrays and arrays with multiple
    rows. This is evident in the implementation of the PSO solver, where the function
    addresses solving one solution at a time. Additionally, the function seamlessly
    manages arrays with multiple rows, a scenario encountered when simultaneously
    evaluating multiple solutions. This aspect will be further elaborated upon later
    in the context of pymoo and PySwarms solvers.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.1 Solving the Michalewicz function using PSO
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: ① Reshape to a 2D array with a single row if the position is a size-1 array.
  prefs: []
  type: TYPE_NORMAL
- en: ② The Michalewicz formula
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now create a PSO solver from scratch. As a continuation of listing 9.1,
    we’ll start by defining a particle class with position, velocity, and personal
    best value as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The fitness function to be minimized is the Michalewicz function in this example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now define the velocity update function following equation 9.1\. The
    function takes three arguments—`particle`, which is an object representing the
    current particle; `gbest_position`, which is the global best position found by
    the swarm so far; and `options`, which is a dictionary containing the algorithm
    parameters (specifically, the inertia weight `w` and the cognitive and social
    acceleration coefficients `c1` and `c2`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The function computes the three components of the new velocity: the inertia
    component, the cognitive component, and the social component, as per equation
    9.1\. It returns the updated velocity as the sum of the three components.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now define the PSO solver function. This function takes four parameters
    as inputs—`swarm_size`, which is the size of the particle swarm; `iterations`,
    which is the maximum number of iterations to run the algorithm for; `bounds`,
    which is a list of tuples defining the lower and upper bounds of the search space
    for each dimension of the input vector; and `options`, which is a dictionary containing
    the algorithm parameters (such as the inertia weight and cognitive and social
    acceleration coefficients):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: ① Initialize a random swarm.
  prefs: []
  type: TYPE_NORMAL
- en: ② Initialize the global best.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Update the velocity and position.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Apply the bounds.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Update the personal best (pbest).
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Update the global best (gbest).
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Update the position.
  prefs: []
  type: TYPE_NORMAL
- en: ⑧ Return the global best position and corresponding value.
  prefs: []
  type: TYPE_NORMAL
- en: The function first initializes the particle swarm by randomly generating the
    initial positions and velocities for each particle within the bounds defined by
    `bounds`. It then evaluates the fitness function for each particle and updates
    its personal best position and value accordingly. The function then enters a loop,
    where it updates the velocity and position of each particle using the `update_velocity`
    function, which takes the global best position found so far as input. The function
    also applies bounds to the particle position and updates its personal best position
    and value. The function then updates the global best position and value based
    on the star topology. Other topologies, such as ring, Von Neumann, and wheel,
    can be found in the complete code of listing 9.1, available in the book’s GitHub
    repository. Finally, the function returns the global best position and value found
    by the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now use this PSO solver to minimize the Michalewicz function after we
    set up the problem and algorithm parameters as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: ① PSO parameters
  prefs: []
  type: TYPE_NORMAL
- en: ② Dimension and domain of the Michalewicz function for each variable
  prefs: []
  type: TYPE_NORMAL
- en: ③ Use the implemented PSO solver to solve the problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can print the optimal solution and minimum value of the function after
    running PSO:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The output would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Compared to genetic algorithms, there are fewer Python libraries available
    for PSO. Pymoo provides a PSO implementation for continuous problems. As a continuation
    of listing 9.1, pymoo PSO can be used to solve the same problem as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: ① Define the problem.
  prefs: []
  type: TYPE_NORMAL
- en: ② The 2D Michalewicz function
  prefs: []
  type: TYPE_NORMAL
- en: ③ Set the lower and upper bounds.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Evaluate the objective function.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Create a problem instance.
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Define the solver with the parameters.
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Apply PSO to solve the problem.
  prefs: []
  type: TYPE_NORMAL
- en: ⑧ Print the optimal solution and minimum value of the function after running
    PSO.
  prefs: []
  type: TYPE_NORMAL
- en: 'This code produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'PySwarms is another open source optimization library for Python that implements
    different variants of PSO. PySwarms can be used as follows to handle the problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: ① Import the PSO solver from pyswarms.
  prefs: []
  type: TYPE_NORMAL
- en: ② Dimension of the Michalewicz function
  prefs: []
  type: TYPE_NORMAL
- en: ③ Create bounds for the search space.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Set up the optimizer.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Create an instance of the optimizer.
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Optimize the Michalewicz function
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Print the optimal solution and minimum value of the function after running
    PSO.
  prefs: []
  type: TYPE_NORMAL
- en: 'This code produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The pyswarms.single package implements various techniques in continuous single-
    objective optimization. From this module, we used the global-best PSO (*gbest*
    PSO) algorithm in the previous code. You can experiment by replacing this solver
    with local-best.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.6 shows the 3D landscape and 2D contours of the Michalewicz function,
    the optimal solution, and the solutions obtained by PSO, PSO Pymoo, and PSO PySwarms.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F06_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.6 3D and 2D plots of the Michalewicz function. The three solutions
    are all very close to the optimal solution.
  prefs: []
  type: TYPE_NORMAL
- en: The three versions of PSO provide comparable results. However, PSO PySwarms
    and PSO pymoo are more stable, as they provide more consistent results each time
    you run the code. The PySwarms library is more comprehensive than pymoo for PSO,
    as it provides implementations of different variants and topologies of PSO, including
    discrete PSO, which will be explained in the next two sections.
  prefs: []
  type: TYPE_NORMAL
- en: 9.3 Binary PSO
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: PSO was originally developed for problems that involve continuous-valued variables.
    However, many real-world problems are discrete or combinatorial in nature, such
    as TSP, task allocation, scheduling, assignment problems, and feature selection,
    among others. These types of problems involve searching through a finite set of
    possible solutions, rather than searching through a continuous space. To handle
    these discrete problems, PSO variants have been developed, such as binary PSO
    and permutation-based PSO.
  prefs: []
  type: TYPE_NORMAL
- en: In *binary PSO* (BPSO), each particle represents a position in the binary space,
    where each element is either 0 or 1\. The binary sequence is updated bit by bit
    based on its current value, the fitness-based value of that particular bit within
    the particle, and the best value of the same bit observed so far among its neighboring
    particles. This approach enables the search to be conducted in a binary space
    rather than a continuous space, which is well suited for problems where the variables
    are binary.
  prefs: []
  type: TYPE_NORMAL
- en: 'In BPSO, the velocity is defined in terms of the probability of the bit changing.
    To restrict the values of the velocity elements to the range of [0,1], the sigmoid
    function is used:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F06_Khamis-EQ06.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 9.6 |'
  prefs: []
  type: TYPE_TB
- en: The position update equation then becomes
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F06_Khamis-EQ07.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 9.7 |'
  prefs: []
  type: TYPE_TB
- en: where *r* is a randomly generated number in [0, 1]. Figure 9.7 shows the sigmoid
    function and the probability of the updated position to be 1\. For example, if
    *v* = 0.3, this means that the probability that the updated position will be 1
    is 30%, and the probability that it will be 0 is 70%.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F07_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.7 Position and velocity notations in binary PSO (BPSO). Each particle
    represents a position in the binary space. Velocity is defined in terms of the
    probability of the bit changing.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you’ll notice, the velocity components will remain as real-valued numbers
    using the original equation, but these values are then passed through the sigmoid
    function before updating the position vector. The following equations are the
    velocity update equations in BPSO:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F07_Khamis-EQ08.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 9.8 |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F07_Khamis-EQ09.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 9.9 |'
  prefs: []
  type: TYPE_TB
- en: 'The positions are updated according to the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F07_Khamis-EQ10.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 9.10 |'
  prefs: []
  type: TYPE_TB
- en: where
  prefs: []
  type: TYPE_NORMAL
- en: '*ϕ*[1] and *ϕ*[2] represent different random numbers drawn from uniform distributions.
    Sometimes these parameters are chosen from a uniform distribution 0–2, such that
    the sum of their two limits is 4.0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*v^i^d[k]* [+1] is the probability that an individual *i* will choose 1 for
    the bit at the *d^(th)* site in the bit string.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*x[k]^(id)* is the current state of string *i* at bit *d*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*v[k]^(id)* is a measure of the string’s current probability to choose 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*pbest[k]^(id)* is the best state found so far for bit *d* of individual *i*
    (i.e., a 1 or a 0).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*gbest[k]^d* is 1 or 0 depending on what the value of bit *d* is in the best
    neighbor to date.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: BPSO example
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate how BPSO works, suppose we have a population of five binary particles,
    where each particle consists of 6 bits. Let’s assume the particles are represented
    by the following binary strings: 101101, 110001, 011110, 100010, and 001011\.
    We want to update particle 4 (represented by the binary string 100010) at bit
    3 (which has a current value of 0). The current propensity (velocity) of this
    bit to be 1 is assumed to be 0.23\. Additionally, we assume that the best value
    of this particle found so far is 101110, while the best value found by the entire
    population is 101111\. Let’s also assume that ϕ[1] = 1.5 and ϕ[2] = 1.9. Using
    equations 9.8 and 9.9, we can get the updated velocity of bit 3 in particle 4
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Particle 4: 100010, *v[k]*^(43) = 0.23, *x[k]*^(43) = 0, *pbest[k]*^(43) =
    1, *gbest[k]*³ = 1, ϕ[1] = 1.5, ϕ[2] = 1.9'
  prefs: []
  type: TYPE_NORMAL
- en: '*v[k]* [+ 1]^(43) = 0.23 + 1.5(1–0) + 1.9(1–0) = 3.63'
  prefs: []
  type: TYPE_NORMAL
- en: '*sig*(*v[k]* [+ 1]^(43)) = *sig*(3.63) = 1/(1 + *e*^(–3.63)) = 0.974'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate a random number *r*^(43) = 0.6, and update the position using equation
    9.10 as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*x[k]* [+ 1]^(43) = 1 as *sig*(*v[k]* [+ 1]^(43)) > *r*^(43)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Updated particle 4: 100110'
  prefs: []
  type: TYPE_NORMAL
- en: For more information about BPSO, see Kennedy and Eberhart’s article “A discrete
    binary version of the particle swarm algorithm” [2].
  prefs: []
  type: TYPE_NORMAL
- en: 9.4 Permutation-based PSO
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Numerous efforts have been undertaken to employ PSO in solving permutation problems.
    The challenge of adapting PSO to tackle these problems arises from the fact that
    the notions of velocity and direction are not inherently applicable to permutation
    problems. To overcome this obstacle, arithmetic operations like addition and multiplication
    need to be redefined.
  prefs: []
  type: TYPE_NORMAL
- en: 'In M. Clerc’s 2004 article, “Discrete particle swarm optimization, illustrated
    by the traveling salesman problem” [3], PSO was applied to solve the TSP. The
    position of a particle was the solution to a problem (the permutation of cities).
    The velocity of a particle was defined as the set of swaps to be performed on
    a particle. As you have seen, the right side of equation 9.1 contains three arithmetic
    operations: multiplication, subtraction, and addition. These operations are redefined
    for the new search space as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Multiplication*—The velocity vector constrains a number of swaps between cities.
    Multiplying this vector by a constant *c*, results in another velocity vector
    with a different length, depending on the value of the constant. If *c* = 0, the
    length of the velocity vector (i.e., the included number of swaps) is set to 0\.
    This means that no swap will be performed. If *c* < 1, the velocity is truncated.
    If *c* > 1, the velocity is augmented as illustrated in figure 9.8\. Augmentation
    means adding a swap taken from the top of the current velocity vector to the end
    of the new velocity vector.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F08_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.8 Redefined multiplication for permutation-based PSO
  prefs: []
  type: TYPE_NORMAL
- en: '*Subtraction*—Subtracting two positions should produce a velocity. This operation
    produces the sequence of swaps that could transform one position to the other.
    For example, let’s consider an 8-city TSP. A candidate solution for this TSP is
    represented by a permutation such as [2, 4, 6, 1, 5, 3, 8, 7]. Figure 9.9 shows
    how a new velocity vector is produced by subtracting two positions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F09_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.9 Redefined subtraction operation for permutation-based PSO
  prefs: []
  type: TYPE_NORMAL
- en: '*Addition*—The operation is performed by applying the sequence of swaps defined
    by the velocity to the position vector. Figure 9.10 shows how a new position (i.e.,
    a new candidate solution) is generated by adding the velocity swap vector to the
    current position.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F10_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.10 Redefined addition operation for permutation-based PSO
  prefs: []
  type: TYPE_NORMAL
- en: These redefined arithmetic operations allow us to update the velocity and position
    of PSO particles.
  prefs: []
  type: TYPE_NORMAL
- en: 9.5 Adaptive PSO
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The inertia, cognitive, and social components are the primary PSO parameters
    that can be used to achieve an equilibrium between exploration and exploitation
    during the optimization process. These three factors significantly influence the
    behavior of the algorithm, as discussed in the following subsections.
  prefs: []
  type: TYPE_NORMAL
- en: 9.5.1 Inertia weight
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The inertia parameter represents the tendency of a particle to maintain its
    current trajectory. By adjusting the inertia value, the algorithm can balance
    its focus on searching the solution space broadly (exploration) or homing in on
    the best solutions found thus far (exploitation). Large values of *ω* promote
    exploration, and small values promote exploitation, as illustrated in figure 9.11\.
    Excessively small values may hinder the swarm’s exploration capabilities. As the
    value of *ω* decreases, the influence of the cognitive and social components on
    position updates becomes more dominant.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F11_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.11 Effect of PSO parameters on the search behavior. Large inertia promotes
    exploration, and small values promote exploitation. *c*1 > *c*2 results in excessive
    wandering of individuals through the search space. In contrast, *c*2 > *c*1 may
    lead particles to rush prematurely toward a local optimum.
  prefs: []
  type: TYPE_NORMAL
- en: When *ω* > 1, particle velocities tend to escalate over time, accelerating toward
    the maximum velocity (provided that velocity clamping is utilized), ultimately
    causing the swarm to diverge. In this scenario, particles struggle to alter their
    direction to return to promising regions. On the other hand, when *ω* < 1, particles
    may gradually decelerate until their velocities approach 0, depending on the acceleration
    coefficients’ values. Velocity clamping can be considered by setting a maximum
    (and minimum) limit for the velocity. If the calculated velocity for a particle
    exceeds this limit, it is set to the maximum (or minimum) value. This prevents
    particles from wandering too far off in the problem space or getting stuck in
    a specific region in the search space.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following methods can be used to update the inertia weight:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Random selection (RS)*—This involves selecting a different inertia weight
    in each iteration. The weight can be chosen from a distribution with a mean and
    standard deviation of your choice, but it’s important to ensure that the swarm
    still converges despite the randomness. The following formula can be used:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F11_Khamis-EQ11.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 9.11 |'
  prefs: []
  type: TYPE_TB
- en: where *rand*(.) is a uniformly distributed random number within the range [0,1].
    Therefore, the mean value of the inertia weight is 0.75.
  prefs: []
  type: TYPE_NORMAL
- en: '*Linear time varying (LTV)*—This involves gradually decreasing the value of
    *𝜔* from a starting high value of *𝜔[max]* to a final low value of *𝜔[min]* following
    this equation:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F11_Khamis-EQ12.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 9.12 |'
  prefs: []
  type: TYPE_TB
- en: where *𝑡[max]* is the number of iterations, *t* is the current iteration, and
    *𝜔[t]* is the value of the inertia weight in the *t*^(th) iteration. Typically,
    the convention is to set *𝜔[max]* and *𝜔[min]* to 0.9 and 0.4 respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '*Nonlinear time varying (NLTV)*—This approach also involves decreasing the
    inertia weight from an initial high value, but this decrement can be nonlinear,
    as shown in the following equation:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F11_Khamis-EQ13.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 9.13 |'
  prefs: []
  type: TYPE_TB
- en: where *𝜔[𝑡]*[=0] = 0.9 is the initial choice of *𝜔*. By allowing more time to
    fall off toward the lower end of the dynamic range, NLTV can enhance local search
    or exploitation.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.12 shows these three update methods.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F12_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.12 Different inertia weight update methods
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, in random selection, a different inertia weight is randomly
    selected in each iteration. The mean value of the inertia weight is 0.75\. LTV
    linearly decreases the inertia weight. In NLTV, the inertia weight decrement is
    more gradual than in LTV. In summary, the inertia weight plays a crucial role
    in the convergence speed and solution quality of the PSO algorithm. A high inertia
    weight promotes exploration, while a low inertia weight encourages exploitation.
  prefs: []
  type: TYPE_NORMAL
- en: 9.5.2 Cognitive and social components
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The cognitive component *c*1 is a parameter associated with a particle’s individual
    learning capability, where the particle is influenced by its own experiences.
    The social component *c*2 is a parameter linked to the collective learning capability
    of all particles within the swarm. It represents the degree to which a particle
    is influenced by the best solutions found by its neighbors. If *c*1 > *c*2, the
    algorithm will show exploratory behavior, and if *c*2 > *c*1, the algorithm will
    tend to exploit the local search space, as illustrated in figure 9.11\. Setting
    *c*1 = 0 reduces the velocity model to a social-only model or selfless model (the
    particles are all attracted to *nbest*). On the other hand, setting *c*2 = 0 reduces
    it to a cognition-only model (particles are independent, as in the case of the
    hill climbing algorithm).
  prefs: []
  type: TYPE_NORMAL
- en: 'Typically, *c*1 and *c*2 are kept constant in PSO. Empirically, the sum of
    *c*1 and *c*2 should be less than or equal to 4, and any significant deviations
    from this may result in divergent behavior. In adaptive PSO, it is advisable to
    gradually decrease the value of *c*1 over time and concurrently increase the value
    of *c*2 using linear formulas [4], as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F12_Khamis-EQ14.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 9.14 |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F12_Khamis-EQ15.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 9.15 |'
  prefs: []
  type: TYPE_TB
- en: where *t* is the iteration index, *c*1*[max]* and *c*2*[max]* are the maximum
    cognitive and social parameters respectively, *c*1*[min]* and *c*2*[min]* are
    the minimum cognitive and social parameters respectively, and *t[max]* is the
    maximum iteration.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.13 shows the linearly changing *c*1 and *c*2. As you can see, we start
    with *c*1 > *c*2 to favor exploration. As the search progresses, *c*2 starts to
    be higher than *c*1 in order to favor exploitation.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F13_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.13 Cognitive and social acceleration coefficient updates. c1>c2 results
    in more exploration, while c2>c1 may lead to more exploitation.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now see how we can use PSO to handle continuous and discrete optimization
    problems.
  prefs: []
  type: TYPE_NORMAL
- en: 9.6 Solving the traveling salesman problem
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous chapter, you saw how to solve the TSP for 20 major cities in
    the United States, starting from New York City, using a genetic algorithm. Let’s
    now solve the same problem using PSO, as shown in the next listing. We’ll start
    by defining the latitude and longitude for the twenty US cities and computing
    the inter-city distances between them.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.2 Solving TSP using PSO
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: ① Define the latitude and longitude for twenty major US cities.
  prefs: []
  type: TYPE_NORMAL
- en: ② Create a haversine distance matrix based on the latitude and longitude coordinates.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Convert the distance dictionary into a dataframe with distances as values
    and city names as headers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can count the number of cities and set up the integer bounds of the
    decision variables, which represent the order in which the cities are visited.
    The first function, `tsp_distance`, takes two arguments: `position` and `distance`.
    `position` is a 1D array that represents the order in which the cities are visited.
    `distance` is a 2D array that contains the distances between all pairs of cities.
    The function first defines `tour` as a permutation of the indices that represent
    the order of visiting the cities. It then calculates the total distance of the
    tour by summing the distances between adjacent cities as well as the distance
    between the last city in the tour and the starting city.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The second function, `tsp_cost`, takes two arguments: `x` and `distance`. `x`
    is a 2D array that contains the decision variables for the TSP problem, with each
    row representing a different particle in the swarm. `distance` is a 2D array that
    contains the distances between all pairs of cities. The function calculates the
    cost of each particle by calling the `tsp_distance` function on each row of `x`
    and returns a list of the costs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: ① Define the TSP problem as a permutation optimization problem with integer
    bounds.
  prefs: []
  type: TYPE_NORMAL
- en: ② Define the TSP distance function
  prefs: []
  type: TYPE_NORMAL
- en: ③ Convert the permutation to a TSP tour.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Compute the total distance of the tour from New York City as the first city,
    and add the distance from the last city back to New York City.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Compute and return the cost of each particle in the swarm.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a continuation of listing 9.2, the following code sets the parameters for
    the PSO optimizer. `options` is a dictionary that contains the values for the
    inertia weight (`w`), cognitive (`c1`) and social (`c2`) acceleration coefficients,
    number of neighbors to consider (`k`), and the p-value for the Minkowski distance
    (`p`). `n_particles` represents the number of particles used in the optimization,
    and `dimensions` represents the number of decision variables, which is equal to
    the number of cities in the TSP problem. The best solution found by the optimizer
    is converted to a TSP tour by sorting the indices of the solution in ascending
    order and using them to index the `city_names` list in the same order. This creates
    a list of city names in the order that they are visited in the best tour. We then
    print the best route and its length:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: ① Set up the PSO parameters.
  prefs: []
  type: TYPE_NORMAL
- en: ② Instantiate the PSO optimizer.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Solve the problem.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Convert the best solution to a TSP tour.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Print the best route and its length.
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing 9.2 produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Figure 9.14 shows the obtained route. The complete version of listing 9.2 is
    available in the book’s GitHub repo, and it shows the steps for visualizing the
    route as a NetworkX graph.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F14_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.14 PSO solution for the 20-city TSP
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to adjust the code according to your needs by modifying elements such
    as the problem data, the initial city, or the parameters of the algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 9.7 Neural network training using PSO
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Machine learning (ML) is a subfield of artificial intelligence (AI) that endows
    an artificial system or process with the ability to learn from experience and
    observation without being explicitly programmed. Many ML approaches have been
    and are still being proposed, and more details about ML will be provided in chapter
    11\. For now, let’s consider neural networks, which are one of the most used and
    successful statistical ML approaches. The artificial neural network (ANN or NN)
    approach is inspired by the biological brain and can be considered a highly simplified
    computational model, as NN is very far from matching a brain’s complexity. NN
    is at the heart of deep learning models that nowadays form the basis of many successful
    applications that touch everybody’s life, such as text, audio, image, and video
    generation, voice assistants, and recommendation engines, to name just a few.
  prefs: []
  type: TYPE_NORMAL
- en: The human brain
  prefs: []
  type: TYPE_NORMAL
- en: Aristotle (384-322 BC) wrote, “Of all the animals, man has the largest brain
    in proportion to his size.” The human brain is composed of an average of 86 billon
    interconnected nerve cells or *neurons*. Each biological neuron is connected to
    several thousand other neurons. It is extremely energy efficient, as it can perform
    the equivalent of an exaflop (a billion billion mathematical operations per second)
    with just 20 watts of power.
  prefs: []
  type: TYPE_NORMAL
- en: For simplicity, consider ML as glorified curve fitting, which intends to find
    a mapping function between independent and dependent variables. For example, suppose
    a vision-based object recognition model takes as input a digital image taken by
    the front camera of a vehicle—the output would be recognized objects, such as
    cars, pedestrians, cyclists, lanes, traffic lights, etc. In fact, ML shares the
    same ingredients as curve fitting in terms of model, scoring criteria, and search
    strategy. However, ML approaches, such as NNs, are a way to create functions that
    no human could write. They tend to create nonlinear, nonmonotonic, nonpolynomial,
    and even noncontinuous functions that approximate the relationship between independent
    and dependent variables in a data set.
  prefs: []
  type: TYPE_NORMAL
- en: 'An NN is a massively parallel adaptive network of simple nonlinear computing
    elements called neurons that are arranged in input, hidden, and output layers.
    Each node, or artificial neuron, connects to another and has an associated weight
    and threshold allowing the node to simulate a neuron firing. Each individual node
    has its own linear regression model, composed of input data, a bias, a threshold,
    and an output, as illustrated in figure 9.15\. A neuron *k* can be described with
    the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F14_Khamis-EQ16.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 9.16 |'
  prefs: []
  type: TYPE_TB
- en: Its output is
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F14_Khamis-EQ17.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 9.17 |'
  prefs: []
  type: TYPE_TB
- en: where *x[i]* are the inputs, *ω[ki]* are the weights, *b* is the bias term that
    defines the ability to fire in the absence of external input to the node, and
    *φ* is the activation function. This activation function makes the neuron fire
    the output when the input *z[k]* reaches a threshold *θ[k]*. There are different
    forms of activation functions (aka squashing functions) such as sign, step, tanh,
    arctan, s-shaped sigmoid (aka logistic), softmax, radial basis function, and rectified
    linear unit (ReLU).
  prefs: []
  type: TYPE_NORMAL
- en: 'As in the case of curve fitting, a scoring criterion or cost function is used
    to estimate deviation between the estimated values and the actual values. In this
    context, training an NN is fundamentally an optimization problem. The goal of
    training is to find the optimal parameters (weights and biases) that minimize
    the difference between the network’s output and the expected output. This difference
    is often quantified using a loss or cost function, such as these:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Mean squared error (MSE)*—MSE is often used in regression problems. It calculates
    the square of the difference between the predicted and actual values and then
    averages these across the dataset. This function heavily penalizes large errors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Cross-entropy loss*—Cross-entropy loss is typically used for binary and multiclass
    classification problems. It measures the dissimilarity between the predicted probability
    distribution and the actual distribution. In other words, it compares the model’s
    confidence in its prediction with the actual outcome.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Negative log likelihood (NLL)*—NLL is another loss function in multiclass
    classification. If *y* is the true label and *p*(*y*) is the predicted probability
    of that label, the negative log likelihood is defined as –log(*p*(*y*)). The log
    function transforms the probabilities, which range between 0 and 1, to a scale
    that ranges from positive infinity to 0\. When the predicted probability for the
    correct class is high (close to 1), the log value is closer to 0, but as the predicted
    probability for the correct class decreases, the log value increases toward infinity.
    Negating the log value thus gives a quantity that is minimized when the predicted
    probability for the correct class is maximized.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F15_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.15 Neural network node demonstration
  prefs: []
  type: TYPE_NORMAL
- en: 'Training an NN involves the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Initialization*—Before training starts, the weights and biases in the network
    are typically initialized with small random numbers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Feedforward*—In this stage, the input is passed through the network to produce
    an output. This output is generated by performing computations on the inputs using
    the initial or current weights, bias, and activation function transformation.
    The output of one layer becomes the input to the next layer until the final output
    is produced.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Error calculation*—After the feedforward stage, the output is compared with
    the desired output to calculate the error using a loss function. This function
    quantifies how far the network’s predictions are from the actual values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Backpropagation*—The calculated error is then propagated back through the
    network, starting from the output layer and moving back toward the input layer.
    This process computes the gradient or derivative of the loss function with respect
    to the weights and biases in the network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Weight adjustment*—In this final stage, the weights of the network are updated
    in an effort to reduce the error. This is typically done using a technique called
    *gradient descent*. The weights are adjusted in the direction that most decreases
    the error, as determined by the gradients calculated during backpropagation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By repeating these steps for many iterations (or epochs), the network gradually
    learns to produce outputs that are closer to the desired ones, thus “learning”
    from the input data.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have a basic understanding of NNs, let’s train a simple NN using
    PSO following a supervised learning approach. During supervised training, the
    NN learns by initially processing a labeled dataset. By training on a labeled
    dataset, the network can subsequently predict labels for a new, unlabeled data
    set during the inferencing stage, after training.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this example, we will use the Penguins dataset. This is a popular dataset
    in the data science community, containing information on the size, sex, and species
    of penguins. The dataset consists of 344 observations collected from three islands
    in the Palmer Archipelago, Antarctica. It includes the following seven variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '`species`—The species of penguin (Adelie, Chinstrap, or Gentoo)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`island`—The island where the penguin was observed (Biscoe, Dream, or Torgersen)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bill_length_mm`—The length of the penguin’s bill in millimeters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bill_depth_mm`—The depth of the penguin’s bill in millimeters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`flipper_length_mm`—The length of the penguin’s flipper in millimeters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`body_mass_g`—The mass of the penguin’s body in grams'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sex`—The sex of the penguin (male or female)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Our simple NN, described in the PySwarms use cases, has the following characteristics:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Input layer size*—4'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Hidden layer size*—10 (activation function: tanh(*x*)). The hyperbolic tangent
    activation function (aka Tanh, tanh, or TanH) maps input values to be between
    –1 and 1, and it’s used to introduce nonlinearity in NNs. Remember that a sigmoid
    function maps input values to be between 0 and 1\. The tanh function is centered
    at 0, which helps mitigate the vanishing gradient problem, compared to the sigmoid
    function. However, both tanh and sigmoid activations suffer from the vanishing
    gradient problem to some degree. Alternatives like rectified linear unit (ReLU)
    and its variants are often preferred.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Output layer size*—3 (activation function: softmax(*x*)). Softmax is a generalization
    of the sigmoid function. This function takes as input the *logits* that represent
    unnormalized outputs of the last layer of the network before they are transformed
    into probabilities by applying a softmax function. These logits can be interpreted
    as a measure of the “evidence” that a certain input belongs to a particular class.
    The higher the logit value for a particular class, the more likely it is that
    the input belongs to that class.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The following listing shows the steps for training this simple NN using PSO.
    We start by importing the libraries we’ll need and reading the penguin dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.3 Neural network training using PSO
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: ① Required for loading the dataset
  prefs: []
  type: TYPE_NORMAL
- en: ② Required for target label encoding
  prefs: []
  type: TYPE_NORMAL
- en: ③ Required for dimensionality reduction
  prefs: []
  type: TYPE_NORMAL
- en: ④ Load the Penguins dataset.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Show the dataset rows and columns.
  prefs: []
  type: TYPE_NORMAL
- en: This produces the output shown in figure 9.16.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F16_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.16 Penguins dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'As a continuation of listing 9.3, we can visualize this dataset using the seaborn
    library as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The output is shown in figure 9.17.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F17_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.17 Bill length vs. body mass by species in the Penguins dataset
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we define a `logits_function` to take in a vector `p` of parameters for
    the NN and return the logits (pre-activation values) for the final layer of the
    network. As illustrated in figure 9.18, this function starts by extracting the
    weights and biases for the first and second layers of the network from the parameter
    vector *p* using indexing and reshaping operations. Then, the function performs
    forward propagation by computing the pre-activation value *z*¹ in the first layer
    as the dot product of the input data *X* and the first set of weights *W*¹, plus
    the bias term *b*¹. It then applies the tanh activation function to *z*¹ to obtain
    the activation value *a*¹ in the first layer. Finally, the function computes the
    pre-activation value for the second layer by taking the dot product of *a*¹ and
    the second set of weights *W*² and adding the bias term *b*². The resulting values
    are returned as the logits from the final layer of the network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: ① Extracting the weights of the first laye
  prefs: []
  type: TYPE_NORMAL
- en: ② Extracting the weights of the second layer
  prefs: []
  type: TYPE_NORMAL
- en: ③ Extracting the biases of the second layer
  prefs: []
  type: TYPE_NORMAL
- en: ④ Calculate the pre-activation value in the first layer .
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Calculate and return the logits.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F18_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9.18 NN layers
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we define the `forward_prop` function to perform a forward pass through
    an NN with two layers. This computes the softmax probabilities and negative log
    likelihood loss for the output, given a set of parameters `params`. The function
    first calls the `logits_function` to obtain the logits for the final layer of
    the network, given the parameters `params`. Then the function applies the softmax
    function to the logits using the `np.exp` function and normalizes the resulting
    values by dividing by the sum of the exponentiated logits for each sample, using
    the `np.sum` function with the `axis=1` argument. This gives a probability distribution
    over the classes for each sample. The function then computes the negative log
    likelihood loss by taking the negative log of the probability of the correct class
    for each sample, which is obtained by indexing the `probs` array using the `y`
    variable, which contains the true class labels. The `np.sum` function is used
    to compute the sum of these negative log probabilities across all samples, and
    the result is divided by the total number of samples to obtain the average loss
    per sample. Finally, the function returns the computed loss:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: ① Obtain the logits for the softmax.
  prefs: []
  type: TYPE_NORMAL
- en: ② Apply softmax to calculate the probability distribution over the classes.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Compute the negative log likelihood.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Compute and return the loss.
  prefs: []
  type: TYPE_NORMAL
- en: 'To perform forward propagation over the whole swarm of particles, we define
    the following `particle_loss()` function. This function computes the loss for
    each particle in a PSO swarm, given its position in the search space. It is worth
    noting that each position represents the NN parameters (w1,b1,w2,b2) with `dimension`
    calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'An example of a candidate setting of NN parameters (i.e., a *position* in PSO
    terminology) is given here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The PSO algorithm can then use these loss values to update the positions of
    the particles and search for the optimal set of parameters for the NN.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: ① Determine the number of particles.
  prefs: []
  type: TYPE_NORMAL
- en: ② Compute and return the loss for each particle.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last function we need is `predict`, which uses the NN parameters corresponding
    to the positions of particles in a PSO swarm to predict the class labels for each
    sample in the dataset. This function first calls `logits_function` to obtain the
    logits for the final layer of the network, given the positions `pos` of the particles
    in the search space. Then the function computes the predicted class labels by
    taking the `argmax` of the logits across the columns (i.e., along the second axis
    or `axis=1`), using the `np.argmax` function. This gives the index of the class
    with the highest probability for each sample. Finally, the function returns the
    predicted class labels as a numpy array `y_pred`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: ① Obtain logits for the final layer of the network.
  prefs: []
  type: TYPE_NORMAL
- en: ② Compute and return the predicted class labels.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now train the NN using different PSOs available in PySwarms. The code
    starts by setting up several training samples, inputs, and the number of hidden
    layers and outputs. The dimensions are then computed based on the number of inputs,
    hidden nodes, and output classes. Three variants of PSO are defined: `globalBest`,
    `localBest`, and `binaryPSO`. The PSO hyperparameters are set using a dictionary
    called `options`. These hyperparameters include the inertia weight `w`, the cognitive
    parameter `c1`, the social parameter `c2`, the number of neighbors to be considered
    `k`, and the Minkowski distance parameter `p` (`p=1` is the sum-of-absolute values
    [or the L1 distance], while `p=2` is the Euclidean [or L2] distance):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: ① Get the feature vector
  prefs: []
  type: TYPE_NORMAL
- en: ② Set up the number of training samples, inputs, hidden layers, and outputs.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Set up the dimensions of the problem.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Define the variants of PSO.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Set up the PSO hyperparameters
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Train the NN using different variants of PSO, and print the best accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: The code then trains an NN, using each variant of PSO in turn, by creating an
    instance of the PSO optimizer and calling the `optimize` method, passing in the
    loss function and the number of iterations to run, `iters`. The best loss and
    particle position found by the optimizer are stored in `cost` and `pos` respectively.
    The code then prints the variant of PSO used along with the best accuracy that
    was obtained by using the corresponding particle position to make a prediction
    and comparing it to the true class label `y`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running the complete listing produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, `globalBest` PSO is the most efficient PSO variant for training
    this NN. Binary PSO does not match with the continuous nature of the NN parameters.
  prefs: []
  type: TYPE_NORMAL
- en: You can experiment with the code by changing the problem and algorithm parameters.
    For example, you could use a reduced feature set such as `bill_length_mm` and
    `flipper_length_mm` instead of the four features used in this code. You could
    also change the algorithm parameters and apply velocity clamping. `velocity clamp`
    is a parameter enabled in PySwarms to set the limits for velocity clamping. It’s
    a tuple of size 2 where the first entry is the minimum velocity and the second
    entry is the maximum velocity.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will be introduced to ant colony optimization (ACO)
    and artificial bee colony (ABC) as other effective optimization algorithms inspired
    by swarm intelligence.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: PSO employs a stochastic approach that utilizes the collective intelligence
    and movement of a swarm of particles. It is based on the idea of social interaction,
    which allows for efficient problem-solving.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The fundamental principle of PSO is to guide the swarm toward the best position
    in the search space while also remembering each particle’s own best-known position,
    as well as the global best-known position of the swarm.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'PSO is guided by a straightforward principle: emulate the success of neighboring
    individuals.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although PSO was initially designed for solving problems with continuous variables,
    many real-world problems involve discrete or combinatorial variables. In these
    problems, the search space is finite, and the algorithm needs to search through
    a set of discrete solutions. To address these types of problems, different variants
    of PSO have been developed, such as binary PSO (BPSO) and permutation-based PSO.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By carefully tuning inertia weight and cognitive and social acceleration coefficients,
    PSO can effectively balance exploration and exploitation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
