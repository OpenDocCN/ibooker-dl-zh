- en: 9 Particle swarm optimization
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9 粒子群优化
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Introducing swarm intelligence
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍群体智能
- en: Understanding the continuous particle swarm optimization algorithm
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解连续粒子群优化算法
- en: Understanding binary particle swarm optimization
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解二进制粒子群优化
- en: Understanding permutation-based particle swarm optimization
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解基于排列的粒子群优化
- en: Adapting particle swarm optimization for a better trade-off between exploration
    and exploitation
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适应粒子群优化以实现探索和利用之间的更好权衡
- en: Solving continuous and discrete problems using particle swarm optimization
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用粒子群优化解决连续和离散问题
- en: In the treasure-hunting mission I introduced in chapter 2, suppose you want
    to collaborate and share information with your friends instead of doing the treasure-
    hunting alone. However, you do not want to follow a competitive approach in which
    you only keep better-performing hunters and recruit new hunters to replace poorer-performing
    ones, like in the genetic algorithm (GA) explained in the previous chapters. You
    want to adopt a more cooperative approach and keep all the hunters, without replacing
    any, but you want to give more weight to the better-performing hunters and try
    to emulate their success. This scenario uses *swarm intelligence* and corresponds
    to population-based optimization algorithms such as *particle swarm optimization*
    (PSO), *ant colony optimization* (ACO), and *artificial bee colony* (ABC) algorithms,
    which will be explained in this fourth part of the book.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二章中我介绍的寻宝任务中，假设你想要与你的朋友合作并共享信息，而不是独自进行寻宝。然而，你不想采取一种竞争性的方法，在这种方法中，你只保留表现更好的猎人，并招募新的猎人替换表现较差的猎人，就像在前几章中解释的遗传算法（GA）那样。你想要采取一种更合作的方法，保留所有猎人，不进行任何替换，但你希望给予表现更好的猎人更多的权重，并尝试模仿他们的成功。这种场景使用了*群体智能*，对应于基于群体的优化算法，如*粒子群优化*（PSO）、*蚁群优化*（ACO）和*人工蜂群*（ABC）算法，这些算法将在本书的第四部分中解释。
- en: In this chapter, we’ll focus on different variants of PSO algorithms and apply
    them to solve continuous and discrete optimization problems. These variants include
    continuous PSO, binary PSO, permutation-based PSO, and adaptive PSO. Function
    optimization, the traveling salesman problem, neural network training, trilateration,
    coffee shop planning, and the doctor scheduling problem are discussed in this
    chapter and its supplementary exercises included in appendix C. The next chapter
    will cover the ACO and ABC algorithms.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将关注PSO算法的不同变体，并将它们应用于解决连续和离散优化问题。这些变体包括连续PSO、二进制PSO、基于排列的PSO和自适应PSO。本章讨论了函数优化、旅行商问题、神经网络训练、三角测量、咖啡馆规划以及医生排班问题，并在附录C中包含了补充练习。下一章将介绍ACO和ABC算法。
- en: 9.1 Introducing swarm intelligence
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.1 介绍群体智能
- en: 'Life on this planet is full of astonishing examples of collective behavior.
    Individual species depend upon one another for sustenance, often forming surprising
    alliances to achieve a common goal: the continuance of the species. The majority
    of living things also display amazing altruism in order to protect and provide
    the best care for their offspring, comparable to any form of sacrifice shown by
    human beings. They can cooperatively perform complex tasks such as foraging for
    food, dividing up labor, constructing nests, brood sorting, protecting, herding,
    schooling, and flocking, to name just a few. These complex collective behaviors
    emerge from individual interactions between spatially distributed and simple entities
    without a centralized controller or coordinator and without a script or access
    to global information. Various cooperation patterns, communication mechanisms,
    and adaptation strategies are employed to enable such complex collective behaviors.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个星球上，集体行为充满了令人惊叹的例子。各种物种为了生存相互依赖，常常形成令人惊讶的联盟以实现共同的目标：物种的延续。大多数生物也表现出惊人的利他主义，为了保护和为它们的后代提供最佳护理，这与人类所表现出的任何形式的牺牲相当。它们可以合作完成复杂的任务，如觅食、分配劳动、建造巢穴、孵化排序、保护、放牧、鱼群和鸟群，仅举几例。这些复杂的集体行为是从空间分布的简单实体之间的个体互动中产生的，没有中央控制器或协调者，也没有脚本或访问全局信息。各种合作模式、通信机制和适应策略被采用，以实现这种复杂的集体行为。
- en: Swarm intelligence
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 群体智能
- en: Swarm intelligence is a subfield of artificial intelligence that explores how
    large groups of relatively simple and spatially distributed agents can interact
    with each other and with their environment in a decentralized and self-organized
    manner to collectively achieve complex goals.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Several efficient population-based algorithms have been designed to exploit
    the power of collective intelligence by mimicking the collective behaviors observed
    in nature to solve complex optimization problems. Table 9.1 provides a non-exhaustive
    list of swarm intelligence algorithms and their sources of inspiration from unicellular
    and multicellular living organisms.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: Table 9.1 Examples of swarm intelligence algorithms and their sources of inspiration
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '| Organisms | Class | Source of inspiration | Algorithms |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
- en: '| Unicellular organisms | Bacteria | Bacterial swarm foraging | Bacterial foraging
    optimization algorithm (BFO)Bacterial swarming algorithm (BSA) |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
- en: '| Multicellular organisms | Bird/fish | Bird flocking and fish schooling |
    Particle swarm optimization (PSO) |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
- en: '| Ant | Ant foraging behaviors | Ant colony optimization (ACO) |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
- en: '| Bees | Foraging behavior of honeybees | Artificial bee colony (ABC) |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
- en: '| Bats | Echolocation behavior of bats | Bat algorithm (BA) |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
- en: '| Fireflies | Flashing behavior of fireflies | Firefly algorithm (FA) |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
- en: '| Butterflies | Foraging behavior of butterflies | Butterfly optimization algorithm
    (BOA) |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
- en: '| Dragonflies | Static and dynamic swarming behaviors of dragonflies | Dragonfly
    algorithm (DA) |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
- en: '| Spiders | Cooperative behavior of the social spiders | Social spider optimization
    (SSO) |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
- en: '| Krill | Herding behavior of krill | Krill herd (KH) |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
- en: '| Frogs | Frog cooperative search for food | Shuffled frog leaping algorithm
    (SFLA) |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
- en: '| Fish | Gregarious behavior of fish | Fish school search (FSS) |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
- en: '| Dolphins | Dolphins’ behavior in detecting, chasing after, and preying on
    swarms of sardines | Dolphin partner optimization (DPO)Dolphin swarm optimization
    algorithm (DSOA) |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
- en: '| Cats | Resting and tracing behaviors of cats | Cat swarm optimization (CSO)
    |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
- en: '| Monkeys | Search for food | Monkey search algorithm (MSA) |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
- en: '| Lions | Solitary and cooperative behaviors of lions | Lion optimization algorithm
    (LOA) |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
- en: '| Cuckoos | Reproduction strategy of cuckoos | Cuckoo search (CS)Cuckoo optimization
    algorithm (COA) |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
- en: '| Wolves | Leadership hierarchy and hunting mechanism of gray wolves | Wolf
    search algorithm (WSA)Grey wolf optimizer (GWO) |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
- en: For example, bacteria, which are single-celled organisms, possess underlying
    social intelligence allowing them to cooperate to solve challenges. Bacteria develop
    intricate communication capabilities like chemotactic signaling to cooperatively
    self-organize into highly structured colonies with elevated environmental adaptability.
    Bacterial chemotaxis is the process by which bacterial cells migrate through concentration
    gradients of chemical attractants and repellents. The E. coli bacterium uses this
    bacterial chemotaxis during the foraging process. This collective behavior provides
    the basis for optimization algorithms such as the bacterial foraging optimization
    algorithm (BFO) and bacterial swarming algorithm (BSA).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，细菌，作为单细胞生物，拥有潜在的社会智慧，这使得它们能够合作解决挑战。细菌发展出复杂的通讯能力，如趋化性信号，以合作的方式自我组织成高度结构化的群体，并提高环境适应性。细菌的趋化性是指细菌细胞通过化学吸引剂和排斥剂的浓度梯度迁移的过程。大肠杆菌在觅食过程中就利用了这种细菌趋化性。这种集体行为为优化算法如细菌觅食优化算法（BFO）和细菌集群算法（BSA）提供了基础。
- en: 'Ethology, the study of animal behavior, is the main source of inspiration for
    swarm intelligence algorithms such as particle swarm optimization (PSO), ant colony
    optimization (ACO), artificial bee colony (ABC), bat algorithm (BA), firefly algorithm
    (FA), and social spider optimization (SSO). For example, honeybees are highly
    cooperative social insects that cooperatively construct hives in which about 30,000
    bees can live and work together. They differentiate their work: some make wax,
    some make honey, some make bee-bread, some shape and mold combs, and some bring
    water to the cells and mingle it with the honey. Young bees engage in out-of-door
    work while the elder bees do the indoor work. During the foraging process, rather
    than expending energy searching in all directions, honeybee colonies use individual
    foragers to reduce the cost/ benefit ratio. Additionally, colonies concentrate
    their foraging efforts on the most lucrative patches and disregard those of lesser
    quality. It has been observed that when a colony’s food resources are scarce,
    foragers recruit more nestmates to food sources they have found, and changes in
    their dance patterns upon returning to the hive facilitate this increased recruitment.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 生态学，动物行为的研究，是群体智能算法如粒子群优化（PSO）、蚁群优化（ACO）、人工蜂群（ABC）、蝙蝠算法（BA）、萤火虫算法（FA）和社会蜘蛛优化（SSO）的主要灵感来源。例如，蜜蜂是一种高度合作的社交昆虫，它们合作建造蜂巢，大约有30,000只蜜蜂可以生活在其中并共同工作。它们分工明确：有的制作蜂蜡，有的制作蜂蜜，有的制作蜂粮，有的塑造和塑造蜂巢，有的将水带到蜂房并与蜂蜜混合。年轻的蜜蜂从事户外工作，而年老的蜜蜂则从事室内工作。在觅食过程中，蜜蜂群体不是在所有方向上消耗能量搜索，而是使用单个觅食者来降低成本/收益比。此外，群体将觅食努力集中在最有利可图的区域，并忽视那些质量较差的区域。观察到，当群体的食物资源稀缺时，觅食者会招募更多的巢居者到它们找到的食物来源，它们在返回蜂巢时舞蹈模式的改变有助于这种增加的招募。
- en: The fundamental components of swarm intelligence algorithms typically involve
    numerous decentralized processing agents that operate without central supervision.
    These agents communicate with neighboring agents and adapt their behavior based
    on received information. Furthermore, the majority of the research carried out
    on swarm intelligence algorithms is primarily based on experimental observations
    of collective behavior exhibited by living organisms. These observations are translated
    into models, which are then tested through simulations in order to derive the
    metaheuristics that form the basis of swarm intelligence algorithms, as illustrated
    in figure 9.1\. This experimental approach enables researchers to gain a deeper
    understanding of the complex interactions between individual agents and how they
    give rise to collective behavior. By simulating these interactions and testing
    various scenarios, researchers can refine the algorithms and improve their effectiveness.
    As an example of such experimental research, you can watch the “The Waggle Dance
    of the Honeybee” video of the experiment conducted by Georgia Tech College of
    Computing to understand how honeybees communicate the location of new food sources
    (www.youtube.com/watch?v=bFDGPgXtK-U).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 群智能算法的基本组件通常涉及大量无需中央监督的分布式处理代理。这些代理与邻近代理进行通信，并根据接收到的信息调整其行为。此外，对群智能算法进行的绝大多数研究主要基于对生物体集体行为的实验观察。这些观察结果被转化为模型，然后通过模拟进行测试，以推导出构成群智能算法基础的元启发式算法，如图9.1所示。这种实验方法使研究人员能够更深入地了解个体代理之间的复杂相互作用以及它们如何产生集体行为。通过模拟这些相互作用并测试各种场景，研究人员可以改进算法并提高其有效性。例如，您可以通过观看乔治亚理工学院计算机学院进行的“蜜蜂摇摆舞”实验视频来了解蜜蜂如何传达新食物源的位置（www.youtube.com/watch?v=bFDGPgXtK-U）。
- en: '![](../Images/CH09_F01_Khamis.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F01_Khamis.png)'
- en: Figure 9.1 Derivation process for swarm intelligence algorithms
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1 群智能算法的推导过程
- en: 'Algorithm 9.1 shows the common steps in a swarm intelligence algorithm. The
    algorithm starts by initializing the algorithm parameters, such as the number
    of individuals in the swarm, the maximum number of iterations, and the termination
    criteria. A swarm of initial candidate solutions is then sampled (the different
    sampling methods were explained in section 7.1). The algorithm then iterates over
    all the individuals in the swarm, performing the following operations: finding
    the best so far, finding the best neighbor, and updating the individual.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 算法9.1展示了群智能算法中的常见步骤。算法首先初始化算法参数，例如群体中个体的数量、最大迭代次数和终止条件。然后从初始候选解群体中采样（不同的采样方法在第7.1节中已解释）。算法随后遍历群体中的所有个体，执行以下操作：找到迄今为止的最佳解、找到最佳邻居以及更新个体。
- en: Algorithm 9.1 Swarm intelligence algorithm
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 算法9.1 群智能算法
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The individual and the neighbor are evaluated using the defined objective/fitness
    function. The neighborhood structure and update mechanism depend on the algorithm
    being used. This loop over all the individuals is repeated until the termination
    criterion is met, which could be a maximum number of iterations or reaching a
    satisfactory fitness level. At this point, the algorithm stops and returns the
    best solution found during the optimization process. In the following sections,
    we’ll dive deep into the PSO algorithm.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 使用定义的目标/适应度函数对个体及其邻居进行评估。邻域结构和更新机制取决于所使用的算法。这个遍历所有个体的循环会重复进行，直到满足终止条件，这可能是一个最大迭代次数或达到令人满意的适应度水平。在此阶段，算法停止并返回优化过程中找到的最佳解。在接下来的章节中，我们将深入探讨PSO算法。
- en: 9.2 Continuous PSO
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.2 连续PSO
- en: Particle swarm optimization (PSO) is a population-based stochastic optimization
    technique developed by Russell Eberhart and James Kennedy in 1995\. Since then,
    PSO has gained popularity and has been applied to various real-world applications
    in different domains. This algorithm is inspired by the conduct of social organisms
    such as birds, fish, ants, termites, wasps, and bees. PSO emulates the actions
    of these creatures, with each member of the swarm being referred to as a *particle*,
    akin to a bird in a flock, a fish in a school, or a bee in a colony. Eberhart
    and Kennedy opted to use the term “particle” to refer to an individual or candidate
    solution in the context of optimization, as they believed it was more suitable
    for describing the particle’s velocity and acceleration.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 粒子群优化（PSO）是一种由Russell Eberhart和James Kennedy于1995年开发的基于群体的随机优化技术。从那时起，PSO已经变得流行，并被应用于不同领域的各种现实世界应用。该算法受到鸟类、鱼类、蚂蚁、白蚁、黄蜂和蜜蜂等社会生物行为的启发。PSO模仿这些生物的行为，群体中的每个成员被称为*粒子*，类似于鸟群中的鸟、鱼群中的鱼或蜂群中的蜜蜂。Eberhart和Kennedy选择使用“粒子”一词来指代优化中的个体或候选解，因为他们认为这更适合描述粒子的速度和加速度。
- en: Bird flocking
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 鸟群行为
- en: 'Bird flocking is a behavior controlled by three simple rules, as illustrated
    in the following figure:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 鸟群行为是由三个简单规则控制的行为，如下面的图所示：
- en: '*Separation*—Prevent getting too close to nearby birds to avoid overcrowding.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*分离*—避免靠近附近的鸟，以防止过度拥挤。'
- en: '*Alignment*—Adjust the heading to correspond to the average direction of neighboring
    birds.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*对齐*—调整航向以对应邻近鸟类的平均方向。'
- en: '*Coherence*—Move toward the average position of neighboring birds.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*一致性*—向邻近鸟类的平均位置移动。'
- en: '![](../Images/CH09_F01_UN01_Khamis.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F01_UN01_Khamis.png)'
- en: 'Bird flocking rules: separation, alignment, and coherence'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 鸟群行为规则：分离、对齐和一致性
- en: When birds—spatially distributed agents interacting with each other and with
    their environment in a decentralized and self-organized manner without access
    to global information—apply these three simple rules, the outcome is the emergent
    behavior of bird flocking.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当鸟类——作为在去中心化和自我组织的方式下相互作用的分布式代理，与它们的环境相互作用，但没有访问全局信息——应用这三个简单规则时，结果是鸟群行为的涌现行为。
- en: 'The particles (candidate solutions) move, or fly, through the feasible search
    space by following the current best particles. Thus, PSO is guided by a straightforward
    principle: emulate the success of neighboring individuals. Each particle in the
    swarm operates in a decentralized manner by utilizing both its own intelligence
    and the collective intelligence of the group. Therefore, if one particle uncovers
    a favorable route to food, the remaining members of the swarm can immediately
    adopt the same path.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 粒子（候选解）通过跟随当前最佳粒子在可行搜索空间中移动或飞行。因此，PSO遵循一个简单的原则：模仿邻近个体的成功。群体中的每个粒子以去中心化的方式运作，利用自身的智能和群体的集体智能。因此，如果一个粒子发现了一条通往食物的有利路径，群体中的其他成员可以立即采用相同的路径。
- en: The PSO algorithm
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: PSO算法
- en: “This [PSO] algorithm belongs ideologically to that philosophical school that
    allows wisdom to emerge rather than trying to impose it, that emulates nature
    rather than trying to control it, and that seeks to make things simpler rather
    than more complex.” J. Kennedy and R. Eberhart, inventors of PSO [1].
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: “这个[PSO]算法在意识形态上属于那个允许智慧自然涌现而不是试图强加智慧、模仿自然而不是试图控制自然、寻求使事物更简单而不是更复杂的哲学学派。” J.
    Kennedy 和 R. Eberhart，PSO的发明者 [1]。
- en: Figure 9.2 shows the PSO flowchart. We start by initializing the algorithm parameters
    and creating an initial swarm of particles. These particles represent the candidate
    solutions. Each particle in the search space holds the current position *x^i*
    and current velocity *v^i*. The fitness of each particle is then evaluated based
    on the fitness/objective function to be optimized. The best position each particle
    has achieved so far is known as the personal best or *pbest*. The best position
    achieved by the particles in its neighborhood is known as *nbest*. If the neighborhood
    is restricted to a few particles, the best is called the local best, *lbest*.
    If the neighborhood is the whole swarm, the best achieved by the whole swarm is
    called the global best, *gbest*. We’ll discuss neighborhood structures in PSO
    further in section 9.2.3.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.2 展示了 PSO 流程图。我们首先初始化算法参数并创建一个初始粒子群。这些粒子代表候选解。搜索空间中的每个粒子都持有当前位置 *x^i* 和当前速度
    *v^i*。每个粒子迄今为止达到的最佳位置称为个人最佳或 *pbest*。粒子在其邻域中达到的最佳位置称为 *nbest*。如果邻域限制为少数几个粒子，则最佳称为局部最佳，*lbest*。如果邻域是整个群体，则整个群体达到的最佳称为全局最佳，*gbest*。我们将在
    9.2.3 节中进一步讨论 PSO 的邻域结构。
- en: '![](../Images/CH09_F02_Khamis.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH09_F02_Khamis.png)'
- en: Figure 9.2 The PSO algorithm
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.2 PSO 算法
- en: After evaluating the fitness of each particle, PSO updates each particle’s personal
    best position if the current fitness is superior, identifies the global best position
    based on the best fitness in the entire swarm, and adjusts particle velocities
    and positions using a combination of personal and global information. These steps
    guide the swarm toward optimal or near-optimal solutions by balancing individual
    and collective learning, promoting exploration and exploitation in the search
    space. The process iterates until termination criteria are met.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估每个粒子的适应度后，PSO（粒子群优化）会更新每个粒子的个人最佳位置，如果当前适应度更高，然后根据整个群体中最佳适应度确定全局最佳位置，并使用个人和全局信息的组合来调整粒子的速度和位置。这些步骤通过平衡个体和集体学习，促进搜索空间中的探索和利用，引导群体向最优或近似最优解发展。这个过程会迭代进行，直到满足终止条件。
- en: 9.2.1 Motion equations
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.1 运动方程
- en: 'The velocity (*v*) and position (*x*) of each particle are updated using the
    following equations:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 每个粒子的速度 (*v*) 和位置 (*x*) 使用以下方程进行更新：
- en: '|'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../Images/CH09_F02_Khamis-EQ01.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH09_F02_Khamis-EQ01.png)'
- en: '| 9.1 |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 9.1 |'
- en: '|'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../Images/CH09_F02_Khamis-EQ02.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH09_F02_Khamis-EQ02.png)'
- en: '| 9.2 |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 9.2 |'
- en: where
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 其中
- en: '*k* is the iteration number.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*k* 是迭代次数。'
- en: '*i* and *d* are the particle number and the dimension. For example, dimension
    = 1 in the case of a univariate optimization problem with a single decision variable,
    dimension = 2 in the case of a bivariate problem, etc.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*i* 和 *d* 是粒子编号和维度。例如，在只有一个决策变量的单变量优化问题中，维度 = 1；在双变量问题中，维度 = 2 等。'
- en: '*ω* is the inertia weight.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ω* 是惯性权重。'
- en: '*c*1, *c*2 are the acceleration coefficients.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*c*1, *c*2 是加速度系数。'
- en: '*r*1, *r*2 are random numbers between 0 and 1 and are generated in each iteration
    for each dimension, and not for each particle.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*r*1, *r*2 是介于 0 和 1 之间的随机数，并在每个迭代中为每个维度生成，而不是为每个粒子生成。'
- en: '*pbest* is the best position achieved by the particle.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*pbest* 是粒子达到的最佳位置。'
- en: '*gbest* is the best position achieved by the whole swarm. *gbest* should be
    replaced by *nbest or lbest* if you are dividing the swarm into multiple neighborhoods.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*gbest* 是整个群体达到的最佳位置。如果您将群体划分为多个邻域，则应将 *gbest* 替换为 *nbest* 或 *lbest*。'
- en: As you can see in these two equations, we start by updating the velocity *v*[(]*[k]*
    [+ 1)]*^(id)*. The position is then updated to *x*[(]*[k]* [+ 1)]*^(id)* by taking
    the current position *x[k]^(id)* and adding to it the new displacement *v*[(]*[k]*
    [+ 1)]*^(id)* × *timestamp* where *timestamp* = 1, which represents a single iteration.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如这两个方程所示，我们首先更新速度 *v*[(]*[k]* [+ 1)]*^(id)*。然后，通过将当前位置 *x[k]^(id)* 与新的位移 *v*[(]*[k]*
    [+ 1)]*^(id)* × *timestamp* 相加，更新位置到 *x*[(]*[k]* [+ 1)]*^(id)*，其中 *timestamp*
    = 1，这代表单次迭代。
- en: 'To understand these motion update equations, let’s visualize these equations
    using vectors in the 2D Cartesian coordinate system, as shown in figure 9.3\.
    As you can see, the velocity update equation consists of three primary components,
    each contributing to the movement of particles in the search space:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解这些运动更新方程，让我们使用二维笛卡尔坐标系中的向量来可视化这些方程，如图 9.3 所示。正如您所看到的，速度更新方程由三个主要组成部分组成，每个部分都贡献于搜索空间中粒子的运动：
- en: '*Inertia component*—The first part of the velocity update equation represents
    the influence of a particle’s inertia, taking into account that a particle (like
    a fish in a school or a bird in a flock) cannot abruptly change its direction.
    As you will see later, this inertia component is crucial, as it allows the algorithm
    to be more adaptive and helps maintain a balance between exploration and exploitation.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*惯性成分*—速度更新方程的第一部分代表了粒子的惯性影响，考虑到粒子（如鱼群中的鱼或鸟群中的鸟）不能突然改变方向。您将在后面看到，这个惯性成分至关重要，因为它使算法更具适应性，并有助于在探索和利用之间保持平衡。'
- en: '*Cognitive component*—The second part of the equation, referred to as the cognitive
    component, represents the particle’s attraction toward its personal best position,
    or individual proximity (*i*-proximity). This component reflects the degree of
    trust a particle places in its own past experiences, without considering the experiences
    of its neighbors or the swarm as a whole. The cognitive component encourages particles
    to explore the areas around their personal best positions, allowing them to fine-tune
    their search in promising regions.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*认知成分*—方程的第二部分被称为认知成分，它代表了粒子对其个人最佳位置的吸引力，或个体邻近性（*i*-邻近性）。这个成分反映了粒子对其自身过去经验的信任程度，不考虑其邻居或整个群体的经验。认知成分鼓励粒子探索其个人最佳位置周围的区域，使他们能够在有希望的区域内微调搜索。'
- en: '*Social component*—The third part of the velocity update equation is the social
    component, which represents the particle’s attraction to the swarm’s collective
    knowledge or group proximity (*g*-proximity). This component takes into account
    the experiences of neighboring particles and the swarm as a whole, guiding the
    particles toward the global best position found so far. The social component fosters
    collaboration among particles, helping them converge toward an optimal solution
    more effectively.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*社会成分*—速度更新方程的第三部分是社会成分，它代表了粒子对群体集体知识或群体邻近性的吸引力（*g*-邻近性）。这个成分考虑了邻近粒子和整个群体的经验，引导粒子向迄今为止找到的全局最佳位置移动。社会成分促进了粒子之间的协作，帮助他们更有效地收敛到最佳解。'
- en: '![](../Images/CH09_F03_Khamis.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F03_Khamis.png)'
- en: Figure 9.3 Visualizing the motion equation for a particle in the swarm
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3 展示了群体中粒子的运动方程
- en: To better understand the meaning of each component, imagine a group of friends
    visiting a large amusement park for the first time. Their goal is to visit the
    most thrilling rides in the park as efficiently as possible. The friends can be
    thought of as particles in the PSO algorithm, with each person’s enjoyment of
    the rides serving as the objective function to optimize. Each person has a preferred
    way of exploring the available rides, like walking through certain parts of the
    park or trying specific rides like roller coasters or water slides. This is similar
    to the inertia component in PSO, where particles maintain their current velocity
    and direction, ensuring they don’t change their exploration pattern too abruptly.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解每个成分的含义，想象一群朋友第一次参观一个大型游乐园。他们的目标是尽可能高效地参观公园中最刺激的游乐设施。这些朋友可以被看作是PSO算法中的粒子，每个人对游乐设施的享受作为要优化的目标函数。每个人都有自己探索可用游乐设施的首选方式，比如穿过公园的某些部分或尝试特定的游乐设施，如过山车或水上滑梯。这类似于PSO中的惯性成分，其中粒子保持其当前的速度和方向，确保他们不会过于突然地改变探索模式。
- en: Each friend relies on their own personal experiences to find the most thrilling
    rides. For instance, one friend might have had a great time on a roller coaster
    earlier in the day. They’re more likely to return to their favorite one or want
    to find more similar rides, knowing it was a good choice. They trust their judgment
    and focus on exploring the areas around the roller coaster, seeking out rides
    that they think they’ll enjoy based on their personal experience. This is the
    cognitive component, where particles in PSO are attracted to their personal best
    positions, following their past experiences and individual preferences.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 每个朋友都依靠自己的个人经验来寻找最刺激的游乐设施。例如，一个朋友可能在当天早些时候在过山车上玩得很开心。他们更有可能回到他们最喜欢的游乐设施，或者想要找到更多类似的游乐设施，因为他们知道这是一个好选择。他们信任自己的判断，并专注于探索过山车周围的区域，寻找他们认为会喜欢的游乐设施，基于他们的个人经验。这就是认知成分，在PSO中，粒子被吸引到它们的个人最佳位置，遵循它们过去的经验和个人偏好。
- en: The friends then collaborate to find the most thrilling ride based on their
    shared experiences. Imagine one of the friends has just ridden the most exciting
    roller coaster and can’t wait to tell the others about it. As they share their
    excitement, the group collectively becomes more attracted to that ride, influencing
    their individual choices. This is the social component, where particles in PSO
    are influenced by the global best position or the collective knowledge of the
    swarm.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，朋友们根据他们的共同经历合作寻找最刺激的游乐设施。想象一下，其中一位朋友刚刚乘坐了最刺激的过山车，迫不及待地想告诉其他人。当他们分享他们的兴奋时，整个群体对那个游乐设施的兴趣会集体增加，影响他们的个人选择。这是社会成分，其中PSO中的粒子受到全局最佳位置或群体集体知识的
    影响。
- en: The following subsections dive into more detail about the different PSO parameters.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的子节将更详细地介绍不同的PSO参数。
- en: 9.2.2 Fitness update
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.2 适应度更新
- en: 'After moving, each particle updates its own personal best using the following
    equation, assuming a minimization problem:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 移动后，每个粒子使用以下方程更新其个人最佳值，假设是一个最小化问题：
- en: '|'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../Images/CH09_F03_Khamis-EQ03.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F03_Khamis-EQ03.png)'
- en: '| 9.3 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 9.3 |'
- en: 'After that, each neighborhood updates its best as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，每个邻域按照以下方式更新其最佳值：
- en: '|'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../Images/CH09_F03_Khamis-EQ04.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F03_Khamis-EQ04.png)'
- en: '| 9.4 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 9.4 |'
- en: The neighborhood best (*nbest*) is the same as the global best (*gbest*) if
    the neighborhood is the whole swarm.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 如果邻域是整个群体，则邻域最佳 (*nbest*) 与全局最佳 (*gbest*) 相同。
- en: 'PSO has two main variants based on how particles’ positions and velocities
    are updated—synchronous and asynchronous PSO:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: PSO根据粒子位置和速度的更新方式主要有两种变体——同步和异步PSO：
- en: '*Synchronous PSO (S-PSO)*—All particles in the swarm update their positions
    and velocities simultaneously in a global manner. The local and global best are
    then updated. This synchronous approach ensures that all particles have access
    to the same global best position when updating their velocities and positions,
    promoting global exploration.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*同步PSO (S-PSO)*——群体中的所有粒子以全局方式同时更新其位置和速度。然后更新局部和全局最佳值。这种同步方法确保了在更新速度和位置时，所有粒子都能访问相同的全局最佳位置，从而促进全局探索。'
- en: '*Asynchronous PSO (A-PSO)*—Particles are updated based on the current state
    of the swarm. This asynchronous approach allows the particles to update their
    positions and velocities based on the most recent information available.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*异步PSO (A-PSO)*——粒子根据群体的当前状态进行更新。这种异步方法允许粒子根据最新的可用信息更新其位置和速度。'
- en: Figure 9.4 shows the difference between S-PSO and A-PSO. As you’ll notice, in
    A-PSO, the neighborhood best update is moved into the particle’s update loop.
    This allows particles to evaluate their fitness and update their positions and
    velocities independently and asynchronously.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.4显示了S-PSO和A-PSO之间的差异。你会注意到，在A-PSO中，邻域最佳更新被移动到粒子的更新循环中。这允许粒子独立和异步地评估其适应度并更新其位置和速度。
- en: '![](../Images/CH09_F04_Khamis.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH09_F04_Khamis.png)'
- en: Figure 9.4 Synchronous and asynchronous PSO
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.4 同步和异步PSO
- en: Although both synchronous and asynchronous PSO strategies can be employed to
    handle optimization problems, the asynchronous version is generally more effective,
    as it allows particles to take advantage of the most recent neighbor information.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管同步和异步PSO策略都可以用于处理优化问题，但异步版本通常更有效，因为它允许粒子利用最新的邻域信息。
- en: 9.2.3 Initialization
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.3 初始化
- en: 'PSO initialization includes initializing the particle position, velocity, and
    personal best, and initializing the algorithm’s parameters:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: PSO初始化包括初始化粒子位置、速度和个人最佳值，以及初始化算法的参数：
- en: '*Particle position initialization*—Particle positions represent candidate solutions
    to the problem, and they can be sampled using different sampling methods, as explained
    in section 7.1\. For example, the initial positions of the particles can be randomly
    assigned within the defined feasible search space.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*粒子位置初始化*——粒子位置代表问题的候选解，它们可以使用不同的采样方法进行采样，如第7.1节所述。例如，粒子的初始位置可以在定义的可行搜索空间内随机分配。'
- en: '*Particle velocity initialization*—The velocities of the particles can be set
    to zero or small values initially. Initializing them with small velocities ensures
    that the particles’ updates are gradual, preventing them from moving too far away
    from their starting positions. In contrast, large initial velocities may lead
    to significant updates, which can potentially cause divergence and hinder the
    convergence of the algorithm.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Personal best position initialization*—The personal best position of each
    particle, which represents the best solution found by the particle so far, should
    be initialized to its initial position. This allows the particles to begin their
    search with their starting points as a reference and to update their personal
    bests as they discover better solutions.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As shown in equation 9.1, PSO has three primary parameters that play a critical
    role in controlling the search algorithm’s behavior: the inertia weight (*ω*)
    and the acceleration coefficients (*c*1, *c*2). These parameters influence the
    balance between exploration and exploitation within the optimization process:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '*Inertia weight*—Large values of *ω* encourage exploration, while small values
    promote exploitation, allowing the cognitive and social components to exert greater
    control. A widely adopted value for *ω* is 0.792.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Acceleration coefficients*—Setting *c*1 to 0 reduces the PSO algorithm to
    a *social-only* or *selfless PSO* model. In this case, particles are solely attracted
    to the group best and ignore their personal bests. This leads to an emphasis on
    global exploration based on the swarm’s collective knowledge. Setting *c*2 to
    0 results in a *cognition-only model*, where particles act as independent hill
    climbers, relying only on their personal bests. In this scenario, the particles
    do not consider the experiences of other swarm members, focusing on local exploitation
    based on their individual experiences. In many applications, *c*1 and *c*2 are
    set to 1.49\. Although there is no theoretical justification for this specific
    value, it has been empirically found to work well in various optimization problems.
    Generally, the sum of *c*1 and *c*2 should be less than or equal to 4 to maintain
    the algorithm’s stability and convergence properties.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Other parameters to consider include swarm size and neighborhood size. There
    is no one-size-fits-all solution, as the optimal values depend on the specific
    problem being solved. However, some best practices and guidelines can help inform
    your choices:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: '*Swarm size*—A large swarm size can promote global exploration and prevent
    premature convergence, but at the cost of increased computational effort. A small
    swarm size can lead to faster convergence and reduced computational effort but
    may increase the risk of premature convergence. For many problems, a swarm size
    between 20 and 100 particles has been found to yield good results. It is advisable
    to conduct experiments with different swarm sizes to determine the best trade-off
    between exploration, exploitation, and computational complexity for the problem
    at hand.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Neighborhood size*—A large neighborhood size can encourage global exploration
    and information sharing among particles but may reduce the ability to exploit
    local optima. A small neighborhood size can promote local exploitation and convergence
    speed but may limit global exploration. You can use different neighborhood structures,
    as you’ll see in the next subsection.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generally speaking, selecting the best algorithm parameters requires experimentation
    and fine-tuning based on the specific problem you are trying to solve. It is often
    beneficial to perform a sensitivity analysis or use a parameter-tuning technique
    to find the optimal parameter values for your problem. We’ll look at this in more
    detail in section 9.5.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: 9.2.4 Neighborhoods
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the PSO algorithm, particles within a specific vicinity engage in mutual
    communication by sharing details about each other’s success within that local
    region. Subsequently, all particles gravitate toward a position that is considered
    to be an improvement based on a key performance indicator. The efficacy of the
    PSO algorithm is heavily reliant on the social network structure it employs. Choosing
    an appropriate neighborhood topology plays a crucial role in ensuring the algorithm’s
    convergence and in preventing it from becoming trapped in local minima.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the prevalent neighborhood topologies utilized in PSO include the star
    social structure, the ring topology, the Von Neumann model, and the wheel topology:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '*The star social structure, also known as the global best (gbest) PSO*—This
    is a neighborhood topology where all particles are connected, as shown in figure
    9.5a. This structure allows access to global information within the swarm, with
    the result that each particle is drawn toward the optimal solution discovered
    by the entire swarm. The *gbest* PSO has been demonstrated to converge more rapidly
    than other network structures. However, it is more prone to becoming ensnared
    in local minima without fully exploring the search space. This topology excels
    when applied to unimodal problems, as it allows for efficient and effective optimization
    in such cases.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Ring topology, also known as the local best (lbest) PSO*—Following this topology,
    a particle interacts exclusively with its immediately adjacent neighbors (figure
    9.5b). Each particle endeavors to emulate its most successful neighbor by gravitating
    toward the optimal solution discovered within the local vicinity. Although convergence
    occurs at a slower pace than with the star structure, the ring topology explores
    a more extensive portion of the search space. This topology is recommended for
    multimodal problems.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Von Neumann model*—In this topology, particles are arranged in a grid-like
    structure or square topology where each particle is connected with four other
    particles (the neighbors above, below, and to the right and left), as shown in
    figure 9.5c.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Wheel topology*—In this topology, the particles are isolated from each other,
    and one particle is randomly selected as the focal point or hub for all information
    flow, as illustrated in figure 9.5d.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The choice of neighborhood topology depends on the problem’s characteristics
    and the desired balance between exploration and exploitation. Experiment with
    different topologies to find the best fit for your problem.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F05_Khamis.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9.5 PSO neighborhood topologies: a) the star social structure, b) the
    ring topology, c) the Von Neumann model, and d) the wheel topology'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now look at how to solve a continuous optimization problem using PSO.
    The Michalewicz function is a nonconvex mathematical function commonly used as
    a test problem for optimization algorithms. This function is given by the following
    formula:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F05_Khamis-EQ05.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
- en: '| 9.5 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
- en: where *d* is the dimension of the problem and *m* is a constant (usually *m*
    = 10). This function has *d* local minima. For *d* = 2, the minimum value is –1.8013
    at (2.20, 1.57).
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by defining the Michalewicz function as shown in listing 9.1\. This
    function can accept size-1 arrays with single or multiple rows. If the input position
    is a size-1 array with a single row, we reshape it to a 2D array with a single
    row using the `reshape()` function. A *size-1 array*, also known as a *singleton
    array*, is an array data structure that contains only one element. This reshaping
    enables uniform handling of both single-row size-1 arrays and arrays with multiple
    rows. This is evident in the implementation of the PSO solver, where the function
    addresses solving one solution at a time. Additionally, the function seamlessly
    manages arrays with multiple rows, a scenario encountered when simultaneously
    evaluating multiple solutions. This aspect will be further elaborated upon later
    in the context of pymoo and PySwarms solvers.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.1 Solving the Michalewicz function using PSO
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: ① Reshape to a 2D array with a single row if the position is a size-1 array.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: ② The Michalewicz formula
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now create a PSO solver from scratch. As a continuation of listing 9.1,
    we’ll start by defining a particle class with position, velocity, and personal
    best value as follows:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The fitness function to be minimized is the Michalewicz function in this example:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We can now define the velocity update function following equation 9.1\. The
    function takes three arguments—`particle`, which is an object representing the
    current particle; `gbest_position`, which is the global best position found by
    the swarm so far; and `options`, which is a dictionary containing the algorithm
    parameters (specifically, the inertia weight `w` and the cognitive and social
    acceleration coefficients `c1` and `c2`):'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The function computes the three components of the new velocity: the inertia
    component, the cognitive component, and the social component, as per equation
    9.1\. It returns the updated velocity as the sum of the three components.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now define the PSO solver function. This function takes four parameters
    as inputs—`swarm_size`, which is the size of the particle swarm; `iterations`,
    which is the maximum number of iterations to run the algorithm for; `bounds`,
    which is a list of tuples defining the lower and upper bounds of the search space
    for each dimension of the input vector; and `options`, which is a dictionary containing
    the algorithm parameters (such as the inertia weight and cognitive and social
    acceleration coefficients):'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ① Initialize a random swarm.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: ② Initialize the global best.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: ③ Update the velocity and position.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: ④ Apply the bounds.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Update the personal best (pbest).
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Update the global best (gbest).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Update the position.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: ⑧ Return the global best position and corresponding value.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: The function first initializes the particle swarm by randomly generating the
    initial positions and velocities for each particle within the bounds defined by
    `bounds`. It then evaluates the fitness function for each particle and updates
    its personal best position and value accordingly. The function then enters a loop,
    where it updates the velocity and position of each particle using the `update_velocity`
    function, which takes the global best position found so far as input. The function
    also applies bounds to the particle position and updates its personal best position
    and value. The function then updates the global best position and value based
    on the star topology. Other topologies, such as ring, Von Neumann, and wheel,
    can be found in the complete code of listing 9.1, available in the book’s GitHub
    repository. Finally, the function returns the global best position and value found
    by the algorithm.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now use this PSO solver to minimize the Michalewicz function after we
    set up the problem and algorithm parameters as follows:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ① PSO parameters
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: ② Dimension and domain of the Michalewicz function for each variable
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: ③ Use the implemented PSO solver to solve the problem.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: 'You can print the optimal solution and minimum value of the function after
    running PSO:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The output would be as follows:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Compared to genetic algorithms, there are fewer Python libraries available
    for PSO. Pymoo provides a PSO implementation for continuous problems. As a continuation
    of listing 9.1, pymoo PSO can be used to solve the same problem as follows:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: ① Define the problem.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: ② The 2D Michalewicz function
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: ③ Set the lower and upper bounds.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: ④ Evaluate the objective function.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Create a problem instance.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Define the solver with the parameters.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Apply PSO to solve the problem.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: ⑧ Print the optimal solution and minimum value of the function after running
    PSO.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: 'This code produces the following output:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'PySwarms is another open source optimization library for Python that implements
    different variants of PSO. PySwarms can be used as follows to handle the problem:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: ① Import the PSO solver from pyswarms.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: ② Dimension of the Michalewicz function
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: ③ Create bounds for the search space.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: ④ Set up the optimizer.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Create an instance of the optimizer.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Optimize the Michalewicz function
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Print the optimal solution and minimum value of the function after running
    PSO.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: 'This code produces the following output:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The pyswarms.single package implements various techniques in continuous single-
    objective optimization. From this module, we used the global-best PSO (*gbest*
    PSO) algorithm in the previous code. You can experiment by replacing this solver
    with local-best.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.6 shows the 3D landscape and 2D contours of the Michalewicz function,
    the optimal solution, and the solutions obtained by PSO, PSO Pymoo, and PSO PySwarms.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F06_Khamis.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
- en: Figure 9.6 3D and 2D plots of the Michalewicz function. The three solutions
    are all very close to the optimal solution.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: The three versions of PSO provide comparable results. However, PSO PySwarms
    and PSO pymoo are more stable, as they provide more consistent results each time
    you run the code. The PySwarms library is more comprehensive than pymoo for PSO,
    as it provides implementations of different variants and topologies of PSO, including
    discrete PSO, which will be explained in the next two sections.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: 9.3 Binary PSO
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: PSO was originally developed for problems that involve continuous-valued variables.
    However, many real-world problems are discrete or combinatorial in nature, such
    as TSP, task allocation, scheduling, assignment problems, and feature selection,
    among others. These types of problems involve searching through a finite set of
    possible solutions, rather than searching through a continuous space. To handle
    these discrete problems, PSO variants have been developed, such as binary PSO
    and permutation-based PSO.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: In *binary PSO* (BPSO), each particle represents a position in the binary space,
    where each element is either 0 or 1\. The binary sequence is updated bit by bit
    based on its current value, the fitness-based value of that particular bit within
    the particle, and the best value of the same bit observed so far among its neighboring
    particles. This approach enables the search to be conducted in a binary space
    rather than a continuous space, which is well suited for problems where the variables
    are binary.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: 'In BPSO, the velocity is defined in terms of the probability of the bit changing.
    To restrict the values of the velocity elements to the range of [0,1], the sigmoid
    function is used:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F06_Khamis-EQ06.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
- en: '| 9.6 |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
- en: The position update equation then becomes
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F06_Khamis-EQ07.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
- en: '| 9.7 |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
- en: where *r* is a randomly generated number in [0, 1]. Figure 9.7 shows the sigmoid
    function and the probability of the updated position to be 1\. For example, if
    *v* = 0.3, this means that the probability that the updated position will be 1
    is 30%, and the probability that it will be 0 is 70%.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F07_Khamis.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
- en: Figure 9.7 Position and velocity notations in binary PSO (BPSO). Each particle
    represents a position in the binary space. Velocity is defined in terms of the
    probability of the bit changing.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: 'As you’ll notice, the velocity components will remain as real-valued numbers
    using the original equation, but these values are then passed through the sigmoid
    function before updating the position vector. The following equations are the
    velocity update equations in BPSO:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F07_Khamis-EQ08.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
- en: '| 9.8 |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
- en: '|'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F07_Khamis-EQ09.png)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
- en: '| 9.9 |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
- en: 'The positions are updated according to the following equation:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F07_Khamis-EQ10.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
- en: '| 9.10 |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
- en: where
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '*ϕ*[1] and *ϕ*[2] represent different random numbers drawn from uniform distributions.
    Sometimes these parameters are chosen from a uniform distribution 0–2, such that
    the sum of their two limits is 4.0.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*v^i^d[k]* [+1] is the probability that an individual *i* will choose 1 for
    the bit at the *d^(th)* site in the bit string.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*x[k]^(id)* is the current state of string *i* at bit *d*.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*v[k]^(id)* is a measure of the string’s current probability to choose 1.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*pbest[k]^(id)* is the best state found so far for bit *d* of individual *i*
    (i.e., a 1 or a 0).'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*gbest[k]^d* is 1 or 0 depending on what the value of bit *d* is in the best
    neighbor to date.'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: BPSO example
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate how BPSO works, suppose we have a population of five binary particles,
    where each particle consists of 6 bits. Let’s assume the particles are represented
    by the following binary strings: 101101, 110001, 011110, 100010, and 001011\.
    We want to update particle 4 (represented by the binary string 100010) at bit
    3 (which has a current value of 0). The current propensity (velocity) of this
    bit to be 1 is assumed to be 0.23\. Additionally, we assume that the best value
    of this particle found so far is 101110, while the best value found by the entire
    population is 101111\. Let’s also assume that ϕ[1] = 1.5 and ϕ[2] = 1.9. Using
    equations 9.8 and 9.9, we can get the updated velocity of bit 3 in particle 4
    as follows:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: 'Particle 4: 100010, *v[k]*^(43) = 0.23, *x[k]*^(43) = 0, *pbest[k]*^(43) =
    1, *gbest[k]*³ = 1, ϕ[1] = 1.5, ϕ[2] = 1.9'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '*v[k]* [+ 1]^(43) = 0.23 + 1.5(1–0) + 1.9(1–0) = 3.63'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '*sig*(*v[k]* [+ 1]^(43)) = *sig*(3.63) = 1/(1 + *e*^(–3.63)) = 0.974'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate a random number *r*^(43) = 0.6, and update the position using equation
    9.10 as follows:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '*x[k]* [+ 1]^(43) = 1 as *sig*(*v[k]* [+ 1]^(43)) > *r*^(43)'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: 'Updated particle 4: 100110'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: For more information about BPSO, see Kennedy and Eberhart’s article “A discrete
    binary version of the particle swarm algorithm” [2].
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: 9.4 Permutation-based PSO
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Numerous efforts have been undertaken to employ PSO in solving permutation problems.
    The challenge of adapting PSO to tackle these problems arises from the fact that
    the notions of velocity and direction are not inherently applicable to permutation
    problems. To overcome this obstacle, arithmetic operations like addition and multiplication
    need to be redefined.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: 'In M. Clerc’s 2004 article, “Discrete particle swarm optimization, illustrated
    by the traveling salesman problem” [3], PSO was applied to solve the TSP. The
    position of a particle was the solution to a problem (the permutation of cities).
    The velocity of a particle was defined as the set of swaps to be performed on
    a particle. As you have seen, the right side of equation 9.1 contains three arithmetic
    operations: multiplication, subtraction, and addition. These operations are redefined
    for the new search space as follows:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '*Multiplication*—The velocity vector constrains a number of swaps between cities.
    Multiplying this vector by a constant *c*, results in another velocity vector
    with a different length, depending on the value of the constant. If *c* = 0, the
    length of the velocity vector (i.e., the included number of swaps) is set to 0\.
    This means that no swap will be performed. If *c* < 1, the velocity is truncated.
    If *c* > 1, the velocity is augmented as illustrated in figure 9.8\. Augmentation
    means adding a swap taken from the top of the current velocity vector to the end
    of the new velocity vector.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F08_Khamis.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
- en: Figure 9.8 Redefined multiplication for permutation-based PSO
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '*Subtraction*—Subtracting two positions should produce a velocity. This operation
    produces the sequence of swaps that could transform one position to the other.
    For example, let’s consider an 8-city TSP. A candidate solution for this TSP is
    represented by a permutation such as [2, 4, 6, 1, 5, 3, 8, 7]. Figure 9.9 shows
    how a new velocity vector is produced by subtracting two positions.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F09_Khamis.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
- en: Figure 9.9 Redefined subtraction operation for permutation-based PSO
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '*Addition*—The operation is performed by applying the sequence of swaps defined
    by the velocity to the position vector. Figure 9.10 shows how a new position (i.e.,
    a new candidate solution) is generated by adding the velocity swap vector to the
    current position.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F10_Khamis.png)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
- en: Figure 9.10 Redefined addition operation for permutation-based PSO
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: These redefined arithmetic operations allow us to update the velocity and position
    of PSO particles.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: 9.5 Adaptive PSO
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The inertia, cognitive, and social components are the primary PSO parameters
    that can be used to achieve an equilibrium between exploration and exploitation
    during the optimization process. These three factors significantly influence the
    behavior of the algorithm, as discussed in the following subsections.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: 9.5.1 Inertia weight
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The inertia parameter represents the tendency of a particle to maintain its
    current trajectory. By adjusting the inertia value, the algorithm can balance
    its focus on searching the solution space broadly (exploration) or homing in on
    the best solutions found thus far (exploitation). Large values of *ω* promote
    exploration, and small values promote exploitation, as illustrated in figure 9.11\.
    Excessively small values may hinder the swarm’s exploration capabilities. As the
    value of *ω* decreases, the influence of the cognitive and social components on
    position updates becomes more dominant.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F11_Khamis.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
- en: Figure 9.11 Effect of PSO parameters on the search behavior. Large inertia promotes
    exploration, and small values promote exploitation. *c*1 > *c*2 results in excessive
    wandering of individuals through the search space. In contrast, *c*2 > *c*1 may
    lead particles to rush prematurely toward a local optimum.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: When *ω* > 1, particle velocities tend to escalate over time, accelerating toward
    the maximum velocity (provided that velocity clamping is utilized), ultimately
    causing the swarm to diverge. In this scenario, particles struggle to alter their
    direction to return to promising regions. On the other hand, when *ω* < 1, particles
    may gradually decelerate until their velocities approach 0, depending on the acceleration
    coefficients’ values. Velocity clamping can be considered by setting a maximum
    (and minimum) limit for the velocity. If the calculated velocity for a particle
    exceeds this limit, it is set to the maximum (or minimum) value. This prevents
    particles from wandering too far off in the problem space or getting stuck in
    a specific region in the search space.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: 'The following methods can be used to update the inertia weight:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: '*Random selection (RS)*—This involves selecting a different inertia weight
    in each iteration. The weight can be chosen from a distribution with a mean and
    standard deviation of your choice, but it’s important to ensure that the swarm
    still converges despite the randomness. The following formula can be used:'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F11_Khamis-EQ11.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
- en: '| 9.11 |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
- en: where *rand*(.) is a uniformly distributed random number within the range [0,1].
    Therefore, the mean value of the inertia weight is 0.75.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '*Linear time varying (LTV)*—This involves gradually decreasing the value of
    *𝜔* from a starting high value of *𝜔[max]* to a final low value of *𝜔[min]* following
    this equation:'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F11_Khamis-EQ12.png)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
- en: '| 9.12 |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
- en: where *𝑡[max]* is the number of iterations, *t* is the current iteration, and
    *𝜔[t]* is the value of the inertia weight in the *t*^(th) iteration. Typically,
    the convention is to set *𝜔[max]* and *𝜔[min]* to 0.9 and 0.4 respectively.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: '*Nonlinear time varying (NLTV)*—This approach also involves decreasing the
    inertia weight from an initial high value, but this decrement can be nonlinear,
    as shown in the following equation:'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F11_Khamis-EQ13.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
- en: '| 9.13 |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
- en: where *𝜔[𝑡]*[=0] = 0.9 is the initial choice of *𝜔*. By allowing more time to
    fall off toward the lower end of the dynamic range, NLTV can enhance local search
    or exploitation.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.12 shows these three update methods.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F12_Khamis.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
- en: Figure 9.12 Different inertia weight update methods
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, in random selection, a different inertia weight is randomly
    selected in each iteration. The mean value of the inertia weight is 0.75\. LTV
    linearly decreases the inertia weight. In NLTV, the inertia weight decrement is
    more gradual than in LTV. In summary, the inertia weight plays a crucial role
    in the convergence speed and solution quality of the PSO algorithm. A high inertia
    weight promotes exploration, while a low inertia weight encourages exploitation.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: 9.5.2 Cognitive and social components
  id: totrans-274
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The cognitive component *c*1 is a parameter associated with a particle’s individual
    learning capability, where the particle is influenced by its own experiences.
    The social component *c*2 is a parameter linked to the collective learning capability
    of all particles within the swarm. It represents the degree to which a particle
    is influenced by the best solutions found by its neighbors. If *c*1 > *c*2, the
    algorithm will show exploratory behavior, and if *c*2 > *c*1, the algorithm will
    tend to exploit the local search space, as illustrated in figure 9.11\. Setting
    *c*1 = 0 reduces the velocity model to a social-only model or selfless model (the
    particles are all attracted to *nbest*). On the other hand, setting *c*2 = 0 reduces
    it to a cognition-only model (particles are independent, as in the case of the
    hill climbing algorithm).
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: 'Typically, *c*1 and *c*2 are kept constant in PSO. Empirically, the sum of
    *c*1 and *c*2 should be less than or equal to 4, and any significant deviations
    from this may result in divergent behavior. In adaptive PSO, it is advisable to
    gradually decrease the value of *c*1 over time and concurrently increase the value
    of *c*2 using linear formulas [4], as follows:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F12_Khamis-EQ14.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
- en: '| 9.14 |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
- en: '|'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F12_Khamis-EQ15.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
- en: '| 9.15 |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
- en: where *t* is the iteration index, *c*1*[max]* and *c*2*[max]* are the maximum
    cognitive and social parameters respectively, *c*1*[min]* and *c*2*[min]* are
    the minimum cognitive and social parameters respectively, and *t[max]* is the
    maximum iteration.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: Figure 9.13 shows the linearly changing *c*1 and *c*2. As you can see, we start
    with *c*1 > *c*2 to favor exploration. As the search progresses, *c*2 starts to
    be higher than *c*1 in order to favor exploitation.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F13_Khamis.png)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
- en: Figure 9.13 Cognitive and social acceleration coefficient updates. c1>c2 results
    in more exploration, while c2>c1 may lead to more exploitation.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now see how we can use PSO to handle continuous and discrete optimization
    problems.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: 9.6 Solving the traveling salesman problem
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous chapter, you saw how to solve the TSP for 20 major cities in
    the United States, starting from New York City, using a genetic algorithm. Let’s
    now solve the same problem using PSO, as shown in the next listing. We’ll start
    by defining the latitude and longitude for the twenty US cities and computing
    the inter-city distances between them.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.2 Solving TSP using PSO
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ① Define the latitude and longitude for twenty major US cities.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: ② Create a haversine distance matrix based on the latitude and longitude coordinates.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: ③ Convert the distance dictionary into a dataframe with distances as values
    and city names as headers.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we can count the number of cities and set up the integer bounds of the
    decision variables, which represent the order in which the cities are visited.
    The first function, `tsp_distance`, takes two arguments: `position` and `distance`.
    `position` is a 1D array that represents the order in which the cities are visited.
    `distance` is a 2D array that contains the distances between all pairs of cities.
    The function first defines `tour` as a permutation of the indices that represent
    the order of visiting the cities. It then calculates the total distance of the
    tour by summing the distances between adjacent cities as well as the distance
    between the last city in the tour and the starting city.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: 'The second function, `tsp_cost`, takes two arguments: `x` and `distance`. `x`
    is a 2D array that contains the decision variables for the TSP problem, with each
    row representing a different particle in the swarm. `distance` is a 2D array that
    contains the distances between all pairs of cities. The function calculates the
    cost of each particle by calling the `tsp_distance` function on each row of `x`
    and returns a list of the costs:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ① Define the TSP problem as a permutation optimization problem with integer
    bounds.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: ② Define the TSP distance function
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: ③ Convert the permutation to a TSP tour.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: ④ Compute the total distance of the tour from New York City as the first city,
    and add the distance from the last city back to New York City.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Compute and return the cost of each particle in the swarm.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: 'As a continuation of listing 9.2, the following code sets the parameters for
    the PSO optimizer. `options` is a dictionary that contains the values for the
    inertia weight (`w`), cognitive (`c1`) and social (`c2`) acceleration coefficients,
    number of neighbors to consider (`k`), and the p-value for the Minkowski distance
    (`p`). `n_particles` represents the number of particles used in the optimization,
    and `dimensions` represents the number of decision variables, which is equal to
    the number of cities in the TSP problem. The best solution found by the optimizer
    is converted to a TSP tour by sorting the indices of the solution in ascending
    order and using them to index the `city_names` list in the same order. This creates
    a list of city names in the order that they are visited in the best tour. We then
    print the best route and its length:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: ① Set up the PSO parameters.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: ② Instantiate the PSO optimizer.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: ③ Solve the problem.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: ④ Convert the best solution to a TSP tour.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Print the best route and its length.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing 9.2 produces the following output:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Figure 9.14 shows the obtained route. The complete version of listing 9.2 is
    available in the book’s GitHub repo, and it shows the steps for visualizing the
    route as a NetworkX graph.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F14_Khamis.png)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
- en: Figure 9.14 PSO solution for the 20-city TSP
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: Feel free to adjust the code according to your needs by modifying elements such
    as the problem data, the initial city, or the parameters of the algorithm.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: 9.7 Neural network training using PSO
  id: totrans-316
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Machine learning (ML) is a subfield of artificial intelligence (AI) that endows
    an artificial system or process with the ability to learn from experience and
    observation without being explicitly programmed. Many ML approaches have been
    and are still being proposed, and more details about ML will be provided in chapter
    11\. For now, let’s consider neural networks, which are one of the most used and
    successful statistical ML approaches. The artificial neural network (ANN or NN)
    approach is inspired by the biological brain and can be considered a highly simplified
    computational model, as NN is very far from matching a brain’s complexity. NN
    is at the heart of deep learning models that nowadays form the basis of many successful
    applications that touch everybody’s life, such as text, audio, image, and video
    generation, voice assistants, and recommendation engines, to name just a few.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: The human brain
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: Aristotle (384-322 BC) wrote, “Of all the animals, man has the largest brain
    in proportion to his size.” The human brain is composed of an average of 86 billon
    interconnected nerve cells or *neurons*. Each biological neuron is connected to
    several thousand other neurons. It is extremely energy efficient, as it can perform
    the equivalent of an exaflop (a billion billion mathematical operations per second)
    with just 20 watts of power.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: For simplicity, consider ML as glorified curve fitting, which intends to find
    a mapping function between independent and dependent variables. For example, suppose
    a vision-based object recognition model takes as input a digital image taken by
    the front camera of a vehicle—the output would be recognized objects, such as
    cars, pedestrians, cyclists, lanes, traffic lights, etc. In fact, ML shares the
    same ingredients as curve fitting in terms of model, scoring criteria, and search
    strategy. However, ML approaches, such as NNs, are a way to create functions that
    no human could write. They tend to create nonlinear, nonmonotonic, nonpolynomial,
    and even noncontinuous functions that approximate the relationship between independent
    and dependent variables in a data set.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: 'An NN is a massively parallel adaptive network of simple nonlinear computing
    elements called neurons that are arranged in input, hidden, and output layers.
    Each node, or artificial neuron, connects to another and has an associated weight
    and threshold allowing the node to simulate a neuron firing. Each individual node
    has its own linear regression model, composed of input data, a bias, a threshold,
    and an output, as illustrated in figure 9.15\. A neuron *k* can be described with
    the following equation:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F14_Khamis-EQ16.png)'
  id: totrans-323
  prefs: []
  type: TYPE_IMG
- en: '| 9.16 |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
- en: Its output is
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F14_Khamis-EQ17.png)'
  id: totrans-327
  prefs: []
  type: TYPE_IMG
- en: '| 9.17 |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
- en: where *x[i]* are the inputs, *ω[ki]* are the weights, *b* is the bias term that
    defines the ability to fire in the absence of external input to the node, and
    *φ* is the activation function. This activation function makes the neuron fire
    the output when the input *z[k]* reaches a threshold *θ[k]*. There are different
    forms of activation functions (aka squashing functions) such as sign, step, tanh,
    arctan, s-shaped sigmoid (aka logistic), softmax, radial basis function, and rectified
    linear unit (ReLU).
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: 'As in the case of curve fitting, a scoring criterion or cost function is used
    to estimate deviation between the estimated values and the actual values. In this
    context, training an NN is fundamentally an optimization problem. The goal of
    training is to find the optimal parameters (weights and biases) that minimize
    the difference between the network’s output and the expected output. This difference
    is often quantified using a loss or cost function, such as these:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: '*Mean squared error (MSE)*—MSE is often used in regression problems. It calculates
    the square of the difference between the predicted and actual values and then
    averages these across the dataset. This function heavily penalizes large errors.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Cross-entropy loss*—Cross-entropy loss is typically used for binary and multiclass
    classification problems. It measures the dissimilarity between the predicted probability
    distribution and the actual distribution. In other words, it compares the model’s
    confidence in its prediction with the actual outcome.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Negative log likelihood (NLL)*—NLL is another loss function in multiclass
    classification. If *y* is the true label and *p*(*y*) is the predicted probability
    of that label, the negative log likelihood is defined as –log(*p*(*y*)). The log
    function transforms the probabilities, which range between 0 and 1, to a scale
    that ranges from positive infinity to 0\. When the predicted probability for the
    correct class is high (close to 1), the log value is closer to 0, but as the predicted
    probability for the correct class decreases, the log value increases toward infinity.
    Negating the log value thus gives a quantity that is minimized when the predicted
    probability for the correct class is maximized.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F15_Khamis.png)'
  id: totrans-334
  prefs: []
  type: TYPE_IMG
- en: Figure 9.15 Neural network node demonstration
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: 'Training an NN involves the following steps:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: '*Initialization*—Before training starts, the weights and biases in the network
    are typically initialized with small random numbers.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Feedforward*—In this stage, the input is passed through the network to produce
    an output. This output is generated by performing computations on the inputs using
    the initial or current weights, bias, and activation function transformation.
    The output of one layer becomes the input to the next layer until the final output
    is produced.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Error calculation*—After the feedforward stage, the output is compared with
    the desired output to calculate the error using a loss function. This function
    quantifies how far the network’s predictions are from the actual values.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Backpropagation*—The calculated error is then propagated back through the
    network, starting from the output layer and moving back toward the input layer.
    This process computes the gradient or derivative of the loss function with respect
    to the weights and biases in the network.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Weight adjustment*—In this final stage, the weights of the network are updated
    in an effort to reduce the error. This is typically done using a technique called
    *gradient descent*. The weights are adjusted in the direction that most decreases
    the error, as determined by the gradients calculated during backpropagation.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By repeating these steps for many iterations (or epochs), the network gradually
    learns to produce outputs that are closer to the desired ones, thus “learning”
    from the input data.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have a basic understanding of NNs, let’s train a simple NN using
    PSO following a supervised learning approach. During supervised training, the
    NN learns by initially processing a labeled dataset. By training on a labeled
    dataset, the network can subsequently predict labels for a new, unlabeled data
    set during the inferencing stage, after training.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: 'For this example, we will use the Penguins dataset. This is a popular dataset
    in the data science community, containing information on the size, sex, and species
    of penguins. The dataset consists of 344 observations collected from three islands
    in the Palmer Archipelago, Antarctica. It includes the following seven variables:'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: '`species`—The species of penguin (Adelie, Chinstrap, or Gentoo)'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`island`—The island where the penguin was observed (Biscoe, Dream, or Torgersen)'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bill_length_mm`—The length of the penguin’s bill in millimeters'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`bill_depth_mm`—The depth of the penguin’s bill in millimeters'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`flipper_length_mm`—The length of the penguin’s flipper in millimeters'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`body_mass_g`—The mass of the penguin’s body in grams'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sex`—The sex of the penguin (male or female)'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Our simple NN, described in the PySwarms use cases, has the following characteristics:'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: '*Input layer size*—4'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Hidden layer size*—10 (activation function: tanh(*x*)). The hyperbolic tangent
    activation function (aka Tanh, tanh, or TanH) maps input values to be between
    –1 and 1, and it’s used to introduce nonlinearity in NNs. Remember that a sigmoid
    function maps input values to be between 0 and 1\. The tanh function is centered
    at 0, which helps mitigate the vanishing gradient problem, compared to the sigmoid
    function. However, both tanh and sigmoid activations suffer from the vanishing
    gradient problem to some degree. Alternatives like rectified linear unit (ReLU)
    and its variants are often preferred.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Output layer size*—3 (activation function: softmax(*x*)). Softmax is a generalization
    of the sigmoid function. This function takes as input the *logits* that represent
    unnormalized outputs of the last layer of the network before they are transformed
    into probabilities by applying a softmax function. These logits can be interpreted
    as a measure of the “evidence” that a certain input belongs to a particular class.
    The higher the logit value for a particular class, the more likely it is that
    the input belongs to that class.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The following listing shows the steps for training this simple NN using PSO.
    We start by importing the libraries we’ll need and reading the penguin dataset.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: Listing 9.3 Neural network training using PSO
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: ① Required for loading the dataset
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: ② Required for target label encoding
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: ③ Required for dimensionality reduction
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: ④ Load the Penguins dataset.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Show the dataset rows and columns.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: This produces the output shown in figure 9.16.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F16_Khamis.png)'
  id: totrans-365
  prefs: []
  type: TYPE_IMG
- en: Figure 9.16 Penguins dataset
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: 'As a continuation of listing 9.3, we can visualize this dataset using the seaborn
    library as follows:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The output is shown in figure 9.17.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F17_Khamis.png)'
  id: totrans-370
  prefs: []
  type: TYPE_IMG
- en: Figure 9.17 Bill length vs. body mass by species in the Penguins dataset
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we define a `logits_function` to take in a vector `p` of parameters for
    the NN and return the logits (pre-activation values) for the final layer of the
    network. As illustrated in figure 9.18, this function starts by extracting the
    weights and biases for the first and second layers of the network from the parameter
    vector *p* using indexing and reshaping operations. Then, the function performs
    forward propagation by computing the pre-activation value *z*¹ in the first layer
    as the dot product of the input data *X* and the first set of weights *W*¹, plus
    the bias term *b*¹. It then applies the tanh activation function to *z*¹ to obtain
    the activation value *a*¹ in the first layer. Finally, the function computes the
    pre-activation value for the second layer by taking the dot product of *a*¹ and
    the second set of weights *W*² and adding the bias term *b*². The resulting values
    are returned as the logits from the final layer of the network:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: ① Extracting the weights of the first laye
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: ② Extracting the weights of the second layer
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: ③ Extracting the biases of the second layer
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: ④ Calculate the pre-activation value in the first layer .
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Calculate and return the logits.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH09_F18_Khamis.png)'
  id: totrans-379
  prefs: []
  type: TYPE_IMG
- en: Figure 9.18 NN layers
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we define the `forward_prop` function to perform a forward pass through
    an NN with two layers. This computes the softmax probabilities and negative log
    likelihood loss for the output, given a set of parameters `params`. The function
    first calls the `logits_function` to obtain the logits for the final layer of
    the network, given the parameters `params`. Then the function applies the softmax
    function to the logits using the `np.exp` function and normalizes the resulting
    values by dividing by the sum of the exponentiated logits for each sample, using
    the `np.sum` function with the `axis=1` argument. This gives a probability distribution
    over the classes for each sample. The function then computes the negative log
    likelihood loss by taking the negative log of the probability of the correct class
    for each sample, which is obtained by indexing the `probs` array using the `y`
    variable, which contains the true class labels. The `np.sum` function is used
    to compute the sum of these negative log probabilities across all samples, and
    the result is divided by the total number of samples to obtain the average loss
    per sample. Finally, the function returns the computed loss:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: ① Obtain the logits for the softmax.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: ② Apply softmax to calculate the probability distribution over the classes.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: ③ Compute the negative log likelihood.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: ④ Compute and return the loss.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: 'To perform forward propagation over the whole swarm of particles, we define
    the following `particle_loss()` function. This function computes the loss for
    each particle in a PSO swarm, given its position in the search space. It is worth
    noting that each position represents the NN parameters (w1,b1,w2,b2) with `dimension`
    calculated as follows:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'An example of a candidate setting of NN parameters (i.e., a *position* in PSO
    terminology) is given here:'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The PSO algorithm can then use these loss values to update the positions of
    the particles and search for the optimal set of parameters for the NN.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: ① Determine the number of particles.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: ② Compute and return the loss for each particle.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: 'The last function we need is `predict`, which uses the NN parameters corresponding
    to the positions of particles in a PSO swarm to predict the class labels for each
    sample in the dataset. This function first calls `logits_function` to obtain the
    logits for the final layer of the network, given the positions `pos` of the particles
    in the search space. Then the function computes the predicted class labels by
    taking the `argmax` of the logits across the columns (i.e., along the second axis
    or `axis=1`), using the `np.argmax` function. This gives the index of the class
    with the highest probability for each sample. Finally, the function returns the
    predicted class labels as a numpy array `y_pred`:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: ① Obtain logits for the final layer of the network.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: ② Compute and return the predicted class labels.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now train the NN using different PSOs available in PySwarms. The code
    starts by setting up several training samples, inputs, and the number of hidden
    layers and outputs. The dimensions are then computed based on the number of inputs,
    hidden nodes, and output classes. Three variants of PSO are defined: `globalBest`,
    `localBest`, and `binaryPSO`. The PSO hyperparameters are set using a dictionary
    called `options`. These hyperparameters include the inertia weight `w`, the cognitive
    parameter `c1`, the social parameter `c2`, the number of neighbors to be considered
    `k`, and the Minkowski distance parameter `p` (`p=1` is the sum-of-absolute values
    [or the L1 distance], while `p=2` is the Euclidean [or L2] distance):'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: ① Get the feature vector
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: ② Set up the number of training samples, inputs, hidden layers, and outputs.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
- en: ③ Set up the dimensions of the problem.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: ④ Define the variants of PSO.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Set up the PSO hyperparameters
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Train the NN using different variants of PSO, and print the best accuracy.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
- en: The code then trains an NN, using each variant of PSO in turn, by creating an
    instance of the PSO optimizer and calling the `optimize` method, passing in the
    loss function and the number of iterations to run, `iters`. The best loss and
    particle position found by the optimizer are stored in `cost` and `pos` respectively.
    The code then prints the variant of PSO used along with the best accuracy that
    was obtained by using the corresponding particle position to make a prediction
    and comparing it to the true class label `y`.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: 'Running the complete listing produces the following output:'
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-409
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: As you can see, `globalBest` PSO is the most efficient PSO variant for training
    this NN. Binary PSO does not match with the continuous nature of the NN parameters.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: You can experiment with the code by changing the problem and algorithm parameters.
    For example, you could use a reduced feature set such as `bill_length_mm` and
    `flipper_length_mm` instead of the four features used in this code. You could
    also change the algorithm parameters and apply velocity clamping. `velocity clamp`
    is a parameter enabled in PySwarms to set the limits for velocity clamping. It’s
    a tuple of size 2 where the first entry is the minimum velocity and the second
    entry is the maximum velocity.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will be introduced to ant colony optimization (ACO)
    and artificial bee colony (ABC) as other effective optimization algorithms inspired
    by swarm intelligence.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-413
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: PSO employs a stochastic approach that utilizes the collective intelligence
    and movement of a swarm of particles. It is based on the idea of social interaction,
    which allows for efficient problem-solving.
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The fundamental principle of PSO is to guide the swarm toward the best position
    in the search space while also remembering each particle’s own best-known position,
    as well as the global best-known position of the swarm.
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'PSO is guided by a straightforward principle: emulate the success of neighboring
    individuals.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although PSO was initially designed for solving problems with continuous variables,
    many real-world problems involve discrete or combinatorial variables. In these
    problems, the search space is finite, and the algorithm needs to search through
    a set of discrete solutions. To address these types of problems, different variants
    of PSO have been developed, such as binary PSO (BPSO) and permutation-based PSO.
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By carefully tuning inertia weight and cognitive and social acceleration coefficients,
    PSO can effectively balance exploration and exploitation.
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
