<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>The mathematical building blocks of neural networks</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>The mathematical building blocks of neural networks</h1>
<blockquote>原文：<a href="https://deeplearningwithpython.io/chapters/chapter02_mathematical-building-blocks">https://deeplearningwithpython.io/chapters/chapter02_mathematical-building-blocks</a></blockquote>


<aside>
<p>This chapter covers
</p>
<ul>
<li>A first example of a neural network</li>
<li>Tensors and tensor operations</li>
<li>How neural networks learn via backpropagation and gradient descent</li>
</ul>
</aside>

<p>Understanding deep learning requires familiarity with many simple mathematical
concepts: <em>tensors</em>, <em>tensor operations</em>, <em>differentiation</em>, <em>gradient descent</em>,
and so on. Our goal in this chapter will be to build up your intuition about these
notions without getting overly technical. In particular, we’ll steer away
from mathematical notation, which can introduce unnecessary barriers for those without
any mathematics background, and isn’t necessary to explain things well. The
most precise, unambiguous description of a mathematical operation
is its executable code.</p>
<p>To provide sufficient context for introducing tensors and gradient descent,
we’ll begin the chapter with a practical example of a neural network.
Then we’ll go over every new concept that’s been introduced, point by point.
Keep in mind that these concepts will be essential for you to understand
the practical examples that will come in the following chapters!</p>
<p>After reading this chapter, you’ll have an intuitive understanding of the
mathematical theory behind deep learning, and you’ll be ready to start diving
into modern deep learning frameworks, in chapter 3.</p>
<aside>
<p><span class="note-title">Running the code in this book</span></p>
<p>This book is full of runnable Python code. Each chapter is paired with a
<em>Jupyter notebook</em> that contains all of the code from the chapter. A Jupyter
notebook is a live Python scratch pad of sorts, where you can interactively run
code, graph data, view images, and a lot more. You will gain a lot more
practical knowledge from this book if you run and experiment with the code as
you read.</p>
<p>By far the easiest way to set up a deep learning environment to run these
notebooks is <em>Google Colaboratory</em> (or Colab for short), a hosted environment
for Jupyter notebooks that has become the industry standard for ML practitioners.
With Colab, you can run the code for this book interactively in the browser,
connecting to cloud runtimes with configurable hardware. By default, the
notebooks in this book will run on Colab’s free GPU runtime.</p>
<p>If you would like, you can also run these notebooks locally on your own machine.
A GPU is recommended, especially as you get to the larger and more compute-intensive
models later in this book.</p>
<p>Instructions for running locally and on Colab, along with the code,
can be found at <a href="https://github.com/fchollet/deep-learning-with-python-notebooks">https://github.com/fchollet/deep-learning-with-python-notebooks</a>.</p>
</aside>

<h2 id="a-first-look-at-a-neural-network">A first look at a neural network</h2>
<p>Let’s look at a concrete example of a neural network that uses the machine
learning library <em>Keras</em> to learn to classify handwritten digits. We will use
Keras extensively throughout this book. It’s a simple, high-level library that
will allow us to stay focused on the concepts we would like to cover.</p>
<p>Unless you already have experience with Keras or similar libraries, you won’t
understand everything about this first example right away. That’s fine. In a few
sections, we’ll review each element in the example and explain it in detail.
So don’t worry if some steps seem arbitrary or look like magic to you! We’ve got
to start somewhere.</p>
<p>The problem we’re trying to solve here is to classify grayscale images
of handwritten digits (28 × 28 pixels) into their 10 categories (0 through 9).
We’ll use the MNIST dataset, a classic in the machine learning community,
which has been around almost as long as the field itself and has been
intensively studied. It’s a set of 60,000 training images, plus 10,000 test
images, assembled by the National Institute of Standards and Technology
(the NIST in MNIST) in the 1980s. You can think of “solving” MNIST
as the “Hello World” of deep learning — it’s what you do to verify
that your algorithms are working as expected. As you become a machine learning
practitioner, you’ll see MNIST come up over and over again,
in scientific papers, blog posts, and so on. You can see some MNIST samples
in figure 2.1.</p>
<aside>
<p>In machine learning, a <em>category</em> in a classification problem is
called a <em>class</em>. Data points are called <em>samples</em>.
The class associated with a specific sample is called a <em>label</em>.</p>
</aside>

<figure id="figure-2-1">
<img src="../Images/b4c5f453ddbc3487d5e5722a8c5d8a57.png" data-original-src="https://deeplearningwithpython.io/images/ch02/MNIST-sample-digits.3d651e1d.png"/>
<figcaption>
<a href="#figure-2-1">Figure 2.1</a>: MNIST sample digits
</figcaption>
</figure>

<p>The MNIST dataset comes preloaded in Keras, in the form of a set of four
NumPy arrays.</p>
<figure id="listing-2-1">
<pre><code class="language-python">from keras.datasets import mnist

(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
</code></pre>
<figcaption>
<a href="#listing-2-1">Listing 2.1</a>: Loading the MNIST dataset in Keras
</figcaption>
</figure>

<p><code>train_images</code> and <code>train_labels</code> form the training set,
the data that the model will learn from. The model will then be tested
on the test set, <code>test_images</code> and <code>test_labels</code>.
The images are encoded as NumPy arrays, and the labels are an array of digits,
ranging from 0 to 9. The images and labels have a one-to-one correspondence.</p>
<aside>
<p>NumPy is a highly popular Python library for numerical computation.
You will see it pop up frequently in your machine learning journey.
It is rarely used to implement modern machine learning algorithms,
due to lacking GPU and <em>autodifferentiation</em> support,
but NumPy arrays are often used as a numerical data exchange
format — like here, for MNIST digits and their labels.</p>
</aside>

<p>Let’s look at the training data:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; train_images.shape</code>
<code class="language-output">(60000, 28, 28)</code>
<code class="language-python">&gt;&gt;&gt; len(train_labels)</code>
<code class="language-output">60000</code>
<code class="language-python">&gt;&gt;&gt; train_labels</code>
<code class="language-output">array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)</code></pre>
</figure>

<p>And here’s the test data:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; test_images.shape</code>
<code class="language-output">(10000, 28, 28)</code>
<code class="language-python">&gt;&gt;&gt; len(test_labels)</code>
<code class="language-output">10000</code>
<code class="language-python">&gt;&gt;&gt; test_labels</code>
<code class="language-output">array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)</code></pre>
</figure>

<p>The workflow will be as follows. First, we’ll feed the neural network the
training data, <code>train_images</code> and <code>train_labels</code>. The network will then learn
to associate images and labels. Finally, we’ll ask the network to produce
predictions for <code>test_images</code>, and we’ll verify whether these predictions
match the labels from <code>test_labels</code>.</p>
<p>Let’s build the network — again, remember that you aren’t expected to
understand everything about this example yet.</p>
<figure id="listing-2-2">
<pre><code class="language-python">import keras
from keras import layers

model = keras.Sequential(
    [
        layers.Dense(512, activation="relu"),
        layers.Dense(10, activation="softmax"),
    ]
)
</code></pre>
<figcaption>
<a href="#listing-2-2">Listing 2.2</a>: The network architecture
</figcaption>
</figure>

<p>The core building block of neural networks is the <em>layer</em>. You can think of a
layer as a filter for data: some data goes in, and
it comes out in a more useful form. Specifically, layers extract
<em>representations</em> out of the data fed into them — hopefully,
representations that are more meaningful for the problem at hand.
Most of deep learning consists of chaining together simple layers that will
implement a form of progressive <em>data distillation</em>.
A deep learning model is like a sieve for data processing,
made of a succession of increasingly refined data filters — the layers.</p>
<p>Here, our model consists of a sequence of two <code>Dense</code> layers, which
are densely connected (also called <em>fully connected</em>) neural layers.
The second (and last) layer is a 10-way <em><code>softmax</code> classification</em> layer,
which means it will return an array of 10 probability scores (summing to 1).
Each score will be the probability that the current digit image belongs
to one of our 10 digit classes.</p>
<p>To make the model ready for training, we need to pick three more things,
as part of the <em>compilation</em> step:</p>
<ul>
<li><em>A loss function</em> — How the model will be able to measure its
performance on the training data and thus how it will be able to steer
itself in the right direction.</li>
</ul>
<ul>
<li><em>An optimizer</em> — The mechanism through which the model will
update itself based on the training data it sees, to improve
its performance.</li>
</ul>
<ul>
<li><em>Metrics to monitor during training and testing</em> — Here, we’ll only care
about accuracy (the fraction of the images that were correctly classified).</li>
</ul>
<p>The exact purpose of the loss function and the optimizer will be made clear
throughout the next two chapters.</p>
<figure id="listing-2-3">
<pre><code class="language-python">model.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"],
)
</code></pre>
<figcaption>
<a href="#listing-2-3">Listing 2.3</a>: The compilation step
</figcaption>
</figure>

<p>Before training, we’ll <em>preprocess</em> the data by reshaping it into the shape the
model expects and scaling it so that all values are in the <code>[0, 1]</code> interval.
Previously, our training images were stored in an array of
shape <code>(60000, 28, 28)</code> of type <code>uint8</code> with values in the <code>[0, 255]</code> interval.
We transform it into a <code>float32</code> array of shape <code>(60000, 28 * 28)</code>
with values between <code>0</code> and <code>1</code>.</p>
<figure id="listing-2-4">
<pre><code class="language-python">train_images = train_images.reshape((60000, 28 * 28))
train_images = train_images.astype("float32") / 255
test_images = test_images.reshape((10000, 28 * 28))
test_images = test_images.astype("float32") / 255
</code></pre>
<figcaption>
<a href="#listing-2-4">Listing 2.4</a>: Preparing the image data
</figcaption>
</figure>

<p>We’re now ready to train the model, which in Keras is done via a call
to the model’s <code>fit()</code> method — we <em>fit</em> the model to its training data.</p>
<figure id="listing-2-5">
<pre><code class="language-python">model.fit(train_images, train_labels, epochs=5, batch_size=128)
</code></pre>
<figcaption>
<a href="#listing-2-5">Listing 2.5</a>: “Fitting” the model
</figcaption>
</figure>

<p>Two quantities are displayed during training: the loss of the model over
the training data and the accuracy of the model over the training data.
We quickly reach an accuracy of 0.989 (98.9%) on the training data.</p>
<p>Now that we have a trained model, we can use it to predict class probabilities
for <em>new</em> digits — images that weren’t part of the training data, like those
from the test set.</p>
<figure id="listing-2-6">
<pre><code class="language-python">&gt;&gt;&gt; test_digits = test_images[0:10]
&gt;&gt;&gt; predictions = model.predict(test_digits)
&gt;&gt;&gt; predictions[0]</code>
<code class="language-output">array([1.0726176e-10, 1.6918376e-10, 6.1314843e-08, 8.4106023e-06,
       2.9967067e-11, 3.0331331e-09, 8.3651971e-14, 9.9999106e-01,
       2.6657624e-08, 3.8127661e-07], dtype=float32)</code></pre>
<figcaption>
<a href="#listing-2-6">Listing 2.6</a>: Using the model to make predictions
</figcaption>
</figure>

<p>Each number of index <code>i</code> in that array corresponds to the probability that
digit image <code>test_digits[0]</code> belong to class <code>i</code>.</p>
<p>This first test digit has the highest probability score (0.99999106, almost 1)
at index 7, so according to our model, it must be a 7:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; predictions[0].argmax()</code>
<code class="language-output">7</code>
<code class="language-python">&gt;&gt;&gt; predictions[0][7]</code>
<code class="language-output">0.99999106</code></pre>
</figure>

<p>We can check that the test label agrees:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; test_labels[0]</code>
<code class="language-output">7</code></pre>
</figure>

<p>On average, how good is our model at classifying such never-before-seen digits?
Let’s check by computing average accuracy over the entire test set.</p>
<figure id="listing-2-7">
<pre><code class="language-python">&gt;&gt;&gt; test_loss, test_acc = model.evaluate(test_images, test_labels)
&gt;&gt;&gt; print(f"test_acc: {test_acc}")</code>
<code class="language-output">test_acc: 0.9785</code></pre>
<figcaption>
<a href="#listing-2-7">Listing 2.7</a>: Evaluating the model on new data
</figcaption>
</figure>

<p>The test set accuracy turns out to be 97.8% — that’s almost double the error
rate of the training set (at 98.9% accuracy). This gap between training accuracy and
test accuracy is an example of <em>overfitting</em>: the fact that machine learning
models tend to perform worse on new data than on their training data.
Overfitting is a central topic in chapter 5.</p>
<p>This concludes our first example. You just saw how you can build
and train a neural network to classify handwritten digits in less
than 15 lines of Python code. In this chapter and the next, we’ll go into detail
about every moving piece we just previewed and clarify what’s going
on behind the scenes. You’ll learn about tensors, the data-storing objects
going into the model; tensor operations, which layers are made of;
and gradient descent, which allows your model to learn from
its training examples.</p>
<h2 id="data-representations-for-neural-networks">Data representations for neural networks</h2>
<p>In the previous example, we started from data stored in multidimensional
NumPy arrays, also called <em>tensors</em>. In general, all current
machine learning systems use tensors as their basic data structure.
Tensors are fundamental to the field — so fundamental that the TensorFlow framework
was named after them. So what’s a tensor?</p>
<p>At its core, a tensor is a container for data — usually numerical data.
So it’s a container for numbers. You may already be familiar with matrices,
which are rank-2 tensors: tensors are a generalization of matrices to an arbitrary
number of dimensions (note that in the context of tensors, a dimension is
often called an <em>axis</em>).</p>
<p>Going over the details of tensors might seem a bit abstract at first. But it’s
well worth it — manipulating tensors will be the bread and butter of any
machine learning code you ever write.</p>
<h3 id="scalars-rank-0-tensors">Scalars (rank-0 tensors)</h3>
<p>A tensor that contains only one number is called
a <em>scalar</em> (or scalar tensor, rank-0 tensor, or 0D tensor).
In NumPy, a <code>float32</code> or <code>float64</code> number is a scalar tensor (or scalar array).
You can display the number of axes of a NumPy tensor via
the <code>ndim</code> attribute; a scalar tensor has 0 axes (<code>ndim == 0</code>).
The number of axes of a tensor is also called its <em>rank</em>.
Here’s a NumPy scalar:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; import numpy as np
&gt;&gt;&gt; x = np.array(12)
&gt;&gt;&gt; x</code>
<code class="language-output">array(12)</code>
<code class="language-python">&gt;&gt;&gt; x.ndim</code>
<code class="language-output">0</code></pre>
</figure>

<h3 id="vectors-rank-1-tensors">Vectors (rank-1 tensors)</h3>
<p>An array of numbers is called a vector (or rank-1 tensor or 1D tensor). A rank-1
tensor has exactly one axis. The following is a NumPy vector:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; x = np.array([12, 3, 6, 14, 7])
&gt;&gt;&gt; x</code>
<code class="language-output">array([12, 3, 6, 14, 7])</code>
<code class="language-python">&gt;&gt;&gt; x.ndim</code>
<code class="language-output">1</code></pre>
</figure>

<p>This vector has five entries and so is called a <em>5-dimensional vector</em>.
Don’t confuse a 5D vector with a 5D tensor! A 5D vector has only one axis
and has five dimensions along its axis, whereas a 5D tensor has five axes
(and may have any number of dimensions along each axis).
<em>Dimensionality</em> can denote either the number of entries along a specific axis
(as in the case of our 5D vector) or the number of axes in a tensor
(such as a 5D tensor), which can be confusing at times.
In the latter case, it’s technically more correct to talk about a
<em>tensor of rank 5</em> (the rank of a tensor being the number of axes),
but the ambiguous notation <em>5D tensor</em> is common regardless.</p>
<h3 id="matrices-rank-2-tensors">Matrices (rank-2 tensors)</h3>
<p>An array of vectors is a <em>matrix</em> (or rank-2 tensor or 2D tensor).
A matrix has two axes (often referred to as <em>rows</em> and <em>columns</em>).
You can visually interpret a matrix as a rectangular grid of numbers.
This is a NumPy matrix:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; x = np.array([[5, 78, 2, 34, 0],
...               [6, 79, 3, 35, 1],
...               [7, 80, 4, 36, 2]])
&gt;&gt;&gt; x.ndim</code>
<code class="language-output">2</code></pre>
</figure>

<p>The entries from the first axis are called the <em>rows</em>, and the entries
from the second axis are called the <em>columns</em>. In the previous example,
<code>[5, 78, 2, 34, 0]</code> is the first row of <code>x</code>,
and <code>[5, 6, 7]</code> is the first column.</p>
<h3 id="rank-3-tensors-and-higher-rank-tensors">Rank-3 tensors and higher-rank tensors</h3>
<p>If you pack such matrices in a new array, you obtain a rank-3 tensor
(or 3D tensor), which you can visually interpret as a cube of numbers.
The following is a NumPy rank-3 tensor:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; x = np.array([[[5, 78, 2, 34, 0],
...                [6, 79, 3, 35, 1],
...                [7, 80, 4, 36, 2]],
...               [[5, 78, 2, 34, 0],
...                [6, 79, 3, 35, 1],
...                [7, 80, 4, 36, 2]],
...               [[5, 78, 2, 34, 0],
...                [6, 79, 3, 35, 1],
...                [7, 80, 4, 36, 2]]])
&gt;&gt;&gt; x.ndim</code>
<code class="language-output">3</code></pre>
</figure>

<p>By packing rank-3 tensors in an array, you can create a rank-4 tensor, and so on.
In deep learning, you’ll generally manipulate tensors with ranks 0 to 4,
although you may go up to 5 if you process video data.</p>
<h3 id="key-attributes">Key attributes</h3>
<p>A tensor is defined by three key attributes:</p>
<ul>
<li><em>Number of axes (rank)</em> — For instance, a rank-3 tensor has three axes,
and a matrix has two axes. This is also called the tensor’s <code>ndim</code> in Python
libraries such as NumPy, JAX, TensorFlow, and PyTorch.</li>
</ul>
<ul>
<li><em>Shape</em> — This is a tuple of integers that describes how many dimensions
the tensor has along each axis. For instance, the previous matrix example has
shape <code>(3, 5)</code>, and the rank-3 tensor example has shape <code>(3, 3, 5)</code>.
A vector has a shape with a single element, such as <code>(5,)</code>,
whereas a scalar has an empty shape, <code>()</code>.</li>
</ul>
<ul>
<li><em>Data type (usually called <code>dtype</code> in Python libraries)</em> —
This is the type of the data contained in the tensor;
for instance, a tensor’s type could be <code>float16</code>, <code>float32</code>, <code>float64</code>, <code>uint8</code>, <code>bool</code>,
and so on. In TensorFlow, you are also likely to come across <code>string</code> tensors.</li>
</ul>
<p>To make this more concrete, let’s look back at the data we processed
in the MNIST example. First, we load the MNIST dataset:</p>
<figure>
<pre><code class="language-python">from keras.datasets import mnist

(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
</code></pre>
</figure>

<p>Next, we display the number of axes of the tensor <code>train_images</code>,
the <code>ndim</code> attribute:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; train_images.ndim</code>
<code class="language-output">3</code></pre>
</figure>

<p>Here’s its shape:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; train_images.shape</code>
<code class="language-output">(60000, 28, 28)</code></pre>
</figure>

<p>And this is its data type, the <code>dtype</code> attribute:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; train_images.dtype</code>
<code class="language-output">uint8</code></pre>
</figure>

<p>So what we have here is a rank-3 tensor of 8-bit integers.
More precisely, it’s an array of 60,000 matrices of 28 × 28 integers.
Each such matrix is a grayscale image, with coefficients between 0 and 255.</p>
<p>Let’s display the fourth digit in this rank-3 tensor, using the library Matplotlib
(part of the standard scientific Python suite); see figure 2.2.</p>
<figure id="listing-2-8">
<pre><code class="language-python">import matplotlib.pyplot as plt

digit = train_images[4]
plt.imshow(digit, cmap=plt.cm.binary)
plt.show()
</code></pre>
<figcaption>
<a href="#listing-2-8">Listing 2.8</a>: Displaying the fourth digit
</figcaption>
</figure>

<figure id="figure-2-2">
<img src="../Images/a8c8edb965fd31d17812646e506c4e03.png" data-original-src="https://deeplearningwithpython.io/images/ch02/The-fourth-sample-in-our-dataset.8685ed9a.png"/>
<figcaption>
<a href="#figure-2-2">Figure 2.2</a>: The fourth sample in our dataset
</figcaption>
</figure>

<p>Naturally, the corresponding label is just the integer 9:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; train_labels[4]</code>
<code class="language-output">9</code></pre>
</figure>

<h3 id="manipulating-tensors-in-numpy">Manipulating tensors in NumPy</h3>
<p>In the previous example,
we selected a specific digit alongside the first axis using the syntax
<code>train_images[i]</code>. Selecting specific elements in a tensor is called
<em>tensor slicing</em>. Let’s look at the tensor-slicing operations you can do on
NumPy arrays.</p>
<p>The following example selects digits #10 to #100 (#100 isn’t included)
and puts them in an array of shape <code>(90, 28, 28)</code>:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; my_slice = train_images[10:100]
&gt;&gt;&gt; my_slice.shape</code>
<code class="language-output">(90, 28, 28)</code></pre>
</figure>

<p>It’s equivalent to this more detailed notation,
which specifies a start index and stop index for the
slice along each tensor axis. Note that <code>:</code> is equivalent to selecting
the entire axis:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; # Equivalent to the previous example
&gt;&gt;&gt; my_slice = train_images[10:100, :, :]
&gt;&gt;&gt; my_slice.shape</code>
<code class="language-output">(90, 28, 28)</code>
<code class="language-python">&gt;&gt;&gt; # Also equivalent to the previous example
&gt;&gt;&gt; my_slice = train_images[10:100, 0:28, 0:28]
&gt;&gt;&gt; my_slice.shape</code>
<code class="language-output">(90, 28, 28)</code></pre>
</figure>

<p>In general, you may select slices between any two indices along each tensor axis.
For instance, to select 14 × 14 pixels in the bottom-right corner
of all images, you would do this:</p>
<figure>
<pre><code class="language-python">my_slice = train_images[:, 14:, 14:]
</code></pre>
</figure>

<p>It’s also possible to use negative indices. Much like negative indices
in Python lists, they indicate a position relative
to the end of the current axis.
To crop the images to patches of 14 × 14 pixels centered in the middle,
do this:</p>
<figure>
<pre><code class="language-python">my_slice = train_images[:, 7:-7, 7:-7]
</code></pre>
</figure>

<h3 id="the-notion-of-data-batches">The notion of data batches</h3>
<p>In general, the first axis (axis 0, because indexing starts at 0)
in all data tensors you’ll come across in deep learning will be the <em>samples axis</em>.
In the MNIST example, “samples” are images of digits.</p>
<p>In addition, deep learning models don’t process an entire dataset at once;
rather, they break the data into small “batches,” or groups of samples with a
fixed size.
Concretely, here’s one batch of our MNIST digits, with a batch size of 128:</p>
<figure>
<pre><code class="language-python">batch = train_images[:128]
</code></pre>
</figure>

<p>And here’s the next batch:</p>
<figure>
<pre><code class="language-python">batch = train_images[128:256]
</code></pre>
</figure>

<p>And the <code>n</code>th batch:</p>
<figure>
<pre><code class="language-python">n = 3
batch = train_images[128 * n : 128 * (n + 1)]
</code></pre>
</figure>

<p>When considering such a batch tensor, the first axis (axis 0) is
called the <em>batch axis</em> (or <em>batch dimension</em>).
You’ll frequently encounter this term when using Keras
and other deep learning libraries.</p>
<h3 id="real-world-examples-of-data-tensors">Real-world examples of data tensors</h3>
<p>Let’s make data tensors more concrete with a few examples similar
to what you’ll encounter later. The data you’ll manipulate will almost
always fall into one of the following categories:</p>
<ul>
<li><em>Vector data</em> — Rank-2 tensors of shape <code>(samples, features)</code>, where each
sample is a vector of numerical attributes (“features”)</li>
<li><em>Timeseries data or sequence data</em>  —  Rank-3 tensors of shape <code>(samples, timesteps, features)</code>,
where each sample is a sequence (of length <code>timesteps</code>) of feature vectors</li>
<li><em>Images</em> — Rank-4 tensors of shape <code>(samples, height, width, channels)</code>,
where each sample is a 2D grid of pixels, and each pixel is represented by a vector of values (“channels”)</li>
<li><em>Video</em> — Rank-5 tensors of shape <code>(samples, frames, height, width, channels)</code>,
where each sample is a sequence (of length <code>frames</code>) of images</li>
</ul>
<h4 id="vector-data">Vector data</h4>
<p>Vector data is one of the most common cases. In such a dataset, each single data point
can be encoded as a vector, and thus a batch of data will be encoded
as a rank-2 tensor (that is, an array of vectors),
where the first axis is the <em>samples axis</em> and the second axis
is the <em>features axis</em>.</p>
<p>Let’s take a look at two examples:</p>
<ul>
<li>An actuarial dataset of people, where we consider each person’s age, gender,
and income. Each person can be characterized as a vector of three values,
and thus an entire dataset of 100,000 people can be stored in a rank-2 tensor
of shape <code>(100000, 3)</code>.</li>
</ul>
<ul>
<li>A dataset of text documents, where we represent each document by the counts
of how many times each word appears in it
(out of a dictionary of 20,000 common words).
Each document can be encoded as a vector of 20,000 values
(one count per word in the dictionary), and thus an entire dataset of
500 documents can be stored in a tensor of shape <code>(500, 20000)</code>.</li>
</ul>
<h4 id="timeseries-data-or-sequence-data">Timeseries data or sequence data</h4>
<p>Whenever time matters in your data (or the notion of sequence order),
it makes sense to store it in a rank-3 tensor with an explicit time axis.
Each sample can be encoded as a sequence of vectors (a rank-2 tensor),
and thus a batch of data will be encoded as a rank-3 tensor (see figure 2.3).</p>
<figure id="figure-2-3">
<img src="../Images/ba394dc8634a1794a9159b2860dd6754.png" data-original-src="https://deeplearningwithpython.io/images/ch02/timeseries_data.a711cc5a.png"/>
<figcaption>
<a href="#figure-2-3">Figure 2.3</a>: A rank-3 timeseries data tensor
</figcaption>
</figure>

<p>The time axis is always the second axis (axis of index 1), by convention.
Let’s look at a few examples:</p>
<ul>
<li><em>A dataset of stock prices</em> — Every minute, we store the current price
of the stock, the highest price in the past minute, and the lowest price
in the past minute. Thus every minute is encoded as a 3D vector,
an entire day of trading is encoded as a matrix of shape <code>(390, 3)</code>
(there are 390 minutes in a trading day), and 250 days’ worth of data
can be stored in a rank-3 tensor of shape <code>(250, 390, 3)</code>.
Here, each sample would be one day’s worth of data.</li>
</ul>
<ul>
<li><em>A dataset of tweets, where we encode each tweet as a sequence of 280 characters
out of an alphabet of 128 unique characters</em> — In this setting, each character
can be encoded as a binary vector of size 128
(an all-zeros vector except for a 1 entry at
the index corresponding to the character).
Then each tweet can be encoded as a rank-2 tensor of shape <code>(280, 128)</code>,
and a dataset of 1 million tweets can be stored in a tensor
of shape <code>(1000000, 280, 128)</code>.</li>
</ul>
<h4 id="image-data">Image data</h4>
<p>Images typically have three dimensions: height, width, and color depth.
Although grayscale images (like our MNIST digits) have only a single color
channel and could thus be stored in rank-2 tensors, by convention image tensors
are always rank-3, with a one-dimensional color channel for grayscale images.
A batch of 128 grayscale images of size 256 × 256 could thus be stored
in a tensor of shape <code>(128, 256, 256, 1)</code>, and a batch of 128 color images
could be stored in a tensor of shape <code>(128, 256, 256, 3)</code> (see figure 2.4).</p>
<figure id="figure-2-4">
<img src="../Images/a1ad92e07f0728088785bcc8ad11d7d5.png" data-original-src="https://deeplearningwithpython.io/images/ch02/image_data.8accee38.png"/>
<figcaption>
<a href="#figure-2-4">Figure 2.4</a>: A rank-4 image data tensor
</figcaption>
</figure>

<p>There are two conventions for the shapes of image tensors:
the <em>channels-last</em> convention (which is standard in JAX and TensorFlow, as well as most other
deep learning tools out there) and the <em>channels-first</em> convention (which is standard in PyTorch).</p>
<p>The channels-last convention places the color-depth axis at the end:
<code>(samples, height, width, color_depth)</code>. Meanwhile, the channels-first
convention places the color depth axis right after the batch axis:
<code>(samples, color_depth, height, width)</code>. With the channels-first convention,
the previous examples would become <code>(128, 1, 256, 256)</code>
and <code>(128, 3, 256, 256)</code>. The Keras API provides support for both formats.</p>
<h4 id="video-data">Video data</h4>
<p>Video data is one of the few types of real-world data for which you’ll
need rank-5 tensors. A video can be understood as a sequence of frames,
each frame being a color image. Because each frame can be stored
in a rank-3 tensor <code>(height, width, color_depth)</code>, a sequence of frames
can be stored in a rank-4 tensor <code>(frames, height, width, color_depth)</code>,
and thus a batch of different videos can be stored in a rank-5 tensor
of shape <code>(samples, frames, height, width, color_depth)</code>.</p>
<p>For instance, a 60-second, 144 × 256 YouTube video clip sampled at
4 frames per second would have 240 frames. A batch of four such video clips
would be stored in a tensor of shape <code>(4, 240, 144, 256, 3)</code>.
That’s a total of 106,168,320 values! If the <code>dtype</code> of the tensor
was <code>float32</code>, then each value would be stored in 32 bits, so the tensor
would represent 425 MB. Heavy! Videos you encounter in real life
are much lighter because they aren’t stored in <code>float32</code> and they’re
typically compressed by a large factor (such as the MPEG format).</p>
<h2 id="the-gears-of-neural-networks-tensor-operations">The gears of neural networks: Tensor operations</h2>
<p>Just like any computer program can be ultimately reduced to a small set of
binary operations on binary inputs (<code>AND</code>, <code>OR</code>, <code>NOR</code>, and so on),
all transformations learned by deep neural networks can be reduced
to a handful of <em>tensor operations</em> (or <em>tensor functions</em>)
applied to tensors of numeric data.
For instance, it’s possible to add tensors, multiply tensors, and so on.</p>
<p>In our initial example, we were building our model by stacking <code>Dense</code> layers
on top of each other. A Keras layer instance looks like this:</p>
<figure>
<pre><code class="language-python">keras.layers.Dense(512, activation="relu")
</code></pre>
</figure>

<p>This layer can be interpreted as a function, which takes as input a matrix
and returns another matrix — a new representation for the input tensor.
Specifically, the function is as follows (where <code>W</code> is a matrix and <code>b</code>
is a vector, both attributes of the layer):</p>
<figure>
<pre><code class="language-python">output = relu(matmul(input, W) + b)
</code></pre>
</figure>

<p>Let’s unpack this. We have three tensor operations here:</p>
<ul>
<li>A tensor product (<code>matmul</code>) between the input tensor and a tensor named <code>W</code>.</li>
<li>An addition (<code>+</code>) between the resulting matrix and a vector <code>b</code>.</li>
<li>A <code>relu</code> operation: <code>relu(x)</code> is <code>max(x, 0)</code>. <code>"relu"</code> stands for “REctified Linear Unit.”</li>
</ul>
<aside>
<p>Although this section deals entirely with linear algebra expressions,
you won’t find any mathematical notation in this book. I’ve found that mathematical
concepts can be more readily mastered by programmers with no mathematical
background if they’re expressed as short Python snippets instead of mathematical
equations. So we’ll use NumPy code throughout.</p>
</aside>

<h3 id="element-wise-operations">Element-wise operations</h3>
<p>The <code>relu</code> operation and addition are element-wise operations: operations
that are applied independently to each entry in the tensors being considered.
This means these operations are highly amenable to massively parallel
implementations (<em>vectorized</em> implementations, a term that comes from
the <em>vector processor</em> supercomputer architecture from the 1970–1990 period).
If you want to write a naive Python implementation of an element-wise operation,
you use a <code>for</code> loop, as in this naive implementation of an element-wise <code>relu</code>
operation:</p>
<figure>
<pre><code class="language-python">def naive_relu(x):
    # x is a rank-2 NumPy tensor.
    assert len(x.shape) == 2
    # Avoids overwriting the input tensor
    x = x.copy()
    for i in range(x.shape[0]):
        for j in range(x.shape[1]):
            x[i, j] = max(x[i, j], 0)
    return x
</code></pre>
</figure>

<p>You could do the same for addition:</p>
<figure>
<pre><code class="language-python">def naive_add(x, y):
    # x and y are rank-2 NumPy tensors.
    assert len(x.shape) == 2
    assert x.shape == y.shape
    # Avoids overwriting the input tensor
    x = x.copy()
    for i in range(x.shape[0]):
        for j in range(x.shape[1]):
            x[i, j] += y[i, j]
    return x
</code></pre>
</figure>

<p>On the same principle, you can do element-wise multiplication, subtraction,
and so on.</p>
<p>In practice, when dealing with NumPy arrays, these operations are available
as well-optimized built-in NumPy functions, which themselves delegate the
heavy lifting to a Basic Linear Algebra Subprograms (BLAS) implementation.
BLAS are low-level, highly parallel, efficient tensor-manipulation routines
that are typically implemented in Fortran or C.</p>
<p>So, in NumPy, you can do the following element-wise operation, and it will
be blazing fast:</p>
<figure>
<pre><code class="language-python">import numpy as np

# Element-wise addition
z = x + y
# Element-wise relu
z = np.maximum(z, 0.0)
</code></pre>
</figure>

<p>Let’s actually time the difference:</p>
<figure>
<pre><code class="language-python">import time

x = np.random.random((20, 100))
y = np.random.random((20, 100))

t0 = time.time()
for _ in range(1000):
    z = x + y
    z = np.maximum(z, 0.0)
print("Took: {0:.2f} s".format(time.time() - t0))
</code></pre>
</figure>

<p>This takes 0.02 seconds. Meanwhile, the naive version takes a stunning 2.45 seconds:</p>
<figure>
<pre><code class="language-python">t0 = time.time()
for _ in range(1000):
    z = naive_add(x, y)
    z = naive_relu(z)
print("Took: {0:.2f} s".format(time.time() - t0))
</code></pre>
</figure>

<p>Likewise, when running JAX/TensorFlow/PyTorch code on a GPU,
element-wise operations are executed via fully vectorized CUDA implementations
that can best utilize the highly parallel GPU chip architecture.</p>
<h3 id="broadcasting">Broadcasting</h3>
<p>Our earlier naive implementation of <code>naive_add</code> only supports the addition
of rank-2 tensors with identical shapes. But in the <code>Dense</code> layer
introduced earlier, we added a rank-2 tensor with a vector. What happens with
addition when the shapes of the two tensors being added differ?</p>
<p>When possible, and if there’s no ambiguity, the smaller tensor will be
<em>broadcast</em> to match the shape of the larger tensor. Broadcasting consists of
two steps:</p>
<ul>
<li>Axes (called <em>broadcast axes</em>) are added to the smaller tensor to match
 the <code>ndim</code> of the larger tensor.</li>
<li>The smaller tensor is repeated alongside these new axes to match the
 full shape of the larger tensor.</li>
</ul>
<p>Let’s look at a concrete example. Consider <code>X</code> with shape <code>(32, 10)</code> and <code>y</code>
with shape <code>(10,)</code>:</p>
<figure>
<pre><code class="language-python">import numpy as np

# X is a random matrix with shape (32, 10).
X = np.random.random((32, 10))
# y is a random vector with shape (10,).
y = np.random.random((10,))
</code></pre>
</figure>

<p>First, we add an empty first axis to <code>y</code>, whose shape
becomes <code>(1, 10)</code>:</p>
<figure>
<pre><code class="language-python"># The shape of y is now (1, 10).
y = np.expand_dims(y, axis=0)
</code></pre>
</figure>

<p>Then, we repeat <code>y</code> 32 times alongside this new axis,
so that we end up with a tensor <code>Y</code> with shape <code>(32, 10)</code>, where <code>Y[i, :] == y</code>
for <code>i</code> in <code>range(0, 32)</code>:</p>
<figure>
<pre><code class="language-python"># Repeat y 32 times along axis 0 to obtain Y with shape (32, 10).
Y = np.tile(y, (32, 1))
</code></pre>
</figure>

<p>At this point, we can add <code>X</code> and <code>Y</code>
because they have the same shape.</p>
<p>In terms of implementation, no new rank-2 tensor is created because that would
be terribly inefficient. The repetition operation is entirely virtual:
it happens at the algorithmic level rather than at the memory level.
But thinking of the vector being repeated 32 times alongside a new axis
is a helpful mental model. Here’s what a naive implementation would look like:</p>
<figure>
<pre><code class="language-python">def naive_add_matrix_and_vector(x, y):
    # x is a rank-2 NumPy tensor.
    assert len(x.shape) == 2
    # y is a NumPy vector.
    assert len(y.shape) == 1
    assert x.shape[1] == y.shape[0]
    # Avoids overwriting the input tensor
    x = x.copy()
    for i in range(x.shape[0]):
        for j in range(x.shape[1]):
            x[i, j] += y[j]
    return x
</code></pre>
</figure>

<p>With broadcasting, you can generally apply two-tensor element-wise operations
if one tensor has shape <code>(a, b, … n, n + 1, … m)</code> and the other has shape
<code>(n, n + 1, … m)</code>. The broadcasting will then automatically happen
for axes <code>a</code> through <code>n - 1</code>.</p>
<p>The following example applies the element-wise <code>maximum</code> operation
to two tensors of different shapes via broadcasting:</p>
<figure>
<pre><code class="language-python">import numpy as np

# x is a random tensor with shape (64, 3, 32, 10).
x = np.random.random((64, 3, 32, 10))
# y is a random tensor with shape (32, 10).
y = np.random.random((32, 10))
# The output z has shape (64, 3, 32, 10) like x.
z = np.maximum(x, y)
</code></pre>
</figure>

<h3 id="tensor-product">Tensor product</h3>
<p>The <em>tensor product</em>, also called <em>dot product</em> or <em>matmul</em>
(short for “matrix multiplication”) is one of the most common,
most useful tensor operations.</p>
<p>In NumPy, a tensor product is done using the <code>np.matmul</code> function, and in
Keras, with the <code>keras.ops.matmul</code> function. Its shorthand is the <code>@</code> operator in Python:</p>
<figure>
<pre><code class="language-python">x = np.random.random((32,))
y = np.random.random((32,))

# Takes the product between x and y
z = np.matmul(x, y)
# This is equivalent.
z = x @ y
</code></pre>
</figure>

<p>In mathematical notation, you’d note the operation with a dot (•)
(hence the name “dot product”):</p>
<figure>
<pre><code class="language-text">z = x • y
</code></pre>
</figure>

<p>Mathematically, what does the <code>matmul</code> operation do? Let’s start with
the product of two vectors <code>x</code> and <code>y</code>. It’s computed as follows:</p>
<figure>
<pre><code class="language-python">def naive_vector_product(x, y):
    # x and y are NumPy vectors.
    assert len(x.shape) == 1
    assert len(y.shape) == 1
    assert x.shape[0] == y.shape[0]
    z = 0.0
    for i in range(x.shape[0]):
        z += x[i] * y[i]
    return z
</code></pre>
</figure>

<p>You’ll have noticed that the product between two vectors is a scalar
and that only vectors with the same number of elements are compatible
for this operation.</p>
<p>You can also take the product between a matrix <code>x</code> and a vector <code>y</code>,
which returns a vector where the coefficients are the products between
<code>y</code> and the rows of <code>x</code>. You implement it as follows:</p>
<figure>
<pre><code class="language-python">def naive_matrix_vector_product(x, y):
    # x is a NumPy matrix.
    assert len(x.shape) == 2
    # y is a NumPy vector.
    assert len(y.shape) == 1
    # The 1st dimension of x must equal the 0th dimension of y!
    assert x.shape[1] == y.shape[0]
    # This operation returns a vector of 0s with as many rows as x.
    z = np.zeros(x.shape[0])
    for i in range(x.shape[0]):
        for j in range(x.shape[1]):
            z[i] += x[i, j] * y[j]
    return z
</code></pre>
</figure>

<p>You could also reuse the code we wrote previously, which highlights the
relationship between a matrix-vector product and a vector product:</p>
<figure>
<pre><code class="language-python">def naive_matrix_vector_product(x, y):
    z = np.zeros(x.shape[0])
    for i in range(x.shape[0]):
        z[i] = naive_vector_product(x[i, :], y)
    return z
</code></pre>
</figure>

<p>Note that as soon as one of the two tensors has an <code>ndim</code> greater than 1,
<code>matmul</code> is no longer <em>symmetric</em>, which is to say that <code>matmul(x, y)</code> isn’t
the same as <code>matmul(y, x)</code>.</p>
<p>Of course, a tensor product generalizes to tensors with an arbitrary number
of axes. The most common applications may be the product between
two matrices. You can take the product of two matrices <code>x</code> and <code>y</code>
(<code>matmul(x, y)</code>) if and only if <code>x.shape[1] == y.shape[0]</code>.
The result is a matrix with shape <code>(x.shape[0], y.shape[1])</code>,
where the coefficients are the vector products between the rows of <code>x</code>
and the columns of <code>y</code>. Here’s the naive implementation:</p>
<figure>
<pre><code class="language-python">def naive_matrix_product(x, y):
    # x and y are NumPy matrices.
    assert len(x.shape) == 2
    assert len(y.shape) == 2
    # The 1st dimension of x must equal the 0th dimension of y!
    assert x.shape[1] == y.shape[0]
    # This operation returns a matrix of 0s with a specific shape.
    z = np.zeros((x.shape[0], y.shape[1]))
    # Iterates over the rows of x ...
    for i in range(x.shape[0]):
        # ... and over the columns of y.
        for j in range(y.shape[1]):
            row_x = x[i, :]
            column_y = y[:, j]
            z[i, j] = naive_vector_product(row_x, column_y)
    return z
</code></pre>
</figure>

<p>To understand vector product shape compatibility, it helps to visualize the input
and output tensors by aligning them as shown in figure 2.5.</p>
<figure id="figure-2-5">
<img src="../Images/427de72c442fcb4c5ccaffb0d3494196.png" data-original-src="https://deeplearningwithpython.io/images/ch02/matrix_dot_box_diagram.3dc0f796.png"/>
<figcaption>
<a href="#figure-2-5">Figure 2.5</a>: Matrix product box diagram
</figcaption>
</figure>

<p><code>x</code>, <code>y</code>, and <code>z</code> are pictured as rectangles (literal boxes of coefficients).
Because the rows of <code>x</code> and the columns of <code>y</code> must have the same size,
it follows that the width of <code>x</code> must match the height of <code>y</code>.
If you go on to develop new machine learning algorithms,
you’ll likely be drawing such diagrams often.</p>
<p>More generally, you can take the product between higher-dimensional
tensors, following the same rules for shape compatibility as outlined
earlier for the 2D case:</p>
<figure>
<pre><code class="language-text">(a, b, c, d) • (d,) -&gt; (a, b, c)
(a, b, c, d) • (d, e) -&gt; (a, b, c, e)
</code></pre>
</figure>

<p>And so on.</p>
<h3 id="tensor-reshaping">Tensor reshaping</h3>
<p>A third type of tensor operation
that’s essential to understand is <em>tensor reshaping</em>. Although it wasn’t
used in the <code>Dense</code> layers in our first neural network example,
we used it when we preprocessed the digits data before feeding it
into our model:</p>
<figure>
<pre><code class="language-python">train_images = train_images.reshape((60000, 28 * 28))
</code></pre>
</figure>

<p>Reshaping a tensor means rearranging its rows and columns to match
a target shape. Naturally, the reshaped tensor has the same total number
of coefficients as the initial tensor. Reshaping is best understood via
simple examples:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; x = np.array([[0., 1.],
...               [2., 3.],
...               [4., 5.]])
&gt;&gt;&gt; x.shape</code>
<code class="language-output">(3, 2)</code>
<code class="language-python">&gt;&gt;&gt; x = x.reshape((6, 1))
&gt;&gt;&gt; x</code>
<code class="language-output">array([[ 0.],
       [ 1.],
       [ 2.],
       [ 3.],
       [ 4.],
       [ 5.]])</code>
<code class="language-python">&gt;&gt;&gt; x = x.reshape((2, 3))
&gt;&gt;&gt; x</code>
<code class="language-output">array([[ 0.,  1.,  2.],
       [ 3.,  4.,  5.]])</code></pre>
</figure>

<p>A special case of reshaping that’s commonly encountered is <em>transposition</em>.
<em>Transposing</em> a matrix means exchanging its rows and its columns,
so that <code>x[i, :]</code> becomes <code>x[:, i]</code>:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; # Creates an all-zeros matrix of shape (300, 20)
&gt;&gt;&gt; x = np.zeros((300, 20))
&gt;&gt;&gt; x = np.transpose(x)
&gt;&gt;&gt; x.shape</code>
<code class="language-output">(20, 300)</code></pre>
</figure>

<h3 id="geometric-interpretation-of-tensor-operations">Geometric interpretation of tensor operations</h3>
<p>Because the contents of the tensors manipulated by tensor operations
can be interpreted as coordinates of points in some geometric space,
all tensor operations have a geometric interpretation. For instance,
let’s consider addition. We’ll start with the following vector:</p>
<figure>
<pre><code class="language-text">A = [0.5, 1]
</code></pre>
</figure>

<p>It’s a point in a 2D space (see figure 2.6). It’s common to picture
a vector as an arrow linking the origin to the point, as shown in figure 2.7.</p>
<figure id="figure-2-6" class="extra-small-image">
<img src="../Images/8370de16886742a4b122e13e32778178.png" data-original-src="https://deeplearningwithpython.io/images/ch02/geometric_interpretation_1.4c2c1983.png"/>
<figcaption>
<a href="#figure-2-6">Figure 2.6</a>: A point in a 2D space
</figcaption>
</figure>

<figure id="figure-2-7" class="extra-small-image">
<img src="../Images/74b9e8f5e514269bd15480a4f8304517.png" data-original-src="https://deeplearningwithpython.io/images/ch02/geometric_interpretation_2.e635ec60.png"/>
<figcaption>
<a href="#figure-2-7">Figure 2.7</a>: A point in a 2D space pictured as an arrow
</figcaption>
</figure>

<p>Let’s consider a new point, <code>B = [1, 0.25]</code>, which we’ll add to the
previous one. This is done geometrically by chaining together the vector arrows,
with the resulting location being the vector representing the sum of
the previous two vectors (see figure 2.8). As you can see, adding a vector <code>B</code>
to a vector <code>A</code> represents the action of copying point <code>A</code> in new location, whose
distance and direction from the original point <code>A</code> is determined by the vector <code>B</code>.
If you apply the same vector addition to a group of points in the plane (an “object”),
you would be creating a copy of the entire object in a new location (see figure 2.9).
Tensor addition thus represents
the action of <em>translating an object</em> (moving the object without distorting it)
by a certain amount in a certain direction.</p>
<figure id="figure-2-8" class="extra-small-image">
<img src="../Images/4a18a2152ec2122893e0f7236c60551d.png" data-original-src="https://deeplearningwithpython.io/images/ch02/geometric_interpretation_3.b1b80fb9.png"/>
<figcaption>
<a href="#figure-2-8">Figure 2.8</a>: Geometric interpretation of the sum of two vectors
</figcaption>
</figure>

<p>In general, elementary geometric operations, such as translation,
rotation, scaling, skewing, and so on, can be expressed as tensor operations.
Here are a few examples:</p>
<ul>
<li><em>Translation</em> — As you just saw, adding a vector to a point will
move this point by a fixed amount in a fixed direction.
Applied to a set of points (such as a 2D object),
this is called a “translation” (see figure 2.9).</li>
</ul>
<figure id="figure-2-9">
<img src="../Images/f15d6633cdde4a5a8da26f7be58dd28e.png" data-original-src="https://deeplearningwithpython.io/images/ch02/translation.c123da84.png"/>
<figcaption>
<a href="#figure-2-9">Figure 2.9</a>: 2D translation as a vector addition
</figcaption>
</figure>

<ul>
<li><em>Rotation</em> — A counterclockwise rotation of a 2D vector by an angle theta (see figure 2.10)
can be achieved via a product with a 2 × 2 matrix
<code>R = [[cos(theta), -sin(theta)], [sin(theta), cos(theta)]]</code>.</li>
</ul>
<figure id="figure-2-10">
<img src="../Images/51a9fb59643fffa14559f2c9cc179ae7.png" data-original-src="https://deeplearningwithpython.io/images/ch02/rotation.8f4da7c4.png"/>
<figcaption>
<a href="#figure-2-10">Figure 2.10</a>: 2D rotation (counterclockwise) as a matrix product
</figcaption>
</figure>

<ul>
<li><em>Scaling</em> — A vertical and horizontal scaling of the image (see figure 2.11)
can be achieved via a product with a 2 × 2 matrix
<code>S = [[horizontal_factor, 0], [0, vertical_factor]]</code> (note that such a matrix
is called a “diagonal matrix” because it only has non-zero coefficients
in its “diagonal,” going from the top left to the bottom right).</li>
</ul>
<figure id="figure-2-11">
<img src="../Images/9d8aa8155ed97d32b0ce2348b521abb4.png" data-original-src="https://deeplearningwithpython.io/images/ch02/scaling.8cca5e17.png"/>
<figcaption>
<a href="#figure-2-11">Figure 2.11</a>: 2D scaling as a matrix product
</figcaption>
</figure>

<ul>
<li><em>Linear transform</em> — A product with an arbitrary matrix implements a
linear transform. Note that <em>scaling</em> and <em>rotation</em>, seen previously,
are, by definition, linear transforms.</li>
</ul>
<ul>
<li><em>Affine transform</em> — An affine transform (see figure 2.12)
is the combination of a linear transform (achieved via a matrix product)
and a translation (achieved via a vector addition).
As you have probably recognized, that’s exactly the <code>y = W @ x + b</code> computation
implemented by the <code>Dense</code> layer! A <code>Dense</code> layer without an activation function
is an affine layer.</li>
</ul>
<figure id="figure-2-12">
<img src="../Images/7511f20f34bb90da31011c4deeb7b51d.png" data-original-src="https://deeplearningwithpython.io/images/ch02/affine_transform.80be4403.png"/>
<figcaption>
<a href="#figure-2-12">Figure 2.12</a>: Affine transform in the plane
</figcaption>
</figure>

<ul>
<li><em><code>Dense</code> layer with <code>relu</code> activation</em> — An important observation about affine
transforms is that if you apply many of them repeatedly,
you still end up with an affine transform (so you could just have
applied that one affine transform in the first place). Let’s try it with two:
<code>affine2(affine1(x)) = W2 @ (W1 @ x + b1) + b2 = (W2 @ W1) @ x + (W2 @ b1 + b2)</code>.
That’s an affine transform where the linear part is the matrix <code>W2 @ W1</code> and the
translation part is the vector <code>W2 @ b1 + b2</code>. As a consequence, a multilayer
neural network made entirely of <code>Dense</code> layers without activations would be
equivalent to a single <code>Dense</code> layer. This “deep” neural network would just
be a linear model in disguise!
This is why we need activation functions, like <code>relu</code> (seen in action
in figure 2.13). Thanks to activation functions,
a chain of <code>Dense</code> layers can be made to implement very complex,
nonlinear geometric transformation, resulting in very rich hypothesis spaces
for your deep neural networks.
We cover this idea in more detail in the next chapter.</li>
</ul>
<figure id="figure-2-13">
<img src="../Images/590aae2bc7fbd5a8e3f8d8a16535c6d7.png" data-original-src="https://deeplearningwithpython.io/images/ch02/dense_transform.d8a02328.png"/>
<figcaption>
<a href="#figure-2-13">Figure 2.13</a>: Affine transform followed by <code>relu</code> activation
</figcaption>
</figure>

<h3 id="a-geometric-interpretation-of-deep-learning">A geometric interpretation of deep learning</h3>
<p>You just learned that neural networks consist entirely of chains of
tensor operations and that all of these tensor operations are just simple
geometric transformations of the input data. It follows that you can interpret
a neural network as a very complex geometric transformation in a
high-dimensional space, implemented via a series of simple steps.</p>
<p>In 3D, the following mental image may prove useful. Imagine two sheets of
colored paper: one red and one blue. Put one on top of the other.
Now crumple them together into a small ball. That crumpled paper ball
is your input data, and each sheet of paper is a class of data in
a classification problem. What a neural network
is meant to do is figure out a
transformation of the paper ball that would uncrumple it to make the
two classes cleanly separable again (see figure 2.14). With deep learning, this would be
implemented as a series of simple transformations of the 3D space,
such as those you could apply on the paper ball with your fingers,
one movement at a time.</p>
<figure id="figure-2-14">
<img src="../Images/a89f2451feb6a78d99e009be13583d1b.png" data-original-src="https://deeplearningwithpython.io/images/ch02/geometric_interpretation_4.f8123b83.png"/>
<figcaption>
<a href="#figure-2-14">Figure 2.14</a>: Uncrumpling a complicated manifold of data
</figcaption>
</figure>

<p>Uncrumpling paper balls is what machine learning is about: finding neat
representations for complex, highly folded data <em>manifolds</em> in high-dimensional
spaces (a manifold is a continuous surface, like our crumpled sheet of paper).
At this point, you should have a pretty good intuition
as to why deep learning excels at this:
it takes the approach of incrementally decomposing a complicated geometric
transformation into a long chain of elementary ones, which is pretty much
the strategy a human would follow to uncrumple a paper ball. Each layer in a
deep network applies a transformation that disentangles the data a little —
and a deep stack of layers makes tractable an extremely
complicated disentanglement process.</p>
<h2 id="the-engine-of-neural-networks-gradient-based-optimization">The engine of neural networks: Gradient-based optimization</h2>
<p>As you saw in the previous section, each neural layer from our first model
example transforms its input data as follows:</p>
<figure>
<pre><code class="language-python">output = relu(matmul(input, W) + b)
</code></pre>
</figure>

<p>In this expression, <code>W</code> and <code>b</code> are tensors that are attributes of the layer.
They’re called the <em>weights</em> or <em>trainable parameters</em> of the layer
(the <code>kernel</code> and <code>bias</code> attributes, respectively). These weights contain the
information learned by the model from exposure to training data.</p>
<p>Initially, these weight matrices are filled with small random values
(a step called <em>random initialization</em>). Of course, there’s no reason to
expect that <code>relu(matmul(input, W) + b)</code>, when <code>W</code> and <code>b</code> are random,
will yield any useful representations. The resulting representations are
meaningless — but they’re a starting point. What comes next is to gradually
adjust these weights, based on a feedback signal. This gradual adjustment,
also called <em>training</em>, is basically the learning that machine learning
is all about.</p>
<p>This happens within what’s called a <em>training loop</em>, which works as follows.
Repeat these steps in a loop, until the loss seems sufficiently low:</p>
<ol>
<li>Draw a batch of training samples <code>x</code> and corresponding targets <code>y_true</code>.</li>
<li>Run the model on <code>x</code> (a step called the <em>forward pass</em>) to obtain
predictions <code>y_pred</code>.</li>
<li>Compute the loss of the model on the batch, a measure of the mismatch
between <code>y_pred</code> and <code>y_true</code>.</li>
<li>Update all weights of the model in a way that slightly reduces the loss
on this batch.</li>
</ol>
<p>You’ll eventually end up with a model that has a very low loss on its
training data: a low mismatch between predictions <code>y_pred</code> and expected targets
<code>y_true</code>. The model has “learned” to map its inputs to correct targets.
From afar, it may look like magic, but when you reduce it to elementary steps,
it turns out to be simple.</p>
<p>Step 1 sounds easy enough — it’s just I/O code. Steps 2 and 3 are merely
the application of a handful of tensor operations, so you could implement
these steps purely from what you learned in the previous section.
The difficult part is step 4: updating the model’s weights.
Given an individual weight coefficient in the model, how can you compute
whether the coefficient should be increased or decreased, and by how much?</p>
<p>One naive solution would be to freeze all weights in the model except
the one scalar coefficient being considered and try different values
for this coefficient. Let’s say the initial value of the coefficient is 0.3.
After the forward pass on a batch of data, the loss of the model on the batch
is 0.5. If you change the coefficient’s value to 0.35 and rerun
the forward pass, the loss increases to 0.6. But if you lower the coefficient
to 0.25, the loss falls to 0.4. In this case, it seems that updating
the coefficient by –0.05 would contribute to minimizing the loss.
This would have to be repeated for all coefficients in the model.</p>
<p>But such an approach would be horribly inefficient because you’d need to
compute two forward passes (which are expensive)
for every individual coefficient
(of which there are many, usually at least a few thousands and potentially up to billions).
Thankfully, there’s a much better approach: <em>gradient descent</em>.</p>
<p>Gradient descent is the optimization technique that powers modern neural networks.
Here’s the gist of it. All of the functions used in
our models (such as <code>matmul</code> or <code>+</code>)
transform their input in a smooth and continuous way: if you look at <code>z = x + y</code>,
for instance,
a small change in <code>y</code> only results in a small change in <code>z</code>, and if you know the
direction of the change in <code>y</code>, you can infer the direction of the change in <code>z</code>.
Mathematically, you’d say these functions are <em>differentiable</em>. If you chain
together such functions, the bigger function you obtain is still differentiable.
In particular, this applies to the function that maps the model’s coefficients
to the loss of the model on a batch of data:
a small change of the model’s coefficients
results in a small, predictable change of the loss value. This enables you to
use a mathematical operator called the <em>gradient</em>
to describe how the loss varies as you move the model’s coefficients
in different directions. If you compute this gradient, you can use it to move
the coefficients (all at once in a single update, rather than one at a time)
in a direction that decreases the loss.</p>
<p>If you already know what <em>differentiable</em> means and what a <em>gradient</em> is, you
can skip the next two sections. Otherwise, the following will help you
understand these concepts.</p>
<h3 id="whats-a-derivative">What’s a derivative?</h3>
<p>Consider a continuous, smooth function <code>f(x) = y</code>, mapping a number <code>x</code>
to a new number <code>y</code>. We can use the function in figure 2.15 as an example.</p>
<figure id="figure-2-15">
<img src="../Images/8d3545d0422fdaf9095c76724c8232d6.png" data-original-src="https://deeplearningwithpython.io/images/ch02/function.4b000cb3.png"/>
<figcaption>
<a href="#figure-2-15">Figure 2.15</a>: A continuous, smooth function
</figcaption>
</figure>

<p>Because the function is <em>continuous</em>, a small change
in <code>x</code> can only result in a small change in <code>y</code> — that’s the intuition behind
<em>continuity</em>. Let’s say you increase <code>x</code> by a small factor <code>epsilon_x</code>:
this results in a small <code>epsilon_y</code> change to <code>y</code>, as shown in figure 2.16.</p>
<figure id="figure-2-16">
<img src="../Images/01e3045f3bc6976160217e7eaa54dadb.png" data-original-src="https://deeplearningwithpython.io/images/ch02/continuity.98fd80b7.png"/>
<figcaption>
<a href="#figure-2-16">Figure 2.16</a>: With a continuous function, a small change in <code>x</code> results in a small change in <code>y</code>.
</figcaption>
</figure>

<p>In addition, because the function is <em>smooth</em>
(its curve doesn’t have any abrupt angles), when <code>epsilon_x</code> is small enough,
around a certain point <code>p</code>, it’s possible to approximate <code>f</code> as
a linear function of slope <code>a</code>, so that <code>epsilon_y</code> becomes <code>a * epsilon_x</code>:</p>
<figure>
<pre><code class="language-text">f(x + epsilon_x) = y + a * epsilon_x
</code></pre>
</figure>

<p>Obviously, this linear approximation is valid only when <code>x</code>
is close enough to <code>p</code>.</p>
<p>The slope <code>a</code> is called the <em>derivative</em> of <code>f</code> in <code>p</code>. If <code>a</code> is negative,
it means a small increase in <code>x</code> around <code>p</code> will result in a decrease of <code>f(x)</code>,
as shown in figure 2.17, and if <code>a</code> is positive, a small increase in <code>x</code>
will result in an increase of <code>f(x)</code>. Further, the absolute value of <code>a</code>
(the <em>magnitude</em> of the derivative) tells you how quickly this increase or
decrease will happen.</p>
<figure id="figure-2-17">
<img src="../Images/8065a8a76ddc704f79e261b220833dd0.png" data-original-src="https://deeplearningwithpython.io/images/ch02/derivation.306de198.png"/>
<figcaption>
<a href="#figure-2-17">Figure 2.17</a>: Derivative of <code>f</code> in <code>p</code>
</figcaption>
</figure>

<p>For every differentiable function <code>f(x)</code> (<em>differentiable</em> means
“can be derived”: for example, smooth, continuous functions can be derived),
there exists a derivative function <code>f'(x)</code> that maps values of <code>x</code> to the
slope of the local linear approximation of <code>f</code> in those points. For instance,
the derivative of <code>cos(x)</code> is <code>-sin(x)</code>, the derivative of
<code>f(x) = a * x</code> is <code>f'(x) = a</code>, and so on.</p>
<p>Being able to derive functions is a very powerful tool when it comes to
<em>optimization</em>, the task of finding values of <code>x</code> that minimize the value of <code>f(x)</code>.
If you’re trying to update <code>x</code> by a factor <code>epsilon_x</code>
to minimize <code>f(x)</code> and you know the derivative of <code>f</code>,
then your job is done: the derivative completely describes how <code>f(x)</code>
evolves as you change <code>x</code>. If you want to reduce the value of <code>f(x)</code>, you just
need to move <code>x</code> a little in the opposite direction from the derivative.</p>
<h3 id="derivative-of-a-tensor-operation-the-gradient">Derivative of a tensor operation: The gradient</h3>
<p>The function we were just looking at turned a scalar value <code>x</code> into another scalar
value <code>y</code>: you could plot it as a curve in a 2D plane. Now, imagine a function that turns
a tuple of scalars <code>(x, y)</code> into a scalar value <code>z</code>: that would be a vector operation.
You could plot it as a 2D <em>surface</em> in a 3D space (indexed by coordinates <code>x, y, z</code>).
Likewise, you can imagine functions that take as input matrices, functions that
take as input rank-3 tensors, etc.</p>
<p>The concept of derivation can be applied to
any such function, as long as the surfaces they describe are continuous and smooth.
The derivative of a tensor operation (or tensor function)
is called a <em>gradient</em>. Gradients are just the generalization
of the concept of derivatives to functions that take tensors as inputs. Remember
how, for a scalar function, the derivative represents the <em>local slope</em> of the curve
of the function? In just the same way, the gradient of a tensor function represents the
<em>curvature</em> of the multidimensional surface described by the function.
It characterizes how the output of the function varies when its input parameters vary.</p>
<p>Let’s look at an example grounded in machine learning. Consider</p>
<ul>
<li>An input vector <code>x</code> (a sample in a dataset)</li>
<li>A matrix <code>W</code> (the weights of a model)</li>
<li>A target <code>y_true</code> (what the model should learn to associated to <code>x</code>)</li>
<li>A loss function <code>loss</code> (meant to measure the gap between the model’s current predictions and <code>y_true</code>).</li>
</ul>
<p>You can use <code>W</code> to compute a target candidate <code>y_pred</code> and then compute the
loss, or mismatch, between the target candidate <code>y_pred</code> and the target <code>y_true</code>:</p>
<figure>
<pre><code class="language-python"># We use the model weights W to make a prediction for x.
y_pred = matmul(x, W)
# We estimate how far off the prediction was.
loss_value = loss(y_pred, y_true)
</code></pre>
</figure>

<p>Now, we’d like to use gradients to figure out how
to update <code>W</code> to make <code>loss_value</code> smaller. How do we do that?</p>
<p>Given fixed inputs <code>x</code> and <code>y_true</code>, the previous operations can be interpreted as
a function mapping values of <code>W</code> (the model’s weights) to loss values:</p>
<figure>
<pre><code class="language-python"># f describes the curve (or high-dimensional surface) formed by loss
# values when W varies.
loss_value = f(W)
</code></pre>
</figure>

<p>Let’s say the current value of <code>W</code> is <code>W0</code>. Then the derivative of <code>f</code>
in the point <code>W0</code> is a tensor <code>grad(loss_value, W0)</code>, with the same shape as <code>W</code>,
where each coefficient <code>grad(loss_value, W0)[i, j]</code> indicates the direction and
magnitude of the change in <code>loss_value</code> you observe when modifying <code>W0[i, j]</code>.
That tensor <code>grad(loss_value, W0)</code> is the gradient of the function
<code>f(W) = loss_value</code> in <code>W0</code>, also called “gradient of <code>loss_value</code> with respect
to <code>W</code> around <code>W0</code>.”</p>
<aside>
<p>The tensor operation <code>grad(f(W), W)</code>
(which takes as input a matrix <code>W</code>)
can be expressed as a combination of scalar functions
<code>grad_ij(f(W), w_ij)</code>, each
of which would return the derivative of <code>loss_value = f(W)</code> with respect to the
coefficient <code>W[i, j]</code> of <code>W</code>, assuming all other coefficients are constant.
<code>grad_ij</code> is called the <em>partial derivative</em> of <code>f</code> with respect to <code>W[i, j]</code>.</p>
</aside>

<p>Concretely, what does <code>grad(loss_value, W0)</code> represent?
You saw earlier that the derivative
of a function <code>f(x)</code> of a single coefficient
can be interpreted as the slope of the curve of <code>f</code>. Likewise,
<code>grad(loss_value, W0)</code>
can be interpreted as the tensor describing the <em>curvature</em>
of <code>loss_value = f(W)</code> around <code>W0</code>. Each partial derivative describes the
curvature of <code>f</code> in a specific direction.</p>
<p>We just saw how for a function <code>f(x)</code>, you can reduce the value of <code>f(x)</code> by moving <code>x</code> a little
in the opposite direction from the derivative. In much the same way, with a
function <code>f(W)</code> of a tensor, you can reduce <code>loss_value = f(W)</code> by moving <code>W</code>
in the opposite direction from the gradient, such as an update of
<code>W1 = W0 - step * grad(f(W0), W0)</code> where <code>step</code> is a small scaling factor. That means going against
the curvature, which intuitively should put you lower on the curve.
Note that the scaling factor <code>step</code> is needed because <code>grad(loss_value, W0)</code>
only approximates the curvature when you’re close to <code>W0</code>,
so you don’t want to get too far from <code>W0</code>.</p>
<h3 id="stochastic-gradient-descent">Stochastic gradient descent</h3>
<p>Given a differentiable function,
it’s theoretically possible to find its minimum analytically: it’s known that
a function’s minimum is a point where the derivative is 0, so all you have
to do is find all the points where the derivative goes to 0 and check
for which of these points the function has the lowest value.</p>
<p>Applied to a neural network, that means finding analytically the combination
of weight values that yields the smallest possible loss function. This can
be done by solving the equation <code>grad(f(W), W) = 0</code> for <code>W</code>. This is a
polynomial equation of <code>N</code> variables, where <code>N</code> is the number of coefficients
in the model. Although it would be possible to solve such an equation
for <code>N = 2</code> or <code>N = 3</code>, doing so is intractable for real neural networks,
where the number of parameters is never less than a few thousand
and can sometimes be in the billions.</p>
<p>Instead, you can use the four-step algorithm outlined at the beginning of
this section: modify the parameters little by little based on the current
loss value on a random batch of data. Because you’re dealing with a
differentiable function, you can compute its gradient, which gives
you an efficient way to implement step 4. If you update the weights
in the opposite direction from the gradient, the loss will be a little
less every time:</p>
<ol>
<li>Draw a batch of training samples <code>x</code> and corresponding targets <code>y_true</code>.</li>
<li>Run the model on <code>x</code> to obtain predictions <code>y_pred</code>
 (this is called the <em>forward pass</em>).</li>
<li>Compute the loss of the model on the batch, a measure of the
 mismatch between <code>y_pred</code> and <code>y_true</code>.</li>
<li>Compute the gradient of the loss with regard to the model’s
 parameters (this is called the <em>backward pass</em>).</li>
<li>Move the parameters a little in the opposite direction from the gradient —
 for example, <code>W -= learning_rate * gradient</code> —
 thus reducing the loss on the batch a bit. The <em>learning rate</em> (<code>learning_rate</code>
 here) would be a scalar factor modulating the “speed” of the
 gradient descent process.</li>
</ol>
<p>Easy enough! What we just described is called
<em>mini-batch stochastic gradient descent</em> (mini-batch SGD).
The term <em>stochastic</em> refers to the fact that each batch of data is drawn
at random (<em>stochastic</em> is a scientific synonym of <em>random</em>).
Figure 2.18 illustrates what happens in 1D, when the model has only
one parameter and you have only one training sample.</p>
<figure id="figure-2-18" class="small-image">
<img src="../Images/3f02512a56330ac15723ca25881d1bef.png" data-original-src="https://deeplearningwithpython.io/images/ch02/sgd_explained_1.0535e152.png"/>
<figcaption>
<a href="#figure-2-18">Figure 2.18</a>: SGD down a 1D loss curve (one learnable parameter)
</figcaption>
</figure>

<p>We can see intuitively that it’s important to pick a reasonable value
for the <code>learning_rate</code> factor. If it’s too small, the descent down the curve will
take many iterations, and it could get stuck in a local minimum.
If <code>learning_rate</code> is too large, your updates may end up taking you to completely
random locations on the curve.</p>
<p>Note that a variant of the mini-batch SGD algorithm would be to draw
a single sample and target at each iteration, rather than drawing
a batch of data. This would be <em>true</em> SGD (as opposed to <em>mini-batch</em> SGD).
Alternatively, going to the opposite extreme, you could run every step
on <em>all</em> data available, which is called <em>batch gradient descent</em>.
Each update would then be more accurate, but far more expensive.
The efficient compromise between these two extremes is to use mini-batches
of reasonable size.</p>
<p>Although figure 2.18 illustrates gradient descent in a 1D parameter space,
in practice, you’ll use gradient descent in highly dimensional spaces:
every weight coefficient in a neural network is a free dimension in the space,
and there may be tens of thousands or even millions of them. To help you
build intuition about loss surfaces, you can also visualize gradient
descent along a 2D loss surface, as shown in figure 2.19. But you can’t
possibly visualize what the actual process of training a neural network
looks like — you can’t represent a 1,000,000-dimensional space in a way
that makes sense to humans. As such, it’s good to keep in mind that the
intuitions you develop through these low-dimensional representations
may not always be accurate in practice. This has historically been
a source of issues in the world of deep learning research.</p>
<figure id="figure-2-19">
<img src="../Images/1c85eb817b782179fdc04f55a0e07216.png" data-original-src="https://deeplearningwithpython.io/images/ch02/gradient_descent_3d.85d77c73.png"/>
<figcaption>
<a href="#figure-2-19">Figure 2.19</a>: Gradient descent down a 2D loss surface (two learnable parameters)
</figcaption>
</figure>

<p>Additionally, there exist multiple variants of SGD that differ by taking
into account previous weight updates when computing the next weight update,
rather than just looking at the current value of the gradients. There is,
for instance, SGD with momentum, as well as Adagrad, RMSprop,
and several others. Such variants are known as <em>optimization methods</em> or
<em>optimizers</em>. In particular, the concept of <em>momentum</em>, which is used
in many of these variants, deserves your attention. Momentum addresses
two issues with SGD: convergence speed and local minima. Consider figure 2.20,
which shows the curve of a loss as a function of a model parameter.</p>
<figure id="figure-2-20">
<img src="../Images/df34e7802f1b473d8a0c90c565ff11c2.png" data-original-src="https://deeplearningwithpython.io/images/ch02/global_minimum.8f000c0a.png"/>
<figcaption>
<a href="#figure-2-20">Figure 2.20</a>: A local minimum and a global minimum
</figcaption>
</figure>

<p>As you can see, around a certain parameter value, there is a <em>local minimum</em>:
around that point, moving left would result in the loss increasing,
but so would moving right. If the parameter under consideration were
being optimized via SGD with a small learning rate, then the optimization
process would get stuck at the local minimum instead of making its way to
the global minimum.</p>
<p>You can avoid such issues by using momentum, which draws inspiration
from physics. A useful mental image here is to think of the optimization
process as a small ball rolling down the loss curve. If it has enough momentum,
the ball won’t get stuck in a ravine and will end up at the global minimum.
Momentum is implemented by moving the ball at each step based not only
on the current slope value (current acceleration) but also on the
current velocity (resulting from past acceleration). In practice, this means
updating the parameter <code>w</code> based not only on the current gradient value but
also on the previous parameter update, such as in this naive implementation:</p>
<figure>
<pre><code class="language-python">past_velocity = 0.0
# Constant momentum factor
momentum = 0.1
# Optimization loop
while loss &gt; 0.01:
    w, loss, gradient = get_current_parameters()
    velocity = past_velocity * momentum - learning_rate * gradient
    w = w + momentum * velocity - learning_rate * gradient
    past_velocity = velocity
    update_parameter(w)
</code></pre>
</figure>

<h3 id="chaining-derivatives-the-backpropagation-algorithm">Chaining derivatives: The Backpropagation algorithm</h3>
<p>In the previously discussed algorithm, we casually assumed that because a function is
differentiable, we can easily compute its gradient. But is that true? How can we
compute the gradient of complex expressions in practice?
In our two-layer network example, how can we get the gradient of the loss with
regard to the weights? That’s where the <em>Backpropagation algorithm</em> comes in.</p>
<h4 id="the-chain-rule">The chain rule</h4>
<p>Backpropagation is a way to use the derivative of simple operations
(such as addition, <code>relu</code>, or tensor product) to easily compute the gradient
of arbitrarily complex combinations of these atomic operations.
Crucially, a neural network consists of many tensor operations
chained together, each of which has a simple, known derivative. For instance,
the model from our first example can be expressed as a function
parameterized by the variables <code>W1</code>, <code>b1</code>, <code>W2</code>, and <code>b2</code>
(belonging to the first and second <code>Dense</code> layers, respectively), involving
the atomic operations <code>matmul</code>, <code>relu</code>, <code>softmax</code>, and <code>+</code>, as well as our
loss function, <code>loss</code>, which are all easily differentiable:</p>
<figure>
<pre><code class="language-python">loss_value = loss(
    y_true,
    softmax(matmul(relu(matmul(inputs, W1) + b1), W2) + b2),
)
</code></pre>
</figure>

<p>Calculus tells us that such a chain of functions can be derived using
the following identity, called the <em>chain rule</em>. 
Consider two functions <code>f</code> and <code>g</code>, as well as the composed function
<code>fg</code> such that <code>y = fg(x) == f(g(x))</code>:</p>
<figure>
<pre><code class="language-python">def fg(x):
    x1 = g(x)
    y = f(x1)
    return y
</code></pre>
</figure>

<p>Then the chain rule states that <code>grad(y, x) == grad(y, x1) * grad(x1, x)</code>.
This enables you to compute the derivative of <code>fg</code> as long as you know
the derivatives of <code>f</code> and <code>g</code>.
The chain rule is named like this because when you add more intermediate
functions, it starts looking like a chain:</p>
<figure>
<pre><code class="language-python">def fghj(x):
    x1 = j(x)
    x2 = h(x1)
    x3 = g(x2)
    y = f(x3)
    return y

grad(y, x) == grad(y, x3) * grad(x3, x2) * grad(x2, x1) * grad(x1, x)
</code></pre>
</figure>

<p>Applying the chain rule to the computation of the gradient values of a
neural network gives rise to an algorithm called <em>backpropagation</em>.
Let’s see how that works, concretely.</p>
<h4 id="automatic-differentiation-with-computation-graphs">Automatic differentiation with computation graphs</h4>
<p>A useful way to think about backpropagation is in terms of <em>computation graphs</em>.
A computation graph is the data structure at the heart of the deep learning revolution.
It’s a directed acyclic graph of operations — in our case, tensor operations.
For instance, figure 2.21 is the graph representation of our first model.</p>
<figure id="figure-2-21" class="small-image">
<img src="../Images/edddc5625b92a1730fb68e9f303cd6a9.png" data-original-src="https://deeplearningwithpython.io/images/ch02/a_first_computation_graph.90dec1fc.png"/>
<figcaption>
<a href="#figure-2-21">Figure 2.21</a>: The computation graph representation of our two-layer model
</figcaption>
</figure>

<p>Computation graphs have been an extremely successful abstraction in
computer science because they enable us to <em>treat computation as data</em>:
a computable expression is encoded as a machine-readable data structure
that can be used as the input or output of another program. For instance,
you could imagine a program that receives a computation graph and returns
a new computation graph that implements a large-scale distributed version
of the same computation — this would mean that you could distribute
any computation without having to write the distribution logic yourself. Or
imagine ... a program that receives a computation graph and can automatically
generate the derivative of the expression it represents. It’s much easier to do
these things if your computation is expressed as an explicit graph
data structure rather than, say, lines of ASCII characters in a <code>.py</code> file.</p>
<p>To explain backpropagation clearly,
let’s look at a really basic example of a computation graph.
We’ll consider a simplified version of the graph in figure 2.21, where we only have one
linear layer and where all variables are scalar, shown in figure 2.22. We’ll take two scalar variables
<code>w</code>, <code>b</code>, a scalar input <code>x</code>,
and apply some operations to them to combine into an output <code>y</code>. Finally,
we’ll apply an absolute value error loss function:
<code>loss_val = abs(y_true - y)</code>. Since we want to update <code>w</code> and <code>b</code> in a way
that would minimize <code>loss_val</code>, we are interested in computing
<code>grad(loss_val, b)</code> and <code>grad(loss_val, w)</code>.</p>
<figure id="figure-2-22" class="extra-small-image">
<img src="../Images/9e863c770b4807b5b36699d4e777d49e.png" data-original-src="https://deeplearningwithpython.io/images/ch02/basic_computation_graph.f3e3c75a.png"/>
<figcaption>
<a href="#figure-2-22">Figure 2.22</a>: A basic example of a computation graph
</figcaption>
</figure>

<p>Let’s set concrete values for the “input nodes” in the graph —
that is, the input <code>x</code>, the target <code>y_true</code>, <code>w</code> and <code>b</code> (figure 2.23).
We propagate these values to all nodes in the graph, from top to bottom,
until we reach <code>loss_val</code>. This is the <em>forward pass</em>.</p>
<figure id="figure-2-23" class="extra-small-image">
<img src="../Images/27324b2738a199602ed527c7e8e06c56.png" data-original-src="https://deeplearningwithpython.io/images/ch02/basic_computation_graph_with_values.e15cd230.png"/>
<figcaption>
<a href="#figure-2-23">Figure 2.23</a>: Running a forward pass
</figcaption>
</figure>

<p>Now let’s “reverse” the graph: for each edge in the graph going from <code>A</code>
to <code>B</code>, we will create an opposite edge from <code>B</code> to <code>A</code>, and ask, “How much does
<code>B</code> vary when <code>A</code> varies?” That is, what is <code>grad(B, A)</code>? We’ll annotate
each inverted edge with this value (figure 2.24).
This backward graph represents the <em>backward pass</em>.</p>
<figure id="figure-2-24" class="small-image">
<img src="../Images/48e99f7d7c2a6e1f6517e5ee25b92f3e.png" data-original-src="https://deeplearningwithpython.io/images/ch02/basic_computation_graph_backward.9e975200.png"/>
<figcaption>
<a href="#figure-2-24">Figure 2.24</a>: Running a backward pass
</figcaption>
</figure>

<p>We have</p>
<ul>
<li><code>grad(loss_val, x2) = 1</code> because as <code>x2</code> varies by an amount epsilon,
<code>loss_val = abs(4 - x2)</code> varies by the same amount.</li>
<li><code>grad(x2, x1) = 1</code> because as <code>x1</code> varies by an amount epsilon,
<code>x2 = x1 + b = x1 + 1</code> varies by the same amount.</li>
<li><code>grad(x2, b) = 1</code> because as <code>b</code> varies by an amount epsilon,
<code>x2 = x1 + b = 6 + b</code> varies by the same amount.</li>
<li><code>grad(x1, w) = 2</code>  because as <code>w</code> varies by an amount epsilon,
<code>x1 = x * w = 2 * w</code> varies by <code>2 * epsilon</code>.</li>
</ul>
<p>What the chain rule says about this backward graph is that you can obtain
the derivative of a node with respect to another node by
<em>multiplying the derivatives for each edge along the path linking the two nodes</em>.
For instance,
<code>grad(loss_val, w) = grad(loss_val, x2) * grad(x2, x1) * grad(x1, w)</code>.</p>
<figure id="figure-2-25" class="small-image">
<img src="../Images/7e87e6dc72a5695f31469a3a176a50f1.png" data-original-src="https://deeplearningwithpython.io/images/ch02/path_in_backward_graph.fe91e7d0.png"/>
<figcaption>
<a href="#figure-2-25">Figure 2.25</a>: Path from <code>loss_val</code> to <code>w</code> in the backward graph
</figcaption>
</figure>

<p>By applying the chain rule to our graph, we obtain what we were looking for:</p>
<ul>
<li><code>grad(loss_val, w) = 1 * 1 * 2 = 2</code></li>
<li><code>grad(loss_val, b) = 1 * 1 = 1</code></li>
</ul>
<aside>
<p>If there are multiple paths linking the two nodes of interest <code>a</code>, <code>b</code>
in the backward graph, we would obtain <code>grad(b, a)</code> by summing
the contributions of all the paths.</p>
</aside>

<p>And with that, you just saw backpropagation in action!
Backpropagation is simply the application of the chain rule to a
computation graph. There’s nothing more to it.
Backpropagation starts with the final loss value and works backward from
the top layers to the bottom layers, computing the contribution that each
parameter had in the loss value. That’s where the name “backpropagation”
comes from: we “back propagate” the loss contributions of different nodes
in a computation graph.</p>
<p>Nowadays, people implement neural networks in modern
frameworks that are capable of <em>automatic differentiation</em>, such as JAX, TensorFlow, and PyTorch.
Automatic differentiation is implemented with the
kind of computation graph previously presented. Automatic differentiation makes
it possible to retrieve the gradients of arbitrary compositions of
differentiable tensor operations without doing any extra work besides
writing down the forward pass. When I wrote my first neural networks in C in the
2000s, I had to write my gradients by hand. Now, thanks to modern automatic
differentiation tools, you’ll never have to implement backpropagation yourself.
Consider yourself lucky!</p>
<h2 id="looking-back-at-our-first-example">Looking back at our first example</h2>
<p>You’re nearing the end of this chapter, and you should now have a general
understanding of what’s going on behind the scenes in a neural network.
What was a magical black box at the start of the chapter has turned into
a clearer picture, as illustrated in figure 2.26: the model,
composed of layers that are chained together, maps the input data to
predictions. The loss function then compares these predictions to the targets,
producing a loss value: a measure of how well the model’s predictions match
what was expected. The optimizer uses this loss value to update the model’s
weights.</p>
<figure id="figure-2-26" class="small-image">
<img src="../Images/dd2bc218f52709e83d164144484ab53c.png" data-original-src="https://deeplearningwithpython.io/images/ch02/deep-learning-in-3-figures-3_alt.40aa865d.png"/>
<figcaption>
<a href="#figure-2-26">Figure 2.26</a>: Relationship between the network, layers, loss function, and optimizer
</figcaption>
</figure>

<p>Let’s go back to the first example and review each piece of it in the light of
what you’ve learned in the previous sections.</p>
<p>This was the input data:</p>
<figure>
<pre><code class="language-python">(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
train_images = train_images.reshape((60000, 28 * 28))
train_images = train_images.astype("float32") / 255
test_images = test_images.reshape((10000, 28 * 28))
test_images = test_images.astype("float32") / 255
</code></pre>
</figure>

<p>Now you understand that the input images are stored in NumPy tensors,
which are here formatted as <code>float32</code> tensors of shape <code>(60000, 784)</code>
(training data) and <code>(10000, 784)</code> (test data), respectively.</p>
<p>This was our model:</p>
<figure>
<pre><code class="language-python">model = keras.Sequential(
    [
        layers.Dense(512, activation="relu"),
        layers.Dense(10, activation="softmax"),
    ]
)
</code></pre>
</figure>

<p>Now you understand that this model consists of a chain of two <code>Dense</code> layers,
that each layer applies a few simple tensor operations to the input data,
and that these operations involve weight tensors. Weight tensors, which
are attributes of the layers, are where the <em>knowledge</em> of the model persists.</p>
<p>This was the model-compilation step:</p>
<figure>
<pre><code class="language-python">model.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"],
)
</code></pre>
</figure>

<p>Now you understand that <code>"sparse_categorical_crossentropy"</code> is the loss function
that’s used as a feedback signal for learning the weight tensors, which
the training phase will attempt to minimize. You also know that this reduction
of the loss happens via mini-batch stochastic gradient descent.
The exact rules governing a specific use of gradient descent are defined
by the <code>"adam"</code> optimizer passed as the first argument.</p>
<p>Finally, this was the training loop:</p>
<figure>
<pre><code class="language-python">model.fit(
    train_images,
    train_labels,
    epochs=5,
    batch_size=128,
)
</code></pre>
</figure>

<p>Now you understand what happens when you call <code>fit</code>: the model will start
to iterate on the training data in mini-batches of 128 samples,
5 times over (each iteration over all the training data is called an <em>epoch</em>).
For each batch, the model will compute the gradient of the loss
with regard to the weights (using the Backpropagation algorithm, which derives
from the chain rule in calculus) and move the weights in the direction
that will reduce the value of the loss for this batch.</p>
<p>After these 5 epochs, the model will have performed 2,345 gradient updates
(469 per epoch), and the loss of the model will be sufficiently low that
the model will be capable of classifying handwritten digits
with high accuracy.</p>
<p>At this point, you already know most of what there is to know
about neural networks. Let’s prove it by reimplementing a simplified version
of that first example step by step, using only low-level operations.</p>
<h3 id="reimplementing-our-first-example-from-scratch">Reimplementing our first example from scratch</h3>
<p>What’s better to demonstrate full, unambiguous understanding than to implement
everything from scratch? Of course, what “from scratch” means here is relative:
we won’t reimplement basic tensor operations,
and we won’t implement backpropagation.
But we’ll go to such a low level that each computation step will be made explicit.</p>
<p>Don’t worry if you don’t understand every little detail in this example just yet.
The next chapter will dive in more detail into the Keras API. For now,
just try to follow the gist of what’s going on — the intent of this example is
to help crystallize your understanding of the mathematics of deep learning using
a concrete implementation. Let’s go!</p>
<h4 id="a-simple-dense-class">A simple Dense class</h4>
<p>You’ve learned earlier that the <code>Dense</code> layer implements the following
input transformation, where <code>W</code> and <code>b</code> are model parameters, and <code>activation</code>
is an element-wise function (usually <code>relu</code>):</p>
<figure>
<pre><code class="language-python">output = activation(matmul(input, W) + b)
</code></pre>
</figure>

<p>Let’s implement a simple Python class <code>NaiveDense</code> that creates two Keras
variables <code>W</code> and <code>b</code>, and exposes a <code>__call__()</code> method
that applies the previous transformation:</p>
<figure>
<pre><code class="language-python"># keras.ops is where you will find all the tensor operations you need.
import keras
from keras import ops

class NaiveDense:
    def __init__(self, input_size, output_size, activation=None):
        self.activation = activation
        self.W = keras.Variable(
            # Creates a matrix W of shape (input_size, output_size),
            # initialized with random values drawn from a uniform
            # distribution
            shape=(input_size, output_size), initializer="uniform"
        )
        # Creates a vector b of shape (output_size,), initialized with
        # zeros
        self.b = keras.Variable(shape=(output_size,), initializer="zeros")

    # Applies the forward pass
    def __call__(self, inputs):
        x = ops.matmul(inputs, self.W)
        x = x + self.b
        if self.activation is not None:
            x = self.activation(x)
        return x

    @property
    # The convenience method for retrieving the layer's weights
    def weights(self):
        return [self.W, self.b]
</code></pre>
</figure>

<h4 id="a-simple-sequential-class">A simple Sequential class</h4>
<p>Now, let’s create a <code>NaiveSequential</code> class to chain these layers. It wraps a list
of layers and exposes a <code>__call__()</code> method that simply calls the underlying
layers on the inputs, in order. It also features a <code>weights</code> property to easily
keep track of the layers’ parameters:</p>
<figure>
<pre><code class="language-python">class NaiveSequential:
    def __init__(self, layers):
        self.layers = layers

    def __call__(self, inputs):
        x = inputs
        for layer in self.layers:
            x = layer(x)
        return x

    @property
    def weights(self):
        weights = []
        for layer in self.layers:
            weights += layer.weights
        return weights
</code></pre>
</figure>

<p>Using this <code>NaiveDense</code> class and this <code>NaiveSequential</code> class, we can create
a mock Keras model:</p>
<figure>
<pre><code class="language-python">model = NaiveSequential(
    [
        NaiveDense(input_size=28 * 28, output_size=512, activation=ops.relu),
        NaiveDense(input_size=512, output_size=10, activation=ops.softmax),
    ]
)
assert len(model.weights) == 4
</code></pre>
</figure>

<h4 id="a-batch-generator">A batch generator</h4>
<p>Next, we need a way to iterate over the MNIST data in mini-batches. This is easy:</p>
<figure>
<pre><code class="language-python">import math

class BatchGenerator:
    def __init__(self, images, labels, batch_size=128):
        assert len(images) == len(labels)
        self.index = 0
        self.images = images
        self.labels = labels
        self.batch_size = batch_size
        self.num_batches = math.ceil(len(images) / batch_size)

    def next(self):
        images = self.images[self.index : self.index + self.batch_size]
        labels = self.labels[self.index : self.index + self.batch_size]
        self.index += self.batch_size
        return images, labels
</code></pre>
</figure>

<h3 id="running-one-training-step">Running one training step</h3>
<p>The most difficult part of the process is the “training step”: updating
the weights of the model after running it on one batch of data. We need to</p>
<ul>
<li>Compute the predictions of the model for the images in the batch</li>
<li>Compute the loss value for these predictions given the actual labels</li>
<li>Compute the gradient of the loss with regard to the model’s weights</li>
<li>Move the weights by a small amount in the direction opposite to the gradient</li>
</ul>
<figure id="listing-2-9">
<pre><code class="language-python">def one_training_step(model, images_batch, labels_batch):
    # Runs the "forward pass"
    predictions = model(images_batch)
    loss = ops.sparse_categorical_crossentropy(labels_batch, predictions)
    average_loss = ops.mean(loss)
    # Computes the gradient of the loss with regard to the weights. The
    # output, gradients, is a list where each entry corresponds to a
    # weight from the model.weights list. We haven't defined this
    # function yet!
    gradients = get_gradients_of_loss_wrt_weights(loss, model.weights)
    # Updates the weights using the gradients. We haven't defined this
    # function yet!
    update_weights(gradients, model.weights)
    return loss
</code></pre>
<figcaption>
<a href="#listing-2-9">Listing 2.9</a>: A single step of training
</figcaption>
</figure>

<h4 id="the-weight-update-step">The weight update step</h4>
<p>As you already know, the purpose of the “weight update” step
(represented by the <code>update_weights()</code> function) is to
move the weights by “a bit” in a direction that will reduce the loss on this
batch. The magnitude of the move is determined by the “learning rate,” typically
a small quantity. The simplest way to implement this <code>update_weights()</code> function
is to subtract <code>gradient * learning_rate</code> from each weight:</p>
<figure>
<pre><code class="language-python">learning_rate = 1e-3

def update_weights(gradients, weights):
    for g, w in zip(gradients, weights):
        # Assigns a new value to the variable, in place
        w.assign(w - g * learning_rate)
</code></pre>
</figure>

<p>In practice, you will almost never implement a weight update step like this by
hand. Instead, you would use an <code>Optimizer</code> instance from Keras — like this:</p>
<figure>
<pre><code class="language-python">from keras import optimizers

optimizer = optimizers.SGD(learning_rate=1e-3)

def update_weights(gradients, weights):
    optimizer.apply_gradients(zip(gradients, weights))
</code></pre>
</figure>

<h4 id="gradient-computation">Gradient computation</h4>
<p>Now, there’s just one thing we’re still missing: gradient computation
(represented by the <code>get_gradients_of_loss_wrt_weights()</code> function in listing 2.9). In the previous section,
we outlined how we could use the chain rule to obtain the gradients of a chain of functions
given their individual derivatives, a process known as backpropagation. We could reimplement
backpropagation from scratch here, but that would be rather cumbersome, especially since
we’re using a <code>softmax</code> operation and a crossentropy loss, which have fairly verbose derivatives.</p>
<p>Instead, we can rely on the automatic differentiation mechanism that’s built into one of the low-level
frameworks supported by Keras, such as TensorFlow, JAX, or PyTorch. For the sake of the example, let’s go with
TensorFlow here. You’ll learn more about TensorFlow, JAX, and PyTorch in the next chapter.</p>
<p>The API through which you can use TensorFlow’s
automatic differentiation capabilities is the <code>tf.GradientTape</code> object.
It’s a Python scope that will “record” the tensor operations that run
inside it, in the form of a computation graph (sometimes called a <em>tape</em>).
This graph can then be used to retrieve the gradient
of any scalar value with respect to any set of input values:</p>
<figure>
<pre><code class="language-python">import tensorflow as tf

# Instantiates a scalar tensor with value 0
x = tf.zeros(shape=())
# Opens a GradientTape scope
with tf.GradientTape() as tape:
    # Inside the scope, applies some tensor operations to our variable
    y = 2 * x + 3
# Uses the tape to retrieve the gradient of the output y with respect
# to our variable x
grad_of_y_wrt_x = tape.gradient(y, x)
</code></pre>
</figure>

<p>Let’s rewrite our function <code>one_training_step()</code> using the TensorFlow <code>GradientTape</code>
(skipping the need for a separate <code>get_gradients_of_loss_wrt_weights()</code> function):</p>
<figure>
<pre><code class="language-python">def one_training_step(model, images_batch, labels_batch):
    with tf.GradientTape() as tape:
        predictions = model(images_batch)
        loss = ops.sparse_categorical_crossentropy(labels_batch, predictions)
        average_loss = ops.mean(loss)
    gradients = tape.gradient(average_loss, model.weights)
    update_weights(gradients, model.weights)
    return average_loss
</code></pre>
</figure>

<p>Now that our per-batch training step is ready, we can move on to implementing
an entire epoch of training.</p>
<h3 id="the-full-training-loop">The full training loop</h3>
<p>An epoch of training simply consists of the repetition of the training step
for each batch in the training data, and the full training loop is simply
the repetition of one epoch:</p>
<figure>
<pre><code class="language-python">def fit(model, images, labels, epochs, batch_size=128):
    for epoch_counter in range(epochs):
        print(f"Epoch {epoch_counter}")
        batch_generator = BatchGenerator(images, labels)
        for batch_counter in range(batch_generator.num_batches):
            images_batch, labels_batch = batch_generator.next()
            loss = one_training_step(model, images_batch, labels_batch)
            if batch_counter % 100 == 0:
                print(f"loss at batch {batch_counter}: {loss:.2f}")
</code></pre>
</figure>

<p>Let’s test-drive it:</p>
<figure>
<pre><code class="language-python">from keras.datasets import mnist

(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

train_images = train_images.reshape((60000, 28 * 28))
train_images = train_images.astype("float32") / 255
test_images = test_images.reshape((10000, 28 * 28))
test_images = test_images.astype("float32") / 255

fit(model, train_images, train_labels, epochs=10, batch_size=128)
</code></pre>
</figure>

<h3 id="evaluating-the-model">Evaluating the model</h3>
<p>We can evaluate the model by taking the <code>argmax</code> of its predictions
over the test images, and comparing it to the expected labels:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; predictions = model(test_images)
&gt;&gt;&gt; predicted_labels = ops.argmax(predictions, axis=1)
&gt;&gt;&gt; matches = predicted_labels == test_labels
&gt;&gt;&gt; f"accuracy: {ops.mean(matches):.2f}"</code>
<code class="language-output">accuracy: 0.83</code></pre>
</figure>

<p>All done! As you can see, it’s quite a bit of work to do “by hand” what you
can do in a few lines of Keras code. But because you’ve gone through these
steps, you should now have a crystal-clear understanding of what goes on inside
a neural network when you call <code>fit()</code>. Having this low-level mental model
of what your code is doing behind the scenes will make you better able to
take advantage of the high-level features of the Keras API.</p>
<h2 id="summary">Summary</h2>
<ul>
<li><em>Tensors</em> form the foundation of modern machine learning systems. They come in
various flavors of <code>dtype</code>, <code>rank</code>, and <code>shape</code>.</li>
</ul>
<ul>
<li>You can manipulate numerical tensors via <em>tensor operations</em>
  (such as addition, tensor product, or element-wise multiplication),
  which can be interpreted as encoding geometric transformations. In
  general, everything in deep learning is amenable to a geometric interpretation.</li>
</ul>
<ul>
<li>Deep learning models consist of chains of simple tensor operations, parameterized
by <em>weights</em>, which are themselves tensors. The weights of a model are where
its “knowledge” is stored.</li>
</ul>
<ul>
<li><em>Learning</em> means finding a set of values for the model’s weights
 that minimizes a <em>loss function</em> for a given set of training data samples
 and their corresponding targets.</li>
</ul>
<ul>
<li>Learning happens by drawing random batches of data samples and their targets
and computing the gradient of the model parameters with respect to the loss
on the batch. The model parameters are then moved a bit
(the magnitude of the move is defined by the learning rate)
in the opposite direction from the gradient.
This is called <em>mini-batch gradient descent</em>.</li>
</ul>
<ul>
<li>The entire learning process is made possible by the fact that all tensor
operations in neural networks are differentiable, and thus
it’s possible to apply the chain rule of derivation to find the gradient
function mapping the current parameters and current batch
of data to a gradient value. This is called <em>backpropagation</em>.</li>
</ul>
<ul>
<li>Two key concepts you’ll see frequently in future chapters are <em>loss</em> and
<em>optimizers</em>. These are the two things you need to define before you begin
feeding data into a model:<ul>
<li>The <em>loss</em> is the quantity you’ll attempt to minimize during training,
so it should represent a measure of success for the task you’re trying to solve.</li>
<li>The <em>optimizer</em> specifies the exact way in which the gradient of the loss
will be used to update parameters:
for instance, it could be the RMSProp optimizer, SGD with momentum, and so on.</li>
</ul>
</li>
</ul>
    
</body>
</html>