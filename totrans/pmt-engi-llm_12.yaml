- en: Chapter 9\. LLM Workflows
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章. LLM工作流程
- en: Classic machine learning models were typically competent at only *one* skill
    in *one* domain—sentiment analysis of tweets, fraud detection from credit card
    transactions, translating text from English to French, and the like. With the
    advent of GPT models, a single model can now perform an enormous variety of tasks
    from seemingly any domain.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 经典的机器学习模型通常只擅长一个领域中的一个技能——例如，对推文的情感分析、从信用卡交易中检测欺诈、将英语翻译成法语等。随着GPT模型的问世，一个模型现在可以执行来自看似任何领域的无数种任务。
- en: But even though model quality has improved tremendously since GPT-2, we are
    nowhere near the point of creating artificial general intelligence, (AGI), which
    is an AI that meets or exceeds human-level cognition. When we do create AGI, it
    will have the ability to assimilate knowledge, reason about it, solve novel and
    complex problems, and even generate new knowledge. AGI will use humanlike creativity
    to address real-world problems in any domain.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管自从GPT-2以来模型质量有了巨大的提升，但我们离创造通用人工智能（AGI）还相去甚远，AGI是一种达到或超过人类认知水平的AI。当我们最终创造AGI时，它将能够吸收知识，对其进行分析，解决新颖和复杂的问题，甚至生成新的知识。AGI将使用类似人类的创造力来解决任何领域的现实世界问题。
- en: In contrast, today’s LLMs show marked deficiencies in reasoning and problem-solving
    and are especially bad at mathematics, a critical component of scientific discovery.
    Text they generate demonstrates a vast understanding of existing knowledge, but
    rarely does it introduce anything new. And outside of training, these models are
    incapable of learning new information. Future AGI, by definition, will possess
    both *strength* (the ability to solve complex problems) and *generality* (the
    ability to solve problems in any domain). But with current LLMs, there seems to
    be a trade-off between these two aspects of intelligence (see [Figure 9-1](#ch09_figure_1_1728407155631009)).
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，今天的LLMs在推理和问题解决方面表现出明显的不足，尤其是在数学方面，而数学是科学发现的一个关键组成部分。它们生成的文本展示了广泛的知识理解，但很少引入任何新内容。而且，在训练之外，这些模型无法学习新信息。未来的AGI，按照定义，将具备两种*优势*（解决复杂问题的能力）和*通用性*（在任何领域解决问题的能力）。但就目前的LLMs而言，似乎在智能的这两个方面之间存在权衡（参见[图9-1](#ch09_figure_1_1728407155631009)）。
- en: At one end of the spectrum is a conversational agent, as introduced in the last
    chapter. At the extreme, a pure chat application such as ChatGPT is *extremely*
    general—it will talk with you about anything you’d like. But it won’t solve complex
    tasks for you. If you craft the agent’s system message for a particular domain
    and equip it with a set of tools for that domain, then the agent becomes less
    general but more capable of accomplishing tasks within that narrower domain. Nevertheless,
    conversational agents are still best at tasks that involve only one or two steps
    at a time, with assistance from the user who is actually trying to get work done.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在光谱的一端是上一章中介绍过的对话代理。在极端情况下，像ChatGPT这样的纯聊天应用*极其*通用——它可以与你谈论你感兴趣的一切。但它不会为你解决复杂任务。如果你为特定领域定制代理的系统消息，并为其配备该领域的工具集，那么代理将变得不那么通用，但更擅长在该更窄领域内完成任务。尽管如此，对话代理仍然最适合涉及一次或两次步骤的任务，并且需要用户的实际帮助来完成工作。
- en: In this chapter, we’ll travel farther along this spectrum, trading off some
    generality in exchange for the ability to complete more complicated tasks. We’ll
    introduce LLM workflows, which improve strength by focusing the domain and building
    a more rigid structure to guide the LLM’s decisions. With LLM workflows, you break
    down a large task into small, well-defined tasks that can be executed with high
    fidelity. A supervisor process (which might or might not make use of an LLM) coordinates
    the tasks, distributes work, collects results, and moves through a flow designed
    to achieve the desired result. A workflow will not handle arbitrary user requests.
    Instead, it is designed for a specific task, and it will therefore be more capable
    of completing that task than a conversational agent would be.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将沿着这个光谱进一步探索，为了完成更复杂的任务，我们将在一些通用性上进行权衡。我们将介绍LLM工作流程，通过聚焦领域和构建更严格的框架来引导LLM的决策，从而提高其能力。使用LLM工作流程，你可以将一个大任务分解成小而明确的任务，这些任务可以以高保真度执行。一个管理过程（可能使用也可能不使用LLM）协调任务，分配工作，收集结果，并通过一个旨在实现预期结果的工作流程进行操作。工作流程不会处理任意用户请求。相反，它是为特定任务设计的，因此它将比对话代理更有能力完成该任务。
- en: '![](assets/pefl_0901.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/pefl_0901.png)'
- en: Figure 9-1\. LLMs are both more powerful and more general than classic machine
    learning, but they have not reached AGI; instead, there is a trade-off between
    generality and strength
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-1\. LLMs比经典机器学习更强大、更通用，但它们还没有达到AGI；相反，在通用性和强度之间存在权衡
- en: Note that this chapter mostly avoids discussion of existing LLM frameworks—LangChain,
    Semantic Kernel, AutoGen, DSPy, and others. Rather than get into nitty-gritty
    implementation details, this chapter keeps the discussion high level. You should
    be able to take the approaches here and implement them in any framework you wish,
    or, as we sometimes recommend, no framework at all!
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，本章主要避免讨论现有的LLM框架——LangChain、Semantic Kernel、AutoGen、DSPy等。而不是深入到具体的实现细节，本章保持讨论的宏观层面。你应该能够将这里的方法应用到任何你想要的框架中，或者，正如我们有时推荐的那样，根本不需要任何框架！
- en: Would a Conversational Agent Suffice?
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对话代理是否足够？
- en: Before digging into workflow agency, let’s consider what would happen if you
    attempted to use conversational agency to achieve more and more complex tasks.
    We’ll introduce an example in this section, and once we’ve demonstrated how the
    wheels fall off, we’ll come back to this example throughout the rest of the chapter.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨工作流程代理之前，让我们考虑一下，如果你尝试使用对话代理来完成更多更复杂的任务会发生什么。我们将在本节中介绍一个例子，一旦我们展示了车轮如何掉落，我们将在本章的其余部分回到这个例子。
- en: 'Let’s say you work at a boutique software development firm that builds Shopify
    storefront plug-ins. Business is slow, so you get the crazy idea to build an LLM
    application that generates plug-in ideas and promotes them to storefront owners.
    Here’s how you might do it:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你在一间精品软件开发公司工作，该公司构建Shopify店面插件。生意清淡，所以你有了这样一个疯狂的想法：构建一个LLM应用，生成插件想法并将其推广给店面所有者。以下是你可以这样做的方式：
- en: Generate a list of popular Shopify storefronts and retrieve their website HTMLs.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成一份流行的Shopify店面列表并检索它们的网站HTML。
- en: For each storefront, extract details—product offering, branding, style, values,
    etc.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个店面，提取详细信息——产品提供、品牌、风格、价值观等。
- en: Review each storefront and come up with a plug-in that would benefit its business.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 审查每个店面并提出一个能对其业务有益的插件。
- en: Generate marketing emails advertising the plug-in concept to each storefront
    owner.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每位店面所有者生成推广插件概念的营销邮件。
- en: Send the emails.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送邮件。
- en: This sounds like a pretty nutty idea, right? You’re basically blasting out emails
    for software products that don’t exist yet! Can an LLM application actually accomplish
    work like this? Would it be good enough that people might even email you back?
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这听起来像是一个非常疯狂的想法，对吧？你基本上是在为尚未存在的软件产品发送邮件！LLM应用真的能完成这样的工作吗？它是否足够好，以至于人们可能会回邮件给你？
- en: The answer is a definitive yes. In early 2023, as the entire world started grappling
    with the new power and possibilities of LLM applications, one entrepreneurial
    developer did just this (see [Figure 9-2](#ch09_figure_2_1728407155631048)).
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是肯定的。2023年初，当整个世界开始应对LLM应用的新力量和可能性时，一位创业开发者就是这样做的（见图9-2）。
- en: The thread went on to reveal some really impressive anecdotes—thousands of marketing
    emails sent at the push of a button, some really creative product ideas, and some
    eager responses from real site owners. The best GPT-4-generated idea was for a
    sock store. It was a web page called Sock-cess Stories (see [Figure 9-3](#ch09_figure_3_1728407155631072)).
    You have to admit that it’s a great sales pitch.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这个话题继续揭示了一些真正令人印象深刻的轶事——一键发送数千封营销邮件，一些真正有创意的产品想法，以及一些来自真实网站所有者的热切回应。最好的GPT-4生成的想法是为一家袜子店。这是一个名为Sock-cess
    Stories的网页（见图9-3）。你必须承认，这是一个很好的销售方案。
- en: '![A screenshot of a social media post  Description automatically generated](assets/pefl_0902.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![社交媒体帖子的截图  自动生成的描述](assets/pefl_0902.png)'
- en: Figure 9-2\. Spencer introduces his buddy Umar’s spectacular LLM innovation
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-2\. 斯宾塞介绍了他的朋友乌马尔令人瞩目的LLM创新
- en: '![A screenshot of a black screen  Description automatically generated](assets/pefl_0903.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![黑色屏幕的截图  自动生成的描述](assets/pefl_0903.png)'
- en: Figure 9-3\. An LLM-generated promotional email that knocked my socks of
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-3\. 一个让我目瞪口呆的LLM生成的促销邮件
- en: 'But can you achieve this with a conversational agent? Let’s start off with
    the simplest possibility, a conversational agent with no tools, and the following
    open-ended system message: “You are a helpful assistant. You can do anything—*you
    just have to believe*.” On the generality to strength spectrum outlined in the
    introduction, this agent is *completely* general and terribly weak.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 但你能用对话代理实现这一点吗？让我们从最简单的情况开始，一个没有任何工具的对话代理，以及以下开放式的系统消息：“你是一个有用的助手。你可以做任何事情——*你只需要相信*。”在引言中概述的通用性到强度的光谱上，这个代理是*完全*通用的，但非常弱。
- en: To kick off the Shopify task, you could simply pass in the list of instructions
    as a user message—something along the lines of “Scrape a bunch of Shopify storefronts,
    think of new plug-ins for each, and then send each storefront a promotional email
    about the idea.” The result, which I won’t bother you with here, is not terribly
    useful. Ultimately, the assistant tells you that it can’t search the web, browse
    specific websites, or send emails. Instead, it generates a hypothetical plan for
    what *you* should do, which is little more than an elaboration on your original
    instructions.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动Shopify任务，你可以简单地将指令列表作为用户消息传递——类似于“抓取大量Shopify店面，为每个店面想出新的插件，然后为每个店面发送关于这个想法的推广电子邮件。”结果，这里就不赘述了，并不十分有用。最终，助手告诉你它不能搜索网络、浏览特定网站或发送电子邮件。相反，它为你生成一个假设的计划，这几乎只是对你原始指示的详细阐述。
- en: 'It’s obvious that this couldn’t possibly work, but you can give your agent
    some tools to help it get better results. Namely, give it the tools it asked for:
    `search_web`, `browse_site`, and `send_email`. This is slightly less general in
    that you’ve narrowed the domain from “literally anything” to “something web-related,”
    but it’s more powerful because the agent can now reach out into the real world.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，这不可能奏效，但你可以为你的代理提供一些工具来帮助它获得更好的结果。具体来说，给它它所请求的工具：`search_web`、`browse_site`
    和 `send_email`。这稍微不那么通用，因为你已经将范围从“实际上任何东西”缩小到“与网络相关的东西”，但它的功能更强大，因为代理现在可以触及现实世界。
- en: If you run the same request with this better-equipped conversational agent,
    you will again be disappointed. The approach for gathering candidate storefronts
    is naive—it will submit a simple web search for “best Shopify storefronts 2024,”
    generate several tersely described plug-ins,” and generate an email that is little
    more than a form letter that literally includes `[your_name]`—and, unless you’re
    really lucky, all that `send_email` will do is spam potential customers with very
    poor marketing.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你用这个设备更完善的对话代理再次运行相同的请求，你还是会感到失望。收集候选店面店面的方法很天真——它将提交一个简单的网络搜索“2024年最佳Shopify店面”，生成几个简短描述的插件”，并生成一封电子邮件，这封电子邮件几乎就是一封形式化的信件，实际上包括了
    `[你的名字]`——除非你真的很幸运，否则 `send_email` 所能做的只是向潜在客户发送非常糟糕的营销邮件。
- en: But let’s not give up just yet; let’s push the conversational agent further
    toward strength and away from generality. Rather than asking the agent to perform
    this work for you, move the instructions into the system message—thus making this
    a very narrowly defined agent. Make sure to provide very specific detail in your
    system message covering all of the problematic aspects just mentioned. You might
    also choose to give the agent more helpful tools tailored to this specific work,
    each with its own descriptions and details. But as you do this, you’re making
    trade-offs. The combination of the system message and the tools is going to make
    the base prompt larger and more complicated, and that’s likely to leave the agent
    distracted and confused as its task becomes longer.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们还没有放弃；让我们进一步推动对话代理向力量靠近，而不是通向通用性。与其要求代理为你完成这项工作，不如将指示移入系统消息中——这样就将这个代理定义得非常狭窄。确保在系统消息中提供非常具体的细节，涵盖刚才提到的所有问题方面。你也可以选择为代理提供更多针对这项具体工作的有帮助的工具，每个工具都有其自己的描述和细节。但在这个过程中，你正在做出权衡。系统消息和工具的结合将使基本提示更大、更复杂，这可能会让代理在任务变得更长时感到分心和困惑。
- en: Really, it’s even worse than this. The conversational agent doesn’t provide
    an easy way to process units of work. Shoveling them all in at once will spell
    disaster, and doing them one at a time is going to require you to set up a queue—so
    you already know you’re going to have to build *something* more complicated than
    a conversational agent. And since the agent has some freedom in how it accomplishes
    the work, then when something fails, what do you do to fix it? The system message
    is basically a strong suggestion and nothing more.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，情况甚至更糟。对话代理没有提供一种简单的方式来处理工作单元。一次性将它们全部塞进去将是一场灾难，而逐个处理它们将需要你设置一个队列——所以你已经知道你将不得不构建比对话代理更复杂的“某种东西”。而且由于代理在完成工作时有某种自由度，那么当某件事失败时，你该如何修复它？系统消息基本上是一个强烈的建议，没有更多。
- en: These negative results showcase the need for more structure. Conversational
    agents are not appropriate for such complicated workstreams. Instead, every step
    in this agent’s process should be isolated and defined as its own specialized
    task, and the full set of tasks should be assembled into a workflow. In the remainder
    of this chapter, we’ll see how our purposes are better served by workflows.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这些负面结果展示了更多结构的需求。对话代理不适合这样的复杂工作流。相反，这个代理的每个步骤都应该被隔离并定义为它自己的专用任务，并将所有任务组合成一个工作流程。在本章的剩余部分，我们将看到工作流程如何更好地服务于我们的目的。
- en: Basic LLM Workflows
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基本LLM工作流程
- en: In the latter half of this chapter, we’ll discuss a workflow in which the driver
    of the tasks is an LLM. In this section, we’ll discuss the more common LLM workflows
    pattern, in which each task is likely to make use of an LLM but the overarching
    workflow is just a traditional, no-frills workflow that is driven by passing work
    items from each task to its connected downstream tasks.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的后半部分，我们将讨论一个任务驱动器为LLM的工作流程。在本节中，我们将讨论更常见的LLM工作流程模式，其中每个任务可能都会使用LLM，但总体工作流程只是一个传统的、无装饰的工作流程，它通过将工作项从每个任务传递到其连接的下游任务来驱动。
- en: 'As shown in [Figure 9-4](#ch09_figure_4_1728407155631094), the steps required
    to build a basic workflow are as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图9-4](#ch09_figure_4_1728407155631094)所示，构建基本工作流程所需的步骤如下：
- en: '*Define goal*. Identify the purpose of the workflow. What is the desired output
    or desired change that the workflow will accomplish?'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*定义目标*。确定工作流程的目的。工作流程将实现什么样的预期输出或预期变化？'
- en: '*Specify tasks*. Break the workflow down into a set of tasks that, when executed
    in proper order, will achieve your goal. For LLM-based tasks, consider the tools
    that each task will need. Also identify each task’s inputs and outputs.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*指定任务*。将工作流程分解成一系列任务，当按正确顺序执行时，将实现你的目标。对于基于LLM的任务，考虑每个任务将需要的工具。还要确定每个任务的输入和输出。'
- en: '*Implement tasks*. Build the tasks as specified. Make sure input and output
    are clearly defined. Ensure that each task works correctly in isolation.'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*实施任务*。按照指定构建任务。确保输入和输出定义清晰。确保每个任务在独立情况下都能正确工作。'
- en: '*Implement workflow*. Connect the tasks into a complete workflow. If necessary,
    adjust tasks to ensure they function correctly in the context of the full workflow.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*实施工作流程*。将任务连接成一个完整的工作流程。如有必要，调整任务以确保它们在完整工作流程的上下文中正确运行。'
- en: '*Optimize workflow*. Optimize tasks to improve quality, performance, and cost.'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*优化工作流程*。优化任务以提高质量、性能和成本。'
- en: '![](assets/pefl_0904.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/pefl_0904.png)'
- en: Figure 9-4\. The workflow for building workflows…you gotta love meta humor!
  id: totrans-40
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-4\. 构建工作流程的工作流程……你不得不爱这种元幽默！
- en: The reason that a workflow is so appealing is because it is modular. Because
    we are breaking a complex problem into its components, it’s easier to build; when
    something breaks, it’s easier to reason about and isolate the problem.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流程之所以如此吸引人，是因为它是模块化的。因为我们正在将复杂问题分解为其组成部分，所以更容易构建；当某件事出错时，更容易推理和隔离问题。
- en: 'Let’s return to the Shopify plug-in promoter and walk through the steps it
    would take to build a successful LLM workflow. We have already defined the goal:
    build an LLM application that generates plug-in ideas and promotes them to storefront
    owners. In the next section, we’ll talk about steps 2 and 3, specifying and implementing
    tasks.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到Shopify插件推广插件，并逐步说明构建成功的LLM工作流程所需的步骤。我们已经定义了目标：构建一个LLM应用程序，生成插件想法并将其推广给店面所有者。在下一节中，我们将讨论步骤2和3，即指定和实施任务。
- en: Tasks
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 任务
- en: 'The second step of creating a workflow is specifying tasks. Let’s just use
    the tasks we already came up with when we introduced the Shopify example:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 创建工作流的第二步是指定任务。让我们只使用我们在介绍Shopify示例时已经提出的任务：
- en: Generate a list of popular Shopify storefronts and retrieve their website HTMLs.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成一份流行的Shopify店面列表，并检索它们的网站HTML。
- en: For each storefront, extract details—product offering, branding, style, values,
    etc.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于每个店面，提取详细信息——产品提供、品牌、风格、价值观等。
- en: Review each storefront and come up with a plug-in that would benefit their business.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 审查每个店面，并提出一个能对其业务有益的插件。
- en: Generate marketing emails advertising the plug-in concept to each storefront
    owner.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每个店面生成推广插件概念的营销电子邮件。
- en: Send the emails.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送电子邮件。
- en: Now, let’s move on to step 3—implementing the tasks. The word *tasks* is a familiar
    term—tasks are substeps of the overall goal. Tasks may be purely algorithmic and
    implemented using traditional software practices, or tasks can be implemented
    using LLMs.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们进入第3步——实现任务。*任务*这个词是一个熟悉的术语——任务是整体目标的子步骤。任务可能是纯算法性的，并使用传统的软件实践实现，或者任务可以使用LLMs实现。
- en: In the completed workflow, tasks will be connected to one another so that the
    output of one task will serve as input into the next. Therefore, the input and
    output of each task must be well defined. What information is required for a task
    to achieve its purpose? What information will it provide as output? Are the inputs
    and outputs structured or free-form text? And if the items are structured, then
    what is their schema?
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成的流程中，任务将相互连接，以便一个任务的输出将成为下一个任务的输入。因此，每个任务的输入和输出必须定义良好。完成任务需要哪些信息？它将提供哪些输出信息？输入和输出是有结构的文本还是自由形式的文本？如果是结构化的，那么它们的架构是什么？
- en: Let’s look at the email generation task in the Shopify example. The input should
    be an idea for a plug-in, but you should make it more specific. Let’s use the
    schema defined in [Table 9-1](#ch09_table_1_1728407155641491).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看Shopify示例中的电子邮件生成任务。输入应该是一个插件的想法，但你应该使其更加具体。让我们使用[表9-1](#ch09_table_1_1728407155641491)中定义的架构。
- en: Table 9-1\. Field definitions and examples describing a Shopify plug-in used
    as input for the email generation task
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 表9-1\. 字段定义和示例，描述用作电子邮件生成任务输入的Shopify插件
- en: '| Field | Datatype | Content | Example |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 字段 | 数据类型 | 内容 | 示例 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| `name` | Text | The name of the plug-in | Sock-cess Stories |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| `name` | 文本 | 插件名称 | Sock-cess Stories |'
- en: '| `concept` | Text | The basic idea | A wall of stories and selfies with store
    merchandise |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| `concept` | 文本 | 基本想法 | 一面展示商店商品的故事和自拍墙 |'
- en: '| `rationale` | Text | The reason this is a good idea | To drive engagement
    and promote a warm brand image |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| `rationale` | 文本 | 这个想法为什么好 | 为了推动参与并推广温暖的品牌形象 |'
- en: '| `store_id` | Uuid | Used to retrieve details about store | `550e8400-e29b-41d4-a716-446655440000`
    |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| `store_id` | Uuid | 用于检索商店详情 | `550e8400-e29b-41d4-a716-446655440000` |'
- en: Similarly, the output of the email task could use the schema defined in [Table 9-2](#ch09_table_2_1728407155641519).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，电子邮件任务的输出可以使用[表9-2](#ch09_table_2_1728407155641519)中定义的架构。
- en: Table 9-2\. Field definitions and examples describing an email that uses the
    output for the email generation task
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 表9-2\. 字段定义和示例，描述使用电子邮件生成任务输出的电子邮件
- en: '| Field | Datatype | Content | Example |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 字段 | 数据类型 | 内容 | 示例 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| `subject_line` | Text | The subject of the email | Introducing Sock-cess
    Stories for your storefront. |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| `subject_line` | 文本 | 邮件主题 | 介绍您的店面Sock-cess Stories。 |'
- en: '| `body` | Text | The basic idea | Your sock store is amazing; we can make
    it better together. |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| `body` | 文本 | 基本想法 | 您的袜子店很棒；我们可以一起让它变得更好。 |'
- en: In addition to specifying the input and output, you need to have a reasonably
    clear idea of *how* the task should be accomplished. For example, it’s not just
    that the email task should generate content to send to storefront owners, but
    it should be a particular *type* of content—a fun presentation of the concept
    designed to appeal to the owner based on values and themes demonstrated in the
    store’s website.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 除了指定输入和输出外，您还需要对任务应该如何完成有一个相当清晰的想法。例如，电子邮件任务不仅要生成发送给店面所有者的内容，而且应该是一种特定类型的**内容**——一种旨在吸引所有者、基于商店网站展示的价值和主题的有趣展示。
- en: Therefore, the email generation task will require content from the web page
    and prompting to condition the model to generate a particular type of response.
    The *how* of the task doesn’t have to be as rigidly defined as the input/output
    schema because it’s going to be much easier to change the content of a task than
    its interface. However, it should be well-enough defined that you’re sure this
    is a reasonable task. Otherwise, when you start building the task, you might find
    yourself back at the drawing board, rearranging tasks or redesigning interfaces.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，邮件生成任务将需要来自网页的内容以及提示来使模型生成特定类型的响应。任务的“如何”不需要像输入/输出模式那样严格定义，因为改变任务内容比改变其界面要容易得多。然而，它应该足够明确，以确保这是一个合理的任务。否则，当你开始构建任务时，你可能会发现自己回到了起点，重新排列任务或重新设计界面。
- en: Implementing LLM-based tasks
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于LLM的任务实施
- en: So you’ve defined your workflow and chopped it up into bite-size tasks, each
    of which has a clear functionality and a well-defined input and output. Now, it’s
    time to start implementing the tasks. Can your task be implemented without an
    LLM? If so, that’s fantastic—LLMs are expensive, slow, nondeterministic, and less
    dependable than traditional software. But since you’re this far into a book about
    LLM application development, it’s likely that most of your tasks will feature
    significant usage of LLMs. In this section, we’ll therefore give you an overview
    of how to implement such tasks.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你已经定义了你的工作流程，并将其拆分成小块任务，每个任务都有明确的功能和定义良好的输入输出。现在，是时候开始实施这些任务了。你的任务是否可以在没有大型语言模型（LLM）的情况下实施？如果是这样，那真是太好了——LLM
    贵、慢、非确定性，并且不如传统软件可靠。但是，既然你已经深入到一本关于 LLM 应用程序开发的书籍中，那么很可能你的大多数任务都会显著使用 LLM。因此，在本节中，我们将为您概述如何实施此类任务。
- en: Templated prompt approach
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模板提示方法
- en: One option is to just build a prompt template customized for the task at hand.
    This is effectively the approach that LangChain encourages—each “link” in the
    chain is a simple prompt template that fills in missing values using inputs and
    then parses the corresponding completion to extract outputs.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一个选择是只为当前任务构建一个定制的提示模板。这实际上是 LangChain 鼓励的方法——链中的每个“链接”都是一个简单的提示模板，它使用输入填充缺失的值，然后解析相应的完成部分以提取输出。
- en: When you’re building a prompt template, you’ll use all that we’ve taught you
    to this point in the book—gathering information relevant to the task, ranking
    it, trimming it to fit into the available prompt context, and then assembling
    a document for which the completion satisfies the intended purpose. For the Shopify
    email generation task, the goal is to write a marketing email that showcases a
    plug-in concept tailored to the store owner’s website. The context will need to
    contain detailed information about their website and a thorough description of
    the plug-in concept. If you are working with a completion model, as shown in [Table 9-3](#ch09_table_3_1728407155641542),
    the prompt will explain the task at hand, present the context, and then have the
    model generate an email. Note that in the example in the table, your company name
    is JivePlug-ins, the inputs are interpolated into the template, and the completion
    is used as the output.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 当你构建一个提示模板时，你将使用本书到目前为止所教授的所有内容——收集与任务相关的信息，对其进行排序，将其修剪以适应可用的提示上下文，然后组装一个文档，其中完成部分满足预期的目的。对于
    Shopify 邮件生成任务，目标是撰写一封展示针对店主网站定制的插件概念的营销邮件。上下文需要包含有关他们网站的详细信息以及插件概念的详细描述。如果你正在使用完成模型，如[表
    9-3](#ch09_table_3_1728407155641542)所示，提示将解释当前任务，展示上下文，然后让模型生成一封邮件。请注意，在表中的示例中，你的公司名称是
    JivePlug-ins，输入被插入到模板中，完成部分被用作输出。
- en: Table 9-3\. A prompt template for a completion model
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9-3\. 完成模型的提示模板
- en: '| Prefix |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 前缀 |'
- en: '[PRE0]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '|'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Suffix |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 后缀 |'
- en: '[PRE1]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '|'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: This is only a starting point, not the final template. After running this a
    couple of times to get a sense of the completions it produces, you would likely
    clarify the instructions in the template about exactly *how* to write the email—it
    should be upbeat, it should compliment the store owner, etc. You might also provide
    more descriptive boilerplate text around the storefront details and the plug-in
    description so that the model has a better understanding of what it’s reading.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是一个起点，而不是最终的模板。在运行几次以了解它产生的完成结果之后，你可能会澄清模板中关于如何编写邮件的具体说明——它应该是乐观的，应该赞美店主等。你也可能提供更多描述性的模板文本，围绕店面细节和插件描述，以便模型更好地理解它所阅读的内容。
- en: Critically, each task will need to post-process the completion and extract the
    output values that will be consumed by downstream tasks. In the prompt in [Table 9-3](#ch09_table_3_1728407155641542),
    this is facilitated by adding `Dear {storefront.owner_name}` to the prefix and
    `We hope to hear from you soon,` in the suffix. With this formulation, the contents
    of the completion will be exactly the content of the message that you want to
    ship to the prospective customer and nothing more.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，每个任务都需要对完成结果进行后处理并提取将被下游任务消费的输出值。在[表9-3](#ch09_table_3_1728407155641542)的提示中，这通过在前面添加`Dear
    {storefront.owner_name}`和在后面添加`We hope to hear from you soon,`来实现。使用这种表述方式，完成内容的正文将正好是你想要发送给潜在客户的邮件内容，没有更多。
- en: Tool-based approach
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 基于工具的方法
- en: Commonly, your workflows will have tasks that extract structured content from
    the input. For instance, a task that scrapes restaurant information might take
    in the HTML of the restaurant page and then extract the name, address, and phone
    number of the restaurant. Models that have tool-calling capabilities make this
    task easy. Simply define a tool that takes, as an argument, the structure that
    you wish to extract, then set up the prompt so that this tool is called. The template
    shown in [Table 9-4](#ch09_table_4_1728407155641566) should do the trick.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你的工作流程将包含从输入中提取结构化内容的任务。例如，一个抓取餐厅信息的任务可能会接收餐厅页面的HTML，然后提取餐厅的名称、地址和电话号码。具有工具调用能力的模型使这项任务变得简单。只需定义一个工具，该工具接受你希望提取的结构作为参数，然后设置提示以调用此工具。[表9-4](#ch09_table_4_1728407155641566)中显示的模板应该可以解决问题。
- en: Table 9-4\. Example using a tool-based approach to gather structured content
    from free-form input data
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 表9-4\. 使用基于工具的方法从自由格式输入数据中收集结构化内容的示例
- en: '| System | `Your job is to extract content about restaurants and save them
    to the database.` |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| 系统 | `你的任务是提取关于餐厅的内容并将其保存到数据库中。` |'
- en: '| Tool |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 工具 |'
- en: '[PRE2]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '|'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| User |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 用户 |'
- en: '[PRE3]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '|'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'If you’re using an OpenAI model, you could even use the `tool_choice` parameter
    to specify that the completion must execute that tool: `{"type": "function", "function":
    {"name": "saveRestaurantDataToDatabase"}}`. Using this approach, the model will
    call `saveRestaurantDataToDatabase` with the structured information you seek.
    It doesn’t matter that there is no actual database. Rather, you are just trying
    to convince the model that it should submit the information that it has read from
    the HTML. Recently, OpenAI introduced [the ability to enforce structured outputs](https://oreil.ly/5kTO0)
    in function calls. This will help ensure that the parsed output is exactly the
    structure you need it to be. The information you receive in the tool call can
    then be passed to a downstream task.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '如果你使用OpenAI模型，甚至可以使用`tool_choice`参数来指定完成必须执行该工具：`{"type": "function", "function":
    {"name": "saveRestaurantDataToDatabase"}}`。使用这种方法，模型将使用你寻求的结构化信息调用`saveRestaurantDataToDatabase`。实际上是否存在数据库并不重要。你只是试图说服模型提交它从HTML中读取的信息。最近，OpenAI在函数调用中引入了[强制结构化输出的能力](https://oreil.ly/5kTO0)。这将有助于确保解析后的输出结构正好是你需要的。在工具调用中接收到的信息然后可以传递给下游任务。'
- en: If you run into problems with this approach, then there are two likely sources.
    First, maybe it’s just difficult to pick out the structured content from the documents
    that you’re processing. Have you tried to do it yourself? If a human can’t do
    it, then the model will be helpless. To resolve this, reread your prompt and clean
    it up so that it’s easier to understand.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你遇到这种方法的问题，可能有两个可能的原因。首先，可能很难从你正在处理的文档中提取结构化内容。你尝试自己做了吗？如果人类做不到，那么模型将无能为力。为了解决这个问题，重新阅读你的提示并对其进行清理，使其更容易理解。
- en: Another possible source of the problem is the structure you’re extracting, which
    may be overly complex. Does the structure have lots of keys? Are there nested
    objects or lists? Might some of the fields be null or empty? In these cases, consider
    breaking down the structure into smaller pieces that can be tackled a bit at a
    time. As an additional benefit, when you focus on smaller pieces of information,
    you also have the opportunity to convey more specific instructions about extracting
    those pieces of information. This will certainly improve your results.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 问题可能的另一个来源是您正在提取的结构，它可能过于复杂。结构有很多键吗？是否有嵌套的对象或列表？某些字段可能是空或空的吗？在这些情况下，考虑将结构分解成更小的部分，可以一次处理一部分。作为额外的优势，当你专注于更小的信息块时，你也有机会传达更多关于提取这些信息块的具体指令。这肯定会提高你的结果。
- en: Adding more sophistication to tasks
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为任务增加复杂性
- en: So you’ve built your first draft task, but you’re not seeing the high-quality
    results that you had hoped to see. Don’t worry just yet. It’s just time to step
    back and consider adopting a more sophisticated approach in your prompt engineering.
    Consider the following prompt-engineering approaches.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 所以你已经完成了第一个草稿任务，但你还没有看到你期望的高质量结果。别担心，现在只是时候退一步，考虑在提示工程中采用更复杂的方法。考虑以下提示工程方法。
- en: In [Chapter 8](ch08.html#ch08_01_conversational_agency_1728429579285372), we
    covered [chain-of-thought reasoning](https://arxiv.org/abs/2201.11903) and [ReAct](https://arxiv.org/abs/2210.03629).
    Both of these prompt-engineering techniques guide the model to first think “out
    loud” about the problem before taking action with tools and before arriving at
    a final answer. If your LLM tasks do not demonstrate sufficient thoughtfulness
    as they complete their task, then you may be able to improve results considerably
    by simply adding in a “let’s think step-by-step” at some point in your prompt
    before demanding a more refined answer.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第8章](ch08.html#ch08_01_conversational_agency_1728429579285372)中，我们介绍了[思维链推理](https://arxiv.org/abs/2201.11903)和[ReAct](https://arxiv.org/abs/2210.03629)。这两种提示工程技术都引导模型在采取行动使用工具和得出最终答案之前，首先“大声思考”问题。如果你的LLM任务在完成任务时没有表现出足够的深思熟虑，那么你可以在提示中添加一个“让我们一步一步思考”的步骤，在要求更精确的答案之前，你可能会显著提高结果。
- en: Also, if the models jump too quickly to function calling without first planning
    the approach, then make a request to the model with function calling turned off.
    This will give the model a chance to reason about the problem before acting on
    the next turn. With OpenAI’s API, you can accomplish this by setting `tool_choice`
    to `"none"`. However, make sure that you continue to include the tool specification
    in the request—you want the model to reason about what to do *given* that it will
    have access to the tools you’ve specified in the next request. If you’re using
    Anthropic’s Claude model, then chain-of-thought reasoning happens by default on
    the Opus model, while the Sonnet and Haiku models will use chain-of-thought reasoning
    when prompted.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果模型在没有首先规划方法的情况下快速跳到函数调用，那么请请求模型关闭函数调用。这将给模型一个机会在采取下一步行动之前对问题进行推理。使用OpenAI的API，你可以通过将`tool_choice`设置为`"none"`来实现这一点。然而，请确保你继续在请求中包含工具规范——你希望模型在下一个请求中推理出它将如何使用你指定的工具。如果你使用Anthropic的Claude模型，那么思维链推理默认在Opus模型上发生，而Sonnet和Haiku模型将在被提示时使用思维链推理。
- en: A common problem you’ll find with LLM-based tasks is that they will confidently
    bring their task to an end and supply their output—but it will be wrong. It will
    be formatted incorrectly, or it won’t actually answer the question. If it’s a
    piece of code, then it may have bugs or even syntax errors. The first thing to
    try is to just tighten up the text in the prompt and make sure your requirements
    are clear and well defined. As a human, when you read the prompt, would you know
    what to do
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现基于LLM的任务的一个常见问题是，它们会自信地结束任务并给出输出——但这是错误的。它可能格式不正确，或者实际上没有回答问题。如果是一段代码，那么它可能存在错误或甚至语法错误。首先尝试的是仅仅收紧提示文本，确保你的要求清晰且定义良好。作为一个人类，当你阅读提示时，你会知道该做什么吗？
- en: But if the task continues to fail, you may need to apply self-correction. One
    technique to accomplish this is [Reflexion](https://arxiv.org/abs/2303.11366),
    in which you use any prompt-engineering method you deem appropriate to accomplish
    your task. (The paper uses ReAct as an example.) Then, in the application layer,
    you perform an analysis of the output to see if it meets your requirements.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果任务继续失败，你可能需要应用自我纠正。实现这一目标的一种技术是[Reflexion](https://arxiv.org/abs/2303.11366)，其中你使用你认为合适的任何提示工程方法来完成你的任务。（论文以ReAct为例。）然后，在应用层，你将对输出进行分析，以查看它是否满足你的要求。
- en: The analysis could be a quick check to see if formatting is alright. If your
    task outputs code, you can potentially compile the code and run unit tests against
    it. The analysis could even ask an LLM to review the output. (You’ll hear this
    referred to as *LLM-as-judge*.) In any case, the analysis will generate a report.
    If the report indicates that the task output satisfies your requirements, then
    you’re done.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 分析可能是一个快速检查，看看格式是否正确。如果你的任务输出代码，你可以尝试编译代码并对其运行单元测试。分析甚至可以要求一个LLM审查输出。（你将听到它被称为*LLM-as-judge*。）无论如何，分析将生成一个报告。如果报告表明任务输出满足你的要求，那么你就完成了。
- en: 'But, here’s where Reflexion kicks in: if the report indicates that the output
    is somehow insufficient, then you enter into a subtask to attempt to fix the problem.
    For this subtask, you craft a new prompt that will include the task requirements,
    the model’s previous attempt, and the contents of the post analysis. Finally,
    the prompt will end with a new request asking the model to learn from its mistakes
    and try the task again. Applying Reflexion one or more times will improve your
    odds of getting good results from your task, but beware that it comes at the cost
    of significantly more compute.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，这里就是Reflexion发挥作用的地方：如果报告表明输出在某些方面不足，那么你将进入一个子任务来尝试修复问题。对于这个子任务，你将创建一个新的提示，其中包括任务要求、模型的先前尝试和后分析的内容。最后，提示将以一个新的请求结束，要求模型从错误中学习并再次尝试任务。应用Reflexion一次或多次可以提高你从任务中获得良好结果的机会，但请注意，这会付出显著更多的计算成本。
- en: Finally, a more experimental approach for complex, open-ended tasks is to lean
    on conversational agents from the previous chapter. Create a conversational agent
    that is an “expert” at the task you want to solve and equipped with the tools
    that it will need to solve the task. Naturally, this agent won’t do anything by
    itself—conversational agents are built for conversational interactions with humans.
    Therefore, you create another agent—a user proxy—that is prompted to work with
    the expert to solve the problem. If you’re interested in trying this approach,
    then take a look at the [AutoGen library](https://arxiv.org/abs/2308.08155.pdf),
    which can be used to build this pattern. This is only one very basic pattern that
    you can implement with AutoGen. The library allows you to create teams of conversational
    agents, all with their own roles and capabilities working together to achieve
    a stated goal. We’ll discuss AutoGen again toward the end of this chapter.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，对于复杂、开放性任务，一个更实验性的方法是依靠上一章中提到的对话代理。创建一个在你要解决的问题上“专家级”的对话代理，并配备它完成任务所需的工具。自然地，这个代理本身不会做任何事情——对话代理是为了与人类进行对话交互而构建的。因此，你需要创建另一个代理——一个用户代理——被提示与专家合作解决问题。如果你对尝试这种方法感兴趣，那么可以看看[AutoGen库](https://arxiv.org/abs/2308.08155.pdf)，它可以用来构建这种模式。这只是一个你可以用AutoGen实现的基本模式之一。该库允许你创建由对话代理组成的团队，每个代理都有自己的角色和能力，共同实现一个既定的目标。我们将在本章末尾再次讨论AutoGen。
- en: Add variety to your task
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为你的任务增加多样性
- en: Everything we’ve said about tasks up to this point assumes that they will be
    implemented with LLMs. This need not be the case. Remember that some tasks are
    better suited to more traditional software implementations. For example, there’s
    no reason to use an LLM in a task that retrieves Shopify storefront content—just
    use a web crawler. Some tasks are mechanical, such as a task that saves content
    to a database. Sometimes, you need machine learning, but it doesn’t have to be
    an LLM. Use a BERT-based classifier if you can get by with it—it will more dependably
    classify input (rather than, say, making commentary) and will be faster and cheaper
    to boot.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们到目前为止所说的关于任务的内容都假设它们将使用LLM来实现。这并不一定非得如此。记住，有些任务更适合使用更传统的软件实现。例如，在检索Shopify店面内容这样的任务中，没有必要使用LLM——只需使用网络爬虫即可。有些任务是机械的，例如将内容保存到数据库的任务。有时，你需要机器学习，但不必一定是LLM。如果你可以用BERT-based
    classifier完成，那就用它——它将更可靠地分类输入（而不是，比如说，发表评论），并且会更快、更便宜。
- en: You may also want to incorporate human interaction in tasks. If any task requires
    taking an action that is expensive and cannot be undone, then you should request
    approval for that action from a human supervisor. In tasks that require human-level
    judgment of the output, queue up some human reviewers. For tasks using Reflexion,
    if a small subset of the tasks fails repeatedly, then have a human inspect the
    problematic task and adjust the prompt to put the task back on track.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可能想在任务中融入人工交互。如果任何任务需要执行昂贵且无法撤销的操作，那么你应该请求人类主管批准该操作。对于需要人类水平判断输出的任务，安排一些人类审阅者。对于使用Reflexion的任务，如果一小部分任务反复失败，那么让人类检查有问题的任务并调整提示，以使任务回到正轨。
- en: Finally, even when tasks are LLM-based, they don’t have to all use *the same*
    LLM. For easy tasks, you should use a lightweight, cheap, self-hosted LLM; for
    a hard task, use whatever big, expensive model is in the news headlines that week;
    and for very customized tasks, use an in-house fine-tuned model.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，即使任务基于LLM，它们也不必都使用**相同的**LLM。对于简单任务，你应该使用轻量级、便宜、自托管的LLM；对于困难任务，使用那周新闻头条中提到的任何大型、昂贵的模型；对于非常定制的任务，使用内部微调的模型。
- en: Evaluation starts at the task level
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 评估从任务级别开始
- en: Even before building out the full workflow, you can start evaluating tasks in
    isolation. The more complexity you have, then the more opportunity there is for
    problems to arise, and the more places you have to search to track them down.
    Workflow agency provides a useful framework for building a modularized system,
    because if something breaks, then it can usually be tracked down to a faulty task.
    So always think through your tasks and how they should perform, what errors they
    might run into, and how they can recover. In the next chapter, we’ll give you
    insights into evaluating LLM applications that will apply well to the tasks and
    workflows discussed in this chapter.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在构建完整的工作流程之前，你也可以开始单独评估任务。复杂性越高，出现问题的机会就越多，需要搜索的地方也就越多，以追踪这些问题。工作流程代理提供了一个有用的框架来构建模块化系统，因为如果出现问题，通常可以追溯到有缺陷的任务。所以，始终要考虑你的任务以及它们应该如何执行，它们可能会遇到什么错误，以及它们如何恢复。在下一章中，我们将为您提供评估LLM应用的内幕，这些内容将适用于本章讨论的任务和工作流程。
- en: Assembling the Workflow
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 组装工作流程
- en: 'By this point, you’ve decomposed your work into a finite set of tasks, each
    of which accomplishes its portion of the workflow with a high success rate. Now,
    it’s time for the next step: assembling the pieces into a workflow.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经将你的工作分解成一系列有限的任务，每个任务都以高成功率完成其工作流程的一部分。现在，是时候进行下一步：将各个部分组装成一个工作流程。
- en: A *workflow* is an interconnected set of tasks that can be conceptualized in
    a number of ways. You can think of the workflow as being a state machine in which
    each task is a state. As input arrives at the task, it is transformed into one
    of possibly several outputs, which are then propagated on to downstream states.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**工作流程**是一系列相互关联的任务集合，可以从多个角度进行概念化。你可以将工作流程视为一个状态机，其中每个任务都是一个状态。当输入到达任务时，它被转换成可能的一组输出之一，然后这些输出被传播到下游状态。'
- en: Alternatively, you can think of tasks as nodes that are connected in publish-subscribe
    fashion to other task nodes and that send and receive work items based on their
    subscriptions. Additionally, you can think of tasks as being fully managed by
    a workflow orchestrator, which supervises the tasks and controls how work items
    progress between them. Fundamentally, though, these are all the same thing—the
    most salient feature is the way in which the tasks are interconnected.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你可以将任务视为以发布/订阅方式连接到其他任务节点的节点，并根据它们的订阅发送和接收工作项。此外，你可以将任务视为完全由工作流程编排器管理，该编排器监督任务并控制工作项在它们之间如何进展。然而，从根本上说，这些都是同一件事——最显著的特征是任务之间的相互连接方式。
- en: Tasks can be connected in various topologies. The simplest arrangement is a
    *pipeline*—a set of tasks that are connected sequentially, so that the output
    of each task is the input into *at most* one task. Pipelines are useful for transforming
    information through a step-by-step process. For instance, you could implement
    the Shopify example as a pipeline as shown in [Figure 9-5](#ch09_figure_5_1728407155631114).
    The benefit of pipelines is their simplicity, but it comes at the cost of flexibility.
    For instance, in the figure, notice that the details extracted from the website
    are used to generate plug-in concepts, but this information is not available to
    the email composer, even though it might actually be quite useful. You can get
    around this problem by passing the extraction details *through* the plug-in generator,
    but this couples together tasks more than they should be. Namely, this requires
    the email composition task to get its store details from the plug-in generator—which
    is not at all intuitive.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 任务可以以各种拓扑结构连接。最简单的安排是*管道*——一系列按顺序连接的任务，其中每个任务的输出最多是另一个任务的输入。管道对于通过逐步过程转换信息非常有用。例如，你可以将Shopify示例实现为一个管道，如图[图9-5](#ch09_figure_5_1728407155631114)所示。管道的优点在于其简单性，但这也牺牲了灵活性。例如，在图中，请注意从网站提取的详细信息用于生成插件概念，但这些信息对电子邮件编写者不可用，尽管实际上可能非常有用。你可以通过将提取的详细信息*通过*插件生成器传递来解决这个问题，但这会使任务之间的耦合程度超过应有的程度。也就是说，这要求电子邮件编写任务从插件生成器获取其商店详情——这并不直观。
- en: '![](assets/pefl_0905.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/pefl_0905.png)'
- en: Figure 9-5\. A pipeline implementation of the Shopify plug-in promoter
  id: totrans-116
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-5\. Shopify插件推广器的管道实现
- en: As workflows become more complicated, a task may send its output to multiple
    downstream tasks or may require input from multiple upstream tasks. If the flow
    of work is always in one direction (e.g., there are no cycles in connectivity,
    so that information flows back to an earlier task), then such a workflow is called
    a *directed acyclic graph* (DAG). The Shopify example can be improved by representing
    it as a DAG in which you address the previously mentioned problem by passing the
    storefront details directly to both the concept generation and email composition
    tasks (see [Figure 9-6](#ch09_figure_6_1728407155631130)).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 随着工作流程变得更加复杂，一个任务可能将其输出发送到多个下游任务，或者可能需要从多个上游任务获取输入。如果工作流程始终沿一个方向进行（例如，连接中没有循环，因此信息不会流回早期任务），则此类工作流程称为*有向无环图*（DAG）。通过将Shopify示例表示为DAG，你可以通过直接将店面详情传递给概念生成和电子邮件编写任务来解决之前提到的问题（参见[图9-6](#ch09_figure_6_1728407155631130)）。
- en: DAGs are crucial in workflow automation because they can effectively model a
    wide range of practical workflows while retaining manageability. Popular workflow
    automation platforms such as [Airflow](https://airflow.apache.org) and [Luigi](https://luigi.readthedocs.io/en/stable)
    treat workflows as DAGs in which nodes represent tasks and the connections represent
    dependencies. This makes reasoning about DAGs simple—a task can be run only if
    all of its upstream dependencies have completed successfully.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: DAG在工作流程自动化中至关重要，因为它们可以有效地模拟广泛的实际工作流程，同时保持可管理性。流行的自动化工作流程平台，如[Airflow](https://airflow.apache.org)和[Luigi](https://luigi.readthedocs.io/en/stable)，将工作流程视为DAG，其中节点代表任务，连接代表依赖关系。这使得对DAG进行推理变得简单——只有当所有上游依赖任务都成功完成后，才能运行任务。
- en: '![](assets/pefl_0906.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/pefl_0906.png)'
- en: Figure 9-6\. A DAG implementation of the Shopify plug-in promoter
  id: totrans-120
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-6\. Shopify插件推广器的DAG实现
- en: As exemplified in [Figure 9-7](#ch09_figure_7_1728407155631147), the most general
    task arrangement is a *cyclic graph*—a network of tasks in which the information
    output from a task can circle back to upstream tasks and form loops. Sometimes,
    cycles are useful. For instance, in the Shopify workflow, you could include a
    quality control—if the emails are of sufficient quality, then you email them to
    the storefront. Otherwise, send information about the failure back upstream to
    the extract details step so that you can hopefully end up with a better result
    the next time around.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图9-7](#ch09_figure_7_1728407155631147)所示，最一般化的任务安排是一个**循环图**——一个任务信息可以从一个任务输出并返回上游任务形成循环的网络。有时，循环是有用的。例如，在Shopify工作流程中，你可以包括一个质量控制环节——如果邮件的质量足够高，那么就发送到店面。否则，将失败信息发送回上游的提取细节步骤，以便你希望在下一次尝试中得到更好的结果。
- en: '![](assets/pefl_0907.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/pefl_0907.png)'
- en: Figure 9-7\. A cyclic graph implementation of the Shopify plug-in promoter
  id: totrans-123
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-7. Shopify插件推广器的循环图实现
- en: Sometimes, when you’re dealing with LLM-based workflows, cyclic graphs will
    be necessary—if the LLM makes a mistake on a particular task, then you may have
    to pass it back upstream and see if the work item can be repaired. But be wary
    of this pattern because it increases complexity considerably. Consider the case
    in [Figure 9-7](#ch09_figure_7_1728407155631147). One problem is that when the
    failure information moves back to the extract details task, it must be reunited
    with the corresponding website content—whereas in the DAG implementation, this
    information will never be needed again and thus doesn’t need to be stored.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，当你处理基于LLM的工作流程时，循环图将是必要的——如果LLM在特定任务上出错，那么你可能需要将其返回上游并查看工作项是否可以修复。但要注意这种模式，因为它大大增加了复杂性。考虑[图9-7](#ch09_figure_7_1728407155631147)中的情况。一个问题是在失败信息返回到提取细节任务时，它必须与相应的网站内容重新组合——而在DAG实现中，这些信息将永远不会再次需要，因此不需要存储。
- en: Another problem is that every task must now anticipate the possibility that
    failure information will be attached to the work items—this will need to be dealt
    with in the implementations of the tasks. Finally, how do you keep work items
    that keep failing from cycling through the system indefinitely? To deal with this,
    you need to track the number of attempts and then give up if the permissible number
    is exceeded. When considering whether to introduce cyclic dependencies into your
    workflow, if possible, it’s a good idea to keep recursion hidden inside the task
    so that the complexity isn’t hoisted up the level of the workflow where other
    tasks will be required to deal with the cyclic dependency.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是一切任务现在都必须考虑到失败信息可能附加到工作项上的可能性——这需要在任务的实现中处理。最后，如何防止不断失败的工作项在系统中无限循环？为了处理这个问题，你需要跟踪尝试次数，然后如果超过允许的数量就放弃。在考虑是否将循环依赖引入到你的工作流程中时，如果可能的话，将递归隐藏在任务内部是一个好主意，这样复杂性就不会提升到工作流程的级别，其他任务将需要处理循环依赖。
- en: Besides task connectivity, you should consider whether the workflow processes
    work items in batch or streaming fashion. A *batch workflow* processes a known
    and finite set of work items, whereas a *streaming workflow* processes an arbitrary
    number of work items that are created or retrieved as the workflow processes.
    Our Shopify concept could be implemented either way—in a batch fashion, where
    we collect a list of storefronts and *then* process them, or in a streaming fashion,
    where a web crawler constantly looks for storefronts and then processes them as
    they arrive. Either approach is fine to use. Batch processing is typically simpler
    to set up and maintain and can efficiently process large volumes of data, while
    streaming is more appropriate for real-time, low-latency tasks but tends to be
    more complex.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 除了任务连接性，你还应该考虑工作流程是否以批量或流式处理方式处理工作项。一个**批量工作流程**处理已知且有限的工作项集合，而一个**流式工作流程**处理任意数量在工作流程处理过程中创建或检索的工作项。我们的Shopify概念可以以这两种方式之一实现——以批量方式，我们先收集店面列表，然后处理它们，或者以流式方式，其中网络爬虫不断寻找店面，然后随着它们的到来进行处理。任何一种方法都可以使用。批量处理通常更容易设置和维护，并且可以高效地处理大量数据，而流式处理更适合实时、低延迟的任务，但往往更复杂。
- en: 'Example Workflow: Shopify Plug-in Marketing'
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 示例工作流程：Shopify插件营销
- en: At the [“Basic LLM Workflows”](#ch09_basic_llm_workflows_1728407155661944),
    we outlined the steps for building a workflow. Let’s put these steps into practice
    by creating a complete workflow for the Shopify plug-in promoter. In this scenario,
    we imagine ourselves to be a small development shop that caters to the Shopify
    ecosystem. Our goal, again, is to review Shopify storefronts, come up with ideas
    for plug-ins, and then promote them to the owners of the storefronts so that *hopefully*,
    we can build a backlog of future projects.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在[“基本LLM工作流程”](#ch09_basic_llm_workflows_1728407155661944)中，我们概述了构建工作流程的步骤。让我们通过创建一个完整的Shopify插件推广者工作流程来将这些步骤付诸实践。在这种情况下，我们想象自己是为Shopify生态系统提供服务的中小企业。我们的目标，再次强调，是审查Shopify店面，提出插件想法，然后将它们推广给店面所有者，*希望*我们能建立一个未来项目的待办事项列表。
- en: 'Starting with our opening example, we’ve already talked about the tasks involved;
    now, let’s build them. Naturally, the full implementation isn’t going to be something
    that fits easily into a book, but since you’ve made it this far in this book,
    you can probably imagine what these tasks will look like when implemented. Here’s
    a quick rundown of the implementation:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们的开篇示例开始，我们已经讨论了涉及的任务；现在，让我们来构建它们。当然，完整的实现不可能轻易地放入一本书中，但既然你已经读到这本书的这一部分，你可能会想象到这些任务在实现时的样子。以下是实现的一个简要概述：
- en: Emit storefront html
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 发出店面HTML
- en: This is a mock implementation. The HTML for several storefronts was manually
    collected and saved to the filesystem. This task simply emits them.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个模拟实现。几个店面HTML被手动收集并保存到文件系统中。这个任务只是简单地发出它们。
- en: Summarize storefront
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 总结店面
- en: 'This extracts the text from the HTML and then prompts an LLM to summarize the
    following salient aspects of the site:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这从HTML中提取文本，然后提示一个LLM总结以下网站的重要方面：
- en: What do they sell?
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他们卖什么？
- en: What is the overall tone of the website? Fun? Serious? Relaxing?
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网站的总体语气是什么？有趣？严肃？放松？
- en: What values do they hold most dear? Sustainability? Social causes?
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 他们最珍视什么价值观？可持续性？社会事业？
- en: What themes are present on the website? Travel? Productivity? Exercise?
  id: totrans-137
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网站上有哪些主题？旅行？生产力？锻炼？
- en: Is there anything praiseworthy on the website? (We’re getting ready to stroke
    their ego in the email!)
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网站上有什么值得称赞的地方？（我们准备在电子邮件中抚摸他们的自尊心！）
- en: Is there anything else that seems noteworthy?
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 还有其他什么值得注意的吗？
- en: Generate new plug-in concept
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 生成新的插件概念
- en: This is a two-step process that first brainstorms several good options and identifies
    the best one and second generates a detailed report about the best idea and how
    it will benefit the client. The reason for handling this in two steps is to separate
    the chain-of-thought brainstorming from the actual plug-in concept, which is the
    only part we retain as the output.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个两步过程，首先头脑风暴几个好选项并确定最佳选项，其次生成关于最佳想法及其如何惠及客户的详细报告。之所以以两步处理，是为了将思维链头脑风暴与实际插件概念分开，这是我们唯一保留作为输出的部分。
- en: Generate email
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 生成电子邮件
- en: This is also a multistep process. In the first step, we use chain-of-thought
    prompting by instructing the model to devise a strategy for promoting the idea
    that will match the storefront. Next, we ask the model for the subject line of
    the email, and finally, we ask for the body of the email.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这也是一个多步骤的过程。在第一步中，我们通过指导模型制定一个策略来促进与店面相匹配的想法，使用思维链提示。接下来，我们要求模型提供电子邮件的主题行，最后，我们要求提供电子邮件的正文。
- en: Send email
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 发送电子邮件
- en: This is also a mocked implementation. The send-email task simply prints the
    email to the screen.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这也是一个模拟实现。发送电子邮件的任务只是将电子邮件打印到屏幕上。
- en: The next step is to integrate the tasks into the completed workflow as shown
    in [Figure 9-8](#ch09_figure_8_1728407155631163). Effectively, this is the same
    diagram as in [Figure 9-6](#ch09_figure_6_1728407155631130)—a DAG—but in [Figure 9-8](#ch09_figure_8_1728407155631163),
    we’ve annotated the specific inputs and outputs.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是将任务集成到完成的工作流程中，如图[图9-8](#ch09_figure_8_1728407155631163)所示。实际上，这与图[图9-6](#ch09_figure_6_1728407155631130)中的图表相同——一个DAG，但在图[图9-8](#ch09_figure_8_1728407155631163)中，我们标注了具体的输入和输出。
- en: Finally, we have a complete workflow. To put it to the test, we allowed it to
    ingest the HTML from [a popular storefront for Sichuan cooking](https://flybyjing.com).
    And the result is not bad for a disembodied virtual intelligence that has never
    experienced the delights of Sichuan cuisine, don’t you think?
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有一个完整的工作流程。为了对其进行测试，我们允许它从 [一个流行的四川菜店面](https://flybyjing.com)中获取 HTML。对于从未体验过四川菜美味的无实体虚拟智能来说，结果并不坏，不是吗？
- en: '![](assets/pefl_0908.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/pefl_0908.png)'
- en: Figure 9-8\. Final implementation of the Shopify plug-in promoter
  id: totrans-149
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 9-8\. Shopify 插件促进者的最终实现
- en: The final step is to optimize the workflow. The example we implemented for this
    chapter is merely a toy problem, so the first thing to do would be to make sure
    that these tasks are actually the *correct* tasks.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是优化工作流程。我们本章实现的示例仅是一个玩具问题，所以首先要做的是确保这些任务是**正确的**任务。
- en: For instance, the ideas generated from this workflow were admittedly a bit lacking
    in variety—there were lots of virtual try-on plug-ins for clothing stores and
    lots of impact trackers for stores focused on their social or environmental impact.
    Perhaps you could make the brainstorming step more robust and steer clear of the
    most common ideas. The next problem is that some of the generated ideas aren’t
    practical to implement. You should probably add a subprocess to plan out the implementation
    of each concept and ensure that the selected concepts are feasible.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，从这个工作流程中产生的想法确实在多样性方面略显不足——有大量针对服装店的虚拟试穿插件，以及大量针对关注其社会或环境影响店铺的影响跟踪器。也许你可以使头脑风暴步骤更加稳健，并避免最常见的想法。下一个问题是，一些生成的想法在实施上并不实用。你可能需要添加一个子过程来规划每个概念的实现，并确保所选的概念是可行的。
- en: Another optimization would be to incorporate corrective feedback into the workflow.
    This can be at the task level, by incorporating a Reflexion prompt flow that evaluates
    task output and then prompts the model for improvements. You can also introduce
    feedback at the workflow level by identifying failed work items and sending them
    back to the beginning of the workflow along with details of how they can be improved
    next time.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种优化是将纠正反馈纳入工作流程。这可以在任务级别进行，通过整合一个评估任务输出的 Reflexion 提示流程，然后提示模型进行改进。你还可以通过识别失败的工作项并将它们连同如何下次改进的详细信息一起发送回工作流程开始处，在工作流程级别引入反馈。
- en: Finally, as soon as the tasks are well defined, you should begin collecting
    example data for each task so that you can improve the tasks. Before a task implementation
    is in production, you should devise offline harness tests that exercise the prompts
    and check that the completions match expected behavior. This will make it easier
    for you to ship changes to the prompt while being confident that task quality
    will not degrade. Having input-output (I/O) examples is also handy for emerging
    optimization techniques such as [DSPy](https://arxiv.org/abs/2310.03714) and [TextGrad](https://arxiv.org/abs/2406.07496).
    These frameworks use I/O examples to optimize the prompt so that the quality,
    as measured by a provided metric, is automatically increased.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，一旦任务定义得很好，你应该开始收集每个任务的示例数据，以便你可以改进任务。在任务实施投入生产之前，你应该设计离线测试 harness，以测试提示并检查完成情况是否符合预期行为。这将使你在对提示进行更改的同时，更有信心任务质量不会下降。拥有输入输出（I/O）示例对于新兴的优化技术，如
    [DSPy](https://arxiv.org/abs/2310.03714) 和 [TextGrad](https://arxiv.org/abs/2406.07496)，也非常有用。这些框架使用
    I/O 示例来优化提示，以便自动提高由提供的指标衡量的质量。
- en: Once a task is in production, it’s important to record I/O data from real traffic.
    This can be sampled to ensure there are no quality degradations. More importantly,
    this traffic can be used to evaluate competing implementations in live-traffic
    A/B tests. We cover evaluation in detail in the next chapter.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦任务投入生产，记录真实流量中的 I/O 数据就很重要。这可以采样以确保没有质量下降。更重要的是，可以使用这些流量在实时流量 A/B 测试中评估竞争性实现。我们将在下一章详细介绍评估。
- en: Advanced LLM Workflows
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级 LLM 工作流程
- en: 'The basic LLM workflows previously described are relatively easy to reason
    about: they are composed of a finite set of tasks, each of which is known a priori
    and all of which are connected in a fixed pattern of communication. Therefore,
    if something goes awry, then the problem is relatively simple to isolate and fix.
    It’s similarly easy to evaluate and optimize the tasks that make up the workflow.
    Because of this simplicity and dependability, you should typically use a basic
    workflow first, before attempting some of the more exotic and “fun” things we
    introduce in this section. However, basic workflows have their limitations. The
    very things that make them easy to work with also make them rigid and unable to
    adapt to scenarios outside of their design.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 之前描述的基本 LLM 工作流程相对容易理解：它们由一组有限的任务组成，每个任务都是事先已知的，并且所有任务都按照固定的通信模式相互连接。因此，如果出现问题，那么问题相对简单就可以隔离和修复。评估和优化构成工作流程的任务也同样容易。正因为这种简单性和可靠性，你应该通常首先使用基本工作流程，然后再尝试本节中介绍的一些更奇特和“有趣”的事情。然而，基本工作流程有其局限性。正是使它们易于处理的东西，也使它们变得僵化，无法适应设计之外的场景。
- en: In this section, we’ll dig into some more advanced workflow approaches. Each
    of the ideas we discuss here allows models to solve more open-ended problems.
    However, we give you fair warning that once you give more autonomy and agency
    to the LLM, the resulting systems will be inherently less stable and therefore
    harder to reason about.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将深入研究一些更高级的工作流程方法。我们在这里讨论的每个想法都允许模型解决更多开放性问题。然而，我们提前警告你，一旦你给予 LLM 更多的自主权和代理权，所得到的系统将本质上是更不稳定的，因此更难以理解。
- en: Nevertheless, as LLMs continue to improve and the community discovers new approaches,
    we believe that advanced techniques will become much more commonly utilized. The
    three approaches we introduce in the following sections are far from exhaustive,
    but hopefully, they will get your gears turning as you think of novel solutions
    in your own problem space.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，随着 LLM 的持续改进和社区发现新的方法，我们相信高级技术将变得更加普遍地被使用。以下几节中我们介绍的三种方法远非详尽无遗，但希望它们能激发你在自己的问题空间中思考新颖解决方案的灵感。
- en: Allowing an LLM Agent to Drive the Workflow
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 允许 LLM 代理驱动工作流程
- en: In the discussion of basic LLM workflows, the tasks themselves use LLMs, but
    the workflows are traditional pipelines, DAGs, or graphs that involve no use of
    LLMs in routing work items. Therefore, the logical next step in complexity and
    flexibility is to allow the flow of work outside the tasks to be directed by an
    LLM. When you do this, the workflow itself acts as an agent orchestrating and
    coordinating the overall work. There are several options here.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论基本 LLM 工作流程时，任务本身使用 LLM，但工作流程是传统的管道、DAG 或不涉及 LLM 在路由工作项中使用的图。因此，在复杂性和灵活性方面的下一个逻辑步骤是允许工作流程中任务之外的工作流程由
    LLM 指导。当你这样做时，工作流程本身充当一个代理，协调和调度整体工作。这里有几个选择。
- en: When you’re putting the LLM in the driver’s seat, one possibility is to keep
    the set of possible tasks fixed and let the workflow agent choose how to route
    work to the tasks that will properly handle it. You can implement this at the
    workflow level by treating the workflow as a conversational agent and giving it
    tools that correspond to the available tasks. Whenever the workflow agent receives
    a new piece of work, it can choose which task to send it to.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 当你将 LLM 放在驾驶员的位置时，一个可能性是保持可能任务集不变，让工作流程代理选择如何将工作路由到能够正确处理它的任务。你可以在工作流程级别通过将工作流程视为一个对话代理，并给它提供与可用任务相对应的工具来实现这一点。每当工作流程代理收到新的工作内容时，它可以选择将其发送到哪个任务。
- en: You can go further down this path. In addition to making the workflow a conversational
    agent that has tools corresponding to tasks, you can make the tasks themselves
    conversational agents that have specialized tools for handling well-defined areas
    of work. In this way, the workflow really becomes an “agent of agents.” A tricky
    part here is that both the task-level agents and the workflow agent still need
    to return a particular output—they can’t just keep chatting. Therefore, give them
    a `finish` tool so that they can submit their work once it’s complete. (See the
    original [ReAct paper](https://arxiv.org/abs/2210.03629) for a good example of
    `finish`.)
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以继续深入这个方向。除了使工作流程成为一个具有对应任务的工具的对话代理外，你还可以使任务本身成为具有专门工具处理定义明确的作业领域的对话代理。这样，工作流程实际上变成了“代理的代理”。这里的一个棘手之处在于，任务级代理和工作流程代理仍然需要返回特定的输出——他们不能只是不停地聊天。因此，给他们一个`finish`工具，这样他们就可以在完成工作后提交他们的成果。（参见原始[ReAct论文](https://arxiv.org/abs/2210.03629)中关于`finish`的一个很好的例子。）
- en: Then, go a step further. Rather than using predefined conversational agents
    for each task, you can have the workflow agent generate *arbitrary* tasks on the
    fly. When the workflow determines that a task is required to be executed, it will
    craft a conversation agent for the task (including a specialized system message
    that outlines the goal of the work), and a set of tools will be deemed necessary
    to satisfy the goal of the task. (The tools will be selected from a large array
    of preexisting tools.)
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，更进一步。与其为每个任务使用预定义的对话代理，你还可以让工作流程代理即时生成*任意*任务。当工作流程确定需要执行某个任务时，它将为该任务创建一个对话代理（包括概述工作目标的专用系统消息），并确定一组必要的工具以满足任务的目标。（工具将从大量现有工具中选择。）
- en: Finally, instead of sending work to one task at a time in a series, the workflow
    agent can manage a growing list of tasks to pursue. Also, using something like
    a work list algorithm, the workflow agent can continually prioritize and reevaluate
    the tasks and submit the ones that are now most relevant to pursue.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，而不是一次只发送一系列任务中的一个任务，工作流程代理可以管理一个不断增长的待办任务列表。此外，使用类似工作列表算法的方法，工作流程代理可以持续优先排序和重新评估任务，并提交现在最相关的任务。
- en: Stateful Task Agents
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有状态的任务代理
- en: Until now, we have conceptualized the workflow as a network of tasks responsible
    for receiving, processing, and forwarding work items on to subsequent tasks. In
    this scenario, a task maintains no persistent state; upon receiving a new work
    item, the task starts anew, with no knowledge of prior work. But what if each
    task is implemented as an agent that is permanently associated with a work item
    and that is responsible for modifying the state of the work item as the need arises?
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今为止，我们将工作流程概念化为一个网络，负责接收、处理并将工作项转发到后续任务。在这种情况下，任务不保持持久状态；在接收到新的工作项时，任务从头开始，没有任何关于先前工作的知识。但如果是每个任务都作为一个与工作项永久关联的代理实现，并且负责根据需要修改工作项的状态呢？
- en: For example, consider the scenario in which the work item is a text file that
    will soon contain the JavaScript implementation of a web page. This text file
    is associated with a code-writing agent that is responsible for building the web
    page code and then updating this file as necessary, based on external events.
    There are other files for other parts of the website, and each has its own associated
    agents.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑这样一个场景：工作项是一个即将包含网页JavaScript实现的文本文件。这个文本文件与一个负责构建网页代码并根据外部事件更新此文件的代码编写代理相关联。还有其他文件用于网站的其它部分，每个部分都有自己的相关代理。
- en: As the “build a website” workflow gets underway, the web page agent might make
    a first attempt at the implementation. But as other files change around it, the
    implementation will need to be updated to remain consistent with other code. For
    instance, a human developer may ask for a change to be made to the UI. A task
    agent associated with the UI will make the appropriate changes and then notify
    related task agents to update their files accordingly. In this case, the web page
    agent may receive an update about the UI, realize that a change is required in
    the web page, make the change, and then notify other agents that the web page
    JavaScript has changed.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 当“构建网站”工作流程开始时，网页代理可能会尝试第一次实现。但随着周围其他文件的变化，实现需要更新以保持与其他代码的一致性。例如，人类开发者可能要求对UI进行更改。与UI关联的任务代理将进行适当的更改，然后通知相关任务代理相应地更新他们的文件。在这种情况下，网页代理可能会收到关于UI的更新，意识到网页需要更改，进行更改，然后通知其他代理网页JavaScript已更改。
- en: At the workflow level, there are several ways to interact with these stateful
    task agents. You could make the workflow agent act as an orchestrator, sending
    requests for particular task agents to update the assets it is responsible for.
    A different approach would be to have the workflow set up a graph of dependencies
    among the task agents as assets are created, and as each work item is updated,
    its task agent would notify dependent tasks of their changes. For this approach,
    it is important to avoid or otherwise deal with circular dependencies, or the
    workflow may never find a stopping point.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在工作流程层面，有几种方式可以与这些具有状态的代理进行交互。你可以让工作流程代理充当协调者，向特定任务代理发送请求以更新其负责的资产。另一种方法是在创建资产时设置任务代理之间的依赖关系图，并且每当工作项更新时，其任务代理就会通知依赖任务它们的更改。对于这种方法，避免或以其他方式处理循环依赖关系非常重要，否则工作流程可能永远找不到停止点。
- en: Finally, since the agents are stateful, this approach offers an interesting
    way for users to interact with the workflow—allowing users to discuss work items
    directly with the agents that are responsible for them. Also, rather than directly
    changing the content of a file, a developer might have a discussion with the agent
    responsible for that file. Once the task agent has made the required changes,
    the neighboring task agents on the dependency graph can be notified to take appropriate
    measures.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，由于代理具有状态，这种方法为用户提供了一种与工作流程互动的有趣方式——允许用户直接与负责这些工作项的代理进行讨论。此外，开发者不必直接更改文件内容，他们可以与负责该文件的代理进行讨论。一旦任务代理完成了必要的更改，依赖图上相邻的任务代理就可以被通知采取适当的措施。
- en: Roles and Delegation
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 角色与委派
- en: 'One emerging trend in LLM-based workflows is to define agents with specific
    roles and then delegate work to them as if they were a team assigned to your goal.
    We already mentioned [AutoGen](https://oreil.ly/6qVL8). In its simplest usage,
    AutoGen introduces two roles: the Assistant and the UserProxy. The Assistant follows
    the exact same design of conversational agency as presented in the last chapter—a
    conversational loop that has the option to run tools in the background.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于LLM的工作流程中，一个新兴趋势是定义具有特定角色的代理，然后将工作委派给他们，就像他们是一个为你的目标分配的团队一样。我们之前提到了[AutoGen](https://oreil.ly/6qVL8)。在其最简单的使用中，AutoGen引入了两个角色：助手和UserProxy。助手遵循与上一章中展示的对话代理完全相同的设计——一个可以选择在后台运行工具的对话循环。
- en: The UserProxy, on the other hand, is an agent that acts as a stand-in for the
    human user. It has a system message instructing it to work with the Assistant
    and accomplish whatever goal the actual human user has specified. The UserProxy
    then engages in the conversation with the Assistant, and as the Assistant accomplishes
    work, the UserProxy acts as a corrective force to keep the Assistant on track,
    offer recommendations, and eventually declare that a goal has been successfully
    accomplished.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，UserProxy是一个代表人类用户的代理。它有一个系统消息指示它与助手一起工作，完成实际人类用户指定的任何目标。UserProxy随后与助手进行对话，当助手完成工作，UserProxy作为纠正力量来保持助手在正确的轨道上，提供建议，并最终宣布目标已成功完成。
- en: Assistant-UserProxy pairs can be thought of as very small LLM-based workflows,
    but AutoGen has more to offer. AutoGen provides a component known as a *group
    chat manager* that acts as a workflow coordinator. It can be provided with several
    conversation agents—each of which has its own roles, system message, and tools—and
    when a question is asked of the manager, the manager is responsible for delegating
    the request as it sees fit.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 助手-用户代理对可以被视为非常小的基于LLM的工作流程，但AutoGen提供的内容更多。AutoGen提供了一个称为*群聊管理器*的组件，它充当工作流程协调器。它可以提供几个对话代理——每个代理都有自己的角色、系统消息和工具——当向管理者提出问题时，管理者负责根据其判断将请求委派出去。
- en: 'A more recent library called [CrewAI](https://crewai.com) fills a similar ecological
    niche. As the name indicates, with CrewAI, you assemble “crews” of agents, each
    of which has its own role, goal, backstory, and tools. The agents are given tasks
    to resolve to accomplish an overall goal, and the agents can be arranged into
    a few different types of processes:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 一个名为[CrewAI](https://crewai.com)的较新库填补了类似的生态位。正如其名称所示，使用CrewAI，您可以组装“船员”团队，每个代理都有自己的角色、目标、背景故事和工具。代理被分配任务以解决以实现整体目标，代理可以被安排成几种不同类型的过程：
- en: Sequential
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 顺序性
- en: As in a pipeline.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 就像在管道中一样。
- en: Hierarchical
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 层级化
- en: A directs the work in a manner similar to the AutoGen group chat manager.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: A以类似于AutoGen群聊管理器的方式指导工作。
- en: Consensual
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性
- en: Agents collaborate to determine how work is accomplished—note that this is still
    in planning at the time of writing this chapter.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 代理协作以确定如何完成工作——请注意，这仍然是在撰写本章时的规划阶段。
- en: Conclusion
  id: totrans-182
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'At the beginning of this chapter, we revealed a trade-off that we are making
    with LLM technology. LLMs are certainly more general and often more powerful than
    old-school machine learning models that were architected and trained for a single
    task, but they are not at the level of full AGI. Therefore, we have to make a
    choice: do we aim for a fairly general intelligence that isn’t terribly powerful
    or a more powerful intelligence that is constrained to a narrower domain? In this
    chapter, we explored the latter option. We showed you how to use workflows to
    decompose complex goals into smaller tasks that you can then implement as a combination
    of conventional software and LLM solutions. In the later portion of the chapter,
    we also showed that you can treat the workflow itself as an agent that orchestrates
    these tasks.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的开头，我们揭示了我们在LLM技术中所做的权衡。LLM当然比专为单一任务设计和训练的传统机器学习模型更通用、更强大，但它们并没有达到完全AGI的水平。因此，我们必须做出选择：我们是追求一种相当通用的但并不特别强大的智能，还是追求一种更强大的智能，但这种智能被限制在更窄的领域内？在本章中，我们探讨了后一种选择。我们向您展示了如何使用工作流程将复杂的目标分解成更小的任务，然后您可以将其作为传统软件和LLM解决方案的组合来实施。在章节的后半部分，我们还展示了您可以将工作流程本身视为一个协调这些任务的代理。
- en: When you’re building your own workflow agents, remember that simpler is almost
    always better. Whenever you can avoid using LLMs, do so. Traditional software
    approaches or even traditional machine learning models are often more dependable
    and easier to debug than LLM-based solutions. When LLMs are required in your workflow,
    it’s still a good idea to keep the LLMs confined to tasks and then integrate the
    task agents into a traditional, deterministic, graph-based workflow. If something
    breaks, it’s much easier to isolate the problem to a task. Similarly, when you’re
    optimizing a workflow, it’s much easier to optimize each task in isolation rather
    than optimizing the entire workflow at once.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 当您构建自己的工作流程代理时，请记住，简单几乎总是更好的。只要可能，就避免使用LLM。传统的软件方法甚至传统的机器学习模型通常比基于LLM的解决方案更可靠，更容易调试。当您的流程需要LLM时，仍然将LLM限制在任务中，然后将任务代理集成到传统的、确定性的、基于图的流程中是个好主意。如果出现问题，将问题隔离到任务中要容易得多。同样，当您优化工作流程时，单独优化每个任务比一次性优化整个工作流程要容易得多。
- en: However, if your goals require the highest degree of flexibility, then step
    into the wild and try your hand at some of the ideas in the Advanced LLM Workflows
    section. While these methods are not yet fully stable or dependable, they are
    absolutely the frontier of development in prompt engineering. As the field moves
    forward, these are the methods and other ideas that we have yet to dream of—that
    will open all sorts of possibilities for LLM applications, from complex problem-solving
    to fully automated software development.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你的目标需要最高程度的灵活性，那么就踏入未知领域，尝试高级LLM工作流程部分的一些想法。虽然这些方法目前还不完全稳定或可靠，但它们绝对是提示工程发展的前沿。随着该领域的前进，这些方法以及其他我们尚未梦想到的想法将会为LLM应用开辟各种可能性，从复杂问题解决到完全自动化的软件开发。
- en: So, fine, you’ve created a workflow—but how do you know it’s doing the right
    thing? In the next chapter, we’ll look at LLM application evaluation.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，好吧，你已经创建了一个工作流程——但是你怎么知道它在做正确的事情呢？在下一章中，我们将探讨LLM应用评估。
