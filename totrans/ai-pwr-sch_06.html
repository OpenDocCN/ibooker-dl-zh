<html><head></head><body>
<div id="sbo-rt-content"><div class="readable-text" id="p1">
<h1 class="readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">5</span> </span> <span class="chapter-title-text">Knowledge graph learning</span></h1>
</div>
<div class="introduction-summary">
<h3 class="introduction-header sigil_not_in_toc">This chapter covers</h3>
<ul>
<li class="readable-text" id="p2">Building and working with knowledge graphs</li>
<li class="readable-text" id="p3">Implementing open information extraction to generate knowledge graphs from text</li>
<li class="readable-text" id="p4">Discovering arbitrary semantic relationships with semantic knowledge graphs</li>
<li class="readable-text" id="p5">Query expansion and rewriting using knowledge graphs</li>
<li class="readable-text" id="p6">Interpreting documents with knowledge graphs</li>
</ul>
</div>
<div class="readable-text" id="p7">
<p>In the last chapter, we primarily focused on learning the similarity between queries and documents based on users’ behavioral signals. In chapter 2, we also discussed how textual document content, instead of being “unstructured data”, is more like a giant graph of hyper-structured data containing a rich graph of semantic relationships connecting the many character sequences, terms, and phrases that exist across our collections of documents.</p>
</div>
<div class="readable-text intended-text" id="p8">
<p>In this chapter, we’ll demonstrate how to use this giant graph of semantic relationships within our content to better interpret domain-specific terminology. We’ll accomplish this by using both traditional knowledge graphs, which enable explicit modeling of relationships within a domain, and semantic knowledge graphs, which enable real-time inference of nuanced semantic relationships within a domain.</p>
</div>
<div class="readable-text intended-text" id="p9">
<p>A semantic knowledge graph is a simple kind of <em>language model</em> (a language model represents a probability distribution over sequences of words). We’ll use a semantic knowledge graph as a stepping stone to understanding large language models (LLMs) in later chapters. LLMs are deep neural networks typically trained on billions of parameters and massive amounts of data (often much of the known internet) to model a general representation of human knowledge. Semantic knowledge graphs, however, are queryable language models representing only the relationships that are actually within your search index. While semantic knowledge graphs don’t contain the ability to reason in general about language, they can be very powerful for domain-specific contextual inference, as we’ll see. </p>
</div>
<div class="readable-text intended-text" id="p10">
<p>We’ll also play with several fun datasets in this chapter, to show some variety in how knowledge graphs can be built and applied to improve query understanding across different domains.</p>
</div>
<div class="readable-text" id="p11">
<h2 class="readable-text-h2" id="sigil_toc_id_66"><span class="num-string">5.1</span> Working with knowledge graphs</h2>
</div>
<div class="readable-text" id="p12">
<p>In section 2.4, we introduced the idea of <em>knowledge graphs</em> and discussed how they relate to other types of knowledge models, such as ontologies, taxonomies, synonyms, and alternative labels. Knowledge graphs, if you recall, integrate each of those other types of knowledge models, so we’ll be referring to them all collectively as “knowledge graphs” as we build throughout this chapter. </p>
</div>
<div class="readable-text intended-text" id="p13">
<p>A knowledge graph (or any graph, for that matter) is represented through the concept of nodes (also known as <em>vertices</em>) and edges. A <em>node</em> is an entity represented in the knowledge graph (such as a term, person, place, thing, or concept), whereas an <em>edge</em> represents a relationship between two nodes. Figure 5.1 shows an example of a graph displaying nodes and edges. </p>
</div>
<div class="browsable-container figure-container" id="p14">
<img alt="figure" height="548" src="../Images/CH05_F01_Grainger.png" width="1013"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.1</span> A graph structure. Graphs are composed of nodes (also known as “vertices”) that represent entities and of edges that represent a node’s relationship with another node. Graphs provide a way to model knowledge and infer new insights by traversing (or “following”) the edges between nodes.</h5>
</div>
<div class="readable-text intended-text" id="p15">
<p>In this figure, you can see four nodes representing authors, one node representing a research paper they wrote together, one node representing the academic conference at which the paper was presented and published, and then nodes representing the city, province, country, and dates during which the conference was held. By traversing (or “following”) the independent edges between nodes, you might infer that one of the authors was in Montreal, Canada in October 2016. While any structure with nodes and edges like this is considered a graph, this particular graph represents factual knowledge and is therefore also considered a knowledge graph.</p>
</div>
<div class="readable-text intended-text" id="p16">
<p>There are numerous ways to build and represent knowledge graphs, both through explicitly modeling data as nodes and edges and through dynamically materializing (discovering) nodes and edges from your data in real time. The latter is what’s known as a <em>semantic knowledge graph</em>. In this chapter, we’ll walk through various examples including building an explicit knowledge graph by hand, autogenerating an explicit knowledge graph, and using a semantic knowledge graph that is already present within your search index.<span class="aframe-location"/></p>
</div>
<div class="readable-text intended-text" id="p17">
<p>To get started with knowledge graphs, you have essentially three options:</p>
</div>
<ul>
<li class="readable-text" id="p18"> Build a knowledge graph from scratch using a graph database (Neo4j, Apache TinkerPop, ArangoDB, etc.) </li>
<li class="readable-text" id="p19"> Plug in a preexisting knowledge graph (ConceptNet, DBpedia, a large language model, etc.) </li>
<li class="readable-text" id="p20"> Autogenerate a knowledge graph from your data, using your content directly to extract knowledge </li>
</ul>
<div class="readable-text" id="p21">
<p>Each approach has its strengths and weaknesses, though the approaches are not necessarily mutually exclusive. If you are building a general-knowledge search engine (such as a web search engine), utilizing a preexisting knowledge graph or large language model is a great place to start. If your search engine is more domain-specific, however, your domain-specific entities and terminology may not be present in a preexisting graph, requiring you to create a custom knowledge graph.</p>
</div>
<div class="readable-text intended-text" id="p22">
<p>In this chapter, we will focus primarily on the third option: autogenerating a knowledge graph from your content. The other two techniques are already covered well in external materials, using technologies like SPARQL, RDF Triples, and Apache Jena or preexisting knowledge graphs like DBpedia and Yago. You will still need to be able to override your knowledge graph and add custom content, so we will include examples of how you can integrate both explicitly defined knowledge graphs (built with a specific list of predefined relationships) and implicitly defined knowledge graphs (autogenerated relationships discovered dynamically from the data) into your search platform. </p>
</div>
<div class="readable-text" id="p23">
<h2 class="readable-text-h2" id="sigil_toc_id_67"><span class="num-string">5.2</span> Using our search engine as a knowledge graph</h2>
</div>
<div class="readable-text" id="p24">
<p>Many organizations spend considerable resources building out knowledge graphs for their organizations but have trouble integrating them within their search engines. We have fortunately chosen a default search engine implementation (Apache Solr) for our examples that has explicit graph traversal capabilities built in, so there is no need to pull in a new, external system to implement or traverse our knowledge graphs. </p>
</div>
<div class="readable-text intended-text" id="p25">
<p>While there may be some advantages to using an external graph database, such as Neo4J or ArangoDB, that supports more sophisticated graph traversal semantics, using an external system like this makes coordinating requests, keeping data in sync, and infrastructure management more complex. Additionally, because some kinds of graph operations can only be done effectively in the search engine (like the semantic knowledge graph traversals using an inverted index, which we’ll encounter shortly), using the search engine as a unified platform for both search and knowledge graph capabilities reduces the number of systems we’ll need to manage.</p>
</div>
<div class="readable-text intended-text" id="p26">
<p>We will focus extensively on implementing a semantic search system in chapter 7, including semantic query parsing, phrase extraction, misspelling detection, synonym expansion, and query rewriting, all of which will be modeled into an explicitly built knowledge graph. Since the purpose of the current chapter is to focus on knowledge graph <em>learning</em>, we’ll save most of the discussion of query-time integration pattens until chapter 7 when we can tie everything from this chapter and chapter 6 together into the appropriate knowledge graph structure. </p>
</div>
<div class="readable-text" id="p27">
<h2 class="readable-text-h2" id="sigil_toc_id_68"><span class="num-string">5.3</span> Automatically extracting knowledge graphs from content</h2>
</div>
<div class="readable-text" id="p28">
<p>While you’ll need to be able to modify nodes and edges in your knowledge graphs, manually maintaining a large-scale knowledge graph is very challenging. Manually maintained knowledge graphs require substantial subject matter expertise, must be actively kept up to date with changing information, and are subject to the biases and errors of those maintaining them. </p>
</div>
<div class="readable-text intended-text" id="p29">
<p><em>Open information extraction</em> is an evolving area of natural language processing (NLP) research. Open information extraction aims to extract facts directly from your text content. This is often done using NLP libraries and language models to parse sentences and assess the dependency graph between them. A <em>dependency graph</em> is a breakdown of the parts of speech for each word and phrase in a sentence, along with an indication of which words refer to which other words.</p>
</div>
<div class="readable-text intended-text" id="p30">
<p>More recent approaches to knowledge graph extraction tend to use LLMs specifically trained for entity extraction, such as UniRel (unified representation and interaction for joint relational triple extraction) and REBEL (relation extraction by end-to-end language generation). LLM-based approaches are likely to become the standard for knowledge graph extraction over time due to their ability to represent and extract more nuanced relationships between entities than traditional dependency graph–based approaches. For the sake of learning in this chapter, however, we’ll focus on the dependency graph–based approach, as it will provide a better foundation for understanding the mechanics of knowledge graph extraction from text and the ability to craft custom relationship extraction patterns. You can always switch to a more advanced LLM-driven approach later if it better suits your needs. </p>
</div>
<div class="readable-text intended-text" id="p31">
<p>In this section, we’ll use a language model and dependency graphs to extract two different types of relationships: arbitrary relationships and hyponym relationships.</p>
</div>
<div class="readable-text" id="p32">
<h3 class="readable-text-h3" id="sigil_toc_id_69"><span class="num-string">5.3.1</span> Extracting arbitrary relationships from text</h3>
</div>
<div class="readable-text" id="p33">
<p>Given the hyper-structured nature of text and the rich relationships expressed within typical sentences and paragraphs, it stands to reason that we should be able to identify the subjects and objects of sentences and how they are related. In this section, we’ll focus on extracting arbitrary relationships between the entities described within the sentences of our text content. </p>
</div>
<div class="readable-text intended-text" id="p34">
<p>By analyzing the nouns and verbs within a sentence, it is often possible to infer a fact that is present in the sentence and map that fact into an RDF triple (also known as a semantic triple). The Resource Description Framework (RDF) is a data model used to represent graphs and relationships. An <em>RDF triple</em> is a three-part data structure representing a subject (starting node), relationship (edge), and object (ending node). For example, in the sentence “Colin attends Riverside High School”, the verb “attends” can be extracted as a relationship type connecting the subject (“Colin”) with the object (“Riverside High School”). The RDF triple is therefore <code>("Colin", "attends",</code> <code>"Riverside High School")</code>. </p>
</div>
<div class="readable-text intended-text" id="p35">
<p>Listing 5.1 walks through an example of using the Python-based spaCy library to extract facts from text content. SpaCy is a popular natural language processing library that ships with state-of-the-art statistical neural network models for part-of-speech tagging, dependency parsing, text categorization, and named-entity recognition.</p>
</div>
<div class="browsable-container listing-container" id="p36">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 5.1</span> Extracting relationships and resolving co-references</h5>
<div class="code-area-container">
<pre class="code-area">def extract_relationships(text, lang_model, coref_model):
  resolved_text = resolve_coreferences(text, coref_model) <span class="aframe-location"/> #1
  sentences = get_sentences(resolved_text, lang_model) <span class="aframe-location"/> #2
  return resolve_facts(sentences, lang_model)<span class="aframe-location"/> #3

text = """
Data Scientists build machine learning models. They also write code.
Companies employ Data Scientists.
Software Engineers also write code. Companies employ Software Engineers.
"""
lang_model = spacy.load("en_core_web_sm")
coref_model = spacy.load("en_coreference_web_trf") <span class="aframe-location"/> #4
graph = extract_relationships(text, lang_model, coref_model)
print(graph)</pre>
<div class="code-annotations-overlay-container">
     #1 Resolves entities, such as replacing pronouns with nouns
     <br/>#2 Classifies parts of speech for the text
     <br/>#3 Generates RDF triples
     <br/>#4 The spaCy-experimental model used for co-reference resolution
     <br/>
</div>
</div>
</div>
<div class="readable-text" id="p37">
<p>Output:</p>
</div>
<div class="browsable-container listing-container" id="p38">
<div class="code-area-container">
<pre class="code-area">sentence: Data Scientists build machine learning models.
dependence_parse: ['nsubj', 'ROOT', 'dobj', 'punct']
---------------------
sentence: Data Scientists also write code.
dependence_parse: ['nsubj', 'advmod', 'ROOT', 'dobj', 'punct']
---------------------
sentence: Companies employ Data Scientists.
dependence_parse: ['nsubj', 'ROOT', 'dobj', 'punct']
---------------------
sentence: Software Engineers also write code.
dependence_parse: ['nsubj', 'advmod', 'ROOT', 'dobj', 'punct']
---------------------
sentence: Companies employ Software Engineers.
dependence_parse: ['nsubj', 'ROOT', 'dobj', 'punct']
---------------------
[['Data Scientists', 'build', 'machine learning models'],
 ['Data Scientists', 'write', 'code'],
 ['Companies', 'employ', 'Data Scientists'],
 ['Software Engineers', 'write', 'code'],
 ['Companies', 'employ', 'Software Engineers']]</pre>
</div>
</div>
<div class="readable-text" id="p39">
<p>As you can see, the example code has taken the text content, parsed it into sentences, and then determined the subjects, relationships, and objects within those sentences. Those RDF triples can then be saved into an explicitly built knowledge graph and traversed.</p>
</div>
<div class="readable-text intended-text" id="p40">
<p>Figure 5.2 provides a visualization of this extracted graph. Though this example is basic, advanced algorithms can extract facts from more sophisticated linguistic patterns. We are using the spaCy library in the code example, which uses a deep-learning-based neural language model to detect parts of speech, phrases, dependencies, and co-references within the input text. The mechanism we then employ to parse those linguistic outputs into RDF triples is more rules-based, following known semantic patterns within the English language. </p>
</div>
<div class="readable-text intended-text" id="p41">
<p>Unfortunately, when parsing arbitrary verbs into relationships this way, the extracted relationships can become quite noisy. Since verbs conjugate differently, have synonyms, and have overlapping meanings, it is often necessary to prune, merge, and otherwise clean up any list of arbitrary extracted relationships.</p>
</div>
<div class="readable-text intended-text" id="p42">
<p>In contrast, some relationship types are much simpler, such as statistical relationships (“is related to”) and hyponyms (“is a”). We’ll spend the rest of the chapter focusing primarily on using these two special types, starting with hyponyms. </p>
</div>
<div class="browsable-container figure-container" id="p43">
<img alt="figure" src="../Images/CH05_F02_Grainger.png" width="80%"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.2</span> Extracted knowledge graph. The nodes and edges in this graph were automatically extracted from textual content based upon part-of-speech patterns.<span class="aframe-location"/></h5>
</div>
<div class="readable-text" id="p44">
<h3 class="readable-text-h3" id="sigil_toc_id_70"><span class="num-string">5.3.2</span> Extracting hyponyms and hypernyms from text</h3>
</div>
<div class="readable-text" id="p45">
<p>While it can be challenging mapping arbitrary verbs to clean lists of relationships within a knowledge graph, extracting hyponyms and hypernyms can be much easier. <em>Hyponyms</em> are entities that maintain an “is a” or “is instance of” relationship with a more general form of the entities, with the more general form being called a <em>hypernym</em>. For example, for the relationships between the terms “phillips head”, “screwdriver”, and “tool”, we would say that “phillips head” is a hyponym of “screwdriver”, that “tool” is a hypernym of “screwdriver”, and that “screwdriver” is both a hypernym of “phillips head” and a hyponym of “tool”. </p>
</div>
<div class="readable-text intended-text" id="p46">
<p>One common and fairly accurate way to extract hyponym/hypernym relationships from text is through the use of Hearst patterns, described by Marti Hearst in “Automatic Acquisition of Hyponyms from Large Text Corpora” (in <em>COLING 1992 Volume 2: The 14th International Conference on Computational Linguistics</em>, 1992). These patterns describe common linguistic templates that reliably indicate the presence of hyponyms within sentences. The following listing demonstrates a few examples of such patterns. </p>
</div>
<div class="browsable-container listing-container" id="p47">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 5.2</span> Hearst patterns that identify semantic relationships</h5>
<div class="code-area-container">
<pre class="code-area">simple_hearst_patterns = [
  ("(NP_\\w+ (, )?such as (NP_\\w+ ?(, )?(and |or )?)+)", "first"),
  ("(such NP_\\w+ (, )?as (NP_\\w+ ?(, )?(and |or )?)+)", "first"),
  ("((NP_\\w+ ?(, )?)+(and |or )?other NP_\\w+)", "last"),
  ("(NP_\\w+ (, )?include (NP_\\w+ ?(, )?(and |or )?)+)", "first"),
  ("(NP_\\w+ (, )?especially (NP_\\w+ ?(, )?(and |or )?)+)", "first")]</pre>
</div>
</div>
<div class="readable-text" id="p48">
<p>Each of these five simple patterns is represented as a Python tuple, with the first entry being a <em>regular expression</em> and the second being a position within the pattern match (i.e., <code>first</code> or <code>last</code>). If you are unfamiliar with regular expressions, they provide a common and powerful syntax for pattern matching within strings. Anywhere you see the <em>NP</em> characters, this stands for the existence of a <em>noun phrase</em> within a sentence. The position specified in the second element of the tuple (<code>first</code> or <code>last</code>) indicates which noun phrase in the sentence represents the hypernym, with all other noun phrases matching the pattern considered the hyponyms. </p>
</div>
<div class="readable-text intended-text" id="p49">
<p>In the following listing, we run through almost 50 of these Hearst patterns to match many combinations of “is a” relationships within our content.</p>
</div>
<div class="browsable-container listing-container" id="p50">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 5.3</span> Extracting hyponym relationships using Hearst patterns</h5>
<div class="code-area-container">
<pre class="code-area">text_content = """Many data scientists have skills such as machine learning,
python, deep learning, apache spark, among others. Job candidates most
prefer job benefits such as commute time, company culture, and salary.
Google, Apple, or other tech companies might sponsor the conference.
Big cities such as San Francisco, Miami, and New York often appeal to
new graduates. Job roles such as Software Engineer, Registered Nurse,
and DevOps Engineer are in high demand. There are job benefits including
health insurance and pto."""

extracted_relationships = HearstPatterns().find_hyponyms(text_content)
facts = [[pair[0], "is_a", pair[1]] for pair in extracted_relationships]
print(*facts, sep="\n")</pre>
</div>
</div>
<div class="readable-text" id="p51">
<p>Output:</p>
</div>
<div class="browsable-container listing-container" id="p52">
<div class="code-area-container">
<pre class="code-area">['machine learning', 'is_a', 'skill']
['python', 'is_a', 'skill']
['deep learning', 'is_a', 'skill']
['apache spark', 'is_a', 'skill']
['commute time', 'is_a', 'job benefit']
['company culture', 'is_a', 'job benefit']
['salary', 'is_a', 'job benefit']
['Google', 'is_a', 'tech company']
['Apple', 'is_a', 'tech company']
['San Francisco', 'is_a', 'big city']
['Miami', 'is_a', 'big city']
['New York', 'is_a', 'big city']
['Software Engineer', 'is_a', 'Job role']
['Registered Nurse', 'is_a', 'Job role']
['DevOps Engineer', 'is_a', 'Job role']
['health insurance', 'is_a', 'job benefit']
['pto', 'is_a', 'job benefit']</pre>
</div>
</div>
<div class="readable-text" id="p53">
<p>As you can see from this listing, by focusing on extracting a fixed type of relationship (and the most prevalent one—the “is a” relationship), we can generate a nice, clean list of taxonomical facts with the more specific term (the hyponym) pointing to the more general term (the hypernym) with an <code>is_a</code> edge. Figure 5.3 demonstrates this generated graph visually.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p54">
<img alt="figure" height="1096" src="../Images/CH05_F03_Grainger.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.3</span> Knowledge graph derived from Hearst patterns. We can see that all nodes are connected to other nodes through an <code>is_a</code> edge.</h5>
</div>
<div class="readable-text" id="p55">
<p>The inconsistency and noise that exists with arbitrary relationship extraction is significantly reduced by utilizing Hearst patterns. We could still have ambiguity about the relationship between similar terms (for example, misspellings, alternative spellings, known phrases, or synonyms), but those are much easier to resolve. In fact, we’ll spend the entire next chapter discussing how to learn this kind of domain-specific language from your signals and content to use it when interpreting incoming user queries.</p>
</div>
<div class="readable-text intended-text" id="p56">
<p>Although it can be useful to extract information from our text into an explicit knowledge graph for later traversal, the reality is that this kind of extraction is a lossy process, as the representation of the items gets disconnected from the originating context of those items within our content (the surrounding text and documents containing the text). In the next section, we’ll introduce an entirely different kind of knowledge graph—a semantic knowledge graph—that is optimized to enable real-time traversal and ranking of the relationships between terms and phrases within our content without having to be explicitly built and without separating terms from their original textual context. </p>
</div>
<div class="readable-text" id="p57">
<h2 class="readable-text-h2" id="sigil_toc_id_71"><span class="num-string">5.4</span> Learning intent by traversing semantic knowledge graphs</h2>
</div>
<div class="readable-text" id="p58">
<p>In chapter 2, sections 2.1 and 2.2, we discussed the myth of text content being “unstructured data” and how, in reality, text documents represent hyper-structured data. We discussed the distributional hypothesis (“a word shall be known by the company it keeps”) and walked through how character sequences, terms, phrases, and other arbitrary term sequences can be thought of as fuzzy foreign keys relating similar concepts between documents. We also discussed how these links between documents can be thought of as edges in a giant graph of relationships, enabling us to learn the contextual meaning of the terms and entities present within our corpus of documents. </p>
</div>
<div class="readable-text intended-text" id="p59">
<p>In this section, we’ll introduce a semantic knowledge graph, a tool and technique that will enable us to traverse that giant graph of semantic relationships present within our documents.</p>
</div>
<div class="readable-text" id="p60">
<h3 class="readable-text-h3" id="sigil_toc_id_72"><span class="num-string">5.4.1</span> What is a semantic knowledge graph?</h3>
</div>
<div class="readable-text" id="p61">
<p>A <em>semantic knowledge graph</em> (SKG) is a “compact, auto-generated model for real-time traversal and ranking of any relationship within a domain”.<a href="#footnote-113" id="ftnote-113"><sup class="footnote-reference">1</sup></a> We can think of an SKG as a search engine that, instead of matching and ranking documents, finds and ranks <em>terms</em> that best match a query. </p>
</div>
<div class="readable-text intended-text" id="p62">
<p>For example, if we indexed a collection of documents about health topics and searched for <code>advil</code>, instead of returning documents that contain the term for the pain reliever “advil”, an SKG would automatically (with no manual list creation or data modeling required) return values like these:</p>
</div>
<div class="browsable-container listing-container" id="p63">
<div class="code-area-container">
<pre class="code-area">advil  0.71
motrin  0.60
aleve  0.47
ibuprofen  0.38
alleve  0.37</pre>
</div>
</div>
<div class="readable-text" id="p64">
<p>Such results can be thought of as “dynamic synonyms”, but instead of the terms having the same meaning, they are more like conceptually related terms. You could expand a lexical search engine query for <code>advil</code> to include these other terms to improve the recall of your search results or to boost documents that conceptually match the meaning of “advil”, instead of just the string containing the five characters <code>a</code>, <code>d</code>, <code>v</code>, <code>i</code>, <code>l</code>.</p>
</div>
<div class="readable-text intended-text" id="p65">
<p>In addition to finding related terms, an SKG can traverse between fields in your inverted index (“find the most-related skills to this job title”), traverse multiple levels deep (“find the most-related job titles to this query and then find the most-related skills for this query and each of those job titles”), and use any arbitrary query you can send to the search engine as a node in the graph traversal to find semantically related terms in any field.</p>
</div>
<div class="readable-text intended-text" id="p66">
<p>The use cases for SKGs are diverse. They can be used for query expansion, generating content-based recommendations, query classification, query disambiguation, anomaly detection, data cleansing, and predictive analytics. We’ll explore several of these in the remainder of this chapter, but let’s first set up some datasets for testing our SKG. </p>
</div>
<div class="readable-text" id="p67">
<h3 class="readable-text-h3" id="sigil_toc_id_73"><span class="num-string">5.4.2</span> Indexing the datasets</h3>
</div>
<div class="readable-text" id="p68">
<p>An SKG works best on datasets where there is more overlap of terms being used together across documents. The more often two words tend to appear within documents, the better we can determine whether those terms appear statistically more often than we would expect. </p>
</div>
<div class="readable-text intended-text" id="p69">
<p>Although Wikipedia is often a good starting dataset for many use cases, it usually has a single page about a major topic that is supposed to be authoritative, so there isn’t significant overlap across most documents, making Wikipedia a poor dataset for this use case. In contrast, most other websites where users submit the content (questions, forum posts, job postings, social media posts, reviews) tend to have excellent datasets for an SKG use case.</p>
</div>
<div class="readable-text intended-text" id="p70">
<p>For this chapter, we have selected two primary datasets: a jobs dataset (job board postings) and a series of Stack Exchange data dumps including posts from the following forums:</p>
</div>
<ul>
<li class="readable-text" id="p71"> health </li>
<li class="readable-text" id="p72"> scifi </li>
<li class="readable-text" id="p73"> devops </li>
<li class="readable-text" id="p74"> travel </li>
<li class="readable-text" id="p75"> cooking </li>
</ul>
<div class="readable-text" id="p76">
<h3 class="readable-text-h3" id="sigil_toc_id_74"><span class="num-string">5.4.3</span> Structure of an SKG</h3>
</div>
<div class="readable-text" id="p77">
<p>To best utilize an SKG, it is useful to understand how the graph works based on its underlying structure. </p>
</div>
<div class="readable-text intended-text" id="p78">
<p>Unlike a traditional knowledge graph, which must be explicitly modeled into nodes and edges, an SKG is <em>materialized</em> from the underlying inverted index of your search engine. This means that all you need to do to produce an SKG is to index documents into a search engine. No extra data modeling is required.</p>
</div>
<div class="readable-text intended-text" id="p79">
<p>The inverted index and a corresponding forward index then serve as the underlying data structure that enables real-time traversal and ranking of any arbitrary semantic relationships present within your collection of documents.</p>
</div>
<div class="readable-text intended-text" id="p80">
<p>Figure 5.4 demonstrates how documents get added into both the forward index and the inverted index. On the left of the figure, you can see three documents, each<span class="aframe-location"/> of which has a <code>job_title</code> field, a <code>desc</code> field, and a <code>skills</code> field. The right side of the figure shows how these documents are mapped into your search engine. We see that the inverted index maps each field to a list of terms, and then maps each term to a postings list containing a list of documents (along with positions in the documents, as well as some other data not included in the figure). This makes it quick and efficient to look up any term in any field and find the set of all documents containing that term.</p>
</div>
<div class="browsable-container figure-container" id="p81">
<img alt="figure" height="738" src="../Images/CH05_F04_Grainger.png" width="919"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.4</span> Inverted index and forward index. Documents get added to an inverted index, which maps documents to lists of terms, and to a forward index, which maps terms back to lists of documents. Having the ability to map both directions will prove important for graph traversal and relationship discovery.</h5>
</div>
<div class="readable-text intended-text" id="p82">
<p>In addition to the well-known inverted index, you can also see the less-well-known <em>forward index</em> in the center of figure 5.4. A forward index can be thought of as an <em>uninverted index</em>: for each field, it maps each document to a list of terms contained within that document. A forward index is what search engines use to generate <em>facets</em> (also called <em>aggregations</em>) on search results, which show the top values per field from a set of documents. In Lucene-based search engines like Solr, OpenSearch, and Elasticsearch, a forward index is usually generated at index time for a field by enabling a feature called <em>doc values</em> on the field. Alternatively, Apache Solr also allows you to generate the same forward index by “uninverting” the inverted index in memory at query time, enabling faceting even on fields for which doc values weren’t added to the index. </p>
</div>
<div class="readable-text intended-text" id="p83">
<p>If you have the ability to search for arbitrary queries and find sets of documents through an inverted index (traversing from terms to documents), and you also have the ability to take arbitrary sets of documents and look up terms in those documents (traversing from documents to terms), this means that by doing two traversals (terms to documents to terms) you can find all of the related terms that appear across any documents matching the query. Figure 5.5 demonstrates how such a traversal can occur, including a data structure view, a set-theory view, and a graph view.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p84">
<img alt="figure" height="520" src="../Images/CH05_F05_Grainger.png" width="1009"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.5</span> Three representations of an SKG. The data structure view shows terms mapped to sets of documents, the set-theory view shows how the intersection of sets of documents forms the relationship between them, and the graph view shows the nodes and edges.</h5>
</div>
<div class="readable-text" id="p85">
<p>In the data structure view, which represents our inverted and forward indices, we see how terms are related to documents based on whether they appear within them. Those relationship links are only present if there is an intersection between the docs that any two nodes (terms, in this case) appear within in the set-theory view. The graph view, finally, demonstrates a third view into the same underlying data structures, but in this case we see nodes (instead of document sets) and edges (instead of intersecting document sets). Essentially, the SKG exists as an abstraction on top of the inverted index that is already built and updated anytime the search engine indexes content.</p>
</div>
<div class="readable-text intended-text" id="p86">
<p>We typically consider the primary function of search engines to be accepting a query, finding matching documents, and returning those documents in a relevance-ranked order. We devoted all of chapter 3 to discussing this process, walking through matching (sections 3.2.4–3.2.6), TF-IDF ranking (section 3.1), and the commonly used BM25 ranking function (section 3.2.1). However, with an SKG, we focus on matching and ranking related <em>terms</em>, as opposed to related documents.</p>
</div>
<div class="readable-text intended-text" id="p87">
<p>Any arbitrary query (anything you can resolve to a document set) can be a node in your graph, and you can traverse from that node to any other term (or arbitrary query) in any document field. Additionally, since each traversal of an edge between two nodes uses both an inverted index (terms to docs) and a forward index (docs to terms), it is trivial to chain these traversals together into a multilevel graph traversal, as shown in figure 5.6.</p>
</div>
<div class="readable-text intended-text" id="p88">
<p>In the figure, the data structure view shows a traversal from a skill node (<code>Java</code>) to a layer of other skills nodes (<code>Java</code>, <code>Oncology</code>, <code>Hibernate</code>, and <code>Scala</code>), to a layer of job title nodes (<code>Software Engineer</code>, <code>Data Scientist</code>, and <code>Java Developer</code>). You can see that not all nodes are connected—the node for <code>Oncology</code>, for example, does not appear in the graph view because none of the original nodes can connect to it through any edges—there are no overlapping documents.</p>
</div>
<div class="readable-text intended-text" id="p89">
<p>Given that not all possible nodes are going to be relevant for any given traversal, it is also important that SKGs be able to score and assign a weight to the relationships between nodes so that those edges can be prioritized during any graph traversal. We will cover the scoring and assignment of weights to edges in the next section. </p>
</div>
<div class="readable-text" id="p90">
<h3 class="readable-text-h3" id="sigil_toc_id_75"><span class="num-string">5.4.4</span> Calculating edge weights to measure the relatedness of nodes</h3>
</div>
<div class="readable-text" id="p91">
<p>Given that the primary function of an SKG is to discover relevant semantic relationships between nodes, the ability to calculate <em>semantic similarity</em> is critical. But what exactly is semantic similarity?</p>
</div>
<div class="readable-text intended-text" id="p92">
<p>If you recall, the distributional hypothesis, introduced in section 2.3, says that words appearing together in the same contexts and with similar distributions tend to share similar meanings. Intuitively, this makes sense—the terms “pain” or “swelling” will be more likely to occur in documents that also mention “advil”, “ibuprofen”, or “ice pack” than in some random documents. Interestingly, though, “ice pack” may also occur in documents containing terms like “cooler”, “road trip”, or “cold”, whereas “advil” and “ibuprofen” likely would not.</p>
</div>
<div class="browsable-container figure-container" id="p93">
<img alt="figure" src="../Images/CH05_F06_Grainger.png" width="80%"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.6</span> Multilevel graph traversal. In the data structure view, we see two traversals: through the inverted index and then the forward index each time. In the graph structure view, we see the corresponding two-level traversal: from skills to skills to job titles.<span class="aframe-location"/></h5>
</div>
<div class="readable-text" id="p94">
<p>These examples show words (and their contexts) with similar meanings, but let’s also consider words like “a”, “the”, “of”, “and”, “if”, “they”, and countless other very common stop words. These words will also appear heavily within the same contexts of “pain”, “swelling”, “advil”, “ibuprofen”, or any of the other words we examined. This points to the second part of the distributional hypothesis—that the words must also occur with similar distributions. In essence, this means that given some number of documents containing a first term, any second term tends to be semantically similar to the first term if it co-occurs in the same documents as the first term more often than it co-occurs in documents with other random terms.</p>
</div>
<div class="readable-text intended-text" id="p95">
<p>Practically, since “the” or “a” tend to co-occur commonly with almost all other terms, they are not considered semantically similar to those terms even though their level of co-occurrence is high. Terms like “pain” and “ibuprofen”, however, occur together statistically way more often than either term appears with random other terms, so they are considered semantically similar.</p>
</div>
<div class="readable-text intended-text" id="p96">
<p>The following equation demonstrates one way to calculate the semantic relatedness of a term to a set of documents:<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p97">
<img alt="figure" height="92" src="../Images/grainger-ch5-eqs-0x.png" width="507"/>
</div>
<div class="readable-text" id="p98">
<p>where</p>
</div>
<ul>
<li class="readable-text" id="p99"> <code>x</code> is a query (usually a term or term sequence) for which the relatedness is calculated relative to another query, the foreground query <code>fg</code>. <code>D<sub>x</sub></code> is the set of documents matching the query <code>x</code>. </li>
<li class="readable-text" id="p100"> <code>D<sub>fg</sub></code> is the set of documents matching the foreground query <code>fg</code>. The relatedness of <code>x</code> is calculated relative to this foreground set. </li>
<li class="readable-text" id="p101"> <code>D<sub>bg</sub></code> is the set of documents matching the background query <code>bg</code>. This <code>bg</code> query should be uncorrelated with <code>x</code> and <code>fg</code> and is usually set to match the entire collection of documents <code>D</code> or a random sample from <code>D</code>. </li>
<li class="readable-text" id="p102"> <code>P<sub>x</sub></code> is the probability of finding <code>x</code> in a random document in the background set, calculated as <span><img alt="equation image" height="30" src="../Images/eq-chapter-5-102-1.png" width="114"/></span> </li>
</ul>
<div class="readable-text" id="p103">
<p>This <code>relatedness</code> calculation (conceptually similar to a z-score in a normal distribution) relies on the concept of a “foreground” set of documents and a “background” set of documents and enables the distribution of the term <code>x</code> to be statistically compared between the two sets. For example, if the foreground set was all documents matching the query <code>pain</code>, and the background set was all documents, then the relatedness of the term “advil” would be a measure of how much more often “advil” occurs in documents also containing the word “pain” (foreground set) versus in any random document (background set). It’s most common to normalize the relatedness score using a sigmoid function to map values between –1.0 and 1.0, with 0.0 indicating no relationship between the terms. For simplicity, we’ll rely on this normalized range of values in the code and all subsequent examples. </p>
</div>
<div class="readable-text intended-text" id="p104">
<p>If two terms are highly related, their relatedness will be a positive number approaching 1.0. If the terms are highly unrelated (meaning they tend to occur in divergent domains only), the score would be closer to –1.0. Finally, terms that aren’t semantically related at all—like stop words—will tend to have a relatedness score close to zero.</p>
</div>
<div class="readable-text intended-text" id="p105">
<p>Apache Solr has SKG capabilities built directly into its faceting API. Faceting provides the ability to traverse from terms to sets of documents to terms, and a relatedness aggregation function (<code>RelatednessAgg</code>) implements the semantic similarity calculation we just described. The following listing demonstrates searching for semantically related terms to “advil” within the Stack Exchange health dataset. </p>
</div>
<div class="browsable-container listing-container" id="p106">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 5.4</span> Discovering semantically related terms to <code>advil</code></h5>
<div class="code-area-container">
<pre class="code-area">health_skg = get_skg(engine.get_collection("health"))

nodes_to_traverse = [{"field": "body", <span class="aframe-location"/> #1
                      "values": ["advil"]}, <span class="aframe-location"/> #2
                     {"field": "body",
                    <span class="aframe-location"/>  "min_occurrences": 2,  #3
                      "limit": 8}] <span class="aframe-location"/> #4

traversal = health_skg.traverse(*nodes_to_traverse) <span class="aframe-location"/> #5
print_graph(traversal, "advil")<span class="aframe-location"/> #6</pre>
<div class="code-annotations-overlay-container">
     #1 The field in which to find values for the starting node
     <br/>#2 Our starting node is the query “advil”.
     <br/>#3 Reduces noise by excluding terms not found at least this many times
     <br/>#4 How many nodes (terms) will be returned
     <br/>#5 Performs the graph traversal
     <br/>#6 Prints the results of the SKG traversal
     <br/>
</div>
</div>
</div>
<div class="readable-text" id="p107">
<p>Output:</p>
</div>
<div class="browsable-container listing-container" id="p108">
<div class="code-area-container">
<pre class="code-area">advil  0.70986
motrin  0.59897
aleve  0.4662
ibuprofen  0.38264
alleve  0.36649
tylenol  0.33048
naproxen  0.31226
acetaminophen  0.17706</pre>
</div>
</div>
<div class="readable-text" id="p109">
<p>As you can see, of all the terms within the forum posts in the Stack Exchange health dataset, the ranked order of the most semantically related terms to <code>advil</code> was a list of similar painkillers. This is the magic of using the distributional hypothesis to discover and rank terms by semantic similarity—it provides us with the ability to automatically discover relationships in real time that can be used to further improve our understanding of incoming queries.</p>
</div>
<div class="readable-text intended-text" id="p110">
<p>The following is a Solr SKG request, which uses Solr’s JSON faceting API and ability to sort on a function—the <code>relatedness</code> calculation we just discussed.</p>
</div>
<div class="browsable-container listing-container" id="p111">
<div class="code-area-container">
<pre class="code-area">{
  "limit": 0,
  "params": {
    "q": "*",
    "fore": "{!${defType} v=$q}",
    "back": "*",
    "defType": "edismax",
    "f0_0_query": "advil"
  },
  "facet": {
    "f0_0": {
      "type": "query",
      "query": "{!edismax qf=body v=$f0_0_query}",
      "field": "body",
      "sort": {"relatedness": "desc"},
      "facet": {"relatedness": {"type": "func",
                                "func": "relatedness($fore,$back)"},
        "f1_0": {
          "type": "terms",
          "mincount": 2,
          "limit": 8,
          "sort": {"relatedness": "desc"},
          "facet": {"relatedness": {"type": "func",
                                    "func": "relatedness($fore,$back)"}
}}}}}}</pre>
</div>
</div>
<div class="readable-text" id="p112">
<p>The <code>skg.traverse(*nodes_to_traverse)</code> function in listing 5.4 abstracts away this engine-specific syntax, but if you’re trying to understand the nuances of how your specific search engine or vector database internally handles these kinds of knowledge graph traversals, you can inspect the function in the notebooks. We’ll mostly show the <code>skg.traverse</code> abstraction going forward, but you can always call the <code>skg.transform_ request(*nodes_to_traverse)</code> function directly to see and debug the internal, engine-specific request. </p>
</div>
<div class="readable-text intended-text" id="p113">
<p>In the next section, we’ll discuss how we can apply the related terms returned from this SKG traversal to improve query relevance. </p>
</div>
<div class="readable-text" id="p114">
<h3 class="readable-text-h3" id="sigil_toc_id_76"><span class="num-string">5.4.5</span> Using SKGs for query expansion</h3>
</div>
<div class="readable-text" id="p115">
<p>Matching and ranking solely on the keywords entered during a search doesn’t always provide sufficient context to find and rank the best results. In these cases, you can significantly improve the quality of search results by dynamically expanding or otherwise augmenting queries to include conceptually related terms. In this section, we’ll walk through how you can generate these related terms, and we’ll demonstrate several strategies for applying the terms to enhance the quality of your search results. </p>
</div>
<div class="readable-text intended-text" id="p116">
<p>Given its ability to start with any keyword or query and to find other highly related terms in any field, one obvious use case for an SKG is to dynamically expand queries to include related terms. This kind of expansion is sometimes referred to as <em>sparse lexical expansion</em>, as it operates on sparse vectors of query tokens made of term-based (lexical) features. One well-known technique for implementing this kind of query expansion is SPLADE (the Sparse Lexical and Expansion model), which we’ll cover in section 7.4.3. Semantic knowledge graphs also provide a great way to generate contextual, sparse lexical expansions and have the benefit that they require no additional fine-tuning to your dataset. This enables documents to match even if they don’t necessarily contain the exact keywords entered by the user, but they do contain other terms that carry a very similar meaning. For example, instead of a user’s query for <code>advil</code>, an expanded query with boosted terms generated by the SKG might look something like <code>advil</code> <code>OR</code> <code>motrin^0.59897</code> <code>OR</code> <code>aleve^0.4662</code> <code>OR</code> <code>ibuprofen^0.3824</code> <code>OR</code> <code>.</code> <code>.</code> <code>.</code>. </p>
</div>
<div class="readable-text intended-text" id="p117">
<p>Let’s walk through the steps for implementing this kind of query expansion, using a dataset from a different domain this time (the Stack Exchange scifi dataset). The following listing shows the first step in this process: searching for an obscure term (as a node in the SKG) and finding related other terms (as related nodes in the SKG). In this case, we’ll use the query for <code>vibranium</code> as our starting node.</p>
</div>
<div class="browsable-container listing-container" id="p118">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 5.5</span> Discovering context for the unknown term “vibranium”</h5>
<div class="code-area-container">
<pre class="code-area">stackexchange_skg = get_skg(engine.get_collection("stackexchange"))

query = "vibranium"
nodes_to_traverse = [{"field": "body", "values": [query]},
                     {"field": "body", "min_occurrences": 2, "limit": 8}]

traversal = stackexchange_skg.traverse(*nodes_to_traverse)

print_graph(traversal, query)</pre>
</div>
</div>
<div class="readable-text" id="p119">
<p>Response:</p>
</div>
<div class="browsable-container listing-container" id="p120">
<div class="code-area-container">
<pre class="code-area">vibranium  0.94237
wakandan  0.8197
adamantium  0.80724
wakanda  0.79122
alloy  0.75724
maclain  0.75623
klaw  0.75222
america's  0.74002</pre>
</div>
</div>
<div class="readable-text" id="p121">
<p>For anyone unfamiliar with the term “vibranium”, it is a strong, fictional metal that exists in Marvel comic books and movies (best popularized through the 2018 Hollywood hit <em>Black Panther</em>). The most related terms that came back were related to “Wakandan” and “Wakanda”, the fictional culture and country from which vibranium originates, “adamantium”, another strong (fictional) metal from Marvel comics, and the names “Maclain” and “Klaw”, characters in the Marvel comic books that are heavily associated with the metal vibranium. Maclain created the vibranium “alloy” used to make Captain “America’s” shield, hence the relatedness of those words.</p>
</div>
<div class="readable-text intended-text" id="p122">
<p>An autogenerated knowledge graph is very effective at identifying related pieces of information. By using an SKG and expanding your query to include additional related context, you can drastically improve the recall of your search requests. By boosting results that best match your query conceptually (as opposed to just the text), you may also be able to improve the precision of your top-ranked search results.</p>
</div>
<div class="readable-text intended-text" id="p123">
<p>The following listing demonstrates an example of translating this original query, along with the SKG output, into an expanded query.</p>
</div>
<div class="browsable-container listing-container" id="p124">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 5.6</span> Expanding a query with nodes in an SKG</h5>
<div class="code-area-container">
<pre class="code-area">expansion = ""
for term, stats in traversal["graph"][0]["values"][query] \
                       ["traversals"][0]["values"].items():
  expansion += f'{term}^{stats["relatedness"]} '
expanded_query = f"{query}^5 " + expansion

print(f"Expanded Query:\n{expanded_query}")</pre>
</div>
</div>
<div class="readable-text" id="p125">
<p>Expanded query:</p>
</div>
<div class="browsable-container listing-container" id="p126">
<div class="code-area-container">
<pre class="code-area">vibranium^5 vibranium^0.94237 wakandan^0.8197 adamantium^0.80724
wakanda^0.79122 alloy^0.75724 maclain^0.75623 klaw^0.75222 america's^0.74002</pre>
</div>
</div>
<div class="readable-text" id="p127">
<p>In this case, we are doing a simple Boolean OR search for any of the keywords related to the original query <code>vibranium</code>, boosting the original query term’s weight by a factor of 5x and weighting each subsequent term’s effect on the relevance score based upon its semantic similarity score. The choice to boost the original term by 5x is arbitrary—you can choose any value here to assign a relative relevance boost compared to the other (expanded) terms.</p>
</div>
<div class="readable-text intended-text" id="p128">
<p>You might also notice that the term “vibranium” appears twice—first as the original term, and then again as an expanded term (since the term is <em>also</em> the most semantically similar to itself). This will almost always be the case if you are searching for individual keywords, but since your query might have phrases or other constructs that make the original query different from the returned terms (if any), it is usually a good idea to include the original query as part of the expanded (rewritten) query, so the user’s actual query is always represented in the results.</p>
</div>
<div class="readable-text intended-text" id="p129">
<p>Although the prior expanded query should rank the results reasonably well (prioritizing documents matching multiple related terms), it is also heavily focused on <em>recall</em> (expanding to include anything relevant) as opposed to <em>precision</em> (ensuring everything included is relevant). An augmented query can be constructed in many ways, depending on your primary goals. </p>
</div>
<div class="readable-text intended-text" id="p130">
<p>Rewritten queries can perform a simple expansion, require a minimum percentage or number of terms to match, require specific terms like the original query to match, or even just change the ranking of the same initial results set. The following listing demonstrates several examples, using minimum match thresholds and percentages, which can tilt the scale between precision and recall as needed.</p>
</div>
<div class="browsable-container listing-container" id="p131">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 5.7</span> Different query augmentation strategies</h5>
<div class="code-area-container">
<pre class="code-area">def generate_request(query, min_match=None, boost=None):
  request = {"query": query,
             "query_fields": ["title", "body"]}
  if min_match:
    request["min_match"] = min_match
  if boost:
    request["query_boosts"] = boost
  return request

simple_expansion = generate_request(f"{query} {expansion}", "1")
increased_conceptual_precision = \
  generate_request(f"{query} {expansion}", "30%")
increased_precision_same_recall = \
  generate_request(f"{query} AND ({expansion})", "2")
slightly_increased_recall = generate_request(f"{query} {expansion}", "2")
same_results_better_ranking = generate_request(query, "2", expansion)</pre>
</div>
</div>
<div class="readable-text" id="p132">
<p>Let’s look at the final search queries for each of the preceding query expansion techniques.</p>
</div>
<div class="readable-text intended-text" id="p133">
<p>Simple query expansion: <code>simple_expansion</code></p>
</div>
<div class="browsable-container listing-container" id="p134">
<div class="code-area-container code-area-with-html">
<pre class="code-area">{"query": "vibranium vibranium^0.94237 wakandan^0.8197 adamantium^0.80724
         <span class="">↪</span>wakanda^0.79122 alloy^0.75724 maclain^0.75623 klaw^0.75222
         <span class="">↪</span>america's^0.74002 ",
 "query_fields": ["title", "body"],
 "min_match": "0%"}</pre>
</div>
</div>
<div class="readable-text" id="p135">
<p>This simple query expansion is the same as previously described, matching any documents containing either the original query or any of the semantically related terms.</p>
</div>
<div class="readable-text intended-text" id="p136">
<p>Increased-precision, reduced-recall query: <code>increased_conceptual_precision</code></p>
</div>
<div class="browsable-container listing-container" id="p137">
<div class="code-area-container code-area-with-html">
<pre class="code-area">{"query": "vibranium AND (vibranium^0.94237 wakandan^0.8197
         <span class="">↪</span>adamantium^0.80724 wakanda^0.79122 alloy^0.75724
         <span class="">↪</span>maclain^0.75623 klaw^0.75222 america's^0.74002)",
 "query_fields": ["title", "body"],
 "min_match": "30%"}</pre>
</div>
</div>
<div class="readable-text" id="p138">
<p>This increased-precision, reduced-recall example specifies a “minimum match” threshold of 30%, meaning that for a document to match, it must contain at least 30% (rounded down) of the terms in the query.</p>
</div>
<div class="readable-text intended-text" id="p139">
<p>Increased precision of top results, no reduction in recall: <code>increased_precision_ same_recall</code></p>
</div>
<div class="browsable-container listing-container" id="p140">
<div class="code-area-container code-area-with-html">
<pre class="code-area">{"query": "vibranium AND (vibranium^0.94237 wakandan^0.8197
         <span class="">↪</span>adamantium^0.80724 wakanda^0.79122 alloy^0.75724
         <span class="">↪</span>maclain^0.75623 klaw^0.75222 america's^0.74002)",
 "query_fields": ["title", "body"],
 "min_match": "2"}</pre>
</div>
</div>
<div class="readable-text" id="p141">
<p>This increased-precision, same-recall query requires the term “vibranium” to match, and it will rank documents higher when other expansion terms match, leading to an increase in precision for the top results.</p>
</div>
<div class="readable-text intended-text" id="p142">
<p>Slightly increased-recall query: <code>slightly_increased_recall</code></p>
</div>
<div class="browsable-container listing-container" id="p143">
<div class="code-area-container code-area-with-html">
<pre class="code-area">{"query": "vibranium vibranium^0.94237 wakandan^0.8197
         <span class="">↪</span>adamantium^0.80724 wakanda^0.79122 alloy^0.75724
         <span class="">↪</span>maclain^0.75623 klaw^0.75222 america's^0.74002",
 "query_fields": ["title", "body"],
 "min_match": "2"}</pre>
</div>
</div>
<div class="readable-text" id="p144">
<p>This slightly increased recall query requires two terms to match, but it does not explicitly require the original query, so it can expand to other documents that are conceptually similar but don’t necessarily contain the original query term. Since the term “vibranium” is repeated twice, any documents containing just “vibranium” will also match.</p>
</div>
<div class="readable-text intended-text" id="p145">
<p>Same results, better conceptual ranking: <code>same_results_better_ranking</code></p>
</div>
<div class="browsable-container listing-container" id="p146">
<div class="code-area-container code-area-with-html">
<pre class="code-area">{"query": "vibranium",
 "query_fields": ["title", "body"],
 "min_match": "2",
 "query_boosts": "vibranium^0.94237 wakandan^0.8197 adamantium^0.80724
                <span class="">↪</span>wakanda^0.79122 alloy^0.75724 maclain^0.75623
                <span class="">↪</span>klaw^0.75222 america's^0.74002 "}</pre>
</div>
</div>
<div class="readable-text" id="p147">
<p>This final query returns the same documents as the original query for <code>vibranium</code>, but it ranks them differently according to how well they match the semantically similar terms from the knowledge graph. This ensures the keyword exists in all matched documents and that all documents containing the user’s query are returned, while also greatly improving ranking by boosting more contextually relevant documents.</p>
</div>
<div class="readable-text intended-text" id="p148">
<p>Of course, there are an unlimited number of possible query permutations you can explore when rewriting your query to include enhanced semantic context, but the preceding examples should provide a good sense of the kinds of options available and the tradeoffs you’ll want to consider. </p>
</div>
<div class="readable-text" id="p149">
<h3 class="readable-text-h3" id="sigil_toc_id_77"><span class="num-string">5.4.6</span> Using SKGs for content-based recommendations</h3>
</div>
<div class="readable-text" id="p150">
<p>In the last section, we explored how we could augment queries by discovering and using related nodes from the SKG, including multiple ways of structuring rewritten queries to optimize for precision, recall, or even improved conceptual ranking over the same results. In addition to expanding queries with semantically related terms, it’s also possible to use the SKG to generate content-based recommendations by translating documents into queries based on the semantic similarity of the terms within the documents. </p>
</div>
<div class="readable-text intended-text" id="p151">
<p>Since nodes in the SKG can represent any arbitrary query, we can take terms from documents and model them as arbitrary nodes to be scored relative to some known context about the document. This means we can take dozens or hundreds of terms from a document, score them all relative to the topic of the document, and then use the most semantically similar terms to generate a query best representing the nuanced, contextual meaning of the document.</p>
</div>
<div class="readable-text intended-text" id="p152">
<p>The following listing walks through an example of translating a document classified as “star wars” and ranking all the terms in the document relative to that topic.</p>
</div>
<div class="browsable-container listing-container" id="p153">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 5.8</span> Calculating how related document terms are to “star wars”</h5>
<div class="code-area-container">
<pre class="code-area">from aips import extract_phrases

stackexchange_skg = get_skg(engine.get_collection("stackexchange"))

classification = "star wars"
document = """this doc contains the words luke, magneto, cyclops,
              darth vader, princess leia, wolverine, apple, banana,
              galaxy, force, blaster, and chloe."""
parsed_document = extract_phrases(document)
nodes_to_traverse = [{"field": "body", "values": [classification]},
                     {"field": "body", "values": parsed_document}]

traversal = stackexchange_skg.traverse(*nodes_to_traverse)

print_graph(traversal, classification)</pre>
</div>
</div>
<div class="readable-text" id="p154">
<p>Scored nodes:</p>
</div>
<div class="browsable-container listing-container" id="p155">
<div class="code-area-container">
<pre class="code-area">luke  0.75212
force  0.73248
darth vader  0.69378
galaxy  0.58693
princess leia  0.50491
blaster  0.47143
this  0.19193
the  0.17519
words  0.10144
and  0.09709
contains  0.03434
doc  0.00885
chloe  0.0
cyclops  -0.01825
magneto  -0.02175
banana  -0.0319
wolverine  -0.03362
apple  -0.03894</pre>
</div>
</div>
<div class="readable-text" id="p156">
<p>In these results, you can see a list of terms from the document that is nicely ordered based upon semantic similarity to the topic of “star wars”. Terms with lower scores will have no relatedness or negative relatedness with the specified topic. The following listing filters terms with at least a relatedness above <code>0.25</code> to get a very clean list of relevant terms from the document.</p>
</div>
<div class="browsable-container listing-container" id="p157">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 5.9</span> Generating a recommendation query from scored phrases</h5>
<div class="code-area-container">
<pre class="code-area">def get_scored_terms(traversal):
  return {term: data["relatedness"]
          for term, data in traversal["graph"][0]["values"]["star wars"] \
                                ["traversals"][0]["values"].items()}

rec_query = " ".join(f'"{term}"^{score}'
                     for term, score in get_scored_terms(traversal).items()
                     if score &gt; 0.25)

print(f"Expanded Query:\n{rec_query}")</pre>
</div>
</div>
<div class="readable-text" id="p158">
<p>Expanded query:</p>
</div>
<div class="browsable-container listing-container" id="p159">
<div class="code-area-container">
<pre class="code-area">"luke"^0.75212 "force"^0.73248 "darth vader"^0.69378 "galaxy"^0.58693
"princess leia"^0.50491 "blaster"^0.47143</pre>
</div>
</div>
<div class="readable-text" id="p160">
<p>The next listing demonstrates the last step in this process—running the search to return the top documents most semantically similar to the original document.</p>
</div>
<div class="browsable-container listing-container" id="p161">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 5.10</span> Running the content-based recommendations query</h5>
<div class="code-area-container">
<pre class="code-area">stackexchange_collection = engine.get_collection("stackexchange")

request = {"query": rec_query,
           "query_fields": ["title", "body"],
           "return_fields": ["title"],
           "limit": 5,
           "filters": [("title", "*")]}

response = stackexchange_collection.search(**request)

print(json.dumps(response["docs"], indent=2))</pre>
</div>
</div>
<div class="readable-text" id="p162">
<p>Output:</p>
</div>
<div class="browsable-container listing-container" id="p163">
<div class="code-area-container code-area-with-html">
<pre class="code-area">[{"title": "At the end of Return of the Jedi, did Darth Vader learn
          <span class="">↪</span>that Princess Leia was his daughter?"},
 {"title": "Did Luke know the &amp;quot;Chosen One&amp;quot; prophecy?"},
 {"title": "Was Darth Vader at his strongest during Episode III?"},
 {"title": "Why couldn't Snoke or Kylo Ren trace Luke using the Force?"},
 {"title": "Does Kylo Ren know that Darth Vader reconciled with Luke?"}]</pre>
</div>
</div>
<div class="readable-text" id="p164">
<p>What we have just created is a content-based recommendations algorithm. When there’s an insufficient amount of user behavioral signals for signal-based recommendations like collaborative filtering (see section 4.2.3), a content-based approach can generate recommendations that are still context- and domain-aware.</p>
</div>
<div class="readable-text intended-text" id="p165">
<p>The example in this section generated a content-based recommendations query based on terms found in the starting document, but it is worth keeping in mind that the SKG is not restricted to using the terms passed in. You could add an extra level to the traversal to find additional terms that are semantically related to the terms in the original document, but not actually contained within it. This can be particularly useful for niche topics where not enough documents match the recommendations query—traversing further will open new possibilities for exploration.</p>
</div>
<div class="readable-text intended-text" id="p166">
<p>In the next section, we’ll take a quick step beyond the “is related to” graph relationships and see if we can use the SKG to also generate and traverse some more interesting edges. </p>
</div>
<div class="readable-text" id="p167">
<h3 class="readable-text-h3" id="sigil_toc_id_78"><span class="num-string">5.4.7</span> Using SKGs to model arbitrary relationships</h3>
</div>
<div class="readable-text" id="p168">
<p>Thus far, all our SKG traversals have used an “is related to” relationship. That is to say, we’ve been finding the strength of the semantic relationship between two words or phrases using the <code>relatedness</code> function, but we have only measured that the nodes are “related”, not <em>how</em> they are related. What if we could find other kinds of edges between nodes instead of just “is related to” type edges?</p>
</div>
<div class="readable-text intended-text" id="p169">
<p>If you recall, the nodes in an SKG are materialized on the fly by executing a query that matches a set of documents. If the node you start with is <code>engineer</code>, that node is internally represented as the set of all documents containing the word “engineer”. If the node is labeled as <code>software engineer</code>, that node is internally represented as the set of all documents containing the term “software” intersected with all documents containing the term “engineer”. If the search is for <code>"software engineer" OR java</code> then it is internally represented as the union of the set of all documents containing the term “software” one position before the term “engineer” (a phrase) with the set of all documents containing the term “java”. All queries, regardless of their complexity, are internally represented as a set of documents.</p>
</div>
<div class="readable-text intended-text" id="p170">
<p>You may also recall that an edge is formed by finding the set of documents containing both nodes. This means that <em>both</em> nodes and edges are internally represented using the same mechanism—a set of documents. Practically speaking, this means that if we can construct a node using a query that approximates an interesting relationship (as opposed to an entity), we can relate two nodes together through the “relationship node” in a similar way to how an edge would be used to relate the nodes together in a traditional graph structure.</p>
</div>
<div class="readable-text intended-text" id="p171">
<p>Let’s work through an example. Revisiting our scifi dataset, let’s say we wanted to ask a question about Jean Grey, one of the popular characters from Marvel Comics’ X-Men franchise. Specifically, let’s say that we wanted to figure out who was in love with Jean Grey.</p>
</div>
<div class="readable-text intended-text" id="p172">
<p>We can accomplish this by using a starting node of <code>jean grey</code>, traversing to the node <code>in love with</code>, and then requesting the top related terms associated with <code>in love with</code> within the context of <code>jean grey</code>. Listing 5.11 demonstrates this query. By traversing through a node designed to capture an explicit linguistic relationship (<code>in love with</code>, in this case), we can use the intermediate node to model an edge between the starting and terminating nodes.</p>
</div>
<div class="browsable-container listing-container" id="p173">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 5.11</span> Materializing an edge through a “relationship node”</h5>
<div class="code-area-container">
<pre class="code-area">scifi_skg = get_skg(engine.get_collection("scifi"))

starting_node = "jean grey"
relationship = "in love with"
nodes_to_traverse = [{"field": "body", "values": [starting_node]},
                     {"field": "body", "values": [relationship],
                      "default_operator": "OR"},
                     {"field": "body",
                      "min_occurrences": 25, "limit": 10}]

traversal = scifi_skg.traverse(*nodes_to_traverse)

print_graph(traversal, starting_node, relationship)</pre>
</div>
</div>
<div class="readable-text" id="p174">
<p>Output:</p>
</div>
<div class="browsable-container listing-container" id="p175">
<div class="code-area-container">
<pre class="code-area">jean  0.84915
grey  0.74742
summers  0.61021
cyclops  0.60693
xavier  0.53004
wolverine  0.48053
mutant  0.46532
x  0.45028
mutants  0.42568
magneto  0.42197</pre>
</div>
</div>
<div class="readable-text" id="p176">
<p>In case you’re unfamiliar with these characters, here’s the relevant background on Jean Grey: she has recurring relationships with two mutants, one named Cyclops (real name: Scott Summers) and one named Wolverine. Additionally, and unknown to most fans, two of Jean Grey’s mentors, Professor Charles Xavier and Magneto, were known to have a love interest in Jean Grey at points throughout the comic books.</p>
</div>
<div class="readable-text intended-text" id="p177">
<p>If we examine the results from listing 5.11, we’ll see all of these expected names listed. The first two terms, “jean” and “grey”, are the most related, since we are searching for <code>in love with</code> relative to <code>jean grey</code>. Her name is going to be highly semantically related to itself. The next two terms, “summers” and “cyclops”, both refer to the same person, Jean’s most prominent love interest. Then we see “xavier” and “wolverine”, and the last result in the list is “magneto”. Figure 5.7 illustrates some of the underlying graph relationships for this traversal.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p178">
<img alt="figure" height="272" src="../Images/CH05_F07_Grainger.png" width="927"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 5.7</span> Traversing arbitrarily defined edge types. By materializing a new node with the combined context of both the originating node (<code>"jean grey"</code>) and a new node (<code>"in love with"</code>), we can traverse from that combined node (<code>"jean grey" + "in love with"</code>) to other nodes. This is equivalent to saying we are traversing from <code>"jean grey"</code> through an edge of <code>"in love with"</code> to the other nodes.</h5>
</div>
<div class="readable-text" id="p179">
<p>By using an intermediate node (i.e., <code>in love with</code>) to model a relationship between other nodes, we can form any arbitrarily typed edge between nodes, as long as we can express that edge as a search query.</p>
</div>
<div class="readable-text intended-text" id="p180">
<p>While the results of our graph traversal in listing 5.11 were pretty good, we do see the terms “x” (presumably from “x-men”) and “mutant” also showing up. Jean Grey and all the other listed people are mutants in the X-Men comics, which is why these terms are so semantically related. However, these terms are not great answers to the question “Who is in love with Jean Grey?”</p>
</div>
<div class="readable-text intended-text" id="p181">
<p>This brings up an important point: the SKG is a statistical knowledge graph. The existence of the <code>in love with</code> relationship is purely based upon statistical correlations of terms within our collection, so just as with any ontology learning approach, there is going to be noise. That said, for an autogenerated graph with no explicit modeling of entities, these results are quite good.</p>
</div>
<div class="readable-text intended-text" id="p182">
<p>If we wanted to improve the quality of these results, one of the easiest things to do would be to run preprocessing on the content to identify entities (people, places, and things) and index those instead of just single-term keywords. This would cause actual people’s names (e.g., “Scott Summers”, “Charles Xavier”, “Jean Grey”) to be returned instead of just individual keywords (“summers”, “xavier”, “jean”, “grey”).</p>
</div>
<div class="readable-text intended-text" id="p183">
<p>It is also worth pointing out that the traversal of relationships depends entirely on whether those relationships were discussed in the underlying corpus of documents. In this case, plenty of forum posts discuss each of these peoples’ relationships with Jean Grey. Had insufficient documents existed, the results returned may have been poor or nonexistent. To avoid noise in our results, we set a <code>min_occurrences</code> threshold of <code>25</code>, indicating that at least 25 documents must exist discussing <code>jean grey</code>, <code>in love with</code>, and the other nodes found and scored. We recommend setting a <code>min_occurrences</code> to some number greater than 1 to avoid false positives. </p>
</div>
<div class="readable-text intended-text" id="p184">
<p>While traversing arbitrary linguistic relationships like “in love with” can be useful from an exploratory standpoint, it is usually sufficient from a query understanding standpoint to stick with the default “is related to” relationship and use the relatedness scores between terms for most semantic search use cases. It can still be useful to traverse through multiple levels of relationships to generate better context, however. Specifically, it can be useful to traverse from a term to a classification field to provide some additional context, and then to related meanings of the term within that category. We’ll cover this strategy in more detail in chapter 6, where we’ll focus on disambiguating terms with multiple meanings. </p>
</div>
<div class="readable-text" id="p185">
<h2 class="readable-text-h2" id="sigil_toc_id_79"><span class="num-string">5.5</span> Using knowledge graphs for semantic search</h2>
</div>
<div class="readable-text" id="p186">
<p>By providing the ability to accept arbitrary queries and dynamically discover related terms in a context-sensitive way, SKGs become a key tool for query interpretation and relevance ranking. We’ve seen that not only can SKGs help interpret and expand queries, they can also provide the abilities to classify queries and keywords in real time and to disambiguate multiple meanings of the terms in each query. </p>
</div>
<div class="readable-text intended-text" id="p187">
<p>Early in the chapter, we also explored how to build explicit knowledge graphs through open information extraction techniques. What may not be obvious yet is how to parse arbitrary incoming queries and look up the appropriate context and entities in the knowledge graph. We’ll spend the majority of chapter 7 covering how to build an end-to-end semantic search system that can parse queries and integrate these knowledge graph capabilities.</p>
</div>
<div class="readable-text intended-text" id="p188">
<p>There are still some critical kinds of relationships we need to add to our knowledge graph that are important for search engines, such as misspellings, synonyms, and domain-specific phrases. We’ll cover how to automatically learn each of these sources of domain-specific terminology from user signals or content in the next chapter, which focuses on learning domain-specific language. </p>
</div>
<div class="readable-text" id="p189">
<h2 class="readable-text-h2" id="sigil_toc_id_80">Summary</h2>
</div>
<ul>
<li class="readable-text" id="p190"> Knowledge graphs model the relationships between entities within your domain and can be built explicitly with known relationships or can be extracted dynamically from your content.  </li>
<li class="readable-text" id="p191"> Open information extraction, the process of extracting facts from your content (subject, relationship, object triples) can be used to learn arbitrary relationships (which typically results in noisy data) or to extract hyponym and hypernym relationships (less noisy) from text into an explicit knowledge graph.  </li>
<li class="readable-text" id="p192"> Semantic knowledge graphs (SKGs) enable the traversal and ranking of arbitrary semantic relationships between any content within your search index. This allows you to use your indexed content directly as a knowledge graph and language model without any additional data modeling required. </li>
<li class="readable-text" id="p193"> Content-based recommendations that don’t rely on user signals can be generated by ranking the most semantically interesting terms and phrases from documents and using them as a query to find and rank other related documents. </li>
<li class="readable-text" id="p194"> SKGs enable a better understanding of user intent by powering domain-sensitive and context-sensitive relationship discovery and query expansion.  </li>
</ul>
<div class="readable-text footnote-readable-text" id="p195">
<p><span class="footnote-definition"><a href="#ftnote-113" id="footnote-113">[1]</a></span> Grainger, et al., “The Semantic Knowledge Graph: A compact, auto-generated model for real-time traversal and ranking of any relationship within a domain.” In <em>2016 IEEE International Conference on Data Science and Advanced Analytics (DSAA)</em>, pp. 420–429. IEEE, 2016.</p>
</div>
</div></body></html>