- en: 5 Agentic RAG
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: What agentic RAG is
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why we need agentic RAG
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to implement agentic RAG
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In earlier chapters, we saw how to find relevant data using different methods
    of vector similarity search. Using similarity search, we can find relevant data
    in unstructured data sources, but data with a structure can often bring more value
    over unstructured data because there’s information in the structure itself.
  prefs: []
  type: TYPE_NORMAL
- en: Adding structure to data can be an incremental process. We can start with a
    simple structure and then add more complex structures as we go. We saw this in
    the previous chapter, where we started with simple graph data and then added more
    complex structures to it.
  prefs: []
  type: TYPE_NORMAL
- en: An agentic RAG system (see figure 5.1) is a system where a variety of retrieval
    agents are available to retrieve the data needed to answer the user question.
    The starting interface to an agentic RAG system is usually a retriever router,
    whose job is to find the best-suited retriever (or retrievers) to perform the
    task at hand.
  prefs: []
  type: TYPE_NORMAL
- en: One common way to implement an agentic RAG system is to use an LLM’s ability
    to use tools (sometimes called *function calling*). Not all LLMs have this ability,
    but OpenAI’s GPT-3.5 and GPT-4 do, and that is what we will use in this chapter.
    This can be achieved with most LLMs using the ReAct approach (see [https://arxiv.org/abs/2210.03629](https://arxiv.org/abs/2210.03629)),
    but over time, the current trajectory is that this feature will be available in
    all LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/5-1.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 The data flow for an application using agentic RAG
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 5.1 What is agentic RAG?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Agentic systems vary in sophistication and complexity, but the core idea is
    that the system can act on behalf of the user to perform tasks. In this chapter,
    we will look at a basic agentic system where the system only has to choose which
    retriever to use and decide whether the found context answers the question. In
    more advanced systems, the system might make up plans on what kind of tasks to
    perform to solve the task at hand. Starting from the basics as we do in this chapter
    is a good way to understand the core concepts of agentic systems, and for RAG
    tasks, this is often all you need.
  prefs: []
  type: TYPE_NORMAL
- en: 'Agentic RAG is a system whereby a variety of retrieval agents are available
    to retrieve the data needed to answer the user question. Successful agentic RAG
    systems require a few foundational parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Retriever router* —A function that takes in the user question(s) and returns
    the best retriever(s) to use'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Retriever agents* —The actual retrievers that can be used to retrieve the
    data needed to answer the user question(s)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Answer critic* —A function that takes in the answers from the retrievers and
    checks if the original question is answered correctly'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 5.1.1 Retriever agents
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Retriever agents are the actual retrievers that can be used to retrieve the
    data needed to answer the user question(s). These retrievers can be very broad,
    like a vector similarity search, or very specific, like a template of a hardcoded
    database query that takes in parameters, such as the retriever router, covered
    in section 5.1.2.
  prefs: []
  type: TYPE_NORMAL
- en: A few generic retriever agents are relevant in most agentic RAG systems, like
    vector similarity search and text2cypher. The former is useful for unstructured
    data sources and the latter for structured data in a graph database, but in a
    real-world production system, it’s not trivial to make any of them perform at
    par with user expectations.
  prefs: []
  type: TYPE_NORMAL
- en: That’s why we need specialized retrievers that are very narrow but perform very
    well at what they’re meant for. These specialized retrievers can be built over
    time as we identify questions that the generic retrievers have problems generating
    queries to answer.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1.2 The retriever router
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To pick the right retriever for the job, we have something called a retriever
    router. The retriever router is a function that takes in the user question and
    returns the best retriever(s) to use. How the router makes this decision can vary,
    but usually an LLM is used to make this decision.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s say we have a question like “What is the capital of France?” And let’s
    say we have coded two retriever agents that are available (that both retrieve
    the answer from a database):'
  prefs: []
  type: TYPE_NORMAL
- en: '`capital_by_country`—A retriever that takes in a country name and returns the
    capital of that country'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`country_by_capital`—A retriever that takes in a capital name and returns the
    country of that capital'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both of these retrievers can be hardcoded database queries that take in a parameter
    for the country or capital.
  prefs: []
  type: TYPE_NORMAL
- en: The retriever router can be an LLM that takes in the user question and returns
    the best retriever to use. In this case, the LLM can return the `capital_by_country`
    retriever with `"France"` as the extracted argument. So the actual call to the
    retriever would be `capital_by_country("France")`.
  prefs: []
  type: TYPE_NORMAL
- en: This is a simple example, but in a real-world scenario, many retrievers may
    be available. The retriever router can be a complex function that uses the LLM
    to pick the best retriever for the job.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1.3 Answer critic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The answer critic is a function that takes in the answers from the retrievers
    and checks whether the original question is answered correctly. The answer critic
    is a blocking function that can stop the answer from being returned to the user
    if the answer is not correct or is incomplete.
  prefs: []
  type: TYPE_NORMAL
- en: If an incomplete or incorrect answer is blocked, the answer critic should generate
    a new question that can be used to retrieve the correct answer and go through
    another round of retrieving the correct answer. It might be that the correct answer
    is not available in the data source, so there needs to be some exit criteria from
    this loop; the answer critic should be able to handle that and return a message
    to the user that the answer is not available in such cases.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Why do we need agentic RAG?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One area where agentic RAG is useful is when we have a variety of data sources
    and we want to use the best data source for the job. Another common usage is when
    the data source is very broad or complex and we need specialized retrievers to
    retrieve the data we need consistently.
  prefs: []
  type: TYPE_NORMAL
- en: As seen earlier in the book, generic retrievers like vector similarity search
    can find relevant data in unstructured data sources. When we have structured data
    sources like a graph database, we might use generic retrievers like text2cypher
    that we introduced in chapter 4\. If the data is very complex, tools like text2cypher
    can have problems generating the right query. In such cases, specialized retrievers
    can be used to retrieve the correct data. This could, for example, be a narrow
    text2cypher retriever or a hard-coded database query that takes in parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Over time, we can identify questions that tools like text2cypher have problems
    generating queries to answer, and we can build specialized retrievers for those
    questions and use text2cypher as a catchall retriever for the cases when there
    isn’t a good specific retriever match.
  prefs: []
  type: TYPE_NORMAL
- en: This is where agentic RAG can be useful. A variety of retrievers are available,
    and we need to use the best retriever for the job and assess the answer before
    returning it to the user. In a production environment, this is very useful to
    keep the performance of the system high and the quality of the answers consistent.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3 How to implement agentic RAG
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we’ll walk through how to implement the foundational parts
    of an agentic RAG system. You can follow the implementation directly in the accompanying
    Jupyter notebook available here: [https://github.com/tomasonjo/kg-rag/blob/main/notebooks/ch05.ipynb](https://github.com/tomasonjo/kg-rag/blob/main/notebooks/ch05.ipynb).'
  prefs: []
  type: TYPE_NORMAL
- en: NOTE In the implementation in this chapter, we use what we call the “Movies
    dataset.” See the appendix for more information on the dataset and various ways
    to load it.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3.1 Implementing retriever tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before we can route the user input to be handled by the right retriever(s),
    we need to have the retrievers available for the router to choose from. The retrievers
    can be very broad, like a vector similarity search, or very specific, like a template
    of a hardcoded database query that takes in parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this practical example, we’ll use a simple list of retrievers: two that
    use Cypher templates to get movies by title and movies by actor name and one that
    uses text2cypher for all other questions. As mentioned earlier, the useful set
    of retrievers differs from system to system and should be added over time as needed
    to improve the performance of the application.'
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.1 Available retriever tools
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Note that `neo4j_driver` and `text2cypher` are imports that you can find implemented
    in the code repository for this book.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE The previous retriever definitions follow OpenAI’s tools format at the
    time of writing this book.
  prefs: []
  type: TYPE_NORMAL
- en: We need to be careful with how we describe the retriever to the LLM. We need
    to make sure the LLM understands the retriever and can make a decision on which
    retriever to use. The parameters are also very important to describe so the LLM
    can make the right call to the retriever.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the LLM can’t make actual calls to your retrievers; it can only make
    a decision on which retriever to use and what parameters to pass to the retriever.
    The actual call to the retriever needs to be done by the system that calls the
    LLM, which we’ll see in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Note on a generic retriever tool
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A generic retriever tool that we almost always include in our agentic RAG systems
    is a tool that is being called if the answer to the question is already given
    within the question or other parts of the context. This tool is usually a simple
    function that extracts the answer from the question or context and returns it.
  prefs: []
  type: TYPE_NORMAL
- en: An example could be a question like “What’s Dave Smith’s last name?” This is
    what the retriever tool could look like.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.2 Generic retriever tool for answer already in context
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 5.3.2 Implementing the retriever router
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The retriever router is the central part of the agentic RAG system. Its job
    is to take in the user question(s) and return the best retriever(s) to use.
  prefs: []
  type: TYPE_NORMAL
- en: When implementing the retriever router, we’ll use an LLM to help us with the
    task. We will provide the LLM with a list of retrievers and the user question(s),
    and the LLM will return the best retriever(s) to use to find the answer for each
    question. For simplicity, we’ll use an LLM that has official tools/function-calling
    support, like OpenAI’s GPT-4o. The functionality can be achieved with other LLMs
    as well, but the implementation might be different.
  prefs: []
  type: TYPE_NORMAL
- en: Before we dig into the routing function, we need to look into some parts that
    are needed to be able to successfully build an agentic RAG system. These parts
    are
  prefs: []
  type: TYPE_NORMAL
- en: Handling tool calls
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuous query updating
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Routing the questions to the relevant retrievers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling tool calls on behalf of the LLM
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When the LLM returns the best retriever to use, the system needs to make the
    call to the retriever. This can be done by having a function that takes in the
    retriever and the arguments and makes the call to the retriever. The following
    listing shows an example of what that function might look like.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.3 Retriever call function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The `tools` we’re passing in is a dictionary where the key is the name of the
    tool and the value is the actual function to call. The `llm_tool_calls` is a list
    of the tools the LLM has decided to use and the arguments to pass to the tool.
    The LLM can decide that it wants to make multiple function calls to respond to
    a single question. The shape of the `llm_tool_calls` argument looks like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Continuous query updating
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When we get to the retriever router function section later, we’ll see that we
    will send the questions to the LLM one by one in sequence. This is a deliberate
    choice to make it easier for the LLM to handle each question individually and
    to make it easier to route the questions to the right retriever.
  prefs: []
  type: TYPE_NORMAL
- en: One extra benefit of sending the questions in sequence is that we can use the
    answers from the previous questions to rewrite the next question. This can be
    useful if the user asks a follow-up question that is dependent on the answer to
    the previous question.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following example: “Who has won the most Oscars, and is that person
    alive?” A rewrite of this question could be “Who won the most Oscars?” and “Is
    that person alive?” where the second question is dependent on the answer to the
    first question.'
  prefs: []
  type: TYPE_NORMAL
- en: So once we have the answer to the first question, we want to update the remaining
    questions with the new information. This can be done by calling a query updater
    with the original question and the answers from the retrievers. The query updater
    updates the existing questions with the new information.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.4 Query updater instructions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The query updater is called with the original question and the answers from
    the retrievers. The output is the updated question, and we instruct the LLM to
    return the updated question in a JSON format. It’s important that the LLM doesn’t
    ask for more information than the original question—only rephrase the question
    to make it more complete.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.5 Query updater function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: With this in place, we can update the questions with the new information as
    we go along and make sure the questions are as complete as possible and that we
    make it as easy as possible to find the answer to the questions.
  prefs: []
  type: TYPE_NORMAL
- en: Routing the questions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The final piece in the retriever router is actually routing the questions to
    the right retriever. This is done by calling the LLM with the questions and the
    available tools, and the LLM will return the best retriever to use for each question.
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to have our tools available in a dictionary so we can pass them
    to the LLM but also find them when it’s time to invoke the tools. Let’s start
    by defining the tools we have available.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.6 Available retriever tools dictionary
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Here we’ve grouped the tool descriptions and the actual functions in a dictionary
    so we can easily find the tools when we need to make the actual call to the tools.
    Let’s start the prompt to the LLM where we describe its task.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.7 Retriever router Instructions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This is a pretty short prompt, but it’s enough to instruct the LLM to pick the
    right retriever for the job because of the built-in tools/function-calling support.
    Next we’ll have a look at the function that calls the LLM.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.8 Retriever router function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This function takes a single question and the available tools and the answers
    from the previous questions. It then calls the LLM with the question and the tools,
    and the LLM will return the best retriever to use for the question. The last line
    of the function is a call to the `handle_tool_calls` function we saw earlier that
    makes the actual call to the retriever.
  prefs: []
  type: TYPE_NORMAL
- en: The final piece of the retrieval router is to tie all previous parts together
    and go all the way from the user input to the answer. We want to make sure that
    we have a loop that goes through all questions and that we update the questions
    with the new information as we go along.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.9 Agentic RAG function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: One thing to note here is that the `handle_user_input` function optionally takes
    in a list of answers. We will get to this in section 5.3.3.
  prefs: []
  type: TYPE_NORMAL
- en: With this in place, we have a complete agentic RAG system that can take in user
    input and return the answer to the user. The system is built in a way that it
    can be extended with more retrievers as needed.
  prefs: []
  type: TYPE_NORMAL
- en: We need to implement one more part to make the system complete, and that is
    the answer critic.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3.3 Implementing the answer critic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The job of the answer critic is to take all answers from the retrievers and
    check if the original question is answered correctly. LLMs are nondeterministic
    and can make mistakes when rewriting the questions, updating the questions, and
    routing the questions, so we want to have this check in place to make sure we
    actually receive the answers we need.
  prefs: []
  type: TYPE_NORMAL
- en: The following listing shows instructions to the LLM for the answer critic.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.10 Answer critic instructions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: We follow the same pattern as before with the JSON format and the instructions
    to the LLM.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll have a look at the function that calls the LLM.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.11 Answer critic function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This function takes the original question and the answers from the retrievers
    and calls the LLM to check if the original question is answered correctly. If
    the question is not answered correctly, the LLM will return a list of new questions
    that can be asked to gather the missing information.
  prefs: []
  type: TYPE_NORMAL
- en: If we get a list of new questions back, we can go through the retriever router
    again to get the missing information. We should also have some exit criteria from
    this loop so we don’t get stuck in a loop where we can’t get the answer to the
    original question from the retrievers.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3.4 Tying it all together
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So far, we have implemented the retriever agents, the retriever router, and
    the answer critic. The final piece is to tie it all together in a main function
    that takes in the user input and returns the answer to the user, if the answer
    is available.
  prefs: []
  type: TYPE_NORMAL
- en: The following listing shows what the main function might look like. Let’s start
    with the instructions to the LLM.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.12 Agentic RAG main instructions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: It’s very important that the LLM only uses the information provided to it in
    the prompt to answer the questions. This is to make sure that the system is consistent
    and that we can trust the answers it provides.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll have a look at the main function.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.13 Agentic RAG main function
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The main function runs the user input through the agentic RAG system and returns
    the answer to the user. If the answer is not complete or is incorrect, the critique
    function will return a list of new questions that can be asked to gather the missing
    information.
  prefs: []
  type: TYPE_NORMAL
- en: We only critique the answers once; if the answers are still incomplete or incorrect
    after the critique, we return the answers to the user as is and rely on the LLM
    to let the user know what’s incomplete.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Agentic RAG is a system where a variety of retrieval agents are available to
    retrieve the data needed to answer the user question.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The main interface to an agentic RAG system is usually some kind of use case
    or retriever router, whose job is to find the best-suited retriever (or retrievers)
    to perform the task at hand.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The foundational parts of an agentic RAG system are retriever agents, retriever
    router, and answer critic.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The main parts of an agentic RAG system can be implemented using an LLM with
    tools/function-calling support.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The retriever agents can be generic or specialized and should be added over
    time as needed to improve the performance of the application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The answer critic is a function that takes in the answers from the retrievers
    and checks if the original question is answered correctly.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
