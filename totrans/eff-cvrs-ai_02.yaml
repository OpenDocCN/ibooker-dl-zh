- en: 2 Building a conversational AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Building an FAQ conversational AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a process-oriented conversational AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using generative AI inside of your conversational AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In production, conversational AI can be quite complex, and throughout this book,
    we’ll cover many techniques that address the real-world problems you’ll face as
    you build and deploy your own solutions. In this chapter, we’ll build Cake Bot,
    a conversational AI solution with elements from several different kinds of conversational
    AIs. This will give us a solid foundation for understanding conversational AI
    structure.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll follow a fictitious small American bakery from Ohio called Cake Shop.
    The company makes custom cakes and takes orders for delivery or pickup. They want
    to add a conversational AI solution to their website to help their customers.
    Since they have never built a bot before, they intend to start small but hope
    to quickly expand the scope and capability of their solution. They decide to start
    with an AI solution that answers their most frequently asked questions.
  prefs: []
  type: TYPE_NORMAL
- en: Many of the tasks in this chapter *could* be done with large language models.
    However, this bakery is cautious. They especially want to control the wording
    of responses given for several question types. Thus, their solution will blend
    traditional and generative techniques.
  prefs: []
  type: TYPE_NORMAL
- en: We will demonstrate the building process using a conversational AI platform
    (IBM’s watsonx Assistant), and we’ll later fold in a generative AI platform (IBM’s
    watsonx.ai). The key concepts we demonstrate are applicable across many different
    AI platforms. You can easily use your platform of choice for conversational AI
    and generative AI.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Building an FAQ bot
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most conversational AI builders start with a question-answering bot. Also known
    as FAQ bots, these AI solutions deliver a response directly to a user’s question,
    often without any follow-up questions. The user asks a question, the bot returns
    an answer, and the conversation is done when the user is finished asking questions.
    These bots work especially well when there are a small number of (frequently asked)
    questions.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will build an FAQ bot for Cake Shop. Some questions will
    have a static response that will be the same no matter how the question is asked.
    Other questions will have a dynamic response that will change based on information
    in the question. But before we train the bot on any question-answering, we will
    first put some basic scaffolding in place.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.1 FAQ bot foundations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Every conversational AI needs to be able to start a conversation and react when
    it doesn’t know what to do. Most conversational AI platforms provide this capability
    by default when creating a new chatbot. It’s worth quickly checking these configurations
    and adapting them to your needs.
  prefs: []
  type: TYPE_NORMAL
- en: Cake Shop starts building their conversational AI (the “assistant”), and they
    title it “Cake Bot.” From the conversational AI’s main menu, their developer navigates
    to Actions, which lists all the assistant’s capabilities. The first list is titled
    “Created by you” and is empty; the second list is titled “Set by assistant,” and
    it lists the default capabilities, which are outlined in table 2.1.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2.1 Default capabilities in a new assistant
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Capability | Executed when |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Greet customer  | The assistant is first opened or engaged with. Opening
    the assistant starts a conversation.  |'
  prefs: []
  type: TYPE_TB
- en: '| No action matches  | No action can be matched to the user’s message (the
    message is not understood). Other platforms may call this the “fallback intent.”  |'
  prefs: []
  type: TYPE_TB
- en: '| Trigger word detected  | Keywords like profanity are detected.  |'
  prefs: []
  type: TYPE_TB
- en: '| Fallback  | The user needs to leave the chatbot.  |'
  prefs: []
  type: TYPE_TB
- en: The first capability is the most important to customize, as it gives us our
    first chance to personalize the assistant. The default text is “Welcome, how can
    I assist you?” The Cake Shop team changes this text to “Welcome to Cake Bot. How
    can I help you?” This is a minimum level of customization—it would be better to
    include additional information, like what the bot can do for users. However, the
    bot does not have any capabilities yet, so the Cake Shop team leaves this message
    as is.
  prefs: []
  type: TYPE_NORMAL
- en: Next, the “No action matches” action should be reviewed. This action will be
    invoked when the bot does not understand the user. Since the bot has no training
    yet, this action will be the default response to any user input. The default configuration
    is shown in figure 2.1.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F01_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 Default configuration of "No action matches" in the assistant
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'This configuration is summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The action counts how many times it has been invoked in the conversation.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If three or less times, the response is “I’m afraid I don’t understand. Please
    rephrase your question.”
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If four or more times, it deflects to a fallback routine. (The default fallback
    routine is to offer a human agent.)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Cake Shop team decides to reduce this threshold by changing the 3 to a 1\.
    This keeps their users from getting stuck.
  prefs: []
  type: TYPE_NORMAL
- en: Fallback action and connection to a human agent
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Most conversational AI platforms have no-code and low-code integrations to connect
    users to a human agent through chat or voice. We will not dive deeper into this,
    since the details are platform-specific. Suffice it to say that this is a common
    pattern. For the sake of this chapter, we will focus on the conversational design
    and AI training.
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we have a chatbot that does three things:'
  prefs: []
  type: TYPE_NORMAL
- en: When the user opens the chat, they are greeted with “Welcome to Cake Bot. How
    can I help you?”
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Whatever they say next, the chatbot responds that it doesn’t understand.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Whatever they say after that, the chatbot offers a human agent.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Boring! Let’s train this bot to answer some questions properly.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.2 Static question and answering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s start with a mental model of the chatbot components involved in answering
    questions.
  prefs: []
  type: TYPE_NORMAL
- en: In some platforms, you can directly connect questions to answers. In others,
    an additional layer is introduced to categorize similar questions into groups
    called *intents*. An intent-based question-answering system gives the builder
    full control over responses generated by the conversational AI. A generalized
    version of this design is shown in figure 2.2, using Cake Bot as our example.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F02_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2 Question-answering bots map user utterances to intents, which map
    to answers.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Let’s review the terminology in this diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Utterance*—This is the input provided to the chatbot. For a question-answering
    bot, these are questions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Intent*—This is a logical grouping of utterances with similar meanings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Response*—This is the output from the chatbot. For a question-answering bot,
    these are answers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For your first chatbot, intents save a lot of time. Notice that, as a builder,
    you do not have to distinguish between questions with similar meaning. “What time
    are you open?” and “What are your hours?” both relate to the operating hours of
    your store. It’s not critical for the bot to differentiate these. We give them
    the same “meaning” via the `#store_hours` intent. “What cakes do you sell?” has
    a different meaning and thus a different intent of `#cake_options`.
  prefs: []
  type: TYPE_NORMAL
- en: For each intent your bot serves, the bot is trained with example utterances.
    Modern intent-based systems require as few as five example utterances per intent.
    This is not a bad trade-off; there are nearly an infinite number of ways to ask
    for store hours, and by providing a handful of examples, you can train your bot
    well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Intent-based question-answering systems are a blessing and a curse: for each
    intent you train, you can control the response, which offers pros and cons.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pros:'
  prefs: []
  type: TYPE_NORMAL
- en: You have complete design control over the response. You can copyedit it, format
    the text, and even include graphical elements. You know the exact contents of
    the response.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a small number of intents, this can be done quickly. You can set up your
    first chatbot in as little as an hour.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cons:'
  prefs: []
  type: TYPE_NORMAL
- en: As the number of intents increases, it becomes more difficult to train the bot
    to recognize them all.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The responses do not adapt to nuances in the user’s questions. For “Are you
    open today?” the bot still responds generically: “We’re open every day.”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inaccurate or untuned responses give the user a painful feeling of “chatbot
    doesn’t understand.”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We’ll address several of these downsides to question-answering bots in the
    next few chapters: how to collect the right data to train your bot (chapter 4),
    how to use that data to train stronger intents (chapter 5), how to supplement
    those intents with answers from documents and generative AI (chapter 6), and how
    to use generative AI for a few more training and testing tasks (chapter 7).'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start by training our chatbot on its first question-answering capabilities.
    For each one, we need a user intent, a set of related user utterances, and a response.
    The first set of questions and answers we’ll define will cover the background
    on Cake Shop, operating hours for their stores, the kinds of cakes offered, the
    approximate cost of cakes, and information about their Cake Club. These intent-based
    question-answering responses are shown in table 2.2.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2.2 Initial set of FAQ intents, with associated utterances and responses
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Intent | Example utterances | Response |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `#background`  | Tell me about Cake Shop What''s the background on your business?'
  prefs: []
  type: TYPE_NORMAL
- en: History of Cake Shop
  prefs: []
  type: TYPE_NORMAL
- en: '| Founded by Grandma Cake in 1980, we''ve made over 10,000 cakes for local
    residents!  |'
  prefs: []
  type: TYPE_TB
- en: '| `#store_hours`  | Store hours What are your store hours?'
  prefs: []
  type: TYPE_NORMAL
- en: When are you open?
  prefs: []
  type: TYPE_NORMAL
- en: '| We are open Monday through Friday, 9:00 a.m. to 9:00 p.m.  |'
  prefs: []
  type: TYPE_TB
- en: '| `#cake_options`  | Cake options Do you make wedding cakes?'
  prefs: []
  type: TYPE_NORMAL
- en: What kinds of cakes do you sell?
  prefs: []
  type: TYPE_NORMAL
- en: '| We offer cakes for many occasions, such as weddings, birthdays, anniversaries,
    retirement, and all- occasion cakes.  |'
  prefs: []
  type: TYPE_TB
- en: '| `#cost`  | How much does a cake cost? Is there a minimum order value?'
  prefs: []
  type: TYPE_NORMAL
- en: Is there a surcharge for delivery?
  prefs: []
  type: TYPE_NORMAL
- en: '| Our cakes typically cost around $30, with a $5 delivery fee.  |'
  prefs: []
  type: TYPE_TB
- en: '| `#cake_club`  | Cake rewards Cake Club'
  prefs: []
  type: TYPE_NORMAL
- en: Any special promotions or discounts?
  prefs: []
  type: TYPE_NORMAL
- en: '| Our Cake Club rewards program earns you a $10 gift certificate for every
    ten cakes you purchase.  |'
  prefs: []
  type: TYPE_TB
- en: In the assistant, we define an action that detects an intent and gives a response—a
    question-answering action. This is the simplest kind of action we can define in
    any conversational AI platform. Figure 2.3 shows the user interface that starts
    this action definition.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F03_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.3 User interface to create our first action
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: For each of these actions, we need to configure how they start (the user utterances)
    and what they do (respond with an answer). You’ll notice that these are the right-most
    columns in table 2.2\. Some conversational AI platforms also use the intent label
    for the action; ours labels the action based on one of the user utterances that
    triggers it. We start our journey of defining the utterances that trigger the
    `#background` action in figure 2.4.
  prefs: []
  type: TYPE_NORMAL
- en: Note that the user interface points out that the chatbot’s recognition of this
    action will improve with more examples. For the sake of our demo, we will use
    three examples per action, which is enough to get us started. We will demonstrate
    multiple ways to find additional training examples in subsequent chapters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our question-answering action is almost complete. We have the questions that
    trigger it; now we need to define the chatbot’s response. The response for our
    `#background` action is shown in figure 2.5\. This action has three parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Conditional logic*—For a static question-answering action, no logic is needed.
    The action only starts when the intent is detected.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Response*—“Assistant says” is the response to the user. Our response is simple
    text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Next step*—For a static question-answering action, no next step is needed.
    Giving the answer ends the action.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F04_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.4 Defining the utterances that trigger an action
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F05_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.5 Defining the response for a question-answering action. The simplest
    form has only one step after detecting the intent—give the response.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We’ll repeat these action-creation steps for each of the five intents. Each
    action is trained with the examples that trigger it and the response it should
    give. Each of these actions is a single-step action that ends once the answer
    is given.
  prefs: []
  type: TYPE_NORMAL
- en: When all five actions have been created, we are ready to do some testing. Figure
    2.6 shows the testing interface for our chatbot.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F06_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.6 Chat preview link
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Let’s ask some questions! Figure 2.7 shows the test results for a sample question.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F07_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.7 Example question-answering response from Cake Bot
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Note that the question asked does not exactly match any of our training examples.
    This indicates that the bot has learned the meaning in the examples. The following
    listing shows additional tests of the bot.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.1 Testing Cake Bot with more questions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This is a great start for our bot. We can train it on more intents, and we can
    make it more accurate by giving it more examples for those intents. But let’s
    consider something different.
  prefs: []
  type: TYPE_NORMAL
- en: All the question-answering actions we’ve created have been single-step actions.
    The user gets the same response no matter what they ask. In the next section,
    you’ll see how to evolve a static response into a dynamic response based on additional
    information.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.3 Dynamic question and answering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Cake Shop presently has four locations: Columbus, Dublin, Westerville, and
    Grandview. When the bot was first created, all four locations had the same operating
    hours: 9:00 a.m. to 9:00 p.m. on weekdays. Circumstances have shifted—the Columbus
    store needs to open and close one hour earlier (8:00 a.m. to 8:00 p.m.). A single
    chatbot response doesn’t cover all the stores anymore. Now when a user asks about
    store hours, we need to figure out which store they need the hours for. If they
    don’t specify, we’ll need to ask them a clarifying question.'
  prefs: []
  type: TYPE_NORMAL
- en: The next listing shows how we want the bot to handle store hours questions in
    a series of sample questions.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.2 Sample conversations for store hours, dependent on location
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Ambiguous question is now clarified before answering'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Unambiguous question is answered directly'
  prefs: []
  type: TYPE_NORMAL
- en: We can also draw a flow diagram covering these sample conversations, as shown
    in figure 2.8\. It’s helpful to create a flow diagram and sample conversations
    when your conversation has dynamism. Some of your team members will prefer the
    diagrams, others the conversations, and some will need both.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F08_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.8 Process flow for a location-specific `#store_hours` intent
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The “store hours” flow can be implemented in three steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Display “To view our store hours, please select a location” and a list of locations.
    The user must choose a location.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If step 1 = “Columbus,” display Columbus hours, and end the action.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Display the hours for the step 1 store, and end the action.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This works because steps “fall through” in our platform. Here’s how a few conversations
    work:'
  prefs: []
  type: TYPE_NORMAL
- en: The user types “store hours,” and step 1 fires. The user selects “Columbus,”
    and step 2 fires and completes the action.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The user types “store hours,” and step 1 fires. The user selects “Grandview,”
    and the step 2 condition is not met. Step 3 fires and completes the action.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The user types “store hours for Columbus.” The step 1 exit conditions are met,
    so step 2 fires and completes the action.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The user types “store hours for Grandview.” The step 1 exit conditions are met,
    and the step 2 condition is not met. Step 3 fires and completes the action.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figure 2.9 shows how these steps are implemented in our assistant.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F09_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.9 The three steps for the `#store_hours` action
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Cake Bot is off to a good start. It can answer some basic questions about Cake
    Shop, and it even has a little dynamism. Grandma Cake won’t have to answer so
    many repetitive questions on the phone! But Cake Bot cannot take any action for
    the users yet. We’ll look at that in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Download this chapter’s chatbot code from the book’s GitHub site: [https://github.com/andrewrfreed/EffectiveConversationalAI](https://github.com/andrewrfreed/EffectiveConversationalAI).
    Load the chatbot in watsonx Assistant, and use the Preview panel to test the chatbot’s
    question and answering flows.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Alternatively, implement Cake Bot in your preferred conversational AI platform:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define a greeting message.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Define a fallback intent and/or fallback message.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement the five intents from table 2.2\.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 2.2 Routing agents and process-oriented bots
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Not all bots are question-answering bots. Q&A bots are great at delivering answers,
    but what if the user needs more than an answer—what if they need the bot to act?
    For Cake Shop, we’d love for customers to be able to order cakes from the bot.
    If all we have is question-answering capability, figure 2.10 is the best we can
    do.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F10_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.10 Cake Shop’s cake order process as question-answering. But it doesn't
    really answer the question!
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The user wants to complete a process but cannot do that inside the bot. They
    only get *instructions* on how to complete the process. A question-answering bot
    is thus often an early iteration of a more capable solution.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.1 Routing agents
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Cake Shop offers a wide variety of cakes with different flavoring and decoration
    options. There are decoration packages for weddings, graduations, birthdays, and
    more. There are flavoring options including vanilla, chocolate, and strawberry.
    Plus, there are payment and delivery methods. Given all these options, it’s reasonable
    to assume the user may want or need to talk this process through with a human.
  prefs: []
  type: TYPE_NORMAL
- en: For many chatbot developers, the next logical iteration of their chatbot is
    a routing agent. The routing agent detects the intent from the user’s utterance
    and determines who can best help fulfill the intent. Figure 2.11 reimagines our
    Cake Bot with routing agent capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F11_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.11 A routing agent detects user intents and routes them to an appropriate
    specialist.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'For the original Q&A requests, the bot works as it did before. But for cake-ordering
    requests, this bot does not attempt to answer the question at all—it just routes
    the call to an appropriate specialist. See our implementation in figure 2.12\.
    The action has one step once the intent is detected: route the user to a specialist.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F12_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.12 Routing agent configuration for `#cake_orders`. As soon as the intent
    is detected, the user is deflected to a human specialist.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This routing agent is just triaging incoming requests, which can be transferred
    to human agents or to specialized AI solutions. The human agents could use the
    telephone or live web chat. In this book, we’ll generically refer to these humans
    as *call center agents*.
  prefs: []
  type: TYPE_NORMAL
- en: Press 1 for appointments . . .
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: You’ve probably phoned an interactive voice response (IVR) system that recites
    a menu of options and prompts you to select one (“press 1 for appointments”).
    This is also a routing agent. One downside to these systems is the length of time
    it takes to read the menu. A conversational AI routing agent lets you speak your
    intent, increasing the convenience over listening to a lengthy menu.
  prefs: []
  type: TYPE_NORMAL
- en: Routing agents let you implement conversational AI solutions iteratively rather
    than needing to handle everything at once.
  prefs: []
  type: TYPE_NORMAL
- en: The human agents in routing agent systems often know what type of request they
    are receiving but little else. In figure 2.12, they were only told that the user
    wanted to order a cake. For some process flows with high degrees of complexity
    and sensitivity, this may be ideal. For instance, a “report fraud” intent should
    probably connect to a human right away.
  prefs: []
  type: TYPE_NORMAL
- en: In other scenarios, an early deflection to a human agent is mundane for the
    agent and expensive for the employer. For insurance systems handling claim statuses,
    member IDs and claim dates must be collected before getting to higher value tasks
    like explaining what has happened with a claim. Here the AI assistant could first
    collect the member ID and claim date before directing the conversation to a human.
  prefs: []
  type: TYPE_NORMAL
- en: Thus, the next evolution of a routing agent is to shift more of the work to
    automation. Let’s build this for Cake Bot.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.2 Transitioning from a routing agent to a process-oriented bot
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The generalized process flow for ordering cakes is shown in figure 2.13\. It
    includes four steps to clarify details about the cake being ordered, then a confirmation
    step, and finally fulfillment. (For brevity, we will omit the fulfillment details
    for the rest of the chapter—example code is available at our GitHub site: [https://github.com/andrewrfreed/EffectiveConversationalAI](https://github.com/andrewrfreed/EffectiveConversationalAI).)'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F13_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.13 Process flow for ordering a cake from Cake Shop
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: With the full process flow designed, we can transition from a routing agent
    toward a process-oriented bot. Cake Bot will handle part of the cake-ordering
    process by collecting a few details before routing to a human agent to complete
    the process. Figure 2.14 shows the design for the first iteration of Cake Bot’s
    transition.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F14_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.14 Transitioning a routing agent to a process-oriented bot. The bot
    now collects two pieces of information before handing off to a human.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Our process used to have one step (figure 2.12). Now we’ll have four:'
  prefs: []
  type: TYPE_NORMAL
- en: The bot will start the process by responding, “I can help with your cake order.”
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ask which size cake is needed, and provide options (small, medium, large).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ask the occasion for the cake, and provide options (birthday, wedding, anniversary,
    retirement, all-occasion).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Transfer the user to a human agent. This is the original first step from the
    routing agent, but the message to the agent has changed from “User wants to order
    a cake” to “User wants to order a <size> <occasion> cake.” The assistant will
    inject the responses from steps 2 and 3 into the message.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These steps are executed sequentially. Figure 2.15 shows step 2.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F15_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.15 The step to collect the cake size offers explicit choices to the
    user.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Note that the bot can offer distinct options to the user as buttons, letting
    the user know which options are available. The bot can also allow the user to
    type their response if they prefer. You can explore these options in the sample
    code provided on the book’s GitHub site.
  prefs: []
  type: TYPE_NORMAL
- en: Also note that each of these options will support a “fall through.” If the user
    starts the conversation with “I want to order a cake,” they will be asked for
    size and occasion. If they say “I want to order a large anniversary cake,” they
    will skip the size and occasion questions since they already provided that information.
  prefs: []
  type: TYPE_NORMAL
- en: The rest of the cake-ordering process has been implemented on the book’s GitHub
    site following the steps described in this section. A sample conversation is provided
    in the following listing.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.3 Sample conversations for cake ordering
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '#1 The confirmation message in step 7 plays back the information collected
    in previous steps.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 The order confirmation in step 8 triggers conditional logic for the price
    of the cake.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Cake Bot is getting more capable. It has static question-answering capability
    about cakes, dynamic question-answering capability about store hours, and a process-oriented
    flow for ordering cakes. The Cake Shop team deploys its chatbot and is pleased
    with the results (and the users are pleased with their cakes!). Next, we’ll take
    on our final challenge of the chapter: adding generative AI capability with a
    large language model (LLM).'
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Refer to this chapter’s chatbot code that you downloaded from the book’s GitHub
    site ([https://github.com/andrewrfreed/EffectiveConversationalAI](https://github.com/andrewrfreed/EffectiveConversationalAI)).
    Load the chatbot in watsonx Assistant, and use the Preview panel to test the chatbot’s
    cake-ordering flow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Alternatively, implement Cake Bot’s ordering process in your preferred conversational
    AI platform:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Detect the cake-ordering intent.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Route the intent directly to a human agent.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Collect all four cake data points, and conclude with a summary.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 2.3 Responding to the user with generative AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cake Bot only uses traditional conversational AI technology so far. The question-answering
    is done by an intent-based classifier. The ordering process is done with a sequential
    series of rules. This has worked well for the needs of Cake Shop so far.
  prefs: []
  type: TYPE_NORMAL
- en: When the Cake Shop team reviews the performance of the Cake Bot, they see an
    unusual trend. Users are asking the bot for recipes they intend to serve for dinner
    before the cake. There’s no other pattern to recipe requests—there are requests
    for casseroles, salads, stir fries, and more. The team is heartened by the diversity
    of their users but does not know how to handle these requests in the Cake Bot.
    How could they detect all these different types of recipes, let alone respond
    to them all?
  prefs: []
  type: TYPE_NORMAL
- en: This is an excellent place for the Cake Shop team to incorporate some generative
    AI into their solution. They can use the existing intent mechanism to detect recipe
    requests and then route those to an LLM to generate an answer. They will need
    to integrate an LLM into their chatbot generally and send specific requests to
    that LLM.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see how they can do that.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.1 Integrating with an LLM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For many conversational AI platforms, the primary way to integrate with external
    systems is through application programming interfaces (APIs). These are ubiquitous
    integration patterns and fortunately are supported by a large variety of generative
    AI platforms that expose LLMs. The specific way APIs are integrated into conversational
    AI will vary by platform. In some platforms, this integration is done with code;
    others are low-code and visual interfaces. Differing platforms have different
    names for their integration capabilities, such as *extensions*, *integrations*,
    and *fulfillments*. Many let you integrate APIs via OpenAPI specifications.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will add a generative AI platform as an extension to do LLM-based text generation.
    There are four steps to adding an extension in our platform (the details of the
    steps are included in the book’s GitHub repository):'
  prefs: []
  type: TYPE_NORMAL
- en: From the Integrations menu, select Build a Custom Extension.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Provide a name and description, like “Generative AI platform API call.”
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Provide an OpenAPI specification file. This file documents the capabilities
    of the extension, including the methods it exposes, its required and optional
    parameters, and the responses it provides. OpenAPI specification files are a common
    documentation format for APIs. They are usually provided by generative AI platforms.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Provide connectivity and authentication details, such as the URL of the API
    implementation and the API key needed to access it.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We add the extension and visually explore it from inside the assistant. Figure
    2.16 shows the extension for the LLM text generation API in our platform.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F16_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.16 OpenAPI spec for our LLM text generation API with a subset of the
    possible request parameters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'At the time of writing, our text generation API includes 15 input parameters
    and 6 output parameters—more than fit in figure 2.16! There are also a handful
    of parameters available without any customization, like the HTTP status code for
    the response. Other generative AI platforms will have a similar parameter set,
    perhaps with different parameter names or locations. Let’s review the most significant
    parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`input` (request)—The prompt to the LLM. It will include the instructions,
    context, and data for the LLM. Some of that data may come directly from the user.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model_id` (request)—Identifier of the LLM to use for the task. Most generative
    AI platforms let you pick from several models.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`parameters` (request)—Key-value pairs that tweak the LLM’s behavior. These
    include the decoding method (greedy or sampling), number of output tokens to generate,
    and several other parameters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`generated_text` (response)—The output from the LLM.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can use an extension from any step in any action. Earlier in this chapter,
    we used capabilities like “Assistant says,” “Continue to next step,” and “Connect
    to Agent.” For extensions, the capability is called “Use an extension.” Figure
    2.17 shows what that extension invocation looks like for our recipe action. Other
    LLM tasks would look similar but have different configuration values. This parameter
    set is tuned for providing recipes.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F17_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.17 Invoking an LLM text-generation API from an action in the assistant
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Let’s look at how we can connect this all together in Cake Bot.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.2 Routing requests to an LLM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The flow diagram in figure 2.18 outlines how the recipe generation will be covered
    in Cake Bot. We first create a new action. Just like our question-answering actions,
    we start with some example utterances that trigger this action. Our first three
    utterances are “Show me a recipe for,” “How can I make,” and “Tell me how to bake
    a.” Given the huge variety of possible recipes, we do not include the names of
    the dishes, just the way that recipe requests are likely to look.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F18_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.18 Flow diagram for recipe generation in Cake Bot via LLM
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Step 1 of the new action is to store the entirety of the user’s original utterance
    (from the system variable `input.text`) in a variable called `recipe_query_text`.
    This is a technique we have not done in previous steps. For the cake-ordering
    action, each option had an explicit and finite set of responses. Even if the user
    said, “large cake, please” we only wanted to store “large.” For the recipe request,
    we have no idea what the user will say, so we will capture their entire utterance.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 of the action is to define the prompt for the LLM. We concatenate a simple
    system prompt with the user’s request. The next listing demonstrates the expression
    used in building the `recipe_prompt` variable.
  prefs: []
  type: TYPE_NORMAL
- en: '**Listing 2.4 Building the recipe prompt, which is stored in the `recipe_prompt`
    variable**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 3 of the action is to call the LLM. The parameters were shown in figure
    2.17, but let’s dive into the specific values here:'
  prefs: []
  type: TYPE_NORMAL
- en: '`input`—We assign the `recipe_prompt` variable value as input. This injects
    the user’s recipe request into the generalized prompt format shown in listing
    2.4\.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`model_id`—There are many models available, but at the time of writing, mistralai/mixtral-8x7b-instruct-v01
    has performed well on this generation task.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`project_id`—This is an identifier from the generative AI platform project
    instance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`min_tokens` and `max_tokens`—These are set to `0` and `1000` respectively,
    increased from the defaults of `0` and `200`, because recipes tend to be a bit
    lengthy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`decoding_method`—Set to `greedy` for ease of debugging, so the model responds
    identically if the same input is given.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`repetition_penalty`—Set to `1` (no penalty), since recipes on the internet
    typically have some repetition in them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`version`—Indicates the minor version of the API requested. We used the default
    at the time of writing: 2023-05-29\.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Step 4 of the action is to check that the API call was successful, and if so,
    to display the response to the user. We’ll generate a response starting with some
    static text, “Here’s your recipe,” and append the LLM response. We don’t need
    to write any JSON parsing code; the OpenAPI specification tells us we can reference
    the value of `generated_text`. Figure 2.19 shows the action response configuration.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F19_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.19 Displaying the output from the LLM call to the user
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This was a lot of fun to build inside Cake Bot! Listing 2.5 shows one example
    conversation we had with the bot. The recipe is lengthy, so most of it is omitted
    for brevity. Load up Cake Bot and try it for yourself!
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.5 Sample abbreviated conversation with Cake Bot
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Exercises
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Refer to this chapter’s chatbot code that you downloaded from the book’s GitHub
    site ([https://github.com/andrewrfreed/EffectiveConversationalAI](https://github.com/andrewrfreed/EffectiveConversationalAI)).
    Load the chatbot in watsonx Assistant, and follow the instructions to integrate
    with watsonx.ai. Use the Preview panel to test the chatbot’s recipe flow.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Alternatively, implement Cake Bot’s ordering process in your preferred conversational
    and generative AI platforms:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Detect the recipe intent.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Build a prompt from a set of instructions and the user’s input.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Direct the LLM’s response to the user.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Question-answering (Q&A) bots are a great way to start building your first conversational
    AI.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Training Q&A bots with examples of questions lets you provide predefined answers
    to related groups of questions (intents).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Actions start with an intent and can have many outcomes: answering a question,
    deflecting a user to a human agent, asking follow-up questions, and making API
    calls.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A routing agent identifies intents and passes information to human agents. It
    is a great method for incrementally adding capability to a conversational AI while
    leaning on human capability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conversational AI can use a combination of traditional and rules-based techniques
    along with generative AI.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
