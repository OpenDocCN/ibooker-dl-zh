["```py\n<script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/\ntfjs@latest/dist/tf.min.js\"></script>\n```", "```py\n<script src=\"https://cdn.jsdelivr.net/npm/\n@tensorflow-models/mobilenet@1.0.0\"></script>\n```", "```py\n<img id=\"image\" src=\"cat.jpg\" />\n<p id=\"prediction_output\">Loading predictions...</p>\n<script>\n const image = document.getElementById(\"image\");\n const predictionOutput = document.getElementById(\"prediction_output\");\n\n *`// Load the model.`*\n mobilenet.load().then(model => {\n   *`// Classify the image. And output the predictions`*\n   model.classify(image).then(predictions => {\n     predictionOutput.innerText = predictions[0].className;\n   });\n });\n</script>\n```", "```py\nconst path = 'https://storage.googleapis.com/tfjs-\nmodels/tfjs/mobilenet_v1_1.0_224/model.json';\n\nmodel = tf.loadLayersModel(path).then(model => {\n    *`// Load model and output predictions here`*\n});\n```", "```py\n$ pip install tensorflowjs\n```", "```py\n$ tensorflowjs_converter --input_format keras keras_model/model.h5 web_model/\n```", "```py\n$ ls web_model\ngroup1-shard1of4  group1-shard3of4  model.json group1-shard2of4  group1-shard4of4\n```", "```py\n$ python3 -m http.server 8080\n```", "```py\nconst path = 'https://storage.googleapis.com/tfjs-\nmodels/tfjs/mobilenet_v1_1.0_224/model.json';\nconst mobilenet = await tf.loadLayersModel(path);\n```", "```py\nconst inputLayerShape = mobilenet.inputs[0].shape; // [null, 224, 224, 3]\nconst outputLayerShape = mobilenet.outputs[0].shape; // [null, 1000]\nconst numLayers = mobilenet.layers.length; // 88\n```", "```py\n// Get a specific layer const layer = mobilenet.getLayer('conv_pw_13_relu');\n\n// Create a new feature extraction model featureExtractionModel = tf.model({inputs: mobilenet.inputs, outputs:\nlayer.output});\n\nfeatureExtractionModel.layers.length; *`// 82`*\n```", "```py\nconst trainableModel = tf.sequential({\n    layers: [\n        tf.layers.flatten({inputShape: [7, 7, 1024]}),\n        tf.layers.dense({\n        units: 64,\n        activation: 'relu',\n        kernelInitializer: 'varianceScaling',\n        useBias: true\n    }),\n    tf.layers.dense({\n        units: 2,\n        kernelInitializer: 'varianceScaling',\n        useBias: false,\n        activation: 'softmax'\n    })]\n});\n```", "```py\nfunction capture() {\n     return tf.tidy(() => {\n         // convert to a tensor\n         const webcamImage = tf.fromPixels(webcam);\n         // crop to 224x224\n         const croppedImage = cropImage(webcamImage);\n         // create batch and normalize\n         const batchedImage = croppedImage.expandDims(0);\n         return batchedImage.toFloat().div(tf.scalar(127)).sub(tf.scalar(1));\n     });\n}\n```", "```py\nfunction addTrainingExample(img, label) {\n     // Extract features.\n     const data = featureExtractionModel.predict(img);\n     // One-hot encode the label.\n     const oneHotLabel = tf.tidy(() =>\n     tf.oneHot(tf.tensor1d([label], 'int32'), 2));\n     // Add the label and data to the training set.\n}\n```", "```py\nconst optimizer = tf.train.adam(learningRate);\nmodel.compile({ optimizer: optimizer, loss: 'categoricalCrossentropy' });\nmodel.fit(data, label, {\n    batchSize,\n    epochs: 5,\n    callbacks: {\n        onBatchEnd: async (batch, logs) => {\n            await tf.nextFrame();\n        }\n    }\n}\n```", "```py\nconst result = a.add(b).square().neg();\nreturn result;\n```", "```py\nconst sum = a.add(b);\nconst square = sum.square();\nconst result = square.neg();\nsum.dispose();\nsquare.dispose();\nreturn result;\n```", "```py\nconst result = tf.tidy(() => {\n    return a.add(b).square().neg();\n});\n```", "```py\n<script src=\"https://unpkg.com/ml5@latest/dist/ml5.min.js\"\ntype=\"text/javascript\"></script>\n```", "```py\n// Initialize the image classifier method with MobileNet\nconst classifier = ml5.imageClassifier('MobileNet', modelLoaded);\n\n// Make a prediction with the selected image\nclassifier.predict(document.getElementById('image'), function(err, results) {\n  console.log(results);\n});\n```", "```py\n<script src=\"http://p5js.org/assets/js/p5.min.js\"></script>\n<script src=\"http://p5js.org/assets/js/p5.dom.min.js\"></script>\n<script src=\"https://unpkg.com/ml5@latest/dist/ml5.min.js\"></script>\n\n<script>\nfunction setup() {\n    // Set up camera here\n\n    // Call PoseNet model\n    const poseNet = ml5.poseNet(video, modelReady);\n\n    // PoseNet callback function\n    poseNet.on('pose', function (results) {\n        const poses = results;\n    });\n}\n</script>\n```", "```py\npython pix2pix.py \\\n  --mode train \\\n  --output_dir facades_train \\\n  --max_epochs 200 \\\n  --input_dir facades/train \\\n  --which_direction BtoA\n```", "```py\npython tools/export-checkpoint.py --checkpoint ../export --output_file\nmodels/MY_MODEL_BtoA.pict\n```", "```py\n// Create a pix2pix model using a pre-trained network\nconst pix2pix = ml5.pix2pix('models/customModel.pict', modelLoaded);\n\n// Transfer using a canvas\npix2pix.transfer(canvas, function(err, result) {\n  console.log(result);\n});\n```"]