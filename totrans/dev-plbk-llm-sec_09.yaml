- en: Chapter 9\. Find the Weakest Link
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You are the weakest link. Goodbye!
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Every episode of *The Weakest Link* game show (BBC/NBC)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: On the morning of December 10th, 2021, I woke up to an overnight message from
    David Linder, my company’s Chief Information Security Officer (CISO). It said,
    “Call me as soon as you’re up. It’s important.” I knew this wasn’t going to be
    good news. Your CISO calling in the middle of the night is the last thing an executive
    wants.
  prefs: []
  type: TYPE_NORMAL
- en: Once I got ahold of David, he told me that in the past 24 hours, major corporations
    worldwide were being hacked. The problem had been traced back to a single, open
    source library embedded into *millions* of applications. *Wired* magazine published
    a story about the incident that cried, [“The Internet Is on Fire!”](https://oreil.ly/I26Ux)
  prefs: []
  type: TYPE_NORMAL
- en: Later in this chapter, I’ll tell you more about that story. I give that snippet
    now to impress upon you how critical the issue of *software supply chain security*
    has become for software development today. Some readers of this book may be coming
    from an application security (AppSec) background and are reading this chapter
    for specific guidance about securing LLMs. However, I’m sure other readers are
    coming here already understanding LLMs and looking for guidance on security best
    practices. Knowing this, I will set up this chapter to cover both.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll start by covering the basic concepts of supply chain security. Then, we
    will examine the unique structure and challenges of an LLM application’s supply
    chain. We’ll discuss some best practices, but we must also acknowledge this is
    a fast-moving part of the LLM security landscape. So, we’ll wrap up with a discussion
    about the future of the space.
  prefs: []
  type: TYPE_NORMAL
- en: Supply Chain Basics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For readers who may be well-versed in AI but newer to AppSec concepts, I will
    start by setting up some basics around the supply chain and discussing some well-known
    case studies involving failure to properly manage supply chain security.
  prefs: []
  type: TYPE_NORMAL
- en: I wasn’t a computer science major in college. I studied business. I could go
    on about how lessons about business have often offered me unique insights into
    software development. The supply chain is one of these cases. It’s a concept thoroughly
    studied by business researchers for decades.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The term *supply chain* refers to the entire process of producing and delivering
    a product or service, from sourcing raw materials to distribution to the end user.
    It encompasses various steps, such as procurement, manufacturing, transportation,
    and distribution, involving a network of entities, including suppliers, manufacturers,
    and retailers. Effective supply chain management is crucial for businesses to
    ensure efficiency, cost-effectiveness, and timely delivery of products and services.
  prefs: []
  type: TYPE_NORMAL
- en: As the world industrialized, our economic model transitioned from a craftsman-based
    system to a mass production–dominated system. This shift led to extensive global
    supply chains, replacing the earlier practice of individuals or small groups producing
    goods with locally sourced materials. In these complex global networks, manufacturers
    rely on suppliers from various countries to provide specific components needed
    for their products. For example, a single delay or quality issue in one part of
    the world, such as a shortage of a specific semiconductor in China, can halt iPhone
    production, leading to widespread shortages. Similarly, if a seat belt component
    sourced from a third-party supplier fails to meet safety standards, it can compel
    a company like Ford to issue a massive safety recall. These scenarios illustrate
    how modern supply chains’ intricate interdependencies and logistical challenges
    can significantly impact product availability and quality.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The proverb “a chain is only as strong as its weakest link” is used to convey
    that a system or organization is vulnerable due to its weakest component. It emphasizes
    the importance of ensuring every part is solid and reliable because even one weak
    point can lead to the failure of the entire system. This concept is often applied
    in various contexts, including security, teamwork, and quality assurance.
  prefs: []
  type: TYPE_NORMAL
- en: Software Supply Chain Security
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Today, large software development teams are often referred to as software factories
    because of the increasing similarities in modern, large-scale software development
    methodologies to traditional mass production, making the concept of the supply
    chain highly relevant.
  prefs: []
  type: TYPE_NORMAL
- en: Software supply chain security is an increasingly pivotal aspect of cybersecurity.
    It involves a series of measures designed to ensure the integrity and security
    of software throughout its lifecycle, from development to deployment. The field
    includes scrutinizing third-party components, such as libraries and packages,
    for vulnerabilities; ensuring the security of code repositories; and safeguarding
    continuous integration and delivery processes.
  prefs: []
  type: TYPE_NORMAL
- en: The essence of software supply chain security is to identify, manage, and mitigate
    risks that might compromise software at any stage of its development or deployment.
    Tight management is crucial because any breach in the supply chain can lead to
    severe data breaches, loss of customer trust, and significant financial and reputational
    damage. Recent high-profile breaches have shown that vulnerabilities in the supply
    chain can have far-reaching effects, impacting countless users and multiple organizations.
  prefs: []
  type: TYPE_NORMAL
- en: As organizations increasingly rely on open source components and third-party
    software, the complexity and interconnectedness of the software supply chain grow.
    Consequently, developers, security professionals, and business leaders must understand
    the risks and implement strategies to safeguard their software supply chains.
    This includes rigorous vetting of third-party components, maintaining an up-to-date
    inventory of all elements used in the software (often through a software bill
    of materials), regular scanning for vulnerabilities, and adopting a comprehensive,
    proactive approach to security.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s look at a few examples of serious breaches, their consequences, and
    lessons learned from them.
  prefs: []
  type: TYPE_NORMAL
- en: The Equifax Breach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In March 2017, researchers disclosed a serious vulnerability ([CVE-2017-5638](https://oreil.ly/k4KTx))
    in the popular Apache Struts web framework. The vulnerability allowed remote code
    execution via malicious input, and the MITRE Corporation (which we’ll learn more
    about later in this chapter) assigned it a maximum severity score of 10\. Equifax,
    one of the largest consumer credit reporting agencies, used Struts in one of its
    public web portals. However, the company failed to patch the disclosed vulnerability
    for over two months, exposing their systems.
  prefs: []
  type: TYPE_NORMAL
- en: In May 2017, hackers exploited the unpatched Struts flaw to breach Equifax systems
    and exfiltrate sensitive personal and financial data related to 148 million consumers.
    Equifax did not discover the breach until July 2017\. This massive breach resulted
    in over $1 billion in losses for Equifax.
  prefs: []
  type: TYPE_NORMAL
- en: Impact
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Equifax breach affected nearly half the US population and had enormous
    consequences:'
  prefs: []
  type: TYPE_NORMAL
- en: Sensitive PII, such as SSNs, addresses, and birth dates, was stolen, enabling
    identity theft.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple class-action lawsuits were filed against Equifax.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hundreds of millions of dollars in settlement money was paid for damages to
    affected consumers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Equifax senior executives were fired and suffered major reputation damage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lessons learned
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The incident highlighted critical software security issues:'
  prefs: []
  type: TYPE_NORMAL
- en: Patch open source components quickly, especially if they are internet facing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understand your external attack surface and third-party risks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use multilayer security controls to limit breach impacts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement incident response planning for “when,” not “if.”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Equifax breach was a seminal event that demonstrated the immense risks unpatched
    software posed to companies and private citizens. Key lessons include quickly
    applying patches, restricting component access, monitoring systems, and planning
    incident responses.
  prefs: []
  type: TYPE_NORMAL
- en: The SolarWinds Hack
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In December 2020, a major cyberattack was uncovered targeting SolarWinds, a
    software company that provides IT management tools used by thousands of organizations
    globally. Hackers had inserted malicious code into the SolarWinds Orion network
    monitoring software, which was then distributed unknowingly to SolarWinds’s customers
    as software updates between March and June 2020.
  prefs: []
  type: TYPE_NORMAL
- en: This supply chain attack took advantage of the widespread use of SolarWinds
    software to infiltrate the networks and systems of high-profile targets like US
    government agencies, major technology companies including Microsoft and FireEye,
    and other large corporations and organizations. The hackers, suspected to be part
    of a sophisticated Russian cyber espionage operation, managed to avoid detection
    for almost a year through stealthy techniques to impersonate legitimate user activity
    and blend in with normal network traffic.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Attackers compromised SolarWinds’s build pipeline to insert the malicious code.
    Securing your build pipelines is crucial to the overall security of your software.
    Failure to do so can impact your customers—not just you!
  prefs: []
  type: TYPE_NORMAL
- en: Impact
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The SolarWinds hack had an unprecedented impact in terms of scale and number
    of affected victims. By infiltrating the software supply chain, the attackers
    gained far-reaching access to thousands of downstream customers. Beyond SolarWinds,
    the access enabled by the compromised Orion software also opened pathways to breach
    the networks of their customers and partners. Estimates indicate that over one
    hundred US companies and government agencies were affected.
  prefs: []
  type: TYPE_NORMAL
- en: 'The full impact is still being uncovered, but consequences include:'
  prefs: []
  type: TYPE_NORMAL
- en: Sensitive government and corporate data theft
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to core infrastructure and internal communications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cascading breaches across interconnected partners and supply chains
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Significant costs for incident response and remediation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lessons learned
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The SolarWinds attack highlighted major risks in increasingly interconnected
    software supply chains and the need for better security practices, including:'
  prefs: []
  type: TYPE_NORMAL
- en: Multifactor authentication, privileged access management, and logging to help
    detect unusual access
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Software verification, code audits, and enhanced supply chain controls by vendors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Improved compartmentalization between systems to limit lateral movement
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assuming breach and engaging in more proactive threat hunting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Faster coordination and information sharing across the public and private sector
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The SolarWinds hack demonstrates the potential scale and impact of supply chain
    cyberattacks by leveraging trusted third-party software to breach countless downstream
    targets. More vigilance and collaboration on software supply chain security will
    be crucial.
  prefs: []
  type: TYPE_NORMAL
- en: The Log4Shell Vulnerability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At the start of this chapter, I shared a story about my CISO calling in the
    middle of the night and filling me in on a major problem. That quickly ballooned
    into one of the biggest stories in supply chain security ever. These are the details
    of that story.
  prefs: []
  type: TYPE_NORMAL
- en: In November 2021, a critical zero-day remote code execution vulnerability was
    discovered in Log4j, a Java logging library used by an incredible number of applications
    and services. Tracked as [CVE-2021-44228](https://oreil.ly/7sGbm) and dubbed “Log4Shell,”
    this vulnerability allowed attackers to gain full control and remote access to
    vulnerable servers.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Zero-day vulnerabilities are unknown software flaws that come to light before
    developers can create a patch (i.e., they have zero days to prepare). They pose
    a significant security risk because attackers can exploit these vulnerabilities
    before a fix is available. The urgency and potential impact of zero-day exploits
    make them a critical concern in cybersecurity, requiring immediate attention to
    protect systems and data from compromise. Zero-day vulnerabilities are a favored
    target for sophisticated cyberattacks, including espionage and cyber warfare.
  prefs: []
  type: TYPE_NORMAL
- en: The Log4j library allows data logging from many sources, including untrusted
    data from users. The vulnerability arose from improper input validation, enabling
    crafted requests to trigger malicious Java code execution on the server. Attackers
    could send payloads over the internet, SMS, and chat apps. When such untrusted
    inputs were innocently written to Log4j, it could allow remote code execution,
    allowing the attacker to gain full shell access to the server—thus the name Log4Shell.
  prefs: []
  type: TYPE_NORMAL
- en: Impact
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Due to Log4j’s ubiquitous use, Log4Shell’s impact was massive. Within days of
    the disclosure, millions of internet-facing systems were nefariously scanned for
    the flaw. Successful exploits surged, with botnets, cryptominers, ransomware groups,
    and state-sponsored hackers all leveraging Log4Shell.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consequences included:'
  prefs: []
  type: TYPE_NORMAL
- en: Data theft from compromised servers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installation of malware, backdoors, and cryptominers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ransomware attacks shutting down operations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cascading supply chain breaches as access opened networks of partners
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Burdensome, urgent, out-of-cycle patching exercises across cloud and on-prem
    infrastructure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lessons learned
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Log4Shell carries several key lessons:'
  prefs: []
  type: TYPE_NORMAL
- en: Open source components can pose massive systemic risks despite their benefits.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More attention is needed to input validation and security hygiene in libraries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More importance needs to be paid to rapid coordination and disclosure of vulnerabilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A software bill of materials can aid in understanding component risks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suppliers should assume breaches and hunt for intrusions rather than just preventing
    exploits.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The scale of the Log4Shell fallout showed just how much interconnectedness amplifies
    supply chain threats. In the aftermath, software integrity and knowing the provenance
    of components have become vital to managing risk.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the LLM Supply Chain
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you’re familiar with the basics of supply chain security and have seen
    classic examples of the price of failure to manage it correctly, let’s look into
    what makes the LLM software supply chain unique. The distinctiveness of LLM supply
    chains primarily stems from their reliance on massive and diverse datasets for
    training and their often intricate interplay with various external data sources
    and services.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating a third-party foundation model introduces a critical dependency
    into your application’s supply chain. This dependency extends beyond just the
    software component; it also encompasses the data used in the model’s development.
    Keeping track of updates, patches, and changes to the model becomes crucial, as
    they can significantly affect your application’s performance and security. Even
    if you start from a pretrained foundation model, you may decide to fine-tune the
    model. In this case, you’ll need to consider any training data you use in your
    supply chain.
  prefs: []
  type: TYPE_NORMAL
- en: LLMs, especially those using techniques like RAG, frequently interact with external
    APIs, databases, and online resources. This integration is pivotal for models
    to access real-time information or specific datasets necessary for certain applications.
    However, it also opens up additional vectors for potential security vulnerabilities,
    data privacy concerns, and compliance issues. Ensuring secure and ethical integration
    with these external systems is another critical aspect of LLM supply chain management.
  prefs: []
  type: TYPE_NORMAL
- en: To understand the landscape better, let’s look at some examples of LLM-specific
    supply chain risks.
  prefs: []
  type: TYPE_NORMAL
- en: Open Source Model Risk
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While many development teams choose to use a proprietary, hosted LLM foundation
    model such as OpenAI’s GPT series, more and more teams are experimenting with
    open source foundation models. If you choose to manage and host a model, the version
    and configuration of your model must be tracked as part of your supply chain.
    Recent events have shown that the supply chain for open source model software
    is highly immature and could leave users open to accidentally acquiring models
    tainted by malicious actors. Let’s look at how this might happen so you can understand
    the risk.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As of this writing, the most popular place to exchange LLM models is called
    [Hugging Face](https://huggingface.co). It describes itself as “The AI community
    building the future. The platform where the machine learning community collaborates
    on models, datasets, and applications.”
  prefs: []
  type: TYPE_NORMAL
- en: In 2023, multiple incidents related to Hugging Face raised the consciousness
    around blindly trusting models acquired from sites like this. In July 2023, the
    [Hugging Face Twitter account posted](https://oreil.ly/iWC2X), “We are looking
    into an incident where a malicious user took control over the Hub organizations
    of Meta/Facebook & Intel via reused employee passwords that were compromised in
    a data breach on another site. We will keep you updated.”
  prefs: []
  type: TYPE_NORMAL
- en: While the full impact of that incident remains unclear, it brought to light
    the possibility that a malicious actor could insert itself into the supply chain
    and change components thought to have come from a trusted source, in this case
    Meta or Intel. It triggered an expanded set of serious discussions in the AI community
    about supply chain security.
  prefs: []
  type: TYPE_NORMAL
- en: While that first incident wasn’t widely reported and seemed isolated, in December
    2023, the team at Lasso Security published research showing that over 1,600 Hugging
    Face API tokens were exposed. The team could use these tokens to access the Hugging
    Face accounts of over 700 organizations, including major players such as Meta,
    Microsoft, Google, and VMware. This demonstrated a clear risk that a malicious
    third party could swap a well-known, well-trusted model for one with its own modifications—a
    massive risk to any application that might download and use such a model.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Pickle, commonly used for serialization in machine learning, is the default
    format for model weights in the popular PyTorch ML toolkit. Hugging Face’s documentation
    warns that loading tainted Pickle files could lead to arbitrary code execution
    attacks. To address these vulnerabilities, Hugging Face is developing a project
    called Safetensors. This project is in its early stages, but is an important development
    to follow to enhance your security posture.
  prefs: []
  type: TYPE_NORMAL
- en: While this was a case of an ethical hacker research group responsibly disclosing
    this risk, this incident further cements the idea that the supply chain for models
    is crucial. Later in this chapter, we’ll discuss how to track the source and provenance
    of your models so that if issues come to light, you are prepared to handle them
    quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Training Data Poisoning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Data poisoning* is a manipulation of training data that can introduce vulnerabilities
    into an LLM. This can be done in various ways, such as injecting falsified information,
    biasing the data, or creating adversarial examples. Data poisoning aims to make
    the LLM produce inaccurate or harmful outputs.'
  prefs: []
  type: TYPE_NORMAL
- en: Training data poisoning is a topic that’s been studied in AI circles for many
    years. Classic examples have involved repeated attempts by spammers to poison
    the data used to train Google’s Gmail spam filters. More recently, research has
    shown this can be a big issue for any LLM application. In early 2023, [researchers
    from Google, ETH Zurich, Nvidia, and Robust Intelligence](https://oreil.ly/J2fMz)
    showed that for as little as $60, the researchers could insert data into resources
    like Wikipedia that could influence training results even against such internet-scale
    resources.
  prefs: []
  type: TYPE_NORMAL
- en: The Hugging Face API token leak mentioned in the last section exposed models
    and datasets. Hugging Face hosts over 250,000 prebuilt datasets that developers
    can use to train or fine-tune their models, and those datasets are targets for
    manipulation in the same way as models. That means managing datasets you use for
    fine-tuning is as important as tracking your foundation model.
  prefs: []
  type: TYPE_NORMAL
- en: Accidentally Unsafe Training Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While data poisoning implies that a malicious actor is actively working to contaminate
    your model, it’s quite possible this could happen by mistake, especially with
    training datasets distilled from public internet sources.
  prefs: []
  type: TYPE_NORMAL
- en: We talked about the idea that your model could “know too much” in [Chapter 5](ch05.html#can_your_llm_know_too_much).
    In those cases, we looked at the possibility of the model regurgitating information
    on which it was trained or to which it had access. In December 2023, researchers
    from Stanford University showed that a highly popular dataset (LAION-5B) used
    to train image generation algorithms such as Stable Diffusion contained over three
    thousand images related to “child sexual abuse material.”
  prefs: []
  type: TYPE_NORMAL
- en: This example sent developers of AI image generation tools scrambling to determine
    if their models used this training data and what impact that might have on their
    applications. If a development team for a particular application hadn’t carefully
    documented the training data they’d used, they wouldn’t know if they were exposed
    to risks that their models could generate inappropriate and illegal images.
  prefs: []
  type: TYPE_NORMAL
- en: Unsafe Plug-ins
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In March 2023, OpenAI introduced a significant expansion of functionality to
    its platform through plug-ins. These plug-ins brought in functionalities from
    third-party providers including Expedia, Zillow, Kayak, Instacart, and OpenTable,
    enabling users to perform diverse tasks such as job searching, real estate listing,
    product recommendations, shopping, gaming, and recipe retrieval. This expansion
    dramatically enhanced the utility and user engagement on the platform.
  prefs: []
  type: TYPE_NORMAL
- en: However, this innovation was not without its risks. Researchers quickly identified
    security concerns, such as the potential for using plug-ins as vectors for injecting
    malicious code into ChatGPT sessions. Such vulnerabilities could lead to severe
    consequences, including data theft, malware installation, or even full control
    over a user’s computer.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, there was the risk of plug-ins being used for unauthorized data
    collection. A plug-in, for instance, could track a user’s browsing activities
    or record conversations with ChatGPT without the user’s knowledge or consent,
    raising significant privacy concerns.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a secure plug-in architecture is a complex and challenging task. If
    your application leverages plug-ins, tracking their sources and versions meticulously
    is crucial. Ensuring the security of these third-party components involves continuous
    monitoring for vulnerabilities, regular updates, and comprehensive security audits.
    This vigilance is vital to safeguard against potential security breaches and maintain
    the users’ trust and safety.
  prefs: []
  type: TYPE_NORMAL
- en: Creating Artifacts to Track Your Supply Chain
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we’ve seen, tracking the components that go into your application is critical.
    The Equifax, SolarWinds, and Log4Shell examples we saw earlier in the chapter
    drove forward the importance of software supply chain security and led to the
    idea that you must track any artifacts going into your software. In particular,
    they gave rise to the popularity of the software bill of materials (SBOM). In
    this chapter, we’ll review the concept of SBOMs, and also related artifacts such
    as model cards and ML-BOMs that will be important to our LLM supply chain.
  prefs: []
  type: TYPE_NORMAL
- en: Importance of SBOMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A *software bill of materials* is a comprehensive inventory or a detailed list
    of all components, libraries, and modules that comprise a piece of software. Think
    of it as a manifest or an ingredient list for software, detailing every element
    in the final product. This includes code written by the software development team
    and any open source or third-party components integrated into the software.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The software bill of materials derives from the manufacturing term “bill of
    materials” (BOM), a comprehensive inventory that lists all the materials, components,
    and sub-assemblies needed to manufacture a product. It typically includes part
    names, numbers, quantities, and other descriptive information.
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of an SBOM is to provide clear visibility into the software’s composition,
    which is crucial for security, compliance, and management. By understanding precisely
    what’s in their software, organizations can better monitor for vulnerabilities,
    comply with legal and licensing requirements, and manage updates and patches more
    effectively. In supply chain security, an SBOM is a vital tool for identifying
    potential risks and ensuring the integrity of software components.
  prefs: []
  type: TYPE_NORMAL
- en: The information tracking in your SBOM is essential for rapid response and remediation,
    reducing the window of opportunity for attackers. Furthermore, an SBOM helps your
    company comply with security standards and regulations, as it provides proof of
    due diligence in using secure and licensed components. In the increasingly complex
    software development landscape, where dependencies are deeply intertwined, an
    SBOM acts as a map, guiding the way to a more secure and resilient software infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see how we might apply and extend SBOM concepts to our LLM models and
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: Model Cards
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Earlier in this chapter, we learned that Hugging Face has become the de facto
    place to trade machine learning models and training sets. With a need to track
    important model information and dependencies, the company developed a standardized
    artifact called a *model card*.
  prefs: []
  type: TYPE_NORMAL
- en: Hugging Face’s model cards are designed to provide comprehensive information
    about each AI model hosted on its platform. The goal is to offer users—whether
    developers, researchers, or end users—a clear understanding of a model’s capabilities,
    limitations, and intended use cases. This approach aligns with broader efforts
    in the AI community to ensure that AI models are used ethically and effectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some key aspects of Hugging Face model cards:'
  prefs: []
  type: TYPE_NORMAL
- en: Model description
  prefs: []
  type: TYPE_NORMAL
- en: Each model card typically starts with a description of the model, including
    its purpose, architecture, and training data. This gives users a high-level understanding
    of what the model is designed to do and how it works.
  prefs: []
  type: TYPE_NORMAL
- en: Training data
  prefs: []
  type: TYPE_NORMAL
- en: The model cards often detail the datasets used to train the model. Understanding
    the model’s potential biases and limitations is crucial, as the nature of the
    training data can significantly influence the model’s performance and behavior.
  prefs: []
  type: TYPE_NORMAL
- en: Intended use
  prefs: []
  type: TYPE_NORMAL
- en: Model cards include information about the model’s intended use, which helps
    users understand the contexts in which the model is expected to perform well.
    This section may also include recommendations or guidelines for use.
  prefs: []
  type: TYPE_NORMAL
- en: Ethical considerations
  prefs: []
  type: TYPE_NORMAL
- en: Many model cards address ethical considerations, such as potential biases in
    the model and the impact of its deployment on various stakeholders. This reflects
    a growing recognition of the need to consider the broader societal and sustainability
    implications of AI technologies.
  prefs: []
  type: TYPE_NORMAL
- en: Performance metrics
  prefs: []
  type: TYPE_NORMAL
- en: The cards often include various performance metrics to show users how well the
    model performs. These metrics are typically based on the model’s performance on
    benchmark datasets or specific tasks for which it is designed.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations
  prefs: []
  type: TYPE_NORMAL
- en: A critical component of model cards is a discussion of the model’s limitations.
    This includes areas where the model may not perform as expected, potential risks
    in certain applications, or areas where the model should be used with caution.
  prefs: []
  type: TYPE_NORMAL
- en: Usage examples and tutorials
  prefs: []
  type: TYPE_NORMAL
- en: Many model cards provide examples of using the model, along with code snippets
    or links to notebooks. This is particularly helpful for developers who want to
    integrate the model into their applications.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Other LLM vendors, such as AWS, have started developing their own model card
    formats. There will be fragmentation in this space, so you’ll want to consider
    which to use for a given project. However, conceptually, you should find them
    similar to what’s discussed here.
  prefs: []
  type: TYPE_NORMAL
- en: Model Cards Versus SBOMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Model cards and SBOMs are tools designed to increase transparency and understanding
    of complex software systems, including AI models. Still, they serve different
    purposes and contain different types of information.
  prefs: []
  type: TYPE_NORMAL
- en: Purpose and focus
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The primary purpose of model cards is to provide a clear, understandable description
    of a machine learning model’s capabilities, behavior, and limitations. They focus
    on the performance, ethical considerations, use cases, and data used in training
    the model. Model cards are handy for end users and developers who need to understand
    an ML model’s operational characteristics and ethical implications.
  prefs: []
  type: TYPE_NORMAL
- en: An SBOM is essentially a detailed inventory of all software product components.
    SBOMs focus on listing and detailing every piece of third-party and open source
    software included in a software product. They are critical for understanding the
    software’s composition, especially for tracking vulnerabilities, licenses, and
    dependencies. Note that AI-specific SBOMs are being developed; we’ll cover that
    later in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Content
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Model cards typically include information such as model architecture, training
    data, performance metrics, intended use, ethical considerations, and limitations.
    They might also provide insights into the model’s development process and any
    potential biases in the model.
  prefs: []
  type: TYPE_NORMAL
- en: SBOMs contain detailed lists of every software component, version, patch status,
    licenses, and sometimes the origin of each component. This information is vital
    for vulnerability management, compliance checks, and software maintenance.
  prefs: []
  type: TYPE_NORMAL
- en: Use in security and compliance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While they do not directly address security vulnerabilities, model cards can
    indirectly indicate the robustness and reliability of a model, which are crucial
    aspects of security in AI systems. They can also highlight ethical risks or biases
    that might have security implications.
  prefs: []
  type: TYPE_NORMAL
- en: SBOMs are directly used in contexts of security and compliance. They are crucial
    for vulnerability management, as they allow security teams to quickly identify
    whether newly discovered vulnerabilities in third-party components impact their
    software. They are also used for license compliance and risk management.
  prefs: []
  type: TYPE_NORMAL
- en: Industry application
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Model cards are specific to AI and machine learning and are part of the broader
    movement toward responsible AI.
  prefs: []
  type: TYPE_NORMAL
- en: SBOMs are broadly applicable across all software development and are increasingly
    becoming a standard part of software documentation, especially in industries where
    security and compliance are paramount.
  prefs: []
  type: TYPE_NORMAL
- en: 'CycloneDX: The SBOM Standard'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CycloneDX, managed by the OWASP Foundation, has become the most powerful standard
    for SBOMs. It’s a standardized format that offers a structured, machine-readable
    inventory of all software components in a project or system, complete with details
    about their relationships and dependencies. Think of CycloneDX as a comprehensive
    ingredient list for software, but far more detailed and insightful.
  prefs: []
  type: TYPE_NORMAL
- en: The creation of CycloneDX was driven by the need for transparency and security
    in the increasingly complex web of software dependencies. This complexity posed
    significant security and compliance challenges. By clearly outlining software
    composition, CycloneDX enhances the ability to identify vulnerabilities and manage
    risks effectively. Another pivotal factor in its development was the need for
    standardization. Before CycloneDX, the diversity of SBOM formats used by different
    tools hindered sharing and interoperability. CycloneDX addresses this by providing
    a unified language for describing software components, fostering seamless integration
    across various tools and platforms.
  prefs: []
  type: TYPE_NORMAL
- en: As an open source project under the stewardship of OWASP, CycloneDX benefits
    from a community-driven approach. This ensures that it continually evolves to
    meet the industry’s changing needs and remains accessible to everyone. A clear
    understanding of your system’s software components is paramount for effective
    vulnerability management and patching. CycloneDX simplifies the process of identifying
    and addressing vulnerabilities, thus bolstering the overall security posture.
  prefs: []
  type: TYPE_NORMAL
- en: From a compliance perspective, especially with regulations like the US Executive
    Order on Improving the Nation’s Cybersecurity mandating SBOMs for government software,
    CycloneDX is instrumental in meeting these requirements. Additionally, CycloneDX
    plays a crucial role in license management by storing license information for
    each component, helping organizations comply with software licenses and avoid
    legal entanglements.
  prefs: []
  type: TYPE_NORMAL
- en: Incorporating CycloneDX into DevOps and continuous integration processes automates
    SBOM generation, providing ongoing insights into software composition throughout
    the development lifecycle. This integration enhances transparency and fosters
    trust among users or customers when organizations share their CycloneDX SBOMs.
  prefs: []
  type: TYPE_NORMAL
- en: The Rise of the ML-BOM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CycloneDX 1.5, released in June 2023, represents a significant advancement in
    the CycloneDX standard. This update is particularly significant for applications
    using machine learning, such as LLM applications, introducing notable transparency,
    security, and compliance enhancements.
  prefs: []
  type: TYPE_NORMAL
- en: A key innovation in CycloneDX 1.5 is the *ML-BOM* (machine learning bill of
    materials), a game changer for ML applications. This feature allows for the comprehensive
    listing of ML models, algorithms, datasets, training pipelines, and frameworks
    within an SBOM. It captures essential details such as model provenance, versioning,
    dependencies, and performance metrics, facilitating reproducibility, governance,
    risk assessment, and compliance for ML systems.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of transparency and understanding, the ML-BOM provides clear visibility
    into the components and processes involved in ML development and deployment. This
    helps stakeholders grasp the composition of ML systems, identify potential risks,
    and consider ethical implications. In the security domain, it enables the identification
    and remedying of vulnerabilities in ML components and dependencies. This feature
    is essential for conducting security audits and risk assessments, contributing
    significantly to developing secure and trustworthy ML systems.
  prefs: []
  type: TYPE_NORMAL
- en: Compliance is another critical area where the ML-BOM has significant impact.
    It supports adherence to regulatory requirements, such as GDPR and CCPA, by ensuring
    transparency and governance of the system. This facility is crucial for compliance
    audits and to demonstrate responsible AI practices.
  prefs: []
  type: TYPE_NORMAL
- en: Beyond these core areas, the ML-BOM offers additional benefits. It enhances
    reproducibility, allowing replication of experiments and results, which is vital
    for scientific rigor and trust in ML systems. Collaboration is also simplified,
    as the ML-BOM enables easier sharing and collaboration across teams and organizations
    on projects. Lastly, it is an effective tool for knowledge management, preserving
    critical information about systems for future maintenance, updates, and audits.
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 9-1](#fig_1_the_cyclone_dx_1_5_object_model_by_owasp) shows the high-level
    object model defined by the spec. This shows the various fields and options, which
    should give you an idea of how entities and their properties are defined. This
    model will define the structure of the SBOM/ML-BOM documents you’ll be creating.
    In the next section, we’ll dive into an example of building a simple version of
    such a document for an LLM application.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/dpls_0901.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9-1\. The CycloneDX 1.5 object model (by OWASP)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: CycloneDX 1.5 will advance transparency, security, and compliance in developing
    and deploying ML applications. It empowers organizations to build more responsible,
    trustworthy, and secure AI systems.
  prefs: []
  type: TYPE_NORMAL
- en: Building a Sample ML-BOM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we’ll use the CycloneDX standard to create a simple ML-BOM
    for a sample application. We will show how to represent the application’s pretrained
    foundation model and the dataset used to fine-tune the model for our application’s
    needs.
  prefs: []
  type: TYPE_NORMAL
- en: As we saw in the last section, ML-BOM artifacts can be quite extensive! To give
    you an idea about how they work, we’ll create a simplified ML-BOM for an LLM-based
    application called Customer Service Bot. It is based on the [Mixtral-8x7B-v0.1
    foundation model](https://oreil.ly/juffo) downloaded from Hugging Face. The model
    was then fine-tuned using an open source dataset for customer service applications
    we grabbed from [GitHub](https://oreil.ly/sc5jT). [Table 9-1](#table-9-1) shows
    a simple ML-BOM covering just these components.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 9-1\. Machine learning bill of materials (ML-BOM) for Customer Service
    Bot; BOM format: CycloneDX; spec version: 1.5; BOM version: 1'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Application: Customer Service Bot | Component: Customer Support LLM Chatbot
    Training Dataset |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Type | Application | Dataset |'
  prefs: []
  type: TYPE_TB
- en: '| Name | Customer Service Bot | Customer Support LLM Chatbot Training Dataset
    |'
  prefs: []
  type: TYPE_TB
- en: '| Version | 1.0.0 | 1.0.0 |'
  prefs: []
  type: TYPE_TB
- en: '| Description | A customer service bot built for company XYZ |  |'
  prefs: []
  type: TYPE_TB
- en: '| Licenses |  | ID: CDLA-Sharing-1.0 Name: Apache 2.0'
  prefs: []
  type: TYPE_NORMAL
- en: 'URL: [*https://choosealicense.com/licenses/apache-2.0*](https://choosealicense.com/licenses/apache-2.0)
    |'
  prefs: []
  type: TYPE_NORMAL
- en: '| External references | VCS: [*https://huggingface.co/mistralai/Mixtral-8x7B-v0.1*](https://huggingface.co/mistralai/Mixtral-8x7B-v0.1)
    The Mixtral-8x7B LLM is a pretrained generative sparse mixture of experts. | VCS:
    [*https://github.com/bitext/customer-support-llm-chatbot-training-dataset*](https://github.com/bitext/customer-support-llm-chatbot-training-dataset)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Bitext: Customer service tagged training dataset for LLM-based virtual assistants'
  prefs: []
  type: TYPE_NORMAL
- en: 'License file: [*https://github.com/bitext/customer-support-llm-chatbot-training-dataset/blob/main/LICENSE.txt*](https://github.com/bitext/customer-support-llm-chatbot-training-dataset/blob/main/LICENSE.txt);
    direct link to the license text for the dataset |'
  prefs: []
  type: TYPE_NORMAL
- en: 'While this version of our ML-BOM is human readable, and thus illustrates the
    concepts, one of the significant features of an SBOM/ML-BOM is to have it be highly
    structured and machine readable. That’s why CycloneDX provides a standard JSON
    format for your BOM. Here’s what this would look like in JSON:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `dataset` section details the training data used for fine-tuning the model,
    pointing to the specific dataset on GitHub. It’s important to populate the `components`
    and `externalReferences` sections with accurate details about your specific use
    case, including any other dependencies, services, or training data used.
  prefs: []
  type: TYPE_NORMAL
- en: In the ML-BOM, the tag VCS refers to a version control system. The URL provided
    is related to a version control repository where the component’s source code,
    model, or related data is managed and stored.
  prefs: []
  type: TYPE_NORMAL
- en: To sum up, model cards and ML-BOMs share some similarities, but there is a substantial
    difference in their details, as summarized in [Table 9-2](#table-9-2). You may
    need to use both in many situations until someone develops a single, comprehensive
    structure.
  prefs: []
  type: TYPE_NORMAL
- en: Table 9-2\. Similarities and differences between model cards and ML-BOMs
  prefs: []
  type: TYPE_NORMAL
- en: '| Feature | Model card | ML-BOM |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Purpose | Document an ML model’s ethical considerations, intended use, and
    performance | List all components used in an ML system to manage and secure the
    application |'
  prefs: []
  type: TYPE_TB
- en: '| Components listed | Model details, performance metrics, and ethical considerations
    | ML models, algorithms, datasets, training pipelines, and frameworks |'
  prefs: []
  type: TYPE_TB
- en: '| Security details | General ethical considerations and use case limitations
    | Detailed security vulnerabilities, dependencies, and versioning |'
  prefs: []
  type: TYPE_TB
- en: '| Usage context | Ethical and responsible AI development | Securing ML applications
    throughout their lifecycle |'
  prefs: []
  type: TYPE_TB
- en: '| Focus on transparency | High, with a focus on ethical transparency | High,
    with a focus on security and compliance |'
  prefs: []
  type: TYPE_TB
- en: '| Legal and compliance | Ethical usage guidelines | Regulatory compliance,
    vulnerability management |'
  prefs: []
  type: TYPE_TB
- en: '| Integration in development lifecycle | Primarily at model evaluation and
    deployment stages | Throughout the entire development and deployment process.
    |'
  prefs: []
  type: TYPE_TB
- en: The Future of LLM Supply Chain Security
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Supply chain security is a mature field for web applications, but is still relatively
    immature for AI and LLM applications. Given all the attention this area has attracted
    recently, I expect we’ll see a lot of innovation and expansion in the near future.
    To prepare you for that, this section will review some of the early movements
    in this area and point you to places to look for future enhancements and innovations
    in LLM supply chain security.
  prefs: []
  type: TYPE_NORMAL
- en: Digital Signing and Watermarking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Establishing robust model authenticity and integrity methods has become critical
    as large language models proliferate. Validating that a model originated from
    the expected source and has not been tampered with is essential for accountability
    and security. Two primary techniques have emerged for this: digital signing and
    watermarking.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Digital signatures* allow the cryptographic signing of a model with a private
    key to mark it as authentic. Any party can then use the corresponding public key
    to verify that the signature matches the model, proving provenance and integrity.
    This technique is important for supply chain security as models are distributed
    or deployed through cloud services. Signing ensures models can be authenticated
    as they move between systems.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Watermarking* embeds identifying information directly in the model’s weights
    or architecture. A watermark inserts a unique fingerprint that indicates the model’s
    origin by subtly altering parameters. Watermarks survive duplication, so cloned
    or stolen models still contain the markup, allowing detection with an extraction
    tool, which confirms that the watermark matches the expected signature for a model.
    Signatures validate origin and prevent tampering via cryptography.'
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Because this technology evolves quickly, consider visiting the [Coalition for
    Content Provenance and Authenticity (C2PA)](https://c2pa.org), a leader in developing
    standards for content authenticity, for the latest resources and standards.
  prefs: []
  type: TYPE_NORMAL
- en: Both digital signing and watermarking should be techniques in your arsenal for
    securing LLMs. Together, these techniques can uniquely authenticate models throughout
    their lifecycle and use. As models grow more powerful, establishing authenticity
    and preventing interference becomes critical. Embedding signatures and watermarked
    fingerprints provides the needed controls for model integrity across supply chains.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Some Google researchers have been promoting a combination of a tool called [Sigstore
    and a management framework called Supply-chain Levels for Software Artifacts (SLSA)](https://oreil.ly/9EX-q)
    to sign and manage ML models. There aren’t many standardized approaches yet, so
    you may want to monitor how this combination evolves.
  prefs: []
  type: TYPE_NORMAL
- en: Vulnerability Classifications and Databases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Vulnerability classifications* refer to categorizing security weaknesses in
    software components based on their characteristics, impact, and exploitability.
    These classifications provide a standardized framework for identifying and describing
    vulnerabilities, facilitating a common understanding among stakeholders. Examples
    include the Common Weakness Enumeration (CWE) for software weaknesses and the
    Common Vulnerability Scoring System (CVSS) for assessing the severity of security
    vulnerabilities.'
  prefs: []
  type: TYPE_NORMAL
- en: Vulnerability databases are essential repositories that gather and document
    identified vulnerabilities within software components. These databases are vital
    for monitoring and referencing known vulnerabilities, furnishing users with in-depth
    information, including descriptions of the vulnerability, its potential impact,
    suggested mitigation strategies, and related references. A notable example of
    such a database is the National Vulnerability Database (NVD), a comprehensive
    catalog of security vulnerabilities. The NVD integrates with the Common Vulnerabilities
    and Exposures (CVE) system, providing each listed vulnerability with a unique
    CVE identifier that facilitates easy reference and cross-linking between databases.
  prefs: []
  type: TYPE_NORMAL
- en: 'Vulnerability classifications and databases are crucial in supply chain security
    for several key reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: Identification and awareness
  prefs: []
  type: TYPE_NORMAL
- en: They provide a systematic way to identify and catalog known vulnerabilities
    in software components. This awareness is the first step in protecting against
    potential exploits.
  prefs: []
  type: TYPE_NORMAL
- en: Standardized communication
  prefs: []
  type: TYPE_NORMAL
- en: Vulnerability classifications offer a standardized language for describing security
    weaknesses, which is essential for clear communication among developers, security
    professionals, and other stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: Risk assessment and prioritization
  prefs: []
  type: TYPE_NORMAL
- en: By classifying vulnerabilities, organizations can assess their potential impact
    and prioritize mitigation efforts accordingly. This helps allocate resources more
    effectively to address the most critical vulnerabilities first.
  prefs: []
  type: TYPE_NORMAL
- en: Tracking and monitoring
  prefs: []
  type: TYPE_NORMAL
- en: Vulnerability databases enable organizations to continuously track new and existing
    vulnerabilities. Regularly monitoring these databases helps organizations stay
    updated with the latest security threats and take proactive measures.
  prefs: []
  type: TYPE_NORMAL
- en: Compliance and reporting
  prefs: []
  type: TYPE_NORMAL
- en: Many regulatory frameworks require organizations to manage known vulnerabilities
    effectively. Access to a comprehensive vulnerability database aids in compliance
    and can be critical for audit and reporting purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Facilitating patch management
  prefs: []
  type: TYPE_NORMAL
- en: By keeping an up-to-date record of vulnerabilities, these databases help in
    the timely patching of software components, which is a critical aspect of maintaining
    secure systems.
  prefs: []
  type: TYPE_NORMAL
- en: Enhancing overall security posture
  prefs: []
  type: TYPE_NORMAL
- en: Regularly referring to vulnerability classifications and databases helps organizations
    develop a more robust security posture by enabling them to anticipate, prepare
    for, and respond to various security threats promptly and effectively.
  prefs: []
  type: TYPE_NORMAL
- en: In the context of supply chain security, where various components and dependencies
    can introduce vulnerabilities, vulnerability classifications and databases are
    invaluable for maintaining the integrity and security of the entire chain.
  prefs: []
  type: TYPE_NORMAL
- en: MITRE CVE
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*MITRE.org* is the online presence of the MITRE Corporation, a not-for-profit
    organization that operates multiple federally funded research and development
    centers in the United States. MITRE’s work primarily supports various US government
    agencies, and its mission is to solve problems for a safer world. It manages the
    CVE program and has developed several key frameworks and models, such as the ATT&CK
    framework, which provides a comprehensive matrix of tactics and techniques used
    by threat actors in cyberattacks.'
  prefs: []
  type: TYPE_NORMAL
- en: The MITRE CVE database is a public online repository of reported security vulnerabilities
    and exposures. It’s a linchpin in cybersecurity, serving as a reference point
    for identifying and classifying vulnerabilities in software and firmware.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a breakdown of CVE’s key features:'
  prefs: []
  type: TYPE_NORMAL
- en: Standardized identifiers
  prefs: []
  type: TYPE_NORMAL
- en: Each entry in the CVE database is uniquely identified by a CVE ID. This standardization
    enables security professionals and software developers to speak the same language
    when discussing security vulnerabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Wide range of sources
  prefs: []
  type: TYPE_NORMAL
- en: The database includes vulnerabilities reported by vendors, researchers, and
    users. This broad source base ensures a comprehensive collection of known issues.
  prefs: []
  type: TYPE_NORMAL
- en: Detailed descriptions
  prefs: []
  type: TYPE_NORMAL
- en: Entries typically include detailed descriptions of the vulnerabilities, providing
    insights into how malicious actors might exploit them, their potential impact,
    and, sometimes, suggested mitigations.
  prefs: []
  type: TYPE_NORMAL
- en: Vulnerability scoring
  prefs: []
  type: TYPE_NORMAL
- en: Many CVE entries include a CVSS score, which gives a quantitative measure of
    the vulnerability’s severity and aids in prioritization for patching or mitigation.
  prefs: []
  type: TYPE_NORMAL
- en: Free and open access
  prefs: []
  type: TYPE_NORMAL
- en: The CVE database is accessible to everyone, promoting transparency and widespread
    vulnerability information sharing. This open approach is crucial for timely and
    effective responses to security threats.
  prefs: []
  type: TYPE_NORMAL
- en: Integration with other tools
  prefs: []
  type: TYPE_NORMAL
- en: The database is often integrated with various security tools and platforms,
    enhancing vulnerability management and threat assessment capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: The MITRE CVE database primarily focuses on software and firmware vulnerabilities,
    emphasizing traditional cybersecurity concerns like network security, application
    security, and operating system flaws. The database includes vulnerabilities in
    various software products and systems, including those you might use in AI or
    LLM applications, like server software, databases, and operating systems.
  prefs: []
  type: TYPE_NORMAL
- en: However, the database wasn’t designed to capture vulnerabilities unique to AI
    systems or LLMs. AI-specific vulnerabilities often require a different approach
    than conventional software vulnerabilities.
  prefs: []
  type: TYPE_NORMAL
- en: MITRE ATLAS
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: MITRE ATLAS (Adversarial Threat Landscape for Artificial Intelligence Systems)
    is an initiative focused on the specific vulnerabilities and threats associated
    with AI systems, particularly in the context of national security. It represents
    a significant step toward understanding and mitigating the unique risks that AI
    technologies pose.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some important aspects of MITRE ATLAS:'
  prefs: []
  type: TYPE_NORMAL
- en: Focus on AI security
  prefs: []
  type: TYPE_NORMAL
- en: Unlike traditional vulnerability databases like CVE, which cover a broad range
    of software and hardware vulnerabilities, ATLAS is dedicated exclusively to AI.
    ATLAS includes threats like adversarial attacks, where intentionally crafted inputs
    manipulate or deceive AI models.
  prefs: []
  type: TYPE_NORMAL
- en: Comprehensive threat modeling
  prefs: []
  type: TYPE_NORMAL
- en: ATLAS provides detailed models of potential adversarial tactics, techniques,
    and procedures (TTPs) specific to AI systems. This threat modeling is crucial
    for understanding how AI systems can be exploited and for developing robust defense
    mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: Collaborative effort
  prefs: []
  type: TYPE_NORMAL
- en: MITRE ATLAS is a collaborative effort involving various stakeholders in the
    AI and cybersecurity communities, including researchers, industry experts, and
    government agencies. This collaboration ensures diverse perspectives and expertise,
    which is vital for tackling complex AI security challenges.
  prefs: []
  type: TYPE_NORMAL
- en: Educational resource
  prefs: []
  type: TYPE_NORMAL
- en: ATLAS is an educational resource for AI and cybersecurity professionals. It
    offers insights into the nature of AI threats and guidance on protecting against
    them. This guidance is valuable for developing training programs and security
    protocols for AI systems.
  prefs: []
  type: TYPE_NORMAL
- en: Guidance for policy and standards
  prefs: []
  type: TYPE_NORMAL
- en: By providing a detailed understanding of AI threats, ATLAS can inform policymaking
    and the development of security standards for AI technologies. This is increasingly
    important as AI becomes more integral to critical infrastructures and national
    security.
  prefs: []
  type: TYPE_NORMAL
- en: As of the writing of this book, there isn’t an authoritative source of AI or
    LLM-specific security incident or vulnerability information, despite several projects
    that have been started. In the coming years, we’ll see organizations like MITRE,
    OWASP, and Hugging Face push forward to create more standard classifications of
    AI and LLM vulnerabilities and allow for the creation or extension of databases
    to track vulnerabilities. The growth of such databases will be critical in maturing
    supply chain security for LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Examples of real exploits of vulnerabilities, such as data poisoning, are far
    more challenging to find than other vulnerabilities like prompt injection. However,
    lessons learned from web software and a growing body of research specific to AI
    and LLMs tell us we must take supply chain security seriously in our LLM applications.
  prefs: []
  type: TYPE_NORMAL
- en: Your models, training data, and even data you access via techniques such as
    RAG may all become part of your software supply chain. You should be careful to
    track each dependency so that you can quickly take action if vulnerabilities are
    discovered in your application’s supply chain. Consider using a standardized format
    such as CycloneDX to do this, as it will allow you to take advantage of the growing
    ecosystem of tooling around that standard.
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, watch developments in this space closely. Supply chain security challenges
    are the least understood but most complex to solve in the LLM vulnerabilities
    I’ve studied. Watch for developments in areas such as watermarking and digital
    signing to track the provenance of your assets. Also watch for how the ecosystem
    around LLM-specific vulnerability and incident tracking evolves, as this will
    give you access to far greater information resources over time.
  prefs: []
  type: TYPE_NORMAL
