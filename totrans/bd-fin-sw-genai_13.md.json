["```py\ndef create_batch_header(setup_info, batch_number):\n…\n    if setup_info[\"standard_entry_class\"] == \"IAT\":\n        batch_header = (\n            f\"5{setup_info['service_class_code']}\"\n            f\"                \"  #1\n            f\"FF\"  #2\n            f\"3\"  #3\n            \"               \"  #4\n            \"US\"  #5\n            f\"{setup_info['company_id']}\"  #6\n            f\"{setup_info[\"standard_entry_class\"]}\"  #7\n            \"GIFT      \"  #8\n            \"USD\"  #9\n            \"USD\"  #10\n            f\"{setup_info.get('effective_entry_date',  #11\n➥today_yymmdd)}\"  \n            f\"{setup_info.get('settlement_date',day_of_year)}\"  #12\n            f\"{setup_info.get('originator_status_code','1')}\"  #13\n            f\"{setup_info.get('odfi','06100001')}\"  #14\n            f\"{setup_info.get('batch_number', batch_number)}\\n\"\n        )\n    else:\n… #15\n    return batch_header\n```", "```py\n  Scenario: Create an ACH for for IAT\n    Given I want to create an ACH file named \"iat.ach\"\n    And I want to have an immediate destination of \"990000013\"\n    And I want to have an immediate origin of \"987654321\"\n    And I want to have 1 batch with ACH credits only\n➥ and a standard entry class code of \"IAT\"\n    And I want 1 entries per batch with random amounts between 100 and 100\n    And I want to use individual names of \"James Smith,\n➥ Sarah Johnson, David Williams, Emma Martinez, Olivia Thomas\"\n    And I want to have company name \"My Company\"\n➥ and company id \"1234567890\"\n    When my ACH is created\n    Then I should have a file of the same name\n    And there should be 1 batch in the file\n    And there should be 1 entries in the file\n```", "```py\nCREATE TABLE ach_iat_batch_headers\n(\n    ach_records_type_5_id          UUID UNIQUE NOT NULL #1\n         REFERENCES ach_records_type_5 (ach_records_type_5_id)  #2\n                                             ON DELETE CASCADE   #2\n                                             ON UPDATE CASCADE, \n    record_type_code               VARCHAR(1)  NOT NULL, #2\n    service_class_code             VARCHAR(3)  NOT NULL, \n    iat_indicator                  VARCHAR(16) NOT NULL, \n    foreign_exchange_indicator     VARCHAR(2)  NOT NULL, #3\n    foreign_exchange_ref_indicator VARCHAR(1)  NOT NULL, \n    foreign_exchange_reference     VARCHAR(15) NOT NULL, \n    iso_destination_country_code   VARCHAR(2)  NOT NULL, \n    originator_id                  VARCHAR(10) NOT NULL, \n    standard_entry_class_code      VARCHAR(3)  NOT NULL, \n    company_entry_description      VARCHAR(10) NOT NULL, \n    iso_originating_currency_code  VARCHAR(3)  NOT NULL, \n    iso_destination_currency_code  VARCHAR(3)  NOT NULL, \n    effective_entry_date           VARCHAR(6)  NOT NULL, \n    settlement_date                VARCHAR(3)  NOT NULL, \n    originator_status_code         VARCHAR(1)  NOT NULL, \n    originating_dfi_identification VARCHAR(8)  NOT NULL, \n    batch_number                   NUMERIC(7)  NOT NULL \n);\n```", "```py\nCREATE TABLE ach_iat_addenda_712_records\n(\n    ach_records_type_7_id        UUID UNIQUE NOT NULL \n            REFERENCES ach_records_type_7 (ach_records_type_7_id) \n            ON DELETE CASCADE ON UPDATE CASCADE,\n    record_type_code             VARCHAR(1)  NOT NULL,\n    addenda_type_code            NUMERIC(2)  NOT NULL DEFAULT 12, #1\n    originator_city              VARCHAR(35), #2\n    originator_state             VARCHAR(35),  #3\n    originator_country           VARCHAR(35),  #3\n    originator_postal_code       VARCHAR(35), \n    entry_detail_sequence_number NUMERIC(7)  NOT NULL\n);\n```", "```py\nclass TestParsingIat712AddendaRecords:\n\n    TABLE_NAME: str = \"ach_iat_addenda_712_records\"\n\n    @pytest.fixture(autouse=True)   #1\n    def setup_teardown_method(self):  #1\n        SqlUtils.truncate_all()  #1\n        yield  #1\n\n    def test_parse_iat_addenda_712_records(self):\n        sample_addenda_record = \"712BILBAO*BIZKAIA\\ #2\n➥                    ES*48001\\                        #2\n➥                  0000001\" \n\nrecord\n        expected_result = { #3\n            \"record_type_code\": Literal[\"7\"],  #3\n            \"addenda_type_code\": 12,  #3\n            \"originator_city\": \"BILBAO\",  #3\n            \"originator_state\": \"BIZKAIA\",  #3\n            \"originator_country\": \"ES\",  #3\n            \"originator_postal_code\": \"48001\",  #3\n            \"entry_detail_sequence_number\": 1,  #3\n        }  #3\n\n        _, ach_records_type_7_id = #4\n            SqlUtils.setup_iat_addenda_test(  #4\n               sample_addenda_record  #4\n            )  #4\n\n        parser = AchFileProcessor() #5\n        parser._parse_iat_addenda_712(ach_records_type_7_id,  #5\n                                      sample_addenda_record) \n\n        sql = AchIat712AddendaSql() #6\n        retrieved_record =  #7\n           sql.get_record(ach_records_type_7_id).model_dump(  #7\n               exclude={\"ach_records_type_7_id\"}  #7\n           )  #7\n\n        assert SqlUtils.get_row_count_of_1( #7\n            self.TABLE_NAME  #7\n        ), f\"Expected 1 row in {self.TABLE_NAME}\"  #7\n        assert (  #7\n            retrieved_record == expected_result  #7\n        ), f\"Expected {expected_result}, #7\n➥ but got {retrieved_record}\"  #7\n```", "```py\ndef _parse_iat_addenda_712(self, ach_records_type_7_id: UUID, line: str):\n     self.expected_record_types = [\"6\", \"7\", \"8\"] #1\n\n     ach_iat_addenda_record = #2\n        AchRecordProcessor().parse_iat_addenda_712(  #3\n           ach_records_type_7_id, line  #3\n        ) \n        AchIat712AddendaSql()#3\n           .insert_record(ach_iat_addenda_record) \n```", "```py\ndef parse_iat_addenda_712(\n        self, ach_records_type_7_id, line\n    ) -> AchIat712AddendaSchema:\n   regex = r\"([^*]+)\\*([^\\\\]+)\\\\\" #1\n   match = re.match(regex, line[3:38]) #2\n   if not match:  #2\n      raise ValueError(\"Error parsing originator  #2\n➥ city and state\")  #2\n   originator_city, originator_state = match.groups()  #2\n\n   match = re.match(regex, line[38:73]) #3\n   if not match:  #3\n      raise ValueError(\"Error parsing originator country   #3\n                                and postal code\")  #3\n   originator_country, originator_postal_code = match.groups()  #3\n\n   return AchIat712AddendaSchema( #4\n      ach_records_type_7_id=ach_records_type_7_id,  #4\n      record_type_code=line[0],  #4\n      addenda_type_code=line[1:3],  #4\n      originator_city=originator_city.strip(),  #4\n      originator_state=originator_state.strip(),  #4\n      originator_country=originator_country.strip(),  #4\n      originator_postal_code=originator_postal_code.strip(),  #4\n      entry_detail_sequence_number=line[87:94],  #4\n   )  #4\n```", "```py\nclass AchIat712AddendaSchema(BaseModel):\n    ach_records_type_7_id: UUID\n    record_type_code: str = Literal[\"7\"]\n    addenda_type_code: int = Literal[12]\n    originator_city: str = Field(..., max_length=35)\n    originator_state: str = Field(..., max_length=35)\n    originator_country: str = Field(..., max_length=35)\n    originator_postal_code: str = Field(..., max_length=35)\n    entry_detail_sequence_number: int = Field(..., ge=0)\n```", "```py\nclass AchIat712AddendaSql: #1\n #2\n    def insert_record(self,  #2\n                      ach_iat_addenda: AchIat712AddendaSchema): \n        with get_db_connection() as conn: #2\n            conn.execute(                 #3\n                \"\"\"  #3\n                   INSERT INTO ach_iat_addenda_712_records (  #3\n                            ach_records_type_7_id, addenda_type_code,  #3\n                            originator_city, originator_state,  #3\n                            originator_country, originator_postal_code,  #3\n                            entry_detail_sequence_number )  #3\n                        VALUES ( %(ach_records_type_7_id)s,  #3\n      %(addenda_type_code)s, %(originator_city)s,  #3\n      %(originator_state)s,  #3\n      %(originator_country)s, %(originator_postal_code)s,   #3\n      %(entry_detail_sequence_number)s)  #3\n                \"\"\",  #3\n                ach_iat_addenda.model_dump(), #4\n            )\n… #5\n```", "```py\ndef test_good_unparsed_records_only(self, parser):\n    filename = \"ppd-mixed.ach\"  #1\n    dir_path = os.path.dirname(os.path.realpath(__file__)) #2\n    file_path = os.path.join(dir_path, \"data\", filename) \n\n    expected_exceptions_result: int = 0 #3\n    expected_total_records_result: int = 14 \n\n    ach_file_id = SqlUtils. #4\n➥create_ach_file_record(filename, \"123456789\")  #4\n #4\n    parser.parse(ach_file_id, file_path)  #4\n    exceptions = SqlUtils.get_exceptions()  #4\n\n    with SqlUtils.get_db() as conn:   #5\n        record_count_type1 = conn.execute(  #5\n            \"SELECT COUNT(*) FROM ach_records_type_1\"  #5\n        ).fetchone()[0]  #5\n…                     #5\n        record_count_type9 = conn.execute(  #5\n            \"SELECT COUNT(*) FROM ach_records_type_9\"  #5\n        ).fetchone()[0]  #5\n\n        total_record_count = ( #6\n            record_count_type1  #6\n            + record_count_type5  #6\n            + record_count_type6  #6\n            + record_count_type7  #6\n            + record_count_type8  #6\n            + record_count_type9  #6\n        )  #6\n\n        assert record_count_type1 == 1, #7\n                f\"Expected 1, but got {record_count_type1}\"  #7\n…  #7\n        assert (  #7\n            total_record_count == expected_total_records_result  #7\n        ), f\"Expected {expected_total_records_result}, but got  #7\n{total_record_count}\"  #7\n…  #7\n```", "```py\nwith SqlUtils.get_db(row_factory=dict_row) as conn: #1\n    record_counts = conn.execute(\n    \"\"\"\n    SELECT \n        record_count_type1, #2\n        record_count_type5,  #2\n        record_count_type6,  #2\n        record_count_type7,  #2\n        record_count_type8,  #2\n        record_count_type9,  #2\n        record_count_type1 + record_count_type5 +  #3\n        record_count_type6 + record_count_type7 +   #3\n        record_count_type8 + record_count_type9   #3\n                             AStotal_record_count  #3\n    FROM ( #4\n     SELECT \n       (SELECT COUNT(*) FROM ach_records_type_1)  \n                          AS record_count_type1, \n       (SELECT COUNT(*) FROM ach_records_type_5)  \n                          AS record_count_type5, #5\n       (SELECT COUNT(*) FROM ach_records_type_6)  \n                          AS record_count_type6, \n       (SELECT COUNT(*) FROM ach_records_type_7)  \n                          AS record_count_type7, \n       (SELECT COUNT(*) FROM ach_records_type_8)  \n                          AS record_count_type8, \n       (SELECT COUNT(*) FROM ach_records_type_9)  \nAS record_count_type9 \n        ) AS counts \n   \"\"\"\n   ).fetchone() #6\n   record_counts[\"exception_count\"] = len(exceptions) #7\n\nassert expected_results == record_counts #8\n```", "```py\nSELECT \n   record_count_type1, #1\n   record_count_type5,  #1\n   record_count_type6,  #1\n   record_count_type7,  #1\n   record_count_type8,  #1\n   record_count_type9,  #1\n   record_count_type1 + record_count_type5 +   #1\n   record_count_type6 + record_count_type7 +  #1\n   record_count_type8 + record_count_type9   #1\n                                         AS total_record_count  #1\nFROM (\n   SELECT #2\n      (SELECT COUNT(*) FROM ach_file_headers)  #2\n                            AS record_count_type1,  #2\n      (SELECT COUNT(*) FROM ach_batch_headers)  #2\n                            AS record_count_type5,  #2\n      (SELECT COUNT(*) FROM ach_entry_ppd_details)  #2\n                                      AS record_count_type6,  #2\n      (SELECT COUNT(*) FROM ach_addenda_ppd_records)  #2\n                                      AS record_count_type7,  #2\n      (SELECT COUNT(*) FROM ach_batch_control_records)  #2\n                                      AS record_count_type8,  #2\n      (SELECT COUNT(*) FROM ach_file_control_records)  #2\n                                      AS record_count_type9  #2\n   ) AS counts   #2\n```", "```py\nSELECT #1\n   record_count_type1, record_count_type5, record_count_type6,  #1\n   record_count_type710, record_count_type711,  #1\n   record_count_type712, record_count_type713,  #1\n   record_count_type714, record_count_type715,   #1\n   record_count_type716, record_count_type8,  #1\n   record_count_type9, record_count_type1 +  #1\n   record_count_type5 + record_count_type6 +  #1\n   record_count_type710 + record_count_type711 +  #1\n   record_count_type712 + record_count_type713 +  #1\n   record_count_type714 + record_count_type715 +  #1\n   record_count_type716 + record_count_type8 +   #1\n                  record_count_type9 AS total_record_count  #1\nFROM ( #2\n   SELECT  #2\n      (SELECT COUNT(*) FROM ach_file_headers)  #2\n                                     AS record_count_type1,  #2\n      (SELECT COUNT(*) FROM ach_iat_batch_headers)  #2\n                                     AS record_count_type5,  #2\n      (SELECT COUNT(*) FROM ach_iat_entry_details)  #2\n                                     AS record_count_type6,  #2\n      (SELECT COUNT(*) FROM ach_iat_addenda_710_records)  #2\n                                     AS record_count_type710,  #2\n      (SELECT COUNT(*) FROM ach_iat_addenda_711_records)  #2\n                                     AS record_count_type711,  #2\n      (SELECT COUNT(*) FROM ach_iat_addenda_712_records)  #2\n                                     AS record_count_type712,  #2\n      (SELECT COUNT(*) FROM ach_iat_addenda_713_records)  #2\n                                     AS record_count_type713,  #2\n      (SELECT COUNT(*) FROM ach_iat_addenda_714_records)  #2\n                                     AS record_count_type714,  #2\n      (SELECT COUNT(*) FROM ach_iat_addenda_715_records)  #2\n                                     AS record_count_type715,  #2\n      (SELECT COUNT(*) FROM ach_iat_addenda_716_records)  #2\n                                     AS record_count_type716,  #2\n      (SELECT COUNT(*) FROM ach_batch_control_records)  #2\n                                     AS record_count_type8,  #2\n      (SELECT COUNT(*) FROM ach_file_control_records)  #2\n                                     AS record_count_type9  #2\n) AS record_counts  #2\n```", "```py\nif line[50:53] == \"IAT\": #1\n self._parse_iat_batch_header(ach_record_id, line) #2\n self.batch_type = \"IAT\" \nelif line[50:53] == \"PPD\": #2\n    self._parse_batch_header(ach_record_id, line)  #3\n self.batch_type = \"PPD\" #3\nelse: #3\n self._add_exception( #4\n AchExceptionSchema( #4\n ach_files_id=ach_file_id, #4\n record_number=sequence_number, #4\n exception_code=AchExceptions.INVALID_BATCH_TYPE.value, #4\n ), #4\n line, #4\n ) #4\n```", "```py\ncase \"6\": #1\n    ach_record = AchRecordType6Schema(  #1\n        ach_records_type_5_id=current_batch_header_id,  #1\n        unparsed_record=line,  #1\n        sequence_number=sequence_number,  #1\n    )  #1\n    ach_record_id = AchRecordsSqlType6()  #1\n➥.insert_record(ach_record)  #1\n    if self.batch_type == \"IAT\": #2\n        self._parse_iat_entry_detail(  #2\n            ach_file_id=ach_file_id,  #2\n            current_batch_header_id=current_batch_header_id,  #2\n            ach_records_type_6_id=ach_record_id,  #2\n            sequence_number=sequence_number,  #2\n            line=line,  #2\n        )  #2\n    elif self.batch_type == \"PPD\": #3\n        self._parse_entry_ppd_detail(  #3\n            ach_file_id=ach_file_id,  #3\n            current_batch_header_id=current_batch_header_id,  #3\n            ach_records_type_6_id=ach_record_id,  #3\n            sequence_number=sequence_number,  #3\n            line=line,  #3\n        )  #3\n    else: #4\n        self._add_exception( #4\n            AchExceptionSchema( #4\n                ach_files_id=ach_file_id,  #4\n                record_number=sequence_number,  #4\n                exception_code=AchExceptions.INVALID_SEC.value,  #4\n            ),  #4\n            line,  #4\n        )  #4\n```", "```py\ndef _parse_iat_addenda_710(self, ach_records_type_7_id: UUID, line: str):\n     self.expected_record_types = [\"7\"] #1\n     self.expected_addenda_type = \"11\" #2\n\n     ach_iat_addenda_record = AchRecordProcessor().parse_iat_addenda_710(\n         ach_records_type_7_id, line\n     )\n     AchIat710AddendaSql().insert_record(ach_iat_addenda_record)\n```", "```py\nself.expected_record_types = [\"6\", \"7\", \"8\"] #1\nself.expected_addenda_type = \"\" #2\n```", "```py\n   def _parse_iat_addenda( #1\n        self, ach_records_type_7_id: UUID,  #1\n        line: str, sequence_number  #1\n    ): \n        addenda_type = line[1:3] #2\n\n        if addenda_type != self.expected_addenda_type: #3\n            self._add_exception( \n                AchExceptionSchema( \n                    ach_files_id=ach_records_type_7_id, \n                    record_number=sequence_number, \n                    exception_code= \n                       AchExceptions.UNEXPECTED_ADDENDA_TYPE.value, \n                ) \n            ) \n            Return \n\n        if addenda_type == \"10\": #4\n            self._parse_iat_addenda_710(ach_records_type_7_id, line)  #5\n…  #5\n        elif addenda_type == \"16\":  #5\n            self._parse_iat_addenda_716(ach_records_type_7_id, line)  #5\n        else:  #5\n            self._add_exception(  #5\n                AchExceptionSchema(  #5\n                    ach_files_id=ach_records_type_7_id,  #5\n                    record_number=sequence_number,  #5\n                    exception_code=  #5\n                        AchExceptions.INVALID_IAT_ADDENDA_TYPE.value,  #5\n                )  #5\n            )  #5\n```", "```py\nSELECT COALESCE(abh.company_name, '') AS company_name, #1\n       COALESCE(abh.company_identification,       #2\n       aibh.originating_dfi_identification) AS company_id,\n       art5.ach_records_type_5_id AS id,\n       COALESCE(abh.batch_number, aibh.batch_number) #3\n                                           AS batch_number, \n       abcd.total_debit_entry_dollar_amount AS debit_total,\n       abcd.total_credit_entry_dollar_amount AS credit_total, \n       abcd.entry_addenda_count \n  FROM ach_files AS af\n…\nLEFT JOIN ach_batch_headers AS abh #4\n                USING (ach_records_type_5_id)  #4\nLEFT JOIN ach_iat_batch_headers AS aibh  #4\n                USING (ach_records_type_5_id)  #4\n    WHERE af.ach_files_id = %s\n ORDER BY COALESCE(abh.originating_dfi_identification,  #5\n                   aibh.originating_dfi_identification); \n```", "```py\n@staticmethod\ndef get_entries(\n    ach_file_id: UUID, ach_batch_id: UUID\n    ) -> list[AchBatchEntriesResponse]:\n    if AchFileSql._is_iat_batch(ach_file_id, ach_batch_id): #1\n        return AchFileSql._get_iat_entries #2\n➥(ach_file_id, ach_batch_id) \n    else:\n        return AchFileSql._get_ppd_entries(ach_file_id, #3\n                                           ach_batch_id) \n```", "```py\nWITH addenda_records_for_entry AS (\n   SELECT art6.ach_records_type_6_id,\n   COUNT(art7.*) AS addenda_count #1\n   FROM ach_files AS af\n…\n   LEFT JOIN ach_records_type_7 AS art7 USING (ach_records_type_6_id)\n   WHERE af.ach_files_id = %s\n      AND art5.ach_records_type_5_id = %s\n      GROUP BY (art6.ach_records_type_6_id)\n)\nSELECT art6.ach_records_type_6_id AS id,\n       aied.transaction_code,\n…\n       aia10d.receiving_name AS individual_name, #2\n       aied.amount, #3\n       CONCAT(\n          '*************',\n          RIGHT(LPAD#D\n➥(aied.foreign_receivers_account_number, 4, '0'), 4) #4\n       ) AS account_number_last_4,\n       arfe.addenda_count\n…\n      INNER JOIN ach_iat_entry_details AS aied  #5\n                  USING (ach_records_type_6_id)  #5\n      INNER JOIN addenda_records_for_entry AS arfe  #5\n                  USING (ach_records_type_6_id)  #5\n      INNER JOIN ach_iat_addenda_10_details AS aia10d   #5\n                  USING (ach_records_type_7_id)  #5\n…\n```", "```py\nCREATE TABLE sdn_list\n(\n    sdn_id          UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    first_name      VARCHAR(255) NOT NULL,\n    middle_name     VARCHAR(255) DEFAULT NULL,\n    last_name       VARCHAR(255) NOT NULL,\n    alias           VARCHAR(255) DEFAULT NULL,\n    created_at      TIMESTAMP    NOT NULL DEFAULT NOW(),\n    updated_at      TIMESTAMP    NOT NULL DEFAULT NOW()\n);\n\nCREATE TABLE sanctioned_countries\n(\n    sanctioned_country_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),\n    country_name          VARCHAR(255) NOT NULL,\n    country_code          VARCHAR(2)   NOT NULL,\n    created_at            TIMESTAMP    NOT NULL DEFAULT NOW(),\n    updated_at            TIMESTAMP    NOT NULL DEFAULT NOW()\n);\n```", "```py\nINSERT INTO \nsdn_list(first_name, middle_name, last_name, alias) \nVALUES ('Cash', DEFAULT, 'Steeler', 'Heister');\nINSERT INTO \nsdn_list(first_name, middle_name, last_name, alias) \nVALUES ('Penny', DEFAULT, 'Pincher', 'Embezzler');\nINSERT INTO \nsdn_list(first_name, middle_name, last_name, alias) \nVALUES ('Ben', 'E', 'Factor', '');\nINSERT INTO \nsdn_list(first_name, middle_name, last_name, alias) \nVALUES ('Lou', DEFAULT, 'Pole', 'Evader');\nINSERT INTO \nsdn_list(first_name, middle_name, last_name, alias) \nVALUES ('Mallory', DEFAULT, 'Practice', 'Biller');\n\nINSERT INTO \nsanctioned_countries(country_name, country_code) \nVALUES ('Bribeland', 'BL');\nINSERT INTO \nsanctioned_countries(country_name, country_code) \nVALUES ('Scamistan', 'SC');\nINSERT INTO \nsanctioned_countries(country_name, country_code) \nVALUES ('Embezzlvania', 'EV');\nINSERT INTO \nsanctioned_countries(country_name, country_code) \nVALUES ('Swindleland', 'SW');\nINSERT INTO \nsanctioned_countries(country_name, country_code) \nVALUES ('Greedonia', 'GD');\n```", "```py\nCREATE EXTENSION IF NOT EXISTS \"fuzzystrmatch\";\n```", "```py\nWITH ach_ppd_collected_names AS (\n    SELECT DISTINCT aped.individual_name, #1\n           REPLACE(aped.individual_name, ' ', '')  #2\n                            AS cleaned_individual_name, \n                    art1.ach_files_id, #3\n                    art5.ach_records_type_5_id \n    FROM ach_files #4\n    INNER JOIN ach_records_type_1 AS art1 \n                     USING (ach_files_id) \n    INNER JOIN ach_records_type_5 AS art5  \n                                 USING (ach_records_type_1_id) \n    INNER JOIN ach_records_type_6 AS art6  \n                                 USING (ach_records_type_5_id) \n    INNER JOIN ach_ppd_entry_details AS aped  \n                                 USING (ach_records_type_6_id) \n    GROUP BY art1.ach_files_id, art5.ach_records_type_5_id, #5\n                      individual_name, cleaned_individual_name \n),\n```", "```py\nach_iat_collected_names AS (\n    SELECT DISTINCT aia10d.receiving_name #1\n                                        AS individual_name, \n                    REPLACE(aia10d.receiving_name, ' ', '') #2\n                           AS cleaned_individual_name, \n                    art1.ach_files_id, #3\n                    art5.ach_records_type_5_id \n    FROM ach_files #4\n    INNER JOIN ach_records_type_1 AS art1  #4\n               USING (ach_files_id)  #4\n    INNER JOIN ach_records_type_5 AS art5  #4\n               USING (ach_records_type_1_id)  #4\n    INNER JOIN ach_records_type_6 AS art6  #4\n               USING (ach_records_type_5_id)  #4\n    INNER JOIN ach_records_type_7 AS art7  #4\n               USING (ach_records_type_6_id)  #4\n    INNER JOIN ach_iat_addenda_10_details AS aia10d   #4\n                                          USING (ach_records_type_7_id)  #4\n    GROUP BY art1.ach_files_id, art5.ach_records_type_5_id, #5\n             individual_name, cleaned_individual_name \n)\n```", "```py\nsdn_names AS (\n    SELECT\n        CONCAT_WS(' ', first_name, middle_name, last_name) #1\n                                              AS sdn_name  \n        REPLACE(\n           CONCAT(first_name, middle_name, last_name), ' ', '')  #2\n                                               AS cleaned_sdn_name, \n        alias, #3\n        REPLACE(alias, ' ', '') as cleaned_sdn_alias \n    FROM sdn_list\n)\n```", "```py\ncomputed_similarity_iat AS (\n    SELECT\n        ach_files_id, \n        ach_records_type_5_id AS ach_batch_id, \n        sdn.sdn_name,\n        aicn.individual_name,\n        alias,\n        (1 - (LEVENSHTEIN(cleaned_individual_name, #1\nsdn.cleaned_sdn_name)::FLOAT  #1\n/ GREATEST(LENGTH(cleaned_individual_name),  #1\nLENGTH(sdn.cleaned_sdn_name)))) * 100  #1\nAS similarity_score,  #1\n        CASE #2\n           WHEN DAITCH_MOKOTOFF(cleaned_individual_name) &&  \n               DAITCH_MOKOTOFF(sdn.cleaned_sdn_name) THEN TRUE \n           ELSE FALSE \n        END AS daitch_mokotoff_match_name,\n        CASE\n           WHEN daitch_mokotoff(cleaned_individual_name) &&\n               DAITCH_MOKOTOFF (sdn.cleaned_sdn_alias) THEN TRUE\n           ELSE FALSE\n        END AS daitch_mokotoff_match_alias\n    FROM ach_iat_collected_names aicn\n    CROSS JOIN sdn_names sdn #3\n```", "```py\ncomputed_similarity AS (\n    SELECT * FROM computed_similarity_ppd #1\n    UNION ALL              #1\n    SELECT * FROM computed_similarity_iat  #1\n)\n```", "```py\nSELECT ROW_NUMBER() #1\n   OVER (ORDER BY ach_files_id, ach_batch_id) AS id, *  #1\nFROM computed_similarity  #1\nWHERE similarity_score >= 80 #2\n   OR daitch_mokotoff_match_name = TRUE  #3\n    OR daitch_mokotoff_match_alias = TRUE  #3\nORDER BY similarity_score DESC\n```", "```py\nclass TestOfacApi:\n    client: TestClient = TestClient(app)\n    ach_files_id: Optional[str] = None\n\n    # Get the directory of our file\n    current_file_dir = Path(__file__).resolve().parent\n\n    @pytest.fixture(autouse=True) #1\n    def mock_client_host(self):  #1\n        with patch(  #1\n            \"fastapi.Request.client\",  #1\n            new_callable=lambda: type(\"Client\", (),  #1\n                             {\"host\": \"127.0.0.1\"}),  #1\n        ):  #1\n            Yield  #1\n\n    def get_absolute_path(self, relative_path): #2\n        return self.current_file_dir / relative_path \n\n    def setup_method(self, _method: Callable) -> None: #3\n        ach_file = \"ofac_elemental_resources.ach\"  #3\n        absolute_path = self.get_absolute_path(  #3\n            Path(\"../data/ofac_elemental_resources.ach\")  #3\n        )  #3\n        SqlUtils.truncate_all()  #3\n        self.ach_files_id = SqlUtils.create_ach_file_record(  #3\n            ach_file, str(randint(1, 99999999))  #3\n        )  #3\n        AchFileProcessor().parse  #3\n➥(self.ach_files_id, absolute_path)  #3\n\n    def test_get_ofac_api_for_ppd_batches(self): #4\n        response = self.client.get(\"/api/v1/files/ofac\")  #5\n assert response.status_code == 200, response.text #5\n  assert len(response.json()) == 3,  #5\n➥ \"Should have 3 matches\"  #5\n```", "```py\n@router.get( #1\n    path=\"/ofac\",  #1\n)  #1\n@log_message(\"Performed OFAC Scan on loaded ACH files\") \nasync def read_files(request: Request): #2\n    return [] \n```", "```py\n@router.get( #1\n    path=\"/ofac\",  #1\n    response_model=list[OfacScanResults],  #1\n    summary=\"Scan for OFAC issues in loaded ACH Files\",  #1\n    description=  #1\n➥\"Perform an OFAC scan and return the results\",  #1\n    response_description=\"Results of OFAC scan.\",  #1\n    tags=[\"OFAC\"],  #1\n)  #1\n@log_message(\"Performed OFAC Scan on loaded ACH files\")  #1\nasync def read_files(request: Request) #2\n➥ -> list[OfacScanResults]:  #2\n    return OfacSql().get_scan_results() \n```", "```py\nclass OfacScanResults(BaseModel):\n    id: int = Field(title=\"ID\", description=\"The ID of the result\")\n    ach_files_id: UUID4 = Field(title=\"ACH Files ID\",   #1\n                           description=\"The ACH Files ID\")  #2\n    ach_batch_id: UUID4 = Field(title=\"ACH Batch ID\",   #2\n                           description=\"The ACH Batch ID\") \n    sdn_name: str = Field(title=\"SDN Name\",  #2\n➥ description=\"The SDN Name\")  #2\n    individual_name: str = Field(  #2\n        title=\"Individual Name\",   #2\n➥description=\"The Individual Name\"  #2\n    )  #2\n    alias: str = Field(title=\"Alias\",   #2\n                      description=\"The Alias from the SDN List\")  #2\n    similarity_score: Decimal = Field( #3\n        title=\"Similarity Score\",   #4\n                      description=\"The Similarity Score\"  #4\n    ) #C\n    daitch_mokotoff_match_name: bool = Field(  #4\n        title=\"Daitch Mokotoff Match Name\",   #4\n        description=\"Daitch Mokotoff Match Name\"  #4\n    )  #4\n    daitch_mokotoff_match_alias: bool = Field(  #4\n        title=\"Daitch Mokotoff Match Alias\",   #4\n        description=\"Daitch Mokotoff Match Alias\"  #4\n    )  #4\n```", "```py\nclass OfacSql:\n    def get_scan_results(self) -> list[OfacScanResults]:\n        with get_db_connection(row_factory=class_row(OfacScanResults)) \n                                                               as conn:\n            result = conn.execute(\n                \"\"\"\n…   #1\n                \"\"\",\n                [],\n            ).fetchall()#2\n\n        return result #3\n```", "```py\nexport default function OfacPage() {\n\n    const [entries, setEntries] = useState<OfacResponse[]>([]);\n\n    useEffect(() => {\n        const apiUrl = process.env.NEXT_PUBLIC_API_URL ?? ''; #1\n        axios.get<OfacResponse[]>(`${apiUrl}/files/ofac`, {  #1\n            headers: {  #1\n                'Content-Type': 'application/json'  #1\n            }  #1\n        }) #1\n            .then(response => {  #1\n                setEntries(response.data);  #1\n            })  #1\n…\n    return ( #2\n…  #2\n                    <OfacRecords records={entries}/>  #2\n…  #2\n    );  #2\n```", "```py\nexport interface OfacResponse {\n id: number;\n ach_files_id: string;\n ach_batch_id: string;\n sdn_name: string;\n individual_name: string;\n alias: string | null;\n similarity_score: number;\n daitch_mokotoff_match_name: boolean;\n daitch_mokotoff_match_alias: boolean;\n}\n```", "```py\ninterface OfacRecordsProps {\n    records: OfacResponse[];\n}\n\nexport default function OfacRecords({records}: \n➥Readonly<OfacRecordsProps>) {\n\n    const columns: GridColDef[] = [\n        {\n            field: 'ach_files_id', #1\n            headerName: '',  #1\n            width: 100,  #1\n            renderCell: (params) => (  #1\n                <Link href={`/fileDetails/${params.value}`}   #1\n                      color=\"inherit\">  #1\n                    View File  #1\n                </Link>  #1\n            ),\n        },\n        {\n            field: 'ach_batch_id', #2\n            headerName: '',  #2\n            width: 100,  #2\n            renderCell: (params) => (  #2\n                <Link   #2\nhref={`/fileDetails  #2\n       /${params.row.ach_files_id}/batchDetails  #2\n       /${params.value}`}   #2\n                      color=\"inherit\">  #2\n                    View batch  #2\n                </Link>  #2\n            ), \n        },\n…\n        {field: 'similarity_score',  #3\n                   headerName: 'Score', width: 75,   #4\n                   renderCell: (params) => (  #4\n                <Typography>{Math.floor(params.value)}</Typography>  #4\n            )},  #4\n        {\n            field: 'daitch_mokotoff_match_name', #4\n            headerName: 'Name Match', \n            width: 100, \n            renderCell: (params) => ( #5\n… \n                   {params.value ?  \n                       <CheckCircle sx={{color: \"green\"}}/> : null} \n… \n        },\n        {\n            field: 'daitch_mokotoff_match_alias', #6\n            headerName: 'Alias Match',  #6\n width: 100, #6\n renderCell: (params) => ( #6\n…  #6\n {params.value ? #6\n <CheckCircle sx={{color: \"green\"}}/> : null} #6\n…  #6\n },\n ];\n…\n <DataGrid columns={columns} rows={records}/> #7\n…\n```"]