- en: Chapter 1\. Introduction to Building AI Applications with Foundation Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章\. 基础模型构建人工智能应用的介绍
- en: If I could use only one word to describe AI post-2020, it’d be *scale*. The
    AI models behind applications like ChatGPT, Google’s Gemini, and Midjourney are
    at such a scale that they’re consuming [a nontrivial portion](https://oreil.ly/J0IyO)
    of the world’s electricity, and we’re at risk of [running out of publicly available
    internet data](https://arxiv.org/abs/2211.04325) to train them.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我可以用一个词来描述2020年后的AI，那将是*规模*。ChatGPT、谷歌的Gemini和Midjourney等应用背后的AI模型规模如此之大，以至于它们正在消耗世界上相当一部分的电力，我们面临[用尽公开可用的互联网数据](https://arxiv.org/abs/2211.04325)来训练它们的危险。
- en: The scaling up of AI models has two major consequences. First, AI models are
    becoming more powerful and capable of more tasks, enabling more applications.
    More people and teams leverage AI to increase productivity, create economic value,
    and improve quality of life.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: AI模型规模的扩大有两个主要后果。首先，AI模型变得更加强大，能够执行更多任务，从而启用更多应用。更多的人和团队利用AI来提高生产力、创造经济价值，并改善生活质量。
- en: 'Second, training large language models (LLMs) requires data, compute resources,
    and specialized talent that only a few organizations can afford. This has led
    to the emergence of *model as a service*: models developed by these few organizations
    are made available for others to use as a service. Anyone who wishes to leverage
    AI to build applications can now use these models to do so without having to invest
    up front in building a model.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，训练大型语言模型（LLMs）需要数据、计算资源和专门人才，只有少数组织能够负担得起。这导致了*模型即服务*的出现：这些少数组织开发的模型现在可供其他人作为服务使用。任何希望利用AI来构建应用的人现在都可以使用这些模型来这样做，而无需在构建模型上预先进行投资。
- en: In short, the demand for AI applications has increased while the barrier to
    entry for building AI applications has decreased. This has turned *AI engineering*—the
    process of building applications on top of readily available models—into one of
    the fastest-growing engineering disciplines.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，对AI应用的需求增加了，而构建AI应用的门槛降低了。这使得*AI工程*——在现成模型上构建应用的过程——成为增长最快的工程学科之一。
- en: Building applications on top of machine learning (ML) models isn’t new. Long
    before LLMs became prominent, AI was already powering many applications, including
    product recommendations, fraud detection, and churn prediction. While many principles
    of productionizing AI applications remain the same, the new generation of large-scale,
    readily available models brings about new possibilities and new challenges, which
    are the focus of this book.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习（ML）模型上构建应用并不是什么新鲜事。在LLM变得突出之前很久，AI就已经在推动许多应用，包括产品推荐、欺诈检测和流失预测。尽管许多将AI应用投入生产的原理保持不变，但新一代的大规模、现成模型带来了新的可能性和新的挑战，这正是本书的重点。
- en: This chapter begins with an overview of foundation models, the key catalyst
    behind the explosion of AI engineering. I’ll then discuss a range of successful
    AI use cases, each illustrating what AI is good and not yet good at. As AI’s capabilities
    expand daily, predicting its future possibilities becomes increasingly challenging.
    However, existing application patterns can help uncover opportunities today and
    offer clues about how AI may continue to be used in the future.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章首先概述了基础模型，这是AI工程爆炸式增长的关键催化剂。然后，我将讨论一系列成功的AI应用案例，每个案例都说明了AI擅长什么以及还不擅长什么。随着AI能力的每日扩展，预测其未来的可能性变得越来越具有挑战性。然而，现有的应用模式可以帮助揭示今天的机遇，并为我们提供关于AI未来可能如何继续被使用的线索。
- en: To close out the chapter, I’ll provide an overview of the new AI stack, including
    what has changed with foundation models, what remains the same, and how the role
    of an AI engineer today differs from that of a traditional ML engineer.^([1](ch01.html#id534))
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 为了结束这一章，我将提供一个关于新人工智能堆栈的概述，包括基础模型的变化、保持不变的内容，以及今天的AI工程师与传统机器学习工程师角色的不同.^([1](ch01.html#id534))
- en: The Rise of AI Engineering
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能工程的兴起
- en: Foundation models emerged from large language models, which, in turn, originated
    as just language models. While applications like ChatGPT and GitHub’s Copilot
    may seem to have come out of nowhere, they are the culmination of decades of technology
    advancements, with the first language models emerging in the 1950s. This section
    traces the key breakthroughs that enabled the evolution from language models to
    AI engineering.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 基础模型是从大型语言模型中产生的，而大型语言模型又起源于语言模型。尽管ChatGPT和GitHub的Copilot等应用似乎突然出现，但它们是几十年技术进步的结晶，最早的语言模型出现在20世纪50年代。本节追溯了从语言模型到AI工程演变的关键突破。
- en: From Language Models to Large Language Models
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从语言模型到大型语言模型
- en: While language models have been around for a while, they’ve only been able to
    grow to the scale they are today with *self-supervision.* This section gives a
    quick overview of what language model and self-supervision mean. If you’re already
    familiar with those, feel free to skip this section.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管语言模型已经存在了一段时间，但它们只有在**自监督**的帮助下才能发展到今天这样的规模。本节简要概述了语言模型和自监督的含义。如果你已经熟悉这些概念，可以自由跳过本节。
- en: Language models
  id: totrans-12
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 语言模型
- en: A *language model* encodes statistical information about one or more languages.
    Intuitively, this information tells us how likely a word is to appear in a given
    context. For example, given the context “My favorite color is __”, a language
    model that encodes English should predict “blue” more often than “car”.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一个**语言模型**编码了关于一种或多种语言的统计信息。直观地说，这些信息告诉我们一个单词在特定上下文中出现的可能性。例如，给定上下文“我最喜欢的颜色是__”，一个编码英语的语言模型应该比预测“car”更频繁地预测“blue”。
- en: The statistical nature of languages was discovered centuries ago. In the 1905
    story [“The Adventure of the Dancing Men”](https://en.wikipedia.org/wiki/The_Adventure_of_the_Dancing_Men),
    Sherlock Holmes leveraged simple statistical information of English to decode
    sequences of mysterious stick figures. Since the most common letter in English
    is *E*, Holmes deduced that the most common stick figure must stand for *E*.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 语言统计性质在几个世纪前就被发现了。在1905年的故事《“跳舞男子的冒险”》中，福尔摩斯利用英语的简单统计信息来解码一系列神秘的棍状人形。由于英语中最常见的字母是*E*，福尔摩斯推断最常见的棍状人形必须代表*E*。
- en: Later on, Claude Shannon used more sophisticated statistics to decipher enemies’
    messages during the Second World War. His work on how to model English was published
    in his 1951 landmark paper [“Prediction and Entropy of Printed English”](https://oreil.ly/G_HBp).
    Many concepts introduced in this paper, including entropy, are still used for
    language modeling today.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，克劳德·香农在第二次世界大战期间使用了更复杂的统计方法来破解敌人的信息。他在1951年的里程碑式论文《“印刷英语的预测与熵”》中发表了关于如何建模英语的工作。这篇论文中介绍的概念，包括熵，至今仍被用于语言建模。
- en: In the early days, a language model involved one language. However, today, a
    language model can involve multiple languages.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期，语言模型仅涉及一种语言。然而，如今，语言模型可以涉及多种语言。
- en: The basic unit of a language model is *token*. A token can be a character, a
    word, or a part of a word (like -tion), depending on the model.^([2](ch01.html#id536))
    For example, GPT-4, a model behind ChatGPT, breaks the phrase “I can’t wait to
    build AI applications” into nine tokens, as shown in [Figure 1-1](#ch01_figure_1_1730130814919858).
    Note that in this example, the word “can’t” is broken into two tokens, *can* and
    *’t*. You can see how different OpenAI models tokenize text on the [OpenAI website](https://oreil.ly/0QI91).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型的基本单位是**标记**。标记可以是字符、单词或单词的一部分（如-tion），具体取决于模型.^([2](ch01.html#id536)) 例如，ChatGPT背后的模型GPT-4将短语“我迫不及待地想构建AI应用”分解成九个标记，如图[图1-1](#ch01_figure_1_1730130814919858)所示。注意，在这个例子中，单词“can’t”被分解成两个标记，*can*和*’t*。你可以在[OpenAI网站](https://oreil.ly/0QI91)上看到不同OpenAI模型如何标记文本。
- en: '![A close up of a sign'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '![一个标志的特写'
- en: Description automatically generated](assets/aien_0101.png)
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](assets/aien_0101.png)
- en: Figure 1-1\. An example of how GPT-4 tokenizes a phrase.
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1\. GPT-4如何标记短语的一个示例。
- en: The process of breaking the original text into tokens is called *tokenization*.
    For GPT-4, an average token is approximately [¾ the length of a word](https://oreil.ly/EYccr).
    So, 100 tokens are approximately 75 words.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 将原始文本分解成标记的过程称为**标记化**。对于GPT-4来说，平均标记的长度大约是单词长度的[¾](https://oreil.ly/EYccr)。因此，100个标记大约相当于75个单词。
- en: The set of all tokens a model can work with is the model’s *vocabulary*. You
    can use a small number of tokens to construct a large number of distinct words,
    similar to how you can use a few letters in the alphabet to construct many words.
    The [Mixtral 8x7B](https://oreil.ly/bxMcW) model has a vocabulary size of 32,000\.
    GPT-4’s vocabulary size is [100,256](https://github.com/openai/tiktoken/blob/main/tiktoken/model.py).
    The tokenization method and vocabulary size are decided by model developers.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 模型可以处理的全部标记集合是模型的*词汇表*。你可以使用少量标记来构建大量不同的单词，类似于你如何使用字母表中的几个字母来构建许多单词。Mixtral
    8x7B模型有32,000个词汇量。GPT-4的词汇量是[100,256](https://github.com/openai/tiktoken/blob/main/tiktoken/model.py)。标记化方法和词汇量由模型开发者决定。
- en: Note
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'Why do language models use *token* as their unit instead of *word* or *character*?
    There are three main reasons:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么语言模型使用*标记*作为它们的单位而不是*单词*或*字符*？有三个主要原因：
- en: Compared to characters, tokens allow the model to break words into meaningful
    components. For example, “cooking” can be broken into “cook” and “ing”, with both
    components carrying some meaning of the original word.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 与字符相比，标记允许模型将单词分解成有意义的组成部分。例如，“cooking”可以被分解成“cook”和“ing”，这两个组成部分都承载着原始单词的一些意义。
- en: Because there are fewer unique tokens than unique words, this reduces the model’s
    vocabulary size, making the model more efficient (as discussed in [Chapter 2](ch02.html#ch02_understanding_foundation_models_1730147895571359)).
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因为独特的标记比独特的单词少，这减少了模型的词汇量，使模型更高效（如第2章[理解基础模型](ch02.html#ch02_understanding_foundation_models_1730147895571359)中讨论的）。
- en: Tokens also help the model process unknown words. For instance, a made-up word
    like “chatgpting” could be split into “chatgpt” and “ing”, helping the model understand
    its structure. Tokens balance having fewer units than words while retaining more
    meaning than individual characters.
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标记还有助于模型处理未知单词。例如，一个虚构的词如“chatgpting”可以被分成“chatgpt”和“ing”，帮助模型理解其结构。标记在比单词更少的单元数和比单个字符更多的意义之间取得平衡。
- en: 'There are two main types of language models: *masked language models* and *autoregressive
    language models*. They differ based on what information they can use to predict
    a token:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型主要有两种类型：*掩码语言模型*和*自回归语言模型*。它们根据可以用来预测标记的信息不同而有所区别：
- en: Masked language model
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 掩码语言模型
- en: A masked language model is trained to predict missing tokens anywhere in a sequence,
    *using the context from both before and after the missing tokens*. In essence,
    a masked language model is trained to be able to fill in the blank. For example,
    given the context, “My favorite __ is blue”, a masked language model should predict
    that the blank is likely “color”. A well-known example of a masked language model
    is bidirectional encoder representations from transformers, or BERT ([Devlin et
    al., 2018](https://arxiv.org/abs/1810.04805)).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 掩码语言模型被训练来预测序列中任何位置的缺失标记，*使用缺失标记前后文的信息*。本质上，掩码语言模型被训练来能够填补空白。例如，给定上下文“我的最喜欢的
    __ 是蓝色”，掩码语言模型应该预测空白处可能是“颜色”。一个著名的掩码语言模型例子是来自转换器的双向编码器表示，或称为BERT ([Devlin et al.,
    2018](https://arxiv.org/abs/1810.04805))。
- en: As of writing, masked language models are commonly used for non-generative tasks
    such as sentiment analysis and text classification. They are also useful for tasks
    requiring an understanding of the overall context, such as code debugging, where
    a model needs to understand both the preceding and following code to identify
    errors.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，掩码语言模型通常用于非生成性任务，如情感分析和文本分类。它们对于需要理解整体上下文的任务也很有用，例如代码调试，其中模型需要理解前后代码以识别错误。
- en: Autoregressive language model
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 自回归语言模型
- en: An autoregressive language model is trained to predict the next token in a sequence,
    *using only the preceding tokens*. It predicts what comes next in “My favorite
    color is __*.*”^([3](ch01.html#id541)) An autoregressive model can continually
    generate one token after another. Today, autoregressive language models are the
    models of choice for text generation, and for this reason, they are much more
    popular than masked language models.^([4](ch01.html#id542))
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 自回归语言模型被训练来预测序列中的下一个标记，*仅使用前面的标记*。它预测“我的最喜欢的颜色是 __*.*”中的下一个内容^([3](ch01.html#id541))。自回归模型可以不断地生成一个标记接着另一个标记。如今，自回归语言模型是文本生成的首选模型，因此，它们比掩码语言模型更受欢迎.^([4](ch01.html#id542))
- en: '[Figure 1-2](#ch01_figure_2_1730130814919894) shows these two types of language
    models.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-2](#ch01_figure_2_1730130814919894)展示了这两种类型的语言模型。'
- en: '![A diagram of a chicken crossword'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '![鸡字谜的图解'
- en: Description automatically generated](assets/aien_0102.png)
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](assets/aien_0102.png)
- en: Figure 1-2\. Autoregressive language model and masked language model.
  id: totrans-37
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-2\. 自回归语言模型和掩码语言模型。
- en: Note
  id: totrans-38
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In this book, unless explicitly stated, *language model* will refer to an autoregressive
    model.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，除非明确说明，*语言模型*将指自回归模型。
- en: The outputs of language models are open-ended. A language model can use its
    fixed, finite vocabulary to construct infinite possible outputs. A model that
    can generate open-ended outputs is called *generative*, hence the term *generative
    AI*.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型的输出是开放式的。语言模型可以使用其固定、有限的词汇构造无限可能的输出。能够生成开放式输出的模型被称为*生成型*，因此有*生成式AI*这个术语。
- en: 'You can think of a language model as a *completion machine*: given a text (prompt),
    it tries to complete that text. Here’s an example:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将语言模型想象成一个*补全机器*：给定一段文本（提示），它试图完成这段文本。以下是一个例子：
- en: '[PRE0]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: It’s important to note that completions are predictions, based on probabilities,
    and not guaranteed to be correct. This probabilistic nature of language models
    makes them both so exciting and frustrating to use. We explore this further in
    [Chapter 2](ch02.html#ch02_understanding_foundation_models_1730147895571359).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，补全是基于概率的预测，并不保证一定是正确的。语言模型的这种概率性质使得它们在使用时既令人兴奋又令人沮丧。我们将在[第二章](ch02.html#ch02_understanding_foundation_models_1730147895571359)中进一步探讨这一点。
- en: 'As simple as it sounds, completion is incredibly powerful. Many tasks, including
    translation, summarization, coding, and solving math problems, can be framed as
    completion tasks. For example, given the prompt: “How are you in French is …”,
    a language model might be able to complete it with: “Comment ça va”, effectively
    translating from one language to another.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然听起来很简单，但补全功能非常强大。许多任务，包括翻译、摘要、编码和解决数学问题，都可以被看作是补全任务。例如，给定提示：“你用法语怎么说……”，语言模型可能能够通过以下方式完成它：“Comment
    ça va”，从而实现从一种语言到另一种语言的翻译。
- en: 'As another example, given the prompt:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 作为另一个例子，给定提示：
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'A language model might be able to complete it with: “Likely spam”, which turns
    this language model into a spam classifier.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型可能能够通过以下方式完成它：“可能是垃圾邮件”，这使得这个语言模型变成了一个垃圾邮件分类器。
- en: While completion is powerful, completion isn’t the same as engaging in a conversation.
    For example, if you ask a completion machine a question, it can complete what
    you said by adding another question instead of answering the question. [“Post-Training”](ch02.html#ch02_post_training_1730147895572108)
    discusses how to make a model respond appropriately to a user’s request.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然补全功能强大，但补全并不等同于参与对话。例如，如果你向补全机器提问，它可以通过添加另一个问题来补全你所说的话，而不是回答问题。[“训练后”](ch02.html#ch02_post_training_1730147895572108)讨论了如何使模型能够适当地响应用户的请求。
- en: Self-supervision
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自监督
- en: Language modeling is just one of many ML algorithms. There are also models for
    object detection, topic modeling, recommender systems, weather forecasting, stock
    price prediction, etc. What’s special about language models that made them the
    center of the scaling approach that caused the ChatGPT moment?
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 语言建模只是许多机器学习算法之一。还有用于目标检测、主题建模、推荐系统、天气预报、股票价格预测等的模型。是什么特别之处使得语言模型成为了导致ChatGPT时刻的扩展方法的中心？
- en: The answer is that language models can be trained using *self-supervision*,
    while many other models require *supervision*. Supervision refers to the process
    of training ML algorithms using labeled data, which can be expensive and slow
    to obtain. Self-supervision helps overcome this data labeling bottleneck to create
    larger datasets for models to learn from, effectively allowing models to scale
    up. Here’s how.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 答案是，语言模型可以使用*自监督*进行训练，而许多其他模型则需要*监督*。监督是指使用标记数据训练机器学习算法的过程，这可能既昂贵又耗时。自监督有助于克服数据标注瓶颈，为模型提供更大的数据集进行学习，从而有效地允许模型扩展。下面是如何做到这一点。
- en: With supervision, you label examples to show the behaviors you want the model
    to learn, and then train the model on these examples. Once trained, the model
    can be applied to new data. For example, to train a fraud detection model, you
    use examples of transactions, each labeled with “fraud” or “not fraud”. Once the
    model learns from these examples, you can use this model to predict whether a
    transaction is fraudulent.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督学习中，你标注示例以展示你希望模型学习的行为，然后在这些示例上训练模型。一旦训练完成，模型就可以应用于新数据。例如，为了训练一个欺诈检测模型，你使用标注为“欺诈”或“非欺诈”的交易示例。一旦模型从这些示例中学习，你就可以使用这个模型来预测交易是否欺诈。
- en: The success of AI models in the 2010s lay in supervision. The model that started
    the deep learning revolution, AlexNet ([Krizhevsky et al., 2012](https://oreil.ly/WEQFj)),
    was supervised. It was trained to learn how to classify over 1 million images
    in the dataset ImageNet. It classified each image into one of 1,000 categories
    such as “car”, “balloon”, or “monkey”.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 2010 年代人工智能模型的成功在于监督学习。启动深度学习革命的模型 AlexNet ([Krizhevsky et al., 2012](https://oreil.ly/WEQFj))
    是经过监督训练的。它被训练来学习如何对数据集 ImageNet 中的超过一百万张图片进行分类。它将每张图片分类到 1,000 个类别之一，例如“汽车”、“气球”或“猴子”。
- en: A drawback of supervision is that data labeling is expensive and time-consuming.
    If it costs 5 cents for one person to label one image, it’d cost $50,000 to label
    a million images for ImageNet.^([5](ch01.html#id545)) If you want two different
    people to label each image—so that you could cross-check label quality—it’d cost
    twice as much. Because the world contains vastly more than 1,000 objects, to expand
    models’ capabilities to work with more objects, you’d need to add labels of more
    categories. To scale up to 1 million categories, the labeling cost alone would
    increase to $50 million.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习的一个缺点是数据标注既昂贵又耗时。如果一个人标注一张图片需要5美分，那么为 ImageNet 标注一百万张图片将花费 50,000 美元.^([5](ch01.html#id545))
    如果你想让两个人分别标注每张图片——以便交叉检查标注质量——那么成本将是两倍。因为世界上包含的对象远远超过 1,000 个，为了扩展模型以处理更多对象，你需要添加更多类别的标签。要将类别扩展到
    1,000 万个，仅标签成本就会增加到 5,000 万美元。
- en: Labeling everyday objects is something that most people can do without prior
    training. Hence, it can be done relatively cheaply. However, not all labeling
    tasks are that simple. Generating Latin translations for an English-to-Latin model
    is more expensive. Labeling whether a CT scan shows signs of cancer would be astronomical.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 标注日常物体是大多数人无需事先训练就能做到的事情。因此，这可以相对便宜地完成。然而，并非所有标注任务都那么简单。为英语到拉丁语的模型生成拉丁语翻译会更昂贵。判断
    CT 扫描是否显示癌症迹象的成本将是天文数字。
- en: Self-supervision helps overcome the data labeling bottleneck. In self-supervision,
    instead of requiring explicit labels, the model can infer labels from the input
    data. Language modeling is self-supervised because each input sequence provides
    both the labels (tokens to be predicted) and the contexts the model can use to
    predict these labels. For example, the sentence “I love street food.” gives six
    training samples, as shown in [Table 1-1](#ch01_table_1_1730130814941480).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 自监督学习有助于克服数据标注瓶颈。在自监督学习中，不需要显式标签，模型可以从输入数据中推断标签。语言模型是自监督的，因为每个输入序列都提供了标签（要预测的标记）和模型可以用来预测这些标签的上下文。例如，句子
    “I love street food.” 提供了六个训练样本，如 [表 1-1](#ch01_table_1_1730130814941480) 所示。
- en: Table 1-1\. Training samples from the sentence “I love street food.” for language
    modeling.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1-1\. 来自句子 “I love street food.” 的语言模型训练样本。
- en: '| Input (context) | Output (next token) |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 输入（上下文） | 输出（下一个标记） |'
- en: '| --- | --- |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `<BOS>` | `I` |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| `<BOS>` | `I` |'
- en: '| `<BOS>, I` | `love` |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| `<BOS>, I` | `love` |'
- en: '| `<BOS>, I, love` | `street` |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| `<BOS>, I, love` | `street` |'
- en: '| `<BOS>, I, love, street` | `food` |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| `<BOS>, I, love, street` | `food` |'
- en: '| `<BOS>, I, love, street, food` | `.` |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| `<BOS>, I, love, street, food` | `.` |'
- en: '| `<BOS>, I, love, street, food, .` | `<EOS>` |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| `<BOS>, I, love, street, food, .` | `<EOS>` |'
- en: In [Table 1-1](#ch01_table_1_1730130814941480), <BOS> and <EOS> mark the beginning
    and the end of a sequence. These markers are necessary for a language model to
    work with multiple sequences. Each marker is typically treated as one special
    token by the model. The end-of-sequence marker is especially important as it helps
    language models know when to end their responses.^([6](ch01.html#id546))
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [表 1-1](#ch01_table_1_1730130814941480) 中，<BOS> 和 <EOS> 标记序列的开始和结束。这些标记对于语言模型与多个序列一起工作来说是必要的。每个标记通常被模型视为一个特殊的标记。序列结束标记尤为重要，因为它帮助语言模型知道何时结束其响应.^([6](ch01.html#id546))
- en: Note
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 备注
- en: Self-supervision differs from unsupervision. In self-supervised learning, labels
    are inferred from the input data. In unsupervised learning, you don’t need labels
    at all.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 自监督学习与无监督学习不同。在自监督学习中，标签是从输入数据中推断出来的。在无监督学习中，你根本不需要标签。
- en: Self-supervised learning means that language models can learn from text sequences
    without requiring any labeling. Because text sequences are everywhere—in books,
    blog posts, articles, and Reddit comments—it’s possible to construct a massive
    amount of training data, allowing language models to scale up to become LLMs.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 自监督学习意味着语言模型可以在不进行任何标记的情况下从文本序列中学习。因为文本序列无处不在——在书籍、博客文章、文章和 Reddit 评论中——因此可以构建大量的训练数据，使语言模型能够扩展成为
    LLM。
- en: LLM, however, is hardly a scientific term. How large does a language model have
    to be to be considered *large*? What is large today might be considered tiny tomorrow.
    A model’s size is typically measured by its number of parameters. A *parameter*
    is a variable within an ML model that is updated through the training process.^([7](ch01.html#id547))
    In general, though this is not always true, the more parameters a model has, the
    greater its capacity to learn desired behaviors.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，LLM 并不是一个科学的术语。一个语言模型需要多大才能被认为是“大”的？今天被认为是大的，明天可能就被视为微小。模型的大小通常通过其参数数量来衡量。*参数*是机器学习模型中的一个变量，它通过训练过程进行更新。[7](ch01.html#id547)
    在一般情况下，尽管这并不总是正确的，但一个模型拥有的参数越多，其学习所需行为的能力就越强。
- en: When OpenAI’s first generative pre-trained transformer (GPT) model came out
    in June 2018, it had 117 million parameters, and that was considered large. In
    February 2019, when OpenAI introduced GPT-2 with 1.5 billion parameters, 117 million
    was downgraded to be considered small. As of the writing of this book, a model
    with 100 billion parameters is considered large. Perhaps one day, this size will
    be considered small.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当 OpenAI 的首个生成式预训练转换器（GPT）模型于 2018 年 6 月发布时，它拥有 1170 万个参数，这被认为是个很大的数字。到了 2019
    年 2 月，当 OpenAI 推出拥有 15 亿个参数的 GPT-2 时，1170 万个参数被降级为较小的规模。截至本书撰写时，一个拥有 1000 亿个参数的模型被认为是大的。或许有一天，这个规模将被视为较小。
- en: 'Before we move on to the next section, I want to touch on a question that is
    usually taken for granted: *Why do larger models need more data?* Larger models
    have more capacity to learn, and, therefore, would need more training data to
    maximize their performance.^([8](ch01.html#id549)) You can train a large model
    on a small dataset too, but it’d be a waste of compute. You could have achieved
    similar or better results on this dataset with smaller models.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进入下一节之前，我想提及一个通常被理所当然的问题：*为什么更大的模型需要更多的数据？* 更大的模型有更大的学习能力，因此需要更多的训练数据来最大化其性能。[8](ch01.html#id549)
    你也可以在小型数据集上训练一个大型模型，但这将是计算资源的浪费。你本可以用较小的模型在这个数据集上实现相似或更好的结果。
- en: From Large Language Models to Foundation Models
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从大型语言模型到基础模型
- en: While language models are capable of incredible tasks, they are limited to text.
    As humans, we perceive the world not just via language but also through vision,
    hearing, touch, and more. Being able to process data beyond text is essential
    for AI to operate in the real world.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管语言模型能够执行令人难以置信的任务，但它们局限于文本。作为人类，我们不仅通过语言，还通过视觉、听觉、触觉等方式感知世界。对于人工智能在现实世界中的运作来说，能够处理文本之外的数据至关重要。
- en: For this reason, language models are being extended to incorporate more data
    modalities. GPT-4V and Claude 3 can understand images and texts. Some models even
    understand videos, 3D assets, protein structures, and so on. Incorporating more
    data modalities into language models makes them even more powerful. OpenAI [noted
    in their GPT-4V system card](https://oreil.ly/NoGX7) in 2023 that “incorporating
    additional modalities (such as image inputs) into LLMs is viewed by some as a
    key frontier in AI research and development.”
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，语言模型正在扩展以包含更多的数据模态。GPT-4V 和 Claude 3 可以理解图像和文本。一些模型甚至可以理解视频、3D 资产、蛋白质结构等等。将更多数据模态纳入语言模型使它们变得更加强大。OpenAI
    在 2023 年的 GPT-4V 系统卡片[noted in their GPT-4V system card](https://oreil.ly/NoGX7)中指出，“将额外的模态（如图像输入）纳入
    LLM 被一些人视为人工智能研究和开发的关键前沿。”
- en: While many people still call Gemini and GPT-4V LLMs, they’re better characterized
    as [*foundation models*](https://arxiv.org/abs/2108.07258). The word *foundation*
    signifies both the importance of these models in AI applications and the fact
    that they can be built upon for different needs.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管许多人仍然将 Gemini 和 GPT-4V 称为大型语言模型（LLM），但它们更准确地被描述为[*基础模型*](https://arxiv.org/abs/2108.07258)。单词“基础”既表明了这些模型在人工智能应用中的重要性，也说明了它们可以根据不同的需求进行构建。
- en: Foundation models mark a breakthrough from the traditional structure of AI research.
    For a long time, AI research was divided by data modalities. Natural language
    processing (NLP) deals only with text. Computer vision deals only with vision.
    Text-only models can be used for tasks such as translation and spam detection.
    Image-only models can be used for object detection and image classification. Audio-only
    models can handle speech recognition (speech-to-text, or STT) and speech synthesis
    (text-to-speech, or TTS).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 基础模型标志着从传统人工智能研究结构中的突破。长期以来，人工智能研究被数据模态所分割。自然语言处理 (NLP) 只处理文本。计算机视觉只处理视觉。仅文本的模型可用于翻译和垃圾邮件检测等任务。仅图像的模型可用于目标检测和图像分类。仅音频的模型可以处理语音识别（语音到文本，或
    STT）和语音合成（文本到语音，或 TTS）。
- en: A model that can work with more than one data modality is also called a *multimodal
    model.* A generative multimodal model is also called a large multimodal model
    (LMM). If a language model generates the next token conditioned on text-only tokens,
    a multimodal model generates the next token conditioned on both text and image
    tokens, or whichever modalities that the model supports, as shown in [Figure 1-3](#ch01_figure_3_1730130814919919).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 能够处理多个数据模态的模型也称为 *多模态模型*。生成型多模态模型也称为大型多模态模型 (LMM)。如果一个语言模型在仅基于文本标记的条件下生成下一个标记，那么多模态模型将在基于文本和图像标记的条件下生成下一个标记，或者模型支持的任何模态，如图
    1-3 所示 [图 1-3](#ch01_figure_3_1730130814919919)。
- en: '![A diagram of a model'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '![模型图'
- en: Description automatically generated](assets/aien_0103.png)
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](assets/aien_0103.png)
- en: Figure 1-3\. A multimodal model can generate the next token using information
    from both text and visual tokens.
  id: totrans-81
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-3\. 多模态模型可以使用来自文本和视觉标记的信息生成下一个标记。
- en: Just like language models, multimodal models need data to scale up. Self-supervision
    works for multimodal models too. For example, OpenAI used a variant of self-supervision
    called *natural language supervision* to train their language-image model [CLIP
    (OpenAI, 2021)](https://oreil.ly/zcqdu). Instead of manually generating labels
    for each image, they found (image, text) pairs that co-occurred on the internet.
    They were able to generate a dataset of 400 million (image, text) pairs, which
    was 400 times larger than ImageNet, without manual labeling cost. This dataset
    enabled CLIP to become the first model that could generalize to multiple image
    classification tasks without requiring additional training.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 就像语言模型一样，多模态模型也需要数据来扩展规模。自监督对于多模态模型也适用。例如，OpenAI 使用了一种名为 *自然语言监督* 的自监督变体来训练他们的语言-图像模型
    [CLIP (OpenAI, 2021)](https://oreil.ly/zcqdu)。他们不是手动为每张图片生成标签，而是在互联网上找到了同时出现的
    (图像，文本) 对。他们能够生成包含 4 亿个 (图像，文本) 对的数据集，这个数据集比 ImageNet 大 400 倍，而且没有手动标注的成本。这个数据集使得
    CLIP 成为第一个能够泛化到多个图像分类任务而无需额外训练的模型。
- en: Note
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: This book uses the term foundation models to refer to both large language models
    and large multimodal models.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 本书使用“基础模型”一词来指代大型语言模型和大型多模态模型。
- en: Note that CLIP isn’t a generative model—it wasn’t trained to generate open-ended
    outputs. CLIP is an *embedding model*, trained to produce joint embeddings of
    both texts and images. [“Introduction to Embedding”](ch03.html#ch03a_introduction_to_embedding_1730150757064669)
    discusses embeddings in detail. For now, you can think of embeddings as vectors
    that aim to capture the meanings of the original data. Multimodal embedding models
    like CLIP are the backbones of generative multimodal models, such as Flamingo,
    LLaVA, and Gemini (previously Bard).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到 CLIP 不是一个生成模型——它没有被训练来生成开放式的输出。CLIP 是一个 *嵌入模型*，被训练来产生文本和图像的联合嵌入。[“嵌入简介”](ch03.html#ch03a_introduction_to_embedding_1730150757064669)
    详细讨论了嵌入。现在，你可以将嵌入视为旨在捕捉原始数据含义的向量。像 CLIP 这样的多模态嵌入模型是生成型多模态模型（如 Flamingo、LLaVA 和
    Gemini（以前称为 Bard））的骨干。
- en: Foundation models also mark the transition from task-specific models to general-purpose
    models. Previously, models were often developed for specific tasks, such as sentiment
    analysis or translation. A model trained for sentiment analysis wouldn’t be able
    to do translation, and vice versa.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 基础模型也标志着从特定任务模型向通用模型的转变。以前，模型通常是为特定任务开发的，例如情感分析或翻译。为情感分析训练的模型无法进行翻译，反之亦然。
- en: '*Foundation models, thanks to their scale and the way they are trained, are
    capable of a wide range of tasks.* Out of the box, general-purpose models can
    work relatively well for many tasks. An LLM can do both sentiment analysis and
    translation. However, you can often tweak a general-purpose model to maximize
    its performance on a specific task.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '*基础模型，得益于其规模和训练方式，能够执行广泛的任务。开箱即用的通用模型在很多任务上可以相对很好地工作。一个大型语言模型可以执行情感分析和翻译。然而，你通常可以调整通用模型以最大化其在特定任务上的性能。*'
- en: '[Figure 1-4](#ch01_figure_4_1730130814919937) shows the tasks used by the Super-NaturalInstructions
    benchmark to evaluate foundation models ([Wang et al., 2022](https://arxiv.org/abs/2204.07705)),
    providing an idea of the types of tasks a foundation model can perform.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-4](#ch01_figure_4_1730130814919937) 展示了Super-NaturalInstructions基准测试所使用的任务，用于评估基础模型（[王等，2022](https://arxiv.org/abs/2204.07705)），提供了基础模型可以执行的任务类型的一个概念。'
- en: Imagine you’re working with a retailer to build an application to generate product
    descriptions for their website. An out-of-the-box model might be able to generate
    accurate descriptions but might fail to capture the brand’s voice or highlight
    the brand’s messaging. The generated descriptions might even be full of marketing
    speech and cliches.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 想象你正在与一家零售商合作，构建一个用于生成其网站产品描述的应用程序。一个开箱即用的模型可能能够生成准确的产品描述，但可能无法捕捉品牌的语气或突出品牌的宣传信息。生成的描述甚至可能充满了营销话语和陈词滥调。
- en: '![A diagram of different colored circles'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![不同颜色圆圈的图示'
- en: Description automatically generated](assets/aien_0104.png)
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](assets/aien_0104.png)
- en: Figure 1-4\. The range of tasks in the Super-NaturalInstructions benchmark (Wang
    et al., 2022).
  id: totrans-92
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-4\. Super-NaturalInstructions基准测试中的任务范围（王等，2022）。
- en: There are multiple techniques you can use to get the model to generate what
    you want. For example, you can craft detailed instructions with examples of the
    desirable product descriptions. This approach is *prompt engineering*. You can
    connect the model to a database of customer reviews that the model can leverage
    to generate better descriptions. Using a database to supplement the instructions
    is called *retrieval-augmented generation* (RAG). You can also *finetune*—further
    train—the model on a dataset of high-quality product descriptions.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用多种技术来让模型生成你想要的内容。例如，你可以编写详细的带有期望产品描述示例的指令。这种方法被称为*提示工程*。你可以将模型连接到客户评论数据库，模型可以利用这个数据库生成更好的描述。使用数据库来补充指令被称为*检索增强生成*（RAG）。你还可以对模型进行*微调*——在高质量产品描述数据集上进一步训练模型。
- en: Prompt engineering, RAG, and finetuning are three very common AI engineering
    techniques that you can use to adapt a model to your needs. The rest of the book
    will discuss all of them in detail.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程、RAG（检索增强生成）和微调是三种非常常见的AI工程技术，你可以使用它们来调整模型以满足你的需求。本书的其余部分将详细讨论所有这些技术。
- en: Adapting an existing powerful model to your task is generally a lot easier than
    building a model for your task from scratch—for example, ten examples and one
    weekend versus 1 million examples and six months. Foundation models make it cheaper
    to develop AI applications and reduce time to market. Exactly how much data is
    needed to adapt a model depends on what technique you use. This book will also
    touch on this question when discussing each technique. However, there are still
    many benefits to task-specific models, for example, they might be a lot smaller,
    making them faster and cheaper to use.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 将现有的强大模型调整到你的任务上通常比从头开始构建模型要容易得多——例如，十个例子和一个周末与一百万个例子和六个月相比。基础模型使得开发AI应用的成本更低，并缩短了上市时间。需要多少数据来调整模型取决于你使用的技术。本书在讨论每种技术时也会涉及这个问题。然而，特定任务的模型仍然有许多好处，例如，它们可能要小得多，这使得它们更快、更便宜。
- en: Whether to build your own model or leverage an existing one is a classic buy-or-build
    question that teams will have to answer for themselves. Discussions throughout
    the book can help with that decision.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 是构建自己的模型还是利用现有的模型是一个经典的“买或建”问题，团队将不得不自己回答。本书中的讨论可以帮助你做出这个决定。
- en: From Foundation Models to AI Engineering
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从基础模型到AI工程
- en: '*AI engineering* refers to the process of building applications on top of foundation
    models. People have been building AI applications for over a decade—a process
    often known as ML engineering or MLOps (short for ML operations). Why do we talk
    about AI engineering now?'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '*AI工程*指的是在基础模型之上构建应用程序的过程。人们已经构建AI应用超过十年——这个过程通常被称为机器学习工程或MLOps（即机器学习操作）。我们为什么现在谈论AI工程？'
- en: 'If traditional ML engineering involves developing ML models, AI engineering
    leverages existing ones. The availability and accessibility of powerful foundation
    models lead to three factors that, together, create ideal conditions for the rapid
    growth of AI engineering as a discipline:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 如果传统的机器学习工程涉及开发机器学习模型，那么AI工程则利用现有的模型。强大基础模型的可用性和可访问性导致三个因素，这三个因素共同创造了AI工程作为一门学科快速增长的理想条件：
- en: 'Factor 1: General-purpose AI capabilities'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 因素1：通用AI能力
- en: Foundation models are powerful not just because they can do existing tasks better.
    They are also powerful because they can do more tasks. Applications previously
    thought impossible are now possible, and applications not thought of before are
    emerging. Even applications not thought possible today might be possible tomorrow.
    This makes AI more useful for more aspects of life, vastly increasing both the
    user base and the demand for AI applications.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 基础模型之所以强大，不仅是因为它们能更好地完成现有任务，还因为它们能完成更多任务。以前认为不可能的应用现在成为可能，以前未曾考虑过的应用正在出现。甚至今天认为不可能的应用明天也可能成为可能。这使得AI在生活的更多方面变得更有用，极大地增加了用户基础和对AI应用的需求。
- en: For example, since AI can now write as well as humans, sometimes even better,
    AI can automate or partially automate every task that requires communication,
    which is pretty much everything. AI is used to write emails, respond to customer
    requests, and explain complex contracts. Anyone with a computer has access to
    tools that can instantly generate customized, high-quality images and videos to
    help create marketing materials, edit professional headshots, visualize art concepts,
    illustrate books, and so on. AI can even be used to synthesize training data,
    develop algorithms, and write code, all of which will help train even more powerful
    models in the future.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，由于AI现在可以像人类一样写作，有时甚至写得更好，AI可以自动化或部分自动化几乎所有需要沟通的任务，这几乎涵盖了所有事情。AI被用来撰写电子邮件、回应客户请求和解释复杂的合同。任何拥有电脑的人都可以访问能够即时生成定制、高质量图像和视频的工具，以帮助创建营销材料、编辑专业肖像、可视化艺术概念、插图书籍等等。AI甚至可以用来合成训练数据、开发算法和编写代码，所有这些都将有助于未来训练更强大的模型。
- en: 'Factor 2: Increased AI investments'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 因素2：增加的AI投资
- en: The success of ChatGPT prompted a sharp increase in investments in AI, both
    from venture capitalists and enterprises. As AI applications become cheaper to
    build and faster to go to market, returns on investment for AI become more attractive.
    Companies rush to incorporate AI into their products and processes. Matt Ross,
    a senior manager of applied research at Scribd, told me that the estimated AI
    cost for his use cases has gone down two orders of magnitude from April 2022 to
    April 2023.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT的成功促使风险投资家和企业在AI领域的投资急剧增加。随着AI应用的建设成本降低和上市速度加快，AI的投资回报变得更加吸引人。公司纷纷将AI融入他们的产品和流程中。Scribd应用研究高级经理Matt
    Ross告诉我，他使用案例的AI成本从2022年4月到2023年4月下降了两个数量级。
- en: '[Goldman Sachs Research](https://oreil.ly/okMw6) estimated that AI investment
    could approach $100 billion in the US and $200 billion globally by 2025.^([9](ch01.html#id561))
    AI is often mentioned as a competitive advantage. [FactSet](https://oreil.ly/tgm-a)
    found that one in three S&P 500 companies mentioned AI in their earnings calls
    for the second quarter of 2023, three times more than did so the year earlier.
    [Figure 1-5](#ch01_figure_5_1730130814919959) shows the number of S&P 500 companies
    that mentioned AI in their earning calls from 2018 to 2023.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[高盛研究](https://oreil.ly/okMw6)估计，到2025年，美国AI投资可能达到1000亿美元，全球达到2000亿美元。[9](ch01.html#id561)
    AI经常被提及为竞争优势。[FactSet](https://oreil.ly/tgm-a)发现，在2023年第二季度财报电话会议中提到AI的S&P 500公司中，有三分之一，是去年同期的三倍。[图1-5](#ch01_figure_5_1730130814919959)显示了从2018年到2023年S&P
    500公司在财报电话会议中提到AI的公司数量。'
- en: '![A graph with numbers and lines'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '![一个带有数字和线条的图表'
- en: Description automatically generated](assets/aien_0105.png)
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](assets/aien_0105.png)
- en: Figure 1-5\. The number of S&P 500 companies that mention AI in their earnings
    calls reached a record high in 2023\. Data from FactSet.
  id: totrans-108
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-5。在 2023 年，提及 AI 的 S&P 500 公司数量达到了历史新高。数据来自 FactSet。
- en: 'According to WallStreetZen, companies that mentioned AI in their earning calls
    saw their stock price increase more than those that didn’t: [an average of a 4.6%
    increase compared to 2.4%](https://oreil.ly/fK5uh). It’s unclear whether it’s
    causation (AI makes these companies more successful) or correlation (companies
    are successful because they are quick to adapt to new technologies).'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 WallStreetZen 的数据，在收益电话中提及 AI 的公司在股价上涨方面超过了那些没有提及的公司：[平均上涨 4.6%，而未提及的公司平均上涨
    2.4%](https://oreil.ly/fK5uh)。不清楚这是因果关系（AI 使这些公司更成功）还是相关性（公司之所以成功，是因为它们迅速适应了新技术）。
- en: 'Factor 3: Low entrance barrier to building AI applications'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 因素 3：构建 AI 应用的低门槛
- en: The model as a service approach popularized by OpenAI and other model providers
    makes it easier to leverage AI to build applications. In this approach, models
    are exposed via APIs that receive user queries and return model outputs. Without
    these APIs, using an AI model requires the infrastructure to host and serve this
    model. These APIs give you access to powerful models via single API calls.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 由 OpenAI 和其他模型提供商推广的“模型即服务”方法使得利用 AI 构建应用变得更加容易。在这种方法中，模型通过 API 向用户提供查询并返回模型输出。没有这些
    API，使用 AI 模型需要基础设施来托管和提供该模型。这些 API 通过单个 API 调用即可访问强大的模型。
- en: Not only that, AI also makes it possible to build applications with minimal
    coding. First, AI can write code for you, allowing people without a software engineering
    background to quickly turn their ideas into code and put them in front of their
    users. Second, you can work with these models in plain English instead of having
    to use a programming language. *Anyone, and I mean anyone, can now develop AI
    applications.*
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅如此，AI 还使得用最少的编码就能构建应用成为可能。首先，AI 可以为您编写代码，使那些没有软件工程背景的人能够快速将他们的想法转化为代码，并将其展示给用户。其次，您可以使用这些模型用普通英语而不是编程语言进行工作。*任何人，我是说任何人，现在都可以开发
    AI 应用程序*。
- en: Because of the resources it takes to develop foundation models, this process
    is possible only for big corporations (Google, Meta, Microsoft, Baidu, Tencent),
    governments ([Japan](https://oreil.ly/r86Qz), the [UAE](https://oreil.ly/IUcVg)),
    and ambitious, well-funded startups (OpenAI, Anthropic, Mistral). In a September
    2022 interview, [Sam Altman, CEO of OpenAI](https://oreil.ly/D9QBM), said that
    the biggest opportunity for the vast majority of people will be to adapt these
    models for specific applications.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 由于开发基础模型所需的资源，这个过程仅适用于大型企业（谷歌、Meta、微软、百度、腾讯）、政府（[日本](https://oreil.ly/r86Qz)、[阿联酋](https://oreil.ly/IUcVg)）和雄心勃勃、资金充足的初创公司（OpenAI、Anthropic、Mistral）。在
    2022 年 9 月的一次采访中，[OpenAI 首席执行官 Sam Altman](https://oreil.ly/D9QBM) 表示，对于绝大多数人来说，最大的机会将是将这些模型应用于特定应用。
- en: The world is quick to embrace this opportunity. AI engineering has rapidly emerged
    as one of the fastest, and quite possibly the fastest-growing, engineering discipline.
    Tools for AI engineering are gaining traction faster than any previous software
    engineering tools. Within just two years, four open source AI engineering tools
    (AutoGPT, Stable Diffusion eb UI, LangChain, Ollama) have already garnered more
    stars on GitHub than Bitcoin. They are on track to surpass even the most popular
    web development frameworks, including React and Vue, in star count. [Figure 1-6](#ch01_figure_6_1730130814919984)
    shows the GitHub star growth of AI engineering tools compared to Bitcoin, Vue,
    and React.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 世界迅速拥抱了这个机会。AI 工程迅速成为最快增长，甚至可能是增长最快的工程学科之一。AI 工程工具的吸引力增长速度比以往任何软件工程工具都要快。仅仅两年内，四个开源
    AI 工程工具（AutoGPT、Stable Diffusion eb UI、LangChain、Ollama）已经在 GitHub 上的星标数量超过了比特币。它们有望在星标数量上超越最流行的
    Web 开发框架，包括 React 和 Vue。[图 1-6](#ch01_figure_6_1730130814919984) 展示了与比特币、Vue 和
    React 相比，AI 工程工具在 GitHub 上的星标增长情况。
- en: A LinkedIn survey from August 2023 shows that the number of professionals adding
    terms like “Generative AI,” “ChatGPT,” “Prompt Engineering,” and “Prompt Crafting”
    to their profile increased [on average 75% each month](https://oreil.ly/m8SvB).
    [*ComputerWorld*](https://oreil.ly/47sGE) declared that “teaching AI to behave
    is the fastest-growing career skill”.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 2023 年 8 月的一项 LinkedIn 调查显示，将“生成式 AI”、“ChatGPT”、“提示工程”和“提示制作”等术语添加到其个人资料中的专业人士数量平均每月增加
    75%[每月平均增加 75%](https://oreil.ly/m8SvB)。[*《计算机世界》*](https://oreil.ly/47sGE) 宣称，“教
    AI 表现是增长最快的职业技能”。
- en: '![A graph of a graph with different colored lines'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '![一个不同颜色线条的图'
- en: Description automatically generated](assets/aien_0106.png)
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](assets/aien_0106.png)
- en: Figure 1-6\. Open source AI engineering tools are growing faster than any other
    software engineering tools, according to their GitHub star counts.
  id: totrans-118
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-6\. 根据GitHub星数，开源AI工程工具的增长速度比任何其他软件工程工具都要快。
- en: The rapidly expanding community of AI engineers has demonstrated remarkable
    creativity with an incredible range of exciting applications. The next section
    will explore some of the most common application patterns.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能工程师的快速增长的社区展示了令人瞩目的创造力，以及一系列令人兴奋的应用。下一节将探讨一些最常见的应用模式。
- en: Foundation Model Use Cases
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基础模型用例
- en: If you’re not already building AI applications, I hope the previous section
    has convinced you that now is a great time to do so. If you have an application
    in mind, you might want to jump to [“Planning AI Applications”](#ch01_planning_ai_applications_1730130814985969).
    If you’re looking for inspiration, this section covers a wide range of industry-proven
    and promising use cases.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有开始构建AI应用，我希望前面的部分已经说服你现在是做这件事的绝佳时机。如果你已经有了应用的想法，你可能想跳转到[“规划AI应用”](#ch01_planning_ai_applications_1730130814985969)。如果你在寻找灵感，本节涵盖了广泛的行业验证和有前景的用例。
- en: The number of potential applications that you could build with foundation models
    seems endless. Whatever use case you think of, there’s probably an AI for that.^([10](ch01.html#id566))
    It’s impossible to list all potential use cases for AI.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以用基础模型构建的潜在应用数量似乎是无限的。无论你想到什么用例，可能都有一个AI与之对应.^([10](ch01.html#id566)) 列出AI的所有潜在用例是不可能的。
- en: 'Even attempting to categorize these use cases is challenging, as different
    surveys use different categorizations. For example, [Amazon Web Services (AWS)](https://oreil.ly/-k_QX)
    has categorized enterprise generative AI use cases into three buckets: customer
    experience, employee productivity, and process optimization. A [2024 O’Reilly
    survey](https://oreil.ly/Kul5E) categorized the use cases into eight categories:
    programming, data analysis, customer support, marketing copy, other copy, research,
    web design, and art.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 对这些用例进行分类本身就具有挑战性，因为不同的调查使用了不同的分类方法。例如，[亚马逊网络服务（AWS）](https://oreil.ly/-k_QX)
    将企业生成式AI用例分为三个类别：客户体验、员工生产力和流程优化。2024年O'Reilly的调查将用例分为八个类别：编程、数据分析、客户支持、营销文案、其他文案、研究、网页设计和艺术。
- en: Some organizations, like [Deloitte](https://oreil.ly/T272_), have categorized
    use cases by value capture, such as cost reduction, process efficiency, growth,
    and accelerating innovation. For value capture, [Gartner](https://oreil.ly/OyIUP)
    has a category for *business continuity*, meaning an organization might go out
    of business if it doesn’t adopt generative AI. Of the 2,500 executives Gartner
    surveyed in 2023, 7% cited business continuity as the motivation for embracing
    generative AI.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 一些组织，如[德勤](https://oreil.ly/T272_)，根据价值获取对用例进行了分类，例如成本降低、流程效率、增长和加速创新。对于价值获取，[高德纳](https://oreil.ly/OyIUP)
    有一个关于*业务连续性*的类别，这意味着如果组织不采用生成式AI，它可能会倒闭。在2023年高德纳调查的2500名高管中，7%的人将业务连续性作为采用生成式AI的动机。
- en: '[Eloundou et al. (2023)](https://arxiv.org/abs/2303.10130) has excellent research
    on how exposed different occupations are to AI. They defined a task as exposed
    if AI and AI-powered software can reduce the time needed to complete this task
    by at least 50%. An occupation with 80% exposure means that 80% of the occupation’s
    tasks are exposed. According to the study, occupations with 100% or close to 100%
    exposure include interpreters and translators, tax preparers, web designers, and
    writers. Some of them are shown in [Table 1-2](#ch01_table_2_1730130814941524).
    Not unsurprisingly, occupations with no exposure to AI include cooks, stonemasons,
    and athletes. This study gives a good idea of what use cases AI is good for.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[Eloundou等人（2023）](https://arxiv.org/abs/2303.10130) 对不同职业暴露于AI的程度进行了优秀的研究。他们将任务定义为暴露，如果AI和AI驱动的软件可以至少减少完成此任务所需的时间的50%。80%暴露的职业意味着该职业的80%的任务是暴露的。根据这项研究，100%或接近100%暴露的职业包括口译员和翻译员、税务筹划师、网页设计师和作家。其中一些在[表1-2](#ch01_table_2_1730130814941524)中展示。不出所料，没有暴露于AI的职业包括厨师、石匠和运动员。这项研究很好地说明了AI适合哪些用例。'
- en: Table 1-2\. Occupations with the highest exposure to AI as annotated by humans.
    $alpha$ refers to exposure to AI models directly, whereas $beta$ and $zeta$ refer
    to exposures to AI-powered software. Table from Eloundou et al. (2023).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1-2\. 人类标注的最易受 AI 影响的职业。$alpha$ 指的是直接接触 AI 模型，而 $beta$ 和 $zeta$ 指的是接触 AI 软件的影响。表来自
    Eloundou 等人（2023）。
- en: '| Group | Occupations with highest exposure | % Exposure |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 团队 | 最易受影响的工作 | % 暴露率 |'
- en: '| --- | --- | --- |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Human $alpha$ | Interpreters and translators Survey researchers'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '| 人 $alpha$ | 口译员和翻译员 调查研究人员'
- en: Poets, lyricists, and creative writers
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 诗人，歌词作者和创意作家
- en: Animal scientists
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 动物科学家
- en: Public relations specialists | 76.5 75.0
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 公关专员 | 76.5 75.0
- en: '68.8'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '68.8'
- en: '66.7'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '66.7'
- en: 66.7 |
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 66.7 |
- en: '| Human $beta$ | Survey researchers Writers and authors'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '| 人 $beta$ | 调查研究人员 写作人和作者'
- en: Interpreters and translators
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 口译员和翻译员
- en: Public relations specialists
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 公关专员
- en: Animal scientists | 84.4 82.5
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 动物科学家 | 84.4 82.5
- en: '82.4'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '82.4'
- en: '80.6'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '80.6'
- en: 77.8 |
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 77.8 |
- en: '| Human $zeta$ | Mathematicians Tax preparers'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '| 人 $zeta$ | 数学家 纳税申报员'
- en: Financial quantitative analysts
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 金融量化分析师
- en: Writers and authors
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 写作人和作者
- en: Web and digital interface designers
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 网页和数字界面设计师
- en: '*Humans labeled 15 occupations as “fully exposed”.* | 100.0 100.0'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '*人类将 15 个职业标记为“完全暴露”.* | 100.0 100.0'
- en: '100.0'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '100.0'
- en: '100.0'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '100.0'
- en: 100.0 |
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 100.0 |
- en: When analyzing the use cases, I looked at both enterprise and consumer applications.
    To understand enterprise use cases, I interviewed 50 companies on their AI strategies
    and read over 100 case studies. To understand consumer applications, I examined
    205 open source AI applications with at least 500 stars on GitHub.^([11](ch01.html#id567))
    I categorized applications into eight groups, as shown in [Table 1-3](#ch01_table_3_1730130814941550).
    The limited list here serves best as a reference. As you learn more about how
    to build foundation models in [Chapter 2](ch02.html#ch02_understanding_foundation_models_1730147895571359)
    and how to evaluate them in [Chapter 3](ch03.html#ch03a_evaluation_methodology_1730150757064067),
    you’ll also be able to form a better picture of what use cases foundation models
    can and should be used for.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析应用场景时，我既考虑了企业应用，也考虑了消费者应用。为了了解企业应用场景，我采访了 50 家公司关于他们的 AI 策略，并阅读了超过 100 个案例研究。为了了解消费者应用，我检查了
    GitHub 上至少有 500 个星标的 205 个开源 AI 应用.^([11](ch01.html#id567)) 我将应用分为八个组，如[表 1-3](#ch01_table_3_1730130814941550)所示。这里有限的列表最好作为参考。当你从[第
    2 章](ch02.html#ch02_understanding_foundation_models_1730147895571359)中了解更多关于如何构建基础模型以及如何在[第
    3 章](ch03.html#ch03a_evaluation_methodology_1730150757064067)中评估它们时，你也将能够更好地了解基础模型可以和应该用于哪些应用场景。
- en: Table 1-3\. Common generative AI use cases across consumer and enterprise applications.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1-3\. 消费者和企业应用中常见的生成式 AI 应用场景。
- en: '| Category | Examples of consumer use cases | Examples of enterprise use cases
    |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 类别 | 消费者应用场景示例 | 企业应用场景示例 |'
- en: '| --- | --- | --- |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Coding | Coding | Coding |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 编码 | 编码 | 编码 |'
- en: '| Image and video production | Photo and video editing Design | Presentation
    Ad generation |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 图像和视频制作 | 照片和视频编辑 设计 | 演示文稿 广告生成 |'
- en: '| Writing | Email Social media and blog posts | Copywriting, search engine
    optimization (SEO) Reports, memos, design docs |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 写作 | 电子邮件 社交媒体和博客文章 | 复写，搜索引擎优化（SEO） 报告，备忘录，设计文档 |'
- en: '| Education | Tutoring Essay grading | Employee onboarding Employee upskill
    training |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 教育 | 家庭教师 作业评分 | 员工入职 员工技能提升培训 |'
- en: '| Conversational bots | General chatbot AI companion | Customer support Product
    copilots |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 对话式机器人 | 通用聊天机器人 AI 伴侣 | 客户支持 产品共同飞行员 |'
- en: '| Information aggregation | Summarization Talk-to-your-docs | Summarization
    Market research |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 信息聚合 | 摘要 文档咨询 | 摘要 市场研究 |'
- en: '| Data organization | Image search [Memex](https://en.wikipedia.org/wiki/Memex)
    | Knowledge management Document processing |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 数据组织 | 图像搜索 [Memex](https://en.wikipedia.org/wiki/Memex) | 知识管理 文档处理 |'
- en: '| Workflow automation | Travel planning Event planning | Data extraction, entry,
    and annotation Lead generation |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 工作流程自动化 | 旅行计划 活动策划 | 数据提取，输入和标注 领导生成 |'
- en: Because foundation models are general, applications built on top of them can
    solve many problems. This means that an application can belong to more than one
    category. For example, a bot can provide companionship and aggregate information.
    An application can help you extract structured data from a PDF and answer questions
    about that PDF.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 因为基础模型是通用的，建立在它们之上的应用可以解决许多问题。这意味着一个应用可以属于多个类别。例如，一个机器人可以提供陪伴和聚合信息。一个应用可以帮助您从
    PDF 中提取结构化数据并回答有关该 PDF 的问题。
- en: '[Figure 1-7](#ch01_figure_7_1730130814920012) shows the distribution of these
    use cases among the 205 open source applications. Note that the small percentage
    of education, data organization, and writing use cases doesn’t mean that these
    use cases aren’t popular. It just means that these applications aren’t open source.
    Builders of these applications might find them more suitable for enterprise use
    cases.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[图1-7](#ch01_figure_7_1730130814920012)显示了这些用例在205个开源应用程序中的分布情况。请注意，教育和数据组织以及写作用例所占的百分比很小，并不意味着这些用例不受欢迎。这仅仅意味着这些应用程序不是开源的。这些应用程序的构建者可能会发现它们更适合企业用例。'
- en: '![A pie chart with different colored circles'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '![一个带有不同颜色圆圈的饼图'
- en: Description automatically generated](assets/aien_0107.png)
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '[自动生成的描述](assets/aien_0107.png)'
- en: Figure 1-7\. Distribution of use cases in the 205 open source repositories on
    GitHub.
  id: totrans-167
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-7。GitHub上205个开源仓库中用例的分布
- en: The enterprise world generally prefers applications with lower risks. For example,
    a [2024 a16z Growth report](https://oreil.ly/XWeDt) showed that companies are
    faster to deploy internal-facing applications (internal knowledge management)
    than external-facing applications (customer support chatbots), as shown in [Figure 1-8](#ch01_figure_8_1730130814920037).
    Internal applications help companies develop their AI engineering expertise while
    minimizing the risks associated with data privacy, compliance, and potential catastrophic
    failures. Similarly, while foundation models are open-ended and can be used for
    any task, many applications built on top of them are still close-ended, such as
    classification. Classification tasks are easier to evaluate, which makes their
    risks easier to estimate.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 企业界通常更喜欢风险较低的应用程序。例如，一份2024年的a16z增长报告([2024 a16z Growth report](https://oreil.ly/XWeDt))显示，公司部署面向内部的应用程序（内部知识管理）比部署面向外部应用程序（客户支持聊天机器人）要快，如图[图1-8](#ch01_figure_8_1730130814920037)所示。内部应用程序有助于公司发展其AI工程专业知识，同时最大限度地降低与数据隐私、合规性和潜在灾难性故障相关的风险。同样，虽然基础模型是开放式的，可以用于任何任务，但许多建立在它们之上的应用程序仍然是封闭式的，例如分类。分类任务更容易评估，这使得其风险更容易估计。
- en: '![A screenshot of a graph'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '![一个图表的截图'
- en: Description automatically generated](assets/aien_0108.png)
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[自动生成的描述](assets/aien_0108.png)'
- en: Figure 1-8\. Companies are more willing to deploy internal-facing applications
  id: totrans-171
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-8。公司更愿意部署面向内部的应用程序
- en: Even after seeing hundreds of AI applications, I still find new applications
    that surprise me every week. In the early days of the internet, few people foresaw
    that the dominating use case on the internet one day would be social media. As
    we learn to make the most out of AI, the use case that will eventually dominate
    might surprise us. With luck, the surprise will be a good one.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 即使看到成百上千的AI应用程序，我每周仍然会发现让我惊讶的新应用。在互联网的早期，很少有人预见有一天互联网上占主导地位的用例将是社交媒体。随着我们学会充分利用AI，最终将占主导地位的用例可能会让我们感到惊讶。幸运的话，这个惊喜将会是好的。
- en: Coding
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编码
- en: In multiple generative AI surveys, coding is hands down the most popular use
    case. AI coding tools are popular both because AI is good at coding and because
    early AI engineers are coders who are more exposed to coding challenges.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在多次生成式AI调查中，编码无疑是最受欢迎的用例。AI编码工具之所以受欢迎，一方面是因为AI擅长编码，另一方面是因为早期的AI工程师大多是程序员，他们更多地接触到了编码挑战。
- en: One of the earliest successes of foundation models in production is the code
    completion tool GitHub Copilot, whose [annual recurring revenue crossed $100 million](https://oreil.ly/Xamik)
    only two years after its launch. As of this writing, AI-powered coding startups
    have raised hundreds of millions of dollars, with [Magic raising $320 million](https://oreil.ly/t0xDf)
    and [Anysphere raising $60 million](https://oreil.ly/BW5Hk), both in August 2024\.
    Open source coding tools like [gpt-engineer](https://github.com/gpt-engineer-org/gpt-engineer)
    and [screenshot-to-code](https://github.com/abi/screenshot-to-code) both got 50,000
    stars on GitHub within a year, and many more are being rapidly introduced.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 基础模型在生产中最早的成功之一是GitHub Copilot代码补全工具，其[年度经常性收入在推出后仅两年就超过了1亿美元](https://oreil.ly/Xamik)。截至本文撰写时，AI驱动的编码初创公司已经筹集了数亿美元，其中[Magic筹集了3.2亿美元](https://oreil.ly/t0xDf)和[Anysphere筹集了6000万美元](https://oreil.ly/BW5Hk)，两者均在2024年8月。开源编码工具如[gpt-engineer](https://github.com/gpt-engineer-org/gpt-engineer)和[screenshot-to-code](https://github.com/abi/screenshot-to-code)在GitHub上一年内都获得了50,000颗星，还有更多正在迅速推出。
- en: 'Other than tools that help with general coding, many tools specialize in certain
    coding tasks. Here are examples of these tasks:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 除了帮助一般编码的工具外，许多工具专门用于某些编码任务。以下是一些这些任务的例子：
- en: Extracting structured data from web pages and PDFs ([AgentGPT](https://github.com/reworkd/AgentGPT))
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从网页和 PDF 中提取结构化数据 ([AgentGPT](https://github.com/reworkd/AgentGPT))
- en: Converting English to code ([DB-GPT](https://github.com/eosphoros-ai/DB-GPT),
    [SQL Chat](https://github.com/sqlchat/sqlchat), [PandasAI](https://github.com/Sinaptik-AI/pandas-ai))
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将英语转换为代码 ([DB-GPT](https://github.com/eosphoros-ai/DB-GPT), [SQL Chat](https://github.com/sqlchat/sqlchat),
    [PandasAI](https://github.com/Sinaptik-AI/pandas-ai))
- en: Given a design or a screenshot, generating code that will render into a website
    that looks like the given image (screenshot-to-code, [draw-a-ui](https://github.com/sawyerhood/draw-a-ui))
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给定一个设计或截图，生成将渲染成类似给定图像（截图转代码，[draw-a-ui](https://github.com/sawyerhood/draw-a-ui)）的网站上的代码
- en: Translating from one programming language or framework to another ([GPT-Migrate](https://github.com/joshpxyne/gpt-migrate),
    [AI Code Translator](https://github.com/mckaywrigley/ai-code-translator))
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将一种编程语言或框架翻译成另一种 ([GPT-Migrate](https://github.com/joshpxyne/gpt-migrate), [AI
    Code Translator](https://github.com/mckaywrigley/ai-code-translator))
- en: Writing documentation ([Autodoc](https://github.com/context-labs/autodoc))
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写文档 ([Autodoc](https://github.com/context-labs/autodoc))
- en: Creating tests ([PentestGPT](https://github.com/GreyDGL/PentestGPT))
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建测试 ([PentestGPT](https://github.com/GreyDGL/PentestGPT))
- en: Generating commit messages ([AI Commits](https://github.com/Nutlope/aicommits))
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成提交信息 ([AI Commits](https://github.com/Nutlope/aicommits))
- en: It’s clear that AI can do many software engineering tasks. The question is whether
    AI can automate software engineering altogether. At one end of the spectrum, [Jensen
    Huang, CEO of NVIDIA](https://oreil.ly/zUpGu), predicts that AI will replace human
    software engineers and that we should stop saying kids should learn to code. In
    a leaked recording, [AWS CEO Matt Garman](https://oreil.ly/Hz_3i) shared that
    in the near future, most developers will stop coding. He doesn’t mean it as the
    end of software developers; it’s just that their jobs will change.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 很明显，人工智能可以完成许多软件工程任务。问题是人工智能是否可以完全自动化软件工程。在光谱的一端，[英伟达(NVIDIA)首席执行官黄仁勋](https://oreil.ly/zUpGu)预测，人工智能将取代人类软件工程师，我们应该停止说孩子们应该学习编程。在一篇泄露的录音中，[AWS
    首席执行官马特·加曼](https://oreil.ly/Hz_3i)表示，在不久的将来，大多数开发者将停止编码。他并不是说软件开发者会消失；只是他们的工作会发生变化。
- en: At the other end are many software engineers who are convinced that they will
    never be replaced by AI, both for technical and emotional reasons (people don’t
    like admitting that they can be replaced).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一端，许多软件工程师坚信他们永远不会被人工智能取代，无论是从技术还是情感上（人们不喜欢承认自己可以被取代）。
- en: Software engineering consists of many tasks. AI is better at some than others.
    [McKinsey](https://oreil.ly/aqUmX) researchers found that AI can help developers
    be twice as productive for documentation, and 25–50% more productive for code
    generation and code refactoring. Minimal productivity improvement was observed
    for highly complex tasks, as shown in [Figure 1-9](#ch01_figure_9_1730130814920060).
    In my conversations with developers of AI coding tools, many told me that they’ve
    noticed that AI is much better at frontend development than backend development.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 软件工程包括许多任务。人工智能在某些任务上比其他任务做得更好。麦肯锡([McKinsey](https://oreil.ly/aqUmX))的研究人员发现，人工智能可以帮助开发者将文档的效率提高一倍，在代码生成和代码重构方面提高
    25-50% 的效率。对于高度复杂的任务，观察到的最小生产力提升，如图 1-9([Figure 1-9](#ch01_figure_9_1730130814920060))
    所示。在与人工智能编码工具的开发者交谈中，许多人告诉我，他们注意到人工智能在前端开发方面比后端开发做得更好。
- en: '![A graph of blue and white bars'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '![蓝色和白色条形的图表'
- en: Description automatically generated](assets/aien_0109.png)
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](assets/aien_0109.png)
- en: Figure 1-9\. AI can help developers be significantly more productive, especially
    for simple tasks, but this applies less for highly complex tasks. Data by McKinsey.
  id: totrans-189
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-9\. 人工智能可以帮助开发者显著提高生产力，尤其是在简单任务上，但对于高度复杂的任务，这种效果就不那么明显了。数据来源：麦肯锡。
- en: Regardless of whether AI will replace software engineers, AI can certainly make
    them more productive. This means that companies can now accomplish more with fewer
    engineers. AI can also disrupt the outsourcing industry, as outsourced tasks tend
    to be simpler ones outside of a company’s core business.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 无论人工智能是否会取代软件工程师，人工智能肯定可以使他们更加高效。这意味着公司现在可以用更少的工程师完成更多的工作。人工智能还可以颠覆外包行业，因为外包的任务往往是公司核心业务之外更简单的任务。
- en: Image and Video Production
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像和视频制作
- en: Thanks to its probabilistic nature, AI is great for creative tasks. Some of
    the most successful AI startups are creative applications, such as Midjourney
    for image generation, Adobe Firefly for photo editing, and Runway, Pika Labs,
    and Sora for video generation. In late 2023, at one and a half years old, [Midjourney](https://oreil.ly/EAzCl)
    had already generated $200 million in annual recurring revenue. As of December
    2023, among the top 10 free apps for Graphics & Design on the Apple App Store,
    half have AI in their names. I suspect that soon, graphics and design apps will
    incorporate AI by default, and they’ll no longer need the word “AI” in their names.
    [Chapter 2](ch02.html#ch02_understanding_foundation_models_1730147895571359) discusses
    the probabilistic nature of AI in more detail.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 由于其概率性质，AI非常适合创意任务。一些最成功的AI初创公司是创意应用，例如Midjourney用于图像生成、Adobe Firefly用于照片编辑，以及Runway、Pika
    Labs和Sora用于视频生成。到2023年底，Midjourney成立不到一年半，已经创造了2亿美元的年度经常性收入。截至2023年12月，在苹果App
    Store图形与设计类前10名免费应用中，有一半在其名称中包含AI。我怀疑不久的将来，图形和设计应用将默认集成AI，它们的名字将不再需要包含“AI”这个词。[第二章](ch02.html#ch02_understanding_foundation_models_1730147895571359)更详细地讨论了AI的概率性质。
- en: It’s now common to use AI to generate profile pictures for social media, from
    LinkedIn to TikTok. Many candidates believe that AI-generated headshots can help
    them put their best foot forward and [increase their chances of landing a job](https://oreil.ly/fZLVg).
    The perception of AI-generated profile pictures has changed significantly. In
    2019, [Facebook](https://oreil.ly/WNqUw) banned accounts using AI-generated profile
    photos for safety reasons. In 2023, many social media apps provide tools that
    let users use AI to generate profile photos.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在在社交媒体上使用AI生成个人头像已经变得很常见，从LinkedIn到TikTok。许多求职者认为，AI生成的头像可以帮助他们展示最好的自己，并[增加找到工作的机会](https://oreil.ly/fZLVg)。人们对AI生成头像的看法已经发生了显著变化。2019年，[Facebook](https://oreil.ly/WNqUw)出于安全考虑禁止使用AI生成的头像的账户。到了2023年，许多社交媒体应用提供了让用户使用AI生成头像的工具。
- en: For enterprises, ads and marketing have been quick to incorporate AI.^([12](ch01.html#id572))
    AI can be used to generate promotional images and videos directly. It can help
    brainstorm ideas or generate first drafts for human experts to iterate upon. You
    can use AI to generate multiple ads and test to see which one works the best for
    the audience. AI can generate variations of your ads according to seasons and
    locations. For example, you can use AI to change leaf colors during fall or add
    snow to the ground during winter.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 对于企业来说，广告和营销迅速地采用了AI。[^([12](ch01.html#id572))] AI可以直接生成促销图像和视频。它可以帮助头脑风暴想法或为人类专家生成初步草案进行迭代。你可以使用AI生成多个广告并测试哪个最适合受众。AI可以根据季节和地点生成你广告的变体。例如，你可以在秋天使用AI改变树叶颜色，或在冬天给地面添加雪。
- en: Writing
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 写作
- en: AI has long been used to aid writing. If you use a smartphone, you’re probably
    familiar with autocorrect and auto-completion, both powered by AI. Writing is
    an ideal application for AI because we do it a lot, it can be quite tedious, and
    we have a high tolerance for mistakes. If a model suggests something that you
    don’t like, you can just ignore it.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: AI长期以来一直被用来辅助写作。如果你使用智能手机，你可能熟悉自动纠错和自动完成，这两者都是由AI驱动的。写作是AI的理想应用，因为我们经常这样做，它可能相当枯燥，而且我们对错误有很高的容忍度。如果一个模型建议了你不喜欢的东西，你只需忽略它即可。
- en: It’s not a surprise that LLMs are good at writing, given that they are trained
    for text completion. To study the impact of ChatGPT on writing, an MIT study ([Noy
    and Zhang, 2023](https://oreil.ly/IzQ6F)) assigned occupation-specific writing
    tasks to 453 college-educated professionals and randomly exposed half of them
    to ChatGPT. Their results show that among those exposed to ChatGPT, the average
    time taken decreased by 40% and output quality rose by 18%. ChatGPT helps close
    the gap in output quality between workers, which means that it’s more helpful
    to those with less inclination for writing. Workers exposed to ChatGPT during
    the experiment were 2 times as likely to report using it in their real job two
    weeks after the experiment and 1.6 times as likely two months after that.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到 LLMs 是为了文本补全而训练的，它们擅长写作也就不足为奇了。为了研究 ChatGPT 对写作的影响，麻省理工学院的一项研究（[Noy 和 Zhang，2023](https://oreil.ly/IzQ6F)）将特定职业的写作任务分配给
    453 名受过大学教育的专业人士，并将其中一半人随机暴露于 ChatGPT。他们的结果显示，在接触 ChatGPT 的人中，平均用时减少了 40%，输出质量提高了
    18%。ChatGPT 有助于缩小工人之间输出质量的差距，这意味着它对写作倾向较弱的人更有帮助。在实验中接触 ChatGPT 的工人，在实验两周后报告在真实工作中使用
    ChatGPT 的可能性是未接触者的两倍，两个月后是 1.6 倍。
- en: For consumers, the use cases are obvious. Many use AI to help them communicate
    better. You can be angry in an email and ask AI to make it pleasant. You can give
    it bullet points and get back complete paragraphs. Several people claimed they
    no longer send an important email without asking AI to improve it first.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 对于消费者来说，使用案例很明显。许多人使用 AI 来帮助他们更好地沟通。你可以在电子邮件中表达愤怒，并让 AI 使其变得愉快。你可以给出要点，然后得到完整的段落。有几个人声称他们现在在发送重要邮件之前，都会先让
    AI 进行改进。
- en: Students are using AI to write essays. Writers are using AI to write books.^([13](ch01.html#id574))
    Many startups already use AI to generate children’s, fan fiction, romance, and
    fantasy books. Unlike traditional books, AI-generated books can be interactive,
    as a book’s plot can change depending on a reader’s preference. This means that
    readers can actively participate in creating the story they are reading. A children’s
    reading app identifies the words that a child has trouble with and generates stories
    centered around these words.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 学生正在使用 AI 来撰写论文。作家正在使用 AI 来创作书籍.^([13](ch01.html#id574)) 许多初创公司已经使用 AI 来生成儿童、同人小说、浪漫和奇幻书籍。与传统的书籍不同，AI
    生成的书籍可以互动，因为一本书的情节可以根据读者的偏好而改变。这意味着读者可以积极参与创造他们正在阅读的故事。一个儿童阅读应用会识别孩子有困难的地方，并围绕这些单词生成故事。
- en: Note-taking and email apps like Google Docs, Notion, and Gmail all use AI to
    help users improve their writing. [Grammarly](https://arxiv.org/abs/2305.09857),
    a writing assistant app, finetunes a model to make users’ writing more fluent,
    coherent, and clear.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 记笔记和电子邮件应用，如 Google Docs、Notion 和 Gmail，都使用 AI 帮助用户提升写作能力。[Grammarly](https://arxiv.org/abs/2305.09857)，一款写作助手应用，通过微调模型使用户的写作更加流畅、连贯和清晰。
- en: AI’s ability to write can also be abused. In 2023, the [New York Times](https://oreil.ly/LB72P)
    reported that Amazon was flooded with shoddy AI-generated travel guidebooks, each
    outfitted with an author bio, a website, and rave reviews, all AI-generated.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: AI 的写作能力也可能被滥用。2023 年，[《纽约时报》](https://oreil.ly/LB72P) 报道称，亚马逊充斥着质量低劣的 AI 生成的旅行指南书籍，每本书都配有作者简介、网站和好评，这些都是
    AI 生成的。
- en: For enterprises, AI writing is common in sales, marketing, and general team
    communication. Many managers told me they’ve been using AI to help them write
    performance reports. AI can help craft effective cold outreach emails, ad copywriting,
    and product descriptions. Customer relationship management (CRM) apps like HubSpot
    and Salesforce also have tools for enterprise users to generate web content and
    outreach emails.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 对于企业来说，AI 写作在销售、营销和团队沟通中很常见。许多经理告诉我，他们一直在使用 AI 帮助他们撰写绩效报告。AI 可以帮助撰写有效的冷邮件、广告文案和产品描述。客户关系管理（CRM）应用如
    HubSpot 和 Salesforce 也为企业用户提供生成网页内容和外联邮件的工具。
- en: AI seems particularly good with SEO, perhaps because many AI models are trained
    with data from the internet, which is populated with SEO-optimized text. AI is
    so good at SEO that it has enabled a new generation of content farms. These farms
    set up junk websites and fill them with AI-generated content to get them to rank
    high on Google to drive traffic to them. Then they sell advertising spots through
    ad exchanges. In June 2023, [NewsGuard](https://oreil.ly/mZKjr) identified almost
    400 ads from 141 popular brands on junk AI-generated websites. One of those junk
    websites produced 1,200 articles a day. Unless something is done to curtail this,
    the future of internet content will be AI-generated, and it’ll be pretty bleak.^([14](ch01.html#id575))
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](assets/aien_0110.png)
- en: Education
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 教育
- en: Whenever ChatGPT is down, OpenAI’s Discord server is flooded with students complaining
    about being unable to complete their homework. Several education boards, including
    the New York City Public Schools and the Los Angeles Unified School District,
    were quick to [ban ChatGPT](https://oreil.ly/pqI5z) for fear of students using
    it for cheating, but [reversed their decisions](https://oreil.ly/nxtzw) just a
    few months later.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 每当ChatGPT出现故障时，OpenAI的Discord服务器就会被学生抱怨无法完成作业的投诉所淹没。包括纽约市公立学校和洛杉矶联合学区在内的几个教育委员会迅速[禁止ChatGPT](https://oreil.ly/pqI5z)，担心学生会用它来作弊，但几个月后[撤销了他们的决定](https://oreil.ly/nxtzw)。
- en: Instead of banning AI, schools could incorporate it to help students learn faster.
    AI can summarize textbooks and generate personalized lecture plans for each student.
    I find it strange that ads are personalized because we know everyone is different,
    but education is not. AI can help adapt the materials to the format best suited
    for each student. Auditory learners can ask AI to read the materials out loud.
    Students who love animals can use AI to adapt visualizations to feature more animals.
    Those who find it easier to read code than math equations can ask AI to translate
    math equations into code.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 学校与其禁止人工智能，不如将其融入教学中以帮助学生更快地学习。人工智能可以总结教科书并为每个学生生成个性化的讲义。我发现广告个性化很奇怪，因为我们知道每个人都是不同的，但教育不是。人工智能可以帮助调整材料，使其最适合每个学生。听觉学习者可以让人工智能大声朗读材料。喜欢动物的学生可以使用人工智能来调整可视化，使其包含更多动物。那些觉得阅读代码比数学方程式更容易的人可以让人工智能将数学方程式翻译成代码。
- en: AI is especially helpful for language learning, as you can ask AI to roleplay
    different practice scenarios. [Pajak and Bicknell (Duolingo, 2022)](https://oreil.ly/C8kmI)
    found that out of four stages of course creation, lesson personalization is the
    stage that can benefit the most from AI, as shown in [Figure 1-10](#ch01_figure_10_1730130814920091).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](assets/aien_0110.png)
- en: '![A white paper with blue text'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能似乎特别擅长SEO，这可能是因为许多人工智能模型都是用来自互联网的数据进行训练的，而互联网上充满了SEO优化的文本。人工智能在SEO方面做得如此之好，以至于它已经催生了一代新的内容农场。这些农场建立垃圾网站，并用人工智能生成的内容填充它们，以便在Google上获得高排名，从而吸引流量。然后他们通过广告交易所出售广告位。2023年6月，[NewsGuard](https://oreil.ly/mZKjr)识别出141个流行品牌在垃圾人工智能生成网站上发布的近400条广告。其中一家垃圾网站每天产生1,200篇文章。除非采取措施遏制这种情况，否则互联网内容的未来将是人工智能生成的，而且前景会很暗淡。[14](ch01.html#id575)
- en: Description automatically generated](assets/aien_0110.png)
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能在语言学习方面特别有用，你可以要求人工智能进行不同场景的模拟练习。[Pajak和Bicknell（Duolingo，2022）](https://oreil.ly/C8kmI)发现，在课程创建的四个阶段中，课程个性化是能够从人工智能中获得最大益处的阶段，如图1-10所示。
- en: Figure 1-10\. AI can be used throughout all four stages of course creation at
    Duolingo, but it’s the most helpful in the personalization stage. Image from Pajak
    and Bicknell (Duolingo, 2022).
  id: totrans-210
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-10\. 在Duolingo的整个四个课程创建阶段中都可以使用人工智能，但在个性化阶段最为有用。图片来自Pajak和Bicknell（Duolingo，2022）。
- en: AI can generate quizzes, both multiple-choice and open-ended, and evaluate the
    answers. AI can become a debate partner as it’s much better at presenting different
    views on the same topic than the average human. For example, [Khan Academy](https://oreil.ly/tC7-g)
    offers [AI-powered](https://oreil.ly/_N1JR) teaching assistants to students and
    course assistants to teachers. An innovative teaching method I’ve seen is that
    teachers assign AI-generated essays for students to find and correct mistakes.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能可以生成测验，包括多项选择和开放式问题，并评估答案。人工智能可以成为辩论伙伴，因为它在呈现同一主题的不同观点方面比普通人要好得多。例如，[可汗学院](https://oreil.ly/tC7-g)为学生提供[人工智能辅助](https://oreil.ly/_N1JR)的教学助理，为教师提供课程助理。我看到的一种创新教学方法是，教师布置人工智能生成的论文让学生去寻找和纠正错误。
- en: While many education companies embrace AI to build better products, many find
    their lunches taken by AI. For example, Chegg, a company that helps students with
    their homework, saw its share price plummet from $28 when ChatGPT launched in
    November 2022 to $2 in September 2024, as [students have been turning to AI for
    help](https://oreil.ly/Y-hBW).
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 当许多教育公司拥抱AI来构建更好的产品时，许多公司发现他们的午餐被AI抢走了。例如，帮助学生的Chegg公司，在ChatGPT于2022年11月推出时，股价从28美元暴跌至2024年9月的2美元，因为[学生已经开始转向AI寻求帮助](https://oreil.ly/Y-hBW)。
- en: If the risk is that AI can replace many skills, the opportunity is that AI can
    be used as a tutor to learn any skill. For many skills, AI can help someone get
    up to speed quickly and then continue learning on their own to become better than
    AI.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 如果风险是AI可以取代许多技能，那么机会是AI可以用作导师来学习任何技能。对于许多技能，AI可以帮助某人快速掌握，然后继续自学，以超越AI。
- en: Conversational Bots
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对话机器人
- en: Conversational bots are versatile. They can help us find information, explain
    concepts, and brainstorm ideas. AI can be your companion and therapist. It can
    emulate personalities, letting you talk to a digital copy of anyone you like.
    Digital girlfriends and boyfriends have become weirdly popular in an incredibly
    short amount of time. Many are already spending more time talking to bots than
    to humans (see the discussions [here](https://oreil.ly/dZbym) and [here](https://oreil.ly/svWj8)).
    Some are worried that AI will [ruin](https://oreil.ly/SNme7) [dating](https://oreil.ly/Jbt4R).
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 对话机器人是多才多艺的。它们可以帮助我们找到信息，解释概念，激发想法。AI可以成为你的伴侣和治疗师。它可以模仿个性，让你与任何你喜欢的人的数字副本交谈。数字男女朋友在极短的时间内变得异常流行。许多人已经花更多的时间与机器人交谈，而不是与人交谈（参见[这里](https://oreil.ly/dZbym)和[这里](https://oreil.ly/svWj8)的讨论）。有些人担心AI会[破坏](https://oreil.ly/SNme7)[约会](https://oreil.ly/Jbt4R)。
- en: In research, people have also found that they can use a group of conversational
    bots to simulate a society, enabling them to conduct studies on social dynamics
    ([Park et al., 2023](https://arxiv.org/abs/2304.03442)).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究中，人们还发现他们可以使用一组对话机器人来模拟一个社会，使他们能够对社会动态进行研究 ([Park et al., 2023](https://arxiv.org/abs/2304.03442))。
- en: For enterprises, the most popular bots are customer support bots. They can help
    companies save costs while improving customer experience because they can respond
    to users sooner than human agents. AI can also be product copilots that guide
    customers through painful and confusing tasks such as filing insurance claims,
    doing taxes, or looking up corporate policies.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 对于企业来说，最受欢迎的机器人是客户支持机器人。它们可以帮助公司节省成本，同时提高客户体验，因为它们可以比人类代理更快地响应用户。AI还可以作为产品副驾驶，引导客户完成痛苦和令人困惑的任务，例如提交保险索赔、做税务或查找公司政策。
- en: The success of ChatGPT prompted a wave of text-based conversational bots. However,
    text isn’t the only interface for conversational agents. Voice assistants such
    as Google Assistant, Siri, and Alexa have been around for years.^([15](ch01.html#id584))
    3D conversational bots are already common in games and gaining traction in retail
    and marketing.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT的成功引发了一波基于文本的对话机器人的热潮。然而，文本并不是对话代理的唯一界面。像Google Assistant、Siri和Alexa这样的语音助手已经存在多年。[15](ch01.html#id584)
    3D对话机器人已经在游戏领域变得很常见，并在零售和营销领域获得了势头。
- en: One use case of AI-powered 3D characters is smart NPCs, non-player characters
    (see NVIDIA’s demos of [Inworld](https://oreil.ly/yn-DN) and [Convai](https://oreil.ly/zAHwz)).^([16](ch01.html#id585))
    NPCs are essential for advancing the storyline of many games. Without AI, NPCs
    are typically scripted to do simple actions with a limited range of dialogues.
    AI can make these NPCs much smarter. Intelligent bots can change the dynamics
    of existing games like *The Sims* and *Skyrim* as well as enable new games never
    possible before.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: AI驱动的3D角色的一种用途是智能NPC，非玩家角色（参见NVIDIA的[Inworld](https://oreil.ly/yn-DN)和[Convai](https://oreil.ly/zAHwz)演示）。[16](ch01.html#id585)
    NPC对于推进许多游戏的故事情节至关重要。没有AI，NPC通常被编写成执行简单的动作，对话范围有限。AI可以使这些NPC变得更加智能。智能机器人可以改变现有游戏如*模拟人生*和*天际*的动态，以及使以前从未可能的新游戏成为可能。
- en: Information Aggregation
  id: totrans-220
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 信息聚合
- en: Many people believe that our success depends on our ability to filter and digest
    useful information. However, keeping up with emails, Slack messages, and news
    can sometimes be overwhelming. Luckily, AI came to the rescue. AI has proven to
    be capable of aggregating information and summarizing it. According to [Salesforce’s
    2023 Generative AI Snapshot Research](https://oreil.ly/74soT), 74% of generative
    AI users use it to distill complex ideas and summarize information.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 许多人认为我们的成功取决于我们过滤和消化有用信息的能力。然而，跟上电子邮件、Slack消息和新闻有时可能会感到压倒性。幸运的是，人工智能及时出现。人工智能已被证明能够聚合信息并总结信息。根据[Salesforce的2023年生成式AI快照研究](https://oreil.ly/74soT)，74%的生成式AI用户使用它来提炼复杂思想和总结信息。
- en: For consumers, many applications can process your documents—contracts, disclosures,
    papers—and let you retrieve information in a conversational manner. This use case
    is also called *talk-to-your-docs*. AI can help you summarize websites, research,
    and create reports on the topics of your choice. During the process of writing
    this book, I found AI helpful for summarizing and comparing papers.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 对于消费者来说，许多应用程序可以处理您的文档——合同、披露、论文——并以对话的方式让您检索信息。这种用例也被称为*与文档对话*。人工智能可以帮助您总结网站、研究和创建关于您选择主题的报告。在撰写这本书的过程中，我发现人工智能在总结和比较论文方面非常有帮助。
- en: Information aggregation and distillation are essential for enterprise operations.
    More efficient information aggregation and dissimilation can help an organization
    become leaner, as it reduces the burden on middle management. When [Instacart](https://oreil.ly/Qq5-g)
    launched an internal prompt marketplace, it discovered that one of the most popular
    prompt templates is “Fast Breakdown”. This template asks AI to summarize meeting
    notes, emails, and Slack conversations with facts, open questions, and action
    items. These action items can then be automatically inserted into a project tracking
    tool and assigned to the right owners.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 信息聚合和提炼对企业运营至关重要。更有效的信息聚合和提炼可以帮助组织变得更加精简，因为它减轻了中层管理的负担。当[Instacart](https://oreil.ly/Qq5-g)推出内部提示市场时，它发现最受欢迎的提示模板之一是“快速分解”。这个模板要求人工智能用事实、开放问题和行动项来总结会议记录、电子邮件和Slack对话。然后，这些行动项可以自动插入到项目跟踪工具中，并分配给正确的负责人。
- en: AI can help you surface the critical information about your potential customers
    and run analyses on your competitors.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能可以帮助您揭示有关潜在客户的关键信息，并对您的竞争对手进行分析。
- en: The more information you gather, the more important it is to organize it. Information
    aggregation goes hand in hand with data organization.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 您收集的信息越多，组织它们的重要性就越大。信息聚合与数据组织相辅相成。
- en: Data Organization
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据组织
- en: One thing certain about the future is that we’ll continue producing more and
    more data. Smartphone users will continue taking photos and videos. Companies
    will continue to log everything about their products, employees, and customers.
    Billions of contracts are being created each year. Photos, videos, logs, and PDFs
    are all unstructured or semistructured data. It’s essential to organize all this
    data in a way that can be searched later.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 关于未来的一件事是，我们将继续产生越来越多的数据。智能手机用户将继续拍照和录像。公司将继续记录有关其产品、员工和客户的一切。每年都会创建数十亿份合同。照片、视频、日志和PDF都是非结构化或半结构化数据。将所有这些数据组织成可以稍后搜索的方式至关重要。
- en: 'AI can help with exactly that. AI can automatically generate text descriptions
    about images and videos, or help match text queries with visuals that match those
    queries. Services like Google Photos are already using AI to surface images that
    match search queries.^([17](ch01.html#id592)) Google Image Search goes a step
    further: if there’s no existing image matching users’ needs, it can generate some.'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能可以在这方面提供帮助。人工智能可以自动生成关于图像和视频的文本描述，或帮助匹配与查询匹配的视觉内容。像Google Photos这样的服务已经使用人工智能来揭示与搜索查询匹配的图像。[17](ch01.html#id592)
    Google图像搜索更进一步：如果不存在与用户需求匹配的现有图像，它可以生成一些。
- en: AI is very good with data analysis. It can write programs to generate data visualization,
    identify outliers, and make predictions like revenue forecasts.^([18](ch01.html#id593))
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能在数据分析方面非常出色。它可以编写程序生成数据可视化、识别异常值和进行预测，如收入预测。[18](ch01.html#id593)
- en: Enterprises can use AI to extract structured information from unstructured data,
    which can be used to organize data and help search it. Simple use cases include
    automatically extracting information from credit cards, driver’s licenses, receipts,
    tickets, contact information from email footers, and so on. More complex use cases
    include extracting data from contracts, reports, charts, and more. It’s estimated
    that the IDP, intelligent data processing, industry will reach [$12.81 billion
    by 2030](https://oreil.ly/vnDNK), growing 32.9% each year.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 企业可以使用人工智能从非结构化数据中提取结构化信息，这些信息可以用来组织数据并帮助搜索。简单的用例包括从信用卡、驾照、收据、票务、电子邮件页脚中的联系信息等自动提取信息。更复杂的用例包括从合同、报告、图表等中提取数据。据估计，智能数据处理（IDP）行业将在2030年达到[128.1亿美元](https://oreil.ly/vnDNK)，每年增长32.9%。
- en: Workflow Automation
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工作流程自动化
- en: Ultimately, AI should automate as much as possible. For end users, automation
    can help with boring daily tasks like booking restaurants, requesting refunds,
    planning trips, and filling out forms.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，人工智能应该尽可能地自动化。对于终端用户来说，自动化可以帮助处理一些无聊的日常任务，如预订餐厅、请求退款、规划旅行和填写表格。
- en: For enterprises, AI can automate repetitive tasks such as lead management, invoicing,
    reimbursements, managing customer requests, data entry, and so on. One especially
    exciting use case is using AI models to synthesize data, which can then be used
    to improve the models themselves. You can use AI to create labels for your data,
    looping in humans to improve the labels. We discuss data synthesis in [Chapter 8](ch08.html#ch08_dataset_engineering_1730130932019888).
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 对于企业来说，人工智能可以自动化重复性任务，如潜在客户管理、发票、报销、管理客户请求、数据录入等。一个特别令人兴奋的用例是使用人工智能模型合成数据，然后可以用这些数据来改进模型本身。你可以使用人工智能为你的数据创建标签，并引入人类来改进这些标签。我们在[第8章](ch08.html#ch08_dataset_engineering_1730130932019888)中讨论了数据合成。
- en: Access to external tools is required to accomplish many tasks. To book a restaurant,
    an application might need permission to open a search engine to look up the restaurant’s
    number, use your phone to make calls, and add appointments to your calendar. AIs
    that can plan and use tools are called *agents*. The level of interest around
    agents borders on obsession, but it’s not entirely unwarranted. AI agents have
    the potential to make every person vastly more productive and generate vastly
    more economic value. Agents are a central topic in [Chapter 6](ch06.html#ch06_rag_and_agents_1730157386571386).
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 完成许多任务需要访问外部工具。为了预订餐厅，一个应用程序可能需要权限打开搜索引擎查找餐厅的电话号码，使用你的手机打电话，并将预约添加到你的日历中。能够规划和使用工具的人工智能被称为*代理*。人们对代理的兴趣几乎到了痴迷的地步，但这并非毫无根据。人工智能代理有潜力使每个人的生产力大幅提高，并产生巨大的经济价值。代理是[第6章](ch06.html#ch06_rag_and_agents_1730157386571386)中的一个中心主题。
- en: It’s been a lot of fun looking into different AI applications. One of my favorite
    things to daydream about is the different applications I can build. However, not
    all applications should be built. The next section discusses what we should consider
    before building an AI application.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 探索不同的人工智能应用非常有趣。我最喜欢幻想的事情之一是我可以构建的不同应用。然而，并不是所有的应用都应该被构建。下一节将讨论在构建人工智能应用之前我们应该考虑什么。
- en: Planning AI Applications
  id: totrans-236
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计划人工智能应用
- en: Given the seemingly limitless potential of AI, it’s tempting to jump into building
    applications. If you just want to learn and have fun, jump right in. Building
    is one of the best ways to learn. In the early days of foundation models, several
    heads of AI told me that they encouraged their teams to experiment with AI applications
    to upskill themselves.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于人工智能看似无限的潜力，人们可能会迫不及待地开始构建应用程序。如果你只是想学习和娱乐，那就直接开始吧。构建是学习最好的方式之一。在基础模型早期，几位人工智能负责人告诉我，他们鼓励他们的团队尝试人工智能应用程序以提高技能。
- en: However, if you’re doing this for a living, it might be worthwhile to take a
    step back and consider why you’re building this and how you should go about it.
    It’s easy to build a cool demo with foundation models. It’s hard to create a profitable
    product.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你以此为生，可能值得退一步思考你为什么要构建这个，以及你应该如何着手。使用基础模型构建一个酷炫的演示很容易。但要创造一个有利可图的产物则很难。
- en: Use Case Evaluation
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用例评估
- en: 'The first question to ask is why you want to build this application. Like many
    business decisions, building an AI application is often a response to risks and
    opportunities. Here are a few examples of different levels of risks, ordered from
    high to low:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要问的问题是为什么你想开发这个应用程序。像许多商业决策一样，构建人工智能应用程序通常是对风险和机遇的回应。以下是一些不同层次的风险示例，按从高到低的顺序排列：
- en: '*If you don’t do this, competitors with AI can make you obsolete.* If AI poses
    a major existential threat to your business, incorporating AI must have the highest
    priority. In the 2023 [Gartner study](https://oreil.ly/gqi3d), 7% cited business
    continuity as their reason for embracing AI. This is more common for businesses
    involving document processing and information aggregation, such as financial analysis,
    insurance, and data processing. This is also common for creative work such as
    advertising, web design, and image production. You can refer to the 2023 OpenAI
    study, “GPTs are GPTs” ([Eloundou et al., 2023](https://arxiv.org/abs/2303.10130)),
    to see how industries rank in their exposure to AI.'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*如果你不这样做，拥有人工智能的竞争对手可能会使你过时。* 如果人工智能对你的业务构成重大的生存威胁，那么将人工智能纳入优先考虑范围是必须的。在2023年
    [Gartner 研究报告](https://oreil.ly/gqi3d)中，7% 的受访者将业务连续性作为他们采用人工智能的原因。这在涉及文档处理和信息聚合的业务中更为常见，例如财务分析、保险和数据处理。这在广告、网页设计和图像制作等创意工作中也很常见。你可以参考2023年
    OpenAI 的研究，“GPTs are GPTs” ([Eloundou 等人，2023](https://arxiv.org/abs/2303.10130))，以了解各行业在人工智能暴露度方面的排名。'
- en: '*If you don’t do this, you’ll miss opportunities to boost profits and productivity.*
    Most companies embrace AI for the opportunities it brings. AI can help in most,
    if not all, business operations. AI can make user acquisition cheaper by crafting
    more effective copywrites, product descriptions, and promotional visual content.
    AI can increase user retention by improving customer support and customizing user
    experience. AI can also help with sales lead generation, internal communication,
    market research, and competitor tracking.'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*如果你不这样做，你将错失提升利润和生产力的机会。* 大多数公司都拥抱人工智能带来的机遇。人工智能可以帮助大多数，如果不是所有业务运营。人工智能可以通过制作更有效的文案、产品描述和促销视觉内容来降低用户获取成本。人工智能可以通过改善客户支持和定制用户体验来提高用户保留率。人工智能还可以帮助销售线索生成、内部沟通、市场研究和竞争对手跟踪。'
- en: '*You’re unsure where AI will fit into your business yet, but you don’t want
    to be left behind.* While a company shouldn’t chase every hype train, many have
    failed by waiting too long to take the leap (cue Kodak, Blockbuster, and BlackBerry).
    Investing resources into understanding how a new, transformational technology
    can impact your business isn’t a bad idea if you can afford it. At bigger companies,
    this can be part of the R&D department.^([19](ch01.html#id599))'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*你还不确定人工智能将如何融入你的业务，但你不想落后。* 虽然公司不应该追逐每一个炒作的潮流，但许多公司因为等待太久才采取行动而失败（提示：柯达、百老汇和黑莓）。如果你负担得起，投资资源去理解一种新的、变革性的技术如何影响你的业务并不是一个坏主意。在更大的公司中，这可能是研发部门的一部分.^([19](ch01.html#id599))'
- en: Once you’ve found a good reason to develop this use case, you might consider
    whether you have to build it yourself. If AI poses an existential threat to your
    business, you might want to do AI in-house instead of outsourcing it to a competitor.
    However, if you’re using AI to boost profits and productivity, you might have
    plenty of buy options that can save you time and money while giving you better
    performance.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你找到了开发这个用例的好理由，你可能需要考虑是否必须自己构建它。如果你的业务面临生存威胁，你可能希望内部进行人工智能开发而不是外包给竞争对手。然而，如果你正在使用人工智能来提高利润和生产率，你可能有很多购买选择，这些选择可以为你节省时间和金钱，同时提供更好的性能。
- en: The role of AI and humans in the application
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人工智能和人类在应用中的作用
- en: 'What role AI plays in the AI product influences the application’s development
    and its requirements. [Apple](https://oreil.ly/Dz1HE) has a great document explaining
    different ways AI can be used in a product. Here are three key points relevant
    to the current discussion:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能在人工智能产品中的作用会影响应用程序的开发及其需求。[苹果](https://oreil.ly/Dz1HE) 有一个很好的文档，解释了人工智能在产品中可以以不同的方式使用。以下是当前讨论相关的三个关键点：
- en: Critical or complementary
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 临界或补充
- en: If an app can still work without AI, AI is complementary to the app. For example,
    Face ID wouldn’t work without AI-powered facial recognition, whereas Gmail would
    still work without Smart Compose.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个应用没有人工智能仍然可以工作，那么人工智能就是应用的补充。例如，没有人工智能驱动的面部识别，Face ID 就无法工作，而 Gmail 没有智能草稿功能仍然可以工作。
- en: The more critical AI is to the application, the more accurate and reliable the
    AI part has to be. People are more accepting of mistakes when AI isn’t core to
    the application.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: AI对应用程序越重要，AI部分的准确性和可靠性就必须越高。当AI不是应用程序的核心时，人们更愿意接受错误。
- en: Reactive or proactive
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 反应性或主动性
- en: A reactive feature shows its responses in reaction to users’ requests or specific
    actions, whereas a proactive feature shows its responses when there’s an opportunity
    for it. For example, a chatbot is reactive, whereas traffic alerts on Google Maps
    are proactive.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 反应性功能会在用户请求或特定动作的反应中展示其响应，而主动性功能会在有机会时展示其响应。例如，聊天机器人是反应性的，而谷歌地图上的交通警报是主动性的。
- en: Because reactive features are generated in response to events, they usually,
    but not always, need to happen fast. On the other hand, proactive features can
    be precomputed and shown opportunistically, so latency is less important.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 由于反应性功能是对事件做出的响应，它们通常需要快速发生，但并非总是如此。另一方面，主动性功能可以预先计算并在机会出现时展示，因此延迟不那么重要。
- en: Because users don’t ask for proactive features, they can view them as intrusive
    or annoying if the quality is low. Therefore, proactive predictions and generations
    typically have a higher quality bar.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 由于用户不会要求主动性功能，如果质量低，他们可能会将其视为侵扰或令人讨厌。因此，主动预测和生成通常有更高的质量标准。
- en: Dynamic or static
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 动态或静态
- en: Dynamic features are updated continually with user feedback, whereas static
    features are updated periodically. For example, Face ID needs to be updated as
    people’s faces change over time. However, object detection in Google Photos is
    likely updated only when Google Photos is upgraded.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 动态功能会根据用户反馈不断更新，而静态功能会定期更新。例如，面部识别需要根据人们随时间变化的面部进行更新。然而，谷歌照片中的对象检测可能只有在谷歌照片升级时才会更新。
- en: In the case of AI, dynamic features might mean that each user has their own
    model, continually finetuned on their data, or other mechanisms for personalization
    such as ChatGPT’s memory feature, which allows ChatGPT to remember each user’s
    preferences. However, static features might have one model for a group of users.
    If that’s the case, these features are updated only when the shared model is updated.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能的情况下，动态功能可能意味着每个用户都有自己的模型，他们的数据会不断微调，或者有其他个性化机制，例如ChatGPT的记忆功能，允许ChatGPT记住每个用户的偏好。然而，静态功能可能为用户组使用一个模型。如果是这样，这些功能仅在共享模型更新时才会更新。
- en: 'It’s also important to clarify the role of humans in the application. Will
    AI provide background support to humans, make decisions directly, or both? For
    example, for a customer support chatbot, AI responses can be used in different
    ways:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 也很重要的是要明确人类在应用程序中的作用。AI是否会为人类提供背景支持，直接做出决策，或者两者兼而有之？例如，对于客户支持聊天机器人，AI响应可以以不同的方式使用：
- en: AI shows several responses that human agents can reference to write faster responses.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI展示出几个响应，供人类代理参考以更快地撰写响应。
- en: AI responds only to simple requests and routes more complex requests to humans.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI只响应简单请求，并将更复杂的请求路由给人类。
- en: AI responds to all requests directly, without human involvement.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AI直接响应所有请求，无需人类参与。
- en: Involving humans in AI’s decision-making processes is called *human-in-the-loop*.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 将人类纳入人工智能的决策过程中被称为*人机交互*。
- en: 'Microsoft (2023) proposed a framework for gradually increasing AI automation
    in products that they call [Crawl-Walk-Run](https://oreil.ly/JW4_A):'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 微软（2023）提出了一种框架，用于逐步增加产品中的AI自动化，他们称之为[Crawl-Walk-Run](https://oreil.ly/JW4_A)：
- en: Crawl means human involvement is mandatory.
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “爬行”意味着人类参与是强制性的。
- en: Walk means AI can directly interact with internal employees.
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “步行”意味着AI可以直接与内部员工互动。
- en: Run means increased automation, potentially including direct AI interactions
    with external users.
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: “奔跑”意味着自动化程度提高，可能包括直接与外部用户进行AI交互。
- en: The role of humans can change over time as the quality of the AI system improves.
    For example, in the beginning, when you’re still evaluating AI capabilities, you
    might use it to generate suggestions for human agents. If the acceptance rate
    by human agents is high, for example, 95% of AI-suggested responses to simple
    requests are used by human agents verbatim, you can let customers interact with
    AI directly for those simple requests.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 随着人工智能系统质量的提高，人类的作用可能会随时间而改变。例如，在开始时，当你还在评估人工智能能力时，你可能会用它来为人类代理生成建议。如果人类代理的接受率很高，例如，95%的AI建议对简单请求的响应被人类代理直接使用，你可以让客户直接与AI进行这些简单请求的交互。
- en: AI product defensibility
  id: totrans-267
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人工智能产品防御性
- en: If you’re selling AI applications as standalone products, it’s important to
    consider their defensibility. The low entry barrier is both a blessing and a curse.
    If something is easy for you to build, it’s also easy for your competitors. What
    moats do you have to defend your product?
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将人工智能应用作为独立产品销售，考虑其防御性是非常重要的。低门槛既是祝福也是诅咒。如果你能轻易地构建某个产品，你的竞争对手也能轻易地做到。你有什么护城河来保护你的产品？
- en: In a way, building applications on top of foundation models means providing
    a layer on top of these models.^([20](ch01.html#id607)) This also means that if
    the underlying models expand in capabilities, the layer you provide might be subsumed
    by the models, rendering your application obsolete. Imagine building a PDF-parsing
    application on top of ChatGPT based on the assumption that ChatGPT can’t parse
    PDFs well or can’t do so at scale. Your ability to compete will weaken if this
    assumption is no longer true. However, even in this case, a PDF-parsing application
    might still make sense if it’s built on top of open source models, gearing your
    solution toward users who want to host models in-house.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 从某种意义上说，在基础模型之上构建应用程序意味着在这些模型之上提供一层。这也意味着，如果底层模型在能力上扩展，你提供的层可能会被模型所吸收，使你的应用程序过时。想象一下，基于ChatGPT无法很好地解析PDF或无法大规模解析PDF的假设，在ChatGPT之上构建PDF解析应用程序。如果这个假设不再成立，你的竞争力将减弱。然而，即使在这种情况下，如果PDF解析应用程序是基于开源模型构建的，面向那些希望内部托管模型的用户，它可能仍然是有意义的。
- en: One general partner at a major VC firm told me that she’s seen many startups
    whose entire products could be a feature for Google Docs or Microsoft Office.
    If their products take off, what would stop Google or Microsoft from allocating
    three engineers to replicate these products in two weeks?
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 一家主要风险投资公司的一位普通合伙人告诉我，她见过许多初创公司的整个产品本可以是Google Docs或Microsoft Office的功能。如果他们的产品起飞，什么能阻止Google或Microsoft在两周内分配三名工程师来复制这些产品？
- en: 'In AI, there are generally three types of competitive advantages: technology,
    data, and distribution—the ability to bring your product in front of users. With
    foundation models, the core technologies of most companies will be similar. The
    distribution advantage likely belongs to big companies.'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能领域，通常有三种类型的竞争优势：技术、数据和分发——将你的产品展示给用户的能力。随着基础模型的出现，大多数公司的核心技术将相似。分销优势可能属于大公司。
- en: The data advantage is more nuanced. Big companies likely have more existing
    data. However, if a startup can get to market first and gather sufficient usage
    data to continually improve their products, data will be their moat. Even for
    the scenarios where user data can’t be used to train models directly, usage information
    can give invaluable insights into user behaviors and product shortcomings, which
    can be used to guide the data collection and training process.^([21](ch01.html#id608))
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 数据优势更为复杂。大公司可能拥有更多现有数据。然而，如果一家初创公司能先进入市场并收集足够的用户数据以不断改进其产品，数据将成为其护城河。即使在用户数据不能直接用于训练模型的情况下，使用信息也能提供关于用户行为和产品不足的宝贵见解，这些见解可用于指导数据收集和训练过程.^([21](ch01.html#id608))
- en: There have been many successful companies whose original products could’ve been
    features of larger products. Calendly could’ve been a feature of Google Calendar.
    Mailchimp could’ve been a feature of Gmail. Photoroom could’ve been a feature
    of Google Photos.^([22](ch01.html#id609)) Many startups eventually overtake bigger
    competitors, starting by building a feature that these bigger competitors overlooked.
    Perhaps yours can be the next one.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 已有许多成功公司，其原始产品本可以是更大产品的一部分。Calendly本可以是Google日历的一部分。Mailchimp本可以是Gmail的一部分。Photoroom本可以是Google照片的一部分.^([22](ch01.html#id609))
    许多初创公司最终超越了更大的竞争对手，开始时是构建这些大公司忽视的功能。也许你的公司可以成为下一个。
- en: Setting Expectations
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设定期望
- en: 'Once you’ve decided that you need to build this amazing AI application by yourself,
    the next step is to figure out what success looks like: how will you measure success?
    The most important metric is how this will impact your business. For example,
    if it’s a customer support chatbot, the business metrics can include the following:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你决定需要自己构建这个令人惊叹的人工智能应用，下一步就是弄清楚成功是什么样子：你将如何衡量成功？最重要的指标是这将如何影响你的业务。例如，如果是一个客户支持聊天机器人，业务指标可以包括以下内容：
- en: What percentage of customer messages do you want the chatbot to automate?
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你希望聊天机器人自动化多少比例的客户消息？
- en: How many more messages should the chatbot allow you to process?
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聊天机器人应该允许你处理多少条消息？
- en: How much quicker can you respond using the chatbot?
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用聊天机器人你能有多快地做出回应？
- en: How much human labor can the chatbot save you?
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聊天机器人能为你节省多少人力？
- en: A chatbot can answer more messages, but that doesn’t mean it’ll make users happy,
    so it’s important to track customer satisfaction and customer feedback in general.
    [“User Feedback”](ch10.html#ch10_user_feedback_1730130985313500) discusses how
    to design a feedback system.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天机器人可以回答更多消息，但这并不意味着它会使用户感到高兴，因此跟踪客户满意度和一般客户反馈非常重要。[“用户反馈”](ch10.html#ch10_user_feedback_1730130985313500)讨论了如何设计反馈系统。
- en: 'To ensure a product isn’t put in front of customers before it’s ready, have
    clear expectations on its usefulness threshold: how good it has to be for it to
    be useful. Usefulness thresholds might include the following metrics groups:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确保产品在准备就绪之前不会出现在客户面前，你需要对其有用性门槛有明确预期：它必须有多好才能变得有用。有用性门槛可能包括以下指标组：
- en: Quality metrics to measure the quality of the chatbot’s responses.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 质量指标用于衡量聊天机器人响应的质量。
- en: Latency metrics including TTFT (time to first token), TPOT (time per output
    token), and total latency. What is considered acceptable latency depends on your
    use case. If all of your customer requests are currently being processed by humans
    with a median response time of an hour, anything faster than this might be good
    enough.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 延迟指标包括TTFT（首次标记时间）、TPOT（每输出标记时间）和总延迟。可接受的延迟取决于你的用例。如果你的所有客户请求目前都由人工处理，平均响应时间为一小时，那么任何比这更快的速度可能就足够好了。
- en: 'Cost metrics: how much it costs per inference request.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成本指标：每推理请求的成本。
- en: Other metrics such as interpretability and fairness.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他指标，如可解释性和公平性。
- en: If you’re not yet sure what metrics you want to use, don’t worry. The rest of
    the book will cover many of these metrics.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有确定想要使用哪些指标，不要担心。本书的其余部分将涵盖许多这些指标。
- en: Milestone Planning
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 里程碑规划
- en: Once you’ve set measurable goals, you need a plan to achieve these goals. How
    to get to the goals depends on where you start. Evaluate existing models to understand
    their capabilities. The stronger the off-the-shelf models, the less work you’ll
    have to do. For example, if your goal is to automate 60% of customer support tickets
    and the off-the-shelf model you want to use can already automate 30% of the tickets,
    the effort you need to put in might be less than if it can automate no tickets
    at all.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你设定了可衡量的目标，你需要一个计划来实现这些目标。如何达到目标取决于你的起点。评估现有模型以了解其能力。现成的模型越强大，你需要做的努力就越少。例如，如果你的目标是自动化60%的客户支持工单，而你想要使用的现成模型已经可以自动化30%的工单，那么你需要付出的努力可能比它完全不能自动化工单的情况要少。
- en: It’s likely that your goals will change after evaluation. For example, after
    evaluation, you may realize that the resources needed to get the app to the usefulness
    threshold will be more than its potential return, and, therefore, you no longer
    want to pursue it.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 评估之后，你的目标很可能会发生变化。例如，评估后，你可能意识到将应用提升到有用性门槛所需的资源可能会超过其潜在回报，因此，你可能不再想继续追求它。
- en: Planning an AI product needs to account for its last mile challenge. Initial
    success with foundation models can be misleading. As the base capabilities of
    foundation models are already quite impressive, it might not take much time to
    build a fun demo. However, a good initial demo doesn’t promise a good end product.
    It might take a weekend to build a demo but months, and even years, to build a
    product.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 计划人工智能产品需要考虑其最后一英里挑战。在基础模型上的初步成功可能会误导人。因为基础模型的基本能力已经相当令人印象深刻，所以构建一个有趣的演示可能不需要太多时间。然而，一个好的初始演示并不能保证最终产品的质量。构建一个演示可能只需要一个周末，但构建一个产品可能需要数月甚至数年。
- en: In the paper UltraChat, [Ding et al. (2023)](https://arxiv.org/abs/2305.14233)
    shared that “the journey from 0 to 60 is easy, whereas progressing from 60 to
    100 becomes exceedingly challenging.” [LinkedIn (2024)](https://www.linkedin.com/blog/engineering/generative-ai/musings-on-building-a-generative-ai-product)
    shared the same sentiment. It took them one month to achieve 80% of the experience
    they wanted. This initial success made them grossly underestimate how much time
    it’d take them to improve the product. They found it took them four more months
    to finally surpass 95%. A lot of time was spent working on the product kinks and
    dealing with hallucinations. The slow speed of achieving each subsequent 1% gain
    was discouraging.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在论文 UltraChat 中，[Ding 等人 (2023)](https://arxiv.org/abs/2305.14233) 分享了“从 0 到
    60 的旅程很容易，而从 60 到 100 的进步变得极其困难。” [LinkedIn (2024)](https://www.linkedin.com/blog/engineering/generative-ai/musings-on-building-a-generative-ai-product)
    也表达了同样的观点。他们花了一个月时间实现了他们想要的 80% 的体验。这种初步的成功使他们大大低估了改进产品所需的时间。他们发现，要最终超过 95%，他们还需要再花四个月时间。他们在产品的小问题和工作上的幻觉处理上花费了大量时间。每次获得后续
    1% 的进步速度缓慢，这令人沮丧。
- en: Maintenance
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 维护
- en: Product planning doesn’t stop at achieving its goals. You need to think about
    how this product might change over time and how it should be maintained. Maintenance
    of an AI product has the added challenge of AI’s fast pace of change. The AI space
    has been moving incredibly fast in the last decade. It’ll probably continue moving
    fast for the next decade. Building on top of foundation models today means committing
    to riding this bullet train.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 产品规划不仅仅是为了实现目标。你需要考虑这个产品随着时间的推移可能会如何变化，以及它应该如何维护。维护人工智能产品面临的额外挑战是人工智能快速变化的速度。在过去十年中，人工智能领域发展非常迅速。它可能会在接下来的十年中继续快速发展。在今天建立在基础模型之上意味着承诺乘坐这趟子弹列车。
- en: Many changes are good. For example, the limitations of many models are being
    addressed. Context lengths are getting longer. Model outputs are getting better.
    Model *inference*, the process of computing an output given an input, is getting
    faster and cheaper. [Figure 1-11](#ch01_figure_11_1730130814920109) shows the
    evolution of inference cost and model performance on Massive Multitask Language
    Understanding (MMLU) ([Hendrycks et al., 2020](https://arxiv.org/abs/2009.03300)),
    a popular foundation model benchmark, between 2022 and 2024.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 许多变化都是好的。例如，许多模型的局限性正在得到解决。上下文长度正在变长。模型输出正在变得更好。模型 *推理*，即给定输入计算输出的过程，正在变得更快、更便宜。[图
    1-11](#ch01_figure_11_1730130814920109) 展示了在 2022 年至 2024 年间，在流行的基础模型基准 Massive
    Multitask Language Understanding (MMLU) ([Hendrycks et al., 2020](https://arxiv.org/abs/2009.03300))
    上的推理成本和模型性能的演变。
- en: '![A graph with numbers and a number of points'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '![包含数字和多个点的图表'
- en: Description automatically generated with medium confidence](assets/aien_0111.png)
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 描述自动生成，置信度中等](assets/aien_0111.png)
- en: Figure 1-11\. The cost of AI reasoning rapidly drops over time. Image from [Katrina
    Nguyen](https://oreil.ly/UyL8r) (2024).
  id: totrans-297
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 1-11\. 人工智能推理的成本随时间迅速下降。图片来自 [Katrina Nguyen](https://oreil.ly/UyL8r) (2024)。
- en: However, even these good changes can cause friction in your workflows. You’ll
    have to constantly be on your guard and run a cost-benefit analysis of each technology
    investment. The best option today might turn into the worst option tomorrow. You
    may decide to build a model in-house because it seems cheaper than paying for
    model providers, only to find out after three months that model providers have
    dropped their prices in half, making in-house the expensive option. You might
    invest in a third-party solution and tailor your infrastructure around it, only
    for the provider to go out of business after failing to secure funding.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，即使是这些良好的变化也可能在你的工作流程中引起摩擦。你必须时刻保持警惕，并对每一项技术投资进行成本效益分析。今天可能是最佳选择，但明天可能变成最差选择。你可能会决定内部构建模型，因为它看起来比支付模型提供商的费用更便宜，但三个月后发现模型提供商将价格降了一半，使得内部模型变得昂贵。你可能会投资第三方解决方案，并围绕它调整你的基础设施，但提供商可能因为未能获得资金而倒闭。
- en: Some changes are easier to adapt to. For example, as model providers converge
    to the same API, it’s becoming easier to swap one model API for another. However,
    as each model has its quirks, strengths, and weaknesses, developers working with
    the new model will need to adjust their workflows, prompts, and data to this new
    model. Without proper infrastructure for versioning and evaluation in place, the
    process can cause a lot of headaches.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 一些变化更容易适应。例如，随着模型提供商趋向于相同的API，用一个模型API替换另一个模型API变得越来越容易。然而，由于每个模型都有其独特的特点、优势和劣势，与新型模型一起工作的开发者需要调整他们的工作流程、提示和数据以适应这个新模型。如果没有适当的版本管理和评估基础设施，这个过程可能会引起很多麻烦。
- en: Some changes are harder to adapt to, especially those around regulations. Technologies
    surrounding AI are considered national security issues for many countries, meaning
    resources for AI, including compute, talent, and data, are heavily regulated.
    The introduction of Europe’s General Data Protection Regulation (GDPR), for example,
    was estimated to cost businesses [$9 billion](https://oreil.ly/eDfB8) to become
    compliant. Compute availability can change overnight as new laws put more restrictions
    on who can buy and sell compute resources (see the [US October 2023 Executive
    Order](https://oreil.ly/eYTmr)). If your GPU vendor is suddenly banned from selling
    GPUs to your country, you’re in trouble.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 一些变化更难适应，尤其是那些与法规相关的变化。对于许多国家来说，围绕人工智能的技术被视为国家安全问题，这意味着人工智能的资源，包括计算、人才和数据，都受到严格的监管。例如，欧洲通用数据保护条例（GDPR）的实施，据估计将使企业花费[90亿美元](https://oreil.ly/eDfB8)来达到合规标准。计算资源的可用性可能会一夜之间发生变化，因为新的法律对谁可以购买和销售计算资源施加了更多限制（参见[美国2023年10月行政命令](https://oreil.ly/eYTmr)）。如果你的GPU供应商突然被禁止向你的国家销售GPU，那你就有麻烦了。
- en: Some changes can even be fatal. For example, regulations around intellectual
    property (IP) and AI usage are still evolving. If you build your product on top
    of a model trained using other people’s data, can you be certain that your product’s
    IP will always belong to you? Many IP-heavy companies I’ve talked to, such as
    game studios, hesitate to use AI for fear of losing their IPs later on.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 一些变化甚至可能是致命的。例如，关于知识产权（IP）和人工智能使用的法规仍在不断发展。如果你在其他人训练的模型之上构建你的产品，你能确定你的产品的IP将始终属于你吗？我交谈过的许多知识产权密集型公司，如游戏工作室，都犹豫不决地使用人工智能，因为他们担心以后会失去他们的知识产权。
- en: Once you’ve committed to building an AI product, let’s look into the engineering
    stack needed to build these applications.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你决定构建人工智能产品，让我们来看看构建这些应用程序所需的工程堆栈。
- en: The AI Engineering Stack
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能工程堆栈
- en: AI engineering’s rapid growth also induced an incredible amount of hype and
    FOMO (fear of missing out). The number of new tools, techniques, models, and applications
    introduced every day can be overwhelming. Instead of trying to keep up with the
    constantly shifting sand, let’s look into the fundamental building blocks of AI
    engineering.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能工程领域的快速发展也引发了大量的炒作和FOMO（错失恐惧）。每天推出的新工具、技术、模型和应用数量可能令人难以承受。与其试图跟上不断变化的沙子，不如让我们来看看人工智能工程的基本构建块。
- en: To understand AI engineering, it’s important to recognize that AI engineering
    evolved out of ML engineering. When a company starts experimenting with foundation
    models, it’s natural that its existing ML team should lead the effort. Some companies
    treat AI engineering the same as ML engineering, as shown in [Figure 1-12](#ch01_figure_12_1730130814920130).
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解人工智能工程，重要的是要认识到人工智能工程是从机器学习工程演变而来的。当一家公司开始尝试使用基础模型时，其现有的机器学习团队领导这项工作是很自然的。一些公司将人工智能工程视为与机器学习工程相同，如图1-12所示。
- en: '![A screenshot of a computer'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '![计算机屏幕截图'
- en: Description automatically generated](assets/aien_0112.png)
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '[自动生成的描述](assets/aien_0112.png)'
- en: Figure 1-12\. Many companies put AI engineering and ML engineering under the
    same umbrella, as shown in the job headlines on LinkedIn from December 17, 2023.
  id: totrans-308
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-12。许多公司将人工智能工程和机器学习工程归为一类，如2023年12月17日在领英上的职位标题所示。
- en: Some companies have separate job descriptions for AI engineering, as shown in
    [Figure 1-13](#ch01_figure_13_1730130814920151).
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 一些公司为人工智能工程单独编写了职位描述，如图1-13所示。
- en: Regardless of where organizations position AI engineers and ML engineers, their
    roles have significant overlap. Existing ML engineers can add AI engineering to
    their lists of skills to expand their job prospects. However, there are also AI
    engineers with no previous ML experience.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 无论组织如何定位AI工程师和机器学习工程师，他们的角色都有很大的重叠。现有的机器学习工程师可以将AI工程添加到他们的技能列表中，以扩大他们的就业前景。然而，也存在没有先前机器学习经验的AI工程师。
- en: To best understand AI engineering and how it differs from traditional ML engineering,
    the following section breaks down different layers of the AI application building
    process and looks at the role each layer plays in AI engineering and ML engineering.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 为了最好地理解AI工程以及它与传统机器学习工程的不同之处，下一节将分解AI应用程序构建过程中的不同层次，并探讨每个层次在AI工程和机器学习工程中的作用。
- en: '![A screenshot of a computer'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '![计算机屏幕截图'
- en: Description automatically generated](assets/aien_0113.png)
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](assets/aien_0113.png)
- en: Figure 1-13\. Some companies have separate job descriptions for AI engineering,
    as shown in the job headlines on LinkedIn from December 17, 2023.
  id: totrans-314
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-13\. 一些公司为AI工程有单独的职位描述，如2023年12月17日在LinkedIn上的职位标题所示。
- en: Three Layers of the AI Stack
  id: totrans-315
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能堆栈的三个层次
- en: 'There are three layers to any AI application stack: application development,
    model development, and infrastructure. When developing an AI application, you’ll
    likely start from the top layer and move down as needed:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 任何AI应用程序堆栈都有三个层次：应用程序开发、模型开发和基础设施。在开发AI应用程序时，你可能会从顶层开始，根据需要向下移动：
- en: Application development
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序开发
- en: With models readily available, anyone can use them to develop applications.
    This is the layer that has seen the most action in the last two years, and it
    is still rapidly evolving. Application development involves providing a model
    with good prompts and necessary context. This layer requires rigorous evaluation.
    Good applications also demand good interfaces.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 由于模型随时可用，任何人都可以使用它们来开发应用程序。这是在过去两年中活动最频繁的层次，并且仍在快速发展。应用程序开发涉及为模型提供良好的提示和必要的上下文。这一层需要严格的评估。好的应用程序也要求良好的接口。
- en: Model development
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 模型开发
- en: This layer provides tooling for developing models, including frameworks for
    modeling, training, finetuning, and inference optimization. Because data is central
    to model development, this layer also contains dataset engineering. Model development
    also requires rigorous evaluation.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 这一层为模型开发提供工具，包括建模、训练、微调和推理优化的框架。由于数据是模型开发的核心，这一层还包含数据集工程。模型开发也需要严格的评估。
- en: Infrastructure
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 基础设施
- en: At the bottom is the stack is infrastructure, which includes tooling for model
    serving, managing data and compute, and monitoring.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在底层是基础设施，包括模型服务、数据管理和计算监控的工具。
- en: These three layers and examples of responsibilities for each layer are shown
    in [Figure 1-14](#ch01_figure_14_1730130814920166).
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个层次以及每个层次的责任示例显示在[图1-14](#ch01_figure_14_1730130814920166)中。
- en: '![A diagram of a software development'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '![软件开发流程的图表'
- en: Description automatically generated](assets/aien_0114.png)
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](assets/aien_0114.png)
- en: Figure 1-14\. Three layers of the AI engineering stack.
  id: totrans-326
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-14\. AI工程堆栈的三个层次。
- en: To get a sense of how the landscape has evolved with foundation models, in March
    2024, I searched GitHub for all AI-related repositories with at least 500 stars.
    Given the prevalence of GitHub, I believe this data is a good proxy for understanding
    the ecosystem. In my analysis, I also included repositories for applications and
    models, which are the products of the application development and model development
    layers, respectively. I found a total of 920 repositories. [Figure 1-15](#ch01_figure_15_1730130814920182)
    shows the cumulative number of repositories in each category month-over-month.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 为了了解基础模型如何推动这一领域的发展，我在2024年3月搜索了GitHub上所有至少有500个星标的AI相关存储库。鉴于GitHub的普及，我相信这些数据是理解生态系统的良好代理。在我的分析中，我还包括了应用程序和模型的存储库，它们分别是应用程序开发和模型开发层次的产物。我总共找到了920个存储库。[图1-15](#ch01_figure_15_1730130814920182)显示了每个月每个类别的存储库累计数量。
- en: '![A graph of a number of people'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '![人数的图表'
- en: Description automatically generated](assets/aien_0115.png)
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](assets/aien_0115.png)
- en: Figure 1-15\. Cumulative count of repositories by category over time.
  id: totrans-330
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-15\. 随时间推移按类别划分的存储库累计数量。
- en: The data shows a big jump in the number of AI toolings in 2023, after the introduction
    of Stable Diffusion and ChatGPT. In 2023, the categories that saw the highest
    increases were applications and application development. The infrastructure layer
    saw some growth, but it was much less than the growth seen in other layers. This
    is expected. Even though models and applications have changed, the core infrastructural
    needs—resource management, serving, monitoring, etc.—remain the same.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 数据显示，在引入Stable Diffusion和ChatGPT之后，2023年AI工具的数量大幅增加。2023年，增长最快的类别是应用和应用开发。基础设施层也有所增长，但远低于其他层的增长。这是预期的。尽管模型和应用已经改变，但核心基础设施需求——资源管理、服务、监控等——仍然相同。
- en: This brings us to the next point. While the level of excitement and creativity
    around foundation models is unprecedented, many principles of building AI applications
    remain the same. For enterprise use cases, AI applications still need to solve
    business problems, and, therefore, it’s still essential to map from business metrics
    to ML metrics and vice versa. You still need to do systematic experimentation.
    With classical ML engineering, you experiment with different hyperparameters.
    With foundation models, you experiment with different models, prompts, retrieval
    algorithms, sampling variables, and more. (Sampling variables are discussed in
    [Chapter 2](ch02.html#ch02_understanding_foundation_models_1730147895571359).)
    We still want to make models run faster and cheaper. It’s still important to set
    up a feedback loop so that we can iteratively improve our applications with production
    data.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 这引出了下一个观点。虽然围绕基础模型的兴奋和创造力是前所未有的，但构建AI应用的原则仍然相同。对于企业用例，AI应用仍然需要解决业务问题，因此，将业务指标映射到机器学习指标以及反之亦然仍然至关重要。您仍然需要进行系统性的实验。在传统的机器学习工程中，您通过不同的超参数进行实验。在基础模型中，您通过不同的模型、提示、检索算法、采样变量等进行实验。（采样变量将在[第2章](ch02.html#ch02_understanding_foundation_models_1730147895571359)中讨论。）我们仍然希望使模型运行得更快、更便宜。设置反馈循环仍然很重要，这样我们就可以使用生产数据迭代地改进我们的应用。
- en: This means that much of what ML engineers have learned and shared over the last
    decade is still applicable. This collective experience makes it easier for everyone
    to begin building AI applications. However, built on top of these enduring principles
    are many innovations unique to AI engineering, which we’ll explore in this book.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着过去十年中机器学习工程师所学习和分享的许多内容仍然适用。这种集体经验使得每个人开始构建AI应用变得更加容易。然而，在这些持久的原则之上，还有许多独特的AI工程创新，我们将在本书中探讨。
- en: AI Engineering Versus ML Engineering
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AI工程与机器学习工程的比较
- en: While the unchanging principles of deploying AI applications are reassuring,
    it’s also important to understand how things have changed. This is helpful for
    teams that want to adapt their existing platforms for new AI use cases and developers
    who are interested in which skills to learn to stay competitive in a new market.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然部署AI应用的不可变原则令人安心，但了解事情是如何改变的也很重要。这对希望为新的AI用例调整现有平台和希望在新市场中保持竞争力的开发者来说很有帮助。
- en: 'At a high level, building applications using foundation models today differs
    from traditional ML engineering in three major ways:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 在高层次上，今天使用基础模型构建应用与传统机器学习工程在三个方面有所不同：
- en: Without foundation models, you have to train your own models for your applications.
    With AI engineering, you use a model someone else has trained for you. This means
    that AI engineering focuses less on modeling and training, and more on model adaptation.
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 没有基础模型，您必须为您的应用训练自己的模型。使用AI工程，您使用的是别人为您训练的模型。这意味着AI工程更少关注建模和训练，而更多关注模型适配。
- en: AI engineering works with models that are bigger, consume more compute resources,
    and incur higher latency than traditional ML engineering. This means that there’s
    more pressure for efficient training and inference optimization. A corollary of
    compute-intensive models is that many companies now need more GPUs and work with
    bigger compute clusters than they previously did, which means there’s more need
    for engineers who know how to work with GPUs and big clusters.^([23](ch01.html#id640))
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: AI工程使用的是比传统机器学习工程更大的模型，消耗更多的计算资源，并且产生更高的延迟。这意味着对高效训练和推理优化的压力更大。计算密集型模型的一个推论是，许多公司现在需要更多的GPU，并与比以前更大的计算集群合作，这意味着对了解如何与GPU和大集群合作工程师的需求更大.^([23](ch01.html#id640))
- en: AI engineering works with models that can produce open-ended outputs. Open-ended
    outputs give models the flexibility to be used for more tasks, but they are also
    harder to evaluate. This makes evaluation a much bigger problem in AI engineering.
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 人工智能工程与能够产生开放性输出的模型一起工作。开放性输出使模型能够用于更多任务，但它们也更难评估。这使得评估在人工智能工程中成为一个更大的问题。
- en: In short, AI engineering differs from ML engineering in that it’s less about
    model development and more about adapting and evaluating models. I’ve mentioned
    model adaptation several times in this chapter, so before we move on, I want to
    make sure that we’re on the same page about what model adaptation means. In general,
    model adaptation techniques can be divided into two categories, depending on whether
    they require updating model weights.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，人工智能工程与机器学习工程的不同之处在于，它更少关注模型开发，更多关注适应和评估模型。我在本章中多次提到了模型适应，所以在我们继续之前，我想确保我们对模型适应的含义有相同的理解。一般来说，模型适应技术可以根据它们是否需要更新模型权重分为两类。
- en: '*Prompt-based techniques, which include prompt engineering, adapt a model without
    updating the model weights.* You adapt a model by giving it instructions and context
    instead of changing the model itself. Prompt engineering is easier to get started
    and requires less data. Many successful applications have been built with just
    prompt engineering. Its ease of use allows you to experiment with more models,
    which increases your chance of finding a model that is unexpectedly good for your
    applications. However, prompt engineering might not be enough for complex tasks
    or applications with strict performance requirements.'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: '*基于提示的技术，包括提示工程，可以在不更新模型权重的情况下适应模型。* 通过提供指令和上下文而不是改变模型本身来适应模型。提示工程更容易上手，并且需要的数据更少。许多成功应用仅使用提示工程就构建而成。其易用性允许你尝试更多模型，这增加了你找到适合你应用的意外好模型的几率。然而，对于复杂任务或对性能要求严格的
    应用，提示工程可能不足以满足需求。'
- en: '*Finetuning, on the other hand, requires updating model weights.* You adapt
    a model by making changes to the model itself. In general, finetuning techniques
    are more complicated and require more data, but they can improve your model’s
    quality, latency, and cost significantly. Many things aren’t possible without
    changing model weights, such as adapting the model to a new task it wasn’t exposed
    to during training.'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，*微调* 需要更新模型权重。通过改变模型本身来适应模型。一般来说，微调技术更复杂，需要更多数据，但它们可以显著提高模型的质量、延迟和成本。许多事情在没有改变模型权重的情况下是不可能的，例如将模型适应于训练期间未接触过的新任务。
- en: Now, let’s zoom into the application development and model development layers
    to see how each has changed with AI engineering, starting with what existing ML
    engineers are more familiar with. This section gives an overview of different
    processes involved in developing an AI application. How these processes work will
    be discussed throughout this book.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们聚焦于应用开发和模型开发层，看看它们如何随着人工智能工程的发展而变化，首先从现有的机器学习工程师更熟悉的内容开始。本节概述了开发人工智能应用涉及的不同过程。这些过程是如何工作的将在本书的后续章节中讨论。
- en: Model development
  id: totrans-344
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型开发
- en: '*Model development* is the layer most commonly associated with traditional
    ML engineering. It has three main responsibilities: modeling and training, dataset
    engineering, and inference optimization. Evaluation is also required, but because
    most people will come across it first in the application development layer, I’ll
    discuss evaluation in the next section.'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '*模型开发* 是与传统的机器学习工程最常相关联的层。它有三个主要职责：建模和训练、数据集工程和推理优化。评估也是必需的，但由于大多数人将在应用开发层首次遇到它，我将在下一节讨论评估。'
- en: Modeling and training
  id: totrans-346
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 建模和训练
- en: '*Modeling and training* refers to the process of coming up with a model architecture,
    training it, and finetuning it. Examples of tools in this category are Google’s
    TensorFlow, Hugging Face’s Transformers, and Meta’s PyTorch.'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '*建模和训练* 指的是提出模型架构、训练它并微调的过程。这个类别中的工具示例包括谷歌的 TensorFlow、Hugging Face 的 Transformers
    和 Meta 的 PyTorch。'
- en: Developing ML models requires specialized ML knowledge. It requires knowing
    different types of ML algorithms (such as clustering, logistic regression, decision
    trees, and collaborative filtering) and neural network architectures (such as
    feedforward, recurrent, convolutional, and transformer). It also requires understanding
    how a model learns, including concepts such as gradient descent, loss function,
    regularization, etc.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 开发机器学习模型需要专门的机器学习知识。这需要了解不同类型的机器学习算法（如聚类、逻辑回归、决策树和协同过滤）以及神经网络架构（如前馈、循环、卷积和变换器）。还需要了解模型是如何学习的，包括梯度下降、损失函数、正则化等概念。
- en: With the availability of foundation models, ML knowledge is no longer a must-have
    for building AI applications. I’ve met many wonderful and successful AI application
    builders who aren’t at all interested in learning about gradient descent. However,
    ML knowledge is still extremely valuable, as it expands the set of tools that
    you can use and helps troubleshooting when a model doesn’t work as expected.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 随着基础模型的出现，机器学习知识不再是构建人工智能应用的必需品。我遇到过许多优秀且成功的AI应用构建者，他们对学习梯度下降并不感兴趣。然而，机器学习知识仍然极其宝贵，因为它扩展了你可用的工具集，并在模型不符合预期时帮助解决问题。
- en: Dataset engineering
  id: totrans-350
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据集工程
- en: '*Dataset engineering* refers to curating, generating, and annotating the data
    needed for training and adapting AI models.'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据集工程*指的是整理、生成和标注用于训练和调整人工智能模型所需的数据。'
- en: In traditional ML engineering, most use cases are close-ended—a model’s output
    can only be among predefined values. For example, spam classification with only
    two possible outputs, “spam” and “not spam”, is close-ended. Foundation models,
    however, are open-ended. Annotating open-ended queries is much harder than annotating
    close-ended queries—it’s easier to determine whether an email is spam than to
    write an essay. So data annotation is a much bigger challenge for AI engineering.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的机器学习工程中，大多数用例都是封闭式的——模型的输出只能是在预定义值中。例如，只有两个可能输出的垃圾邮件分类（“垃圾邮件”和“非垃圾邮件”）是封闭式的。然而，基础模型是开放式的。标注开放式查询比标注封闭式查询要困难得多——判断一封电子邮件是否为垃圾邮件比写一篇文章要容易。因此，数据标注对人工智能工程来说是一个更大的挑战。
- en: Another difference is that traditional ML engineering works more with tabular
    data, whereas foundation models work with unstructured data. In AI engineering,
    data manipulation is more about deduplication, tokenization, context retrieval,
    and quality control, including removing sensitive information and toxic data.
    Dataset engineering is the focus of [Chapter 8](ch08.html#ch08_dataset_engineering_1730130932019888).
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个区别是，传统的机器学习工程更多地与表格数据打交道，而基础模型则处理非结构化数据。在人工智能工程中，数据处理更多地涉及去重、分词、上下文检索和质量控制，包括移除敏感信息和有害数据。数据集工程是[第8章](ch08.html#ch08_dataset_engineering_1730130932019888)的重点。
- en: Many people argue that because models are now commodities, data will be the
    main differentiator, making dataset engineering more important than ever. How
    much data you need depends on the adapter technique you use. Training a model
    from scratch generally requires more data than finetuning, which, in turn, requires
    more data than prompt engineering.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 许多人认为，由于模型现在是商品，数据将成为主要的差异化因素，使得数据集工程比以往任何时候都更重要。你需要多少数据取决于你使用的适配技术。从头开始训练一个模型通常需要比微调更多的数据，而微调又需要比提示工程更多的数据。
- en: Regardless of how much data you need, expertise in data is useful when examining
    a model, as its training data gives important clues about that model’s strengths
    and weaknesses.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你需要多少数据，在检查模型时，数据方面的专业知识都是有用的，因为其训练数据为该模型的优势和劣势提供了重要线索。
- en: Inference optimization
  id: totrans-356
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 推理优化
- en: '*Inference optimization* means making models faster and cheaper. Inference
    optimization has always been important for ML engineering. Users never say no
    to faster models, and companies can always benefit from cheaper inference. However,
    as foundation models scale up to incur even higher inference cost and latency,
    inference optimization has become even more important.'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '*推理优化*意味着使模型更快、更便宜。推理优化一直是机器学习工程中的重要部分。用户总是欢迎更快模型的，而公司也能从更便宜的推理中获益。然而，随着基础模型规模的扩大，导致更高的推理成本和延迟，推理优化变得更加重要。'
- en: One challenge with foundation models is that they are often *autoregressive*—tokens
    are generated sequentially. If it takes 10 ms for a model to generate a token,
    it’ll take a second to generate an output of 100 tokens, and even more for longer
    outputs. As users are getting notoriously impatient, getting AI applications’
    latency down to the [100 ms latency](https://oreil.ly/gGXZ-) expected for a typical
    internet application is a huge challenge. Inference optimization has become an
    active subfield in both industry and academia.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 基础模型的一个挑战是它们通常是 *自回归* 的——标记是按顺序生成的。如果模型生成一个标记需要 10 毫秒，那么生成 100 个标记的输出将需要一秒钟，更长的输出则需要更多时间。由于用户越来越没有耐心，将人工智能应用程序的延迟降低到典型互联网应用程序预期的
    [100 毫秒延迟](https://oreil.ly/gGXZ-) 是一个巨大的挑战。推理优化已成为工业和学术界的一个活跃的子领域。
- en: A summary of how the importance of different categories of model development
    change with AI engineering is shown in [Table 1-4](#ch01_table_4_1730130814941579).
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [表 1-4](#ch01_table_4_1730130814941579) 中展示了随着人工智能工程的发展，不同类别模型开发的重要性如何变化。
- en: Table 1-4\. How different responsibilities of model development have changed
    with foundation models.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1-4\. 基础模型出现后，模型开发的职责如何发生变化。
- en: '| Category | Building with traditional ML | Building with foundation models
    |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
  zh: '| 类别 | 使用传统机器学习构建 | 使用基础模型构建 |'
- en: '| --- | --- | --- |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Modeling and training | ML knowledge is required for training a model from
    scratch | ML knowledge is a nice-to-have, not a must-have^([a](ch01.html#id652))
    |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '| 建模和训练 | 从头开始训练模型需要机器学习知识 | 机器学习知识是可取的，但不是必需的^([a](ch01.html#id652)) |'
- en: '| Dataset engineering | More about feature engineering, especially with tabular
    data | Less about feature engineering and more about data deduplication, tokenization,
    context retrieval, and quality control |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '| 数据集工程 | 更多关于特征工程，尤其是在表格数据中 | 更少关于特征工程，更多关于数据去重、标记化、上下文检索和质量控制 |'
- en: '| Inference optimization | Important | Even more important |'
  id: totrans-365
  prefs: []
  type: TYPE_TB
  zh: '| 推理优化 | 重要 | 更加重要 |'
- en: '| ^([a](ch01.html#id652-marker)) Many people would dispute this claim, saying
    that ML knowledge is a must-have. |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| ^([a](ch01.html#id652-marker)) 许多人会对此观点提出异议，认为机器学习知识是必不可少的。|'
- en: Inference optimization techniques, including quantization, distillation, and
    parallelism, are discussed in Chapters [7](ch07.html#ch07) through [9](ch09.html#ch09_inference_optimization_1730130963006301).
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 第 7 章 [量化](ch07.html#ch07) 到第 9 章 [推理优化](ch09.html#ch09_inference_optimization_1730130963006301)
    讨论了推理优化技术，包括量化、蒸馏和并行化。
- en: Application development
  id: totrans-368
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 应用程序开发
- en: With traditional ML engineering, where teams build applications using their
    proprietary models, the model quality is a differentiation. With foundation models,
    where many teams use the same model, differentiation must be gained through the
    application development process.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 使用传统的机器学习工程，团队使用他们自己的模型来构建应用程序，模型质量是区分度。而在使用基础模型的场景中，许多团队使用相同的模型，区分度必须通过应用程序开发过程来获得。
- en: 'The application development layer consists of these responsibilities: evaluation,
    prompt engineering, and AI interface.'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序开发层包括以下职责：评估、提示工程和人工智能界面。
- en: Evaluation
  id: totrans-371
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 评估
- en: '*Evaluation* is about mitigating risks and uncovering opportunities. Evaluation
    is necessary throughout the whole model adaptation process. Evaluation is needed
    to select models, to benchmark progress, to determine whether an application is
    ready for deployment, and to detect issues and opportunities for improvement in
    production.'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '*评估* 是关于降低风险和发现机会。在整个模型适应过程中，评估都是必要的。评估用于选择模型、基准测试进度、确定应用程序是否准备就绪用于部署，以及检测生产中的问题和改进机会。'
- en: While evaluation has always been important in ML engineering, it’s even more
    important with foundation models, for many reasons. The challenges of evaluating
    foundation models are discussed in [Chapter 3](ch03.html#ch03a_evaluation_methodology_1730150757064067).
    To summarize, these challenges chiefly arise from foundation models’ open-ended
    nature and expanded capabilities. For example, in close-ended ML tasks like fraud
    detection, there are usually expected ground truths that you can compare your
    model’s outputs against. If a model’s output differs from the expected output,
    you know the model is wrong. For a task like chatbots, however, there are so many
    possible responses to each prompt that it is impossible to curate an exhaustive
    list of ground truths to compare a model’s response to.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然评估在机器学习工程中始终很重要，但在基础模型中，它的重要性更是如此，原因有很多。评估基础模型的挑战在[第3章](ch03.html#ch03a_evaluation_methodology_1730150757064067)中进行了讨论。总结来说，这些挑战主要源于基础模型的开放性和扩展能力。例如，在像欺诈检测这样的封闭式机器学习任务中，通常有预期的真实情况可以与你的模型输出进行比较。如果一个模型的输出与预期输出不同，你就知道模型是错误的。然而，对于像聊天机器人这样的任务，每个提示都有如此多的可能响应，以至于不可能编制一个详尽的真实情况列表来比较模型响应。
- en: The existence of so many adaptation techniques also makes evaluation harder.
    A system that performs poorly with one technique might perform much better with
    another. When Google launched Gemini in December 2023, they claimed that Gemini
    is better than ChatGPT in the MMLU benchmark ([Hendrycks et al., 2020](https://arxiv.org/abs/2009.03300)).
    Google had evaluated Gemini using a prompt engineering technique called [CoT@32](https://oreil.ly/VDwaR).
    In this technique, Gemini was shown 32 examples, while ChatGPT was shown only
    5 examples. When both were shown five examples, ChatGPT performed better, as shown
    in [Table 1-5](#ch01_table_5_1730130814941611).
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 存在如此多的适应技术也使得评估变得更加困难。一个技术在某方面表现不佳的系统，可能在使用另一种技术时表现得更好。当谷歌在2023年12月推出Gemini时，他们声称Gemini在MMLU基准测试中优于ChatGPT
    ([Hendrycks等人，2020](https://arxiv.org/abs/2009.03300))。谷歌使用一种名为[CoT@32](https://oreil.ly/VDwaR)的提示工程技术对Gemini进行了评估。在这种技术中，Gemini展示了32个示例，而ChatGPT只展示了5个示例。当两者都展示了五个示例时，ChatGPT的表现更好，如[表1-5](#ch01_table_5_1730130814941611)所示。
- en: Table 1-5\. Different prompts can cause models to perform very differently,
    as seen in Gemini’s technical report (December 2023).
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 表1-5。不同的提示可能导致模型表现差异很大，正如Gemini的技术报告（2023年12月）中所示。
- en: '|  | Gemini Ultra | Gemini Pro | GPT-4 | GPT-3.5 | PaLM 2-L | Claude 2 | Inflection-2
    | Grok 1 | Llama-2 |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '|  | Gemini Ultra | Gemini Pro | GPT-4 | GPT-3.5 | PaLM 2-L | Claude 2 | Inflection-2
    | Grok 1 | Llama-2 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-377
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| MMLU performance | 90.04% CoT@32 | 79.13% CoT@8 | 87.29% CoT@32'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: '| MMLU性能 | 90.04% CoT@32 | 79.13% CoT@8 | 87.29% CoT@32'
- en: (via API) | 70% 5-shot | 78.4% 5-shot | 78.5% 5-shot CoT | 79.6% 5-shot | 73.0%
    5-shot | 68.0% |
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: (via API) | 70% 5-shot | 78.4% 5-shot | 78.5% 5-shot CoT | 79.6% 5-shot | 73.0%
    5-shot | 68.0% |
- en: '| 83.7% 5-shot | 71.8% 5-shot | 86.4% 5-shot (reported) |  |  |  |  |  |  |'
  id: totrans-380
  prefs: []
  type: TYPE_TB
  zh: '| 83.7% 5-shot | 71.8% 5-shot | 86.4% 5-shot (报告) |  |  |  |  |  |  |'
- en: Prompt engineering and context construction
  id: totrans-381
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 提示工程和上下文构建
- en: '*Prompt engineering* is about getting AI models to express the desirable behaviors
    from the input alone, without changing the model weights. The Gemini evaluation
    story highlights the impact of prompt engineering on model performance. By using
    a different prompt engineering technique, Gemini Ultra’s performance on MMLU went
    from 83.7% to 90.04%.'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: '*提示工程*是指让AI模型仅从输入中表达出期望的行为，而不改变模型权重。Gemini的评估故事突出了提示工程对模型性能的影响。通过使用不同的提示工程技术，Gemini
    Ultra在MMLU上的性能从83.7%提升到了90.04%。'
- en: It’s possible to get a model to do amazing things with just prompts. The right
    instructions can get a model to perform the task you want, in the format of your
    choice. Prompt engineering is not just about telling a model what to do. It’s
    also about giving the model the necessary context and tools to do a given task.
    For complex tasks with long context, you might also need to provide the model
    with a memory management system so that the model can keep track of its history.
    [Chapter 5](ch05.html#ch05a_prompt_engineering_1730156991195551) discusses prompt
    engineering, and [Chapter 6](ch06.html#ch06_rag_and_agents_1730157386571386) discusses
    context construction.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 只需提示，就可以让模型完成令人惊叹的事情。正确的指令可以让模型以你选择的格式执行你想要的任务。提示工程不仅仅是告诉模型要做什么。它还涉及到为模型提供完成任务所需的必要背景和工具。对于需要长时间背景的复杂任务，你可能还需要为模型提供一个内存管理系统，以便模型可以跟踪其历史。[第5章](ch05.html#ch05a_prompt_engineering_1730156991195551)讨论了提示工程，[第6章](ch06.html#ch06_rag_and_agents_1730157386571386)讨论了上下文构建。
- en: AI interface
  id: totrans-384
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: AI界面
- en: '*AI interface* means creating an interface for end users to interact with your
    AI applications. Before foundation models, only organizations with sufficient
    resources to develop AI models could develop AI applications. These applications
    were often embedded into the organizations’ existing products. For example, fraud
    detection was embedded into Stripe, Venmo, and PayPal. Recommender systems were
    part of social networks and media apps like Netflix, TikTok, and Spotify.'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: '*AI界面*意味着为最终用户创建一个与您的AI应用交互的界面。在基础模型出现之前，只有拥有足够资源开发AI模型的组织才能开发AI应用。这些应用通常嵌入到组织的现有产品中。例如，欺诈检测被嵌入到Stripe、Venmo和PayPal中。推荐系统是社交网络和媒体应用如Netflix、TikTok和Spotify的一部分。'
- en: With foundation models, anyone can build AI applications. You can serve your
    AI applications as standalone products or embed them into other products, including
    products developed by other people. For example, ChatGPT and Perplexity are standalone
    products, whereas GitHub’s Copilot is commonly used as a plug-in in VSCode, and
    Grammarly is commonly used as a browser extension for Google Docs. Midjourney
    can either be used via its standalone web app or via its integration in Discord.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 基于基础模型，任何人都可以构建AI应用。你可以将你的AI应用作为独立产品提供服务，或者将它们嵌入到其他产品中，包括其他人开发的产品。例如，ChatGPT和Perplexity是独立产品，而GitHub的Copilot通常用作VSCode的插件，Grammarly则通常用作Google
    Docs的浏览器扩展。Midjourney可以通过其独立的Web应用使用，也可以通过其在Discord中的集成使用。
- en: 'There need to be tools that provide interfaces for standalone AI applications
    or make it easy to integrate AI into existing products. Here are just some of
    the interfaces that are gaining popularity for AI applications:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 需要提供工具，为独立AI应用提供接口或使AI集成到现有产品变得容易。以下是一些正在流行起来的AI应用接口：
- en: Standalone web, desktop, and mobile apps.^([26](ch01.html#id668))
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独立Web、桌面和移动应用.^([26](ch01.html#id668))
- en: Browser extensions that let users quickly query AI models while browsing.
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 浏览器扩展，允许用户在浏览时快速查询AI模型。
- en: Chatbots integrated into chat apps like Slack, Discord, WeChat, and WhatsApp.
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集成到Slack、Discord、微信和WhatsApp等聊天应用中的聊天机器人。
- en: Many products, including VSCode, Shopify, and Microsoft 365, provide APIs that
    let developers integrate AI into their products as plug-ins and add-ons. These
    APIs can also be used by AI agents to interact with the world, as discussed in
    [Chapter 6](ch06.html#ch06_rag_and_agents_1730157386571386).
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 许多产品，包括VSCode、Shopify和Microsoft 365，都提供了API，允许开发者将AI集成到他们的产品中作为插件和附加组件。这些API还可以被AI代理用来与世界交互，如[第6章](ch06.html#ch06_rag_and_agents_1730157386571386)中讨论的。
- en: While the chat interface is the most commonly used, AI interfaces can also be
    voice-based (such as with voice assistants) or embodied (such as in augmented
    and virtual reality).
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然聊天界面是最常用的，但AI界面也可以基于语音（如语音助手）或具身（如在增强和虚拟现实中）。
- en: These new AI interfaces also mean new ways to collect and extract user feedback.
    The conversation interface makes it so much easier for users to give feedback
    in natural language, but this feedback is harder to extract. User feedback design
    is discussed in [Chapter 10](ch10.html#ch10_ai_engineering_architecture_and_user_feedback_1730130985311851).
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 这些新的AI界面也意味着收集和提取用户反馈的新方法。对话界面使得用户以自然语言给出反馈变得容易得多，但这种反馈提取起来更困难。用户反馈设计在[第10章](ch10.html#ch10_ai_engineering_architecture_and_user_feedback_1730130985311851)中讨论。
- en: A summary of how the importance of different categories of app development changes
    with AI engineering is shown in [Table 1-6](#ch01_table_6_1730130814941642).
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: '[表1-6](#ch01_table_6_1730130814941642)展示了随着人工智能工程的发展，不同类别应用开发的重要性如何变化。'
- en: Table 1-6\. The importance of different categories in app development for AI
    engineering and ML engineering.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 表1-6\. 人工智能工程和机器学习工程中不同类别在应用开发中的重要性。
- en: '| Category | Building with traditional ML | Building with foundation models
    |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| 分类 | 使用传统机器学习构建 | 使用基础模型构建 |'
- en: '| --- | --- | --- |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| AI interface | Less important | Important |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| 人工智能界面 | 不太重要 | 重要 |'
- en: '| Prompt engineering | Not applicable | Important |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| 提示工程 | 不适用 | 重要 |'
- en: '| Evaluation | Important | More important |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| 评估 | 重要 | 更重要 |'
- en: AI Engineering Versus Full-Stack Engineering
  id: totrans-401
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 人工智能工程与全栈工程
- en: The increased emphasis on application development, especially on interfaces,
    brings AI engineering closer to full-stack development.^([27](ch01.html#id675))
    The rising importance of interfaces leads to a shift in the design of AI toolings
    to attract more frontend engineers. Traditionally, ML engineering is Python-centric.
    Before foundation models, the most popular ML frameworks supported mostly Python
    APIs. Today, Python is still popular, but there is also increasing support for
    JavaScript APIs, with [LangChain.js](https://github.com/langchain-ai/langchainjs),
    [Transformers.js](https://github.com/huggingface/transformers.js), [OpenAI’s Node
    library](https://github.com/openai/openai-node), and [Vercel’s AI SDK](https://github.com/vercel/ai).
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 对应用开发，尤其是界面的重视，使人工智能工程更接近全栈开发。[27](ch01.html#id675)  界面日益重要导致AI工具设计方向的转变，以吸引更多前端工程师。传统上，机器学习工程以Python为中心。在基础模型出现之前，最受欢迎的机器学习框架主要支持Python
    API。今天，Python仍然很受欢迎，但JavaScript API的支持也在增加，包括[LangChain.js](https://github.com/langchain-ai/langchainjs)，[Transformers.js](https://github.com/huggingface/transformers.js)，[OpenAI的Node库](https://github.com/openai/openai-node)，以及[Vercel的AI
    SDK](https://github.com/vercel/ai)。
- en: While many AI engineers come from traditional ML backgrounds, more are increasingly
    coming from web development or full-stack backgrounds. An advantage that full-stack
    engineers have over traditional ML engineers is their ability to quickly turn
    ideas into demos, get feedback, and iterate.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然许多人工智能工程师来自传统的机器学习背景，但越来越多的人来自Web开发或全栈背景。全栈工程师相对于传统机器学习工程师的优势在于他们能够快速将想法转化为演示，获取反馈，并进行迭代。
- en: With traditional ML engineering, you usually start with gathering data and training
    a model. Building the product comes last. However, with AI models readily available
    today, it’s possible to start with building the product first, and only invest
    in data and models once the product shows promise, as visualized in [Figure 1-16](#ch01_figure_16_1730130814920205).
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 使用传统的机器学习工程，你通常从收集数据和训练模型开始。构建产品是最后一步。然而，随着今天可用的AI模型，可以首先从构建产品开始，一旦产品显示出希望，再投资于数据和模型，如图[图1-16](#ch01_figure_16_1730130814920205)所示。
- en: '![A close-up of arrows'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: '![箭头的特写'
- en: Description automatically generated](assets/aien_0116.png)
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 自动生成的描述](assets/aien_0116.png)
- en: Figure 1-16\. The new AI engineering workflow rewards those who can iterate
    fast. Image recreated from “The Rise of the AI Engineer” ([Shawn Wang, 2023](https://oreil.ly/OOZK-)).
  id: totrans-407
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-16\. 新的人工智能工程工作流程奖励那些能够快速迭代的人。图片来自“人工智能工程师的崛起”([肖恩·王，2023](https://oreil.ly/OOZK-))。
- en: In traditional ML engineering, model development and product development are
    often disjointed processes, with ML engineers rarely involved in product decisions
    at many organizations. However, with foundation models, AI engineers tend to be
    much more involved in building the product.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的机器学习工程中，模型开发和产品开发通常是分离的过程，许多组织的机器学习工程师很少参与产品决策。然而，随着基础模型的出现，人工智能工程师在构建产品方面往往更加参与。
- en: Summary
  id: totrans-409
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: I meant this chapter to serve two purposes. One is to explain the emergence
    of AI engineering as a discipline, thanks to the availability of foundation models.
    Two is to give an overview of the process needed to build applications on top
    of these models. I hope that this chapter achieved this goal. As an overview chapter,
    it only lightly touched on many concepts. These concepts will be explored further
    in the rest of the book.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这一章能起到两个作用。一是解释人工智能工程作为一门学科的兴起，归功于基础模型的出现。二是概述在这些模型之上构建应用程序所需的过程。我希望这一章达到了这个目标。作为概述章节，它只是轻触了许多概念。这些概念将在本书的其余部分进一步探讨。
- en: The chapter discussed the rapid evolution of AI in recent years. It walked through
    some of the most notable transformations, starting with the transition from language
    models to large language models, thanks to a training approach called self-supervision.
    It then traced how language models incorporated other data modalities to become
    foundation models, and how foundation models gave rise to AI engineering.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论了近年来人工智能的快速演变。它回顾了一些最显著的转变，从语言模型到大型语言模型的过渡，这得益于一种称为自监督的训练方法。然后追溯了语言模型如何通过纳入其他数据模式成为基础模型，以及基础模型如何催生了人工智能工程。
- en: The rapid growth of AI engineering is motivated by the many applications enabled
    by the emerging capabilities of foundation models. This chapter discussed some
    of the most successful application patterns, both for consumers and enterprises.
    Despite the incredible number of AI applications already in production, we’re
    still in the early stages of AI engineering, with countless more innovations yet
    to be built.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能工程的快速增长是由基础模型新兴能力所启用的众多应用所推动的。本章讨论了一些最成功的应用模式，包括消费者和企业。尽管已经有许多人工智能应用投入生产，但我们仍然处于人工智能工程的早期阶段，还有无数的创新等待构建。
- en: Before building an application, an important yet often overlooked question is
    whether you should build it. This chapter discussed this question together with
    major considerations for building AI applications.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 在构建应用程序之前，一个重要但又常常被忽视的问题是你是否应该构建它。本章讨论了这个问题，以及构建人工智能应用程序的主要考虑因素。
- en: While AI engineering is a new term, it evolved out of ML engineering, which
    is the overarching discipline involved with building applications with all ML
    models. Many principles from ML engineering are still applicable to AI engineering.
    However, AI engineering also brings with it new challenges and solutions. The
    last section of the chapter discusses the AI engineering stack, including how
    it has changed from ML engineering.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然人工智能工程是一个新术语，但它是从机器学习工程演变而来的，机器学习工程是涉及使用所有机器学习模型构建应用程序的总体学科。许多机器学习工程的原则仍然适用于人工智能工程。然而，人工智能工程也带来了新的挑战和解决方案。本章的最后部分讨论了人工智能工程栈，包括它如何从机器学习工程中演变而来。
- en: One aspect of AI engineering that is especially challenging to capture in writing
    is the incredible amount of collective energy, creativity, and engineering talent
    that the community brings. This collective enthusiasm can often be overwhelming,
    as it’s impossible to keep up-to-date with new techniques, discoveries, and engineering
    feats that seem to happen constantly.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能工程的一个特别难以用文字描述的方面是社区带来的巨大集体能量、创造力和工程才能。这种集体热情常常令人难以承受，因为很难跟上不断出现的新技术、发现和工程壮举。
- en: One consolation is that since AI is great at information aggregation, it can
    help us aggregate and summarize all these new updates. But tools can help only
    to a certain extent. The more overwhelming a space is, the more important it is
    to have a framework to help us navigate it. This book aims to provide such a framework.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 一个安慰是，由于人工智能擅长信息聚合，它可以帮助我们聚合和总结所有这些新更新。但工具只能帮助到一定程度。一个领域越令人难以承受，就越需要一个框架来帮助我们导航。本书旨在提供这样一个框架。
- en: 'The rest of the book will explore this framework step-by-step, starting with
    the fundamental building block of AI engineering: the foundation models that make
    so many amazing applications possible.'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 本书余下的部分将逐步探索这个框架，从人工智能工程的基本构建块开始：使许多令人惊叹的应用成为可能的基础模型。
- en: ^([1](ch01.html#id534-marker)) In this book, I use *traditional ML* to refer
    to all ML before foundation models.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch01.html#id534-marker)) 在本书中，我使用 *传统机器学习* 来指代基础模型之前的所有机器学习。
- en: ^([2](ch01.html#id536-marker)) For non-English languages, a single Unicode character
    can sometimes be represented as multiple tokens.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch01.html#id536-marker)) 对于非英语语言，一个单一的Unicode字符有时可以表示为多个标记。
- en: ^([3](ch01.html#id541-marker)) Autoregressive language models are sometimes
    referred to as [causal language models](https://oreil.ly/h0Y8x).
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch01.html#id541-marker)) 自回归语言模型有时被称为 [因果语言模型](https://oreil.ly/h0Y8x)。
- en: ^([4](ch01.html#id542-marker)) Technically, a masked language model like BERT
    can also be used for text generations if you try really hard.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch01.html#id542-marker)) 技术上，如果你真的努力，像BERT这样的掩码语言模型也可以用于文本生成。
- en: ^([5](ch01.html#id545-marker)) The actual data labeling cost varies depending
    on several factors, including the task’s complexity, the scale (larger datasets
    typically result in lower per-sample costs), and the labeling service provider.
    For example, as of September 2024, [Amazon SageMaker Ground Truth](https://oreil.ly/EVXJl)
    charges 8 cents per image for labeling fewer than 50,000 images, but only 2 cents
    per image for labeling more than 1 million images.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch01.html#id545-marker)) 实际的数据标注成本取决于多个因素，包括任务的复杂度、规模（较大的数据集通常会导致每样本成本降低），以及标注服务提供商。例如，截至2024年9月，[Amazon
    SageMaker Ground Truth](https://oreil.ly/EVXJl)对标注少于50,000张图片的费用为每张8美分，但对标注超过1百万张图片的费用仅为每张2美分。
- en: ^([6](ch01.html#id546-marker)) This is similar to how it’s important for humans
    to know when to stop talking.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch01.html#id546-marker)) 这与人类知道何时停止说话一样重要。
- en: ^([7](ch01.html#id547-marker)) In school, I was taught that model parameters
    include both model weights and model biases. However, today, we generally use
    model weights to refer to all parameters.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch01.html#id547-marker)) 在学校，我被教导模型参数包括模型权重和模型偏差。然而，今天，我们通常用模型权重来指代所有参数。
- en: ^([8](ch01.html#id549-marker)) It seems counterintuitive that larger models
    require more training data. If a model is more powerful, shouldn’t it require
    fewer examples to learn from? However, we’re not trying to get a large model to
    match the performance of a small model using the same data. We’re trying to maximize
    model performance.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch01.html#id549-marker)) 似乎反直觉的是，更大的模型需要更多的训练数据。如果一个模型更强大，难道不应该需要更少的例子来学习吗？然而，我们并不是试图让一个大模型使用相同的数据来匹配小模型的表现。我们试图最大化模型性能。
- en: ^([9](ch01.html#id561-marker)) For comparison, the entire US expenditures for
    public elementary and secondary schools are around $900 billion, only nine times
    the investments in AI in the US.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](ch01.html#id561-marker)) 作为比较，美国公共小学和中学的总支出约为9万亿美元，仅是美国AI投资的九倍。
- en: '^([10](ch01.html#id566-marker)) Fun fact: as of September 16, 2024, the website
    [*theresanaiforthat.com*](https://theresanaiforthat.com/) lists 16,814 AIs for
    14,688 tasks and 4,803 jobs.'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: ^([10](ch01.html#id566-marker)) 有趣的事实：截至2024年9月16日，网站[*theresanaiforthat.com*](https://theresanaiforthat.com/)列出了16,814个AI，用于14,688个任务和4,803个职位。
- en: ^([11](ch01.html#id567-marker)) Exploring different AI applications is perhaps
    one of my favorite things about writing this book. It’s a lot of fun seeing what
    people are building. You can find the [list of open source AI applications](https://huyenchip.com/llama-police)
    that I track. The list is updated every 12 hours.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: ^([11](ch01.html#id567-marker)) 探索不同的AI应用可能是我在撰写这本书时最喜欢的事情之一。看到人们正在构建什么非常有趣。您可以找到我跟踪的[开源AI应用列表](https://huyenchip.com/llama-police)。该列表每12小时更新一次。
- en: ^([12](ch01.html#id572-marker)) Because enterprises usually spend a lot of money
    on ads and marketing, automation there can lead to huge savings. On average, 11%
    of a company’s budget is spent on marketing. See [“Marketing Budgets Vary by Industry”](https://oreil.ly/D0-yA)
    (Christine Moorman, *WSJ*, 2017).
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: ^([12](ch01.html#id572-marker)) 由于企业通常在广告和营销上花费大量资金，因此自动化可以带来巨大的节省。平均而言，公司的11%的预算用于营销。参见[“Marketing
    Budgets Vary by Industry”](https://oreil.ly/D0-yA)（Christine Moorman，*WSJ*，2017）。
- en: ^([13](ch01.html#id574-marker)) I have found AI very helpful in the process
    of writing this book, and I can see that AI will be able to automate many parts
    of the writing process. When writing fiction, I often ask AI to brainstorm ideas
    on what it thinks will happen next or how a character might react to a situation.
    I’m still evaluating what kind of writing can be automated and what kind of writing
    can’t be.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: ^([13](ch01.html#id574-marker)) 我发现AI在撰写这本书的过程中非常有帮助，并且可以看出AI将能够自动化写作过程的许多部分。在撰写小说时，我经常让AI构思它认为接下来会发生什么或一个角色可能如何对某种情况进行反应的想法。我仍在评估哪些类型的写作可以自动化，哪些类型的写作不能。
- en: ^([14](ch01.html#id575-marker)) My hypothesis is that we’ll become so distrustful
    of content on the internet that we’ll only read content generated by people or
    brands we trust.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: ^([14](ch01.html#id575-marker)) 我的假设是，我们将对互联网上的内容产生如此大的不信任，以至于我们只会阅读我们信任的人或品牌生成的内容。
- en: ^([15](ch01.html#id584-marker)) It surprises me how long it takes Apple and
    Amazon to incorporate generative AI advances into Siri and Alexa. A friend thinks
    it’s because these companies might have higher bars for quality and compliance,
    and it takes longer to develop voice interfaces than chat interfaces.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: ^([15](ch01.html#id584-marker)) 苹果和亚马逊将生成式AI的进步融入Siri和Alexa的速度让我感到惊讶。一位朋友认为这可能是因为这些公司可能对质量和合规性有更高的标准，开发语音界面的时间比聊天界面长。
- en: '^([16](ch01.html#id585-marker)) Disclaimer: I’m an advisor of Convai.'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: ^([16](ch01.html#id585-marker)) 声明：我是Convai的顾问。
- en: ^([17](ch01.html#id592-marker)) I currently have over 40,000 photos and videos
    in my Google Photos. Without AI, it’d be near impossible for me to search for
    the photos I want, when I want them.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: ^([17](ch01.html#id592-marker)) 我目前在Google Photos中拥有超过40,000张照片和视频。没有AI，我几乎不可能在我需要的时候找到我想要的图片。
- en: ^([18](ch01.html#id593-marker)) Personally, I also find AI good at explaining
    data and graphs. When encountering a confusing graph with too much information,
    I ask ChatGPT to break it down for me.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: ^([18](ch01.html#id593-marker)) 个人而言，我也发现AI擅长解释数据和图表。当遇到信息过多的复杂图表时，我会让ChatGPT为我分解它。
- en: ^([19](ch01.html#id599-marker)) Smaller startups, however, might have to prioritize
    product focus and can’t afford to have even one person to “look around.”
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: ^([19](ch01.html#id599-marker)) 然而，较小的初创公司可能必须优先考虑产品重点，而且无法承担连一个人“四处看看”的代价。
- en: ^([20](ch01.html#id607-marker)) A running joke in the early days of generative
    AI is that AI startups are OpenAI or Claude wrappers.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: ^([20](ch01.html#id607-marker)) 在生成式AI的早期，有一个流行的笑话是，AI初创公司只是OpenAI或Claude的包装。
- en: ^([21](ch01.html#id608-marker)) During the process of writing this book, I could
    hardly talk to any AI startup without hearing the phrase “data flywheel.”
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: ^([21](ch01.html#id608-marker)) 在撰写这本书的过程中，我几乎和任何AI初创公司交谈都不会听到“数据飞轮”这个词。
- en: '^([22](ch01.html#id609-marker)) Disclaimer: I’m an investor in Photoroom.'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: ^([22](ch01.html#id609-marker)) 声明：我是Photoroom的投资者。
- en: '^([23](ch01.html#id640-marker)) As the head of AI at a Fortune 500 company
    told me: his team knows how to work with 10 GPUs, but they don’t know how to work
    with 1,000 GPUs.'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: ^([23](ch01.html#id640-marker)) 一家财富500强公司的AI负责人告诉我：他的团队知道如何使用10个GPU，但他们不知道如何使用1,000个GPU。
- en: ^([24](ch01.html#id642-marker)) And they are offered [incredible compensation
    packages](https://oreil.ly/AhANP).
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: ^([24](ch01.html#id642-marker)) 他们提供的[令人难以置信的薪酬方案](https://oreil.ly/AhANP)。
- en: ^([25](ch01.html#id645-marker)) If you find the terms “pre-training” and “post-training”
    lacking in imagination, you’re not alone. The AI research community is great at
    many things, but naming isn’t one of them. We already talked about how “large
    language models” is hardly a scientific term because of the ambiguity of the word
    “large”. And I really wish people would stop publishing papers with the title
    “X is all you need.”
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: ^([25](ch01.html#id645-marker)) 如果你觉得“预训练”和“后训练”这两个术语缺乏想象力，你并不孤单。AI研究社区在很多方面都很出色，但命名并不是其中之一。我们已经讨论过，“大型语言模型”这个术语几乎不是一个科学的术语，因为“大”这个词的模糊性。我真的希望人们停止发表标题为“X是你所需要的”的论文。
- en: ^([26](ch01.html#id668-marker)) Streamlit, Gradio, and Plotly Dash are common
    tools for building AI web apps.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: ^([26](ch01.html#id668-marker)) Streamlit、Gradio和Plotly Dash是构建AI网络应用的常见工具。
- en: ^([27](ch01.html#id675-marker)) Anton Bacaj told me that “AI engineering is
    just software engineering with AI models thrown in the stack.”
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: ^([27](ch01.html#id675-marker)) 安东·巴卡告诉我，“AI工程只是将AI模型加入软件工程堆栈中。”
