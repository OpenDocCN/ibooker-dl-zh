- en: 9 RAG development framework and further exploration
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 9 RAG 开发框架及进一步探索
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: A recap of the concepts covered in this book using a six-stage RAG development
    framework
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用六阶段 RAG 开发框架回顾本书中涵盖的概念
- en: Areas for further exploration
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进一步探索的领域
- en: The previous eight chapters covered a wide breadth of retrieval-augmented generation
    (RAG), including a conceptual foundation, critical components, evaluation methods,
    advanced techniques, the operations stack, and essential variants of RAG. By now,
    you should be equipped with the necessary information required to develop RAG
    systems.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 前八章涵盖了广泛的检索增强生成（RAG）内容，包括概念基础、关键组件、评估方法、高级技术、操作堆栈和 RAG 的基本变体。到现在，你应该已经具备了开发
    RAG 系统所需的所有必要信息。
- en: This concluding chapter summarizes the discussion and recaps all the previously
    discussed concepts. To accomplish this, we put all the different aspects of developing
    RAG systems together and came up with a RAG development framework. Across the
    six stages of this RAG development framework, we recap the concepts covered in
    this book along with some best practices. This framework not only covers the technical
    aspects but also looks at the development process holistically.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这最后一章总结了讨论内容，并回顾了之前讨论的所有概念。为了完成这一目标，我们将开发 RAG 系统的所有不同方面结合起来，并提出一个 RAG 开发框架。在这个
    RAG 开发框架的六个阶段中，我们回顾了本书中涵盖的概念以及一些最佳实践。这个框架不仅涵盖了技术方面，而且从整体上审视了开发过程。
- en: RAG is a rapidly evolving technique. At the end of this chapter, we also discuss
    some of the ideas that you can explore further. Some of these approaches to incorporating
    context may compete with the RAG technique, while others may be complementary.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 是一种快速发展的技术。在本章结束时，我们还将讨论一些你可以进一步探索的想法。其中一些将上下文纳入的方法可能与 RAG 技术竞争，而另一些则可能是互补的。
- en: By the end of this chapter, you should
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你应该
- en: Have reviewed and consolidated your understanding of key RAG concepts.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已审查并巩固你对关键 RAG 概念的理解。
- en: Get a solid understanding of the RAG development framework.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 RAG 开发框架的坚实基础。
- en: Be ready to build and deploy RAG systems.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备构建和部署 RAG 系统。
- en: Often, the problem statements that the developer of a RAG system is presented
    with will be open ended. For example, an e-commerce platform wants to develop
    a buying assistant, or the marketing function wants a research agent to track
    and summarize competitive information. So, how does one navigate from an open-ended
    problem statement to a fully developed RAG system? It becomes very important that
    this journey is guided by a thought process. For this purpose, let’s define and
    discuss a framework for developing RAG systems.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，RAG 系统开发者面临的问题陈述往往是开放式的。例如，一个电商平台希望开发一个购买助手，或者营销部门需要一个研究代理来跟踪和总结竞争信息。那么，如何从开放式的问题陈述过渡到一个完全开发的
    RAG 系统？这个过程由一个思维过程引导变得非常重要。为此，让我们定义并讨论一个开发 RAG 系统的框架。
- en: 9.1 RAG development framework
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.1 RAG 开发框架
- en: 'The process of developing RAG systems is not very different from developing
    an application that uses a machine learning model. We have seen that a RAG system
    can be complex and include several components. It goes beyond the elements such
    as models, data, and retrievers. It requires a service infrastructure to make
    the system available to users. Evaluation, monitoring, and maintaining the systems
    becomes as important as developing and deploying them. It all begins with an understanding
    of requirements and a conceptual design. To address all these aspects, a RAG development
    framework that will assist us in building RAG systems is proposed here. This framework
    involves the following six stages:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 开发 RAG 系统的过程与开发使用机器学习模型的程序并没有很大区别。我们已经看到，RAG 系统可能很复杂，包括多个组件。它超越了模型、数据和检索器等元素。它需要一个服务基础设施来使系统可供用户使用。评估、监控和维护系统与开发和部署同样重要。这一切都始于对需求的理解和概念设计。为了解决所有这些方面，我们提出了一个将帮助我们构建
    RAG 系统的 RAG 开发框架。这个框架包括以下六个阶段：
- en: '*Initiatio**n*—This stage involves understanding the problem statement, aligning
    the stakeholders, gathering system requirements, and analyzing these requirements
    to draft a high-level system architecture.'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*启动*—这一阶段涉及理解问题陈述，协调利益相关者，收集系统需求，并分析这些需求以制定高级系统架构。'
- en: '*Desig**n*—At this stage, design choices for RAG pipelines are made, and the
    suite of tools to develop the system is developed. In addition, different layers
    of the RAG operations stack are conceptualized.'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*设计*—在这个阶段，为RAG管道做出设计选择，并开发用于构建系统的工具集。此外，还概念化了RAG操作堆栈的不同层次。'
- en: '*Developmen**t*—This stage involves developing a working prototype of the desired
    RAG system. All required models are trained, and the required APIs are developed.
    This stage leads to the creation of the knowledge base and the development of
    the application orchestration layer.'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*开发*—这个阶段涉及开发所需RAG系统的可工作原型。所有必需的模型都经过训练，并开发了所需的API。这个阶段导致知识库的创建和应用程序编排层的开发。'
- en: '*Evaluation*—During this stage, the retrieval and generation components are
    evaluated, along with testing the end-to-end system performance. At the end of
    this stage, the system is ready for deployment.'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*评估*—在这个阶段，评估检索和生成组件，以及测试端到端系统的性能。在这个阶段结束时，系统准备就绪，可以部署。'
- en: '*Deploymen**t*—During this stage, the system is made available to end users.
    The deployment strategy is also decided at this stage.'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*部署*—在这个阶段，系统对最终用户可用。部署策略也在此阶段决定。'
- en: '*Maintenanc**e*—This final stage is an ongoing one that involves system monitoring,
    incorporating user feedback, and keeping abreast of technological enhancements.'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*维护*—这个最终阶段是一个持续的过程，涉及系统监控、整合用户反馈和跟踪技术改进。'
- en: Bear in mind that the RAG development framework is not a linear process, but
    flexible, iterative, and cyclic. Figure 9.1 illustrates the cyclic nature of the
    six stages of the RAG development framework, showing the key artifacts of each
    stage.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，RAG开发框架不是一个线性过程，而是灵活的、迭代的和循环的。图9.1说明了RAG开发框架六个阶段的循环性质，展示了每个阶段的关键工件。
- en: '![A diagram of a process'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![一个流程图'
- en: AI-generated content may be incorrect.](../Images/CH09_F01_Kimothi.png)
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的内容可能是不正确的。](../Images/CH09_F01_Kimothi.png)
- en: Figure 9.1  The six stages of the RAG development framework are iterative and
    cyclic. At each stage, specific artifacts can be created.
  id: totrans-23
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.1 RAG开发框架的六个阶段是迭代和循环的。在每一个阶段，都可以创建特定的工件。
- en: Each of the stages involves certain activities. We look at these activities
    one by one and discuss the best practices associated with them. We begin with
    the initiation stage.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 每个阶段都涉及某些活动。我们逐一查看这些活动，并讨论与之相关的最佳实践。我们首先从启动阶段开始。
- en: '9.1.1 Initiation stage: Defining and scoping the RAG system'
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1.1 启动阶段：定义和范围RAG系统
- en: The journey toward a successful RAG system begins with the initial interactions
    with the stakeholders. This is an opportunity to gain an in-depth understanding
    of the problem statement and the user requirements. It is an exploratory stage
    and sets the direction of the project.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 成功RAG系统的旅程始于与利益相关者的初始互动。这是一个深入了解问题陈述和用户需求的机会。这是一个探索阶段，并为项目设定了方向。
- en: Use case identification
  id: totrans-27
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 用例识别
- en: 'A lot of the choices a developer will make in the development process of a
    RAG system depend heavily on the use case being addressed. Even a basic understanding
    of the industry domain/function and a simple definition of the use case is enough
    to answer crucial starting questions about the system. The requirement of a RAG
    system needs to be assessed here. Recall from chapter 1 the challenges that RAG
    solves: RAG overcomes training data limitations, knowledge cut-off date, and LLM
    hallucinations to bring factual accuracy, reliability, and trust to the system.
    It is important to assess whether these RAG benefits are pivotal to the use case.
    There can be LLM applications that may not even require RAG. Here are some questions
    you may need to ask at this stage:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 开发者在RAG系统开发过程中所做的许多选择都高度依赖于所解决的使用案例。即使对行业领域/功能有基本了解，以及对使用案例的简单定义也足以回答关于系统的关键起始问题。需要评估RAG系统的需求。回想一下第1章中RAG解决的问题：RAG克服了训练数据限制、知识截止日期和LLM的幻觉，为系统带来了事实准确性、可靠性和信任。评估这些RAG收益是否对使用案例至关重要是很重要的。可能存在不需要RAG的LLM应用。在这个阶段，你可能需要问以下问题：
- en: Does the system require data that may not be present in the training set of
    an available LLM?
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统是否需要可能不在可用LLM训练集中的数据？
- en: Does the system require data that is current or updates frequently?
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统是否需要当前数据或频繁更新的数据？
- en: Does the system need to quote or generate facts? How crucial is the accuracy
    of the generated facts?
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统需要引用或生成事实吗？生成事实的准确性有多重要？
- en: Will the users benefit if the sources are cited?
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果引用了来源，用户会受益吗？
- en: A use case evaluation card as the one shown in figure 9.2 can help in assessing
    whether a RAG system is required to solve the use case. Use cases such as creative
    writing, language translation, sentiment analysis, grammar correction, and so
    forth do not generally require a RAG system unless some nuance of the use case
    warrants it.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如图9.2所示的用例评估卡可以帮助评估是否需要RAG系统来解决用例。如创意写作、语言翻译、情感分析、语法纠正等用例通常不需要RAG系统，除非用例的某些细微之处需要它。
- en: Apart from this, the industry domain and function can also give an early indication
    of the system requirements. For example, use cases from the healthcare and finance
    domain may require more security and compliance measures, while a use case from
    sports may require processing of quickly updating information.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这个之外，行业领域和功能也可以给出对系统需求的早期指示。例如，来自医疗和金融领域的用例可能需要更多的安全和合规措施，而来自体育领域的用例可能需要处理快速更新的信息。
- en: This initial assessment of the use case may provide early insights, but a detailed
    understanding and analysis of the requirements is necessary before proceeding
    further.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 对用例的初步评估可能提供早期见解，但在进一步进行之前，对需求进行详细理解和分析是必要的。
- en: Gathering of requirements
  id: totrans-36
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 收集需求
- en: Developing the right RAG system means meeting the stakeholders’ needs and wants.
    Understanding these needs and wants is a crucial step. Gaining this understanding
    is an interactive and investigative process. Most stakeholders and end users may
    have limited knowledge about technology and how a RAG system is built. It is therefore
    important to know what a successful application would mean to them. These requirements
    can range from the features needed in the system to the expected scale and the
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 开发正确的RAG系统意味着满足利益相关者的需求和期望。理解这些需求和期望是一个关键步骤。获得这种理解是一个互动和调查的过程。大多数利益相关者和最终用户可能对技术以及如何构建RAG系统了解有限。因此，了解成功应用对他们意味着什么非常重要。这些需求可能包括系统中需要的特性，到预期的规模和系统的期望性能。
- en: '![A chart of a system'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '![系统图表'
- en: AI-generated content may be incorrect.](../Images/CH09_F02_Kimothi.png)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的内容可能是错误的。](../Images/CH09_F02_Kimothi.png)
- en: Figure 9.2  A use case evaluation card with the evaluating questions can help
    in assessing whether a RAG system is required to address the use case.
  id: totrans-40
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.2  带有评估问题的用例评估卡可以帮助评估是否需要RAG系统来应对用例。
- en: desired performance of the system. A good way to gather requirements may be
    to look at them through different lenses, such as
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 期望的性能。收集需求的一个好方法是通过不同的视角来看待它们，例如
- en: '*Business objective**s*—These requirements relate to the main business reasons
    for building these systems, such as increasing click-through rates, saving process
    costs, improving customer satisfaction, and so forth. Technical developers may
    not directly be responsible for business metrics, but these business metrics can
    act as the leading light in the development process of the system.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*业务目标*—这些需求与构建这些系统的核心商业原因相关，例如提高点击率、节省流程成本、提高客户满意度等。技术开发者可能不直接负责业务指标，但这些业务指标可以在系统开发过程中起到指引作用。'
- en: '*User need**s*—These are the core requirements of the users for whom the system
    is being developed. Expressing these needs helps in determining the inputs and
    outputs of the system along with other functionalities such as multilingual support
    and source citation. These needs are also key in determining the types of user
    queries that the RAG system can expect.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*用户需求*—这些是系统开发目标用户的核心理求。表达这些需求有助于确定系统的输入和输出，以及其他功能，如多语言支持和来源引用。这些需求也是确定RAG系统可以预期的用户查询类型的关键。'
- en: '*Functional requirement**s*—These are the core functionalities of the system,
    such as the supported data types, number of documents to be retrieved and length/tone/style
    of generation, and similar. Functional requirements are influenced by user needs
    and business objectives. They are also the main influencers of the development
    process.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*功能需求*—这些是系统的核心功能，例如支持的数据类型、要检索的文档数量以及生成内容的长度/语气/风格等。功能需求受用户需求和业务目标的影响。它们也是开发过程的主要影响因素。'
- en: '*Non-functional requirement**s*—These are requirements about the performance,
    scalability, reliability, security, and privacy of the system. There may be additional
    requirements such as legal and compliance, especially for regulated industries.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*非功能性需求*——这些是关于系统性能、可扩展性、可靠性、安全性和隐私的要求。可能还有其他要求，如法律和合规性，尤其是在受监管的行业。'
- en: '*Constraint**s*—One should also focus on any constraints that the system should
    be cognizant of, such as access to the internet, availability of data, cost, and
    integration with existing systems.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*限制*——还应关注系统应意识到的任何限制，例如互联网访问、数据可用性、成本和与现有系统的集成。'
- en: A customer service system, for example, may be envisioned to reduce customer
    query resolution time, requiring quick response time and a constraint of integrating
    with existing customer support platforms. An illustrative requirement document
    for the above can look like the one shown in figure 9.3, detailing out different
    types of requirements.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个客户服务系统可能被设想为减少客户查询解决时间，需要快速响应时间，并限制与现有客户支持平台的集成。上述要求的示例文档可能看起来像图9.3中所示，详细说明了不同类型的要求。
- en: '![A screenshot of a customer support system'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '![客户支持系统截图'
- en: AI-generated content may be incorrect.](../Images/CH09_F03_Kimothi.png)
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的内容可能不正确。](../Images/CH09_F03_Kimothi.png)
- en: Figure 9.3  An illustrative requirements document for a customer support system
    requiring RAG
  id: totrans-50
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.3  需要RAG的客户支持系统的示例要求文档
- en: Requirements analysis
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 需求分析
- en: Eliciting requirements from the stakeholders is a major activity in the initiation
    stage. These raw requirements then need to be analyzed. The requirements should
    be clear, precise, and quantifiable so that they can lead to specific development
    steps. For example, a non-functional need for a quick response may be too vague.
    Instead, a better requirement is that 90% of queries should be responded to within
    2 seconds. Similarly, a constraint of limited internet connectivity can lead the
    developer to believe that a completely offline system is required. Such vagueness
    in the requirements needs to be addressed in further interactions with the stakeholders.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在启动阶段，从利益相关者中提取需求是一项主要活动。然后需要分析这些原始需求。需求应该是清晰、精确和可量化的，以便它们可以导致特定的开发步骤。例如，对快速响应的非功能性需求可能过于模糊。相反，一个更好的需求是90%的查询应在2秒内得到响应。同样，有限的互联网连接限制可能导致开发者认为需要一个完全离线的系统。这种需求中的模糊性需要在与利益相关者的进一步互动中解决。
- en: At this stage, it is also important to define the success criteria on which
    the system will be evaluated. A few success metrics need to be defined and agreed
    on. For developers, these success metrics should be different from the business
    objectives since business outcomes may depend on factors beyond their control.
    Latency, throughput, percentage of queries resolved, and similar, are good criteria
    for success metrics. Figure 9.4 presents an illustrative requirements document
    after an analysis of the success metrics. It is an improvement on the previous
    requirement document shown in figure 9.3.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，定义系统评估的成功标准也非常重要。需要定义和同意几个成功指标。对于开发者来说，这些成功指标应该与业务目标不同，因为业务成果可能取决于他们无法控制的因素。延迟、吞吐量、查询解决百分比等是成功指标的良好标准。图9.4展示了在分析成功指标后的示例要求文档。这是对图9.3中显示的先前要求文档的改进。
- en: '![A screenshot of a customer support system'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '![客户支持系统截图'
- en: AI-generated content may be incorrect.](../Images/CH09_F04_Kimothi.png)
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的内容可能不正确。](../Images/CH09_F04_Kimothi.png)
- en: Figure 9.4  Illustrative requirements document with success metrics defined
    and requirements analyzed for clarity and precision
  id: totrans-56
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.4  定义了成功指标并分析了清晰性和精确性的示例要求文档
- en: High-level architecture
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 高级架构
- en: Once the requirements are understood well, the initiation stage can be deemed
    complete. It is good practice to close the initiation stage with a high-level
    architecture diagram that can be used as a starting point for the design stage.
    This architecture can be used to bring alignment among stakeholders and discuss
    the requirements further. The focus of this high-level architecture is to illustrate
    the system inputs and outputs. Since data plays such a crucial role in a RAG system,
    this high-level architecture should also include the data component. As illustrated
    in figure 9.5, for a multichannel customer support system, the system must allow
    inputs and outputs from and to different channels.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦对需求有深入了解，启动阶段可以被视为完成。在启动阶段结束时，使用一个高级架构图作为设计阶段的起点是一个好的做法。这个架构可用于在利益相关者之间达成一致并进一步讨论需求。这个高级架构的重点是说明系统的输入和输出。由于数据在RAG系统中扮演着如此关键的角色，这个高级架构还应包括数据组件。如图9.5所示，对于一个多渠道客户支持系统，系统必须允许从不同渠道进行输入和输出。
- en: '![A diagram of a product portal'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![产品门户图](../Images/CH09_F06_Kimothi.png)'
- en: AI-generated content may be incorrect.](../Images/CH09_F05_Kimothi.png)
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的内容可能是不正确的。](../Images/CH09_F05_Kimothi.png)
- en: Figure 9.5  High-level architecture of a proposed customer support bot highlighting
    inputs and outputs, along with the data, human-in-the-loop, and cache layers
  id: totrans-61
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.5  突出输入输出、数据、人工参与和缓存层的拟议客户支持机器人高级架构
- en: A first go/no-go decision or the going forward strategic call can be taken on
    the completion of the initiation stage. Once the stakeholders are aligned, all
    the RAG operations layers for the system can be designed in the next stage.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成启动阶段后，可以做出初步的通过/不通过决策或前进的战略性决策。一旦利益相关者达成一致，系统所有RAG操作层可以在下一阶段进行设计。
- en: '9.2 Design stage: Layering the RAGOps stack'
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.2 设计阶段：分层RAGOps堆栈
- en: With a clear understanding of the use case and the requirements, developers
    can start planning for the development. In the design stage, the high-level architecture
    is refined to map out RAGOps stack, and the choices around tools and technology
    are made. At this stage, we design the indexing and generation pipelines along
    with other components such as caching, guardrails, and the like.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在对用例和需求有清晰理解的基础上，开发者可以开始规划开发。在设计阶段，高级架构被细化以绘制RAGOps堆栈，并做出关于工具和技术的选择。在这一阶段，我们设计索引和生成管道，以及其他组件，如缓存、安全线等。
- en: 9.2.1 Indexing pipeline design
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.1 索引管道设计
- en: In the requirement-gathering step, we identify the data sources. During the
    design stage, we double-click on these data sources to identify the nature of
    the source systems, file types, and nature of the data itself to determine the
    development steps for the knowledge base. Recall from chapter 3 that the knowledge
    base is created for a RAG system via the indexing pipeline. Components such as
    data loading, chunking, embeddings, and storage form the indexing pipeline. In
    chapter 7, we also discussed that the data layer of the RAGOps stack enables this
    by extracting, transforming, and loading the data. Figure 9.6 summarizes the indexing
    pipeline components and the data layer.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在需求收集步骤中，我们识别数据源。在设计阶段，我们双击这些数据源以确定源系统的性质、文件类型和数据本身的性质，以确定知识库的开发步骤。回想第3章，知识库是通过索引管道为RAG系统创建的。数据加载、分块、嵌入和存储等组件构成了索引管道。在第7章，我们还讨论了RAGOps堆栈的数据层通过提取、转换和加载数据来实现这一点。图9.6总结了索引管道组件和数据层。
- en: '![A diagram of data processing'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '![数据处理图](../Images/CH09_F05_Kimothi.png)'
- en: AI-generated content may be incorrect.](../Images/CH09_F06_Kimothi.png)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的内容可能是不正确的。](../Images/CH09_F06_Kimothi.png)
- en: Figure 9.6  The indexing pipeline of the RAG system is executed using the data
    layer in the RAGOps stack.
  id: totrans-69
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.6  RAG系统的索引管道使用RAGOps堆栈中的数据层执行。
- en: Now let’s look at some important points of consideration that will help us when
    making the choices for the indexing pipeline design.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看一些重要的考虑要点，这些要点将帮助我们做出索引管道设计的决策。
- en: Data ingestion
  id: totrans-71
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据摄取
- en: 'When you’re working with less data, like a few PDF files or a couple of websites,
    *data ingestion* is a relatively simple step. However, in production-grade systems,
    the complexity increases with the scale of the data. Special attention needs to
    be given to the source systems and the file formats. Here are a few questions
    about connecting to source systems that will help in designing the data ingestion
    component:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 当你处理较少的数据，如几个PDF文件或几个网站时，*数据摄取*是一个相对简单的步骤。然而，在生产级系统中，随着数据规模的增加，复杂性也会增加。需要特别注意源系统和文件格式。以下是一些关于连接到源系统的问题，这些问题将有助于设计数据摄取组件：
- en: Which source systems will the data layer need to connect to?
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据层需要连接到哪些源系统？
- en: Are the connectors readily available? If yes, which tools or services are required
    to establish these connections?
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 连接器是否容易获取？如果是，需要哪些工具或服务来建立这些连接？
- en: Which connectors will need to be developed? Which technology will these connectors
    be developed on?
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要开发哪些连接器？这些连接器将基于哪种技术进行开发？
- en: Is access to open internet required? How will the system connect to the internet?
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否需要访问开放互联网？系统将如何连接到互联网？
- en: 'The following group of questions is about parsing files:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 以下问题组是关于文件解析的：
- en: Which file formats will be ingested?
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将摄取哪些文件格式？
- en: How will the web pages be scraped, if required?
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果需要，网页将如何被抓取？
- en: Do we have the necessary parsers for the different file types?
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否有不同文件类型的必要解析器？
- en: Is some special parsing technique required to be developed?
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否需要开发特殊的解析技术？
- en: Can there be more than one modality of data in a single file?
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单个文件中可以有多于一种的数据模态吗？
- en: The answers to these questions will determine the tools you will need to use
    for ingesting data and the parts that will need to be developed.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题的答案将决定你需要使用的工具来摄取数据以及需要开发的部件。
- en: Data transformation
  id: totrans-84
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据转换
- en: Once the data is ingested, the *transformation step* converts the data into
    a suitable format for the knowledge base. In the data transformation step, the
    data will first be cleaned and pre-processed. A good practice is also to extract
    metadata information. Sometimes, other preprocessing steps such as PII data redaction
    or resolving conflicting information are required.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦数据被摄取，*转换步骤*将数据转换为知识库的合适格式。在数据转换步骤中，数据首先将被清理和预处理。提取元数据信息也是一个好的实践。有时，还需要其他预处理步骤，如PII数据删除或解决冲突信息。
- en: After pre-processing, the data will be chunked using a suitable chunking technique.
    Chunk size, overlap size, and the chunking strategy should be decided at this
    stage. Chunking can be fixed size, structure driven, semantic chunking, or agentic
    chunking.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在预处理之后，数据将使用合适的分块技术进行分块。在此阶段应决定分块大小、重叠大小和分块策略。分块可以是固定大小、结构驱动、语义分块或代理分块。
- en: Once the chunks are created, they need to be transformed for retrieval. We have
    discussed approaches such as embeddings and knowledge graphs. For use cases that
    require relational understanding between chunks, knowledge graphs should be explored.
    The creation of vector embeddings is almost mandatory in all RAG systems. To create
    vector embeddings, pre-trained embeddings models can be used. However, sometimes,
    due to the peculiarity of the domain, embedding models may need to be fine-tuned.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建了分块，它们需要被转换以供检索。我们已经讨论了诸如嵌入和知识图谱的方法。对于需要分块之间关系理解的用例，应探索知识图谱。在所有RAG系统中，创建向量嵌入几乎是强制性的。为了创建向量嵌入，可以使用预训练的嵌入模型。然而，有时，由于领域的特殊性，嵌入模型可能需要微调。
- en: 'Let’s now look at some of the questions that should be considered at this stage.
    The first group of questions is about pre-processing:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在看看在这个阶段应该考虑的一些问题。第一组问题是关于预处理的：
- en: How noisy is the data? What algorithms and techniques can be used to clean up
    the data?
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据有多嘈杂？可以使用哪些算法和技术来清理数据？
- en: Is structured data like tables or JSON present?
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否存在结构化数据，如表格或JSON？
- en: Is metadata readily available, or should it be extracted?
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 元数据是否容易获取，或者是否需要提取？
- en: 'What algorithms or models should be used for metadata extraction? (Note: All
    models sit in the model library of the model layer of the RAGOps stack.)'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应该使用哪些算法或模型进行元数据提取？（注意：所有模型都位于RAGOps堆栈模型层的模型库中。）
- en: Does the data contain sensitive information that needs to be masked or redacted?
    What techniques will be used to execute this?
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据是否包含需要屏蔽或删除的敏感信息？将使用哪些技术来执行此操作？
- en: Are there any other data protocols or guidelines that need to be followed?
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否有其他需要遵循的数据协议或指南？
- en: 'When it comes to chunking, consider asking the following questions:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到分块时，考虑以下问题：
- en: Is the chunk size pre-determined? If not, what chunk sizes should be experimented
    with?
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分块大小是否预先确定？如果不是，应该实验哪些分块大小？
- en: Is the data in a format that will warrant structured chunking?
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据格式是否需要结构化分块？
- en: What techniques and models will be employed for semantic chunking, if required?
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果需要，将采用哪些技术和模型进行语义分块？
- en: Is a chunking agent readily available, or will it need to be built? Which models,
    algorithms, and tools will be used by the chunking agent?
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分块代理是否 readily 可用，或者需要构建？分块代理将使用哪些模型、算法和工具？
- en: 'The following group of questions covers graphRAG:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 以下问题组涵盖了 graphRAG：
- en: Is a hierarchical indexing structure required?
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否需要分层索引结构？
- en: Do we need to extract entities and relationships for relational context? Do
    we have the necessary budget?
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否需要提取关系上下文中的实体和关系？我们是否有必要的预算？
- en: What approaches are we going to take for entity-relationship extraction?
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将采取哪些方法进行实体-关系提取？
- en: Are we using any frameworks for graph extraction?
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否使用任何用于图提取的框架？
- en: Which models are going to be used?
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将使用哪些模型？
- en: 'As for embeddings, ask the following:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 关于嵌入，请考虑以下问题：
- en: Which embeddings model will we use? Are there any domain-specific embeddings
    models available that will be more useful?
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将使用哪种嵌入模型？是否有可用的特定领域嵌入模型，这将更有用？
- en: Are multimodal embeddings required?
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否需要多模态嵌入？
- en: Do we need to fine-tune embeddings for our use case? Do we have the training
    data for fine-tuning? How will the training data be sourced?
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否需要针对我们的用例微调嵌入？我们是否有用于微调的训练数据？训练数据将从哪里获取？
- en: Data transformation steps require significant thought and effort. This is also
    where significant costs can be incurred, especially in using agents and employing
    graphRAG.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 数据转换步骤需要大量的思考和努力。这也是可能产生重大成本的地方，尤其是在使用代理和采用 graphRAG 时。
- en: Data storage
  id: totrans-111
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 数据存储
- en: The final component of the data layer is the storage. Depending on the choices
    made during the data transformation, the storage will comprise vector stores,
    graph databases, and document stores (if necessary). At this stage, we should
    also keep in mind that a cache store may be required in the application that can
    be a part of the data layer. We will discuss caching separately. Some of the questions
    pertinent to data storage are
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 数据层的最后一个组件是存储。根据数据转换期间所做的选择，存储将包括向量存储、图数据库和文档存储（如果需要）。在这一阶段，我们还应该记住，应用程序可能需要一个缓存存储，这可以是数据层的一部分。我们将单独讨论缓存。与数据存储相关的一些问题是
- en: Can all data be stored in a single collection, or are multiple collections required?
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有数据是否可以存储在单个集合中，或者需要多个集合？
- en: Can we manage the vector database or do we require a managed service?
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们能否管理向量数据库，或者我们需要托管服务？
- en: What is the current scale of data and how is it likely to grow?
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前数据规模如何，以及它可能如何增长？
- en: Which vector database will we use?
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将使用哪种向量数据库？
- en: Do we need a graph database? Which graph database will we use?
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否需要一个图数据库？我们将使用哪个图数据库？
- en: Do we need to store raw documents or images? Which document store will we use
    for this purpose?
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否需要存储原始文档或图像？我们将使用哪种文档存储来执行此目的？
- en: With the storage in place, the creation of the knowledge base can be executed.
    It is important to note that the choices at this stage should be flexible. You
    should also keep options available for tools, services and libraries that can
    be experimented with during development. You’ll also have to estimate the costs
    associated with different steps of this stage and ensure that the stakeholders
    are aligned with these costs.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 在存储就绪后，可以执行知识库的创建。重要的是要注意，这一阶段的决策应该是灵活的。你还应该为开发期间可以实验的工具、服务和库保留选项。你还需要估计这一阶段不同步骤的相关成本，并确保利益相关者对这些成本达成一致。
- en: With the data layer of the RAGOps stack, the design of the indexing pipeline
    is complete. You may also note that the indexing pipeline also interacts with
    the model layer where embeddings models and LLMs along with other task specific
    algorithms sit.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在 RAGOps 栈的数据层中，索引管道的设计已经完成。你也许还会注意到索引管道也与模型层交互，其中包含嵌入模型和 LLM 以及其他特定任务的算法。
- en: 9.2.2 Generation pipeline design
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.2 生成管道设计
- en: 'We have discussed that the real-time interaction of the user with the knowledge
    base is facilitated by the generation pipeline. In chapter 4, we developed the
    three main components of the generation pipeline—the retrievers, augmentation
    via prompts, and generation using LLMs. Apart from these three components, query
    optimization in the pre-retrieval stage and context optimization in the post-retrieval
    stage are advanced components of the generation pipeline. Sometimes, even post-generation,
    response optimization is conducted to better align the responses. The generation
    pipeline is powered by the model layer of the RAGOps stage, which has the LLMs,
    the retrievers, embeddings models, and other task-specific models. The generation
    pipeline is brought alive by the app orchestration layer of the RAGOps stack.
    Let’s discuss the design of the generation pipeline in the following six steps:
    query optimization (pre-retrieval), retrieval, context optimization (post-retrieval),
    augmentation, generation, and response optimization (post-generation).'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论过，用户与知识库的实时交互是通过生成管道来实现的。在第4章中，我们开发了生成管道的三个主要组件——检索器、通过提示进行增强以及使用LLMs进行生成。除了这三个组件之外，检索前阶段的查询优化和检索后阶段的内容优化是生成管道的高级组件。有时，甚至在生成后，还会进行响应优化以更好地对齐响应。生成管道由RAGOps阶段的模型层提供动力，该层包含LLMs、检索器、嵌入模型以及其他特定任务的模型。生成管道通过RAGOps堆栈的应用编排层变得生动起来。接下来，我们将分以下六个步骤讨论生成管道的设计：查询优化（检索前）、检索、内容优化（检索后）、增强、生成和响应优化（生成后）。
- en: Query optimization
  id: totrans-123
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 查询优化
- en: Query optimization techniques are employed to help retrieval better align with
    the query. Several techniques are employed for transforming and rewriting queries.
    For agentic RAG, query routing is an important aspect of this step. Some of the
    questions to help finalize the nature of query optimization are
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 查询优化技术被采用以帮助检索更好地与查询对齐。采用了几种技术来转换和重写查询。对于代理RAG，查询路由是这一步骤的一个重要方面。以下是一些有助于确定查询优化性质的问题
- en: How many types of queries can the user ask? Do each of these query types require
    different downstream processes?
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户可以提出多少种类型的查询？每种查询类型是否需要不同的下游处理过程？
- en: Are there multiple collections in the knowledge base that need to be selected
    before the search?
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在搜索之前需要选择知识库中的多个集合吗？
- en: Are user queries expected to be short or generic?
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户查询预计会是简短的还是通用的？
- en: Are users looking for precise responses?
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户是否在寻找精确的响应？
- en: How much processing time can be afforded to query optimization?
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以承受多少查询优化的处理时间？
- en: Which models and techniques will be used for query optimization?
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将使用哪些模型和技术进行查询优化？
- en: Query optimization is optional but may be unavoidable when the data in the knowledge
    base is voluminous. It must also be noted that query optimization can add to the
    latency of the system.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 查询优化是可选的，但在知识库中的数据量很大时可能不可避免。还必须注意，查询优化可能会增加系统的延迟。
- en: Retrieval
  id: totrans-132
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 检索
- en: Retrieval is a pivotal component of RAG systems. There are many retrieval techniques
    and strategies discussed in this book. The quality of the RAG system hinges on
    the accuracy of the retrieval component. You may use a dense embeddings similarity
    match for simple RAG systems. In more complex systems, you will need to use hybrid,
    iterative, or adaptive retrieval strategies. The questions to ask at this stage
    are
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 检索是RAG系统的一个关键组件。本书中讨论了许多检索技术和策略。RAG系统的质量取决于检索组件的准确性。对于简单的RAG系统，您可以使用密集嵌入相似度匹配。在更复杂的系统中，您将需要使用混合、迭代或自适应检索策略。在这个阶段需要提出的问题是
- en: Does our retrieval component need high precision, high recall, or both?
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的检索组件需要高精度、高召回率，还是两者都需要？
- en: Can the queries be resolved with a simple similarity match?
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询可以通过简单的相似度匹配来解决吗？
- en: Do we need graph retrieval?
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要图检索吗？
- en: Will searching through the entire data be prohibitively long? Do we need filtering?
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 搜索整个数据集是否会过长？我们需要过滤吗？
- en: Will a single pass retrieve all necessary documents?
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单次遍历可以检索到所有必要的文档吗？
- en: Will the information from the retrieved documents lead to more questions?
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从检索到的文档中获取的信息会导致更多问题吗？
- en: Which models and techniques will we use for adaptive, recursive, or iterative
    retrieval?
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将使用哪些模型和技术进行自适应、递归或迭代检索？
- en: Which retrieval algorithms should we try?
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们应该尝试哪些检索算法？
- en: Are there any providers or libraries that we will leverage?
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将利用哪些提供者或库？
- en: How will we estimate the cost of retrieval?
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们将如何估计检索的成本？
- en: How many documents should be retrieved for acceptable levels of coverage?
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应该检索多少文档才能达到可接受的覆盖率水平？
- en: Does ranking in retrieved results matter?
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检索结果中的排名是否重要？
- en: Retrieval, especially in large knowledge bases, can lead to significant latency
    and should be optimized for speed and accuracy.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在大型知识库中，检索可能导致显著的延迟，应该针对速度和准确性进行优化。
- en: Context optimization
  id: totrans-147
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 上下文优化
- en: 'Once the results are retrieved from the knowledge base, they need to be sent
    to the LLM for generation along with the original user query. However, once the
    results are retrieved to sharpen the context, certain optimization techniques
    such as re-ranking and compression can be applied. These techniques filter, compress,
    and optimize the retrieved information to reduce noise and increase the precision
    of the context. To validate the need for context optimization, a few questions
    can be asked:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦从知识库检索到结果，它们需要与原始用户查询一起发送给LLM进行生成。然而，一旦检索到结果以锐化上下文，可以应用某些优化技术，如重新排名和压缩。这些技术过滤、压缩和优化检索到的信息，以减少噪声并提高上下文的精确度。为了验证上下文优化的必要性，可以提出以下问题：
- en: Will the amount of information retrieved overwhelm the LLM?
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检索到的信息量是否会压倒LLM？
- en: Will the retrieved information fit the context window of the LLM?
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检索到的信息是否适合LLM的上下文窗口？
- en: Is there a possibility of the retrieved information being noisy?
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检索到的信息可能存在噪声吗？
- en: Have a lot of documents been retrieved? Do we need to discard a few?
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否检索了大量文档？我们需要丢弃一些吗？
- en: Which techniques can be used to sharpen the retrieve context to the query?
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 哪些技术可以用来锐化检索上下文以匹配查询？
- en: Are there any services or libraries that we can use?
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有没有我们可以使用的服务或库？
- en: Can we afford the time taken for this optimization?
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们能否承担优化所需的时间？
- en: Optimizations like this are very helpful in making the context precise and improving
    the overall quality of the RAG system, but they do add to the processing time
    and cost.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的优化对于使上下文精确并提高RAG系统的整体质量非常有帮助，但它们确实会增加处理时间和成本。
- en: Augmentation
  id: totrans-157
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 增强层
- en: Augmentation is the process of adding the retrieved context to the original
    query in a prompt that can be sent to the LLM for generation. While it may seem
    a simple step, there can be many nuances to it. All the use case context along
    with the retrieved context also needs to be passed. Sometimes, you may need to
    pass examples of desired responses or the thought process. In cases where you
    need to use the LLMs internal parametric knowledge, this can also be specified
    in the prompt. Key questions to ask at this stage are
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 增强是将检索到的上下文添加到可以发送给LLM进行生成的提示中的过程。虽然这可能看起来是一个简单的步骤，但它可能有很多细微之处。所有用例上下文以及检索到的上下文也需要传递。有时，你可能需要传递期望的响应示例或思维过程。在需要使用LLM内部参数化知识的情况下，这也可以在提示中指定。在这个阶段需要询问的关键问题是
- en: What is the system prompt or the overall persona that we need the LLM to take?
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要LLM采取的系统提示或整体角色是什么？
- en: Does the response require nuanced analysis? Can that be passed as a chain of
    thought?
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 响应是否需要细微的分析？这能否作为一个思维链传递？
- en: Do we want to restrict the responses to the context only?
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否希望将响应限制在上下文中？
- en: What kind of examples should be given?
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应该给出什么样的示例？
- en: Will different query types need different prompting techniques?
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的查询类型是否需要不同的提示技术？
- en: Augmentation is done through prompts, and prompts can be managed by the prompt
    layer of the RAGOps stack. Prompting affects the cost and latency since the LLM-s
    processing depends on the number of tokens passed in the prompt.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 增强是通过提示完成的，提示可以通过RAGOps堆栈的提示层进行管理。提示会影响成本和延迟，因为LLM的处理取决于提示中传递的令牌数量。
- en: Generation
  id: totrans-165
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 生成
- en: 'Generation is a core component of all generative AI apps and contains an LLM
    that takes a prompt as input and generates a response. The nature of the LLM determines
    the efficacy and efficiency of the RAG system to a large extent. There are several
    choices that you will need to make:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 生成是所有生成式AI应用的核心组件，它包含一个LLM，该LLM以提示作为输入并生成响应。LLM的性质在很大程度上决定了RAG系统的有效性和效率。你需要做出几个选择：
- en: Should an open source model be used? Do we have the skills and resources to
    use them?
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应该使用开源模型吗？我们是否有使用它们的技能和资源？
- en: Should a proprietary managed LLM be used?
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否应该使用专有管理的LLM？
- en: Will we need to fine-tune an LLM for our use case?
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们是否需要针对我们的用例微调一个LLM？
- en: How large a model do we need? What capabilities do we need to address?
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要多大型的模型？我们需要哪些能力来应对？
- en: How can we estimate the cost of the generation component?
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们如何估算生成组件的成本？
- en: Are there any deployment constraints to be considered?
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要考虑任何部署限制吗？
- en: Will the models need optimization for deployment?
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型在部署前需要优化吗？
- en: Are there any security implications to be considered?
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要考虑任何安全影响吗？
- en: Are there any ethical or legal implications to be considered?
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要考虑任何伦理或法律上的影响吗？
- en: The selected LLMs will sit in the model library. All training fine-tuning activities
    and optimization are carried out in the model layer of the RAGOps stack. LLMs
    can be costly to train and use. Using the right LLM is key to the success of the
    RAG system.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 选定的LLM将位于模型库中。所有训练微调活动和优化都在RAGOps堆栈的模型层进行。LLM的训练和使用可能成本高昂。选择正确的LLM是RAG系统成功的关键。
- en: Response optimization
  id: totrans-177
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 响应优化
- en: Sometimes, the response from the generation component may be further processed
    before presenting the results to the user. This can range from evaluating the
    response for relevance to checking the format and appending the responses with
    the retrieved sources. Some questions that can help with the assessment at this
    stage are
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，生成组件的响应在向用户展示结果之前可能需要进一步处理。这可以从评估响应的相关性到检查格式，以及将检索到的来源附加到响应。在这一阶段可以帮助评估的一些问题是
- en: Does the response from the LLM be presented to the user as is?
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM的响应是否直接以原样呈现给用户？
- en: Is there any kind of verification that the responses need to go through?
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要对响应进行任何类型的验证吗？
- en: What is the impact of a sub-optimal result?
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不理想结果的影响是什么？
- en: Are there any workflows that need to be triggered based on the responses?
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否有基于响应需要触发的任何工作流程？
- en: Response optimizations are highly subjective and closely coupled to the use
    case, but it is a consideration that should not be overlooked.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 响应优化非常主观，并且与用例紧密相关，但这是一个不应被忽视的考虑因素。
- en: With these seven steps, the generation pipeline design is complete. The model
    library and the training/fine-tuning components of the RAGOps stack can be covered
    with the necessary tools, platforms, and algorithms. The orchestration of the
    generation pipeline can also be finalized depending on the choices made during
    this stage. The prompt layer can also be addressed after finalizing the augmentation
    techniques. Figure 9.7 shows the generation pipeline design with the overarching
    question of each step.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这七个步骤，生成管道设计完成。RAGOps堆栈的模型库和训练/微调组件可以用必要的工具、平台和算法进行覆盖。生成管道的编排也可以根据这一阶段的选择最终确定。在最终确定增强技术后，也可以解决提示层。图9.7显示了生成管道设计，其中每个步骤都有一个总体问题。
- en: '![A diagram of a system'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '![系统图'
- en: AI-generated content may be incorrect.](../Images/CH09_F07_Kimothi.png)
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的内容可能是错误的。](../Images/CH09_F07_Kimothi.png)
- en: Figure 9.7  Key questions need to be answered to make the choices for the generation
    pipeline.
  id: totrans-187
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.7  需要回答关键问题以对生成管道进行选择。
- en: This completes the design choices of the core RAG pipelines. The model, prompt,
    and the orchestration layers are largely complete by this stage. But there are
    more design considerations regarding security, guardrails, caching, and other
    use case requirements.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了核心RAG管道的设计选择。到这一阶段，模型、提示和编排层基本上已经完成。但还有更多关于安全、限制、缓存和其他用例要求的设计考虑。
- en: 9.2.3 Other design considerations
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.3 其他设计考虑
- en: 'While well-designed core RAG pipelines complete the critical layers of the
    RAG system, other system considerations and business requirements also need to
    be addressed:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然设计良好的核心RAG管道完成了RAG系统的关键层，但还需要解决其他系统考虑因素和业务需求：
- en: What kind of guardrails are required in the system? Should the user queries
    be restricted? Is there any kind of information that should not be output?
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统中需要哪些类型的限制？用户查询是否应该受到限制？是否有不应输出的信息？
- en: Is it possible and useful to cache certain kinds of responses?
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缓存某些类型的响应是否可能且有用？
- en: Do we need human supervision or action at any stage in the system?
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在系统的任何阶段是否需要人工监督或采取行动？
- en: How will the models be protected from adverse attacks?
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型将如何免受恶意攻击的保护？
- en: Is there any approval workflow required in the system?
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统中需要任何审批工作流程吗？
- en: Are users looking for explainability?
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户是否在寻找可解释性？
- en: These questions will help address the essential and enhancement layers of the
    RAGOps stack. You should be able to have a complete view of the necessary components,
    tools, platforms, and libraries for the development of the RAG system. The last
    choice to be made is on deployment options.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题将有助于解决 RAGOps 栈的基本和增强层。您应该能够全面了解开发 RAG 系统所需的必要组件、工具、平台和库。最后要作出的选择是部署选项。
- en: You can choose between a managed deployment on the cloud, a self-hosted deployment
    on a private cloud, a bare metal server, or local/edge machines. The choice will
    largely be driven by the business constraints but can have an effect on the design
    choices of the pipelines. Fully managed deployment favors managed services for
    storage and compute to reduce development complexity and ensure scalability, self-hosted
    solutions need a special focus on a design with modularity and optimization techniques
    to handle limited infrastructure, and in edge deployment, you should emphasize
    lightweight components and efficient retrieval strategies due to resource constraints.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以选择在云上托管部署、在私有云上自托管部署、裸金属服务器或本地/边缘机器。选择将主要受业务约束驱动，但可能会影响管道的设计选择。完全托管部署倾向于使用托管服务进行存储和计算以降低开发复杂性并确保可扩展性，自托管解决方案需要特别关注具有模块化和优化技术的设计以处理有限的基础设施，而在边缘部署中，由于资源限制，应强调轻量级组件和高效的检索策略。
- en: With all these design elements finalized, experimentation can begin for the
    development of the RAG system.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有这些设计元素确定之后，可以开始进行 RAG 系统的开发实验。
- en: '9.2.4 Development stage: Building modular RAG pipelines'
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.4 开发阶段：构建模块化 RAG 管道
- en: The development stage of the RAG development framework focuses on implementing
    the design choices into a functional RAG system. The ideal way would be to build
    the RAG pipelines in a modular fashion, which involves decomposing the system
    into distinct, interchangeable components, each responsible for a specific function.
    This approach enhances flexibility, scalability, and maintainability, allowing
    for tailored configurations to meet diverse application requirements. A few activities
    in the development stage involve training and fine-tuning models; creating APIs
    or microservices for different components; and creating an orchestration layer
    using different tools, services, and libraries.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 开发框架的开发阶段侧重于将设计选择实现为一个功能性的 RAG 系统。理想的方式是模块化地构建 RAG 管道，这涉及到将系统分解为不同的、可互换的组件，每个组件负责特定的功能。这种方法增强了灵活性、可扩展性和可维护性，允许根据不同的应用需求进行定制配置。开发阶段的一些活动包括训练和微调模型；为不同组件创建
    API 或微服务；以及使用不同的工具、服务和库创建编排层。
- en: Model training and fine-tuning LLMs
  id: totrans-202
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型训练和微调 LLM
- en: For most systems, a pre-trained foundation LLM and embeddings models will meet
    the requirement. There may be instances where you may need to fine-tune models
    for domain adaptation. In rare cases, you may choose to train language models
    from scratch. In such cases, the development of RAG systems may take a back seat,
    and training the models will be the core of the development effort. You can follow
    a progressive approach when deciding whether to fine-tune embeddings models and
    LLMs.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数系统，预训练的基础 LLM 和嵌入模型将满足需求。可能存在需要针对领域适应性微调模型的情况。在罕见的情况下，您可能选择从头开始训练语言模型。在这种情况下，RAG
    系统的开发可能会退居次要位置，而模型的训练将成为开发工作的核心。在决定是否微调嵌入模型和 LLM 时，您可以遵循渐进式方法。
- en: When creating embeddings using a pre-trained model, you will need to assess
    if a similarity search yields relevant results. To do this, you can also create
    ground truth data. The ground truth data can be a set of manually curated search
    queries and their matching documents. If the embeddings model can retrieve the
    documents accurately, you may use the pre-trained model. If not, you can either
    look for another embeddings model more suited for the use case domain or fine-tune
    the pre-trained embeddings model for the use case domain.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用预训练模型创建嵌入时，您需要评估相似性搜索是否产生相关结果。为此，您还可以创建真实数据。真实数据可以是一组手动整理的搜索查询及其匹配的文档。如果嵌入模型可以准确检索文档，则可以使用预训练模型。如果不可以，您可以寻找更适合用例领域域的另一个嵌入模型，或者针对用例领域微调预训练的嵌入模型。
- en: Similarly, if a pre-trained LLM generates desired results by prompting alone,
    you can use the model as is. In cases where you desire a specific style, vocabulary,
    or tonality, you can choose to fine-tune a model.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，如果预训练的LLM仅通过提示就能生成所需的结果，你可以直接使用该模型。在需要特定风格、词汇或语调的情况下，你可以选择微调模型。
- en: If the system warrants other models such as query classification, harmful content
    detection, usefulness, and similar, they will also need to be trained.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 如果系统需要其他模型，如查询分类、有害内容检测、有用性检测等，它们也需要进行训练。
- en: Module development
  id: totrans-207
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模块开发
- en: Different RAG pipeline components should be developed as independent modules
    in the form of packages, APIs, or other modular frameworks. Some of the modules
    can be
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 应将不同的RAG管道组件以独立模块的形式开发，形式为包、API或其他模块化框架。其中一些模块可以是
- en: '*Data loading and parsin**g*—Responsible for connecting to the source system
    and parsing file formations'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据加载和解析*—负责连接到源系统并解析文件格式'
- en: '*Metadata extractio**n*—Responsible for extracting and tagging metadata'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*元数据提取*—负责提取和标记元数据'
- en: '*Chunkin**g*—Responsible for creating chunks from documents'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*分块*—负责从文档中创建文档块'
- en: '*Embedding**s*—Responsible for converting chunks into vector embeddings'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*嵌入*—负责将文档块转换为向量嵌入'
- en: '*Storag**e*—Responsible for storing embeddings into vector databases'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*存储*—负责将嵌入存储到向量数据库中'
- en: '*Query optimizatio**n*—Responsible for aligning user query with retrievers'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*查询优化*—负责将用户查询与检索器对齐'
- en: '*Retrieva**l*—Responsible for efficient retrieval of documents'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*检索*—负责高效检索文档'
- en: '*Augmentatio**n*—Responsible for maintaining and invoking the prompt library'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*增强*—负责维护和调用提示库'
- en: '*Generatio**n*—Responsible for using the LLMs to generate responses'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*生成*—负责使用LLM生成响应'
- en: '*Memor**y*—Responsible for storing conversations, user preferences, and similar'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*记忆*—负责存储对话、用户偏好等'
- en: These are only a few examples. Modularity will be dependent on the complexity
    of the components. For example, if you are convinced that fixed-size chunking
    is sufficient for your use case, you may not develop an independent chunking module.
    Conversely, if you assume that LLMs may need to be changed as the system evolves
    with the technology, you can create the generation module that allows for quick
    and easy replacement of models. Figure 9.8 recalls the modular RAG design discussed
    in chapter 6.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这些只是几个例子。模块化将取决于组件的复杂性。例如，如果你确信固定大小的分块对你用例足够，你可能不需要开发独立的分块模块。相反，如果你假设随着技术的进步，系统可能需要更改LLM，你可以创建允许快速轻松替换模型的生成模块。图9.8回顾了第6章中讨论的模块化RAG设计。
- en: Orchestration
  id: totrans-220
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**编排**'
- en: Finally, you will develop the orchestration layer that will manage the interaction
    among the different modules that you have developed. This enables the workflow
    of your RAGsystem. This workflow should be flexible enough to adapt with feedback
    for different query types.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你将开发编排层，该层将管理你开发的各个模块之间的交互。这使你的RAG系统的工作流程得以实现。这个工作流程应该足够灵活，能够适应不同查询类型的反馈。
- en: '![A diagram of a computer'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '![计算机的图示'
- en: AI-generated content may be incorrect.](../Images/CH09_F08_Kimothi.png)
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的内容可能是不正确的。](../Images/CH09_F08_Kimothi.png)
- en: Figure 9.8  Modular structure allows for flexibility and scalability of individual
    components.
  id: totrans-224
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.8 模块化结构允许单个组件的灵活性和可扩展性。
- en: You will also have access to various managed services, frameworks, libraries,
    and tools that you can integrate with any of the modules. For example, LangChain
    is a framework that provides libraries for most components of a RAG framework.
    You can use these libraries for quick and easy development. However, for components
    that you desire more control over, you may need to build the functionality from
    scratch.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 你还将能够访问各种托管服务、框架、库和工具，你可以将它们与任何模块集成。例如，LangChain是一个提供RAG框架大多数组件库的框架。你可以使用这些库进行快速轻松的开发。然而，对于你希望有更多控制的组件，你可能需要从头开始构建功能。
- en: Development is an experimentation-driven iterative process. To finalize the
    different components of the RAG system, you will need to evaluate them and benchmark
    them against the goals you had set in the initiation stage.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 开发是一个以实验驱动的迭代过程。为了最终确定RAG系统的不同组件，你需要评估它们，并将它们与你在启动阶段设定的目标进行基准测试。
- en: '9.2.5 Evaluation stage: Validating and optimizing the RAG system'
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.5 评估阶段：验证和优化RAG系统
- en: Evaluation of the RAG system is a key component of its development process.
    All the different strategies, tools, and frameworks must be evaluated against
    some set of benchmarks. The actual business effect can only be measured post-deployment,
    but some metrics can be evaluated at the development stage. We can look at these
    metrics in two broad categories.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: RAG系统的评估是其开发过程中的关键组成部分。所有不同的策略、工具和框架都必须与一些基准进行比较。实际的业务效果只能在部署后衡量，但在开发阶段可以评估一些指标。我们可以从两个广泛的类别来查看这些指标。
- en: RAG components
  id: totrans-229
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: RAG组件
- en: 'The purpose of evaluating the RAG system is to assess the performance of different
    RAG components. To this end, there can be retriever-specific, generation-specific,
    and overall RAG evaluation metrics. Here is a summary of these metrics discussed
    in chapter 5\. We begin with retriever-specific metrics:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 评估RAG系统的目的是评估不同RAG组件的性能。为此，可以有针对检索器的特定指标、针对生成器的特定指标和整体RAG评估指标。以下是第5章中讨论的这些指标的总结。我们首先从检索器特定指标开始：
- en: '*Accuracy* is typically defined as the proportion of correct predictions (both
    true positives and true negatives) among the total number of cases examined.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*准确率*通常定义为在检查的总案例中正确预测的比例（包括真阳性和真阴性）。'
- en: '*Precision* focuses on the quality of the retrieved results. It measures the
    proportion of retrieved documents relevant to the user query. It answers the question,
    “Of all the documents that were retrieved, how many were relevant?”'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*精度*关注检索结果的品质。它衡量检索到的文档中有多少与用户查询相关。它回答了这样的问题：“在所有检索到的文档中，有多少是相关的？”'
- en: '*Precision@k* is a variation of precision that measures the proportion of relevant
    documents among the top ‘k’ retrieved results. It is particularly important because
    it focuses on the top results rather than all the retrieved documents. For RAG,
    it is important because only the top results are most likely to be used for augmentation.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Precision@k*是精度的一种变体，它衡量在顶部“k”个检索结果中相关文档的比例。它特别重要，因为它关注的是顶部结果，而不是所有检索到的文档。对于RAG来说，它很重要，因为只有顶部结果最有可能被用于增强。'
- en: '*Recall* focuses on the coverage that the retriever provides. It measures the
    proportion of the relevant documents retrieved from all the relevant documents
    in the corpus. It answers the question, “Of all the relevant documents, how many
    were retrieved?”'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*召回率*关注检索器提供的覆盖范围。它衡量从语料库中检索到的相关文档占所有相关文档的比例。它回答了这样的问题：“在所有相关文档中，有多少被检索到了？”'
- en: '*F1-score* is the harmonic mean of precision and recall. It provides a single
    metric that balances both the quality and coverage of the retriever.'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*F1分数*是精度和召回率的调和平均值。它提供了一个平衡了检索器质量和覆盖范围的单一指标。'
- en: '*Mean reciprocal rank, or MRR*, is particularly useful in evaluating the rank
    of the relevant document. It measures the reciprocal of the ranks of the first
    relevant document in the list of results. MRR is calculated over a set of queries.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*平均倒数排名，或MRR*，在评估相关文档的排名方面特别有用。它衡量列表中第一个相关文档的排名的倒数。MRR是在一组查询上计算的。'
- en: '*Mean average precision, or MAP,* is a metric that combines precision and recall
    at different cut-off levels of ‘k’ (i.e. the cut-off number for the top results).
    It calculates a measure called average precision and then averages it across all
    queries.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*平均平均精度，或MAP*，是一个结合了不同“k”（即顶部结果的截止数）截止水平的精度和召回率的指标。它首先计算平均精度，然后对所有查询进行平均。'
- en: '*nDCG* evaluates the ranking quality by considering the position of relevant
    documents in the result list and assigning higher scores to relevant documents
    appearing earlier.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*nDCG*通过考虑相关文档在结果列表中的位置并给较早出现的相关文档分配更高的分数来评估排名质量。'
- en: 'Here is the summary of generation specific metrics:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是生成器特定指标的总结：
- en: '*Coherence* assesses the logical flow and clarity of the response, ensuring
    that the information is presented in an understandable and organized manner.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*连贯性*评估响应的逻辑流程和清晰度，确保信息以可理解和组织的方式呈现。'
- en: '*Conciseness* evaluates whether the response is succinct and to the point,
    avoiding unnecessary verbosity, while still conveying complete information.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*简洁性*评估响应是否简洁明了，避免不必要的冗长，同时仍然传达完整的信息。'
- en: 'We conclude with a summary of overall RAG metrics:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以对整体RAG指标的总结来结束：
- en: '*Context relevance* assesses the proportion of retrieved information relevant
    to the user query.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*上下文相关性*评估检索到的信息中有多少与用户查询相关。'
- en: '*Faithfulness* or *groundedness* assesses the proportion of the claims in the
    response that are backed by the retrieved context.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*忠实度*或*扎根性*评估响应中声明的比例，这些声明得到了检索到的上下文的支持。'
- en: '*Hallucination rate*calculates the proportion of generated claims in the response
    that are not present in the retrieved context.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*幻觉率*计算响应中生成的声明比例，这些声明在检索到的上下文中不存在。'
- en: '*Coverage* measures the number of relevant claims in the context and calculates
    the proportion of relevant claims present in the generated response.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*覆盖率*衡量上下文中相关声明的数量，并计算生成响应中存在的相关声明的比例。'
- en: '*Answer relevance* assesses the overall effectiveness of the system by calculating
    the relevance of the final response to the original question.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*答案相关性* 通过计算最终响应与原始问题的相关性来评估系统的整体有效性。'
- en: Recall the triad of RAG evaluation from chapter 5\. Figure 9.9 shows the pairwise
    interaction between the user query, retrieved context, and the generated response,
    which calculates the RAG specific metrics.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 回想第5章中RAG评估的三要素。图9.9展示了用户查询、检索到的上下文和生成的响应之间的相互作用，这些相互作用计算了RAG特定的指标。
- en: '![A diagram of a customer relationship management'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '![客户关系管理图](../Images/CH09_F09_Kimothi.png)'
- en: AI-generated content may be incorrect.](../Images/CH09_F09_Kimothi.png)
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的内容可能是不正确的。](../Images/CH09_F09_Kimothi.png)
- en: Figure 9.9  The triad of RAG evaluation proposed by TruEra
  id: totrans-251
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.9  TruEra提出的RAG评估三要素
- en: To calculate some of these metrics, a ground truth dataset is required. Ground
    truth is information known to be real or true. In RAG, and the generative AI domain
    in general, ground truth is a prepared set of prompt–context–response or question–context–response
    examples, akin to labeled data in supervised machine learning parlance. Ground
    truth data created for your knowledge base can be used for the evaluation of your
    RAG system.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 要计算这些指标中的一些，需要一个真实数据集。真实数据是已知为真实或正确的信息。在RAG和生成式AI领域，真实数据是一组准备好的提示-上下文-响应或问题-上下文-响应示例，类似于监督机器学习中的标记数据。为您的知识库创建的真实数据可用于评估您的RAG系统。
- en: You can measure these metrics for different components. For example, you can
    check if context relevance increases by replacing a hybrid retrieval strategy
    with an adaptive one. You can also check the effectiveness of query and context
    optimization. You can also compare two service providers for a particular component.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以测量这些指标的不同组件。例如，您可以通过用自适应检索策略替换混合检索策略来检查上下文相关性是否增加。您还可以检查查询和上下文优化的有效性。您还可以比较特定组件的两个服务提供商。
- en: System performance
  id: totrans-254
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 系统性能
- en: System performance metrics relate to the non-functional requirements of the
    system, which affect the usability of the system more than the accuracy of the
    system. Some of these metrics are
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 系统性能指标与系统的非功能性需求相关，这些需求比系统的准确性更多地影响系统的可用性。其中一些指标包括
- en: '*Latenc**y*—Measures the time taken from receiving a query to delivering a
    response. Low latency is crucial for user satisfaction, especially in real-time
    applications.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*延迟*——衡量从接收查询到提供响应所需的时间。低延迟对于用户满意度至关重要，尤其是在实时应用中。'
- en: '*Throughpu**t*—Indicates the number of queries the system can handle within
    a specific time frame. Higher throughput reflects the system’s ability to manage
    large volumes of requests efficiently.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*吞吐量*——表示系统在特定时间框架内可以处理的查询数量。更高的吞吐量反映了系统高效管理大量请求的能力。'
- en: '*Resource utilizatio**n*—Assesses the efficiency of CPU and GPU usage during
    operations. Optimal utilization ensures cost-effectiveness and prevents resource
    bottlenecks.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*资源利用率*——评估操作期间CPU和GPU使用的效率。最优利用确保成本效益并防止资源瓶颈。'
- en: '*Cost per query* calculates the average expense incurred for processing each
    query, encompassing infrastructure, energy, and maintenance costs.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*每查询成本*计算处理每个查询的平均费用，包括基础设施、能源和维护成本。'
- en: Latency and cost get special attention in LLM-based systems. This is because
    of the inherent nature of the LLM architecture. RAG adds to both latency and cost.
    Therefore, the impact of additional components like filtering during retrieval,
    optimizations, and retrieval strategies should be evaluated from this lens. Sometimes
    the stakeholders may also ask you to evaluate some use case-specific metrics,
    and that should also be a part of this evaluation stage.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于LLM的系统中对延迟和成本给予了特别关注。这是因为LLM架构的固有性质。RAG增加了延迟和成本。因此，应该从这个角度评估检索过程中的过滤、优化和检索策略等附加组件的影响。有时利益相关者也可能要求你评估一些特定用例的指标，这也应该是评估阶段的一部分。
- en: When your system is thoroughly evaluated and improved to meet all the benchmarks,
    it is ready to go. You can now deploy it to make it available to the intended
    users.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的系统经过彻底评估和改进，以满足所有基准时，它就准备就绪了。你现在可以部署它，使其可供目标用户使用。
- en: '9.2.6 Deployment stage: Launching and scaling the RAG system'
  id: totrans-262
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.6 部署阶段：启动和扩展RAG系统
- en: Once the system is ready to ship, it needs to be deployed into a production
    server accessible by the intended users. There are a few deployment techniques
    that are popular for software systems, which can also be used for RAG systems.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦系统准备就绪，就需要将其部署到可由目标用户访问的生产服务器上。对于软件系统，有一些流行的部署技术，这些技术也可以用于RAG系统。
- en: Blue–green deployment
  id: totrans-264
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 蓝绿部署
- en: Blue–green deployment maintains two separate environments named blue and green.
    The existing system is in the blue environment, and the new RAG system is put
    in the green. Once the green environment is tested and verified, all traffic is
    directed to the green environment, and the blue environment is deactivated. The
    advantage of this blue–green deployment is that it is possible to test the production
    environment without affecting the live traffic. Consequently, there is zero downtime
    and an easy option for a rollback if any problem is encountered. However, it is
    a costly option since the entire production environment is duplicated. Indexing
    pipelines can be updated in the green environment without affecting the live system.
    Changes to retrieval strategies or embeddings models can be safely validated before
    production use.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 蓝绿部署维护两个独立的 环境，分别命名为蓝色和绿色。现有系统位于蓝色环境，而新的RAG系统置于绿色环境。一旦绿色环境经过测试和验证，所有流量就会导向绿色环境，蓝色环境被停用。这种蓝绿部署的优势在于可以在不影响实时流量的情况下测试生产环境。因此，几乎没有停机时间，并且在遇到任何问题时，可以轻松回滚。然而，这是一个成本较高的选项，因为整个生产环境都被复制了。可以在绿色环境中更新索引管道，而不会影响实时系统。检索策略或嵌入模型的更改可以在生产使用之前安全地验证。
- en: Canary deployment
  id: totrans-266
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 金丝雀部署
- en: Canary deployment gradually releases the new RAG system to a small number of
    users. If it performs well with these users, it is expanded to all users. Canary
    deployment allows for real-time user feedback that enables early detection of
    problems. However, it adds feedback and monitoring complexity and multiple versions
    to manage. It can test changes in retrieval algorithms, embeddings, or generation
    models on limited queries or specific regions.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 金丝雀部署逐渐将新的RAG系统发布给一小部分用户。如果它与这些用户的表现良好，就会扩展到所有用户。金丝雀部署允许实时用户反馈，从而能够早期发现问题。然而，它增加了反馈和监控的复杂性，以及需要管理的多个版本。它可以在有限的查询或特定区域上测试检索算法、嵌入或生成模型的变化。
- en: Rolling deployment
  id: totrans-268
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 滚动部署
- en: Rolling deployment is used when there are multiple production servers. The new
    RAG system is deployed to one server incrementally at a time before moving to
    the next. So, there is no complete downtime and only a part of the system is offline
    at one time. It may become complex if problems arise mid-deployment. The rollback
    can become tedious when some servers are updated, while others are not.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 滚动部署用于存在多个生产服务器的情况。在移动到下一个服务器之前，新的RAG系统会逐个部署到一台服务器上。因此，没有完全的停机时间，一次只有系统的一部分离线。如果在部署过程中出现问题，可能会变得复杂。当一些服务器更新时，而其他服务器没有更新，回滚可能会变得繁琐。
- en: Shadow deployment
  id: totrans-270
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 影子部署
- en: Shadow deployment mirrors live traffic to a new version of the system running
    alongside the old one, without exposing the new RAG system’s responses to users.
    By doing this, the system can be tested without affecting the users. However,
    it requires duplication of the infrastructure much like the blue–green deployment.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 影子部署将实时流量镜像到与旧版本系统并行运行的新版本系统，而不将新RAG系统的响应暴露给用户。通过这样做，可以在不影响用户的情况下测试系统。然而，它需要像蓝绿部署一样复制基础设施。
- en: A/B testing
  id: totrans-272
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: A/B测试
- en: A/B testing involves deploying two versions of the RAG system (A and B) to separate
    subsets of users and comparing their performance to determine the better option.
    This can also be done for new systems. It enables direct comparison and provides
    clear insights into performance. However, it requires robust mechanisms to split
    traffic and collect performance metrics. It allows for experimenting with different
    LLMs or retrieval strategies and variations in prompting and augmentation techniques.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: A/B测试涉及将RAG系统的两个版本（A和B）部署到不同的用户子集，并比较它们的性能以确定更好的选项。这也可以用于新系统。它允许直接比较，并为性能提供清晰的见解。然而，它需要强大的机制来分割流量并收集性能指标。它允许尝试不同的LLM或检索策略，以及提示和增强技术的变化。
- en: Interleaving experiments
  id: totrans-274
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 交错实验
- en: '*Interleaving experiments* compare two RAG systems by blending their outputs
    into a single result set shown to users. Results from both systems are interleaved,
    and user interactions are attributed to the originating system to determine which
    performs better. This approach provides fast feedback and reduces bias by comparing
    systems under identical conditions. However, the attribution of user engagement
    to the correct system can be complex.'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '*交错实验*通过将两个RAG系统的输出混合成单个结果集展示给用户来比较两个RAG系统。两个系统的结果交错，用户交互归因于原始系统以确定哪个表现更好。这种方法提供了快速的反馈，并通过在相同条件下比较系统来减少偏差。然而，将用户参与度归因于正确的系统可能很复杂。'
- en: The choices for the deployment strategy can depend on factors like such as tolerance,
    and using strategies such as shadow, canary, and blue–green can mitigate risks
    in mission-critical systems. It also depends on the scale, and rolling deployments
    make sense for large-scale systems. Small new RAG systems can be also deployed
    all at once.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 部署策略的选择可能取决于诸如容错性等因素，并且使用如影子、金丝雀和蓝绿等策略可以减轻关键任务系统中的风险。这还取决于规模，对于大规模系统，滚动部署是有意义的。小型新的RAG系统也可以一次性部署。
- en: Now that the system is available to the users, you will start getting real-time
    feedback, and the success and failure of the system will also depend on how you
    react to the feedback. To measure and improve the system, continuous monitoring
    is required.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 现在系统对用户可用后，你将开始获得实时反馈，系统的成功与失败也将取决于你对反馈的反应。为了衡量和改进系统，需要持续监控。
- en: '9.2.7 Maintenance stage: Ensuring reliability and adaptability'
  id: totrans-278
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2.7 维护阶段：确保可靠性和适应性
- en: 'Deploying a RAG system into production is only the first milestone in the journey
    toward an evolved contextual AI system. Explicit user feedback, evolving technology,
    and changing user behavior present previously unexplored challenges that the system
    may encounter. It is therefore essential to be continually vigilant and monitor
    the system performance. There are several reasons why a RAG system may fail in
    production. There are operational reasons such as compute resource constraints,
    sudden spikes in load, and malicious attacks. The reason can also be a shift in
    the type of data in the knowledge base or a change in user queries. It is therefore
    essential to measure a few metrics:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 将RAG系统部署到生产中只是向进化语境AI系统迈进的第一里程碑。显式的用户反馈、技术演变和用户行为的变化带来了系统可能遇到的前所未有的挑战。因此，持续保持警惕并监控系统性能至关重要。RAG系统在生产中可能失败的原因有几个。有操作性的原因，如计算资源限制、负载的突然激增和恶意攻击。原因也可能是知识库中数据类型的转变或用户查询的变化。因此，测量一些指标是至关重要的：
- en: RAG component metrics that were evaluated before deployment need to be continuously
    monitored for degradation.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在部署前评估的RAG组件指标需要持续监控以检测退化。
- en: Changes in user behavior can be tracked by analyzing the nature of user queries.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过分析用户查询的性质可以跟踪用户行为的变化。
- en: System performance metrics such as latency, throughput, and similar should also
    be continuously monitored.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统性能指标，如延迟、吞吐量和类似指标也应持续监控。
- en: Additional metrics such as error rates, system downtime, malicious attacks,
    and similar should also be tracked.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应跟踪的附加指标还包括错误率、系统停机时间、恶意攻击等。
- en: User engagement metrics such as customer satisfaction scores or repeat engagement
    can indicate the usability of the system.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户参与度指标，如客户满意度评分或重复参与度可以表明系统的可用性。
- en: Business metrics such as revenue effects and cost savings should also be tracked.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应跟踪如收入影响和成本节省等业务指标。
- en: This development framework completed its cycle with maintenance. However, it
    is not a linear process. New requirements and business objectives will emerge.
    This will re-initiate the development cycle for an improved RAG system. This development
    framework will prove to be a good reference resource while building RAG systems.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 此开发框架通过维护完成了其周期。然而，它不是一个线性过程。新的需求和业务目标将出现。这将重新启动改进RAG系统的开发周期。在构建RAG系统时，此开发框架将证明是一个良好的参考资源。
- en: We conclude this book and end the discussion on RAG in the next section with
    some additional considerations to keep in mind as the generative AI domain evolves.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本节结束本书的讨论，并在下一节中讨论RAG时，提出一些额外的考虑事项，以保持对生成AI领域演变的关注。
- en: 9.3 Ideas for further exploration
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9.3 进一步探索的想法
- en: Like any technology, even with RAG, there are some complementary and some competing
    ideas that coexist. You may hear about these techniques and sometimes be challenged
    to defend the use of RAG. There are also common points of failure for RAG systems
    that need attention.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 就像任何技术一样，即使是RAG，也有一些互补和竞争的想法共存。您可能会听到这些技术，有时会面临挑战，需要捍卫RAG的使用。RAG系统也有常见的故障点需要关注。
- en: 9.3.1 Fine-tuning within RAG
  id: totrans-290
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.1 RAG中的微调
- en: 'Supervised fine-tuning (SFT) of LLMs has become a popular method to customize
    and adapt foundation models for specific objectives. There has been a growing
    debate in the applied AI community around the application of fine-tuning or RAG
    to accomplish tasks. While RAG enhances the non-parametric memory of a foundation
    model without changing the parameters, SFT changes the parameters of a foundation
    model and therefore influences the parametric memory. RAG and SFT should be considered
    as complementary, rather than competing, techniques because both address different
    parts of a generative AI system. You may prefer fine-tuning over RAG if there
    is a change required in the writing style, tonality, and vocabulary of the LLM
    responses. In their paper “Retrieval-Augmented Generation for Large Language Models:
    A Survey” ([https://arxiv.org/abs/2312.10997](https://arxiv.org/abs/2312.10997)),
    Gao and colleagues plot the evolution of prompt engineering to RAG and fine-tuning.
    This is illustrated in figure 9.10, demonstrating the need for fine-tuning with
    the increase in the need for model adaptation.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 监督微调（SFT）LLM已成为定制和适应基础模型以实现特定目标的流行方法。在应用AI社区中，关于微调或RAG的应用以完成任务的讨论日益增多。虽然RAG在不改变参数的情况下增强了基础模型的无参数记忆，但SFT改变了基础模型的参数，因此影响了参数化记忆。RAG和SFT应被视为互补技术，而不是竞争技术，因为它们都针对生成AI系统的不同部分。如果您需要改变LLM响应的写作风格、语气和词汇，您可能会更喜欢微调而不是RAG。在他们的论文“大型语言模型的检索增强生成：综述”([https://arxiv.org/abs/2312.10997](https://arxiv.org/abs/2312.10997))中，高及其同事绘制了提示工程到RAG和微调的演变图。这如图9.10所示，展示了随着模型适应需求增加，微调的必要性。
- en: '![A diagram of a diagram'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '![一个图表的图表'
- en: AI-generated content may be incorrect.](../Images/CH09_F10_Kimothi.png)
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的内容可能是不正确的。](../Images/CH09_F10_Kimothi.png)
- en: 'Figure 9.10  Prompt engineering requires low modifications to the model and
    external knowledge, focusing on harnessing the capabilities of LLMs themselves.
    Fine-tuning, however, involves further training the model. Source: [https://arxiv.org/abs/2312.10997](https://arxiv.org/abs/2312.10997).'
  id: totrans-294
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.10  提示工程需要对模型和外部知识进行低修改，专注于利用LLM自身的功能。然而，微调却涉及进一步训练模型。来源：[https://arxiv.org/abs/2312.10997](https://arxiv.org/abs/2312.10997)。
- en: Fine-tuning methods for both retrievers and generators hold immense potential
    for significantly improving RAG performance. Retriever fine-tuning enhances the
    ability of retrieval models to accurately capture semantic nuances relevant to
    specific domains, using methods such as contrastive learning, supervised embedding
    fine-tuning, LM-
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 对于检索器和生成器，微调方法具有显著提高RAG性能的巨大潜力。检索器微调通过使用对比学习、监督嵌入微调等方法，增强了检索模型准确捕捉特定领域相关语义细微差别的能力。
- en: supervised retrieval, or reward-based fine-tuning. Generator fine-tuning complements
    this by adapting language models through methods such as fusion-in-decoder (FiD),
    prompt tuning, latent fusion techniques, and parameter-efficient fine-tuning (PEFT).
    Combining these approaches within a hybrid fine-tuning framework can align the
    retrieval and generation components more effectively, leading to higher accuracy,
    reduced hallucinations, and improved adaptability to domain-specific tasks.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 监督检索或基于奖励的微调。生成器微调通过通过融合解码器（FiD）、提示调整、潜在融合技术以及参数高效微调（PEFT）等方法调整语言模型来补充这一点。将这些方法结合在一个混合微调框架中可以更有效地对齐检索和生成组件，从而提高准确性、减少幻觉并提高对特定领域任务的适应性。
- en: 9.3.2 Long-context windows in LLMs
  id: totrans-297
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.2 LLMs中的长上下文窗口
- en: Context windows in LLMs keep growing significantly with iteration. As of this
    writing, Claude 3.5 sonnet supports a window of up to 200,000 tokens, while GPT-4o,
    O1, and variants can process 128,000 tokens. Google Gemini 1.5 leads with a massive
    1-million-token context window. It is possible that when you read this book, there
    may be models with even longer context windows. So, in a lot of cases, we can
    just pass the entire context such as a long document to the model as part of the
    prompt. This would eliminate the need for chunking, indexing, and retrieval in
    cases where the knowledge base is not too large. In their paper, “Retrieval Augmented
    Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach” ([https://arxiv.org/abs/2407.16833](https://arxiv.org/abs/2407.16833)),
    Li and colleagues systematically compare RAG and LLMs with long-context windows.
    They demonstrate that long-context LLMs outperform RAG with a few exceptions.
    However, processing long contexts directly with LLMs can be computationally expensive.
    RAG is significantly more cost-efficient owing to processing shorter inputs. A
    hybrid approach such as SELF-ROUTE proposed in the same paper uses model self-reflection
    to decide whether a query can be answered with retrieved chunks or if it needs
    the full context. Figure 9.11 illustrates the SELF-ROUTE approach, in which the
    model receives the query with the retrieved chunks and determines whether the
    query can be answered based on this information. If yes, it generates the answer.
    If no, the full context is provided to the model, and the model generates the
    final answer.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLMs中，上下文窗口随着迭代显著增长。截至本文撰写时，Claude 3.5 sonnet支持高达200,000个token的窗口，而GPT-4o、O1及其变体可以处理128,000个token。Google
    Gemini 1.5以1百万token的上下文窗口领先。在你阅读这本书的时候，可能会有具有更长上下文窗口的模型。因此，在许多情况下，我们只需将整个上下文，例如长文档，作为提示的一部分传递给模型。这将消除在知识库不是特别大的情况下进行分块、索引和检索的需要。在他们的论文“检索增强生成或长上下文LLMs？全面研究和混合方法”([https://arxiv.org/abs/2407.16833](https://arxiv.org/abs/2407.16833))中，Li及其同事系统地比较了RAG和具有长上下文窗口的LLMs。他们证明，在少数例外的情况下，长上下文LLMs优于RAG。然而，直接使用LLMs处理长上下文可能会非常耗费计算资源。RAG由于处理较短的输入而显著更节省成本。同一篇论文中提出的混合方法SELF-ROUTE使用模型自我反思来决定一个查询是否可以用检索到的块来回答，或者是否需要完整的上下文。图9.11说明了SELF-ROUTE方法，其中模型接收带有检索块的查询，并基于此信息确定是否可以回答查询。如果可以，它生成答案。如果不可以，则向模型提供完整上下文，模型生成最终答案。
- en: '![A diagram of a diagram'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '![一个图表的图表'
- en: AI-generated content may be incorrect.](../Images/CH09_F11_Kimothi.png)
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的内容可能是不正确的。](../Images/CH09_F11_Kimothi.png)
- en: Figure 9.11  A hybrid approach utilizing RAG and long context in LLMs can lead
    to better performance without adversely increasing the costs.
  id: totrans-301
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图9.11  利用RAG和LLMs中的长上下文的混合方法可以在不增加成本的情况下提高性能。
- en: 9.3.3 Managed solutions
  id: totrans-302
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.3 管理解决方案
- en: With the growing popularity of RAG and its significance in generative AI applications,
    many service providers offer managed RAG pipelines in which several RAG components
    can be configured without the need for custom development. For example, knowledge
    bases are an Amazon Bedrock capability that facilitates implementation of the
    entire RAG workflow. Azure AI Search provides indexing and query capabilities,
    with the infrastructure of the Azure cloud, and Vertex AI RAG Engine is a component
    of Google’s Vertex AI platform that facilitates RAG. There are also independent
    service providers such as CustomGPT, Needle AI, Ragie, and so forth that provide
    managed RAG pipelines. As with managed solutions across technologies, the factors
    to consider are cost, applicability to the use case, flexibility, and control
    over components.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 随着RAG的日益流行及其在生成AI应用中的重要性，许多服务提供商提供托管RAG管道，其中可以配置多个RAG组件，而无需定制开发。例如，知识库是Amazon
    Bedrock的一项功能，有助于实现整个RAG工作流程。Azure AI Search提供索引和查询功能，基于Azure云的基础设施，而Vertex AI
    RAG Engine是Google Vertex AI平台的一个组件，有助于RAG。还有像CustomGPT、Needle AI、Ragie等独立服务提供商，提供托管RAG管道。与跨技术托管解决方案一样，需要考虑的因素包括成本、适用性、灵活性和对组件的控制。
- en: 9.3.4 Difficult queries
  id: totrans-304
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3.4 难以处理的查询
- en: Some key reasons for failures in RAG systems are related to the types of queries.
    As RAG developers, it is important to keep focusing on these query types so that
    the technique can be improved. Some of these are
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: RAG系统中失败的一些关键原因与查询类型有关。作为RAG开发者，持续关注这些查询类型对于改进技术至关重要。其中一些包括
- en: '*Multi-step reasonin**g*—RAG struggles with queries needing multi-hop retrieval
    (e.g., “What nationality is the performer of song XXX?”).'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*多步推理*——RAG在需要多跳检索的查询上遇到困难（例如，“XXX歌手的国籍是什么？”）。'
- en: '*General querie**s*—Vague or broad questions are hard to retrieve relevant
    chunks for (e.g., “What does the group think about XXX?”)'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*通用查询*——模糊或宽泛的问题难以检索相关片段（例如，“这个团体对XXX的看法是什么？”）'
- en: '*Complex or long querie**s*—Complex queries challenge the retriever’s understanding.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*复杂或长查询*——复杂查询挑战检索器的理解。'
- en: '*Implicit querie**s*—Questions requiring comprehensive context understanding
    can’t be addressed by RAG alone.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*隐含查询*——需要全面上下文理解的查询不能仅由RAG解决。'
- en: 'We have come a long way in our discussion on RAG. This chapter provided an
    exhaustive summary of the contents of this book, from the benefit of RAG to the
    best practices in building RAG systems. At the risk of repetition, RAG is an important
    and evolving technique in the field of generative AI. I hope you had a good time
    reading this book. I’ll leave you with the following closing thoughts:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在RAG的讨论中已经走得很远了。本章全面总结了本书的内容，从RAG的好处到构建RAG系统的最佳实践。尽管有重复的风险，但RAG是生成AI领域的一个重要且不断发展的技术。希望您阅读这本书时有所收获。以下是我的一些结束语：
- en: Remember to remain familiar with the principles of contextual AI powered by
    RAG.
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记住要熟悉由RAG驱动的上下文AI的原则。
- en: Have faith in your ability to build complex RAG systems.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信任您构建复杂RAG系统的能力。
- en: Always bear in mind the development challenges and strategies to overcome them.
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 总是牢记开发挑战和克服它们的策略。
- en: Understand the ethical and legal concerns around generative AI.
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解围绕生成AI的伦理和法律问题。
- en: Be on top of the rapidly changing trends.
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保持对快速变化的趋势的关注。
- en: Summary
  id: totrans-316
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: RAG development framework
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: RAG开发框架
- en: The RAG development framework provides a structured approach to building, deploying,
    and maintaining retrieval-augmented generation systems.
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAG开发框架提供了一个构建、部署和维护检索增强生成系统的结构化方法。
- en: 'It addresses the complexity of RAG systems by incorporating six iterative and
    cyclic stages: initiation, design, development, evaluation, deployment, and maintenance.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过包含六个迭代和循环阶段：启动、设计、开发、评估、部署和维护，该框架解决了RAG系统的复杂性。
- en: The framework emphasizes both the technical and operational aspects of RAG system
    development.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该框架强调RAG系统开发的技术和操作方面。
- en: RAG development framework stages
  id: totrans-321
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: RAG开发框架阶段
- en: '**Initiation stage**'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**启动阶段**'
- en: Focuses on understanding the problem statement, aligning stakeholders, and gathering
    requirements.
  id: totrans-323
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 专注于理解问题陈述、协调利益相关者并收集需求。
- en: Emphasizes use case identification and assessing the need for RAG, using tools
    like use case evaluation cards.
  id: totrans-324
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强调使用用例识别和评估RAG需求，使用如用例评估卡片等工具。
- en: Involves requirements gathering across business, functional, and non-functional
    needs.
  id: totrans-325
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 涉及业务、功能和非功能性需求的需求收集。
- en: Concludes with drafting a high-level architecture diagram for alignment and
    strategic decision-making.
  id: totrans-326
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以绘制高级架构图来结束，以进行对齐和战略决策。
- en: '**Design stage**'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设计阶段**'
- en: Transforms high-level architecture into detailed pipeline designs for indexing
    and generation.
  id: totrans-328
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将高级架构转换为详细的管道设计，用于索引和生成。
- en: Incorporates choices around chunking, embeddings, and retrieval strategies.
  id: totrans-329
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包含关于分块、嵌入和检索策略的选择。
- en: Addresses additional considerations such as guardrails, caching, security, and
    deployment strategies.
  id: totrans-330
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决额外的考虑因素，如安全网、缓存、安全和部署策略。
- en: '**Development stage**'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开发阶段**'
- en: Implements modular RAG pipelines, enabling flexibility, scalability, and maintainability.
  id: totrans-332
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实施模块化RAG管道，实现灵活性、可扩展性和可维护性。
- en: Activities include training/fine-tuning models, creating independent modules
    (e.g., chunking, retrieval, generation), and building orchestration layers.
  id: totrans-333
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 活动包括训练/微调模型、创建独立模块（例如，分块、检索、生成）和构建编排层。
- en: '**Evaluation stage**'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**评估阶段**'
- en: Validates RAG system components and overall performance using metrics such as
    context relevance, faithfulness, precision, recall, latency, and cost per query.
  id: totrans-335
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用上下文相关性、忠实度、精确度、召回率、延迟和每查询成本等指标验证RAG系统组件和整体性能。
- en: Employs ground truth datasets for benchmarking and optimization.
  id: totrans-336
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用真实数据集进行基准测试和优化。
- en: '**Deployment stage**'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**部署阶段**'
- en: Includes deployment strategies like blue-green, canary, rolling, and A/B testing
    to ensure smooth transitions and minimal disruption.
  id: totrans-338
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 包括部署策略，如蓝绿部署、金丝雀部署、滚动部署和A/B测试，以确保平稳过渡和最小化干扰。
- en: Emphasizes real-time user feedback and system scalability.
  id: totrans-339
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强调实时用户反馈和系统可扩展性。
- en: '**Maintenance stage**'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**维护阶段**'
- en: Ensures system reliability through continuous monitoring of component metrics,
    user behavior, and performance metrics.
  id: totrans-341
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过持续监控组件指标、用户行为和性能指标来确保系统可靠性。
- en: Adapts to evolving use cases, technological advancements, and user feedback.
  id: totrans-342
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 适应不断发展的用例、技术进步和用户反馈。
- en: Best practices in RAG development
  id: totrans-343
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: RAG开发的最佳实践
- en: Modular design improves adaptability and ease of updates.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模块化设计提高了适应性和更新便利性。
- en: Ground truth datasets are essential for accurate evaluation and fine-tuning.
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 真实数据集对于准确评估和微调至关重要。
- en: Deployment strategies should align with system criticality, scale, and risk
    tolerance.
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署策略应与系统关键性、规模和风险承受能力相一致。
- en: Regularly monitor for changes in user behavior, data, and performance to maintain
    reliability.
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定期监控用户行为、数据和性能的变化，以保持可靠性。
- en: Ideas for further exploration
  id: totrans-348
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 进一步探索的想法
- en: '**RAG vs. fine-tuning**'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RAG与微调的比较**'
- en: RAG complements fine-tuning by enhancing non-parametric memory, while fine-tuning
    adapts parametric memory for style, tonality, and vocabulary.
  id: totrans-350
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAG通过增强非参数记忆来补充微调，而微调则适应参数记忆以调整风格、语气和词汇。
- en: Use cases may benefit from hybrid approaches, depending on specific needs.
  id: totrans-351
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据具体需求，用例可能从混合方法中受益。
- en: '**Long-context windows in LLMs**'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LLM中的长上下文窗口**'
- en: Advances in LLMs (e.g., 200k+ token contexts) can reduce reliance on chunking
    and retrieval for smaller knowledge bases.
  id: totrans-353
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs（例如，200k+令牌上下文）的进步可以减少对较小知识库的分块和检索的依赖。
- en: Hybrid models such as SELF-ROUTE combine RAG with long-context processing to
    optimize cost and accuracy.
  id: totrans-354
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混合模型，如SELF-ROUTE，将RAG与长上下文处理相结合，以优化成本和准确性。
- en: '**Managed solutions**'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管理解决方案**'
- en: Services such as Amazon Bedrock, Azure AI Search, and Google Vertex AI RAG Engine
    offer prebuilt RAG pipelines, simplifying deployment and reducing development
    effort.
  id: totrans-356
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如Amazon Bedrock、Azure AI Search和Google Vertex AI RAG Engine等服务提供预构建的RAG管道，简化部署并减少开发工作量。
- en: '**Handling difficult queries**'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**处理困难查询**'
- en: Multi-step reasoning, general queries, and implicit questions remain challenges
    for RAG systems.
  id: totrans-358
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多步骤推理、通用查询和隐含问题仍然是RAG系统的挑战。
