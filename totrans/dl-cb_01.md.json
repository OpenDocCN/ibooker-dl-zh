["```py\nLear. Attend the lords of France and Burgundy, Gloucester.\nGlou. I shall, my liege.\n```", "```py\nSELECT ?item ?itemLabel ?pic\nWHERE\n{\n\t?item wdt:P31 wd:Q146 .\n\tOPTIONAL {\n\t\t?item wdt:P18 ?pic\n\t}\n\tSERVICE wikibase:label {\n\t  bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\"\n\t}\n}\n```", "```py\nshakespeare = strip_headers(load_etext(100))\n```", "```py\nchar_cnn_model.fit(training_data, training_labels, epochs=20, batch_size=128)\n```", "```py\nchar_cnn_model.fit_generator(\n    data_generator(train_tweets, batch_size=BATCH_SIZE),\n    epochs=20\n)\n```", "```py\ndata_train, data_test, label_train, label_test = train_test_split(\n    data, labels, test_size=0.33, random_state=42)\n```", "```py\ndef train_or_test(gen, train=True):\n    for i, x in enumerate(gen):\n        if (i % 4 == 0) != train:\n            yield x\n```", "```py\nidx_to_token = list(set(tokens))\ntoken_to_idx = {token: idx for idx, token in enumerate(idx_to_token)}\none_hot = lambda token: [1 if i == token_to_idx[token] else 0\n                         for i in range(len(idx_to_token))]\nencoded = np.asarray([one_hot(token) for token in tokens])\n```", "```py\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    horizontal_flip=True)\n\nmodel.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n                    steps_per_epoch=len(x_train) / 32, epochs=epochs)\n```"]