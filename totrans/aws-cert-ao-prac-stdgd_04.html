<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 3. AI and Machine Learning"><div class="chapter" id="chapter_three_ai_and_machine_learning">
<h1><span class="label">Chapter 3. </span>AI and Machine Learning</h1>
<p>AI is not a new field; <a contenteditable="false" data-type="indexterm" data-primary="AI (artificial intelligence)" data-secondary="history of" id="id729"/><a contenteditable="false" data-type="indexterm" data-primary="McCulloch, Warren" id="id730"/><a contenteditable="false" data-type="indexterm" data-primary="Pitts, Walter" id="id731"/><a contenteditable="false" data-type="indexterm" data-primary="neural networks" data-secondary="researchers McCulloch and Pitts" id="id732"/>its origins date back decades. In the 1940s, researchers like Warren McCulloch and Walter Pitts developed foundational concepts for neural networks. <a contenteditable="false" data-type="indexterm" data-primary="Turing, Alan" id="id733"/><a contenteditable="false" data-type="indexterm" data-primary="“Computing Machinery and Intelligence” (Turing)" data-primary-sortas="Computing Machinery and Intelligence" id="id734"/><a contenteditable="false" data-type="indexterm" data-primary="Turing test" id="id735"/>This was followed by the pioneering work of mathematician Alan Turing, who in 1950 authored the paper “Computing Machinery and Intelligence.” In it, he introduced the Turing test, a method for evaluating a machine’s ability to exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human.</p>
<p>The term <em>artificial intelligence</em> was coined<a contenteditable="false" data-type="indexterm" data-primary="McCarthy, John" id="id736"/><a contenteditable="false" data-type="indexterm" data-primary="AI (artificial intelligence)" data-secondary="“artificial intelligence” coined" data-secondary-sortas="artificial intelligence" id="id737"/><a contenteditable="false" data-type="indexterm" data-primary="Minsky, Marvin" id="id738"/><a contenteditable="false" data-type="indexterm" data-primary="Shannon, Claude" id="id739"/> in 1956 by computer scientist John McCarthy for a conference at Dartmouth College. The event gathered luminaries such as Marvin Minsky and Claude Shannon. <a contenteditable="false" data-type="indexterm" data-primary="Newell, Allen" id="id740"/><a contenteditable="false" data-type="indexterm" data-primary="Simon, Herbert A." id="id741"/><a contenteditable="false" data-type="indexterm" data-primary="Logic Theorist AI program (Newell and Simon)" id="id742"/>Two attendees, Allen Newell and Herbert A. Simon, demonstrated the Logic Theorist, an AI program that could solve mathematical theorems. While today’s AI developments are far more advanced, the fundamental concepts established by these early pioneers remain critical building blocks.</p>
<p>No doubt, today’s AI developments are light-years ahead of these early applications. Yet some of their underlying fundamentals have been worked on for many years. They were the critical building blocks.</p>
<p>In this chapter, we’ll focus on the fundamentals,<a contenteditable="false" data-type="indexterm" data-primary="exam for AIF-C01" data-secondary="topics covered" data-tertiary="AI and ML fundamentals" id="id743"/><a contenteditable="false" data-type="indexterm" data-primary="topics covered in exam for AIF-C01" data-secondary="AI and ML fundamentals" id="id744"/> which are a major part of the AIF-C01 exam. This will include focusing on a core topic of AI—that is, machine learning.</p>
<section data-type="sect1" data-pdf-bookmark="Understanding AI"><div class="sect1" id="understanding_ai">
<h1>Understanding AI</h1>
<p>AI can seem overwhelming.<a contenteditable="false" data-type="indexterm" data-primary="AI (artificial intelligence)" data-secondary="understanding AI" id="c03exp"/> Part of this is due to the complexity of the technology. After all, it often involves advanced mathematics, complex algorithms, and large amounts of data.</p>
<p>Meanwhile, AI is undergoing significant change and innovation. It’s extremely <span class="keep-together">difficult—if</span> not impossible—to keep up with everything. This is the case even for the world’s top data scientists.</p>
<p>Then there is the hype, as it seems like every tech company is about AI. Even many traditional companies boast about their own AI.</p>
<p>Given all this, it should be no surprise that it’s common for people to have misunderstandings about AI. This even includes its definition!</p>
<p>But of course, when it comes to the AIF-C01 exam, you need to have a good one. What to do? The best is to see how <a href="https://oreil.ly/vniGg">AWS defines AI</a>:<a contenteditable="false" data-type="indexterm" data-primary="AI (artificial intelligence)" data-secondary="defined" id="id745"/></p>
<blockquote>
<p>AI, also known as artificial intelligence, is a technology with humanlike problem-solving capabilities. AI in action appears to simulate human intelligence—it can recognize images, write poems, and make data-based predictions.</p>
</blockquote>
<p>This is certainly a good, high-level definition. Yet we need to dig deeper. And a good way to do this is to get a visual of AI,<a contenteditable="false" data-type="indexterm" data-primary="AI (artificial intelligence)" data-secondary="understanding AI" data-tertiary="components of AI" id="id746"/> as shown in <a data-type="xref" href="#figure_three_onedot_the_various_compone">Figure 3-1</a>.</p>
<figure class="width-35"><div id="figure_three_onedot_the_various_compone" class="figure">
<img src="assets/awsc_0301.png" alt="" width="487" height="535"/>
<h6><span class="label">Figure 3-1. </span>The various components of AI</h6>
</div></figure>
<p>For the most part, AI is a collection of different approaches and fields. In some cases, they can work on their own. In other situations, there is a combination.</p>
<p>A subset of AI is ML, which<a contenteditable="false" data-type="indexterm" data-primary="AI (artificial intelligence)" data-secondary="understanding AI" data-tertiary="ML as a subset" id="id747"/><a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="AI component" id="id748"/> is where a computer learns from data. The ML algorithms find the patterns in the data and use these as the basis for predictions. Generally, the more data, the better—especially if it is high quality. <a contenteditable="false" data-type="indexterm" data-primary="fraud detection" data-secondary="ML for" id="id749"/>Some of the common use cases for ML include fraud detection, predictive analytics, and recommendation engines.</p>
<p>Next, a subset of ML is <em>deep learning</em>.<a contenteditable="false" data-type="indexterm" data-primary="deep learning" data-secondary="ML component" id="id750"/><a contenteditable="false" data-type="indexterm" data-primary="neural networks" data-secondary="deep learning of ML" id="id751"/><a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="deep learning as component of" id="id752"/> This is a flavor of ML that uses neural networks. These are essentially modeled on the human brain. The processing of data is based on analyzing data across layers and connections. This can often detect complex patterns and relationships. In some cases, they do what humans are not able to do. Thanks to deep learning, we have seen advances in categories like speech processing, NLP, and image recognition.</p>
<p>A subset of deep learning is generative AI.<a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="deep learning component" id="id753"/><a contenteditable="false" data-type="indexterm" data-primary="deep learning" data-secondary="generative AI" id="id754"/> This is at the cutting-edge of AI. It’s what powers breakout applications like OpenAI’s ChatGPT and Anthropic’s Claude.</p>
<p>A generative AI model also processes data, but the scale is usually massive. With this, it can create new content like text, software code, images, audio, and video. It can often seem humanlike.</p>
<p>Even though generative AI is powerful, it is not a silver bullet. Sometimes it’s better to use ML or deep learning, depending on the use case and requirements. Knowing some of these is important for the book.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="03exp" id="id755"/></p>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Machine Learning"><div class="sect1" id="machine_learning">
<h1>Machine Learning</h1>
<p>During the 1950s and 1960s, <a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="understanding" id="id756"/><a contenteditable="false" data-type="indexterm" data-primary="Samuel, Arthur" id="id757"/><a contenteditable="false" data-type="indexterm" data-primary="AI (artificial intelligence)" data-secondary="understanding AI" data-tertiary="ML explained" id="id758"/><a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="“machine learning” coined" data-secondary-sortas="machine learning coined" id="id759"/>Arthur Samuel was a noted computer scientist and researcher at IBM. He created one of the first pioneering AI applications, which learned how to play checkers. He also coined <em>machine learning</em>, which he <a href="https://oreil.ly/l32nO">defined</a> as “the field of study that gives computers the ability to learn without explicitly being programmed.”</p>
<p>To understand this, let’s walk through an example.<a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="understanding" data-tertiary="example of ML" id="id760"/><a contenteditable="false" data-type="indexterm" data-primary="real estate house price ML example" id="id761"/><a contenteditable="false" data-type="indexterm" data-primary="costs" data-secondary="real estate house price ML example" id="id762"/> Suppose you’re working at a real estate agency, and you want to predict how much house 5 in <a data-type="xref" href="#table_three_onedot_house_values_example">Table 3-1</a> will sell for. You know that many factors go into pricing: location, the size of the house, the number of bedrooms, and how close it is to good schools. Instead of trying to create a long list of rules for calculating prices, you can use ML to handle the heavy lifting.</p>
<table class="border" id="table_three_onedot_house_values_example">
<caption><span class="label">Table 3-1. </span>House values example</caption>
<thead>
<tr>
<th>House</th>
<th>Location</th>
<th>Size (in sq. ft.)</th>
<th>Number of bedrooms</th>
<th>Price</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Tier 1</td>
<td>500</td>
<td>1</td>
<td>$500,000</td>
</tr>
<tr>
<td>2</td>
<td>Tier 2</td>
<td>500</td>
<td>1</td>
<td>$350,000</td>
</tr>
<tr>
<td>3</td>
<td>Tier 2</td>
<td>1,000</td>
<td>2</td>
<td>$700,000</td>
</tr>
<tr>
<td>4</td>
<td>Tier 2</td>
<td>1,500</td>
<td>3</td>
<td>$1,500,000</td>
</tr>
<tr>
<td>5</td>
<td>Tier 1</td>
<td>1,000</td>
<td>2</td>
<td>To be predicted</td>
</tr>
</tbody>
</table>
<p>Here’s how it works: you gather a bunch of data on homes—maybe thousands of records—including details about their features and their actual sale prices. Then, you feed all of this into an ML algorithm. It analyzes the data and learns the patterns. For example, it might understand that homes in a certain neighborhood are worth more or that every extra bedroom adds a specific amount to the price.</p>
<p>Once the algorithm is trained, it’s ready to make predictions. Even though it’s never seen house 5 before, the model can estimate its price based on what it learned from the previous data.</p>
<p>That’s the beauty of machine learning. It lets computers learn from data and improve over time, instead of relying on hard-coded rules.</p>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Amazon SageMaker"><div class="sect1" id="amazon_sagemaker">
<h1>Amazon SageMaker</h1>
<p>In this chapter, we’ll explore Amazon SageMaker,<a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="Amazon SageMaker" data-seealso="Amazon SageMaker" id="id763"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon SageMaker" data-secondary="explained" id="id764"/> which is a platform for anyone working with ML on AWS. SageMaker is powerful, but with so many tools and features, it can feel overwhelming at first. This is why we’ll start with a high-level overview to make the components easier to understand.</p>
<p>Amazon SageMaker is a fully managed service that helps you build, train, and deploy ML models at scale. Instead of worrying about setting up infrastructure, you can focus on what matters most—developing and improving your models.</p>
<p>SageMaker supports the entire<a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="ML lifecycle" data-tertiary="Amazon SageMaker supporting" id="id765"/><a contenteditable="false" data-type="indexterm" data-primary="ML lifecycle" data-secondary="Amazon SageMaker supporting" id="id766"/> ML lifecycle, from preparing data to monitoring deployed models. It also integrates smoothly with other AWS services like Amazon S3, Amazon Redshift, and Kinesis.</p>

<p><a data-type="xref" href="#figure_three_twodot_key_components_of_s">Figure 3-2</a> shows the key components that make up the SageMaker ecosystem.</p>
<figure class="width-90"><div id="figure_three_twodot_key_components_of_s" class="figure">
<img src="assets/awsc_0302.png" alt="" width="1254" height="753"/>
<h6><span class="label">Figure 3-2. </span>Key components of SageMaker</h6>
</div></figure>
<p class="pagebreak-before">Let’s look at each component (we’ll also cover these in more detail in this chapter):</p>
<dl>
<dt>SageMaker Studio Classic</dt>
<dd><p>A web-based development environment<a contenteditable="false" data-type="indexterm" data-primary="Amazon SageMaker" data-secondary="SageMaker Studio Classic" data-tertiary="defined" id="id767"/><a contenteditable="false" data-type="indexterm" data-primary="IDE (integrated development environment)" data-secondary="Amazon SageMaker Studio Classic" data-tertiary="defined" id="id768"/> where you can manage every step of your ML workflow in one place. It supports team collaboration and automation.</p></dd>
<dt>Notebook instances</dt>
<dd><p>Managed Jupyter notebooks<a contenteditable="false" data-type="indexterm" data-primary="Jupyter Notebook" data-secondary="instances in Amazon SageMaker" id="id769"/> for writing code, running experiments, and visualizing results—no setup required.</p></dd>
<dt>JumpStart</dt>
<dd><p>A library of pretrained models<a contenteditable="false" data-type="indexterm" data-primary="Amazon SageMaker" data-secondary="SageMaker JumpStart" data-tertiary="defined" id="id770"/><a contenteditable="false" data-type="indexterm" data-primary="pretrained models" data-secondary="SageMaker JumpStart" id="id771"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon SageMaker" data-secondary="SageMaker JumpStart" data-tertiary="pretrained models" id="id772"/><a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="pretrained models" data-tertiary="SageMaker JumpStart" id="id773"/> and built-in algorithms to help you get started quickly or fine-tune models for your specific use case.</p></dd>
<dt>Data Wrangler</dt>
<dd><p>A tool for cleaning, transforming,<a contenteditable="false" data-type="indexterm" data-primary="Amazon SageMaker" data-secondary="SageMaker Data Wrangler" data-tertiary="defined" id="id774"/> and exploring data. It connects to over 50 data sources, making preprocessing faster and easier.</p></dd>
<dt>Model Monitor</dt>
<dd><p>Keeps an eye on deployed models,<a contenteditable="false" data-type="indexterm" data-primary="Amazon SageMaker" data-secondary="SageMaker Model Monitor" data-tertiary="defined" id="id775"/><a contenteditable="false" data-type="indexterm" data-primary="monitoring" data-secondary="SageMaker Model Monitor" id="id776"/> automatically detecting issues like data drift or declining performance.</p></dd>
<dt>MLOps tools</dt>
<dd><p>Includes services to manage ML workflows with automation, governance, and version control.<a contenteditable="false" data-type="indexterm" data-primary="machine learning operations (MLOps)" data-secondary="tools in Amazon SageMaker" id="id777"/></p></dd>
</dl>
<p>SageMaker is built for flexibility and scale. There are also strong systems for security, compliance, and access controls.</p>
</div></section>
<section data-type="sect1" data-pdf-bookmark="The ML Lifecycle"><div class="sect1" id="the_ml_lifecycle">
<h1>The ML Lifecycle</h1>
<p>The ML lifecycle is a fancy way<a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="ML lifecycle" id="c03life"/><a contenteditable="false" data-type="indexterm" data-primary="ML lifecycle" id="c03life2"/><a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="ML lifecycle" data-tertiary="about" id="id778"/><a contenteditable="false" data-type="indexterm" data-primary="ML lifecycle" data-secondary="about" id="id779"/> of describing the process for building AI systems. There is no right way to do this, as there are various approaches and flavors. But AWS does offer its own flow, which includes the following steps:</p>
<ul>
<li><p>Business goal identification</p></li>
<li><p>ML problem framing</p></li>
<li><p>Data processing</p></li>
<li><p>Model development</p></li>
<li><p>Model deployment</p></li>
<li><p>Monitoring</p></li>
</ul>
<p>Let’s go through each of these steps.</p>
<section data-type="sect2" data-pdf-bookmark="Business Goal Identification"><div class="sect2" id="business_goal_identification">
<h2>Business Goal Identification</h2>
<p>The first step in the ML lifecycle<a contenteditable="false" data-type="indexterm" data-primary="ML lifecycle" data-secondary="business goal identification" id="id780"/><a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="ML lifecycle" data-tertiary="business goal identification" id="id781"/> is about answering a straightforward question: What’s the goal of the project? Usually, it’s senior leaders and managers who hammer out the key details and make the final decision. They have the authority and budget to make things happen. When it comes to AI, these projects can be expensive. They are also often considered strategic for a company.</p>
<p>A plan may not necessarily be detailed. For example, it could be a PowerPoint with 5 to 10 slides or so. However, it should be clear what the goal is. <a contenteditable="false" data-type="indexterm" data-primary="key performance indicators (KPIs)" id="id782"/>A way to express this is with key performance indicators (KPIs), which are the metrics to measure whether the ML project is hitting its mark or not.</p>
<p>For example, suppose you work at a traditional retail company. During the past year, there have been problems with customer churn. However, you believe that AI can help solve the problem. You work with senior executives but also include domain experts in the organization, such as from the customer success department. From all this, you and the team come up with the KPI to reduce churn by 15% in the next year and set aside a budget of $200,000 for building and deploying the ML model.</p>
<p>This is not to imply that this KPI is set in stone. It may need to be adjusted because of the complexities of AI. This is especially the case for organizations that do not have much or any experience with AI projects. Regardless, it’s important to set specific KPIs to help guide the project and provide for accountability.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="ML Problem Framing"><div class="sect2" id="ml_problem_framing">
<h2>ML Problem Framing</h2>
<p>After you’ve settled on a business objective,<a contenteditable="false" data-type="indexterm" data-primary="ML lifecycle" data-secondary="ML problem framing" id="id783"/><a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="ML lifecycle" data-tertiary="ML problem framing" id="id784"/><a contenteditable="false" data-type="indexterm" data-primary="business problem framing" id="id785"/> the next step is to translate this into something that ML can handle. This is known as ML <em>problem framing</em>.</p>
<p>This stage of the process involves a team of technical experts, such as data scientists, data engineers, and ML architects. <a contenteditable="false" data-type="indexterm" data-primary="subject matter experts (SMEs)" id="id786"/>There are also subject matter experts (SMEs), who have a strong understanding of a particular process in an organization or industry-specific expertise.</p>
<p>It’s important that this team take an open-minded approach. The fact is that ML may not be the right solution—or any other AI technique. Rather, a problem could be solved by using traditional data analytics or process automation.</p>
<p>However, if ML is the right choice, then there needs to be an evaluation of important factors like:</p>
<ul>
<li><p>Is there quality data for the ML model?</p></li>
<li><p>Does the organization have the skills needed for success for the project?</p></li>
<li><p>Are there enough resources?</p></li>
</ul>
<p>For example, suppose a healthcare company wants to predict patient readmission rates to improve care and reduce costs. The business problem is clear: fewer readmissions lead to better outcomes and lower expenses. During ML problem framing, the team decides that this can be formulated as a classification problem. The goal is to predict whether a patient is likely to be readmitted within 30 days after discharge.</p>
<p>However, it’s equally important to recognize situations where ML may not be the right solution. For instance, if the task can be solved using a straightforward rule-based system—like calculating a patient’s BMI from weight and height—then ML introduces unnecessary complexity. In such cases, traditional programming is faster, cheaper, and easier to maintain. <a contenteditable="false" data-type="indexterm" data-primary="transparency" data-secondary="ML suitability and" id="id787"/><a contenteditable="false" data-type="indexterm" data-primary="compliance" data-secondary="ML suitability and" id="id788"/>Similarly, ML may not be suitable when full transparency and explainability are nonnegotiable. In regulatory-heavy environments such as healthcare or finance, decisions affecting patient eligibility or loan approval may demand a clear, auditable logic path—something that many ML models, especially deep learning ones, struggle to provide. Before jumping into model development, teams should ask: Can a rules engine handle this? And will we be able to confidently explain the output to users or auditors? If the answer is no, machine learning may not be the right tool for the job.</p>
<p>After this, the team will evaluate the data requirements. In this case, there will likely need to be historical patient records, discharge summaries, and demographic details. Are these available? And if they are, does the team have the right to use the data?</p>
<p>In the meantime, there needs to be a focus on putting together the team to carry out the project. However, there may not be enough employees. In this case, there needs to be a realistic analysis of what it would take to hire people or bring on contractors. How long would this take? What are the costs?</p>
<p>This process can take some time, but it is well worth the effort. It can greatly mitigate the potential for failure of an ML project.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Data Processing"><div class="sect2" id="data_processing-id000023">
<h2>Data Processing</h2>
<p>Data processing is about converting data into a usable format. This includes these main steps:<a contenteditable="false" data-type="indexterm" data-primary="ML lifecycle" data-secondary="data processing" id="c03dp"/><a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="ML lifecycle" data-tertiary="data processing" id="id789"/><a contenteditable="false" data-type="indexterm" data-primary="data processing" data-secondary="ML lifecycle" id="id790"/></p>
<ul>
<li><p>Data collection and integration</p></li>
<li><p>Data preprocessing</p></li>
<li><p>Feature engineering, which is the process of selecting, creating, or modifying input variables (features) to improve model performance by making the data more meaningful and predictive</p></li>
<li><p>Data visualization</p></li>
</ul>
<p>We’ll cover each of these steps in the next few sections.</p>
<section data-type="sect3" data-pdf-bookmark="Data collection and integration"><div class="sect3" id="data_collection_and_integration">
<h3>Data collection and integration</h3>
<p>When collecting and integrating data<a contenteditable="false" data-type="indexterm" data-primary="data processing" data-secondary="ML lifecycle" data-tertiary="data collection and integration" id="id791"/> for an ML project, you want to have it in a central place. This helps to streamline the process, providing for more consistency, accuracy, and speed.</p>
<p>With AWS, there is the advantage of using different types of data stores like Amazon S3 and Amazon EBS, which we covered in <a data-type="xref" href="ch02.html#chapter_two_aws_fundamentals_for_the_ai">Chapter 2</a>. For more sophisticated workloads, you can use data warehouses. These can store large amounts of structured data from many sources. Amazon Redshift has this capability.</p>
<p>Or you can use a lakehouse. This is a modern architecture for storage, which stores any type of data. Amazon SageMaker Lakehouse exemplifies this by integrating Amazon S3 data lakes and Amazon Redshift data warehouses. This allows for access and management of diverse data types.</p>
<p>Then there is Kinesis. This is designed to handle large amounts of real-time data processing. While Kinesis is not a lakehouse, it integrates seamlessly into a lakehouse architecture.</p>
<p>Regardless of these storage options, the fact remains that all data is not created equal. Simply put, if your data is low quality, the results of the ML model will likely fall short. This goes to the famous rule of thumb: garbage in, garbage out. This is why it is critical to choose your data sources thoughtfully. Some questions to ask:</p>
<ul>
<li><p>Does the data relate to the problem to be solved?</p></li>
<li><p>Is the data accurate?</p></li>
<li><p>Is it diverse? Is it representative of the real world?</p></li>
<li><p>Is there enough data for the model?</p></li>
<li><p>Is the data up-to-date?</p></li>
</ul>
<p>It’s important to know that data comes in two main categories:<a contenteditable="false" data-type="indexterm" data-primary="unlabeled data" id="id792"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="unlabeled data" id="id793"/><a contenteditable="false" data-type="indexterm" data-primary="labeled data" id="id794"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="labeled data" id="id795"/></p>
<dl>
<dt>Labeled data</dt>
<dd><p>This is where the data has a description. For instance, in a spam filter, emails are labeled as “spam” or “not spam.” These labels usually come from human input.</p></dd>
<dt>Unlabeled data</dt>
<dd><p>This is raw data.</p></dd>
</dl>
<p>There are also two formats of data:<a contenteditable="false" data-type="indexterm" data-primary="structured data" id="id796"/><a contenteditable="false" data-type="indexterm" data-primary="unstructured data" id="id797"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="unstructured data" id="id798"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="structured data" id="id799"/></p>
<dl>
<dt>Structured data</dt>
<dd><p>This is organized data. The most common format is for rows and columns in a spreadsheet or database (which is also called <em>tabular data</em>). This type of data is certainly useful for ML projects. But structured data can also be expressed as time-series data. This is where it is collected over time, such as stock prices or weather information.</p></dd>
<dt>Unstructured data</dt>
<dd><p>This data doesn’t have a predefined format. Examples of this include text, images, audio, and video. To make sense of it, you’ll need more advanced AI techniques to uncover patterns and insights.</p></dd>
</dl>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Data preprocessing, feature engineering, and data visualization"><div class="sect3" id="data_preprocessingcomma_feature_enginee">
<h3>Data preprocessing, feature engineering, and data visualization</h3>
<p>Data is messy. Missing values, outliers, errors, and inconsistencies are common. To deal with these problems, there is data preprocessing or data preparation.<a contenteditable="false" data-type="indexterm" data-primary="data processing" data-secondary="ML lifecycle" data-tertiary="data preprocessing, feature engineering, visualization" id="id800"/><a contenteditable="false" data-type="indexterm" data-primary="data preprocessing" id="id801"/> But there’s a hitch—this process can be time-consuming and costly. According to a survey by Anaconda,<sup><a data-type="noteref" id="ch01fn1-marker" href="ch03.html#ch01fn1">1</a></sup> data scientists spend about 45% of their time wrestling with these tasks.</p>
<p>Even when the data is cleaned up, there is more to do.<a contenteditable="false" data-type="indexterm" data-primary="feature engineering" id="id802"/> The next step is feature engineering. This is where data scientists will determine the meaningful aspects of the data. The focus is on finding those values that have the biggest impact on accurate predictions.</p>
<p>To help with this, <a contenteditable="false" data-type="indexterm" data-primary="visualization of data" id="id803"/><a contenteditable="false" data-type="indexterm" data-primary="exploratory data analysis (EDA)" id="id804"/><a contenteditable="false" data-type="indexterm" data-primary="EDA (exploratory data analysis)" id="id805"/>there is data visualization. Data scientists will try to get a better understanding of the dataset by using scatterplots, histograms, and box plots. This is known as exploratory data analysis (EDA).</p>
<p>Data preprocessing, feature engineering, and data visualization can be labor-intensive. <a contenteditable="false" data-type="indexterm" data-primary="Amazon SageMaker" data-secondary="SageMaker Data Wrangler" id="id806"/><a contenteditable="false" data-type="indexterm" data-primary="data processing" data-secondary="ML lifecycle" data-tertiary="SageMaker Data Wrangler" id="id807"/>But with SageMaker you can use Data Wrangler to streamline the process. It provides access to all AWS data sources, but there are also integrations with 50+ third-party data providers, such as Snowflake and Databricks. Next, Data Wrangler verifies data quality and detects anomalies. This is done with 300+ built-in transformations. This means there is no need to learn tools like PySpark or Apache Spark. Data Wrangler also provides visualization templates and reports. What may take weeks—using traditional approaches—can take only minutes using Data Wrangler.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="03dp" id="id808"/></p>
</div></section>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Model Development"><div class="sect2" id="model_development">
<h2>Model Development</h2>
<p>Model development has three main steps, which we’ll cover in the following sections:<a contenteditable="false" data-type="indexterm" data-primary="ML lifecycle" data-secondary="model development" id="c03modev"/><a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="ML lifecycle" data-tertiary="model development" id="c03modev2"/><a contenteditable="false" data-type="indexterm" data-primary="model development" data-secondary="ML lifecycle" id="id809"/></p>
<ul>
<li><p>Training</p></li>
<li><p>Evaluation</p></li>
<li><p>Tuning</p></li>
</ul>

<section data-type="sect3" data-pdf-bookmark="Training"><div class="sect3" id="training">
<h3>Training</h3>
<p>Training involves teaching<a contenteditable="false" data-type="indexterm" data-primary="model development" data-secondary="training" id="c03train"/><a contenteditable="false" data-type="indexterm" data-primary="ML lifecycle" data-secondary="model development" data-tertiary="training" id="c03train2"/><a contenteditable="false" data-type="indexterm" data-primary="training" id="c03train3"/> a model to learn patterns and making predictions. This is based on using ML algorithms on datasets. The process is iterative, as it will require adjustments to the model parameters to improve the predictions of the model. There are three types of algorithms:</p>
<ul>
<li><p>Supervised learning</p></li>
<li><p>Unsupervised learning</p></li>
<li><p>Reinforcement learning</p></li>
</ul>
<p>Evaluating these types of models requires expertise in data science. There are rules of thumb as to which to use for certain use cases. We’ll look at these in the next few sections of this book. But before doing this,<a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="dataset split into three sections" id="id810"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="training data" id="id811"/> it’s important that the dataset is split up into three sections:</p>
<dl>
<dt>Training data (70% to 80% of the dataset)</dt>
<dd><p>This is where you use the data with the ML algorithms to teach it to understand patterns and make predictions.</p></dd>
<dt>Validating data (10% to 15%)</dt>
<dd><p>This is for tuning the data to get better performance.</p></dd>
<dt>Testing data (10% to 15%)</dt>
<dd><p>Here, the model is evaluated based on unseen data. This helps to provide a sense of how it may work with real-world applications.</p></dd>
</dl>
<section data-type="sect4" data-pdf-bookmark="Supervised learning"><div class="sect4" id="supervised_learning">
<h4>Supervised learning</h4>
<p>In supervised learning,<a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="supervised learning" id="c03sup"/><a contenteditable="false" data-type="indexterm" data-primary="supervised learning" id="c03sup2"/><a contenteditable="false" data-type="indexterm" data-primary="labeled data" data-secondary="supervised learning" id="id812"/><a contenteditable="false" data-type="indexterm" data-primary="supervised learning" data-secondary="labeled data" id="id813"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="labeled data" data-tertiary="supervised learning" id="id814"/> the model learns using labeled data. Basically, the labels act as a guide, helping the model understand the relationship between inputs and their matching outputs. Think of it as a teacher supervising a student—hence the name “supervised learning.” For example, let’s say there’s a dataset full of images of fruits, each labeled as an apple, banana, or orange. After training on this data, the model can take a new, unlabeled image of a banana and identify it correctly.</p>
<p>Supervised learning can be divided into two main tasks: classification and regression.</p>
<p><strong><em>Classification.</em></strong> Classification<a contenteditable="false" data-type="indexterm" data-primary="supervised learning" data-secondary="classification" id="id815"/><a contenteditable="false" data-type="indexterm" data-primary="classification in supervised learning" id="id816"/> is about sorting data into predefined categories. The model learns patterns from labeled data so it can categorize new examples. An example is credit risk assessment. A classification model can analyze a loan applicant’s credit history, income, and debts to determine whether they fall into the “low risk” or “high risk” category. This helps financial institutions make smarter lending decisions.</p>
<p>Other examples of classification include the following:<a contenteditable="false" data-type="indexterm" data-primary="fraud detection" data-secondary="classification for" id="id817"/></p>
<ul>
<li><p>Fraud detection</p></li>
<li><p>Customer churn prediction</p></li>
<li><p>Image recognition</p></li>
<li><p>Medical diagnostics</p></li>
<li><p>Sentiment analysis</p></li>
<li><p>Spam filtering</p></li>
</ul>
<p><strong><em>Regression.</em></strong> Regression<a contenteditable="false" data-type="indexterm" data-primary="supervised learning" data-secondary="regression" id="id818"/><a contenteditable="false" data-type="indexterm" data-primary="regression in supervised learning" id="id819"/> refers to predicting continuous values rather than categories. It looks at the relationship between variables to make forecasts. Here are some examples of use cases:</p>
<ul>
<li><p>Forecasting sales numbers</p></li>
<li><p>Estimating stock market trends</p></li>
<li><p>Predicting population growth</p></li>
<li><p>Calculating life expectancy</p></li>
</ul>
<p>Let’s take a more detailed look with an example. Suppose you are building an ML model to predict hourly energy consumption of a building. In the feature engineering stage, you determine the independent variables. These are values that are not changed by other values in the algorithm. For our example, we come up with the following:</p>
<ul>
<li><p>Outdoor temperature</p></li>
<li><p>Humidity levels</p></li>
<li><p>Time of day</p></li>
<li><p>Day of the week</p></li>
<li><p>Occupancy levels</p></li>
<li><p>Historical energy consumption data</p></li>
</ul>
<p>Then we have the dependent variable. This is the value we are predicting in our ML model, which is the energy consumption or kWh (kilowatt-hour).</p>
<p>There are different types of regression algorithms like linear regression, random forest regression, or support vector regression (SVR). Then which one to use? Evaluation can be a complex process. You need to know the intricacies of the algorithms. But generally, when it comes to a regression model, it’s about understanding the relationship between the independent and dependent variables. In our example, the linear regression model would probably not be a good option. The reason is that it assumes a straight-line relationship between input features and the target variable, which may not capture the complex, nonlinear patterns often present in building energy consumption data. Rather, a random forest regression and SVR are better suited for modeling such complexities.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c03sup" id="id820"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c03sup2" id="id821"/></p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="Unsupervised learning"><div class="sect4" id="unsupervised_learning">
<h4>Unsupervised learning</h4>
<p>Unsupervised learning is where<a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="unsupervised learning" id="id822"/><a contenteditable="false" data-type="indexterm" data-primary="unsupervised learning" id="id823"/><a contenteditable="false" data-type="indexterm" data-primary="unlabeled data" data-secondary="unsupervised learning" id="id824"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="unlabeled data" data-tertiary="unsupervised learning" id="id825"/> a model is trained on unlabeled datasets. The algorithms will analyze the structure of the data, such as to find the underlying patterns, groupings, and relationships. This is done without any prior guidance.</p>
<p>There are two main approaches to unsupervised learning:</p>
<ul>
<li><p>Clustering</p></li>
<li><p>Dimensionality reduction</p></li>
</ul>
<p><strong><em>Clustering.</em></strong> Clustering<a contenteditable="false" data-type="indexterm" data-primary="clustering in unsupervised learning" id="id826"/><a contenteditable="false" data-type="indexterm" data-primary="unsupervised learning" data-secondary="clustering" id="id827"/> groups data based on similarities. This is usually done by using a measurement technique. The closer two points are, the more similar they are. Here are common approaches to this:</p>
<dl>
<dt>Euclidean distance</dt>
<dd><p>This measures the straight-line distance between two points. It’s done in multidimensional space. This refers to areas that extend beyond the typical three dimensions of length, width, and height.</p></dd>
<dt>Cosine similarity</dt>
<dd><p>This measures the angle between two points (the cosine). If the two are in the same direction, then they are similar.</p></dd>
<dt>Manhattan distance</dt>
<dd><p>This is the sum of the absolute differences of two points. Yes, it’s based on how a taxicab navigates through a city grid.</p></dd>
</dl>
<p>As for the algorithms for clustering, <a contenteditable="false" data-type="indexterm" data-primary="clustering in unsupervised learning" data-secondary="k-means clustering" id="id828"/><a contenteditable="false" data-type="indexterm" data-primary="k-means clustering" id="id829"/>one of the most popular is <em>k</em>-means clustering. It often uses Euclidean distance to cluster the data points that are the closest. For example, a retail company can use <em>k</em>-means clustering to group customers based on the spending amount, product preferences, or purchase frequency. This can be used for more personalized marketing, say with relevant product selections and discounts.</p>
<p>Another algorithm for clustering is<a contenteditable="false" data-type="indexterm" data-primary="density-based spatial clustering of applications with noise (DBSCAN)" id="id830"/><a contenteditable="false" data-type="indexterm" data-primary="DBSCAN (density-based spatial clustering of applications with noise)" id="id831"/><a contenteditable="false" data-type="indexterm" data-primary="fraud detection" data-secondary="DBSCAN algorithm for clustering" id="id832"/> density-based spatial clustering of applications with noise (DBSCAN), which often uses Euclidean or Manhattan measurements. A common example of this is fraud detection. By using DBSCAN, outliers can be detected, which may indicate fraudulent behavior. It could find that generally the transactions are in the range of $100 to $200, with a few that are for more than $10,000.</p>
<p>Amazon’s Random Cut Forest (RCF) algorithm<a contenteditable="false" data-type="indexterm" data-primary="Random Cut Forest (RCF) algorithm" id="id833"/><a contenteditable="false" data-type="indexterm" data-primary="outliers detected by Random Cut Forest" id="id834"/> is particularly effective for identifying outliers in financial transaction data. Unlike clustering algorithms that group similar data points, RCF focuses on detecting anomalies by assigning an anomaly score <span class="keep-together">to each data</span> point based on how easily it can be isolated. For instance, in a dataset where most transactions range between $100 and $200, an unexpected transaction <span class="keep-together">of $10,000</span> would likely receive a high anomaly score, flagging it for further <span class="keep-together">investigation.</span></p>
<p><strong><em>Dimensionality reduction.</em></strong> High-dimensional data<a contenteditable="false" data-type="indexterm" data-primary="unsupervised learning" data-secondary="dimensionality reduction" id="id835"/><a contenteditable="false" data-type="indexterm" data-primary="dimensionality reduction" id="id836"/><a contenteditable="false" data-type="indexterm" data-primary="curse of dimensionality" id="id837"/> is when a dataset has a large number of features. However, this can cause problems for ML models. This phenomenon is referred to as the “curse of dimensionality.”</p>
<p>A typical issue with<a contenteditable="false" data-type="indexterm" data-primary="costs" data-secondary="high-dimensional data" id="id838"/> high-dimensional data is high computational costs. This requires more processing power, memory, and time to analyze the data.</p>
<p>Next, there is the issue with overfitting,<a contenteditable="false" data-type="indexterm" data-primary="overfitting" data-secondary="high-dimensional data" id="id839"/> which is when an ML model learns too much from the training data and does not generalize well on unseen data.</p>
<p>To understand this, let’s take an example. Suppose we have a spam filter that has training data with a high frequency of the word <em>free</em>. Overfitting would mean that the model will detect spam, even though the word has many legitimate uses.</p>
<p>To deal with these problems, you can use dimensionality reduction. Simply put, this is the process of reducing the number of features in a dataset, but the changes must not materially impact the dataset.</p>
<p>Principal component analysis (PCA), t-SNE, and autoencoders are some of the other algorithms that can be used.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="Reinforcement learning"><div class="sect4" id="reinforcement_learning">
<h4>Reinforcement learning</h4>
<p>You did not use a guidebook<a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="reinforcement learning" id="id840"/><a contenteditable="false" data-type="indexterm" data-primary="reinforcement learning (RL)" id="id841"/> or take lessons to ride a bike, right? Of course not. Instead, you watched others and then tried it yourself. There was lots of falling and some scraped knees and hands. But ultimately, you were able to figure it out. Riding a bike would soon become natural.</p>
<p>This process is similar to reinforcement learning. This is how an ML model learns by trial and error—that is, there is positive and negative reinforcement based on interacting with an environment.</p>
<p>Reinforcement learning has been shown to be particularly effective with:</p>
<dl>
<dt>Games</dt>
<dd><p>They have the benefit of clear rules, scores, and constraints (like a game board). With this environment, an ML model can run millions of simulations, which will allow for learning. This has been key for systems like AlphaGo, which beat the world champion of the game Go.</p></dd>
<dt>Robotics</dt>
<dd><p>Since robotics navigate in the real world, reinforcement learning can allow these systems to understand their environment.</p></dd>
</dl>
<p>The three types of ML learning—supervised learning, unsupervised learning, and reinforcement learning—are shown<a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="supervised learning" id="id842"/><a contenteditable="false" data-type="indexterm" data-primary="supervised learning" id="id843"/><a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="unsupervised learning" id="id844"/><a contenteditable="false" data-type="indexterm" data-primary="unsupervised learning" id="id845"/> in <a data-type="xref" href="#figure_three_threedot_the_three_main_ty">Figure 3-3</a>.</p>
<figure><div id="figure_three_threedot_the_three_main_ty" class="figure">
<img src="assets/awsc_0303.png" alt="" width="1266" height="450"/>
<h6><span class="label">Figure 3-3. </span>The three main types of ways for machines to learn using ML</h6>
</div></figure>
</div></section>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Using AWS for model development"><div class="sect3" id="using_aws_for_model_development">
<h3>Using AWS for model development</h3>
<p>Model development in ML<a contenteditable="false" data-type="indexterm" data-primary="model development" data-secondary="AWS for" id="id846"/><a contenteditable="false" data-type="indexterm" data-primary="ML lifecycle" data-secondary="model development" data-tertiary="AWS for model development" id="id847"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon SageMaker" data-secondary="model development" id="id848"/> involves the process of designing, training, and refining algorithms to analyze data and make predictions or decisions. This includes selecting appropriate models, preparing data, training the models, and evaluating their performance to ensure they meet the desired objectives.</p>
<p>With Amazon SageMaker, there are three main options for model development:</p>
<dl>
<dt>Pretrained models</dt>
<dd><p>There are hundreds of pretrained models available,<a contenteditable="false" data-type="indexterm" data-primary="pretrained models" data-secondary="SageMaker JumpStart" id="id849"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon SageMaker" data-secondary="SageMaker JumpStart" data-tertiary="pretrained models" id="id850"/><a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="pretrained models" data-tertiary="SageMaker JumpStart" id="id851"/><a contenteditable="false" data-type="indexterm" data-primary="pretrained models" data-secondary="foundation models as" id="id852"/><a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="pretrained models" data-tertiary="foundation models" id="id853"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="pretrained" id="id854"/> which require little fine-tuning or configuration. You can access them using SageMaker JumpStart (see <a data-type="xref" href="#figure_three_fourdot_foundation_models">Figure 3-4</a>). FMs, computer vision models, and NLP models are available.</p>
<figure><div id="figure_three_fourdot_foundation_models" class="figure">
<img src="assets/awsc_0304.png" alt="" width="1403" height="836"/>
<h6><span class="label">Figure 3-4. </span>Foundation models section of the SageMaker JumpStart dashboard for pretrained models</h6>
</div></figure>
</dd>
<dt>Built-in algorithms</dt>
<dd><p>These are tailored for large datasets and where there is a need for scalability and performance optimization.</p></dd>
<dt>Docker images</dt>
<dd><p>Docker images are for popular ML frameworks<a contenteditable="false" data-type="indexterm" data-primary="Docker images for model development" id="id855"/> like TensorFlow, PyTorch, and scikit-learn. There are also images for your own models. This is when you want <span class="keep-together">customization.</span><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c03train" id="id856"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c03train2" id="id857"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c03train3" id="id858"/></p></dd>
</dl>

</div></section>
<section data-type="sect3" data-pdf-bookmark="Evaluation"><div class="sect3" id="evaluation-id000025">
<h3>Evaluation</h3>
<p>Before a model goes into production,<a contenteditable="false" data-type="indexterm" data-primary="model development" data-secondary="evaluation" id="c03eval"/><a contenteditable="false" data-type="indexterm" data-primary="evaluation in model development" id="c03eval2"/><a contenteditable="false" data-type="indexterm" data-primary="ML lifecycle" data-secondary="model development" data-tertiary="evaluation" id="c03eval3"/> there needs to be extensive evaluation of the performance. There are various metrics for this, and many of these depend on the type of model you use. The metrics are not foolproof but provide general guidance. We’ll take a look at the following metrics:</p>
<ul>
<li><p>Model fit</p></li>
<li><p>Classification</p></li>
<li><p>Regression</p></li>
</ul>
<section data-type="sect4" data-pdf-bookmark="Model fit"><div class="sect4" id="model_fit">
<h4>Model fit</h4>
<p>Model fit refers to how well<a contenteditable="false" data-type="indexterm" data-primary="model development" data-secondary="evaluation" data-tertiary="model fit" id="id859"/><a contenteditable="false" data-type="indexterm" data-primary="evaluation in model development" data-secondary="model fit" id="id860"/> a model captures patterns in the data. The goal is to strike a balance between overfitting and underfitting to achieve optimal <span class="keep-together">accuracy.</span></p>
<p><a contenteditable="false" data-type="indexterm" data-primary="overfitting" id="id861"/>To mitigate overfitting, you can:</p>
<ul>
<li><p>Reduce the number of features.</p></li>
<li><p>Increase the size of the training dataset.</p></li>
<li><p>Apply regularization techniques like L1 (lasso regression) and L2 (ridge regression) to simplify the model.</p></li>
</ul>
<p>Underfitting happens when<a contenteditable="false" data-type="indexterm" data-primary="underfitting" id="id862"/> a model is too simple to capture the underlying patterns in the data. For example, if you’re building a model to recognize handwritten digits and use logistic regression, it may struggle because handwritten digits have complex, nonlinear patterns. In such cases, a more complex algorithm, like a neural network or decision tree, may be more appropriate.</p>
<p>There are other causes of underfitting. One is that the data does not have enough features. There may also be too few iterations—or epochs—for the training.</p>
<p>To measure overfitting and underfitting,<a contenteditable="false" data-type="indexterm" data-primary="bias" id="id863"/><a contenteditable="false" data-type="indexterm" data-primary="variance" id="id864"/> you can use bias and variance, which are statistical calculations. Bias is the difference between the average predicted values <span class="keep-together">and actual</span> values. It’s a way to gauge a model’s tendency to make errors based on simplistic assumptions, which means there is underfitting.</p>
<p>Variance, on the other hand, measures the fluctuations in the predicted values. A high variance means that the model is sensitive to small changes in the training, which can indicate overfitting.</p>
<p>Again, the goal is to strike a balance—that is, to have a model with low bias and low variance.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="Classification"><div class="sect4" id="classification">
<h4>Classification</h4>
<p>Classification metrics are used<a contenteditable="false" data-type="indexterm" data-primary="model development" data-secondary="evaluation" data-tertiary="classification metrics" id="c03class"/><a contenteditable="false" data-type="indexterm" data-primary="evaluation in model development" data-secondary="classification metrics" id="c03class2"/><a contenteditable="false" data-type="indexterm" data-primary="classification metrics for model evaluation" id="c03class3"/> to measure the performance of ML models that assign labels to data points. These metrics help evaluate how accurately a model makes predictions and where it might be going wrong. For example, if you’re developing a model to predict whether a patient has a certain disease based on medical test results, classification metrics can show how often the model makes correct diagnoses, misses true cases, or raises false alarms.</p>
<p>For a classification problem, you can evaluate the model by using techniques like the following:</p>
<ul>
<li><p>Confusion matrix</p></li>
<li><p>Accuracy</p></li>
<li><p>Precision</p></li>
<li><p>Recall</p></li>
<li><p>Area under the curve-receiver operating curve (AUC-ROC)</p></li>
</ul>
<p>To understand these metrics, we’ll use an example. Suppose you are building an ML model to detect credit card fraud. It will use the binary classification approach, which will indicate whether a transaction is either fraudulent or legitimate.</p>
<p>Let’s next apply the metrics.</p>
<p><strong><em>Confusion matrix.</em></strong> A confusion matrix<a contenteditable="false" data-type="indexterm" data-primary="evaluation in model development" data-secondary="classification metrics" data-tertiary="confusion matrix" id="id865"/><a contenteditable="false" data-type="indexterm" data-primary="confusion matrix" data-secondary="evaluation in model development" id="id866"/> is a way to understand the reasons why an outcome of an ML model is wrong. After the training is complete, you will get the number of occurrences of true positives, false positives, false negatives, and true negatives (see <a data-type="xref" href="#table_three_twodot_confusion_matrix_for">Table 3-2</a>).</p>
<table class="border" id="table_three_twodot_confusion_matrix_for">
<caption><span class="label">Table 3-2. </span>Confusion matrix for a fraud deduction ML model</caption>
<thead>
<tr>
<th>Actual/predicted values</th>
<th>Fraudulent (positive)</th>
<th>Legitimate (negative)</th>
</tr>
</thead>
<tbody>
<tr>
<td>Fraudulent</td>
<td>70</td>
<td>30</td>
</tr>
<tr>
<td>Legitimate</td>
<td>20</td>
<td>880</td>
</tr>
</tbody>
</table>
<p>Let’s analyze this confusion matrix:</p>
<dl>
<dt>True positives</dt>
<dd><p>70 transactions classified as fraudulent.</p></dd>
<dt>False negatives</dt>
<dd><p>30 fraudulent transactions incorrectly identified as legitimate.</p></dd>
<dt>False positives</dt>
<dd><p>20 legitimate transactions incorrectly identified as fraudulent.</p></dd>
<dt>True negatives (TN)</dt>
<dd><p>880 transactions correctly classified as legitimate.</p></dd>
</dl>
<p>The takeaway? While the model is effective in detecting fraud, there can be improvement in minimizing the false negative and false positives.</p>
<p>Keep in mind that the confusion matrix is also the basis for calculating accuracy, precision, and recall.</p>
<p><strong><em>Accuracy.</em></strong> The accuracy<a contenteditable="false" data-type="indexterm" data-primary="evaluation in model development" data-secondary="classification metrics" data-tertiary="accuracy" id="id867"/><a contenteditable="false" data-type="indexterm" data-primary="accuracy" id="id868"/> of the model is also called the <em>score</em>. It is the sum of the correct predictions, which are divided by the number of predictions. In our credit card fraud example, the accuracy is 95%:</p>
<ul class="list_style_type_none">
<li><p>True positives (TP) = 70</p></li>
<li><p>False negatives (FN) = 30</p></li>
<li><p>False positives (FP) = 20</p></li>
<li><p>True negatives (TN) = 880</p></li>
<li><p>Accuracy = (TP + TN) / (TP + FN + FP + TN)</p></li>
<li><p>= (70 + 880) / (70 + 30 + 20 + 880) = 950 / 1000 = 95%</p></li>
</ul>
<p>But this metric can be deceiving. It can be less useful when there are many true negatives in the dataset. This is why it’s important to use several metrics when evaluating a model.</p>
<p><strong><em>Precision.</em></strong> Precision<a contenteditable="false" data-type="indexterm" data-primary="evaluation in model development" data-secondary="classification metrics" data-tertiary="precision" id="id869"/><a contenteditable="false" data-type="indexterm" data-primary="precision" id="id870"/> focuses on the true and false positives. That is, it is calculated as the number of true positives divided by the true positives and false positives. For our credit card fraud example, the precision is 77.8%:</p>
<ul class="list_style_type_none">
<li><p>70 / (70 + 20)</p></li>
</ul>
<p>Generally, precision is useful when the cost of false positives is high. This is certainly the case with fraud detection. If a false positive happens when a transaction is <span class="keep-together">legitimate—tagging</span> it as fraudulent—this can lead to lower customer satisfaction. Or if a false negative occurs—where the machine learning model classifies a fraudulent transaction as legitimate—it can lead to financial losses.</p>
<p class="pagebreak-before"><strong><em>Recall.</em></strong> With recall,<a contenteditable="false" data-type="indexterm" data-primary="evaluation in model development" data-secondary="classification metrics" data-tertiary="recall" id="id871"/><a contenteditable="false" data-type="indexterm" data-primary="recall" id="id872"/> the focus is the positives for the confusion matrix. It’s calculated as the true positives divided by the sum of the true positives and false negatives. For our credit card fraud example, it’s 70%:</p>
<ul class="list_style_type_none">
<li><p>70 / (70 + 30)</p></li>
</ul>
<p>This essentially measures a model’s ability to classify actual fraudulent transactions.</p>
<p><strong><em>Area under the curve-receiver operating curve (AUC-ROC).</em></strong> AUC-ROC plots<a contenteditable="false" data-type="indexterm" data-primary="evaluation in model development" data-secondary="classification metrics" data-tertiary="area under the curve-receiver operating curve" id="id873"/><a contenteditable="false" data-type="indexterm" data-primary="area under the curve-receiver operating curve (AUC-ROC)" id="id874"/> the recall against the false positive rate, as shown in <a data-type="xref" href="#figure_three_fivedot_the_curve_receiver">Figure 3-5</a>. This is done at different threshold settings. For example, with our credit card fraud example, we could have a lower threshold. This means that more transactions will be classified as fraudulent, which will increase the detection rate of actual frauds or true positives. Or we could do the opposite. It depends on the goals and requirements.</p>
<p>Generally, the higher the AUC, the better the model is at distinguishing between fraudulent and legitimate transactions. An AUC close to 1.0 indicates strong performance, while an AUC near 0.5 means the model isn’t much better than random guessing.</p>
<figure><div id="figure_three_fivedot_the_curve_receiver" class="figure">
<img src="assets/awsc_0305.png" alt="The curve-receiver operating curve (AUC-ROC)" width="1187" height="919"/>
<h6><span class="label">Figure 3-5. </span>The curve-receiver operating curve (AUC-ROC)</h6>
</div></figure>
</div></section>
<section data-type="sect4" data-pdf-bookmark="Regression"><div class="sect4" id="regression">
<h4>Regression</h4>
<p>There are numerous metrics for regression.<a contenteditable="false" data-type="indexterm" data-primary="model development" data-secondary="evaluation" data-tertiary="regression" id="id875"/><a contenteditable="false" data-type="indexterm" data-primary="evaluation in model development" data-secondary="regression" id="id876"/><a contenteditable="false" data-type="indexterm" data-primary="regression in model evaluation" id="id877"/> But for purposes of the exam, you should focus on these two: mean squared error (MSE) and R squared (R<sup>2</sup>).</p>
<p>Of these two, MSE is generally<a contenteditable="false" data-type="indexterm" data-primary="regression in model evaluation" data-secondary="mean squared error" id="id878"/><a contenteditable="false" data-type="indexterm" data-primary="mean squared error (MSE)" id="id879"/> the most common.</p>
<p><strong><em>Mean squared error.</em></strong> With MSE, you compare the differences between the predictions and actual outcomes. To calculate it, you square each difference, sum them, and take the average.</p>
<p>Suppose you are creating a regression model to predict annual salaries based on an employee’s experience with the company. <a data-type="xref" href="#table_three_threedot_regression_model_f">Table 3-3</a> shows the data.</p>
<table class="border" id="table_three_threedot_regression_model_f">
<caption><span class="label">Table 3-3. </span>Regression model for salaries</caption>
<thead>
<tr>
<th>Employee<br/>ID</th>
<th>Years of<br/>experience</th>
<th>Actual salary ($1,000s)</th>
<th>Predicted salary ($1,000s)</th>
<th>Error (actual/predicted)</th>
<th>Squared error</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>2</td>
<td>50</td>
<td>55</td>
<td>–5</td>
<td>25</td>
</tr>
<tr>
<td>2</td>
<td>5</td>
<td>80</td>
<td>75</td>
<td>5</td>
<td>25</td>
</tr>
<tr>
<td>3</td>
<td>7</td>
<td>100</td>
<td>95</td>
<td>5</td>
<td>25</td>
</tr>
<tr>
<td>4</td>
<td>10</td>
<td>150</td>
<td>140</td>
<td>10</td>
<td>100</td>
</tr>
<tr>
<td>5</td>
<td>12</td>
<td>150</td>
<td>140</td>
<td>10</td>
<td>100</td>
</tr>
</tbody>
</table>
<p>Based on this, the MSE is 40. What does this mean? It’s the average of the square difference between the predicted and actual values. Generally, the lower this is, the more accurate the prediction.</p>
<p><strong><em>R squared.</em></strong> R<sup>2</sup> is a value<a contenteditable="false" data-type="indexterm" data-primary="regression in model evaluation" data-secondary="R squared" id="id880"/><a contenteditable="false" data-type="indexterm" data-primary="R squared (R²)" id="id881"/> from 0 to 1. It shows how much of a regression model is explained by the variability of the prediction. The closer the value is to 1, the more accurate the model.</p>
<p>But this also depends on the category. For example, a relatively lower R squared—such a 0.40 or 0.50—may be fine for social studies. But for physics and engineering, you would probably want something like 0.9 or higher.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c03eval" id="id882"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c03eval2" id="id883"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c03eval3" id="id884"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c03class" id="id885"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c03class2" id="id886"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c03class3" id="id887"/></p>
</div></section>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Tuning"><div class="sect3" id="tuning">
<h3>Tuning</h3>
<p>Tuning is the process<a contenteditable="false" data-type="indexterm" data-primary="model development" data-secondary="tuning" id="id888"/><a contenteditable="false" data-type="indexterm" data-primary="tuning a model" id="id889"/><a contenteditable="false" data-type="indexterm" data-primary="parameters" data-secondary="tuning a model" id="id890"/><a contenteditable="false" data-type="indexterm" data-primary="ML lifecycle" data-secondary="model development" data-tertiary="tuning" id="id891"/> of adjusting a model’s parameters and settings to improve its performance. When you first train an ML model, the initial results are often underwhelming because the default settings may not capture the underlying patterns in the data or may not be well-suited to the specific problem. That’s why tuning is typically necessary—to refine the model so it can make more accurate predictions.</p>
<p>One approach is hyperparameter optimization.<a contenteditable="false" data-type="indexterm" data-primary="hyperparameters" data-secondary="optimization or tuning" id="id892"/> A hyperparameter is a setting in an ML model, which is to control how it learns. This can be done by adjusting:<a contenteditable="false" data-type="indexterm" data-primary="batch size" id="id893"/><a contenteditable="false" data-type="indexterm" data-primary="learning rate" id="id894"/><a contenteditable="false" data-type="indexterm" data-primary="neural networks" data-secondary="hyperparameter tuning" id="id895"/></p>
<dl>
<dt>Batch size</dt>
<dd><p>The number of training examples that are processed at a time</p></dd>
<dt>Learning rate</dt>
<dd><p>How quickly the model adapts to the new data</p></dd>
<dt>Neural network</dt>
<dd><p>The number and size of layers</p></dd>
</dl>
<p>How does a hyperparameter differ from a parameter? A parameter is learned during training, whereas a hyperparameter must be defined before the training and will remain fixed.</p>
<p>As for hyperparameter optimization, this is where you adjust the hyperparameter to improve the performance of the model. Keep in mind that even a small change can make a big difference. There are various methods to help with this:</p>
<dl>
<dt>Grid search</dt>
<dd><p>This is where you process multiple combinations of hyperparameters.</p></dd>
<dt>Random search</dt>
<dd><p>Process random combinations within defined ranges.</p></dd>
<dt>Bayesian optimization</dt>
<dd><p>Use probability models for the search.</p></dd>
<dt>Optuna</dt>
<dd><p>This is a modern, open source optimization framework that uses a smarter sampling strategy to efficiently search the hyperparameter space. It’s known for being fast, flexible, and easy to integrate into Python-based ML workflows.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c03modev" id="id896"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c03modev2" id="id897"/></p></dd>
</dl>
</div></section>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Model Deployment"><div class="sect2" id="model_deployment">
<h2>Model Deployment</h2>
<p>When the ML model finally meets<a contenteditable="false" data-type="indexterm" data-primary="ML lifecycle" data-secondary="model deployment" id="id898"/><a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="ML lifecycle" data-tertiary="model deployment" id="id899"/><a contenteditable="false" data-type="indexterm" data-primary="model deployment" id="id900"/><a contenteditable="false" data-type="indexterm" data-primary="deploying a model" id="id901"/><a contenteditable="false" data-type="indexterm" data-primary="model deployment" data-secondary="self-hosted versus managed API" id="id902"/><a contenteditable="false" data-type="indexterm" data-primary="deploying a model" data-secondary="self-hosted versus managed API" id="id903"/> your requirements after the development phase, the next step is to put it into production. There are two main ways for this:</p>
<dl>
<dt>Self-hosted API</dt>
<dd><p>This is when you deploy the ML model on your own IT infrastructure. This can be in a private cloud, on-premises, or a cloud platform, such as AWS. You will need to set up VMs, web servers, networking, storage, and <span class="keep-together">databases.</span></p></dd>
<dt>Managed API</dt>
<dd><p>This is where a platform—like SageMaker—handles the infrastructure, deployment, and automatic scaling.</p></dd>
</dl>
<p>There are pros and cons for each option. With the self-hosted API, you have much more control. This can allow for customization, unique requirements, and implementing security. Then again, this option can be expensive and time-consuming. You will also need IT personnel who are experienced with infrastructure.</p>
<p>The managed API, on the other hand, is much more simplified. You can focus more time on building ML models, not managing the underlying infrastructure. The costs are usually lower as well. Then again, there is not as much flexibility.</p>
<p>Once deployed—whether through a self-hosted API or a managed platform like <span class="keep-together">SageMaker—your</span> model<a contenteditable="false" data-type="indexterm" data-primary="model deployment" data-secondary="inferencing" id="id904"/><a contenteditable="false" data-type="indexterm" data-primary="deploying a model" data-secondary="inferencing" id="id905"/><a contenteditable="false" data-type="indexterm" data-primary="inferencing by model" id="id906"/> is ready for inferencing, making predictions based on new input data.</p>
<p>There are different ways to do this. For example, with SageMaker you can do the <span class="keep-together">following:</span><a contenteditable="false" data-type="indexterm" data-primary="real-time inference" id="id907"/><a contenteditable="false" data-type="indexterm" data-primary="batch transform" id="id908"/><a contenteditable="false" data-type="indexterm" data-primary="inferencing by model" data-secondary="real-time inference" id="id909"/><a contenteditable="false" data-type="indexterm" data-primary="inferencing by model" data-secondary="batch transform" id="id910"/></p>
<dl>
<dt>Real-time inference</dt>
<dd><p>Use this when an ML application needs to act near instantaneously. This is for high-stakes use cases, such as self-driving cars, healthcare monitoring, and fraud detection.</p></dd>
<dt>Batch transform</dt>
<dd><p>Batch transform is generally for large datasets that don’t require immediate responses. For instance, a marketing team might use batch transform to segment thousands of customers overnight, enabling targeted email campaigns the next morning.</p></dd>
<dt>Asynchronous inference</dt>
<dd><p>This is for large payloads or long-running jobs; for example, an image recognition app that analyzes high-resolution photos uploaded by users. While the image is being processed, the user can continue browsing the app without delay.</p></dd>
<dt>On-demand serverless inference</dt>
<dd><p>Applications with intermittent traffic, as with a small business chatbot, for example, can use serverless inference to respond to customer inquiries, automatically scaling resources based on the volume of users at any given time—without needing a permanently running server.</p></dd>
</dl>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Monitoring"><div class="sect2" id="monitoring">
<h2>Monitoring</h2>
<p>Monitoring is about tracking<a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="ML lifecycle" data-tertiary="monitoring" id="id911"/><a contenteditable="false" data-type="indexterm" data-primary="ML lifecycle" data-secondary="monitoring" id="id912"/><a contenteditable="false" data-type="indexterm" data-primary="monitoring" data-secondary="ML lifecycle" id="id913"/> an ML model to ensure it is working as intended. Part of this is to look at KPIs, as we mentioned earlier in this chapter.</p>
<p>But it’s important to understand that even high-quality models will degrade in accuracy. This is due to factors like the following:</p>
<dl>
<dt>Data drift</dt>
<dd><p>Features of the model change over time,<a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="data drift" id="id914"/> yet the relationships remain the same. For example, suppose you have built an ML model for predictive maintenance, where the system will try to anticipate needs for repairs for machines. However, after a few years, the model may show lower performance levels since the machines will be older, which can lead to changes in the characteristics of the features like vibration levels and temperature readings.</p></dd>
<dt>Concept drift</dt>
<dd><p>The relationship between the<a contenteditable="false" data-type="indexterm" data-primary="concept drift" id="id915"/> features has changed. For example, this can be the case when a spam filter becomes less effective because spammers find ways to game the system.</p></dd>
<dt>Label shift</dt>
<dd><p>There is a shift in the labels<a contenteditable="false" data-type="indexterm" data-primary="labeled data" data-secondary="label shift" id="id916"/><a contenteditable="false" data-type="indexterm" data-primary="supervised learning" data-secondary="labeled data" data-tertiary="label shift" id="id917"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="labeled data" data-tertiary="label shift" id="id918"/> of a dataset over time, but the relationships of the labels remain the same. To understand this, let’s look again at the spam filter scenario. Suppose the ML model was built with a dataset that has 30% of emails labeled as spam. But in the next year, there’s a notable increase in spam activities. This can have an adverse impact on performance of the ML model since it may not be able to pick up on the higher proportion of spam.</p></dd>
<dt>Feature drift</dt>
<dd><p>This is similar to data drift.<a contenteditable="false" data-type="indexterm" data-primary="feature drift" id="id919"/> With feature drift, the distribution of features in a dataset change over time, but the relationships remain constant. An example is with credit scores. Let’s say a model is basing its predictions on income of $30,000 to $50,000. But in a couple years, the population has seen improved gains, with income ranging from $50,000 to $70,000. This means that the distribution of the feature has changed. This could easily mean inaccurate predictions.</p></dd>
</dl>
<p>There are many monitoring systems available to detect these problems. <a contenteditable="false" data-type="indexterm" data-primary="Amazon SageMaker" data-secondary="SageMaker Model Monitor" id="id920"/>As for AWS, there is SageMaker Model Monitor. It provides continuous monitoring of real-time endpoints, batch transform jobs that run regularly, and asynchronous batch transform jobs that are on schedule.</p>
<p>The system is highly configurable, allowing for setting alerts for when there are issues with an ML model. You can then be proactive in taking actions. These may be to retrain the model or fix quality issues.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="MLOps"><div class="sect2" id="mlops">
<h2>MLOps</h2>
<p>Machine learning operations (MLOps) <a contenteditable="false" data-type="indexterm" data-primary="ML lifecycle" data-secondary="MLOps" id="id921"/><a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="ML lifecycle" data-tertiary="MLOps" id="id922"/><a contenteditable="false" data-type="indexterm" data-primary="machine learning operations (MLOps)" data-secondary="ML lifecycle" id="id923"/>is about a set of practices, processes, and automations to better manage the ML lifecycle. It is for the following:</p>
<ul>
<li><p>Data preparation</p></li>
<li><p>Testing and validating models</p></li>
<li><p>Model training</p></li>
<li><p>Deployment</p></li>
<li><p>Monitoring</p></li>
</ul>
<p>MLOps is based on underlying concepts of DevOps, which is focused on the integration of software development and IT teams.</p>
<p>However, with MLOps, it must deal with the unique aspects of ML models. These include the experimental nature of these systems, the reliance of large datasets, and the continuous monitoring. Then there are the challenges of finding skilled <span class="keep-together">employees.</span></p>
<p>A key advantage of MLOps is that an application can get to market faster. It provides a framework to organize a project and leverage repeatable processes. The planning can go a long way in avoiding wasted efforts and expenses. This also includes using automation systems, like SageMaker.</p>
<p>MLOps can be integrated with CI/CD. This is for the automations of building, testing, and deploying the ML models. This will also include versioning of the inputs and outputs of the model, which allows for better understanding of the performance of the models. Versioning also provides for rollbacks, which means that the system will be returned to the prior setup.</p>
<p>Another advantage of MLOps is that it can help promote a culture of collaboration among data scientists, data engineers, software engineers, and IT personnel. This is no easy feat given that each role has specialized backgrounds. But there needs to be a focus on strong governance. This means having clear documentation and ways to provide constructive feedback. Of course, there must be systems in place to provide for data, privacy, and security compliance.</p>
<p>Amazon SageMaker has numerous tools for MLOps. Some of them we have already covered, such as Data Wrangler and Model Monitor. Here are some others:<a contenteditable="false" data-type="indexterm" data-primary="machine learning operations (MLOps)" data-secondary="tools in Amazon SageMaker" id="id924"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon SageMaker" data-secondary="SageMaker Feature Store" id="id925"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon SageMaker" data-secondary="SageMaker Experiments" id="id926"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon SageMaker" data-secondary="SageMaker Processing" id="id927"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon SageMaker" data-secondary="SageMaker Model Registry" id="id928"/><a contenteditable="false" data-type="indexterm" data-primary="data preprocessing" data-secondary="SageMaker Processing automating" id="id929"/><a contenteditable="false" data-type="indexterm" data-primary="data processing" data-secondary="ML lifecycle" data-tertiary="SageMaker Processing" id="id930"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c03life" id="id931"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c03life2" id="id932"/></p>
<dl>
<dt>SageMaker Feature Store</dt>
<dd><p>This assists in creating, sharing, and managing ML features.</p></dd>
<dt>SageMaker Experiments</dt>
<dd><p>You can experiment with mixes of datasets, models, and parameters. The system will then evaluate the accuracy.</p></dd>
<dt>SageMaker Processing</dt>
<dd><p>This automates data preprocessing, feature engineering, and model evaluation.</p></dd>
<dt>SageMaker Model Registry</dt>
<dd><p>With this, you can catalog models, manage model versions, process the approvals, or deploy models to production.</p></dd>
</dl>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="AWS Development Tools"><div class="sect1" id="aws_development_tools">
<h1>AWS Development Tools</h1>

<p>To support development, SageMaker provides two key environments: SageMaker Notebook Instances and SageMaker Studio Classic.<a contenteditable="false" data-type="indexterm" data-primary="AWS (Amazon Web Services)" data-secondary="development tools" id="c03devtoo"/><a contenteditable="false" data-type="indexterm" data-primary="development tools in AWS" id="c03devtoo2"/><a contenteditable="false" data-type="indexterm" data-primary="AWS (Amazon Web Services)" data-secondary="development tools" data-tertiary="about" id="id933"/><a contenteditable="false" data-type="indexterm" data-primary="development tools in AWS" data-secondary="about" id="id934"/></p>

<section data-type="sect2" data-pdf-bookmark="SageMaker Notebook Instances"><div class="sect2" id="sagemaker_notebook_instances">
<h2>SageMaker Notebook Instances</h2>
<p>A Jupyter notebook is an<a contenteditable="false" data-type="indexterm" data-primary="AWS (Amazon Web Services)" data-secondary="development tools" data-tertiary="SageMaker Notebook Instances" id="id935"/><a contenteditable="false" data-type="indexterm" data-primary="development tools in AWS" data-secondary="SageMaker Notebook Instances" id="id936"/><a contenteditable="false" data-type="indexterm" data-primary="Jupyter Notebook" data-secondary="instances in Amazon SageMaker" data-tertiary="development tool" id="id937"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon SageMaker" data-secondary="SageMaker Notebook Instances" id="id938"/> open source system, which is accessible from the internet. You can create documents that have live code, documentation, equations, and visualizations. Jupyter Notebooks are popular for building ML models.</p>
<p>You can use these in AWS with SageMaker Notebook Instances. These are fully managed Jupyter notebooks that you can launch from the SageMaker console.</p>
<p>Let’s walk through an example to see how it works. First, you will log in to your AWS account, which we learned about in <a data-type="xref" href="ch02.html#chapter_two_aws_fundamentals_for_the_ai">Chapter 2</a>, and then click the menu icon (sometimes called the “burger” icon) on the top left. From the menu, you will click “Create notebook instance.”</p>
<p>You’ll see a configuration screen. Here, you can fill out details like access permissions, GitHub integration, and network settings. But at a minimum, you will enter a name for the notebook and use the default role.</p>
<p>AWS will spin up a VM instance to host your notebook. It might take a couple of minutes to set up. When it’s ready, click the name of your instance, and then select Open Jupyter. On the left side of the screen, choose New, and from the drop-down menu, select conda_python_3. The notebook will show up (see <a data-type="xref" href="#figure_three_sixdot_jupyter_notebook_in">Figure 3-6</a>).</p>
<p>As you can see, I put in some sample code. This program loads and displays the Iris dataset, a well-known dataset used for ML.</p>
<p>Each line in the notebook is called a <em>cell</em>. It can be for either documentation or description, which is in a Markdown format. This is similar to how you would format a web page. Then there is a cell for the code. For ML projects, this is usually Python, Scala, or R.</p>
<p>In <a data-type="xref" href="#figure_three_sixdot_jupyter_notebook_in">Figure 3-6</a>, the title for the project—at the top—is in Markdown; the code is Python.</p>
<p>To run the code in a cell, you will click it and then press Shift+Enter. The output—if there is any—will appear below it.</p>

<div data-type="note" epub:type="note"><h6>Note</h6>
<p>When you are using SageMaker Notebook Instances—or any other AWS service—you need to be careful. In some cases, the billing will continue. For a notebook, this may be less than a dollar per month. But this can still add up, as you add more. Because of this, if you do not expect to use any in the future, then you should delete them.</p>
</div>

<figure><div id="figure_three_sixdot_jupyter_notebook_in" class="figure">
<img src="assets/awsc_0306.png" alt="" width="1010" height="939"/>
<h6><span class="label">Figure 3-6. </span>Jupyter Notebook in SageMaker</h6>
</div></figure>


</div></section>
<section data-type="sect2" data-pdf-bookmark="SageMaker Studio Classic"><div class="sect2" id="sagemaker_studio_classic">
<h2>SageMaker Studio Classic</h2>
<p>SageMaker Studio Classic is<a contenteditable="false" data-type="indexterm" data-primary="AWS (Amazon Web Services)" data-secondary="development tools" data-tertiary="SageMaker Studio Classic" id="id939"/><a contenteditable="false" data-type="indexterm" data-primary="development tools in AWS" data-secondary="SageMaker Studio Classic" id="id940"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon SageMaker" data-secondary="SageMaker Studio Classic" id="id941"/><a contenteditable="false" data-type="indexterm" data-primary="IDE (integrated development environment)" data-secondary="Amazon SageMaker Studio Classic" id="id942"/> an IDE for creating and deploying ML models. It’s user-friendly, supports team collaboration, and doesn’t use VMs, which helps to lower the costs. It is also compatible with tools like Jupyter Notebook, VS Code, and RStudio.</p>
<p>To use SageMaker Studio Classic, log in to your AWS account and select the icon on the top left. Choose “Create a SageMaker domain” and then select the “Quick setup” option, which is for a single user. It will then take a few minutes for SageMaker to be initialized.</p>
<p class="pagebreak-before">After this, go to User Profiles and choose Launch. You’ll see the dashboard for SageMaker Studio Classic, as shown in <a data-type="xref" href="#figure_three_sevendot_dashboard_for_the">Figure 3-7</a>.</p>
<figure><div id="figure_three_sevendot_dashboard_for_the" class="figure">
<img src="assets/awsc_0307.png" alt="" width="1877" height="945"/>
<h6><span class="label">Figure 3-7. </span>Dashboard for the SageMaker Studio Classic</h6>
</div></figure>
<p>On the left side of the screen, you’ll find a navigation panel with applications like JupyterLab and the Code Editor. Below that, you can access key ML services, including Data, Auto ML, and Experiments.</p>
<p>For the rest of this book, we’ll focus on SageMaker Studio Classic.</p>
<p>Let’s move on and explore other AWS services.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="AWS ML Services"><div class="sect2" id="aws_ml_services">
<h2>AWS ML Services</h2>
<p>In this section, we’ll focus on<a contenteditable="false" data-type="indexterm" data-primary="AWS (Amazon Web Services)" data-secondary="development tools" data-tertiary="AWS ML services" id="c03mlserv"/><a contenteditable="false" data-type="indexterm" data-primary="development tools in AWS" data-secondary="AWS ML services" id="c03mlserv2"/><a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-secondary="AWS ML services" id="c03mlserv3"/> ready-to-use AWS ML services that don’t require extensive model building or training. These solutions can be quickly integrated into applications to add powerful AI capabilities—such as language understanding, translation, speech recognition, and personalization—without deep ML expertise.</p>
<section data-type="sect3" data-pdf-bookmark="Amazon Comprehend"><div class="sect3" id="amazon_comprehen">
<h3>Amazon Comprehend</h3>
<p>Amazon Comprehend is an NLP tool.<a contenteditable="false" data-type="indexterm" data-primary="Amazon Comprehend" id="id943"/><a contenteditable="false" data-type="indexterm" data-primary="natural language processing (NLP)" data-secondary="Amazon Comprehend" id="id944"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="security and privacy" data-tertiary="sensitive data identified and redacted" id="id945"/><a contenteditable="false" data-type="indexterm" data-primary="privacy" data-secondary="sensitive data" data-tertiary="identified and redacted" id="id946"/><a contenteditable="false" data-type="indexterm" data-primary="personally identifiable information (PII)" data-secondary="Amazon Comprehend redacting" id="id947"/> It can extract insights from data, such as documents, product reviews, social media feeds, and customer support tickets. The tool will try to understand the content by focusing on key phrases, entities, places, people, sentiment, and topics. Amazon Comprehend also has security features to identify and redact personally identifiable information (PII).</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Amazon Translate"><div class="sect3" id="amazon_translate">
<h3>Amazon Translate</h3>
<p>Amazon Translate is for language translation.<a contenteditable="false" data-type="indexterm" data-primary="Amazon Translate" id="id948"/> It can understand 75 languages. The system uses neural translation, which is based on sophisticated deep learning models. This allows for more accurate and natural-sounding translations.</p>
<p>The tool leverages Active Custom Translation (ACT).<a contenteditable="false" data-type="indexterm" data-primary="Active Custom Translation (ACT)" id="id949"/> This means you can use your own data to customize the translations. But there is no need to create a new model.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Amazon Textract"><div class="sect3" id="amazon_textract">
<h3>Amazon Textract</h3>
<p>Amazon Textract extracts<a contenteditable="false" data-type="indexterm" data-primary="Amazon Textract" id="id950"/> text and handwriting from scanned documents, PDFs, and images. But this is more than a typical optical character recognition (OCR) system. Amazon Textract can also identify and understand the information that is extracted.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Amazon Lex"><div class="sect3" id="amazon_lex">
<h3>Amazon Lex</h3>
<p>Amazon Lex is a fully managed<a contenteditable="false" data-type="indexterm" data-primary="Amazon Lex" id="id951"/> AI service that allows for the creation, testing, and deployment of conversational interfaces, such as chatbots. The core engine is the Alexa platform. Amazon Lex also uses Lambda, which allows for customization based on an organization’s internal data.</p>
<p>This system can be easily deployed on mobile, IoT devices, and call centers. There are also integrations with Facebook Messenger, Slack, and Twilio SMS.</p>
<p>On the backend, there is a dashboard, which provides extensive analytics.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Amazon Polly"><div class="sect3" id="amazon_polly">
<h3>Amazon Polly</h3>
<p>Amazon Polly provides tools<a contenteditable="false" data-type="indexterm" data-primary="Amazon Polly" id="id952"/> to allow applications to have lifelike speech. It comes with more than 100 male and female voices. They span more than 40 languages and language variants.</p>
<p>Amazon Polly has many use cases. For example, you can use it to allow text-to-speech with blog posts, PDFs, and web pages.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Amazon Transcribe"><div class="sect3" id="amazon_transcrib">
<h3>Amazon Transcribe</h3>
<p>Amazon Transcribe is known as<a contenteditable="false" data-type="indexterm" data-primary="Amazon Transcribe" id="id953"/><a contenteditable="false" data-type="indexterm" data-primary="automatic speech recognition (ASR)" id="id954"/> an automatic speech recognition (ASR) service. This means it can convert speech into text, such as from WAV and MP3 files. The service provides timestamps for every word, which allows for search capabilities. Amazon Transcribe can also be used in real time.</p>
<p>Some of the use cases include:</p>
<ul>
<li><p>Transcriptions of customer support calls</p></li>
<li><p>Creation of subtitles for audio and video files</p></li>
<li><p>Content analysis</p></li>
</ul>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Amazon Rekognition"><div class="sect3" id="amazon_rekognition">
<h3>Amazon Rekognition</h3>
<p>Amazon Rekognition is a sophisticated<a contenteditable="false" data-type="indexterm" data-primary="Amazon Rekognition" id="id955"/><a contenteditable="false" data-type="indexterm" data-primary="computer vision" data-secondary="Amazon Rekognition" id="id956"/><a contenteditable="false" data-type="indexterm" data-primary="real-world applications of AWS tools" data-secondary="computer vision" data-tertiary="Amazon Rekognition" id="id957"/> computer vision tool. It makes it possible to identify objects, people, scenes, and activities in images and videos. This system also allows for facial search and analysis, helping with user verification and people <span class="keep-together">counting.</span></p>
<p>These are other use cases:</p>
<ul>
<li><p>Detect unsafe or inappropriate content</p></li>
<li><p>Identify video segments that help to lower costs</p></li>
<li><p>Provide alerts when an unknown person is detected near your home</p></li>
</ul>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Amazon Kendra"><div class="sect3" id="amazon_kendra">
<h3>Amazon Kendra</h3>
<p>Amazon Kendra is an <a contenteditable="false" data-type="indexterm" data-primary="Amazon Kendra" id="id958"/>enterprise search system that works across various structured and unstructured repositories. This can be easily implemented into corporate websites and applications.</p>
<p>A powerful feature is <a contenteditable="false" data-type="indexterm" data-primary="Amazon Kendra" data-secondary="GenAI index" id="id959"/>the Kendra GenAI index. This uses RAG, which leverages generative AI for searching proprietary documents. With this, you can create personalized digital assistants.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Amazon Personalize"><div class="sect3" id="amazon_personalize">
<h3>Amazon Personalize</h3>
<p>Amazon Personalize helps <a contenteditable="false" data-type="indexterm" data-primary="Amazon Personalize" id="id960"/>create AI applications that are customized based on the interests and behaviors of users. Setup of the system can take a few hours. But this is fairly low compared to many others.</p>
<p>Amazon Personalize is built to be highly adaptable. In real time, it will incorporate user data to improve recommendations. Some of the use cases for this tool are:</p>
<ul>
<li><p>Customer sentiment analysis</p></li>
<li><p>Targeted marketing campaigns</p></li>
<li><p>Identification of market trends</p></li>
</ul>
</div></section>
<section data-type="sect3" data-pdf-bookmark="AWS DeepRacer"><div class="sect3" id="aws_deepracer">
<h3>AWS DeepRacer</h3>
<p>AWS DeepRacer is a 3D simulation<a contenteditable="false" data-type="indexterm" data-primary="AWS DeepRacer" id="id961"/><a contenteditable="false" data-type="indexterm" data-primary="3D simulation AWS DeepRacer" id="id962"/><a contenteditable="false" data-type="indexterm" data-primary="reinforcement learning (RL)" data-secondary="AWS DeepRacer" id="id963"/> application of a fully autonomous race car. This provides a fun way to learn about reinforcement learning.</p>
<p>In <a data-type="xref" href="#table_three_fourdot_aws_ai_services">Table 3-4</a>, you’ll find a summary of the AWS AI services.</p>
<table class="border less_space pagebreak-before" id="table_three_fourdot_aws_ai_services">
<caption class="less_space"><span class="label">Table 3-4. </span>AWS AI services</caption>
<thead>
<tr>
<th>Service</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Amazon Comprehend</td>
<td>Extracts insights from text using NLP, including sentiment and PII detection</td>
</tr>
<tr>
<td>Amazon Kendra</td>
<td>Provides intelligent enterprise search across document repositories</td>
</tr>
<tr>
<td>Amazon Lex</td>
<td>Creates conversational chatbots using speech and text input</td>
</tr>
<tr>
<td>Amazon Personalize</td>
<td>Generates real-time, personalized recommendations using user data</td>
</tr>
<tr>
<td>Amazon Polly</td>
<td>Converts text into lifelike speech in multiple voices and languages</td>
</tr>
<tr>
<td>Amazon Rekognition</td>
<td>Detects objects, scenes, and faces in images and videos</td>
</tr>
<tr>
<td>Amazon Textract</td>
<td>Extracts and understands text and handwriting from documents and images</td>
</tr>
<tr>
<td>Amazon Transcribe</td>
<td>Converts speech to text with support for real-time transcription</td>
</tr>
<tr>
<td>Amazon Translate</td>
<td>Provides real-time language translation for over 75 languages</td>
</tr>
<tr>
<td>AWS DeepRacer</td>
<td>Simulates autonomous driving to teach reinforcement learning</td>
</tr>
</tbody>
</table>
<p>AWS services, including Amazon SageMaker, are continuously updated with new features and capabilities. For the latest information, always refer to the official <a href="https://oreil.ly/_49DF">AWS <span class="keep-together">documentation</span></a>.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c03devtoo" id="id964"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c03devtoo2" id="id965"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c03mlserv" id="id966"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c03mlserv2" id="id967"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c03mlserv3" id="id968"/></p>
</div></section>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Conclusion"><div class="sect1" id="conclusion-id000008">
<h1>Conclusion</h1>
<p>In this chapter, we had an overview of ML. It’s certainly a big topic with many moving parts. To help make this more understandable, we focused on the ML lifecycle, which has phases like data processing, model deployment, and monitoring. In each step, we learned about the key concepts and use cases along with the relevant AWS tools.</p>
<p>After this, we covered MLOps, which is a comprehensive approach to managing ML projects. We also looked at the numerous other AWS ML services for specific use cases.</p>
<p>In the next chapter, we’ll take a look at generative AI.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Quiz"><div class="sect1" id="ch3quiz">
	<h1>Quiz</h1>

<p>To check your answers, please refer to the <a data-type="xref" href="app02.html#answers_ch_3">“Chapter 3 Answer Key”</a>.</p>

<ol>
<li><p>Which of the following best describes the role of feature engineering in machine learning (ML)?</p>
<ol type="a">
<li><p>It creates new variables or transforms data to improve model performance.</p></li>
<li><p>It trains the model using labeled data.</p></li>
<li><p>It evaluates the accuracy of a trained model.</p></li>
<li><p>It ensures that the model is not biased.</p></li>
</ol>
</li>
</ol>

<ol class="less_space pagebreak before" start="2">
<li><p>What is the primary purpose of reinforcement learning in AI?</p>
<ol type="a">
<li><p>To learn patterns from labeled data</p></li>
<li><p>To optimize decisions based on rewards and penalties</p></li>
<li><p>To detect anomalies in datasets</p></li>
<li><p>To reduce dimensionality in high-dimensional datasets</p></li>
</ol>
</li>

<li><p>A company is using Amazon SageMaker to build a machine learning (ML) model. What is the primary advantage of using SageMaker over traditional on-premises ML infrastructure?</p>
<ol type="a">
<li><p>It eliminates the need for data preprocessing.</p></li>
<li><p>It requires more manual intervention than on-premises solutions.</p></li>
<li><p>It provides pretrained models that cannot be customized.</p></li>
<li><p>It automates the entire ML lifecycle, from training to deployment.</p></li>
</ol>
</li>

<li><p>What is the primary difference between supervised and unsupervised learning?</p>
<ol type="a">
<li><p>Supervised learning does not require labeled data, while unsupervised learning does.</p></li>
<li><p>Supervised learning focuses on reinforcement learning, while unsupervised learning does not.</p></li>
<li><p>Supervised learning uses labeled data, while unsupervised learning finds patterns in unlabeled data.</p></li>
<li><p>Supervised learning is only used for classification tasks, while unsupervised learning is used for all other ML applications.</p></li>
</ol>
</li>

<li><p>A retailer wants to group its customers based on purchasing behavior without using predefined labels. Which machine learning (ML) approach should they use?</p>
<ol type="a">
<li><p>Reinforcement learning</p></li>
<li><p>Supervised learning</p></li>
<li><p>Unsupervised learning</p></li>
<li><p>Semisupervised learning</p></li>
</ol>
</li>

<li><p>Why is model monitoring important in machine learning (ML)?</p>
<ol type="a">
<li><p>It prevents overfitting by reducing the number of features in a dataset.</p></li>
<li><p>It ensures that a deployed model maintains accuracy and adapts to data changes.</p></li>
<li><p>It eliminates the need for retraining models over time.</p></li>
<li><p>It guarantees that predictions will always be correct.</p></li>
</ol>
</li>
</ol>
</div></section>

<div data-type="footnotes"><p data-type="footnote" id="ch01fn1"><sup><a href="ch03.html#ch01fn1-marker">1</a></sup> Alex Woodie, <a href="https://oreil.ly/K1mvn">“Data Prep Still Dominates Data Scientists’ Time, Survey Finds”</a>, <span class="keep-together">BigDATAwire,</span> July 6, 2020.</p></div></div></section></div></div></body></html>