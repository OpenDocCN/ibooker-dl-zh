# 第6章。基因组学的深度学习

每个生物体的核心是其基因组：包含制造生物体工作部分的所有指令的DNA分子。如果一个细胞是一台计算机，那么它的基因组序列就是它执行的软件。如果DNA可以被视为软件，信息是计算机处理的，那么我们肯定可以使用我们自己的计算机来分析这些信息并理解它是如何运作的？

当然，DNA不仅仅是一个抽象的存储介质。它是一种行为复杂的物理分子。它还与成千上万的其他分子相互作用，所有这些分子都在维持、复制、指导和执行DNA中包含的指令方面发挥重要作用。基因组是一个由成千上万部分组成的巨大而复杂的机器。我们对大多数这些部分如何工作仍知之甚少，更不用说它们如何作为一个整体运作了。

这将引出*遗传学*和*基因组学*这两个领域。遗传学将DNA视为抽象信息。它研究遗传模式，或者在人群中寻找相关性，以发现DNA序列和生理特征之间的联系。另一方面，基因组学将基因组视为一个物理机器。它试图理解构成该机器的部分以及它们如何协同工作。这两种方法是互补的，深度学习可以成为它们两者的强大工具。

# DNA、RNA和蛋白质

即使你不是生物学家，在你的教育过程中，你可能也学习过基因组是如何运作的基础知识。我们将首先回顾通常在入门课程中教授的基因组的简化图景。然后我们将描述现实世界更为复杂的一些方面。

DNA是一种聚合物：一长串重复单元串在一起。在DNA的情况下，有四种可能出现的单元（称为*碱基*）：腺嘌呤、胞嘧啶、鸟嘌呤和胸腺嘧啶，简称为A、C、G和T（参见[图6-1](#dna-structure-bases)）。关于如何制造生物体的几乎所有信息最终都编码在构成其基因组的这四种重复单元的特定模式中。

![](Images/dlls_0601.png)

###### 图6-1\. DNA分子的结构。它由许多A、C、G和T碱基组成的两条链组成。这两条链是互补的：一条链中的每个C与另一条链中的G配对，一条链中的每个A与另一条链中的T配对。 (来源：[Wikimedia](https://en.wikipedia.org/wiki/Molecular_Structure_of_Nucleic_Acids:_A_Structure_for_Deoxyribose_Nucleic_Acid#/media/File:DNA-structure-and-bases.png).)

如果DNA是软件，那么蛋白质就是最重要的硬件。蛋白质是微小的机器，在细胞中几乎完成所有工作。蛋白质也是聚合物，由称为*氨基酸*的重复单元组成。有20种主要氨基酸，它们的物理性质差异很大。有些大，而有些小。有些带有电荷，而有些没有。有些倾向于吸引水，而有些倾向于排斥水。当恰到好处的氨基酸集合以恰到好处的顺序串在一起时，它将自发地折叠成一个三维形状，所有部分都被正确地定位，以使其作为一个机器发挥作用。

DNA的主要功能之一是记录生物体蛋白质的氨基酸序列。它以一种简单直接的方式做到这一点。特定的DNA片段直接对应于特定的蛋白质。每个三个DNA碱基序列（称为*密码子*）对应一个氨基酸。例如，模式AAA表示氨基酸赖氨酸，而模式GCC表示氨基酸丙氨酸。

从DNA到蛋白质涉及另一种分子，RNA，它作为中间表示来携带信息从细胞的一部分到另一部分。RNA是另一种聚合物，化学上与DNA非常相似。它也有四种碱基，可以以任意顺序链接在一起。要创建蛋白质，信息必须被复制两次。首先，DNA序列被*转录*成等效的RNA序列，然后RNA分子被*翻译*成蛋白质分子。携带信息的RNA分子称为*信使RNA*，简称mRNA。

这告诉我们蛋白质是如何制造的，但没有告诉我们*何时*。人类细胞可以制造许多不同的蛋白质。它肯定不会一直生产所有这些蛋白质的副本，对吧？显然必须有某种调节机制来控制何时制造哪些蛋白质。在传统观念中，这是由称为*转录因子（TFs）*的特殊蛋白质完成的。每个TF识别并结合到特定的DNA序列。根据特定的TF和其结合位置，它可以增加或减少附近基因的转录速率。

这提供了一个简单、易于理解的基因组工作方式的图像。DNA的工作是编码蛋白质。DNA的一段（称为*基因*）使用简单、明确定义的密码编码蛋白质。DNA被转录为RNA，它只作为信息载体。然后RNA被转化为蛋白质，蛋白质才是真正的工作。整个过程非常优雅，就像一个有才华的工程师设计的东西。多年来，人们一直相信这种图像基本上是正确的。所以，在我们揭示现实实际上更加混乱和复杂之前，花点时间享受一下吧。

# 现在进入真实世界

现在是时候谈论基因组*真正*的工作方式了。在前一节中描述的图像简单而优雅，但不幸的是它与现实几乎没有联系。本节将快速介绍大量信息，但不用担心记住或理解所有内容。重要的是要对生物体的令人难以置信的复杂性有所感知。我们将在本章的后面回到其中一些主题，并进行更详细的讨论。

让我们从考虑DNA分子（称为*染色体*）开始。在细菌中，DNA存在为简单的自由漂浮分子。但真核生物（包括变形虫、人类和中间所有生物）拥有更大的基因组。为了适应细胞内，每个染色体必须被打包到非常小的空间中。这是通过将其缠绕在称为*组蛋白*的蛋白质周围来实现的。但如果所有DNA都被紧密打包起来，它如何被转录呢？答案当然是不能。在基因可以被转录之前，首先必须解开包含它的DNA片段。细胞如何知道哪些DNA需要解开呢？答案仍然不明确。据信涉及各种类型的组蛋白分子的化学修饰，以及识别特定修饰的蛋白质。显然涉及到一种调节机制，但许多细节仍然未知。我们将很快回到这个主题。

DNA本身可以通过一种称为*甲基化*的过程进行化学修饰。DNA的一段被高度甲基化，就越不可能被转录，因此这是细胞可以用来控制蛋白质产生的另一种调节机制。但它如何控制哪些DNA区域被甲基化呢？这也仍然不明确。

在前一节中，我们说特定的DNA片段对应于特定的蛋白质。这对细菌来说是正确的，但在真核生物中情况更加复杂。在DNA被转录成信使RNA后，该RNA经常被编辑以去除部分并连接（或*剪接*）剩余部分（称为*外显子*）。最终被翻译成蛋白质的RNA序列可能与原始DNA序列不同。此外，许多基因具有多个*剪接变体* - 去除部分以形成最终序列的不同方式。这意味着单个DNA片段实际上可以编码多种不同的蛋白质！

所有这些听起来开始变得非常复杂了吗？好吧，继续阅读，因为我们才刚刚开始！进化选择能够起作用的机制，而不关心它们是否简单或易于理解。这导致了非常复杂的系统，理解它们需要我们面对这种复杂性。

在传统观念中，RNA被视为仅仅是一个信息载体，但即使在基因组学的早期，生物学家们就知道这并不完全正确。将mRNA翻译成蛋白质的工作是由*核糖体*完成的，这是由部分蛋白质和部分RNA组成的复杂分子机器。翻译中的另一个关键角色是由称为*转运RNA*（或简称tRNA）的分子执行的。这些分子定义了“遗传密码”，识别mRNA中的三个碱基的模式，并将正确的氨基酸添加到不断增长的蛋白质中。因此，半个多世纪以来，我们已经知道至少有三种RNA：mRNA，核糖体RNA和tRNA。

但RNA仍然有许多窍门。它是一种令人惊讶地多才多艺的分子。在过去的几十年中，发现了许多其他类型的RNA。以下是一些例子：

+   *微小RNA*（miRNAs）是一种短的RNA片段，它们结合到信使RNA上，阻止其被翻译成蛋白质。这是一种在某些动物，尤其是哺乳动物中非常重要的调节机制。

+   *短干扰RNA*（siRNA）是另一种类型的RNA，它结合到mRNA上并阻止其被翻译。它类似于miRNA，但siRNA是双链的（不像miRNA是单链的），它们的一些功能细节是不同的。我们将在本章后面更详细地讨论siRNA。

+   *核酶*是可以作为酶来催化化学反应的RNA分子。化学是生命细胞中发生的一切的基础，因此催化剂对生命至关重要。通常这项工作由蛋白质完成，但我们现在知道有时也由RNA完成。

+   *核糖开关*是由两部分组成的RNA分子。一部分充当信使RNA，而另一部分能够结合到小分子上。当它结合时，可以启用或阻止mRNA的翻译。这是另一种调节机制，可以根据细胞中特定小分子的浓度来调整蛋白质的产生。

当然，所有这些不同类型的RNA都必须被制造出来，DNA必须包含如何制造它们的说明。因此，DNA不仅仅是一串编码蛋白质序列的字符串。它还包含RNA序列，以及转录因子和其他调节分子的结合位点，以及有关如何剪接信使RNA的说明，以及影响其如何缠绕在组蛋白周围以及哪些基因被转录的各种化学修饰。

现在考虑核糖体将mRNA翻译成蛋白质后会发生什么。一些蛋白质可以自发地折叠成正确的三维形状，但许多其他蛋白质需要其他蛋白质（称为*分子伴侣*）的帮助。在翻译后，蛋白质通常需要额外的化学修饰。然后，成品蛋白质必须被运送到细胞的正确位置以完成其工作，并在不再需要时最终被降解。每个这些过程都受到额外的调节机制的控制，并涉及与许多其他分子的相互作用。

如果这一切听起来令人不知所措，那是因为它确实如此！一个活体生物比人类创造的任何机器都要复杂得多。试图理解它应该让你感到害怕！

但这也是为什么机器学习是如此强大的工具。我们有大量数据，这些数据是由一个复杂且不被充分理解的过程生成的。我们希望发现数据中隐藏的微妙模式。这正是深度学习擅长的问题类型！

事实上，深度学习非常适合这个问题。传统的统计技术很难表示基因组的复杂性。它们通常基于简化的假设。例如，它们寻找变量之间的线性关系，或者试图将一个变量建模为仅取决于少数其他变量。但基因组涉及数百个变量之间的复杂非线性关系：这正是深度神经网络可以有效描述的关系类型。

# 转录因子结合

以将深度学习应用于基因组学为例，让我们考虑预测转录因子结合的问题。回想一下，TF是结合到DNA的蛋白质。当它们结合时，它们会影响附近基因被转录成RNA的概率。但是TF如何知道在哪里结合？像基因组学的许多问题一样，这个问题有一个简单的答案，然后是许多复杂性。

在第一次近似中，每个转录因子都有一个特定的DNA序列，称为其*结合位点基序*，它会与之结合。结合位点基序往往很短，通常为10个碱基或更少。无论TF的基序出现在基因组的哪个位置，TF都会与之结合。

实际上，基序并不完全特异。一个TF可能能够结合许多相似但不完全相同的序列。基序内的一些碱基可能比其他碱基更重要。这通常被建模为*位置权重矩阵*，指定TF对基序内每个位置的每个可能碱基的偏好程度。当然，这假设基序内的每个位置都是独立的，这并不总是正确的。有时，甚至基序的长度也会有所变化。虽然结合主要由基序内的碱基决定，但基序两侧的DNA也可能会产生一些影响。

这只考虑了序列！DNA的其他方面也可能很重要。许多TF受到DNA的物理形状的影响，例如双螺旋的紧密程度。如果DNA被甲基化，那可能会影响TF的结合。请记住，真核生物中的大多数DNA都被紧密包裹在组蛋白周围。TF只能结合到已经展开的部分。

其他分子也发挥着重要作用。TF经常与其他分子相互作用，这些相互作用可能会影响DNA结合。例如，TF可能会与第二个分子结合形成一个复合物，然后该复合物会与TF单独结合到不同的DNA基序。

生物学家花费了数十年来解开这些细节并设计TF结合的模型。让我们看看是否可以使用深度学习直接从数据中学习模型，而不是做这些工作。

## TF结合的卷积模型

对于这个例子，我们将使用一个名为JUND的特定转录因子的实验数据。进行了一个实验来识别人类基因组中它结合的每个位置。为了使事情更容易处理，我们只包括染色体22的数据，这是最小的人类染色体之一。它仍然有超过5000万个碱基，因此我们有足够的数据来处理。整个染色体已经被分成短片段，每个片段长101个碱基，并且每个片段已被标记以指示是否包含JUND结合的位置。我们将尝试训练一个模型，根据每个片段的序列来预测这些标签。

这些序列是用一位热编码表示的。对于每个碱基，我们有四个数字，其中一个设置为1，其他设置为0。哪个数字设置为1表示碱基是A、C、G还是T。

为了处理数据，我们将使用一个卷积神经网络，就像我们在[第3章](ch03.xhtml#machine_learning_with_deepchem)中识别手写数字时所做的那样。实际上，您会发现这两个模型在很大程度上相似。这次我们将使用1D卷积，因为我们处理的是1D数据（DNA序列）而不是2D数据（图像），但模型的基本组件将是相同的：输入，一系列卷积层，一个或多个密集层来计算输出，以及一个交叉熵损失函数。

让我们从创建一个`TensorGraph`并定义输入开始：

```py
model = dc.models.TensorGraph(batch_size=1000)
features = layers.Feature(shape=(None, 101, 4))
labels = layers.Label(shape=(None, 1))
weights = layers.Weights(shape=(None, 1))

```

注意输入的大小。对于每个样本，我们有一个大小为101（碱基数）乘以4（每个碱基的一位热编码）的特征向量。我们还有一个标签的单个数字（0或1，表示是否包含结合位点）和一个权重的单个数字。在这个例子中使用损失函数中的权重是至关重要的，因为数据非常不平衡。不到1%的所有样本包含结合位点。这意味着模型可以通过只为每个样本输出0来轻松获得超过99%的准确率。我们通过给正样本比负样本更高的权重来防止这种情况。

接下来，我们创建一个具有相同参数的三个卷积层的堆叠：

```py
prev = features
for i in range(3):
  prev = layers.Conv1D(filters=15, kernel_size=10,
                       activation=tf.nn.relu, padding='same',
                       in_layers=prev)
  prev = layers.Dropout(dropout_prob=0.5, in_layers=prev)

```

我们指定卷积核的宽度为10，并且每个层应包括15个滤波器（即输出）。第一层以原始特征（每个碱基四个数字）作为输入。它查看连续10个碱基的跨度，因此总共有40个输入值。对于每个跨度，它将这40个值乘以一个卷积核以产生15个输出值。第二层再次查看10个碱基的跨度，但这次的输入是第一层计算的15个值。它为每个碱基计算一组新的15个值，依此类推。

为了防止过拟合，我们在每个卷积层后添加一个dropout层。dropout概率设置为0.5，意味着50%的所有输出值会被随机设置为0。

接下来我们使用一个密集层来计算输出：

```py
logits = layers.Dense(out_channels=1, in_layers=layers.Flatten(prev))
output = layers.Sigmoid(logits)
model.add_output(output)

```

我们希望输出在0到1之间，这样我们可以将其解释为特定样本包含结合位点的概率。密集层可以产生任意值，不限于任何特定范围。因此，我们通过一个逻辑sigmoid函数将其压缩到所需的范围。这个函数的输入通常被称为*对数几率*。这个名称指的是数学对数几率函数，它是逻辑sigmoid的反函数。

最后，我们计算每个样本的交叉熵并乘以权重以获得损失：

```py
loss = layers.SigmoidCrossEntropy(in_layers=[labels, logits])
weighted_loss = layers.WeightedError(in_layers=[loss, weights])
model.set_loss(weighted_loss)

```

请注意，出于数值稳定性的原因，交叉熵层以对数几率作为输入，而不是逻辑sigmoid函数的输出。

现在我们准备训练和评估模型。我们使用ROC AUC作为我们的评估指标。在每10个训练周期之后，我们在训练集和验证集上评估模型：

```py
train = dc.data.DiskDataset('train_dataset')
valid = dc.data.DiskDataset('valid_dataset')
metric = dc.metrics.Metric(dc.metrics.roc_auc_score)
for i in range(20):
  model.fit(train, nb_epoch=10)
  print(model.evaluate(train, [metric]))
  print(model.evaluate(valid, [metric]))

```

结果显示在[图6-2](#evolution_of_roc_auc_during_training_for_the_training)中。验证集性能在50个epochs后达到约0.75的峰值，然后略有下降。训练集性能继续增加，最终在约0.87左右趋于稳定。这告诉我们，超过50个epochs的训练只会导致过拟合，我们应该在那一点停止训练：

![训练集（虚线）和验证集（实线）训练期间ROC AUC分数的演变。](Images/dlls_0602.png)

###### 图6-2。训练集（虚线）和验证集（实线）训练期间ROC AUC分数的演变。

ROC AUC分数为0.75并不算糟糕，但也不是很好。可能我们可以通过改进模型来提高它。我们可以尝试改变许多超参数：卷积层的数量，每层的核宽度，每层的滤波器数量，dropout率等。我们可以尝试许多组合，也许会找到一个性能更好的组合。

但我们也知道，这个模型能够工作的好坏存在根本限制。它只看到DNA序列作为输入，而TF结合还取决于许多其他因素：可访问性、甲基化、形状、其他分子的存在等。任何忽略这些因素的模型在预测准确性方面都会受到限制。所以现在让我们尝试添加第二个输入，看看是否有帮助。

# 染色质可访问性

名称*染色质*指的是构成染色体的一切：DNA、组蛋白和各种其他蛋白质和RNA分子。*染色质可访问性*指的是染色体的每个部分对外部分子的可访问程度。当DNA紧密缠绕在组蛋白周围时，对转录因子和其他分子是不可访问的。它们无法接触到它，DNA实际上是不活跃的。当它从组蛋白中解开时，它再次变得可访问，并恢复其作为细胞机器中心部分的角色。

染色质可访问性既不是均匀的也不是静态的。它在细胞类型和细胞生命周期阶段之间变化。它可以受到环境条件的影响。这是细胞用来调节其基因组活动的工具之一。任何基因都可以通过将其所在染色体区域包装起来而关闭。

可访问性也在DNA对细胞内事件的反应中不断变化。与将可访问性视为二元选择（可访问或不可访问）不同，将其视为连续变量（每个区域可访问的时间比例）更好。

我们在上一节分析的数据来自对一种名为HepG2的细胞的实验。实验确定了基因组中转录因子JUND结合的位置。结果受染色质可访问性的影响。如果HepG2细胞中的某个特定区域几乎总是不可访问，即使DNA序列本来是一个完美的结合位点，实验也很难在那里找到JUND结合。因此，让我们尝试将可访问性纳入我们的模型。

首先让我们加载一些关于可访问性的数据。我们将其保存在一个文本文件中，其中每一行对应于我们数据集中的一个样本（染色体22的101个碱基片段）。一行包含样本ID，后面跟着一个数字，表示该区域在HepG2细胞中通常有多可访问。我们将其加载到一个Python字典中：

```py
span_accessibility = {}
for line in open('accessibility.txt'):
  fields = line.split()
  span_accessibility[fields[0]] = float(fields[1])

```

现在开始构建模型。我们将几乎完全使用与上一节相同的模型，只有两个小改变。首先，我们需要一个第二个特征输入来表示可访问性数值。每个样本都有一个数字：

```py
accessibility = layers.Feature(shape=(None, 1))

```

现在我们需要将可访问性值纳入计算中。我们可以以许多方式做到这一点。在本例中，我们将使用一种特别简单的方法。在前一节中，我们将最后一个卷积层的输出展平，然后将其用作计算输出的密集层的输入。

```py
logits = layers.Dense(out_channels=1, in_layers=layers.Flatten(prev))

```

这次我们将做同样的事情，但也将可访问性附加到卷积的输出中：

```py
prev = layers.Concat([layers.Flatten(prev), accessibility])
logits = layers.Dense(out_channels=1, in_layers=prev)

```

模型就是这样了！现在是训练的时候了。

在这一点上，我们遇到了一个困难：我们的模型有两个不同的“特征”层！到目前为止，我们的模型只有一个“特征”层，一个“标签”层，可能还有一个“权重”层。我们通过调用`fit(dataset)`来训练它们，这会自动将正确的数据连接到每个层：特征的数据集`X`字段，标签的`y`字段，权重的`w`字段。但是当模型具有多个特征集时，这显然行不通。

通过使用DeepChem的更高级功能来处理这种情况。我们可以编写一个Python生成器函数，该函数会迭代批次。每个批次由一个字典表示，其键是输入层，其值是用于这些层的NumPy数组：

```py
def generate_batches(dataset, epochs):
  for epoch in range(epochs):
    for X, y, w, ids in dataset.iterbatches(batch_size=1000,
                                            pad_batches=True):
      yield {
	features: X,
	accessibility: np.array([span_accessibility[id] for id in ids]),
	labels: y,
	weights: w
      }

```

注意数据集如何为我们迭代批次。它为每个批次提供数据，我们可以从中构建模型所需的任何输入。

现在训练和评估过程与以前完全相同。我们使用了接受生成器而不是数据集的方法的替代形式：

```py
for i in range(20):
  model.fit_generator(generate_batches(train, 10))
  print(model.evaluate_generator(generate_batches(train, 1), [metric],
                                 labels=[labels], weights=[weights]))
  print(model.evaluate_generator(generate_batches(valid, 1), [metric],
                                 labels=[labels], weights=[weights]))

```

结果显示在[图6-3](#evolution_of_roc_auc_during_training_for_the_training_set_dashed)中。与忽略染色质可访问性的模型相比，训练集和验证集的分数都有所提高。ROC AUC分数现在达到了训练集的0.91和验证集的0.80。

![在包括染色质可访问性作为输入时，训练集（虚线）和验证集（实线）的ROC AUC分数在训练期间的演变。](Images/dlls_0603.png)

###### 图6-3。在包括染色质可访问性作为输入时，训练集（虚线）和验证集（实线）的ROC AUC分数在训练期间的演变。

# RNA干扰

对于我们的最后一个示例，让我们转向RNA。与DNA类似，这是由称为碱基的四个重复单元组成的聚合物。实际上，四个碱基中的三个与它们的DNA版本几乎相同，只是多了一个氧原子。第四个碱基有些不同。RNA中没有胸腺嘧啶（T），而是有一种称为尿嘧啶（U）的碱基。当DNA序列被转录成RNA时，每个T都会被U替换。

碱基G和C彼此*互补*，即它们有很强的结合倾向。同样，碱基A和T（或U）是互补的。如果你有两条DNA或RNA链，其中一条中的每个碱基与另一条中对应的碱基互补，那么这两条链就会倾向于粘在一起。这个事实在许多生物过程中起着关键作用，包括转录和翻译，以及细胞分裂时的DNA复制。

这也是所谓的*RNA干扰*的核心。这种现象直到1990年代才被发现，这一发现导致了2006年的诺贝尔奖。一小段RNA，其序列与信使RNA的一部分互补，可以结合到该mRNA上。当这种情况发生时，它会“沉默”mRNA，防止其被翻译成蛋白质。执行沉默的分子称为短干扰RNA（siRNA）。

除此之外，这个过程还有更多内容。RNA干扰是一个复杂的生物机制，不仅仅是两个孤立的RNA链碰巧粘在一起的副作用。它始于siRNA结合到一组被称为*RNA诱导沉默复合物*（RISC）的蛋白质。RISC使用siRNA作为模板来搜索细胞中匹配的mRNA并降解它们。这既是调节基因表达的机制，也是对抗病毒的防御。

这也是生物学和医学的强大工具。它让你暂时“关闭”任何你想要的基因。你可以用它来治疗疾病，或者研究当一个基因被禁用时会发生什么。只需识别你想要阻断的mRNA，选择任何短片段，并创建一个具有互补序列的siRNA分子。

当然，事情并不像那么简单。你不能随意选择mRNA的任何片段，因为RNA分子并不只是四个字母的抽象模式。它们是具有独特属性的物理对象，这些属性取决于序列。一些RNA分子比其他的更稳定。一些与它们的互补序列结合得更紧密。一些折叠成形状，使得RISC更难与它们结合。这意味着一些siRNA序列比其他的更有效，如果你想将RNA干扰作为一种工具使用，你需要知道如何选择一个好的！

生物学家已经开发了许多用于选择siRNA序列的经验法则。例如，他们会说，第一个碱基应该是A或G，G和C碱基应该占序列的30%到50%，等等。这些经验法则是有帮助的，但让我们看看是否可以利用机器学习做得更好。

我们将使用一个包含2,431个siRNA分子的库来训练我们的模型，每个分子长21个碱基。每一个都经过实验测试，并标记为0到1之间的值，表示它在沉默目标基因方面的有效性。较小的值表示无效的分子，而较大的值表示更有效的分子。模型以序列作为输入，并尝试预测有效性。

这是构建模型的代码：

```py
model = dc.models.TensorGraph()
features = layers.Feature(shape=(None, 21, 4))
labels = layers.Label(shape=(None, 1))
prev = features
for i in range(2):
  prev = layers.Conv1D(filters=10, kernel_size=10,
                       activation=tf.nn.relu, padding='same',
                       in_layers=prev)
  prev = layers.Dropout(dropout_prob=0.3, in_layers=prev)
output = layers.Dense(out_channels=1, activation_fn=tf.sigmoid,
                      in_layers=layers.Flatten(prev))
model.add_output(output)
loss = layers.ReduceMean(layers.L2Loss(in_layers=[labels, output]))
model.set_loss(loss)

```

这与我们用于TF结合的模型非常相似，只是有一些区别。因为我们使用较短的序列并在较少的数据上进行训练，所以我们减小了模型的大小。只有2个卷积层，每层有10个滤波器，而不是15个。也不需要权重，因为我们希望在优化过程中每个样本都能做出贡献。

我们还使用了不同的损失函数。TF结合的模型是一个分类模型。每个标签要么是0，要么是1，我们试图预测这两个离散值中的哪一个。但这个模型是一个回归模型。标签是连续的数字，模型试图尽可能地匹配它们。因此，我们使用<math><msub><mi>L</mi> <mn>2</mn></msub></math>距离作为我们的损失函数，它试图最小化真实标签和预测标签之间的均方差。

这是训练模型的代码：

```py
train = dc.data.DiskDataset('train_siRNA')
valid = dc.data.DiskDataset('valid_siRNA')
metric = dc.metrics.Metric(dc.metrics.pearsonr, mode='regression')
for i in range(20):
  model.fit(train, nb_epoch=10)
  print(model.evaluate(train, [metric]))
  print(model.evaluate(valid, [metric]))

```

对于TF结合，我们使用ROC AUC作为我们的评估指标，它衡量模型如何将数据分成两类。这对于分类问题是合适的，但对于回归问题来说没有意义，因此我们使用皮尔逊相关系数。这是一个介于-1和1之间的数字，其中0表示模型根本没有提供信息，1表示模型完美地重现了实验数据。

结果显示在[图6-4](#evolution_of_the_pearson_correlation_coefficient_during_training_for_the_training_set_dashed_and_validation_set_solid)中。验证集得分在50个epochs后达到0.65的峰值。训练集得分继续增加，但由于验证集得分没有进一步提高，这只是过拟合。考虑到模型的简单性和有限的训练数据量，相关系数0.65已经相当不错。在更大数据集上训练的更复杂模型稍微更好，但这已经是非常可观的表现了。

![在训练过程中Pearson相关系数的演变，包括训练集（虚线）和验证集（实线）。](Images/dlls_0604.png)

###### 图6-4\. 在训练过程中Pearson相关系数的演变，包括训练集（虚线）和验证集（实线）。

# 结论

基因组是一个极其复杂的机器，有大量的部分共同工作，指导和执行蛋白质和其他分子的制造。深度学习是研究它的强大工具。神经网络可以挑出基因组数据中微妙的模式，提供对基因组功能的洞察，同时也可以对其进行预测。

与生命科学的大多数其他领域相比，基因组学产生了大量的实验数据。例如，单个人类基因组序列包含超过60亿个碱基。传统的统计技术很难在所有这些数据中找到信号。它们经常需要简化假设，这些假设并不能反映基因组调控的复杂性。深度学习非常适合处理这些数据，并推动我们对生命细胞核心功能的理解。

^([1](ch06.xhtml#idm45806168574584-marker)) Huesken, D., J. Lange, C. Mickanin, J. Weiler, F. Asselbergs, J. Warner, B. Meloon, S. Engel, A. Rosenberg, D. Cohen, M. Labow, M. Reinhardt, F. Natt, and J. Hall, “Design of a Genome-Wide siRNA Library Using an Artificial Neural Network.” *Nature Biotechnology* 23:995–1001\. 2005\. *[https://doi.org/10.1038/nbt1118](https://doi.org/10.1038/nbt1118)*.
