["```py\nfrom fastai.text.all import *\n\ndls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test')\n```", "```py\npath = untar_data(URLs.IMDB)\ndls = DataBlock(\n    blocks=(TextBlock.from_folder(path),CategoryBlock),\n    get_y = parent_label,\n    get_items=partial(get_text_files, folders=['train', 'test']),\n    splitter=GrandparentSplitter(valid_name='test')\n).dataloaders(path)\n```", "```py\nfiles = get_text_files(path, folders = ['train', 'test'])\ntxts = L(o.open().read() for o in files[:2000])\n```", "```py\ntok = Tokenizer.from_folder(path)\ntok.setup(txts)\ntoks = txts.map(tok)\ntoks[0]\n```", "```py\n(#374) ['xxbos','xxmaj','well',',','\"','cube','\"','(','1997',')'...]\n```", "```py\nnum = Numericalize()\nnum.setup(toks)\nnums = toks.map(num)\nnums[0][:10]\n```", "```py\ntensor([   2,    8,   76,   10,   23, 3112,   23,   34, 3113,   33])\n```", "```py\nnums_dec = num.decode(nums[0][:10]); nums_dec\n```", "```py\n(#10) ['xxbos','xxmaj','well',',','\"','cube','\"','(','1997',')']\n```", "```py\ntok.decode(nums_dec)\n```", "```py\n'xxbos xxmaj well , \" cube \" ( 1997 )'\n```", "```py\ntok((txts[0], txts[1]))\n```", "```py\n((#374) ['xxbos','xxmaj','well',',','\"','cube','\"','(','1997',')'...],\n (#207)\n > ['xxbos','xxmaj','conrad','xxmaj','hall','went','out','with','a','bang'...])\n```", "```py\ndef f(x:int): return x+1\ntfm = Transform(f)\ntfm(2),tfm(2.0)\n```", "```py\n(3, 2.0)\n```", "```py\n@Transform\ndef f(x:int): return x+1\nf(2),f(2.0)\n```", "```py\n(3, 2.0)\n```", "```py\nclass NormalizeMean(Transform):\n    def setups(self, items): self.mean = sum(items)/len(items)\n    def encodes(self, x): return x-self.mean\n    def decodes(self, x): return x+self.mean\n```", "```py\ntfm = NormalizeMean()\ntfm.setup([1,2,3,4,5])\nstart = 2\ny = tfm(start)\nz = tfm.decode(y)\ntfm.mean,y,z\n```", "```py\n(3.0, -1.0, 2.0)\n```", "```py\ntfms = Pipeline([tok, num])\nt = tfms(txts[0]); t[:20]\n```", "```py\ntensor([   2,    8,   76,   10,   23, 3112,   23,   34, 3113,   33,   10,    8,\n > 4477,   22,   88,   32,   10,   27,   42,   14])\n```", "```py\ntfms.decode(t)[:100]\n```", "```py\n'xxbos xxmaj well , \" cube \" ( 1997 ) , xxmaj vincenzo \\'s first movie , was one\n > of the most interesti'\n```", "```py\ntls = TfmdLists(files, [Tokenizer.from_folder(path), Numericalize])\n```", "```py\nt = tls[0]; t[:20]\n```", "```py\ntensor([    2,     8,    91,    11,    22,  5793,    22,    37,  4910,    34,\n > 11,     8, 13042,    23,   107,    30,    11,    25,    44,    14])\n```", "```py\ntls.decode(t)[:100]\n```", "```py\n'xxbos xxmaj well , \" cube \" ( 1997 ) , xxmaj vincenzo \\'s first movie , was one\n > of the most interesti'\n```", "```py\ntls.show(t)\n```", "```py\nxxbos xxmaj well , \" cube \" ( 1997 ) , xxmaj vincenzo 's first movie , was one\n > of the most interesting and tricky ideas that xxmaj i 've ever seen when\n > talking about movies . xxmaj they had just one scenery , a bunch of actors\n > and a plot . xxmaj so , what made it so special were all the effective\n > direction , great dialogs and a bizarre condition that characters had to deal\n > like rats in a labyrinth . xxmaj his second movie , \" cypher \" ( 2002 ) , was\n > all about its story , but it was n't so good as \" cube \" but here are the\n > characters being tested like rats again .\n\n \" nothing \" is something very interesting and gets xxmaj vincenzo coming back\n > to his ' cube days ' , locking the characters once again in a very different\n > space with no time once more playing with the characters like playing with\n > rats in an experience room . xxmaj but instead of a thriller sci - fi ( even\n > some of the promotional teasers and trailers erroneous seemed like that ) , \"\n > nothing \" is a loose and light comedy that for sure can be called a modern\n > satire about our society and also about the intolerant world we 're living .\n > xxmaj once again xxmaj xxunk amaze us with a great idea into a so small kind\n > of thing . 2 actors and a blinding white scenario , that 's all you got most\n > part of time and you do n't need more than that . xxmaj while \" cube \" is a\n > claustrophobic experience and \" cypher \" confusing , \" nothing \" is\n > completely the opposite but at the same time also desperate .\n\n xxmaj this movie proves once again that a smart idea means much more than just\n > a millionaire budget . xxmaj of course that the movie fails sometimes , but\n > its prime idea means a lot and offsets any flaws . xxmaj there 's nothing\n > more to be said about this movie because everything is a brilliant surprise\n > and a totally different experience that i had in movies since \" cube \" .\n```", "```py\ncut = int(len(files)*0.8)\nsplits = [list(range(cut)), list(range(cut,len(files)))]\ntls = TfmdLists(files, [Tokenizer.from_folder(path), Numericalize],\n                splits=splits)\n```", "```py\ntls.valid[0][:20]\n```", "```py\ntensor([    2,     8,    20,    30,    87,   510,  1570,    12,   408,   379,\n > 4196,    10,     8,    20,    30,    16,    13, 12216,   202,   509])\n```", "```py\nlbls = files.map(parent_label)\nlbls\n```", "```py\n(#50000) ['pos','pos','pos','pos','pos','pos','pos','pos','pos','pos'...]\n```", "```py\ncat = Categorize()\ncat.setup(lbls)\ncat.vocab, cat(lbls[0])\n```", "```py\n((#2) ['neg','pos'], TensorCategory(1))\n```", "```py\ntls_y = TfmdLists(files, [parent_label, Categorize()])\ntls_y[0]\n```", "```py\nTensorCategory(1)\n```", "```py\nx_tfms = [Tokenizer.from_folder(path), Numericalize]\ny_tfms = [parent_label, Categorize()]\ndsets = Datasets(files, [x_tfms, y_tfms])\nx,y = dsets[0]\nx[:20],y\n```", "```py\nx_tfms = [Tokenizer.from_folder(path), Numericalize]\ny_tfms = [parent_label, Categorize()]\ndsets = Datasets(files, [x_tfms, y_tfms], splits=splits)\nx,y = dsets.valid[0]\nx[:20],y\n```", "```py\n(tensor([    2,     8,    20,    30,    87,   510,  1570,    12,   408,   379,\n > 4196,    10,     8,    20,    30,    16,    13, 12216,   202,   509]),\n TensorCategory(0))\n```", "```py\nt = dsets.valid[0]\ndsets.decode(t)\n```", "```py\n('xxbos xxmaj this movie had horrible lighting and terrible camera movements .\n > xxmaj this movie is a jumpy horror flick with no meaning at all . xxmaj the\n > slashes are totally fake looking . xxmaj it looks like some 17 year - old\n > idiot wrote this movie and a 10 year old kid shot it . xxmaj with the worst\n > acting you can ever find . xxmaj people are tired of knives . xxmaj at least\n > move on to guns or fire . xxmaj it has almost exact lines from \" when a xxmaj\n > stranger xxmaj calls \" . xxmaj with gruesome killings , only crazy people\n > would enjoy this movie . xxmaj it is obvious the writer does n\\'t have kids\n > or even care for them . i mean at show some mercy . xxmaj just to sum it up ,\n > this movie is a \" b \" movie and it sucked . xxmaj just for your own sake , do\n > n\\'t even think about wasting your time watching this crappy movie .',\n 'neg')\n```", "```py\ndls = dsets.dataloaders(bs=64, before_batch=pad_input)\n```", "```py\ntfms = [[Tokenizer.from_folder(path), Numericalize], [parent_label, Categorize]]\nfiles = get_text_files(path, folders = ['train', 'test'])\nsplits = GrandparentSplitter(valid_name='test')(files)\ndsets = Datasets(files, tfms, splits=splits)\ndls = dsets.dataloaders(dl_type=SortedDL, before_batch=pad_input)\n```", "```py\npath = untar_data(URLs.IMDB)\ndls = DataBlock(\n    blocks=(TextBlock.from_folder(path),CategoryBlock),\n    get_y = parent_label,\n    get_items=partial(get_text_files, folders=['train', 'test']),\n    splitter=GrandparentSplitter(valid_name='test')\n).dataloaders(path)\n```", "```py\nfrom fastai.vision.all import *\npath = untar_data(URLs.PETS)\nfiles = get_image_files(path/\"images\")\n```", "```py\nclass SiameseImage(Tuple):\n    def show(self, ctx=None, **kwargs):\n        img1,img2,same_breed = self\n        if not isinstance(img1, Tensor):\n            if img2.size != img1.size: img2 = img2.resize(img1.size)\n            t1,t2 = tensor(img1),tensor(img2)\n            t1,t2 = t1.permute(2,0,1),t2.permute(2,0,1)\n        else: t1,t2 = img1,img2\n        line = t1.new_zeros(t1.shape[0], t1.shape[1], 10)\n        return show_image(torch.cat([t1,line,t2], dim=2),\n                          title=same_breed, ctx=ctx)\n```", "```py\nimg = PILImage.create(files[0])\ns = SiameseImage(img, img, True)\ns.show();\n```", "```py\nimg1 = PILImage.create(files[1])\ns1 = SiameseImage(img, img1, False)\ns1.show();\n```", "```py\ns2 = Resize(224)(s1)\ns2.show();\n```", "```py\ndef label_func(fname):\n    return re.match(r'^(.*)_\\d+.jpg$', fname.name).groups()[0]\n```", "```py\nclass SiameseTransform(Transform):\n    def __init__(self, files, label_func, splits):\n        self.labels = files.map(label_func).unique()\n        self.lbl2files = {l: L(f for f in files if label_func(f) == l)\n                          for l in self.labels}\n        self.label_func = label_func\n        self.valid = {f: self._draw(f) for f in files[splits[1]]}\n\n    def encodes(self, f):\n        f2,t = self.valid.get(f, self._draw(f))\n        img1,img2 = PILImage.create(f),PILImage.create(f2)\n        return SiameseImage(img1, img2, t)\n\n    def _draw(self, f):\n        same = random.random() < 0.5\n        cls = self.label_func(f)\n        if not same:\n            cls = random.choice(L(l for l in self.labels if l != cls))\n        return random.choice(self.lbl2files[cls]),same\n```", "```py\nsplits = RandomSplitter()(files)\ntfm = SiameseTransform(files, label_func, splits)\ntfm(files[0]).show();\n```", "```py\ntls = TfmdLists(files, tfm, splits=splits)\nshow_at(tls.valid, 0);\n```", "```py\ndls = tls.dataloaders(after_item=[Resize(224), ToTensor],\n    after_batch=[IntToFloatTensor, Normalize.from_stats(*imagenet_stats)])\n```"]