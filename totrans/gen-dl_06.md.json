["```py\nfrom tensorflow.keras import datasets\n(x_train,y_train), (x_test,y_test) = datasets.fashion_mnist.load_data()\n```", "```py\ndef preprocess(imgs):\n    imgs = imgs.astype(\"float32\") / 255.0\n    imgs = np.pad(imgs, ((0, 0), (2, 2), (2, 2)), constant_values=0.0)\n    imgs = np.expand_dims(imgs, -1)\n    return imgs\n\nx_train = preprocess(x_train)\nx_test = preprocess(x_test)\n```", "```py\nencoder_input = layers.Input(\n    shape=(32, 32, 1), name = \"encoder_input\"\n) ![1](Images/1.png)\nx = layers.Conv2D(32, (3, 3), strides = 2, activation = 'relu', padding=\"same\")(\n    encoder_input\n) ![2](Images/2.png)\nx = layers.Conv2D(64, (3, 3), strides = 2, activation = 'relu', padding=\"same\")(x)\nx = layers.Conv2D(128, (3, 3), strides = 2, activation = 'relu', padding=\"same\")(x)\nshape_before_flattening = K.int_shape(x)[1:]\n\nx = layers.Flatten()(x) ![3](Images/3.png)\nencoder_output = layers.Dense(2, name=\"encoder_output\")(x) ![4](Images/4.png)\n\nencoder = models.Model(encoder_input, encoder_output) ![5](Images/5.png)\n```", "```py\ndecoder_input = layers.Input(shape=(2,), name=\"decoder_input\") ![1](Images/1.png)\nx = layers.Dense(np.prod(shape_before_flattening))(decoder_input) ![2](Images/2.png)\nx = layers.Reshape(shape_before_flattening)(x) ![3](Images/3.png)\nx = layers.Conv2DTranspose(\n    128, (3, 3), strides=2, activation = 'relu', padding=\"same\"\n)(x) ![4](Images/4.png)\nx = layers.Conv2DTranspose(\n    64, (3, 3), strides=2, activation = 'relu', padding=\"same\"\n)(x)\nx = layers.Conv2DTranspose(\n    32, (3, 3), strides=2, activation = 'relu', padding=\"same\"\n)(x)\ndecoder_output = layers.Conv2D(\n    1,\n    (3, 3),\n    strides = 1,\n    activation=\"sigmoid\",\n    padding=\"same\",\n    name=\"decoder_output\"\n)(x)\n\ndecoder = models.Model(decoder_input, decoder_output) ![5](Images/5.png)\n```", "```py\nautoencoder = Model(encoder_input, decoder(encoder_output)) ![1](Images/1.png)\n```", "```py\n# Compile the autoencoder\nautoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n```", "```py\nautoencoder.fit(\n    x_train,\n    x_train,\n    epochs=5,\n    batch_size=100,\n    shuffle=True,\n    validation_data=(x_test, x_test),\n)\n```", "```py\nexample_images = x_test[:5000]\npredictions = autoencoder.predict(example_images)\n```", "```py\nembeddings = encoder.predict(example_images)\n\nplt.figure(figsize=(8, 8))\nplt.scatter(embeddings[:, 0], embeddings[:, 1], c=\"black\", alpha=0.5, s=3)\nplt.show()\n```", "```py\nmins, maxs = np.min(embeddings, axis=0), np.max(embeddings, axis=0)\nsample = np.random.uniform(mins, maxs, size=(18, 2))\nreconstructions = decoder.predict(sample)\n```", "```py\nz = z_mean + z_sigma * epsilon\n```", "```py\nz_sigma = exp(z_log_var * 0.5)\nepsilon ~ N(0,I)\n```", "```py\nclass Sampling(layers.Layer): ![1](Images/1.png)\n    def call(self, inputs):\n        z_mean, z_log_var = inputs\n        batch = tf.shape(z_mean)[0]\n        dim = tf.shape(z_mean)[1]\n        epsilon = K.random_normal(shape=(batch, dim))\n        return z_mean + tf.exp(0.5 * z_log_var) * epsilon ![2](Images/2.png)\n```", "```py\nencoder_input = layers.Input(\n    shape=(32, 32, 1), name=\"encoder_input\"\n)\nx = layers.Conv2D(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(\n    encoder_input\n)\nx = layers.Conv2D(64, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\nx = layers.Conv2D(128, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\nshape_before_flattening = K.int_shape(x)[1:]\n\nx = layers.Flatten()(x)\nz_mean = layers.Dense(2, name=\"z_mean\")(x) ![1](Images/1.png)\nz_log_var = layers.Dense(2, name=\"z_log_var\")(x)\nz = Sampling()([z_mean, z_log_var]) ![2](Images/2.png)\n\nencoder = models.Model(encoder_input, [z_mean, z_log_var, z], name=\"encoder\") ![3](Images/3.png)\n```", "```py\nkl_loss = -0.5 * sum(1 + z_log_var - z_mean ^ 2 - exp(z_log_var))\n```", "```py\nclass VAE(models.Model):\n    def __init__(self, encoder, decoder, **kwargs):\n        super(VAE, self).__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n        self.total_loss_tracker = metrics.Mean(name=\"total_loss\")\n        self.reconstruction_loss_tracker = metrics.Mean(\n            name=\"reconstruction_loss\"\n        )\n        self.kl_loss_tracker = metrics.Mean(name=\"kl_loss\")\n\n    @property\n    def metrics(self):\n        return [\n            self.total_loss_tracker,\n            self.reconstruction_loss_tracker,\n            self.kl_loss_tracker,\n        ]\n\n    def call(self, inputs): ![1](Images/1.png)\n        z_mean, z_log_var, z = encoder(inputs)\n        reconstruction = decoder(z)\n        return z_mean, z_log_var, reconstruction\n\n    def train_step(self, data): ![2](Images/2.png)\n        with tf.GradientTape() as tape:\n            z_mean, z_log_var, reconstruction = self(data)\n            reconstruction_loss = tf.reduce_mean(\n                500\n                * losses.binary_crossentropy(\n                    data, reconstruction, axis=(1, 2, 3)\n                )\n            ) ![3](Images/3.png)\n            kl_loss = tf.reduce_mean(\n                tf.reduce_sum(\n                    -0.5\n                    * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)),\n                    axis = 1,\n                )\n            )\n            total_loss = reconstruction_loss + kl_loss ![4](Images/4.png)\n\n        grads = tape.gradient(total_loss, self.trainable_weights)\n        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n\n        self.total_loss_tracker.update_state(total_loss)\n        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n        self.kl_loss_tracker.update_state(kl_loss)\n\n        return {m.name: m.result() for m in self.metrics}\n\nvae = VAE(encoder, decoder)\nvae.compile(optimizer=\"adam\")\nvae.fit(\n    train,\n    epochs=5,\n    batch_size=100\n)\n```", "```py\nbash scripts/download_kaggle_data.sh jessicali9530 celeba-dataset\n```", "```py\ntrain_data = utils.image_dataset_from_directory(\n    \"/app/data/celeba-dataset/img_align_celeba/img_align_celeba\",\n    labels=None,\n    color_mode=\"rgb\",\n    image_size=(64, 64),\n    batch_size=128,\n    shuffle=True,\n    seed=42,\n    interpolation=\"bilinear\",\n)\n```", "```py\ndef preprocess(img):\n    img = tf.cast(img, \"float32\") / 255.0\n    return img\n\ntrain = train_data.map(lambda x: preprocess(x))\n```", "```py\ngrid_width, grid_height = (10,3)\nz_sample = np.random.normal(size=(grid_width * grid_height, 200)) ![1](Images/1.png)\n\nreconstructions = decoder.predict(z_sample) ![2](Images/2.png)\n\nfig = plt.figure(figsize=(18, 5))\nfig.subplots_adjust(hspace=0.4, wspace=0.4)\nfor i in range(grid_width * grid_height):\n    ax = fig.add_subplot(grid_height, grid_width, i + 1)\n    ax.axis(\"off\")\n    ax.imshow(reconstructions[i, :, :]) ![3](Images/3.png)\n```", "```py\nz_new = z + alpha * feature_vector\n```", "```py\nz_new = z_A * (1- alpha) + z_B * alpha\n```"]