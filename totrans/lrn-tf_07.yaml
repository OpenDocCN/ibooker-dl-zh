- en: Chapter 7\. TensorFlow Abstractions and Simplifications
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章 TensorFlow抽象和简化
- en: The aim of this chapter is to get you familiarized with important practical
    extensions to TensorFlow. We start by describing what abstractions are and why
    they are useful to us, followed by a brief review of some of the popular TensorFlow
    abstraction libraries. We then go into two of these libraries in more depth, demonstrating
    some of their core functionalities along with some examples.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目的是让您熟悉TensorFlow的重要实用扩展。我们首先描述抽象是什么以及为什么它们对我们有用，然后简要回顾一些流行的TensorFlow抽象库。然后我们更深入地研究其中两个库，演示一些它们的核心功能以及一些示例。
- en: Chapter Overview
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 章节概述
- en: As most readers probably know, the term *abstraction* in the context of programming
    refers to a layer of code “on top” of existing code that performs purpose-driven
    generalizations of the original code. Abstractions are formed by grouping and
    wrapping pieces of code that are related to some higher-order functionality in
    a way that conveniently reframes them together. The result is simplified code
    that is easier to write, read, and debug, and generally easier and faster to work
    with. In many cases TensorFlow abstractions not only make the code cleaner, but
    can also drastically reduce code length and as a result significantly cut development
    time.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 正如大多数读者可能知道的那样，在编程的上下文中，术语*抽象*指的是一层代码，“在”现有代码之上执行原始代码的目的驱动泛化的代码。抽象是通过将与某些高阶功能相关的代码片段分组和包装在一起的方式形成的，以便方便地将它们重新框架在一起。结果是简化的代码，更容易编写、阅读和调试，通常更容易和更快地使用。在许多情况下，TensorFlow的抽象不仅使代码更清晰，还可以显著减少代码长度，从而显著缩短开发时间。
- en: 'To get us going, let’s illustrate this basic notion in the context of TensorFlow,
    and take another look at some code for building a CNN like we did in [Chapter 4](ch04.html#convolutional_neural_networks):'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让我们开始，让我们在TensorFlow的上下文中说明这个基本概念，并再次查看一些构建CNN的代码，就像我们在[第4章](ch04.html#convolutional_neural_networks)中所做的那样：
- en: '[PRE0]'
  id: totrans-5
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In native TensorFlow, in order to create a convolutional layer, we have to define
    and initialize its weights and biases according to the shapes of the input and
    the desired output, apply the convolution operation with defined strides and padding,
    and finally add the activation function operation. It’s easy to either accidentally
    forget one of these fundamental components or get it wrong. Also, repeating this
    process multiple times can be somewhat laborious and feels as if it could be done
    more efficiently.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在原生TensorFlow中，为了创建一个卷积层，我们必须根据输入和期望输出的形状定义和初始化其权重和偏置，应用具有定义步幅和填充的卷积操作，最后添加激活函数操作。很容易忘记其中一个基本组件或出错。此外，多次重复此过程可能有些繁琐，感觉可以更有效地完成。
- en: 'In the preceding code example we created our own little abstraction by using
    functions that eliminate some of the redundancies in this process. Let’s compare
    the readability of that code with another version of it that does exactly the
    same, but without using any of the functions:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码示例中，我们通过使用消除这个过程中一些冗余的函数来创建了自己的小抽象。让我们将该代码的可读性与另一个版本进行比较，该版本完全相同，但没有使用任何函数：
- en: '[PRE1]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Even with just three layers, the resulting code looks pretty messy and confusing.
    Clearly, as we progress to larger and more advanced networks, code such as this
    would be hard to manage and pass around.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 即使只有三层，结果代码看起来也相当混乱和令人困惑。显然，随着我们进展到更大更先进的网络，像这样的代码将很难管理和传递。
- en: 'Beyond the more typical medium-sized batching of code, long and complex code
    is often “wrapped up” for us in abstraction libraries. This is particularly effective
    in relatively simple models where very little customization is ever required.
    As a preview to what will follow in the next section, you can already see how
    in `contrib.learn`, one of the abstractions available for TensorFlow, the core
    of defining and training a linear regression model similar to the one at the end
    of [Chapter 3](ch03.html#understanding_tensorflow_basics) could be done in just
    two lines:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 除了更典型的中等大小的代码批处理外，长而复杂的代码通常会在抽象库中为我们“包装起来”。这在相对简单的模型中特别有效，几乎不需要任何定制。作为下一节内容的预览，您已经可以看到在`contrib.learn`中，一个适用于TensorFlow的可用抽象之一，定义和训练线性回归模型的核心，类似于[第3章](ch03.html#understanding_tensorflow_basics)末尾的模型，只需两行代码即可完成：
- en: '[PRE2]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: High-Level Survey
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高级调查
- en: 'More than a few great TensorFlow open source extensions are available at the
    time of writing this book. Among the popular ones are:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本书时，有不少出色的TensorFlow开源扩展可用。其中一些流行的扩展包括：
- en: '`tf.contrib.learn`'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tf.contrib.learn`'
- en: TFLearn
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TFLearn
- en: TF-Slim
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TF-Slim
- en: Keras
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keras
- en: While TFLearn needs to be installed, `contrib.learn` and TF-Slim (now `tf.contrib.slim`)
    are merged with TensorFlow and therefore require no installation. In 2017 Keras
    gained official Google support, and it has also been moved into `tf.contrib` as
    of version 1.1 (`tf.contrib.keras`). The name *contrib* refers to the fact that
    code in this library is “contributed” and still requires testing to see if it
    receives broad acceptance. Therefore, it could still change, and is yet to be
    part of the core TensorFlow.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然需要安装TFLearn，但`contrib.learn`和TF-Slim（现在是`tf.contrib.slim`）已与TensorFlow合并，因此无需安装。2017年，Keras获得了官方的Google支持，并且已经移入`tf.contrib`作为1.1版本（`tf.contrib.keras`）。名称*contrib*指的是该库中的代码是“贡献的”，仍然需要测试以查看是否得到广泛接受。因此，它仍可能发生变化，并且尚未成为核心TensorFlow的一部分。
- en: '`contrib.learn` started as an independent simplified interface for TensorFlow
    and was initially called *Scikit Flow*, with the intention of making the creation
    of complex networks with TensorFlow more accessible for those who are transitioning
    from the `scikit-learn` world of “one-liner” machine learning. As is often the
    case, it was later merged to TensorFlow and is now regarded as its *Learn module*,
    with extensive documentation and examples that are available on the official TensorFlow
    website.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '`contrib.learn`最初是作为TensorFlow的独立简化接口而创建的，最初被称为*Scikit Flow*，旨在使那些从“一行代码”机器学习的`scikit-learn`世界过渡的人更容易创建复杂的网络。通常情况下，它后来被合并到TensorFlow中，现在被视为其*Learn模块*，具有广泛的文档和示例，可在官方TensorFlow网站上找到。'
- en: Like other libraries, the main goal of `contrib.learn` is to make it easy to
    configure, train, and evaluate our learning models. For very simple models, you
    can use out-of-the-box implementations to train with just a few lines of code.
    Another great advantage of `contrib.learn`, as we will see shortly, is functionality
    with which data features can be handled very conveniently.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他库一样，`contrib.learn`的主要目标是使配置、训练和评估我们的学习模型变得简单。对于非常简单的模型，您可以使用现成的实现来训练，只需几行代码。正如我们很快将看到的，`contrib.learn`的另一个巨大优势是功能，可以非常方便地处理数据特征。
- en: While `contrib.learn` is more transparent and low-level, the other three extensions
    are a bit cleaner and more abstract, and each has its own specialties and little
    advantages that might come in handy depending on the needs of the user.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然`contrib.learn`更加透明和低级，其他三个扩展更加清晰和抽象，每个都有自己的特长和小优势，根据用户的需求可能会很有用。
- en: TFLearn and Keras are full of functionality and have many of the elements needed
    for various types of state-of-the-art modeling. Unlike all the other libraries,
    which were created to communicate solely with TensorFlow, Keras supports both
    TensorFlow and Theano (a popular library for deep learning).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: TFLearn和Keras充满了功能，并且具有许多各种类型的最新建模所需的元素。与所有其他库不同的是，这些库是专门为与TensorFlow通信而创建的，而Keras支持TensorFlow和Theano（一种流行的深度学习库）。
- en: TF-Slim was created mainly for designing complex convolutional nets with ease
    and has a wide variety of pretrained models available, relieving us from the expensive
    process of having to train them ourselves.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: TF-Slim主要用于轻松设计复杂的卷积网络，并且有各种预训练模型可用，使我们免于自己训练这些昂贵的过程。
- en: These libraries are very dynamic and are constantly changing, with the developers
    adding new models and functionalities, and occasionally modifying their syntax.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这些库非常动态，不断变化，开发人员添加新模型和功能，并偶尔修改其语法。
- en: Theano
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Theano
- en: '*Theano* is a Python library that allows you to manipulate symbolic mathematical
    expressions that involve tensor arrays in an efficient way, and as such it can
    serve as a deep learning framework, competing with TensorFlow. Theano has been
    around longer, and therefore is a bit more mature than TensorFlow, which is still
    changing and evolving but is rapidly becoming the leader of the pack (it is widely
    considered by many to already be the leading library, with many advantages over
    other frameworks).'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '*Theano*是一个Python库，允许您以高效的方式操作涉及张量数组的符号数学表达式，因此它可以作为一个深度学习框架，与TensorFlow竞争。Theano存在的时间更长，因此比TensorFlow更成熟一些，后者仍在不断变化和发展，但正在迅速成为领头羊（许多人普遍认为它已经是领先的库，具有许多优势，超过其他框架）。'
- en: In the following sections we demonstrate how to use these extensions, alongside
    some examples. We begin by focusing on `contrib.learn`, demonstrating how easily
    it lets us train and run simple regression and classification models. Next we
    introduce TFLearn and revisit the more advanced models introduced in the previous
    chapters—CNN and RNN. We then give a short introduction to autoencoders and demonstrate
    how to create one with Keras. Finally, we close this chapter with brief coverage
    of TF-Slim and show how to classify images using a loaded pretrained state-of-the-art
    CNN model.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们演示如何使用这些扩展，以及一些示例。我们首先关注`contrib.learn`，演示它如何轻松让我们训练和运行简单的回归和分类模型。接下来我们介绍TFLearn，并重新访问前几章介绍的更高级模型——CNN和RNN。然后我们简要介绍自编码器，并演示如何使用Keras创建一个。最后，我们结束本章，简要介绍TF-Slim，并展示如何使用加载的预训练最先进的CNN模型对图像进行分类。
- en: contrib.learn
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: contrib.learn
- en: 'Using `contrib.learn` doesn’t require any installation since it’s been merged
    with TensorFlow:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`contrib.learn`不需要任何安装，因为它已经与TensorFlow合并：
- en: '[PRE3]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We start with `contrib.learn`’s out-of-the-box *estimators* (a fancy name for
    models), which we can train in a quick and efficient manner. These predefined
    estimators include simple linear and logistic regression models, a simple linear
    classifier, and a basic deep neural network. [Table 7-1](#tble0701) lists some
    of the popular estimators we can use.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从`contrib.learn`的现成*评估器*（模型的花哨名称）开始，可以快速高效地训练。这些预定义的评估器包括简单的线性和逻辑回归模型，简单的线性分类器和基本的深度神经网络。[表7-1](#tble0701)列出了我们可以使用的一些流行的评估器。
- en: Table 7-1\. Popular built-in contrib.learn estimators
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 表7-1\. 流行的内置contrib.learn评估器
- en: '| Estimator | Description |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 评估器 | 描述 |'
- en: '| --- | --- |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `LinearRegressor()` | Linear regression model to predict label value given
    observation of feature values. |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| `LinearRegressor()` | 线性回归模型，用于根据特征值的观察来预测标签值。 |'
- en: '| `LogisticRegressor()` | Logistic regression estimator for binary classification.
    |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| `LogisticRegressor()` | 用于二元分类的逻辑回归评估器。 |'
- en: '| `LinearClassifier()` | Linear model to classify instances into one of multiple
    possible classes. When the number of possible classes is 2, this is binary classification.
    |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| `LinearClassifier()` | 线性模型，将实例分类为多个可能的类别之一。当可能的类别数为2时，这是二元分类。 |'
- en: '| `DNNRegressor()` | A regressor for TensorFlow deep neural network (DNN) models.
    |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| `DNNRegressor()` | 用于TensorFlow深度神经网络（DNN）模型的回归器。 |'
- en: '| `DNNClassifier()` | A classifier for TensorFlow DNN models. |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| `DNNClassifier()` | 用于TensorFlow DNN模型的分类器。 |'
- en: 'Of course, we would also like to use more-advanced and customized models, and
    for that `contrib.learn` lets us conveniently wrap our own homemade estimators,
    a feature that will be covered as we go along. Once we have an estimator ready
    for deployment, whether it was made for us or we made it ourselves, the steps
    are pretty much the same:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，我们也希望使用更先进和定制的模型，为此`contrib.learn`让我们方便地包装我们自己制作的估计器，这是我们将在接下来讨论的功能之一。一旦我们准备好部署一个估计器，无论是为我们制作还是我们自己制作的，步骤基本相同：
- en: 'We *instantiate* the estimator class to create our model:'
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们*实例化*评估器类来创建我们的模型：
- en: '[PRE4]'
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Then we *fit* it using our training data:'
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后我们使用我们的训练数据*拟合*它：
- en: '[PRE5]'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'We *evaluate* the model to see how well it does on some given dataset:'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们*评估*模型，看它在某个给定数据集上的表现如何：
- en: '[PRE6]'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Finally, we use our fitted model to *predict* outcomes, usually for new data:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们使用我们拟合的模型来*预测*结果，通常是针对新数据：
- en: '[PRE7]'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: These four fundamental stages are also found in other extensions.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这四个基本阶段也存在于其他扩展中。
- en: '`contrib` offers many other functionalities and features; in particular, `contrib.learn`
    has a very neat way to treat our input data, which will be the focus of the next
    subsection, where we discuss linear models.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '`contrib`提供许多其他功能和特性；特别是，`contrib.learn`有一种非常巧妙的方式来处理我们的输入数据，这将是下一小节的重点，我们将在其中讨论线性模型。'
- en: Linear Regression
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 线性回归
- en: 'We start our `contrib.learn` engagement with one of its strongest features:
    linear models. We say that a model is *linear* whenever it is defined by a function
    of a weighted sum of the features, or more formally *f*(*w[1]x[1]* + *w[2]x[2]*
    +...+ *w[n]x[n]*), where *f* could be any sort of function, like the identity
    function (as in linear regression) or a logistic function (as in logistic regression).
    Although limited in their expressive power, linear models have lots of advantages,
    such as clear interpretability, optimization speed, and simplicity.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从`contrib.learn`的一个最强大的功能开始，即线性模型。我们说一个模型是*线性*的，每当它由特征的加权和的函数定义时，或更正式地*f*(*w[1]x[1]*
    + *w[2]x[2]* +...+ *w[n]x[n]*)，其中*f*可以是任何类型的函数，如恒等函数（如线性回归中）或逻辑函数（如逻辑回归中）。尽管在表达能力上有限，线性模型具有许多优点，如清晰的可解释性、优化速度和简单性。
- en: In [Chapter 3](ch03.html#understanding_tensorflow_basics) we created our own
    linear regression model using native TensorFlow by first creating a graph with
    placeholders for the input and target data, Variables for the set of parameters, a
    loss function, and an optimizer. After the model was defined, we ran the session
    and obtained results.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第3章](ch03.html#understanding_tensorflow_basics)中，我们使用原生TensorFlow创建了自己的线性回归模型，首先创建了一个包含输入和目标数据占位符的图形，一组参数的变量，损失函数和优化器。在定义了模型之后，我们运行了会话并获得了结果。
- en: 'In the following section we first repeat this full process, and then show how
    drastically easier it is to do with `contrib.learn`. For this example we use the
    Boston Housing dataset, available to download using the [`sklearn` library](http://bit.ly/2sXIfrX?). The
    Boston Housing dataset is a relatively small dataset (506 samples), containing
    information concerning housing in the area of Boston, Massachusetts. There are
    13 predictors in this dataset:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，我们首先重复这个完整的过程，然后展示如何使用`contrib.learn`来做到这一点要容易得多。在这个例子中，我们使用波士顿房屋数据集，可以使用[`sklearn`库](http://bit.ly/2sXIfrX?)下载。波士顿房屋数据集是一个相对较小的数据集（506个样本），包含有关马萨诸塞州波士顿地区住房的信息。这个数据集中有13个预测变量：
- en: 'CRIM: per capita crime rate by town'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CRIM：按城镇人均犯罪率
- en: 'ZN: proportion of residential land zoned for lots over 25,000 sq.ft.'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: ZN：用于超过25,000平方英尺地块的住宅用地比例
- en: 'INDUS: proportion of nonretail business acres per town'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: INDUS：每个城镇非零售业务面积的比例
- en: 'CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: CHAS：查尔斯河虚拟变量（如果地块边界河流则为1；否则为0）
- en: 'NOX: nitric oxide concentration (parts per 10 million)'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: NOX：一氧化氮浓度（每千万份之）
- en: 'RM: average number of rooms per dwelling'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: RM：每个住宅的平均房间数
- en: 'AGE: proportion of owner-occupied units built prior to 1940'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: AGE：1940年之前建造的自住单位比例
- en: 'DIS: weighted distances to five Boston employment centers'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: DIS：到波士顿五个就业中心的加权距离
- en: 'RAD: index of accessibility to radial highways'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: RAD：到径向高速公路的可达性指数
- en: 'TAX: full-value property tax rate per $10,000'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TAX：每1万美元的全额财产税率
- en: 'PTRATIO: pupil–teacher ratio by town'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PTRATIO：按城镇的师生比
- en: 'B: 1000(Bk – 0.63)^2, where Bk is the proportion of blacks by town'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: B：1000(Bk - 0.63)^2，其中Bk是按城镇划分的黑人比例
- en: 'LSTAT: % lower status of the population'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LSTAT：人口的较低地位%
- en: The target variable is the median value of owner-occupied homes in thousands
    of dollars. In this example we try to predict the target variable by using some
    linear combination of these 13 features.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 目标变量是以千美元为单位的自住房屋的中位数价值。在这个例子中，我们尝试通过使用这13个特征的一些线性组合来预测目标变量。
- en: 'First, we import the data:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们导入数据：
- en: '[PRE8]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next, we use the same linear regression model as in [Chapter 3](ch03.html#understanding_tensorflow_basics).
    This time we track the “loss” so we can measure the mean squared error (MSE),
    which is the average of the squared differences between the real target value
    and our predicted value. We use this measure as an indicator of how well our model
    performs:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用与[第3章](ch03.html#understanding_tensorflow_basics)中相同的线性回归模型。这次我们跟踪“损失”，以便测量均方误差（MSE），即实际目标值与我们预测值之间的平方差的平均值。我们使用这个度量作为我们的模型表现如何的指标：
- en: '[PRE9]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'After 200 iterations, we print out the MSE calculated for the training set.
    Now we perform the exact same process, but using `contrib.learn`’s estimator for
    linear regression. The whole process of defining, fitting, and evaluating the
    model comes down to just a few lines:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 经过200次迭代，我们打印出训练集计算的MSE。现在我们执行完全相同的过程，但使用`contrib.learn`的线性回归估计器。定义、拟合和评估模型的整个过程只需要几行代码：
- en: 'The linear regression model is instantiated using `learn.LinearRegressor()` and
    fed with knowledge about the data representation and the type of optimizer:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 线性回归模型是使用`learn.LinearRegressor()`实例化的，并提供有关数据表示和优化器类型的知识：
- en: '[PRE10]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The `regressor` object is trained using `.fit()`. We pass the covariates and
    the target variable, and set the number of steps and batch size:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`.fit()`训练`regressor`对象。我们传递协变量和目标变量，并设置步数和批量大小：
- en: '[PRE11]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The MSE loss is returned by `.evaluate()`:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: MSE损失由`.evaluate()`返回：
- en: '[PRE12]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here’s the code in its entirety:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是完整的代码：
- en: '[PRE13]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Some representation of the input data is passed in the regressor instantiation
    as a processed variable called `feature_columns`. We will return to this shortly.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 输入数据的某种表示形式作为一个名为`feature_columns`的处理变量传递给回归器实例化。我们很快会回到这个问题。
- en: DNN Classifier
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DNN分类器
- en: As with regression, we can use `contrib.learn` to apply an out-of-the-box classifier.
    In [Chapter 2](ch02.html#go_with_the_flow) we created a simple softmax classifier
    for the MNIST data. The `DNNClassifier` estimator allows us to perform a similar
    task with a considerably reduced amount of code. Also, it lets us add hidden layers (the
    “deep” part of the DNN).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 与回归一样，我们可以使用`contrib.learn`来应用一个开箱即用的分类器。在[第2章](ch02.html#go_with_the_flow)中，我们为MNIST数据创建了一个简单的softmax分类器。`DNNClassifier`估计器允许我们使用大大减少的代码量执行类似的任务。此外，它允许我们添加隐藏层（DNN的“深”部分）。
- en: 'As in [Chapter 2](ch02.html#go_with_the_flow), we first import the MNIST data:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 与[第2章](ch02.html#go_with_the_flow)一样，我们首先导入MNIST数据：
- en: '[PRE14]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Note that in this case, due to the requirement of the estimator, we pass the
    target in its class label form:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这种情况下，由于估计器的要求，我们以其类别标签形式传递目标：
- en: '[PRE15]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: returning a single integer per sample, corresponding to the correct digit class
    (i.e., values from 0 to [number of classes] – 1), instead of the one-hot form
    where each label is a vector with 1 in the index that corresponds to the correct
    class.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个样本返回一个单个整数，对应于正确的数字类别（即从0到[类别数] - 1的值），而不是每个标签都是一个向量，其中每个标签是一个向量，其中1在对应于正确类别的索引中。
- en: 'The next steps are similar to the ones we took in the previous example, except
    that when we define the model, we add the number of classes (10 digits) and pass
    a list where each element corresponds to a hidden layer with the specified number
    of units. In this example we use one hidden layer with 200 units:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的步骤与我们在前面的示例中所采取的步骤类似，只是在定义模型时，我们添加了类别数（10个数字）并传递一个列表，其中每个元素对应于具有指定单位数的隐藏层。在这个例子中，我们使用一个具有200个单位的隐藏层：
- en: '[PRE16]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Though not as good as our CNN model in [Chapter 4](ch04.html#convolutional_neural_networks)
    (above 99%), the test accuracy here (around 98%) is significantly better than
    it was in the simple softmax example (around 92%) as a result of adding just a
    single layer. In [Figure 7-1](#mnist_classification_test_accuracy) we see how
    the accuracy of the model increases with the number of units in that hidden layer.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管不如我们在[第4章](ch04.html#convolutional_neural_networks)中的CNN模型（超过99%）那么好，但这里的测试准确性（约98%）比简单softmax示例中的要好得多（约92%），这是由于添加了一个隐藏层。在[图7-1](#mnist_classification_test_accuracy)中，我们看到模型的准确性随着隐藏层中单位数的增加而增加。
- en: '![](assets/letf_0701.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/letf_0701.png)'
- en: Figure 7-1\. MNIST classification test accuracy as a function of units added
    in a single hidden layer.
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-1。单个隐藏层中添加的单位数与MNIST分类测试准确性的关系。
- en: 'Using the `<*Estimator*>.predict()` method, we can predict the classes of new
    samples. Here we will use the predictions to demonstrate how we can analyze our
    model’s performance—what classes were best identified and what types of typical
    errors were made. Plotting a *confusion matrix* can help us understand these behaviors.
    We import the code to create the confusion matrix from the `scikit-learn` library:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`<*Estimator*>.predict()`方法，我们可以预测新样本的类别。在这里，我们将使用预测来演示如何分析我们模型的性能——哪些类别被最好地识别，以及发生了哪些类型的典型错误。绘制*混淆矩阵*可以帮助我们理解这些行为。我们从`scikit-learn`库中导入创建混淆矩阵的代码：
- en: '[PRE17]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The confusion matrix is shown in [Figure 7-2](#predicted_digits_for_each_true).
    Its rows correspond to the true digits, its columns to the predicted digits. We
    see, for example, that the model sometimes misclassified `5` as `3` and `9` as
    `4` and `7`.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 混淆矩阵显示在[图7-2](#predicted_digits_for_each_true)中。其行对应于真实数字，列对应于预测数字。例如，我们看到模型有时将`5`误分类为`3`，将`9`误分类为`4`和`7`。
- en: '![](assets/letf_0702.png)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/letf_0702.png)'
- en: Figure 7-2\. A confusion matrix showing the number of predicted digits (columns)
    for each true label (rows).
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-2。显示每个真实标签（行）的预测数字（列）的混淆矩阵。
- en: FeatureColumn
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FeatureColumn
- en: One of `contrib.learn`’s nicest offerings is handling features of different
    types, which can sometimes be a little tricky. To make things easier, `contrib.learn`
    offers us the `FeatureColumn` abstraction.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`contrib.learn`的一个最好的功能是处理不同类型的特征，有时可能会有点棘手。为了简化事情，`contrib.learn`为我们提供了`FeatureColumn`抽象。'
- en: With a `FeatureColumn` we can maintain a representation of a single feature
    in our data, while performing a range of transformations defined over it. A `FeatureColumn`
    can be either one of the original columns or any new columns that may be added
    depending on our transformations. These may include creating a suitable and effective
    representation for categorical data by encoding it as a sparse vector (often referred
    to as *dummy encoding*), creating feature crosses to look for feature interactions,
    and bucketization (discretization of the data). All this can be done while manipulating
    the feature as a single semantic unit (encompassing, for example, all dummy vectors).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`FeatureColumn`，我们可以在执行一系列定义在其上的转换的同时，保持数据中单个特征的表示。`FeatureColumn`可以是原始列之一，也可以是根据我们的转换添加的任何新列。这些可能包括通过将其编码为稀疏向量（通常称为*虚拟编码*）来为分类数据创建合适和有效的表示形式，创建特征交叉以查找特征交互作用，以及桶化（数据的离散化）。所有这些都可以在将特征作为单个语义单元（例如，所有虚拟向量）的情况下完成。
- en: 'We use the `FeatureColumn` abstraction to specify the form and structure of
    each feature of our input data. For instance, let’s say that our target variable
    is `height`, and we try to predict it using two features, `weight` and `species`. We
    make our own synthetic data where heights are generated by dividing each weight
    by a factor of 100 and adding a constant that varies according to the species:
    1 is added for Humans, 0.9 for Goblins, and 1.1 for ManBears. We then add normally
    distributed noise to each instance:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`FeatureColumn`抽象来指定输入数据的每个特征的形式和结构。例如，假设我们的目标变量是`height`，我们尝试使用两个特征`weight`和`species`来预测它。我们制作自己的合成数据，其中身高是通过将每个体重除以一个系数100并添加一个根据物种变化的常数生成的：为Humans添加1，为Goblins添加0.9，为ManBears添加1.1。然后我们为每个实例添加正态分布的噪声：
- en: '[PRE18]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[Figure 7-3](#heights_for_three_species) shows visualizations of the data samples.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '[图7-3](#heights_for_three_species)展示了数据样本的可视化。'
- en: '![](assets/letf_0703.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/letf_0703.png)'
- en: 'Figure 7-3\. Left: A histogram of heights for the three types of species: Goblins,
    Humans, and ManBears (distributions centered at 1.6, 1.7, and 1.8, respectively).
    Right: A scatter plot of heights vs. weights.'
  id: totrans-107
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-3\. 左：三种物种（Goblins，Humans和ManBears）身高的直方图（分布中心分别为1.6、1.7和1.8）。右：身高与体重的散点图。
- en: Our target variable is a numeric NumPy array of heights `height`, and our covariates
    are the numeric NumPy array of weights `weight` and a list of strings denoting
    the name of each species `spec`.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标变量是一个数值型的身高NumPy数组`height`，我们的协变量是数值型的体重NumPy数组`weight`和表示每个物种名称的字符串列表`spec`。
- en: 'We use the Pandas library to have the data represented as a data frame (table),
    so that we can conveniently access each of its columns:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用Pandas库将数据表示为数据框（表），以便我们可以方便地访问每一列：
- en: '[PRE19]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[Figure 7-4](#fig0704) shows what our data frame looks like.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '[图7-4](#fig0704)展示了我们的数据框的样子。'
- en: '![](assets/letf_0704.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/letf_0704.png)'
- en: Figure 7-4\. Ten rows of the Height–Species–Weight data frame. Heights and Weights
    are numeric; Species is categorical with three categories.
  id: totrans-113
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-4\. 身高-物种-体重数据框的十行。身高和体重是数值型的；物种是具有三个类别的分类变量。
- en: Pandas
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Pandas
- en: Pandas is a very popular and useful library in Python for working with relational
    or labeled data like tabular data, multidimensional time series, etc. For more
    information on how to use Pandas, we refer the reader to Wes McKinney’s book [*Python
    for Data Analysis*](http://bit.ly/2uma9Om) (O’Reilly).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas是Python中非常流行和有用的库，用于处理关系型或带标签的数据，如表格数据，多维时间序列等。有关如何使用Pandas的更多信息，我们建议读者参考Wes
    McKinney的书[*Python for Data Analysis*](http://bit.ly/2uma9Om)（O’Reilly）。
- en: 'We start by specifying the nature of each feature. For `Weight` we use the
    following `FeatureColumn` command, indicating that it’s a continuous variable:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先指定每个特征的性质。对于`Weight`，我们使用以下`FeatureColumn`命令，指示它是一个连续变量：
- en: '[PRE20]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Layers
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Layers
- en: '`contrib.layers` is not a part of `contrib.learn`, but another independent
    subsection of the TensorFlow Python API that offers high-level operations and
    tools for building neural network layers.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '`contrib.layers`不是`contrib.learn`的一部分，而是TensorFlow Python API的另一个独立子部分，提供用于构建神经网络层的高级操作和工具。'
- en: The name that was passed to the function (in this case `Weight`) is crucially
    important since it will be used to associate the `FeatureColumn` representation
    with the actual data.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 传递给函数的名称（在本例中为`Weight`）非常重要，因为它将用于将`FeatureColumn`表示与实际数据关联起来。
- en: '`Species` is a categorical variable, meaning its values have no natural ordering,
    and therefore cannot be represented as a single variable in the model. Instead,
    it has to be extended and encoded as several variables, depending on the number
    of categories. `FeatureColumn` does this for us, so we just have to use the following
    command to specify that it is a categorical feature and indicate the name of each
    category:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '`Species`是一个分类变量，意味着其值没有自然顺序，因此不能在模型中表示为单个变量。相反，它必须被扩展和编码为多个变量，取决于类别的数量。`FeatureColumn`为我们做到了这一点，因此我们只需使用以下命令指定它是一个分类特征，并指定每个类别的名称：'
- en: '[PRE21]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Next, we instantiate an estimator class and input a list of our `FeatureColumn`s:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们实例化一个估计器类并输入我们的`FeatureColumn`列表：
- en: '[PRE22]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Up to now we’ve defined how the data will be represented in the model; in the
    following stage of fitting the model we need to provide the actual training data.
    In the Boston Housing example, the features were all numeric, and as a result
    we could just input them as `x_data` and target data.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经定义了数据在模型中的表示方式；在拟合模型的下一阶段中，我们需要提供实际的训练数据。在波士顿房屋的例子中，特征都是数值型的，因此我们可以将它们直接输入为`x_data`和目标数据。
- en: Here, `contrib.learn` requires that we use an additional encapsulating input
    function. The function gets both predictors and target data in their native form
    (Pandas data frame, NumPy array, list, etc.) as input, and returns a dictionary
    of tensors. In these dictionaries, each key is a name of a `FeatureColumn` (the
    names `Weight` and `Species` that were given as input previously), and its value
    needs to be a Tensor that contains the corresponding data. This means that we
    also have to transform the values into a TensorFlow Tensor inside the function.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`contrib.learn`要求我们使用一个额外的封装输入函数。该函数以原生形式（Pandas数据框，NumPy数组，列表等）获取预测变量和目标数据作为输入，并返回一个张量字典。在这些字典中，每个键都是一个`FeatureColumn`的名称（之前作为输入给出的`Weight`和`Species`的名称），其值需要是包含相应数据的张量。这意味着我们还需要在函数内部将值转换为TensorFlow张量。
- en: 'In our current example, the function receives our data frame, creates a dictionary
    `feature_cols`, and then stores the values of each column in the data frame as
    a Tensor for the corresponding key. It then returns that dictionary and the target
    variable as a Tensor. The keys have to match the names we used to define our `FeatureColumn`s:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们当前的示例中，该函数接收我们的数据框，创建一个名为`feature_cols`的字典，然后将数据框中每一列的值存储为对应键的张量。然后将该字典和目标变量作为张量返回。键必须与我们用来定义`FeatureColumn`的名称匹配：
- en: '[PRE23]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The values of `Species` are required by their `FeatureColumn` specification
    to be encoded in a sparse format. For that we use `tf.SparseTensor()`, where each
    `i` index corresponds to a nonzero value (in this case, all the rows in a one-column
    matrix).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '`Species`的值需要按照它们的`FeatureColumn`规范以稀疏格式进行编码。为此，我们使用`tf.SparseTensor()`，其中每个`i`索引对应一个非零值（在这种情况下，一个列矩阵中的所有行）。'
- en: 'For example, the following:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下内容：
- en: '[PRE24]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'represents the dense tensor:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 表示密集张量：
- en: '[PRE25]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We pass it to the `.fit()` method in the following way:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以以下方式将其传递给`.fit()`方法：
- en: '[PRE26]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Here, `input_fn()` is the function we just created, `df` is the data frame containing
    the data, and we also specify the number of iterations.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`input_fn()`是我们刚刚创建的函数，`df`是包含数据的数据框，我们还指定了迭代次数。
- en: Note that we pass the function in a form of a `lambda` function rather than
    the function’s outputs, because the `.fit()` method requires a function object.
    Using `lambda` allows us to pass our input arguments and keep it in an object
    form. There are other workarounds we could use to achieve the same outcome, but
    `lambda` does the trick.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们以`lambda`函数的形式传递函数，而不是函数的输出，因为`.fit()`方法需要一个函数对象。使用`lambda`允许我们传递输入参数并将其保持在对象形式中。我们可以使用其他方法来实现相同的结果，但`lambda`可以胜任。
- en: The fitting process may take a while. If you don’t want to do it all at once,
    you can split it into segments (see the following note).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 拟合过程可能需要一段时间。如果您不想一次完成所有操作，可以将其分成几个部分（请参阅下面的注释）。
- en: Splitting the training process
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分割训练过程
- en: 'It’s possible to perform the fit iteratively since the state of the model is
    preserved in the classifier. For example, instead of performing all 50,000 iterations
    consecutively like we did, we could split it into five segments:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 由于模型的状态在分类器中得以保留，因此可以进行迭代拟合。例如，我们可以将其分成五个部分，而不是像之前那样连续进行所有的50,000次迭代：
- en: '[PRE27]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: and achieve the same outcome. This could be useful if we want to have some tracking
    of the model while training it; however, there are better ways to do that, as
    we will see later on.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 并实现相同的结果。如果我们想要在训练过程中跟踪模型，这可能会很有用；然而，后面我们将看到有更好的方法来实现这一点。
- en: 'Now let’s see how well the model does by looking at the estimated weights. We
    can use the the `.get_variable_value()` method to get the variables’ values:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们通过查看估计的权重来看看模型的表现如何。我们可以使用`.get_variable_value()`方法获取变量的值：
- en: '[PRE28]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We request the values of the weights for both `Weight` and `Species`. `Species`
    is a categorical variable, so its three weights serve as different bias terms.
    We see that the model did quite well in estimating the true weights (`0.01` for
    `Weight` and `0.9`, `1`, `1.1` for `Goblins`, `Humans`, and `ManBears`, respectively,
    for `Species`). We can get the names of the variables by using the `.get_variable_names()`
    method.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们请求`Weight`和`Species`的权重值。`Species`是一个分类变量，因此它的三个权重值用作不同的偏差项。我们看到模型在估计真实权重（`Weight`为`0.01`，`Goblins`、`Humans`和`ManBears`的`Species`分别为`0.9`、`1`、`1.1`）方面表现得相当不错。我们可以使用`.get_variable_names()`方法获取变量的名称。
- en: The same process can be used in more complicated scenarios where we want to
    handle many types of features and their interactions. [Table 7-2](#tble0702) lists
    some useful operations you can do with `contrib.learn`.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在更复杂的情况下，我们可以使用相同的过程处理许多类型的特征及其交互。[表7-2](#tble0702)列出了一些您可以使用`contrib.learn`进行的有用操作。
- en: Table 7-2\. Useful feature transformation operations
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 表7-2\. 有用的特征转换操作
- en: '| Operation | Description |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| 操作 | 描述 |'
- en: '| --- | --- |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `layers.sparse_column_with_keys()` | Handles the conversion of categorical
    values  |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| `layers.sparse_column_with_keys()` | 处理分类值的转换 |'
- en: '| `layers.sparse_column_with_hash_bucket()` | Handles the conversion of categorical
    features for which you don’t know all possible values |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| `layers.sparse_column_with_hash_bucket()` | 处理您不知道所有可能值的分类特征的转换 |'
- en: '| `layers.crossed_column()` | Sets up feature crosses (interactions) |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| `layers.crossed_column()` | 设置特征交叉（交互） |'
- en: '| `layers.bucketized_column()` | Turns a continuous column into a categorical
    column |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| `layers.bucketized_column()` | 将连续列转换为分类列 |'
- en: Homemade CNN with contrib.learn
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用`contrib.learn`创建自制CNN
- en: We next move on to creating our own estimator by using `contrib.learn`. To do
    so, we first need to construct a model function where our homemade network will
    reside and an object containing our training settings.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将使用`contrib.learn`来创建自己的估计器。为此，我们首先需要构建一个模型函数，其中我们自制的网络将驻留，并包含我们的训练设置的对象。
- en: In the following example we create a custom CNN estimator that is identical
    to the one used at the beginning of [Chapter 4](ch04.html#convolutional_neural_networks),
    and use it again to classify the MNIST data. We begin by creating a function for
    our estimator with inputs that include our data, the mode of operation (training
    or test), and the parameters of the model.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的示例中，我们创建一个自定义的CNN估计器，它与[第4章](ch04.html#convolutional_neural_networks)开头使用的相同，并再次用于对MNIST数据进行分类。我们首先创建一个包含数据、操作模式（训练或测试）和模型参数的估计器函数。
- en: 'In the MNIST data the pixels are concatenated in the form of a vector and therefore
    require that we reshape them:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在MNIST数据中，像素以向量形式连接在一起，因此需要对它们进行重塑：
- en: '[PRE29]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We build the network by using the `contrib.layers` functionality, making the
    process of layer construction simpler.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过使用`contrib.layers`功能来构建网络，使得层构建过程更简单。
- en: 'Using `layers.convolution2d()` we can set everything in a one-liner command:
    we pass the input (the output of the previous layer), and then indicate the number
    of feature maps (32), the size of the filter (5×5), and the activation function
    (`relu`), and initialize the weights and biases. The dimensionality of the input
    is automatically identified and does not need to be specified. Also, unlike when
    working in lower-level TensorFlow, we don’t need to separately define the shapes
    of the variables and biases:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`layers.convolution2d()`，我们可以在一行命令中设置所有内容：我们传递输入（上一层的输出），然后指定特征映射的数量（32）、滤波器的大小（5×5）和激活函数（`relu`），并初始化权重和偏置。输入的维度会自动识别，不需要指定。此外，与在较低级别的TensorFlow中工作时不同，我们不需要单独定义变量和偏置的形状：
- en: '[PRE30]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: The padding is set to `'SAME'` by default (unchanged number of pixels), resulting
    in an output of shape 28×28×32.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 填充默认设置为`'SAME'`（像素数不变），导致输出形状为28×28×32。
- en: 'We also add the standard 2×2 pooling layer:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还添加了标准的2×2池化层：
- en: '[PRE31]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We then repeat these steps, this time for 64 target feature maps:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们重复这些步骤，这次是为64个目标特征映射：
- en: '[PRE32]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Next, we flatten the 7×7×64 tensor and add a fully connected layer, reducing
    it to 1,024 entries. We use `fully_connected()` similarly to `convolution2d()`,
    except we specify the number of output units instead of the size of the filter
    (there’s just one of those):'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将展平7×7×64的张量，并添加一个全连接层，将其减少到1,024个条目。我们使用`fully_connected()`类似于`convolution2d()`，只是我们指定输出单元的数量而不是滤波器的大小（这只有一个）：
- en: '[PRE33]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We then add dropout with `keep_prob` as set in the parameters given to the
    function (train/test mode), and the final fully connected layer with 10 output
    entries, corresponding to the 10 classes:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们使用`keep_prob`添加了dropout，该参数设置在函数中（训练/测试模式），并添加了最终的具有10个输出条目的全连接层，对应于10个类别：
- en: '[PRE34]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: We complete our model function by defining a training object with the loss and
    the learning rate of the optimizer.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 通过定义具有损失和优化器学习率的训练对象，我们完成了模型函数的定义。
- en: 'We now have one function that encapsulates the entire model:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个封装整个模型的函数：
- en: '[PRE35]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We instantiate the estimator by using `contrib.learn.Estimator()`, and we’re
    good to go. Once defined, we can use it with the same functionalities as before:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过使用`contrib.learn.Estimator()`来实例化评估器，然后就可以开始了。一旦定义好，我们可以像以前一样使用它的功能：
- en: '[PRE36]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Using `contrib.learn` and `contrib.layers`, the number of lines of code was
    cut down considerably in comparison to lower-level TensorFlow. More important,
    the code is much more organized and easier to follow, debug, and write.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 与较低级别的TensorFlow相比，使用`contrib.learn`和`contrib.layers`可以大大减少代码行数。更重要的是，代码更有组织性，更容易跟踪、调试和编写。
- en: With this example we conclude the `contrib.learn` portion of this chapter. We’ll
    now move on to cover some of the functionalities of the TFLearn library.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个例子，我们结束了本章的`contrib.learn`部分。现在我们将继续介绍TFLearn库的一些功能。
- en: TFLearn
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: TFLearn
- en: TFLearn is another library that allows us to create complex custom models in
    a very clean and compressed way, while still having a reasonable amount of flexibility,
    as we will see shortly.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: TFLearn是另一个库，它允许我们以非常干净、压缩的方式创建复杂的自定义模型，同时仍然具有合理的灵活性，我们很快就会看到。
- en: Installation
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装
- en: 'Unlike the previous library, TFLearn first needs to be installed. The installation
    is straightforward using `pip`:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的库不同，TFLearn首先需要安装。使用`pip`进行安装非常简单：
- en: '[PRE37]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: If that doesn’t work, it can be downloaded from [GitHub](https://github.com/tflearn/tflearn)
    and installed manually.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这样不起作用，可以从[GitHub](https://github.com/tflearn/tflearn)下载并手动安装。
- en: 'After the library has been successfully installed, you should be able to import
    it:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 在库成功安装后，您应该能够导入它：
- en: '[PRE38]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: CNN
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CNN
- en: Many of the functionalities of TFLearn resemble those covered in the previous
    section on `contrib.learn`; however, creating a custom model is a bit simpler
    and cleaner in comparison. In the following code we use the same CNN used earlier
    for the MNIST data.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: TFLearn的许多功能与前一节中涵盖的`contrib.learn`类似；然而，相比之下，在TFLearn中创建自定义模型更简单、更清晰。在下面的代码中，我们使用了之前用于MNIST数据的相同CNN模型。
- en: 'Model construction is wrapped and finalized using `regression()`, where we
    set the loss and optimization configuration as we did previously for the training
    object in `contrib.learn` (here we simply specify `''categorical_crossentropy''`
    for the loss, rather than explicitly defining it):'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 模型构建通过`regression()`进行包装和最终化，我们在其中设置损失和优化配置，就像我们在`contrib.learn`中为训练对象做的那样（这里我们只是简单地指定了`'categorical_crossentropy'`作为损失，而不是显式定义它）：
- en: '[PRE39]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Another layer that’s been added here, and that we briefly mentioned in [Chapter 4](ch04.html#convolutional_neural_networks),
    is the local response normalization layer. See the upcoming note for more details
    about this layer.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里添加的另一层是局部响应归一化层，我们在[第4章](ch04.html#convolutional_neural_networks)中简要提到过。有关此层的更多详细信息，请参阅即将发布的说明。
- en: The `tflearn.DNN()` function is somewhat equivalent to `contrib.learn.Estimator()`—it’s
    the DNN model wrapper with which we instantiate the model and to which we pass
    our constructed network.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '`tflearn.DNN()`函数在某种程度上相当于`contrib.learn.Estimator()`——它是DNN模型的包装器，我们用它来实例化模型，并传递我们构建的网络。'
- en: Here we can also set the TensorBoard and checkpoints directories, the level
    of verbosity of TensorBoard’s logs (0–3, from basic loss and accuracy reports
    to other measures like gradients and weights), and other settings.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们还可以设置TensorBoard和检查点目录，TensorBoard日志的详细程度（0-3，从基本的损失和准确度报告到其他指标如梯度和权重），以及其他设置。
- en: Once we have a model instance ready, we can then perform standard operations
    with it. [Table 7-3](#tble0703) summarizes the model’s functionalities in TFLearn.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有一个准备好的模型实例，我们就可以执行标准操作。[表7-3](#tble0703)总结了TFLearn中模型的功能。
- en: Table 7-3\. Standard TFLearn operations
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 表7-3. 标准TFLearn操作
- en: '| Function | Description |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| 函数 | 描述 |'
- en: '| --- | --- |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `evaluate(*X*, *Y*, *batch_size=128*)` | Perform evaluations of the model
    on given samples. |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| `evaluate(*X*, *Y*, *batch_size=128*)` | 对给定样本进行模型评估。 |'
- en: '| `fit(*X*, *Y*, *n_epoch=10*)` | Train the model with input features `*X*`
    and target `*Y*` to the network. |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| `fit(*X*, *Y*, *n_epoch=10*)` | 使用输入特征`*X*`和目标`*Y*`对网络进行训练。 |'
- en: '| `get_weights(*weight_tensor*)` | Get a variable’s weights. |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| `get_weights(*weight_tensor*)` | 获取变量的权重。 |'
- en: '| `load(*model_file*)` | Restore model weights. |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| `load(*model_file*)` | 恢复模型权重。 |'
- en: '| `predict(*X*)` | Get model predictions for the given input data. |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| `predict(*X*)` | 获取给定输入数据的模型预测。 |'
- en: '| `save(*model_file*)` | Save model weights. |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| `save(*model_file*)` | 保存模型权重。 |'
- en: '| `set_weights(*tensor*, *weights*)` | Assign a tensor variable a given value.
    |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| `set_weights(*tensor*, *weights*)` | 为张量变量分配给定值。 |'
- en: 'Similarly with `contrib.learn`, the fitting operation is performed by using
    the `.fit()` method, to which we feed the data and control training settings:
    the number of epochs, training and validation batch sizes, displayed measures,
    saved summaries frequency, and more. During fitting, TFLearn displays a nice dashboard,
    enabling us to track the training process online.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 与`contrib.learn`类似，通过使用`.fit()`方法执行拟合操作，我们向其中提供数据和控制训练设置：要执行的周期数，训练和验证批量大小，显示的度量，保存的摘要频率等。在拟合过程中，TFLearn显示一个漂亮的仪表板，使我们能够在线跟踪训练过程。
- en: Local response normalization
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 局部响应归一化
- en: The local response normalization (LRN) layer performs a kind of *lateral inhibition*
    by normalizing over local input regions. This is done by dividing the input values
    by the weighted, squared sum of all inputs within some depth radius, which we
    can manually choose. The resulting effect is that the activation contrast between
    the excited neurons and their local surroundings increases, producing more salient
    local maxima. This method encourages inhibition since it will diminish activations
    that are large, but uniform. Also, normalization is useful to prevent neurons
    from saturating when inputs may have varying scale (ReLU neurons have unbounded
    activation). There are more modern alternatives for regularization, such as batch
    normalization and dropout, but it is good to know about LRN too.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 局部响应归一化（LRN）层通过对局部输入区域进行归一化来执行一种*横向抑制*。这是通过将输入值除以某个深度半径内所有输入的加权平方和来完成的，我们可以手动选择。其结果是激活神经元与其周围局部环境之间的激活对比增加，产生更显著的局部极大值。这种方法鼓励抑制，因为它将减少大但均匀的激活。此外，归一化对于防止神经元在输入可能具有不同尺度时饱和是有用的（ReLU神经元具有无界激活）。有更现代的替代方法用于正则化，例如批量归一化和丢失，但了解LRN也是很好的。
- en: 'After fitting the model, we evaluate performance on the test data:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 在拟合模型后，我们在测试数据上评估性能：
- en: '[PRE40]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'and form new predictions (using them here again as a “sanity check” to the
    previous evaluation):'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 并形成新的预测（再次使用它们作为对先前评估的“健全性检查”）：
- en: '[PRE41]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Iterations training steps and epochs in TFLearn
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在TFLearn中的迭代训练步骤和周期
- en: In TFLearn, each *iteration* is a full pass (forward and backward) over one
    example. The *training step* is the number of full passes to perform, determined
    by the batch size you set (the default is 64), and an *epoch* is a full pass over
    all the training examples (50,000 in the case of MNIST). [Figure 7-5](#fig0705)
    shows an example of the interactive display in TFLearn.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在TFLearn中，每次*迭代*是对一个示例的完整传递（前向和后向）。*训练步骤*是要执行的完整传递次数，由您设置的批量大小（默认为64）确定，*周期*是对所有训练示例的完整传递（在MNIST的情况下为50,000）。[图7-5](#fig0705)显示了TFLearn中交互式显示的示例。
- en: '![](assets/letf_0705.png)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/letf_0705.png)'
- en: Figure 7-5\. Interactive display in TFLearn.
  id: totrans-214
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-5。TFLearn中的交互式显示。
- en: RNN
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: RNN
- en: We wrap up our introduction to TFLearn by constructing a fully functioning text
    classification RNN model that considerably simplifies the code we saw in Chapters
    [5](ch05.html#text_i) and [6](ch06.html#text_ii).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 通过构建一个完全功能的文本分类RNN模型，我们结束了对TFLearn的介绍，这大大简化了我们在第[5](ch05.html#text_i)章和第[6](ch06.html#text_ii)章中看到的代码。
- en: 'The task we perform is a sentiment analysis for movie reviews with binary classification
    (good or bad). We will use a well-known dataset of IMDb reviews, containing 25,000
    training samples and 25,000 test samples:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们执行的任务是对电影评论进行情感分析，进行二元分类（好或坏）。我们将使用一个著名的IMDb评论数据集，包含25,000个训练样本和25,000个测试样本：
- en: '[PRE42]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We first prepare the data, which has different sequence lengths, by equalizing
    the sequences with zero-padding by using `tflearn.data_utils.pad_sequences()`
    and setting 100 as the maximum sequence length:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先准备数据，这些数据具有不同的序列长度，通过使用`tflearn.data_utils.pad_sequences()`进行零填充来使序列相等，并将最大序列长度设置为100：
- en: '[PRE43]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Now we can represent data in one tensor, with samples in its rows and word IDs
    in its columns. As was explained in [Chapter 5](ch05.html#text_i), IDs here are
    integers that are used to encode the actual words arbitrarily. In our case, we
    have 10,000 unique IDs.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以用一个张量表示数据，其中样本在其行中，单词ID在其列中。正如在[第5章](ch05.html#text_i)中解释的那样，这里的ID是用来任意编码实际单词的整数。在我们的情况下，有10,000个唯一的ID。
- en: 'Next, we embed each word into a continuous vector space by using `tflearn.embedding()`,
    transforming our two-dimensional tensor `[*samples*, *IDs*]` into a three-dimensional
    tensor, `[*samples*, *IDs*, *embedding-size*]`, where each word ID now corresponds
    to a vector of size of 128\. Before that we use `input_data()` to input/feed data
    to the network (a TensorFlow placeholder is created with the given shape):'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用`tflearn.embedding()`将每个单词嵌入到连续的向量空间中，将我们的二维张量`[*samples*, *IDs*]`转换为三维张量`[*samples*,
    *IDs*, *embedding-size*]`，其中每个单词ID现在对应于大小为128的向量。在此之前，我们使用`input_data()`将数据输入/馈送到网络（使用给定形状创建了一个TensorFlow占位符）：
- en: '[PRE44]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Finally, we add an LSTM layer and a fully connected layer to output the binary
    outcome:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们添加了一个LSTM层和一个全连接层来输出二元结果：
- en: '[PRE45]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Here’s the full code:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是完整的代码：
- en: '[PRE46]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: In this section, we had just a quick taste of TFLearn. The library has nice
    [documentation](http://tflearn.org) and many examples that are well worth looking
    at.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们只是简单地尝试了一下TFLearn。该库有很好的[文档](http://tflearn.org)和许多示例，非常值得一看。
- en: Keras
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Keras
- en: Keras is one of the most popular and powerful TensorFlow extension libraries. Among
    the extensions we survey in this chapter, Keras is the only one that supports
    both Theano—upon which it was originally built—and TensorFlow. This is possible
    because of Keras’s complete abstraction of its backend; Keras has its own graph
    data structure for handling computational graphs and communicating with TensorFlow.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: Keras是最流行和强大的TensorFlow扩展库之一。在本章中我们调查的扩展中，Keras是唯一支持Theano和TensorFlow两者的库。这是因为Keras完全抽象了其后端；Keras有自己的图数据结构来处理计算图并与TensorFlow通信。
- en: In fact, because of that it could even be possible to define a Keras model with
    either TensorFlow or Theano and then switch to the other.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，由于这一点，甚至可能定义一个使用TensorFlow或Theano的Keras模型，然后切换到另一个。
- en: 'Keras has two main types of models to work with: sequential and functional.
    The sequential type is designed for simple architectures, where we just want to
    stack layers in a linear fashion. The functional API can support more-general
    models with a diverse layer structure, such as multioutput models.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: Keras有两种主要类型的模型可供使用：顺序和函数。顺序类型适用于简单的架构，我们只需按线性方式堆叠层。函数API可以支持更通用的具有多样化层结构的模型，如多输出模型。
- en: We will take a quick look at the syntax used for each type of model.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将快速查看每种模型类型使用的语法。
- en: Installation
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装
- en: 'In TensorFlow 1.1+ Keras can be imported from the `contrib` library; however,
    for older versions it needs to be installed externally. Note that Keras requires
    the `numpy`, `scipy`, and `yaml` dependencies. Similarly to TFLearn, Keras can
    either be installed using `pip`:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在TensorFlow 1.1+中，Keras可以从`contrib`库中导入；然而，对于旧版本，需要外部安装。请注意，Keras需要`numpy`、`scipy`和`yaml`依赖项。与TFLearn类似，Keras也可以使用`pip`安装：
- en: '[PRE47]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'or downloaded from [GitHub](https://github.com/fchollet/keras) and installed
    using:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 或者从[GitHub](https://github.com/fchollet/keras)下载并安装：
- en: '[PRE48]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'By default, Keras will use TensorFlow as its tensor manipulation library. If
    it is set to use Theano, it can be switched by changing the settings in the file
    called `$HOME/.keras/keras.json` (for Linux users—modify the path according to
    your OS), where the attribute `backend` appears in addition to other technical
    settings not important in this chapter:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Keras将使用TensorFlow作为其张量操作库。如果设置为使用Theano，可以通过更改名为`$HOME/.keras/keras.json`的文件中的设置来切换（对于Linux用户——根据您的操作系统修改路径），其中除了其他本章不重要的技术设置外，还有`backend`属性：
- en: '[PRE49]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'If we want to access the backend, we can easily do so by first importing it:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想要访问后端，可以通过首先导入它来轻松实现：
- en: '[PRE50]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'We can then use it for most tensor operations as we would in TensorFlow (also
    for Theano). For example, this:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以像在TensorFlow中一样使用它进行大多数张量操作（也适用于Theano）。例如，这样：
- en: '[PRE51]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'is equivalent to:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 等同于：
- en: '[PRE52]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Sequential model
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 顺序模型
- en: 'Using the sequential type is very straightforward—we define it and can simply
    start adding layers:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 使用顺序类型非常简单——我们定义它并可以简单地开始添加层：
- en: '[PRE53]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Or equivalently:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 或者等效地：
- en: '[PRE54]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: A *dense* layer is a fully connected layer. The first argument denotes the number
    of output units, and the input shape is the shape of the input (in this example
    the weight matrix would be of size 784×64). `Dense()` also has an optional argument
    where we can specify and add an activation function, as in the second example.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '*密集*层是一个全连接层。第一个参数表示输出单元的数量，输入形状是输入的形状（在这个例子中，权重矩阵的大小将为784×64）。`Dense()`还有一个可选参数，我们可以在第二个例子中指定并添加激活函数。'
- en: 'After the model is defined, and just before training it, we set its learning
    configurations by using the `.compile()` method. It has three input arguments—the
    loss function, the optimizer, and another metric function that is used to judge
    the performance of your model (not used as the actual loss when training the model):'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义模型之后，在训练之前，我们使用`.compile()`方法设置其学习配置。它有三个输入参数——损失函数、优化器和另一个度量函数，用于评估模型的性能（在训练模型时不用作实际损失）：
- en: '[PRE55]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'We can set the optimizer at a finer resolution (learning rate, method, etc.) using
    `.optimizers`. For example:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`.optimizers`来设置优化器的更精细分辨率（学习率、方法等）。例如：
- en: '[PRE56]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Finally, we feed `.fit()` the data and set the number of epochs and batch size.
    As with the previous libraries, we can now easily evaluate how it does and perform
    predictions with new test data:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将数据传递给`.fit()`并设置epoch数和批量大小。与之前的库一样，我们现在可以轻松评估其表现并使用新的测试数据进行预测：
- en: '[PRE57]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Note that a `callbacks` argument was added to the `fit()` method. Callbacks
    are functions that are applied during the training procedure, and we can use them
    to get a view on statistics and make dynamic training decisions by passing a list
    of them to the `.fit()` method.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在`fit()`方法中添加了一个`callbacks`参数。回调函数是在训练过程中应用的函数，我们可以通过将它们的列表传递给`.fit()`方法来查看统计信息并做出动态训练决策。
- en: 'In this example we plug in two callbacks: TensorBoard, specifying its output
    folder, and early stopping.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们插入了两个回调函数：TensorBoard，指定其输出文件夹，和提前停止。
- en: Early stopping
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提前停止
- en: Early stopping is used to protect against overfitting by preventing the learner
    from further improving its fit to the training data at the expense of increasing
    the generalization error. In that sense, it can be thought of as a form of regularization.
    In Keras we can specify the minimum change to be monitored (`min_delta`), the
    number of no-improvement epochs to stop after (`patience`), and the direction
    of wanted change (`mode`).
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 提前停止用于防止过拟合，通过防止学习器进一步改善对训练数据的拟合而增加泛化误差。在这种意义上，它可以被认为是一种正则化形式。在Keras中，我们可以指定要监视的最小变化（`min_delta`）、在多少个不改进的epoch后停止（`patience`）以及所需变化的方向（`mode`）。
- en: Functional model
  id: totrans-263
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 函数模型
- en: The main practical difference between the functional model and the sequential
    model is that here we first define our input and output, and only then instantiate
    the model.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 函数模型和顺序模型之间的主要实际区别在于，这里我们首先定义输入和输出，然后实例化模型。
- en: 'We first create an input Tensor according to its shape:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 首先根据其形状创建一个输入张量：
- en: '[PRE58]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Then we define our model:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们定义我们的模型：
- en: '[PRE59]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: As we can see, the layers act as functions, giving the functional model its
    name.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，层就像函数一样起作用，给功能模型赋予了其名称。
- en: 'And now we instantiate the model, passing both inputs and outputs to `Model`:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们实例化模型，将输入和输出都传递给`Model`：
- en: '[PRE60]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'The other steps follow as before:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 其他步骤如前所述：
- en: '[PRE61]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: We will end this section by introducing the concept of autoencoders and then
    showing how to implement one using Keras.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过介绍自动编码器的概念来结束本节，然后展示如何使用Keras实现一个自动编码器。
- en: Autoencoders
  id: totrans-275
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自动编码器
- en: '*Autoencoders* are neural networks that try to output a reconstruction of the
    input. In most cases the input is reconstructed after having its dimensionality
    reduced. Dimensionality reduction will be our main focus; however, autoencoders
    can also be used to achieve “overcomplete” representations (for more stable decomposition),
    which actually increases dimensions.'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '*自动编码器*是神经网络，试图输出输入的重构。在大多数情况下，输入在降维后进行重构。降维将是我们的主要关注点；然而，自动编码器也可以用于实现“过完备”表示（用于更稳定的分解），实际上会增加维度。'
- en: In dimensionality reduction we wish to translate each vector of data with size *n* to
    a vector with size *m*, where *m < n*, while trying to keep as much important
    information as possible. One very common way to do that is using principal component
    analysis (PCA), where we can represent each original data column *x[j]* (all data
    points corresponding to an original feature) with some linear combination of the
    new reduced features, called the *principal components*, such that *x[j]* = *Σ[i=1]^mw[i]b[i]*.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在降维中，我们希望将大小为*n*的每个数据向量转换为大小为*m*的向量，其中*m < n*，同时尽量保留尽可能多的重要信息。一个非常常见的方法是使用主成分分析（PCA），我们可以用新减少的特征的一些线性组合来表示每个原始数据列*x[j]*（所有数据点对应于一个原始特征），称为*主成分*，使得*x[j]*
    = *Σ[i=1]^mw[i]b[i]*。
- en: PCA, however, is limited to only linear transformation of the data vectors.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，PCA仅限于对数据向量进行线性变换。
- en: Autoencoders are more general compressors, allowing complicated nonlinear transformations
    and finding nontrivial relations between visible and hidden units (in fact, PCA
    is like a one-layer “linear autoencoder”). The weights of the models are learned
    automatically by reducing a given loss function with an optimizer (SGD, for example).
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 自动编码器是更通用的压缩器，允许复杂的非线性变换，并找到可见单元和隐藏单元之间的非平凡关系（事实上，PCA就像是一个一层“线性自动编码器”）。模型的权重是通过减少给定的损失函数并使用优化器（例如SGD）自动学习的。
- en: Autoencoders that reduce input dimensionality create a bottleneck layer called
    a *hidden layer* that has a smaller number of units than the input layer, forcing
    the data to be represented in a lower dimension ([Figure 7-6](#autoencoder)) before
    it is reconstructed. For the reconstruction (decoding), autoencoders extract representative
    features that capture some hidden abstractions, like the shape of an eye, wheel
    of a car, type of sport, etc., with which we can reconstruct the original input.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 降低输入维度的自动编码器会创建一个称为*隐藏层*的瓶颈层，其单元数量少于输入层，强制数据在较低维度中表示（[图7-6](#autoencoder)）然后进行重构。对于重构（解码），自动编码器提取代表性特征，捕捉一些隐藏的抽象，比如眼睛的形状，汽车的轮子，运动类型等，我们可以用这些特征重构原始输入。
- en: '![](assets/letf_0706.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/letf_0706.png)'
- en: Figure 7-6\. Illustration of an autoencoder—a typical autoencoder will have
    input and output layers consisting of the same number of units, and bottleneck
    hidden layers, where the dimensionality of the data is reduced (compressed).
  id: totrans-282
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-6。自动编码器的示例——一个典型的自动编码器将具有相同数量的单元的输入和输出层，以及瓶颈隐藏层，其中数据的维度被减少（压缩）。
- en: Like some of the models we’ve seen so far, autoencoder networks can have layers
    stacked on top of each other, and they can include convolutions as in CNNs.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们迄今看到的一些模型一样，自动编码器网络可以将层堆叠在一起，并且可以包括卷积，就像CNN中一样。
- en: Autoencoders are currently not very suitable for real-world data compression
    problems due to their data specificity—they are best used on data that is similar
    to what they were trained on. Their current practical applications are mostly
    for extracting lower-dimensional representations, denoising data, and data visualization
    with reduced dimensionality. Denoising works because the network learns the important
    abstractions of the image, while losing unimportant image-specific signals like
    noise.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 由于自动编码器对数据的特定性，目前不太适用于真实世界的数据压缩问题——它们最适用于与它们训练的数据相似的数据。它们目前的实际应用主要用于提取较低维度的表示，去噪数据以及降低维度的数据可视化。去噪有效是因为网络学习了图像的重要抽象，同时丢失了不重要的图像特定信号，如噪音。
- en: Now let’s build a toy CNN autoencoder with Keras. In this example we will train
    the autoencoder on one category of a noisy version of the CIFAR10 data images,
    and then use it to denoise a test set of the same category. In this example we
    will use the functional model API.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们使用Keras构建一个玩具CNN自动编码器。在这个例子中，我们将在带噪声的CIFAR10数据图像的一个类别上训练自动编码器，然后使用它对相同类别的测试集进行去噪。在这个例子中，我们将使用功能模型API。
- en: 'First we load the images by using Keras, and then we choose only the images
    that correspond to the label `1` (the automobile class):'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 首先我们通过Keras加载图像，然后我们只选择与标签`1`（汽车类）对应的图像：
- en: '[PRE62]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Next we do a little pre-processing, by first converting our data to `float32`
    and then normalizing it to a range between [0,1]. This normalization will allow
    us to perform an element-wise comparison at the pixel level, as we will see shortly.
    First, the type conversion:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们进行一些预处理，首先将数据转换为`float32`，然后将其归一化到[0,1]范围内。这种归一化将允许我们在像素级别执行逐元素比较，我们很快就会看到。首先是类型转换：
- en: '[PRE63]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'We then add some Gaussian noise to create the noisy dataset, and clip values
    that are either smaller than 0 or larger than 1:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们添加一些高斯噪声来创建带噪声的数据集，并裁剪小于0或大于1的值：
- en: '[PRE64]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Now we declare the input layer (every image in the CIFAR10 dataset is 32×32
    pixels with RGB channels):'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们声明输入层（CIFAR10数据集中的每个图像都是32×32像素，带有RGB通道）：
- en: '[PRE65]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Next, we start adding our usual “LEGO brick" layers.  Our first layer is a 2D
    convolution layer, where the first argument is the number of filters (and thus
    the number of output images), and the second is the size of each filter. Like
    the other libraries, Keras automatically identifies the shape of the input.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们开始添加我们通常的“乐高积木”层。我们的第一层是一个2D卷积层，第一个参数是滤波器的数量（因此是输出图像的数量），第二个是每个滤波器的大小。与其他库一样，Keras会自动识别输入的形状。
- en: We use a 2×2 pooling layer, which reduces the total number of pixels per channel
    by 4, creating the desired bottleneck. After another convolutional layer, we regain
    the same number of units for each channel by applying an up-sampling layer. This
    is done by quadrupling each pixel in a pixel’s near vicinity (repeating the rows
    and columns of the data) to get back the same number of pixels in each image.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用一个2×2的池化层，将每个通道的像素总数减少4倍，创建所需的瓶颈。在另一个卷积层之后，通过应用上采样层，我们恢复每个通道的相同单位数。这是通过在像素的附近四倍化每个像素（重复数据的行和列）来完成的，以获得每个图像中相同数量的像素。
- en: 'Finally, we add a convolutional output layer where we go back to three channels:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们添加一个卷积输出层，回到三个通道：
- en: '[PRE66]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'We declare the functional model format, passing both inputs and outputs:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 我们声明功能模型格式，传递输入和输出：
- en: '[PRE67]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'Next we compile the model, defining the loss function and the optimizer—in
    this case we use the Adagrad optimizer (just to show another example!). For denoising
    of the images, we want our loss to capture the discrepancy between the decoded
    images and the original, pre-noise images. For that we use a binary cross-entropy
    loss, comparing each decoded pixel to its corresponding original one (it’s now
    between [0,1]):'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们编译模型，定义损失函数和优化器——在这种情况下，我们使用Adagrad优化器（只是为了展示另一个例子！）。对于图像的去噪，我们希望我们的损失能够捕捉解码图像与原始、去噪前图像之间的差异。为此，我们使用二元交叉熵损失，将每个解码像素与其对应的原始像素进行比较（现在在[0,1]之间）：
- en: '[PRE68]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'After the model is defined, we fit it with 10 training epochs:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 模型定义后，我们用10个训练周期来拟合它：
- en: '[PRE69]'
  id: totrans-303
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Hopefully the model will capture some internal structure, which it can later
    generalize to other noisy images, and denoise them as a result.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 希望模型能够捕捉一些内部结构，然后将其推广到其他嘈杂图像，并因此对其进行去噪。
- en: We use our test set as validation data for loss evaluation at the end of each
    epoch (the model will not be trained on this data), and also for visualization
    in TensorBoard. In addition to the TensorBoard callback, we add a model saver
    callback and set it to save our weights every two epochs.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将测试集用作每个周期结束时损失评估的验证数据（模型不会在此数据上进行训练），还用于在TensorBoard中进行可视化。除了TensorBoard回调，我们还添加了一个模型保存回调，并设置为每两个周期保存一次权重。
- en: 'Later, when we wish to load our weights, we need to reconstruct the network
    and then use the `Model.load_weights()` method, passing our model as the first
    argument and our saved weights file path as the second (more on saving models
    in [Chapter 10](ch10.html#exporting_and_serving_models_with_tensorflow)):'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 稍后，当我们希望加载我们的权重时，我们需要重建网络，然后使用`Model.load_weights()`方法，将我们的模型作为第一个参数，将保存的权重文件路径作为第二个参数（有关在[第10章](ch10.html#exporting_and_serving_models_with_tensorflow)中保存模型的更多信息）：
- en: '[PRE70]'
  id: totrans-307
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: h5py requirement
  id: totrans-308
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: h5py要求
- en: 'For model saving, it is required that the `h5py` package is installed. This
    package is primarily used for storing large amounts of data and manipulating it
    from NumPy. You can install it using `pip`:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保存模型，需要安装`h5py`包。这个包主要用于存储大量数据并从NumPy中操作数据。您可以使用`pip`安装它：
- en: '[PRE71]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '[Figure 7-7](#before_and_after_autoencoding) shows the denoised test images
    of our chosen category for different numbers of training epochs.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '[图7-7](#before_and_after_autoencoding)显示了我们选择类别的去噪测试图像，不同训练周期的结果。'
- en: '![](assets/letf_0707.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/letf_0707.png)'
- en: Figure 7-7\. Noisy CIFAR10 images before autoencoding (upper row) and after
    autoencoding (lower rows). The 4 bottom rows show results after increasing number
    of training epochs.
  id: totrans-313
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-7。自动编码之前的嘈杂CIFAR10图像（上排）和自动编码之后的图像（下排）。底部4行显示了增加训练周期后的结果。
- en: Keras also has a bunch of pretrained models to download, like *inception*, *vgg*,
    and *resnet*. In the next and final section of this chapter, we will discuss these
    models and show an example of how to download and use a pretrained VGG model for
    classification using the TF-Slim extension.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: Keras还有一堆预训练模型可供下载，如*inception*、*vgg*和*resnet*。在本章的下一部分和最后一部分中，我们将讨论这些模型，并展示如何下载和使用TF-Slim扩展来进行分类的预训练VGG模型的示例。
- en: Pretrained models with TF-Slim
  id: totrans-315
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TF-Slim的预训练模型
- en: In this section of the chapter we will introduce the last abstraction to be
    covered here, TF-Slim. TF-Slim stands out by offering simplified syntax for defining
    convolutional neural networks in TensorFlow—its abstractions make it easy to build
    complex networks in a clean, streamlined manner. Like Keras, it also offers a
    nice variety of [pretrained CNN models](http://bit.ly/2sZt5lE?) to download and
    use.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的这一部分，我们将介绍这里要涵盖的最后一个抽象概念，TF-Slim。TF-Slim通过提供简化的语法来定义TensorFlow中的卷积神经网络而脱颖而出——它的抽象使得以一种干净、简洁的方式构建复杂网络变得容易。与Keras一样，它还提供了各种[预训练的CNN模型](http://bit.ly/2sZt5lE?)供下载和使用。
- en: We start this section by learning about some of the general features and benefits
    of TF-Slim, and why it’s a great tool to use for building CNNs. In the second
    part of this section we will demonstrate how to download and deploy a pretrained
    model (VGG) for image classification.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过学习TF-Slim的一些一般特性和优点来开始本节，说明为什么它是构建CNN的绝佳工具。在本节的第二部分中，我们将演示如何下载和部署一个预训练模型（VGG）进行图像分类。
- en: TF-Slim
  id: totrans-318
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TF-Slim
- en: TF-Slim is a relatively new lightweight extension of TensorFlow that, like other
    abstractions, allows us to define and train complex models quickly and intuitively. TF-Slim
    doesn’t require any installation since it’s been merged with TensorFlow.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: TF-Slim是TensorFlow的一个相对较新的轻量级扩展，类似于其他抽象，它允许我们快速直观地定义和训练复杂模型。TF-Slim不需要任何安装，因为它已经与TensorFlow合并。
- en: This extension is all about convolutional neural networks. CNNs are notorious
    for having a lot of messy boilerplate code. TF-Slim was designed with the goal
    of optimizing the creation of very complex CNN models so that they could be elegantly
    written and easy to interpret and debug by using high-level layers, variable abstractions,
    and argument scoping, which we will touch upon shortly.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 这个扩展主要是关于卷积神经网络。CNN以混乱的样板代码而闻名。TF-Slim的设计目标是优化非常复杂的CNN模型的创建，使其能够通过使用高级层、变量抽象和参数作用域进行优雅编写、易于解释和调试。
- en: 'In addition to enabling us to create and train our own models, TF-Slim has
    available pretrained networks that can be easily downloaded, read, and used: VGG,
    AlexNet, Inception, and more.'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 除了让我们能够创建和训练自己的模型之外，TF-Slim还提供了可以轻松下载、阅读和使用的预训练网络：VGG、AlexNet、Inception等。
- en: We start this section by briefly describing some of TF-Slim’s abstraction features.
    Then we shift our focus to how to download and use a pretrained model, demonstrating
    it for the VGG image classification model.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从简要描述TF-Slim的一些抽象特性开始这一部分。然后我们将重点放在如何下载和使用预训练模型上，以VGG图像分类模型为例进行演示。
- en: Creating CNN models with TF-Slim
  id: totrans-323
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用TF-Slim创建CNN模型
- en: 'With TF-Slim we can create a variable easily by defining its initialization,
    regularization, and device with one wrapper. For example, here we define weights
    initialized from a truncated normal distribution using L2 regularization and placed
    on the CPU (we will talk about distributing model parts across devices in [Chapter 9](ch09.html#distributed_tensorflow)):'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 使用TF-Slim，我们可以通过定义初始化、正则化和设备来轻松创建一个变量。例如，在这里，我们定义了从截断正态分布初始化的权重，使用L2正则化，并放置在CPU上（我们将在[第9章](ch09.html#distributed_tensorflow)讨论跨设备分配模型部分）：
- en: '[PRE72]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Like the other abstractions we’ve seen in this chapter, TF-Slim can reduce
    a lot of boilerplate code and redundant duplication. As with Keras or TFLearn,
    we can define a layer operation at an abstract level to include the convolution
    operation, weights initialization, regularization, activation function, and more
    in a single command:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 与本章中看到的其他抽象一样，TF-Slim可以减少大量样板代码和冗余复制。与Keras或TFLearn一样，我们可以在抽象级别定义一个层操作，包括卷积操作、权重初始化、正则化、激活函数等，都可以在一个命令中完成：
- en: '[PRE73]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: TF-Slim extends its elegance even beyond that, providing a clean way to replicate
    layers compactly by using the `repeat`, `stack`, and `arg_scope` commands.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: TF-Slim甚至将其优雅性扩展到了更远的地方，通过使用`repeat`、`stack`和`arg_scope`命令提供了一种紧凑地复制层的方法。
- en: '`repeat` saves us the need to copy and paste the same line over and over so
    that, for example, instead of having this redundant duplication:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '`repeat`可以避免我们反复复制粘贴相同的行，例如，与其有这种冗余复制：'
- en: '[PRE74]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'we could just enter this:'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以这样输入：
- en: '[PRE75]'
  id: totrans-332
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'But this is viable only in cases where we have layers of the same size. When
    this does not hold, we can use the `stack` command, allowing us to concatenate
    layers of different shapes. So, instead of this:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 但这仅适用于具有相同大小的层的情况。当这种情况不成立时，我们可以使用`stack`命令，允许我们连接不同形状的层。因此，与其这样：
- en: '[PRE76]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'we can write this:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以这样写：
- en: '[PRE77]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Finally, we also have a scoping mechanism referred to as `arg_scope`, allowing
    users to pass a set of shared arguments to each operation defined in the same
    scope. Say, for example, that we have four layers having the same activation function,
    initialization, regularization, and padding. We can then simply use the `slim.arg_scope`
    command, where we specify the shared arguments as in the following code:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们还有一个称为`arg_scope`的作用域机制，允许用户将一组共享参数传递给同一作用域中定义的每个操作。例如，假设我们有四个具有相同激活函数、初始化、正则化和填充的层。我们可以简单地使用`slim.arg_scope`命令，指定共享参数，如下面的代码所示：
- en: '[PRE78]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: The individual arguments inside the `arg_scope` command can still be overwritten,
    and we can also nest one `arg_scope` inside another.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '`arg_scope`命令中的各个参数仍然可以被覆盖，我们也可以将一个`arg_scope`嵌套在另一个中。'
- en: 'In these examples we used `conv2d()`: however, TF-Slim has many of the other
    standard methods for building neural networks. [Table 7-4](#tble0704) lists some
    of the available options. For the full list, consult [the documentation](http://bit.ly/2txy6PN?).'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些示例中，我们使用了`conv2d()`：然而，TF-Slim还有许多其他用于构建神经网络的标准方法。[表7-4](#tble0704)列出了一些可用选项。要查看完整列表，请参阅[文档](http://bit.ly/2txy6PN?)。
- en: Table 7-4\. Available layer types in TF-Slim
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 表7-4。TF-Slim中可用的层类型
- en: '| Layer | TF-Slim |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| Layer | TF-Slim |'
- en: '| --- | --- |'
  id: totrans-343
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| BiasAdd | `slim.bias_add()` |'
  id: totrans-344
  prefs: []
  type: TYPE_TB
  zh: '| BiasAdd | `slim.bias_add()` |'
- en: '| BatchNorm | `slim.batch_norm()` |'
  id: totrans-345
  prefs: []
  type: TYPE_TB
  zh: '| BatchNorm | `slim.batch_norm()` |'
- en: '| Conv2d | `slim.conv2d()` |'
  id: totrans-346
  prefs: []
  type: TYPE_TB
  zh: '| Conv2d | `slim.conv2d()` |'
- en: '| Conv2dInPlane | `slim.conv2d_in_plane()` |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
  zh: '| Conv2dInPlane | `slim.conv2d_in_plane()` |'
- en: '| Conv2dTranspose (Deconv) | `slim.conv2d_transpose()` |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
  zh: '| Conv2dTranspose (Deconv) | `slim.conv2d_transpose()` |'
- en: '| FullyConnected | `slim.fully_connected()` |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '| FullyConnected | `slim.fully_connected()` |'
- en: '| AvgPool2D | `slim.avg_pool2d()` |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
  zh: '| AvgPool2D | `slim.avg_pool2d()` |'
- en: '| Dropout | `slim.dropout()` |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
  zh: '| Dropout | `slim.dropout()` |'
- en: '| Flatten | `slim.flatten()` |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
  zh: '| Flatten | `slim.flatten()` |'
- en: '| MaxPool2D | `slim.max_pool2d()` |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
  zh: '| MaxPool2D | `slim.max_pool2d()` |'
- en: '| OneHotEncoding | `slim.one_hot_encoding()` |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
  zh: '| OneHotEncoding | `slim.one_hot_encoding()` |'
- en: '| SeparableConv2 | `slim.separable_conv2d()` |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
  zh: '| SeparableConv2 | `slim.separable_conv2d()` |'
- en: '| UnitNorm | `slim.unit_norm` |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
  zh: '| UnitNorm | `slim.unit_norm` |'
- en: 'To illustrate how convenient TF-Slim is for creating complex CNNs, we will
    build the VGG model by Karen Simonyan and Andrew Zisserman that was introduced
    in 2014 (see the upcoming note for more information). VGG serves as a good illustration
    of how a model with many layers can be created compactly using TF-Slim. Here we
    construct the 16-layer version: 13 convolution layers plus 3 fully connected layers.'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明TF-Slim在创建复杂CNN时有多方便，我们将构建Karen Simonyan和Andrew Zisserman在2014年提出的VGG模型（有关更多信息，请参见即将发布的说明）。VGG是一个很好的例子，说明了如何使用TF-Slim紧凑地创建具有许多层的模型。在这里，我们构建16层版本：13个卷积层加上3个全连接层。
- en: 'Creating it, we take advantage of two of the features we’ve just mentioned:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 创建它时，我们利用了我们刚提到的两个特性：
- en: We use the `arg_scope` feature since all of the convolution layers have the
    same activation function and the same regularization and initialization.
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们使用`arg_scope`功能，因为所有卷积层具有相同的激活函数和相同的正则化和初始化。
- en: Many of the layers are exact duplicates of others, and therefore we also take
    advantage of the `repeat` command.
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 许多层都是相同的副本，因此我们还利用了`repeat`命令。
- en: 'The result very compelling—the entire model is defined with just 16 lines of
    code:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 结果非常引人注目——整个模型仅用16行代码定义：
- en: '[PRE79]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: VGG and the ImageNet Challenge
  id: totrans-363
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: VGG和ImageNet挑战
- en: The [ImageNet project](http://www.image-net.org) is a large database of images
    collected for the purpose of researching visual object recognition. As of 2016
    it contained over 10 million hand-annotated images.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImageNet项目](http://www.image-net.org)是一个大型图像数据库，旨在研究视觉对象识别。截至2016年，它包含超过1000万个手工注释的图像。'
- en: Each year (since 2010) a competition takes place called the ImageNet Large Scale
    Visual Recognition Challenge (ILSVRC), where research teams try to automatically
    classify, detect, and localize objects and scenes in a subset of the ImageNet
    collection. In the 2012 challenge, dramatic progress occurred when a deep convolutional
    neural net called AlexNet, created by Alex Krizhevsky, managed to get a top 5
    (top 5 chosen categories) classification error of only 15.4%, winning the competition
    by a large margin.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 自2010年以来，每年都会举行一场名为ImageNet大规模视觉识别挑战（ILSVRC）的比赛，研究团队试图在ImageNet收集的子集中自动分类、检测和定位对象和场景。在2012年的挑战中，当时由Alex
    Krizhevsky创建的深度卷积神经网络AlexNet取得了令人瞩目的进展，成功将前5名（前5个选择的类别）的分类错误率降至仅15.4%，以较大的优势赢得了比赛。
- en: Over the next couple of years the error rate kept falling, from ZFNet with 14.8%
    in 2013, to GoogLeNet (introducing the Inception module) with 6.7% in 2014, to
    ResNet with 3.6% in 2015.  The Visual Geometry Group (VGG) was another CNN competitor
    in the 2014 competition that also achieved an impressive low error rate (7.3%).
    A lot of people prefer VGG over GoogLeNet because it has a nicer, simpler architecture.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几年里，错误率不断下降，从2013年的ZFNet的14.8%，到2014年的GoogLeNet（引入Inception模块）的6.7%，再到2015年的ResNet的3.6%。视觉几何组（VGG）是2014年比赛中的另一个CNN竞争对手，也取得了令人印象深刻的低错误率（7.3%）。许多人更喜欢VGG而不是GoogLeNet，因为它具有更好、更简单的架构。
- en: In VGG the only spatial dimensions used are very small 3×3 filters with a stride
    of 1 and a 2×2 max pooling, again with a stride of 1\. Its superiority is achieved
    by the number of layers it uses, which is between 16 and 19.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 在VGG中，唯一使用的空间维度是非常小的3×3滤波器，步幅为1，以及2×2最大池化，步幅再次为1。它的优越性是通过使用的层数来实现的，介于16和19之间。
- en: Downloading and using a pretrained model
  id: totrans-368
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 下载和使用预训练模型
- en: Next we will demonstrate how to download and deploy a pretrained VGG model.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们将演示如何下载和部署预训练的VGG模型。
- en: 'First we need to clone the repository where the actual models will reside by
    running:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要克隆存放实际模型的存储库，方法是运行：
- en: '[PRE80]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Now we have the scripts we need for modeling on our computer, and we can use
    them by setting the path:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们在计算机上拥有建模所需的脚本，并且可以通过设置路径来使用它们：
- en: '[PRE81]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'Next we will download the pretrained VGG-16 (16 layers) model—it is available
    [on GitHub](http://bit.ly/2vkqMHq), as are other models, such as Inception, ResNet,
    and more:'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将下载预训练的VGG-16（16层）模型——它可以在[GitHub](http://bit.ly/2vkqMHq)上找到，还有其他模型，如Inception、ResNet等：
- en: '[PRE82]'
  id: totrans-375
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: The downloaded checkpoint file contains information about both the model and
    the variables. Now we want to load it and use it for classification of new images.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 下载的检查点文件包含有关模型和变量的信息。现在我们想要加载它并将其用于对新图像进行分类。
- en: However, before that we first have to prepare our input image, turning it into
    a readable TensorFlow format and performing a little pre-processing to make sure
    that it is resized to match the size of the images the model was trained on.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在此之前，我们首先必须准备好我们的输入图像，将其转换为可读的TensorFlow格式，并执行一些预处理，以确保它被调整大小以匹配模型训练时的图像大小。
- en: 'We can load the image into TensorFlow either as a URL link or as a desktop
    image. For a URL link, we can load the image as a string with `urllib2` (this
    needs to be imported), and then decode it into a Tensor by using `tf.image_decode_jpeg()`:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将图像加载到TensorFlow中，可以作为URL链接或桌面图像。对于URL链接，我们可以使用`urllib2`将图像加载为字符串（需要导入），然后使用`tf.image_decode_jpeg()`将其解码为Tensor：
- en: '[PRE83]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'Or, for PNG:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，对于PNG：
- en: '[PRE84]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'To load an image from our computer, we can create a queue of our filenames
    in the target directory, and then read the entire image file by using `tf.WholeFileReader()`:'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 要从计算机加载图像，我们可以在目标目录中创建一个文件名队列，然后使用`tf.WholeFileReader()`读取整个图像文件：
- en: '[PRE85]'
  id: totrans-383
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: Don’t worry about the details for this step; we will discuss queues and reading
    data in much more depth in [Chapter 8](ch08.html#queues_threads_and_reading_data).
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 不要担心这一步的细节；我们将在[第8章](ch08.html#queues_threads_and_reading_data)中更深入地讨论队列和读取数据。
- en: 'Next we want to resize the image so that it matches the size of the images
    VGG was trained on. For that, we first extract the desired size from the VGG script
    (in this case, it is 224):'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们要调整图像的大小，使其与VGG训练时的图像大小匹配。为此，我们首先从VGG脚本中提取所需的大小（在本例中为224）：
- en: '[PRE86]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: 'Then we feed the raw image and the image size to the VGG pre-processing unit,
    where the image will be resized with a preserved aspect ratio (the width-to-height
    ratio of the image) and then cropped:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将原始图像和图像尺寸传递给VGG预处理单元，在那里图像将被调整大小以保持纵横比（图像的宽高比），然后裁剪：
- en: '[PRE87]'
  id: totrans-388
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'Next we use `tf.expand_dims()` to insert a dimension of 1 into a tensor’s shape.
    This is done to add a batch dimension to a single element (changing `[*height*,
    *width*, *channels*]` to `[1, *height*, *width*, *channels*]`):'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用`tf.expand_dims()`将一个维度1插入到张量的形状中。这是为了将批处理维度添加到单个元素（将`[*高度*, *宽度*, *通道*]`更改为`[1,
    *高度*, *宽度*, *通道*]`）：
- en: '[PRE88]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: Now we create the model from the script we cloned earlier. We pass the model
    function the images and number of classes. The model has shared arguments; therefore,
    we call it using `arg_scope`, as we saw earlier, and use the `vgg_arg_scope()`
    function in the script to define the shared arguments. The function is shown in
    the following code snippet.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们从之前克隆的脚本创建模型。我们将图像和类别数传递给模型函数。模型具有共享参数；因此，我们像之前看到的那样使用`arg_scope`调用它，并在脚本中使用`vgg_arg_scope()`函数定义共享参数。该函数如下代码片段所示。
- en: '`vgg_16()` returns the logits (numeric values acting as evidence for each class),
    which we can then turn into probabilities by using `tf.nn.softmax()`. We use the
    argument `is_training` to indicate that we are interested in forming predictions
    rather than training:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: '`vgg_16()`返回逻辑值（作为每个类别的证据），我们可以通过使用`tf.nn.softmax()`将其转换为概率。我们使用参数`is_training`来指示我们感兴趣的是形成预测而不是训练：'
- en: '[PRE89]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: '[PRE90]'
  id: totrans-394
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: 'Now, just before starting the session, we need to load the variables we downloaded
    using `slim.assign_from_checkpoint_fn()`, to which we pass the containing directory:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在开始会话之前，我们需要使用`slim.assign_from_checkpoint_fn()`加载下载的变量，我们将其传递给包含目录：
- en: '[PRE91]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: Finally, the main event—we run the session, load the variables, and feed in
    the images and the desired probabilities.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，主要事件——我们运行会话，加载变量，并输入图像和所需的概率。
- en: 'We can get the class names by using the following lines:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下行获取类别名称：
- en: '[PRE92]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: 'We extract the five classes with the highest probabilities for our given image, and
    the probabilities as well:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提取给定图像的五个具有最高概率的类别，以及概率：
- en: '[PRE93]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: In this example we passed the image shown in [Figure 7-8](#lakeside_in_switzerland)
    as input to the pretrained VGG model.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将显示在[图7-8](#lakeside_in_switzerland)中的图像作为输入传递给预训练的VGG模型。
- en: '![](assets/letf_0708.png)'
  id: totrans-403
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/letf_0708.png)'
- en: Figure 7-8\. A lakeside in Switzerland.
  id: totrans-404
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-8\. 瑞士的湖边。
- en: 'Here are the output results for the top-five chosen classes and their probabilities:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是前五个选择的类别及其概率的输出结果：
- en: '[PRE94]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: As you can see, the classifier does quite well at capturing different elements
    in this image.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，分类器在捕捉图像中的不同元素方面表现得相当不错。
- en: Summary
  id: totrans-408
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'We started this chapter by discussing the importance of abstractions, followed
    by high-level coverage and then focusing in on some of the popular TensorFlow
    extensions: `contrib.learn`, TFLearn, Keras, and TF-Slim. We revisited models
    from previous chapters, using out-of-the-box `contrib.learn` linear regression
    and linear classification models. We then saw how to use the `FeatureColumn` abstraction
    for feature handling and pre-processing, incorporate TensorBoard, and create our
    own custom estimator. We introduced TFLearn and exemplified how easily CNN and
    RNN models can be constructed with it. Using Keras, we demonstrated how to implement
    an autoencoder. Finally, we created complex CNN models with TF-Slim and deployed
    a pretrained model.'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从讨论抽象的重要性开始了本章，然后进行了高层次的覆盖，然后专注于一些流行的TensorFlow扩展：`contrib.learn`，TFLearn，Keras和TF-Slim。我们重新访问了前几章的模型，使用了现成的`contrib.learn`线性回归和线性分类模型。然后我们看到了如何使用`FeatureColumn`抽象来处理特征和预处理，整合TensorBoard，并创建我们自己的自定义估算器。我们介绍了TFLearn，并演示了如何使用它轻松构建CNN和RNN模型。使用Keras，我们演示了如何实现自动编码器。最后，我们使用TF-Slim创建了复杂的CNN模型，并部署了一个预训练模型。
- en: In the next chapters we cover scaling up, with queuing and threading, distributed
    computing, and model serving.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将涵盖扩展规模，包括排队和线程，分布式计算和模型服务。
