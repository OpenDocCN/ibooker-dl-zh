- en: 2 Graph embeddings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Exploring graph embeddings and their importance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating node embeddings using non-GNN and GNN methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Comparing node embeddings on a semi-supervised problem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Taking a deeper dive into embedding methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Graph embeddings are essential tools in graph-based machine learning. They transform
    the intricate structure of graphs—be it the entire graph, individual nodes, or
    edges—into a more manageable, lower-dimensional space. We do this to compress
    a complex dataset into a form that’s easier to work with, without losing its inherent
    patterns and relationships, the information to which we’ll apply a graph neural
    network (GNN) or other machine learning method.
  prefs: []
  type: TYPE_NORMAL
- en: Graphs, as we’ve learned, encapsulate relationships and interactions within
    networks, whether they’re social networks, biological networks, or any system
    where entities are interconnected. Embeddings capture these real-life relationships
    in a compact form, facilitating tasks such as visualization, clustering, or predictive
    modeling.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are numerous strategies to derive these embeddings, each with its unique
    approach and application: from classical graph algorithms that use the network’s
    topology, to linear algebra techniques that decompose matrices representing the
    graph, and more advanced methods such as GNNs [1]. GNNs stand out because they
    can integrate the embedding process directly into the learning algorithm itself.'
  prefs: []
  type: TYPE_NORMAL
- en: In traditional machine learning workflows, embeddings are generated as a separate
    step, serving as a dimensionality-reduction technique in tasks such as regression
    or classification. However, GNNs merge embedding generation with the model’s learning
    process. As the network processes inputs through its layers, the embeddings are
    refined and updated, making the learning phase and the embedding phase inseparable.
    This means that GNNs learn the most informative representation of the graph data
    during training time.
  prefs: []
  type: TYPE_NORMAL
- en: Using graph embeddings can significantly enhance your data science and machine
    learning projects, especially when dealing with complex networked data. By capturing
    the essence of the graph in a lower-dimensional space, embeddings make it feasible
    to apply a variety of other machine learning techniques to graph data, opening
    up a world of possibilities for analysis and model building.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we begin with an introduction to graph embeddings and a case
    study on a graph of political book purchases. We start with Node2Vec (N2V) to
    establish a baseline with a non-GNN approach, guiding you through its practical
    application. In section 2.2, we shift to GNNs, offering a hands-on introduction
    to GNN-based embeddings, including setup, preprocessing, and visualization. Section
    2.3 provides a comparative analysis of N2V and GNN embeddings, highlighting their
    applications. The chapter then rounds off with a discussion of the theoretical
    aspects of these embedding methods, with a special focus on the principles behind
    N2V and the message-passing mechanism in GNNs. The process we take in this chapter
    is illustrated in figure 2.1.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/2-1.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 Summary of process and objectives in chapter 2
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Note  Code from this chapter can be found in notebook form at the GitHub repository
    ([https://mng.bz/qxnE](https://mng.bz/qxnE)). Colab links and data from this chapter
    can be accessed in the same location.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Creating embeddings with Node2Vec
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Understanding the relationships within a network is a core task in many fields,
    from social network analysis to biology and recommendation systems. In this section,
    we’ll explore how to create node embeddings using *Node2Vec (N2V)*, a technique
    inspired by Word2Vec from natural language processing (NLP) [2]. N2V captures
    the context of nodes within a graph by simulating random walks, allowing us to
    understand the neighborhood relationships between nodes in a low-dimensional space.
    This approach is effective for identifying patterns, clustering similar nodes,
    and preparing data for machine learning tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make this process accessible, we’ll use the `Node2Vec` Python library, which
    is beginner-friendly, although it may be slower on larger graphs. N2V helps create
    embeddings that capture the structural relationships between nodes, which we can
    then visualize to uncover insights about the graph’s structure. Our workflow involves
    several steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Load data and set N2V parameters.* We start by loading our graph data and
    initializing N2V with specific parameters to control the random walks, such as
    walk length and the number of walks per node.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Create embeddings.* N2V generates node embeddings by performing random walks
    on the graph, effectively summarizing each node’s local neighborhood into a vector
    format.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Transform embeddings.* The resulting embeddings are saved and then transformed
    into a format suitable for visualization.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Visualize embeddings in two dimensions.* We use UMAP, a dimensionality reduction
    technique, to project these embeddings into two dimensions, making it easier to
    visualize and interpret the results.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Our data is the Political Books dataset, which comprises books (nodes) connected
    by frequent co-purchases on Amazon.com during the 2004 US election period (edges)
    [3]. Using this dataset provides a compelling example of how N2V can reveal underlying
    patterns in co-purchasing behavior, potentially reflecting broader ideological
    groupings among book buyers [4]. Table 2.1 provides key information about the
    Political Books graph.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2.1 Overview of the Political Books dataset
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Books in the political genre co-purchased on Amazon.com |  |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Number of nodes (books)  | 105  |'
  prefs: []
  type: TYPE_TB
- en: '| Left-leaning nodes  | 41.0%  |'
  prefs: []
  type: TYPE_TB
- en: '| Right-leaning nodes  | 46.7%  |'
  prefs: []
  type: TYPE_TB
- en: '| Neutral nodes  | 12.4%  |'
  prefs: []
  type: TYPE_TB
- en: '| Number of edges Edges represent the prevalence of a co-purchase between two
    books.  | 441  |'
  prefs: []
  type: TYPE_TB
- en: 'The Political Books dataset contains the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Nodes* —Represent books about US politics sold by [Amazon.com](http://Amazon.com).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Edges* —Indicate frequent co-purchasing by the same buyers, as suggested by
    Amazon’s “customers who bought this book also bought these other books” feature.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In figure 2.2, books are shaded based on their political alignment—darker shade
    for liberal, lighter shade for conservative, and striped for neutral. The categories
    were assigned by Mark Newman through a qualitative analysis of book descriptions
    and reviews posted on Amazon.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/2-2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2 Graph visualization of the Political Books dataset. Right-leaning
    books (nodes) are in a lighter shade and are clustered in the top half of the
    figure, left-leaning are darker shaded circles and clustered in the lower half
    of the figure, and neutral political stance are dark squares and appear in the
    middle. When two nodes are connected, it indicates that they have been purchased
    together frequently on Amazon.com.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This dataset, compiled by Valdis Krebs and available through the GNN in Action
    repository ([https://mng.bz/qxnE](https://mng.bz/qxnE)) or the Carnegie Mellon
    University website ([https://mng.bz/mG8M](https://mng.bz/mG8M)), contains 105
    books (nodes) and 441 edges (co-purchases). If you want to learn more about the
    background of this dataset, Krebs has written an article with this information
    [4].
  prefs: []
  type: TYPE_NORMAL
- en: Using N2V, we aim to explore the structure of this collection of books, uncovering
    insights based on political leanings and the potential associations between different
    book categories. By visualizing the embeddings created by N2V, we can gain a better
    understanding of how books are grouped and which ones might share a common audience,
    providing valuable insights into consumer behavior during a politically charged
    period.
  prefs: []
  type: TYPE_NORMAL
- en: From the visualization, note that the data is already clustered in a logical
    way. This is thanks to the *Kamada-Kawai algorithm* graph algorithm, which exploits
    the topological data only without the metadata and is useful for visualizing the
    graph. This graph visualization technique positions nodes in a way that reflects
    their connections, aiming for an arrangement where closely connected nodes are
    near each other but less connected nodes are farther apart. It achieves this by
    treating the nodes like points connected by springs, iteratively adjusting their
    positions until the “tension” in the springs is minimized. This results in a layout
    that naturally reveals clusters and relationships within the graph based purely
    on its structure.
  prefs: []
  type: TYPE_NORMAL
- en: For the Political Books dataset, the Kamada-Kawai algorithm helps us visualize
    books (nodes) based on how often they are co-purchased on Amazon, without using
    any external information such as political alignment or book titles. This gives
    us an initial view of how books are grouped together by buying behavior. In the
    next steps, we’ll use methods such as N2V to create embeddings that capture more
    detailed patterns and further distinguish different book groups.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.1 Loading data, setting parameters, and creating embeddings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We use the `Node2Vec` and `NetworkX` libraries for our first hands-on encounter
    with graph embeddings. After installing these packages using pip, we load our
    dataset’s graph data, which is stored in .gml format (Graph Modeling Language,
    GML), using the `NetworkX` library and generate the embeddings with the `Node2Vec`
    library.
  prefs: []
  type: TYPE_NORMAL
- en: GML is a simple, human-readable plain text file format used to represent graph
    structures. It stores information about nodes, edges, and their attributes in
    a structured way, making it easy to read and write graph data. For instance, a
    .gml file might contain a list of nodes (e.g., books in our dataset) and edges
    (connections representing co-purchases) along with additional properties such
    as labels or weights. This format is widely used for exchanging graph data between
    different software and tools. By loading the .gml file with `NetworkX`, we can
    easily manipulate and analyze the graph in Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `Node2Vec` library’s `Node2Vec` function, we can use the following parameters
    to specify the calculations done and the properties of the output embedding:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Size of the embedding (*`dimensions`*)* —Think of this as how detailed each
    node’s profile is, as in how many different traits you’re noting down. The standard
    detail level is 128 traits, but you can tweak this based on how complex you want
    each node’s profile to be.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Length of each walk (*`Walk` `Length`*)* —This is about how far each random
    walk through your graph goes, with 80 steps being the usual journey. If you want
    to see more of the neighborhood around a node, increase this number.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Number of walks per node (*`Num` `Walks`*)* —This tells us how many times
    we’ll take a walk starting from each node. Starting with 10 walks gives a good
    overview, but if you want a fuller picture of a node’s surroundings, consider
    going on more walks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Backtracking control (Return Parameter,* `p`*)* —This setting helps decide
    if our walk should circle back to where it’s been. Setting it at 1 keeps things
    balanced, but adjusting it can make your walks more or less exploratory.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Exploration Depth (In-Out Parameter,* `q`*)* —This one’s about choosing between
    taking in the broader neighborhood scene (e.g., a breadth-first search with `q`
    greater than 1) or diving deep into specific paths (e.g., a depth-first search
    with `q` less than 1), with 1 being a mix of both.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adjust these settings based on what you’re looking to understand about your
    nodes and their connections. Want more depth? Tweak the exploration depth. Looking
    for broader context? Adjust the walk length and the number of walks. In addition,
    keep in mind that the size of your embeddings should match the level of detail
    you need. In general, it’s a good idea to try different combinations of these
    parameters to see the effect on the embeddings.
  prefs: []
  type: TYPE_NORMAL
- en: For this exercise, we’ll use the first four parameters. Deeper details on these
    parameters are found in section 2.4.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code in listing 2.1 begins by loading the graph into a variable called
    `books_ graph`, using the `read_gml` method from the `NetworkX` library. Next,
    a N2V `model` is initialized with the loaded graph. This model is set up with
    specific parameters: it will create 64-dimensional embeddings for each node, use
    walks of 30 steps long, perform 200 walks starting from each node to gather context,
    and run these operations in parallel across four workers to speed up the process.'
  prefs: []
  type: TYPE_NORMAL
- en: The N2V model is then trained with additional parameters defined in the `fit`
    method. This involves setting a context window size of 10 nodes around each target
    node to learn the embeddings, considering all nodes at least once (`min_count=1`),
    and processing four words (nodes, in this context) each time during training.
  prefs: []
  type: TYPE_NORMAL
- en: Once trained, we access the node embeddings using the `model`’s `wv` method
    (reflecting its NLP heritage, wv stands for word vectors). For our downstream
    tasks, we map each node to its embedding using a dictionary comprehension.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.1 Generating N2V embeddings
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Loads the graph data from a GML file into a NetworkX graph object'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Initializes the N2V model with specified parameters for the input graph'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Trains the N2V model'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Extracts and stores the node embeddings generated by the N2V model in a
    dictionary'
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.2 Demystifying embeddings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s explore what these embeddings are and why they are valuable. An *embedding*
    is a dense numerical vector that represents the identity of a node, edge, or graph
    in a way that captures essential information about its structure and relationships.
    In our context, an embedding created by N2V captures a node’s position and neighborhood
    within the graph using topological information. This means it summarizes how the
    node is connected to others, effectively capturing its role and importance in
    the network. Later, when we use GNNs to create embeddings, they will also encapsulate
    the node’s features, providing an even richer representation that includes both
    structure and attributes. We get deeper into theoretical aspects of embeddings
    in section 2.4\.
  prefs: []
  type: TYPE_NORMAL
- en: These embeddings are powerful because they transform complex, high-dimensional
    graph data into a fixed-size vector format that can be easily used in various
    analyses and machine learning tasks. For example, they allow us to perform exploratory
    data analysis by revealing patterns, clusters, and relationships within the graph.
    Beyond this, embeddings can be directly used as features in machine learning models,
    where each dimension of the vector represents a distinct feature. This is particularly
    useful in applications where understanding the structure and connections between
    data points, such as in social networks or recommendation systems, can significantly
    improve model performance.
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate, consider the node representing the book *Losing Bin Laden* in
    our Political Books dataset. Using the command `model.wv['Losing` `Bin` `Laden']`,
    we retrieve its dense vector embedding. This vector, shown in figure 2.3, captures
    various aspects of the book’s role within the network of co-purchased books, providing
    a compact, informative representation that can be used for further analysis or
    as input to other models.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/2-3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.3 Extracting the embedding for the node associated with the political
    book Losing Bin Laden. The output is a dense vector represented as a Python list.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: These embeddings can be used for exploratory data analysis to see the patterns
    and relationships in a graph. However, their usage extends further. One common
    application is to use these vectors as features in a machine learning problem
    that uses tabular data. In that case, each element in our embedding array will
    become a distinct feature column in the tabular data. This can add a rich representation
    of each node to complement other attributes in model training. In the next section,
    we’ll look at how to visualize these embeddings to gain deeper insights into the
    patterns and relationships they represent.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.3 Transforming and visualizing the embeddings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Visualization methods such as Uniform Manifold Approximation and Projection
    (UMAP) are powerful tools for reducing high-dimensional datasets into lower-dimensional
    space [5]. UMAP is particularly effective for identifying inherent clusters and
    visualizing complex structures that are difficult to perceive in high-dimensional
    data. Compared to other methods, such as t-SNE, UMAP excels in preserving both
    local and global structures, making it ideal for revealing patterns and relationships
    across different scales in the data.
  prefs: []
  type: TYPE_NORMAL
- en: While N2V generates embeddings by capturing the network structure of our data,
    UMAP takes these high-dimensional embeddings and maps them onto a lower-dimensional
    space (typically two or three dimensions). This mapping aims to keep similar nodes
    close together while also preserving broader structural relationships, providing
    a more comprehensive visualization of the graph’s topology. After obtaining our
    N2V embeddings and converting them into a numerical array, we initialize the UMAP
    model with two components to project our data onto a 2D plane. By carefully selecting
    parameters such as the number of neighbors and minimum distance, UMAP can balance
    between revealing fine-grained local relationships and maintaining global distances
    between clusters.
  prefs: []
  type: TYPE_NORMAL
- en: By using UMAP, we gain a more accurate and interpretable visualization of our
    graph embeddings as shown in the following listing, allowing us to explore and
    analyze patterns, clusters, and structures more effectively than with traditional
    methods such as t-SNE.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.2 Visualizing the embeddings using UMAP
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Transforms the embeddings into a list of vectors for UMAP'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Initializes and fits UMAP'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Plots the nodes with UMAP embeddings and color by their value'
  prefs: []
  type: TYPE_NORMAL
- en: The resultant figure 2.4 encapsulates the political book graph’s embeddings
    as distilled by N2V and subsequently visualized through UMAP. The nodes appear
    in different shades according to their political alignment. The visualization
    unfolds a discernible structure, with potential clusters that correspond to the
    various political leanings.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/2-4.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.4 Embeddings of the Political Books dataset graph generated by N2V
    and visualized using UMAP. Shape and shading variations distinguish the three
    political classes.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: You might wonder why we don’t just reduce the dimensions of the N2V embeddings
    from `64` to `2` and visualize them directly, bypassing UMAP altogether? In listing
    2.3, we show this approach, applying a 2D N2V transformation directly to our `books_graph`
    object. (For more technical detail and theory of these methods, see section 2.4.)
  prefs: []
  type: TYPE_NORMAL
- en: The `dimensions` parameter is set to `2`, aiming for a direct 2D representation
    suitable for immediate visualization without further dimensionality reduction.
    The other parameters are kept the same.
  prefs: []
  type: TYPE_NORMAL
- en: Once the model is fitted with the specified window and word batch settings,
    we extract the 2D embeddings and store them in a dictionary keyed by the string
    representation of each node. This enables a direct mapping from the node to its
    embedding vector.
  prefs: []
  type: TYPE_NORMAL
- en: The extracted 2D points are compiled into a NumPy array and plotted. We use
    the standard `Matplotlib` library to create a scatterplot of these points using
    the prepared color scheme to represent the political leaning of each node visually.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.3 Visualizing 2D N2V embeddings without t-SNE
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Initializes N2V with 2D embeddings for visualization'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Trains N2V model with specified window and walks settings'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Maps nodes to their 2D embeddings'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Forms an array of 2D points for each node’s embedding'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Plots the 2D embeddings with specified node colors'
  prefs: []
  type: TYPE_NORMAL
- en: The outcome shows how the books are separated by political leanings, similar
    to the UMAP result, but where the books are more bunched together (see figure
    2.5). The two embeddings are then shown in figure 2.6.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/2-5.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.5 Embeddings of the Political Books dataset graph generated and visualized
    by N2V for two dimensions. Shape and shading variations distinguish the three
    political classes. Here, we see a similar clustering by political leaning as earlier
    in figure 2.4 but more bunched together.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/2-6.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.6 Comparison of embeddings generated by N2V and t-SNE and a direct
    visualization of 2D Node2Vec
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: It’s clear that both methods know to separate the books into groups based on
    political leanings. N2V is less expressive in how it separates the books, bunching
    them together across the two dimensions. Meanwhile, UMAP is better for spreading
    out the books in two dimensions. The relevant benefit or information contained
    within these dimensions depends on the task at hand.
  prefs: []
  type: TYPE_NORMAL
- en: '2.1.4 Beyond visualization: Applications and considerations of N2V embeddings'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While visualizing N2V embeddings offers intuitive insights into the dataset’s
    structure, their usage extends far beyond graphical representation. N2V is an
    embedding method designed specifically for graphs; it captures both the local
    and global structural properties of nodes by simulating random walks through the
    graph. This process allows N2V to create dense, numerical vectors that summarize
    the position and context of each node within the overall network.
  prefs: []
  type: TYPE_NORMAL
- en: These embeddings can then serve as feature-rich inputs for a variety of machine
    learning tasks, such as classification, recommendation, or clustering. For example,
    in our Political Books dataset, embeddings could help predict a book’s political
    leaning based on its co-purchase patterns or could recommend books to users with
    similar political interests. They might even be used to forecast future sales
    based on the content of a book.
  prefs: []
  type: TYPE_NORMAL
- en: However, it’s important to understand the nature of N2V’s learning approach,
    which is *transductive*. Transductive learning is designed to work only with the
    specific dataset it was trained on and can’t generalize to new, unseen nodes without
    retraining the model. This characteristic makes N2V highly effective for static
    datasets where all nodes and edges are known up front but less suitable for dynamic
    settings where new data points or connections frequently appear. Essentially,
    N2V focuses on extracting detailed patterns and relationships from the existing
    graph rather than developing a model that can easily adapt to new data.
  prefs: []
  type: TYPE_NORMAL
- en: While this transductive nature has its limitations, it also offers significant
    advantages. Because N2V uses the full structure of the graph during training,
    it can capture intricate relationships and dependencies that might be missed by
    more generalized methods. This makes N2V particularly powerful for tasks where
    the complete, fixed structure of the data is known and stable. However, to apply
    N2V effectively, it’s crucial to ensure that the graph data is represented in
    a way that captures all relevant features. In some cases, additional edges or
    nodes may need to be added to the graph to fully represent the underlying relationships.
  prefs: []
  type: TYPE_NORMAL
- en: For those interested in a deeper understanding of transductive models and how
    N2V’s approach compares to other methods, further details are provided in section
    2.4.2\. That section will explore the tradeoffs between transductive and inductive
    learning in greater depth [6, 7], helping you understand when each approach is
    most appropriate.
  prefs: []
  type: TYPE_NORMAL
- en: While N2V is effective for generating embeddings that capture the structure
    of a fixed graph, real-world data often demands a more flexible and generalizable
    approach. This need brings us to our first GNN architecture for creating node
    embeddings. Unlike N2V, which is a transductive method limited to the specific
    nodes and edges in the training data, GNNs can learn in an *inductive* manner.
    This means GNNs are capable of generalizing to new, unseen nodes or edges without
    requiring retraining on the entire graph.
  prefs: []
  type: TYPE_NORMAL
- en: GNNs achieve this by not only understanding the network’s complex structure
    but also by incorporating node features and relationships into the learning process.
    This approach allows GNNs to adapt dynamically to changes in the graph, making
    them well-suited for applications where the data is continually evolving. The
    shift from N2V to GNNs represents a key transition from focusing on deep analysis
    within a static dataset to a broader applicability across diverse, evolving networks.
    This adaptability sets the stage for a wider range of graph-based machine learning
    applications that require flexibility and scalability. In the next section, we’ll
    explore how GNNs go beyond the capabilities of N2V and other transductive methods,
    allowing for more versatile and powerful models that can handle the dynamic nature
    of real-world data.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Creating embeddings with a GNN
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While N2V provides a powerful method for generating embeddings by capturing
    the local and global structure of a graph, it’s fundamentally a transductive approach,
    meaning it can’t easily generalize to unseen nodes or edges without retraining.
    Although there have been extensions to N2V that enable it to work in inductive
    settings, GNNs are inherently designed for inductive learning. This means they
    can learn general patterns from the graph data that allow them to make predictions
    or to generate embeddings for new nodes or edges without needing to retrain the
    entire model. This gives GNNs a significant edge in scenarios where flexibility
    and adaptability are crucial.
  prefs: []
  type: TYPE_NORMAL
- en: GNNs not only incorporate the structural information of the graph, like N2V,
    but they also use node features to create richer representations. This dual capacity
    allows GNNs to learn both the complex relationships within the graph and the specific
    characteristics of individual nodes, enabling them to excel in tasks where both
    types of information are important.
  prefs: []
  type: TYPE_NORMAL
- en: That said, while GNNs have demonstrated impressive performance across many applications,
    they don’t universally outperform methods such as N2V in all cases. For instance,
    N2V and other random walk-based methods can sometimes perform better in scenarios
    where labeled data is scarce or noisy, thanks to their ability to work with just
    the graph structure without needing additional node features.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.1 Constructing the embeddings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unlike N2V, GNNs learn graph representations and perform tasks such as node
    classification or link prediction simultaneously during training. Information
    from the entire graph is processed through successive GNN layers, each refining
    the node embeddings without requiring a separate step for their creation.
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate how a GNN extracts features from graph data, we’ll perform a
    straightforward pass-through using an untrained model to generate preliminary
    embeddings. Even without the optimization typically involved in training, this
    approach will show how GNNs use message passing (explored further in section 2.4.4)
    to update embeddings, capturing both the graph’s structure and its node features.
    When optimization is added, these embeddings become tailored to specific tasks
    such as node classification or link prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Defining our GNN architecture
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We initiate our process by defining a simple GCN architecture, as shown in listing
    2.4\. Our `SimpleGNN` class inherits from `torch.nn.Module` and is composed of
    two `GCNConv` layers, which are the building blocks of our GNN. This architecture
    is shown in figure 2.7, consisting of the first layer, a message passing layer
    (`self.conv1`), an activation (`torch.relu`), a dropout layer (`torch.dropout`),
    and a second message passing layer.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.4 Our `SimpleGNN` class
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Initializes the GNN class with input and hidden layer sizes'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 First GCN layer from input features to hidden channels'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Second GCN layer within the hidden space'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Forward pass function defines data flow'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 First GCN layer processing'
  prefs: []
  type: TYPE_NORMAL
- en: '#6 Activation function for nonlinearity'
  prefs: []
  type: TYPE_NORMAL
- en: '#7 Dropout for regularization during training'
  prefs: []
  type: TYPE_NORMAL
- en: '#8 Second GCN layer processing'
  prefs: []
  type: TYPE_NORMAL
- en: '#9 Returns the final node embeddings'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/2-7.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.7 Architecture diagram of the `SimpleGNN` model
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Let’s talk about the architecture aspects specific to GNNs. The activation and
    dropout are common in many deep learning scenarios. The GNN layers, however, are
    different from conventional deep learning layers in a fundamental way. The core
    principle that allows GNNs to learn from graph data is message passing. For each
    GNN layer, in addition to updating the layer’s weights, a “message” is gathered
    from every node or edge neighborhood and used to update an embedding. Essentially,
    each node sends messages to its neighbors and simultaneously receives messages
    from them. For every node, its new embedding is computed by combining its own
    features with the aggregated messages from its neighbors, through a combination
    of nonlinear transformations.
  prefs: []
  type: TYPE_NORMAL
- en: In this example, we’re going to be using a graph convolutional network (GCN)
    to act as our message-passing GNN layers. We describe GCNs in much more detail
    in chapter 3\. For now, you just need to know that GCNs act as message-passing
    layers that are critical in constructing embeddings.
  prefs: []
  type: TYPE_NORMAL
- en: Data preparation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Next, we prepare our data. We’ll start with the same graph from the previous
    section, `books_gml`, in its `NetworkX` form. We have to convert this `NetworkX`
    object into a tensor form that is suitable to use with PyTorch operations. Because
    PyTorch Geometric (PyG) has many functions that convert graph objects, we can
    do this quite simply with `data` `=` `from_NetworkX(gml_graph)`. Method `from_NetworkX`
    specifically translates the edge lists and node/edge attributes into PyTorch tensors.
  prefs: []
  type: TYPE_NORMAL
- en: For GNNs, generating node embeddings requires initializing node features. In
    our case, we don’t have any predefined node features. When no node features are
    available or they aren’t informative, it’s common practice to initialize the node
    features randomly. A more effective approach is to use *Xavier initialization*,
    which sets the initial node features with values drawn from a distribution that
    keeps the variety of activations consistent across layers. This technique ensures
    that the model starts with a balanced representation, preventing problems such
    as vanishing or exploding gradients.
  prefs: []
  type: TYPE_NORMAL
- en: 'By initializing `data.x` with Xavier initialization, we provide the GNN with
    a starting point that allows it to learn meaningful node embeddings from noninformative
    features. During training, the network adjusts these initial values to minimize
    the loss function. When the loss function is aligned with a specific target, such
    as node prediction, the embeddings learned from the initial random features will
    become tailored to the task at hand, resulting in more effective representations.
    We randomize the node features using the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We could have also used the embeddings from the N2V exercise to use as node
    features. Recall the `node_embeddings` object from section 2.1.3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'From this, we can convert the node embedding to a PyTorch tensor object and
    assign it to the node feature object, `data.x`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Passing the graph through the GNN
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: With the structure of our GNN model defined and our graph data formatted for
    PyG, we proceed to the embedding generation step. We initialize our model, `SimpleGNN`,
    specifying the number of features for each node and the size of the hidden channels
    within the network.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Here, we specify 64 hidden channels because we want to compare the resulting
    embeddings to the ones we produced using the `node2vec` method, which had 64 dimensions.
    Because the second GNN layer is the last layer, the output will be a 64-element
    vector.
  prefs: []
  type: TYPE_NORMAL
- en: Once initialized, we switch the model to evaluation mode using `model.eval()`.
    This mode is used during inference or validation phases when we want to make predictions
    or assess model performance without modifying the model’s parameters. Specifically,
    `model.eval()` turns off certain behaviors specific to training, such as *dropout*,
    which randomly deactivates some neurons to prevent overfitting, and *batch normaliza**tion*,
    which normalizes inputs across a mini-batch. By disabling these features, the
    model provides consistent and deterministic outputs, ensuring that the evaluation
    accurately reflects its true performance on unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to disable gradient computations because they’re not necessary
    for the forward pass and embedding generation. So, we employ `torch.no_grad()`,
    which ensures that the computational graph that records operations for backpropagation
    isn’t constructed, preventing us from accidentally changing performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we pass our node-feature matrix (`data.x)` and the edge index (`data.edge_
    index`) through the model. The result is `gnn_embeddings`, a tensor where each
    row corresponds to the embedding of a node in our graph—a numerical representation
    learned by our GNN, ready for downstream tasks such as visualization or classification:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'After producing these embeddings, we use UMAP to visualize them, as we did
    in section 2.1.3\. Since we’ve been working with PyTorch tensor data types running
    on a GPU, we need to convert our embeddings to a NumPy array data type to use
    analysis methods outside of PyTorch, which are done on a CPU:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: With this conversion, we can produce the UMAP calculations and visualization
    following the process we used in the N2V case. The resulting scatterplot (figure
    2.8) is a first glimpse at the clusters within our graph. We add different shadings
    based on each node’s label (left-, right-, or neutral-leaning) to see that similar
    leaning books are fairly well grouped, given that these embeddings were constructed
    from topology alone.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s discuss both how GNN embeddings are used and how they differ from
    those produced with N2V.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/2-8.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.8 Visualization of embeddings generated from passing a graph through
    a GNN
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 2.2.2 GNN vs. N2V embeddings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Throughout this book, we predominantly use GNNs to generate embeddings because
    this embedding process is intrinsic to a GNN’s architecture. While embeddings
    play a pivotal role in the methodologies and applications we explore in the rest
    of the book, their presence is often subtle and not always highlighted. This approach
    allows us to focus on the broader concepts and applications of GNN-based machine
    learning without getting slowed down by the technicalities. Nonetheless, it’s
    important to acknowledge that the underlying power and adaptability of embeddings
    are central to the advanced techniques and insights we get into throughout the
    text.
  prefs: []
  type: TYPE_NORMAL
- en: GNN-produced node embeddings are particularly powerful because they enable us
    to tackle a broad range of graph-related tasks by using their inductive nature.
    Inductive learning allows these embeddings to generalize to new, unseen nodes
    or even entirely new graphs without needing to retrain the model. In contrast,
    N2V embeddings are limited to the specific graphs they were trained on and can’t
    easily adapt to new data. Let’s reiterate the key ways in which GNN embeddings
    differ from other embedding methods, such as N2V [1, 3].
  prefs: []
  type: TYPE_NORMAL
- en: Adaptability to new graphs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One of the critical features of GNN embeddings is their adaptability. Because
    GNNs learn a function that maps node features to embeddings, this function can
    be applied to nodes in new graphs without needing to be retrained, provided the
    nodes have similar feature spaces. This inductive capability is particularly valuable
    in dynamic environments where the graph may evolve over time or in applications
    where the model needs to be applied to different but structurally similar graphs.
    N2V, on the other hand, needs to be reapplied for each new graph or set of nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Enhanced feature integration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: GNNs inherently consider node features during the embedding process, allowing
    for a complex and nuanced representation of each node. This integration of node
    features, alongside the structural information, offers a more comprehensive view
    compared to N2V and other methods that focus on a graph’s topology. This capability
    makes GNN embeddings particularly suited for tasks where node features contain
    significant additional information.
  prefs: []
  type: TYPE_NORMAL
- en: Task-specific optimization
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: GNN embeddings are trained alongside specific tasks, such as node classification,
    link prediction, or even graph classification. Through end-to-end training, the
    GNN model learns to optimize the embeddings for the task at hand, leading to potentially
    higher performance and efficiency compared to using pre-generated embeddings such
    as those from N2V.
  prefs: []
  type: TYPE_NORMAL
- en: That said, while GNN embeddings offer clear advantages in terms of adaptability
    and applicability to new data, N2V embeddings have their strengths, particularly
    in capturing nuanced patterns within a specific graph’s structure. In practice,
    the choice between GNN and N2V embeddings may depend on the specific requirements
    of the task, the nature of the graph data, and the constraints of the computational
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: For tasks where the graph structure is static and well-defined, N2V might provide
    a simpler and computationally efficient solution. Conversely, for dynamic graphs,
    large-scale applications, or scenarios requiring the incorporation of node features,
    GNNs will often be the more robust and versatile choice. Additionally, when the
    task itself is not well-defined and the work is exploratory, N2V is likely faster
    and easier to use.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve now successfully built our first GNN embedding. This is the key first
    step for all GNN models, and everything from this point will build on it. In the
    next section, we give an example of some of these next steps and show how to use
    embeddings to solve a machine learning problem.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 Using node embeddings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Semi-supervised learning, which involves a combination of labeled and unlabeled
    data, provides a valuable opportunity to compare different embedding techniques.
    In this chapter, we’ll explore how GNN and N2V embeddings can be used to predict
    labels when the majority of the data lacks labels.
  prefs: []
  type: TYPE_NORMAL
- en: Our task involves the Political Books dataset (`books_graph`), where nodes represent
    political books and edges indicate co-purchase relationships. To make the process
    clearer, let’s review the steps taken so far and outline our next steps, as illustrated
    in figure 2.9.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/2-9.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.9 Overview of steps taken in chapter 2
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We began with the `books_graph` dataset in graph format and performed light
    preprocessing to prepare the data for embedding. For N2V, this involved converting
    the dataset from a .gml file to a `NetworkX` format. For the GNN-based embeddings,
    we converted the `NetworkX` graph into a PyTorch tensor and initialized the node
    features using Xavier initialization to ensure balanced variability across layers.
  prefs: []
  type: TYPE_NORMAL
- en: After preparing the data, we generated embeddings using both N2V and GCNs. Now,
    in this section, we’ll apply these embeddings to a semi-supervised classification
    problem. This involves further processing to define the classification task, where
    only 20% of the book labels are retained, simulating a realistic scenario with
    sparse labeled data.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll use the two sets of embeddings (N2V and GCN) with two different classifiers:
    a random forest classifier (to use the embeddings as tabular features) and a GCN
    classifier (to use the graph structure and node features). The goal is to predict
    the political orientation of the books, with the remaining 80% of the labels inferred
    based on the given embeddings.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.1 Data preprocessing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To start, we do a little more preprocessing to our `books_gml` dataset (see
    listing 2.5). We must format the labels in a suitable way for the learning process.
    Because all the nodes are labeled, we also have to set up the semi-supervised
    problem by randomly selecting the nodes from which we hide the labels.
  prefs: []
  type: TYPE_NORMAL
- en: Nodes associated with attribute `'c'` are classified as `'right'`, while those
    with `'l'` are classified as `'left'`. Nodes that don’t fit these criteria, including
    those with neutral or unspecified attributes, are categorized as `'neutral'`.
    These classifications are then placed into a NumPy array, `labels`, for optimized
    computational handling.
  prefs: []
  type: TYPE_NORMAL
- en: Then, an array, `indices`, is created, representing the positional indexes of
    all nodes within the dataset. A subset of these indices, corresponding to 20%
    of the total node count, is designated as our labeled data.
  prefs: []
  type: TYPE_NORMAL
- en: To manage the labeled and unlabeled data, Boolean masks, `labelled_mask` and
    `unlabelled_mask`, are initialized and populated. The `labelled_mask` is set to
    `True` for indices selected as labeled; these are the ground truth labels for
    corresponding nodes. Similarly, `unlabelled_mask` is set to `False`. These masks
    segment the dataset for training and evaluation, ensuring that algorithms are
    correctly trained and validated on the correct subsets of data.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.5 Preprocessing for semi-supervised problem
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Extracts labels and handles neutral values'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Random seed for reproducibility'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Indices of all nodes'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 20% of data to keep as labeled'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Selects a subset of indices to remain labeled'
  prefs: []
  type: TYPE_NORMAL
- en: '#6 Initializes masks for labeled and unlabeled data'
  prefs: []
  type: TYPE_NORMAL
- en: '#7 Updates masks'
  prefs: []
  type: TYPE_NORMAL
- en: '#8 Uses masks to split the dataset'
  prefs: []
  type: TYPE_NORMAL
- en: '#9 Transformed labels to numerical form'
  prefs: []
  type: TYPE_NORMAL
- en: Now we transform the data for model training, as shown in listing 2.6\. For
    the GNN-derived embeddings, `X_train_gnn` and `y_train_gnn` are assigned arrays
    of embeddings and corresponding numeric labels filtered by a `labelled_mask`.
    This mask is a Boolean array indicating which nodes in the graph are part of the
    labeled subset, ensuring that only data points with known labels are included
    in the training set.
  prefs: []
  type: TYPE_NORMAL
- en: For N2V embeddings, a similar approach is adopted with an added preprocessing
    step to align the embeddings with their corresponding labels. The embeddings for
    each node are aggregated into NumPy array `X_n2v` in the same order as the nodes
    appear in the `books_graph`. This ensures consistency between the embeddings and
    their labels, a crucial step for supervised learning tasks. Subsequently, `X_train_n2v`
    and `y_train_n2v` are populated with N2V embeddings and labels, again applying
    the `labelled_mask` to filter for the labeled data points.
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing 2.6 Preprocessing: constructing training data'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '#1 For GNN embeddings'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 For N2V embeddings'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Ensures N2V embeddings are in the same order as labels'
  prefs: []
  type: TYPE_NORMAL
- en: The extra alignment step for the N2V embeddings isn’t necessary for the GNN
    embeddings because GNN models inherently maintain the order of nodes as they process
    the entire graph in a structured manner. As a result, the output embeddings from
    a GNN are naturally ordered in correspondence with the input graph’s node order.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, N2V generates embeddings through independent random walks starting
    from each node, and the order of the resulting embeddings doesn’t necessarily
    match the order of nodes in the original graph data structure. Therefore, an explicit
    alignment step is required to ensure that each N2V embedding is correctly associated
    with its corresponding label, as extracted from the graph. This step is critical
    for supervised learning tasks where the correct matching of features (embeddings)
    to labels is essential for model training and evaluation. For this task, we use
    the attribute `index_to_key`, which contains the identifiers of the nodes in the
    order they are processed and stored within the model.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.2 Random forest classification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With our data prepped, we use GNN and N2V embeddings from sections 2.1 and 2.2
    as input features for a `RandomForestClassifier`, as shown in listing 2.7\.
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing 2.7 Preprocessing: constructing training data'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Classifier for GNN embeddings'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Classifier for N2V embeddings'
  prefs: []
  type: TYPE_NORMAL
- en: This approach allows us to directly compare the embeddings’ predictive power,
    where we compare results in table 2.2.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2.2 Classification performance
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Embedding Type | Accuracy | F1 Score |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| GNN  | 83.33%  | 82.01%  |'
  prefs: []
  type: TYPE_TB
- en: '| N2V  | 84.52%  | 80.72%  |'
  prefs: []
  type: TYPE_TB
- en: 'For this basic classification exercise, we’ll evaluate the performance of our
    models using two fundamental metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Accuracy —*This metric measures the proportion of correct predictions made
    by the model out of all predictions. It provides a straightforward assessment
    of how often the classifier correctly identifies the political orientation of
    the books. For instance, an accuracy of 84.52% means that the model correctly
    predicted the orientation of the books approximately 85 times out of 100\.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*F1 score*—This is a more nuanced metric that balances precision and recall,
    which is particularly useful in cases where the data is imbalanced—meaning the
    classes aren’t equally represented. It provides a harmonic mean of precision (the
    number of true positive predictions divided by the total number of positive predictions)
    and recall (the number of true positive predictions divided by the total number
    of actual positives). A higher F1 score indicates a model’s robust performance
    in correctly identifying both the presence and absence of the different classes,
    minimizing both false positives and false negatives.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The performance metrics reveal that N2V embeddings yield a slightly higher
    accuracy of 84.52% when used within a `RandomForestClassifier`, compared to 83.33%
    for GNN embeddings. However, GNN embeddings achieve a marginally better F1 score
    of 82.01%, compared to 80.72% for N2V embeddings. This nuanced difference underscores
    potential tradeoffs between the two embedding types: while N2V provides slightly
    better overall prediction accuracy, GNN embeddings may offer a more balanced performance
    across both the majority and minority classes.'
  prefs: []
  type: TYPE_NORMAL
- en: In general, the inductive nature of GNNs presents a robust framework for learning
    node representations for graphs of many different sizes. Even on smaller graphs,
    GNNs can effectively learn the underlying patterns and interactions between nodes,
    as evidenced by the higher F1 score, indicating a better balance between precision
    and recall in classification tasks.
  prefs: []
  type: TYPE_NORMAL
- en: In this context, the choice between GNN and N2V embeddings might also hinge
    on the specific goals of the analysis and the performance metrics of greatest
    interest. If the priority is achieving the highest possible accuracy and the dataset
    is unlikely to expand significantly, N2V could be the more suitable option. Conversely,
    if the task values a balance between precision and recall and there’s potential
    for applying the learned model to similar but new graphs, GNNs offer valuable
    flexibility and robustness, even for smaller datasets. Having used the N2V and
    GNN embeddings as inputs to a random forest model, let’s next study what happens
    when we use them as inputs to a full end-to-end GNN model.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.3 Embeddings in an end-to-end model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the previous section, we used GNN and N2V embeddings as static inputs to
    a traditional machine learning model, namely a random forest classifier. Here,
    we use an end-to-end GNN model applied to the same problem of label prediction.
    By *end-to-end*, we mean that the embeddings will be generated while we also predict
    labels. This means that the embeddings here won’t be static because, as the GNN
    learns, it will update the node embeddings.
  prefs: []
  type: TYPE_NORMAL
- en: 'To build this model, we’ll use the same tools as before—the `books_gml` dataset,
    and the `SimpleGNN` architecture. We’ll change the GNN slightly, by adding a log
    `softmax` activation at the end, to facilitate the output for a three-label classification
    problem. We’ll also slightly modify the output of our `SimpleGNN` class, allowing
    us to observe the embeddings as well as the predictive output. Our process includes
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Data prep
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model/architecture modification
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish the training loop
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Study performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Study embeddings pre-training and post-training
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data prep
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Assuming we use the `books_gml` data set, the process to transform it for use
    within the PyG framework remains the same. We’ll train two versions of the data:
    one with node features initialized randomly, and one with node features using
    the N2V embeddings.'
  prefs: []
  type: TYPE_NORMAL
- en: Model modification
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We use the same `SimpleGNN` class with modifications. First, in this enhanced
    version of the `SimpleGNN` class, we extend its functionality to provide a predictive
    output for each node. This is achieved by applying a log `softmax` activation
    to the embeddings produced by the second GCN layer. The log `softmax` output provides
    a normalized log probability distribution over the potential classes for each
    node for the classification task.
  prefs: []
  type: TYPE_NORMAL
- en: 'Second, we introduce dual outputs. The method returns two values: the raw embeddings
    from the `conv2` layer, which capture the node representations, and the log `softmax`
    of these embeddings. For us to observe both the embedding and the predictions,
    we have the `forward` method return both. In addition to this two-layer model,
    we added two layers to this architecture to have a four-layer model for comparison,
    as shown in listing 2.8.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Listing 2.8 Preprocessing: Constructing training data'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Predicts classes by passing the final conv layer through a log softmax'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 The class returns both the last embedding and the prediction.'
  prefs: []
  type: TYPE_NORMAL
- en: Establish the training loop
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We program the training loop for the GNN model in a semi-supervised learning
    context, as shown in listing 2.9\. This loop iterates over a specified number
    of epochs, where an epoch represents a complete pass through the entire training
    dataset. Within each epoch, the model’s parameters are updated to minimize a loss
    function, which quantifies the difference between the predicted outputs and the
    actual labels for the nodes in the training set. For those familiar with programming
    deep learning training loops, this should be very familiar. For those who could
    do with a quick reminder, the following describes some of the key steps in initializing
    and running the training loop:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Optimizer initialization*—The optimizer is initialized with a specific learning
    rate when it’s created. For example, here we use the Adam optimizer, with an initial
    learning rate of 0.01\.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Zeroing the gradients*—`optimizer.zero_grad()` ensures that the gradients
    are reset before each update, preventing them from accumulating across epochs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Model forward pass*—The model processes the node features (`data.x`) and the
    graph structure (`data.edge_index`) to produce output predictions. In semi-supervised
    settings, not all nodes have labels, so the model’s output includes predictions
    for both labeled and unlabeled nodes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Applying the training mask*—`out_masked` `=` `out[data.train_mask]` applies
    a mask to the model’s output to select only the predictions corresponding to labeled
    nodes. This is crucial in semi-supervised learning, where only a subset of nodes
    has known labels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Loss computation and backpropagation*—Loss function `loss_fn` compares the
    selected predictions (`out_masked`) with the true labels of the labeled nodes
    (`train_labels`). The `loss.backward()` call computes the gradient of the loss
    function with respect to the model parameters, which is then used to update these
    parameters via `optimizer.step()`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Logging*—The training loop prints the loss at regular intervals (every 10
    epochs in this case) to monitor the training progress.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Listing 2.9 Training loop
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Number of epochs'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Passes both node features and edge_index to the model'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Applies the training mask to select only the outputs for the labeled nodes'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Computes the loss using only the labeled nodes'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Prints the loss every 10 epochs'
  prefs: []
  type: TYPE_NORMAL
- en: This process iteratively refines the model’s parameters to improve its predictions
    on the labeled portion of the dataset, with the goal of learning a model that
    can generalize well to the unlabeled nodes and potentially to new, unseen data.
  prefs: []
  type: TYPE_NORMAL
- en: 'GNN results: Randomized vs. N2V node features'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let’s compare the classification task comparing the GNN performance from the
    randomized node features versus the N2V node features, as shown in table 2.3.
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 2.3 Classification performance of the GNN model where the input graph
    uses different node features**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Model | GNN Accuracy | GNN F1 Score |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Two-layer, randomized features  | 82.27%  | 82.14%  |'
  prefs: []
  type: TYPE_TB
- en: '| Two-layer, N2V features  | 87.79%  | 88.10%  |'
  prefs: []
  type: TYPE_TB
- en: '| Four-layer, randomized features  | 86.58%  | 86.90%  |'
  prefs: []
  type: TYPE_TB
- en: '| Four-layer, N2V features  | 88.99%  | 89.29%  |'
  prefs: []
  type: TYPE_TB
- en: The table summarizes the performance of different GNN models based on their
    accuracy and F1 score. It highlights that GNNs using N2V features consistently
    outperform those using randomized features across all model configurations. Specifically,
    the four-layer GNN with N2V features achieves the highest accuracy and F1 score,
    indicating the effectiveness of incorporating meaningful node representations
    derived from N2V embeddings. If we had more information about specific features
    for the node, as we do in chapter 3, the GNN embeddings may further improve accuracy
    for the GNN model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Results: GNN vs. random forest'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We now compare the performance of the GNN model from this section with the random
    forest model from the previous section (see table 2.4).
  prefs: []
  type: TYPE_NORMAL
- en: '**Table 2.4 Comparison of classification performance between the GNN model
    and the random forest model**'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Model | Data Input | Accuracy | F1 Score |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Random forest  | Embedding from GNN  | 83.33%  | 82.01%  |'
  prefs: []
  type: TYPE_TB
- en: '| Random forest  | Embedding from N2V  | 84.52%  | 80.72%  |'
  prefs: []
  type: TYPE_TB
- en: '| Two-layer simple GNN  | Graph with randomized node features  | 82.27%  |
    82.14%  |'
  prefs: []
  type: TYPE_TB
- en: '| Two-layer simple GNN  | Graph with n2v embeddings as node features  | 87.79%  |
    88.10%  |'
  prefs: []
  type: TYPE_TB
- en: '| Four-layer simple GNN  | Graph with randomized node features  | 86.58%  |
    86.90%  |'
  prefs: []
  type: TYPE_TB
- en: '| Four-layer simple GNN  | Graph with n2v embeddings as node features  | 88.99%  |
    89.29%  |'
  prefs: []
  type: TYPE_TB
- en: Figure 2.10 visualizes the results from table 2.4\. Overall, the GNN models
    outperformed the random forest models.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/2-10.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.10 Chart comparing the classification performance of the random forest
    with the GNN. Only one GNN model is outperformed by the random forest: The two-layer
    model trained on graph data with randomized node features is outperformed in terms
    of accuracy.'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: When comparing the performance of the GNN models with the random forest models,
    we can make several observations. Random forest, when trained on embeddings derived
    from GNN pass-through or N2V embeddings, achieves comparable accuracy to the two-layer
    simple GNN model. However, when considering the F1 score, both GNN models outperform
    random forest. Notably, the four-layer simple GNN model, especially when using
    N2V embeddings as features, exhibits significantly better performance than the
    random forest model, showcasing higher accuracy and F1 score.
  prefs: []
  type: TYPE_NORMAL
- en: This indicates that while random forest may outperform simpler GNN architectures
    such as the two-layer model in terms of accuracy, the more complex GNN architectures
    demonstrate superior performance in terms of F1 score, especially when using sophisticated
    node embeddings such as N2V. Therefore, the choice between random forest and GNN
    should consider both accuracy and F1 score, as well as the complexity of the model
    architecture and the nature of the input features, to achieve optimal performance
    for the given task and dataset.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that this short example didn’t extensively fine-tune
    either the GNN or the random forest models. Further optimization of both types
    of models could potentially lead to significant improvements in their performance.
    Fine-tuning hyperparameters, adjusting model architectures, and optimizing training
    processes could all contribute to enhancing the accuracy and F1 score of both
    GNNs and random forest classifiers. Therefore, while the results presented here
    provide starting insights into the performance on a small graph dataset, we suggest
    you try out the models and experiment with performance.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4 Under the Hood
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section gets deeper into the theoretical foundations of graph representations
    and embeddings, particularly in the context of GNNs. It emphasizes the importance
    of embeddings in transforming complex graph data into lower-dimensional, manageable
    forms that retain essential information.
  prefs: []
  type: TYPE_NORMAL
- en: 'We distinguish between two primary types of learning: transductive and inductive.
    Transductive methods, such as N2V, optimize embeddings specifically for the training
    data, making them effective within a known dataset but less adaptable to new data.
    In contrast, inductive methods, as exemplified by GNNs, enable generalization
    to new, unseen data by integrating both graph structure and node features during
    training. This section also examines the mechanisms behind N2V (random walk) and
    GNNs (message passing).'
  prefs: []
  type: TYPE_NORMAL
- en: 2.4.1 Representations and embeddings
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Understanding graph representations and the role of embeddings is crucial for
    effectively applying GNNs in machine learning. Representations convert complex
    graph data into simpler, manageable forms without losing essential information,
    facilitating analysis and interpretation of the underlying structures within graphs.
    In the context of GNNs, representations enable the processing of graph data in
    a way that is compatible with machine learning algorithms, ensuring that the rich
    and complex structures of graphs are preserved.
  prefs: []
  type: TYPE_NORMAL
- en: Traditional methods such as adjacency matrices and edge lists provide a foundational
    way to represent graph structures, but they often fall short in capturing richer
    information, such as node features or subtle topological details. This limitation
    is where graph embeddings come into play. A graph embedding is a low-dimensional
    vector representation of a graph, node, or edge that retains essential structural
    and relational information. Much like reducing a high-resolution image to a compact
    feature vector, embeddings condense the graph’s complexity while preserving its
    distinguishing characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: Embeddings simplify data handling and open new possibilities for machine learning
    applications. They enable visualization of complex graphs in two or three dimensions,
    allowing us to explore their inherent structures and relationships more intuitively.
    Furthermore, embeddings serve as versatile inputs for various downstream tasks,
    such as node classification and link prediction, as demonstrated in earlier sections
    of this chapter. By providing a bridge between raw graph data and machine learning
    models, embeddings are key to unlocking the full potential of GNNs.
  prefs: []
  type: TYPE_NORMAL
- en: The significance of node similarity and context
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: An important use of graph embeddings is to encapsulate the notion of similarity
    and context within the graph. In a spatial context, proximity (or similarity)
    often translates to a measurable distance or angle between points.
  prefs: []
  type: TYPE_NORMAL
- en: For graphs, however, these concepts are redefined in terms of connections and
    paths. The similarity between nodes can be interpreted through their connectivity,
    that is, how many “hops” or steps it takes to move from one node to another, or
    the likelihood of traversing from one node to another during random walks on the
    graph (figure 2.11).
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/2-11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.11 Comparison of similarity concepts: using distance on a plane (left)
    and using steps along a graph (right)'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Another way to think about proximity is in terms of probability: Given two
    nodes (node A and node B), what is the chance that I will encounter node B if
    I start to hop from node A? In figure 2.12, if the number of hops is 1, the probability
    is 0, as there is no way to reach node B from node A in one hop. However, if the
    number of hops is 2, then we need to first count to see how many different possible
    routes there are. Let’s also assume that no node can be encountered twice in a
    traversal and that each direction is equally likely. With these assumptions, there
    are three unique routes of 2 hops starting from node A. Of those, only one leads
    to node B. Thus, the probability is one out of three, or 33%. This probabilistic
    approach to measuring proximity between nodes offers a nuanced understanding of
    the graph’s topology, meaning that graph structures can be encoded within a probability
    space.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/2-12.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.12 Illustrating the notion of proximity computed in terms of probability:
    given a walk from node A, the probability of encountering node B is a measure
    of proximity.'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The ideas explained here are relevant as we approach the topic of inductive
    and transductive methods as applied to graph embeddings. Both of these methodologies
    use the notion of node proximity, although in distinct ways, to generate embeddings
    that capture the essence of node relationships and graph structure. Inductive
    methods excel in generalizing to accommodate new, unseen data, enabling models
    to adapt and learn beyond their initial training set. Conversely, transductive
    methods specialize in optimizing embeddings specifically for the training data
    itself, making them highly effective within their learned context but less flexible
    when introduced to new data.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4.2 Transductive and inductive methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The way an embedding is created determines the scope of its subsequent usage.
    Here we examine embedding methods that can be broadly classified as transductive
    and inductive. Transductive embedding methods learn representations for a fixed
    set of nodes in a single, static graph:'
  prefs: []
  type: TYPE_NORMAL
- en: These methods directly optimize individual embeddings for each node.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The entire graph structure must be available during training.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These methods can’t naturally generalize to unseen nodes or graphs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding new nodes requires retraining the entire model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples include DeepWalk [8], N2V, and matrix factorization approaches.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transductive methods allow us to reduce the scope of the prediction problem.
    For transduction, we’re only concerned with the data we’re presented with.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These methods are computationally costly for large amounts of data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Inductive embedding methods learn a function to generate embeddings, allowing
    generalization to unseen nodes and even entirely new graphs:'
  prefs: []
  type: TYPE_NORMAL
- en: These methods learn to aggregate and transform node features and local graph
    structure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These methods can generate embeddings for previously unseen nodes without retraining.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Node attributes or structural features are often used.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These methods are more flexible and scalable for dynamic or expanding graphs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples include GraphSAGE, GCNs, and graph attention networks (GATs).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s illustrate this with two examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Example 1: Email spam detection*—An inductive model for email spam detection
    is trained on a dataset of labeled emails (spam or not spam) and learns to generalize
    from the training data. Once trained, the model can classify new incoming emails
    as spam or not spam without needing to retrain.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transductive wouldn’t be better in this example because models would require
    retraining with every new batch of emails, making them computationally expensive
    and impractical for real-time spam detection.
  prefs: []
  type: TYPE_NORMAL
- en: '*Example 2: Semi-supervised learning for community detection in social networks*—A
    transductive model uses the entire graph to identify communities within a social
    network. Using a combination of labeled and unlabeled nodes, the model exploits
    the network in a better way: inductive models wouldn’t take full advantage of
    the specific network structure and node interconnections because they only process
    part of the data—the training set. This isn’t enough information for accurate
    community detection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Table 2.5 compares the types of graph representation we’ve learned so far, consisting
    of representations generated by both nonembedding methods, and embedding methods.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2.5 Different methods of graph representation
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Representation | Description | Examples |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Basic data representations  | • Great for analytical methods that involve
    network traversal • Useful for some node classification algorithms'
  prefs: []
  type: TYPE_NORMAL
- en: '• Information provided: Node and edge neighbors'
  prefs: []
  type: TYPE_NORMAL
- en: '| • Adjacency list • Edge list'
  prefs: []
  type: TYPE_NORMAL
- en: • Adjacency matrix
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Transductive (shallow) embeddings  | • Useless for data not trained on •
    Difficult to scale'
  prefs: []
  type: TYPE_NORMAL
- en: '| • DeepWalk • N2V'
  prefs: []
  type: TYPE_NORMAL
- en: • TransE
  prefs: []
  type: TYPE_NORMAL
- en: • RESCAL
  prefs: []
  type: TYPE_NORMAL
- en: • Graph factorization
  prefs: []
  type: TYPE_NORMAL
- en: • Spectral techniques
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Inductive embeddings  | • Models can be generalized to new and structurally
    different graphs • Represents data as vectors in continuous space'
  prefs: []
  type: TYPE_NORMAL
- en: • Learns a mapping from data (new and old) to positions within the continuous
    space
  prefs: []
  type: TYPE_NORMAL
- en: '| • GNNs can be used to inductively generate embeddings • Transformers'
  prefs: []
  type: TYPE_NORMAL
- en: • N2V with feature concatenation
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Summary of terms related to transductive embedding methods
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Two additional terms related to embedding methods and sometimes used interchangeably
    with it are *shallow methods* and *encoders*. Here, we’ll briefly distinguish
    these terms.
  prefs: []
  type: TYPE_NORMAL
- en: Transductive methods, explained earlier, are a large class of methods of which
    graph embedding is one application. So, outside of our present context of representation
    learning, the attributes of transductive learning remain the same.
  prefs: []
  type: TYPE_NORMAL
- en: In machine learning, *shallow* is often used to refer to the opposite of deep
    learning models or algorithms. Such models are distinguished from deep learning
    models in that they don’t use multiple processing layers to produce an output
    from input data. In our context of graph/node embeddings, this term also refers
    to methods that aren’t based on deep learning, but more specifically points to
    methods that mimic a simple lookup table, rather than a generalized model produced
    from a supervised learning algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Any method that reproduces a low dimensional representation of data, an embedding,
    is often known as an *encoder*. This encoder simply matches a given data point
    such as a node (or even an entire graph) to its respective embedding in low dimensional
    space. GNNs can be broadly understood as a class of encoders, similar to Transformers.
    However, there are specific GNN encoders, such as the graph autoencoder (GAE),
    which you’ll meet in chapter 5\.
  prefs: []
  type: TYPE_NORMAL
- en: '2.4.3 N2V: Random walks across graphs'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Random walk approaches construct embeddings by using random walks across the
    graph. With these, the similarity between two nodes, A and B, is defined as the
    probability that one will encounter node B on a random graph traversal from node
    A (as we described in section 2.4.1). These walks are unrestricted, with no restriction
    preventing a walk from backtracking or encountering the same node multiple times.
  prefs: []
  type: TYPE_NORMAL
- en: For each node, we perform a random walk within its neighborhood. As we perform
    more and more random walks, we begin to notice similarities in the types of nodes
    we encounter. A potential mental model is exploring a city or forest. In a distinct
    neighborhood, for example, as we take the same streets or paths multiple times,
    we begin to notice that houses have a similar style and trees have a similar species.
  prefs: []
  type: TYPE_NORMAL
- en: The result of a random walk method is a vector of nodes visited for each walk,
    with different starting nodes. In the upcoming figure 2.13, we show some examples
    of how we can walk (or search) across a graph.
  prefs: []
  type: TYPE_NORMAL
- en: DeepWalk is one method that creates embeddings by performing several random
    walks of a fixed size for each node and calculating embeddings from each of these.
    Here, any path is equally likely to occur, making the walks unbiased and meaning
    that all nodes connected by an edge are equally likely to be encountered at each
    step. The output for a DeepWalk on the graph in figure 2.13 might be the vector
    [u, s1, s3] or the vector [u, s1, s2, s4, s5]. Each of these vectors contains
    the unique nodes visited in a random walk.
  prefs: []
  type: TYPE_NORMAL
- en: 'N2V improved on DeepWalk by introducing tunable bias in these random walks.
    The idea is to be able to trade off learnings from a node’s close-by neighborhood
    and from further away. N2V captures this in two parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '`p`—Controls the probability that the path walked will return to the previous
    node.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`q`—Controls the probability of whether a depth-first search (DFS, a hopping
    strategy that emphasizes faraway nodes) or breadth-first search (BFS, a strategy
    that emphasizes nearby nodes). DFS and BFS are illustrated in figure 2.13, where
    we demonstrate what happens for four hops.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To mimic the DeepWalk algorithm, both `p` and `q` would be set to `0` such that
    the search is *unbiased*. So, for figure 2.13, the output for N2V could be [u,
    s1,s2] or [u,s4,s5,s6] depending on whether the walks are BFS or DFS.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/2-13.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.13 Depth-first search (DFS) and breadth first search (BFS) on a graph
    where embeddings are generated based on random walks using these graph-traversal
    strategies. DFS (light arrows) prioritizes going deep down one path, while BFS
    (dark arrows) prioritizes checking all adjacent and nearby paths.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Once we have the vector of nodes, we create embeddings by using a neural network
    to predict the most likely neighboring node for a given node. Usually, this neural
    network is shallow, with one hidden layer. After training, the hidden layer becomes
    that node’s embedding.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4.4 Message passing as deep learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Deep learning methods in general are composed of building blocks, or layers,
    that take some tensor-based input and then produce an output that is transformed
    as it flows through the various layers. At the end, more transformations and aggregations
    are applied to yield a prediction. However, often the output of the hidden layers
    is directly exploited for other tasks within the model architecture or are used
    as inputs to other models. This is what we saw in our classification problem in
    section 2.3\. We constructed a vector of visited nodes, and these nodes were then
    passed to a deep learning model. The deep learning model learned to predict future
    nodes based on a starting node. But the actual embeddings were contained within
    *the hidden layer* of the network.
  prefs: []
  type: TYPE_NORMAL
- en: Tip  For a refresher on deep learning, read *Deep Learning with Python* by François
    Chollet (Manning, 2021).
  prefs: []
  type: TYPE_NORMAL
- en: We show the classic architecture for a deep feed-forward neural network, specifically
    a multilayer perceptron (MLP), in figure 2.14\. Briefly, the network takes a node
    vector as input, and the hidden layers are trained to produce an output vector
    that achieves some task, such as identifying a node class. The input vector may
    be flattened images, and the output may be a single number reflecting where there
    is a dog or cat in the image. For the N2V example, the input is a vector of starting
    nodes, and the output is the corresponding other node vectors that are visited
    after traversing the graph from the starting node. In the image example, the output
    is the explicit task function, namely to classify images based on whether they
    contain a dog or cat. In N2V, the output is implicit in the graph structure. We
    know the subsequent nodes that are visited, but we’re interested in the way the
    network has encoded the data, that is, how it has built an embedding of the node
    data. This is contained within the hidden layer, where typically we just take
    the last layer.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/2-14.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.14 Structure of a multilayer perceptron
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: For GNNs, the input will be the entire graph structure, and the output will
    be the embeddings. Therefore, the model is explicit in how it constructs the embeddings.
    However, the output isn’t restricted to embeddings. Instead, we can have the output
    as a classification, such as whether the book has a specific political affiliation
    in that node in the graph. The embeddings are again implicit in the hidden layers.
    However, the entire process is wrapped into a single model, so we don’t need to
    extract this data. Instead, we’ve used the embeddings to achieve our goal, such
    as node classification.
  prefs: []
  type: TYPE_NORMAL
- en: While the architecture of GNNs is very different from feed-forward neural networks,
    there are some parallels. In many of the GNNs we learn about, a graph in tensor
    form is passed into the GNN architecture, and one or more iterations of message
    passing is applied. The message-passing process is shown in figure 2.15.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/2-15.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.15 Elements of our message-passing layer. Each message-passing layer
    consists of an aggregation, a transformation, and an update step.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In chapter 1, we first discussed the idea of message passing. In its simplest
    form, message passing reflects that we’re taking information or data from nodes
    or edges and sending it somewhere else [1]. The messages are the data, and we’re
    passing the messages across the structure of our graph. Each message can contain
    information from either sender or receiver, or often both.
  prefs: []
  type: TYPE_NORMAL
- en: We can now explain further why message passing is so important to GNNs. The
    message passing step updates the information about each node by using the node
    information and nodes neighborhood information (both in terms of nearby node data
    and the edge data connecting them). Message passing is how we construct representations
    about our graph. These are the critical mechanisms that build graph embeddings,
    which inform other tasks such as node classification. There are two important
    aspects to consider when constructing these node (or edge) embeddings.
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to think about what is inside a message. In our earlier example,
    we had a list of books on political topics. This dataset only had information
    about the books’ co-purchasing connections and their political leaning labels.
    However, if we had additional information such as the book length, author name,
    or even the synopsis, then those node features could be contained within our messages.
    However, it’s important to remember that it could also be edge data, such as when
    another book was bought together, that could also be contained in messages. In
    fact, sometimes messages can contain both node and edge data.
  prefs: []
  type: TYPE_NORMAL
- en: Second, we need to think about how much local information we want to consider
    when making each embedding. We want to know how much of the neighborhood to sample.
    We already discussed this when we introduced random walk methods. We need to define
    how many hops to take when sampling our graph.
  prefs: []
  type: TYPE_NORMAL
- en: Both the data and the number of hops are critical to message passing in GNNs.
    The features, either node or edge data, are the messages, and the number of hops
    is the number of times we pass a message. Both of these are controlled by the
    layers of a GNN. The number of hidden layers is the number of hops that we’ll
    be sending messages. The input to each hidden layer is the data contained in a
    message. This is almost always the case for GNNs but it’s worth noting that it
    isn’t always true. Sometimes, other mechanisms such as attention can determine
    the depth of message-passing samples from the neighborhood. We’ll discuss graph
    attention networks (GATs) in chapter 4\. Until then, understanding that the number
    of layers in a GNN reflects the number of hops undertaken during message passing
    is a good intuition to have.
  prefs: []
  type: TYPE_NORMAL
- en: For a feed-forward network, like the one on the left in figure 2.15, information
    is passed between the nodes of our neural network. In a GNN, this information
    comprises the messages that we send over our graph. For each message-passing step,
    the vertex in our neural network collects information from nodes or edges one
    hop away. So, if we want our node representations to take account of nodes from
    three hops away from each node, we need three hidden message-passing layers. Three
    layers may not seem like very many, but the amount of a graph we cover scales
    exponentially with the number of hops. Intuitively, we can understand this as
    a type of six degrees of separation principle—that all people are only six degrees
    of social separation apart from each other. This would mean that you and I could
    be connected by six short hops across the global combined social network.
  prefs: []
  type: TYPE_NORMAL
- en: Different message-passing schemes lead to different flavors of GNNs. So, for
    each GNN we study in this book, we’ll pay close attention to the math and code
    implementation for message passing. One important aspect is how we aggregate messages,
    which we’ll discuss in chapter 3 when we discuss GCNs in depth.
  prefs: []
  type: TYPE_NORMAL
- en: After message passing, the resulting tensor is passed through feed-forward layers
    that result in a prediction. In the left of figure 2.16, which illustrates a GNN
    model for node prediction, the data flows through message-passing layers, the
    tensor then passes through an additional MLP and activation function to output
    a prediction. For example, we could use our GNN to classify whether employees
    are likely to join a new company or have good recommendations.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/2-16.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.16 A simple GNN architecture diagram (left). A graph is input on the
    left, encountering node-information-passing layers. This is followed by MLP layers.
    After an activation is applied, a prediction is yielded. A GNN architecture (right).
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: However, as with the feed-forward neural network illustrated previously, we
    can also output just the hidden layers and work directly with that output. For
    GNNs, this output is the graph, node, or edge embeddings.
  prefs: []
  type: TYPE_NORMAL
- en: One final note on message passing in GNNs is that in each step in the message-passing
    layer of our GNNs, we’ll be passing information from nodes to another node one
    hop away. Importantly, a neural network then takes the data from the one-hop neighbors
    and applies a nonlinear transformation. This is the beauty of GNNs; we’re applying
    many small neural networks at the level of individual nodes and/or edges to build
    embeddings of the graph features. Therefore, when we say that a message-passing
    layer is like the first layer of a neural network, we’re really saying that it’s
    the first layer of many individual neural networks that are all learning on local
    node data or edge-specific data. In practice, the overall code constructing and
    training is the same as if it were one single transformation, but the intuition
    that we’re applying individual nonlinear transformations will become useful as
    we travel deeper into the workings of complex GNN models.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Node and graph embeddings are powerful methods to extract insights from our
    data, and they can serve as inputs/features in our machine learning models. There
    are several independent methods for generating such embeddings. GNNs have embedding
    built into the architecture.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Graph embeddings, including node and edge embeddings, serve as foundational
    techniques to transform complex graph data into structured formats suitable for
    machine learning tasks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We explored two main types of graph embeddings: N2V, a transductive method,
    and GNN-based embeddings, an inductive method, each with distinct characteristics
    and applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: N2V operates on fixed datasets using random walks to establish node contexts
    and similarities, but it doesn’t generalize to unseen data or graphs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GNNs, on the other hand, are versatile, inductive frameworks that can generate
    embeddings for new, unseen data, making them adaptable across different graph
    structures.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The comparison of embeddings in machine learning tasks, such as semi-supervised
    learning, reveals the importance of choosing the right embedding method based
    on the data size, complexity, and specific problem at hand.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Despite the effectiveness of random forest classifiers in handling both N2V
    and GNN embeddings for smaller graphs, GNNs demonstrate a unique ability to use
    graph topology and node features, particularly in larger and more complex graphs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Embeddings can be used as features in traditional machine learning models and
    in graph data visualization and insight extraction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
