- en: Chapter 6\. Real-Time Communication with Generative Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章. 使用生成模型进行实时通信
- en: This chapter will explore AI streaming workloads such as chatbots, detailing
    the use of real-time communication technologies like SSE and WebSocket. You will
    learn the difference between these technologies and how to implement model streaming
    by building endpoints for real-time text-to-text interactions.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将探讨AI流式工作负载，如聊天机器人，详细介绍了实时通信技术如SSE和WebSocket的使用。你将了解这些技术的区别以及如何通过构建实时文本到文本交互的端点来实现模型流。
- en: Web Communication Mechanisms
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 网络通信机制
- en: In the previous chapter, you learned about implementing concurrency in AI workflows
    by leveraging asynchronous programming, background tasks, and continuous batching.
    With concurrency, your services become more resilient to matching increased demand
    when multiple users access your application simultaneously. Concurrency solves
    the problem of allowing simultaneous users to access your service and helps to
    decrease the waiting times, yet AI data generation remains a resource-intensive
    and time-consuming task.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你学习了通过利用异步编程、后台任务和连续批处理来实现AI工作流程的并发性。通过并发，你的服务在多个用户同时访问应用程序时能够更好地应对增加的需求。并发解决了允许同时用户访问服务的问题，并有助于减少等待时间，但AI数据生成仍然是一个资源密集和时间消耗的任务。
- en: Up until this point, you’ve been building endpoints using the conventional HTTP
    communication where the client sends a request to the server. The web server processes
    the incoming requests and responds via HTTP messages.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你一直在使用传统的HTTP通信来构建端点，其中客户端向服务器发送请求。网络服务器处理传入的请求并通过HTTP消息进行响应。
- en: '[Figure 6-1](#client_server_architecture) shows the client-server architecture.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '[图6-1](#client_server_architecture)展示了客户端-服务器架构。'
- en: '![bgai 0601](assets/bgai_0601.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 0601](assets/bgai_0601.png)'
- en: 'Figure 6-1\. The client-server architecture (Source: [scaleyourapp.com](https://scaleyourapp.com))'
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-1. 客户端-服务器架构（来源：[scaleyourapp.com](https://scaleyourapp.com))
- en: Since the HTTP protocol is stateless, the server treats each incoming request
    completely independent and unrelated from other requests. This means that multiple
    incoming requests from differing clients wouldn’t affect how the server responds
    to each one. As an example, in a conversational AI service that doesn’t use a
    database, each request may provide the full conversation history and receive the
    correct response from the server.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 由于HTTP协议是无状态的，服务器将每个传入请求视为完全独立且与其他请求无关。这意味着来自不同客户端的多个传入请求不会影响服务器对每个请求的响应方式。例如，在一个不使用数据库的对话式AI服务中，每个请求可能提供完整的对话历史并从服务器接收正确的响应。
- en: The *HTTP request-response* model is a widely adopted API design pattern used
    across the web due to its simplicity. However, this approach becomes inadequate
    as soon as the client or the server needs real-time updates.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '*HTTP请求-响应*模型是一种广泛采用的API设计模式，因其简单性而被广泛应用于网络。然而，当客户端或服务器需要实时更新时，这种方法就变得不适用了。'
- en: In the standard HTTP request-response model, your services typically respond
    to the user’s request once it has been entirely processed. However, if the data
    generation process is lengthy and sluggish, your users will wait a long time and
    subsequently be inundated with lots of information at once. Imagine chatting to
    a bot that takes several minutes to reply, and once it does, you’re shown overwhelming
    blocks of text.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在标准的HTTP请求-响应模型中，你的服务通常在完全处理完用户的请求后响应。然而，如果数据生成过程漫长且缓慢，用户将等待很长时间，随后会一次性接收到大量信息。想象一下与一个需要几分钟才能回复的机器人聊天，一旦它回复，你会看到大量的文本信息。
- en: Alternatively, if you provide the data to the client as it’s being generated,
    rather than holding off until the entire generation process is complete, you can
    mitigate lengthy delays and deliver the information in digestible chunks. This
    approach not only enhances user experience but also maintains user engagement
    during the ongoing processing of their request.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果你在生成数据的同时将其提供给客户端，而不是等到整个生成过程完成，你可以减少长时间延迟，并以可消化的块形式提供信息。这种方法不仅提升了用户体验，而且在处理用户请求的过程中保持了用户的参与度。
- en: There will be cases where implementing real-time features can be overkill and
    escalate the development burden. For instance, some open source models or APIs
    lack the real-time generation capability. Furthermore, adding data streaming endpoints
    can add to the complexity of your system on both sides, the server and the client.
    It means having to handle exceptions differently and manage concurrent connections
    to the streaming endpoints to avoid memory leakage. If the client disconnects
    during a stream, there may be a chance for data loss or state drift between the
    server and the client. And, you may need to implement complex reconnection and
    state management logic to handle cases where the connection drops.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，实现实时功能可能会过度设计，并增加开发负担。例如，一些开源模型或API缺乏实时生成能力。此外，添加数据流端点可能会在服务器和客户端两方面增加系统的复杂性。这意味着需要以不同的方式处理异常，并管理对数据流端点的并发连接，以避免内存泄漏。如果客户端在流传输过程中断开连接，服务器和客户端之间可能会出现数据丢失或状态漂移。而且，你可能需要实现复杂的重新连接和状态管理逻辑来处理连接断开的情况。
- en: Maintaining many concurrent open connections can also put a burden on your servers
    and lead to an increase in hosting and infrastructure costs.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 维护许多并发打开的连接也可能给你的服务器带来负担，并导致托管和基础设施成本的增加。
- en: Equally important, you also need to consider the scalability of handling a large
    number of concurrent streams, your application’s latency requirements, and browser
    compatibilities with your chosen streaming protocol.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 同样重要的是，你还需要考虑处理大量并发流的可扩展性、你应用的延迟要求以及浏览器与所选流协议的兼容性。
- en: Note
  id: totrans-15
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Compared to traditional web applications that have some form of I/O or data
    processing latency, AI applications also have AI model inference latency, depending
    on the model you’re using.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 与具有某种形式的I/O或数据处理延迟的传统Web应用相比，AI应用还有AI模型推理延迟，这取决于你使用的模型。
- en: Since this latency can be significant, your AI services should be able to handle
    longer waiting times on both the server and client sides, including managing the
    user experience.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这种延迟可能很大，你的AI服务应该能够在服务器和客户端两方面处理更长的等待时间，包括管理用户体验。
- en: 'If your use case does benefit from real-time features, then you have a few
    architectural design patterns you can implement:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的用例确实从实时功能中获益，那么你可以实施以下几种架构设计模式：
- en: Regular/short polling
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定期/短轮询
- en: Long polling
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 长轮询
- en: SSE
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SSE
- en: WS
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WS
- en: The choice depends on your requirements for user experience, scalability, latency,
    development cost, and maintainability.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 选择取决于你对用户体验、可扩展性、延迟、开发成本和可维护性的要求。
- en: Let’s explore each option in more detail.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地探讨每个选项。
- en: Regular/Short Polling
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定期/短轮询
- en: A method to benefit from semi-real-time updates is to use *regular/short polling*,
    as shown in [Figure 6-2](#short_polling). In this polling mechanism, the client
    periodically sends HTTP requests to the server to check for updates at preconfigured
    intervals. The shorter the intervals, the closer you get to real-time updates
    but also the higher the traffic you will have to manage.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 要从半实时更新中获益的一种方法是使用*定期/短轮询*，如[图6-2](#short_polling)所示。在这种轮询机制中，客户端定期向服务器发送HTTP请求，以检查预配置间隔内的更新。间隔越短，你越接近实时更新，但同时也需要管理更高的流量。
- en: '![bgai 0602](assets/bgai_0602.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 0602](assets/bgai_0602.png)'
- en: Figure 6-2\. Regular/short polling
  id: totrans-28
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-2\. 定期/短轮询
- en: You can use this technique if you’re building a service to generate data such
    as images in batches. The client simply submits a request to start the batch job
    and is given a unique job/request identifier. It then periodically checks back
    with the server to confirm the status and outputs of the requested job. The server
    then responds with new data or provides an empty response (and perhaps a status
    update) if outputs are yet to be computed.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在构建一个用于批量生成数据（如图像）的服务，你可以使用这种技术。客户端只需提交一个请求以启动批处理作业，并得到一个唯一的作业/请求标识符。然后客户端定期与服务器联系，以确认请求作业的状态和输出。如果输出尚未计算，服务器则响应新数据或提供空响应（可能还有状态更新）。
- en: As you can imagine with short polling, you’ll end up with an excessive number
    of incoming requests that the server needs to respond to, even when there’s no
    new information. If you have multiple concurrent users, this approach can quickly
    overwhelm the server, which limits your application’s scalability. However, you
    can still reduce server load by using cached responses (i.e., executing status
    checks on the backend at a tolerable frequency) and implementing rate limiting,
    which you will learn more about in Chapters [9](ch09.html#ch09) and [10](ch10.html#ch10).
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 就像你可以想象到的短轮询一样，你最终会收到大量的传入请求，服务器需要对这些请求做出响应，即使没有新的信息。如果你有多个并发用户，这种方法可能会迅速压垮服务器，这限制了应用程序的可扩展性。然而，你仍然可以通过使用缓存响应（即在可容忍的频率上在后台执行状态检查）和实现速率限制来减少服务器负载，你将在第[9](ch09.html#ch09)章和第[10](ch10.html#ch10)章中了解更多关于速率限制的内容。
- en: A potential use case for short polling in AI services is when you have some
    in-progress batch or inference jobs. You can expose endpoints for your clients
    to use short polling to keep up-to-date with the status of these jobs. And, fetch
    the results when they’re completed.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在AI服务中，短轮询的一个潜在用例是当你有一些正在进行的批量或推理作业。你可以为客户端提供端点，让他们使用短轮询来保持这些作业状态的更新。当作业完成时，你可以获取结果。
- en: An alternative is to leverage long polling instead.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个选择是利用长轮询。
- en: Long Polling
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 长轮询
- en: If you want to reduce the burden on your server while continuing to leverage
    a real-time polling mechanism, you can implement *long polling* (see [Figure 6-3](#long_polling)),
    an improved version of regular/short polling.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在继续利用实时轮询机制的同时减轻服务器的负担，你可以实现*长轮询*（见[图6-3](#long_polling)），这是常规/短轮询的改进版本。
- en: '![bgai 0603](assets/bgai_0603.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 0603](assets/bgai_0603.png)'
- en: Figure 6-3\. Long polling
  id: totrans-36
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-3\. 长轮询
- en: With long polling, both the server and the client are configured to prevent
    *timeouts* (if possible) that occur when either the client or the server gives
    up on the prolonged request.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在长轮询中，服务器和客户端都被配置为防止（如果可能的话）当客户端或服务器放弃长时间请求时发生的*超时*。
- en: Tip
  id: totrans-38
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Timeouts are observed more often in a typical HTTP request-response cycle when
    a request takes an extended time to resolve or when there are network issues.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在典型的HTTP请求-响应周期中，当请求需要较长时间才能解决或存在网络问题时，通常会观察到超时。
- en: To implement long polling, the server keeps the incoming requests open (i.e.,
    hanging) until there is data available to send back. For instance, this can be
    useful when you have an LLM with unpredictable processing times. The client is
    instructed to wait for an extended period of time and avoid aborting and repeating
    the requests prematurely.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 要实现长轮询，服务器会保持传入的请求打开（即挂起），直到有数据可以发送回客户端。例如，当你有一个具有不可预测处理时间的LLM时，这可能会很有用。客户端被指示等待较长时间，并避免过早地终止和重复请求。
- en: You can use long polling if you need a simple API design and application architecture
    for processing prolonged jobs, such as multiple AI inferences. This technique
    allows you to avoid implementing a batch job manager to keep track of jobs for
    bulk data generation. Instead, the client requests remain open until they are
    processed, avoiding the constant short polling request-response cycle that can
    overload the server.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要一个简单的API设计和应用程序架构来处理长时间作业，如多个AI推理，你可以使用长轮询。这项技术允许你避免实现批处理作业管理器来跟踪大量数据生成作业。相反，客户端请求保持打开状态，直到它们被处理，避免了可能使服务器过载的持续短轮询请求-响应周期。
- en: While long polling sounds similar to the typical HTTP request-response model,
    it differs on how the client handles requests. In long polling, the client typically
    receives a single message per request. Once the server sends a response, the connection
    is closed. The client then immediately opens a new connection to wait for the
    next message. This process repeats, allowing the client to receive multiple messages
    over time, but each HTTP request-response cycle handles only one message.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然长轮询听起来与典型的HTTP请求-响应模型相似，但在客户端如何处理请求方面有所不同。在长轮询中，客户端通常在每个请求中接收一条消息。一旦服务器发送响应，连接就会关闭。然后客户端立即打开一个新的连接等待下一条消息。这个过程会重复，允许客户端随着时间的推移接收多条消息，但每个HTTP请求-响应周期只处理一条消息。
- en: Since long polling maintains an open connection until a message is available,
    it reduces the frequency of requests compared to short polling and implements
    a near-real-time communication mechanism. However, the server still has to hold
    onto unfulfilled requests, which consume server resources. Additionally, if there
    are multiple open requests by the same client, message ordering can be challenging
    to manage, potentially leading to out-of-order messages.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 由于长轮询会保持一个打开的连接，直到有消息可用，因此与短轮询相比，它减少了请求的频率，并实现了一种近似实时的通信机制。然而，服务器仍然需要保留未满足的请求，这会消耗服务器资源。此外，如果同一客户端有多个打开的请求，可能会难以管理消息顺序，可能导致消息顺序错误。
- en: If you don’t have a specific requirement for using polling mechanisms, a more
    modern alternative to polling mechanisms for real-time communication is SSE via
    the Event Source interface.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有使用轮询机制的具体要求，那么对于实时通信，一个更现代的轮询机制替代方案是通过事件源接口的SSE（单播服务器发送事件）。
- en: Server-Sent Events
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 服务器发送事件
- en: '*Server-sent events* (SSE) is an HTTP-based mechanism for establishing a persistent
    and unidirectional connection from the server to the client. While the connection
    is open, the server can continuously push updates to the client as data becomes
    available.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*服务器发送事件*（SSE）是一种基于HTTP的机制，用于从服务器到客户端建立持久和单向的连接。在连接打开期间，服务器可以在数据可用时持续向客户端推送更新。'
- en: Once the client establishes the persistent SSE connection with the server, it
    won’t need to re-establish it again, unlike the long polling mechanism where the
    client repeatedly sends requests to the server to maintain an open connection.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦客户端与服务器建立了持久的SSE连接，它就不再需要重新建立连接，这与长轮询机制不同，在长轮询机制中，客户端需要反复向服务器发送请求以保持连接打开。
- en: When you’re serving GenAI models, SSE will be a more suitable real-time communication
    mechanism compared to long polling. SSE is designed specifically for handling
    real-time events and is more efficient than long polling. Due to repeated opening
    and closing connections, long polling becomes resource intensive and leads to
    higher latency and overhead. SSE, on the other hand, supports automatic reconnection
    and event IDs to resume interrupted streams, which long polling lacks.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 当你提供GenAI（生成式人工智能）模型时，与长轮询相比，SSE将是一个更适合实时通信的机制。SSE专门设计用于处理实时事件，比长轮询更高效。由于反复打开和关闭连接，长轮询变得资源密集，导致更高的延迟和开销。另一方面，SSE支持自动重连和事件ID以恢复中断的流，这是长轮询所缺乏的。
- en: 'In SSE, the client makes a standard HTTP `GET` request with an `Accept:text/event-stream`
    header, and the server responds with a status code of `200` and a `Content-Type:
    text/event-stream` header. After this handshake, the server can send events to
    the client over the same connection.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '在SSE中，客户端通过带有`Accept:text/event-stream`头的标准HTTP `GET`请求，服务器响应状态码为`200`和带有`Content-Type:
    text/event-stream`头的响应。在此握手之后，服务器可以通过相同的连接向客户端发送事件。'
- en: While SSE should be your first choice for real-time applications, you can still
    opt for a simpler long polling mechanism where updates are infrequent or if your
    environment doesn’t support persistent connections.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然SSE应该是实时应用程序的首选，但你仍然可以选择一个更简单的长轮询机制，其中更新不频繁或如果你的环境不支持持久连接。
- en: One last important detail to note is that SSE connections are *unidirectional*,
    meaning that you send a regular HTTP request to the server, and you get the response
    via SSE. Therefore, they’re only suitable for applications that don’t need to
    send data to the server. You may have seen SSE in action within news feeds, notifications,
    and real-time dashboards like stock data charts.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个需要注意的重要细节是，SSE连接是**单向的**，这意味着你向服务器发送一个常规的HTTP请求，并通过SSE接收响应。因此，它们只适用于不需要向服务器发送数据的应用程序。你可能已经在新闻源、通知和实时仪表板（如股票数据图表）中看到过SSE的实际应用。
- en: Unsurprisingly, SSE also shines in chat applications when you need to stream
    LLM responses in a conversation. In this instance, the client can establish a
    separate persistent connection until the server fully streams the LLM’s response
    to the user.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 令人意外的是，当需要在对话中流式传输LLM（大型语言模型）的响应时，SSE在聊天应用中也表现出色。在这种情况下，客户端可以建立一个独立的持久连接，直到服务器完全将LLM的响应流式传输给用户。
- en: Note
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: ChatGPT leverages SSE under the hood to enable real-time responses to user queries.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT在底层利用SSE（单播服务器发送事件）来启用对用户查询的实时响应。
- en: '[Figure 6-4](#server_sent_events) shows how the SSE communication mechanism
    operates.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '[图6-4](#server_sent_events)展示了SSE通信机制的工作方式。'
- en: '![bgai 0604](assets/bgai_0604.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 0604](assets/bgai_0604.png)'
- en: Figure 6-4\. SSE
  id: totrans-57
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-4\. SSE
- en: To solidify your understanding, we will be building two mini-projects in this
    chapter using SSE. One to stream data from a mocked data generator, and another
    to stream LLM responses.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了巩固您的理解，我们将在本章中构建两个小型项目，使用SSE。一个是从模拟数据生成器中流式传输数据，另一个是流式传输LLM响应。
- en: You will learn more details about the SSE mechanism during the aforementioned
    projects.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述项目中，您将了解更多关于SSE机制的相关细节。
- en: In summary, SSE is excellent for establishing persistent unidirectional connections,
    but what if you need to both send and receive messages during a persistent connection?
    This is where WebSocket would come in handy.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，SSE非常适合建立持久的单向连接，但如果你需要在持久连接期间发送和接收消息呢？这就是WebSocket发挥作用的地方。
- en: WebSocket
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: WebSocket
- en: The last real-time communication mechanism to cover is WebSocket.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 最后要介绍的是实时通信机制——WebSocket。
- en: WebSocket is an excellent real-time communication mechanism for establishing
    persistent *bidirectional connections* between the client and the server for real-time
    chat, as well as voice and video applications with an AI model. A bidirectional
    connection means that both sides can send and receive real-time data in any order,
    as long as a persistent connection is open between the client and the server.
    It’s designed to work over standard HTTP ports to ensure compatibility with existing
    security measures. Web applications that require two-way communication with servers
    benefit the most from this mechanism as they can avoid the overhead and complexity
    of HTTP polling.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: WebSocket是一种优秀的实时通信机制，可以用于在客户端和服务器之间建立持久的**双向连接**，用于实时聊天、以及具有AI模型的语音和视频应用。双向连接意味着只要客户端和服务器之间保持持久连接，双方就可以在任何顺序发送和接收实时数据。它是设计在标准HTTP端口上工作的，以确保与现有安全措施的兼容性。需要与服务器进行双向通信的Web应用程序最能从这种机制中受益，因为它们可以避免HTTP轮询的开销和复杂性。
- en: You can use WebSocket in a variety of applications including social feeds, multiplayer
    games, financial feeds, location-based updates, multimedia chat, etc.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在各种应用程序中使用WebSocket，包括社交动态、多人游戏、财经动态、基于位置的更新、多媒体聊天等。
- en: Unlike all other communication mechanisms discussed so far, the WebSocket protocol
    doesn’t transfer data over HTTP after the initial handshake. Instead, the WebSocket
    protocol defined in the RFC 6455 specification implements a two-way messaging
    mechanism (full-duplex) over a single TCP connection. As a result, WebSocket is
    faster for data transmission than HTTP because it has less protocol overhead and
    operates at a lower level in the network protocol stack. This is because HTTP
    sits on top of TCP, so stripping back to TCP will be faster.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 与迄今为止讨论的所有其他通信机制不同，WebSocket协议在初始握手之后不在HTTP上传输数据。相反，RFC 6455规范中定义的WebSocket协议在单个TCP连接上实现了一种双向消息机制（全双工）。因此，WebSocket在数据传输方面比HTTP更快，因为它具有更少的协议开销，并在网络协议栈的较低级别运行。这是因为HTTP位于TCP之上，所以回退到TCP将会更快。
- en: Tip
  id: totrans-66
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: WebSocket keeps a socket open on both the client and the server for the duration
    of the connection. Note that this also makes servers stateful, which makes scaling
    trickier.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: WebSocket在连接期间在客户端和服务器上都保持套接字打开状态。请注意，这也使得服务器具有状态性，这使得扩展变得更加困难。
- en: You may now be wondering how the WebSocket protocol works.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可能想知道WebSocket协议是如何工作的。
- en: According to RFC 6455, to establish a WebSocket connection, the client sends
    an HTTP “upgrade” request to the server, asking to open a WebSocket connection.
    This is referred to as the *opening handshake*, which initiates the WebSocket
    connection lifecycle in the *CONNECTING* state.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 根据RFC 6455，为了建立WebSocket连接，客户端向服务器发送一个HTTP“升级”请求，请求打开一个WebSocket连接。这被称为**打开握手**，它启动WebSocket连接的生命周期，处于**连接中**状态。
- en: Warning
  id: totrans-70
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Your AI services should be able to handle multiple concurrent handshakes and
    also authenticate them before opening a connection. New connections can consume
    server resources, so they must be handled properly by your server.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 您的AI服务应该能够处理多个并发握手，并在打开连接之前对它们进行身份验证。新连接可能会消耗服务器资源，因此它们必须由您的服务器正确处理。
- en: The HTTP upgrade request should contain a set of required headers, as shown
    in [Example 6-1](#websocket_handshake).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP升级请求应包含一组必需的头部信息，如[示例6-1](#websocket_handshake)所示。
- en: Example 6-1\. WebSocket opening handshake over HTTP
  id: totrans-73
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例6-1. 通过HTTP的WebSocket打开握手
- en: '[PRE0]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-1)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-1)'
- en: Make an HTTP upgrade request to the WebSocket endpoint. WebSocket endpoints
    start with `ws://` instead of the typical `http://`.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 向 WebSocket 端点发送 HTTP 升级请求。WebSocket 端点以 `ws://` 开头，而不是典型的 `http://`。
- en: '[![2](assets/2.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-2)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-2)'
- en: Request to upgrade and open a WebSocket connection.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 请求升级并打开 WebSocket 连接。
- en: '[![3](assets/3.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-4)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-4)'
- en: Use a random, 16-byte, Base64-encoded string to ensure the server supports the
    WebSocket protocol.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一个随机的、16字节的 Base64 编码字符串以确保服务器支持 WebSocket 协议。
- en: '[![4](assets/4.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-5)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO1-5)'
- en: Use the `html-chat` or the `text-chat` subprotocol if `html-chat` is not available.
    Subprotocols regulate what data will be exchanged.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `html-chat` 不可用，请使用 `html-chat` 或 `text-chat` 子协议。子协议规定将交换什么数据。
- en: Warning
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: In production, always use secure WebSocket `wss://` endpoints.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中，始终使用安全的 WebSocket `wss://` 端点。
- en: The `wss://` protocol, similar to `https://`, is not only encrypted but also
    more reliable. That’s because `ws://` data is not encrypted and visible for any
    intermediary. Old proxy servers don’t know about WebSocket. They may see “strange”
    headers and abort the connection.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 与 `https://` 类似的 `wss://` 协议不仅加密，而且更可靠。这是因为 `ws://` 数据未加密且对任何中间代理可见。旧的代理服务器不了解
    WebSocket。它们可能看到“奇怪”的头部并终止连接。
- en: On the other hand, `wss://` is the secure version of WebSocket, running over
    Transport Layer Security (TLS), which encrypts the data at the sender and decrypts
    it at the receiver. So data packets are passed encrypted through proxies. They
    can’t see what’s inside and let them through.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，`wss://` 是 WebSocket 的安全版本，通过传输层安全性 (TLS) 运行，它对发送方的数据进行加密，并在接收方进行解密。因此数据包通过代理加密传输。代理无法看到里面的内容，并允许其通过。
- en: Once the WebSocket connection is established, text or binary messages can be
    transmitted in both directions in the form of *message frames*. The connection
    lifecycle is now in the *OPEN* state.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 WebSocket 连接建立，文本或二进制消息可以以*消息帧*的形式在两个方向上传输。连接生命周期现在处于*打开*状态。
- en: You can view the WebSocket communication mechanism in [Figure 6-5](#websockets).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[图 6-5](#websockets)中查看 WebSocket 通信机制。
- en: '![bgai 0605](assets/bgai_0605.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 0605](assets/bgai_0605.png)'
- en: Figure 6-5\. WS communication
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-5\. WS 通信
- en: '*Message frames* are a way to package and transmit data between the client
    and server. They aren’t anything unique to WebSocket as they apply to all connections
    over the TCP protocol that form the basis of HTTP. However, a WebSocket message
    frame consists of several components:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '*消息帧*是客户端和服务器之间打包和传输数据的方式。它们不是 WebSocket 独有的，因为它们适用于所有基于 HTTP 的 TCP 协议连接。然而，WebSocket
    消息帧由几个组件组成：'
- en: Fixed header
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 固定头部
- en: Describes basic information about the message
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 描述消息的基本信息
- en: Extended payload length (optional)
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 扩展有效载荷长度（可选）
- en: Provides the actual length of the payload when the length exceeds 125 bytes
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 当有效载荷长度超过 125 字节时，提供实际有效载荷的长度
- en: Masking key
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 遮蔽密钥
- en: Masks the payload data in frames sent from the client to the server, preventing
    certain types of security vulnerabilities, particularly *cache poisoning*^([1](ch06.html#id893))
    and *cross-protocol*^([2](ch06.html#id894)) attacks
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在客户端发送到服务器的帧中屏蔽有效载荷数据，防止某些类型的网络安全漏洞，尤其是*缓存中毒*^([1](ch06.html#id893))和*跨协议*^([2](ch06.html#id894))攻击
- en: Payload
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 有效载荷
- en: Contains the actual message content
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 包含实际的消息内容
- en: 'Unlike the verbose headers in HTTP requests, WebSocket frames have minimal
    headers that include the following:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 与 HTTP 请求中冗长的头部不同，WebSocket 帧具有最小头部，包括以下内容：
- en: Text frames
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 文本帧
- en: Used for UTF-8 encoded text data
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 用于 UTF-8 编码的文本数据
- en: Binary frames
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 二进制帧
- en: Used for binary data
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 用于二进制数据
- en: Fragmentation
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 分片
- en: Used to fragment messages into multiple frames, which are reassembled by the
    recipient
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 用于将消息分割成多个帧，由接收方重新组装
- en: The beauty of the WebSocket protocol is also its ability to maintain a persistent
    connection through *control frames*.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: WebSocket 协议的美丽之处也在于其通过*控制帧*保持持久连接的能力。
- en: '*Control frames* are special frames used to manage the connection:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '*控制帧*是用于管理连接的特殊帧：'
- en: Ping/pong frames
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Ping/pong 帧
- en: Used to check the connection’s status
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 用于检查连接的状态
- en: Close frame
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 关闭帧
- en: Used to terminate the connection gracefully
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 用于优雅地终止连接
- en: When it’s time to close the WebSocket connection, a close frame is sent by the
    client or the server. The close frame can optionally specify a status code and/or
    a reason for closing the connection. At this point, the WebSocket connection enters
    the *CLOSING* state.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 当需要关闭WebSocket连接时，客户端或服务器会发送一个关闭帧。关闭帧可以可选地指定状态码和/或关闭连接的原因。此时，WebSocket连接进入*关闭中*状态。
- en: The *CLOSING* state ends once the other party responds with another close frame.
    This concludes the full WebSocket connection lifecycle at the *CLOSED* state,
    as shown in [Figure 6-6](#websocket_connection_lifecycle).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 当另一方响应另一个关闭帧时，*关闭*状态结束。这标志着WebSocket连接生命周期在*关闭*状态下的完整结束，如图[图6-6](#websocket_connection_lifecycle)所示。
- en: '![bgai 0606](assets/bgai_0606.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 0606](assets/bgai_0606.png)'
- en: Figure 6-6\. WebSocket connection lifecycle
  id: totrans-116
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-6. WebSocket连接生命周期
- en: As you can see, using the WebSocket communication mechanism can be a bit of
    overkill for simple applications that won’t require the overheads. For most GenAI
    applications, SSE connections may be enough.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，对于不需要额外开销的简单应用来说，使用WebSocket通信机制可能有点过度。对于大多数GenAI应用，SSE连接可能就足够了。
- en: However, there are GenAI use cases where WebSocket can shine, such as multimedia
    chat and voice-to-voice applications, collaborative GenAI apps, and real-time
    transcription services based on bidirectional communication. To gain some hands-on
    experience, you will be building a speech-to-text application later in this chapter.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有一些通用人工智能（GenAI）用例中WebSocket可以大放异彩，例如多媒体聊天和语音对语音应用、协作GenAI应用以及基于双向通信的实时转录服务。为了获得一些实际操作经验，你将在本章后面构建一个语音转文字应用。
- en: Now that you’ve learned about several unique web communication mechanisms for
    real-time applications, let’s quickly summarize how they all compare.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经了解了几个独特的实时应用网络通信机制，让我们快速总结一下它们之间的比较。
- en: Comparing Communication Mechanisms
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较通信机制
- en: '[Figure 6-7](#communication_mechanims_figure) outlines the aforementioned five
    communication mechanisms used in web development.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '[图6-7](#communication_mechanims_figure)概述了在Web开发中使用的上述五种通信机制。'
- en: '![bgai 0607](assets/bgai_0607.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 0607](assets/bgai_0607.png)'
- en: Figure 6-7\. Comparison of web communication mechanisms
  id: totrans-123
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-7. Web通信机制比较
- en: As you can see from [Figure 6-7](#communication_mechanims_figure), the messaging
    patterns differ in each approach.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图6-7](#communication_mechanims_figure)所示，不同的方法中消息模式各不相同。
- en: '*HTTP request-response* is the most common model supported by all web clients
    and servers, suitable for RESTful APIs and services that don’t require real-time
    updates.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '*HTTP请求-响应*是所有Web客户端和服务器支持的最常见模型，适用于不需要实时更新的RESTful API和服务。'
- en: '*Short/regular polling* involves clients checking for data at set intervals,
    which is straightforward but can be resource-intensive when scaling services.
    It is normally used in applications to perform infrequent updates such as in analytics
    dashboards.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '*短/定期轮询*涉及客户端在设定的时间间隔检查数据，这很简单，但在扩展服务时可能会消耗大量资源。它通常用于需要执行不频繁更新的应用程序，例如分析仪表板。'
- en: '*Long polling* is more efficient for real-time updates by keeping connections
    open until data is available on the server. However, it can still drain the server
    resources, making it ideal for near-real-time features such as notifications.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '*长轮询*通过保持连接打开直到服务器上有数据可用，对于实时更新来说更有效率。然而，它仍然可能会耗尽服务器资源，使其对于近实时功能，如通知，非常理想。'
- en: '*SSE* maintains a single persistent connection that is server-to-client only,
    using the HTTP protocol. It is straightforward to set up, leverages the browser’s
    `EventSource` API and ships with built-in features like reconnection. These factors
    make SSE suitable for applications requiring live feeds, chat features, and real-time
    dashboards.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '*SSE*维护一个单一的持久连接，仅从服务器到客户端，使用HTTP协议。它设置简单，利用浏览器的`EventSource` API，并带有内置功能，如自动重连。这些因素使SSE适用于需要实时流、聊天功能和实时仪表板的应用程序。'
- en: '*WebSocket* provides full-duplex (double-sided) communication with low latency
    and binary data support, but is complex to implement. It is widely used in applications
    requiring high interactivity and real-time data exchange, such as multiplayer
    games, chat applications, collaborative tools, and real-time transcription services.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '*WebSocket*提供全双工（双向）通信，低延迟和二进制数据支持，但实现起来比较复杂。它在需要高交互性和实时数据交换的应用程序中广泛使用，例如多人游戏、聊天应用、协作工具和实时转录服务。'
- en: With the invention of SSE and WebSocket and their rising popularity, short/regular
    polling and long polling are becoming less common real-time mechanisms in web
    applications.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 随着SSE和WebSocket的发明及其日益流行，短/定期轮询和长轮询正在成为网络应用中较少使用的实时机制。
- en: '[Table 6-1](#communication_mechanisms_table) compares the features, challenges,
    and applications for each mechanism in detail.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[表 6-1](#communication_mechanisms_table) 详细比较了每种机制的特点、挑战和应用。'
- en: Table 6-1\. Comparison of web communication mechanisms
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6-1\. 网络通信机制比较
- en: '| Communication mechanism | Features | Challenges | Applications |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 通信机制 | 特点 | 挑战 | 应用 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| HTTP request-response | Simple request-and-response model, stateless protocol,
    supported by all web clients and servers | High latency for real-time updates,
    inefficient for frequent server-to-client data transfer | RESTful APIs, web services
    where real-time updates aren’t critical |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| HTTP请求-响应 | 简单的请求-响应模型，无状态协议，所有网络客户端和服务器都支持 | 实时更新延迟高，频繁服务器到客户端数据传输效率低 |
    RESTful API，实时更新不是关键点的网络服务 |'
- en: '| Short/regular polling | Client regularly requests data at intervals, easy
    to implement | Wasteful of resources when there’s no new data, latency depends
    on poll intervals | Applications with infrequent updates, simple near-real-time
    dashboards, status updates for submitted jobs |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 短/定期轮询 | 客户端定期以间隔请求数据，易于实现 | 当没有新数据时，资源浪费，延迟取决于轮询间隔 | 需要更新不频繁的应用，简单的近实时仪表板，提交作业的状态更新
    |'
- en: '| Long polling | More efficient than short polling for real-time updates, maintains
    open connection until data is available | Can be resource-intensive on the server,
    complex to manage multiple connections | Real-time notifications, older chat applications
    |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 长轮询 | 对于实时更新比短轮询更高效，保持开放连接直到有数据可用 | 服务器端可能资源密集，管理多个连接复杂 | 实时通知，较老的聊天应用 |'
- en: '| Server-sent events | Single persistent connection for updates, built-in reconnection
    and event ID support | Unidirectional communication from server to the client
    only | Live feeds, chat application, real-time analytics dashboards |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 服务器发送事件 | 单个持久连接用于更新，内置重连和事件 ID 支持 | 仅从服务器到客户端的单向通信 | 实时流，聊天应用，实时分析仪表板 |'
- en: '| WebSocket | Full-duplex communication, low latency, supports binary data
    | More complex to implement and manage, requires WebSocket support on the server
    | Multiplayer games, chat applications, collaborative editing tools, video conferencing
    and webinar apps, real-time transcription and translation apps |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| WebSocket | 全双工通信，低延迟，支持二进制数据 | 实现和管理更复杂，服务器需要WebSocket支持 | 多玩家游戏，聊天应用，协作编辑工具，视频会议和网络研讨会应用，实时转录和翻译应用
    |'
- en: Having reviewed real-time communication mechanisms in detail, let’s dive deeper
    into SSE and WebSocket by implementing our own streaming endpoints using these
    two mechanisms. In the next section, you will learn how to implement streaming
    endpoints working with both technologies.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在详细审查了实时通信机制之后，让我们通过使用这两种机制实现自己的流式端点来更深入地了解 SSE 和 WebSocket。在下一节中，你将学习如何实现与这两种技术一起工作的流式端点。
- en: Implementing SSE Endpoints
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现SSE端点
- en: In [Chapter 3](ch03.html#ch03), you learned about LLMs, which are *autoregressive*
    models that predict the next token based on previous inputs. After each generation
    step, the output token is appended to the inputs and passed through the model
    again until a `<stop>` token is generated to break the loop. Instead of waiting
    for the loop to finish, you can forward the output tokens as they’re being generated
    to the user as a data stream.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [第 3 章](ch03.html#ch03) 中，你学习了关于 LLMs 的内容，它们是 *自回归* 模型，根据先前输入预测下一个标记。在每个生成步骤之后，输出标记被附加到输入中并通过模型再次传递，直到生成
    `<stop>` 标记以中断循环。你不必等待循环完成，可以将生成的输出标记作为数据流直接转发给用户。
- en: Model providers will normally expose an option for you to set the output mode
    as a data stream using `stream=True`. With this option set, the model provider
    can return a data generator instead of the final output to you, which you can
    directly pass to your FastAPI server for streaming.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 模型提供者通常会提供一个选项，允许你使用 `stream=True` 将输出模式设置为数据流。设置此选项后，模型提供者可以返回一个数据生成器而不是最终输出给你，你可以直接将其传递到你的
    FastAPI 服务器进行流式传输。
- en: To demonstrate this in action, refer to [Example 6-2](#async_azure_openai_client),
    which implements an asynchronous data generator using the `openai` library.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 要演示这一功能，请参考[示例 6-2](#async_azure_openai_client)，它使用 `openai` 库实现了一个异步数据生成器。
- en: Tip
  id: totrans-145
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: To run [Example 6-2](#async_azure_openai_client), you will need to create an
    instance of Azure OpenAI on the Azure portal and create a model deployment. Make
    note of API endpoint, key, and model deployment name. For [Example 6-2](#async_azure_openai_client),
    you can use the `2023-05-15` api version.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行[示例 6-2](#async_azure_openai_client)，你需要在 Azure 门户上创建 Azure OpenAI 的实例并创建一个模型部署。注意
    API 端点、密钥和模型部署名称。对于[示例 6-2](#async_azure_openai_client)，你可以使用 `2023-05-15` api
    版本。
- en: Example 6-2\. Implementing Azure OpenAI async chat client for streaming responses
  id: totrans-147
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-2\. 实现用于流式响应的 Azure OpenAI 异步聊天客户端
- en: '[PRE1]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-1)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)[#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-1]'
- en: Create an asynchronous `AzureOpenAIChatClient` to interact with the Azure OpenAI
    API. The chat client requires an API endpoint, deployment name, key, and version
    to function.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个异步的 `AzureOpenAIChatClient` 以与 Azure OpenAI API 进行交互。聊天客户端需要 API 端点、部署名称、密钥和版本才能运行。
- en: '[![2](assets/2.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-2)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png)[#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-2]'
- en: Define a `chat_stream` asynchronous generator method that yields each output
    token from the API.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 定义一个 `chat_stream` 异步生成器方法，用于从 API `yield` 每个输出令牌。
- en: '[![3](assets/3.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-3)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '![3](assets/3.png)[#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-3]'
- en: Set the `stream=True` to receive an output stream from the API instead of the
    full response at once.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 设置 `stream=True` 以从 API 接收输出流，而不是一次性接收完整响应。
- en: '[![4](assets/4.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-4)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '![4](assets/4.png)[#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-4]'
- en: Loop over the stream and yield each output token or return an empty string if
    `delta.content` is empty. The `data:` substring should be prefixed to each token
    so that browsers can correctly parse the content using the `EventSource` API.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 遍历流，`yield` 每个输出令牌，如果 `delta.content` 为空，则返回一个空字符串。每个令牌应带有 `data:` 子串前缀，以便浏览器可以使用
    `EventSource` API 正确解析内容。
- en: '[![5](assets/5.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-5)'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '![5](assets/5.png)[#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO2-5]'
- en: Slow down the streaming rate to reduce back pressure on the clients.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 减慢流速率以减少对客户端的背压。
- en: In [Example 6-2](#async_azure_openai_client), you create an instance of `AsyncAzureOpenAI`,
    which allows you to chat with the Azure OpenAI models via an API in your private
    Azure environment.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在[示例 6-2](#async_azure_openai_client)中，你创建了一个 `AsyncAzureOpenAI` 的实例，这允许你通过你的私有
    Azure 环境中的 API 与 Azure OpenAI 模型进行聊天。
- en: By setting the `stream=True`, `AsyncAzureOpenAI` returns a data stream (an async
    generator function) instead of the full model response. You can loop over the
    data stream and `yield` tokens with the `data:` prefix to comply with the SSE
    specification. This will let browsers to automatically parse the stream content
    using the widely available `EventSource` web API.^([3](ch06.html#id906))
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 通过设置 `stream=True`，`AsyncAzureOpenAI` 返回一个数据流（一个异步生成器函数），而不是完整的模型响应。你可以遍历数据流，并使用
    `data:` 前缀 `yield` 令牌，以符合 SSE 规范。这将允许浏览器使用广泛可用的 `EventSource` 网络API自动解析流内容。[^([3](ch06.html#id906))]
- en: Warning
  id: totrans-161
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: When exposing streaming endpoints, you’ll need to consider how fast the clients
    can consume the data you’re sending them. A good practice is to reduce the streaming
    rate as you saw in [Example 6-2](#async_azure_openai_client) to reduce the back
    pressure on clients. You can adjust the throttling by testing your services with
    different clients on various devices.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 当公开流式端点时，你需要考虑客户端可以多快消费你发送给他们的数据。一个良好的做法是像在[示例 6-2](#async_azure_openai_client)中看到的那样减少流速率，以减少对客户端的背压。你可以通过在不同的设备上使用不同的客户端测试你的服务来调整节流。
- en: SSE with GET Request
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 GET 请求的 SSE
- en: You can now implement the SSE endpoint by passing the chat stream to the FastAPI’s
    `StreamingResponse` as a `GET` endpoint, as shown in [Example 6-3](#sse_endpoint).
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可以通过将聊天流传递给 FastAPI 的 `StreamingResponse` 作为 `GET` 端点来实现 SSE 端点，如[示例 6-3](#sse_endpoint)所示。
- en: Example 6-3\. Implementing an SSE endpoint using the FastAPI’s `StreamingResponse`
  id: totrans-165
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-3\. 使用 FastAPI 的 `StreamingResponse` 实现一个 SSE 端点
- en: '[PRE2]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO3-1)'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO3-1)'
- en: Implement an SSE endpoint with the `GET` method to use with the `EventSource`
    API on the browser.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `GET` 方法实现一个 SSE 端点，以便在浏览器中使用 `EventSource` API。
- en: '[![2](assets/2.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO3-2)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO3-2)'
- en: Pass the chat stream generator to the `StreamingResponse` to forward the output
    stream as it is being generated to the client. Set the `media_type=text/event-stream`
    as per SSE specifications so that the browsers can handle the response correctly.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 将聊天流生成器传递给 `StreamingResponse`，以便将生成的输出流直接转发给客户端。根据 SSE 规范设置 `media_type=text/event-stream`，以便浏览器可以正确处理响应。
- en: With the `GET` endpoint set up on the server, you can create a simple HTML form
    on the client to consume the SSE stream via the `EventSource` interface, as shown
    in [Example 6-4](#sse_client).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在服务器上设置了 `GET` 端点后，你可以在客户端创建一个简单的 HTML 表单，通过 `EventSource` 接口消费 SSE 流，如 [示例
    6-4](#sse_client) 所示。
- en: Tip
  id: totrans-172
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: '[Example 6-4](#sse_client) doesn’t use any JavaScript libraries or web frameworks.
    However, there are libraries to assist you in implementing the `EventSource` connection
    in any framework of your choice such as React, Vue, or SvelteKit.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 6-4](#sse_client) 不使用任何 JavaScript 库或 Web 框架。然而，有一些库可以帮助你在你选择的任何框架（如 React、Vue
    或 SvelteKit）中实现 `EventSource` 连接。'
- en: Example 6-4\. Implementing SSE on the client using the browser `EventSource`
    API
  id: totrans-174
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-4\. 使用浏览器 `EventSource` API 在客户端实现 SSE
- en: '[PRE3]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-1)'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-1)'
- en: Create a simple HTML input and button for initiating SSE requests.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个简单的 HTML 输入和按钮以启动 SSE 请求。
- en: '[![2](assets/2.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-2)'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-2)'
- en: Create an empty container to be used as a sink for the stream content.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个空容器，用作流内容的接收器。
- en: '[![3](assets/3.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-3)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-3)'
- en: Listen for button `clicks` and run the SSE callback.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 监听按钮 `clicks` 并运行 SSE 回调。
- en: '[![4](assets/4.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-4)'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-4)'
- en: Reset the content form and response container of previous content.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 重置先前内容的内容表单和响应容器。
- en: '[![5](assets/5.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-5)'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-5)'
- en: Create a new `EventSource` object and listen to connection state changes to
    handle events.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的 `EventSource` 对象并监听连接状态变化以处理事件。
- en: '[![6](assets/6.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-6)'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](assets/6.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO4-6)'
- en: Log to console when an SSE connection is opened. Handle each message by rendering
    message content to the response container until the `[DONE]` message is received,
    which signals that the connection should now be closed. Additionally, close the
    connection if any errors occur and log the error to the browser’s console.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 当 SSE 连接打开时记录到控制台。通过将消息内容渲染到响应容器中处理每个消息，直到接收到 `[DONE]` 消息，这表示连接现在应该关闭。此外，如果发生任何错误，关闭连接并将错误记录到浏览器的控制台。
- en: With the SSE client implemented in [Example 6-4](#sse_client), you can now use
    it to test your SSE endpoint. However, you need to serve the HTML first.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [示例 6-4](#sse_client) 中实现了 SSE 客户端后，你现在可以使用它来测试你的 SSE 端点。然而，你需要首先提供 HTML 服务。
- en: Create a `pages` directory and then place the HTML file inside. Then *mount*
    the directory onto your FastAPI server to serve its content as static files, as
    shown in [Example 6-5](#mounting_static_files). Via mounting, FastAPI takes care
    of mapping API paths to each file so that you can access them with a browser from
    the same origin as your server.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个`pages`目录，然后将HTML文件放入其中。然后*挂载*该目录到你的FastAPI服务器上，以将其内容作为静态文件提供服务，如[示例 6-5](#mounting_static_files)所示。通过挂载，FastAPI负责将API路径映射到每个文件，这样你就可以从与服务器相同的源通过浏览器访问它们。
- en: Example 6-5\. Mounting HTML files on the server as static assets
  id: totrans-190
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-5\. 在服务器上挂载HTML文件作为静态资源
- en: '[PRE4]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO5-1)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO5-1)'
- en: Mount the `pages` directory onto the `/pages` to serve its content as static
    assets. Once mounted, you can access each file by visiting `*<origin>*/pages/*<filename>*`.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 将`pages`目录挂载到`/pages`以将其内容作为静态资源提供服务。一旦挂载，你就可以通过访问`*<origin>*/pages/*<filename>*`来访问每个文件。
- en: By implementing [Example 6-5](#mounting_static_files), you serve the HTML from
    the same origin as your API server. This avoids triggering the browser’s CORS
    security mechanism, which can block outgoing requests reaching your server.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 通过实现[示例 6-5](#mounting_static_files)，你从与你的API服务器相同的源提供服务HTML。这避免了触发浏览器的CORS安全机制，该机制可能会阻止到达服务器的出站请求。
- en: You can now access the HTML page by visiting `http://localhost:8000/pages/sse-client.html`.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可以通过访问`http://localhost:8000/pages/sse-client.html`来访问HTML页面。
- en: Cross-origin resource sharing
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 跨源资源共享
- en: If you try to open the [Example 6-4](#sse_client) HTML file in your browser
    directly and click the Start Streaming button, you will notice that nothing happens.
    You can check the browser’s network tab to view what happened to the outgoing
    requests.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你尝试直接在你的浏览器中打开[示例 6-4](#sse_client) HTML文件并点击开始流式传输按钮，你会注意到没有任何反应。你可以检查浏览器的网络标签来查看出站请求发生了什么。
- en: After some investigations, you should notice that your browser has blocked outgoing
    requests to your server as its preflight *cross-origin resource sharing* (CORS)
    checks with your server have failed.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 经过一些调查，你应该会注意到你的浏览器已经阻止了对服务器的出站请求，因为它的预检**跨源资源共享**（CORS）检查与你的服务器失败了。
- en: CORS is a security mechanism implemented in browsers to control how resources
    on a web page can be requested from another domain, and is relevant only when
    sending requests directly from the browser instead of a server. Browsers use CORS
    to check whether they’re allowed to send requests to the server from a different
    origin (i.e., domain) than the server.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: CORS是浏览器中实现的一种安全机制，用于控制网页上的资源如何从另一个域请求，并且仅在直接从浏览器而不是服务器发送请求时相关。浏览器使用CORS来检查它们是否被允许从与服务器不同的源（即域）发送请求。
- en: For example, if your client is hosted on `https://example.com` and it needs
    to fetch data from an API hosted on `https://api.example.com`, the browser will
    block this request unless the API server has CORS enabled.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你的客户端托管在`https://example.com`，并且它需要从托管在`https://api.example.com`的API获取数据，浏览器将阻止此请求，除非API服务器启用了CORS。
- en: For now, you can bypass these CORS errors by adding a CORS middleware on your
    server, as you can see in [Example 6-6](#cors), to allow any incoming requests
    from browsers.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，你可以在服务器上添加一个CORS中间件来绕过这些CORS错误，如[示例 6-6](#cors)所示，以允许来自浏览器的任何入站请求。
- en: Example 6-6\. Apply CORS settings
  id: totrans-202
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-6\. 应用CORS设置
- en: '[PRE5]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO6-1)'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO6-1)'
- en: Allow incoming requests from any origins, methods (`GET`, `POST`, etc.) and
    headers.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 允许来自任何源、方法（`GET`、`POST`等）和头部的入站请求。
- en: Streamlit avoids triggering the CORS mechanism by sending requests on its internal
    server even though the generated UI runs on the browser.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: Streamlit通过在其内部服务器上发送请求来避免触发CORS机制，尽管生成的UI在浏览器上运行。
- en: On the other hand, the FastAPI documentation page makes requests from the same
    origin as the server (i.e., `http://localhost:8000`), so requests by default don’t
    trigger the CORS security mechanism.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，FastAPI文档页面从与服务器相同的源（即`http://localhost:8000`）发送请求，因此默认情况下不会触发CORS安全机制。
- en: Warning
  id: totrans-208
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: In [Example 6-6](#cors), you configure the CORS middleware to process any incoming
    requests, effectively bypassing the CORS security mechanism for easier development.
    In production, you should allow only a handful of origins, methods, and headers
    to be processed by your server.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [示例 6-6](#cors) 中，您配置了 CORS 中间件来处理任何传入的请求，有效地绕过了 CORS 安全机制以简化开发。在生产环境中，您应该只允许服务器处理少量来源、方法和头信息。
- en: If you followed Example [6-5](#mounting_static_files) or [6-6](#cors), you should
    now be able to view the incoming stream from your SSE endpoint (see [Figure 6-8](#sse_results)).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您遵循了示例 [6-5](#mounting_static_files) 或 [6-6](#cors)，现在您应该能够查看来自您的 SSE 端点的传入流（参见
    [图 6-8](#sse_results)）。
- en: '![bgai 0608](assets/bgai_0608.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 0608](assets/bgai_0608.png)'
- en: Figure 6-8\. Incoming stream from the SSE endpoint
  id: totrans-212
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 6-8\. 从 SSE 端点传入的流
- en: Congratulations! You now have a full working solution where model responses
    are directly streamed to your client as soon as generated data becomes available.
    By implementing this feature, your users will now have a more pleasant experience
    interacting with your chatbot as they receive responses to their queries in real
    time.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！您现在拥有了一个完整的解决方案，其中模型响应会在生成数据一可用就直接流式传输到您的客户端。通过实现此功能，您的用户在与聊天机器人交互时将获得更愉快的体验，因为他们可以实时收到对查询的响应。
- en: Your solution also implemented concurrency using an asynchronous client for
    interacting with the Azure OpenAI API to stream faster responses to your users.
    You can try using a synchronous client to compare the differences in generation
    speeds. With an asynchronous client, the generation speed can be so fast that
    you will receive a block of text at once even though it is actually being streamed
    to the browser.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 您的解决方案还通过使用异步客户端与 Azure OpenAI API 交互来实现并发，以便更快地向用户流式传输响应。您可以尝试使用同步客户端来比较生成速度的差异。使用异步客户端时，生成速度可以非常快，以至于您会一次性接收到一大块文本，尽管实际上这些文本正在被流式传输到浏览器。
- en: Streaming LLM outputs from Hugging Face models
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从 Hugging Face 模型流式传输 LLM 输出
- en: Now that you’ve learned how to implement SSE endpoints with model providers
    such as Azure OpenAI, you may be wondering if you can stream model outputs from
    open source models you’ve previously downloaded from Hugging Face.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经学会了如何使用 Azure OpenAI 等模型提供者实现 SSE 端点，您可能会想知道是否可以从您之前从 Hugging Face 下载的开源模型中流式传输模型输出。
- en: Although Hugging Face’s `transformers` library implements a `TextStreamer` component
    that you can pass to your model pipeline, the easiest solution is to run a separate
    inference server such as HF Inference Server to implement model streaming.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Hugging Face的 `transformers` 库实现了一个 `TextStreamer` 组件，您可以将它传递到您的模型管道中，但最简单的解决方案是运行一个单独的推理服务器，如
    HF Inference Server，以实现模型流式传输。
- en: '[Example 6-7](#hf_llm_inference_server) shows how to set up a simple model
    inference server using Docker by providing a `model-id`.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 6-7](#hf_llm_inference_server) 展示了如何通过提供 `model-id` 使用 Docker 设置简单的模型推理服务器。'
- en: Example 6-7\. Serving HF LLM models via HF Inference Server
  id: totrans-219
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-7\. 通过 HF Inference Server 提供HF LLM模型
- en: '[PRE6]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-1)'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png) (#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-1)'
- en: Use Docker to download and run the latest `vllm/vllm-openai` container on all
    available NVIDIA GPUs.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Docker 在所有可用的 NVIDIA GPU 上下载并运行最新的 `vllm/vllm-openai` 容器。
- en: '[![2](assets/2.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-2)'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png) (#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-2)'
- en: Share a volume with the Docker container to avoid downloading weights every
    run.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Docker 容器共享一个卷，以避免每次运行时都下载权重。
- en: '[![3](assets/3.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-3)'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '![3](assets/3.png) (#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-3)'
- en: Set the secret environment variable to access gated models like `mistralai/Mistral-7B-v0.1`.^([4](ch06.html#id909))
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 设置秘密环境变量以访问受保护的模型，例如 `mistralai/Mistral-7B-v0.1`。^([4](ch06.html#id909))
- en: '[![4](assets/4.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-4)'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '![4](assets/4.png) (#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-4)'
- en: Run the inference server on localhost port `8080` by mapping host port `8080`
    to exposed Docker container port `8000`.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在本地主机端口 `8080` 上运行推理服务器，通过将主机端口 `8080` 映射到暴露的 Docker 容器端口 `8000`。
- en: '[![5](assets/5.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-5)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '![5](assets/5.png) (#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-5)'
- en: Enable inter-process communication (IPC) between the container and the host
    to allow the container to access the host’s shared memory.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器和主机之间启用进程间通信 (IPC)，以便容器可以访问主机的共享内存。
- en: '[![6](assets/6.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-7)'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '![6](assets/6.png)[#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-7]'
- en: The vLLM inference server uses the OpenAI API Specification for LLM serving.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: vLLM 推理服务器使用 OpenAI API 规范进行 LLM 服务。
- en: '[![7](assets/7.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-8)'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '![7](assets/7.png)[#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO7-8]'
- en: Download and use the gated `mistralai/Mistral-7B-v0.1` from Hugging Face Hub.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 从 Hugging Face Hub 下载并使用受控的 `mistralai/Mistral-7B-v0.1`。
- en: With the model server running, you can now use an `AsyncInferenceClient` to
    generate outputs in a streaming format, as shown in [Example 6-8](#hf_llm_streaming).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 当模型服务器运行时，你现在可以使用 `AsyncInferenceClient` 以流格式生成输出，如 [示例 6-8](#hf_llm_streaming)
    所示。
- en: Example 6-8\. Consuming the LLM output stream from HF Inference Stream
  id: totrans-236
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-8\. 从 HF 推理流消费 LLM 输出流
- en: '[PRE7]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: While [Example 6-8](#hf_llm_streaming) shows how to use the Hugging Face inference
    server, you can still use other model-serving frameworks such as [vLLM](https://oreil.ly/LQAzF)
    that support streaming model responses.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 [示例 6-8](#hf_llm_streaming) 展示了如何使用 Hugging Face 推理服务器，但你仍然可以使用支持流式模型响应的其他模型服务框架，如
    [vLLM](https://oreil.ly/LQAzF)。
- en: Before we move on to talking about WebSocket, let’s look at consuming another
    variant of SSE endpoints using the `POST` method.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续讨论 WebSocket 之前，让我们看看如何使用 `POST` 方法消费 SSE 端点的另一种变体。
- en: SSE with POST Request
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 POST 请求的 SSE
- en: The [`EventSource` specification](https://oreil.ly/61ovi) expects `GET` endpoints
    on the server to correctly consume the incoming SSE stream. This makes implementing
    real-time applications with SSE straightforward as the `EventSource` interface
    can handle issues such as connection drops and automatic reconnection.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '[`EventSource` 规范](https://oreil.ly/61ovi) 预期服务器上的 `GET` 端点能够正确消费传入的 SSE 流。这使得使用
    SSE 实现实时应用变得简单，因为 `EventSource` 接口可以处理诸如连接中断和自动重连等问题。'
- en: However, using HTTP `GET` requests comes with its own limitations. `GET` requests
    are normally less secure than other request methods and more vulnerable to *XSS*
    attacks.^([5](ch06.html#id912)) In addition, since `GET` requests can’t have any
    request body, you can only transfer data as part of the URL’s query parameters
    to the server. The issue is that there is a URL length limit you need to consider
    and any query parameters must be encoded correctly into the request URL. Therefore,
    you can’t just append the whole conversation history to the URL as a parameter.
    Your server must handle maintaining the history of the conversation and keeping
    track of conversational context with `GET` SSE endpoints.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，使用 HTTP `GET` 请求有其自身的局限性。`GET` 请求通常比其他请求方法的安全性更低，更容易受到 *XSS* 攻击。[5](ch06.html#id912)
    此外，由于 `GET` 请求不能有任何请求体，你只能将数据作为 URL 的查询参数发送到服务器。问题是存在 URL 长度限制，你必须考虑，并且任何查询参数都必须正确编码到请求
    URL 中。因此，你不能简单地将整个对话历史作为参数附加到 URL 上。你的服务器必须处理维护对话历史和跟踪对话上下文，使用 `GET` SSE 端点。
- en: A common workaround to the aforementioned limitation is to implement a `POST`
    SSE endpoint even if the SSE specification doesn’t support it. As a result, the
    implementation will be more complex.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 解决上述限制的一个常见方法是即使 SSE 规范不支持，也实现一个 `POST` SSE 端点。因此，实现将更加复杂。
- en: First let’s implement the `POST` endpoint on the server in [Example 6-9](#sse_server_post).
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们在 [示例 6-9](#sse_server_post) 中实现服务器上的 `POST` 端点。
- en: Example 6-9\. Implementing SSE endpoint on the server
  id: totrans-245
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-9\. 在服务器上实现 SSE 端点
- en: '[PRE8]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: With the `POST` endpoint for streaming chat outputs implemented, you can now
    develop the client logic to process the SSE stream.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现了流式聊天输出的 `POST` 端点后，你现在可以开发客户端逻辑来处理 SSE 流。
- en: You will have to manually process the incoming streaming yourself using the
    browser’s `fetch` web interface, as shown in [Example 6-10](#sse_client_post).
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 你将不得不手动使用浏览器 `fetch` 网络接口处理传入的流，如 [示例 6-10](#sse_client_post) 所示。
- en: Example 6-10\. Implementing SSE on the client using the browser `EventSource`
    API
  id: totrans-249
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-10\. 使用浏览器 `EventSource` API 在客户端实现 SSE
- en: '[PRE9]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-1)'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)[#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-1]'
- en: Send a `POST` request to the backend using the browser’s `fetch` interface.
    Prepare the body as a JSON string as part of the request. Add headers to specify
    the request body being sent and the response that is expected from the server.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 使用浏览器的 `fetch` 接口向后端发送 `POST` 请求。将正文作为 JSON 字符串作为请求的一部分准备。添加标头以指定要发送的请求正文和从服务器期望的响应。
- en: '[![2](assets/2.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-2)'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png)(#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-2)'
- en: Access the `reader` of the stream from the response body stream.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 从响应体流中访问流的 `reader`。
- en: '[![3](assets/3.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-3)'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '![3](assets/3.png)(#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-3)'
- en: Create an instance of a text decoder for processing each message.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 为处理每条消息创建一个文本解码器实例。
- en: '[![4](assets/4.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-4)'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '![4](assets/4.png)(#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-4)'
- en: Run an infinite loop and read the next message in the stream using the `reader`.
    If the stream has ended, `done=true`, so break the loop; otherwise, decode the
    message with the text decoder and append to the response container’s `textContent`
    to render.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 运行一个无限循环，并使用 `reader` 读取流中的下一条消息。如果流已结束，则 `done=true`，因此退出循环；否则，使用文本解码器解码消息并将其追加到响应容器的
    `textContent` 以进行渲染。
- en: '[![5](assets/5.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-5)'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '![5](assets/5.png)(#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO8-5)'
- en: Listen on button `click` events to run a callback that resets the form state
    and makes the SSE connection with the backend endpoint with a prompt.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 监听按钮 `click` 事件以运行回调，重置表单状态，并使用提示与后端端点建立 SSE 连接。
- en: As you can see from [Example 6-10](#sse_client_post), consuming the SSE stream
    without the `EventSource` can become complex.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 如 [示例 6-10](#sse_client_post) 所示，在没有 `EventSource` 的情况下消费 SSE 流可能会变得复杂。
- en: Tip
  id: totrans-262
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: An alternative to [Example 6-10](#sse_client_post) is to use `GET` SSE endpoints
    but send the large payload to the server beforehand using a `POST` request. The
    server stores the data and uses it when the SSE connection is established.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 6-10](#sse_client_post) 的另一种方法是使用 `GET` SSE 端点，但在此之前使用 `POST` 请求将大量有效负载发送到服务器。服务器存储数据，并在建立
    SSE 连接时使用它。'
- en: SSE also supports cookies, so you can rely on cookies to exchange large payloads
    in `GET` SSE endpoints.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: SSE 还支持 cookies，因此您可以在 `GET` SSE 端点中依赖 cookies 来交换大量有效负载。
- en: If you want to consume the SSE endpoint in production, your solution should
    also support retry functionality, error handling, or even the ability to abort
    connections.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想在生产中消费 SSE 端点，您的解决方案还应支持重试功能、错误处理，甚至能够断开连接的能力。
- en: '[Example 6-11](#sse_retry) demonstrates how to implement a client-side retry
    functionality with an *exponential backoff delay* in JavaScript.^([6](ch06.html#id914))'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '[示例 6-11](#sse_retry) 展示了如何在 JavaScript 中实现具有 *指数退避延迟* 的客户端重试功能.^([6](ch06.html#id914))'
- en: Example 6-11\. Implementing client-side retry functionality with exponential
    backoff
  id: totrans-267
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-11\. 使用指数退避实现客户端重试功能
- en: '[PRE10]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-1)'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)(#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-1)'
- en: As long as `maxRetries` isn’t reached, attempt to establish the SSE connection.
    Count each attempt.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 只要 `maxRetries` 没有达到，就尝试建立 SSE 连接。计算每次尝试。
- en: '[![2](assets/2.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-2)'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png)(#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-2)'
- en: Use a `try` and `catch` to handle connection errors.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `try` 和 `catch` 来处理连接错误。
- en: '[![3](assets/3.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-3)'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '![3](assets/3.png)(#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-3)'
- en: Exit the function if successful.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 如果成功，则退出函数。
- en: '[![4](assets/4.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-4)'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '![4](assets/4.png)(#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-4)'
- en: Pause in `delay` milliseconds before retrying.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在重试之前暂停 `delay` 毫秒。
- en: '[![5](assets/5.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-5)'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '![5](assets/5.png)(#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-5)'
- en: Implement exponential backoff by multiplying a backoff factor to the delay value
    in each iteration.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在每个迭代中将退避因子乘以延迟值来实现指数退避。
- en: '[![6](assets/6.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-6)'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](assets/6.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO9-6)'
- en: Rethrow the `error` if `maxRetries` is reached.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 如果达到`maxRetries`，则重新抛出`error`。
- en: You should now feel more comfortable implementing your own SSE endpoints for
    streaming model responses. SSE is the go-to communication mechanism that applications
    like ChatGPT use for real-time conversations with the model. Since SSE predominantly
    supports text-based streams, it is ideal for LLM output streaming scenarios.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在应该更舒适地实现自己的SSE端点以流式传输模型响应。SSE是ChatGPT等应用程序用于与模型进行实时对话的首选通信机制。由于SSE主要支持基于文本的流，它非常适合LLM输出流场景。
- en: In the next section, we’re going to implement the same solution using the WebSocket
    mechanism so that you can compare differences in the implementation details. In
    addition, you’re going to learn what makes WebSocket ideal for scenarios that
    require real-time duplex communication such as in live transcription services.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将使用WebSocket机制实现相同的解决方案，以便您可以比较实现细节中的差异。此外，您还将了解WebSocket为何适合需要实时双向通信的场景，例如在实时转录服务中。
- en: Implementing WS Endpoints
  id: totrans-283
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现WS端点
- en: In this section, you’re going to implement an endpoint using the WebSocket protocol.
    With this endpoint, you will stream the LLM outputs to the client using WebSocket
    to compare with the SSE connection. By the end, you will learn the differences
    and similarities between SSE and WebSocket in streaming LLM outputs in real time.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将使用WebSocket协议实现一个端点。通过此端点，您将使用WebSocket将LLM输出流式传输到客户端，并与SSE连接进行比较。到结束时，您将了解SSE和WebSocket在实时流式传输LLM输出中的异同。
- en: Streaming LLM Outputs with WebSocket
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用WebSocket进行LLM输出流
- en: FastAPI supports WebSocket through the use of the `WebSocket` interface from
    the Starlette web framework. As WebSocket connections need to be managed, let’s
    start by implementing a connection manager to keep track of active connections
    and managing their states.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: FastAPI通过使用Starlette web框架的`WebSocket`接口支持WebSocket。由于WebSocket连接需要管理，让我们首先实现一个连接管理器来跟踪活动连接并管理它们的状态。
- en: You can implement a WebSocket connection manager by following [Example 6-12](#websockets_manager).
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过遵循[示例 6-12](#websockets_manager)来实现WebSocket连接管理器。
- en: Example 6-12\. Implementing a WebSocket connection manager
  id: totrans-288
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-12\. 实现WebSocket连接管理器
- en: '[PRE11]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-1)'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-1)'
- en: Create a `WSConnectionManager` to track and handle active WS connections.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个`WSConnectionManager`来跟踪和处理活动WS连接。
- en: '[![2](assets/2.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-2)'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-2)'
- en: Open a WebSocket connection using the `accept()` method. Add the new connection
    to the list of active connections.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`accept()`方法打开WebSocket连接。将新连接添加到活动连接列表中。
- en: '[![3](assets/3.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-3)'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-3)'
- en: When disconnecting, close the connection and remove the `websocket` instance
    from the active connections list.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 断开连接时，关闭连接并从活动连接列表中移除`websocket`实例。
- en: '[![4](assets/4.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-4)'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-4)'
- en: Receive incoming messages as text during an open connection.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在打开连接期间接收作为文本的消息。
- en: '[![5](assets/5.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-5)'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-5)'
- en: Send messages to the client using the relevant send method.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 使用相关发送方法向客户端发送消息。
- en: '[![6](assets/6.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-6)'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](assets/6.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO10-6)'
- en: Create a single instance of the `WSConnectionManager` to reuse across the app.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个`WSConnectionManager`的单例实例，以便在整个应用程序中重用。
- en: You can also extend the connection manager in [Example 6-12](#websockets_manager)
    to *broadcast* messages (e.g., real-time system alerts, notifications, or updates)
    to all connected clients. This is useful in applications such as group chats or
    collaborative whiteboard/document editing tools.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以扩展连接管理器，如[示例 6-12](#websockets_manager)所示，以**广播**消息（例如，实时系统警报、通知或更新）给所有已连接的客户端。这在群聊或协作白板/文档编辑工具等应用中非常有用。
- en: As the connection manager maintains a pointer to every client via the `active_​con⁠nec⁠tions`
    list, you can broadcast messages to each client, as shown in [Example 6-13](#websockets_broadcast).
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 由于连接管理器通过 `active_connections` 列表维护对每个客户端的指针，因此你可以向每个客户端广播消息，如[示例 6-13](#websockets_broadcast)所示。
- en: Example 6-13\. Broadcasting messages to connected clients using the WebSocket
    manager
  id: totrans-304
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-13\. 使用 WebSocket 管理器向已连接客户端广播消息
- en: '[PRE12]'
  id: totrans-305
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: With the WebSocket manager implemented, you can now develop a WebSocket endpoint
    to stream responses to the clients. However, before implementing the endpoint,
    follow [Example 6-14](#chat_stream_ws) to update the `chat_stream` method so that
    it yields the stream content in a suitable format for WebSocket connections.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 在实现端点之前，遵循[示例 6-14](#chat_stream_ws)更新 `chat_stream` 方法，使其以适合 WebSocket 连接的格式返回流内容。
- en: Example 6-14\. Update the chat client streaming method to yield content suitable
    for WebSocket connections
  id: totrans-307
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-14\. 更新聊天客户端流方法以返回适合 WebSocket 连接的内容
- en: '[PRE13]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO11-1)'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO11-1)'
- en: Only yield non-empty content.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 仅返回非空内容。
- en: '[![2](assets/2.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO11-2)'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO11-2)'
- en: Yield the stream content based on connection type (SSE or WS).
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 根据连接类型（SSE 或 WS）返回流内容。
- en: After updating the `stream_chat` method, you can focus on adding a WebSocket
    endpoint. Use the `@app.websocket` to decorate a controller function that uses
    the FastAPI’s `WebSocket` class, as shown in [Example 6-15](#websocket_endpoint).
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 在更新 `stream_chat` 方法后，你可以专注于添加 WebSocket 端点。使用 `@app.websocket` 装饰一个控制器函数，该函数使用
    FastAPI 的 `WebSocket` 类，如[示例 6-15](#websocket_endpoint)所示。
- en: Example 6-15\. Implementing a WS endpoint
  id: totrans-314
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-15\. 实现一个 WS 端点
- en: '[PRE14]'
  id: totrans-315
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-1)'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-1)'
- en: Create a WebSocket endpoint accessible at `ws://localhost:8000/generate/text/stream`.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个可访问的 WebSocket 端点 `ws://localhost:8000/generate/text/stream`。
- en: '[![2](assets/2.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-2)'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-2)'
- en: Open the WebSocket connection between the client and the server.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 打开客户端和服务器之间的 WebSocket 连接。
- en: '[![3](assets/3.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-3)'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-3)'
- en: As long as the connection is open, keep sending or receiving messages.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 只要连接打开，就持续发送或接收消息。
- en: '[![4](assets/4.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-4)'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-4)'
- en: Handle errors and log important events within the `websocket_controller` to
    identify root causes of errors and handle unexpected situations gracefully. Break
    the infinite loop when the connection is closed by the server or the client.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `websocket_controller` 中处理错误并记录重要事件，以识别错误的根本原因并优雅地处理意外情况。当服务器或客户端关闭连接时，中断无限循环。
- en: '[![5](assets/5.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-5)'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-5)'
- en: When the first message is received, pass it as a prompt to OpenAI API.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 当收到第一条消息时，将其作为提示传递给 OpenAI API。
- en: '[![6](assets/6.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-6)'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](assets/6.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-6)'
- en: Asynchronously iterate over the generated chat stream and send each chunk to
    the client.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 异步遍历生成的聊天流，并将每个块发送到客户端。
- en: '[![7](assets/7.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-7)'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '![7](assets/7.png)[#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-7]'
- en: Wait for a small amount of time before sending the next message to reduce race
    condition issues and allow the client sufficient time for stream processing.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 在发送下一条消息之前等待一小段时间，以减少竞争条件问题并允许客户端有足够的时间进行流处理。
- en: '[![8](assets/8.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-8)'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '![8](assets/8.png)[#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-8]'
- en: When the client closes the WebSocket connection, the `WebSocketDisconnect` exception
    is raised.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 当客户端关闭 WebSocket 连接时，将引发 `WebSocketDisconnect` 异常。
- en: '[![9](assets/9.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-9)'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '![9](assets/9.png)[#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-9]'
- en: If there is a server-side error during an open connection, log the error and
    identify the client.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在打开连接期间发生服务器端错误，记录错误并识别客户端。
- en: '[![10](assets/10.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-10)'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '![10](assets/10.png)[#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO12-10]'
- en: Break the infinite loop and gracefully close the WebSocket connection if the
    stream has finished, there is an internal error, or the client has closed the
    connection. Remove the connection from the active WebSocket connections list.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 如果流已结束、存在内部错误或客户端已关闭连接，则中断无限循环并优雅地关闭 WebSocket 连接。从活动 WebSocket 连接列表中删除连接。
- en: Now that you have a WebSocket endpoint, let’s develop the client HTML to test
    the endpoint (see [Example 6-16](#ws_client)).
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经有了 WebSocket 端点，让我们开发客户端 HTML 来测试端点（见[示例 6-16](#ws_client)）。
- en: Example 6-16\. Implement client-side WebSocket connections with error handling
    and exponential backoff retry functionality
  id: totrans-337
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 示例 6-16\. 实现具有错误处理和指数退避重试功能的客户端 WebSocket 连接
- en: '[PRE15]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[![1](assets/1.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-1)'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '![1](assets/1.png)[#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-1]'
- en: Establish a WebSocket connection with the FastAPI server.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 与 FastAPI 服务器建立 WebSocket 连接。
- en: '[![2](assets/2.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-2)'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: '![2](assets/2.png)[#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-2]'
- en: Add callback handlers to the WebSocket connection instance to handle opening,
    closing, message, and error events.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 向 WebSocket 连接实例添加回调处理程序以处理打开、关闭、消息和错误事件。
- en: '[![3](assets/3.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-3)'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '![3](assets/3.png)[#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-3]'
- en: Gracefully handle connection errors and re-establish the connection with an
    exponential backoff retry functionality using an `isError` flag.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 优雅地处理连接错误，并使用带有 `isError` 标志的指数退避重试功能重新建立连接。
- en: '[![4](assets/4.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-4)'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '![4](assets/4.png)[#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-4]'
- en: Add an event listener to the streaming button to send the first message to the
    server.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 为流按钮添加事件监听器以将第一条消息发送到服务器。
- en: '[![5](assets/5.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-5)'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: '![5](assets/5.png)[#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-5]'
- en: Once the connection is established, send the initial non-empty prompt as the
    first message to the server.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦建立连接，将初始的非空提示作为第一条消息发送到服务器。
- en: '[![6](assets/6.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-6)'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '![6](assets/6.png)[#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-6]'
- en: Reset the form to before establishing the WebSocket connection to start.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 将表单重置为建立 WebSocket 连接之前的状态以开始。
- en: '[![7](assets/7.png)](#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-7)'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '![7](assets/7.png)[#co_real_time_communication___span_class__keep_together__with_generative_models__span__CO13-7]'
- en: Add an event listener to the close connection button to close the connection
    when the button is clicked.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 为关闭连接按钮添加事件监听器，以便在按钮被点击时关闭连接。
- en: Now you can visit [*http://localhost:8000/pages/client-ws.html*](http://localhost:8000/pages/client-ws.html)
    to test your WebSocket streaming endpoint (see [Figure 6-9](#ws_results)).
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您可以访问[*http://localhost:8000/pages/client-ws.html*](http://localhost:8000/pages/client-ws.html)来测试您的
    WebSocket 流式传输端点（见[图 6-9](#ws_results)）。
- en: '![bgai 0609](assets/bgai_0609.png)'
  id: totrans-354
  prefs: []
  type: TYPE_IMG
  zh: '![bgai 0609](assets/bgai_0609.png)'
- en: Figure 6-9\. Incoming stream from the WebSocket endpoint
  id: totrans-355
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-9\. 从WebSocket端点传入的流
- en: You should now have a fully working LLM streaming application with WebSocket.
    Well done!
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在应该有一个完全工作的带有WebSocket的LLM流应用程序。做得好！
- en: 'You now may be wondering which solution is better: streaming with SSE or WS
    connections. The answer depends on your application requirements. SSE is simple
    to implement and is native to HTTP protocol, so most clients support it. If all
    you need is one-way streaming to the client, then I suggest implementing SSE connections
    for streaming LLM outputs.'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可能想知道哪种解决方案更好：使用SSE或WS连接进行流。答案取决于您的应用程序需求。SSE易于实现，并且是HTTP协议的原生功能，因此大多数客户端都支持它。如果您只需要向客户端进行单向流传输，那么我建议实现SSE连接以进行LLM输出的流传输。
- en: WebSocket connections provide more control to your streaming mechanism and allow
    for duplex communication within the same connection—for instance, in real-time
    chat applications with multiple users and the LLM, speech-to-text, text-to-speech,
    and speech-to-speech services. However, using WebSocket requires upgrading the
    connection from HTTP to the WebSocket protocol, which legacy clients and older
    browsers may not support. In addition, you will need to handle exceptions slightly
    differently with WebSocket endpoints.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: WebSocket连接为您的流机制提供了更多控制，并允许在同一连接中进行双向通信——例如，在具有多个用户和LLM的实时聊天应用、语音转文本、文本转语音和语音转语音服务中。然而，使用WebSocket需要将连接从HTTP升级到WebSocket协议，这可能不被旧版客户端和旧浏览器支持。此外，您需要以不同的方式处理WebSocket端点的异常。
- en: Handling WebSocket Exceptions
  id: totrans-359
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理WebSocket异常
- en: Handling WebSocket exceptions differs from traditional HTTP connections. If
    you refer to [Example 6-15](#websocket_endpoint), you will notice that you’re
    no longer returning a response with status codes, or `HTTPExceptions`, to the
    client but rather maintaining an open connection after connection acceptance.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 处理WebSocket异常与传统HTTP连接不同。如果您参考[示例6-15](#websocket_endpoint)，您会注意到您不再返回带有状态码的响应或`HTTPExceptions`给客户端，而是在连接接受后保持连接开启。
- en: As long as the connection is open, you’re sending and receiving messages. However,
    as soon as an exception has occurred, you should handle it either by gracefully
    closing the connection and/or by sending an error message to the client in replacement
    of an `HTTPException` response.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 只要连接保持开启状态，您就会发送和接收消息。然而，一旦发生异常，您应该通过优雅地关闭连接和/或向客户端发送错误消息来处理它，以替代`HTTPException`响应。
- en: Since the WebSocket protocol doesn’t support the usual HTTP status codes (`4xx`
    or `5xx`), you can’t use status codes to notify the clients of server-side issues.
    Instead, you should send WebSocket messages to clients to notify them of issues
    before you close any active connections from the server.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 由于WebSocket协议不支持常规的HTTP状态码（`4xx`或`5xx`），您不能使用状态码来通知客户端服务器端的问题。相反，您应该在关闭任何从服务器发出的活动连接之前，向客户端发送WebSocket消息来通知他们问题。
- en: During the connection closure, you can use several WebSocket-related status
    codes to specify the closure reason. Using these closure reasons, you can implement
    any custom closure behavior on the server or the clients.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 在连接关闭期间，您可以使用几个与WebSocket相关的状态码来指定关闭原因。使用这些关闭原因，您可以在服务器或客户端上实现任何自定义关闭行为。
- en: '[Table 6-2](#ws_status_codes) shows a few common status codes that can be sent
    with a `CLOSE` frame.'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: '[表6-2](#ws_status_codes)显示了可以与`CLOSE`帧一起发送的一些常见状态码。'
- en: Table 6-2\. WebSocket protocol common status codes
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 表6-2\. WebSocket协议常见状态码
- en: '| Status code | Description |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '| 状态码 | 描述 |'
- en: '| --- | --- |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1000 | Normal closure |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '| 1000 | 正常关闭 |'
- en: '| 1001 | Client navigated away or server has gone down |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '| 1001 | 客户端已导航离开或服务器已关闭 |'
- en: '| 1002 | An endpoint (i.e., client or server) received data violating the WS
    protocol (e.g., unmasked packets, invalid payload length) |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '| 1002 | 端点（即客户端或服务器）接收到的数据违反了WS协议（例如，未掩码的数据包，无效的有效负载长度）|'
- en: '| 1003 | An endpoint received unsupported data (e.g., was expecting text, got
    binary) |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| 1003 | 端点接收到的数据不受支持（例如，期望文本，却收到二进制数据）|'
- en: '| 1007 | An endpoint received inconsistently encoded data (e.g., non-UTF-8
    data within a text message) |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| 1007 | 接收到的端点数据编码不一致（例如，文本消息中的非UTF-8数据）|'
- en: '| 1008 | An endpoint received a message that violates its policy; can be used
    to hide closure details for security reasons |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| 1008 | 端点接收到的消息违反了其策略；可以用于出于安全原因隐藏关闭细节|'
- en: '| 1011 | Internal server error |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| 1011 | 内部服务器错误 |'
- en: You can learn more about other WebSocket status codes in the WebSocket protocol
    [RFC 6455—Section 7.4](https://oreil.ly/1L_HH).
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在WebSocket协议[RFC 6455—第7.4节](https://oreil.ly/1L_HH)中了解更多关于其他WebSocket状态码的信息。
- en: Designing APIs for Streaming
  id: totrans-376
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设计流式API
- en: Now that you’re more familiar with both SSE and WebSocket endpoint implementations,
    I want to cover one last important detail around their architectural design.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你对SSE和WebSocket端点实现更加熟悉，我想讨论它们架构设计的一个最后重要细节。
- en: A common pitfall of designing streaming APIs is exposing an excessive number
    of streaming endpoints. For instance, if you’re building a chatbot application,
    you may expose several streaming endpoints, each preconfigured to handle different
    incoming messages in a single conversation. By using this particular API design
    pattern, you’re asking the client to switch between endpoints, providing the necessary
    information in each step while navigating the streaming connections during a single
    conversation. This design pattern adds to the complexity of both the backend and
    frontend applications since the conversation states need to be managed on both
    sides while avoiding race condition and networking issues between components.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 设计流式API的一个常见陷阱是暴露过多的流式端点。例如，如果你正在构建一个聊天机器人应用程序，你可能需要暴露几个流式端点，每个端点预先配置以处理单个对话中的不同传入消息。通过使用这种特定的API设计模式，你要求客户端在单个对话中切换端点，在导航流式连接的同时，在每一步提供必要的信息。这种设计模式增加了后端和前端应用程序的复杂性，因为需要在双方管理会话状态，同时避免组件之间的竞争条件和网络问题。
- en: A simpler API design pattern is to provide a single entry point for the client
    to initiate a stream with your GenAI model(s) and use headers, request body, or
    query parameters to trigger the relevant logic in the backend. With this design,
    the backend logic is abstracted away from the client, which simplifies state management
    on the frontend while all routing and business logic are implemented on the backend.
    Since the backend has access to databases, other services, and customized prompts,
    it can easily perform CRUD operations and switch between prompts or models to
    compute a response. Therefore, one endpoint can act as a single entry point for
    switching logic, manage application states, and generate custom responses.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 一个更简单的API设计模式是为客户端提供一个单一的入口点，以启动与你的GenAI模型（s）的流，并使用头部、请求体或查询参数来触发后端的相关逻辑。在这种设计中，后端逻辑从客户端抽象出来，这简化了前端的状态管理，而所有路由和业务逻辑都实现在后端。由于后端可以访问数据库、其他服务和定制提示，它可以轻松执行CRUD操作并在提示或模型之间切换以计算响应。因此，一个端点可以作为切换逻辑的单个入口点，管理应用程序状态，并生成自定义响应。
- en: Summary
  id: totrans-380
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter covered several different strategies for implementing real-time
    communication via data streaming in your GenAI services.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了在GenAI服务中通过数据流实现实时通信的几种不同策略。
- en: You learned about several web communication mechanisms including the traditional
    HTTP request-response model, short/regular polling, long polling, SSE, and WebSocket.
    You then compared these mechanisms in detail to understand their features, benefits,
    disadvantages, and use cases, in particular for AI workflows. Finally, you implemented
    two LLM streaming endpoints using the asynchronous Azure OpenAI client to learn
    how to leverage SSE and WebSocket real-time communication mechanisms.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 你学习了包括传统HTTP请求-响应模型、短/常规轮询、长轮询、SSE和WebSocket在内的几种网络通信机制。然后你详细比较了这些机制，以了解它们的特性、优点、缺点和用例，特别是对于AI工作流。最后，你使用异步Azure
    OpenAI客户端实现了两个LLM流式端点，以学习如何利用SSE和WebSocket实时通信机制。
- en: In the next chapter, you will learn more about API development workflows when
    integrating databases for AI services. This will include how to set up, migrate,
    and interact with databases. You’ll also learn how to handle data storage-and-retrieval
    operations within streaming endpoints by using FastAPI’s background tasks.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习更多关于在集成数据库时API开发工作流程的知识。这包括如何设置、迁移和与数据库交互。你还将学习如何通过使用FastAPI的背景任务来处理流式端点内的数据存储和检索操作。
- en: Topics covered in the next chapter will include setting up databases and designing
    schemas, working with the SQLAlchemy, database migrations, and handling database
    operations when streaming model outputs.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将涵盖设置数据库、设计模式、使用SQLAlchemy、数据库迁移以及处理流模型输出时的数据库操作等主题。
- en: ^([1](ch06.html#id893-marker)) Attackers can use cache poisoning to inject malicious
    data to caching systems, which then serve incorrect data to users or systems.
    To protect against this attack, the client and the server mask payloads to appear
    as random data before sending them.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch06.html#id893-marker)) 攻击者可以使用缓存中毒来向缓存系统注入恶意数据，然后向用户或系统提供错误的数据。为了防止这种攻击，客户端和服务器在发送之前将有效载荷伪装成随机数据。
- en: ^([2](ch06.html#id894-marker)) These attacks involve tricking a server into
    leaking sensitive information by sending an HTTP response to a WebSocket frame.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch06.html#id894-marker)) 这些攻击涉及通过向 WebSocket 帧发送 HTTP 响应来诱骗服务器泄露敏感信息。
- en: ^([3](ch06.html#id906-marker)) See MDN resources for more details on the [`EventSource`
    interface](https://oreil.ly/0yuKA).
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch06.html#id906-marker)) 更多关于 `EventSource` 接口的信息，请参阅 MDN 资源。[`EventSource`
    接口](https://oreil.ly/0yuKA)。
- en: ^([4](ch06.html#id909-marker)) Follow the [“Accessing Private/Gated Models”
    guide](https://oreil.ly/a7KeV) to generate a Hugging Face user access token.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch06.html#id909-marker)) 按照指南[“访问私有/受保护模型”](https://oreil.ly/a7KeV)生成
    Hugging Face 用户访问令牌。
- en: ^([5](ch06.html#id912-marker)) Attackers use the XSS vulnerability to insert
    harmful scripts into web pages, which are then executed by other users’ browsers.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch06.html#id912-marker)) 攻击者利用 XSS 漏洞将有害脚本插入网页，然后由其他用户的浏览器执行。
- en: ^([6](ch06.html#id914-marker)) Exponential backoff reduces the chances of API
    rate-limiting errors by increasing the delay after each retry.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch06.html#id914-marker)) 指数退避通过增加每次重试后的延迟来降低 API 速率限制错误的概率。
