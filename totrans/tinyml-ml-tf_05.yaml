- en: 'Chapter 5\. The “Hello World” of TinyML: Building an Application'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章。TinyML的“Hello World”：构建一个应用程序
- en: A model is just one part of a machine learning application. Alone, it’s just
    a blob of information; it can’t do much at all. To use our model, we need to wrap
    it in code that sets up the necessary environment for it to run, provides it with
    inputs, and uses its outputs to generate behavior. [Figure 5-1](#basic_architecture)
    shows how the model, on the right hand side, fits into a basic TinyML application.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 模型只是机器学习应用程序的一部分。单独来看，它只是一块信息；它几乎什么都做不了。要使用我们的模型，我们需要将其包装在代码中，为其设置必要的运行环境，提供输入，并使用其输出生成行为。图5-1显示了模型在右侧如何适配到基本TinyML应用程序中。
- en: In this chapter, we will build an embedded application that uses our sine model
    to create a tiny light show. We’ll set up a continuous loop that feeds an `x`
    value into the model, runs inference, and uses the result to switch an LED on
    and off, or to control an animation if our device has an LCD display.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将构建一个嵌入式应用程序，使用我们的正弦模型创建一个微小的灯光秀。我们将设置一个连续循环，将一个`x`值输入模型，运行推断，并使用结果来开关LED灯，或者控制动画，如果我们的设备有LCD显示器的话。
- en: This [application](https://oreil.ly/mqkw3) has already been written. It’s a
    C++ 11 program whose code is designed to show the smallest possible implementation
    of a full TinyML application, avoiding any complex logic. This simplicity makes
    it a helpful tool for learning how to use TensorFlow Lite for Microcontrollers,
    since you can see exactly what code is necessary and very little else. It also
    makes it a useful template. After reading this chapter, you’ll understand the
    general structure of a TensorFlow Lite for Microcontrollers program, and you can
    reuse the same structure in your own projects.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这个应用程序已经编写好了。这是一个C++ 11程序，其代码旨在展示一个完整的TinyML应用程序的最小可能实现，避免任何复杂的逻辑。这种简单性使它成为学习如何使用TensorFlow
    Lite for Microcontrollers的有用工具，因为您可以清楚地看到需要哪些代码，以及很少的其他内容。它也是一个有用的模板。阅读完本章后，您将了解TensorFlow
    Lite for Microcontrollers程序的一般结构，并可以在自己的项目中重用相同的结构。
- en: This chapter walks through the application code and explains how it works. The
    next chapter will provide detailed instructions for building and deploying it
    to several devices. If you’re not familiar with C++, don’t panic. The code is
    relatively simple, and we explain everything in detail. By the time we’re done,
    you should feel comfortable with all the code that’s required to run a model,
    and you might even learn a little C++ along the way.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将逐步介绍应用程序代码并解释其工作原理。下一章将提供详细的构建和部署说明，适用于多种设备。如果您不熟悉C++，不要惊慌。代码相对简单，我们会详细解释一切。到最后，您应该对运行模型所需的所有代码感到满意，甚至可能在学习过程中学到一些C++知识。
- en: '![Diagram showing a basic TinyML application architecture](Images/timl_0501.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![显示基本TinyML应用程序架构的图表](Images/timl_0501.png)'
- en: Figure 5-1\. A basic TinyML application architecture
  id: totrans-6
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-1。基本TinyML应用程序架构
- en: Tip
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Remember, since TensorFlow is an actively developed open source project, there
    might be some minor differences between the code printed here and the code online.
    Don’t worry—even if a few lines of code change, the basic principles remain the
    same.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，由于TensorFlow是一个积极开发的开源项目，这里打印的代码与在线代码之间可能存在一些细微差异。不用担心，即使有一些代码行发生变化，基本原则仍然保持不变。
- en: Walking Through the Tests
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试步骤
- en: Before getting our hands dirty with application code, it’s often a good idea
    to write some tests. Tests are short snippets of code that demonstrate a particular
    piece of logic. Since they are made of working code, we can run them to prove
    that the code does what it’s supposed to. After we have written them, tests are
    often run automatically as a way to continually verify that a project is still
    doing what we expect despite any changes we might make to its code. They’re also
    very useful as working examples of how to do things.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理应用程序代码之前，编写一些测试通常是一个好主意。测试是演示特定逻辑片段的短代码片段。由于它们由可工作的代码组成，我们可以运行它们来证明代码是否按预期运行。编写完测试后，通常会自动运行测试，以持续验证项目是否仍然按照我们的期望运行，尽管我们可能对其代码进行了任何更改。它们也非常有用，作为如何执行操作的工作示例。
- en: The `hello_world` example has a test, defined in [*hello_world_test.cc*](https://oreil.ly/QW0SS),
    that loads our model and uses it to run inference, checking that its predictions
    are what we expect. It contains the exact code needed to do this, and nothing
    else, so it will be a great place to start learning TensorFlow Lite for Microcontrollers.
    In this section, we walk through the test and explain what each and every part
    of it does. After we’re done reading the code, we can run the test to prove that
    it’s correct.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '`hello_world`示例有一个测试，在[*hello_world_test.cc*](https://oreil.ly/QW0SS)中定义，加载我们的模型并使用它运行推断，检查其预测是否符合我们的期望。它包含了执行此操作所需的确切代码，没有其他内容，因此这将是学习TensorFlow
    Lite for Microcontrollers的绝佳起点。在本节中，我们将逐步介绍测试，并解释其中的每个部分的作用。阅读完代码后，我们可以运行测试以证明其正确性。'
- en: Let’s now walk through it, section by section. If you’re at a computer, it might
    be helpful to open up [*hello_world_test.cc*](https://oreil.ly/s0f6Q) and follow
    along.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们逐节来看一下。如果您在电脑上，打开*hello_world_test.cc*并跟着走可能会有帮助。
- en: Including Dependencies
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 包含依赖项
- en: 'The first part, below the license header (which specifies that anybody can
    use or share this code under the [Apache 2.0](https://oreil.ly/Xa5_x) open source
    license), looks like this:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 第一部分，在许可证标题下方（指定任何人都可以在[Apache 2.0](https://oreil.ly/Xa5_x)开源许可下使用或共享此代码），如下所示：
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The `#include` directive is a way for C++ code to specify other code that it
    depends on. When a code file is referenced with an `#include`, any logic or variables
    it defines will be available for us to use. In this section, we use `#include`
    to import the following items:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '`#include`指令是C++代码指定其依赖的其他代码的一种方式。当使用`#include`引用代码文件时，它定义的任何逻辑或变量将可供我们使用。在本节中，我们使用`#include`导入以下项目：'
- en: '*tensorflow/lite/micro/examples/hello_world/sine_model_data.h*'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '*tensorflow/lite/micro/examples/hello_world/sine_model_data.h*'
- en: The sine model we trained, converted, and transformed into C++ using `xxd`
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们训练的正弦模型，使用`xxd`转换并转换为C++
- en: '*tensorflow/lite/micro/kernels/all_ops_resolver.h*'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*tensorflow/lite/micro/kernels/all_ops_resolver.h*'
- en: A class that allows the interpreter to load the operations used by our model
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 一个允许解释器加载我们模型使用的操作的类
- en: '*tensorflow/lite/micro/micro_error_reporter.h*'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '*tensorflow/lite/micro/micro_error_reporter.h*'
- en: A class that can log errors and output to help with debugging
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 一个可以记录错误并输出以帮助调试的类
- en: '*tensorflow/lite/micro/micro_interpreter.h*'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '* tensorflow/lite/micro/micro_interpreter.h *'
- en: The TensorFlow Lite for Microcontrollers interpreter, which will run our model
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 将运行我们模型的TensorFlow Lite for Microcontrollers解释器
- en: '*tensorflow/lite/micro/testing/micro_test.h*'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '*tensorflow/lite/micro/testing/micro_test.h*'
- en: A lightweight framework for writing tests, which allows us to run this file
    as a test
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一个用于编写测试的轻量级框架，允许我们将此文件作为测试运行
- en: '*tensorflow/lite/schema/schema_generated.h*'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '*tensorflow/lite/schema/schema_generated.h*'
- en: The schema that defines the structure of TensorFlow Lite FlatBuffer data, used
    to make sense of the model data in *sine_model_data.h*
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 定义了TensorFlow Lite FlatBuffer数据结构的模式，用于理解*sine_model_data.h*中的模型数据
- en: '*tensorflow/lite/version.h*'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*tensorflow/lite/version.h*'
- en: The current version number of the schema, so we can check that the model was
    defined with a compatible version
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 模式的当前版本号，以便我们可以检查模型是否使用兼容版本定义
- en: We’ll talk more about some of these dependencies as we dig into the code.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们深入代码时，我们将更多地讨论其中一些依赖关系。
- en: Note
  id: totrans-32
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'By convention, C++ code designed to be used with `#include` directives is written
    as two files: a *.cc* file, known as the *source file*, and a *.h* file, known
    as the *header file*. Header files define the interface that allows the code to
    connect to other parts of the program. They contain things like variable and class
    declarations, but very little logic. Source files implement the actual logic that
    performs computation and makes things happen. When we `#include` a dependency,
    we specify its header file. For example, the test we’re walking through includes
    [*micro_interpreter.h*](https://oreil.ly/60uYt). If we look at that file, we can
    see that it defines a class but doesn’t contain much logic. Instead, its logic
    is contained within [*micro_interpreter.cc*](https://oreil.ly/twN7J).'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 按照惯例，设计用于与`#include`指令一起使用的C++代码通常编写为两个文件：一个*.cc*文件，称为*源文件*，以及一个*.h*文件，称为*头文件*。头文件定义了允许代码连接到程序其他部分的接口。它们包含变量和类声明等内容，但几乎没有逻辑。源文件实现了执行计算和使事情发生的实际逻辑。当我们`#include`一个依赖项时，我们指定其头文件。例如，我们正在讨论的测试包括[*micro_interpreter.h*](https://oreil.ly/60uYt)。如果我们查看该文件，我们可以看到它定义了一个类，但没有包含太多逻辑。相反，它的逻辑包含在[*micro_interpreter.cc*](https://oreil.ly/twN7J)中。
- en: Setting Up the Test
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置测试
- en: 'The next part of the code is used by the TensorFlow Lite for Microcontrollers
    testing framework. It looks like this:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 代码的下一部分用于TensorFlow Lite for Microcontrollers测试框架。看起来像这样：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In C++, you can define specially named chunks of code that can be reused by
    including their names elsewhere. These chunks of code are called *macros*. The
    two statements here, `TF_LITE_MICRO_TESTS_BEGIN` and `TF_LITE_MICRO_TEST`, are
    the names of macros. They are defined in the file [*micro_test.h*](https://oreil.ly/NoGm4).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在C++中，您可以定义特殊命名的代码块，可以通过在其他地方包含它们的名称来重用。这些代码块称为*宏*。这里的两个语句，`TF_LITE_MICRO_TESTS_BEGIN`和`TF_LITE_MICRO_TEST`，是宏的名称。它们在文件[*micro_test.h*](https://oreil.ly/NoGm4)中定义。
- en: These macros wrap the rest of our code in the necessary apparatus for it to
    be executed by the TensorFlow Lite for Microcontrollers testing framework. We
    don’t need to worry about how exactly this works; we just know that we can use
    these macros as shortcuts to set up a test.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这些宏将我们代码的其余部分包装在必要的装置中，以便通过TensorFlow Lite for Microcontrollers测试框架执行。我们不需要担心这是如何工作的；我们只需要知道我们可以使用这些宏作为设置测试的快捷方式。
- en: The second macro, named `TF_LITE_MICRO_TEST`, accepts an argument. In this case,
    the argument being passed in is `LoadModelAndPerformInference`. This argument
    is the test name, and when the tests are run, it will be output along with the
    test results so that we can see whether the test passed or failed.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个名为`TF_LITE_MICRO_TEST`的宏接受一个参数。在这种情况下，传入的参数是`LoadModelAndPerformInference`。这个参数是测试名称，当运行测试时，它将与测试结果一起输出，以便我们可以看到测试是通过还是失败。
- en: Getting Ready to Log Data
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 准备记录数据
- en: 'The remaining code in the file is the actual logic of our test. Let’s take
    a look at the first portion:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 文件中剩余的代码是我们测试的实际逻辑。让我们看一下第一部分：
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In the first line, we define a `MicroErrorReporter` instance. The `MicroErrorReporter`
    class is defined in [*micro_error_reporter.h*](https://oreil.ly/AkZrm). It provides
    a mechanism for logging debug information during inference. We’ll be calling it
    to print debug information, and the TensorFlow Lite for Microcontrollers interpreter
    will use it to print any errors it encounters.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一行中，我们定义了一个`MicroErrorReporter`实例。`MicroErrorReporter`类在[*micro_error_reporter.h*](https://oreil.ly/AkZrm)中定义。它提供了在推理期间记录调试信息的机制。我们将调用它来打印调试信息，而TensorFlow
    Lite for Microcontrollers解释器将使用它来打印遇到的任何错误。
- en: Note
  id: totrans-44
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: You’ve probably noticed the `tflite::` prefix before each of the type names,
    such as `tflite::MicroErrorReporter`. This is a *namespace*, which is just a way
    to help organize C++ code. TensorFlow Lite defines all of its useful stuff under
    the namespace `tflite`, which means that if another library happens to implement
    classes with the same name, they won’t conflict with those that TensorFlow Lite
    provides.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能已经注意到每个类型名称之前的`tflite::`前缀，例如`tflite::MicroErrorReporter`。这是一个*命名空间*，只是帮助组织C++代码的一种方式。TensorFlow
    Lite在命名空间`tflite`下定义了所有有用的内容，这意味着如果另一个库恰好实现了具有相同名称的类，它们不会与TensorFlow Lite提供的类发生冲突。
- en: The first declaration seems straightforward, but what about the funky-looking
    second line, with the `*` and `&` characters? Why are we declaring an `ErrorReporter`
    when we already have a `MicroErrorReporter`?
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个声明看起来很简单，但是第二行看起来有点奇怪，带有`*`和`&`字符？为什么我们要声明一个`ErrorReporter`当我们已经有一个`MicroErrorReporter`了？
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: To explain what is happening here, we need to know a little background information.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 解释这里发生的事情，我们需要了解一些背景信息。
- en: '`MicroErrorReporter` is a subclass of the `ErrorReporter` class, which provides
    a template for how this sort of debug logging mechanism should work in TensorFlow
    Lite. `MicroErrorReporter` overrides one of `ErrorReporter`’s methods, replacing
    it with logic that is specifically written for use on microcontrollers.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`MicroErrorReporter`是`ErrorReporter`类的一个子类，为TensorFlow Lite中这种调试日志机制应该如何工作提供了一个模板。`MicroErrorReporter`覆盖了`ErrorReporter`的一个方法，用专门为在微控制器上使用而编写的逻辑替换它。'
- en: In the preceding code line, we create a variable called `error_reporter`, which
    has the type `ErrorReporter`. It’s also a pointer, indicated by the * used in
    its declaration.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的代码行中，我们创建了一个名为`error_reporter`的变量，它的类型是`ErrorReporter`。它也是一个指针，其声明中使用了*表示。
- en: A pointer is a special type of variable that, instead of holding a value, holds
    a reference to a location in memory where a value can be found. In C++, a pointer
    of a certain class (such as `ErrorReporter`) can point to a value that is one
    of its child classes (such as `MicroErrorReporter`).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 指针是一种特殊类型的变量，它不是保存一个值，而是保存一个引用，指向内存中的一个值。在C++中，一个类的指针（比如`ErrorReporter`）可以指向它的一个子类（比如`MicroErrorReporter`）的值。
- en: As we mentioned earlier, `MicroErrorReporter` overrides one of the methods of
    `ErrorReporter`. Without going into too much detail, the process of overriding
    this method has the side effect of obscuring some of its other methods.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，`MicroErrorReporter`覆盖了`ErrorReporter`的一个方法。不详细讨论，覆盖这个方法的过程会导致一些其他方法被隐藏。
- en: To still have access to the non overridden methods of `ErrorReporter`, we need
    to treat our `MicroErrorReporter` instance as if it were actually an `ErrorReporter`.
    We achieve this by creating an `ErrorReporter` pointer and pointing it at the
    `micro_error_reporter` variable. The ampersand (`&`) in front of `micro_error_reporter`
    in the assignment means that we are assigning its pointer, not its value.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了仍然可以访问`ErrorReporter`的未覆盖方法，我们需要将我们的`MicroErrorReporter`实例视为实际上是`ErrorReporter`。我们通过创建一个`ErrorReporter`指针并将其指向`micro_error_reporter`变量来实现这一点。赋值语句中`&`在`micro_error_reporter`前面的意思是我们正在分配它的指针，而不是它的值。
- en: Phew! This sounds complicated. Don’t panic if you found it difficult to follow;
    C++ can be a little unwieldy. For our purposes, all we need to know is that that
    we should use `error_reporter` to print debug information, and that it’s a pointer.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 哎呀！听起来很复杂。如果你觉得难以理解，不要惊慌；C++可能有点难以掌握。对于我们的目的，我们只需要知道我们应该使用`error_reporter`来打印调试信息，并且它是一个指针。
- en: Mapping Our Model
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 映射我们的模型
- en: 'The reason we immediately set up a mechanism for printing debug information
    is so that we can log any problems that occur in the rest of the code. We rely
    on this in the next piece of code:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们立即建立打印调试信息的机制的原因是为了记录代码中发生的任何问题。我们在下一段代码中依赖于这一点：
- en: '[PRE4]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In the first line, we take our model data array (defined in the file [*sine_model_data.h*](https://oreil.ly/m68Wj))
    and pass it into a method named `GetModel()`. This method returns a `Model` pointer,
    which is assigned to a variable named `model`. As you might have anticipated,
    this variable represents our model.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一行中，我们将我们的模型数据数组（在文件[*sine_model_data.h*](https://oreil.ly/m68Wj)中定义）传递给一个名为`GetModel()`的方法。这个方法返回一个`Model`指针，被赋值给一个名为`model`的变量。正如你可能预料的那样，这个变量代表我们的模型。
- en: The type `Model` is a *struct*, which in C++ is very similar to class. It’s
    defined in [*schema_generated.h*](https://oreil.ly/SGNtU), and it holds our model’s
    data and allows us to query information about it.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 类型`Model`是一个*struct*，在C++中与类非常相似。它在[*schema_generated.h*](https://oreil.ly/SGNtU)中定义，它保存我们模型的数据并允许我们查询有关它的信息。
- en: 'As soon as `model` is ready, we call a method that retrieves the model’s version
    number:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦`model`准备好，我们调用一个检索模型版本号的方法：
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: We then compare the model’s version number to `TFLITE_SCHEMA_VERSION`, which
    indicates the version of the TensorFlow Lite library we are currently using. If
    the numbers match, our model was converted with a compatible version of the TensorFlow
    Lite Converter. It’s good practice to check the model version, because a mismatch
    might result in strange behavior that is tricky to debug.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将模型的版本号与`TFLITE_SCHEMA_VERSION`进行比较，这表示我们当前使用的TensorFlow Lite库的版本。如果数字匹配，我们的模型是使用兼容版本的TensorFlow
    Lite Converter转换的。检查模型版本是一个好习惯，因为版本不匹配可能导致难以调试的奇怪行为。
- en: Note
  id: totrans-63
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: In the preceding line of code, `version()` is a method that belongs to `model`.
    Notice the arrow (->) that points from `model` to `version()`. This is C++’s *arrow
    operator*, and it’s used whenever we want to access the members of an object to
    which we have a pointer. If we had the object itself (and not just a pointer),
    we would use a dot (`.`) to access its members.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一行代码中，`version()`是属于`model`的一个方法。注意箭头（->）从`model`指向`version()`。这是C++的*箭头运算符*，当我们想要访问一个对象的成员时使用。如果我们有对象本身（而不仅仅是一个指针），我们将使用点（.）来访问它的成员。
- en: 'If the version numbers don’t match, we’ll carry on anyway, but we’ll log a
    warning using our `error_reporter`:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如果版本号不匹配，我们仍然会继续，但我们会使用我们的`error_reporter`记录一个警告：
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We call the `Report()` method of `error_reporter` to log this warning. Since
    `error_reporter` is also a pointer, we use the -> operator to access `Report()`.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们调用`error_reporter`的`Report()`方法来记录这个警告。由于`error_reporter`也是一个指针，我们使用->运算符来访问`Report()`。
- en: The `Report()` method is designed to behave similarly to a commonly used C++
    method, `printf()`, which is used to log text. As its first parameter, we pass
    in a string that we want to log. This string contains two `%d` format specifiers,
    which act as placeholders where variables will be inserted when the message is
    logged. The next two parameters we pass in are the model version and the TensorFlow
    Lite schema version. These will be inserted into the string, in order, to replace
    the `%d` characters.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '`Report()`方法的设计类似于一个常用的C++方法`printf()`，用于记录文本。作为它的第一个参数，我们传递一个我们想要记录的字符串。这个字符串包含两个`%d`格式说明符，它们充当变量在消息记录时插入的占位符。我们传递的下两个参数是模型版本和TensorFlow
    Lite模式版本。这些将按顺序插入到字符串中，以替换`%d`字符。'
- en: Note
  id: totrans-69
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The `Report()` method supports different format specifiers that work as placeholders
    for different types of variables. `%d` should be used as a placeholder for integers,
    `%f` should be used as a placeholder for floating-point numbers, and `%s` should
    be used as a placeholder for strings.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`Report()`方法支持不同的格式说明符，用作不同类型变量的占位符。`%d`应该用作整数的占位符，`%f`应该用作浮点数的占位符，`%s`应该用作字符串的占位符。'
- en: Creating an AllOpsResolver
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建一个AllOpsResolver
- en: 'So far so good! Our code can log errors, and we’ve loaded our model into a
    handy struct and checked that it is a compatible version. We’ve been moving a
    little slowly, given that we’re reviewing some C++ concepts along the way, but
    things are starting to make sense. Next up, we create an instance of `AllOpsResolver`:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止一切顺利！我们的代码可以记录错误，我们已经将模型加载到一个方便的结构中，并检查它是否是兼容的版本。鉴于我们一路上在回顾一些C++概念，我们进展有点慢，但事情开始变得清晰起来了。接下来，我们创建一个`AllOpsResolver`的实例：
- en: '[PRE7]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This class, defined in [*all_ops_resolver.h*](https://oreil.ly/O0qgy), is what
    allows the TensorFlow Lite for Microcontrollers interpreter to access *operations*.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这个类在[*all_ops_resolver.h*](https://oreil.ly/O0qgy)中定义，它允许TensorFlow Lite for
    Microcontrollers解释器访问*操作*。
- en: In [Chapter 3](ch03.xhtml#chapter_get_up_to_speed), you learned that a machine
    learning model is composed of various mathematical operations that are run successively
    to transform input into output. The `AllOpsResolver` class knows all of the operations
    that are available to TensorFlow Lite for Microcontrollers and is able to provide
    them to the interpreter.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第3章](ch03.xhtml#chapter_get_up_to_speed)中，您了解到机器学习模型由各种数学运算组成，这些运算按顺序运行，将输入转换为输出。`AllOpsResolver`类知道TensorFlow
    Lite for Microcontrollers可用的所有操作，并能够将它们提供给解释器。
- en: Defining a Tensor Arena
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义张量区域
- en: 'We almost have all the ingredients ready to create an interpreter. The final
    thing we need to do is allocate an area of working memory that our model will
    need while it runs:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们几乎已经准备好创建一个解释器所需的所有要素。我们需要做的最后一件事是分配一个工作内存区域，我们的模型在运行时将需要这个内存区域：
- en: '[PRE8]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As the comment says, this area of memory will be used to store the model’s input,
    output, and intermediate tensors. We call it our *tensor arena*. In our case,
    we’ve allocated an array that is 2,048 bytes in size. We specify this with the
    expression `2 × 1024`.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 正如注释所说，这个内存区域将用于存储模型的输入、输出和中间张量。我们称之为我们的*张量区域*。在我们的情况下，我们分配了一个大小为2,048字节的数组。我们用表达式`2
    × 1024`来指定这一点。
- en: So, how large should our tensor arena be? That’s a good question. Unfortunately,
    there’s not a simple answer. Different model architectures have different sizes
    and numbers of input, output, and intermediate tensors, so it’s difficult to know
    how much memory we’ll need. The number doesn’t need to be exact—we can reserve
    more memory than we need—but since microcontrollers have limited RAM, we should
    keep it as small as possible so there’s space for the rest of our program.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们的张量区域应该有多大呢？这是一个很好的问题。不幸的是，没有一个简单的答案。不同的模型架构具有不同大小和数量的输入、输出和中间张量，因此很难知道我们需要多少内存。数字不需要精确——我们可以保留比我们需要的更多的内存——但由于微控制器的RAM有限，我们应该尽可能保持它小，以便为程序的其余部分留出空间。
- en: 'We can do this through trial and error. That’s why we express the array size
    as *`n`* `× 1024`: so that it’s easy to scale the number up and down (by changing
    *`n`*) while keeping it a multiple of eight. To find the correct array size, start
    fairly high so that you can be sure it works. The highest number used in this
    book’s examples is `70 × 1024`. Then, reduce the number until your model no longer
    runs. The last number that worked is the correct one!'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过试错来完成这个过程。这就是为什么我们将数组大小表示为*`n`* `× 1024`：这样可以很容易地通过改变*`n`*来扩大或缩小数字（保持为8的倍数）。要找到正确的数组大小，从一个相对较高的数字开始，以确保它有效。本书示例中使用的最大数字是`70
    × 1024`。然后，减少数字直到您的模型不再运行。最后一个有效的数字就是正确的数字！
- en: Creating an Interpreter
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建解释器
- en: 'Now that we’ve declared `tensor_arena`, we’re ready to set up the interpreter.
    Here’s how that looks:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经声明了`tensor_arena`，我们准备设置解释器。下面是具体步骤：
- en: '[PRE9]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'First, we declare a `MicroInterpreter` named `interpreter`. This class is the
    heart of TensorFlow Lite for Microcontrollers: a magical piece of code that will
    execute our model on the data we provide. We pass in most of the objects we’ve
    created so far to its constructor, and then make a call to `AllocateTensors()`.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们声明一个名为`interpreter`的`MicroInterpreter`。这个类是TensorFlow Lite for Microcontrollers的核心：一个神奇的代码片段，将在我们提供的数据上执行我们的模型。我们将迄今为止创建的大部分对象传递给它的构造函数，然后调用`AllocateTensors()`。
- en: In the previous section, we set aside an area of memory by defining an array
    called `tensor_arena`. The `AllocateTensors()` method walks through all of the
    tensors defined by the model and assigns memory from the `tensor_arena` to each
    of them. It’s critical that we call `AllocateTensors()` before attempting to run
    inference, because otherwise inference will fail.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们通过定义一个名为`tensor_arena`的数组来设置了一个内存区域。`AllocateTensors()`方法遍历模型定义的所有张量，并为每个张量从`tensor_arena`中分配内存。在尝试运行推理之前，我们必须调用`AllocateTensors()`，因为否则推理将失败。
- en: Inspecting the Input Tensor
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查输入张量
- en: 'After we’ve created an interpreter, we need to provide some input for our model.
    To do this, we write our input data to the model’s input tensor:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们创建了一个解释器之后，我们需要为我们的模型提供一些输入。为此，我们将我们的输入数据写入模型的输入张量：
- en: '[PRE10]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: To grab a pointer to an input tensor, we call the interpreter’s `input()` method.
    Since a model can have multiple input tensors, we need to pass an index to the
    `input()` method that specifies which tensor we want. In this case, our model
    has only one input tensor, so its index is `0`.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取输入张量的指针，我们调用解释器的`input()`方法。由于一个模型可以有多个输入张量，我们需要向`input()`方法传递一个指定我们想要的张量的索引。在这种情况下，我们的模型只有一个输入张量，所以它的索引是`0`。
- en: 'In TensorFlow Lite, tensors are represented by the `TfLiteTensor` struct, which
    is defined in [*c_api_internal.h*](https://oreil.ly/Qvhre). This struct provides
    an API for interacting with and learning about tensors. In the next chunk of code,
    we use this functionality to verify that our tensor looks and feels correct. Because
    we’ll be using tensors a lot, let’s walk through this code to become familiar
    with how the `TfLiteTensor` struct works:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在TensorFlow Lite中，张量由`TfLiteTensor`结构表示，该结构在[*c_api_internal.h*](https://oreil.ly/Qvhre)中定义。这个结构提供了一个API来与张量进行交互和了解张量。在下一段代码中，我们使用这个功能来验证我们的张量看起来和感觉正确。因为我们将经常使用张量，让我们通过这段代码来熟悉`TfLiteTensor`结构的工作方式：
- en: '[PRE11]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The first thing you’ll notice is a couple of macros: `TFLITE_MICRO_EXPECT_NE`
    and `TFLITE_MICRO_EXPECT_EQ`. These macros are part of the TensorFlow Lite for
    Microcontrollers testing framework, and they allow us to make *assertions* about
    the values of variables, proving that they have certain expected values.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到的第一件事是一对宏：`TFLITE_MICRO_EXPECT_NE`和`TFLITE_MICRO_EXPECT_EQ`。这些宏是TensorFlow
    Lite for Microcontrollers测试框架的一部分，它们允许我们对变量的值进行*断言*，证明它们具有某些期望的值。
- en: For example, the macro `TF_LITE_MICRO_EXPECT_NE` is designed to assert that
    the two variables it is called with are not equal (hence the `_NE` part of its
    name, which stands for Not Equal). If the variables are not equal, the code will
    continue to execute. If they are equal, an error will be logged, and the test
    will be marked as having failed.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，宏`TF_LITE_MICRO_EXPECT_NE`旨在断言它所调用的两个变量不相等（因此其名称中的`_NE`部分表示不相等）。如果变量不相等，代码将继续执行。如果它们相等，将记录一个错误，并标记测试为失败。
- en: 'The first thing we check is that our input tensor actually exists. To do this,
    we assert that it is *not equal* to a `nullptr`, which is a special C++ value
    representing a pointer that is not actually pointing at any data:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先检查的是我们的输入张量是否实际存在。为了做到这一点，我们断言它*不等于*`nullptr`，这是一个特殊的C++值，表示一个指针实际上没有指向任何数据：
- en: '[PRE12]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The next thing we check is the *shape* of our input tensor. As discussed in
    [Chapter 3](ch03.xhtml#chapter_get_up_to_speed), all tensors have a shape, which
    is a way of describing their dimensionality. The input to our model is a scalar
    value (meaning a single number). However, due to [the way Keras layers accept
    input](https://oreil.ly/SFiRV), this value must be provided inside of a 2D tensor
    containing one number. For an input of 0, it should look like this:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来检查的是我们输入张量的*形状*。如[第3章](ch03.xhtml#chapter_get_up_to_speed)中讨论的，所有张量都有一个形状，这是描述它们维度的一种方式。我们模型的输入是一个标量值（表示一个单个数字）。然而，由于[Keras层接受输入的方式](https://oreil.ly/SFiRV)，这个值必须提供在一个包含一个数字的2D张量中。对于输入0，它应该是这样的：
- en: '[PRE13]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note how the input scalar, 0, is wrapped inside of two vectors, making this
    a 2D tensor.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，输入标量0被包裹在两个向量中，使其成为一个2D张量。
- en: 'The `TfLiteTensor` struct contains a `dims` member that describes the dimensions
    of the tensor. The member is a struct of type `TfLiteIntArray`, also defined in
    *c_api_internal.h*. Its `size` member represents the number of dimensions that
    the tensor has. Since the input tensor should be 2D, we can assert that the value
    of `size` is `2`:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`TfLiteTensor`结构包含一个`dims`成员，描述张量的维度。该成员是一个类型为`TfLiteIntArray`的结构，也在*c_api_internal.h*中定义。它的`size`成员表示张量的维度数。由于输入张量应该是2D的，我们可以断言`size`的值为`2`：'
- en: '[PRE14]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'We can further inspect the `dims` struct to ensure the tensor’s structure is
    what we expect. Its `data` variable is an array with one element for each dimension.
    Each element is an integer representing the size of that dimension. Because we
    are expecting a 2D tensor containing one element in each dimension, we can assert
    that both dimensions contain a single element:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以进一步检查`dims`结构，以确保张量的结构是我们期望的。它的`data`变量是一个数组，每个维度有一个元素。每个元素是一个表示该维度大小的整数。因为我们期望一个包含每个维度一个元素的2D张量，我们可以断言两个维度都包含一个单一元素：
- en: '[PRE15]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: We can now be confident that our input tensor has the correct shape. Finally,
    since tensors can consist of a variety of different types of data (think integers,
    floating-point numbers, and Boolean values), we should make sure that our input
    tensor has the correct type.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以确信我们的输入张量具有正确的形状。最后，由于张量可以由各种不同类型的数据组成（比如整数、浮点数和布尔值），我们应该确保我们的输入张量具有正确的类型。
- en: 'The tensor struct’s `type` variable informs us of the data type of the tensor.
    We’ll be providing a 32-bit floating-point number, represented by the constant
    `kTfLiteFloat32`, and we can easily assert that the type is correct:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 张量结构体的`type`变量告诉我们张量的数据类型。我们将提供一个32位浮点数，由常量`kTfLiteFloat32`表示，我们可以轻松地断言类型是正确的：
- en: '[PRE16]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Perfect—our input tensor is now guaranteed to be the correct size and shape
    for our input data, which will be a single floating-point value. We’re ready to
    run inference!
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 完美——我们的输入张量现在已经保证是正确的大小和形状，适用于我们的输入数据，这将是一个单个浮点值。我们准备好进行推理了！
- en: Running Inference on an Input
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在输入上运行推理
- en: 'To run inference, we need to add a value to our input tensor and then instruct
    the interpreter to invoke the model. Afterward, we will check whether the model
    successfully ran. Here’s how that looks:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行推理，我们需要向我们的输入张量添加一个值，然后指示解释器调用模型。之后，我们将检查模型是否成功运行。这是它的样子：
- en: '[PRE17]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'TensorFlow Lite’s `TfLiteTensor` struct has a `data` variable that we can use
    to set the contents of our input tensor. You can see this being used here:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Lite的`TfLiteTensor`结构有一个`data`变量，我们可以用来设置输入张量的内容。你可以在这里看到它被使用：
- en: '[PRE18]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The `data` variable is a `TfLitePtrUnion`—it’s a *union*, which is a special
    C++ data type that allows you to store different data types at the same location
    in memory. Since a given tensor can contain one of many different types of data
    (for example, floating-point numbers, integers, or Booleans), a union is the perfect
    type to help us store it.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '`data`变量是一个`TfLitePtrUnion`——它是一个*union*，是一种特殊的C++数据类型，允许您在内存中的同一位置存储不同的数据类型。由于给定张量可以包含多种不同类型的数据（例如浮点数、整数或布尔值），union是帮助我们存储它的完美类型。'
- en: 'The `TfLitePtrUnion` union is declared in [*c_api_internal.h*](https://oreil.ly/v4h7K).
    Here’s what it looks like:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`TfLitePtrUnion`联合在[*c_api_internal.h*](https://oreil.ly/v4h7K)中声明。这是它的样子：'
- en: '[PRE19]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: You can see that there are a bunch of members, each representing a certain type.
    Each member is a pointer, which can point at a place in memory where the data
    should be stored. When we call `interpreter.AllocateTensors()`, like we did earlier,
    the appropriate pointer is set to point at the block of memory that was allocated
    for the tensor to store its data. Because each tensor has a specific data type,
    only the pointer for the corresponding type will be set.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到有一堆成员，每个代表一种特定类型。每个成员都是一个指针，可以指向内存中应存储数据的位置。当我们像之前那样调用`interpreter.AllocateTensors()`时，适当的指针被设置为指向为张量分配的内存块，以存储其数据。因为每个张量有一个特定的数据类型，所以只有相应类型的指针会被设置。
- en: This means that to store data, we can use whichever is the appropriate pointer
    in our `TfLitePtrUnion`. For example, if our tensor is of type `kTfLiteFloat32`,
    we’ll use `data.f`.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着为了存储数据，我们可以在`TfLitePtrUnion`中使用适当的指针。例如，如果我们的张量是`kTfLiteFloat32`类型，我们将使用`data.f`。
- en: 'Since the pointer points at a block of memory, we can use square brackets (`[]`)
    after the pointer name to instruct our program where to store the data. In our
    example, we do the following:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 由于指针指向一块内存块，我们可以在指针名称后使用方括号(`[]`)来指示程序在哪里存储数据。在我们的例子中，我们这样做：
- en: '[PRE20]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The value we’re assigning is written as `0.`, which is shorthand for `0.0`.
    By specifying the decimal point, we make it clear to the C++ compiler that this
    value should be a floating-point number, not an integer.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们分配的值写为`0.`，这是`0.0`的简写。通过指定小数点，我们让C++编译器清楚地知道这个值应该是一个浮点数，而不是整数。
- en: You can see that we assign this value to `data.f[0]`. This means that we’re
    assigning it as the first item in our block of allocated memory. Given that there’s
    only one value, this is all we need to do.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到我们将这个值分配给`data.f[0]`。这意味着我们将其分配为我们分配的内存块中的第一个项目。鉴于只有一个值，这就是我们需要做的。
- en: 'After we’ve set up the input tensor, it’s time to run inference. This is a
    one-liner:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 设置完输入张量后，是时候运行推理了。这是一个一行代码：
- en: '[PRE21]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: When we call `Invoke()` on the `interpreter`, the TensorFlow Lite interpreter
    runs the model. The model consists of a graph of mathematical operations which
    the interpreter executes to transform the input data into an output. This output
    is stored in the model’s output tensors, which we’ll dig into later.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们在`interpreter`上调用`Invoke()`时，TensorFlow Lite解释器会运行模型。该模型由数学运算图组成，解释器执行这些运算以将输入数据转换为输出。这个输出存储在模型的输出张量中，我们稍后会深入研究。
- en: 'The `Invoke()` method returns a `TfLiteStatus` object, which lets us know whether
    inference was successful or there was a problem. Its value can either be `kTfLiteOk`
    or `kTfLiteError`. We check for an error and report it if there is one:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`Invoke()`方法返回一个`TfLiteStatus`对象，让我们知道推理是否成功或是否有问题。它的值可以是`kTfLiteOk`或`kTfLiteError`。我们检查是否有错误，并在有错误时报告：'
- en: '[PRE22]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Finally, we assert that the status must be `kTfLiteOk` in order for our test
    to pass:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们断言状态必须是`kTfLiteOk`，以便我们的测试通过：
- en: '[PRE23]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: That’s it—inference has been run! Next up, we grab the output and make sure
    it looks good.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样——推理已经运行！接下来，我们获取输出并确保它看起来不错。
- en: Reading the Output
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 阅读输出
- en: 'Like the input, our model’s output is accessed through a `TfLiteTensor`, and
    getting a pointer to it is just as simple:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 与输入一样，我们模型的输出通过`TfLiteTensor`访问，获取指向它的指针同样简单：
- en: '[PRE24]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The output is, like the input, a floating-point scalar value nestled inside
    a 2D tensor. For the sake of our test, we double-check that the output tensor
    has the expected size, dimensions, and type:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 输出与输入一样，是一个嵌套在2D张量中的浮点标量值。为了测试，我们再次检查输出张量的预期大小、维度和类型：
- en: '[PRE25]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Yep, it all looks good. Now, we grab the output value and inspect it to make
    sure that it meets our high standards. First we assign it to a `float` variable:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，一切看起来都很好。现在，我们获取输出值并检查它，确保它符合我们的高标准。首先，我们将其分配给一个`float`变量：
- en: '[PRE26]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Each time inference is run, the output tensor will be overwritten with new values.
    This means that if you want to keep an output value around in your program while
    continuing to run inference, you’ll need to copy it from the output tensor, like
    we just did.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 每次运行推理时，输出张量将被新值覆盖。这意味着如果您想在程序中保留一个输出值，同时继续运行推理，您需要从输出张量中复制它，就像我们刚刚做的那样。
- en: 'Next, we use `TF_LITE_MICRO_EXPECT_NEAR` to prove that the value is close to
    the value we’re expecting:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们使用`TF_LITE_MICRO_EXPECT_NEAR`来证明该值接近我们期望的值：
- en: '[PRE27]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: As we saw earlier, `TF_LITE_MICRO_EXPECT_NEAR` asserts that the difference between
    its first argument and its second argument is less than the value of its third
    argument. In this statement, we’re testing that the output is within 0.05 of 0,
    which is the mathematical sine of the input, 0.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前看到的，`TF_LITE_MICRO_EXPECT_NEAR`断言其第一个参数和第二个参数之间的差异小于其第三个参数的值。在这个语句中，我们测试输出是否在0的数学正弦输入0的0.05范围内。
- en: Note
  id: totrans-141
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'There are two reasons why we expect a number that is *near* to what we want,
    but not an exact value. The first is that our model only *approximates* the real
    sine value, so we know that it will not be exactly correct. The second is because
    floating-point calculations on computers have a margin of error. The error can
    vary from computer to computer: for example, a laptop’s CPU might come up with
    slightly different results to an Arduino. By having flexible expectations, we
    make it more likely that our test will pass on any platform.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们期望得到一个接近我们想要的数字的原因有两个，但不是一个精确值。第一个原因是我们的模型只是*近似*真实的正弦值，所以我们知道它不会完全正确。第二个原因是因为计算机上的浮点计算有一个误差范围。误差可能因计算机而异：例如，笔记本电脑的
    CPU 可能会产生与 Arduino 稍有不同的结果。通过具有灵活的期望，我们更有可能使我们的测试在任何平台上通过。
- en: 'If this test passes, things are looking good. The remaining tests run inference
    a few more times, just to further prove that our model is working. To run inference
    again, all we need to do is assign a new value to our input tensor, call `interpreter.Invoke()`,
    and read the output from our output tensor:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这个测试通过，情况看起来很好。其余的测试会再次运行推理几次，只是为了进一步证明我们的模型正在工作。要再次运行推理，我们只需要为我们的输入张量分配一个新值，调用
    `interpreter.Invoke()`，并从输出张量中读取输出：
- en: '[PRE28]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Note how we’re reusing the same `input` and `output` tensor pointer. Because
    we already have the pointers, we don’t need to call `interpreter.input(0)` or
    `interpreter.output(0)` again.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意我们如何重复使用相同的 `input` 和 `output` 张量指针。因为我们已经有了指针，所以我们不需要再次调用 `interpreter.input(0)`
    或 `interpreter.output(0)`。
- en: 'At this point in our tests we’ve proven that TensorFlow Lite for Microcontrollers
    can successfully load our model, allocate the appropriate input and output tensors,
    run inference, and return the expected results. The final thing to do is indicate
    the end of the tests by using a macro:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的测试中，我们已经证明了 TensorFlow Lite for Microcontrollers 可以成功加载我们的模型，分配适当的输入和输出张量，运行推理，并返回预期的结果。最后要做的是使用宏指示测试的结束：
- en: '[PRE29]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: And with that, we’re done walking through the tests. Next, let’s run them!
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们完成了测试。接下来，让我们运行它们！
- en: Running the Tests
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行测试
- en: Even though this code is eventually destined to run on microcontrollers, we
    can still build and run our tests on our development machine. This makes it much
    easier to write and debug code. Compared with microcontrollers, a personal computer
    has far more convenient tools for logging output and stepping through code, which
    makes it a lot simpler to figure out any bugs. In addition, deploying code to
    a device takes time, so it’s a lot quicker to just run our code locally.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这段代码最终将在微控制器上运行，但我们仍然可以在开发计算机上构建和运行我们的测试。这样做可以更轻松地编写和调试代码。与微控制器相比，个人计算机具有更方便的日志记录工具和代码调试工具，这使得更容易找出任何错误。此外，将代码部署到设备需要时间，因此仅在本地运行代码会更快。
- en: A good workflow for building embedded applications (or, honestly, any kind of
    software) is to write as much of the logic as you can in tests that can be run
    on a normal development machine. There’ll always be some parts that require the
    actual hardware to run, but the more you can test locally, the easier your life
    will be.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 构建嵌入式应用程序（或者说，任何类型的软件）的一个好的工作流程是尽可能多地在可以在普通开发计算机上运行的测试中编写逻辑。总会有一些部分需要实际硬件才能运行，但你在本地测试的越多，你的生活就会变得更容易。
- en: Practically, this means that we should try to write the code that preprocesses
    inputs, runs inference with the model, and processes any outputs in a set of tests
    before trying to get it working on-device. In [Chapter 7](ch07.xhtml#chapter_speech_wake_word_example),
    we walk through a speech recognition application that is much more complex than
    this example. You’ll see how we’ve written detailed unit tests for each of its
    components.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这意味着我们应该尝试在一组测试中编写预处理输入、使用模型运行推理以及处理任何输出的代码，然后再尝试在设备上使其正常工作。在[第7章](ch07.xhtml#chapter_speech_wake_word_example)中，我们将介绍一个比这个示例复杂得多的语音识别应用程序。你将看到我们为其每个组件编写了详细的单元测试。
- en: Grabbing the code
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 获取代码
- en: Until now, between Colab and GitHub, we’ve been doing everything in the cloud.
    To run our tests, we need to pull down the code to our development computer and
    compile it.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在 Colab 和 GitHub 之间，我们一直在云端进行所有操作。为了运行我们的测试，我们需要将代码下载到我们的开发计算机并进行编译。
- en: 'To do all this, we need the following software tools:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一切，我们需要以下软件工具：
- en: A terminal emulator, such as Terminal in macOS
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 终端仿真器，如 macOS 中的终端
- en: A bash shell (the default in macOS prior to Catalina and most Linux distributions)
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 bash shell（在 macOS Catalina 之前和大多数 Linux 发行版中是默认的）
- en: '[Git](https://git-scm.com/) (installed by default in macOS and most Linux distributions)'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Git](https://git-scm.com/)（在 macOS 和大多数 Linux 发行版中默认安装）'
- en: Make, version 3.82 or later
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Make，版本3.82或更高版本
- en: 'After you have all the tools, open up a terminal and enter the command that
    follows to download the TensorFlow source code, which includes the example code
    we’re working with. It will create a directory containing the source code in whatever
    location you run it:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在你拥有所有工具之后，打开一个终端并输入以下命令来下载 TensorFlow 源代码，其中包括我们正在使用的示例代码。它将在你运行它的任何位置创建一个包含源代码的目录：
- en: '[PRE30]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Next, change into the *tensorflow* directory that was just created:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，切换到刚刚创建的 *tensorflow* 目录：
- en: '[PRE31]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Great stuff—we’re now ready to run some code!
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 太棒了 - 我们现在准备运行一些代码！
- en: Using Make to run the tests
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Make 运行测试
- en: As you saw from our list of tools, we use a program called *Make* to run the
    tests. Make is a tool for automating build tasks in software. It’s been in use
    since 1976, which in computing terms is almost forever. Developers use a special
    language, written in files called *Makefiles*, to instruct Make how to build and
    run code. TensorFlow Lite for Microcontrollers has a Makefile defined in [*micro/tools/make/Makefile*](https://oreil.ly/6Kvx5);
    there’s more information about it in [Chapter 13](ch13.xhtml#chapter_tensorflow_lite_for_microcontrollers).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们的工具列表中可以看到，我们使用一个名为*Make*的程序来运行测试。Make是一个用于自动化软件构建任务的工具。它自1976年以来一直在使用，从计算术语来看几乎是永远的。开发人员使用一种特殊的语言，在名为*Makefiles*的文件中编写，指示Make如何构建和运行代码。TensorFlow
    Lite for Microcontrollers在[*micro/tools/make/Makefile*](https://oreil.ly/6Kvx5)中定义了一个Makefile；在[第13章](ch13.xhtml#chapter_tensorflow_lite_for_microcontrollers)中有更多关于它的信息。
- en: 'To run our tests using Make, we can issue the following command, making sure
    we’re running it from the root of the *tensorflow* directory we downloaded with
    Git. We first specify the Makefile to use, followed by the *target*, which is
    the component that we want to build:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Make运行我们的测试，我们可以发出以下命令，确保我们是从使用Git下载的*tensorflow*目录的根目录运行。我们首先指定要使用的Makefile，然后是*target*，即我们要构建的组件：
- en: '[PRE32]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The Makefile is set up so that in order to run tests, we provide a target with
    the prefix `test_` followed by the name of the component that we want to build.
    In our case, that component is *`hello_world_test`*, so the full target name is
    *`test_hello_world_test`*.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Makefile被设置为为了运行测试，我们提供一个以`test_`为前缀的目标，后面跟着我们想要构建的组件的名称。在我们的情况下，该组件是*`hello_world_test`*，因此完整的目标名称是*`test_hello_world_test`*。
- en: Try running this command. You should start to see a ton of output fly past!
    First, some necessary libraries and tools will be downloaded. Next, our test file,
    along with all of its dependencies, will be built. Our Makefile has instructed
    the C++ compiler to build the code and create a binary, which it will then run.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试运行这个命令。您应该开始看到大量输出飞过！首先，将下载一些必要的库和工具。接下来，我们的测试文件以及所有依赖项将被构建。我们的Makefile已经指示C++编译器构建代码并创建一个二进制文件，然后运行它。
- en: 'You’ll need to wait a few moments for the process to complete. When the text
    stops zooming past, the last few lines should look like this:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要等待一段时间才能完成这个过程。当文本停止飞过时，最后几行应该是这样的：
- en: '[PRE33]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Nice! This output shows that our test passed as expected. You can see the name
    of the test, `LoadModelAndPerformInference`, as defined at the top of its source
    file. Even if it’s not on a microcontroller yet, our code is successfully running
    inference.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 很好！这个输出显示我们的测试按预期通过了。您可以看到测试的名称`LoadModelAndPerformInference`，如其源文件顶部所定义。即使它还没有在微控制器上，我们的代码也成功地运行了推断。
- en: 'To see what happens when tests fail, let’s introduce an error. Open up the
    test file, *hello_world_test.cc*. It will be at this path, relative to the root
    of the directory:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看测试失败时会发生什么，让我们引入一个错误。打开测试文件*hello_world_test.cc*。它将位于相对于目录根目录的路径：
- en: '[PRE34]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'To make the test fail, let’s provide a different input to the model. This will
    cause the model’s output to change, so the assertion that checks the value of
    our output will fail. Find the following line:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使测试失败，让我们为模型提供不同的输入。这将导致模型的输出发生变化，因此检查我们输出值的断言将失败。找到以下行：
- en: '[PRE35]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Change the assigned value, like so:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 更改分配的值，如下所示：
- en: '[PRE36]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Now save the file, and use the following command to run the test again (remember
    to do this from the root of the *tensorflow* directory):'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 现在保存文件，并使用以下命令再次运行测试（记得要从*tensorflow*目录的根目录运行）：
- en: '[PRE37]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The code will be rebuilt, and the test will run. The final output you see should
    look like this:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 代码将被重建，测试将运行。您看到的最终输出应该如下所示：
- en: '[PRE38]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The output contains some useful information about why the test failed, including
    the file and line number where the failure took place (`hello_world_test.cc:94`).
    If this were caused by a real bug, this output would be helpful in tracking down
    the issue.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 输出包含有关测试失败原因的一些有用信息，包括失败发生的文件和行号（`hello_world_test.cc:94`）。如果这是由于真正的错误引起的，这个输出将有助于追踪问题。
- en: Project File Structure
  id: totrans-185
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 项目文件结构
- en: With the help of our test, you’ve learned how to use the TensorFlow Lite for
    Microcontrollers library to run inference in C++. Next, we’re going to walk through
    the source code of an actual application.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 借助我们的测试，您已经学会了如何使用TensorFlow Lite for Microcontrollers库在C++中运行推断。接下来，我们将浏览一个实际应用程序的源代码。
- en: As discussed earlier, the program we’re building consists of a continuous loop
    that feeds an `x` value into the model, runs inference, and uses the result to
    produce some sort of visible output (like a pattern of flashing LEDs), depending
    on the platform.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们正在构建的程序由一个连续循环组成，该循环将一个`x`值输入模型，运行推断，并使用结果生成某种可见输出（如闪烁LED的模式），具体取决于平台。
- en: Because the application is complex and spans multiple files, let’s take a look
    at its structure and how it all fits together.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 因为应用程序很复杂，涉及多个文件，让我们看看它的结构以及它们如何相互配合。
- en: 'The root of the application is in *tensorflow/lite/micro/examples/hello_world*.
    It contains the following files:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 应用程序的根目录在*tensorflow/lite/micro/examples/hello_world*中。它包含以下文件：
- en: BUILD
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: BUILD
- en: A file that lists the various things that can be built using the application’s
    source code, including the main application binary and the tests we walked through
    earlier. We don’t need to worry too much about it at this point.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 一个列出可以使用应用程序源代码构建的各种内容的文件，包括主应用程序二进制文件和我们之前讨论过的测试。在这一点上，我们不需要太担心它。
- en: Makefile.inc
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: Makefile.inc
- en: A Makefile that contains information about the build targets within our application,
    including *hello_world_test*, which is the test we ran earlier, and *hello_world*,
    the main application binary. It defines which source files are part of them.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 一个包含有关应用程序内部构建目标信息的Makefile，包括*hello_world_test*，这是我们之前运行的测试，以及*hello_world*，主应用程序二进制文件。它定义了它们的哪些源文件是其中的一部分。
- en: README.md
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: README.md
- en: A readme file containing instructions on building and running the application.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 一个包含构建和运行应用程序说明的自述文件。
- en: constants.h, constants.cc
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: constants.h, constants.cc
- en: A pair of files containing various *constants* (variables that don’t change
    during the lifetime of a program) that are important for defining the program’s
    behavior.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 一对包含各种*常量*（在程序生命周期中不会改变的变量）的文件，这些常量对于定义程序行为很重要。
- en: create_sine_model.ipynb
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: create_sine_model.ipynb
- en: The Jupyter notebook used in the previous chapter.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中使用的 Jupyter 笔记本。
- en: hello_world_test.cc
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: hello_world_test.cc
- en: A test that runs inference using our model.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 一个使用我们模型运行推断的测试。
- en: main.cc
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: main.cc
- en: The entry point of the program, which runs first when the application is deployed
    to a device.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 程序的入口点，在应用部署到设备时首先运行。
- en: main_functions.h, main_functions.cc
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: main_functions.h, main_functions.cc
- en: A pair of files that define a `setup()` function, which performs all the initialization
    required by our program, and a `loop()` function, which contains the program’s
    core logic and is designed to be called repeatedly in a loop. These functions
    are called by *main.cc* when the program starts.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 一对文件，定义了一个`setup()`函数，执行我们程序所需的所有初始化，以及一个`loop()`函数，包含程序的核心逻辑，并设计为在循环中重复调用。这些函数在程序启动时由*main.cc*调用。
- en: output_handler.h, output_handler.cc
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: output_handler.h, output_handler.cc
- en: A pair of files that define a function we can use to display an output each
    time inference is run. The default implementation, in *output_handler.cc*, prints
    the result to the screen. We can override this implementation so that it does
    different things on different devices.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 一对文件，定义了一个函数，我们可以用它来显示每次运行推断时的输出。默认实现在*output_handler.cc*中，将结果打印到屏幕上。我们可以覆盖这个实现，使其在不同设备上执行不同的操作。
- en: output_handler_test.cc
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: output_handler_test.cc
- en: A test that proves that the code in *output_handler.h* and *output_handler.cc*
    is working correctly.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 一个证明*output_handler.h*和*output_handler.cc*中的代码正常工作的测试。
- en: sine_model_data.h, sine_model_data.cc
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: sine_model_data.h, sine_model_data.cc
- en: A pair of files that define an array of data representing our model, as exported
    using `xxd` in the first part of this chapter.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 一对文件，定义了一个表示我们模型的数据数组，这些数据是在本章的第一部分中使用`xxd`导出的。
- en: 'In addition to these files, the directory contains the following subdirectories
    (and perhaps more):'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这些文件外，目录中还包含以下子目录（可能还有更多）：
- en: '*arduino/*'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*arduino/*'
- en: '*disco_f76ng/*'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*disco_f76ng/*'
- en: '*sparkfun_edge/*'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*sparkfun_edge/*'
- en: Because different microcontroller platforms have different capabilities and
    APIs, our project structure allows us to provide device-specific versions of source
    files that will be used instead of the defaults if the application is built for
    that device. For example, the *arduino* directory contains custom versions of
    *main.cc*, *constants.cc*, and *output_handler.cc* that tailor the application
    to work with Arduino. We dig into these custom implementations later.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 因为不同的微控制器平台具有不同的功能和 API，我们的项目结构允许我们提供设备特定版本的源文件，如果应用程序为该设备构建，则将使用这些版本而不是默认版本。例如，*arduino*目录包含了定制版本的*main.cc*、*constants.cc*和*output_handler.cc*，以使应用程序能够与
    Arduino 兼容。我们稍后会深入研究这些定制实现。
- en: Walking Through the Source
  id: totrans-217
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 源代码解析
- en: Now that we know how the application’s source is structured, let’s dig into
    the code. We’ll begin with [*main_functions.cc*](https://oreil.ly/BYS5k), where
    most of the magic happens, and branch out into the other files from there.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了应用程序源代码的结构，让我们深入代码。我们将从[*main_functions.cc*](https://oreil.ly/BYS5k)开始，这里发生了大部分的魔法，并从那里扩展到其他文件。
- en: Note
  id: totrans-219
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: A lot of this code will look very familiar from our earlier adventures in *hello_world_test.cc*.
    If we’ve covered something already, we won’t go into depth on how it works; we’d
    rather focus mainly on the things you haven’t seen before.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码中很多内容在*hello_world_test.cc*中会看起来很熟悉。如果我们已经涵盖了某些内容，我们不会深入讨论它的工作原理；我们更愿意主要关注您之前没有见过的内容。
- en: Starting with main_functions.cc
  id: totrans-221
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从main_functions.cc开始
- en: 'This file contains the core logic of our program. It begins like this, with
    some familiar `#include` statements and some new ones:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 这个文件包含了我们程序的核心逻辑。它从一些熟悉的`#include`语句和一些新的语句开始：
- en: '[PRE39]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: We saw a lot of these in *hello_world_test.cc*. New to the scene are *constants.h*
    and `output_handler.h`, which we learned about in the list of files earlier.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在*hello_world_test.cc*中看到了很多这样的内容。新出现的是*constants.h*和`output_handler.h`，我们在前面的文件列表中了解到了这些。
- en: 'The next part of the file sets up the global variables that will be used within
    *main_functions.cc*:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 文件的下一部分设置了将在*main_functions.cc*中使用的全局变量：
- en: '[PRE40]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: You’ll notice that these variables are wrapped in a `namespace`. This means
    that even though they will be accessible from anywhere within *main_functions.cc*,
    they won’t be accessible from any other files within the project. This helps prevent
    problems if two different files happen to define variables with the same name.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 您会注意到这些变量被包裹在一个`namespace`中。这意味着即使它们可以在*main_functions.cc*中的任何地方访问，但在项目中的其他文件中是无法访问的。这有助于防止如果两个不同的文件恰好定义了相同名称的变量时出现问题。
- en: All of these variables should look familiar from the tests. We set up variables
    to hold all of our familiar TensorFlow objects, along with a `tensor_arena`. The
    only new thing is an `int` that holds `inference_count`, which will keep track
    of how many inferences our program has performed.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些变量应该在测试中看起来很熟悉。我们设置变量来保存所有熟悉的 TensorFlow 对象，以及一个`tensor_arena`。唯一新的是一个保存`inference_count`的`int`，它将跟踪我们的程序执行了多少次推断。
- en: The next part of the file declares a function named `setup()`. This function
    will be called when the program first starts, but never again after that. We use
    it to do all of the one-time housekeeping work that needs to happen before we
    start running inference.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 文件的下一部分声明了一个名为`setup()`的函数。这个函数将在程序首次启动时调用，但之后不会再次调用。我们用它来做所有需要在开始运行推断之前发生的一次性工作。
- en: 'The first part of `setup()` is almost exactly the same as in our tests. We
    set up logging, load our model, set up the interpreter, and allocate memory:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '`setup()`的第一部分几乎与我们的测试中的相同。我们设置日志记录，加载我们的模型，设置解释器并分配内存：'
- en: '[PRE41]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Familiar territory so far. After this point, though, things get a little different.
    First, we grab pointers to both the input *and* output tensors:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止都是熟悉的领域。然而，在这一点之后，事情有点不同。首先，我们获取输入张量和输出张量的指针：
- en: '[PRE42]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: You might be wondering how we can interact with the output before inference
    has been run. Well, remember that `TfLiteTensor` is just a struct that has a member,
    `data`, pointing to an area of memory that has been allocated to store the output.
    Even though no output has been written yet, the struct and its `data` member still
    exist.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能想知道在运行推断之前我们如何与输出交互。请记住，`TfLiteTensor`只是一个结构体，它有一个成员`data`，指向一个已分配用于存储输出的内存区域。即使还没有写入任何输出，结构体及其`data`成员仍然存在。
- en: 'Finally, to end the `setup()` function, we set our `inference_count` variable
    to `0`:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，为了结束`setup()`函数，我们将我们的`inference_count`变量设置为`0`：
- en: '[PRE43]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: At this point, all of our machine learning infrastructure is set up and ready
    to go. We have all the tools required to run inference and get the results. The
    next thing to define is our application logic. What is the program actually going
    to *do*?
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们所有的机器学习基础设施都已经设置好并准备就绪。我们拥有运行推断并获得结果所需的所有工具。接下来要定义的是我们的应用逻辑。程序实际上要做什么？
- en: Our model was trained to predict the sine of any number from 0 to 2π, which
    represents the full cycle of a sine wave. To demonstrate our model, we could just
    feed in numbers in this range, predict their sines, and then output the values
    somehow. We could do this in a sequence so that we show the model working across
    the entire range. This sounds like a good plan!
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型经过训练，可以预测从0到2π的任何数字的正弦值，这代表正弦波的完整周期。为了展示我们的模型，我们可以只输入这个范围内的数字，预测它们的正弦值，然后以某种方式输出这些值。我们可以按顺序执行这些操作，以展示模型在整个范围内的工作。这听起来是一个不错的计划！
- en: 'To do this, we need to write some code that runs in a loop. First, we declare
    a function called `loop()`, which is what we’ll be walking through next. The code
    we place in this function will be run repeatedly, over and over again:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做到这一点，我们需要编写一些在循环中运行的代码。首先，我们声明一个名为`loop()`的函数，接下来我们将逐步介绍。我们放在这个函数中的代码将被重复运行，一遍又一遍：
- en: '[PRE44]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'First in our `loop()` function, we must determine what value to pass into the
    model (let’s call it our `x` value). We determine this using two constants: `kXrange`,
    which specifies the maximum possible `x` value as 2π, and `kInferencesPerCycle`,
    which defines the number of inferences that we want to perform as we step from
    0 to 2π. The next few lines of code calculate the `x` value:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 首先在我们的`loop()`函数中，我们必须确定要传递给模型的值（让我们称之为我们的`x`值）。我们使用两个常量来确定这一点：`kXrange`，它指定最大可能的`x`值为2π，以及`kInferencesPerCycle`，它定义了我们希望在从0到2π的步骤中执行的推断数量。接下来的几行代码计算`x`值：
- en: '[PRE45]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: The first two lines of code just divide `inference_count` (which is the number
    of inferences we’ve done so far) by `kInferencesPerCycle` to obtain our current
    “position” within the range. The next line multiplies that value by `kXrange`,
    which represents the maximum value in the range (2π). The result, `x_val`, is
    the value we’ll be passing into our model.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 前两行代码只是将`inference_count`（到目前为止我们已经做的推断次数）除以`kInferencesPerCycle`，以获得我们在范围内的当前“位置”。下一行将该值乘以`kXrange`，它代表范围中的最大值（2π）。结果`x_val`是我们将传递给模型的值。
- en: Note
  id: totrans-244
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: '`static_cast<float>()` is used to convert `inference_count` and `kInferencesPerCycle`,
    which are both integer values, into floating-point numbers. We do this so that
    we can correctly perform division. In C++, if you divide two integers, the result
    is an integer; any fractional part of the result is dropped. Because we want our
    `x` value to be a floating-point number that includes the fractional part, we
    need to convert the numbers being divided into floating points.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '`static_cast<float>()`用于将`inference_count`和`kInferencesPerCycle`（两者都是整数值）转换为浮点数。我们这样做是为了能够正确执行除法。在C++中，如果你将两个整数相除，结果将是一个整数；结果的任何小数部分都会被舍弃。因为我们希望我们的`x`值是一个包含小数部分的浮点数，所以我们需要将被除数转换为浮点数。'
- en: The two constants we use, `kInferencesPerCycle` and `kXrange`, are defined in
    the files *constants.h* and *constants.cc*. It’s a C++ convention to prefix the
    names of constants with a `k`, so they’re easily identifiable as constants when
    using them in code. It can be useful to define constants in a separate file so
    they can be included and used in any place that they are needed.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的两个常量，`kInferencesPerCycle`和`kXrange`，在文件*constants.h*和*constants.cc*中定义。在使用这些常量时，C++的惯例是在常量名称前加上`k`，这样它们在代码中使用时很容易识别为常量。将常量定义在单独的文件中可能很有用，这样它们可以在需要的任何地方被包含和使用。
- en: 'The next part of our code should look nice and familiar; we write our `x` value
    to the model’s input tensor, run inference, and then grab the result (let’s call
    it our `y` value) from the output tensor:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我们代码的下一部分应该看起来很熟悉；我们将我们的`x`值写入模型的输入张量，运行推断，然后从输出张量中获取结果（让我们称之为我们的`y`值）：
- en: '[PRE46]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: We now have a sine value. Since it takes a small amount of time to run inference
    on each number, and this code is running in a loop, we’ll be generating a sequence
    of sine values over time. This will be perfect for controlling some blinking LEDs
    or an animation. Our next job is to output it somehow.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个正弦值。由于对每个数字运行推断需要一点时间，并且这段代码在循环中运行，我们将随时间生成一系列正弦值。这将非常适合控制一些闪烁的LED或动画。我们的下一个任务是以某种方式输出它。
- en: 'The following line calls the `HandleOutput()` function, defined in *output_handler.cc*:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 以下一行调用了在*output_handler.cc*中定义的`HandleOutput()`函数：
- en: '[PRE47]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: We pass in our `x` and `y` values, along with our `ErrorReporter` instance,
    which we can use to log things. To see what happens next, let’s explore *output_handler.cc*.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 我们传入我们的`x`和`y`值，以及我们的`ErrorReporter`实例，我们可以用它来记录事情。要查看接下来会发生什么，让我们来探索*output_handler.cc*。
- en: Handling Output with output_handler.cc
  id: totrans-253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用output_handler.cc处理输出
- en: 'The file *output_handler.cc* defines our `HandleOutput()` function. Its implementation
    is very simple:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 文件*output_handler.cc*定义了我们的`HandleOutput()`函数。它的实现非常简单：
- en: '[PRE48]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: All this function does is use the `ErrorReporter` instance to log the `x` and
    `y` values. This is just a bare-minimum implementation that we can use to test
    the basic functionality of our application, for example by running it on our development
    computer.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数所做的就是使用`ErrorReporter`实例来记录`x`和`y`的值。这只是一个最基本的实现，我们可以用来测试应用程序的基本功能，例如在开发计算机上运行它。
- en: Our goal, though, is to deploy this application to several different microcontroller
    platforms, using each platform’s specialized hardware to display the output. For
    each individual platform we’re planning to deploy to, such as Arduino, we provide
    a custom replacement for *output_handler.cc* that uses the platform’s APIs to
    control output—for example, by lighting some LEDs.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，我们的目标是将此应用程序部署到几种不同的微控制器平台上，使用每个平台的专用硬件来显示输出。对于我们计划部署到的每个单独平台，例如Arduino，我们提供一个自定义替换*output_handler.cc*，使用平台的API来控制输出，例如点亮一些LED。
- en: 'As mentioned earlier, these replacement files are located in subdirectories
    with the name of each platform: *arduino/*, *disco_f76ng/*, and *sparkfun_edge/*.
    We’ll dive into the platform-specific implementations later. For now, let’s jump
    back into *main_functions.cc*.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，这些替换文件位于具有每个平台名称的子目录中：*arduino/*、*disco_f76ng/*和*sparkfun_edge/*。我们将稍后深入研究特定于平台的实现。现在，让我们跳回*main_functions.cc*。
- en: Wrapping Up main_functions.cc
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结束main_functions.cc
- en: 'The last thing we do in our `loop()` function is increment our `inference_count`
    counter. If it has reached the maximum number of inferences per cycle defined
    in `kInferencesPerCycle`, we reset it to 0:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在`loop()`函数中做的最后一件事是增加我们的`inference_count`计数器。如果它已经达到了在`kInferencesPerCycle`中定义的每个周期的最大推理次数，我们将其重置为0：
- en: '[PRE49]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: The next time our loop iterates, this will have the effect of either moving
    our `x` value along by a step or wrapping it around back to 0 if it has reached
    the end of the range.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 下一次循环迭代时，这将使我们的`x`值沿着一步移动或者如果它已经达到范围的末尾，则将其包装回0。
- en: We’ve now reached the end of our `loop()` function. Each time it runs, a new
    `x` value is calculated, inference is run, and the result is output by `HandleOutput()`.
    If `loop()` is continually called, it will run inference for a progression of
    `x` values in the range 0 to 2π and then repeat.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经到达了我们的`loop()`函数的末尾。每次运行时，都会计算一个新的`x`值，运行推理，并由`HandleOutput()`输出结果。如果`loop()`不断被调用，它将对范围为0到2π的`x`值进行推理，然后重复。
- en: But what is it that makes the `loop()` function run over and over again? The
    answer lies in the file *main.cc*.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 但是是什么让`loop()`函数一遍又一遍地运行？答案在*main.cc*文件中。
- en: Understanding main.cc
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解main.cc
- en: The [C++ standard](https://oreil.ly/BfmkW) specifies that every C++ program
    contain a global function named `main()`, which will be run when the program starts.
    In our program, this function is defined in the file *main.cc*. The existence
    of this `main()` function is the reason *main.cc* represents the entry point of
    our program. The code in `main()` will be run any time the microcontroller starts
    up.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '[C++标准](https://oreil.ly/BfmkW)规定每个C++程序都包含一个名为`main()`的全局函数，该函数将在程序启动时运行。在我们的程序中，这个函数在*main.cc*文件中定义。这个`main()`函数的存在是*main.cc*代表我们程序入口点的原因。每当微控制器启动时，`main()`中的代码将运行。'
- en: 'The file *main.cc* is very short and sweet. First, it contains an `#include`
    statement for *main_functions.h*, which will bring in the `setup()` and `loop()`
    functions defined there:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 文件*main.cc*非常简短而简洁。首先，它包含了一个*main_functions.h*的`#include`语句，这将引入那里定义的`setup()`和`loop()`函数：
- en: '[PRE50]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Next, it declares the `main()` function itself:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，它声明了`main()`函数本身：
- en: '[PRE51]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: When `main()` runs, it first calls our `setup()` function. It will do this only
    once. After that, it enters a `while` loop that will continually call the `loop()`
    function, over and over again.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 当`main()`运行时，它首先调用我们的`setup()`函数。它只会执行一次。之后，它进入一个`while`循环，将不断调用`loop()`函数，一遍又一遍。
- en: This loop will keep running indefinitely. Yikes! If you’re from a server or
    web programming background, this might not sound like a great idea. The loop will
    block our single thread of execution, and there’s no way to exit the program.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 这个循环将无限运行。天啊！如果您来自服务器或Web编程背景，这可能听起来不是一个好主意。循环将阻塞我们的单个执行线程，并且没有退出程序的方法。
- en: However, when writing software for microcontrollers, this type of endless loop
    is actually pretty common. Because there’s no multitasking, and only one application
    will ever run, it doesn’t really matter that the loop goes on and on. We just
    continue making inferences and outputting data for as long as the microcontroller
    is connected to power.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在为微控制器编写软件时，这种无休止的循环实际上是相当常见的。因为没有多任务处理，只有一个应用程序会运行，循环继续进行并不重要。只要微控制器连接到电源，我们就继续进行推理并输出数据。
- en: We’ve now walked through our entire microcontroller application. In the next
    section, we’ll try out the application code by running it on our development machine.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经走完了整个微控制器应用程序。在下一节中，我们将通过在开发计算机上运行应用程序代码来尝试该应用程序代码。
- en: Running Our Application
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行我们的应用程序
- en: 'To give our application code a test run, we first need to build it. Enter the
    following Make command to create an executable binary for our program:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 为了给我们的应用程序代码进行测试运行，我们首先需要构建它。输入以下Make命令以为我们的程序创建一个可执行二进制文件：
- en: '[PRE52]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'When the build completes, you can run the application binary by using the following
    command, depending on your operating system:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 当构建完成后，您可以使用以下命令运行应用程序二进制文件，具体取决于您的操作系统：
- en: '[PRE53]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: If you can’t find the correct path, list the directories in *tensorflow/lite/micro/tools/make/gen/*.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 如果找不到正确的路径，请列出*tensorflow/lite/micro/tools/make/gen/*中的目录。
- en: 'After you run the binary, you should hopefully see a bunch of output scrolling
    past, looking something like this:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行二进制文件之后，您应该希望看到一堆输出滚动过去，看起来像这样：
- en: '[PRE54]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Very exciting! These are the logs written by the `HandleOutput()` function in
    *output_handler.cc*. There’s one log per inference, and the `x_value` gradually
    increments until it reaches 2π, at which point it goes back to 0 and starts again.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 非常令人兴奋！这些是`output_handler.cc`中`HandleOutput()`函数写入的日志。每次推理都有一个日志，`x_value`逐渐增加，直到达到2π，然后回到0并重新开始。
- en: As soon as you’ve had enough excitement, you can press Ctrl-C to terminate the
    program.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你体验到足够的刺激，你可以按Ctrl-C来终止程序。
- en: Note
  id: totrans-285
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: You’ll notice that the numbers are output as values with power-of-two exponents,
    like `1.4137159*2^1`. This is an efficient way to log floating-point numbers on
    microcontrollers, which often don’t have hardware support for floating-point operations.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到这些数字以二的幂次方的形式输出，比如`1.4137159*2^1`。这是在微控制器上记录浮点数的高效方式，因为这些设备通常没有浮点运算的硬件支持。
- en: 'To get the original value, just pull out your calculator: for example, `1.4137159*2^1`
    evaluates to `2.8274318`. If you’re curious, the code that prints these numbers
    is in [*debug_log_numbers.cc*](https://oreil.ly/sb06c).'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 要获得原始值，只需拿出你的计算器：例如，`1.4137159*2^1`计算结果为`2.8274318`。如果你感兴趣，打印这些数字的代码在[*debug_log_numbers.cc*](https://oreil.ly/sb06c)中。
- en: Wrapping Up
  id: totrans-288
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: We’ve now confirmed the program works on our development machine. In the next
    chapter, we’ll get it running on some microcontrollers!
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经确认程序在我们的开发机器上运行正常。在下一章中，我们将让它在一些微控制器上运行！
