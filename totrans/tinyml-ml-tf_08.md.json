["```py\nos.environ[\"WANTED_WORDS\"] = \"yes,no\"\n```", "```py\nos.environ[\"WANTED_WORDS\"] = \"on,off\"\n```", "```py\nos.environ[\"TRAINING_STEPS\"]=\"15000,3000\"\nos.environ[\"LEARNING_RATE\"]=\"0.001,0.0001\"\n```", "```py\nTraining these words: on,off\nTraining steps in each stage: 15000,3000\nLearning rate in each stage: 0.001,0.0001\nTotal number of training steps: 18000\n```", "```py\n!python tensorflow/tensorflow/examples/speech_commands/train.py \\\n--model_architecture=tiny_conv --window_stride=20 --preprocess=micro \\\n--wanted_words=${WANTED_WORDS} --silence_percentage=25 --unknown_percentage=25 \\\n--quantize=1 --verbosity=WARN --how_many_training_steps=${TRAINING_STEPS} \\\n--learning_rate=${LEARNING_RATE} --summaries_dir=/content/retrain_logs \\\n--data_dir=/content/speech_dataset --train_dir=/content/speech_commands_train\n```", "```py\n>> Downloading speech_commands_v0.02.tar.gz 18.1%\n```", "```py\n!python tensorflow/tensorflow/examples/speech_commands/freeze.py \\\n  --model_architecture=tiny_conv --window_stride=20 --preprocess=micro \\\n  --wanted_words=${WANTED_WORDS} --quantize=1 \\\n  --output_file=/content/tiny_conv.pb \\\n  --start_checkpoint=/content/speech_commands_train/tiny_conv. \\\n  ckpt-${TOTAL_STEPS}\n```", "```py\n!toco\n  --graph_def_file=/content/tiny_conv.pb --output_file= \\\n  /content/tiny_conv.tflite \\\n  --input_shapes=1,49,40,1 --input_arrays=Reshape_2\n  --output_arrays='labels_softmax' \\\n  --inference_type=QUANTIZED_UINT8 --mean_values=0 --std_dev_values=9.8077\n```", "```py\nimport os\nmodel_size = os.path.getsize(\"/content/tiny_conv.tflite\")\nprint(\"Model is %d bytes\" % model_size)\n```", "```py\n# Install xxd if it is not available\n!apt-get -qq install xxd\n# Save the file as a C source file\n!xxd -i /content/tiny_conv.tflite > /content/tiny_conv.cc\n# Print the source file\n!cat /content/tiny_conv.cc\n```", "```py\nunsigned char _content_tiny_conv_tflite[] = {\n  0x1c, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, 0x00, 0x00, 0x00, 0x00,\n  0x00, 0x00, 0x0e, 0x00, 0x18, 0x00, 0x04, 0x00, 0x08, 0x00, 0x0c, 0x00,\n  // ...\n  0x00, 0x09, 0x06, 0x00, 0x08, 0x00, 0x07, 0x00, 0x06, 0x00, 0x00, 0x00,\n  0x00, 0x00, 0x00, 0x04\n};\nunsigned int _content_tiny_conv_tflite_len = 18208;\n```", "```py\nconst unsigned char\n    g_tiny_conv_micro_features_model_data[] DATA_ALIGN_ATTRIBUTE = {\n        0x18, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, 0x00, 0x00, 0x0e, 0x00,\n        0x18, 0x00, 0x04, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x14, 0x00,\n        //...\n        0x00, 0x09, 0x06, 0x00, 0x08, 0x00, 0x07, 0x00, 0x06, 0x00, 0x00, 0x00,\n        0x00, 0x00, 0x00, 0x04};\nconst int g_tiny_conv_micro_features_model_data_len = 18208;\n```", "```py\nconst char* kCategoryLabels[kCategoryCount] = {\n    \"silence\",\n    \"unknown\",\n    \"yes\",\n    \"no\",\n};\n```", "```py\nconst char* kCategoryLabels[kCategoryCount] = {\n    \"silence\",\n    \"unknown\",\n    \"on\",\n    \"off\",\n};\n```", "```py\n// If we heard a \"yes\", switch on an LED and store the time.\nif (found_command[0] == 'y') {\n  last_yes_time = current_time;\n  digitalWrite(LED_BUILTIN, HIGH);\n}\n```", "```py\nif (found_command[0] == 'o') {\n  last_yes_time = current_time;\n  digitalWrite(LED_BUILTIN, HIGH);\n}\n```", "```py\nif (found_command[0] == 'y') {\n  am_hal_gpio_output_set(AM_BSP_GPIO_LED_YELLOW);\n}\nif (found_command[0] == 'n') {\n  am_hal_gpio_output_set(AM_BSP_GPIO_LED_RED);\n}\nif (found_command[0] == 'u') {\n  am_hal_gpio_output_set(AM_BSP_GPIO_LED_GREEN);\n}\n```", "```py\nif (found_command[0] == 'o' && found_command[1] == 'n') {\n  am_hal_gpio_output_set(AM_BSP_GPIO_LED_YELLOW);\n}\nif (found_command[0] == 'o' && found_command[1] == 'f') {\n  am_hal_gpio_output_set(AM_BSP_GPIO_LED_RED);\n}\nif (found_command[0] == 'u') {\n  am_hal_gpio_output_set(AM_BSP_GPIO_LED_GREEN);\n}\n```", "```py\nif (*found_command == 'y') {\n  lcd.Clear(0xFF0F9D58);\n  lcd.DisplayStringAt(0, LINE(5), (uint8_t *)\"Heard yes!\", CENTER_MODE);\n} else if (*found_command == 'n') {\n  lcd.Clear(0xFFDB4437);\n  lcd.DisplayStringAt(0, LINE(5), (uint8_t *)\"Heard no :(\", CENTER_MODE);\n} else if (*found_command == 'u') {\n  lcd.Clear(0xFFF4B400);\n  lcd.DisplayStringAt(0, LINE(5), (uint8_t *)\"Heard unknown\", CENTER_MODE);\n} else {\n  lcd.Clear(0xFF4285F4);\n  lcd.DisplayStringAt(0, LINE(5), (uint8_t *)\"Heard silence\", CENTER_MODE);\n}\n```", "```py\nif (found_command[0] == 'o' && found_command[1] == 'n') {\n  lcd.Clear(0xFF0F9D58);\n  lcd.DisplayStringAt(0, LINE(5), (uint8_t *)\"Heard on!\", CENTER_MODE);\n} else if (found_command[0] == 'o' && found_command[1] == 'f') {\n  lcd.Clear(0xFFDB4437);\n  lcd.DisplayStringAt(0, LINE(5), (uint8_t *)\"Heard off\", CENTER_MODE);\n} else if (*found_command == 'u') {\n  lcd.Clear(0xFFF4B400);\n  lcd.DisplayStringAt(0, LINE(5), (uint8_t *)\"Heard unknown\", CENTER_MODE);\n} else {\n  lcd.Clear(0xFF4285F4);\n  lcd.DisplayStringAt(0, LINE(5), (uint8_t *)\"Heard silence\", CENTER_MODE);\n}\n```", "```py\npip uninstall -y tensorflow tensorflow_estimator\npip install -q tf-estimator-nightly==1.14.0.dev2019072901 \\\n  tf-nightly-gpu==1.15.0.dev20190729\n```", "```py\ngit clone -q https://github.com/tensorflow/tensorflow\ngit -c advice.detachedHead=false -C tensorflow checkout 17ce384df70\n```", "```py\npython tensorflow/tensorflow/examples/speech_commands/train.py \\\n  --model_architecture=tiny_conv --window_stride=20 --preprocess=micro \\\n  --wanted_words=\"on,off\" --silence_percentage=25 --unknown_percentage=25 \\\n  --quantize=1 --verbosity=INFO --how_many_training_steps=\"15000,3000\" \\\n  --learning_rate=\"0.001,0.0001\" --summaries_dir=/tmp/retrain_logs \\\n  --data_dir=/tmp/speech_dataset --train_dir=/tmp/speech_commands_train\n```", "```py\npython tensorflow/tensorflow/examples/speech_commands/freeze.py \\\n  --model_architecture=tiny_conv --window_stride=20 --preprocess=micro \\\n  --wanted_words=\"on,off\" --quantize=1 --output_file=/tmp/tiny_conv.pb \\\n  --start_checkpoint=/tmp/speech_commands_train/tiny_conv.ckpt-18000\n```", "```py\ntoco\n  --graph_def_file=/tmp/tiny_conv.pb --output_file=/tmp/tiny_conv.tflite \\\n  --input_shapes=1,49,40,1 --input_arrays=Reshape_2 \\\n  --output_arrays='labels_softmax' \\\n  --inference_type=QUANTIZED_UINT8 --mean_values=0 --std_dev_values=9.8077\n```", "```py\nxxd -i /tmp/tiny_conv.tflite > /tmp/tiny_conv_micro_features_model_data.cc\n```", "```py\npython tensorflow/examples/speech_commands/train.py \\\n  --model_architecture=tiny_conv --window_stride=20 --preprocess=micro \\\n  --wanted_words=\"up,down,left,right\" --silence_percentage=15 \\\n  --unknown_percentage=15 --quantize=1\n```", "```py\npython tensorflow/examples/speech_commands/train.py \\\n  --model_architecture=tiny_conv --window_stride=20 --preprocess=micro \\\n  --data_url=\"\" --data_dir=/tmp/my_wavs/ --wanted_words=\"laughter,glass\" \\\n  --silence_percentage=25 --unknown_percentage=25 --quantize=1\n```", "```py\nmkdir oggs\ngsutil -m cp gs://${BUCKET_NAME}/* oggs/\n```", "```py\nfind ${BASEDIR}/oggs -iname \"*.ogg\" -size -5k -delete\n```", "```py\nmkdir -p ${BASEDIR}/wavs\nfind ${BASEDIR}/oggs -iname \"*.ogg\" -print0 | \\\n  xargs -0 basename -s .ogg | \\\n  xargs -I {} ffmpeg -i ${BASEDIR}/oggs/{}.ogg -ar 16000 ${BASEDIR}/wavs/{}.wav\n```", "```py\ngit clone https://github.com/petewarden/extract_loudest_section \\\n  /tmp/extract_loudest_section_github\npushd /tmp/extract_loudest_section_github\nmake\npopd\nmkdir -p ${BASEDIR}/trimmed_wavs\n/tmp/extract_loudest_section/gen/bin/extract_loudest_section \\\n  ${BASEDIR}'/wavs/*.wav' ${BASEDIR}/trimmed_wavs/\n```", "```py\npython tensorflow/examples/speech_commands/train.py \\\n  --model_architecture=tiny_conv --window_stride=20 --preprocess=micro \\\n  --wanted_words=\"yes,no\" --silence_percentage=25 --unknown_percentage=25 \\\n  --quantize=1 --background_volume=0.2 --background_frequency=0.7 \\\n  --time_shift_ms=200\n```", "```py\npython tensorflow/examples/speech_commands/train.py \\\n --model_architecture=my_model_name --window_stride=20 --preprocess=micro \\\n  --wanted_words=\"yes,no\" --silence_percentage=25 \\--unknown_percentage=25 \\\n  --quantize=1\n```"]