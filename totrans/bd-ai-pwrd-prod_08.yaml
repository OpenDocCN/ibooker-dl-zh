- en: Chapter 8\. Building AI Agents
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AI agents are fundamentally transforming industries by automating tasks, enhancing
    user experiences, and, most importantly, delivering on the promise that chatbots
    once made but never quite fulfilled. Researchers Poole and Mackworth discuss the
    foundational characteristics of an *intelligent* or *AI agent*. Their work introduces
    the framework depicted in [Figure 8-1](#ch08_figure_1_1736793248602392).
  prefs: []
  type: TYPE_NORMAL
- en: 'Within this framework, an agent is something that acts in an environment. An
    agent acts intelligently if:'
  prefs: []
  type: TYPE_NORMAL
- en: Its actions are appropriate for its goals and circumstances.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is flexible to changing environments and goals.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It learns from experience.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It makes appropriate choices given perceptual and computational limitations.^([1](ch08.html#id1228))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](assets/bapp_0801.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-1\. An agent interacting with an environment (source: David L. Poole
    and Alan K. Mackworth)'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This model emphasizes the importance of adaptability and learning, which are
    critical features of modern AI agents. As shown in [Figure 8-1](#ch08_figure_1_1736793248602392),
    an agent’s abilities, goals, and prior knowledge influence its actions within
    an environment. The agent senses stimuli, draws on past experiences, and uses
    its computational capacity to make decisions.
  prefs: []
  type: TYPE_NORMAL
- en: These intelligent systems have advanced far beyond simple conversational bots,
    and are now evolving into autonomous entities capable of not just understanding
    users’ needs but *anticipating* them, executing complex tasks, and learning from
    each interaction. This progression is more than a technological shift; it is a
    strategic advantage that every forward-thinking product leader must embrace.
  prefs: []
  type: TYPE_NORMAL
- en: What Is an AI Agent?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*AI agents* are defined by their ability to perform autonomously, adapting
    and improving based on user interactions. Historically, AI agents began as rule-based
    systems—if you think back to early AI projects such as IBM’s [Deep Blue](https://oreil.ly/1yuAV)
    or even Google’s [AlphaGo](https://oreil.ly/L7H01), they were limited to solving
    highly specific problems, without much flexibility. Modern AI agents, however,
    possess a far greater degree of autonomy and learning capability, as evidenced
    by OpenAI’s GPT-4–powered [ChatGPT](https://openai.com/gpt-4), Google’s [Project
    Astra](https://oreil.ly/JbIZR), OpenAI’s [Operator](https://oreil.ly/3Uqx1), or
    Microsoft’s [Copilot](https://oreil.ly/11zHZ). These tools are not just reactive
    but proactive, enabling new levels of user engagement by predicting needs and
    even performing tasks on behalf of users.'
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI provides an option for its users to create their own custom agents, called
    *CustomGPTs*. These are tailored versions of OpenAI’s GPT models designed to meet
    specific user needs or tasks. They don’t require extensive fine-tuning of the
    base model or direct alterations to the model’s underlying architecture. Instead,
    they focus on customizing behavior and outputs by using existing capabilities
    of the foundational GPT model in conjunction with dynamic prompts, tool integrations,
    and structured workflows.
  prefs: []
  type: TYPE_NORMAL
- en: 'I often get asked: “Wait, but isn’t ChatGPT an AI agent?” The answer is no,
    not quite. ChatGPT is an impressive AI language model, but it’s not classified
    as an AI agent. ChatGPT functions primarily as a conversational model—it responds
    to user prompts based on pretrained data, but it doesn’t possess autonomy. It
    doesn’t independently perform tasks or make decisions on behalf of the user. It
    needs explicit input, lacks a goal-driven framework, and doesn’t act within an
    environment in an agentic sense.'
  prefs: []
  type: TYPE_NORMAL
- en: However, custom Gems on Gemini or custom versions of ChatGPT (that combine instructions
    and extra knowledge/skills) can be considered AI agents, as they can autonomously
    execute tasks without constant and explicit user prompts. These tailored models
    are more autonomous and are designed to perform specific tasks, make decisions,
    and take actions, typically based on a user’s needs. There are also ways for agents
    to interact with other tools or processes, offering more dynamic, proactive experiences
    and automated workflows via the use of, for example, zaps by Zapier.
  prefs: []
  type: TYPE_NORMAL
- en: In essence, *agentic products* are experiences that serve specific purposes;
    for example, NotebookLM is an agent that exists in order to understand complex
    topics and be a dedicated research assistant for the user. Agents operate based
    on predefined objectives, adapt to new information, and fulfill specific use cases.
    Kence Anderson captures the essence of agent autonomy in his book [*Designing
    Autonomous AI*](https://www.oreilly.com/library/view/designing-autonomous-ai/9781098110741)(O’Reilly,
    2022), noting, “True autonomy in AI systems requires not just the ability to execute
    predefined tasks but the capacity to learn, adapt, and act independently in pursuit
    of user goals, often under dynamic and unpredictable conditions.”
  prefs: []
  type: TYPE_NORMAL
- en: 'AI agents can:'
  prefs: []
  type: TYPE_NORMAL
- en: Help you plan, make decisions, and boost productivity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Take action, create, and orchestrate tasks autonomously
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make you feel connected, supported, and entertained
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Help you discover new information and learn
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide unique and personalized experiences tailored to the user and their goals
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For product leaders, navigating the world of agentic products can feel new and,
    at times, overwhelming. Building AI agents requires a deep understanding not only
    of AI capabilities but also of your users’ behaviors and needs. More than ever,
    your success relies on identifying the right opportunities to incorporate AI agents
    into your product ecosystem. The question is not just about whether to build an
    agent but about crafting the *right* agent—one that will meaningfully enhance
    user experiences while driving business value.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, navigating this shift comes with challenges. Working with AI agents
    presents a host of considerations—from defining the scope of their autonomy to
    ensuring their ability to learn and adapt. They also require a different mindset
    in terms of product design: one in which the agent becomes an active participant
    in the user journey, rather than just a feature.'
  prefs: []
  type: TYPE_NORMAL
- en: It’s crucial to understand the evolving landscape of AI agents and their applications
    in real-world products. Companies such as Spotify are already using AI agents
    to provide music recommendations adapted to users’ individual listening habits,
    while Amazon uses them for predictive inventory management and automated customer
    service, with a strong focus on learning from real-time data. Tesla is integrating
    AI agents into autonomous driving, while Apple is evolving Siri with advanced
    agentive capabilities. Studying the strategies of these early adopters can give
    product leaders a significant edge.
  prefs: []
  type: TYPE_NORMAL
- en: 'For those who can master these systems, the rewards are immense: reduced friction,
    better engagement, and even entirely new forms of value creation for users. In
    this chapter, I will guide you through the core concepts of AI agents, exploring
    the types of agents that exist today and how they differ from their predecessors.
    I will also examine how leading companies are leveraging these systems to create
    breakthrough products, and provide actionable steps for getting started with building
    AI agents for your own product. Whether you’re new to this space or looking to
    refine your strategy, this chapter will equip you with the insights you need to
    succeed in the world of agentic AI products.'
  prefs: []
  type: TYPE_NORMAL
- en: Not Just Glorified Chatbots
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At a glance, AI agents might seem like simply chatbots with a new name, but
    the reality is far more nuanced. While both AI agents and chatbots use NLP to
    engage with users, the scope, complexity, and capabilities of AI agents go far
    beyond what traditional chatbots offer.
  prefs: []
  type: TYPE_NORMAL
- en: Chatbots, as we’ve known them, are largely rule-based systems. They are designed
    to respond to a specific set of inputs based on scripted dialogues (e.g., “Where’s
    my order?” or “When do you open?”). Think of the early iterations of customer
    service bots on websites such as [Zendesk](https://www.zendesk.com) or the virtual
    assistants that helped users navigate simple transactions on Facebook Messenger.
  prefs: []
  type: TYPE_NORMAL
- en: AI agents, on the other hand, are designed to act autonomously, learn from interactions,
    and make decisions without relying solely on scripted responses. For example,
    while a chatbot might help you find a product on an ecommerce site, an AI agent
    like Amazon Alexa can anticipate when you’ll run out of household supplies and
    automatically reorder them for you, based on historical purchase data. Moreover,
    AI agents can handle far more complex tasks, such as integrating with various
    external systems (APIs, databases) and autonomously optimizing their actions over
    time through mechanisms such as reinforcement learning.
  prefs: []
  type: TYPE_NORMAL
- en: Before discussing how to build an AI agent, let’s take a look at how AI agents
    have evolved over the years.
  prefs: []
  type: TYPE_NORMAL
- en: Early Rule-Based Agents
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: AI agents have evolved significantly from their early beginnings as rule-based
    systems to the more autonomous, adaptable models we see today. Early agents were
    limited by their rigid frameworks, programmed to perform specific tasks within
    controlled environments based on predefined instructions. They had little capacity
    for flexibility or learning, and were often constrained by the abilities and goals
    that were directly coded into them. A prime example is [Microsoft’s Clippy](https://oreil.ly/zsxRn),
    a little animated paperclip that appeared when a user was writing a document to
    offer assistance based on preprogrammed rules. While widely mocked by the world,
    Clippy was a glimpse into the future of AI agents.
  prefs: []
  type: TYPE_NORMAL
- en: Early strategy and simulation games provided a fascinating playground for AI
    agents, particularly these rule-based systems. For example, in the 1998 release
    of *Battle Chess* for MS-DOS ([Figure 8-2](#ch08_figure_2_1736793248602425)),
    the pieces were controlled by simple AI agents with preprogrammed “move” and “capture”
    behaviors that followed the rules of chess. However, the AI had no capacity to
    adapt or learn from past games, relying solely on predefined strategies.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bapp_0802.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-2\. Battle Chess (MS-DOS, 1998)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'In 1990s computer games like [*Warcraft II: Tides of Darkness*](https://oreil.ly/EfhWt)
    or [*StarCraft*](https://oreil.ly/6GUns), AI-controlled units patrolled designated
    areas, guarded critical resources, and engaged enemies using preprogrammed tactics.
    These games showcased early examples of AI-driven behavior, with enemy units responding
    dynamically to player actions, defending their bases, or coordinating attacks
    in a way that felt intentional and strategic. While this was a groundbreaking
    development for its time, the lack of adaptability was evident.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another memorable game featuring early AI agents was *Lemmings* (1991). The
    game ([Figure 8-3](#ch08_figure_4_1736793248602478)) had simple rule-based agents:
    the lemmings followed strict behavioral patterns, marching forward endlessly unless
    the player intervened to assign them a specific task, such as building bridges
    or digging. Again, these agents had no learning capabilities and could only follow
    a set path based on the player’s inputs.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bapp_0803.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-3\. Lemmings (1991 “agents/bots”)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: These early AI systems set the stage for future developments by highlighting
    the limitations of purely rule-based approaches. Over time, AI agents became more
    dynamic and adaptable, evolving into systems capable of learning, making decisions,
    and taking actions autonomously.
  prefs: []
  type: TYPE_NORMAL
- en: 'The defining components of an agent are its:'
  prefs: []
  type: TYPE_NORMAL
- en: Abilities
  prefs: []
  type: TYPE_NORMAL
- en: The tasks the agent can perform, such as speech recognition, decision making,
    or physical actions.
  prefs: []
  type: TYPE_NORMAL
- en: Goals or preferences
  prefs: []
  type: TYPE_NORMAL
- en: The agent’s objectives or the specific desires it aims to fulfill. These are
    usually preprogrammed.
  prefs: []
  type: TYPE_NORMAL
- en: Prior knowledge
  prefs: []
  type: TYPE_NORMAL
- en: Information the agent already has about the environment or task.
  prefs: []
  type: TYPE_NORMAL
- en: Stimuli
  prefs: []
  type: TYPE_NORMAL
- en: Input from the environment, such as data from sensors, interactions, or user
    feedback. These inputs can include triggers that invoke specific behaviors based
    on predefined rules or logic. For instance, in simple systems, a particular sensor
    reading might directly activate a preset response (such as a thermostat turning
    on the heat when the temperature drops below a threshold). In more advanced AI
    agents, however, stimuli are processed dynamically, allowing the agent to adapt
    its actions based on prior experiences, goals, and contextual understanding. This
    evolution from rigid, rule-based reactions to adaptive, learning-based responses
    is a defining feature of modern AI agents.
  prefs: []
  type: TYPE_NORMAL
- en: Past experiences
  prefs: []
  type: TYPE_NORMAL
- en: The agent’s history of interactions that shape future actions and decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Over time, AI agents began to incorporate learning mechanisms, marking the shift
    from rigid, rule-based systems to more flexible, dynamic ones. The introduction
    of reinforcement learning allowed agents to learn from experience, adapting their
    behavior based on the outcomes of their actions. Agents no longer needed to be
    told what to do in every scenario. Instead, they could learn by trial and error,
    optimizing their actions to achieve goals.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, in popular strategy games like 2010’s *StarCraft II*, [AI agents
    learn from their mistakes](https://oreil.ly/OlDi3), adjusting their strategies
    in real time based on the player’s actions. These agents are designed to be more
    adaptable, using reinforcement learning to improve performance over time.
  prefs: []
  type: TYPE_NORMAL
- en: Today, AI agents incorporate deep learning and neural networks, enabling them
    to handle complex, multifaceted tasks with minimal human intervention. These modern
    agents are not just limited to responding to immediate input; they can forecast,
    plan, and collaborate with other agents to achieve shared goals. They are still
    widely used in computer and console games such as *Red Dead Redemption 2*, *FIFA*,
    *Bioshock Infinite*, and *Grand Theft Auto V*. *Divinity**:* *Original Sin II*,
    from 2017, also has an impressive non-player-character (NPC) AI.
  prefs: []
  type: TYPE_NORMAL
- en: One striking example is the rise of multi-agent systems. In environments such
    as healthcare, [multiple AI agents collaborate](https://oreil.ly/IdcZi) to diagnose
    and treat patients, continuously learning and sharing information to improve outcomes.
    For instance, in [one paper](https://oreil.ly/gQTtY) that created a hospital simulation
    for research purposes, different AI agents assumed the roles of doctors, nurses,
    and patients, collectively working toward better patient care ([Figure 8-4](#ch08_figure_5_1736793248602500)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bapp_0804.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-4\. Multi-agent simulation system set at a hospital (source: *https://oreil.ly/ziXvT*)'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: These agents have memories, can take in sensory input, and can improve themselves
    based on new data. Their evolution has paved the way for sophisticated applications
    in areas such as autonomous driving, where vehicles (agents) interact with their
    environment, learn from real-time data, and make life-or-death decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Agentive Products
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Three major advancements have transformed AI agents into the sophisticated
    systems we see today: learning, decision making, and autonomous action. These
    advancements enable agents to process a diverse array of inputs, continuously
    adapt to their environment, and, most importantly, autonomously fulfill user needs
    without requiring explicit instructions:'
  prefs: []
  type: TYPE_NORMAL
- en: Learning
  prefs: []
  type: TYPE_NORMAL
- en: Modern AI agents are designed to learn from experience, much like humans do.^([2](ch08.html#id1273))
    This ability allows them to refine their behavior and improve their effectiveness
    over time. For example, a recommendation system in an ecommerce platform can analyze
    user preferences, purchasing patterns, and behaviors to make increasingly accurate
    suggestions. Through ML models, agents gain the ability to evolve their understanding
    of user interactions and environmental stimuli.^([3](ch08.html#id1275))
  prefs: []
  type: TYPE_NORMAL
- en: Making decisions
  prefs: []
  type: TYPE_NORMAL
- en: As agents gather data and learn from their interactions, they also gain the
    ability to make informed decisions. This is not just about responding to stimuli
    with predefined actions; it involves evaluating multiple options and choosing
    the most appropriate response based on goals, constraints, and user needs. In
    the context of customer service, for instance, an AI agent might decide whether
    to escalate an issue to a human representative based on the complexity and sentiment
    of the conversation.
  prefs: []
  type: TYPE_NORMAL
- en: Taking autonomous action
  prefs: []
  type: TYPE_NORMAL
- en: The most significant leap in agents’ evolution is their ability to act autonomously.
    These actions are not merely reactions to specific triggers; they are proactive
    decisions that reflect a deeper understanding of user intent. Autonomous agents
    can perform tasks such as scheduling meetings, sending notifications, and even
    generating creative content without direct human intervention. They act on behalf
    of users, anticipating their needs and optimizing outcomes with minimal input.^([4](ch08.html#id1276))
  prefs: []
  type: TYPE_NORMAL
- en: Thanks to these advancements, AI agents have become indispensable in many applications.
    They provide personalized solutions by delivering the right response or action
    at precisely the right time. AI agents are no longer just bots performing repetitive
    tasks in isolation; they are integral parts of the user experience, designed to
    assist in meaningful ways.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, users might employ an AI assistant to automate the process of
    organizing emails, setting up meetings, or even managing their lives (e.g., placing
    a grocery order). Creative professionals use AI tools to brainstorm ideas, design
    layouts, or even produce music.^([5](ch08.html#id1277))
  prefs: []
  type: TYPE_NORMAL
- en: Comparing Chatbots to AI Agents and Multi-agents
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You might be wondering how exactly an AI agent differs from a chatbot, and what
    happens when multiple agents work together. While both chatbots and AI agents
    handle user interactions, their capabilities and autonomy levels are vastly different.
    To help clarify, I’ve broken down the key differences in [Table 8-1](#ch08_table_1_1736793248607404)
    and [Figure 8-5](#ch08_figure_6_1736793248602522). This comparison highlights
    how they operate together, their unique capabilities, and the value they bring
    to different product scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Table 8-1\. Comparing chatbots, AI agents, and multiple AI agents
  prefs: []
  type: TYPE_NORMAL
- en: '| Feature | Chatbot | AI agent | Multiple AI agents |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Primary purpose | Conversation and basic task execution | Autonomous task
    execution and decision making | Collaborative problem-solving and task execution
    |'
  prefs: []
  type: TYPE_TB
- en: '| Scope | Limited, often rule-based or predefined conversations | Broad, with
    complex tasks and adaptability | Complex, multistep tasks requiring teamwork and
    coordination |'
  prefs: []
  type: TYPE_TB
- en: '| Autonomy | Low: Limited to predefined scripts and responses | Medium: Can
    make autonomous decisions and act on its own | High: Agents communicate, collaborate,
    and coordinate autonomously |'
  prefs: []
  type: TYPE_TB
- en: '| Learning ability | Basic: Often relies on static rules or scripted responses
    | Advanced: Can use reinforcement learning and data feedback loops to adapt |
    Highly advanced: Agents learn both individually and as a group, improving coordination
    and performance |'
  prefs: []
  type: TYPE_TB
- en: '| Interactivity | Primarily user facing; responds to user input | Interacts
    with both users and other systems | Interacts with multiple agents, users, and
    systems simultaneously |'
  prefs: []
  type: TYPE_TB
- en: '| Complexity | Low: Simple logic or basic NLP models | Medium to high: Uses
    sophisticated AI models, can integrate multiple capabilities | Very high: Incorporates
    multiple agents with different specializations, requiring advanced coordination
    mechanisms |'
  prefs: []
  type: TYPE_TB
- en: '| Decision making | None to limited: Follows scripted rules or decision trees
    | Autonomous: Can analyze data and make informed decisions | Collective: Makes
    decisions based on interagent communication and shared goals |'
  prefs: []
  type: TYPE_TB
- en: '| Adaptability | Static: Limited to predefined changes in conversation flow
    | Dynamic: Can adapt to new information and changing environments | Highly dynamic:
    Agents adapt individually and collectively to optimize outcomes in real time |'
  prefs: []
  type: TYPE_TB
- en: '| Example use cases | FAQ bots, basic reservations | Personal assistants, customer
    support | Autonomous driving (coordinated cars), virtual hospitals (AI agents
    collaborating on patient care) |'
  prefs: []
  type: TYPE_TB
- en: Chatbots are primarily designed for conversation and basic task execution. They
    operate within a limited scope and with minimal autonomy, relying mostly on scripted
    responses. They are suitable for straightforward tasks such as FAQ interactions
    and making reservations.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, autonomous AI agents are capable of more complex and adaptive decision
    making, using advanced learning techniques such as reinforcement learning to improve
    their responses and actions over time. These agents are used in roles such as
    personal assistants and customer support, where a higher level of interaction
    and decision-making autonomy is beneficial.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bapp_0805.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-5\. Comparison of AI agents, chatbots, and multi-agents (source: Dr.
    Marily Nika)'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Multiple AI agents exhibit the highest level of complexity and dynamic interaction,
    collaborating and communicating to solve complicated, multistep tasks in real
    time. This type of AI system is used in highly coordinated environments such as
    autonomous driving and virtual hospitals, where seamless integration and collective
    decision making are crucial.
  prefs: []
  type: TYPE_NORMAL
- en: The differences in scope, complexity, and adaptability across these AI systems
    highlight the varying capabilities and suitable applications of each type of agent.
  prefs: []
  type: TYPE_NORMAL
- en: The AI Agent Product Landscape
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The AI agent product landscape spans several domains, offering diverse tools
    that showcase how companies are leveraging AI to drive productivity and innovation.
    In the automation space, tools such as [Magic Loops](https://www.magicloops.ai)
    and [Respell](https://www.respell.ai) excel at streamlining repetitive workflows,
    from email management to creative content production, making them invaluable for
    businesses looking to enhance efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: Virtual assistants form another prominent category, with examples such as [Lindy](https://www.lindy.ai),
    which automates professional administrative tasks, and [HyperWrite](https://www.hyperwrite.ai),
    a tool designed to support content creation and email management, boosting productivity
    for individual users and teams alike. For developers, specialized AI agents such
    as Sweep AI and [Phind](https://www.phind.com) simplify coding tasks by automating
    bug fixes and providing efficient access to coding resources, empowering software
    professionals to work smarter.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, new form factors such as [Humane](https://humane.com) and [Rewind](https://www.rewind.ai)
    integrate hardware with advanced AI capabilities, enabling seamless user experiences
    through voice-controlled and memory-enhancing technologies.
  prefs: []
  type: TYPE_NORMAL
- en: Because the AI space evolves quickly, many of these tools are likely to become
    outdated or be replaced by newer, more advanced agents. Some tools worth checking
    out are [Cassidy](https://www.cassidyai.com) to build AI automations, CrewAI’s
    [Multi-Agent Platform](https://www.crewai.com), [Criya](https://www.criya.co)
    for hyper-personalized campaigns, or [Wayfound](https://www.wayfound.ai) for AI
    agent management. In my [newsletter](https://marily.substack.com), I regularly
    share the latest trends and developments in the field.
  prefs: []
  type: TYPE_NORMAL
- en: As I write this in late 2024, Microsoft has deeply integrated its [Copilot AI](https://oreil.ly/11zHZ)
    into its Office Suite and Windows, making it a core part of user workflows. Copilot
    assists with document creation, emails, and other tasks, and is positioned as
    a productivity AI agent available across devices.
  prefs: []
  type: TYPE_NORMAL
- en: In 2023, Meta built AI-driven personas ([Figure 8-6](#ch08_figure_7_1736793248602542)),
    designed for social interactions, into Facebook and Instagram, though these are
    no longer used; Meta originally had plans to integrate them more widely into its
    Metaverse project, with its mixed-reality hardware.
  prefs: []
  type: TYPE_NORMAL
- en: I mention this because it was a good example of a strategic design choice that
    fostered personalization. The idea was that users could intuitively connect with
    the persona that best suited their needs, whether that was a playful creative
    assistant or a focused professional guide.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bapp_0806.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-6\. Meta’s AI personas (no longer used)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In 2025, OpenAI introduced [Operator](https://oreil.ly/3Uqx1), an AI agent designed
    to perform tasks autonomously within digital environments by leveraging a Computer-Using
    Agent (CUA) model. Unlike other agents that rely solely on APIs or structured
    inputs, Operator is equipped with GPT-4o’s vision capabilities and can interact
    with interfaces by using a mouse and keyboard. This allows it to complete tasks
    such as filling out forms, navigating websites, and executing multistep workflows
    across various platforms ([Figure 8-7](#ch08_figure_7a_1736793248602542)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Capabilities of OpenAI Operator include:'
  prefs: []
  type: TYPE_NORMAL
- en: Dining and event planning
  prefs: []
  type: TYPE_NORMAL
- en: Book tables at restaurants, suggest highly rated venues, and secure tickets
    for events or shows.
  prefs: []
  type: TYPE_NORMAL
- en: Delivery tracking and scheduling
  prefs: []
  type: TYPE_NORMAL
- en: Monitor package deliveries, update schedules, and notify users of changes.
  prefs: []
  type: TYPE_NORMAL
- en: Travel and shopping assistance
  prefs: []
  type: TYPE_NORMAL
- en: Compare prices, make reservations, and provide updates on itineraries.
  prefs: []
  type: TYPE_NORMAL
- en: Human-agent collaboration
  prefs: []
  type: TYPE_NORMAL
- en: Users can intervene in ongoing tasks—such as modifying form inputs or verifying
    details—and return control to Operator, which seamlessly resumes its work.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic suggestions
  prefs: []
  type: TYPE_NORMAL
- en: Based on user behavior and preferences, Operator offers actionable recommendations,
    from curated news updates to meal ideas.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bapp_0807.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-7\. OpenAI’s Operator in action: while making a restaurant reservation,
    it allows users to “take control” of the browser for manual input before seamlessly
    resuming automation'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Crafting the Right AI Agent for Your Product
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now it’s your turn. Start with your users’ most urgent need. Choose a well-defined,
    specific use case. Focus on an area where AI can have the most immediate impact—whether
    that’s automating customer service, streamlining internal processes, or enhancing
    user experiences. This section presents some considerations to help you figure
    out what type of agent can fulfill this need, and ends with a reflective questionnaire
    to help you put it all together.
  prefs: []
  type: TYPE_NORMAL
- en: Task-Specific Vertical Agents Versus General-Purpose Agents
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are generally two categories of agents: task specific and general purpose.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Task-specific agents* are designed for specialized tasks in specific domains,
    such as sending emails, booking tickets, or generating content; for example, an
    AI agent for a sales team that sends basic automated messages to prospects. These
    agents, called *simple reflex agents*, operate based on predefined if-then rules,
    reacting to specific stimuli without memory or learning.'
  prefs: []
  type: TYPE_NORMAL
- en: Task-specific agents can be *goal based*—using AI to choose options that help
    them accomplish a specific goal, such as optimizing sales outreach or finding
    the most efficient travel route. They can also be *utility based*—designed to
    maximize a specific utility, such as minimizing energy consumption.
  prefs: []
  type: TYPE_NORMAL
- en: '*General-purpose* or “all-in-one” AI agents have an internal model of the world
    that allows them to adapt their responses and actions to a changing environment.
    They are designed to handle a wide variety of tasks across multiple domains, from
    booking flights to generating content.'
  prefs: []
  type: TYPE_NORMAL
- en: '[Figure 8-8](#ch08_figure_8_1736793248602563) shows a framework I use to wrap
    my mind around the type of agent I will be building.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bapp_0808.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-8\. Mental model to visualize agentic capabilities
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see, another critical distinction of AI agents lies in whether they
    operate behind the scenes or are directly consumer facing. Understanding this
    contrast can help clarify the different roles agents play within a product ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the x-axis:'
  prefs: []
  type: TYPE_NORMAL
- en: Behind-the-scenes agents
  prefs: []
  type: TYPE_NORMAL
- en: These agents work in the background, automating processes, optimizing operations,
    or managing workflows without direct user interaction. For instance, an AI agent
    embedded in a logistics platform may optimize inventory management or route planning,
    ensuring efficiency without the end user ever knowing it exists. These agents
    often focus on operational excellence, driving business outcomes through seamless
    integration with existing systems.
  prefs: []
  type: TYPE_NORMAL
- en: Consumer-facing agents
  prefs: []
  type: TYPE_NORMAL
- en: These agents interact directly with users, providing services, recommendations,
    or assistance in real time. Examples include virtual assistants such as Siri and
    Alexa, which engage users through NLP to fulfill tasks. These agents prioritize
    user experience, aiming to create intuitive and personalized interactions.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the y-axis:'
  prefs: []
  type: TYPE_NORMAL
- en: Task-specific agents
  prefs: []
  type: TYPE_NORMAL
- en: These agents are designed to handle highly specialized functions within a defined
    scope. They operate with a clear focus, addressing singular objectives such as
    email filtering, customer support, or scheduling. For example, [Chatfuel](https://chatfuel.com)
    creates chatbots for customer interactions, while [NotebookLM](https://notebooklm.google)
    serves as a personalized AI tool for summarizing and organizing notes, enabling
    users to quickly derive insights from structured documents. These agents excel
    at simplifying repetitive tasks or improving efficiency in targeted areas, making
    them ideal for organizations looking to automate specific workflows without requiring
    complex integrations.
  prefs: []
  type: TYPE_NORMAL
- en: General-purpose agents
  prefs: []
  type: TYPE_NORMAL
- en: These agents are versatile systems capable of managing a wide variety of tasks
    across multiple domains. Unlike task-specific agents, they adapt to dynamic user
    needs and handle diverse objectives, from generating content to managing workflows.
    Examples include [LangChain](https://www.langchain.com), a platform for integrating
    language models with APIs and databases, and [Adept ACT-1](https://oreil.ly/act-1),
    an AI agent designed to interact with software tools to help users accomplish
    tasks such as document editing and data analysis. These agents prioritize flexibility
    and scalability, making them powerful tools for businesses seeking to support
    broad use cases or deliver comprehensive solutions to users.
  prefs: []
  type: TYPE_NORMAL
- en: Agent Activation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You need to decide how the agent will be activated. Agents can be proactive
    or reactive. Will it require user input via text, audio, or video, or will it
    act on its own? *Proactive agents* initiate interactions based on users’ behavior
    or the context. Examples include [Dynamic Yield](https://oreil.ly/dyield) and
    [Zapier](https://zapier.com). *Reactive agents* respond only when a user explicitly
    invokes them. Examples include [Botpress](https://botpress.com) and [HubSpot’s
    Chatbot Builder](https://oreil.ly/SZ0Qq). This choice depends on the user scenario
    and the level of interactivity needed for the task at hand. Understanding these
    factors ensures that your agent delivers value without feeling intrusive or overwhelming.
  prefs: []
  type: TYPE_NORMAL
- en: Autonomy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When designing an AI agent, it’s crucial to consider what kind of autonomy is
    appropriate for your users. Agents can vary greatly in their level of autonomy
    ([Figure 8-9](#ch08_figure_9_1736793248602582)). Some agents simply provide suggestions,
    while others can take action on behalf of the user—such as making purchases or
    scheduling appointments—with explicit consent. For example, an AI shopping agent
    may start by suggesting products but could eventually make purchases on the user’s
    behalf, progressively gaining more autonomy. Controlling autonomy levels involves
    clear decision making about how much independence the agent should have. A critical
    choice is whether the agent acts reactively, requiring explicit user input, or
    proactively, anticipating user needs and initiating actions. For instance, a reactive
    agent might wait for a scheduling request, while a proactive agent could identify
    calendar conflicts and reschedule on its own.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bapp_0809.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-9\. Agentic AI autonomy levels
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Feedback and Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You’ll also need to define your AI agent’s long-term learning capabilities.
    Does the agent need to learn and adapt over time? Decide whether your agent will
    need reinforcement learning capabilities or feedback loops to improve its performance
    and responsiveness. You might also consider implementing user feedback tools,
    such as [Zowie](https://getzowie.com) or [Replika](https://replika.com), that
    allow users to “train” the agent through interactions. These loops can come from
    explicit feedback (thumbs up/down or star ratings) and implicit feedback (analyzing
    patterns in user interactions).
  prefs: []
  type: TYPE_NORMAL
- en: Designing these feedback mechanisms requires careful thought. To elicit user-driven
    feedback, you might implement tools that allow users to provide corrections or
    preferences directly, such as editing suggestions or flagging errors. For instance,
    a user might refine an AI-generated report or indicate that a recommendation wasn’t
    relevant.
  prefs: []
  type: TYPE_NORMAL
- en: For system-driven feedback, you could enable the agent to analyze its own actions,
    learning from its successes and failures. Techniques such as reinforcement learning
    can help optimize future decisions based on outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Design Patterns for Agent Interaction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What will your agent *look* like? The UI and interaction patterns will also
    shape the overall experience. This section offers some design patterns to consider
    as you decide how users will interact with your agent.
  prefs: []
  type: TYPE_NORMAL
- en: Side Panel
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A persistent side panel offers a constant, accessible UI element that provides
    contextual assistance. This works well for both proactive and reactive agents,
    particularly in domains such as writing, sales, and productivity. A great example
    is [Microsoft Copilot](https://oreil.ly/11zHZ) ([Figure 8-10](#ch08_figure_10_1736793248602601)),
    which appears as a side panel in Microsoft Office applications, offering suggestions
    like rewriting content or creating charts based on user activities (online version
    [available](https://oreil.ly/FyZHM)). Similarly, [HyperWrite](https://www.hyperwriteai.com)
    uses a side panel to assist with writing tasks by offering suggestions and content
    creation options.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bapp_0810.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8-10\. Microsoft Copilot side panel (source: [Microsoft](https://oreil.ly/FyZHM))'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Floating Bubble
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A *floating bubble*is a small, movable icon that users can click to interact
    with the agent. It’s often used in reactive agents that respond to specific user
    inputs. This pattern is commonly seen in tools like [Intercom](https://www.intercom.com)
    or [Floatbot.AI](https://floatbot.ai) ([Figure 8-11](#ch08_figure_12_1736793248602660)),
    where the bubble allows users to easily access chat-based assistance.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bapp_0811.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-11\. Intercom (A) and Floatbot.AI (B)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Chat Interface
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A dedicated conversational space, either through text or voice, is ideal for
    all-in-one agents. This approach provides users with a direct way to communicate
    with the agent and is most useful for handling more complex tasks. [Salesloft](https://oreil.ly/-A2J-),
    for instance, uses this format to facilitate conversational interactions between
    users and AI agents for customer support or sales inquiries ([Figure 8-12](#ch08_figure_13_1736793248602679)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bapp_0812.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-12\. Drift interface
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Integrated UI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this design, the agent is seamlessly integrated into the product’s workflow,
    offering suggestions or actions without requiring a dedicated interface. This
    is ideal for proactive agents that subtly enhance user interactions without demanding
    direct engagement. Two examples are Grammarly, which acts as a real-time assistant
    by analyzing text, suggesting corrections, and improving writing style dynamically,
    and Tesla’s Autopilot, an advanced AI agent capable of analyzing real-time data
    to make autonomous decisions while driving.
  prefs: []
  type: TYPE_NORMAL
- en: Pop-up Notifications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Pop-up notifications are best suited for proactive agents that need to guide
    users or provide timely advice. These notifications can alert users of opportunities
    or actions the agent can take based on their behavior. For example, Grammarly
    ([Figure 8-13](#ch08_figure_14_1736793248602697)) uses this approach to suggest
    grammar improvements or rewording in real time, ensuring that users receive relevant
    advice just when they need it.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/bapp_0813.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8-13\. Pop-up notification in Grammarly
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Collaborative Browser Interface
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: OpenAI’s Operator introduces a unique *collaborative browser interface*, blending
    autonomous action with manual control to create a flexible and user-friendly experience.
    This interface allows users to interact directly with tasks being performed by
    the agent, such as filling out forms, navigating websites, or booking services.
    Unlike traditional interfaces that rely solely on either automation or user input,
    Operator’s design facilitates a seamless transition between both modes.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, when making a restaurant reservation, Operator autonomously navigates
    to a reservation platform, selects appropriate options, and prepares the booking.
    At any point, users can choose to “take control” of the browser to manually adjust
    details, as shown in [Figure 8-7](#ch08_figure_7a_1736793248602542)—such as selecting
    a different time or verifying specific inputs—before returning control to Operator,
    which resumes the task without disruption. This capability ensures accuracy and
    adaptability, particularly in tasks where user preferences or complex inputs may
    require manual intervention.
  prefs: []
  type: TYPE_NORMAL
- en: 'The collaborative browser interface excels in situations requiring a combination
    of automation and human oversight, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Comparing ticket prices across platforms while allowing users to view and select
    their preferred options
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Completing online applications with user-specified customizations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reviewing and approving actions before submission, ensuring confidence in automated
    workflows
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scalability, Future-proofing, and Other Considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It’s likely that, over time, your agent will need to scale up. Consider how
    your AI agent can handle increased user load, expand to include different languages,
    or integrate new features over time. Think about the backend infrastructure needed
    to support scaling and real-time responses to user questions.
  prefs: []
  type: TYPE_NORMAL
- en: Data privacy is paramount, especially if your AI agent handles sensitive user
    information. Ensure compliance with regulations such as GDPR and the California
    Consumer Privacy Act (CCPA).
  prefs: []
  type: TYPE_NORMAL
- en: Also ensure that the agent can interact with existing systems, APIs, and databases
    within your organization. Compatibility with CRM, enterprise resource planning
    (ERP), or customer service platforms might be essential. Platforms can help integrate
    the agent consistently across tools. I recommend [MuleSoft](https://www.mulesoft.com)
    for API integrations and [Make](https://oreil.ly/cab_B) for process automation.
  prefs: []
  type: TYPE_NORMAL
- en: Define Success for Your Agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At the end of the day, an agentic AI product is still a product, so the metrics
    you learned about in [Chapter 6](ch06.html#ch06_setting_goals_and_measuring_success_1736793247821683)
    apply. Consider using these metrics to evaluate your agent:'
  prefs: []
  type: TYPE_NORMAL
- en: Task completion rate
  prefs: []
  type: TYPE_NORMAL
- en: How effective is the agent in fulfilling its intended tasks? Example metrics
    include the number of successful scheduled meetings or the response rate to automated
    messages.
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy and quality
  prefs: []
  type: TYPE_NORMAL
- en: Can the agent handle complex user queries? Feedback mechanisms, such as thumbs
    up/down or star ratings, can help assess the quality of interactions.
  prefs: []
  type: TYPE_NORMAL
- en: Intervention
  prefs: []
  type: TYPE_NORMAL
- en: Does the user escalate to a human often? Track the number of sessions in which
    human intervention was needed, with success meaning a decreasing need for these
    interventions over time.
  prefs: []
  type: TYPE_NORMAL
- en: Satisfaction
  prefs: []
  type: TYPE_NORMAL
- en: Implement surveys or feedback forms to capture direct user feedback. Positive
    comments on usefulness, ease of interaction, and the agent’s ability to assist
    with tasks are great indicators of success.
  prefs: []
  type: TYPE_NORMAL
- en: AI Agent Questionnaire
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Use this questionnaire to help you and your team think through the decisions
    you’ll need to make as you design your agent:'
  prefs: []
  type: TYPE_NORMAL
- en: What user need will your product fulfill?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will your agent be task specific or general? If task specific, will it be a
    simple reflex agent, goal based, or utility based?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will your agent be proactive or reactive? If reactive, how will users invoke
    it?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does the agent need to learn and adapt over time? Decide whether your agent
    will need reinforcement learning capabilities or feedback loops to improve its
    performance and responsiveness.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will you implement user feedback tools that allow users to “train” the agent
    through interactions? If so, which one(s)?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What should the experience look like?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which design pattern(s) will your agent use for user interaction?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How will the agent scale? What infrastructure will you need?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What data does the agent access, and how will you secure it?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How will the agent personalize the user experience?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How will the agent integrate with other tools or platforms?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What metrics will you use to define success?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AI agents are not just a technological marvel; they represent a new paradigm
    in how we solve problems, interact with users, and design products. Throughout
    this chapter, we’ve explored the evolution of AI agents, from simple rule-based
    systems to the complex, learning-driven entities that shape our digital experiences
    today. We dove into crafting AI agents tailored to specific product needs and
    outlined a practical checklist to help you make informed decisions. Whether your
    goal is to automate tasks, enhance personalization, or empower users to make decisions
    autonomously, the possibilities are endless.
  prefs: []
  type: TYPE_NORMAL
- en: But this is just the beginning. The role of an AI PM is to keep learning, keep
    iterating, and stay ahead of emerging trends. As AI continues to evolve, so too
    will the tools and strategies we use to bring these intelligent systems to life.
    You’ve now explored the foundational principles of AI product management—how AI
    fits into the broader product lifecycle, how to measure success, and how to create
    meaningful, scalable AI experiences.
  prefs: []
  type: TYPE_NORMAL
- en: For more real-world examples, certifications, and up-to-date content, I invite
    you to visit [AI Product Hub](https://www.aiproduct.com) for ongoing insights,
    resources, and community-driven discussions to ensure that your journey into AI
    product management remains dynamic and impactful.
  prefs: []
  type: TYPE_NORMAL
- en: '^([1](ch08.html#id1228-marker)) David L. Poole and Alan K. Mackworth, *Artificial
    Intelligence: Foundations of Computational Agents*, 2nd Edition (Cambridge University
    Press, 2017).'
  prefs: []
  type: TYPE_NORMAL
- en: ^([2](ch08.html#id1273-marker)) Tom M. Mitchell, *Machine Learning* (McGraw-Hill
    Education, 1997).
  prefs: []
  type: TYPE_NORMAL
- en: '^([3](ch08.html#id1275-marker)) David Silver et al., [“Mastering the Game of
    Go with Deep Neural Networks and Tree Search”](https://oreil.ly/HLSwd), *Nature*
    529, no. 7587 (2016): 484–489.'
  prefs: []
  type: TYPE_NORMAL
- en: '^([4](ch08.html#id1276-marker)) Ahmed Elgammal et al., [“CAN: Creative Adversarial
    Networks, Generating ‘Art’ by Learning About Styles and Deviating from Style Norms”](https://oreil.ly/TIVr-),
    *arXiv* preprint, arXiv:1706.07068, June 21, 2017.'
  prefs: []
  type: TYPE_NORMAL
- en: '^([5](ch08.html#id1277-marker)) Akshay Kore, [*Designing Human-Centric AI Experiences:
    Applied UX Design for Artificial Intelligence*](https://learning.oreilly.com/library/view/designing-human-centric-ai/9781484280881)
    (O’Reilly, 2022).'
  prefs: []
  type: TYPE_NORMAL
