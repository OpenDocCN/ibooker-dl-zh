- en: 'Chapter 15\. Becoming a Maker: Exploring Embedded AI at the Edge'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第15章。成为创客：探索边缘嵌入式AI
- en: 'Contributed by guest author: Sam Sterckval'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 由客座作者Sam Sterckval撰写
- en: You know how to build a great AI application, but you want more. You don’t want
    to be limited to just running AI software on some computer, you want to bring
    it out in the real physical world. You want to build devices to make things more
    interactive, to make life easier, to serve humanity, or perhaps just for the fun
    of it. Maybe you want to build an interactive painting that smiles at you when
    you look at it. A camera on your door that makes a loud alarm when an unauthorized
    person attempts to steal delivered packages. Maybe a robotic arm that sorts recyclables
    and trash. A device in the woods to prevent wildlife poaching, perhaps? Or a drone
    that can autonomously survey large areas and identify people in distress during
    floods. Maybe even a wheelchair that could drive on its own. What you need is
    a smart electronic device, but how would you build it, what would it cost, how
    powerful would it be? In this chapter, we begin to address those questions.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 您知道如何构建出色的AI应用程序，但您想要更多。您不想仅仅在某台计算机上运行AI软件，您想将其带到现实世界中。您想要构建设备，使事物更具互动性，使生活更轻松，为人类服务，或者仅仅是为了好玩。也许您想要构建一个互动绘画，当您看着它时会微笑。门口的摄像头在未经授权的人试图偷取包裹时发出响亮的警报。也许是一个可以分类回收物和垃圾的机械臂。在树林中防止盗猎的设备，也许？或者一架可以自主巡视大面积并在洪水期间识别处于困境中的人的无人机。甚至可能是一辆可以自行驾驶的轮椅。您需要的是一个智能电子设备，但您将如何构建它，它将花费多少，它将有多强大？在本章中，我们开始探讨这些问题。
- en: We look at how to implement AI on an embedded device—a device that you might
    use in a “maker” project. Makers are people with a DIY spirit who use their creativity
    to build something new. Often starting as amateur hobbyists, makers are fun-loving
    problem solvers, roboticists, innovators, and sometimes entrepreneurs.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看看如何在嵌入式设备上实现AI——这是您可能在“创客”项目中使用的设备。创客是具有DIY精神的人，他们利用自己的创造力构建新事物。创客通常从业余爱好者开始，他们是热爱解决问题的人、机器人专家、创新者，有时也是企业家。
- en: The aim of this chapter is to spark your ability to select the appropriate device
    for the task (which means not trying to run a heavy GAN on a tiny CPU or get a
    quadrillion-core GPU to run a “Not Hotdog” classifier), and set it up for the
    tests as quickly and easily as possible. We do this by exploring a few of the
    better-known devices out there, and seeing how we can use them to perform inferencing
    of our model. And finally, we look at how makers around the world are using AI
    to build robotic projects.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的目的是激发您选择适当设备的能力（这意味着不要试图在微小CPU上运行重型GAN，或者获取一台千核GPU来运行“不是热狗”分类器），并尽快轻松地为测试设置它。我们通过探索一些更为人熟知的设备，看看我们如何使用它们来执行我们模型的推理。最后，我们将看看全球的创客们如何利用AI来构建机器人项目。
- en: Let’s take our first step and look at the current landscape of embedded AI devices.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们迈出第一步，看看嵌入式AI设备的当前情况。
- en: Exploring the Landscape of Embedded AI Devices
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索嵌入式AI设备的现状
- en: In this section, we explore a few well-known embedded AI devices, listed in
    [Table 15-1](part0018.html#device_list). We talk about their inner workings and
    the differences between them before we go into testing.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们探索一些知名的嵌入式AI设备，列在[表15-1](part0018.html#device_list)中。在我们进行测试之前，我们将讨论它们的内部工作原理和它们之间的区别。
- en: Table 15-1\. Device list
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 表15-1\. 设备列表
- en: '| **Raspberry Pi 4** | **The most famous single-board computer, as of this
    writing** |'
  id: totrans-9
  prefs: []
  type: TYPE_TB
  zh: '| **Raspberry Pi 4** | **截至目前为止最著名的单板计算机** |'
- en: '| --- | --- |'
  id: totrans-10
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| **Intel Movidius NCS2** | A USB accelerator using a 16-core Visual Processing
    Unit (VPU) |'
  id: totrans-11
  prefs: []
  type: TYPE_TB
  zh: '| **Intel Movidius NCS2** | 使用16核视觉处理单元（VPU）的USB加速器 |'
- en: '| **Google Coral USB** | A USB accelerator using a custom Google Application-Specific
    Integrated Circuit (ASIC) |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
  zh: '| **Google Coral USB** | 使用自定义的谷歌应用特定集成电路（ASIC）的USB加速器 |'
- en: '| **NVIDIA Jetson Nano** | A single-board computer using a combination of CPU
    and 128-core CUDA GPU |'
  id: totrans-13
  prefs: []
  type: TYPE_TB
  zh: '| **NVIDIA Jetson Nano** | 使用CPU和128核CUDA GPU组合的单板计算机 |'
- en: '| **PYNQ-Z2** | A single-board computer using the combination of CPU and 50k
    CLB Field-Programmable Gate Array (FPGA) |'
  id: totrans-14
  prefs: []
  type: TYPE_TB
  zh: '| **PYNQ-Z2** | 使用CPU和50k CLB现场可编程门阵列（FPGA）组合的单板计算机 |'
- en: 'Instead of saying one is better than the other, we want to learn how to choose
    a setup for a particular project. We don’t typically see a Ferrari during the
    morning commute. Smaller, more compact cars are more common, and they get the
    job done just as well, if not better. Similarly, using a powerful $1,000-plus
    NVIDIA 2080 Ti GPU might be overkill for a battery-powered drone. Following are
    some questions we should be asking ourselves to understand which of these edge
    devices would best suit our needs:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不想说哪个更好，我们想学习如何为特定项目选择设置。我们通常在早晨上班途中看不到法拉利。更小、更紧凑的汽车更常见，它们同样有效，甚至更好。同样，对于电池供电的无人机来说，使用功能强大的1000美元以上的NVIDIA
    2080 Ti GPU可能过于夸张。以下是我们应该问自己的一些问题，以了解哪种边缘设备最适合我们的需求：
- en: How big is the device (for instance, compared to a coin)?
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设备有多大（例如，与硬币相比）？
- en: How much does the device cost? Consider whether you’re on a tight budget.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设备的成本是多少？考虑一下您是否预算有限。
- en: How fast is the device? Will it process a single FPS or 100 FPS?
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设备有多快？它会处理单个FPS还是100 FPS？
- en: How much power (in watts) does the device typically need? For battery-powered
    projects, this can be essential.
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设备通常需要多少功率（瓦特）？对于电池供电项目，这可能至关重要。
- en: With these questions in mind, let’s explore some of the devices in [Figure 15-1](part0018.html#family_photo_of_embedded_ai_devicessemic)
    one by one.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑这些问题的同时，让我们逐个探索[图15-1](part0018.html#family_photo_of_embedded_ai_devicessemic)中的一些设备。
- en: '![Family photo of Embedded AI devices; starting at the top, going clockwise:
    PYNQ-Z2, Arduino UNO R3, Intel Movidius NCS2, Raspberry Pi 4, Google Coral USB
    Accelerator, NVIDIA Jetson Nano, and a €1 coin for reference in the middle](../images/00057.jpeg)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![嵌入式AI设备的家庭照片；从顶部开始，顺时针方向：PYNQ-Z2，Arduino UNO R3，英特尔Movidius NCS2，树莓派4，谷歌珊瑚USB加速器，NVIDIA
    Jetson Nano，以及一个欧元硬币用于参考在中间](../images/00057.jpeg)'
- en: 'Figure 15-1\. Family photo of Embedded AI devices; starting at the top, going
    clockwise: PYNQ-Z2, Arduino UNO R3, Intel Movidius NCS2, Raspberry Pi 4, Google
    Coral USB Accelerator, NVIDIA Jetson Nano, and a €1 coin for reference in the
    middle'
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图15-1. 嵌入式AI设备的家庭照片；从顶部开始，顺时针方向：PYNQ-Z2，Arduino UNO R3，英特尔Movidius NCS2，树莓派4，谷歌珊瑚USB加速器，NVIDIA
    Jetson Nano，以及一个欧元硬币用于参考在中间
- en: Raspberry Pi
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 树莓派
- en: 'Because we will be talking about embedded devices for makers, let’s begin with
    the one universally synonymous with electronic projects: the Raspberry Pi ([Figure 15-2](part0018.html#raspberry_pi_4)).
    It’s cheap, it’s easy to build on, and it has a huge community.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们将讨论面向制造商的嵌入式设备，让我们从与电子项目普遍同义的一个开始：树莓派（[图15-2](part0018.html#raspberry_pi_4)）。它便宜，易于构建，并且有一个庞大的社区。
- en: '![Raspberry Pi 4](../images/00017.jpeg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![树莓派4](../images/00017.jpeg)'
- en: Figure 15-2\. Raspberry Pi 4
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图15-2. 树莓派4
- en: '| **Size** | 85.6 mm x 56.5 mm |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| **尺寸** | 85.6毫米 x 56.5毫米 |'
- en: '| **Price** | Starting at $35 |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| **价格** | 起价$35 |'
- en: '| **Processing unit** | ARM Cortex-A72 CPU |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| **处理单元** | ARM Cortex-A72 CPU |'
- en: '| **Power rating** | 15W |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| **功率评级** | 15W |'
- en: First of all, what is a Raspberry Pi? It’s a “single board computer,” which
    simply means that all calculations can be performed on a single printed circuit
    board (PCB). The fourth version of the single-board computer houses a Broadcom
    SoC (system-on-a-chip) containing (most important) an ARMv8-A72 quad-core CPU,
    a VideoCore VI 3D unit, and some video decoders and encoders. It comes with a
    choice of RAM size, up to 4 GB.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，什么是树莓派？它是一台“单板计算机”，这意味着所有计算都可以在一块印刷电路板（PCB）上完成。这款单板计算机的第四版搭载了一个Broadcom SoC（片上系统），包含（最重要的）一个ARMv8-A72四核CPU，一个VideoCore
    VI 3D单元，以及一些视频解码器和编码器。它配备了不同大小的RAM，最高可达4GB。
- en: This version is a big step up from the Raspberry Pi 3 in terms of performance,
    but it does lose a bit of efficiency. This is due to the Raspberry Pi 3 having
    an ARMv8-A53 core, which is the high-efficiency version, whereas the ARMv8-A72
    core (used in version 4) is the high-performance version. We can see this reflected
    in the power supply recommendation, which was 2.5 amps for the Raspberry Pi 3\.
    For the Raspberry Pi 4, this became 3 amps. It is also important to note that
    the Raspberry Pi 4 has USB 3 ports, where the Raspberry Pi 3 only has USB 2 ports.
    This will prove to be important information in the future.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这个版本在性能上比树莓派3有了很大的提升，但效率稍微降低了一些。这是因为树莓派3拥有一个ARMv8-A53核心，这是高效版本，而ARMv8-A72核心（用于第4版）是高性能版本。我们可以看到这反映在电源供应建议中，树莓派3为2.5安培。对于树莓派4，这变成了3安培。还要注意的是，树莓派4具有USB
    3端口，而树莓派3只有USB 2端口。这将在未来证明是重要信息。
- en: On to some machine learning stuff now. However powerful the Raspberry Pi 4 has
    become, it still mainly consists of four sequential CPU cores (which now support
    Out of Order [OoO] execution). It has the VideoCore VI, but there is no TensorFlow
    version available for this architecture as of this writing. Koichi Nakamura from
    Idein Inc. has built [py-videocore](https://oreil.ly/AuEzr), a Python library
    for accessing the Quad Processing Units (QPUs; the GPU-like cores of the Raspberry
    Pi’s SoC). He has accelerated neural networks with it before, but simple acceleration
    of TensorFlow isn’t possible yet. C++ libraries for accessing these cores are
    also available. But as you might suspect, these cores are not that powerful, so
    even when used to accelerate neural networks, they might not yield the desired
    results. For the sake of simplicity, we will not go into these libraries, because
    digging into the algorithms is beyond the scope of this book. And, and as we will
    see further on, this might not be necessary at all.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来谈谈一些机器学习的内容。无论树莓派4变得多么强大，它仍然主要由四个顺序CPU核心组成（现在支持乱序执行）。它有VideoCore VI，但截至目前还没有适用于这种架构的TensorFlow版本。Idein
    Inc.的中村浩一（Koichi Nakamura）构建了一个名为[py-videocore](https://oreil.ly/AuEzr)的Python库，用于访问树莓派SoC的四核处理单元（QPUs；类似GPU的核心）。他以前用它加速了神经网络，但目前还不能简单加速TensorFlow。也有用于访问这些核心的C++库。但正如你可能怀疑的那样，这些核心并不那么强大，所以即使用于加速神经网络，也可能无法产生期望的结果。为了简单起见，我们不会深入研究这些库，因为深入算法已超出本书的范围。而且，正如我们将在接下来看到的，这可能根本不是必要的。
- en: In the end, the Raspberry Pi has proven to be an immensely useful piece of hardware
    for numerous tasks. It is often used for educational purposes, and by makers.
    You would be surprised how many industries use the Raspberry Pi in industrial
    environments (there is a thing called the netPi, which is just a Raspberry Pi
    with a robust enclosure).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，树莓派已被证明是一个非常有用的硬件设备，可用于许多任务。它经常用于教育目的，以及由制造商使用。您会惊讶地发现有多少行业在工业环境中使用树莓派（有一种叫做netPi的东西，它只是一个带有坚固外壳的树莓派）。
- en: Intel Movidius Neural Compute Stick
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 英特尔Movidius神经计算棒
- en: 'Let’s now dive straight into one of the reasons the Raspberry Pi is the go-to
    base for a lot of projects: The Intel Movidius Neural Compute Stick 2 ([Figure 15-3](part0018.html#intel_neural_compute_stick_2)),
    the second generation of a USB accelerator created by Intel.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们直接深入探讨树莓派成为许多项目首选基础的原因之一：英特尔Movidius神经计算棒2（[图15-3](part0018.html#intel_neural_compute_stick_2)），这是英特尔推出的第二代USB加速器。
- en: '![Intel Neural Compute Stick 2](../images/00306.jpeg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![英特尔神经计算棒2](../images/00306.jpeg)'
- en: Figure 15-3\. Intel Neural Compute Stick 2
  id: totrans-38
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图15-3. 英特尔神经计算棒2
- en: '| **Size** | 72.5 mm x 27 mm |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| **尺寸** | 72.5毫米 x 27毫米 |'
- en: '| **Price** | $87.99 |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| **价格** | $87.99 |'
- en: '| **Processing unit** | Myriad X VPU |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| **处理单元** | Myriad X VPU |'
- en: '| **Power rating** | 1W |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| **功率评级** | 1W |'
- en: 'What it does is pretty simple: you give it a neural network and some data,
    and it does all the calculations necessary for inference. And it’s connected only
    through USB, so you can just hook it up to your Raspberry Pi, run your inferencing
    on the USB accelerator, and free up the CPU of your Raspberry Pi to do all the
    other cool stuff you want it to do.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 它的功能非常简单：您提供一个神经网络和一些数据，它会执行推理所需的所有计算。它只通过USB连接，因此您可以将其连接到树莓派上，运行USB加速器上的推理，并释放树莓派的CPU来执行您想要执行的所有其他酷炫操作。
- en: It is based on the Myriad VPU. The first generation had a Myriad 2 VPU, this
    one has a Myriad X VPU. The VPU contains 16 SHAVE (Streaming Hybrid Architecture
    Vector Engine) cores, which are kind of like GPU cores but less tailored to graphics-related
    operations. It features on-chip RAM, which is especially useful when doing neural
    network inferencing because these networks tend to create a lot of data while
    they compute, which then can be stored right next to the core, which reduces access
    time drastically.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 它基于Myriad VPU。第一代使用了Myriad 2 VPU，而这一代使用了Myriad X VPU。VPU包含16个SHAVE（流式混合架构向量引擎）核心，类似于GPU核心，但不太适合图形相关操作。它具有片上RAM，这在进行神经网络推理时特别有用，因为这些网络在计算时会产生大量数据，这些数据可以直接存储在核心旁边，从而大大降低访问时间。
- en: Google Coral USB Accelerator
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Google Coral USB加速器
- en: 'The Google Coral ([Figure 15-4](part0018.html#google_coral_usb_accelerator-id00001)),
    containing the Google Edge TPU, is the second USB accelerator we will discuss.
    First, a little explanation on why we are looking at two different USB accelerators.
    The Intel stick, as mentioned, has a number of SHAVE cores, which have multiple
    available instructions, like GPU cores, and thus act as a processing unit. The
    Google Edge TPU, on the other hand, is an ASIC (Application Specific Integrated
    Circuit), which also does some processing, but it serves a single purpose (hence
    the “Specific” keyword). An ASIC comes with a few properties inherent to the hardware,
    some of which are really nice, others less so:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Google Coral（[图15-4](part0018.html#google_coral_usb_accelerator-id00001)），包含Google
    Edge TPU，是我们将讨论的第二个USB加速器。首先，解释一下为什么我们要看两种不同的USB加速器。如前所述，英特尔棒具有多个SHAVE核心，具有多个可用指令，类似于GPU核心，因此充当处理单元。另一方面，Google
    Edge TPU是一种ASIC（特定应用集成电路），它也进行一些处理，但只服务于一个目的（因此有“特定”关键字）。ASIC具有一些硬件固有的属性，其中一些非常好，另一些则不太好：
- en: Speed
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 速度
- en: Because all electronic circuits inside the TPU serve a single purpose, there
    is no overhead in terms of decoding operations. You pump in input data and weights,
    and it gives you a result, almost instantly.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于TPU内部的所有电子电路只服务于一个目的，因此在解码操作方面没有额外的开销。您输入输入数据和权重，它会几乎立即给出结果。
- en: Efficiency
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 效率
- en: All ASICs serve a single purpose, so no extra energy is required. The performance/watt
    figure for ASICs is usually the highest in the business.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 所有ASIC只服务于一个目的，因此不需要额外的能量。ASIC的性能/瓦特指标通常是业内最高的。
- en: Flexibility
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 灵活性
- en: An ASIC can do only what it was designed for; in this case, that would be accelerating
    TensorFlow Lite neural networks. You will need to stick to the Google Edge TPU
    compiler and 8-bit *.tflite* models.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ASIC只能执行其设计用途；在这种情况下，那将是加速TensorFlow Lite神经网络。您需要使用Google Edge TPU编译器和8位*.tflite*模型。
- en: Complexity
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂性
- en: Google is, in essence, a software company and it knows how to make things easy
    to use. That is exactly what it has done here, as well. The Google Coral is incredibly
    easy to get started with.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: Google本质上是一家软件公司，它知道如何使事物易于使用。这正是它在这里所做的。Google Coral非常容易上手。
- en: 'So how does the Google Edge TPU work? Information on the Edge TPU itself has
    not been shared, but information about the Cloud TPU has, so the assumption is
    that the Edge TPU works in broadly the same way as the Cloud TPU. It has dedicated
    hardware to do the multiply-add, activation, and pooling operations. All the transistors
    on the chip have been connected in such a way that it can take weights and input
    data, and it will calculate the output in a highly parallel fashion. The single
    biggest part of the chip (apart from the on-chip memory, that is) is a part that
    does exactly what it sounds like: the “Matrix Multiply Unit.” It uses a rather
    clever, though not so new, principle called [*systolic execution*](https://oreil.ly/R5VpP).
    This execution principle helps lower memory bandwidth by storing intermediate
    results in the processing elements rather than in memory.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 那么Google Edge TPU是如何工作的呢？关于Edge TPU本身的信息尚未公开，但有关Cloud TPU的信息已经公开，因此可以假设Edge
    TPU的工作方式与Cloud TPU大致相同。它具有专用硬件来执行乘法-加法、激活和池化操作。芯片上的所有晶体管都已连接在一起，以便接收权重和输入数据，并以高度并行的方式计算输出。芯片上最大的部分（除了片上内存外）是一个部分，确切地说就是“矩阵乘法单元”。它使用一种相当聪明但并非全新的原则，称为[*系统执行*](https://oreil.ly/R5VpP)。这种执行原则通过将中间结果存储在处理元素中而不是存储在内存中来降低内存带宽。
- en: '![Google Coral USB Accelerator](../images/00265.jpeg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![Google Coral USB加速器](../images/00265.jpeg)'
- en: Figure 15-4\. Google Coral USB Accelerator
  id: totrans-57
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图15-4。Google Coral USB加速器
- en: '| **Size** | 65 mm x 30 mm |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| **尺寸** | 65毫米 x 30毫米 |'
- en: '| **Price** | $74.99 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| **价格** | $74.99 |'
- en: '| **Processing unit** | Google Edge TPU |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| **处理单元** | Google Edge TPU |'
- en: '| **Power rating** | 2.5W |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| **功率评级** | 2.5W |'
- en: Note
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: What’s the main difference between the two USB accelerators we’ve discussed?
    The Google Coral is more powerful, but a (little) less flexible than the Intel
    Movidius NCS2\. That being said, the Coral is far easier to set up and work with,
    certainly after you have the trained and converted model.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论的两种USB加速器之间的主要区别是什么？Google Coral更强大，但比英特尔Movidius NCS2（稍微）不太灵活。也就是说，Coral设置和使用起来要容易得多，尤其是在您训练和转换模型之后。
- en: NVIDIA Jetson Nano
  id: totrans-64
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: NVIDIA Jetson Nano
- en: 'On to a different kind of hardware: the NVIDIA Jetson Nano ([Figure 15-5](part0018.html#nvidia_jetson_nano-id00001)),
    a single board AI computer. Kind of like the Raspberry Pi, but with a 128-core
    CUDA-enabled Maxwell GPU. The addition of the GPU makes it kind of similar to
    a Raspberry Pi with an Intel NCS2, but where the NCS2 has 16 cores, this Jetson
    has 128\. What more does it contain? A quad-core A57 ARMv8 CPU, which is the predecessor
    of the ARMv8 A72 in the Raspberry Pi 4 (it is also a few months older than the
    Raspberry Pi 4), 4 GB of Low-Power Double Data Rate 4 (LPDDR4) RAM memory, which
    is, quite conveniently, shared between the CPU and GPU, which allows you to process
    data on the GPU, without copying it.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 关于另一种硬件：NVIDIA Jetson Nano（[图15-5](part0018.html#nvidia_jetson_nano-id00001)），一款单板AI计算机。有点像树莓派，但配备了一个128核CUDA启用的Maxwell
    GPU。GPU的添加使其有点类似于带有Intel NCS2的树莓派，但NCS2有16个核心，而这个Jetson有128个。它还包含什么？一个四核A57 ARMv8
    CPU，是树莓派4中ARMv8 A72的前身（它比树莓派4早几个月），4GB的低功耗双数据速率4（LPDDR4）RAM内存，非常方便地与CPU和GPU共享，这使您可以在GPU上处理数据，而无需复制它。
- en: '![NVIDIA Jetson Nano](../images/00120.jpeg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![NVIDIA Jetson Nano](../images/00120.jpeg)'
- en: Figure 15-5\. NVIDIA Jetson Nano
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图15-5\. NVIDIA Jetson Nano
- en: '| **Size** | 100 mm x 79 mm |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| **尺寸** | 100毫米 x 79毫米 |'
- en: '| **Price** | $99.00 |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| **价格** | $99.00 |'
- en: '| **Processing unit** | ARM A57 + 128 core Maxwell GPU |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| **处理单元** | ARM A57 + 128核Maxwell GPU |'
- en: '| **Power rating** | 10W (Can spike higher under high load) |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| **功率评级** | 10W（在高负载下可能会更高） |'
- en: The thing about this single board computer is that, as said before, these GPU
    cores are CUDA enabled, so yes, they can run TensorFlow-GPU or any-other-framework,
    which will make a big difference compared to a Raspberry Pi, especially when you
    also plan to train networks. Also, it’s dirt cheap for a GPU. At this point in
    time, the Jetson Nano is yours for $99, and this includes a rather high-performance
    ARM CPU and a 128-core GPU. In comparison, the Raspberry Pi 4 with 4 GB of memory
    is around $55, the Coral USB accelerator is around $75, and the Movidius NCS2
    is about $90, as well. The latter two are not standalone, and will at least need
    an additional Raspberry Pi to actually do something, and the Pi has no GPU that
    can easily accelerate deep learning applications.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这款单板计算机的特点是，正如之前所说，这些GPU核心是CUDA启用的，因此是的，它们可以运行TensorFlow-GPU或任何其他框架，这将与树莓派相比产生很大的差异，特别是当您计划训练网络时。而且，这对于GPU来说价格便宜。目前，Jetson
    Nano售价为$99，其中包括一款性能相当高的ARM CPU和一个128核GPU。相比之下，带有4GB内存的树莓派4售价约为$55，Coral USB加速器约为$75，Movidius
    NCS2约为$90。后两者不是独立的，至少需要额外的树莓派才能真正发挥作用，而树莓派没有可以轻松加速深度学习应用的GPU。
- en: 'One more note about the Jetson Nano: it can accelerate default TensorFlow 32-bit
    floating-point operations, but it will get much more efficient when 16-bit floating-point
    operations are used, and even more efficient if you use its own TensorRT framework.
    Luckily, the company has a nice little open source library called TensorFlow-TensorRT
    (TF-TRT) that will accelerate the available operations with TensorRT automatically
    while allowing TensorFlow to do the rest. This library offers grand speedups of
    around four times compared to TensorFlow-GPU. With all this in mind, this makes
    the Jetson Nano easily the most flexible device.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 关于Jetson Nano的另一个说明：它可以加速默认的TensorFlow 32位浮点运算，但如果使用16位浮点运算，它将变得更加高效，如果使用其自己的TensorRT框架，效率将更高。幸运的是，该公司有一个名为TensorFlow-TensorRT（TF-TRT）的小型开源库，它将自动加速可用的操作，并允许TensorFlow执行其余操作。与TensorFlow-GPU相比，这个库提供了大约四倍的加速。考虑到所有这些，这使得Jetson
    Nano成为最灵活的设备。
- en: FPGA + PYNQ
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FPGA + PYNQ
- en: Now is the time to fasten your seatbelts, because we are about to take a deep
    dive into the dark world of electronics. The PYNQ platform ([Figure 15-6](part0018.html#xilinx_pynq-z2)),
    based on the Xilinx Zynq family of chips is, for the most part, a totally different
    side of the electronics world compared to the other devices discussed in this
    topic. If you do a bit of research, you’ll find out it has a dual-core ARM-A9
    CPU, at a whopping 667 MHz. The first thing you’ll think is “Are you serious?
    That is ridiculous compared to the 1.5 GHz quad-core A72 from the Raspberry Pi?!”
    And you’d be right, the CPU in this thing is, for the most part, absolutely worthless.
    But it has something else on board—an FPGA.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是系好安全带的时候了，因为我们即将深入探讨电子领域的黑暗世界。基于Xilinx Zynq芯片系列的PYNQ平台（[图15-6](part0018.html#xilinx_pynq-z2)），在很大程度上与本主题中讨论的其他设备完全不同。如果您稍微研究一下，您会发现它配备了一款双核ARM-A9
    CPU，时钟频率高达667 MHz。您会想到的第一件事是“你是认真的吗？与树莓派的1.5 GHz四核A72相比，这太荒谬了！”您是对的，这款设备中的CPU在很大程度上是毫无价值的。但它还有另一项功能——一个FPGA。
- en: '![Xilinx PYNQ-Z2](../images/00081.jpeg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![Xilinx PYNQ-Z2](../images/00081.jpeg)'
- en: Figure 15-6\. Xilinx PYNQ-Z2
  id: totrans-77
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图15-6\. Xilinx PYNQ-Z2
- en: '| **Size** | 140 mm x 87 mm |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| **尺寸** | 140毫米 x 87毫米 |'
- en: '| **Price** | $119.00 |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| **价格** | $119.00 |'
- en: '| **Processing unit** | Xilinx Zynq-7020 |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| **处理单元** | Xilinx Zynq-7020 |'
- en: '| **Power rating** | 13.8W |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| **功率评级** | 13.8W |'
- en: FPGAs
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FPGAs
- en: 'To understand what an FPGA is, we need to first look at some familiar concepts.
    Let’s begin with a CPU: a device that knows a list of operations known as the
    Instruction Set Architecture (ISA). This is a set that defines everything the
    CPU can do, and usually contains operations such as “Load Word” (a word is typically
    a number of bits equal to the datapath size of the CPU, usually 32-bit or 64-bit),
    which will load some value into an internal register of the CPU, and “Add,” which
    can add up two of the internal registers, and store the result in a third register,
    for example.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解FPGA是什么，我们首先需要看一些熟悉的概念。让我们从CPU开始：一个知道一系列操作的设备，称为指令集架构（ISA）。这是一个定义CPU可以执行的所有操作的集合，通常包含操作，例如“加载字”（字通常是等于CPU数据通路大小的位数的值，通常为32位或64位），它将某个值加载到CPU的内部寄存器中，“加法”，可以将两个内部寄存器相加，并将结果存储在第三个寄存器中，例如。
- en: The reason the CPU can do this is because it contains a whole bunch of transistors
    (look at these as electrical switches if you like) that are hardwired in such
    a way that the CPU automatically translates the operations and does whatever that
    operation was intended to do. A software program is just a really long list of
    these operations, in a precisely thought-out order. A single-core CPU will take
    in operation per operation and carry them out, at pretty impressive speeds.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: CPU之所以能够做到这一点，是因为它包含了一大堆晶体管（如果你愿意，可以将其视为电气开关），这些晶体管被硬连线在一起，以便CPU自动翻译操作并执行操作的预期目的。软件程序只是这些操作的一个非常长的列表，按照精心考虑的顺序。单核CPU将逐个接收操作并执行它们，速度相当惊人。
- en: Let’s look at parallelism. Neural networks, as you know, consist of mostly convolutions
    or linear nodes, which can all be translated to matrix multiplications. If we
    look at the mathematics behind these operations, we can spot that each output
    point of a layer can be calculated independently from the other output points,
    as demonstrated in [Figure 15-7](part0018.html#matrix_multiplication).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看并行性。正如你所知，神经网络主要由卷积或线性节点组成，这些节点都可以转换为矩阵乘法。如果我们看一下这些操作背后的数学，我们会发现每个层的每个输出点可以独立于其他输出点计算，如[图15-7](part0018.html#matrix_multiplication)所示。
- en: '![Matrix multiplication](../images/00038.jpeg)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![矩阵乘法](../images/00038.jpeg)'
- en: Figure 15-7\. Matrix multiplication
  id: totrans-87
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图15-7。矩阵乘法
- en: We can now see that all of these operations could actually be done in a parallel
    fashion. Our single-core CPU won’t be able to do so, because it can do only one
    operation at a time, but that’s where multicore CPUs come in. A quad-core CPU
    can do four operations at a time, which means a theoretical speedup of four times.
    The SHAVE cores in the Intel Movidius NCS2 and the CUDA cores in the Jetson Nano
    might not be as complex as a CPU core, but they are good enough for these multiplications
    and additions, and instead of having four of these, the NCS2 has 16, and the Jetson
    Nano has 128\. A bigger GPU like a RTX 2080 Ti even has 4,352 CUDA cores. It’s
    easy to see now why GPUs are better at performing deep learning tasks compared
    to CPUs.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以看到所有这些操作实际上都可以以并行方式完成。我们的单核CPU无法做到这一点，因为它一次只能执行一个操作，但这就是多核CPU的用武之地。四核CPU可以同时执行四个操作，这意味着理论上的加速四倍。英特尔Movidius
    NCS2中的SHAVE核和Jetson Nano中的CUDA核可能不像CPU核心那样复杂，但它们足够好用于这些乘法和加法，而NCS2有16个，Jetson
    Nano有128个，而像RTX 2080 Ti这样的大型GPU甚至有4352个CUDA核。现在很容易看出为什么GPU在执行深度学习任务时比CPU更好。
- en: Let’s get back to FPGAs. Whereas CPUs and GPUs are huge collections of transistors
    hardwired to carry out a set of instructions, you can think of an FPGA as that
    same huge collection of transistors, but not wired. You can choose how they are
    wired, and rewire them whenever you want, making them reconfigurable. You can
    wire them to be a CPU. You can also find schematics and projects for which people
    have wired them to be a GPU. But most interesting here is that they can even be
    wired to the exact same architecture as your deep learning neural network, which
    would actually make them a physical implementation of your network. The word “wired”
    is used intentionally here. Often, you’ll find people talking about this configuration
    with the word “program,” but this can be confusing. What you’re doing is reconfiguring
    the actual hardware, unlike a CPU or GPU for which you download a program that
    the hardware can run.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到FPGAs。而CPU和GPU是巨大的晶体管集合，硬连线执行一组指令，你可以把FPGA想象成同样巨大的晶体管集合，但没有连线。你可以选择它们如何连线，并且随时重新连线，使它们可重构。你可以把它们连线成为CPU。你也可以找到人们将它们连线成为GPU的原理图和项目。但最有趣的是，它们甚至可以被连线成为与你的深度学习神经网络完全相同的架构，这实际上使它们成为你网络的物理实现。这里故意使用了“连线”一词。通常，你会发现人们用“程序”这个词来谈论这种配置，但这可能会让人困惑。你所做的是重新配置实际的硬件，不像CPU或GPU那样下载一个硬件可以运行的程序。
- en: PYNQ platform
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PYNQ平台
- en: We usually call the “wiring” file for an FPGA a *bitstream* or a *bitmap*, because
    what you flash onto the chip is basically just a map of the connections that should
    be made. As you can imagine, making these bitstreams is quite a lot more complicated
    than running a Python script. That’s where PYNQ comes in. Its tagline is “Python
    productivity for Zynq.” The company installs the PYNQ image that automatically
    runs a Jupyter Notebook on the ARM inside the chip, and it comes with a few basic
    bitstreams; however, more bitstreams will likely become available in the future.
    Within the PYNQ world, these bitstreams are called *overlays*.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常将FPGA的“连线”文件称为*比特流*或*位图*，因为你刷入芯片的内容基本上只是应该建立的连接的地图。正如你可以想象的那样，制作这些比特流比运行Python脚本要复杂得多。这就是PYNQ的用武之地。它的标语是“Zynq的Python生产力”。该公司安装了PYNQ图像，自动在芯片内部的ARM上运行Jupyter
    Notebook，并附带一些基本的比特流；然而，未来可能会有更多的比特流可用。在PYNQ世界中，这些比特流被称为*叠加*。
- en: If you go looking for examples, you’ll quickly find an example called “BNN-PYNQ,”
    which has a simple VGG-style, six-layer CNN that can run at 3,000-ish FPS on the
    PYNQ-Z1 and Z2, and close to 10,000 FPS on the ZCU104, which has the Ultrascale+
    version of the Zynq chip onboard. These numbers look pretty insane, but take into
    account that they run on 32x32 pixel images, rather than the usual 224x224 pixel
    images and that this network is “binarized,” which means it has weights and activations
    of one bit, instead of the 32-bits of TensorFlow. To have a better comparison
    of performance, I tried to recreate a similar network in Keras.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你寻找示例，你很快会找到一个名为“BNN-PYNQ”的示例，其中有一个简单的VGG风格、六层CNN，可以在PYNQ-Z1和Z2上以大约3000 FPS运行，在ZCU104上接近10000
    FPS，该芯片板载了Zynq芯片的Ultrascale+版本。这些数字看起来相当疯狂，但要考虑到它们是在32x32像素图像上运行，而不是通常的224x224像素图像，并且这个网络是“二值化”的，这意味着它的权重和激活只有一位，而不是TensorFlow的32位。为了更好地比较性能，我尝试在Keras中重新创建一个类似的网络。
- en: I built the FP32 model and trained it on the CIFAR-10 dataset. The CIFAR-10
    dataset is easily available with Keras using `keras.datasets.cifar10`. The FP32
    model reached a roughly 17% error rate, which is, surprisingly, only 2% better
    than the binary model. Inference speeds are around 132 FPS on an Intel i9 eight-core
    CPU. There is, to my knowledge, no easy way of using a binary network efficiently
    and easily on a CPU—you’ll need to dig into some specific Python packages or some
    C code to get the most out of the hardware. You could potentially achieve a speedup
    of three to five times. This would, however, still be far less than a low-end
    FPGA, and a CPU will usually draw more power in doing so. Of course, everything
    has a flip side, and for FPGAs that has to be the complexity of the design. Open
    source frameworks exist, namely the [FINN](https://oreil.ly/CijXF) framework,
    backed by Xilinx. Other manufacturers offer additional frameworks, but none of
    them come close to how easy to use software packages and frameworks like TensorFlow
    are. Designing a neural network for an FPGA would also involve a lot of electronics
    knowledge, and thus is beyond the scope of this book.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我构建了FP32模型并在CIFAR-10数据集上对其进行了训练。 CIFAR-10数据集可以在Keras中轻松使用`keras.datasets.cifar10`获得。
    FP32模型达到了大约17％的错误率，令人惊讶的是，仅比二进制模型好了2％。在Intel i9八核CPU上，推理速度约为132 FPS。据我所知，在CPU上没有一种简单有效地使用二进制网络的方法——您需要深入研究一些特定的Python软件包或一些C代码，以充分利用硬件。您可能会实现三到五倍的加速。然而，这仍然远远不及低端FPGA，并且CPU通常会在这样做时消耗更多电力。当然，一切都有两面性，对于FPGA来说，这必须是设计的复杂性。存在开源框架，即由Xilinx支持的[FINN](https://oreil.ly/CijXF)框架。其他制造商提供额外的框架，但没有一个能与TensorFlow等易于使用的软件包和框架相提并论。为FPGA设计神经网络还涉及大量的电子知识，因此超出了本书的范围。
- en: Arduino
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Arduino
- en: Arduino ([Figure 15-8](part0018.html#arduino_uno_r3)) can make your life a lot
    easier when trying to interact with the real world through sensors and actuators.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: Arduino（[图15-8](part0018.html#arduino_uno_r3)）在通过传感器和执行器与现实世界进行交互时可以让您的生活变得更加轻松。
- en: AnMicroController Units (MCUs) Arduino is a microcontroller development board
    built around the 8-bit Advanced Virtual RISC (AVR) ATMega328p microcontroller
    running at 16 MHz (so yeah, let’s not try to run a decent neural network on that).
    A microcontroller is something everyone has come into contact with—you can find
    microcontrollers in almost everything that is slightly electronic, ranging from
    every screen/TV, to your desktop keyboard, heck bicycle lights may even contain
    a microcontroller to enable the flashing mode.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 微控制器单元（MCUs）Arduino是围绕8位高级虚拟RISC（AVR）ATMega328p微控制器构建的微控制器开发板，运行速度为16 MHz（所以是的，我们不要试图在上面运行一个体面的神经网络）。微控制器是每个人都接触过的东西——您几乎可以在稍微电子化的所有东西中找到微控制器，从每个屏幕/电视到您的桌面键盘，甚至自行车灯甚至可能包含微控制器以启用闪烁模式。
- en: These boards come in a variety of shapes, sizes, and performances, and although
    the MCU in the Arduino UNO is pretty low performance, more potent MCUs are available.
    The ARM Cortex-M series is probably the most well known. Recently TensorFlow and
    uTensor (an extremely lightweight machine learning inference framework aimed at
    MCUs) joined forces to enable the possibility to run TensorFlow models on these
    MCUs.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这些板子有各种形状，大小和性能，尽管Arduino UNO中的MCU性能相对较低，但更强大的MCU可用。 ARM Cortex-M系列可能是最知名的。最近，TensorFlow和uTensor（一种针对MCU的极轻量级机器学习推理框架）联手，使得在这些MCU上运行TensorFlow模型成为可能。
- en: '![Arduino UNO R3](../images/00327.jpeg)'
  id: totrans-98
  prefs: []
  type: TYPE_IMG
  zh: '![Arduino UNO R3](../images/00327.jpeg)'
- en: Figure 15-8\. Arduino UNO R3
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图15-8\. Arduino UNO R3
- en: '| **Size** | 68.6 mm x 53.3 mm |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| **尺寸** | 68.6毫米 x 53.3毫米 |'
- en: '| **Price** | Less than $10.00 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| **价格** | 少于10.00美元 |'
- en: '| **Processing unit** | AVR ATMega328p |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| **处理单元** | AVR ATMega328p |'
- en: '| **Power rating** | 0.3W |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| **功率评级** | 0.3瓦特 |'
- en: Although the Arduino UNO is not really useful for performing lots of calculations,
    it has many other benefits that make it a mandatory part of the workbench of a
    maker. It’s cheap, it’s simple, it’s reliable, and it has a huge community surrounding
    it. Most sensors and actuators have some kind of library and shield for Arduino,
    which makes it a really easy platform to interact with. The AVR architecture is
    a kind of dated 8-bit modified Harvard architecture, but it’s really easy to learn,
    especially with the Arduino framework on top of it. The huge community around
    Arduino obviously brings a lot of tutorials with it, so just look up any Arduino
    tutorial for your sensor of choice, and you’ll surely find what you need for your
    project.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Arduino UNO实际上不适用于执行大量计算，但它具有许多其他优点，使其成为制作者工作台上不可或缺的一部分。它便宜，简单，可靠，并且周围有一个庞大的社区。大多数传感器和执行器都有某种Arduino库和盾牌，这使得它成为一个非常容易与之交互的平台。AVR架构是一种有点过时的8位修改的哈佛架构，但学习起来非常容易，尤其是在其顶部的Arduino框架上。围绕Arduino的庞大社区显然带来了许多教程，因此只需查找您选择的传感器的任何Arduino教程，您肯定会找到您项目所需的内容。
- en: Tip
  id: totrans-105
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Using Python’s serial library, you can easily interface with an Arduino using
    a Universal Asynchronous Receiver/Transmitter (UART) through a USB cable to send
    commands or data back and forth.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Python的串行库，您可以通过USB电缆使用通用异步收发器（UART）轻松地与Arduino进行接口，以便来回发送命令或数据。
- en: A Qualitative Comparison of Embedded AI Devices
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 嵌入式AI设备的定性比较
- en: '[Table 15-2](part0018.html#pros_and_cons_of_tested_platforms) summarizes the
    platforms we’ve talked about, and [Figure 15-9](part0018.html#performance_versus_complexity-to-use_lef)
    plots performance versus complexity for each device.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[表15-2](part0018.html#pros_and_cons_of_tested_platforms)总结了我们谈论过的平台，[图15-9](part0018.html#performance_versus_complexity-to-use_lef)绘制了每个设备的性能与复杂性之间的关系。'
- en: Table 15-2\. Pros and cons of tested platforms
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 表15-2\. 测试平台的优缺点
- en: '| **Embedded device** | **Pros** | **Cons** |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| **嵌入式设备** | **优点** | **缺点** |'
- en: '| --- | --- | --- |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| **Raspberry Pi 4** |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| **树莓派4** |'
- en: Easy
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单
- en: Large community
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 庞大的社区
- en: Readily available
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易得
- en: Cheap
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 便宜
- en: '|'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Lacks computing power
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏计算能力
- en: '|'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| **Intel Movidius NCS2** |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| **Intel Movidius NCS2** |'
- en: Easy optimizations
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单优化
- en: Supports most platforms
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持大多数平台
- en: '|'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Rather expensive for the speedup
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加速而言相对昂贵
- en: Not so powerful
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不那么强大
- en: '|'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| **Google Coral USB** |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| **Google Coral USB** |'
- en: Easy getting started
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 易于入门
- en: Huge speedup
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 巨大的加速
- en: Price versus speedup
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 价格与加速比
- en: '|'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Supports only *.tflite*
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅支持*.tflite*
- en: Needs eight-bit quantization
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要八位量化
- en: '|'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| **NVIDIA Jetson Nano** |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| **NVIDIA Jetson Nano** |'
- en: All-in-one
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一体化
- en: Training is possible
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练是可能的
- en: Cheap
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 便宜
- en: Really easy to achieve decent performance
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现良好性能真的很容易
- en: CUDA GPU
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CUDA GPU
- en: '|'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Performance might still be lacking
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 性能可能仍然不足
- en: Advanced optimizations can be complex
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级优化可能会很复杂
- en: '|'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| **PYNQ-Z2** |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| **PYNQ-Z2** |'
- en: Potentially huge power efficiency
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 潜在的巨大功率效率
- en: Actual hardware design
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实际硬件设计
- en: Potentially huge performance
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 潜在的巨大性能
- en: Even more versatile than the Jetson Nano
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比Jetson Nano更加多功能
- en: '|'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: Massively complex
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非常复杂
- en: Long design flow
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计流程长
- en: '|'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![Performance versus complexity-to-use (the size of the circle represents price)](../images/00286.jpeg)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![性能与使用复杂性之间的关系（圆圈的大小代表价格）](../images/00286.jpeg)'
- en: Figure 15-9\. Performance versus complexity-to-use (the size of the circle represents
    price)
  id: totrans-155
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图15-9。性能与使用复杂性之间的关系（圆圈的大小代表价格）
- en: In this section, we attempt to test some platforms by performing 250 classifications
    of the same image using MobileNetV2, with the top platform trained on the ImageNet
    dataset. We use the same image every time because this will allow us to eliminate
    part of the data bottlenecks that can occur in systems that don’t have enough
    RAM to store all weights and lots of different images.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们尝试通过使用MobileNetV2对相同图像进行250次分类来测试一些平台，顶部平台经过ImageNet数据集训练。我们每次使用相同的图像，因为这将使我们能够消除在系统中可能发生的数据瓶颈的一部分，这些系统没有足够的RAM来存储所有权重和许多不同的图像。
- en: Ok, let’s find an image first. Who doesn’t like cats? So, let’s have an image
    of a beautiful cat ([Figure 15-10](part0018.html#cat)) that is exactly 224 x 224
    pixels, that way we don’t need to scale the image.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，让我们先找一张图片。谁不喜欢猫呢？所以，让我们有一张美丽猫的图片（[图15-10](part0018.html#cat)），它的尺寸正好是224
    x 224像素，这样我们就不需要调整图像。
- en: '![The image of the cat we will be using for our experiments](../images/00246.jpeg)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![我们将用于实验的猫的图像](../images/00246.jpeg)'
- en: Figure 15-10\. The image of the cat we will be using for our experiments
  id: totrans-159
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图15-10。我们将用于实验的猫的图像
- en: 'It’s always nice to have a benchmark, so let’s run the model on our PC first.
    [Chapter 2](part0004.html#3Q283-13fa565533764549a6f0ab7f11eed62b) explains how
    to do this, so let’s go ahead and write a script that will invoke the prediction
    250 times, and measure how long this takes. You can find the full script on the
    book’s GitHub website (see [*http://PracticalDeepLearning.ai*](http://PracticalDeepLearning.ai))
    at *code/chapter-15*:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有基准测试总是不错的，所以让我们先在PC上运行模型。[第2章](part0004.html#3Q283-13fa565533764549a6f0ab7f11eed62b)解释了如何做到这一点，所以让我们继续编写一个脚本，该脚本将调用预测250次，并测量这需要多长时间。您可以在本书的GitHub网站上找到完整的脚本（请参阅[*http://PracticalDeepLearning.ai*](http://PracticalDeepLearning.ai)）位于*code/chapter-15*：
- en: '[PRE0]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Now that we’ve established our benchmark, it’s time to begin looking at how
    to run this model on the embedded devices and see whether and how we can take
    the performance to a useful level.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经建立了基准测试，现在是时候开始研究如何在嵌入式设备上运行这个模型，看看我们是否以及如何将性能提升到一个有用的水平。
- en: Hands-On with the Raspberry Pi
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与树莓派一起动手
- en: 'We begin with the most well-known and most basic of the previously discussed
    devices: the Raspberry Pi (RPi for short).'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从先前讨论的设备中最知名和最基本的设备开始：树莓派（简称RPi）。
- en: 'We start by installing Raspbian, a Linux variant made especially for the Raspberry
    Pi. For the sake of brevity, let’s assume that we have a Raspberry Pi with everything
    installed, updated, connected, and ready. We can go straight to installing TensorFlow
    on the Pi, which should work using the `pip` installer:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先安装Raspbian，这是专为Raspberry Pi制作的Linux变体。为了简洁起见，让我们假设我们有一个已安装、更新、连接并准备就绪的Raspberry
    Pi。我们可以直接在Pi上安装TensorFlow，这应该可以使用`pip`安装程序完成：
- en: '[PRE1]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Note
  id: totrans-167
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'Due to the recent switch to Raspbian Buster, we encountered some problems,
    which were resolved by using the following `piwheel`:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 由于最近切换到Raspbian Buster，我们遇到了一些问题，通过使用以下`piwheel`解决了这些问题：
- en: '[PRE2]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Installing Keras is straightforward with `pip`, but don’t forget to install
    `libhdf5-dev`, which you will need if you want to load weights into a neural network:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`pip`安装Keras很简单，但不要忘记安装`libhdf5-dev`，如果您想要将权重加载到神经网络中，则会需要它：
- en: '[PRE3]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Because installing OpenCV, called in code as cv2, on the RPi can be a burden
    (especially when a recent switch of OS has happened), we can load the image using
    the PIL instead of OpenCV. This means replacing the import of cv2 with an import
    for PIL, and changing the code to load the image to use this library:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在RPi上安装OpenCV（在代码中称为cv2）可能是一种负担（特别是在最近切换操作系统后），我们可以使用PIL加载图像而不是OpenCV。这意味着用PIL替换cv2的导入，并更改代码以使用此库加载图像：
- en: '[PRE4]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Tip
  id: totrans-174
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Unlike OpenCV, PIL loads images in the RGB format, so a conversion from BGR
    to RGB is no longer needed.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 与OpenCV不同，PIL以RGB格式加载图像，因此不再需要从BGR转换为RGB。
- en: 'And that’s it! The exact same script should run on your Raspberry Pi now:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！现在应该可以在您的Raspberry Pi上运行完全相同的脚本：
- en: '[PRE5]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: As you can see, it runs a lot slower, dropping to less than three FPS. Time
    to think about how we can speed this up.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，它运行速度慢得多，下降到不到三帧每秒。是时候考虑如何加快速度了。
- en: The first thing we could do is have a look at TensorFlow Lite. TensorFlow has,
    as discussed in [Chapter 13](part0015.html#E9OE3-13fa565533764549a6f0ab7f11eed62b),
    a converter built in, which lets us easily convert any model to a TensorFlow Lite
    (*.tflite*) model.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以做的第一件事是看看TensorFlow Lite。TensorFlow内置了一个转换器，让我们可以轻松地将任何模型转换为TensorFlow Lite（*.tflite*）模型。
- en: We proceed by writing a small script, very similar to the original benchmark
    script, which will just set up everything to use the TensorFlow Lite model and
    run the 250 predictions. This script is, of course, also available on the book’s
    GitHub webiste (see [*http://PracticalDeepLearning.ai*](http://PracticalDeepLearning.ai)).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们继续编写一个小脚本，与原始基准测试脚本非常相似，它将设置好一切以使用TensorFlow Lite模型并运行250次预测。当然，这个脚本也可以在本书的GitHub网站上找到（参见[*http://PracticalDeepLearning.ai*](http://PracticalDeepLearning.ai)）。
- en: Let’s go ahead and run this so that we can evaluate our effort to speed things
    up.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续运行这个脚本，以便评估我们加快速度的努力。
- en: '[PRE6]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note
  id: totrans-183
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The [Google Coral website](https://coral.withgoogle.com) has 8-bit quantized
    CPU models available, which you can run using TensorFlow Lite.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '[Google Coral网站](https://coral.withgoogle.com)提供了可使用TensorFlow Lite运行的8位量化CPU模型。'
- en: For the Raspberry Pi 4, we observed an increase in speed of three times (see
    [Table 15-3](part0018.html#raspberry_pi_benchmarks)). Not bad for a quick try,
    but we still only achieved 7.8 FPS, which is kind of nice and perfectly fine for
    a lot of applications. But what if our original plan was to do something on live
    video, for example? Then this is not enough. Quantizing the model can achieve
    even more performance, but this will be only a marginal increase given that the
    CPU in the Raspberry Pi has not been optimized for 8-bit integer operations.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 对于树莓派4，我们观察到速度增加了三倍（参见[Table 15-3](part0018.html#raspberry_pi_benchmarks)）。对于一个快速尝试来说，这还不错，但我们仍然只达到了7.8
    FPS，对于许多应用来说已经足够好了。但是如果我们最初的计划是在实时视频上做一些事情呢？那么这还不够。对模型进行量化可以实现更高的性能，但鉴于树莓派的CPU并未针对8位整数运算进行优化，这只会带来一点点性能提升。
- en: Table 15-3\. Raspberry Pi benchmarks
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 表15-3。树莓派基准测试
- en: '| **Setup** | **FPS** |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| **设置** | **FPS** |'
- en: '| --- | --- |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Raspberry Pi 4 (tflite, 8-bit) | 8.6 |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| Raspberry Pi 4 (tflite, 8-bit) | 8.6 |'
- en: '| Raspberry Pi 4 (tflite) | 7.8 |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| Raspberry Pi 4 (tflite) | 7.8 |'
- en: '| Raspberry Pi 3B+ (tflite, 8-bit) | 4.2 |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| Raspberry Pi 3B+ (tflite, 8-bit) | 4.2 |'
- en: '| Raspberry Pi 4 | 2.7 |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| Raspberry Pi 4 | 2.7 |'
- en: '| Raspberry Pi 3B+ | 2.1 |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| Raspberry Pi 3B+ | 2.1 |'
- en: 'So how can we speed things up even more so that they become useful for applications
    like autonomous racecars or automatic drones? We touched on it before: the USB
    accelerators.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们如何进一步加快速度，使其对自动赛车或自动无人机等应用变得更有用呢？我们之前提到过：USB加速器。
- en: Speeding Up with the Google Coral USB Accelerator
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Google Coral USB加速器加速
- en: 'That’s right, these accelerators come in quite handy right now. All of our
    hardware setup can stay exactly the same, we just need to add a little bit here
    and there. So let’s find out: how do we get the Google Coral USB Accelerator to
    run on the Raspberry Pi, and will it speed things up?'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 没错，这些加速器现在非常方便。我们的硬件设置可以保持完全不变，只需要稍微添加一点内容。那么让我们看看：如何让Google Coral USB加速器在树莓派上运行，并且是否可以加快速度？
- en: First things first. Assuming that we have a USB accelerator on our hands, the
    first thing we should always do is look for a “Getting Started” guide from the
    vendor. Check out [*https://coral.withgoogle.com/*](https://coral.withgoogle.com/),
    head to *Docs>USB Accelerator>Get Started*, and you’re rolling in mere minutes.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 首先要做的事情。假设我们手头有一个USB加速器，我们应该做的第一件事是从供应商那里找到一个“入门指南”。查看[*https://coral.withgoogle.com/*](https://coral.withgoogle.com/)，转到*Docs>USB
    Accelerator>Get Started*，您将在几分钟内开始运行。
- en: As of this writing, the Coral USB Accelerator is not yet fully compatible with
    the Raspberry Pi 4, but after fiddling around with the *install.sh* script, it
    is pretty easy to get it running. You need to simply add a part to the install
    script so that it recognizes the Pi 4, as demonstrated in [Figure 15-11](part0018.html#google_coral_install_script_changes).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 截至目前，Coral USB加速器尚未完全兼容树莓派4，但在调整*install.sh*脚本后，很容易让它运行起来。您只需要简单地在安装脚本中添加一部分，以便它识别Pi
    4，如[图15-11](part0018.html#google_coral_install_script_changes)所示。
- en: '![Google Coral install script changes](../images/00206.jpeg)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![Google Coral install script changes](../images/00206.jpeg)'
- en: Figure 15-11\. Google Coral install script changes
  id: totrans-200
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图15-11。Google Coral安装脚本更改
- en: 'Now the *install.sh* script will run correctly. Then, we need to rename a *.so*
    file, so that it will also work with Python 3.7\. To do this, use the Unix copy
    command:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 现在*install.sh*脚本将正确运行。然后，我们需要重命名一个*.so*文件，以便它也可以在Python 3.7中运行。使用Unix的复制命令来完成这一步：
- en: '[PRE7]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: After you do this, everything should work correctly, and the demonstrations
    from Google should run.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些步骤后，一切应该正常工作，Google的演示应该可以运行。
- en: Now that we have the Coral running, let’s try to benchmark the same MobileNetV2
    model again. But this time, it must be the quantized version of it, because Google’s
    Edge TPU supports only 8-bit integer operations. Google supplied us with the quantized
    and converted MobileNetV2 model, ready to use with the Edge TPU. We can download
    it from the Coral website under *Resources > See pre-compiled models > MobileNetV2(ImageNet)
    > Edge TPU Model*.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经让Coral运行起来了，让我们再次尝试对同一个MobileNetV2模型进行基准测试。但这次，必须使用它的量化版本，因为Google的Edge
    TPU仅支持8位整数运算。Google提供了经过量化和转换的MobileNetV2模型，可以直接在Edge TPU上使用。我们可以从Coral网站下载它，路径为*Resources
    > See pre-compiled models > MobileNetV2(ImageNet) > Edge TPU Model*。
- en: Note
  id: totrans-205
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If you want to create, train, quantize, and convert your own model for the Edge
    TPU, this is a bit more work and cannot be done using Keras. You can find information
    on how to do this on the [Google Coral website](https://oreil.ly/ydoSy).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想为Edge TPU创建、训练、量化和转换自己的模型，这需要更多工作，不能使用Keras完成。您可以在[Google Coral网站](https://oreil.ly/ydoSy)上找到如何操作的信息。
- en: 'We have a working USB accelerator and a model to run on it. Now, let’s make
    a new script to test its performance. The file we are about to make is again very
    similar to the previous one and takes a lot straight from the examples Google
    supplied with the Coral. And, as always, this file is available for download at
    GitHub website (see [*http://PracticalDeepLearning.ai*](http://PracticalDeepLearning.ai)):'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个可用的USB加速器和一个可以在其上运行的模型。现在，让我们制作一个新的脚本来测试其性能。我们即将制作的文件与之前的文件非常相似，并且很多内容直接来自Google提供的Coral示例。而且，像往常一样，这个文件可以在GitHub网站上下载（请参见[*http://PracticalDeepLearning.ai*](http://PracticalDeepLearning.ai)）：
- en: '[PRE8]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Yes, that is correct. It did all 250 classifications already! For the Raspberry
    Pi 4 with USB3, it took only 1.04 seconds, which translates to 240.38 FPS! Now
    that’s a speedup. As you can expect with these speeds, live video would be no
    problem at all.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，没错。它已经完成了250次分类！对于带有USB3的Raspberry Pi 4，只需要1.04秒，这相当于240.38 FPS！现在这才是加速。正如您可以期待的那样，使用这些速度，实时视频将毫无问题。
- en: Lots of precompiled models are available, for all kinds of different purposes,
    so check them out. You might be able to find a model that suits your needs so
    that you don’t need to go through the flow (or struggle) to create, train, quantize,
    and convert your own.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多预编译的模型可用，用于各种不同的目的，所以请查看它们。您可能会找到一个适合您需求的模型，这样您就不需要经历创建、训练、量化和转换自己的流程（或挣扎）。
- en: The Raspberry Pi 3 has no USB3 ports, only USB2\. We can clearly see in [Table 15-4](part0018.html#google_coral_benchmarks)
    that this creates a data bottleneck for the Coral.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: Raspberry Pi 3没有USB3端口，只有USB2。我们可以在[表15-4](part0018.html#google_coral_benchmarks)中清楚地看到这为Coral创建了一个数据瓶颈。
- en: Table 15-4\. Google Coral benchmarks
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 表15-4. Google Coral基准测试
- en: '| **Setup** | **FPS** |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| **设置** | **FPS** |'
- en: '| --- | --- |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| i7-7700K + Coral (tflite, 8-bit) | 352.1 |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| i7-7700K + Coral（tflite，8位）| 352.1 |'
- en: '| Raspberry Pi 4 + Coral (tflite, 8-bit) | 240.4 |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| Raspberry Pi 4 + Coral（tflite，8位）| 240.4 |'
- en: '| Jetson Nano + Coral (tflite, 8-bit) | 223.2 |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| Jetson Nano + Coral（tflite，8位）| 223.2 |'
- en: '| RPi3 + Coral (tflite, 8-bit) | 75.5 |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| RPi3 + Coral（tflite，8位）| 75.5 |'
- en: Port to NVIDIA Jetson Nano
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 移植到NVIDIA Jetson Nano
- en: That USB accelerator is nice, but what if your project needs a real niche model,
    trained on some crazy, self-made, dataset? As we said earlier, creating a new
    model for the Coral Edge TPU is quite a bit more work than just creating a Keras
    model. So, is there an easy way to have a custom model running on the edge with
    some decent performance? NVIDIA to the rescue! With its Jetson Nano, the company
    has created a replacement for the Raspberry Pi that has a CUDA enabled, and rather
    efficient, GPU on board, which lets you accelerate not only TensorFlow, but anything
    you like.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 那个USB加速器很好，但是如果您的项目需要一个真正的特定模型，该模型在一些疯狂的、自制的数据集上进行了训练呢？正如我们之前所说，为Coral Edge
    TPU创建一个新模型要比创建一个Keras模型要复杂得多。那么，在边缘上运行具有良好性能的自定义模型是否有简单的方法？NVIDIA来拯救！通过其Jetson
    Nano，该公司已经为Raspberry Pi创建了一个替代品，它具有启用CUDA的、相当高效的GPU，让您不仅可以加速TensorFlow，还可以加速任何您喜欢的东西。
- en: Again, we must begin by installing all needed packages. First, you want to download
    a copy of NVIDIA’s JetPack, which is its version of a Debian-like OS for the Jetson
    platform. Then, to install TensorFlow and the needed packages, NVIDIA walks us
    through how to do that [here](https://oreil.ly/d11bQ).
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们必须首先安装所有所需的软件包。首先，您需要下载NVIDIA的JetPack副本，这是其针对Jetson平台的类似Debian的操作系统版本。然后，为了安装TensorFlow和所需的软件包，NVIDIA指导我们如何在[这里](https://oreil.ly/d11bQ)进行操作。
- en: Note
  id: totrans-222
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'Note there is a known issue with `pip3`: “`cannot import name ‘main’`”.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`pip3`存在一个已知问题：“`无法导入名称‘main’`”。
- en: 'Here’s the solution:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 这是解决方案：
- en: '[PRE9]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Tip
  id: totrans-226
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: 'Updating all `pip` packages can take a long time; if you want to ensure that
    your Jetson did not freeze, you might want to first install `htop`:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 更新所有`pip`软件包可能需要很长时间；如果您想确保Jetson没有冻结，您可能首先想要安装`htop`：
- en: '[PRE10]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This lets you monitor CPU utilization. As long as this is working, your Jetson
    is, too.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 这让您可以监视CPU利用率。只要这个工作正常，您的Jetson也是如此。
- en: Note
  id: totrans-230
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The Jetson Nano tends to run rather hot when compiling, so we recommend using
    some kind of fan. The development board has a connector, but keep in mind this
    will feed 5V to the fan, whereas most fans are rated for 12V.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: Jetson Nano在编译时往往会变得很热，因此我们建议使用某种风扇。开发板有一个连接器，但请记住这会向风扇提供5V电压，而大多数风扇的额定电压为12V。
- en: Some 12V fans might do the trick out of the box, some might need a little push
    to get started. You will need a 40 mm x 40 mm fan. 5V versions are also available.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 一些12V风扇可能可以直接解决问题，有些可能需要一点推动才能启动。您将需要一个40毫米x 40毫米的风扇。也有5V版本可用。
- en: Unfortunately, the NVIDIA walkthrough is not as easy as the Google one. Chances
    are you will go through a bit of a struggle with the occasional table-flip moment.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，NVIDIA的操作指南并不像Google的那么简单。您可能会经历一些挣扎，偶尔会有翻桌的时刻。
- en: But hang in there; you’ll get there eventually.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 但请坚持下去；您最终会成功的。
- en: Tip
  id: totrans-235
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: 'Installing Keras on the Jetson requires scipy, which requires `libatlas-base-dev`
    and `gfortran`, so start by installing the latter, and move to the front:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在Jetson上安装Keras需要scipy，它需要`libatlas-base-dev`和`gfortran`，因此首先安装后者，然后再前进：
- en: '[PRE11]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'After everything is done, we can choose to run the *benchmark.py* file directly,
    which will be, because of the GPU, a lot faster than it was on the Raspberry Pi:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 一切都完成后，我们可以选择直接运行*benchmark.py*文件，由于GPU的存在，速度比在Raspberry Pi上快得多：
- en: '[PRE12]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This immediately shows the power of the Jetson Nano: it runs almost exactly
    like any other PC with a GPU. However, 12 FPS is still not huge, so let’s look
    at how to optimize this.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 这立即展示了Jetson Nano的强大之处：它几乎与带有GPU的任何其他PC一样运行。但是，12 FPS仍然不算很高，因此让我们看看如何优化这一点。
- en: Tip
  id: totrans-241
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: You also can attach the Google Coral to your Jetson Nano, which opens up the
    possibility to run one model on the Coral, and another one on the GPU simultaneously.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以将Google Coral连接到Jetson Nano上，这样可以同时在Coral上运行一个模型，在GPU上运行另一个模型的可能性就打开了。
- en: The GPU of the Jetson is actually built specifically for 16-bit-floating point
    operations, so inherently, this will be the best trade-off between precision and
    performance. As mentioned earlier, NVIDIA has a package called TF-TRT, which facilitates
    optimization and conversion. However, it is still a bit more complex than the
    Coral example (keep in mind that Google supplied us with the precompiled model
    file for the Coral). You’ll need to freeze the Keras model and then create a TF-TRT
    inference graph. Doing this can take quite a while if you need to find everything
    laying around on GitHub, so it’s bundled on this book’s GitHub website (see [*http://PracticalDeepLearning.ai*](http://PracticalDeepLearning.ai)).
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: Jetson的GPU实际上是专门用于16位浮点运算的，因此，这将是精度和性能之间的最佳折衷。如前所述，NVIDIA有一个名为TF-TRT的软件包，可以促进优化和转换。然而，这仍然比Coral示例复杂一些（请记住，谷歌为我们提供了Coral的预编译模型文件）。您需要冻结Keras模型，然后创建一个TF-TRT推理图。如果您需要在GitHub上找到所有内容，这可能需要一段时间，因此它已捆绑在本书的GitHub网站上（请参见[*http://PracticalDeepLearning.ai*](http://PracticalDeepLearning.ai)）。
- en: You can use the *tftrt_helper.py* file to optimize your own models for inferencing
    on the Jetson Nano. All it really does is freeze the Keras model, removes the
    training nodes, and then use NVIDIA’s TF-TRT Python package (included in TensorFlow
    Contrib) to optimize the model.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用*tftrt_helper.py*文件来优化自己的模型，以便在Jetson Nano上进行推理。它实际上只是冻结Keras模型，删除训练节点，然后使用NVIDIA的TF-TRT
    Python软件包（包含在TensorFlow Contrib中）来优化模型。
- en: '[PRE13]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 48 FPS, that’s a speedup of four times with just a few lines of code. Exciting,
    isn’t it? You can achieve similar speedups on your own custom models, tailored
    to the specific needs of your project; these performance benchmarks can be found
    in [Table 15-5](part0018.html#nvidia_jetson_nano_benchmarks).
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 48 FPS，仅几行代码就实现了四倍的加速。令人兴奋，不是吗？您可以在自己定制的模型上实现类似的加速，以满足项目特定需求；这些性能基准可以在[表15-5](part0018.html#nvidia_jetson_nano_benchmarks)中找到。
- en: Table 15-5\. NVIDIA Jetson Nano benchmarks
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 表15-5. NVIDIA Jetson Nano基准测试
- en: '| **Setup** | **FPS** |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| **设置** | **FPS** |'
- en: '| --- | --- |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Jetson Nano + Coral (tflite, 8-bit) | 223.2 |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| Jetson Nano + Coral（tflite，8位） | 223.2 |'
- en: '| Jetson Nano (TF-TRT, 16-bit) | 48.8 |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| Jetson Nano（TF-TRT，16位） | 48.8 |'
- en: '| Jetson Nano 128CUDA | 12.2 |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| Jetson Nano 128CUDA | 12.2 |'
- en: '| Jetson Nano (tflite, 8-bit) | 11.3 |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| Jetson Nano（tflite，8位） | 11.3 |'
- en: Comparing the Performance of Edge Devices
  id: totrans-254
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 比较边缘设备的性能
- en: '[Table 15-6](part0018.html#full_benchmarking_results) shows a quantitative
    comparison of several edge devices running the MobileNetV2 model.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '[表15-6](part0018.html#full_benchmarking_results)显示了运行MobileNetV2模型的几个边缘设备的定量比较。'
- en: Table 15-6\. Full benchmarking results
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 表15-6. 完整的基准测试结果
- en: '| **Setup** | **FPS** |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| **设置** | **FPS** |'
- en: '| --- | --- |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| i7-7700K + Coral (tflite, 8-bit) | 352.1 |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| i7-7700K + Coral（tflite，8位） | 352.1 |'
- en: '| i7-7700K + GTX1080 2560CUDA | 304.9 |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| i7-7700K + GTX1080 2560CUDA | 304.9 |'
- en: '| Raspberry Pi 4 + Coral | 240.4 |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| 树莓派4 + Coral | 240.4 |'
- en: '| Jetson Nano + Coral (tflite, 8-bit) | 223.2 |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| Jetson Nano + Coral（tflite，8位） | 223.2 |'
- en: '| RPi3 + Coral (tflite, 8-bit) | 75.5 |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| RPi3 + Coral（tflite，8位） | 75.5 |'
- en: '| Jetson Nano (TF-TRT, 16-bit) | 48.8 |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| Jetson Nano（TF-TRT，16位） | 48.8 |'
- en: '| i7-7700K (tflite, 8-bit) | 32.4 |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| i7-7700K（tflite，8位） | 32.4 |'
- en: '| i9-9880HQ (2019 MacBook Pro) | 15.0 |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| i9-9880HQ（2019款MacBook Pro） | 15.0 |'
- en: '| Jetson Nano 128CUDA | 12.2 |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| Jetson Nano 128CUDA | 12.2 |'
- en: '| Jetson Nano (tflite, 8-bit) | 11.3 |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| Jetson Nano（tflite，8位） | 11.3 |'
- en: '| i7-4870HQ (2014 MacBook Pro) | 11.1 |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| i7-4870HQ（2014款MacBook Pro） | 11.1 |'
- en: '| Jetson Nano (tflite, 8-bit) | 10.9 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| Jetson Nano（tflite，8位） | 10.9 |'
- en: '| Raspberry Pi 4 (tflite, 8-bit) | 8.6 |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| 树莓派4（tflite，8位） | 8.6 |'
- en: '| Raspberry Pi 4 (tflite) | 7.8 |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| 树莓派4（tflite） | 7.8 |'
- en: '| RPi3B+ (tflite, 8-bit) | 4.2 |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| RPi3B+（tflite，8位） | 4.2 |'
- en: '| Raspberry Pi 4 | 2.7 |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| 树莓派4 | 2.7 |'
- en: '| RPi3B+ | 2.1 |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| RPi3B+ | 2.1 |'
- en: 'We can summarize the takeaways from these experiments as follows:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以总结这些实验的要点如下：
- en: Good optimizations make a big difference. The world of computing optimization
    is still growing rapidly, and we will see big things coming up in the next few
    years.
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 良好的优化会产生很大的影响。计算优化领域仍在迅速发展，我们将在未来几年看到一些重大变化。
- en: More is always better when talking about computing units for AI.
  id: totrans-278
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在谈论AI的计算单元时，更多总是更好的。
- en: ASIC > FPGA > GPU > CPU in terms of performance/watt.
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在性能/瓦特方面，ASIC > FPGA > GPU > CPU。
- en: TensorFlow Lite is awesome, especially for small CPUs. Keep in mind that it
    is specifically aimed at small CPUs, and using it for x64 machines will not be
    that interesting.
  id: totrans-280
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: TensorFlow Lite非常棒，尤其适用于小型CPU。请记住，它专门针对小型CPU，对于x64机器使用将不那么有趣。
- en: Case Studies
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 案例研究
- en: This chapter is about makers. And it would be incomplete without showcasing
    what they make. Let’s look at a few things that have been created by running AI
    on the edge.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 这一章是关于制造者的。没有展示他们制造的东西，这一章就是不完整的。让我们看一下通过在边缘运行AI所创造的一些东西。
- en: JetBot
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: JetBot
- en: NVIDIA has been at the forefront of the deep learning revolution, enabling researchers
    and developers with powerful hardware and software. And in 2019, they took the
    next step to enable makers, too, by releasing the Jetson Nano. We already know
    the power of this hardware, so now it’s time to build something with it—like a
    DIY miniature car. Luckily, NVIDIA has us covered with JetBot ([Figure 15-12](part0018.html#nvidia_jetbot)),
    the open source robot that can be controlled by an onboard Jetson Nano.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: NVIDIA一直处于深度学习革命的前沿，为研究人员和开发人员提供强大的硬件和软件。2019年，他们迈出了下一步，也为制造者们提供了Jetson Nano。我们已经了解了这款硬件的强大之处，现在是时候用它来构建一些东西了，比如DIY微型汽车。幸运的是，NVIDIA为我们提供了JetBot（[图15-12](part0018.html#nvidia_jetbot)），这是一个开源机器人，可以由Jetson
    Nano控制。
- en: 'The [JetBot wiki](https://oreil.ly/3nExK) features beginner-friendly step-by-step
    instructions on building it. Here’s a high-level look:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '[JetBot维基](https://oreil.ly/3nExK)提供了适合初学者的逐步构建说明。以下是一个高层次的概述：'
- en: Buy the parts specified in the Bill of Materials, like the motor, caster, camera,
    and WiFi antenna. There are about 30 parts, costing around $150, on top of the
    $99 Jetson Nano.
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 购买材料清单中指定的零件，如电机、转向器、摄像头和WiFi天线。除了99美元的Jetson Nano外，还有大约30个零件，总成本约为150美元。
- en: It’s time to channel our inner MacGyver, get a set of pliers and a cross-tip
    screwdriver, and assemble the parts. The end result should be something resembling
    [Figure 15-12](part0018.html#nvidia_jetbot).
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在是时候发挥我们内心的麦克盖尔，拿起一把钳子和一个十字螺丝刀，组装这些零件。最终结果应该类似于[图15-12](part0018.html#nvidia_jetbot)。
- en: Next, we’d set up the software. This involves flashing the JetBot image onto
    an SD card, booting the Jetson Nano, connecting it to WiFi, and finally connecting
    to our JetBot from a web browser.
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将设置软件。这涉及将JetBot镜像刷入SD卡，启动Jetson Nano，将其连接到WiFi，最后通过Web浏览器连接到我们的JetBot。
- en: Finally, we run through the example notebooks provided. The provided notebooks
    enable us, through little code, to not only control the bot from a web browser,
    but also use its camera to collect training data from streaming video, train a
    deep learning model right on the device (the Jetson Nano is a mini-GPU after all),
    and use it for tasks such as avoiding obstacles and following objects such as
    a person or a ball.
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们运行提供的示例笔记本。提供的笔记本使我们能够通过少量代码不仅可以从Web浏览器控制机器人，还可以使用其摄像头从流视频中收集训练数据，在设备上训练深度学习模型（毕竟Jetson
    Nano是一个迷你GPU），并将其用于避开障碍物和跟随对象（如人或球）等任务。
- en: '![NVIDIA JetBot](../images/00165.jpeg)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![NVIDIA JetBot](../images/00165.jpeg)'
- en: Figure 15-12\. NVIDIA JetBot
  id: totrans-291
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图15-12. NVIDIA JetBot
- en: 'Makers are already using this base framework to extend the JetBot’s capabilities,
    such as attaching lidar sensors to it for understanding the environment better,
    bringing JetBot to different physical forms like tanks, Roomba vacuum cleaners
    (JetRoomba), object-following spiders (JetSpider), and more. Because all roads
    eventually lead to racing cars, the Jetson Nano team eventually released a similar
    open source recipe book for a racing car called JetRacer. It’s based on a faster
    chassis, higher camera frame rate, and optimizations for inference (with TensorRT)
    to handle the speed. The end result: JetRacer is already being raced at events
    like the DIY Robocars meetups.'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 制造商已经在这个基础框架上扩展了JetBot的功能，例如将激光雷达传感器连接到JetBot上，以更好地理解环境，将JetBot带到不同的物理形式，如坦克、Roomba吸尘器（JetRoomba）、跟随物体的蜘蛛（JetSpider）等。因为所有道路最终都通向赛车，Jetson
    Nano团队最终发布了一个类似的开源配方书，用于名为JetRacer的赛车。它基于更快的底盘、更高的摄像头帧率，并针对推理进行了优化（使用TensorRT）以处理速度。最终结果：JetRacer已经在DIY
    Robocars聚会等活动中进行比赛。
- en: The slowest step here is…waiting for the hardware to arrive.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 这里最慢的步骤是...等待硬件到货。
- en: Squatting for Metro Tickets
  id: totrans-294
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 蹲下换取地铁票
- en: When good health can’t motivate people to exercise, what else would? The answer
    turns out to be…free train tickets! To raise public awareness for its growing
    obesity crisis, Mexico City installed ticket machines with cameras at subway stations
    that give free tickets, but only if you exercise. Ten squats get a free ticket
    ([Figure 15-13](part0018.html#squatting_for_tickets)). Moscow, too, implemented
    a similar system at its metro stations, but apparently, officials there had a
    much higher fitness standard at 30 squats per person.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 当健康不能激励人们锻炼时，还有什么？答案是...免费的火车票！为了提高公众对其不断增长的肥胖危机的认识，墨西哥城在地铁站安装了带摄像头的售票机，提供免费车票，但只有在你锻炼时才能获得。十个深蹲可以获得一张免费车票（[图15-13](part0018.html#squatting_for_tickets)）。莫斯科也在其地铁站实施了类似的系统，但显然，那里的官员对每个人要求30个深蹲。
- en: Inspired by these, we could foresee how to build our own “squat-tracker.” We
    could achieve this in multiple ways, the simplest being to train our own classifier
    with the classes “squatting” and “not squatting.” This would clearly involve building
    a dataset with thousands of pictures of people either squatting or not squatting.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 受到这些启发，我们可以预见如何构建我们自己的“深蹲跟踪器”。我们可以通过多种方式实现这一目标，最简单的方法是用“深蹲”和“不深蹲”这两个类别训练我们自己的分类器。这显然需要构建一个包含成千上万张人们蹲下或不蹲下的图片的数据集。
- en: A much better way to accomplish this would involve running PoseNet (which tracks
    body joints, as we saw in [Chapter 10](part0012.html#BE6O3-13fa565533764549a6f0ab7f11eed62b))
    on, say, Google Coral USB Accelerator. With its 10-plus FPS, we could track how
    many times the hip points drop low enough and count much more accurately. All
    we would need is a Raspberry Pi, a Pi Camera, a Coral USB Accelerator, and a public
    transport operator to provide a ticket printer and endless free tickets, and we
    could start making our cities fitter than ever.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 更好的方法是运行PoseNet（跟踪身体关节，正如我们在[第10章](part0012.html#BE6O3-13fa565533764549a6f0ab7f11eed62b)中看到的）在Google
    Coral USB加速器上。借助其10多FPS，我们可以跟踪髋部点下降到足够低的次数，并更准确地计数。我们所需要的只是一个树莓派、一个Pi摄像头、一个Coral
    USB加速器和一个公共交通运营商提供一个车票打印机和无尽的免费车票，我们就可以开始让我们的城市变得更健康。
- en: '![Squatting for tickets](../images/00126.jpeg)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![蹲下换取地铁票](../images/00126.jpeg)'
- en: Figure 15-13\. Squatting for tickets
  id: totrans-299
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图15-13. 蹲下换取车票
- en: Cucumber Sorter
  id: totrans-300
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 黄瓜分类器
- en: Makoto Koike, the son of cucumber farmers in Japan, observed that his parents
    spent a lot of time postharvest sorting through cucumbers. The sorting required
    separating cucumbers into nine categories based on fine-grained analysis of very
    small features such as minute texture differences, tiny scratches, and prickles,
    along with larger attributes such as size, thickness, and curvature. The system
    was complicated and hiring part-time workers was pretty much a no-go because of
    how long it would take to train them. He couldn’t sit by idly watching his parents
    go through the labor-intensive task for more than eight hours every single day.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 日本黄瓜农场主的儿子小池真琴观察到，他的父母在收获后花费了大量时间分类黄瓜。这种分类需要根据非常小的特征（如微小的纹理差异、微小的划痕和刺，以及更大的属性，如大小、厚度和曲率）将黄瓜分成九类。这个系统很复杂，雇佣兼职工人几乎是不可能的，因为培训他们需要花费很长时间。他不能袖手旁观，看着父母每天超过八个小时地进行这种劳动密集型的任务。
- en: One detail we didn’t mention yet is that Mr. Koike was formerly an embedded
    systems designer at Toyota. He realized that a lot of the visual inspection could
    be automated using the power of deep learning. He took more than 7,000 pictures
    of different cucumbers that his mother had manually sorted over a three-month
    period. He then trained a classifier that could look at a picture of a cucumber
    and predict with a high degree of accuracy to which category it belonged. But
    a classifier is not going to do much on its own now, will it?
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还没有提到的一个细节是，小池先生曾是丰田的嵌入式系统设计师。他意识到很多视觉检查可以利用深度学习的力量自动化。他拍摄了超过7000张他母亲在三个月内手动分类的不同黄瓜的照片。然后，他训练了一个分类器，可以查看黄瓜的照片，并以高度准确性预测它属于哪个类别。但一个分类器现在单独做不了什么，对吧？
- en: Using his experience in embedded systems, he deployed a classifier to a Raspberry
    Pi that was connected to a camera, a conveyor-belt system, and a sorting arm that
    pushed each cucumber into one of the multiple bins based on the predictions from
    the Raspberry Pi ([Figure 15-14](part0018.html#makoto_koikeapostrophes_cucumber_sorting)).
    The Raspberry Pi ran a small cucumber/not-cucumber classifier as a first pass.
    For images classified as cucumber, the Raspberry Pi would send the image to a
    server that ran the more sophisticated multiple category cucumber classifier.
    Keep in mind that this was in 2015, shortly after TensorFlow was released (long
    before the days of TensorFlow Lite, MobileNet, and the extra power of the current
    Raspberry Pi 4 or even 3). With a machine like this, his parents could spend more
    time in actual farming rather than sorting through already harvested cucumbers
    for days on end.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 利用他在嵌入式系统方面的经验，他将一个分类器部署到一个连接了摄像头、传送带系统和分类手臂的树莓派上，根据树莓派的预测将每个黄瓜推入多个箱子中的一个（[图15-14](part0018.html#makoto_koikeapostrophes_cucumber_sorting)）。树莓派首先运行一个小黄瓜/非黄瓜分类器。对于被分类为黄瓜的图像，树莓派会将图像发送到一个运行更复杂的多类别黄瓜分类器的服务器。请记住，这是在2015年，就在TensorFlow发布不久之后（远在TensorFlow
    Lite、MobileNet以及当前树莓派4甚至3的强大功能之前）。有了这样一台机器，他的父母可以花更多时间在实际的农业上，而不是整天在已经收获的黄瓜中进行分类。
- en: '![Makoto Koike’s cucumber sorting machine (image source)](../images/00086.jpeg)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![小池真的黄瓜分类机（图片来源）](../images/00086.jpeg)'
- en: Figure 15-14\. Makoto Koike’s cucumber sorting machine ([image source](https://oreil.ly/0cSOp))
  id: totrans-305
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图15-14\. 小池真的黄瓜分类机（[图片来源](https://oreil.ly/0cSOp)）
- en: 'Even though the debate on AI taking over jobs appears daily in the news, Mr.
    Koike’s story truly highlights the real value that AI provides: making humans
    more productive and augmenting our abilities, along with making his parents proud.'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管关于人工智能接管工作的辩论每天都出现在新闻中，但小池先生的故事真正突出了人工智能提供的真正价值：使人类更加高效，增强我们的能力，同时让他的父母感到骄傲。
- en: Further Exploration
  id: totrans-307
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步探索
- en: 'There are two equally important aspects to focus on when becoming a maker:
    the hardware and the software. One is incomplete without the other. There are
    more DIY projects to explore than one can build in a lifetime. But the key is
    to find some that you’re passionate about, build them end to end, and feel the
    excitement when they start to actually function. Gradually, you’ll develop the
    know-how so that the next time you read a project, you can guess how to build
    it yourself.'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 成为一个创客时要关注的两个同等重要的方面是硬件和软件。一个缺一不可。有更多的DIY项目可以探索，一个人一辈子也无法完成。但关键是找到一些你热衷的项目，从头到尾构建它们，当它们开始真正运作时感受到兴奋。逐渐地，你会积累知识，下次阅读一个项目时，你可以猜测如何自己构建它。
- en: The best way to get started is to get hands-on and build more and more projects.
    Some excellent sources for inspiration include *Hackster.io*, *Hackaday.io*, and
    *[Instructables.com](http://Instructables.com)*, which feature a large range of
    project themes, platforms, and skill levels (from beginner to advanced), often
    along with the step-by-step instructions.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 开始的最佳方式是动手并构建更多项目。一些优秀的灵感来源包括*Hackster.io*、*Hackaday.io*和*[Instructables.com](http://Instructables.com)*，它们涵盖了各种项目主题、平台和技能水平（从初学者到高级），通常还包括逐步说明。
- en: To reduce the overhead of assembling hardware for beginners, there are several
    kits available in the market. For example, AI Kits for Raspberry Pi including
    AIY Vision Kit (Google), AIY Speech Kit (Google), GoPiGo (Dexter Industries),
    and DuckieTown platform (MIT), to name a few. They lower the barriers for getting
    started with electronic hardware projects, making the new area more approachable
    and hence usable for everyone, from high schoolers to rapid prototypers.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少初学者组装硬件的开销，市场上有几种套件可用。例如，树莓派的AI套件包括AIY Vision Kit（谷歌）、AIY Speech Kit（谷歌）、GoPiGo（Dexter
    Industries）和DuckieTown平台（麻省理工学院），等等。它们降低了开始电子硬件项目的门槛，使这个新领域更易接近，因此对每个人都可用，从高中生到快速原型制作者。
- en: On the software side of things, running AI faster on low-power devices means
    making the models more performant. Model compression techniques like quantization
    and pruning (as mentioned in [Chapter 6](part0008.html#7K4G3-13fa565533764549a6f0ab7f11eed62b))
    can help get us there. To go even faster (at some loss in accuracy), BNNs, which
    represent models in one bit instead of the normal 32 bits, are a potential solution.
    Companies like XNOR.ai and Microsoft’s Embedded Learning Library allow us to make
    such models. For running AI on even lower-power devices like microcontrollers
    with less than 100 KB of memory, Pete Warden’s book [*TinyML*](http://shop.oreilly.com/product/0636920254508.do)
    is an excellent learning resource.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在软件方面，让低功耗设备上的人工智能运行更快意味着使模型更加高效。像量化和修剪这样的模型压缩技术（如[第6章](part0008.html#7K4G3-13fa565533764549a6f0ab7f11eed62b)中提到的）可以帮助我们实现这一目标。为了更快地运行（牺牲一些准确性），BNNs代表模型使用一位而不是正常的32位，是一个潜在的解决方案。像XNOR.ai和微软的嵌入式学习库这样的公司让我们能够制作这样的模型。对于在内存少于100
    KB的微控制器等更低功耗设备上运行人工智能，Pete Warden的书籍[*TinyML*](http://shop.oreilly.com/product/0636920254508.do)是一个优秀的学习资源。
- en: Summary
  id: totrans-312
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we introduced some well-known embedded AI devices and looked
    at how to run a Keras model on some of them. We presented a high-level view of
    their inner workings, and how they achieve the computing capacity needed for running
    neural networks. Eventually benchmarking them to develop an intuition on which
    might be suitable for our projects depending on size, costs, latency, and power
    requirements. Going from platforms to robotic projects, we looked at some ways
    in which makers around the world are using them to build electronic projects.
    The devices discussed in this chapter are obviously just a handful of those available.
    New devices will keep popping up as the edge becomes a more desirable place to
    be for AI.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了一些知名的嵌入式人工智能设备，并看了看如何在其中一些设备上运行Keras模型。我们从高层次的视角介绍了它们的内部运作方式，以及它们如何实现运行神经网络所需的计算能力。最终，我们对它们进行基准测试，以便根据项目的大小、成本、延迟和功耗需求来开发直觉。从平台到机器人项目，我们看了看全球创客们如何利用它们来构建电子项目的一些方法。本章讨论的设备显然只是众多可用设备中的一小部分。随着边缘成为人工智能更受欢迎的地方，新设备将不断涌现。
- en: With the power of edge AI, makers can imagine and bring their dream projects
    to reality, which might have been considered science fiction just a few years
    ago. On your journey in this DIY AI world, remember, you are among a tight-knit
    community of tinkerers with a lot of openness and willingness to share. The forums
    are active, so if you ever get stuck on a problem, there are helpful souls to
    call upon. And hopefully, with your project, you can inspire others to become
    makers themselves.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 借助边缘人工智能的力量，创客们可以想象并实现他们的梦想项目，这些项目在几年前可能被认为是科幻小说。在这个DIY人工智能世界中的旅程中，请记住，你是一个与许多开放和愿意分享的修补者紧密联系在一起的社区中的一员。论坛很活跃，所以如果你遇到问题，总会有乐意帮助的人可以求助。希望通过你的项目，你可以激励其他人成为创客。
