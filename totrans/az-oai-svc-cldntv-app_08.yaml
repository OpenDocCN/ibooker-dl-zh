- en: Chapter 7\. Exploring the Big Picture
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter includes the last pieces of knowledge for your generative AI learning
    with Azure OpenAI and other Microsoft technologies. It includes some future visions,
    interviews with experts, and success stories. Remember, generative AI (and artificial
    intelligence in general) is a highly evolving domain, so use this book as your
    entry to a whole universe of knowledge and learning assets.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start this last chapter by discussing what’s next, from an Azure OpenAI
    perspective. For an avid learner and AI adopter like you, what are the other areas
    you should explore?
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: What’s Next? The Evolution Toward Microsoft Copilot
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Azure OpenAI Service is part of a wider ecosystem. All architectures, APIs,
    and integrations with other generative AI building blocks contribute to the notion
    of AI copilots, which we mentioned in the first chapter.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: AI copilots are technology-enabled assistants, companions that help human agents
    become better, more efficient, workers. The principle behind them is to provide
    an interface (written or spoken) that helps people perform complex tasks, such
    as finding specific information or adding information to a third-party system
    (e.g., a CRM, a support ticketing system).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in [Figure 7-1](#fig_1_the_end_to_end_copilot_architecture),
    the end-to-end Microsoft vision for AI copilots includes models from Azure OpenAI,
    but also their connection with other systems such as Microsoft 365, which already
    includes [its own copilot](https://oreil.ly/Jwuff). This can be expanded with
    additional capabilities by leveraging the data from the [Microsoft Graph API](https://oreil.ly/3qy8E),
    the development interface to access data from the 365 suite (including calendar
    and emails from Outlook, and meeting recordings and transcript from Teams, to
    name a few), and the [Microsoft Dataverse](https://oreil.ly/onOnS), previously
    known as Common Data Model, a data store for the Power Platform and [Dynamics
    365](https://oreil.ly/omP3a) ecosystems.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aoas_0701.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
- en: Figure 7-1\. The end-to-end copilot architecture
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The combination of all these building blocks enables new development patterns,
    augmenting generative AI models with other data sources and systems, and the notion
    of a copilot will certainly evolve over the next few years. You will see this
    kind of end-to-end architecture becoming an industry standard, so I recommend
    you understand how all these pieces connect and enable new productivity and generative
    AI scenarios.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: That said, it would take two or three more books to explore all these pieces,
    but to leverage some official Microsoft resources, take a look at the [Learning
    Pathways site](https://oreil.ly/kljOi) from the Microsoft UK team, and check the
    [AI Learning Companion path](https://oreil.ly/SntTJ) as it contains a huge variety
    of videos, articles, and training programs. You can also explore an [illustrative
    example](https://oreil.ly/1_p3Q) of the Microsoft Copilot technology stack, which
    includes Azure OpenAI and other Microsoft services—very useful if you have a technical
    background.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，要探索所有这些内容可能需要两三本书，但为了利用一些官方的微软资源，请查看微软英国团队提供的[学习路径网站](https://oreil.ly/kljOi)，并检查[人工智能学习伴侣路径](https://oreil.ly/SntTJ)，因为它包含大量视频、文章和培训项目。如果您有技术背景，还可以探索微软Copilot技术栈的[示例](https://oreil.ly/1_p3Q)，其中包括Azure
    OpenAI和其他微软服务——如果您有技术背景，这将非常有用。
- en: 'Let’s now go to what I consider the hidden gem of this book: valuable and exclusive
    insights from interviews with some of the biggest experts out there, which will
    complement the content of this book with diverse perspectives on related topics
    such as design, data quality, the future of AI, etc.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们转向我认为这本书的隐藏宝藏：从一些最大专家那里获得的宝贵且独家见解，这些见解将从设计、数据质量、人工智能的未来等相关的多个角度补充本书的内容。
- en: Expert Insights for the Generative AI Era
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 生成式人工智能时代的专家见解
- en: It is pretty rare, and an extraordinary privilege, to get access to some of
    the most relevant experts on generative AI, people who have a hand in shaping
    generative AI and how organizations are adopting Azure OpenAI and other related
    building blocks.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 能够接触到一些最相关的生成人工智能专家，这些人参与了塑造生成人工智能以及组织如何采用Azure OpenAI和其他相关构建块的工作，这非常罕见，是一种非凡的特权。
- en: 'This section includes a series of interviews with:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本节包括一系列访谈：
- en: '[David Carmona](https://oreil.ly/FOSlv)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[大卫·卡莫纳](https://oreil.ly/FOSlv)'
- en: Vice president and CTO for Strategic Incubations at Microsoft and author of
    the [*The AI Organization* (O’Reilly)](https://oreil.ly/JvO8O). This interview
    includes a discussion on AI adoption and advanced use cases, as well as his vision
    of the future of generative AI. We’ll gain top insights from a visionary leader.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 微软战略孵化副总裁兼首席技术官，也是[*《人工智能组织》*（O’Reilly）](https://oreil.ly/JvO8O)一书的作者。这次访谈讨论了人工智能的采用和高级用例，以及他对生成式人工智能未来的展望。我们将从一位有远见的领导者那里获得顶级见解。
- en: '[Brendan Burns](https://oreil.ly/e_vU5)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '[布伦丹·伯恩斯](https://oreil.ly/e_vU5)'
- en: 'Corporate vice president at Microsoft, an authentic legend of the cloud native
    ecosystem thanks to his role as Kubernetes cofounder and the author of multiple
    O’Reilly books such as [*Kubernetes: Up and Running*](https://oreil.ly/c86hW),
    [*Kubernetes Best Practices*](https://oreil.ly/DIsrj), [*Managing Kubernetes*](https://oreil.ly/cJDzq),
    and [*Designing Distributed Systems*](https://oreil.ly/5GcFO). This conversation
    discusses the convergence between the generative AI era cloud native architectures.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 微软公司副总裁，由于他在Kubernetes共同创始人以及多本O’Reilly书籍（如[*《Kubernetes：快速入门》*](https://oreil.ly/c86hW)、[*《Kubernetes最佳实践》*](https://oreil.ly/DIsrj)、[*《管理Kubernetes》*](https://oreil.ly/cJDzq)、[*《设计分布式系统》*](https://oreil.ly/5GcFO)）的作者身份，成为了云原生生态系统的真实传奇人物。这次对话讨论了生成式人工智能时代云原生架构的融合。
- en: '[John Maeda](https://oreil.ly/4jxQ0)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[约翰·梅达](https://oreil.ly/4jxQ0)'
- en: Vice president of Engineering and head of Computational Design/AI Platform at
    Microsoft, and the main sponsor of the Semantic Kernel project. This is an amazing
    exploration of the role of design for AI solutions and the importance of LLM orchestration
    technologies.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 微软工程副总裁兼计算设计/人工智能平台负责人，以及语义内核项目的主要赞助人。这是对人工智能解决方案设计作用和LLM编排技术重要性的一个令人惊叹的探索。
- en: '[Sarah Bird](https://oreil.ly/N_NK9)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[莎拉·伯德](https://oreil.ly/N_NK9)'
- en: Microsoft’s chief product officer of Responsible AI. This interview includes
    a conversation with the leader in charge of RAI developments for the Azure AI
    platform, including Azure OpenAI. Sarah gives us a different perspective on such
    an important topic.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 微软负责任人工智能的首席产品官。这次访谈包括与负责Azure人工智能平台（包括Azure OpenAI）RAI发展的领导者的对话。莎拉为我们提供了对这个重要话题的不同视角。
- en: '[Tim Ward](https://oreil.ly/cersn)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[蒂姆·沃德](https://oreil.ly/cersn)'
- en: CEO at CluedIn, is a great source for data management topics. This discussion
    dives into data quality as an enabler for generative AI developments, but also
    looks at how AI is changing the way companies perform master data management (MDM)
    and quality control.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: CluedIn的CEO，是数据管理主题的优秀来源。这次讨论深入探讨了数据质量作为生成式AI发展的推动力，同时也审视了AI如何改变公司执行主数据管理（MDM）和质量控制的方式。
- en: '[Seth Juarez](https://oreil.ly/oIrgI)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[Seth Juarez](https://oreil.ly/oIrgI)'
- en: Principal program manager for the AI Platform at Microsoft. Seth has been one
    of the more visible faces of the Azure OpenAI era, thanks to his role as host
    of the [AI Show](https://oreil.ly/h-Fvw). Seth is one of the most well-known professionals
    for Azure OpenAI and Azure AI Studio topics, and a great storyteller who makes
    complex topics look a bit simpler.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 微软AI平台的首席项目经理。Seth是Azure OpenAI时代的更知名面孔之一，多亏了他作为[AI Show](https://oreil.ly/h-Fvw)的主持人。Seth是Azure
    OpenAI和Azure AI Studio主题最知名的专业人士之一，也是一个伟大的讲故事者，他能让复杂的话题看起来简单一些。
- en: '[Saurabh Tiwary](https://oreil.ly/qUK9P)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[Saurabh Tiwary](https://oreil.ly/qUK9P)'
- en: Corporate VP for Microsoft Copilot & Turing. This interview includes a great
    exchange about the vision for Microsoft Copilot as the end-to-end architecture
    that leverages Azure OpenAI Service.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 微软Copilot & Turing的副总裁。这次访谈包括关于微软Copilot作为利用Azure OpenAI服务的端到端架构的愿景的精彩交流。
- en: Let’s dig into these interviews!
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入这些访谈！
- en: 'David Carmona: AI Adoption and the Future of Generative AI'
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: David Carmona：AI的采用和生成式AI的未来
- en: '**A.G.**: So, I know your background, I know about your career at Microsoft,
    but who is David and what’s your role at the Microsoft organization?'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**：所以，我知道你的背景，也知道你在微软的职业生涯，但谁是David，你在微软组织中的角色是什么？'
- en: '![](assets/aoas_07in01.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_07in01.png)'
- en: '**D.C.:** Well, thank you for inviting me. It’s a big pleasure. I think we
    share the pain of writing a book, so I am always in awe when somebody takes that
    big adventure. It’s amazing that you did it, so congratulations for that. I think
    when I look at my role in Microsoft at the end of the day, it’s all about creating
    new incubation businesses. I’ve been in Microsoft for almost 23 years now, and
    it’s always been very focused on that function. I’m originally from Spain, I was
    working for Microsoft in Western Europe, then I moved 15 years ago to Corp in
    Seattle. I was part of the cloud incubation, which was amazing to be part of that.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**D.C.**：嗯，感谢你的邀请，这是一件非常愉快的事情。我认为我们都有写书的痛苦，所以当有人接受这个大冒险时，我总是非常敬畏。你做到了，所以恭喜你。我认为，当我最终审视我在微软的角色时，它全部关于创建新的孵化业务。我在微软已经快23年了，我一直非常专注于这个职能。我最初来自西班牙，我在西欧为微软工作，然后15年前我搬到了西雅图的总部。我曾参与云孵化项目，那是非常令人兴奋的。'
- en: Then after that, when the cloud became mainstream, and I didn’t have to prove
    all the time the importance of the cloud, then I was offered to lead AI incubation.
    It was just when cloud was becoming mainstream at that time, which was eight,
    nine years ago as it was something that started in Microsoft Research. I was working
    with Microsoft Research at that time, and it was all about creating a new business
    category for Microsoft. Just when that started to be mainstream too, I recently—two
    years ago, so just when I didn’t have to prove again in every conversation the
    importance of AI—I moved to the next businesses. I’m working now on areas like
    the future of AI, which are the new frontiers of AI that we will see in the future.
    For example, applying AI to science, which is an amazing use case scenario. Then
    other areas like quantum computing, which I also have the pleasure to incubate,
    and some others like space, communications, future of communication, and so on.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在云成为主流之后，我不再需要不断证明云的重要性，于是我被邀请领导AI孵化项目。那时正是云开始主流化的时期，大约八到九年前，它始于微软研究院。当时我正在与微软研究院合作，我们的目标是创造一个新的商业类别。就在那开始变得主流的时候，也就是两年前，就在我不需要在每次对话中再次证明AI的重要性时，我转向了下一个业务。我现在正在研究像AI的未来这样的领域，这些是我们在未来将会看到的AI的新前沿。例如，将AI应用于科学，这是一个惊人的用例场景。然后其他领域，如量子计算，我也很荣幸地参与了孵化，还有一些其他领域，如太空、通信、通信的未来等等。
- en: '**A.G.**: You’re a good person to talk to about the vision of generative AI,
    artificial intelligence in general, and how we will be using them in the next
    few years. What’s the potential and the cool things that you’re seeing now? What’s
    your vision for this generative AI era?'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 你是谈论生成式AI、一般人工智能以及我们将在未来几年如何使用它们的理想人选。你现在看到了哪些潜在的和有趣的东西？你对这个生成式AI时代的展望是什么？'
- en: '**D.C.**: For me, the big difference is the scenarios that you can address
    with this new AI that you couldn’t address before, of course. The whole concept
    of reasoning on top of language, or any other modality, and not only data, that
    is something super powerful and we can speak about a lot. But for me, the big
    transformation, what is really the revolution of this new generation of AI is
    that it is broader, it is more generalized. In the past, to create an AI model,
    you required a specific dataset and a specific model. I still remember those early
    times of AI when we were creating these milestones for AI in Microsoft Research
    of image classification of human parity, speech recognition, etc. All of those
    require a very specific team, super specialized on that, with a very specific
    dataset and model.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**D.C.**: 对于我来说，最大的不同之处在于你可以用这个新的AI解决之前无法解决的问题，当然。在语言或其他任何模态之上进行推理的概念，而不仅仅是数据，这是非常强大的，我们可以有很多话要说。但对我来说，真正的变革，这一代新AI的革命性之处在于它更加广泛，更加通用。在过去，要创建一个AI模型，你需要一个特定的数据集和一个特定的模型。我仍然记得那些早期AI的时光，当时我们在微软研究院为AI创造了这些里程碑，比如图像分类、人类对等、语音识别等。所有这些都需要一个非常专业的团队，对那个领域有非常具体的了解，拥有非常具体的数据集和模型。'
- en: The big change of that, the big impact of that is the possibility. Now that
    model has become something that is not only for data scientists to create, but
    for even end users to customize and use in their daily lives and jobs, which is
    the concept of Copilot. The rest is history after that. But for me, that is the
    core difference of this new AI.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这种变化的大变化，这种影响的大影响在于可能性。现在，这个模型已经变成不仅仅是数据科学家可以创建的，甚至最终用户也可以定制并在他们的日常生活和工作中使用，这就是Copilot的概念。在那之后，其余的都是历史。但对我来说，这就是这一代新AI的核心区别。
- en: '**A.G.**: Exactly. Because we have been using AI. We had AI in different products,
    but most people weren’t aware that they were using AI or being subject to AI.
    Now it’s natural, and that’s the concept of democratization, access to technology,
    because we use language, which is the purest way to communicate. I think it’s
    very exciting.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 正是如此。因为我们一直在使用AI。我们在不同的产品中都有AI，但大多数人并没有意识到他们正在使用AI或受到AI的影响。现在这是自然而然的，这就是民主化的概念，技术的可访问性，因为我们使用语言，这是最纯粹的沟通方式。我认为这非常令人兴奋。'
- en: '**D.C.**: This is just the beginning. As you know, I’m super excited about
    what is going to come next. Not only on the technology itself, of course, the
    technology will evolve, but also I think as we understand the technology better,
    and we start using it in more use cases, we’re going to see scenarios that we
    can not even think about today. The one that I mentioned at the beginning that
    I work on a lot lately is, of course, the applicability to scientific discovery,
    which is going to open areas that are just amazing, that we cannot even imagine
    yet.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**D.C.**: 这只是开始。正如你所知，我对接下来会发生什么感到非常兴奋。当然，技术本身将会发展，但我认为随着我们对技术的理解更加深入，我们开始在更多用例中使用它，我们将看到我们今天甚至无法想象的场景。我之前提到的一个我最近一直在研究的场景是，当然，它在科学发现中的应用，这将开辟一些我们甚至无法想象的令人惊叹的领域。'
- en: '**A.G.:** Yes. Bringing that scalability to situations where maybe in the traditional
    world we couldn’t take care of that. There’s this public case with the SERMAS,
    the health department of Madrid in Spain, with Julian Isla that you probably know.
    They’re trying to leverage generative AI to spot the good information, to retrieve
    the good information for rare diseases. Usually, you have a business case behind
    everything, and with traditional AI, you will say, OK, there’s not enough of a
    target public because it’s a rare disease. With this, you can actually bring that
    to all the doctors in the world, and they can spot the situation in a faster and
    more efficient way. That’s a perfect example of the kind of things that even if
    they don’t sound super advanced because it’s just retrieving information, I personally
    love it.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的。将这种可扩展性应用到那些在传统世界中我们可能无法处理的情况中。有一个公共案例，是西班牙马德里卫生部门的SERMAS，你可能知道朱利安·伊斯拉。他们试图利用生成式AI来识别好的信息，为罕见疾病检索好的信息。通常，每件事背后都有一个商业案例，而使用传统AI，你会说，好吧，目标公众不够多，因为这是一种罕见疾病。而使用这种方法，你实际上可以将它带给全世界的医生，他们可以更快、更有效地识别这种情况。这是一个完美的例子，即使它听起来并不特别先进，因为它只是检索信息，但我个人非常喜欢它。'
- en: '**D.C.**: Yeah. I’m in love with that use case. I’m also part of the nonprofit
    [Foundation 29](https://oreil.ly/DCC5D) that Julian Isla leads, with Carlos Mascias
    and others. For me, it is a great example, as you said, because it’s focused,
    as you know, on diagnosing rare diseases. The problem that we have with a profession
    like doctors is that it relies a lot on the experience of the doctor. That works
    perfectly fine when you are diagnosing a common disease. But the exposure to rare
    diseases in primary care doctors is very low. It’s very difficult for them to
    diagnose those diseases. Consider that the average time of diagnosis of a rare
    disease is seven years. Those are seven years that you are not applying the right
    treatment to that disease. With things like this where a model can help because
    it’s always helping the doctor, so guiding the doctor, giving them clues on where
    the disease could come from, that is an amazing tool that I think is a great example
    of this new paradigm of humans and machines working together.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**D.C.**: 是的。我对这个用例爱不释手。我也是朱利安·伊斯拉领导的非营利组织[Foundation 29](https://oreil.ly/DCC5D)的一部分，还有卡洛斯·马斯西亚斯和其他人。对我来说，这是一个很好的例子，正如你所说，因为它专注于诊断罕见疾病。我们面临的一个问题是，像医生这样的职业很大程度上依赖于医生的经验。当你诊断常见疾病时，这工作得很好。但初级保健医生接触罕见疾病的机会非常少。他们很难诊断这些疾病。考虑到罕见疾病的平均诊断时间为七年。这七年你都没有对这种疾病应用正确的治疗。像这样的东西，一个模型可以帮助，因为它总是在帮助医生，引导医生，给他们提供疾病可能来源的线索，这是一个了不起的工具，我认为它是这种新的人机合作范例的一个很好的例子。'
- en: '**A.G.**: Exactly, and improving the status quo. Something that is impossible
    to deny is that there’s something that we can improve with technology. You have
    mentioned the models, you have mentioned the platform. This book is about Azure
    OpenAI, but how do you see Azure OpenAI as a piece of technology or as a platform,
    as a technology enabler for this era? How do you see this going? It’s about the
    model, it’s about the platform, the different layers, the thing around it. I have
    my opinion, but I want to hear yours.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 没错，这是在改善现状。一个无法否认的事实是，我们可以通过技术来改进某些事情。你提到了模型，你提到了平台。这本书是关于Azure OpenAI的，但你如何看待Azure
    OpenAI作为一项技术或作为一个平台，作为这个时代的技术推动者？你如何看待它的未来发展？这关乎模型，关乎平台，不同层次，以及与之相关的事物。我有我的看法，但我想听听你的。'
- en: '**D.C.**: I think it’s a deeper conversation, I could say. If you look at this
    only at one particular layer of the ecosystem, you are probably missing a lot
    of things. For me, AI is more than a technology, it’s a new paradigm, it’s a new
    economy actually. You look at the impact that AI is going to have even for core
    GDP growth and it’s huge. We are addressing it with just a layer of the stack,
    it’s not enough. You need to take a look at the entire ecosystem. In that entire
    ecosystem, you have many players. Of course, you have at the bottom of it, you
    have even the chips, even the pure hardware that you need to consider for this.
    On top of that, you have the big data centers that you need to address and to
    target one of these applications. Then on top of that, you have the foundational
    models, which are super visible, of course, they are a critical part of it. But
    on top of that, you also need the tooling, the platform to really get the most
    of these models. It’s very easy and you know this more than anybody, it’s very
    easy to start a proof of concept on a service and model. Very easy to start doing
    prompts and start getting more of that model. But to create a real use case, to
    create a full scenario, you need way more than that. You need to start talking
    about grounding, safety, things like services integration, such as plug-ins and
    many other areas that are satellite to the model but are equally important. Then
    on top of that, you still have more layers. You have responsibility, which is
    critical. You have the applications, you have the distribution.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**D.C.**：我认为这是一个更深层次的对话，我可以这么说。如果你只从生态系统的某一特定层来看待这个问题，你可能会错过很多东西。对我来说，AI不仅仅是一种技术，它是一个新的范式，实际上是一个新的经济。你看，AI对核心GDP增长的影响是巨大的。我们只是用技术栈的一层来应对这个问题，这还不够。你需要审视整个生态系统。在整个生态系统中，有众多参与者。当然，在最底层，你有芯片，甚至有你需要考虑的纯硬件。然后，在最上面，你需要解决和针对这些应用的大数据中心。再往上，你有基础模型，它们当然非常明显，它们是其中的关键部分。但除此之外，你还需要工具和平台，才能真正充分利用这些模型。这很容易，你知道这一点比任何人都清楚，很容易在服务和模型上启动一个概念验证，很容易开始进行提示并获取更多模型。但要创建一个真正的用例，要创建一个完整的场景，你需要的东西远不止这些。你需要开始谈论基础，安全性，以及像服务集成、插件等许多其他领域，这些虽然与模型相关，但同样重要。然后，在这之上，你还有更多的层次。你有责任，这是至关重要的。你有应用，你有分发。'
- en: In the case of Azure OpenAI, I think the key thing, of course it’s a critical
    piece of that full stack. But in our case, the principle that we have from the
    very beginning since we started with AI, is that we believe in a speed of innovation
    that goes side by side with the platform. Even internally in Microsoft, the way
    that we look at innovation is providing that innovation as a platform to the rest
    of the company. Then at the same time, we bring that platform to Azure so our
    customers can use it. So Azure OpenAI is a perfect example of that because what
    we did was create the concept of model as a service, making it super easy to be
    accessible from customers, and making it like a first-class citizen of Azure.
    You access it just like any other service, which is again, bringing that to the
    broader platform for developers to create new applications with it.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在Azure OpenAI的情况下，我认为关键之处，当然它是整个技术栈中不可或缺的一部分。但在我们的情况下，从我们开始使用AI的那一刻起，我们就坚持的一个原则是，我们相信创新的速度应该与平台并驾齐驱。即使在微软内部，我们看待创新的方式也是将这种创新作为平台提供给公司的其他部分。同时，我们将这个平台带到Azure，让我们的客户能够使用它。因此，Azure
    OpenAI是这一点的完美例证，因为我们所做的是创造了“模型即服务”的概念，使得它对客户来说变得极其容易访问，并且让它成为Azure的第一公民。你可以像访问任何其他服务一样访问它，这再次将这一点带到了更广泛的平台，让开发者能够用它来创建新的应用程序。
- en: '**A.G.**: Yes. With all these layers that you have mentioned from the platform,
    that’s why I was asking the question, because usually the discussion is around
    the model. We are creating a bigger model and this is, before it was like more
    parameters, now it’s the one that is better on the benchmark. But I think the
    models are becoming a commodity, very expensive and difficult to create. But now
    the value, the real value is in the combination of these models with the rest
    of the platform. That’s what I have liked the most from the evolution of Azure
    OpenAI and Azure AI Studio in general during this 2023-2024 period.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的。你提到的平台上的所有这些层级，这就是我提问的原因，因为通常讨论都是围绕模型进行的。我们正在创建一个更大的模型，在此之前，它更多的是参数更多，而现在它是在基准测试中表现更好的模型。但我认为模型正变成一种商品，非常昂贵且难以创建。但现在，真正的价值在于将这些模型与平台的其他部分相结合。这正是我从Azure
    OpenAI和Azure AI Studio在2023-2024年这一时期的发展中最为欣赏的部分。'
- en: '**D.C.**: Yeah. Completely agree.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**D.C.**: 是的。完全同意。'
- en: '**A.G.:** You have a general view of everything that’s happening at Microsoft,
    like internally, externally, like platforms, models, cool projects, Microsoft
    research, papers, the new things that are coming. What’s the part that gets you
    most excited? Is this about the large language models, the small language models—do
    you have any preference?'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 你对微软正在发生的一切都有一个全面的了解，无论是内部还是外部，比如平台、模型、酷炫项目、微软研究、论文，以及即将到来的一些新事物。哪一部分让你最兴奋？这是关于大型语言模型还是小型语言模型——你有什么偏好吗？'
- en: '**D.C.:** From the research probably because, of course, in that full stack
    there are things happening on every layer. I’m excited with each of them because
    they are super important. In my heart, I’m a software developer. I’m especially
    passionate about anything that has to do with the platform because it’s what really
    enables developers to create important cool stuff on top of it. I’m a super fan
    of, for example, Azure AI Studio and all the tooling that is there. Anything that
    has to do with the orchestration of the entire lifecycle of models, super big
    fan. In my initial role, I was very focused on how we can transform the development
    process with the cloud. The concept of DevOps, continuous integration, continuous
    deployment, and so on. We released what was at that time called [Visual Studio
    Online (VSO)](https://oreil.ly/IJeOu), now it’s Azure DevOps. I think that we
    always forget that part of the stack and it is hugely important. There’s no way
    that you can be successful in an enterprise adopting AI if you just take a very
    specific tooling and model approach, so you need to look at the entire lifecycle,
    and orchestrate that lifecycle. That, I’m super passionate about.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**D.C.**: 从研究的角度来看，可能是因为，当然，在全栈中，每一层都在发生着事情。我对每一层都感到兴奋，因为它们都非常重要。在我心中，我是一个软件开发者。我对与平台相关的一切都特别热情，因为它真正使开发者能够在其上创建重要的酷炫东西。我是Azure
    AI Studio和那里所有工具的超级粉丝。任何与模型整个生命周期编排相关的东西，我都是超级粉丝。在我最初的职位上，我非常专注于我们如何利用云来改变开发过程。DevOps的概念，持续集成，持续部署等等。我们发布了当时被称为[Visual
    Studio Online (VSO)](https://oreil.ly/IJeOu)，现在它是Azure DevOps。我认为我们总是忘记这部分栈，它非常重要。如果你只是采用非常具体的工具和模型方法来采用AI，那么你不可能在企业中取得成功，所以你需要查看整个生命周期，并编排这个生命周期。这一点，我非常热情。'
- en: But now, if you ask me about the wow stuff, the things that are coming from
    research that gets me excited, I have to say that, probably because of my current
    job, I’m a huge fan of all the work coming on applying AI to science. There are
    things in there that are just mind-blowing, that we’re just scratching the surface
    of right now. One example that we recently announced was the application of some
    of these models to an actual scientific discovery. In this case, it was a battery
    discovery, the rest of the material to create a battery. It was discovered fully
    with these tools. They are the three things that these models can do, but in a
    sense, at the core of it the concept is as simple as saying, hey, just like AI
    can reason on top of text, just like AI can reason on top of images, video, and
    so on, AI can also reason on top of graphs. A very important graph that is all
    around us is molecules. They are just graphs of atoms. The possibility of AI to
    reason on top of those structures, on top of molecules, is just amazing. We see
    the same concept that we see with generative AI apply for images. Think of DALL·E
    when you write a prompt and the model will deliver an image like an output. We’re
    starting to see that and Microsoft Research has already delivered some of those
    externally on models that can do that with molecules. Think of explaining the
    model, what are the properties that you are looking for in a particular model,
    and the model creating a lot of variance and a lot of possibilities for that molecule.
    That is mind-blowing, think of the possibilities of that.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 但现在，如果你问我关于令人惊叹的东西，那些让我兴奋的研究成果，我必须说我，可能是因为我的当前工作，我对将AI应用于科学的所有工作都是一个大粉丝。其中有些东西令人震惊，我们现在只是触及了表面。我们最近宣布的一个例子是将这些模型应用于实际的科学发现。在这种情况下，这是一项电池发现，其余的材料来制造电池。它是完全使用这些工具发现的。它们是这些模型可以做的三件事，但在某种程度上，其核心概念就像说，嘿，就像AI可以在文本之上进行推理，就像AI可以在图像、视频等之上进行推理一样，AI也可以在图之上进行推理。一个非常重要的图就在我们周围，那就是分子。它们只是原子的图。AI在那些结构、分子之上进行推理的可能性是令人惊叹的。我们看到与生成AI相同的理念也适用于图像。想想当你写一个提示时，模型会提供一个图像作为输出。DALL·E。我们现在开始看到这一点，微软研究院已经在一些模型上实现了这一点，这些模型可以用分子做到这一点。想想解释模型，你在特定的模型中寻找哪些特性，模型为该分子创造了很多变化和可能性。这是令人震惊的，想想这个的可能性。
- en: But then, that is the generation part. Then the second part is the simulation.
    With AI, we can simulate the properties and the interactions of these molecules,
    which are, imagine the equivalent of that could be to go to a “wet lab” and do
    that in person. Now, if you are able to do it with AI, accelerating thousands
    of times, the time that was needed on traditional compute, what that allows you
    is to just expand your search space. Now, you can screen millions of molecules
    to find those properties. Then the last one is also helping us to synthesize those
    molecules, giving us the best and more efficient ways of synthesizing those molecules.
    The implications of that in any science—so from materials to health, to sustainability,
    to climate change, to many other domains—is just amazing. When you combine it
    with the concept of reasoning on top of knowledge, now you have on one side AI
    models that can simulate nature. On the other side, you have the concept of a
    copilot for the scientists, where the scientists can use it to reason with all
    the past scientific knowledge and all the current knowledge of that domain. It’s
    just mind-blowing the possibilities of it.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 但那部分是关于生成的。接下来的一部分是模拟。有了AI，我们可以模拟这些分子的特性和相互作用，想象一下，这相当于亲自去“湿实验室”进行操作。现在，如果你能通过AI做到这一点，加速数千倍，那么在传统计算上所需的时间，这让你能够只是扩展你的搜索空间。现在，你可以筛选数百万种分子以找到那些特性。最后一点是帮助我们合成这些分子，给我们提供合成这些分子的最佳和更有效的方法。这在任何科学领域中的影响——从材料到健康，到可持续性，到气候变化，到许多其他领域——都是令人惊叹的。当你结合知识推理的概念时，现在你有一边是能够模拟自然的AI模型。另一方面，你有科学家的共飞行员概念，科学家可以使用它来与所有过去的科学知识和该领域的当前知识进行推理。它的可能性令人震惊。
- en: '**A.G.**: It’s impressive, the impact at all levels, even the academic level.
    People that are learning can retrieve all the information, and they can accelerate
    their learning, and they can contribute more and more to the research. You see,
    that’s why I invited you, because you have the vision of these kinds of things.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 这很令人印象深刻，影响到了所有层面，甚至学术层面。正在学习的人可以检索到所有信息，他们可以加速他们的学习，并且他们可以越来越多地贡献于研究。你看，这就是为什么我邀请你的原因，因为你对这些事情有远见。'
- en: '**D.C.:** It’s funny because I think what we always talk about, the work that
    AI can do on behalf of humans, but with this concept of AI reasoning on top of
    the collective knowledge of the scientific community, what it can do is actually
    bring in that community even closer, because right now there’s a big barrier for
    scientists to reason on top of the knowledge that was created by other scientists,
    because there’s so much. It’s almost impossible for a scientist to be on top of
    all the collective knowledge of the community. Now, with these tools, it will
    make it easier for scientists to build on top of the discoveries and the progress
    of others, which is amazing.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**D.C.:** 这很有趣，因为我们总是谈论人工智能代表人类所能做的工作，但有了在科学界集体知识之上的AI推理这一概念，它实际上可以使这个社区更加紧密，因为现在科学家在基于其他科学家创造的知识进行推理时面临很大的障碍，因为知识太多了。几乎不可能让一个科学家掌握社区的集体知识。现在，有了这些工具，它将使科学家更容易建立在他人发现和进步的基础上，这真是太神奇了。'
- en: '**A.G.**: To finish the discussion, I’ll come back to your book, *The AI Organization*.
    Students are wondering OK, is this relevant? Descriptive AI, like traditional
    AI, do I need to learn this when I’m talking about generative AI? Now we have
    so many new experts talking about the topic. I said, yes, of course, the kind
    of consideration, the technical consideration, but also organizational considerations
    of adoption and the barriers and the tricks and the things that you need to do
    and the data component, the data strategy of the companies, this is very important.
    And I feel like your book includes a lot of good examples. I remember the one
    with Telefonica and Chema, Alonso, that I like especially because it’s very illustrative
    and very creative. But what would be, if you had to sell the value of that book
    for the generative AI adopters at the company level, what would be the value of
    it?'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 为了结束这次讨论，我会回到你的书，*《人工智能组织》*。学生们在思考，好吧，这和我们有关系吗？描述性人工智能，就像传统人工智能一样，当我谈论生成性人工智能时，我需要学习这些吗？现在我们有很多新的专家在谈论这个话题。我说，当然，这种考虑，技术考虑，但还有组织上的考虑，包括采用的障碍、技巧以及你需要做的事情，还有公司的数据组件，数据战略，这些都非常重要。我感觉你的书包含了很多很好的例子。我记得Telefonica和Chema，Alonso的那个例子，我特别喜欢，因为它非常具有说明性和创造性。但如果你要向公司层面的生成性人工智能采用者推销这本书的价值，它的价值会是什么？'
- en: '**D.C.:** Yeah, I mean, the book was written just thinking of the learnings
    that I was seeing with big companies embracing AI, right? So, I’ve seen many of
    those in the early days, right? So, early days in AI are like eight years ago.
    So not a long time ago. And it’s funny because usually the blockers that I was
    seeing for adopting AI at scale had nothing to do with technology. So that made
    me wonder, hey, there’s a lot of books talking about the technology, but there’s
    a gap in there on telling the broader story that leaders in organizations of any
    level should know to be successful with AI. So that was the approach to the book.
    I identify four big areas that you need to address to be successful in adopting
    AI at scale. So again, not proof of concept, not specific use cases, but really
    transforming your company with AI, right? And becoming that concept of AI organization.
    And it’s, yeah, technology is one of them. So, of course, it’s there and I talk
    a lot about technology, but I talk about the strategy. You need to have a full
    comprehensive strategy that is inclusive of the short term, but also the long
    term and connecting between those two, right? So I share the learnings in Microsoft
    as well. How we approach that, we call it the horizon framework and how we actually
    make sure that we balance those investments across the horizon. We have a connected
    strategy that is investing in the short term because it has value for the short
    term, but also in the long term and how to connect both, right? So that is good.
    I also talk about the importance of having an approach that is from the technology
    to the business, but then also from the business to the technology, right? That
    is critical. I see, and I was seeing at that time, a lot of conversations that
    started on the possibilities of the technologies, but not what the business needed,
    right? So you need a framework. And I also share the framework that we use in
    Microsoft to have a conversation that is business centric. And then connecting
    that to the technology to focus on identifying the use cases and the long-term
    bets in my company. So that’s the strategy.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '**D.C.:** 是的，我的意思是，这本书是想着那些我看到的，大型公司拥抱人工智能时的学习经验而写的，对吧？所以，我在早期就看到了很多这样的例子，对吧？所以，人工智能的早期阶段就像是在八年前。所以并不是很久以前。而且很有趣，因为我看到阻碍大规模采用人工智能的因素与技术无关。所以这让我想，嘿，有很多书在谈论技术，但在这其中有一个缺口，就是没有讲述一个更广泛的故事，这是任何级别的组织领导者为了在人工智能方面取得成功而应该知道的。所以这就是这本书的写作方法。我确定了四个你需要解决的大领域，才能在规模化的采用人工智能方面取得成功。所以，再次强调，不是概念验证，也不是具体用例，而是真正用人工智能来转型你的公司，对吧？并成为那个人工智能组织的概念。是的，技术是其中之一。所以，当然，技术是存在的，我谈了很多关于技术的事情，但我还谈到了策略。你需要有一个全面综合的策略，它包括短期，但也包括长期，并且在这两者之间建立联系，对吧？所以我分享了在微软的所学。我们如何处理这个问题，我们称之为“地平线框架”，以及我们如何确保我们在地平线上平衡这些投资。我们有一个连接性的策略，它投资于短期，因为这对短期有价值，但也投资于长期，以及如何将两者联系起来，对吧？所以这是好的。我还谈到了有一个从技术到业务，然后从业务到技术的方法的必要性，对吧？这是至关重要的。我看到，当时我看到很多对话都是从技术的可能性开始的，但没有考虑到业务需求，对吧？所以你需要一个框架。我还分享了我们在微软使用的框架，以进行以业务为中心的对话，并将其与技术联系起来，以专注于识别我公司的用例和长期赌注。所以这就是策略。'
- en: The second one is culture because that’s another critical one. This AI transformation
    is not something that happens in a laboratory. It’s not that you can create a
    center of excellence of AI and consider it like a black box and forget about this
    problem. This is something that will impact, as a leader, you need to know that
    this is something that will impact the entire organization. So every employee
    has to be part of it. And that’s something that requires specific action and need.
    And I also share ways of doing that, some learnings from Microsoft. We have a
    lot of learnings on that one. And you realize how important it is if you compare
    failures with successes, you see that culture is usually a huge part of that.
    When you have the organization not fully bought in, where you have things that
    are isolated, that are not connected, it’s very difficult to have an impact in
    the business by doing that. And then the last one is responsibility. So that is
    a critical one, as you know. And it’s something that we tend to think that it’s
    just creating principles for AI. It’s far more than that, right? You need to turn
    those principles into reality. And now even more as at that time, there was no
    regulation, but now with regulation coming, it’s not going to be like a good addition.
    It’s going to be absolutely critical that every company does that. And it’s not
    something that you can think of at the end of the process, it’s something that
    you have to consider in every step of your development, from the ideation to the
    development to the deploying and monitoring.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个是文化，因为这也是一个关键因素。这种AI转型不是在实验室里发生的事情。并不是你可以创建一个AI卓越中心，把它当作一个黑盒子，然后忘记这个问题。这是一件会影响整个组织的事情。作为领导者，你需要知道这一点。所以每个员工都必须参与其中。这是一件需要具体行动和需求的事情。我也分享了如何做到这一点，一些来自微软的经验。我们在那方面有很多经验。你意识到这一点有多重要，如果你将失败与成功进行比较，你会发现文化通常是其中的一个巨大部分。当你有一个组织没有完全投入其中，有些事情是孤立的，没有连接起来，通过这种方式很难在业务上产生影响。最后一个是责任。正如你所知，这是一个关键因素。我们倾向于认为这只是为AI制定原则。这远远不止这些，对吧？你需要将这些原则付诸实践。现在甚至比那时更重要，因为那时没有法规，但现在随着法规的出现，它不仅仅是一个好的补充。它将变得绝对关键，每个公司都必须这样做。这不是你可以在过程结束时考虑的事情，这是你在开发的每一步都必须考虑的事情，从构思到开发，再到部署和监控。
- en: '**A.G.**: I totally agree. And look, these four pillars are exactly the same
    today. We have the same kind of cases, people get excited about technology, then
    forget the overall strategy of the company, creating a case that has nothing to
    do with the strategy of the company, or the return investment, or the potential
    value for the company. The culture, all the education parts, now it’s becoming
    more obvious that people need to learn about genetic AI, and we see that trend
    beside the technology teams. And the responsible AI part, which is, I call it
    accountability. It’s not AI at this point, because it’s accountable. It’s trustworthy,
    it’s responsible, it’s ethical, everything you want, but there’s a regulation.
    So now we want to be compliant with regulations. So it’s still the same. And that’s
    why I think that it’s still a very good classic for any generative AI adopter
    out there.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 我完全同意。看，这四个支柱今天仍然完全相同。我们面临的是同样的情况，人们对技术感到兴奋，然后忘记了公司的整体战略，创造出与公司战略、回报投资或公司潜在价值无关的案例。文化，所有的教育部分，现在越来越明显，人们需要了解基因人工智能，我们看到这一趋势在技术团队旁边。至于负责任的AI部分，我称之为问责制。现在这还不是AI，因为它是有责任的。它是值得信赖的，是负责任的，是道德的，是一切你想要的，但有一个法规。所以现在我们希望遵守法规。所以它还是一样的。这就是为什么我认为它仍然是对任何生成式AI采用者来说非常好的经典。'
- en: 'Brendan Burns: The Role of Cloud Native for Generative AI Developments'
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 布伦丹·伯恩斯：云原生在生成式AI开发中的作用
- en: '**A.G.**: I’m very happy to have you here. I know that a lot of people know
    you, but what’s your current role and journey at Microsoft?'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 我很高兴你能来。我知道很多人都知道你，但你在微软的当前角色和经历是什么？'
- en: '![](assets/aoas_07in02.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_07in02.png)'
- en: '**B.B.**: Sure. I’m currently the corporate vice president for cloud native
    open source and the Azure Management platform. So that’s a focus on, I guess the
    best summary is maybe all things DevOps and modern application development on
    Azure, with a special focus on containers and Linux.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '**B.B.**: 当然。我目前是云原生开源和Azure管理平台的副总裁。所以重点是，我想最好的总结可能是所有关于Azure上的DevOps和现代应用开发的事情，特别关注容器和Linux。'
- en: '**A.G.**: So everything related to cloud native and the Microsoft ecosystem,
    you’re there.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 所以与云原生和微软生态系统相关的一切，你都在那里。'
- en: '**B.B.**: Yep. As well as the Azure Resource Manager, which is sort of the
    API gateway with policy, and all sort of infrastructure as code tooling.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '**B.B.**: 是的。还有 Azure 资源管理器，它有点像带策略的 API 网关，以及所有基础设施即代码的工具。'
- en: '**A.G.**: Very important for the kind of architecture we discuss in the book.
    And even if it’s an obvious question, what’s your experience in cloud native and
    Kubernetes?'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 对于我们在书中讨论的那种架构来说非常重要。即使这是一个明显的问题，你在云原生和 Kubernetes 方面的经验是什么？'
- en: '**B.B.**: Sure, yeah. So I mean, obviously I started the Kubernetes project.
    It’s closing in on a decade actually, which is kind of, I guess, why there’s some
    gray hair, but, you know, I was responsible for the early days of that project,
    shaping, helping shape the community. And then I came to Azure and focused on
    really figuring out how Azure can be the best place to run open source and cloud
    native workloads. And as part of that also, I think helping a lot of enterprises,
    traditional Microsoft customers with their transition to cloud native applications.
    I think there’s a sense that cloud native is like a new startup thing, but actually
    the truth is that I think most of the cloud native applications that are being
    built today are being built by large companies that need this kind of development
    agility and reliability for their applications.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**B.B.**: 当然，是的。我的意思是，显然我是开始 Kubernetes 项目的。实际上，这已经接近十年了，这也是为什么我可能会有一些白发的原因，但你知道，我负责了那个项目的早期阶段，塑造并帮助塑造了社区。然后我来到了
    Azure，专注于真正弄清楚 Azure 如何成为运行开源和云原生工作负载的最佳场所。作为那部分工作的一部分，我也认为帮助了许多企业，传统的微软客户，他们在向云原生应用程序的过渡中。我认为云原生就像是一个新的初创企业事物，但实际上，我认为今天正在构建的大多数云原生应用程序都是由需要这种开发敏捷性和可靠性的大型公司构建的。'
- en: '**A.G.**: Yeah, which is connected to the current era of generative AI here
    at Microsoft. What’s your personal point of view on this new wave?'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的，这与微软当前的时代生成式 AI 相关联。你对这场新潮流的个人观点是什么？'
- en: '**B.B.**: Well, I’m super excited about it. I think everybody’s excited about
    it. I’m really excited about it at a personal level, because it’s actually helped
    me. I think using things like GitHub Copilot actually really does speed up, especially
    when I’m learning something new. I was just learning Rust over maybe six months
    ago. And I found that when you’re in a new language, it just made a huge difference
    in the speed with which I could pick up the idioms. And you think, because sometimes,
    when you’re learning a new language, you’re programming it like the other language.
    So you end up writing Python, like you used to write Java, for example. I think
    having access to those idiomatic patterns helps you become fluent in the language
    a lot faster. Plus I found Rust also is a little bit, the error messages are not
    as good as they could be, I think. And so again, having that ability to be like,
    please fix this error message for me, right? It would just give me the code snippet
    that I needed. And that was pretty useful as well. So I think that’s cool.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '**B.B.**: 嗯，我对这个非常兴奋。我认为每个人都对此感到兴奋。我在个人层面上也非常兴奋，因为这实际上帮助了我。我认为使用 GitHub Copilot
    这样的工具实际上确实可以加快速度，尤其是在我学习新事物的时候。我大概在六个月前开始学习 Rust。我发现当你处于一种新的语言中时，它对提高你掌握惯用模式的速度产生了巨大的影响。你可能会想，因为有时候，当你学习一种新语言时，你会像编程其他语言一样编程。所以你最终会像以前写
    Java 一样写 Python，例如。我认为能够访问那些惯用模式有助于你更快地掌握语言。此外，我发现 Rust 的错误信息也不如它们本可以那么好，我认为。所以再次，有那种请为我修复这个错误信息的能力，对吧？它会给我我需要的代码片段。这也很有用。所以我认为这很酷。'
- en: I think it’s really exciting also how we can help our customers have similar
    reductions in complexity, whether it’s for programming languages, or their infrastructure,
    or you know, any number of things. Becoming cloud native is a good example, actually,
    infrastructure as code (IaC) can be hard for people and enabling people to transition
    from, you know, ClickOps in the portal to infrastructure as code easily is really
    great. And things like mechanical export of an infrastructure as code template
    hasn’t always been that great. And I think generative AI gives us the opportunity
    to go in a different direction and get better, more fluid templates than we do
    if we just, you know, sort of write code that tries to do it.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为我们也非常兴奋地看到我们如何帮助客户在编程语言、基础设施或任何其他众多事物上实现类似的复杂性降低。成为云原生是一个很好的例子，实际上，基础设施即代码
    (IaC) 对人们来说可能很难，而使人们能够轻松地从门户中的 ClickOps 过渡到基础设施即代码是非常棒的。而像基础设施即代码模板的机械导出这类事情并不总是那么好。我认为生成式
    AI 给我们提供了走不同方向并做得更好、更流畅模板的机会，如果我们只是写一些试图完成这个任务的代码，我们可能做不到。
- en: '**A.G.**: Yeah, and I think it’s exciting because it goes both ways, no? We
    can leverage generative AI for all cloud native purposes. And we can leverage
    the good practices of cloud native to implement generative AI on existing and
    new applications.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的，我认为这很令人兴奋，因为它是双向的，不是吗？我们可以利用生成式 AI 来实现所有云原生目的。同时，我们也可以利用云原生的良好实践来在现有和新应用程序上实现生成式
    AI。'
- en: '**B.B.**: Absolutely. Yeah, I mean, it’s interesting to think, right? I mean,
    it sounds sort of grandiose to claim that generative AI wouldn’t exist without
    Kubernetes. But I think actually, it’s kind of true, right? In the sense of not
    like Kubernetes is special, but in the sense of it enabled a lot of people who
    wanted to build large-scale systems to kind of forget about machine management.
    The first step to doing AI inferences is no longer figuring out how to get a bunch
    of machines to work together. Containers and Kubernetes took care of that for
    you. And so you can just say, OK, I’ve got this fleet of machines with GPUs and
    everything else. How do I get my application out there to do the training? And
    I think that that’s the history of computer science in general, building higher
    levels of abstraction to enable the next platform to build on top.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '**B.B.**: 绝对如此。是的，我认为这很有趣，对吧？声称没有 Kubernetes 就不会有生成式 AI，听起来似乎有些夸张。但我想实际上，这倒是真的，对吧？并不是说
    Kubernetes 特别特殊，而是它让很多想要构建大规模系统的人可以不必再考虑机器管理。进行 AI 推理的第一步不再是想方设法让多台机器协同工作。容器和
    Kubernetes 已经为你解决了这个问题。所以你可以说，好吧，我有一支配备了 GPU 等设备的机器群。我该如何将我的应用程序部署出去进行训练呢？我认为这实际上是计算机科学的历史，即构建更高层次的抽象，以使下一个平台能够在其之上构建。'
- en: '**A.G.**: And that’s one of the cases I love the most. If you check the success
    stories at *kubernetes.io* or [CNCF](https://oreil.ly/epXxD), they talk about
    [OpenAI with Cloud Native](https://oreil.ly/b5EfH) and how that was enabling all
    the kinds of things that we have seen, like wider scale, a lot of people can connect
    to ChatGPT. Of course, there is the AI infrastructure from Microsoft behind that.
    But that’s a new enabler for all these areas of applications and the AI compilers.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 这是我最喜欢的一个案例之一。如果你查看 *kubernetes.io* 或 [CNCF](https://oreil.ly/epXxD)
    上的成功故事，他们会谈到 [OpenAI with Cloud Native](https://oreil.ly/b5EfH) 以及它是如何使我们看到的所有这些事物成为可能的，比如更广泛的规模，很多人可以连接到
    ChatGPT。当然，背后还有微软的 AI 基础设施。但这为所有这些应用领域和 AI 编译器提供了一种新的推动力。'
- en: '**B.B.**: Yeah. And a reduction in complexity again, too. So not only can generative
    AI reduce complexity, but having that orchestrator reduces the complexity for
    the AI engineers who just don’t need to worry about that problem. And then when
    you get it from Azure, you don’t even have to worry about running it. It just
    takes care of it for you.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**B.B.**: 是的。再次提到复杂性降低的问题。所以，生成式 AI 不仅能够降低复杂性，而且拥有那个编排器还可以降低 AI 工程师们的复杂性，他们不必担心这个问题。而且当你从
    Azure 获取它时，你甚至不必担心运行它。它只是为你处理这一切。'
- en: '**A.G.**: Saving a lot of people like me.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 为像我这样的人节省了很多时间。'
- en: '**B.B.**: I think it’s also always the goal, right? It’s much easier to consume
    the idea than it is to implement the idea. You can say, OK I know how to use a
    sorting algorithm. You can probably write a sorting algorithm, but it’s going
    to take you a lot more time to write it than it is to use it. It empowers a lot
    of people, which is great.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**B.B.**: 我认为这也是一个目标，对吧？消费一个想法比实施一个想法要容易得多。你可以这么说，好吧，我知道如何使用排序算法。你可能能写出排序算法，但写它的时间要比使用它的时间多得多。这赋予了许多人力量，这是很棒的。'
- en: '**A.G.**: Yeah. And accelerates the implementation, something that would take
    so long before now is becoming like a, I wouldn’t say commodity, but certainly
    like something easier to implement.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的。它加速了实施，以前需要花费很长时间才能完成的事情现在变得更容易实现。'
- en: '**B.B.**: Yeah. And I think you’ll see, I think you see that creative explosion
    then afterwards, where a lot of people who maybe wouldn’t have the patience or
    the skillset to implement generative AI, but they can have really creative ideas
    about how to use it. And so when you make that capability available, you’re going
    to just generate a ton of creativity about how to use it.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**B.B.**: 是的。我想你会看到，我认为你会看到随后发生的创造性爆炸，许多可能没有耐心或技能集来实施生成式AI的人，但他们可以真正有创造性的想法来使用它。所以当你使这种能力可用时，你将仅仅产生大量关于如何使用它的创意。'
- en: '**A.G.**: Certainly. From the cloud native perspective at Microsoft, how do
    you see all this explosion of the [technology stack for Copilot](https://oreil.ly/jGrqE),
    Semantic Kernel, all the different cool pieces that we mention in this book? What’s
    your personal opinion on that?'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 当然。从微软的云原生角度来看，你是如何看待所有这些关于Copilot、语义内核以及我们在本书中提到的所有不同酷炫组件的技术栈爆炸的？你对这些有什么个人看法？'
- en: '**B.B.**: Well, I mean, you still have to run your application somewhere, right?
    You know, you don’t get to, generative AI doesn’t enable you to not have a webpage
    there or not having a Restful API somewhere. And so not only do tools like Azure
    Machine Learning build on top of Azure Kubernetes Service (AKS), but we’re actually
    also seeing a lot of people building, you know, the frontend application or the
    APIs that they need to have, even plug-ins for OpenAI on top of AKS. It’s still
    a really great place to host code and integrate there. And of course, we have
    GPU support in AKS, so there are people who are doing their own inference or building
    their own models. And some of our largest clusters actually are built to do that
    kind of AI for a variety of different groups. And again, I think it’s about simplicity,
    right? Because if you want to focus on AI, you don’t want to focus on what it
    takes to run a 5,000-node Kubernetes cluster. It’s not the easiest thing to do.
    And if you can just click a bunch of buttons or do an infrastructure as code template
    and have 5,000 GPU nodes, that’s pretty good. And then know that my team is on
    call for those. Saves you a lot of time.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**B.B.**: 嗯，我的意思是，你仍然需要在某处运行你的应用程序，对吧？你知道，生成式AI并不能让你不需要网页或者不需要某个地方的Restful
    API。因此，不仅像Azure Machine Learning这样的工具建立在Azure Kubernetes Service (AKS)之上，而且我们实际上还看到很多人在AKS上构建他们需要的客户端应用程序或API，甚至还有OpenAI的插件。它仍然是一个非常好的托管代码和集成的场所。当然，我们在AKS中提供了GPU支持，所以有些人正在自己进行推理或构建自己的模型。实际上，我们最大的集群实际上是为了为各种不同的群体执行这种类型的AI而构建的。再次强调，我认为这是关于简单性，对吧？因为如果你想要专注于AI，你不想专注于运行一个5,000节点Kubernetes集群所需的一切。这不是一件容易的事情。如果你只需点击一些按钮或执行一个基础设施即代码模板，就能拥有5,000个GPU节点，那就相当不错了。然后知道我的团队会随时待命。这可以节省你很多时间。'
- en: '**A.G.**: Yes. And that’s what we’re seeing with Azure AI Studio now, and with
    all these applications and the ability to deploy any kind of model, because the
    book is about Azure OpenAI and a proprietary model. How do you see the role of
    open source as an enabler for generative AI?'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的。这正是我们现在在Azure AI Studio中看到的情况，以及所有这些应用程序和部署任何类型模型的能力，因为这本书是关于Azure
    OpenAI和专有模型的。你是如何看待开源作为生成式AI推动者的角色的？'
- en: '**B.B.**: Yeah. I think, over time, I suspect that there’s going to be more
    and more models that happen, that people tune, that people build for different
    situations. I mean, you’re already seeing that kind of model sharing and model
    retraining happening. I think that’s really great. I think you look at something,
    you know, Semantic Kernel is out in open source sharing our best practices. LangChain
    is out there in open source. I think it’s all rooted in open source. I think also
    one of the things that is going to happen over time, I think will be higher level
    frameworks, too. I think people are still trying to figure out exactly what it
    takes to build a complete copilot. I think there’s a lot of what I would call
    sort of vertical copilots, you know, copilots that are good at one thing. But
    I think there’s value in sort of saying, well, actually, there are some really
    broad areas out there and you may actually want something that knows how to choose
    between copilots. I think of it sort of like search, maybe, right, when you do
    a web search, maps, video? Like there’s a variety of different kinds of content
    you could be searching for. And I think the same thing is going to be true with
    Copilot. There’s going to be multiple levels in terms of choosing what you want
    to generate. I mean, in some sense, it’s like your friends, I guess. Like you
    go to one friend for tech advice, you go to one friend for sports or whatever.
    And you’re going to find the same thing.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**B.B.**: 是的。我认为，随着时间的推移，我怀疑将会出现越来越多的模型，人们会为不同的情况调整、构建。我的意思是，你已经在看到这种模型共享和模型重新训练发生了。我认为这真的很棒。我认为你看某样东西，你知道，Semantic
    Kernel正在开源共享我们的最佳实践。LangChain也在开源中。我认为这一切都根植于开源。我认为随着时间的推移，还将发生一些事情，我认为将会是更高级的框架。我认为人们仍在试图弄清楚构建一个完整的协作者需要什么。我认为有很多我称之为垂直协作者的，你知道，擅长某一件事的协作者。但我认为，实际上，有一些非常广泛的领域，你可能实际上需要一种知道如何选择协作者的东西。我想象它有点像搜索，对吧，当你进行网络搜索时，地图、视频？你可以搜索各种不同类型的内容。我认为Copilot也会是这样。在选择你想要生成的内容方面，将会有多个层次。我的意思是，在某种程度上，它就像你的朋友一样。比如，你去找一个朋友寻求技术建议，你去找一个朋友寻求体育或其他什么。你将会找到同样的事情。'
- en: '**A.G.**: On one side, there are all the building blocks that are being created
    and the orchestrators that you have mentioned, different approaches like retrieval
    (RAG), like the kind of knowledge bases that we can use, that can be databases,
    etc. And I feel like that’s evolving a lot, of course.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 在一方面，有所有正在创建的构建块以及你提到的协调者，不同的方法，比如检索（RAG），比如我们可以使用的知识库，可以是数据库等。我感觉这正在快速发展，当然。'
- en: '**B.B.**: For sure. And I think there’s a little bit of one of the questions
    I’ve had that, you know, I don’t necessarily have the right answer for, which
    is, when do you do retraining versus when do you do retrieval-augmented generation?
    Because they kind of both do the same thing at some level, you can influence what
    your results are either by retraining or retraining on your corpus or by doing
    retrieval-augmented generation. I think questions like that people are going to
    need to struggle with for a while.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**B.B.**: 当然。我认为我有一个问题，你知道，我并不一定有正确的答案，那就是，你什么时候进行重新训练，什么时候进行检索增强生成？因为它们在某种程度上都做同样的事情，你可以通过重新训练或在你自己的语料库上重新训练，或者通过进行检索增强生成来影响你的结果。我认为像这样的问题，人们可能需要一段时间才能解决。'
- en: '**A.G.**: Yes. There’s no single answer for that. In one of the chapters from
    this book, I mention (very carefully as it is such a new topic) that we need to
    try and test depending on the dataset, depending on the kind of retraining, the
    kind of fine-tuning you want to have or the general behavior of the LLM compared
    to the kind of tasks that you’re assigning.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的。对于这个问题没有单一的答案。在这本书的其中一个章节中，我提到（非常谨慎地，因为这个话题非常新）我们需要根据数据集，根据你想要的重新训练类型，你想要的微调类型，或者与分配的任务相比的LLM的一般行为来尝试和测试。'
- en: '**B.B.**: Or even the app. You’re probably not going to be able to retrain
    it for every single customer. You may have to do it because you’re like, well,
    I have such a diverse set of users. I want to provide personalized content for
    each user, but I can’t retrain every user, so I’m going to use retrieval-augmented
    generation. But on the other hand, you can be like, I am my company and it’s worth
    it to retrain because I know my company and I’m only going to have results for
    my company. I think it’s interesting stuff.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**B.B.**: 或者甚至应用。你可能无法为每位客户重新训练它。你可能必须这样做，因为你，嗯，我有一群多样化的用户。我想为每位用户提供个性化的内容，但我无法为每位用户重新训练，所以我将使用检索增强生成。但另一方面，你也可以这样想，我是我的公司，重新训练是值得的，因为我了解我的公司，我只会有针对我公司的结果。我认为这是很有趣的事情。'
- en: '**A.G.:** Right, and maybe it’s a combination with segmentation or a recommender
    system, something that will pre-filter the kind of users you have in front of
    you. And then based on the ability that user may have to access the information,
    the knowledge base based on the active directory or whatever, you can customize
    that answer then.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 对，也许它是与分段或推荐系统的结合，某种预先过滤你面前用户类型的东西。然后根据用户可能访问信息的能力，基于活动目录或任何其他知识库，你可以定制那个答案。'
- en: '**B.B.:** I mean, role-based access control (RBAC) is a fascinating part. We
    have this challenge even in the Azure Resource Graph, which is used for at-scale
    querying. It’s an index of all your Azure resources. Applying access control to
    that is a very interesting problem. Because obviously you can’t build an index
    for each user, right? There’s one index of all the resources. And so then you
    have to basically be like, OK, I did the query. I found some data. Now, which
    of the data that I got back did this user actually have access to or put it into
    the query itself and actually say, as I do my search query, only show me things
    that also this person has access to. And yeah, obviously, it’s important to get
    right.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**B.B.**: 我的意思是，基于角色的访问控制（RBAC）是一个迷人的部分。我们在Azure资源图中也面临这样的挑战，它用于大规模查询。它是所有Azure资源的索引。将访问控制应用于它是一个非常有趣的问题。因为显然你不能为每位用户构建一个索引，对吧？有一个所有资源的索引。然后你必须基本上这样做，好的，我进行了查询。我找到了一些数据。现在，我得到的数据中哪些是这位用户实际上可以访问的，或者将其放入查询本身，并在进行搜索查询时，只显示这位用户也有权限访问的内容。显然，正确地做到这一点非常重要。'
- en: '**A.G.:** Totally. With all this complexity, what would be your recommendation
    in terms of upskilling, for people to follow in this area, like any kind of thing
    that will help learners and readers to keep track of everything that’s going on?'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 完全同意。在这个复杂性中，你对于提升技能有什么建议，对于想要在这个领域跟进的人来说，比如任何有助于学习者读者跟上所有发生事情的东西？'
- en: '**B.B.**: The two things I would say is, I would definitely recommend playing
    around with it. I think the Bing chat is a great way to get in and give it a try,
    because it’s really important, I think, to get a sense for what it’s good at and
    what it’s not good at. Because I think when you see or read the articles or you
    hear, or even when you see examples, they’ve been kind of cherry-picked. They’re
    never going to show you bad examples. And I think it’s really valuable to get
    in there and realize that it’s not perfect. Even beyond the hallucinations, which
    I think people are getting a handle on how to deal with, I think with some questions
    it just isn’t very good. And I think that experiential is the way to go. Give
    yourself a task, try and figure out what the system is good at.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '**B.B.**: 我会说的两件事是，我肯定会推荐尝试一下。我认为Bing聊天是一个很好的入门方式，因为它真的非常重要，我认为，要了解它的优点和缺点。因为我认为当你看到或阅读文章，或者听到，甚至当你看到例子时，它们已经被挑选出来。它们永远不会展示给你不好的例子。我认为真正进入其中并意识到它并不完美是非常有价值的。甚至超出了幻觉，我认为人们正在掌握如何处理它，我认为对于一些问题，它并不是很好。我认为经验是关键。给自己一个任务，尝试找出系统擅长什么。'
- en: In particular, I would say I think it’s really good at summarization in general.
    I found that it’s quite good at taking information and distilling it down. It
    can be good at things like error messages for compilers. It can be really bad
    also sometimes. I think you have to get your own sense of what you think it is
    good at and what you think it’s bad at. Because it will give you a sense of which
    ideas you could use it for. Because you may think, I could use generative AI to
    do this and you’re like, well, in practice, that’s not going to work out very
    well. So that’s part one, and then I think part two is that I’m a big believer
    in getting your hands dirty with a toy project that’s meaningful to you. I do
    a lot of hacking with random stuff in my house to turn on lights or whatever.
    Don’t just go through the toy examples because you don’t have a personal connection.
    And I think that personal connection helps you build. Of course, you can’t build
    the whole app at the start. You need something small and constrained to make sure
    you continue to make progress. I think that’s usually the way I go when I’m learning
    new tech. I really want to get a sense of how it works and how I put a whole piece
    of it together. That skeleton. And then, you know, then you can move on to saying,
    OK, I now have the knowledge to go build the real app that I was thinking about
    building.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是我想说，它在一般意义上的总结方面做得非常好。我发现它在提取信息并提炼信息方面相当出色。它可能在编译器的错误消息等方面做得很好。有时它也可能真的很糟糕。我认为你必须自己判断它擅长什么，不擅长什么。因为这将给你一个感觉，你可以用它来实现哪些想法。因为你可能会想，我可以使用生成式
    AI 来做这件事，但实际上，这可能不会很顺利。所以这是第一部分，然后我认为第二部分是我非常相信通过一个对你有意义的玩具项目来“动手实践”。我在家里用一些随机的东西做很多黑客攻击，比如打开灯之类的。不要只是通过玩具示例，因为你没有个人联系。我认为这种个人联系有助于你构建。当然，你不可能一开始就构建整个应用程序。你需要一个小的、受限制的东西来确保你继续取得进步。我认为我学习新技术时通常就是这样做的。我真的想了解它是如何工作的，以及我是如何把它拼凑在一起的。那个框架。然后，你知道的，然后你可以继续说，好吧，我现在有了知识去构建我真正想要构建的应用程序。
- en: '**A.G.**: I think those two points are very precise on what acquiring the experience
    is like. Of course with Azure OpenAI, but also the different technologies out
    there or the flavors of Azure OpenAI on different products, and what the limitations
    and the advantages are. Because there are very good advantages, but also limitations.
    For example, I was checking something related to finding information related to
    a specific person. Maybe that’s not always the best use case scenario because
    it’s linguistics, you have Adrián González from Microsoft and another Adrián González,
    the baseball player. So, yeah, I totally agree on that.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 我认为这两个点非常精确地描述了获得经验的过程。当然，有 Azure OpenAI，还有那里不同的技术或 Azure OpenAI
    在不同产品上的版本，以及它们的局限性和优势。因为确实有很多优势，但也有局限性。例如，我检查了一些与查找特定人物相关信息的东西。也许这并不总是最好的用例场景，因为它是语言学，你有来自微软的阿德里安·冈萨雷斯（Adrián
    González）和另一位棒球运动员阿德里安·冈萨雷斯（Adrián González）。所以，是的，我完全同意这一点。'
- en: And remind me, you have several O’Reilly books as well, right? You’re in the
    club of authors with several books. Can you tell us a bit about them and what
    they are about?
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒我，你也有几本 O’Reilly 的书，对吧？你是拥有多本书的作者俱乐部的一员。你能告诉我们一些关于它们的内容和它们是关于什么的吗？
- en: '**B.B.**: Well, I’ve written a couple of different books on Kubernetes. [*Kubernetes:
    Up and Running*](https://oreil.ly/NZcsJ), which I wrote with Kelsey Hightower
    and Joe Beda. And then more recently, [the third edition](https://oreil.ly/IvoU6)
    was written with Lachlan Evanson, who’s another person at Microsoft. And then
    actually right now I’m working on the [second edition](https://oreil.ly/7HkaR)
    of [*Designing Distributed Systems*](https://oreil.ly/vbUwd). And it’s actually
    going to go into a little bit, probably not in as much depth as your book, but
    go into a little bit of how to build AI systems in the context of distributed
    systems.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**B.B.**: 嗯，我写过几本关于 Kubernetes 的不同书籍。[《Kubernetes: Up and Running》](https://oreil.ly/NZcsJ)，这本书是我和凯尔西·海托沃（Kelsey
    Hightower）以及乔·贝达（Joe Beda）合著的。然后最近，[第三版](https://oreil.ly/IvoU6) 是和微软的另一位人士拉克兰·埃文森（Lachlan
    Evanson）合著的。实际上，我现在正在编写 [*Designing Distributed Systems*](https://oreil.ly/vbUwd)
    的 [第二版](https://oreil.ly/7HkaR)。它实际上会涉及到一些内容，可能不会像你的书那样深入，但会涉及到如何在分布式系统的背景下构建
    AI 系统。'
- en: And then actually the most exciting chapter that I’m adding there for the second
    edition is what I’m going to call the greatest hits chapter, which is all of the
    problems that people had, which discusses all of the mistakes that people make
    that keep coming up over and over again. Because we go to live sites and you sit
    through outages and postmortems and all this kind of stuff. And after you do it
    for a few years you see that there are patterns that repeat. And I’ve been taking
    some notes and I’ve written down a bunch of the ones that repeat over and over
    again. For example, one of the ones that comes up a lot is our monitoring didn’t
    think that the absence of errors should be an error. If there were a lot of errors
    you’d notice. But if it goes absolutely quiet and there’s nothing, it could mean
    you’re totally OK, but it could also mean that you’re not processing anything.
    And several times we’ve seen systems where they have a monitoring gap, where for
    some reason they stopped processing anything. With this idea that no news was
    treated as good news, they didn’t alert anybody until a customer was like, hey,
    wait a minute, where are my deliveries? You could be monitoring delivery lanes,
    anything like that in terms of an online retailer, right? An online retailer could
    monitor how long it takes a package to get from point A to point B from my delivery
    center to the customer. And they could alert if that goes over 12 hours or whatever.
    But if you stop delivering all packages, that alert does not fire. Because there’s
    no deliveries, it didn’t take any time. It’s subtleties like that and it doesn’t
    occur to you in the first place because you’re so used to the steady state.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，实际上我为第二版添加的最激动人心的章节，我将称之为“经典之作”章节，其中包含了人们遇到的所有问题，讨论了人们反复犯的错误。因为我们去现场，你会在故障和事后分析中度过时间，以及所有这类事情。在你做了几年之后，你会发现有一些模式是重复出现的。我已经做了一些笔记，并记下了那些反复出现的许多问题。例如，其中一个经常出现的问题是我们的监控没有意识到错误的缺失应该被视为一个错误。如果有大量的错误，你会注意到。但是，如果它完全安静下来，什么都没有，这可能意味着你完全正常，但也可能意味着你没有处理任何东西。我们曾多次看到系统存在监控缺口，由于某种原因，它们停止了处理任何东西。这种“没有消息就是好消息”的想法，他们直到客户说，嘿，等一下，我的货物在哪里？你可以在在线零售商的交付通道上进行监控，任何类似的事情，对吧？在线零售商可以监控包裹从我的配送中心到客户点A到点B需要多长时间。如果超过12小时或
    whatever，他们可以发出警报。但是，如果你停止交付所有包裹，这个警报就不会触发。因为没有交付，所以没有花费时间。这样的细微差别，你一开始可能不会想到，因为你已经习惯了稳定状态。
- en: '**A.G.**: I think that applies to what we’ll see in future editions of this
    book. Like the kind of learnings from the industry, the kind of things we don’t
    know because we don’t know it yet. It will be based on experience. We are just
    starting this wave for generative AI, but certainly the same case here.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 我认为这适用于我们将在本书的未来版本中看到的内容。就像从行业中获得的那些学习经验，以及我们不知道的事情，因为我们还没有意识到。它将基于经验。我们刚刚开始这股生成式AI的浪潮，但在这里情况肯定是一样的。'
- en: '**B.B.**: Yeah. Oh, yeah. I imagine it’s going to change rapidly, actually,
    as more and more people get in there. The first couple of years when people got
    in, the same thing happened with cloud native open source, right? Even with UI
    frameworks. I think mostly people use React now, but like there was a solid two
    or three years where I felt like people were changing every three months. It seemed
    like every time I talked to somebody, they’d switch their JavaScript framework.
    I’m sure the same thing will happen with AI, right? Because I think it takes a
    little bit for people to figure out what abstractions actually work. What are
    the abstractions that make sense? What are the common problems that we can turn
    into libraries? I think there’s a lot of free-form prompt engineering happening
    right now. I think there’s going to be a lot more science that comes into that.
    And I don’t know if science is the right word, but a lot more like rigor that
    comes into that kind of stuff over time as people figure out kind of what works
    and what doesn’t work. The templates, operations, the best practices, the countermeasures.
    I think at some point you’ll probably just be able to hit a checkbox and get a
    bunch of the fixes and all that kind of stuff, hallucination prevention and stuff
    like that.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**B.B.**: 是的。哦，是的。我想随着越来越多的人加入其中，这实际上会变化得非常快。前几年，当人们刚开始加入时，云原生开源的情况也是这样，对吧？甚至包括UI框架。我认为现在大多数人都在使用React，但就像曾经有一段时间，我觉得人们每三个月就会更换一次JavaScript框架。每次我与人交谈时，他们似乎都会切换他们的JavaScript框架。我确信这种情况也会发生在AI上，因为我认为人们需要一点时间去弄清楚哪些抽象实际上有效。哪些抽象是有意义的？哪些是我们可以将其转化为库的常见问题？我认为现在正在进行大量的自由形式提示工程。我认为将来会有更多的科学进入这个领域。我不知道“科学”这个词是否恰当，但随着人们弄清楚哪些有效哪些无效，会有更多类似严谨的东西进入这个领域。模板、操作、最佳实践、对策。我认为在某个时候，你可能只需勾选一个复选框，就能得到一大堆修复和类似的东西，幻觉预防等。'
- en: '**A.G.**: Hey, just a last question, because you mentioned the postmortem,
    but there’s something we mentioned in the book, which is the premortem. Did you
    use the notion of a premortem to see what could go wrong?'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 嘿，就剩最后一个问题了，因为你提到了尸检，但我们书中还提到了一个概念，那就是生前检查。你有没有使用生前检查的概念来预想可能会出错的地方？'
- en: '**B.B.:** Yeah, it’s sort of like what we call red teaming as well, where you’re
    trying to break that, you know, you’re purposely trying to break stuff. And yeah,
    I think that’s really important. I think you check both bad stuff, obviously,
    like there’s been stuff in the press and otherwise about, you know, ways you can
    trick these models, but also honestly, just to see if it does a good job. I think
    it’s more prosaic. You know, nobody writes a headline about something that they’re
    like, this query was not answered very well. But obviously, if you’re building
    a product, that’s really important to understand: does it actually work? And I
    think actually measuring, that’s the other thing I think is going to be really
    interesting. And a lot of growth is happening. It’s like measuring the quality
    of a model. I don’t think we’ve done a ton of rigorous scientific measurement.
    I mean, there are scoreboards and things like that to measure against benchmarks
    but it’s not clear that’s 100 percent connected to the reality of a user experience
    once you build it into a product. And I think just as we’ve done a lot of work,
    you know, in the Azure portal and things like that on figuring out, where we are
    confusing the user? You know, where do we have a UI that’s not great? I think
    we’re going to do the same thing with these chat systems, right, where it’s probably
    going to be, how many times did people click on the prompts we suggested or how
    many times did they hit the clear button or, you know, there’s a lot of ways you
    can figure out, are we giving them the answers that they want?'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**B.B.**: 是的，这有点像我们所说的“红队”行动，你试图打破它，你知道，你是有意尝试破坏东西的。是的，我认为这非常重要。我认为你检查了坏的东西，显然，媒体上和其它地方都有关于如何欺骗这些模型的方法，但老实说，只是为了看看它是否做得好。我认为这更实际。你知道，没有人会写一个标题说，这个查询回答得不好。但显然，如果你在构建一个产品，真正重要的是要理解：它实际上是否有效？我认为实际测量也是另一件非常有趣的事情。我认为我们在这方面还没有做很多严格的科学测量。我的意思是，有一些排行榜和类似的东西可以用来与基准进行比较，但一旦你将其集成到产品中，这并不一定与用户体验的现实情况100%相关。我认为我们就像在Azure门户等地方做的大量工作一样，去弄清楚，我们在哪里让用户感到困惑？你知道，我们的UI哪里不好？我认为我们也会对聊天系统做同样的事情，对吧，可能就是，人们点击我们建议的提示有多少次，或者他们按了多少次清除按钮，或者，你知道，有很多方法可以找出，我们是否提供了他们想要的答案？'
- en: '**A.G.**: Totally, because right now with the benchmarks and the evals type
    of projects on LangChain and Azure AI Studio, we are focusing on the core model
    parts. But then you are mentioning all the quantitative and qualitative measures
    that we usually do in product analytics, for example. That’s something I mention
    in the book. You’ll see it in some of the chapters because obviously that part
    will evolve a lot, but getting the sense of the metrics, how good or bad you are
    doing from a user perspective, is crucial. I think that would also be very useful
    for companies.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 完全同意，因为目前我们在LangChain和Azure AI Studio上的基准和评估类型的项目中，主要关注核心模型部分。但您提到的所有定量和定性指标，我们通常在产品分析中都会用到，例如。这一点我在书中也提到了。您会在一些章节中看到它，因为显然这部分会有很多变化，但了解这些指标，从用户的角度来看，你做得好还是不好，这是至关重要的。我认为这对公司也会非常有用。'
- en: '**B.B.**: For sure. Yeah, absolutely. I think that it’s in its infancy right
    now. It’s going to be really interesting to see how we figure that out. So I also
    am pretty excited. Microsoft is also really big into accessibility and computing
    for all. And I think that it’s also going to be a game changer in terms of usability,
    because we see people with challenges and we do a lot of work in our UX for accessibility,
    but I think a chat or a voice-based UX that is actually empowered by generative
    language could be significantly better than what we provide with a mouse-based
    or sound-based UI.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**B.B.**: 当然。是的，绝对如此。我认为它目前还处于初级阶段。看到我们如何解决这个问题将非常有趣。所以我也是非常兴奋的。微软也非常重视可访问性和面向所有人的计算。我认为这也会在可用性方面带来变革，因为我们看到人们面临挑战，我们在我们的UX可访问性方面做了很多工作，但我认为由生成语言支持的聊天或基于语音的UX可能会比我们用鼠标或声音UI提供的要好得多。'
- en: '**A.G.**: I’m loving this case with the Portuguese government [creating an
    avatar](https://oreil.ly/jMgb6) for people who cannot write and then you have
    another for people who can write but cannot talk. I think that’s where we are
    leading to. We’re saying that this generative AI is equivalent to what the visual
    interface was to command lines. And I believe that’s kind of true.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 我非常喜欢这个葡萄牙政府的案例，[为不能写字的人创建一个头像](https://oreil.ly/jMgb6)，然后你还有一个为能写字但不能说话的人准备的。我认为这就是我们正在走向的方向。我们说这种生成式AI相当于视觉界面与命令行之间的关系。我相信这是真的。'
- en: '**B.B.**: Yeah, I think it’s going to be really exciting to see how it transforms
    things. And it’s fun to be a part of it. I guess that’s why we’re always here.
    It’s fun to be involved in the transformation as well.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**B.B.**: 是的，我认为看到它如何改变事物将会非常激动人心。参与其中也很有趣。我想这就是我们一直在这里的原因。参与变革也很有趣。'
- en: 'John Maeda: About AI Design and Orchestration'
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 约翰·梅达：关于AI设计和编排
- en: '**A.G.**: I know you very well just because I’m some sort of groupie of what
    you are doing with your learning resources, but let’s learn a little bit about
    who John is and what your role at Microsoft is as well as your previous background.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 我非常了解你，只是因为我某种程度上是你的粉丝，因为我喜欢你所做的学习资源。但让我们了解一下约翰是谁，以及你在微软的角色以及你的背景。'
- en: '![](assets/aoas_07in03.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_07in03.png)'
- en: '**J.M.**: I’m lucky to get to work in the middle of the AI Superstorm and there
    is a project called Semantic Kernel that I am helping to advance. It’s a way to
    enable more enterprises to take advantage of this new kind of AI. Before that,
    I was in the physical security industry. I was a chief technology officer of a
    mid-cap security company called Everbridge. We took care of the world, countries,
    cities, and corporations. Before that I worked in places like venture capitals.
    I was at MIT for a while and did research and I also worked in a late-stage startup
    to really understand where the world is heading.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '**J.M.**: 我很幸运能参与到AI超级风暴的中心，有一个名为语义内核的项目，我在帮助推进它。这是一种让更多企业利用这种新型AI的方法。在那之前，我在物理安全行业工作。我是Everbridge这家中型安全公司的首席技术官。我们照顾了世界、国家、城市和公司。在那之前，我在风险投资公司工作过。我在麻省理工学院待了一段时间，进行过研究，还在一家后期初创公司工作，真正理解世界的发展方向。'
- en: '**A.G.**: Amazing. Such an interesting background. One of the things I really
    like about you is that you are converging the design world and the AI world, which
    is very intuitive for some people. Like, of course, if we’re interacting with
    artificial intelligence, we want to have an interface and a design with a human-centric
    process. But what’s your opinion on the importance of this kind of design process
    and design thinking for AI applications, including generative AI?'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 太惊人了。这样的背景非常有趣。我真的很喜欢你的一个地方，就是你将设计界和AI界结合起来，这对一些人来说非常直观。比如，当然，如果我们与人工智能互动，我们希望有一个以人为中心的过程的界面和设计。但你对这种设计过程和设计思维在AI应用，包括生成式AI中的重要性有何看法？'
- en: '**J.M.**: Yeah, well, I give an annual report at South by Southwest about the
    intersection of design, technology, and business. This year was called [Design
    Against AI](https://oreil.ly/pOZmj), which has two meanings. One meaning is design
    protest against AI, and the other is design competes against AI. So one is more
    of a kind of like, you know, give up. Stop it. The other is to, say, maybe I’ll
    take it on. I think creative people should be competing with AI instead. Trying
    to see how to advance their craft. Many people say it’s about collaborating with
    AI instead of just competing. That said, I think that this kind of AI is not about
    the pictures or the text. It really is about the tools, functions, actions. That’s
    why in Semantic Kernel we say plug-ins, planners, personas. I’ve heard nowadays
    people say large action model instead of just large language model where large
    action model assumes you’re using functions, plug-ins, function calling. I think
    that verb aspect of AI is going to be the thing that unlocks much more value than
    we could ever imagine.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**J.M.**: 是的，嗯，我在南加州西南部会议上做了一份年度报告，关于设计、技术和商业的交汇。今年叫做[设计对抗AI](https://oreil.ly/pOZmj)，有两个含义。一个含义是设计对AI的抗议，另一个含义是设计与AI竞争。所以一个更像是，你知道的，放弃。停止。另一个是说，也许我会接受它。我认为创意人士应该与AI竞争，试图看到如何提升他们的技艺。许多人说这更多是关于与AI合作而不是竞争。话虽如此，我认为这种AI并不关乎图片或文本。它实际上关乎工具、功能、动作。这就是为什么在语义内核中我们说插件、规划者、角色。我听说现在人们说大型动作模型而不是仅仅大型语言模型，因为大型动作模型假设你在使用功能、插件、功能调用。我认为AI的这种动词方面将会是解锁比我们想象的更多价值的东西。'
- en: '**A.G.**: Yeah, because it’s the interaction with tools. And in general, people
    are worried about AI replacing some basic functions of society. But some people
    are skipping the part where generative AI can be the interface to interact with
    very complex functions like designing 3D or analyzing SQL databases. So that draws
    the sign as an interface. Models and tools like Semantic Kernel.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的，因为它是与工具的互动。一般来说，人们担心AI会取代社会的一些基本功能。但有些人跳过了生成式AI可以作为与非常复杂的功能（如设计3D或分析SQL数据库）交互界面的部分。所以这就像一个界面。像语义内核这样的模型和工具。'
- en: '**J.M.**: Well, I think plug-ins are so powerful. Whether you call them functions
    or tools or whatever you want to call them, when you integrate them with a large
    language model, of course, you get the kind of planning capability. And that’s
    what we saw with Semantic Kernel. When you use GPT-4, you give it plug-ins that
    can plan. And once it can plan, it’s basically writing code that you could never
    have written. It writes code on the fly, basically. From a design perspective,
    a lot of time has been spent making the perfect user experience. That’s something
    very hard to do. We’ll build a journey to take you step by step through it. In
    reality, though, with function calling, you don’t need a journey. You just say,
    I want to do this, and it’s done. You didn’t have to have a user interface. That’s
    why you hear people calling it sort of like a zero UI era, where you don’t have
    a journey, you teleport to the goal.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**J.M.**: 我认为插件非常强大。无论你称它们为函数、工具还是你想叫什么，当你将它们与大型语言模型集成时，当然你会得到规划能力。这正是我们在语义内核中看到的。当你使用GPT-4时，你给它提供可以规划的插件。一旦它可以规划，它基本上就是在编写你永远无法编写的代码。它即兴编写代码。从设计角度来看，我们花费了大量时间来制作完美的用户体验。这是一件非常困难的事情。我们将构建一个旅程，带你一步步通过。然而，在现实中，通过函数调用，你不需要旅程。你只需说，我想做这个，就完成了。你不需要用户界面。这就是为什么人们称它为某种零UI时代，你没有旅程，你直接传送到目标。'
- en: '**A.G.**: I love that notion because from my perspective with the book, I think
    that function calling and the planning part was the most difficult part to explain,
    to be honest.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 我喜欢这个观点，因为从我的角度来看，我认为函数调用和规划部分是解释起来最困难的部分，说实话。'
- en: '**J.M.**: It is. It’s so hard. It’s hard because if you’re a developer right
    now, you’re just too busy shipping regular code. You’re tired at the end of the
    week. You know, it’s a weekend, you want to take a break, and like, what, this
    new thing, what, embeddings? What, you’ve got to do language model understanding,
    testing, what, these are all new tools. You know, Python may not be your thing
    you do every day too. It’s like, oh, I don’t want to, I played with Python, whatever.
    And so that’s why we’re trying to make it easier for enterprise devs who live
    in .NET or Java or boring languages. So I tell people, Semantic Kernel is for
    boring AI people.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '**J.M.**: 是的。这太难了。这是因为如果你现在是一名开发者，你只是太忙于发布常规代码。到周末结束时你都很累。你知道，周末你想休息一下，然后，比如，这个新事物，比如，嵌入？比如，你必须做语言模型的理解、测试，比如，这些都是新工具。你知道，Python可能不是你每天都会做的事情。就像，哦，我不想，我玩过Python，随便吧。这就是为什么我们试图让居住在.NET或Java或无聊语言的企业开发者更容易使用。所以我告诉人们，Semantic
    Kernel是为无聊的AI人准备的。'
- en: '**A.G.**: Boring AI people. That’s such good marketing.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 无聊的AI人。这是如此好的营销。'
- en: '**J.M.:** Well, it’s because enterprise likes “boring.” I mean, we also have
    a Python branch, but I find that the Python stuff is so advanced that actually
    integrating into an enterprise, it’s not so easy because it’s a different developer.
    An app dev is more about shipping “real code.” So we need an easier way to do
    that. That’s why Semantic Kernel exists.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '**J.M.**: 嗯，这是因为企业喜欢“无聊”。我的意思是，我们也有一个Python分支，但我发现Python的东西非常先进，实际上集成到企业中并不容易，因为它是不同的开发者。应用开发者更关注的是发布“真正的代码”。所以我们需要一个更简单的方式来做到这一点。这就是Semantic
    Kernel存在的原因。'
- en: '**A.G.**: That’s very smart positioning. And how can you define Semantic Kernel?
    You have explained the plug-ins, the personas, but if you think of Semantic Kernel
    as a thing, today and in the future, if we’re able to get a sneak peek here, what’s
    your vision? How is it helping companies?'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 这是一个非常聪明的定位。那么你如何定义Semantic Kernel？你已经解释了插件、角色，但如果将Semantic Kernel视为一个事物，今天和未来，如果我们能在这里提前一瞥，你的愿景是什么？它是如何帮助公司的？'
- en: '**J.M.**: Well, you know, I think the biggest way it helps companies is it
    helps you be boring because the latest thing is the latest thing, but the problem
    with the latest thing is it just got new today. And so you’re just so distracted.
    Like, what do I do? Oh my gosh, it changes every day. So Semantic Kernel is good
    insurance for building on a middleware layer. When the lower parts change, it’s
    easy to adapt it at the middleware level. So it’s like insurance for the high
    speed of AI change. And it’s grounded in the plug-in because the plug-ins are
    where function calling becomes valuable. We have so many ways to do plug-ins with
    native code or native plus semantic code, you know, pick your own language. And
    the planners are designed to not just leverage the plug-ins to call them automatically,
    but to generate a script basically that you can read yourself, not a Python program,
    but a handlebars-formatted plan. We found many enterprises are happy that AI generated
    the plan and they want to freeze the plan because they know it works. They don’t
    need it to invent something new. So frozen plans. And we’re all talking about
    agents now. So it also incorporates agents.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '**J.M.**: 嗯，你知道，我认为它帮助公司最大的方式是它帮助你变得无聊，因为最新的东西就是最新的东西，但最新东西的问题就是它今天才出现。所以你只是太分心了。比如，我该怎么办？哦，我的天，它每天都在变化。所以Semantic
    Kernel是构建在中间件层上的好保险。当底层发生变化时，在中间件级别上适应它很容易。所以它就像是AI变化高速的保险。它基于插件，因为插件是功能调用的价值所在。我们有多种方式来做插件，使用原生代码或原生加语义代码，你知道，选择你自己的语言。规划器被设计成不仅利用插件自动调用它们，而且生成一个你可以自己阅读的脚本，不是Python程序，而是一个handlebars格式的计划。我们发现许多企业很高兴AI生成了计划，并且他们想冻结计划，因为他们知道它有效。他们不需要发明新的东西。所以有冻结计划。现在我们都在谈论代理，所以它也包含了代理。'
- en: '**A.G.**: Agents, we’re talking about the difference with someone I cannot
    disclose right now, the difference between agents and copilots.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 代理，我们正在讨论的是与我现在不能透露的人的区别，即代理和副驾驶之间的区别。'
- en: '**J.M.**: I don’t know if I could get into that conversation. It’s very meta,
    I believe.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '**J.M.**: 我不知道我能否进入那个对话。这非常具有元属性，我相信。'
- en: '**A.G.**: It’s very meta. I think it’s a matter of the audience. The people
    talking about agents are probably a more developer-oriented audience.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 这非常具有元属性。我认为这取决于观众。谈论代理的人可能是一个更偏向开发者的观众。'
- en: '**J.M.**: Yes. Good point. Well, if you remember the shift to object oriented
    programming, I remember that being a radical idea. It’s like, how do you do that?
    I’m so used to programming in this linear, compartmentalized way. Object? What’s
    an object? The number one thing you learn in object oriented programming is don’t
    make everything into an object. I think agent oriented programming also, sometimes
    agents are useful. Sometimes they’re not. It’s just a new pattern, I believe.'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**J.M.**: 是的。很好的观点。嗯，如果你记得转向面向对象编程的变革，我记得那是一个激进的观念。就像，你怎么做？我已经习惯了以这种线性、模块化的方式编程。对象？对象是什么？面向对象编程的第一件事就是不要把所有东西都变成对象。我认为面向代理编程也是如此，有时代理是有用的，有时则不然。我认为它只是一种新的模式。'
- en: '**A.G.**: Yes, totally. I like that example because I was born during the object
    oriented era. And I could see how the previous era was like, this doesn’t make
    sense. You’re doing this in a linear way when you need to create relations between
    objects.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的，完全同意。我喜欢这个例子，因为我出生在面向对象的时代。我可以看到前一个时代是什么样的，这没有意义。当你需要创建对象之间的关系时，你以线性方式做这件事。'
- en: '**J.M.**: And you remember, you suddenly make everything into an object and
    then you can’t understand it anymore. You create some kind of compromise. I think
    agents are a new way of improving the output of models through iteration, through
    feedback loops. It’s a more clever way to do prompting. It’s more compartmentalized.
    But sometimes if you need a linear workflow, that might be what your application
    requires. In that case, you don’t need agents. In that case.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '**J.M.**: 你记得，你突然把一切变成对象，然后你就无法理解它了。你创造了一些妥协。我认为代理是一种通过迭代、通过反馈循环来提高模型输出的新方法。这是一种更聪明的提示方法。它更加模块化。但有时如果你需要一个线性工作流程，那可能就是你的应用程序所需的内容。在这种情况下，你不需要代理。在这种情况下。'
- en: '**A.G.**: Interesting. And from an Azure OpenAI perspective and any kind of
    generative AI in Azure, how do you see that connection with Semantic Kernel? And
    how do you see in general the role of orchestration? Like in Copilot, we’re talking
    about Prometheus and other orchestration engines. How do you make sense of this?
    There are so many things in this area.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 有趣。从Azure OpenAI的角度来看，以及Azure中任何类型的生成式AI，您如何看待它与语义内核之间的联系？您一般如何看待编排的作用？比如在Copilot中，我们谈论的是Prometheus和其他编排引擎。您如何理解这一点？这个领域有太多东西了。'
- en: '**J.M.**: Well, you know, there’s people who want to call the model directly,
    call the APIs. I’m sure you’ve seen things like [Ollama](https://oreil.ly/Eyl-u)
    or [LM Studio](https://oreil.ly/qQBmG), they’re all adapting to the OpenAI API
    specification. I kind of feel like OpenAI has become a kind of interfacing body.
    And because Azure OpenAI is super tight, a fast follow, I think anyone in that
    ecosystem gets to take advantage of that. And then you may want to orchestrate
    directly to talk to the API, or you want to talk in a layer. And a layer is like
    clothing. There’s all kinds of brands of clothing, basically. And the particular
    brand of clothing that is Symantec Kernel is plug-ins first. And then the plug-ins
    are the foundation. And the neat thing is planners are also plug-ins, and also
    our agents, personas, are plug-ins too. We say we’re plug-ins all the way down.
    So we’re very boring.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '**J.M.**: 嗯，你知道，有些人想直接调用模型，调用API。我确信你见过像[Ollama](https://oreil.ly/Eyl-u)或[LM
    Studio](https://oreil.ly/qQBmG)这样的东西，它们都在适应OpenAI API规范。我有点感觉OpenAI已经成为了一种接口机构。由于Azure
    OpenAI非常紧密，快速跟进，我认为生态系统中的任何人都能够利用这一点。然后你可能想直接编排以与API通信，或者你想要在某一层进行通信。层就像衣服一样。基本上有各种各样的品牌。Symantec
    Kernel这个特定品牌的衣服是先插插件。然后插件是基础。而且很酷的是，规划器也是插件，我们的代理、角色也是插件。我们说我们从头到尾都是插件。所以我们非常无聊。'
- en: '**A.G.**: This is like a multilayer architecture in which they’re communicating,
    and then you have different options to communicate with this service and another.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 这是一个多层架构，其中它们在相互通信，然后你有不同的选项来与这个服务和其他服务进行通信。'
- en: '**J.M.**: Everything is just code. We’re not trying to make a magical spell
    that you’re not programming anymore. You’re still programming. And everything
    is a computational unit. It’s a plug-in. And you can make plans that are also
    plug-ins, or you can make agents that are plug-ins. And it’s just like connecting
    those dots.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**J.M.**: 一切都是代码。我们不是试图创造一个魔法咒语，让你不再编程。你仍然在编程。一切都是计算单元。它是一个插件。你可以创建也是插件的计划，或者你可以创建也是插件的代理。这就像连接那些点。'
- en: '**A.G.:** Amazing. Let me ask this question. I’ve got several people asking
    the same question. And you can tell me if this is not a good question, but what’s
    the difference, convergence, compatibility between Semantic Kernel and LangChain?'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 太棒了。让我问一个问题。有好几个人问我同样的问题。你可以告诉我这不是一个好问题，但Semantic Kernel和LangChain之间的区别、趋同、兼容性是什么？'
- en: '**J.M.**: Very common question. Yeah. LangChain and Semantic Kernel are both
    open source projects. Open source projects support each other. All I have is good
    things to say about LangChain and also [Harrison](https://oreil.ly/ttbiM), that
    community. I also love [LlamaIndex](https://oreil.ly/QZtYV), which I think of
    as like a sister or cousin project, which I adore. And the difference really is
    in the fact that LangChain is running the fastest with the latest and greatest
    AI ideas. Semantic Kernel, that’s not the role. The role of Semantic Kernel is
    to enable enterprises to leverage this large language model or large action model
    revolution. And they’re gonna tend to move slower and need more sense of safety
    and security. So Semantic Kernel is architected with very few package dependencies,
    if at all. It’s designed to be loved by the CISO (Chief Information Security Officer).
    And it’s designed to be loved by procurement because it’s free, but it’s also
    part of the Microsoft world.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**J.M.**: 这是一个非常常见的问题。是的，LangChain和Semantic Kernel都是开源项目。开源项目之间相互支持。我对LangChain只有好评，还有[Harrison](https://oreil.ly/ttbiM)这个社区。我也非常喜欢[LlamaIndex](https://oreil.ly/QZtYV)，我认为它就像是一个姐妹或表亲项目，我非常喜欢。真正的区别在于LangChain正在以最快的速度运行最新的AI想法。Semantic
    Kernel并不扮演这个角色。Semantic Kernel的角色是帮助企业利用这个大型语言模型或大型动作模型革命。它们可能会走得慢一些，需要更多的安全感和保障。因此，Semantic
    Kernel的设计中包含非常少的包依赖，如果有的话。它被设计成让CISO（首席信息安全官）喜欢，也设计成让采购部门喜欢，因为它免费，但也是微软世界的一部分。'
- en: '**A.G.:** Yeah. Which makes total sense. I think both of them are necessary.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的。这完全有道理。我认为两者都是必要的。'
- en: '**J.M.:** Yeah, yeah, yeah. I mean, like I say that if you want to drive a
    Tesla Model S Plaid, then LangChain’s fun. If you wanna drive a Toyota Camry XLE
    Hybrid, then you’ve got Semantic Kernel. And the neat thing is with a Python branch,
    everything is becoming 1.0\. .NET became 1.0 first. We’re aligning Python and
    Java releases. If you’re a Python team, usually a data science–oriented team,
    and you use Semantic Kernel, all of your YAML files and everything easily shift
    to the App Dev. So that’s the advantage.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**J.M.**: 是的，是的，是的。我的意思是，就像我说的，如果你想驾驶特斯拉Model S Plaid，那么LangChain很有趣。如果你想驾驶丰田Camry
    XLE混合动力车，那么你就有了Semantic Kernel。而且，有趣的是，随着Python分支的出现，一切都在成为1.0。.NET首先成为1.0。我们正在对齐Python和Java的发布。如果你是Python团队，通常是一个以数据科学为导向的团队，并且使用Semantic
    Kernel，所有你的YAML文件和一切都可以轻松转移到App Dev。所以这是优势。'
- en: '**A.G.:** And what’s the role of orchestration? I know that it’s a bit of a
    stretch, but what’s the role of orchestration to bring the proper information
    and the proper format and good timing in a timely manner for compliance? I’m located
    in Madrid, in Spain, Europe, AI Act, similar things in Canada, in the future in
    the United States. I feel like there’s a lot of potential for that layer in the
    middle to distribute information that is required at log level.'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 那协调的作用是什么？我知道这有点牵强，但协调在及时提供适当的信息和格式以及良好的时机以符合规定方面有什么作用？我位于西班牙的马德里，欧洲，AI
    Act，加拿大类似的东西，未来在美国。我觉得中间层有大量潜力来分配日志级别所需的信息。'
- en: '**J.M.**: Well, I mean, that’s a nice thing about Semantic Kernel having been
    built 1.0 first with .NET C#, because it has all the logging everywhere. It’s
    got all the Azure kind of security, safeness built into how it’s architected.
    You often hear people who love how Semantic Kernel has been architected, because
    it’s been Microsoft architected. If you haven’t seen, or if any of your readers
    or viewers haven’t seen how we wrap plug-ins, you’re gonna be pleasantly surprised
    because it’s so little code to enable function calling of complex plug-ins. And
    you’re thinking, wait, this is all the code I need? And you’re like, yep, we can
    get going. People love that. And that was architected by [Stephen Toub](https://oreil.ly/i7kqx),
    one of the .NET architect legends. I remember when he said it’s gotta be this
    way. And we’re like, OK. And he said wow, that’s really good. It’s really good.
    But anyone who sees it, they’re kind of, where’s the code? It’s all there because
    it’s using the abstractions available already of an enterprise-class language.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '**J.M.**: 嗯，我认为Semantic Kernel首先用.NET C#构建1.0版本是个好事，因为它在所有地方都有日志记录。它具有所有Azure类型的安保，安全性已经集成到其架构中。你经常听到人们喜欢Semantic
    Kernel的架构，因为它是由微软架构的。如果你还没有看到，或者如果你的读者或观众还没有看到我们如何封装插件，你会感到很惊喜，因为启用复杂插件的函数调用只需要这么少的代码。你可能会想，等等，这就是我需要的所有代码吗？然后你会说，是的，我们可以开始了。人们都喜欢这样。这是由.NET架构传奇人物[斯蒂芬·图布](https://oreil.ly/i7kqx)设计的。我记得他曾经说过必须这样。我们说，好吧。然后他说哇，这真的很棒。真的很棒。但任何看到它的人都会觉得，代码在哪里？因为它是使用企业级语言已经提供的抽象来实现的，所以所有的代码都在那里。'
- en: '**A.G.:** Learning is the goal of this interview and I know that you are a
    humble person because you are not talking that much about your activities and
    your background, but you’re creating learning resources, which I personally love.
    That’s why I’m writing this book. That’s why we’re creating all this stuff. And
    I have two examples, LinkedIn Learning and DeepLearning.AI. What are they about,
    for people to continue learning?'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 学习是这个采访的目标，我知道你是一个谦逊的人，因为你没有太多谈论你的活动和背景，但你正在创建学习资源，我个人非常喜欢。这就是我写这本书的原因。这就是我们为什么创造所有这些内容的原因。我有两个例子，LinkedIn
    Learning和DeepLearning.AI。它们是关于什么的，让人们继续学习？'
- en: '**J.M.:** Oh, thanks. Let’s see, I have a [LinkedIn Learning course](https://oreil.ly/TXE5e).
    Now I have [multiple](https://oreil.ly/G6grC), including one for [AI engineering
    for leadership](https://oreil.ly/z-nXp). Because AI engineering is about leading
    change. And most developers love to be introverts, but they sometimes become managers
    and they have to lead people. And this AI stuff is kind of scary for people. It’s
    also very technical to understand. I have a whole new course themed on the kitchen.
    Also, Microsoft Dev Channel has a new show we’ve made, called [Mr. Maeda’s Cozy
    AI Kitchen](https://oreil.ly/N9oCg). Yes, we cook AI every two weeks in my kitchen.
    And we have guests and they try the AI.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '**J.M.**: 哦，谢谢。让我看看，我有一个[LinkedIn Learning课程](https://oreil.ly/TXE5e)。现在我有很多，包括一个关于[AI工程领导力](https://oreil.ly/z-nXp)的。因为AI工程是关于引领变革的。大多数开发者喜欢内向，但他们有时会变成管理者，他们必须领导他人。这些AI东西对人们来说有点可怕。理解起来也非常技术性。我还有一个全新的关于厨房主题的课程。此外，微软开发者频道有一个我们制作的新节目，叫做[梅达先生的温馨AI厨房](https://oreil.ly/N9oCg)。是的，我们每两周在我的厨房里烹饪AI。我们还有嘉宾，他们尝试使用AI。'
- en: 'And the [DeepLearning.AI course](https://oreil.ly/nxusL) was an opportunity
    to talk with [Andrew Ng](https://oreil.ly/CDLm-), who I think is one of the great
    minds of our time. And he gave this talk at the Wall Street Journal CIO Summit,
    where someone asked him if this is going to change how people’s jobs are, and
    all the fear around it. And he said the best thing I’ve ever heard anyone say:
    you should think of AI as automating tasks, not jobs. Any given job has many tasks.
    And if there are a lot of tasks that you don’t like to do as a human, that aren’t
    of high value as a human, then automating them with AI makes a lot of sense and
    can improve your job. Whether it’s a gnarly testing function you’re writing where
    you’re thinking, “Oh, that’s going to be such a pain with all the cases,” and
    boom! It’s there. Or something like a shell script that is always different in
    every language with a little subtlety. You just say I need a shell script. Just
    a half an hour ago, I did that. I need a shell script. And then find out, oh,
    that was easy. And you debug it yourself too. So, it’s taking tasks that I don’t
    like to do and having it be done for me.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 而 [DeepLearning.AI 课程](https://oreil.ly/nxusL) 是一个与 [Andrew Ng](https://oreil.ly/CDLm-)
    谈话的机会，我认为他是我们这个时代的大思想家之一。他在《华尔街日报》CIO 峰会上发表了这次演讲，有人问他这是否会改变人们的就业方式，以及围绕这一点的所有恐惧。他说了最好听的话：你应该把人工智能看作是自动化任务，而不是工作。任何一项工作都有许多任务。如果你有很多不喜欢做的人工作，这些工作对人类来说价值不高，那么用人工智能来自动化它们就很有意义，并且可以提高你的工作效率。无论是你正在编写的复杂的测试功能，你想着，“哦，所有这些情况都会很痛苦，”然后砰！它就出现了。或者像
    shell 脚本那样，在每种语言中都有细微的差别。你只需要说，我需要一个 shell 脚本。就在半小时前，我就做了这件事。我需要一个 shell 脚本。然后发现，哦，这很简单。你自己也调试它。所以，这是在为我完成我不喜欢做的任务。
- en: '**A.G.:** I can really see that. Like, right after this discussion, I’m creating
    the transcription and I’m creating the action points and the summary of the most
    important information. No one likes to do that and that’s maybe 10% of my job
    because we are having so many meetings. I just want to go back to your design
    background. Looking at this adoption pattern where companies and people are using
    generative AI, LLMs, and they are learning how to evaluate them, how to use them,
    how to orchestrate, from a design point of view, do you see anything happening
    in the near future that will be radically different from a design UX, UI point
    of view?'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 我真的能理解这一点。就像，就在这次讨论之后，我正在创建转录、创建行动要点和总结最重要的信息。没有人喜欢做这件事，这可能占我工作的10%，因为我们有太多的会议。我想回到你的设计背景。看着公司和个人使用生成式AI、LLM，他们正在学习如何评估它们、使用它们、如何从设计角度进行编排，你认为在不久的将来，从设计UX、UI的角度来看，会发生什么与现在截然不同的事情吗？'
- en: '**J.M.**: Yeah. Well, I definitely think that this zero UI revolution is happening
    where you don’t need a lot of user interface, user experience, psychology when
    the machine can discover your intent and execute the task. There’s this thing
    called [Jobs to Be Done by Clayton Christensen](https://oreil.ly/Aq12m). It’s
    almost as if we create user experiences to get a job done, but if the machine
    knows what job you want to get done and you tell it what to do and it does it,
    did you really need any experience in the first place?'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '**J.M.**: 是的。我确实认为这场零界面革命正在发生，当机器能够发现你的意图并执行任务时，你不需要很多用户界面、用户体验或心理学。有件事叫做 [克雷顿·克里斯滕森的“要完成的任务”](https://oreil.ly/Aq12m)。几乎就像我们创建用户体验来完成一项工作，但如果机器知道你想要完成的工作，你告诉它怎么做，它就去做，你真的需要任何经验吗？'
- en: '**A.G.**: That’s amazing, that is funny. Just today I was getting that question
    from a student about how to define the jobs to be done for artificial intelligence.
    I was like, I don’t know, I don’t know.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 这太令人惊讶了，真是有趣。就在今天，我有一个学生问我如何定义人工智能要完成的任务。我想，我不知道，我真的不知道。'
- en: '**J.M.**: Yeah, because with tool calling and function calling, you give it,
    like in Semantic Kernel, just last week I had this weird moment where I gave it
    five plug-ins I wrote, and then I didn’t have to construct the logic of how to
    make them all work. It was actually too hard for me to write the logic, and the
    planner just constructed the flow the way that I couldn’t write.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '**J.M.**: 是的，因为有了工具调用和函数调用，你给它，就像在语义内核中，上周我有一个奇怪的瞬间，我给了它我写的五个插件，然后我就不必构建它们如何协同工作的逻辑了。实际上，对我来说编写逻辑太难了，规划者实际上以我无法编写的方式构建了流程。'
- en: '**A.G.**: Wow, that’s incredible. And just to finish, since you mentioned the
    kitchen, if you had to choose, did you have one recipe that you say, this is something
    that someone needs to learn for the next stage of adoption?'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '**J.M.**: Oh, good question. Yeah, I tell everyone that in the kitchen that
    you have to realize there’s two kinds of AI models. One AI model does completion,
    the other does similarity. And this is called the embeddings model. This is called
    the completion or chat completion model. It’s a combination of these two together
    that are making this revolution amazing. If you only have one, it’s no good. If
    you have chat completion or completion, it’s going to be ungrounded. It’ll say
    things that make no sense. If you have similarity models, which are basically
    search, you can find something, but you can’t synthesize. The two together make
    an incredible pair. It’s like one is butter and one is flour. Like together you
    can make great cookies. And this is the core recipe for everything with large
    language model AIs. You can create function calling models, you can create sophisticated
    chat, you can create supply chain automation, all from these two models. But one
    model alone is not good enough, you need the two together.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '**A.G.**: You’re right. And I think this in the human comparison would be something
    like IQ and EQ together. Like the ability to remember information, traditional
    intelligence, but that ability to explain in a proper way that is adapting to
    the audience. Yes, I love it.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: 'Sarah Bird: Responsible AI for LLMs and Generative AI'
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**A.G.**: Do you want to start by explaining your role in the organization
    and what you are doing at Microsoft?'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aoas_07in04.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
- en: '**S.B.**: Yeah. I’m Microsoft’s chief product officer of responsible AI. What
    that means is my team is responsible for figuring out how we take a new AI technology
    and ensure that it’s developed responsibly. In the case of a lot of the AI we
    build at Microsoft, we’re figuring that out ourselves. If we’re partnering with
    other organizations such as OpenAI, then we work with them to ensure that the
    right things are happening as they develop the AI. But then it’s not just about
    the model, it’s really about how we ship a complete application safely. We take
    that new AI technology and look at what the entire approach we need to follow
    is to use this technology effectively.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: For example, for GPT-4, an exciting new piece of technology, the first place
    we shipped this was in Microsoft Copilot, originally called Bing Chat. Our team
    went in and basically led the responsible AI (RAI) development of that. We developed
    new mitigations, we developed new testing tools, we developed new techniques for
    red teaming. All that we learned, we built into the Azure AI platform and that
    enables it to power all of the AI at Microsoft as well as enable our customers
    who are building their own AI applications to use the same best practices. That’s
    the mission of the team, figuring out how we really put AI into practice, and
    then ensuring that we’re using those best practices across Microsoft and empowering
    others to do that as well.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，对于GPT-4这个令人兴奋的新技术，我们第一次发布这个技术是在微软Copilot中，最初被称为Bing Chat。我们的团队进去并基本上领导了负责任AI（RAI）的开发。我们开发了新的缓解措施，开发了新的测试工具，开发了新的红队技术。我们学到的一切，我们都构建到了Azure
    AI平台上，这使得它能够为微软的所有AI提供动力，同时也使我们的客户在构建自己的AI应用时能够使用相同的最佳实践。这就是团队的任务，找出我们如何真正将AI付诸实践，并确保我们在微软内部使用这些最佳实践，并赋予他人这样做的能力。
- en: '**A.G.**: That’s a lovely mission. And it’s not a new one. There’s a journey
    at Microsoft with responsible AI even before the GPT models.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 这是一个很棒的任务。而且它不是一个新的任务。在微软，负责任AI的旅程甚至早于GPT模型。'
- en: '**S.B.**: Yeah, it’s something that we’ve actually been doing a long time.
    I was fortunate to be part of founding the first research group in responsible
    AI in Microsoft, and this is the [FATE group](https://oreil.ly/hmo69), back in
    2015\. This is something we’ve been doing for almost 10 years. But we’ve come
    a long way during that time. It went from just some ideas in research to, the
    next thing that we founded was the Office of Responsible AI, which was really
    starting to set what is the policy or the standard we want to follow. But even
    creating a policy without much experience in implementation is really hard. A
    lot of the journey since then has been figuring out how we really do this, and
    iterating between policy, engineering, and research to really mature our practices,
    tools, and technology. But even with generative AI, for a lot of people, the first
    moment they were aware of it was ChatGPT. But actually, well before ChatGPT came
    out, Microsoft shipped GitHub Copilot, which was really the first generative AI
    application that we produced at scale. A lot of the things that we used in Bing
    Chat and other applications were actually originally developed for GitHub Copilot,
    because that was the first real-time generative AI application. [Azure AI Content
    Safety](https://oreil.ly/uB6d-), the safety system that we use in our gen AI applications
    today, was actually first developed for GitHub Copilot.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.B.**: 是的，这是我们实际上已经做了很长时间的事情。我很幸运能成为微软第一个负责任AI研究团队的创始人之一，那就是[FATE团队](https://oreil.ly/hmo69)，那是2015年。这是我们几乎已经做了10年的事情。但在这段时间里，我们已经走了很长的路。它从研究中的几个想法发展到，我们接下来成立的是负责任AI办公室，这实际上开始设定我们想要遵循的政策或标准。但即使在没有太多实施经验的情况下制定政策也是非常困难的。从那时起，我们的大部分旅程都是
    figuring out how we really do this，在政策、工程和研究之间迭代，以真正成熟我们的实践、工具和技术。但即使有了生成式AI，对于很多人来说，他们第一次意识到它的那一刻是ChatGPT。但实际上，在ChatGPT推出之前，微软就已经发布了GitHub
    Copilot，这是我们大规模生产的第一个生成式AI应用。我们在Bing Chat和其他应用中使用的大多数东西实际上最初是为GitHub Copilot开发的，因为那是第一个真正的实时生成式AI应用。[Azure
    AI内容安全](https://oreil.ly/uB6d-)，我们今天在gen AI应用中使用的安全系统，最初也是为GitHub Copilot开发的。'
- en: '**A.G.**: It’s funny because a lot of people forget, including ourselves, when
    we are talking about different Copilots, that GitHub Copilot is actually the patient
    zero, the first one and the original one.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 这很有趣，因为很多人，包括我们自己，在谈论不同的Copilot时，往往会忘记，GitHub Copilot实际上是零号病人，第一个，也是最初的那个。'
- en: '**S.B.**: It was eye-opening for us working on it because the GPT technology
    was exciting, but it felt like it could still be, it was still a toy. Then when
    the GitHub team really showed the early prototypes of GitHub Copilot, we were
    like, wow, this is real, this is really exciting. But at that time, we weren’t
    sure, is it just this one application? How narrow is the technology? How many
    more GitHub Copilots will there be? Then when the next wave of it came out, going
    from GPT-3 to GPT-4, GPT-4 was when we were like…oh, this is not narrow anymore.
    There will be many more Copilots that are possible. That jump in the technology,
    I think, really unlocked many more applications, but GitHub Copilot really showed
    the way first.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.B**：对我们来说，这是一个令人耳目一新的发现，因为GPT技术令人兴奋，但它感觉仍然像一个玩具。然后当GitHub团队展示了GitHub Copilot的早期原型时，我们想，哇，这是真的，这真的很令人兴奋。但那时，我们并不确定，这只是这一个应用吗？这项技术有多窄？会有多少个GitHub
    Copilot？然后当下一波产品推出，从GPT-3到GPT-4时，当我们看到GPT-4时，我们想……哦，这不再是狭窄的了。将会有更多可能的Copilot。这种技术上的飞跃，我认为，真正解锁了许多更多的应用，但GitHub
    Copilot首先展示了这条路。'
- en: '**A.G.**: Yes, and I think from an RAI perspective, the idea or the adoption
    pattern of having a regular completion, something that is a singular interaction
    with the machine, and then moving to something that is chat-related, with memory,
    with all the benefits and all the considerations. I think that that’s probably
    the evolution of that learning, the engineering and policy duet that you’re talking
    about.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G**：是的，我认为从RAI（人工智能伦理）的角度来看，有一个定期完成的想法或采用模式，即与机器进行单一交互，然后转向与聊天相关的交互，具有记忆力和所有好处以及所有考虑因素。我认为这可能就是你所谈论的学习、工程和政策二重奏的演变。'
- en: '**S.B.**: Yes, certainly. There are nuances in the GitHub Copilot application.
    I actually really loved the design of it because it is a paradigm people are already
    familiar with, with the autosuggest. We’re already comfortable with the idea of…hey,
    the suggestion might not be perfect, but if I like it, I can keep it and I can
    still go and edit it. We all know that it makes us go faster in natural language.
    But then knowing that actually was going to be effective for code, that wasn’t
    obvious. But we did have to look at both with that natural language risk, hateful
    content, violent content, things like that, and also code risks, like the ability
    to produce security vulnerabilities or known weaknesses in the code. We had to
    address both of those dimensions. Because the application is only useful if it
    goes faster than people actually can type, there were really extreme latency requirements.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.B**：是的，当然。GitHub Copilot应用中确实有一些细微差别。我实际上非常喜欢它的设计，因为它是一个人们已经熟悉的范例，有自动建议。我们已经习惯了这样的想法……嘿，建议可能并不完美，但如果我喜欢，我可以保留它，我仍然可以去编辑它。我们都知道这使我们用自然语言更快。但后来知道这实际上对代码也有效，这一点并不明显。但我们确实不得不考虑这两个方面，即自然语言风险，如仇恨内容、暴力内容等，以及代码风险，如产生安全漏洞或代码中的已知弱点。我们必须解决这两个维度。因为只有当应用比人们实际打字速度快时，它才有用，所以对延迟的要求非常高。'
- en: Now, the transition to Bing and Copilot since then in the chat applications,
    as you said, adds this multiturn dimension. Now, if you’re trying to look at an
    interaction and say “Hey, did the AI system do the right thing?” you actually
    have to score a multiturn natural language conversation, and that’s much more
    challenging. There’s a much bigger diversity of topics and types of interaction
    that the system is going to look at. We started with a strong foundation with
    GitHub Copilot, but certainly with the power of GPT-4 and the power of the search
    engine, and the breadth of things that we wanted to cover there, we really had
    to look much broader. So that’s when you start having conversations about things
    like hallucination, because accuracy really matters, or missing disinformation
    because the search engine is so connected with information integrity. And so the
    aperture really broadened with that application.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，自从在聊天应用中转向Bing和Copilot以来，正如你所说，增加了这个多轮交互维度。现在，如果你试图观察一个交互并说“嘿，AI系统做得对吗？”你实际上必须对多轮自然语言对话进行评分，这要困难得多。系统将要考虑的话题和交互类型更加多样化。我们从GitHub
    Copilot的坚实基础开始，但当然，有了GPT-4的力量和搜索引擎的力量，以及我们想要涵盖的广泛内容，我们真的必须考虑得更广泛。因此，这就是你开始讨论诸如幻觉等问题的时候，因为准确性真的很重要，或者因为搜索引擎与信息完整性的紧密联系，可能会遗漏错误信息。因此，随着该应用的发展，视野确实变得更加开阔。
- en: '**A.G.**: It must be very interesting, that moment that we realized we actually
    need new metrics, because you have mentioned the performance, and we had the ROC
    curve, the F1 and F2 scores for classification topics and stuff. And then we arrived
    there and we said, OK, we have a new kind of application that is based on something
    called generative AI. We need to test the performance of this. We have the metrics
    from traditional linguistics like BLUE and ROUGE. How was that? At the AI level,
    like what do we do now?'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 那一刻我们必须意识到我们实际上需要新的指标，这一定非常有趣，因为你提到了性能，我们有了ROC曲线、F1和F2分数用于分类话题等。然后我们到达那里，我们说，好吧，我们有一种新的应用，它基于被称为生成式人工智能的东西。我们需要测试这个应用的性能。我们有来自传统语言学的指标，比如BLUE和ROUGE。那怎么样？在人工智能层面，我们现在该怎么做？'
- en: '**S.B.**: You know, the thing is we always knew we needed metrics to actually
    address these risks, right? It’s very hard to understand if mitigation is effective
    or if a risk is present without actual metrics. And one of the big challenges
    in RAI for a long time is that these metrics were really difficult to get. For
    example, let’s go back to saying, “How do I rate a multiturn conversation?” So
    if you’re looking at doing that for “hate” (as an AI content safety metric), our
    guidelines internally are more than 20 pages long to kind of score that conversation,
    and they’re built for expert linguists. And so that meant that we can measure
    for response by risk, but only very infrequently as sort of the outer loop. OK,
    an application is basically ready to ship. We can run one set of tests that are
    very manual, and have the human reviewer score them. And if the results look good,
    great, we can ship it. But with that, you’re not able to really innovate in the
    inner loop and really try different things, and find which one works the best.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.B.**: 你知道，问题是我们一直都知道我们需要指标来实际解决这些风险，对吧？如果没有实际的指标，很难理解缓解措施是否有效或是否存在风险。在RAI（负责任的人工智能）领域的一个长期重大挑战是，这些指标真的很难获得。例如，让我们回到“如何评估多轮对话”这个问题。如果你是作为一个AI内容安全指标来考虑“仇恨”，我们内部的指南有超过20页长，用于评估这样的对话，它们是为专家语言学家设计的。这意味着我们可以按风险来衡量响应，但只能非常偶尔地作为外循环。好吧，一个应用基本上准备发货了。我们可以运行一组非常手动化的测试，由人工评审员评分。如果结果看起来不错，那就太好了，我们可以发货。但这样，你实际上无法在内循环中真正创新，真正尝试不同的事情，并找出哪一种效果最好。'
- en: Actually, one of the most memorable things for me about developing Bing Chat
    quite early, as we were using GPT-4, was realizing that it actually had the potential
    to help us automate these metrics. We were actually able to use GPT-4, with a
    lot of prompt engineering, and get it to score similar to the level of those expert
    humans. And so that meant we went from…hey, we’re gonna be able to check this
    very rarely, maybe once a month, maybe at the very end, to every single night
    when we make a change to the system, we can run the safety test overnight, look
    at the scores, and iterate. And so that unlocked just a whole new wave of responsible
    AI innovation. The technology is obviously a significant breakthrough for AI,
    but it’s also a significant breakthrough for responsible AI and safety and security
    because it’s this amazing new technology that just understands language and context
    so much more. We’ve really put that to use in our own development of AI.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，关于开发Bing Chat的早期记忆之一，当我们使用GPT-4时，就是意识到它实际上有潜力帮助我们自动化这些指标。我们实际上能够使用GPT-4，通过大量的提示工程，让它评分达到那些专家人类水平。这意味着我们从“嘿，我们可能只能每月检查一次，或者是在最后，我们将能够每晚在系统更改时运行安全测试，查看分数，并迭代。”转变为每晚都可以进行。这解锁了负责任人工智能创新的新一波浪潮。这项技术显然是人工智能的一个重大突破，但它也是负责任的人工智能、安全和保障的一个重大突破，因为它是一种理解语言和上下文如此之多的惊人新技术。我们真的在我们的AI开发中充分利用了这一点。
- en: '**A.G.**: And you have mentioned the key words like safety, security, even
    compliance, regulations, and responsible AI. Everything is converging at this
    point. Everything is going towards something that in the beginning was the ethical
    way to do things, like the willingness to do something that is good, towards something
    that is responsible, that is accountable. And I think that that’s a wonderful
    thing from a technology perspective, that organic evolution.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 你提到了像安全、保障、甚至合规、法规和负责任的人工智能这样的关键词。所有这些都在这个点上汇聚。一切都在朝着最初是道德行事方式的方向发展，比如愿意做有益的事情，朝着负责任、可问责的方向发展。我认为从技术角度来看，这是一种非常美妙的事情，一种有机的进化。'
- en: '**S.B.**: Yeah, I think with generative AI, one of the things that’s been exciting,
    but also challenging, frankly, is that with a lot of the responsible AI work we
    did before, just the AI developer could manage it. And everyone kind of got the
    benefit, but they didn’t need to really understand the details as long as you
    work with a great AI provider like Microsoft. You were set. With generative AI,
    we really end up needing both for safety and security to use a defense in depth
    approach where the model developer needs to do things, the safety system developer
    needs to do things, the application developer needs to look at the meta-prompt
    and the grounding information, the final application developer needs to look at
    how the human interacts. What does that UX look like?'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.B.**: 是的，我认为在生成式AI方面，一件既令人兴奋又坦白说具有挑战性的事情是，在我们之前进行的许多负责任AI工作中，只有AI开发者能够管理这些工作。每个人都能从中受益，但只要与像微软这样的优秀AI提供商合作，他们就不需要真正了解细节。但在生成式AI方面，我们实际上需要采取深度防御的方法来确保安全和安全，这意味着模型开发者需要做一些事情，安全系统开发者需要做一些事情，应用程序开发者需要查看元提示和基础信息，最终的应用程序开发者需要查看人类如何与之互动。这种用户体验是什么样的？'
- en: There’s so much more that needs to be done to use this technology effectively.
    And it’s not surprising, it’s a much more general-purpose, more powerful technology.
    This went from something that was really just housed in a small number of responsible
    AI experts to something that now every organization, every security professional,
    every AI developer needs to think about. It’s been really fun to see the interesting
    growth and support for the work, but also the explosion of demand means there’s
    so much more that we have to do. And that’s really exciting, but also can be challenging.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效地使用这项技术，还需要做更多的事情。这并不令人惊讶，它是一种更通用、更强大的技术。这项技术已经从仅由少数负责任AI专家掌握，发展到如今每个组织、每个安全专业人士、每个AI开发者都需要考虑的事情。看到这项工作的有趣增长和支持真的很有趣，但需求的爆炸性增长意味着我们还有更多的事情要做。这真的很令人兴奋，但也具有挑战性。
- en: '**A.G.**: It is very exciting. And I think it’s very aligned with the kind
    of artifacts and material that the [Responsible AI Initiative at Microsoft](https://oreil.ly/tCL6L)
    is putting out there, available for organizations at both the technical and organizational
    level. I’m thinking about the [impact assessment](https://oreil.ly/bJAeg), the
    [HAX toolkit](https://oreil.ly/AtDRJ) for the interfaces. What’s your favorite?
    If you had to choose different pieces of material that are useful for organizations
    in terms of responsible AI, what would be your selection?'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 这非常令人兴奋。我认为它与微软的[负责任AI倡议](https://oreil.ly/tCL6L)所推出的各种工具和材料非常契合，这些工具和材料既适用于技术层面也适用于组织层面。我在想[影响评估](https://oreil.ly/bJAeg)和[HAX工具包](https://oreil.ly/AtDRJ)对于界面的应用。你最喜欢哪一个？如果你必须从对组织在负责任AI方面有用的材料中选择不同的部分，你会选择哪些？'
- en: '**S.B.**: Oh, it’s so hard. I love all the responsible AI things. But I think
    what you’ve called out is really important because it is a mix of practices, policies,
    and technologies. And you really have to look at the whole spectrum and customers
    and organizations are asking us for that. So, for example, one of the things I
    really like is that we’ve put out our [Responsible AI Standard](https://oreil.ly/j5tBY),
    which is really the guide for how we do this overall out there. So organizations
    can look at it. They can adopt something similar if that works for them. We also
    put it out there so we can get feedback. People can tell us what they think we’re
    missing, what they’re finding works, what they’re finding doesn’t work. And so
    that’s really kind of where everything starts with us. But then if you want to
    go and put that into practice, you need to first start with a process like an
    impact assessment where you’re really mapping the risk. You then need to be able
    to measure risk effectively. And so actually we just released [new safety evaluations
    for generative AI](https://oreil.ly/GcCSo), which are the tests that we run ourselves
    to really measure these risks. And that’s actually the breakthrough I was telling
    you about earlier.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.B.**：哦，这太难了。我喜欢所有的负责任AI事物。但我认为你指出的这一点非常重要，因为它涉及实践、政策和技术的混合。你必须全面审视整个范围，客户和组织都在向我们提出这样的要求。例如，我非常喜欢我们发布的[负责任AI标准](https://oreil.ly/j5tBY)，这实际上是我们如何整体上做这件事的指南。因此，组织可以查看它。如果那对他们有效，他们可以采用类似的东西。我们还发布它，以便我们能够获得反馈。人们可以告诉我们他们认为我们遗漏了什么，他们发现什么有效，什么无效。因此，这实际上是我们一切开始的地方。但如果你想要将其付诸实践，你首先需要从像影响评估这样的流程开始，你实际上是在映射风险。然后你需要能够有效地衡量风险。因此，我们实际上刚刚发布了[生成式AI的新安全评估](https://oreil.ly/GcCSo)，这是我们运行的自测，以真正衡量这些风险。这实际上就是我之前告诉你的突破。'
- en: And then you also need to be able to mitigate the risk. Azure AI Content Safety
    is a great way we mitigate the risk. That’s the safety system layer. The HAX toolkit
    really helps with the application, the UX layer. We’ve also put out prompt engineering
    guides and meta-prompt templates to help with the prompt layer. You really have
    to look holistically across all of these to adopt that. Another one that we get
    asked about a lot from customers is how to red team, how to do that kind of final
    expert validation. We put out [red teaming guidelines](https://oreil.ly/oDBO_),
    but we know red teams are limited resources. So we’ve just released [PyRIT](https://oreil.ly/azSbW),
    which is a tool that helps accelerate the productivity of red teamers by helping
    them get more ideas for the next thing to try, basically using AI to assist them
    the same way we’re using AI to assist many other roles now with what we’ve developed.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你还需要能够减轻风险。Azure AI内容安全是我们减轻风险的一个很好的方法。这是安全系统层。HAX工具包在应用和UX层上提供了很大帮助。我们还发布了提示工程指南和元提示模板，以帮助提示层。你必须全面地审视所有这些才能采用它。我们还经常被客户询问的一个问题是关于如何进行红队测试，如何进行那种最终专家验证。我们发布了[红队测试指南](https://oreil.ly/oDBO_)，但我们知道红队资源有限。因此，我们刚刚发布了[PyRIT](https://oreil.ly/azSbW)，这是一个工具，通过帮助红队人员获得更多尝试新事物的想法来提高他们的生产力，基本上是使用AI以与我们现在使用AI帮助许多其他角色相同的方式帮助他们。
- en: We’re finding that people really need all of these pieces. A lot of the work
    we’re doing is trying to make sure that they understand that complete spectrum
    of practices and policies and tools that they’re going to need to achieve this.
    And we want to make it easy for everybody to just pick these up and go running
    with them, but also customize them as they need. We know different domains are
    different, organizations are different, and so we don’t want it to be just the
    Microsoft way. We just want to make it really easy for people to start with the
    responsible AI state of the art and then adapt it to them.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现人们确实需要所有这些部分。我们正在进行的大量工作都是为了确保他们理解他们将要需要的完整范围的实践、政策和工具。我们希望让每个人都能轻松地拿起这些工具并开始使用，同时根据需要对其进行定制。我们知道不同的领域和组织是不同的，所以我们不希望它只是微软的方式。我们只想让人们能够轻松地从负责任的AI前沿开始，然后根据他们的需求进行适配。
- en: '**A.G.:** Yeah, and this is useful. In my case, I’m using it with partners,
    with integrators, with consulting firms, with clients also who are asking for
    inspiration or some good practices on how they can approach responsible AI. Traditionally,
    it was about defining the AI principles, like we want to be accountable, transparent,
    etc. But now we’re going farther on how to approach this at an organizational
    and technical level.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的，这很有用。在我的情况下，我正在与合作伙伴、集成商、咨询公司以及寻求灵感或一些良好实践以了解如何接近负责任的人工智能的客户一起使用它。传统上，这关乎定义人工智能原则，比如我们希望负责、透明等。但现在我们在组织和技术层面如何接近这个问题上走得更远。'
- en: '**S.B.**: Yeah, and I think we have people ask both, how do I do a practice
    like red teaming or evaluation that we mentioned? Or they ask, how do I address
    a particular potential risk, such as hallucination or prompt injection attacks?
    We see people looking for guidance in both of those dimensions. And the answer
    for something like hallucination is…here are the steps: here is where you identify
    that risk, here’s how you measure that risk, how you red team it, here’s layers
    of mitigation for that. They’re actually a horizontal and vertical pattern, but
    we hear people asking for guidance in both of those ways.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.B.**: 是的，我认为人们提出了两个问题，一个是如何进行我们提到的像红队或评估这样的实践？或者他们问，我该如何应对特定的潜在风险，比如幻觉或提示注入攻击？我们看到人们在两个维度上都在寻找指导。对于像幻觉这样的问题的答案是这样的：这里是识别风险的步骤，这里是衡量风险的步骤，如何进行红队测试，这里是缓解风险的层级。它们实际上是横向和纵向的模式，但我们听到人们以这两种方式寻求指导。'
- en: '**A.G.**: Yes, indeed. And I think you have mentioned the experiences with
    GitHub, or Microsoft Bing/Copilot, that I think have been extremely illustrative
    for everyone trying to create their own copilot or whatever platform, even for
    competitors. I remember people saying…“Hey, Jordi Ribas (CVP Microsoft) and the
    team are releasing learnings every week, and this is so useful now for everyone.”
    So that’s very exciting, that movement from model to platform, and all the learnings
    that go with it.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的，确实如此。我认为你提到了GitHub或微软Bing/Copilot的经验，我认为这对所有试图创建自己的Copilot或任何平台，甚至竞争对手的人来说都是极具说明性的。我记得人们说……“嘿，Jordi
    Ribas（微软CVP）和他的团队每周都在发布学习成果，这对现在每个人来说都非常有用。”所以这非常令人兴奋，从模型到平台的转变，以及与之相关的所有学习成果。'
- en: '**S.B.**: Yeah, and we’re still learning every day now, as technology becomes
    more accessible to more people, all of the exciting new use cases that people
    can think of. But I think those early days were very special. The rate of learning
    was just insanely high. And we had the first ones where we had brought experts
    from around the company to work on this. Quite a few folks from Microsoft Research
    volunteered to work on that full time. We had these great minds all working together,
    iterating every day. And I think for a lot of people, that experience also kind
    of changed their work after that in their research directions, because they went
    in and really saw what the real challenges we have right now are, but also the
    real amazing potential of the technology. That hands-on experience where you were
    learning so much and we were all learning together, I think was really shaped
    in the way we’ve done AI at Microsoft and many different people’s outlook on that.
    So that certainly I think was a really special innovative time for us.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.B.**: 是的，我们现在每天都在学习，随着技术对更多人变得可访问，人们可以想到的所有令人兴奋的新用例。但我认为那些早期是非常特别的。学习的速度非常高。我们第一次将来自公司各个领域的专家召集起来工作。微软研究部门的很多人自愿全职参与其中。我们这些伟大的思想家一起工作，每天迭代。我认为对于很多人来说，那次经历也改变了他们在研究方向上的工作，因为他们真正看到了我们现在面临的真正挑战，以及技术的真正惊人潜力。那种亲身体验，你在其中学到了很多，我们都在一起学习，我认为这对我们在微软做人工智能的方式以及许多人对它的看法产生了真正的影响。所以这确实是我们一个非常特别的创新时期。'
- en: '**A.G.**: That must be amazing. I can imagine those days and those discussions,
    the daily work. It was very exciting also from the consumer point of view, just
    to see the news and all the new functionalities, not only the models, but everything
    that goes with that. What’s your vision for the next…it’s too difficult not to
    say two or three years, but just for the next year, your vision of how this will
    evolve, the kind of things that we may see, the kind of challenges that we may
    have, what do you think will happen?'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 这一定很神奇。我可以想象那些日子和那些讨论，日常的工作。从消费者的角度来看，看到新闻和所有新的功能也非常令人兴奋，不仅限于模型，还有与之相关的所有东西。你对未来的展望是什么……不说两三年太难了，但就下一年而言，你对这种发展的展望，我们可能会看到什么，我们可能会面临的挑战，你认为会发生什么？'
- en: '**S.B.**: Yeah, I think there’s a couple of patterns that we’re seeing. Certainly
    one of them is multimodal, right? A lot of the applications are still kind of
    mostly text, but there’s so much more potential when you can understand together
    different modalities, images, audio, video, etc. We’re starting to see very exciting
    examples of that technology. I think over the next year, a lot more multimodal
    will come in, and that certainly brings new types of risks from a responsible
    AI point of view. I think there’s a lot of excitement about the next wave of technology
    and AI agents, having the technology that can perform more actions. That of course
    greatly increases the space of things you need to think about in terms of responsible
    AI, but also the level of quality and inaccuracy that you need, because if you’re
    taking an action, a mistake can have a much bigger impact.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.B.**: 是的，我认为我们看到了一些模式。当然，其中一个就是多模态，对吧？许多应用仍然主要是文本，但当你能够理解不同模态（如图像、音频、视频等）的结合时，潜力就大得多。我们开始看到这个技术的非常令人兴奋的例子。我认为在未来一年里，会有更多多模态的应用出现，这无疑会从负责任的AI角度来看带来新的风险。我认为人们对下一波技术和AI代理非常兴奋，拥有能够执行更多动作的技术。这当然大大增加了你在负责任的AI方面需要考虑的事物范围，同时也提高了你需要的质量和准确性，因为如果你采取行动，错误可能会产生更大的影响。'
- en: Those are kind of two big ones that are on my mind, but maybe in the kind of
    bigger picture sense, Kevin Scott (Microsoft CTO) says regularly that right now
    this technology is on an exponential curve, but we only get to see the next points
    on the curve every year or two, when the next wave of technology comes out. I
    think a lot of us are asking ourselves, “Is the next one really gonna be exponentially
    better than GPT-4?” And if it is, what does that really mean? Like our minds have
    a hard time thinking in exponentials, we really kind of project out linearly.
    There’s also this chance that we’re gonna be just seeing another extreme breakthrough,
    sometime soon. And so, I think, one of the exciting open questions is just how
    much better will the next wave of technology be?
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是我心中想的两件大事，但在更大的图景中，凯文·斯科特（微软首席技术官）经常说，目前这项技术正处于指数曲线上，但我们只能每年或每两年看到曲线上的下一个点，当下一波技术出现时。我认为我们中的许多人都在问自己，“下一个是否真的会比GPT-4呈指数级更好？”如果是的话，这到底意味着什么？因为我们的思维很难在指数上思考，我们实际上是以线性方式预测的。还有一种可能，我们很快就会看到另一个极端的突破。因此，我认为，一个令人兴奋的开放问题是，下一波技术会变得多好？
- en: '**A.G.**: Yeah, I think it’s exponential, the kind of performance that we’ll
    see, and the kind of considerations that you’re mentioning. Like I said, there
    are multiple dimensions that we need to consider on that journey of new applications
    being created. A good example is what we saw with [OpenAI releasing Sora](https://oreil.ly/ppSjf)
    and just putting it out there, and showing the benefits but also sharing it with
    different parts of the community to analyze the potential considerations, because
    we can do a lot of things with this technology. But it’s exciting.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的，我认为性能将呈指数增长，你提到的那些考虑因素。就像我说的，在创建新应用的过程中，我们需要考虑多个维度。一个很好的例子是，我们看到了[OpenAI发布Sora](https://oreil.ly/ppSjf)并将其发布出去，展示了其好处，同时也与社区的不同部分分享，以分析潜在的考虑因素，因为我们可以用这项技术做很多事情。但这很令人兴奋。'
- en: '**S.B.**: Yeah, I think it’s as a technologist, it’s your hope, but certainly
    not expectation, that you’re gonna be around when the technology goes through
    a critical transformation, really crosses the threshold from being something that’s
    an exciting research idea to something that is really ready for practice. And
    so, I remind my team every day, we need to be enjoying every moment of this, because
    obviously I think the impact of the technology will only grow and that will be
    really exciting as well, but nothing is quite like the beginning in terms of the
    change that that brings, and the rate of learning and everything. And so, we’re
    just enjoying the ride, but also very, very aware that we’re in a position of
    leadership where we need to steer the direction of the future of this technology,
    and we need to help the world be able to use it in effective ways, but also ensure
    that it is not used in ways that I think society really doesn’t want. And so,
    I think we’re also very aware of the weight of the responsibility of being here
    in this position at the beginning and really making sure that we make decisions
    we think are going to be right for the future.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.B.**: 是的，我认为作为一个技术专家，这是你的希望，但当然不是期望，你会在技术经历关键转型时仍然在，真正地跨越从令人兴奋的研究想法到真正准备好实践的门槛。因此，我每天都会提醒我的团队，我们需要享受这一刻的每一刻，因为显然我认为这项技术的影响只会增长，这也会非常令人兴奋，但没有什么能像开始那样带来如此大的变化，以及学习的速度和一切。所以，我们只是在享受这个过程，但同时也非常清楚，我们处于一个领导地位，需要引导这项技术的未来方向，我们需要帮助世界能够以有效的方式使用它，同时确保它不会被用于我认为社会不希望的方式。因此，我认为我们也非常清楚，在这个位置上所承担的责任之重，确保我们做出的决定对未来是正确的。'
- en: 'Tim Ward: The Impact of Data Quality on LLM Implementations'
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'Tim Ward: 数据质量对LLM实施的影响'
- en: '**A.G.**: Of course, you’re the CEO of CluedIn, but what’s your role in the
    company? What’s CluedIn doing in terms of data management, data quality, and so
    on?'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 当然，你是CluedIn的CEO，但在公司中你的角色是什么？CluedIn在数据管理、数据质量等方面做了些什么？'
- en: '![](assets/aoas_07in05.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_07in05.png)'
- en: '**T.W.**: Yeah, sure. I’m actually joining you from a hotel room in Seattle.
    I am literally about 200 meters away from the Microsoft headquarters in Redmond,
    so I’ve been working with that group all week. This has a little bit to do with
    my role. I run the CluedIn team, I’m the CEO of CluedIn, but I come from a very
    product-driven software engineering background. I’ve been architecting products
    and building enterprise-grade products for some time. What we do at CluedIn is
    bring some pretty critical and necessary elements to Microsoft customers, and
    that is in the form of data quality and master data management (MDM).'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '**T.W.**: 是的，当然。我实际上是从西雅图的一家酒店房间加入你们的。我实际上就在雷德蒙德微软总部大约200米远的地方，所以我整个星期都在和那个团队一起工作。这和我扮演的角色有点关系。我领导着CluedIn团队，我是CluedIn的CEO，但我来自一个非常以产品为导向的软件开发背景。我已经在架构产品和构建企业级产品一段时间了。我们在CluedIn所做的是为微软客户提供一些非常关键和必要的元素，那就是数据质量和主数据管理（MDM）。'
- en: 'Data quality is probably one of those aspects we’re all aware of, we know we
    need to fix. MDM is somewhat one of those mysterious topics that I think people
    might even say is synonymous with data quality. What’s MDM versus data quality?
    At CluedIn, we really see there’s quite a lot of similarities between what data
    quality fixes and MDM. What we’ve really done is find those different elements
    or categories, and here is the kicker: CluedIn is a tool that’s really targeted
    at nontechnical users. That’s because we think that data quality doesn’t seem
    like one of those stubborn things that we’re always tripping over, and we know
    we need to do it. What we believe and what we’ve seen with our customers is we
    were never able to bring the business in and make them responsible for this. Often,
    the tooling was a little bit too complex, and so what I’m happy to say is that
    we bring those capabilities to anyone that’s in that Microsoft ecosystem. They’ve
    got Fabric, they’ve got maybe Purview, they’ve got Azure Data Factory. But at
    some point, they need to go, how do I bring the business in and have them play
    a role in this supply chain of data as well.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 数据质量可能是我们都意识到的那些方面之一，我们知道我们需要修复它。MDM是那些神秘话题之一，我认为人们甚至可能会说它与数据质量同义。MDM与数据质量有什么区别？在CluedIn，我们真正看到数据质量修复和MDM之间有很多相似之处。我们真正做的是找到那些不同的元素或类别，这里有一个关键点：CluedIn是一个真正针对非技术用户的工具。这是因为我们认为数据质量似乎不是那些我们总是跌倒的顽固事物之一，我们知道我们需要做这件事。我们相信的，以及我们从客户那里看到的，是我们从未能够将业务带入并让他们对此负责。通常，工具过于复杂，所以我很高兴地说，我们将这些能力带给任何在Microsoft生态系统中的人。他们有Fabric，可能有Purview，有Azure
    Data Factory。但到了某个时候，他们需要考虑如何将业务带入并让他们在这个数据供应链中发挥作用。
- en: '**A.G.**: Well, that’s amazing because I’m pretty sure you heard with this
    initial generative AI wave like…oh, we don’t need data anymore, so we don’t need
    to care about the quality. Then what happened, people were saying they would like
    to customize development and use their own data, but wait, we haven’t taken care
    of the data quality for a while, so what to do?'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 哇，这太令人惊讶了，因为我非常确信你听到了这个初始生成式AI浪潮，就像……哦，我们不再需要数据了，所以我们不需要关心质量。然后发生了什么，人们说他们想要定制开发并使用自己的数据，但是等等，我们已经有一段时间没有关注数据质量了，那该怎么办？'
- en: '**T.W.**: Exactly. Now, there’s somewhat a race condition here in that to yield
    value and insights with data, and specifically AI, we probably need AI to help
    us with the data quality piece. There’s this quite self-fulfilling recursive nature
    to the yin and the yang between solving data quality and actually yielding value
    AI. Spot on with, I think, your analogy there.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '**T.W.**: 正确。现在，这里有一种竞争条件，为了从数据中获得价值和洞察力，特别是AI，我们可能需要AI帮助我们解决数据质量问题。在解决数据质量问题和真正产生AI价值之间，有一种相当自洽的阴阳相生相克。我认为你的类比非常准确。'
- en: '**A.G.**: Yes. Before we go into the details of data quality, because I think
    it deserves some discussion here, but how was 2023 for CluedIn from a generative
    AI perspective? I know that you have been working on a lot of things, including
    your own product. How did you experience this?'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的。在我们深入探讨数据质量细节之前，因为我认为这里值得进行一些讨论，但2023年从生成式AI的角度来看，CluedIn的情况如何？我知道你一直在忙于很多事情，包括你自己的产品。你是如何体验这一过程的？'
- en: '**T.W.**: Many facets. Number one thing, being a company just “slightly” smaller
    than Microsoft, just slightly, that I guess we adopted AI ourselves, just internally
    as a business very early on, and it started with GitHub Copilot. It then progressed.
    Fortunately, due to our great relationship and partnership with Microsoft, we
    were given early access to Azure OpenAI in a private preview. That was something
    we instantly realized, wow, that’s how we’re going to build this in our own products.
    This also gave us a bit of time to learn about the guardrails that were necessary.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '**T.W.**: 有很多方面。首先，作为一个比微软“稍微”小一点的公司，我想我们很早就自己采用了AI，作为业务的一部分。这始于GitHub Copilot。然后它逐渐发展。幸运的是，由于我们与微软之间伟大的关系和合作伙伴关系，我们获得了对Azure
    OpenAI的早期访问权限，这是一个私人预览。我们立刻意识到，哇，这就是我们将在自己的产品中构建的方式。这也给了我们一些时间来了解必要的护栏。'
- en: You and I both know, Adrián, GenAI forms some pretty spectacular demonstrations,
    but being in the data management space and data governance and data quality, often
    the discussion goes to how do I make sure that our generative AI initiatives are
    actually going to survive the tumultuous nature of the enterprise? Is it secure?
    Is it governed? Do I have an audit trail of what happened? Is someone responsible
    for the data that’s being used? What about all the data sovereignty questions
    about where is data? Pretty early, we were having those discussions internally,
    but also with our early customer adopters that were saying, as soon as you guys
    start to implement AI in your platform, please let me know because there just
    seems like such an opportunity to apply AI to the actual data management practices
    itself, not just use it as an end consumption piece of software.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我们都知道，Adrián，生成式AI形成了一些相当惊人的演示，但在数据管理空间、数据治理和数据质量方面，讨论往往转向如何确保我们的生成式AI倡议能够真正地经受住企业动荡的本质？它是安全的吗？它是受管理的吗？我有没有发生事件的审计跟踪？谁对使用的数据负责？关于数据主权的问题，数据在哪里？我们很早就开始内部讨论这些问题，也与我们的早期客户采用者讨论，他们表示，一旦你们开始在平台上实施AI，请让我知道，因为似乎有如此多的机会将AI应用于实际的数据管理实践本身，而不仅仅是将其用作软件的最终消费部分。
- en: '**A.G.**: Which makes total sense from a Copilot point of view of interacting,
    of adding something to the user interface, we are saying, MDM or data quality
    in general, they are traditionally some sort of technical task, but we want to
    bring this to a business because they know their data, they know the information,
    so we can put this layer to infuse generative AI, and that’s what you guys did,
    and did it very early.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 从Copilot的角度来看，从交互、向用户界面添加内容的角度来看，我们说，MDM或数据质量在传统上是一种技术任务，但我们希望将其带入业务，因为他们了解他们的数据，他们了解信息，因此我们可以添加这一层来注入生成式AI，这正是你们所做，而且做得非常早。'
- en: '**T.W.**: Yeah. I would argue that’s been the biggest gap that we haven’t been
    able to bring the business into, because we often give them this software and
    we say, hey I bought this great MDM platform for you, just put all your data quality
    rules in there. Then someone comes in and says, OK, it says put a regular expression.
    Sorry, what’s a regular expression? I’ve been a software engineer for 19 years,
    and I still don’t know how to build regular expressions, but we’re asking people
    to somehow do this and that’s how they’ll play a role. And I think that’s why
    often these initiatives get thrown back to IT naturally because this seems like
    it’s for them. Then IT says, “No, I’ve got my tools, I’ve got Fabric, and I’ve
    got Azure Data Factory, that allows me to play my role, but it asks me to be very
    technical.” You could argue, Adrián, haven’t we been trying to bring the business
    in for 30 years? What has changed? Well, apart from the fact technology has just
    changed in general, getting access to different software is easier and easier
    all the time, and the cloud of course brought part of that.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '**T.W.**: 是的，我认为这是我们一直没有能够将业务带入的最大差距，因为我们经常给他们提供这种软件，然后说，嘿，我为你买了一个很棒的MDM平台，你只需要把所有的数据质量规则放进去。然后有人进来问，好的，它说要放一个正则表达式。抱歉，什么是正则表达式？我已经做了19年的软件工程师，我仍然不知道如何构建正则表达式，但我们却要求人们做这样或那样的事情，这就是他们的角色。我认为这就是为什么这些倡议往往自然地被推回给IT，因为这看起来像是为他们准备的。然后IT部门会说，“不，我们有自己的工具，我们有Fabric，我们有Azure
    Data Factory，这让我能够扮演我的角色，但它要求我非常技术化。”你可以争论，Adrián，我们不是已经尝试将业务带入30年了么？有什么变化？好吧，除了技术本身一直在变化之外，获取不同软件的途径越来越容易，当然，云也带来了其中的一部分。'
- en: The other piece is we’ve been handed in this nice little wrapped up bow an easy
    way to interact with LLMs; that is that chasm, it’s that bridge between, you can
    tell me what you intend and I’ll translate it underneath into what the underlying
    system needs. Because the thing is, for detecting patterns in data, especially
    in a deterministic way, regular expressions are somewhat just the way we do that.
    You need some underlying function to be able to do that, especially in a cost-efficient
    economic way. We can’t at this point, which is one of the things I’m looking forward
    to, we can’t just throw a large language model at every problem. Actually, we
    shouldn’t. I personally wouldn’t sleep as well if I realized my whole supply chain
    was just running off a model that sometimes gets things right and sometimes gets
    things wrong. It’s that bridge, how do I use the general knowledge to bridge that
    technical thing that these tools will still ask you to do, but now it’s not so
    much in this very like, oh, I need to be technical to do it.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，我们得到了一个简单易行的方式来与大型语言模型（LLMs）互动；那就是那个鸿沟，它是连接我们的桥梁，你可以告诉我你的意图，我会将其翻译成底层系统所需的内容。因为，对于在数据中检测模式，尤其是在确定性方式下，正则表达式只是我们这样做的一种方式。你需要一些底层函数来实现这一点，尤其是在成本效益和经济的方式下。目前我们做不到这一点，这也是我期待的事情之一，我们不能把大型语言模型应用到每一个问题上。实际上，我们也不应该这样做。如果我发现我的整个供应链只是运行在一个有时对有时错的模型上，我恐怕会睡不好觉。这就是那个桥梁，我如何使用一般知识来弥合这些工具仍然要求你做的技术问题，但现在这并不是那么需要技术。
- en: '**A.G.**: These are the cases where when we’re interacting with the tools,
    or we are processing information, or we are trying to fulfill some JSON file by
    using generative AI, the engine itself becomes more deterministic. It’s like we
    are not giving that much creativity because we are trying to find that connection
    with the system. In your case, you have software, you have a backend layer with
    all the data, you are connected to the data. I think that that’s the perfect example
    of evolution on the interfaces. When Bill Gates said this is like the evolution
    from the command line to Windows, and then from Windows to this kind of generative
    AI interface. How do you see the relationship? I know that this is not an answer
    for now, it could be an answer for later, and for later, and for later on the
    roadmap of the different products. But how do you see the current relationship
    between a company like CluedIn, or even the MDM and data quality solution, and
    the Azure OpenAI engine?'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**：这些是我们与工具互动、处理信息或尝试通过使用生成式AI来满足某些JSON文件的情况，引擎本身变得更加确定。就像我们并没有给予太多创造力，因为我们试图与系统建立联系。在你的情况下，你有软件，你有包含所有数据的后端层，你与数据相连。我认为这是界面进化的一个完美例子。当比尔·盖茨说这是从命令行到Windows，再到这种生成式AI界面的进化时，你怎么看待这种关系？我知道这现在不是一个答案，它可能是未来的答案，在产品路线图上的未来答案。但是，你怎么看待像CluedIn这样的公司，甚至MDM和数据质量解决方案，与Azure
    OpenAI引擎之间的当前关系？'
- en: '**T.W.**: So I think the relationship is somewhat symbiotic, and a good example
    is the plug-in architecture for Azure OpenAI. The fact that you can plug in something
    like Uber, KAYAK, or TripAdvisor, and the LLM knows. I know when you want general
    chat and general knowledge, but then I also can do the smart thing of saying,
    actually, when do you just want to talk to KAYAK or TripAdvisor, and book a trip?
    A very similar thing happens on the data management side, via CluedIn’s copilot
    that we have in our platforms, very similar to what you have in Microsoft 365
    or Power BI, or up-and-coming Fabric. If you had a big dataset with a million
    records, right now, without actually training your own model on that data, there’s
    really no easy way via context windows to just, not in an economically viable
    way anyway, to say what’s the value in column 4 in row 464,000? But the symbiosis
    is, how do I translate that language into an underlying language that can then
    do that query in a very efficient way? That could be translating it locally into
    SQL. In our case, it’s translating it locally into something like an elastic search
    query that says, I’ll build the query, so the LLM is not actually looking at a
    million records, it’s transposing into the local environment.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '**T.W.**: 所以我认为这种关系是某种共生关系，一个很好的例子是Azure OpenAI的插件架构。你可以插入像Uber、KAYAK或TripAdvisor这样的东西，而LLM知道。我知道当你想要一般聊天和一般知识时，但我也可以做到聪明的事情，比如说，实际上，你什么时候只想和KAYAK或TripAdvisor聊天并预订一次旅行？在数据管理方面，通过我们平台上的CluedIn的copilot，发生着非常类似的事情，就像你在Microsoft
    365或Power BI或新兴的Fabric中看到的那样。如果你有一个包含一百万条记录的大数据集，现在，实际上没有在那些数据上训练自己的模型，真的没有通过上下文窗口以经济可行的方式说出第4列第464,000行的价值。但共生之处在于，我如何将这种语言翻译成底层语言，然后以非常高效的方式执行查询？这可能是将其本地翻译成SQL。在我们的案例中，它被翻译成类似弹性搜索查询的东西，比如说，我会构建查询，这样LLM实际上并没有查看一百万条记录，它是在本地环境中进行转换。'
- en: Listen, I think at some point you will have these unlimited token sizes where
    you can either just say, I want the whole one million rows in the context, or
    potentially it’s going to be…load that data into a model, and your copilot is
    running off your custom model. And Azure AI Studio is a great tool that makes
    it so easy already to build your own copilot of Llama and Mistral and things like
    this, and also throw your own data from quite heterogeneous file types as well.
    Everything from PDF to images, to CSV, to Excel, to text, to video, and even C#
    and SQL files, it can swallow that stuff up. At some point, you are going to get
    to a point where you might not even need to do that local translation in all situations.
    You could literally talk to your entire data estate with a native feel in chat.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 听着，我认为在某个时候，你将会有这些无限的令牌大小，你可以要么只说，我想要整个一百万行的上下文，或者可能它将是……将数据加载到模型中，你的copilot正在运行你的自定义模型。Azure
    AI Studio是一个伟大的工具，它使得构建自己的Llama和Mistral等copilot变得非常容易，同时也可以处理来自各种异构文件类型的数据。从PDF到图像，再到CSV、Excel、文本、视频，甚至C#和SQL文件，它都能处理这些。在某个时候，你可能会达到一个点，你甚至不需要在所有情况下进行本地翻译。你实际上可以用聊天的方式与你的整个数据资产进行交流，感觉就像是在本地一样。
- en: '**A.G.**: Yes, there is another discussion with Dr. John Maeda, he was mentioning
    the notion of plug-ins, everything is interacting, and we are even building the
    code based on needs. It’s like function calling, but imagine automatic function
    calling, on which the model can realize, I need to check on my storage or Cosmos
    DB, I need to check on whatever source of information I have. Even more, if I
    was imagining (and I know this interview is about asking you questions), but just
    imagining the future, and this is not even related to roadmaps or whatever, but
    imagine in the future you have your data state, then you are handling general
    data governance with a solution like Purview, then you are going to the details
    of data quality and MDM to prepare all the data, and then there’s a smooth two-clicks
    way to push to a data store.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的，还有与约翰·梅达博士的另一个讨论，他提到了插件的概念，一切都在互动，我们甚至根据需求构建代码。这就像函数调用，但想象一下自动函数调用，在这个基础上，模型可以实现，我需要检查我的存储或Cosmos
    DB，我需要检查我所拥有的任何信息源。更进一步，如果我是在想象（我知道这次采访是关于向你提问的），但只是想象一下未来，这甚至与路线图或任何东西无关，想象一下在未来，你拥有你的数据状态，然后你使用Purview这样的解决方案来处理一般数据治理，然后你进入数据质量和MDM的细节来准备所有数据，然后有一个平滑的两击推送方式到数据存储。'
- en: '**T.W.**: I then have to comment on this, Adrián, because very early on when
    OpenAI came out, almost within a matter of days, this concept of LangChain came
    out as well, in that I want to chain multiple things together, and of course this
    was one thing we said is we have to have this included, because what we want via
    the plug-in architecture is to say, go get me all of our employee files that we
    have, bring them in, map them into the same concept, and trade the semantics of
    column names for me. If you’ve got F name, first name, first, of course it easily
    swallows that up, but in many cases you might bring on an SAP system, and it’s
    column names, not that obvious, they are German acronyms in a lot of cases. And
    for it to be able to chew that up and say, “I know what you mean,” but then to
    chain things, and then after that, check every column and apply appropriate data
    quality checks, and that’s the one thing I love, the fact that you can just be
    very dynamic. That you’re not being prescriptive and saying, “No please enforce
    this standard of phone numbers,” that will work, but also the fact you can be
    very dynamic and fluid in the way you interact.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '**T.W.**: 我必须对此发表评论，阿德里安，因为在OpenAI出现之初，几乎就在几天之内，LangChain这个概念也随之出现，我想将多个事物串联起来，当然这也是我们说必须包含在内的原因，因为通过插件架构，我们想要的是获取我们所有的员工文件，将它们导入，将它们映射到相同的概念，并为我转换列名语义。如果你有F名，即名字，那么它很容易就吸收了，但在许多情况下，你可能会引入一个SAP系统，它的列名并不明显，在许多情况下是德语缩写。而且为了让它能够理解并说“我知道你的意思”，然后将其串联起来，之后检查每一列并应用适当的数据质量检查，这正是我最喜欢的一点，那就是你可以非常灵活。你不是在规定性地要求，比如说，“请强制执行电话号码的标准”，这会有效，但你也可以非常灵活和流畅地互动。'
- en: I am in the data government space, but to be honest, I don’t know ISO codes
    off the top of my head, I don’t know how fun that person would be at a party if
    they actually did know that, and you’re wanting the large language model—the truth
    is it knows that stuff, it knows the ISO codes, it knows what they do and that
    chaining of things, I think this is what takes the use of GenAI from something
    that saves you 5, 10 seconds, to something that genuinely saves hours of research
    or trial and error. And that’s where I think the key thing is in bringing it into
    products, we have this kind of standard or set of ethics we have on the use of
    AI in our product, and we take a couple of these from inspiration from Microsoft
    as well, one of them being your data is your data, we’re never going to use cross-customer
    data to train this general model.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 我在数据治理领域，但说实话，我并不清楚ISO代码，我不知道如果那个人真的知道这些，在聚会上会有多有趣，而你希望大型语言模型——实际上它知道这些，它知道ISO代码，它知道它们的作用以及这些事物的串联，我认为这正是将GenAI的使用从节省你5到10秒的事情转变为真正节省数小时研究和试错的时间的关键。我认为关键在于将其引入产品中，我们对我们产品中AI的使用有一套标准或伦理规范，我们也从微软那里汲取了一些灵感，其中之一就是“你的数据是你的数据”，我们永远不会使用跨客户数据来训练这个通用模型。
- en: But one of the ones we’ve added ourselves is, no AI for AI’s sake, and what
    that means is, if we build something on our platform, and actually you could probably
    do the same thing in the old way, probably faster or relatively the same, why
    bother using AI? You know a good example would be, it’s technically impressive
    in a chat to say “Find me all the employees that are over 64,” but actually by
    the time you’ve just used our rule builder, you’ve probably taken the same amount
    of time to do it by hand than using AI, and at that point it’s like, what’s the
    value there? And I would argue, it’s not so much. There are cases where it is
    smart, for example if I said, “Go get me all of our customers in the Nordic region,”
    and I don’t have to say, “where the country is Denmark or Iceland” or this or
    this. Now that’s great you’ve saved 15 seconds, but really the things we should
    be focusing on is, how did I save you complexity? How did I increase simplicity?
    And what were the things that saved me one or two hours, three days, that’s what
    we’re really trying to focus on here at CluedIn.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们自己添加的一个案例是，不要为了AI而使用AI，这意味着如果我们在我们平台上构建了一些东西，实际上你也许可以用旧的方式做同样的事情，可能更快或相对相同，为什么要使用AI呢？你知道，在聊天中声称“找到所有超过64岁的员工”在技术上给人留下深刻印象，但实际上当你使用我们的规则构建器时，你可能已经用与使用AI相同的时间手动完成了它，到那时，它就像，那里的价值在哪里？我会争论，价值并不大。有些情况下它是聪明的，例如，如果我这么说，“去找到我们所有在斯堪的纳维亚地区的客户，”我不用说我需要说“国家是丹麦还是冰岛”或这样那样。现在，你节省了15秒，但真正应该关注的是，我是如何为你节省复杂性的？我是如何增加简单性的？以及哪些事情为我节省了一两个小时，三天，这是我们真正在这里CluedIn上试图关注的。
- en: '**A.G.**: Yes, I love that vision of how the end-to-end architecture chains
    different functions that handle the data and AI activities of any company. But
    I am seeing cases in which people are using generative AI to re-create chatbots
    all the time, for example, because I want it to be deterministic, I want to use
    it like a knowledge base, and then I have 10 questions, 10 answers, and I say
    that’s not necessarily something we maybe want to do with generative AI. Do you
    have interesting stories or insights on how data quality is already impacting,
    either in a negative or positive way, generative AI implementations with Azure
    OpenAI, or any other technology? Like clients saying that because we have been
    working on data quality, and we have this data state properly done, we have seen
    the difference.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的，我喜欢这种端到端架构将不同功能链起来处理任何公司的数据和AI活动的愿景。但我看到一些案例，人们一直在使用生成式AI来不断重新创建聊天机器人，例如，因为我希望它是确定性的，我希望像使用知识库一样使用它，然后我有10个问题，10个答案，我说这并不一定是我们可能想要用生成式AI做的事情。你有没有有趣的故事或见解，关于数据质量已经如何影响，无论是负面还是正面，Azure
    OpenAI或任何其他技术的生成式AI实现？比如客户说，因为我们一直在做数据质量工作，我们已经正确地完成了数据状态，我们看到了差异。'
- en: '**T.W.**: One of the things that’s so interesting about the form factor of
    chatting to your data is that it surfaces bad data quality quicker than probably
    any other form factor like search, or anything like this. It becomes abundantly
    clear, and I think also it’s because people have high expectations of LLMs, so
    even when it does something slightly silly, in my head I go like, “I appreciate
    this so much, this is so amazing,” like with my children, I will forgive my ChatGPT
    more often than I don’t, and I think one of the cases is when you start throwing
    your own data into a LLM, what happens is the chat interface starts to surface
    your data quality issues really clearly.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '**T.W.**: 与你的数据聊天的一个非常有趣的地方是，它比其他任何形式，比如搜索或类似的东西，更快地暴露出数据质量问题。它变得非常明显，我认为这也是因为人们对LLM有很高的期望，所以即使它做了点愚蠢的事情，在我的脑海中，我会想，“我非常感激这一点，这太神奇了，”就像对我的孩子一样，我会更频繁地原谅ChatGPT，而不是不原谅它，我认为其中一个案例是你开始将你的数据投入LLM，发生的事情是聊天界面开始清楚地暴露你的数据质量问题。'
- en: A good example would be a case where, pulling in HR data on employees as part
    of a HR onboarding process, to make new employees feel a little bit like they
    don’t have to go and find out, “Who do I talk to about this and that?” Now of
    course they have a HR system where it’s tagged with information like, this person
    is a software engineer, and they’ve got these responsibilities, but also with
    the large amount of employees, it was improbable that that would be the best way
    to do it, so the form factor of being able to use your own natural language was
    great. What happened is when you typed in something like, “Can you give me the
    contact details for the person that knows the most about Azure OpenAI?” or something
    like this, it would come back very confidently and say, “Not a problem, I’ve got
    this and this and this phone number.” And you know, there’s a couple of challenges
    with that, number one is, you’re more confused now, the second thing is, without
    proper attribution, you’re not 100% aware if the AI is making this up.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 一个很好的例子是，在HR入职流程中，将员工的人力资源数据纳入其中，让新员工感觉他们不必去寻找，“我该找谁谈论这件事？”当然，他们有一个带有类似信息的HR系统，比如，这个人是一名软件工程师，他们有这些职责，但随着员工数量的增加，这种方式可能不是最好的，因此能够使用自己的自然语言的形式非常好。发生的情况是，当你输入类似“你能给我知道Azure
    OpenAI最多的人的联系方式吗？”这样的内容时，它会非常有信心地回复，“没问题，我这里有这个和这个电话号码。”当然，这里有几个挑战，首先是，你现在更困惑了，第二点是，如果没有适当的归属，你就不完全清楚AI是否在编造东西。
- en: One of the great elements about Azure AI Studio, and if you’re using that particular
    place to host your copilots and anything you’ve done with your custom models,
    you get attribution at a file input level, for free. The challenge is that the
    data lineage doesn’t start there, it started a long time ago in a different place,
    but you get it at one of the places where it landed, so you could put it into
    your AI model, but actually the lineage of what happened to that file, where was
    the source system, what happened along the way, who changed what, why did they
    change this…this is some of the lineage that things like Microsoft Purview brings
    in at an asset level, and CluedIn is bringing us at a record level. Purview can
    say, these four assets on employee data were fed into your model, great. Then
    CluedIn says, see that Martin there, and that Martin there, there’s no way for
    me to stitch this data together, but I actually put those together into the same
    record, and so once you’re using the Copilot on this cleaner data, the answers
    are much more precise, and much more trustworthy because you can see…here is the
    phone number for Martin, oh, and that’s where I got it from, that’s what made
    me decide on it, so it becomes so abundantly clear, when you start to use the
    copilot, you’re like technology is great and super interesting, did it just make
    this up? And you’ll know from these AI models, they’re not self-aware. They cannot
    let you know if they made something up. Isn’t that a weird difference between
    the large language models and us? Like I am self-aware if I’ve made something
    up, but the LLM is not.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: Azure AI Studio 的一个重要元素是，如果你在那个特定的地方托管你的共飞行员（copilots）以及你用自定义模型所做的任何事情，你可以在文件输入级别免费获得归属。挑战在于数据溯源并不始于那里，它始于很久以前的一个不同地方，但你可以在数据最终到达的地方获得它，因此你可以将其放入你的AI模型中，但实际上，该文件的溯源，包括源系统是什么，过程中发生了什么，谁改变了什么，为什么他们要改变……这些都是像Microsoft
    Purview在资产级别引入的一些溯源，CluedIn在记录级别为我们带来的。Purview可以说，这些四个与员工数据相关的资产被输入到了你的模型中，很好。然后CluedIn说，看那里的Martin，还有那里的Martin，我无法将这些数据拼接在一起，但我实际上已经将它们放到了同一个记录中，因此一旦你在这个更干净的数据上使用共飞行员，答案就会更加精确，也更加可靠，因为你可以看到……这是Martin的电话号码，哦，还有我是从哪里得到它的，这就是我决定使用它的原因，所以当你开始使用共飞行员时，你会觉得技术很棒，超级有趣，它只是凭空想出来的吗？而且你会从这些AI模型中知道，它们没有自我意识。它们不能让你知道它们是否编造了东西。这不是大型语言模型和我们之间的一个奇怪差异吗？比如，如果是我编造了东西，我会意识到，但LLM（大型语言模型）不会。
- en: '**A.G.**: And it depends. I really like that, because imagine you are a data
    scientist, and you are performing an exploratory data analysis. If you don’t have
    the context on the business, you’re not able to understand if something that you
    see on the data, or even your own analysis, will be actually true, and I was thinking
    about that notion of EDA or exploratory data analysis, like the next barrier,
    because you have probably seen it in your projects. The best EDAs are those that
    include people who are from a mathematical and technical background, but also
    those that are from the business side, and usually they (business folks) don’t
    perform EDAs because they don’t have the technical means to explore the data,
    and to ask questions to the data.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 这取决于。我真的很喜欢这一点，因为想象一下，如果你是一名数据科学家，你正在进行探索性数据分析。如果你对业务背景没有了解，你就无法理解你在数据中看到的东西，甚至你自己的分析，是否真正是真实的。我一直在思考这种EDA（探索性数据分析）或探索性数据分析的概念，就像下一个障碍，因为你可能已经在你的项目中看到过它。最好的EDA是那些包括来自数学和技术背景的人，也包括来自业务方面的人，而通常他们（业务人士）不会进行EDA，因为他们没有技术手段来探索数据，向数据提问。'
- en: But this notion that you’re bringing, exploring the data and understanding that
    something is wrong, leads to the discussion where people are talking about “model
    hallucination.” I don’t like that expression, hallucination, because it’s not
    like a human, but they were talking about the model, and I feel like this chaining
    of capabilities shows that it’s not only about the model, it’s also about the
    data. Because you can have the best model, GPT-5 or whatever, and even if it’s
    very precise, we combine it with our information, which is feasible for a lot
    of scenarios, and we need to take care of that data so the LLM retrieves the good
    information. What’s your vision for these topics on generative AI in regards to
    CluedIn for this and the years to come? How do you see this evolution of a platform
    at a functional level?
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 但你提出的这个概念，即探索数据并理解某些东西是错误的，导致了一场讨论，人们谈论的是“模型幻觉”。我不喜欢这个表达，幻觉，因为它不像人类，但他们是在谈论模型，我觉得这种能力的连锁反应表明，这不仅仅关乎模型，也关乎数据。因为你可以拥有最好的模型，比如GPT-5，或者任何其他模型，即使它非常精确，我们结合我们的信息，这在很多场景下是可行的，我们需要注意这些数据，以便LLM检索到好的信息。你对这些关于生成式AI的话题有何看法？特别是关于CluedIn以及未来几年的发展？你如何看待这个平台在功能层面的演变？
- en: '**T.W.**: You know, the part where I realized that LLMs were something super
    powerful was the first time it clicked that I can translate my input to a targeted
    output, where I can say, here’s what I want, and can you actually return your
    answer, like this JSON structure? And it was at that moment that I went back to
    our team, and I said, all right, let’s look through all of the functionality that
    includes, and I want us to go through and really understand, could I use AI in
    every different part of the platform? And you could look at some of the things,
    like that when people make a change we cause an audit trail, and you can think,
    no, that’s like a log, why would AI have anything to do with that? And you realize,
    well, some of these records over time, they change a lot, and instead of having
    to go through a huge changelog, can I summarize the history of the change? And
    you could literally put this in all different places and have a net positive.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '**T.W.**: 你知道，我意识到LLM（大型语言模型）非常强大的那一刻，是我第一次意识到我可以将我的输入转换为有针对性的输出，我可以这样说，这是我想要的，你能实际返回这样的答案吗，就像这个JSON结构？就在那一刻，我回到我们团队，我说，好吧，让我们看看所有包含的功能，我希望我们真正理解，我能否在平台的每个不同部分使用AI？你可以看看一些事情，比如当人们做出改变时，我们会引发审计跟踪，你可以想，不，那就像一个日志，AI为什么要参与其中？然后你意识到，嗯，随着时间的推移，一些记录会发生变化很多，而不是要浏览一个巨大的变更日志，我能总结一下变更的历史吗？你几乎可以把这个应用到所有不同的地方，并且产生净正面效果。'
- en: For me, the vision is, where are the biggest wins? Where are the wins that are
    2 hours instead of 20 seconds? We need to focus on the things that actually are
    time-saving, and hit some type of business metric, make more money, lower operational
    costs, lower risk, complexity, etc. so we can just get things done without stressing
    all the time. So, I would argue to some degree, this space of AI is moving so
    fast, that for ChatGPT or even the DaVinci model, we haven’t milked all the value
    out of that. There’s just so much you could start to do, and, of course, the beautiful
    part is we get to wake up every day, and think…that same prompt, it’s just more
    reliable with an answer now, and I didn’t really have to do anything besides change
    to a model that also supports that functionality, like function calls, or completions,
    or something like that. For me, the vision of CluedIn’s use of GenAI is very much
    self-aware that you need AI to solve the data quality problem in a more complete
    way. You will still use traditional techniques that are kind of deterministic,
    I can sleep at night because it’ll do the same thing, every time, you still need
    those.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我来说，愿景是最大的胜利在哪里？那些需要2小时而不是20秒就能完成的胜利在哪里？我们需要关注那些真正能节省时间的事情，并达到某种业务指标，比如增加收入、降低运营成本、降低风险、复杂性等，这样我们就可以在不总是感到压力的情况下完成任务。所以，我可以说，在某种程度上，这个AI领域发展得太快，以至于对于ChatGPT甚至DaVinci模型，我们还没有完全挖掘出它们的价值。你可以开始做的事情太多了，而且，当然，美妙的部分是我们可以每天醒来，思考……同样的提示，现在有了答案，而且我实际上除了改变到一个也支持该功能（如函数调用、完成或类似的东西）的模型之外，真的不需要做任何事情。对我来说，CluedIn使用GenAI的愿景非常清楚，你需要AI以更完整的方式解决数据质量问题。你仍然会使用那种有点确定性的传统技术，我可以在晚上安心睡觉，因为每次它都会做同样的事情，但你仍然需要那些。
- en: And then, I think, what our job here at CluedIn is, I need to bring that to
    the data management process, so we can finally bring the business in, and make
    them responsible for data quality, because up to this point, I think it’s one
    of those elephants in the room we never talk about. Like why is data quality never
    cracked? Why is it never cracked? That’s just hard, and yes, it is, but actually,
    the thing is, we’ve never brought the business in and said, “Right, see this list
    of clients, that data comes from across 15 different places,” and so I love the
    fact that, even in their own 15 systems, it’s perfect.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我认为，我们在这里CluedIn的工作是，我需要将其带入数据管理流程，这样我们最终可以引入业务，让他们对数据质量负责，因为到目前为止，我认为这是房间里的大象，我们从未谈论过。比如为什么数据质量从未被解决？为什么从未被解决？这太难了，是的，它确实很难，但实际上，问题是，我们从未让业务介入并说，“好吧，看看这个客户列表，这些数据来自15个不同的地方，”所以我喜欢这样一个事实，即使在他们的15个系统中，它也是完美的。
- en: The problem, when we start to bring data together, is that there are things,
    despite all the governance that we could set up in the world, that take their
    own path, and someone needs to be responsible for that. And IT will still play
    a role in that, definitely in things like, “I can get the data to you reliably,
    I can get it with rollback, we can process it again really fast, we can scale,”
    but at the end of the day, someone from the business comes in and says, “That’s
    wrong and I know it because I work with this data every day.” And being an engineer
    myself, I know how to work with data, but I don’t know how to do those things,
    I have no idea how to just look at a record and go check if it meets all the right
    patterns. But I didn’t know that those were actually the same company, and there’s
    some real impact that happens if you don’t crack that, it could be as simple as
    sending the invoice to the wrong email address, and then you wonder why aren’t
    they paying us, and then you realize that’s not the team that pays it. And you
    go, “Wow, I’m now 30 days overdue,” and realistically, I need to send them another
    invoice and wait another 30 days,and cause maybe a cash flow issue. And you realize
    that’s where it really hits the bottom line, and you need to be exposed to that
    reality to then appreciate the effort of cracking that data quality. AI just in
    a way exacerbates the need for it, because as soon as you use it, it will stand
    out really obviously because of the form factor.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们开始汇集数据时的问题是，尽管我们可以在世界上设置所有的治理，但有些事情会走自己的路，有人需要对此负责。IT在这个问题中仍然会发挥作用，肯定是在像“我可以可靠地获取数据，我可以进行回滚，我们可以非常快地再次处理它，我们可以进行扩展”这样的东西上，但最终，业务部门的人会进来并说，“这是错误的，我知道，因为我每天都在处理这些数据。”作为一个工程师，我知道如何处理数据，但我不懂如何做这些事情，我不知道如何仅仅查看一条记录并检查它是否符合所有正确的模式。但我不了解这些实际上是同一家公司，如果你不解决这个问题，可能会很简单，比如把发票发送到错误的电子邮件地址，然后你不知道为什么他们不付我们钱，然后你意识到那不是付款的团队。然后你去，“哇，我现在已经逾期30天了，”实际上，我需要给他们发送另一张发票并等待另一个30天，可能造成现金流问题。你意识到这真的触及了底线，你需要了解这个现实，然后才能欣赏解决数据质量问题所付出的努力。AI只是以一种加剧了这种需求的方式，因为一旦你使用它，它就会因为形式因素而非常明显地突出出来。
- en: '**A.G.**: I love this part of the discussion. I was thinking about the roles
    and responsibilities of data governance in the company, even if you take a framework
    like DAMA or whatever, with the different roles, this is a new archetype, this
    is like the Ultron (Marvel reference) of the DAMA roles, like you have an Ultron
    (well, maybe not an Ultron, let’s get a Jarvis), a Jarvis working for you, to
    do the things that, let’s be honest, humans are not doing, because it’s a manual
    process, and we don’t have time to do that every time, every day, in a proper
    way.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 我喜欢这个讨论的部分。我在想公司中数据治理的角色和责任，即使你采用DAMA或任何框架，不同的角色，这是一个新的原型，这就像是DAMA角色的奥丁（漫威参考），就像你有一个奥丁（嗯，可能不是奥丁，让我们来一个贾维斯），一个为你工作的贾维斯，去做那些，让我们说实话，人类不做的事情，因为这是一个手动过程，我们没有时间每次、每天以正确的方式去做这些。'
- en: 'Seth Juarez: From Generative AI Models to a Full LLM Platform'
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'Seth Juarez: 从生成式AI模型到完整的LLM平台'
- en: '**A.G.**: So, what’s your role at Microsoft? What are you doing in the organization?'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 那么，你在微软的角色是什么？你在组织中做什么？'
- en: '![](assets/aoas_07in06.png)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aoas_07in06.png)'
- en: '**S.J.**: So, I work in the Azure AI platform as a program manager. My job
    is to work in incubations and narrative. Those are the two mandates that I have.
    Incubations, meaning we build stuff. For example, if we want to explain how something
    works, we will build prototypes, etc. Wherever those prototypes may differ from
    what our product is doing, we feed back into our product prioritization and what
    it is that we build, just to make sure that the narratives work out, which leads
    us to the second part. We also do technical narrative, which is to explain what
    is going on and how these things work. Again, anytime the ideal story doesn’t
    match with product truth, we feed back into our product group, and sometimes they
    even put us in charge of certain features. We’re like every person, the primary
    goal being incubations, building samples and stuff that help people understand
    how to do this, and then the technical narrative that follows from that.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.J.**: 所以，我在Azure AI平台工作，担任项目经理。我的工作是负责孵化和叙事。这是我拥有的两个任务。孵化意味着我们构建东西。例如，如果我们想解释某件事是如何工作的，我们会构建原型等。无论这些原型与我们的产品有何不同，我们都会将其反馈到我们的产品优先级和构建内容中，以确保叙事能够顺利进行，这引出了第二部分。我们还进行技术叙事，即解释正在发生的事情以及这些事物是如何工作的。同样，任何理想的故事与产品真相不符时，我们都会将其反馈给我们的产品团队，有时他们甚至会让我们负责某些功能。我们就像其他人一样，主要目标是孵化，构建帮助人们理解如何做到这一点的样本和东西，然后是随之而来的技术叙事。'
- en: '**A.G.**: You are like Marvel’s The Watcher, seeing everything that’s happening
    at the product level, accelerators, repositories, prototypes, and new functionalities.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 你就像漫威的《守望者》，看到产品层面发生的所有事情，加速器、存储库、原型和新的功能。'
- en: '**S.J.**: That’s right. But it’s not just me. Obviously, there’s a couple of
    us that work on this. For example, you may know [Cassie](https://oreil.ly/33PBM).
    She’s appeared on the [AI Show](https://oreil.ly/h-Fvw) as well, but her and I
    work together on this stuff.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.J.**: 对的。但这不仅仅是我的事。显然，我们有一群人在做这个。例如，你可能知道[Cassie](https://oreil.ly/33PBM)。她也出现在了[AI
    Show](https://oreil.ly/h-Fvw)上，但她和我一起做这个。'
- en: '**A.G.**: Wonderful. Thank you for the introduction. You have seen the whole
    evolution of Azure OpenAI Service, and the convergence with the rest of Azure
    AI Studio. How do you see something that started as a model, and now is becoming
    a platform, and a very good one with a lot of functionality?'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 太棒了。感谢你的介绍。你已经看到了Azure OpenAI服务的整个演变过程，以及与Azure AI Studio的融合。你是如何看待一个最初只是模型，现在却成为了一个功能丰富的平台？'
- en: '**S.J.**: That’s a great question. It turns out that there’s a lot of AI models
    and the Azure AI platform has been in the business of surfacing models, enabling
    you to customize these models and then enabling you to create your own models
    for a number of years, maybe half a decade already. The idea that a new model
    comes in, the reason why it was awesome for us is because we already had the infrastructure
    in place to make these models shine. While the new GPT series of models, and LLMs
    and AI models in general, may seem like a new thing when it comes to infrastructure
    and how these things are actually run, it’s not new to us. We were able to ramp
    up quickly and deliver these models to folks at scale, which is really nice, obviously
    in partnership with OpenAI.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.J.**: 这是一个非常好的问题。结果证明，有很多AI模型，Azure AI平台已经从事模型曝光的业务，让您能够定制这些模型，并且已经允许您创建自己的模型多年了，可能已经有半个世纪了。一个新模型的出现，它对我们来说之所以如此出色，是因为我们已经有基础设施来让这些模型发光。虽然新的GPT系列模型、LLMs以及AI模型在基础设施和这些事物实际运行方式上可能看起来像是一件新事物，但这对我们来说并不新鲜。我们能够迅速扩大规模并交付这些模型给人们，这真是太好了，显然是在与OpenAI的合作下。'
- en: '**A.G.**: That was one of the things I was surprised about during these recent
    months, to see this model as a service. Basically, being able to consume the APIs
    so quickly and so easily, that was almost magic for any developer out there.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 这是我最近几个月感到惊讶的一件事，看到这个模型作为服务。基本上，能够如此快速、如此容易地消费API，这对任何开发者来说都几乎是魔法。'
- en: '**S.J.**: Yeah, and the cool thing is that the reason why it seemed magical
    is because we’ve been doing this, like I said, for a number of years with our
    Cognitive Services or AI services. We’ve been delivering, for example, text-to-speech,
    speech-to-text, translation, etc. as APIs. And those, if you think about them,
    are basically models as a service as well. They just happen to be more at the
    application layer, but it’s actually the same thing. These models as a service
    are similar. The weights happen to be different, and the model structure is different,
    but the things that are needed to run them are actually quite similar.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.J.**: 是的，而且有趣的是，它之所以看起来神奇，是因为我们像我说的一样，已经用我们的认知服务或AI服务做了这件事好几年了。我们一直在通过API提供，例如，文本到语音、语音到文本、翻译等。如果你想想，它们基本上也是模型即服务。它们只是碰巧更多地处于应用层，但实际上是同一件事。这些模型即服务是相似的。权重可能不同，模型结构也不同，但运行它们所需的东西实际上非常相似。'
- en: '**A.G.**: Yes, I like this convergence with the AI Studio and the model catalog.
    Just to see all the models available out there, and not only Azure OpenAI. How
    do you see this platform evolving, in which we have different models, a full catalog,
    so easy to deploy, with the APIs out there, we just consume them, we have Llama,
    Mistral, and then we have this ecosystem of prompt flow that I know is another
    part of the platform, all the evaluation, etc. What’s going on? How do you see
    it?'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的，我喜欢AI Studio和模型目录的这种融合。只是为了看看所有可用的模型，而不仅仅是Azure OpenAI。您如何看待这个平台的发展，其中我们有不同的模型，一个完整的目录，部署起来非常容易，有API可供使用，我们只需消费它们，我们有Llama、Mistral，然后我们还有这个提示流生态系统，我知道这是平台的一部分，所有的评估等等。发生了什么？您如何看待它？'
- en: '**S.J.**: Yeah, that’s a wonderful question. It turns out that we want to commoditize
    the ability for folks to find, consume, and refine models. That’s basically what
    we want to do. So generative AI happens to be one of the most exciting in my opinion.
    For example, if you have an idea and you want to add AI to it, the basic thing
    is go to the model catalog, see if you can find something, look at some of our
    services, and see if you can incorporate it. My particular opinion on this, and
    this is something that I’m coming to realize, is that much like in the early 2000-2005s,
    if you didn’t have a phone app, an iPhone app, people were like…are you a technical
    company?'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.J.**: 是的，这是一个非常好的问题。结果是我们希望使人们找到、消费和改进模型的能力商品化。这正是我们想要做的事情。所以，在我看来，生成式AI恰好是最令人兴奋的之一。例如，如果你有一个想法并且想要添加AI，基本步骤是去模型目录，看看是否能找到一些东西，查看我们的服务，看看是否能将其整合。我特别的观点是，就像在2000-2005年早期，如果你没有手机应用，一个iPhone应用，人们会问：你们是一家技术公司吗？'
- en: My sense is that people will think the same thing when it comes to AI experiences
    inside of your applications, where people will think if you do not include these
    things that normalize human interaction with computers, they’re going to feel
    like your app might be fundamentally broken. We’re coming to a place where we
    will no longer have to adapt to computers, but computers will adapt to us using
    AI, making experiences more natural. So my sense is that we need to start thinking
    about how we can add those niceties and soften the edges around our software,
    and how can AI help with those experiences? My sense is that we’re going to start
    to see these things included wholesale into almost everything we do, to the point
    where someone’s going to come to you in 2025 and be like, wow, your app doesn’t
    have AI? Maybe you should add it, because people will feel like it may be fundamentally
    broken.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我的看法是，当涉及到应用程序中的AI体验时，人们会有同样的想法，他们会认为如果你不包含这些使人与计算机交互标准化的东西，他们可能会觉得你的应用可能从根本上是有缺陷的。我们正走向一个不再需要适应计算机，而是计算机通过AI适应我们的地方，使体验更加自然。所以我的看法是，我们需要开始思考如何添加这些细微之处，并软化我们软件的边缘，AI如何帮助这些体验？我的看法是，我们将开始看到这些事物被大量地整合到我们做的几乎所有事情中，到2025年，有人会来找你，说：哇，你的应用没有AI？也许你应该添加它，因为人们会感觉它可能从根本上是有缺陷的。
- en: '**A.G.**: I love it. This is very related to the discussion we were having
    with Dr. John Maeda on Semantic Kernel, and the influence of design for artificial
    intelligence, and then this reflection about how AI just brings a new kind of
    interface, which is way beyond just the visual interface that we know today. And
    I know that this is just a personal opinion, something that you imagine, but what’s
    your vision of what’s going to happen in the next one or two years?'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 我非常喜欢这个。这与我们与约翰·梅达博士讨论语义内核以及人工智能设计的影响非常相关，以及关于AI仅仅带来一种新界面的反思，这种界面远远超出了我们今天所知道的视觉界面。我知道这仅仅是一个个人观点，一些你想象的东西，但你对未来一两年内会发生什么有什么看法？'
- en: '**S.J.**: Two things, and they’re going to seem diametrically opposed, but
    they work together. The first is the expansion and proliferation of the use of
    these models inside of software. You’re going to see these models being used to
    do all sorts of things, to make experiences more delightful, to make experiences
    more user and customer focused. You’re going to see a big expansion of the use
    of these models, and we’re already seeing that today. I mean, it’s only been like
    a year and a couple of months since ChatGPT came out, and it’s actually now everyone’s
    expecting it to be part of the experience. So that’s getting bigger in terms of
    the volume of people using these things.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.J.**: 两件事，它们看起来似乎是截然相反的，但它们是相互配合的。第一点是这些模型在软件中的应用的扩展和普及。你会看到这些模型被用于做各种事情，使体验更加愉悦，使体验更加以用户和客户为中心。你会看到这些模型的使用范围大幅扩大，而且我们现在已经看到了这一点。我的意思是，自从ChatGPT发布以来，还不到一年半的时间，现在每个人都期待它成为体验的一部分。所以，在用户数量方面，它正在变得越来越大。'
- en: But there are also things that are going to get smaller. There’s going to be
    more specialized GenAI models that are going to become smaller and that are going
    to be used in a more targeted way to do specific things. Like the GenAI models
    we have now are quite general and big. However, you can make small language models
    (SLM), much smaller but more targeted. The smaller the model, the more targeted
    the task you need to make it do. You’re going to see the proliferation of small
    language models included perhaps even on devices within the next two to three
    years. You’re going to have those experiences move into a native local experience
    as well as a larger cloud experience together, and together those models are going
    to work to really get to laser focus into what the customer experience is for
    each task that it’s solving, as well as a general way to actually solve other
    language problems. This is for language models, for example. Two diametrically
    opposed things, things are going to get bigger in terms of volume of people using,
    and things are going to get smaller in terms of the models that people use, and
    those two things are going to be used in combination, I think quite effectively.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 但也有一些事情会变得更小。会有更多专门化的通用人工智能模型，它们会变得更小，并且将以更有针对性的方式用于完成特定的事情。就像我们现在拥有的通用人工智能模型相当通用且规模很大。然而，你可以制作小型语言模型（SLM），它们更小但更有针对性。模型越小，你需要让它完成的任务就越有针对性。你将看到小型语言模型的普及，可能在接下来的两到三年内，甚至包括在设备上。这些体验将同时进入本地原生体验以及更大的云体验，并且这些模型将共同努力，真正聚焦于解决每个任务时的客户体验，以及以一般方式解决其他语言问题。这是针对语言模型的。两件截然相反的事情，一方面是使用人数的规模会变大，另一方面是人们使用的模型会变小，我认为这两者将非常有效地结合使用。
- en: '**A.G.**: I believe so. For the second point that you mentioned, this kind
    of multilayer or multimodal architecture on which we could dispatch our first
    model, depending on the topic that it identifies. We can even fine-tune that first
    model and then use GPT-4 for one purpose and another model for another purpose.
    How do you see it?'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 我相信是这样的。对于你提到的第二点，这种多层或多模态架构，我们可以根据它识别的主题来部署我们的第一个模型。我们甚至可以微调第一个模型，然后使用GPT-4来完成一个目的，另一个模型来完成另一个目的。你怎么看待这个问题？'
- en: '**S.J.**: I think that’s a great way of putting it. We’re going to get into
    this multimodal, which means multiple models, as well as multimodal, which means
    multiple modalities like maybe speech, vision, and text, for example.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.J.**: 我认为这是一种很好的表达方式。我们将进入多模态，这意味着多个模型，以及多模态，这意味着多种模态，比如可能是语音、视觉和文本，例如。'
- en: '**A.G.**: What about combining models of different providers?'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 那么结合不同提供商的模型呢？'
- en: '**S.J.**: Yeah, I think that’s great. In Azure, on Azure AI Studio, we really
    don’t care what models you bring, and we are trying to forge partnerships with
    multiple folks. We’ve [announced a partnership with Meta last year](https://oreil.ly/ehdf3),
    and some of the Llama 2 models are already in there. We recently [announced another
    partnership with Mistral](https://oreil.ly/SU0PT), and we have Mistral Large directly
    in our model catalog, and some of these models you can even fine-tune.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.J.**: 是的，我认为那很好。在Azure的Azure AI Studio上，我们真的不在乎你带来什么模型，我们正在尝试与多个人建立合作伙伴关系。我们去年[宣布与Meta的合作](https://oreil.ly/ehdf3)，其中一些Llama
    2模型已经包含在内。我们最近[宣布与Mistral的另一项合作](https://oreil.ly/SU0PT)，Mistral Large直接在我们的模型目录中，其中一些模型你甚至可以进行微调。'
- en: But the reality is that the Azure AI platform is built on top of something we
    call Azure Machine Learning Studio, a general-purpose machine learning, MLOps
    platform for you to build any model that you like. In theory, you could start
    from something like PyTorch or TensorFlow, build your own model or do any code,
    and you could train those models directly in Azure Machine Learning, and surface
    them in AI Studio. The reality is, we really don’t care what AI models you bring,
    whether they’re stuff that we’ve forged through partnerships or things that you
    literally make yourselves, all of those things should and will be available to
    you in your applications.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 但现实是，Azure AI平台是建立在Azure Machine Learning Studio之上的，这是一个通用的机器学习、MLOps平台，你可以用它来构建你喜欢的任何模型。从理论上讲，你可以从PyTorch或TensorFlow这样的东西开始，构建你自己的模型或进行任何编码，你可以在Azure
    Machine Learning中直接训练这些模型，并在AI Studio中展示它们。但现实是，我们真的不在乎你带来什么AI模型，无论是我们通过合作伙伴关系锻造的东西，还是你亲自制作的东西，所有这些都应该并且将在你的应用程序中可用。
- en: '**A.G.**: Even that curation of models from Hugging Face, we have basically
    a variety of good models out there.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 即使是从Hugging Face精心挑选的模型，我们基本上有各种各样的好模型。'
- en: '**S.J.**: Yeah, Hugging Face is an amazing partner. They’ve done a really good
    job of surfacing tons of functionalities, and we hope that with those functionalities,
    you will be able to deploy and use them reliably in your applications.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.J.**: 是的，Hugging Face是一个了不起的合作伙伴。他们做了很多工作，展示了大量的功能，我们希望这些功能能够让你在应用程序中可靠地部署和使用。'
- en: '**A.G.**: Yes, and you mentioned machine learning operations (MLOps), now LLM
    operations, and we know that this is a new area. We’ve been discussing responsible
    AI. But if we go to the core aspect of measuring the performance of the models,
    how do you see this? Because this is evolving and getting more and more complex
    but also more intuitive. Because one year ago, it was not easy to know how to
    measure the performance of an LLM. I think that is getting clear now. Where are
    we going with that part?'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的，你提到了机器学习操作（MLOps），现在变成了LLM操作，我们知道这是一个新领域。我们一直在讨论负责任的AI。但如果我们要深入到衡量模型性能的核心方面，你是如何看待这个问题的？因为这是在不断发展，变得越来越复杂，但也越来越直观。因为一年前，知道如何衡量LLM的性能并不容易。我认为现在这个问题已经变得清晰了。我们在这一部分将走向何方？'
- en: '**S.J.**: Great question. We’ll start first with DevOps. DevOps is not an old
    concept, but it’s one that’s pretty well known. DevOps is a union of people, processes,
    and products to enable the continuous delivery of value. MLOps is the same thing.
    The union of people, processes, and products enable a continuous delivery of value,
    but with machine learning, LLMOps is the same thing but with LLMs. The idea of
    unifying this three-legged stool, people, process, and products, is super important.
    Because the thing about DevOps, LLMOps, and MLOps is that a product is not going
    to solve your process problem, and it’s not going to solve a people problem. If
    people don’t buy into the process, then no tool is going to satisfy that need.'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.J.**: 这是一个很好的问题。我们首先从DevOps开始。DevOps不是一个老概念，但它是相当为人所知的。DevOps是人员、流程和产品的结合，以实现价值的持续交付。MLOps也是如此。人员、流程和产品的结合实现了价值的持续交付，但与机器学习相结合，LLMOps与LLMs相同。统一这个三脚架——人员、流程和产品——的想法非常重要。因为关于DevOps、LLMOps和MLOps，一个产品不能解决你的流程问题，也不能解决人员问题。如果人们不接受这个流程，那么没有任何工具能够满足这种需求。'
- en: I think that’s the first thing to bring out is that there is no magic bullet
    or elixir or product that’s going to solve a process thing, and the fact that
    people buy into the process. That’s the first thing. The second thing is, once
    you do want to buy into a process, people want to buy into a process, the question
    is what do we do in LLMOps to make this process reliable and useful, when it comes
    to how we evaluate the prompts that we do, and how to evaluate or how to make
    sure that the thing is working in production. In Azure AI Studio, we have a number
    of ways to do that.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为首先需要明确的是，没有一劳永逸的解决方案、灵丹妙药或产品能够解决流程问题，以及人们对于流程的认同。这是首要的事情。第二点是，一旦人们想要认同某个流程，那么在LLMOps中，我们应该如何确保这个流程的可靠性和实用性，尤其是在评估我们使用的提示词以及如何评估或确保生产中的事物是否正常工作方面。在Azure
    AI Studio中，我们有多种方法来实现这一点。
- en: 'There’s two kinds of evaluations that I think exist (but obviously, this is
    an evolving space, and so we’re learning a ton here too). But the two kinds are
    unsupervised checks and then supervised checks. Supervised checks are probably
    the easiest. Imagine you have a call to an LLM and you want to make sure that
    it gets a certain answer out that’s similar to what you have. Basically, you would
    need to have a dataset of inputs and the expected outputs. To me, that’s a supervised
    test because you have the answer that you want. There’s a number of metrics that
    you can do. Here’s a simple one: for example, you can take the answer that’s ground
    truth, project that into, for example, an Ada embedding or any other embedding,
    and take the answer that the LLM gives you, project that into an LLM embedding
    and then measure the angle. Maybe there’s a particular tolerance that you have
    that gives a semantic closeness or meaning. That’s one way of checking.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为存在两种评估方式（但显然，这是一个不断发展的领域，因此我们在这里也在学习很多）。但两种评估方式是无监督检查和监督检查。监督检查可能是最简单的。想象一下，你调用了一个LLM，并想要确保它给出一个与你的预期相似的答案。基本上，你需要有一个输入和预期输出的数据集。对我来说，这是一个监督测试，因为你已经有了你想要的答案。你可以进行多种度量。这里有一个简单的例子：例如，你可以将真实答案投影到，比如说，一个Ada
    embedding或其他任何嵌入中，然后将LLM给出的答案投影到一个LLM embedding中，然后测量角度。也许有一个特定的容忍度可以给出语义接近度或意义。这是一种检查方式。
- en: You can also use what we like to call GPT star metrics where you have the ground
    truth, and once you get the ground truth, you give that to a GPT star metric like
    similarity, and you ask the LLM as a language problem, how similar are these things
    on a scale of one to five? You give it some few-shot learning. That’s an example
    of two supervised learning methodologies, one that’s more empirical and one that’s
    more stochastic because it’s using the actual LLM to do it. The other one is also
    stochastic because it’s using embeddings, but you have a way of just projecting
    these things and then measuring an actual metric.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以使用我们喜欢称之为GPT star metrics的方法，其中你有真实数据，一旦你获得了真实数据，你就可以将其提供给GPT star metric，比如相似度，然后你作为语言问题向LLM询问，这些事物在一到五的尺度上有多相似？你给它一些少样本学习。这是一个监督学习方法的例子，一个更经验性的，另一个更随机的，因为它使用了实际的LLM来完成。另一个也是随机的，因为它使用了嵌入，但你有一种方法可以仅将这些事物投影出来，然后测量一个实际指标。
- en: 'Then there’s these other ones that I like to call unsupervised that look at
    the structure of the actual thing that’s going into the prompt and the context,
    and with the answer it measures what the structural integrity of the entire thing
    is. Let me give you one example: groundedness, which is a measure of how grounded
    the answer is in the context that was given to the LLM. For example, and this
    is the canonical example we use, we have a “Contoso” outdoor store and you ask
    a question about tents. Notice you have the question and then whatever the answer
    is, but the internal structure of the prompt flow or LangChain or whatever you’re
    using fetches some information from a data source, which we know to be true. That
    to me is the context, and that generally gets embedded directly into the prompt
    in something we call retrieval-augmented generation (RAG). You get the question,
    you fetch some data, you put it into the prompt. With this particular call to
    the LLM, you have a question, you have the answer, and then you have the context
    that was fetched. With those three things, we’re going to measure something called
    groundedness, which is how grounded the answer is that we fetched in the context,
    the answer that it generated from the context that we fetched. This is a normal
    interaction. You might ask me a question and I’ll start answering with facts and
    good faith, and you might say, “No, that’s not what I meant” and that’s totally
    cool. We want the LLM to be grounded in that way.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 然后还有一些我喜欢称之为无监督的，它们关注的是实际进入提示和上下文的结构，以及答案，它衡量的是整个结构的完整性。让我给你举一个例子：扎根度，这是衡量答案在提供给
    LLM 的上下文中的扎根程度的指标。例如，这是我们常用的一个典型例子，我们有一个“Contoso”户外商店，你问了一个关于帐篷的问题。注意，你有问题，然后无论答案是什么，但提示流或
    LangChain 或你使用的任何内部结构都会从数据源中获取一些信息，我们知道这是真实的。对我来说，这就是上下文，它通常直接嵌入到我们称之为检索增强生成（RAG）的提示中。你得到问题，你获取一些数据，你将其放入提示中。在这个特定的
    LLM 调用中，你有一个问题，你有一个答案，然后你有获取的上下文。有了这三样东西，我们将衡量一种叫做扎根度的东西，即我们获取的答案在上下文中的扎根程度，以及它从我们获取的上下文中生成的答案。这是一个正常的交互。你可能会问我一个问题，我会开始用事实和诚意回答，然后你可能会说，“不，这不是我想要的”那是完全正常的。我们希望
    LLM 以这种方式扎根。
- en: There’s a measurement on a scale of one to five of how grounded the answer is
    in the context we fetched and the question that was given, which is super nice.
    It turns out that this measurement is another GPT star metric where we give the
    question/context/answer, and then we say, “On a scale of one to five, how grounded
    is the answer in the context?” and then we do some few-shot learning in the actual
    prompt. This is something that you can also control. For example, you can change
    the entire groundedness prompt to directly match your few-shot learning priorities.
    Let’s just say you’re an outdoor company, you put those things in there and it’s
    able to do that. Those are the two kinds of evaluations that I see coming out.
    A supervised one where you have ground truth and you measure ground truth against
    the answers, and then unsupervised evaluations where you’re measuring the internal
    consistency of the truth versus the answers that you provide.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 有一个衡量答案在获取的上下文和给出的问题中的扎根程度的量表，从一到五，这非常棒。结果证明，这个衡量标准是另一个 GPT 星级指标，我们给出问题/上下文/答案，然后我们说，“在一到五的量表上，答案在上下文中的扎根程度如何？”然后我们在实际的提示中进行一些少样本学习。这也是你可以控制的事情。例如，你可以改变整个扎根度提示，直接匹配你的少样本学习优先级。假设你是一家户外公司，你把这些东西放进去，它就能做到这一点。这些都是我看到即将出现的两种评估类型。一种是监督评估，你有一个真实情况，你将真实情况与答案进行衡量，然后是无监督评估，你是在衡量真实与提供的答案之间的内部一致性。
- en: There are other ones like fluency, coherence, relevance, and those are all GPT
    star unsupervised metrics, and you can even invent your own. There’s some clever
    ones that folks have invented like the apology metric, which is how many times
    it apologizes, and do we want to minimize that. But you’ve entered basically a
    world where you can evaluate these things in a way that is tailored to your business
    needs, your voice, and maybe even your ground truth, if that makes sense.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他一些，比如流畅性、连贯性、相关性，这些都是 GPT 星级无监督指标，你甚至可以发明自己的。有些人发明了一些很巧妙的指标，比如道歉指标，它衡量的是道歉了多少次，我们是否希望最小化这个数值。但你现在基本上进入了一个可以按你的业务需求、你的声音，甚至可能是你的真实情况来评估这些事物的世界，如果这样理解的话。
- en: '**A.G.**: That’s why the platform evolves so much along with the evaluation
    flows that we have on the platform, and what we can do with these metrics. By
    the way, you have explained this in a better way than the book. This is why I
    wanted to interview you, because I know that you are so good at explaining these
    terms! This is amazing.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 这就是为什么平台会随着我们在平台上拥有的评估流程以及我们可以使用这些指标的能力而不断进化。顺便说一句，你比书中的解释更好。这就是为什么我想采访你，因为我知道你非常擅长解释这些术语！这太棒了。'
- en: '**S.J.**: Yeah. It’s like I said, I remember talking to some nontechnical folks,
    business folks, and they were concerned about using these LLMs because they’re
    like, well, how do we ensure that they’re doing the right thing? I showed them
    and they’re like, oh, so I can use English or the language of my choice, because
    they are trained in multiple languages, to actually evaluate these models. And
    I said, absolutely, and that’s not all. For those unsupervised tests, notice that
    you do not need ground truth. As you deploy in Azure AI Studio, you have something
    called a model data collector, which enables you to capture the input/context/answer
    and store it in your storage (we don’t see any of this stuff, we take this very
    seriously). Then even in production, you’re able to create jobs that look at this
    data and measure those same metrics, and even alerts you when those things go
    out of whack.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.J.**: 是的。就像我说的，我记得和一些非技术人士、商业人士交谈过，他们担心使用这些LLM，因为他们会问，我们如何确保它们做的是正确的事情？我向他们展示了，他们就像，哦，所以我可以用英语或我选择的任何语言，因为它们在多种语言中受过训练，实际上可以评估这些模型。我说，绝对可以，而且不止如此。对于那些无监督测试，请注意，你不需要真实数据。当你部署在Azure
    AI Studio时，你有一个叫做模型数据收集器的东西，它使你能够捕获输入/上下文/答案并将它们存储在你的存储中（我们看不到这些内容，我们非常重视这些）。然后即使在生产中，你也能创建查看这些数据并测量相同指标的工作，甚至当这些指标出现问题时还会提醒你。'
- en: Now we’re getting into the actual LLMOps, which enables the continuous delivery
    of value. That’s the thing. If the value goes down, you need to be alerted and
    to fix it, and then have that go back into the process. With these unsupervised
    evaluations and metrics, you’re able to actually run them on a subset of your
    production data if you so choose, which makes this even better for folks who are
    concerned about these things staying on track in inference time or production.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们正在进入实际的LLMOps，它使得价值的持续交付成为可能。这就是关键所在。如果价值下降，你需要被提醒并修复它，然后让它回到流程中。通过这些无监督评估和指标，如果你选择的话，你实际上可以在你的生产数据的一个子集上运行它们，这使得这对那些担心这些事情在推理时间或生产中保持一致的人更加有利。
- en: '**A.G.**: That’s amazing. I just want to see the roadmap of what’s coming next
    in this aspect, because there is so much discussion on LLMOps, but it’s such an
    initial discussion for obvious reasons. This is a pretty new area. If you had
    to recommend one resource besides the AI Show, and the documentation, and all
    the official resources from Microsoft, do you have something in mind that you
    would recommend to learners and people who are listening to the discussion, that
    you consider good for their upskilling journey?'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 太棒了。我只是想看看这个方面的未来路线图，因为关于LLMOps有很多讨论，但显然这是一个初步的讨论。这是一个相对较新的领域。如果你必须推荐除了《AI
    Show》、文档以及所有来自微软的官方资源之外的资源，你有没有什么推荐给学习者以及正在听讨论的人，你认为这对他们的技能提升之旅有帮助？'
- en: '**S.J.**: Yes. I will say this, and this is going to be counterintuitive again
    because I like being counterintuitive. You are your own ultimate resource. My
    sense is that there is no amount of reading, or looking, or thinking about this
    stuff that really beats getting in there and trying something. That’s what I would
    suggest you do. Try something, make a prompt, have the answer come out and see
    what happens. In my mental model, maybe this will help: you should not think of
    these “LLM things” as repositories of knowledge. They’re not databases that have
    information. They are basically language calculators or language synthesizers.
    Think of your prompt as the language arithmetic that you’re putting into the LLM
    and think of the response as the answer.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.J.**: 是的。我要说的是，这又将是一个反直觉的观点，因为我喜欢反直觉。你是你自己的终极资源。我的感觉是，无论你阅读多少，或者观察，或者思考这些内容，真正能打败的是亲自尝试。这就是我建议你做的事情。尝试一些东西，制作一个提示，看看答案出来后会发生什么。在我的思维模型中，也许这会有所帮助：你不应该把这些“LLM事物”看作是知识的存储库。它们不是包含信息的数据库。它们基本上是语言计算器或语言合成器。把你的提示看作是放入LLM中的语言算术，把响应看作是答案。'
- en: For example, this paragraph plus this paragraph minus this paragraph, what does
    that look like? I use LLMs like this all the time, even this morning. I wrote
    down a jumble of thoughts that I wanted to make so that it was smoothed out and
    GPT-4 was super nice and said, yeah, you should write it like this. It wasn’t
    perfect, but it enabled me to start with garbage, get something more refined,
    and now I could become an editor. Editing is much easier than creating. Think
    of LLMs as language calculators and start using them to solve tasks. Once you
    do that as your own resource, you’re going to get super far. These things are
    not hard to get started with, you just see the endpoint and you need to just put
    in a prompt and have something come out.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这段加上这段减去这段，看起来会是什么样子？我经常使用LLM来这样做，甚至今天早上。我写下了一堆我想表达的想法，以便使其变得平滑，GPT-4非常友好地建议，是的，你应该这样写。它并不完美，但它使我能够从垃圾开始，得到一些更精致的东西，现在我可以成为一个编辑。编辑比创作容易得多。将LLM视为语言计算器，并开始使用它们来解决任务。一旦你将其作为自己的资源，你将走得很远。这些事情并不难开始，你只需要看到终点，然后输入一个提示，就会得到一些结果。
- en: '**A.G.**: Yeah, there are plenty of examples of notebooks where people can
    play with the API and test and see how it reacts. This notion of a calculator,
    I love it. It’s aligned with the notion of a copilot for a person that will be
    interacting with the system by using the linguistic ability of the models. It’s
    amazing.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的，有很多笔记本的例子，人们可以玩API，测试并看到它的反应。这个计算器的概念，我非常喜欢。它与一个人作为系统交互者的Copilot概念相一致，这个人将使用模型的言语能力。太令人惊叹了。'
- en: 'Saurabh Tiwary: The New Microsoft Copilot Era'
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 'Saurabh Tiwary: 新的微软Copilot时代'
- en: '**A.G.**: For those who don’t know, could you please explain who you are and
    what your role at Microsoft is with which unit?'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 对于那些不了解的人来说，你能解释一下你是谁，你在微软的哪个部门担任什么角色吗？'
- en: '![](assets/aoas_07in07.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aoas_07in07.png)'
- en: '**S.T.**: I lead a team called Turing, and the team has been training LLMs
    and applying them. It’s an applied team, so it uses these models in a variety
    of products from the Edge browser to Bing question answering, or if you are getting
    emails in Outlook, you will see those text predictions as you type, you will see
    the sentences complete, so a lot of features like that. More recently, my team
    has been driving the Copilot experience across many of the Copilots that Microsoft
    has announced. Most of the heavily used ones like the Windows Copilot, Edge Copilot,
    Bing, in a similar way, even on the enterprise side. The backend of all of those
    Copilots is the same with an extensibility model, and so my team is building that.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.T.**: 我领导一个名为图灵的团队，该团队一直在训练LLM并应用它们。这是一个应用团队，因此它将这些模型用于从Edge浏览器到Bing问答的各种产品中，或者如果你在Outlook中收到邮件，你会在输入时看到那些文本预测，你会看到句子被完成，所以有很多这样的功能。最近，我的团队一直在推动微软宣布的许多Copilot体验。大多数被广泛使用的，如Windows
    Copilot、Edge Copilot、Bing，以类似的方式，甚至在企业方面。所有这些Copilot的后端都是相同的，有一个可扩展模型，因此我的团队正在构建这个模型。'
- en: '**A.G.**: It’s amazing. Legend has it that you created the Turing team, along
    with that first set of GPUs with which you were preparing the first models. That
    was some time ago.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 太令人惊叹了。传说中，你创建了图灵团队，以及那套第一批GPU，你用它们准备第一批模型。那是在很久以前。'
- en: '**S.T.**: Yeah, it was quite some time back, like maybe eight or nine years
    back, at least on the product side. Obviously, Microsoft Research has been pushing
    the state of the art for a very long period of time. But on the product side,
    I kind of bought the first GPUs, then built the first clusters, and ran the software
    layer on top of it, so that you can do some large-scale (which is not large-scale
    by any standards now), but some large-scale training on that small cluster, then
    evolve that to a bunch of GPU running in Azure, and now there we are, where even
    the inference GPUs are massive.'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.T.**: 是的，那已经是很久以前了，可能是在八九年以前，至少在产品方面。显然，微软研究院已经长期推动着技术的最前沿。但在产品方面，我买了第一批GPU，然后搭建了第一批集群，并在其上运行软件层，这样你就可以进行一些大规模的训练（现在任何标准下都不算大规模），在那个小集群上进行一些大规模的训练，然后发展到Azure上运行的一批GPU，现在我们就在这里，甚至推理GPU也变得非常庞大。'
- en: '**A.G.**: You mentioned Microsoft Bing Chat, and Microsoft Copilot now. How
    was that journey? Because I think that after GitHub Copilot, this has been the
    best exponent of experimentation and learnings; it has even been shared by Jordi
    Ribas and the team on the blog, and it was amazing just to see what you were doing.
    How was that?'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**：你提到了微软Bing Chat和现在的Microsoft Copilot。这个旅程是怎样的？因为我认为在GitHub Copilot之后，这已经成为实验和学习最好的例证；它甚至被Jordi
    Ribas和他的团队在博客上分享，看到你所做的一切真是太令人惊叹了。这个过程是怎样的？'
- en: '**S.T.:** This is a phenomenal experience. Obviously, the team has been pushing
    very hard in terms of adding features, improving the experiences, etc. Let me
    maybe share a little bit of the backstory behind this. As I was mentioning, we
    were training our own LLMs in the past, and we had this conviction that conversational
    AI will be the next step in the journey. Even before ChatGPT or GPT-4 came out,
    we had our own conversational experience like a chat experience, which we were
    running in a stealth mode in India and MSIB countries (Malaysia, Singapore, Indonesia,
    and Philippines). We were working on it for a few years, I would say a couple
    of years before ChatGPT came out. We were iterating safety mechanisms, like not
    touching controversial topics, how do you address jailbreaks, etc. A lot of these
    things we were already experimenting with at a much smaller scale, and the surface
    area and the interaction mechanism was also a little bit different.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.T.**：这是一个神奇的经历。显然，团队在添加功能、改进体验等方面付出了极大的努力。让我分享一下背后的故事。正如我提到的，我们过去一直在训练自己的LLM，我们坚信对话式AI将是旅程的下一步。甚至在ChatGPT或GPT-4出现之前，我们就已经有了自己的对话式体验，就像聊天体验一样，我们在印度和MSIB国家（马来西亚、新加坡、印度尼西亚和菲律宾）以隐秘模式运行。我们为此工作了几年，可以说是在ChatGPT出现前两年。我们一直在迭代安全机制，比如不触及有争议的话题，如何处理越狱等问题。我们已经在更小的规模上对这些事情进行了很多实验，表面面积和交互机制也有所不同。'
- en: But, even within that experiment, we were finding that there was a lot of user
    engagement, in the sense that I remember one of the longer conversations was running
    for 13 or 14 hours. The user was talking to the bot for 13 to 14 hours straight
    with, I don’t know, maybe 1,800 messages back and forth going between the user
    and the bot, etc. That actually, that initial experiment gave us some baseline
    footing, so that when we got access to GPT-4, we had our paths somewhat mapped
    out. Hence, within a fairly short period of time, I think we got access to GPT-4
    somewhere around August or September of 2022, and then we released it within four
    or five months on February 7, 2023\. We released what was called the Bing Chat
    experience, which is right now the Microsoft Copilot experience.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，即使在那个实验中，我们也发现用户参与度很高，我记得有一场较长的对话持续了13或14个小时。用户连续与机器人交谈了13到14个小时，我不知道，可能来回有1,800条消息在用户和机器人之间传递，等等。实际上，那个初始实验为我们提供了一些基准，所以当我们获得GPT-4的访问权限时，我们已经大致规划了路径。因此，在相对较短的时间内，我认为我们大约在2022年8月或9月获得了GPT-4的访问权限，然后在2023年2月7日前后四到五个月内发布了它。我们发布了被称为Bing
    Chat体验的东西，现在就是微软Copilot体验。
- en: It has been a fantastic journey, lots of late nights. Actually, the team worked
    through Thanksgiving and holidays and stuff like that, but it was a very exciting
    journey and seeing it populate across all the different surfaces that Microsoft
    has, whether it be Word, PowerPoint, M365, Edge, Bing as well as across our app
    family, the mobile app family, it has been just amazing. The partnerships have
    been great. The company has been working like one to propagate this belief or
    mission about Copilot across all these surfaces. If you take a step back, being
    able to do something like this is just phenomenal.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一段精彩的旅程，有很多个深夜。实际上，团队在感恩节和假日等时候都在工作，但这是一段非常激动人心的旅程，看到它在微软的所有不同表面上普及，无论是Word、PowerPoint、M365、Edge、Bing，还是我们的应用家族，移动应用家族，这真是太令人惊叹了。合作伙伴关系非常出色。公司像一个人一样努力传播关于Copilot的信念或使命到所有这些表面上。如果你退一步想，能够做这样的事情真是太神奇了。
- en: '**A.G.**: It’s true. From the field, I see it like this belief that there is
    a notion of Copilot that is everywhere, aligned with all the products. Even this
    end-to-end architecture of what a Copilot is, that is certainly new, but it’s
    something exciting. I feel like one of the most incredible things was to see the
    day-to-day, night-to-night, week-to-week progress of Bing Chat, Microsoft Copilot,
    all the learnings that you were sharing with the industry, even with the competitors
    on the blog, I was like, “This is gold!” All the improvements, I could really
    feel the improvements on the product. That pace of innovation is something that
    I think is difficult to replicate.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 这是真的。从现场来看，我觉得这是一种信念，即存在一种无处不在的Copilot概念，与所有产品相一致。即使是Copilot的端到端架构，这确实很新，但也很令人兴奋。我觉得最令人难以置信的事情之一就是看到Bing
    Chat、Microsoft Copilot日复一日、夜复一夜、周复一周的进步，你所分享给行业的所有学习成果，甚至包括在博客上与竞争对手的交流，我都觉得这是“金子”！所有的改进，我都能真正感受到产品上的改进。这种创新的速度我认为是难以复制的。'
- en: '**S.T.**:I will say kudos to the team members who have been working super hard,
    and across Microsoft, working towards this common goal, and providing a delightful
    as well as a useful experience. It’s not just conversations. At the end of the
    day, we have our mission statement of making every person and organization in
    the world more productive. Along that particular goal, we don’t just want just
    a chit-chat experience. We also want people to accomplish things, do things. Within
    that mission, how do we connect all of the Copilots, add features like these plug-ins
    and GPTs that we have added? Actually, some of the things which might be coming
    up soon are even going towards task completion, etc. We are trying to evolve the
    product in a very significant way.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.T.**: 我要称赞那些一直非常努力工作的团队成员，他们在微软内部共同努力，朝着这个共同目标前进，提供令人愉悦且实用的体验。这不仅仅是对话。最终，我们的使命宣言是让世界上每一个人和组织都更加高效。沿着这个特定的目标，我们不仅想要闲聊的体验。我们还希望人们能够完成事情，做事情。在这个使命中，我们如何连接所有的Copilot，添加我们添加的这些插件和GPT等特性？实际上，一些即将出现的事情甚至指向了任务完成等。我们正在以非常显著的方式演进产品。'
- en: '**A.G.**: Yes, and the notion of the end-to-end Copilot. People ask, what’s
    Copilot exactly? Then there’s this and the other Copilot, all the Copilots on
    the products. But this notion of end-to-end Copilot that goes way beyond the model…it’s
    not just the model, it is the orchestration, it is the combination with Copilot
    for 365, etc. All this architecture, how do you design something that is so massive
    and so interesting from a combination of capabilities point of view?'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的，还有端到端Copilot的概念。人们问，Copilot究竟是什么？然后有这个Copilot、那个Copilot，所有产品上的Copilot。但这个端到端Copilot的概念远远超出了模型……它不仅仅是模型，它是编排，是与Copilot
    for 365等的结合。所有这些架构，你是如何从能力组合的角度设计出如此庞大且有趣的东西的？'
- en: '**S.T.**: Yeah. The design principle of Copilot is that it is in the true sense
    a Copilot, as there is in aircraft. That if you are interacting with any piece
    of software from Microsoft, whether it be Teams or Outlook or wherever you are,
    the Copilot will be there next to you to help you. Obviously, it won’t be a static
    experience depending upon which interface you are in, so if you are at the operating
    system level, at Windows level, you may want to do system-level commands, like
    for example, turn on focus mode or change my Bluetooth settings or open an app.
    If you are in Outlook, you may want to summarize your email while having general-purpose
    conversations as well.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.T.**: 是的。Copilot的设计原则是，它真正意义上是一个Copilot，就像飞机上的一样。如果你在与微软的任何软件进行交互，无论是Teams、Outlook还是其他任何地方，Copilot都会在你身边帮助你。显然，这不会是一个静态的体验，取决于你所在的界面，所以如果你在操作系统级别，在Windows级别，你可能想执行系统级命令，比如打开专注模式或更改我的蓝牙设置或打开一个应用。如果你在Outlook中，你可能想在进行通用对话的同时总结你的电子邮件。'
- en: The way we have architected it is so that irrespective of whatever surface you
    are using the Copilot in, you get a slightly different experience, which is conditioned
    on what surface area you are in. That’s where we are pushing this default idea
    of a Copilot, that it will be there for you to help you do your work or do your
    task or whatever you’re planning to do, with a much better experience than if
    you were to do it alone.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 我们构建它的方式是，无论你在哪里使用Copilot，你都会得到一个略有不同的体验，这取决于你所处的表面区域。这就是我们推动这个默认的Copilot理念的地方，它将为你提供帮助，让你能够以比独自完成更好的体验来完成你的工作或任务或你计划要做的事情。
- en: '**A.G.**: Yes, and one of the original tasks, I mean, the main one is search.
    How did you and the team reinvent this notion of internet search by combining
    LLMs with traditional search? How was that, getting to that idea? I feel like
    it’s mind-blowing.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的，其中一个原始任务，我的意思是，主要任务是搜索。你是如何将LLMs与传统的搜索相结合，重新发明了互联网搜索这一概念的？你是如何得到这个想法的？我觉得这太令人震惊了。'
- en: '**S.T.**: Yes, I have been working in search for quite some time. One of the
    things that we were thinking was that, if you look at us as a user, either it’s
    me or you or anyone else. Why do we want to search? Search is actually a simplification
    of what the technology can offer to us and users or us as humanity have gotten
    used to using it in a particular way, which is that, for example, you will see
    in search, if you look into search logs, you will see a lot of queries which are
    very like two words, three words each. You will see something like “best elementary
    school,” for example. Now, it’s very abstract. The reason why people search, the
    uber problem that the person may want to solve with a search like “best elementary
    school’” is something like…I have a kid who has been going to this prep school
    and is looking for something that is nearby and good quality, or maybe the user
    is planning to buy a house, and they’re wondering whether they should buy the
    house in this particular neighborhood or somewhere else and so on. There might
    be a lot of deeper intent, which the user does not express in search engines,
    because they have learned from past experience.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.T.**: 是的，我在搜索领域工作已经有一段时间了。我们一直在思考的一个问题是，如果你把我们当作用户，无论是我自己、你，还是其他任何人。我们为什么想要搜索？搜索实际上是对技术能为我们提供的东西的一种简化，而我们作为用户或人类已经习惯了以某种特定方式使用它，比如，在搜索中，如果你查看搜索日志，你会看到很多非常像两三个词的查询。例如，你会看到“最好的小学”这样的内容。现在，这非常抽象。人们搜索的原因，或者说，可能希望通过搜索“最好的小学”这样的查询解决的问题，可能像……我有一个孩子一直在上这所预备学校，正在寻找附近且质量好的地方，或者用户可能在计划买房，他们在想是否应该在这个特定的社区买房，等等。可能会有很多更深层次的意图，但用户并没有在搜索引擎中表达出来，因为他们已经从过去的经验中学到了这一点。'
- en: People who have been in this business for a long time may remember [Ask Jeeves](https://oreil.ly/yuhNk),
    which existed around 20 to 25 years back. With Ask Jeeves, you were told to just
    express yourself in long sentences and it will find the information. At that time
    the technology was not great, and most of the time when you ask questions like,
    “I’m trying to buy a house, can you share what will be the good elementary school
    in this particular area?” and so on, it wouldn’t find the information, which is
    why search engines trained humans to type in very specific keywords. Even when
    you type those keywords, if you look into a user session or how we engage, what
    happens is we try to click on a search result, we read some content, then we click
    on something else, then we modify the queries, and for this example, we may find
    that there are public school and private school options. We might decide we should
    look into those depending upon whether they’re affordable or not, and then you
    iterate and so on. Given that the large language models have become a lot more
    powerful, we can try to compress this complex effort, which as humans we have
    broken down into these very specific sets. Let’s issue this first query, look
    at results, then modify it, then ask the other thing, and then the other thing.
    At the end of the day, you may open a map and then say, where is that region and
    where is the house, and what’s the distance, and so on.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个领域工作很长时间的人可能还记得[Ask Jeeves](https://oreil.ly/yuhNk)，它大约在20到25年前存在。使用Ask Jeeves，你会被告知只需用长句表达自己，它就会找到信息。当时的技术并不出色，而且大多数时候当你提出像“我正在尝试买房，你能告诉我这个特定地区有哪些好的小学吗？”等问题时，它找不到信息，这就是为什么搜索引擎训练人类输入非常具体的关键词。即使你输入了这些关键词，如果你查看用户会话或我们如何互动，发生的事情是我们尝试点击搜索结果，阅读一些内容，然后点击其他东西，然后修改查询，在这个例子中，我们可能会发现存在公立学校和私立学校的选择。我们可能会决定我们应该根据它们是否负担得起来考虑这些选择，然后你迭代等等。鉴于大型语言模型变得非常强大，我们可以尝试压缩这个复杂的工作，这是我们人类将这些工作分解成非常具体的集合。让我们发出第一个查询，查看结果，然后修改它，然后询问其他事情，然后是其他事情。最终，你可能会打开地图，然后说，那个地区在哪里，房子在哪里，距离有多远，等等。
- en: Instead of that, with LLMs and with this Copilot experience, you can type what
    you really want. You can say, “I’m new to this area, I’m looking into buying a
    house, I have two young kids, where should I find good schools in this region?”
    etc. You can express all of that. Then the model is actually, as a Copilot, breaking
    that, because they know they have access to the search engine, the model itself.
    It will now break your complex scenario into smaller subcomponents, issue search
    queries, look at results, follow up again, etc., and then provide that comprehensive
    view. Instead of you doing all of these tasks, the model is helping you do that.
    That was our initial thing, because we have seen our users struggle in a session,
    trying lots of different things, iterating, making changes, etc. Anyways, that’s
    the story behind this improved search experience with the Copilot.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 与其那样，使用大型语言模型（LLMs）和这个Copilot体验，你可以输入你真正想要的内容。你可以这样说，“我对这个领域不太熟悉，我正在考虑买房，我有两个孩子，我应该在这个地区哪里找好的学校？”等等。你可以表达所有这些内容。然后，作为Copilot，模型实际上会将其分解，因为它们知道它们可以访问搜索引擎，即模型本身。现在，它会将你的复杂场景分解成更小的子组件，发出搜索查询，查看结果，再次跟进，等等，然后提供全面的视图。不是你完成所有这些任务，而是模型在帮助你完成这些任务。这就是我们的初衷，因为我们看到我们的用户在会话中挣扎，尝试很多不同的事情，迭代，做出改变，等等。无论如何，这就是Copilot改进搜索体验背后的故事。
- en: '**A.G.**: I guess you had started with the models, and then there was the orchestration
    part, now we talk about LlamaIndex, LangChain, Semantic Kernel, but [Prometheus](https://oreil.ly/Vkgtt)
    was there. That concept of orchestrating knowledge and combining pieces, skills,
    etc.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**：我想你们最初是从模型开始的，然后是编排部分，现在我们谈论LlamaIndex、LangChain、Semantic Kernel，但[Prometheus](https://oreil.ly/Vkgtt)已经存在了。这种编排知识和结合片段、技能等的概念。'
- en: '**S.T.**: Yes, one of the other things for people who have been playing, or
    trying to build bots using LLMs, with one of these options like LangChain and
    stuff like that, one of the challenges that initially doesn’t show up, but it
    happens when you start doing more complex things, is that when you have a database,
    or an interface through which you can pull in information, it’s very easy to write
    a prompt, and you can add things over there. In Microsoft’s case, there are many,
    many different complex things which the system can access. For example, even for
    Bing, there is a search index which is there, and that is one interface. But we
    also have our Ads engine, we have introduced image creation as a capability, we
    have GPT4-V for image understanding. There are many, we have actually introduced
    this notion of plug-ins if you want real-time flight information from KAYAK, being
    able to access that.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.T**：是的，对于那些在玩或者尝试使用LLM（大型语言模型）构建机器人，使用像LangChain这样的选项的人，最初不会出现的一个挑战，但当你开始做更复杂的事情时就会出现，那就是当你有一个数据库或者一个可以通过它拉取信息的界面时，编写提示非常容易，你可以在那里添加东西。在微软的情况下，系统可以访问许多不同的复杂事物。例如，即使是Bing，也有一个搜索索引，这是一个接口。但我们也有我们的广告引擎，我们引入了图像创建作为一项功能，我们有GPT4-V用于图像理解。有很多，我们实际上引入了插件的概念，如果你想要从KAYAK获取实时航班信息，能够访问到它。'
- en: Once you start adding many of these pieces, what happens is if you start using
    the raw prompt-based method, the prompt will become just ginormous, and even the
    model quality will suffer because it now has to follow instructions, a very long
    instruction set, and just like humans where if you give too many instructions,
    you will be confused at the end of the page about what was written at the top.
    You see similar behaviors over here as well, that the model quality may not follow
    everything to the right intent of what is written. Hence, we had to build a more
    sophisticated orchestration engine which can do state-based prompting, it can
    do dynamic prompting so that the prompt which is sent to the model is a lot smaller.
    There’s a lot of sophistication which has gone inside it so that we can provide
    a really compelling experience for our users.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦开始添加许多这些片段，如果你开始使用基于原始提示的方法，提示就会变得极其庞大，甚至模型质量也会受到影响，因为它现在必须遵循指令，一个非常长的指令集，就像人类一样，如果你给出太多的指令，你会在页面底部对顶部写了什么感到困惑。你在这里也能看到类似的行为，即模型质量可能无法完全遵循所写内容的正确意图。因此，我们必须构建一个更复杂的编排引擎，它可以进行基于状态的提示，它可以进行动态提示，这样发送给模型的提示就会小得多。其中包含了很多复杂性，以便我们能为用户提供真正令人信服的体验。
- en: '**A.G.**: Totally. There’s the model, the orchestration, and the third leg
    of this chair, I think, is the user interface. How did you experiment with that
    experience, how to adapt, because there is a learning process for users from traditional
    keyword search to something where we will be interacting and then understanding
    the results? How was that, all that experimentation?'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G**：完全同意。这里有模型、编排，我认为这个椅子的第三条腿是用户界面。你是如何实验那种体验的，如何适应，因为用户从传统的关键词搜索到我们将要互动并理解结果的过程有一个学习过程？那个实验是怎样的？'
- en: '**S.T.**: Yeah, right now, there are some standard interfaces which a lot of
    companies who are entering this area have settled on. But since we were almost
    first to market, we had to design and iterate on this a lot. From day zero when
    we released the product to where it is now, it has gone through a ton of iterative
    improvements. One of the first things that we did was we introduced the conversational
    interface on top of our search engine. So the question was, well, most of the
    users don’t even know this product exists. So how would they engage? Because maybe
    you and I are more connected to technology, and maybe we have read the latest
    news, but how does a common user engage with this kind of technology? How do they
    even know this is there? One of the very subtle things that we did was on Bing.com,
    you would have icons to go to Copilot, like you can click and go on. But if you
    do a mouse scroll, you can switch seamlessly between conversations and search
    results. So that provides a very natural way in which I type this query and most
    of the time, the user will be typing the query for the search results. They get
    the search results, but let me just do a mouse scroll, just a couple of clicks.
    You land into the conversational interface and you can have that conversation.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.T.**：是的，目前，有一些标准界面，许多进入这个领域的公司都已经选择了这些界面。但由于我们是第一个进入市场的，我们不得不对此进行大量设计和迭代。从我们发布产品的那一天到现在，它已经经历了很多次迭代改进。我们最早做的事情之一就是在我们的搜索引擎上引入了对话界面。问题是，大多数用户甚至不知道这个产品的存在。他们如何参与呢？因为我们可能你和我对技术更熟悉，也许我们阅读了最新的新闻，但普通用户如何与这种技术互动？他们甚至怎么知道这里有这样的东西？我们做的一个非常微妙的事情是在Bing.com上，你可以点击图标进入Copilot，就像你可以点击并进入一样。但如果你滚动鼠标，你可以无缝地在对话和搜索结果之间切换。所以这提供了一种非常自然的方式，我输入这个查询，大多数时候，用户会输入查询以获取搜索结果。他们得到了搜索结果，但让我只是滚动鼠标，点击几下。你进入了对话界面，你可以进行对话。'
- en: There were other very subtle things that we did, for example, for question answering
    or weather, sports, etc. We had these follow-up queries, which we show on the
    Bing search page itself. When you click on that, you land into the chat interface.
    This is how we were trying to educate, instead of having a tutorial or a notification
    bar that now you can do this, we were having these subtle ways in which, now if
    you click on this, you see you go into a conversation interface, the Copilot will
    respond to your follow-on question and then the user knows that, OK, there is
    something else, something smarter, richer, which is behind the scenes, and then
    they can engage further with that.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还做了其他一些非常微妙的事情，例如，用于问答或天气、体育等。我们有一些后续查询，这些查询我们在Bing搜索页面上展示。当你点击它时，你会进入聊天界面。这就是我们试图教育用户的方式，而不是通过教程或通知栏告诉他们现在可以这样做，我们采用了这些微妙的方式，现在如果你点击这个，你会看到你进入了一个对话界面，Copilot会回答你的后续问题，然后用户就会知道，好吧，背后还有其他一些东西，更智能、更丰富的东西，然后他们可以进一步参与其中。
- en: '**A.G.**: Yeah, totally product-led. So people will just get into a product
    and they will learn in an organic way how to handle this new functionality, very
    smart. So, because this book is about Azure OpenAI, then this transition, this
    evolution towards the Microsoft Copilot notion, this new era of AI that we are
    living today…what’s your vision of what’s next and the evolution in the industry
    or even the upcoming research topics that you think may be interesting to take
    a look at?'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**：是的，完全以产品为导向。所以人们会直接进入一个产品，并以一种有机的方式学习如何处理这种新的功能，非常聪明。因此，由于这本书是关于Azure
    OpenAI的，那么这种过渡，这种向Microsoft Copilot概念的演变，我们今天所生活的这个AI新时代……你对未来有什么愿景？在行业或即将到来的研究主题中，你认为哪些可能值得一看？'
- en: '**S.T.**: Yeah, I mean, that’s a very important and challenging question. A
    lot of people have argued that the last year has been transformational and a lot
    of stuff has been happening. But given the trend lines that we are seeing, I think,
    and it is hard to believe, but I think the rate of change will actually accelerate
    and not slow down, that’s our belief. I know we have released Copilot across many
    surfaces, but the way we see the Copilot today, I believe it is going to evolve
    from these conversational text-based interfaces to a much richer experience very,
    very quickly. Yes, typing is something and there are certain places, so for example,
    messaging apps, etc., have educated us that you can type and you can get back
    and forth conversations, etc. We are following that mode. But models are becoming
    more powerful, think about true multimodality, just like we have as humans.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.T.**: 是的，我的意思是，这是一个非常重要且具有挑战性的问题。很多人认为去年是变革性的，发生了许多事情。但鉴于我们看到的趋势线，我认为，虽然很难相信，但我认为变化的速率实际上会加速而不是减缓，这是我们相信的。我知道我们已经将Copilot发布到许多表面，但就我们今天看到的Copilot而言，我相信它将很快从这些基于对话的文本界面发展到更加丰富的体验。是的，打字是一种方式，有些地方，例如，消息应用等，已经教育我们，你可以打字，你可以进行来回的对话等。我们正在遵循这种模式。但模型变得更加强大，想想真正的多模态，就像我们人类一样。'
- en: For example, when I’m talking to you, I’m seeing this Microsoft Teams window,
    I’m seeing your face, I also see your name written next to it. As a human, I’m
    not going into a text mode or an image mode like, I’m just looking at the face
    and now I’m going to read the text, etc. Everything is very seamless for me when
    I’m looking at your screen. In a similar way, even for the Copilot, we will start
    seeing things where the engagement will be very natural. People could speak and
    the model could produce an image. They could actually put in an image with some
    text and it may respond back, etc. Very similar, it’s not going through pipelines
    of like, this model has got called and then text to speech, and so on. So that
    is one axis which will be fairly powerful that the models may start operating
    at the pixel level. So instead of a text model or image model, it just looks at
    pixels and some of those pixels end up being text and some of them end up being
    images and that’s OK.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当我与你交谈时，我看到这个Microsoft Teams窗口，我看到你的脸，我还看到你的名字写在旁边。作为一个人类，我不会进入文本模式或图像模式，比如，我只是看着你的脸，现在我准备阅读文本等。当我看着你的屏幕时，一切对我来说都非常无缝。同样，对于Copilot来说，我们也将开始看到一些非常自然参与的事情。人们可以说话，模型可以生成图像。他们实际上可以插入带有文本的图像，它可能会做出回应等。非常相似，它不是通过像这样的管道，这个模型被调用，然后是文本到语音等。所以这是模型可能开始以像素级别操作的相当强大的一轴。所以，而不是一个文本模型或图像模型，它只是查看像素，其中一些像素最终成为文本，一些像素最终成为图像，这是可以的。
- en: Another thing that I feel is where the world is heading is towards this behavior
    of agents. Meaning, right now, I was giving the search example earlier that you
    had a very complex task, and as a user we were interacting with the search engine
    by breaking down that problem into very small pieces, issuing those queries, looking
    at results, and we were the orchestrator in our mind, doing this complex thing
    even though we never explicitly said that we are the orchestrator. I think the
    same is true even with our Copilot today, they are limited to a certain extent
    because they are a lot about information gathering. We are trying to do some of
    the task completions with the KAYAK reference that I was adding.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 另一件我觉得世界正走向的方向是代理的行为。意思是，现在，我之前给出了搜索的例子，你有一个非常复杂的任务，作为用户，我们通过与搜索引擎交互，将问题分解成非常小的部分，发出查询，查看结果，我们在心中是协调者，即使我们从未明确说过我们是协调者。我认为今天我们的Copilot也是如此，它们在某种程度上受到限制，因为它们很大程度上是关于信息收集。我们正在尝试使用我添加的KAYAK参考来完成一些任务。
- en: Ultimately, what you want to do is, one of the popular examples in our Copilot
    is, “Can you plan an itinerary for me?” If I’m going on vacation, do whatever,
    pick your favorite place. London, for example. It will search, pick up various
    places, etc. It can create an itinerary, and it can also recommend hotels and
    so on. But ultimately, what you want to do is, you want to just plan the vacation.
    Because right now, for example, my wife hands that task to me, and it’s super
    painful. I need to go read all the reviews, make sure that the hotels are good,
    nearby to the places we want to go, etc. I have to do a lot of these things, then
    go to the website, search for the hotel, do the booking, and so on.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，你想要做的是，在我们Copilot中有一个流行的例子，“你能为我安排行程吗？”如果我正在度假，随便什么，选你最喜欢的地方。比如伦敦。它会搜索，挑选各种地方，等等。它可以创建行程，也可以推荐酒店等。但最终，你想要做的是，你只想安排这次度假。因为现在，比如，我的妻子把这个任务交给我，这非常痛苦。我需要去阅读所有评论，确保酒店好，靠近我们想去的地方，等等。我必须做很多这些事情，然后去网站，搜索酒店，进行预订，等等。
- en: I would say it is not a simple process. It takes quite a bit of cognitive load
    as well as time and energy. But if you think about it, a lot of these capabilities
    are there on the web. They are designed for humans because we can open a browser,
    we can click on results, we can book stuff, and so on. I think where these models
    are heading is towards having this agentic behavior or an agent-like behavior
    where you just tell them, obviously with some user interface, etc. Obviously,
    you can’t run it in a fully autonomous way. “I want to go to London for X number
    of days. Can you plan that trip?” But plan here means really planning that trip
    and not just a text interface. Where it goes and it starts doing booking, looking
    for flights, and all of that. Checking weather, that’s another thing, whether
    the weather is good or not. If it is not, if it is going to rain on a particular
    day, maybe you want to plan some different activities on those days, etc. Being
    able to do that where the Copilot on users’ behalf can start doing those types
    of things like open web pages, clicking on things, and these are all arbitrary
    interfaces. I feel like that’s where the world is heading towards.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这并不是一个简单的过程。它需要相当多的认知负荷，以及时间和精力。但如果你仔细想想，网络上有许多这些能力。它们是为人类设计的，因为我们可以打开浏览器，我们可以点击结果，我们可以预订东西，等等。我认为这些模型的发展方向是拥有这种代理行为或类似代理的行为，你只需告诉它们，显然还需要一些用户界面等。显然，你不能完全自主地运行它。“我想去伦敦X天。你能帮我安排这次旅行吗？”但这里的计划意味着真正地安排这次旅行，而不仅仅是提供一个文本界面。它会去哪里，开始进行预订，寻找航班，等等。检查天气，这也是另一件事，看天气是否好。如果不好，如果某天会下雨，你可能想在那些天安排一些不同的活动，等等。能够做到这一点，即Copilot代表用户开始做这些类型的事情，比如打开网页，点击东西，这些都是任意的界面。我感觉这就是世界正在走向的方向。
- en: '**A.G.**: Yes, I think so. It’s not even orchestration. It’s a multilayer architecture
    in which you are going and performing all these actions, and instead of being
    the agent ourselves and booking all the vacations, the hotel, and the trip, etc.,
    we have a system that is relying on the existing interfaces that we have today,
    the frontends and the backends.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**：是的，我认为是这样。这甚至不是编排。它是一个多层架构，你正在执行所有这些动作，而不是我们自己作为代理去预订所有假期、酒店和旅行等，我们有一个系统，它依赖于我们今天已有的现有接口，即前端和后端。'
- en: '**S.T.**: Think of it as your own personal assistant. If you had a personal
    assistant who really knew you well, obviously, it’s just like if you were to hire
    a new personal assistant for yourself. Initially, it will be like, OK, just do
    simple things, etc. But at some point when the trust grows, and you know that
    person can do these things and they understand my interests and boundaries and
    so on, they can start acting on your behalf much, much more. I think that’s where
    I feel like these models will go. On day zero, obviously, they won’t do anything
    because people will be freaked out like, why did you make this particular choice
    or that particular choice? But as things evolve, I think we are going toward that
    future.'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.T.**：把它想象成你自己的私人助理。如果你有一个非常了解你的私人助理，显然，这就好像你要为自己雇佣一个新的私人助理一样。最初，可能就是做一些简单的事情，等等。但到了某个时候，当信任建立起来，你知道那个人可以做到这些事情，并且他们理解我的兴趣和界限等，他们就可以代表你做更多的事情。我认为这就是我觉得这些模型会走向的方向。在零天，显然，它们什么都不会做，因为人们会感到恐慌，为什么你做出了这个特定的选择或那个特定的选择？但随着事情的发展，我认为我们正在走向那个未来。'
- en: '**A.G.**: I think so, it’s very promising what we’ll see in the next one, two,
    three years. That’s why I don’t ask for your vision for the next five years because
    I know that it’s impossible to do so. Look, this is super interesting, wonderful
    insights. I’m just so happy that you are sharing all this information here. Did
    you have a last recommendation for our readers to continue exploring?'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 我认为如此，未来一两年我们将看到的东西非常有希望。这就是为什么我不要求你为未来五年提供愿景，因为我知道这是不可能的。看，这非常有趣，见解非常精彩。我非常高兴你能在这里分享所有这些信息。你对我们读者有什么最后的建议，以继续探索？'
- en: '**S.T.**: I think this field is moving so fast that, personally for me because
    I have been in this area for the last 9 to 10 years, I think a lot of the social
    sites generally are useful, Twitter, if you follow the right set of people and
    so on. Right now, actually, things have evolved a lot. There are newsletters that
    are there, which actually provide the latest, and are actually using LLMs to simplify
    and summarize a lot of the conversation so that you can have a synthesized set
    of information and obviously you can drill down a little bit more if something
    is of interest. I think those are probably the more interesting routes.'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.T.**: 我认为这个领域发展非常快，就我个人而言，因为我在这领域已经工作了9到10年，我认为很多社交网站通常是有用的，比如Twitter，如果你关注正确的一组人等等。现在，实际上，事情已经发生了很大的变化。有一些新闻简报，实际上提供了最新的信息，并且正在使用LLM来简化并总结很多对话，这样你就可以获得一个综合的信息集，显然，如果你对某个东西感兴趣，你可以进一步深入。我认为这些可能是更有趣的途径。'
- en: I can give one other example. Generally, conferences were used for knowledge
    dissemination. Right now, if you look into the deep learning space, conferences
    are mostly for networking. The papers were already put on [arXiv](https://oreil.ly/O9tW3)
    probably three months to six months back. If they were useful, they would have
    already been discussed till death by the time the conference happens. Even the
    research community has shaped itself. Then I will say the same is true for us
    as well. I would say just keep being on the cutting edge and the latest edge.
    I think things are evolving very quickly in this world.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以再举一个例子。通常，会议用于知识传播。现在，如果你看看深度学习领域，会议主要是为了建立联系。论文可能已经在arXiv([arXiv](https://oreil.ly/O9tW3))上放了几个月到六个月。如果它们有用，那么在会议发生之前，它们已经被讨论到不能再讨论了。甚至研究社区也已经形成了。然后我要说的是，对我们来说也是如此。我会说，只需保持处于最前沿和最新前沿。我认为在这个世界上，事情发展得非常快。
- en: '**A.G.**: So quick. Even this Azure OpenAI book has evolved a lot, I don’t
    know how many iterations every week, just to keep updating and adding all the
    information.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 所以很快。即使是这本Azure OpenAI的书也发生了很大的变化，我不知道每周迭代了多少次，只是为了保持更新和添加所有信息。'
- en: '**S.T.**: Maybe even after publishing, you may have to iterate on, I don’t
    know, like a book pointed to an appendix or something.'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '**S.T.**: 也许在出版之后，你可能还需要迭代，比如一本书指向附录或类似的东西。'
- en: '**A.G.**: Yeah, appendix, second, third edition…almost every month.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '**A.G.**: 是的，附录，第二版，第三版……几乎每个月都有。'
- en: Conclusion
  id: totrans-280
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'The experts interviewed in this chapter offer exclusive insights related to
    the current state of generative AI and LLMs (e.g., why data quality matters for
    RAG patterns, new LLMOps trends for model performance tracking, advanced use cases,
    the underlying cloud native infrastructure) but also insights into its future.
    There are two recurrent topics here: multimodality for models to analyze different
    kinds of information, and the evolution of AI agents, as a sort of combined automation
    of steps leading to complete complex tasks—all of this without forgetting the
    responsible and safe implementation of generative AI systems.'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 本章采访的专家提供了与生成式AI和LLMs当前状态相关的独家见解（例如，为什么数据质量对RAG模式很重要，新的LLMOps趋势用于模型性能跟踪，高级用例，以及底层云原生基础设施），同时也提供了对其未来的见解。这里有两个反复出现的话题：多模态模型用于分析不同类型的信息，以及AI代理的演变，作为一种将步骤自动化以完成复杂任务的组合——所有这一切都不要忘记生成式AI系统的负责任和安全实施。
- en: Overall, this last chapter was my way to bring together all the topics from
    Chapters [1](ch01.html#introduction_to_generative_ai_and_azure_openai_ser) to
    [6](ch06.html#elaborating_generative_ai_business_cases), and to discuss them in
    a highly applied manner with an amazing set of professionals. From technology
    building blocks and architectures to organizational considerations. From Azure
    OpenAI Service to the rest of the related “pieces” that enable your cloud native
    generative AI developments.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来说，这一章是我将第[1](ch01.html#introduction_to_generative_ai_and_azure_openai_ser)章到第[6](ch06.html#elaborating_generative_ai_business_cases)章的所有主题汇集在一起的方式，并且与一组令人惊叹的专业人士以高度应用的方式进行了讨论。从技术构建块和架构到组织考虑因素。从Azure
    OpenAI服务到其他能够支持您云原生生成式AI开发的“相关部分”。
- en: And here we are, at the end of this book’s journey. More than 200 pages full
    of explanations, examples, and technical topics related to generative AI and Azure
    OpenAI. But this is, of course, just the beginning. Companies are adopting Azure
    OpenAI, and the Microsoft product teams are working to continue evolving the platform,
    by adding not only new AI models, but also product features related to the operationalization
    of enterprise-level deployments. This is an amazing race, and the generative era
    has just started. This book is a small contribution for AI adopters around the
    world to get the most from Azure OpenAI Service. Let’s keep innovating.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们来到了这本书的终点。超过200页，充满了与生成式AI和Azure OpenAI相关的解释、示例和技术主题。但当然，这只是一个开始。公司正在采用Azure
    OpenAI，微软的产品团队正在努力继续演进该平台，不仅添加新的AI模型，还添加与企业级部署的运营化相关的产品功能。这是一场惊人的竞赛，生成式时代才刚刚开始。这本书是对全球AI采用者的小小贡献，以便他们从Azure
    OpenAI服务中获得最大收益。让我们继续创新。
