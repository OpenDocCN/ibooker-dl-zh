["```py\nimport pandas as pd\n\nfrom dlfb.utils.context import assets\n\ntrain_df = pd.read_csv(assets(\"dna/datasets/CTCF_train_sequences.csv\"))\ntrain_df\n\n```", "```py\n                  sequence  label transcription_factor subset\n0      TACCACATGAGTTCTC...      1                 CTCF  train\n1      CATCAACACTCGTGCG...      0                 CTCF  train\n2      GCACACAGCGCAGGAA...      1                 CTCF  train\n...                    ...    ...                  ...    ...\n61080  CCTCCCTCCCATCCCC...      1                 CTCF  train\n61081  CAGGAATGCACCGGAA...      0                 CTCF  train\n61082  AAAACAGAAACTGAAA...      0                 CTCF  train\n\n[61083 rows x 4 columns]\n\n```", "```py\ntrain_df[\"label\"].value_counts()\n\n```", "```py\nlabel\n1    30545\n0    30538\nName: count, dtype: int64\n\n```", "```py\nimport numpy as np\n\ndef dna_to_one_hot(dna_sequence: str) -> np.ndarray:\n  \"\"\"Convert DNA into a one-hot encoded format with channel ordering ACGT.\"\"\"\n  base_to_one_hot = {\n    \"A\": (1, 0, 0, 0),\n    \"C\": (0, 1, 0, 0),\n    \"G\": (0, 0, 1, 0),\n    \"T\": (0, 0, 0, 1),\n    \"N\": (1, 1, 1, 1),  # N represents any unknown or ambiguous base.\n  }\n  one_hot_encoded = np.array([base_to_one_hot[base] for base in dna_sequence])\n  return one_hot_encoded\n\n```", "```py\ndna_to_one_hot(\"AAACGT\")\n```", "```py\narray([[1, 0, 0, 0],\n       [1, 0, 0, 0],\n       [1, 0, 0, 0],\n       [0, 1, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 0, 1]])\n\n```", "```py\nx_train = np.array([dna_to_one_hot(seq) for seq in train_df[\"sequence\"]])\ny_train = train_df[\"label\"].values[:, None]\n\n```", "```py\ndef load_dataset(sequence_db) -> dict[str, np.ndarray]:\n  \"\"\"Load sequences and labels from a CSV into numpy arrays.\"\"\"\n  df = pd.read_csv(sequence_db)\n  return {\n    \"labels\": df[\"label\"].to_numpy()[:, None],\n    \"sequences\": np.array([dna_to_one_hot(seq) for seq in df[\"sequence\"]]),\n  }\n\n```", "```py\ndef convert_to_tfds(\n  dataset, batch_size: int | None = None, is_training: bool = False\n):\n  \"\"\"Convert DNA sequences and labels to a TensorFlow dataset.\"\"\"\n  ds = tf.data.Dataset.from_tensor_slices(dataset)\n  if is_training:\n    ds = ds.shuffle(buffer_size=len(dataset[\"sequences\"]))\n    ds = ds.repeat()\n  batch_size = batch_size or len(dataset[\"labels\"])\n  ds = ds.batch(batch_size)\n  ds = ds.prefetch(tf.data.experimental.AUTOTUNE)\n  return ds\n\n```", "```py\nbatch_size = 32\n\ntrain_ds = convert_to_tfds(\n  load_dataset(assets(\"dna/datasets/CTCF_train_sequences.csv\")),\n  batch_size=batch_size,\n  is_training=True,\n)\n\n```", "```py\nbatch = next(train_ds.as_numpy_iterator())\nprint(f'Batch sequence shape: {batch[\"sequences\"].shape}')\nprint(f'Batch sequence instances: {batch[\"sequences\"][:3,:3,]}...')\nprint(f'Batch labels shape: {batch[\"labels\"].shape}')\nprint(f'Batch labels instances: {batch[\"labels\"][:3,]}...')\n\n```", "```py\nBatch sequence shape: (32, 200, 4)\nBatch sequence instances: [[[0 1 0 0]\n  [0 0 1 0]\n  [0 0 1 0]]\n\n [[1 0 0 0]\n  [1 0 0 0]\n  [0 1 0 0]]\n\n [[1 0 0 0]\n  [0 1 0 0]\n  [0 1 0 0]]]...\nBatch labels shape: (32, 1)\nBatch labels instances: [[0]\n [1]\n [0]]...\n\n```", "```py\nvalid_ds = load_dataset(assets(\"dna/datasets/CTCF_valid_sequences.csv\"))\n\n```", "```py\nclass ConvModel(nn.Module):\n  \"\"\"Basic CNN model for binary sequence classification.\"\"\"\n\n  conv_filters: int = 64  # Number of filters for conv layers.\n  kernel_size: tuple[int] = (10,)  # Kernel size for 1D conv layers.\n  dense_units: int = 128  # Units in first dense fully-connected layer.\n\n  @nn.compact\n  def __call__(self, x):\n    # First convolutional layer.\n    x = nn.Conv(\n      features=self.conv_filters, kernel_size=self.kernel_size, padding=\"SAME\"\n    )(x)\n    x = nn.gelu(x)\n    x = nn.max_pool(x, window_shape=(2,), strides=(2,))\n\n    # Second convolutional layer.\n    x = nn.Conv(\n      features=self.conv_filters, kernel_size=self.kernel_size, padding=\"SAME\"\n    )(x)\n    x = nn.gelu(x)\n    x = nn.max_pool(x, window_shape=(2,), strides=(2,))\n\n    # Flatten the values before passing them to the dense layers.\n    x = x.reshape((x.shape[0], -1))\n\n    # First dense layer.\n    x = nn.Dense(self.dense_units)(x)\n    x = nn.gelu(x)\n\n    # Second dense layer.\n    x = nn.Dense(self.dense_units // 2)(x)\n    x = nn.gelu(x)\n\n    # Output layer (single unit for binary classification).\n    return nn.Dense(1)(x)\n\n```", "```py\nmodel = ConvModel()\n\n```", "```py\nimport jax\nimport jax.numpy as jnp\n\ndummy_input = jnp.ones((1, *batch[\"sequences\"][1,].shape))\nprint(dummy_input.shape)\n\nrng_init = jax.random.PRNGKey(42)\nvariables = model.init(rng_init, dummy_input)\nparams = variables[\"params\"]\n\n```", "```py\n(1, 200, 4)\n\n```", "```py\nparams.keys()\n\n```", "```py\ndict_keys(['Conv_0', 'Conv_1', 'Dense_0', 'Dense_1', 'Dense_2'])\n\n```", "```py\nfor layer_name in params.keys():\n  print(f'Layer {layer_name} param shape: {params[layer_name][\"kernel\"].shape}')\n\n```", "```py\nLayer Conv_0 param shape: (10, 4, 64)\nLayer Conv_1 param shape: (10, 64, 64)\nLayer Dense_0 param shape: (3200, 128)\nLayer Dense_1 param shape: (128, 64)\nLayer Dense_2 param shape: (64, 1)\n\n```", "```py\nlogits = model.apply({\"params\": params}, batch[\"sequences\"])\n\n# Apply sigmoid to convert logits to probabilities.\nprobs = nn.sigmoid(logits)\n\n# Print just the first few predictions.\nprint(probs[0:5])\n\n```", "```py\n[[0.48703438]\n [0.49615338]\n [0.48638064]\n [0.4973824 ]\n [0.48106888]]\n\n```", "```py\nimport optax\n\ndef calculate_loss(params, batch):\n  \"\"\"Make predictions on batch and compute binary cross entropy loss.\"\"\"\n  logits = model.apply({\"params\": params}, batch[\"sequences\"])\n  loss = optax.sigmoid_binary_cross_entropy(logits, batch[\"labels\"]).mean()\n  return loss\n\n```", "```py\ncalculate_loss(params, batch)\n\n```", "```py\nArray(0.69774264, dtype=float32)\n\n```", "```py\nlearning_rate = 0.001\n\ntx = optax.adam(learning_rate)\n\n```", "```py\nfrom flax.training.train_state import TrainState\n\nstate = TrainState.create(apply_fn=model.apply, params=params, tx=tx)\n\n```", "```py\ndef create_train_state(model, rng, dummy_input, tx) -> TrainState:\n  variables = model.init(rng, dummy_input)\n  state = TrainState.create(\n    apply_fn=model.apply, params=variables[\"params\"], tx=tx\n  )\n  return state\n\n```", "```py\n@jax.jit\ndef train_step(state, batch):\n  \"\"\"Run single training step to compute gradients and update model params.\"\"\"\n  grad_fn = jax.value_and_grad(calculate_loss, has_aux=False)\n  loss, grads = grad_fn(state.params, batch)\n  state = state.apply_gradients(grads=grads)\n  return state, loss\n\n```", "```py\nstate, loss = train_step(state, batch)\n\n```", "```py\ncalculate_loss(state.params, batch)\n\n```", "```py\nArray(0.63649833, dtype=float32)\n\n```", "```py\nimport tqdm\n\n# Reinitialize the model state to ensure we start fresh each time cell is run.\nrng_init = jax.random.PRNGKey(42)\nstate = create_train_state(model, rng_init, dummy_input, tx)\n\n# Keep track of both the training and validation set losses.\ntrain_losses, valid_losses = [], []\ntrain_batches = train_ds.as_numpy_iterator()\n\n# We use tqdm, which is a progress bar.\nfor step in tqdm.tqdm(range(500)):\n  batch = next(train_batches)\n  state, loss = train_step(state, batch)\n  train_losses.append({\"step\": step, \"loss\": loss.item()})\n\n  # Compute loss on the entire validation set occasionally (every 100 steps).\n  if step % 100 == 0:\n    valid_loss = calculate_loss(state.params, valid_ds)\n    valid_losses.append({\"step\": step, \"loss\": valid_loss.item()})\n\nlosses = pd.concat(\n  [\n    pd.DataFrame(train_losses).assign(split=\"train\"),\n    pd.DataFrame(valid_losses).assign(split=\"valid\"),\n  ]\n)\n\n```", "```py\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom dlfb.utils.metric_plots import DEFAULT_SPLIT_COLORS\n\nsns.lineplot(\n  data=losses,\n  x=\"step\",\n  y=\"loss\",\n  hue=\"split\",\n  style=\"split\",\n  palette=DEFAULT_SPLIT_COLORS\n);\n\n```", "```py\nctcf_motif_dna = \"CCACCAGGGGGCGC\" * 14 + \"AAAA\"\nprint(\"Length of CTCF motif-filled DNA string:\", len(ctcf_motif_dna))\n\n# We add the None here as a batch axis, since our model expects batched input.\nctcf_input = dna_to_one_hot(ctcf_motif_dna)[None, :]\nctcf_input.shape\n\n```", "```py\nLength of CTCF motif-filled DNA string: 200\n(1, 200, 4)\n\n```", "```py\njax.nn.sigmoid(model.apply({\"params\": state.params}, ctcf_input))\n\n```", "```py\nArray([[0.9994091]], dtype=float32)\n\n```", "```py\nrandom_dna_strings = [\n  \"A\" * 200,\n  \"C\" * 200,\n  \"G\" * 200,\n  \"T\" * 200,\n  \"ACGTACGT\" * 25,\n  \"TCGATCGT\" * 25,\n  \"TATACGCG\" * 25,\n  \"CAGGCAGG\" * 25,\n]\n\nprobabilities = []\n\nfor random_dna_string in random_dna_strings:\n  random_dna_input = dna_to_one_hot(random_dna_string)[None, :]\n\n  probabilities.append(\n    jax.nn.sigmoid(model.apply({\"params\": state.params}, random_dna_input))[0]\n  )\n\nprobabilities\n\n```", "```py\n[Array([0.00025924], dtype=float32),\n Array([6.9913156e-05], dtype=float32),\n Array([6.1404e-05], dtype=float32),\n Array([2.6038255e-05], dtype=float32),\n Array([0.10472302], dtype=float32),\n Array([0.00381694], dtype=float32),\n Array([0.01843039], dtype=float32),\n Array([0.00171606], dtype=float32)]\n\n```", "```py\n# The first positive example of a sequence that binds the transcription factor.\nfirst_positive_index = np.argmax(valid_ds[\"labels\"].flatten() == 1)\n\noriginal_sequence = valid_ds[\"sequences\"][first_positive_index].copy()\nprint(f'This sequence has label: {valid_ds[\"labels\"][4]}')\n\n```", "```py\nThis sequence has label: [1]\n\n```", "```py\npred = nn.sigmoid(\n  model.apply({\"params\": state.params}, original_sequence[None, :])\n)\npred\n\n```", "```py\nArray([[0.9581409]], dtype=float32)\n\n```", "```py\nsequence = original_sequence.copy()\nprint(f\"Original base at index 100: {sequence[100]}\")\n\nsequence[100] = np.array([0, 1, 0, 0])\nprint(f\"Mutated base at index 100: {sequence[100]}\")\n\n```", "```py\nOriginal base at index 100: [0 0 1 0]\nMutated base at index 100: [0 1 0 0]\n\n```", "```py\npred_with_mutation = nn.sigmoid(\n  model.apply({\"params\": state.params}, sequence[None, :])\n)\npred_with_mutation\n\n```", "```py\nArray([[0.93434644]], dtype=float32)\n\n```", "```py\ndef generate_all_mutations(sequence: np.ndarray) -> np.ndarray:\n  \"\"\"Generate all possible single base mutations of a one-hot DNA sequence.\"\"\"\n  mutated_sequences = []\n  for i in range(sequence.shape[0]):\n    # At each position, one the four 'mutations' is the original base (no-op).\n    for j in range(4):\n      mutated_sequence = sequence.copy()\n      mutated_sequence[i] = np.zeros(4)\n      mutated_sequence[i][j] = 1\n      mutated_sequences.append(mutated_sequence)\n\n  sequences = np.stack(mutated_sequences)\n  return sequences\n\nmutated_sequences = generate_all_mutations(sequence=original_sequence.copy())\nprint(f\"Shape of mutated sequences: {mutated_sequences.shape}\")\n\n```", "```py\nShape of mutated sequences: (800, 200, 4)\n\n```", "```py\npreds = nn.sigmoid(model.apply({\"params\": state.params}, mutated_sequences))\n\n# Reshape to get the shape (sequence_length, dna_bases).\npreds = preds.reshape((200, 4))\n\n```", "```py\nplt.figure(figsize=(20, 3))\nsns.heatmap(preds.T, cmap=\"RdBu_r\", yticklabels=[\"A\", \"C\", \"G\", \"T\"])\nplt.xlabel(\"Position in DNA sequence\")\nplt.ylabel(\"DNA Base\");\n\n```", "```py\nbaseline_pred = nn.sigmoid(\n  model.apply({\"params\": state.params}, original_sequence[None, :])\n)\ndeltas = preds - baseline_pred\n\nplt.figure(figsize=(20, 3))\nsns.heatmap(deltas.T, center=0, cmap=\"RdBu_r\", yticklabels=[\"A\", \"C\", \"G\", \"T\"])\nplt.xlabel(\"Position in DNA sequence\")\nplt.ylabel(\"DNA Base\");\n\n```", "```py\nfor i in range(4):\n  print(describe_change((100, i), deltas, original_sequence))\n\n```", "```py\nposition 100 with G→A (-4.20% decrease)\nposition 100 with G→C (-2.38% decrease)\nposition 100 with G→G (0.00% increase)\nposition 100 with G→T (0.24% increase)\n\n```", "```py\nfrom dlfb.dna.inspect import plot_binding_site\n\nimportance = np.sum(np.abs(deltas), axis=1)\nplot_binding_site(\n  panels={\n    \"tiles\": {\"label\": \"Deltas\", \"values\": deltas},\n    \"line\": {\"label\": \"Importance\", \"values\": importance},\n  }\n);\n\n```", "```py\ndef one_hot_to_dna(one_hot_encoded: np.ndarray) -> str:\n  \"\"\"Convert one-hot encoded array back to DNA sequence.\"\"\"\n  one_hot_to_base = {\n    (1, 0, 0, 0): \"A\",\n    (0, 1, 0, 0): \"C\",\n    (0, 0, 1, 0): \"G\",\n    (0, 0, 0, 1): \"T\",\n    (1, 1, 1, 1): \"N\",  # N represents any unknown or ambiguous base.\n  }\n\n  dna_sequence = \"\".join(\n    one_hot_to_base[tuple(base)] for base in one_hot_encoded\n  )\n  return dna_sequence\n\n```", "```py\nprint(one_hot_to_dna(original_sequence)[0:25], \"...\")\n\n```", "```py\nACCCCAGGGTAGGGCCTATTGTATG ...\n\n```", "```py\nplot_binding_site(\n  panels={\n    \"tiles\": {\"label\": \"Deltas\", \"values\": deltas},\n    \"line\": {\"label\": \"Importance\", \"values\": importance},\n  },\n  highlight=(92, 106),\n);\n\n```", "```py\n@jax.jit\ndef compute_input_gradient(state, sequence):\n  \"\"\"Compute input gradient for a one-hot DNA sequence.\"\"\"\n  if len(sequence.shape) != 2:\n    raise ValueError(\"Input must be a single one-hot encoded DNA sequence.\")\n\n  sequence = jnp.asarray(sequence, dtype=jnp.float32)[None, :]\n\n  def predict(sequence):\n    # We take the mean to ensure we have a single scalar to take the grad of.\n    return jnp.mean(state.apply_fn({\"params\": state.params}, sequence))\n\n  gradient = jax.grad(lambda x: predict(x))(sequence)\n  return jnp.squeeze(gradient)\n\n```", "```py\ninput_gradient = compute_input_gradient(state, original_sequence)\ninput_gradient.shape\n\n```", "```py\n(200, 4)\n\n```", "```py\nimportance = np.sum(np.abs(input_gradient), axis=1)\nplot_binding_site(\n  panels={\n    \"tiles\": {\"label\": \"Gradients\", \"values\": input_gradient},\n    \"line\": {\"label\": \"Importance\", \"values\": importance},\n  },\n);\n\n```", "```py\nimportant_sequence = one_hot_to_dna(original_sequence)[90:110]\nprint(\"Central DNA sequence with high importance: \", important_sequence)\n\nplt.figure(figsize=(10, 2))\nsns.heatmap(\n  input_gradient[90:110].T,\n  cmap=\"RdBu_r\",\n  center=0,\n  xticklabels=important_sequence,\n  yticklabels=[\"A\", \"C\", \"G\", \"T\"],\n)\nplt.tight_layout();\n\n```", "```py\nCentral DNA sequence with high importance:  TGGCCTCTGGGGGCGCTCTG\n\n```", "```py\nfrom dlfb.dna.inspect import plot_10_gradients\n\nplot_10_gradients(state, valid_ds, target_label=1);\n\n```", "```py\nplot_10_gradients(state, valid_ds, target_label=0);\n\n```", "```py\ntranscription_factors = [\n  \"ARID3\",\n  \"ATF2\",\n  \"BACH1\",\n  \"CTCF\",\n  \"ELK1\",\n  \"GABPA\",\n  \"MAX\",\n  \"REST\",\n  \"SRF\",\n  \"ZNF24\",\n]\n\n```", "```py\n    num_steps = 1000\n\n    scheduler = optax.cosine_decay_schedule(\n      init_value=0.001,\n      decay_steps=num_steps,  # How long to decay over.\n    )\n    learning_rates = [scheduler(i) for i in range(num_steps)]\n\n    plt.scatter(range(num_steps), learning_rates)\n    plt.title(\"Learning Rate over Steps\")\n    plt.ylabel(\"Learning Rate\")\n    plt.xlabel(\"Step\");\n\n    ```", "```py\nclass ConvModelV2(nn.Module):\n  \"\"\"CNN with batch norm and dropout for binary classification.\"\"\"\n\n  conv_filters: int = 64  # Number of filters for conv layers.\n  kernel_size: tuple[int] = (10,)  # Kernel size for 1D conv layers.\n  dense_units: int = 128  # Units in first dense fully-connected layer.\n  dropout_rate: float = 0.2  # Proportion of dense neurons to randomly drop out.\n\n  @nn.compact\n  def __call__(self, x, is_training: bool = True):\n    # First convolutional layer.\n    x = nn.Conv(\n      features=self.conv_filters, kernel_size=self.kernel_size, padding=\"SAME\"\n    )(x)\n    x = nn.BatchNorm(use_running_average=not is_training)(x)\n    x = nn.gelu(x)\n    x = nn.max_pool(x, window_shape=(2,), strides=(2,))\n\n    # Second convolutional layer.\n    x = nn.Conv(\n      features=self.conv_filters, kernel_size=self.kernel_size, padding=\"SAME\"\n    )(x)\n    x = nn.gelu(x)\n    x = nn.BatchNorm(use_running_average=not is_training)(x)\n    x = nn.max_pool(x, window_shape=(2,), strides=(2,))\n\n    # Flatten the values before passing them to the dense layers.\n    x = x.reshape((x.shape[0], -1))\n\n    # First dense layer.\n    x = nn.Dense(self.dense_units)(x)\n    x = nn.gelu(x)\n    x = nn.Dropout(rate=self.dropout_rate)(x, deterministic=not is_training)\n\n    # Second dense layer.\n    x = nn.Dense(self.dense_units // 2)(x)\n    x = nn.gelu(x)\n    x = nn.Dropout(rate=self.dropout_rate)(x, deterministic=not is_training)\n\n    # Output layer (single unit for binary classification).\n    return nn.Dense(1)(x)\n\n  def create_train_state(self, rng: jax.Array, dummy_input, tx):\n    \"\"\"Initializes model parameters and returns a train state for training.\"\"\"\n    rng, rng_init, rng_dropout = jax.random.split(rng, 3)\n    variables = self.init(rng_init, dummy_input)\n    state = TrainStateWithBatchNorm.create(\n      apply_fn=self.apply,\n      tx=tx,\n      params=variables[\"params\"],\n      batch_stats=variables[\"batch_stats\"],\n      key=rng_dropout,\n    )\n    return state\n\n```", "```py\nrng = jax.random.PRNGKey(42)\nrng, rng_init, rng_train = jax.random.split(rng, 3)\nstate = ConvModelV2().create_train_state(\n  rng=rng_init, dummy_input=batch[\"sequences\"], tx=optax.adam(scheduler)\n)\n\n```", "```py\n@jax.jit\ndef train_step(state, batch, rng_dropout: jax.Array):\n  \"\"\"Run a training step and update parameters.\"\"\"\n\n  def calculate_loss(params, batch):\n    \"\"\"Make predictions on batch and compute binary cross-entropy loss.\"\"\"\n    logits, updates = state.apply_fn(\n      {\"params\": params, \"batch_stats\": state.batch_stats},\n      x=batch[\"sequences\"],\n      is_training=True,\n      rngs={\"dropout\": rng_dropout},\n      mutable=[\"batch_stats\"],\n    )\n\n    loss = optax.sigmoid_binary_cross_entropy(logits, batch[\"labels\"]).mean()\n\n    return loss, updates\n\n  grad_fn = jax.value_and_grad(calculate_loss, has_aux=True)\n  (loss, updates), grads = grad_fn(state.params, batch)\n  state = state.apply_gradients(grads=grads)\n  state = state.replace(batch_stats=updates[\"batch_stats\"])\n\n  metrics = {\"loss\": loss}\n\n  return state, metrics\n\n```", "```py\n# Overfit on one batch.\nfor i in range(5):\n  rng, rng_dropout = jax.random.split(rng, 2)\n  state, metrics = train_step(state, batch, rng_dropout)\n  print(f\"Step {i} loss: {metrics['loss']}\")\n\n```", "```py\nStep 0 loss: 0.6932974457740784\nStep 1 loss: 0.25415313243865967\nStep 2 loss: 0.08513301610946655\nStep 3 loss: 0.02221144177019596\nStep 4 loss: 0.019464049488306046\n\n```", "```py\ndef eval_step(state, batch):\n  \"\"\"Evaluate model on a single batch.\"\"\"\n  logits = state.apply_fn(\n    {\"params\": state.params, \"batch_stats\": state.batch_stats},\n    x=batch[\"sequences\"],\n    is_training=False,\n    mutable=False,\n  )\n  loss = optax.sigmoid_binary_cross_entropy(logits, batch[\"labels\"]).mean()\n  metrics = {\n    \"loss\": loss.item(),\n    **compute_metrics(batch[\"labels\"], logits),\n  }\n  return metrics\n\ndef compute_metrics(y_true: np.ndarray, logits: np.ndarray):\n  \"\"\"Compute accuracy and auROC for model predictions.\"\"\"\n  metrics = {\n    \"accuracy\": accuracy_score(y_true, nn.sigmoid(logits) >= 0.5),\n    \"auc\": roc_auc_score(y_true, logits).item(),\n  }\n  return metrics\n\n```", "```py\n# Evaluate the batch.\nmetrics = eval_step(state, batch)\nprint(metrics)\n\n```", "```py\n{'loss': 0.45877009630203247, 'accuracy': 0.9375, 'auc': 1.0}\n\n```", "```py\n@restorable\ndef train(\n  state: TrainStateWithBatchNorm,\n  rng: jax.Array,\n  dataset_splits: dict[str, tf.data.Dataset],\n  num_steps: int,\n  eval_every: int = 100,\n) -> tuple[TrainStateWithBatchNorm, Any]:\n  \"\"\"Train a model and log metrics over steps.\"\"\"\n  metrics = MetricsLogger()\n  train_batches = dataset_splits[\"train\"].as_numpy_iterator()\n\n  steps = tqdm(range(num_steps))  # Steps with progress bar.\n  for step in steps:\n    steps.set_description(f\"Step {step + 1}\")\n\n    rng, rng_dropout = jax.random.split(rng, 2)\n    train_batch = next(train_batches)\n    state, batch_metrics = train_step(state, train_batch, rng_dropout)\n    metrics.log_step(split=\"train\", **batch_metrics)\n\n    if step % eval_every == 0:\n      for eval_batch in dataset_splits[\"valid\"].as_numpy_iterator():\n        batch_metrics = eval_step(state, eval_batch)\n        metrics.log_step(split=\"valid\", **batch_metrics)\n      metrics.flush(step=step)\n\n    steps.set_postfix_str(metrics.latest([\"loss\"]))\n\n  return state, metrics.export()\n\n```", "```py\ndef load_dataset_splits(\n  path, transcription_factor, batch_size: int | None = None\n):\n  \"\"\"Load TF dataset splits (train, valid, test) as TensorFlow datasets.\"\"\"\n  dataset_splits = {}\n  for split in [\"train\", \"valid\", \"test\"]:\n    dataset = load_dataset(\n      sequence_db=f\"{path}/{transcription_factor}_{split}_sequences.csv\"\n    )\n    ds = convert_to_tfds(dataset, batch_size, is_training=(split == \"train\"))\n    dataset_splits.update({split: ds})\n  return dataset_splits\n\n```", "```py\nprefix = assets(\"dna/datasets\")\ntf_metrics = {}\n\n# Train one model per transcription factor.\nfor transcription_factor in transcription_factors:\n  # Load data for this TF.\n  dataset_splits = load_dataset_splits(\n    assets(\"dna/datasets\"), transcription_factor, batch_size\n  )\n  rng = jax.random.PRNGKey(42)\n  rng, rng_init, rng_train = jax.random.split(rng, 3)\n  dummy_batch = next(dataset_splits[\"train\"].as_numpy_iterator())[\"sequences\"]\n\n  # Create train state.\n  state = ConvModelV2().create_train_state(\n    rng=rng_init,\n    dummy_input=dummy_batch,\n    tx=optax.adam(scheduler),\n  )\n\n  # Train the model.\n  _, metrics = train(\n    state=state,\n    rng=rng_train,\n    dataset_splits=dataset_splits,\n    num_steps=num_steps,\n    eval_every=100,\n    store_path=assets(f\"dna/models/{transcription_factor}\"),\n  )\n\n  # Store metrics.\n  tf_metrics.update({transcription_factor: metrics})\n\n```", "```py\nfrom dlfb.dna.inspect import plot_learning\n\ntf = \"CTCF\"\nplot_learning(tf_metrics[tf], tf);\n\n```", "```py\nfrom dlfb.utils.metric_plots import to_df\n\n# Extract metrics logged per transcription factor.\ntf_df = []\nfor tf, metrics in tf_metrics.items():\n  tf_df.append(to_df(metrics).assign(TF=tf))\ntf_df = pd.concat(tf_df)\n\n# Determine order of best performance.\nauc_df = tf_df[(tf_df[\"metric\"] == \"auc\") & (tf_df[\"split\"] == \"valid\")]\nmax_auc_by_tf = auc_df.groupby(\"TF\")[\"mean\"].max()\ntf_order = max_auc_by_tf.sort_values(ascending=False).index.tolist()\ntf_df[\"TF\"] = pd.Categorical(tf_df[\"TF\"], categories=tf_order, ordered=True)\n\n```", "```py\nsns.set_context(\"notebook\", font_scale=2, rc={\"lines.linewidth\": 2.5})\nsns.set_style(\"ticks\", {\"axes.grid\": True})\ng = sns.relplot(\n  data=tf_df,\n  x=\"round\",\n  y=\"mean\",\n  hue=\"split\",\n  style=\"metric\",\n  kind=\"line\",\n  col=\"TF\",\n  col_order=tf_order,\n  col_wrap=4,\n  alpha=0.8,\n  palette=DEFAULT_SPLIT_COLORS,\n  dashes=True,\n)\ng.set_axis_labels(\"Step\", \"Value\")\ng.set(ylim=(0, 1));\n\n```", "```py\nprint(max_auc_by_tf.sort_values(ascending=False))\n\n```", "```py\nTF\nATF2     0.985182\nCTCF     0.980479\nSRF      0.849944\n           ...   \nARID3    0.769149\nBACH1    0.767122\nZNF24    0.761506\nName: mean, Length: 10, dtype: float64\n\n```", "```py\nclass ConvBlock(nn.Module):\n  \"\"\"Convolutional block with batch norm, GELU and max pooling.\"\"\"\n\n  conv_filters: int\n  kernel_size: tuple[int]\n  pool_size: int\n\n  @nn.compact\n  def __call__(self, x, is_training: bool = True):\n    x = nn.Conv(\n      features=self.conv_filters, kernel_size=self.kernel_size, padding=\"SAME\"\n    )(x)\n    x = nn.BatchNorm(use_running_average=not is_training)(x)\n    x = nn.gelu(x)\n    x = nn.max_pool(\n      x, window_shape=(self.pool_size,), strides=(self.pool_size,)\n    )\n    return x\n\nclass MLPBlock(nn.Module):\n  \"\"\"Dense + GELU + dropout block.\"\"\"\n\n  dense_units: int\n  dropout_rate: float = 0.0\n\n  @nn.compact\n  def __call__(self, x, is_training: bool = True):\n    x = nn.Dense(self.dense_units)(x)\n    x = nn.gelu(x)\n    x = nn.Dropout(rate=self.dropout_rate)(x, deterministic=not is_training)\n    return x\n\n```", "```py\nclass ConvTransformerModel(nn.Module):\n  \"\"\"Model combining CNN, transformer, and MLP blocks.\"\"\"\n\n  num_conv_blocks: int = 2\n  conv_filters: int = 64\n  kernel_size: tuple[int] = (10,)\n  num_mlp_blocks: int = 2\n  dense_units: int = 128\n  dropout_rate: float = 0.2  # Global.\n  num_transformer_blocks: int = 0\n  num_transformer_heads: int = 8\n  transformer_dense_units: int = 64\n\n  @nn.compact\n  def __call__(self, x, is_training: bool = True):\n    for _ in range(self.num_conv_blocks):\n      x = ConvBlock(\n        conv_filters=self.conv_filters,\n        kernel_size=self.kernel_size,\n        pool_size=2,\n      )(x, is_training)\n\n    for i in range(self.num_transformer_blocks):\n      x = TransformerBlock(\n        num_heads=self.num_transformer_heads,\n        dense_units=self.transformer_dense_units,\n        dropout_rate=self.dropout_rate,\n      )(x, is_training)\n\n    x = x.reshape((x.shape[0], -1))\n\n    for i in range(self.num_mlp_blocks):\n      x = MLPBlock(\n        dense_units=self.dense_units // (i + 1), dropout_rate=self.dropout_rate\n      )(x, is_training)\n\n    return nn.Dense(1)(x)\n\n```", "```py\nclass TransformerBlock(nn.Module):\n  \"\"\"Transformer block with self-attention and MLP.\"\"\"\n\n  num_heads: int = 8\n  dense_units: int = 64\n  dropout_rate: float = 0.2\n\n  @nn.compact\n  def __call__(self, x, is_training: bool = True):\n    # Self-attention with layer norm.\n    residual = x\n    x = nn.LayerNorm()(x)\n    x = nn.SelfAttention(num_heads=self.num_heads)(x)\n    x += residual\n\n    # Feedforward block.\n    residual = x\n    x = nn.LayerNorm()(x)\n    x = nn.Dense(self.dense_units)(x)\n    x = nn.gelu(x)\n    x = nn.Dropout(rate=self.dropout_rate)(x, deterministic=not is_training)\n    x = nn.Dense(self.dense_units)(x)  # No GELU after this Dense.\n    x += residual\n    return x\n\n```", "```py\nmodels = {\n  # Our standard 2-layer CNN with dropout and MLP.\n  \"baseline\": ConvTransformerModel(),\n  # Ablations: Remove or reduce certain components.\n  # Only a single convolutional block.\n  \"single_conv_only\": ConvTransformerModel(\n    num_conv_blocks=1, num_transformer_blocks=0, num_mlp_blocks=0\n  ),\n  # Reduced capacity by lowering conv filters.\n  \"fewer_conv_channels\": ConvTransformerModel(conv_filters=8),\n  # Drop the MLP layers to test if they help.\n  \"remove_MLP\": ConvTransformerModel(num_mlp_blocks=0),\n  # Potential improvements: Add more expressive capacity.\n  # Add a transformer block after convolutions.\n  \"add_one_transformer_block\": ConvTransformerModel(num_transformer_blocks=1),\n  # Stack two transformer blocks.\n  \"add_two_transformer_block\": ConvTransformerModel(num_transformer_blocks=2),\n}\n\n```", "```py\n# Train and evaluate multiple model architectures on the ZNF24 dataset.\ntranscription_factor = \"ZNF24\"\ndataset_splits = load_dataset_splits(\n  assets(\"dna/datasets\"), transcription_factor, batch_size\n)\n\n# Prepare a dummy input for model initialization.\ndummy_input = next(dataset_splits[\"train\"].as_numpy_iterator())[\"sequences\"]\n\n# Initialize PRNGs.\nrng = jax.random.PRNGKey(42)\nrng, rng_init, rng_train = jax.random.split(rng, 3)\n\n# Dictionary to store metrics for each model variant.\nmodel_metrics = {}\n\n# Train each model variant and store its metrics.\nfor name, model in models.items():\n  state = model.create_train_state(\n    rng=rng_init,\n    dummy_input=dummy_input,\n    tx=optax.adamw(\n      optax.cosine_decay_schedule(\n        init_value=learning_rate,\n        decay_steps=num_steps,\n      )\n    ),\n  )\n  _, metrics = train(\n    state=state,\n    rng=rng_train,\n    dataset_splits=dataset_splits,\n    num_steps=num_steps,\n    eval_every=100,\n    store_path=assets(f\"dna/models/{name}\"),\n  )\n  model_metrics.update({name: metrics})\n\n```", "```py\n# Extract metrics logged per transcription factor.\nmodel_df = []\nfor model, metrics in model_metrics.items():\n  model_df.append(to_df(metrics).assign(model=model))\nmodel_df = pd.concat(model_df)\n\n# Determine order of best performance.\nauc_df = model_df[\n  (model_df[\"metric\"] == \"auc\") & (model_df[\"split\"] == \"valid\")\n]\nmax_auc_by_model = auc_df.groupby(\"model\")[\"mean\"].max()\nmodel_order = max_auc_by_model.sort_values(ascending=False).index.tolist()\nmodel_df[\"model\"] = pd.Categorical(\n  model_df[\"model\"], categories=model_order, ordered=True\n)\n\n```", "```py\nsns.set_context(\"notebook\", font_scale=1.2, rc={\"lines.linewidth\": 2.5})\nsns.set_style(\"ticks\", {\"axes.grid\": True})\ng = sns.relplot(\n  data=model_df,\n  x=\"round\",\n  y=\"mean\",\n  hue=\"split\",\n  style=\"metric\",\n  kind=\"line\",\n  col=\"model\",\n  col_order=model_order,\n  col_wrap=2,\n  alpha=0.8,\n  palette=DEFAULT_SPLIT_COLORS,\n  dashes=True,\n)\ng.set_axis_labels(\"Step\", \"Value\")\ng.set(ylim=(0.4, 0.9));\n\n```", "```py\ng = sns.lineplot(\n  data=model_df[(model_df[\"metric\"] == \"auc\")],\n  x=\"round\",\n  y=\"mean\",\n  hue=\"model\",\n  style=\"model\",\n  alpha=0.8,\n)\ng.set_xlabel(\"Step\")\ng.set_ylabel(\"auROC\");\n\n```", "```py\nprint(max_auc_by_model.sort_values(ascending=False))\n\n```", "```py\nmodel\nadd_two_transformer_block    0.770343\nadd_one_transformer_block    0.769196\nbaseline                     0.756317\nremove_MLP                   0.752024\nsingle_conv_only             0.719931\nfewer_conv_channels          0.697637\nName: mean, dtype: float64\n\n```", "```py\n# Identify best-performing model variant based on validation auROC.\ntop_model = model_order[0]\n\n# Restore the trained model state from disk.\nstate, _ = restore(\n  assets(f\"dna/models/{top_model}\"),\n  models[top_model].create_train_state(\n    rng=rng_init,\n    dummy_input=next(dataset_splits[\"train\"].as_numpy_iterator())[\"sequences\"],\n    tx=optax.adamw(\n      optax.cosine_decay_schedule(\n        init_value=learning_rate,\n        decay_steps=num_steps,\n      )\n    ),\n  ),\n)\n\n# Evaluate on the held-out test set.\ntest_batch = next(dataset_splits[\"test\"].as_numpy_iterator())\nmetrics = eval_step(state, test_batch)\nprint(metrics)\n\n```", "```py\n{'loss': 0.5123618841171265, 'accuracy': 0.75, 'auc': 0.8196078431372549}\n\n```"]