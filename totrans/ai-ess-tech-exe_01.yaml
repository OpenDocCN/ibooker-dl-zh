- en: Chapter 1\. 99% of Executives Are Misled by AI Advice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As an executive, you’re bombarded with articles and advice on building AI products.
  prefs: []
  type: TYPE_NORMAL
- en: The problem is, a lot of this “advice” comes from other executives who rarely
    interact with the practitioners actually working with AI. This disconnect leads
    to misunderstandings, misconceptions, and wasted resources.
  prefs: []
  type: TYPE_NORMAL
- en: A Case Study in Misleading AI Advice
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An example of this disconnect in action comes from an [interview](https://oreil.ly/7OZOA)
    with Jake Heller, CEO of Casetext.
  prefs: []
  type: TYPE_NORMAL
- en: 'During the interview, Jake made a statement about AI testing that was widely
    shared:'
  prefs: []
  type: TYPE_NORMAL
- en: One of the things we learned is that after it passes 100 tests, the odds that
    it will pass a random distribution of 100k user inputs with *100% accuracy* is
    very high. (emphasis added)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This claim was then amplified by influential figures like [Jared Friedman](https://oreil.ly/gdL7o)
    and [Garry Tan](https://oreil.ly/j_uwY) of Y Combinator, reaching countless founders
    and executives:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aete_01in01.png)'
  prefs: []
  type: TYPE_IMG
- en: The morning after this advice was shared, I received numerous emails from founders
    asking if they should aim for 100% test-pass rates.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re not hands-on with AI, this advice might sound reasonable. But any
    practitioner would know it’s deeply flawed.
  prefs: []
  type: TYPE_NORMAL
- en: “Perfect” Is Flawed
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In AI, a perfect score is a red flag. This happens when a model has inadvertently
    been trained on data or prompts that are too similar to tests. Like a student
    who was given the answers before an exam, the model will look good on paper but
    be unlikely to perform well in the real world.
  prefs: []
  type: TYPE_NORMAL
- en: If you are sure your data is clean but you’re still getting 100% accuracy, chances
    are your test is too weak or not measuring what matters. Tests that always pass
    don’t help you improve; they’re just giving you a false sense of security.
  prefs: []
  type: TYPE_NORMAL
- en: Most importantly, when all your models have perfect scores, you lose the ability
    to differentiate between them. You won’t be able to identify why one model is
    better than another, or strategize about how to make further improvements.
  prefs: []
  type: TYPE_NORMAL
- en: '*The goal of evaluations isn’t to pat yourself on the back for a perfect score.*'
  prefs: []
  type: TYPE_NORMAL
- en: It’s to uncover areas for improvement and ensure your AI is truly solving the
    problems it’s meant to address. By focusing on real-world performance and continuous
    improvement, you’ll be much better positioned to create AI that delivers genuine
    value. Evals are a big topic, and we’ll dive into them more in a future chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Moving Forward
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When you’re not hands-on with AI, it’s hard to separate hype from reality.
    Here are some key takeaways to keep in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: Be skeptical of advice or metrics that sound too good to be true.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Focus on real-world performance and continuous improvement.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Seek advice from experienced AI practitioners who can communicate effectively
    with executives. (*You’ve come to the right place!*)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll dive deeper into how to test AI, along with a data review toolkit in a
    future chapter. First, we’ll look at the biggest mistake executives make when
    investing in AI.
  prefs: []
  type: TYPE_NORMAL
