<html><head></head><body><section data-pdf-bookmark="Chapter 8. Building AI Agents" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch08_building_ai_agents_1736793248616953">&#13;
<h1><span class="label">Chapter 8. </span>Building AI Agents</h1>&#13;
&#13;
<p>AI <a contenteditable="false" data-primary="AI agents" data-type="indexterm" id="icd801"/>agents are fundamentally transforming industries by automating tasks, enhancing user experiences, and, most importantly, delivering on the promise that chatbots once made but never quite fulfilled. Researchers Poole and Mackworth<a contenteditable="false" data-primary="Mackworth, Alan K." data-type="indexterm" id="id1226"/><a contenteditable="false" data-primary="Poole, David L." data-type="indexterm" id="id1227"/> discuss the foundational characteristics of an <em>intelligent </em>or<em> AI agent</em>. Their work introduces the framework depicted in <a data-type="xref" href="#ch08_figure_1_1736793248602392">Figure 8-1</a>.</p>&#13;
&#13;
<p>Within this framework, an agent is something that acts in an environment. An agent acts intelligently if:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Its actions are appropriate for its goals and circumstances.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>It is flexible to changing environments and goals.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>It learns from experience.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p class="fix_tracking">It makes appropriate choices given perceptual and computational limitations.<sup><a data-type="noteref" href="ch08.html#id1228" id="id1228-marker">1</a></sup></p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<figure><div class="figure" id="ch08_figure_1_1736793248602392"><img src="assets/bapp_0801.png"/>&#13;
<h6><span class="label">Figure 8-1. </span>An agent interacting with an environment (source: David L. Poole and <span class="keep-together">Alan K. Mackworth)</span></h6>&#13;
</div></figure>&#13;
&#13;
<p>This model emphasizes the importance of adaptability<a contenteditable="false" data-primary="adaptability" data-secondary="AI agents" data-type="indexterm" id="id1229"/> and learning, which are critical features of modern AI agents. As shown in <a data-type="xref" href="#ch08_figure_1_1736793248602392">Figure 8-1</a>, an agent’s abilities, goals, and prior knowledge influence its actions within an environment. The agent senses stimuli, draws on past experiences, and uses its computational capacity to make decisions.</p>&#13;
&#13;
<p>These intelligent systems have advanced far beyond simple conversational bots, and are now evolving into autonomous entities capable of not just understanding users’ needs but <em>anticipating</em> them, executing complex tasks, and learning from each interaction. This progression is more than a technological shift; it is a strategic advantage that every forward-thinking product leader must embrace.</p>&#13;
&#13;
<section data-pdf-bookmark="What Is an AI Agent?" data-type="sect1"><div class="sect1" id="ch08_what_is_an_ai_agent_1736793248617153">&#13;
<h1>What Is an AI Agent?</h1>&#13;
&#13;
<p><em>AI agents</em> are defined by their ability to perform autonomously, adapting and improving based on user interactions. Historically, AI agents began as <a contenteditable="false" data-primary="rule-based agents" data-type="indexterm" id="id1230"/>rule-based systems—if you think back to early AI projects such as <a contenteditable="false" data-primary="IBM" data-secondary="Deep Blue" data-type="indexterm" id="id1231"/>IBM’s <a href="https://oreil.ly/1yuAV">Deep Blue</a> or even Google’s <a href="https://oreil.ly/L7H01">AlphaGo</a>, <a contenteditable="false" data-primary="Google" data-secondary="AlphaGo" data-type="indexterm" id="id1232"/><a contenteditable="false" data-primary="AlphaGo" data-type="indexterm" id="id1233"/>they were limited to solving highly specific problems, without much flexibility. Modern AI agents, however, possess a far greater degree of autonomy and learning capability, as evidenced by <a contenteditable="false" data-primary="OpenAI" data-secondary="GPT-4 model" data-type="indexterm" id="id1234"/><a contenteditable="false" data-primary="GPT-4 model" data-type="indexterm" id="id1235"/>OpenAI’s GPT-4–powered <a href="https://openai.com/gpt-4">ChatGPT</a>, <a contenteditable="false" data-primary="ChatGPT" data-type="indexterm" id="id1236"/><a contenteditable="false" data-primary="OpenAI" data-secondary="ChatGPT" data-type="indexterm" id="id1237"/>Google’s <a href="https://oreil.ly/JbIZR">Project Astra</a>, <a contenteditable="false" data-primary="Project Astra" data-type="indexterm" id="id1238"/><a contenteditable="false" data-primary="Google" data-secondary="Project Astra" data-type="indexterm" id="id1239"/> OpenAI’s <a href="https://oreil.ly/3Uqx1">Operator</a>, or Microsoft’s<a href="https://oreil.ly/11zHZ"> Copilot</a>. <a contenteditable="false" data-primary="Microsoft" data-secondary="Copilot" data-type="indexterm" id="id1240"/><a contenteditable="false" data-primary="Copilot" data-type="indexterm" id="id1241"/>These tools are not just reactive but proactive, enabling new levels of user engagement by predicting needs and even performing tasks on behalf of users.</p>&#13;
&#13;
<p>OpenAI provides an option for its users to create their own custom agents, called <em>CustomGPTs</em>. <a contenteditable="false" data-primary="CustomGPTs" data-type="indexterm" id="id1242"/><a contenteditable="false" data-primary="OpenAI" data-secondary="CustomGPTs" data-type="indexterm" id="id1243"/>These are tailored versions of OpenAI’s GPT models designed to meet specific user needs or tasks. They don’t require extensive fine-tuning of the base model or direct alterations to the model’s underlying architecture. Instead, they focus on customizing behavior and outputs by using existing capabilities of the foundational GPT model in conjunction with dynamic prompts, tool integrations, and structured workflows.</p>&#13;
&#13;
<p>I often get asked: “Wait, but isn’t ChatGPT an AI agent?” The answer is no, not quite. ChatGPT is an impressive AI language model, but it’s not classified as an AI agent. ChatGPT functions primarily as a conversational model—it responds to user prompts based on pretrained data, but it doesn’t possess autonomy. It doesn’t independently perform tasks or make decisions on behalf of the user. It needs explicit input, lacks a goal-driven framework, and doesn’t act within an environment in an agentic sense.</p>&#13;
&#13;
&#13;
<p>However, custom Gems on Gemini or custom versions of ChatGPT (that combine instructions and extra knowledge/skills) can be considered AI agents, as they can autonomously execute tasks without constant and explicit user prompts. These tailored models are more autonomous and are designed to perform specific tasks, make decisions, and take actions, typically based on a user’s needs. There are also ways for agents to interact with other tools or processes, offering more dynamic, proactive experiences and automated workflows via the use of, for example, zaps by Zapier.</p>&#13;
&#13;
&#13;
&#13;
<p>In essence, <em> agentic products</em> are experiences that serve specific purposes; for example, NotebookLM is an agent that exists in order to understand complex topics and be a dedicated research assistant for the user. Agents operate based on predefined objectives, adapt to new information, and fulfill specific use cases. Kence Anderson <a contenteditable="false" data-primary="Anderson, Kence" data-type="indexterm" id="id1244"/>captures the essence of agent autonomy in his book <a class="orm:hideurl" href="https://www.oreilly.com/library/view/designing-autonomous-ai/9781098110741"><em>Designing Autonomous AI</em></a><em> </em>(O’Reilly, 2022), <a contenteditable="false" data-primary="Designing Autonomous AI (Anderson)" data-type="indexterm" id="id1245"/>noting, “True autonomy in AI systems requires not just the ability to execute predefined tasks but the capacity to learn, adapt, and act independently in pursuit of user goals, often under dynamic and unpredictable conditions.”</p>&#13;
&#13;
<p>AI agents can:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Help you plan, make decisions, and boost productivity</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Take action, create, and orchestrate tasks autonomously</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Make you feel connected, supported, and entertained</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Help you discover new information and learn</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Provide unique and personalized experiences tailored to the user and their goals</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>For product leaders, navigating the world of agentic products can feel new and, at times, overwhelming. Building AI agents requires a deep understanding not only of AI capabilities but also of your users’ behaviors and needs. More than ever, your success relies on identifying the right opportunities to incorporate AI agents into your product ecosystem. The question is not just about whether to build an agent but about crafting the <em>right</em> agent—one that will meaningfully enhance user experiences while driving business value.</p>&#13;
&#13;
<p>However, navigating this shift comes with challenges. Working with AI agents presents a host of considerations—from defining the scope of their autonomy to ensuring their ability to learn and adapt. They also require a <span class="keep-together">different</span> mindset in terms of product design: one in which the agent becomes an active participant in the user journey, rather than just a feature.</p>&#13;
&#13;
<p>It’s crucial to understand the evolving landscape of AI agents and their applications in real-world products. Companies such as <a contenteditable="false" data-primary="Spotify" data-type="indexterm" id="id1246"/>Spotify are already using AI agents to provide music recommendations<a contenteditable="false" data-primary="content recommendation systems" data-secondary="AI agents" data-type="indexterm" id="id1247"/><a contenteditable="false" data-primary="music streaming services" data-secondary="AI agents" data-type="indexterm" id="id1248"/> adapted to users’ individual listening habits, while Amazon<a contenteditable="false" data-primary="Amazon" data-secondary="AI agents" data-type="indexterm" id="id1249"/> uses them for predictive inventory management and automated customer service, with a strong focus on learning from real-time data. Tesla<a contenteditable="false" data-primary="Tesla" data-secondary="AI agents" data-type="indexterm" id="id1250"/><a contenteditable="false" data-primary="autonomous vehicles" data-secondary="AI agents" data-type="indexterm" id="id1251"/> is integrating AI agents into autonomous driving, while Apple<a contenteditable="false" data-primary="Apple Siri" data-type="indexterm" id="id1252"/><a contenteditable="false" data-primary="Siri" data-type="indexterm" id="id1253"/> is evolving Siri with advanced agentive capabilities. Studying the strategies of these early adopters can give product leaders a significant edge.</p>&#13;
&#13;
<p>For those who can master these systems, the rewards are immense: reduced friction, better engagement, and even entirely new forms of value creation for users. In this chapter, I will guide you through the core concepts of AI agents, exploring the types of agents that exist today and how they differ from their predecessors. I will also examine how leading companies are leveraging these systems to create breakthrough products, and provide actionable steps for getting started with building AI agents for your own product. Whether you’re new to this space or looking to refine your strategy, this chapter will equip you with the insights you need to succeed in the world of agentic AI products.</p>&#13;
&#13;
<section data-pdf-bookmark="Not Just Glorified Chatbots" data-type="sect2"><div class="sect2" id="ch08_not_just_glorified_chatbots_1736793248617227">&#13;
<h2>Not Just Glorified Chatbots</h2>&#13;
&#13;
<p>At<a contenteditable="false" data-primary="chatbots" data-secondary="AI agents versus" data-type="indexterm" id="id1254"/> a glance, AI agents might seem like simply chatbots with a new name, but the reality is far more nuanced. While both AI agents and chatbots use <a contenteditable="false" data-primary="NLP (natural language processing)" data-secondary="AI agents" data-type="indexterm" id="id1255"/>NLP to engage with users, the scope, complexity, and capabilities of AI agents go far beyond what traditional chatbots offer.</p>&#13;
&#13;
<p>Chatbots, as we’ve known them, are largely rule-based systems. They are designed to respond to a specific set of inputs based on scripted dialogues (e.g., “Where’s my order?” or “When do you open?”). Think of the early iterations of customer service bots<a contenteditable="false" data-primary="customer service chatbots" data-secondary="AI agents versus" data-type="indexterm" id="id1256"/> on websites such as <a href="https://www.zendesk.com">Zendesk</a> or <a contenteditable="false" data-primary="Zendesk" data-type="indexterm" id="id1257"/>the virtual assistants<a contenteditable="false" data-primary="virtual assistants" data-type="indexterm" id="id1258"/> that helped users navigate simple transactions on <a contenteditable="false" data-primary="Facebook" data-secondary="Messenger" data-type="indexterm" id="id1259"/><a contenteditable="false" data-primary="Meta" data-secondary="Facebook Messenger" data-type="indexterm" id="id1260"/>Facebook Messenger.</p>&#13;
&#13;
<p>AI agents, on the other hand, are designed to act autonomously, learn from interactions, and make decisions without relying solely on scripted responses. For example, while a chatbot might help you find a product on an ecommerce site, an AI agent like <a contenteditable="false" data-primary="Amazon" data-secondary="Alexa" data-type="indexterm" id="id1261"/>Amazon Alexa can anticipate when you’ll run out of household supplies and automatically reorder them for you, based on historical purchase data. Moreover, AI agents can handle far more complex tasks, such as integrating with various external systems (APIs, databases) and autonomously optimizing their actions over time through mechanisms such as reinforcement learning.</p>&#13;
&#13;
<p>Before discussing how to build an AI agent, let’s take a look at how AI agents have evolved over the years.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Early Rule-Based Agents" data-type="sect2"><div class="sect2" id="ch08_early_rule_based_agents_1736793248617290">&#13;
<h2>Early Rule-Based Agents</h2>&#13;
&#13;
<p>AI <a contenteditable="false" data-primary="rule-based agents" data-type="indexterm" id="icd803a"/>agents have evolved significantly from their early beginnings as rule-based systems to the more autonomous, adaptable models we see today. Early agents were limited by their rigid frameworks, programmed to perform specific tasks within controlled environments based on predefined instructions. They had little capacity for flexibility or learning, and were often constrained by the abilities and goals that were directly coded into them. A prime example <a contenteditable="false" data-primary="Microsoft" data-secondary="Clippy" data-type="indexterm" id="id1262"/><a contenteditable="false" data-primary="Clippy" data-type="indexterm" id="id1263"/>is <a href="https://oreil.ly/zsxRn">Microsoft’s Clippy</a>, a little animated paperclip that appeared when a user was writing a document to offer assistance based on preprogrammed rules. While widely mocked by the world, Clippy was a glimpse into the future of AI agents.</p>&#13;
&#13;
<p>Early strategy and simulation games provided a fascinating playground for AI agents, particularly these rule-based systems. For example, in the 1998 release of <em>Battle Chess</em> for<a contenteditable="false" data-primary="Battle Chess" data-type="indexterm" id="id1264"/> MS-DOS (<a data-type="xref" href="#ch08_figure_2_1736793248602425">Figure 8-2</a>), the pieces were controlled by simple AI agents with preprogrammed “move” and “capture” behaviors that followed the rules of chess. However, the AI had no capacity to adapt or learn from past games, relying solely on predefined strategies.</p>&#13;
&#13;
<figure><div class="figure" id="ch08_figure_2_1736793248602425"><img src="assets/bapp_0802.png"/>&#13;
<h6><span class="label">Figure 8-2. </span>Battle Chess (MS-DOS, 1998)</h6>&#13;
</div></figure>&#13;
&#13;
<p class="pagebreak-before">In 1990s computer games like <a href="https://oreil.ly/EfhWt"><em>Warcraft II: Tides of Darkness</em></a> or <a href="https://oreil.ly/6GUns"><em>StarCraft</em></a>, AI-controlled units patrolled designated areas, guarded critical resources, and engaged enemies using preprogrammed tactics. These games showcased early examples of AI-driven behavior, with enemy units responding dynamically to player actions, defending their bases, or coordinating attacks in a way that felt intentional and strategic. While this was a groundbreaking development for its time, the lack of adaptability was evident.</p>&#13;
&#13;
<p>Another memorable game featuring early AI agents <a contenteditable="false" data-primary="Lemmings" data-type="indexterm" id="id1265"/>was <em>Lemmings</em> (1991). The game (<a data-type="xref" href="#ch08_figure_4_1736793248602478">Figure 8-3</a>) had simple rule-based agents: the lemmings followed strict behavioral patterns, marching forward endlessly unless the player intervened to assign them a specific task, such as building bridges or digging. Again, these agents had no learning capabilities and could only follow a set path based on the player’s inputs.</p>&#13;
&#13;
<figure><div class="figure" id="ch08_figure_4_1736793248602478"><img src="assets/bapp_0803.png"/>&#13;
<h6><span class="label">Figure 8-3. </span>Lemmings (1991 “agents/bots”)</h6>&#13;
</div></figure>&#13;
&#13;
<p>These early AI systems set the stage for future developments by highlighting the limitations of purely rule-based approaches. Over time, AI agents became more dynamic and adaptable, evolving into systems capable of learning, making decisions, and taking actions autonomously.</p>&#13;
&#13;
<p class="pagebreak-before">The defining components of an agent are its:</p>&#13;
&#13;
<dl>&#13;
	<dt>Abilities</dt>&#13;
	<dd>&#13;
	<p>The tasks the agent can perform, such as speech recognition, decision making, or physical actions.</p>&#13;
	</dd>&#13;
	<dt>Goals or preferences</dt>&#13;
	<dd>&#13;
	<p>The agent’s objectives or the specific desires it aims to fulfill. These are usually preprogrammed.</p>&#13;
	</dd>&#13;
	<dt>Prior knowledge</dt>&#13;
	<dd>&#13;
	<p>Information the agent already has about the environment or task.</p>&#13;
	</dd>&#13;
	<dt>Stimuli</dt>&#13;
	<dd>&#13;
	<p>Input from the environment, such as data from sensors, interactions, or user feedback. These inputs can include triggers that invoke specific behaviors based on predefined rules or logic. For instance, in simple systems, a particular sensor reading might directly activate a preset response (such as a thermostat turning on the heat when the temperature drops below a threshold). In more advanced AI agents, however, stimuli are processed dynamically, allowing the agent to adapt its actions based on prior experiences, goals, and contextual understanding. This evolution from rigid, rule-based reactions to adaptive, learning-based responses is a defining feature of modern AI agents.</p>&#13;
	</dd>&#13;
	<dt>Past experiences</dt>&#13;
	<dd>&#13;
	<p>The agent’s history of interactions that shape future actions and decisions.</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<p>Over time, AI agents began to incorporate learning mechanisms, marking the shift from rigid, rule-based systems to more flexible, dynamic ones. The introduction of reinforcement learning allowed agents to learn from experience, adapting their behavior based on the outcomes of their actions. Agents no longer needed to be told what to do in every scenario. Instead, they could learn by trial and error, optimizing their actions to achieve goals.</p>&#13;
&#13;
<p>For instance, in popular strategy games like <a contenteditable="false" data-primary="StarCraft II" data-type="indexterm" id="id1266"/>2010’s <em>StarCraft II</em>, <a href="https://oreil.ly/OlDi3">AI agents learn from their mistakes</a>, adjusting their strategies in real time based on the player’s actions. These agents are designed to be more adaptable, using reinforcement learning to improve performance over time.</p>&#13;
&#13;
<p>Today, AI agents incorporate deep learning and neural networks, enabling them to handle complex, multifaceted tasks with minimal human intervention. These modern agents are not just limited to responding to immediate input; they can forecast, plan, and collaborate with other agents to achieve shared goals. They are still widely used in computer and console games such <a contenteditable="false" data-primary="Grand Theft Auto V" data-type="indexterm" id="id1267"/><a contenteditable="false" data-primary="Bioshock Infinite" data-type="indexterm" id="id1268"/><a contenteditable="false" data-primary="FIFA" data-type="indexterm" id="id1269"/><a contenteditable="false" data-primary="Red Dead Redemption 2" data-type="indexterm" id="id1270"/>as <em>Red Dead Redemption 2</em>, <em>FIFA</em>, <em>Bioshock Infinite</em>, and <em>Grand Theft Auto V</em>. <em>Divinity</em><em>: </em><em>Original Sin II</em>, from 2017, also has an impressive non-player-character (NPC) AI.</p>&#13;
&#13;
<p>One striking example is the rise of multi-agent systems<a contenteditable="false" data-primary="multi-agent systems" data-type="indexterm" id="id1271"/>. In environments such as healthcare, <a href="https://oreil.ly/IdcZi">multiple AI agents collaborate</a> to diagnose and treat patients, continuously learning and sharing information to improve outcomes. For instance, in <a href="https://oreil.ly/gQTtY">one paper</a> that created a hospital simulation for research purposes, different AI agents assumed the roles of doctors, nurses, and patients, collectively working toward better patient care (<a data-type="xref" href="#ch08_figure_5_1736793248602500">Figure 8-4</a>).</p>&#13;
&#13;
<figure><div class="figure" id="ch08_figure_5_1736793248602500"><img src="assets/bapp_0804.png"/>&#13;
<h6><span class="label">Figure 8-4. </span>Multi-agent simulation system set at a hospital (source: <em>https://oreil.ly/ziXvT</em>)</h6>&#13;
</div></figure>&#13;
&#13;
<p class="fix_tracking">These agents have memories, can take in sensory input, and can improve themselves based on new data. Their evolution has paved the way for sophisticated applications in areas such as autonomous driving, where vehicles (agents) interact with their environment, learn from real-time data, and make life-or-death <a contenteditable="false" data-primary="rule-based agents" data-startref="icd803a" data-type="indexterm" id="id1272"/>decisions.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Agentive Products" data-type="sect1"><div class="sect1" id="ch08_agentive_products_1736793248617359">&#13;
<h1>Agentive Products</h1>&#13;
&#13;
<p class="fix_tracking">Three<a contenteditable="false" data-primary="AI agents" data-secondary="agentive products" data-type="indexterm" id="icd804"/> major advancements have transformed AI agents into the sophisticated systems we see today: learning, decision making, and autonomous action. These advancements enable agents to process a diverse array of inputs, continuously adapt to their environment, and, most importantly, autonomously fulfill user needs without requiring explicit instructions:</p>&#13;
&#13;
<dl>&#13;
	<dt>Learning</dt>&#13;
	<dd>&#13;
	<p class="fix_tracking">Modern AI agents are designed to learn from experience, much like humans do.<sup><a data-type="noteref" href="ch08.html#id1273" id="id1273-marker">2</a></sup> This ability allows them to refine their behavior and improve their effectiveness over time. For example, a<a contenteditable="false" data-primary="content recommendation systems" data-secondary="AI agents" data-type="indexterm" id="id1274"/> recommendation system in an ecommerce platform can analyze user preferences, purchasing patterns, and behaviors to make increasingly accurate suggestions. Through ML models, agents gain the ability to evolve their understanding of user interactions and environmental stimuli.<sup><a data-type="noteref" href="ch08.html#id1275" id="id1275-marker">3</a></sup></p>&#13;
	</dd>&#13;
	<dt>Making decisions</dt>&#13;
	<dd>&#13;
	<p class="fix_tracking">As agents gather data and learn from their interactions, they also gain the ability to make informed decisions. This is not just about responding to stimuli with predefined actions; it involves evaluating multiple options and choosing the most appropriate response based on goals, constraints, and user needs. In the context of customer service, for instance, an AI agent might decide whether to escalate an issue to a human representative based on the complexity and sentiment of the conversation.</p>&#13;
	</dd>&#13;
	<dt>Taking autonomous action</dt>&#13;
	<dd>&#13;
	<p class="fix_tracking">The <a contenteditable="false" data-primary="autonomy, of AI agents" data-type="indexterm" id="icd804a"/>most significant leap in agents’ evolution is their ability to act autonomously. These actions are not merely reactions to specific triggers; they are proactive decisions that reflect a deeper understanding of user intent. Autonomous agents can perform tasks such as scheduling meetings, sending notifications, and even generating creative content without direct human intervention. They act on behalf of users, anticipating their needs and optimizing outcomes with minimal input.<sup><a data-type="noteref" href="ch08.html#id1276" id="id1276-marker">4</a></sup></p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<p>Thanks to these advancements, AI agents have become indispensable in many applications. They provide personalized solutions by delivering the right response or action at precisely the right time. AI agents are no longer just bots performing repetitive tasks in isolation; they are integral parts of the user experience, designed to assist in meaningful ways.</p>&#13;
&#13;
<p>For instance, users might employ an AI assistant to automate the process of organizing emails, setting up meetings, or even managing their lives (e.g., placing a grocery order). Creative professionals use AI tools to brainstorm ideas, design layouts, or even produce music.<sup><a data-type="noteref" href="ch08.html#id1277" id="id1277-marker">5</a></sup></p>&#13;
&#13;
<section data-pdf-bookmark="Comparing Chatbots to AI Agents and Multi-agents" data-type="sect2"><div class="sect2" id="ch08_comparing_chatbots_to_ai_agents_and_multi_agents_1736793248617433">&#13;
<h2>Comparing Chatbots to AI Agents and Multi-agents</h2>&#13;
&#13;
<p>You<a contenteditable="false" data-primary="chatbots" data-secondary="AI agents versus" data-type="indexterm" id="icd805a"/><a contenteditable="false" data-primary="multi-agent systems" data-type="indexterm" id="icd806a"/> might be wondering how exactly an AI agent differs from a chatbot, and what happens when multiple agents work together. While both chatbots and AI agents handle user interactions, their capabilities and autonomy levels are vastly different. To help clarify, I’ve broken down the key differences in <a data-type="xref" href="#ch08_table_1_1736793248607404">Table 8-1</a> and <a data-type="xref" href="#ch08_figure_6_1736793248602522">Figure 8-5</a>. This comparison highlights how they operate together, their unique capabilities, and the value they bring to different product <a contenteditable="false" data-primary="autonomy, of AI agents" data-startref="icd804a" data-type="indexterm" id="id1278"/><a contenteditable="false" data-primary="complexity" data-secondary="AI agents versus chatbots and multi-agents" data-type="indexterm" id="id1279"/><a contenteditable="false" data-primary="decision-making" data-secondary="AI agents versus chatbots and multi-agents" data-type="indexterm" id="id1280"/><a contenteditable="false" data-primary="adaptability" data-secondary="AI agents" data-type="indexterm" id="id1281"/>scenarios.</p>&#13;
&#13;
<table id="ch08_table_1_1736793248607404">&#13;
	<caption><span class="label">Table 8-1. </span>Comparing chatbots, AI agents, and multiple AI agents</caption>&#13;
	<thead>&#13;
		<tr>&#13;
			<th>Feature</th>&#13;
			<th>Chatbot</th>&#13;
			<th>AI agent</th>&#13;
			<th>Multiple AI agents</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td>&#13;
			<p>Primary purpose</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Conversation and basic task execution</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Autonomous task execution and decision making</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Collaborative problem-solving and task execution</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>&#13;
			<p>Scope</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Limited, often rule-based or predefined conversations</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Broad, with complex tasks and adaptability</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Complex, multistep tasks requiring teamwork and coordination</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>&#13;
			<p>Autonomy</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Low: Limited to predefined scripts and responses</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Medium: Can make autonomous decisions and act on its own</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>High: Agents communicate, collaborate, and coordinate autonomously</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>&#13;
			<p>Learning ability</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Basic: Often relies on static rules or scripted responses</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Advanced: Can use reinforcement learning and data feedback loops to adapt</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Highly advanced: Agents learn both individually and as a group, improving coordination and performance</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>&#13;
			<p>Interactivity</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Primarily user facing; responds to user input</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Interacts with both users and other systems</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Interacts with multiple agents, users, and systems simultaneously</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>&#13;
			<p>Complexity</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Low: Simple logic or basic NLP models</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Medium to high: Uses sophisticated AI models, can integrate multiple capabilities</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Very high: Incorporates multiple agents with different specializations, requiring advanced coordination mechanisms</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>&#13;
			<p>Decision making</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>None to limited: Follows scripted rules or decision trees</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Autonomous: Can analyze data and make informed decisions</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Collective: Makes decisions based on interagent communication and shared goals</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>&#13;
			<p>Adaptability</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Static: Limited to predefined changes in conversation flow</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Dynamic: Can adapt to new information and changing environments</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Highly dynamic: Agents adapt individually and collectively to optimize outcomes in real time</p>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>&#13;
			<p>Example use cases</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>FAQ bots, basic reservations</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Personal assistants, customer support</p>&#13;
			</td>&#13;
			<td>&#13;
			<p>Autonomous driving (coordinated cars), virtual hospitals (AI agents collaborating on patient care)</p>&#13;
			</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<p>Chatbots are primarily designed for conversation and basic task execution. They operate within a limited scope and with minimal autonomy, relying mostly on scripted responses. They are suitable for straightforward tasks such as FAQ interactions and making reservations.</p>&#13;
&#13;
<p>In contrast, autonomous AI agents are capable of more complex and adaptive decision making, using advanced learning techniques such as reinforcement learning to improve their responses and actions over time. These agents are used in roles such as personal assistants and customer support, where a higher level of interaction and decision-making autonomy is beneficial.</p>&#13;
&#13;
<figure><div class="figure" id="ch08_figure_6_1736793248602522"><img src="assets/bapp_0805.png"/>&#13;
<h6><span class="label">Figure 8-5. </span>Comparison of AI agents, chatbots, and multi-agents (source: Dr. Marily Nika)</h6>&#13;
</div></figure>&#13;
&#13;
<p>Multiple AI agents exhibit the highest level of <a contenteditable="false" data-primary="complexity" data-secondary="AI agents versus chatbots and multi-agents" data-type="indexterm" id="id1282"/>complexity and dynamic interaction, collaborating and communicating to solve complicated, multistep tasks in real time. This type of AI system is used in highly coordinated environments such as autonomous driving and virtual hospitals, where seamless integration and collective decision making are crucial.</p>&#13;
&#13;
<p>The differences in scope, complexity, and adaptability across these AI systems highlight the varying capabilities and suitable applications of each type of <a contenteditable="false" data-primary="chatbots" data-secondary="AI agents versus" data-startref="icd805a" data-type="indexterm" id="id1283"/><a contenteditable="false" data-primary="multi-agent systems" data-startref="icd806a" data-type="indexterm" id="id1284"/>agent.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="The AI Agent Product Landscape" data-type="sect2"><div class="sect2" id="ch08_the_ai_agent_product_landscape_1736793248617498">&#13;
<h2>The AI Agent Product Landscape</h2>&#13;
&#13;
<p>The AI agent product landscape spans several domains, offering diverse tools that showcase how companies are leveraging AI to drive productivity and innovation. In the automation space, tools such as <a href="https://www.magicloops.ai">Magic Loops</a> and <a href="https://www.respell.ai">Respell</a> excel<a contenteditable="false" data-primary="Magic Loops" data-type="indexterm" id="id1285"/><a contenteditable="false" data-primary=" Respell" data-type="indexterm" id="id1286"/> at streamlining repetitive workflows, from email management to creative content production, making them invaluable for businesses looking to enhance efficiency.</p>&#13;
&#13;
<p class="pagebreak-before">Virtual assistants<a contenteditable="false" data-primary="virtual assistants" data-type="indexterm" id="id1287"/> form another prominent category, with examples such <a contenteditable="false" data-primary="Lindy" data-type="indexterm" id="id1288"/>as <a href="https://www.lindy.ai">Lindy</a>, which automates professional administrative tasks, and <a href="https://www.hyperwrite.ai">HyperWrite</a>, <a contenteditable="false" data-primary="HyperWrite" data-type="indexterm" id="id1289"/>a tool designed to support content creation and email management, boosting productivity for individual users and teams alike. For developers, specialized AI agents such as Sweep AI and <a href="https://www.phind.com">Phind</a> simplify<a contenteditable="false" data-primary="Sweep AI" data-type="indexterm" id="id1290"/><a contenteditable="false" data-primary="Phind" data-type="indexterm" id="id1291"/> coding tasks by automating bug fixes and providing efficient access to coding resources, empowering software professionals to work smarter.</p>&#13;
&#13;
<p>Finally, new form factors such <a contenteditable="false" data-primary="Humane" data-type="indexterm" id="id1292"/><a contenteditable="false" data-primary="Rewind" data-type="indexterm" id="id1293"/>as <a href="https://humane.com">Humane</a> and <a href="https://www.rewind.ai">Rewind</a> integrate hardware with advanced AI capabilities, enabling seamless user experiences through voice-controlled and memory-enhancing <span class="keep-together">technologies.</span></p>&#13;
&#13;
<p>Because the AI space evolves quickly, many of these tools are likely to become outdated or be replaced by newer, more advanced agents. Some tools worth checking out <a contenteditable="false" data-primary="Cassidy" data-type="indexterm" id="id1294"/>are <a href="https://www.cassidyai.com">Cassidy</a> to build AI automations, CrewAI’s <a href="https://www.crewai.com">Multi-Agent Platform</a>, <a href="https://www.criya.co">Criya</a> for<a contenteditable="false" data-primary="CrewAI’s Criya" data-type="indexterm" id="id1295"/><a contenteditable="false" data-primary="Criya, CrewAI" data-type="indexterm" id="id1296"/> hyper-personalized campaigns, or <a href="https://www.wayfound.ai">Wayfound</a> for <a contenteditable="false" data-primary="Wayfound" data-type="indexterm" id="id1297"/>AI agent management. In my <a href="https://marily.substack.com">newsletter</a>, I regularly share the latest trends and developments in the field.</p>&#13;
&#13;
<p>As I write this in late 2024, Microsoft<a contenteditable="false" data-primary="Microsoft" data-secondary="Copilot" data-type="indexterm" id="id1298"/><a contenteditable="false" data-primary="Copilot" data-type="indexterm" id="id1299"/> has deeply integrated its <a href="https://oreil.ly/11zHZ">Copilot AI</a> into its Office Suite and Windows, making it a core part of user workflows. Copilot assists with document creation, emails, and other tasks, and is positioned as a productivity AI agent available across devices.</p>&#13;
&#13;
<p>In 2023, <a contenteditable="false" data-primary="Meta" data-secondary="AI-driven personas" data-type="indexterm" id="id1300"/>Meta built <a contenteditable="false" data-primary="personas" data-secondary="AI driven" data-type="indexterm" id="id1301"/>AI-driven personas (<a data-type="xref" href="#ch08_figure_7_1736793248602542">Figure 8-6</a>), designed for social interactions, into Facebook<a contenteditable="false" data-primary="Facebook" data-secondary="AI-driven personas" data-type="indexterm" id="id1302"/><a contenteditable="false" data-primary="Meta" data-secondary="Facebook" data-type="indexterm" id="id1303"/> and Instagram<a contenteditable="false" data-primary="Instagram" data-type="indexterm" id="id1304"/><a contenteditable="false" data-primary="Meta" data-secondary="Instagram" data-type="indexterm" id="id1305"/>, though these are no longer used; Meta originally had plans to integrate them more widely into its Metaverse<a contenteditable="false" data-primary="Meta" data-secondary="Metaverse" data-type="indexterm" id="id1306"/> project, with its mixed-reality hardware.</p>&#13;
&#13;
<p>I mention this because it was a good example of a strategic design choice that fostered personalization. The idea was that users could intuitively connect with the persona that best suited their needs, whether that was a playful creative assistant or a focused professional <a contenteditable="false" data-primary="AI agents" data-secondary="agentive products" data-startref="icd804" data-type="indexterm" id="id1307"/>guide.</p>&#13;
&#13;
<figure><div class="figure" id="ch08_figure_7_1736793248602542"><img src="assets/bapp_0806.png"/>&#13;
<h6><span class="label">Figure 8-6. </span>Meta’s AI personas (no longer used)</h6>&#13;
</div></figure>&#13;
&#13;
<p>In 2025, OpenAI introduced <a href="https://oreil.ly/3Uqx1">Operator</a>, an <a contenteditable="false" data-primary="Operator, OpenAI" data-type="indexterm" id="id1308"/><a contenteditable="false" data-primary="OpenAI Operator" data-type="indexterm" id="id1309"/>AI agent designed to perform tasks autonomously within digital environments by leveraging a Computer-Using Agent (CUA) model. Unlike other agents that rely solely on APIs or structured inputs, Operator is equipped with GPT-4o’s vision capabilities and can interact with interfaces by using a mouse and keyboard. This allows it to complete tasks such as filling out forms, navigating websites, and executing multistep workflows across various platforms (<a data-type="xref" href="#ch08_figure_7a_1736793248602542">Figure 8-7</a>).</p>&#13;
&#13;
<p>Capabilities of OpenAI Operator include:</p>&#13;
&#13;
<dl>&#13;
	<dt>Dining and event planning</dt>&#13;
	<dd>&#13;
	<p>Book tables at restaurants, suggest highly rated venues, and secure tickets for events or shows.</p>&#13;
	</dd>&#13;
	<dt>Delivery tracking and scheduling</dt>&#13;
	<dd>&#13;
	<p>Monitor package deliveries, update schedules, and notify users of changes.</p>&#13;
	</dd>&#13;
	<dt>Travel and shopping assistance</dt>&#13;
	<dd>&#13;
	<p>Compare prices, make reservations, and provide updates on itineraries.</p>&#13;
	</dd>&#13;
	<dt class="pagebreak-before less_space">Human-agent collaboration</dt>&#13;
	<dd>&#13;
	<p class="fix_tracking">Users can intervene in ongoing tasks—such as modifying form inputs or verifying details—and return control to Operator, which seamlessly resumes its work.</p>&#13;
	</dd>&#13;
	<dt>Dynamic suggestions</dt>&#13;
	<dd>&#13;
	<p>Based on user behavior and preferences, Operator offers actionable recommendations, from curated news updates to meal ideas.</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<figure><div class="figure" id="ch08_figure_7a_1736793248602542"><img src="assets/bapp_0807.png"/>&#13;
<h6><span class="label">Figure 8-7. </span>OpenAI’s Operator in action: while making a restaurant reservation, it allows users to “take control” of the browser for manual input before seamlessly resuming automation</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Crafting the Right AI Agent for Your Product" data-type="sect1"><div class="sect1" id="ch08_crafting_the_right_ai_agent_for_your_product_1736793248617562">&#13;
<h1>Crafting the Right AI Agent for Your Product</h1>&#13;
&#13;
<p>Now it’s your turn. Start with your users’ most urgent need. Choose a well-defined, specific use case. Focus on an area where AI can have the most immediate impact—whether that’s automating customer service, streamlining internal processes, or enhancing user experiences. This section presents some considerations to help you figure out what type of agent can fulfill this need, and ends with a reflective questionnaire to help you put it all together.</p>&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="Task-Specific Vertical Agents Versus General-Purpose Agents" data-type="sect2"><div class="sect2" id="ch08_task_specific_vertical_agents_versus_general_purpo_1736793248617628">&#13;
<h2 class="less_space">Task-Specific Vertical Agents Versus General-Purpose Agents</h2>&#13;
&#13;
<p>There<a contenteditable="false" data-primary="task-specific AI agents" data-type="indexterm" id="icd808a"/><a contenteditable="false" data-primary="general-purpose AI agents" data-type="indexterm" id="icd808b"/> are generally two categories of agents: task specific and general purpose.</p>&#13;
&#13;
<p><em>Task-specific agents</em> are designed for specialized tasks in specific domains, such as sending emails, booking tickets, or generating content; for example, an AI agent for a sales team that sends basic automated messages to prospects. These agents, called <em>simple reflex agents</em>, operate based on predefined if-then rules, reacting to specific stimuli without memory or learning.</p>&#13;
&#13;
<p>Task-specific agents can be <em>goal based</em>—using AI to choose options that help them accomplish a specific goal, such as optimizing sales outreach or finding the most efficient travel route. They can also be <a contenteditable="false" data-primary="utility-based AI agents" data-type="indexterm" id="id1310"/><em>utility based</em>—designed to maximize a specific utility, such as minimizing energy consumption.</p>&#13;
&#13;
<p><em>General-purpose</em> or “all-in-one” AI agents have an internal model of the world that allows them to adapt their responses and actions to a changing environment. They are designed to handle a wide variety of tasks across multiple domains, from booking flights to generating content.</p>&#13;
&#13;
<p><a data-type="xref" href="#ch08_figure_8_1736793248602563">Figure 8-8</a> shows a framework I use to wrap my mind around the type of agent I will be building.</p>&#13;
&#13;
<figure><div class="figure" id="ch08_figure_8_1736793248602563"><img src="assets/bapp_0808.png"/>&#13;
<h6><span class="label">Figure 8-8. </span>Mental model to visualize agentic capabilities</h6>&#13;
</div></figure>&#13;
&#13;
<p class="pagebreak-before">As you can see, another critical distinction of AI agents lies in whether they operate behind the scenes or are directly consumer facing. Understanding this contrast can help clarify the different roles agents play within a product ecosystem.</p>&#13;
&#13;
<p>On the x-axis:</p>&#13;
&#13;
<dl>&#13;
	<dt>Behind-the-scenes agents</dt>&#13;
	<dd>&#13;
	<p>These <a contenteditable="false" data-primary="behind-the-scenes AI agents" data-type="indexterm" id="id1311"/>agents work in the background, automating processes, optimizing operations, or managing workflows without direct user interaction. For instance, an AI agent embedded in a logistics platform may optimize inventory management or route planning, ensuring efficiency without the end user ever knowing it exists. These agents often focus on operational excellence, driving business outcomes through seamless integration with existing systems.</p>&#13;
	</dd>&#13;
	<dt>Consumer-facing agents</dt>&#13;
	<dd>&#13;
	<p>These <a contenteditable="false" data-primary="consumer-facing AI agents" data-type="indexterm" id="id1312"/>agents interact directly with users, providing services, recommendations, or assistance in real time. Examples include virtual assistants such as Siri<a contenteditable="false" data-primary="Siri" data-type="indexterm" id="id1313"/><a contenteditable="false" data-primary="Apple Siri" data-type="indexterm" id="id1314"/> and Alexa<a contenteditable="false" data-primary="Amazon" data-secondary="Alexa" data-type="indexterm" id="id1315"/>, which engage users through<a contenteditable="false" data-primary="NLP (natural language processing)" data-secondary="AI agents" data-type="indexterm" id="id1316"/> NLP to fulfill tasks. These agents prioritize user experience, aiming to create intuitive and personalized interactions.</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<p>On the y-axis:</p>&#13;
&#13;
<dl>&#13;
	<dt>Task-specific agents</dt>&#13;
	<dd>&#13;
	<p>These agents are designed to handle highly specialized functions within a defined scope. They operate with a clear focus, addressing singular objectives such as email filtering, customer support, or scheduling. <a contenteditable="false" data-primary="Chatfuel" data-type="indexterm" id="id1317"/>For example, <a href="https://chatfuel.com">Chatfuel</a> creates chatbots <a contenteditable="false" data-primary="chatbots" data-secondary="task-specific agents" data-type="indexterm" id="id1318"/><a contenteditable="false" data-primary="customer service chatbots" data-secondary="task-specific agents" data-type="indexterm" id="id1319"/>for customer interactions, <a contenteditable="false" data-primary="NotebookLM" data-type="indexterm" id="id1320"/>while <a href="https://notebooklm.google">NotebookLM</a> serves as a personalized AI tool for summarizing and organizing notes, enabling users to quickly derive insights from structured documents. These agents excel at simplifying repetitive tasks or improving efficiency in targeted areas, making them ideal for organizations looking to automate specific workflows without requiring complex integrations.</p>&#13;
	</dd>&#13;
	<dt class="pagebreak-before less_space">General-purpose agents</dt>&#13;
	<dd>&#13;
	<p>These agents are versatile systems capable of managing a wide variety of tasks across multiple domains. Unlike task-specific agents, they adapt to dynamic user needs and handle diverse objectives, from generating content to managing workflows. Examples <a contenteditable="false" data-primary="LangChain" data-type="indexterm" id="id1321"/>include <a href="https://www.langchain.com">LangChain</a>, a platform for integrating language models with APIs and databases, and <a href="https://oreil.ly/act-1">Adept ACT-1</a>, an AI agent designed to interact with software tools to help users accomplish tasks such as document editing and data analysis. These agents prioritize flexibility and scalability, making them powerful tools for businesses seeking to support broad use cases or deliver comprehensive solutions to <a contenteditable="false" data-primary="task-specific AI agents" data-startref="icd808a" data-type="indexterm" id="id1322"/><a contenteditable="false" data-primary="general-purpose AI agents" data-startref="icd808b" data-type="indexterm" id="id1323"/>users.</p>&#13;
	</dd>&#13;
</dl>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Agent Activation" data-type="sect2"><div class="sect2" id="ch08_agent_activation_1736793248617685">&#13;
<h2>Agent Activation</h2>&#13;
&#13;
<p>You need to decide how the agent will be activated. Agents can be proactive or reactive. Will it require user input via text, audio, or video, or will it act on its own? <em>Proactive agents </em><a contenteditable="false" data-primary="proactive AI agents" data-type="indexterm" id="id1324"/>initiate interactions based on users’ behavior or the context. Examples <a contenteditable="false" data-primary="Zapier" data-type="indexterm" id="id1325"/><a contenteditable="false" data-primary="Dynamic Yield" data-type="indexterm" id="id1326"/>include <a href="https://oreil.ly/dyield">Dynamic Yield</a> and<a href="https://zapier.com"> Zapier</a>. <em>Reactive agents</em> respond<a contenteditable="false" data-primary="reactive AI agents" data-type="indexterm" id="id1327"/> only when a user explicitly invokes them. Examples <a contenteditable="false" data-primary="Botpress" data-type="indexterm" id="id1328"/>include <a href="https://botpress.com">Botpress</a> and<a href="https://oreil.ly/SZ0Qq"> <span class="keep-together">HubSpot’s</span> Chatbot Builder</a>. <a contenteditable="false" data-primary="HubSpot Chatbot Builder" data-type="indexterm" id="id1329"/>This choice depends on the user scenario and the level of interactivity needed for the task at hand. Understanding these factors ensures that your agent delivers value without feeling intrusive or overwhelming.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Autonomy" data-type="sect2"><div class="sect2" id="ch08_autonomy_1736793248617740">&#13;
<h2>Autonomy</h2>&#13;
&#13;
<p>When<a contenteditable="false" data-primary="autonomy, of AI agents" data-type="indexterm" id="id1330"/> designing an AI agent, it’s crucial to consider what kind of autonomy is appropriate for your users. Agents can vary greatly in their level of autonomy (<a data-type="xref" href="#ch08_figure_9_1736793248602582">Figure 8-9</a>). Some agents simply provide suggestions, while others can take action on behalf of the user—such as making purchases or scheduling appointments—with explicit consent. For example, an AI shopping agent<a contenteditable="false" data-primary="shopping agents" data-type="indexterm" id="id1331"/> may start by suggesting products but could eventually make purchases on the user’s behalf, progressively gaining more autonomy. Controlling autonomy levels involves clear decision making about how much independence the agent should have. A critical choice is whether the agent acts reactively, requiring explicit user input, or proactively, anticipating user needs and initiating actions. For instance, a reactive agent might wait for a scheduling request, while a proactive agent could identify calendar conflicts and reschedule on its own.</p>&#13;
&#13;
<figure><div class="figure" id="ch08_figure_9_1736793248602582"><img src="assets/bapp_0809.png"/>&#13;
<h6><span class="label">Figure 8-9. </span>Agentic AI autonomy levels</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Feedback and Learning" data-type="sect2"><div class="sect2" id="ch08_feedback_and_learning_1736793248617794">&#13;
<h2>Feedback and Learning</h2>&#13;
&#13;
<p>You’ll also need to define your AI agent’s long-term learning capabilities. Does the agent need to learn and adapt over time? Decide whether your agent will need reinforcement learning capabilities or feedback loops to improve its performance and responsiveness. You might also consider implementing user feedback tools, such as <a href="https://getzowie.com">Zowie</a> or <a href="https://replika.com">Replika</a>, <a contenteditable="false" data-primary="Zowie" data-type="indexterm" id="id1332"/><a contenteditable="false" data-primary="Replika" data-type="indexterm" id="id1333"/>that allow users to “train” the agent through interactions. These loops can come from explicit feedback (thumbs up/down or star ratings) and implicit feedback (analyzing patterns in user interactions).</p>&#13;
&#13;
<p>Designing these feedback mechanisms requires careful thought. To elicit user-driven feedback, you might implement tools that allow users to provide corrections or preferences directly, such as editing suggestions or flagging errors. For instance, a user might refine an AI-generated report or indicate that a recommendation wasn’t relevant.</p>&#13;
&#13;
<p>For system-driven feedback, you could enable the agent to analyze its own actions, learning from its successes and failures. Techniques such as reinforcement learning<a contenteditable="false" data-primary="RL (reinforcement learning)" data-type="indexterm" id="id1334"/><a contenteditable="false" data-primary="reinforcement learning (RL)" data-type="indexterm" id="id1335"/><a contenteditable="false" data-primary="learning methods" data-secondary="reinforcement learning" data-type="indexterm" id="id1336"/> can help optimize future decisions based on outcomes.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="Design Patterns for Agent Interaction" data-type="sect1"><div class="sect1" id="ch08_design_patterns_for_agent_interaction_1736793248617853">&#13;
<h1 class="less_space">Design Patterns for Agent Interaction</h1>&#13;
&#13;
<p>What will your agent <em>look </em>like? The UI and interaction patterns will also shape the overall experience. This section offers some design patterns to consider as you decide how users will interact with your agent.</p>&#13;
&#13;
<section data-pdf-bookmark="Side Panel" data-type="sect2"><div class="sect2" id="ch08_side_panel_1736793248617911">&#13;
<h2>Side Panel</h2>&#13;
&#13;
<p>A <a contenteditable="false" data-primary="side panels" data-type="indexterm" id="id1337"/>persistent side panel offers a constant, accessible UI element that provides contextual assistance. This works well for both proactive and reactive agents, particularly in domains such as writing, sales, and productivity. A great example is <a href="https://oreil.ly/11zHZ">Microsoft Copilot</a><a contenteditable="false" data-primary="Microsoft" data-secondary="Copilot" data-type="indexterm" id="id1338"/><a contenteditable="false" data-primary="Copilot" data-type="indexterm" id="id1339"/> (<a data-type="xref" href="#ch08_figure_10_1736793248602601">Figure 8-10</a>), which appears as a side panel in Microsoft Office applications, offering suggestions like rewriting content or creating charts based on user activities (online version <a href="https://oreil.ly/FyZHM">available</a>). Similarly,<a href="https://www.hyperwriteai.com"> HyperWrite</a> uses<a contenteditable="false" data-primary="HyperWrite" data-type="indexterm" id="id1340"/> a side panel to assist with writing tasks by offering suggestions and content creation options.</p>&#13;
&#13;
<figure><div class="figure" id="ch08_figure_10_1736793248602601"><img src="assets/bapp_0810.png"/>&#13;
<h6><span class="label">Figure 8-10. </span>Microsoft Copilot side panel (source: <a href="https://oreil.ly/FyZHM">Microsoft</a>)</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="Floating Bubble" data-type="sect2"><div class="sect2" id="ch08_floating_bubble_1736793248617965">&#13;
<h2 class="less_space">Floating Bubble</h2>&#13;
&#13;
<p>A <em>floating bubble</em><a contenteditable="false" data-primary="floating bubbles" data-type="indexterm" id="id1341"/><em> </em>is a small, movable icon that users can click to interact with the agent. It’s often used in reactive agents that respond to specific user inputs. This pattern is commonly seen in tools <a contenteditable="false" data-primary="Intercom" data-type="indexterm" id="id1342"/><a contenteditable="false" data-primary="Floatbot.AI" data-type="indexterm" id="id1343"/>like<a href="https://www.intercom.com"> Intercom</a> or<a href="https://floatbot.ai"> Floatbot.AI</a> (<a data-type="xref" href="#ch08_figure_12_1736793248602660">Figure 8-11</a>), where the bubble allows users to easily access chat-based assistance.</p>&#13;
&#13;
<figure><div class="figure" id="ch08_figure_12_1736793248602660"><img src="assets/bapp_0811.png"/>&#13;
<h6><span class="label">Figure 8-11. </span>Intercom (A) and Floatbot.AI (B)</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="Chat Interface" data-type="sect2"><div class="sect2" id="ch08_chat_interface_1736793248618019">&#13;
<h2 class="less_space">Chat Interface</h2>&#13;
&#13;
<p>A <a contenteditable="false" data-primary="chat interfaces" data-type="indexterm" id="id1344"/>dedicated conversational space, either through text or voice, is ideal for all-in-one agents. This approach provides users with a direct way to communicate with the agent and is most useful for handling more complex tasks. <a href="https://oreil.ly/-A2J-">Salesloft</a>, for instance, uses this format to facilitate conversational interactions between users and AI agents for customer support or sales inquiries (<a data-type="xref" href="#ch08_figure_13_1736793248602679">Figure 8-12</a>).</p>&#13;
&#13;
<figure><div class="figure" id="ch08_figure_13_1736793248602679"><img src="assets/bapp_0812.png"/>&#13;
<h6><span class="label">Figure 8-12. </span>Drift interface</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Integrated UI" data-type="sect2"><div class="sect2" id="ch08_integrated_ui_1736793248618072">&#13;
<h2>Integrated UI</h2>&#13;
&#13;
<p>In this design, the agent is seamlessly integrated into the product’s workflow, offering suggestions or actions without requiring a dedicated interface. This is ideal for proactive agents that subtly enhance user interactions without demanding direct engagement. Two examples <a contenteditable="false" data-primary="Grammarly" data-type="indexterm" id="id1345"/>are Grammarly, which acts as a real-time assistant by analyzing text, suggesting corrections, and improving writing style dynamically, and Tesla’s Autopilot<a contenteditable="false" data-primary="Tesla" data-secondary="integrated UIs" data-type="indexterm" id="id1346"/><a contenteditable="false" data-primary="autonomous vehicles" data-secondary="integrated UIs" data-type="indexterm" id="id1347"/>, an advanced AI agent capable of analyzing real-time data to make autonomous decisions while driving.</p>&#13;
</div></section>&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="Pop-up Notifications" data-type="sect2"><div class="sect2" id="ch08_pop_up_notifications_1736793248618126">&#13;
<h2 class="less_space">Pop-up Notifications</h2>&#13;
&#13;
<p>Pop-up <a contenteditable="false" data-primary="pop-up notifications" data-type="indexterm" id="id1348"/>notifications are best suited for proactive agents that need to guide users or provide timely advice. These notifications can alert users of opportunities or actions the agent can take based on their behavior. For example, Grammarly (<a data-type="xref" href="#ch08_figure_14_1736793248602697">Figure 8-13</a>) uses this approach to suggest grammar improvements or rewording in real time, ensuring that users receive relevant advice just when they need it.</p>&#13;
&#13;
<figure><div class="figure" id="ch08_figure_14_1736793248602697"><img src="assets/bapp_0813.png"/>&#13;
<h6><span class="label">Figure 8-13. </span>Pop-up notification in Grammarly</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Collaborative Browser Interface" data-type="sect2"><div class="sect2" id="ch08_collaborative_browser_interface_1736793248618126">&#13;
<h2>Collaborative Browser Interface</h2>&#13;
&#13;
<p>OpenAI’s Operator introduces <a contenteditable="false" data-primary="OpenAI Operator" data-type="indexterm" id="id1349"/><a contenteditable="false" data-primary="Operator, OpenAI" data-type="indexterm" id="id1350"/><a contenteditable="false" data-primary="collaborative browser interface, OpenAI Operator" data-type="indexterm" id="id1351"/>a unique <em>collaborative browser interface</em>, blending autonomous action with manual control to create a flexible and user-friendly experience. This interface allows users to interact directly with tasks being performed by the agent, such as filling out forms, navigating websites, or booking services. Unlike traditional interfaces that rely solely on either automation or user input, Operator’s design facilitates a seamless transition between both modes.</p>&#13;
&#13;
<p>For instance, when making a restaurant reservation, Operator autonomously navigates to a reservation platform, selects appropriate options, and prepares the booking. At any point, users can choose to “take control” of the browser to manually adjust details, as shown in <a data-type="xref" href="#ch08_figure_7a_1736793248602542">Figure 8-7</a>—such as selecting a different time or verifying specific inputs—before returning control to Operator, which resumes the task without disruption. This capability ensures accuracy and adaptability, particularly in tasks where user preferences or complex inputs may require manual intervention.</p>&#13;
&#13;
<p>The collaborative browser interface excels in situations requiring a combination of automation and human oversight, such as:</p>&#13;
&#13;
<ul>&#13;
	<li>Comparing ticket prices across platforms while allowing users to view and select their preferred options</li>&#13;
	<li>Completing online applications with user-specified customizations</li>&#13;
	<li>Reviewing and approving actions before submission, ensuring confidence in automated workflows</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Scalability, Future-proofing, and Other Considerations" data-type="sect2"><div class="sect2" id="ch08_scalability_future_proofing_and_other_considerat_1736793248618183">&#13;
<h2>Scalability, Future-proofing, and Other Considerations</h2>&#13;
&#13;
<p>It’s <a contenteditable="false" data-primary="scalability" data-secondary="AI agents" data-type="indexterm" id="id1352"/>likely that, over time, your agent will need to scale up. Consider how your AI agent can handle increased user load, expand to include different languages, or integrate new features over time. Think about the backend infrastructure needed to support scaling and real-time responses to user questions.</p>&#13;
&#13;
<p>Data privacy is paramount, especially if your AI agent handles sensitive user information. Ensure compliance with regulations such as <a contenteditable="false" data-primary="regulatory compliance" data-secondary="AI agents" data-type="indexterm" id="id1353"/>GDPR<a contenteditable="false" data-primary="GDPR (General Data Protection Regulation)" data-secondary="AI agents" data-type="indexterm" id="id1354"/> and the California Consumer Privacy Act (CCPA)<a contenteditable="false" data-primary="CCPA (California Consumer Privacy Act)" data-type="indexterm" id="id1355"/>.</p>&#13;
&#13;
<p>Also ensure that the agent can interact with existing systems, APIs, and databases within your organization. Compatibility with CRM, enterprise resource planning (ERP), or customer service platforms might be essential. Platforms can help integrate the agent consistently across tools. I <a contenteditable="false" data-primary="MuleSoft" data-type="indexterm" id="id1356"/>recommend<a href="https://www.mulesoft.com"> MuleSoft</a> for API integrations <a contenteditable="false" data-primary="Make" data-type="indexterm" id="id1357"/>and<a href="https://oreil.ly/cab_B"> Make</a> for process automation.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="Define Success for Your Agent" data-type="sect1"><div class="sect1" id="ch08_define_success_for_your_agent_1736793248618240">&#13;
<h1 class="less_space">Define Success for Your Agent</h1>&#13;
&#13;
<p>At the end of the day, an agentic AI product is still a product, so the metrics you learned about in <a data-type="xref" href="ch06.html#ch06_setting_goals_and_measuring_success_1736793247821683">Chapter 6</a> apply. Consider using these metrics to evaluate your agent:</p>&#13;
&#13;
<dl>&#13;
	<dt>Task completion rate</dt>&#13;
	<dd>&#13;
	<p>How effective is the agent in fulfilling its intended tasks? Example metrics include the number of successful scheduled meetings or the response rate to automated messages.</p>&#13;
	</dd>&#13;
	<dt>Accuracy and quality</dt>&#13;
	<dd>&#13;
	<p class="fix_tracking">Can the agent handle complex user queries? Feedback mechanisms, such as thumbs up/down or star ratings, can help assess the quality of interactions.</p>&#13;
	</dd>&#13;
	<dt>Intervention</dt>&#13;
	<dd>&#13;
	<p>Does the user escalate to a human often? Track the number of sessions in which human intervention was needed, with success meaning a decreasing need for these interventions over time.</p>&#13;
	</dd>&#13;
	<dt>Satisfaction</dt>&#13;
	<dd>&#13;
	<p>Implement surveys or feedback forms to capture direct user feedback. Positive comments on usefulness, ease of interaction, and the agent’s ability to assist with tasks are great indicators of success.</p>&#13;
	</dd>&#13;
</dl>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="AI Agent Questionnaire" data-type="sect1"><div class="sect1" id="ch08_ai_agent_questionnaire_1736793248618296">&#13;
<h1>AI Agent Questionnaire</h1>&#13;
&#13;
<p>Use this questionnaire to help you and your team think through the decisions you’ll need to make as you design your agent:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>What user need will your product fulfill?</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Will your agent be task specific or general? If task specific, will it be a simple reflex agent, goal based, or utility based?</p>&#13;
	</li>&#13;
	<li>&#13;
	<p class="fix_tracking">Will your agent be proactive or reactive? If reactive, how will users invoke it?</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Does the agent need to learn and adapt over time? Decide whether your agent will need reinforcement learning capabilities or feedback loops to improve its performance and responsiveness.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Will you implement user feedback tools that allow users to “train” the agent through interactions? If so, which one(s)?</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>What should the experience look like?</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Which design pattern(s) will your agent use for user interaction?</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>How will the agent scale? What infrastructure will you need?</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>What data does the agent access, and how will you secure it?</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>How will the agent personalize the user experience?</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>How will the agent integrate with other tools or platforms?</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>What metrics will you use to define success?</p>&#13;
	</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Conclusion" data-type="sect1"><div class="sect1" id="ch08_conclusion_1736793248618349">&#13;
<h1>Conclusion</h1>&#13;
&#13;
<p>AI agents are not just a technological marvel; they represent a new paradigm in how we solve problems, interact with users, and design products. Throughout this chapter, we’ve explored the evolution of AI agents, from simple rule-based systems to the complex, learning-driven entities that shape our digital experiences today. We dove into crafting AI agents tailored to specific product needs and outlined a practical checklist to help you make informed decisions. Whether your goal is to automate tasks, enhance personalization, or empower users to make decisions autonomously, the possibilities are endless.</p>&#13;
&#13;
<p>But this is just the beginning. The role of an AI PM is to keep learning, keep iterating, and stay ahead of emerging trends. As AI continues to evolve, so too will the tools and strategies we use to bring these intelligent systems to life. You’ve now explored the foundational principles of AI product management—how AI fits into the broader product lifecycle, how to measure success, and how to create meaningful, scalable AI experiences.</p>&#13;
&#13;
<p>For more real-world examples, certifications, and up-to-date content, I invite you to visit <a href="https://www.aiproduct.com">AI Product Hub</a> for ongoing insights, resources, and community-driven discussions to ensure that your journey into AI product management remains dynamic and <a contenteditable="false" data-primary="AI agents" data-startref="icd801" data-type="indexterm" id="id1358"/>impactful.</p>&#13;
</div></section>&#13;
<div data-type="footnotes"><p data-type="footnote" id="id1228"><sup><a href="ch08.html#id1228-marker">1</a></sup> David L. Poole and Alan K. Mackworth, <em>Artificial Intelligence: Foundations of Computational Agents</em>, <span class="keep-together">2nd Edition</span> (Cambridge University Press, 2017).</p><p data-type="footnote" id="id1273"><sup><a href="ch08.html#id1273-marker">2</a></sup> Tom M. Mitchell, <em>Machine Learning</em> (McGraw-Hill Education, 1997).</p><p data-type="footnote" id="id1275"><sup><a href="ch08.html#id1275-marker">3</a></sup> David Silver et al., <a href="https://oreil.ly/HLSwd">“Mastering the Game of Go with Deep Neural Networks and Tree Search”</a>, <em>Nature</em> 529, no. 7587 (2016): 484–489.</p><p data-type="footnote" id="id1276"><sup><a href="ch08.html#id1276-marker">4</a></sup> Ahmed Elgammal et al., <a href="https://oreil.ly/TIVr-">“CAN: Creative Adversarial Networks, Generating ‘Art’ by Learning About Styles and Deviating from Style Norms”</a>, <em>arXiv</em> preprint, arXiv:1706.07068, June 21, 2017.</p><p data-type="footnote" id="id1277"><sup><a href="ch08.html#id1277-marker">5</a></sup> Akshay Kore, <a class="orm:hideurl" href="https://learning.oreilly.com/library/view/designing-human-centric-ai/9781484280881"><em>Designing Human-Centric AI Experiences: Applied UX Design for Artificial Intelligence</em></a> (O’Reilly, 2022).</p></div></div></section></body></html>