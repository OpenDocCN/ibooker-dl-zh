<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 4. Navigating Agent Trade-Offs: Custom Builds, Frameworks, and Hosted Solutions"><div class="chapter" id="ch04_navigating_agent_trade_offs_custom_builds_framew_1758256567997699">
      <h1><span class="label">Chapter 4. </span>Navigating Agent Trade-Offs: Custom Builds, Frameworks, and Hosted Solutions</h1>
      <blockquote data-type="epigraph" epub:type="epigraph">
        <p>Digital organizations shift the primary focus of integration from the systems to the capabilities, emphasizing clean interfaces over those <span class="keep-together">capabilities</span>.</p>
        <p data-type="attribution">Brandon Byars</p>
      </blockquote>
      <p>Whether you are an insurance company or a startup, the fundamental considerations at the start of the process of deploying an AI agent are largely the same: build versus buy, frameworks versus customization, and of course, cost and scalability concerns. If these trade-offs and considerations sound familiar, they should. Despite AI agents being a wholly new category of technology, their <em>fundamentals</em> are those of most software products. That should give us heart because we have decades of precedent upon which we can rely to build resilient solutions.</p>
      <section data-type="sect1" data-pdf-bookmark="The Developer’s Dilemma: Framework Versus Custom Architecture"><div class="sect1" id="ch04_the_developer_s_dilemma_framework_versus_custom_a_1758256567997789">
        <h1>The Developer’s Dilemma: Framework Versus <span class="keep-together">Custom Architecture</span></h1>
        <p>Not all projects involving or centered around AI agents require the same tooling considerations. Ultimately, the choice between, say, using LangGraph to build out an agent and turning to a hosted service such as Glean AI comes down to one thing: scope. Is the project you’re about to undertake existential to your company’s future, or is it experimental and exploratory? How much data will you need to ingest and process regularly? Will your initial user base begin as large or small? Is this purely an internal tool, or will it be customer facing? Does your company already have a robust infrastructure supporting AI agents, or is this project the first of its kind? All of these questions and more must be, if not answered, at least understood in order to reasonably select a proper AI agent architecture for your project.</p>
        <p><a data-type="xref" href="#ch04_figure_1_1758256567994933">Figure 4-1</a> shows a helpful decision framework for considering some of the most common questions that arise when considering the build-versus-buy decision for AI agents.</p>
        <figure><div id="ch04_figure_1_1758256567994933" class="figure">
          <img alt="Diagram of an AI agent architecture decision grid, showing pros and cons for using custom build, framework, or hosted solution across different use case scenarios." src="assets/mmai_0401.png" width="1242" height="788"/>
          <h6><span class="label">Figure 4-1. </span>AI agent architecture decision framework</h6>
        </div></figure>
        <p>But a simple chart only scratches the surface of the complexities involved. The following three sections break down the case for build, the case for frameworks, and the case for hosted solutions respectively.</p>
        <section data-type="sect2" data-pdf-bookmark="The Case for Build"><div class="sect2" id="ch04_the_case_for_build_1758256567997847">
          <h2>The Case for Build</h2>
          <p>Whether to build from scratch is likely the most consequential decision you can make when starting an AI agent project. It demands significant resources, both in labor and capital. However, it offers unmatched control, and if agents are core to your business, there’s no better decision you can make. Here are a few considerations:</p>
          <dl>
            <dt>“If it’s a core business function—do it yourself no matter what.”</dt>
            <dd>
              <p>This time-tested principle from Joel Spolsky’s classic essay on build-versus-buy decisions is especially relevant for AI agents. When AI becomes core to your competitive advantage, frameworks and hosted solutions can turn into strategic liabilities by limiting your ability to differentiate and iterate rapidly.<sup><a data-type="noteref" id="id74-marker" href="ch04.html#id74">1</a></sup></p>
            </dd>
            <dt>Unparalleled flexibility and customization</dt>
            <dd>
              <p>When you build AI agents from scratch, you’re limited only by the ability of your engineers to code the system you desire and the availability of the integrations you hope to access. This empowers unique and specific solutions to your business problems and software systems that most frameworks will be unable to match. Consider this: the more bespoke software systems you have in place, the less likely an open source framework will meet all your needs.</p>
            </dd>
            <dt>The AI agent becomes more valuable as it becomes more extensible</dt>
            <dd>
              <p>The entire point of the AI agent revolution isn’t simply that AI agents are dynamic chatbots—it’s that their dynamism extends to their ability to call and access tools. But as Brandon Byars notes in his essay “You Can’t Buy Integration,” we shouldn’t think of this as merely “connecting systems together, or sharing data to keep systems in sync.” The real goal is to create “clean interfaces between capabilities” that drive organizational agility. For AI agents, this distinction is foundational to the agility they enable organizations to achieve. When you build from scratch, you have complete control over how these interfaces are designed and optimized. As Byars states, success should be measured “by increasing digital agility over time,” where “those digital capabilities become the primary value driver, arguably even more important than the systems themselves.”<sup><a data-type="noteref" id="id75-marker" href="ch04.html#id75">2</a></sup></p>
            </dd>
            <dt>Performance and cost optimization at scale</dt>
            <dd>
              <p>While not every company should build its own foundational models or infrastructure, there’s a compelling economic case for custom AI agents as usage scales. External services typically charge per API call or token, meaning costs grow linearly (or worse) with success. Custom builds flip this equation: after the initial development investment, increased usage often reduces per-interaction costs through economies of scale. Your infrastructure costs become more predictable and controllable, and performance can be optimized specifically for your use patterns rather than generic workloads. For companies expecting high-volume AI agent interactions, this cost-structure advantage can become substantial over time.</p>
            </dd>
          </dl>
        </div></section>
        <section data-type="sect2" data-pdf-bookmark="The Case for Frameworks"><div class="sect2" id="ch04_the_case_for_frameworks_1758256567997899">
          <h2>The Case for Frameworks</h2>
          <p>Using frameworks to build agents is often the best starting point for new projects. If you’re new to agents, frameworks provide guidance through up-to-date documentation, state-of-the-art capabilities, and fast iteration. If you’re more experienced, frameworks still help you build quickly and gather feedback for proof-of-concept work. Here’s a breakdown of their main benefits:</p>
          <dl>
            <dt>Accelerated development and prototyping</dt>
            <dd>
              <p>When you are building an AI agent, start with the fundamentals: what is the project scope? If scope remains unclear but stakeholder demos are critical, consider established frameworks like LangGraph, AutoGen, and CrewAI, which have quick tutorials on building agents zero-to-one on their websites. Remember, you can always refactor code from a framework to a customization. But it’s much more difficult to refactor the other way around—from a customization to a framework.</p>
            </dd>
            <dt>Lower barrier to entry</dt>
            <dd>
              <p>The greatest benefit of a good framework is its lower barrier to entry—that’s the whole point of an abstraction. What’s easier: building a car from scratch or buying one premade? The same logic applies to AI agents. If your team is new to agents, it’s much wiser to leverage a prewritten open source framework that thousands of people have tried, tested, and kicked the <span class="keep-together">tires on</span>.</p>
            </dd>
            <dt>Encapsulation of best practices</dt>
            <dd>
              <p>So long as you are careful, frameworks will be the encapsulation of industry best practices. In the best-case scenario, adopting a modern, popular framework will put you in an advantageous position to leverage proven patterns and tools. But be careful in your choice of frameworks. Always scope out the potential use cases for your AI agent. Ask any seasoned developer about the pains of having chosen (or been forced into) the wrong framework—suddenly, a simple integration turns into weeks of work that could have been written manually in hours.</p>
            </dd>
          </dl>
        </div></section>
        <section data-type="sect2" data-pdf-bookmark="The Case for Hosted Solutions"><div class="sect2" id="ch04_the_case_for_hosted_solutions_1758256567997947">
          <h2>The Case for Hosted Solutions</h2>
          <p>Hosted solutions are arguably the most straightforward cases to consider. If your organization lacks robust experience or infrastructure to build AI agents, they’re usually a safe bet:</p>
          <dl>
            <dt>Fastest time to value</dt>
            <dd>
              <p>When it comes to zero-to-one deployments of an AI system, you’re usually not going to get faster results than a hosted solution. Hosted platforms such as Glean or Cognigy focus solely on providing customers with the ability to deploy agents with minimal overhead. Cloud providers such as Amazon Web Services (AWS), Google Cloud, and Azure all offer their own versions of agent platforms that, while typically requiring more intensive work, will more easily integrate into existing enterprise cloud networks.</p>
            </dd>
            <dt>No infrastructure overhead</dt>
            <dd>
              <p>The primary value of hosted solutions is the lack of infrastructure management required. For every hour spent managing infrastructure, users could be focusing on core tasks that drive business value instead.</p>
            </dd>
            <dt>Professional support and service-level agreements (SLAs)</dt>
            <dd>
              <p>Most hosted solutions include professional support and SLAs that severely derisk the reliance on such tools, especially by enterprise staff who have less experience with generative AI and machine learning engineering.</p>
            </dd>
            <dt>Continuous updates and improvements</dt>
            <dd>
              <p>These solutions regularly enhance their features and product offerings, soliciting feedback from their user base to maintain feature parity with the competition and to retain best practices.</p>
            </dd>
          </dl>
        </div></section>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Designing for the Future: Preventing Architectural and Vendor Lock-In"><div class="sect1" id="ch04_designing_for_the_future_preventing_architectural_1758256567997998">
        <h1>Designing for the Future: Preventing Architectural and Vendor Lock-In</h1>
        <p>While the allure of rapid deployment and expansive capabilities makes AI vendor solutions attractive, understanding how these systems create dependencies is crucial for maintaining long-term flexibility and control over your technology stack. </p>
        <section data-type="sect2" data-pdf-bookmark="The Nature of AI Lock-In"><div class="sect2" id="ch04_the_nature_of_ai_lock_in_1758256567998047">
          <h2>The Nature of AI Lock-In</h2>
          <p>There are many manifestations and flavors of vendor lock-in. Here are three of the most common:</p>
          <dl>
            <dt>Proprietary model APIs</dt>
            <dd>
              <p>Some API designs require you to code around certain frameworks and specifications that are vendor and framework specific and are not adopted industrywide. Avoid this if you can. The only appropriate time is if you are in a niche industry or require niche data that simply cannot be returned another way.</p>
            </dd>
            <dt>Nonexportable fine-tuned models</dt>
            <dd>
              <p>Some vendors provide the option to fine-tune models on their systems but do not provide the option to export their model weights in hopes you will simply use their APIs. This can come up when resource-constrained companies look for quick fixes but can leave your IP held hostage.</p>
            </dd>
            <dt>Integrated data and memory systems</dt>
            <dd>
              <p>By far the most consequential lock-in occurs in the storage of critical data on external AI vendor systems—data such as conversation histories, user metadata, and vector embeddings for memory. Migrating this data can become costly because of substantial egress fees, technical challenges, and even the inability to host that data on your own systems.</p>
            </dd>
          </dl>
          <p>These lock-in phenomena are not mutually exclusive, nor are they collectively exhaustive. Only by planning ahead can you mitigate these risks effectively.</p>
        </div></section>
        <section data-type="sect2" data-pdf-bookmark="Architectural Strategies for Portability"><div class="sect2" id="ch04_architectural_strategies_for_portability_1758256567998093">
          <h2>Architectural Strategies for Portability</h2>
          <p>Beyond understanding lock-in risks, successful organizations implement concrete architectural patterns that preserve flexibility while still leveraging the power of modern AI services:</p>
          <dl>
            <dt>Modularity and abstraction</dt>
            <dd>
              <p>The most effective strategy to avoid vendor lock-in (and overcomplexity) is to design agent systems with modular, composable architectures. This enables easy swapping between different vendors or even between external vendors and nascent and growing internal services that could eventually replace the vendors altogether. The easiest way to achieve this is to build abstractions around vendor APIs such that the internal API remains consistent and agnostic to the external API call. Such an abstraction can serve as, say, a generative AI (GenAI) chat-completion service that is able to route its calls dynamically between GPT-5, Sonnet 4, and an internally hosted model. If your organization later decided to switch models from Anthropic to, say, Google Gemini, or even to abandon external LLMs altogether, only the internal GenAI service would need to be updated, while the core application code would remain unchanged.</p>
            </dd>
            <dt>Open standards</dt>
            <dd>
              <p>Whenever possible, reduce dependency risks by building on well-established standards and protocols rather than proprietary ones. This ensures greater interoperability between your systems and vendors. This does not mean you should integrate the bleeding edge of open source tooling—the field of GenAI is too tumultuous to lock yourself in. For example, while MCP has garnered a great deal of interest, there’s no guarantee it will become the industry norm. Balance innovation with stability.</p>
            </dd>
            <dt>Containerization</dt>
            <dd>
              <p>A tried-and-true method, containerization is one of the key architectural decisions a team can make to ensure flexibility and portability of their app—flexibility that can be used to avoid vendor lock-in. When we containerize an app, we encapsulate our entire application and its dependencies into a single portable unit. This container can then be deployed on almost any cloud platform (AWS, Google Cloud, Azure, etc.) or even on premises for those companies who anticipate their agents becoming central to their business. This approach maximizes deployment options and effectively decouples an agent application from its underlying host environment.</p>
            </dd>
          </dl>
          <p>By leaning on the fundamentals of software engineering, teams can more confidently navigate the build-versus-buy decision space for AI agents. The key is to anchor decisions in the function of the agent and its strategic relevance to your business. If your goal is to run a quick proof of concept, a hosted solution offers a fast and low-risk path to user feedback. If you’re experimenting with new paradigms, agent frameworks provide a flexible and low-friction starting point. But if your company is committed to riding the agent wave for the long haul, it’s essential to start with a framework, iterate quickly, and then graduate to your own custom stack—one that protects your independence and positions you for long-term agility and control.</p>
        </div></section>
      </div></section>
    <div data-type="footnotes"><p data-type="footnote" id="id74"><sup><a href="ch04.html#id74-marker">1</a></sup> Joel Spolsky, “In Defense of Not-Invented-Here Syndrome,” Joel on Software, October 14, 2001, <a href="https://www.joelonsoftware.com/2001/10/14/in-defense-of-not-invented-here-syndrome"><em class="hyperlink">https://www.joelonsoftware.com/2001/10/14/in-defense-of-not-invented-here-syndrome</em></a>. </p><p data-type="footnote" id="id75"><sup><a href="ch04.html#id75-marker">2</a></sup> Brandon Byars, “You Can’t Buy Integration,” MartinFowler.com, December 14, 2021, <a href="https://martinfowler.com/articles/cant-buy-integration.html"><em class="hyperlink">https://martinfowler.com/articles/cant-buy-integration.html</em></a>.</p></div></div></section></div></div></body></html>