- en: Chapter 4\. Using Data with PyTorch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4章\. 使用PyTorch的数据
- en: In the first three chapters of this book, you trained models using a variety
    of data, from the Fashion MNIST dataset that was conveniently bundled via an API
    to the image-based “Horses or Humans” and “Dogs vs. Cats” datasets, which were
    available as ZIP files that you had to download and preprocess. So by now, you’ve
    probably realized that there are lots of different ways of getting the data with
    which to train a model.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的前三章中，你使用各种数据训练模型，从通过API方便地捆绑的Fashion MNIST数据集，到基于图像的“马或人”和“狗与猫”数据集，这些数据集作为ZIP文件提供，你需要下载并预处理。因此，到现在你可能已经意识到，有无数种方式获取用于训练模型的数据。
- en: However, many public datasets require you to learn lots of different domain-specific
    skills before you begin to consider your model architecture. The goal behind PyTorch
    domains and the tools available at the `torch.utils.data.Datasets` namespace is
    to expose datasets in a way that’s easy to consume, where all the preprocessing
    steps of acquiring the data and getting it into PyTorch-friendly APIs are done
    for you.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，许多公共数据集要求你在开始考虑模型架构之前学习很多不同的领域特定技能。PyTorch领域和`torch.utils.data.Datasets`命名空间中提供的工具背后的目标是以一种易于消费的方式公开数据集，其中获取数据和将其转换为PyTorch友好的API的所有预处理步骤都为你完成。
- en: 'You’ve already seen a little of this idea in how PyTorch handled Fashion MNIST
    back in [Chapter 2](ch02.html#ch02_introduction_to_computer_vision_1748548889076080).
    As a recap, all you had to do to get the data was this:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经在[第2章](ch02.html#ch02_introduction_to_computer_vision_1748548889076080)中看到PyTorch如何处理Fashion
    MNIST，对此进行回顾，你获取数据所需要做的只是以下这些：
- en: '[PRE0]'
  id: totrans-4
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In the case of this dataset, we also did an import from the torchvision library
    to get the datasets object that contained the reference to Fashion MNIST:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个数据集的情况下，我们还从torchvision库中导入以获取包含Fashion MNIST引用的数据集对象：
- en: '[PRE1]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Given that it’s a computer vision–oriented dataset, it makes sense that it would
    be in the torchvision library.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个面向计算机视觉的数据集，它位于torchvision库中是有道理的。
- en: 'PyTorch has many other datasets of different data types that can be loaded
    in the same way. These include the following:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch有许多其他不同类型的数据集，可以以相同的方式加载。以下是一些：
- en: Vision
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉
- en: Fashion MNIST is in the aforementioned torchvision library. It’s one of the
    “Image Classification” built-in datasets, but there are many more for other scenarios
    like Image Detection, Segmentation, Optical Flow, Stereo Matching, Image Pairing,
    Image Captioning, Video Classification, Video Predictions, and more.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Fashion MNIST位于前面提到的torchvision库中。它是“图像分类”内置数据集之一，但还有更多适用于其他场景的数据集，如图像检测、分割、光流、立体匹配、图像配对、图像描述、视频分类、视频预测等。
- en: Text
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 文本
- en: Common text datasets are available in the torchtext library. There are far too
    many to list here, but there are ones for Text Classification, Language Modeling,
    Machine Translation, Sequence Tagging, Question and Answer, and Unsupervised Learning.
    You can find more details on these in the [PyTorch documentation](https://oreil.ly/aFamN).
    Note that this library isn’t limited to the datasets; it also has many helper
    functions that you will use when processing text.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在torchtext库中可以找到常见的文本数据集。这里列出的太多，无法一一列举，但包括文本分类、语言模型、机器翻译、序列标注、问答和未监督学习等。更多详情可以在[PyTorch文档](https://oreil.ly/aFamN)中找到。请注意，这个库不仅限于数据集；它还包含许多辅助函数，这些函数在处理文本时你会用到。
- en: '*Audio*'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '*音频*'
- en: The torchaudio library contains many datasets that can be used in machine learning
    scenarios for sound or speech. Details can be found in the [PyTorch documentation](https://oreil.ly/tvDe4).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: torchaudio库包含许多数据集，可以在机器学习场景中用于声音或语音。详细信息可以在[PyTorch文档](https://oreil.ly/tvDe4)中找到。
- en: All datasets are subclasses of `torch.utils.data.Dataset,` so it’s important
    to take a look at this library and understand it well. That will help you not
    only consume existing datasets but also create your own to share with others.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 所有数据集都是`torch.utils.data.Dataset`的子类，因此查看这个库并深入了解它非常重要。这将帮助你不仅消费现有的数据集，还可以创建自己的数据集与他人分享。
- en: Getting Started with Datasets
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用数据集
- en: 'The `torch.utils.data.Dataset` is an abstract class that represents a dataset.
    To create a custom dataset, you just need to subclass it and implement these methods:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.utils.data.Dataset`是一个表示数据集的抽象类。要创建自定义数据集，你只需将其子类化并实现这些方法：'
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This should return the total number of items in your dataset:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该返回你数据集中的项目总数：
- en: '[PRE3]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This should return a single item from your dataset at the specified index. This
    item will be transformed before sending it to the model.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该从你的数据集中返回指定索引的单个项目。在将其发送到模型之前，该项目将被转换。
- en: 'Here’s an example:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个示例：
- en: '[PRE4]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: That’s pretty much it at a very low level. The data itself is in an array called
    `data[]`. Now, imagine we want to create a dataset with a linear relationship
    between an *x* value and a *y* value like we had in [Chapter 1](ch01.html#ch01_introduction_to_pytorch_1748548870019566).
    How would we use it?
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在非常低级别上，数据本身位于名为`data[]`的数组中。现在，想象一下，我们想要创建一个具有*x*值和*y*值之间线性关系的数据集，就像我们在[第1章](ch01.html#ch01_introduction_to_pytorch_1748548870019566)中看到的那样。我们该如何使用它？
- en: 'Let’s say we start with some simple synthetic data, like this:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们从一个简单的合成数据开始，如下所示：
- en: '[PRE5]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Then, we could turn it into a dataset like this:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以将其转换为如下所示的数据集：
- en: '[PRE6]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Then, to use the dataset, we simply create an instance of the class, initialize
    it with our *x* and *y* values, pass it to a `DataLoader`, and enumerate that:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，为了使用数据集，我们只需创建一个类的实例，用我们的*x*和*y*值初始化它，将其传递给一个`DataLoader`，并枚举它：
- en: '[PRE7]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: With this foundation, you can now explore the dataset classes that have been
    made available in the various libraries we’ve mentioned since the beginning of
    this chapter. Given that they will build on or extend this class, the APIs should
    look familiar.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个基础上，你现在可以探索自本章开始以来在各个库中提供的数据集类。鉴于它们将基于或扩展此类，API应该看起来很熟悉。
- en: Exploring the FashionMNIST Class
  id: totrans-32
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索FashionMNIST类
- en: Earlier in the book, we saw the `FashionMNIST` class—which provides access to
    the Fashion-MNIST dataset, which is a training set of 60,000 examples of 10 classes
    of clothing—and an accompanying test set of 10,000 examples. Each of these examples
    is a 28 × 28 grayscale image.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的早期，我们看到了`FashionMNIST`类——它提供了访问Fashion-MNIST数据集的权限，这是一个包含10类服装60,000个示例的训练集，以及一个包含10,000个示例的配套测试集。每个示例都是一个28
    × 28的灰度图像。
- en: 'In the case of this dataset, you use the *same* class whether you’re using
    training data or test/validation data, and the data that you receive is based
    on the `train` parameter that you pass to it. Here’s an example:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个数据集的情况下，无论你是使用训练数据还是测试/验证数据，你都会使用相同的类，而你接收到的数据基于传递给它的`train`参数。以下是一个示例：
- en: '[PRE8]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: When you set `train=True,` the code that overrides the class init method will
    take the 60,000 records and return them to the caller. Other parameters are there,
    like specifying the root for where the data should go and even whether or not
    to download the data. Finally, as you’ll commonly see when downloading data, there
    is the `transform=` parameter. As you saw in the preceding base class, this parameter
    will be available as an optional parameter for all datasets, and it will apply
    a transform when set.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当你设置`train=True`时，覆盖类初始化方法的代码将获取60,000条记录并将其返回给调用者。其他参数包括指定数据应存放的根目录，甚至是否下载数据。最后，正如你通常在下载数据时看到的，还有`transform=`参数。正如你在前面的基类中看到的，当设置此参数时，它将作为所有数据集的可选参数，并在设置时应用转换。
- en: Generic Dataset Classes
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通用数据集类
- en: You may need to use some data that isn’t available in the dataset classes, like
    `FashionMNIST`, but you’ll also want to take advantage of everything in the data
    ecosystem—such as the ability to transform your data, things like splitting, and
    all the good stuff in the `DataLoader` class you’ll see later in this chapter.
    To that end, `torch.utils.data` provides a number of generic dataset classes you
    could use.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能需要使用在数据集类中不可用的某些数据，例如`FashionMNIST`，但你也会想利用数据生态系统中的一切——例如，转换你的数据的能力，像拆分这样的东西，以及你将在本章后面看到的`DataLoader`类中的所有好东西。为此，`torch.utils.data`提供了一系列通用的数据集类，你可以使用。
- en: ImageFolder
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ImageFolder
- en: In [Chapter 3](ch03.html#ch03_going_beyond_the_basics_detecting_features_in_ima_1748570891074912),
    we used the “Horses or Humans,” “Rock, Paper, Scissors,” and “Cats vs. Dogs” datasets,
    which are not available in a class directly but instead as a ZIP file containing
    the images. When we downloaded them and saved them into subdirectories for the
    different image types (e.g., one folder for “Horses” and another for “Humans”),
    the generic `ImageFolder` dataset class could act as a dataset for us.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第3章](ch03.html#ch03_going_beyond_the_basics_detecting_features_in_ima_1748570891074912)中，我们使用了“马或人”、“石头、剪刀、布”和“猫对狗”数据集，这些数据集不是直接作为类提供的，而是作为包含图像的ZIP文件。当我们下载并将它们保存到不同图像类型的子目录中（例如，“马”一个文件夹，“人”另一个文件夹）时，通用的`ImageFolder`数据集类可以充当我们的数据集。
- en: In that case, the images were streamed (via a `DataLoader`) from the directory
    according to the batch size and other rules on the `DataLoader`. The labels were
    derived from the directory names, and the associated class indices were the labels
    in alphabetical order. So, “Horses” would be class 0, and “Humans” would be class
    1\. Please watch out for that when building and debugging because you might miss
    out on this ordering!
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，图像是通过 `DataLoader` 从目录中按批大小和其他规则流式传输的。标签是从目录名称派生出来的，相关的类索引是按字母顺序排列的标签。所以，“Horses”
    将是类别 0，“Humans” 将是类别 1。请注意，在构建和调试时要注意这一点，因为你可能会错过这种排序！
- en: For example, we tend to say, “Rock, Paper, Scissors” in that order, and we would
    therefore expect them to be classes 0, 1, and 2, respectively. But in *alphabetical*
    order, Paper would be class 0, Rock would be class 1, and Scissors would be class
    2!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们倾向于按此顺序说“石头，剪刀，布”，因此我们预计它们分别是类别 0、1 和 2。但在字母顺序中，纸张将是类别 0，石头将是类别 1，剪刀将是类别
    2！
- en: Tip
  id: totrans-43
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: 'One tool to use for this is to create a custom index like the one below:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 用于此目的的一个工具是创建一个如下所示的定制索引：
- en: '[PRE9]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: DatasetFolder
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DatasetFolder
- en: '`ImageFolder` is actually a subclass of the more generic `DatasetFolder` class,
    one that’s customized for images. The `DatasetFolder` class isn’t limited to image
    data, and you can use it for anything. It also allows you to use directories for
    labels. So, for example, say you have text files that contain text of different
    classes with a directory structure like this:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`ImageFolder` 实际上是更通用的 `DatasetFolder` 类的一个子类，它针对图像进行了定制。`DatasetFolder` 类不仅限于图像数据，你可以用它来处理任何东西。它还允许你使用目录作为标签。例如，假设你有一些包含不同类别文本的文本文件，其目录结构如下：'
- en: '[PRE10]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: You could then use a `DatasetFolder` to stream the documents according to the
    correct labels. Also, because this class is document based, you could apply a
    transform to extract from the file!
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以使用 `DatasetFolder` 按正确的标签流式传输文档。此外，因为这个类是基于文档的，所以你可以应用转换来从文件中提取信息！
- en: FakeData
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: FakeData
- en: '`FakeData` is a useful generic dataset that, as its name suggests, provides
    you with fake data. At the time of writing, it only supports creating fake image
    data. It’s also very useful if you don’t have data on hand but want to experiment
    with different architectures, or if you want to benchmark your system.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '`FakeData` 是一个有用的通用数据集，正如其名称所暗示的，为你提供虚假数据。在撰写本文时，它仅支持创建虚假图像数据。如果你没有数据但想实验不同的架构，或者如果你想对你的系统进行基准测试，它也非常有用。'
- en: 'You can use `FakeData` in the same way you’d use any of the datasets you’ve
    seen so far in this book. So, for example, if you wanted to create a set of `FakeData`
    for the MobileNet model, which uses 224 × 224 color images, you’d do it with code
    like this:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 `FakeData` 的方式使用你在这本书中看到的任何数据集。例如，如果你想为使用 224 × 224 彩色图像的 MobileNet 模型创建一组
    `FakeData`，你可以用如下代码实现：
- en: '[PRE11]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This would create 100 images (containing just noise) of the desired size and
    span them across 10 classes. You could then use this data in a `DataLoader` in
    the same way you’d use any other dataset.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建 100 张所需尺寸的包含噪声的图像，并将它们分布在 10 个类别中。然后，你可以像使用任何其他数据集一样在 `DataLoader` 中使用这些数据。
- en: While `FakeData` only gives image types, you could relatively easily create
    your own CustomData (as we looked at earlier) to provide fake data in other formats,
    such as numeric or sequence data.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 `FakeData` 只提供图像类型，但你相对容易地创建自己的 CustomData（如我们之前所看到的）以提供其他格式的虚假数据，例如数值或序列数据。
- en: Using Custom Splits
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用自定义拆分
- en: Up to this point, all of the data you’ve been using to build models has been
    pre-split for you into training and test sets. For example, with Fashion MNIST,
    you had 60,000 and 10,000 records, respectively. But what if you don’t want to
    use those splits? What if you want to split the data yourself, according to your
    own needs?
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你用来构建模型的所有数据都已经预先为你分割成训练集和测试集。例如，对于 Fashion MNIST，你有 60,000 和 10,000 条记录。但如果你不想使用这些分割怎么办？如果你想根据自己的需求来分割数据怎么办？
- en: Thankfully, when using datasets, you can generally do this with an easy and
    intuitive API.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，在使用数据集时，你可以通常通过一个简单直观的 API 来完成这些操作。
- en: So, for example, when you loaded the `FashionMNIST` class previously, you specified
    the `train` parameter to get it to give you the training data (60,000 records)
    or the test data (10,000 records).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，当你之前加载 `FashionMNIST` 类时，你指定了 `train` 参数以获取训练数据（60,000 条记录）或测试数据（10,000 条记录）。
- en: 'To override this, you simply ignore it, and you’ll get all of the data:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'To create your own split, you can use the `torch.utils.data` namespace, which
    contains a function called `random_split`. So, for example, if you want to have
    a validation set that `FashionMNIST` doesn’t provide, you can divide the dataset
    into three datasets with `random_split`. Here’s the code that will assign 70%
    of the data to a training set, 15% to a testing set, and 15% to a validation set:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As you can see, this process is pretty straightforward. We get the number of
    records in the dataset as `total_count` and then calculate 70% of them (0.7 times
    the total count) to be the training count and 15% of them to be the validation
    count. When making calculations like this, you may end up with rounding errors
    that leave some records out—so instead of using 15% for the test count, you can
    just set the quotient for training to be the total minus the training and validation
    records. This will ensure all the data is used and none is wasted.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: What’s really nice about this approach is that it gives you a really simple
    way to get new and different slices of your dataset. As you train models, it gives
    you a new way to evaluate them for accuracy.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: For example, one slice of the dataset may train at high accuracy while another
    does so at low accuracy, indicating that there are likely issues in your model
    architecture that make it overfit on one dataset. On the other hand, if you try
    multiple different splits of your data and the model training and validation results
    are consistent, then you’ll have a signal that your architecture is sound.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: I would definitely encourage you to use custom splits when training models,
    as it can really help you get over some gotchas!
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: One more thing to consider when using custom splits is that the name `random`
    doesn’t mean that this approach *shuffles* or randomizes your dataset. It merely
    slices the dataset at random points to give you different slices each time. Should
    you want to also shuffle the dataset, you can do it in the DataLoader, which we’ll
    explore in the next section.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: The ETL Process for Managing Data in Machine Learning
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Extract, Transfer, Load* (ETL) is the core pattern for training ML models,
    regardless of scale. We’ve been exploring small-scale, single-computer model building
    in this book, but we can use the same technology for large-scale training across
    multiple machines with massive datasets.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: 'The Extract, Transfer, Load process consists of the three phases that are in
    the process’s name:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: Extract phase
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: This occurs when the raw data is loaded from wherever it is stored and prepared
    in a way that can be transformed.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Transform phase
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: This occurs when the data is manipulated in a way that makes it suitable or
    improved for training. For example, batching, image augmentation, mapping to feature
    columns, and other such logic applied to the data can be considered part of this
    phase.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: Load phase
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: This occurs when the data is loaded into the neural network for training.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这发生在数据被加载到神经网络进行训练时。
- en: 'Consider the code from [Chapter 3](ch03.html#ch03_going_beyond_the_basics_detecting_features_in_ima_1748570891074912)
    that we used to train the “Horses or Humans” classifier. At the top of the code,
    you saw a chunk like this:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑我们用来训练“马或人”分类器的 [第 3 章](ch03.html#ch03_going_beyond_the_basics_detecting_features_in_ima_1748570891074912)
    中的代码。在代码的顶部，你看到了这样的片段：
- en: '[PRE14]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This is the ETL pattern embodied in code!
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是代码中体现的 ETL 模式！
- en: The code begins by defining the `transform` (the “T”), but the active code doesn’t
    begin until the lines under the `Load the datasets` comment. Look carefully here
    and you’ll see that the `ImageFolder` is being used to *extract* the data from
    its location at rest on disk.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 代码首先定义了 `transform`（“T”），但活跃的代码直到 `Load the datasets` 注释下的行才开始。仔细看看这里，你会看到 `ImageFolder`
    正在被用来 *提取* 数据，这些数据位于磁盘上的静态位置。
- en: Then, as the data is extracted, the `transform` that we defined is applied.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，随着数据的提取，我们定义的 `transform` 被应用。
- en: Then, under the `Data loaders` comment, we perform the *load* of the data using
    the `train_loader` and `val_loader` we’ve defined. Strictly speaking, the actual
    loading doesn’t take place until we execute the training loop to pull the data
    out of the loaders.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在 `Data loaders` 注释下，我们使用定义好的 `train_loader` 和 `val_loader` 来执行数据的 *加载*。严格来说，实际的加载直到我们执行训练循环以从加载器中提取数据时才会发生。
- en: It’s important to know that using this process can make your data pipelines
    less susceptible to changes in the data and the underlying schema. When you use
    this approach to extract data, the same underlying structure is used regardless
    of whether the data is small enough to fit in memory or large enough that it cannot
    be contained even on a simple machine. The APIs for applying the transformation
    are also consistent, so you can use similar ones regardless of the underlying
    data source. And of course, once the data is transformed, the process of loading
    the data is also consistent, regardless of your training backend.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 了解这一点很重要，使用这个过程可以使你的数据管道对数据及其底层模式的变化不那么敏感。当你使用这种方法提取数据时，无论数据是否足够小以适应内存，或者足够大以至于即使在简单的机器上也无法容纳，都会使用相同的底层结构。应用转换的
    API 也是一致的，所以无论底层数据源如何，你都可以使用类似的 API。当然，一旦数据被转换，加载数据的过程也是一致的，无论你的训练后端是什么。
- en: However, how you load the data can have a huge impact on your training speed.
    Let’s take a look at that next.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，你如何加载数据可能会对你的训练速度产生巨大影响。让我们接下来看看这一点。
- en: Optimizing the Load Phase
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 优化加载阶段
- en: Let’s take a closer look at the ETL process when you’re training a model. We
    can consider the extraction and transformation of the data to be possible on any
    processor, including a CPU. In fact, the code you use in these phases to perform
    tasks like downloading data, unzipping it, and going through it record by record
    and processing those records is not what GPUs and TPUs are built for, so the code
    will likely execute on the CPU anyway. When it comes to training, however, you
    can get great benefits from a GPU or TPU, so it makes sense for you to use one
    for this phase if possible. Thus, in a situation where a GPU or TPU is available
    to you, you should ideally split the workload between the CPU and the GPU/TPU,
    with Extract and Transform taking place on the CPU and Load taking place on the
    GPU/TPU.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在训练模型时，让我们更仔细地看看 ETL 流程。我们可以认为数据的提取和转换可以在任何处理器上进行，包括 CPU。实际上，你在这些阶段使用的代码来执行诸如下载数据、解压缩以及逐条记录地处理这些记录的任务并不是
    GPU 和 TPU 设计来完成的，所以代码很可能会在 CPU 上执行。然而，当涉及到训练时，你可以从 GPU 或 TPU 获得巨大的好处，所以如果可能的话，使用一个来处理这个阶段是有意义的。因此，在你有
    GPU 或 TPU 的情况下，理想情况下你应该在 CPU 和 GPU/TPU 之间分配工作量，提取和转换在 CPU 上进行，而加载在 GPU/TPU 上进行。
- en: If you explore the code that you’ve been using in this book, you’ll notice that
    we’ve used the .`to(device)` methodology. Whenever you’re dealing with training
    or inference and you want the data or model to be on the accelerator, you’ll see
    something like .`to(“cuda”)`, but for the extraction and transform, you won’t
    see it because it would be a waste of the GPU’s resources.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你探索这本书中使用的代码，你会注意到我们使用了 `.to(device)` 方法。无论你是在处理训练或推理，并且希望数据或模型在加速器上，你都会看到类似
    `.to(“cuda”)` 的内容，但对于提取和转换，你不会看到它，因为这会浪费 GPU 的资源。
- en: Suppose you’re working with a large dataset. Assuming it’s so large that you
    have to prepare the data (i.e., do the extraction and transformation) in batches,
    you’ll end up with a situation like that shown in [Figure 4-1](#ch04_figure_1_1748548966489345).
    While the first batch is being prepared, the GPU or TPU is idle. Then, when that
    batch is ready, you can send it to the GPU/TPU for training, but then the CPU
    will be idle until the training is done and it can start preparing the second
    batch. There’s a lot of idle time here, so we can see that there’s room for optimization.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在处理一个大型数据集。假设它非常大，以至于你必须分批准备数据（即进行提取和转换），你最终会得到如图 [图 4-1](#ch04_figure_1_1748548966489345)
    所示的情况。当第一批数据正在准备时，GPU 或 TPU 是空闲的。然后，当该批次准备好后，你可以将其发送到 GPU/TPU 进行训练，但此时 CPU 将处于空闲状态，直到训练完成并开始准备第二批数据。这里有大量的空闲时间，因此我们可以看到有优化的空间。
- en: '![Training on a CPU/GPU](assets/aiml_0401.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![Training on a CPU/GPU](assets/aiml_0401.png)'
- en: Figure 4-1\. Training on a CPU or GPU/TPU
  id: totrans-91
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-1\. 在 CPU 或 GPU/TPU 上进行训练
- en: The logical solution is to do the work in parallel, preparing and training side
    by side. This process is called *pipelining* and is illustrated in [Figure 4-2](#ch04_figure_2_1748548966489381).
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 合理的解决方案是在并行中进行工作，同时准备和训练。这个过程被称为*流水线*，如图 [图 4-2](#ch04_figure_2_1748548966489381)
    所示。
- en: '![](assets/aiml_0402.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![aiml_0402.png](assets/aiml_0402.png)'
- en: Figure 4-2\. Pipelining
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 4-2\. 流水线
- en: In this case, while the CPU is preparing the first batch, the GPU/TPU again
    has nothing to work on, so it’s idle. When the first batch is done, the GPU/TPU
    can start training—but in parallel with this, the CPU will prepare the second
    batch. Of course, the time it takes to train batch *n* – 1 and prepare batch *n*
    won’t always be the same, and if the training time is shorter, you’ll have periods
    of idle time on the GPU/TPU, and if the training time is longer, you’ll have periods
    of idle time on the CPU. Choosing the correct batch size can help you optimize
    here—and as GPU/TPU time is likely more expensive, you’ll probably want to reduce
    its idle time as much as possible.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，当 CPU 准备第一批数据时，GPU/TPU 再次没有工作可做，因此处于空闲状态。当第一批数据准备完毕后，GPU/TPU 可以开始训练——但是在此过程中，CPU
    将准备第二批数据。当然，训练批次 *n* – 1 和准备批次 *n* 所需的时间不一定相同，如果训练时间较短，你将在 GPU/TPU 上有闲置时间，如果训练时间较长，你将在
    CPU 上有闲置时间。选择正确的批次大小可以帮助你在这里进行优化——由于 GPU/TPU 时间可能更昂贵，你可能会想尽可能减少其闲置时间。
- en: 'This is one of the reasons why we use batching, even for the simple examples
    like MNIST: the pipelining model is in place so that regardless of how large your
    dataset is, you’ll continue to use a consistent pattern for ETL on it.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们使用批处理的原因之一，即使是像 MNIST 这样的简单示例：流水线模型已经就位，因此无论你的数据集有多大，你都会继续使用一致的 ETL 模式。
- en: Using the DataLoader Class
  id: totrans-97
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 DataLoader 类
- en: We’ve seen the `DataLoader` class many times already, but it’s good to take
    a slightly deeper look at it now to help you get the most out of it in your ML
    workflows. It provides the following features that you can use.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经多次看到了 `DataLoader` 类，但现在深入了解一下它，可以帮助你在机器学习工作流程中充分利用它。它提供了以下你可以使用的功能。
- en: Batching
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 批处理
- en: Intuitively, you might think that the forward pass works one data item at a
    time. You *could* do that, but some optimizers, like stochastic gradient descent,
    do much better when inputs are passed in batches so that they can calculate more
    accurately. Batching can also speed up your training in larger scenarios, where
    you are using GPUs with fixed memory sizes. It’s most efficient to maximize the
    use of that memory by having a batch of data that fits it fully. If you’re using
    a `DataLoader`, batching is simply a matter of setting a parameter.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地，你可能认为前向传递一次处理一个数据项。你*可以*这样做，但一些优化器，如随机梯度下降，当输入以批次形式传递时，效果会更好，这样它们可以更准确地计算。批处理还可以加快你在使用固定内存大小的
    GPU 上的训练速度。最有效的方法是通过拥有一个完全适合该内存的数据批次来最大化使用该内存。如果你使用 `DataLoader`，批处理只是设置一个参数的问题。
- en: Shuffling
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 打乱顺序
- en: Shuffling the data is very important, particularly when you do batching. Consider
    the following scenario with something like Fashion MNIST.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 打乱数据顺序非常重要，尤其是在进行批处理时。考虑以下类似于 Fashion MNIST 的场景。
- en: You have 60,000 samples each for 10 classes, and they are not shuffled. You
    batch one thousand records at a time, so your first batch of one thousand is all
    for class 0, the second batch is all for class 1, and so on. In this scenario,
    the model may not effectively learn because each batch is biased toward a particular
    label—but the ability of your model to generalize will improve if the batches
    are shuffled, meaning your first thousand items will have varied labels, etc.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 你有10个类别，每个类别有60,000个样本，它们没有被打乱。你一次批处理一千条记录，所以你的第一个批次的一千条记录都是类别0，第二个批次都是类别1，以此类推。在这种情况下，模型可能无法有效地学习，因为每个批次都偏向于特定的标签——但如果批次被打乱，意味着你的前一千个物品将具有不同的标签等，那么你的模型泛化的能力将会提高。
- en: Parallel Data Loading
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并行数据加载
- en: Often, and in particular with complex data, loading data into the model for
    the forward pass can be time-consuming. But the `DataLoader` class offers parallelism
    through Python’s multiprocessing model, which can significantly speed this up.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，尤其是在处理复杂数据时，将数据加载到模型中进行正向传递可能会很耗时。但是`DataLoader`类通过Python的进程池模型提供了并行性，这可以显著加快这个过程。
- en: As you saw previously, you should consider your data loading/transformation
    and your model learning to be two separate processes. You want to avoid scenarios
    where the model training has no data to work with and is sitting idle, waiting
    for data to be loaded, and you also want to avoid scenarios where you have tons
    of data piled up in memory but the model can’t get to it. Parallel data loading,
    when well tuned, can be helpful here, and there’s a skill you can learn to ensure
    that you’re getting the most out of your training by running this at peak efficiency.
    You’ll learn how to do this in the next section.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你之前看到的，你应该将数据加载/转换和模型学习视为两个独立的过程。你想要避免模型训练没有数据可用而闲置等待数据加载的情况，也想要避免内存中有大量数据但模型无法访问的情况。当数据加载并行化调优得当，这里可能会有所帮助，你可以学习一项技能来确保通过在峰值效率下运行来获得最佳的训练效果。你将在下一节中学习如何做到这一点。
- en: Custom Data Sampling
  id: totrans-107
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自定义数据采样
- en: In addition to shuffling for random data sampling, you can create custom data
    sampling, in which you can specify how the data will be loaded. The `torch.utils.data.Sampler`
    class provides a base class that you can build a custom sampler on. This process
    is beyond the scope of this book, but there are many excellent examples of it
    online.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 除了随机数据采样时的打乱，你还可以创建自定义数据采样，其中你可以指定数据如何被加载。`torch.utils.data.Sampler`类提供了一个基类，你可以在其上构建自定义采样器。这个过程超出了本书的范围，但网上有许多关于它的优秀示例。
- en: Parallelizing ETL to Improve Training Performance
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 通过并行化ETL来提高训练性能
- en: If you’re using the `DataLoader` class, you can easily perform parallelization
    by using the `num_workers` parameter. So, for example, say you want to train a
    model on the `CIFAR10` dataset, and you want to use parallel training. Let’s take
    a look at how to do this, step-by-step.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在使用`DataLoader`类，你可以通过使用`num_workers`参数轻松实现并行化。例如，假设你想在`CIFAR10`数据集上训练一个模型，并且你想使用并行训练。让我们一步一步地看看如何做这件事。
- en: 'First, we’ll explore the Extract and Transform steps:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们将探索提取和转换步骤：
- en: '[PRE15]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Then, we’ll configure and create the DataLoader to the Load step:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将配置并创建DataLoader到加载步骤：
- en: '[PRE16]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Note the `num_workers=4` parameter, which will create four subprocesses to load
    the data in parallel simultaneously. Based on the hardware you have available
    and the number of cores, the speed of your CPU, etc., you can experiment with
    this number to reduce the overall bottlenecks.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 注意`num_workers=4`参数，这将创建四个子进程来并行同时加载数据。根据你拥有的硬件、核心数量以及CPU的速度等因素，你可以尝试调整这个数字以减少整体瓶颈。
- en: 'What’s really nice about this approach is that the ETL process is neatly encapsulated
    in it, so your model training loop doesn’t have to change in any way, even though
    you’re loading the data by using parallelism! Here’s the code for the simple `CIFAR`
    model that uses this data:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这个方法的真正好处是ETL过程被巧妙地封装在其中，所以你的模型训练循环不需要任何改变，即使你是通过并行化来加载数据！以下是使用此数据的简单`CIFAR`模型的代码：
- en: '[PRE17]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Parallelizing is another tool that’s available to you when you’re training your
    models. There’s no one-size-fits-all approach, but it’s a good tool to use when
    you experience training slowdowns. It’s easy to assume that training operates
    slowly just because of the network architecture, but you may be surprised at how
    much of that time is wasted by the forward pass waiting for new data! By adding
    this type of parallelism, you have the potential to greatly speed up training.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 并行化是你在训练模型时可以使用的另一个工具。没有一种适合所有情况的解决方案，但当你遇到训练速度减慢时，这是一个很好的工具。很容易认为训练速度慢只是因为网络架构的原因，但你可能会惊讶地发现，有很大一部分时间被前向传递等待新数据浪费了！通过添加这种并行性，你有潜力大大加快训练速度。
- en: Summary
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: This chapter covered the data ecosystem in PyTorch and introduced you to the
    `dataset` and `DataLoader` classes. You saw how they use a common API and a common
    format to help reduce the amount of code you have to write to get access to data,
    and you also saw how to use the ETL process, which is at the heart of the common
    design patterns in training models with PyTorch. In particular, we explored parallelizing
    the extraction, transformation, and loading of data to improve training performance.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了 PyTorch 中的数据生态系统，并介绍了 `dataset` 和 `DataLoader` 类。你看到了它们如何使用通用的 API 和通用的格式来帮助减少你需要编写的代码量，以便访问数据，你也看到了如何使用
    ETL 流程，这是 PyTorch 训练模型时通用设计模式的核心。特别是，我们探讨了并行化数据的提取、转换和加载，以提高训练性能。
- en: So now that you’ve had a chance to look at the process, see if you can create
    your own dataset! Maybe do it from some photos in your albums, or some test, or
    just random noise like we did here.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经有机会查看这个过程了，看看你能否创建自己的数据集！也许可以从你相册中的照片、一些测试，或者像我们这里一样随机噪声中创建。
- en: In the next chapter, you’ll take what you’ve learned so far and start applying
    it to natural language processing problems.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将把到目前为止学到的知识应用到自然语言处理问题上。
