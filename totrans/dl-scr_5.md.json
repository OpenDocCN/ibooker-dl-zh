["```py\ninput_1d = np.array([1,2,3,4,5])\nparam_1d = np.array([1,1,1])\n```", "```py\ndef _pad_1d(inp: ndarray,\n            num: int) -> ndarray:\n    z = np.array([0])\n    z = np.repeat(z, num)\n    return np.concatenate([z, inp, z])\n\n_pad_1d(input_1d, 1)\n```", "```py\narray([0., 1., 2., 3., 4., 5., 0.])\n```", "```py\ndef conv_1d(inp: ndarray,\n            param: ndarray) -> ndarray:\n\n    # assert correct dimensions\n    assert_dim(inp, 1)\n    assert_dim(param, 1)\n\n    # pad the input\n    param_len = param.shape[0]\n    param_mid = param_len // 2\n    input_pad = _pad_1d(inp, param_mid)\n\n    # initialize the output\n    out = np.zeros(inp.shape)\n\n    # perform the 1d convolution\n    for o in range(out.shape[0]):\n        for p in range(param_len):\n            out[o] += param[p] * input_pad[o+p]\n\n    # ensure shapes didn't change\n    assert_same_shape(inp, out)\n\n    return out\n\nconv_1d_sum(input_1d, param_1d)\n```", "```py\narray([ 3.,  6.,  9., 12.,  9.])\n```", "```py\ndef conv_1d_sum(inp: ndarray,\n                param: ndarray) -> ndarray:\n    out = conv_1d(inp, param)\n    return np.sum(out)\n```", "```py\n# randomly choose to increase 5th element by 1\ninput_1d_2 = np.array([1,2,3,4,6])\nparam_1d = np.array([1,1,1])\n\nprint(conv_1d_sum(input_1d, param_1d))\nprint(conv_1d_sum(input_1d_2, param_1d))\n```", "```py\n39.0\n41.0\n```", "```py\n# param: in our case an ndarray of shape (1,3)\n# param_len: the integer 3\n# inp: in our case an ndarray of shape (1,5)\n# input_grad: always an ndarray the same shape as \"inp\"\n# output_pad: in our case an ndarray of shape (1,7)\nfor o in range(inp.shape[0]):\n    for p in range(param.shape[0]):\n        input_grad[o] += output_pad[o+param_len-p-1] * param[p]\n```", "```py\ninput_1d = np.array([1,2,3,4,5])\n# randomly choose to increase first element by 1\nparam_1d_2 = np.array([2,1,1])\n\nprint(conv_1d_sum(input_1d, param_1d))\nprint(conv_1d_sum(input_1d, param_1d_2))\n```", "```py\n39.0\n49.0\n```", "```py\n# param: in our case an ndarray of shape (1,3)\n# param_grad: an ndarray the same shape as param\n# inp: in our case an ndarray of shape (1,5)\n# input_pad: an ndarray the same shape as (1,7)\n# output_grad: in our case an ndarray of shape (1,5)\nfor o in range(inp.shape[0]):\n    for p in range(param.shape[0]):\n        param_grad[p] += input_pad[o+p] * output_grad[o]\n```", "```py\ninput_1d_batch = np.array([[0,1,2,3,4,5,6],\n                           [1,2,3,4,5,6,7]])\n```", "```py\ndef conv_1d_batch(inp: ndarray,\n                  param: ndarray) -> ndarray:\n\n    outs = [conv_1d(obs, param) for obs in inp]\n    return np.stack(outs)\n```", "```py\n# \"_input_grad\" is the function containing the for loop from earlier:\n# it takes in a 1d input, a 1d filter, and a 1d output_gradient and computes\n# the input grad\ngrads = [_input_grad(inp[i], param, out_grad[i])[1] for i in range(batch_size)]\nnp.stack(grads)\n```", "```py\n# param: in our case an ndarray of shape (1,3)\n# param_grad: an ndarray the same shape as param\n# inp: in our case an ndarray of shape (1,5)\n# input_pad: an ndarray the same shape as (1,7)\n# output_grad: in our case an ndarray of shape (1,5)\nfor i in range(inp.shape[0]): # inp.shape[0] = 2\n    for o in range(inp.shape[1]): # inp.shape[0] = 5\n        for p in range(param.shape[0]): # param.shape[0] = 3\n            param_grad[p] += input_pad[i][o+p] * output_grad[i][o]\n```", "```py\n# input_pad: a version of the input that has been padded appropriately based on\n# the size of param\n\nout = np.zeros_like(inp)\n\nfor o in range(out.shape[0]):\n    for p in range(param_len):\n        out[o] += param[p] * input_pad[o+p]\n```", "```py\n# input_pad: a version of the input that has been padded appropriately based on\n# the size of param\n\nout = np.zeros_like(inp)\n\nfor o_w in range(img_size): # loop through the image height\n    for o_h in range(img_size): # loop through the image width\n        for p_w in range(param_size): # loop through the parameter width\n            for p_h in range(param_size): # loop through the parameter height\n                out[o_w][o_h] += param[p_w][p_h] * input_pad[o_w+p_w][o_h+p_h]\n```", "```py\ninput_grad = np.zeros_like(inp)\n\nfor o in range(inp.shape[0]):\n    for p in range(param_len):\n        input_grad[o] += output_pad[o+param_len-p-1] * param[p]\n```", "```py\n# output_pad: a version of the output that has been padded appropriately based\n# on the size of param\ninput_grad = np.zeros_like(inp)\n\nfor i_w in range(img_width):\n    for i_h in range(img_height):\n        for p_w in range(param_size):\n            for p_h in range(param_size):\n                input_grad[i_w][i_h] +=\n                  output_pad[i_w+param_size-p_w-1][i_h+param_size-p_h-1] \\\n                  * param[p_w][p_h]\n```", "```py\noutput_pad[i+param_size-p-1] * param[p]\n```", "```py\noutput_pad[i_w+param_size-p_w-1][i_h+param_size-p_h-1] * param[p_w][p_h]\n```", "```py\n# input_pad: a version of the input that has been padded appropriately based on\n# the size of param\n\nparam_grad = np.zeros_like(param)\n\nfor i in range(batch_size): # equal to inp.shape[0]\n    for o_w in range(img_size):\n        for o_h in range(img_size):\n            for p_w in range(param_size):\n                for p_h in range(param_size):\n                    param_grad[p_w][p_h] += input_pad[i][o_w+p_w][o_h+p_h] \\\n                    * output_grad[i][o_w][o_h]\n```", "```py\ndef _compute_output_obs(obs: ndarray,\n                       param: ndarray) -> ndarray:\n    '''\n obs: [channels, img_width, img_height]\n param: [in_channels, out_channels, param_width, param_height]\n '''\n    assert_dim(obs, 3)\n    assert_dim(param, 4)\n\n    param_size = param.shape[2]\n    param_mid = param_size // 2\n    obs_pad = _pad_2d_channel(obs, param_mid)\n\n    in_channels = fil.shape[0]\n    out_channels = fil.shape[1]\n    img_size = obs.shape[1]\n\n    out = np.zeros((out_channels,) + obs.shape[1:])\n    for c_in in range(in_channels):\n        for c_out in range(out_channels):\n            for o_w in range(img_size):\n                for o_h in range(img_size):\n                    for p_w in range(param_size):\n                        for p_h in range(param_size):\n                            out[c_out][o_w][o_h] += \\\n                              param[c_in][c_out][p_w][p_h]\n                              * obs_pad[c_in][o_w+p_w][o_h+p_h]\n    return out\n\ndef _output(inp: ndarray,\n            param: ndarray) -> ndarray:\n    '''\n obs: [batch_size, channels, img_width, img_height]\n param: [in_channels, out_channels, param_width, param_height]\n '''\n    outs = [_compute_output_obs(obs, param) for obs in inp]\n\n    return np.stack(outs)\n```", "```py\ndef _compute_grads_obs(input_obs: ndarray,\n                       output_grad_obs: ndarray,\n                       param: ndarray) -> ndarray:\n    '''\n input_obs: [in_channels, img_width, img_height]\n output_grad_obs: [out_channels, img_width, img_height]\n param: [in_channels, out_channels, img_width, img_height]\n '''\n    input_grad = np.zeros_like(input_obs)\n    param_size = param.shape[2]\n    param_mid = param_size // 2\n    img_size = input_obs.shape[1]\n    in_channels = input_obs.shape[0]\n    out_channels = param.shape[1]\n    output_obs_pad = _pad_2d_channel(output_grad_obs, param_mid)\n\n    for c_in in range(in_channels):\n        for c_out in range(out_channels):\n            for i_w in range(input_obs.shape[1]):\n                for i_h in range(input_obs.shape[2]):\n                    for p_w in range(param_size):\n                        for p_h in range(param_size):\n                            input_grad[c_in][i_w][i_h] += \\\n                            output_obs_pad[c_out][i_w+param_size-p_w-1][i_h+param_size-p_h-1] \\\n                            * param[c_in][c_out][p_w][p_h]\n    return input_grad\n\ndef _input_grad(inp: ndarray,\n                output_grad: ndarray,\n                param: ndarray) -> ndarray:\n\n    grads = [_compute_grads_obs(inp[i], output_grad[i], param) for i in range(output_grad.shape[0])]\n\n    return np.stack(grads)\n```", "```py\ndef _param_grad(inp: ndarray,\n                output_grad: ndarray,\n                param: ndarray) -> ndarray:\n    '''\n inp: [in_channels, img_width, img_height]\n output_grad_obs: [out_channels, img_width, img_height]\n param: [in_channels, out_channels, img_width, img_height]\n '''\n    param_grad = np.zeros_like(param)\n    param_size = param.shape[2]\n    param_mid = param_size // 2\n    img_size = inp.shape[2]\n    in_channels = inp.shape[1]\n    out_channels = output_grad.shape[1]\n\n    inp_pad = _pad_conv_input(inp, param_mid)\n    img_shape = output_grad.shape[2:]\n\n    for i in range(inp.shape[0]):\n        for c_in in range(in_channels):\n            for c_out in range(out_channels):\n                for o_w in range(img_shape[0]):\n                    for o_h in range(img_shape[1]):\n                        for p_w in range(param_size):\n                            for p_h in range(param_size):\n                                param_grad[c_in][c_out][p_w][p_h] += \\\n                                inp_pad[i][c_in][o_w+p_w][o_h+p_h] \\\n                                * output_grad[i][c_out][o_w][o_h]\n    return param_grad\n```", "```py\nclass Flatten(Operation):\n    def __init__(self):\n        super().__init__()\n\n    def _output(self) -> ndarray:\n        return self.input.reshape(self.input.shape[0], -1)\n\n    def _input_grad(self, output_grad: ndarray) -> ndarray:\n        return output_grad.reshape(self.input.shape)\n```", "```py\nclass Conv2D(Layer):\n\n    def __init__(self,\n                 out_channels: int,\n                 param_size: int,\n                 activation: Operation = Sigmoid(),\n                 flatten: bool = False) -> None:\n        super().__init__()\n        self.out_channels = out_channels\n        self.param_size = param_size\n        self.activation = activation\n        self.flatten = flatten\n\ndef _setup_layer(self, input_: ndarray) -> ndarray:\n\n    self.params = []\n    conv_param = np.random.randn(self.out_channels,\n                                 input_.shape[1],  # input channels\n                                 self.param_size,\n                                 self.param_size)\n    self.params.append(conv_param)\n\n    self.operations = []\n    self.operations.append(Conv2D(conv_param))\n    self.operations.append(self.activation)\n\n    if self.flatten:\n        self.operations.append(Flatten())\n\n    return None\n```", "```py\nmodel = NeuralNetwork(\n    layers=[Conv2D(out_channels=32,\n                   param_size=5,\n                   dropout=0.8,\n                   weight_init=\"glorot\",\n                   flatten=True,\n                  activation=Tanh()),\n            Dense(neurons=10,\n                  activation=Linear())],\n            loss = SoftmaxCrossEntropy(),\nseed=20190402)\n```", "```py\nValidation accuracy after 100 batches is 79.65%\nValidation accuracy after 200 batches is 86.25%\nValidation accuracy after 300 batches is 85.47%\nValidation accuracy after 400 batches is 87.27%\nValidation accuracy after 500 batches is 88.93%\nValidation accuracy after 600 batches is 88.25%\nValidation accuracy after 700 batches is 89.91%\nValidation accuracy after 800 batches is 89.59%\nValidation accuracy after 900 batches is 89.96%\nValidation loss after 1 epochs is 3.453\n\nModel validation accuracy after 1 epoch is 90.50%\n```"]