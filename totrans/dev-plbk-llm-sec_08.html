<html><head></head><body><section data-pdf-bookmark="Chapter 8. Don&#x2019;t Lose Your Wallet" data-type="chapter" epub:type="chapter"><div class="chapter" id="don_t_lose_your_wallet">&#13;
      <h1><span class="label">Chapter 8. </span>Don’t Lose Your Wallet</h1>&#13;
      <blockquote data-type="epigraph" epub:type="epigraph">&#13;
        <p>Beware of little expenses; a small leak will sink a great ship.</p>&#13;
        <p data-type="attribution">Benjamin Franklin</p>&#13;
      </blockquote>&#13;
      <p>This chapter will explore denial-of-service (DoS), denial-of-wallet (DoW), and model cloning attacks, examining the similarities and differences between these attack types. Despite the divergent outcomes—from service disruption and financial loss to the unauthorized duplication of your intellectual property—these three attack vectors exploit similar vulnerabilities within the application. By exploring these threats side-by-side, you’ll understand the protective measures to thwart such attacks.</p>&#13;
      <p>The term DoS has become synonymous with the disruption of online services. A DoS attack is an intentional effort to make a computer system, network, or application unavailable to its intended users, typically by overwhelming the app with requests. Historically, these attacks have targeted various online services, from financial institutions to social media platforms, causing significant operational disruptions and economic losses. As we dig deeper into the era of advanced computing and AI, the implications of DoS attacks have extended to more sophisticated technologies, including LLMs.</p>&#13;
      <p>While LLMs are not immune to traditional cybersecurity threats, their unique characteristics can make them highly vulnerable to DoS attacks, and such attacks can have unique and severe consequences. Today, DoS attacks are not merely about disrupting service availability; they extend to exploiting these models’ intrinsic features, leading to resource exhaustion, degraded performance, and possible direct financial losses. This new frontier of DoS attacks is not just a technical challenge, but a significant business concern, as it directly impacts the reliability and economic viability of services utilizing LLMs.</p>&#13;
      <p>The recent emergence of DoW attacks, a highly dangerous variant of DoS, against LLMs brings an additional financial dimension to LLMs’ security concerns. These attacks specifically target the economic resources of an organization by exploiting the pay-per-use models of cloud-based AI services. In a DoW attack, the adversary aims to cause the service provider to incur unsustainable costs by generating excessive queries or operations, leading to financial strain rather than mere service disruption. This phenomenon highlights a unique vulnerability in the deployment of LLMs, where the financial integrity of an application is as crucial as its operational security. </p>&#13;
      <p>This chapter will also discuss <em>model cloning attacks</em>, in which an adversary aims to steal the intellectual property underlying your model by flooding the system with questions, recording the answers, and then using those answers to train their own model. While these attacks are often classified differently than denial attacks, there are fundamental similarities. In particular, model cloning attacks depend on driving repeated queries against your model, just like DoS attacks. This similarity means many of the same defensive techniques apply.</p>&#13;
      <section data-pdf-bookmark="DoS Attacks" data-type="sect1"><div class="sect1" id="dos_attacks">&#13;
        <h1>DoS Attacks</h1>&#13;
        <p><a contenteditable="false" data-primary="denial-of-service (DoS) attacks" data-type="indexterm" id="ch08.html0"/>The impact of DoS attacks is far reaching. They can lead to significant downtime for online services, resulting in considerable financial losses, especially for businesses that rely heavily on online transactions. Beyond financial damage, DoS attacks can erode trust in a service or brand, mainly if they occur frequently or the service provider doesn’t handle them effectively. Furthermore, DoS attacks can be a cover for more sinister activities, such as data breaches or malware injection, because they divert the attention of IT staff.</p>&#13;
        <p>Let’s examine the types, causes, and mitigation steps for general DoS attacks before we dive into the LLM-specific aspects. </p>&#13;
        <p>To understand the issue better, let’s look at three major categories of DoS attacks.</p>&#13;
        <section data-pdf-bookmark="Volume-Based Attacks" data-type="sect2"><div class="sect2" id="volume_based_attacks">&#13;
          <h2>Volume-Based Attacks</h2>&#13;
          <p><a contenteditable="false" data-primary="denial-of-service (DoS) attacks" data-secondary="volume-based attacks" data-type="indexterm" id="id473"/><a contenteditable="false" data-primary="volume-based attacks" data-type="indexterm" id="id474"/>Volume-based attacks are the most straightforward type of DoS attack. In a volume-based attack, the target is overwhelmed with massive amounts of traffic, using tactics like User Datagram Protocol (UDP) floods, Internet Control Message Protocol (ICMP) floods, and other spoofed-packet floods. The sheer volume of traffic consumes the bandwidth of the targeted site or application, making it inaccessible to legitimate traffic.</p>&#13;
          <p>While simple volume-based attacks inundate a target with significant traffic from a single source, <em>distributed denial-of-service</em> (DDoS) attacks amplify this threat by leveraging multiple compromised systems to launch a coordinated assault. These attacks utilize a network of infected devices, known as a <em>botnet</em>, to generate a flood of traffic that overwhelms the target from numerous points across the internet. </p>&#13;
        </div></section>&#13;
        <section data-pdf-bookmark="Protocol Attacks" data-type="sect2"><div class="sect2" id="protocol_attacks">&#13;
          <h2>Protocol Attacks</h2>&#13;
          <p><a contenteditable="false" data-primary="denial-of-service (DoS) attacks" data-secondary="protocol attacks" data-type="indexterm" id="id475"/><a contenteditable="false" data-primary="protocol attacks" data-type="indexterm" id="id476"/><em>Protocol attacks</em> target the network layer or transport layer of a network connection. They exploit weaknesses in the protocols that run the internet. By manipulating the flaws in these protocols, attackers can send a relatively small amount of traffic to create a disproportionately large load on the target, effectively disrupting its ability to communicate. Examples include <em>SYN floods</em>, <em>ping of death</em>, and <em>Smurf attacks</em>:</p>&#13;
          <dl>&#13;
            <dt>SYN floods</dt>&#13;
            <dd>&#13;
              <p><a contenteditable="false" data-primary="SYN floods" data-type="indexterm" id="id477"/>This attack exploits the TCP handshake process, which is the initial negotiation between the client and the server to establish a connection. In a SYN flood, the attacker sends a rapid succession of SYN requests (a signal to start a connection) to a target server, but intentionally fails to complete the handshake by not sending the final acknowledgment.</p>&#13;
            </dd>&#13;
            <dt>Ping of death</dt>&#13;
            <dd>&#13;
              <p><a contenteditable="false" data-primary="ping of death attacks" data-type="indexterm" id="id478"/>This attack involves sending malicious pings to a system. In a ping of death scenario, the attacker sends larger pings than the IP protocol allows (65,535 bytes). Older systems often couldn’t handle these oversized packets, causing them to freeze, crash, or reboot. </p>&#13;
            </dd>&#13;
            <dt>Smurf attack</dt>&#13;
            <dd>&#13;
              <p><a contenteditable="false" data-primary="ICMP (internet control message protocol) requests" data-type="indexterm" id="id479"/><a contenteditable="false" data-primary="internet control message protocol (ICMP) requests" data-type="indexterm" id="id480"/><a contenteditable="false" data-primary="smurf attacks" data-type="indexterm" id="id481"/>The attacker sends ICMP requests (usually pings) to a network’s broadcast address, spoofing the return address with the target’s IP. All devices on the broadcast network respond to this ping, sending replies to the victim’s IP address. This amplifies the volume of traffic directed at the target, overwhelming its resources. </p>&#13;
            </dd>&#13;
          </dl>&#13;
          <p>Each of these attacks represents a different approach to overwhelming a target with unwanted traffic or requests, resulting in a denial of service. Protection against such attacks often involves a combination of traffic filtering, rate limiting, and network configuration adjustments to reduce vulnerability. </p>&#13;
        </div></section>&#13;
        <section data-pdf-bookmark="Application Layer Attacks" data-type="sect2"><div class="sect2" id="application_layer_attacks">&#13;
          <h2>Application Layer Attacks</h2>&#13;
          <p><a contenteditable="false" data-primary="application layer attacks" data-type="indexterm" id="id482"/><a contenteditable="false" data-primary="denial-of-service (DoS) attacks" data-secondary="application layer attacks" data-type="indexterm" id="id483"/>Application layer attacks are more sophisticated attacks that target the application layer, where web pages are generated and delivered in response to HTTP requests. The attacker requests so many resources from the server that it cannot serve legitimate user requests. Such attacks often require fewer resources than volume-based or protocol attacks but can be highly effective due to their targeted nature. Examples of this kind of attack include <em>HTTP flood</em> and <em>Slowloris</em>:</p>&#13;
          <dl>&#13;
            <dt>HTTP flood</dt>&#13;
            <dd>&#13;
              <p><a contenteditable="false" data-primary="application layer attacks" data-secondary="HTTP flood" data-type="indexterm" id="id484"/><a contenteditable="false" data-primary="HTTP flood attacks" data-type="indexterm" id="id485"/>This attack involves flooding a web server with a high volume of HTTP requests, overwhelming its capacity to respond effectively to legitimate user traffic. Attackers exploit vulnerabilities in the HTTP protocol by inundating the server with a barrage of requests, aiming to exhaust its resources, disrupt services, and ultimately render the website inaccessible to genuine users. </p>&#13;
            </dd>&#13;
            <dt>Slowloris</dt>&#13;
            <dd>&#13;
              <p><a contenteditable="false" data-primary="application layer attacks" data-secondary="Slowloris" data-type="indexterm" id="id486"/><a contenteditable="false" data-primary="Slowloris attacks" data-type="indexterm" id="id487"/>Here, the attacker initiates multiple HTTP connections to the target web server, but deliberately keeps them open by sending partial requests slowly, thereby consuming available server resources and preventing the server from serving legitimate requests. </p>&#13;
            </dd>&#13;
          </dl>&#13;
        </div></section>&#13;
        <section data-pdf-bookmark="An Epic DoS Attack: Dyn" data-type="sect2"><div class="sect2" id="an_epic_dos_attack_dyn">&#13;
          <h2>An Epic DoS Attack: Dyn</h2>&#13;
          <p><a contenteditable="false" data-primary="denial-of-service (DoS) attacks" data-secondary="attack on Dyn" data-type="indexterm" id="id488"/><a contenteditable="false" data-primary="Dyn, DoS attack on" data-type="indexterm" id="id489"/>In October 2016, the internet faced a massive disruption due to a sophisticated and large-scale DoS attack on Dyn, a leading Domain Name System (DNS) provider. This event made headlines and marked a pivotal moment in understanding cyber threats and their potential impact on global internet infrastructure.</p>&#13;
          <p>Dyn, known for its role in internet performance management and website application security, became the target of a DDoS attack in which attackers used compromised IoT devices, such as digital cameras and DVRs, to generate malicious traffic. Infected with the Mirai malware, these devices formed a botnet to flood Dyn’s servers with overwhelming traffic.</p>&#13;
          <p>The attack generated traffic volumes estimated at around 1.2 Tbps (terabits per second). At the time, it was one of the most impactful DDoS attacks on record. The assault on Dyn’s DNS services had a ripple effect, causing major internet platforms and services to become unavailable to users across Europe and North America. High-profile websites, including Twitter, Netflix, PayPal, and Amazon, faced significant disruptions. The attack was executed in multiple waves, resulting in intermittent outages and widespread uncertainty throughout the attack.<a contenteditable="false" data-primary="" data-startref="ch08.html0" data-type="indexterm" id="id490"/></p>&#13;
        </div></section>&#13;
      </div></section>&#13;
      <section data-pdf-bookmark="Model DoS Attacks Targeting LLMs" data-type="sect1"><div class="sect1" id="model_dos_attacks_targeting_llms">&#13;
        <h1>Model DoS Attacks Targeting LLMs</h1>&#13;
        <p><a contenteditable="false" data-primary="denial-of-service (DoS) attacks" data-secondary="model DOS attacks" data-type="indexterm" id="ch08.html1"/><a contenteditable="false" data-primary="model DoS attacks" data-type="indexterm" id="ch08.html2"/>Unlike traditional DoS attacks that mainly target vulnerabilities in network and server infrastructures, a model DoS attack focuses on exploiting the unique vulnerabilities inherent in LLMs. In a model DoS attack, the attacker’s goal is to compromise the functionality or exhaust the resources of an LLM. </p>&#13;
        <p>An LLM application connected to the web via a web user interface or a REST API could be the target of the traditional DoS attacks we detailed earlier in the chapter, such as volume-based, protocol, and application layer attacks. However, the nature of LLMs opens them up to specific new concerns we’ll discuss in this section. </p>&#13;
        <section data-pdf-bookmark="Scarce Resource Attacks" data-type="sect2"><div class="sect2" id="scarce_resource_attacks">&#13;
          <h2>Scarce Resource Attacks</h2>&#13;
          <p><a contenteditable="false" data-primary="model DoS attacks" data-secondary="scarce resource" data-type="indexterm" id="id491"/><a contenteditable="false" data-primary="scarce resource attacks" data-type="indexterm" id="id492"/>LLMs are resource intensive due to the architecture they use to generate complex text responses. This makes them vulnerable to attacks designed to overburden their processing capabilities. For example, an attacker could repeatedly prompt an LLM to translate large documents or generate long-form content. This type of request, especially if scaled up by automation or bots, can quickly drain the computational resources available to the LLM. </p>&#13;
          <p>Let’s look at a practical example to help illustrate the point. Several service providers use LLMs to power highly effective machine translation services, offering the ability to process and understand text in one language and fluently translate it into another. Yet, the sophistication of LLMs comes at a cost: a high demand for computational resources that are both intensive and specialized. Unlike more straightforward computational tasks you can handle with inexpensive network bandwidth or general-purpose CPUs, LLMs usually require advanced hardware, such as GPUs or specialized AI accelerators, which are more costly and in limited supply, even in expansive cloud computing environments.</p>&#13;
          <p>Consider a situation where an LLM-based translation service is targeted not by a sophisticated DDoS attack utilizing botnets, but by a simple, cheap flood of translation requests. These requests, individually, might not raise alarms—after all, they are the type of input the service provider designed it to handle. However, due to the resource-intensive nature of LLM processing, even a modestly coordinated influx of complex translation requests could disproportionately consume computational resources.</p>&#13;
          <p>This reliance on high-end computational resources for every translation task makes LLMs particularly susceptible to exploitation. With minimal effort, an attacker can submit a large block of complex text for translation. While sending this text is trivial, requiring negligible resources from the attacker, the translation process places a substantial load on the LLM. The system must perform deep, nuanced analysis and <span class="keep-together">generation</span> tasks that consume significant amounts of these scarce, expensive computational resources.</p>&#13;
          <p>The significant gap between the trivial effort required to make a request and the intensive resources needed for processing underscores the likelihood of exploitation. This reality amplifies the importance of establishing robust defenses, as LLMs are much more susceptible to these attacks than simpler systems.</p>&#13;
          <p>In this scenario, attackers don’t need to compromise a vast network of devices or employ advanced techniques to launch an effective disruption; the very architecture of the LLM, designed for deep, thoughtful analysis, becomes its Achilles’ heel. A small number of attackers, or even a single one with modest resources, can initiate a flood of translation requests that, while seemingly legitimate, are intended to exploit the LLM’s computational demands. As a result, the service could slow dramatically or even grind to a halt, denying access to legitimate users and potentially incurring substantial operational costs for the service provider.</p>&#13;
        </div></section>&#13;
        <section data-pdf-bookmark="Context Window Exhaustion" data-type="sect2"><div class="sect2" id="context_window_exhaustion">&#13;
          <h2>Context Window Exhaustion</h2>&#13;
          <p><a contenteditable="false" data-primary="context window exhaustion" data-type="indexterm" id="id493"/><a contenteditable="false" data-primary="model DoS attacks" data-secondary="context window exhaustion" data-type="indexterm" id="id494"/>In <a data-type="xref" href="ch03.html#architectures_and_trust_boundaries">Chapter 3</a>, we touched on the concept of “attention,” which is part of the transformer architecture underlying modern LLMs. It’s a groundbreaking innovation that allows these models to focus on different parts of the input text as they generate responses or translations. Attention mechanisms are pivotal because they enable LLMs to dynamically prioritize specific inputs over others, mimicking how human attention works when we read or listen. This ability is crucial for understanding the context and nuances of language, making LLMs remarkably effective at processing and generating natural language.</p>&#13;
          <p>Building on the foundation of attention, the <em>context window</em> can be seen as the short-term memory of an LLM. It defines the scope within which the model focuses its attention, limiting how much text it can “remember” or consider at any given moment. Without this context window, an LLM would operate statelessly, akin to attempting a conversation without the ability to recall what was said moments before. Such a limitation would drastically reduce the model’s utility, as it could not produce coherent, context-aware responses over more extended interactions.</p>&#13;
          <p>The context window, therefore, is not just a technical limitation; it’s a crucial feature that enables LLMs to apply their attention mechanisms effectively. It allows the model to hold a running “conversation” or maintain the thread of a narrative or argument within its memory bounds. This capability makes LLMs powerful and versatile across various applications, from writing assistance and chatbots to more complex tasks like summarization and translation.</p>&#13;
          <p>However, as we’ve highlighted, the very feature that empowers LLMs with such capabilities also introduces specific vulnerabilities. The computational demand to maintain and process within this context window is significant. Attackers can exploit these demands by crafting inputs that push the limits of the context window, thereby straining the model’s resources. This could include providing extremely long prompts or crafting prompts that cause the LLM to give highly verbose answers that could fill a chatbot’s context window. Recognizing and mitigating these vulnerabilities is essential not only for the operational efficiency of LLMs but also for safeguarding against potential exploitation that could compromise their functionality or incur excessive costs.</p>&#13;
        </div></section>&#13;
        <section class="pagebreak-before" data-pdf-bookmark="Unpredictable User Input" data-type="sect2"><div class="sect2" id="unpredictable_user_input">&#13;
          <h2>Unpredictable User Input</h2>&#13;
          <p><a contenteditable="false" data-primary="model DoS attacks" data-secondary="unpredictable user input" data-type="indexterm" id="id495"/>Another vulnerability is the interaction of LLMs with unpredictable user inputs. Since these models are designed to respond to varied queries, attackers can manipulate them to perform complex, resource-intensive tasks. For example, an attacker could craft complicated questions or prompts that force the LLM to engage in deep, extended analyses or computations, effectively draining its resources. </p>&#13;
          <p>A striking example of this vulnerability can be observed in seemingly innocuous mathematical requests that, upon closer examination, reveal the potential for exponential resource consumption. Consider a scenario where an LLM, equipped with the capability to generate code or solve complex problems, receives a request such as “What is one million factorial?” It requires only a few dozen bytes to encode that request and send it to the LLM, but it would cause one million multiplication operations to be executed by the host system.</p>&#13;
          <p>But a modern CPU can do a million multiplications in milliseconds. So, let’s look at a few requests that might really stump the poor system:</p>&#13;
          <dl>&#13;
            <dt>Computationally intensive requests</dt>&#13;
            <dd>&#13;
              <p>These might include questions such as “What is the sum of all prime numbers up to one billion?” While asking for the sum of primes seems straightforward, identifying all prime numbers up to a large number like one billion requires significant computational effort, involving checks for primality across a vast range of numbers.</p>&#13;
            </dd>&#13;
            <dt>Extensive content generation requests </dt>&#13;
            <dd>&#13;
              <p>An innocuous-sounding request such as “Write a detailed history of every World Cup match” could force the LLM to generate an extensive amount of content, stringing together hundreds of separate events into a single, comprehensive narrative. Each token generation requires computational resources, and a lengthy, detailed response could significantly tax the system.</p>&#13;
            </dd>&#13;
            <dt>Complex reasoning and explanation chains </dt>&#13;
            <dd>&#13;
              <p>A prompt such as “List and explain every step involved in producing a smartphone from mining raw materials to final assembly, including the socioeconomic impacts at each stage” might require linking multiple knowledge domains with deep causal and explanatory chains, significantly increasing the generative task’s complexity and duration.</p>&#13;
            </dd>&#13;
          </dl>&#13;
          <p>Without proper safeguards, the LLM could embark on many boundless computational journeys, significantly draining system resources and potentially disrupting service.<a contenteditable="false" data-primary="" data-startref="ch08.html2" data-type="indexterm" id="id496"/><a contenteditable="false" data-primary="" data-startref="ch08.html1" data-type="indexterm" id="id497"/></p>&#13;
        </div></section>&#13;
      </div></section>&#13;
      <section class="pagebreak-before" data-pdf-bookmark="DoW Attacks" data-type="sect1"><div class="sect1" id="dow_attacks">&#13;
        <h1>DoW Attacks</h1>&#13;
        <p><a contenteditable="false" data-primary="cloud computing services" data-secondary="DoW attacks" data-type="indexterm" id="ch08.html3"/><a contenteditable="false" data-primary="denial-of-wallet (DoW) attacks" data-type="indexterm" id="ch08.html4"/>DoW is a variant of DoS that, while not new, is starting to gain significant prominence in the era of cloud computing and scalable online services. Unlike traditional DoS attacks, which aim to disrupt the availability of a service, DoW attacks target an organization’s financial resources. Often the primary objective of a DoW attack is to inflict economic damage by exploiting the usage-based pricing models of online services, leading to runaway costs for the victim.</p>&#13;
        <p>Historically, DoW attacks have been associated with cloud services where costs are directly tied to usage metrics such as compute time, data transfer, or transaction volumes. The basic premise involves driving up the usage—and, consequently, the <span class="keep-together">costs—to</span> unsustainable levels, thereby “denying” the organization its financial resources.</p>&#13;
        <p>Any scalable web application could be the target of a DoW attack. However, LLM applications typically have many characteristics that make them particularly vulnerable. Here are some items to consider:</p>&#13;
        <dl>&#13;
          <dt>High computational costs</dt>&#13;
          <dd>&#13;
            <p>LLMs require significant processing power for text generation, translation, or data analysis tasks. This high computational demand translates into higher operational costs in cloud-based deployment models.</p>&#13;
          </dd>&#13;
          <dt>Scalability of usage</dt>&#13;
          <dd>&#13;
            <p>LLM applications are designed to scale with the volume of requests. This scalability can be exploited in a DoW attack scenario, causing a rapid escalation in resource consumption and associated costs.</p>&#13;
          </dd>&#13;
          <dt>API-based access</dt>&#13;
          <dd>&#13;
            <p>LLMs are often accessed through APIs, making it easier for an attacker to programmatically generate a high volume of requests, thereby driving up costs.</p>&#13;
          </dd>&#13;
          <dt>Expensive, complex pricing models</dt>&#13;
          <dd>&#13;
            <p>The pricing structures for LLM services can be complex and based on multiple factors, such as the number of tokens processed, the duration of interactions, or the type of model used. Attackers can use these characteristics to maximize the financial impact of their actions.</p>&#13;
          </dd>&#13;
        </dl>&#13;
        <p>Taking this concept of DoW a step further, we now see attacks that go beyond simply draining the service provider’s resources to cause unwanted expenses. In this even more severe variant of DoW, the attacker leverages other vulnerabilities, such as prompt injection (see <a data-type="xref" href="ch04.html#prompt_injection">Chapter 4</a>), to take over access to the LLM and then use it for nefarious purposes—all at the target’s expense. For example, imagine a scenario where an attacker successfully executes a prompt injection attack to skirt the guardrails of the LLM. The attacker then issues requests that are out of alignment with the intent of the application and uses the LLM to generate phishing emails or crack CAPTCHA puzzles as part of a broader cyber hacking campaign.</p>&#13;
        <p>This scenario resembles traditional cryptojacking attacks, in which cloud resources are commandeered for cryptocurrency mining. In cryptojacking, attackers illicitly use victims’ computing power to mine cryptocurrency, incurring operational costs for the victim while profiting the attacker. </p>&#13;
        <p>In both scenarios, the unauthorized use of resources results in financial loss to the victim and potential profit to the attacker. However, there is a key difference from cryptojacking, which primarily results in financial loss due to increased computational resource usage. These advanced DoW attacks, where the attacker can use the system for illegal or malicious tasks, may open the target to additional legal liability worries and an empty wallet.<a contenteditable="false" data-primary="" data-startref="ch08.html4" data-type="indexterm" id="id498"/><a contenteditable="false" data-primary="" data-startref="ch08.html3" data-type="indexterm" id="id499"/></p>&#13;
      </div></section>&#13;
      <section data-pdf-bookmark="Model Cloning" data-type="sect1"><div class="sect1" id="model_cloning">&#13;
        <h1>Model Cloning</h1>&#13;
        <p><a contenteditable="false" data-primary="model cloning" data-type="indexterm" id="id500"/>Model cloning has emerged as a particularly insidious form of attack. <a contenteditable="false" data-primary="training data" data-secondary="model cloning and" data-type="indexterm" id="id501"/>Model cloning involves strategically querying an LLM application with a vast array of prompts on specific topics or using the model to generate synthetic training data. The attacker’s goal is to harvest the outputs from these interactions to fine-tune an alternate model, effectively replicating the functionality and knowledge base of the original LLM without direct access to its underlying architecture or training data. This is a form of model stealing where the attacker can, in effect, steal the highly valuable intellectual property you used to create your trained model and application.</p>&#13;
        <p>By exploiting the model’s resources through extensive querying, this attack vector shares certain tactical similarities with DoS and DoW attacks, so we’re including it in this section. However, the intent and end goals diverge significantly. While DoS aims to disrupt service availability, model cloning seeks to covertly replicate the model’s capabilities, posing a direct threat to intellectual property and potentially enabling unauthorized access to proprietary technologies.</p>&#13;
      </div></section>&#13;
      <section data-pdf-bookmark="Mitigation Strategies" data-type="sect1"><div class="sect1" id="mitigation_strategies">&#13;
        <h1>Mitigation Strategies</h1>&#13;
        <p><a contenteditable="false" data-primary="denial-of-service (DoS) attacks" data-secondary="mitigation strategies" data-type="indexterm" id="ch08.html5"/><a contenteditable="false" data-primary="mitigation strategies, for DoS and DoW attacks" data-type="indexterm" id="ch08.html6"/>The emerging threat landscape discussed in this chapter underscores the need for robust security measures to deploy and manage your application’s LLM. Organizations must monitor their LLM applications for any signs of unauthorized access or unusual activity. Implementing stringent access controls, conducting regular security audits, and deploying real-time anomaly detection systems are crucial to protecting against such scenarios. </p>&#13;
        <p>Many DoS or DoW attacks start with a prompt injection designed to jailbreak the system and take down guardrails that you may have put in place to align the model to your wishes. Thus, it’s critically important for you to follow the strategies for prompt injection mitigation we described in <a data-type="xref" href="ch04.html#prompt_injection">Chapter 4</a>. However, <a data-type="xref" href="ch04.html#prompt_injection">Chapter 4</a> also showed that nullifying prompt injection attacks is hard, so you’ll need to put other safeguards in place as well.</p>&#13;
        <section data-pdf-bookmark="Domain-Specific Guardrails" data-type="sect2"><div class="sect2" id="domain_specific_guardrails">&#13;
          <h2>Domain-Specific Guardrails</h2>&#13;
          <p><a contenteditable="false" data-primary="denial-of-service (DoS) attacks" data-secondary="mitigation strategies" data-tertiary="domain-specific guardrails" data-type="indexterm" id="id502"/><a contenteditable="false" data-primary="domain-specific guardrails, for DoS and DoW attacks" data-type="indexterm" id="id503"/><a contenteditable="false" data-primary="mitigation strategies, for DoS and DoW attacks" data-secondary="domain-specific guardrails" data-type="indexterm" id="id504"/>Consider fine-tuning your model by rewarding it to respond only to domain-specific inquiries. As discussed in <a data-type="xref" href="ch04.html#prompt_injection">Chapter 4</a>, alignment is crucial for ensuring that an AI system’s objectives resonate with the developer’s intended values, goals, and safety considerations. By tailoring your model to respond primarily to questions relevant to the application’s context—such as product inquiries on an ecommerce platform—you can significantly reduce the computational waste of processing irrelevant or off-topic requests. </p>&#13;
          <p>This focused approach can help safeguard the system against exploitation through unnecessary and resource-intensive tasks. For instance, an ecommerce website’s chatbot, powered by a fine-tuned model, would answer customer-related questions about purchases and product details while deflecting unrelated queries, such as complex mathematical problems. This selective responsiveness serves a dual purpose: it ensures that the application’s processing power is utilized efficiently, aligning with the operational goals of the platform, and it reduces the risk of incurring excessive costs from resource-draining inputs that contribute little to user satisfaction or the bottom line.</p>&#13;
        </div></section>&#13;
        <section data-pdf-bookmark="Input Validation and Sanitization" data-type="sect2"><div class="sect2" id="input_validation_and_sanitization">&#13;
          <h2>Input Validation and Sanitization</h2>&#13;
          <p><a contenteditable="false" data-primary="denial-of-service (DoS) attacks" data-secondary="mitigation strategies" data-tertiary="input validation/sanitization" data-type="indexterm" id="id505"/><a contenteditable="false" data-primary="input validation" data-secondary="for preventing DoS/DoW attacks" data-type="indexterm" id="id506"/><a contenteditable="false" data-primary="mitigation strategies, for DoS and DoW attacks" data-secondary="input validation/sanitization" data-type="indexterm" id="id507"/><a contenteditable="false" data-primary="sanitization" data-type="indexterm" id="id508"/>Effective input validation and sanitization are critical in preventing attacks that exploit an LLM’s processing capabilities. This involves establishing strict criteria for acceptable input and rigorously checking all incoming data against these standards. Sanitization goes further by actively removing or neutralizing any potentially harmful elements in the data. For example, inputs exceeding the context window size can be truncated or divided, and inputs with unusual or complex structures likely to cause excessive processing can be simplified or rejected. This approach not only helps mitigate the risk of resource-intensive operations triggered by malicious inputs, but also helps maintain the overall integrity and performance of the LLM.</p>&#13;
        </div></section>&#13;
        <section data-pdf-bookmark="Robust Rate Limiting" data-type="sect2"><div class="sect2" id="robust_rate_limiting">&#13;
          <h2>Robust Rate Limiting</h2>&#13;
          <p><a contenteditable="false" data-primary="denial-of-service (DoS) attacks" data-secondary="mitigation strategies" data-tertiary="robust rate limiting" data-type="indexterm" id="id509"/><a contenteditable="false" data-primary="mitigation strategies, for DoS and DoW attacks" data-secondary="robust rate limiting" data-type="indexterm" id="id510"/><a contenteditable="false" data-primary="robust rate limiting" data-type="indexterm" id="id511"/>Implementing robust rate limiting is essential to control access to LLM resources. This strategy involves defining and enforcing limits on how frequently a user or system can make requests to the LLM within a given time frame. By setting sensible thresholds on the number of requests or the amount of data processed, rate limiting can effectively prevent the system from being overwhelmed by excessive demands, whether they are part of a deliberate attack or a surge in legitimate usage. Sophisticated rate limiting can also involve dynamic adjustments based on ongoing system performance and user behavior monitoring, allowing for more flexible and responsive control.</p>&#13;
        </div></section>&#13;
        <section data-pdf-bookmark="Resource Use Capping" data-type="sect2"><div class="sect2" id="resource_use_capping">&#13;
          <h2>Resource Use Capping</h2>&#13;
          <p><a contenteditable="false" data-primary="denial-of-service (DoS) attacks" data-secondary="mitigation strategies" data-tertiary="resource use capping" data-type="indexterm" id="id512"/><a contenteditable="false" data-primary="mitigation strategies, for DoS and DoW attacks" data-secondary="resource use capping" data-type="indexterm" id="id513"/><a contenteditable="false" data-primary="resource use capping" data-type="indexterm" id="id514"/>Capping resource use per query or processing step is a direct way to control the computational burden placed on an LLM. This can involve setting limits on the number of tokens processed per request, the complexity of the computation allowed, or the time allowed for processing a single input. By imposing these caps, it becomes more difficult for an attacker to induce the LLM to perform highly resource-intensive tasks. This strategy can also help maintain predictable and stable system performance, even under high load conditions.</p>&#13;
        </div></section>&#13;
        <section data-pdf-bookmark="Monitoring and Alerts" data-type="sect2"><div class="sect2" id="monitoring_and_alerts">&#13;
          <h2>Monitoring and Alerts</h2>&#13;
          <p><a contenteditable="false" data-primary="denial-of-service (DoS) attacks" data-secondary="mitigation strategies" data-tertiary="monitoring/alerts" data-type="indexterm" id="id515"/><a contenteditable="false" data-primary="mitigation strategies, for DoS and DoW attacks" data-secondary="monitoring/alerts" data-type="indexterm" id="id516"/><a contenteditable="false" data-primary="monitoring" data-secondary="for DoS/DoW attacks" data-type="indexterm" id="id517"/>Continuous monitoring of the LLM’s resource utilization is vital for early detection of potential attacks. This monitoring involves tracking various metrics, such as CPU usage, memory consumption, response times, and the number of concurrent requests. Establishing baseline patterns of regular operation makes detecting anomalies that may indicate an attack easier. Implementing a robust alerting system ensures that any unusual activity is promptly brought to the attention of relevant personnel, allowing for quick investigation and response. This proactive approach is critical in minimizing the impact of attacks and maintaining the reliability of the LLM service.</p>&#13;
        </div></section>&#13;
        <section data-pdf-bookmark="Financial Thresholds and Alerts" data-type="sect2"><div class="sect2" id="financial_thresholds_and_alerts">&#13;
          <h2>Financial Thresholds and Alerts</h2>&#13;
          <p><a contenteditable="false" data-primary="denial-of-service (DoS) attacks" data-secondary="mitigation strategies" data-tertiary="financial thresholds/alerts" data-type="indexterm" id="id518"/><a contenteditable="false" data-primary="financial thresholds and alerts, for DoS and DoW attacks" data-type="indexterm" id="id519"/><a contenteditable="false" data-primary="mitigation strategies, for DoS and DoW attacks" data-secondary="financial thresholds/alerts" data-type="indexterm" id="id520"/>Setting financial thresholds and alerts for cloud-based LLMs can drastically reduce the damage from DoW attacks. You should establish budget limits for LLM usage and configure alerts to notify administrators when these thresholds are approached or exceeded. Such measures are essential in pay-per-use models, where the cost implications of high usage can be significant. By closely monitoring usage costs and setting predefined limits, organizations can avoid unexpected financial burdens due to malicious exploitation of their LLM resources.</p>&#13;
          <p>Model DoS and DoW represent significant threats. As these models become more integral to various applications, understanding and mitigating these threats is essential for maintaining LLM-based services’ operational integrity and financial viability.<a contenteditable="false" data-primary="" data-startref="ch08.html6" data-type="indexterm" id="id521"/><a contenteditable="false" data-primary="" data-startref="ch08.html5" data-type="indexterm" id="id522"/></p>&#13;
        </div></section>&#13;
      </div></section>&#13;
      <section data-pdf-bookmark="Conclusion" data-type="sect1"><div class="sect1" id="conclusion_5">&#13;
        <h1>Conclusion</h1>&#13;
        <p>DoS and DoW attacks have long been significant threats to web applications. Integrating LLMs into these applications has magnified these concerns, introducing new dimensions of risk that demand heightened vigilance and strategic foresight.</p>&#13;
        <p>The architecture of LLMs, characterized by their intensive computational needs and often complex, usage-based billing models, makes them particularly susceptible to these types of attacks. As we’ve seen, the potential damage extends far beyond the traditional boundaries of operational disruption. There’s an escalated financial risk due to the high costs of running these models at scale. More alarmingly, there’s an elevated risk of liability, especially in cases where LLMs are hijacked and used for illicit purposes. Such scenarios can entangle organizations in legal complications and cause irreparable harm to their reputations.</p>&#13;
      </div></section>&#13;
    </div></section></body></html>