- en: 1 How AI works
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 AI的工作原理
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: The way LLMs process inputs and generate outputs
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs处理输入和生成输出的方式
- en: The transformer architecture that powers LLMs
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 驱动LLMs的transformer架构
- en: Different types of machine learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的机器学习类型
- en: How LLMs and other AI models learn from data
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs和其他AI模型如何从数据中学习
- en: How convolutional neural networks are used to process different types of media
    with AI
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用卷积神经网络结合AI处理不同类型的媒体
- en: Combining different types of data (e.g., producing images from text)
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结合不同类型的数据（例如，从文本生成图像）
- en: This chapter clarifies how AI works, discussing many foundational AI topics.
    Since the latest AI boom, many of these topics (e.g., “embeddings” and “temperature”)
    are now widely discussed, not just by AI practitioners but also by businesspeople
    and the general public. This chapter demystifies them.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章阐明AI的工作原理，讨论了许多基础AI主题。自从最新的AI热潮以来，许多这些主题（例如，“嵌入”和“温度”）现在被广泛讨论，不仅限于AI从业者，还包括商人和公众。本章消除了这些主题的神秘感。
- en: Instead of just piling up definitions and writing textbook explanations, this
    chapter is a bit more opinionated. It points out common AI problems, misconceptions,
    and limitations based on my experience working in the field, as well as discussing
    some interesting insights you might not be aware of. For example, we’ll discuss
    why language generation is more expensive in French than in English and how OpenAI
    hires armies of human workers to manually help train ChatGPT. So, even if you
    are already familiar with all the topics covered in this chapter, reading it might
    provide you with a different perspective.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 与仅仅堆积定义和撰写教科书式解释不同，本章更具观点性。它基于我在该领域工作的经验，指出常见的AI问题、误解和局限性，并讨论一些你可能不知道的有趣见解。例如，我们将讨论为什么在法语中生成语言比在英语中更昂贵，以及OpenAI如何雇佣大量人工工人手动帮助训练ChatGPT。因此，即使你已经熟悉本章涵盖的所有主题，阅读它也可能为你提供不同的视角。
- en: The first part of this chapter is a high-level explanation of how *large language
    models* (LLMs) such as ChatGPT work. Its sections are ordered to roughly mimic
    how LLMs themselves turn inputs into outputs one step at a time.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的第一部分是对*大型语言模型*（LLMs）如ChatGPT如何工作的概述。其章节顺序大致模仿了LLMs本身逐步将输入转换为输出的过程。
- en: The middle part of this chapter discusses *machine learning,* which is the technique
    that makes computers learn from data to create LLMs and other types of AI. Note
    that AI and machine learning don’t mean the same. AI is a research field that
    tries to create computer programs to perform tasks in a way similar to humans.
    Machine learning may or may not be used for that goal. However, machine learning
    has been the preferred methodology in AI for at least two decades. So, you might
    hear people use the terms AI and machine learning interchangeably. When I speak
    of AI in this book, I mean current AI methods, and these methods involve the use
    of machine learning.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的中间部分讨论了*机器学习*，这是使计算机从数据中学习以创建LLMs和其他类型AI的技术。请注意，AI和机器学习并不意味着相同。AI是一个试图创建计算机程序以以类似于人类的方式执行任务的研究领域。机器学习可能或可能不用于该目标。然而，至少在过去二十年里，机器学习一直是AI的首选方法。因此，你可能会听到人们交替使用AI和机器学习这两个术语。当我在本书中提到AI时，我指的是当前的AI方法，这些方法涉及机器学习的使用。
- en: The last third of this chapter discusses how AI works outside language generation.
    Specifically, I give an overview of how AI analyzes and generates images or combinations
    of text and images. We also comment on current developments in AI-based video
    generation.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的最后三分之一讨论了AI在语言生成之外的运作方式。具体来说，我概述了AI如何分析和生成图像或文本和图像的组合。我们还对基于AI的视频生成领域的当前发展进行了评论。
- en: Enjoy the ride!
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 享受这段旅程吧！
- en: How LLMs work
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LLMs的工作原理
- en: Language models are computer programs that try to represent the structure of
    human language. A large language model, or LLM, is a language model on steroids.
    Its sheer size lets the LLM perform complex analyses of sentences and generate
    new text with impressive performance. Examples of LLMs are Open­AI’s GPT-4o, Meta’s
    Llama-3, Anthropic’s Claude 3.5 Sonnet, Google’s Gemini 1.5 Pro, and Mistral AI’s
    Mixtral 8x7b.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型是试图表示人类语言结构的计算机程序。大型语言模型，或LLM，是一种增强版的语言模型。其庞大的规模使得LLM能够执行复杂的句子分析，并以令人印象深刻的表现生成新文本。LLM的例子包括OpenAI的GPT-4o、Meta的Llama-3、Anthropic的Claude
    3.5 Sonnet、Google的Gemini 1.5 Pro和Mistral AI的Mixtral 8x7b。
- en: Current LLMs are designed to perform one specific task—guess the next word given
    an input sentence. The input sentence is known as the *prompt.* Suppose I asked
    you to predict the word that comes after the incomplete sentence “The Eiffel.”
    You’re very likely to suggest that “Tower” is the most logical choice. This is
    the exact job LLMs are designed to do. So, we can think of LLMs as sophisticated
    autocomplete programs. Officially, we say that LLMs are *autoregressive,* which
    means that they’re designed to produce a single extra piece of content based on
    previous content.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的LLM被设计来执行一个特定的任务——根据输入句子猜测下一个单词。输入句子被称为*提示*。假设我要求你预测不完整的句子“埃菲尔”之后的单词。你很可能建议“塔”是最合理的选项。这正是LLM被设计来做的。因此，我们可以将LLM视为复杂的自动补全程序。官方上，我们说LLM是*自回归的*，这意味着它们被设计为基于先前内容产生额外的一块内容。
- en: 'The autocomplete task may seem simple at first, but it is far-reaching. Consider
    the following prompt: “How much is 2 + 5? It is. . .” Autocompleting this kind
    of sentence requires knowing how to perform arithmetic operations. So, the task
    of performing arithmetic operations is included in the autocomplete task.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 自动补全任务可能一开始看起来很简单，但它的影响范围很广。考虑以下提示：“2加5等于多少？它是……”完成这类句子的自动补全需要知道如何执行算术运算。因此，执行算术运算的任务包含在自动补全任务中。
- en: 'Now, consider the following prompt: “How do you say ‘umbrella’ in French?”
    To accurately autocomplete this kind of sentence, you’d need to be capable of
    translating French to English. So, at least in theory, the autocomplete task encompasses
    all sorts of tasks.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，考虑以下提示：“法语中‘雨伞’怎么说？”为了准确完成这类句子，你需要能够将法语翻译成英语。所以，至少在理论上，自动补全任务包括所有各种任务。
- en: LLMs are created using machine learning, a process in which a computer analyzes
    a huge amount of data—pretty much a snapshot of the entire public internet—to
    automatically put the LLM together. The resulting LLM is a self-contained piece
    of software, meaning that it doesn’t access any external information to generate
    its outputs. For example, it doesn’t browse the web to make its next-word predictions.
    In addition, the LLM is static, so it must be periodically updated with new data
    if we want it to speak about recent events.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: LLM是通过机器学习创建的，这是一个计算机分析大量数据的过程——几乎是对整个公共互联网的快照——以自动组合LLM。结果LLM是一个自包含的软件组件，这意味着它不会访问任何外部信息来生成其输出。例如，它不会浏览网络来做出下一个单词的预测。此外，LLM是静态的，因此如果我们希望它讨论最近的事件，我们必须定期用新数据更新它。
- en: When we interact with LLMs, we don’t usually do so directly. Instead, we use
    an intermediary piece of software that processes our requests and manages the
    underlying LLM. Let’s call it the *LLM wrapper.* The wrapper uses tricks to provide
    further functionality to the user than just guessing the next word like the bare
    LLM would do. For example, the wrapper generates entire sentences, responds in
    a chatty way, and answers with real-time information, such as the current date.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们与大型语言模型（LLM）交互时，我们通常不会直接这样做。相反，我们使用一个中间软件来处理我们的请求并管理底层的LLM。让我们称它为*LLM包装器*。包装器使用技巧为用户提供比裸LLM猜测下一个单词更多的功能。例如，包装器可以生成整个句子，以闲聊的方式回答，并回答实时信息，例如当前日期。
- en: An example of an LLM wrapper is ChatGPT, which is OpenAI’s customer-facing application.
    This application manages our interactions with the underlying LLM, such as GPT-4
    and GPT-4o. Note that it is common to just use the term LLM to refer to the whole
    AI system, including the wrapper.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 一个LLM包装器的例子是ChatGPT，这是OpenAI面向客户的应用程序。此应用程序管理我们与底层LLM（如GPT-4和GPT-4o）的交互。请注意，通常人们只用LLM这个术语来指代整个AI系统，包括包装器。
- en: The next few sections discuss examples of how LLM wrappers use tricks to enhance
    the capabilities of their underlying, next-word guessing LLMs.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的几节将讨论LLM包装器如何使用技巧来增强其底层、猜测下一个单词的LLM的能力的例子。
- en: Text generation
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文本生成
- en: 'We typically use LLMs to output entire sentences instead of just guessing a
    single word. The LLM wrapper achieves this through a simple trick: it makes the
    LLM eat its own output repeatedly. Suppose we give an LLM the prompt “The Eiffel.”
    The LLM guesses the most likely continuation of the sentence: “Tower.” The LLM
    wrapper then attaches this word to the initial prompt, which leads to the new
    prompt: “The Eiffel Tower.” It then uses the LLM to guess the following word,
    say, “is” and attaches it to the prompt again. The process is repeated (see figure
    1.1) to generate entire sentences such as “The Eiffel Tower is in Paris.”'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常使用LLM来输出整个句子，而不仅仅是猜测一个单词。LLM包装器通过一个简单的技巧实现这一点：它让LLM反复吞噬自己的输出。假设我们给一个LLM提示“埃菲尔。”LLM猜测句子的最可能延续：“塔。”然后LLM包装器将这个单词附加到初始提示上，从而形成新的提示：“埃菲尔塔。”然后它使用LLM猜测下一个单词，比如“是”，并将其再次附加到提示上。这个过程被重复（见图1.1）以生成完整的句子，例如“埃菲尔塔位于巴黎。”
- en: '![](../Images/CH01_F01_Maggiori.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH01_F01_Maggiori.png)'
- en: Figure 1.1  To generate full sentences, the LLM wrapper used the LLM to generate
    one word, then attached that word to the initial prompt, then used the LLM again
    to generate one more word, and so on.
  id: totrans-26
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.1. 为了生成完整的句子，LLM包装器使用LLM生成一个单词，然后将该单词附加到初始提示上，然后再次使用LLM生成另一个单词，依此类推。
- en: End of text
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文本结束
- en: In addition to outputting regular words, LLMs are designed to output a handful
    of special code words. One of them, often stylized as “<|end of text|>” in the
    literature, is a code word that signals the end of the text. When the LLM is built,
    it is exposed to examples of sentences containing this special code word to indicate
    their end. So, the LLM gains the capability of guessing that the next best word
    is actually an indication of its ending.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 除了输出常规单词外，LLM还被设计用来输出一些特殊的代码单词。其中之一，在文献中通常被格式化为“<|文本结束|>”，是一个表示文本结束的代码单词。当LLM被构建时，它会接触到包含这个特殊代码单词的句子示例，以指示它们的结束。因此，LLM获得了猜测下一个最佳单词实际上是表示其结束的能力。
- en: When the LLM wrapper encounters this special code word, it stops the process
    of having the LLM eat its own output to generate more text, as explained in the
    previous section.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当LLM包装器遇到这个特殊的代码单词时，它就会停止按照上一节中解释的那样，让LLM吞噬其自己的输出以生成更多文本的过程。
- en: Chat
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Chat
- en: 'Have a look at what happened when I inputted the prompt “The Eiffel” to ChatGPT:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 看看当我向ChatGPT输入提示“埃菲尔”时发生了什么：
- en: '**![image](../Images/Response-Chatgpt.png)**  It seems that your sentence was
    cut off. Were you asking about the Eiffel Tower?'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**![图片](../Images/Response-ChatGPT.png)**  看起来你的句子被截断了。你是想问关于埃菲尔铁塔的吗？'
- en: The Eiffel Tower is one of the most iconic landmarks in the world, located in
    Paris, France. It was designed by Gustave Eiffel and completed in 1889 for the
    Exposition Universelle, a world’s fair held to celebrate the 100th anniversary
    of the French Revolution. Originally criticized by some of Paris's leading artists
    and intellectuals for its design, the tower has become a global cultural icon
    of France and one of the most recognizable structures in the world.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 埃菲尔铁塔是世界上最具标志性的地标之一，位于法国巴黎。它是古斯塔夫·埃菲尔设计的，于1889年为庆祝法国大革命100周年而举行的万国博览会（Exposition
    Universelle）而建成。最初，一些巴黎的著名艺术家和知识分子因其设计而批评了这座塔，但如今它已成为法国的全球文化象征，也是世界上最具辨识度的建筑之一。
- en: By the looks of it, the LLM is not just autocompleting my input, or else it
    would have continued with “Tower” instead of telling me that my sentence was cut
    off.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 从外观上看，这个大型语言模型（LLM）不仅仅是自动补全我的输入，否则它应该会继续说“塔”而不是告诉我我的句子被截断了。
- en: What happened here was that, behind the scenes, the LLM wrapper inserted a special
    code word to indicate the end of my prompt. This code word is often stylized as
    “<|end of prompt|>” in the literature. So, the actual input sent to the LLM by
    the wrapper was “The Eiffel<|end of prompt|>”. During its construction, the underlying
    LLM was fed examples of dialog ending with “<|end of prompt|>”, which is why it
    recognized that in my sentence, the code word was located at an unusual place.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 发生在这里的是，在幕后，LLM包装器插入了一个特殊的代码单词来指示我的提示结束。在文献中，这个代码单词通常被格式化为“<|提示结束|>”。因此，包装器实际发送给LLM的输入是“埃菲尔<|提示结束|>”。在构建过程中，底层LLM被提供了以“<|提示结束|>”结尾的对话示例，这就是为什么它能识别出在我这句话中，代码单词位于一个不寻常的位置。
- en: As we continue chatting back and forth with ChatGPT, the wrapper sends the LLM
    a history of the entire conversation each time, filled with “<|end of prompt|>”
    and “<|end of text|>” code words to clearly delimit the beginning and end of each
    interaction. This helps ChatGPT converse effectively.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们继续与ChatGPT来回聊天时，包装器每次都会向LLM发送整个对话的历史记录，其中充满了“<|end of prompt|>”和“<|end of
    text|>”代码词，以清楚地界定每次交互的开始和结束。这有助于ChatGPT有效地进行对话。
- en: OpenAI lets software developers use a more naked version of the LLM wrapper,
    which doesn’t insert the “<|end of prompt|>” code word after the user’s prompt.
    This is available through the API (an API is a way to connect two pieces of software—in
    this case, your software with OpenAI’s software) or the online platform for software
    developers (see [https://platform.openai.com](https://platform.openai.com)) by
    using the *completions* mode of the API instead of the default *chat* mode.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI允许软件开发者使用LLM包装器的更裸露版本，它不会在用户的提示后插入“<|end of prompt|>”代码词。这可以通过API（API是连接两个软件的方式——在这种情况下，你的软件与OpenAI的软件）或软件开发者的在线平台（见[https://platform.openai.com](https://platform.openai.com)）通过使用API的*completions*模式而不是默认的*chat*模式来实现。
- en: NOTE OpenAI’s documentation contains a warning sign telling us that the completions
    mode is “now considered legacy,” but it is still available for use as of this
    writing.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：OpenAI的文档中有一个警告标志告诉我们，完成模式“现在被认为是过时的”，但截至本文撰写时，它仍然可用。
- en: 'Let’s see what happened when I inputted “The Eiffel” to the LLM using the completions
    mode instead:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看当我使用完成模式将“埃菲尔”输入到LLM时发生了什么：
- en: '**![image](../Images/Response-Chatgpt.png)**  Tower was inaugurated on March
    31st in 1889\. It was originally built as the entrance arch for the 1889 World’s
    Fair, and was only intended to stand for 20 years. However, its unique design
    and popularity among Parisians and tourists alike led to its preservation and
    it has become an iconic symbol of France and one of the most recognizable monuments
    in the world. The idea for the Eiffel Tower came from businessman Gustave Eiffel,
    who wanted to create a structure that would showcase the advancements in engineering
    and design during the Industrial Revolution. He and his team spent two years designing
    and constructing the tower, using over 18,000 individual pieces of wrought iron
    and 2.5 million rivets.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**![image](../Images/Response-ChatGPT.png)** 埃菲尔铁塔于1889年3月31日启用。它最初被建造为1889年世界博览会的入口拱门，原计划只站立20年。然而，由于其独特的设计以及巴黎人和游客的喜爱，它得以保留，并成为法国的象征之一，也是世界上最著名的纪念碑之一。埃菲尔铁塔的想法来自商人古斯塔夫·埃菲尔，他希望创造一个能够展示工业革命期间工程和设计进步的结构。他和他的团队花费了两年时间设计和建造这座塔，使用了超过18,000个单独的锻造铁件和250万个铆钉。'
- en: We can see that the API simply autocompleted my input with a sensible continuation,
    which is why it started with “ Tower” (the word *Tower* with a leading space)
    instead of telling me that my prompt was incomplete.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到API只是简单地用合理的延续自动完成我的输入，这就是为什么它以“塔”（带前导空格的单词*Tower*）开头而不是告诉我我的提示不完整。
- en: The system prompt
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 系统提示
- en: I asked, “What is today’s date?” The response was
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我问：“今天是几号？”回答是
- en: '**![image](../Images/Response-Chatgpt.png)**  Today’s date is May 30, 2024.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '**![image](../Images/Response-ChatGPT.png)** 今天的日期是2024年5月30日。'
- en: This was the correct response at the time of me asking. This is a bit surprising
    because, as LLMs simply analyze sentences to guess the next word, they don’t have
    access to real-time data.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我提问时的正确回答。这有点令人惊讶，因为LLM只是分析句子来猜测下一个单词，它们无法访问实时数据。
- en: 'What happened here was that ChatGPT secretly inserted additional text before
    my prompt to provide contextual information to the LLM. This is known as the *system
    prompt.* We don’t know the exact details, but the rumor is that ChatGPT’s system
    prompt is as follows (see [https://mng.bz/RVOv](https://mng.bz/RVOv)):'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 发生在这里的事情是ChatGPT在提示前秘密插入额外的文本，为LLM提供上下文信息。这被称为*系统提示*。我们不知道确切的细节，但据传言，ChatGPT的系统提示如下（见[https://mng.bz/RVOv](https://mng.bz/RVOv)）：
- en: '**![image](../Images/Prompt-Icon.png)** You are ChatGPT, a large language model
    trained by Open­AI. Answer as concisely as possible. Knowledge cutoff: [knowledge
    cutoff] Current date: [current date and time]'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '**![image](../Images/Prompt-Icon.png)** 你是ChatGPT，一个由OpenAI训练的大型语言模型。尽可能简洁地回答。知识截止日期：[知识截止日期]
    当前日期：[当前日期和时间]'
- en: This prompt is secretly inserted every time you start a chat with ChatGPT. Because
    the date appears in ChatGPT’s system prompt, the chatbot can answer questions
    about the current date, as in the previous example. Note that the knowledge cutoff
    date is also inserted, which helps ChatGPT inform the user that it cannot answer
    questions about events that took place after a certain date.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这个提示在每次与ChatGPT开始聊天时都会秘密插入。因为日期出现在ChatGPT的系统提示中，所以聊天机器人可以回答关于当前日期的问题，就像之前的例子一样。请注意，知识截止日期也会插入，这有助于ChatGPT告知用户它无法回答关于某个日期之后发生的事件的问题。
- en: Software developers can interact with OpenAI’s LLMs via an API instead of using
    the customer-facing ChatGPT. The API lets you define what the system prompt is,
    which is inserted before your initial interactions with the LLM. Figure 1.2 shows
    a visual interface provided by OpenAI to help developers try out the API. We can
    see a box dedicated to the system prompt.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 软件开发人员可以通过API与OpenAI的LLM交互，而不是使用面向客户的ChatGPT。API允许你定义系统提示，这是在您与LLM的初始交互之前插入的。图1.2显示了OpenAI提供的可视化界面，以帮助开发者尝试API。我们可以看到一个专门用于系统提示的框。
- en: I asked the GPT-4o LLM about the current date using OpenAI’s API, while leaving
    the system prompt empty. In figure 1.2, we can see that the LLM refused to answer
    about the date.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用OpenAI的API向GPT-4o LLM询问当前日期，同时保持系统提示为空。在图1.2中，我们可以看到LLM拒绝回答关于日期的问题。
- en: '![](../Images/CH01_F02_Maggiori.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH01_F02_Maggiori.png)'
- en: Figure 1.2  OpenAI’s API lets users define a system prompt, which is a piece
    of text inserted into the beginning of the user’s prompt.
  id: totrans-52
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.2 OpenAI的API允许用户定义系统提示，这是一段文本，插入到用户提示的开始部分。
- en: Figure 1.3 shows that the LLM does answer with the date if it is given as part
    of the system prompt, like ChatGPT would do.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3显示，如果将日期作为系统提示的一部分提供，LLM会回答，就像ChatGPT会做的那样。
- en: Calling external software functions
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 调用外部软件功能
- en: I asked ChatGPT about the current weather in London. ChatGPT’s user interface
    showed a sign that said, “Searching the web.” A second later, the sign turned
    into “Searching current weather in London.” Afterward, it told me what the weather
    in London was like (see figure 1.4).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我向ChatGPT询问了伦敦的当前天气。ChatGPT的用户界面显示了一个标志，上面写着“正在搜索网络。”一秒后，标志变成了“正在搜索伦敦的当前天气。”之后，它告诉我伦敦的天气情况（见图1.4）。
- en: The trick here is to describe in the system prompt a list of software functions
    that the LLM can suggest the wrapper to call if it needs to gather external information.
    If the LLM suggests calling one of those functions, it is the job of the LLM wrapper
    to call it and then insert the result into the prompt.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的技巧是在系统提示中描述一系列软件功能，如果LLM需要收集外部信息，它可以建议调用这些包装器。如果LLM建议调用这些功能之一，那么调用该功能并将其结果插入提示的责任就落在LLM包装器上。
- en: '![](../Images/CH01_F03_Maggiori.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH01_F03_Maggiori.png)'
- en: Figure 1.3  When the current date is supplied as part of the system prompt,
    the LLM can answer questions about the current date.
  id: totrans-58
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.3 当当前日期作为系统提示的一部分提供时，LLM可以回答关于当前日期的问题。
- en: Suppose a developer wants to create a chatbot app that can seamlessly answer
    questions about current events, such as the weather, the value of stocks, and
    trending news topics. The developer could explain in the system prompt that, if
    the current weather in London is required, the LLM should output `"current_weather(London)"`,
    if the value of Apple stock is needed, it should output `"stock_value(Apple)"`,
    and so on. When these special messages are outputted, the developer will call
    software functions to gather the necessary information and add it to the prompt.
    This will give the end user the impression of seamless access to real-time data.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 假设一个开发者想要创建一个聊天机器人应用程序，它可以无缝地回答关于当前事件的问题，例如天气、股票价值以及热门新闻话题。开发者可以在系统提示中解释，如果需要伦敦的当前天气，LLM应该输出`"current_weather(London)"`，如果需要苹果股票的价值，它应该输出`"stock_value(Apple)"`，依此类推。当这些特殊消息输出时，开发者将调用软件功能来收集必要的信息并将其添加到提示中。这将给最终用户留下无缝访问实时数据的印象。
- en: '![](../Images/CH01_F04_Maggiori.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH01_F04_Maggiori.png)'
- en: Figure 1.4  ChatGPT called a function to search the web behind the scenes and
    inserted the results into the user’s prompt. This creates the illusion that the
    LLM browses the web.
  id: totrans-61
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.4 ChatGPT在幕后调用了一个搜索网络的函数，并将结果插入到用户的提示中。这创造了一种LLM浏览网络的错觉。
- en: 'OpenAI has created a framework that lets a developer easily define a list of
    functions that the LLM could suggest calling. Here’s an example of how to define
    a `"get_current_weather"` function, as described in the official documentation
    (see [https://mng.bz/2y4a](https://mng.bz/2y4a)):'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI创建了一个框架，允许开发者轻松定义LLM可以建议调用的函数列表。以下是如何定义`"get_current_weather"`函数的示例，如官方文档中所述（见[https://mng.bz/2y4a](https://mng.bz/2y4a)）：
- en: '[PRE0]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note that the code of the weather-fetching function is not part of this declaration.
    Only a description of the function and its inputs is provided. The LLM wrapper
    inserts the description of this function into the system prompt so that the underlying
    LLM can suggest calling it if needed.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，天气获取函数的代码不属于此声明的一部分。只提供了函数及其输入的描述。LLM包装器将此函数的描述插入到系统提示中，以便底层LLM在需要时可以建议调用它。
- en: 'When the wrapper detects that the LLM suggests calling the function, it notifies
    the user. Here’s an example of the API response object, using OpenAI’s Python
    SDK, that resulted after the user asked about the weather in London:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 当包装器检测到LLM建议调用该函数时，它会通知用户。以下是一个示例，使用OpenAI的Python SDK，在用户询问伦敦天气后得到的API响应对象：
- en: '[PRE1]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The software developer must code the "`get_current_weather"` function, run
    it, and then insert the response into the following prompt (“Weather in London,
    United Kingdom: 20 degrees Celsius, rainy”). The LLM can then use this newly added
    information. The app end user gets the impression that the LLM itself was capable
    of answering about the weather in real time. In reality, the LLM is still a self-contained
    program; the enhanced functionality is achieved outside the LLM.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 软件开发者必须编写`"get_current_weather"`函数，运行它，然后将响应插入以下提示（“伦敦，英国天气：20摄氏度，雨天”）。然后，LLM可以使用这些新添加的信息。应用程序的最终用户会感觉到LLM本身能够实时回答关于天气的问题。实际上，LLM仍然是一个独立的程序；增强的功能是在LLM之外实现的。
- en: Retrieval-augmented generation
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 检索增强生成
- en: Sometimes users want the LLM to analyze documents that aren’t present in the
    training data. For example, a business may want to answer questions about its
    internal documents, or an app may want to analyze the content of up-to-date webpages.
    Retrieval-augmented generation, or RAG, is a popular way of doing that (you can
    learn more in *A Simple Guide to Retrieval Augmented Generation* by Abhinav Kimothi,
    available at [https://mng.bz/yWpe](https://mng.bz/yWpe)). When the user submits
    a prompt, the LLM wrapper first searches for relevant documents in a database.
    For example, it may extract keywords from the prompt and find documents that match
    the keywords. This is known as *retrieval.*
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 有时用户希望LLM分析训练数据中不存在的文档。例如，一家企业可能希望回答有关其内部文档的问题，或者一个应用程序可能希望分析最新网页的内容。检索增强生成（RAG）是这样做的一种流行方式（你可以在Abhinav
    Kimothi的*《检索增强生成简单指南》*中了解更多信息，可在[https://mng.bz/yWpe](https://mng.bz/yWpe)找到）。当用户提交提示时，LLM包装器首先在数据库中搜索相关文档。例如，它可能从提示中提取关键词并找到匹配的文档。这被称为*检索*。
- en: '*Afterward, the LLM wrapper inserts the content of these documents into the
    prompt. So, the prompt is said to be *augmented* with additional, relevant information.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '*之后，LLM包装器将这些文档的内容插入到提示中。因此，提示被认为是*增强*了额外的相关信息。'
- en: When the LLM generates text, it has access to these documents as part of the
    prompt, so it can use their content to enhance its predictions. RAG is a popular
    approach to creating an in-house chatbot adapted to a specific business. In addition,
    it is commonly used to create the illusion that an LLM can access up-to-date web
    content in real time. RAG can also help identify specific sources used by the
    LLM to generate its output and thus cite references.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当LLM生成文本时，它可以访问这些文档作为提示的一部分，因此可以使用它们的内容来增强其预测。RAG是一种流行的创建适应特定业务内部聊天机器人的方法。此外，它通常用于创建LLM可以实时访问最新网络内容的错觉。RAG还可以帮助识别LLM生成输出时使用的特定来源，从而引用参考文献。
- en: One of the challenges of the RAG approach is finding relevant documents based
    on the prompt. Many algorithms have been used for a long time by search engines
    to index and retrieve content, and researchers are studying specific retrieval
    techniques for RAG (see [https://arxiv.org/abs/2405.06211](https://arxiv.org/abs/2405.06211)).
    Another challenge is that prompts can become quite long with the added documents.
    LLMs only accept a maximum prompt length (more on this in the following), so you
    must make sure that the documents inserted into the prompt fit the maximum allowed
    length. In addition, longer prompts incur higher costs as AI providers charge
    fees that depend on the amount of text inputted and outputted.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: RAG方法的一个挑战是根据提示找到相关文档。许多算法长期以来一直被搜索引擎用于索引和检索内容，研究人员正在研究RAG（参见[https://arxiv.org/abs/2405.06211](https://arxiv.org/abs/2405.06211)）的特定检索技术。另一个挑战是，随着文档的增加，提示可能会变得相当长。LLM只能接受最大提示长度（以下将详细介绍），因此你必须确保插入到提示中的文档符合最大允许长度。此外，较长的提示会带来更高的成本，因为AI提供商根据输入和输出的文本量收费。
- en: The concept of tokens
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 标记的概念
- en: We’ve been saying that LLMs guess the next word from an input prompt, but this
    isn’t quite accurate. Let’s now refine our understanding.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们一直在说LLM从输入提示中猜测下一个单词，但这并不完全准确。现在让我们更精确地理解这一点。
- en: LLMs contain a fixed-size internal vocabulary. These are the words that LLMs
    can read and generate. An LLM’s vocabulary typically contains
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: LLM包含一个固定大小的内部词汇。这些是LLM可以读取和生成的单词。LLM的词汇量通常包含
- en: Common words (e.g., “dog”)
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常用词汇（例如，“狗”）
- en: Common pieces of words (e.g., “ish”)
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常用单词片段（例如，“ish”）
- en: Common Latin characters (e.g., “a” and “b”)
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 常见的拉丁字母（例如，“a”和“b”）
- en: Special symbols from a text-encoding standard called UTF-8, which are combined
    together to represent non-Latin characters and other symbols (e.g., “á,” “æ,”
    and “你”)
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自名为UTF-8的文本编码标准的特殊符号，这些符号组合在一起用来表示非拉丁字符和其他符号（例如，“á”，“æ”和“你”）
- en: Special code words such as “<end of text>” and “<end of prompt>”
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 特殊的代码词，如“<文本结束>”和“<提示结束>”
- en: Each element in the vocabulary is known as a *token.* We can think of a token
    as a common piece of text. Using tokens instead of entire words, lets LLMs read
    and produce words that aren’t in the dictionary (e.g., “hungryish”) by combining
    common pieces of words (“hungry” + “ish”). It also lets LLMs read and produce
    non-Latin text and invent new words.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 词汇表中的每个元素都称为*标记*。我们可以将标记视为常见的文本片段。使用标记而不是整个单词，LLM可以通过组合常见的单词片段（“hungry”+“ish”）来读取和生成不在字典中的单词（例如，“hungryish”）。它还允许LLM读取和生成非拉丁文本并创造新词。
- en: Current LLMs’ vocabularies contain roughly 100,000 different possible tokens.
    For example, some of OpenAI’s LLMs, including GPT-3.5 and GPT-4, have a vocabulary
    with 100,261 possible tokens.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 当前大型语言模型（LLM）的词汇量大约包含10万个不同的可能标记。例如，包括GPT-3.5和GPT-4在内的OpenAI的LLM，其词汇量有100,261个可能的标记。
- en: Note that many tokens represent common words with a leading space attached to
    them. For example, both “dog” and “ dog” are tokens in the vocabulary of OpenAI’s
    LLMs. So, the LLM is often spared from having to use the dedicated whitespace
    token. From now on, whenever I speak of an individual token in this book, such
    as the “dog” token, bear in mind there might be a leading space attached to it.
    (I won’t be writing the space every time, as it’s a bit ugly to read.)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，许多标记代表带有前导空格的常用词汇。例如，“dog”和“ dog”都是OpenAI的LLM词汇表中的标记。因此，LLM通常可以避免使用专门的空白标记。从现在开始，每当我在本书中提到单个标记，例如“dog”标记时，请记住它可能带有前导空格。
    （我不会每次都写上空格，因为它看起来有点难看。）
- en: The vocabulary of an LLM is created by running an automated analysis over thousands
    of documents to identify the most common text patterns (the algorithm usually
    used for this is called byte pair encoding. You can find more details and a step-by-step
    example in a blog article I wrote at [https://emaggiori.com/chatgpt-vocabulary/](https://emaggiori.com/chatgpt-vocabulary/)).
    OpenAI stopped disclosing how it creates LLMs’ vocabularies, but we do know how
    they did it with older models. For example, GPT-3’s vocabulary was created by
    automatically following links from popular Reddit discussions, collecting the
    text from the linked webpages, and identifying the most common words and combinations
    of characters in them (Redford et al., “Language Models are Unsupervised Multitask
    Learners,” 2019).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的词汇表是通过在数千份文档上运行自动分析来创建的，以识别最常见的文本模式（通常用于此的算法称为字节对编码。您可以在我在[https://emaggiori.com/ChatGPT-vocabulary/](https://emaggiori.com/ChatGPT-vocabulary/)上写的博客文章中找到更多细节和逐步示例）。OpenAI停止公开其创建LLM词汇表的方法，但我们确实知道它们是如何使用旧模型做到这一点的。例如，GPT-3的词汇表是通过自动跟踪来自流行Reddit讨论的链接、收集链接网页上的文本以及识别其中最常见的单词和字符组合来创建的（Redford等人，“语言模型是无监督的多任务学习者”，2019年）。
- en: One token at a time
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 一次一个标记
- en: 'LLMs are designed to read a sequence of valid tokens from their vocabulary.
    So, the LLM wrapper first subdivides the input prompt into valid tokens. For example,
    when using GPT-3.5, the prompt “The dog’s bark was barely” is subdivided as follows
    by the LLM wrapper before passing it to the LLM:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs（大型语言模型）被设计为从它们的词汇表中读取一系列有效的标记。因此，LLM包装器首先将输入提示符细分为有效的标记。例如，当使用GPT-3.5时，提示符“狗的叫声几乎”在传递给LLM之前被LLM包装器如下细分：
- en: '[PRE2]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The subdivision is performed using an algorithm that roughly tries to split
    the input using the largest possible tokens from the vocabulary.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 使用算法进行细分，该算法大致尝试使用词汇表中的最大标记来分割输入。
- en: OpenAI provides a webpage where you can input text and see how it’s tokenized
    before being fed into a model. You can find it at [https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI提供了一个网页，您可以在其中输入文本并查看在将其输入模型之前如何对其进行标记化。您可以在[https://platform.openai.com/tokenizer](https://platform.openai.com/tokenizer)找到它。
- en: 'LLMs don’t read raw text. Instead, the LLM wrapper first converts the input
    prompt into a list of integers indicating the ID of each token, which is its position
    in the vocabulary:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: LLM不读取原始文本。相反，LLM包装器首先将输入提示符转换为表示每个标记ID的整数列表，这是其在词汇表中的位置：
- en: '[PRE3]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Afterward, the wrapper uses the LLM to predict the ID of the most likely next
    token. In the previous example, the LLM outputs that the token with ID 80415 is
    the most likely continuation of the input prompt. This token corresponds to “audible”.The
    LLM wrapper then attaches that token to the input:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，包装器使用LLM来预测最有可能的下一个标记的ID。在先前的例子中，LLM输出ID为80415的标记最有可能是输入提示符的后续内容。这个标记对应于“audible”。然后LLM包装器将这个标记附加到输入上：
- en: '[PRE4]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, the LLM wrapper feeds this new prompt (as a list of integers, `[791,`
    `5679,` `596,` `54842,` `574,` `20025,` `80415]`) to the LLM to have it “eat its
    own output” and generate one more token. This process is repeated many times to
    generate more tokens:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，LLM包装器将这个新提示（作为整数列表，`[791, 5679, 596, 54842, 574, 20025, 80415]`）输入到LLM中，让它“吃掉自己的输出”并生成一个额外的标记。这个过程重复多次以生成更多标记：
- en: '[PRE5]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In this example, after a few more paragraphs of mumbo jumbo regarding dogs and
    noise, the LLM decided that the token with ID 100276 was the most likely continuation
    of the prompt. This token is code for “<|end of text|>”. So, the LLM deemed this
    a good place to end the text. Upon stumbling on this token, the LLM wrapper heeded
    the LLM’s recommendation and stopped generating more text.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，在关于狗和噪音的几段胡言乱语之后，LLM决定ID为100276的标记最有可能是提示符的后续内容。这个标记代表“<|end of text|>”。因此，LLM认为这是一个结束文本的好地方。在遇到这个标记后，LLM包装器遵循LLM的建议并停止生成更多文本。
- en: 'Have a look at how GPT-3.5 explained to me the meaning of the word “hungryish”,
    token by token:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 看看GPT-3.5是如何逐个标记地向我解释单词“hungryish”的含义的：
- en: '[PRE6]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We can see that, even though the word “hungryish” isn’t part of GPT-3.5’s vocabulary,
    it managed to generate it using a sequence of two tokens, “hungry” and “ish.”
    Note that the words “milder,” “I’m,” “you’re,” and “It’s” were also produced using
    two tokens each.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，尽管单词“hungryish”不是GPT-3.5词汇表的一部分，但它通过两个标记的序列“hungry”和“ish”成功地生成了它。请注意，“milder”、“I’m”、“you’re”和“It’s”这些单词也是通过每个单词两个标记生成的。
- en: Billed by the token
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 按标记计费
- en: Most LLM APIs, which let software developers use LLMs programmatically, bill
    users by the number of tokens inputted and outputted to the LLM. Thus, longer
    prompts and longer responses incur higher costs.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数LLM API，允许软件开发者以编程方式使用LLM，按输入和输出到LLM的标记数向用户收费。因此，较长的提示词和较长的响应会产生更高的成本。
- en: As of today, for example, GPT-4o costs US$5 per million input tokens plus US$15
    per million output tokens. For reference, the entire Shakespearean play *Romeo
    and Juliet* requires 40,000 tokens, so inputting it to GPT-4o would cost $0.20,
    and generating it would cost $0.60\. This doesn’t sound like a lot, but bills
    can easily add up if you use LLMs repeatedly. For example, if you send a long
    prompt to an LLM every time a user visits your website, you could spend thousands
    a month.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，截至今天，GPT-4o的费用是每百万输入标记5美元，每百万输出标记15美元。以参考为例，整个莎士比亚戏剧《罗密欧与朱丽叶》需要40,000个标记，因此将其输入到GPT-4o将花费0.20美元，生成它将花费0.60美元。这听起来并不多，但如果反复使用LLM，账单很容易增加。例如，如果你每次用户访问你的网站时都向LLM发送一个长提示词，你可能会每月花费数千美元。
- en: Note that when you chat back and forth with an LLM, you must include your entire
    chat history on every interaction with it, or at least you must do so if you want
    the LLM to be able to analyze the previous conversation when generating new outputs.
    So, the prompt becomes increasingly expensive as your chat history becomes longer.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，当你与LLM进行来回聊天时，你必须在与它的每次互动中都包括你的整个聊天历史，或者至少如果你想让LLM能够在生成新输出时分析之前的对话，你必须这样做。因此，随着你的聊天历史变长，提示词的成本会越来越高。
- en: What about languages other than English?
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 那么，对于英语以外的语言呢？
- en: LLM’s vocabularies tend to be optimized for the English language. For example,
    they contain a “dog” token but not one to represent the French word for dog. So,
    words not in English tend to be split into many tokens, often covering one or
    two letters at a time, as the vocabulary doesn’t contain as many tokens to represent
    entire words.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的词汇表往往针对英语进行优化。例如，它们包含“dog”标记，但没有表示狗的法语单词的标记。因此，非英语单词往往被分成许多标记，通常每次覆盖一个或两个字母，因为词汇表中没有足够的标记来表示整个单词。
- en: 'Have a look at how the preamble of the U.S. Constitution is tokenized before
    being inputted into GPT-4:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 看看美国宪法序言在被输入到GPT-4之前的标记化过程：
- en: '[PRE7]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'And now, have a look at its French translation:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，看看它的法语翻译：
- en: '[PRE8]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The French text takes more than twice the number of tokens than its English
    counterpart. In addition, the subdivision of words in French doesn’t make much
    sense. For example, “États-Unis d’Amérique” (United States of America) is chopped
    up into many meaningless pieces such as “ats” and “-Un.”
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 法语文本比其英文对应文本的标记数多出两倍以上。此外，法语中单词的细分并没有太多意义。例如，“États-Unis d’Amérique”（美国）被分割成许多无意义的片段，如“ats”和“-Un”。
- en: 'This problem gets even more serious with non-Latin alphabets. An extreme example,
    widely discussed around the internet, is the word for “woman” in Telugu, one of
    the languages spoken in India: స్త్రీ. This word is made up of a combination of
    six characters arranged horizontally and vertically. GPT-4 requires a whopping
    18 tokens to represent this word using special UTF-8 tokens.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题在非拉丁字母中变得更加严重。一个广泛讨论的极端例子是印度使用的泰卢固语中“woman”这个词：స్త్రీ。这个词由六个字符的组合组成，这些字符水平垂直排列。GPT-4需要18个特殊的UTF-8标记来表示这个单词。
- en: As LLMs are billed by the token, the higher number of tokens can make them more
    expensive to use in other languages compared to English. In addition, it can be
    more challenging for the LLM to analyze the prompt because individual inputs,
    such as an “é” token, don’t carry much meaning by themselves; the LLM must work
    extra hard to contextualize adjacent tokens and derive meaning from them.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大型语言模型（LLM）按标记计费，与其他语言相比，使用其他语言的LLM可能会更昂贵。此外，LLM分析提示词可能更具挑战性，因为单个输入，如“é”标记，本身并不携带太多意义；LLM必须额外努力来上下文化相邻的标记并从中提取意义。
- en: The bias toward a specific language—English in the most popular LLMs—may not
    be easily removed. To better tokenize words in other languages, the vocabulary
    would have to be extended to include words or common pieces of words in, say,
    French, Chinese, Telugu, and so on. This would multiply the vocabulary size, well
    beyond the current 100,000 mark, which could turn LLMs ineffective and slow.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 对特定语言（在最受欢迎的LLMs中是英语）的偏见可能不容易消除。为了更好地标记其他语言的单词，词汇表必须扩展到包括法语、中文、泰卢固语等语言中的单词或常见的单词片段。这将使词汇表的大小增加，远远超过当前的10万标记，这可能会使LLMs变得无效并减慢速度。
- en: OpenAI has been working on improving its LLMs’ internal vocabularies to better
    handle non-English text. The details haven’t been disclosed yet as of this writing,
    but its creators shared a few illustrative cases with the new vocabulary used
    by GPT-4o (see [https://openai.com/index/hello-gpt-4o/](https://openai.com/index/hello-gpt-4o/)).
    For example, a snippet of text in Telugu requires 3.5× fewer tokens than before,
    but it still requires twice as many as its English counterpart.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI一直在努力改进其LLMs的内部词汇表，以更好地处理非英语文本。截至本文撰写时，细节尚未公开，但它的创造者与GPT-4o使用的新词汇的一些示例案例进行了分享（见[https://openai.com/index/hello-gpt-4o/](https://openai.com/index/hello-gpt-4o/)）。例如，一段泰卢固语的文本比之前少用了3.5倍的标记，但仍然比其英语对应物多一倍。
- en: Why do LLMs need tokens anyway?
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么LLMs需要标记呢？
- en: One may wonder why tokens are needed at all; that is, why not have the LLM directly
    read and generate individual characters instead? As we’ll discuss soon, LLMs try
    to internally describe the *meaning* of each individual input. Describing the
    meaning of a token such as “Paris” is quite easy. For instance, we could describe
    it as “capital of France.” However, describing the meaning of a token such as
    “P” is much harder, as we don’t know what the letter refers to unless we analyze
    the context. That’s why it’s much more straightforward to take “Paris” as a single
    token in one go. The same goes for generating text—it’s much more straightforward
    to let the LLM output a token such as “Paris,” which carries a strong meaning
    by itself, instead of having it output the same word one character at a time.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 一个人可能会想知道为什么需要标记；也就是说，为什么不直接让LLM读取和生成单个字符呢？正如我们很快将要讨论的，LLMs试图内部描述每个单个输入的*意义*。描述像“巴黎”这样的标记的意义相当简单。例如，我们可以将其描述为“法国的首都”。然而，描述像“P”这样的标记的意义要困难得多，因为我们不知道这个字母指的是什么，除非我们分析上下文。这就是为什么一次性将“巴黎”作为一个单独的标记要直接得多。同样的道理也适用于生成文本——让LLM输出像“巴黎”这样的标记，它本身就有很强的意义，而不是让它一个字符一个字符地输出相同的单词，要直接得多。
- en: We could take this idea to the extreme and create a huge vocabulary that includes
    all sorts of words and their derivatives, such as “Parisian,” “Parisians,” “Parisian
    weather,” and “Emily in Paris.” But this would go too far—the vocabulary would
    become huge, and it would be wasteful because many tokens would represent closely
    related ideas. The current setup, with tokens representing the most common words
    and pieces of words, is an in-between solution that works well in practice.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这个想法推向极致，创建一个包含各种单词及其派生词的巨大词汇表，例如“巴黎人”、“巴黎人”、“巴黎天气”和“巴黎的艾米丽”。但这会走得太远——词汇表会变得非常大，而且会浪费资源，因为许多标记将代表密切相关的内容。当前设置，使用标记表示最常见的单词和单词片段，是一种在实践中效果良好的折中方案。
- en: 'Embeddings: A way to represent meaning'
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 嵌入：表示意义的一种方式
- en: One of the greatest challenges of AI is finding an effective way to represent
    high-level concepts, meaning, and ideas. When designing an LLM, we want the model
    to internally represent the meaning of a token instead of its letters. For example,
    we want the token “dog” to be represented by a description of what a dog is (say,
    a friendly, four-legged animal).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能最大的挑战之一是找到一种有效的方式来表示高级概念、意义和思想。在设计LLM时，我们希望模型内部表示标记的意义而不是其字母。例如，我们希望标记“dog”被表示为对狗的描述（比如说，一个友好的四足动物）。
- en: An *embedding* is one of the most common ways of representing meaning. It is
    used by LLMs and other types of AI*.* An embedding is a list (or “vector”) of
    numbers. The number of elements in the vector is known as the embedding’s *dimension.*
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '*嵌入*是表示意义最常见的方式之一。它被LLMs和其他类型的AI使用。嵌入是一个数字列表（或“向量”）。向量中的元素数量被称为嵌入的*维度*。'
- en: '*We can think of each position in this vector as a measure of how much a token
    matches a certain topic. Let’s have a look at an example. Imagine an embedding
    vector of length five represents the following five topics: “Animal,” “Cat,” “Large,”
    “Scary,” and “Four legs.” Suppose we want to represent the meaning of the “dog”
    token using these topics. Figure 1.5 provides an (imagined) solution.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们可以将这个向量中的每个位置视为衡量一个标记与某个主题匹配程度的一个指标。让我们来看一个例子。假设一个长度为五的嵌入向量代表以下五个主题：“动物”、“猫”、“大型”、“可怕”和“四条腿”。假设我们想使用这些主题来表示“狗”标记的含义。图1.5提供了一个（虚构的）解决方案。'
- en: '![](../Images/CH01_UN01_Maggiori.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH01_UN01_Maggiori.png)'
- en: Figure 1.5 Each token is mapped to a vector of numbers. We can imagine that
    each number in the vector represents a topic. Here’s an imaginary list of topics
    and their respective numbers for the “dog” token.
  id: totrans-123
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.5：每个标记被映射到一个数字向量。我们可以想象向量中的每个数字代表一个主题。以下是一个关于“狗”标记的虚构主题列表及其相应的数字。
- en: In this illustration, the token was mapped to five numbers, each of them indicating
    how much the meaning of the token matches each topic. We can see that the token
    scores a high value with respect to the “Animal” topic, as a dog is certainly
    an animal. The token scores a negative value with respect to the “Cat” topic,
    as a dog is sometimes seen as the opposite of a cat. It scores a neutral value
    of zero with respect to “Large” because we don’t typically think of a dog as being
    a particularly large or small object. Figure 1.6 shows how we could imagine the
    embedding for the “elephant” token.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个插图上，标记被映射到五个数字，每个数字都表示标记的含义与每个主题匹配的程度。我们可以看到，在“动物”主题上，标记得到了一个高分数，因为狗当然是一种动物。在“猫”主题上，标记得到了一个负分数，因为狗有时被视为猫的对立面。在“大型”主题上，标记得到了一个零分的中性值，因为我们通常不会认为狗是一个特别大或小的物体。图1.6展示了我们如何想象“大象”标记的嵌入。
- en: '![](../Images/CH01_UN02_Maggiori.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH01_UN02_Maggiori.png)'
- en: Figure 1.6 An imaginary embedding vector for the “elephant” token
  id: totrans-126
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.6：一个关于“大象”标记的虚构嵌入向量
- en: In this case, the embedding vector is neutral with respect to “Cat” and highly
    positive with respect to “Large.”
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，嵌入向量对“猫”是中性的，而对“大型”则是高度积极的。
- en: LLMs are all about embeddings. LLMs go to great lengths to try to find a good,
    contextualized representation of tokens by using embeddings. At the end of many
    layers of processing, the embeddings are very good at representing the true meaning
    of the input tokens, which makes it easy for the LLM to do the job of guessing
    the next token.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs的核心是嵌入。LLMs会不遗余力地尝试通过使用嵌入来找到标记的良好、上下文化的表示。在经过多层处理之后，嵌入向量非常擅长表示输入标记的真实含义，这使得LLM能够轻松地完成猜测下一个标记的任务。
- en: LLMs use much longer embedding vectors than in the above example, which lets
    them represent a huge number of topics. For example, GPT-3 uses 12,288-dimensional
    embeddings, so each input token is represented by 12,288 numbers. The smallest
    model in the Llama 3 family, developed by Meta, uses embeddings of 4,096 dimensions,
    and the largest one uses embeddings of 16,384 dimensions ([https://arxiv.org/abs/2407.21783](https://arxiv.org/abs/2407.21783)).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs使用比上述示例中更长的嵌入向量，这使得它们能够表示大量的主题。例如，GPT-3使用12,288维度的嵌入向量，因此每个输入标记由12,288个数字表示。Llama
    3系列中最小的模型，由Meta开发，使用4,096维度的嵌入向量，而最大的模型使用16,384维度的嵌入向量（[https://arxiv.org/abs/2407.21783](https://arxiv.org/abs/2407.21783)）。
- en: Machine learning and embeddings
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习和嵌入
- en: Designing long embeddings by hand would be very difficult. Thus, we use *machine
    learning* to do the job instead. This means that we make a computer analyze a
    large amount of data, such as text collected from the internet, to come up with
    useful embeddings.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 手动设计长嵌入向量是非常困难的。因此，我们使用*机器学习*来完成这项工作。这意味着我们让计算机分析大量数据，例如从互联网收集的文本，以得出有用的嵌入向量。
- en: When AI engineers use, say, 12,288-dimensional embeddings inside an LLM, what
    they do is leave room for 12,288 topics. However, it is up to the machine to select
    and organize the topics to best attain its objectives.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 当AI工程师在LLM中使用，比如说12,288维度的嵌入时，他们实际上是为12,288个主题留出了空间。然而，选择和组织主题以最佳实现其目标的工作则由机器来完成。
- en: As embeddings are created automatically, it is very hard to know which topics
    are represented by each of their dimensions. In addition, the topics may not be
    as clear-cut as “Large” and “Cat.” So, by using machine learning, we can create
    effective embeddings—the proof being that LLMs work well—but we can’t understand
    exactly how they work. *Explainability* is sacrificed in the name of predictive
    power.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 由于嵌入是自动创建的，很难知道每个维度代表哪些主题。此外，主题可能不像“大”和“猫”那样清晰。因此，通过使用机器学习，我们可以创建有效的嵌入——证明是LLMs表现良好——但我们无法确切了解它们是如何工作的。*可解释性*在预测能力的名义下被牺牲了。
- en: Visualizing embeddings
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 可视化嵌入
- en: A location on Earth can be determined by its latitude and longitude. We can
    equally think of each number inside an embedding vector as coordinates that help
    us figure out where the token is inside a space of meaning. Figure 1.7 illustrates
    an example of the space of meaning defined by a 2D embedding vector with the topics
    “Scary” and “Large.” Every token is placed inside this space according to its
    “Scary” and “Large” values in the embedding vector.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 地球上的一个位置可以通过其纬度和经度来确定。我们可以同样将嵌入向量中的每个数字视为坐标，这些坐标帮助我们确定标记在意义空间中的位置。图1.7展示了由二维嵌入向量定义的意义空间的一个例子，其中包含“可怕”和“大”这两个主题。每个标记都根据其在嵌入向量中的“可怕”和“大”值放置在这个空间中。
- en: '![](../Images/CH01_F05_Maggiori.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH01_F05_Maggiori.png)'
- en: Figure 1.7 We can think the numbers in an embedding vector as coordinates that
    place the token in a multidimensional “meaning space.”
  id: totrans-137
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.7 我们可以将嵌入向量中的数字视为坐标，这些坐标将标记放置在多维“意义空间”中。
- en: You can see that similar objects tend to group together; that’s why the tokens
    “anaconda” and “snake” are close together in this space and so are “beetle” and
    “ladybug,” but “anaconda” and “ladybug” are far apart.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到相似的对象往往聚集在一起；这就是为什么在这个空间中，“蟒蛇”和“蛇”这两个标记很近，而“甲虫”和“瓢虫”也是如此，但“蟒蛇”和“瓢虫”则相距甚远。
- en: Well-designed, useful embeddings are such that tokens that are closely related
    in terms of meaning are also placed close together within this imaginary embedding
    space. If embedding vectors do a bad job at representing the true meaning of tokens,
    then related tokens will not be close together in this imaginary embedding space.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 设计良好的、有用的嵌入是这样的，即意义上紧密相关的标记在这个假想的嵌入空间中也放置得相对较近。如果嵌入向量在表示标记的真实意义上做得不好，那么相关的标记在这个假想的嵌入空间中就不会靠近。
- en: As embedding vectors are usually very long, the embedding space is high-dimensional.
    We can’t draw it, but we can still imagine that, in this high-dimensional space,
    related tokens are physically clustered together.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 由于嵌入向量通常非常长，嵌入空间是高维的。我们无法绘制它，但我们仍然可以想象，在这个高维空间中，相关的标记在物理上是聚集在一起的。
- en: Why embeddings are useful
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么嵌入是有用的
- en: Embedding vectors are particularly useful because it’s possible to compare them
    or extract information from them very easily, just by performing simple, linear
    calculations. Suppose you want to compare the meaning of two tokens. You can do
    that by calculating their physical distance in the imaginary embedding space.
    One popular way of doing that is calculating the *dot product* between the two
    vectors, which produces a sort of “signed distance” between them. If the result
    is positive, the tokens are close enough in the embedding space and thus their
    meanings are related. If it’s zero, they are unrelated. If it’s negative, their
    meanings are opposed, such as in “large” and “small.”
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入向量特别有用，因为我们可以通过进行简单的线性计算来轻松比较它们或从中提取信息。假设你想比较两个标记的意义。你可以通过计算它们在假想嵌入空间中的物理距离来实现这一点。一种流行的方法是计算两个向量之间的*点积*，这产生了一种“有符号距离”。如果结果是正的，那么在嵌入空间中这两个标记足够接近，因此它们的意义是相关的。如果是零，它们是不相关的。如果是负的，它们的意义是相反的，例如在“大”和“小”中。
- en: NOTE The dot product is calculated by multiplying the numbers in one vector
    by their corresponding numbers in the other vector (at the same position) and
    then adding the results.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：点积是通过将一个向量中的数字与另一个向量中相应位置的数字相乘，然后将结果相加来计算的。
- en: Now, suppose you want to extract a limited amount of information of interest
    from a much more expressive embedding vector. For example, you may want to extract
    animal-related topics and dump everything else. We can think of this as squashing
    the multidimensional embedding space into a lower-dimensional space, such as flattening
    the 3D space to turn it into a thin plate, thus discarding uninformative dimensions.
    We could imagine, for instance, squashing the entire 12,288-dimensional space
    into, say, a 100-dimentional space that only focuses on animal-related topics
    (e.g., “Barks,” “Mammal,” “Pet”). The mathematical operation to perform such a
    squashing is known as a *projection.*
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设你想要从一个表达性更强的嵌入向量中提取有限的有用信息。例如，你可能想要提取与动物相关的主题，并丢弃其他所有内容。我们可以将这视为将多维嵌入空间压缩到低维空间，例如将3D空间压扁成薄板，从而丢弃无信息维度。例如，我们可以将整个12,288维度的空间压缩到，比如说，一个只关注动物相关主题的100维空间（例如，“吠叫”，“哺乳动物”，“宠物”）。执行这种压缩的数学运算被称为*投影*。
- en: '*A projection is performed by multiplying a matrix by the embedding vector.
    The matrix represents the direction in which we want to squeeze the embedding
    space. Note that, as we don’t usually understand how embeddings encode meaning,
    we don’t understand how meaning is represented in the squeezed embedding space.
    Just like with the embeddings, the projections into squeezed spaces are also determined
    through machine learning and not designed by hand.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '*投影是通过将矩阵乘以嵌入向量来执行的。矩阵表示我们想要挤压嵌入空间的方向。请注意，由于我们通常不了解嵌入如何编码意义，因此我们也不了解意义如何在挤压的嵌入空间中表示。就像嵌入一样，挤压空间的投影也是通过机器学习确定的，而不是手工设计的。'
- en: In addition to their use within LLMs and other types of AI, it has become popular
    for engineers to use third-party tools to generate embeddings for all sorts of
    content-retrieval applications. For example, you can use an embeddings API to
    generate embeddings that represent the meaning of text documents, and then you
    compare documents by calculating the dot product of their embeddings. Specifically,
    OpenAI provides an embeddings API that helps generate an embedding for a text
    document.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在大型语言模型和其他类型的AI中使用外，工程师使用第三方工具为各种内容检索应用生成嵌入已成为一种流行趋势。例如，你可以使用嵌入API生成代表文本文档意义的嵌入，然后通过计算嵌入的点积来比较文档。具体来说，OpenAI提供了一个嵌入API，帮助生成文本文档的嵌入。
- en: In addition, some APIs generate embeddings for different input modalities, such
    as text and images. One example is Google Clouds’ embeddings API (see [https://mng.bz/1Xvq](https://mng.bz/1Xvq)).
    The generated embeddings can be directly compared. For example, a piece of text
    speaking about cats and a picture of a cat are mapped to closely related embedding
    vectors. Thus, you can use dot products to find the image that best matches a
    description.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，一些API为不同的输入模式生成嵌入，例如文本和图像。一个例子是Google Clouds的嵌入API（见[https://mng.bz/1Xvq](https://mng.bz/1Xvq)）。生成的嵌入可以直接比较。例如，一篇关于猫的文本和一张猫的图片被映射到紧密相关的嵌入向量。因此，你可以使用点积来找到与描述最匹配的图像。
- en: Why LLMs struggle to analyze individual letters
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么大型语言模型在分析单个字母时遇到困难
- en: LLMs are notorious for struggling to correctly analyze the individual letters
    in words, such as counting the number of occurrences of a letter. They also struggle
    to follow instructions that require generating text with certain letters in it.
    Figure 1.8 shows an example of this problem using GPT-4o.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型在正确分析单词中的单个字母方面臭名昭著，例如计算字母出现的次数。它们也难以遵循需要生成包含特定字母的文本的指令。图1.8展示了使用GPT-4o的这个问题的一个例子。
- en: '![](../Images/CH01_F06_Maggiori.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH01_F06_Maggiori.png)'
- en: Figure 1.8  LLMs often struggle to analyze individual letters in words.
  id: totrans-151
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.8  大型语言模型在分析单词中的单个字母时经常遇到困难。
- en: If you remember, LLMs receive tokens as inputs, not letters. So, the exact letters
    of a word are not inputted to the model. In the example of figure 1.8, the token
    “berry” is inputted to the LLM in one go.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你记得，大型语言模型接收的是标记作为输入，而不是字母。因此，单词的确切字母并没有输入到模型中。在图1.8的例子中，标记“berry”一次性输入到大型语言模型中。
- en: Each token is then mapped to an embedding vector to represent its meaning. So,
    any references to individual letters are likely to be completely lost at this
    stage, as it’d be wasteful to devote space in the embedding vector to represent
    topics such as “token with two times the letter a,” when there are much more useful
    topics to represent instead.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，每个标记被映射到一个嵌入向量以表示其意义。因此，任何关于单个字母的引用在这个阶段很可能会完全丢失，因为当有更多有用的主题需要表示时，在嵌入向量中为“包含两倍字母a的标记”等主题分配空间将是浪费的。
- en: As people have been widely mocking LLMs’ terrible performance at analyzing letters,
    it’s likely AI engineers will take ad hoc measures to directly address this problem.
    For example, the LLM wrapper may augment the prompt with words’ spellings if it
    detects that there are questions about individual letters. Maybe some of this
    has already been done, as newer LLMs seem to struggle less to analyze individual
    letters. However, the problem persists in even the most recent LLMs as of this
    writing, so it hasn’t been fully solved yet.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 由于人们广泛地嘲笑LLMs在分析字母方面的糟糕表现，AI工程师可能会采取临时措施来直接解决这个问题。例如，如果LLM包装器检测到有关单个字母的问题，它可能会在提示中添加单词的拼写。也许其中一些已经完成了，因为较新的LLMs似乎在分析单个字母方面遇到的困难较少。然而，这个问题在写作时甚至在最新的LLMs中仍然存在，所以它还没有得到完全解决。
- en: The transformer architecture
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 变压器架构
- en: The methodology that powers current LLMs was invented by a group of Google researchers.
    It was described in a famous paper, published in 2017, titled “Attention Is All
    You Need” (available at [https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)).
    The paper proposed a new way of designing language models, which became known
    as the *transformer architecture* or just *transformers.*
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 当前LLMs所采用的推动方法是谷歌研究人员发明的一组方法。它被描述在一篇著名的论文中，该论文于2017年发表，标题为“Attention Is All
    You Need”（可在[https://arxiv.org/abs/1706.03762](https://arxiv.org/abs/1706.03762)找到）。该论文提出了一种设计语言模型的新方法，这被称为*变压器架构*或简称*transformers*。
- en: If you remember, when I asked an LLM to complete the sentence “the dog’s bark
    was barely,” it correctly outputted “audible.” Despite its apparent simplicity,
    this sentence is challenging because the word “bark” has two distinct meanings—the
    noise made by a dog and the coating of a tree. If I asked an LLM to continue the
    sentence “the tree’s bark was barely,” then “audible” would be a poor choice.
    I tried it, and the LLM outputted “visible” instead of “audible.” The LLM managed
    to correctly disambiguate the word “bark” based on whether “dog” or “tree” appeared
    earlier in the sentence. The transformer architecture was especially designed
    to effectively disambiguate tokens based on their context.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还记得，当我要求一个LLM完成句子“狗的叫声几乎”时，它正确地输出了“audible”。尽管这个句子看起来很简单，但它很有挑战性，因为单词“bark”有两个不同的含义——狗发出的噪音和树的树皮。如果我要求LLM继续句子“树的树皮几乎”，那么“audible”将是一个糟糕的选择。我试了试，LLM输出了“visible”而不是“audible”。LLM设法根据句子中是否出现了“dog”或“tree”来正确地消除“bark”一词的多义性。变压器架构特别设计用来根据上下文有效地消除标记的多义性。
- en: 'Before the transformer architecture, the most popular language models were
    based on a type of AI model known as LSTM (long short-term memory). LSTMs try
    to predict the next token based on the following two things:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在变压器架构出现之前，最受欢迎的语言模型是基于一种称为LSTM（长短期记忆）的AI模型。LSTM试图根据以下两点预测下一个标记：
- en: The last token in the input prompt (“barely” if the input is “the dog’s bark
    was barely”)
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入提示中的最后一个标记（如果输入是“狗的叫声几乎”，则是“barely”）
- en: A single embedding that summarizes the meaning of all the previous tokens (a
    single embedding vector that represents “the dog’s bark was”)
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个总结所有先前标记意义的单一嵌入（一个代表“狗的叫声是”的单个嵌入向量）
- en: These two pieces of information are used to predict the next token (“audible”
    in this case). As the entire context before the last token is squashed into a
    single, fixed-sized embedding vector, LSTMs can process inputs of varying lengths
    without any complications. This is one of the reasons they became so popular.
    But this is also LSTMs’ Achilles’ heel—by squashing such a large context into
    a single vector, they often lose important, fine-grained contextual information
    necessary to properly guess the next word.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这两块信息被用来预测下一个标记（在这个例子中是“可听见的”）。由于最后一个标记之前的整个上下文都被压缩成一个单一、固定大小的嵌入向量，LSTM可以处理不同长度的输入而不会出现任何复杂情况。这也是它们变得如此受欢迎的原因之一。但这也是LSTM的阿喀琉斯之踵——通过将如此大的上下文压缩成一个单一向量，它们往往失去了正确猜测下一个单词所必需的、重要的、细粒度的上下文信息。
- en: The transformer architecture solved this problem by processing the previous
    tokens in a different way, without squashing them all. The process, which follows
    three steps, is depicted in figure 1.9\.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 变换器架构通过以不同的方式处理之前的标记，而不是将它们全部压缩，从而解决了这个问题。这个过程分为三个步骤，如图1.9所示。
- en: '![](../Images/CH01_F07_Maggiori.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH01_F07_Maggiori.png)'
- en: Figure 1.9  LLM overview. In step 1, the tokens are mapped to embeddings one
    by one. In step 2, each embedding is improved by contextualizing it using the
    previous tokens in the prompt. In step 3,
  id: totrans-164
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.9  LLM概述。在步骤1中，标记逐个映射到嵌入。在步骤2中，通过使用提示符中的先前标记对每个嵌入进行上下文化来改进每个嵌入。在步骤3，
- en: the much-improved embeddings are used to make predictions about
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 使用大幅改进的嵌入来预测下一个标记。
- en: the next token.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 下一个标记。
- en: First, the model maps each token in the input prompt to an embedding vector
    that seeks to represent its meaning. This is performed on each token separately,
    so no contextual information is used—each token is processed as if the other ones
    didn’t exist. While these embeddings can be okay sometimes, they can’t be too
    good because in many cases, it’s hard to know the true meaning of a token without
    looking at the context. For example, the embedding generated for a token such
    as “bark” will be poor because the model can’t know if it refers to dogs or trees.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，模型将输入提示符中的每个标记映射到一个嵌入向量，该向量试图表示其含义。这是对每个标记单独执行的，因此不使用任何上下文信息——每个标记被处理得好像其他标记不存在一样。虽然这些嵌入有时可以接受，但它们不能太好，因为在许多情况下，不查看上下文很难知道一个标记的真正含义。例如，为“bark”这样的标记生成的嵌入将很差，因为模型无法知道它是指狗还是树。
- en: In the second step, the LLM improves the embedding of each individual token
    by analyzing its previous tokens—each token is *transformed* by taking its context
    into account. Note that, compared to LSTMs, the transformer architecture does
    not squash embeddings together to summarize the entire prompt.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二步中，LLM通过分析其先前标记来改进每个单独标记的嵌入——每个标记通过考虑其上下文而被*转换*。请注意，与LSTM相比，变换器架构不会将嵌入压缩在一起来总结整个提示符。
- en: The LLM uses a fixed number of previous tokens to contextualize each token,
    which is known as the *context window.* For example, suppose an LLM has a context
    window of 10,000 tokens. Each token is contextualized by analyzing its previous
    9,999 tokens. If the user’s prompt is shorter than 10,000 tokens, then the beginning
    of the prompt is padded with dummy values like zeros until it reaches 10,000 tokens.
    If the user’s prompt is longer than 10,000 tokens, then the LLM wrapper rejects
    the user request or drops the beginning of the prompt.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 长短期记忆网络（LLM）使用固定数量的先前标记来对每个标记进行上下文化，这被称为*上下文窗口*。例如，假设一个LLM的上下文窗口为10,000个标记。每个标记通过分析其前9,999个标记来进行上下文化。如果用户的提示符少于10,000个标记，那么提示符的开头将用零等虚拟值填充，直到达到10,000个标记。如果用户的提示符超过10,000个标记，那么LLM包装器将拒绝用户请求或丢弃提示符的开头。
- en: You need to carefully consider the context window before using an LLM. If you
    want to, say, ask an LLM to summarize an entire novel, you need to make sure that
    it fits within the context window, or the LLM won’t be able to summarize the entire
    novel at once. In addition, if you use a RAG approach to insert the content of
    relevant documents into a user’s prompt, you also need to make sure the context
    window can fit them all. Moreover, when you chat back and forth with an LLM-based
    app, the entire history of the conversation is usually included in each prompt,
    making the prompt longer as you converse with the chatbot.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用LLM之前，您需要仔细考虑上下文窗口。如果您想，比如说，让LLM总结一整本小说，您需要确保它适合上下文窗口，否则LLM将无法一次性总结整个小说。此外，如果您使用RAG方法将相关文档的内容插入到用户的提示符中，您也需要确保上下文窗口可以容纳它们。此外，当您与基于LLM的应用程序进行来回聊天时，整个对话历史通常包含在每个提示符中，随着您与聊天机器人的对话，提示符会变得更长。
- en: Earlier LLMs had very limited context windows. For example, GPT-3’s context
    window was 2,048 tokens. Therefore, their capabilities to analyze long inputs
    were limited.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 早期的LLM上下文窗口非常有限。例如，GPT-3的上下文窗口为2,048个标记。因此，它们分析长输入的能力有限。
- en: Over time, the context window has grown. As of this writing, OpenAI’s latest
    model, GPT-4o, has a context window of 128,000 tokens. And one of Google’s models,
    Gemini 1.5 Pro, offers a context window of 1 million tokens to its enterprise
    customers. The size of the context window is specified in an LLM’s official documentation.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，上下文窗口已经扩大。截至本文撰写时，OpenAI的最新模型GPT-4o拥有128,000个标记的上下文窗口。而谷歌的一个模型Gemini
    1.5 Pro向其企业客户提供1百万个标记的上下文窗口。上下文窗口的大小在LLM的官方文档中指定。
- en: After the end of this contextualization step, the embeddings associated with
    each input token are much more accurate and thus useful than the initial ones,
    thanks to contextualization. For example, we could imagine that the embedding
    for “bark” becomes more animal-like at the end of step 2 if the word “dog” appears
    before. Conversely, its embedding would become more tree-like if the context contains
    tree references.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在上下文化步骤结束后，与每个输入标记相关的嵌入比最初的嵌入更加准确和有用，这要归功于上下文化。例如，如果我们假设在“dog”（狗）这个词出现之前，“bark”（吠声）的嵌入在第二步结束时变得更加动物化。相反，如果上下文中包含树的相关内容，其嵌入就会变得更加树状。
- en: The third step in the transformer architecture (see figure 1.9) is to predict
    the next token based on the enhanced, contextualized embeddings generated in step
    2\. This is performed through a very simple mathematical operation because it
    is assumed that step 2 produced really good embeddings that can help guess the
    next word very easily.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 变换器架构中的第三步（见图1.9）是根据第二步生成的增强、上下文化的嵌入来预测下一个标记。这是因为假设第二步产生了非常好的嵌入，可以很容易地猜测下一个单词，所以这个过程通过一个非常简单的数学运算来完成。
- en: In the next few sections, we describe each of the three steps in more detail,
    and we explain how machine learning enters the picture.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几节中，我们将更详细地描述这三个步骤中的每一个，并解释机器学习是如何进入画面的。
- en: 'Step 1: Initial embeddings'
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第一步：初始嵌入
- en: 'The initial embeddings are obtained very easily. The LLM contains an internal
    dictionary that maps each possible token to its corresponding embedding. We could
    imagine it as follows:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 初始嵌入很容易获得。LLM包含一个内部字典，将每个可能的标记映射到其相应的嵌入。我们可以想象如下：
- en: '[PRE9]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The initial embeddings are created by looking up each token in the dictionary
    and replacing it with its corresponding embedding. The result is an initial set
    of embeddings, created one by one without context, which concludes step 1 (see
    figure 1.9).
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 初始嵌入是通过在字典中查找每个标记并将其替换为其相应的嵌入来创建的。结果是创建了一个初始嵌入集，这些嵌入一个接一个地创建，没有上下文，这标志着第一步的结束（见图1.9）。
- en: 'The numbers inside the dictionary are not defined by hand. These numbers are
    all *learnable parameters* of the model. This means that the AI engineer leaves
    them as blanks in the code and lets the computer fill in their values later, when
    the learning algorithm runs. We can think of the previous dictionary as follows
    from the point of view of the AI engineer:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 字典中的数字不是手工定义的。这些数字都是模型的*可学习参数*。这意味着AI工程师在代码中将它们留为空白，并在学习算法运行时让计算机填充它们的值。我们可以从AI工程师的角度这样想象之前的字典：
- en: '[PRE10]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: When the computer fills in the blanks, which is known as *learning* or *training,*
    it designs its own embedding space. So, the computer is free to organize tokens
    and pick topics as it wishes to attain its goal of effectively guessing the next
    word.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 当计算机填充空白时，这被称为*学习*或*训练*，它会设计自己的嵌入空间。因此，计算机可以自由地组织标记和选择主题，以达到有效猜测下一个单词的目标。
- en: Consider a model whose vocabulary contains 100,000 different tokens and whose
    embeddings contain 10,000 dimensions, as is the case with many LLMs. The dictionary
    would contain 100,000 entries, and each entry would contain 10,000 numbers, which
    are question marks. The total number of learnable parameters (the question marks)
    would be 100,000 × 10,000 = 1 billion. That’s a lot of learnable parameters! And
    it’s just the beginning.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个词汇量包含100,000个不同标记且嵌入包含10,000维度的模型，这在许多LLM中很常见。字典将包含100,000个条目，每个条目将包含10,000个数字，这些数字是问号。可学习的参数总数（问号）将是100,000
    × 10,000 = 10亿。这有很多可学习的参数！而且这只是开始。
- en: 'Step 2: Contextualization'
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第二步：上下文化
- en: In the second step, the LLM contextualizes each of the input tokens, one by
    one, by considering its previous tokens (within the context window). Let’s see,
    for example, how the LLM would contextualize the token “bark” in “dog’s bark”.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二步中，LLM（大型语言模型）通过考虑其前一个标记（在上下文窗口内）逐个将每个输入标记进行上下文化。让我们看看，例如，LLM会如何将“bark”（狗吠）这个标记在“dog’s
    bark”（狗的吠声）中进行上下文化。
- en: Contextualization starts by calculating an attention score for each token in
    the context. The attention score indicates how it’s best to divide attention among
    all the tokens in the context window to disambiguate the last one. For example,
    to contextualize “bark”, it’s worth focusing most of your attention on “dog,”
    followed by “bark” itself, and finally by “’s”. Figure 1.10 represents this operation.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文化首先为上下文中的每个标记计算一个注意力分数。注意力分数表明如何最好地在上下文窗口中的所有标记之间分配注意力，以消除最后一个标记的歧义。例如，为了上下文化“bark”，值得将大部分注意力集中在“dog”上，然后是“bark”本身，最后是“’s”。图1.10展示了这一操作。
- en: The calculation of attention scores, known as the *attention mechanism,* is
    performed through a series of mathematical operations, such as projections on
    the embedding vectors (see section 1.3.3). We won’t cover the details here, so
    let’s just say that these operations are specially designed to let the LLM extract
    meaning from the embeddings and compare them.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力分数的计算，称为*注意力机制*，是通过一系列数学运算来完成的，例如在嵌入向量上的投影（参见1.3.3节）。这里我们不涉及细节，所以我们就说这些操作是专门设计来让LLM从嵌入中提取意义并比较它们的。
- en: '![](../Images/CH01_F08_Maggiori.png)'
  id: totrans-188
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH01_F08_Maggiori.png)'
- en: Figure 1.10  The attention mechanism calculates the relative relevance of all
    tokens in the context window to contextualize or disambiguate the last token.
  id: totrans-189
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.10  注意力机制计算上下文窗口中所有标记的相对相关性，以上下文化或消除最后一个标记的歧义。
- en: The AI engineer determines the type of number of operations but leaves blanks
    that are determined later using machine learning. For example, the numbers inside
    projection matrixes, which configure what projections do, are left as blanks.
    Thus, we can picture a projection matrix as
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: AI工程师确定操作的类型和数量，但留下空白，这些空白将使用机器学习后来确定。例如，配置投影做什么的投影矩阵中的数字被留作空白。因此，我们可以将投影矩阵想象成
- en: '[[ ? ? ? ... ?],'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '[[ ? ? ? ... ?],'
- en: '[ ? ? ? ... ?],'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[ ? ? ? ... ?],'
- en: '...'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '...'
- en: '[ ? ? ? ... ?]]'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '[ ? ? ? ... ?]]'
- en: So, the AI engineer tells the computer how to disambiguate tokens—by using projections
    to compare embeddings, and so on—but lets the machine fill in the details. The
    machine discovers by itself useful ways of analyzing the embeddings to disambiguate
    problematic tokens like “bark”. Projection matrices are rather large, so this
    step can easily add a few hundred million, if not billions of learnable parameters
    to the model.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，AI工程师告诉计算机如何消除标记的歧义——通过使用投影来比较嵌入，等等——但让机器填写细节。机器会自己发现分析嵌入以消除像“bark”这样的问题标记的有用方式。投影矩阵相当大，所以这一步可以轻松地为模型增加数亿个可学习的参数。
- en: Once the LLM has calculated attention scores, it uses the resulting values to
    guide the contextualization of tokens’ embedding vectors. We can think of this
    step as letting information from tokens rub off onto other tokens using the attention
    score for guidance.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦LLM计算了注意力分数，它就会使用这些结果值来引导标记嵌入向量的上下文化。我们可以将这一步骤想象成利用注意力分数的引导，让标记的信息相互影响。
- en: For example, a lot of information from “dog” rubs off on “bark”, as its attention
    mechanism determined that the token “dog” was relevant to the meaning of “bark”.
    As a consequence of this step, the embedding for “bark” becomes more animal-like,
    as opposed to tree-like. Conversely, very little information from “’s” rubs off
    on “bark”, as the attention score deems it rather irrelevant. The process of updating
    the embeddings based on the context is known as the *feed-forward* step of the
    transformer.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，很多来自“狗”的信息会影响到“bark”，因为其注意力机制确定“dog”标记与“bark”的意义相关。因此，这一步骤的结果是，“bark”的嵌入变得更加动物化，而不是树状。相反，来自“’s”的信息对“bark”的影响非常小，因为注意力分数认为它相当不相关。根据上下文更新嵌入的过程被称为transformer的*前馈*步骤。
- en: In the previous example, the end result of the attention and feed-forward mechanisms
    is an improved version of the embedding for “bark”. The same process is applied
    to contextualize all the tokens in input the prompt, using their previous ones,
    which leads to a new generation of improved embeddings, as illustrated in step
    2 of figure 1.9.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的例子中，注意力和前馈机制的最后结果是“bark”嵌入的改进版本。相同的流程被应用于上下文化输入提示中的所有标记，使用它们之前的标记，这导致了一代新的改进嵌入，如图1.9步骤2所示。
- en: At the end of this process, the LLM is in a much better position to make a guess
    about the next token, as it contains an improved, contextualized representation
    of the meaning of the entire input prompt.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个过程结束时，LLM在猜测下一个标记方面处于更好的位置，因为它包含了一个改进的、上下文化的整个输入提示的意义表示。
- en: Multilayer architecture
  id: totrans-200
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 多层架构
- en: The contextualization step we just described (step 2) is usually applied multiple
    times. So, the embedding vectors are improved many times. This is known as a *multilayer*
    transformer. Most LLMs contain at least a few tens of layers of transformers applied
    in sequence. Each transformer layer has its own set of learnable parameters, so
    each layer can specialize in different contextualization tasks.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚才描述的上下文化步骤（步骤2）通常需要应用多次。因此，嵌入向量被多次改进。这被称为*多层*转换器。大多数大型语言模型（LLM）至少包含几十层按顺序应用的转换器。每个转换器层都有自己的可学习参数集，因此每个层可以专门处理不同的上下文化任务。
- en: GPT-3, for example, has 96 transformer layers. This leads to a whopping total
    of 175 billion learnable parameters inside the model.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，GPT-3有96个转换器层。这导致模型内部有高达1750亿个可学习参数。
- en: Multiheaded attention
  id: totrans-203
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 多头注意力
- en: The attention mechanism is often subdivided into different heads, meaning that
    it analyzes different parts of the embedding vectors separately, one chunk at
    a time. This forces the LLM to design embedding vectors with highly specialized
    segments. For example, we could imagine that one segment is dedicated to all things
    animal related and another one to all things tree related, although we still can’t
    usually understand the embedding vectors. This has been observed to work better
    in practice than having a single head that processes the entire embedding vector
    at once.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力机制通常被细分为不同的头，这意味着它分别单独分析嵌入向量的不同部分。这迫使LLM设计具有高度专业化的嵌入向量段。例如，我们可以想象一个段是专门用于所有与动物相关的事物，另一个段是专门用于所有与树木相关的事物，尽管我们仍然通常无法理解嵌入向量。实践观察表明，这种方法比使用一个一次性处理整个嵌入向量的单一头效果更好。
- en: 'Step 3: Predictions'
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤3：预测
- en: The last step, step 3 in figure 1.9, is to make a prediction about the most
    likely next token, which is the LLM’s ultimate job. This is performed through
    projections over the contextualized embeddings generated in step 2.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步，图1.9中的步骤3，是对最可能的下一个标记进行预测，这是LLM的最终任务。这是通过在步骤2生成的上下文化嵌入上进行投影来完成的。
- en: While we’ve been saying that LLMs predict the most likely next token, that’s
    not quite accurate. In reality, they calculate a probability value for each possible
    token in the vocabulary. So, the LLM’s output is a vector with as many numbers
    as tokens in the vocabulary. Each position refers to one possible token, as shown
    in table 1.1\. In this example, the token “audible” receives a high probability
    of 0.8, meaning that the LLM deems it a highly likely next token.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们一直在说LLM预测最可能的下一个标记，但这并不完全准确。实际上，它们为词汇表中的每个可能的标记计算一个概率值。因此，LLM的输出是一个向量，其数字数量与词汇表中的标记数量相同。每个位置都指代一个可能的标记，如表1.1所示。在这个例子中，标记“audible”获得了一个高概率值0.8，这意味着LLM认为它是一个高度可能的下一个标记。
- en: Table 1.1  In the last step, the LLM assigns a probability value
  id: totrans-208
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表1.1 在最后一步，LLM为词汇表中的每个可能的标记分配一个概率值
- en: for each possible token in the vocabulary. All the values add to 1.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 对于词汇表中的每个可能的标记。所有值加起来等于1。
- en: '| 0.01 | 0.0 | 0.05 | … | 0.8 | … |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| 0.01 | 0.0 | 0.05 | … | 0.8 | … |'
- en: '| “a” | “b” | “c” |  | “audible” |  |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| “a” | “b” | “c” |  | “audible” |  |'
- en: The LLM wrapper picks the next token based on the LLM’s output probabilities.
    One way to do this is to pick the token with the highest probability according
    to the LLM (in the unlikely event that two tokens have the exact same probability,
    either one can be picked at random). However, there are other ways to do this,
    which lets the LLM get more adventurous. We will discuss this next.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: LLM包装器根据LLM的输出概率选择下一个标记。一种方法是选择LLM中概率最高的标记（在两个标记具有完全相同的概率的极不可能事件中，可以随机选择任何一个）。然而，还有其他方法可以做到这一点，这使LLM能够更加大胆。我们将在下一节讨论这个问题。
- en: Temperature
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 温度
- en: As discussed in the previous section, LLMs output a probability for each token
    that describes how likely it is to come right after the input prompt. One way
    to select the next token from the vocabulary is to pick the one with the highest
    probability according to the LLM. However, this encourages the LLM to play it
    a bit too safe—sometimes we want a more adventurous output. So, instead, the next
    token is often selected by randomly *sampling* a token from the vocabulary using
    the LLM’s output probabilities. For example, if the LLM outputs a probability
    of 0.9 for the “audible” token, then the sampler picks that token with 90% probability
    and other ones with 10% probability.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 如前文所述，LLMs为每个标记输出一个概率，描述该标记紧随输入提示出现的可能性。从词汇表中选择下一个标记的一种方法是根据LLM输出的概率选择概率最高的标记。然而，这会鼓励LLM过于保守——有时我们希望得到更具冒险性的输出。因此，通常通过使用LLM的输出概率随机从词汇表中采样一个标记来选择下一个标记。例如，如果LLM为“audible”标记输出概率为0.9，那么采样器以90%的概率选择该标记，其他标记以10%的概率选择。
- en: The user can usually regulate how adventurous the output should be by adjusting
    a setting known as the *temperature.* This setting squeezes or smooths out the
    LLM’s output probabilities. A low temperature pushes the highest sampling probabilities
    upward and lowers the others. For example, a probability of 0.9 may be transformed
    into 0.95, while a probability of 0.05 may be transformed into 0.01\. This makes
    it more likely for the LLM wrapper to pick tokens at the top of the ranking. We
    can think of this as making the LLM wrapper more conservative, as it becomes more
    prone to select the most obvious tokens at the top of the ranking and less prone
    to pick alternative ones.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 用户通常可以通过调整称为*温度*的设置来调节输出的冒险程度。此设置挤压或平滑LLM的输出概率。低温度将最高的采样概率推向上方并降低其他概率。例如，0.9的概率可能被转换为0.95，而0.05的概率可能被转换为0.01。这使得LLM包装器更有可能选择排名靠前的标记。我们可以将其视为使LLM包装器更加保守，因为它更倾向于选择排名靠前的明显标记，而不太可能选择替代标记。
- en: Conversely, a high temperature smooths out probabilities. For example, a probability
    of 0.9 may be transformed to 0.8, and a probability of 0.01 may be transformed
    to 0.05\. This makes the output more creative by making lower-ranked tokens more
    likely to be picked. Each LLM wrapper offers its own range of temperature values.
    OpenAI’s API, for example, allows users to set the temperature to a value between
    zero (conservative) and two (creative).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，高温度会平滑概率。例如，0.9的概率可能被转换为0.8，而0.01的概率可能被转换为0.05。这使得输出更具创造性，因为低排名的标记更有可能被选中。每个LLM包装器都提供自己的一组温度值。例如，OpenAI的API允许用户将温度设置为介于零（保守）和二（创意）之间的值。
- en: In the following paragraphs, we describe two alternative ways of setting how
    adventurous we want our output to be.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下段落中，我们描述了两种设置我们希望输出有多冒险的替代方法。
- en: Top-p
  id: totrans-218
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Top-p
- en: An alternative setting known as *Top-p* is a cutoff level of cumulative probability.
    If we set Top-p to, say, 0.8, then we only sample from the top tokens that cover
    80% of the probability. The tokens covering the bottom 20% of probability are
    ignored.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个称为*Top-p*的设置是对可以采样的最高标记数量的限制。例如，如果我们设置Top-p为0.8，那么我们只从覆盖80%概率的顶部标记中进行采样。覆盖概率最低的20%的标记将被忽略。
- en: Top k
  id: totrans-220
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Top k
- en: The *Top-k* setting imposes a limit on the number of top tokens we can sample
    from. For example, if we set Top-k to 20, the LLM wrapper is only allowed to pick
    a token among the top-20 tokens. If we set Top-k to 1, we force the LLM to pick
    the top token every time.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '*Top-k*设置对可以从其采样的最高标记数量施加限制。例如，如果我们设置Top-k为20，LLM包装器就只能从顶部20个标记中选择一个标记。如果我们设置Top-k为1，我们迫使LLM每次都选择顶部标记。'
- en: Note that not all LLM wrappers let users configure all these settings—sometimes
    only one or two of them are available. For example, as of today, OpenAI lets users
    set temperature and Top-p but not Top-k. The available settings are described
    in the documentation.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，并非所有LLM包装器都允许用户配置所有这些设置——有时只有一两个可用。例如，截至今天，OpenAI允许用户设置温度和Top-p，但不允许设置Top-k。可用的设置在文档中描述。
- en: Can you get an LLM to always output the same thing?
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你能让LLM始终输出相同的内容吗？
- en: It is sometimes desirable to generate *reproducible* outputs with an LLM, meaning
    that the LLM generates the exact same output every time it’s given the same input
    prompt. This can be useful to benchmark the performance of LLMs or share examples
    of LLMs’ outputs that others can replicate.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 有时使用LLM生成可复制的输出是有需求的，这意味着LLM每次接收到相同的输入提示时都会生成完全相同的输出。这可以用来评估LLM的性能或分享其他人可以复制的LLM输出示例。
- en: It is theoretically possible to have an LLM generate reproducible outputs. For
    example, this could be achieved by using a top-1 sampling strategy, in which we
    always pick the token with the highest probability, thus making sure that all
    mathematical calculations inside the LLM are performed exactly the same way on
    different runs.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上，可以让LLM生成可复制的输出。例如，这可以通过使用top-1采样策略来实现，其中我们总是选择概率最高的标记，从而确保LLM内部的所有数学计算在不同的运行中都以完全相同的方式进行。
- en: However, while this is theoretically possible, it is not always the case in
    practice. As of today, for example, it’s not possible to guarantee that OpenAI’s
    LLMs will generate the exact same output on different runs. There is official
    guidance on how to configure settings to produce mostly reproducible outputs,
    but they’re not guaranteed to be exactly alike (see [https://mng.bz/PdeR](https://mng.bz/PdeR)).
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，虽然这在理论上是有可能的，但在实践中并不总是如此。例如，截至目前，我们无法保证OpenAI的LLM在不同的运行中会生成完全相同的输出。有官方指南说明如何配置设置以产生大部分可复制的输出，但它们并不能保证完全相同（见[https://mng.bz/PdeR](https://mng.bz/PdeR)）。
- en: This probably happens because popular AI and arithmetic libraries divide a calculation
    into multiple threads which can be executed in different orders every time (see
    [https://news.ycombinator.com/item?id=37006224](https://news.ycombinator.com/item?id=37006224)).
    This can cause slight differences in outputs due to round-off errors when adding
    the same numbers in different orders (see [https://mng.bz/JYQZ](https://mng.bz/JYQZ)).
    In the future, if these problems are fixed, it will be possible to generate reproducible
    outputs with popular LLM APIs.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是因为流行的AI和算术库将计算分解成多个线程，每次可以以不同的顺序执行（见[https://news.ycombinator.com/item?id=37006224](https://news.ycombinator.com/item?id=37006224)）。这可能导致由于加法顺序不同而产生的舍入误差，从而在输出中产生细微的差异（见[https://mng.bz/JYQZ](https://mng.bz/JYQZ)）。在未来，如果这些问题得到解决，将有可能使用流行的LLM
    API生成可复制的输出。
- en: Where to learn more
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更多学习资源
- en: In this section, we’ve covered the gist of how LLMs work. We haven’t discussed
    the implementation details, such as the exact calculations performed inside the
    LLM, but we did discuss the overall process LLMs follow to make their predictions.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了LLM工作原理的要点。我们没有讨论实现细节，例如LLM内部的确切计算，但我们确实讨论了LLM遵循的整体预测过程。
- en: If you want to know the details, I recommend you to directly have a look at
    the publicly available source code of GPT-2 ([https://mng.bz/wJR5](https://mng.bz/wJR5)).
    The file called models.py is the most important one; it defines the entire model
    in a very compact way (just 174 lines). The code is moderately easy to follow
    if you understand some Python coding and the TensorFlow library and start from
    the bottom of the file. I also recommend you read a guide called *The Illustrated
    Transformer* ([https://mng.bz/qxlx](https://mng.bz/qxlx)) to learn the details
    of the architecture.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解详细信息，我建议你直接查看GPT-2的公开源代码（[https://mng.bz/wJR5](https://mng.bz/wJR5)）。名为models.py的文件是最重要的一个；它以非常紧凑的方式定义了整个模型（仅174行）。如果你理解一些Python编程和TensorFlow库，并从文件底部开始阅读，代码相对容易理解。我还推荐你阅读一份名为《图解Transformer》的指南（[https://mng.bz/qxlx](https://mng.bz/qxlx)），以了解架构的细节。
- en: Even if you don’t want to go through all the code, a quick skim through it reveals
    that the LLM is genuinely just a sequence of simple mathematical operations. As
    you can see in the code, each layer (called a “block”) first calculates the attention
    scores (“attn”) and then uses them to update the embeddings (“mlp”). Projections
    (“matmul”) are among the most common operations performed by the model.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你不想阅读所有代码，快速浏览一下也能发现，LLM实际上只是一系列简单的数学运算。正如你在代码中所见，每一层（称为“块”）首先计算注意力分数（“attn”），然后使用它们来更新嵌入（“mlp”）。投影（“matmul”）是模型执行的最常见操作之一。
- en: We’ve now covered how LLMs generate their predictions and mentioned that their
    details are filled in using machine learning. We haven’t, however, described how
    learning unfolds. That’s where we move next.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经介绍了 LLMs 如何生成它们的预测，并提到它们的细节是通过机器学习来填充的。然而，我们还没有描述学习是如何展开的。这就是我们接下来要讨论的内容。
- en: Machine learning
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习
- en: In traditional software development, the engineer writes every single line of
    code to tell the computer exactly what to do. Machine learning, or ML, is a different
    way of creating programs (these programs are known as *models* in ML jargon).
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统的软件开发中，工程师编写每一行代码来告诉计算机确切要做什么。机器学习（或 ML）是创建程序（在机器学习术语中，这些程序被称为**模型**）的另一种方式。
- en: 'The ML approach comprises two steps. The first step is designing the *architecture*
    of the solution, which in ML means a template of the steps the program will follow
    to accomplish the task. Have a look at a piece of Python code using the popular
    ML library PyTorch:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习方法包括两个步骤。第一步是设计解决方案的**架构**，在机器学习中这意味着程序完成任务将遵循的步骤模板。看看下面使用流行的机器学习库 PyTorch
    的 Python 代码片段：
- en: '[PRE11]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In the first line, the engineer defines an embedding operation that maps a vocabulary
    of 100,000 tokens to embedding vectors of length 10,000, similar to what LLMs
    do. In the second line, the engineer defines a projection to transform an embedding
    vector of length 10,000 into one of length 2,000\. The third line applies each
    of those operations sequentially, first the embedding and then the projection.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一行，工程师定义了一个嵌入操作，将 10 万个标记的词汇映射到长度为 10,000 的嵌入向量，这与 LLMs 所做的工作类似。在第二行，工程师定义了一个投影操作，将长度为
    10,000 的嵌入向量转换成长度为 2,000 的向量。第三行按顺序应用这些操作，首先是嵌入，然后是投影。
- en: We can see that the engineer puts together the building blocks of the model
    manually. However, the model has blanks in it, known as *parameters,* which are
    not defined by hand. In the above example, the embedding block contains 1 billion
    parameters (100,000 × 10,000) which are not defined by hand. The second building
    block, the projection, contains over 20 million parameters (I’ll leave the math
    to you).
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到工程师手动组合了模型的构建块。然而，模型中存在空白，称为**参数**，这些参数不是手工定义的。在上面的例子中，嵌入块包含 10 亿个参数（100,000
    × 10,000），这些参数不是手工定义的。第二个构建块，投影，包含超过 2000 万个参数（数学计算留给您）。
- en: Note that the architecture of a machine learning model is designed carefully—the
    building blocks are introduced with a specific intention in mind and in a way
    that is tailor-made to the application. For example, the transformer architecture
    is designed to contextualize words.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，机器学习模型的架构是精心设计的——构建块是以特定的意图引入的，并且是根据应用量身定制的。例如，转换器架构是为了使单词具有上下文。
- en: The following step in the ML approach is known as *training* or *learning.*
    The choice between these two words is down to grammar—you typically say that a
    person trains a model and that the machine learns.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习方法中的下一步被称为**训练**或**学习**。这两个词的选择取决于语法——你通常会说一个人训练一个模型，而机器学习。
- en: During training, the engineer runs an algorithm that tries to find the best
    way of setting the model’s parameters (filling in the blanks in the template)
    to accomplish the desired task. The training algorithm uses data for guidance—usually
    lots of it—to find promising ways of adjusting the parameter values to improve
    the model’s performance.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，工程师运行一个算法，试图找到设置模型参数（填充模板中的空白）的最佳方式以完成所需的任务。训练算法使用数据作为指导——通常是大量数据——以找到调整参数值的可行方法，从而提高模型的表现。
- en: 'The training step is time-consuming and data-hungry, but, if all goes well,
    the resulting model is often seen to perform much better than if we tried to write
    the entire program by hand. This is mainly due to the following reasons:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 训练步骤耗时且需要大量数据，但如果一切顺利，得到的模型通常表现得比我们手动编写整个程序要好得多。这主要归因于以下原因：
- en: The process is data-driven, so we rely on evidence to build the best model instead
    of intuition.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该过程是数据驱动的，因此我们依靠证据来构建最佳模型，而不是直觉。
- en: The model can be millions of times larger than a manually written program.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型可以比手动编写的程序大数百万倍。
- en: The training process can identify serendipitous ways of solving the problem
    that engineers wouldn’t rely on if writing the program manually.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练过程可以识别出工程师在手动编写程序时不会依赖的解决问题的偶然方式。
- en: Throughout this section, we’ll dig a bit deeper into how machine learning works
    and discuss common terminology.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将更深入地探讨机器学习的工作原理，并讨论常见的术语。
- en: Deep learning
  id: totrans-247
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 深度学习
- en: 'In earlier machine learning, the engineer would first write a dedicated piece
    of software to extract representative *features* from the input. For example,
    the engineer would write a dedicated algorithm to extract keywords from text or
    detect lines in an image. Afterward, a small ML model would be used to make predictions
    from these manually engineered features. This process can be summarized as follows:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期的机器学习中，工程师首先会编写专门的软件来从输入中提取代表性的*特征*。例如，工程师会编写专门的算法从文本中提取关键词或在图像中检测线条。之后，会使用一个小型机器学习模型从这些手动工程化的特征中进行预测。这个过程可以总结如下：
- en: Raw input -> Feature engineering -> Model -> Prediction
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 原始输入 -> 特征工程 -> 模型 -> 预测
- en: 'In deep learning, which is a type of machine learning, the model processes
    much rawer inputs, such as tokens or an unprocessed input image:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习中，这是一种机器学习类型，模型处理许多更原始的输入，例如标记或未处理的输入图像：
- en: Raw input -> Model -> Prediction
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 原始输入 -> 模型 -> 预测
- en: 'In deep learning, the model itself learns a useful way to represent the input—it
    performs its own feature engineering. We saw that in action with LLMs: the machine
    works hard to produce contextualized embeddings to represent the meaning of the
    input tokens. To process rawer inputs, the model usually contains multiple layers
    of processing stacked on top of each other, which is where the name “deep” comes
    from.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习中，模型本身学习了一种有用的方式来表示输入——它执行自己的特征工程。我们在LLMs中看到了这一点：机器努力产生上下文化的嵌入来表示输入标记的意义。为了处理更原始的输入，模型通常包含多层处理，这些处理层堆叠在一起，这就是“深度”这个名字的由来。
- en: In many applications within text generation and image analysis, deep learning
    is much more accurate than the previous two-step process with manually engineered
    features. This requires, however, devising an effective architecture for the task,
    such as the transformer architecture.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在文本生成和图像分析等许多应用中，深度学习比之前的手动工程化特征的两步过程更准确。然而，这需要为任务设计一个有效的架构，例如变压器架构。
- en: Note that there’s still a place for old-school, “shallow” learning. Whenever
    your input is already abstract and informative—say, patient records with their
    age, blood type, and so on—then all you need is a shallow ML model on top. In
    addition, deep learning models are too large to understand, so it’s hard to know
    exactly how they produce outputs. We need to trust them based on their high performance.
    But sometimes you want to have an explainable model that you can fully understand.
    In that case, a more explainable model over manually engineered features may be
    the right choice.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，仍然有老式、“浅层”学习的地方。当你的输入已经是抽象且信息丰富的时候——比如说，带有年龄、血型等的患者记录——那么你只需要在顶部添加一个浅层机器学习模型。此外，深度学习模型太大，难以理解，因此很难确切知道它们是如何产生输出的。我们需要基于它们的高性能来信任它们。但有时你想要一个可解释的模型，你可以完全理解。在这种情况下，一个比手动工程化特征更可解释的模型可能是正确的选择。
- en: Types of machine learning
  id: totrans-255
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 机器学习的类型
- en: In this section, we discuss the four most common ML paradigms. These paradigms
    differ in terms of how they formulate the task and process the training data.
    Afterward, we discuss which of these paradigms is used by LLMs.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了四种最常用的机器学习范式。这些范式在如何制定任务和处理训练数据方面有所不同。之后，我们讨论LLMs使用了这些范式中的哪一个。
- en: Supervised learning
  id: totrans-257
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 监督学习
- en: Most ML models learn by example. You supply the computer with a large—or even
    huge—number of examples of how to do the job you want it to do. This is known
    as *supervised learning.* In supervised learning, each example is a pair of an
    input and its corresponding *label,* which is the “true” output we’d like the
    model to learn how to produce.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数机器学习模型通过示例进行学习。你向计算机提供大量——甚至巨大的——如何完成你想要它完成的任务的示例。这被称为*监督学习*。在监督学习中，每个示例都是一个输入及其对应的*标签*，这是我们希望模型学习如何产生的“真实”输出。
- en: In the case of LLMs, training examples are sentences labeled with the “correct”
    next-token guess, such as
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLMs的情况下，训练示例是带有“正确”的下一个标记猜测的句子，例如
- en: “Better safe than” / “sorry”
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: “宁为安全”/“抱歉”
- en: “The Eiffel” / “Tower”
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: “埃菲尔”/“塔”
- en: This way, the LLM is shown examples of how to perform the exact task it is expected
    to perform. All the examples supplied to the machine make up its *training data.*
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，LLM就被展示了如何执行它预期执行的精确任务。提供给机器的所有示例都构成了它的*训练数据*。
- en: '*To cite another example, in the case of a model for automated image categorization,
    the training data contains thousands of sample images, each of them labeled with
    their right category (“strawberry,” “plane,” “dog,” and so on).'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '*以另一个例子来说明，在自动图像分类模型的案例中，训练数据包含数千个样本图像，每个图像都标记了正确的类别（“草莓”、“飞机”、“狗”等等）。'
- en: Gathering labeled data often requires manual work. For example, to create an
    ML model for image categorization, people are often hired to manually label tens
    of thousands of images with their respective categories. Sometimes, there is no
    way to escape this, and data labeling becomes a costly and time-consuming bottleneck.
    In other cases, it’s possible to use tricks to generate labels automatically by
    analyzing existing data, which we will discuss soon.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 收集标记数据通常需要人工操作。例如，为了创建用于图像分类的机器学习模型，人们经常雇佣人员手动将成千上万张图像标记为它们各自的类别。有时，这种情况无法避免，数据标记变成了成本高昂且耗时的瓶颈。在其他情况下，通过分析现有数据，可以使用技巧自动生成标签，我们将在后面讨论这一点。
- en: Ideally, the machine will learn a general process to perform the required task.
    So, it will also work well with inputs not exactly present in the training data,
    such as new sentences or new images. When this happens, the model is said to *generalize.*
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，机器将学习一个通用的过程来完成所需的任务。因此，它也能很好地处理训练数据中不存在的输入，例如新的句子或新的图像。当这种情况发生时，我们说模型具有*泛化能力*。
- en: In some unfortunate cases, the model memorizes specific training examples instead
    of learning a general process to perform the task. So, it doesn’t work well when
    it must do its job on data not seen during training. This is known as *overfitting.*
    In other cases, a model might learn a process that is too simple, so it doesn’t
    work effectively on training data or other data. This is known as *underfitting.*
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在一些不幸的情况下，模型会记住特定的训练示例，而不是学习一个通用的过程来完成任务。因此，当它必须在训练数据之外的数据上工作时，表现不佳。这被称为*过拟合*。在其他情况下，模型可能学习到的过程过于简单，因此在训练数据或其他数据上无法有效工作。这被称为*欠拟合*。
- en: '*#### A note on simulated data'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '*关于模拟数据的笔记'
- en: As of late, people have been asking me why they can’t just run a computer program
    to generate simulated training samples (also known as synthetic data) instead
    of going through the painstaking process of collecting and manually labeling data.
    Imagine you had a program that could generate training examples for an LLM. That
    program would have to be able to correctly guess the next word given a prompt
    to generate examples such as “Better safe than” / “sorry”. But that program would
    already be an LLM. If you had such a program to effectively generate correctly
    labeled training examples, then you wouldn’t need to build an LLM in the first
    place!
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，人们问我为什么他们不能直接运行一个计算机程序来生成模拟的训练样本（也称为合成数据），而不是通过收集和手动标记数据的繁琐过程。想象一下，如果你有一个程序可以生成LLM的训练示例。这个程序必须能够根据提示正确猜测下一个单词，例如“宁为安全死”/“抱歉”。但这个程序本身就是一个LLM。如果你有一个这样的程序可以有效地生成正确标记的训练示例，那么你最初就根本不需要构建一个LLM！
- en: The confusion about simulated data seems to arise from the fact that, in a few
    narrow scenarios, it is indeed possible to create training data by simulation.
    This was the case with AlphaZero, the famous ML model that beat a human player
    at the game of Go. Its creators had a computer play Go against itself to generate
    millions of simulated games and generate training examples. But this was only
    possible because it’s easy to calculate the end result of a game—you can easily
    tell who won. This isn’t the case with most applications outside game-playing.
    For example, you can’t easily tell what the next token is unless you already have
    an LLM, and you can’t easily tell an image’s category unless you already have
    an effective image categorization model.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 关于模拟数据的混淆似乎源于这样一个事实：在少数特定场景中，通过模拟确实可以创建训练数据。AlphaZero就是这种情况，这是一个著名的机器学习模型，在围棋游戏中击败了人类玩家。它的创造者让计算机与自己下围棋，以生成数百万个模拟游戏并生成训练示例。但这只因为计算游戏的结果很容易——你可以很容易地判断谁赢了。但在大多数非游戏应用中并非如此。例如，除非你已经有一个LLM，否则你无法轻易地判断下一个标记是什么，除非你已经有一个有效的图像分类模型。
- en: Some people also suggest augmenting your existing training data by automatically
    creating new training examples from combinations of existing ones. One technique
    called SMOTE (*synthetic minority oversampling technique*), for instance, is sometimes
    used to generate more examples of an underrepresented category. Suppose you’re
    trying to train an ML model to detect whether a credit card transaction is fraudulent.
    The training data may contain very few instances of transactions labeled as fraud
    because (hopefully) fraud doesn’t happen all that often. By using SMOTE, the AI
    engineer creates additional examples of fraudulent transactions by combining existing
    ones. However, this doesn’t add any *new* information to the training data. So,
    the machine cannot learn anything new with this extra data that it couldn’t learn
    before (for a more detailed discussion, see [https://mng.bz/7paQ](https://mng.bz/7paQ)).
    I advise you to be careful if anyone suggests you should concoct fake data to
    improve the performance of your model. In most cases, such fake data is used to
    compensate for a poor formulation of the task and not a necessity.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 有些人还建议通过自动从现有数据的组合中创建新的训练示例来增强你的现有训练数据。例如，一种称为SMOTE（*合成少数类过采样技术*）的技术有时被用来生成更多少数类别的示例。假设你正在尝试训练一个机器学习模型来检测信用卡交易是否欺诈。由于（希望）欺诈并不经常发生，训练数据中可能包含非常少的标记为欺诈的交易实例。通过使用SMOTE，AI工程师通过组合现有实例来创建额外的欺诈交易示例。然而，这并没有向训练数据中添加任何*新*信息。因此，机器无法通过这些额外的数据学习到之前无法学习到的新知识（更详细的讨论，见[https://mng.bz/7paQ](https://mng.bz/7paQ)）。我建议你在有人建议你应该编造假数据以提高模型性能时要小心。在大多数情况下，这种假数据是用来弥补任务表述不佳，而不是必要的。
- en: Self-supervised learning
  id: totrans-271
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 自监督学习
- en: In some applications, it’s possible to generate a huge number of labeled examples
    by automatically extracting information from existing data. This is known as *self-supervised
    learning.*
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些应用中，可以通过自动从现有数据中提取信息来生成大量的标记示例。这被称为*自监督学习*。
- en: Imagine that an AI engineer collects a huge amount of text from the internet.
    The engineer then extracts thousands of sentences from it and removes the last
    token from each, turning it into the label. The result is a large number of examples
    of how to guess the next token from the previous ones, which is exactly what LLMs
    need.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，一个AI工程师从互联网上收集了大量文本。然后，工程师从中提取了数千个句子，并从每个句子中移除最后一个标记，将其转换为标签。结果是大量如何从前一个标记猜测下一个标记的示例，这正是LLMs所需要的。
- en: Suppose a sentence in the data is “The Eiffel Tower is in Paris.” The engineer
    generates the training examples by using the previous process, as shown in figure
    1.10.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 假设数据中的一个句子是“埃菲尔铁塔在巴黎。”工程师通过如图1.10所示的过程生成训练示例。
- en: '![](../Images/CH01_UN03_Maggiori.png)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH01_UN03_Maggiori.png)'
- en: Figure 1.10 Training examples are generated by subdividing existing sentences
    and turning the last token in each into the desired autocomplete label.
  id: totrans-276
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.10：通过细分现有句子并将每个句子中的最后一个标记转换为所需的自动补全标签来生成训练示例。
- en: Afterward, supervised machine learning is used to train the LLM from these examples.
    Machine learning is still supervised, because it’s based on examples of how to
    do the job. But we say it’s “self” supervised to indicate that the labels were
    generated automatically from our original data source as opposed to obtained elsewhere,
    such as through manual labeling.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，使用监督机器学习从这些示例中训练LLM。机器学习仍然是监督的，因为它基于如何完成工作的示例。但我们说它是“自我”监督的，以表明标签是从我们的原始数据源自动生成的，而不是从其他地方获得的，例如通过人工标注。
- en: This trick works only when we can formulate the task as learning to reconstruct
    a corrupted input. In the case of LLMs, we artificially corrupt the input by removing
    the last token and then ask the LLM to reconstruct it by guessing that token.
    The fact that we can use this trick is probably one of the main reasons for LLMs’
    success, as it’s possible to generate a huge number of training examples without
    manual labeling.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 这个技巧只有在我们可以将任务表述为学习重建损坏的输入时才有效。在LLMs的情况下，我们通过移除最后一个标记来人为地损坏输入，然后要求LLMs通过猜测该标记来重建它。我们能够使用这个技巧可能是LLMs成功的主要原因之一，因为它可以在不进行人工标注的情况下生成大量的训练示例。
- en: This isn’t the case, however, with most ML applications. For example, when building
    a model for image categorization, we cannot use the self-supervised trick. Suppose
    our data contains a picture of a strawberry. The label “strawberry” is not available
    inside the picture, so we can’t remove it and then ask the model to guess it as
    we do with LLMs.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在大多数机器学习应用中并非如此。例如，在构建图像分类模型时，我们不能使用自监督技巧。假设我们的数据包含一张草莓的图片。标签“草莓”图片内部不可用，因此我们无法将其移除并要求模型猜测，就像我们在LLM中所做的那样。
- en: Reinforcement learning
  id: totrans-280
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 强化学习
- en: In an alternative, less common ML paradigm, the computer learns by trial and
    error. The training algorithm picks random actions, tries them out, and learns
    from feedback collected afterward. For example, suppose an advertising platform
    wants to create a model of a user’s interests using machine learning. The advertiser
    first shows random ads every time the user visits a webpage and registers whether
    the user clicked on the ad or not—this is known as *exploration.* Over time, the
    training algorithm identifies the kinds of things the user is interested in based
    on their clicks. Once the advertiser has an idea of the user’s interests, it starts
    showing relevant ads to them—this is known as *exploitation.*
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个不太常见但替代的机器学习范式下，计算机通过试错来学习。训练算法选择随机的动作，尝试它们，并从之后的反馈中学习。例如，假设一个广告平台想使用机器学习创建一个用户兴趣的模型。广告商首先在用户每次访问网页时展示随机的广告，并记录用户是否点击了广告——这被称为*探索*。随着时间的推移，训练算法根据用户的点击识别出用户感兴趣的事物类型。一旦广告商对用户的兴趣有了概念，它就开始向用户展示相关的广告——这被称为*利用*。
- en: '*The technique of learning by trial and error is known as *reinforcement learning,*
    or *RL**.* One of the major research topics in this field is how to balance exploitation
    and exploration over time. For example, after user preferences are discovered,
    the advertiser may still want to sometimes show random ads to the user to discover
    new preferences.'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '*通过试错来学习的技术被称为*强化学习*，或*RL*。该领域的主要研究课题之一是如何在时间上平衡利用和探索。例如，在发现用户偏好之后，广告商可能仍然希望有时向用户展示随机广告，以发现新的偏好。'
- en: While RL has been successful in some applications, its use in a commercial setting
    is rare. This is probably because learning by trial and error is a rather wasteful
    way of learning compared to supervised learning, in which we directly provide
    the machine with examples of how to do the job.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然强化学习在有些应用中取得了成功，但在商业环境中的应用却很少。这可能是由于与监督学习相比，通过试错来学习是一种相当浪费的学习方式，在监督学习中，我们直接向机器提供如何完成工作的示例。
- en: 'With the rise of LLMs, there is a new flavor of RL that has become popular,
    called *reinforcement learning with human feedback,* or RLHF. This technique is
    used to improve an existing LLM. It works as follows: an army of human workers
    are asked to manually create thousands of imaginary LLM prompts and pairs of alternative
    LLM outputs, and they are asked to label the alternative outputs based on preference
    (“best” versus “not best”). Afterward, AI engineers train a supervised ML model
    to guess whether an LLM output is good or bad based on these manually labeled
    examples. The result is an LM model, called the *reward model,* which is especially
    designed to determine whether an LLM’s output is good or bad.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 随着LLM的兴起，一种新的RL变种变得流行，被称为*带有人类反馈的强化学习*，或RLHF。这项技术用于改进现有的LLM。它的工作方式如下：一群人类工作者被要求手动创建数千个虚构的LLM提示和替代LLM输出的成对示例，并要求他们根据偏好（“最佳”与“非最佳”）对这些替代输出进行标注。之后，AI工程师训练一个监督ML模型，根据这些手动标注的示例来猜测LLM输出是好是坏。结果是称为*奖励模型*的LM模型，它专门设计用来确定LLM的输出是好是坏。
- en: Afterward, the AI engineers run a reinforcement learning algorithm to refine
    an existing LLM. The algorithm generates random LLM outputs and determines how
    good they are using the reward model. The feedback from the reward model is used
    to slightly improve the LLM. This algorithm progressively refines the LLM by better
    aligning it with what the human labelers considered good outputs.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，AI工程师运行强化学习算法来微调现有的LLM。该算法生成随机的LLM输出，并使用奖励模型来确定它们的好坏。奖励模型的反馈被用来略微改进LLM。该算法通过更好地将LLM与人类标注者认为的好输出对齐，逐步改进LLM。
- en: Unsupervised learning
  id: totrans-286
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 无监督学习
- en: Our final machine learning category is *unsupervised learning.* In this paradigm,
    we do not supply the machine with examples of the “right output.” In fact, there
    is no such notion because the task doesn’t have a single right answer. Unsupervised
    learning is typically used to explore data and find patterns in it.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 我们最后的机器学习类别是*无监督学习*。在这个范式下，我们并不向机器提供“正确输出”的例子。事实上，没有这样的概念，因为任务没有唯一的正确答案。无监督学习通常用于探索数据并从中发现模式。
- en: The most common example of unsupervised learning is *clustering*, in which we
    try to group similar data points together. For example, we may want to group similar
    patients together based on their medical records to create a handful of imaginary
    representative patients and analyze them. There is no notion of the “right group”
    a patient should belong to. We could group them into two, three, or five clusters,
    and there is no conclusive way of determining which number of clusters is the
    right one.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 无监督学习最常见的一个例子是*聚类*，其中我们试图将相似的数据点分组在一起。例如，我们可能希望根据他们的医疗记录将相似的病人分组，以创建几个假想的代表性病人并分析他们。没有关于病人应该属于“正确分组”的概念。我们可以将他们分成两个、三个或五个簇，但没有确定的方法来确定哪个簇的数量是正确的。
- en: 'Because there is no uniquely right model, we cannot measure the success of
    an unsupervised learning algorithm in a clear-cut way. That’s why people often
    suggest a multitude of rules of thumb to use unsupervised learning. Some of them
    are poorly defined. For example, they suggest creating many different models,
    calculating a metric for each, plotting a curve with the results, and finally,
    picking the model at the “knee” or “elbow” of the curve. The popular book *The
    Elements of Statistical Learning* (2nd ed., Penguin, 2009) by Hastie et al. explains
    the conundrum as follows:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 由于没有唯一正确的模型，我们无法以明确的方式衡量无监督学习算法的成功。这就是为什么人们经常建议使用许多经验法则来应用无监督学习。其中一些定义得并不好。例如，他们建议创建许多不同的模型，为每个模型计算一个指标，绘制结果曲线，最后，选择曲线的“膝部”或“肘部”处的模型。Hastie等人撰写的流行书籍《统计学习的要素》（第2版，企鹅出版社，2009年）将这一难题解释如下：
- en: With supervised learning there is a clear measure of success, or lack thereof,
    that can be used to judge adequacy in particular situations and to compare the
    effectiveness of different methods over various situations. . . . In the context
    of unsupervised learning, there is no such direct measure of success. It is difficult
    to ascertain the validity of inferences drawn from the output of most unsupervised
    learning algorithms. One must resort to heuristic arguments not only for motivating
    the algorithms, as is often the case in supervised learning as well, but also
    for judgments as to the quality of the results. This uncomfortable situation has
    led to heavy proliferation of proposed methods, since effectiveness is a matter
    of opinion and cannot be verified directly. (p. 486)
  id: totrans-290
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在监督学习中，有一个明确的成功或失败的标准，可以用来判断特定情况下的适当性，并比较不同方法在不同情况下的有效性。在无监督学习的背景下，没有这样的直接成功衡量标准。从大多数无监督学习算法的输出中得出的推断的有效性很难确定。人们必须求助于启发式论证，不仅是为了激励算法，正如在监督学习中经常发生的那样，而且也是为了判断结果的质量。这种不舒服的情况导致了大量方法的提出，因为有效性是主观的，不能直接验证。（第486页）
- en: In my experience, many of the people who try to use unsupervised learning need
    supervised learning instead.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我的经验，许多试图使用无监督学习的人实际上需要的是监督学习。
- en: For example, I know an engineer from a hospital who was trying to predict the
    severity of a patient’s disease. He used a clustering algorithm to automatically
    group patients together into a handful of representative patients. Afterward,
    when a new patient arrived, he tried to triage them based on their closest cluster.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我认识一位来自医院的工程师，他试图预测患者疾病的严重程度。他使用聚类算法自动将患者分组到几个代表性的患者中。之后，当一位新患者到来时，他试图根据他们最近的簇对他们进行分类。
- en: It didn’t work well, and the engineer was quite frustrated. He’d tried several
    popular approaches to create good clusters. He asked me, “How can I find high-quality
    clusters, so that triage works well?” I explained to him that there is no such
    thing; you cannot evaluate the quality of clusters independently of what you want
    to use them for. What he really needed was supervised learning trained on pairs
    of patient records with their expected triage outcomes.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 这并没有奏效，工程师感到非常沮丧。他尝试了多种流行的方法来创建好的聚类。他问我：“我怎样才能找到高质量的聚类，以便分类工作能顺利进行？”我向他解释说，没有这样的事情；你不能独立于你打算如何使用它们来评估聚类的质量。他真正需要的是在包含预期分类结果的病人记录对上训练的监督学习。
- en: Note that sometimes people use the term “unsupervised learning” to refer to
    supervised learning without manually generated labels, which only adds extra confusion
    to the matter.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，有时人们使用“无监督学习”这个术语来指代没有手动生成标签的监督学习，这只会使问题更加混乱。
- en: How LLMs are trained (and tamed)
  id: totrans-295
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LLM是如何训练（以及驯服）的
- en: The first LLMs were built using only self-supervised learning. The AI engineers
    collected a huge amount of text from the internet and generated training examples
    automatically using the process described above (“Better safe than sorry” / “Better
    safe than” / “Sorry”). One popular source of data was Common Crawl, a database
    that contains a huge amount of text gathered from all over the internet. Another
    popular source of text was Books3, a database of 190,000 books. Note that a lot
    of this data was collected without authorization from its authors; we’ll return
    to this controversial topic later.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 第一批LLM仅使用自监督学习构建。AI工程师从互联网上收集了大量文本，并使用上述过程（“宁为安全”/“宁为安全”/“抱歉”）自动生成训练示例。一个流行的数据来源是Common
    Crawl，这是一个包含从互联网上收集的大量文本的数据库。另一个流行的文本来源是Books3，这是一个包含190,000本书的数据库。请注意，其中很多数据是在未经作者授权的情况下收集的；我们稍后会回到这个有争议的话题。
- en: 'In a 2018 paper, OpenAI researchers revealed that their largest model until
    then, GPT-2, managed to perform impressive tasks just by using self-supervised
    learning (Redford et al., 2019). This promising result made them very ambitious
    about this approach. They speculated that the large amount of data available on
    the internet combined with self-supervised learning could lead to LLMs that learned
    to perform all sorts of tasks:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 在2018年的一篇论文中，OpenAI的研究人员揭示了他们当时最大的模型GPT-2，仅通过使用自监督学习（Redford等人，2019年）就成功地完成了令人印象深刻的任务。这个有希望的结果使他们对此方法非常雄心勃勃。他们推测，互联网上可用的海量数据与自监督学习相结合，可能导致LLM学会执行各种任务：
- en: The internet contains a vast amount of information that is passively available
    without the need for interactive communication. Our speculation is that a language
    model with sufficient capacity will begin to learn to infer and perform the tasks
    demonstrated in natural language sequences [e.g., asking the LLM to translate
    or summarize text] in order to better predict them [guess the next word], regardless
    of their method of procurement.
  id: totrans-298
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 互联网上包含大量无需互动交流即可被动获取的信息。我们的推测是，一个具有足够容量的语言模型将开始学习从自然语言序列中推断和执行任务[例如，要求LLM翻译或总结文本]，以便更好地预测它们[猜测下一个单词]，无论它们获取信息的方法如何。
- en: In addition, they argued that the task of guessing the next word encompassed
    many other tasks, so it was generally enough to build really powerful LLMs. By
    using jargon from the mathematical optimization field, they explained that the
    “global minimum” (the best solution) to the next-token-prediction task coincided
    with the “global minimum” (the best solution) to perform all sorts of other tasks.
    So, striving to find the best solution to the next-token-prediction task was equivalent
    to striving to find the best solution to other tasks.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，他们还认为，猜测下一个单词的任务涵盖了其他许多任务，因此构建真正强大的LLM通常就足够了。他们使用数学优化领域的术语解释说，下一个标记预测任务的“全局最小值”（最佳解决方案）与执行各种其他任务的“全局最小值”（最佳解决方案）相一致。因此，努力找到下一个标记预测任务的最佳解决方案等同于努力找到其他任务的最佳解决方案。
- en: 'But enthusiasm didn’t last long. While LLMs trained using the self-supervised
    approach worked very well in many cases, they also erred badly in others. In addition,
    sometimes they generated inappropriate outputs. Researchers from OpenAI discussed
    the problem in a 2022 paper (available at [https://arxiv.org/pdf/2203.02155](https://arxiv.org/pdf/2203.02155)):'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 但热情并没有持续太久。虽然使用自我监督方法训练的LLM在许多情况下表现良好，但它们在其他情况下也犯下了严重的错误。此外，有时它们会生成不适当的输出。OpenAI的研究人员在2022年的一篇论文中讨论了这个问题（可在[https://arxiv.org/pdf/2203.02155](https://arxiv.org/pdf/2203.02155)找到）：
- en: These models often express unintended behaviors such as making up facts, generating
    biased or toxic text, or simply not following user instructions. This is because
    the language modeling objective used for many recent large LMs—predicting the
    next token on a webpage from the internet—is different from the objective “follow
    the user’s instructions helpfully and safely.”
  id: totrans-301
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这些模型经常表现出无意的行为，例如编造事实、生成有偏见或有害的文本，或者简单地不遵循用户指令。这是因为许多最近的大型语言模型使用的语言建模目标——从互联网网页上预测下一个标记——与“有帮助且安全地遵循用户指令”的目标不同。
- en: As this quote illustrates, the researchers attributed the problem to a misalignment
    between what we *really* want from LLMs—produce factual, appropriate text—and
    what they’re trained to do—guess the next token according to text collected from
    the internet.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 正如这句话所说明的，研究人员将问题归因于我们对LLM真正想要的——产生事实、适当的文本——与他们被训练去做的事情——根据从互联网收集的文本猜测下一个标记——之间的不一致。
- en: The OpenAI researchers proposed a solution to this problem, called InstructGPT
    ([https://arxiv.org/abs/2203.02155](https://arxiv.org/abs/2203.02155)), which
    trains the LLM in four steps. First, the model is trained the usual way by using
    internet data in a self-supervised way.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: OpenAI的研究人员提出了一个解决方案，称为InstructGPT ([https://arxiv.org/abs/2203.02155](https://arxiv.org/abs/2203.02155))，该方案通过四个步骤训练LLM。首先，模型通过使用互联网数据进行自我监督的方式，以通常的方式进行训练。
- en: Second, human workers are hired to manually write thousands of examples of input
    prompts and their corresponding desired outputs. These manually written examples
    provide extra training data to help improve and “tame” the model, for example,
    by showing it how to perform popular tasks, have two-way conversations, and refuse
    to answer inappropriate questions. According to a *Time* article, “OpenAI used
    Kenyan Workers on less than $2 per hour” for the job of labeling data ([https://mng.bz/mGP8](https://mng.bz/mGP8)).
    This goes to show that training high-performing LLMs is more manual than it seems
    at first sight.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，雇佣了人工工作者手动编写数千个输入提示及其对应期望输出的示例。这些手动编写的示例提供了额外的训练数据，有助于改进和“驯服”模型，例如，通过展示如何执行流行任务、进行双向对话以及拒绝回答不适当的问题。据《时代》杂志文章报道，OpenAI为这项标注数据的工作支付了每小时不到2美元的肯尼亚工人([https://mng.bz/mGP8](https://mng.bz/mGP8))。这表明，训练高性能LLM比最初看起来更依赖于人工。
- en: Third, the existing LLM is *fine-tuned* using the manually generated data. This
    means that its parameters are slightly adjusted through a few extra rounds of
    training with the new examples.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，现有的LLM使用手动生成数据进行微调。这意味着通过使用新示例进行几轮额外的训练，其参数略有调整。
- en: The fourth step is to use reinforcement learning with human feedback to refine
    the LLM even further (see the explanation under “*Reinforcement learning”*). In
    this case, humans are asked to manually rank alternative LLM outputs based on
    their quality, which provides feedback to the training algorithm to improve the
    LLM.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 第四步是使用带有人类反馈的强化学习进一步细化LLM（见“*强化学习*”下的解释）。在这种情况下，人类被要求根据其质量手动对LLM的替代输出进行排名，这为训练算法提供反馈，以改进LLM。
- en: ChatGPT was the first popular model trained using steps 1–4\. This turn of events
    may have caused some serious disappointment among those who believed that the
    highest performing LLMs would be created just from data collected from the internet,
    without any manual labeling.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT是第一个使用步骤1-4训练的流行模型。这一事件可能让那些相信最高性能的LLM只需从互联网收集的数据创建，而不需要任何人工标注的人感到严重失望。
- en: A note on privacy
  id: totrans-308
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 关于隐私的说明
- en: As people use LLMs, their conversations may be recorded by the LLM provider.
    The resulting data may be used to improve models, either automatically—by generating
    new training data and fine-tuning the model—or manually—by having employees identify
    recurring problems faced by users and come up with ways of fixing them. Some apps
    such as ChatGPT let users rate answers with a thumbs up or thumbs down, and they
    sometimes ask users to rank alternative answers, which might be later used to
    improve the LLMs.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 随着人们使用大型语言模型（LLM），他们的对话可能会被LLM提供商记录。这些数据可能被用于改进模型，无论是通过自动生成新的训练数据并微调模型，还是通过让员工识别用户面临的问题并想出解决问题的方法。一些应用程序，如ChatGPT，允许用户用点赞或点踩来评价答案，有时还会要求用户对替代答案进行排序，这些信息可能后来会被用于改进LLM。
- en: You should be careful if you include sensitive information within an LLM’s prompt,
    as it might be seen or used by the staff who works on creating and improving LLMs.
    You’ll probably be able to opt out from your prompts being recorded. For example,
    OpenAI’s website explains, “When you use our services for individuals such as
    ChatGPT, we may use your content to train our models. You can opt out of training
    through our privacy portal. . . . We do not use content from our business offerings
    such as ChatGPT Team or ChatGPT Enterprise to train our models.”
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在LLM的提示中包含敏感信息，你应该小心，因为这些信息可能会被负责创建和改进LLM的员工看到或使用。你可能会选择不记录你的提示。例如，OpenAI的网站解释说：“当你使用我们的服务，如ChatGPT，我们可能会使用你的内容来训练我们的模型。你可以通过我们的隐私门户选择退出训练……我们不使用来自我们的商业产品，如ChatGPT团队或ChatGPT企业，来训练我们的模型。”
- en: Loss
  id: totrans-311
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 损失
- en: Let’s move on to the topic of how ML models learn. The first ingredient is a
    way of assessing the quality of a given model, known as the *loss* or *cost.*
    This is used by the learning algorithm to compare alternative models (with different
    parameter values) and find opportunities for improvement.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续讨论ML模型如何学习的话题。第一个要素是评估给定模型质量的方法，称为*损失*或*成本*。这是学习算法用来比较不同参数值的替代模型，并找到改进机会的。
- en: The loss calculates how inaccurate the outputs of a model are compared to the
    training examples—the higher the value, the worse the model.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 损失计算了模型的输出与训练示例相比的不准确性——值越高，模型越差。
- en: Consider a training example, “The Eiffel” paired with its corresponding label
    “Tower”, which is used to train an LLM. Our goal is to calculate a loss value
    that measures how far off the LLM’s output is when given the input “The Eiffel”.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个训练示例，“埃菲尔铁塔”与其对应的标签“塔”，这是用来训练LLM的。我们的目标是计算一个损失值，以衡量当输入“埃菲尔铁塔”时，LLM的输出偏离程度。
- en: The loss is calculated by looking at the probability the LLM assigns to the
    right token, such as “Tower” in this case. If the probability is high, the loss
    is low, and vice versa. This is calculated by taking the negative logarithm of
    the probability, which is known as the *cross-entropy loss* or *log loss.* The
    loss is zero if the probability of “ Tower” is 1.0 (−log(1) = 0), and it takes
    an increasingly higher value the lower the probability assigned to “Tower” (e.g.,
    −log(0.2) = 1.6 and −log(0.1) = 2.3).
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 损失是通过查看LLM分配给正确标记的概率来计算的，例如在本例中的“塔”。如果概率高，损失就低，反之亦然。这是通过取概率的负对数来计算的，这被称为*交叉熵损失*或*对数损失*。如果“塔”的概率是1.0（-log(1)
    = 0），则损失为零，而分配给“塔”的概率越低，损失值就越高（例如，-log(0.2) = 1.6和-log(0.1) = 2.3）。
- en: The loss over the entire dataset is calculated by adding the individual losses
    of each of the training examples. The better the model is at guessing the correct
    next token according to the training data, the higher the probabilities it assigns
    to them, and the lower the loss. Mission accomplished.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 整个数据集上的损失是通过将每个训练示例的个别损失相加来计算的。模型在根据训练数据猜测正确下一个标记方面越好，它分配给它们的概率就越高，损失就越低。任务完成。
- en: Note, however, that the loss measures the performance of the model on *training*
    data. The AI engineer hopes that a lower loss will translate to a higher performance
    on unseen, new data. But this isn’t always the case; if the model suffers from
    overfitting, it memorizes individual instances of the training data, thus achieving
    a low loss, but it doesn’t work well with other data.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，损失衡量的是模型在*训练*数据上的性能。AI工程师希望较低的损失值能转化为在未见过的、新数据上的更高性能。但这并不总是如此；如果模型出现过拟合，它会记住训练数据中的个别实例，从而实现低损失，但与其他数据不兼容。
- en: Stochastic gradient descent
  id: totrans-318
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 随机梯度下降
- en: 'So far, we’ve described the following ML ingredients:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经描述了以下机器学习（ML）的成分：
- en: The architecture of a model, which contains learnable parameters (“blanks”)
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的架构，其中包含可学习的参数（“空白”）
- en: Training examples
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练示例
- en: A way to measure the quality of a model (the loss) according to the training
    examples
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种根据训练示例来衡量模型质量（损失）的方法
- en: The only remaining ingredient is an algorithm to find the best way to adjust
    the parameters, so that the model yields the lowest loss.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 剩下的唯一成分是一个算法，用于找到调整参数的最佳方式，从而使模型产生最低的损失。
- en: The most common algorithm for this, used to build LLMs and many other ML models,
    is stochastic gradient descent (SGD). It works as follows. First, all the parameters
    inside the model are initialized using random values. So, this first version of
    the model is completely useless at the task at hand—for example, the next-token
    predictions of the LLM are nonsensical.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 用于此目的最常见算法，用于构建大型语言模型（LLM）和许多其他机器学习模型，是随机梯度下降（SGD）。它的工作原理如下。首先，模型内部的所有参数都使用随机值初始化。因此，这个模型的第一版在当前任务上完全无用——例如，LLM的下个标记预测是无意义的。
- en: Afterward, the training algorithm selects a small number of training samples,
    called a *batch* or *minibatch,* to calculate a promising way of slightly modifying
    the model’s parameters to reduce the loss on that batch. In calculus jargon, this
    amounts to computing the *gradient* of the loss. We can think of this as wiggling
    the parameters a little bit to find a promising direction of change. Think of
    an optometrist slightly varying your glasses prescription and asking you if you
    see better than before. Afterward, the training algorithm slightly modifies the
    model’s parameters according to the promising direction it just found, hoping
    this will slightly improve the model.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，训练算法选择一小部分训练样本，称为*批次*或*小批量*，来计算略微修改模型参数以减少该批次损失的有希望的方法。在微积分术语中，这相当于计算损失的*梯度*。我们可以将其视为稍微调整参数以找到变化的有希望方向。想象一下，验光师稍微改变你的眼镜处方，并问你是否比以前看得更清楚。之后，训练算法根据刚刚找到的有希望方向略微修改模型的参数，希望这能略微提高模型。
- en: Note that only a batch of training examples is used for this calculation, instead
    of the entire training data. This is why the algorithm is said to be *stochastic*,
    because you estimate the gradient based on a sample of the data instead of all
    the data. This makes the process much quicker.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这里只使用一个训练示例批次进行计算，而不是整个训练数据。这就是为什么算法被称为*随机*的，因为你是基于数据样本而不是所有数据来估计梯度的。这使得整个过程变得更快。
- en: The next step is to repeat the above operation using a second batch of examples
    extracted from the training data. The parameters are again slightly updated in
    the direction of the gradient calculated on that batch. This process is repeated,
    one batch at a time. At some point, the algorithm makes a full pass over the entire
    training data, which is known as an *epoch.* Usually, training is performed for
    several epochs, so there are multiple passes over the entire training data. We
    don’t know the exact number of epochs used to train popular LLMs, but OpenAI once
    revealed training a model for 100 epochs (see [https://mng.bz/5gy7](https://mng.bz/5gy7)).
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是使用从训练数据中提取的第二批示例重复上述操作。参数再次根据该批次计算的梯度方向略微更新。这个过程逐批重复。在某个时刻，算法对整个训练数据进行了完整的一次遍历，这被称为*一个epoch*。通常，训练会进行多个epoch，因此整个训练数据会有多次遍历。我们不知道训练流行LLM所使用的确切epoch数量，但OpenAI曾经透露训练一个模型需要100个epoch（见[https://mng.bz/5gy7](https://mng.bz/5gy7))）。
- en: The training process is very time-consuming. It can take days to complete and
    multiple GPUs working in unison to do all the number crunching.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 训练过程非常耗时。可能需要几天时间才能完成，并且需要多个GPU协同工作来完成所有数值计算。
- en: Stochastic gradient descent helps progressively improve the model, but it doesn’t
    guarantee finding the best possible model of all. This is because making slight
    improvements in the direction of the gradient can get the model stuck in a *local
    minimum.* This means that the model cannot be improved any further by making *small*
    changes to parameter values. There may be a better model, perhaps the globally
    best one, if parameters were changed widely from their current ones, but this
    is like finding a needle in a haystack.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 随机梯度下降有助于逐步改进模型，但它并不能保证找到所有可能模型中的最佳模型。这是因为沿着梯度方向进行微小的改进可能会使模型陷入*局部最小值*。这意味着通过调整参数值的小幅变化无法进一步改进模型。如果参数值从当前值进行广泛调整，可能会有更好的模型，也许是全局最佳模型，但这就像在
    haystack 中找针一样困难。
- en: It is kind of crazy that we can create a good LLM following this process, as
    we must find effective values for billions of parameters starting from completely
    random ones. It is wild! The reason it works is that the model’s architecture
    is laser-focused and tailor-made to the task (e.g., it enforces a multi-headed
    attention mechanism with simple, linear projections and dot products). So, the
    model’s parameter values are guided in the right direction thanks to their specialization
    to perform the task in a human-prescribed way.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能够遵循这个过程创建一个优秀的LLM，这有点疯狂，因为我们必须从完全随机的参数中找到有效的值。这太疯狂了！它之所以有效，是因为模型的架构是高度专注且量身定制的，以适应任务（例如，它强制执行具有简单线性投影和点积的多头注意力机制）。因此，模型的参数值在执行人类规定的任务方面得到了正确的引导。
- en: Note that using an existing model is much faster than training it. All the parameters
    are already defined, so you just need to use the model once to calculate its outputs
    from its inputs. Using an already created model is often described as *inference
    time* to distinguish it from the much lengthier *training time.*
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，使用现有模型的速度要比训练它快得多。所有参数已经定义，你只需要使用一次模型来计算其从输入中得到的输出。使用已经创建的模型通常被称为*推理时间*，以区别于更长的*训练时间*。
- en: '*So far, we’ve covered AI within the context of LLMs. Understanding the gist
    of how AI works with other inputs, such as images, isn’t a big leap from what
    we’ve already discussed. In the next couple of sections, we’ll briefly comment
    on how AI processes images and combinations of different data types. We start
    with convolutional neural networks, which are a type of architecture that did
    for image analysis what transformers did for text analysis.'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '*到目前为止，我们已经从LLMs的背景下讨论了AI。理解AI如何与其他输入（如图像）一起工作的大致原理，与我们已经讨论的内容并没有太大的跳跃。在接下来的几节中，我们将简要讨论AI如何处理图像和不同数据类型的组合。我们首先从卷积神经网络开始，这是一种架构，它在图像分析方面所做的贡献与transformers在文本分析方面所做的贡献类似。'
- en: Generative AI (and are LLMs generative?)
  id: totrans-333
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 生成式AI（以及LLMs是否是生成式的？）
- en: Since the proliferation of LLMs, the term “generative AI” has become a popular
    way of describing any AI model used to generate new content, such as text and
    images. In this sense, LLMs are generative.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 随着LLMs的普及，“生成式AI”一词已成为描述用于生成新内容（如文本和图像）的任何AI模型的流行方式。在这个意义上，LLMs是生成式的。
- en: However, that’s not what “generative” used to mean in the technical ML literature,
    so you may find conflicting uses of the word.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在技术机器学习文献中，“生成式”一词的原始含义并非如此，因此你可能会发现这个词的用法存在冲突。
- en: In ML, a model is said to be *discriminative* when it calculates the probability
    of a label given the input. We can describe this mathematically as the conditional
    probability P(Label | Input). This is exactly what LLMs calculate—the probability
    of the next token given the previous ones—so they’re technically discriminative
    models.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，当模型根据输入计算标签的概率时，我们称其为*判别式*模型。我们可以用条件概率P（Label | Input）来数学地描述这一点。这正是LLMs所计算的内容——给定前一个标记计算下一个标记的概率——因此，从技术上讲，它们是判别式模型。
- en: By contrast, a *generative* model in the ML literature is one that calculates
    the probability of stumbling upon a certain piece of data—both input and label.
    For example, if you give the generative model a picture of a cat paired with the
    label “cat,” it tells you how likely you are to ever find such an image paired
    with such a label. So, it also assesses the plausibility of the cat image itself.
    If you give the model a picture of a blue cat paired with the label “cat,” it
    will probably output a low probability, as you’re unlikely to find pictures of
    blue cats. In mathematical terms, a generative model calculates P(Input, Label),
    the joint probability of stumbling upon a specific input/label training example.
    LLMs are not designed to do this, so, strictly speaking, they’re not generative
    models (see discussion at [https://mng.bz/6eMR](https://mng.bz/6eMR)).
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，机器学习文献中的生成模型是指计算遇到特定数据（包括输入和标签）概率的模型。例如，如果你给生成模型一张猫的图片并配以“猫”的标签，它会告诉你找到这样一张图片并配以这样标签的可能性有多大。因此，它也会评估猫图片本身的合理性。如果你给模型一张蓝色猫的图片并配以“猫”的标签，它可能会输出一个低概率，因为你不太可能找到蓝色猫的图片。用数学术语来说，生成模型计算P（输入，标签），即遇到特定输入/标签训练样本的联合概率。LLMs不是为此而设计的，所以，严格来说，它们不是生成模型（参见[https://mng.bz/6eMR](https://mng.bz/6eMR)的讨论）。
- en: Convolutions (images, video, and audio)
  id: totrans-338
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卷积（图像、视频和音频）
- en: Let’s now step away from text generation and take a quick look at how AI models
    process other data types like images. In the 2010s, an ML model architecture known
    as *convolutional neural network*, or CNN, became extremely popular for image
    categorization. The input to a CNN is an image—represented as a table of numbers,
    or *pixels*—and the output is a prediction of the image’s category, such as “strawberry.”
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们暂时离开文本生成，快速看看AI模型如何处理其他数据类型，如图像。在2010年代，一种被称为卷积神经网络（convolutional neural
    network，或CNN）的机器学习模型架构，在图像分类中变得极为流行。CNN的输入是一个图像——表示为数字表，或称为像素——输出是对图像类别的预测，例如“草莓”。
- en: 'CNNs were specifically designed to exploit a strong assumption about image
    categorization: objects can be detected by the presence of their parts (e.g.,
    a cat can be identified by the presence of a tail, eyes, whiskers), but we don’t
    care so much about the exact location of the parts (e.g., the direction in which
    a cat’s tail points is irrelevant to recognize that it’s a cat).'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）被特别设计来利用关于图像分类的强假设：可以通过物体部分的存在来检测物体（例如，通过尾巴、眼睛、胡须的存在可以识别出一只猫），但我们并不太关心这些部分的确切位置（例如，猫尾巴指向的方向对于识别它是一只猫来说并不重要）。
- en: A CNN applies a series of transformations to the input image. The first transformation
    is a *convolution,* which is a simple mathematical operation that filters the
    image and produces a slightly modified version of it. Convolutions can be configured
    to do things such as
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: CNN对输入图像应用一系列变换。第一个变换是卷积，这是一种简单的数学运算，它过滤图像并产生一个略微修改后的版本。卷积可以配置为执行诸如
- en: Blur the image
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模糊图像
- en: Highlight areas of a specific color
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 突出显示特定颜色的区域
- en: Highlight areas of sharp color changes in given directions (e.g., diagonal lines)
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在给定方向上突出显示颜色变化明显的区域（例如，对角线）
- en: The exact filter applied by a convolution is configured by defining the numbers
    in a small matrix. These values are learnable parameters of the CNN, so the model
    decides which filters to apply at training time instead of the engineer defining
    them beforehand.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积所应用的精确滤波器是通过定义一个小矩阵中的数字来配置的。这些值是CNN的可学习参数，因此模型在训练时决定应用哪些滤波器，而不是工程师事先定义它们。
- en: The CNN performs multiple convolutions simultaneously and combines the results
    into a new image. Afterward, the image in *downsampled,* meaning that it is spatially
    shrunk. For example, an image of size 1024 × 1024 pixels might be shrunk to a
    size of 512 × 512 pixels by averaging the values of quadruplets of neighboring
    pixels. The effect of downsampling is to make this image more abstract by removing
    objects’ precise locations (as we said above, we assumed precise locations to
    be unimportant in the context of image categorization).
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: CNN同时执行多次卷积并将结果组合成一个新的图像。之后，图像被下采样，这意味着它在空间上被缩小。例如，一个1024 × 1024像素大小的图像可能通过平均相邻像素的四重值缩小到512
    × 512像素大小。下采样的效果是通过去除物体的精确位置（正如我们上面所说的，我们假设在图像分类的上下文中精确位置并不重要）使图像更加抽象。
- en: New convolutions are applied to the resulting image, followed by another round
    of downsampling. This is then done again and again. As filters are applied over
    already filtered images, the CNN can detect progressively complicated patterns.
    We could imagine, for example, that at first, the CNN uses convolutions to detect
    simple lines, then it detects pairs of parallel lines, then groups of parallel
    lines, then whiskers from those lines, and finally, it detects cats from their
    whiskers. As the exact filters are determined through machine learning, it’s hard
    to understand the exact strategy used by CNNs to make predictions.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 在得到的图像上应用新的卷积，然后进行另一轮下采样。这个过程会反复进行。由于在已经过滤的图像上应用过滤器，CNN可以检测到越来越复杂的模式。例如，我们可以想象，CNN最初使用卷积来检测简单的线条，然后检测平行线对，接着是平行线组，然后是线条的胡须，最后从胡须中检测到猫。由于确切的过滤器是通过机器学习确定的，因此很难理解CNN用于预测的确切策略。
- en: The end result of this process is an embedding that effectively represents the
    content of the image in an abstract way. This embedding is used to predict the
    probability of the image belonging to each possible category. Mission accomplished.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程的最终结果是嵌入，它有效地以抽象的方式表示图像的内容。这个嵌入用于预测图像属于每个可能类别的概率。任务完成。
- en: CNNs are also used to transform images into other images of the same size. This
    is useful, for example, when reconstructing a damaged image or making any picture
    look like a Van Gogh painting. A popular architecture, called U-Net, achieves
    this in two steps. First, a usual CNN performs the above-described transformations
    to shrink the input image into a smaller, more abstract representation of its
    content. Afterward, another CNN-like structure extracts the intermediate images
    produced by the CNN and “stiches” them together to reconstruct a full-size image
    in a different style.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: CNNs也被用于将图像转换为相同大小的其他图像。例如，在重建损坏的图像或使任何图片看起来像梵高的画作时，这很有用。一种称为U-Net的流行架构通过两个步骤实现这一点。首先，一个普通的CNN执行上述描述的转换，将输入图像缩小为内容的一个更小、更抽象的表示。之后，另一个类似CNN的结构提取CNN产生的中间图像，并将它们“缝合”在一起，以不同的风格重建一个全尺寸图像。
- en: CNNs have also become popular to process audio and video. The principle is the
    same—the input goes through a series of convolutions and downsampling operations
    until it’s transformed into a more abstract representation.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNNs）也变得流行，用于处理音频和视频。其原理相同——输入数据经过一系列卷积和下采样操作，直到转化为更抽象的表示。
- en: Transformers have become the go-to architecture to process text, and CNNs have
    become the go-to architecture to process images, video, and audio. In the next
    section, we see how transformer and CNNs are combined in multimodal AI.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 变换器（Transformers）已成为处理文本的首选架构，而CNNs已成为处理图像、视频和音频的首选架构。在下一节中，我们将看到变换器和CNNs如何在多模态人工智能中结合使用。
- en: Multimodal AI
  id: totrans-352
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多模态人工智能
- en: Some AI models, known as *multimodal,* are capable of consuming or producing
    combinations of text, image, and audio. One example is AI that generates images
    from a textual description, such as the popular Midjourney and DALL-E.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 一些被称为*多模态*的AI模型能够消费或产生文本、图像和音频的组合。一个例子是能够从文本描述生成图像的AI，例如流行的Midjourney和DALL-E。
- en: Multimodal AI models are architected by combining LLMs and CNNs. There are myriad
    ways of combining them, so we’ll only briefly describe two approaches, one to
    generate text from images and one to generate images from text.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态人工智能模型是通过结合大型语言模型（LLMs）和CNNs来构建的。有无数种结合方式，所以我们只简要描述两种方法，一种是从图像生成文本，另一种是从文本生成图像。
- en: A popular image-to-text architecture uses an independently trained CNN to generate
    an embedding for the input image. The embedding is then transformed through a
    linear projection to make it comparable to the LLM’s embedding. For example, the
    embedding generated by the CNN for an image of a cat is turned into the embedding
    the LLM uses for the “cat” token. The new embedding is then injected inside the
    LLM. *Voilà!*
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 一种流行的图像到文本架构使用独立训练的CNN为输入图像生成嵌入。然后，通过线性投影将嵌入转换，使其与LLM的嵌入可比较。例如，CNN为猫的图像生成的嵌入被转换为LLM用于“猫”标记的嵌入。新的嵌入随后被注入到LLM中。*哇！*
- en: Let’s now turn to a highly popular text-to-image approach, known as a *conditional
    diffusion* model. In this approach, a U-Net type of CNN is trained to reconstruct
    an image from a corrupted version of the image and its textual caption (see figure
    1.11).
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们转向一个高度流行的文本到图像的方法，称为**条件扩散**模型。在这个方法中，一种U-Net类型的CNN被训练从图像的损坏版本及其文本标题中重建图像（见图1.11）。
- en: '![](../Images/CH01_F09_Maggiori.png)'
  id: totrans-357
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH01_F09_Maggiori.png)'
- en: Figure 1.11  A diffusion model is trained to improve a corrupted image paired
    with its caption.
  id: totrans-358
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.11  训练扩散模型以改善与其标题配对的损坏图像。
- en: 'The model takes two inputs:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 模型接受两个输入：
- en: A corrupted image (often called a “noisy” image)
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一张损坏的图像（通常称为“噪声”图像）
- en: An embedding that represents the meaning of the text caption (e.g., generated
    using a language model)
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表示文本标题含义的嵌入（例如，使用语言模型生成）
- en: The text embedding is inserted into the model as an additional input. This is
    often done, for example, by using an embedding that matches the image size and
    inserting it as an additional color channel, on top of red, green, and blue.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 文本嵌入被作为额外的输入插入到模型中。这通常是通过使用与图像大小匹配的嵌入，并将其作为额外的颜色通道插入，覆盖在红色、绿色和蓝色之上来完成的。
- en: The CNN is trained to repair the damaged image. This is performed in a supervised
    way. This requires a database with numerous examples of corrupted images, their
    corresponding captions, and their uncorrupted versions. The corrupted image is
    generated automatically by artificially corrupting a higher-quality image, and
    the captions are generated manually.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: CNN被训练来修复损坏的图像。这是以监督的方式进行。这需要一个包含大量损坏图像示例、它们相应的标题和它们未损坏版本的数据库。损坏的图像是通过人工损坏一个高质量图像自动生成的，而标题是手动生成的。
- en: Once this model is trained, it is capable of slightly improving a bad image
    using the caption for guidance. Let’s see how this model is used to create a brand-new
    image from a description, as we do with Midjourney.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦这个模型被训练，它就能够使用标题作为指导，略微改善一张糟糕的图像。让我们看看这个模型是如何从描述中创建一个全新的图像的，就像我们在Midjourney中做的那样。
- en: First, the model is fed a totally random image, which resembles the static noise
    in a faulty TV set, together with the caption of the desired image (see figure
    1.12). The model then produces a slightly “improved” version of this image, where
    we see the desired object slightly pop up from the noise.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，模型被输入一张完全随机的图像，它类似于故障电视中的静态噪声，以及所需图像的标题（见图1.12）。然后，模型产生这个图像的略微“改进”版本，我们在这个版本中看到所需的对象从噪声中略微浮现出来。
- en: '![](../Images/CH01_F10_Maggiori.png)'
  id: totrans-366
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH01_F10_Maggiori.png)'
- en: Figure 1.12  A diffusion model is used repeatedly to have a desired image emerge
    from Gaussian noise.
  id: totrans-367
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.12  使用扩散模型重复生成所需图像，使其从高斯噪声中显现出来。
- en: The model is then used repeatedly on its own output, which progressively enhances
    the image. After doing this many times, the image becomes nice and sharp. This
    is usually performed a fixed number of times decided in advance through experimentation—the
    number of steps is set to be large enough to guarantee that most images will be
    sharp by the end. Some people are studying techniques to vary the number of steps
    depending on the prompt ([https://arxiv.org/abs/2408.02054](https://arxiv.org/abs/2408.02054)).
    We can think of this process as diffusing away the “noise,” hence the term “diffusion
    model.” This technique powers the most popular text-to-image models. Diffusion
    is also the cornerstone of text-to-video models, which is a hot research topic.
    For example, OpenAI’s video-generating model called Sora uses diffusion ([https://mng.bz/oKlD](https://mng.bz/oKlD)).
    Instead of denoising an image, it is designed to denoise a *patch,* which is a
    representation of a small piece of video over space and time. A patch covers a
    small portion of the screen, such as the top-left corner, across a few contiguous
    frames. Just like with images, the model is used repeatedly to progressively enhance
    patches using the prompt for guidance, starting from random noise. As of this
    writing, the model hasn’t yet been released to the public.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，模型会反复对其自己的输出进行使用，这逐渐增强了图像。经过多次这样的操作后，图像变得既清晰又锐利。这通常是通过实验预先确定的一个固定次数来执行的——步数被设定得足够大，以确保大多数图像在结束时都会变得清晰。有些人正在研究根据提示来调整步骤数量的技术（[https://arxiv.org/abs/2408.02054](https://arxiv.org/abs/2408.02054)）。我们可以将这个过程视为消除“噪声”，因此称之为“扩散模型”。这种技术推动了最受欢迎的文本到图像模型。扩散也是文本到视频模型的基础，这是一个热门的研究课题。例如，OpenAI的名为Sora的视频生成模型就使用了扩散技术（[https://mng.bz/oKlD](https://mng.bz/oKlD)）。它不是去噪图像，而是设计用来去噪“补丁”，这是空间和时间上一个小片段视频的表示。补丁覆盖屏幕的一小部分，如左上角，跨越几个连续的帧。就像图像一样，模型被反复使用，在提示的指导下逐步增强补丁，从随机噪声开始。截至本文撰写时，该模型尚未向公众发布。
- en: This brings us to the end of our (relatively) quick rundown of some of the fundamental
    elements of AI. Let’s draw things to a close with a high-level reflection about
    machine learning before we move on to the next chapter.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 这就带我们结束了（相对）快速概述的一些AI基本要素。在我们进入下一章之前，让我们对机器学习进行一次高层次的反思。
- en: No free lunch
  id: totrans-370
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 没有免费的午餐
- en: I’d like to wrap things up with a reflection about machine learning. As we’ve
    seen throughout this chapter, ML requires designing a dedicated architecture to
    each problem. For example, transformers are used to generate text, CNNs are used
    to analyze images, and creative combinations of the two are used in a multimodal
    setting. Each model’s architecture is based on assumptions of how to best solve
    the problem at hand. For example, transformers force the model to calculate attention
    scores, and CNNs impose using convolutions.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 我想以对机器学习的反思来结束本次讨论。正如我们在本章中看到的，机器学习需要为每个问题设计一个专门的架构。例如，变换器用于生成文本，CNNs用于分析图像，两种技术的创造性组合在多模态环境中得到应用。每个模型的架构都是基于如何最好地解决当前问题的假设。例如，变换器迫使模型计算注意力分数，而CNNs则强制使用卷积。
- en: Every ML milestone has been attained thanks to the invention of a new type of
    architecture that does a better job than previous ones at the task at hand. For
    example, transformers replaced LSTMs, and there was a boom in AI’s performance
    at text generation. Progress is made when we tailor architectures to specific
    tasks in a creative and useful way. So, current AI is about designing tailored
    solutions to each problem and not about devising a general approach that works
    on everything.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 每一个机器学习里程碑的取得都得益于一种新架构的发明，这种新架构在完成当前任务方面比之前的架构做得更好。例如，变换器取代了LSTMs，AI在文本生成方面的性能得到了显著提升。当我们以创造性和实用的方式为特定任务量身定制架构时，就会取得进步。因此，当前的AI是关于为每个问题设计定制解决方案，而不是设计一个适用于所有事物的通用方法。
- en: 'In fact, the No Free Lunch Theorem of machine learning says, in simple terms,
    that there is no universally best architecture that is optimal for all problems
    (see David Wolpert, 1996, “The lack of a priori distinctions between learning
    algorithms,” *Neural Computation* 8.7: 1341–1390). Instead, each problem requires
    a dedicated architecture.'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: '事实上，机器学习的“没有免费午餐定理”简单来说，就是没有一种普遍最佳的架构对所有问题都是最优的（参见David Wolpert，1996年，“学习算法之间缺乏先验区分”，*神经计算*
    8.7: 1341–1390）。相反，每个问题都需要一个专门的架构。'
- en: Sometimes, we get the impression that machines learn by themselves and that
    current AI is a general approach. In reality, we help the machine learn. And we
    help a lot.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们会有一种印象，即机器是自行学习的，并且当前的AI是一种通用方法。实际上，我们帮助机器学习。而且我们帮助很多。
- en: Summary
  id: totrans-375
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: LLMs are designed to guess the best next word that completes an input prompt.
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs被设计用来猜测完成输入提示的最佳下一个单词。
- en: LLMs subdivide inputs into valid tokens (common words or pieces of words) from
    an internal vocabulary.
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs将输入细分为来自内部词汇表的有效标记（常见单词或单词片段）。
- en: LLMs calculate the probability that each possible token is the one that comes
    next after the input.
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs计算每个可能的标记是输入之后下一个标记的概率。
- en: A wrapper around the LLM enhances its capabilities. For examples, it makes the
    LLM eat its own output repeatedly to generate full outputs, one token at a time.
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在LLM周围添加一个包装器可以增强其功能。例如，它使LLM反复食用自己的输出以生成完整的输出，每次一个标记。
- en: Current LLMs represent information using embedding vector, which are lists of
    numbers.
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前的LLM使用嵌入向量表示信息，这些向量是数字列表。
- en: Current LLMs follow the transformer architecture, which is a method to progressively
    contextualize input tokens.
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前的LLM遵循转换器架构，这是一种逐步对输入标记进行上下文化的方法。
- en: LLMs are created using machine learning, meaning that data is used to define
    missing parameters inside the model.
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs是通过机器学习创建的，这意味着数据用于定义模型内部缺失的参数。
- en: There are different types of machine learning, including supervised, self-supervised,
    and unsupervised learning.
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有不同类型的机器学习，包括监督学习、自监督学习和无监督学习。
- en: In supervised learning, the computer learns by example—it is fed with examples
    of how to perform the task. In the case of self-supervised learning, these examples
    are generated automatically by scanning data.
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在监督学习中，计算机通过示例进行学习——它被提供执行任务的示例。在自监督学习的情况下，这些示例通过扫描数据自动生成。
- en: Popular LLMs were first trained in a self-supervised way using publicly available
    data, and then, they were refined using manually generated data to align them
    to the users’ objectives.
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流行的LLM最初以自监督的方式使用公开数据训练，然后，它们使用手动生成数据进行微调，以使它们与用户的客观目标保持一致。
- en: CNNs are a popular architecture to process other types of data, such as images.
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNNs）是一种流行的架构，用于处理其他类型的数据，例如图像。
- en: CNNs are combined with transformers to create multimodal AI.*******
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNNs）与转换器（transformers）结合以创建多模态人工智能。
