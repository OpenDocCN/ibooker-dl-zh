- en: The universal workflow of machine learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习的通用工作流程
- en: 原文：[https://deeplearningwithpython.io/chapters/chapter06_universal-workflow-of-ml](https://deeplearningwithpython.io/chapters/chapter06_universal-workflow-of-ml)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[https://deeplearningwithpython.io/chapters/chapter06_universal-workflow-of-ml](https://deeplearningwithpython.io/chapters/chapter06_universal-workflow-of-ml)'
- en: Our previous examples have assumed that we already had a labeled dataset to
    start from, and that we could immediately start training a model. In the real
    world, this is often not the case. You don’t start from a dataset; you start from
    a problem.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前的例子假设我们已经有了一个标记的数据集来开始，并且我们可以立即开始训练一个模型。在现实世界中，这通常不是情况。你不是从一个数据集开始的；你是从一个问题开始的。
- en: 'Imagine that you’re launching your own machine learning consulting shop. You
    incorporate, you put up a fancy website, you notify your network. The projects
    start rolling in:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下你正在启动自己的机器学习咨询店。你注册公司，建立了一个华丽的网站，通知了你的网络。项目开始滚滚而来：
- en: A personalized photo search engine for a picture-sharing social network — type
    in “wedding” and retrieve all the pictures you took at weddings, without any manual
    tagging needed.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为图片分享社交网络的个性化照片搜索引擎 — 输入“婚礼”并检索你在婚礼上拍摄的所有照片，无需任何手动标记。
- en: Flagging spam and offensive text content among the posts of a budding chat app.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在新兴的聊天应用帖子中标记垃圾邮件和攻击性文本内容。
- en: Building a music recommendation system for users of an online radio.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为在线电台的用户构建音乐推荐系统。
- en: Detecting credit card fraud for an e-commerce website.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为电子商务网站检测信用卡欺诈。
- en: Predicting display ad click-through rate to decide which ad to serve to a given
    user at a given time.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预测展示广告的点击通过率，以决定在特定时间向特定用户展示哪个广告。
- en: Flagging anomalous cookies on the conveyor belt of a cookie-manufacturing line.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在饼干制造线的传送带上标记异常饼干。
- en: Using satellite images to predict the location of as-yet unknown archaeological
    sites.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用卫星图像预测尚未发现的考古遗址的位置。
- en: It would be very convenient if you could import the correct dataset from `keras.datasets`
    and start fitting some deep learning models. Unfortunately, in the real world,
    you’ll have to start from scratch.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你能从 `keras.datasets` 导入正确的数据集并开始拟合一些深度学习模型，那将非常方便。不幸的是，在现实世界中，你必须从头开始。
- en: In this chapter, you’ll learn about the universal step-by-step blueprint that
    you can use to approach and solve any machine learning problem, like those previously
    listed. This template will bring together and consolidate everything you’ve learned
    in chapters 4 and 5 and give you the wider context that should anchor what you
    will learn in the next chapters.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将了解可以用来接近和解决任何机器学习问题（如之前所列）的通用逐步蓝图。这个模板将汇集和巩固你在第4章和第5章中学到的所有内容，并为你提供更广泛的背景，这将为你将在下一章中学习的内容提供锚点。
- en: 'The universal workflow of machine learning is broadly structured in three parts:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的通用工作流程大致分为三个部分：
- en: '*Define the task* — Understand the problem domain and the business logic underlying
    what the customer asked. Collect a dataset, understand what the data represents,
    and choose how you will measure success on the task.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*定义任务* — 理解问题域和客户所提要求背后的业务逻辑。收集数据集，理解数据代表什么，并选择你将如何衡量任务上的成功。'
- en: '*Develop a model* — Prepare your data so that it can be processed by a machine
    learning model, select a model evaluation protocol and a simple baseline to beat,
    train a first model that has generalization power that can overfit, and then regularize
    and tune your model until you achieve the best possible generalization performance.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*开发一个模型* — 准备你的数据以便机器学习模型可以处理，选择一个模型评估协议和一个简单的基线来超越，训练一个具有泛化能力但可能过拟合的第一个模型，然后正则化和调整你的模型，直到你达到最佳可能的泛化性能。'
- en: '*Deploy the model* — Present your work to stakeholders, ship the model to a
    web server, a mobile app, a web page, or an embedded device, monitor the model’s
    performance in the wild, and start collecting the data you’ll need to build the
    next model generation.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*部署模型* — 向利益相关者展示你的工作，将模型部署到网络服务器、移动应用、网页或嵌入式设备上，监控模型在野外的性能，并开始收集你将需要用于构建下一个模型生成所需的数据。'
- en: Let’s dive in.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨。
- en: Defining the task
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义任务
- en: You can’t do good work without a deep understanding of the context of what you’re
    doing. Why is your customer trying to solve this particular problem? What value
    will they derive from the solution? How will your model be used? How will it fit
    into your customer’s business processes? What kind of data is available or could
    be collected? What kind of machine learning task can be mapped to the business
    problem?
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 没有对你所做事情的背景有深入的理解，你无法做好工作。为什么你的客户想要解决这个特定问题？他们将从解决方案中获得什么价值？你的模型将如何被使用？它将如何融入客户的企业流程？有什么类型的数据可用或可以收集？可以将哪种机器学习任务映射到商业问题？
- en: Framing the problem
  id: totrans-20
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建问题
- en: 'Framing a machine learning problem usually involves many detailed discussions
    with stakeholders. Here are the questions that should be on top of your min:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 构建机器学习问题通常涉及与利益相关者的许多详细讨论。以下是你应该放在首位的问题：
- en: 'What will your input data be? What are you trying to predict? You can only
    learn to predict something if you have available training data: for example, you
    can only learn to classify the sentiment of movie reviews if you have both movie
    reviews and sentiment annotations available. As such, data availability is usually
    the limiting factor at this stage. In many cases, you will have to resort to collecting
    and annotating new datasets yourself (which we cover in the next section).'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的输入数据将是什么？你试图预测什么？只有在你有可用训练数据的情况下，你才能学会预测某物：例如，只有在你有电影评论和情感注释可用的情况下，你才能学会分类电影评论的情感。因此，数据可用性通常是这一阶段的限制因素。在许多情况下，你将不得不自己收集和注释新的数据集（我们将在下一节中介绍）。
- en: 'What type of machine learning task are you facing? Is it binary classification?
    Multiclass classification? Scalar regression? Vector regression? Multiclass, multilabel
    classification? Image segmentation? Ranking? Something else, like clustering,
    generation, or reinforcement learning? In some cases, it may be that machine learning
    isn’t even the best way to make sense of your data, and you should use something
    else, such as plain old-school statistical analysis:'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你正在面对哪种机器学习任务？是二分类？多分类？标量回归？向量回归？多分类、多标签分类？图像分割？排序？其他，比如聚类、生成或强化学习？在某些情况下，可能机器学习甚至不是理解你的数据的最佳方式，你应该使用其他方法，例如传统的统计分析：
- en: The photo search engine project is a multiclass, multilabel classification task.
  id: totrans-24
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图片搜索引擎项目是一个多分类、多标签分类任务。
- en: The spam detection project is a binary classification task. If you set “offensive
    content” as a separate class, it’s a three-way classification task.
  id: totrans-25
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 垃圾邮件检测项目是一个二分类任务。如果你将“攻击性内容”作为一个单独的类别，它就是一个三分类任务。
- en: The music recommendation engine turns out to be better handled not via deep
    learning, but via matrix factorization (collaborative filtering).
  id: totrans-26
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音乐推荐引擎的解决方案不是通过深度学习，而是通过矩阵分解（协同过滤）来处理的。
- en: The credit card fraud detection project is a binary classification task.
  id: totrans-27
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信用卡欺诈检测项目是一个二分类任务。
- en: The click-through rate prediction project is a scalar regression task.
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击率预测项目是一个标量回归任务。
- en: Anomalous cookie detection is a binary classification task, but it will also
    require an object detection model as a first stage to correctly crop out the cookies
    in raw images. Note that the set of machine learning techniques known as “anomaly
    detection” would not be a good fit in this setting!
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常饼干检测是一个二分类任务，但它还需要一个作为第一阶段的对象检测模型来正确裁剪原始图像中的饼干。请注意，被称为“异常检测”的机器学习技术集合在这个设置中可能并不适用！
- en: 'The project about finding new archaeological sites from satellite images is
    an image similarity ranking task: you need to retrieve new images that look the
    most like known archaeological sites.'
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从卫星图像中寻找新考古遗址的项目是一个图像相似性排序任务：你需要检索出看起来最像已知考古遗址的新图像。
- en: What do existing solutions look like? Perhaps your customer already has a hand-crafted
    algorithm that handles spam filtering or credit card fraud detection — with lots
    of nested `if` statements. Perhaps a human is currently in charge of manually
    handling the process considered — monitoring the conveyor belt at the cookie plant
    and manually removing the bad cookies, or crafting playlists of song recommendations
    to be sent out to users who liked a specific artist. You should make sure to understand
    what systems are already in place, and how they work.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现有的解决方案是什么样的？也许你的客户已经有一个手工制作的算法来处理垃圾邮件过滤或信用卡欺诈检测——包含大量的嵌套`if`语句。也许有人目前负责手动处理这个过程——在饼干工厂监控传送带并手动移除坏饼干，或者为喜欢特定艺术家的用户制作歌曲推荐播放列表。你应该确保理解已经存在的系统，以及它们是如何工作的。
- en: Are there particular constraints you will need to deal with? For example, you
    could find out that the app for which you’re building a spam detection system
    is strictly end-to-end encrypted, so that the spam detection model will have to
    live on the end-user’s phone, and must be trained on an external dataset. Perhaps
    the cookie-filtering model has such latency constraints that it will need to run
    on an embedded device at the factory rather than on a remote server. You should
    understand the full context in which your work will fit.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要处理特定的约束条件吗？例如，你可能发现你正在为构建垃圾邮件检测系统的应用，该应用是严格端到端加密的，因此垃圾邮件检测模型将不得不运行在终端用户的手机上，并且必须在外部数据集上训练。也许cookie过滤模型有如此大的延迟限制，它需要在工厂的嵌入式设备上运行，而不是在远程服务器上。你应该理解你的工作将适应的完整背景。
- en: 'Once you’ve done your research, you should know what your inputs will be, what
    your targets will be, and what broad type of machine learning task the problem
    maps to. Be aware of the hypotheses you’re making at this stage:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你完成了研究，你应该知道你的输入将是什么，你的目标将是什么，以及问题映射到的广泛类型的机器学习任务。在这个阶段，要意识到你正在提出的假设：
- en: You hypothesize that your targets can be predicted given your inputs.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你假设给定你的输入，可以预测你的目标。
- en: You hypothesize that the data that’s available (or that you will soon collect)
    is sufficiently informative to learn the relationship between inputs and targets.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你假设可用的数据（或你将很快收集的数据）足够信息量，可以学习输入和目标之间的关系。
- en: Until you have a working model, these are merely hypotheses, waiting to be validated
    or invalidated. Not all problems can be solved with machine learning; just because
    you’ve assembled examples of inputs X and targets Y doesn’t mean X contains enough
    information to predict Y. For instance, if you’re trying to predict the movements
    of a stock on the stock market given its recent price history, you’re unlikely
    to succeed, because price history doesn’t contain much predictive information.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在你有一个工作模型之前，这些只是假设，等待被验证或证伪。并不是所有问题都可以用机器学习来解决；仅仅因为你有输入X和目标Y的例子，并不意味着X包含足够的信息来预测Y。例如，如果你试图根据最近的股价历史预测股市中股票的走势，你不太可能成功，因为价格历史并不包含很多预测信息。
- en: Collecting a dataset
  id: totrans-37
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 收集数据集
- en: 'Once you understand the nature of the task and you know what your inputs and
    targets are going to be, it’s time for data collection — the most arduous, time-consuming,
    and costly part of most machine learning projects:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你理解了任务的性质，并且知道你的输入和目标将是什么，那么就是数据收集的时候了——这是大多数机器学习项目中最为艰巨、耗时且昂贵的部分：
- en: The photo search engine project requires you to first select the set of labels
    you want to classify — you settle on 10,000 common image categories. Then, you
    need to manually tag hundreds of thousands of your past user-uploaded images with
    labels from this set.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 照片搜索引擎项目要求你首先选择你想要分类的标签集——你确定了10,000个常见的图像类别。然后，你需要手动将成千上万你过去用户上传的图像用这个集合中的标签进行标记。
- en: For the chat app spam detection project, because user chats are end-to-end encrypted,
    you cannot use their contents for training a model. You need to gain access to
    a separate dataset of tens of thousands of unfiltered social media posts, and
    manually tag them as spam, offensive, or acceptable.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于聊天应用垃圾邮件检测项目，因为用户聊天是端到端加密的，你不能使用它们的内文来训练模型。你需要获取一个包含数万条未过滤社交媒体帖子的独立数据集，并手动将其标记为垃圾邮件、冒犯性或可接受。
- en: For the music recommendation engine, you can just use the “likes” of your users.
    No new data needs to be collected. Likewise, for the click-through rate prediction
    project, you have an extensive record of click-through rate for your past ads,
    going back years.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于音乐推荐引擎，你可以直接使用用户的“喜欢”。不需要收集新的数据。同样，对于点击率预测项目，你有一份广泛的点击率记录，这些记录可以追溯到多年前的广告。
- en: For the cookie-flagging model, you will need to install cameras above the conveyor
    belts to collect tens of thousands of images, and then someone will need to manually
    label these images. The people who know how to do this currently work at the cookie
    factory — but it doesn’t seem too difficult, you should be able to train people
    to do it.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于饼干标记模型，你需要在输送带上方安装摄像头来收集数万张图像，然后有人需要手动标注这些图像。目前知道如何做这项工作的人正在饼干工厂工作——但这似乎并不太难，你应该能够训练人们来做这件事。
- en: The satellite imagery project will require a team of archaeologists to collect
    a database of existing sites of interest, and for each site, you will need to
    find existing satellite images taken in different weather conditions. To get a
    good model, you’re going to need thousands of different sites.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卫星图像项目将需要一支考古学家团队来收集现有兴趣点的数据库，并且对于每个地点，你需要找到在不同天气条件下拍摄的存在卫星图像。为了得到一个好的模型，你需要数千个不同的地点。
- en: You’ve learned in chapter 5 that a model’s ability to generalize comes almost
    entirely from the properties of the data it is trained on — the number of data
    points you have, the reliability of your labels, the quality of your features.
    A good dataset is an asset worthy of care and investment. If you get an extra
    50 hours to spend on a project, chances are that the most effective way to allocate
    them is to collect more data, rather than search for incremental modeling improvements.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 你在第五章中学到，一个模型泛化能力几乎完全来自其训练数据的特点——你拥有的数据点的数量，你标签的可靠性，你特征的质量。一个好的数据集是一个值得关注和投资的资产。如果你有额外的50小时可以用于项目，那么最有效的方式可能是收集更多数据，而不是寻找增量模型改进。
- en: The point that data matters more than algorithms was most famously made in a
    2009 paper by Google researchers titled “The Unreasonable Effectiveness of Data”
    (the title is a riff on the well-known 1960 book *The Unreasonable Effectiveness
    of Mathematics in the Natural Sciences* by Eugene Wigner). This was before deep
    learning was popular, but remarkably, the rise of deep learning has only increased
    the importance of data.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 数据比算法更重要这一点在2009年一篇由谷歌研究人员撰写的论文中被最著名地提出，该论文题为“数据的不可思议有效性”（标题是对尤金·维格纳1960年出版的著名书籍《数学在自然科学中的不可思议有效性》的改编）。这在大规模深度学习流行之前，但令人惊讶的是，深度学习的兴起反而增加了数据的重要性。
- en: 'If you’re doing supervised learning, then once you’ve collected inputs (such
    as images) you’re going to need *annotations* for them (such as tags for those
    images): the targets you will train your model to predict.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在进行监督学习，那么一旦你收集了输入（如图像），你将需要为它们提供*标注*（如图像的标签）：你将训练模型预测的目标。
- en: Sometimes, annotations can be retrieved automatically — for instance, in the
    case of our music recommendation task or our click-through rate prediction task.
    But often, you have to annotate your data by hand. This is a labor-heavy process.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，标注可以自动检索——例如，在我们的音乐推荐任务或点击率预测任务中。但通常，你必须手动标注你的数据。这是一个劳动密集型的过程。
- en: Investing in data annotation infrastructure
  id: totrans-48
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 投资数据标注基础设施
- en: 'Your data annotation process will determine the quality of your targets, which,
    in turn, determines the quality of your model. Carefully consider the options
    you have available:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 你的数据标注过程将决定你的目标质量，这反过来又决定了你的模型质量。仔细考虑你拥有的选项：
- en: Should you annotate the data yourself?
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你是否应该自己标注数据？
- en: Should you use a crowdsourcing platform like Mechanical Turk to collect labels?
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你是否应该使用像Mechanical Turk这样的众包平台来收集标签？
- en: Should you use the services of a specialized data-labeling company?
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你是否应该使用专门的数据标注公司的服务？
- en: Outsourcing can potentially save you time and money but takes away control.
    Using something like Mechanical Turk is likely to be inexpensive and to scale
    well, but your annotations may end up being quite noisy.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 外包可能可以节省你的时间和金钱，但会失去控制。使用像Mechanical Turk这样的服务可能是低成本的，并且可以很好地扩展，但你的标注可能最终会相当嘈杂。
- en: 'To pick the best option, consider the constraints you’re working with:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了选择最佳选项，考虑你正在工作的限制条件：
- en: Do the data labelers need to be subject matter experts, or could anyone annotate
    the data? The labels for a cat-versus-dog image classification problem can be
    selected by anyone, but those for a dog breed classification task require specialized
    knowledge. Meanwhile, annotating CT scans of bone fractures pretty much requires
    a medical degree.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据标注员需要是领域专家吗，或者任何人都可以标注数据？猫狗图像分类问题的标签可以被任何人选择，但对于狗品种分类任务则需要专业知识。同时，标注骨折的CT扫描几乎需要医学学位。
- en: If annotating the data requires specialized knowledge, can you train people
    to do it? If not, how can you get access to relevant experts?
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果标注数据需要专业知识，你能培训人员来做吗？如果不能，你如何获取相关专家的帮助？
- en: Do you, yourself, understand the way experts come up with the annotations? If
    you don’t, you will have to treat your dataset as a black box, and you won’t be
    able to perform manual feature engineering — this isn’t critical, but it can be
    limiting.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你自己是否理解专家是如何生成标注的？如果你不理解，你将不得不将你的数据集视为一个黑盒，你将无法进行手动特征工程——这虽然不是关键，但可能会有限制。
- en: If you decide to label your data in-house, ask yourself what software you will
    use to record annotations. You may well need to develop that software yourself.
    Productive data annotation software will save you a lot of time, so it’s something
    worth investing in early in a project.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你决定在内部标注数据，问问自己你将使用什么软件来记录标注。你可能需要自己开发那个软件。高效的数据标注软件可以为你节省大量时间，所以在项目早期就值得投资。
- en: Beware of nonrepresentative data
  id: totrans-59
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 警惕非代表性数据
- en: Machine learning models can only make sense of inputs that are similar to what
    they’ve seen before. As such, it’s critical that the data used for training should
    be *representative* of the production data. This concern should be the foundation
    of all of your data collection work.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型只能理解与它们之前所见相似的输入。因此，用于训练的数据应该能够代表生产数据，这一点至关重要，应该是你所有数据收集工作的基础。
- en: 'Suppose you’re developing an app where users can take pictures of a dish to
    find out its name. You train a model using pictures from an image-sharing social
    network that’s popular with foodies. Come deployment time, and feedback from angry
    users starts rolling in: your app gets the answer wrong 8 times out of 10\. What’s
    going on? Your accuracy on the test set was well over 90%! A quick look at user-uploaded
    data reveals that mobile picture uploads of random dishes from random restaurants
    taken with random smartphones look nothing like the professional-quality, well-lit,
    appetizing pictures you trained the model on: *your training data wasn’t representative
    of the production data*. That’s a cardinal sin — welcome to machine learning hell.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你正在开发一个应用程序，用户可以拍照来查找菜肴的名称。你使用一个受美食爱好者欢迎的图片分享社交网络的图片来训练模型。到了部署时间，愤怒的用户反馈开始涌入：你的应用程序有8次错误。发生了什么？你的测试集准确率远超过90%！快速查看用户上传的数据揭示，随机餐馆随机智能手机拍摄的随机菜肴的移动图片与你训练模型时所用的专业质量、光线充足、令人垂涎的图片大相径庭：*你的训练数据并不代表生产数据*。这是一个严重的错误——欢迎来到机器学习地狱。
- en: If possible, collect data directly from the environment where your model will
    be used. A movie review sentiment classification model should be used on new IMDB
    reviews, not on Yelp restaurant reviews, nor on Twitter status updates. If you
    want to rate the sentiment of a tweet, start by collecting and annotating actual
    tweets — from a similar set of users as those you’re expecting in production.
    If it’s not possible to train on production data, then make sure you fully understand
    how your training and production data differ, and that you are actively correcting
    these differences.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果可能的话，直接从你的模型将使用的环境中收集数据。一个电影评论情感分类模型应该用于新的IMDb评论，而不是Yelp餐厅评论，也不是Twitter状态更新。如果你想对推文的情感进行评分，首先收集并标注实际的推文——来自与你预期在生产中使用的类似用户群体。如果无法在生产数据上训练，那么确保你完全理解你的训练数据和生产数据之间的差异，并且你正在积极纠正这些差异。
- en: A related phenomenon you should be aware of is *concept drift*. You’ll encounter
    concept drift in almost all real-world problems, especially those that deal with
    user-generated data. Concept drift occurs when the properties of the production
    data change over time, causing model accuracy to gradually decay. A music recommendation
    engine trained in the year 2013 may not be very effective today. Likewise, the
    IMDB dataset you worked with was collected in 2011, and a model trained on it
    would likely not perform as well on reviews from 2020 compared to reviews from
    2012, as vocabulary, expressions, and movie genres evolve over time. Concept drift
    is particularly acute in adversarial contexts like credit card fraud detection,
    where fraud patterns change practically every day. Dealing with fast concept drift
    requires constant data collection, annotation, and model retraining.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该注意的一个相关现象是*概念漂移*。你几乎会在所有现实世界的问题中遇到概念漂移，尤其是那些处理用户生成数据的问题。当生产数据的属性随时间变化时，就会发生概念漂移，导致模型精度逐渐下降。2013年训练的音乐推荐引擎可能今天并不太有效。同样，你使用的IMDB数据集是在2011年收集的，基于它的模型在2020年的评论上可能不如2012年的评论表现得好，因为词汇、表达和电影类型随着时间的推移而演变。在对抗性环境（如信用卡欺诈检测）中，概念漂移尤其严重，欺诈模式几乎每天都在变化。处理快速概念漂移需要持续的数据收集、标注和模型重新训练。
- en: Keep in mind that machine learning can only be used to memorize patterns that
    are present in your training data. You can only recognize what you’ve seen before.
    Using machine learning trained on past data to predict the future is making the
    assumption that the future will behave like the past. That often isn’t the case.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，机器学习只能用来记忆训练数据中存在的模式。你只能识别你之前看到过的。使用基于过去数据的机器学习来预测未来是假设未来会像过去一样表现。这通常并不成立。
- en: Understanding your data
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 理解你的数据
- en: 'It’s bad practice to treat a dataset as a black box. Before you start training
    models, you should explore and visualize your data to gain insights about what
    makes it predictive — which will inform feature engineering — and screen for potential
    issues:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据集视为黑盒是不良的做法。在你开始训练模型之前，你应该探索和可视化你的数据，以了解使其具有预测性的因素——这将指导特征工程——并筛选潜在的问题：
- en: If your data includes images or natural language text, take a look at a few
    samples (and their labels) directly.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的数据包含图像或自然语言文本，直接查看一些样本（及其标签）。
- en: If your data contains numerical features, it’s a good idea to plot the histogram
    of feature values to get a feel for the range of values taken and the frequency
    of different values.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的数据包含数值特征，绘制特征值的直方图是一个好主意，以了解值的范围和不同值的频率。
- en: If your data includes location information, plot it on a map. Do any clear patterns
    emerge?
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的数据包含位置信息，将其绘制在地图上。是否有任何明显的模式出现？
- en: Are some samples missing values for some features? If so, you’ll need to deal
    with this when you prepare the data (we cover how to do this in the next section).
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否有一些样本缺少某些特征值？如果是这样，你需要在准备数据时处理这个问题（我们将在下一节中介绍如何做）。
- en: If your task is a classification problem, print the number of instances of each
    class in your data. Are the classes roughly equally represented? If not, you will
    need to account for this imbalance.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的任务是分类问题，打印出数据中每个类别的实例数量。类别是否大致均匀分布？如果不均匀，你需要考虑这种不平衡。
- en: Check for *target leaking* — the presence of features in your data that provide
    information about the targets that may not be available in production. If you’re
    training a model on medical records to predict whether someone will be treated
    for cancer in the future, and the records include the feature “This person has
    been diagnosed with cancer,” then your targets are being artificially leaked into
    your data. Always ask yourself, is every feature in your data something that will
    be available in the same form in production?
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查是否存在*目标泄露*——数据中存在提供关于目标的信息的特征，而这些信息在生产环境中可能不可用。如果你正在使用医疗记录来训练模型以预测某人将来是否会接受癌症治疗，并且记录中包含特征“这个人已被诊断出患有癌症”，那么你的目标就被人为地泄露到数据中。始终问自己，数据中的每个特征在生产环境中是否将以相同的形式可用？
- en: Choosing a measure of success
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择成功度量
- en: To control something, you need to be able to observe it. To achieve success
    on a project, you must first define what you mean by success. Accuracy? Precision
    and recall? Customer retention rate? Your metric for success will guide all of
    the technical choices you will make throughout the project. It should directly
    align with your higher-level goals, such as the business success of your customer.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 要控制某物，你需要能够观察它。要在项目中取得成功，你必须首先定义你所说的成功是什么。准确率？精确率和召回率？客户保留率？你的成功指标将指导你在整个项目中做出的所有技术选择。它应该直接与你的高级目标对齐，例如你客户的商业成功。
- en: For balanced classification problems, where every class is equally likely, accuracy
    and *area under curve* (AUC) of the *receiver operating characteristic* (ROC)
    are common metrics. For class-imbalanced problems, ranking problems, or multilabel
    classification, you can use precision and recall or a metric that counts false
    positives, true positives, false negatives, and true negatives. And it isn’t uncommon
    to have to define your own custom metric by which to measure success. To get a
    sense of the diversity of machine learning success metrics and how they relate
    to different problem domains, it’s helpful to browse the data science competitions
    on Kaggle ([https://kaggle.com](https://kaggle.com)); it showcases a wide range
    of problems and evaluation metrics.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 对于平衡的分类问题，其中每个类别的可能性相等，准确率和**曲线下面积**（AUC）以及**接收者操作特征**（ROC）是常见的指标。对于类别不平衡问题、排名问题或多标签分类，你可以使用精确率和召回率或一个计算假阳性、真阳性、假阴性和真阴性的指标。而且，定义自己的自定义指标来衡量成功并不罕见。为了了解机器学习成功指标的多样性以及它们如何与不同的问题域相关，浏览Kaggle上的数据科学竞赛（[https://kaggle.com](https://kaggle.com)）很有帮助；它展示了广泛的问题和评估指标。
- en: Developing a model
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开发模型
- en: Once you know how you will measure your progress, you can get started with model
    development. Most tutorials and research projects assume that this is the only
    step — skipping problem definition and dataset collection, which are assumed to
    be already done, and skipping model deployment and maintenance, which is assumed
    to be handled by someone else. In fact, model development is only *one step* in
    the machine learning workflow, and if you ask me, it’s not the most difficult
    one. The hardest things in machine learning are framing problems and collecting,
    annotating, and cleaning data. So cheer up, what comes next will be easy in comparison!
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你知道如何衡量你的进度，你就可以开始模型开发了。大多数教程和研究项目都假设这是唯一的一步——跳过问题定义和数据集收集，这些被认为是已经完成的，并且跳过模型部署和维护，这些被认为是其他人负责的。实际上，模型开发只是机器学习工作流程中的一步，如果问我，这并不是最困难的一步。机器学习中最困难的事情是定义问题、收集、标注和清理数据。所以加油，接下来与比较起来将会容易得多！
- en: Preparing the data
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 准备数据
- en: As you’ve learned before, deep learning models typically don’t ingest raw data.
    Data preprocessing aims at making the raw data at hand more amenable to neural
    networks. This includes vectorization, normalization, or handling missing values.
    Many preprocessing techniques are domain specific (for example, specific to text
    data or image data); we’ll cover those in the following chapters as we encounter
    them in practical examples. For now, we’ll review the basics that are common to
    all data domains.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如你之前所学，深度学习模型通常不会直接摄入原始数据。数据预处理的目标是使手头的原始数据更适合神经网络处理。这包括向量化、归一化或处理缺失值。许多预处理技术是特定领域的（例如，特定于文本数据或图像数据）；我们将在遇到实际示例时介绍这些技术。现在，我们将回顾适用于所有数据域的基本内容。
- en: Vectorization
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 向量化
- en: All inputs and targets in a neural network must be typically tensors of floating-point
    data (or, in specific cases, tensors of integers or strings). Whatever data you
    need to process — sound, images, text — you must first turn into tensors, a step
    called *data vectorization*. For instance, in the two previous text classification
    examples from chapter 4, we started from text represented as lists of integers
    (standing for sequences of words), and we used multi-hot encoding to turn them
    into a tensor of `float32` data. In the examples of classifying digits and predicting
    house prices, the data already came in vectorized form, so you were able to skip
    this step.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络中的所有输入和目标通常必须是浮点数据张量（或在特定情况下，整数或字符串的张量）。无论你需要处理什么数据——声音、图像、文本——你都必须首先将其转换为张量，这一步称为*数据向量化*。例如，在第四章的两个先前的文本分类示例中，我们从表示为整数列表（代表单词序列）的文本开始，我们使用多热编码将它们转换为`float32`数据张量。在分类数字和预测房价的示例中，数据已经以向量化的形式提供，因此你可以跳过这一步。
- en: Value normalization
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 值归一化
- en: In the MNIST digit-classification example from chapter 2, you started from image
    data encoded as integers in the 0–255 range, encoding grayscale values. Before
    you fed this data into your network, you had to cast it to `float32` and divide
    by 255 so you’d end up with floating-point values in the 0–1 range. Similarly,
    when predicting house prices, you started from features that took a variety of
    ranges — some features had small floating-point values, others had fairly large
    integer values. Before you fed this data into your network, you had to normalize
    each feature independently so that it had a standard deviation of 1 and a mean
    of 0.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二章的MNIST数字分类示例中，你从0-255范围内的整数编码图像数据开始，编码灰度值。在你将此数据输入网络之前，你必须将其转换为`float32`并除以255，以便最终得到0-1范围内的浮点值。同样，在预测房价时，你从具有各种范围的特性开始——一些特征具有小的浮点值，而其他特征则具有相当大的整数值。在你将此数据输入网络之前，你必须独立归一化每个特征，使其具有标准差为1和均值为0。
- en: 'In general, it isn’t safe to feed into a neural network data that takes relatively
    large values (for example, multi-digit integers, which are much larger than the
    initial values taken by the weights of a network) or data that is heterogeneous
    (for example, data where one feature is in the range 0–1, and another is in the
    range 100–200). Doing so can trigger large gradient updates that will prevent
    the network from converging. To make learning easier for your network, your data
    should have the following characteristics:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，将相对较大的值（例如，多位整数，这些值远大于网络的初始权重值）或异构数据（例如，一个特征的范围在0-1之间，另一个特征的范围在100-200之间）输入神经网络是不安全的。这样做可能会触发大的梯度更新，从而阻止网络收敛。为了使网络的学习更容易，你的数据应具有以下特征：
- en: '*Take small values*  — Typically, most values should be in the 0–1 range.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*取小值*——通常，大多数值应在0-1范围内。'
- en: '*Be homogeneous* — That is, all features should take values in roughly the
    same range.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*保持同质性*——也就是说，所有特征应取大致相同的值范围。'
- en: 'Additionally, the following stricter normalization practice is common and can
    help, although it isn’t always necessary (for example, you didn’t do this in the
    digit-classification example):'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，以下更严格的归一化实践很常见，并且可能有所帮助，尽管并不总是必要的（例如，在数字分类示例中你没有这样做）：
- en: Normalize each feature independently to have a mean of 0.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独立归一化每个特征，使其均值为0。
- en: Normalize each feature independently to have a standard deviation of 1.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 独立归一化每个特征，使其标准差为1。
- en: 'This is easy to do with NumPy arrays:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过NumPy数组轻松完成：
- en: '[PRE0]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Handling missing values
  id: totrans-92
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 处理缺失值
- en: You may sometimes have missing values in your data. For instance, in the house
    price example, the second feature was the median age of houses in the district.
    What if this feature wasn’t available for all samples? You’d then have missing
    values in the training or test data.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能有时会在数据中遇到缺失值。例如，在房价示例中，第二个特征是该地区房屋的中位年龄。如果这个特征对于所有样本都不可用怎么办？那么在训练或测试数据中就会出现缺失值。
- en: 'You could just discard the feature entirely, but you don’t necessarily have
    to:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以完全丢弃该特征，但并不一定必须这样做：
- en: If the feature is categorical, it’s safe to create a new category that means
    “the value is missing.” The model will automatically learn what this implies with
    respect to the targets.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果特征是分类的，创建一个表示“值缺失”的新类别是安全的。模型将自动学习这与目标之间的关系。
- en: If the feature is numerical, avoid inputting an arbitrary value like 0 because
    it may create a discontinuity in the latent space formed by your features, making
    it harder for a model trained on it to generalize. Instead, consider replacing
    the missing value with the average or median value for the feature in the dataset.
    You could also train a model to predict the feature value given the values of
    other features.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果特征是数值型的，避免输入一个任意的值，比如0，因为这可能会在你的特征形成的潜在空间中造成不连续性，使得在它上面训练的模型更难泛化。相反，考虑用数据集中该特征的均值或中位数来替换缺失值。你也可以训练一个模型来预测给定其他特征值的特征值。
- en: 'Note that if you’re expecting missing categorical features in the test data,
    but the network was trained on data without any missing values, the network won’t
    have learned to ignore missing values! In this situation, you should artificially
    generate training samples with missing entries: copy some training samples several
    times, and drop some of the categorical features that you expect are likely to
    be missing in the test data.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果你预计测试数据中会有缺失的类别特征，但网络是在没有缺失值的数据上训练的，那么网络就没有学会忽略缺失值！在这种情况下，你应该人工生成带有缺失条目的训练样本：复制一些训练样本多次，并丢弃你预计在测试数据中可能缺失的某些类别特征。
- en: Choosing an evaluation protocol
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择一个评估协议
- en: As you’ve learned in the previous chapter, the purpose of a model is to achieve
    generalization, and every modeling decision you will make throughout the model
    development process will be guided by *validation metrics* that seek to measure
    generalization performance. The goal of your validation protocol is to accurately
    estimate what your success metric of choice (such as accuracy) will be on actual
    production data. The reliability of that process is critical to building a useful
    model.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在上一章所学，模型的目的在于实现泛化，你在整个模型开发过程中所做的每一个建模决策都将由寻求衡量泛化性能的*验证指标*所指导。你的验证协议的目标是准确估计你选择的成功指标（如准确率）在实际生产数据上的表现。这个过程的可信度对于构建一个有用的模型至关重要。
- en: 'In chapter 5, we’ve reviewed three common evaluation protocols:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在第5章中，我们回顾了三种常见的评估协议：
- en: '*Maintaining a hold-out validation set*  — The way to go when you have plenty
    of data'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*维护一个保留验证集* — 当你拥有大量数据时的可行方法'
- en: '*Doing K-fold cross-validation*  — The right choice when you have too few samples
    for hold-out validation to be reliable'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*执行K折交叉验证* — 当你拥有的样本太少，保留验证集不可靠时的正确选择'
- en: '*Doing iterated K-fold validation*  — For performing highly accurate model
    evaluation when little data is available'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*执行迭代K折验证* — 当数据很少时进行高度精确的模型评估'
- en: Just pick one of these. In most cases, the first will work well enough. As you’ve
    learned before, always be mindful of the *representativity* of your validation
    set(s) and be careful not to have redundant samples between your training set
    and your validation set(s).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 只需从中选择一个。在大多数情况下，第一个就足够好了。正如你之前所学的，始终要关注你的验证集（s）的*代表性*，并小心不要在训练集和验证集（s）之间有重复的样本。
- en: Beating a baseline
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 打败基线
- en: As you start working on the model itself, your initial goal is to achieve *statistical
    power*, as you saw in chapter 5 — that is, to develop a small model that is capable
    of beating a simple baseline.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 当你开始着手构建模型本身时，你的初始目标是实现*统计功效*，正如你在第5章所见——也就是说，开发一个能够打败简单基线的小型模型。
- en: 'At this stage, these are the three most important things you should focus on:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，你应该关注以下三个最重要的方面：
- en: '*Feature engineering* — Filter out uninformative features (feature selection)
    and use your knowledge of the problem to develop new features that are likely
    to be useful.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*特征工程* — 过滤掉无信息特征（特征选择）并利用你对问题的了解来开发可能有用的新特征。'
- en: '*Selecting the correct architecture priors* — What type of model architecture
    will you use? A densely connected network, a ConvNet, a recurrent neural network,
    a Transformer? Is deep learning even a good approach for the task, or should you
    use something else?'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*选择正确的架构先验* — 你将使用哪种类型的模型架构？一个密集连接的网络、一个卷积神经网络（ConvNet）、一个循环神经网络、一个Transformer？深度学习对于这个任务来说甚至是一个好的方法吗，或者你应该使用其他方法？'
- en: '*Selecting a good enough training configuration* — What loss function should
    you use? What batch size and learning rate?'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*选择一个足够好的训练配置* — 你应该使用什么损失函数？什么批大小和学习率？'
- en: For most problems, there are existing templates you can start from. You’re not
    the first person to try to build a spam detector, a music recommendation engine,
    or an image classifier. Make sure to research prior art to identify the feature
    engineering techniques and model architectures that are most likely to perform
    well on your task.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数问题，你可以从现有的模板开始。你不是第一个尝试构建垃圾邮件检测器、音乐推荐引擎或图像分类器的人。确保研究先前的艺术，以确定最有可能在你的任务上表现良好的特征工程技术和模型架构。
- en: 'Note that it’s not always possible to achieve statistical power. If you can’t
    beat a simple baseline after trying multiple reasonable architectures, it may
    be that the answer to the question you’re asking isn’t present in the input data.
    Remember that you’re making two hypotheses:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，并不总是能够实现统计能力。如果你尝试了多个合理的架构后仍然无法击败一个简单的基线，那么你可能问的问题的答案可能不在输入数据中。记住，你正在做出两个假设：
- en: You hypothesize that your outputs can be predicted given your inputs.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你假设，给定你的输入，可以预测你的输出。
- en: You hypothesize that the available data is sufficiently informative to learn
    the relationship between inputs and outputs.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你假设可用的数据足够有信息量，可以学习输入和输出之间的关系。
- en: It may well be that these hypotheses are false, in which case you must go back
    to the drawing board.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 这些假设可能是不正确的，在这种情况下，你必须回到起点。
- en: 'Scale up: developing a model that overfits'
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 扩大规模：开发一个过拟合的模型
- en: Once you’ve obtained a model that has statistical power, the question becomes,
    is your model sufficiently powerful? Does it have enough layers and parameters
    to properly model the problem at hand? For instance, a logistic regression model
    has statistical power on MNIST but wouldn’t be sufficient to solve the problem
    well. Remember that the universal tension in machine learning is between optimization
    and generalization; the ideal model is one that stands right at the border between
    underfitting and overfitting, between undercapacity and overcapacity. To figure
    out where this border lies, first you must cross it.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你获得了一个具有统计能力的模型，问题就变成了，你的模型是否足够强大？它是否有足够的层和参数来正确地模拟当前的问题？例如，逻辑回归模型在MNIST上具有统计能力，但不足以很好地解决这个问题。记住，机器学习中的普遍张力在于优化和泛化之间；理想模型是那种正好位于欠拟合和过拟合、欠容量和过容量之间的模型。为了找出这个边界的位置，首先你必须跨越它。
- en: 'To figure out how big a model you’ll need, you must develop a model that overfits.
    This is fairly easy, as you learned in chapter 5:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找出你需要多大的模型，你必须开发一个过拟合的模型。这相当容易，正如你在第5章中学到的：
- en: Add layers.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加层。
- en: Make the layers bigger.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使层更大。
- en: Train for more epochs.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练更多的轮次。
- en: Always monitor the training loss and validation loss, as well as the training
    and validation values for any metrics you care about. When you see that the model’s
    performance on the validation data begins to degrade, you’ve achieved overfitting.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 总是监控训练损失和验证损失，以及你关心的任何指标的训练和验证值。当你看到模型在验证数据上的性能开始下降时，你就实现了过拟合。
- en: Regularizing and tuning your model
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 规范化和调整你的模型
- en: Once you’ve achieved statistical power and you’re able to overfit, you know
    you’re on the right path. At this point, your goal becomes to maximize generalization
    performance.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你获得了统计能力并且能够过拟合，你就知道你走在了正确的道路上。此时，你的目标变成了最大化泛化性能。
- en: 'This phase will take the most time: you’ll repeatedly modify your model, train
    it, evaluate on your validation data (not the test data, at this point), modify
    it again, and repeat, until the model is as good as it can get. Here are some
    things you should try:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这个阶段将花费最多的时间：你将反复修改你的模型，训练它，在验证数据上评估（此时不是测试数据），再次修改，然后重复，直到模型尽可能好。以下是一些你应该尝试的事情：
- en: Try different architectures; add or remove layers.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试不同的架构；添加或移除层。
- en: Add dropout.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加dropout。
- en: If your model is small, add L1 or L2 regularization.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的模型很小，添加L1或L2正则化。
- en: Try different hyperparameters (such as the number of units per layer or the
    learning rate of the optimizer) to find the optimal configuration.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试不同的超参数（例如每层的单元数或优化器的学习率）以找到最佳配置。
- en: 'Optionally, iterate on data curation or feature engineering: collect and annotate
    more data, develop better features, or remove features that don’t seem to be informative.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可选地，迭代数据整理或特征工程：收集和标注更多数据，开发更好的特征，或者移除似乎没有信息量的特征。
- en: It’s possible to automate a large chunk of this work by using *automated hyperparameter
    tuning software*, such as KerasTuner. We’ll cover this in chapter 18.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过使用*自动超参数调整软件*，如KerasTuner，来自动化大部分这项工作。我们将在第18章中介绍这一点。
- en: 'Be mindful of the following: every time you use feedback from your validation
    process to tune your model, you leak information about the validation process
    into the model. Repeated just a few times, this is innocuous; however, done systematically
    over many iterations, it will eventually cause your model to overfit to the validation
    process (even though no model is directly trained on any of the validation data).
    This makes the evaluation process less reliable.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意以下几点：每次你使用验证过程中的反馈来调整你的模型时，你都会将有关验证过程的信息泄露到模型中。重复几次是无害的；然而，在许多迭代中系统地这样做，最终会导致你的模型过度拟合验证过程（即使没有模型直接在验证数据上训练）。这使得评估过程变得不太可靠。
- en: Once you’ve developed a satisfactory model configuration, you can train your
    final production model on all the available data (training and validation) and
    evaluate it one last time on the test set. If it turns out that performance on
    the test set is significantly worse than the performance measured on the validation
    data, this may mean either that your validation procedure wasn’t reliable after
    all, or that you began overfitting to the validation data while tuning the parameters
    of the model. In this case, you may want to switch to a more reliable evaluation
    protocol (such as iterated K-fold validation).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你开发出一个令人满意的模型配置，你就可以在所有可用数据（训练和验证）上训练你的最终生产模型，并在测试集上最后一次评估它。如果测试集上的性能明显低于验证数据上的性能，这可能意味着你的验证程序最终并不可靠，或者你在调整模型参数时开始过度拟合验证数据。在这种情况下，你可能想切换到一个更可靠的评估协议（例如迭代K折验证）。
- en: Deploying your model
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署你的模型
- en: After your model has successfully cleared its final evaluation on the test set,
    it’s ready to be deployed and to begin its productive life.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的模型成功通过测试集的最终评估后，它就准备好部署并开始其生产生活。
- en: Explaining your work to stakeholders and setting expectations
  id: totrans-136
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 向利益相关者解释你的工作并设定期望
- en: Success and customer trust are about consistently meeting or exceeding people’s
    expectations; the actual system you deliver is only half of that picture. The
    other half is setting appropriate expectations before launch.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 成功和客户信任关乎始终满足或超越人们的期望；你实际交付的系统只是这幅图的一半。另一半是在发布前设定适当的期望。
- en: The expectations of nonspecialists toward AI systems are often unrealistic.
    For example, they might expect that the system “understands” its task and is capable
    of exercising human-like common sense in the context of the task. To address this,
    you should consider showing some examples of the *failure modes* of your model
    (for instance, show what incorrectly classified samples look like, especially
    those for which the misclassification seems surprising).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 非专业人士对人工智能系统的期望往往是不切实际的。例如，他们可能期望系统“理解”其任务，并在任务背景下具备类似人类的常识。为了解决这个问题，你应该考虑展示一些你模型（例如，展示被错误分类的样本看起来是什么样子，特别是那些误分类似乎令人惊讶的样本）的*故障模式*。
- en: They might also expect human-level performance, especially for processes that
    were previously handled by people. Most machine learning models, because they
    are (imperfectly) trained to approximate human-generated labels, do not nearly
    get there. You should clearly convey model performance expectations. Avoid using
    abstract statements like “The model has 98% accuracy” (which most people mentally
    round up to 100%), and prefer talking, for instance, about false-negative rates
    and false- positive rates. You could say, “With these settings, the fraud detection
    model would have a 5% false-negative rate and a 2.5% false-positive rate. Every
    day, an average of 200 valid transactions would be flagged as fraudulent and sent
    for manual review, and an average of 14 fraudulent transactions would be missed.
    An average of 266 fraudulent transactions would be correctly caught.” Clearly
    relate the model’s performance metrics to business goals.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 他们可能还期望达到人类水平的表现，尤其是对于以前由人类处理的流程。大多数机器学习模型，因为它们（不完美地）被训练来近似人类生成的标签，远远达不到这个水平。您应该清楚地传达模型性能预期。避免使用像“该模型准确率为98%”这样的抽象陈述（大多数人会在心里将其四舍五入到100%），而更倾向于谈论假阴性率和假阳性率。例如，您可以说：“在这些设置下，欺诈检测模型的假阴性率为5%，假阳性率为2.5%。每天，平均有200笔有效交易会被标记为欺诈并送交人工审查，平均有14笔欺诈交易会被遗漏。平均有266笔欺诈交易会被正确捕获。”明确地将模型性能指标与业务目标联系起来。
- en: You should also make sure to discuss with stakeholders the choice of key launch
    parameters — for instance, the probability threshold at which a transaction should
    be flagged (different thresholds will produce different false-negative and false-positive
    rates). Such decisions involve tradeoffs that can only be handled with a deep
    understanding of the business context.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 您还应该确保与利益相关者讨论关键发布参数的选择——例如，在哪个概率阈值下应标记交易（不同的阈值会产生不同的假阴性率和假阳性率）。这类决策涉及权衡，只有深入了解业务背景才能处理。
- en: Shipping an inference model
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署推理模型
- en: A machine learning project doesn’t end when you arrive at a Colab notebook that
    can save a trained model. You rarely put into production the exact same Python
    model object that you manipulated during training.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习项目并不在你到达一个可以保存训练模型的Colab笔记本时就结束了。你很少会将训练期间操作的精确Python模型对象投入生产。
- en: 'First, you may want to export your model to something other than Python:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您可能希望将模型导出为Python以外的其他格式：
- en: Your production environment may not support Python at all — for instance, if
    it’s a mobile app or an embedded system.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的生产环境可能根本不支持Python——例如，如果它是一个移动应用或嵌入式系统。
- en: If the rest of the app isn’t in Python (it could be in JavaScript, C++, etc.),
    the use of Python to serve a model may induce significant overhead.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果应用程序的其他部分不在Python中（它可能是JavaScript、C++等），使用Python来提供服务可能会引起显著的开销。
- en: Second, since your production model will only be used to output predictions
    (a phase called *inference*), rather than for training, you have room to perform
    various optimizations that can make the model faster and reduce its memory footprint.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，由于您的生产模型仅用于输出预测（称为*推理*阶段），而不是用于训练，您有空间进行各种优化，可以使模型运行更快并减少其内存占用。
- en: Let’s take a quick look at the different model deployment options you have available.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们快速看一下您可用的不同模型部署选项。
- en: Deploying a model as a REST API
  id: totrans-148
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 将模型作为REST API部署
- en: Perhaps the easiest way to turn a model into a product is to serve it online
    via a REST API. There are a number of libraries out there for making this happen.
    Keras supports two of the most popular approaches out of the box — *TensorFlow
    Serving* and *ONNX* (short for Open Neural Network Exchange). Both libraries operate
    by lifting all model weights and a computation graph outside of the Python program,
    so you can serve it from a number of different environments (for example, a C++
    server). If this sounds a lot like the compilation mechanism discussed in chapter
    3 you are spot-on. TensorFlow Serving is essentially a library for serving `tf.function`
    computation graphs with a specific set of saved weights.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型转化为产品的最简单方法可能是通过REST API在线提供服务。有许多库可以帮助实现这一点。Keras支持两种最流行的方法——*TensorFlow
    Serving*和*ONNX*（即Open Neural Network Exchange）。这两个库都是通过将所有模型权重和计算图从Python程序中提取出来来运行的，因此您可以从多个不同的环境中提供服务（例如，一个C++服务器）。如果这听起来很像第3章中讨论的编译机制，您就完全正确了。TensorFlow
    Serving本质上是一个用于通过特定保存权重的`tf.function`计算图提供服务的库。
- en: 'Keras allows access to both TensorFlow Serving and ONNX via an easy-to-use
    `export()` method available on all Keras models. Here’s a code snippet showing
    how this works for TensorFlow Serving:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: Keras 允许通过所有 Keras 模型上可用的易于使用的 `export()` 方法访问 TensorFlow Serving 和 ONNX。以下是一个代码片段，展示了它是如何为
    TensorFlow Serving 工作的：
- en: '[PRE1]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'A similar flow exists for ONNX:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 ONNX 也存在类似的流程：
- en: '[PRE2]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You should use this deployment setup when
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该在以下情况下使用此部署设置：
- en: The application that will consume the model’s prediction will have reliable
    access to the internet (obviously). For instance, if your application is a mobile
    app, serving predictions from a remote API means that the application won’t be
    usable in airplane mode or in a low-connectivity environment.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将会消费模型预测的应用程序将能够可靠地访问互联网（显然）。例如，如果您的应用程序是一个移动应用程序，从远程 API 提供预测意味着在飞行模式或低连接性环境中应用程序将不可用。
- en: 'The application does not have strict latency requirements: the request, inference,
    and answer round trip will typically take around 500 ms.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序没有严格的延迟要求：请求、推理和回答往返通常需要大约 500 毫秒。
- en: 'The input data sent for inference is not highly sensitive: the data will need
    to be available on the server in a decrypted form, since it will need to be seen
    by the model (but note that you should use SSL encryption for the HTTP request
    and answer).'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于推理的输入数据不太敏感：数据将以解密形式在服务器上可用，因为模型需要查看它（但请注意，您应该使用 SSL 加密 HTTP 请求和响应）。
- en: For instance, the image search engine project, the music recommender system,
    the credit card fraud detection project, and the satellite imagery project are
    all a good fit for serving via a REST API.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，图像搜索引擎项目、音乐推荐系统、信用卡欺诈检测项目和卫星图像项目都非常适合通过 REST API 提供服务。
- en: An important question when deploying a model as a REST API is whether you want
    to host the code on your own or whether you want to use a fully managed third-party
    cloud service. For instance, Cloud AI Platform, a Google product, lets you simply
    upload your TensorFlow model to Google Cloud Storage (GCS) and gives you an API
    endpoint to query it. It takes care of many practical details such as batching
    predictions, load balancing, and scaling.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 当将模型作为 REST API 部署时，一个重要的问题是您是想自己托管代码还是想使用完全管理的第三方云服务。例如，Google 产品 Cloud AI
    Platform 允许您简单地将您的 TensorFlow 模型上传到 Google Cloud Storage (GCS)，并提供一个 API 端点来查询它。它负责许多实际细节，例如批处理预测、负载均衡和扩展。
- en: Deploying a model on a device
  id: totrans-160
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在设备上部署模型
- en: 'Sometimes, you may need your model to live on the same device that runs the
    application that uses it — maybe a smartphone, an embedded ARM CPU on a robot,
    or a microcontroller on a tiny device. For instance, perhaps you’ve already seen
    a camera capable of automatically detecting people and faces in the scenes you
    pointed it at: that was probably a small deep learning model running directly
    on the camera.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，您可能需要您的模型与运行使用它的应用程序的同一设备上运行——可能是一台智能手机、机器人上的嵌入式 ARM CPU 或小型设备上的微控制器。例如，也许您已经看到过一种能够自动检测您指向的场景中的人脸和人物的相机：那可能是一个直接在相机上运行的微型深度学习模型。
- en: You should use this setup when
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该在以下情况下使用此设置：
- en: Your model has strict latency constraints or needs to run in a low-connectivity
    environment. If you’re building an immersive augmented-reality application, querying
    a remote server is not a viable option.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的模型有严格的延迟限制，或者需要在低连接性环境中运行。如果您正在构建沉浸式增强现实应用程序，查询远程服务器不是一个可行的选项。
- en: Your model can be made sufficiently small that it can run under the memory and
    power constraints of the target device.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您可以将模型做得足够小，使其能够在目标设备的内存和功耗限制下运行。
- en: 'Getting the highest possible accuracy isn’t mission critical for your task:
    there is always a tradeoff between runtime efficiency and accuracy, so memory
    and power constraints often require you to ship a model that isn’t quite as good
    as the best model you could run on a large GPU.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于您的任务来说，获得尽可能高的准确度不是至关重要的：运行时间和准确度之间总是存在权衡，因此内存和功耗限制通常要求您发送一个模型，它的性能不如您在大型
    GPU 上运行的最好模型。
- en: The input data is strictly sensitive and thus shouldn’t be decryptable on a
    remote server.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入数据非常敏感，因此不应在远程服务器上解密。
- en: For instance, our spam detection model will need to run on the end user’s smartphone
    as part of the chat app, because messages are end-to-end encrypted and thus cannot
    be read by a remotely hosted model at all. Likewise, the bad-cookie-detection
    model has strict latency constraints and will need to run at the factory. Thankfully,
    in this case, we don’t have any power or space constraints, so we can actually
    run the model on a GPU.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们的垃圾邮件检测模型需要作为聊天应用的一部分在终端用户的智能手机上运行，因为消息是端到端加密的，所以根本无法由远程托管模型读取。同样，坏cookie检测模型有严格的延迟限制，需要在工厂运行。幸运的是，在这种情况下，我们没有电力或空间限制，因此实际上可以在GPU上运行该模型。
- en: To deploy a Keras model on a smartphone or embedded device, you can again use
    the `export()` method to create a TensorFlow or ONNX save of your model including
    the computation graph. TensorFlow Lite ([https://www.tensorflow.org/lite](https://www.tensorflow.org/lite))
    is a framework for efficient on-device deep learning inference that runs on Android
    and iOS smartphones, as well as ARM CPUs, Raspberry Pi, or certain microcontrollers.
    It uses the same TensorFlow save model format as TensorFlow Serving. The ONNX
    runtime can also run on mobile devices.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 要在智能手机或嵌入式设备上部署Keras模型，你可以再次使用`export()`方法创建包含计算图的TensorFlow或ONNX保存的模型。TensorFlow
    Lite（[https://www.tensorflow.org/lite](https://www.tensorflow.org/lite)）是一个在Android和iOS智能手机、ARM
    CPU、Raspberry Pi或某些微控制器上运行的框架，用于高效的设备上深度学习推理。它使用与TensorFlow Serving相同的TensorFlow保存模型格式。ONNX运行时也可以在移动设备上运行。
- en: Deploying a model in the browser
  id: totrans-169
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 在浏览器中部署模型
- en: Deep learning is often used in browser-based or desktop-based JavaScript applications.
    While it is usually possible to have the application query a remote model via
    a REST API, there can be key advantages in instead having the model run directly
    in the browser, on the user’s computer (utilizing GPU resources if available).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习通常用于基于浏览器或桌面基于JavaScript的应用程序。虽然通常可以通过REST API让应用程序查询远程模型，但让模型直接在浏览器中、用户的电脑上运行（如果可用，利用GPU资源）可能会有关键优势。
- en: Use this setup when
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下情况下使用此设置：
- en: You want to offload compute to the end user, which can dramatically reduce server
    costs.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你希望将计算任务卸载给终端用户，这可以显著降低服务器成本。
- en: The input data needs to stay on the end user’s computer or phone. For instance,
    in our spam detection project, the web version and the desktop version of the
    chat app (implemented as a cross-platform app written in JavaScript) should use
    a locally run model.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 输入数据需要保持在终端用户的电脑或手机上。例如，在我们的垃圾邮件检测项目中，聊天应用的网页版和桌面版（作为用JavaScript编写的跨平台应用实现）应使用本地运行的模型。
- en: 'Your application has strict latency constraints: while a model running on the
    end user’s laptop or smartphone is likely to be slower than one running on a large
    GPU on your own server, you don’t have the extra 100 ms of network round trip.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你的应用程序有严格的延迟限制：虽然运行在终端用户笔记本电脑或智能手机上的模型可能比运行在你自己服务器上大型GPU上的模型要慢，但你没有额外的100毫秒的网络往返时间。
- en: You need your app to keep working without connectivity, after the model has
    been downloaded and cached.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在模型下载并缓存后，你需要确保你的应用在没有连接的情况下也能继续工作。
- en: 'Of course, you should only go with this option if your model is small enough
    that it won’t hog the CPU, GPU, or RAM of your user’s laptop or smartphone. In
    addition, since the entire model will be downloaded to the user’s device, you
    should make sure that nothing about the model needs to stay confidential. Be mindful
    of the fact that, given a trained deep learning model, it is usually possible
    to recover some information about the training data: better not to make your trained
    model public if it was trained on sensitive data.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，只有当你的模型足够小，不会占用用户笔记本电脑或智能手机的CPU、GPU或RAM时，你才应该选择这个选项。此外，由于整个模型将下载到用户的设备上，你应该确保模型中没有任何需要保密的内容。请注意，给定一个训练好的深度学习模型，通常可以恢复一些关于训练数据的信息：如果模型是在敏感数据上训练的，最好不要将其公开。
- en: To deploy a model in JavaScript, the TensorFlow ecosystem includes TensorFlow.js
    ([https://www.tensorflow.org/js](https://www.tensorflow.org/js)), and ONNX supports
    a native JavaScript runtime. TensorFlow.js even implements almost all of the Keras
    API (it was originally developed under the working name WebKeras) as well as many
    lower-level TensorFlow APIs. You can easily import a saved Keras model into TensorFlow.js
    to query it as part of your browser-based JavaScript app or your desktop Electron
    app.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在JavaScript中部署模型时，TensorFlow生态系统包括TensorFlow.js ([https://www.tensorflow.org/js](https://www.tensorflow.org/js))，并且ONNX支持原生JavaScript运行时。TensorFlow.js甚至实现了几乎所有的Keras
    API（它最初是在WebKeras这个工作名称下开发的）以及许多低级别的TensorFlow API。你可以轻松地将保存的Keras模型导入TensorFlow.js，以便在基于浏览器的JavaScript应用或桌面Electron应用中查询它。
- en: Inference model optimization
  id: totrans-178
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 推理模型优化
- en: Optimizing your model for inference is especially important when deploying in
    an environment with strict constraints on available power and memory (smartphones
    and embedded devices) or for applications with low-latency requirements. You should
    always seek to optimize your model before importing it into TensorFlow.js or exporting
    it to TensorFlow Lite.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在对推理环境进行优化时，特别是在对可用功率和内存有严格限制的环境（如智能手机和嵌入式设备）或对低延迟有要求的场景中，优化你的模型尤为重要。在将模型导入TensorFlow.js或导出到TensorFlow
    Lite之前，你应该始终寻求优化模型。
- en: 'There are two popular optimization techniques you can apply:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以应用两种流行的优化技术：
- en: '*Weight pruning* — Not every coefficient in a weight tensor contributes equally
    to the predictions. It’s possible to considerably lower the number of parameters
    in the layers of your model by only keeping the most significant ones. This reduces
    the memory and compute footprint of your model at a small cost in performance
    metrics. By tuning how much pruning you want to apply, you are in control of the
    tradeoff between size and accuracy.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*权重剪枝* — 并非权重张量中的每个系数都对预测贡献相同。通过仅保留最重要的系数，你可以显著减少模型层中的参数数量。这会在性能指标上带来轻微的代价，但可以减少模型的内存和计算占用。通过调整你想要应用的剪枝程度，你可以控制大小和准确度之间的权衡。'
- en: '*Weight quantization* — Deep learning models are trained with single-precision
    floating-point (`float32`) weights. However, it’s possible to *quantize* weights
    to 8-bit signed integers (`int8`) to get an inference-only model that’s four times
    smaller but remains near the accuracy of the original model. Keras models come
    with a built-in `quantize()` API that can help with this. Simply call `model.quantize("int8")`
    to compress each weight in your model to a single byte.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*权重量化* — 深度学习模型使用单精度浮点数(`float32`)权重进行训练。然而，可以将权重*量化*到8位有符号整数(`int8`)，以获得一个仅用于推理的模型，其大小是原来的四分之一，但仍然接近原始模型的准确度。Keras模型自带内置的`quantize()`
    API，可以帮助实现这一点。只需调用`model.quantize("int8")`即可将模型中的每个权重压缩到一个字节。'
- en: Monitoring your model in the wild
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 监控野外的模型
- en: You’ve exported an inference model, you’ve integrated it into your application,
    and you’ve done a dry run on production data — the model behaved exactly as you
    expected. You’ve written unit tests as well as logging and status-monitoring code
    — perfect. Now it’s time to press the big red button and deploy to production.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经导出了推理模型，将其集成到你的应用中，并在生产数据上进行了测试运行——模型的行为完全符合你的预期。你已经编写了单元测试以及日志和状态监控代码——完美。现在是你按下那个大红色按钮并将模型部署到生产环境的时候了。
- en: 'Even this is not the end. Once you’ve deployed a model, you need to keep monitoring
    its behavior, its performance on new data, its interaction with the rest of the
    application, and its eventual impact on business metrics:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 即使这样也不是终点。一旦部署了模型，你需要持续监控其行为、在新数据上的性能、与其他应用的交互，以及最终对业务指标的影响：
- en: 'Is user engagement in your online radio up or down after deploying the new
    music recommender system? Has average ad click-through rate increased after switching
    to the new click-through rate prediction model? Consider using *randomized A/B
    testing* to isolate the impact of the model itself from other changes: a subset
    of cases should go through the new model, while another control subset should
    stick to the old process. Once sufficiently many cases have been processed, the
    difference in outcomes between the two is likely attributable to the model.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在部署新的音乐推荐系统后，你的在线广播的用户参与度是上升还是下降？在切换到新的点击率预测模型后，平均广告点击率是否有所增加？考虑使用*随机A/B测试*来隔离模型本身的影响与其他变化：一部分案例应该通过新的模型，而另一部分控制案例应该坚持旧的过程。一旦处理了足够多的案例，两个结果之间的差异很可能是模型的影响。
- en: 'If possible, do a regular manual audit of the model’s predictions on production
    data. It’s generally possible to reuse the same infrastructure as for data annotation:
    send some fraction of the production data to be manually annotated and compare
    the model’s predictions to the new annotations. For instance, you should definitely
    do this for the image search engine and the bad-cookie-flagging system.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果可能的话，对模型在生产数据上的预测进行定期手动审计。通常可以重用数据标注的基础设施：将一部分生产数据发送进行手动标注，并将模型的预测与新的标注进行比较。例如，你绝对应该为图像搜索引擎和不良cookie标记系统做这件事。
- en: When manual audits are impossible, consider alternative evaluation avenues such
    as user surveys (for example, in the case of the spam and offensive content–flagging
    system).
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当手动审计不可能时，考虑其他评估途径，例如用户调查（例如，在垃圾邮件和违规内容标记系统中）。
- en: Maintaining your model
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 维护你的模型
- en: 'Lastly, no model lasts forever. You’ve already learned about *concept drift*:
    over time, the characteristics of your production data will change, gradually
    degrading the performance and relevance of your model. The lifespan of your music
    recommender system will be counted in weeks. For the credit card fraud detection
    system, it would be days; a couple of years in the best case for the image search
    engine.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，没有模型是永恒的。你已经了解了*概念漂移*：随着时间的推移，你的生产数据的特征会发生变化，逐渐降低模型的性能和相关性。你的音乐推荐系统的寿命将以周计算。对于信用卡欺诈检测系统，可能是几天；在最佳情况下，图像搜索引擎可能是几年。
- en: 'As soon as your model has launched, you should be getting ready to train the
    next generation that will replace it:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的模型上线，你就应该开始准备训练下一代将取代它的模型：
- en: Watch out for changes in the production data. Are new features becoming available?
    Should you expand or otherwise edit the label set?
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注意生产数据的变化。是否有新特征可用？你是否应该扩展或修改标签集？
- en: Keep collecting and annotating data, and keep improving your annotation pipeline
    over time. In particular, you should pay special attention to collecting samples
    that seem to be difficult to classify for your current model — such samples are
    the most likely to help improve performance.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 继续收集和标注数据，并随着时间的推移不断改进你的标注流程。特别是，你应该特别注意收集那些似乎难以分类的样本，因为当前模型最有可能帮助提高性能。
- en: This concludes the universal workflow of machine learning — that’s a lot of
    things to keep in mind. It takes time and experience to become an expert, but
    don’t worry, you’re already a lot wiser than you were a few chapters ago. You
    are now familiar with the big picture — the entire spectrum of what machine learning
    projects entail. While most of this book will focus on the model development part,
    you’re now aware that it’s only one part of the entire workflow. Always keep in
    mind the big picture!
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 这就结束了机器学习的通用工作流程——这有很多事情需要记住。成为专家需要时间和经验，但不用担心，你已经比几章前聪明多了。你现在已经熟悉了大局——机器学习项目涵盖的整个范围。虽然本书的大部分内容将关注模型开发部分，但你现在已经意识到，这仅仅是整个工作流程的一部分。始终牢记大局！
- en: Summary
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: 'When you take on a new machine learning project, first, define the problem
    at hand:'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你承担一个新的机器学习项目时，首先，定义手头的问题：
- en: Understand the broader context of what you’re setting out to do — what’s the
    end goal and what are the constraints?
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解你着手要做的事情的更广泛背景——最终目标是什么，有什么限制？
- en: Collect and annotate a dataset; make sure you understand your data in depth.
  id: totrans-198
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集并标注数据集；确保你深入理解你的数据。
- en: Choose how you’ll measure success on your problem. What metrics will you monitor
    on your validation data?
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择你将如何衡量你问题的成功。你将在验证数据上监控哪些指标？
- en: 'Once you understand the problem and you have an appropriate dataset, develop
    a model:'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦你理解了问题，并且拥有合适的数据集，开发一个模型：
- en: Prepare your data.
  id: totrans-201
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 准备你的数据。
- en: Pick your evaluation protocol. Hold-out validation? K-fold validation? Which
    portion of the data should you use for validation?
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择你的评估协议。保留验证？K折验证？你应该使用数据集的哪一部分进行验证？
- en: 'Achieve statistical power: beat a simple baseline.'
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实现统计功效：击败简单的基线。
- en: 'Scale up: develop a model that can overfit.'
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 规模化：开发一个可以过拟合的模型。
- en: Regularize your model and tune its hyperparameters, based on performance on
    the validation data. A lot of machine learning research tends to focus only on
    this step — but keep the big picture in mind.
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据验证数据上的性能，对模型进行正则化并调整其超参数。许多机器学习研究往往只关注这一步——但请记住大局。
- en: 'When your model is ready and yields good performance on the test data, it’s
    time for deployment:'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当模型准备就绪，并在测试数据上表现出良好的性能时，就到了部署的时候：
- en: First, make sure to set appropriate expectations with stakeholders.
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，确保与利益相关者设定适当的期望。
- en: Optimize a final model for inference, and ship the model to the deployment environment
    of choice — web server, mobile, browser, embedded device, etc.
  id: totrans-208
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 优化用于推理的最终模型，并将其部署到所选的部署环境中——例如，Web服务器、移动设备、浏览器、嵌入式设备等。
- en: Monitor your model’s performance in production and keep collecting data so you
    can develop the next generation of the model.
  id: totrans-209
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控模型在生产环境中的性能，并持续收集数据，以便开发下一代的模型。
