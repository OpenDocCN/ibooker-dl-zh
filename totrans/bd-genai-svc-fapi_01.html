<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><section data-pdf-bookmark="Preface" data-type="preface" epub:type="preface"><div class="preface" id="id419">
<h1>Prefazione</h1><div data-type="note"><p>Questo lavoro è stato tradotto utilizzando l'AI. Siamo lieti di ricevere il tuo feedback e i tuoi commenti: <a href="mailto:translation-feedback@oreilly.com">translation-feedback@oreilly.com</a></p></div>
<p>L'<em>IA generativa</em> (GenAI) sta conquistando il mondo dopo il rilascio di tecnologie come ChatGPT. Questo nuovo tipo di IA è in grado di creare contenuti in varie <em>modalità</em> (come testo, audio, video, ecc.) imparando a imitare gli schemi dei dati di addestramento. Con l'aumento delle capacità dell'IA generativa, molte aziende stanno investendo in strumenti di IA off-the-shelf o personalizzati. Questi strumenti richiedono servizi di backend manutenibili e scalabili in grado di adattarsi a una domanda elevata.</p>
<p>Le capacità dell'IA sono entusiasmanti perché aprono le porte a infinite possibilità che liberano il potenziale di nuovi strumenti. Prima dell'IA generativa, gli sviluppatori dovevano scrivere script e addestrare modelli di ottimizzazione per creare automazione e pipeline di dati per l'elaborazione di dati non strutturati come i corpora di testi.
Questo processo poteva essere noioso, soggetto a errori e applicabile solo a casi d'uso limitati. Tuttavia, con l'avvento dei modelli di IA generativa, come i modelli linguistici di grandi dimensioni (LLMs), ora possiamo digerire, confrontare e riassumere set di dati e documenti non strutturati, riformulare idee complesse e generare visualizzazioni e illustrazioni.</p>
<p>Sebbene la maggior parte dei modelli generativi come ChatGPT siano eccellenti per quello che fanno da soli, riesci a immaginare le possibilità che si aprono quando li colleghiamo a internet, ai nostri database e ad altri servizi? Se possiamo "parlare" ai nostri servizi in<span class="keep-together">linguaggio</span> naturale o fornire loro immagini, video o audio e fargli fare delle cose per noi, si aprono tantissime opportunità per creare nuove<span class="keep-together">applicazioni</span> accessibili e automatizzate.</p>
<p>I chatbot non sono le uniche applicazioni che possiamo creare con questi modelli generativi. Possiamo creare agenti di servizio backend in grado di eseguire diversi compiti complessi che richiedono la comprensione, il ragionamento logico e l'analisi dei testi.</p>
<p>Collegando i nostri modelli generativi ai servizi esistenti e a internet, forniamo ai nostri servizi di IA ulteriori dati per arricchire la loro comprensione del problema in questione. Ad esempio, un'azienda può utilizzare un LLM open source, interno e ottimizzato per analizzare gli ordini di acquisto, generare fatture e convalidare i dati rispetto al database dei clienti prima di effettuare un ordine con un sistema di pagamento.
Altri casi d'uso possono essere i sistemi di gestione dei contenuti che possono aiutare gli utenti a generare contenuti e i costruttori di siti web che possono suggerire immagini, icone e componenti dell'interfaccia utente (UI) per velocizzare il design del sito.</p>
<p>LLMs e altri modelli generativi richiedono una grande potenza di elaborazione e una grande quantità di memoria per funzionare e non è chiaro quali siano i modelli di distribuzione e i livelli di integrazione che gli sviluppatori dovrebbero utilizzare per sfruttare questi modelli. Costruire servizi di IA generativa è impegnativo perché devi trovare un equilibrio tra scalabilità, sicurezza, prestazioni e privacy dei dati. Vorrai anche avere la possibilità di moderare, riqualificare e ottimizzare questi servizi per l'inferenza in tempo reale. Queste sfide saranno diverse per ogni organizzazione e il modo in cui costruirai i tuoi servizi di IA generativa dipenderà dai tuoi sistemi e servizi software esistenti.</p>
<p>Le risorse e la documentazione esistenti forniscono le informazioni necessarie per iniziare ad addestrare modelli personalizzati e a mettere a punto modelli linguistici di grandi dimensioni. Tuttavia, la maggior parte degli sviluppatori potrebbe continuare a incontrare difficoltà nel confezionare e distribuire questi nuovi modelli generativi come parte di sistemi e servizi software esistenti.</p>
<p>L'obiettivo di questo libro è quello di mostrarti come produrre GenAI comprendendo il processo end-to-end di costruzione e distribuzione dei tuoi servizi AI con strumenti come il framework web FastAPI.</p>
<section data-pdf-bookmark="Objective and Approach" data-type="sect1"><div class="sect1" id="id429">
<h1>Obiettivo e approccio</h1>
<p>L'obiettivo di questo libro è quello di aiutarti a esplorare le sfide dello sviluppo, della messa in sicurezza, del test e dell'implementazione dell'IA generativa come servizio integrato con i tuoi sistemi e le tue applicazioni esterne.</p>
<p>Questo libro è incentrato sulla costruzione di servizi AI generativi modulari e sicuri dal punto di vista tipologico in FastAPI, con un supporto continuo alla gestione degli schemi di database e all'integrazione dei modelli per alimentare backend in grado di generare nuovi dati.</p>
<p>L'importanza di questi argomenti deriva dalla crescente richiesta di costruire servizi flessibili in grado di adattarsi a requisiti mutevoli, di mantenere prestazioni elevate e di scalare in modo efficiente utilizzando il modello dei microservizi.</p>
<p>Imparerai anche il processo di arricchimento dei tuoi servizi con dati contestuali provenienti da diverse fonti come database, web, sistemi esterni e file caricati dagli utenti.</p>
<p>Alcuni modelli generativi richiedono una grande potenza di elaborazione e una grande quantità di memoria per poter funzionare. Esplorerai come gestire questi modelli in produzione e come scalare i tuoi servizi per gestire il carico. Esplorerai anche come gestire le attività di lunga durata come l'inferenza del modello.</p>
<p>Infine, discuteremo i concetti di autenticazione, le considerazioni sulla sicurezza, l'ottimizzazione delle prestazioni, i test e l'implementazione di servizi di IA generativa pronti per la produzione.</p>
</div></section>
<section data-pdf-bookmark="Prerequisites" data-type="sect1"><div class="sect1" id="id430">
<h1>Prerequisiti</h1>
<p>Questo libro non presuppone alcuna conoscenza preliminare dell'IA generativa e non richiede che tu comprenda appieno il funzionamento dei modelli generativi. Tratterò l'intuizione di come questi modelli generano i dati, ma non mi addentrerò nella loro matematica di base. Tuttavia, se vuoi saperne di più su come costruire i tuoi modelli di IA generativa in dettaglio, ti consiglio <a class="orm:hideurl" href="https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/"><em>Generative Deep Learning</em></a> di David Foster (O'Reilly, 2024).</p>
<p>Poiché si tratta di un libro su FastAPI per le applicazioni di intelligenza artificiale generativa, presuppongo una certa familiarità con questo framework web. Se hai bisogno di un ripasso o vuoi ampliare la tua comprensione delle funzionalità di FastAPI, ti consiglio di leggere <a class="orm:hideurl" href="https://www.oreilly.com/library/view/fastapi/9781098135492/"><em>FastAPI</em></a> di Bill Lubanovic (O'Reilly, 2023). Tuttavia, non è un requisito per seguire questo libro.</p>
<p>Inoltre, il libro presuppone una certa esperienza con Python, con Docker per il deployment, con il funzionamento del web e con la comunicazione attraverso il protocollo HTTP.</p>
<p>Per migliorare le tue conoscenze di Python, ti consiglio di visitare il sito <a href="https://realpython.org">realpython.org</a> per trovare ottimi tutorial su concetti più avanzati. Anche il <a href="https://www.docker.com">sito</a> ufficiale <a href="https://www.docker.com">di Docker</a> offre un eccellente tutorial pratico sulla containerizzazione e sulla scrittura dei file Docker.</p>
<p>In questo libro non tratterò i fondamenti del web, ma consiglio vivamente <a href="https://oreil.ly/vvwzI">la documentazione di MDN</a> come punto di partenza.</p>
<p>Infine, il libro non richiede la conoscenza di framework per l'apprendimento profondo come TensorFlow e Keras, che verranno introdotti laddove necessario. Al contrario, lavoreremo per lo più con modelli pre-addestrati ospitati nel <a href="https://oreil.ly/vC0DA">repository di modelli di Hugging Face</a>.</p>
</div></section>
<section data-pdf-bookmark="Book Structure" data-type="sect1"><div class="sect1" id="id431">
<h1>Struttura del libro</h1>
<p>Il libro è suddiviso in tre parti:</p>
<dl>
<dt><a data-type="xref" data-xrefstyle="part-num-title" href="part01.html#part1">Parte I, "Sviluppare i servizi AI"</a></dt>
<dd>
<p>Questa parte copre tutti i passi necessari per impostare un progetto FastAPI che alimenterà il tuo servizio GenAI. Imparerai a integrare vari modelli generativi in un'applicazione FastAPI type-safe e a esporre gli endpoint per interagire con essi.</p>
<ul>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch01.html#ch01">Capitolo 1, "Introduzione":</a> Questo capitolo parla dell'importanza di GenAI nel futuro e introduce i progetti pratici che realizzerai nel corso del libro.</p>
</li>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch02.html#ch02">Capitolo 2, "Come iniziare con FastAPI":</a> Questo capitolo introduce FastAPI, un framework moderno per la creazione di servizi di intelligenza artificiale, di cui comprenderai le caratteristiche, le limitazioni e il confronto con altri framework web. Alla fine del capitolo sarai in grado di iniziare a creare applicazioni FastAPI, organizzare progressivamente i progetti e migrare da framework come Flask o Django.</p>
</li>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch03.html#ch03">Capitolo 3, "Integrazione dell'intelligenza artificiale e servizio di modelli":</a> Questo capitolo tratta l'intero processo di integrazione e di servizio di vari modelli GenAI (tra cui modelli linguistici, audio, di visione e 3D) come servizio FastAPI utilizzando l'application lifespan. Verranno esaminate varie strategie per il servizio dei modelli, come il precaricamento, l'esternalizzazione e il monitoraggio dei modelli con il middleware.</p>
</li>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch04.html#ch04">Capitolo 4, "Implementare servizi AI sicuri dal punto di vista tipologico":</a> Questo capitolo introduce il concetto di sicurezza dei tipi e come le annotazioni sui tipi di Python e gli strumenti di validazione dei dati come Pydantic possono aiutare a validare e serializzare i dati che passano attraverso i tuoi servizi di intelligenza artificiale.</p>
</li>
</ul>
</dd>
<dt><a data-type="xref" data-xrefstyle="part-num-title" href="part02.html#part2">Parte II, "Comunicare con i sistemi esterni".</a></dt>
<dd>
<p>In questa parte, integreremo i nostri servizi di intelligenza artificiale con sistemi esterni come i database e impareremo a servire utenti simultanei. Implementeremo anche lo streaming in tempo reale dei risultati dei modelli.</p>
<ul>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch05.html#ch05">Capitolo 5, "Ottenere la concomitanza nei carichi di lavoro dell'intelligenza artificiale":</a> Questo capitolo introduce i concetti di concomitanza e parallelismo e mette a confronto diverse strategie per risolvere i problemi di concomitanza. Rivedremo lo scopo della programmazione asincrona nella gestione dei compiti a lungo termine e di quelli bloccanti ed esamineremo i limiti del Global Interpreter Lock (GIL) di Python nella gestione di questi processi asincroni. Per fare pratica, implementeremo un chatbot funzionante "parla con il web e con i tuoi documenti" utilizzando una tecnica chiamata <em>retrieval augmented generation (RAG</em> ). Infine, tratteremo la funzione dei compiti in background di FastAPI per affrontare le operazioni a lungo termine.</p>
</li>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch06.html#ch06">Capitolo 6, "Comunicazione in tempo reale<span class="keep-together">con i modelli generativi</span>":</a> In questo capitolo ci concentreremo sull'abilitazione della comunicazione client-server in tempo reale con i modelli generativi, confrontando vari meccanismi come i web socket e gli eventi di streaming del server per lo streaming dei dati da/verso i modelli generativi con esempi pratici.</p>
</li>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch07.html#ch07">Capitolo 7, "Integrazione dei database nei servizi di intelligenza artificiale":</a> Questo capitolo offre una panoramica delle tecnologie di database adatte ai servizi GenAI e illustra le migliori pratiche per lavorare con i database utilizzando strumenti collaudati come l'ORM SQLAlchemy e Alembic per facilitare le migrazioni. Infine, presenteremo Prisma, uno strumento di prossima uscita per generare un client di database completamente tipizzato e gestire automaticamente le migrazioni.</p>
</li>
</ul>
</dd>
<dt><a data-type="xref" data-xrefstyle="part-num-title" href="part03.html#part3">Parte III, "Protezione, ottimizzazione, test e distribuzione dei servizi di intelligenza artificiale".</a></dt>
<dd>
<p>In questa parte ci concentriamo sull'implementazione del livello di autenticazione per la gestione degli utenti, oltre che sui miglioramenti della sicurezza e dell'ottimizzazione. Ci concentreremo poi sui test e infine sul deploy del nostro servizio AI attraverso la containerizzazione.</p>
<ul>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch08.html#ch08">Capitolo 8, "Autenticazione e autorizzazione":</a> In questo capitolo tratteremo l'implementazione dei livelli di autenticazione per la gestione degli utenti, al fine di proteggere e limitare l'accesso ai servizi di IA. Esamineremo e implementeremo diverse strategie di autenticazione, tra cui quella di base, quella basata sui token e quella OAuth. Introdurremo poi i modelli di autorizzazione, tra cui il controllo dell'accesso basato sui ruoli (RBAC) e spiegheremo il ruolo del grafo delle dipendenze di FastAPI in questo processo. Questo includerà l'aggiunta di permessi restrittivi per gli utenti in base ai ruoli, in modo che le interazioni con i servizi di IA possano essere moderate automaticamente.</p>
</li>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch09.html#ch09">Capitolo 9, "Messa in sicurezza dei servizi di intelligenza artificiale":</a> Questo capitolo offre una panoramica dei vettori di attacco più comuni per le soluzioni generative. Qui ci concentreremo sull'implementazione di varie misure di sicurezza nel nostro servizio di IA, come la limitazione del tasso e i guardrail, per proteggerci dagli output tossici del modello, dagli attacchi comuni, dagli abusi e dall'uso improprio.</p>
</li>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch10.html#ch10">Capitolo 10, "Ottimizzazione dei servizi di intelligenza artificiale":</a> Questo capitolo tratta diverse tecniche di ottimizzazione delle prestazioni come l'elaborazione in batch, il caching semantico e il prompt engineering per migliorare la qualità e la velocità dei servizi di IA.</p>
</li>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch11.html#ch11">Capitolo 11, "Test dei servizi AI":</a> Questo capitolo tratta le sfide e le migliori pratiche per testare i servizi di intelligenza artificiale. Passeremo in rassegna vari concetti di test, tra cui le fasi di test, i confini e i mock, per poi implementare i mock dei servizi esterni, mantenendo isolati gli ambienti di test. Infine, introdurremo un nuovo approccio per testare i modelli generativi di intelligenza artificiale anche quando producono output diversi nelle varie esecuzioni di test.</p>
</li>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch12.html#ch12">Capitolo 12, "Distribuzione dei servizi AI":</a> Questo capitolo tratta vari approcci di distribuzione, tra cui l'uso di macchine virtuali, funzioni cloud, servizi app gestiti e tecnologie di containerizzazione come Docker. Ci concentreremo quindi sui concetti di containerizzazione, come lo storage e il networking, per distribuire il nostro servizio AI utilizzando Docker.</p>
</li>
</ul>
</dd>
</dl>
</div></section>
<section data-pdf-bookmark="How to Read This Book" data-type="sect1"><div class="sect1" id="id432">
<h1>Come leggere questo libro</h1>
<p>Questo libro può essere letto tutto d'un fiato oppure può essere utilizzato come riferimento per poter approfondire qualsiasi capitolo. In ogni capitolo spiego i concetti e confronto gli approcci prima di immergerci in esempi pratici di codice. Per questo motivo, ti consiglio di leggere ogni capitolo due volte: una volta per capire l'approccio e poi per ripassare gli esempi di codice usando il <a href="https://github.com/Ali-Parandeh/building-generative-ai-services">repository di codice</a> allegato al libro.</p>
<div data-type="tip"><h6>Suggerimento</h6>
<p>Sono un convinto sostenitore della spiegazione di concetti tecnici complessi con analogie, diagrammi e storie di tutti i giorni a cui chiunque può fare riferimento. Spesso questi vengono utilizzati dopo l'introduzione di un nuovo concetto complesso. Cerca sezioni di suggerimenti come questa per migliorare la tua comprensione dei concetti.</p>
</div>
<p>In definitiva, il modo migliore per imparare i concetti contenuti in questo libro è quello di mettere le mani su un modello generativo open source e poi costruire un servizio attorno ad esso utilizzando il tuo codice. Soprattutto, ti auguro di trovarlo utile e piacevole da leggere!</p>
</div></section>
<section data-pdf-bookmark="Hardware and Software Requirements" data-type="sect1"><div class="sect1" id="id433">
<h1>Requisiti hardware e software</h1>
<p>L'esecuzione di modelli generativi è generalmente un'attività ad alta intensità di calcolo che richiede una GPU potente. Tuttavia, ho fatto del mio meglio per fornire esempi di codice che utilizzano piccoli modelli generativi open source che non richiedono una GPU.</p>
<p>Solo alcuni capitoli contengono esempi di codice che richiedono l'accesso a una GPU per l'elaborazione di operazioni simultanee o per l'esecuzione di modelli più pesanti. In questi casi, ti consiglio di noleggiare una macchina virtuale con GPU NVIDIA abilitata a CUDA da qualsiasi provider cloud o di lavorare da un desktop con GPU abilitata a CUDA con un minimo di 16 GB di VRAM.</p>
<p>Consulta le istruzioni di installazione di NVIDIA CUDA per <a href="https://oreil.ly/fgwVk">Windows</a> o <a href="https://oreil.ly/3rMv2">Linux</a>.</p>
<p>Infine, per eseguire i modelli su una GPU NVIDIA compatibile con CUDA, dovrai installare il pacchetto <code translate="no">torch</code> compilato per CUDA.</p>
</div></section>
<section data-pdf-bookmark="Conventions Used in This Book" data-type="sect1"><div class="sect1" id="id434">
<h1>Convenzioni utilizzate in questo libro</h1>
<p>In questo libro vengono utilizzate le seguenti convenzioni tipografiche:</p>
<dl>
<dt><em>Corsivo</em></dt>
<dd>
<p>Indica nuovi termini, URL, indirizzi e-mail, nomi di file ed estensioni di file.</p>
</dd>
<dt><code translate="no">Constant width</code></dt>
<dd>
<p>Utilizzato per i listati dei programmi e all'interno dei paragrafi per fare riferimento a elementi del programma come nomi di variabili o funzioni, database, tipi di dati, variabili d'ambiente, dichiarazioni e parole chiave.</p>
</dd>
<dt><em><code translate="no">Constant width italic</code></em></dt>
<dd>
<p>Mostra il testo che deve essere sostituito con valori forniti dall'utente o con valori determinati dal contesto.</p>
</dd>
</dl>
<div data-type="tip"><h6>Suggerimento</h6>
<p>Questo elemento indica un consiglio o un suggerimento.</p>
</div>
<div data-type="note" epub:type="note"><h6>Nota</h6>
<p>Questo elemento indica una nota generale.</p>
</div>
<div data-type="warning" epub:type="warning"><h6>Avvertenze</h6>
<p>Questo elemento indica un avviso o un'avvertenza.</p>
</div>
</div></section>
<section data-pdf-bookmark="Using Code Examples" data-type="sect1"><div class="sect1" id="id435">
<h1>Utilizzo di esempi di codice</h1>
<p>Il libro è accompagnato da un repository di codice per i progetti guidati, disponibile per il download all'indirizzo <a class="bare" href="https://github.com/Ali-Parandeh/building-generative-ai-services"><em class="hyperlink">https://github.com/Ali-Parandeh/building-generative-ai-services.</em></a> Puoi trovare altre risorse, articoli e materiali di supporto sul sito web del libro all'indirizzo <a class="bare" href="https://buildinggenai.com"><em class="hyperlink">https://buildinggenai.com</em></a> <a class="bare" href="https://github.com/Ali-Parandeh/building-generative-ai-services"><em class="hyperlink">.</em></a></p>
<p>Dopo aver scaricato e clonato il repository, puoi eseguire un'installazione locale. Ad esempio, se utilizzi <code translate="no">conda</code>, puoi seguire questo setup per creare il tuo ambiente <code translate="no">genaiservice</code>:</p>
<pre data-type="programlisting" translate="no">conda create -n genaiservice python=3.11
conda activate genaiservice</pre>
<p>Puoi quindi installare tutte le dipendenze necessarie nell'ambiente Python appena creato:</p>
<pre data-type="programlisting" translate="no">pip install -r requirements.txt</pre>
<p>Ci sono più di 170 esempi di codice sparsi nei vari capitoli, che ti mostrano come costruire progressivamente un servizio di IA generativa pronto per la produzione con il framework web FastAPI. Ti illustreremo il codice per ogni passo, con indicazioni chiare che mostrano come il codice implementa la teoria alla base di ogni tecnica.</p>
<p>Il repository del codice contiene diversi rami che mappano lo stato del codice dell'applicazione all'inizio e alla fine di ogni capitolo, mentre gli esempi si sviluppano in modo incrementale. Gli esempi di codice sono organizzati per rami invece che per cartelle, per evitare il disordine e per fornire una base di codice pulita su cui lavorare. Il ramo <code translate="no">main</code> contiene lo stato finale del codice dell'applicazione alla fine del libro.</p>
<p>All'inizio di ogni capitolo, consulta il ramo <code translate="no">starter</code> corrispondente per seguire gli esempi di codice durante lo sviluppo dell'applicazione. Per esempio, all'inizio del <a data-type="xref" href="ch02.html#ch02">Capitolo 2</a>, puoi consultare il ramo <code translate="no">ch02-start</code>. Se ti blocchi o vuoi vedere lo stato del repository alla fine di ogni capitolo, puoi consultare il ramo <code translate="no">end</code> corrispondente (cioè <code translate="no">ch02-end</code>) e confrontare il tuo codice con quello presente nel repository.</p>
<div data-type="note" epub:type="note"><h6>Nota</h6>
<p>Il repository di codice contiene istruzioni nel file <em>README.md</em> del ramo <code translate="no">main</code> su come clonare il repository e cambiare ramo se non hai familiarità con Git.</p>
</div>
<p>Ogni ramo conterrà anche un file <em>README.md</em> per guidarti negli elementi pratici del capitolo.</p>
<p>Nel corso del libro, fornirò ulteriori compiti ed esercizi per aiutarti a consolidare la comprensione dei concetti come parte del progetto guidato. Tieni d'occhio queste sezioni per le istruzioni sull'implementazione di questi compiti. Le soluzioni sono fornite all'interno del repository di codice. Tuttavia, ti consiglio di provare a risolvere questi compiti da solo prima di consultare le soluzioni. Tieni presente che possono esistere molte soluzioni per un determinato compito.</p>
<p>Se hai una domanda tecnica o un problema nell'utilizzo degli esempi di codice, invia un'e-mail a <a class="email" href="mailto:support@oreilly.com"><em>support@oreilly.com.</em></a></p>
<p>In generale, se insieme a questo libro viene offerto del codice di esempio, puoi utilizzarlo nei tuoi programmi e nella tua documentazione. Non è necessario contattarci per ottenere l'autorizzazione, a meno che tu non stia riproducendo una parte significativa del codice. Ad esempio, scrivere un programma che utilizzi diverse parti di codice di questo libro non richiede l'autorizzazione.
Vendere o distribuire esempi tratti dai libri di O'Reilly richiede l'autorizzazione. Rispondere a una domanda citando questo libro e citando il codice di esempio non richiede l'autorizzazione. Incorporare una quantità significativa di codice di esempio tratto da questo libro nella documentazione del tuo prodotto richiede l'<span class="keep-together">autorizzazione.</span></p>
<p>Apprezziamo, ma generalmente non richiediamo, l'attribuzione. Un'attribuzione di solito include il titolo, l'autore, l'editore e l'ISBN. Ad esempio, "<em>Building Generative AI Services with FastAPI</em> by Alireza Parandeh (O'Reilly). Copyright 2025 Ali Parandeh, 978-1-098-16030-2".</p>
<p>Se ritieni che il tuo utilizzo di esempi di codice non rientri nell'ambito del fair use o dei permessi sopra indicati, contattaci all'indirizzo <a class="email" href="mailto:permissions@oreilly.com"><em>permissions@oreilly.com.</em></a></p>
</div></section>
<section data-pdf-bookmark="O’Reilly Online Learning" data-type="sect1"><div class="sect1" id="id436">
<h1>Formazione online O'Reilly</h1>
<div class="ormenabled" data-type="note" epub:type="note"><h6>Nota</h6>
<p>Da oltre 40 anni, <a class="orm:hideurl" href="https://oreilly.com"><em class="hyperlink">O'Reilly Media</em></a> fornisce formazione, conoscenze e approfondimenti tecnologici e commerciali per aiutare le aziende ad avere successo.</p>
</div>
<p>La nostra rete unica di esperti e innovatori condivide le proprie conoscenze e competenze attraverso libri, articoli e la nostra piattaforma di apprendimento online. La piattaforma di apprendimento online di O'Reilly ti dà accesso on-demand a corsi di formazione dal vivo, percorsi di apprendimento approfonditi, ambienti di codifica interattivi e una vasta collezione di testi e video di O'Reilly e di oltre 200 altri editori. Per maggiori informazioni, visita <a class="orm:hideurl" href="https://oreilly.com"><em>https://oreilly.com</em></a>.</p>
</div></section>
<section data-pdf-bookmark="How to Contact Us" data-type="sect1"><div class="sect1" id="id437">
<h1>Come contattarci</h1>
<p>Ti invitiamo a rivolgere commenti e domande su questo libro all'editore:</p>
<ul class="simplelist">
<li>O'Reilly Media, Inc.</li>
<li>1005 Gravenstein Highway North</li>
<li>Sebastopol, CA 95472</li>
<li>800-889-8969 (negli Stati Uniti o in Canada)</li>
<li>707-827-7019 (internazionale o locale)</li>
<li>707-829-0104 (fax)</li>
<li><a class="email" href="mailto:support@oreilly.com"><em>support@oreilly.com</em></a></li>
<li><a href="https://oreilly.com/about/contact.html"><em>https://oreilly.com/about/contact.html</em></a></li>
</ul>
<p>Abbiamo una pagina web dedicata a questo libro, dove elenchiamo gli errori, gli esempi e tutte le informazioni aggiuntive. Puoi accedere a questa pagina all'indirizzo <a class="bare" href="https://oreil.ly/building-gen-ai-fastAPI"><em class="hyperlink">https://oreil.ly/building-gen-ai-fastAPI.</em></a></p>
<!--Don't forget to update the link above.-->
<p>Per notizie e informazioni sui nostri libri e corsi, visita il sito <a class="bare" href="https://oreilly.com"><em class="hyperlink">https://oreilly.com.</em></a></p>
<p>Trovaci su LinkedIn: <a class="bare" href="https://linkedin.com/company/oreilly-media"><em class="hyperlink">https://linkedin.com/company/oreilly-media.</em></a></p>
<p>Guardaci su YouTube: <a class="bare" href="https://youtube.com/oreillymedia"><em class="hyperlink">https://youtube.com/oreillymedia.</em></a></p>
</div></section>
<section data-pdf-bookmark="Acknowledgments" data-type="sect1"><div class="sect1" id="id438">
<h1>Ringraziamenti</h1>
<p>Scrivere questo libro è stata un'esperienza e un viaggio incredibili per me. La mia più profonda gratitudine va alla mia famiglia per il suo sostegno incondizionato durante il processo di scrittura. Vorrei dare un riconoscimento speciale a mia sorella, Tara Parandeh; ai miei genitori, Mansoureh Tahabaz e Mohammadreza Parandeh; e alla mia compagna, Cherry Waller.</p>
<p>Sono grato agli amici, ai colleghi, ai collaboratori e al personale dell'ADSP che mi hanno aiutato a coltivare un ambiente favorevole.
Grazie a David Foster, Ross Witeszczak, Amy Bull, Zine Eddine, Joe Rowe, Jonathan Davies, Aneta Blazyczek, Giulia Scardovi, Maddy Clements, Sarah Davies, Evelina Kireilyte, Khaleel Syed, Rob Foster, Mai Do, Bogdan Bija, Nicholas Rawitscher Torres, Snehan Sighat e Leon Watson.</p>
<p>In particolare, vorrei ringraziare il mio mentore, David Foster, autore di <em>Generative Deep Learning</em> (O'Reilly), per avermi ispirato a scrivere il mio libro. Il suo libro è stato una fonte di apprendimento e di ispirazione sull'IA generativa durante il processo di stesura. Inoltre, sono grato agli amici più stretti che hanno contribuito a plasmare la mia carriera: Lee Dalchow, Isaac Cleave e Rabah Tahraoui.</p>
<p>Lavorare con O'Reilly è stato incredibile. Un ringraziamento speciale va alle mie meravigliose editor Rita Fernando e Melissa Potter per il loro supporto durante il processo di scrittura, per l'entusiasmo e per l'eccellente feedback. Non avrei potuto chiedere editor migliori. Grazie a Clare Laylock per aver preparato i capitoli in anteprima e per aver risolto i problemi di formattazione durante il processo. Vedere questi capitoli sulla piattaforma O'Reilly e ricevere un feedback positivo da parte dei lettori è stata una motivazione importante per la scrittura. Grazie anche a Nicole Butterfield e Amanda Quinn per il loro aiuto nella realizzazione di questo libro e per aver dato il via al progetto.</p>
<p>Infine, un enorme ringraziamento va ai miei revisori tecnici, David Foster, Joe Rowe e Julien Brendel, per la loro meticolosa e dettagliata revisione del libro. Ogni revisore ha contribuito con una prospettiva diversa per garantire che tutte le incongruenze, le imprecisioni e le lacune fossero affrontate. Senza il loro contributo, la qualità di questo libro<span class="keep-together">ne avrebbe risentito</span>.</p>
</div></section>
</div></section></div></div></body></html>