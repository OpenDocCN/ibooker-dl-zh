<html><head></head><body><section data-pdf-bookmark="Preface" data-type="preface" epub:type="preface"><div class="preface" id="id419">
<h1>Preface</h1>


<p><em>Generative AI</em> (GenAI) is taking the world by storm since the release of technologies like ChatGPT.
This new type of AI can create content in various <em>modalities</em> (such as text, audio, video, etc.) by learning to mimic patterns from its training data.
With the increased advancement in GenAI capabilities, many businesses are investing in off-the-shelf or custom AI tools.
These tools require maintainable and scalable backend services that can adapt to high demand.</p>

<p>AI capabilities are exciting because they open the door to endless possibilities that unlock the potential for new tools.
Before generative AI, developers had to write scripts and train optimization models to build automation and data pipelines for their processing of unstructured data like corpora of texts.
This process could be tedious, error-prone, and applicable only to limited use cases.
However, with the rise of GenAI models such as large language models (LLMs), we can now digest, compare, and summarize unstructured datasets and documents; reword complex ideas; and generate visualizations and illustrations.</p>

<p>While most generative models such as ChatGPT are excellent at what they do on their own, can you imagine the possibilities when we connect them to the internet, our own databases, and other services?
If we can just “talk” to our services in natural 
<span class="keep-together">language</span> or give them some image, video, or audio and get them to do things for us, it opens up so many opportunities to create newly accessible and automated 
<span class="keep-together">applications.</span></p>

<p>Chatbots are not the only apps that we can create with such generative models.
There is so much more we can do.
We can create backend service agents that can perform various complex tasks requiring comprehension, logical reasoning, and analysis of texts.</p>

<p>By connecting our generative models to existing services and the internet, we are giving our AI services additional data to enrich their understanding of the problem at hand.
For instance, a company can use an open source, in-house, fine-tuned LLM to parse purchase orders, generate invoices, and validate data against their customer database before placing an order with a payment system.
This is where generative models shine.
Other use cases can include content management systems that can help users with generating content and website builders that can suggest imagery, icons, and user interface (UI) components to fast-track the site’s design.</p>

<p>There is a catch.
LLMs and other generative models require heavy processing power and memory to function, and it is not clear what deployment patterns and integration layers the developers should use to leverage these models.
Building generative AI services is challenging because you need to balance scalability, security, performance, and data privacy.
You’ll also want the ability to moderate, retrain, and optimize these services for real-time inference.
These challenges will be different for every organization, and how you build your generative AI services will depend on your existing software systems and services.</p>

<p>Existing resources and documentation provide the necessary information to get started with training custom models and fine-tuning large language models.
However, most developers may continue to face challenges in packaging and deploying these novel generative models as part of existing software systems and services.</p>

<p>My aim with this book is to show you how to productionize GenAI by understanding the end-to-end process in building and deploying your own AI services with tools such as the FastAPI web framework.</p>






<section data-pdf-bookmark="Objective and Approach" data-type="sect1"><div class="sect1" id="id429">
<h1>Objective and Approach</h1>

<p>The objective of this book is to help you explore the challenges of developing, securing, testing, and deploying generative AI as services integrated with your own external systems and applications.</p>

<p>This book centers on constructing modular, type-safe generative AI services in FastAPI with seamless database schema handling support and model integration to power backends that can generate new data.</p>

<p>The significance of these topics stems from the growing demand for building flexible services that can adapt to changing requirements, maintain high performance, and scale efficiently using the microservice pattern.</p>

<p>You will also learn the process of enriching your services with contextual data from a variety of sources such as databases, the web, external systems, and files uploaded by users.</p>

<p>A few generative models require heavy processing power and memory to function.
You will explore how to handle these models in production and how to scale your services to handle the load.
You will also explore how to handle long-running tasks such as model inference.</p>

<p>Finally, we will discuss authentication concepts, security considerations, performance optimization, testing, and deployment of production-ready generative AI services.</p>
</div></section>






<section data-pdf-bookmark="Prerequisites" data-type="sect1"><div class="sect1" id="id430">
<h1>Prerequisites</h1>

<p>This book assumes no prior knowledge of generative AI and won’t require you to fully understand how generative models work.
I will be covering the intuition of how such models generate data but will not dive into their underlying mathematics.
However, if you want to learn more about building your own generative AI models in detail, I recommend <a class="orm:hideurl" href="https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/"><em>Generative Deep Learning</em></a> by David Foster (O’Reilly, 2024).</p>

<p>As this is a FastAPI book for generative AI applications, I do assume some familiarity with this web framework.
If you need a refresher or would like to expand your understanding of FastAPI features, I recommend reading <a class="orm:hideurl" href="https://www.oreilly.com/library/view/fastapi/9781098135492/"><em>FastAPI</em></a> by Bill Lubanovic (O’Reilly, 2023).
However, this is not a requirement for following along with this book.</p>

<p>Furthermore, the book does assume some experience with Python, with Docker for deployment, with how the web works, and with communicating through the HTTP protocol.</p>

<p>To brush up on your Python skills, I highly recommend visiting <a href="https://realpython.org">realpython.org</a> for excellent tutorials on more advanced concepts.
The official <a href="https://www.docker.com">Docker website</a> also provides an excellent practical tutorial on containerization and writing Dockerfiles.</p>

<p>I will not be covering the fundamentals of the web in this book, but I highly recommend <a href="https://oreil.ly/vvwzI">MDN’s documentation</a> as a starting point.</p>

<p>Finally, the book won’t require knowledge of deep learning frameworks such as Tensorflow and Keras.
Where relevant, you’ll be introduced to these frameworks.
Instead, we will mostly work with pretrained models hosted on the <a href="https://oreil.ly/vC0DA">Hugging Face model repository</a>.</p>
</div></section>






<section data-pdf-bookmark="Book Structure" data-type="sect1"><div class="sect1" id="id431">
<h1>Book Structure</h1>

<p>The book is broken into three parts:</p>
<dl>
<dt><a data-type="xref" data-xrefstyle="part-num-title" href="part01.html#part1">Part I, “Developing AI Services”</a></dt>
<dd>
<p>This part covers all the necessary steps to set up a FastAPI project that will power your GenAI service.
You will learn to integrate various generative models into a type-safe FastAPI application and expose endpoints to interact with them.</p>

<ul>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch01.html#ch01">Chapter 1, “Introduction”</a>: This chapter discusses the importance of GenAI in the future and introduces the practical projects you’ll build throughout the book.</p>
</li>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch02.html#ch02">Chapter 2, “Getting Started with FastAPI”</a>: This chapter introduces FastAPI, a modern framework for building AI services.
You will understand its features, limitations, and how it compares to other web frameworks.
By the end of this chapter, you will be able to start creating FastAPI applications, progressively organize projects, and migrate from frameworks like Flask or Django.</p>
</li>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch03.html#ch03">Chapter 3, “AI Integration and Model Serving”</a>: This chapter covers the full process of integrating and serving various GenAI models (including language, audio, vision, and 3D models) as a FastAPI service using application lifespan.
We’ll review various strategies for model serving like preloading, externalizing, and monitoring models with middleware.</p>
</li>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch04.html#ch04">Chapter 4, “Implementing Type-Safe AI Services”</a>: This chapter introduces the concept of type-safety and how Python’s type annotations and data validation tools like Pydantic can help validate and serialize data running past your AI services.</p>
</li>
</ul>
</dd>
<dt><a data-type="xref" data-xrefstyle="part-num-title" href="part02.html#part2">Part II, “Communicating with External Systems”</a></dt>
<dd>
<p>In this part, we’ll integrate our AI services with external systems such as databases and learn how to serve concurrent users.
We will also implement real-time streaming of model outputs.</p>

<ul>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch05.html#ch05">Chapter 5, “Achieving Concurrency in AI Workloads”</a>: This chapter introduces the concepts of concurrency and parallelism alongside comparing different strategies for solving concurrency problems.
We’ll review the purpose of asynchronous programming in handling long-running and blocking tasks and review the limitations of Python’s Global Interpreter Lock (GIL) when handling these asynchronous processes.
To practice, we’ll implement a working “talk to the web and your documents” chatbot using a technique called <em>retrieval augmented generation</em> (RAG).
Finally, we’ll cover FastAPI’s background tasks feature for tackling long-running operations.</p>
</li>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch06.html#ch06">Chapter 6, “Real-Time Communication 
<span class="keep-together">with Generative Models</span>”</a>: In this chapter, we will focus on enabling real-time client-server communication with generative models.
As part of this, we’ll compare various mechanisms such as web sockets and server streaming events when streaming data to/from generative models with practical examples.</p>
</li>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch07.html#ch07">Chapter 7, “Integrating Databases into AI Services”</a>: This chapter provides an overview of database technologies suitable for GenAI services.
We’ll cover best practices when working with databases using battle-tested tools such as SQLAlchemy ORM and Alembic for facilitating migrations.
Finally, we’ll introduce Prisma, an upcoming tool for generating a fully typed database client and automatic handling of migrations.</p>
</li>
</ul>
</dd>
<dt><a data-type="xref" data-xrefstyle="part-num-title" href="part03.html#part3">Part III, “Securing, Optimizing, Testing, and Deploying AI Services”</a></dt>
<dd>
<p>In this part, we focus on implementing the authentication layer for user management, alongside security and optimization enhancements.
We’ll then shift our focus on testing and finally deploying our AI service through containerization.</p>

<ul>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch08.html#ch08">Chapter 8, “Authentication and Authorization”</a>: In this chapter, we will cover the implementation of authentication layers for user management to secure, protect, and restrict access to AI services.
We’ll review and implement various authentication strategies including basic, token-based, and OAuth.
We’ll then introduce authorization models including role-based access control (RBAC) and explain the role of FastAPI’s dependency graph in the process.
This will include adding restrictive permissions for users based on roles where AI service interactions can be automatically moderated.</p>
</li>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch09.html#ch09">Chapter 9, “Securing AI Services”</a>: This chapter provides an overview of common attack vectors for generative solutions.
Here, we’ll shift focus on implementing various security measures across our AI service, such as rate limiting and guardrails, to protect against toxic model outputs, common attacks, abuse, and misuse.</p>
</li>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch10.html#ch10">Chapter 10, “Optimizing AI Services”</a>: This chapter covers various performance optimization techniques like batch processing, semantic caching, and prompt engineering for enhancing the quality and speed of AI services.</p>
</li>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch11.html#ch11">Chapter 11, “Testing AI Services”</a>: This chapter covers the challenges and best practices in testing AI services.
We’ll review various testing concepts including testing phases, boundaries, and mocks and then implement mocks of external services, keeping test environments isolated.
Finally, we’ll introduce a novel approach to testing generative AI models even when they produce varying outputs across test runs.</p>
</li>
<li>
<p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch12.html#ch12">Chapter 12, “Deployment of AI Services”</a>: This chapter covers various deployment approaches including the use of virtual machines, cloud functions, managed app services, and containerization technologies like Docker.
We’ll then focus on containerization concepts, such as storage and networking, for deploying our AI service using Docker.</p>
</li>
</ul>
</dd>
</dl>
</div></section>






<section data-pdf-bookmark="How to Read This Book" data-type="sect1"><div class="sect1" id="id432">
<h1>How to Read This Book</h1>

<p>This book can be read cover to cover or used as a reference so you can dip into any chapter. In every chapter, I explain the concepts and compare approaches before we dive into practical code examples.
Therefore, I recommend reading each chapter twice: once to understand the approach and then revisiting them to work through the code examples yourself using this book’s accompanying <a href="https://github.com/Ali-Parandeh/building-generative-ai-services">code repository</a>.</p>
<div data-type="tip"><h6>Tip</h6>
<p>I am a firm believer in explaining complex technical concepts with everyday analogies, diagrams, and stories that anyone can relate to.
These are often used after a new complex concept is introduced.
Look out for tip sections like this one to help improve your understanding of the concepts.</p>
</div>

<p>Ultimately, the best way to learn the concepts in this book is to get your hands on an open source generative model and then build a service around it using your own code.
Above all, I hope you find it a useful and enjoyable read!</p>
</div></section>






<section data-pdf-bookmark="Hardware and Software Requirements" data-type="sect1"><div class="sect1" id="id433">
<h1>Hardware and Software Requirements</h1>

<p>Running generative models is generally a compute-intensive task that requires a strong GPU.
However, I’ve tried my best to provide code examples that use small open source generative models that won’t require a GPU.</p>

<p>Only a few chapters will have code examples that require you to have access to a GPU to process concurrent operations or to run heavier models.
In such cases, I recommend renting a virtual machine with CUDA-enabled NVIDIA GPUs from any cloud provider or to work from a CUDA-enabled GPU desktop with a minimum of 16 GB of VRAM.</p>

<p>Please refer to NVIDIA’s CUDA installation instructions for <a href="https://oreil.ly/fgwVk">Windows</a> or <a href="https://oreil.ly/3rMv2">Linux</a>.</p>

<p>Finally, to run models on a CUDA-enabled NVIDIA GPU, you will also need to install the <code>torch</code> package compiled for CUDA.</p>
</div></section>






<section data-pdf-bookmark="Conventions Used in This Book" data-type="sect1"><div class="sect1" id="id434">
<h1>Conventions Used in This Book</h1>

<p>The following typographical conventions are used in this book:</p>
<dl>
<dt><em>Italic</em></dt>
<dd>
<p>Indicates new terms, URLs, email addresses, filenames, and file extensions.</p>
</dd>
<dt><code>Constant width</code></dt>
<dd>
<p>Used for program listings, as well as within paragraphs to refer to program elements such as variable or function names, databases, data types, environment variables, statements, and keywords.</p>
</dd>
<dt><em><code>Constant width italic</code></em></dt>
<dd>
<p>Shows text that should be replaced with user-supplied values or by values determined by context.</p>
</dd>
</dl>
<div data-type="tip"><h6>Tip</h6>
<p>This element signifies a tip or suggestion.</p>
</div>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>This element signifies a general note.</p>
</div>
<div data-type="warning" epub:type="warning"><h6>Warning</h6>
<p>This element indicates a warning or caution.</p>
</div>
</div></section>






<section data-pdf-bookmark="Using Code Examples" data-type="sect1"><div class="sect1" id="id435">
<h1>Using Code Examples</h1>

<p>The book accompanies a code repository for the guided projects.
This repository is available for download at <a class="bare" href="https://github.com/Ali-Parandeh/building-generative-ai-services"><em class="hyperlink">https://github.com/Ali-Parandeh/building-generative-ai-services</em></a>.
You can also find additional resources, articles, and supporting materials on the book’s companion website at <a class="bare" href="https://buildinggenai.com"><em class="hyperlink">https://buildinggenai.com</em></a>.</p>

<p>After downloading and cloning the repository, you can perform a local installation.
For example, if using <code>conda</code>, you can follow this setup to create your <code>genaiservice</code> environment:</p>

<pre data-type="programlisting">conda create -n genaiservice python=3.11
conda activate genaiservice</pre>

<p>You can then install all the necessary dependencies in your newly created Python environment:</p>

<pre data-type="programlisting">pip install -r requirements.txt</pre>

<p>There are around 170+ code examples scattered across the chapters.
These code examples show you how to progressively build a production-ready generative AI service with the FastAPI web framework.
We will walk through the code for each step-by-step, with clear signposts that show how the code implements the theory underpinning each technique.</p>

<p>The code repository contains several branches that map the state of application code to the start and end of each chapter as examples incrementally build on one another.
The code examples are organized by branches instead of folders to avoid clutter and to provide you with a clean codebase to work from.
The <code>main</code> branch contains the final state of the application code at the end of the book.</p>

<p>At the start of each chapter, check out the relevant <code>starter</code> branch to follow along with the code examples as you develop the application.
For instance, at the start of <a data-type="xref" href="ch02.html#ch02">Chapter 2</a>, you can check out the <code>ch02-start</code> branch.
If you get stuck or want to view the repository state at the end of each chapter, you can then check out the corresponding <code>end</code> branch (i.e., <code>ch02-end</code>) and compare your code with the code in the repository.</p>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>The code repository contains instructions in the <em>README.md</em> file on the <code>main</code> branch on how to clone the repository and switch branches if you’re not familiar with Git.</p>
</div>

<p>Each branch will also contain a <em>README.md</em> file to guide you with the practical elements of the chapter.</p>

<p>Throughout the book, I will provide additional tasks and exercises to help solidify your understanding of the concepts as part of the guided project.
Look out for these sections for instructions on implementing these tasks.
Solutions are provided within the code repository.
However, I recommend trying to solve these tasks on your own before consulting the solutions.
Please note that many solutions can exist for a given task.</p>

<p>If you have a technical question or a problem using the code examples, please send an email to <a class="email" href="mailto:support@oreilly.com"><em>support@oreilly.com</em></a>.</p>

<p>This book is here to help you get your job done.
In general, if example code is offered with this book, you may use it in your programs and documentation.
You do not need to contact us for permission unless you’re reproducing a significant portion of the code.
For example, writing a program that uses several chunks of code from this book does not require permission.
Selling or distributing examples from O’Reilly books does require permission.
Answering a question by citing this book and quoting example code does not require permission.
Incorporating a significant amount of example code from this book into your product’s documentation does require 
<span class="keep-together">permission.</span></p>

<p>We appreciate, but generally do not require, attribution.
An attribution usually includes the title, author, publisher, and ISBN.
For example, “<em>Building Generative AI Services with FastAPI</em> by Alireza Parandeh (O’Reilly).
Copyright 2025 Ali Parandeh, 978-1-098-16030-2.”</p>

<p>If you feel your use of code examples falls outside fair use or the permission given above, feel free to contact us at <a class="email" href="mailto:permissions@oreilly.com"><em>permissions@oreilly.com</em></a>.</p>
</div></section>






<section data-pdf-bookmark="O’Reilly Online Learning" data-type="sect1"><div class="sect1" id="id436">
<h1>O’Reilly Online Learning</h1>
<div class="ormenabled" data-type="note" epub:type="note"><h6>Note</h6>
<p>For more than 40 years, <a class="orm:hideurl" href="https://oreilly.com"><em class="hyperlink">O’Reilly Media</em></a> has provided technology and business training, knowledge, and insight to help companies succeed.</p>
</div>

<p>Our unique network of experts and innovators share their knowledge and expertise through books, articles, and our online learning platform.
O’Reilly’s online learning platform gives you on-demand access to live training courses, in-depth learning paths, interactive coding environments, and a vast collection of text and video from O’Reilly and 200+ other publishers.
For more information, visit <a class="orm:hideurl" href="https://oreilly.com"><em>https://oreilly.com</em></a>.</p>
</div></section>






<section data-pdf-bookmark="How to Contact Us" data-type="sect1"><div class="sect1" id="id437">
<h1>How to Contact Us</h1>

<p>Please address comments and questions concerning this book to the publisher:</p>
<ul class="simplelist">
  <li>O’Reilly Media, Inc.</li>
  <li>1005 Gravenstein Highway North</li>
  <li>Sebastopol, CA 95472</li>
  <li>800-889-8969 (in the United States or Canada)</li>
  <li>707-827-7019 (international or local)</li>
  <li>707-829-0104 (fax)</li>
  <li><a class="email" href="mailto:support@oreilly.com"><em>support@oreilly.com</em></a></li>
  <li><a href="https://oreilly.com/about/contact.html"><em>https://oreilly.com/about/contact.html</em></a></li>
</ul>

<p>We have a web page for this book, where we list errata, examples, and any additional information. You can access this page at <a class="bare" href="https://oreil.ly/building-gen-ai-fastAPI"><em class="hyperlink">https://oreil.ly/building-gen-ai-fastAPI</em></a>.</p>
<!--Don't forget to update the link above.-->

<p>For news and information about our books and courses, visit <a class="bare" href="https://oreilly.com"><em class="hyperlink">https://oreilly.com</em></a>.</p>

<p>Find us on LinkedIn: <a class="bare" href="https://linkedin.com/company/oreilly-media"><em class="hyperlink">https://linkedin.com/company/oreilly-media</em></a>.</p>

<p>Watch us on YouTube: <a class="bare" href="https://youtube.com/oreillymedia"><em class="hyperlink">https://youtube.com/oreillymedia</em></a>.</p>
</div></section>






<section data-pdf-bookmark="Acknowledgments" data-type="sect1"><div class="sect1" id="id438">
<h1>Acknowledgments</h1>

<p>Writing this book has been an incredible experience and journey for me.
My deepest gratitude to my family for their unconditional support during the writing process.
I would like to give special recognition to my sister, Tara Parandeh; my parents, Mansoureh Tahabaz and Mohammadreza Parandeh; and my partner, Cherry Waller.</p>

<p>I’m grateful to the friends, colleagues, collaborators, and ADSP folks who helped cultivate a supportive environment.
Thank you to David Foster, Ross Witeszczak, Amy Bull, Zine Eddine, Joe Rowe, Jonathan Davies, Aneta Blazyczek, Giulia Scardovi, Maddy Clements, Sarah Davies, Evelina Kireilyte, Khaleel Syed, Rob Foster, Mai Do, Bogdan Bija, Nicholas Rawitscher Torres, Snehan Sighat, and Leon Watson.</p>

<p>Specifically, I would like to thank my mentor, David Foster, author of <em>Generative Deep Learning</em> (O’Reilly), for inspiring me to write my own book.
His book was a source of learning and inspiration on generative AI during the drafting process. In addition, I’m grateful to the close friends who played a role in shaping my career: Lee Dalchow, Isaac Cleave, and Rabah Tahraoui.</p>

<p>Working with O’Reilly was incredible.
Special thanks to my wonderful editors Rita Fernando and Melissa Potter for their support during the writing process, enthusiasm, and excellent feedback.
I could not have asked for better editors.
Thanks to Clare Laylock for preparing early release chapters and fixing formatting issues during the process.
Seeing these chapters on the O’Reilly platform and receiving positive feedback from readers was a significant motivator with writing.
Also thanks to Nicole Butterfield and Amanda Quinn for their help in realizing this book and kick-starting the project.</p>

<p>Lastly, massive thanks to my technical reviewers, David Foster, Joe Rowe, and Julien Brendel, for their meticulous and detailed run-through of the book.
Each reviewer contributed a different perspective to ensure all inconsistencies, inaccuracies, and gaps were addressed.
Without their input, the quality of this book would have 
<span class="keep-together">suffered.</span></p>
</div></section>
</div></section></body></html>