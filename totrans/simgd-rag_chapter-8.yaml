- en: 8 Graph, multimodal, agentic, and other RAG variants
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8 图、多模态、代理式和其他RAG变体
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Introducing RAG variants
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍RAG变体
- en: Knowledge graph RAG
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 知识图谱RAG
- en: Multimodal RAG
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多模态RAG
- en: Agentic RAG
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代理式RAG
- en: Other RAG variants
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他RAG变体
- en: The first part of the book introduced retrieval-augmented generation (RAG) and
    the core idea behind it. The second part dealt with building and evaluating basic
    RAG systems. Part 3 took RAG beyond the naïve approach and discussed advanced
    techniques and the technology stack that supports a RAG system. The last part
    of the book looks at more RAG patterns, and we conclude our discussion with a
    few best practices and some areas for further exploration.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的第一部分介绍了检索增强生成（RAG）及其背后的核心思想。第二部分处理了构建和评估基本RAG系统。第三部分将RAG超越了简单方法，讨论了高级技术和支持RAG系统的技术栈。本书的最后部分探讨了更多的RAG模式，并以一些最佳实践和一些进一步探索的领域结束我们的讨论。
- en: Chapter 8 looks at some popular RAG variants. These variants adapt different
    stages of RAG (i.e., indexing, retrieval, augmentation, and generation) to specific
    use case requirements. The chapter begins by discussing the emergence of these
    variants and the purpose they serve. We then continue talking about three important
    variants that have gained prominence in applied RAG. These are knowledge-graph-enhanced,
    multimodal, and agentic RAG. We also briefly examine other RAG variants that significantly
    contribute to the evolution of RAG in practical applications. We discuss the purpose
    and motivation behind each variant. This chapter also breaks down the workflow,
    features, and technical details of the variants along with their strengths and
    weaknesses. For simplicity, the code for these variants is not included in this
    chapter but can be found in the book’s code repository.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 第8章探讨了几个流行的RAG变体。这些变体将RAG的不同阶段（即索引、检索、增强和生成）适应特定的用例需求。本章首先讨论了这些变体的出现及其目的。然后我们继续讨论在应用RAG中取得显著成效的三个重要变体。这些是知识图谱增强型、多模态和代理式RAG。我们还简要考察了其他对RAG在实际应用中的进化有显著贡献的RAG变体。我们讨论了每个变体的目的和动机。本章还分析了这些变体的工作流程、特性和技术细节，以及它们的优缺点。为了简化，这些变体的代码不包括在本章中，但可以在本书的代码仓库中找到。
- en: By the end of this chapter, you should
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你应该
- en: Be familiar with the idea and motivation behind RAG variants.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解RAG变体的思想和动机。
- en: Have an in-depth understanding of graph, multimodal, and agentic RAG.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 深入理解图、多模态和代理式RAG。
- en: Be aware of several popular RAG variants and the use cases they solve.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解几个流行的RAG变体及其解决的用例。
- en: There are several limitations of a naïve approach to RAG that affect the overall
    usability of a standard RAG system. These limitations range from difficulties
    in understanding relationships across different documents to challenges in handling
    various data types, as well as concerns regarding system cost and efficiency.
    Chapter 6 discussed several pre-retrieval, retrieval, and post-retrieval techniques,
    such as index optimization, query optimization, hybrid and iterative retrieval
    strategies, compression, and re-ranking, which address different limitations and
    improve the accuracy of a RAG system. Several RAG patterns that incorporate one
    or more of these techniques have emerged over time to solve specific use challenges.
    We refer to them as RAG variants.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 对RAG的简单方法存在几个局限性，这些局限性影响了标准RAG系统的整体可用性。这些局限性从理解不同文档之间关系上的困难到处理各种数据类型，以及关于系统成本和效率的担忧。第6章讨论了几种检索前、检索和检索后的技术，如索引优化、查询优化、混合和迭代检索策略、压缩和重新排序，这些技术针对不同的局限性并提高了RAG系统的准确性。随着时间的推移，出现了一些结合了这些技术之一或多个的RAG模式，以解决特定的用例挑战。我们将它们称为RAG变体。
- en: 8.1 What are RAG variants, and why do we need them?
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.1 RAG变体是什么，为什么我们需要它们？
- en: The universe of applications that rely on RAG is expanding every day. Some of
    these applications process not just text, but different data modalities such as
    image, video, and audio as well. Others are being applied in domains such as healthcare
    and finance, where the effects of inaccurate results are catastrophic. The emerging
    domain of using LLMs as decision-making agents has also enabled a more adaptive
    and intelligent RAG system. Apart from factual accuracy, practical RAG applications
    demand low latency and low costs to enhance user experience and adoption. As the
    range of applications for RAG has expanded, so need specialized variations of
    RAG—known as RAG variants—designed to address unique challenges across different
    tasks and data types.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖于RAG的应用程序每天都在扩展。其中一些应用程序不仅处理文本，还处理不同的数据模态，如图像、视频和音频。其他应用领域如医疗保健和金融，不准确的结果可能带来灾难性的影响。使用LLMs作为决策代理的新兴领域也使得RAG系统更加适应和智能。除了事实准确性外，实际的RAG应用还需要低延迟和低成本，以提升用户体验和采用率。随着RAG应用范围的扩大，需要专门化的RAG变体——称为RAG变体——来应对不同任务和数据类型中的独特挑战。
- en: These RAG variants are adaptations of the standard RAG framework that extend
    its functionality to meet demands of diverse and complex use cases. By employing
    advanced pre-retrieval, retrieval and post-retrieval techniques, these variants
    enhance RAG with capabilities such as handling multimodal data, providing higher
    accuracy, and better relational understanding. The evolution of these RAG variants
    makes the system both flexible and domain aware.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这些RAG变体是对标准RAG框架的适应性调整，扩展了其功能以满足多样化的复杂用例需求。通过采用先进的预检索、检索和后检索技术，这些变体增强了RAG，使其具备处理多模态数据、提供更高准确性和更好的关系理解等能力。这些RAG变体的演变使得系统既灵活又具有领域意识。
- en: 'While several RAG variants have emerged, the three that we are going to discuss
    in-depth in the subsequent sections have gained prominence:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然已经出现了几种RAG变体，但我们在接下来的几节中将深入讨论的三个变体已经获得了显著的关注：
- en: '*Multimodal RA**G*—Extends capabilities of the standard RAG beyond text data
    and incorporates other data types such as images, video, and audio. This characteristic
    enables the system to fetch information from nontextual documents and provide
    additional context.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*多模态RA**G**——扩展了标准RAG的功能，使其超越文本数据，并整合了其他数据类型，如图像、视频和音频。这一特性使得系统能够从非文本文档中获取信息，并提供额外的上下文。'
- en: '*Knowledge graph RA**G*—Integrates knowledge graphs into the retrieval process.
    This idea was introduced in chapter 6 as part of improving the indexing structure.
    Knowledge graphs help establish relationships between entities, providing better
    context, especially in multi-hop queries.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*知识图谱RA**G**——将知识图谱整合到检索过程中。这一想法在第6章中作为改进索引结构的一部分被引入。知识图谱有助于建立实体之间的关系，提供更好的上下文，特别是在多跳查询中。'
- en: '*Agentic RA**G*—Incorporates LLM agents into the RAG framework. These agents
    enable autonomous decision making across the RAG value chain from indexing to
    generation. Simultaneously, all components become adaptive to the user query.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*代理RA**G**——将LLM代理整合到RAG框架中。这些代理能够在RAG价值链的索引到生成过程中实现自主决策。同时，所有组件都适应用户查询。'
- en: In addition to these three, we also touch upon additional variants, such as
    corrective RAG, self-RAG, and more, but first, we begin by discussing multimodality.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这三个之外，我们还涉及到一些额外的变体，例如校正RAG、自RAG等，但首先，我们从多模态开始讨论。
- en: 8.2 Multimodal RAG
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.2 多模态RAG
- en: Until now, we have seen that standard RAG systems are effective in managing
    and retrieving textual data to generate context-aware and grounded responses.
    However, the scope of enterprise data extends beyond text to image, audio, and
    video. Standard RAG systems fall short when attempting to interpret nontextual
    data formats. This is the core motivation behind a multimodal variant of RAG,
    which extends the capabilities to more data formats.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 迄今为止，我们已经看到标准RAG系统在管理和检索文本数据以生成上下文感知和基于事实的响应方面是有效的。然而，企业数据范围超出了文本，还包括图像、音频和视频。当尝试解释非文本数据格式时，标准RAG系统显得力不从心。这就是多模态RAG变体的核心动机，它扩展了能力以支持更多数据格式。
- en: 8.2.1 Data modality
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.1 数据模态
- en: Multimodality can be a confusing term for the uninitiated, especially because
    “modality” varies in meaning across different fields. Grammatical modality relates
    to the expression of the speaker’s attitude, while treatment modality may refer
    to the medical approach in medicine. In RAG, and AI in general, modality refers
    to data format. Text is a modality, image is a modality, video and audio are different
    modalities, and we can also consider tables and code as distinct modalities. Figure
    8.1 shows some data modalities, including less common ones such as genomic and
    3D data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '![A group of icons with text'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: AI-generated content may be incorrect.](../Images/CH08_F01_Kimothi.png)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.1  Examples of different data modalities
  id: totrans-28
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Multimodal RAG is, therefore, the extended variant of standard RAG with the
    capability to process multiple data modalities. Before diving into the requirements
    and architectural details of multimodal RAG, let’s ponder over the use cases where
    multimodal RAG is necessary.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: 8.2.2 Multimodal RAG use cases
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are several industries and functions where a multimodal variant of RAG
    is required, such as
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '*Medical diagnosi**s*—A diagnostic assistant can work with patient records
    that may include medical history (in text form), lab results (in tabular form),
    and diagnostic images (like X-rays, MRIs, etc.), along with studies and research
    papers that include graphs, charts, or microscopic images. When the patient comes
    in for a consultation, this assistant can provide a holistic analysis to the doctor.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Investment analysi**s*—Working with financial reports and other filings that
    have charts showing trends, earnings, and projections along with balance sheets
    and income statements in tabular form, apart from the usual text commentary, an
    investment research assistant can provide analysts with crucial information needed
    to make investment decisions.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Buying assistanc**e*—Through an analysis of product images, textual descriptions,
    product specifications (in tabular form), and customer reviews, a shopping assistant
    can help the shoppers on an e-commerce website with personalized recommendations.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Coding assistanc**e*—Coding assistants retrieve relevant documentation, function
    usage examples, and code snippets from repositories based on the query context.
    For example, when a developer asks how to implement a certain API function. The
    RAG system retrieves precise code snippets and explanations from the documentation,
    helping the developer avoid time-consuming searches.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Equipment maintenanc**e*—Using historical text reports with visual inspection
    images or video feed, sensor data, and performance tables, a maintenance assistant
    can provide maintenance recommendations and trends.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are just a few examples. While standard text-only RAG finds acceptability
    in the initial stages of a use case, a large proportion of production-grade RAG
    systems incorporate at least one other modality of data.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: 8.2.3 Multimodal RAG pipelines
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s now explore how developing a multimodal RAG pipeline differs from a standard
    text-only RAG pipeline you have learned so far. An obvious change will be in loading
    and indexing the data of nontext modalities.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来探讨开发多模态RAG管道与您迄今为止所学的标准文本RAG管道有何不同。一个明显的改变将是在加载和索引非文本模态的数据。
- en: Multimodal indexing pipeline
  id: totrans-40
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 多模态索引管道
- en: Developing the knowledge base for multimodal RAG requires enhancement in each
    of the four components of the indexing pipelines. Apart from loading and chunking
    files of different modalities, creating embeddings for multimodal data requires
    special attention. Let’s look at each of the components one by one.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 开发多模态RAG的知识库需要对索引管道的四个组件进行增强。除了加载和分块不同模态的文件外，为多模态数据创建嵌入也需要特别注意。让我们逐一查看每个组件。
- en: '*The data-loading step* is quite like the standard text-only RAG but now includes
    connectors and data loaders for nontext modalities. There are several options
    available. `Pillow`, also known as `PIL`, is a popular Python library for loading
    images. `Unstructured` is an open source library that includes components for
    ingesting a variety of data formats. `Pydub` is another Python library that allows
    the loading of audio files such as WAV and MP3\. LangChain provides an integration
    with the unstructured library. `UnstructuredImageLoader` is a class available
    in LangChain document loaders for loading images. For audio and video transcription,
    libraries such as `OpenAIWhisperParser`, `AssemblyAIAudioTranscriptLoader`, and
    `YoutubeLoader` can be used. Likewise, for tabular data `CSVLoader` and `DataFrameLoader`
    come in handy. For simplicity, sometimes data of different modalities is transcribed
    into text.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据加载步骤*与仅文本的RAG标准流程非常相似，但现在包括了连接器和用于非文本模态的数据加载器。有几种选项可供选择。`Pillow`，也称为`PIL`，是一个流行的Python库，用于加载图像。`Unstructured`是一个开源库，包括用于摄入各种数据格式的组件。`Pydub`是另一个Python库，允许加载WAV和MP3等音频文件。LangChain提供了与未结构化库的集成。`UnstructuredImageLoader`是LangChain文档加载器中可用于加载图像的一个类。对于音频和视频转录，可以使用`OpenAIWhisperParser`、`AssemblyAIAudioTranscriptLoader`和`YoutubeLoader`等库。同样，对于表格数据，`CSVLoader`和`DataFrameLoader`也很有用。为了简单起见，有时不同模态的数据会被转录成文本。'
- en: '*Chunking* for multimodal data largely follows a process similar to text chunking
    in cases where audio/video data is transcribed and stored as text. However, for
    raw audio and video data, specific chunking methods can be employed. Voice activity
    detection (VAD) chunks the data based on silences or background noise in the audio.
    Scene-detection-based chunking identifies major changes in the scene to segment
    the video. For tabular data, sometimes row/column-level chunking can be incorporated,
    and for code, the chunking can be carried out at a function, a class, or a logical
    unit level. All strategies used for chunking text data such as context enrichment,
    semantic chunking, and similar are also held here. For images, chunking is generally
    not done. `semantic_chunkers` is a multimodal chunking library for intelligent
    chunking of text, video, and audio. It makes AI and data processing more efficient
    and accurate.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '*分块*对于多模态数据在很大程度上遵循与文本分块类似的过程，在音频/视频数据被转录并存储为文本的情况下。然而，对于原始音频和视频数据，可以采用特定的分块方法。语音活动检测（VAD）根据音频中的静默或背景噪声来分块数据。基于场景检测的分块识别场景中的主要变化以分割视频。对于表格数据，有时可以结合行/列级别的分块，而对于代码，分块可以在函数、类或逻辑单元级别进行。所有用于分块文本数据的策略，如上下文丰富、语义分块等，也在这里适用。对于图像，通常不进行分块。`semantic_chunkers`是一个用于智能分块文本、视频和音频的多模态分块库。它使AI和数据处理更加高效和准确。'
- en: '*Embeddings* is where nuance begins in multimodal RAG. In standard text-only
    RAG, there are several embeddings models available to vectorize the chunks. But
    how does one vectorize data of different modalities, such as an image? There are
    three approaches to deal with this complexity: shared or joint embedding models,
    modality-specific embeddings, and conversion of all non-text data into text.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在多模态RAG中，*嵌入*是细微差别开始的地方。在标准的仅文本RAG中，有几种嵌入模型可用于将分块向量化。但如何将不同模态的数据，如图像，向量化呢？处理这种复杂性的方法有三种：共享或联合嵌入模型、特定模态的嵌入以及将所有非文本数据转换为文本。
- en: Shared or joint embeddings models map diverse data types into a unified embeddings
    space. By doing this, cross-modal retrieval is enabled, such as finding images
    based on textual descriptions or generating text from images. Google Vertex AI
    offers shared embeddings models that generate vectors for all data modalities
    in the unified embeddings space. Shared embeddings models are also called multimodal
    embeddings models. While efficient at understanding general image data, multimodal
    embeddings sometimes fall short when granular understanding is needed, as in charts
    and tables represented as images and infographics. In figure 8.2, image, text,
    audio, and video data are plotted in the same 3D vector space.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 共享或联合嵌入模型将不同的数据类型映射到一个统一的嵌入空间中。通过这样做，实现了跨模态检索，例如根据文本描述查找图像或从图像生成文本。Google Vertex
    AI提供共享嵌入模型，该模型在统一的嵌入空间中为所有数据模态生成向量。共享嵌入模型也称为多模态嵌入模型。虽然多模态嵌入在理解一般图像数据方面效率很高，但在需要细粒度理解时（如图表和表格以图像和信息图表的形式表示），有时会不足。在图8.2中，图像、文本、音频和视频数据被绘制在同一个3D向量空间中。
- en: The modality-specific embeddings approach resemble multimodal embeddings, except
    that instead of a single embeddings space for all modalities, the embeddings space
    maps only two modalities. In such a scenario, we need an image–text embeddings
    model to process text, image, and audio data (e.g., Contrastive Language–Image
    Pretraining, or CLIP) and an audio-text embeddings model (e.g., Contrastive Language–Audio
    Pretraining, or CLAP). The knowledge base has text, image, and audio embeddings
    in different embeddings spaces and stored separately. Figure 8.3 is an example
    of CLIP image–text embeddings where image and text embeddings are projected onto
    a shared embeddings space.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 模态特定嵌入方法类似于多模态嵌入，但不同之处在于，它不是为所有模态提供一个单一的嵌入空间，而是仅映射两种模态。在这种情况下，我们需要一个图像-文本嵌入模型来处理文本、图像和音频数据（例如，对比语言-图像预训练，或CLIP）以及一个音频-文本嵌入模型（例如，对比语言-音频预训练，或CLAP）。知识库在不同的嵌入空间中存储文本、图像和音频嵌入，并分别存储。图8.3是CLIP图像-文本嵌入的一个例子，其中图像和文本嵌入被投影到一个共享的嵌入空间中。
- en: '![A diagram of a dog'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '![狗的示意图'
- en: AI-generated content may be incorrect.](../Images/CH08_F02_Kimothi.png)
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的内容可能是不正确的。](../Images/CH08_F02_Kimothi.png)
- en: Figure 8.2 Images, text, video, and audio are plotted on the same embeddings
    space. Dog, bark, and dog’s image are close to each other.
  id: totrans-49
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.2 图像、文本、视频和音频被绘制在同一个嵌入空间中。狗、吠叫和狗的图像彼此靠近。
- en: '![A diagram of a number of letters'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '![多个字母的示意图'
- en: AI-generated content may be incorrect.](../Images/CH08_F03_Kimothi.png)
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的内容可能是不正确的。](../Images/CH08_F03_Kimothi.png)
- en: Figure 8.3  CLIP uses multimodal pre-training to convert classification into
    a retrieval task, which enables pre-trained models to tackle zero-shot recognition.
  id: totrans-52
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.3  CLIP通过多模态预训练将分类转换为检索任务，这使得预训练模型能够处理零样本识别。
- en: Conversion of all non-text data into text is employed to first convert all nontext
    (image) data into text using a multimodal LLM and then follow the standard text-only
    RAG approach. (A multimodal LLM is a large language model that processes all modalities
    of data. You will read more about multimodal LLMs later in this section.) In this
    strategy, you may notice that we may not be entirely using multimodal data as
    information loss is bound to occur when converting nontext to text data. In a
    variation of this strategy, instead of converting all multimodal data into text
    and using it as text, a two-pronged approach is employed. Here all multimodal
    data is summarized in text using a multimodal LLM. Embeddings of this text are
    used to search for during the retrieval process. However, for generation, not
    only the summary but the actual multimodal file (e.g., a .jpeg) is retrieved and
    passed to the multimodal LLM for generation. This reduces the loss of information
    when converting to text.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有非文本数据转换为文本，首先使用多模态LLM将所有非文本（图像）数据转换为文本，然后遵循仅文本的RAG方法。 (多模态LLM是一种处理所有数据模态的大型语言模型。你将在本节后面了解更多关于多模态LLM的信息。)
    在这种策略中，你可能注意到我们可能并没有完全使用多模态数据，因为将非文本转换为文本数据时必然会发生信息损失。在这种策略的一种变体中，我们不是将所有多模态数据转换为文本并使用它，而是采用双管齐下的方法。在这里，所有多模态数据都使用多模态LLM进行总结。在检索过程中，使用这些文本的嵌入进行搜索。然而，对于生成，不仅需要检索总结，还需要检索实际的多模态文件（例如，一个.jpeg文件）并将其传递给多模态LLM进行生成。这减少了转换为文本时的信息损失。
- en: Embeddings, either multimodal or text, are *stored* in vector databases such
    as standard text-only RAG. In addition to vector storage, document storage is
    required to store raw files that can be retrieved and passed to the LLM for generation.
    Document stores such as Redis can be used to store raw files. When text summaries
    are used, a key mapping of the summary embeddings to the raw documents must be
    created. Figure 8.4 shows the indexing pipeline with all three options for embeddings.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入，无论是多模态还是文本，都*存储*在向量数据库中，例如标准的仅文本RAG。除了向量存储外，还需要文档存储来存储可以检索并传递给LLM进行生成的原始文件。可以使用如Redis这样的文档存储来存储原始文件。当使用文本摘要时，必须创建摘要嵌入到原始文档的关键映射。图8.4显示了包含所有三种嵌入选项的索引管道。
- en: '![A diagram of a diagram'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '![一个图表的图表'
- en: AI-generated content may be incorrect.](../Images/CH08_F04_Kimothi.png)
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的内容可能是不正确的。](../Images/CH08_F04_Kimothi.png)
- en: Figure 8.4  Multimodal indexing pipeline presenting three options
  id: totrans-57
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.4 多模态索引管道展示三种选项
- en: While the loading, chunking, and storage components are similar, the embedding
    component presents several options in multimodal RAG. Table 8.1 compares the indexing
    pipelines of text-only RAG and multimodal RAG.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然加载、分块和存储组件相似，但在多模态RAG中，嵌入组件提供了几个选项。表8.1比较了仅文本RAG和多模态RAG的索引管道。
- en: Table 8.1 Indexing pipelines of text-only vs. multimodal RAG
  id: totrans-59
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表8.1 仅文本RAG与多模态RAG的索引管道
- en: '| Indexing component | Text-only RAG | Multimodal RAG |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 索引组件 | 仅文本RAG | 多模态RAG |'
- en: '| Loading | Standard text data loaders are used to load documents, such as
    plain text files, PDFs, and other text-based formats. | Requires connectors for
    additional data types. For images, libraries such as `Pillow` (`PIL`) and `Unstructured­ImageLoader`
    in LangChain are used; for audio, we use libraries such as `Pydub` or `OpenAIWhisperParser`,
    whereas `CSVLoader` and `DataFrameLoader` are used for tabular data. Audio and
    video transcription tools such as AssemblyAI and YoutubeLoader are also incorporated
    to preprocess audio/video content. |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 加载 | 使用标准的文本数据加载器来加载文档，例如纯文本文件、PDF和其他基于文本的格式。 | 需要连接器来处理额外的数据类型。对于图像，使用如`Pillow`（`PIL`）和LangChain中的`Unstructured­ImageLoader`库；对于音频，我们使用如`Pydub`或`OpenAIWhisperParser`的库，而对于表格数据，则使用`CSVLoader`和`DataFrameLoader`。还纳入了如AssemblyAI和YoutubeLoader这样的音频/视频转录工具来预处理音频/视频内容。
    |'
- en: '| Chunking | Text data is divided into segments (chunks) based on context or
    structure (e.g., sentences, paragraphs) and optionally enriched semantically.
    | Follows text chunking when data is transcribed to text (audio/video). For raw
    audio, voice activity detection (VAD) can be used to chunk by pauses. For videos,
    scene detection identifies visual transitions, and tabular data can be chunked
    row/column-wise. Image chunking is typically skipped. |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 分块 | 根据上下文或结构（例如，句子、段落）将文本数据划分为段（分块），并可选地进行语义丰富。 | 当数据被转录为文本（音频/视频）时，遵循文本分块。对于原始音频，可以使用语音活动检测（VAD）通过停顿进行分块。对于视频，场景检测识别视觉转换，而表格数据可以按行/列进行分块。通常跳过图像分块。
    |'
- en: '| Embeddings | Text embeddings are created using a single-modality text embeddings
    model (e.g., OpenAI embeddings or BERT), which vectorizes each chunk for storage
    and retrieval. | Embeddings can be generated via multimodal embeddings models,
    which unify all data types in a shared vector space for cross-modal retrieval,
    modality-specific embeddings such as CLIP and CLAP or converting multimodal data
    to text first and use text embeddings, although this may cause information loss.
    |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 嵌入 | 使用单模态文本嵌入模型（例如，OpenAI嵌入或BERT）创建文本嵌入，该模型将每个分块向量化以进行存储和检索。 | 嵌入可以通过多模态嵌入模型生成，这些模型将所有数据类型统一到一个共享的向量空间中，以实现跨模态检索，或者使用特定于模态的嵌入（如CLIP和CLAP）或将多模态数据首先转换为文本并使用文本嵌入，尽管这可能会导致信息丢失。
    |'
- en: '| Storage | Embeddings are stored in vector databases. | Embeddings are stored
    in vector databases, but additional document storage for raw multimodal files
    may be used. |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 存储 | 嵌入被存储在向量数据库中。 | 嵌入被存储在向量数据库中，但可能还会使用额外的文档存储来存储原始的多模态文件。 |'
- en: Once the knowledge base is created, such as in text-only RAG, the generation
    pipeline is responsible for real-time interaction with the knowledge base. Depending
    on the embedding strategy used, the generation pipeline components adapt to incorporate
    multimodal data.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建了知识库，例如在仅文本RAG中，生成管道负责与知识库进行实时交互。根据所使用的嵌入策略，生成管道组件会适应以包含多模态数据。
- en: Multimodal generation pipeline
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 多模态生成管道
- en: 'Once the knowledge base is created by the indexing pipeline, the generation
    pipeline needs to search, retrieve, process, and generate multimodal data. This
    requires variations in retrieval approach and a multimodal LLM:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦索引管道创建了知识库，生成管道需要搜索、检索、处理和生成多模态数据。这需要检索方法的变体和多模态 LLM：
- en: '*Retrieva**l*—Depending on the embeddings strategy, the retrieval technique
    varies:'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*检索*—根据嵌入策略，检索技术会有所不同：'
- en: In case a shared multimodal embeddings model is used, the retrieval process
    follows a similarity search approach, where the user query is converted into a
    vector form using the same multimodal embeddings, and the documents are retrieved
    based on their cosine similarity value irrespective of their modality.
  id: totrans-69
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果使用共享的多模态嵌入模型，检索过程遵循相似度搜索方法，其中用户查询使用相同的模态嵌入转换为向量形式，并根据它们的余弦相似度值检索文档，无论它们的模态如何。
- en: In the modality-specific embedding approach, because multiple embeddings are
    present, a multi-vector retrieval approach is employed. For a single query, documents
    are retrieved from each modality-specific embeddings space based on similarity.
    These documents may later be re-ranked before augmentation and generation.
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在模态特定嵌入方法中，由于存在多个嵌入，采用了多向量检索方法。对于单个查询，根据相似度从每个模态特定嵌入空间检索文档。这些文档在增强和生成之前可能会被重新排序。
- en: When nontext data is converted into text, the retrieval process is the same
    as the standard text-only RAG. In the variation where both text summaries and
    raw files are used, the retriever first retrieves the relevant summaries from
    the text embeddings space, and then the files from the document stores mapped
    to those summaries are also retrieved.
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当非文本数据转换为文本时，检索过程与标准仅文本 RAG 相同。在同时使用文本摘要和原始文件的变化中，检索器首先从文本嵌入空间检索相关摘要，然后检索映射到这些摘要的文档存储中的文件。
- en: '*Augmentatio**n*—The augmentation step remains the same as text-only RAG, except
    that the augmented prompt now includes the raw multimodal file accompanying the
    text prompt.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*增强*—增强步骤与仅文本 RAG 相同，只是增强提示现在包括与文本提示一起的原始多模态文件。'
- en: '*Generatio**n*—Like multimodal embeddings, for processing and generating multimodal
    data, multimodal LLMs are used. LLMs are limited by their ability to process text
    data only. Multimodal LLMs are transformers-based models, too, but have been trained
    on data of all modalities, in addition to text data. There are nuanced differences
    in the training process of multimodal LLMs, and the readers are encouraged to
    explore them. However, for building RAG systems, we can use the available foundation
    multimodal LLMs. OpenAI’s GPT 4o and GPT 4o mini and Google’s Gemini are popular
    proprietary multimodal LLMs, while Meta’s Llama 3.2 and Mistral AI’s Pixtral are
    open source multimodal LLMs.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*生成*—类似于多模态嵌入，为了处理和生成多模态数据，使用多模态 LLMs。LLMs 受限于只能处理文本数据的能力。多模态 LLMs 也是基于 transformers
    的模型，但除了文本数据外，还训练了所有模态的数据。多模态 LLMs 的训练过程存在细微的差异，鼓励读者探索它们。然而，对于构建 RAG 系统，我们可以使用可用的基础多模态
    LLMs。OpenAI 的 GPT 4o 和 GPT 4o mini 以及 Google 的 Gemini 是流行的专有多模态 LLMs，而 Meta 的
    Llama 3.2 和 Mistral AI 的 Pixtral 是开源的多模态 LLMs。'
- en: While the augmentation step remains similar to text-only RAG, the retrieval
    step adapts based on the embeddings strategy used, and the generation step swaps
    the LLMs with multimodal LLMs. The differences in the generation pipelines are
    highlighted in
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然增强步骤与仅文本 RAG 相似，但检索步骤根据所使用的嵌入策略进行适应，生成步骤则将 LLMs 替换为多模态 LLMs。生成管道中的差异在
- en: table 8.2\.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8.2\.
- en: Table 8.2 Indexing pipelines of text-only vs. multimodal RAG
  id: totrans-76
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 8.2 仅文本 RAG 与多模态 RAG 的索引管道
- en: '| Generation component | Text-only RAG | Multimodal RAG |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 生成组件 | 仅文本 RAG | 多模态 RAG |'
- en: '| Retrieval | Retrieves similar text embeddings to the query using similarity
    search | Varies by embedding strategy—in shared embeddings model, a similarity
    search is employed regardless of modality, converting the query into a multimodal
    vector. In modality-specific embeddings, multi-vector retrieval is used for modality-specific
    results, and in text-converted nontext data, a standard text retrieval along with
    raw files mapped to text summaries is used. |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 检索 | 使用相似度搜索检索与查询相似的文本嵌入 | 根据嵌入策略而变化——在共享嵌入模型中，无论模态如何，都采用相似度搜索，将查询转换为多模态向量。在模态特定嵌入中，使用多向量检索用于特定模态的结果，在文本转换的非文本数据中，使用标准的文本检索以及映射到文本摘要的原始文件。|'
- en: '| Augmentation | Adds retrieved text to the prompt | Similar to text-only but
    includes the raw multimodal files alongside the text in the prompt. |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 增强 | 将检索到的文本添加到提示中 | 与纯文本类似，但在提示中包括文本旁边的原始多模态文件。|'
- en: '| Generation | Uses LLMs to generate responses | Uses multimodal LLMs instead
    of text-only LLMs. |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 生成 | 使用LLM生成响应 | 使用多模态LLM而不是纯文本LLM。|'
- en: By tweaking the indexing and generation pipelines, a standard text-only RAG
    system can be upgraded to a multimodal RAG system, as illustrated in figure 8.5.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 通过调整索引和生成管道，可以将标准的纯文本RAG系统升级为多模态RAG系统，如图8.5所示。
- en: '![A diagram of a multilevel system'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![多级系统图]'
- en: AI-generated content may be incorrect.](../Images/CH08_F05_Kimothi.png)
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: AI生成的内容可能是错误的。](../Images/CH08_F05_Kimothi.png)
- en: Figure 8.5  For each of the three approaches, the generation pipeline also adapts.
  id: totrans-84
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.5  对于这三种方法，生成管道也进行了调整。
- en: 8.2.4 Challenges and best practices
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.4 挑战和最佳实践
- en: Multimodal RAG systems are gaining prominence owing to the diversity present
    in enterprise data. However, one must note that with multimodality, the complexity
    of the system increases along with higher latency and more expenditure on multimodal
    embeddings and generation. Some of the common challenges associated with multimodal
    RAG are
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态RAG系统因企业数据中的多样性而日益受到重视。然而，必须注意，随着多模态的出现，系统的复杂性也随之增加，同时延迟更高，在多模态嵌入和生成上的支出也更多。与多模态RAG相关的一些常见挑战包括
- en: Ensuring coherent alignment between different data modalities (e.g., text and
    images) can be difficult. Utilizing multimodal embeddings projecting different
    modalities into a common embedding space does create better integration, but these
    embeddings models can still lead to inaccuracies and must be evaluated.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保不同数据模态（例如文本和图像）之间的一致性对齐可能很困难。利用将不同模态投影到公共嵌入空间的多模态嵌入确实可以创造更好的整合，但这些嵌入模型仍然可能导致不准确，必须进行评估。
- en: Handling multiple data types may increase computational requirements and processing
    time. Robust preprocessing pipelines to standardize and align data from various
    modalities are essential. Sometimes, converting multimodal data to text and following
    a text-only RAG approach may be enough to generate the desired results.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理多种数据类型可能会增加计算需求和处理时间。构建健壮的预处理管道，以标准化和调整来自各种模态的数据，是必不可少的。有时，将多模态数据转换为文本并采用仅文本的RAG方法可能就足以生成所需的结果。
- en: Not all models are capable of effectively processing and integrating multimodal
    data of all modalities. Incorporate only those that add significant value to the
    task to optimize performance and resource utilization.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 并非所有模型都能有效地处理和整合所有模态的多模态数据。仅包含那些对任务有显著价值的模型，以优化性能和资源利用。
- en: We have looked at a RAG variant that extends the capability of RAG to different
    data modalities. However, standard RAG is still deficient when the information
    is dispersed across different documents. Let’s now look at a pattern in which
    knowledge graphs are used to establish higher-order relationships.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经研究了一种RAG变体，它扩展了RAG对不同数据模态的能力。然而，当信息分散在不同文档中时，标准RAG仍然存在不足。现在让我们看看一种使用知识图来建立更高层次关系的模式。
- en: 8.3 Knowledge graph RAG
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.3 知识图RAG
- en: Imagine summarizing a large report or answering complex questions that draw
    information from diverse sources. For example, a question such as, “What are the
    main themes in this report?” or “Which products in the catalogue are endorsed
    by the same celebrities?” are questions that are difficult for standard RAG systems
    to answer.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下总结一份大型报告或回答需要从不同来源获取信息的复杂问题。例如，像“这份报告的主要主题是什么？”或“目录中哪些产品由相同的名人支持？”这样的问题对于标准的RAG系统来说很难回答。
- en: In a summarization task such as the “main themes” in a report, there is no chunk
    of the document that can answer the question completely. Likewise, “endorsed by
    the same celebrities” is not likely to be present in the data for the retriever
    to search through.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在像报告中的“主要主题”这样的摘要任务中，没有文档片段可以完全回答问题。同样，“由相同名人支持”的数据对于检索器搜索来说也不太可能存在。
- en: To answer these kinds of complex questions requiring multi-hop reasoning, identifying
    contextual relationships, and addressing higher-order queries, a powerful RAG
    pattern that incorporates knowledge graphs has been widely successful.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这些需要多跳推理、识别上下文关系和解决更高层次查询的复杂问题，一种结合知识图的强大RAG模式已经取得了广泛的成功。
- en: This pattern is called knowledge graph RAG or simply *graph RAG* (not to be
    confused with Microsoft’s GraphRAG, which is a specific framework of knowledge
    graph RAG). It must be noted here that graph RAG is not necessarily a replacement
    for standard vector-based RAG, but a hybrid approach in which both vectors and
    graphs are used to retrieve context. Before moving forward, The following sections
    explain what knowledge graphs are and what benefits are inherent to them.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: 8.3.1 Knowledge graphs
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The term *knowledge graph* was popularized by Google somewhere around 2012 by
    integrating an entity-relationship structure into its search engine to deliver
    more accurate and context-aware results. The simplest way to understand knowledge
    graphs is through the node-and-edge structure. Nodes may represent entities such
    as people, organizations, products, and events, and edges represent relationships
    between the nodes, such as *is a part of*, *works at*, *is related to*, and so
    on. The nodes and edges can also have attributes such as id, timestamp, and similar.
    Knowledge graphs, therefore, rely on semantics or meaning to create a shared,
    human-like, understanding of data. Figure 8.6 illustrates a simple knowledge graph
    with nodes, edges, and attributes for customer data.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Knowledge graphs offer several advantages over standard structured databases
    such as SQL by prioritizing relationships and context, which results in deeper
    data exploration. A standard row–column or a document storage does not allow for
    context a knowledge graph does.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: The storage and data processing in knowledge graphs is unique. Specialized databases
    such as Neo4j, Amazon Neptune, and TigerGraph are used to store knowledge graph
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '![A diagram of a product'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: AI-generated content may be incorrect.](../Images/CH08_F06_Kimothi.png)
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.6  Knowledge graph representation of customer activity where nodes
    (circles) represent entities, edges (arrows) represent relationships, and attributes
    (rectangles) are the properties.
  id: totrans-102
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: data, and query languages such as Cypher, Gremlin, and SparkQL are used for
    graph traversal. Readers are encouraged to learn more about graph databases, but
    some key concepts to keep in mind are
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '*Nodes and edge**s**—*Nodes represent entities, and edges represent relationships
    to form the graph structure and enable a visual structure to the knowledge.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Attribute**s*—Attributes are properties of entities(nodes) and relationships(edges).'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Triplet**s*—Knowledge is represented in triplets such as “customer A purchased
    product X” (node–edge–node). Here the two entities, “customer A” and “product
    X,” and one relationship, “purchased,” form a triplet. These triples are the building
    blocks of knowledge graphs, capturing facts and relationships in a structured
    way.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Ontolog**y*—An ontology defines the schema or structure of a knowledge graph,
    specifying the types of entities, relationships, and their properties.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Graph embedding**s*—Graph embeddings are vector representations of nodes and
    edges that capture graph structure.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*图嵌入*——图嵌入是节点和边的向量表示，它捕捉了图结构。'
- en: '*Graph query languag**e*—SPARQL, Cypher, and similar languages allow users
    to retrieve information from the graph, formulating complex queries to find patterns,
    connections, and insights.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*图查询语言*——SPARQL、Cypher和类似语言允许用户从图中检索信息，形成复杂的查询以找到模式、连接和洞察。'
- en: '*Graph traversa**l*—This is the method of navigating through nodes and edges
    to discover paths, patterns, and insights, essential for algorithms such as shortest
    path or recommendation systems.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*图遍历*——这是通过导航节点和边来发现路径、模式和洞察的方法，对于最短路径或推荐系统等算法至关重要。'
- en: Because of their inherent focus on relationships and context, knowledge graphs
    enhance standard RAG for a superior context-aware retrieval.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 由于它们内在关注关系和上下文，知识图谱增强了标准的RAG（关系型数据库查询语言），以实现更高级的上下文感知检索。
- en: 8.3.2 Knowledge graph RAG use cases
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.2 知识图谱RAG用例
- en: 'Knowledge graphs can be useful in a variety of use cases where the ability
    to handle multi-hop relationships, entity disambiguation, and complex networks
    is required. Standard RAG systems are limited to retrieving isolated information
    chunks, while knowledge graph RAG can dynamically connect and analyze data points
    within a network, making it ideal for applications requiring a deep understanding
    of interrelated data. Here are some examples:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱在需要处理多跳关系、实体消歧和复杂网络的各种用例中非常有用。标准的RAG系统仅限于检索孤立的信息块，而知识图谱RAG可以动态连接和分析网络中的数据点，使其非常适合需要深入理解相互关联数据的应用。以下是一些示例：
- en: '*Personalized treatment plan**s*—Knowledge graph RAG can link drugs, treatments,
    and conditions in a networked format, which allows it to identify potential interactions
    and customize treatment recommendations based on multiple factors. Standard RAG
    can retrieve information about a specific drug or treatment but struggles to cross-reference
    interactions across a network of symptoms, conditions, and treatments.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*个性化治疗方案*——知识图谱RAG可以以网络格式链接药物、治疗和条件，这使得它可以识别潜在的相互作用，并根据多个因素定制治疗方案。标准的RAG可以检索有关特定药物或治疗的信息，但难以在症状、条件和治疗网络中进行交叉引用。'
- en: '*Personalized product recommendation**s*—Standard RAG can retrieve individual
    touchpoints or customer reviews but fails to capture the interconnected path a
    customer follows across their journey. Knowledge graph RAG allows for multi-hop
    reasoning across transactions, browsing history, and customer feedback, enabling
    a more holistic analysis of the journey and providing highly relevant recommendations
    based on relationships between customer behaviors and preferences.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*个性化产品推荐*——标准的RAG可以检索个人接触点或客户评价，但无法捕捉客户在其旅程中遵循的相互关联的路径。知识图谱RAG允许跨交易、浏览历史和客户反馈进行多跳推理，从而实现对旅程的更全面分析，并基于客户行为和偏好之间的关系提供高度相关的推荐。'
- en: '*Contract analysi**s*—Standard RAG can retrieve text from individual contracts
    or clauses but cannot map relationships among contracts, parties, or compliance
    requirements. Knowledge graph RAG can link contracts, clauses, and parties in
    a relational network, enabling it to identify conflicts, dependencies, and compliance
    risks across interconnected legal documents.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*合同分析*——标准的RAG可以从单个合同或条款中检索文本，但不能映射合同、当事人或合规要求之间的关系。知识图谱RAG可以在关系网络中链接合同、条款和当事人，使其能够识别冲突、依赖性和合规风险。'
- en: While standard RAG can solve simple queries, for processes that require analysis
    and reasoning on data from multiple sources, knowledge graph can prove to be advantageous.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然标准的RAG可以解决简单的查询，但对于需要从多个来源的数据进行分析和推理的过程，知识图谱可以证明是有优势的。
- en: 8.3.3 Graph RAG approaches
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3.3 图RAG方法
- en: Knowledge graph is a powerful data pattern. The approach to using knowledge
    graphs can be determined by the complexity of the use case and the diversity of
    data. This section discusses three common approaches that can be followed.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 知识图谱是一种强大的数据模式。使用知识图谱的方法可以根据用例的复杂性和数据的多样性来确定。本节讨论了可以遵循的三个常见方法。
- en: Structure awareness through graphs
  id: totrans-120
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 通过图实现结构感知
- en: This is the simplest approach to incorporating knowledge graphs. Recall that
    in the standard vector-based RAG approach, documents are chunked, and embeddings
    are created then and stored for retrieval. The problem that may arise is that
    the information in the adjacent chunks might not be retrieved, and a certain degree
    of context loss may happen. In section 6.2.1, we discussed a hierarchical indexing
    structure such as a parent–child structure. The parent document contains overarching
    themes or summaries, while child documents delve into specific details. During
    retrieval, the system can first locate the most relevant child documents and then
    refer to the parent documents for additional context if required. This approach
    enhances the precision of retrieval, while maintaining the broader context.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: An efficient way to store documents in a hierarchical structure is in graphs.
    Parent and child documents can be stored in the nodes with a relationship “is
    child of.” More levels of hierarchies can be created. In figure 8.7, there are
    three levels of indexing hierarchy, and while the search happens at the lowest
    level, parent documents at a higher hierarchy level are retrieved for deeper context.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a diagram'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: AI-generated content may be incorrect.](../Images/CH08_F07_Kimothi.png)
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.7  While search in a hierarchical index structure happens at the lowest
    level, retrieved documents are more contextually complete from a higher level
    of hierarchy.
  id: totrans-125
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Graph-enhanced vector search
  id: totrans-126
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Graphs are not mandatory when implementing hierarchical indexing. The true value
    of knowledge graphs is realized when connections can be made across chunks. Standard
    vector-based search on a collection of chunks can be enhanced by traversing a
    knowledge graph to retrieve related chunks. To do this, a set of entities and
    relationships are extracted from the chunks using an LLM.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: In the retrieval stage, the first step is a usual vector search executed based
    on the user query. An initial set of chunks is identified that has a high similarity
    with the user query. In the next step, the knowledge graph is traversed to fetch-related
    entities around the entities of the chunks identified in the first step. By doing
    this, the retriever fetches not only the chunks similar to the user query but
    also related chunks, which leads to deeper context and can be quite effective
    in solving multi-hop queries. This is often coupled with hierarchical structures
    and a re-ranking of retrieved documents. Figure 8.8 shows an enhanced knowledge
    graph, where chuwnks also have the extracted entities and relationships. During
    retrieval, in addition to similar chunks, the parent chunks of related entities
    are also retrieved.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F08_Kimothi.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
- en: Figure 8.8  Entities and relationships extracted from the chunks play a crucial
    role. When chunks similar to the user query are retrieved, the chunks that have
    entities related to the entities of similar chunks are also retrieved.
  id: totrans-130
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Graph communities and community summaries
  id: totrans-131
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As discussed before, knowledge graphs are about entities and their relationships.
    Depending on the process, there may be patterns in which certain entities interact
    more with each other. Graph communities are a subset of entities connected more
    densely. For example, communities of customers with similar demographics and buying
    patterns can be identified or clusters of product features that appear together
    can be discovered. Community detection algorithms such as the Leiden and the Louvain
    algorithm are employed to detect communities within a knowledge graph. After detecting
    these communities, an LLM is used to generate summaries of the entities and the
    relationship information in the community. The retrieval process can be similar
    to vector search, where initial nodes are identified using a similarity score
    and community summaries related to the nodes are fetched, or vector search can
    be employed directly on the community summaries since they already contain a deeper
    context of several entities. This approach is particularly useful when queries
    relate to the broader themes within the knowledge base. Figure 8.9 shows how the
    retrieval at a community level is sufficient to answer questions at a broader
    thematic level.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: In any of these approaches, both the indexing and the retrieval pipeline need
    to be modified to incorporate the graph and create a hybrid retrieval system where
    both vector databases and graph databases exist.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 8.3.4 Graph RAG pipelines
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we have been discussing, knowledge graph is a unique data pattern that requires
    specific processing and storage. RAG pipelines need to be customized to incorporate
    knowledge graphs. Depending on the approach used, both the indexing and the generation
    pipelines need tweaking.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Knowledge graph RAG indexing pipeline
  id: totrans-136
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The knowledge base in graph RAG requires a different kind of parsing and storage.
    New components are introduced in the indexing pipeline to create knowledge graphs,
    extract summaries, and store the data for generation. While the loading and chunking
    components remain similar, the remaining components change significantly:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '*Data loadin**g*—There is no difference in the loading of the documents from
    the standard vector-based RAG.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Data chunkin**g*—To create knowledge graphs from the documents, large documents
    are chunked in the same way as the vector RAG approach. These chunks are then
    passed to an LLM to extract entities and their relationships.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Entity relationship attribute extraction (for graph-enhanced RAG**)*—This
    is a crucial step in graph enhancement because the quality of responses will depend
    on how well the entities and relationships have been identified. This step can
    be customized'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![A diagram of a community'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: AI-generated content may be incorrect.](../Images/CH08_F09_Kimothi.png)
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.9  Communities club entities under a consistent theme and summarize
    the information at this group level. Since the summaries are created from a high
    number of thematically related chunks, these summaries can answer broad queries.
  id: totrans-143
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: according to the need and complexity of the use case. The simplest approach
    can be to ask an LLM directly to do the extraction. The exact kind of entities
    and relationships can also be predetermined, say, allowed entities are “people,”
    “country,” and “organization,” and allowed relationships are “nationality,” “located
    at,” and “works at.” There can be another approach in which an LLM is used to
    identify the schema of the knowledge graph. Attributes can also be added to the
    entities and relationships. There can be multiple passes of this step to ensure
    that an exhaustive list has been created. Another step can be employed to remove
    redundancies and duplication. In LangChain, `LLMGraphTransformer` class is available
    in the `langchain_experimental` library that abstracts the entity relationship
    extraction from documents.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Storag**e*—Once the entities, relationships, and attributes have been extracted,
    these can be stored in a graph database such as Neo4j. LangChain has integration
    with the Neo4j graph database, and the `Neo4jGraph` library from the `langchain_community`
    can be used. Since the entity relationship extraction is done at a chunk level,
    the storage is also iterative, and the graph database is updated after each pass.
    In LangChain, the `add_graph_documents()` function of the `Neo4jGraph` library
    can be used to directly update the knowledge graph.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Creating community summarie**s*—As discussed previously, once the knowledge
    graph is created, an algorithm is used to detect communities, and an LLM is used
    to create a summary of the community. `Graphrag`, a library developed by Microsoft,
    provides end-to-end knowledge graph and community summary creation from documents.
    Another approach is to just use the community summaries and store the summaries
    in a vector database and use the standard vector RAG on the community summaries.'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This graph database can be used as the complete knowledge base or be treated
    as an addition to the regular vector database in the knowledge base. Figure 8.10
    illustrates the indexing pipeline with each step.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '![A diagram of a graph'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: AI-generated content may be incorrect.](../Images/CH08_F10_Kimothi.png)
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.10  Indexing pipeline for graph RAG. Chunks can directly be stored
    for simple structure-aware indexing, and community summaries can be created and
    stored with the graph.
  id: totrans-150
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Generation pipeline
  id: totrans-151
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Since the nature of the knowledge base in graph RAG is quite unlike standard
    RAG, it requires significant changes in the generation pipeline. The retrieval
    process becomes slightly more nuanced than vector retrieval because of an additional
    step of graph traversal. Graph databases such as Neo4j have introduced vector
    indexes, via the Neo4j vector search plugin, which represent nodes and attributes
    as embeddings and enable similarity search. For effective retrieval, the user
    query (in natural language) is converted into a graph query that can be used to
    traverse the knowledge graph. Neo4j uses a graph query language called Cypher.
    For using the Cypher query language, there are a couple of approaches:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '*Template base**d*—Several pre-defined Cypher templates are created and based
    on the user query, an LLM selects which template to use. This is an extremely
    rigid and limiting approach.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*LLM-generated quer**y*—An LLM generates the Cypher query directly based on
    the natural language user query. Prompt engineering techniques such as few-shot
    prompting are employed. This approach is more flexible than a template-based approach,
    but not 100% reliable.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In LangChain, the `GraphCypherQAChain` class is from the `langchain.chains`
    library. For better querying, the schema of the knowledge graph is also provided
    to the LLM:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '*Augmentatio**n*—Depending on the graph query, the response received from the
    graph database is processed to extract the text that can be augmented to the original
    user query. Apart from this, the augmentation step is the same as in vector RAG.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Generatio**n*—The augmented prompt is sent to the LLM like in the standard
    vector RAG approach.'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While the final generation step and initial data loading and chunking do not
    require any special adjustment, the rest of the process changes significantly.
    Table 8.3 summarizes the differences between vector and graph RAG.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: Table 8.3 Differences between vector RAG and graph RAG
  id: totrans-159
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Step | Vector RAG | Graph RAG |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
- en: '| Data loading | Loads documents without specialized preprocessing for relationships
    | Similar to vector RAG; documents are loaded without special graph handling.
    |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
- en: '| Data chunking | Divides large documents into smaller chunks for embedding
    and vector storage | Documents are chunked similarly; each chunk is then processed
    to extract entities and relationships, building a relational structure. |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
- en: '| Entity and relationship extraction | Not applicable; focuses on creating
    embeddings from chunks | Entities, relationships, and attributes are extracted
    from each chunk using an LLM, potentially in multiple passes to refine and de-duplicate
    entities and relationships. |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
- en: '| Storage | Stores embeddings in a vector database | Entities and relationships
    are stored in a graph database (e.g., Neo4j), with the option to update the graph
    iteratively. Tools such as LangChain’s Neo4jGraph can automate this process. |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
- en: '| Community summaries | Not applicable; primarily relies on similarity search
    on individual embeddings | Detects communities within the knowledge graph and
    uses an LLM to create summaries for each community. These summaries can be stored
    as vectors for a hybrid graph–vector RAG approach. |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
- en: '| Retrieval | Performs direct similarity searches on embeddings | Involves
    graph traversal using Cypher queries, generated either from pre-defined templates
    or dynamically by an LLM. Neo4j’s vector indexes can enhance similarity-based
    node searches. |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
- en: '| Augmentation | Uses retrieved embeddings to augment the user’s query | Retrieved
    nodes, relationships, or summaries augment the user’s query. Additional LLM processing
    might be used to refine responses based on the retrieved graph content. |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
- en: '| Generation | Sends the augmented prompt to an LLM for response generation
    | Like vector RAG but relies on augmented data with graph-derived insights, relationships,
    and context from the knowledge graph to enrich the response. |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
- en: 8.3.5 Challenges and best practices
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Despite all the benefits of graph RAG, there are certain challenges that must
    be considered carefully:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: Merging diverse data sources into a cohesive knowledge graph can be intricate
    and time-consuming. Start with a focused domain and gradually expand the knowledge
    graph to manage complexity.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Due to the iterative LLM processing at different stages, large-scale knowledge
    graph generation and community summarization from documents are computationally
    expensive. Therefore, the data for graph RAG must be selected carefully.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Current similarity measurement techniques may not fully capture the nuanced
    relationships or structural dependencies in graphs, leading to potential mismatches
    in retrieved information. Careful use of case-specific evaluation is warranted
    for acceptable accuracy.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each deployment may need custom graph data construction, indexing, and retrieval
    adaptations, which makes generalization difficult. Keeping the knowledge graph
    updated with accurate and current information requires continuous effort. Consequently,
    graph RAG may not be the default RAG strategy.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'So far, we have looked at two RAG variants that extend standard RAG capabilities
    by including multimodal data and graph structures. Next, we discuss one of the
    most significant concepts in the field of generative AI: agents.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: 8.4 Agentic RAG
  id: totrans-177
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By now, you understand that challenges exist with standard RAG systems. They
    may struggle with reasoning, answering complex questions, and multistep processes.
    One of the key aspects of comprehensive RAG systems is the ability to search through
    multiple sources of data. This can be internal company documents, the open internet,
    third-party applications, and even structured data sources like an SQL database.
    So far in this book, we have built systems that can search through a single knowledge
    base, and for any query, the entire knowledge base is searched through.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Two challenges arise with this approach. First, all information must be indexed
    and stored in a single vector store, which leads to storage problems at scale.
    Second, for any query, the entire knowledge base needs to be searched, which is
    highly inefficient for large knowledge bases. To overcome this challenge, a module
    that can understand the user’s query and route the query to a relevant source
    is needed. This is one of the limitations addressed by agentic RAG that uses one
    or more LLM agents for decision-making. Let’s first understand what is meant by
    the term *agent*.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: 8.4.1 LLM agents
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The use of agents in AI predates the popularity of LLMs. The overarching meaning
    of an AI agent is a software system that can autonomously perceive the environment
    it is in, make decisions, and perform actions to achieve a goal. Traditionally,
    AI agents have been developed to execute specific tasks and rely on predefined
    rules or learned behaviors, like in the fields of autonomous vehicles or robotics.
    Due to the ability to process and understand language (and now even multimodal
    data), LLMs are now being seen as a general-purpose technology that can help build
    autonomous decision-making without explicitly defining rules or environment data.
    While there is no common definition of an LLM-based AI agent, there are four key
    components of the system that enable autonomous decision-making and task execution.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: The*core LLM brain* is an LLM that assigned a certain role and a task. This
    component is responsible for understanding the user request and interacting with
    other components to respond to the user. For example, an AI agent built for travel
    assistance may have to deal with different types of tasks such as searching for
    information, creating itineraries, booking tickets, or managing previous bookings.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: The*memory* component manages the agent’s past experiences. It can be short-term
    like the chat history of the current conversation or long-term where important
    pieces of information from previous interactions are stored. For a travel assistant
    AI agent, short-term memory will hold the current context of the user query, while
    the ticket booking history or previous travel searches can be fetched from long-term
    memory.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: The*planning* component creates a step-by-step sequence of tasks that will be
    followed to respond to the user’s request. Task decomposition or breaking down
    complex tasks into smaller, manageable subtasks. ReAct, which stands for reasoning
    and acting, or reflection, where the agent does a self-assessment of the outcomes,
    can be part of the planning component.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '*Tools* assist the agent in performing actions on resources external to it.
    This can be conducting a web search on the internet, querying an external database
    such as an SQL database, invoking a third-party API such as a weather API, and
    similar. The core LLM brain is responsible for sending the payload request to
    the tools in the accepted format. These four components and their interactions
    are shown in figure 8.11\.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '![A diagram of a process'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: AI-generated content may be incorrect.](../Images/CH08_F11_Kimothi.png)
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.11  An LLM agent’s four components break down the user’s query, recall
    the history of interaction with the user, and employ external tools to accomplish
    tasks and respond to the user.
  id: totrans-188
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Since the definition of AI agents continues evolving, these components are not
    set in stone but are generally agreed upon. To help understand how these components
    interact, let’s take an example of an AI agent built for travel assistance, like
    the customer service agent of an online travel agency.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Suppose a customer asks a question like, “Is my flight on schedule?” The core
    LLM brain receives this input and understands that the user intent is to check
    a specific flight status. At this stage, the core LLM brain can invoke the planning
    module to decide the course of action required to answer queries of this intent.
    The planning module may respond with steps such as retrieving booking information
    from previous interactions (memory), querying the latest flight information from
    a database, comparing it with previous details from memory, and conveying the
    result to the user. Here, retrieving the information from the database will require
    a tool such as an API, which is a prebuilt module that the core LLM brain has
    access to. The planning module can also bring in conditional steps—for example,
    if the previous booking information cannot be retrieved from memory, the core
    LLM brain must prompt the user to provide this information. When the core LLM
    brain gets the plan from the planning module, it retrieves previous booking information,
    invokes the tool to retrieve flight information, compares the new information
    with the old information in memory, and crafts a response based on this analysis.
    This simple workflow of the agent is illustrated in figure 8.12.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '![A diagram of a flight process'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: AI-generated content may be incorrect.](../Images/CH08_F12_Kimothi.png)
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.12  A simple task of responding to a user query on flight schedule
    responded to by an LLM agent by using the planning, memory, and tools modules
  id: totrans-193
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This is an example of a simple task. Multiple agents can come together to solve
    tasks of a higher level of complexity, such as “Plan and book a holiday for me.”
    The field of LLM-based AI agents is quite promising, and readers are encouraged
    to read more about this evolving domain. For our discussion on agentic RAG in
    this section, we focus on a few aspects, specifically on tool usage and a little
    bit of planning. The use cases for agentic RAG span across industries, so it makes
    more sense to look at the capabilities of agentic RAG.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: 8.4.2 Agentic RAG capabilities
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In our introduction to agentic RAG, we highlighted the challenge in standard
    RAG using a single knowledge base. Agentic RAG infuses abilities in the RAG system
    that make the system more efficient and accurate.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: Query understanding and routing
  id: totrans-197
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Based on the user query, an LLM agent can be tasked with deciding which knowledge
    base to search through. For example, assume a programming assistant that can not
    only search the codebase but also the product documentation, along with searching
    the web. Depending on the question that the developer asks, the agent can decide
    which database to query. For generic messages such as greetings, the agent can
    also decide not to invoke the retriever and send the message directly to the LLM
    for a response.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Tools usage
  id: totrans-199
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the previous example, the system was also required to search the web. The
    internet cannot be stored in a knowledge base and is usually accessed through
    an API that returns search results. This search API is an example of a tool the
    agent can use. Similarly, other APIs, such as Notion or Google Drive, can be used
    to access information sources. One of the features of tools like APIs is that
    they have fixed query and response formats. The job of the agent is to process
    natural language information into the format structure and parse the response
    to use it for generation.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Adaptive retrieval
  id: totrans-201
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Recall adaptive retrieval discussed in chapter 6\. An LLM is enabled to determine
    the most appropriate moment and content for retrieval. This is an extension of
    query routing, where after deciding the most appropriate source to query, an agent
    can also determine whether the retrieved information is good enough to generate
    responses or whether another iteration of retrieval is required. For the next
    iteration, the agent can also form fresh queries based on the retrieved context.
    This enables the RAG system to solve complex queries.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: These capabilities enable agentic RAG systems to be comprehensive and work on
    a scale. While the indexing and generation pipelines do not change in structure,
    agents can be invoked throughout the two pipelines.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: 8.4.3 Agentic RAG pipelines
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The capability of LLM-based agents to understand the context and invoke tools
    can be used to elevate each stage of the RAG pipeline.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: Indexing pipeline
  id: totrans-206
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The idea of the knowledge base in agentic RAG is no different from standard
    RAG. Agents can be used across components to enhance the indexing pipeline:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '*Data loadin**g*—Loading data and extracting information is the first and incredibly
    crucial step of RAG system development. Accurate parsing of information is critical
    in building an accurate RAG system. Parsing complex documents such as PDF reports
    can be tough. While there are libraries and tools present for these tasks, LLM
    agents can be used for high-precision parsing. The importance of metadata in RAG
    cannot be overstated. It is useful for filtering, more contextual mapping, and
    source citation. In most scenarios, it is difficult to source rich metadata. LLM
    agents can be used to build metadata architecture and extract contextual metadata.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Chunkin**g*—In agentic chunking, chunks from the text are created based on
    a goal or a task. Consider an e-commerce platform wanting to analyze customer
    reviews. The best way for the reviews to be chunked is if the reviews about a
    particular topic are put in the same chunk. Similarly, the critical and positive
    reviews may be put in different chunks. To achieve this kind of chunking, we will
    need to do sentiment analysis, entity extraction, and some kind of clustering.
    This can be achieved by a multiagent system. Agentic chunking is still an active
    area of research and improvement.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Embedding**s*—The role of agents in embeddings can be the selection of the
    right embeddings model, depending on the context of the chunks. For example, if
    there is information from multiple domains in the loaded data, there may be a
    case for using domain-specific embeddings for different chunks. Apart from this,
    quality control agents can validate embeddings by measuring similarity or alignment
    with predefined standards or use case requirements. You may also recall from the
    discussion on graph RAG that agents can also decide to use graph structures for
    certain chunks.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Storag**e*—There is also a possibility to store chunk embeddings from the
    same document in different collections owing to the nature of the information.
    For example, the information related to the installation and troubleshooting of
    a product can be stored in one collection of a vector database, and product features
    and advantages can be stored in another. This helps in setting the retrieval up
    for higher precision. You may notice that the use of agents in chunking, embeddings,
    and storage are closely related.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figure 8.13 summarizes how the use of agents can embellish the indexing pipeline.
    The nature of the knowledge base itself doesn’t change, but the process of creation
    is embellished with agents.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Generation Pipeline
  id: totrans-213
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The true advantage of an agentic system lies in how it transforms the entire
    generation pipeline across all three stages:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '*Retrieval*—Perhaps the most significant use of agents is in the retrieval
    stage. Query routing to the most appropriate source and the integration of tools
    to query external sources of information is a crucial feature of agentic RAG.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F13_Kimothi.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
- en: Figure 8.13  Agentic embellishment to the indexing pipeline enhances the quality
    of the knowledge base.
  id: totrans-217
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Adaptive retrieval strategies also bring significant improvement in the retrieval
    stage.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Augmentation*—Agents can choose the correct prompting technique for augmentation,
    depending on the nature of the query and the retrieved context. Prompts can also
    be generated dynamically by an agent.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Generation*—One of the uses of agentic RAG is also in multistep generation
    such as IterRetGen or iterative-retrieval generation. In this approach, an agent
    is used to review the response generated by the LLM in the first pass, and it
    decides if any further iteration of retrieval and generation is required to completely
    respond to the user query. This is particularly useful in multi-hop reasoning
    and fact verification.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another way to think about agentic RAG is that wherever dynamic decision-making
    can improve the RAG system, an agent can be used to autonomously make those decisions.
    From the previous discussion, you may conclude that agentic RAG is a superior
    version of standard RAG. Table 8.4 summarizes the advantages of agentic over standard
    RAG.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: Table 8.4 Advantages of agentic RAG
  id: totrans-222
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Aspect | Standard RAG | Agentic RAG |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
- en: '| Retrieval process | Passive retrieval based on initial query | Adaptive retrieval
    with intelligent agents routing and reformulating queries as needed |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
- en: '| Handling complex queries | Struggles with multistep reasoning and complex
    queries | Can be used to break down and address complex, multifaceted queries
    |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
- en: '| Tool integration | Limited integration with external tools and APIs | Seamless
    integration with various external tools and APIs for enhanced information gathering
    |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
- en: '| Scalability | Challenges in scaling due to static processes | Scalable through
    modular agent-based architecture, allowing for easy expansion |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
- en: '| Accuracy and relevance | Dependent on initial query quality; may retrieve
    less relevant information | Higher accuracy and relevance due to agents’ ability
    to refine queries and validate information |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
- en: 8.4.4 Challenges and pest practices
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'LLM based agents are still evolving and are not foolproof. There are also concerns
    around the planning and reasoning abilities of LLMs. For implementing agentic
    abilities into the RAG pipelines, a few aspects should be evaluated carefully:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: The accuracy of tool selection diminishes when a single agent is responsible
    for invoking a high number of tools. Therefore, the number of decision choices
    for the agent needs to be controlled.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No agent can be expected to be accurate all the time. Error rates in multiagent
    systems can also increase. It is important to establish a failsafe at every stage.
    The choice of the use case should also be guided by the expected accuracy levels.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Increased autonomy in decision-making can lead to unintended actions if not
    properly controlled. In other words, agents can misfire, and establishing explicit
    boundaries and guidelines for agent behavior is critical.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multimodal, graph, and agentic RAG patterns have demonstrated significant improvements
    over the standard RAG pipelines. Multimodal RAG opens the RAG systems to different
    modalities, graph RAG introduces relational understanding, and agentic RAG infuses
    RAG systems with intelligence and autonomous decision making. Apart from these
    three, ongoing research on RAG has resulted in several other frameworks and variations
    to the standard RAG systems. The next section discusses variants that show significant
    promise.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: 8.5 Other RAG variants
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have talked about the three major RAG variants in this chapter. Research
    in the field is bustling, and every week, several papers are released by researchers
    about their experiments and key findings. Out of these papers, quite a few demonstrate
    RAG variants that find relevance in practical applications. We close this chapter
    by briefly discussing four such RAG variants.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: 8.5.1 Corrective RAG
  id: totrans-237
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The effectiveness of a RAG system depends on the quality of retrieval. Inaccuracies
    in retrieval negate all RAG benefits. To address this, the corrective RAG (CRAG)
    approach evaluates the quality of retrieved documents. It uses a lightweight evaluator
    and triggers corrective action if the retrieved information is found to be inaccurate.
    The key CRAG components are
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: '*Retrieval evaluato**r*—A model that evaluates the relevance of the retrieved
    documents and assigns a relevance score to each retrieved document. In the original
    CRAG paper ([https://arxiv.org/abs/2401.15884](https://arxiv.org/abs/2401.15884)),
    the evaluator is a fine-tuned T5 model that assigns a score of being correct,
    incorrect, or ambiguous.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Web search supplementatio**n*—If a retrieved document is classified as incorrect,
    the system conducts a web search to supplement the knowledge base, ensuring more
    accurate, up-to-date information.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Knowledge refinemen**t*—Retrieved documents classified as correct by the evaluator
    and the content retrieved from web search are broken down further into smaller
    knowledge strips, and each strip undergoes evaluation.'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figure 8.14 illustrates the CRAG workflow with the evaluator, knowledge refinement,
    and web search added to the standard RAG flow.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: 'As for its advantages and limitations, CRAG secures accurate, context-relevant
    knowledge for generation, particularly in cases where initial retrieval may be
    flawed. The corrective actions enhance the factual accuracy of the generated content.
    CRAG is a solution that can be integrated with all RAG pipelines and other RAG
    variants without causing any disruptions. There are also a couple of factors that
    need to be considered:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: The additional corrective actions and web search integration may increase response
    time.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The performance of the system is closely tied to the accuracy of the evaluator
    model.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CRAG is an improvement over standard RAG, which uses the retrieved documents
    as is. The corrective approach makes it effective for accuracy-sensitive applications
    that demand data verification.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH08_F14_Kimothi.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.14  CRAG corrects the knowledge at the most granular level, hence
    the name corrective RAG. Source: [https://arxiv.org/abs/2401.15884](https://arxiv.org/abs/2401.15884).'
  id: totrans-248
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 8.5.2 Speculative RAG
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Latency and redundancy are ubiquitous concerns in RAG systems. Speculative RAG
    addresses these in a two-step approach. First, small language models parallelly
    generate multiple answer drafts, each based on diverse subsets of documents. Then,
    a larger LLM verifies and selects the most accurate draft. The key components
    of speculative RAG are
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '*Document clusterin**g*—Retrieved documents are clustered into topic-related
    groups, each offering a unique perspective.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*RAG drafte**r*—A smaller LLM produces initial answer drafts based on each
    cluster subset, generating responses and rationales in parallel for efficiency.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*RAG verifie**r*—A larger LLM evaluates each draft’s accuracy and coherence,
    assigning confidence scores based on self-consistency and rationale support.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The key advantage of speculative RAG is faster response generation by reducing
    the workload on the generator LLM and performing parallel draft generation. However,
    some of the following limitations require careful consideration:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: Involves managing a two-model setup and document clustering, which may increase
    initial setup complexity.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Document clustering directly affects draft diversity, and poor clustering can
    lead to redundant drafts by grouping highly similar or repetitive documents into
    multiple clusters.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The smaller LLM may require training for effective draft and rationale generation.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unlike standard RAG, which incorporates all retrieved data into a single prompt,
    speculative RAG uses parallel draft generation for efficiency and a dedicated
    verification step for accuracy, which leads to a reduction in latency, while improving
    the factual efficiency of the responses.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: 8.5.3 Self-reflective (self RAG)
  id: totrans-259
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Self-reflection in an LLM is the ability of the LLM to analyze its actions,
    identify potential errors or flaws in its reasoning process, and then use that
    feedback to improve its responses and decision-making. Self RAG incorporates reflection
    to dynamically decide whether to retrieve relevant information, evaluate retrieved
    content, and to critique its output. The key components of self RAG are
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '*Reflection token**s*—Self RAG trains an LLM to use “reflection tokens,” which
    help it assess the relevance, support, and usefulness of retrieved passages. These
    tokens are designed to guide the model in judging the quality of both the retrieved
    content and its generated response, adding layers of control and adaptability.
    A *retrieve token* indicates whether retrieval is needed. Similarly, the *relevance
    token* determines whether a passage is relevant, the *support token* verifies
    whether the generated response is fully supported by retrieved content, and the
    *utility token* scores the usefulness of the response.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Dynamic retrieval decisio**n*—The model uses reflection tokens to determine
    if retrieval is necessary based on each segment of the response and skips retrieval
    if it is unnecessary at any step.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Self-critiqu**e*—The model critiques its output at each generation step, applying
    reflection tokens to guide retrieval and refine the response in real time.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Adaptive retrieval in self RAG reduces unnecessary retrievals, and self-reflection
    results in better accuracy, factual consistency, and relevance. However, some
    limitations need to be considered:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: Processing multiple passages in parallel and self-reflection may increase computational
    demands.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The additional training and use of reflection tokens require fine-tuning of
    thresholds.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Self RAG is one of the most cited techniques in research on RAG. Its dynamic
    adjustment of retrieval based on task needs evaluates output quality, achieving
    superior accuracy.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: 8.5.4 RAPTOR
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Recursive abstractive processing for tree-organized retrieval, or RAPTOR, is
    a RAG variant designed to handle hierarchical relationships in data. It creates
    a multilevel, tree-based structure of recursive summaries, capturing both granular
    details and overarching themes in long documents. Like graph RAG, RAPTOR uses
    a tree structure to achieve similar objectives. Here are the key RAPTOR components:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '*Chunk clustering and summarizatio**n*—Chunk embeddings are clustered based
    on similarity, and an LLM is used to summarize the clusters. Soft clustering with
    Gaussian mixture models allows text segments to belong to multiple clusters.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Recursive tree constructio**n*—RAPTOR builds a multilayered tree by using
    chunks, clusters, and summaries in a bottom-up process.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Dual querying mechanism**s*—A top-down approach starts traversing down to
    select the most relevant nodes at each level based on cosine similarity to the
    query. Another single-layer search retrieves context across all tree nodes irrespective
    of the levels.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Like graph RAG, RAPTOR enables better multi-hop reasoning and thematic question
    answering by incorporating both granular and high-level summaries. However, tree
    structures are complex to manage and RAPTOR comes with its set of challenges:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: The recursive clustering and summarization steps can be computationally intensive,
    especially for very large documents.
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Effective retrieval hinges on the quality of the clustering; errors in initial
    clustering can propagate up the tree.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unlike standard RAG, which may struggle with multilayered content, RAPTOR’s
    hierarchical model allows targeted retrieval, optimizing for both specificity
    and contextual relevance.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: This chapter explored RAG variants that use advanced techniques to improve RAG
    systems for specific use cases. Multimodal pipelines give RAG systems access to
    previously unusable data, graph RAG provides the ability of relational analysis,
    and agentic RAG introduces autonomous decision-making for complex tasks. Each
    RAG variant addresses a certain aspect of improvement in standard RAG systems.
    Corrective RAG focuses on factual relevance, RAPTOR builds relational intelligence
    for hierarchical data, speculative RAG is built for efficiency, and self RAG makes
    the system adaptive.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: With this chapter, we are almost at the end of our discussion on RAG. The last
    chapter discusses some of the independent considerations and best practices across
    different stages of RAG system lifecycle.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Introducing RAG variants
  id: totrans-280
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: RAG variants are adaptations of the naïve RAG framework that extend its functionality
    to specific use cases.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These variants address challenges, such as processing nontextual data, improving
    relational understanding, enhancing accuracy, and enabling autonomous decision-making.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Three major RAG variants were discussed in depth: multimodal, graph, and agentic
    RAG.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other promising RAG variants are corrective RAG, speculative RAG, self RAG,
    and RAPTOR.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multimodal rag
  id: totrans-285
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It extends RAG capabilities to handle multiple data modalities such as text,
    images, audio, and video. It can be used for
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Medical diagnosi**s*—Analyzing text, images (X-rays), and tabular data (lab
    results)'
  id: totrans-287
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Investment analysi**s*—Processing financial documents, charts, and balance
    sheets'
  id: totrans-288
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Equipment maintenanc**e*—Combining text reports, visual inspections, and sensor
    data'
  id: totrans-289
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: As for the pipeline enhancements, multimodal RAG introduces multimodal embeddings
    (shared or modality specific), transcription tools, and specialized chunking methods
    to indexing pipeline. In the generation pipeline, it employs multimodal LLMs (e.g.,
    GPT-4o, Google Gemini).
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multimodal RAG has high computational requirements and increased latency. Information
    loss is possible during text conversion of nontext modalities.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Knowledge graph RAG
  id: totrans-292
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It enhances retrieval and reasoning through relationships represented in a graph
    structure. It can be used for
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Personalized treatment plan**s*—Linking drugs, conditions, and symptoms for
    customized recommendations'
  id: totrans-294
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Contract analysi**s*—Identifying dependencies and compliance risks across
    interconnected legal documents'
  id: totrans-295
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: As for the pipeline enhancements, the knowledge graph RAG extracts entities,
    relationships, and attributes from chunks to create a graph in the indexing pipeline.
    As for the generation pipeline, it incorporates graph traversal using graph query
    languages such as Cypher.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building and maintaining knowledge graphs is complex and computationally expensive.
    It also requires custom adaptations for each deployment.
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Agentic RAG
  id: totrans-298
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It introduces LLM-based agents for autonomous decision-making and dynamic query
    routing. Agentic RAG can be used for
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Query understanding and routing to relevant data sources
  id: totrans-300
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Adaptive retrieval and multistep generation
  id: totrans-301
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Integration with tools such as web search APIs and external databases
  id: totrans-302
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: With regard to pipeline enhancements, agentic RAG enhances chunking, metadata
    extraction, and embeddings selection with agentic decision-making in the indexing
    pipeline. In the generation pipeline, it dynamically augments prompts and employs
    iterative retrieval-generation workflows.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Agentic RAG requires robust controls to prevent unintended actions by agents.
    High computational overhead and multiplied error rates in multiagent systems.
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other RAG variants
  id: totrans-305
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Corrective RAG (CRAG) Focuses on factual accuracy by evaluating retrieved content.
    It also adds corrective steps such as web search supplementation and knowledge
    refinement.
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Advantage**s*—Enhances accuracy and can integrate seamlessly with other RAG
    pipelines'
  id: totrans-307
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Challenge**s*—Increased response time and dependency on the evaluator model'
  id: totrans-308
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Speculative RAG reduces latency by generating multiple drafts in parallel using
    smaller LLMs. A larger LLM verifies and selects the most accurate draft.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Advantage**s*—Faster response generation'
  id: totrans-310
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Challenge**s*—Requires careful document clustering and draft diversity'
  id: totrans-311
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Self RAG incorporates reflection tokens for adaptive retrieval and self-assessment
    of generated content.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Advantage**s*—Superior accuracy and factual consistency'
  id: totrans-313
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Challenge**s*—Computationally demanding and requires fine-tuned thresholds'
  id: totrans-314
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: RAPTOR builds hierarchical relationships through tree-structured summaries.
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Advantage**s*—Optimized for multi-hop reasoning and thematic queries'
  id: totrans-316
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Challenge**s*—Computationally intensive and relies on effective clustering'
  id: totrans-317
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
