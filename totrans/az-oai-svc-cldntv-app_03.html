<html><head></head><body>
<div id="book-content" class="calibre2">
<div id="sbo-rt-content" class="calibre3"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 2. Designing Cloud Native Architectures for Generative AI" class="calibre5"><div class="preface" id="designing_cloud_native_architectures_for_generativ">
      <h1 class="calibre4"><span class="keep-together">Chapter 2. </span>Designing Cloud Native Architectures <span class="keep-together">for Generative AI</span></h1>
      <p class="subtitle">Cloud native architecture<a contenteditable="false" data-type="indexterm" data-primary="cloud native architectures and applications" id="xi_cloudnativearchitecturesandapplications2335" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="Azure OpenAI Service" data-secondary="cloud native architectures" id="xi_AzureOpenAIServicecloudnativearchitectures2335" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> is a way of designing and building applications that can take advantage of the cloud’s unique capabilities and constraints. Cloud native applications are typically composed of microservices that run in containers, orchestrated by platforms like Kubernetes, and use DevOps and continuous integration and continuous deployment (CI/CD) practices to enable rapid delivery and scalability. Cloud native architectures are at the core of the generative AI era.</p>
      <p class="subtitle">Organizations<a contenteditable="false" data-type="indexterm" data-primary="Cloud Native Computing Foundation (CNCF)" id="id382" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> such as the <a href="https://oreil.ly/dUsAO" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Cloud Native Computing Foundation (CNCF)</a> are great catalysts of cloud native best practices and community development. Their goal is to be <em class="hyperlink">“</em>the vendor-neutral hub of cloud native computing, to make cloud native universal and sustainable.” CNCF is a great source of information and learning material for these topics. Another great resource<a contenteditable="false" data-type="indexterm" data-primary="twelve-factor app" id="id383" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> is the <a href="https://oreil.ly/AFEgd" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">twelve-factor app</a>, a public methodology for building cloud native applications.</p>
      <p class="subtitle">As part of the cloud native movement, there are several projects and communities oriented to the use of cloud native architecture to enable scalable, reliable, and robust AI systems. They often require large amounts of data, complex algorithms, and specialized hardware to perform tasks such as image recognition, natural language processing, or recommendation systems. This is not always possible with traditional IT architecture patterns (e.g., <a href="https://oreil.ly/TrFNL" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">monolithic applications</a>).</p>
      <p class="subtitle">The need for cloud native architecture for AI systems arises from the following <span class="keep-together">reasons:</span></p>
      <dl class="stafflist">
        <dt class="calibre10">System performance</dt>
        <dd class="calibre11">
          <p class="subtitle">AI systems need to process large volumes of data and run complex computations in a fast and efficient manner. Cloud native architecture enables AI systems to leverage the cloud’s elastic resources, such as compute, storage, and network, to scale up or down according to demand. It also allows AI systems to use specialized hardware, such as graphics processing units (GPUs) or tensor processing units (TPUs), that are optimized for AI workloads.</p>
        </dd>
        <dt class="calibre10">Agility</dt>
        <dd class="calibre11">
          <p class="subtitle">AI systems need to adapt to changing business requirements, user feedback, and data quality. Cloud native architecture enables AI systems to deploy new features, models, or updates quickly and reliably using DevOps and CI/CD practices. It also allows AI systems to experiment with different architectures, algorithms, or parameters using techniques such as A/B testing or canary deployments.</p>
        </dd>
        <dt class="calibre10">Innovation and integrability</dt>
        <dd class="calibre11">
          <p class="subtitle">AI systems need to leverage the latest advances in AI research and technology. Cloud native architecture enables AI systems to access the cloud’s rich ecosystem of AI services, tools, and frameworks that offer state-of-the-art functionality and performance. It also allows AI systems to integrate with other cloud services, such as data analytics, Internet of Things, or edge computing, that can enhance the value and intelligence of AI systems.</p>
        </dd>
      </dl>
      <p class="subtitle">The most important areas for cloud native are described by CNCF as CI/CD, DevOps, microservices, and containers, as shown in <a data-type="xref" href="#fig_1__cloud_native_building_blocks_for_generative_ai_a" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Figure 2-1</a>.</p>
      <figure class="calibre18"><div id="fig_1__cloud_native_building_blocks_for_generative_ai_a" class="figure">
        <img src="assets/aoas_0201.png" alt="" class="calibre19"/>
        <h6 class="calibre20"><span class="keep-together">Figure 2-1. </span> Cloud native building blocks for generative AI (source: adapted from an image by CNCF)</h6>
      </div></figure>
      <p class="subtitle">These four areas are relevant to generative AI applications:</p>
      <dl class="stafflist">
        <dt class="calibre10">CI/CD </dt>
        <dd class="calibre11">
          <p class="subtitle">Enables a streamlined and automated process<a contenteditable="false" data-type="indexterm" data-primary="CI/CD (continuous integration and continuous deployment)" id="id384" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="continuous integration and continuous deployment (CI/CD)" id="id385" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="deployment of generative AI" data-secondary="CI/CD" id="id386" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="integrations" data-secondary="CI/CD" id="id387" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> for integrating code changes, building, testing, and deploying AI models and applications, and facilitates faster iterations and reduces time to market for generative AI developments.</p>
        </dd>
        <dt class="calibre10">DevOps</dt>
        <dd class="calibre11">
          <p class="subtitle">Combines the principles and practices of DevOps<a contenteditable="false" data-type="indexterm" data-primary="DevOps" data-seealso="Azure DevOps" id="id388" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> for AI technologies to improve the development, deployment, and operations of AI systems, and facilitates the integration of generative AI into the overall software development lifecycle. It also ensures reliable monitoring, logging, and feedback loops, enabling quick identification and resolution of issues in generative AI systems.</p>
        </dd>
        <dt class="calibre10">Microservices</dt>
        <dd class="calibre11">
          <p class="subtitle">Allows complex generative AI systems to be broken down into smaller, independent services<a contenteditable="false" data-type="indexterm" data-primary="microservices" id="id389" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>, which enables modular development and deployment of different components of the AI system. It also enhances scalability and flexibility, as individual microservices can be developed, deployed, and scaled independently.</p>
        </dd>
        <dt class="calibre10">Containers</dt>
        <dd class="calibre11">
          <p class="subtitle">Offers a lightweight and portable way to package<a contenteditable="false" data-type="indexterm" data-primary="containers and containerization" id="id390" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> and deploy generative AI models and applications, and enables easy scaling, replication, and orchestration of generative AI workloads.</p>
        </dd>
      </dl>
      <p class="subtitle">Cloud native architecture is a key enabler for developing advanced, intelligent AI systems that can deliver high performance, agility, and innovation on the cloud platform. In this chapter, we will explore how to prepare a cloud native architecture for an AI-enabled system that leverages Azure OpenAI Service, regardless of the kind of application you are planning to develop. Let’s start by digging into some typical scenarios for AI cloud native development.</p>
      <section data-type="sect1" data-pdf-bookmark="Modernizing Applications for Generative AI" class="calibre5"><div class="preface" id="modernizing_applications_for_generative_ai">
        <h1 class="calibre4">Modernizing Applications for Generative AI</h1>
        <p class="subtitle">This book focuses on the development<a contenteditable="false" data-type="indexterm" data-primary="cloud native architectures and applications" data-secondary="modernizing applications" id="xi_cloudnativearchitecturesandapplicationsmodernizingapplications24848" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> of new cloud native applications with Azure OpenAI Service and the rest of the Microsoft Azure stack. However, there may be scenarios in which a company tries to leverage these capabilities for their existing applications. Let’s compare both scenarios and see the approaches:</p>
        <dl class="stafflist">
          <dt class="calibre10">New cloud native applications </dt>
          <dd class="calibre11">
            <p class="subtitle">Designed from scratch using <a href="https://oreil.ly/U0o9G" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">containerization</a> and a microservices architecture, enabling scalability, resilience, and elasticity. They leverage the four areas previously mentioned, and they make the deployment and maintenance of generative AI applications a bit simpler.</p>
          </dd>
          <dt class="calibre10">Existing apps </dt>
          <dd class="calibre11">
            <p class="subtitle">Likely require migration or modernization. This means they’ll either be migrated to the cloud, or modified to align with cloud native principles, such as breaking down a monolithic architecture into microservices or introducing containerization. The modernization process involves step-by-step upgrades, addressing scalability, resilience, and fault tolerance, and adopting DevOps practices gradually. </p>
          </dd>
        </dl>
        <p class="subtitle"><a class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2" href="https://oreil.ly/Rqw0P"><em class="hyperlink">Learning Microsoft Azure</em> (O’Reilly)</a> by Jonah Carrio Andersson<a contenteditable="false" data-type="indexterm" data-primary="Andersson, Jonah Carrio" id="id391" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="Learning Microsoft Azure (Andersson)" id="id392" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> lays out some different strategies, and Microsoft’s <a href="https://oreil.ly/5Sm8X" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">modernization guide</a> describes the process for migrating and modernizing existing on-prem/monolithic applications to the cloud, with specific cloud native features. <a data-type="xref" href="#fig_2_cloud_native_modernization_levels_moving_towards_g" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Figure 2-2</a> illustrates the different levels of cloud <span class="keep-together">modernization.</span></p>
        <figure class="calibre18"><div id="fig_2_cloud_native_modernization_levels_moving_towards_g" class="figure">
          <img src="assets/aoas_0202.png" alt="" class="calibre19"/>
          <h6 class="calibre20"><span class="keep-together">Figure 2-2. </span>Cloud native modernization levels moving toward generative AI <span class="keep-together">(source: adapted</span> from an image by Microsoft)</h6>
        </div></figure>
        <p class="subtitle">Based on the modernization steps, there are different levels of maturity that range from existing on-premises applications to full cloud native ones. This is relevant for implementations with Azure OpenAI Service, as a native cloud-enabled PaaS, because new and existing applications will need some level of cloud readiness before integrating generative AI capabilities. Think of this as the way the rest of the application blocks connect with Azure OpenAI Service in a cloud-enabled way, with native and simple integrations.</p>
        <p class="subtitle">The levels of maturity are as follows:</p>
        <dl class="stafflist">
          <dt class="calibre10">Cloud infrastructure–ready applications</dt>
          <dd class="calibre11">
            <p class="subtitle">With this migration strategy<a contenteditable="false" data-type="indexterm" data-primary="cloud infrastructure-ready applications, migrating to Azure OpenAI" id="id393" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>, you simply transfer or relocate your existing on-site applications to an infrastructure-as-a-service (IaaS) environment. While the structure of your applications remains largely unchanged, they are now hosted on virtual machines in the cloud. This straightforward migration method is commonly referred to as “lift and shift” within the sector, but it only gets a portion of the cloud value you can get from managed PaaS/SaaS services.</p>
          </dd>
          <dt class="calibre10">Cloud-optimized applications</dt>
          <dd class="calibre11">
            <p class="subtitle">At this stage<a contenteditable="false" data-type="indexterm" data-primary="cloud-optimized applications, migrating to Azure OpenAI" id="id394" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>, without making major code changes or redesigning, you can tap into the advantages of running your application in the cloud using contemporary technologies like containers and other cloud-managed services. This enhances your application’s flexibility, allowing for quicker releases by optimizing your business’s DevOps practices. This enhancement is made possible by tools like Windows containers, rooted in the Docker Engine. Containers address the challenges posed by application dependencies during multistage deployments. In this maturity framework, you have the option to deploy containers on either IaaS or PaaS, leveraging additional cloud-managed services such as database solutions, caching services, monitoring, and CI/CD workflows.</p>
          </dd>
          <dt class="calibre10">Cloud native applications</dt>
          <dd class="calibre11">
            <p class="subtitle">This migration<a contenteditable="false" data-type="indexterm" data-primary="cloud native architectures and applications" data-secondary="migrating to Azure OpenAI" id="id395" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> approach typically is driven by business needs and targets modernizing your mission-critical applications. At this level, you use cloud services to move your apps to PaaS computing platforms. You implement cloud native applications and microservices architecture to evolve applications with long-term agility, and to scale to new limits. This type of modernization usually requires architecting specifically for the cloud, and even writing new code (or rewriting it), especially when you move to cloud native application and microservice-based models. This approach can help you gain benefits that are difficult to achieve in your monolithic and on-premises application environment.</p>
          </dd>
        </dl>
        <p class="subtitle">The last level is the end goal for optimal generative AI–enabled applications, but any of these levels (especially the last two) would be “good enough” for any application to “connect” to Azure OpenAI Service. The rest of the chapter will focus on new cloud native applications, but if you plan to leverage Azure OpenAI Service for existing applications, please start by evaluating them and analyzing the next migration or modernization steps towards AI adoption.</p>
        <p class="subtitle">Now, let’s focus on the key advantages of cloud native, and the key Azure-enabled building blocks that will allow you to build your Azure OpenAI solutions<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_cloudnativearchitecturesandapplicationsmodernizingapplications24848" id="id396" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>.</p>
      </div></section>
      <section data-type="sect1" class="calibre5" data-pdf-bookmark="Cloud Native Development with Azure OpenAI Service"><div class="preface" id="cloud_native_development_with_azure_openai">
        <h1 class="calibre4">Cloud Native Development with Azure OpenAI Service</h1>
        <p class="subtitle">Part of the idea behind cloud native architectures is to split code development<a contenteditable="false" data-type="indexterm" data-primary="cloud native architectures and applications" data-secondary="code development" id="xi_cloudnativearchitecturesandapplicationscodedevelopment28491" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="coding use case" data-secondary="designing cloud native architectures" id="xi_codingusecasedesigningcloudnativearchitectures28491" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> into different pieces called microservices<a contenteditable="false" data-type="indexterm" data-primary="microservices" id="xi_microservices284134" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>, so all modules communicate based on a functional flow, without being part of the same technical block. This has a series of advantages, not only for Azure OpenAI–enabled development, but any cloud native implementation. We can imagine several reasons to leverage a microservices <span class="keep-together">architecture:</span></p>
        <dl class="stafflist">
          <dt class="calibre10">Modular and granular AI functionality</dt>
          <dd class="calibre11">
            <p class="subtitle">In AI applications, different tasks such as data preprocessing, feature extraction, model training, inference, and result visualization may be involved. By implementing each of these functionalities as separate microservices, the AI system becomes more modular and granular. This allows developers to focus on building and maintaining individual services, making it easier to understand, develop, test, and deploy specific AI components. This also allows reusability of components as there might be certain cleaning pipelines or even models that could be used for different applications within the same company. Last but not least, it supports team specialization depending on the task (e.g., model output processing tends to be an integration or data engineering task, while model implementation a data science one).</p>
          </dd>
          <dt class="calibre10">Scalability and performance optimization</dt>
          <dd class="calibre11">
            <p class="subtitle">AI workloads can vary in intensity<a contenteditable="false" data-type="indexterm" data-primary="scalability of generative AI" data-secondary="with microservices" data-secondary-sortas="microservices" id="id397" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="performance optimization, with microservices" id="id398" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>, with some tasks requiring more computational resources than others. By breaking down an AI application into microservices, each service can be scaled independently based on its specific resource needs. This scalability ensures efficient resource utilization and improved performance. For example, model training and inference services can be scaled independently to handle varying workloads, providing better response times and overall system performance.</p>
          </dd>
          <dt class="calibre10">AI algorithm lifecycle management</dt>
          <dd class="calibre11">
            <p class="subtitle">AI applications<a contenteditable="false" data-type="indexterm" data-primary="algorithms" data-secondary="lifecycle management with microservices" id="id399" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> often require experimenting with different algorithms, models, or data sources to achieve the desired outcome. With microservices, developers can easily swap out or update individual AI services without affecting the rest of the system. This flexibility enables rapid prototyping, experimentation, and iteration with different AI approaches, facilitating the discovery of the most effective algorithms or models for specific tasks. Also, certain systems might run algorithms in parallel to obtain a better result by selecting the best answers of those algorithms.</p>
          </dd>
          <dt class="calibre10">Integration with external services</dt>
          <dd class="calibre11">
            <p class="subtitle">Microservices architecture promotes loose coupling and well-defined APIs, making it easier to integrate AI services with external systems, tools, or services. This allows AI functionality to be leveraged across different applications, domains, or platforms. For instance, an AI service for NLP can be exposed via an API and utilized by multiple applications or integrated into a chatbot or customer support system.</p>
          </dd>
        </dl>
        <p class="subtitle">Now, if we think about generative AI–enabled applications with Azure OpenAI Service, the goal is to structure the end-to-end architecture in a way that makes sense and connects the “AI pieces” to both backend elements (code, cloud resources), and frontend interfaces (one or several, depending on the application), as you can see in <a data-type="xref" href="#fig_3_microservice_enabled_ai_development" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Figure 2-3</a>.</p>
        <figure class="calibre18"><div id="fig_3_microservice_enabled_ai_development" class="figure">
          <img src="assets/aoas_0203.png" alt="" class="calibre19"/>
          <h6 class="calibre20"><span class="keep-together">Figure 2-3. </span>Microservice-enabled AI development</h6>
        </div></figure>
        <p class="subtitle">All the involved elements need to be interoperable, replaceable, and available. For that purpose, organizing the building blocks in microservices is key. The next two sections look at the containerization and serverless approaches. Let’s discuss their role as cloud native enablers.</p>
        <section data-type="sect2" data-pdf-bookmark="Microservice-Based Apps and Containers" class="calibre5"><div class="preface" id="microservice_based_apps_and_containers">
          <h2 class="calibre21">Microservice-Based Apps and Containers</h2>
          <p class="subtitle">Cloud native development<a contenteditable="false" data-type="indexterm" data-primary="containers and containerization" data-secondary="microservices" id="xi_containersandcontainerizationmicroservices211138" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="Docker" id="xi_Docker211138" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="Kubernetes" id="xi_Kubernetes211138" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="orchestration, role in AI" id="xi_orchestrationroleinAI211138" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> approaches leverage the power of the cloud, by choosing the right way to develop and to deploy applications. They rely on containerization, which often refers to Docker-type containers, and Kubernetes orchestration. As they are both based on international standards<a contenteditable="false" data-type="indexterm" data-primary="Open Container Initiative (OCI)" id="id400" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="OCI (Open Container Initiative)" id="id401" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> (e.g., the <a href="https://oreil.ly/JKa4L" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Open Container Initiative [OCI]</a>), cloud native applications are usually portable and scalable to different public and private cloud providers. </p>
          <p class="subtitle">For Microsoft Azure, the key managed containerization services<a contenteditable="false" data-type="indexterm" data-primary="Azure Kubernetes Service (AKS)" id="id402" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="AKS (Azure Kubernetes Service)" id="id403" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="Azure Red Hat OpenShift (ARO)" id="id404" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="ARO (Azure Red Hat OpenShift)" id="id405" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> are <a href="https://oreil.ly/ymIkj" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Azure Kubernetes Service (AKS)</a> and <a href="https://oreil.ly/SXs9T" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Azure Red Hat OpenShift (ARO)</a>. While both are managed Kubernetes services offered by Microsoft, there are some key differences:</p>
          <dl class="stafflist">
            <dt class="calibre10">
              
                <a href="https://oreil.ly/YqfZ3" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">AKS</a>
              
            </dt>
            <dd class="calibre11">
              <p class="subtitle">A managed Kubernetes service provided by Microsoft Azure, utilizing native Kubernetes technology. It offers a fully managed Kubernetes cluster on Azure infrastructure and focuses on providing a streamlined and simplified Kubernetes experience on Azure. It provides essential Kubernetes features, including scaling, load balancing, and deployment management. AKS integrates well with other Azure services and provides native Azure resource management and monitoring capabilities. You can find pricing information <a href="https://oreil.ly/OoChO" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">online</a>.</p>
            </dd>
            <dt class="calibre10">
              <a href="https://oreil.ly/mM0MD" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">
                ARO
              </a>
            </dt>
            <dd class="calibre11">
              <p class="subtitle">A joint offering between Microsoft and Red Hat, built on the <a href="https://oreil.ly/AftCs" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Red Hat OpenShift</a> Container Platform. ARO incorporates Kubernetes technology but provides additional features and integrations from the OpenShift platform. It provides a more comprehensive and enterprise-focused platform with additional security, compliance, and management capabilities.</p>
            </dd>
          </dl>
          <p class="subtitle">In summary, they differ in terms of the underlying technology, vendor, and platform features. The choice between AKS and ARO depends on the specific requirements and preferences of your organization, such as the need for additional enterprise features and any existing investments or partnerships with Red Hat. Other related services<a contenteditable="false" data-type="indexterm" data-primary="Azure Container Apps" id="id406" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="Azure Arc for Kubernetes" id="id407" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> you may want to explore are <a href="https://oreil.ly/QDzs2" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Azure Container Apps</a> and <a href="https://oreil.ly/X5vd_" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Azure Arc for Kubernetes</a> (for hybrid cloud scenarios).</p>
          <p class="subtitle">Now that we have explored the containerization options in Azure, let’s understand the notion of serverless and its relevance for microservice-based implementations<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_microservices284134" id="id408" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_containersandcontainerizationmicroservices211138" id="id409" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_Docker211138" id="id410" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_Kubernetes211138" id="id411" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_orchestrationroleinAI211138" id="id412" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>.</p>
        </div></section>
        <section data-type="sect2" data-pdf-bookmark="Serverless Workflows" class="calibre5"><div class="preface" id="serverless_workflows">
          <h2 class="calibre21">Serverless Workflows</h2>
          <p class="subtitle">An alternative or complementary option is the serverless<a contenteditable="false" data-type="indexterm" data-primary="serverless workflows" id="xi_serverlessworkflows213670" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> approach. Serverless computing is a cloud computing model that allows developers to build and run applications without the need to manage underlying infrastructure. It is particularly beneficial for AI workloads, including generative AI, as it provides a scalable and cost-effective solution.</p>
          <p class="subtitle">In serverless architecture, developers focus on writing code for specific functions or tasks, known as serverless functions<a contenteditable="false" data-type="indexterm" data-primary="Azure Functions" id="id413" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>, with <a href="https://oreil.ly/Gm-h9" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Azure Functions</a> being the native Microsoft option. These functions are executed in containers that are managed and scaled automatically by the cloud provider, as you can see in <a data-type="xref" href="#fig_4_managed_cloud_as_a_service_levels" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Figure 2-4</a>. This eliminates the need for developers to provision and manage servers, making it easier to deploy and maintain AI applications.</p>
          <figure class="calibre18"><div id="fig_4_managed_cloud_as_a_service_levels" class="figure">
            <img src="assets/aoas_0204.png" alt="" class="calibre19"/>
            <h6 class="calibre20"><span class="keep-together">Figure 2-4. </span>Managed cloud–as-a-service levels</h6>
          </div></figure>
          <p class="subtitle">Much like other cloud native elements, one of the key advantages of serverless for AI workloads is scalability<a contenteditable="false" data-type="indexterm" data-primary="cloud-as-a-service levels, managed" id="id414" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="scalability of generative AI" data-secondary="with serverless workflows" data-secondary-sortas="serverless workflows" id="id415" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>. Generative AI models often require significant computational resources, especially when training large models or generating complex outputs. Serverless platforms automatically scale resources on demand, allowing AI applications to handle fluctuations in workload without manual intervention. This scalability enables efficient resource utilization and cost optimization, as developers pay for only the actual compute resources used during execution.</p>
          <p class="subtitle">Another advantage of serverless computing is its event-driven<a contenteditable="false" data-type="indexterm" data-primary="event-driven architecture, serverless workflows" id="id416" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> nature. Serverless functions are triggered by specific events, such as HTTP requests or messages from message queues. This event-driven architecture is well-suited for AI workloads that require real-time or asynchronous processing. For example, generative AI applications can be triggered by user interactions or scheduled tasks, allowing them to generate outputs on demand or periodically. Additionally, serverless can be used to perform actions within a generative AI pipeline<a contenteditable="false" data-type="indexterm" data-primary="pipelines, serverless workflows for" id="id417" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="Azure Logic Apps" id="id418" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>. For that purpose, <a href="https://oreil.ly/Qvt6X" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Azure Logic Apps</a> can be used to trigger orchestration and workflows, and it has integration with other Microsoft 365 and Azure services, which can be useful in triggering generative AI pipelines or events.</p>
          <p class="subtitle">There are some limitations related to serverless platforms, such as execution time limits, memory constraints, and deployment package size limits. However, techniques like function composition, caching, and parallel execution can help improve the efficiency and responsiveness of generative AI applications running on serverless architectures. Fine-tuning resource allocation and optimizing data processing pipelines can also contribute to better overall performance.</p>
          <p class="subtitle">In general terms, you will be combining a PaaS such as Azure OpenAI, plus containerized and/or serverless pieces, depending on your implementation approach. We will now explore the web development part of your applications, to get an initial idea of the services that Azure OpenAI leverages to deploy generative AI–enabled web-based applications<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_serverlessworkflows213670" id="id419" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>.</p>
        </div></section>
        <section data-type="sect2" data-pdf-bookmark="Azure-Based Web Development and CI/CD" class="calibre5"><div class="preface" id="azure_based_web_development_and_ci_cd">
          <h2 class="calibre21">Azure-Based Web Development and CI/CD</h2>
          <p class="subtitle">Now, let’s focus on development<a contenteditable="false" data-type="indexterm" data-primary="web development" id="id420" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="continuous integration and continuous deployment (CI/CD)" id="id421" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="CI/CD (continuous integration and continuous deployment)" id="id422" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="deployment of generative AI" data-secondary="CI/CD" id="id423" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="integrations" data-secondary="CI/CD" id="id424" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> building blocks that go beyond core AI capabilities. As a cloud native practitioner, you will likely split your application code into several pieces. As you have already seen, those blocks are microservices that could contain backend and frontend modules (mobile applications, websites, intranets, etc.). </p>
          <p class="subtitle">The interesting part comes when you discover you can host web-based applications directly via Azure App Service<a contenteditable="false" data-type="indexterm" data-primary="Azure App Service" id="id425" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>. Azure App Service is a PaaS, a fully managed service that allows adopters to build, deploy, and scale web applications and APIs without the need to manage underlying infrastructure. It supports various programming languages and frameworks and enables web, mobile, and API app development, as well as workflows (Logic Apps), CI/CD, and monitoring, while offering simple integration with the whole Microsoft Azure suite.</p>
          <p class="subtitle">Overall, Azure App Service simplifies the process of building, deploying, and scaling web applications and APIs in the Azure cloud. It offers a robust and feature-rich platform that enables developers to focus on application development while benefiting from the scalability, availability, and management capabilities provided by the Azure platform.</p>
          <p class="subtitle">You will see in <a data-type="xref" href="ch03.html#implementing_cloud_native_generative_ai_with_azure" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Chapter 3</a> how Azure OpenAI offers simple deployment options that leverage Azure App Service to create chat-based applications with preexisting <span class="keep-together">templates.</span></p>
          <div data-type="note" epub:type="note" class="calibre15"><h6 class="calibre16">Note</h6>
            <p class="subtitle">If you want to dive deeper into any of these topics, please visit the following links:</p>
            <ul class="stafflist">
              <li class="calibre8">
                <p class="calibre24">Application hosting: <a href="https://oreil.ly/moBFz" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Azure App Service Overview | Microsoft Learn</a> </p>
              </li>
              <li class="calibre8">
                <p class="calibre24">GitHub for CI/CD: <a href="https://oreil.ly/Z9EBe" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Deploy to App Service Using GitHub Actions | Microsoft Learn </a></p>
              </li>
              <li class="calibre8">
                <p class="calibre24">YouTube video: <a href="https://oreil.ly/dSe0R" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">How to Deploy Your Web App Using GitHub Actions | Azure Portal Series</a></p>
              </li>
            </ul>
          </div>
          <p class="subtitle">We will now cover the fundamentals of the Azure portal, mostly for readers with no or low Azure experience, as a way to help you understand how to search, configure, and deploy Azure OpenAI and other related services. If you have already worked with Azure and its portal, you may skip this section<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_cloudnativearchitecturesandapplicationscodedevelopment28491" id="id426" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_codingusecasedesigningcloudnativearchitectures28491" id="id427" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>.</p>
        </div></section>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Understanding the Azure Portal" class="calibre5"><div class="preface" id="understanding_the_azure_portal">
        <h1 class="calibre4">Understanding the Azure Portal</h1>
        <p class="subtitle">The Azure portal<a contenteditable="false" data-type="indexterm" data-primary="cloud native architectures and applications" data-secondary="Azure portal" id="xi_cloudnativearchitecturesandapplicationsAzureportal217228" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="Azure portal" id="xi_Azureportal217228" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="user interface (UI)" data-secondary="Azure portal" id="xi_userinterfaceUIAzureportal217228" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> is a web-based UI provided by Microsoft Azure that allows users to manage and interact with their Azure resources. It serves as a central hub for accessing and managing various Azure services and functionalities, including Azure OpenAI Service. The portal provides a visually appealing and intuitive interface that simplifies the management and monitoring of Azure resources (<a data-type="xref" href="#fig_5_azure_portal_main_interface" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Figure 2-5</a>).</p>
        <figure class="calibre18"><div id="fig_5_azure_portal_main_interface" class="figure">
          <img src="assets/aoas_0205.png" alt="" class="calibre19"/>
          <h6 class="calibre20"><span class="keep-together">Figure 2-5. </span>Azure portal: main interface</h6>
        </div></figure>
        <p class="subtitle">As you can see in <a data-type="xref" href="#fig_5_azure_portal_main_interface" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Figure 2-5</a>, it includes a customizable dashboard that provides an overview of your Azure resources, recent activities, and personalized tiles for quick access to frequently used services. </p>
        <p class="subtitle">The navigation pane on the left side of the portal allows you to access different categories of Azure services, including Compute, Storage, Networking, Security + Identity, AI + Machine Learning, and more. You can see the sequence in <a data-type="xref" href="#fig_6_azure_portal_left_panel" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Figure 2-6</a>. </p>
        <figure class="calibre18"><div id="fig_6_azure_portal_left_panel" class="figure">
          <img src="assets/aoas_0206.png" alt="" class="calibre19"/>
          <h6 class="calibre20"><span class="keep-together">Figure 2-6. </span>Azure portal: left panel</h6>
        </div></figure>
        <p class="subtitle">Also, clicking on a specific category expands a menu with subcategories and services within that category. You can actually find Azure OpenAI Service within the AI + Machine Learning category (<a data-type="xref" href="#fig_7_azure_portal_resources_azure_openai_example" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Figure 2-7</a>).</p>
        <figure class="calibre18"><div id="fig_7_azure_portal_resources_azure_openai_example" class="figure">
          <img src="assets/aoas_0207.png" alt="" class="calibre19"/>
          <h6 class="calibre20"><span class="keep-together">Figure 2-7. </span>Azure portal: resources (Azure OpenAI Service example)</h6>
        </div></figure>
        <p class="subtitle">Alternatively, the Azure portal offers a search bar at the top, allowing you to quickly find services, resources, or documentation. As you can see in <a data-type="xref" href="#fig_8_azure_portal_search_azure_openai_example" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Figure 2-8</a>, you can search by keywords or use the natural language query to locate specific functionalities or resources within Azure. Basically, you can find Azure OpenAI by just typing it there. </p>
        <figure class="calibre18"><div id="fig_8_azure_portal_search_azure_openai_example" class="figure">
          <img src="assets/aoas_0208.png" alt="" class="calibre19"/>
          <h6 class="calibre20"><span class="keep-together">Figure 2-8. </span>Azure portal: search (Azure OpenAI Service example)</h6>
        </div></figure>
        <p class="subtitle">Each Azure service has its own dedicated blade, which is essentially a panel that provides detailed information and management options for that service. If you choose Azure OpenAI from either the search engine or the left panel, you will enter your resource details (<a data-type="xref" href="#fig_9_azure_portal_resource_details_azure_openai_examp" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Figure 2-9</a>). Basically, you are able to create new resources for Azure OpenAI, or manage those previously deployed. If you choose Create, you can see the required information to deploy a new Azure OpenAI Service. </p>
        <figure class="calibre18"><div id="fig_9_azure_portal_resource_details_azure_openai_examp" class="figure">
          <img src="assets/aoas_0209.png" alt="" class="calibre19"/>
          <h6 class="calibre20"><span class="keep-together">Figure 2-9. </span>Azure portal: resource details (Azure OpenAI Service example)</h6>
        </div></figure>
        <p class="subtitle">You can find details related to your subscription, geographic region preferences, the unique name chosen for your Azure resource, and the pricing tier. (Tiers are the level of pricing based on estimated usage; for now there is only one option for Azure OpenAI, called “Standard S0.” Any update should be available via the <a href="https://oreil.ly/7Gmq6" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">official pricing page</a>, and the <a href="https://oreil.ly/2SQ4C" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Azure calculator</a>.)</p>
        <p class="subtitle">In addition to managing individual resources, the Azure portal<a contenteditable="false" data-type="indexterm" data-primary="resource groups, Azure portal" id="id428" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> allows you to create <a href="https://oreil.ly/J2LMM" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">resource groups</a> to logically organize and manage related resources together. This is an interesting feature, and a recommended best practice to group the required resources for your generative AI implementations with Azure, including Azure OpenAI Service and others we will need for our projects.</p>
        <div data-type="note" epub:type="note" class="calibre15"><h6 class="calibre16">Note</h6>
          <p class="subtitle">If you haven’t created an Azure account before, the first step is to <a href="https://oreil.ly/WVIm2" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">create a free one</a>. It usually includes credits with a value of USD $200 for initial experimentation. It requires a corporate email for the specific account and payment information.</p>
        </div>
        <p class="subtitle">We will explore the details of generative AI implementation approaches with Microsoft Azure in <a data-type="xref" href="ch03.html#implementing_cloud_native_generative_ai_with_azure" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Chapter 3</a>, but the idea behind the Azure portal is to facilitate the deployment, management, and maintenance process of the different resources required to create these architectures, regardless of the type of service. Deploying any Azure services from the Azure portal involves several steps, so remember the high-level process:</p>
        <dl class="stafflist">
          <dt class="calibre10">1. Sign in to the Azure portal.</dt>
          <dd class="calibre11">
            <p class="subtitle">Open a web browser, navigate to the Azure portal, and sign up with your Azure account credentials.</p>
          </dd>
          <dt class="calibre10">2. Create a resource.</dt>
          <dd class="calibre11">
            <p class="subtitle">To deploy an Azure service, you need to create a resource. A resource represents a service or component in Azure, such as a virtual machine, a storage account, or a database. Click on the “Create a resource” button in the Azure portal.</p>
          </dd>
          <dt class="calibre10">3. Select a service.</dt>
          <dd class="calibre11">
            <p class="subtitle">In the resource creation wizard, you’ll see a list of available Azure services. Choose the service you want to deploy by browsing through the categories or using the search bar.</p>
          </dd>
          <dt class="calibre10">4. Configure the resource.</dt>
          <dd class="calibre11">
            <p class="subtitle">Once you’ve selected a service, you’ll be taken to a configuration page where you can specify the settings for the resource. The options available depend on the specific service you’re deploying. Fill in the required information, such as resource name, region, pricing tier, and any other relevant settings.</p>
          </dd>
          <dt class="calibre10">5. Review and create.</dt>
          <dd class="calibre11">
            <p class="subtitle">After configuring the resource, review the settings to ensure they are correct. You can also enable additional features or add-ons if available. Once you’re satisfied, click the “Review + Create” button.</p>
          </dd>
          <dt class="calibre10">6. Validation and deployment.</dt>
          <dd class="calibre11">
            <p class="subtitle">Azure will validate the configuration settings and check for any potential issues. If everything is in order, click the “Create” button to initiate the deployment <span class="keep-together">process.</span></p>
          </dd>
          <dt class="calibre10">7. Monitor the deployment.</dt>
          <dd class="calibre11">
            <p class="subtitle">Azure will start provisioning the resources based on your configuration. You can monitor the deployment progress in the Azure portal. Depending on the service, the deployment may take a few minutes to complete.</p>
          </dd>
          <dt class="calibre10">8. Access and manage the deployed service.</dt>
          <dd class="calibre11">
            <p class="subtitle">Once the deployment is finished, you can access and manage the deployed service through the Azure portal. You can view its properties, make changes to its configuration, monitor its performance, and perform other administrative tasks as needed.</p>
          </dd>
        </dl>
        <p class="subtitle">This is the process for most of the Azure resources, but there are other deployment methods such as <a href="https://oreil.ly/TZXTy" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Azure Resource Manager templates</a>, <a href="https://oreil.ly/jezRs" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">API-enabled resource orchestration</a>, <a href="https://oreil.ly/aZOxZ" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Azure Bicep</a>, <a href="https://oreil.ly/Wi9xy" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Terraform on Azure</a>, or command-line tools such as <a href="https://oreil.ly/Mm4N1" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Azure CLI</a> or <a href="https://oreil.ly/22BEd" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Azure PowerShell</a>, all of them for more advanced admin/technical users. Feel free to explore them if you want to learn more. </p>
        <p class="subtitle">For Azure OpenAI Service, you can always visit the <a href="https://oreil.ly/hSPh3" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">official resource deployment guide</a>, which summarizes the steps we just walked through. Other information you may want to review before deploying the service includes the <a href="https://oreil.ly/MDBhf" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">main product page</a>, the previously mentioned <a href="https://oreil.ly/7Gmq6" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">pricing guide</a>, the service <a href="https://oreil.ly/tYnCe" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">availability by geographic region</a> (for example, if you deploy the service from the European Union, you may want to use a closer region, such as West Europe in Amsterdam, for better latency, performance, and maybe pricing), and the <a href="https://oreil.ly/3oNQU" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">general documentation</a>.</p>
        <p class="subtitle">Now that you know how to use the Azure portal, and the key information about the Azure OpenAI Service deployment process, let’s analyze some important considerations at the model and general architecture levels<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_cloudnativearchitecturesandapplicationsAzureportal217228" id="id429" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_Azureportal217228" id="id430" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_userinterfaceUIAzureportal217228" id="id431" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>. This will be key to creating the end-to-end implementations we will see in <a data-type="xref" href="ch03.html#implementing_cloud_native_generative_ai_with_azure" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Chapter 3</a>.</p>
      </div></section>
      <section data-type="sect1" class="calibre5" data-pdf-bookmark="General Azure OpenAI Service Considerations"><div class="preface" id="general_azure_openai_considerations">
        <h1 class="calibre4">General Azure OpenAI Service Considerations</h1>
        <p class="subtitle">Now that we have explored the notion of cloud native development with Azure, and the fundamentals of the Azure portal for Azure OpenAI Service, let’s go deeper into the different AI models that are available and the high-level architectures so you can know how to make sense of the Azure-enabled generative AI offerings.</p>
        <section data-type="sect2" data-pdf-bookmark="Available Azure OpenAI Service Models" class="calibre5"><div class="preface" id="available_azure_openai_models">
          <h2 class="calibre21">Available Azure OpenAI Service Models</h2>
          <p class="subtitle">Most cloud-enabled PaaS resources from any public cloud<a contenteditable="false" data-type="indexterm" data-primary="cloud native architectures and applications" data-secondary="models from Azure OpenAI" id="xi_cloudnativearchitecturesandapplicationsmodelsfromAzureOpenAI224769" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="Azure OpenAI Service" data-secondary="models" id="xi_AzureOpenAIServicemodels224769" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="models" id="xi_models224769" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>, including those from Microsoft Azure, leverage native endpoints and APIs as a way to connect and to consume their models. This is the case for Azure OpenAI Service and the rest of the Azure AI Services we have seen in this chapter.</p>
          <p class="subtitle">Also, there are visual elements<a contenteditable="false" data-type="indexterm" data-primary="Azure AI Studio" id="id432" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="Azure ML Studio" id="id433" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="Azure OpenAI Studio" id="id434" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> such as <a href="https://oreil.ly/PCMD3" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Azure AI Studio</a> and <a href="https://oreil.ly/kdZhY" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Azure ML Studio</a> (not to be confused with <a href="https://oreil.ly/LWQO1" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Azure OpenAI Studio</a>, which we will explain and leverage in <a data-type="xref" href="ch03.html#implementing_cloud_native_generative_ai_with_azure" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Chapter 3</a>) that provide access to different proprietary and open source AI/foundation models. This includes a model catalog to leverage the curated selection of models, including those from Azure OpenAI, Meta, and Hugging Face (e.g., the <a href="https://oreil.ly/96mAx" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Hugging Face Hub in Azure</a>, announced by both Microsoft and Hugging Face during Microsoft Build 2023). This also allows us to test and deploy those models in a very simple way. </p>
          <p class="subtitle">As you can see in <a data-type="xref" href="#fig_10_azure_ai_studio_main_interface" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Figure 2-10</a>, if you visit the <a href="https://oreil.ly/kdZhY" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Studio page</a>, you will get access to your existing workspaces, or you will be able to create a new one if it is your first time connecting to the studio.</p>
          <figure class="calibre18"><div id="fig_10_azure_ai_studio_main_interface" class="figure">
            <img src="assets/aoas_0210.png" alt="" class="calibre19"/>
            <h6 class="calibre20"><span class="keep-together">Figure 2-10. </span>Azure AI Studio: main interface</h6>
          </div></figure>
          <p class="subtitle">If you access the workspace, you will see the same kind of visual interface we reviewed earlier in this chapter. In <a data-type="xref" href="#fig_11_azure_ai_studio_left_panel" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Figure 2-11</a>, the left panel for the workspace menu offers all options related to data, models, endpoints, required resources, etc. For the sake of simplicity, we will focus on two main features<a contenteditable="false" data-type="indexterm" data-primary="model catalog, Azure AI Studio" id="xi_modelcatalogAzureAIStudio2254412" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>: the <a href="https://oreil.ly/BYkuc" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">model catalog</a>, and later in <a data-type="xref" href="ch04.html#additional_cloud_and_ai_capabilities" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Chapter 4</a>, the prompt flow functionality.</p>
          <figure class="calibre18"><div id="fig_11_azure_ai_studio_left_panel" class="figure">
            <img src="assets/aoas_0211.png" alt="" class="calibre19"/>
            <h6 class="calibre20"><span class="keep-together">Figure 2-11. </span>Azure AI Studio: left panel</h6>
          </div></figure>
          <p class="subtitle">If you choose the model catalog option and search “Azure OpenAI” or click directly on the tile as shown in <a data-type="xref" href="#fig_12_azure_ai_studio_model_catalog" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Figure 2-12</a>, you will get access to the updated list of available Azure OpenAI models.</p>
          <figure class="calibre18"><div id="fig_12_azure_ai_studio_model_catalog" class="figure">
            <img src="assets/aoas_0212.png" alt="" class="calibre19"/>
            <h6 class="calibre20"><span class="keep-together">Figure 2-12. </span>Azure AI Studio: model catalog</h6>
          </div></figure>
          <p class="subtitle">The models in <a data-type="xref" href="#fig_13_azure_ai_studio_azure_openai_models" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Figure 2-13</a> are those available at the time of writing, but depending on when you check the catalog, you will likely find these and/or others. An alternative way to check all the available models at the moment is to use the <a href="https://oreil.ly/bk7Zd" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">List API</a>.</p>
          <figure class="calibre18"><div id="fig_13_azure_ai_studio_azure_openai_models" class="figure">
            <img src="assets/aoas_0213.png" alt="" class="calibre19"/>
            <h6 class="calibre20"><span class="keep-together">Figure 2-13. </span>Azure AI Studio: Azure OpenAI Service models</h6>
          </div></figure>
          <p class="subtitle">Now, keeping in mind the evolving nature of the availability of Azure OpenAI models, explore the key model families and some examples of specific models that you will leverage for your generative AI projects. This will certainly change over time, but it is a good beginning.</p>
          <p class="subtitle">Azure OpenAI Service splits its capabilities into different <em class="hyperlink">model families</em>. A model family typically associates AI models by their intended task, such as natural language understanding, code generation, or image synthesis. Some of the most popular Azure OpenAI model families are as follows:</p>
          <dl class="stafflist">
            <dt class="calibre10">Language-related models</dt>
            <dd class="calibre11">
              <p class="subtitle">Popular language-related models<a contenteditable="false" data-type="indexterm" data-primary="language-related AI models" id="id435" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="models" data-secondary="language-related" id="id436" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> include the following:</p>
              <dl class="stafflist">
                <dt class="calibre10">GPT-3.5 Turbo and GPT-3.5 Turbo Instruct</dt>
                <dd class="calibre11"><p class="subtitle">Models that improve on previous GPT-3<a contenteditable="false" data-type="indexterm" data-primary="GPT-3" id="id437" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> versions and can understand and generate natural language and code. There are several versions with different context length limits, including those for 4K and 16K tokens, which is the measure of the maximum text input.</p></dd>
                <dt class="calibre10">GPT-4, GPT-4 Turbo, GPT-4o</dt>
                <dd class="calibre11"><p class="subtitle">Models with better performance<a contenteditable="false" data-type="indexterm" data-primary="GPT-4" id="id438" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> (and higher cost) than 3.5 Turbo, which can handle more complex tasks and generate more accurate and diverse outputs. They can also handle bigger text inputs (which we usually define as “context”) than their predecessors.</p></dd>
                <dt class="calibre10">Speech</dt>
                <dd class="calibre11"><p class="subtitle">There are other options in Azure, but Azure AI Studio<a contenteditable="false" data-type="indexterm" data-primary="Whisper (speech-to-text model)" id="id439" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="speech-to-text model (Whisper)" id="id440" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> includes the speech-to-text <a href="https://oreil.ly/9si-P" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Whisper model</a> from OpenAI (i.e., by typing “whisper” and selecting the model). It is not directly available from Azure OpenAI Studio, but it can be integrated with the rest of GPT models to create voice-to-text scenarios.</p></dd>
            </dl>
            </dd>
            <dt class="calibre10">Other models</dt>
            <dd class="calibre11">
              <p class="subtitle">Other popular models include the following:</p>
              <dl class="stafflist">
                <dt class="calibre10">Codex for programming code</dt>
                <dd class="calibre11"><p class="subtitle">A series of models that can understand and generate code<a contenteditable="false" data-type="indexterm" data-primary="Codex" id="id441" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>, including translating natural language to code. The reality is that Codex was initially a separate model, but after some time OpenAI added its capabilities to the regular GPT-3.5 Turbo and GPT-4 language models. This means the same models handle both natural language and programming code.</p></dd>
                <dt class="calibre10">DALL·E for images</dt>
                <dd class="calibre11"><p class="subtitle">A series of models<a contenteditable="false" data-type="indexterm" data-primary="DALL·E model series" id="id442" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> that can generate original images from natural language<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_modelcatalogAzureAIStudio2254412" id="id443" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="model families, Azure OpenAI" id="xi_modelfamiliesAzureOpenAI229198" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>. This is the model behind tools like <a href="https://oreil.ly/YwDy-" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Bing Create</a> and <a href="https://oreil.ly/oIRon" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Microsoft Designer</a>, and it is directly available from Azure OpenAI Studio, as we will see in <a data-type="xref" href="ch03.html#implementing_cloud_native_generative_ai_with_azure" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Chapter 3</a>.</p></dd>
              </dl>
            </dd>
          </dl>
          <p class="subtitle">It is important to differentiate the different model families and their specific capabilities to understand which ones we will use for our generative AI projects. Also, the trade-off of different Azure OpenAI models depends on the use case and the available budget. Generally speaking, more capable models like GPT-4o can handle more complex tasks and generate more accurate and diverse outputs, but they also consume more resources and incur higher costs. We will explore several scenarios in <a data-type="xref" href="ch03.html#implementing_cloud_native_generative_ai_with_azure" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Chapter 3</a> that can work with all these GPT models. You can also explore the whole set of OpenAI models, including some deprecated ones that are still<a href="https://oreil.ly/SG-fe" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"> traced via OpenAI’s documentation</a>.</p>
          <p class="subtitle">Besides all these functionalities, one of the key features for LLM-enabled<a contenteditable="false" data-type="indexterm" data-primary="embeddings" id="xi_embeddings229688" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> systems is <em class="hyperlink">embeddings</em>. This is a general term related to NLP and LLMs. Embeddings are a way of representing data in a multidimensional space. They are often used to capture the semantic meaning of words, images, or other types of data. For example, in <a data-type="xref" href="#fig_14_embedding_model" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Figure 2-14</a>, an embedding model can map a word to a vector of numbers, such that words with similar meanings have similar vectors. This means we can connect pieces of information that are not directly connected, but that may have a mathematical or linguistic connection (e.g., several knowledge bases from companies of the same sector, internal and external sources, etc.).</p>
          <figure class="calibre18"><div id="fig_14_embedding_model" class="figure">
            <img src="assets/aoas_0214.png" alt="" class="calibre19"/>
            <h6 class="calibre20"><span class="keep-together">Figure 2-14. </span>Embedding model</h6>
          </div></figure>
          <p class="subtitle">This example illustrates the typical <em class="hyperlink">generation and search process</em>:</p>
          <ol class="stafflist">
            <li class="calibre34">
              <p class="calibre24">We collect different data inputs (PDFs, text files, URLs, etc.) to create our knowledge base. This is a simplified view as sources are previously processed to extract the text-based information. We will see options for this such as official accelerators and Azure AI Document Intelligence in <a data-type="xref" href="ch03.html#implementing_cloud_native_generative_ai_with_azure" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Chapter 3</a>.</p>
            </li>
            <li class="calibre34">
              <p class="calibre24">We leverage the <a href="https://oreil.ly/bhgTY" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Embeddings API</a> to generate the embeddings from diverse sources. We can use a basic API call with the text input that returns the generated <span class="keep-together">vectors.</span></p>
            </li>
            <li class="calibre34">
              <p class="calibre24">The generated vectors/embeddings are stored in a vector database<a contenteditable="false" data-type="indexterm" data-primary="vector database" id="id444" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>. We will explore several database options in Azure in <a data-type="xref" href="ch03.html#implementing_cloud_native_generative_ai_with_azure" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Chapter 3</a>.</p>
            </li>
            <li class="calibre34">
              <p class="calibre24">After the generation process, we can assume end users will want to search for specific topics or information that will be included as part of the different data inputs we have collected and vectorized. For that purpose, we will use the same embeddings API to generate the embeddings of the questions itself (note: we need the same embedding model for both knowledge and questions).</p>
            </li>
            <li class="calibre34">
              <p class="calibre24">The vector database will support search<a contenteditable="false" data-type="indexterm" data-primary="search use case" data-secondary="vector database functions" id="id445" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> functions. This means we will use the vectorized user questions as input to find information from the vector database that contains our knowledge base.</p>
            </li>
            <li class="calibre34">
              <p class="calibre24">If there are related topics, the search function will return a Top-k variety of results that we can use to generate the answer (either by directly printing the results or by passing them as input for a chat-based scenario).</p>
            </li>
          </ol>
          <p class="subtitle">The embeddings use cases available in Azure OpenAI Service are as follows:</p>
          <dl class="stafflist">
            <dt class="calibre10">Text similarity</dt>
            <dd class="calibre11">
              <p class="subtitle">A set of models<a contenteditable="false" data-type="indexterm" data-primary="text similarity use case for embeddings" id="id446" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="similarity metric, generative AI performance" id="id447" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> that provide embeddings that capture the semantic similarity of pieces of text. These models are useful for many tasks such as clustering, regression, anomaly detection, and visualization.</p>
            </dd>
            <dt class="calibre10">Text search</dt>
            <dd class="calibre11">
              <p class="subtitle">A set of models<a contenteditable="false" data-type="indexterm" data-primary="text search use case for embeddings" id="id448" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="search use case" data-secondary="text search for embeddings" id="id449" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> that provide embeddings that enable semantic information retrieval over documents. These models are useful for tasks such as search, context relevance, and information retrieval.</p>
            </dd>
            <dt class="calibre10">Code search</dt>
            <dd class="calibre11">
              <p class="subtitle">A set of models that provide embeddings that enable finding relevant code<a contenteditable="false" data-type="indexterm" data-primary="coding use case" data-secondary="for embeddings" id="id450" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> with a query in natural language. These models are useful for tasks such as code search and relevance.</p>
            </dd>
          </dl>
          <p class="subtitle">At a technical level, the recommended model option for embeddings with Azure OpenAI Service<a contenteditable="false" data-type="indexterm" data-primary="Ada, embedding model" id="id451" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> is called “Ada”; this is an <a href="https://oreil.ly/6m7SL" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">improved and more cost-effective</a> model than its predecessors. This is pretty useful to increase the knowledge scope of Azure OpenAI, by consuming information from PDFs, websites, text files, etc.</p>
          <p class="subtitle">As previously mentioned, embeddings generation is based on a very simple API call/response dynamic, and the specific details on how to generate embeddings for a given source are available in <a href="https://oreil.ly/2cxWx" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">the official documentation</a>, as well as the specific <a href="https://oreil.ly/SQSGw" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">context length limits</a> (e.g., 8K tokens for Ada version 2). Generating embeddings is as simple as calling the embedding API with the desired text input you want to vectorize. For example, in Python:</p>
            <pre data-type="programlisting" data-code-language="python" class="calibre35"><code class="kn">import</code> <code class="nn">openai</code>
<code class="n">openai</code><code class="o">.</code><code class="n">api_type</code> <code class="o">=</code> <code class="s">"azure"</code>
<code class="n">openai</code><code class="o">.</code><code class="n">api_key</code> <code class="o">=</code> <code class="n">YOUR_API_KEY</code>
<code class="n">openai</code><code class="o">.</code><code class="n">api_base</code> <code class="o">=</code> <code class="s">"https://YOUR_RESOURCE_NAME.openai.azure.com"</code>
<code class="n">openai</code><code class="o">.</code><code class="n">api_version</code> <code class="o">=</code> <code class="s">"2023-05-15"</code>

<code class="n">response</code> <code class="o">=</code> <code class="n">openai</code><code class="o">.</code><code class="n">Embedding</code><code class="o">.</code><code class="n">create</code><code class="p">(</code>
    <code class="nb">input</code><code class="o">=</code><code class="s">"Your text string goes here"</code><code class="p">,</code>
    <code class="n">engine</code><code class="o">=</code><code class="s">"YOUR_DEPLOYMENT_NAME"</code>
<code class="p">)</code>
<code class="n">embeddings</code> <code class="o">=</code> <code class="n">response</code><code class="p">[</code><code class="s">'data'</code><code class="p">][</code><code class="mi">0</code><code class="p">][</code><code class="s">'embedding'</code><code class="p">]</code>
<code class="nb">print</code><code class="p">(</code><code class="n">embeddings</code><code class="p">)</code></pre>
          <p class="subtitle">The output of this would be a numerical representation, where each number in the list corresponds to a dimension in the embedding space. The exact values will depend on the specific model and its training data, but it could look like this:</p>
            <pre data-type="programlisting" class="calibre35">[0.123, 0.456, 0.789, ..., 0.987]</pre>
          <p class="subtitle">We have completed the review of Azure OpenAI models and their capabilities. While we will cover the details of project examples and architectures in <a data-type="xref" href="ch03.html#implementing_cloud_native_generative_ai_with_azure" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Chapter 3</a>, the next section will explore general architectural building blocks for Azure OpenAI–enabled implementations, as well as general cloud infrastructure topics<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_cloudnativearchitecturesandapplicationsmodelsfromAzureOpenAI224769" id="id452" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_AzureOpenAIServicemodels224769" id="id453" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_modelfamiliesAzureOpenAI229198" id="id454" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_embeddings229688" id="id455" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_models224769" id="id456" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>.</p>
        </div></section>
        <section data-type="sect2" data-pdf-bookmark="Architectural Elements of Generative AI Systems" class="calibre5"><div class="preface" id="architectural_elements_of_generative_ai_systems">
          <h2 class="calibre21">Architectural Elements of Generative AI Systems</h2>
          <p class="subtitle">Azure-based architectures<a contenteditable="false" data-type="indexterm" data-primary="cloud native architectures and applications" data-secondary="elements of generative AI systems" id="xi_cloudnativearchitecturesandapplicationselementsofgenerativeAIsystems235739" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="architectural elements of" id="xi_generativeAIarchitecturalelementsof235739" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> rely on a series of interconnected services that can communicate with each other for a specific purpose. In this case, Azure OpenAI plays a crucial role to enable interactions between any customer-side application, but we rely on more building blocks to build our generative AI solutions. In <a data-type="xref" href="#fig_15_high_level_architecture_building_blocks" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Figure 2-15</a>, you can see the main building blocks of an Azure OpenAI–enabled (simplified) architecture.</p>
          <figure class="calibre18"><div id="fig_15_high_level_architecture_building_blocks" class="figure">
            <img src="assets/aoas_0215.png" alt="" class="calibre19"/>
            <h6 class="calibre20"><span class="keep-together">Figure 2-15. </span>High-level architecture building blocks</h6>
          </div></figure>
          <p class="subtitle">Let’s take a look at these pieces in a little more detail:</p>
          <dl class="stafflist">
            <dt class="calibre10">Application frontend</dt>
            <dd class="calibre11">
              <p class="subtitle">Any app-side element that leverages generative AI capabilities.</p>
            </dd>
            <dt class="calibre10">Middleware/orchestration</dt>
            <dd class="calibre11">
              <p class="subtitle">We will explore this element in <a data-type="xref" href="ch03.html#implementing_cloud_native_generative_ai_with_azure" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Chapter 3</a>, but the orchestration piece basically allows us to connect different Azure OpenAI skills with other relevant services. Also, the middleware can include API management and other topics that we will see in <a data-type="xref" href="ch03.html#implementing_cloud_native_generative_ai_with_azure" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Chapter 3</a>.</p>
            </dd>
            <dt class="calibre10">Azure OpenAI Service</dt>
            <dd class="calibre11">
              <p class="subtitle">For text-based skills, such as explaining the answer to a complex question, for both completion and chat-based scenarios.</p>
            </dd>
            <dt class="calibre10">Additional knowledge base</dt>
            <dd class="calibre11">
              <p class="subtitle">This is a combination of the core data sources (databases, blob storage, etc.) and knowledge extraction elements such as embeddings, Azure Cognitive Search, Bing Search, etc. For now, we will define them as “grounding blocks,” but we will see the details in <a data-type="xref" href="ch03.html#implementing_cloud_native_generative_ai_with_azure" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Chapter 3</a>.</p>
            </dd>
          </dl>
          <p class="subtitle">If you develop an application that leverages Azure OpenAI and other Azure services, and that implementation is part of a bigger data/AI-enabled platform, the end-to-end architecture might start to look something like <a data-type="xref" href="#fig_16_end_to_end_azure_platform_including_azure_openai" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Figure 2-16</a>.</p>
          <figure class="calibre18"><div id="fig_16_end_to_end_azure_platform_including_azure_openai" class="figure">
            <img src="assets/aoas_0216.png" alt="" class="calibre19"/>
            <h6 class="calibre20"><span class="keep-together">Figure 2-16. </span>End-to-end Azure platform (including Azure OpenAI Service)</h6>
          </div></figure>
          <p class="subtitle">In this case, Azure OpenAI Service is just part of a bigger end-to-end that includes data sources, integration processes, SQL/NoSQL databases, containerization, analytics, etc. The final setup depends on the structure of the platform itself, but this is a good overview to understand where Azure OpenAI sits for any data and AI implementation with Microsoft Azure. </p>
          <p class="subtitle">If you want to learn more about Azure-enabled architectures and the details of all these cloud services, please check out <a class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2" href="https://oreil.ly/G2U08"><em class="hyperlink">Learning Microsoft Azure</em></a> by Jonah Carrio Andersson<a contenteditable="false" data-type="indexterm" data-primary="Andersson, Jonah Carrio" id="id457" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="Learning Microsoft Azure (Andersson)" id="id458" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>. Also, the main reference for architecture<a contenteditable="false" data-type="indexterm" data-primary="Microsoft Architecture Center" id="id459" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> is the official <a href="https://oreil.ly/0jzik" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Microsoft Architecture Center</a> for specific <a href="https://oreil.ly/y-gPD" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Azure OpenAI scenarios</a>. You may want to bookmark this resource as the Microsoft teams continuously update the content with new visual architectures and explanations, including some examples with Azure OpenAI <span class="keep-together">Service.</span></p>
          <p class="subtitle">Another interesting architecture<a contenteditable="false" data-type="indexterm" data-primary="Azure OpenAI Landing Zone" id="id460" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> you can explore is the <a href="https://oreil.ly/xLs8X" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Azure OpenAI Landing Zone reference architecture</a>, which includes end-to-end cloud considerations, including core infrastructure topics such as identity and security, monitorization, cost management, user and API management, FinOps, etc. This is a very rich and complete overview of what an enterprise-grade implementation would include, beyond the core generative AI capabilities.</p>
          <p class="subtitle">Last but not least, don’t forget to explore<a contenteditable="false" data-type="indexterm" data-primary="CNCF Cloud Native AI Whitepaper" id="id461" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="Cloud Native Computing Foundation (CNCF)" id="id462" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/> the <a href="https://oreil.ly/qd4lq" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">CNCF Cloud Native AI Whitepaper</a> from the <a href="https://oreil.ly/8k0bc" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">AI Working Group</a>, which includes technology building blocks, techniques, and cloud native resources for generative AI topics<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_cloudnativearchitecturesandapplicationselementsofgenerativeAIsystems235739" id="id463" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_generativeAIarchitecturalelementsof235739" id="id464" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>.</p>
        </div></section>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="Conclusion" class="calibre5"><div class="preface" id="conclusion_1">
        <h1 class="calibre4">Conclusion</h1>
        <p class="subtitle">As you can see, cloud native architectures are valuable for generative AI development, as they seamlessly integrate with Azure OpenAI and other Azure services<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_cloudnativearchitecturesandapplications2335" id="id465" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_AzureOpenAIServicecloudnativearchitectures2335" id="id466" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2"/>. We will explore different implementation approaches in <a data-type="xref" href="ch03.html#implementing_cloud_native_generative_ai_with_azure" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Chapter 3</a>, but all of them rely on the capabilities and key building blocks discussed here. As an adopter, you may face situations where you will need to optimize existing applications so they can incorporate generative AI capabilities (as we reviewed in the modernization section), but you will also have the opportunity to develop new Azure OpenAI–enabled applications from scratch. In this case, leveraging containerization, serverless, and PaaS pieces will help you design well-architected and scalable architectures and solutions. Depending on your current level of knowledge, it will be important for you to understand the cloud fundamentals behind Microsoft Azure and specific services for development, APIs, and Kubernetes container orchestration. </p>
        <p class="subtitle"><a data-type="xref" href="ch03.html#implementing_cloud_native_generative_ai_with_azure" class="pcalibre1 pcalibre3 calibre6 pcalibre4 pcalibre2">Chapter 3</a> will focus on different alternatives for enhancing your Azure OpenAI applications with specific company knowledge, as well as the main features and interfaces that you will leverage for your next projects. It also includes new terms that we briefly explored in this, such as vector database and orchestration. Let’s continue.</p>
      </div></section>
    </div></section></div>
</div>
</body></html>