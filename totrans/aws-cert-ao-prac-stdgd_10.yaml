- en: Chapter 9\. Security, Compliance, and Governance for AI Solutions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: On an annual basis, JPMorgan spends more than $600 million on cybersecurity.^([1](ch09.html#ch01fn29))
    The amount is over $1 billion for Bank of America.
  prefs: []
  type: TYPE_NORMAL
- en: These are not outliers. Cybersecurity spending is a massive category, with the
    amount estimated at $183 billion—across the globe—in 2024, according to research
    from Gartner.^([2](ch09.html#ch01fn30)) The firm predicts an 11.7% compound annual
    growth rate (CAGR) from 2023 to 2028\. Some of the factors driving this include
    the increased threats of AI and cloud technologies.
  prefs: []
  type: TYPE_NORMAL
- en: For AWS, security is its top priority. This includes massive investments in
    protecting the platform as well as offering a wide array of services for millions
    of customers. Many of these services—like AWS IAM, Amazon GuardDuty, and AWS Config—are
    highlighted on the AIF-C01 exam. In this chapter, we’ll look at these tools and
    the broader principles of governance and security for AI systems—critical topics
    for passing the AWS exam.
  prefs: []
  type: TYPE_NORMAL
- en: Overview of Security, Compliance, and Governance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is common to lump together the concepts of security, governance, and compliance.
    Yet each has a different role, and it’s important to understand the distinctions.
    Here is a breakdown:'
  prefs: []
  type: TYPE_NORMAL
- en: Security
  prefs: []
  type: TYPE_NORMAL
- en: Focusing on protecting data and infrastructure, its goal is to ensure confidentiality
    (only the right people can access information), integrity (data stays accurate
    and trustworthy), and availability (systems and data are accessible when needed).
    You’ll usually hear this function referred to as *information security* or *cybersecurity*.
  prefs: []
  type: TYPE_NORMAL
- en: Governance
  prefs: []
  type: TYPE_NORMAL
- en: This is about guiding the organization wisely. It ensures the business can create
    value while effectively managing risk. In the context of AI, governance provides
    the structure that keeps innovation aligned with accountability. It helps organizations
    move fast without breaking things—especially when those “things” include customer
    trust, ethical standards, or regulatory compliance.
  prefs: []
  type: TYPE_NORMAL
- en: Compliance
  prefs: []
  type: TYPE_NORMAL
- en: This makes sure the organization follows the rules—whether they come from laws,
    regulations, internal policies, or industry standards. It’s about meeting requirements
    consistently and reliably.
  prefs: []
  type: TYPE_NORMAL
- en: Together, these three functions help an organization deliver on its core mission.
    They define the nonnegotiables—the essential safeguards that shouldn’t be compromised.
  prefs: []
  type: TYPE_NORMAL
- en: For the rest of the chapter, we’ll have sections for each of the three functions
    and what you will need to know for the exam for each of them.
  prefs: []
  type: TYPE_NORMAL
- en: Security
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To effectively secure AI systems, organizations employ layered strategies and
    specific frameworks designed to manage risk across different use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Security approaches with AWS tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Defense in depth* is a layered security approach based on the idea that no
    single control is foolproof. Think of it like securing your home. You might lock
    the front door—that’s your firewall, like AWS web application firewall (WAF) or
    security groups. But you also install an alarm system, which is similar to using
    Amazon GuardDuty or AWS Security Hub to detect and alert on threats. Add motion
    detectors, and you’re proactively sensing unusual activity—just like using Amazon
    EventBridge to trigger automated responses. And finally, you set up security cameras,
    which record events so you can review what happened. In AWS, this is CloudTrail
    or AWS Config, which provide logging and historical visibility. If one measure
    fails, the others help catch what slipped through. This is the essence of defense
    in depth on AWS.'
  prefs: []
  type: TYPE_NORMAL
- en: This strategy—which is likely to be on the exam—becomes especially important
    when you’re dealing with generative AI, where workloads often involve sensitive
    data, valuable intellectual property, and a fast-moving development cycle (see
    [Figure 9-1](#figure_nine_onedot_the_layers_of_securi)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/awsc_0901.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9-1\. The layers of security in AWS
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Before setting up the layers, you should write clear, actionable policies. For
    example, suppose your data science team spins up training clusters often. Implement
    least privilege access with AWS IAM and use the Access Analyzer to flag permissions
    that might be too permissive. Then enforce short-lived credentials so no one ends
    up with long-term administrative access they don’t need.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at each of these layers in more detail:'
  prefs: []
  type: TYPE_NORMAL
- en: Data protection
  prefs: []
  type: TYPE_NORMAL
- en: For data at rest, you can use AWS Key Management Service (KMS) to encrypt everything—from
    training datasets in Amazon S3 to model checkpoints. Enable versioning in Amazon
    S3 so you can roll back if anything gets corrupted or tampered with.
  prefs: []
  type: TYPE_NORMAL
- en: For data in transit, use AWS Certificate Manager (ACM) to handle TLS certificates
    and AWS Private CA to issue internal certs. Route sensitive traffic through AWS
    PrivateLink to avoid exposing it to the public internet.
  prefs: []
  type: TYPE_NORMAL
- en: IAM
  prefs: []
  type: TYPE_NORMAL
- en: Using IAM, you should create distinct roles for your model training, inference,
    and monitoring workloads. Avoid using root credentials and enable multi-factor
    authentication (MFA) for every human user.
  prefs: []
  type: TYPE_NORMAL
- en: Application protection
  prefs: []
  type: TYPE_NORMAL
- en: There are different ways to protect applications. For example, you can use AWS
    Shield to mitigate denial-of-service (DoS) attacks and Amazon Cognito to securely
    manage user sign-in and identity federation.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say you’re hosting a generative text API. A bad actor could try to overwhelm
    it with automated requests. Shield helps absorb the traffic, while Cognito enforces
    rate limits and authentication rules to keep access secure.
  prefs: []
  type: TYPE_NORMAL
- en: Threat detection and incident response
  prefs: []
  type: TYPE_NORMAL
- en: Things will go wrong. The key is catching the problems early and knowing how
    to respond. You can use Amazon GuardDuty to detect suspicious activity in your
    accounts. Combine it with AWS Security Hub to centralize alerts across services.
  prefs: []
  type: TYPE_NORMAL
- en: When incidents happen, automate your first steps. Use Amazon EventBridge to
    trigger a Lambda function that quarantines suspicious Amazon EC2 instances or
    revokes IAM permissions automatically. This opens up more time for your team to
    investigate.
  prefs: []
  type: TYPE_NORMAL
- en: Infrastructure protection
  prefs: []
  type: TYPE_NORMAL
- en: As part of a defense-in-depth strategy, the infrastructure layer acts as one
    of the key lines of defense. Here, the goal is to harden your environment against
    potential attacks by controlling access and isolating resources. For example,
    you can use IAM policies to tightly manage who is allowed to launch or modify
    infrastructure components. Network access control lists (ACLs) add another layer
    by restricting traffic flow between subnets, helping to contain threats if one
    area is compromised. Additionally, defining IAM user groups with clear boundaries
    ensures that only authorized roles can perform sensitive operations.
  prefs: []
  type: TYPE_NORMAL
- en: Network and edge protection
  prefs: []
  type: TYPE_NORMAL
- en: You want to establish strong protection on the perimeter of the network. You
    can use Amazon VPC to create isolated environments for each phase of your AI pipeline.
    Add AWS WAF to block common exploits at the edge, and restrict access to public
    endpoints as much as possible.
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI Security Scoping Matrix
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Generative AI Security Scoping Matrix is a framework developed by AWS to
    help organizations in assessing and implementing security controls for their generative
    AI workloads. It categorizes AI implementations into five distinct scopes, each
    representing varying levels of control and responsibility over the AI models and
    associated data (see [Figure 9-2](#figure_nine_twodot_the_generative_ai_se)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/awsc_0902.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9-2\. The Generative AI security scoping matrix
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let’s look at each scope in more detail:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Scope 1: Consumer applications'
  prefs: []
  type: TYPE_NORMAL
- en: At this level, you’re using publicly available generative AI tools right out
    of the box—no customization, no backend access. These are tools like ChatGPT or
    other similar platforms that anyone can use by signing up or logging in. You’re
    operating entirely within the provider’s environment, with no visibility into
    how the model was trained or what data it used. All interactions happen through
    a user interface or an API, and you’re bound by the provider’s terms of service.
    A typical example would be an employee asking ChatGPT for creative ideas for a
    marketing campaign.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scope 2: Enterprise applications'
  prefs: []
  type: TYPE_NORMAL
- en: Here, you’re working with third-party software tailored for businesses, which
    includes embedded generative AI features. Unlike Scope 1, these tools often come
    with formal vendor relationships—contracts, support, and service-level agreements
    (SLAs). You might get more flexibility or configuration options, but the core
    AI model still lies firmly in the vendor’s control. A good example would be using
    a business-grade calendar app that leverages AI to draft meeting agendas based
    on your past patterns and inputs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scope 3: Pretrained models'
  prefs: []
  type: TYPE_NORMAL
- en: In Scope 3, you’re building your own applications using preexisting AI models,
    accessed via APIs. The model itself lives on a third-party platform, but you control
    how it fits into your application, what data you feed into it, and how it interacts
    with your business processes. For instance, you might create a customer service
    chatbot that connects to Anthropic’s Claude model via Amazon Bedrock, tailoring
    the responses based on your input data and application flow.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scope 4: Fine-tuned models'
  prefs: []
  type: TYPE_NORMAL
- en: In this scope you’re fine-tuning an FM with your own data to better fit your
    specific needs. This gives you more control and also adds more responsibility—you’re
    shaping how the model behaves based on your proprietary information. Let’s say
    your marketing team wants AI-generated content that reflects your brand voice.
    You could fine-tune an existing model with past campaigns, customer data, and
    tone guidelines to generate spot-on promotional material.
  prefs: []
  type: TYPE_NORMAL
- en: 'Scope 5: Self-trained models'
  prefs: []
  type: TYPE_NORMAL
- en: At the highest level of control, you’re building and training your own generative
    AI models from scratch. This means collecting the data, designing the architecture,
    running the training, and maintaining the whole system. You own everything—data,
    model, outcomes—and carry full responsibility for performance, ethics, and compliance.
    This scope suits organizations with highly specialized needs or strict regulatory
    environments. For example, a financial firm might develop its own FM trained exclusively
    on regulatory filings, internal reports, and market data to power licensed analytics
    services.
  prefs: []
  type: TYPE_NORMAL
- en: 'For each scope, AWS emphasizes five critical security disciplines:'
  prefs: []
  type: TYPE_NORMAL
- en: Governance and compliance
  prefs: []
  type: TYPE_NORMAL
- en: Establishing policies and procedures to manage risks and ensure adherence to
    regulations
  prefs: []
  type: TYPE_NORMAL
- en: Legal and privacy
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring compliance with legal requirements and protecting user data privacy
  prefs: []
  type: TYPE_NORMAL
- en: Risk management
  prefs: []
  type: TYPE_NORMAL
- en: Identifying potential threats and implementing mitigation strategies
  prefs: []
  type: TYPE_NORMAL
- en: Controls
  prefs: []
  type: TYPE_NORMAL
- en: Applying security controls appropriate to the level of responsibility and risk
  prefs: []
  type: TYPE_NORMAL
- en: Resilience
  prefs: []
  type: TYPE_NORMAL
- en: Designing systems to maintain availability and recover from disruptions
  prefs: []
  type: TYPE_NORMAL
- en: Security for AI and Generative AI
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'From protecting infrastructure to guarding against input manipulation, the
    attack surface grows in new and sometimes unexpected ways when it comes to AI
    and generative AI. Let’s break down five essential areas that are critical for
    mitigating these threats:'
  prefs: []
  type: TYPE_NORMAL
- en: Threat detection
  prefs: []
  type: TYPE_NORMAL
- en: Threat detection in the context of AI means actively monitoring for signs that
    someone—or something—is trying to compromise your systems. Attackers might use
    generative AI to create fake content, tamper with data, or automate parts of a
    broader cyberattack. To keep up, you can deploy AI-powered tools that sift through
    network traffic, analyze user behavior, and watch for unusual patterns.
  prefs: []
  type: TYPE_NORMAL
- en: Vulnerability management
  prefs: []
  type: TYPE_NORMAL
- en: Every system has weak spots, and AI is no exception. Bugs in the code, flaws
    in the model, and exploitable entry points—like malware-laced files or phishing
    attachments—can all create risk. Managing these vulnerabilities means running
    regular security assessments, doing penetration testing (intentionally trying
    to break your own system), and performing detailed code reviews. Just as importantly,
    stay on top of patches and updates. Unpatched software is one of the easiest ways
    for attackers to breach a system.
  prefs: []
  type: TYPE_NORMAL
- en: Infrastructure protection
  prefs: []
  type: TYPE_NORMAL
- en: AI relies on cloud platforms, edge devices, databases, and other foundational
    components. If these pieces aren’t secure, your AI system isn’t either. Infrastructure
    protection involves setting strict access controls, isolating systems with network
    segmentation, and encrypting sensitive resources. You also want to design your
    infrastructure for resilience—so it can bounce back quickly from attacks, outages,
    or system failures without taking your AI offline.
  prefs: []
  type: TYPE_NORMAL
- en: Prompt injection resistance
  prefs: []
  type: TYPE_NORMAL
- en: Prompt injection is a newer type of threat, unique to generative AI. To defend
    against this, sanitize and validate all incoming prompts. You can also design
    models and training processes that are more resistant to this kind of manipulation—essentially
    teaching the system to ignore shady instructions.
  prefs: []
  type: TYPE_NORMAL
- en: Data encryption
  prefs: []
  type: TYPE_NORMAL
- en: Use strong encryption to protect data both when it’s stored (data at rest) and
    when it’s moving between systems (data in transit). Just as critical, manage your
    encryption keys with care. If attackers get access to them, the encryption becomes
    useless. Treat them like the keys to your entire operation—because in many ways,
    they are.
  prefs: []
  type: TYPE_NORMAL
- en: AWS security tools and services for AI workloads
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: AWS offers many security tools to help you protect AI systems at every layer—from
    data and infrastructure to identity and access. You’ve already seen how services
    like AWS Security Hub and Amazon GuardDuty can centralize and automate threat
    detection. Let’s look at a few more services that round out your AI security toolbox.
  prefs: []
  type: TYPE_NORMAL
- en: AWS Key Management Service
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You can choose between AWS-managed keys for ease of use or create and manage
    your own customer keys if you need tighter control. Either way, KMS ensures your
    data stays protected, whether it’s at rest or in motion.
  prefs: []
  type: TYPE_NORMAL
- en: AWS Shield Advanced
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: It includes tools like AWS WAF and AWS Firewall Manager to give you layered
    defense and centralized policy management.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Macie
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Amazon Macie uses machine learning to automatically identify and classify sensitive
    data across your AWS environment. It’s especially helpful for scanning S3 buckets
    to uncover PII, protected health information (PHI), or financial records. If you’re
    preparing training datasets for an AI model, Macie can flag data that needs to
    be removed or further secured. You can even extend this by exporting database
    contents to S3 and scanning that data as well.
  prefs: []
  type: TYPE_NORMAL
- en: Zero trust and fine-grained access controls
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To adopt a zero trust approach, AWS offers tools like Verified Access and Verified
    Permissions. These services allow you to implement granular access policies without
    relying on traditional VPNs. They help you enforce identity-based security in
    a way that’s scalable and efficient.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon SageMaker Role Manager
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If you’re using Amazon SageMaker, the Role Manager can help you create IAM roles
    tailored to different machine learning roles. It includes built-in personas—like
    data scientist, MLOps engineer, and SageMaker compute—that come with preconfigured
    permissions for common tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Network security and data flow control
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You can manage data ingress and egress at the network level with AWS Network
    Firewall and Amazon VPC policies. AWS Network Firewall supports deep packet inspection,
    letting you decrypt and inspect TLS traffic before it leaves or enters your environment.
    Amazon VPC gives you full control over your virtual networking environment, similar
    to managing your own on-premises data center. To avoid exposing internal traffic
    to the internet, AWS PrivateLink lets you connect your VPC privately to services
    like Amazon Bedrock (see [Table 9-1](#table_nine_onedot_summary_of_aws_securi)).
  prefs: []
  type: TYPE_NORMAL
- en: Table 9-1\. Summary of AWS security tools
  prefs: []
  type: TYPE_NORMAL
- en: '| AWS service | Key features | Use cases |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AWS Key Management Service (KMS) | Encryption at rest/in transit, AWS-managed
    or customer-managed keys | Protect sensitive AI training data, manage encryption
    policies for datasets |'
  prefs: []
  type: TYPE_TB
- en: '| AWS Shield Advanced | DDoS protection, integration with WAF and Network Firewall
    Manager, real-time attack mitigation | Defend AI applications exposed to the internet
    from DDoS disruptions |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon Macie | ML-powered sensitive data discovery, automatic classification
    (e.g., PII, PHI) | Scan S3 buckets for sensitive data before training AI models
    |'
  prefs: []
  type: TYPE_TB
- en: '| AWS Zero Trust (Verified Access/Permissions) | Identity-based access control,
    policy-based authorization without VPN | Enforce least-privilege access to AI
    model endpoints and dashboards |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon SageMaker Role Manager | Prebuilt IAM roles for ML personas, permission
    customization | Grant data scientists and MLOps engineers appropriate access within
    SageMaker environments |'
  prefs: []
  type: TYPE_TB
- en: '| AWS Network Firewall | Deep packet inspection, TLS decryption, threat prevention
    | Prevent data exfiltration or malicious traffic in AI model pipelines |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon VPC | Subnet isolation, route tables, security groups | Create secure
    AI compute environments with no public internet exposure |'
  prefs: []
  type: TYPE_TB
- en: '| AWS PrivateLink | Private, secure access to AWS services without exposing
    traffic to the internet | Privately connect to services like Amazon Bedrock for
    model inference and fine-tuning workflows |'
  prefs: []
  type: TYPE_TB
- en: Compliance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Compliance for AI is complex, as it must align with evolving legal, ethical,
    and technical expectations.
  prefs: []
  type: TYPE_NORMAL
- en: A first step is to create an AI governance board or committee. This group should
    include people from across the organization—not just technology and data science
    but also legal, risk, compliance, privacy, and even customer advocacy. You want
    a mix of people who understand both the technology and the potential impact of
    how it’s used.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say you’re building an AI model to screen job applicants. Your AI team
    might be focused on performance metrics, but HR and legal can help spot bias or
    fairness issues early on. Having them in the room from day one avoids headaches
    later.
  prefs: []
  type: TYPE_NORMAL
- en: Once the board is in place, define clear roles and responsibilities. Who’s reviewing
    models before deployment? Who owns the escalation path if an issue is flagged
    in production? Who sets policy around what kinds of data you can and can’t use?
  prefs: []
  type: TYPE_NORMAL
- en: 'Then move on to policies and procedures, such as with the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Data sourcing and privacy requirements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model training and evaluation standards
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment criteria and approval steps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ongoing monitoring for drift, misuse, or regulatory changes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compliance standards
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'AWS supports over 140 security standards and compliance certifications. True,
    it’s up to each customer to decide how much risk they’re willing to accept. But
    there are certain security frameworks that are especially relevant when you’re
    working with AI systems:'
  prefs: []
  type: TYPE_NORMAL
- en: National Institute of Standards and Technology (NIST)
  prefs: []
  type: TYPE_NORMAL
- en: The NIST 800-53 framework outlines a set of security controls used primarily
    by US federal agencies. Organizations following this standard go through formal
    assessments to confirm they’ve got the right protections in place for safeguarding
    sensitive information.
  prefs: []
  type: TYPE_NORMAL
- en: European Union Agency for Cybersecurity (ENISA)
  prefs: []
  type: TYPE_NORMAL
- en: ENISA plays a central role in shaping the EU’s approach to cybersecurity. It
    develops certification structures that build trust in digital services and infrastructure,
    and it works closely with EU member states to help prepare for evolving cyber
    threats.
  prefs: []
  type: TYPE_NORMAL
- en: International Organization for Standardization (ISO)
  prefs: []
  type: TYPE_NORMAL
- en: ISO security standards—especially those based on ISO/IEC 27002—provide a road
    map for managing security risks. They provide best practices and detailed controls
    for creating a strong information security management system (ISMS).
  prefs: []
  type: TYPE_NORMAL
- en: AWS System and Organization Controls (SOC)
  prefs: []
  type: TYPE_NORMAL
- en: SOC reports from AWS are third-party audits that verify how well AWS has implemented
    its compliance and security practices.
  prefs: []
  type: TYPE_NORMAL
- en: Health Insurance Portability and Accountability Act (HIPAA)
  prefs: []
  type: TYPE_NORMAL
- en: For healthcare organizations in the US, AWS supports HIPAA compliance by offering
    a secure environment for handling PHI. That includes everything from storing data
    to processing and transmitting it.
  prefs: []
  type: TYPE_NORMAL
- en: General Data Protection Regulation (GDPR)
  prefs: []
  type: TYPE_NORMAL
- en: The GDPR sets a high bar for data privacy in the European Union. It’s designed
    to protect personal information and gives EU residents more control over how their
    data is used.
  prefs: []
  type: TYPE_NORMAL
- en: Payment Card Industry Data Security Standard (PCI DSS)
  prefs: []
  type: TYPE_NORMAL
- en: PCI DSS is about protecting credit card data. Managed by the PCI Security Standards
    Council—a group formed by major credit card companies like Visa and Mastercard—it
    outlines the technical and operational requirements for keeping payment data safe.
  prefs: []
  type: TYPE_NORMAL
- en: Compliance is complicated, as it needs to align with legal, ethical, and technical
    expectations for how AI gets built, deployed, and used. And unlike traditional
    software, AI brings a few new wrinkles that complicate the picture.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some of the challenges for AI compliance:'
  prefs: []
  type: TYPE_NORMAL
- en: Complexity and lack of transparency
  prefs: []
  type: TYPE_NORMAL
- en: AI systems—especially LLMs and generative AI—often operate like black boxes.
    Their internal logic can be incredibly complex, and it’s not always clear how
    they generate a given output. That lack of explainability makes compliance audits
    harder.
  prefs: []
  type: TYPE_NORMAL
- en: Constant change
  prefs: []
  type: TYPE_NORMAL
- en: Many models evolve over time, learning from new data or adapting in production.
    That’s a problem for traditional compliance frameworks, which usually expect systems
    to behave consistently once they’re deployed.
  prefs: []
  type: TYPE_NORMAL
- en: Emergent capabilities
  prefs: []
  type: TYPE_NORMAL
- en: As AI systems grow more sophisticated, they can develop emergent capabilities—skills
    or behaviors the designers didn’t plan for. These aren’t bugs or features someone
    explicitly coded in. They’re by-products of how complex systems interact. That
    unpredictability means regulators and developers alike need to stay alert and
    flexible.
  prefs: []
  type: TYPE_NORMAL
- en: Accountability
  prefs: []
  type: TYPE_NORMAL
- en: AI systems need to be explainable, traceable, and subject to human review. Some
    governments are already moving in this direction. The EU’s Artificial Intelligence
    Act, for example, lays out requirements for transparency, risk assessments, and
    human oversight. In the US, cities like New York have passed laws requiring disclosure
    and review of automated decision-making tools.
  prefs: []
  type: TYPE_NORMAL
- en: Regulated workloads
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A regulated workload is one that must follow specific compliance rules—whether
    legal, industry-specific, or tied to safety and liability concerns. These requirements
    often apply in fields like healthcare, finance, or aerospace, where systems process
    sensitive data or impact high-stakes decisions. If your workload falls under standards
    like HIPAA, GDPR, PCI DSS, or FDA regulations, it’s clearly regulated.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, regulation doesn’t always look the same. It can show up in how you
    operate, what risks you manage, or how much oversight your system requires. A
    few examples include:'
  prefs: []
  type: TYPE_NORMAL
- en: Processes under oversight
  prefs: []
  type: TYPE_NORMAL
- en: Such as submitting reports to agencies like the FDA
  prefs: []
  type: TYPE_NORMAL
- en: Decisions with consequences
  prefs: []
  type: TYPE_NORMAL
- en: Like mortgage approvals or credit scoring, where fairness and transparency matter
  prefs: []
  type: TYPE_NORMAL
- en: Critical system usage
  prefs: []
  type: TYPE_NORMAL
- en: In areas where failure could risk lives, health, or infrastructure
  prefs: []
  type: TYPE_NORMAL
- en: Liability from AI models
  prefs: []
  type: TYPE_NORMAL
- en: Especially when a model’s output could lead to legal or financial repercussions
  prefs: []
  type: TYPE_NORMAL
- en: 'Some compliance expectations aren’t legally mandated but still demand attention.
    Frameworks like HIPAA set policies for how organizations govern data—not just
    how they store or transmit it. These standards may be enforced through audits,
    contractual obligations, or industry norms. Workloads that typically require close
    oversight include:'
  prefs: []
  type: TYPE_NORMAL
- en: HR systems handling confidential employee data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Safety systems where performance impacts human health or public safety
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compliance and inspection workflows used for audits or internal controls
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Not every workload comes with a legal label, so it helps to ask the right questions:'
  prefs: []
  type: TYPE_NORMAL
- en: Will this workload need to be audited?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Am I required to retain the data for a specific duration?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are the outputs considered official records or special data types?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Does this workload touch data with internal classification rules—even if not
    formally regulated?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you answered yes to any of these, treat your workload as regulated. It’s
    better to be cautious and compliant than caught off guard later.
  prefs: []
  type: TYPE_NORMAL
- en: AWS compliance tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Compliance tools in AWS are designed to help you meet regulatory, industry,
    and internal standards. These services streamline evidence collection, provide
    access to third-party audits, and identify vulnerabilities that may pose compliance
    risks.
  prefs: []
  type: TYPE_NORMAL
- en: AWS Audit Manager
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: AWS Audit Manager automates evidence collection for audits by continuously evaluating
    your AWS environment against prebuilt or custom control frameworks like SOC 2,
    GDPR, HIPAA, and ISO 27001\. It collects and maps data from AWS services, so you
    can generate audit-ready reports with less manual effort. This helps reduce the
    burden of preparing for audits and ensures your controls are functioning as intended.
  prefs: []
  type: TYPE_NORMAL
- en: AWS Artifact
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: AWS Artifact is a self-service portal for accessing AWS’s compliance reports
    and certifications. It includes documents like SOC 1/2/3 reports, ISO certifications,
    and PCI compliance documentation. AWS Artifact helps you understand how AWS complies
    with various standards, but you are still responsible for configuring and managing
    your environment to meet your own compliance obligations.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Inspector
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Amazon Inspector is a vulnerability management service that continuously scans
    your EC2 instances, Lambda functions, and container images for known security
    issues. It identifies software vulnerabilities and network exposures using real-world
    threat intelligence from sources like the National Vulnerability Database (NVD).
    Findings are prioritized based on severity. This allows for addressing high-risk
    issues first—an important step in maintaining compliance with standards that require
    regular vulnerability assessments.
  prefs: []
  type: TYPE_NORMAL
- en: AWS Trusted Advisor
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: AWS Trusted Advisor evaluates your AWS account against best practices for security,
    fault tolerance, performance, service limits, and cost optimization. From a compliance
    perspective, its security checks—such as exposed ports or overly permissive IAM
    policies—help organizations proactively identify and address risks that might
    otherwise lead to compliance violations (see [Table 9-2](#table_nine_twodot_summary_of_aws_servic)).
  prefs: []
  type: TYPE_NORMAL
- en: Table 9-2\. Summary of AWS services for compliance
  prefs: []
  type: TYPE_NORMAL
- en: '| AWS service | Key features | Use cases |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AWS Audit Manager | Automated evidence collection, continuous assessment,
    prebuilt/custom control frameworks | Generate audit-ready reports for SOC 2, HIPAA,
    or ISO 27001 with reduced manual effort |'
  prefs: []
  type: TYPE_TB
- en: '| AWS Artifact | Self-service access to AWS compliance reports and certifications
    | Download AWS’s PCI DSS, ISO, and SOC reports for use in your own compliance
    documentation efforts |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon Inspector | Continuous vulnerability scanning, real-time threat intelligence
    integration | Detect and prioritize EC2 or container vulnerabilities for HIPAA,
    PCI DSS, or ISO 27001 compliance |'
  prefs: []
  type: TYPE_TB
- en: '| AWS Trusted Advisor | Best practice checks including security and access
    risks | Identify overly permissive IAM roles or open ports that could violate
    compliance policies |'
  prefs: []
  type: TYPE_TB
- en: Governance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Effective AI requires strong governance. Let’s explore what that entails in
    the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: Data governance concepts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data governance is a specialized domain within that broader governance umbrella.
    It focuses specifically on how data is collected, stored, accessed, protected,
    and used. It involves policies, standards, roles, and tools to ensure data quality,
    integrity, security, and privacy.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon highlights six essential data management concepts that play a critical
    role in the development, deployment, and ongoing health of AI systems (see [Figure 9-3](#figure_nine_threedot_data_management_co)).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/awsc_0903.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9-3\. Data management concepts
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let’s look at each of them:'
  prefs: []
  type: TYPE_NORMAL
- en: Data lifecycles
  prefs: []
  type: TYPE_NORMAL
- en: The concept of a data lifecycle describes the journey data takes from the moment
    it’s created to the point it’s archived or deleted. For AI workloads, this includes
    everything from raw data collection to how that data is processed, stored, used
    in training and inference, and ultimately retired.
  prefs: []
  type: TYPE_NORMAL
- en: Each phase needs careful planning. For instance, if you collect data without
    clear labeling during the initial stage, you could face serious problems when
    it comes time to train your models. On the flip side, failing to archive or properly
    dispose outdated data can introduce compliance risks or inflate storage costs.
  prefs: []
  type: TYPE_NORMAL
- en: Data logging
  prefs: []
  type: TYPE_NORMAL
- en: Data logging is about keeping a detailed record of what your AI system is doing
    with its data. This includes capturing input and output data, model performance
    metrics, and key system events. This helps you debug issues, monitor ongoing performance,
    and trace problems when something unexpected happens.
  prefs: []
  type: TYPE_NORMAL
- en: Data logging is a powerful tool for transparency and accountability. When you’re
    trying to understand why a model made a certain prediction—or why it suddenly
    started underperforming—logs can often tell the full story.
  prefs: []
  type: TYPE_NORMAL
- en: Data residency
  prefs: []
  type: TYPE_NORMAL
- en: Data residency refers to where your data physically resides and where it gets
    processed. Some countries require that data about their citizens stay within their
    borders—a concept known as data sovereignty.
  prefs: []
  type: TYPE_NORMAL
- en: From an AI perspective, data residency decisions also affect performance. Keeping
    your training data close to the compute resources doing the heavy lifting can
    reduce latency and lower costs. But the main takeaway here is that you need to
    know where your data is and why it’s there, particularly if you’re working across
    multiple regions or cloud providers.
  prefs: []
  type: TYPE_NORMAL
- en: Data monitoring
  prefs: []
  type: TYPE_NORMAL
- en: Data monitoring is the practice of continuously monitoring the quality, consistency,
    and relevance of your data. Over time, real-world data changes, and your models
    can become less effective.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring helps catch issues like anomalies, low-quality data, or changes in
    distribution before they lead to performance problems. For teams managing production
    AI systems, this kind of oversight is crucial for preventing silent model failures
    and maintaining trust in the system’s outputs.
  prefs: []
  type: TYPE_NORMAL
- en: Data analysis
  prefs: []
  type: TYPE_NORMAL
- en: Data analysis involves analyzing your datasets to understand their structure,
    detect patterns, and uncover insights that can shape how you train and evaluate
    models. This usually includes methods like statistical summaries, data visualization,
    and exploratory data analysis (EDA).
  prefs: []
  type: TYPE_NORMAL
- en: Without proper analysis, you risk feeding your models data that’s incomplete,
    biased, or irrelevant. Solid analysis not only improves model design and feature
    engineering but also helps identify gaps in your dataset that could lead to blind
    spots in the model’s predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Data retention
  prefs: []
  type: TYPE_NORMAL
- en: Data retention is about deciding how long to keep your data—and why. In AI,
    retention policies can serve several purposes, such as meeting legal or industry
    regulations, preserving historical data for retraining, or managing the cost of
    cloud storage.
  prefs: []
  type: TYPE_NORMAL
- en: It’s a balancing act. Keeping data for too long can increase risks around privacy
    and compliance, while discarding it too quickly might eliminate valuable context
    needed to improve models over time.
  prefs: []
  type: TYPE_NORMAL
- en: AWS governance tools and services
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Governance in AWS focuses on managing resources at scale, enforcing organizational
    policies, and ensuring consistent configurations across multiple accounts and
    teams. These tools help organizations maintain control, standardize environments,
    and align cloud usage with business and regulatory requirements.
  prefs: []
  type: TYPE_NORMAL
- en: AWS Organizations and service control policies (SCPs)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: AWS Organizations enables centralized management of multiple AWS accounts, allowing
    you to group accounts, apply policies, and manage billing from a single location.
    Service control policies (SCPs) act as permission guardrails, defining what actions
    can or cannot be performed within specific accounts or organizational units—regardless
    of individual IAM permissions. This helps prevent accidental or unauthorized use
    of sensitive services or configurations across your environment.
  prefs: []
  type: TYPE_NORMAL
- en: AWS Control Tower
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: AWS Control Tower provides a way to set up and govern a secure, multiaccount
    AWS environment, also known as a *landing zone*. It automates account creation,
    configures guardrails, and sets up logging and security baselines. With Control
    Tower, enterprises can maintain consistent policies while enabling development
    teams to move quickly within defined boundaries.
  prefs: []
  type: TYPE_NORMAL
- en: AWS Config
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: AWS Config tracks and records configuration changes to your AWS resources. This
    allows you to assess compliance with desired states over time. It provides a detailed
    history of resource configurations and relationships, helping with troubleshooting,
    audit readiness, and policy enforcement. You can also define Config rules to automatically
    detect noncompliant resources and trigger remediations.
  prefs: []
  type: TYPE_NORMAL
- en: AWS CloudTrail
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: While often categorized as a security and audit tool, CloudTrail also plays
    a governance role by logging every API call across your AWS accounts. It enables
    visibility into user and service activity, supports compliance investigations,
    and can trigger alerts based on specific actions. CloudTrail logs are critical
    for maintaining accountability and enforcing governance across distributed teams
    (see [Table 9-3](#table_nine_threedot_summary_of_aws_serv)).
  prefs: []
  type: TYPE_NORMAL
- en: Table 9-3\. Summary of AWS services for governance
  prefs: []
  type: TYPE_NORMAL
- en: '| AWS service | Key features | Use cases |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AWS Organizations and SCPs | Centralized account management, hierarchical
    structure, policy enforcement | Restrict use of certain services/org units regardless
    of IAM permissions |'
  prefs: []
  type: TYPE_TB
- en: '| AWS Control Tower | Automates setup of multiaccount environments, applies
    guardrails, baseline configuration | Establish secure landing zones with predefined
    governance policies |'
  prefs: []
  type: TYPE_TB
- en: '| AWS Config | Tracks configuration changes, resource relationships, compliance
    auditing | Identify and remediate noncompliant resources automatically |'
  prefs: []
  type: TYPE_TB
- en: '| AWS CloudTrail | Logs API activity across AWS accounts, enables user/service
    activity monitoring | Investigate actions, support audits, and enforce accountability
    |'
  prefs: []
  type: TYPE_TB
- en: Understanding data and model lineage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data and model lineage refers to the complete history of where your data and
    models come from, how they’ve changed over time, and what processes shaped them.
    In AI—and especially in generative AI—keeping track of this lineage is critical.
    It gives you a clear picture of your system’s origins, its reliability, and any
    potential biases baked into your data or models.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding data and model lineage in AWS touches all three categories—compliance,
    security, and governance—but it aligns most directly with governance, with strong
    ties to compliance.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will look at the key components of data and model lineage.
  prefs: []
  type: TYPE_NORMAL
- en: Source citation and data origins documentation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Source citation and data origins documentation is key for building trustworthy
    AI. They’re the practices that help make your system transparent, traceable, and
    accountable. Here’s a closer look at what each one involves:'
  prefs: []
  type: TYPE_NORMAL
- en: Source citation
  prefs: []
  type: TYPE_NORMAL
- en: In generative AI, source citation means properly acknowledging where your training
    data comes from. Whether you’re pulling from datasets, databases, or other resources,
    it’s important to document every source clearly. You’ll also want to capture any
    licenses, permissions, or terms of use tied to the data.
  prefs: []
  type: TYPE_NORMAL
- en: Documenting data origins
  prefs: []
  type: TYPE_NORMAL
- en: 'Documenting data origins goes deeper. It’s about recording every detail about
    how the training data was collected, curated, cleaned, and transformed. Here’s
    what you should document:'
  prefs: []
  type: TYPE_NORMAL
- en: How and where the data was collected
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How the data was cleaned and curated
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any preprocessing steps or transformations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By doing this, you surface any hidden biases, limitations, or quality issues
    early on. That insight can make or break the reliability of your model down the
    line.
  prefs: []
  type: TYPE_NORMAL
- en: Data lineage
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'When done right, data lineage makes your source citations and origin documentation
    much easier. We will look at some of the main approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: Cataloging
  prefs: []
  type: TYPE_NORMAL
- en: 'Cataloging organizes your datasets, models, and resources systematically. Think
    of it as building a library for your AI system: every piece of data, every model,
    and every license has a “book” with all its details inside.'
  prefs: []
  type: TYPE_NORMAL
- en: A well-kept catalog improves how you manage, communicate, and audit your data
    and model lineage—whether internally or with outside stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: Model cards
  prefs: []
  type: TYPE_NORMAL
- en: 'Model cards offer a standardized way to document your machine learning models.
    In generative AI, a good model card tells the full story of:'
  prefs: []
  type: TYPE_NORMAL
- en: What data the model used
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where that data came from
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any licenses or terms tied to the data
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Known biases, risks, or quality issues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Beyond data origins, model cards also describe the model’s intended use, performance
    benchmarks, and limitations. They help you set the right expectations with users,
    support audits, and align your models with business goals.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re using Amazon SageMaker, SageMaker Model Cards can make this process
    even smoother by offering a centralized space for all your model details.
  prefs: []
  type: TYPE_NORMAL
- en: Review of data usage in generative AI
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Effective data governance starts with understanding the different types of
    data used in generative AI and who controls them. Most generative AI applications
    rely on three key categories: user data, fine-tuning data, and training data.
    Each plays a distinct role in shaping how the model performs—and each comes with
    different governance implications.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a closer look at each type of data and how it’s typically governed.
  prefs: []
  type: TYPE_NORMAL
- en: User data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: User data includes anything the customer or end user provides—inputs, prompts,
    requirements—basically, whatever the user sends into the system to generate a
    specific output.
  prefs: []
  type: TYPE_NORMAL
- en: No matter the application scope, the customer always controls their own user
    data. This is an important constant you can count on.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tuning data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Fine-tuning data is used to adapt a pretrained generative AI model to meet the
    specific needs of a customer or a particular domain.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s how fine-tuning data typically works:'
  prefs: []
  type: TYPE_NORMAL
- en: It’s often a subset of the original training data or new data collected specifically
    from the application’s domain.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fine-tuning tweaks the model’s internal settings—its parameters and weights—so
    it produces more relevant and personalized results for the task at hand.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Control of the fine-tuning data depends on the application scope:'
  prefs: []
  type: TYPE_NORMAL
- en: In Scopes 1 and 2, the application provider controls the fine-tuning data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In Scope 4, the customer controls the fine-tuning data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Knowing who controls what is critical for both governance and compliance, so
    it’s worth keeping this breakdown top of mind.
  prefs: []
  type: TYPE_NORMAL
- en: Training data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Training data is the large, diverse dataset used to build the model’s initial
    knowledge and core capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s what you need to know about training data:'
  prefs: []
  type: TYPE_NORMAL
- en: It often includes a wide range of content—text, images, audio—depending on what
    the model is designed to do.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This data teaches the model the patterns, structures, and relationships it needs
    to generate new, meaningful outputs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'When it comes to ownership:'
  prefs: []
  type: TYPE_NORMAL
- en: In Scopes 1, 2, 3, and 4, the application provider controls the training data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In Scope 5, the customer controls the training data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The control plays a big role in how governance, security, and customization
    are handled across different generative AI projects.
  prefs: []
  type: TYPE_NORMAL
- en: Secure data engineering
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Strong secure data engineering practices are key to safe, reliable AI and generative
    AI systems. Let’s dive into the key areas you need to focus on.
  prefs: []
  type: TYPE_NORMAL
- en: Assessing data quality
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Assessing data quality starts with setting clear metrics. You’ll want to define
    standards for completeness, ensuring your training data covers a broad and representative
    range of scenarios without major gaps or biases. Accuracy is equally important;
    the data must be correct, up to date, and reflect real-world situations the model
    will face. Timeliness, sometimes called *currency*, measures how current your
    data is—outdated data can quickly erode a model’s performance. Finally, consistency
    ensures the data remains coherent and logically sound throughout development and
    deployment. To enforce these standards, integrate validation checks at multiple
    stages of your data pipeline, perform regular data profiling, and monitor quality
    issues as they arise. It’s also crucial to maintain a feedback loop for continuous
    improvement and document detailed data lineage and metadata to keep track of your
    data’s journey and transformations.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing privacy-enhancing technologies
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Protecting user and training data requires implementing privacy-enhancing technologies.
    Start with techniques like data masking, data obfuscation, or differential privacy,
    which help reduce the risk of exposing sensitive information even if a breach
    occurs. Strengthen your defenses further by using encryption, tokenization, and
    secure multi-party computation to safeguard data while it’s being processed or
    stored. These approaches work together to ensure that your data remains protected
    without sacrificing performance or usability.
  prefs: []
  type: TYPE_NORMAL
- en: Data access control
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Controlling who can access your data—and under what circumstances—is fundamental
    for maintaining security. Establish a strong data governance framework with well-defined
    policies that govern access, use, and sharing. Implement role-based access controls
    and assign fine-grained permissions so that users only have access to what they
    truly need. Strengthen these controls by using authentication and authorization
    systems like single sign-on (SSO), multi-factor authentication (MFA), and IAM
    solutions. Keep a close eye on your system by monitoring and logging all data
    access activities to catch unauthorized use early. Regularly review and update
    permissions to align with the principle of least privilege, ensuring minimum necessary
    access for each role.
  prefs: []
  type: TYPE_NORMAL
- en: Data integrity
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Maintaining data integrity ensures your AI models are built on solid, trustworthy
    foundations. Implement validation and integrity checks throughout your data pipeline,
    such as schema validation, referential integrity checks, and business rule validations,
    to catch errors before they cause bigger issues. Always have a robust backup and
    recovery strategy in place so you can quickly restore data after system failures,
    mistakes, or disasters. Use transaction management and atomicity principles to
    keep data consistent and reliable during processing and transformation. Document
    your data’s full history by maintaining detailed data lineage and audit trails,
    which allow you to track every change. Finally, make a habit of regularly monitoring
    and testing your data integrity controls, adjusting them as needed to stay resilient
    against evolving risks.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Securing AI systems is a necessity. As organizations build more sophisticated
    models and adopt generative AI technologies, the stakes keep rising. Security,
    compliance, and governance must work hand in hand to protect sensitive data, ensure
    ethical practices, and meet growing regulatory demands. By taking a layered approach
    to defense, setting clear governance frameworks, and implementing strong data
    management practices, companies not only can reduce risks but also strengthen
    the trust of customers, partners, and regulators. In the end, building responsible
    AI isn’t just about avoiding problems—it’s about creating solutions that are resilient,
    transparent, and ready for the future.
  prefs: []
  type: TYPE_NORMAL
- en: Quiz
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To check your answers, please refer to the [“Chapter 9 Answer Key”](app02.html#answers_ch_9).
  prefs: []
  type: TYPE_NORMAL
- en: What is a key difference between governance and compliance?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Governance enforces laws, while compliance manages innovation.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Governance protects data, while compliance ensures ethical AI development.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Governance guides decision making and risk management, while compliance ensures
    adherence to external and internal rules.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Governance is optional, but compliance is legally mandatory for all companies.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: In AWS, what best describes the purpose of a defense-in-depth strategy?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To rely on a single strong security control.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To use multiple, layered security measures to catch threats that bypass one
    control.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To automate model training and inference pipelines.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To combine multiple security layers so if one fails, others can provide protection.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which AWS services would you primarily use to protect applications against denial-of-service
    (DoS) attacks and manage secure user sign-ins?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon GuardDuty and AWS Private CA
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Key Management Service (KMS) and AWS Certificate Manager (ACM)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Shield and Amazon Cognito
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon Virtual Private Cloud (VPC) and AWS WAF
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which AWS service helps route sensitive traffic privately without exposing it
    to the public internet?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS PrivateLink
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: AWS Security Hub
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon VPC
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Amazon GuardDuty
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following is an example of a governance policy for AI solutions?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Building AI models without any human review
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Using only public datasets without checking privacy concerns
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Defining standards for data sourcing, model training, evaluation, and deployment
    approvals
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Allowing unrestricted model deployment to speed innovation
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which AWS-supported compliance framework is specifically focused on protecting
    United States healthcare information?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Payment Card Industry Data Security Standard (PCI DSS)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Health Insurance Portability and Accountability Act (HIPAA)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: General Data Protection Regulation (GDPR)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: European Union Agency for Cybersecurity (ENISA)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: ^([1](ch09.html#ch01fn29-marker)) Bianca Chan, [“Wall Street Is Worried It Can’t
    Keep Up with AI-Powered Cybercriminals”](https://oreil.ly/KxT8C), *Business Insider*,
    March 11, 2025.
  prefs: []
  type: TYPE_NORMAL
- en: '^([2](ch09.html#ch01fn30-marker)) Shailendra Upadhyay, [“Information Security
    Spending: What Does the Future Hold?”](https://oreil.ly/bpJ46), Gartner, November
    27, 2024.'
  prefs: []
  type: TYPE_NORMAL
