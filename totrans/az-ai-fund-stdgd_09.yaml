- en: Chapter 9\. Strategies and Techniques for Successfully Taking the AI-900 Exam
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We’ve covered a lot of AI and Microsoft Azure topics in this book—and yes, it
    can feel like a bit much. So, to prepare for the AI-900 exam, you’re going to
    need to dig in and put in some serious study time. Just how much time depends
    on your experience level. If you’re new to the topics, setting aside around 15–20
    hours is a solid target. But if you’ve already got a handle on the basics, you
    might be looking at closer to 5–10 hours of study time.
  prefs: []
  type: TYPE_NORMAL
- en: We have included a practice exam that can help you get a sense of whether you’re
    ready to take the exam. It’s also a great idea to review the glossary at the end
    of this book because many exam questions focus on definitions of AI and Azure
    terms.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter first will dive into some useful strategies for approaching the
    exam. Then, we’ll break down the key topics by category, giving you a summary
    to focus on as you prep.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the Exam Experience
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Microsoft has a [sandbox](https://oreil.ly/QqH3I) that shows the exam experience.
    It’s important to check it out so as to get a sense of what to expect. [Figure 9-1](#i09_chapter9_figure_1_1742068263972753)
    shows what it looks like.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/aaif_0901.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9-1\. The sandbox for the exam experience
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: On the left, you’ll find options to take a break, change up the color scheme,
    or get help if you need it. At the top of the screen, a progress bar shows how
    many questions you’ve already chosen. You’ll also see a timer to keep track. Each
    question will appear in the center screen as you go. If you’d like to revisit
    a question later, select “Review later.” You can also leave feedback about any
    issues or suggestions you have regarding the exam.
  prefs: []
  type: TYPE_NORMAL
- en: Manage Your Time
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When it comes to managing your time during the AI-900 exam, it’s all about pacing
    yourself and staying focused. You’ll have 45 minutes to tackle somewhere between
    40 and 60 questions, giving you roughly one minute per question.
  prefs: []
  type: TYPE_NORMAL
- en: Start with the questions you know—those easy wins will give you confidence and
    help you keep momentum. If a question stumps you, don’t waste precious time. Just
    mark it for review and come back later. Making a first pass to answer what you
    know will free up time to dig into the more challenging questions during the second
    pass.
  prefs: []
  type: TYPE_NORMAL
- en: Read Questions Carefully
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Carefully reading each question might seem like obvious advice, but it can genuinely
    make a big difference in your exam performance. Exam questions often contain specific
    keywords like *not*, *except*, or *only*, which can completely change the intended
    answer. These tiny words are easy to overlook in a rush, and missing them could
    send you down the wrong path. For example, a question that asks, “Which of the
    following is not a benefit of using Azure AI?” requires an entirely different
    thought process than one asking for a straightforward list of benefits. Missing
    that one *not* could mean selecting the exact opposite answer of what’s required.
  prefs: []
  type: TYPE_NORMAL
- en: Taking a few extra seconds to read the question carefully helps you fully understand
    what’s being asked. This clarity means you’re more likely to select the correct
    answer on your first attempt, which in turn reduces the need to go back and double-check
    or change answers later.
  prefs: []
  type: TYPE_NORMAL
- en: Use the Process of Elimination
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you’re faced with multiple-choice questions, especially those where you’re
    uncertain about the answer, start by removing any options that are clearly incorrect
    or don’t make sense. Crossing off these outliers will narrow your choices, making
    it much easier to focus on what’s left. This is particularly useful when the answer
    isn’t immediately obvious because it allows you to home in on the most plausible
    options instead of wasting time debating all of them.
  prefs: []
  type: TYPE_NORMAL
- en: Eliminating wrong answers also increases your chances of guessing correctly
    if you’re still unsure after narrowing down. For example, in a question with four
    choices, removing just one incorrect answer boosts your odds from 25% to 33% if
    you’re left to make an educated guess. Remove two, and you’ve got a 50/50 shot.
    It’s a simple technique, but it can be a lifesaver when you’re dealing with those
    last few tricky questions. Additionally, by focusing on fewer options, you reduce
    mental strain, helping you conserve energy for the rest of the exam. This approach
    not only streamlines your decision-making process but also keeps you moving forward
    with confidence and efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: Stay Calm and Double-Check Your Answers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Staying calm throughout the exam is essential. It’s easy to feel overwhelmed,
    especially if you hit a tough question or notice time slipping away faster than
    expected. When that happens, it’s natural to feel a surge of stress, but letting
    that stress take over can lead to rushed decisions and mistakes. Instead, take
    a moment to breathe deeply and refocus. A few deep breaths can slow your racing
    thoughts, which can help you regain control and bring a sense of calm back to
    your mindset. This pause may seem minor, but it can make a huge difference in
    your ability to think clearly and stay efficient as you work through each question.
  prefs: []
  type: TYPE_NORMAL
- en: If you manage your time well and finish with a few minutes left, use those final
    moments to review your answers. Go back to any questions you marked for review,
    especially if they were ones that you found tricky or that you rushed through
    initially. These last few minutes can be incredibly valuable. They can allow you
    to spot any small mistakes or second-guess moments. Often, a fresh look at a question
    can bring new clarity and help you make a more confident choice. Even minor corrections
    can boost your score, so taking advantage of any extra time to double-check your
    work is a smart move.
  prefs: []
  type: TYPE_NORMAL
- en: Key Concepts to Review
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the next few sections, we’ll take a look at the main sections of the exam
    and the key concepts to focus on. These concepts are in line with the main topics
    from the AI-900 study guide: responsible AI, ML, computer vision, NLP, and generative
    AI.'
  prefs: []
  type: TYPE_NORMAL
- en: AI Fundamentals and Responsible AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Ethics is a key part of the exam. This is why it’s a good idea to memorize
    the six core principles of responsible AI: fairness, reliability and safety, privacy
    and security, inclusiveness, transparency, and accountability. We covered these
    in [Chapter 3](ch03.html#i03_chapter3_overview_of_ai_workloads_and_key_use_cases_1742068261133633).'
  prefs: []
  type: TYPE_NORMAL
- en: When a question pops up, try to match it with one of these principles. For instance,
    if the question mentions “making systems understandable to users,” think transparency.
    If it’s about “avoiding bias based on gender or ethnicity,” you’re looking at
    fairness.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pay extra attention to scenario-based questions. They often throw real-world
    business examples at you and ask which principle is most relevant. Here’s a tip:
    watch for keywords. “Bias” points to fairness, “understanding how it works” signals
    transparency, “security of personal data” means privacy and security, and “governance
    framework” usually leads to accountability. Sometimes, it may seem like a scenario
    touches on more than one principle, but focus on finding the main one.'
  prefs: []
  type: TYPE_NORMAL
- en: Another big area is AI workloads and knowing when to use each type. Expect questions
    where you need to connect a business problem to the right AI solution. For example,
    if it’s about making large amounts of data searchable, think knowledge mining.
    Interactive conversations? Go with conversational AI. The trick is knowing not
    just what a service does but also what problem it actually solves.
  prefs: []
  type: TYPE_NORMAL
- en: 'AI governance and implementation also come up a lot. Think in order: first,
    identify potential harms, then measure them, and finally, mitigate them. You might
    also get questions about specific Microsoft policies, such as why Microsoft has
    retired facial recognition features for certain purposes, such as to detect emotions,
    gender, and age.'
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you’re diving into ML and data science questions, it’s key to get the basics
    down—especially the difference between supervised and unsupervised learning. You’ll
    see this distinction pop up in practical scenarios. In supervised learning, watch
    for clues like “labeled data” or historical data with known outcomes. For instance,
    if a question is about predicting house prices based on previous sales, it’s a
    supervised learning case. Specifically, it’s regression, because house prices
    are continuous numbers. On the flip side, if it’s about grouping customers or
    spotting patterns with no labeled outcomes, think unsupervised learning, usually
    clustering.
  prefs: []
  type: TYPE_NORMAL
- en: It’s also crucial to know the terms used in model training, especially *features*
    versus *labels*. When a question involves predictions, immediately zero in on
    which variables are your features (inputs) and which is your label (what you’re
    trying to predict). For example, when predicting customer churn, demographics
    and purchase history are features while churn status is the label.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you’re tackling Azure Machine Learning and AutoML questions, remember the
    workflow sequence: create a workspace first, prepare your data, split it into
    training and validation sets, and then train the model. Pay attention to evaluation
    metrics, too, such as *R*² for regression models and accuracy for classification
    models. The exam often asks about which metrics suit different models. Also, watch
    for overfitting (good performance on training data, but poor performance on validation
    data) and underfitting (poor performance on both).'
  prefs: []
  type: TYPE_NORMAL
- en: 'With Azure Machine Learning Designer, think in terms of pipelines. You create
    the pipeline first, add datasets next, and then add training modules. The order
    matters, so don’t get tricked by questions that suggest skipping steps. Also,
    know the difference between training and inference pipelines: training pipelines
    are for building the model, and inference pipelines are for deploying it.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, practice spotting the right algorithm for different business problems.
    If the question is about predicting numbers (like sales or temperature), think
    regression. For sorting items into categories (like spam detection or image classification),
    that’s classification.
  prefs: []
  type: TYPE_NORMAL
- en: Computer Vision
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you’re dealing with computer vision questions, understanding the different
    image analysis tasks is key. The test often checks if you can tell the difference
    between image classification (figuring out what’s in an image), object detection
    (finding multiple objects and marking them with boxes), and semantic segmentation
    (labeling each pixel by category). When a scenario question mentions “identifying
    multiple objects in an image with their locations,” think object detection. If
    it’s about “categorizing the main subject of an image,” that’s image classification.
  prefs: []
  type: TYPE_NORMAL
- en: Azure AI Vision services come with prebuilt models that you’ll need to be familiar
    with. For instance, some models are specialized for specific tasks, such as recognizing
    celebrities and landmarks. The test often asks about what’s supported (like OCR)
    and what’s not (like emotion detection, which was retired because of ethical concerns).
    Watch for questions about output formats, too—for instance, image analysis returns
    confidence scores for each feature, while object detection gives bounding boxes
    and labels.
  prefs: []
  type: TYPE_NORMAL
- en: For OCR, you’ll want to know both what it can do and its limits. OCR is for
    reading text, so understand the difference between recognizing printed text versus
    handwriting and remember use cases like digitizing medical records or pulling
    text from documents. The exam may give scenarios to check if OCR is the right
    tool. Keep in mind that OCR is for text extraction only, not for broader image
    analysis or facial detection. What’s more, OCR can be used alongside other services
    like translation for document processing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Facial detection and recognition questions are a bit more nuanced now, thanks
    to Microsoft’s ethical AI principles. Be clear about what the Azure AI Face Service
    does: detecting faces, verifying identity, and redacting faces, but no longer
    recognizing emotions. The test may check your knowledge of these ethical limitations.
    Also, know the difference between facial detection (finding faces in an image)
    and facial verification (confirming identity), as they’re used in different situations.'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, DALL-E models can create images from text prompts, edit images, or
    make variations of existing images. When these questions come up, know what DALL-E
    can and can’t do. For example, DALL-E can generate images based on descriptions
    but doesn’t handle tasks like image classification or facial recognition.
  prefs: []
  type: TYPE_NORMAL
- en: Natural Language Processing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When you’re getting into Azure’s NLP services, the first step is to know which
    service handles which task. Start by identifying the main goal: are you trying
    to understand meaning (language understanding), pull out specific details (key
    phrase extraction), gauge emotions (sentiment analysis), or translate languages?
    For instance, if the question is about analyzing customer reviews for positive
    or negative feelings, you’re looking at sentiment analysis. If it’s about finding
    main topics in a document, that’s key phrase extraction.'
  prefs: []
  type: TYPE_NORMAL
- en: For Azure AI Language services, it’s about knowing what each feature can—and
    can’t—do. Pay close attention to the difference between similar features. Named
    entity recognition (NER), for example, identifies types of words (like people
    or places), while entity linking takes it a step further by connecting those words
    to a knowledge base. Sometimes, a scenario may seem to fit multiple services,
    but your job is to pick the best one. Also remember that specific features, such
    as language detection, give outputs like ISO codes and confidence scores, which
    can help you eliminate wrong answers.
  prefs: []
  type: TYPE_NORMAL
- en: 'When it comes to translation, make sure you understand the difference between
    the translation services. Azure AI Translator does text-to-text translation while
    Azure AI Speech handles speech-to-text and text-to-speech. For document-translation
    questions, know whether you’re dealing with a single file (synchronous) or multiple
    files (asynchronous). The exam often asks which service to pick based on details
    like file volume or whether real-time translation is needed. Also remember Azure
    AI Custom Translator: it’s tailored for specific industry jargon and domain-specific
    terms.'
  prefs: []
  type: TYPE_NORMAL
- en: For language models, especially Azure OpenAI, know the types of models and what
    they’re good at. GPT models are great for understanding and generating natural
    language while embedding models are built for comparing and analyzing text similarity.
    Watch for questions on system messages and prompt engineering. Also be ready for
    questions about responsible AI with language models, covering areas like content
    filtering and safety.
  prefs: []
  type: TYPE_NORMAL
- en: With speech-related questions, focus on both the technical abilities and the
    real-world uses of Azure AI Speech services. Get familiar with the differences
    between speech-to-text, text-to-speech, and speech translation. Certain features,
    such as speaker recognition, language identification, and voice assistants, are
    worth remembering.
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you’re handling questions about generative AI and LLMs, it’s crucial to
    know what each model family is best at. GPT models are built for generating and
    understanding text and code while DALL-E is for creating images. The test often
    checks if you can pick the right model for the task. For example, a question that
    involves generating Python code or filling in code snippets is GPT territory,
    not DALL-E.
  prefs: []
  type: TYPE_NORMAL
- en: For copilot-related questions, remember that copilots are AI assistants embedded
    in applications. Their main job is to bridge the gap between users and the AI
    models. This makes it easy for people to get help with everyday tasks using natural
    language. When you see these questions, think about how copilots boost productivity,
    such as by suggesting solutions, completing tasks, or offering context-sensitive
    help. The exam may ask if a copilot is the right choice for a business need, so
    remember that they’re more than just chatbots. They’re designed to understand
    context and give tailored assistance.
  prefs: []
  type: TYPE_NORMAL
- en: Prompt engineering has become a hot topic. Know the parts of effective prompting,
    especially system messages that set the context and limitations for a model’s
    responses. The exam might quiz you on how to steer model outputs effectively.
    For example, this can be using system messages to specify tone, format, or other
    constraints. Be ready for questions on different prompting techniques, and understand
    when each one is the right fit.
  prefs: []
  type: TYPE_NORMAL
- en: 'Questions about content safety and harm mitigation are all about responsible
    AI layers. Know the different layers that help prevent harm: the safety system
    layer for content filtering, the user experience layer for clear documentation,
    and the metaprompt and grounding layer for setting context.'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we’ve taken a look at the key strategies and techniques to
    use in order to take the AI-900 exam confidently. By focusing on time management,
    understanding key concepts, and employing practical test-taking strategies like
    process of elimination and careful reading, you’re better prepared to face the
    exam’s challenges. Each section—from AI fundamentals to ML, computer vision, NLP,
    and generative AI—provided targeted insights to help you identify the right solutions
    in real-world scenarios. Armed with these techniques and a solid grasp of Microsoft
    Azure’s AI capabilities, you’re well positioned to demonstrate your knowledge
    and succeed on the AI-900 exam.
  prefs: []
  type: TYPE_NORMAL
