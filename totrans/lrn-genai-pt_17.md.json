["```py\n<[SNote] time: 1.0325520833333333 type: note_on, value: 74, velocity: 86>\n<[SNote] time: 1.0442708333333333 type: note_on, value: 38, velocity: 77>\n<[SNote] time: 1.2265625 type: note_off, value: 74, velocity: None>\n<[SNote] time: 1.2395833333333333 type: note_on, value: 73, velocity: 69>\n<[SNote] time: 1.2408854166666665 type: note_on, value: 37, velocity: 64>\n```", "```py\n<Event type: time_shift, value: 99>, \n <Event type: time_shift, value: 2>, \n <Event type: velocity, value: 21>, \n <Event type: note_on, value: 74>, \n <Event type: time_shift, value: 0>, \n <Event type: velocity, value: 19>, \n <Event type: note_on, value: 38>, \n <Event type: time_shift, value: 17>, \n <Event type: note_off, value: 74>, \n <Event type: time_shift, value: 0>, \n <Event type: velocity, value: 17>, \n <Event type: note_on, value: 73>, \n <Event type: velocity, value: 16>, \n <Event type: note_on, value: 37>, \n <Event type: time_shift, value: 0>\n…\n```", "```py\n!pip install pretty_midi music21\n```", "```py\nimport os\n\nos.makedirs(\"files/maestro-v2.0.0/train\", exist_ok=True)\nos.makedirs(\"files/maestro-v2.0.0/val\", exist_ok=True)\nos.makedirs(\"files/maestro-v2.0.0/test\", exist_ok=True)\n```", "```py\nimport json\nimport pickle\nfrom utils.processor import encode_midi\n\nfile=\"files/maestro-v2.0.0/maestro-v2.0.0.json\"\n\nwith open(file,\"r\") as fb:\n    maestro_json=json.load(fb)                            ①\n\nfor x in maestro_json:                                    ②\n    mid=rf'files/maestro-v2.0.0/{x[\"midi_filename\"]}'\n    split_type = x[\"split\"]                               ③\n    f_name = mid.split(\"/\")[-1] + \".pickle\"\n    if(split_type == \"train\"):\n        o_file = rf'files/maestro-v2.0.0/train/{f_name}'\n    elif(split_type == \"validation\"):\n        o_file = rf'files/maestro-v2.0.0/val/{f_name}'\n    elif(split_type == \"test\"):\n        o_file = rf'files/maestro-v2.0.0/test/{f_name}'\n    prepped = encode_midi(mid)\n    with open(o_file,\"wb\") as f:\n        pickle.dump(prepped, f)\n```", "```py\ntrain_size=len(os.listdir('files/maestro-v2.0.0/train'))\nprint(f\"there are {train_size} files in the train set\")\nval_size=len(os.listdir('files/maestro-v2.0.0/val'))\nprint(f\"there are {val_size} files in the validation set\")\ntest_size=len(os.listdir('files/maestro-v2.0.0/test'))\nprint(f\"there are {test_size} files in the test set\")\n```", "```py\nthere are 967 files in the train set\nthere are 137 files in the validation set\nthere are 178 files in the test set\n```", "```py\nimport pickle\nfrom utils.processor import encode_midi\nimport pretty_midi\nfrom utils.processor import (_control_preprocess,\n    _note_preprocess,_divide_note,\n    _make_time_sift_events,_snote2events)\n\nfile='MIDI-Unprocessed_Chamber1_MID--AUDIO_07_R3_2018_wav--2'\nname=rf'files/maestro-v2.0.0/2018/{file}.midi'               ①\n\nevents=[]\nnotes=[]\nsong=pretty_midi.PrettyMIDI(name)\nfor inst in song.instruments:\n    inst_notes=inst.notes\n    ctrls=_control_preprocess([ctrl for ctrl in \n       inst.control_changes if ctrl.number == 64])\n    notes += _note_preprocess(ctrls, inst_notes)             ②\ndnotes = _divide_note(notes)                                 ③\ndnotes.sort(key=lambda x: x.time)    \nfor i in range(5):\n    print(dnotes[i])   \n```", "```py\n<[SNote] time: 1.0325520833333333 type: note_on, value: 74, velocity: 86>\n<[SNote] time: 1.0442708333333333 type: note_on, value: 38, velocity: 77>\n<[SNote] time: 1.2265625 type: note_off, value: 74, velocity: None>\n<[SNote] time: 1.2395833333333333 type: note_on, value: 73, velocity: 69>\n<[SNote] time: 1.2408854166666665 type: note_on, value: 37, velocity: 64>\n```", "```py\ncur_time = 0\ncur_vel = 0\nfor snote in dnotes:\n    events += _make_time_sift_events(prev_time=cur_time,    ①\n                                     post_time=snote.time)\n    events += _snote2events(snote=snote, prev_vel=cur_vel)  ②\n    cur_time = snote.time\n    cur_vel = snote.velocity    \nindexes=[e.to_int() for e in events]   \nfor i in range(15):                                         ③\n    print(events[i]) \n```", "```py\n<Event type: time_shift, value: 99>\n<Event type: time_shift, value: 2>\n<Event type: velocity, value: 21>\n<Event type: note_on, value: 74>\n<Event type: time_shift, value: 0>\n<Event type: velocity, value: 19>\n<Event type: note_on, value: 38>\n<Event type: time_shift, value: 17>\n<Event type: note_off, value: 74>\n<Event type: time_shift, value: 0>\n<Event type: velocity, value: 17>\n<Event type: note_on, value: 73>\n<Event type: velocity, value: 16>\n<Event type: note_on, value: 37>\n<Event type: time_shift, value: 0>\n```", "```py\nimport torch,os,pickle\n\nmax_seq=2048\ndef create_xys(folder):  \n    files=[os.path.join(folder,f) for f in os.listdir(folder)]\n    xys=[]\n    for f in files:\n        with open(f,\"rb\") as fb:\n            music=pickle.load(fb)\n        music=torch.LongTensor(music)      \n        x=torch.full((max_seq,),389, dtype=torch.long)\n        y=torch.full((max_seq,),389, dtype=torch.long)      ①\n        length=len(music)\n        if length<=max_seq:\n            print(length)\n            x[:length]=music                                ②\n            y[:length-1]=music[1:]                          ③\n            y[length-1]=388                                 ④\n        else:\n            x=music[:max_seq]\n            y=music[1:max_seq+1]   \n        xys.append((x,y))\n    return xys\n```", "```py\ntrainfolder='files/maestro-v2.0.0/train'\ntrain=create_xys(trainfolder)\n```", "```py\n15\n5\n1643\n1771\n586\n```", "```py\nvalfolder='files/maestro-v2.0.0/val'\ntestfolder='files/maestro-v2.0.0/test'\nprint(\"processing the validation set\")\nval=create_xys(valfolder)\nprint(\"processing the test set\")\ntest=create_xys(testfolder)\n```", "```py\nprocessing the validation set\nprocessing the test set\n1837\n```", "```py\nval1, _ = val[0]\nprint(val1.shape)\nprint(val1)\n```", "```py\ntorch.Size([2048])\ntensor([324, 366,  67,  ...,  60, 264, 369])\n```", "```py\nfrom utils.processor import decode_midi\n\nfile_path=\"files/val1.midi\"\ndecode_midi(val1.cpu().numpy(), file_path=file_path)\n```", "```py\nfrom torch.utils.data import DataLoader\n\nbatch_size=2\ntrainloader=DataLoader(train,batch_size=batch_size,\n                       shuffle=True)\n```", "```py\nfrom torch import nn\nclass Config():\n    def __init__(self):\n        self.n_layer = 6\n        self.n_head = 8\n        self.n_embd = 512\n        self.vocab_size = 390\n        self.block_size = 2048 \n        self.embd_pdrop = 0.1\n        self.resid_pdrop = 0.1\n        self.attn_pdrop = 0.1\nconfig=Config()\ndevice=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n```", "```py\nfrom utils.ch14util import Model\n\nmodel=Model(config)\nmodel.to(device)\nnum=sum(p.numel() for p in model.transformer.parameters())\nprint(\"number of parameters: %.2fM\" % (num/1e6,))\nprint(model)\n```", "```py\nnumber of parameters: 20.16M\nModel(\n  (transformer): ModuleDict(\n    (wte): Embedding(390, 512)\n    (wpe): Embedding(2048, 512)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-5): 6 x Block(\n        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (attn): CausalSelfAttention(\n          (c_attn): Linear(in_features=512, out_features=1536, bias=True)\n          (c_proj): Linear(in_features=512, out_features=512, bias=True)\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (mlp): ModuleDict(\n          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n          (act): GELU()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=512, out_features=390, bias=False)\n)\n```", "```py\nlr=0.0001\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\nloss_func=torch.nn.CrossEntropyLoss(ignore_index=389)\n```", "```py\nmodel.train()  \nfor i in range(1,101):\n    tloss = 0.\n    for idx, (x,y) in enumerate(trainloader):              ①\n        x,y=x.to(device),y.to(device)\n        output = model(x)\n        loss=loss_func(output.view(-1,output.size(-1)),\n                           y.view(-1))                     ②\n        optimizer.zero_grad()\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(),1)     ③\n        optimizer.step()                                   ④\n    print(f'epoch {i} loss {tloss/(idx+1)}') \ntorch.save(model.state_dict(),f'files/musicTrans.pth')     ⑤\n```", "```py\nfrom utils.processor import decode_midi\n\nprompt, _  = test[42]\nprompt = prompt.to(device)\nlen_prompt=250\nfile_path = \"files/prompt.midi\"\ndecode_midi(prompt[:len_prompt].cpu().numpy(),\n            file_path=file_path)\n```", "```py\nsoftmax=torch.nn.Softmax(dim=-1)\ndef sample(prompt,seq_length=1000,temperature=1):\n    gen_seq=torch.full((1,seq_length),389,dtype=torch.long).to(device)\n    idx=len(prompt)\n    gen_seq[..., :idx]=prompt.type(torch.long).to(device)    \n    while(idx < seq_length):                                       ①\n        y=softmax(model(gen_seq[..., :idx])/temperature)[...,:388] ②\n        probs=y[:, idx-1, :]\n        distrib=torch.distributions.categorical.Categorical(probs=probs)\n        next_token=distrib.sample()                                ③\n        gen_seq[:, idx]=next_token\n        idx+=1\n    return gen_seq[:, :idx]                                        ④\n```", "```py\nmodel.load_state_dict(torch.load(\"files/musicTrans.pth\",\n    map_location=device))\nmodel.eval()\n```", "```py\nfrom utils.processor import encode_midi\n\nfile_path = \"files/prompt.midi\"\nprompt = torch.tensor(encode_midi(file_path))\ngenerated_music=sample(prompt, seq_length=1000)\n```", "```py\nmusic_data = generated_music[0].cpu().numpy()\nfile_path = 'files/musicTrans.midi'\ndecode_midi(music_data, file_path=file_path)\n```", "```py\ninfo removed pitch: 52\ninfo removed pitch: 83\ninfo removed pitch: 55\ninfo removed pitch: 68\n```", "```py\nfile_path = \"files/prompt.midi\"\nprompt = torch.tensor(encode_midi(file_path))\ngenerated_music=sample(prompt, seq_length=1000,temperature=1.5)\nmusic_data = generated_music[0].cpu().numpy()\nfile_path = 'files/musicHiTemp.midi'\ndecode_midi(music_data, file_path=file_path)\n```"]