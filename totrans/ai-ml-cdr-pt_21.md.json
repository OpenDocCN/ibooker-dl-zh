["```py\ngit clone https://github.com/huggingface/diffusers\ncd diffusers\npip install .\n```", "```py\n!git clone https://github.com/huggingface/diffusers\n%cd diffusers\n!pip install .\n```", "```py\n%cd /content/diffusers/examples/text_to_image # or whatever your dir is\n!pip install -r requirements.txt\n```", "```py\n!pip install xformers\n```", "```py\n{ \"file_name\": \"rightprofile-smile.png\", \n               \"prompt\": \"photo of (lora-misato-token), \n               right side profile, high quality, detailed features, \n               smiling, professional photo \"}\n\n{ \"file_name\": \"rightprofile-neutral.png\", \n               \"prompt\": \"photo of (lora-misato-token), \n               right side profile, high quality, detailed features, \n               professional photo \"}\n```", "```py\nfrom accelerate.utils import write_basic_config\n\nwrite_basic_config()\n```", "```py\n!accelerate launch train_text_to_image_lora.py \\\n  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-2\" \\\n  --dataset_name=\"lmoroney/misato\" \\\n  --caption_column=\"prompt\" \\\n  --resolution=512 \\\n  --random_flip \\\n  --train_batch_size=1 \\\n  --num_train_epochs=1000 \\\n  --checkpointing_steps=5000 \\\n  --learning_rate=1e-04 \\\n  --lr_scheduler=\"constant\" \\\n  --lr_warmup_steps=0 \\\n  --seed=42 \\\n  --output_dir=\"/content/lm-misato-lora\"\n```", "```py\nResolving data files: 100% 22/22 [00:00<00:00, 74.14it/s]\n12/30/2024 19:23:48 - INFO - __main__ - ***** Running training *****\n12/30/2024 19:23:48 - INFO - __main__ -   Num examples = 21\n12/30/2024 19:23:48 - INFO - __main__ -   Num Epochs = 1000\n12/30/2024 19:23:48 - INFO - __main__ -   Instantaneous batch size per device...\n12/30/2024 19:23:48 - INFO - __main__ -   Total train batch size (w. parallel...\n12/30/2024 19:23:48 - INFO - __main__ -   Gradient Accumulation steps = 1\n12/30/2024 19:23:48 - INFO - __main__ -   Total optimization steps = 1000\nSteps:  10% 103/1000 [05:03<44:00,  2.94s/it, lr=0.0001, step_loss=0.227]\n```", "```py\nimport torch\nfrom diffusers import (\n    StableDiffusionPipeline,\n    EulerAncestralDiscreteScheduler,  \n)\n```", "```py\nmodel_id = \"stabilityai/stable-diffusion-2\"\n\n# Choose your device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# 1\\. Pick your scheduler\nscheduler = EulerAncestralDiscreteScheduler.from_pretrained(\n    model_id,\n    subfolder=\"scheduler\"\n)\n```", "```py\n# 2\\. Load the pipeline with the chosen scheduler\npipe = StableDiffusionPipeline.from_pretrained(\n    model_id,\n    scheduler=scheduler,\n    torch_dtype=torch.float16\n).to(device)\n```", "```py\n# 3\\. (Optional) Load LoRA weights\npipe.load_lora_weights(\"lmoroney/finetuned-misato-sd2\")\n```", "```py\n# 4\\. Define prompts and parameters\nprompt = \"(lora-misato-token) in food ad, billboard sign, 90s, anime, \n         japanese pop, japanese words, front view, plain background\"\n\nnegative_prompt = (\n    \"(deformed, distorted, disfigured:1.3), poorly drawn, bad anatomy, \n     wrong anatomy, \"\n    \"extra limb, missing limb, floating limbs, (mutated hands and \n     fingers:1.4), \"\n    \"disconnected limbs, mutation, mutated, ugly, disgusting, blurry, \n     amputation\"\n)\n```", "```py\nnum_inference_steps = 50\nguidance_scale = 6.0\nwidth = 512\nheight = 512\nseed = 1234567\n```", "```py\n# 5\\. Create a generator for reproducible results\ngenerator = torch.Generator(device=device).manual_seed(seed)\n\n# 6\\. Run the pipeline\nimage = pipe(\n    prompt,\n    negative_prompt=negative_prompt,\n    width=width,\n    height=height,\n    num_inference_steps=num_inference_steps,\n    guidance_scale=guidance_scale,\n    generator=generator,\n).images[0]\n\n# 7\\. Save the result\nimage.save(\"lora-with-negative.png\")\n```", "```py\n# For DPMSolver, use:\nfrom diffusers import DPMSolverMultistepScheduler\n\nscheduler = DPMSolverMultistepScheduler.from_pretrained(model_id, \n            subfolder=\"scheduler\", algorithm_type=\"dpmsolver++\")\n```"]