- en: Chapter 11\. Using Convolutional and Recurrent Methods for Sequence Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第11章\. 使用卷积和循环方法进行序列模型
- en: The last few chapters introduced you to sequence data. You saw how to predict
    it, first by using statistical methods and then by using basic ML methods with
    a deep neural network. You also explored how to tune the model’s hyperparameters
    for better performance.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 最后几章向您介绍了序列数据。您了解了如何预测它，首先是通过使用统计方法，然后是通过使用基本的机器学习方法和深度神经网络。您还探讨了如何调整模型的超参数以获得更好的性能。
- en: In this chapter, you’ll look at additional techniques that may further enhance
    your ability to predict sequence data by using convolutional neural networks as
    well as recurrent neural networks.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将了解可能进一步增强您使用卷积神经网络以及循环神经网络预测序列数据能力的其他技术。
- en: Convolutions for Sequence Data
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 序列数据的卷积
- en: 'In [Chapter 3](ch03.html#ch03_going_beyond_the_basics_detecting_features_in_ima_1748570891074912),
    you were introduced to convolutions in which a two-dimensional (2D) filter was
    passed over an image to modify it and potentially extract features. Over time,
    the neural network learned which filter values were effective at matching the
    modifications that had been made to the pixels to their labels, thus effectively
    extracting features from the image. The same technique can be applied to numeric
    time series data, but with one modification: the convolution will be one dimensional
    (1D) instead of two dimensional.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第3章](ch03.html#ch03_going_beyond_the_basics_detecting_features_in_ima_1748570891074912)中，您被介绍到一种卷积，其中二维（2D）滤波器在图像上通过以修改它并可能提取特征。随着时间的推移，神经网络学会了哪些滤波器值在匹配对像素所做的修改及其标签方面是有效的，从而有效地从图像中提取特征。相同的技巧可以应用于数值时间序列数据，但有一个修改：卷积将是一维（1D）而不是二维。
- en: Consider, for example, the series of numbers in [Figure 11-1](#ch11_figure_1_1748549734749083).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑[图11-1](#ch11_figure_1_1748549734749083)中的数字序列。
- en: '![](assets/aiml_1101.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![aiml_1101.png](assets/aiml_1101.png)'
- en: Figure 11-1\. A sequence of numbers
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-1\. 数字序列
- en: A 1D convolution could operate on these as follows. Consider the convolution
    to be a 1 × 3 filter with filter values of –0.5, 1, and –0.5, respectively. In
    this case, the first value in the sequence will be lost and the second value will
    be transformed from 8 to –1.5 (see [Figure 11-2](#ch11_figure_2_1748549734749133)).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 一维卷积可以按以下方式操作。考虑一个1 × 3的滤波器，滤波器值分别为-0.5、1和-0.5。在这种情况下，序列中的第一个值将丢失，第二个值将从8变为-1.5（见[图11-2](#ch11_figure_2_1748549734749133)）。
- en: '![](assets/aiml_1102.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![aiml_1102.png](assets/aiml_1102.png)'
- en: Figure 11-2\. Using a convolution with the number sequence
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-2\. 使用数字序列进行卷积
- en: The filter will then stride across the values, calculating new ones as it goes.
    So, for example, in the next stride, 15 will be transformed into 3 (see [Figure 11-3](#ch11_figure_3_1748549734749161)).
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 滤波器将随后在值上步进，在移动过程中计算新的值。例如，在下一个步长中，15将变为3（见[图11-3](#ch11_figure_3_1748549734749161)）。
- en: '![](assets/aiml_1103.png)'
  id: totrans-12
  prefs: []
  type: TYPE_IMG
  zh: '![aiml_1103.png](assets/aiml_1103.png)'
- en: Figure 11-3\. An additional stride in the 1D convolution
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-3\. 一维卷积中的额外步长
- en: Using this method, it’s possible to extract the patterns between values and
    learn the filters that extract them successfully, in much the same way that convolutions
    on the pixels in images can extract features. In this instance, there are no labels,
    but the convolutions that minimize overall loss can be learned.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法，可以提取值之间的模式，并学习成功提取这些模式的滤波器，这与在图像像素上进行的卷积提取特征的方式非常相似。在这种情况下，没有标签，但可以学习最小化总体损失的卷积。
- en: Coding Convolutions
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编码卷积
- en: Before coding convolutions, you’ll need to use the *sliding windows* technique
    to create a dataset, as shown in [Chapter 10](ch10.html#ch10_creating_ml_models_to_predict_sequences_1748549713795870).
    The code is available [on this book’s GitHub page](https://oreil.ly/pytorch_ch11).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在编码卷积之前，您需要使用*滑动窗口*技术创建数据集，如[第10章](ch10.html#ch10_creating_ml_models_to_predict_sequences_1748549713795870)中所示。代码可在本书的GitHub页面[上找到](https://oreil.ly/pytorch_ch11)。
- en: 'Once you have that dataset, you can add a convolutional layer before the dense
    layers that you had previously. Here’s the code, which we’ll look at line by line:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦有了这个数据集，您可以在之前拥有的密集层之前添加一个卷积层。以下是代码，我们将逐行分析：
- en: '[PRE0]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'First, notice the new line that defines a 1D convolutional layer:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，注意定义一个一维卷积层的换行符：
- en: '[PRE1]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `in_channels` parameter defines the dimensionality of the input data. As
    we have a single sequence of numbers with a single value per data point, this
    is `1`. If we were using multiple features per time step, such as perhaps an RGB
    color value, this would be `3`.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '`in_channels`参数定义了输入数据的维度。由于我们有一个包含每个数据点单个值的单个数字序列，因此这是`1`。如果我们每一步使用多个特征，例如可能是RGB颜色值，这将变为`3`。'
- en: The `out_channels` parameter is the number of filters (aka convolutions) that
    the network will learn.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '`out_channels`参数是网络将学习的过滤器（也称为卷积）的数量。'
- en: The `kernel_size` parameter determines the size of the convolution (i.e., the
    number of data points on the line that a convolution will filter). Refer back
    to [Figure 11-2](#ch11_figure_2_1748549734749133) and [Figure 11-3](#ch11_figure_3_1748549734749161)
    and you’ll see a convolution there with a kernel size of 3.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '`kernel_size`参数决定了卷积的大小（即卷积将过滤的线上的数据点数量）。回顾[图11-2](#ch11_figure_2_1748549734749133)和[图11-3](#ch11_figure_3_1748549734749161)，你会在那里看到一个卷积，其核大小为3。'
- en: The `padding` parameter adds elements to the beginning and end of your list
    of data. So, for example, the list of numbers in [Figure 11-1](#ch11_figure_1_1748549734749083)
    is [4 8 15 16 23 42 51 64 99 –1]. When the filter of kernel size 3 looks at this
    list, it begins with [4 8 15], and *4* never gets to be the “middle” number. The
    filter effectively ignores the numbers at the beginning and end of the list. With
    padding, a 0 will be added at the front and back of the list to make it [0 4 8
    15 16 23 42 51 64 99 –1 0], and you can now see that the filter will look first
    at [0 4 8].
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '`padding`参数在数据列表的开始和末尾添加元素。例如，[图11-1](#ch11_figure_1_1748549734749083)中的数字列表是[4
    8 15 16 23 42 51 64 99 –1]。当核大小为3的过滤器查看这个列表时，它从[4 8 15]开始，*4*永远不会成为“中间”数字。过滤器实际上忽略了列表开头和结尾的数字。使用填充，将在列表的前后添加0，使其变为[0
    4 8 15 16 23 42 51 64 99 –1 0]，现在你可以看到过滤器首先查看[0 4 8]。'
- en: 'Next, we see a line that looks like this:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们看到一行看起来像这样：
- en: '[PRE2]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This helps us to know the size of the output from the convolutional layer to
    inform the “next” layer in the sequence.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这有助于我们知道卷积层输出的尺寸，以便通知序列中的“下一层”。
- en: Why is it the input size, you might wonder. This is the idea of “same padding”
    that comes about from setting the `padding=1` parameter.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想知道，为什么是输入大小。这是从设置`padding=1`参数中产生的“相同填充”的概念。
- en: If you consider what would happen if you slid a kernel of size 3 across a list
    of values as in Figures [11-2](#ch11_figure_2_1748549734749133) and [11-3](#ch11_figure_3_1748549734749161),
    you’d see an odd effect. Because the kernel starts with its left side aligned
    with the first value and its center at the second value, and because it slides
    across to the end of the list where the center of the kernel will be aligned to
    the second-to-last value, the result of the calculations against the values in
    the list will give us n – 2 answers, where *n* is the length of the list. But
    if we pad the list with `padding=1`, then the kernel sliding across the list will
    give us *n* answers, so the output size from the layer will be the *same* as the
    input size.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你考虑如果将大小为3的核在如图[11-2](#ch11_figure_2_1748549734749133)和[11-3](#ch11_figure_3_1748549734749161)所示的值列表上滑动会发生什么，你会看到一个奇怪的效果。因为核的左侧与第一个值对齐，其中心在第二个值上，并且因为它滑到列表的末尾，核的中心将对齐到倒数第二个值，所以与列表中的值的计算结果将给我们n
    – 2个答案，其中*n*是列表的长度。但是如果我们用`padding=1`填充列表，那么核在列表上滑动将给我们*n*个答案，因此层的输出大小将与输入大小相同。
- en: 'So now, after ReLUing and flattening the results, we can see the next line:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在，在ReLU和展平结果之后，我们可以看到下一行：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The input to this will be a number of values: the size of the list, multiplied
    by 128, where 128 is the number of kernels. It will then output 28 values, which
    will be fed into the next linear layer.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这个输入将是一系列值：列表的大小乘以128，其中128是核的数量。然后它将输出28个值，这些值将被输入到下一个线性层。
- en: 'Now, when you get to the forward function, it begins with this line:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当你到达前向函数时，它从这一行开始：
- en: '[PRE4]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This looks quite unusual, but it’s necessary for dealing with the convolutions.
    First of all, consider what the input to a convolution should look like. There’ll
    be batches of them being fed in, each batch will have 1 dimension, and each item
    in the batch will have a number of items in it. If we are learning from sequences
    of 20 items, for example, and if we batch them 32 at a time, then the dimensionality
    of data being fed into the neural network will be [32, 1, 20].
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来相当不寻常，但这是处理卷积所必需的。首先，考虑卷积的输入应该是什么样子。会有批次的输入，每个批次将有一个维度，并且批次中的每个项目将包含一定数量的项。如果我们从20个项目的序列中学习，例如，如果我们每次批量处理32个，那么输入到神经网络的数据维度将是[32,
    1, 20]。
- en: But if our dataset isn’t giving us that—and if, for example, there are only
    two dimensions [32, 20]—then we want to use unsqueeze to slip in another dimension.
    When we pass a `1` into it, it will be put at position `1`, so we’ll get [32,
    1, 20] as desired.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果我们的数据集没有提供这些——例如，如果只有两个维度[32, 20]——那么我们想要使用unsqueeze来插入另一个维度。当我们传递一个`1`给它时，它将被放置在位置`1`，所以我们将得到所需的[32,
    1, 20]。
- en: The other case might be if we haven’t put our dimension in correctly and added
    it on the end, like in [32, 20, 1], so the `x = x.transpose(1, 2)` will flip these
    around and make the dimension [32, 1, 20] again.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种情况可能是我们没有正确放置维度并在末尾添加它，比如在[32, 20, 1]，所以`x = x.transpose(1, 2)`将翻转这些维度，再次使维度为[32,
    1, 20]。
- en: Now, these are two specific cases I hardcoded for. You may encounter others,
    so watch out for issues with your data when feeding it into the neural network.
    This is likely a place where you can fix them.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这是我为硬编码的两个特定案例。你可能会遇到其他情况，所以当将数据输入到神经网络时要留意数据问题。这可能是你可以修复它们的地方。
- en: The rest of the forward pass is pretty straightforward; it’s just passing the
    data through the different layers.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 前向传播的其余部分相当直接；它只是将数据通过不同的层。
- en: 'The loss function and optimizer are going to be pretty straightforward, too,
    using a mean-squared-error loss and an Adam optimizer:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数和优化器将非常直接，使用均方误差损失和Adam优化器：
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Training with this will give you a model as before, and to get predictions
    from the model, you can just use the loader in the same way as you did for training
    the model. So, for example, you can do this:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种方法训练将给出一个与之前相同的模型，要从模型中获取预测，你可以像训练模型时一样使用相同的加载器。例如，你可以这样做：
- en: '[PRE6]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'And here’s a helper function that can predict an entire series, batch by batch:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个辅助函数可以逐批预测整个系列：
- en: '[PRE7]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'You can then get the full set of predictions like this:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以像这样获取完整的预测集：
- en: '[PRE8]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Similarly, if you want to plot them, you could extend on this a little to pass
    in a loader and get back arrays of the predictions and the targets as well as
    an analytic, such as the MAE:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，如果你想绘制它们，可以稍微扩展一下，传入一个加载器，并返回预测和目标数组以及分析，如MAE：
- en: '[PRE9]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'And then you’d call this to get back the multiple responses like this:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然后你可以调用这个函数来获取多个响应，如下所示：
- en: '[PRE10]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This is now nice and easy to plot:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 现在绘制它变得简单易行：
- en: '[PRE11]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: A plot of the results against the series is in [Figure 11-4](#ch11_figure_4_1748549734749177).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 结果与系列的对比图在[图11-4](#ch11_figure_4_1748549734749177)中。
- en: The MAE in this case is 5.33, which is slightly worse than for the previous
    prediction. This could be because we haven’t tuned the convolutional layer appropriately,
    or it could be that convolutions simply don’t help. This is the type of experimentation
    you’ll need to do with your data.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，MAE是5.33，这比之前的预测略差。这可能是因为我们没有适当地调整卷积层，或者可能是因为卷积根本不起作用。这是你需要对你数据进行实验的一种类型。
- en: Do note that this data has a random element in it, so values will change across
    sessions. If you’re using code from [Chapter 10](ch10.html#ch10_creating_ml_models_to_predict_sequences_1748549713795870)
    and then running this code separately, you will, of course, have random fluctuations
    affecting your data and thus your MAE.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这个数据中有一个随机元素，所以值会在会话之间变化。如果你使用[第10章](ch10.html#ch10_creating_ml_models_to_predict_sequences_1748549713795870)中的代码然后单独运行这段代码，你当然会看到数据和你MAE的随机波动。
- en: '![](assets/aiml_1104.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_1104.png)'
- en: Figure 11-4\. Convolutional neural network with time sequence data prediction
    versus actual
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-4. 基于时间序列数据预测的卷积神经网络与实际结果对比
- en: But when using convolutions, questions always come up. Why choose the parameters
    that we chose? Why 128 filters? Why size 3 × 1? The good news is that you can
    experiment with these things easily to explore different results.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，当使用卷积时，总是会有问题。为什么选择我们选择的参数？为什么是128个过滤器？为什么是3 × 1的大小？好消息是你可以轻松地实验这些参数，以探索不同的结果。
- en: Experimenting with the Conv1D Hyperparameters
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 尝试Conv1D超参数
- en: In the previous section, you saw a 1D convolution that was hardcoded with parameters
    for things like filter number, kernel size, number of strides, etc. When you were
    training the neural network with it, it appeared that the MAE went up slightly,
    so you got no benefit from using the `Conv1D`. This may not always be the case,
    depending on your data, but it could be because of suboptimal hyperparameters.
    So, in this section, you’ll see how you can do a neural architecture search to
    find the best results.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，你看到了一个硬编码了参数（如过滤器数量、内核大小、步长数量等）的1D卷积。当你用这个参数训练神经网络时，MAE略有上升，所以你没有从使用`Conv1D`中获得任何好处。这并不总是这种情况，这取决于你的数据，但可能是由于次优的超参数。因此，在本节中，你将看到如何进行神经架构搜索以找到最佳结果。
- en: One of the nice things about how verbose PyTorch is, in particular for defining
    the neural network and the forward pass, is that it becomes pretty straightforward
    to change up the parameters that you use. The idea with a *neural architecture
    search* is to come up with sets of different parameters to try and then explore
    the impact that they have on the results by training for a short time and finding
    those that give the best results.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 关于PyTorch的详尽性，特别是对于定义神经网络和正向传递，有一个很好的方面，那就是改变你使用的参数变得相当直接。*神经架构搜索*的想法是提出一组不同的参数来尝试，然后通过短时间训练并找到那些给出最佳结果的参数来探索它们对结果的影响。
- en: So, for example, here, we used a single `Conv1D` layer. But what if there were
    more? Similarly, we hardcoded a number of channels and a kernel size, and we also
    hardcoded the size of the dense layers and the LR for the optimizer. But what
    if, instead of hardcoding them, we created a set of options like this?
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，例如，在这里，我们使用了一个单一的`Conv1D`层。但如果有更多呢？同样，我们硬编码了通道数和内核大小，我们还硬编码了密集层的尺寸和优化器的LR。但如果我们不是硬编码它们，而是创建一组像这样的选项呢？
- en: '[PRE12]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: With 4 options for the `conv` layers, 2 for the kernel sizes, 3 for the dense
    dimensions, and 2 for the LR, we have 4 × 2 × 3 × 2 options total, which is 48
    combinations. This is called the *search space*.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 对于`conv`层有4个选项，内核大小有2个选项，密集维度有3个选项，LR有2个选项，我们总共有4 × 2 × 3 × 2个选项，即48种组合。这被称为*搜索空间*。
- en: Note that in this case, you might think it would be 96 because there are 2 layers
    options and 4 channels options. But in the code to define the search space, which
    you’ll see in a moment, I only allowed `conv` channel options that match the number
    of layers, so there will just be 4 options in total for the `conv` layers.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在这种情况下，你可能认为应该是96，因为有2个层选项和4个通道选项。但在定义搜索空间的代码中，你将很快看到，我只允许与层数相匹配的`conv`通道选项，所以`conv`层将只有4个选项。
- en: 'These options will be loaded into a configurations array, with name-value pairs
    set up for the parameters, like this:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这些选项将被加载到一个配置数组中，为参数设置名称-值对，如下所示：
- en: '[PRE13]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'So now, we can loop through these configurations and set up our `CNN1D` model
    by using them like this. Note the use of the `config[]` array:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以遍历这些配置，并使用它们来设置我们的`CNN1D`模型，如下所示。注意使用`config[]`数组：
- en: '[PRE14]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'It would be really time-consuming to train each of the 48 combinations for
    the full set of epochs (say, 100), so we’ve introduced the idea of *early stopping*.
    First, let’s train the model with the parameters we loaded from the configuration
    and a new parameter: `early stopping patience`:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 训练包含48种组合的全集（例如，100个epoch）将非常耗时，因此我们引入了*早期停止*的概念。首先，让我们使用从配置文件加载的参数以及一个新参数：`早期停止耐心`来训练模型：
- en: '[PRE15]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Then, within the training loop, we can implement an early stopping like this:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在训练循环中，我们可以实现一个早期停止，如下所示：
- en: '[PRE16]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This keeps track of the loss for the best model and compares the current model
    with the best one. If the current model “loses” more times than our patience parameter
    (in this case, 10), then we’ll throw it out and move to the next one. If it “wins,”
    then we’ll keep the current model as the best one.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这跟踪最佳模型的损失，并将当前模型与最佳模型进行比较。如果当前模型“失败”次数超过我们的耐心参数（在这种情况下，10次），那么我们将将其丢弃并移动到下一个。如果它“获胜”，那么我们将保持当前模型作为最佳模型。
- en: Starting from this code, you can try to experiment with the hyperparameters
    for the number of filters, the size of the kernel, and the size of the stride,
    keeping the other parameters static.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 从这段代码开始，你可以尝试调整过滤器的数量、内核大小和步长大小的超参数，同时保持其他参数不变。
- en: After some experimentation, I discovered that 2 convolutional layers, with 64
    and 32 filters (respectively), a kernel size of 5, two dense layers of 64 and
    32, and an LR of .0001 gave the best MAE on the validation set, giving me a final
    result of 4.4439 MAE.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 经过一些实验后，我发现使用 2 个卷积层，64 和 32 个过滤器（分别），内核大小为 5，两个 64 和 32 的密集层，以及学习率 LR 为 .0001，在验证集上给出了最佳的
    MAE，最终结果为 4.4439 MAE。
- en: After training with this, the model had improved accuracy compared with both
    the naive CNN created earlier *and* the original DNN, giving the results shown
    in [Figure 11-5](#ch11_figure_5_1748549734749203).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这些数据进行训练后，模型与之前创建的朴素 CNN 和原始 DNN 相比，准确率有所提高，结果如图 11-5 所示 [图 11-5](#ch11_figure_5_1748549734749203)。
- en: '![](assets/aiml_1105.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_1105.png)'
- en: Figure 11-5\. Optimized CNN time series predictions versus actual
  id: totrans-80
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-5\. 优化的 CNN 时间序列预测与实际值对比
- en: Further experimentation with the CNN hyperparameters may improve this further.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步实验调整 CNN 的超参数可能会进一步提升效果。
- en: Beyond convolutions, the techniques we explored in the chapters on NLP with
    RNNs, including LSTMs, may be powerful when working with sequence data. By their
    very nature, RNNs are designed for maintaining context, so previous values can
    have an effect on later ones. You’ll explore using RNNs for sequence modeling
    next. But first, let’s move on from a synthetic dataset and start looking at real
    data. In this case, we’ll consider weather data.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 除了卷积之外，我们在关于使用 RNN 的 NLP 章节中探索的技术，包括 LSTM，在处理序列数据时可能非常强大。由于它们的本质，RNN 被设计用来保持上下文，因此前面的值可以影响后面的值。接下来，你将探索使用
    RNN 进行序列建模。但在那之前，让我们从合成数据集转向真实数据。在这种情况下，我们将考虑天气数据。
- en: Using NASA Weather Data
  id: totrans-83
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 NASA 天气数据
- en: One great resource for time series weather data is the [NASA Goddard Institute
    for Space Studies (GISS) Surface Temperature Analysis](https://oreil.ly/6IixP).
    If you follow the [Station Data link](https://oreil.ly/F9Hmw), on the right side
    of the page, you can pick a weather station to get data from. For example, I chose
    the Seattle Tacoma (SeaTac) airport and was taken to the page shown in [Figure 11-6](#ch11_figure_6_1748549734749227).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列天气数据的一个很好的资源是 [NASA 戈达德太空研究所 (GISS) 表面温度分析](https://oreil.ly/6IixP)。如果你点击页面右侧的
    [站数据链接](https://oreil.ly/F9Hmw)，你可以选择一个气象站来获取数据。例如，我选择了西雅图塔科马（SeaTac）机场，并被带到了
    [图 11-6](#ch11_figure_6_1748549734749227) 所示的页面。
- en: '![](assets/aiml_1106.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_1106.png)'
- en: Figure 11-6\. Surface temperature data from GISS
  id: totrans-86
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-6\. GISS 的表面温度数据
- en: You can also see a link to download monthly data as CSV at the bottom of this
    page. If you select this link, a file called *station.csv* will be downloaded
    to your device, and if you open it, you’ll see that it’s a grid of data with a
    year in each row and a month in each column (see [Figure 11-7](#ch11_figure_7_1748549734749249)).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以在页面底部看到下载月度数据的 CSV 链接。如果你选择此链接，一个名为 *station.csv* 的文件将被下载到你的设备上，如果你打开它，你会看到它是一个数据网格，每行代表一年，每列代表一个月（参见
    [图 11-7](#ch11_figure_7_1748549734749249)）。
- en: '![](assets/aiml_1107.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_1107.png)'
- en: Figure 11-7\. Exploring the data
  id: totrans-89
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-7\. 探索数据
- en: As this is CSV data, it’s pretty easy to process in Python, but as with any
    dataset, do note the format. When reading CSV, you tend to read it line by line,
    and often, each line has one data point that you’re interested in. In this case,
    there are at least 12 data points of interest per line, so you’ll have to consider
    this when reading the data.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是 CSV 数据，因此在 Python 中处理起来相当容易，但就像任何数据集一样，请注意其格式。在读取 CSV 时，你通常会逐行读取，并且通常每行都有一个你感兴趣的数据点。在这种情况下，每行至少有
    12 个感兴趣的数据点，因此在读取数据时你必须考虑这一点。
- en: Reading GISS Data in Python
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Python 中读取 GISS 数据
- en: 'The code to read the GISS data is shown here:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 读取 GISS 数据的代码如下所示：
- en: '[PRE17]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This will open the file at the indicated path (yours will, of course, differ)
    and read in the entire file as a set of lines, where the line split is the new
    line character (`\n`). It will then loop through each line, ignoring the first
    line, and split them on the comma character into a new array called `linedata`.
    The items from 1 through 13 in this array will indicate the values for the months
    January through February as strings, and these values will then be converted into
    floats and added to the array called `temperatures`. Once it’s completed, it will
    be turned into a NumPy array called `series`, and another NumPy array called `time`
    will be created that’s the same size as `series`. As it is created using `np.arange`,
    the first element will be 1, the second will be 2, etc. Thus, this function will
    return `time` in steps from 1 to the number of data points and will return `series`
    as the data for that time.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打开指定路径的文件（当然，你的路径会有所不同）并将整个文件作为一系列行读取，行分割是新行字符（`\n`）。然后它将遍历每一行，忽略第一行，并将它们按逗号字符分割到一个名为
    `linedata` 的新数组中。这个数组中的第 1 到 13 项将表示从一月到二月的月份值，这些值然后将被转换为浮点数并添加到名为 `temperatures`
    的数组中。一旦完成，它将被转换为一个名为 `series` 的 NumPy 数组，并创建另一个与 `series` 大小相同的 NumPy 数组 `time`。由于它是使用
    `np.arange` 创建的，第一个元素将是 1，第二个将是 2，等等。因此，这个函数将按从 1 到数据点数量的步骤返回 `time`，并将 `series`
    作为该时间的数据返回。
- en: 'I have noticed that often, there will be “unfilled” data in some of the columns,
    and these are represented by the value 999.9\. This will, of course, skew any
    predictive results you want to create. But fortunately, 999.9 values are usually
    at the *end* of the dataset, so they can easily be cropped. Here’s a helper function
    to normalize the series while cropping out the 999.9 values:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我注意到，通常，某些列中会有“未填充”的数据，这些数据用值 999.9 表示。这当然会歪曲你想要创建的任何预测结果。但幸运的是，999.9 值通常位于数据集的
    *末尾*，因此它们可以很容易地被裁剪。这里有一个辅助函数，可以在裁剪 999.9 值的同时对序列进行归一化：
- en: '[PRE18]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'You can now load this into a `torch.tensor` and turn it into a set of sliding
    windows with a target value as before. We discussed the helper function in [Chapter 10](ch10.html#ch10_creating_ml_models_to_predict_sequences_1748549713795870):'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在可以将它加载到 `torch.tensor` 中，并将其转换为具有目标值的一组滑动窗口，就像之前一样。我们在 [第 10 章](ch10.html#ch10_creating_ml_models_to_predict_sequences_1748549713795870)
    中讨论了辅助函数：
- en: '[PRE19]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Once we have that, we can turn it into a `TensorDataset` and split it into
    subsets for training and validation:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了这些，我们就可以将其转换为 `TensorDataset` 并将其拆分为用于训练和验证的子集：
- en: '[PRE20]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now that we have the splits as datasets, we can create loaders for them that
    the neural network will use:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了作为数据集的拆分，我们可以为它们创建加载器，神经网络将使用这些加载器：
- en: '[PRE21]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: And now, we’re ready to train with this data. We can inspect the split by charting
    the data, and we can see this with the training/validation split in [Figure 11-8](#ch11_figure_8_1748549734749270).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们准备好使用这些数据进行训练了。我们可以通过绘制数据来检查拆分，并且我们可以在 [图 11-8](#ch11_figure_8_1748549734749270)
    中看到这一点。
- en: '![](assets/aiml_1108.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_1108.png)'
- en: Figure 11-8\. The time series train/validation split
  id: totrans-105
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-8\. 时间序列训练/验证拆分
- en: In the next section, we’ll explore creating a simple RNN-based neural network
    to see if we can predict the next values in the sequence.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探索创建一个简单的基于 RNN 的神经网络，看看我们是否可以预测序列中的下一个值。
- en: Using RNNs for Sequence Modeling
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 RNNs 进行序列建模
- en: 'Now that you have the data from the NASA CSV in a windowed dataset, it’s relatively
    easy to create a model to train a predictor for it. (However, it’s a bit more
    difficult to train a *good* one!) Let’s start with a simple, naive model using
    RNNs. Here’s the code:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经将来自 NASA CSV 的数据放入了窗口数据集中，创建一个用于训练预测器的模型相对容易。（然而，训练一个 *好的* 模型要困难一些！）让我们从一个简单的、天真的模型开始，使用
    RNNs。以下是代码：
- en: '[PRE22]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In this case, as you can see, we use a basic RNN. RNNs are a class of neural
    networks that are powerful for exploring sequence models, and you first saw them
    in [Chapter 7](ch07.html#ch07_recurrent_neural_networks_for_natural_language_pro_1748549654891648),
    when you were looking at NLP. I won’t go into detail on how they work here, but
    if you’re interested and you skipped that chapter, take a look back at it now.
    Notably, an RNN has an internal loop that iterates over the time steps of a sequence
    while maintaining an internal state of the time steps it has seen so far.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，如您所见，我们使用了一个基本的RNN。RNN是一类神经网络，对于探索序列模型非常强大，您第一次在[第7章](ch07.html#ch07_recurrent_neural_networks_for_natural_language_pro_1748549654891648)中看到它们，当时您正在查看自然语言处理。这里我不会详细介绍它们的工作原理，但如果您对此感兴趣并且跳过了那一章，现在可以回顾一下。值得注意的是，RNN有一个内部循环，它遍历序列的时间步，同时保持到目前为止看到的时间步的内部状态。
- en: 'While training, you can use a loss function and optimizer like this:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，您可以使用这样的损失函数和优化器：
- en: '[PRE23]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The full code is available in this book’s [GitHub repository](https://oreil.ly/pytorch_ch11).
    Even one hundred epochs of training is enough to get an idea of how the model
    can predict values. [Figure 11-9](#ch11_figure_9_1748549734749285) shows the results.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的代码可以在本书的 [GitHub 仓库](https://oreil.ly/pytorch_ch11) 中找到。即使进行一百个训练周期也足以了解模型如何预测值。[图11-9](#ch11_figure_9_1748549734749285)
    展示了结果。
- en: '![](assets/aiml_1109.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_1109.png)'
- en: Figure 11-9\. Results of the SimpleRNN time series prediction versus actual
  id: totrans-115
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-9\. SimpleRNN时间序列预测与实际结果
- en: As you can see, the results were pretty good. It may be a little off in the
    peaks and when the pattern changes unexpectedly (like at time steps 160–170),
    but on the whole, it’s not bad. Now, let’s see what happens if we train it for
    1,500 epochs (see [Figure 11-10](#ch11_figure_10_1748549734749297)).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，结果相当不错。在峰值和模式意外变化时（如时间步160-170），可能会有一些偏差，但总体来说，还不错。现在，让我们看看如果我们训练它1,500个周期会发生什么（见[图11-10](#ch11_figure_10_1748549734749297)）。
- en: '![](assets/aiml_1110.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_1110.png)'
- en: Figure 11-10\. Time series prediction versus actual for RNN trained over 1,500
    epochs
  id: totrans-118
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-10\. 经过1,500个周期训练的RNN的时间序列预测与实际结果
- en: There’s not much of a difference, except that some of the peaks are smoothed
    out. If you look at the history of loss on both the validation set and the training
    set, it looks like [Figure 11-11](#ch11_figure_11_1748549734749310).
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 差别不大，只是有些峰值被平滑了。如果您查看验证集和训练集上的损失历史，看起来就像[图11-11](#ch11_figure_11_1748549734749310)。
- en: '![](assets/aiml_1111.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_1111.png)'
- en: Figure 11-11\. Training and validation model loss over time for the SimpleRNN
  id: totrans-121
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-11\. SimpleRNN的训练和验证模型损失随时间的变化
- en: As you can see, there’s a healthy match between the training loss and the validation
    loss, but as the epochs increase, the model begins to overfit on the training
    set. Perhaps a better number of epochs would be around five hundred.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，训练损失和验证损失之间有一个健康的匹配，但随着周期的增加，模型开始对训练集过拟合。可能更好的周期数是大约五百个。
- en: One reason for this could be the fact that the data, being monthly weather data,
    is highly seasonal. Another is that there is a very large training set and a relatively
    small validation set.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能的原因之一是数据本身是高度季节性的月度天气数据。另一个原因是训练集非常大，而验证集相对较小。
- en: Next, we’ll explore using a larger climate dataset.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将探索使用更大的气候数据集。
- en: Exploring a Larger Dataset
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索更大的数据集
- en: The [KNMI Climate Explorer](https://oreil.ly/J8CP0) allows you to explore granular
    climate data from many locations around the world. [I downloaded a dataset](https://oreil.ly/Ci9DI)
    consisting of daily temperature readings from the center of England from the years
    1772 to 2020\. This data is structured differently from the GISS data, with the
    date as a string, followed by a number of spaces, followed by the reading. Go
    back to [Chapter 4](ch04.html#ch04_using_data_with_pytorch_1748548966496246) to
    check the details on handling and managing large datasets.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '[KNMI气候探索器](https://oreil.ly/J8CP0) 允许您探索来自世界各地许多地点的细粒度气候数据。[我下载了一个数据集](https://oreil.ly/Ci9DI)，它包含从1772年到2020年英格兰中心的每日温度读数。这些数据结构与GISS数据不同，日期是一个字符串，后面跟着若干个空格，然后是读数。回到[第4章](ch04.html#ch04_using_data_with_pytorch_1748548966496246)查看处理和管理大数据集的详细信息。'
- en: 'I’ve prepared the data, stripping the headers and removing the extraneous spaces,
    so that there’s only one space between the date and the reading. That way, it’s
    easy to read with code like this:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经准备好了数据，去除了标题并移除了多余的空格，这样日期和阅读内容之间就只有一个空格。这样，使用如下代码阅读起来就很容易：
- en: '[PRE24]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This dataset has 91,502 data points in it, so before training your model, be
    sure to split it appropriately. I used a split time of 80,000, leaving 10,663
    records for validation:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 该数据集包含91,502个数据点，因此在训练您的模型之前，请确保适当地将其分割。我使用了80,000的分割时间，留下10,663条记录用于验证：
- en: '[PRE25]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Everything else can remain the same. As you can see in [Figure 11-12](#ch11_figure_12_1748549734749322),
    after training for one hundred epochs, the plot of the predictions against the
    validation set looks pretty good.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 其他所有内容都可以保持不变。正如您在[图11-12](#ch11_figure_12_1748549734749322)中看到的那样，经过一百个epoch的训练后，预测值与验证集的图表看起来相当不错。
- en: '![](assets/aiml_1112.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_1112.png)'
- en: Figure 11-12\. Plot of predictions against real data
  id: totrans-133
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-12. 预测值与实际数据的图表
- en: There’s a lot of data here, so let’s zoom in to the last hundred days’ worth
    (see [Figure 11-13](#ch11_figure_13_1748549734749335)).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有大量数据，所以让我们放大最后一百天的数据（参见[图11-13](#ch11_figure_13_1748549734749335))。
- en: '![](assets/aiml_1113.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_1113.png)'
- en: Figure 11-13\. Results of time series prediction versus actual for one hundred
    days’ worth of data
  id: totrans-136
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-13. 一百天数据的时间序列预测与实际值的结果
- en: While the chart generally follows the curve of the data and is getting the trends
    roughly correct, it is pretty far off, particularly at the extreme ends, so there’s
    room for improvement.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然图表总体上遵循数据的曲线，并且大致正确地捕捉到了趋势，但它离实际值相当远，尤其是在极端端，因此还有改进的空间。
- en: It’s also important to remember that we normalized the data, so while our loss
    and MAE may look low, that’s because they are based on the loss and MAE of normalized
    values that have a much lower variance than the real ones. As [Figure 11-14](#ch11_figure_14_1748549734749347)
    shows, a tiny amount of loss might lead you into having a false sense of security.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 还重要的是要记住，我们对数据进行归一化处理，因此虽然我们的损失和MAE可能看起来很低，但这是因为它们是基于归一化值的损失和MAE，这些值的方差远低于实际值。正如[图11-14](#ch11_figure_14_1748549734749347)所示，微小的损失可能会让您产生错误的安心感。
- en: '![](assets/aiml_1114.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_1114.png)'
- en: Figure 11-14\. Training and validation model loss over time for large dataset
  id: totrans-140
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-14. 大数据集的训练和验证模型损失随时间的变化
- en: 'To denormalize the data, you can do the inverse of normalization: first, multiply
    by the standard deviation, and then add back the mean. At that point, if you wish,
    you can calculate the real MAE for the prediction set as you’ve done previously.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 为了去归一化数据，您可以执行归一化的逆操作：首先乘以标准差，然后加上均值。到那时，如果您愿意，可以像之前那样计算预测集的真实MAE。
- en: Using Other Recurrent Methods
  id: totrans-142
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用其他循环方法
- en: In addition to the `RNN`, PyTorch has other recurrent layer types, such as gated
    recurrent units (GRUs) and long short-term memory layers (LSTMs), which we discussed
    in [Chapter 7](ch07.html#ch07_recurrent_neural_networks_for_natural_language_pro_1748549654891648).
    It is relatively simple to just drop in these RNN types if you want to experiment.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 除了`RNN`之外，PyTorch还有其他循环层类型，例如门控循环单元（GRUs）和长短期记忆层（LSTMs），我们在[第7章](ch07.html#ch07_recurrent_neural_networks_for_natural_language_pro_1748549654891648)中讨论了这些。如果您想进行实验，只需简单地替换这些RNN类型即可。
- en: 'So, for example, if you consider the simple, naive RNN that you created earlier,
    replacing it with a GRU becomes as easy as using `nn.GRU`:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果您考虑您之前创建的简单、天真的RNN，用GRU替换它就像使用`nn.GRU`一样简单：
- en: '[PRE26]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'With an LSTM, it’s similar:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LSTM时，情况类似：
- en: '[PRE27]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: It’s worth experimenting with these layer types as well as with different hyperparameters,
    loss functions, and optimizers. There’s no one-size-fits-all solution, so what
    works best for you in any given situation will depend on your data and your requirements
    for prediction with that data.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 值得尝试这些层类型以及不同的超参数、损失函数和优化器。没有一种适合所有情况的解决方案，因此任何给定情况下最适合您的方案将取决于您的数据和您对该数据进行预测的要求。
- en: Using Dropout
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Dropout
- en: If you encounter overfitting in your models, where the MAE or loss for the training
    data is much better than with the validation data, you can use dropout. As discussed
    in earlier chapters, with dropout, neighboring neurons are randomly dropped out
    (ignored) during training to avoid a familiarity bias. When you’re using RNNs,
    there’s also a *recurrent dropout* parameter that you can use.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你遇到模型过拟合的情况，即训练数据的 MAE 或损失比验证数据好得多，你可以使用 dropout。如前几章所述，使用 dropout 时，相邻神经元在训练过程中会被随机丢弃（忽略），以避免熟悉偏差。当你使用
    RNN 时，还有一个可用的 *recurrent dropout* 参数。
- en: What’s the difference? Recall that when using RNNs, you typically have an input
    value and the neuron calculates an output value and a value that gets passed to
    the next time step. Dropout will randomly drop out the input values, and recurrent
    dropout will randomly drop out the recurrent values that get passed to the next
    step.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 有什么区别？回想一下，当使用 RNN 时，你通常有一个输入值，神经元计算一个输出值和一个传递到下一个时间步的值。Dropout 会随机丢弃输入值，而 recurrent
    dropout 会随机丢弃传递到下一个步骤的循环值。
- en: For example, consider the basic RNN architecture shown in [Figure 11-15](#ch11_figure_15_1748549734749377).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑图 11-15 所示的基本 RNN 架构。
- en: '![](assets/aiml_1115.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aiml_1115.png)'
- en: Figure 11-15\. A recurrent neural network
  id: totrans-154
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-15\. 一个循环神经网络
- en: Here, you can see the inputs into the layers at different time steps (*x*).
    The current time is *t*, and the steps shown are *t* – 2 through *t* + 1\. The
    relevant outputs at the same time steps (*y*) are also shown, and the recurrent
    values passed between time steps are indicated by the dotted lines and labeled
    as *r*.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以看到不同时间步长的层输入 (*x*)。当前时间是 *t*，显示的步骤是 *t* – 2 到 *t* + 1。同一时间步长的相关输出 (*y*)
    也已显示，时间步长之间传递的循环值由虚线和标签 *r* 表示。
- en: Using *dropout* will randomly drop out the *x* inputs, while using *recurrent
    dropout* will randomly drop out the *r* recurrent values.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 *dropout* 会随机丢弃 *x* 输入，而使用 *recurrent dropout* 会随机丢弃 *r* 循环值。
- en: You can learn more about how recurrent dropout works from a deeper mathematical
    perspective in the paper [“A Theoretically Grounded Application of Dropout in
    Recurrent Neural Networks” by Yarin Gal and Zoubin Ghahramani](https://oreil.ly/MqqRR).
    One other thing to consider when using recurrent dropout is discussed by Gal in
    his research around [uncertainty in deep learning](https://oreil.ly/3v8IB), in
    which he demonstrates that the same pattern of dropout units should be applied
    at every time step and that a similar constant dropout mask should also be applied
    at every time step.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从 Yarin Gal 和 Zoubin Ghahramani 的论文“在循环神经网络中基于理论的应用 Dropout”中更深入地了解 recurrent
    dropout 的工作原理。[“A Theoretically Grounded Application of Dropout in Recurrent Neural
    Networks” by Yarin Gal and Zoubin Ghahramani](https://oreil.ly/MqqRR)。在使用 recurrent
    dropout 时，还有一件事需要考虑，这是 Gal 在其关于[深度学习中的不确定性](https://oreil.ly/3v8IB)的研究中讨论的，其中他证明了应该在每个时间步长应用相同的
    dropout 单元模式，并且在每个时间步长也应该应用一个类似的常数 dropout 掩码。
- en: 'To add dropout and recurrent dropout, you use the relevant parameters on your
    layers. For example, adding them to the basic GRU from earlier was as simple as
    using a parameter in the recurrent layers and adding another layer between the
    RNNs and the linears:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 要添加 dropout 和 recurrent dropout，你可以在层上使用相关参数。例如，将它们添加到之前的基本 GRU 中，就像在循环层中使用一个参数并在
    RNN 和线性层之间添加另一个层一样简单：
- en: '[PRE28]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Each parameter takes a value between 0 and 1 that indicates the proportion of
    values to drop out. For example, a value of 0.1 will drop out 10% of the requisite
    values.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 每个参数的值介于 0 和 1 之间，表示要丢弃的值的比例。例如，0.1 的值将丢弃所需值的 10%。
- en: Training a model with dropout like this shows a much steeper learning curve,
    which is still trending downward at 100 epochs. The validation is quite flat,
    indicating that a larger validation set may be necessary. It’s also quite noisy,
    and you’ll often see noise like this in the loss when using dropout. It’s an indication
    that you may want to tweak the amount of dropout as well as the parameters of
    the loss function and optimizer, such as the LR. You can see this in [Figure 11-16](#ch11_figure_16_1748549734749392).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这种 dropout 训练模型会显示出更陡峭的学习曲线，在 100 个周期时仍然呈下降趋势。验证结果相当平稳，表明可能需要更大的验证集。它也非常嘈杂，使用
    dropout 时你经常会看到这样的损失噪声。这是一个迹象，表明你可能需要调整 dropout 的数量以及损失函数和优化器的参数，例如学习率 (LR)。你可以在[图
    11-16](#ch11_figure_16_1748549734749392)中看到这一点。
- en: '![](assets/aiml_1116.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aiml_1116.png)'
- en: Figure 11-16\. Training and validation loss over time using a GRU with dropout
  id: totrans-163
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 11-16\. 使用带有 dropout 的 GRU 随时间变化的训练和验证损失
- en: As you’ve seen in this chapter, predicting time sequence data using neural networks
    is a difficult proposition, but tweaking their hyperparameters can be a powerful
    way to improve your model and its subsequent predictions.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在本章中看到的，使用神经网络预测时间序列数据是一个困难的任务，但调整它们的超参数可以是一种强大的方法来改进你的模型及其随后的预测。
- en: Using Bidirectional RNNs
  id: totrans-165
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用双向RNN
- en: Another technique to consider when classifying sequences is to use bidirectional
    training. This may seem counterintuitive at first, as you might wonder how future
    values could impact past ones. But recall that time series values can contain
    seasonality, where values repeat over time, and when using a neural network to
    make predictions, all we’re doing is sophisticated pattern matching. Given that
    data repeats, a signal for how data can repeat might be found in future values—and
    when using bidirectional training, we can train the network to try to spot patterns
    going from time *t* to time *t* + *x*, as well as going from time *t* + *x* to
    time *t*.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在对序列进行分类时，可以考虑使用双向训练作为另一种技术。一开始这可能会感觉有些反直觉，因为你可能会想知道未来的值如何影响过去的值。但请记住，时间序列值可能包含季节性，即值随时间重复，而在使用神经网络进行预测时，我们实际上只是在进行复杂的模式匹配。鉴于数据会重复，数据如何重复的信号可能存在于未来的值中——当使用双向训练时，我们可以训练网络尝试从时间
    *t* 到时间 *t* + *x* 以及从时间 *t* + *x* 到时间 *t* 的模式。
- en: Fortunately, coding this is simple. For example, consider the GRU from the previous
    section. To make this bidirectional, you simply add a `bidirectional` parameter.
    This will effectively train twice on each step—once with the sequence data in
    the original order and once with it in reverse order. The results are then merged
    before proceeding to the next step.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，编写这个代码很简单。例如，考虑上一节中的GRU。为了使其双向，你只需添加一个`bidirectional`参数。这将有效地在每一步训练两次——一次是按原始顺序的序列数据，一次是按相反顺序的数据。然后结果在进入下一步之前被合并。
- en: 'Here’s an example:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一个例子：
- en: '[PRE29]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: A plot of the results of training with a bidirectional GRU with dropout on the
    time series is shown in [Figure 11-17](#ch11_figure_17_1748549734749407). While
    the MAE has improved slightly, the bigger impact is that the predicted curve has
    lost the “lag” compared with the single direction version.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间序列上使用带有dropout的双向GRU的训练结果如图[图11-17](#ch11_figure_17_1748549734749407)所示。虽然平均绝对误差（MAE）略有提高，但更大的影响是预测曲线与单方向版本相比失去了“滞后”。
- en: Additionally, tweaking the training parameters—particularly `window_size`, to
    get multiple seasons—can have a pretty big impact.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，调整训练参数——特别是`window_size`，以获得多个季节——可以产生相当大的影响。
- en: '![](assets/aiml_1117.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_1117.png)'
- en: Figure 11-17\. Time series prediction training with a bidirectional GRU
  id: totrans-173
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图11-17. 使用双向GRU进行时间序列预测训练
- en: As you can see, you can experiment with different network architectures and
    different hyperparameters to improve your overall predictions. The ideal choices
    are very much dependent on the data, so the skills you’ve learned in this chapter
    will help you with your specific datasets!
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所见，你可以尝试不同的网络架构和不同的超参数来提高你的整体预测能力。理想的选择很大程度上取决于数据，所以你在本章中学到的技能将帮助你处理特定的数据集！
- en: Summary
  id: totrans-175
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you explored different network types for building models to
    predict time series data. You built on the simple DNN from [Chapter 10](ch10.html#ch10_creating_ml_models_to_predict_sequences_1748549713795870),
    adding convolutions, and you experimented with recurrent network types such as
    simple RNNs, GRUs, and LSTMs. You also learned how to tweak hyperparameters and
    the network architecture to improve your model’s accuracy, and you practiced working
    with some real-world datasets, including one massive dataset with hundreds of
    years’ worth of temperature readings.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你探索了不同的网络类型来构建预测时间序列数据的模型。你从第10章的简单DNN（[第10章](ch10.html#ch10_creating_ml_models_to_predict_sequences_1748549713795870)）开始，增加了卷积，并尝试了如简单RNN、GRU和LSTM等循环网络类型。你还学习了如何调整超参数和网络架构以提高模型的准确性，并练习了使用一些真实世界的数据集，包括一个包含数百年温度读数的巨大数据集。
- en: Now, you’re ready to get started building networks for a variety of datasets,
    and you have a good understanding of what you need to know to optimize them!
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你准备好开始为各种数据集构建网络了，并且你对优化它们所需了解的内容有了很好的理解！
