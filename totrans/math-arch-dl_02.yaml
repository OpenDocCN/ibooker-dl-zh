- en: 3 Classifiers and vector calculus
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We took a first look at the core concept of machine learning in section [1.3](../Text/01.xhtml#sec-cat_brain).
    Then, in section [2.8.2](02.xhtml#subsec-hyper-planes-classifiers), we examined
    classifiers as a special case. But so far, we have skipped the topic of error
    minimization: given one or more training examples, how do we adjust the weights
    and biases to make the machine closer to the desired ideal? We will study this
    topic in this chapter by discussing the concept of gradients.'
  prefs: []
  type: TYPE_NORMAL
- en: NOTE The complete PyTorch code for this chapter is available at [http://mng.bz](http://mng.bz/4Zya)
    [/4Zya](http://mng.bz/4Zya) in the form of fully functional and executable Jupyter
    notebooks.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Geometrical view of image classification
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To fix our ideas, consider a machine that classifies whether an image contains
    a car or a giraffe. Such classifiers, with only two classes, are known as *binary
    classifiers*. The first question is how to represent the input.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.1 Input representation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The car-versus-giraffe scenario belongs to a special class of problems where
    we are analyzing a visual scene. Here, the inputs are the brightness levels of
    various points in the 3D scene projected onto a 2D image plane. Each element of
    the image represents a point in the actual scene and is referred to as a *pixel*.
    The image is a two-dimensional array representing the collection of pixel values
    at a given instant in time. It is usually scaled to a fixed size, say 224 × 224.
    As such, the image can be viewed as a matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-00-a.png)'
  prefs: []
  type: TYPE_IMG
- en: Each element of the matrix, *X[i, j]*, is a pixel color value in the range [0,255].
  prefs: []
  type: TYPE_NORMAL
- en: Image rasterization
  prefs: []
  type: TYPE_NORMAL
- en: In the previous chapters, we have always seen a *vector* as the input to a machine
    learning system. The vector representation of the input allowed us to view it
    as a point in a high-dimensional space. This led to many geometric insights about
    classification. But here, our input is an image, which is akin to a *matrix* rather
    than a vector. Can we represent an image (matrix) as a vector?
  prefs: []
  type: TYPE_NORMAL
- en: The answer is yes. A matrix can always be converted into a vector by a process
    called *rasterization*. During rasterization, we iterate over the elements of
    the matrix from left to right and top to bottom, storing successive encountered
    elements into a vector. The result is the rasterized vector. It has the same elements
    as the original matrix, but they are organized differently. The length of the
    rasterized vector is equal to the product of the row count and column count of
    the matrix. The rasterized vector for the earlier matrix *X* has 224 × 224 = 50176
    elements
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-00-b.png)'
  prefs: []
  type: TYPE_IMG
- en: where *x[i]* ∈ [0,255] are values of the image pixels. Thus, a 224 × 224 input
    image can be viewed as a vector (equivalently, a point) in a 50, 176-dimensional
    space.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.2 Classifiers as decision boundaries
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We see that input images can be converted to vectors via rasterization. Each
    vector can be viewed as a point in a high-dimensional space. But the points corresponding
    to any given object or class, say *giraffe* or *car*, are not distributed randomly
    all over the space. Rather, they occupy a small portion subspace) in the vast
    high-dimensional space of inputs. This is because there is always inherent commonality
    in members of a class. For instance, all giraffes are predominantly yellow with
    a bit of black, and cars have a somewhat fixed shape. This causes the pixel values
    in images containing the same object to have somewhat similar values. Overall,
    this means points belonging to a class loosely form a *cluster*.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE Geometrically speaking, a classifier is a hypersurface that separates the
    point clusters for the classes we want to recognize. This surface forms a *decision
    boundary*—the decision about which class a specific input point belongs to is
    made by looking at which side of the surface the point belongs to.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F01a_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Car vs. giraffe classifier
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F01b_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Horse vs. zebra classifier
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.1 Geometric depiction of a classification problem. In the multidimensional
    input space, each data instance corresponds to a point. In figure [3.1a](#fig-classifier_diagram),
    the points marked *c* denote cars, and points marked *g* denote giraffes. This
    is a simple case: the points form reasonably distinct clusters, so the classification
    can be done with a relatively simple surface, a hyperplane. The exact parameters
    of the hyperplane—orientation and position—are determined via training. In figure
    [3.1b](#fig-classifier_diagram), the points marked *h* denote horses, and those
    marked *z* denote zebras. This case is a bit more difficult: the classification
    has to be done with a curved (nonplanar) surface, a hypersphere. The parameters
    of the hypersphere—radius and center—are determined via training.'
  prefs: []
  type: TYPE_NORMAL
- en: Figure [3.1a](#fig-classifier_diagram) shows an example of a rasterized space
    for the giraffe and car classification problem. The points corresponding to a
    giraffe are marked *g*, and those corresponding to a car are marked *c*. This
    is a simple case. Here, the classifier surface (aka decision boundary) that separates
    the cluster of points corresponding to *car* from those corresponding to *giraffe*
    is a hyperplane, depicted in figure [3.1a](#fig-classifier_diagram).
  prefs: []
  type: TYPE_NORMAL
- en: NOTE We often call surfaces *hypersurfaces* and planes *hyperplanes* in greater
    than three dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure [3.1b](#fig-classifier_diagram) shows a more difficult example: horse
    and zebra classification in images. Here the points corresponding to horses are
    marked *h* and those corresponding to zebras are marked *z*. In this example,
    we need a nonlinear (curved) surface (such as a hypersphere) to separate the two
    classes.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.3 Modeling in a nutshell
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unfortunately, in the typical scenario, we do not know the separating surface.
    In fact, we do not even know all the points belonging to a class of interest.
    All we know is a *sampled* set of inputs ![](../../OEBPS/Images/AR_x.png)*[i]*
    (training inputs) and corresponding classes *![](../../OEBPS/Images/AR_y2.png)[i]*
    (the ground truth). The complete set of training inputs plus ground truth—{*![](../../OEBPS/Images/AR_x.png)[i],
    ![](../../OEBPS/Images/AR_y2.png)[i]*} for a large set of *i* values—is called
    the *training data*. When we want to teach a baby to recognize a car, we show
    the baby several example cars and say “This is a car.” The training data plays
    the same role for a neural network.
  prefs: []
  type: TYPE_NORMAL
- en: From only this training dataset {*![](../../OEBPS/Images/AR_x.png)[i], ![](../../OEBPS/Images/AR_y2.png)[i]*}
    ∀*[i] ∈* [1, *n*], we have to identify a good enough approximation of the general
    classifying surface that when presented with a random scene, we can map it to
    an input point ![](../../OEBPS/Images/AR_x.png), check which side of the surface
    that point lies on, and identify the class (car or giraffe). This process of developing
    a best guess for a surface that forms a decision boundary between various classes
    of interest is called *modeling the classifier*.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE The ground truth labels (*![](../../OEBPS/Images/AR_y2.png)[i]*) for the
    training images ![](../../OEBPS/Images/AR_x.png)*[i]* are often created manually.
    This process of manually generating labels for the training images is one of the
    most painful aspects of machine learning, and significant research effort is going
    on at the moment to mitigate it.
  prefs: []
  type: TYPE_NORMAL
- en: 'As indicated in section [1.3](../Text/01.xhtml#sec-cat_brain), modeling has
    two steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Model architecture selection*: Choose the parametric model function *ϕ*(![](../../OEBPS/Images/AR_x.png); ![](../../OEBPS/Images/AR_w.png),
    *b*). This function takes an input vector ![](../../OEBPS/Images/AR_x.png) and
    emits the class *y*. It has a set of parameters ![](../../OEBPS/Images/AR_w.png),
    *b*, which are unknown at first. This function is typically chosen from a bank
    of well-known functions that are tried and tested; for simple problems, we may
    choose a linear model, and for more complex problems, we choose nonlinear models.
    The model designer makes the choice based on their understanding of the problem.
    Remember, at this point the parameters are still unknown—we have only decided
    on the *function family* for the model.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Model training*: Estimate the parameters ![](../../OEBPS/Images/AR_w.png),
    *b* such that *ϕ* emits the known correct output (as closely as possible) on the
    training data inputs. This is typically done via an iterative process. For each
    training data instance ![](../../OEBPS/Images/AR_x.png)[i], we evaluate *y**[i]*
    = *ϕ*(![](../../OEBPS/Images/AR_x.png)*[i ]*;![](../../OEBPS/Images/AR_w.png),
    *b*). This emitted output is compared with the corresponding known outputs *ȳ[i]*.
    Their difference, *e[i]* = ||*y**[i]* − *ȳ[i]*||, is called the *training error*.
    The sum of training errors over all training data is the aggregate training error.
    We iteratively adjust the parameters ![](../../OEBPS/Images/AR_w.png), *b* such
    that the aggregate training error keeps going down. This means at each iteration,
    we adjust the parameters so the model output *y**[i]* moves a little closer to
    the target output *ȳ[i]* for all *i*. Exactly how to adjust the parameters to
    reduce the error forms the bulk of this chapter and will be introduced in section
    [3.3](../Text/03.xhtml#sec-grad).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The function *ϕ*(![](../../OEBPS/Images/AR_x.png); ![](../../OEBPS/Images/AR_w.png),
    *b*) represents the decision boundary hypersurface. For example, in the binary
    classification problem depicted in figure [3.1](#fig-classifier_diagram), *ϕ*(![](../../OEBPS/Images/AR_x.png); ![](../../OEBPS/Images/AR_w.png),
    *b*) may represent a plane (shown by the dashed line). Points on one side of the
    plane are classified as cars, while points on the other side are classified as
    giraffes. Here,
  prefs: []
  type: TYPE_NORMAL
- en: '*ϕ*(![](../../OEBPS/Images/AR_x.png); ![](../../OEBPS/Images/AR_w.png), *b*)
    = ![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png) + *b*'
  prefs: []
  type: TYPE_NORMAL
- en: From equation [2.14](02.xhtml#eq-plane-1) we know this equation represents a
    plane.
  prefs: []
  type: TYPE_NORMAL
- en: In figure [3.1b](#fig-classifier_diagram), a good planar separation does not
    exist—we need a nonlinear separator, such as the spherical separator shown with
    dashed lines. Here,
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-00-c.png)'
  prefs: []
  type: TYPE_IMG
- en: This equation represents a sphere.
  prefs: []
  type: TYPE_NORMAL
- en: It should be noted that in typical real-life cases, the separating surface does
    not correspond to any known geometric surface (see figure [3.2](#fig-real_life_classifier_diagram)).
    But in this chapter, we will continue to use simple examples to bring out the
    underlying concepts.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F02_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.2 In real-life problems, the surface is often not a well-known surface
    like a plane or sphere. And often, the classification is not perfect—some points
    fall on the wrong side of the separator.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.4 Sign of the surface function in binary classification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the special case of binary classifiers, the *sign* of the expression *ϕ*(![](../../OEBPS/Images/AR_x.png);![](../../OEBPS/Images/AR_w.png),
    *b*) representing the decision boundary has a special significance. To see this,
    consider a line in a 2D plane corresponding to the equation
  prefs: []
  type: TYPE_NORMAL
- en: '*y* + 2*x* + 1 = 0'
  prefs: []
  type: TYPE_NORMAL
- en: All points *on* the line have *x*, *y* coordinate values satisfying this equation.
    The line divides the 2D plane into two half planes. All points on one half plane
    have *x*, *y* values such that *y* + 2*x* + 1 is negative. All points in the other
    half plane have *x*, *y* values such that *y* + 2*x* + 1 is positive. This is
    shown in figure [3.3](#fig-line_sign). This idea can be extended to other surfaces
    and higher dimensions. Thus, in binary classification, once we have estimated
    an optimal decision surface *ϕ*(![](../../OEBPS/Images/AR_x.png); ![](../../OEBPS/Images/AR_w.png),
    *b*), given any input vector ![](../../OEBPS/Images/AR_x.png), we can compute
    the sign of *ϕ*(![](../../OEBPS/Images/AR_x.png); ![](../../OEBPS/Images/AR_w.png),
    *b*) to predict the class.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F03_Chaudhury.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.3 Given a point (*x*[0], *y*[0]) and a separator *y* + 2*x* + 1 = 0,
    we can tell which side of the separator the point lies on from the sign of *y*[0]
    + 2*x*[0] + 1.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Error, aka loss function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As stated earlier, during training, we adjust the parameters ![](../../OEBPS/Images/AR_w.png),
    *b* so that the error keeps going down. Let’s derive a quantitative expression
    for this error aka loss function). Later, we will see how to minimize it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Overall, training data consists of a set of labeled inputs (training data instances
    paired with known ground truths):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-00-d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now we define a *loss function*. On a specific training data instance, the
    loss function effectively measures the error made by the machine on that particular
    training data—input-target pair (![](../../OEBPS/Images/AR_x.png)^((*i*)), *y*^((*i*))).
    Although there are many sophisticated error functions more suitable for this problem,
    for now, let’s use a squared error function for the sake of simplicity (introduced
    in section [2.5.4](02.xhtml#subsection-vector_length)). The squared error on the
    *i*th training data element is the squared difference between the output yielded
    by the model and the expected or target output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-01.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 3.1
  prefs: []
  type: TYPE_NORMAL
- en: The total loss (aka squared error) during training is
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-02.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 3.2
  prefs: []
  type: TYPE_NORMAL
- en: Note that this total error is not a function of any specific training data instance.
    Rather, it is the *overall error over the entire training data set*. This is what
    we minimize by adjusting ![](../../OEBPS/Images/AR_w.png) and *b*. To be precise,
    we estimate the ![](../../OEBPS/Images/AR_w.png) and *b* that will minimize *L*(![](../../OEBPS/Images/AR_w.png),
    *b*).
  prefs: []
  type: TYPE_NORMAL
- en: '3.3 Minimizing loss functions: Gradient vectors'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The goal of training is to estimate the weights and bias parameter ![](../../OEBPS/Images/AR_w.png),
    *b* that will minimize *L*. This is usually done by an iterative process. We start
    with random values of ![](../../OEBPS/Images/AR_w.png), *b* and adjust these values
    so that the loss *L*(![](../../OEBPS/Images/AR_w.png), *b*) = *E*²(![](../../OEBPS/Images/AR_w.png),
    *b*) declines rapidly. Doing this many times is likely to take us close to the
    optimal values for ![](../../OEBPS/Images/AR_w.png), *b*. This is the essential
    idea behind the process of training a model. It is important to note that we are
    minimizing the total error: this prevents us from over-indexing on any particular
    training instance. If the training data is a well-sampled set, the parameters
    ![](../../OEBPS/Images/AR_w.png), *b* that minimize loss over the training dataset
    will also work well during inferencing.'
  prefs: []
  type: TYPE_NORMAL
- en: How do we “adjust” ![](../../OEBPS/Images/AR_w.png), *b* so that the value of
    loss *L* = *E*² declines? This is where gradients come in. For any function *L*(![](../../OEBPS/Images/AR_w.png),
    *b*), the gradient with respect to ![](../../OEBPS/Images/AR_w.png), *b*—that
    is, ∇[![](../../OEBPS/Images/AR_w.png), *b*]*L*(![](../../OEBPS/Images/AR_w.png),
    *b*)—indicates the direction along which the maximum change in *L* occurs. The
    gradient is the analog of a derivative in 1D calculus. Intuitively, going down
    along the direction of the gradient of a function seems like the best strategy
    for minimizing the function value.
  prefs: []
  type: TYPE_NORMAL
- en: Geometrically speaking, if we start at an arbitrary point on the surface corresponding
    to *L*(![](../../OEBPS/Images/AR_w.png), *b*) and move along the direction of
    the gradient ∇[![](../../OEBPS/Images/AR_w.png), *b*]*L*(![](../../OEBPS/Images/AR_w.png),
    *b*), we will go toward the minimum at the fastest rate (this is discussed in
    detail throughout the rest of this section). Hence, during training, we iteratively
    move toward the minimum by taking steps along ∇[![](../../OEBPS/Images/AR_w.png),
    *b*]*L*(![](../../OEBPS/Images/AR_w.png), *b*). Note that *the gradient is with
    respect to weights, not the input*. The overall algorithm is shown in algorithm
    [3.2](../Text/03.xhtml#alg-supervised_training_detailed).
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 3.2 Training a supervised model (overall idea)
  prefs: []
  type: TYPE_NORMAL
- en: Initialize ![](../../OEBPS/Images/AR_w.png), *b* with random values
  prefs: []
  type: TYPE_NORMAL
- en: '**while** *L*(![](../../OEBPS/Images/AR_w.png), *b*) > *threshold* **do**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-02-a.png)'
  prefs: []
  type: TYPE_IMG
- en: Recompute *L* on new ![](../../OEBPS/Images/AR_w.png), *b*.
  prefs: []
  type: TYPE_NORMAL
- en: '**end** **while**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/AR_w.png)[*] ← ![](../../OEBPS/Images/AR_w.png), *b*[*]
    ← *b*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Note the following points:'
  prefs: []
  type: TYPE_NORMAL
- en: In each iteration, we are adjusting ![](../../OEBPS/Images/AR_w.png), *b* along
    the gradient of the error function. We will see in section [3.3](../Text/03.xhtml#sec-grad)
    that this is the direction of maximum change for *L*. Thus, *L* is reduced at
    a maximal rate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*μ* is the learning rate: larger values imply longer steps, and smaller values
    imply shorter steps. The simplest approach, outlined in algorithm [3.2](../Text/03.xhtml#alg-supervised_training_detailed),
    takes equal-sized steps everywhere. In later chapters, we will study more sophisticated
    approaches where we try to sense how close to the minimum we are and vary the
    step size accordingly:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We take longer steps when far from the minimum, to progress quickly.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We take shorter steps when near the minimum, to avoid overshooting it.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Mathematically, we should keep iterating until the loss becomes minimal (that
    is, the gradient of the loss is zero). But in practice, we simply iterate until
    the accuracy is good enough for the purpose at hand.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '3.3.1 Gradients: A machine learning-centric introduction'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In machine learning, we model the output as a parametric function of the inputs.
    We define a loss function that quantifies the difference between the model output
    and the known ideal output on the set of training inputs. Then we try to obtain
    the parameter values that will minimize this loss. This effectively identifies
    the parameters that will result in the model function emitting outputs as close
    as possible to the ideal on the set of training inputs.
  prefs: []
  type: TYPE_NORMAL
- en: The loss function depends on ![](../../OEBPS/Images/AR_x.png) (the model inputs),
    *ȳ* (the known ideal outputs on the training data—aka ground truth), and ![](../../OEBPS/Images/AR_w.png)
    (the parameters). Here only the behavior of the loss function with respect to
    the parameters is of interest to us, so we are ignoring everything else and denoting
    the loss function as a function of the parameters as *L*(![](../../OEBPS/Images/AR_w.png)).
  prefs: []
  type: TYPE_NORMAL
- en: NOTE For the sake of brevity, here we use the symbol *w* to denote all parameters—weight
    as well as bias.
  prefs: []
  type: TYPE_NORMAL
- en: 'The core question we are trying to answer is this: given a loss *L*(![](../../OEBPS/Images/AR_w.png))
    and current parameter values ![](../../OEBPS/Images/AR_w.png), what is the optimal
    change in the parameters ![](../../OEBPS/Images/AR_delta.png) that maximally reduces
    the loss? Equivalently, we want to determine ![](../../OEBPS/Images/AR_delta.png)
    that will make *δL* = *L*(![](../../OEBPS/Images/AR_w.png) + ![](../../OEBPS/Images/AR_delta.png))
    - *L*(![](../../OEBPS/Images/AR_w.png)) as negative as possible. Toward that goal,
    we will study the relationship between the loss function *L*(*w*) and change in
    parameter values ![](../../OEBPS/Images/AR_delta.png) in several scenarios of
    increasing complexity.[¹](#fn9)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F04a_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: '(a) Line: *L*(*w*) = 2*w* + 1, *dL*/*dw* = *m*'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F04b_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: '(b) Parabola: *L*(*w*) = *w*², *dL*/*dw* = 2*w*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.4 *δL* in terms of *δw* in one dimension, illustrated with two example
    curves: a straight line and a parabola. In general, *δL* = (*dL*/*dw)* *δw*. To
    decrease loss, *δw* must have the opposite sign of the derivative *dL*/*dw*. In
    (a), this implies we always have to move left (decrease *w*) to decrease *L*.
    In (b), if we are in the left half (e.g., point Q), the derivative is negative,
    and we have to move to the right to decrease *L*. But if we are in the right half,
    the derivative is positive, and we have to move to the left to decrease *L*. Geometrically,
    this is equivalent to following the tangent “downward.”'
  prefs: []
  type: TYPE_NORMAL
- en: One-dimensional loss functions
  prefs: []
  type: TYPE_NORMAL
- en: 'For simplicity, we begin by examining this topic in one dimension—meaning there
    is a single parameter *w*. The first example we will study is the simplest possible
    case: a linear one-dimensional loss function, shown in figure [3.5](#fig-line_tangent).
    A linear loss function in one dimension can be written as *L*(*w*) = *mw* + *c*.
    If we change the parameter *w* by a small amount *δw*, what is the corresponding
    change in loss *δL*? We have *δL* = *L*(*w* + *δw*) − *L*(*w*) = (*m*(*w* + *δw*)+*c*)
    − (*m*(*w*)+*c*) = *m* *δw* which gives us *δL*/*δw* = *m*, a constant. By definition,
    the derivative *dL*/*dw* = lim[*δw*→0] *δL*/*δw*, which leads to *dL*/*dw* = *m*.
    Thus, for the straight line *L*(*w*) = *mw* + *c*, the rate of change of *L* with
    respect to *w* is constant everywhere and equals the slope *m*. Putting all this
    together, we get *δL* = *m δw* = *dL*/*dw* *δw*.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now study a slightly more complex, non-linear but still one dimensional
    case—a parabolic loss function illustrated in figure [3.4](#fig-parabola_tangent).
    This parabola can be written as *L*(*w*) = *w*². If we change the parameter *w*
    by a small amount *δw*, what is the corresponding change in in loss *δL*? We have
    *δL* = *L*(*w* + *δw*) − *L*(*w*) = (*w* + *δw*)² − *w*² = (2*wδw* + *δw*²). For
    infinitesimally small *δw*, *δw*² becomes negligibly small and we get lim[*δw*→0]
    *δL* = lim[*δw*→0] (2*wδw* + *δw*²) = 2*wδw* and *dL*/*dw* = lim[*δw*→0] *δL*/*δw*
    = 2w. Combining all these we get the same equation as the linear case *δL* = *dL*/*dw*
    *δw*. Of course, in case of the straight line this expression holds for all *δw*
    while in the non-linear curves the expression holds only for small *δw*.
  prefs: []
  type: TYPE_NORMAL
- en: '*δL* and *δw*'
  prefs: []
  type: TYPE_NORMAL
- en: 'In general, for all one-dimensional loss functions *L*(*w*), the change *δL*
    caused by a change *δw* in parameters can be expressed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-03.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 3.3
  prefs: []
  type: TYPE_NORMAL
- en: To decrease *L*, *δL* must be negative. From equation [3.3](#eq-derivative_total_change),
    we can see that this requires *δw* (change in *w*) and *dL*/*dw* (derivative)
    to have opposite signs.
  prefs: []
  type: TYPE_NORMAL
- en: Geometrically speaking, the loss function represents a curve with the loss *L*(*w*)
    plotted along the *Y* axis against the parameter *w* plotted along the *X* axis
    (see figure [3.4](#fig-tangent-1d) for examples). The tangent at any point can
    be viewed as the local approximation to the curve itself for an infinitesimally
    small neighborhood around the point. The derivative at any point represents the
    slope of the tangent to the curve at that point.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE Equation [3.3](#eq-derivative_total_change) basically tells us that to
    reduce the loss value, we have to follow the tangent, moving to the right (i.e.,
    positive *δw*) if the derivative is negative and moving to the left (i.e., negative
    *δw*) if the derivative is positive.
  prefs: []
  type: TYPE_NORMAL
- en: Multidimensional loss functions
  prefs: []
  type: TYPE_NORMAL
- en: If there are many tunable parameters, our loss function will be a function of
    many variables, which implies that we have a high-dimensional vector ![](../../OEBPS/Images/AR_w.png)
    and a loss function *L*(![](../../OEBPS/Images/AR_w.png)). Our goal is to compute
    the change *δL* in *L*(![](../../OEBPS/Images/AR_w.png)) caused by a small vector
    displacement ![](../../OEBPS/Images/AR_delta.png).
  prefs: []
  type: TYPE_NORMAL
- en: 'We immediately note a fundamental difference from the one-dimensional case:
    the parameter change is a vector, ![](../../OEBPS/Images/AR_delta.png), which
    has not only a magnitude denoted ||![](../../OEBPS/Images/AR_delta.png)|| but
    also a direction denoted by the unit vector ![](../../OEBPS/Images/AR_bw_hat.png).
    We can take a step of the same size in the *w* space, and the change in *L*(![](../../OEBPS/Images/AR_w.png))
    will be different for different directions. The situation is illustrated in figure
    [3.5](#fig-surface_gradient), which shows an example loss function *L*(![](../../OEBPS/Images/AR_w.png))
    ≡ *L*(*w*[0], *w*[1]) = 2*w*[0]² + 3*w*[1]² for two independent variables *w*[0]
    and *w*[1]. Let’s examine how this loss function changes with a few concrete examples.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F05_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.5 Plot for surface *L*(![](../../OEBPS/Images/AR_w.png)) ≡ *L*(*w*[0],
    *w*[1]) = 2*w*[0]² + 3*w*[1]² against ![](../../OEBPS/Images/AR_w.png) ≡ (*w*[0],
    *w*[1]). From an example point *P* ≡ (*w*[0]=3, *w*[1]=4, *L* = 66) on the surface,
    we can travel in many directions to reduce *L*. Some of these are shown byarrows.
    The maximum reduction occurs when we travel along the dark arrow: this happens
    when ![](../../OEBPS/Images/AR_w.png) is changed along ![](../../OEBPS/Images/AR_delta.png)
    = [-12, -24]*^T*, which is the negative of the gradient of *L*(![](../../OEBPS/Images/AR_w.png))
    at *P*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose we are at ![](../../OEBPS/Images/eq_03-03-a.png). The corresponding
    value of *L*(![](../../OEBPS/Images/AR_w.png)) is 2 ∗ 3² + 3 ∗ 4² = 66. Now, suppose
    we undergo a small displacement from this point: ![](../../OEBPS/Images/eq_03-03-b.png).
    The new value is *L*(![](../../OEBPS/Images/AR_w.png) + ![](../../OEBPS/Images/AR_delta.png))
    = *L*(3.0003, 4.0004) = 2 ∗ 3.0003² + 3 ∗ 4.0004² ≈ 66.0132066. Thus this displacement
    vector ![](../../OEBPS/Images/eq_03-03-b.png) causes a change *δL* = 66.01320066
    – 66 = 0.01320066 in *L*.'
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, if the displacement is ![](../../OEBPS/Images/eq_03-03-c.png),
    we get *L*(![](../../OEBPS/Images/AR_w.png) + ![](../../OEBPS/Images/AR_delta.png))
    = *L*(3.0004, 4.0003) = 2 ∗ 3.0004² + 3 ∗ 4.0003² ≈ 66.0120006. Thus, this displacement
    causes a change *δL* = 66.0120006 − 66 = 0.0120006 in *L*. The displacement ![](../../OEBPS/Images/eq_03-03-b.png)
    and ![](../../OEBPS/Images/eq_03-03-c.png) have the same length ![](../../OEBPS/Images/eq_03-03-d.png)
    but different directions. The change they cause to the function value is different.
    This exemplifies our thesis that in multivariable loss function, the change in
    the loss function depends not only on the magnitude but also on the direction
    of the displacement in the parameter space.
  prefs: []
  type: TYPE_NORMAL
- en: What is the general relationship between the displacement vector ![](../../OEBPS/Images/AR_delta.png)
    in the parameter space and the overall change in loss *L*(![](../../OEBPS/Images/AR_w.png))?
    To examine this question, we need to know what a partial derivative is.
  prefs: []
  type: TYPE_NORMAL
- en: Partial derivatives
  prefs: []
  type: TYPE_NORMAL
- en: The derivative *dL*/*dw* of a function *L*(*w*) indicates the rate of change
    of the function with respect to *w*. But if *L* is a function of many variables,
    how does it change if only one of those variables is changed? This question leads
    to the notion of partialderivatives.
  prefs: []
  type: TYPE_NORMAL
- en: The *partial derivative* of a function of many variables is a derivative taken
    with respect to exactly one variable, treating all other variables as constants.
    For instance, given *L*(![](../../OEBPS/Images/AR_w.png)) ≡ *L*(*w*[0], *w*[1])
    = 2*w*[0]² + 3*w*[1]², the partial derivatives with respect to *w*[0] , *w*[1]
    are
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-03-e.png)'
  prefs: []
  type: TYPE_IMG
- en: Total change in a multidimensional function
  prefs: []
  type: TYPE_NORMAL
- en: Partial derivatives estimate the change in a function if a single variable changes
    and the others stay constant. How do we estimate the change in a function’s value
    if all the variables change together?
  prefs: []
  type: TYPE_NORMAL
- en: 'The total change can be estimated by taking a weighted combination of the partial
    derivatives. Let ![](../../OEBPS/Images/AR_w.png) and ![](../../OEBPS/Images/AR_delta.png)
    denote the point and the displacement vector, respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-03-f.png)'
  prefs: []
  type: TYPE_IMG
- en: Then
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-04.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 3.4
  prefs: []
  type: TYPE_NORMAL
- en: 'Equation [3.4](#eq-partial_deriv_total_change) essentially says that the total
    change in *L* is obtained by adding up the changes caused by displacements in
    individual variables. The rate of change of *L* with respect to the change in
    *w[i]* only is *∂L*/*∂w[i]*. The displacement along the variable *w[i]* is *δw[i]*.
    Hence, the change caused by the *i*th element of the displacement is *∂L*/*∂w[i]*
    *δw[i]*— this follows from equation [3.3](#eq-derivative_total_change). The total
    change is obtained by adding the changes caused by individual elements of the
    displacement vector: that is, summing over all *i* from 0 to *n*. This leads to
    equation [3.4](#eq-partial_deriv_total_change). Thus equation [3.4](#eq-partial_deriv_total_change)
    is simply the multidimensional version of equation [3.3](#eq-derivative_total_change).'
  prefs: []
  type: TYPE_NORMAL
- en: Gradients
  prefs: []
  type: TYPE_NORMAL
- en: 'It would be nice to be able to represent equation [3.4](#eq-partial_deriv_total_change)
    compactly. To do this, we define a quantity called a *gradient*: the vector of
    all the partial derivatives.'
  prefs: []
  type: TYPE_NORMAL
- en: Given an *n*-dimensional function *L*(![](../../OEBPS/Images/AR_w.png)), its
    gradient is defined as
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-05.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 3.5
  prefs: []
  type: TYPE_NORMAL
- en: Using gradients, we can rewrite equation [3.4](#eq-partial_deriv_total_change)
    as
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-06.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 3.6
  prefs: []
  type: TYPE_NORMAL
- en: Equation [3.6](#eq-gradient_total_change) tells us that the total change, *δL*
    in *L*(![](../../OEBPS/Images/AR_w.png)), caused by displacement ![](../../OEBPS/Images/AR_delta.png)
    from ![](../../OEBPS/Images/AR_w.png) in parameter space is the dot product between
    the gradient vector ∇*L*(![](../../OEBPS/Images/AR_w.png)) and the displacement
    vector ![](../../OEBPS/Images/AR_delta.png). This is the exact multidimensional
    analog of equation [3.3](#eq-derivative_total_change).
  prefs: []
  type: TYPE_NORMAL
- en: 'Recall from section [2.5.6.2](02.xhtml#subsubsec-dotproduct_as_agreement) that
    the dot product of two vectors (of fixed magnitude) attains a maximum value when
    the vectors are aligned in direction. This yields a physical interpretation of
    the gradient vector: its direction is the direction in parameter space *along
    which the multidimensional function is changing fastest*. It is the multidimensional
    counterpart of the derivative. This is why, in machine learning, when we want
    to minimize the loss function, we change the parameter values along the direction
    of the gradient vector of the loss function.'
  prefs: []
  type: TYPE_NORMAL
- en: The gradient is zero at the minimum
  prefs: []
  type: TYPE_NORMAL
- en: 'any *optimum* (that is, maximum or minimum) of a function is a point of inflection.
    This means the function turns around at the optimum point. In other words, the
    gradient direction on one side of the optimum is the opposite of that on the other
    side. If we try to travel smoothly from positive values to negative values, we
    must cross zero somewhere in between. Thus, the gradient is zero at the exact
    point of inflection maximum or minimum). This is easiest to see in 2D and is depicted
    in figure [3.6](#fig-gradient_zero_at_minima). However, the idea is general: it
    works in higher dimensions, too. The fact that the gradient becomes zero at the
    optimum is often used to algebraically compute the optimum. The following example
    illustrates this.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F06_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.6 The minimum is always a point of inflection, meaning the function
    turns around at that point. If we consider any two points *P*[−] and *P* [+] on
    both sides of the minimum, the gradient is positive on one side and negative on
    the other. Assuming the gradient changes smoothly, it must be zero in between,
    at the minimum.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the simple example function *L*(*w*[0], *w*[1]) = √*w*[0]² + *w*[1]².
    Its optimum occurs when its gradient is zero:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-06-a.png)'
  prefs: []
  type: TYPE_IMG
- en: The solution is *w*[0] = 0, *w*[1] = 0 The function attains its minimum value
    at the origin, which agrees with our intuition.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.2 Level surface representation and loss minimization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In figure [3.5](#fig-surface_gradient), we plotted the loss function *L*(![](../../OEBPS/Images/AR_w.png))
    against the parameter values ![](../../OEBPS/Images/AR_w.png). In this section,
    we study a different way of visualizing loss surfaces. This will lend further
    insight into gradients and minimization.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will continue with our simple example function from the last subsection.
    Consider a field *L*(*w*[0], *w*[1]) = √(*w*[0]² + *w*[1]²). Its domain is the
    infinite 2D plane defined by the axes *W*[0] and *W*[1]. Note that the function
    has constant values along concentric circles centered on the origin. For instance,
    at all points on the circumference of the circle *w*[0]² + *w*[1]² = 1, the function
    has a constant function value of 1. At all points on the circumference of the
    circle *w*[0]² + *w*[1]² = 25, the function has a constant function value of 5.
    Such constant function value curves on the domain are called *level contours*
    in 2D. This is shown as a heat map in figure [3.7](#fig-circle-field-2D). The
    idea of level contours can be generalized to higher dimensions where we have level
    surfaces or level hypersurfaces. Note that while the ![](../../OEBPS/Images/AR_w.png),
    *L*(![](../../OEBPS/Images/AR_w.png)) in figure [3.5](#fig-surface_gradient) was
    on an (*n*+1)-dimensional space (where *n* is the dimensionality of ![](../../OEBPS/Images/AR_w.png)),
    the level surface/contour representation is in *n*-dimensional space. At any point
    on the domain, what is the direction along which the biggest *change* in the function
    value occurs? The answer is *along the direction of the gradient*. The magnitude
    of the change corresponds to the magnitude of the gradient. In the current example,
    say we are at a point (*w*[0], *w*[1]). There exists a level contour through this
    point: the circle with origin at the center passing through (*w*[0], *w*[1]).
    If we move along the circumference of this circle—that is, along the tangent to
    this circle—the function value does not change. In other words, at any point,
    the tangent to the level contour through that point is the direction of *minimal*
    change. On the other hand, *if we move perpendicular to the tangent, maximum change
    in the function value occurs*. The perpendicular to the tangent is known as a
    *normal*. This is the direction of the gradient. *The gradient at any point on
    the domain is always normal to the level contour through that point, indicating
    the direction of maximum change in the function value*. In figure [3.7](#fig-circle-field-2D),
    the gradients are all parallel to the radii of the concentric circles.'
  prefs: []
  type: TYPE_NORMAL
- en: Recall that while training a machine learning model, we essentially define a
    loss function in terms of a tunable set of parameters and try to minimize the
    loss by adjusting (tuning) the parameters. We start at a random point and iteratively
    progress toward the minimum. Geometrically, this can be viewed as starting at
    an arbitrary point on the domain and continuing to move in a direction that minimizes
    the function value. Of course, we would like to progress to the minimum of the
    function value in as few iterations as possible. In figure [3.7](#fig-circle-field-2D),
    the minimum is at the origin, which is also the center of all the concentric circles.
    Wherever we start, we will have to always travel radially inward to reach the
    minimum (0,0) of the function √(*w*[0]² + *w*[1]²).
  prefs: []
  type: TYPE_NORMAL
- en: 'In higher dimensions, level contours become level surfaces. Given any function
    *L*(![](../../OEBPS/Images/AR_w.png)) with ![](../../OEBPS/Images/AR_w.png)] ∈
    ℝ*^n*, we define level surfaces as *L*(![](../../OEBPS/Images/AR_w.png)) = *constant*.
    If we move along the level surface, the change in *L*(![](../../OEBPS/Images/AR_w.png))
    is minimal (0). The gradient of a function at any point is normal to the level
    surface through that point. This is the direction along which the function value
    is changing fastest. Moving along the gradient, we pass from one level surface
    to another, as shown in figure [3.8](#fig-grad_sphere). Here the function is 3D:
    *L*(![](../../OEBPS/Images/AR_w.png)) = *L*(*w*[0], *w*[1], *w*[2]) = *w*[0]²
    + *w*[1]² + *w*[2]². The level surfaces *w*[0]² + *w*[1]² + *w*[2]² = *constant*
    for various values of the constant are concentric spheres, with the origin as
    their center. The gradient vector at any point is along the outward-pointing radius
    of the sphere through that point.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F07_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.7 The domain of *L*(*w*[0], *w*[1]) = √(*w*[0]² + *w*[1]²) shown as
    a heat map of function values. Gradients point radially outward, as shown by the
    arrowed line. The intensity of the heat map changes fastest along the gradient
    (that is, radii). This is the direction to follow to rapidly reach lower values
    of the function represented by the heat map.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F08_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.8 Gradient example in 3D: the function *L*(*w*[0], *w*[1], *w*[2])
    = *L*(![](../../OEBPS/Images/AR_w.png)) = *w*[0]² + *w*[1]² + *w*[2]². The levelsurfaces
    *L*(![](../../OEBPS/Images/AR_w.png)) = *constant* are concentric spheres with
    the origin as their center. One such surface is partially shown in the diagram.
    ∇*L*(![](../../OEBPS/Images/AR_w.png)) = *k*[*w*[0] *w*[1] *w*[2]]*^T*—the gradient
    points radially outward. along the gradient, we go from one level surface to another,
    corresponding to maximum change in *L*(![](../../OEBPS/Images/AR_w.png)). Moving
    along any direction orthogonal to the gradient, we stay on the same level surface
    (sphere), which corresponds to zero change in the function value. *D[θ]*(![](../../OEBPS/Images/AR_w.png))
    denotes the directional derivative along the displacement direction making angle
    *θ* with the gradient. If *l̂* denotes this displacement direction, *D[θ]*(![](../../OEBPS/Images/AR_w.png))
    = ∇*L*(![](../../OEBPS/Images/AR_w.png)) ⋅ *l̂*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another example is shown in figure [3.9](#fig-grad_cylinder). Here the function
    is 3D: *L*(![](../../OEBPS/Images/AR_w.png)) = *f*(*w*[0], *w*[1], *w*[2]) = *w*[0]²
    + *w*[1]². The level surfaces *w*[0]² + *w*[1]² = *constant* for various values
    of the constant are coaxial cylinders, with *w*[2] as the axis. The gradient vector
    at any point is along the outward-pointing radius of the planar circle belonging
    to the cylinder through that point.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F09_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.9 Gradient example in 3D: the function *L*(*w*[0], *w*[1], *w*[2])
    = *L*(![](../../OEBPS/Images/AR_w.png)) = *w*[0]² + *w*[1]². The level surfaces
    *f*(![](../../OEBPS/Images/AR_w.png)) = *constant* are coaxial cylinders. One
    such surface is partially shown in the diagram: ∇*L*(![](../../OEBPS/Images/AR_w.png))
    = *k*[*w*[0] *w*[1] 0]*^T*. The gradient is normal to the curved surface of the
    cylinder along the outward radiusof the circle. Moving along the gradient, we
    go from one level surface to another, corresponding to themaximum change in *L*(![](../../OEBPS/Images/AR_w.png)).
    Moving along any direction orthogonal to the gradient, we stay on thesame level
    surface (cylinder), which corresponds to zero change in the function value.'
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have studied the change in loss value resulting from infinitesimally
    small displacements in the parameter space. In practice, the programmatic displacements
    undergone during parameter updates while training are small, but not infinitesimally
    so. Is there any way to improve the approximation in these cases? This is discussed
    in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Local approximation for the loss function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Equation [3.6](#eq-gradient_total_change) expresses the change *δL* in the
    loss value corresponding to displacement ![](../../OEBPS/Images/AR_delta.png)
    in the parameter space. The equation is exactly true if and only if the loss function
    is linear or the magnitude of the displacement is infinitesimally small. In practice,
    we adjust parameter values by small—but not infinitesimally small—amounts. Under
    these circumstances, equation [3.6](#eq-gradient_total_change) is only approximately
    true: the larger the magnitude of ||![](../../OEBPS/Images/AR_delta.png)||, the
    worse the approximation.'
  prefs: []
  type: TYPE_NORMAL
- en: A Taylor series offers a way to approximate a multidimensional function in the
    local neighborhood of any point by expressing it in terms of the displacements
    in the parameter space. It is an infinite series, meaning the equation is exactly
    true (zero approximation) only when we have summed an infinite number of terms.
    Of course, we cannot add an infinite number of terms with a computer program.
    But we can improve the accuracy of the approximation as much as we like by including
    more and more terms. In practice, we include at most up to the second term. Anything
    beyond that is redundant because the improvement is too small to be realized by
    the floating point system of current computers. First we will study a Taylor series
    in one dimension.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.1 1*D* Taylor series recap
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Suppose we are trying to describe the curve *L*(*w*) in the neighborhood of
    a particular point *w*. If we stay infinitesimally close to *w*, then, as described
    in section [3.3](../Text/03.xhtml#sec-grad), we can approximate the curve with
    a straight line:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-06-b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'But in the general case, if we are describing a continuous (smooth) function
    in the neighborhood of a specific point, we use a Taylor series. A Taylor series
    allows us to describe a function in the neighborhood of a specific point in terms
    of the value of the function and its derivatives at that point. Doing so is relatively
    simple in 1D:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-07.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 3.7
  prefs: []
  type: TYPE_NORMAL
- en: Note that the terms become progressively smaller (since they involve higher
    and higher powers of a small number *δw*). Hence, although the series goes on
    to infinity, in practice we entail a negligible loss in accuracy by dropping higher-order
    terms. We often use the first-order approximation (or, at most, second-order).
    Equation [3.7](#eq-taylor-onedim) can be rewritten as
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-07-a.png)'
  prefs: []
  type: TYPE_IMG
- en: Note that the second term has (*δw*)² as a factor, which is nearly zero at small
    values of the displacement *δw*. So, for really small *δw*, we include only the
    first term. Then we get *δL* = (*δw*/1!) (*dL*/*dw)*, which is the same as equation
    [3.3](#eq-derivative_total_change). If *δw* is a bit larger and we want greater
    accuracy, we can include the second-order term. In practice, as mentioned earlier,
    that is hardly ever done.
  prefs: []
  type: TYPE_NORMAL
- en: A handy example of a Taylor series is the expansion of the exponential function
    *e^x* near *x* = 0
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-07-b.png)'
  prefs: []
  type: TYPE_IMG
- en: where we use the fact that *d^n*/*dx^n* (*e^x*)|[*x* = 0] = *e^x*|[*x* = 0]
    = 1 for all *n*.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.2 Multidimensional Taylor series and the Hessian matrix
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In equation [3.7](#eq-taylor-onedim), we express a function of one variable
    in a small neighborhood around a point in terms of the derivatives. Can we do
    a similar thing in higher dimensions? Yes. We simply need to replace the first
    derivative with the gradient. We replace the second derivative with its multidimensional
    counterpart: the Hessian matrix. The multidimensional Taylor series is as follows'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-08.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 3.8
  prefs: []
  type: TYPE_NORMAL
- en: where *H*(*L*(![](../../OEBPS/Images/AR_w.png))), called the *Hessian matrix*,
    is defined as
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-09.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 3.9
  prefs: []
  type: TYPE_NORMAL
- en: The Hessian matrix is symmetric since ![](../../OEBPS/Images/eq_03-09-a.png).
    Also, note that the Taylor expansion assumes that the function is continuous in
    the neighborhood.
  prefs: []
  type: TYPE_NORMAL
- en: Equation [3.8](../Text/03.xhtml#eq-taylor-multidim) allows us to compute the
    value of *L* in a small neighborhood around point ![](../../OEBPS/Images/AR_w.png)
    in the parameter space. If we displace from ![](../../OEBPS/Images/AR_w.png) by
    the vector ![](../../OEBPS/Images/AR_delta.png), we arrive at ![](../../OEBPS/Images/AR_w.png)
    + ![](../../OEBPS/Images/AR_delta.png). The loss there is *L*(![](../../OEBPS/Images/AR_w.png)
    + ![](../../OEBPS/Images/AR_delta.png)), which is expressed by equation [3.8](../Text/03.xhtml#eq-taylor-multidim)
    in terms of the loss *L*(![](../../OEBPS/Images/AR_w.png)) at the original point
    and the displacement ![](../../OEBPS/Images/AR_delta.png).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-10.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 3.10
  prefs: []
  type: TYPE_NORMAL
- en: Note that the first term is same as equation [3.6](#eq-gradient_total_change)
    and the second term has squares of the displacement. Since the square of a small
    quantity is even smaller, for very small displacements, the second term disappears,
    and we essentially get back equation [3.6](#eq-gradient_total_change). This is
    called *first-order approximation*. For slightly larger displacements, we can
    include the second term, involving Hessians to improve the approximation. As stated
    earlier, this is hardly ever done in practice.
  prefs: []
  type: TYPE_NORMAL
- en: 3.5 PyTorch code for gradient descent, error minimization,and model training
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we study PyTorch examples in which models are trained by minimizing
    errors via gradient descent. Before we present the code, we briefly recap the
    main ideas from a practical point of view. Complete code for this section can
    be found at [http://mng.bz/4Zya](http://mng.bz/4Zya).)
  prefs: []
  type: TYPE_NORMAL
- en: 3.5.1 PyTorch code for linear models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If the true underlying function we are trying to predict is very simple, linear
    models suffice. Otherwise, we require nonlinear models. Here we will look at the
    linear model. In machine learning, we identify the input and output variables
    pertaining to the problem at hand and cast the problem as generating outputs from
    input variables. All the inputs are represented together by the vector ![](../../OEBPS/Images/AR_x.png).
    Sometimes there are multiple outputs, and sometimes there is a single output.
    Accordingly, we have an output vector ![](../../OEBPS/Images/AR_y.png) or an output
    scalar *y*. Let’s denote the function that generates the output from the input
    vector as *f*: that is, *y* = *f*(![](../../OEBPS/Images/AR_x.png)).'
  prefs: []
  type: TYPE_NORMAL
- en: In real-life problems, we do not know *f*. The crux of machine learning is to
    estimate *f* from a set of observed inputs ![](../../OEBPS/Images/AR_x.png)*[i]*
    and their corresponding outputs *y[i]*. Each observation can be depicted as a
    pair ⟨![](../../OEBPS/Images/AR_x.png)*[i]*, *y[i]*⟩. We model the unknown function
    *f* with a known function *ϕ*. *ϕ* is a parameterized function. Although the nature
    of *ϕ* is known, its parameter values are unknown. These parameter values are
    “learned” via training. This means we estimate the parameter values such that
    the overall error on the observations is minimized.
  prefs: []
  type: TYPE_NORMAL
- en: If ![](../../OEBPS/Images/AR_w.png), *b* denotes the current set of parameters
    (weights, bias), then the model will output *ϕ*(![](../../OEBPS/Images/AR_x.png)*[i]*,
    ![](../../OEBPS/Images/AR_w.png), *b*) on the observed input ![](../../OEBPS/Images/AR_x.png)*[i]*.
    Thus the error on this *i*th observation is *e[i]*² = (*ϕ*(![](../../OEBPS/Images/AR_x.png)*[i]*,
    ![](../../OEBPS/Images/AR_w.png), *b*)−*y[i]*)². We can batch several observations
    and add up the errors into a batch error *L* = Σ[*i* = 0]^(*i* = *N*) (*e^((i))*)².
  prefs: []
  type: TYPE_NORMAL
- en: 'The error is a function of the parameter set ![](../../OEBPS/Images/AR_w.png).
    The question is, how do we adjust ![](../../OEBPS/Images/AR_w.png) so that the
    error *e[i]*² decreases? We know a function’s value changes most when we move
    along the direction of the gradient of the parameters. Hence, we adjust the parameters
    ![](../../OEBPS/Images/AR_w.png), *b* as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-10-a.png)'
  prefs: []
  type: TYPE_IMG
- en: Each adjustment reduces the error. Starting from a random set of parameter values
    and doing this a sufficiently large number of times ields the desired model.
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple and popular model *ϕ* is the linear function (the predicted value
    is the dot product between the input vector and parameters vector plus bias):
    *ỹ[i]* = *ϕ*(![](../../OEBPS/Images/AR_x.png)*[i]*, ![](../../OEBPS/Images/AR_w.png),
    *b*) = ![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png) +
    *b* = ∑*[j]w[j]x[j]* + *b*. Our initial implementation (listing [3.1](#listing3-1))
    simply mimics this formula. For more complicated models *ϕ* (with millions of
    parameters and nonlinearities), we cannot obtain closed-form gradients like this.
    In such cases, we use a technique called autograd (automatic gradient computation),
    which does not required closed form gradients. This is discussed in the next section.'
  prefs: []
  type: TYPE_NORMAL
- en: NOTE In real-world problems, we will not know the true underlying function mapping
    inputs to outputs. But here, for the sake of gaining insight, we will assume known
    output functions and perturb them with noise to make them slightly more realistic.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.1 PyTorch linear model (closed-form gradient formula needed)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: ① Generates random input values
  prefs: []
  type: TYPE_NORMAL
- en: ② Generates output values by applying a simple known function to the input and
    then adds noise. Let’s see if our learned function matches the known underlying
    function.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Our model, initialized with arbitrary parameter values
  prefs: []
  type: TYPE_NORMAL
- en: ④ Model error is the (squared) difference between the observed and predicted
    values.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Calculates the gradient of the error using calculus. Possible only with such
    simple models.
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Adjusts the weight, bias along the gradient of error
  prefs: []
  type: TYPE_NORMAL
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '3.5.2 Autograd: PyTorch automatic gradient computation'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the PyTorch code in listing [3.1](#listing3-1), for this specific model architecture,
    we computed the gradient using calculus. This approach does not scale to more
    complex models with millions of weights and perhaps nonlinear complex functions.
    For scalability, we use an *automatic differentiation* software library like PyTorch
    Autograd. Users of the library need not worry about how to compute the gradients—they
    just construct the model function. Once the function is specified, PyTorch figures
    out how to compute its gradient through the Autograd technology.
  prefs: []
  type: TYPE_NORMAL
- en: To use Autograd, we explicitly tell PyTorch to track gradients for a variable
    by setting `requires_grad = True` when creating the variable. PyTorch remembers
    a computation graph that is updated every time we create an expression using tracked
    variables. Figure [3.10](#fig-auto-grad) shows an example of a computation graph.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F10_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.10 Autograd analysis
  prefs: []
  type: TYPE_NORMAL
- en: The following listing, which implements a linear model in PyTorch, relies on
    PyTorch’s Autograd for gradient computation. Note that this method does not require
    the closed-form gradient.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.2 Linear modeling with PyTorch
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '① Updates parameters: adjusts the weight, bias along the gradient of error'
  prefs: []
  type: TYPE_NORMAL
- en: ② Doesn’t track gradients during parameter updates
  prefs: []
  type: TYPE_NORMAL
- en: ③ Restores gradient tracking
  prefs: []
  type: TYPE_NORMAL
- en: ④ Generates random training input
  prefs: []
  type: TYPE_NORMAL
- en: '⑤ Generates training output: applies a simple known function to the input and
    then adds noise. Let’s see if our learned function matches the known underlying
    function.'
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Our model, initialized with arbitrary parameter values
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ The model error is the (squared) difference
  prefs: []
  type: TYPE_NORMAL
- en: between the observed and predicted values.
  prefs: []
  type: TYPE_NORMAL
- en: '⑧ Backpropagates: computes the partial'
  prefs: []
  type: TYPE_NORMAL
- en: derivatives of the error with respect to
  prefs: []
  type: TYPE_NORMAL
- en: each variable and stores them in the “grad” field within the variable
  prefs: []
  type: TYPE_NORMAL
- en: ⑨ Updates parameters using those partial derivatives
  prefs: []
  type: TYPE_NORMAL
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 3.5.3 Nonlinear Models in PyTorch
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In listings [3.1](#listing3-1) and [3.2](#listing3-2), we fit a linear model
    to a data distribution that we know to be linear. From the output, we can see
    that those models converged to a pretty good approximation of the underlying output
    function. This is also shown graphically in figure [3.11](#fig-gradients-pytorch-linear).
    But what happens if the underlying output function is nonlinear?
  prefs: []
  type: TYPE_NORMAL
- en: First, listing [3.3](#listing3-3) tries to use a linear model on a nonlinear
    data distribution. As expected (and demonstrated via the output as well as figure
    [3.12](#fig-gradients-pytorch-non-linear-using-linear)), this model does not do
    well, because we are using an inadequate model architecture. Further training
    will not help.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F11_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.11 Linear approximation of linear data. By step 1,000, the model has
    more or less converged to the true underlying function.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F12_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.12 Linear approximation of nonlinear data. Clearly the model is not
    converging to anything close to the desired/true function. Our model architecture
    is inadequate.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.3 Linear approximation of nonlinear data
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: ① Generates random input training data
  prefs: []
  type: TYPE_NORMAL
- en: '② Generates training output: applies a known nonlinear function to the input
    and then perturbs it with noise'
  prefs: []
  type: TYPE_NORMAL
- en: ③ Trains a linear model as in listing 3.2
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Next, listing [3.4](#listing3-4) tries a nonlinear model. As expected (and demonstrated
    via the output as well as figure [3.13](#fig-gradients-pytorch-nonlinear)), the
    nonlinear model does well. In real-life problems, we usually assume nonlinearity
    and choose a model architecture accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F13_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.13 If we use a nonlinear model, it more or less converges to the true
    underlying function.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.4 Nonlinear modeling with PyTorch
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 3.5.4 A linear model for the cat brain in PyTorch
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In section [2.12.5](02.xhtml#python-overdet), we solved the cat-brain problem
    directly via pseudo-inverse. Now, let’s train a PyTorch model over the same dataset.
    As expected, the model parameters will converge to a solution close to that obtained
    by the pseudo-inverse technique this being a simple training dataset); but in
    the following listing, we demonstrate our first somewhat sophisticated PyTorch
    model.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.5 Our first realistic PyTorch model (solves the cat-brain problem)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '① *X*, ![](../../OEBPS/Images/AR_y.png) created (see section [2.12.3](02.xhtml#subsec-over-under-determined-linsys))
    as per equation [2.22](02.xhtml#eq-lin-model) It is easy to verify that the solution
    to equation [2.22](02.xhtml#eq-lin-model) is roughly *w*[0] = 1, *w*[1] = 1, *b*
    = −1. But the equations are not consistent: no one solution perfectly fits all
    of them. We expect the learned model to be close to *y* = *x*[0] + *x*[1] − 1.'
  prefs: []
  type: TYPE_NORMAL
- en: ② Adds a column of all 1s to augment the data matrix *X*
  prefs: []
  type: TYPE_NORMAL
- en: ③ Parameter is a type (subclass) of Torch Tensor suitable for model parameters
    (weights+bias).
  prefs: []
  type: TYPE_NORMAL
- en: '④ Linear model: ![](../../OEBPS/Images/AR_y.png) = *X*![](../../OEBPS/Images/AR_w.png)(*X*
    is augmented, and ![](../../OEBPS/Images/AR_w.png) includes bias)'
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Ready-made class for computing squared error loss/
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Ready-made class for updating weights using the gradient of error
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Zeros out all partial derivatives
  prefs: []
  type: TYPE_NORMAL
- en: ⑧ Computes partial derivatives via autograd
  prefs: []
  type: TYPE_NORMAL
- en: ⑨ Updates the parameters using gradients computed in the backward() step
  prefs: []
  type: TYPE_NORMAL
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 3.6 Convex and nonconvex functions, and global and local minima
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A convex surface (see figure [3.14](#fig-convex_diagram)) has a single optimum
    (maximum/minimum): the global one.[²](#fn10) Wherever we are on such a surface,
    if we keep moving along the gradient in parameter space, we will eventually reach
    the global minimum. On the other hand, on a nonconvex surface, we might get stuck
    in a local minimum. For instance, in figure [3.14b](#fig-nonconvex_diagram), if
    we start at the point marked with the arrowed line indicating a gradient and move
    downward following the gradient, we will arrive at a local minimum. At the minimum,
    the gradient is zero, and we will never move out of that point.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F14a_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) A convex function
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F14b_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) A nonconvex function
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.14 Convex vs. nonconvex functions. Convex functions have only a global
    optimum (minimum or maximum), nolocal optimum. Following the gradient downward
    is guaranteed to reach the global minimum. Friendly error functions are convex.
    A nonconvex function has one or more local optima. Following the gradient may
    reach a local minimum and never discover the global minimum. Unfriendly error
    functions are nonconvex.
  prefs: []
  type: TYPE_NORMAL
- en: There was a time when researchers put a lot of effort into trying to avoid local
    minima. Special techniques (such as simulated annealing) were developed to avoid
    them. However, neural networks typically do not do anything special to deal with
    local minima and nonconvex functions. Often, the local minimum is good enough.
    Or we can retrain by starting from a different random point, which may help us
    escape the local minimum.
  prefs: []
  type: TYPE_NORMAL
- en: 3.7 Convex sets and functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In section [3.6](../Text/03.xhtml#sec-locglob-minima), we briefly encountered
    convex functions and how convexity tells us whether a function has local minima.
    In this section, we look at convex functions in more detail. In particular, we
    learn how to tell whether a given function is convex. We also discuss some important
    properties of convex functions that will come in handy later—for instance, when
    we study Jensen’s inequality in probability and statistics, in the appendix. We
    will mostly illustrate the ideas in 2D space, but they can be easily extended
    to higher dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: 3.7.1 Convex sets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Informally speaking, a set of points is said to be convex if and only if the
    straight line joining any pair of points in the set lies entirely within the set.
    For example, if we join any pair of points in the shaded region on the left-hand
    side of figure [3.15](#fig-convex-set) with a straight line, all points on that
    line will also be in the shaded region. This is illustrated by points A and B
    in the figure. The complete set of points in any such region constitutes a convex
    set.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F15_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.15 Convex and nonconvex sets. The points in the left-hand shaded region
    form a convex set.The line joining any pair of points in that shaded region lies
    entirely in the shaded region: for example, AB.The points in the right-hand shaded
    region form a nonconvex set. For instance, the line joining points C and D passes
    through a nonshaded region even though both end points belong to a shaded region.'
  prefs: []
  type: TYPE_NORMAL
- en: Conversely, a set of points is nonconvex if it contains at least one pair of
    points whose joining line contains a point not belonging to the set. For instance,
    the shaded region on the right-hand side of figure [3.15](#fig-convex-set) contains
    a pair of points C and D whose joining line passes through points not belonging
    to the shaded region.
  prefs: []
  type: TYPE_NORMAL
- en: The boundary of a convex set is always a convex curve.
  prefs: []
  type: TYPE_NORMAL
- en: 3.7.2 Convex curves and surfaces
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Consider a function *g*(*x*). Let’s pick any two points on the curve *y* =
    *g*(*x*): *A* ≡ (*x*[1], *y*[1] = *g*(*x*[1])) and *B* ≡ (*x*[2], *y*[2] = *g*(*x*[2])).
    Now consider the line segment *L* joining *A* and *B*. From section [2.8.1](02.xhtml#sec-multidim-line-eq)
    (equation [2.12](02.xhtml#eq-collinearity) and figure [2.8](02.xhtml#fig-multi-dim-lineeq)),
    we know that all points *C* on *L* can be expressed as a weighted average of the
    coordinates of *A* and *B*, with the sum of weights being 1. Thus, *C* ≡ (*α*[1]*x*[1]
    + *α*[2]*x*[2], *α*[1]*y*[1] + *α*[2]*y*[2]), where *α*[1] + *α*[2] = 1. Compare
    *C* with its corresponding point *D* on the curve, which has the same *X* coordinate:'
  prefs: []
  type: TYPE_NORMAL
- en: '*D* ≡ (*α*[1]*x*[1] + *α*[2]*x*[2], *g*(*α*[1]*x*[1] + *α*[2]*x*[2])).'
  prefs: []
  type: TYPE_NORMAL
- en: If and only if *g*(*x*) is a convex function, *C* will always be above *D*,
    or
  prefs: []
  type: TYPE_NORMAL
- en: '*α*[1]*y*[1] + *α*[2]*y*[2] = *α*[1]*g*(*x*[1]) + *α*[2]*g*(*x*[2]) ≥ *g*(*α*[1]*x*[1]
    + *α*[2]*x*[2])'
  prefs: []
  type: TYPE_NORMAL
- en: Viewed another way, if we drop a perpendicular to the *X*-axis from any point
    on the secant line joining a pair of points on the curve, that perpendicular will
    cut the curve at a lower point (that is, smaller in its *Y*-coordinate).
  prefs: []
  type: TYPE_NORMAL
- en: 'This is illustrated on the left-hand side of figure [3.19](#fig-convex-wt-avg)
    with the function *g*(*x*) = *x*² known to be convex) and *A* ≡ (−3,9) and *B*
    ≡ (5,25), *α*[1] = 0.3, *α*[2] = 0.7. It can be seen that the weighted average
    point *C* on the line lies above the corresponding point on the curve *D*. The
    right-hand side illustrates the nonconvex function *g*(*x*) = *x*³, with *A* ≡
    (−8,−512) and *B* ≡ (5,125), *α*[1] = 0.3, *α*[2] = 0.7. The figure shows one
    weighted average point (*C*) on the line joining points *A* and *B* on the curve:
    *C* lies below point *D* on the curve, which has the same *X*-coordinate.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F16_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.16 Convex and nonconvex curves. *A* and *B* are a pair of points on
    the curve. *C* = 0.3*A* + 0.7*B* is a weighted average of the coordinates of A
    and B, with weights summing to 1. *C* lies on the line joining *A* and *B*. The
    left-hand curve is convex: *C* lies above the corresponding curve point *D*. The
    right-hand curve is nonconvex: *C* lies below the corresponding curve point *D*.'
  prefs: []
  type: TYPE_NORMAL
- en: We need not restrict ourselves to two points. We can take the weighted average
    of an arbitrary number of points on the curve, with the weights summing to one.
    The point corresponding to the weighted average will lie above the curve (that
    is, above the point on the curve with the same *X*-coordinate). The idea also
    extends to higher dimensions, as discussed next.
  prefs: []
  type: TYPE_NORMAL
- en: Definition 1
  prefs: []
  type: TYPE_NORMAL
- en: In general, a multidimensional function *g*(![](../../OEBPS/Images/AR_x.png))
    is convex if and only if
  prefs: []
  type: TYPE_NORMAL
- en: Given an arbitrary set of points on the function surface (curve, if the function
    is 1D), (![](../../OEBPS/Images/AR_x.png)[1], *g*(![](../../OEBPS/Images/AR_x.png)[1])),
    (![](../../OEBPS/Images/AR_x.png)[2], *g*(![](../../OEBPS/Images/AR_x.png)[2])),
    ⋯, (*![](../../OEBPS/Images/AR_x.png)[n]*, *g*(*![](../../OEBPS/Images/AR_x.png)[n]*)),
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And given an arbitrary set of *n* weights *α*[1], *α*[2], ⋯, *α[n]* that sum
    to 1 (that is, Σ*[i]^n*[= 1] *α[i]* = 1),
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*The weighted sum of the function outputs exceeds or equals the function output
    on the weighted sums*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-11.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 3.11
  prefs: []
  type: TYPE_NORMAL
- en: A little thought will reveal that definition 1 implies that convex curves always
    curl upward and/or rightward everywhere. This leads to another equivalent definition
    of convexity.
  prefs: []
  type: TYPE_NORMAL
- en: Definition 2
  prefs: []
  type: TYPE_NORMAL
- en: In general, a multidimensional function *g*(![](../../OEBPS/Images/AR_x.png))
    is convex if and only if
  prefs: []
  type: TYPE_NORMAL
- en: 'A 1D function *g*(*x*) is convex if and only if its curvature is positive everywhere:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_03-12.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 3.12
  prefs: []
  type: TYPE_NORMAL
- en: A multidimensional function *g*(![](../../OEBPS/Images/AR_x.png)) is convex
    if and only if its Hessian matrix (see section [3.4.2](#sec-taylor-multidim),
    equation [3.9](../Text/03.xhtml#eq-hessian)) is positive semi-definite that is,
    all the eigenvalues of the Hessian matrix are greater than or equal to zero).
    This is just the multidimensional analog of equation [3.12](#eq-convexity-2nd-deriv).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One subtle point to note is that if the second derivative is negative everywhere
    or the Hessian is negative semi-definite, the curve or surface is said to be *concave*.
    This is different from nonconvex curves, where the second derivative is positive
    in some places and negative in others. The negative of a concave function is a
    convex function. But the negative of a nonconvex function is again nonconvex.
  prefs: []
  type: TYPE_NORMAL
- en: A function that curves upward everywhere always lies above its tangent. This
    leads to another equivalent definition of a convex function.
  prefs: []
  type: TYPE_NORMAL
- en: Definition 3
  prefs: []
  type: TYPE_NORMAL
- en: In general, a multidimensional function *g*(![](../../OEBPS/Images/AR_x.png))
    is convex if and only if
  prefs: []
  type: TYPE_NORMAL
- en: A function *g*(*x*) is convex if and only if all the points on the curve *S*
    ≡ (*x*, *g*(*x*)) lie above the tangent line *T* at any point *A* on *S*, with
    *S* touching *T* only at *A*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A function *g*(![](../../OEBPS/Images/AR_x.png)) is convex if and only if all
    the points on the surface *S* ≡ (![](../../OEBPS/Images/AR_x.png), *g*(![](../../OEBPS/Images/AR_x.png)))
    lie above the tangent plane *T* at any point *A* on *S*, with *S* touching *T*
    only at *A*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is illustrated in figure [3.17](#fig-convex-tangent).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH03_F17_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.17 The left-hand curve is convex. If we draw a tangent line at any
    point *A* on the curve, the entire curve is *above* the tangent line, touching
    it only at *A*. The right-hand cuve is nonconvex: part of the curve lies above
    the tangent and part of it below.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.7.3 Convexity and the Taylor series
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In section [3.4.1](#sec-taylor-onedim), equation [3.7](#eq-taylor-onedim), we
    saw the one-dimensional Taylor expansion for a function in the neighborhood of
    a point *x*. If we retain the terms in the Taylor expansion only up to the first
    derivative and ignore all subsequent terms, that is equivalent to approximating
    the function at *x* with its tangent at *x* (see figure [3.17](#fig-convex-tangent)).
    This is the linear approximation to the curve. If we retain one more term (that
    is, up to the second derivative), we get the quadratic approximation to the curve.
    If the second derivative of the function is always positive (as in convex functions),
    the quadratic approximation to the function will always be greater than or equal
    to the linear approximation. In other words, locally, the curve will curve so
    that it lies above the tangent. This connects the second derivative definition
    (definition 2) with the tangent definition (definition 3) of convexity.
  prefs: []
  type: TYPE_NORMAL
- en: 3.7.4 Examples of convex functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The function *g*(*x*) = *x*² is convex. The easiest way to verify this is to
    compute *d*²*g*/*dx*² = *d*2*x*/*dx* = 2, which is always positive. In fact, any
    even power of *x*, *g*(*x*) = *x*^(2*n*) for an integer *n*, such as *x*⁴ or *x*⁶,
    is convex. *g*(*x*) = *e^x* is also convex. This can be easily verified by taking
    its second derivative. *g*(*x*) = *logx* is concave. Hence, *g*(*x*) = −*logx*
    is convex.
  prefs: []
  type: TYPE_NORMAL
- en: Multiplication by a positive scalar preserves convexity. The sum of convex functions
    is also a convex function.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We would like to leave you with the following mental pictures from this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Inputs for a machine learning problem can be viewed as vectors or, equivalently,
    points in a high-dimensional feature space. Classification is nothing but separating
    clusters of points belonging to individual classes in this space.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A classifier is can be viewed geometrically as the hypersurface (aka decision
    boundary) in the high-dimensional feature space, separating the point clusters
    corresponding to individual classes. During training, we collect sample inputs
    with known classes and identify the surface that best separates the corresponding
    points. During inferencing, given an unknown input, we determine which side of
    the decision boundary this point lies in—this tells us the class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For two-class classifiers (aka binary classifiers), if we plug in the point
    in the function for the classifier hypersurface, the sign of the corresponding
    output yields the class.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To compute the hypersurface decision boundary that best separates the training
    data, we first choose a parametric function family to model this surface (for
    example, a hyperplane for simple problems). Then we estimate the optimal parameter
    values that best separate the training data, usually in an iterative fashion.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To estimate the parameter values that optimally separates the training data,
    we define a loss function that measures the difference between the model output
    and the known desired output over the entire training dataset. Then, starting
    from random initial values, we iteratively adjust the parameter values so that
    the loss value decreases progressively.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At every iteration, the adjustment to the parameter values that optimally reduces
    the loss is estimated by computing the gradient of the loss function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The gradient of a multidimensional function identifies the direction in the
    parameter space corresponding to the maximum change in the function. Thus, the
    gradient of the loss function identifies the direction in which we can adjust
    the parameters to maximally decrease the loss.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The gradient is zero at the maximum or minimum point of a function, which is
    always a point of inflection. This can be used to recognize when we have reached
    the minimum. However, in practice, in machine learning we often do an early stop:
    terminate training iterations when the loss is sufficiently low.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A multidimensional Taylor series can be used to create local approximations
    to a smooth function in the neighborhood of a point. The function is expressed
    in terms of the displacement from the point, the first-order derivatives (gradient),
    second-order derivatives Hessian matrix), and so on. This can be used to make
    higher-accuracy approximations to the change in loss value resulting from a displacement
    in the parameter space.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loss functions can be*convex* or *nonconvex*. In a convex function, there is
    no local minimum, only a single global minimum. Hence, gradient descent is guaranteed
    to converge to the global minimum. A nonconvex function can have both a local
    and a global minimum. So, gradient-based descent may get stuck in a local minimum.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '* * *'
  prefs: []
  type: TYPE_NORMAL
- en: ¹  If the change in a quantity such as *w* is infinitesimally small, we use
    the symbol *dw* to denote the change. If the change is small but not infinitesimally
    so, we use the symbol *δw*. [↩](#fnref9)
  prefs: []
  type: TYPE_NORMAL
- en: ²  Although the theory applies to either optimum, maximum or minimum, for brevity’s
    sake, here we will only talk in terms of the minimum [↩](#fnref10)
  prefs: []
  type: TYPE_NORMAL
