# 第一章 工具和技术

在本章中，我们将介绍深度学习的常见工具和技术。这是一个很好的章节，可以通读一次以了解各种情况，并在需要时回头查看。

我们将首先概述本书涵盖的不同类型的神经网络。本书后面的大部分配方都侧重于完成任务，并仅简要讨论深度神经网络的架构。

接下来我们将讨论数据来源。像 Facebook 和 Google 这样的科技巨头可以访问大量数据来进行他们的深度学习研究，但我们也有足够的数据可以做一些有趣的事情。本书中的配方从各种来源获取数据。

下一部分是关于数据预处理的。这是一个经常被忽视的非常重要的领域。即使您拥有正确的网络设置和出色的数据，您仍然需要确保您拥有的数据以最佳方式呈现给网络。您希望尽可能地让网络学习它需要学习的东西，并且不要被数据中的其他无关紧要的部分分散注意力。

# 1.1 神经网络的类型

在本章和整本书中，我们将讨论*网络*和*模型*。网络是神经网络的简称，指的是一堆连接的*层*。您在一侧输入数据，转换后的数据从另一侧输出。每个层对通过它流动的数据执行数学操作，并具有一组可以修改的变量，这些变量确定了层的确切行为。这里的*数据*指的是*张量*，一个具有多个维度的向量（通常是二维或三维）。

对不同类型的层及其操作背后的数学进行全面讨论超出了本书的范围。最简单类型的层，即*全连接*层，将其输入作为矩阵，将该矩阵与另一个称为*权重*的矩阵相乘，并添加一个称为*偏置*的第三个矩阵。每个层后面都跟着一个*激活*函数，这是一个数学函数，将一个层的输出映射到下一层的输入。例如，一个简单的激活函数称为 ReLU 会传递所有正值，但将负值设为零。

从技术上讲，术语*网络*指的是架构，即各个层之间连接的方式，而*模型*是一个网络加上确定运行时行为的所有变量。训练模型会修改这些变量，使预测更好地符合预期输出。然而，在实践中，这两个术语经常可以互换使用。

实际上，“深度学习”和“神经网络”这些术语涵盖了各种模型。这些网络中的大多数将共享一些元素（例如，几乎所有分类网络都将使用特定形式的*损失函数*）。虽然模型空间多样，但我们可以将大多数模型分为一些广泛的类别。一些模型将使用来自多个类别的部分：例如，许多图像分类网络具有一个全连接部分“头部”来执行最终分类。

## 全连接网络

全连接网络是第一种被研究的网络类型，并且在 1980 年代后期之前占据了主导地位。在全连接网络中，每个输出单元都被计算为所有输入的加权和。术语“全连接”源于这种行为：每个输出都连接到每个输入。我们可以将其写成一个公式：

<math><mrow><msub><mi>y</mi> <mi>i</mi></msub> <mo>=</mo> <munder><mo>∑</mo> <mi>j</mi></munder> <msub><mi>W</mi> <mrow><mi>i</mi><mi>j</mi></mrow></msub> <msub><mi>x</mi> <mi>j</mi></msub></mrow></math>

为简洁起见，大多数论文使用矩阵表示全连接网络。在这种情况下，我们将一个输入向量与权重矩阵*W*相乘以获得一个输出向量：

<math><mrow><mi>y</mi> <mo>=</mo> <mi>W</mi> <mi>x</mi></mrow></math>

由于矩阵乘法是一个线性操作，一个只包含矩阵乘法的网络将被限制在学习线性映射。为了使我们的网络更具表现力，我们在矩阵乘法后面加上一个非线性激活函数。这可以是任何可微函数，但有一些非常常见。双曲正切函数，或*tanh*函数，直到最近仍然是主要的激活函数类型，并且仍然可以在一些模型中找到：

![双曲正切激活](img/dlcb_01in03.png)

双曲正切函数的困难在于当输入远离零时它非常“平坦”。这导致梯度很小，这意味着网络可能需要很长时间才能改变行为。最近，其他激活函数变得流行起来。其中最常见的是修正线性单元，或*ReLU*，激活函数：

![Relu 激活](img/dlcb_01in04.png)

最后，许多网络在网络的最后一层使用*sigmoid*激活函数。这个函数总是输出一个介于 0 和 1 之间的值。这使得输出可以被视为概率：

![Sigmoid 激活](img/dlcb_01in05.png)

矩阵乘法后跟激活函数被称为网络的一个*层*。在一些网络中，完整的网络可以有超过 100 层，尽管全连接网络往往被限制在少数几个。如果我们正在解决一个分类问题（“这张图片中有什么类型的猫？”），网络的最后一层被称为*分类层*。它的输出数量总是与我们可以选择的类别数量相同。

网络中间的层被称为*隐藏层*，来自隐藏层的单个输出有时被称为*隐藏单元*。术语“隐藏”来自于这些单元不像输入或输出那样直接可见于我们模型的外部。这些层中的输出数量取决于模型：

![网络层](img/dlcb_01in06.png)

虽然有一些关于如何选择隐藏层的数量和大小的经验法则，但除了试错之外，没有选择最佳设置的一般政策。

## 卷积网络

早期的研究使用全连接网络来尝试解决各种问题。但是当我们的输入是图像时，全连接网络可能是一个不好的选择。图像非常大：一个单独的 256×256 像素图像（分类常用分辨率）有 256×256×3 个输入（每个像素 3 种颜色）。如果这个模型有一个具有 1,000 个隐藏单元的单隐藏层，那么这一层将有近 2 亿个参数（可学习的值）！由于图像模型在分类时需要相当多的层，如果我们仅使用全连接层来实现它们，我们最终将得到数十亿个参数。

由于参数太多，我们几乎不可能避免*过拟合*我们的模型（过拟合在下一章节中将详细描述；它指的是当网络无法泛化，而只是记住结果时）。*卷积神经网络*（CNN）为我们提供了一种使用更少参数训练超人类图像分类器的方法。它们通过模仿动物和人类的视觉方式来实现这一点：

![CNN 层 - 来自维基百科](img/dlcb_01in07.png)

CNN 中的基本操作是*卷积*。与将函数应用于整个输入图像不同，卷积一次在图像的一个小窗口上扫描。在每个位置，它应用一个*核*（通常是矩阵乘法后跟激活函数，就像在全连接网络中一样）。单个核通常被称为*滤波器*。将核应用于整个图像的结果是一个新的、可能更小的图像。例如，常见的滤波器形状是（3, 3）。如果我们将 32 个这些滤波器应用于我们的输入图像，我们将需要 3 * 3 * 3（输入颜色）* 32 = 864 个参数——这比全连接网络节省了很多！

### 子采样

这种操作节省了参数的数量，但现在我们有了一个不同的问题。网络中的每一层只能一次“看”图像的一个 3×3 层：如果是这种情况，我们如何可能识别占据整个图像的对象？为了处理这个问题，典型的卷积网络在图像通过网络时使用*子采样*来减小图像的大小。用于子采样的两种常见机制是：

步幅卷积

在步幅卷积中，我们在滑动卷积滤波器时简单地跳过一个或多个像素。这会导致图像尺寸变小。例如，如果我们的输入图像是 256×256，并且我们跳过每隔一个像素，那么我们的输出图像将是 128×128（为简单起见，我们忽略了图像边缘的填充问题）。这种步幅下采样通常在生成器网络中找到（参见“对抗网络和自动编码器”）。

池化

许多网络不是在卷积过程中跳过像素，而是使用*池化层*来缩小它们的输入。池化层实际上是另一种形式的卷积，但我们不是将输入乘以矩阵，而是应用池化运算符。通常，池化使用*最大*或*平均*运算符。最大池化从正在扫描的区域中的每个*通道*（颜色）中取最大值。平均池化则对该区域中的所有值进行平均。 （可以将其视为输入的简单模糊处理。）

一种思考子采样的方式是将其视为增加网络所做的抽象级别的一种方式。在最低级别上，我们的卷积检测小的局部特征。有许多不太深的特征。通过每个池化步骤，我们增加了抽象级别；特征的数量减少，但每个特征的深度增加。这个过程一直持续到最终得到非常少的具有高度抽象的特征，可以用于预测。

### 预测

在堆叠了多个卷积和池化层之后，CNN 在网络头部使用一个或两个全连接层来输出预测。

## 循环网络

*循环神经网络*（RNNs）在概念上类似于 CNNs，但在结构上有很大的不同。当我们有一个顺序输入时，经常应用循环网络。在处理文本或语音时，这些输入通常是常见的。与处理单个示例完全不同（就像我们可能使用 CNN 处理图像一样），对于顺序问题，我们可以一次只处理问题的一部分。例如，让我们考虑构建一个为我们写莎士比亚剧本的网络。我们的输入自然是莎士比亚的现有剧本：

```py
Lear. Attend the lords of France and Burgundy, Gloucester.
Glou. I shall, my liege.
```

我们希望网络学会为我们预测剧本的下一个单词。为了做到这一点，它需要“记住”到目前为止看到的文本。循环网络为我们提供了这样的机制。它们还允许我们构建自然适用于不同长度输入（例如句子或语音块）的模型。最基本形式的 RNN 如下所示：

![RNN 层-来自维基百科](img/dlcb_01in08.png)

从概念上讲，你可以将这个 RNN 看作是一个非常深的全连接网络，我们已经“展开”了。在这个概念模型中，网络的每一层接受两个输入，而不是我们习惯的一个：

![RNN 层展开](img/dlcb_01in09.png)

回想一下，在我们最初的全连接网络中，我们有一个类似的矩阵乘法操作：

<math><mrow><mi>y</mi> <mo>=</mo> <mi>W</mi> <mi>x</mi></mrow></math>

将第二个输入添加到这个操作的最简单方法是将其简单地连接到我们的隐藏状态中：

<math alttext="dollar-sign h i d d e n Subscript i Baseline equals upper W left-brace h i d d e n Subscript i minus 1 Baseline vertical-bar x right-brace dollar-sign"><mrow><mi>h</mi> <mi>i</mi> <mi>d</mi> <mi>d</mi> <mi>e</mi> <msub><mi>n</mi> <mi>i</mi></msub> <mo>=</mo> <mi>W</mi> <mfenced close="}" open="{" separators=""><mi>h</mi> <mi>i</mi> <mi>d</mi> <mi>d</mi> <mi>e</mi> <msub><mi>n</mi> <mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></msub> <mrow><mo>|</mo> <mi>x</mi></mrow></mfenced></mrow></math>

在这种情况下，“|”代表连接。与全连接网络一样，我们可以对矩阵乘法的输出应用激活函数以获得我们的新状态：

<math alttext="dollar-sign h i d d e n Subscript i Baseline equals f left-parenthesis upper W left-brace h i d d e n Subscript i minus 1 Baseline vertical-bar x right-brace right-parenthesis dollar-sign"><mrow><mi>h</mi> <mi>i</mi> <mi>d</mi> <mi>d</mi> <mi>e</mi> <msub><mi>n</mi> <mi>i</mi></msub> <mo>=</mo> <mi>f</mi> <mfenced close=")" open="(" separators=""><mi>W</mi> <mfenced close="}" open="{" separators=""><mi>h</mi> <mi>i</mi> <mi>d</mi> <mi>d</mi> <mi>e</mi> <msub><mi>n</mi> <mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></msub> <mrow><mo>|</mo> <mi>x</mi></mrow></mfenced></mfenced></mrow></math>

通过这种对我们 RNN 的解释，我们也可以很容易地理解它如何被训练：我们简单地将 RNN 视为我们展开的全连接网络，并正常训练它。这在文献中被称为*时间反向传播*（BPTT）。如果我们有非常长的输入，通常将它们分成较小的片段并独立训练每个片段。虽然这并不适用于每个问题，但通常是安全的，并且是一种广泛使用的技术。

### 消失的梯度和 LSTM

我们的朴素 RNN 不幸地在处理长输入序列时表现得比我们希望的要差。这是因为其结构使得它很可能遇到“消失的梯度”问题。消失的梯度是由于我们的展开网络非常深。每次经过激活函数时，都有可能导致一个小梯度通过（例如，ReLU 激活函数对于任何输入<0 都有零梯度）。一旦这发生在一个单元上，就无法通过该单元进一步传递更多的训练。这导致随着我们向下进行，训练信号变得越来越稀疏。观察到的结果是网络学习非常缓慢或根本没有学习。

为了对抗这一点，研究人员开发了一种构建 RNN 的替代机制。保持时间上展开我们的状态的基本模型，但是不再进行简单的矩阵乘法后跟激活函数，而是通过更复杂的方式将我们的状态向前传递（来源：[维基百科](https://bit.ly/2HJL86P)）：

![LSTM 架构](img/dlcb_01in13.png)

*长短期记忆网络*（LSTM）用四个矩阵乘法替换了我们的单个矩阵乘法，并引入了与向量相乘的*门*的概念。使 LSTM 比普通 RNN 更有效地学习的关键行为是，从最终预测到保留梯度的任何层始终存在一条路径。它是如何实现这一点的细节超出了本章的范围，但网上有几篇[优秀的教程](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)。

## 对抗网络和自动编码器

对抗网络和自动编码器并没有像我们迄今讨论过的网络那样引入新的结构组件。相反，它们使用最适合问题的结构：例如，用于图像的对抗网络或自动编码器将使用卷积。它们的不同之处在于它们的训练方式。大多数普通网络被训练以从输入（一张图片）预测输出（这是一只猫吗？）：

![猫检测](img/dlcb_01in14.png)

相反，自动编码器被训练为输出它们所呈现的图像：

![自动编码猫](img/dlcb_01in15.png)

为什么我们要这样做呢？如果我们网络中间的隐藏层包含比原始图像少（显着）的信息量，但原始图像可以从中重建，那么这将导致一种压缩形式：我们可以通过隐藏层的值来表示任何图像。一种思考方式是，我们将原始图像使用网络投影到一个抽象空间中。该空间中的每个点都可以转换回图像。

自动编码器已成功应用于小图像，但训练它们的机制无法扩展到更大的问题。从中间提取图像的空间实际上不够“密集”，许多点实际上并不代表连贯的图像。

我们将在第十三章中看到一个自动编码器网络的示例。

对抗网络是一种更近期的模型，可以生成逼真的图像。它们通过将问题分为两部分来工作：生成器网络和鉴别器网络。生成器网络接受一个小的随机种子并生成一幅图片（或文本）。鉴别器网络试图确定输入图像是“真实的”还是来自生成器网络。

当我们训练我们的对抗模型时，我们同时训练这两个网络：

对抗网络

我们从生成器网络中采样一些图像，并通过鉴别器网络进行馈送。生成器网络会受到奖励，因为它生成的图像可以欺骗鉴别器。鉴别器网络还必须正确识别真实图像（不能总是说图像是假的）。通过让网络相互竞争，这个过程可以导致生成器网络生成高质量的自然图像。第十四章展示了我们如何使用生成对抗网络生成图标。

## 结论

设计网络有许多方法，选择显然主要取决于网络的目的。设计一种新类型的网络属于研究领域，即使重新实现一篇论文中描述的网络类型也很困难。实际上，最容易的方法是找到一个示例，该示例朝着您想要的方向做一些事情，并逐步更改，直到它真正实现您想要的功能。

# 1.2 获取数据

近年来深度学习蓬勃发展的一个关键原因是数据的可用性大幅增加。二十年前，网络是用数千张图像进行训练的；而如今，像 Facebook 和 Google 这样的公司使用数十亿张图像。

毫无疑问，这些以及其他互联网巨头对用户信息的全部访问为他们在深度学习领域带来了自然优势。然而，互联网上有许多数据源很容易获取，稍加整理即可适用于许多训练目的。在本节中，我们将讨论最重要的数据源。对于每个数据源，我们将探讨如何获取数据，有哪些流行的库可用于解析，以及典型的用例是什么。我还会引导您查看使用此数据源的任何配方。

## 维基百科

英文维基百科不仅包括 500 多万篇文章，而且维基百科也以[数百种语言](https://en.wikipedia.org/wiki/List_of_Wikipedias)提供，尽管深度和质量差异很大。基本的维基思想只支持链接作为编码结构的一种方式，但随着时间的推移，维基百科已经超越了这一点。

类别页面链接到具有相同属性或主题的页面，由于维基百科页面链接回它们的类别，我们可以有效地将它们用作标签。类别可以非常简单，比如“猫”，但有时在它们的名称中编码信息，有效地为页面分配（键，值）对，比如“1758 年描述的哺乳动物”。类别层次结构，就像维基百科上的许多内容一样，相当临时。此外，递归类别只能通过沿树向上行走来跟踪。

*模板*最初被设计为维基标记的片段，意味着它们可以自动复制（“转入”）到页面中。通过将模板的名称放在`{{双大括号}}`中添加它们。这使得可以保持不同页面的布局同步，例如，所有城市页面都有一个信息框，其中包含人口、位置和旗帜等属性，这些属性在页面上呈现一致。

这些模板具有参数（如人口）并可以被视为将结构化数据嵌入维基百科页面的一种方式。在第四章中，我们使用这个来提取一组电影，然后用来训练电影推荐系统。

## 维基数据

[维基数据](https://www.wikidata.org/)是维基百科的结构化数据表兄弟。它不太为人所知，也不太完整，但更加雄心勃勃。它旨在提供一个可以由任何人在公共领域许可下使用的数据共享源。因此，它是一个极好的免费数据来源。

所有维基数据都以（主题，谓词，对象）的形式存储为三元组。所有主题和谓词都有自己的维基数据条目，列出了适用于它们的所有谓词。对象可以是维基数据条目，也可以是字符串、数字或日期等文字。这种结构受到早期围绕语义网络的想法的启发。

维基数据有自己的查询语言，看起来像 SQL，具有一些有趣的扩展。例如：

```py
SELECT ?item ?itemLabel ?pic
WHERE
{
	?item wdt:P31 wd:Q146 .
	OPTIONAL {
		?item wdt:P18 ?pic
	}
	SERVICE wikibase:label {
	  bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en"
	}
}
```

将选择一系列猫和它们的图片。任何以问号开头的内容都是一个变量。`wdt:P31`，或属性 31，表示“是一个实例”，`wd:Q146`是家猫的类别。因此，第四行将任何猫的实例存储在`item`中。`OPTIONAL { .. }`子句然后尝试查找项目的图片，最后一个神奇的行尝试使用自动语言功能或英语找到项目的标签。

在第十章中，我们使用维基数据和维基百科的组合来获取类别的规范图像，以用作反向图像搜索引擎的基础。

## 开放街图

[开放街图](https://www.openstreetmap.org/)就像维基百科，但用于地图。维基百科的理念是，如果世界上每个人都在维基上写下他们所知道的一切，我们将拥有最好的百科全书，而开放街图（OSM）则基于这样一个理念，即如果每个人都在维基上记录他们所知道的道路，我们将拥有最好的地图系统。值得注意的是，这两个理念都取得了相当不错的成效。

尽管 OSM 的覆盖范围相当不均匀，从几乎没有覆盖的地区到与谷歌地图相媲美或超过的地方，但数据量庞大且全部免费提供，使其成为所有地理性质项目的重要资源。

OSM 可以免费下载为二进制格式或一个庞大的 XML 文件。整个世界有数十吉字节，但在互联网上有许多地方可以找到按国家或地区分类的 OSM 数据转储，如果我们想要从小处开始。

二进制和 XML 格式都具有相同的结构：地图由一系列具有*纬度*和*经度*的*节点*组成，然后是一系列将先前定义的节点组合成较大结构的*路径*。最后，有*关系*将之前看到的任何内容（节点、路径或关系）组合成超级结构。

节点用于表示地图上的点，包括单个特征，以及定义路径的形状。路径用于简单的形状，如建筑物和道路段。最后，关系用于包含多个形状或非常大的事物，如海岸线或边界。

书中的后续部分，我们将研究一个模型，该模型接收卫星图像和渲染地图，并尝试学习自动识别道路。这些配方使用的实际数据并非专门来自 OSM，但 OSM 在深度学习中用于这类事情。例如，["Images to OSM"项目](https://github.com/jremillard/images-to-osm)展示了如何训练网络以从卫星图像中提取体育场形状，以改进 OSM 本身。

## Twitter

作为一个社交网络，Twitter 可能无法与更大的 Facebook 竞争，但作为训练深度学习模型的文本来源，它要好得多。Twitter 的 API 非常全面，可以支持各种应用。对于新手机器学习黑客来说，流式 API 可能是最有趣的。

Twitter 提供的所谓的 Firehose API 将所有推文直接流向客户端。可以想象，这是一大量数据。此外，Twitter 对此收费。不太为人所知的是，免费的 Twitter API 提供 Firehose API 的抽样版本。该 API 仅返回所有推文的 1%，但对于许多文本处理应用来说已经足够了。

推文大小有限，并附带一组有趣的元信息，如作者、时间戳、有时位置，当然还有标签、图片和 URL。在第七章中，我们研究使用此 API 构建分类器来基于文本预测表情符号。我们利用流式 API，仅保留包含一个表情符号的推文。获取一个体面的训练集需要几个小时，但如果你有一台带有稳定互联网连接的计算机，让其运行几天不应该是问题。

Twitter 是情感分析实验的热门数据来源，可以说预测表情符号是其变体，但针对语言检测、位置消歧和命名实体识别的模型也已成功在 Twitter 数据上训练。

## 古腾堡计划

早在 Google Books 之前，事实上，早在 Google 甚至互联网问世之前，1971 年，[古腾堡计划](http://www.gutenberg.org/)启动，旨在数字化所有图书。它包含超过 5 万部作品的全文，不仅包括小说、诗歌、短篇小说和戏剧，还包括烹饪书、参考书和期刊。大部分作品属于公共领域，可以从网站上免费下载。

这是一个大量文本的便捷格式，如果你不介意大部分文本有点陈旧（因为它们不再受版权保护），那么这是一个非常好的用于文本处理实验的数据来源。在第五章中，我们使用古腾堡计划获取莎士比亚的作品集作为生成更多类似莎士比亚文本的基础。如果你有 Python 库可用，只需这一行代码：

```py
shakespeare = strip_headers(load_etext(100))
```

通过古腾堡计划提供的材料大多是英文，尽管少量作品提供其他语言版本。该项目最初是纯 ASCII，但后来发展到支持多种字符编码，因此如果下载非英文文本，需要确保选择正确的编码方式——世界上并非所有内容都是 UTF-8。在第八章中，我们从古腾堡计划检索的一组书籍中提取所有对话，然后训练一个聊天机器人来模仿这些对话。

## Flickr

[Flickr](https://www.flickr.com/)是一个自 2004 年以来运营的照片分享网站。最初，它是一个名为*Game Neverending*的大型多人在线游戏的副产品。当游戏未能独立成为业务时，公司的创始人意识到公司的照片分享部分正在起飞，因此他们执行了所谓的*转变*，完全改变了公司的主要重点。一年后，Flickr 被雅虎收购。

在众多照片分享网站中，Flickr 因为几个原因而成为深度学习实验的有用图像来源。

一点是，Flickr 已经做了很长时间，并收集了数十亿张图像。这可能与人们在一个月内上传到 Facebook 的图像数量相比相形见绌，但由于用户将他们为公众消费而感到自豪的照片上传到 Flickr，Flickr 的图像平均质量更高，更具一般兴趣。

第二个原因是许可证。Flickr 上的用户为他们的照片选择许可证，许多人选择某种形式的[知识共享许可证](https://creativecommons.org/)，允许在不征得许可的情况下重新使用。虽然如果你只是通过最新的巧妙算法运行一堆照片，并且只对最终结果感兴趣，通常不需要这个，但如果你的项目最终需要重新发布原始或修改后的图像，这是非常重要的。Flickr 使这成为可能。

最后，也可能是最重要的优势是 Flickr 相对于大多数竞争对手具有 API。就像 Twitter 的 API 一样，它是一个经过深思熟虑的 REST 风格 API，使得可以轻松地以自动方式执行与网站相同的任何操作。就像 Twitter 一样，API 有很好的 Python 绑定，这使得开始实验变得更加容易。你只需要正确的库和一个 Flickr API 密钥。

对于本书相关的 API 的主要特点是搜索图像和获取图像。搜索功能非常灵活，模仿了主要网站的大多数搜索选项，尽管一些高级过滤器遗憾地缺失。获取图像可以为多种尺寸完成。通常最好先用较小版本的图像开始，然后再放大。

在第九章中，我们使用 Flickr API 获取了两组图像，一组是狗的图像，另一组是猫的图像，并训练了一个分类器来学习两者之间的区别。

## 互联网档案馆

[互联网档案馆](https://archive.org/)的宣布使命是提供“对所有知识的普遍访问”。该项目可能最著名的是其 Wayback Machine，这是一个 Web 界面，让用户随时间查看网页。它包含超过 3000 亿个捕获，追溯到 2001 年，项目称之为三维网络索引。

但互联网档案馆远远不止 Wayback Machine，它包括一系列文档、媒体和数据集，涵盖从过期的书籍到 NASA 图像再到 CD 封面艺术品到音频和视频材料的一切。这些都值得浏览，通常会激发新项目的灵感。

一个有趣的例子是截至 2015 年的所有 Reddit 评论集，共有超过 5000 万条记录。这起初是一个 Reddit 用户的项目，他耐心地使用 Reddit API 下载了所有评论，然后在 Reddit 上宣布了这一消息。当提出要将其托管在何处时，互联网档案馆成为一个不错的选择（尽管相同的数据也可以在 Google 的 BigQuery 上找到，以进行更即时的分析）。

我们在本书中使用的一个示例是[Stack Exchange 问题集](https://archive.org/details/stackexchange)。Stack Exchange 一直以来都是根据知识共享许可证授权的，因此没有什么能阻止我们自己下载这些集合，但是从互联网档案馆获取它们要容易得多。在本书中，我们使用这个数据集来训练一个模型，以匹配问题和答案（参见第六章）。

## 爬取

如果您需要项目中的特定内容，那么您要获取的数据很可能无法通过公共 API 访问。即使有公共 API，它可能会被限制到无法使用的程度。您喜欢的体育比赛的历史结果很难获得。您当地的报纸可能有在线存档，但可能没有 API 或数据转储。Instagram 有一个不错的 API，但最近对服务条款的更改使得难以使用它来获取大量的训练数据。

在这些情况下，您总是可以使用爬取，或者，如果您想听起来更加正式，可以使用爬取。在最简单的情况下，您只是想在本地系统上获取网站的副本，并且对该网站的结构或 URL 格式没有先验知识。在这种情况下，您只需从网站的根开始，获取其网页内容，从该网页内容中提取所有链接，并对每个链接执行相同的操作，直到找不到新链接为止。这也是谷歌的做法，只是规模更大。[Scrapy](https://scrapy.org)是这种类型的框架的有用工具。

有时存在明显的层次结构，比如一个旅行网站有国家页面，这些国家的地区，这些地区的城市，最后是这些城市的景点。在这种情况下，编写一个更有针对性的爬虫可能更有用，依次通过各层次的层次结构工作，直到获取所有景点。

其他时候，有一个内部 API 可以利用。许多内容导向的网站将加载整体布局，然后使用 JSON 回调到 Web 服务器获取实际数据，并将其动态插入到模板中。这样就可以轻松支持无限滚动和搜索。从服务器返回的 JSON 通常很容易理解，传递给服务器的参数也很容易理解。Chrome 扩展程序[Request Maker](http://bit.ly/request-maker)显示页面发出的所有请求，是查看是否有任何有用信息传输的好方法。

然后有一些不希望被爬取的网站。谷歌可能已经建立了一个基于爬取世界的帝国，但是它的许多服务非常聪明地检测到爬取的迹象，并会阻止您，可能会阻止从您的 IP 地址发出请求的任何人，直到您完成验证码。您可以尝试限制速率和用户代理，但是在某个时候，您可能不得不使用浏览器进行爬取。

WebDriver 是一个为测试网站而开发的框架，通过操纵浏览器可以在这些情况下非常有帮助。页面的获取是通过您选择的浏览器完成的，因此对于 Web 服务器来说，一切都似乎是真实的。然后，您可以使用控制脚本“点击”链接以转到下一页并检查结果。考虑在代码中添加延迟，使其看起来像是一个人在浏览网站，然后您就可以开始了。

第十章中的代码使用爬取技术从维基百科获取图像。有一个 URL 方案可以从维基百科 ID 转到相应的图像，但并不总是奏效。在这种情况下，我们获取包含图像的页面，并跟随链接图形，直到找到实际图像。

## 其他选项

有许多获取数据的方法。[ProgrammableWeb](https://www.programmableweb.com/)列出了超过 18,000 个公共 API（尽管其中一些处于失修状态）。以下是值得强调的三个：

Common Crawl

如果网站规模不是很大，那么爬取一个网站是可行的。但是如果您想爬取互联网的所有主要页面呢？Common Crawl 每月进行一次爬取，每次获取大约 20 亿个网页，格式易于处理。AWS 将其作为公共数据集提供，因此如果您恰好在该平台上运行，这是在互联网上运行作业的简便方法。

Facebook

多年来，Facebook API 从一个构建在 Facebook 数据之上的应用程序的非常有用的资源，逐渐转变为一个构建使 Facebook 数据更好的应用程序的资源。尽管这从 Facebook 的角度来看是可以理解的，但作为数据勘探者，人们常常想知道它可能公开的数据。尽管如此，Facebook API 仍然是一个有用的资源——尤其是在 OSM 编辑不均匀的情况下，Places API 是一个有用的资源。

美国政府

美国政府在各个层面发布了大量数据，所有这些数据都是免费可访问的。例如，人口普查数据提供了关于美国人口的详细信息，而 Data.gov 则提供了一个包含各种不同数据集的门户网站。此外，各个州和城市都有值得关注的资源。

# 预处理数据

深度神经网络在数据中找到有助于学习预测数据标签的模式方面表现出色。这也意味着我们必须小心处理给予它们的数据；数据中的任何与我们问题无关的模式都可能导致网络学习错误的内容。通过正确预处理数据，我们可以确保为我们的网络尽可能简化事情。

## 获取平衡的训练集

一个传闻故事讲述了美国军队曾经训练过一个神经网络，用于区分伪装坦克和普通森林——这是在自动分析卫星数据时非常有用的技能。乍一看，他们做了一切正确。有一天，他们在一片有伪装坦克的森林上空飞行，并拍摄了照片，另一天，当没有坦克时，他们做了同样的事情，确保拍摄的场景相似但不完全相同。他们将数据分成训练集和测试集，并让网络进行训练。

网络训练良好，开始获得良好的结果。然而，当研究人员将其送到野外测试时，人们认为这是一个笑话。预测似乎完全随机。经过一番调查，发现输入数据存在问题。所有包含坦克的图片都是在晴天拍摄的，而只有森林的图片恰好是在多云天气下拍摄的。因此，尽管研究人员认为他们的网络已经学会区分坦克和非坦克，但实际上他们训练的是一个观察天气的网络。

预处理数据的关键在于确保网络捕捉到我们希望捕捉到的信号，并且不会被无关的事物分散注意力。这里的第一步是确保我们实际上拥有正确的输入数据。理想情况下，数据应尽可能接近真实世界的情况。

确保数据中的信号是我们试图学习的信号似乎是显而易见的，但很容易出错。获取数据很困难，每个来源都有其独特之处。

当我们发现输入数据被污染时，我们可以做一些事情。最好的方法当然是重新平衡数据。因此，在坦克与森林的例子中，我们将尝试在所有类型的天气条件下获取两种情况的图片。（当您考虑到，即使所有原始图片都是在晴天拍摄的，训练集仍然会是次优的——平衡的集合应包含所有类型的天气条件。）

第二个选择是丢弃一些数据，使数据集更加平衡。也许确实有一些坦克的图片是在多云天气下拍摄的，但数量不够，所以我们可以丢弃一些晴天的图片。然而，这显然会减少训练集的大小，并且可能不是一个选项。（数据增强，在“图像预处理”中讨论，可能会有所帮助。）

第三个选择是尝试修复输入数据，比如使用一个照片滤镜使天气条件看起来更相似。然而，这很棘手，很容易导致网络可能检测到其他或更多的伪影。

## 创建数据批次

神经网络以批量（输入/输出对的集合）消耗数据。确保这些批次被适当随机化是很重要的。想象一下，我们有一组图片，前一半都是猫，后一半是狗。如果不进行洗牌，网络将无法从这个数据集中学到任何东西：几乎所有的批次要么只包含猫，要么只包含狗。如果我们使用 Keras，并且数据完全存储在内存中，这很容易通过使用`fit`方法来实现，因为它会为我们进行洗牌：

```py
char_cnn_model.fit(training_data, training_labels, epochs=20, batch_size=128)
```

这将从`training_data`和`training_labels`集合中随机创建大小为 128 的批次。Keras 会负责适当的随机化。只要我们的数据在内存中，这通常是一个不错的选择。

###### 注意

在某些情况下，我们可能希望一次使用一个批次调用`fit`，在这种情况下，我们确实需要确保事物被适当洗牌。`numpy.random.shuffle`可以很好地完成这项任务，尽管我们必须小心地同时洗牌数据和标签。

我们并不总是将所有数据存储在内存中。有时数据量太大，或者需要实时处理，无法以理想格式提供。在这种情况下，我们使用`fit_generator`：

```py
char_cnn_model.fit_generator(
    data_generator(train_tweets, batch_size=BATCH_SIZE),
    epochs=20
)
```

在这里，`data_generator`是一个生成器，产生数据批次。生成器必须确保数据被适当随机化。如果数据是从文件中读取的，那么洗牌实际上并不是一个选项。如果文件来自 SSD，并且记录都是相同大小，我们可以通过在文件内部随机寻找来进行洗牌。如果不是这种情况，文件有某种排序，我们可以通过在同一个文件中具有多个文件句柄，每个句柄位于不同位置，来增加随机性。

当设置一个生成器来实时生成批次时，我们还需要注意保持事物适当随机化。例如，在第四章中，我们通过在维基百科文章上进行训练来构建一个电影推荐系统，使用从电影页面到其他页面的链接作为训练单元。生成这些（FromPage，ToPage）对的最简单方法是随机选择一个 FromPage，然后从 FromPage 上找到的所有链接中随机选择一个 ToPage。

当然，这种方法有效，但它会更频繁地选择链接较少的页面，而不是应该的频率。一个页面上只有一个链接的 FromPage 在第一步被选中的机会与一个页面上有一百个链接的页面相同。然而，在第二步中，那一个链接肯定会被选中，而来自有一百个链接的页面的任何链接只有很小的选择机会。

## 训练、测试和验证数据

在我们设置好干净、规范化的数据并进入实际训练阶段之前，我们需要将数据分成训练集、测试集和可能的验证集。和许多事情一样，我们这样做的原因与过拟合有关。网络几乎总是会记住一点训练数据，而不是学习泛化。通过将一小部分数据分离出来作为我们不用于训练的测试集，我们可以衡量这种情况发生的程度；每个时代结束后，我们都会在训练集和测试集上测量准确性，只要这两个数字不相差太多，我们就没问题。

如果我们的数据在内存中，我们可以使用`sklearn`中的`train_test_split`来将数据整齐地分成训练集和测试集：

```py
data_train, data_test, label_train, label_test = train_test_split(
    data, labels, test_size=0.33, random_state=42)
```

这将创建一个包含 33%数据的测试集。`random_state`变量用于随机种子，这可以保证如果我们两次运行相同的程序，我们会得到相同的结果。

当使用生成器向我们的网络提供输入时，我们需要自己进行拆分。一个一般但不是非常高效的方法是使用类似以下的东西：

```py
def train_or_test(gen, train=True):
    for i, x in enumerate(gen):
        if (i % 4 == 0) != train:
            yield x
```

当`train`为`False`时，这将产生来自生成器`gen`的每四个元素。当它为`True`时，它将产生其余的元素。

有时会从训练数据中分离出第三组，称为*验证集*。这里的命名有些混淆；当只有两组时，测试集有时也被称为验证集（或留出集）。在有训练、验证和测试集的情况下，验证集用于在调整模型时测量性能。测试集只用于在所有调整完成且不再对代码进行更改时使用。

保留这第三组的原因是为了防止我们手动过拟合。复杂的神经网络可能有非常多的调整选项或超参数。找到这些超参数的正确值是一个优化问题，也可能会受到过拟合的影响。我们不断调整这些参数，直到验证集上的性能不再增加。通过拥有一个在调整过程中未使用的测试集，我们可以确保我们没有无意中为验证集优化我们的超参数。

## 文本预处理

许多神经网络问题涉及文本处理。在这些情况下，预处理输入文本涉及将输入文本映射到可以馈送到网络中的向量或矩阵。

通常，第一步是将文本分成单元。有两种常见的方法可以做到这一点：按字符或按单词。

将文本分成一系列单个字符是直接的，并且给我们一个可预测的不同标记数量。如果我们所有的文本都是基于音素的脚本，那么不同标记的数量是相当受限的。

将文本分成单词是一种更复杂的标记化策略，特别是在不指示单词开始和结束的脚本中。此外，我们最终得到的不同标记的数量没有明显的上限。许多文本处理工具包都有一个“标记化”功能，通常还允许去除重音并可选择将所有标记转换为小写。

一个称为*词干提取*的过程，其中我们将每个单词转换为其根形式（通过删除任何与语法相关的修改），可以帮助，特别是对于比英语更注重语法的语言。在第八章中，我们将遇到一种子词标记化策略，将复杂的单词分解为子标记，从而保证不同标记的数量有一个特定的上限。

一旦我们将文本分成标记，我们需要对其进行向量化。最简单的方法是称为*一热编码*。在这里，我们为每个唯一的标记分配一个整数*i*，从 0 到标记数量，然后将每个标记表示为一个只包含 0 的向量，除了第*i*个条目，其中包含 1。在 Python 代码中，这将是：

```py
idx_to_token = list(set(tokens))
token_to_idx = {token: idx for idx, token in enumerate(idx_to_token)}
one_hot = lambda token: [1 if i == token_to_idx[token] else 0
                         for i in range(len(idx_to_token))]
encoded = np.asarray([one_hot(token) for token in tokens])
```

这应该让我们得到一个准备好供消费的大型二维数组。

一热编码适用于在字符级别处理文本时。它也适用于单词级别处理，尽管对于词汇量大的文本，可能会变得难以处理。有两种流行的编码策略可以解决这个问题。

第一种方法是将文档视为“词袋”。在这里，我们不关心单词的顺序，只关心某个单词是否存在。然后，我们可以将文档表示为一个向量，其中每个唯一标记都有一个条目。在最简单的方案中，如果单词在文档中存在，则我们将放置一个 1，如果不存在则放置一个 0。

由于英语中出现频率最高的 100 个单词占所有文本的一半左右，它们对于文本分类任务并不是很有用；几乎所有文档都会包含它们，所以在我们的向量中包含这些词并没有太大帮助。一个常见的策略是从我们的词袋中删除它们，这样网络就可以专注于那些真正有影响的词语。

术语频率-逆文档频率，或 tf-idf，是这一概念的一个更复杂的版本。我们不是在文档中存储一个标记是否存在，而是存储该术语在文档中的相对频率，与该术语在整个文档语料库中出现的频率相比。这里的直觉是，一个不太常见的标记在文档中出现比一个一直出现的标记更有意义。Scikit-learn 提供了自动计算这一概念的方法。

处理单词级别的编码的第二种方法是使用嵌入。第三章讲解了嵌入并提供了一个很好的理解方式。通过嵌入，我们将一个特定大小的向量（通常长度为 50 到 300）与每个标记关联起来。当我们输入一个表示为标记 ID 序列的文档时，嵌入层将自动查找相应的嵌入向量并输出一个二维数组。

嵌入层将学习每个术语的正确权重，就像神经网络中的任何一层一样。这通常需要大量的学习，无论是在处理方面还是所需的数据量方面。不过，嵌入的一个好处是可以下载预训练集，并且我们可以使用这些预训练集来初始化我们的嵌入层。第七章有一个这种方法的很好例子。

## 图像预处理

深度神经网络在处理图像方面非常有效，可以用于从视频中检测猫到将不同艺术家的风格应用于自拍等各种任务。然而，与文本一样，正确预处理输入图像是至关重要的。

第一步是标准化。许多网络只能在特定大小上运行，因此第一步是将图像调整/裁剪到目标大小。通常使用中心裁剪和直接调整大小，但有时结合使用效果更好，以保留更多图像的同时保持调整大小的失真在一定范围内。

为了使颜色标准化，对于每个像素，我们通常减去平均值并除以标准差。这确保所有值的平均值围绕 0 中心，并且近 70%的值在舒适的[-1, 1]范围内。这里的一个新发展是使用*批量标准化*；而不是事先对所有数据进行标准化，这会减去批次的平均值并除以标准差。这会带来更好的结果，并且可以作为网络的一部分。

*数据增强*是一种通过添加训练图像的变化来增加训练数据量的策略。如果我们在训练数据中添加水平翻转的图像版本，那么我们就可以将训练数据翻倍——镜像猫仍然是一只猫。从另一个角度来看，我们所做的是告诉网络可以忽略翻转。如果我们所有的猫图片都是朝一个方向看的，我们的网络可能会学习到这是猫的一部分；添加翻转会撤销这一点。

Keras 有一个方便的`ImageDataGenerator`类，您可以配置它来生成各种图像变化，包括旋转、平移、颜色调整和放大。然后，您可以将其用作模型的`fit_generator`方法的数据生成器：

```py
datagen = ImageDataGenerator(
    rotation_range=20,
    horizontal_flip=True)

model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),
                    steps_per_epoch=len(x_train) / 32, epochs=epochs)
```

## 结论

在训练深度学习模型之前，数据的预处理是一个重要的步骤。所有这些中的一个共同点是，我们希望网络尽可能容易地学习正确的内容，而不会被输入的无关特征所困扰。获取平衡的训练集，创建随机化的训练批次，以及规范化数据的各种方式都是其中的重要部分。
