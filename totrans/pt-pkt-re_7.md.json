["```py\nfrom torchvision.models import vgg16\n\nmodel = vgg16(pretrained=True)\n```", "```py\nimport numpy as np\n\nmodel_parameters = filter(lambda p:\n      p.requires_grad, model.parameters())\n\nparams = sum([np.prod(p.size()) for\n      p in model_parameters])\nprint(params)\n\n# out: 138357544\n```", "```py\nimport system\nimport torch\n\nif __name__ == \"__main__\":\n  model = MyModel()\n  model.load_state_dict(torch.load(PATH))\n  model.eval()\n  outputs = model(inputs)\n  print(outputs)\n```", "```py\nimport torch\n\nmodel = vgg16(pretrained=True)\nexample_input = torch.rand(1, 3, 224, 224)\ntorchscript_model = torch.jit.trace(model,\n                            example_input)\ntorchscript_model.save(\"traced_vgg16_model.pt\")\n```", "```py\nimport torch.nn as nn\n\nclass ControlFlowModel(nn.Module):\n  def __init__(self, N):\n    super(ControlFlowModel, self).__init__()\n    self.fc = nn.Linear(N,100)\n\n  def forward(self, input):\n    if input.sum() > 0:\n      output = input\n    else:\n      output = -input\n    return output\n\nmodel = ControlFlowModel(10)\ntorchcript_model = torch.jit.script(model)\ntorchscript_model.save(\"scripted_vgg16_model.pt\")\n```", "```py\n\ninclude<torch/script.h>#include <iostream>#include <memory>intmain(intargc,constchar*argv[]){if(argc!=2){std::cerr<<\"usage: example-app\">>\\\n\"*`<path-to-exported-script-module>`*\\n\";return-1;}torch::jit::script::Modulemodel;model=torch::jit::load(argv[1]);std::vector<torch::jit::IValue>inputs;inputs.push_back(\\\ntorch::ones({1,3,224,224}));at::Tensoroutput=model.forward(inputs).toTensor();std::cout\\\n<<output.slice(/*dim=*/1,\\\n/*start=*/0,/*end=*/5)\\\n<<'\\n';}}\n```", "```py\n\n$ `conda``install``torchserve``torch-model-archiver``-c``pytorch`$ `pip``install``torchserve``torch-model-archiver`\n```", "```py\n\n$`torch``-``model``-``archiver``-``-``model``-``name``vgg16``-``-``version``1.0``-``-``serialized``-``file``model``.``pt``-``-``handler``image_classifier`\n```", "```py\n\n$`torch``-``model``-``archiver``-``-``model``-``name``vgg16``-``-``version``1.0``-``-``model``-``file``model``.``py``-``-``serialized``-``file``model``.``pt``-``-``handler``image_classifier`\n```", "```py\n\n$ `torch-model-archiver``-h`usage:torch-model-archiver[-h]--model-nameMODEL_NAME--versionMODEL_VERSION_NUMBER--model-fileMODEL_FILE_PATH--serialized-fileMODEL_SERIALIZED_PATH--handlerHANDLER[--runtime{python,python2,python3}][--export-pathEXPORT_PATH][-f][--requirements-file]\n```", "```py\n\n$ `torchserve``--model-store``/models``--start``--models``all`\n```", "```py\n\n$c`url``http://localhost:8080/predictions/vgg16``-T``hot_dog.jpg`\n```", "```py\n{\n    \"class\": \"n02175045 hot dog\",\n    \"probability\": 0.788482002828\n}\n```", "```py\n\n$ `curl``http://localhost:8080/ping`\n```", "```py\n{\n  \"health\": \"healthy!\"\n}\n```", "```py\n\n$ `curl``-X``OPTIONS``http://localhost:8080`\n```", "```py\n\n$ `curl``http://127.0.0.1:8082/metrics`# HELP ts_inference_latency_microseconds #    Cumulative inference # TYPE ts_inference_latency_microseconds counter ts_inference_latency_microseconds{uuid=\"d5f84dfb-fae8-4f92-b217-2f385ca7470b\",...ts_inference_latency_microseconds{uuid=\"d5f84dfb-fae8-4f92-b217-2f385ca7470b\",model_name=\"noop\"...# HELP ts_inference_requests_total Total number of inference ... # TYPE ts_inference_requests_total counter ts_inference_requests_total{uuid=\"d5f84dfb-fae8-4f92-b217-2f385ca7470b\",...ts_inference_requests_total{uuid=\"d5f84dfb-fae8-4f92-b217-2f385ca7470b\",model_name=\"noop\"...# HELP ts_queue_latency_microseconds Cumulative queue duration ... # TYPE ts_queue_latency_microseconds counter ts_queue_latency_microseconds{uuid=\"d5f84dfb-fae8-4f92-b217-2f385ca7470b\",...ts_queue_latency_microseconds{uuid=\"d5f84dfb-fae8-4f92-b217-2f385ca7470b\",model_name=\"noop\"...\n```", "```py\nmodel = vgg16(pretrained=True)\nexample_input = torch.rand(1, 3, 224, 224)\nonnx_model = torch.onnx.export(model,\n                               example_input,\n                               \"vgg16.onnx\")\n```", "```py\nimport onnx\n\nmodel = onnx.load(\"vgg16.onnx\")\nonnx.checker.check_model(model)\nonnx.helper.printable_graph(model.graph)\n```", "```py\nimport io\nimport json\n\nfrom torchvision import models\nimport torchvision.transforms as transforms\nfrom PIL import Image\nfrom flask import Flask, jsonify, request\n```", "```py\nimport json\nimagenet_class_index = json.load(\n    open(\"./imagenet_class_index.json\"))\n\nmodel = models.vgg16(pretrained=True)\n\nimage_transforms = transforms.Compose(\n    [transforms.Resize(255),\n     transforms.CenterCrop(224),\n     transforms.ToTensor(),\n     transforms.Normalize(\n          [0.485, 0.456, 0.406],\n          [0.229, 0.224, 0.225])])\n\ndef get_prediction(image_bytes):\n    image = Image.open(io.BytesIO(image_bytes))\n    tensor = image_transforms(image)\n    outputs = model(tensor)\n    _, y = outputs.max(1)\n    predicted_idx = str(y.item())\n    return imagenet_class_index[predicted_idx]\n```", "```py\napp = Flask(__name__)\n\n@app.route('/predict', methods=['POST'])\ndef predict():\n  if request.method == 'POST':\n    file = request.files['file']\n  img_bytes = file.read()\n  class_id, class_name = \\\n    get_prediction(image_bytes=img_bytes)\n  return jsonify({'class_id': class_id,\n                 'class_name': class_name})\n```", "```py\nif __name__ == '__main__':\n    app.run()\n```", "```py\n>>> FLASK_ENV=development FLASK_APP=app.py flask run\n```", "```py\nimport requests\n\nresp = requests.post(\n    \"http://localhost:5000/predict\",\n    files={\"file\": open('cat.jpg','rb')})\n\nprint(resp.json())\n\n>>> {\"class_id\": \"n02124075\", \"class_name\": \"Egyptian_cat\"}\n```", "```py\n!pip install flask-ngrok\n```", "```py\nfromflask_ngrokimportrun_with_ngrok![1](Images/1.png)@app.route(\"/\")defhome():return\"<h1>Running Flask on Google Colab!</h1>\"app.run()app=Flask(__name__)run_with_ngrok(app)![2](Images/2.png)@app.route('/predict',methods=['POST'])defpredict():ifrequest.method=='POST':file=request.files['file']img_bytes=file.read()class_id,class_name=\\\nget_prediction(image_bytes=img_bytes)returnjsonify({'class_id':class_id,'class_name':class_name})app.run()![3](Images/3.png)\n```", "```py\n\n * Serving Flask app \"__main__\" (lazy loading)\n * Environment: production\n   WARNING: This is a development server.\n     Do not use it in a production deployment.\n   Use a production WSGI server instead.\n * Debug mode: off\n * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n * Running on http://c0c97117ba27.ngrok.io\n * Traffic stats available on http://127.0.0.1:4040\n127.0.0.1 - - [08/Dec/2020 20:46:05] \"GET / HTTP/1.1\" 200 -\n127.0.0.1 - - [08/Dec/2020 20:46:05]\n  \"GET /favicon.ico HTTP/1.1\" 404 -\n127.0.0.1 - - [08/Dec/2020 20:46:06] \"GET / HTTP/1.1\" 200 -\n\n```", "```py\nimport requests\n\nresp = requests.post(\n      \"http://c0c97117ba27.ngrok.io/predict\",\n      files={\"file\": open('cat.jpg','rb')})\n\nprint(resp.json())\n\n# out :\n# {\"class_id\": \"n02124075\",\n#  \"class_name\": \"Egyptian_cat\"}\n```", "```py\n\n$ git clone https://github.com/pytorch/serve.git\ncd serve/docker\n\n```", "```py\n\n$ curl -o /home/model-server/vgg16.pth \\\n    https://download.pytorch.org/models/vgg16.pth\n\n```", "```py\n\n$ ./build_image.sh -g\n\n```", "```py\n\n$ docker run --rm -it --gpus '\"device=1\"' \\\n    -p 8080:8080 -p 8081:8081 -p 8082:8082 \\\n    -p 7070:7070 -p 7071:7071 \\\n    pytorch/torchserve:latest-gpu\n\n```", "```py\nimporttorchimporttorchvisionfromtorch.utils.mobile_optimizer \\ importoptimize_for_mobilemodel=torchvision.models.vgg16(pretrained=True)model.eval()example=torch.rand(1,3,224,224)![1](Images/1.png)traced_script_module=\\\ntorch.jit.trace(model,example)![2](Images/2.png)torchscript_model_optimized=\\\noptimize_for_mobile(traced_script_module)![3](Images/3.png)torchscript_model_optimized.save(\"model.pt\")![4](Images/4.png)\n```", "```py\n\n$ pod install\n\n```", "```py\nlet image = UIImage(named: \"image.jpg\")! \\\n  imageView.image = image\n\nlet resizedImage = image.resized(\n  to: CGSize(width: 224, height: 224))\n\nguard var pixelBuffer = resizedImage.normalized()\nelse return\n```", "```py\nprivate lazy var module: TorchModule = {\n    if let filePath = Bundle.main.path(\n      forResource: \"model\", ofType: \"pt\"),\n\n        let module = TorchModule(\n                 fileAtPath: filePath) {\n          return module\n    } else {\n        fatalError(\"Can't find the model file!\")\n    }\n}()\n```", "```py\nguard let outputs = module.predict(image:\n  UnsafeMutableRawPointer(&pixelBuffer))\nelse {\n    return\n}\n```", "```py\nat::Tensor tensor = torch::from_blob(\n  imageBuffer, {1, 3, 224, 224}, at::kFloat);\n\ntorch::autograd::AutoGradMode guard(false);\nauto outputTensor = _impl.forward(\n  {tensor}).toTensor();\nfloat* floatBuffer =\n  outputTensor.data_ptr<float>();\n```", "```py\nimport torch\nimport torchvision\nfrom torch.utils.mobile_optimizer \\\n  import optimize_for_mobile\n\nmodel = torchvision.models.vgg16(pretrained=True)\nmodel.eval()\nexample = torch.rand(1, 3, 224, 224)\n\ntraced_script_module = \\\n  torch.jit.trace(model, example)\ntorchscript_model_optimized = \\\n  optimize_for_mobile(traced_script_module)\ntorchscript_model_optimized.save(\"model.pt\")\n```", "```py\nrepositories {\n  jcenter()\n}\n\ndependencies {\n  implementation\n    'org.pytorch:pytorch_android:1.4.0'\n  implementation\n    'org.pytorch:pytorch_android_torchvision:1.4.0'\n}\n```", "```py\nBitmap bitmap = \\\n  BitmapFactory.decodeStream(\n    getAssets().open(\"image.jpg\"));\n\nTensor inputTensor = \\\n  TensorImageUtils.bitmapToFloat32Tensor(\n    bitmap,\n    TensorImageUtils.TORCHVISION_NORM_MEAN_RGB,\n    TensorImageUtils.TORCHVISION_NORM_STD_RGB);\n```", "```py\nModule module = Module.load(\n  assetFilePath(this, \"model.pt\"));\n```", "```py\nTensor outputTensor = module.forward(\n  IValue.from(inputTensor)).toTensor();\nfloat[] scores = \\\n  outputTensor.getDataAsFloatArray();\n\nfloat maxScore = -Float.MAX_VALUE;\nint maxScoreIdx = -1;\nfor (int i = 0; i < scores.length; i++) {\n  if (scores[i] > maxScore) {\n    maxScore = scores[i];\n    maxScoreIdx = i;\n  }\n}\nString className = \\\n  ImageNetClasses.IMAGENET_CLASSES[maxScoreIdx];\n```"]