["```py\nmake -f tensorflow/lite/micro/tools/make/Makefile test\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile \\\n  TARGET=\"sparkfun_edge\" micro_speech_bin\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile \\\n  TARGET=\"disco_f746ng\" generate_micro_speech_mbed_project\n```", "```py\nTfLiteStatus GetAudioSamples(tflite::ErrorReporter* error_reporter,\n                             int start_ms, int duration_ms,\n                             int* audio_samples_size, int16_t** audio_samples);\nint32_t LatestAudioTimestamp();\n```", "```py\nnamespace {\nint16_t g_dummy_audio_data[kMaxAudioSampleSize];\nint32_t g_latest_audio_timestamp = 0;\n}  // namespace\n\nTfLiteStatus GetAudioSamples(tflite::ErrorReporter* error_reporter,\n                             int start_ms, int duration_ms,\n                             int* audio_samples_size, int16_t** audio_samples) {\n  for (int i = 0; i < kMaxAudioSampleSize; ++i) {\n    g_dummy_audio_data[i] = 0;\n  }\n  *audio_samples_size = kMaxAudioSampleSize;\n  *audio_samples = g_dummy_audio_data;\n  return kTfLiteOk;\n}\n\nint32_t LatestAudioTimestamp() {\n  g_latest_audio_timestamp += 100;\n  return g_latest_audio_timestamp;\n}\n```", "```py\n   for (int b = 0; b < batches; ++b) {\n      for (int out_y = 0; out_y < output_height; ++out_y) {\n        for (int out_x = 0; out_x < output_width; ++out_x) {\n          for (int ic = 0; ic < input_depth; ++ic) {\n            for (int m = 0; m < depth_multiplier; m++) {\n              const int oc = m + ic * depth_multiplier;\n              const int in_x_origin = (out_x * stride_width) - pad_width;\n              const int in_y_origin = (out_y * stride_height) - pad_height;\n              int32 acc = 0;\n              for (int filter_y = 0; filter_y < filter_height; ++filter_y) {\n                for (int filter_x = 0; filter_x < filter_width; ++filter_x) {\n                  const int in_x =\n                      in_x_origin + dilation_width_factor * filter_x;\n                  const int in_y =\n                      in_y_origin + dilation_height_factor * filter_y;\n                  // If the location is outside the bounds of the input image,\n                  // use zero as a default value.\n                  if ((in_x >= 0) && (in_x < input_width) && (in_y >= 0) &&\n                      (in_y < input_height)) {\n                    int32 input_val =\n                        input_data[Offset(input_shape, b, in_y, in_x, ic)];\n                    int32 filter_val = filter_data[Offset(\n                        filter_shape, 0, filter_y, filter_x, oc)];\n                    acc += (filter_val + filter_offset) *\n                           (input_val + input_offset);\n                  }\n                }\n              }\n              if (bias_data) {\n                acc += bias_data[oc];\n              }\n              acc = DepthwiseConvRound<output_rounding>(acc, output_multiplier,\n                                                        output_shift);\n              acc += output_offset;\n              acc = std::max(acc, output_activation_min);\n              acc = std::min(acc, output_activation_max);\n              output_data[Offset(output_shape, b, out_y, out_x, oc)] =\n                  static_cast<uint8>(acc);\n            }\n          }\n        }\n      }\n    }\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile \\\n  TARGET=\"bluepill\" TAGS=\"portable_optimized foo\" test\n```", "```py\nifeq ($(TARGET),$(filter $(TARGET),apollo3evb sparkfun_edge))\n  export PATH := $(MAKEFILE_DIR)/downloads/gcc_embedded/bin/:$(PATH)\n  TARGET_ARCH := cortex-m4\n  TARGET_TOOLCHAIN_PREFIX := arm-none-eabi-\n...\n  $(eval $(call add_third_party_download,$(GCC_EMBEDDED_URL), \\\n      $(GCC_EMBEDDED_MD5),gcc_embedded,))\n  $(eval $(call add_third_party_download,$(CMSIS_URL),$(CMSIS_MD5),cmsis,))\n...\n  PLATFORM_FLAGS = \\\n    -DPART_apollo3 \\\n    -DAM_PACKAGE_BGA \\\n    -DAM_PART_APOLLO3 \\\n    -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK \\\n...\n  LDFLAGS += \\\n    -mthumb -mcpu=cortex-m4 -mfpu=fpv4-sp-d16 -mfloat-abi=hard \\\n    -nostartfiles -static \\\n    -Wl,--gc-sections -Wl,--entry,Reset_Handler \\\n...\n  MICROLITE_LIBS := \\\n    $(BOARD_BSP_PATH)/gcc/bin/libam_bsp.a \\\n    $(APOLLO3_SDK)/mcu/apollo3/hal/gcc/bin/libam_hal.a \\\n    $(GCC_ARM)/lib/gcc/arm-none-eabi/7.3.1/thumb/v7e-m/fpv4-sp/hard/crtbegin.o \\\n    -lm\n  INCLUDES += \\\n    -isystem$(MAKEFILE_DIR)/downloads/cmsis/CMSIS/Core/Include/ \\\n    -isystem$(MAKEFILE_DIR)/downloads/cmsis/CMSIS/DSP/Include/ \\\n    -I$(MAKEFILE_DIR)/downloads/CMSIS_ext/ \\\n...\n  MICROLITE_CC_SRCS += \\\n    $(APOLLO3_SDK)/boards/apollo3_evb/examples/hello_world/gcc_patched/ \\\n        startup_gcc.c \\\n    $(APOLLO3_SDK)/utils/am_util_delay.c \\\n    $(APOLLO3_SDK)/utils/am_util_faultisr.c \\\n    $(APOLLO3_SDK)/utils/am_util_id.c \\\n    $(APOLLO3_SDK)/utils/am_util_stdio.c\n```", "```py\n# Tests the feature provider module using the mock audio provider.\n$(eval $(call microlite_test,feature_provider_mock_test,\\\n$(FEATURE_PROVIDER_MOCK_TEST_SRCS),$(FEATURE_PROVIDER_MOCK_TEST_HDRS)))\n```", "```py\n#include \"tensorflow/lite/micro/testing/micro_test.h\"\n\nTF_LITE_MICRO_TESTS_BEGIN\n\nTF_LITE_MICRO_TEST(SomeTest) {\n  TF_LITE_LOG_EXPECT_EQ(true, true);\n}\n\nTF_LITE_MICRO_TESTS_END\n```", "```py\n----------------------------------------------------------------------------\nTesting SomeTest\n1/1 tests passed\n~~~ALL TESTS PASSED~~~\n----------------------------------------------------------------------------\n```", "```py\n#include <stdio.h>\n\nint main(int argc, char** argv) {\n  fprintf(stderr, \"Hello World!\\n\");\n}\n```", "```py\nvoid DebugLog(const char* s) {\n  asm(\"mov r0, #0x04\\n\"  // SYS_WRITE0\n      \"mov r1, %[str]\\n\"\n      \"bkpt #0xAB\\n\"\n      :\n      : [ str ] \"r\"(s)\n      : \"r0\", \"r1\");\n}\n\nint main(int argc, char** argv) {\n  DebugLog(\"Hello World!\\n\");\n}\n```", "```py\n#include <mbed.h>\n\n// On mbed platforms, we set up a serial port and write to it for debug logging.\nvoid DebugLog(const char* s) {\n  static Serial pc(USBTX, USBRX);\n  pc.printf(\"%s\", s);\n}\n\nint main(int argc, char** argv) {\n  DebugLog(\"Hello World!\\n\");\n}\n```", "```py\n#include \"Arduino.h\"\n\n// The Arduino DUE uses a different object for the default serial port shown in\n// the monitor than most other models, so make sure we pick the right one. See\n// https://github.com/arduino/Arduino/issues/3088#issuecomment-406655244\n#if defined(__SAM3X8E__)\n#define DEBUG_SERIAL_OBJECT (SerialUSB)\n#else\n#define DEBUG_SERIAL_OBJECT (Serial)\n#endif\n\n// On Arduino platforms, we set up a serial port and write to it for debug\n// logging.\nvoid DebugLog(const char* s) {\n  static bool is_initialized = false;\n  if (!is_initialized) {\n    DEBUG_SERIAL_OBJECT.begin(9600);\n    // Wait for serial port to connect. Only needed for some models apparently?\n    while (!DEBUG_SERIAL_OBJECT) {\n    }\n    is_initialized = true;\n  }\n  DEBUG_SERIAL_OBJECT.println(s);\n}\n\nint main(int argc, char** argv) {\n  DebugLog(\"Hello World!\\n\");\n}\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile \\\n  generate_micro_error_reporter_test_make_project\n```", "```py\n#include \"tensorflow/lite/micro/debug_log.h\"\n\nextern \"C\" void DebugLog(const char* s) {\n  // Do nothing for now.\n}\n```", "```py\nint main(int argc, char** argv) {\n  tflite::MicroErrorReporter micro_error_reporter;\n  tflite::ErrorReporter* error_reporter = &micro_error_reporter;\n  error_reporter->Report(\"Number: %d\", 42);\n  error_reporter->Report(\"Badly-formed format string %\");\n  error_reporter->Report(\"Another % badly-formed %% format string\");\n  error_reporter->Report(\"~~~%s~~~\", \"ALL TESTS PASSED\");\n}\n```", "```py\nNumber: 42\nBadly-formed format string\nAnother  badly-formed  format string\n~~~ALL TESTS PASSED~~~\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=my_mcu clean\nmake -f tensorflow/lite/micro/tools/make/Makefile \\\n  TARGET=my_mcu generate_micro_error_reporter_test_make_project\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile generate_projects \\\n  TARGET=my_mcu\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile \\\n  TARGET=bluepill micro_error_reporter_test_bin\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=bluepill test\n```", "```py\nroot_type Model;\n```", "```py\ntable Model {\n```", "```py\n  // Map the model into a usable data structure. This doesn't involve any\n  // copying or parsing, it's a very lightweight operation.\n  const tflite::Model* model =\n      ::tflite::GetModel(g_tiny_conv_micro_features_model_data);\n```", "```py\n  if (model->version() != TFLITE_SCHEMA_VERSION) {\n    error_reporter->Report(\n        \"Model provided is schema version %d not equal \"\n        \"to supported version %d.\\n\",\n        model->version(), TFLITE_SCHEMA_VERSION);\n    return 1;\n  }\n```", "```py\n  // Version of the schema.\n  version:uint;\n```", "```py\n  const flatbuffers::Vector<flatbuffers::Offset<Buffer>>* buffers =\n      model->buffers();\n```", "```py\n// Table of raw data buffers (used for constant tensors). Referenced by tensors\n// by index. The generous alignment accommodates mmap-friendly data structures.\ntable Buffer {\n  data:[ubyte] (force_align: 16);\n}\n```", "```py\n  auto* subgraphs = model->subgraphs();\n  if (subgraphs->size() != 1) {\n    error_reporter->Report(\"Only 1 subgraph is currently supported.\\n\");\n    initialization_status_ = kTfLiteError;\n    return;\n  }\n  subgraph_ = (*subgraphs)[0];\n```", "```py\n// The root type, defining a subgraph, which typically represents an entire\n// model.\ntable SubGraph {\n  // A list of all tensors used in this subgraph.\n  tensors:[Tensor];\n\n  // Indices of the tensors that are inputs into this subgraph. Note this is\n  // the list of non-static tensors that feed into the subgraph for inference.\n  inputs:[int];\n\n  // Indices of the tensors that are outputs out of this subgraph. Note this is\n  // the list of output tensors that are considered the product of the\n  // subgraph's inference.\n  outputs:[int];\n\n  // All operators, in execution order.\n  operators:[Operator];\n\n  // Name of this subgraph (used for debugging).\n  name:string;\n}\n```", "```py\n  tensors_ = subgraph_->tensors();\n```", "```py\ntable Tensor {\n  // The tensor shape. The meaning of each entry is operator-specific but\n  // builtin ops use: [batch size, height, width, number of channels] (That's\n  // Tensorflow's NHWC).\n  shape:[int];\n  type:TensorType;\n  // An index that refers to the buffers table at the root of the model. Or,\n  // if there is no data buffer associated (i.e. intermediate results), then\n  // this is 0 (which refers to an always existent empty buffer).\n  //\n  // The data_buffer itself is an opaque container, with the assumption that the\n  // target device is little-endian. In addition, all builtin operators assume\n  // the memory is ordered such that if `shape` is [4, 3, 2], then index\n  // [i, j, k] maps to data_buffer[i*3*2 + j*2 + k].\n  buffer:uint;\n  name:string;  // For debugging and importing back into tensorflow.\n  quantization:QuantizationParameters;  // Optional.\n\n  is_variable:bool = false;\n}\n```", "```py\noperators_ = subgraph_->operators();\n```", "```py\n// An operator takes tensors as inputs and outputs. The type of operation being\n// performed is determined by an index into the list of valid OperatorCodes,\n// while the specifics of each operations is configured using builtin_options\n// or custom_options.\ntable Operator {\n  // Index into the operator_codes array. Using an integer here avoids\n  // complicate map lookups.\n  opcode_index:uint;\n\n  // Optional input and output tensors are indicated by -1.\n  inputs:[int];\n  outputs:[int];\n\n  builtin_options:BuiltinOptions;\n  custom_options:[ubyte];\n  custom_options_format:CustomOptionsFormat;\n\n  // A list of booleans indicating the input tensors which are being mutated by\n  // this operator.(e.g. used by RNN and LSTM).\n  // For example, if the \"inputs\" array refers to 5 tensors and the second and\n  // fifth are mutable variables, then this list will contain\n  // [false, true, false, false, true].\n  //\n  // If the list is empty, no variable is mutated in this operator.\n  // The list either has the same length as `inputs`, or is empty.\n  mutating_variable_inputs:[bool];\n}\n```", "```py\ntable Conv2DOptions {\n  padding:Padding;\n  stride_w:int;\n  stride_h:int;\n  fused_activation_function:ActivationFunctionType;\n  dilation_w_factor:int = 1;\n  dilation_h_factor:int = 1;\n}\n```", "```py\n  const flexbuffers::Map& m = flexbuffers::GetRoot(buffer_t, length).AsMap();\n  op_data->max_detections = m[\"max_detections\"].AsInt32();\n```", "```py\nbazel test tensorflow/lite/kernels:all\n```", "```py\nbazel test ttensorflow/lite/micro/kernels:conv_test --test_output=streamed\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile test_conv_test\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=bluepill test_conv_test\n```"]