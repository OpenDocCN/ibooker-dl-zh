<html><head></head><body><section data-pdf-bookmark="Chapter 3. Data and AI Governance and AI Engineering" data-type="chapter" epub:type="chapter"><div class="chapter" id="chapter_3_data_and_ai_governance_and_ai_engineering_1748539918115723">
<h1><span class="label">Chapter 3. </span>Data and AI Governance and AI Engineering</h1>

<p>The first chapter of this book introduced the EU AI Act and laid the foundation for understanding trustworthy AI as its primary motivation. We then explored the engineering aspects of the ML development process and examined the synergy between the CRISP-ML(Q) lifecycle model and the technical components of MLOps, highlighting how this integration supports the development of trustworthy AI through structured processes, transparency, and reproducibility. Here, we will focus on compliance from an organizational perspective, considering the interplay between data and AI governance, risk management, and conformity with the EU AI Act.</p>

<section data-pdf-bookmark="The Importance of Data and AI Governance in the EU AI Act Era" data-type="sect1"><div class="sect1" id="chapter_3_the_importance_of_data_and_ai_governance_in_the_eu_1748539918115932">
<h1>The Importance of Data and AI Governance in the <span class="keep-together">EU AI Act Era</span></h1>

<p>Let’s start with three notable real-world examples that illustrate how poor data governance and AI governance<a contenteditable="false" data-primary="AI governance" data-seealso="data governance" data-type="indexterm" id="ai-gov-1"/> practices have led to significant failures<a contenteditable="false" data-primary="AI failures (case studies)" data-type="indexterm" id="ai-fail-1"/> of AI products:</p>

<dl>
	<dt>IBM Watson for Oncology</dt>
	<dd>
	<p>The development of Watson for Oncology<a contenteditable="false" data-primary="AI failures (case studies)" data-secondary="IBM Watson for Oncology" data-type="indexterm" id="id462"/> (launched in 2016) faced significant criticism due to the system recommending <a href="https://oreil.ly/iCQ0B">unsafe and incorrect cancer treatments</a>. This was attributed to incomplete and biased training data that included only a small number of synthetic cancer cases rather than real clinical data, resulting in flawed recommendations and limited clinical relevance. Internal documents and customer feedback highlighted a lack of transparency, systemic issues, and dissatisfaction with the product’s recommendations. This case emphasizes the critical need for high-quality, accurate, and relevant data in AI training.</p>
	</dd>
	<dt class="pagebreak-before">Amazon’s AI recruiting tool</dt>
	<dd>
	<p>In 2018, Amazon developed an experimental AI recruiting<a contenteditable="false" data-primary="AI failures (case studies)" data-secondary="Amazon’s AI recruiting tool" data-type="indexterm" id="id463"/> tool to automate candidate screening. However, the system was found to exhibit <a href="https://oreil.ly/L2cEr">bias against women</a>, due to the AI model being trained on 10 years’ worth of resumes that had come overwhelmingly from male candidates. This led to it downgrading resumes containing the word “women’s” and penalizing candidates from all-women’s colleges. This result highlighted the lack of sufficient auditing of the training data and model for demographic bias and led to Amazon scrapping the tool entirely. This case underscores the need for careful data screening and debiasing in AI <span class="keep-together">applications</span>.</p>
	</dd>
	<dt>iTutor Group’s AI recruiting tool</dt>
	<dd>
	<p>In 2023, iTutor Group used AI-powered recruiting software<a contenteditable="false" data-primary="AI failures (case studies)" data-secondary="iTutor Group’s AI recruiting tool" data-type="indexterm" id="id464"/> that automatically rejected female applicants aged 55 and older and male applicants aged 60 and older. The system’s screening criteria were based on age, leading to discriminatory practices. As a result, the US Equal Employment Opportunity Commission (EEOC) filed a suit against iTutor Group, which <a href="https://oreil.ly/66rkj">the company settled</a> by agreeing to pay $365,000 and implement new anti-discrimination policies. This case highlights the need for oversight and bias prevention in AI recruiting tools.​</p>
	</dd>
</dl>

<p class="fix_tracking">These and other <a href="https://oreil.ly/l3E9Y">famous AI disasters</a> illustrate the critical need for rigorous data governance practices, including ensuring data quality, <span class="keep-together">representativeness</span>, and transparency. Thorough data quality<a contenteditable="false" data-primary="data quality" data-type="indexterm" id="id465"/> assessments, robust data protection measures, and ethical considerations in AI development and deployment are essential. Comprehensive bias testing across diverse populations is particularly important in sensitive areas such as healthcare and education, and ongoing monitoring and auditing of AI systems in production are necessary to identify and address issues early.</p>

<p>Data and AI governance play a vital role in the age of the EU AI Act. Organizations must have robust data and AI governance frameworks in place to meet the Act’s strict requirements related to data quality, documentation, transparency, human oversight, and risk management. Moreover, effective governance is essential for identifying, assessing, and mitigating the risks associated with AI systems, which can pose threats to fundamental rights, safety, and the environment if not properly managed.</p>

<p>Strong data and AI governance promote responsible and ethical AI development, in line with the EU AI Act’s aim to foster the development of trustworthy AI that upholds EU values and principles. This approach enables organizations to innovate with AI while safeguarding privacy and other fundamental rights.</p>

<p>Transparency and explainability in AI systems are not just technical challenges but legal and ethical requirements. The examples mentioned here underscore the critical need for rigorous data governance practices, including ensuring data quality, <span class="keep-together">representativeness</span>, transparency, and ethical considerations in AI development and deployment. Next, we’ll take a closer<a contenteditable="false" data-primary="AI governance" data-startref="ai-gov-1" data-type="indexterm" id="id466"/> look at what those practices <a contenteditable="false" data-primary="AI failures (case studies)" data-startref="ai-fail-1" data-type="indexterm" id="id467"/>entail.</p>
</div></section>

<section data-pdf-bookmark="Overview of Data Governance" data-type="sect1"><div class="sect1" id="chapter_3_overview_of_data_governance_1748539918116016">
<h1>Overview of Data Governance</h1>

<p>At the heart of the EU AI Act lies a motivation to create AI systems that are not just powerful but trustworthy. Data governance is a pretty dry topic to describe, so I recommend you start by reviewing the metaphorical framework in the following sidebar to make the abstract concepts more tangible.</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="chapter_3_data_governance_managing_the_ingredients_1748539918116098">
<h1>Data Governance: Managing the Ingredients</h1>

<p>I’ll use a metaphor to explain data governance: imagine a vast kitchen in a high-end restaurant, where data represents the ingredients and AI is the collection of sophisticated cooking utensils and equipment.</p>

<p>Metaphorically speaking, data governance is like running the kitchen’s ingredient management system:</p>

<ul>
	<li>
	<p><em>Sourcing</em> involves ensuring that data comes from reliable sources, much like ensuring that ingredients come from trustworthy suppliers.</p>
	</li>
	<li>
	<p><em>Storage</em> entails organizing and storing data properly to maintain its quality and prevent any contamination, similar to how ingredients in the kitchen are stored to maintain freshness.</p>
	</li>
	<li>
	<p><em>Labeling</em> means clearly marking data with details such as contents, expiration dates, and usage guidelines, just as ingredients are labeled for easy identification.</p>
	</li>
	<li>
	<p><em>Access control and data privacy</em> <a contenteditable="false" data-primary="access control" data-type="indexterm" id="id468"/>are about determining who can access which data and for what purposes, similar to how access to ingredients is controlled in a kitchen.</p>
	</li>
	<li>
	<p><em>Quality checks</em> involve regularly inspecting data to maintain high standards, much like inspecting ingredients to ensure their quality.</p>
	</li>
</ul>

<p>The goal is to ensure that every dish (data-driven decision or product) starts with the best possible ingredients.</p>
</div></aside>

<section data-pdf-bookmark="Data Governance Defined" data-type="sect2"><div class="sect2" id="chapter_3_data_governance_defined_1748539918116155">
<h2>Data Governance Defined</h2>

<p>As we saw in <a data-type="xref" href="ch01.html#chapter_1_understanding_the_ai_regulations_1748539916832819">Chapter 1</a>, data governance is a data management function that guarantees the availability, usability, integrity, and security of the data collected and used in an organization. While the core principles of data governance remain consistent across industries, the specific focus and implementation can vary based on industry needs and regulatory requirements. For instance, data governance in healthcare encompasses “the overall administration, through clearly defined procedures and plans, that assures the availability, integrity, security, and usability of the structured and unstructured data available to an organization while ensuring compliance with regulations such as HIPAA.”<sup><a data-type="noteref" href="ch03.html#id469" id="id469-marker">1</a></sup> Here, the focus is on ensuring patient data privacy and security and maintaining compliance with healthcare regulations (e.g., HIPAA<a contenteditable="false" data-primary="Health Insurance Portability and Accountability Act (HIPAA)" data-type="indexterm" id="id470"/>).</p>

<p>On the other hand, data governance in banking involves “establishing policies, procedures, and controls for data quality, privacy, and security; implementing data management technologies and systems; and ensuring that data across the organization is consistent, accessible, and properly used.”<sup><a data-type="noteref" href="ch03.html#id471" id="id471-marker">2</a></sup> Here, the focus is on ensuring data accuracy for risk assessment and management, complying with financial regulations (e.g., Basel III, the Dodd-Frank Act), and protecting sensitive financial information.</p>
</div></section>

<section data-pdf-bookmark="The Data Engineering Lifecycle and Data Governance" data-type="sect2"><div class="sect2" id="chapter_3_the_data_engineering_lifecycle_and_data_governance_1748539918116214">
<h2>The Data Engineering Lifecycle and Data Governance</h2>

<p>One way to understand the data governance framework is to apply governance concepts across each stage of the typical data engineering lifecycle<a contenteditable="false" data-primary="data engineering lifecycle" data-type="indexterm" id="del-1"/>, as depicted in <a data-type="xref" href="#chapter_3_figure_1_1748539918097843">Figure 3-1</a>.</p>

<figure><div class="figure" id="chapter_3_figure_1_1748539918097843"><img src="assets/taie_0301.png"/>
<h6><span class="label">Figure 3-1. </span>The data governance process across the stages of the data engineering lifecycle (adapted from <a class="orm:hideurl" href="https://oreil.ly/2JPXv"><span class="plain">Fundamentals of Data Engineering</span></a> by Joe Reis and Matt Housley [O’Reilly])</h6>
</div></figure>

<p>The data engineering lifecycle comprises the following stages: data generation, storage, ingestion, transformation, and serving. Let’s take a closer look at how governance applies to each of those stages.</p>

<section data-pdf-bookmark="Data generation" data-type="sect3"><div class="sect3" id="chapter_3_data_generation_1748539918116270">
<h3>Data generation</h3>

<p>At the start of the data engineering lifecycle<a contenteditable="false" data-primary="data engineering lifecycle" data-secondary="generation" data-type="indexterm" id="id472"/>, data is created or collected from various source systems (applications, databases, Internet of Things devices, etc.). In the data generation stage, data governance processes focus on establishing data quality standards and validation rules.</p>

<p>Usually, at this point you define metadata requirements and implement data collection policies compliant with privacy regulations. Additionally, within the organization, data ownership is defined and corresponding roles are assigned. For example, an organization can implement automated data quality<a contenteditable="false" data-primary="data quality" data-type="indexterm" id="id473"/> checks at the point of data creation, ensuring that customer data adheres to predefined formats and completeness criteria.</p>
</div></section>

<section data-pdf-bookmark="Ingestion" data-type="sect3"><div class="sect3" id="chapter_3_ingestion_1748539918116322">
<h3>Ingestion</h3>

<p>In the next phase, data<a contenteditable="false" data-primary="data engineering lifecycle" data-secondary="ingestion" data-type="indexterm" id="id474"/> is moved from the source systems into centralized storage or processing systems. Data governance processes focus on data lineage<a contenteditable="false" data-primary="data lineage" data-type="indexterm" id="dl-1"/> tracking, implementing data classification, and tagging. An important part of data governance is monitoring data quality during ingestion and maintaining audit logs of data movement. Often, organizations automatically tag incoming data with source information and sensitivity levels. This enables easier tracking and management of data throughout its lifecycle.</p>
</div></section>

<section data-pdf-bookmark="Transformation" data-type="sect3"><div class="sect3" id="chapter_3_transformation_1748539918116374">
<h3>Transformation</h3>

<p>During the transformation stage of the data engineering lifecycle<a contenteditable="false" data-primary="data engineering lifecycle" data-secondary="transformation" data-type="indexterm" id="id475"/>, raw data is cleaned, normalized, aggregated, and converted into formats suitable for analysis. At this point, data governance ensures that data quality rules are enforced. You should maintain data lineage throughout all transformations and apply version control to data models.</p>

<p>Imagine a retail company processing customer purchase data. Here, data governance tasks might include data quality (error) checks, such as verifying that email formats are valid and there are no duplicate entries, and data cleaning procedures such as removing inconsistencies in product names. All extract–transform–load (ETL) processes should be documented, and changes to the customer data model should go through a formal approval process. In addition, it’s essential to ensure compliance with data privacy regulations during transformations.</p>
</div></section>

<section data-pdf-bookmark="Storage" data-type="sect3"><div class="sect3" id="chapter_3_storage_1748539918116424">
<h3>Storage</h3>

<p>Next, the transformed data <a contenteditable="false" data-primary="data engineering lifecycle" data-secondary="storage" data-type="indexterm" id="id476"/>is stored in systems such as data lakes, data warehouses, or other cloud-based storage solutions. At this stage, data governance involves defining data retention policies, implementing access controls and encryption, and ensuring proper data backups. Maintaining data lineage<a contenteditable="false" data-primary="data lineage" data-startref="dl-1" data-type="indexterm" id="id477"/> and audit trails is also essential for accountability and traceability.</p>

<p>For instance, organizations may implement role-based access controls <a contenteditable="false" data-primary="access control" data-type="indexterm" id="id478"/>and encrypt sensitive data at rest to protect personal information in compliance with the GDPR. Scheduling regular data backups and disaster recovery tests are also common practices to ensure data resilience and availability.</p>
</div></section>

<section data-pdf-bookmark="Serving" data-type="sect3"><div class="sect3" id="chapter_3_serving_1748539918116473">
<h3>Serving</h3>

<p>In the final stage of the data engineering lifecycle, serving<a contenteditable="false" data-primary="data engineering lifecycle" data-secondary="serving" data-type="indexterm" id="id479"/>, processed data and insights are made available to end users, applications, or external partners for consumption and analysis. Data governance requires that organizations control access to data based on user roles and permissions and implement data masking for sensitive information. Monitoring data usage, access patterns, and compliance with data sharing agreements is also essential. Many organizations implement self-service data portals that allow users to access datasets appropriate to their roles or use cases, with sensitive information automatically masked, redacted, or anonymized based on predefined governance rules.</p>

<p>Organizations can ensure data quality, security, and compliance by applying these governance processes across the data engineering lifecycle. This approach to data governance helps AI engineers understand the importance of maintaining data integrity and security throughout the entire data pipeline<a contenteditable="false" data-primary="data engineering lifecycle" data-startref="del-1" data-type="indexterm" id="id480"/>.</p>
</div></section>
</div></section>

<section data-pdf-bookmark="Integrating Data Governance into MLOps" data-type="sect2"><div class="sect2" id="chapter_3_integrating_data_governance_into_mlops_1748539918116543">
<h2>Integrating Data Governance into MLOps</h2>

<p>As you learned in <a data-type="xref" href="ch02.html#chapter_2_ai_engineering_a_proactive_compliance_catalyst_1748539917637495">Chapter 2</a>, the MLOps Stack Canvas<a contenteditable="false" data-primary="data governance" data-secondary="integration with MLOps" data-type="indexterm" id="data-gov-mlops-integ"/> provides a comprehensive blueprint for designing the end-to-end technical infrastructure needed to develop, deploy, and maintain machine learning applications in a robust, scalable, and governed manner. It facilitates cost estimation, planning, and decision making for operationalizing machine learning across the entire lifecycle. By extending the MLOps Stack Canvas with data governance considerations (which you will do here), you can ensure that data is managed responsibly and complies with relevant regulations throughout the ML lifecycle. This holistic approach to MLOps and data governance enables organizations to build trustworthy, compliant, and sustainable ML systems.</p>

<p>Let’s take a look at how we can incorporate data governance into each of the MLOps Stack Canvas’s components.</p>

<section data-pdf-bookmark="Value Proposition" data-type="sect3"><div class="sect3" id="chapter_3_value_proposition_1748539918116613">
<h3>Value Proposition</h3>

<p>When you formulate a general value proposition for the MLOps platform you’re building, be sure to include data governance goals and compliance requirements in the value proposition. Consider how data governance enhances the overall value of the ML project.</p>

<p>A useful way to track the success of data governance integration into the AI lifecycle is to define and track particular metrics, such as:</p>

<dl>
	<dt>Policy compliance rate</dt>
	<dd>
	<p>The percentage of data management activities that comply with established policies and standards.</p>
	</dd>
	<dt>Regulatory compliance</dt>
	<dd>
	<p>The percentage of data processes and policies that comply with relevant regulations.</p>
	</dd>
	<dt>Audit compliance rate</dt>
	<dd>
	<p>The success rate of internal and external audits in terms of compliance with data governance policies.</p>
	</dd>
	<dt>Incident response time</dt>
	<dd>
	<p>The average time taken to respond to data governance–related incidents or issues.</p>
	</dd>
	<dt>Data audit results</dt>
	<dd>
	<p>The number of audit findings related to data governance and the severity of these findings.</p>
	</dd>
	<dt>Training and certification levels</dt>
	<dd>
	<p>The number of employees who have completed data governance training and certifications.</p>
	</dd>
	<dt>Cost of poor data quality</dt>
	<dd>
	<p>The financial impact of data quality issues, including costs associated with correcting errors.</p>
	</dd>
</dl>

<p>Useful metrics to consider to track data usage, quality, and security include:</p>

<dl>
	<dt>Data accessibility</dt>
	<dd>
	<p>The ease with which authorized users can access the data they need. Collect feedback from users on the ease of accessing and using the data.</p>
	</dd>
	<dt>Data usage frequency</dt>
	<dd>
	<p>The number of times datasets are accessed or used within a specific period.</p>
	</dd>
	<dt>Data accuracy</dt>
	<dd>
	<p>The percentage of data entries that are correct.</p>
	</dd>
	<dt>Data completeness</dt>
	<dd>
	<p>The percentage of missing values or incomplete data entries.</p>
	</dd>
	<dt>Data consistency</dt>
	<dd>
	<p>The percentage of data that is uniform and consistent across different databases.</p>
	</dd>
	<dt>Data timeliness</dt>
	<dd>
	<p>The time it takes for data to be updated and available for use.</p>
	</dd>
	<dt>Data validity</dt>
	<dd>
	<p>The percentage of data entries that meet the specified format, type, or range.</p>
	</dd>
	<dt>Number of data breaches</dt>
	<dd>
	<p>The count of security incidents involving unauthorized access to data.</p>
	</dd>
	<dt>Time to detect and mitigate security threats</dt>
	<dd>
	<p>The average time to detect and address data security threats.</p>
	</dd>
</dl>
</div></section>

<section data-pdf-bookmark="Data Sources and Data Versioning" data-type="sect3"><div class="sect3" id="chapter_3_data_sources_and_data_versioning_1748539918116671">
<h3>Data Sources and Data Versioning</h3>

<p>In addition to the standard tasks for the Data Sources and Data Versioning component in the MLOps Stack Canvas, you should also implement the following governance-related tasks:</p>

<ul>
	<li>
	<p>Identify, catalog, and classify data sources based on sensitivity, privacy, and regulatory requirements. Define roles and responsibilities for data access (e.g., data owners, stewards, consumers).</p>
	</li>
	<li>
	<p>Establish data access controls and permissions based on data classification, such as personally identifiable information (PII), protected health information (PHI), and payment card industry (PCI) data.</p>
	</li>
	<li>
	<p>Establish a data taxonomy and metadata schema for consistent data organization and labeling.</p>
	</li>
	<li>
	<p>Implement data lineage<a contenteditable="false" data-primary="data lineage" data-type="indexterm" id="dl-2"/> to track data origin and transformations and ensure data provenance, including information about data sources, ownership, and quality, to enable traceability and reproducibility.</p>
	</li>
	<li>
	<p>Establish sustainable data documentation processes to document data origin, transformations, and dependencies throughout the data lifecycle.</p>
	</li>
	<li>
	<p>Ensure data versioning aligns with data retention policies and compliance needs.</p>
	</li>
</ul>

<p>To implement data lineage and provenance, you can utilize tools to capture and visualize data flows and dependencies automatically. Examples include OpenLineage, Apache Atlas, Cloudera Navigator, and Talend Data Fabric.</p>

<p>To implement data version control to track and manage changes to datasets over time, you can use a tool like DVC, Pachyderm, lakeFS, or Delta Lake.</p>

<p>For implementing data privacy and compliance solutions to ensure adherence to regulations (e.g., GDPR, HIPAA), tools such as Privitar, OneTrust, BigID, and Informatica can be helpful.</p>

<p>Data quality and validation frameworks to ensure data accuracy, completeness, and consistency include Apache Griffin, Deequ, Great Expectations, and Monte Carlo.</p>
</div></section>

<section data-pdf-bookmark="Data Analysis and Experiment Management" data-type="sect3"><div class="sect3" id="chapter_3_data_analysis_and_experiment_management_1748539918116726">
<h3>Data Analysis and Experiment Management</h3>

<p>Incorporating data governance into the Data Analysis and Experiment Management component of the MLOps Stack Canvas involves the following steps:</p>

<ul>
	<li>
	<p>Enforce data privacy and security measures during analysis and experimentation.</p>
	</li>
	<li>
	<p>Define strict access controls <a contenteditable="false" data-primary="access control" data-type="indexterm" id="id481"/>for data and experimental artifacts, and implement privacy controls (such as redaction, pseudonymization, or anonymization) for sensitive data used in experiments. Use role-based access control systems to ensure only authorized personnel can access sensitive data and critical experiment configurations.</p>
	</li>
	<li>
	<p>For reproducibility and compliance<a contenteditable="false" data-primary="reproducibility (MLOps principle)" data-type="indexterm" id="id482"/>, maintain audit trails of data usage in experiments. Use version control systems not only for code, but also for experiment configurations and datasets. All changes should be logged with user information, timestamps, and descriptions to provide a clear and complete audit trail.</p>
	</li>
	<li>
	<p>Continuously monitor experiments and data handling practices to ensure compliance with internal policies and external regulations (e.g., GDPR, HIPAA). This might involve automated checks or periodic reviews.</p>
	</li>
</ul>

<p>You can use experiment tracking and management platforms like MLflow, Weights &amp; Biases, or Neptune.ai to manage and govern metadata—including data lineage, versioning, and governance information—and artifacts. These tools (and others, such as TensorBoard) also support logging and visualizing metrics, hyperparameters, and outcomes. They help streamline the experimentation process and guarantee that all metadata is captured systematically.</p>
</div></section>

<section class="pagebreak-before" data-pdf-bookmark="Feature Store and Workflows" data-type="sect3"><div class="sect3" id="chapter_3_feature_store_and_workflows_1748539918116781">
<h3 class="less_space">Feature Store and Workflows</h3>

<p>When extending the Feature Store and Workflows component of the MLOps Stack Canvas to include data governance, several key processes and tools should be implemented to support compliance, reproducibility, and proper management of features:</p>

<ul>
	<li>
	<p>Secure and govern the feature store by cataloging features with metadata such as creation date, creator, and usage rights. Thoroughly document feature engineering workflows to ensure compliance with data privacy regulations.</p>
	</li>
	<li>
	<p>Establish policies and guidelines for feature creation, storage, and usage to comply with data protection regulations (e.g., GDPR, HIPAA).</p>
	</li>
	<li>
	<p>Implement access controls and authentication for the feature store. Define policies for granting, reviewing, and revoking access to features based on user roles and responsibilities.</p>
	</li>
	<li>
	<p>Maintain feature lineage and track data sources, transformations, and feature dependencies for auditing and reproducibility. For feature provenance, include the creation date, version, and owner.</p>
	</li>
	<li>
	<p>Establish data retention policies for features that align with regulatory requirements. For data minimization purposes, create and store only features that are necessary.</p>
	</li>
	<li>
	<p>Document all features, providing clear descriptions and justifications for each.</p>
	</li>
</ul>

<p>Some feature store platforms have built-in governance capabilities such as access control, versioning, and lineage tracking. Examples include Feast, Hopsworks, AWS SageMaker Feature Store, and Google Cloud Vertex AI Feature Store. You can implement data lineage and provenance to capture and visualize feature dependencies and transformations using tools like OpenLineage, Apache Atlas, Cloudera Navigator, or Talend Data Fabric.</p>
</div></section>

<section data-pdf-bookmark="Foundations (Reflecting DevOps)" data-type="sect3"><div class="sect3" id="chapter_3_foundations_reflecting_devops_1748539918116835">
<h3>Foundations (Reflecting DevOps)</h3>

<p>Organizations can embed data governance throughout the development and deployment lifecycle by integrating appropriate processes and tools into the DevOps Foundations component of the MLOps Stack Canvas. Consider the following best practices:</p>

<ul>
	<li>
	<p>Integrate data governance policies and processes into DevOps practices by adding data governance checks and automated compliance checks for data handling to CI/CD pipelines.</p>
	</li>
	<li>
	<p>Implement data security measures, such as data masking, encryption, tokenization, and other minimization controls, to enforce data security and privacy in CI/CD pipelines.</p>
	</li>
	<li>
	<p>Protect sensitive data throughout the build, test, and deployment processes.</p>
	</li>
	<li>
	<p>Establish secure data handling practices and access controls within the CI/CD workflow.</p>
	</li>
	<li>
	<p>Automate data quality<a contenteditable="false" data-primary="data quality" data-type="indexterm" id="id483"/> checks and validations as part of your DevOps workflows, incorporating data quality gates in CI/CD pipelines to maintain integrity and consistency.</p>
	</li>
	<li>
	<p>Set up automated data profiling and anomaly detection mechanisms to identify data quality issues. Include data profiling reports as artifacts in CI/CD pipelines for easy access and review.</p>
	</li>
</ul>
</div></section>

<section data-pdf-bookmark="CI/CT/CD: ML Pipeline Orchestration" data-type="sect3"><div class="sect3" id="chapter_3_ci_ct_cd_ml_pipeline_orchestration_1748539918116896">
<h3>CI/CT/CD: ML Pipeline Orchestration</h3>

<p>Here are some steps you can take to maintain data integrity, compliance, and reliability throughout the ML pipeline when incorporating data governance into the CI/CT/CD component of the MLOps Stack Canvas:</p>

<ul>
	<li>
	<p>Integrate data validation and quality checks into ML pipelines.</p>
	</li>
	<li>
	<p>Automate data bias and fairness assessments during model training.</p>
	</li>
	<li>
	<p>Implement data drift<a contenteditable="false" data-primary="data drift" data-type="indexterm" id="id484"/> detection and alerting within the CI/CD workflow. Establish baseline data distributions and monitor for significant deviations over time, triggering automated alerts and notifications when data drift exceeds predefined thresholds.</p>
	</li>
	<li>
	<p>Define metrics and thresholds to evaluate the fairness and representativeness of the training data (e.g., demographic parity, equal opportunity, disparate impact).</p>
	</li>
	<li>
	<p>Automate bias detection and mitigation techniques to ensure models are trained on unbiased data.</p>
	</li>
</ul>

<p>To evaluate and mitigate bias in training data, you can use tools such as IBM AI Fairness 360<a contenteditable="false" data-primary="fairness metrics" data-secondary="tools for" data-type="indexterm" id="id485"/> or Google’s What-If Tool. Tools to implement data drift detection and monitoring platforms to identify and alert on data drift in the ML pipeline include Evidently AI, Arthur AI, and Fiddler AI. You can also utilize MLOps platforms that have built-in data governance features, such as MLflow on Databricks, Kubeflow, AWS SageMaker, or the Google Cloud AI Platform.</p>
</div></section>

<section data-pdf-bookmark="Model Registry and Model Versioning" data-type="sect3"><div class="sect3" id="chapter_3_model_registry_and_model_versioning_1748539918116956">
<h3>Model Registry and Model Versioning</h3>

<p>Extending the Model Registry and Model Versioning component of the MLOps Stack Canvas to include data governance requires the implementation of proper management, versioning, and governance practices for ML models (we’ll look at AI model governance later in this chapter). Here are some best practices:</p>

<ul>
	<li>
	<p>Maintain a centralized model registry with governance metadata (e.g., data used, compliance checks).</p>
	</li>
	<li>
	<p>Implement access controls and permissions for the model registry.</p>
	</li>
	<li>
	<p>Ensure the model registry includes data lineage and provenance information. Implement a process for tracking model lineage, including data sources, hyperparameters, training artifacts, and who trained the ML models.</p>
	</li>
	<li>
	<p>Establish a model versioning strategy aligned with the data versioning and governance policies.</p>
	</li>
	<li>
	<p>Maintain a comprehensive version history of models in the registry, along with the associated governance metadata.</p>
	</li>
</ul>

<p>Integrating data governance and model management practices fosters transparency, accountability, and trust in the ML models deployed in production environments. To capture and visualize the relationships between models, data, and other artifacts, you can use data lineage<a contenteditable="false" data-primary="data lineage" data-startref="dl-2" data-type="indexterm" id="id486"/> and provenance tools such as OpenLineage, Datakin, Pachyderm, and Marquez. To track and monitor model governance activities and maintain audit trails, use tools like Apache Ranger, Privacera, Immuta, or Informatica.</p>
</div></section>

<section data-pdf-bookmark="Model Deployment" data-type="sect3"><div class="sect3" id="chapter_3_model_deployment_1748539918117009">
<h3>Model Deployment</h3>

<p>Incorporating data governance into model deployment involves deploying models in a controlled environment where performance can be monitored against criteria such as fairness and privacy impact. Consider the following activities to integrate data governance into your model deployment practices:</p>

<ul>
	<li>
	<p>Implement staged deployment practices like canary releases to evaluate compliance in production settings.</p>
	</li>
	<li>
	<p>Use data privacy and anonymization platforms to protect sensitive data during model inference and deployment.</p>
	</li>
	<li>
	<p>Track and audit data usage throughout the deployment process.</p>
	</li>
	<li>
	<p>Automate data compliance checks as part of the deployment workflow.</p>
	</li>
</ul>

<p>Model governance and orchestration frameworks such as Kubeflow, MLflow, Apache Airflow, and Seldon Core can be used to manage and automate the deployment process in compliance with data governance policies.</p>
</div></section>

<section data-pdf-bookmark="Prediction Serving" data-type="sect3"><div class="sect3" id="chapter_3_prediction_serving_1748539918117062">
<h3>Prediction Serving</h3>

<p>Integrating data governance into the Prediction Serving component involves controlling how models are served while ensuring compliance with data protection regulations. To achieve this, you should:</p>

<ul>
	<li>
	<p>Validate that production data meets governance standards (input data <span class="keep-together">validation</span>).</p>
	</li>
	<li>
	<p>Implement measures to protect sensitive predictions (output data protection).</p>
	</li>
	<li>
	<p>Encrypt prediction inputs and outputs both in transit and at rest.</p>
	</li>
	<li>
	<p>Enforce data access controls and authentication for prediction requests.</p>
	</li>
	<li>
	<p>Monitor and audit data usage during prediction serving for compliance.</p>
	</li>
	<li>
	<p>Establish data retention policies for input data and predictions.</p>
	</li>
	<li>
	<p>Establish a process for protecting sensitive data during prediction serving.</p>
	</li>
	<li>
	<p>Use data masking, anonymization, tokenization, and data minimization techniques to safeguard PII or other sensitive data.</p>
	</li>
	<li>
	<p>Audit and log prediction requests and responses.</p>
	</li>
	<li>
	<p>Capture metadata such as timestamp, input data, and prediction results for each prediction request.</p>
	</li>
	<li>
	<p>Store audit logs securely and make them accessible for compliance and monitoring purposes.</p>
	</li>
	<li>
	<p>Continuously monitor prediction quality and fairness.</p>
	</li>
	<li>
	<p>Implement mechanisms to detect and alert on any deviations in prediction quality, performance, or fairness metrics and regularly assess the prediction serving system for potential biases or discriminatory outcomes.</p>
	</li>
</ul>

<p>Data privacy and protection tools such as HashiCorp Vault, AWS Key Management Service (KMS), Azure Key Vault, and Google Cloud Data Loss Prevention (DLP) can be used to safeguard sensitive data during prediction serving. To capture and store prediction request and response metadata, you can use auditing and logging frameworks such as Elastic Stack, Splunk, Fluentd, AWS CloudTrail, or Google Cloud Audit Logs. For tracking prediction quality, performance, and fairness metrics, consider tools such as Prometheus, Grafana, Datadog, New Relic, AWS CloudWatch, or Google Cloud Monitoring.</p>
</div></section>

<section data-pdf-bookmark="Model, Data, and Application Monitoring" data-type="sect3"><div class="sect3" id="chapter_3_model_data_and_application_monitoring_1748539918117117">
<h3>Model, Data, and Application Monitoring</h3>

<p>To incorporate data governance into the ML model, data, and system monitoring part of the MLOps Stack Canvas, extend your monitoring capabilities to include governance metrics such as data quality, model drift, and compliance with data usage policies. The following tasks are recommended:</p>

<ul>
	<li>
	<p>Monitor data quality, bias, and drift in production ML systems.</p>
	</li>
	<li>
	<p>Set up alerts and notifications for data governance violations and anomalies.</p>
	</li>
	<li>
	<p>Continuously audit data usage and access to ensure compliance with relevant regulations. Establish processes for investigating and remediating governance issues.</p>
	</li>
	<li>
	<p>Track operational metrics (e.g., latency, throughput, resource utilization) alongside governance-specific metrics defined in the value proposition.</p>
	</li>
	<li>
	<p>Establish governance policies and thresholds for acceptable operational <span class="keep-together">performance</span>.</p>
	</li>
	<li>
	<p>Implement alerts and escalation procedures for operational issues that affect model availability, reliability, or compliance.</p>
	</li>
</ul>

<p>This monitoring component should aggregate and unify all relevant metrics, thresholds, and alerts from the other parts of the MLOps Stack Canvas to provide a comprehensive view of system health and governance compliance.</p>

<p>Operational monitoring and alerting tools such as Prometheus, Grafana, Datadog, New Relic, and Elastic Stack can be used to track system performance, resource utilization, and availability. Platforms like PagerDuty, OpsGenie, ​​Splunk On-Call, and xMatters help organizations respond to ML system issues and compliance breaches quickly. These tools reduce incident response times and improve overall system <span class="keep-together">reliability</span>.</p>
</div></section>

<section data-pdf-bookmark="Metadata Management" data-type="sect3"><div class="sect3" id="chapter_3_metadata_management_1748539918117170">
<h3>Metadata Management</h3>

<p>Metadata management for AI system compliance engineering is such a large and important topic that it deserves a separate book. The Metadata Management section of the MLOps Stack Canvas spans the entire AI system lifecycle, capturing information about datasets, models, experiments, deployments, and more to support ML governance, reproducibility, and comparability.</p>

<p>Integrating data governance into metadata management requires developing a unified strategy that provides greater visibility into data lineage<a contenteditable="false" data-primary="data lineage" data-type="indexterm" id="id487"/>, model history, and EU AI Act compliance. You will need to:</p>

<ul>
	<li>
	<p>Establish a metadata schema and taxonomy to standardize data labeling and organization. Include fields such as model purpose, data sources, performance metrics, compliance checks, and approval status.</p>
	</li>
	<li>
	<p>Capture and store governance-related metadata (e.g., data and model lineage and provenance, compliance checks, and access logs).</p>
	</li>
	<li>
	<p>Consistently capture and maintain governance and ML metadata to create a comprehensive audit trail for every model version. Use that metadata to support compliance reporting and lifecycle tracking.</p>
	</li>
	<li>
	<p>Document and catalog metadata associated with datasets, features, models, and experiments. Experiment metadata should include data lineage, versioning, and governance information.</p>
	</li>
	<li>
	<p>Enable metadata integration and interoperability across tools and lifecycle stages. Develop processes to harmonize metadata across ML development, deployment, and monitoring systems, facilitating traceability and regulatory alignment.</p>
	</li>
</ul>

<p>There are various tools and platforms available to support metadata management across the ML lifecycle. These include:</p>

<ul>
	<li>
	<p>Metadata management platforms that capture, store, and govern metadata across ML systems, such as Alation, Collibra, Informatica Enterprise Data Catalog, and Apache Atlas</p>
	</li>
	<li>
	<p>Data lineage and provenance tools to track and visualize the flow and dependencies of data and metadata, such as OpenLineage, Datakin, Nexla, and Octopai</p>
	</li>
	<li>
	<p>Centralized metadata catalogs or repositories that enable discovery, search, and access to ML system metadata, such as Amundsen, DataHub, Metacat, and Datum</p>
	</li>
	<li>
	<p>Compliance and audit tools to enforce governance policies and assess the adherence of metadata to standards, such as Collibra Governance, Informatica Axon, and Apache Ranger</p>
	</li>
	<li>
	<p>APIs and integration frameworks to support interoperability and data exchange between ML tools and platforms, such as OpenMetadata, Egeria, and Apache Kafka</p>
	</li>
</ul>

<p>By deeply embedding data governance into each component of the MLOps Stack Canvas, you guarantee that data governance is not an afterthought but a fundamental aspect of the machine learning lifecycle. This approach not only helps you meet regulatory requirements but also builds trust with stakeholders by promoting the ethical use of data and models.</p>

<p>Data governance is tightly linked to AI governance, and understanding this relationship is especially important in the context of the EU AI Act. AI systems are only as good and as safe as the data they are trained on. Weak data governance will cause AI governance to fall short. We’ll turn our attention to this critical topic next<a contenteditable="false" data-primary="data governance" data-secondary="integration with MLOps" data-startref="data-gov-mlops-integ" data-type="indexterm" id="id488"/>.</p>
</div></section>
</div></section>
</div></section>

<section data-pdf-bookmark="Overview of AI Governance" data-type="sect1"><div class="sect1" id="chapter_3_overview_of_ai_governance_1748539918117232">
<h1>Overview of AI Governance</h1>

<p>The introduction of the EU AI Act<a contenteditable="false" data-primary="AI governance" data-type="indexterm" id="ai-gov-2"/> has caused enterprises to increasingly prioritize AI governance. To explain what this entails, let’s return to the earlier metaphor of a high-end restaurant kitchen, where data represents the ingredients and AI is the collection of sophisticated cooking utensils and equipment.</p>

<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="chapter_3_ai_governance_managing_the_kitchen_equipment_1748539918117308">
<h1>AI Governance: Managing the Kitchen Equipment</h1>

<p>AI governance is similar to managing the kitchen’s specialized cooking equipment:</p>

<ul>
	<li>
	<p><em>Safety protocols</em> establish guidelines for using powerful tools like the AI-powered sous chef robot or smart ovens.</p>
	</li>
	<li>
	<p><em>Training</em> ensures that all staff know how to properly use and maintain the AI equipment.</p>
	</li>
	<li>
	<p><em>Maintenance</em> mandates regular check-ups and updates to keep the AI tools functioning correctly and safely.</p>
	</li>
	<li>
	<p><em>Output monitoring</em> is like taste-testing dishes prepared by AI to guarantee quality and consistency.</p>
	</li>
	<li>
	<p><em>Ethical considerations</em> ensure that AI tools are used fairly.</p>
	</li>
</ul>

<p>The aim is to use advanced AI instruments to enhance the kitchen’s capabilities while maintaining control, safety, and the human touch in cooking.</p>

<p>Together, data governance and AI governance help create a well-run kitchen that consistently produces excellent meals (outcomes) in an ethical and efficient manner. They help balance innovation with responsibility, ensuring that the restaurant (organization) maintains its reputation and meets all health and safety standards.</p>
</div></aside>

<section data-pdf-bookmark="AI Governance Defined" data-type="sect2"><div class="sect2" id="chapter_3_ai_governance_defined_1748539918117362">
<h2>AI Governance Defined</h2>

<p>The objective of AI governance<a contenteditable="false" data-primary="AI governance" data-secondary="definition of" data-type="indexterm" id="id489"/> is to establish and maintain a framework that ensures AI systems are developed, deployed, and used responsibly, ethically, and in alignment with organizational goals and values. AI governance covers various aspects, including AI algorithms, decision making based on AI predictions, security, and data privacy. It operates as an ecosystem within the enterprise, involving people, processes, and <span class="keep-together">policies</span>.</p>

<p>AI governance is a key responsibility of the company’s leadership and oversight bodies such as AI ethics boards. These individuals are accountable for defining policies and guidelines, implementing AI risk management processes, and establishing monitoring and auditing mechanisms. Other stakeholders <a contenteditable="false" data-primary="AI governance" data-secondary="stakeholders in" data-type="indexterm" id="id490"/>include AI and data science teams, legal and compliance teams, business unit leaders, risk management teams, external advisors and auditors, and customers and end users.</p>

<p>A strong AI governance framework includes AI training and awareness programs to provide guardrails and guidance for AI development and use across the organization. AI governance policies may cover ethical AI principles, AI risk assessment and mitigation, data governance and privacy protection, model development and deployment standards, transparency and explainability requirements, AI model monitoring and evaluation processes, and ML-centric incident response procedures. As this suggests, robust data governance provides the foundation for effective AI governance.</p>
</div></section>

<section data-pdf-bookmark="The AI System Lifecycle and AI Governance" data-type="sect2"><div class="sect2" id="chapter_3_the_ai_system_lifecycle_and_ai_governance_1748539918117421">
<h2>The AI System Lifecycle and AI Governance</h2>

<p>Ensuring AI systems are developed and used responsibly, ethically, and in alignment with organization goals and values requires a holistic approach involving people, processes, and technologies. Organizations can integrate AI governance checkpoints throughout the entire AI system development lifecycle to create ethical, transparent, fair, and accountable AI systems. The key is to make AI governance an integral part of the development process rather than an afterthought. <a data-type="xref" href="#chapter_3_table_1_1748539918103855">Table 3-1</a> shows how the AI governance principles<a contenteditable="false" data-primary="AI governance principles" data-type="indexterm" id="ai-gov-prin-1"/> outlined <a contenteditable="false" data-primary="AI governance principles" data-secondary="business and data understanding" data-type="indexterm" id="id491"/><a contenteditable="false" data-primary="AI governance principles" data-secondary="data preparation" data-type="indexterm" id="id492"/><a contenteditable="false" data-primary="AI governance principles" data-secondary="modeling" data-type="indexterm" id="id493"/><a contenteditable="false" data-primary="AI governance principles" data-secondary="evaluation" data-type="indexterm" id="id494"/><a contenteditable="false" data-primary="AI governance principles" data-secondary="deployment" data-type="indexterm" id="id495"/><a contenteditable="false" data-primary="AI governance principles" data-secondary="monitoring and maintenance" data-type="indexterm" id="id496"/>earlier map to the corresponding phases of the CRISP-ML(Q)<a contenteditable="false" data-primary="CRISP-ML(Q)" data-type="indexterm" id="crisp-ml-2"/> framework discussed in <a data-type="xref" href="ch02.html#chapter_2_ai_engineering_a_proactive_compliance_catalyst_1748539917637495">Chapter 2</a>.</p>

<table id="chapter_3_table_1_1748539918103855">
	<caption><span class="label">Table 3-1. </span>Integrating AI governance into each phase of CRISP-ML(Q)</caption>
	<thead>
		<tr>
			<th>CRISP-ML(Q) phase</th>
			<th>AI governance principles</th>
			<th>Relevance to the EU AI Act</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td rowspan="5">
			<p>Business and data understanding</p>
			</td>
			<td>
			<p>Human-centered design: Ensure the AI project aligns with human needs and values. Involve stakeholders from various departments to validate the AI project’s goals.</p>
			</td>
			<td>
			<p>The EU AI Act promotes human-centric and trustworthy AI (Article 1). Ensuring alignment with human needs during this phase contributes to achieving this objective.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Ethical and responsible AI practices: Conduct an ethical impact assessment to identify potential risks and harms.</p>
			</td>
			<td>
			<p>The Act prohibits certain harmful AI practices (Article 5) and outlines specific requirements for high-risk AI systems (Article 6). Conducting an ethical impact assessment aligns with its risk-based approach.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Privacy and data security: Implement data governance practices during data collection and verification.</p>
			</td>
			<td>
			<p>Article 10 mandates data quality and governance for high-risk AI systems. Establishing robust data governance practices in this phase is crucial for compliance.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Fairness and inclusiveness: When defining success criteria, include metrics for fairness and inclusiveness. Examine the data for potential biases that could lead to unfair outcomes.</p>
			</td>
			<td>
			<p>Article 10 also requires addressing potential biases in data for high-risk systems. Incorporating fairness metrics in this phase helps ensure compliance and mitigate potential discrimination.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Accountability: Define clear roles and responsibilities for the AI project.</p>
			</td>
			<td>
			<p>The EU AI Act demands accountability by requiring providers to demonstrate compliance with its requirements. Defining clear roles in this phase supports establishing accountability throughout the AI system lifecycle.</p>
			</td>
		</tr>
		<tr>
			<td rowspan="4">
			<p>Data preparation</p>
			</td>
			<td>
			<p>Privacy and data security: Implement robust data protection measures during data cleaning and transformation. Where necessary, apply data anonymization or pseudonymization techniques. Ensure that data handling complies with relevant privacy regulations.</p>
			</td>
			<td>
			<p>Article 10 requires data governance for high-risk AI, while Article 27 concerns GDPR compliance. Article 59 provides provisions for further processing of personal data under specific conditions, which may be relevant in this phase.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Fairness and inclusiveness: Address class imbalances and potential biases in the data.</p>
			</td>
			<td>
			<p>Article 10 mandates addressing potential biases in data for high-risk AI systems. This phase offers a critical opportunity to mitigate bias and ensure fairness.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Reproducibility: Document all data preparation steps and use version control for datasets.</p>
			</td>
			<td>
			<p>Article 11 mandates the provision of technical documentation to support reproducibility and enable the traceability of data preparation steps.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Transparency and explainability: Keep detailed records of any data transformations or feature engineering steps.</p>
			</td>
			<td>
			<p>Article 13 emphasizes transparency and explainability for high-risk AI systems. Maintaining detailed records in this phase supports fulfilling these requirements.</p>
			</td>
		</tr>
		<tr>
			<td rowspan="5">
			<p>Modeling</p>
			</td>
			<td>
			<p>Safety, security, and dependability<a contenteditable="false" data-primary="safety, security, and dependability" data-type="indexterm" id="id497"/>: Choose modeling techniques appropriate for the application’s level of risk and implement safeguards against potential vulnerabilities.</p>
			</td>
			<td>
			<p>The Act requires a risk management system (Article 9) and specific provisions for the accuracy, robustness, and cybersecurity of high-risk AI systems (Article 15). Implementing safeguards in this phase is crucial for achieving compliance.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Fairness and inclusiveness: Monitor and mitigate any biases that emerge during the modeling process. Use fairness-aware machine learning techniques if necessary.</p>
			</td>
			<td>
			<p>Articles 10 and 50 highlight the importance of addressing bias and promoting fairness. Monitoring and mitigating bias during model engineering is essential for compliance.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Transparency and explainability: Implement model documentation practices (e.g., model cards and dataset sheets).</p>
			</td>
			<td>
			<p>Article 13 mandates transparency and explainability for high-risk AI systems. Implementing documentation practices in this phase contributes to fulfilling these requirements.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Reproducibility: Ensure that the modeling process is fully documented and reproducible. This includes recording random seeds, hyperparameters, and model architectures.</p>
			</td>
			<td>
			<p>Article 11 sets requirements for technical documentation, supporting reproducibility and allowing for auditing and verification of the modeling process.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Robustness: Develop models that are robust to variations in input data and potential adversarial attacks.</p>
			</td>
			<td>
			<p>Robustness is a key requirement for high-risk AI systems under Article 15. Developing robust models in this phase is essential for compliance.</p>
			</td>
		</tr>
		<tr>
			<td rowspan="5">
			<p>Evaluation</p>
			</td>
			<td>
			<p>Human-centered design and oversight: Involve domain experts in interpreting model results and assessing potential impacts.</p>
			</td>
			<td>
			<p>Human oversight is a crucial aspect of the EU AI Act, particularly for high-risk systems (Articles 14 and 26). Involving domain experts in this phase aligns with this principle.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Fairness and inclusiveness: Conduct thorough testing for fairness across different subgroups.</p>
			</td>
			<td>
			<p>Focusing on fairness and inclusiveness is essential for identifying, assessing, and mitigating risks associated with AI systems. This is relevant to Articles 10 and 50, highlighting the importance of addressing bias and promoting fairness.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Transparency and explainability: Use model interpretation techniques to understand and communicate how the model arrives at its decisions.</p>
			</td>
			<td>
			<p>Transparency and explainability are central to the Act, with Article 13 focusing on high-risk systems and Article 86 providing a right to explanation for individuals affected by AI decisions. Using interpretation techniques in this phase supports compliance.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Robustness: Perform extensive testing of the model’s performance under various conditions, including edge cases and potential adversarial scenarios.</p>
			</td>
			<td>
			<p>Robustness is a key requirement for high-risk AI systems under Article 15. Comprehensive testing in this phase helps ensure the model’s resilience and compliance.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Accountability and redress: Establish clear criteria for model performance and define processes for handling cases where the model fails to meet these criteria.</p>
			</td>
			<td>
			<p>Article 20 addresses corrective actions. Establishing criteria and processes for redress in this phase contributes to meeting these obligations.</p>
			</td>
		</tr>
		<tr>
			<td rowspan="4">
			<p>Deployment</p>
			</td>
			<td>
			<p>Human oversight: Establish human-in-the-loop processes for high-stakes decisions. Design the deployment process to allow for human oversight and intervention when necessary.</p>
			</td>
			<td>
			<p>Articles 14 and 26 mandate human oversight, particularly for high-risk systems. Implementing human-in-the-loop processes during deployment is essential for compliance.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Safety, security, and dependability<a contenteditable="false" data-primary="safety, security, and dependability" data-type="indexterm" id="id498"/>: Implement safeguards to protect the deployed model from tampering or unauthorized access.</p>
			</td>
			<td>
			<p>Article 15 addresses security and robustness. Implementing safeguards during deployment ensures ongoing compliance.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Transparency and explainability: Provide clear documentation on how the model should be used, including its limitations and potential biases.</p>
			</td>
			<td>
			<p>Transparency is crucial under the EU AI Act. Providing clear documentation during deployment contributes to meeting this requirement.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Accountability and redress: Log model inputs/outputs for auditing purposes. Establish clear lines of responsibility for the model’s outputs and decisions. Set up mechanisms for users to challenge or appeal decisions made by the AI system.</p>
			</td>
			<td>
			<p>The Act requires recordkeeping (Article 12), places obligations on providers (Article 16), outlines corrective actions (Article 20), and grants a right to appeal AI decisions (Article 85).</p>
			</td>
		</tr>
		<tr>
			<td rowspan="4">
			<p>Monitoring and maintenance</p>
			</td>
			<td>
			<p>Human oversight: Regularly review model performance and decisions with human experts.</p>
			</td>
			<td>
			<p>Human oversight is a continuous requirement for high-risk systems. Regular reviews with experts contribute to fulfilling this obligation.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Safety and dependability: Monitor for data/concept drift and model performance degradation. Continuously evaluate the model’s performance and security, updating as necessary to address any emerging vulnerabilities.</p>
			</td>
			<td>
			<p>The EU AI Act mandates risk management (Article 9) and robustness and security (Article 15). Continuous monitoring and updates align with these requirements.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Fairness and inclusiveness: Track fairness metrics in production. Regularly check for any emerging biases or unfair outcomes as the model operates on new data.</p>
			</td>
			<td>
			<p>Articles 10 and 50 emphasize addressing bias. Monitoring fairness metrics in this phase helps ensure ongoing compliance.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Accountability and redress: Establish processes for addressing and correcting model errors or biases. Implement a feedback loop to incorporate lessons learned from the model’s real-world performance into future iterations.</p>
			</td>
			<td>
			<p>Continuously improving the model within ethical boundaries may be guided by codes of practice (Article 56).</p>
			</td>
		</tr>
	</tbody>
</table>

<p>The integration<a contenteditable="false" data-primary="CRISP-ML(Q)" data-startref="crisp-ml-2" data-type="indexterm" id="id499"/> of AI governance and MLOps<a contenteditable="false" data-primary="AI governance principles" data-startref="ai-gov-prin-1" data-type="indexterm" id="id500"/> is discussed in <a data-type="xref" href="app03.html#appendix_c_the_integration_of_ai_governance_and_mlops_1748539915562039">Appendix C</a>.</p>

<p>To further demonstrate why data and AI governance are interleaved and should be considered holistically, let’s consider an example. Suppose an EU-based company develops an AI model for job candidate screening (a high-risk AI use case under the EU AI Act). Without data governance, it may unknowingly train the model on biased data (e.g., historical hiring patterns favoring one gender), leading to discriminatory decisions. Without AI governance, it may deploy the model without proper transparency, testing, or monitoring. This would result in noncompliance with the EU AI Act, risking fines, reputational damage, and harm to individuals.</p>

<p>However, if both data and AI governance are integrated:</p>

<ul>
	<li>
	<p>The dataset will be assessed for fairness, diversity, and quality.</p>
	</li>
	<li>
	<p>The model will be explainable, monitored, and thoroughly documented.</p>
	</li>
	<li>
	<p>The organization will be able to demonstrate compliance and maintain trust.</p>
	</li>
</ul>
</div></section>
</div></section>

<section data-pdf-bookmark="Emerging Trends in Data and AI Governance" data-type="sect1"><div class="sect1" id="chapter_3_emerging_trends_in_data_and_ai_governance_1748539918117481">
<h1>Emerging Trends in Data and AI Governance</h1>

<p>The evolving landscape of data and AI governance<a contenteditable="false" data-primary="AI governance" data-secondary="trends" data-type="indexterm" id="ai-gov-trends"/> highlights<a contenteditable="false" data-primary="data governance" data-secondary="trends" data-type="indexterm" id="data-gov-trends"/> the need for more advanced, automated, and ethical approaches to managing and using data and AI technologies. Organizations that adapt to these trends will likely gain a competitive advantage in leveraging their data assets while ensuring compliance and security. Let’s look at the five most notable trends in data and AI governance:</p>

<dl>
	<dt>Focus on ethics, trust, and enhanced data privacy</dt>
	<dd>
	<p>There’s a <a contenteditable="false" data-primary="AI governance" data-secondary="ethics, trust, and enhanced data privacy" data-type="indexterm" id="id501"/>growing emphasis on building trust in AI systems through ethical practices. This includes addressing concerns about fairness, bias, privacy, and the potential misuse of AI technologies. In the age of generative AI, organizations are increasingly developing and implementing ethical frameworks for AI governance to address issues such as large language model hallucinations and to implement corresponding safety guardrails. These frameworks address issues of bias, fairness, and transparency in AI systems and ensure adherence to the organization’s own ethical values and industry-specific standards.</p>

	<p>In addition, amid growing privacy concerns—especially around AI—companies are placing more focus on data privacy measures. This includes strengthening data protection policies and increasing transparency about data usage.</p>
	</dd>
	<dt>Adoption of AI in data management and proactive compliance automation</dt>
	<dd>
	<p>AI and ML <a contenteditable="false" data-primary="AI governance" data-secondary="adoption of AI in data management and proactive compliance automation" data-type="indexterm" id="id502"/>technologies are being integrated into data governance processes to automate data governance tasks, enhance data quality, and provide predictive analytics. This trend enables more efficient data processing and improved scalability in data management. Furthermore, AI is increasingly used to automate and improve compliance processes, including risk forecasting, regulatory change management, and real-time monitoring.</p>
	</dd>
	<dt>Focus on data lineage and provenance in AI</dt>
	<dd>
	<p>With the rise of generative AI<a contenteditable="false" data-primary="AI governance" data-secondary="data lineage and provenance" data-type="indexterm" id="id503"/>, there’s an increased emphasis on tracing data lineage <a contenteditable="false" data-primary="data lineage" data-type="indexterm" id="id504"/>throughout AI models. This trend is crucial for error detection, analysis, and ensuring regulatory compliance in AI applications. I expect proactive data and AI governance frameworks to emerge based on data lineage and active metadata.</p>
	</dd>
	<dt>Shift left data and AI governance</dt>
	<dd>
	<p>Companies are prioritizing a “shift left”<a contenteditable="false" data-primary="AI governance" data-secondary="shift left data" data-type="indexterm" id="id505"/> approach, implementing data governance and security measures early in the data collection and processing stages. This proactive approach simplifies data security, improves data quality, and addresses issues early on.</p>
	</dd>
	<dt>Decentralized data governance</dt>
	<dd>
	<p>There’s currently a shift toward<a contenteditable="false" data-primary="data governance" data-secondary="decentralized" data-type="indexterm" id="id506"/> more decentralized governance structures. This allows for greater autonomy and agility within domain teams while maintaining overall organizational standards. With the growing emphasis on “data as a product” <a contenteditable="false" data-primary="data as a product" data-type="indexterm" id="id507"/>thinking and data contracts, many companies are adopting this approach to <a contenteditable="false" data-primary="data governance" data-secondary="trends" data-startref="data-gov-trends" data-type="indexterm" id="id508"/>data <a contenteditable="false" data-primary="AI governance" data-secondary="trends" data-startref="ai-gov-trends" data-type="indexterm" id="id509"/>governance<a contenteditable="false" data-primary="AI governance" data-startref="ai-gov-2" data-type="indexterm" id="id510"/>.</p>
	</dd>
</dl>
</div></section>

<section class="pagebreak-before" data-pdf-bookmark="Conclusion" data-type="sect1"><div class="sect1" id="chapter_3_conclusion_1748539918117531">
<h1 class="less_space">Conclusion</h1>

<p>This chapter discussed the data and AI governance processes required for compliance with the EU AI Act. The Act emphasizes the importance of robust data and AI governance frameworks. Data governance ensures high-quality, representative data for training AI models, which is crucial for both regulatory compliance and the development of trustworthy AI systems. AI governance frameworks provide the oversight and controls needed to align AI development with business strategy, regulatory requirements, and ethical principles. Both data and AI governance are essential for managing the risks associated with AI use, which is central to business strategy, compliance, and trustworthiness. Transparency and accountability, core principles of governance, are not only required by the EU AI Act but are fundamental to trustworthy AI.</p>

<p>In the next chapter, I will outline the classification framework for AI system risk. For high-risk and limited-risk AI systems, planning AI engineering processes to ensure compliance with the EU AI Act is critical. When integrating ethical and compliance aspects into the AI system development process, it’s also vital to structure team topologies to include dedicated ethics, compliance, and governance roles.</p>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="id469"><sup><a href="ch03.html#id469-marker">1</a></sup> OvalEdge Team, “The Importance of Data Governance in Healthcare,” OvalEdge, March 22, 2023, <a href="https://oreil.ly/dXnvR"><em>https://oreil.ly/dXnvR</em></a>.</p><p data-type="footnote" id="id471"><sup><a href="ch03.html#id471-marker">2</a></sup> Yuriy Voloshynskyy, “Data Governance in Banking and Finance: A Complete Guide,” N-iX, March 27, 2024, <a href="https://oreil.ly/dHAXj"><em>https://oreil.ly/dHAXj</em></a>.</p></div></div></section></body></html>