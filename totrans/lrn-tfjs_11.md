# 第十章：图像训练

> “一切都应该尽可能简单。但不要过于简单。”
> 
> —阿尔伯特·爱因斯坦

我将向您描述一个数字。我希望您根据其特征的描述来猜出这个数字。我想的数字顶部是圆的，右侧只有一条线，底部有一个重叠的环状物。花点时间，心理上映射我刚刚描述的数字。有了这三个特征，你可能可以猜出来。

视觉数字的特征可能会有所不同，但聪明的描述意味着您可以在脑海中识别数字。当我说“圆顶”时，您可能会立即排除一些数字，同样的情况也适用于“只有右侧有一条线”。这些特征组成了数字的独特之处。

如果您按照图 10-1 中显示的数字描述，并将其描述放入 CSV 文件中，您可能可以通过训练好的神经网络在这些数据上获得 100%的准确性。整个过程都很顺利，只是依赖于人类描述每个数字的顶部、中部和底部。如何自动化这个人类方面呢？如果您可以让计算机识别图像的独特特征，如环、颜色和曲线，然后将其输入神经网络，机器就可以学习将描述分类为图像所需的模式。

![数字二的三部分。](img/ltjs_1001.png)

###### 图 10-1。如果您发现这是数字二，恭喜您。

幸运的是，通过出色的计算机视觉技巧，解决了图像特征工程的问题。

我们将：

+   学习模型的卷积层的概念

+   构建您的第一个多类模型

+   学习如何读取和处理图像以供 TensorFlow.js 使用

+   在画布上绘制并相应地对绘图进行分类

完成本章后，您将能够创建自己的图像分类模型。

# 理解卷积

卷积来自于数学世界中表达形状和函数的概念。您可以深入研究卷积在数学中的概念，然后从头开始将这些知识重新应用到数字图像信息的收集概念。如果您是数学和计算机图形的爱好者，这是一个非常令人兴奋的领域。

然而，当你有像 TensorFlow.js 这样的框架时，花费一周学习卷积操作的基础并不是必要的。因此，我们将专注于卷积操作的高级优势和特性，以及它们在神经网络中的应用。始终鼓励您在这个快速入门之外深入研究卷积的深层历史。

让我们看看您应该从非数学解释的卷积中获得的最重要概念。

图 10-2 中的两个数字二的图像是*完全*相同的数字，只是它们在边界框中从左到右移动。将这两个数字转换为张量后，会创建出两个明显不同的不相等张量。然而，在本章开头描述的特征系统中，这些特征将是相同的。

![卷积特征与无特征](img/ltjs_1002.png)

###### 图 10-2。卷积简化了图像的本质

对于视觉张量，图像的特征比每个像素的确切位置更重要。

## 卷积快速总结

卷积操作用于提取高级特征，如边缘、梯度、颜色等。这些是分类给定视觉的关键特征。

那么应该提取哪些特征呢？这并不是我们实际决定的。您可以控制在查找特征时使用的滤波器数量，但最好定义可用模式的实际特征是在训练过程中定义的。这些滤波器从图像中突出和提取特征。

例如，看一下图 10-3 中的照片。南瓜灯是多种颜色，几乎与模糊但略带明暗的背景形成对比。作为人类，您可以轻松识别出照片中的内容。

![南瓜灯艺术的照片](img/ltjs_1003.png)

###### 图 10-3\. 南瓜灯艺术

现在这是同一图像，通过 3 x 3 的边缘检测滤波器卷积在像素上。注意结果在图 10-4 中明显简化和更明显。

不同的滤波器突出显示图像的不同方面，以简化和澄清内容。不必止步于此；您可以运行激活以强调检测到的特征，甚至可以在卷积上运行卷积。

结果是什么？您已经对图像进行了特征工程。通过各种滤波器对图像进行预处理，让您的神经网络看到原本需要更大、更慢和更复杂模型才能看到的模式。

![前一图像的卷积结果](img/ltjs_1004.png)

###### 图 10-4\. 卷积结果

## 添加卷积层

感谢 TensorFlow.js，添加卷积层与添加密集层一样简单，但称为`conv2d`，并具有自己的属性。

```py
tf.layers.conv2d({
  filters: 32, // ①
  kernelSize: 3, // ②
  strides: 1, // ③
  padding: 'same', // ④
  activation: 'relu',  // ⑤
  inputShape: [28, 28, 1] // ⑥
})
```

①

确定要运行多少个滤波器。

②

`kernelSize`控制滤波器的大小。这里的`3`表示 3 x 3 的滤波器。

③

小小的 3 x 3 滤波器不适合您的图像，因此需要在图像上滑动。步幅是滤波器每次滑动的像素数。

④

填充允许卷积在`strides`和`kernelSize`不能均匀地分割成图像宽度和高度时决定如何处理。当将填充设置为`same`时，会在图像周围添加零，以保持生成的卷积图像的大小不变。

⑤

然后将结果通过您选择的激活函数运行。

⑥

输入是一个图像张量，因此输入图像是模型的三维形状。这不是卷积的必需限制，正如您在第六章中学到的那样，但如果您不是在制作完全卷积模型，则建议这样做。

不要被可能的参数列表所压倒。想象一下自己必须编写所有这些不同设置。您可以像现有模型那样配置您的卷积，也可以使用数字进行调整以查看其对结果的影响。调整这些参数并进行实验是 TensorFlow.js 等框架的好处。最重要的是，随着时间的推移建立您的直觉。

重要的是要注意，这个`conv2d`层是用于图像的。同样，您将在线性序列上使用`conv1d`，在处理 3D 空间对象时使用`conv3d`。大多数情况下，使用 2D，但概念并不受限制。

# 理解最大池化

通过卷积层使用滤波器简化图像后，您在过滤后的图形中留下了大量空白空间。此外，由于所有图像滤波器，输入参数的数量显着增加。

最大池化是简化图像中识别出的最活跃特征的一种方法。

## 最大池化快速总结

为了压缩生成的图像大小，您可以使用最大池化来减少输出。简单地说，最大池化是将窗口中最活跃的像素保留为该窗口中所有像素块的表示。然后您滑动窗口并取其中的最大值。只要窗口的步幅大于 1，这些结果就会汇总在一起，以生成一个更小的图像。

以下示例通过取每个子方块中的最大数来将图像的大小分成四分之一。研究图 10-5 中的插图。

![最大池化演示](img/ltjs_1005.png)

###### 图 10-5。2 x 2 核和步幅为 2 的最大池

在图 10-5 中的`kernelSize`为 2 x 2。因此，四个左上角的方块一起进行评估，从数字`[12, 5, 11, 7]`中，最大的是`12`。这个最大数传递给结果。步幅为 2，核窗口的方块完全移动到前一个方块的相邻位置，然后重新开始使用数字`[20, 0, 12, 3]`。这意味着每个窗口中最强的激活被传递下去。

你可能会觉得这个过程会切割图像并破坏内容，但你会惊讶地发现，生成的图像是相当容易识别的。最大池化甚至强调了检测，并使图像更容易识别。参见图 10-6，这是在之前的南瓜灯卷积上运行最大池的结果。

最大池化强调检测

###### 图 10-6。卷积的 2 x 2 核最大池结果

虽然图 10-4 和图 10-6 在插图目的上看起来相同大小，但后者由于池化过程而稍微清晰一些，并且是原始大小的四分之一。

## 添加最大池化层

类似于`conv2d`，最大池化被添加为一层，通常紧跟在卷积之后：

```py
tf.layers.maxPooling2d({
  poolSize: 2, // ①
  strides: 2   // ②
})
```

①

`poolSize`是窗口大小，就像`kernelSize`一样。之前的例子都是 2（代表 2 x 2）。

②

`strides`是在每次操作中向右和向下移动窗口的距离。这也可以写成`strides: [2, 2]`。

通常，阅读图像的模型会有几层卷积，然后池化，然后再次卷积和池化。这会消耗图像的特征，并将它们分解成可能识别图像的部分。⁠²

# 训练图像分类

经过几层卷积和池化后，你可以将结果滤波器展平或序列化成一个单一链，并将其馈送到一个深度连接的神经网络中。这就是为什么人们喜欢展示 MNIST 训练示例；它是如此简单，以至于你实际上可以在一个图像中观察数据。

看一下使用卷积和最大池化对数字进行分类的整个过程。图 10-7 应该从底部向顶部阅读。

![MNIST 逐层输出](img/ltjs_1007.png)

###### 图 10-7。MNIST 处理数字五

如果你跟随图 10-7 中显示的这幅图像的过程，你会看到底部的输入，然后是该输入与六个滤波器的卷积直接在其上方。接下来，这六个滤波器被最大池化或“下采样”，你可以看到它们变小了。然后再进行一次卷积和池化，然后将它们展平到一个完全连接的密集网络层。在展平的层上方是一个密集层，顶部的最后一个小层是一个具有 10 个可能解的 softmax 层。被点亮的是“五”。

从鸟瞰视角看，卷积和池化看起来像魔术，但它将图像的特征消化成神经元可以识别的模式。

在分层模型中，这意味着第一层通常是卷积和池化风格的层，然后它们被传递到神经网络中。图 10-8 展示了这个过程的高层视图。以下是三个阶段：

1.  输入图像

1.  特征提取

1.  深度连接的神经网络

![CNN 流程图](img/ltjs_1008.png)

###### 图 10-8。CNN 的三个基本阶段

## 处理图像数据

使用图像进行训练的一个缺点是数据集可能非常庞大且难以处理。数据集通常很大，但对于图像来说，它们通常是巨大的。这也是为什么相同的视觉数据集一遍又一遍地被使用的另一个原因。

即使图像数据集很小，当加载到内存张量形式时，它可能占用大量内存。你可能需要将训练分成张量的块，以处理庞大的图像集。这可能解释了为什么像 MobileNet 这样的模型被优化为今天标准下被认为相对较小的尺寸。在所有图像上增加或减少一个像素会导致指数级的尺寸差异。由于数据的本质，灰度张量在内存中是 RGB 图像的三分之一大小，是 RGBA 图像的四分之一大小。

# 分拣帽

现在是时候进行你的第一个卷积神经网络了。对于这个模型，你将训练一个 CNN 来将灰度绘画分类为 10 个类别。

如果你是 J.K.罗琳的流行书系列《哈利·波特》的粉丝，这将是有意义且有趣的。然而，如果你从未读过一本《哈利·波特》的书或者看过任何一部电影，这仍然是一个很好的练习。在书中，魔法学校霍格沃茨有四个学院，每个学院都有与之相关联的动物。你将要求用户画一幅图片，并使用该图片将它们分类到各个学院。我已经准备了一个数据集，其中的绘画在某种程度上类似于每个组的图标和动物。

我准备的数据集是从[Google 的 Quick, Draw!数据集](https://oreil.ly/kq3bX)中的一部分绘画中制作的。类别已经缩减到 10 个，并且数据已经经过了大幅清理。

与本章相关的代码可以在[*chapter10/node/node-train-houses*](https://oreil.ly/xr3Bu)找到，你会发现一个包含数万个 28 x 28 绘画的 ZIP 文件，包括以下内容：

1.  鸟类

1.  猫头鹰

1.  鹦鹉

1.  蛇

1.  蜗牛

1.  狮子

1.  老虎

1.  浣熊

1.  松鼠

1.  头巾

这些绘画变化很大，但每个类别的特征是可辨认的。这里是一些涂鸦的随机样本，详见图 10-9。一旦你训练了一个模型来识别这 10 个类别中的每一个，你就可以使用该模型将类似特定动物的绘画分类到其相关联的学院。鸟类去拉文克劳，狮子和老虎去格兰芬多，等等。

![霍格沃茨学院绘画网格形式](img/ltjs_1009.png)

###### 图 10-9\. 绘画的 10 个类别

处理这个问题的方法有很多，但最简单的方法是使用 softmax 对最终层进行模型分类。正如你记得的那样，softmax 会给我们 N 个数字，它们的总和都为一。例如，如果一幅图是 0.67 的鸟，0.12 的猫头鹰，和 0.06 的鹦鹉，因为它们都代表同一个学院，我们可以将它们相加，结果总是小于一。虽然你熟悉使用返回这种结果的模型，但这将是你从头开始创建的第一个 softmax 分类模型。

## 入门

有几种方法可以使用 TensorFlow.js 来训练这个模型。将几兆字节的图像加载到浏览器中可以通过几种方式完成：

+   你可以使用后续的 HTTP 请求加载每个图像。

+   你可以将训练数据合并到一个大的精灵表中，然后使用你的张量技能来提取和堆叠每个图像到 X 和 Y 中。

+   你可以将图像加载到 CSV 中，然后将它们转换为张量。

+   你可以将图像进行 Base64 编码，并从单个 JSON 文件加载它们。

你在这里看到的一个常见问题是，你必须做一些额外的工作，将数据加载到浏览器的沙盒中。因此，最好使用 Node.js 进行具有大规模数据集的图像训练。我们将在本书后面讨论这种情况不那么重要的情况。

与本章相关的 Node.js 代码包含了你需要的训练数据。你会在存储库中看到一个接近 100MB 的文件（GitHub 对单个文件的限制），你需要解压到指定位置（见图 10-10）。

![解压文件.zip 截图](img/ltjs_1010.png)

###### 图 10-10\. 将图像解压缩到文件夹中

现在你有了图片，也知道如何在 Node.js 中读取图片，训练这个模型的代码会类似于示例 10-1。

##### 示例 10-1\. 理想的设置

```py
  // Read images
  const [X, Y] = await folderToTensors() // ①

  // Create layers model
  const model = getModel() // ②

  // Train
  await model.fit(X, Y, {
    batchSize: 256,
    validationSplit: 0.1,
    epochs: 20,
    shuffle: true, // ③
  })

  // Save
  model.save('file://model_result/sorting_hat') // ④

  // Cleanup!
  tf.dispose([X, Y, model])
  console.log('Tensors in memory', tf.memory().numTensors)
```

①

创建一个简单的函数将图片加载到所需的 X 和 Y 张量中。

②

创建一个适合的 CNN 层模型。

③

使用`shuffle`属性，该属性会对当前批次进行混洗。

④

将生成的训练模型保存在本地。

###### 注意

示例 10-1 中的代码没有提及设置任何测试数据。由于这个项目的性质，真正的测试将在绘制图像并确定每个笔画如何使图像更接近或更远离期望目标时进行。在训练中仍将使用验证集。

## 转换图像文件夹

`folderToTensors`函数需要执行以下操作：

1.  识别所有 PNG 文件路径。

1.  收集图像张量和答案。

1.  随机化两组数据。

1.  归一化和堆叠张量。

1.  清理并返回结果。

要识别和访问所有图像，可以使用类似`glob`的库，它接受一个给定的路径，如*files/**/*.png*，并返回一个文件名数组。/**会遍历该文件夹中的所有子文件夹，并找到每个文件夹中的所有 PNG 文件。

你可以通过以下方式使用 NPM 安装`glob`：

```py
$ npm i glob
```

现在节点模块可用，可以被要求或导入：

```py
const glob = require('glob')
// OR
import { default as glob } from 'glob'
```

由于 glob 是通过回调来操作的，你可以将整个函数包装在 JavaScript promise 中，以将其转换为异步/等待。如果你对这些概念不熟悉，可以随时查阅相关资料或仅仅学习本章提供的代码。

在收集了一组文件位置之后，你可以加载文件，将其转换为张量，甚至通过查看图像来自哪个文件夹来确定每个图像的“答案”或“y”。

记住，每次需要修改张量时都会创建一个*新张量*。因此，最好将张量保存在 JavaScript 数组中，而不是在进行归一化和堆叠张量时逐步进行。

将每个字符串读入这两个数组的过程可以通过以下方式完成：

```py
files.forEach((file) => {
  const imageData = fs.readFileSync(file)
  const answer = encodeDir(file)
  const imageTensor = tf.node.decodeImage(imageData, 1)

  // Store in memory
  YS.push(answer)
  XS.push(imageTensor)
})
```

`encodeDir`函数是我编写的一个简单函数，用于查看每个图像的路径并返回一个相关的预测数字：

```py
function encodeDir(filePath) {
  if (filePath.includes('bird')) return 0
  if (filePath.includes('lion')) return 1
  if (filePath.includes('owl')) return 2
  if (filePath.includes('parrot')) return 3
  if (filePath.includes('raccoon')) return 4
  if (filePath.includes('skull')) return 5
  if (filePath.includes('snail')) return 6
  if (filePath.includes('snake')) return 7
  if (filePath.includes('squirrel')) return 8
  if (filePath.includes('tiger')) return 9

  // Should never get here
  console.error('Unrecognized folder')
  process.exit(1)
}
```

一旦将图片转换为张量形式，你可能会考虑堆叠和返回它们，但在此之前*至关重要*的是在混洗之前对它们进行混洗。如果不混合数据，你的模型将会以最奇怪的方式快速训练。请容我用一个奇特的比喻。

想象一下，如果我让你在一堆形状中指出我在想的形状。你很快就会发现我总是在想圆形，然后你开始获得 100%的准确率。在我们的第三次测试中，我开始说，“不，那不是正方形！你错得很离谱。”于是你开始指向正方形，再次获得 100%的准确率。每三次测试，我都会改变形状。虽然你的分数超过 99%的准确率，但你从未学会选择哪个形状的实际指标。因此，当形状每次都在变化时，你就会失败。你从未学会指标，因为数据没有被混洗。

未经混洗的数据将产生相同的效果：训练准确率接近完美，而验证和测试分数则很差。即使你对每个数据集进行混洗，大部分时间你只会对相同的 256 个值进行混洗。

要对 X 和 Y 进行相同的排列混洗，可以使用`tf.utils.shuffleCombo`。*我听说向 TensorFlow.js 添加此功能的人非常酷。*

```py
// Shuffle the data (keep XS[n] === YS[n])
tf.util.shuffleCombo(XS, YS)
```

由于这是对 JavaScript 引用进行混洗，因此在此混洗中不会创建新的张量。

最后，您将希望将答案从整数转换为独热编码。独热编码是因为您的模型将使用 softmax，即 10 个值相加为 1，其中正确答案是唯一的主导值。

TensorFlow.js 有一个名为`oneHot`的方法，它将数字转换为独热编码的张量值。例如，从 5 个可能类别中的数字`3`将被编码为张量`[0,0,1,0,0]`。这就是我们希望格式化答案以匹配分类模型预期输出的方式。

现在，您可以将 X 和 Y 数组值堆叠成一个大张量，并通过除以`255`来将图像归一化为值`0-1`。堆叠和编码看起来像这样：

```py
// Stack values
console.log('Stacking')
const X = tf.stack(XS)
const Y = tf.oneHot(YS, 10)

console.log('Images all converted to tensors:')
console.log('X', X.shape)
console.log('Y', Y.shape)

// Normalize X to values 0 - 1
const XNORM = X.div(255)
// cleanup
tf.dispose([XS, X])
```

由于处理数千个图像，您的计算机可能会在每个日志之间暂停。代码打印以下内容：

```py
Stacking
Images all converted to tensors:
X [ 87541, 28, 28, 1 ]
Y [ 87541, 10 ]
```

现在我们有了用于训练的 X 和 Y，它们的形状是我们将创建的模型的输入和输出形状。

## CNN 模型

现在是创建卷积神经网络模型的时候了。该模型的架构将是三对卷积和池化层。在每个新的卷积层上，我们将使滤波器的数量加倍。然后我们将将模型展平为一个具有 128 个单元的单个密集隐藏层，具有`tanh`激活，并以具有 softmax 激活的 10 个可能输出的最终层结束。如果您对为什么使用 softmax 感到困惑，请回顾我们在第九章中介绍的分类模型的结构。

您应该能够仅通过描述编写模型层，但这里是创建所描述的顺序模型的代码：

```py
const model = tf.sequential()

// Conv + Pool combo
model.add(
  tf.layers.conv2d({
    filters: 16,
    kernelSize: 3,
    strides: 1,
    padding: 'same',
    activation: 'relu',
    kernelInitializer: 'heNormal',
    inputShape: [28, 28, 1],
  })
)
model.add(tf.layers.maxPooling2d({ poolSize: 2, strides: 2 }))

// Conv + Pool combo
model.add(
  tf.layers.conv2d({
    filters: 32,
    kernelSize: 3,
    strides: 1,
    padding: 'same',
    activation: 'relu',
  })
)
model.add(tf.layers.maxPooling2d({ poolSize: 2, strides: 2 }))

// Conv + Pool combo
model.add(
  tf.layers.conv2d({
    filters: 64,
    kernelSize: 3,
    strides: 1,
    padding: 'same',
    activation: 'relu',
  })
)
model.add(tf.layers.maxPooling2d({ poolSize: 2, strides: 2 }))

// Flatten for connecting to deep layers
model.add(tf.layers.flatten())

// One hidden deep layer
model.add(
  tf.layers.dense({
    units: 128,
    activation: 'tanh',
  })
)
// Output
model.add(
  tf.layers.dense({
    units: 10,
    activation: 'softmax',
  })
)
```

这个新的用于非二进制分类数据的最终层意味着您需要将损失函数从`binaryCrossentropy`更改为`categoricalCrossentropy`。因此，现在`model.compile`的代码看起来像这样：

```py
model.compile({
  optimizer: 'adam',
  loss: 'categoricalCrossentropy',
  metrics: ['accuracy'],
})
```

让我们通过我们学到的关于卷积和最大池化的知识来审查`model.summary()`方法，以确保我们已经正确构建了一切。您可以在示例 10-2 中看到结果的打印输出。

##### 示例 10-2。`model.summary()`的输出

```py
_________________________________________________________________
Layer (type)                 Output shape              Param #
=================================================================
conv2d_Conv2D1 (Conv2D)      [null,28,28,16]           160         // ①
_________________________________________________________________
max_pooling2d_MaxPooling2D1  [null,14,14,16]           0           // ②
_________________________________________________________________
conv2d_Conv2D2 (Conv2D)      [null,14,14,32]           4640        // ③
_________________________________________________________________
max_pooling2d_MaxPooling2D2  [null,7,7,32]             0
_________________________________________________________________
conv2d_Conv2D3 (Conv2D)      [null,7,7,64]             18496       // ④
_________________________________________________________________
max_pooling2d_MaxPooling2D3  [null,3,3,64]             0
_________________________________________________________________
flatten_Flatten1 (Flatten)   [null,576]                0           // ⑤
_________________________________________________________________
dense_Dense1 (Dense)         [null,128]                73856       // ⑥
_________________________________________________________________
dense_Dense2 (Dense)         [null,10]                 1290        // ⑦
=================================================================
Total params: 98442
Trainable params: 98442
Non-trainable params: 0
_________________________________________________________________
```

①

第一个卷积层的输入为`[stacksize, 28, 28, 1]`，卷积输出为`[stacksize, 28, 28, 16]`。大小相同是因为我们使用了`padding: 'same'`，而 16 是当我们指定`filters: 16`时得到的 16 个不同的滤波器结果。您可以将其视为每个堆栈中的每个图像的 16 个新滤波图像。这为网络提供了 160 个新参数进行训练。可训练参数的计算方式为(图像数量) * (卷积核窗口) * (输出图像) + (输出图像)，计算结果为`1 * (3x3) * 16 + 16 = 160`。

②

最大池化将滤波后的图像行和列大小减半，从而将像素分成四分之一。由于算法是固定的，因此此层没有任何可训练参数。

③

卷积和池化再次发生，并且在每个级别都使用更多的滤波器。图像的大小正在缩小，可训练参数的数量迅速增长，即`16 * (3x3) * 32 + 32 = 4,640`。

④

在这里，有一个最终的卷积和池化。池化奇数会导致大于 50%的减少。

⑤

将 64 个 3 x 3 图像展平为一个由 576 个单元组成的单层。

⑥

这 576 个单元中的每一个都与 128 个单元的层密切连接。使用传统的线+节点计算，这将得到`(576 * 128) + 128 = 73,856`个可训练参数。

⑦

最后，最后一层有 10 个可能的值对应每个类别。

您可能想知道为什么我们评估`model.summary()`而不是检查正在发生的事情的图形表示。即使在较低的维度，图形表示正在发生的事情也很难说明。我已经尽力在图 10-11 中创建了一个相对详尽的插图。

![CNN 神经网络](img/ltjs_1011.png)

###### 图 10-11\. 每一层的可视化

与以往的神经网络图不同，CNN 的可视化解释可能有些局限性。堆叠在一起的滤波图像只能提供有限的信息。卷积过程的结果被展平并连接到一个深度连接的神经网络。您已经达到了一个复杂性的程度，`summary()`方法是理解内容的最佳方式。

###### 提示

如果您想要一个动态的可视化，并观看每个训练滤波器在每一层的激活结果，数据科学 Polo Club 创建了一个美丽的[CNN 解释器](https://oreil.ly/o24uR)在 TensorFlow.js 中。查看[交互式可视化器](https://oreil.ly/SYHsp)。

你已经到了那里。您的结果`[3, 3, 64]`在连接到神经网络之前展平为 576 个人工神经元。您不仅创建了图像特征，还简化了一个`[28, 28, 1]`图像的输入，原本需要 784 个密集连接的输入。有了这种更先进的架构，您可以从`folderToTensors()`加载数据并创建必要的模型。您已经准备好训练了。

## 训练和保存

由于这是在 Node.js 中进行训练，您将不得不直接在机器上设置 GPU 加速。这通常是通过 NVIDIA CUDA 和 CUDA 深度神经网络（cuDNN）完成的。如果您想使用`@tensorflow/tfjs-node-gpu`进行训练并获得比普通`tfjs-node`更快的速度提升，您将不得不正确设置 CUDA 和 cuDNN 以与您的 GPU 一起工作。请参阅图 10-12。

![CUDA GPU 截图](img/ltjs_1012.png)

###### 图 10-12\. 使用 GPU 可以提高 3-4 倍的速度

在 20 个时代之后，生成的模型在训练中的准确率约为 95%，在验证集中的准确率约为 90%。生成模型的文件大小约为 400 KB。您可能已经注意到训练集的准确率不断上升，但验证集有时会下降。不管好坏，最后一个时代将是保存的模型。如果您想确保最高可能的验证准确性，请查看最后的章节挑战。

###### 注意

如果您对这个模型运行了太多时代，模型将过拟合，并接近 100%的训练准确率，而验证准确率会降低。

# 测试模型

要测试这个模型，您需要用户的绘图。您可以在网页上创建一个简单的绘图表面，使用一个画布。画布可以订阅鼠标按下时、鼠标沿着画布移动时以及鼠标释放时的事件。使用这些事件，您可以从一个点绘制到另一个点。

## 构建一个草图板

您可以使用这三个事件构建一个简单的可绘制画布。您将使用一些新方法来移动画布路径和绘制线条，但这是相当易读的。以下代码设置了一个：

```py
const canvas = document.getElementById("sketchpad");
const context = canvas.getContext("2d");
context.lineWidth = 14;
context.lineCap = "round";
let isIdle = true;

function drawStart(event) {
  context.beginPath();
  context.moveTo(
    event.pageX - canvas.offsetLeft,
    event.pageY - canvas.offsetTop
  );
  isIdle = false;
}
function drawMove(event) {
  if (isIdle) return;
  context.lineTo(
    event.pageX - canvas.offsetLeft,
    event.pageY - canvas.offsetTop
  );
  context.stroke();
}
function drawEnd() { isIdle = true; }
// Tie methods to events
canvas.addEventListener("mousedown", drawStart, false);
canvas.addEventListener("mousemove", drawMove, false);
canvas.addEventListener("mouseup", drawEnd, false);
```

这些图纸是由一堆较小的线条制成的，线条的笔画宽度为 14 像素，并且在边缘自动圆润。您可以在图 10-13 中看到一个测试绘图。

![示例绘图](img/ltjs_1013.png)

###### 图 10-13\. 运行得足够好

当用户在画布上单击鼠标时，任何移动都将从一个点绘制到新点。每当用户停止绘制时，将调用`drawEnd`函数。您可以添加一个按钮来对画布进行分类，或者直接将其连接到`drawEnd`函数并对图像进行分类。

## 阅读草图板

当你在画布上调用 `tf.browser.fromPixels` 时，你会得到 100% 的黑色像素。为什么会这样？答案是画布的某些地方没有绘制任何内容，而其他地方是黑色像素。当画布转换为张量值时，它会将空白转换为黑色。画布可能看起来有白色背景，但实际上是透明的，会显示底部的任何颜色或图案（参见 图 10-14）。

![一个空的画布](img/ltjs_1014.png)

###### 图 10-14\. 一个画布是透明的，所以空白像素为零

为了解决这个问题，你可以添加一个清除函数，在画布上绘制一个大的白色正方形，这样黑色线条就会在白色背景上，就像训练图像一样。这也是你可以在绘画之间清除画布的函数。要用白色背景填充画布，你可以使用 `fillRect` 方法，就像你在 第六章 中用来勾画标签的方法一样。

```py
context.fillStyle = "#fff";
context.fillRect(0, 0, canvas.clientWidth, canvas.clientHeight);
```

一旦画布用白色背景初始化，你就可以对画布绘制进行预测了。

```py
async function makePrediction(canvas, model) {
  const drawTensor = tf.browser.fromPixels(canvas, 1) // ①
  const resize = tf.image.resizeNearestNeighbor(drawTensor, [28,28], true) // ②

  const batched = resize.expandDims() // ③
  const results = await model.predict(batched)
  const predictions = await results.array()

  // Display
  displayResults(predictions[0]) // ④
  // Cleanup
  tf.dispose([drawTensor, resize, batched, results])
}
```

①

当你读取画布时，不要忘记标识你只对单个通道感兴趣；否则，你需要在继续之前将 3D 张量转换为 1D 张量。

②

使用最近邻算法将图像调整为 28 x 28 的大小，以输入到模型中。最近邻引起的像素化在这里并不重要，所以这是一个明智的选择，因为它比 `resizeBilinear` 更快。

③

模型期望一个批次数据，所以准备数据作为一个批次的数据。这将创建一个 `[1, 28, 28, 1]` 的输入张量。

④

预测结果已经作为一个包含 10 个数字的批次返回到 JavaScript。想出一种创造性的方式来展示结果。

现在你已经得到了结果，你可以以任何你喜欢的格式展示答案。我个人是按照房间组织了分数，并用它们来设置标签的不透明度。这样，你可以在每画一条线时得到反馈。标签的不透明度取决于值 `0-1`，这与 softmax 预测结果非常契合。

```py
function displayResults(predictions) {
  // Get Scores
  const ravenclaw = predictions[0] + predictions[2] + predictions[3]
  const gryffindor = predictions[1] + predictions[9]
  const hufflepuff = predictions[4] + predictions[8]
  const slytherin = predictions[6] + predictions[7]
  const deatheater = predictions[5]

  document.getElementById("ravenclaw").style.opacity = ravenclaw
  document.getElementById("gryffindor").style.opacity = gryffindor
  document.getElementById("hufflepuff").style.opacity = hufflepuff
  document.getElementById("slytherin").style.opacity = slytherin

  // Harry Potter fans will enjoy this one
  if (deatheater > 0.9) {
    alert('DEATH EATER DETECTED!!!')
  }
}
```

你可能会想知道拉文克劳是否有轻微的数学优势，因为它由更多类别组成，你是对的。在所有条件相同的情况下，一组完全随机的线更有可能被分类为拉文克劳，因为它拥有大多数类别。然而，当图像不是随机的时，这在统计上是不显著的。如果你希望模型只有九个类别，可以移除 `bird` 并重新训练，以创建最平衡的分类谱。

###### 提示

如果你有兴趣确定哪些类别可能存在问题或混淆，你可以使用视觉报告工具，如混淆矩阵或 [t-SNE](https://oreil.ly/sBio5) 算法。这些工具对于评估训练数据特别有帮助。

我强烈建议你从[*chapter10/simple/simplest-draw*](https://oreil.ly/emOWR)加载本章的代码，并测试一下你的艺术技能！我的鸟类绘画将我分类到了拉文克劳，如 图 10-15 所示。

![网页正确识别出一只鸟](img/ltjs_1015.png)

###### 图 10-15\. 一个 UI 和绘画杰作

我能够糟糕地画出并被正确分类到其他可能的房间中。然而，我不会再用我的“艺术”来惩罚你。

# 章节回顾

你已经在视觉数据上训练了一个模型。虽然这个数据集仅限于灰度图，但你所学到的经验可以适用于任何图像数据集。有很多优秀的图像数据集可以与你创建的模型完美配合。我们将在接下来的两章中详细介绍。

我为本章中的[绘画识别特色](https://oreil.ly/jnlhb)创建了一个更加复杂的页面。

## 章节挑战：保存魔法

如果您最感兴趣的是获得最高验证准确性模型，那么您的最佳模型版本很可能不是最后一个版本。例如，如果您查看图 10-16，90.3%的验证准确性会丢失，最终验证模型为 89.6%。

对于本章挑战，与其保存模型的最终训练版本，不如添加一个回调函数，当验证准确性达到新的最佳记录时保存模型。这种代码非常有用，因为它允许您运行多个时期。随着模型过拟合，您将能够保留最佳的通用模型用于生产。

![验证与训练准确性](img/ltjs_1016.png)

###### 图 10-16。评估哪个准确性更重要

您可以在附录 B 中找到此挑战的答案。

## 复习问题

让我们回顾一下你在本章编写的代码中学到的教训。花点时间回答以下问题：

1.  卷积层有许多可训练的*什么*，可以帮助提取图像的特征？

1.  控制卷积窗口大小的属性名称是什么？

1.  如果你希望卷积结果与原始图像大小相同，应该将填充设置为什么？

1.  真或假？在将图像插入卷积层之前，必须将其展平。

1.  在 81 x 81 图像上，步幅为 3 的最大池 3 x 3 的输出大小将是多少？

1.  如果您要对数字 12 进行独热编码，您是否有足够的信息来这样做？

这些练习的解决方案可以在附录 A 中找到。

¹ YouTube 上的[3Blue1Brown](https://oreil.ly/zuGzT)的视频和讲座是任何想要深入了解卷积的人的绝佳起点。

² TensorFlow.js 中还有其他可用于实验的池化方法。
