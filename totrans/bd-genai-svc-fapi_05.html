<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><section data-pdf-bookmark="Chapter 3. AI Integration and Model Serving" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch03">
<h1><span class="label">Capitolo 3. </span>Integrazione dell'IA e servizio del modello</h1><div data-type="note"><p>Questo lavoro è stato tradotto utilizzando l'AI. Siamo lieti di ricevere il tuo feedback e i tuoi commenti: <a href="mailto:translation-feedback@oreilly.com">translation-feedback@oreilly.com</a></p></div>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id629">
<h1>Obiettivi del capitolo</h1>
<p>In questo capitolo imparerai a conoscere:</p>
<ul>
<li>
<p>Come funzionano i diversi modelli GenAI</p>
</li>
<li>
<p>Come integrare e servire i modelli generativi in FastAPI</p>
</li>
<li>
<p>Come lavorare con testo, immagini, audio, video e modelli 3D</p>
</li>
<li>
<p>Come costruire rapidamente un'interfaccia utente per la prototipazione</p>
</li>
<li>
<p>Diverse strategie di model-serving in FastAPI</p>
</li>
<li>
<p>Come sfruttare il middleware per il monitoraggio dei servizi</p>
</li>
</ul>
</div></aside>
<p>In questo capitolo imparerai i meccanismi dei vari modelli GenAI e come servirli in un'applicazione FastAPI. Inoltre, utilizzando il <a href="https://oreil.ly/9BXmn">pacchetto Streamlit UI</a>, creerai un semplice client browser per interagire con gli endpoint che servono i modelli. Esploreremo le diverse strategie di servizio dei modelli, come precaricare i modelli per renderli più efficienti e come utilizzare le funzioni FastAPI per il<span class="keep-together">monitoraggio</span> dei servizi.</p>
<p>Per consolidare quanto appreso in questo capitolo, costruiremo progressivamente un servizio FastAPI utilizzando modelli GenAI open source che generano testo, immagini, audio e geometrie 3D, il tutto partendo da zero. Nei capitoli successivi, costruirai la funzionalità di analisi dei documenti e dei contenuti web per il tuo servizio GenAI in modo da poter dialogare con loro utilizzando un modello linguistico.</p>
<div data-type="note" epub:type="note"><h6>Nota</h6>
<p>Nel capitolo precedente hai visto come configurare un nuovo progetto FastAPI in Python. Assicurati di avere pronta un'installazione fresca prima di leggere il resto di questo capitolo. In alternativa, puoi clonare o scaricare il <a href="https://github.com/Ali-Parandeh/building-generative-ai-services">repository GitHub</a> del libro. Poi, una volta clonato, passa al ramo <code translate="no">ch03-start</code>, pronto per i passi da seguire.</p>
</div>
<p>Alla fine di questo capitolo, avrai un servizio FastAPI che serve vari modelli GenAI open source che potrai testare all'interno dell'interfaccia utente Streamlit. Inoltre, il tuo servizio sarà in grado di registrare i dati di utilizzo su disco utilizzando il middleware.</p>
<section data-pdf-bookmark="Serving Generative Models" data-type="sect1"><div class="sect1" id="id39">
<h1>Modelli generativi al servizio del cliente</h1>
<p><a data-primary="serving GenAI models" data-type="indexterm" id="ix_ch03-asciidoc0"/>Prima di utilizzare modelli generativi pre-addestrati nella tua applicazione, vale la pena di imparare come questi modelli vengono addestrati e generano dati. Grazie a questa conoscenza, puoi personalizzare gli interni della tua applicazione per migliorare i risultati che fornisci all'utente.</p>
<p>In questo capitolo ti mostrerò come servire i modelli in diverse modalità, tra cui:</p>
<ul>
<li>
<p>Modelli<em>linguistici</em> basati sull'architettura della rete neurale trasformatrice</p>
</li>
<li>
<p>Modelli<em>audio</em> nei servizi text-to-speech e text-to-audio basati sull'architettura a trasformatori aggressivi</p>
</li>
<li>
<p>Modelli di<em>visione</em> per servizi text-to-image e text-to-video basati sulla Diffusione Stabile e sulle architetture di trasformazione della visione</p>
</li>
<li>
<p>Modelli<em>3D</em> per servizi text-to-3D basati sull'architettura del codificatore di funzioni implicite condizionali e del decodificatore di diffusione</p>
</li>
</ul>
<p>Questo elenco non è esaustivo e copre una manciata di modelli GenAI. Per esplorare altri modelli, visita il <a href="https://oreil.ly/-4wlQ">repository dei modelli Hugging Face</a>.<sup><a data-type="noteref" href="ch03.html#id630" id="id630-marker" translate="no">1</a></sup></p>
<section data-pdf-bookmark="Language Models" data-type="sect2"><div class="sect2" id="id40">
<h2>Modelli linguistici</h2>
<p><a data-primary="language models" data-type="indexterm" id="ix_ch03-asciidoc1"/><a data-primary="serving GenAI models" data-secondary="language models" data-type="indexterm" id="ix_ch03-asciidoc2"/>In questa sezione parliamo dei modelli linguistici, compresi i trasformatori e le reti neurali ricorrenti (RNN).</p>
<section data-pdf-bookmark="Transformers versus recurrent neural networks" data-type="sect3"><div class="sect3" id="id41">
<h3>Trasformatori contro reti neurali ricorrenti</h3>
<p><a data-primary="language models" data-secondary="transformers versus recurrent neural networks" data-type="indexterm" id="ix_ch03-asciidoc3"/><a data-primary="recurrent neural networks (RNNs), transformers versus" data-type="indexterm" id="ix_ch03-asciidoc4"/><a data-primary="serving GenAI models" data-secondary="language models" data-tertiary="transformers versus recurrent neural networks" data-type="indexterm" id="ix_ch03-asciidoc5"/><a data-primary="transformers" data-secondary="recurrent neural networks versus" data-type="indexterm" id="ix_ch03-asciidoc6"/>Il mondo dell'Intelligenza Artificiale è stato scosso dalla pubblicazione dell'importante articolo "Attention Is All You Need".<sup><a data-type="noteref" href="ch03.html#id631" id="id631-marker" translate="no">2</a></sup>
In questo articolo, gli autori proponevano un approccio completamente diverso all'elaborazione del linguaggio naturale (NLP) e alla modellazione delle sequenze che si differenziava dalle architetture RNN esistenti.</p>
<p>La<a data-type="xref" href="#transformer_architecture">Figura 3-1</a> mostra una versione semplificata dell'architettura del trasformatore proposta nell'articolo originale.</p>
<figure><div class="figure" id="transformer_architecture">
<img alt="bgai 0301" src="assets/bgai_0301.png" width="1401" height="359"/>
<h6><span class="label">Figura 3-1. </span>Architettura del trasformatore</h6>
</div></figure>
<p>Storicamente, le attività di generazione del testo hanno sfruttato i modelli RNN per apprendere modelli in dati sequenziali come il testo libero.<a data-primary="tokens" data-secondary="in RNNs" data-type="indexterm" id="id632"/>Per elaborare il testo, questi modelli lo suddividono in piccoli pezzi, come una parola o un carattere, chiamati <em>token</em>, che possono essere elaborati in sequenza.</p>
<p><a data-primary="state vector" data-type="indexterm" id="id633"/>Le RNN mantengono un archivio di memoria chiamato <em>vettore di stato</em>, che trasporta le informazioni da un token all'altro per tutta la sequenza di testo, fino alla fine. Questo significa che quando si arriva alla fine della sequenza di testo, l'impatto dei primi token sul vettore di stato è molto minore rispetto ai token più recenti.</p>
<p>Idealmente, ogni token dovrebbe avere la stessa importanza degli altri token in un testo. Tuttavia, poiché le RNN possono prevedere l'elemento successivo in una sequenza solo osservando gli elementi che l'hanno preceduto, non riescono a cogliere le dipendenze a lungo raggio e a modellare i modelli in grandi porzioni di testo. Di conseguenza, non riescono a ricordare o a comprendere le informazioni essenziali o il contesto in documenti di grandi dimensioni.</p>
<p>Con l'invenzione dei trasformatori, la modellazione ricorrente o convoluzionale poteva essere sostituita da un approccio più efficiente.<a data-primary="self-attention" data-type="indexterm" id="id634"/>Poiché i trasformatori non mantengono una memoria di stato nascosta e sfruttano una nuova capacità definita <em>auto-attenzione</em>, sono in grado di modellare le relazioni tra le parole, indipendentemente dalla distanza tra loro in una frase. Questa componente di auto-attenzione consente al modello di "porre l'attenzione" sulle parole contestualmente rilevanti all'interno di una frase.</p>
<p>Mentre le RNN modellano le relazioni tra parole vicine in una frase, i trasformatori mappano le relazioni a coppie tra ogni parola del testo.</p>
<p>La<a data-type="xref" href="#rnn_vs_transformer">Figura 3-2</a> mostra come le RNN elaborano le frasi rispetto ai trasformatori.</p>
<figure><div class="figure" id="rnn_vs_transformer">
<img alt="bgai 0302" src="assets/bgai_0302.png" width="1153" height="601"/>
<h6><span class="label">Figura 3-2. </span>RNN rispetto ai trasformatori nell'elaborazione delle frasi</h6>
</div></figure>
<p>Ciò che alimenta il sistema di auto-attenzione sono blocchi specializzati chiamati <em>teste di attenzione</em> che catturano gli schemi di coppia tra le parole come <em>mappe di attenzione</em>.</p>
<p>La <a data-type="xref" href="#head_attention_map">Figura 3-3</a> visualizza la mappa di attenzione di una testa di attenzione.<sup><a data-type="noteref" href="ch03.html#id635" id="id635-marker" translate="no">3</a></sup>
Le connessioni possono essere bidirezionali e lo spessore rappresenta la forza della relazione tra le parole della frase.</p>
<figure><div class="figure" id="head_attention_map">
<img alt="bgai 0303" src="assets/bgai_0303.png" width="1252" height="596"/>
<h6><span class="label">Figura 3-3. </span>Vista di una mappa di attenzione all'interno di una testa di attenzione</h6>
</div></figure>
<p><a data-primary="attention maps" data-type="indexterm" id="id636"/>Un modello trasformatore contiene diverse teste di attenzione distribuite tra gli strati della rete neurale. Ogni testa calcola la propria mappa di attenzione in modo indipendente per catturare le relazioni tra le parole concentrandosi su determinati schemi negli input. Utilizzando più teste di attenzione, il modello può analizzare simultaneamente gli input da diverse angolazioni e contesti per comprendere schemi complessi e dipendenze all'interno dei dati.</p>
<p>La<a data-type="xref" href="#model_attention_map">Figura 3-4</a> mostra le mappe di attenzione per ogni testa (cioè un insieme indipendente di pesi di attenzione) all'interno di ogni strato del modello.</p>
<figure><div class="figure" id="model_attention_map">
<img alt="bgai 0304" src="assets/bgai_0304.png" width="2025" height="2030"/>
<h6><span class="label">Figura 3-4. </span>Vista delle mappe di attenzione all'interno del modello</h6>
</div></figure>
<p class="less_space pagebreak-before">Le RNN richiedono inoltre una grande potenza di calcolo per l'addestramento, in quanto il processo di addestramento non può essere parallelizzato su più GPU a causa della natura sequenziale dei loro algoritmi di addestramento. I trasformatori, invece, elaborano le parole in modo non sequenziale, quindi possono eseguire i meccanismi di attenzione in parallelo sulle GPU.</p>
<p>L'efficienza dell'architettura a trasformatori significa che questi modelli sono più scalabili se ci sono più dati, potenza di calcolo e memoria. È possibile costruire modelli linguistici con un corpus che abbraccia le biblioteche di libri prodotti dall'umanità. Tutto ciò che serve è una grande potenza di calcolo e dati per addestrare un LLM. E questo è esattamente ciò che ha fatto OpenAI, l'azienda dietro la famosa applicazione ChatGPT che era alimentata da diversi LLM proprietari, tra cui GPT-4o.</p>
<p>Al momento in cui scriviamo, i dettagli dell'implementazione dei LLMs di OpenAI rimangono un segreto commerciale. Sebbene molti ricercatori abbiano una conoscenza generale dei metodi di OpenAI, non è detto che abbiano le risorse per replicarli. Tuttavia, da allora sono state rilasciate diverse alternative open source per la ricerca e l'uso commerciale, tra cui Llama (Facebook), Gemma (Google), Mistral e Falcon, solo per citarne alcune.<sup><a data-type="noteref" href="ch03.html#id637" id="id637-marker" translate="no">4</a></sup>
Al momento in cui scriviamo, le dimensioni dei modelli variano da 0,05B a 480B parametri (cioè pesi e distorsioni del modello) per adattarsi alle tue esigenze.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id638">
<h1>Requisiti hardware per gli LLM Open Source</h1>
<p><a data-primary="large language models (LLMs)" data-secondary="hardware requirements for open source LLMs" data-type="indexterm" id="id639"/><a data-primary="Snowflake Arctic LLM" data-type="indexterm" id="id640"/>Il più grande LLM open source al momento in cui scriviamo è il multilingue <a href="https://oreil.ly/DLukR"><em>Snowflake Arctic</em></a> da 480B parametri.<a data-primary="video random access memory (VRAM)" data-type="indexterm" id="id641"/>L'hardware consigliato per eseguire questo enorme modello è una singola istanza AWS/Azure 8xH100, che contiene otto schede GPU per data center H100, ciascuna delle quali fornisce 80 GB di VRAM. Anche altri LLM open di punta, come il multilingue Llama 3.1 da 405B parametri, richiedono un<span class="keep-together">hardware</span> simile.</p>
<p>A partire da gennaio 2024, una delle migliori schede GPU di fascia consumer che si possono acquistare per i carichi di lavoro AI è la NVIDIA 4090 RTX, che viene fornita con soli 24 GB di VRAM. Una singola GPU consumer come la 4090 RTX potrebbe non essere in grado di eseguire modelli di dimensioni superiori a 30B a causa dei limiti di memoria, a meno che il modello non venga quantizzato (cioè compresso).</p>
<p>Se vuoi eseguire un modello quantizzato di 70B-Llama, potresti aver bisogno di una <a href="https://oreil.ly/dJbKa">GPU con 64 GB di VRAM o di più schede più piccole</a>. A parte i problemi di alimentazione e raffreddamento legati all'installazione di un server domestico multi-GPU, potresti comunque riscontrare tassi di predizione lenti quando esegui modelli di queste dimensioni.</p>
<p>Scoprirai di più sul processo di quantizzazione e sull'utilizzo degli LLMs quantizzati nel <a data-type="xref" href="ch10.html#ch10">Capitolo 10</a>.</p>
</div></aside>
<p>Il servizio di LLM rimane una sfida a causa degli elevati requisiti di memoria, che raddoppiano se devi addestrarli e metterli a punto sul tuo set di dati. Questo perché il processo di addestramento richiede la memorizzazione nella cache e il riutilizzo dei parametri del modello tra i vari lotti di addestramento. Di conseguenza, la maggior parte delle organizzazioni può affidarsi a modelli leggeri (fino a 3B) o alle API di fornitori di LLMs come OpenAI, Anthropic, Cohere, Mistral, ecc.</p>
<p>Con l'aumento della popolarità degli LLMs, diventa ancora più importante capire come vengono addestrati e come elaborano i dati, quindi parliamo dei meccanismi sottostanti.<a data-startref="ix_ch03-asciidoc6" data-type="indexterm" id="id642"/><a data-startref="ix_ch03-asciidoc5" data-type="indexterm" id="id643"/><a data-startref="ix_ch03-asciidoc4" data-type="indexterm" id="id644"/><a data-startref="ix_ch03-asciidoc3" data-type="indexterm" id="id645"/></p>
</div></section>
<section data-pdf-bookmark="Tokenization and embedding" data-type="sect3"><div class="sect3" id="id42">
<h3>Tokenizzazione e incorporazione</h3>
<p><a data-primary="language models" data-secondary="tokenization and embedding" data-type="indexterm" id="ix_ch03-asciidoc7"/><a data-primary="serving GenAI models" data-secondary="language models" data-tertiary="tokenization and embedding" data-type="indexterm" id="ix_ch03-asciidoc8"/><a data-primary="tokenization" data-type="indexterm" id="ix_ch03-asciidoc9"/>Le reti neurali non possono elaborare direttamente le parole perché sono grandi modelli statistici che funzionano con i numeri. Per colmare il divario tra linguaggio e numeri, è necessario ricorrere alla <em>tokenizzazione</em>. Con la tokenizzazione, si scompone il testo in pezzi più piccoli che un modello può elaborare.</p>
<p>Qualsiasi testo deve essere innanzitutto suddiviso in un elenco di <em>token</em> che rappresentano parole, sillabe, simboli e punteggiature. Questi token vengono poi mappati in numeri unici in modo da poter modellare numericamente i modelli.</p>
<p>Fornendo un vettore di token in ingresso a un trasformatore addestrato, la rete può prevedere il token successivo migliore per generare il testo, una parola alla volta.</p>
<p>La<a data-type="xref" href="#openai_tokenizer">Figura 3-5</a> mostra come il tokenizer di OpenAI converte il testo in una sequenza di token, assegnando a ciascuno di essi degli identificatori unici.</p>
<figure><div class="figure" id="openai_tokenizer">
<img alt="bgai 0305" src="assets/bgai_0305.png" width="1178" height="651"/>
<h6><span class="label">Figura 3-5. </span>Tokenizer di OpenAI (Fonte: <a href="https://oreil.ly/S-a9M">OpenAI</a>)</h6>
</div></figure>
<p class="less_space pagebreak-before">Quindi, cosa si può fare dopo aver tokenizzato un testo? Questi token devono essere elaborati ulteriormente prima che un modello linguistico possa elaborarli.</p>
<p><a data-primary="embeddings" data-type="indexterm" id="id646"/>Dopo la tokenizzazione, è necessario utilizzare un <em>embedder</em><sup><a data-type="noteref" href="ch03.html#id647" id="id647-marker" translate="no">5</a></sup> per convertire questi token in vettori densi di numeri reali chiamati <em>embeddings</em>, che catturano le informazioni semantiche (cioè il significato di ogni token) in uno spazio vettoriale continuo. La<a data-type="xref" href="#embeddings">Figura 3-6</a> mostra questi embeddings.</p>
<figure><div class="figure" id="embeddings">
<img alt="bgai 0306" src="assets/bgai_0306.png" width="772" height="412"/>
<h6><span class="label">Figura 3-6. </span>Assegnazione di un vettore di incorporamento di dimensione<span class="plain">n</span> a ciascun token durante il processo di<span class="keep-together">incorporamento</span> </h6>
</div></figure>
<div data-type="tip"><h6>Suggerimento</h6>
<p>Questi vettori di incorporamento utilizzano piccoli <em>numeri in virgola mobile</em> (non numeri interi) per catturare le relazioni sfumate tra i token con maggiore flessibilità e precisione. Inoltre, tendono a essere <em>distribuiti normalmente</em>, quindi l'addestramento e l'inferenza del modello linguistico possono essere più stabili e coerenti.</p>
</div>
<p>Dopo il processo di embedding, a ogni token viene assegnato un vettore di embedding composto da <em>n</em> numeri. Ogni numero del vettore di embedding si concentra su una dimensione che rappresenta un aspetto specifico del significato del token.<a data-startref="ix_ch03-asciidoc9" data-type="indexterm" id="id648"/><a data-startref="ix_ch03-asciidoc8" data-type="indexterm" id="id649"/><a data-startref="ix_ch03-asciidoc7" data-type="indexterm" id="id650"/></p>
</div></section>
<section data-pdf-bookmark="Training transformers" data-type="sect3"><div class="sect3" id="id43">
<h3>Trasformatori di formazione</h3>
<p><a data-primary="language models" data-secondary="training transformers" data-type="indexterm" id="ix_ch03-asciidoc10"/><a data-primary="serving GenAI models" data-secondary="language models" data-tertiary="training transformers" data-type="indexterm" id="ix_ch03-asciidoc11"/><a data-primary="transformers" data-secondary="training" data-type="indexterm" id="ix_ch03-asciidoc12"/>Una volta ottenuta una serie di vettori di incorporamento, puoi addestrare un modello sui tuoi documenti per aggiornare i valori all'interno di ciascun incorporamento. Durante l'addestramento del modello, l'algoritmo di addestramento aggiorna i parametri degli strati di incorporamento in modo che i vettori di incorporamento descrivano il significato di ciascun token il più possibile all'interno del testo in ingresso.</p>
<p class="less_space pagebreak-before">Capire come funzionano i vettori di incorporamento può essere difficile, quindi proviamo un approccio di visualizzazione.</p>
<p>Immagina di utilizzare vettori di incorporamento bidimensionali, cioè contenenti solo due numeri. Se tracci questi vettori, prima e dopo l'addestramento del modello, osserverai dei grafici simili a quelli della <a data-type="xref" href="#untrained_to_trained_transformer">Figura 3-7</a>. I vettori di incorporamento di token, o parole, con significati simili saranno più vicini tra loro.</p>
<figure><div class="figure" id="untrained_to_trained_transformer">
<img alt="bgai 0307" src="assets/bgai_0307.png" width="1099" height="691"/>
<h6><span class="label">Figura 3-7. </span>Spazio latente di addestramento della rete di trasformatori utilizzando i vettori di incorporazione</h6>
</div></figure>
<p><a data-primary="cosine similarity" data-type="indexterm" id="id651"/>Per determinare la somiglianza tra due parole, puoi calcolare l'angolo tra i vettori utilizzando un calcolo noto come <em>somiglianza del coseno</em>. Angoli più piccoli implicano una maggiore somiglianza, che rappresenta un contesto e un significato simili. Dopo l'addestramento, il calcolo della somiglianza del coseno di due vettori di incorporamento con significati simili convaliderà che questi vettori sono vicini tra loro.</p>
<p>La<a data-type="xref" href="#embedding_vectors">Figura 3-8</a> illustra l'intero processo di tokenizzazione, incorporazione e formazione.</p>
<figure><div class="figure" id="embedding_vectors">
<img alt="bgai 0308" src="assets/bgai_0308.png" width="1415" height="1082"/>
<h6><span class="label">Figura 3-8. </span>Elaborazione di dati sequenziali come un testo in un vettore di token e di incorporazioni di token</h6>
</div></figure>
<p>Una volta ottenuto un livello di incorporazione addestrato, puoi utilizzarlo per incorporare qualsiasi nuovo testo in ingresso nel modello di trasformatore mostrato nella <a data-type="xref" href="#transformer_architecture">Figura 3-1</a>.<a data-startref="ix_ch03-asciidoc12" data-type="indexterm" id="id652"/><a data-startref="ix_ch03-asciidoc11" data-type="indexterm" id="id653"/><a data-startref="ix_ch03-asciidoc10" data-type="indexterm" id="id654"/></p>
</div></section>
<section data-pdf-bookmark="Positional encoding" data-type="sect3"><div class="sect3" id="id44">
<h3>Codifica posizionale</h3>
<p><a data-primary="language models" data-secondary="positional encoding" data-type="indexterm" id="id655"/><a data-primary="positional encoding" data-type="indexterm" id="id656"/><a data-primary="serving GenAI models" data-secondary="language models" data-tertiary="positional encoding" data-type="indexterm" id="id657"/>Un'ultima fase prima di inoltrare i vettori di incorporamento agli strati di attenzione della rete di trasformazione consiste nell'implementare la <em>codifica posizionale</em>. Il processo di codifica posizionale produce i vettori di incorporamento posizionale che vengono poi sommati ai vettori di incorporamento dei token.</p>
<p>Poiché i trasformatori elaborano le parole simultaneamente anziché in sequenza, sono necessari embedding posizionali per registrare l'ordine delle parole e il contesto all'interno dei dati sequenziali, come le frasi. I vettori embedding risultanti catturano sia il significato che le informazioni posizionali delle parole nelle frasi prima di passarle ai meccanismi di attenzione del trasformatore. Questo processo assicura che le teste di attenzione abbiano tutte le informazioni necessarie per apprendere efficacemente i modelli.</p>
<p class="less_space pagebreak-before">La<a data-type="xref" href="#positional_encoding">Figura 3-9</a> mostra il processo di codifica posizionale in cui le incorporazioni posizionali vengono sommate alle incorporazioni dei token.</p>
<figure><div class="figure" id="positional_encoding">
<img alt="bgai 0309" src="assets/bgai_0309.png" width="1435" height="1055"/>
<h6><span class="label">Figura 3-9. </span>Codifica posizionale</h6>
</div></figure>
</div></section>
<section data-pdf-bookmark="Autoregressive prediction" data-type="sect3"><div class="sect3" id="id45">
<h3>Previsione autoregressiva</h3>
<p><a data-primary="autoregressive prediction" data-type="indexterm" id="ix_ch03-asciidoc13"/><a data-primary="language models" data-secondary="autoregressive prediction" data-type="indexterm" id="ix_ch03-asciidoc14"/><a data-primary="serving GenAI models" data-secondary="language models" data-tertiary="autoregressive prediction" data-type="indexterm" id="ix_ch03-asciidoc15"/><a data-primary="tokens" data-secondary="autoregressive prediction and" data-type="indexterm" id="ix_ch03-asciidoc16"/>Il trasformatore è un modello autoregressivo (cioè sequenziale), in quanto le previsioni future si basano sui valori passati, come mostrato nella <a data-type="xref" href="#autoregressive_prediction3">Figura 3-10</a>.</p>
<figure><div class="figure" id="autoregressive_prediction3">
<img alt="bgai 0310" src="assets/bgai_0310.png" width="721" height="221"/>
<h6><span class="label">Figura 3-10. </span>Previsione autoregressiva</h6>
</div></figure>
<p>Il modello riceve dei token in ingresso che vengono poi incorporati e passati attraverso la rete per fare la migliore previsione del token successivo. Questo processo si ripete fino a quando non viene generato un token <code translate="no">&lt;stop&gt;</code> o di fine frase <code translate="no">&lt;eos&gt;</code>.<sup><a data-type="noteref" href="ch03.html#id658" id="id658-marker" translate="no">6</a></sup></p>
<p>Tuttavia, c'è un limite al numero di token che il modello può immagazzinare nella sua memoria per generare il token successivo.<a data-primary="context window" data-type="indexterm" id="id659"/>Questo limite di token è indicato come la <em>finestra di contesto</em> del modello, un fattore importante da considerare durante la fase di selezione del modello per i tuoi servizi GenAI.</p>
<p>Se il limite della finestra di contesto viene raggiunto, il modello scarta semplicemente i token utilizzati più di recente, il che significa che può <em>dimenticare</em> le frasi utilizzate più di recente nei documenti o nei messaggi di una conversazione.</p>
<div data-type="note" epub:type="note"><h6>Nota</h6>
<p>Al momento in cui scriviamo, il contesto del modello OpenAI <code translate="no">gpt-4o-mini</code> meno costoso è di circa 128.000 tokens, equivalenti a più di 300 pagine di testo.</p>
<p>La finestra di contesto più grande a marzo 2025 appartiene a <a href="https://oreil.ly/10Mj1">Magic.Dev LTM-2-mini</a> con 100 milioni di gettoni. Ciò equivale a ~10 milioni di righe di codice di ~750 romanzi.</p>
<p>La finestra di contesto di altri modelli si aggira intorno alle centinaia di migliaia di gettoni.</p>
</div>
<p>Finestre brevi comportano la perdita di informazioni, la difficoltà di mantenere le conversazioni e una minore coerenza con la query dell'utente.</p>
<p>D'altro canto, le finestre di contesto più lunghe hanno requisiti di memoria più elevati e possono causare problemi di prestazioni o rallentamenti dei servizi quando si scalano a migliaia di utenti contemporanei che utilizzano il tuo servizio. Inoltre, dovrai considerare i costi di affidarti a modelli con finestre di contesto più ampie, in quanto tendono ad essere più costosi a causa dei maggiori requisiti di calcolo e di memoria. La scelta corretta dipenderà dal tuo budget e dalle esigenze degli utenti nel tuo caso d'uso.<a data-startref="ix_ch03-asciidoc16" data-type="indexterm" id="id660"/><a data-startref="ix_ch03-asciidoc15" data-type="indexterm" id="id661"/><a data-startref="ix_ch03-asciidoc14" data-type="indexterm" id="id662"/><a data-startref="ix_ch03-asciidoc13" data-type="indexterm" id="id663"/></p>
</div></section>
<section data-pdf-bookmark="Integrating a language model into your application" data-type="sect3"><div class="sect3" id="id46">
<h3>Integrare un modello linguistico nella tua applicazione</h3>
<p><a data-primary="language models" data-secondary="integrating a model into an application" data-type="indexterm" id="ix_ch03-asciidoc17"/><a data-primary="serving GenAI models" data-secondary="language models" data-tertiary="integrating a model into an application" data-type="indexterm" id="ix_ch03-asciidoc18"/>Puoi scaricare e utilizzare un modello linguistico all'interno della tua applicazione con poche righe di codice.<a data-primary="small language model (SLM)" data-type="indexterm" id="ix_ch03-asciidoc19a"/><a data-primary="TinyLlama" data-type="indexterm" id="ix_ch03-asciidoc19"/>Nell'<a data-type="xref" href="#language_model_usage_example">Esempio 3-1</a>, scaricherai un modello TinyLlama con 1,1 miliardi di parametri e preaddestrato su 3 trilioni di token.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id664">
<h1>Installazione delle dipendenze di TinyLlama</h1>
<p>Per integrare TinyLlama nella tua applicazione, puoi utilizzare la libreria Hugging Face <code translate="no">transformers</code>.<sup><a data-type="noteref" href="ch03.html#id665" id="id665-marker" translate="no">7</a></sup>
Dovrai inoltre installare il framework di deep learning PyTorch installando il pacchetto <code translate="no">torch</code>. Entrambi i pacchetti possono essere installati tramite <code translate="no">pip</code>.</p>
<p>Su Windows, dovrai fornire il flag <code translate="no">--index-url</code> a <code translate="no">pip</code> quando installi <code translate="no">torch</code> compilato per una GPU CUDA.<sup><a data-type="noteref" href="ch03.html#id666" id="id666-marker" translate="no">8</a></sup></p>
<pre data-code-language="bash" data-type="programlisting" translate="no"><code class="c1" translate="no"># Install `torch` with CUDA 12.4 and `transformers` packages for Windows.</code>

$<code class="w" translate="no"> </code>pip<code class="w" translate="no"> </code>install<code class="w" translate="no"> </code>transformers<code class="w" translate="no"> </code>torch<code class="w" translate="no"> </code><code class="se" translate="no">\</code>
<code class="w" translate="no">  </code>--index-url<code class="w" translate="no"> </code>https://download.pytorch.org/whl/cu124<code class="w" translate="no"/></pre>
<p>TinyLlama non può generare più di un paio di frasi alla volta. Avrai inoltre bisogno di circa 3 GB di spazio su disco e di RAM per caricare il modello in memoria per l'inferenza. Ti consiglio di eseguire il modello su una GPU NVIDIA abilitata a CUDA (con la ruota <code translate="no">torch</code> compilata per CUDA) poiché l'inferenza su CPU può essere lenta. Consulta le istruzioni di installazione di NVIDIA CUDA per <a href="https://oreil.ly/LeA1O">Windows</a> o <a href="https://oreil.ly/qjNaO">Linux</a>.</p>
<p>Inoltre, per eseguire l'<a data-type="xref" href="#language_model_usage_example">Esempio 3-1</a> su Windows, potrebbe essere necessario installare Visual Studio Build Tools 2022 con gli strumenti di sviluppo C++ e .NET per risolvere i problemi di librerie DLL e dipendenze mancanti.</p>
</div></aside>
<div data-type="example" id="language_model_usage_example">
<h5><span class="label">Esempio 3-1. </span>Scaricare e caricare un modello linguistico dal repository di Hugging Face</h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># models.py</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="nn" translate="no">torch</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">transformers</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">Pipeline</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">pipeline</code><code translate="no">
</code><code translate="no">
</code><code class="n" translate="no">prompt</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">How to set up a FastAPI project?</code><code class="s2" translate="no">"</code><code translate="no">
</code><code class="n" translate="no">system_prompt</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="s2" translate="no">"""</code><code class="s2" translate="no">
</code><code class="s2" translate="no">Your name is FastAPI bot and you are a helpful</code><code class="s2" translate="no">
</code><code class="s2" translate="no">chatbot responsible for teaching FastAPI to your users.</code><code class="s2" translate="no">
</code><code class="s2" translate="no">Always respond in markdown.</code><code class="s2" translate="no">
</code><code class="s2" translate="no">"""</code><code translate="no">
</code><code translate="no">
</code><code class="n" translate="no">device</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">torch</code><code class="o" translate="no">.</code><code class="n" translate="no">device</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">cuda</code><code class="s2" translate="no">"</code><code translate="no"> </code><code class="k" translate="no">if</code><code translate="no"> </code><code class="n" translate="no">torch</code><code class="o" translate="no">.</code><code class="n" translate="no">cuda</code><code class="o" translate="no">.</code><code class="n" translate="no">is_available</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="k" translate="no">else</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">cpu</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO1-1" id="co_ai_integration_and_model_serving_CO1-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">load_text_model</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">pipe</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">pipeline</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">        </code><code class="s2" translate="no">"</code><code class="s2" translate="no">text-generation</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">model</code><code class="o" translate="no">=</code><code class="s2" translate="no">"</code><code class="s2" translate="no">TinyLlama/TinyLlama-1.1B-Chat-v1.0</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO1-2" id="co_ai_integration_and_model_serving_CO1-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">torch_dtype</code><code class="o" translate="no">=</code><code class="n" translate="no">torch</code><code class="o" translate="no">.</code><code class="n" translate="no">bfloat16</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">device</code><code class="o" translate="no">=</code><code class="n" translate="no">device</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO1-3" id="co_ai_integration_and_model_serving_CO1-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">pipe</code><code translate="no">
</code><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">generate_text</code><code class="p" translate="no">(</code><code class="n" translate="no">pipe</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">Pipeline</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">prompt</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">str</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">temperature</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">float</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="mf" translate="no">0.7</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">-</code><code class="o" translate="no">&gt;</code><code translate="no"> </code><code class="nb" translate="no">str</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">messages</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="p" translate="no">[</code><code translate="no">
</code><code translate="no">        </code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">role</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">system</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">content</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">system_prompt</code><code class="p" translate="no">}</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">        </code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">role</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">user</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">content</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">prompt</code><code class="p" translate="no">}</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">    </code><code class="p" translate="no">]</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO1-4" id="co_ai_integration_and_model_serving_CO1-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">prompt</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">pipe</code><code class="o" translate="no">.</code><code class="n" translate="no">tokenizer</code><code class="o" translate="no">.</code><code class="n" translate="no">apply_chat_template</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">messages</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">tokenize</code><code class="o" translate="no">=</code><code class="kc" translate="no">False</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">add_generation_prompt</code><code class="o" translate="no">=</code><code class="kc" translate="no">True</code><code translate="no">
</code><code translate="no">    </code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO1-5" id="co_ai_integration_and_model_serving_CO1-5"><img alt="5" src="assets/5.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">predictions</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">pipe</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">prompt</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">temperature</code><code class="o" translate="no">=</code><code class="n" translate="no">temperature</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">max_new_tokens</code><code class="o" translate="no">=</code><code class="mi" translate="no">256</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">do_sample</code><code class="o" translate="no">=</code><code class="kc" translate="no">True</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">top_k</code><code class="o" translate="no">=</code><code class="mi" translate="no">50</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">top_p</code><code class="o" translate="no">=</code><code class="mf" translate="no">0.95</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">    </code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO1-6" id="co_ai_integration_and_model_serving_CO1-6"><img alt="6" src="assets/6.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">output</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">predictions</code><code class="p" translate="no">[</code><code class="mi" translate="no">0</code><code class="p" translate="no">]</code><code class="p" translate="no">[</code><code class="s2" translate="no">"</code><code class="s2" translate="no">generated_text</code><code class="s2" translate="no">"</code><code class="p" translate="no">]</code><code class="o" translate="no">.</code><code class="n" translate="no">split</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">&lt;/s&gt;</code><code class="se" translate="no">\n</code><code class="s2" translate="no">&lt;|assistant|&gt;</code><code class="se" translate="no">\n</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code class="p" translate="no">[</code><code class="o" translate="no">-</code><code class="mi" translate="no">1</code><code class="p" translate="no">]</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO1-7" id="co_ai_integration_and_model_serving_CO1-7"><img alt="7" src="assets/7.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">output</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO1-1" id="callout_ai_integration_and_model_serving_CO1-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Controlla se è disponibile una GPU NVIDIA e, in caso affermativo, imposta <code translate="no">device</code> sulla GPU corrente abilitata a CUDA. Altrimenti, continua a usare la CPU.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO1-2" id="callout_ai_integration_and_model_serving_CO1-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a></dt>
<dd><p>Scarica e carica in memoria il modello TinyLlama con un tipo di dati di precisione tensoriale <code translate="no">float16</code>.<sup><a data-type="noteref" href="ch03.html#id667" id="id667-marker" translate="no">9</a></sup></p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO1-3" id="callout_ai_integration_and_model_serving_CO1-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a></dt>
<dd><p>Sposta l'intera pipeline sulla GPU al primo caricamento.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO1-4" id="callout_ai_integration_and_model_serving_CO1-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a></dt>
<dd><p>Prepara l'elenco dei messaggi, che consiste in dizionari con coppie chiave-valore di ruolo e contenuto. L'ordine dei dizionari detta l'ordine dei messaggi da quelli più vecchi a quelli più recenti in una conversazione. Il primo messaggio è spesso un prompt del sistema per guidare l'output del modello in una conversazione.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO1-5" id="callout_ai_integration_and_model_serving_CO1-5"><img alt="5" src="assets/5.png" width="12" height="12"/></a></dt>
<dd><p>Convertire l'elenco dei messaggi di chat in un elenco di token interi per il modello. Al modello viene quindi chiesto di generare un output in formato testuale, non in token interi <code translate="no">tokenize=False</code>. Viene anche aggiunto un prompt di generazione alla fine dei messaggi di chat (<code translate="no">add_generation_prompt=True</code>) in modo che il modello sia incoraggiato a generare una risposta basata sulla cronologia della chat.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO1-6" id="callout_ai_integration_and_model_serving_CO1-6"><img alt="6" src="assets/6.png" width="12" height="12"/></a></dt>
<dd><p>Il prompt preparato viene passato al modello con diversi parametri di inferenza per ottimizzare le prestazioni di generazione del testo. Alcuni di questi parametri di inferenza chiave includono:</p>
<ul>
<li>
<p><code translate="no">max_new_tokens</code>: Specifica il numero massimo di nuovi token da generare nell'output.</p>
</li>
<li>
<p><code translate="no">do_sample</code>: Determina, quando produce l'output, se scegliere un token in modo casuale da un elenco di token adatti (<code translate="no">True</code>) o se scegliere semplicemente il token più probabile a ogni passo (<code translate="no">False</code>).</p>
</li>
<li>
<p><code translate="no">temperature</code>: I valori più bassi rendono i risultati del modello più precisi, mentre quelli più alti consentono risposte più creative.</p>
</li>
<li>
<p><code translate="no">top_k</code>: Limita le previsioni dei token del modello alle prime K opzioni.<code translate="no">top_k=50</code> significa creare un elenco dei 50 token più adatti da scegliere nella fase di previsione dei token corrente.</p>
</li>
<li>
<p><code translate="no">top_p</code>: Implementa il <em>campionamento dei nuclei</em> quando si crea un elenco dei token più adatti.<code translate="no">top_p=0.95</code> significa creare un elenco dei token migliori fino a quando non si è soddisfatti che l'elenco contenga il 95% dei token più adatti da cui scegliere, per la fase di previsione dei token corrente.</p>
</li>
</ul></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO1-7" id="callout_ai_integration_and_model_serving_CO1-7"><img alt="7" src="assets/7.png" width="12" height="12"/></a></dt>
<dd><p>L'output finale è ottenuto dall'oggetto <code translate="no">predictions</code>. Il testo generato da TinyLlama include l'intera cronologia della conversazione, con la risposta generata aggiunta alla fine. Il token di stop <code translate="no">&lt;/s&gt;</code> seguito dai token <code translate="no">\n&lt;|assistant|&gt;\n</code> sono utilizzati per selezionare il contenuto dell'ultimo messaggio della conversazione, che è la risposta del modello.</p></dd>
</dl></div>
<p>L<a data-type="xref" href="#language_model_usage_example">'esempio 3-1</a> è un buon punto di partenza; puoi caricare questo modello sulla tua CPU e ottenere risposte in tempi ragionevoli. Tuttavia, TinyLlama potrebbe non avere le stesse prestazioni delle sue controparti più grandi. Per i carichi di lavoro di produzione, vorrai utilizzare modelli più grandi per ottenere una migliore qualità e prestazioni.</p>
<p>A questo punto puoi utilizzare le funzioni <code translate="no">load_model</code> e <code translate="no">predict</code> all'interno di una funzione del controller<sup><a data-type="noteref" href="ch03.html#id668" id="id668-marker" translate="no">10</a></sup> e poi aggiungere un decoratore di gestione delle rotte per servire il modello tramite un endpoint, come mostrato nell'<a data-type="xref" href="#text_endpoint">Esempio 3-2</a>.</p>
<div data-type="example" id="text_endpoint">
<h5><span class="label">Esempio 3-2. </span>Servire un modello linguistico tramite un endpoint FastAPI</h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># main.py</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">fastapi</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">FastAPI</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">models</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">load_text_model</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">generate_text</code><code translate="no">
</code><code translate="no">
</code><code class="n" translate="no">app</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">FastAPI</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">
</code><code class="nd" translate="no">@app</code><code class="o" translate="no">.</code><code class="n" translate="no">get</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">/generate/text</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO2-1" id="co_ai_integration_and_model_serving_CO2-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">serve_language_model_controller</code><code class="p" translate="no">(</code><code class="n" translate="no">prompt</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">str</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">-</code><code class="o" translate="no">&gt;</code><code translate="no"> </code><code class="nb" translate="no">str</code><code class="p" translate="no">:</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO2-2" id="co_ai_integration_and_model_serving_CO2-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">pipe</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">load_text_model</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO2-3" id="co_ai_integration_and_model_serving_CO2-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">output</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">generate_text</code><code class="p" translate="no">(</code><code class="n" translate="no">pipe</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">prompt</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO2-4" id="co_ai_integration_and_model_serving_CO2-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">output</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO2-5" id="co_ai_integration_and_model_serving_CO2-5"><img alt="5" src="assets/5.png" width="12" height="12"/></a></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO2-1" id="callout_ai_integration_and_model_serving_CO2-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Crea un server FastAPI e aggiungi un gestore di rotte <code translate="no">/generate</code> per servire il modello.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO2-2" id="callout_ai_integration_and_model_serving_CO2-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a></dt>
<dd><p>Il sito <code translate="no">serve_language_model_controller</code> è responsabile di prendere il prompt dai parametri della query di richiesta.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO2-3" id="callout_ai_integration_and_model_serving_CO2-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a></dt>
<dd><p>Il modello viene caricato in memoria.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO2-4" id="callout_ai_integration_and_model_serving_CO2-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a></dt>
<dd><p>Il controllore passa la query al modello per eseguire la previsione.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO2-5" id="callout_ai_integration_and_model_serving_CO2-5"><img alt="5" src="assets/5.png" width="12" height="12"/></a></dt>
<dd><p>Il server FastAPI invia l'output come risposta HTTP al client.</p></dd>
</dl></div>
<p>Una volta che il servizio FastAPI è attivo e funzionante, puoi visitare la pagina di documentazione Swagger all'indirizzo <code translate="no">http://localhost:8000/docs</code>per testare il tuo nuovo endpoint:</p>
<pre data-type="programlisting" translate="no">http://localhost:8000/generate/text?prompt="What is FastAPI?"</pre>
<p>Se stai eseguendo gli esempi di codice su una CPU, ci vorrà circa un minuto per ricevere una risposta dal modello, come mostrato nella <a data-type="xref" href="#text_gen_response">Figura 3-11</a>.</p>
<figure><div class="figure" id="text_gen_response">
<img alt="bgai 0311" src="assets/bgai_0311.png" width="1372" height="460"/>
<h6><span class="label">Figura 3-11. </span>Risposta di TinyLlama</h6>
</div></figure>
<p><a data-primary="hallucinations" data-type="indexterm" id="id669"/>Non è una cattiva risposta per un piccolo modello di linguaggio (SLM) che gira su una CPU del tuo computer, se non fosse che TinyLlama ha avuto <em>l'allucinazione</em> di credere che FastAPI utilizzi Flask. Si tratta di un'affermazione errata: FastAPI utilizza Starlette come framework web sottostante, non Flask.</p>
<p>Le<em>allucinazioni</em> si riferiscono a risultati che non sono basati sui dati di addestramento o sulla realtà. Anche se SLM open source come TinyLlama sono stati addestrati su un numero impressionante di token (3 trilioni), un numero ridotto di parametri del modello può aver limitato la loro capacità di apprendere la verità di base nei dati.<a data-startref="ix_ch03-asciidoc19" data-type="indexterm" id="id670"/><a data-startref="ix_ch03-asciidoc19a" data-type="indexterm" id="id671"/>Inoltre, potrebbero essere stati utilizzati anche dati di addestramento non filtrati, che possono contribuire ad aumentare i casi di allucinazioni.</p>
<div data-type="warning" epub:type="warning"><h6>Avvertenze</h6>
<p>Quando utilizzi i modelli linguistici, informa sempre i tuoi utenti di controllare i risultati con fonti esterne, perché i modelli linguistici potrebbero avere delle <em>allucinazioni</em> e produrre affermazioni errate.</p>
</div>
<p>Ora puoi utilizzare un client per browser web in Python per testare visivamente il tuo servizio con maggiore interattività rispetto all'utilizzo di un client a riga di comando.</p>
<p>Un ottimo pacchetto Python per sviluppare rapidamente un'interfaccia utente è <a href="https://oreil.ly/9BXmn">Streamlit</a>, che ti permette di creare UI belle e personalizzabili per i tuoi servizi di AI con poco sforzo.<a data-startref="ix_ch03-asciidoc18" data-type="indexterm" id="id672"/><a data-startref="ix_ch03-asciidoc17" data-type="indexterm" id="id673"/></p>
</div></section>
<section data-pdf-bookmark="Connecting FastAPI with Streamlit UI generator" data-type="sect3"><div class="sect3" id="id47">
<h3>Connettere FastAPI con il generatore di UI Streamlit</h3>
<p><a data-primary="language models" data-secondary="connecting FastAPI with Streamlit UI generator" data-type="indexterm" id="ix_ch03-asciidoc20"/><a data-primary="serving GenAI models" data-secondary="language models" data-tertiary="connecting FastAPI with Streamlit UI generator" data-type="indexterm" id="ix_ch03-asciidoc21"/><a data-primary="Streamlit UI generator" data-type="indexterm" id="ix_ch03-asciidoc22"/>Streamlit ti permette di creare facilmente un'interfaccia utente di chat per il test e la prototipazione di modelli. Puoi installare il pacchetto <code translate="no">streamlit</code> utilizzando <code translate="no">pip</code>:</p>
<pre data-code-language="bash" data-type="programlisting" translate="no">$<code class="w" translate="no"> </code>pip<code class="w" translate="no"> </code>install<code class="w" translate="no"> </code>streamlit<code class="w" translate="no"/></pre>
<p>L<a data-type="xref" href="#streamlit_chat_ui">'esempio 3-3</a> mostra come sviluppare una semplice interfaccia utente per connettersi al servizio.</p>
<div data-type="example" id="streamlit_chat_ui">
<h5><span class="label">Esempio 3-3. </span>L'interfaccia utente della chat di Streamlit che utilizza l'endpoint FastAPI /<code translate="no">generate</code> </h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># client.py</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="nn" translate="no">requests</code><code translate="no">
</code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="nn" translate="no">streamlit</code><code translate="no"> </code><code class="k" translate="no">as</code><code translate="no"> </code><code class="nn" translate="no">st</code><code translate="no">
</code><code translate="no">
</code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">title</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">FastAPI ChatBot</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO3-1" id="co_ai_integration_and_model_serving_CO3-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">if</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">messages</code><code class="s2" translate="no">"</code><code translate="no"> </code><code class="ow" translate="no">not</code><code translate="no"> </code><code class="ow" translate="no">in</code><code translate="no"> </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">session_state</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">session_state</code><code class="o" translate="no">.</code><code class="n" translate="no">messages</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="p" translate="no">[</code><code class="p" translate="no">]</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO3-2" id="co_ai_integration_and_model_serving_CO3-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">for</code><code translate="no"> </code><code class="n" translate="no">message</code><code translate="no"> </code><code class="ow" translate="no">in</code><code translate="no"> </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">session_state</code><code class="o" translate="no">.</code><code class="n" translate="no">messages</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">with</code><code translate="no"> </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">chat_message</code><code class="p" translate="no">(</code><code class="n" translate="no">message</code><code class="p" translate="no">[</code><code class="s2" translate="no">"</code><code class="s2" translate="no">role</code><code class="s2" translate="no">"</code><code class="p" translate="no">]</code><code class="p" translate="no">)</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">markdown</code><code class="p" translate="no">(</code><code class="n" translate="no">message</code><code class="p" translate="no">[</code><code class="s2" translate="no">"</code><code class="s2" translate="no">content</code><code class="s2" translate="no">"</code><code class="p" translate="no">]</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO3-3" id="co_ai_integration_and_model_serving_CO3-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">if</code><code translate="no"> </code><code class="n" translate="no">prompt</code><code translate="no"> </code><code class="o" translate="no">:=</code><code translate="no"> </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">chat_input</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">Write your prompt in this input field</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code class="p" translate="no">:</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO3-4" id="co_ai_integration_and_model_serving_CO3-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">session_state</code><code class="o" translate="no">.</code><code class="n" translate="no">messages</code><code class="o" translate="no">.</code><code class="n" translate="no">append</code><code class="p" translate="no">(</code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">role</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">user</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">content</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">prompt</code><code class="p" translate="no">}</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO3-5" id="co_ai_integration_and_model_serving_CO3-5"><img alt="5" src="assets/5.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">with</code><code translate="no"> </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">chat_message</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">user</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">text</code><code class="p" translate="no">(</code><code class="n" translate="no">prompt</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO3-6" id="co_ai_integration_and_model_serving_CO3-6"><img alt="6" src="assets/6.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">response</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">requests</code><code class="o" translate="no">.</code><code class="n" translate="no">get</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">        </code><code class="sa" translate="no">f</code><code class="s2" translate="no">"</code><code class="s2" translate="no">http://localhost:8000/generate/text</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">params</code><code class="o" translate="no">=</code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">prompt</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">prompt</code><code class="p" translate="no">}</code><code translate="no">
</code><code translate="no">    </code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO3-7" id="co_ai_integration_and_model_serving_CO3-7"><img alt="7" src="assets/7.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">response</code><code class="o" translate="no">.</code><code class="n" translate="no">raise_for_status</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO3-8" id="co_ai_integration_and_model_serving_CO3-8"><img alt="8" src="assets/8.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">with</code><code translate="no"> </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">chat_message</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">assistant</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">markdown</code><code class="p" translate="no">(</code><code class="n" translate="no">response</code><code class="o" translate="no">.</code><code class="n" translate="no">text</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO3-9" id="co_ai_integration_and_model_serving_CO3-9"><img alt="9" src="assets/9.png" width="12" height="12"/></a></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO3-1" id="callout_ai_integration_and_model_serving_CO3-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Aggiungi un titolo alla tua applicazione che sarà reso all'interfaccia utente.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO3-2" id="callout_ai_integration_and_model_serving_CO3-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a></dt>
<dd><p>Inizializza la chat e tiene traccia della cronologia della chat.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO3-3" id="callout_ai_integration_and_model_serving_CO3-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a></dt>
<dd><p>Visualizza i messaggi della cronologia delle chat al riavvio dell'applicazione.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO3-4" id="callout_ai_integration_and_model_serving_CO3-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a></dt>
<dd><p>Attendi che l'utente invii un prompt tramite il campo di inserimento della chat.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO3-5" id="callout_ai_integration_and_model_serving_CO3-5"><img alt="5" src="assets/5.png" width="12" height="12"/></a></dt>
<dd><p>Aggiungi i messaggi dell'utente o dell'assistente alla cronologia delle chat.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO3-6" id="callout_ai_integration_and_model_serving_CO3-6"><img alt="6" src="assets/6.png" width="12" height="12"/></a></dt>
<dd><p>Visualizza il messaggio dell'utente nel contenitore dei messaggi della chat.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO3-7" id="callout_ai_integration_and_model_serving_CO3-7"><img alt="7" src="assets/7.png" width="12" height="12"/></a></dt>
<dd><p>Invia una richiesta <code translate="no">GET</code> con il prompt come parametro di query al tuo endpoint FastAPI per generare una risposta da TinyLlama.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO3-8" id="callout_ai_integration_and_model_serving_CO3-8"><img alt="8" src="assets/8.png" width="12" height="12"/></a></dt>
<dd><p>Convalida che la risposta sia OK.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO3-9" id="callout_ai_integration_and_model_serving_CO3-9"><img alt="9" src="assets/9.png" width="12" height="12"/></a></dt>
<dd><p>Visualizza il messaggio dell'assistente nel contenitore dei messaggi della chat.</p></dd>
</dl></div>
<p>Ora puoi avviare l'applicazione client Streamlit:<sup><a data-type="noteref" href="ch03.html#id674" id="id674-marker" translate="no">11</a></sup></p>
<pre data-code-language="bash" data-type="programlisting" translate="no">$<code class="w" translate="no"> </code>streamlit<code class="w" translate="no"> </code>run<code class="w" translate="no"> </code>client.py<code class="w" translate="no"/></pre>
<p>Ora dovresti essere in grado di interagire con TinyLlama all'interno di Streamlit, come mostrato nella <a data-type="xref" href="#streamlit_ui_text_results">Figura 3-12</a>. Tutto questo è stato possibile con alcuni brevi script Python.</p>
<figure><div class="figure" id="streamlit_ui_text_results">
<img alt="bgai 0312" src="assets/bgai_0312.png" width="1996" height="1444"/>
<h6><span class="label">Figura 3-12. </span>Client Streamlit</h6>
</div></figure>
<p>La<a data-type="xref" href="#tiny_llama_fastapi_architecture">Figura 3-13</a> mostra l'architettura generale del sistema della soluzione che abbiamo sviluppato finora.</p>
<figure><div class="figure" id="tiny_llama_fastapi_architecture">
<img alt="bgai 0313" src="assets/bgai_0313.png" width="967" height="374"/>
<h6><span class="label">Figura 3-13. </span>Architettura del sistema di servizi FastAPI</h6>
</div></figure>
<div class="less_space pagebreak-before" data-type="warning" epub:type="warning"><h6>Avvertenze</h6>
<p>Sebbene la soluzione dell'<a data-type="xref" href="#streamlit_chat_ui">Esempio 3-3</a> sia ottima per la prototipazione e il test dei modelli, non è adatta per i carichi di lavoro di produzione in cui diversi utenti hanno bisogno di accedere simultaneamente al modello. Questo perché con la configurazione attuale, il modello viene caricato e scaricato in memoria ogni volta che viene elaborata una richiesta. Dover caricare e scaricare un modello di grandi dimensioni da e verso la memoria è lento e<span class="keep-together">blocca</span> l'I/O.</p>
</div>
<p>Il servizio TinyLlama che hai appena costruito utilizza un trasformatore <em>decodificatore</em>, ottimizzato per i casi d'uso delle conversazioni e delle chat. Tuttavia, il <a href="https://oreil.ly/RqztC">documento originale sui trasformatori</a> introduceva un'architettura che consisteva sia in un encoder che in un decoder.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id675">
<h1>Varianti di trasformatori</h1>
<p><a data-primary="transformers" data-secondary="variants" data-type="indexterm" id="id676"/>Ci sono tre tipi di trasformatori che devi conoscere quando lavori con i modelli linguistici, come mostra la <a data-type="xref" href="#transformer_architectures">Figura 3-14</a>.</p>
<figure><div class="figure" id="transformer_architectures">
<img alt="bgai 0314" src="assets/bgai_0314.png" width="1238" height="868"/>
<h6><span class="label">Figura 3-14. </span>Architetture di trasformatori</h6>
</div></figure>
<p>Ogni variante di trasformatore ha capacità uniche e si specializza in determinati compiti.</p>
<dl class="less_space pagebreak-before">
<dt>Trasformatori encoder-decoder</dt>
<dd>
<ul>
<li>
<p>Serve a trasformare una sequenza di informazioni in un'altra.</p>
</li>
<li>
<p>Ottimizza le attività di traduzione, riassunto di testi, domande e risposte</p>
</li>
</ul>
</dd>
<dt>Trasformatori per soli encoder</dt>
<dd>
<ul>
<li>
<p>Utilizzato per comprendere e rappresentare i significati delle sequenze di input</p>
</li>
<li>
<p>Specializzati nell'analisi del sentimento, nell'estrazione di entità e nella classificazione di testi.</p>
</li>
</ul>
</dd>
<dt>Trasformatori per soli decoder</dt>
<dd>
<ul>
<li>
<p>Utilizzato per prevedere il token successivo in una sequenza</p>
</li>
<li>
<p>Supera gli altri trasformatori nella generazione di testi, nelle attività di conversazione e di modellazione linguistica</p>
</li>
</ul>
</dd>
</dl>
<p>In pratica, devi scegliere il trasformatore più adatto al tuo caso d'uso in base alla sua specializzazione e alle sue capacità.</p>
</div></aside>
<p>A questo punto dovresti essere più sicuro di come funzionano i modelli linguistici e di come confezionarli in un server web FastAPI.<a data-startref="ix_ch03-asciidoc22" data-type="indexterm" id="id677"/><a data-startref="ix_ch03-asciidoc21" data-type="indexterm" id="id678"/><a data-startref="ix_ch03-asciidoc20" data-type="indexterm" id="id679"/></p>
<p>I modelli linguistici rappresentano solo una parte di tutti i modelli generativi. Le prossime sezioni amplieranno le tue conoscenze per includere il funzionamento e il servizio dei modelli che generano audio, immagini e video.<a data-startref="ix_ch03-asciidoc2" data-type="indexterm" id="id680"/><a data-startref="ix_ch03-asciidoc1" data-type="indexterm" id="id681"/></p>
<p>Possiamo iniziare a lavorare con i modelli audio.</p>
</div></section>
</div></section>
<section data-pdf-bookmark="Audio Models" data-type="sect2"><div class="sect2" id="id48">
<h2>Modelli audio</h2>
<p><a data-primary="serving GenAI models" data-secondary="audio models" data-type="indexterm" id="ix_ch03-asciidoc23"/>Nei servizi GenAI, i modelli audio sono importanti per la creazione di suoni interattivi e realistici. A differenza dei modelli di testo con cui hai familiarità, che si concentrano sull'elaborazione e la generazione del testo, i modelli audio possono gestire i segnali audio. Con essi puoi<span class="keep-together">sintetizzare</span> il parlato, generare musica e persino creare effetti sonori per applicazioni come gli assistenti<span class="keep-together">virtuali</span>, il doppiaggio automatico, lo sviluppo di giochi e gli<span class="keep-together">ambienti</span> audio immersivi.</p>
<p><a data-primary="Bark (Suno AI text-to-audio model)" data-type="indexterm" id="ix_ch03-asciidoc24"/><a data-primary="Suno AI" data-type="indexterm" id="ix_ch03-asciidoc25"/>Uno dei modelli text-to-speech e text-to-audio più efficaci è il modello Bark creato da Suno AI. Questo modello, basato su trasformatori, è in grado di generare un parlato e un audio multilingue realistico che include musica, rumore di fondo ed effetti sonori.</p>
<p>Il modello Bark è composto da quattro modelli concatenati tra loro come una pipeline per sintetizzare forme d'onda audio a partire da prompt testuali, come mostrato nella <a data-type="xref" href="#bark_pipeline">Figura 3-15</a>.</p>
<figure><div class="figure" id="bark_pipeline">
<img alt="bgai 0315" src="assets/bgai_0315.png" width="1436" height="769"/>
<h6><span class="label">Figura 3-15. </span>Pipeline di sintesi della corteccia</h6>
</div></figure>
<dl>
<dt>1. Modello semantico del testo</dt>
<dd>
<p>Un modello trasformatore autoregressivo causale (sequenziale) accetta un testo di input tokenizzato e ne cattura il significato tramite tokens semantici. I modelli autoregressivi predicono i valori futuri di una sequenza riutilizzando i propri output precedenti.</p>
</dd>
<dt>2. Modello acustico grossolano</dt>
<dd>
<p>Un trasformatore autoregressivo causale riceve le uscite del modello semantico e genera le caratteristiche audio iniziali, che mancano di dettagli più fini. Ogni previsione si basa sulle informazioni passate e presenti della sequenza di token semantici.</p>
</dd>
<dt>3. Modello di acustica fine</dt>
<dd>
<p>Un trasformatore autocodificatore non causale perfeziona la rappresentazione audio generando le caratteristiche audio rimanenti. Poiché il modello acustico grossolano ha generato l'intera sequenza audio, il modello fine non deve essere casuale.</p>
</dd>
<dt>4. Modello di codec audio Encodec</dt>
<dd>
<p>Il modello decodifica l'array audio in uscita da tutti i codici audio generati in precedenza.</p>
</dd>
</dl>
<p>Bark sintetizza la forma d'onda audio decodificando le caratteristiche audio raffinate nell'uscita audio finale sotto forma di parole, musica o semplici effetti audio.</p>
<p>L<a data-type="xref" href="#small_bark">'esempio 3-4</a> mostra come utilizzare il modello del piccolo Bark.</p>
<div data-type="example" id="small_bark">
<h5><span class="label">Esempio 3-4. </span>Scarica e carica il modello della piccola corteccia dal repository di Hugging Face</h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># schemas.py</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">typing</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">Literal</code><code translate="no">
</code><code translate="no">
</code><code class="n" translate="no">VoicePresets</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">Literal</code><code class="p" translate="no">[</code><code class="s2" translate="no">"</code><code class="s2" translate="no">v2/en_speaker_1</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">v2/en_speaker_9</code><code class="s2" translate="no">"</code><code class="p" translate="no">]</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO4-1" id="co_ai_integration_and_model_serving_CO4-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">
</code><code class="c1" translate="no"># models.py</code><code translate="no">
</code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="nn" translate="no">torch</code><code translate="no">
</code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="nn" translate="no">numpy</code><code translate="no"> </code><code class="k" translate="no">as</code><code translate="no"> </code><code class="nn" translate="no">np</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">transformers</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">AutoProcessor</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">AutoModel</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">BarkProcessor</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">BarkModel</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">schemas</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">VoicePresets</code><code translate="no">
</code><code translate="no">
</code><code class="n" translate="no">device</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">torch</code><code class="o" translate="no">.</code><code class="n" translate="no">device</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">cuda</code><code class="s2" translate="no">"</code><code translate="no"> </code><code class="k" translate="no">if</code><code translate="no"> </code><code class="n" translate="no">torch</code><code class="o" translate="no">.</code><code class="n" translate="no">cuda</code><code class="o" translate="no">.</code><code class="n" translate="no">is_available</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="k" translate="no">else</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">cpu</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">load_audio_model</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">-</code><code class="o" translate="no">&gt;</code><code translate="no"> </code><code class="nb" translate="no">tuple</code><code class="p" translate="no">[</code><code class="n" translate="no">BarkProcessor</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">BarkModel</code><code class="p" translate="no">]</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">processor</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">AutoProcessor</code><code class="o" translate="no">.</code><code class="n" translate="no">from_pretrained</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">suno/bark-small</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">device</code><code class="o" translate="no">=</code><code class="n" translate="no">device</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO4-2" id="co_ai_integration_and_model_serving_CO4-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">model</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">AutoModel</code><code class="o" translate="no">.</code><code class="n" translate="no">from_pretrained</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">suno/bark-small</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">device</code><code class="o" translate="no">=</code><code class="n" translate="no">device</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO4-3" id="co_ai_integration_and_model_serving_CO4-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">processor</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">model</code><code translate="no">
</code><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">generate_audio</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">processor</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">BarkProcessor</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">model</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">BarkModel</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">prompt</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">str</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">preset</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">VoicePresets</code><code class="p" translate="no">,</code><code translate="no">
</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">-</code><code class="o" translate="no">&gt;</code><code translate="no"> </code><code class="nb" translate="no">tuple</code><code class="p" translate="no">[</code><code class="n" translate="no">np</code><code class="o" translate="no">.</code><code class="n" translate="no">array</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="nb" translate="no">int</code><code class="p" translate="no">]</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">inputs</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">processor</code><code class="p" translate="no">(</code><code class="n" translate="no">text</code><code class="o" translate="no">=</code><code class="p" translate="no">[</code><code class="n" translate="no">prompt</code><code class="p" translate="no">]</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">return_tensors</code><code class="o" translate="no">=</code><code class="s2" translate="no">"</code><code class="s2" translate="no">pt</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code class="n" translate="no">voice_preset</code><code class="o" translate="no">=</code><code class="n" translate="no">preset</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO4-4" id="co_ai_integration_and_model_serving_CO4-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">output</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">model</code><code class="o" translate="no">.</code><code class="n" translate="no">generate</code><code class="p" translate="no">(</code><code class="o" translate="no">*</code><code class="o" translate="no">*</code><code class="n" translate="no">inputs</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">do_sample</code><code class="o" translate="no">=</code><code class="kc" translate="no">True</code><code class="p" translate="no">)</code><code class="o" translate="no">.</code><code class="n" translate="no">cpu</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code class="o" translate="no">.</code><code class="n" translate="no">numpy</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code class="o" translate="no">.</code><code class="n" translate="no">squeeze</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO4-5" id="co_ai_integration_and_model_serving_CO4-5"><img alt="5" src="assets/5.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">sample_rate</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">model</code><code class="o" translate="no">.</code><code class="n" translate="no">generation_config</code><code class="o" translate="no">.</code><code class="n" translate="no">sample_rate</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO4-6" id="co_ai_integration_and_model_serving_CO4-6"><img alt="6" src="assets/6.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">output</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">sample_rate</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO4-1" id="callout_ai_integration_and_model_serving_CO4-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Specifica le opzioni di preselezione vocale supportate utilizzando un tipo di <code translate="no">Literal</code>.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO4-2" id="callout_ai_integration_and_model_serving_CO4-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a></dt>
<dd><p>Scarica il piccolo processore Bark, che prepara il prompt di testo per il modello principale.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO4-3" id="callout_ai_integration_and_model_serving_CO4-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a></dt>
<dd><p>Scarica il modello Bark, che verrà utilizzato per generare l'audio in uscita. Entrambi gli oggetti saranno necessari per la generazione dell'audio in seguito.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO4-4" id="callout_ai_integration_and_model_serving_CO4-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a></dt>
<dd><p>Preelabora il prompt di testo con un embedding della voce dell'altoparlante e restituisce un array di tensori PyTorch di input tokenizzati utilizzando <code translate="no">return_tensors="pt"</code>.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO4-5" id="callout_ai_integration_and_model_serving_CO4-5"><img alt="5" src="assets/5.png" width="12" height="12"/></a></dt>
<dd><p>Genera un array audio che contiene i valori di ampiezza del segnale audio sintetizzato nel tempo.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO4-6" id="callout_ai_integration_and_model_serving_CO4-6"><img alt="6" src="assets/6.png" width="12" height="12"/></a></dt>
<dd><p>Ottieni la frequenza di campionamento dalle configurazioni di generazione del modello, che possono essere utilizzate per produrre l'audio.</p></dd>
</dl></div>
<p>Quando generi l'audio utilizzando un modello, l'output è una sequenza di numeri a virgola mobile che rappresentano l'<em>ampiezza</em> (o la forza) del segnale audio in ogni momento.</p>
<p>Per riprodurre l'audio, è necessario convertirlo in un formato digitale che possa essere inviato agli altoparlanti, il che comporta il campionamento del segnale audio a una frequenza fissa e la quantizzazione dei valori di ampiezza a un numero fisso di bit. La libreria <code translate="no">soundfile</code> può aiutarti a generare il file audio utilizzando una <em>frequenza di campionamento</em>. Più alta è la frequenza di campionamento, più campioni vengono prelevati, migliorando la qualità dell'audio ma aumentando anche le dimensioni del file.</p>
<p>Puoi installare la libreria audio <code translate="no">soundfile</code> per scrivere file audio utilizzando <code translate="no">pip</code>:</p>
<pre data-code-language="bash" data-type="programlisting" translate="no">$<code class="w" translate="no"> </code>pip<code class="w" translate="no"> </code>install<code class="w" translate="no"> </code>soundfile<code class="w" translate="no"/></pre>
<p>L<a data-type="xref" href="#audio_endpoint">'esempio 3-5</a> mostra come puoi trasmettere il contenuto audio al client.</p>
<div data-type="example" id="audio_endpoint">
<h5><span class="label">Esempio 3-5. </span>Endpoint FastAPI per la restituzione dell'audio generato</h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># utils.py</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">io</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">BytesIO</code><code translate="no">
</code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="nn" translate="no">soundfile</code><code translate="no">
</code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="nn" translate="no">numpy</code><code translate="no"> </code><code class="k" translate="no">as</code><code translate="no"> </code><code class="nn" translate="no">np</code><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">audio_array_to_buffer</code><code class="p" translate="no">(</code><code class="n" translate="no">audio_array</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">np</code><code class="o" translate="no">.</code><code class="n" translate="no">array</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">sample_rate</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">int</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">-</code><code class="o" translate="no">&gt;</code><code translate="no"> </code><code class="n" translate="no">BytesIO</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">buffer</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">BytesIO</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">soundfile</code><code class="o" translate="no">.</code><code class="n" translate="no">write</code><code class="p" translate="no">(</code><code class="n" translate="no">buffer</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">audio_array</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">sample_rate</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="nb" translate="no">format</code><code class="o" translate="no">=</code><code class="s2" translate="no">"</code><code class="s2" translate="no">wav</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO5-1" id="co_ai_integration_and_model_serving_CO5-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">buffer</code><code class="o" translate="no">.</code><code class="n" translate="no">seek</code><code class="p" translate="no">(</code><code class="mi" translate="no">0</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">buffer</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO5-2" id="co_ai_integration_and_model_serving_CO5-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">
</code><code class="c1" translate="no"># main.py</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">fastapi</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">FastAPI</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">status</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">fastapi</code><code class="nn" translate="no">.</code><code class="nn" translate="no">responses</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">StreamingResponse</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">models</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">load_audio_model</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">generate_audio</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">schemas</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">VoicePresets</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">utils</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">audio_array_to_buffer</code><code translate="no">
</code><code translate="no">
</code><code class="nd" translate="no">@app</code><code class="o" translate="no">.</code><code class="n" translate="no">get</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">    </code><code class="s2" translate="no">"</code><code class="s2" translate="no">/generate/audio</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">responses</code><code class="o" translate="no">=</code><code class="p" translate="no">{</code><code class="n" translate="no">status</code><code class="o" translate="no">.</code><code class="n" translate="no">HTTP_200_OK</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">content</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">audio/wav</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="p" translate="no">{</code><code class="p" translate="no">}</code><code class="p" translate="no">}</code><code class="p" translate="no">}</code><code class="p" translate="no">}</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">response_class</code><code class="o" translate="no">=</code><code class="n" translate="no">StreamingResponse</code><code class="p" translate="no">,</code><code translate="no">
</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO5-3" id="co_ai_integration_and_model_serving_CO5-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">serve_text_to_audio_model_controller</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">prompt</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">str</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">preset</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">VoicePresets</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">v2/en_speaker_1</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no">
</code><code class="p" translate="no">)</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">processor</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">model</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">load_audio_model</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">output</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">sample_rate</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">generate_audio</code><code class="p" translate="no">(</code><code class="n" translate="no">processor</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">model</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">prompt</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">preset</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">StreamingResponse</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">audio_array_to_buffer</code><code class="p" translate="no">(</code><code class="n" translate="no">output</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">sample_rate</code><code class="p" translate="no">)</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">media_type</code><code class="o" translate="no">=</code><code class="s2" translate="no">"</code><code class="s2" translate="no">audio/wav</code><code class="s2" translate="no">"</code><code translate="no">
</code><code translate="no">    </code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO5-4" id="co_ai_integration_and_model_serving_CO5-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO5-1" id="callout_ai_integration_and_model_serving_CO5-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Installa la libreria <code translate="no">soundfile</code> per scrivere l'array audio nella memoria buffer utilizzando la sua frequenza di campionamento.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO5-2" id="callout_ai_integration_and_model_serving_CO5-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a></dt>
<dd><p>Riporta il cursore del buffer all'inizio del buffer e restituisce il buffer iterabile.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO5-3" id="callout_ai_integration_and_model_serving_CO5-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a></dt>
<dd><p>Crea un nuovo endpoint audio che restituisca il tipo di contenuto <code translate="no">audio/wav</code> come <code translate="no">StreamingResponse</code>.<code translate="no">StreamingResponse</code> è tipicamente utilizzato quando si desidera trasmettere i dati di risposta, ad esempio quando si restituiscono file di grandi dimensioni o quando si generano i dati di risposta. Ti permette di restituire una funzione di generazione che produce pezzi di dati da inviare al client.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO5-4" id="callout_ai_integration_and_model_serving_CO5-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a></dt>
<dd><p>Converte l'array audio generato in un buffer iterabile che può essere passato alla risposta dello streaming.</p></dd>
</dl></div>
<p><a data-primary="memory buffer" data-type="indexterm" id="id682"/>Nell'<a data-type="xref" href="#audio_endpoint">Esempio 3-5</a>, hai generato un array audio utilizzando il modello small Bark e hai trasmesso in streaming il buffer di memoria del contenuto audio. Lo streaming è più efficiente per i file più grandi, in quanto il client può consumare il contenuto mentre viene servito. Negli esempi precedenti non abbiamo utilizzato le risposte in streaming, in quanto le immagini o il testo generati possono essere piuttosto piccoli rispetto ai contenuti audio o video.</p>
<div data-type="tip"><h6>Suggerimento</h6>
<p>Lo streaming di contenuti audio direttamente da un buffer di memoria è più veloce ed efficiente della scrittura dell'array audio in un file e dello streaming dei contenuti dal disco rigido.</p>
<p>Se hai bisogno di memoria per altre attività, puoi scrivere prima l'array audio su un file e poi fare lo streaming da esso utilizzando un generatore di lettura di file.</p>
</div>
<p>Ora che hai un endpoint per la generazione dell'audio, puoi aggiornare il codice del tuo client Streamlit UI per eseguire il rendering dei messaggi audio. Aggiorna il codice del tuo client Streamlit come mostrato nell'<a data-type="xref" href="#barksmall_streamlit_ui">Esempio 3-6</a>.</p>
<div class="less_space pagebreak-before" data-type="example" id="barksmall_streamlit_ui">
<h5><span class="label">Esempio 3-6. </span>UI audio Streamlit che utilizza l'endpoint di generazione FastAPI <code translate="no">/audio</code> </h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># client.py</code><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">for</code><code translate="no"> </code><code class="n" translate="no">message</code><code translate="no"> </code><code class="ow" translate="no">in</code><code translate="no"> </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">session_state</code><code class="o" translate="no">.</code><code class="n" translate="no">messages</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">with</code><code translate="no"> </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">chat_message</code><code class="p" translate="no">(</code><code class="n" translate="no">message</code><code class="p" translate="no">[</code><code class="s2" translate="no">"</code><code class="s2" translate="no">role</code><code class="s2" translate="no">"</code><code class="p" translate="no">]</code><code class="p" translate="no">)</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">content</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">message</code><code class="p" translate="no">[</code><code class="s2" translate="no">"</code><code class="s2" translate="no">content</code><code class="s2" translate="no">"</code><code class="p" translate="no">]</code><code translate="no">
</code><code translate="no">        </code><code class="k" translate="no">if</code><code translate="no"> </code><code class="nb" translate="no">isinstance</code><code class="p" translate="no">(</code><code class="n" translate="no">content</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="nb" translate="no">bytes</code><code class="p" translate="no">)</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">            </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">audio</code><code class="p" translate="no">(</code><code class="n" translate="no">content</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">        </code><code class="k" translate="no">else</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">            </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">markdown</code><code class="p" translate="no">(</code><code class="n" translate="no">content</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">if</code><code translate="no"> </code><code class="n" translate="no">prompt</code><code translate="no"> </code><code class="o" translate="no">:=</code><code translate="no"> </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">chat_input</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">Write your prompt in this input field</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">response</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">requests</code><code class="o" translate="no">.</code><code class="n" translate="no">get</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">        </code><code class="sa" translate="no">f</code><code class="s2" translate="no">"</code><code class="s2" translate="no">http://localhost:8000/generate/audio</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">params</code><code class="o" translate="no">=</code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">prompt</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">prompt</code><code class="p" translate="no">}</code><code translate="no">
</code><code translate="no">    </code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">response</code><code class="o" translate="no">.</code><code class="n" translate="no">raise_for_status</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">with</code><code translate="no"> </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">chat_message</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">assistant</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">text</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">Here is your generated audio</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">audio</code><code class="p" translate="no">(</code><code class="n" translate="no">response</code><code class="o" translate="no">.</code><code class="n" translate="no">content</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO6-1" id="co_ai_integration_and_model_serving_CO6-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO6-1" id="callout_ai_integration_and_model_serving_CO6-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Aggiorna il codice del client Streamlit per renderizzare i contenuti audio.</p></dd>
</dl></div>
<p>Con Streamlit puoi scambiare i componenti per renderizzare qualsiasi tipo di contenuto, comprese immagini, audio e video.</p>
<p>Ora dovresti essere in grado di generare un audio vocale molto realistico nell'interfaccia utente Streamlit aggiornata, come mostrato nella <a data-type="xref" href="#streamlit_bark_ui">Figura 3-16</a>.</p>
<figure><div class="figure" id="streamlit_bark_ui">
<img alt="bgai 0316" src="assets/bgai_0316.png" width="1408" height="465"/>
<h6><span class="label">Figura 3-16. </span>Rendering delle risposte audio nell'interfaccia utente Streamlit</h6>
</div></figure>
<p>Tieni presente che stai utilizzando la versione compressa del modello Bark, ma con la versione light puoi generare audio vocale e musicale in modo abbastanza veloce anche con una sola CPU, in cambio di una certa qualità nella generazione dell'audio.<a data-startref="ix_ch03-asciidoc25" data-type="indexterm" id="id683"/><a data-startref="ix_ch03-asciidoc24" data-type="indexterm" id="id684"/></p>
<p>Ora dovresti sentirti più a tuo agio nel servire contenuti più grandi ai tuoi utenti tramite le risposte in streaming e nel lavorare con i modelli audio.</p>
<p>Finora hai costruito servizi di conversazione e text-to-speech. Ora vediamo come interagire con un modello di visione per costruire un servizio di generazione di immagini.<a data-startref="ix_ch03-asciidoc23" data-type="indexterm" id="id685"/></p>
</div></section>
<section data-pdf-bookmark="Vision Models" data-type="sect2"><div class="sect2" id="id49">
<h2>Modelli di visione</h2>
<p><a data-primary="serving GenAI models" data-secondary="vision models" data-type="indexterm" id="ix_ch03-asciidoc26"/>Utilizzando i modelli di visione, puoi generare, migliorare e comprendere le informazioni visive contenute nei prompt.</p>
<p>Poiché questi modelli sono in grado di produrre risultati molto realistici più velocemente di qualsiasi essere umano e di comprendere e manipolare i contenuti visivi esistenti, sono estremamente utili per applicazioni come i generatori e gli editor di immagini, il rilevamento di oggetti, la classificazione e la didascalia delle immagini e la realtà aumentata.</p>
<p><a data-primary="Stable Diffusion (SD)" data-type="indexterm" id="ix_ch03-asciidoc27"/><a data-primary="SD (Stable Diffusion)" data-type="indexterm" id="ix_ch03-asciidoc27a"/>Una delle architetture più popolari utilizzate per addestrare i modelli di immagini si chiama <em>Diffusione Stabile</em> (SD).</p>
<p>I modelli SD vengono addestrati per codificare le immagini in ingresso in uno spazio latente. Questo spazio latente è la rappresentazione matematica dei modelli nei dati di addestramento che il modello ha appreso. Se provi a visualizzare un'immagine codificata, tutto ciò che vedresti è un'immagine di rumore bianco, simile ai punti bianchi e neri che vedi sullo schermo della tua TV quando perde il segnale.</p>
<p>La<a data-type="xref" href="#stable_diffusion">Figura 3-17</a> mostra l'intero processo di addestramento e inferenza e visualizza come le immagini vengono codificate e decodificate attraverso i processi di diffusione in avanti e inversa. Un codificatore di testo che utilizza testo, immagini e mappe semantiche aiuta a controllare l'output attraverso la diffusione inversa.</p>
<figure><div class="figure" id="stable_diffusion">
<img alt="bgai 0317" src="assets/bgai_0317.png" width="1262" height="793"/>
<h6><span class="label">Figura 3-17. </span>Formazione e inferenza della diffusione stabile</h6>
</div></figure>
<p>Ciò che rende questi modelli magici è la loro capacità di decodificare le immagini rumorose in immagini di input originali. In effetti, i modelli SD imparano anche a rimuovere il rumore bianco da un'immagine codificata per riprodurre l'immagine originale. Il modello esegue questo processo di denoising in diverse iterazioni.</p>
<p>Tuttavia, non vuoi ricreare immagini già esistenti, ma vuoi che il modello crei nuove immagini mai viste prima. Ma come può un modello SD raggiungere questo obiettivo? La risposta sta nello spazio latente in cui risiedono le immagini rumorose codificate. Puoi modificare il rumore di queste immagini in modo che quando il modello le denobilita e le decodifica, ottieni un'immagine completamente nuova che il modello non ha mai visto prima.</p>
<p>La soluzione consiste nel codificare anche le descrizioni dell'immagine accanto all'immagine stessa. I modelli nello spazio latente vengono quindi mappati in descrizioni testuali dell'immagine che si vede in ogni immagine di input. A questo punto, si utilizzano prompt testuali per campionare lo spazio latente rumoroso in modo che l'immagine di output prodotta dopo il processo di denoising sia quella desiderata.</p>
<p>In questo modo i modelli SD possono generare nuove immagini che non hanno mai visto prima nei loro dati di formazione. In sostanza, questi modelli navigano in uno spazio latente che contiene rappresentazioni codificate di vari modelli e significati.<sup><a data-type="noteref" href="ch03.html#id686" id="id686-marker" translate="no">12</a></sup>
Il modello affina iterativamente questo rumore attraverso un processo di denoising per produrre un'immagine nuova non presente nel set di dati di addestramento.</p>
<p>Per scaricare un modello SD, è necessario che sia installata la libreria Hugging Face <code translate="no">diffusers</code>:</p>
<pre data-code-language="bash" data-type="programlisting" translate="no">$<code class="w" translate="no"> </code>pip<code class="w" translate="no"> </code>install<code class="w" translate="no"> </code>diffusers<code class="w" translate="no"/></pre>
<p>L<a data-type="xref" href="#sd_model_usage_example">'esempio 3-7</a> mostra come caricare un modello SD in memoria.</p>
<div data-type="example" id="sd_model_usage_example">
<h5><span class="label">Esempio 3-7. </span>Scaricare e caricare un modello SD dal repository di Hugging Face</h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># models.py</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="nn" translate="no">torch</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">diffusers</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">DiffusionPipeline</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">StableDiffusionInpaintPipelineLegacy</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">PIL</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">Image</code><code translate="no">
</code><code translate="no">
</code><code class="n" translate="no">device</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">torch</code><code class="o" translate="no">.</code><code class="n" translate="no">device</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">cuda</code><code class="s2" translate="no">"</code><code translate="no"> </code><code class="k" translate="no">if</code><code translate="no"> </code><code class="n" translate="no">torch</code><code class="o" translate="no">.</code><code class="n" translate="no">cuda</code><code class="o" translate="no">.</code><code class="n" translate="no">is_available</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="k" translate="no">else</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">cpu</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">load_image_model</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">-</code><code class="o" translate="no">&gt;</code><code translate="no"> </code><code class="n" translate="no">StableDiffusionInpaintPipelineLegacy</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">pipe</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">DiffusionPipeline</code><code class="o" translate="no">.</code><code class="n" translate="no">from_pretrained</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">        </code><code class="s2" translate="no">"</code><code class="s2" translate="no">segmind/tiny-sd</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">torch_dtype</code><code class="o" translate="no">=</code><code class="n" translate="no">torch</code><code class="o" translate="no">.</code><code class="n" translate="no">float32</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">device</code><code class="o" translate="no">=</code><code class="n" translate="no">device</code><code translate="no">
</code><code translate="no">    </code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO7-1" id="co_ai_integration_and_model_serving_CO7-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">pipe</code><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">generate_image</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">pipe</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">StableDiffusionInpaintPipelineLegacy</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">prompt</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">str</code><code translate="no">
</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">-</code><code class="o" translate="no">&gt;</code><code translate="no"> </code><code class="n" translate="no">Image</code><code class="o" translate="no">.</code><code class="n" translate="no">Image</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">output</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">pipe</code><code class="p" translate="no">(</code><code class="n" translate="no">prompt</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">num_inference_steps</code><code class="o" translate="no">=</code><code class="mi" translate="no">10</code><code class="p" translate="no">)</code><code class="o" translate="no">.</code><code class="n" translate="no">images</code><code class="p" translate="no">[</code><code class="mi" translate="no">0</code><code class="p" translate="no">]</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO7-2" id="co_ai_integration_and_model_serving_CO7-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO7-3" id="co_ai_integration_and_model_serving_CO7-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">output</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO7-4" id="co_ai_integration_and_model_serving_CO7-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO7-1" id="callout_ai_integration_and_model_serving_CO7-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Scarica e carica il modello TinySD in memoria con il tipo di tensore <code translate="no">float32</code>, meno efficiente dal punto di vista della memoria. L'uso di <code translate="no">float16</code>, che ha una precisione limitata per modelli grandi e complessi, porta all'instabilità numerica e alla perdita di precisione. Inoltre, il supporto hardware per <code translate="no">float16</code> è limitato, quindi cercare di eseguire un modello SD sulla tua CPU con il tipo di tensore <code translate="no">float16</code> potrebbe non essere possibile. Fonte: <a href="https://oreil.ly/rzw8P">Hugging Face</a>.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO7-2" id="callout_ai_integration_and_model_serving_CO7-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a></dt>
<dd><p>Passa il prompt al modello per generare un elenco di immagini e scegliere la prima. Alcuni modelli ti permettono di generare più immagini in un unico passaggio di inferenza.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO7-3" id="callout_ai_integration_and_model_serving_CO7-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a></dt>
<dd><p><code translate="no">num_inference_steps=10</code> specifica il numero di passi di diffusione da eseguire durante l'inferenza. In ogni passo di diffusione, viene prodotta un'immagine rumorosa più forte dai passi di diffusione precedenti. Il modello genera più immagini rumorose eseguendo più passi di diffusione. Con queste immagini, il modello può comprendere meglio i modelli di rumore presenti nei dati di input e imparare a rimuoverli in modo più efficace. Maggiore è il numero di passi di inferenza, migliori saranno i risultati ottenuti, ma al costo della potenza di calcolo necessaria e di tempi di elaborazione più lunghi.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO7-4" id="callout_ai_integration_and_model_serving_CO7-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a></dt>
<dd><p>L'immagine generata sarà un tipo di immagine di Python Pillow, quindi avrai accesso a una serie di metodi di immagine di Pillow per la post-elaborazione e l'archiviazione. Ad esempio, puoi chiamare il metodo <code translate="no">image.save()</code> per archiviare l'immagine nel tuo filesystem.</p></dd>
</dl></div>
<div data-type="note" epub:type="note"><h6>Nota</h6>
<p>I modelli di visione sono estremamente affamati di risorse. Per caricare e utilizzare un piccolo modello di visione come TinySD sulla CPU, avrai bisogno di circa<span class="keep-together">5 GB</span> di spazio su disco e di RAM. Tuttavia, puoi installare <code translate="no">accelerate</code> utilizzando <code translate="no">pip install accelerate</code> per ottimizzare le risorse richieste in modo che la pipeline del modello utilizzi meno memoria della CPU.</p>
<p>Per servire i modelli video, dovrai utilizzare una GPU. Più avanti in questo capitolo ti mostrerò come sfruttare le GPU per i<span class="keep-together">modelli</span> video.</p>
</div>
<p>Ora puoi impacchettare questo modello in un altro endpoint come nell'<a data-type="xref" href="#text_endpoint">Esempio 3-2</a>, con la differenza che la risposta restituita sarà un'immagine binaria (non un testo). Fai riferimento all'<a data-type="xref" href="#image_endpoint">Esempio 3-8</a>.</p>
<div data-type="example" id="image_endpoint">
<h5><span class="label">Esempio 3-8. </span>Endpoint FastAPI per la restituzione di un'immagine generata</h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># utils.py</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">typing</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">Literal</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">PIL</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">Image</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">io</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">BytesIO</code><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">img_to_bytes</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">image</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">Image</code><code class="o" translate="no">.</code><code class="n" translate="no">Image</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">img_format</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">Literal</code><code class="p" translate="no">[</code><code class="s2" translate="no">"</code><code class="s2" translate="no">PNG</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">JPEG</code><code class="s2" translate="no">"</code><code class="p" translate="no">]</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">PNG</code><code class="s2" translate="no">"</code><code translate="no">
</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">-</code><code class="o" translate="no">&gt;</code><code translate="no"> </code><code class="nb" translate="no">bytes</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">buffer</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">BytesIO</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">image</code><code class="o" translate="no">.</code><code class="n" translate="no">save</code><code class="p" translate="no">(</code><code class="n" translate="no">buffer</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="nb" translate="no">format</code><code class="o" translate="no">=</code><code class="n" translate="no">img_format</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">buffer</code><code class="o" translate="no">.</code><code class="n" translate="no">getvalue</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO8-1" id="co_ai_integration_and_model_serving_CO8-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">
</code><code class="c1" translate="no"># main.py</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">fastapi</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">FastAPI</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">Response</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">status</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">models</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">load_image_model</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">generate_image</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">utils</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">img_to_bytes</code><code translate="no">
</code><code translate="no">
</code><code class="o" translate="no">.</code><code class="o" translate="no">.</code><code class="o" translate="no">.</code><code translate="no">
</code><code translate="no">
</code><code class="nd" translate="no">@app</code><code class="o" translate="no">.</code><code class="n" translate="no">get</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">/generate/image</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">         </code><code class="n" translate="no">responses</code><code class="o" translate="no">=</code><code class="p" translate="no">{</code><code class="n" translate="no">status</code><code class="o" translate="no">.</code><code class="n" translate="no">HTTP_200_OK</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">content</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">image/png</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="p" translate="no">{</code><code class="p" translate="no">}</code><code class="p" translate="no">}</code><code class="p" translate="no">}</code><code class="p" translate="no">}</code><code class="p" translate="no">,</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO8-2" id="co_ai_integration_and_model_serving_CO8-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">         </code><code class="n" translate="no">response_class</code><code class="o" translate="no">=</code><code class="n" translate="no">Response</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO8-3" id="co_ai_integration_and_model_serving_CO8-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">serve_text_to_image_model_controller</code><code class="p" translate="no">(</code><code class="n" translate="no">prompt</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">str</code><code class="p" translate="no">)</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">pipe</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">load_image_model</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">output</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">generate_image</code><code class="p" translate="no">(</code><code class="n" translate="no">pipe</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">prompt</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO8-4" id="co_ai_integration_and_model_serving_CO8-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">Response</code><code class="p" translate="no">(</code><code class="n" translate="no">content</code><code class="o" translate="no">=</code><code class="n" translate="no">img_to_bytes</code><code class="p" translate="no">(</code><code class="n" translate="no">output</code><code class="p" translate="no">)</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">media_type</code><code class="o" translate="no">=</code><code class="s2" translate="no">"</code><code class="s2" translate="no">image/png</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO8-5" id="co_ai_integration_and_model_serving_CO8-5"><img alt="5" src="assets/5.png" width="12" height="12"/></a></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO8-1" id="callout_ai_integration_and_model_serving_CO8-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Crea un buffer in memoria, salva l'immagine in questo buffer in un determinato formato e poi restituisce i dati grezzi in byte del buffer.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO8-2" id="callout_ai_integration_and_model_serving_CO8-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a></dt>
<dd><p>Specifica il tipo di contenuto multimediale e i codici di stato per la pagina di documentazione Swagger UI generata automaticamente.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO8-3" id="callout_ai_integration_and_model_serving_CO8-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a></dt>
<dd><p>Specifica la classe di risposta per evitare che FastAPI aggiunga <code translate="no">application/json</code>come ulteriore tipo di supporto di risposta accettabile.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO8-4" id="callout_ai_integration_and_model_serving_CO8-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a></dt>
<dd><p>La risposta restituita dal modello sarà in formato immagine Pillow.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO8-5" id="callout_ai_integration_and_model_serving_CO8-5"><img alt="5" src="assets/5.png" width="12" height="12"/></a></dt>
<dd><p>Dovremo utilizzare la classe FastAPI <code translate="no">Response</code> per inviare una risposta speciale che trasporta byte di immagini con un tipo di supporto PNG.</p></dd>
</dl></div>
<p><a data-type="xref" href="#tinysd_swagger_docs">La Figura 3-18</a> mostra i risultati del test del nuovo endpoint <code translate="no">/generate/image</code> tramite i documenti FastAPI Swagger con il prompt <code translate="no">A cosy living room with trees in it</code>.</p>
<figure><div class="figure" id="tinysd_swagger_docs">
<img alt="bgai 0318" src="assets/bgai_0318.png" width="802" height="956"/>
<h6><span class="label">Figura 3-18. </span>Servizio TinySD FastAPI</h6>
</div></figure>
<p class="less_space pagebreak-before">A questo punto, collega il tuo endpoint a un'interfaccia utente Streamlit per la prototipazione, come mostrato nell'<a data-type="xref" href="#tinysd_streamlit_code">Esempio 3-9</a>.</p>
<div data-type="example" id="tinysd_streamlit_code">
<h5><span class="label">Esempio 3-9. </span>Streamlit Vision UI che consuma l'endpoint di generazione FastAPI <code translate="no"><em>/image</em></code> per la generazione di endpoint</h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># client.py</code><code translate="no">
</code><code translate="no">
</code><code class="o" translate="no">.</code><code class="o" translate="no">.</code><code class="o" translate="no">.</code><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">for</code><code translate="no"> </code><code class="n" translate="no">message</code><code translate="no"> </code><code class="ow" translate="no">in</code><code translate="no"> </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">session_state</code><code class="o" translate="no">.</code><code class="n" translate="no">messages</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">with</code><code translate="no"> </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">chat_message</code><code class="p" translate="no">(</code><code class="n" translate="no">message</code><code class="p" translate="no">[</code><code class="s2" translate="no">"</code><code class="s2" translate="no">role</code><code class="s2" translate="no">"</code><code class="p" translate="no">]</code><code class="p" translate="no">)</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">image</code><code class="p" translate="no">(</code><code class="n" translate="no">message</code><code class="p" translate="no">[</code><code class="s2" translate="no">"</code><code class="s2" translate="no">content</code><code class="s2" translate="no">"</code><code class="p" translate="no">]</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO9-1" id="co_ai_integration_and_model_serving_CO9-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a><code translate="no">
</code><code class="o" translate="no">.</code><code class="o" translate="no">.</code><code class="o" translate="no">.</code><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">if</code><code translate="no"> </code><code class="n" translate="no">prompt</code><code translate="no"> </code><code class="o" translate="no">:=</code><code translate="no"> </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">chat_input</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">Write your prompt in this input field</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="o" translate="no">.</code><code class="o" translate="no">.</code><code class="o" translate="no">.</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">response</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">requests</code><code class="o" translate="no">.</code><code class="n" translate="no">get</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">        </code><code class="sa" translate="no">f</code><code class="s2" translate="no">"</code><code class="s2" translate="no">http://localhost:8000/generate/image</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">params</code><code class="o" translate="no">=</code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">prompt</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">prompt</code><code class="p" translate="no">}</code><code translate="no">
</code><code translate="no">    </code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO9-2" id="co_ai_integration_and_model_serving_CO9-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">response</code><code class="o" translate="no">.</code><code class="n" translate="no">raise_for_status</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">with</code><code translate="no"> </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">chat_message</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">assistant</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">text</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">Here is your generated image</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">st</code><code class="o" translate="no">.</code><code class="n" translate="no">image</code><code class="p" translate="no">(</code><code class="n" translate="no">response</code><code class="o" translate="no">.</code><code class="n" translate="no">content</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">
</code><code translate="no">    </code><code class="o" translate="no">.</code><code class="o" translate="no">.</code><code class="o" translate="no">.</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO9-1" id="callout_ai_integration_and_model_serving_CO9-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Le immagini trasferite tramite il protocollo HTTP saranno in formato binario. Pertanto, aggiorniamo la funzione di visualizzazione per rendere il contenuto delle immagini binario. Puoi utilizzare il metodo <code translate="no">st.image</code> per visualizzare le immagini nell'interfaccia utente.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO9-2" id="callout_ai_integration_and_model_serving_CO9-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a></dt>
<dd><p>Aggiorna la richiesta <code translate="no">GET</code> in modo che raggiunga l'endpoint <code translate="no">/generate/image</code>. Quindi, visualizza un messaggio testuale e un'immagine per l'utente.</p></dd>
</dl></div>
<p>La<a data-type="xref" href="#tinysd_streamlitui">Figura 3-19</a> mostra i risultati finali dell'esperienza dell'utente con il modello.</p>
<figure><div class="figure" id="tinysd_streamlitui">
<img alt="bgai 0319" src="assets/bgai_0319.png" width="704" height="794"/>
<h6><span class="label">Figura 3-19. </span>Rendering dei messaggi immagine nell'interfaccia utente di Streamlit</h6>
</div></figure>
<aside class="less_space pagebreak-before" data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id687">
<h1>Modelli Running XL</h1>
<p><a data-primary="serving GenAI models" data-secondary="running XL models" data-type="indexterm" id="id688"/><a data-primary="XL models" data-type="indexterm" id="id689"/>Ora hai visto come implementare gli endpoint di model-serving con FastAPI e Streamlit per generare testo o immagini. Abbiamo utilizzato versioni ridotte di questi modelli in modo che tu possa eseguire gli esempi sulla tua CPU. Tuttavia, i requisiti hardware aumentano significativamente se devi utilizzare le versioni XL per ottenere una qualità migliore.
Ad esempio, per eseguire il modello SDXL sono necessari 16 GB di RAM della CPU e 16 GB di VRAM della GPU per generare un'immagine. Questo perché dovrai prima caricare il modello sulla CPU dal disco e poi spostarlo sulla GPU per l'inferenza. Tratteremo questo processo in modo più dettagliato quando parleremo delle strategie di model-serving.</p>
</div></aside>
<p>Abbiamo visto come anche con un modello SD di piccole dimensioni sia possibile generare immagini dall'aspetto ragionevole. Le versioni XL possono produrre immagini ancora più realistiche, ma hanno comunque i loro<span class="keep-together">limiti.</span></p>
<p>Al momento in cui scriviamo, gli attuali modelli di SD open source presentano alcune<span class="keep-together">limitazioni:</span></p>
<dl>
<dt>Coerenza</dt>
<dd>
<p>I modelli non possono produrre tutti i dettagli descritti nei prompt e le composizioni complesse.</p>
</dd>
<dt>Dimensioni dell'uscita</dt>
<dd>
<p>Le immagini in uscita possono avere solo dimensioni predefinite come 512 × 512 o 1024 × 1024 pixel.</p>
</dd>
<dt>Compostezza</dt>
<dd>
<p>Non puoi controllare completamente l'immagine generata e definire la composizione dell'immagine.</p>
</dd>
<dt>Fotorealismo</dt>
<dd>
<p>Gli output generati mostrano dettagli che fanno capire che sono stati generati dall'intelligenza artificiale.</p>
</dd>
<dt>Testo leggibile</dt>
<dd>
<p>Alcuni modelli non sono in grado di generare testi leggibili.</p>
</dd>
</dl>
<p>Il modello <code translate="no">tinysd</code> con cui hai lavorato è un modello in fase iniziale che ha subito il processo di <em>distillazione</em> (cioè di compressione) dal modello SD V1.5 più grande.<a data-startref="ix_ch03-asciidoc27" data-type="indexterm" id="id690"/><a data-startref="ix_ch03-asciidoc27a" data-type="indexterm" id="id691"/>Di conseguenza, i risultati generati potrebbero non soddisfare gli standard di produzione o non essere del tutto coesi e potrebbero non incorporare tutti i concetti menzionati nei prompt del testo. Tuttavia, i modelli distillati potrebbero funzionare bene se <a href="https://oreil.ly/Nqtkm">li<em>metti a punto</em> usando il <em>Low-Rank Adaptation</em> (LoRA)</a> su concetti/stili specifici.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id692">
<h1>Adattamento a basso rango nei modelli generativi di fine tuning</h1>
<p><a data-primary="low-rank adaptation (LoRA)" data-type="indexterm" id="id693"/><a data-primary="serving GenAI models" data-secondary="low-rank adaptation in fine-tuning generative models" data-type="indexterm" id="id694"/>La LoRA è una strategia di addestramento che introduce un numero minimo di parametri addestrabili in ogni strato di un modello, mentre la maggior parte dei parametri del modello originale rimane fissa.</p>
<p>Limitando il numero di parametri da addestrare, LoRA riduce notevolmente la memoria della GPU necessaria per l'addestramento, il che è molto utile per la messa a punto o l'addestramento di modelli su larga scala, dove i vincoli di memoria sono in genere una sfida importante per la personalizzazione.</p>
</div></aside>
<p>Ora puoi costruire servizi GenAI sia basati sul testo che sulle immagini. Tuttavia, ti starai chiedendo come costruire servizi da testo a video basati su modelli video. Scopriamo di più sui modelli video, come funzionano e come costruire un servizio di animazione di immagini con essi.<a data-startref="ix_ch03-asciidoc26" data-type="indexterm" id="id695"/></p>
</div></section>
<section data-pdf-bookmark="Video Models" data-type="sect2"><div class="sect2" id="id50">
<h2>Modelli video</h2>
<p><a data-primary="serving GenAI models" data-secondary="video models" data-type="indexterm" id="ix_ch03-asciidoc28"/>I modelli video sono tra i modelli generativi più avidi di risorse e spesso richiedono una GPU per produrre un breve frammento di buona qualità. Questi modelli devono generare diverse decine di fotogrammi per produrre un singolo secondo di video, anche senza alcun contenuto audio.</p>
<p><a data-primary="Stability AI" data-type="indexterm" id="id696"/>Stability AI ha rilasciato diversi modelli video open source basati sull'architettura SD di Hugging Face. Lavoreremo con la versione compressa del loro modello immagine-video per un servizio di animazione delle immagini più veloce.</p>
<p>Per iniziare, facciamo funzionare un piccolo modello immagine-video usando l'<a data-type="xref" href="#video_model_loading">Esempio 3-10</a>.</p>
<div data-type="note" epub:type="note"><h6>Nota</h6>
<p>Per eseguire l'<a data-type="xref" href="#video_model_loading">Esempio 3-10</a>, potresti aver bisogno di accedere a una GPU NVIDIA compatibile con CUDA.</p>
<p>Inoltre, per l'uso commerciale del modello <code translate="no">stable-video-diffusion-img2vid</code>, fai riferimento alla sua <a href="https://oreil.ly/DM-0p">scheda modello</a>.</p>
</div>
<div data-type="example" id="video_model_loading">
<h5><span class="label">Esempio 3-10. </span>Scarica e carica il modello <em>img2vid</em> dell'IA Stability dal repository Hugging Face.</h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># models.py</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="nn" translate="no">torch</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">diffusers</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">StableVideoDiffusionPipeline</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">PIL</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">Image</code><code translate="no">
</code><code translate="no">
</code><code class="n" translate="no">device</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">torch</code><code class="o" translate="no">.</code><code class="n" translate="no">device</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">cuda</code><code class="s2" translate="no">"</code><code translate="no"> </code><code class="k" translate="no">if</code><code translate="no"> </code><code class="n" translate="no">torch</code><code class="o" translate="no">.</code><code class="n" translate="no">cuda</code><code class="o" translate="no">.</code><code class="n" translate="no">is_available</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="k" translate="no">else</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">cpu</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">load_video_model</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">-</code><code class="o" translate="no">&gt;</code><code translate="no"> </code><code class="n" translate="no">StableVideoDiffusionPipeline</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">pipe</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">StableVideoDiffusionPipeline</code><code class="o" translate="no">.</code><code class="n" translate="no">from_pretrained</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">        </code><code class="s2" translate="no">"</code><code class="s2" translate="no">stabilityai/stable-video-diffusion-img2vid</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">torch_dtype</code><code class="o" translate="no">=</code><code class="n" translate="no">torch</code><code class="o" translate="no">.</code><code class="n" translate="no">float16</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">variant</code><code class="o" translate="no">=</code><code class="s2" translate="no">"</code><code class="s2" translate="no">fp16</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">device</code><code class="o" translate="no">=</code><code class="n" translate="no">device</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">    </code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">pipe</code><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">generate_video</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">pipe</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">StableVideoDiffusionPipeline</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">image</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">Image</code><code class="o" translate="no">.</code><code class="n" translate="no">Image</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">num_frames</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">int</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="mi" translate="no">25</code><code translate="no">
</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">-</code><code class="o" translate="no">&gt;</code><code translate="no"> </code><code class="nb" translate="no">list</code><code class="p" translate="no">[</code><code class="n" translate="no">Image</code><code class="o" translate="no">.</code><code class="n" translate="no">Image</code><code class="p" translate="no">]</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">image</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">image</code><code class="o" translate="no">.</code><code class="n" translate="no">resize</code><code class="p" translate="no">(</code><code class="p" translate="no">(</code><code class="mi" translate="no">1024</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="mi" translate="no">576</code><code class="p" translate="no">)</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO10-1" id="co_ai_integration_and_model_serving_CO10-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">generator</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">torch</code><code class="o" translate="no">.</code><code class="n" translate="no">manual_seed</code><code class="p" translate="no">(</code><code class="mi" translate="no">42</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO10-2" id="co_ai_integration_and_model_serving_CO10-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">frames</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">pipe</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">image</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">decode_chunk_size</code><code class="o" translate="no">=</code><code class="mi" translate="no">8</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">generator</code><code class="o" translate="no">=</code><code class="n" translate="no">generator</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">num_frames</code><code class="o" translate="no">=</code><code class="n" translate="no">num_frames</code><code translate="no">
</code><code translate="no">    </code><code class="p" translate="no">)</code><code class="o" translate="no">.</code><code class="n" translate="no">frames</code><code class="p" translate="no">[</code><code class="mi" translate="no">0</code><code class="p" translate="no">]</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO10-3" id="co_ai_integration_and_model_serving_CO10-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">frames</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO10-1" id="callout_ai_integration_and_model_serving_CO10-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Ridimensiona l'immagine in ingresso a una dimensione standard prevista dal modello di input. Il ridimensionamento protegge anche da input di grandi dimensioni.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO10-2" id="callout_ai_integration_and_model_serving_CO10-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a></dt>
<dd><p>Crea un generatore di tensori casuali con il seme impostato a 42 per generare fotogrammi video riproducibili.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO10-3" id="callout_ai_integration_and_model_serving_CO10-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a></dt>
<dd><p>Esegui la pipeline di generazione dei fotogrammi per produrre tutti i fotogrammi video in una volta sola.<span class="keep-together">Afferra il primo</span> gruppo di fotogrammi generati. Questo passaggio richiede una notevole quantità di memoria video.<code translate="no">num_frames</code> specifica il numero di fotogrammi da generare, mentre<code translate="no">decode_chunk_size</code> specifica quanti fotogrammi generare in una volta sola.</p></dd>
</dl></div>
<p>Con le funzioni di caricamento del modello già pronte, puoi ora creare l'<span class="keep-together">endpoint</span> per il servizio video.</p>
<p>Tuttavia, prima di procedere con la dichiarazione del route handler, hai bisogno di una funzione di utilità che elabori gli output del modello video dai fotogrammi in un video in streaming utilizzando un buffer I/O.</p>
<p>Per esportare una sequenza di fotogrammi in video, devi codificarli in un contenitore video utilizzando una libreria video come <code translate="no">av</code>, che implementa i binding di Python alla popolare libreria di elaborazione video<code translate="no">ffmpeg</code>.</p>
<p>Puoi installare la libreria <code translate="no">av</code> tramite:</p>
<pre data-code-language="bash" data-type="programlisting" translate="no">$<code class="w" translate="no"> </code>pip<code class="w" translate="no"> </code>install<code class="w" translate="no"> </code>av<code class="w" translate="no"/></pre>
<p>Ora puoi utilizzare l'<a data-type="xref" href="#frames_to_videos">Esempio 3-11</a> per creare buffer video in streaming.</p>
<div data-type="example" id="frames_to_videos">
<h5><span class="label">Esempio 3-11. </span>Esportazione dell'output del modello video dai fotogrammi a un buffer video in streaming utilizzando la libreria <code translate="no">av</code> </h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># utils.py</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">io</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">BytesIO</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">PIL</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">Image</code><code translate="no">
</code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="nn" translate="no">av</code><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">export_to_video_buffer</code><code class="p" translate="no">(</code><code class="n" translate="no">images</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">list</code><code class="p" translate="no">[</code><code class="n" translate="no">Image</code><code class="o" translate="no">.</code><code class="n" translate="no">Image</code><code class="p" translate="no">]</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">-</code><code class="o" translate="no">&gt;</code><code translate="no"> </code><code class="n" translate="no">BytesIO</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">buffer</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">BytesIO</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">output</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">av</code><code class="o" translate="no">.</code><code class="n" translate="no">open</code><code class="p" translate="no">(</code><code class="n" translate="no">buffer</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">w</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="nb" translate="no">format</code><code class="o" translate="no">=</code><code class="s2" translate="no">"</code><code class="s2" translate="no">mp4</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO11-1" id="co_ai_integration_and_model_serving_CO11-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">stream</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">output</code><code class="o" translate="no">.</code><code class="n" translate="no">add_stream</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">h264</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="mi" translate="no">30</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO11-2" id="co_ai_integration_and_model_serving_CO11-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">stream</code><code class="o" translate="no">.</code><code class="n" translate="no">width</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">images</code><code class="p" translate="no">[</code><code class="mi" translate="no">0</code><code class="p" translate="no">]</code><code class="o" translate="no">.</code><code class="n" translate="no">width</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">stream</code><code class="o" translate="no">.</code><code class="n" translate="no">height</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">images</code><code class="p" translate="no">[</code><code class="mi" translate="no">0</code><code class="p" translate="no">]</code><code class="o" translate="no">.</code><code class="n" translate="no">height</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">stream</code><code class="o" translate="no">.</code><code class="n" translate="no">pix_fmt</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">yuv444p</code><code class="s2" translate="no">"</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO11-3" id="co_ai_integration_and_model_serving_CO11-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">stream</code><code class="o" translate="no">.</code><code class="n" translate="no">options</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">crf</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">17</code><code class="s2" translate="no">"</code><code class="p" translate="no">}</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO11-4" id="co_ai_integration_and_model_serving_CO11-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">for</code><code translate="no"> </code><code class="n" translate="no">image</code><code translate="no"> </code><code class="ow" translate="no">in</code><code translate="no"> </code><code class="n" translate="no">images</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">frame</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">av</code><code class="o" translate="no">.</code><code class="n" translate="no">VideoFrame</code><code class="o" translate="no">.</code><code class="n" translate="no">from_image</code><code class="p" translate="no">(</code><code class="n" translate="no">image</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">packet</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">stream</code><code class="o" translate="no">.</code><code class="n" translate="no">encode</code><code class="p" translate="no">(</code><code class="n" translate="no">frame</code><code class="p" translate="no">)</code><code translate="no">   </code><a class="co" href="#callout_ai_integration_and_model_serving_CO11-5" id="co_ai_integration_and_model_serving_CO11-5"><img alt="5" src="assets/5.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">output</code><code class="o" translate="no">.</code><code class="n" translate="no">mux</code><code class="p" translate="no">(</code><code class="n" translate="no">packet</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO11-6" id="co_ai_integration_and_model_serving_CO11-6"><img alt="6" src="assets/6.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">packet</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">stream</code><code class="o" translate="no">.</code><code class="n" translate="no">encode</code><code class="p" translate="no">(</code><code class="kc" translate="no">None</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">output</code><code class="o" translate="no">.</code><code class="n" translate="no">mux</code><code class="p" translate="no">(</code><code class="n" translate="no">packet</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">buffer</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO11-7" id="co_ai_integration_and_model_serving_CO11-7"><img alt="7" src="assets/7.png" width="12" height="12"/></a></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO11-1" id="callout_ai_integration_and_model_serving_CO11-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Apri un buffer per scrivere un file MP4 e poi configura un flusso video con il multiplexer video di AV.<sup><a data-type="noteref" href="ch03.html#id697" id="id697-marker" translate="no">13</a></sup></p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO11-2" id="callout_ai_integration_and_model_serving_CO11-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a></dt>
<dd><p>Imposta la codifica video su <code translate="no">h264</code> a 30 fotogrammi al secondo e assicurati che le dimensioni dei fotogrammi corrispondano a quelle fornite alla funzione.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO11-3" id="callout_ai_integration_and_model_serving_CO11-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a></dt>
<dd><p>Imposta il formato dei pixel del flusso video su <code translate="no">yuv444p</code> in modo che ogni pixel abbia la risoluzione completa per i componenti <code translate="no">y</code> (luminanza o luminosità) e <code translate="no">u</code> e <code translate="no">v</code> (crominanza o colore).</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO11-4" id="callout_ai_integration_and_model_serving_CO11-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a></dt>
<dd><p>Configura il fattore di velocità costante (CRF) dello stream per controllare la qualità e la compressione del video. Imposta il CRF a 17 per produrre un video di alta qualità senza perdite e con una compressione minima.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO11-5" id="callout_ai_integration_and_model_serving_CO11-5"><img alt="5" src="assets/5.png" width="12" height="12"/></a></dt>
<dd><p>Codifica i fotogrammi in ingresso in pacchetti codificati con il multiplexer video configurato.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO11-6" id="callout_ai_integration_and_model_serving_CO11-6"><img alt="6" src="assets/6.png" width="12" height="12"/></a></dt>
<dd><p>Aggiunge i fotogrammi codificati nel buffer del contenitore video aperto.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO11-7" id="callout_ai_integration_and_model_serving_CO11-7"><img alt="7" src="assets/7.png" width="12" height="12"/></a></dt>
<dd><p>Spegne tutti i fotogrammi rimasti nel codificatore e combina il pacchetto risultante nel file di uscita prima di restituire il buffer contenente il video codificato.</p></dd>
</dl></div>
<p>Per utilizzare i prompt di immagini con il servizio come upload di file, devi installare la libreria <code translate="no">python-multipart</code>:<sup><a data-type="noteref" href="ch03.html#id698" id="id698-marker" translate="no">14</a></sup></p>
<pre data-code-language="bash" data-type="programlisting" translate="no">$<code class="w" translate="no"> </code>pip<code class="w" translate="no"> </code>install<code class="w" translate="no"> </code>python-multipart<code class="w" translate="no"/></pre>
<p>Una volta installato, puoi configurare il nuovo endpoint utilizzando l'<a data-type="xref" href="#video_endpoint">Esempio 3-12</a>.</p>
<div data-type="example" id="video_endpoint">
<h5><span class="label">Esempio 3-12. </span>Servire i video generati dal modello immagine-video</h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># main.py</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">fastapi</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">status</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">FastAPI</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">File</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">fastapi</code><code class="nn" translate="no">.</code><code class="nn" translate="no">responses</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">StreamingResponse</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">io</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">BytesIO</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">PIL</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">Image</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">models</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">load_video_model</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">generate_video</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">utils</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">export_to_video_buffer</code><code translate="no">
</code><code translate="no">
</code><code class="o" translate="no">.</code><code class="o" translate="no">.</code><code class="o" translate="no">.</code><code translate="no">
</code><code translate="no">
</code><code class="nd" translate="no">@app</code><code class="o" translate="no">.</code><code class="n" translate="no">post</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">    </code><code class="s2" translate="no">"</code><code class="s2" translate="no">/generate/video</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">responses</code><code class="o" translate="no">=</code><code class="p" translate="no">{</code><code class="n" translate="no">status</code><code class="o" translate="no">.</code><code class="n" translate="no">HTTP_200_OK</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">content</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">video/mp4</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="p" translate="no">{</code><code class="p" translate="no">}</code><code class="p" translate="no">}</code><code class="p" translate="no">}</code><code class="p" translate="no">}</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">response_class</code><code class="o" translate="no">=</code><code class="n" translate="no">StreamingResponse</code><code class="p" translate="no">,</code><code translate="no">
</code><code class="p" translate="no">)</code><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">serve_image_to_video_model_controller</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">image</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">bytes</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">File</code><code class="p" translate="no">(</code><code class="o" translate="no">.</code><code class="o" translate="no">.</code><code class="o" translate="no">.</code><code class="p" translate="no">)</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">num_frames</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">int</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="mi" translate="no">25</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO12-1" id="co_ai_integration_and_model_serving_CO12-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a><code translate="no">
</code><code class="p" translate="no">)</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">image</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">Image</code><code class="o" translate="no">.</code><code class="n" translate="no">open</code><code class="p" translate="no">(</code><code class="n" translate="no">BytesIO</code><code class="p" translate="no">(</code><code class="n" translate="no">image</code><code class="p" translate="no">)</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO12-2" id="co_ai_integration_and_model_serving_CO12-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">model</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">load_video_model</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">frames</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">generate_video</code><code class="p" translate="no">(</code><code class="n" translate="no">model</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">image</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">num_frames</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">StreamingResponse</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">export_to_video_buffer</code><code class="p" translate="no">(</code><code class="n" translate="no">frames</code><code class="p" translate="no">)</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">media_type</code><code class="o" translate="no">=</code><code class="s2" translate="no">"</code><code class="s2" translate="no">video/mp4</code><code class="s2" translate="no">"</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO12-3" id="co_ai_integration_and_model_serving_CO12-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="p" translate="no">)</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO12-1" id="callout_ai_integration_and_model_serving_CO12-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Utilizza l'oggetto <code translate="no">File</code> per specificare <code translate="no">image</code> come caricamento del file del modulo.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO12-2" id="callout_ai_integration_and_model_serving_CO12-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a></dt>
<dd><p>Crea un oggetto Pillow <code translate="no">Image</code> passando i byte dell'immagine trasferiti al servizio. La pipeline del modello si aspetta un formato di immagine Pillow come input.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO12-3" id="callout_ai_integration_and_model_serving_CO12-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a></dt>
<dd><p>Esporta i fotogrammi generati come video MP4 e trasmettili al client utilizzando un buffer video iterabile.</p></dd>
</dl></div>
<p>Con l'endpoint video configurato, ora puoi caricare le immagini sul tuo servizio FastAPI per animarle come video.</p>
<p>Ci sono altri modelli video disponibili sull'hub che ti permettono di generare GIF e animazioni. Per fare ulteriore pratica, puoi provare a creare un servizio GenAI con questi modelli.<a data-primary="large vision model (LVM)" data-type="indexterm" id="ix_ch03-asciidoc29a"/><a data-primary="LVM (large vision model)" data-type="indexterm" id="ix_ch03-asciidoc29b"/>Mentre i modelli video open source possono produrre video di ampia qualità, l'annuncio di OpenAI di un nuovo modello di visione di grandi dimensioni (LVM) chiamato Sora ha scosso il settore della generazione di video.</p>
<section data-pdf-bookmark="OpenAI Sora" data-type="sect3"><div class="sect3" id="id51">
<h3>OpenAI Sora</h3>
<p><a data-primary="OpenAI Sora video generation model" data-type="indexterm" id="ix_ch03-asciidoc29"/><a data-primary="serving GenAI models" data-secondary="OpenAI Sora" data-type="indexterm" id="ix_ch03-asciidoc30"/><a data-primary="Sora video generation model" data-type="indexterm" id="ix_ch03-asciidoc31"/>I modelli text-to-video sono limitati nelle loro capacità di generazione: a parte l'immensa potenza di calcolo necessaria per generare sequenzialmente fotogrammi video coerenti, l'addestramento di questi modelli può essere impegnativo a causa di:</p>
<ul>
<li>
<p><em>Mantenere la coerenza temporale e spaziale tra i fotogrammi</em> per ottenere risultati video realistici e non distorti.</p>
</li>
<li>
<p><em>Mancanza di dati di formazione</em> con didascalie e metadati di alta qualità, necessari per addestrare i modelli video.</p>
</li>
<li>
<p>Le<em>sfide legate alle didascalie</em> sono molteplici: la didascalia del contenuto dei video, chiara e descrittiva, richiede molto tempo e va oltre la stesura di brevi brani di testo. Le didascalie devono descrivere la narrazione e le scene di ogni sequenza affinché il modello possa apprendere e mappare i ricchi schemi contenuti nel video nel testo.</p>
</li>
</ul>
<p>Per questi motivi, non c'è stata una svolta nei modelli di generazione video fino all'annuncio del modello Sora di OpenAI.</p>
<p>Sora è un modello di trasformatore generalista per la diffusione della visione di grandi dimensioni in grado di generare video e immagini con durate, rapporti d'aspetto e risoluzioni diverse, fino a un minuto intero di video ad alta definizione. La sua architettura si basa sui trasformatori comunemente utilizzati negli LLMs e sul processo di diffusione. Mentre gli LLMs utilizzano token di testo, Sora utilizza patch visive.</p>
<div data-type="tip"><h6>Suggerimento</h6>
<p>Il modello Sora combina elementi e principi delle architetture transformer e SD, mentre nell'<a data-type="xref" href="#video_model_loading">Esempio 3-10</a> hai utilizzato il modello SD di Stability AI per generare i video.</p>
</div>
<p>Quindi cosa rende Sora diverso?</p>
<p>I trasformatori hanno dimostrato una notevole scalabilità nei modelli linguistici, nella visione computerizzata e nella generazione di immagini, quindi era logico che l'architettura di Sora si basasse sui trasformatori per gestire input diversi come testo, immagini o fotogrammi video. Inoltre, poiché i trasformatori sono in grado di comprendere schemi complessi e dipendenze a lungo raggio nei dati sequenziali, Sora, in quanto trasformatore di visione, può anche catturare relazioni temporali e spaziali a grana fine tra i fotogrammi video per generare fotogrammi coerenti con transizioni fluide tra di essi (cioè, che mostrano coerenza temporale).</p>
<p>Inoltre, Sora prende in prestito le capacità dei modelli SD per generare fotogrammi video di alta qualità e visivamente coerenti, con controlli precisi grazie al processo iterativo di riduzione del rumore. L'utilizzo del processo di diffusione consente a Sora di generare immagini con dettagli fini e proprietà desiderabili.</p>
<p>Combinando il ragionamento sequenziale dei trasformatori con il perfezionamento iterativo di SD, Sora è in grado di generare video ad alta risoluzione, coerenti e fluidi da input multimodali come testo e immagini che contengono concetti astratti.</p>
<p>L'architettura di rete di Sora è stata progettata anche per ridurre la dimensionalità attraverso una rete<span class="keep-together">a forma di U</span> in cui i dati visivi altamente dimensionali vengono compressi e codificati in uno spazio latente rumoroso. Sora può quindi generare patch dallo spazio latente attraverso il processo di diffusione del denoising.</p>
<p>Il processo di diffusione è simile a quello dei modelli SD basati sulle immagini. Invece di avere una<span class="keep-together">rete U</span> 2D normalmente utilizzata per le immagini, OpenAI ha addestrato una rete U 3D in cui la terza dimensione è una sequenza di fotogrammi nel tempo (un video), come mostra la <a data-type="xref" href="#images_to_videos">Figura 3-20</a>.</p>
<figure><div class="figure" id="images_to_videos">
<img alt="bgai 0320" src="assets/bgai_0320.png" width="680" height="352"/>
<h6><span class="label">Figura 3-20. </span>Una sequenza di immagini forma un video</h6>
</div></figure>
<p>OpenAI ha dimostrato che comprimendo i video in patch, come mostrato nella <a data-type="xref" href="#videos_to_patches">Figura 3-21</a>, il modello può raggiungere la scalabilità dell'apprendimento di rappresentazioni ad alta dimensionalità durante l'addestramento su diversi tipi di video e immagini che variano per risoluzione, durata e rapporto di aspetto.</p>
<figure><div class="figure" id="videos_to_patches">
<img alt="bgai 0321" src="assets/bgai_0321.png" width="1184" height="429"/>
<h6><span class="label">Figura 3-21. </span>Compressione video in patch spazio-temporali</h6>
</div></figure>
<p>Tramite il processo di diffusione, Sora sminuzza le patch rumorose in ingresso per generare video e immagini pulite in qualsiasi rapporto di aspetto, dimensione e risoluzione per i dispositivi direttamente nelle loro dimensioni native.</p>
<p>Mentre un trasformatore di testo predice il token successivo in una sequenza di testo, il trasformatore di visione di Sora predice la patch successiva per generare un'immagine o un video, come mostrato nella <a data-type="xref" href="#vision_transformer_sequence">Figura 3-22</a>.</p>
<figure><div class="figure" id="vision_transformer_sequence">
<img alt="bgai 0322" src="assets/bgai_0322.png" width="1171" height="347"/>
<h6><span class="label">Figura 3-22. </span>Previsione dei token da parte del trasformatore di visione</h6>
</div></figure>
<p>Grazie all'addestramento su vari set di dati, OpenAI ha superato le sfide precedentemente menzionate per l'addestramento dei modelli di visione, come la mancanza di didascalie di qualità, l'elevata dimensionalità dei dati video e così via, per citarne alcune.</p>
<p>Ciò che affascina di Sora e potenzialmente di altri LVM sono le capacità emergenti che mostrano:</p>
<dl>
<dt>Coerenza 3D</dt>
<dd>
<p>Gli oggetti nelle scene generate rimangono coerenti e si adattano alla prospettiva anche quando la telecamera si muove e ruota intorno alla scena.</p>
</dd>
<dt>Permanenza dell'oggetto e coerenza ad ampio raggio</dt>
<dd>
<p>Gli oggetti e le persone che vengono occlusi o che escono da un'inquadratura in una determinata posizione persisteranno quando riappariranno nel campo visivo. In alcuni casi, il modello ricorda effettivamente come mantenerli coerenti nell'ambiente. Si tratta anche della <em>coerenza temporale</em>, che la maggior parte dei modelli video non riesce a gestire.</p>
</dd>
<dt>Interazione mondiale</dt>
<dd>
<p>Le azioni simulate nei video generati influenzano realisticamente l'ambiente. Ad esempio, Sora capisce che l'azione di mangiare un hamburger dovrebbe lasciare il segno di un morso su di esso.</p>
</dd>
<dt>Simulazione di ambienti</dt>
<dd>
<p>Sora può anche simulare mondi reali o fittizi, come nei giochi, rispettando le regole delle interazioni in quegli ambienti, come nel caso di un personaggio in un livello di <em>Minecraft</em>. In altre parole, Sora ha imparato a essere un motore fisico guidato dai dati.</p>
</dd>
</dl>
<p>La<a data-type="xref" href="#sora_emerging_capabilities">Figura 3-23</a> illustra queste funzionalità.</p>
<figure><div class="figure" id="sora_emerging_capabilities">
<img alt="bgai 0323" src="assets/bgai_0323.png" width="1352" height="1146"/>
<h6><span class="label">Figura 3-23. </span>Capacità emergenti di Sora</h6>
</div></figure>
<p>Al momento della stesura di questo articolo, Sora non è ancora stato rilasciato come API, ma sono già nate delle alternative open source. Un promettente modello di visione di grandi dimensioni chiamato "Latte" ti permette di mettere a punto l'LVM sui tuoi dati visivi.</p>
<div data-type="caution"><h6>Attenzione</h6>
<p>Al momento in cui scriviamo non è ancora possibile commercializzare alcuni modelli open source, tra cui Latte. Controlla sempre la scheda del modello e la licenza per assicurarti che l'uso commerciale sia consentito.</p>
</div>
<p>La combinazione di trasformatori e diffusori per creare LVM è un'area di ricerca promettente per la generazione di output complessi come i video. Tuttavia, immagino che lo stesso processo possa essere applicato per generare altri tipi di dati ad alta dimensionalità che possono essere rappresentati come array multidimensionali<a data-startref="ix_ch03-asciidoc31" data-type="indexterm" id="id699"/><a data-startref="ix_ch03-asciidoc30" data-type="indexterm" id="id700"/><a data-startref="ix_ch03-asciidoc29" data-type="indexterm" id="id701"/><a data-startref="ix_ch03-asciidoc29a" data-type="indexterm" id="id702"/> <a data-startref="ix_ch03-asciidoc29b" data-type="indexterm" id="id703"/> .<a data-startref="ix_ch03-asciidoc28" data-type="indexterm" id="id704"/></p>
<p>Ora dovresti sentirti più a tuo agio nella creazione di servizi con modelli di testo, audio, visione e video. Poi, diamo un'occhiata a un'altra serie di modelli in grado di generare dati complessi come le geometrie 3D costruendo un servizio di generatore di asset 3D.</p>
</div></section>
</div></section>
<section data-pdf-bookmark="3D Models" data-type="sect2"><div class="sect2" id="id52">
<h2>Modelli 3D</h2>
<p><a data-primary="3D models" data-primary-sortas="threeD" data-type="indexterm" id="ix_ch03-asciidoc32"/><a data-primary="serving GenAI models" data-secondary="3D models" data-secondary-sortas="threeD" data-type="indexterm" id="ix_ch03-asciidoc33"/>Ora hai capito come i modelli precedentemente citati utilizzano trasformatori e diffusori per generare qualsiasi forma di dati testuali, audio o visivi. La produzione di geometrie 3D richiede un approccio diverso rispetto alla generazione di immagini, audio e testi, perché devi tenere conto delle relazioni spaziali, delle informazioni sulla profondità e della coerenza geometrica, che aggiungono livelli di complessità non presenti in altri tipi di dati.</p>
<p><a data-primary="meshes" data-type="indexterm" id="ix_ch03-asciidoc34"/>Per le geometrie 3D, le <em>mesh</em> vengono utilizzate per definire la forma di un oggetto. Pacchetti software come Autodesk 3ds Max, Maya e SolidWorks possono essere utilizzati per produrre, modificare e renderizzare queste mesh.</p>
<p>Le mesh sono effettivamente una collezione di <em>vertici</em>, <em>bordi</em> e <em>facce</em> che risiedono in uno spazio virtuale 3D. I vertici sono punti nello spazio che si collegano per formare i bordi. I bordi formano le facce (poligoni) quando si racchiudono su una superficie piana, spesso a forma di triangolo o quadrilatero. La<a data-type="xref" href="#vertices_edges_faces">Figura 3-24</a> mostra le differenze tra vertici, bordi e facce.</p>
<figure><div class="figure" id="vertices_edges_faces">
<img alt="bgai 0324" src="assets/bgai_0324.png" width="785" height="307"/>
<h6><span class="label">Figura 3-24. </span>Vertici, bordi e facce</h6>
</div></figure>
<p>Puoi definire i vertici in base alle loro coordinate in uno spazio 3D, solitamente determinate da un sistema di coordinate cartesiane (x, y, z). In sostanza, la disposizione e la connessione dei vertici formano le superfici di una maglia 3D che definiscono una geometria.</p>
<p>La<a data-type="xref" href="#mesh">Figura 3-25</a> mostra come queste caratteristiche si combinano per definire una mesh di una geometria 3D come la testa di una scimmia.</p>
<figure><div class="figure" id="mesh">
<img alt="bgai 0325" src="assets/bgai_0325.png" width="2490" height="1442"/>
<h6><span class="label">Figura 3-25. </span>Mesh per la geometria 3D di una testa di scimmia che utilizza poligoni triangolari e<span class="keep-together">quadrilateri</span> (mostrato in Blender, software di modellazione 3D open source)</h6>
</div></figure>
<p>Puoi addestrare e utilizzare un modello trasformatore per prevedere il prossimo token di una sequenza in cui la sequenza è costituita da coordinate di vertici su una superficie mesh 3D. Un modello generativo di questo tipo può produrre geometrie 3D prevedendo il prossimo set di vertici e facce all'interno di uno spazio 3D che formano la geometria desiderata. Tuttavia, la geometria richiederebbe migliaia di vertici e facce per ottenere una superficie liscia.</p>
<p>Ciò significa che per ogni oggetto 3D è necessario attendere a lungo il completamento della generazione e che i risultati possono rimanere a bassa fedeltà. Per questo motivo, i modelli più efficaci (ad esempio Shap-E di OpenAI) nella produzione di geometrie 3D utilizzano funzioni (con molti parametri) per definire implicitamente superfici e volumi in uno spazio 3D.</p>
<p><a data-primary="implicit functions" data-type="indexterm" id="id705"/>Le funzioni implicite sono utili per creare superfici lisce o per gestire dettagli intricati che sono difficili da gestire per le rappresentazioni discrete come le mesh. Un modello addestrato può consistere in un codificatore che mappa i modelli in una funzione implicita.<a data-primary="conditional 3D GenAI models" data-primary-sortas="conditional threeD GenAI models" data-type="indexterm" id="id706"/>Invece di generare esplicitamente sequenze di vertici e facce per una mesh, i modelli 3D<em>condizionali</em> possono valutare le funzioni implicite addestrate in uno spazio 3D continuo. Di conseguenza, il processo di generazione ha un alto grado di libertà, controllo e flessibilità nella produzione di output ad alta fedeltà, diventando adatto per le applicazioni che richiedono geometrie 3D dettagliate e intricate.</p>
<p><a data-primary="neural radiance fields (NeRF)" data-type="indexterm" id="id707"/>Una volta che l'encoder del modello è stato addestrato a produrre funzioni implicite, sfrutta la tecnica di rendering dei <em>campi di radianza neurale</em> (NeRF), come parte del decodificatore, per costruire scene 3D. NeRF mappa una coppia di input - una coordinata spaziale 3D e una direzione di visione 3D - in un output costituito da una densità di oggetti e da un colore RGB tramite le funzioni implicite.
Per sintetizzare nuove viste in una scena 3D, il metodo NeRF considera la finestra di visualizzazione come una matrice di raggi. Ogni pixel corrispondente a un raggio ha origine dalla posizione della telecamera e si estende nella direzione di visualizzazione. Il colore di ogni raggio e del pixel associato viene calcolato valutando la funzione implicita lungo il raggio e integrando i risultati per calcolare il colore RGB.</p>
<p><a data-primary="signed distance functions (SDFs)" data-type="indexterm" id="id708"/><a data-primary="SDFs (signed distance functions)" data-type="indexterm" id="id709"/>Una volta calcolata la scena 3D, le <em>funzioni di distanza firmata</em> (SDF) vengono utilizzate per generare mesh o wireframe di oggetti 3D calcolando la distanza e il colore di ogni punto rispetto alla superficie più vicina dell'oggetto 3D. Pensa alle SDF come a un modo per descrivere un oggetto 3D indicando la distanza di ogni punto nello spazio dalla superficie dell'oggetto.
Questa funzione fornisce un numero per ogni punto: se il punto si trova all'interno dell'oggetto, il numero è negativo; se si trova sulla superficie, il numero è zero; se si trova all'esterno, il numero è positivo. La superficie dell'oggetto è quella in cui tutti i punti hanno il numero zero. Le SDF aiutano a trasformare queste informazioni in una mesh 3D.</p>
<p>Nonostante l'uso di funzioni implicite, la qualità dei risultati è ancora inferiore a quella degli asset 3D creati dall'uomo e può sembrare un cartone animato. Tuttavia, con i modelli 3D GenAI puoi generare le geometrie 3D iniziali per iterare i concetti e perfezionare gli asset 3D in modo rapido.</p>
<section data-pdf-bookmark="OpenAI Shap-E" data-type="sect3"><div class="sect3" id="id53">
<h3>OpenAI Shap-E</h3>
<p><a data-primary="OpenAI Shap-E" data-type="indexterm" id="ix_ch03-asciidoc35"/><a data-primary="serving GenAI models" data-secondary="OpenAI Shap-E" data-type="indexterm" id="ix_ch03-asciidoc36"/><em>Shap-E</em> (sviluppato da OpenAI) è un modello open source che "condiziona" i dati 3D in ingresso (descrizioni, parametri, geometrie parziali, colori, ecc.) per generare forme 3D specifiche. Puoi usare Shap-E per creare un'immagine o servizi text-to-3D.</p>
<p>Come al solito, si inizia scaricando e caricando il modello da Hugging Face, come mostrato nell'<a data-type="xref" href="#loading_shap-e">Esempio 3-13</a>.</p>
<div data-type="example" id="loading_shap-e">
<h5><span class="label">Esempio 3-13. </span>Scaricare e caricare il modello Shap-E di OpenAI</h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># models.py</code><code translate="no">
</code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="nn" translate="no">torch</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">diffusers</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">ShapEPipeline</code><code translate="no">
</code><code translate="no">
</code><code class="n" translate="no">device</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">torch</code><code class="o" translate="no">.</code><code class="n" translate="no">device</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">cuda</code><code class="s2" translate="no">"</code><code translate="no"> </code><code class="k" translate="no">if</code><code translate="no"> </code><code class="n" translate="no">torch</code><code class="o" translate="no">.</code><code class="n" translate="no">cuda</code><code class="o" translate="no">.</code><code class="n" translate="no">is_available</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="k" translate="no">else</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">cpu</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">load_3d_model</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">-</code><code class="o" translate="no">&gt;</code><code translate="no"> </code><code class="n" translate="no">ShapEPipeline</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">pipe</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">ShapEPipeline</code><code class="o" translate="no">.</code><code class="n" translate="no">from_pretrained</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">openai/shap-e</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">device</code><code class="o" translate="no">=</code><code class="n" translate="no">device</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">pipe</code><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">generate_3d_geometry</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">pipe</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">ShapEPipeline</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">prompt</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">str</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">num_inference_steps</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">int</code><code translate="no">
</code><code class="p" translate="no">)</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">images</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">pipe</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">prompt</code><code class="p" translate="no">,</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO13-1" id="co_ai_integration_and_model_serving_CO13-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">guidance_scale</code><code class="o" translate="no">=</code><code class="mf" translate="no">15.0</code><code class="p" translate="no">,</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO13-2" id="co_ai_integration_and_model_serving_CO13-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">num_inference_steps</code><code class="o" translate="no">=</code><code class="n" translate="no">num_inference_steps</code><code class="p" translate="no">,</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO13-3" id="co_ai_integration_and_model_serving_CO13-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">output_type</code><code class="o" translate="no">=</code><code class="s2" translate="no">"</code><code class="s2" translate="no">mesh</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO13-4" id="co_ai_integration_and_model_serving_CO13-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="p" translate="no">)</code><code class="o" translate="no">.</code><code class="n" translate="no">images</code><code class="p" translate="no">[</code><code class="mi" translate="no">0</code><code class="p" translate="no">]</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO13-5" id="co_ai_integration_and_model_serving_CO13-5"><img alt="5" src="assets/5.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">images</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO13-1" id="callout_ai_integration_and_model_serving_CO13-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Questa specifica pipeline di Shap-E accetta prompt testuali, ma se vuoi passare prompt di immagini, devi caricare una pipeline diversa.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO13-2" id="callout_ai_integration_and_model_serving_CO13-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a></dt>
<dd><p>Utilizza il parametro <code translate="no">guidance_scale</code> per regolare il processo di generazione in modo da adattarlo meglio al prompt.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO13-3" id="callout_ai_integration_and_model_serving_CO13-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a></dt>
<dd><p>Utilizza il parametro <code translate="no">num_inference_steps</code> per controllare la risoluzione dell'output in cambio di calcoli aggiuntivi. Richiedendo un numero maggiore di passi di inferenza o aumentando la scala di guida puoi allungare i tempi di rendering in cambio di output di qualità superiore che seguono meglio le richieste dell'utente.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO13-4" id="callout_ai_integration_and_model_serving_CO13-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a></dt>
<dd><p>Imposta il parametro <code translate="no">output_type</code> per produrre i tensori <code translate="no">mesh</code> come output.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO13-5" id="callout_ai_integration_and_model_serving_CO13-5"><img alt="5" src="assets/5.png" width="12" height="12"/></a></dt>
<dd><p>Per impostazione predefinita, la pipeline Shap-E produce una sequenza di immagini che possono essere combinate per generare un'animazione GIF rotante dell'oggetto. Puoi esportare questo output in GIF, video o file OBJ che possono essere caricati in strumenti di modellazione 3D come Blender.</p></dd>
</dl></div>
<p>Ora che disponi delle funzioni di caricamento del modello e di generazione della mesh 3D, esporta la mesh in un buffer utilizzando l'<a data-type="xref" href="#mesh_to_buffer">Esempio 3-14</a>.</p>
<div data-type="tip"><h6>Suggerimento</h6>
<p><code translate="no">open3d</code> è una libreria open source per l'elaborazione di dati 3D come nuvole di punti, mesh e immagini a colori con informazioni sulla profondità (ad esempio, immagini RGB-D). Per eseguire l'<a data-type="xref" href="#mesh_to_buffer">Esempio 3-14</a> è necessario installare <code translate="no">open3d</code>:</p>
<pre data-code-language="bash" data-type="programlisting" translate="no">$<code class="w" translate="no"> </code>pip<code class="w" translate="no"> </code>install<code class="w" translate="no"> </code>open3d<code class="w" translate="no"/></pre>
</div>
<div data-type="example" id="mesh_to_buffer">
<h5><span class="label">Esempio 3-14. </span>Esportazione di una mesh tensoriale 3D in un buffer OBJ Wavefront</h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># utils.py</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="nn" translate="no">os</code><code translate="no">
</code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="nn" translate="no">tempfile</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">io</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">BytesIO</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">pathlib</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">Path</code><code translate="no">
</code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="nn" translate="no">open3d</code><code translate="no"> </code><code class="k" translate="no">as</code><code translate="no"> </code><code class="nn" translate="no">o3d</code><code translate="no">
</code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="nn" translate="no">torch</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">diffusers</code><code class="nn" translate="no">.</code><code class="nn" translate="no">pipelines</code><code class="nn" translate="no">.</code><code class="nn" translate="no">shap_e</code><code class="nn" translate="no">.</code><code class="nn" translate="no">renderer</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">MeshDecoderOutput</code><code translate="no">
</code><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">mesh_to_obj_buffer</code><code class="p" translate="no">(</code><code class="n" translate="no">mesh</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">MeshDecoderOutput</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">-</code><code class="o" translate="no">&gt;</code><code translate="no"> </code><code class="n" translate="no">BytesIO</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">mesh_o3d</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">o3d</code><code class="o" translate="no">.</code><code class="n" translate="no">geometry</code><code class="o" translate="no">.</code><code class="n" translate="no">TriangleMesh</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO14-1" id="co_ai_integration_and_model_serving_CO14-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">mesh_o3d</code><code class="o" translate="no">.</code><code class="n" translate="no">vertices</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">o3d</code><code class="o" translate="no">.</code><code class="n" translate="no">utility</code><code class="o" translate="no">.</code><code class="n" translate="no">Vector3dVector</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">mesh</code><code class="o" translate="no">.</code><code class="n" translate="no">verts</code><code class="o" translate="no">.</code><code class="n" translate="no">cpu</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code class="o" translate="no">.</code><code class="n" translate="no">detach</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code class="o" translate="no">.</code><code class="n" translate="no">numpy</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO14-2" id="co_ai_integration_and_model_serving_CO14-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">mesh_o3d</code><code class="o" translate="no">.</code><code class="n" translate="no">triangles</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">o3d</code><code class="o" translate="no">.</code><code class="n" translate="no">utility</code><code class="o" translate="no">.</code><code class="n" translate="no">Vector3iVector</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">mesh</code><code class="o" translate="no">.</code><code class="n" translate="no">faces</code><code class="o" translate="no">.</code><code class="n" translate="no">cpu</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code class="o" translate="no">.</code><code class="n" translate="no">detach</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code class="o" translate="no">.</code><code class="n" translate="no">numpy</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO14-2" id="co_ai_integration_and_model_serving_CO14-3"><img alt="2" src="assets/2.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">if</code><code translate="no"> </code><code class="nb" translate="no">len</code><code class="p" translate="no">(</code><code class="n" translate="no">mesh</code><code class="o" translate="no">.</code><code class="n" translate="no">vertex_channels</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">==</code><code translate="no"> </code><code class="mi" translate="no">3</code><code class="p" translate="no">:</code><code translate="no">  </code><code class="c1" translate="no"># You have color channels</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">vert_color</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">torch</code><code class="o" translate="no">.</code><code class="n" translate="no">stack</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">            </code><code class="p" translate="no">[</code><code class="n" translate="no">mesh</code><code class="o" translate="no">.</code><code class="n" translate="no">vertex_channels</code><code class="p" translate="no">[</code><code class="n" translate="no">channel</code><code class="p" translate="no">]</code><code translate="no"> </code><code class="k" translate="no">for</code><code translate="no"> </code><code class="n" translate="no">channel</code><code translate="no"> </code><code class="ow" translate="no">in</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">RGB</code><code class="s2" translate="no">"</code><code class="p" translate="no">]</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">dim</code><code class="o" translate="no">=</code><code class="mi" translate="no">1</code><code translate="no">
</code><code translate="no">        </code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO14-3" id="co_ai_integration_and_model_serving_CO14-4"><img alt="3" src="assets/3.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">mesh_o3d</code><code class="o" translate="no">.</code><code class="n" translate="no">vertex_colors</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">o3d</code><code class="o" translate="no">.</code><code class="n" translate="no">utility</code><code class="o" translate="no">.</code><code class="n" translate="no">Vector3dVector</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">            </code><code class="n" translate="no">vert_color</code><code class="o" translate="no">.</code><code class="n" translate="no">cpu</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code class="o" translate="no">.</code><code class="n" translate="no">detach</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code class="o" translate="no">.</code><code class="n" translate="no">numpy</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">        </code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO14-4" id="co_ai_integration_and_model_serving_CO14-5"><img alt="4" src="assets/4.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">with</code><code translate="no"> </code><code class="n" translate="no">tempfile</code><code class="o" translate="no">.</code><code class="n" translate="no">NamedTemporaryFile</code><code class="p" translate="no">(</code><code class="n" translate="no">delete</code><code class="o" translate="no">=</code><code class="kc" translate="no">False</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">suffix</code><code class="o" translate="no">=</code><code class="s2" translate="no">"</code><code class="s2" translate="no">.obj</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="k" translate="no">as</code><code translate="no"> </code><code class="n" translate="no">tmp</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">o3d</code><code class="o" translate="no">.</code><code class="n" translate="no">io</code><code class="o" translate="no">.</code><code class="n" translate="no">write_triangle_mesh</code><code class="p" translate="no">(</code><code class="n" translate="no">tmp</code><code class="o" translate="no">.</code><code class="n" translate="no">name</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">mesh_o3d</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">write_ascii</code><code class="o" translate="no">=</code><code class="kc" translate="no">True</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">        </code><code class="k" translate="no">with</code><code translate="no"> </code><code class="nb" translate="no">open</code><code class="p" translate="no">(</code><code class="n" translate="no">tmp</code><code class="o" translate="no">.</code><code class="n" translate="no">name</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">rb</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="k" translate="no">as</code><code translate="no"> </code><code class="n" translate="no">f</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">            </code><code class="n" translate="no">buffer</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">BytesIO</code><code class="p" translate="no">(</code><code class="n" translate="no">f</code><code class="o" translate="no">.</code><code class="n" translate="no">read</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO14-5" id="co_ai_integration_and_model_serving_CO14-6"><img alt="5" src="assets/5.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">os</code><code class="o" translate="no">.</code><code class="n" translate="no">remove</code><code class="p" translate="no">(</code><code class="n" translate="no">tmp</code><code class="o" translate="no">.</code><code class="n" translate="no">name</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO14-6" id="co_ai_integration_and_model_serving_CO14-7"><img alt="6" src="assets/6.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">buffer</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO14-1" id="callout_ai_integration_and_model_serving_CO14-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Crea un oggetto mesh triangolare Open3D.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO14-2" id="callout_ai_integration_and_model_serving_CO14-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a></dt>
<dd><p>Convertire la mesh generata dal modello in un oggetto mesh triangolare Open3D. Per fare ciò, prendi i vertici e i triangoli dalla mesh 3D generata spostando i tensori dei vertici e delle facce della mesh sulla CPU e convertendoli in array <code translate="no">numpy</code>.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO14-4" id="callout_ai_integration_and_model_serving_CO14-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a></dt>
<dd><p>Controlla se il mesh ha tre canali di colore dei vertici (che indicano i dati dei colori RGB) e impila questi canali in un tensore.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO14-5" id="callout_ai_integration_and_model_serving_CO14-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a></dt>
<dd><p>Converte il tensore del colore della mesh in un formato compatibile con Open3D per impostare i colori dei vertici della mesh.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO14-6" id="callout_ai_integration_and_model_serving_CO14-5"><img alt="5" src="assets/5.png" width="12" height="12"/></a></dt>
<dd><p>Utilizza un file temporaneo per creare e restituire un buffer di dati.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO14-7" id="callout_ai_integration_and_model_serving_CO14-6"><img alt="6" src="assets/6.png" width="12" height="12"/></a></dt>
<dd><p>Windows non supporta l'opzione <code translate="no">NameTemporaryFile</code>'<code translate="no">delete=True</code>. Invece, rimuovi manualmente il file temporaneo creato appena prima di restituire il buffer in memoria.</p></dd>
</dl></div>
<p class="less_space pagebreak-before">Infine, puoi creare gli endpoint, come mostrato nell'<a data-type="xref" href="#shap-e_endpoint">esempio 3-15</a>.</p>
<div data-type="example" id="shap-e_endpoint">
<h5><span class="label">Esempio 3-15. </span>Creazione dell'endpoint di servizio del modello 3D</h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># main.py</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">fastapi</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">FastAPI</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">status</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">fastapi</code><code class="nn" translate="no">.</code><code class="nn" translate="no">responses</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">StreamingResponse</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">models</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">load_3d_model</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">generate_3d_geometry</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">utils</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">mesh_to_obj_buffer</code><code translate="no">
</code><code translate="no">
</code><code class="o" translate="no">.</code><code class="o" translate="no">.</code><code class="o" translate="no">.</code><code translate="no">
</code><code translate="no">
</code><code class="nd" translate="no">@app</code><code class="o" translate="no">.</code><code class="n" translate="no">get</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">    </code><code class="s2" translate="no">"</code><code class="s2" translate="no">/generate/3d</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">responses</code><code class="o" translate="no">=</code><code class="p" translate="no">{</code><code class="n" translate="no">status</code><code class="o" translate="no">.</code><code class="n" translate="no">HTTP_200_OK</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">content</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">model/obj</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="p" translate="no">{</code><code class="p" translate="no">}</code><code class="p" translate="no">}</code><code class="p" translate="no">}</code><code class="p" translate="no">}</code><code class="p" translate="no">,</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO15-1" id="co_ai_integration_and_model_serving_CO15-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">response_class</code><code class="o" translate="no">=</code><code class="n" translate="no">StreamingResponse</code><code class="p" translate="no">,</code><code translate="no">
</code><code class="p" translate="no">)</code><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">serve_text_to_3d_model_controller</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">prompt</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">str</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">num_inference_steps</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">int</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="mi" translate="no">25</code><code translate="no">
</code><code class="p" translate="no">)</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">model</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">load_3d_model</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">mesh</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">generate_3d_geometry</code><code class="p" translate="no">(</code><code class="n" translate="no">model</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">prompt</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">num_inference_steps</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">response</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">StreamingResponse</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">mesh_to_obj_buffer</code><code class="p" translate="no">(</code><code class="n" translate="no">mesh</code><code class="p" translate="no">)</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">media_type</code><code class="o" translate="no">=</code><code class="s2" translate="no">"</code><code class="s2" translate="no">model/obj</code><code class="s2" translate="no">"</code><code translate="no">
</code><code translate="no">    </code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">response</code><code class="o" translate="no">.</code><code class="n" translate="no">headers</code><code class="p" translate="no">[</code><code class="s2" translate="no">"</code><code class="s2" translate="no">Content-Disposition</code><code class="s2" translate="no">"</code><code class="p" translate="no">]</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">        </code><code class="sa" translate="no">f</code><code class="s2" translate="no">"</code><code class="s2" translate="no">attachment; filename=</code><code class="si" translate="no">{</code><code class="n" translate="no">prompt</code><code class="si" translate="no">}</code><code class="s2" translate="no">.obj</code><code class="s2" translate="no">"</code><code translate="no">
</code><code translate="no">    </code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO15-2" id="co_ai_integration_and_model_serving_CO15-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">response</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO15-1" id="callout_ai_integration_and_model_serving_CO15-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Specifica la specifica OpenAPI per una risposta di successo che includa <code translate="no">model/obj</code> come tipo di contenuto multimediale.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO15-2" id="callout_ai_integration_and_model_serving_CO15-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a></dt>
<dd><p>Indica ai client che il contenuto della risposta in streaming deve essere trattato come un allegato.</p></dd>
</dl></div>
<p>Se invii una richiesta all'endpoint <code translate="no">/generate/3d</code>, il download dell'oggetto 3D come file OBJ Wavefront dovrebbe iniziare non appena la generazione è completata.</p>
<p>Puoi importare il file OBJ in qualsiasi software di modellazione 3D, come Blender, per visualizzare la geometria 3D. Utilizzando prompt come <code translate="no">apple</code>, <code translate="no">car</code>, <code translate="no">phone</code> e <code translate="no">donut</code>puoi generare le geometrie 3D mostrate nella <a data-type="xref" href="#shape_e_blender">Figura 3-26</a>.</p>
<figure><div class="figure" id="shape_e_blender">
<img alt="bgai 0326" src="assets/bgai_0326.png" width="3024" height="1716"/>
<h6><span class="label">Figura 3-26. </span>Geometrie 3D di un'automobile, una mela, un telefono e una ciambella importate in Blender</h6>
</div></figure>
<p>Se isoli un oggetto come la mela e attivi la vista wireframe, puoi vedere tutti i vertici e gli spigoli che compongono la maglia della mela, rappresentati come poligoni triangolari, come mostrato all'indirizzo<a data-startref="ix_ch03-asciidoc36" data-type="indexterm" id="id710"/> nella <a data-type="xref" href="#shape_e_apple_wireframe">Figura 3-27</a>.</p>
<figure><div class="figure" id="shape_e_apple_wireframe">
<img alt="bgai 0327" src="assets/bgai_0327.png" width="1442" height="876"/>
<h6><span class="label">Figura 3-27. </span>Ingrandimento della mesh 3D generata per visualizzare i poligoni triangolari; in basso: visualizzazione della mesh della geometria della mela generata (inclusi vertici e bordi).</h6>
</div></figure>
<p>Shap-E sostituisce un altro modello più vecchio, chiamato <em>Point-E</em>, che genera <em>nuvole di punti</em><span class="keep-together">di oggetti 3D.</span>Questo perché Shap-E, rispetto a Point-E, converge più velocemente e<span class="keep-together">raggiunge una</span> qualità di generazione della forma paragonabile o migliore, nonostante la modellazione di uno spazio di output multidimensionale e multirappresentazione.<a data-startref="ix_ch03-asciidoc35" data-type="indexterm" id="id711"/><a data-startref="ix_ch03-asciidoc34" data-type="indexterm" id="id712"/></p>
<p>Le nuvole di punti (spesso utilizzate nel settore edile) sono un'ampia raccolta di coordinate di punti che rappresentano fedelmente un oggetto 3D (come la struttura di un edificio) in uno spazio reale. I dispositivi di scansione ambientale, come gli scanner laser LiDAR, producono nuvole di punti per rappresentare gli oggetti all'interno di uno spazio 3D con misure approssimative vicine all'ambiente reale.</p>
<p>Con il miglioramento dei modelli 3D, potrebbe essere possibile generare oggetti che rappresentano fedelmente le loro controparti reali<a data-startref="ix_ch03-asciidoc33" data-type="indexterm" id="id713"/><a data-startref="ix_ch03-asciidoc32" data-type="indexterm" id="id714"/>.<a data-startref="ix_ch03-asciidoc0" data-type="indexterm" id="id715"/></p>
</div></section>
</div></section>
</div></section>
<section data-pdf-bookmark="Strategies for Serving Generative AI Models" data-type="sect1"><div class="sect1" id="id54">
<h1>Strategie per servire i modelli di intelligenza artificiale generativa</h1>
<p><a data-primary="serving GenAI models" data-secondary="strategies" data-type="indexterm" id="ix_ch03-asciidoc37"/>Ora dovresti sentirti più sicuro nel creare i tuoi endpoint che servono una varietà di modelli dal repository di modelli di Hugging Face. Abbiamo toccato alcuni modelli diversi, tra cui quelli che generano testo, immagini, video, audio e forme 3D.</p>
<p>I modelli utilizzati erano piccoli, quindi potevano essere caricati e utilizzati su una CPU con risultati ragionevoli.<a data-primary="video random access memory (VRAM)" data-type="indexterm" id="id716"/>Tuttavia, in uno scenario di produzione, potresti voler utilizzare modelli più grandi per produrre risultati di qualità superiore che potrebbero essere eseguiti solo su GPU e richiedere una quantità significativa di memoria video ad accesso casuale (VRAM).</p>
<p>Oltre a sfruttare le GPU, dovrai scegliere una strategia di model-serving tra diverse opzioni:</p>
<dl>
<dt>Sii agnostico rispetto al modello</dt>
<dd>
<p>Carica i modelli e genera gli output a ogni richiesta (utile per lo scambio di modelli).</p>
</dd>
<dt>Essere efficiente dal punto di vista del calcolo</dt>
<dd>
<p>Utilizza la FastAPI lifespan per precaricare i modelli che possono essere riutilizzati per ogni richiesta.</p>
</dd>
<dt>Sii snello</dt>
<dd>
<p>Servire i modelli all'esterno senza framework o lavorare con API di modelli di terze parti e interagire con esse tramite FastAPI.</p>
</dd>
</dl>
<p>Vediamo nel dettaglio ogni strategia.</p>
<section data-pdf-bookmark="Be Model Agnostic: Swap Models on Every Request" data-type="sect2"><div class="sect2" id="id55">
<h2>Sii agnostico: scambia i modelli ad ogni richiesta</h2>
<p><a data-primary="model swapping (model-serving strategy)" data-type="indexterm" id="ix_ch03-asciidoc38"/><a data-primary="serving GenAI models" data-secondary="strategies" data-tertiary="model agnostic: swapping models on every request" data-type="indexterm" id="ix_ch03-asciidoc39"/>Negli esempi di codice precedenti, hai definito le funzioni di caricamento e generazione del modello e poi le hai utilizzate nei controller dei route handler. Utilizzando questa strategia di servizio, FastAPI carica un modello nella RAM (o nella VRAM se si utilizza una GPU) ed esegue un processo di generazione. Una volta che FastAPI restituisce i risultati, il modello viene scaricato dalla RAM. Il processo si ripete per la richiesta successiva.</p>
<p>Quando il modello viene scaricato dopo l'uso, la memoria viene liberata per essere utilizzata da un altro processo o modello. Con questo approccio, puoi scambiare dinamicamente vari modelli in un'unica richiesta se il tempo di elaborazione non è un problema. Ciò significa che altre richieste concorrenti devono aspettare prima che il server risponda.</p>
<p>Quando serve le richieste, FastAPI mette in coda le richieste in arrivo e le elabora in un ordine "first in first out" (FIFO). Questo comportamento comporta lunghi tempi di attesa perché un modello deve essere caricato e scaricato ogni volta. Nella maggior parte dei casi, questa strategia non è consigliata, ma se hai bisogno di scambiare tra più modelli di grandi dimensioni e non hai sufficiente RAM, allora puoi adottarla per la prototipazione. Tuttavia, negli scenari di produzione, non dovresti mai usare questa strategia per ovvie ragioni: i tuoi utenti vorranno evitare i lunghi tempi di attesa.</p>
<p><a data-type="xref" href="#model_loading_on_request">La Figura 3-28</a> mostra questo modello di strategia di servizio.</p>
<figure><div class="figure" id="model_loading_on_request">
<img alt="bgai 0329" src="assets/bgai_0329.png" width="1106" height="983"/>
<h6><span class="label">Figura 3-28. </span>Caricamento e utilizzo dei modelli ad ogni richiesta</h6>
</div></figure>
<p>Se hai bisogno di usare modelli diversi per ogni richiesta e hai una memoria limitata, questo metodo può funzionare bene per fare delle prove veloci su un computer meno potente con pochi utenti. Il compromesso è un tempo di elaborazione significativamente più lento a causa dello<span class="keep-together">scambio dei</span>modelli<span class="keep-together">.</span>Tuttavia, negli scenari di produzione, è meglio avere una RAM più grande e usare la strategia di precaricamento dei modelli con la durata dell'applicazione FastAPI.<a data-startref="ix_ch03-asciidoc39" data-type="indexterm" id="id717"/><a data-startref="ix_ch03-asciidoc38" data-type="indexterm" id="id718"/></p>
</div></section>
<section data-pdf-bookmark="Be Compute Efficient: Preload Models with the FastAPI Lifespan" data-type="sect2"><div class="sect2" id="id56">
<h2>Efficienza di calcolo: Precaricare i modelli con la durata di vita di FastAPI</h2>
<p><a data-primary="application lifespan" data-type="indexterm" id="ix_ch03-asciidoc40"/><a data-primary="model preloading (model-serving strategy)" data-type="indexterm" id="ix_ch03-asciidoc41"/><a data-primary="serving GenAI models" data-secondary="strategies" data-tertiary="compute efficient: preloading models with FastAPI lifespan" data-type="indexterm" id="ix_ch03-asciidoc42"/>La strategia più efficiente dal punto di vista dei calcoli per caricare i modelli in FastAPI è quella di utilizzare la durata di vita dell'applicazione. Con questo approccio, carichi i modelli all'avvio dell'applicazione e li scarichi allo spegnimento. Durante lo spegnimento, puoi anche eseguire tutte le operazioni di pulizia necessarie, come la pulizia del filesystem o la registrazione.</p>
<p>Il vantaggio principale di questa strategia rispetto alla prima è che eviti di ricaricare i modelli pesanti a ogni richiesta. Puoi caricare un modello pesante una volta sola e poi eseguire le generazioni a ogni richiesta che arriva utilizzando un modello precaricato. Di conseguenza, risparmierai diversi minuti di tempo di elaborazione in cambio di una parte significativa della tua RAM (o VRAM se usi la GPU). Tuttavia, l'esperienza dell'utente dell'applicazione migliorerà notevolmente grazie ai tempi di risposta più brevi.</p>
<p>La<a data-type="xref" href="#model_loading_lifespan">Figura 3-29</a> mostra la strategia di model-serving che utilizza l'application lifespan.</p>
<figure><div class="figure" id="model_loading_lifespan">
<img alt="bgai 0330" src="assets/bgai_0330.png" width="1284" height="1144"/>
<h6><span class="label">Figura 3-29. </span>Utilizzo dell'applicazione FastAPI per precaricare i modelli</h6>
</div></figure>
<p>Puoi implementare il precaricamento del modello utilizzando l'applicazione lifespan, come mostrato nell'<a data-type="xref" href="#model_preloading_lifespan">Esempio 3-16</a>.</p>
<div data-type="example" id="model_preloading_lifespan">
<h5><span class="label">Esempio 3-16. </span>Precaricamento del modello con l'applicazione lifespan</h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># main.py</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">contextlib</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">asynccontextmanager</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">typing</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">AsyncIterator</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">fastapi</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">FastAPI</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">Response</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">status</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">models</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">load_image_model</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">generate_image</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">utils</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">img_to_bytes</code><code translate="no">
</code><code translate="no">
</code><code class="n" translate="no">models</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="p" translate="no">{</code><code class="p" translate="no">}</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO16-1" id="co_ai_integration_and_model_serving_CO16-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">
</code><code class="nd" translate="no">@asynccontextmanager</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO16-2" id="co_ai_integration_and_model_serving_CO16-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a><code translate="no">
</code><code class="k" translate="no">async</code><code translate="no"> </code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">lifespan</code><code class="p" translate="no">(</code><code class="n" translate="no">_</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">FastAPI</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">-</code><code class="o" translate="no">&gt;</code><code translate="no"> </code><code class="n" translate="no">AsyncIterator</code><code class="p" translate="no">[</code><code class="kc" translate="no">None</code><code class="p" translate="no">]</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">models</code><code class="p" translate="no">[</code><code class="s2" translate="no">"</code><code class="s2" translate="no">text2image</code><code class="s2" translate="no">"</code><code class="p" translate="no">]</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">load_image_model</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO16-3" id="co_ai_integration_and_model_serving_CO16-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">yield</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO16-4" id="co_ai_integration_and_model_serving_CO16-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">
</code><code translate="no">    </code><code class="o" translate="no">.</code><code class="o" translate="no">.</code><code class="o" translate="no">.</code><code translate="no"> </code><code class="c1" translate="no"># Run cleanup code here</code><code translate="no">
</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">models</code><code class="o" translate="no">.</code><code class="n" translate="no">clear</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO16-5" id="co_ai_integration_and_model_serving_CO16-5"><img alt="5" src="assets/5.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">
</code><code class="n" translate="no">app</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">FastAPI</code><code class="p" translate="no">(</code><code class="n" translate="no">lifespan</code><code class="o" translate="no">=</code><code class="n" translate="no">lifespan</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO16-6" id="co_ai_integration_and_model_serving_CO16-6"><img alt="6" src="assets/6.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">
</code><code class="nd" translate="no">@app</code><code class="o" translate="no">.</code><code class="n" translate="no">get</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">    </code><code class="s2" translate="no">"</code><code class="s2" translate="no">/generate/image</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">responses</code><code class="o" translate="no">=</code><code class="p" translate="no">{</code><code class="n" translate="no">status</code><code class="o" translate="no">.</code><code class="n" translate="no">HTTP_200_OK</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">content</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">image/png</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="p" translate="no">{</code><code class="p" translate="no">}</code><code class="p" translate="no">}</code><code class="p" translate="no">}</code><code class="p" translate="no">}</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">response_class</code><code class="o" translate="no">=</code><code class="n" translate="no">Response</code><code class="p" translate="no">,</code><code translate="no">
</code><code class="p" translate="no">)</code><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">serve_text_to_image_model_controller</code><code class="p" translate="no">(</code><code class="n" translate="no">prompt</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">str</code><code class="p" translate="no">)</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">output</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">generate_image</code><code class="p" translate="no">(</code><code class="n" translate="no">models</code><code class="p" translate="no">[</code><code class="s2" translate="no">"</code><code class="s2" translate="no">text2image</code><code class="s2" translate="no">"</code><code class="p" translate="no">]</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">prompt</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO16-7" id="co_ai_integration_and_model_serving_CO16-7"><img alt="7" src="assets/7.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">Response</code><code class="p" translate="no">(</code><code class="n" translate="no">content</code><code class="o" translate="no">=</code><code class="n" translate="no">img_to_bytes</code><code class="p" translate="no">(</code><code class="n" translate="no">output</code><code class="p" translate="no">)</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">media_type</code><code class="o" translate="no">=</code><code class="s2" translate="no">"</code><code class="s2" translate="no">image/png</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO16-1" id="callout_ai_integration_and_model_serving_CO16-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Inizializza un dizionario mutabile vuoto nell'ambito dell'applicazione <em>globale</em> per contenere uno o più modelli.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO16-2" id="callout_ai_integration_and_model_serving_CO16-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a></dt>
<dd><p><a data-primary="async context manager" data-type="indexterm" id="id719"/>Utilizza il decoratore <code translate="no">asynccontextmanager</code> per gestire gli eventi di avvio e chiusura come parte di un gestore di contesto asincrono:</p>
<ul>
<li>
<p>Il gestore del contesto eseguirà il codice prima e dopo la parola chiave <code translate="no">yield</code>.</p>
</li>
<li>
<p>La parola chiave <code translate="no">yield</code> nella funzione decorata <code translate="no">lifespan</code> separa le fasi di avvio e di arresto.</p>
</li>
<li>
<p>Il codice precedente alla parola chiave <code translate="no">yield</code> viene eseguito all'avvio dell'applicazione prima che vengano gestite le richieste.</p>
</li>
<li>
<p>Quando vuoi terminare l'applicazione, FastAPI eseguirà il codice dopo la parola chiave <code translate="no">yield</code> come parte della fase di arresto.</p>
</li>
</ul></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO16-3" id="callout_ai_integration_and_model_serving_CO16-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a></dt>
<dd><p>Precarica il modello all'avvio sul dizionario <code translate="no">models</code>.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO16-4" id="callout_ai_integration_and_model_serving_CO16-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a></dt>
<dd><p>Inizia a gestire le richieste perché la fase di avvio è terminata.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO16-5" id="callout_ai_integration_and_model_serving_CO16-5"><img alt="5" src="assets/5.png" width="12" height="12"/></a></dt>
<dd><p>Cancella il modello all'arresto dell'applicazione.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO16-6" id="callout_ai_integration_and_model_serving_CO16-6"><img alt="6" src="assets/6.png" width="12" height="12"/></a></dt>
<dd><p>Crea il server FastAPI e passagli la funzione lifespan da utilizzare.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO16-7" id="callout_ai_integration_and_model_serving_CO16-7"><img alt="7" src="assets/7.png" width="12" height="12"/></a></dt>
<dd><p>Passa l'istanza del modello globale precaricato alla funzione di generazione.</p></dd>
</dl></div>
<p>Se avvii l'applicazione ora, dovresti vedere immediatamente il caricamento delle pipeline del modello nella memoria. Prima di applicare queste modifiche, le pipeline del modello venivano caricate solo quando si effettuava la prima richiesta.</p>
<div data-type="warning" epub:type="warning"><h6>Avvertenze</h6>
<p class="fix_tracking">Puoi precaricare più di un modello in memoria usando la strategia lifespan model-serving, ma questo non è pratico con modelli GenAI di grandi dimensioni. I modelli generativi possono essere affamati di risorse e nella maggior parte dei casi avrai bisogno di GPU per accelerare il processo di generazione. Le GPU consumer più potenti vengono fornite con soli 24 GB di VRAM. Alcuni modelli richiedono 18 GB di memoria per eseguire l'inferenza, quindi cerca di distribuire i modelli su istanze dell'applicazione e GPU separate.</p>
</div>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id720">
<h1>Eventi di avvio e spegnimento</h1>
<p><a data-primary="shutdown event handler functions" data-type="indexterm" id="id721"/><a data-primary="startup event handler functions" data-type="indexterm" id="id722"/>Prima dell'introduzione dei gestori di contesto asincroni della durata della vita in FastAPI 0.93.0 per gestire la durata della vita dell'applicazione, venivano comunemente utilizzate funzioni di gestione degli eventi di avvio e di arresto separate. L <a data-type="xref" href="#startup_shutdown_events">'esempio 3-17</a> mostra un esempio di utilizzo.</p>
<div data-type="example" id="startup_shutdown_events">
<h5><span class="label">Esempio 3-17. </span>Eventi di avvio e spegnimento</h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># main.py</code>
<code class="kn" translate="no">from</code> <code class="nn" translate="no">models</code> <code class="kn" translate="no">import</code> <code class="n" translate="no">load_image_model</code>

<code class="n" translate="no">models</code> <code class="o" translate="no">=</code> <code class="p" translate="no">{}</code>
<code class="n" translate="no">app</code> <code class="o" translate="no">=</code> <code class="n" translate="no">FastAPI</code><code class="p" translate="no">()</code>

<code class="nd" translate="no">@app</code><code class="o" translate="no">.</code><code class="n" translate="no">on_event</code><code class="p" translate="no">(</code><code class="s2" translate="no">"startup"</code><code class="p" translate="no">)</code>
<code class="k" translate="no">def</code> <code class="nf" translate="no">startup_event</code><code class="p" translate="no">():</code>
    <code class="n" translate="no">models</code><code class="p" translate="no">[</code><code class="s2" translate="no">"text2image"</code><code class="p" translate="no">]</code> <code class="o" translate="no">=</code> <code class="n" translate="no">load_image_model</code><code class="p" translate="no">()</code>

<code class="nd" translate="no">@app</code><code class="o" translate="no">.</code><code class="n" translate="no">on_event</code><code class="p" translate="no">(</code><code class="s2" translate="no">"shutdown"</code><code class="p" translate="no">)</code>
<code class="k" translate="no">def</code> <code class="nf" translate="no">shutdown_event</code><code class="p" translate="no">():</code>
    <code class="k" translate="no">with</code> <code class="nb" translate="no">open</code><code class="p" translate="no">(</code><code class="s2" translate="no">"log.txt"</code><code class="p" translate="no">,</code> <code class="n" translate="no">mode</code><code class="o" translate="no">=</code><code class="s2" translate="no">"a"</code><code class="p" translate="no">)</code> <code class="k" translate="no">as</code> <code class="n" translate="no">logfile</code><code class="p" translate="no">:</code>
        <code class="n" translate="no">logfile</code><code class="o" translate="no">.</code><code class="n" translate="no">write</code><code class="p" translate="no">(</code><code class="s2" translate="no">"Application shutdown"</code><code class="p" translate="no">)</code></pre></div>
<p>Alcune risorse sul web possono utilizzare questo approccio alternativo e tradizionale, quindi vale la pena conoscerlo.<a data-startref="ix_ch03-asciidoc42" data-type="indexterm" id="id723"/><a data-startref="ix_ch03-asciidoc41" data-type="indexterm" id="id724"/><a data-startref="ix_ch03-asciidoc40" data-type="indexterm" id="id725"/></p>
</div></aside>
</div></section>
<section data-pdf-bookmark="Be Lean: Serve Models Externally" data-type="sect2"><div class="sect2" id="id272">
<h2>Essere snelli: servire i modelli all'esterno</h2>
<p><a data-primary="serving GenAI models" data-secondary="strategies" data-tertiary="lean: serving models externally" data-type="indexterm" id="ix_ch03-asciidoc43"/>Un'altra strategia per servire i modelli GenAI è quella di pacchettizzarli come servizi esterni tramite altri strumenti. Puoi quindi utilizzare la tua applicazione FastAPI come livello logico tra il tuo client e il server esterno del modello. In questo livello logico puoi gestire il coordinamento tra i modelli, la comunicazione con le API, la gestione degli utenti, le misure di sicurezza, le attività di monitoraggio, il filtraggio dei contenuti, il miglioramento dei prompt o qualsiasi altra logica necessaria.</p>
<section data-pdf-bookmark="Cloud providers" data-type="sect3"><div class="sect3" id="id57">
<h3>Fornitori di Cloud</h3>
<p><a data-primary="cloud providers, for serving GenAI models" data-type="indexterm" id="id726"/>I fornitori di Cloud stanno innovando costantemente le soluzioni serverless e di calcolo dedicate che puoi utilizzare per servire i tuoi modelli all'esterno. Ad esempio, Azure Machine Learning Studio fornisce ora uno strumento PromptFlow che puoi utilizzare per distribuire e personalizzare modelli OpenAI o di linguaggi open source. Al momento della distribuzione, riceverai un endpoint del modello eseguito sul tuo calcolo Azure pronto per essere utilizzato. Tuttavia, l'utilizzo di PromptFlow o di strumenti simili richiede una curva di apprendimento ripida, in quanto possono richiedere dipendenze particolari e passaggi non tradizionali da seguire.</p>
</div></section>
<section data-pdf-bookmark="BentoML" data-type="sect3"><div class="sect3" id="id58">
<h3>BentoML</h3>
<p><a data-primary="BentoML" data-type="indexterm" id="ix_ch03-asciidoc44"/>Un altro grande concorrente per il servizio di modelli esterni a FastAPI è BentoML, che<span class="keep-together">si</span> ispira a FastAPI ma implementa una strategia di servizio diversa, costruita appositamente per i modelli AI.</p>
<p>Un enorme miglioramento rispetto a FastAPI per la gestione delle richieste di modelli concorrenti è la capacità<span class="keep-together">di BentoML</span> di eseguire richieste diverse su processi worker diversi. Può parallelizzare le richieste delimitate dalla CPU senza dover gestire direttamente il multiprocessing di Python. Inoltre, BentoML può anche eseguire inferenze di modelli in batch, in modo che il processo di generazione per più utenti possa essere eseguito con un'unica chiamata al modello.</p>
<p>Ho trattato BentoML in dettaglio nel <a data-type="xref" href="ch02.html#ch02">Capitolo 2</a>.</p>
<div data-type="tip"><h6>Suggerimento</h6>
<p>Per eseguire BentoML, dovrai prima installare alcune dipendenze:</p>
<pre data-code-language="bash" data-type="programlisting" translate="no">$<code class="w" translate="no"> </code>pip<code class="w" translate="no"> </code>install<code class="w" translate="no"> </code>bentoml<code class="w" translate="no"/></pre>
</div>
<p>Puoi vedere come avviare un server BentoML nell'<a data-type="xref" href="#bentoml_usage">Esempio 3-18</a>.</p>
<div data-type="example" id="bentoml_usage">
<h5><span class="label">Esempio 3-18. </span>Servire un modello di immagine con BentoML</h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># bento.py</code><code translate="no">
</code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="nn" translate="no">bentoml</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">models</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">load_image_model</code><code translate="no">
</code><code translate="no">
</code><code class="nd" translate="no">@bentoml</code><code class="o" translate="no">.</code><code class="n" translate="no">service</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">resources</code><code class="o" translate="no">=</code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">cpu</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">4</code><code class="s2" translate="no">"</code><code class="p" translate="no">}</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">traffic</code><code class="o" translate="no">=</code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">timeout</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="mi" translate="no">120</code><code class="p" translate="no">}</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">http</code><code class="o" translate="no">=</code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">port</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="mi" translate="no">5000</code><code class="p" translate="no">}</code><code translate="no">
</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO17-1" id="co_ai_integration_and_model_serving_CO17-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a><code translate="no">
</code><code class="k" translate="no">class</code><code translate="no"> </code><code class="nc" translate="no">Generate</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">def</code><code translate="no"> </code><code class="fm" translate="no">__init__</code><code class="p" translate="no">(</code><code class="bp" translate="no">self</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">-</code><code class="o" translate="no">&gt;</code><code translate="no"> </code><code class="kc" translate="no">None</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">        </code><code class="bp" translate="no">self</code><code class="o" translate="no">.</code><code class="n" translate="no">pipe</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">load_image_model</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">
</code><code translate="no">    </code><code class="nd" translate="no">@bentoml</code><code class="o" translate="no">.</code><code class="n" translate="no">api</code><code class="p" translate="no">(</code><code class="n" translate="no">route</code><code class="o" translate="no">=</code><code class="s2" translate="no">"</code><code class="s2" translate="no">/generate/image</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO17-2" id="co_ai_integration_and_model_serving_CO17-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">generate</code><code class="p" translate="no">(</code><code class="bp" translate="no">self</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">prompt</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">str</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">-</code><code class="o" translate="no">&gt;</code><code translate="no"> </code><code class="nb" translate="no">str</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">output</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="bp" translate="no">self</code><code class="o" translate="no">.</code><code class="n" translate="no">pipe</code><code class="p" translate="no">(</code><code class="n" translate="no">prompt</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">num_inference_steps</code><code class="o" translate="no">=</code><code class="mi" translate="no">10</code><code class="p" translate="no">)</code><code class="o" translate="no">.</code><code class="n" translate="no">images</code><code class="p" translate="no">[</code><code class="mi" translate="no">0</code><code class="p" translate="no">]</code><code translate="no">
</code><code translate="no">        </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">output</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO17-1" id="callout_ai_integration_and_model_serving_CO17-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Dichiara un servizio BentoML con quattro CPU allocate. Il servizio deve andare in time out in 120 secondi se il modello non viene generato in tempo e deve essere eseguito dalla porta <code translate="no">5000</code>.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO17-2" id="callout_ai_integration_and_model_serving_CO17-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a></dt>
<dd><p>Dichiara un controllore API per eseguire il processo di generazione del modello principale. Questo controllore si aggancia al gestore delle rotte API di BentoML.</p></dd>
</dl></div>
<p>Puoi quindi eseguire il servizio BentoML localmente:</p>
<pre data-code-language="bash" data-type="programlisting" translate="no">$<code class="w" translate="no"> </code>bentoml<code class="w" translate="no"> </code>serve<code class="w" translate="no"> </code>service:Generate<code class="w" translate="no"/></pre>
<p>Il tuo server FastAPI può ora diventare un client con il modello che viene servito esternamente. Ora puoi fare richieste HTTP <code translate="no">POST</code> dall'interno di FastAPI per ottenere una risposta, come mostrato nell'<a data-type="xref" href="#fastapi_bentoml_usage">esempio 3-19</a>.</p>
<div data-type="example" id="fastapi_bentoml_usage">
<h5><span class="label">Esempio 3-19. </span>Endpoint BentoML tramite FastAPI</h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># main.py</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="nn" translate="no">httpx</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">fastapi</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">FastAPI</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">Response</code><code translate="no">
</code><code translate="no">
</code><code class="n" translate="no">app</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">FastAPI</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">
</code><code class="nd" translate="no">@app</code><code class="o" translate="no">.</code><code class="n" translate="no">get</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">    </code><code class="s2" translate="no">"</code><code class="s2" translate="no">/generate/bentoml/image</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">responses</code><code class="o" translate="no">=</code><code class="p" translate="no">{</code><code class="n" translate="no">status</code><code class="o" translate="no">.</code><code class="n" translate="no">HTTP_200_OK</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">content</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">image/png</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="p" translate="no">{</code><code class="p" translate="no">}</code><code class="p" translate="no">}</code><code class="p" translate="no">}</code><code class="p" translate="no">}</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">response_class</code><code class="o" translate="no">=</code><code class="n" translate="no">Response</code><code class="p" translate="no">,</code><code translate="no">
</code><code class="p" translate="no">)</code><code translate="no">
</code><code class="k" translate="no">async</code><code translate="no"> </code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">serve_bentoml_text_to_image_controller</code><code class="p" translate="no">(</code><code class="n" translate="no">prompt</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">str</code><code class="p" translate="no">)</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">async</code><code translate="no"> </code><code class="k" translate="no">with</code><code translate="no"> </code><code class="n" translate="no">httpx</code><code class="o" translate="no">.</code><code class="n" translate="no">AsyncClient</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="k" translate="no">as</code><code translate="no"> </code><code class="n" translate="no">client</code><code class="p" translate="no">:</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO18-1" id="co_ai_integration_and_model_serving_CO18-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">response</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="k" translate="no">await</code><code translate="no"> </code><code class="n" translate="no">client</code><code class="o" translate="no">.</code><code class="n" translate="no">post</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">            </code><code class="s2" translate="no">"</code><code class="s2" translate="no">http://localhost:5000/generate</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">json</code><code class="o" translate="no">=</code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">prompt</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">prompt</code><code class="p" translate="no">}</code><code translate="no">
</code><code translate="no">        </code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO18-2" id="co_ai_integration_and_model_serving_CO18-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">Response</code><code class="p" translate="no">(</code><code class="n" translate="no">content</code><code class="o" translate="no">=</code><code class="n" translate="no">response</code><code class="o" translate="no">.</code><code class="n" translate="no">content</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">media_type</code><code class="o" translate="no">=</code><code class="s2" translate="no">"</code><code class="s2" translate="no">image/png</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO18-1" id="callout_ai_integration_and_model_serving_CO18-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Crea un client HTTP asincrono utilizzando la libreria <code translate="no">httpx</code>.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO18-2" id="callout_ai_integration_and_model_serving_CO18-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a></dt>
<dd><p>Invia una richiesta <code translate="no">POST</code> all'endpoint del modello di generazione di immagini BentoML.<a data-startref="ix_ch03-asciidoc44" data-type="indexterm" id="id727"/></p></dd>
</dl></div>
</div></section>
<section data-pdf-bookmark="Model providers" data-type="sect3"><div class="sect3" id="id59">
<h3>Fornitori di modelli</h3>
<p><a data-primary="model providers" data-secondary="for serving GenAI models externally" data-type="indexterm" id="ix_ch03-asciidoc45"/><a data-primary="OpenAI, external model serving with" data-type="indexterm" id="ix_ch03-asciidoc46"/><a data-primary="serving GenAI models" data-secondary="model providers for" data-type="indexterm" id="ix_ch03-asciidoc47"/>Oltre a BentoML e ai cloud provider, puoi anche utilizzare fornitori esterni di servizi di modello come OpenAI. In questo caso, la tua applicazione FastAPI diventa un wrapper di servizio sulle API di OpenAI.</p>
<p>Fortunatamente, l'integrazione con le API dei fornitori di modelli come OpenAI è piuttosto semplice, come mostrato nell'<a data-type="xref" href="#openai_usage">Esempio 3-20</a>.</p>
<div data-type="tip"><h6>Suggerimento</h6>
<p>Per eseguire l'<a data-type="xref" href="#openai_usage">Esempio 3-20</a>, devi ottenere una chiave API e impostare la variabile d'ambiente <code translate="no">OPENAI_API_KEY</code> su questa chiave, come consigliato da OpenAI.</p>
</div>
<div data-type="example" id="openai_usage">
<h5><span class="label">Esempio 3-20. </span>Integrazione con il servizio OpenAI</h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># main.py</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">fastapi</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">FastAPI</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">openai</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">OpenAI</code><code translate="no">
</code><code translate="no">
</code><code class="n" translate="no">app</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">FastAPI</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no">
</code><code class="n" translate="no">openai_client</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">OpenAI</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no">
</code><code class="n" translate="no">system_prompt</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">You are a helpful assistant.</code><code class="s2" translate="no">"</code><code translate="no">
</code><code translate="no">
</code><code class="nd" translate="no">@app</code><code class="o" translate="no">.</code><code class="n" translate="no">get</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">/generate/openai/text</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">serve_openai_language_model_controller</code><code class="p" translate="no">(</code><code class="n" translate="no">prompt</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">str</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">-</code><code class="o" translate="no">&gt;</code><code translate="no"> </code><code class="nb" translate="no">str</code><code translate="no"> </code><code class="o" translate="no">|</code><code translate="no"> </code><code class="kc" translate="no">None</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">response</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">openai_client</code><code class="o" translate="no">.</code><code class="n" translate="no">chat</code><code class="o" translate="no">.</code><code class="n" translate="no">completions</code><code class="o" translate="no">.</code><code class="n" translate="no">create</code><code class="p" translate="no">(</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO19-1" id="co_ai_integration_and_model_serving_CO19-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">model</code><code class="o" translate="no">=</code><code class="s2" translate="no">"</code><code class="s2" translate="no">gpt-4o</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">messages</code><code class="o" translate="no">=</code><code class="p" translate="no">[</code><code translate="no">
</code><code translate="no">            </code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">role</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">system</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">content</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="sa" translate="no">f</code><code class="s2" translate="no">"</code><code class="si" translate="no">{</code><code class="n" translate="no">system_prompt</code><code class="si" translate="no">}</code><code class="s2" translate="no">"</code><code class="p" translate="no">}</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">            </code><code class="p" translate="no">{</code><code class="s2" translate="no">"</code><code class="s2" translate="no">role</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">user</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">content</code><code class="s2" translate="no">"</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">prompt</code><code class="p" translate="no">}</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">        </code><code class="p" translate="no">]</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">    </code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">response</code><code class="o" translate="no">.</code><code class="n" translate="no">choices</code><code class="p" translate="no">[</code><code class="mi" translate="no">0</code><code class="p" translate="no">]</code><code class="o" translate="no">.</code><code class="n" translate="no">message</code><code class="o" translate="no">.</code><code class="n" translate="no">content</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO19-1" id="callout_ai_integration_and_model_serving_CO19-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Usa il modello <code translate="no">gpt-4o</code> per chattare con il modello tramite l'API OpenAI.</p></dd>
</dl></div>
<p>Ora dovresti essere in grado di ottenere gli output tramite chiamate esterne al servizio OpenAI.</p>
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="id728">
<h1>LangChain</h1>
<p><a data-primary="LangChain" data-type="indexterm" id="id729"/>Puoi utilizzare la libreria <code translate="no">langchain</code> per passare l'integrazione con qualsiasi fornitore di LLM. La libreria fornisce anche ottimi strumenti per lavorare con gli LLM, che tratteremo più avanti nel libro.  Per prima cosa, installa la libreria:</p>
<pre data-code-language="bash" data-type="programlisting" translate="no">$<code class="w" translate="no"> </code>pip<code class="w" translate="no"> </code>install<code class="w" translate="no"> </code>langchain<code class="w" translate="no"> </code>langchain-openai<code class="w" translate="no"/></pre>
<p>Una volta installato <code translate="no">langchain</code>, segui l'<a data-type="xref" href="#langchain_usage">Esempio 3-21</a> per integrarti con le API di modelli esterni come OpenAI.</p>
<div data-type="example" id="langchain_usage">
<h5><span class="label">Esempio 3-21. </span>Integrazione con le API di provider esterni con LangChain</h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># main.py</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">fastapi</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">FastAPI</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">langchain</code><code class="nn" translate="no">.</code><code class="nn" translate="no">chains</code><code class="nn" translate="no">.</code><code class="nn" translate="no">llm</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">LLMChain</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">langchain_core</code><code class="nn" translate="no">.</code><code class="nn" translate="no">prompts</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">PromptTemplate</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">langchain_openai</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">OpenAI</code><code translate="no">
</code><code translate="no">
</code><code class="n" translate="no">llm</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">OpenAI</code><code class="p" translate="no">(</code><code class="n" translate="no">openai_organization</code><code class="o" translate="no">=</code><code class="s2" translate="no">"</code><em><code class="s2" translate="no">YOUR_ORGANIZATION_ID</code></em><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO20-1" id="co_ai_integration_and_model_serving_CO20-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a><code translate="no">
</code><code class="n" translate="no">template</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="s2" translate="no">"""</code><code class="s2" translate="no">
</code><code class="s2" translate="no">Your name is FastAPI bot and you are a helpful</code><code class="s2" translate="no">
</code><code class="s2" translate="no">chatbot responsible for teaching FastAPI to your users.</code><code class="s2" translate="no">
</code><code class="s2" translate="no">Here is the user query: </code><code class="si" translate="no">{query}</code><code class="s2" translate="no">
</code><code class="s2" translate="no">"""</code><code translate="no">
</code><code class="n" translate="no">prompt</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">PromptTemplate</code><code class="o" translate="no">.</code><code class="n" translate="no">from_template</code><code class="p" translate="no">(</code><code class="n" translate="no">template</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO20-2" id="co_ai_integration_and_model_serving_CO20-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a><code translate="no">
</code><code class="n" translate="no">llm_chain</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">LLMChain</code><code class="p" translate="no">(</code><code class="n" translate="no">prompt</code><code class="o" translate="no">=</code><code class="n" translate="no">prompt</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">llm</code><code class="o" translate="no">=</code><code class="n" translate="no">llm</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO20-3" id="co_ai_integration_and_model_serving_CO20-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">
</code><code class="n" translate="no">app</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">FastAPI</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">
</code><code class="nd" translate="no">@app</code><code class="o" translate="no">.</code><code class="n" translate="no">get</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">/generate/text</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code translate="no">
</code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">generate_text_controller</code><code class="p" translate="no">(</code><code class="n" translate="no">query</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="nb" translate="no">str</code><code class="p" translate="no">)</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">llm_chain</code><code class="o" translate="no">.</code><code class="n" translate="no">run</code><code class="p" translate="no">(</code><code class="n" translate="no">query</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO20-4" id="co_ai_integration_and_model_serving_CO20-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO20-1" id="callout_ai_integration_and_model_serving_CO20-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Crea il client OpenAI con l'ID dell'organizzazione.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO20-2" id="callout_ai_integration_and_model_serving_CO20-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a></dt>
<dd><p>Costruisci un modello di prompt.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO20-3" id="callout_ai_integration_and_model_serving_CO20-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a></dt>
<dd><p>Costruisce l'oggetto OpenAI <code translate="no">llm_chain</code> dal modello di prompt.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO20-4" id="callout_ai_integration_and_model_serving_CO20-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a></dt>
<dd><p>Esegui il processo di generazione del testo passando la query dell'utente.</p></dd>
</dl></div>
</div></aside>
<p class="less_space pagebreak-before">Quando utilizzi servizi esterni, tieni presente che i dati saranno condivisi con fornitori di servizi terzi. In questo caso, se tieni alla privacy e alla sicurezza dei dati, potresti preferire le soluzioni self-hosted. Con il self-hosting, il compromesso sarà una maggiore complessità nell'implementazione e nella gestione dei tuoi server modello.<a data-startref="ix_ch03-asciidoc47" data-type="indexterm" id="id730"/><a data-startref="ix_ch03-asciidoc46" data-type="indexterm" id="id731"/><a data-startref="ix_ch03-asciidoc45" data-type="indexterm" id="id732"/></p>
<p>Se vuoi davvero evitare di servire da solo modelli di grandi dimensioni, i provider Cloud possono fornire soluzioni gestite in cui i tuoi dati non vengono mai condivisi con terze parti. Un esempio è Azure OpenAI, che al momento in cui scriviamo fornisce istantanee dei migliori LLMs e del generatore di immagini di OpenAI<a data-startref="ix_ch03-asciidoc43" data-type="indexterm" id="id733"/>.<a data-startref="ix_ch03-asciidoc37" data-type="indexterm" id="id734"/></p>
<p>Ora hai alcune opzioni per il servizio del modello. Un ultimo sistema da implementare prima di concludere questo capitolo è la registrazione e il monitoraggio del servizio.</p>
</div></section>
</div></section>
</div></section>
<section data-pdf-bookmark="The Role of Middleware in Service Monitoring" data-type="sect1"><div class="sect1" id="middleware_monitoring">
<h1>Il ruolo del middleware nel monitoraggio dei servizi</h1>
<p><a data-primary="middleware" data-secondary="for service monitoring" data-type="indexterm" id="ix_ch03-asciidoc48"/><a data-primary="monitoring, middleware role in" data-type="indexterm" id="ix_ch03-asciidoc49"/><a data-primary="service monitoring, middleware role in" data-type="indexterm" id="ix_ch03-asciidoc50"/><a data-primary="serving GenAI models" data-secondary="middleware role in service monitoring" data-type="indexterm" id="ix_ch03-asciidoc51"/>Puoi implementare un semplice strumento di monitoraggio in cui i prompt e le risposte possono essere registrati insieme all'utilizzo dei token di richiesta e di risposta. Per implementare il sistema di logging, puoi scrivere alcune funzioni di logging all'interno del controller che serve il modello. Tuttavia, se hai più modelli ed endpoint, potresti trarre vantaggio dallo sfruttamento del meccanismo middleware FastAPI.</p>
<p>Il middleware è un blocco di codice essenziale che viene eseguito prima e dopo l'elaborazione di una richiesta da parte di uno qualsiasi dei tuoi controller. Puoi definire un middleware personalizzato da allegare ai gestori delle rotte API. Una volta che le richieste raggiungono i gestori delle rotte, il middleware funge da intermediario, elaborando le richieste e le risposte tra il client e il controller del server.</p>
<p>Tra gli utilizzi eccellenti del middleware ci sono il logging e il monitoraggio, la limitazione della velocità, il filtraggio dei contenuti e l'implementazione di CORS (cross-origin resource sharing).</p>
<p>L<a data-type="xref" href="#middleware_monitoring_example">'esempio 3-22</a> mostra come puoi monitorare i gestori che servono il modello.</p>
<div data-type="warning" epub:type="warning"><h1>Registrazione dell'uso tramite middleware personalizzato in produzione</h1>
<p><a data-primary="loggers/logging" data-secondary="usage logging via custom middleware in production" data-type="indexterm" id="id735"/>Non usare l'<a data-type="xref" href="#middleware_monitoring_example">Esempio 3-22</a> in produzione perché i registri di monitoraggio possono scomparire se esegui l'applicazione da un container Docker o da una macchina host che può essere cancellata o riavviata senza un volume persistente montato o un registro su un database.</p>
<p>Nel <a data-type="xref" href="ch07.html#ch07">Capitolo 7</a>, integrerai il sistema di monitoraggio con un database per conservare i log al di fuori dell'ambiente applicativo.</p>
</div>
<div class="less_space pagebreak-before" data-type="example" id="middleware_monitoring_example">
<h5><span class="label">Esempio 3-22. </span>Utilizzo dei meccanismi middleware per acquisire i log di utilizzo dei servizi</h5>
<pre data-code-language="python" data-type="programlisting" translate="no"><code class="c1" translate="no"># main.py</code><code translate="no">
</code><code translate="no">
</code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="nn" translate="no">csv</code><code translate="no">
</code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="nn" translate="no">time</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">datetime</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">datetime</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">timezone</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">uuid</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">uuid4</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">typing</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">Awaitable</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">Callable</code><code translate="no">
</code><code class="kn" translate="no">from</code><code translate="no"> </code><code class="nn" translate="no">fastapi</code><code translate="no"> </code><code class="kn" translate="no">import</code><code translate="no"> </code><code class="n" translate="no">FastAPI</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">Request</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">Response</code><code translate="no">
</code><code translate="no">
</code><code class="c1" translate="no"># preload model with a lifespan</code><code translate="no">
</code><code class="o" translate="no">.</code><code class="o" translate="no">.</code><code class="o" translate="no">.</code><code translate="no">
</code><code translate="no">
</code><code class="n" translate="no">app</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">FastAPI</code><code class="p" translate="no">(</code><code class="n" translate="no">lifespan</code><code class="o" translate="no">=</code><code class="n" translate="no">lifespan</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">
</code><code class="n" translate="no">csv_header</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="p" translate="no">[</code><code translate="no">
</code><code translate="no">    </code><code class="s2" translate="no">"</code><code class="s2" translate="no">Request ID</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">Datetime</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">Endpoint Triggered</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">Client IP Address</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">    </code><code class="s2" translate="no">"</code><code class="s2" translate="no">Response Time</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">Status Code</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">Successful</code><code class="s2" translate="no">"</code><code translate="no">
</code><code class="p" translate="no">]</code><code translate="no">
</code><code translate="no">
</code><code translate="no">
</code><code class="nd" translate="no">@app</code><code class="o" translate="no">.</code><code class="n" translate="no">middleware</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">http</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO21-1" id="co_ai_integration_and_model_serving_CO21-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a><code translate="no">
</code><code class="k" translate="no">async</code><code translate="no"> </code><code class="k" translate="no">def</code><code translate="no"> </code><code class="nf" translate="no">monitor_service</code><code class="p" translate="no">(</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">req</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">Request</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">call_next</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">Callable</code><code class="p" translate="no">[</code><code class="p" translate="no">[</code><code class="n" translate="no">Request</code><code class="p" translate="no">]</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">Awaitable</code><code class="p" translate="no">[</code><code class="n" translate="no">Response</code><code class="p" translate="no">]</code><code class="p" translate="no">]</code><code translate="no">
</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">-</code><code class="o" translate="no">&gt;</code><code translate="no"> </code><code class="n" translate="no">Response</code><code class="p" translate="no">:</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO21-2" id="co_ai_integration_and_model_serving_CO21-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">request_id</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">uuid4</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code class="o" translate="no">.</code><code class="n" translate="no">hex</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO21-3" id="co_ai_integration_and_model_serving_CO21-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">request_datetime</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">datetime</code><code class="o" translate="no">.</code><code class="n" translate="no">now</code><code class="p" translate="no">(</code><code class="n" translate="no">timezone</code><code class="o" translate="no">.</code><code class="n" translate="no">utc</code><code class="p" translate="no">)</code><code class="o" translate="no">.</code><code class="n" translate="no">isoformat</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">start_time</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">time</code><code class="o" translate="no">.</code><code class="n" translate="no">perf_counter</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">response</code><code class="p" translate="no">:</code><code translate="no"> </code><code class="n" translate="no">Response</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="k" translate="no">await</code><code translate="no"> </code><code class="n" translate="no">call_next</code><code class="p" translate="no">(</code><code class="n" translate="no">req</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">response_time</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="nb" translate="no">round</code><code class="p" translate="no">(</code><code class="n" translate="no">time</code><code class="o" translate="no">.</code><code class="n" translate="no">perf_counter</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">-</code><code translate="no"> </code><code class="n" translate="no">start_time</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="mi" translate="no">4</code><code class="p" translate="no">)</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO21-4" id="co_ai_integration_and_model_serving_CO21-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">response</code><code class="o" translate="no">.</code><code class="n" translate="no">headers</code><code class="p" translate="no">[</code><code class="s2" translate="no">"</code><code class="s2" translate="no">X-Response-Time</code><code class="s2" translate="no">"</code><code class="p" translate="no">]</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="nb" translate="no">str</code><code class="p" translate="no">(</code><code class="n" translate="no">response_time</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="n" translate="no">response</code><code class="o" translate="no">.</code><code class="n" translate="no">headers</code><code class="p" translate="no">[</code><code class="s2" translate="no">"</code><code class="s2" translate="no">X-API-Request-ID</code><code class="s2" translate="no">"</code><code class="p" translate="no">]</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">request_id</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO21-5" id="co_ai_integration_and_model_serving_CO21-5"><img alt="5" src="assets/5.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">with</code><code translate="no"> </code><code class="nb" translate="no">open</code><code class="p" translate="no">(</code><code class="s2" translate="no">"</code><code class="s2" translate="no">usage.csv</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="s2" translate="no">"</code><code class="s2" translate="no">a</code><code class="s2" translate="no">"</code><code class="p" translate="no">,</code><code translate="no"> </code><code class="n" translate="no">newline</code><code class="o" translate="no">=</code><code class="s2" translate="no">"</code><code class="s2" translate="no">"</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="k" translate="no">as</code><code translate="no"> </code><code class="n" translate="no">file</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">writer</code><code translate="no"> </code><code class="o" translate="no">=</code><code translate="no"> </code><code class="n" translate="no">csv</code><code class="o" translate="no">.</code><code class="n" translate="no">writer</code><code class="p" translate="no">(</code><code class="n" translate="no">file</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">        </code><code class="k" translate="no">if</code><code translate="no"> </code><code class="n" translate="no">file</code><code class="o" translate="no">.</code><code class="n" translate="no">tell</code><code class="p" translate="no">(</code><code class="p" translate="no">)</code><code translate="no"> </code><code class="o" translate="no">==</code><code translate="no"> </code><code class="mi" translate="no">0</code><code class="p" translate="no">:</code><code translate="no">
</code><code translate="no">            </code><code class="n" translate="no">writer</code><code class="o" translate="no">.</code><code class="n" translate="no">writerow</code><code class="p" translate="no">(</code><code class="n" translate="no">csv_header</code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">        </code><code class="n" translate="no">writer</code><code class="o" translate="no">.</code><code class="n" translate="no">writerow</code><code class="p" translate="no">(</code><code translate="no"> </code><a class="co" href="#callout_ai_integration_and_model_serving_CO21-6" id="co_ai_integration_and_model_serving_CO21-6"><img alt="6" src="assets/6.png" width="12" height="12"/></a><code translate="no">
</code><code translate="no">            </code><code class="p" translate="no">[</code><code translate="no">
</code><code translate="no">                </code><code class="n" translate="no">request_id</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">                </code><code class="n" translate="no">request_datetime</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">                </code><code class="n" translate="no">req</code><code class="o" translate="no">.</code><code class="n" translate="no">url</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">                </code><code class="n" translate="no">req</code><code class="o" translate="no">.</code><code class="n" translate="no">client</code><code class="o" translate="no">.</code><code class="n" translate="no">host</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">                </code><code class="n" translate="no">response_time</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">                </code><code class="n" translate="no">response</code><code class="o" translate="no">.</code><code class="n" translate="no">status_code</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">                </code><code class="n" translate="no">response</code><code class="o" translate="no">.</code><code class="n" translate="no">status_code</code><code translate="no"> </code><code class="o" translate="no">&lt;</code><code translate="no"> </code><code class="mi" translate="no">400</code><code class="p" translate="no">,</code><code translate="no">
</code><code translate="no">            </code><code class="p" translate="no">]</code><code translate="no">
</code><code translate="no">        </code><code class="p" translate="no">)</code><code translate="no">
</code><code translate="no">    </code><code class="k" translate="no">return</code><code translate="no"> </code><code class="n" translate="no">response</code><code translate="no">
</code><code translate="no">
</code><code translate="no">
</code><code class="c1" translate="no"># Usage Log Example</code><code translate="no">
</code><code translate="no">
</code><code class="sd" translate="no">""""
Request ID: 3d15d3d9b7124cc9be7eb690fc4c9bd5
Datetime: 2024-03-07T16:41:58.895091
Endpoint triggered: http://localhost:8000/generate/text
Client IP Address: 127.0.0.1
Processing time: 26.7210 seconds
Status Code: 200
Successful: True
"""</code><code translate="no">
</code><code translate="no">
</code><code class="c1" translate="no"># model-serving handlers</code><code translate="no">
</code><code class="o" translate="no">.</code><code class="o" translate="no">.</code><code class="o" translate="no">.</code></pre>
<dl class="calloutlist">
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO21-1" id="callout_ai_integration_and_model_serving_CO21-1"><img alt="1" src="assets/1.png" width="12" height="12"/></a></dt>
<dd><p>Dichiara una funzione decorata dal meccanismo middleware HTTP di FastAPI. La funzione deve ricevere l'oggetto <code translate="no">Request</code> e la funzione di callback <code translate="no">call_next</code> per essere considerata un middleware <code translate="no">http</code> valido.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO21-2" id="callout_ai_integration_and_model_serving_CO21-2"><img alt="2" src="assets/2.png" width="12" height="12"/></a></dt>
<dd><p>Passa la richiesta al gestore del percorso per elaborare la risposta.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO21-3" id="callout_ai_integration_and_model_serving_CO21-3"><img alt="3" src="assets/3.png" width="12" height="12"/></a></dt>
<dd><p>Genera un ID di richiesta per tracciare tutte le richieste in arrivo anche se viene sollevato un errore in <code translate="no">call_next</code> durante l'elaborazione della richiesta.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO21-4" id="callout_ai_integration_and_model_serving_CO21-4"><img alt="4" src="assets/4.png" width="12" height="12"/></a></dt>
<dd><p>Calcola la durata della risposta con quattro cifre decimali.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO21-5" id="callout_ai_integration_and_model_serving_CO21-5"><img alt="5" src="assets/5.png" width="12" height="12"/></a></dt>
<dd><p>Imposta intestazioni di risposta personalizzate per il tempo di elaborazione e l'ID della richiesta.</p></dd>
<dt><a class="co" href="#co_ai_integration_and_model_serving_CO21-6" id="callout_ai_integration_and_model_serving_CO21-6"><img alt="6" src="assets/6.png" width="12" height="12"/></a></dt>
<dd><p>Registra l'URL dell'endpoint attivato, la data e l'ID della richiesta, l'indirizzo IP del cliente, il tempo di elaborazione della risposta e il codice di stato in un file CSV su disco in modalità <code translate="no">append</code>.</p></dd>
</dl></div>
<p>In questa sezione vengono catturate le informazioni sull'utilizzo dell'endpoint, tra cui il tempo di elaborazione, il codice di stato, il percorso dell'endpoint e l'IP del client.</p>
<p>Il middleware è un potente sistema per eseguire blocchi di codice prima che le richieste vengano passate ai gestori delle rotte e prima che le risposte vengano inviate all'utente. Hai visto un esempio di come il middleware può essere utilizzato per registrare l'utilizzo del modello per qualsiasi endpoint che serva il modello.<a data-startref="ix_ch03-asciidoc51" data-type="indexterm" id="id736"/><a data-startref="ix_ch03-asciidoc50" data-type="indexterm" id="id737"/><a data-startref="ix_ch03-asciidoc49" data-type="indexterm" id="id738"/><a data-startref="ix_ch03-asciidoc48" data-type="indexterm" id="id739"/></p>
<div data-type="warning" epub:type="warning"><h1>Accesso ai corpi delle richieste e delle risposte nel middleware</h1>
<p>Se hai bisogno di tracciare le interazioni con i tuoi modelli, compresi i prompt e il contenuto che generano, l'utilizzo del middleware per il logging è più efficiente rispetto all'aggiunta di logger individuali a ogni gestore. Tuttavia, devi tenere conto della privacy dei dati e delle prestazioni quando registri i corpi delle richieste e delle risposte, poiché l'utente potrebbe inviare al tuo servizio dati sensibili o di grandi dimensioni, che richiederanno una gestione attenta.</p>
</div>
</div></section>
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="id440">
<h1>Sommario</h1>
<p>In questo capitolo abbiamo trattato molti concetti, quindi rivediamo rapidamente tutto ciò che abbiamo discusso.</p>
<p>Hai visto come scaricare, integrare e servire una serie di modelli GenAI open source dal repository Hugging Face in una semplice interfaccia utente utilizzando il pacchetto Streamlit, con poche righe di codice. Hai anche esaminato diversi tipi di modelli e come servirli tramite endpoint FastAPI. I modelli che hai sperimentato erano basati su testo, immagini, audio, video e 3D e hai visto come elaborano i dati. Hai anche imparato le architetture dei modelli e i meccanismi sottostanti che li alimentano.</p>
<p>In seguito, hai esaminato diverse strategie di model-serving, tra cui lo scambio di modelli su richiesta, il preloading dei modelli e infine il model-serving al di fuori dell'applicazione FastAPI utilizzando altri framework come BentoML o API di terze parti.</p>
<p>Poi hai notato che i modelli più grandi potevano impiegare un po' di tempo per generare le risposte. Infine, hai implementato un meccanismo di monitoraggio dei servizi per i tuoi modelli che sfrutta il sistema middleware FastAPI per ogni endpoint che serve i modelli. Hai poi scritto i log su disco per analisi future.</p>
<p>Ora dovresti sentirti più sicuro nel costruire i tuoi servizi GenAI basati su una serie di modelli open source.</p>
<p>Nel prossimo capitolo imparerai a conoscere meglio la sicurezza dei tipi e il suo ruolo nell'eliminare i bug delle applicazioni e nel ridurre l'incertezza quando si lavora con API e servizi esterni. Vedrai anche come convalidare le richieste e gli schemi di risposta per rendere i tuoi servizi ancora più affidabili.</p>
</div></section>
<section class="less_space pagebreak-before" data-pdf-bookmark="Additional References" data-type="sect1"><div class="sect1" id="id441">
<h1>Riferimenti aggiuntivi</h1>
<ul>
<li>
<p><a href="https://oreil.ly/HKT8O">"Bark",</a> nella documentazione di "Transformers", <em>Hugging Face</em>, consultato il 26 marzo 2024.</p>
</li>
<li>
<p>Borsos, Z., et al. (2022).<a href="https://oreil.ly/8YZBr">"AudioLM: A Language Modeling Approach to Audio Generation".</a> arXiv preprint arXiv:2209.03143.</p>
</li>
<li>
<p>Brooks, T., et al. (2024).<a href="https://oreil.ly/52duF">"Video Generation Models as World Simulators".</a> OpenAI.</p>
</li>
<li>
<p>Défossez, A., et al. (2022).<a href="https://oreil.ly/p4_-5">"High-Fidelity Neural Audio Compression".</a> arXiv preprint arXiv:2210.13438.</p>
</li>
<li>
<p>Jun, H. &amp; Nichol, A. (2023).<a href="https://oreil.ly/LzLy0">"Shap-E: Generating Conditional 3D Implicit Functions".</a> arXiv preprint arXiv:2305.02463.</p>
</li>
<li>
<p>Kim, B.-K., et al. (2023).<a href="https://oreil.ly/uErOQ">"BK-SDM: A Lightweight, Fast, and Cheap Version of Stable Diffusion".</a> arXiv preprint arXiv:2305.15798.</p>
</li>
<li>
<p>Liu, Y., et al. (2024).<a href="https://oreil.ly/Zr6bJ">"Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models".</a> arXiv preprint arXiv:2402.17177.</p>
</li>
<li>
<p>Mildenhall, B., et al. (2020).<a href="https://oreil.ly/hBiBV">"NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis".</a> arXiv preprint arXiv:2003.08934.</p>
</li>
<li>
<p>Nichol, A., et al. (2022).<a href="https://oreil.ly/FW-wT">"Point-E: A System for Generating 3D Point Clouds from Complex Prompts".</a> arXiv preprint arXiv:2212.08751.</p>
</li>
<li>
<p>Vaswani, A., et al. (2017).<a href="https://oreil.ly/N4MkH">"Attention Is All You Need".</a> arXiv preprint arXiv:1706.03762.</p>
</li>
<li>
<p>Wang, C., et al. (2023).<a href="https://oreil.ly/h1D0e">"Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers".</a> arXiv preprint arXiv:2301.02111.</p>
</li>
<li>
<p>Zhang, P., et al. (2024). <a href="https://oreil.ly/Idi1B">"TinyLlama: An Open-Source Small Language Model".</a> arXiv preprint arXiv:2401.02385.</p>
</li>
</ul>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="id630"><sup><a href="ch03.html#id630-marker">1</a></sup> Hugging Face offre l'accesso a un'ampia gamma di modelli di apprendimento automatico pre-addestrati, set di dati e <span class="keep-together">applicazioni.</span></p><p data-type="footnote" id="id631"><sup><a href="ch03.html#id631-marker">2</a></sup> A. Vaswani et al. (2017), <a href="https://oreil.ly/sO33r">"Attention Is All You Need",</a> arXiv preprint arXiv:1706.03762.</p><p data-type="footnote" id="id635"><sup><a href="ch03.html#id635-marker">3</a></sup> Un ottimo strumento per visualizzare le mappe di attenzione è <a href="https://oreil.ly/e2Q7X">BertViz</a>.</p><p data-type="footnote" id="id637"><sup><a href="ch03.html#id637-marker">4</a></sup> Puoi trovare l'elenco aggiornato degli LLMs open source sul <a href="https://oreil.ly/GZaEr">repository Open LLM GitHub</a>.</p><p data-type="footnote" id="id647"><sup><a href="ch03.html#id647-marker">5</a></sup> Un modello di embedding o uno strato di embedding come in un trasformatore</p><p data-type="footnote" id="id658"><sup><a href="ch03.html#id658-marker">6</a></sup> Questo processo di generazione sequenziale dei token può anche limitare la scalabilità di sequenze lunghe, poiché ogni token si basa su quello precedente.</p><p data-type="footnote" id="id665"><sup><a href="ch03.html#id665-marker">7</a></sup> Il <a href="https://huggingface.co">repository dei modelli di Hugging Face</a> è una risorsa per gli sviluppatori di IA per pubblicare e condividere i loro modelli pre-addestrati.</p><p data-type="footnote" id="id666"><sup><a href="ch03.html#id666-marker">8</a></sup> Consulta la <a href="https://pytorch.org">documentazione</a> di <a href="https://pytorch.org">PyTorch</a> per le istruzioni di installazione.</p><p data-type="footnote" id="id667"><sup><a href="ch03.html#id667-marker">9</a></sup> La precisione del tensore <code translate="no">float16</code> è più efficiente in termini di memoria in ambienti con vincoli di memoria. I calcoli possono essere più veloci ma la precisione è inferiore rispetto ai tensori di <code translate="no">float32</code>. Per maggiori informazioni, consulta la <a href="https://oreil.ly/rsmoB">scheda del modello TinyLlama</a>.</p><p data-type="footnote" id="id668"><sup><a href="ch03.html#id668-marker">10</a></sup> Come abbiamo visto nel <a data-type="xref" href="ch02.html#ch02">Capitolo 2</a>, i controller sono funzioni che gestiscono le richieste in entrata di una rotta API e restituiscono le risposte al cliente attraverso un'esecuzione logica di servizi o provider.</p><p data-type="footnote" id="id674"><sup><a href="ch03.html#id674-marker">11</a></sup> Streamlit raccoglie le statistiche di utilizzo per impostazione predefinita, ma puoi disattivare questa funzione utilizzando un <a href="https://oreil.ly/m_Jix">file di configurazione</a>.</p><p data-type="footnote" id="id686"><sup><a href="ch03.html#id686-marker">12</a></sup> Lo spazio latente di un modello addestrato, quando viene visualizzato, può sembrare un rumore bianco ma contiene rappresentazioni strutturate che il modello ha imparato a codificare e decodificare.</p><p data-type="footnote" id="id697"><sup><a href="ch03.html#id697-marker">13</a></sup> <em>Il multiplexing</em> è il processo di combinazione di più flussi (come audio, video e sottotitoli) in un unico file o flusso in modo sincronizzato.</p><p data-type="footnote" id="id698"><sup><a href="ch03.html#id698-marker">14</a></sup> La libreria <code translate="no">python-multipart</code> è utilizzata per il parsing di <code translate="no">multipart/form-data</code>, una codifica comunemente utilizzata per l'invio di moduli di caricamento di file.</p></div></div></section></div></div></body></html>