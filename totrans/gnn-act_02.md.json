["```py\nimport NetworkX as nx\nfrom Node2Vec import Node2Vec\nbooks_graph = nx.read_gml('PATH_TO_GML_FILE')   #1\nnode2vec = Node2Vec(books_graph, dimensions=64,\n walk_length=30, num_walks=200, workers=4)   #2\nmodel = node2vec.fit(window=10, min_count=1,\\\nbatch_words=4)   #3\nembeddings = {str(node): model.wv[str(node)]\\\n for node in gml_graph.nodes()}   #4\n```", "```py\nnode_embeddings = [embeddings[str(node)] \\\nfor node in gml_graph.nodes()]   #1\nnode_embeddings_array = np.array(node_embeddings)  \n\numap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, \\\nrandom_state=42)\numap_features = umap_model.fit_transform\\\n(node_embeddings_array)  #2\n\nplt.scatter(umap_features[:, 0], \\\numap_features[:, 1], color=node_colors, alpha=0.7)  #3\n```", "```py\nnode2vec = Node2Vec(gml_graph, dimensions=2, \\\nwalk_length=30, num_walks=200, workers=4)   #1\nmodel = node2vec.fit(window=10, min_count=1,\\\n batch_words=4)   #2\n\nembeddings_2d = {str(node): model.wv[str(node)] \\\nfor node in gml_graph.nodes()}   #3\n\npoints = np.array([embeddings_2d[node] \\\nfor node in gml_graph.nodes()])   #4\n\nplt.scatter(points[:, 0], points[:, 1], \\\ncolor=node_colors, alpha=0.7)   #5\n```", "```py\nclass SimpleGNN_embeddings(torch.nn.Module):\n    def __init__(self, num_features, hidden_channels):   #1\n        super(SimpleGNN, self).__init__()\n        self.conv1 = GCNConv(num_features, \\\nhidden_channels)   #2\n        self.conv2 = GCNConv(hidden_channels,\\\n hidden_channels)  #3\n\n    def forward(self, x, edge_index):   #4\n        x = self.conv1(x, edge_index)  #5\n        x = torch.relu(x)   #6\n        x = torch.dropout(x, p=0.5, train=self.training)   #7\n        x = self.conv2(x, edge_index)    #8\n        return x   #9\n```", "```py\ndata.x = torch.randn((data.num_nodes, 64), dtype=torch.float)\n'nn.init.xavier_uniform_(data.x) '\n```", "```py\nnode_embeddings = [embeddings[str(node)] for node in gml_graph.nodes()]\n```", "```py\nnode_features = torch.tensor(node_embeddings, dtype=torch.float) \ndata.x = node_features\n```", "```py\nmodel = SimpleGNN(num_features=data.x.shape[1], hidden_channels=64)\n```", "```py\nmodel.eval()\nwith torch.no_grad():\n    gnn_embeddings = model(data.x, data.edge_index)\n```", "```py\ngnn_embeddings_np = gnn_embeddings.detach().cpu().numpy()\n```", "```py\nlabels = []\nfor node, data in gml_graph.nodes(data=True):   #1\n    if data['value'] == 'c':\n        labels.append('right')\n    elif data['value'] == 'l':\n        labels.append('left')\n    else:  \n        labels.append('neutral')\nlabels = np.array(labels)\n\nrandom.seed(52)   #2\n\nindices = list(range(len(labels)))   #3\n\nlabelled_percentage = 0.2    #4\n\nlabelled_indices = random.sample(indices, \\\nint(labelled_percentage * len(labels)))   #5\n\nlabelled_mask = np.zeros(len(labels), dtype=bool)   #6\nunlabelled_mask = np.ones(len(labels), dtype=bool)\n\nlabelled_mask[labelled_indices] = True   #7\nunlabelled_mask[labelled_indices] = False\n\nlabelled_labels = labels[labelled_mask]   #8\nunlabelled_labels = labels[unlabelled_mask]\n\nlabel_mapping = {'left': 0, 'right': 1, 'neutral': 2}   #9\nnumeric_labels = np.array([label_mapping[label] for label in labels])\n```", "```py\nX_train_gnn = gnn_embeddings[labelled_mask]   #1\nY_train_gnn = numeric_labels[labelled_mask]  \n\nX_n2v = np.array([embeddings[str(node)] \\\nfor node in gml_graph.nodes()])  #2\nX_train_n2v = X_n2v[labelled_mask]              #3\ny_train_n2v = numeric_labels[labelled_mask]     #3\n```", "```py\nclf_gnn = RandomForestClassifier()   #1\nclf_gnn.fit(X_train_gnn, y_train_gnn)\n\nclf_n2v = RandomForestClassifier()  #2\nclf_n2v.fit(X_train_n2v, y_train_n2v)\n```", "```py\nclass SimpleGNN_inference(torch.nn.Module):\n    def __init__(self, num_features, hidden_channels):\n        super(SimpleGNN, self).__init__()\n        self.conv1 = GCNConv(num_features, hidden_channels)\n        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n\n    def forward(self, x, edge_index):\n        # First Graph Convolutional layer\n        x = self.conv1(x, edge_index)\n        x = F.relu(x)\n        x = F.dropout(x, training=self.training)\n\n        # Second Graph Convolutional layer\n        x = self.conv2(x, edge_index)\n        predictions = F.log_softmax(x, dim=1)    #1\n\n        return x, predictions   #2\n```", "```py\nfor epoch in range(3000):    #1\n    optimizer.zero_grad()\n\n    _, out = model(data.x, data.edge_index)   #2\n\n    out_masked = out[data.train_mask]   #3\n\n    loss = loss_fn(out_masked, train_labels)   #4\n    loss.backward()\n    optimizer.step()\n\n    if epoch % 10 == 0:    #5\n        print(f'Epoch {epoch}, Log Loss: {loss.item()}')\n```"]