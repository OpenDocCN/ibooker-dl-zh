["```py\nCreate a blog post about “{blogPostTopic}”. Write it in a “{tone}” tone.\nUse transition words.\nUse active voice. Write over 1000 words.\nUse very creative titles for the blog post.\nAdd a title for each section. Ensure there are a minimum of 9 sections. Each\nsection should have a minimum of two paragraphs.\nInclude the following keywords: “{keywords}”.\nCreate a good slug for this post and a meta description with a maximum of 100\nwords and add it to the end of the blog post.\n```", "```py\npip install google-searchresults pandas html2text pytest-playwright chromadb \\\nnest_asyncio --quiet\n```", "```py\nfrom langchain_openai.chat_models import ChatOpenAI\nfrom langchain.output_parsers import PydanticOutputParser\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nimport os\n\n# Custom imports:\nfrom content_collection import collect_serp_data_and_extract_text_from_webpages\nfrom custom_summarize_chain import create_all_summaries, DocumentSummary\n\nimport nest_asyncio\nnest_asyncio.apply()\n\n# Constant variables:\nTOPIC = \"Neural networks\"\nos.environ[\"SERPAPI_API_KEY\"] = \"\"\nos.environ[\"STABILITY_API_KEY\"] = \"\"\n```", "```py\n# Extract content from webpages into LangChain documents:\ntext_documents = await \\\ncollect_serp_data_and_extract_text_from_webpages(TOPIC)\n\n# LLM, text splitter + parser:\nllm = ChatOpenAI(temperature=0)\ntext_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n    chunk_size=1500, chunk_overlap=400\n)\nparser = PydanticOutputParser(pydantic_object=DocumentSummary)\n\nsummaries = await create_all_summaries(text_documents,\nparser,\nllm,\ntext_splitter)\n```", "```py\nfrom langchain_community.document_loaders import AsyncHtmlLoader, \\\nAsyncChromiumLoader\n\nclass ChromiumLoader(AsyncChromiumLoader):\n    async def load(self):\n        raw_text = [await self.ascrape_playwright(url) for url in self.urls]\n        # Return the raw documents:\n        return [Document(page_content=text) for text in raw_text]\n\nasync def get_html_content_from_urls(\n    df: pd.DataFrame, number_of_urls: int = 3, url_column: str = \"link\"\n) -> List[Document]:\n    # Get the HTML content of the first 3 URLs:\n    urls = df[url_column].values[:number_of_urls].tolist()\n\n    # If there is only one URL, convert it to a list:\n    if isinstance(urls, str):\n        urls = [urls]\n\n    # Check for empty URLs:\n    urls = [url for url in urls if url != \"\"]\n\n    # Check for duplicate URLs:\n    urls = list(set(urls))\n\n    # Throw error if no URLs are found:\n    if len(urls) == 0:\n        raise ValueError(\"No URLs found!\")\n    # loader = AsyncHtmlLoader(urls) # Faster but might not always work.\n    loader = ChromiumLoader(urls)\n    docs = await loader.load()\n    return docs\n\nasync def create_all_summaries(\n    # ... commented out for brevity\n) -> List[DocumentSummary]:\n    # ... commented out for brevity\n```", "```py\nfrom expert_interview_chain import InterviewChain\ninterview_chain = InterviewChain(topic=TOPIC, document_summaries=summaries)\ninterview_questions = interview_chain()\n\nfor question in interview_questions.questions:\n    print(f\"Answer the following question: {question.question}\\n\", flush=True)\n    answer = input(f\"Answer the following question: {question.question}\\n\")\n    print('------------------------------------------')\n    question.answer = answer\n```", "```py\nsystem_message = \"\"\"You are a content SEO researcher. Previously you have\nsummarized and extracted key points from SERP results. The insights gained\nwill be used to do content research and we will compare the key points,\ninsights and summaries across multiple articles. You are now going to\ninterview a content expert. You will ask them questions about the following\ntopic: {topic}.\n\nYou must follow the following rules:\n - Return a list of questions that you would ask a content expert about\n the topic.\n - You must ask at least and at most 5 questions.\n - You are looking for information gain and unique insights that are not\n already covered in the {document_summaries} information.\n - You must ask questions that are open-ended and not yes/no questions.\n    {format_instructions}\n\"\"\"\n```", "```py\nfrom expert_interview_chain import InterviewQuestions\n\n# Set up a parser + inject instructions into the prompt template:\nparser = PydanticOutputParser(pydantic_object=InterviewQuestions)\n```", "```py\nfrom article_outline_generation import BlogOutlineGenerator\n\nblog_outline_generator = BlogOutlineGenerator(topic=TOPIC,\nquestions_and_answers=[item.dict() for item in interview_questions.questions])\n\nquestions_and_answers = blog_outline_generator.questions_and_answers\noutline_result = blog_outline_generator.generate_outline(summaries)\n```", "```py\nfrom typing import List, Any\nfrom pydantic.v1 import BaseModel\n\nclass SubHeading(BaseModel):\n    title: str # Each subheading should have a title.\n\nclass BlogOutline(BaseModel):\n    title: str\n    sub_headings: List[SubHeading] # An outline has many sub_headings\n\n# Langchain libraries:\nfrom langchain.prompts.chat import (ChatPromptTemplate,\nSystemMessagePromptTemplate)\nfrom langchain.output_parsers import PydanticOutputParser\nfrom langchain_openai.chat_models import ChatOpenAI\n\n# Custom types:\nfrom custom_summarize_chain import DocumentSummary\n\nclass BlogOutlineGenerator:\n    def __init__(self, topic: str, questions_and_answers: Any):\n        self.topic = topic\n        self.questions_and_answers = questions_and_answers\n\n        # Create a prompt\n        prompt_content = \"\"\"\n Based on my answers and the summary, generate an outline for a blog\n article on {topic}.\n topic: {topic}\n document_summaries: {document_summaries}\n ---\n Here is the interview which I answered:\n        {interview_questions_and_answers}\n ---\n Output format: {format_instructions}\n \"\"\"\n\n        system_message_prompt =\n        SystemMessagePromptTemplate.from_template(prompt_content)\n\n        self.chat_prompt = ChatPromptTemplate.from_messages(\n        [system_message_prompt])\n\n        # Create an output parser\n        self.parser = PydanticOutputParser(pydantic_object=BlogOutline)\n\n        # Set up the chain\n        self.outline_chain = self.chat_prompt | ChatOpenAI() | self.parser\n\n    def generate_outline(self, summaries: List[DocumentSummary]) -> Any:\n        print(\"Generating the outline...\\n---\")\n        result = self.outline_chain.invoke(\n            {\"topic\": self.topic,\n            \"document_summaries\": [s.dict() for s in summaries],\n            \"interview_questions_and_answers\": self.questions_and_answers,\n            \"format_instructions\": self.parser.get_format_instructions(),\n            }\n        )\n        print(\"Finished generating the outline!\\n---\")\n        return result\n```", "```py\n# Set up the chain:\nself.outline_chain = self.chat_prompt | ChatOpenAI() | self.parser\n```", "```py\nfrom article_generation import ContentGenerator\n\ncontent_gen = ContentGenerator(\ntopic=TOPIC, outline=outline_result,\nquestions_and_answers=questions_and_answers)\n\n# Vectorize and store the original webpages:\ncontent_gen.split_and_vectorize_documents(text_documents)\n# Create the blog post:\nblog_post = content_gen.generate_blog_post()\n```", "```py\nfrom typing import List, Dict, Any\nfrom langchain.memory import ConversationSummaryBufferMemory\n\nfrom langchain_core.messages import SystemMessage\n\nclass OnlyStoreAIMemory(ConversationSummaryBufferMemory):\n    def save_context(self, inputs: Dict[str, Any],\n    outputs: Dict[str, str]) -> None:\n        input_str, output_str = self._get_input_output(inputs, outputs)\n        self.chat_memory.add_ai_message(output_str)\n```", "```py\ndef generate_blog_post(self) -> List[str]:\n        blog_post = []\n        print(\"Generating the blog post...\\n---\")\n        for subheading in self.outline.sub_headings:\n            k = 5  # Initialize k\n            while k >= 0:\n                try:\n                    relevant_documents = (self.chroma_db.as_retriever() \\\n                    .invoke(subheading.title,\n                    k=k))\n                    section_prompt = f\"\"\"\n ...prompt_excluded_for_brevity...\n Section text:\n \"\"\"\n                    result = self.blog_post_chain.predict(section_prompt)\n                    blog_post.append(result)\n                    break\n                except Exception as e:\n                    print(f\"An error occurred: {e}\")\n                    k -= 1\n                if k < 0:\n                    print('''All attempts to fetch relevant documents have\n failed. Using an empty string for relevant_documents.\n ''')\n                    relevant_documents = \"\"\n        print(\"Finished generating the blog post!\\n---\")\n        return blog_post\n```", "```py\nsection_prompt = f\"\"\"You are currently writing the section: {subheading.title}\n---\nHere are the relevant documents for this section: {relevant_documents}.\nIf the relevant documents are not useful, you can ignore them.\nYou must never copy the relevant documents as this is plagiarism.\n---\nHere are the relevant insights that we gathered from our interview questions\nand answers: {self.questions_and_answers}.\nYou must include these insights where possible as they are important and will\nhelp our content rank better.\n---\nYou must follow the following principles:\n- You must write the section: {subheading.title}\n- Render the output in .md format\n- Include relevant formats such as bullet points, numbered lists, etc.\n---\nSection text:\n\"\"\"\n```", "```py\nDescribe in detail the writing style of Harry Dry from MarketingExamples.com\nDo not mention the writer or source, and respond only with bullet points:\n-\n```", "```py\n- Concise and to the point\n- Humorous and knowledgeable tone\n- Relatable and accessible language\n- Uses storytelling to convey ideas\n- Relies on examples and case studies\n- Provides actionable advice and tips\n- Uses subheadings and bullet points for easy readability\n- Emphasizes key points or takeaways with bold or italicized text\n- Addresses the reader directly, creating a conversational tone\n```", "```py\nRewrite the article in the following style:\n\n- Concise and to the point\n- Professional and knowledgeable tone\n- Relatable and accessible language\n- Uses storytelling to convey ideas\n- Relies on examples and case studies\n- Mixes personal anecdotes with industry insights\n- Provides actionable advice and tips\n- Uses subheadings and bullet points for easy readability\n```", "```py\nYou will be provided with the sample text.\nYour task is to rewrite the text into a different writing style.\nThe writing style can be described as follows:\n1\\. Informative and Analytical: The writer presents detailed information\nabout different strategies, especially the main theme of the text, and breaks\ndown its benefits, challenges, and implementation steps. This depth of\ninformation shows that the writer has a solid grasp of the topic.\n2\\. Structured and Organized: The writing follows a logical flow, starting\nwith a brief overview of different approaches, delving into a deep dive on\nthe topic, and concluding with potential challenges and contexts where it\nmight be best applied.\n3\\. Conversational Tone with Professionalism: While the information is\npresented in a professional manner, the writer uses a conversational tone\n(\"Here’s how to implement...\"), which makes it more relatable and easier for\nreaders to understand.\n4\\. Practical and Actionable: The writer not only explains the concept but\nalso offers actionable advice (\"Here’s how to implement X\") with step-by-step\nguidance based on real world-experience.\n5\\. Balanced Perspective: The writer doesn’t just present the benefits of the\ntopic but also discusses its challenges, which gives a well-rounded\nperspective to readers.\n6\\. Examples and Analogies: To make concepts clearer, the writer uses\nconcrete examples (e.g., how much a company might save per month) and\nanalogies (e.g., making comparisons to popular frames of reference). This\nhelps readers relate to the concepts and understand them better.\n7\\. Direct and Clear: The writer uses straightforward language without\nexcessive jargon. Concepts are broken down into digestible bits, making it\naccessible for a broad audience, even if they're not well-versed in business\nstrategies. In essence, this writing style is a blend of professional\nanalysis with practical, actionable advice, written in a clear and\nconversational tone.\n```", "```py\nillustration of websites being linked together.\nin the style of Corporate Memphis,\nwhite background, professional, clean lines, warm pastel colors\n```", "```py\nDescribe an image that would go well at the top of this article:\n\n{text}\n```", "```py\nA seamless collage or mosaic of diverse cultural elements from around the world,\nincluding traditional dances, art pieces, landmarks, and people in various\ntraditional attires, symbolizing the interconnectedness of human cultures.\n```", "```py\nimport base64\nimport os\nimport requests\nimport uuid\n\nengine_id = \"stable-diffusion-xl-1024-v1-0\"\napi_host = os.getenv('API_HOST', 'https://api.stability.ai')\napi_key = os.getenv(\"STABILITY_API_KEY\")\n\ndef generate_image(prompt):\n    response = requests.post(\n        f\"{api_host}/v1/generation/{engine_id}/text-to-image\",\n        headers={\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\",\n            \"Authorization\": f\"Bearer {api_key}\"\n        },\n        json={\n            \"text_prompts\": [\n                {\n                    \"text\":'''an illustration of \"+prompt+\". in the style of\n Corporate Memphis,\n white background, professional, clean lines, warm pastel\n colors'''\n                }\n            ],\n            \"cfg_scale\": 7,\n            \"height\": 1024,\n            \"width\": 1024,\n            \"samples\": 1,\n            \"steps\": 30,\n        },\n    )\n\n    if response.status_code != 200:\n        raise Exception(\"Non-200 response: \" + str(response.text))\n\n    data = response.json()\n\n    image_paths = []\n\n    for i, image in enumerate(data[\"artifacts\"]):\n        filename = f\"{uuid.uuid4().hex[:7]}.png\"\n        with open(filename, \"wb\") as f:\n            f.write(base64.b64decode(image[\"base64\"]))\n\n        image_paths.append(filename)\n\n    return image_paths\n\nprompt = \"\"\"A seamless collage or mosaic of diverse cultural elements from\naround the world, including traditional dances, art pieces, landmarks, and\npeople in various traditional attires, symbolizing the interconnectedness of\nhuman cultures.\"\"\"\n\ngenerate_image(prompt)\n```", "```py\nfrom image_generation_chain import create_image\nimage = create_image(outline_result.title)\n```", "```py\nimport base64\nfrom langchain_openai.chat_models import ChatOpenAI\nfrom langchain_core.messages import SystemMessage\nimport os\nimport requests\nimport uuid\n\nengine_id = \"stable-diffusion-xl-1024-v1-0\"\napi_host = os.getenv(\"API_HOST\", \"https://api.stability.ai\")\napi_key = os.getenv(\"STABILITY_API_KEY\", \"INSERT_YOUR_IMAGE_API_KEY_HERE\")\n\nif api_key == \"INSERT_YOUR_IMAGE_API_KEY_HERE\":\n    raise Exception(\n        '''You need to insert your API key in the\n image_generation_chain.py file.'''\n        \"You can get your API key from https://platform.openai.com/\"\n    )\n\ndef create_image(title) -> str:\n    chat = ChatOpenAI()\n    # 1\\. Generate the image prompt:\n    image_prompt = chat.invoke(\n        [\n            SystemMessage(content=f\"\"\"Create an image prompt\n that will be used for Midjourney for {title}.\"\"\"\n            )\n        ]\n    ).content\n\n    # 2\\. Generate the image::\n    response = requests.post(\n        f\"{api_host}/v1/generation/{engine_id}/text-to-image\",\n        headers={\n            \"Content-Type\": \"application/json\",\n            \"Accept\": \"application/json\",\n            \"Authorization\": f\"Bearer {api_key}\",\n        },\n        json={\n            \"text_prompts\": [\n                {\n                    \"text\": f'''an illustration of {image_prompt} in the\n style of Corporate Memphis, white background,\n professional, clean lines, warm pastel colors'''\n                }\n            ],\n            \"cfg_scale\": 7,\n            \"height\": 1024,\n            \"width\": 1024,\n            \"samples\": 1,\n            \"steps\": 30,\n        },\n    )\n\n    if response.status_code != 200:\n        raise Exception(\"Non-200 response: \" + str(response.text))\n\n    data = response.json()\n    image_paths = []\n\n    for i, image in enumerate(data[\"artifacts\"]):\n        filename = f\"{uuid.uuid4().hex[:7]}.png\"\n        with open(filename, \"wb\") as f:\n            f.write(base64.b64decode(image[\"base64\"]))\n        image_paths.append(filename)\n    return image_paths\n```"]