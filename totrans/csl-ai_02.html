<html><head></head><body>
<div id="sbo-rt-content"><div class="readable-text" id="p1">
<h1 class="readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">2</span> </span> <span class="chapter-title-text">A primer on probabilistic generative modeling</span></h1>
</div>
<div class="introduction-summary">
<h3 class="introduction-header sigil_not_in_toc">This chapter covers</h3>
<ul>
<li class="readable-text" id="p2">A primer on probability models</li>
<li class="readable-text" id="p3">Computational probability with the pgmpy and Pyro libraries</li>
<li class="readable-text" id="p4">Statistics for causality: data, populations, and models</li>
<li class="readable-text" id="p5">Distinguishing between probability models and subjective Bayesianism</li>
</ul>
</div>
<div class="readable-text" id="p6">
<p>Chapter 1 made the case for learning how to code causal AI. This chapter will introduce some fundamentals we need to tackle causal modeling with probabilistic machine learning, which roughly refers to machine learning techniques that use probability to model uncertainty and simulate data. There is a flexible suite of cutting-edge tools for building probabilistic machine learning models. This chapter will introduce the concepts from probability, statistics, modeling, inference, and even philosophy that we will need in order to implement key ideas from causal inference with the probabilistic machine learning approach.</p>
</div>
<div class="readable-text intended-text" id="p7">
<p>This chapter will not provide a mathematically exhaustive introduction to these ideas. I’ll focus on what is needed for the rest of this book and omit the rest. Any data scientist seeking causal inference expertise should not neglect the practical nuances of probability, statistics, machine learning, and computer science. See the chapter notes at <a href="https://www.altdeep.ai/p/causalaibook">https://www.altdeep.ai/p/causalaibook</a> for recommended resources where you can get deeper introductions or review materials.</p>
</div>
<div class="readable-text intended-text" id="p8">
<p>In this chapter, I’ll introduce two Python programming libraries for probabilistic machine learning: </p>
</div>
<ul>
<li class="readable-text" id="p9"> <em>pgmpy</em> is a library for building probabilistic graphical models. As a traditional graphical modeling tool, it is far less flexible and cutting-edge than Pyro but also easier to use and debug. What it does, it does well. </li>
<li class="readable-text" id="p10"> <em>Pyro</em> is a general probabilistic machine learning library. It is quite flexible, and it leverages PyTorch’s cutting-edge gradient-based learning techniques. </li>
</ul>
<div class="readable-text" id="p11">
<p>Pyro and pgmpy are the general modeling libraries we’ll use in this book. Other libraries we’ll use are designed specifically for causal inference.</p>
</div>
<div class="readable-text" id="p12">
<h2 class="readable-text-h2" id="sigil_toc_id_27"><span class="num-string">2.1</span> Primer on probability</h2>
</div>
<div class="readable-text" id="p13">
<p>Let’s review the probability theory you’ll need to work with this book. We’ll start with a few basic mathematical axioms and their logical extensions without yet adding any real-world interpretation. Let’s begin with the concrete idea of a simple three-sided die (these exist).</p>
</div>
<div class="readable-text" id="p14">
<h3 class="readable-text-h3" id="sigil_toc_id_28"><span class="num-string">2.1.1</span> Random variables and probability</h3>
</div>
<div class="readable-text" id="p15">
<p>A <em>random variable</em> is a variable whose possible values are the numerical outcomes of a random phenomenon. These values can be discrete or continuous. In this section, we’ll focus on the discrete case. For example, the values of a discrete random variable representing a three-sided die roll could be {1, 2, 3}. Alternatively, in a 0-indexed programming language like Python, it might be better to use {0, 1, 2}. Similarly, a discrete random variable representing a coin flip could have outcomes {0, 1} or {True, False}. Figure 2.1 illustrates three-sided dice.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p16">
<img alt="figure" height="287" src="../Images/CH02_F01_Ness.png" width="529"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.1</span> Three-sided dice each represent a random variable with three discrete outcomes.</h5>
</div>
<div class="readable-text intended-text" id="p17">
<p>The typical approach to notation is to write random variables with capitals like <em>X</em>, <em>Y</em>, and <em>Z</em>. For example, suppose <em>X</em> represents a die roll with outcomes {1, 2, 3}, and the outcome represents the number on the side of the die. <em>X</em><em> </em>=<em> </em>1 and <em>X</em><em> </em>=<em> </em>2 represent the events of rolling a 1 and 2 respectively. If we want to abstract away the specific outcome with a variable, we typically use lowercase. For example, I would use “<em>X</em><em> </em>=<em> </em><em>x</em>” (e.g., <em>X</em><em> </em>=<em> </em>1) to represent the event “I rolled an ‘<em>x</em><em> </em>’!” where <em>x</em> can be any value in {1, 2, 3}. See figure 2.2.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p18">
<img alt="figure" height="211" src="../Images/CH02_F02_Ness.png" width="501"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.2</span> <em>X</em> represents the outcome of a three-sided die roll. If the die roles a 2, the observed outcome is <em>X</em>=2.</h5>
</div>
<div class="readable-text" id="p19">
<p>Each outcome of a random variable has a <em>probability value</em>. The probability value is often called a <em>probability mass</em> for discrete variables and a <em>probability density</em> for continuous variables. For discrete variables, probability values are between zero and one, and summing up the probability values for each possible outcome yields 1. For continuous variables, probability densities are greater than zero, and integrating the probability densities over each possible outcome yields 1.</p>
</div>
<div class="readable-text intended-text" id="p20">
<p>Given a random variable with outcomes {0, 1} representing a coin flip, what is the probability value assigned to 0? What about 1? At this point, we just know the two values are between zero and one, and that they sum to one. To go beyond that, we have to talk about how to <em>interpret</em> probability. First, though, let’s hash out a few more concepts.</p>
</div>
<div class="readable-text" id="p21">
<h3 class="readable-text-h3" id="sigil_toc_id_29"><span class="num-string">2.1.2</span> Probability distributions and distribution functions</h3>
</div>
<div class="readable-text" id="p22">
<p>A <em>probability distribution function</em> is a function that maps the random variable outcomes to a probability value. For example, if the outcome of a coin flip is 1 (heads) and the probability value is 0.51, the distribution function maps 1 to 0.51. I stick to the standard notation <em>P</em><em> </em>(<em>X</em>=<em>x</em>), as in <em>P</em><em> </em>(<em>X</em>=1) = 0.51. For longer expressions, when the random variable is obvious, I drop the capital letter and keep the outcome, so <em>P</em><em> </em>(<em>X</em><em> </em>=<em>x</em><em> </em>) becomes <em>P</em><em> </em>(<em>x</em><em> </em>), and <em>P</em><em> </em>(<em>X</em>=1) becomes <em>P</em><em> </em>(1).</p>
</div>
<div class="readable-text intended-text" id="p23">
<p>If the random variable has a finite set of discrete outcomes, we can represent the probability distribution with a table. For example, a random variable representing outcomes {1, 2, 3} might look like figure 2.3.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p24">
<img alt="figure" height="83" src="../Images/CH02_F03_Ness.png" width="270"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.3</span> A simple tabular representation of a discrete distribution</h5>
</div>
<div class="readable-text" id="p25">
<p> In this book, I adopt the common notation <em>P</em>(<em>X</em>) to represent the probability distribution over all possible outcomes of <em>X</em>, while <em>P</em><em> </em>(<em>X</em><em> </em>=<em> </em><em>x</em><em> </em>) represents the probability value of a specific outcome. To implement a probability distribution as an object in pgmpy, we’ll use the <code>DiscreteFactor</code> class. </p>
</div>
<div class="browsable-container listing-container" id="p26">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 2.1</span> Implementing a discrete distribution table in pgmpy</h5>
<div class="code-area-container">
<pre class="code-area">from pgmpy.factors.discrete import DiscreteFactor
dist = DiscreteFactor(
    variables=["X"],   <span class="aframe-location"/> #1
    cardinality=[3],   <span class="aframe-location"/> #2
  <span class="aframe-location"/>  values=[.45, .30, .25],  #3
    state_names= {'X': ['1', '2', '3']}    <span class="aframe-location"/> #4
)
print(dist)</pre>
<div class="code-annotations-overlay-container">
     #1 A list of the names of the variables in the factor
     <br/>#2 The cardinality (number of possible outcomes) of each variable in the factor
     <br/>#3 The values each variable in the factor can take
     <br/>#4 A dictionary, where the key is the variable name and the value is a list of the names of that variable’s outcomes
     <br/>
</div>
</div>
</div>
<div class="readable-text" id="p27">
<p>This code prints out the following:</p>
</div>
<div class="browsable-container listing-container" id="p28">
<div class="code-area-container">
<pre class="code-area">+------+----------+
| X    |   phi(X) |
+======+==========+
| X(1) |   0.4500 |
+------+----------+
| X(2) |   0.3000 |
+------+----------+
| X(3) |   0.2500 |
+------+----------+</pre>
</div>
</div>
<div class="callout-container sidebar-container">
<div class="readable-text" id="p29">
<h5 class="callout-container-h5 readable-text-h5 sigil_not_in_toc">Setting up your environment</h5>
</div>
<div class="readable-text" id="p30">
<p>This code was written with pgmpy version 0.1.24 and Pyro version 1.8.6. The version of pandas used was 1.5.3.</p>
</div>
<div class="readable-text" id="p31">
<p>See <a href="https://www.altdeep.ai/p/causalaibook">https://www.altdeep.ai/p/causalaibook</a> for links to the Jupyter notebooks for each chapter, with the code and notes on setting up a working environment.</p>
</div>
</div>
<div class="readable-text" id="p32">
<h3 class="readable-text-h3" id="sigil_toc_id_30"><span class="num-string">2.1.3</span> Joint probability and conditional probability</h3>
</div>
<div class="readable-text" id="p33">
<p>Often, we are interested in reasoning about more than one random variable. Suppose, in addition to the random variable <em>X</em> in figure 2.1, there was an additional random variable <em>Y</em> with two outcomes {0, 1}. Then there is a <em>joint probability</em> distribution function that maps each combination of <em>X</em> and <em>Y</em> to a probability value.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p34">
<img alt="figure" height="156" src="../Images/CH02_F04_Ness.png" width="260"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.4</span> A simple representation of a tabular joint probability distribution</h5>
</div>
<div class="readable-text intended-text" id="p35">
<p>As a table, it could look like figure 2.4.</p>
</div>
<div class="readable-text intended-text" id="p36">
<p>The <code>DiscreteFactor</code> object can represent joint distributions as well.</p>
</div>
<div class="browsable-container listing-container" id="p37">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 2.2</span> Modeling a joint distribution in pgmpy</h5>
<div class="code-area-container">
<pre class="code-area">joint = DiscreteFactor(
    variables=['X', 'Y'],  <span class="aframe-location"/> #1
    cardinality=[3, 2],  <span class="aframe-location"/>   #2


values=[.25, .20, .20, .10, .15, .10],    <span class="aframe-location"/> #3
    state_names= {
        'X': ['1', '2', '3'],    #3
        'Y': ['0', '1']    #3
    }
)
print(joint)    <span class="aframe-location"/> #4</pre>
<div class="code-annotations-overlay-container">
     #1 Now we have two variables instead of one.
     <br/>#2 X has 3 outcomes, Y has 2.
     <br/>#3 Now there are two variables, so we name the outcomes for both variables.
     <br/>#4 You can look at the printed output to see how the values are ordered of values.
     <br/>
</div>
</div>
</div>
<div class="readable-text" id="p38">
<p>The preceding code prints this output:</p>
</div>
<div class="browsable-container listing-container" id="p39">
<div class="code-area-container">
<pre class="code-area">+------+------+------------+
| X    | Y    |   phi(X,Y) |
+======+======+============+
| X(1) | Y(0) |     0.2500 |
+------+------+------------+
| X(1) | Y(1) |     0.2000 |
+------+------+------------+
| X(2) | Y(0) |     0.2000 |
+------+------+------------+
| X(2) | Y(1) |     0.1000 |
+------+------+------------+
| X(3) | Y(0) |     0.1500 |
+------+------+------------+
| X(3) | Y(1) |     0.1000 |
+------+------+------------+</pre>
</div>
</div>
<div class="readable-text" id="p40">
<p>Note that the probability values sum to 1. Further, when we marginalize (i.e., “sum over” or “integrate over”) <em>Y</em> across the rows, we recover the original distribution <em>P</em><em> </em>(<em>X</em><em>  </em>), (aka the marginal distribution of <em>X</em><em>  </em>). Summing up over the rows in figure 2.5 produces the marginal distribution of <em>X</em> on the bottom.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p41">
<img alt="figure" height="182" src="../Images/CH02_F05_Ness.png" width="260"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.5</span> Marginalizing over <em>Y</em> yields the marginal distribution of <em>X</em>.</h5>
</div>
<div class="readable-text" id="p42">
<p>The marginalize method will sum over the specified variables for us.</p>
</div>
<div class="browsable-container listing-container" id="p43">
<div class="code-area-container code-area-with-html">
<pre class="code-area"><strong>print(joint.marginalize(variables=['Y'], inplace=False)</strong><strong>)</strong></pre>
</div>
</div>
<div class="readable-text" id="p44">
<p>This prints the following output:</p>
</div>
<div class="browsable-container listing-container" id="p45">
<div class="code-area-container">
<pre class="code-area">+------+----------+
| X    |   phi(X) |
+======+==========+
| X(1) |   0.4500 |
+------+----------+
| X(2) |   0.3000 |
+------+----------+
| X(3) |   0.2500 |
+------+----------+</pre>
</div>
</div>
<div class="readable-text" id="p46">
<p>Setting the <code>inplace</code> argument to <code>False</code> gives us a new marginalized table rather than modifying the original joint distribution table.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p47">
<img alt="figure" height="152" src="../Images/CH02_F06_Ness.png" width="318"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.6</span> Marginalizing over <em>X</em> yields the marginal distribution of <em>Y</em>.</h5>
</div>
<div class="readable-text intended-text" id="p48">
<p>Similarly, when we marginalize <em>X</em> over the columns, we get <em>P</em><em> </em>(<em>Y</em><em>  </em>). In figure 2.6, summing over the values of <em>X</em> in the columns gives us the marginal distribution of <em>Y</em> on the right.</p>
</div>
<div class="browsable-container listing-container" id="p49">
<div class="code-area-container code-area-with-html">
<pre class="code-area"><strong>print(joint.marginalize(variables=['X'], inplace=False))</strong></pre>
</div>
</div>
<div class="readable-text" id="p50">
<p>This prints the following output:</p>
</div>
<div class="browsable-container listing-container" id="p51">
<div class="code-area-container">
<pre class="code-area">+------+----------+
| Y    |   phi(Y) |
+======+==========+
| Y(0) |   0.6000 |
+------+----------+
| Y(1) |   0.4000 |
+------+----------+</pre>
</div>
</div>
<div class="readable-text" id="p52">
<p>I’ll use the notation <em>P</em><em> </em>(<em>X</em>, <em>Y</em><em>  </em>) to represent joint distributions. I’ll use <em>P</em><em> </em>(<em>X</em><em> </em>=<em>x</em>, <em>Y</em><em> </em>=<em> </em><em>y</em>) to represent an outcome probability, and for shorthand, I’ll write <em>P</em><em> </em>(<em>x</em>, <em>y</em>). For example, in figure 2.6, <em>P</em><em> </em>(<em>X</em><em> </em>=1, <em>Y</em><em> </em>=<em> </em>0) = <em>P</em><em> </em>(1, 0) = 0.25. We can define a joint distribution on any number of variables; if there were three variables {<em>X</em>, <em>Y</em>, <em>Z</em><em>  </em>}, I’d write the joint distribution as <em>P</em><em> </em>(<em>X</em>, <em>Y</em>, <em>Z</em><em>  </em>).</p>
</div>
<div class="readable-text intended-text" id="p53">
<p>In this tabular representation of the joint probability distribution, the number of cells increases exponentially with each additional variable. There are some (but not many) “canonical” joint probability distributions (such as the multivariate normal distribution—I’ll show more examples in section 2.1.7). For that reason, in multivariate settings, we tend to work with <em>conditional probability</em> distributions.</p>
</div>
<div class="readable-text intended-text" id="p54">
<p>The conditional probability of <em>Y</em>, given <em>X</em>, is<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p55">
<img alt="figure" height="55" src="../Images/ness-ch2-eqs-0x.png" width="370"/>
</div>
<div class="readable-text" id="p56">
<p>Intuitively, <em>P</em><em> </em>(<em>Y</em><em>  </em>|<em>X</em><em>  </em>=<em> </em>1) refers to the probability distribution for Y conditional on <em>X</em> being 1. In the case of tabular representations of distributions, we can derive the conditional distribution table by dividing the cells in the joint probability distribution table with the marginal probability values, as in figure 2.7. Note that the columns on the conditional probability table in figure 2.7 now sum to 1. <span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p57">
<img alt="figure" height="203" src="../Images/CH02_F07_Ness.png" width="553"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.7</span> Derive the values of the conditional probability distribution by dividing the values of the joint distribution by those of the marginal distribution.</h5>
</div>
<div class="readable-text" id="p58">
<p>The pgmpy library allows us to do this division using the “/” operator:</p>
</div>
<div class="browsable-container listing-container" id="p59">
<div class="code-area-container code-area-with-html">
<pre class="code-area"><strong>print(joint / dist)</strong></pre>
</div>
</div>
<div class="readable-text" id="p60">
<p>That line produces the following output:</p>
</div>
<div class="browsable-container listing-container" id="p61">
<div class="code-area-container">
<pre class="code-area">+------+------+------------+
| X    | Y    |   phi(X,Y) |
+======+======+============+
| X(1) | Y(0) |     0.5556 |
+------+------+------------+
| X(1) | Y(1) |     0.4444 |
+------+------+------------+
| X(2) | Y(0) |     0.6667 |
+------+------+------------+
| X(2) | Y(1) |     0.3333 |
+------+------+------------+
| X(3) | Y(0) |     0.6000 |
+------+------+------------+
| X(3) | Y(1) |     0.4000 |
+------+------+------------+</pre>
</div>
</div>
<div class="readable-text" id="p62">
<p>Also, you can directly specify a conditional probability distribution table with the <code>TabularCPD</code> class:</p>
</div>
<div class="browsable-container listing-container" id="p63">
<div class="code-area-container code-area-with-html">
<pre class="code-area">from pgmpy.factors.discrete.CPD import TabularCPD
PYgivenX = TabularCPD(
    variable='Y',   <span class="aframe-location"/> #1
    variable_card=2,    <span class="aframe-location"/> #2
    values=[  
        [.25/.45, .20/.30, .15/.25],    <span class="aframe-location"/> #3
        [.20/.45, .10/.30, .10/.25],     #3
    ], 
    evidence=['X'],
    evidence_card=[3],
    state_names = {
        'X': ['1', '2', '3'],
        'Y': ['0', '1']
    })

<strong>print(PYgivenX)</strong></pre>
<div class="code-annotations-overlay-container">
     #1 A conditional distribution has one variable instead of ΔiscreteFactor’s list of variables.
     <br/>#2 variable_card is the cardinality of Y.
     <br/>#3 Elements of the list correspond to outcomes for Y. Elements of each list correspond to elements of X.
     <br/>
</div>
</div>
</div>
<div class="readable-text" id="p64">
<p>That produces the following output:</p>
</div>
<div class="browsable-container listing-container" id="p65">
<div class="code-area-container">
<pre class="code-area">+------+--------------------+---------------------+------+
| X    | X(1)               | X(2)                | X(3) |
+------+--------------------+---------------------+------+
| Y(0) | 0.5555555555555556 | 0.6666666666666667  | 0.6  |
+------+--------------------+---------------------+------+
| Y(1) | 0.4444444444444445 | 0.33333333333333337 | 0.4  |
+------+--------------------+---------------------+------+</pre>
</div>
</div>
<div class="readable-text" id="p66">
<p>The <code>variable_card</code> argument is the cardinality of <em>Y</em> (meaning the number of outcomes <em>Y</em> can take), and <code>evidence_card</code> is the cardinality of <em>X</em>.</p>
</div>
<div class="callout-container sidebar-container">
<div class="readable-text" id="p67">
<h5 class="callout-container-h5 readable-text-h5 sigil_not_in_toc">Conditioning as an operation</h5>
</div>
<div class="readable-text" id="p68">
<p>In the phrase “conditional probability,” “conditional” is an adjective. It is useful to think of “condition” as a verb (an action). You condition a random variable like <em>Y</em> on another random variable <em>X</em>. For example, in figure 2.5, I can condition <em>Y</em><em> </em>on <em>X</em>=1, and essentially get a new random variable with the same outcome values as <em>Y</em> but with a probability distribution equivalent to <em>P</em>(<em>Y</em>|<em>X</em>=1).</p>
</div>
<div class="readable-text" id="p69">
<p>For those with more programming experience, think of conditioning on <em>X</em> = 1 as filtering on the event <em>X</em> == 1; for example, “what is the probability distribution of <em>Y</em> when <em>X</em> == 1?” Filtering in this sense is like the <code>WHERE</code> clause in a SQL query. <em>P</em>(<em>Y</em>) is the distribution of the rows in the <em>Y</em> table when your query is <code>SELECT</code> <code>*</code> <code>FROM</code> <code>Y</code>, and <em>P</em>(<em>Y</em>|<em>X</em>=1) is the distribution of the rows when your query is <code>SELECT</code> <code>*</code> <code>FROM</code> <code>Y</code> <code>WHERE X=1</code>.</p>
</div>
<div class="readable-text" id="p70">
<p>Thinking of “conditioning” as an action helps us better understand probabilistic machine learning libraries. In these libraries, you have objects representing random variables, and conditioning is an operation applied to these objects. As you’ll see, the idea of conditioning as an action also contrasts nicely with the core causal modeling concept of “intervention,” where we “intervene” on a random variable.</p>
</div>
<div class="readable-text" id="p71">
<p>Pyro implements conditioning as an operation with the <code>pyro.condition</code> function. We’ll explore this in chapter 3.</p>
</div>
</div>
<div class="readable-text" id="p72">
<h3 class="readable-text-h3" id="sigil_toc_id_31"><span class="num-string">2.1.4</span> The chain rule, the law of total probability, and Bayes Rule</h3>
</div>
<div class="readable-text" id="p73">
<p>From the basic axioms of probability, we can derive the chain rule of probability, the law of total probability, and Bayes rule. These laws of probability are especially important in the context of probabilistic modeling and causal modeling, so we’ll highlight them briefly.</p>
</div>
<div class="readable-text intended-text" id="p74">
<p>The <em>chain rule of probability</em> states that we can factorize a joint probability into the product of conditional probabilities. For example <em>P</em><em> </em>(<em>X</em>, <em>Y</em>, <em>Z</em><em> </em>) can be factorized as follows:<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p75">
<img alt="figure" height="22" src="../Images/ness-ch2-eqs-1x.png" width="376"/>
</div>
<div class="readable-text" id="p76">
<p>We can factorize in any order we like. Above, the ordering was <em>X</em>, then <em>Y</em>, then <em>Z</em>. However, <em>Y</em>, then <em>Z</em>, then <em>X</em>, or <em>Z</em>, then <em>X</em>, then <em>Y</em>, and other orderings are just as valid.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p77">
<img alt="figure" height="96" src="../Images/ness-ch2-eqs-2x.png" width="385"/>
</div>
<div class="readable-text" id="p78">
<p>The chain rule is important from a modeling and a computational perspective. The challenge of implementing a single object that represents <em>P</em><em> </em>(<em>X</em>, <em>Y</em>, <em>Z</em><em> </em>) is that it needs to map each combination of possible outcomes for <em>X</em>, <em>Y</em>, and <em>Z</em> to a probability value. The chain rule lets us break this into three separate tasks for each factor in a factorization of <em>P</em><em> </em>(<em>X</em>, <em>Y</em>, <em>Z</em><em> </em>).</p>
</div>
<div class="readable-text intended-text" id="p79">
<p>The <em>law of total probability</em> allows you to relate marginal probability distributions (distributions of individual variables) to joint distributions. For example, if we want to derive the marginal distribution of <em>X</em>, denoted <em>P</em>(<em>X</em>), from the distribution of <em>X</em> and <em>Y</em>, denoted <em>P</em><em> </em>(<em>X</em>, <em>Y</em><em>  </em>), we can sum over <em>Y</em>.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p80">
<img alt="figure" height="56" src="../Images/ness-ch2-eqs-3x.png" width="204"/>
</div>
<div class="readable-text" id="p81">
<p>In figure 2.5, we did this by summing over <em>Y</em> in the rows to get <em>P</em><em> </em>(<em>X</em><em> </em>). In the case where <em>X</em> is a continuous random variable, we integrate over <em>Y</em> rather than summing over <em>Y</em>. </p>
</div>
<div class="readable-text intended-text" id="p82">
<p>Finally, we have <em>Bayes rule</em>:<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p83">
<img alt="figure" height="56" src="../Images/ness-ch2-eqs-4x.png" width="235"/>
</div>
<div class="readable-text" id="p84">
<p>We derive this by taking the original definition of conditional probability and applying the chain rule to the numerator:<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p85">
<img alt="figure" height="56" src="../Images/ness-ch2-eqs-5x.png" width="351"/>
</div>
<div class="readable-text" id="p86">
<p>By itself, the Bayes rule is not particularly interesting—it’s a derivation. The more interesting idea is <em>Bayesianism</em>, a philosophy that uses Bayes rule to help the modeler reason about their subjective uncertainty regarding the problems they are modeling. I’ll touch on this in section 2.4.</p>
</div>
<div class="readable-text" id="p87">
<h3 class="readable-text-h3" id="sigil_toc_id_32"><span class="num-string">2.1.5</span> Markovian assumptions and Markov kernels</h3>
</div>
<div class="readable-text" id="p88">
<p>A common approach to modeling when you have chains of factors is to use <em>Markovian assumptions</em>. This modeling approach takes an ordering of variables and makes a simplifying assumption that every element in the ordering depends only on the element that came directly before it. For example, consider again the following factorization of <em>P</em><em> </em>(<em>x</em>, <em>y</em>, <em>z</em>): <span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p89">
<img alt="figure" height="22" src="../Images/ness-ch2-eqs-6x.png" width="376"/>
</div>
<div class="readable-text" id="p90">
<p>If we applied a Markovian assumption, this would simplify to: <span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p91">
<img alt="figure" height="22" src="../Images/ness-ch2-eqs-7x.png" width="349"/>
</div>
<div class="readable-text" id="p92">
<p>This would let us replace <em>P</em><em> </em>(<em>z</em><em>  </em>|<em>x</em>, <em>y</em>) with <em>P</em><em> </em>(<em>z</em><em>  </em>|<em>y</em>), which is easier to model. In this book, when we have a factor from a factorization that has been simplified using the Markov assumption, like <em>P</em><em> </em>(<em>z</em><em>  </em>|<em>y</em>), we’ll call it a <em>Markov kernel</em>.</p>
</div>
<div class="readable-text intended-text" id="p93">
<p>The Markov assumption is a common simplifying assumption in statistics and machine learning; <em>Z</em> may <em>actually</em> still depend on <em>X</em> after accounting for <em>Y</em>, but we’re <em>assuming</em> that the dependence is weak and we can safely ignore it in our model. We’ll see that the Markovian assumption is key to graphical causality, where we’ll assume effects are independent of their indirect causes, given their direct causes.</p>
</div>
<div class="readable-text" id="p94">
<h3 class="readable-text-h3" id="sigil_toc_id_33"><span class="num-string">2.1.6</span> Parameters</h3>
</div>
<div class="readable-text" id="p95">
<p>Suppose I wanted to implement in code an abstract representation of a probability distribution, like the tabular distribution in figure 2.1, that I could use for different finite discrete outcomes. To start, if I were to model another three-sided die, it might have different probability values. What I want to keep is the basic structure as in figure 2.8.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p96">
<img alt="figure" height="91" src="../Images/CH02_F08_Ness.png" width="270"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.8</span> The scaffolding for a tabular probability distribution data structure</h5>
</div>
<div class="readable-text intended-text" id="p97">
<p>In code, I could represent this as some object type with a constructor that takes two arguments, <em>ρ</em><sub>1</sub> and <em>ρ</em><sub>2</sub>, as in figure 2.9 (“<em>ρ</em>” is the Greek letter “rho”).<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p98">
<img alt="figure" height="92" src="../Images/CH02_F09_Ness.png" width="274"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.9</span> Adding parameters to the data structure</h5>
</div>
<div class="readable-text intended-text" id="p99">
<p>The reason the third probability value is a function of the other two (instead of a third argument, <em>ρ</em><sub>3</sub>) is because the probability values must sum to one. The set of two values {<em>ρ</em><sub>1</sub>, <em>ρ</em><sub>2</sub>} are the parameters of the distribution. In programming terms, I could create a data type that represents a table with three values. Then, when I want a new distribution, I could construct a new instance of this type with these two parameters as arguments.</p>
</div>
<div class="readable-text intended-text" id="p100">
<p>Finally, in my three-sided die example, there were three outcomes, {1, 2, 3}. Perhaps I want my data structure to handle a different prespecified number of outcomes. In that case, I’d need a parameter for the number of outcomes. Let’s denote that with the Greek letter kappa, <em>Κ</em>. My parameterization is {<em>Κ</em>, <em>ρ</em><sub>1</sub>, <em>ρ</em><sub>2</sub>, … <em>ρ</em><em><sub>Κ</sub></em><sub>–1</sub>}, where <em>ρ</em><em><sub>Κ</sub></em><sub> </sub>is 1 minus the sum of the other <em>ρ</em> parameters.</p>
</div>
<div class="readable-text intended-text" id="p101">
<p>In the pgmpy classes <code>DiscreteFactor</code> and <code>TabularCPD</code>, the <em>ρ</em><em>’</em>s (rhos) are the list of values passed to the <code>values</code> argument, and the <em>Κ</em> corresponds to the values passed to the <code>cardinality</code>, <code>variable_card</code>, and <code>evidence_card</code> arguments. Once we have a representation of a probability distribution like <code>TabularCPD</code>, we can specify an instance of that distribution with a set of parameters.</p>
</div>
<div class="callout-container sidebar-container">
<div class="readable-text" id="p102">
<h5 class="callout-container-h5 readable-text-h5 sigil_not_in_toc">Greeks vs. Romans</h5>
</div>
<div class="readable-text" id="p103">
<p>In this book, I use Roman letters (<em>A</em>, <em>B</em>, and <em>C</em>) to refer to random variables representing objects in the modeling domain, such as a “dice roll” or “gross domestic product,” and I use Greek letters for so-called <em>parameters</em>. <em>Parameters</em> in this context are values that characterize the probability distributions of the Roman-lettered variables. This distinction between Greeks and Romans is not as important in statistics; for example, a Bayesian statistician treats both Roman and Greek letters as random variables. However, in causal modeling the difference matters, because Roman letters can be causes and effects, while Greek letters serve to characterize the statistical relationship between causes and effects. </p>
</div>
</div>
<div class="readable-text" id="p104">
<h3 class="readable-text-h3" id="sigil_toc_id_34"><span class="num-string">2.1.7</span> Canonical classes of probability distribution</h3>
</div>
<div class="readable-text" id="p105">
<p>There are several common classes of distribution functions. For example, the tabular examples we just studied are examples from the class of <em>categorical distributions</em>. Categorical distributions are distributions on discrete outcomes we can view as categories, such as {“ice cream”, “frozen yogurt”, “sherbet”}. A Bernoulli distribution class is a special case of the categorical class where there are only two possible outcomes. A discrete uniform distribution is a categorical distribution where all outcomes have the same probability. In implementation, categorical distributions are defined either on the categories directly (like “tails” and “heads”) or on indices to the category (like 0 and 1).</p>
</div>
<div class="callout-container sidebar-container">
<div class="readable-text" id="p106">
<h5 class="callout-container-h5 readable-text-h5 sigil_not_in_toc">Discrete vs. continuous random variables </h5>
</div>
<div class="readable-text" id="p107">
<p>For discrete random variables, we have been using have probability distribution functions with the notation <em>P</em>(<em>X</em><em> </em>=<em> </em><em>x</em>). Probability distribution functions return the probability that a variable takes a specific value. With continuous random variables, we also have <em>probability density functions</em>, which describe the relative likelihood of observing any outcome within a continuous range and that integrate over an interval to give a probability. </p>
</div>
<div class="readable-text" id="p108">
<p>When we have specific cases where discrete or continuous parameterizations matter, we’ll call them out and use <em>p</em>(<em>X</em><em> </em>=<em> </em><em>x</em>) to denote a probability density function. However, in this book, we’ll focus on framing our causal questions independently of whether we’re in a discrete or continuous setting. We’ll stick mostly to the probability distribution function notation <em>P</em>(<em>X</em><em> </em>=<em> </em><em>x</em>), but keep in mind that the causal ideas work in the continuous case as well. </p>
</div>
</div>
<div class="readable-text" id="p109">
<p>There are other canonical distribution classes appropriate for continuous, bounded, or unbounded sets of variables. For example, the normal (Gaussian) distribution class illustrates the famous “bell curve.” I use the term “class” (or, perhaps more ideally, “type”) in the computer science sense because the distribution isn’t realized until we assign our Greek-lettered parameters. For a normal (Gaussian) distribution class, the probability density function is<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p110">
<img alt="figure" height="57" src="../Images/ness-ch2-eqs-8x.png" width="332"/>
</div>
<div class="readable-text" id="p111">
<p>Here, <em>μ</em> and <em class="obliqued">σ</em> are the parameters. </p>
</div>
<div class="readable-text intended-text" id="p112">
<p>Figure 2.10 is a popular figure that illustrates several commonly used canonical distributions. The arrows between the distributions highlight relationships between the distributions (e.g., Bernoulli is a special case of the binomial distribution) that we won’t dive into here.</p>
</div>
<div class="browsable-container figure-container" id="p113">
<img alt="figure" height="672" src="../Images/CH02_F10_Ness.png" width="913"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.10</span> A popular common set of canonical probability distributions. The edges capture mathematical relationships between the distributions (that we won’t get into here). Light-colored distributions are discrete and dark-colored distributions are continuous. An arrow represents the existence of a transformation that converts one distribution to another.<span class="aframe-location"/></h5>
</div>
<div class="readable-text" id="p114">
<h4 class="readable-text-h4 sigil_not_in_toc">Types of parameters</h4>
</div>
<div class="readable-text" id="p115">
<p>In probabilistic modeling settings, it is useful to have an intuition for how to interpret canonical parameters. To that end, think of the probability in a distribution as a scarce resource that must be shared across all the possible outcomes. Some outcomes may get more than others, but at the end of the day, it all must sum or integrate to 1. Parameters characterize how the finite probability is distributed to the outcomes.</p>
</div>
<div class="readable-text intended-text" id="p116">
<p>As an analogy, we’ll use a city with a fixed population. The parameters of the city determine where that population is situated. Location parameters, such as the normal distribution’s “<em>μ</em>” (<em>μ</em> is the mean of the normal, but not all <em>location parameters</em> are means), are like the pin that drops down when you search the city’s name in Google Maps. The pin characterizes a precise point we might call the “city center.” In some cities, most of the people live near the city center, and it gets less populated the further away from the center you go. But in other cities, other non-central parts of the city are densely populated. <em>Scale parameters</em>, like the normal’s “<em class="obliqued">σ</em>” (<em class="obliqued">σ</em> is the standard deviation of a normal distribution, but not all scale parameters are standard deviation parameters), determine the spread of the population; Los Angeles has a high scale parameter. A <em>shape parameter</em> (and its inverse, the <em>rate parameter</em>) affects the shape of a distribution in a manner that does not simply shift it (as a location parameter does) or stretch or shrink it (as a scale parameter does). As an example, think of the skewed shape of Hong Kong, which has a densely packed collection of skyscrapers in the downtown area, while the more residential Kowloon has shorter buildings spread over a wider space.</p>
</div>
<div class="readable-text intended-text" id="p117">
<p>The Pyro library provides canonical distributions as modeling primitives. The Pyro analog to a discrete categorical distribution table is a <code>Categorical</code> object.</p>
</div>
<div class="browsable-container listing-container" id="p118">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 2.3</span> Canonical parameters in Pyro</h5>
<div class="code-area-container">
<pre class="code-area">import torch
from pyro.distributions import Bernoulli, Categorical, Gamma, Normal   <span class="aframe-location"/> #1

print(Categorical(probs=torch.tensor([.45, .30, .25])))   <span class="aframe-location"/> #2
print(Normal(loc=0.0, scale=1.0))
print(Bernoulli(probs=0.4))
print(Gamma(concentration=1.0, rate=2.0))</pre>
<div class="code-annotations-overlay-container">
     #1 Pyro includes the commonly used canonical distributions.
     <br/>#2 The Categorical distribution takes a list of probability values, each value corresponding to an outcome.
     <br/>
</div>
</div>
</div>
<div class="readable-text" id="p119">
<p>This prints the following representations of the distribution objects:</p>
</div>
<div class="browsable-container listing-container" id="p120">
<div class="code-area-container">
<pre class="code-area">Categorical(probs: torch.Size([3]))
Normal(loc: 0.0, scale: 1.0)
Bernoulli(probs: 0.4000)
Gamma(concentration: 1.0, rate: 2.0)</pre>
</div>
</div>
<div class="readable-text" id="p121">
<p>Rather than providing a probability value, the <code>log_prob</code> method will provide the natural log of the probability value, because log probabilities have computational advantages over regular probabilities. Exponentiating (taking <em>e</em><em> </em><sup><em>l</em></sup> where <em>l</em> is the log probability) converts back to the probability scale. For example, we can create a Bernoulli distribution object with a parameter value of 0.4.</p>
</div>
<div class="browsable-container listing-container" id="p122">
<div class="code-area-container">
<pre class="code-area">bern = Bernoulli(0.4)</pre>
</div>
</div>
<div class="readable-text" id="p123">
<p>That distribution assigns a 0.4 probability to the value 1.0. For numerical reasons, we typically work with the natural log of probability values. </p>
</div>
<div class="readable-text intended-text" id="p124">
<p>We can use the <code>exp</code> function in the math library to convert from log probability back to the probability scale:</p>
</div>
<div class="browsable-container listing-container" id="p125">
<div class="code-area-container">
<pre class="code-area">lprob = bern.log_prob(torch.tensor(1.0))

import math
print(math.exp(lprob))</pre>
</div>
</div>
<div class="readable-text" id="p126">
<p>Exponentiating the log probability returns the following probability value:</p>
</div>
<div class="browsable-container listing-container" id="p127">
<div class="code-area-container">
<pre class="code-area">0.3999999887335489</pre>
</div>
</div>
<div class="readable-text" id="p128">
<p>It is close, but not the same as 0.4 due to rounding error associated with floating-point precision in computer calculations.</p>
</div>
<div class="readable-text" id="p129">
<h4 class="readable-text-h4 sigil_not_in_toc">Conditional probability with canonical distributions</h4>
</div>
<div class="readable-text" id="p130">
<p>There are few canonical distributions commonly used to characterize sets of individual random variables, such as random vectors or matrices. However, we can use the chain rule to factor a joint probability distribution into conditional distributions that we can represent with canonical distributions. For example, we could represent <em>Y</em> conditioned on <em>X</em> and <em>Z</em> with the following normal distribution,<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p131">
<img alt="figure" height="58" src="../Images/ness-ch2-eqs-9x.png" width="355"/>
</div>
<div class="readable-text" id="p132">
<p>where the location parameter <em>μ</em>(<em>x</em>,<em>z</em>) is a function of <em>x</em> and <em>z</em>. An example is the following linear function:<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p133">
<img alt="figure" height="23" src="../Images/ness-ch2-eqs-10x.png" width="279"/>
</div>
<div class="readable-text" id="p134">
<p>Other functions, such as neural networks, are possible as well. These <em class="obliqued">β</em> parameters are typically called <em>weight parameters</em> in machine learning.</p>
</div>
<div class="readable-text" id="p135">
<h3 class="readable-text-h3" id="sigil_toc_id_35"><span class="num-string">2.1.8</span> Visualizing distributions</h3>
</div>
<div class="readable-text" id="p136">
<p>In probabilistic modeling and Bayesian inference settings, we commonly conceptualize distributions in terms of visuals. In the discrete case, a common visualization is the bar plot. For example, we can visualize the probabilities in figure 2.3 as the bar plot in figure 2.11. Note that this is not a histogram; I’ll highlight the distinction in section 2.3.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p137">
<img alt="figure" height="494" src="../Images/CH02_F11_Ness.png" width="709"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.11</span> Visualization of a discrete probability distribution. The outcomes in the distribution are on the horizontal axis, and probability is on the vertical axis.</h5>
</div>
<div class="readable-text" id="p138">
<p>We still use visualizations when the distribution has a non-finite set of outcomes. For example, figure 2.12 overlays two distributions functions: a discrete Poisson distribution and a continuous normal (Gaussian) distribution (I specified the two distributions in such a way that they overlapped). The discrete Poisson has no upper bound on outcomes (its lower bound is 0), but the probability tapers off for higher numbers, resulting in smaller and smaller bars until the bar becomes too infinitesimally small to draw. We visualize the normal distribution by simply drawing the probability distribution function as a curve in the figure. The normal has no lower or upper bound, but the further away you get from the center, the smaller the probability values get. <span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p139">
<img alt="figure" height="229" src="../Images/CH02_F12_Ness.png" width="1032"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.12</span> A continuous normal distribution (solid line) approximates a discrete Poisson distribution (gray bars). Again, the outcomes are on the horizontal axis, and the probability values are on the vertical axis. </h5>
</div>
<div class="readable-text" id="p140">
<p>Visualizing conditional probability distributions involves mapping each conditioning variable to some element in the image. For example, in figure 2.13, <em>X</em> is discrete, and <em>Y</em> conditioned on <em>X</em> has a normal distribution where the location parameter is a function of <em>X</em>. <span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p141">
<img alt="figure" height="398" src="../Images/CH02_F13_Ness.png" width="810"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.13</span> A visualization of the conditional probability distribution of continuous <em>Y</em>, given discrete <em>X</em>. For different values of <em>X</em>, we get a different distribution of <em>Y</em>.</h5>
</div>
<div class="readable-text" id="p142">
<p>Since <em>X</em> is discrete, it is simplest to map <em>X</em> to color and overlay the curves for <em>P</em>(<em>Y</em><em>  </em>|<em>X</em><em> </em>=<em> </em>1), <em>P</em><em> </em>(<em>Y</em><em>  </em>|<em>X</em><em> </em>=<em> </em>2), and <em>P</em><em> </em>(<em>Y</em><em>  </em>|<em>X</em><em> </em>=<em> </em>3). However, if we wanted to visualize <em>P</em>(<em>Y</em><em>  </em>|<em>X</em>, <em>Z</em>), we’d need to map <em>Z</em> to an aesthetic element other than color, such as a third axis in a pseudo-3D image or rows in a grid of images. But there is only so much information we can add to a 2D visualization. Fortunately, conditional independence helps us reduce the number of conditioning variables.</p>
</div>
<div class="readable-text" id="p143">
<h3 class="readable-text-h3" id="sigil_toc_id_36"><span class="num-string">2.1.9</span> Independence and conditional independence</h3>
</div>
<div class="readable-text" id="p144">
<p>Two random variables are <em>independent</em> if, informally speaking, observing an outcome of one random variable does not affect the probability of outcomes for the other variable, i.e., <em>P</em><em> </em>(<em>y</em><em> </em>|<em>x</em>)<em> </em><em>=</em><em> </em><em>P</em><em> </em>(<em>y</em><em> </em>). We denote this as <em>X</em> ⊥ <em>Y</em>. If two variables are not independent, they are <em>dependent</em>.</p>
</div>
<div class="readable-text intended-text" id="p145">
<p>Two dependent variables can become <em>conditionally independent</em> given other variables. For example, <em>X</em> ⊥ <em>Y</em> | <em>Z</em> means that <em>X</em> and <em>Y</em> may be dependent, but they are conditionally independent given <em>Z</em>. In other words, if <em>X</em> and <em>Y</em> are dependent, and <em>X</em> ⊥ <em>Y</em> | <em>Z</em>, then it is not true that <em>P</em><em> </em>(<em>y</em><em> </em>|<em>x</em>) <span class="regular-symbol">≠</span> <em>P</em>(<em>y</em>) but it is true that <em>P</em><em> </em>(<em>y</em><em> </em>|<em>x</em>, <em>z</em>) = <em>P</em><em> </em>(<em>y</em><em> </em>|<em>z</em>).</p>
</div>
<div class="readable-text" id="p146">
<h4 class="readable-text-h4 sigil_not_in_toc">Independence is a powerful tool for simplification </h4>
</div>
<div class="readable-text" id="p147">
<p>Independence is a powerful tool for simplifying representations of probability distributions. Consider a joint probability distribution <em>P</em><em> </em>(<em>W</em>, <em>X</em>, <em>Y</em>, <em>Z</em><em> </em>) represented as a table. The number of cells in the table would be the product of the number of possible outcomes each for <em>W</em>, <em>X</em>, <em>Y</em>, and <em>Z</em>. We could use the chain rule to break the problem up into factors {<em>P</em><em> </em>(<em>W</em><em>  </em>), <em>P</em>(<em>X</em><em>  </em>|<em>W</em><em>  </em>), <em>P</em>(<em>Y</em><em>  </em>|<em>X</em>, <em>W</em><em>  </em>), <em>P</em>(<em>Z</em><em>  </em>|<em>Y</em>, <em>X</em>, <em>W</em><em>  </em>)}, but the total number of parameters across these factors wouldn’t change, so the aggregate complexity would be the same.</p>
</div>
<div class="readable-text intended-text" id="p148">
<p>However, what if <em>X</em> ⊥ <em>W</em><em>   </em>? Then <em>P</em><em> </em>(<em>X</em><em>  </em>|<em>W</em><em> </em>) reduces to <em>P</em>(<em>X</em><em> </em>). What if <em>Z</em> ⊥ <em>Y</em><em>  </em>|<em>X</em><em>  </em>? Then <em>P</em><em> </em>(<em>Z</em><em>  </em>|<em>Y</em>, <em>X</em>, <em>W</em><em> </em>) reduces to <em>P</em><em> </em>(<em>Z</em><em>  </em>|<em>X</em>, <em>W</em><em> </em>). Every time we can impose a pairwise conditional independence condition as a constraint on the joint probability distribution, we can reduce the complexity of the distribution by a large amount. Indeed, much of model building and evaluation in statistical modeling, regularization in machine learning, and deep learning techniques such as “drop-out” are either direct or implicit attempts to impose conditional independence on the joint probability distribution underlying the data.</p>
</div>
<div class="readable-text" id="p149">
<h4 class="readable-text-h4 sigil_not_in_toc">Conditional independence and causality</h4>
</div>
<div class="readable-text" id="p150">
<p>Conditional independence is fundamental to causal modeling. Causal relationships lead to conditional independence between correlated variables. For example, a child’s parents’ and grandparents’ blood types are all causes of that child’s blood type; these blood types are all correlated. But all you need is the parents’ blood type, the direct causes, to fully determine the child’s blood type, as illustrated in figure 2.14. In probabilistic terms, the child’s and grandparents’ blood types are conditionally independent, given the parents.</p>
</div>
<div class="browsable-container figure-container" id="p151">
<img alt="figure" height="395" src="../Images/CH02_F14_Ness.png" width="510"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.14</span> How causality can induce conditional independence. The blood types of the parents cause the blood type of the child. The grandfather’s blood type is correlated with that of the child’s (dashed line). But the parents’ blood types are direct causes that fully determine that of the child. These direct causes render the child’s and grandfather’s blood types conditionally independent.</h5>
</div>
<div class="readable-text intended-text" id="p152">
<p>The fact that causality induces conditional independence allows us to learn and validate causal models against evidence of conditional independence. In chapter 4, we’ll explore the relationship between conditional independence and causality in formal terms. </p>
</div>
<div class="readable-text" id="p153">
<h3 class="readable-text-h3" id="sigil_toc_id_37"><span class="num-string">2.1.10</span> Expected value<span class="aframe-location"/></h3>
</div>
<div class="readable-text" id="p154">
<p>The <em>expected value</em> of a function of a random variable is the weighted average of the function’s possible output values, where the weight is the probability of that outcome.<span class="aframe-location"/><span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p155">
<img alt="figure" height="54" src="../Images/ness-ch2-eqs-11x.png" width="280"/>
</div>
<div class="browsable-container figure-container" id="p156">
<img alt="figure" height="54" src="../Images/ness-ch2-eqs-12x.png" width="355"/>
</div>
<div class="readable-text" id="p157">
<p>In the case of a continuum of possible outcomes, the expectation is defined by integration.<span class="aframe-location"/><span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p158">
<img alt="figure" height="55" src="../Images/ness-ch2-eqs-13x.png" width="316"/>
</div>
<div class="browsable-container figure-container" id="p159">
<img alt="figure" height="55" src="../Images/ness-ch2-eqs-14x.png" width="387"/>
</div>
<div class="readable-text" id="p160">
<p>Some of the causal quantities we’ll be interested in calculating will be defined in terms of expectation. Those quantities only reason about the expectation, not about how the expectation is calculated. It is easier to get an intuition for a problem when working with the basic arithmetic of discrete expectation rather than integral calculus in the continuous case. So, in this book, when there is a choice, I use examples with discrete random variables and discrete expectation. The causal logic in those examples all generalize to the continuous case. </p>
</div>
<div class="readable-text intended-text" id="p161">
<p>There are many interesting mathematical properties of expectation. In this book, we care about the fact that conditional expectations simplify under conditional independence: If <em>X</em> ⊥ <em>Y</em>, then <em>E</em><em> </em>(<em>X</em><em>  </em>|<em>Y</em><em>  </em>) = <em>E</em><em> </em>(<em>X</em><em> </em>). If <em>X</em> ⊥ <em>Y</em><em>  </em>|<em>Z</em>, then <em>E</em><em> </em>(<em>X</em><em>  </em>|<em>Y</em>,<em>Z</em><em> </em>) = <em>E</em><em> </em>(<em>X</em><em>  </em>|<em>Z</em><em> </em>). In simpler terms, if two variables (<em>X</em> and <em>Y</em><em> </em>) are independent, our expectation for one does not change with information about the other. If their independence holds conditional on a third variable (<em>Z</em><em>  </em>), our expectation for one, given that we know the third variable, is unaffected by information about the other variable.</p>
</div>
<div class="readable-text intended-text" id="p162">
<p>Other than this, the most important property is the linearity of the expectation, meaning that the expectation passes through linear functions. Here are some useful reference examples of the linearity of expectation: </p>
</div>
<ul>
<li class="readable-text" id="p163"> For random variables <em>X</em> and <em>Y</em>: <em>E</em><em> </em>(<em>X</em> + <em>Y</em><em>  </em>) = <em>E</em><em> </em>(<em>X</em><em>  </em>) + <em>E</em><em> </em>(<em>Y</em><em>  </em>) and<span class="aframe-location"/> </li>
</ul>
<div class="browsable-container figure-container" id="p164">
<img alt="figure" height="53" src="../Images/ness-ch2-eqs-15x.png" width="231"/>
</div>
<ul>
<li class="readable-text" id="p165"> For constants <em>a</em> and <em>b</em>: <em>E</em><em> </em>(<em>aX</em> + <em>b</em><em> </em>) = <em>aE</em><em> </em>(<em>X</em><em>  </em>) + <em>b</em> </li>
<li class="readable-text" id="p166"> If <em>X</em> only has outcomes 0 and 1, and <em>E</em>(<em>Y</em>|<em>X</em>) = <em>aX</em> + <em>b</em>, then <em>E</em><em> </em>(<em>Y</em><em>  </em>|<em>X</em><em> </em>=<em> </em>1) – <em>E</em><em> </em>(<em>Y</em><em>  </em>|<em>X</em><em> </em>=<em> </em>0) = <em>a</em>. (This is true because <em>a</em>*1 + <em>b</em> – (<em>a</em><em> </em>*<em> </em>0 + <em>b</em>) = <em>a</em>. Spoiler alert: this one is important for linear regression-based causal effect inference techniques.) </li>
</ul>
<div class="readable-text" id="p167">
<p>The mean of the random variable’s distribution is the expected value of the variable itself, as in <em>E</em>(<em>X</em>) (i.e., the function is the <em>identity function</em>, <em>f</em><em> </em>(<em>X</em><em>  </em>) = <em>X</em><em> </em>). In several canonical distributions, the mean is a simple function of the parameters. In some cases, such as in the normal distribution, the location parameter is equivalent to the expectation. But the location parameter and the expectation are not always the same. For example, the Cauchy distribution has a location parameter, but its mean is undefined.</p>
</div>
<div class="readable-text intended-text" id="p168">
<p>In the next section, you’ll learn how to represent distributions and calculate expectations using computational methods.</p>
</div>
<div class="readable-text" id="p169">
<h2 class="readable-text-h2" id="sigil_toc_id_38"><span class="num-string">2.2</span> Computational probability</h2>
</div>
<div class="readable-text" id="p170">
<p>We need to <em>code</em> probability distributions and expectations from probability to use them in our models. In the previous section, you saw how to code up a probability distribution for a three-sided die. But how do we code up <em>rolling</em> a three-sided die? How do we write code representing two dice rolls that are conditionally independent? While we’re at it, how do we get a computer to do the math that calculates an expectation? How do we get a computer, where everything is deterministic, to roll dice so that the outcome is unknown beforehand?</p>
</div>
<div class="readable-text" id="p171">
<h3 class="readable-text-h3" id="sigil_toc_id_39"><span class="num-string">2.2.1</span> The physical interpretation of probability</h3>
</div>
<div class="readable-text" id="p172">
<p>Suppose I have a three-sided die. I have some probability values assigned to each outcome on the die. What do those probability values mean? How do I interpret them?</p>
</div>
<div class="readable-text intended-text" id="p173">
<p>Suppose I repeatedly rolled the die and kept a running tally of how many times I saw each outcome. First, the roll is random, meaning that although I roll it the same way each time, I get varying results. The physical shape of the die affects those tallies; if one face of the die is larger than the other two, that size difference will affect the count. As I repeat the roll many times, the proportion of total times I see a given outcome converges to a number. Suppose I use that number for my probability value. Further, suppose I interpret that number as the “chance” of seeing that outcome each time I roll.</p>
</div>
<div class="readable-text intended-text" id="p174">
<p>This idea is called <em>physical</em> (or <em>frequentist</em>)<em> probability</em>. Physical probability means imagining some repeatable physical random process that results in one outcome among a set of possible outcomes. We assign a probability value using the convergent proportion of times the outcome appears when we repeat the random process ad infinitum. We then interpret that probability as the propensity for that physical process to produce that outcome.</p>
</div>
<div class="readable-text" id="p175">
<h3 class="readable-text-h3" id="sigil_toc_id_40"><span class="num-string">2.2.2</span> Random generation</h3>
</div>
<div class="readable-text" id="p176">
<p>Given the preceding definition for physical probability, we can define random generation. In <em>random generation</em>, an algorithm randomly chooses an outcome from a given distribution. The algorithm’s choice is inspired by physical probability; the way it selects an outcome is such that if we ran the algorithm ad infinitum, the proportion of times it would choose that outcome would equal the distribution’s probability value for that outcome.</p>
</div>
<div class="readable-text intended-text" id="p177">
<p>Computers are deterministic machines. If we repeatedly run a computer procedure on the same input, it will always return the same output; it cannot produce anything genuinely random (unless it has a random input). Computers have to use deterministic algorithms to emulate random generation. These algorithms are called pseudo-random number generators—they take a starting number, called a <em>random seed</em>, and return a deterministic series of numbers. Those algorithms mathematically guarantee that a series of numbers is statistically indistinguishable from the ideal of random generation.</p>
</div>
<div class="readable-text intended-text" id="p178">
<p>In notation, I write random generation as follows:<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p179">
<img alt="figure" height="22" src="../Images/ness-ch2-eqs-16x.png" width="101"/>
</div>
<div class="readable-text" id="p180">
<p>This reads as “x is generated from the probability distribution of <em>X</em>.”</p>
</div>
<div class="readable-text intended-text" id="p181">
<p>In random generation, synonyms for “generate” include “simulate” and “sample.” For example, in pgmpy the <code>sample</code> method in <code>DiscreteFactor</code> does random generation. It returns a pandas DataFrame. Note that since this is random generation, you will likely get different outputs when you run this code:<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p182">
<img alt="figure" height="22" src="../Images/ness-ch2-eqs-17x.png" width="154"/>
</div>
<div class="browsable-container listing-container" id="p183">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 2.4</span> Simulating random variates from <code>DiscreteFactor</code> in pgmpy</h5>
<div class="code-area-container">
<pre class="code-area">from pgmpy.factors.discrete import DiscreteFactor
dist = DiscreteFactor(
    variables=["X"],
    cardinality=[3],
    values=[.45, .30, .25],
    state_names= {'X': ['1', '2', '3']}
)

dist.sample(n=1)   <span class="aframe-location"/> #1</pre>
<div class="code-annotations-overlay-container">
     #1 n is the number of instances you wish to generate.
     <br/>
</div>
</div>
</div>
<div class="readable-text" id="p184">
<p>This produces the table pictured in figure 2.15.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p185">
<img alt="figure" height="374" src="../Images/CH02_F15_Ness.png" width="300"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.15</span> Generating one instance from <em>P</em>(<em>X</em>) creates a pandas <code>DataFrame</code> object with one row.</h5>
</div>
<div class="readable-text" id="p186">
<p>We can also generate from joint probability distributions.</p>
</div>
<div class="browsable-container listing-container" id="p187">
<div class="code-area-container">
<pre class="code-area">joint = DiscreteFactor(
    variables=['X', 'Y'],
    cardinality=[3, 2],
    values=[.25, .20, .20, .10, .15, .10],
    state_names= {
        'X': ['1', '2', '3'],
        'Y': ['0', '1']
    }
)

joint.sample(n=1)</pre>
</div>
</div>
<div class="readable-text" id="p188">
<p>This produces the table pictured in figure 2.16.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p189">
<img alt="figure" height="397" src="../Images/CH02_F16_Ness.png" width="480"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.16</span> Generating one instance from <em>P</em>(<em>X</em><em>,</em><em> Y</em>) creates a pandas <code>DataFrame</code> object with one row.</h5>
</div>
<div class="readable-text" id="p190">
<p>Pyro also has a <code>sample</code> method for canonical distributions:</p>
</div>
<div class="browsable-container listing-container" id="p191">
<div class="code-area-container">
<pre class="code-area">import torch
from pyro.distributions import Categorical
Categorical(probs=torch.tensor([.45, .30, .25])).sample()</pre>
</div>
</div>
<div class="readable-text" id="p192">
<p>This generates a sample from that categorical distribution, i.e., either 0, 1, or 2. </p>
</div>
<div class="browsable-container listing-container" id="p193">
<div class="code-area-container">
<pre class="code-area">tensor(1.)</pre>
</div>
</div>
<div class="readable-text" id="p194">
<h3 class="readable-text-h3" id="sigil_toc_id_41"><span class="num-string">2.2.3</span> Coding random processes</h3>
</div>
<div class="readable-text" id="p195">
<p>We can write our own random processes as code when we want to generate values in a particular way. A random process written as code is sometimes called a <em>stochastic function</em>, <em>probabilistic subroutine</em>, or <em>probabilistic program</em>. For example, consider the joint probability distribution <em>P</em><em> </em>(<em>X</em>, <em>Y</em>, <em>Z</em><em> </em>). How can we randomly generate from this joint distribution? Unfortunately, software libraries don’t usually provide pseudo-random generation for arbitrary joint distributions.</p>
</div>
<div class="readable-text intended-text" id="p196">
<p>We can get around this by applying the chain rule and, if it exists, conditional independence. For example, we could factorize as follows:<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p197">
<img alt="figure" height="23" src="../Images/ness-ch2-eqs-18x.png" width="343"/>
</div>
<div class="readable-text" id="p198">
<p>Suppose that <em>Y</em> is conditionally independent of <em>Z</em> given <em>X</em>, then:<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p199">
<img alt="figure" height="23" src="../Images/ness-ch2-eqs-19x.png" width="318"/>
</div>
<div class="readable-text" id="p200">
<p>Finally, suppose we can sample from <em>P</em><em> </em>(<em>Z</em><em>  </em>), <em>P</em><em> </em>(<em>X</em><em>  </em>|<em>Z</em>), and <em>P</em><em> </em>(<em>Y</em><em>  </em>|<em>X</em>) given the basic random generation functions in our software library. Then we can use this factorization to compose an algorithm for sampling:<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p201">
<img alt="figure" height="96" src="../Images/ness-ch2-eqs-20x.png" width="165"/>
</div>
<div class="readable-text" id="p202">
<p>This is a random process that we can execute in code. First, we generate a <em>Z</em>-outcome <em>z</em> from <em>P</em><em> </em>(<em>Z</em><em>  </em>). We then condition <em>X</em> on that <em>z</em>, and generate an <em>X</em>-outcome <em>x</em>. We do the same to generate a <em>Y</em>-outcome <em>y</em>. Finally, this procedure generates a tuple {<em>x</em>, <em>y</em>, <em>z</em>} from the joint distribution <em>P</em><em> </em>(<em>X</em>, <em>Y</em>, <em>Z</em><em>  </em>).</p>
</div>
<div class="readable-text intended-text" id="p203">
<p>In pgmpy, we can create a random process using the class called <code>BayesianNetwork</code>.</p>
</div>
<div class="browsable-container listing-container" id="p204">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 2.5</span> Creating a random process in pgmpy and Pyro</h5>
<div class="code-area-container">
<pre class="code-area">from pgmpy.factors.discrete.CPD import TabularCPD
from pgmpy.models import BayesianNetwork
from pgmpy.sampling import BayesianModelSampling

PZ = TabularCPD(    <span class="aframe-location"/> #1
    variable='Z',     #1
    variable_card=2,     #1
    values=[[.65], [.35]],     #1
    state_names = {     #1
        'Z': ['0', '1']     #1
    })     #1

PXgivenZ = TabularCPD(    <span class="aframe-location"/> #2
    variable='X',    #2
    variable_card=2,   #2
    values=[   #2
        [.8, .6],   #2
        [.2, .4],   #2
    ],    #2
    evidence=['Z'],    #2
    evidence_card=[2],  #2
    state_names = {    #2
        'X': ['0', '1'],    #2
        'Z': ['0', '1'] #2
    })   #2

PYgivenX = TabularCPD(    <span class="aframe-location"/> #3
    variable='Y',     #3
    variable_card=3,     #3
    values=[    #3
        [.1, .8],     #3
        [.2, .1],     #3
        [.7, .1],    #3
    ],    #3
    evidence=['X'],     #3
    evidence_card=[2],    #3
    state_names = {    #3
        'Y': ['1', '2', '3'],    #3
        'X': ['0', '1']    #3
    })    #3

model = BayesianNetwork([('Z', 'X'), ('X', 'Y')])  <span class="aframe-location"/> #4
model.add_cpds(PZ, PXgivenZ, PYgivenX)    <span class="aframe-location"/> #5

generator = BayesianModelSampling(model)   <span class="aframe-location"/> #6
generator.forward_sample(size=1)   <span class="aframe-location"/> #7</pre>
<div class="code-annotations-overlay-container">
     #1 P(Z)
     <br/>#2 P(X|Z=z)
     <br/>#3 P(X|Z=z)
     <br/>#4 P(Y|X=x)
     <br/>#5 Create a BayesianNetwork object. The arguments are edges of a directed graph, which we’ll cover in chapter 3.
     <br/>#6 Add the conditional probability distributions to the model.
     <br/>#7 Create a BayesianModelSampling object from the BayesianNetwork object.
     <br/>#8 Sample from the resulting object
     <br/>
</div>
</div>
</div>
<div class="readable-text" id="p205">
<p>This produces one row in a pandas DataFrame, shown in figure 2.17.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p206">
<img alt="figure" height="379" src="../Images/CH02_F17_Ness.png" width="654"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.17</span> The <code>forward_sample</code> method simulates one instance of <em>X</em>, <em>Y</em>, and <em>Z</em> as a row in a pandas DataFrame.</h5>
</div>
<div class="readable-text" id="p207">
<p>Implementing random processes for random generation is powerful because it allows generating from joint distributions that we can’t represent in clear mathematical terms or as a single canonical distribution. For example, while pgmpy works well with categorical distributions, Pyro gives us the flexibility of working with combinations of canonical distributions. </p>
</div>
<div class="readable-text intended-text" id="p208">
<p>The following listing shows a Pyro version of the previous random process. It has the same dependence between <em>Z</em>, <em>X</em>, and <em>Y</em>, but different canonical distributions.</p>
</div>
<div class="browsable-container listing-container" id="p209">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 2.6</span> Working with combinations of canonical distributions in Pyro</h5>
<div class="code-area-container">
<pre class="code-area">import torch
from pyro.distributions import Bernoulli, Poisson, Gamma

z = Gamma(7.5, 1.0).sample()   <span class="aframe-location"/> #1
x = Poisson(z).sample()   <span class="aframe-location"/> #2
y = Bernoulli(x / (5+x)).sample()  <span class="aframe-location"/> #3
print(z, x, y)</pre>
<div class="code-annotations-overlay-container">
     #1 Represent P(Z) with a gamma distribution, and sample z.
     <br/>#2 Represent P(X|Z=z) with a Poisson distribution with location parameter z, and sample x.
     <br/>#3 Represent P(Y|X=x) with a Bernoulli distribution. The probability parameter is a function of x.
     <br/>
</div>
</div>
</div>
<div class="readable-text" id="p210">
<p>This prints out a sample set, such as the following:</p>
</div>
<div class="browsable-container listing-container" id="p211">
<div class="code-area-container">
<pre class="code-area">tensor(7.1545) tensor(5.) tensor(1.)</pre>
</div>
</div>
<div class="readable-text" id="p212">
<p><em>Z</em> comes from a gamma distribution, <em>X</em> from a Poisson distribution with mean parameter set to <em>z</em>, and <em>Y</em> from a Bernoulli distribution with its parameter set to a function of <em>x</em>.</p>
</div>
<div class="readable-text intended-text" id="p213">
<p>Implementing a random function with a programming language lets us use nuanced conditional control flow. Consider the following pseudocode:</p>
</div>
<div class="browsable-container listing-container" id="p214">
<div class="code-area-container">
<pre class="code-area">z ~ P(Z)
x ~ P(X|Z=z)
y = 0
for i in range(0, x){    <span class="aframe-location"/> #1
    y_i ~ P(Y|X=x)    #1
    y += y_i    <span class="aframe-location"/> #2
}</pre>
<div class="code-annotations-overlay-container">
     #1 We can use control flow, like this for loop, to generate values.
     <br/>#2 y is the sum of the values generated in the for loop. y still depends on x, but through nuanced control flow.
     <br/>
</div>
</div>
</div>
<div class="readable-text" id="p215">
<p>Here, <em>y</em> is still dependent on <em>x</em>. However, it is defined as the sum of <em>x</em> individual random components. In Pyro, we might implement this as follows.</p>
</div>
<div class="browsable-container listing-container" id="p216">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 2.7</span> Random processes with nuanced control flow in Pyro</h5>
<div class="code-area-container">
<pre class="code-area">import torch
from pyro.distributions import Bernoulli, Poisson, Gamma
z = Gamma(7.5, 1.0).sample()
x = Poisson(z).sample()
y = torch.tensor(0.0)   <span class="aframe-location"/> #1
for i in range(int(x)):     #1
    y += Bernoulli(.5).sample()     #1
print(z, x, y)</pre>
<div class="code-annotations-overlay-container">
     #1 y is defined as a sum of random coin flips, so y is generated from P(Y|X=x) because the number of flips depends on x.
     <br/>
</div>
</div>
</div>
<div class="readable-text" id="p217">
<p>In Pyro, best practice is to implement random processes as functions. Further, use the function <code>pyro.sample</code> to generate, rather than using the <code>sample</code> method on distribution objects. We could rewrite the preceding <code>random_process</code> code (listing 2.7) as follows.</p>
</div>
<div class="browsable-container listing-container" id="p218">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 2.8</span> Using functions for random processes and <code>pyro.sample</code> </h5>
<div class="code-area-container">
<pre class="code-area">import torch
import pyro
def random_process():
    z = pyro.sample("z", Gamma(7.5, 1.0))
    x = pyro.sample("x", Poisson(z))
    y = torch.tensor(0.0)
    for i in range(int(x)):
        y += pyro.sample(f"y{i}", Bernoulli(.5))   <span class="aframe-location"/> #1
    return y</pre>
<div class="code-annotations-overlay-container">
     #1 f"y{i}" creates the names "y1", "y2", etc.
     <br/>
</div>
</div>
</div>
<div class="readable-text" id="p219">
<p>The first argument in <code>pyro.sample</code> is a string that assigns a name to the variable you are sampling. The reason for that will become apparent when we start running inference algorithms in Pyro in chapter 3. </p>
</div>
<div class="readable-text" id="p220">
<h3 class="readable-text-h3" id="sigil_toc_id_42"><span class="num-string">2.2.4</span> Monte Carlo simulation and expectation</h3>
</div>
<div class="readable-text" id="p221">
<p><em>Monte Carlo algorithms</em> use random generation to estimate expectations from a distribution of interest. The idea is simple. You have some way of generating from <em>P</em><em> </em>(<em>X</em><em>  </em>). If you want <em>E</em>(<em>X</em><em>  </em>), generate multiple <em>x</em>’s, and take the average of those <em>x</em>’s. If you want <em>E</em><em> </em>(<em>f</em><em> </em>(<em>X</em><em>  </em>)), generate multiple <em>x</em>’s and apply the function <em>f</em><em> </em>(.) to each of those <em>x</em>’s, and take the average. Monte Carlo works even in cases when <em>X</em> is continuous.</p>
</div>
<div class="readable-text intended-text" id="p222">
<p>In pgmpy, you use the <code>sample</code> or <code>forward_sample</code> methods to generate a pandas DataFrame. You can then calculate the panda’s <code>mean</code> method.</p>
</div>
<div class="browsable-container listing-container" id="p223">
<div class="code-area-container">
<pre class="code-area">generated_samples = generator.forward_sample(size=100)
generated_samples['Y'].apply(int).mean()</pre>
</div>
</div>
<div class="readable-text" id="p224">
<p>In Pyro, we call the <code>random_process</code> function repeatedly. We can do this for the preceding Pyro generator with a <code>for</code> loop that generates 100 samples:</p>
</div>
<div class="browsable-container listing-container" id="p225">
<div class="code-area-container">
<pre class="code-area">generated_samples = torch.stack([random_process() for _ in range(100)])</pre>
</div>
</div>
<div class="readable-text" id="p226">
<p>This code repeatedly calls <code>random_process</code> in a Python list comprehension. Recall that Pyro extends PyTorch, and the value of y it returns is a tensor. I use <code>torch.stack</code> to turn this list of tensors into a single tensor. Finally, I call the <code>mean</code> method on the tensor to obtain the Monte Carlo estimate of <em>E</em><em> </em>(<em>Y</em><em>  </em>).</p>
</div>
<div class="browsable-container listing-container" id="p227">
<div class="code-area-container">
<pre class="code-area">generated_samples.mean()</pre>
</div>
</div>
<div class="readable-text" id="p228">
<p>When I ran this code, I got a value of about 3.78, but you’ll likely get something slightly different.</p>
</div>
<div class="readable-text intended-text" id="p229">
<p>Most things you’d want to know about a distribution can be framed in terms of some function <em>f</em><em> </em>(<em>X</em><em>  </em>). For example, if you wanted to know the probability of <em>X</em> being greater than 10, you could simply generate a bunch of <em>x</em>’s and convert each <em>x</em> to 1 if it is greater than 10 and 0 otherwise. Then you’d take the average of the 1’s and 0’s, and the resulting value would estimate the desired probability.</p>
</div>
<div class="readable-text intended-text" id="p230">
<p>To illustrate, the following code extends the previous block to calculate <em>E</em>(<em>Y</em><em>  </em><sup>2</sup>).</p>
</div>
<div class="browsable-container listing-container" id="p231">
<div class="code-area-container">
<pre class="code-area">torch.square(generated_samples).mean()</pre>
</div>
</div>
<div class="readable-text" id="p232">
<p>When calculating <em>E</em>(<em>f</em><em> </em>(<em>X</em><em>  </em>)) for a random variable <em>X</em>, remember to get the Monte Carlo estimate by applying the function to the samples first, and then take the average. If you apply the function to the sample average, you’ll instead get an estimate of <em>f</em><em> </em>(<em>E</em><em> </em>(<em>X</em><em>  </em>)), which is almost always different. </p>
</div>
<div class="readable-text" id="p233">
<h3 class="readable-text-h3" id="sigil_toc_id_43"><span class="num-string">2.2.5</span> Programming probabilistic inference</h3>
</div>
<div class="readable-text" id="p234">
<p>Suppose we implement in code a random process that generates an outcome {<em>x</em>, <em>y</em>, <em>z</em>} from <em>P</em><em> </em>(<em>X</em>, <em>Y</em>, <em>Z</em><em>  </em>) as follows:<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p235">
<img alt="figure" height="96" src="../Images/ness-ch2-eqs-20x.png" width="165"/>
</div>
<div class="readable-text" id="p236">
<p>Further, suppose we are interested in generating from <em>P</em><em> </em>(<em>Z</em><em>  </em>|<em>Y</em><em> </em>=<em> </em>3). How might we do this? Our process can sample from <em>P</em><em> </em>(<em>Z</em><em>  </em>), <em>P</em><em> </em>(<em>X</em><em>  </em>|<em>Z</em><em>  </em>), and <em>P</em><em> </em>(<em>Y</em><em>  </em>|<em>Z</em><em>  </em>), but it is not clear how we go from these to <em>P</em><em> </em>(<em>Z</em><em>  </em>|<em>Y</em><em>  </em>).</p>
</div>
<div class="readable-text intended-text" id="p237">
<p><em>Probabilistic inference algorithms</em> generally take an outcome-generating random process and some target distribution as inputs. Then, they return a means of generating from that target distribution. This class of algorithms is often called Bayesian inference algorithms because the algorithms often use Bayes rule to go from <em>P</em><em> </em>(<em>Y</em><em>  </em>|<em>Z</em><em> </em>) to <em>P</em><em> </em>(<em>Z</em><em>  </em>|<em>Y</em><em>  </em>). However, the connection to Bayes rule is not always explicit, so I prefer “probabilistic inference” over “Bayesian inference algorithms.”</p>
</div>
<div class="readable-text intended-text" id="p238">
<p>For example, a simple class of probabilistic inference algorithms is called accept/reject algorithms. Applying a simple accept/reject technique to generating from <em>P</em><em> </em>(<em>Z</em><em>  </em>|<em>Y</em><em> </em>=<em> </em>3) works as follows:</p>
</div>
<ol>
<li class="readable-text" id="p239"> Repeatedly generate {<em>x</em>, <em>y</em>, <em>z</em>} using our generator for <em>P</em><em> </em>(<em>X</em>, <em>Y</em>, <em>Z</em><em>  </em>). </li>
<li class="readable-text" id="p240"> Throw away any generated outcome where <em>y</em> is not equal to 3. </li>
<li class="readable-text" id="p241"> The resulting set of outcomes for <em>Z</em> will have the distribution <em>P</em><em> </em>(<em>Z</em><em>  </em>|<em>Y</em><em> </em>=<em> </em>3). </li>
</ol>
<div class="readable-text" id="p242">
<p>Illustrating with Pyro, let’s rewrite the previous <code>random_process</code> function to return <em>z</em> and <em>y</em>. After that, we’ll obtain a Monte Carlo estimate of <em>E</em><em> </em>(<em>Z</em><em>  </em>|<em>Y</em><em> </em>=<em> </em>3).</p>
</div>
<div class="browsable-container listing-container" id="p243">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 2.9</span> Monte Carlo estimation in Pyro</h5>
<div class="code-area-container">
<pre class="code-area">import torch
import pyro
from pyro.distributions import Bernoulli, Gamma, Poisson
def random_process():
    z = pyro.sample("z", Gamma(7.5, 1.0))
    x = pyro.sample("x", Poisson(z))
    y = torch.tensor(0.0)
    for i in range(int(x)):



        y += pyro.sample(f"{i}", Bernoulli(.5))
    return z, y   <span class="aframe-location"/> #1

generated_samples = [random_process() for _ in range(1000)]    <span class="aframe-location"/> #2
<span class="aframe-location"/>z_mean = torch.stack([z for z, _ in generated_samples]).mean()     #3
print(z_mean)</pre>
<div class="code-annotations-overlay-container">
     #1 This new version of random_process returns both z and y.
     <br/>#2 Generate 1000 instances of z and y using a list comprehension.
     <br/>#3 Turn the individual z tensors into a single tensor, and then calculate the Monte Carlo estimate via the mean method.
     <br/>
</div>
</div>
</div>
<div class="readable-text" id="p244">
<p>This code estimates <em>E</em>(<em>Z</em><em>  </em>). Since <em>Z</em> is simulated from a gamma distribution, the true mean <em>E</em><em> </em>(<em>Z</em><em>  </em>) is the shape parameter 7.5 divided by the rate parameter 1.0, which is 7.5. </p>
</div>
<div class="readable-text intended-text" id="p245">
<p>Now, to estimate <em>E</em><em> </em>(<em>Z</em><em>  </em>|<em>Y</em>=3), we’ll filter the samples and keep only the samples where <em>Y</em> is 3.</p>
</div>
<div class="browsable-container listing-container" id="p246">
<div class="code-area-container">
<pre class="code-area">z_given_y = torch.stack([z for z, y in generated_samples if y == 3])
print(z_given_y.mean())</pre>
</div>
</div>
<div class="readable-text" id="p247">
<p>One run of this code produced <code>tensor(6.9088)</code>, but your result might be slightly different. That probabilistic inference algorithm works well if the outcome <em>Y</em>=3 occurs frequently. If that outcome were rare, the algorithm would be inefficient: we’d have to generate many samples to get samples that meet the condition, and we’d be throwing away many samples.</p>
</div>
<div class="readable-text intended-text" id="p248">
<p>There are various other algorithms for probabilistic inference, but the topic is too rich and tangential to causal modeling for us to explore in depth. Nevertheless, the following algorithms are worth mentioning for what we cover in this book. Visit <a href="https://www.altdeep.ai/p/causalaibook">https://www.altdeep.ai/p/causalaibook</a> for links to some complementary materials on inference with pgmpy and Pyro.</p>
</div>
<div class="readable-text" id="p249">
<h4 class="readable-text-h4 sigil_not_in_toc">Probability weighting methods</h4>
</div>
<div class="readable-text" id="p250">
<p>These methods generate outcomes from a joint probability distribution and then weight them according to their probability in the target distribution. We can then use the weights to do weighted averaging via Monte Carlo estimation. Popular variants of this kind of inference include importance sampling and inverse probability reweighting, the latter of which is popular in causal inference and is covered in chapter 11.</p>
</div>
<div class="readable-text" id="p251">
<h4 class="readable-text-h4 sigil_not_in_toc">Inference with probabilistic graphical models</h4>
</div>
<div class="readable-text" id="p252">
<p>Probabilistic graphical models use graphs to represent conditional independence in a joint probability distribution. The presence of a graph enables graph-based algorithms to power inference. Two well-known approaches include variable elimination and belief propagation. In figures 2.5 and 2.6, I showed that you could “eliminate” a variable by summing over its columns or rows in the probability table. Variable elimination uses the graph structure to optimally sum over the variables you wish to eliminate until the resulting table represents the target distribution. In contrast, belief propagation is a message-passing system; the graph is used to form different “cliques” of neighboring variables. For example, if <em>P</em><em> </em>(<em>Z</em><em>  </em>|<em>Y</em><em> </em>=<em> </em>1) is the target distribution, <em>Y</em>=1 is a message iteratively passed back and forth between cliques. Each time a message is received, parameters in the clique are updated, and the message is passed on. Eventually, the algorithm converges, and we can derive a new distribution for <em>Z</em> from those updated parameters.</p>
</div>
<div class="readable-text intended-text" id="p253">
<p>One of the attractive features of graph-based probabilistic inference is that users typically don’t implement them themselves; software like pgmpy does it for you. There are theoretical caveats, but they usually don’t matter in practice. This feature is an example of the “commodification of inference” trend I highlighted in chapter 1. In this book, we’ll work with causal graphical models, a special type of probabilistic graphical model that works as a causal model. That gives us the option of applying graph-based inference for causal problems.</p>
</div>
<div class="readable-text" id="p254">
<h4 class="readable-text-h4 sigil_not_in_toc">Variational inference</h4>
</div>
<div class="readable-text" id="p255">
<p>In <em>variational inference</em>, we write code for a new stochastic process that generates samples from an “approximating distribution” that resembles the target distribution. That stochastic process has parameters that we optimize using gradient-based techniques now common in deep learning software. The objective function of the optimization tries to minimize the difference between the approximating distribution and the target distribution.</p>
</div>
<div class="readable-text intended-text" id="p256">
<p>Pyro is a probabilistic modeling language that treats variational inference as a principal inference technique. It calls the stochastic process that generates from the approximating distribution a “guide function,” and a savvy Pyro programmer gets good at writing guide functions. However, it also provides a suite of tools for “automatic guide generation,” another example of the commodification of inference.</p>
</div>
<div class="readable-text" id="p257">
<h4 class="readable-text-h4 sigil_not_in_toc">Markov chain Monte Carlo</h4>
</div>
<div class="readable-text" id="p258">
<p><em>Markov chain Monte Carlo</em> (MCMC) is an inference algorithm popular amongst computational Bayesians. These are accept/reject algorithms where each newly generated outcome depends on the previous (non-rejected) generated outcome. This produces a chain of outcomes, and the distribution of outcomes in the chain eventually converges to the target distribution. <em>Hamiltonian Monte Carlo</em> (HMC) is a popular version that doesn’t require users to implement the generator. Pyro, and similar libraries, such as PyMC, implement HMC and other MCMC algorithms.</p>
</div>
<div class="readable-text" id="p259">
<h4 class="readable-text-h4 sigil_not_in_toc">Advanced Inference Methods</h4>
</div>
<div class="readable-text" id="p260">
<p>Research in generative models continues to develop new inference techniques. Examples include techniques such adversarial inference, inference with normalizing flows, and diffusion-based inference. The goal of such techniques are to efficiently sample from the complex distributions common in machine learning problems. Again, see <a href="https://www.altdeep.ai/p/causalaibook">https://www.altdeep.ai/p/causalaibook</a> for references. We’ll see an example of a structural causal model that leverages normalizing flows in chapter 6. The approach taken in this book is to leverage the “commodification of inference” trend discussed in chapter 1, such that we can build causal models that leverage these algorithms, as well as new algorithms as they are released.</p>
</div>
<div class="readable-text" id="p261">
<h2 class="readable-text-h2" id="sigil_toc_id_44"><span class="num-string">2.3</span> Data, populations, statistics, and models</h2>
</div>
<div class="readable-text" id="p262">
<p>So far, we have talked about random variables and distributions. Now we’ll move on to data and statistics. Let’s start with defining some terms. You doubtless have an idea of what data is, but let’s define it in terms we’ve already defined in this chapter. <em>Data</em> is a set of recorded outcomes of a random variable or set of random variables. A <em>statistic</em> is anything you calculate from data. For example, when you train a neural network on training data, the learned weight parameter values are statistics, and so are the model’s predictions (since they depend on the training data via the weights).</p>
</div>
<div class="readable-text intended-text" id="p263">
<p>The real-world causal process that generates a particular stream of data is called the <em>data generating process</em> (DGP). A <em>model</em> is a simplified mathematical description of that process. A <em>statistical model</em> is a model with parameters tuned such that the model aligns with statistical patterns in the data.</p>
</div>
<div class="readable-text intended-text" id="p264">
<p>This section presents some of the core concepts related to data and statistics needed to make sense of this book.</p>
</div>
<div class="readable-text" id="p265">
<h3 class="readable-text-h3" id="sigil_toc_id_45"><span class="num-string">2.3.1</span> Probability distributions as models for populations</h3>
</div>
<div class="readable-text" id="p266">
<p>In applied statistics, we take statistical insights from data and generalize them to a population. Consider, for example, the MNIST digit classification problem described in chapter 1. Suppose the goal of training a classification model on MNIST data was to deploy the model in software that digitizes written text documents. In this case, the population is all the digits on all the texts the software will see in the future.</p>
</div>
<div class="readable-text intended-text" id="p267">
<p>Populations are heterogeneous, meaning members of the population vary. While a feature on a website might drive engagement among the population of users, on average, the feature might make some subpopulation of users less engaged, so you would want to target the feature to the right subpopulations. Marketers call this “segmentation.” </p>
</div>
<div class="readable-text intended-text" id="p268">
<p>In another example, a medicine might not be much help on average for a broad population of patients, but there some subpopulation might experience benefits. Targeting those subpopulations is the goal of the field of precision medicine.</p>
</div>
<div class="readable-text intended-text" id="p269">
<p>In probabilistic models, we use probability distributions to model populations. It is particularly useful to target subpopulations with conditional probability. For example, suppose <em>P</em><em> </em>(<em>E</em><em>  </em>|<em>F</em><em> </em>=True) represents the distribution of engagement numbers among all users exposed to a website feature. Then <em>P</em><em> </em>(<em>E</em><em>  </em>|<em>F</em><em> </em>=True, <em>G</em><em> </em>="millennial") represents the subpopulation of users exposed to the feature who are also millennials.</p>
</div>
<div class="readable-text" id="p270">
<h4 class="readable-text-h4 sigil_not_in_toc">Canonical distributions and stochastic processes as models of populations</h4>
</div>
<div class="readable-text" id="p271">
<p>If we use probability distributions to model populations, what canonical distributions should we use for a given population? Figure 2.18 includes common distributions and the phenomena they typically model.</p>
</div>
<div class="browsable-container figure-container" id="p272">
<img alt="figure" height="533" src="../Images/CH02_F18_Ness.png" width="1015"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.18</span> Examples of common canonical distributions and the types of phenomena and data they typically model</h5>
</div>
<div class="readable-text intended-text" id="p273">
<p>These choices don’t come from nowhere. The canonical distributions are themselves derived from stochastic functions. For example, the binomial distribution is the result of a process where you do a series of coin flips. When something is the result of adding together a bunch of independent (or weakly dependent) small changes, you get a normal distribution. Waiting time distributions capture the distribution of the amount of time one must wait for an event (e.g., a device failure or a car accident). The exponential distribution is appropriate for waiting times when the amount of time you’ve already been waiting has no bearing on how much time you still must wait (e.g., for the amount of time it takes a radioactive atom to decay). If the time to event has an exponential distribution, the number of times that event has occurred within a fixed time period has a Poisson distribution.<span class="aframe-location"/></p>
</div>
<div class="readable-text intended-text" id="p274">
<p>A useful trick in probabilistic modeling is to think of the stochastic process that created your target population. Then either choose the appropriate canonical distribution or implement the stochastic process in code using various canonical distributions as primitives in the code logic. In this book, we’ll see that this line of reasoning aligns well with causal modeling. </p>
</div>
<div class="readable-text" id="p275">
<h4 class="readable-text-h4 sigil_not_in_toc">Sampling, IID, and generation</h4>
</div>
<div class="readable-text" id="p276">
<p>Usually, our data is not the whole population but a small subset from the population. The act of randomly choosing an individual is called <em>sampling</em>. When the data is created by repeatedly sampling from the population, the resulting dataset is called a <em>random sample</em>. If we can view data as a <em>random sample</em>, we call that data <em>independent and identically distributed (IID)</em>. That means that the selection of each individual data point is <em>identical</em> in how it was sampled, and each sampling occurred <em>independently</em> of the others, and they all were sampled from the same population distribution. Figure 2.19 illustrates how an IID random sample is selected from a population.</p>
</div>
<div class="browsable-container figure-container" id="p277">
<img alt="figure" height="359" src="../Images/CH02_F19_Ness.png" width="781"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.19</span> Creating a random sample by random selection from a population. Individuals are randomly selected from the population such that the sample distribution resembles the population distribution. The sample is identically and independently distributed (IID), meaning that sample members are selected the same way, and whether an individual is selected doesn’t depend on whether another individual was selected.<span class="aframe-location"/></h5>
</div>
<div class="readable-text" id="p278">
<p>The idea of sampling and IID data illustrates the second benefit of using probability distributions to model populations. We can use generation from that distribution to model sampling from a population. We can implement a stochastic process that represents the DGP by first writing a stochastic process that represents the population and then composing it with a process that generates data from the population process, emulating IID sampling.</p>
</div>
<div class="readable-text intended-text" id="p279">
<p>In pgmpy, this is as simple as generating more than one sample.</p>
</div>
<div class="browsable-container listing-container" id="p280">
<div class="code-area-container">
<pre class="code-area">generator.forward_sample(size=10)</pre>
</div>
</div>
<div class="readable-text" id="p281">
<p>This produces the table showing in figure 2.20<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p282">
<img alt="figure" height="432" src="../Images/CH02_F20_Ness.png" width="124"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.20</span> A pandas DataFrame created by generating ten data points from a model in pgmpy</h5>
</div>
<div class="readable-text" id="p283">
<p>The Pyro approach for IID sampling is <code>pyro.plate</code>.</p>
</div>
<div class="browsable-container listing-container" id="p284">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 2.10</span> Generating IID samples in Pyro</h5>
<div class="code-area-container">
<pre class="code-area">import pyro
from pyro.distributions import Bernoulli, Poisson, Gamma

def model():
    z = pyro.sample("z", Gamma(7.5, 1.0))
    x = pyro.sample("x", Poisson(z))
    with pyro.plate("IID", 10):    <span class="aframe-location"/> #1
        y = pyro.sample("y", Bernoulli(x / (5+x)))   <span class="aframe-location"/> #2
    return y

model()</pre>
<div class="code-annotations-overlay-container">
     #1 pyro.plate is a context manager for generating conditionally independent samples. This instance of pyro.plate will generate 10 IIΔ samples.
     <br/>#2 Calling pyro.sample generates a single outcome y, where y is a tensor of 10 IIΔ samples.
     <br/>
</div>
</div>
</div>
<div class="readable-text" id="p285">
<p>Using generation to model sampling is particularly useful in machine learning, because often the data is not IID. In the MNIST example in chapter 1, the original NIST data was not IID—one block of data came from high school students and the other from government officers. You could capture the identity of the digit writer as a variable in your stochastic process. Then the data would be IID <em>conditional</em> on that variable.</p>
</div>
<div class="readable-text" id="p286">
<h4 class="readable-text-h4 sigil_not_in_toc">Don’t mistake the map for the terrain</h4>
</div>
<div class="readable-text" id="p287">
<p>Consider again the MNIST data. The population for that data is quite nebulous and abstract. If that digit classification software were licensed to multiple clients, the population would be a practically unending stream of digits. Generalizing to abstract populations is the common scenario in machine learning, as it is for statistics. When R.A. Fisher, the founding father of modern statistics, was designing experiments for testing soil types on crop growth at Rothamsted Research, he was trying to figure out how to generalize to the population of future crops (with as small a number of samples as possible).</p>
</div>
<div class="readable-text intended-text" id="p288">
<p>The problem with working with nebulously large populations is that it can lead to the mistake of mentally conflating populations with the probability distributions. Do not do this. Do not mistake the map (the distribution used to model the population) for the terrain (the population itself). </p>
</div>
<div class="readable-text intended-text" id="p289">
<p>To illustrate, consider the following example: While writing part of this chapter, I was vacationing in Silves, a town in the Portuguese Algarve with a big castle, deep history, and great hiking. Suppose I were interested in modeling the heights of Silves residents.</p>
</div>
<div class="readable-text intended-text" id="p290">
<p>Officially, the population of Silves is 11,000, so let’s take that number as ground truth. That means there are 11,000 different height values in Silves. Suppose I physically went down to the national health center in Silves and got a spreadsheet of every resident’s height. Then the data I’d have is not a randomly sampled subset of the population—it is the full population itself.</p>
</div>
<div class="readable-text intended-text" id="p291">
<p>I could then compute a <em>histogram</em> on that population, as shown in figure 2.21. A histogram is a visualization of the counts of values (in this case, heights) in a population or sample. For continuous values like heights, we count how many values fall into a range or “bin.”<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p292">
<img alt="figure" height="215" src="../Images/CH02_F21_Ness.png" width="450"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.21</span> A histogram illustrating the height distribution of all Silves residents</h5>
</div>
<div class="readable-text" id="p293">
<p>This histogram represents the full population distribution. I can make it look more like a probability distribution by dividing the counts by the number of people, as in figure 2.22<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p294">
<img alt="figure" height="215" src="../Images/CH02_F22_Ness.png" width="439"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.22</span> Histogram of proportions of Silves residents with given height</h5>
</div>
<div class="readable-text intended-text" id="p295">
<p>One might say this distribution follows the normal (Gaussian) probability distribution, because we see a bell curve, and indeed, the normal is appropriate for evolutionary bell-shaped phenomena such as height. But that statement is not precisely true. To see this, consider that all normal distributions are defined for negative numbers (though those numbers might have an infinitesimal amount of probability density), whereas heights can’t be negative. What we are really doing is using the normal distribution as a <em>model</em>—as an <em>approximation</em> of this population distribution.</p>
</div>
<div class="readable-text intended-text" id="p296">
<p>In another example, figure 2.23 shows the true distribution of the parts of speech in Jane Austen’s novels. Note that this is not based on a sample of pages from her novels; I created this visualization from the parts-of-speech distribution of the 725 thousand words in <em>all</em> her six completed novels.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p297">
<img alt="figure" height="300" src="../Images/CH02_F23_Ness.png" width="429"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.23</span> Actual distribution of word types in all of Jane Austen’s novels</h5>
</div>
<div class="readable-text intended-text" id="p298">
<p>As modelers, we use canonical distributions to model the population distribution, but the model is not equivalent to the population distribution. This point may seem like trivial semantics, but in the era of big data, we often can reason about an entire population instead of just a random sample. For example, popular online social networks have hundreds of millions and sometimes billions of users. That’s a huge size, yet the entire population is just one database query away.</p>
</div>
<div class="readable-text intended-text" id="p299">
<p>In causal modeling, being precise in how we think about modeling data and populations is extremely useful. Causal inferences are about the real-world attributes of the population, rather than just statistical trends in the data. And different causal questions we want to answer will require us to bake different causal assumptions into our models, some of which are stronger or harder to validate than others. </p>
</div>
<div class="readable-text" id="p300">
<h3 class="readable-text-h3" id="sigil_toc_id_46"><span class="num-string">2.3.2</span> From the observed data to the data generating process</h3>
</div>
<div class="readable-text" id="p301">
<p>In causal modeling, it is important to understand how the observed data maps back to the joint probability distribution of the variables in the data, and how that joint probability distribution maps back to the DGP. Most modelers have some level of intuition about the relationships between these entities, but in causal modeling we must be explicit. This explicit understanding is important because, while in ordinary statistical modeling you model the joint distribution (or elements of it), in causal modeling you need to model the DGP.</p>
</div>
<div class="readable-text" id="p302">
<h4 class="readable-text-h4 sigil_not_in_toc">From the observed data to the empirical joint distribution</h4>
</div>
<div class="readable-text" id="p303">
<p>Suppose we had the dataset of five data points shown in table 2.1.</p>
</div>
<div class="browsable-container browsable-table-container framemaker-table-container" id="p304">
<h5 class="browsable-container-h5 sigil_not_in_toc"><span class="num-string">Table 2.1</span> A simple data set with five examples</h5>
<table>
<thead>
<tr>
<th/>
<th>
<div>
         jenny_throws_rock 
       </div></th>
<th>
<div>
         brian_throws_rock 
       </div></th>
<th>
<div>
         window_breaks 
       </div></th>
</tr>
</thead>
<tbody>
<tr>
<td>  1 <br/></td>
<td>  False <br/></td>
<td>  True <br/></td>
<td>  False <br/></td>
</tr>
<tr>
<td>  2 <br/></td>
<td>  True <br/></td>
<td>  False <br/></td>
<td>  True <br/></td>
</tr>
<tr>
<td>  3 <br/></td>
<td>  False <br/></td>
<td>  False <br/></td>
<td>  False <br/></td>
</tr>
<tr>
<td>  4 <br/></td>
<td>  False <br/></td>
<td>  False <br/></td>
<td>  False <br/></td>
</tr>
<tr>
<td>  5 <br/></td>
<td>  True <br/></td>
<td>  True <br/></td>
<td>  True <br/></td>
</tr>
</tbody>
</table>
</div>
<div class="readable-text" id="p305">
<p>We can take counts of all the observed observable outcomes, as in table 2.2.</p>
</div>
<div class="browsable-container browsable-table-container framemaker-table-container" id="p306">
<h5 class="browsable-container-h5 sigil_not_in_toc"><span class="num-string">Table 2.2</span> Empirical counts of each possible outcome combination</h5>
<table>
<thead>
<tr>
<th/>
<th>
<div>
         jenny_throws_rock 
       </div></th>
<th>
<div>
         brian_throws_rock 
       </div></th>
<th>
<div>
         window_breaks 
       </div></th>
<th>
<div>
         counts 
       </div></th>
</tr>
</thead>
<tbody>
<tr>
<td>  1 <br/></td>
<td>  False <br/></td>
<td>  False <br/></td>
<td>  False <br/></td>
<td>  2 <br/></td>
</tr>
<tr>
<td>  2 <br/></td>
<td>  True <br/></td>
<td>  False <br/></td>
<td>  False <br/></td>
<td>  0 <br/></td>
</tr>
<tr>
<td>  3 <br/></td>
<td>  False <br/></td>
<td>  True <br/></td>
<td>  False <br/></td>
<td>  1 <br/></td>
</tr>
<tr>
<td>  4 <br/></td>
<td>  True <br/></td>
<td>  True <br/></td>
<td>  False <br/></td>
<td>  0 <br/></td>
</tr>
<tr>
<td>  5 <br/></td>
<td>  False <br/></td>
<td>  False <br/></td>
<td>  True <br/></td>
<td>  0 <br/></td>
</tr>
<tr>
<td>  6 <br/></td>
<td>  True <br/></td>
<td>  False <br/></td>
<td>  True <br/></td>
<td>  1 <br/></td>
</tr>
<tr>
<td>  7 <br/></td>
<td>  False <br/></td>
<td>  True <br/></td>
<td>  True <br/></td>
<td>  0 <br/></td>
</tr>
<tr>
<td>  8 <br/></td>
<td>  True <br/></td>
<td>  True <br/></td>
<td>  True <br/></td>
<td>  1 <br/></td>
</tr>
</tbody>
</table>
</div>
<div class="readable-text" id="p307">
<p>Dividing by the number of outcomes (5) gives us the <em>empirical joint distribution</em>, shown in table 2.3.</p>
</div>
<div class="browsable-container browsable-table-container framemaker-table-container" id="p308">
<h5 class="browsable-container-h5 sigil_not_in_toc"><span class="num-string">Table 2.3</span> The empirical distribution of the data</h5>
<table>
<thead>
<tr>
<th/>
<th>
<div>
         jenny_throws_rock 
       </div></th>
<th>
<div>
         brian_throws_rock 
       </div></th>
<th>
<div>
         window_breaks 
       </div></th>
<th>
<div>
         proportion 
       </div></th>
</tr>
</thead>
<tbody>
<tr>
<td>  1 <br/></td>
<td>  False <br/></td>
<td>  False <br/></td>
<td>  False <br/></td>
<td>  0.40 <br/></td>
</tr>
<tr>
<td>  2 <br/></td>
<td>  True <br/></td>
<td>  False <br/></td>
<td>  False <br/></td>
<td>  0.00 <br/></td>
</tr>
<tr>
<td>  3 <br/></td>
<td>  False <br/></td>
<td>  True <br/></td>
<td>  False <br/></td>
<td>  0.20 <br/></td>
</tr>
<tr>
<td>  4 <br/></td>
<td>  True <br/></td>
<td>  True <br/></td>
<td>  False <br/></td>
<td>  0.00 <br/></td>
</tr>
<tr>
<td>  5 <br/></td>
<td>  False <br/></td>
<td>  False <br/></td>
<td>  True <br/></td>
<td>  0.00 <br/></td>
</tr>
<tr>
<td>  6 <br/></td>
<td>  True <br/></td>
<td>  False <br/></td>
<td>  True <br/></td>
<td>  0.20 <br/></td>
</tr>
<tr>
<td>  7 <br/></td>
<td>  False <br/></td>
<td>  True <br/></td>
<td>  True <br/></td>
<td>  0.00 <br/></td>
</tr>
<tr>
<td>  8 <br/></td>
<td>  True <br/></td>
<td>  True <br/></td>
<td>  True <br/></td>
<td>  0.20 <br/></td>
</tr>
</tbody>
</table>
</div>
<div class="readable-text" id="p309">
<p>So, in the case of discrete outcomes, we go from the data to the empirical distribution using counts.</p>
</div>
<div class="readable-text intended-text" id="p310">
<p>In the continuous case, we could calculate a histogram or a density curve or some other statistical representation of the empirical distribution. There are different statistical choices you can make about how you create those summaries, but these are representations of the same underlying empirical distribution.</p>
</div>
<div class="readable-text intended-text" id="p311">
<p>Importantly, the empirical joint distribution is not the actual joint distribution of the variables in the data. For example, we see that several outcomes in the empirical distribution never appeared in those five data points. Is the probability of their occurrence zero? More likely, the probabilities were greater than zero but we didn’t see those outcomes, since only five points were sampled.</p>
</div>
<div class="readable-text intended-text" id="p312">
<p>As an analogy, a fair die has a 1/6 probability of rolling a 1. If you roll the die five times, you have a near (1–1/6)<sup>5</sup>=40% probability of not seeing 1 in any of those rolls. If that happened to you, you wouldn’t want to conclude that the probability of seeing a 1 is zero. If, however, you kept rolling, the proportion of times you saw the 1 would converge to 1/6.</p>
</div>
<div class="readable-text print-book-callout" id="p313">
<p><span class="print-book-callout-head">NOTE</span>  More precisely, our frequentist interpretation of probability tells us to interpret probability as the proportion of times we get a 1 when we roll ad infinitum. Despite the “ad infinitum,” we don’t have to roll many times before the proportion starts converging to a number (1/6).</p>
</div>
<div class="readable-text" id="p314">
<h4 class="readable-text-h4 sigil_not_in_toc">From the empirical joint distribution to the observational joint distribution</h4>
</div>
<div class="readable-text" id="p315">
<p>The <em>observational joint probability</em> distribution is the true joint distribution of the variables observed in the data. Let’s suppose table 2.4 shows the true observational joint probability distribution of these observed variables.</p>
</div>
<div class="browsable-container browsable-table-container framemaker-table-container" id="p316">
<h5 class="browsable-container-h5 sigil_not_in_toc"><span class="num-string">Table 2.4</span> Assume this is the true observational joint distribution.</h5>
<table>
<thead>
<tr>
<th/>
<th>
<div>
         jenny_throws_rock 
       </div></th>
<th>
<div>
         brian_throws_rock 
       </div></th>
<th>
<div>
         window_breaks 
       </div></th>
<th>
<div>
         probability 
       </div></th>
</tr>
</thead>
<tbody>
<tr>
<td>  1 <br/></td>
<td>  False <br/></td>
<td>  False <br/></td>
<td>  False <br/></td>
<td>  0.25 <br/></td>
</tr>
<tr>
<td>  2 <br/></td>
<td>  True <br/></td>
<td>  False <br/></td>
<td>  False <br/></td>
<td>  0.15 <br/></td>
</tr>
<tr>
<td>  3 <br/></td>
<td>  False <br/></td>
<td>  True <br/></td>
<td>  False <br/></td>
<td>  0.15 <br/></td>
</tr>
<tr>
<td>  4 <br/></td>
<td>  True <br/></td>
<td>  True <br/></td>
<td>  False <br/></td>
<td>  0.05 <br/></td>
</tr>
<tr>
<td>  5 <br/></td>
<td>  False <br/></td>
<td>  False <br/></td>
<td>  True <br/></td>
<td>  0.00 <br/></td>
</tr>
<tr>
<td>  6 <br/></td>
<td>  True <br/></td>
<td>  False <br/></td>
<td>  True <br/></td>
<td>  0.10 <br/></td>
</tr>
<tr>
<td>  7 <br/></td>
<td>  False <br/></td>
<td>  True <br/></td>
<td>  True <br/></td>
<td>  0.10 <br/></td>
</tr>
<tr>
<td>  8 <br/></td>
<td>  True <br/></td>
<td>  True <br/></td>
<td>  True <br/></td>
<td>  0.20 <br/></td>
</tr>
</tbody>
</table>
</div>
<div class="readable-text" id="p317">
<p>Sampling from the joint observational distribution produces the empirical joint distribution, as illustrated in figure 2.24.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p318">
<img alt="figure" height="159" src="../Images/CH02_F24_Ness.png" width="346"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.24</span> Sampling from the observational joint distribution produces the observed data and empirical distribution.</h5>
</div>
<div class="readable-text" id="p319">
<h4 class="readable-text-h4 sigil_not_in_toc">Latent variables: From the observed joint distribution to the full joint distribution</h4>
</div>
<div class="readable-text" id="p320">
<p>In statistical modeling, <em>latent variables</em> are variables that are not directly observed in the data but are included in the statistical model. Going back to our data example, imagine there were a fourth latent variable, “strength_of_impact”, shown in table 2.5.</p>
</div>
<div class="browsable-container browsable-table-container framemaker-table-container" id="p321">
<h5 class="browsable-container-h5 sigil_not_in_toc"><span class="num-string">Table 2.5</span> The values in the strength_of_impact column are unseen “latent” variables.</h5>
<table>
<thead>
<tr>
<th/>
<th>
<div>
         jenny_throws_rock 
       </div></th>
<th>
<div>
         brian_throws_rock 
       </div></th>
<th>
<div>
         strength_of_impact 
       </div></th>
<th>
<div>
         window_breaks 
       </div></th>
</tr>
</thead>
<tbody>
<tr>
<td>  1 <br/></td>
<td>  False <br/></td>
<td>  True <br/></td>
<td>  0.6 <br/></td>
<td>  False <br/></td>
</tr>
<tr>
<td>  2 <br/></td>
<td>  True <br/></td>
<td>  False <br/></td>
<td>  0.6 <br/></td>
<td>  True <br/></td>
</tr>
<tr>
<td>  3 <br/></td>
<td>  False <br/></td>
<td>  False <br/></td>
<td>  0.0 <br/></td>
<td>  False <br/></td>
</tr>
<tr>
<td>  4 <br/></td>
<td>  False <br/></td>
<td>  False <br/></td>
<td>  0.0 <br/></td>
<td>  False <br/></td>
</tr>
<tr>
<td>  5 <br/></td>
<td>  True <br/></td>
<td>  True <br/></td>
<td>  0.8 <br/></td>
<td>  True <br/></td>
</tr>
</tbody>
</table>
</div>
<div class="readable-text" id="p322">
<p>Latent variable models are common in disciplines ranging from machine learning to econometrics to bioinformatics. For example, in natural language processing, an example of a popular probabilistic latent variable model is <em>topic models</em>, where the observed variables represent the presence of words and phrases in a document, and the latent variable represents the topic of the document (e.g., sports, politics, finance, etc.)</p>
</div>
<div class="readable-text intended-text" id="p323">
<p>The latent variables are omitted from the observational joint probability distribution because, as the name implies, they are not observed. The joint probability distribution of both the observed and the latent variables is the full joint distribution. To go from the full joint distribution to the observational joint distribution, we marginalize over the latent variables, as shown in figure 2.25.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p324">
<img alt="figure" height="234" src="../Images/CH02_F25_Ness.png" width="455"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.25</span> Marginalizing the full joint distribution over the latent variables produces the observational joint distribution.</h5>
</div>
<div class="readable-text" id="p325">
<h4 class="readable-text-h4 sigil_not_in_toc">From the full joint distribution to the data generating process</h4>
</div>
<div class="readable-text" id="p326">
<p>I wrote the actual DGP for the five data points using the following Python code.</p>
</div>
<div class="browsable-container listing-container" id="p327">
<h5 class="listing-container-h5 browsable-container-h5 sigil_not_in_toc"><span class="num-string">Listing 2.11</span> An example of a DGP in code form</h5>
<div class="code-area-container">
<pre class="code-area">
def true_dgp(jenny_inclination, brian_inclination, window_strength):    <span class="aframe-location"/> #1
   <span class="aframe-location"/> jenny_throws_rock = jenny_inclination &gt; 0.5     #2
    brian_throws_rock = brian_inclination &gt; 0.5    #2
    if jenny_throws_rock and brian_throws_rock:<span class="aframe-location"/>    #3
        strength_of_impact = 0.8   #3
    elif jenny_throws_rock or brian_throws_rock:    <span class="aframe-location"/> #4
        strength_of_impact = 0.6    #4
    <span class="aframe-location"/>else:     #5
        strength_of_impact = 0.0   #5
    window_breaks = window_strength &lt; strength_of_impact   <span class="aframe-location"/> #6
    return jenny_throws_rock, brian_throws_rock, window_breaks</pre>
<div class="code-annotations-overlay-container">
     #1 Input variables reflect Jenny and Brian’s inclination to throw and the window’s strength.
     <br/>#2 Jenny and Brian throw the rock if so inclined.
     <br/>#3 If both Jenny and Brian throw the rock, the total strength of the impact is .8.
     <br/>#4 If either Jenny or Brian throws the rock, the total strength of the impact is .6.
     <br/>#5 Otherwise, no one throws and the strength of impact is 0.
     <br/>#6 If the strength of impact is greater than the strength of the window, the window breaks.
     <br/>
</div>
</div>
</div>
<div class="readable-text print-book-callout" id="p328">
<p><span class="print-book-callout-head">Note</span>  In general, the DGP is unknown, and our models are making guesses about its structure. </p>
</div>
<div class="readable-text" id="p329">
<p>In this example<code>, jenny_inclination</code>, <code>brian_inclination</code>, and <code>window_strength</code> are latent variables between 0 and 1. <code>jenny_inclination</code> represents Jenny’s initial desire to throw, <code>brian_inclination</code> represents Brian’s initial desire to throw, and <code>window_strength</code> represents the strength of the window pane. These are the initial conditions that lead to one instantiation of the observed variables in the data: (<code>jenny_throws_ball</code>, <code>brian_throws_ball</code>, <code>window_breaks</code>).</p>
</div>
<div class="readable-text intended-text" id="p330">
<p>I then called the <code>true_dgp</code> function on the following five sets of latent variables:</p>
</div>
<div class="browsable-container listing-container" id="p331">
<div class="code-area-container">
<pre class="code-area">initials = [
    (0.6, 0.31, 0.83),
    (0.48, 0.53, 0.33),
    (0.66, 0.63, 0.75),
    (0.65, 0.66, 0.8),
    (0.48, 0.16, 0.27)
]</pre>
</div>
</div>
<div class="readable-text" id="p332">
<p>In other words, the following <code>for</code> loop in Python is the literal sampling process producing the five data points:</p>
</div>
<div class="browsable-container listing-container" id="p333">
<div class="code-area-container">
<pre class="code-area">data_points = []
for jenny_inclination, brian_inclination, window_strength in initials:    
    data_points.append(
        true_dgp(
            jenny_inclination, brian_inclination, window_strength
        )
    )</pre>
</div>
</div>
<div class="readable-text" id="p334">
<p>The DGP is the causal process that generated the data. Note the narrative element that is utterly missing from the full joint probability distribution; Jenny and Brian throw a rock at a window if they are so inclined, and if they hit the window, the window may break, depending on whether one or both of them threw rocks and the strength of the window. The DGP entails the full joint probability distribution, as shown in figure 2.26. In other words, the joint probability distribution is a consequence of the DGP based on <em>how</em> it generates data.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p335">
<img alt="figure" height="307" src="../Images/CH02_F26_Ness.png" width="344"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.26</span> The DGP entails the full joint distribution.</h5>
</div>
<div class="readable-text intended-text" id="p336">
<p> In summary, the DGP entails the full joint distribution, and marginalizing over the full joint distribution produces the observational joint distribution. Sampling from that distribution produces the observed data and the corresponding empirical joint distribution. There is a many-to-one relationship as we move down this hierarchy that has implications for causal modeling and inference.</p>
</div>
<div class="readable-text" id="p337">
<h4 class="readable-text-h4 sigil_not_in_toc">Many-to-one relationships down the hierarchy<span class="aframe-location"/></h4>
</div>
<div class="browsable-container figure-container" id="p338">
<img alt="figure" height="244" src="../Images/CH02_F27_Ness.png" width="319"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 2.27</span> There is a many-to-one relationship as we move down the hierarchy. In summary, there are multiple DGPs consistent with the observed data.</h5>
</div>
<div class="readable-text" id="p339">
<p>As we move down from the DGP to full joint to observational joint to empirical joint distribution and observed data, there is a many-to-one relationship from the preceding level to the subsequent level, as illustrated in figure 2.27.</p>
</div>
<div class="readable-text intended-text" id="p340">
<p>Similarly, an object at one of the levels is consistent with multiple objects at the next level up:</p>
</div>
<ul>
<li class="readable-text" id="p341"> <em>There could be multiple observational joint distributions consistent with the empirical joint distribution</em>. If we sample five points, then sample five more, we’ll get different datasets and thus different empirical distributions. </li>
<li class="readable-text" id="p342"> <em>There could be multiple full joint distributions consistent with one observational joint distribution</em>. The difference between the two distributions is the latent variables. But what if we have different choices for the sets of latent variables? For example, if our observation distribution is <em>P</em><em> </em>(<em>X</em>, <em>Y</em><em>  </em>), the full joint would be <em>P</em><em> </em>(<em>X</em>, <em>Y</em>, <em>Z</em>, <em>W</em>) if our set of latent variables is {<em>Z</em>, <em>W</em><em>  </em>}, or <em>P</em><em> </em>(<em>X</em>, <em>Y</em>, <em>Z</em>, <em>V</em><em>  </em>) if our set of latent variables is {<em>Z</em>, <em>V</em><em>  </em>}. </li>
<li class="readable-text" id="p343"> <em>There could be multiple DGP’s consistent with one full joint probability distribution</em>. Suppose in our window-breaking example, Jenny had a friend Isabelle who sometimes egged Jenny on to throw the rock and sometimes did not, affecting Jenny’s inclination to throw. This DGP is different from the original, but the relationship between the latent variable of Isabell’s peer pressure and Jenny’s inclination to throw could be such that this new DGP entailed exactly the same joint probability distribution. As a more trivial example, suppose we looked at the distribution of a single variable corresponding to the sum of the roll of three dice. The DGP is rolling three dice and then summing them together. Two DGPs could differ in terms of the order of summing the dice; e.g., (first + second) + third or (first + third) + second or (second + third) + first. These would all yield the same distribution. </li>
</ul>
<div class="readable-text" id="p344">
<p>Those last two many-to-one relationships are fundamental to the concept of <em>causal identifiability,</em> the core reason why causal inference is hard. This concept is the reason “correlation does not imply causation,” as the saying goes.</p>
</div>
<div class="readable-text" id="p345">
<h3 class="readable-text-h3" id="sigil_toc_id_47"><span class="num-string">2.3.3</span> Statistical tests for independence</h3>
</div>
<div class="readable-text" id="p346">
<p>Causality imposes independence and conditional independence on variables, so we rely on statistical tests for conditional independence to build and validate causal models.</p>
</div>
<div class="readable-text intended-text" id="p347">
<p>Suppose <em>X</em> and <em>Y</em> are independent, or <em>X</em> and <em>Y</em> are conditionally independent given <em>Z</em>. If we have data observing <em>X</em>, <em>Y</em>, and <em>Z</em>, we can run a statistical test for independence. The canonical statistical independence procedure returns a test statistic that quantifies the statistical association between <em>X</em> and <em>Y</em>, and a p-value that quantifies the probability of getting that degree of association, or one more extreme, by pure chance when <em>X</em> and <em>Y</em> are actually conditionally independent given <em>Z</em>. Put simply, the test quantifies the statistical evidence of dependence or independence.</p>
</div>
<div class="readable-text intended-text" id="p348">
<p>Evidence suggesting that someone committed a murder is not the same as the definitive truth that they did. Similarly, statistical evidence indicating independence between two variables does not equate to the actual fact of their independence. In both cases, evidence can point toward a conclusion without definitively proving it. For example, given that independence is true, the strength of the statistical evidence can vary on several factors, such as how much data there is. And it is always possible to make false conclusions from these tests.</p>
</div>
<div class="readable-text intended-text" id="p349">
<p>Remember that if <em>X</em> and <em>Y</em> are independent, then <em>P</em><em> </em>(<em>Y</em><em>  </em>|<em>X</em><em>  </em>) is equivalent to <em>P</em><em> </em>(<em>Y</em><em>  </em>). In predictive terms, that means <em>X</em> has no predictive power on <em>Y</em>. If you can’t use classical statistical tests (e.g., if <em>X</em> and <em>Y</em> are vectors) then you can try training a predictive model and subjectively evaluating how well the model predicts.</p>
</div>
<div class="readable-text" id="p350">
<h3 class="readable-text-h3" id="sigil_toc_id_48"><span class="num-string">2.3.4</span> Statistical estimation of model parameters</h3>
</div>
<div class="readable-text" id="p351">
<p>When we “train” or “fit” a model, we are attempting to estimate the values of parameters of the model, such as the weights in a regression model or neural network. Generally, in statistical modeling and machine learning, the goal of parameter estimation is modeling the observational or joint probability distribution. In causal modeling, the objective is modeling the DGP. The distinction is important for making good causal inferences.</p>
</div>
<div class="readable-text" id="p352">
<h4 class="readable-text-h4 sigil_not_in_toc">Estimating by maximizing likelihood</h4>
</div>
<div class="readable-text" id="p353">
<p>In informal terms and in the context of parameter estimation, likelihood is the probability of having observed the data given a candidate value of the parameter vector. <em>Maximizing likelihood</em> means choosing the value of the parameter vector that has the highest likelihood. Usually, we work with maximizing the log of the likelihood instead of the likelihood directly because it is mathematically and computationally easier to do so; the value that maximizes likelihood is the same as the value that maximizes log-likelihood. In special cases, such as linear regression, the maximum likelihood estimate has a solution we can derive mathematically, but in general, we must find the solution using numerical optimization techniques. In some models, such as neural networks, it is infeasible to find the value that maximizes likelihood, so we settle for a candidate that has a relatively high likelihood.</p>
</div>
<div class="readable-text" id="p354">
<h4 class="readable-text-h4 sigil_not_in_toc">Estimating by minimizing other loss functions and regularization</h4>
</div>
<div class="readable-text" id="p355">
<p>In machine learning, there are a variety of loss functions for estimating parameters. Maximizing likelihood is a special case of minimizing a loss function, namely the negative log-likelihood loss function. </p>
</div>
<div class="readable-text intended-text" id="p356">
<p><em>Regularization</em> is the practice of adding additional elements to the loss function that steer the optimization toward better parameter values. For example, L2 regularization adds a value proportional to the sum of the square of the parameter values to the loss. Since a small increase in value leads to a larger increase in the square of the value, L2 regularization helps avoid exceedingly large parameter estimates.</p>
</div>
<div class="readable-text" id="p357">
<h4 class="readable-text-h4 sigil_not_in_toc">Bayesian estimation</h4>
</div>
<div class="readable-text" id="p358">
<p><em>Bayesian estimation</em> treats parameters as random variables and tries to model the conditional distribution of the parameters (typically called the <em>posterior </em>distribution) given the observed variables in the data. It does so by putting a “prior probability distribution” on the parameters. The prior distribution has its own parameters called “hyperparameters” that the modeler must specify. When there are latent variables in the model, Bayesian inference targets the joint distribution of the parameters and the latent variables conditional on the observed variables.</p>
</div>
<div class="readable-text intended-text" id="p359">
<p>As mentioned before, in this book I use Greek letters for parameters and Roman letters for variables in the DGP, including latent variables. But for a Bayesian statistician, the distinction is irrelevant; both parameters and latent variables are unknown and thus targets of inference. </p>
</div>
<div class="readable-text intended-text" id="p360">
<p>One of the main advantages of Bayesian estimation is that rather than getting a point value for the parameters, you get an entire conditional probability distribution of the parameters (more specifically, you get samples from or parameter values representing that distribution). That probability distribution represents uncertainty about the parameter values, and you can incorporate that uncertainty into predictions or other inferences you make from the model.</p>
</div>
<div class="readable-text intended-text" id="p361">
<p>According to Bayesian philosophy, the prior distribution should capture the modeler’s subjective beliefs about the true value of the parameters. We’ll do something similar in causal modeling when we turn our beliefs about the causal structure and mechanisms of the DGP into causal assumptions in the model.</p>
</div>
<div class="readable-text" id="p362">
<h4 class="readable-text-h4 sigil_not_in_toc">Statistical and computational attributes of an estimator</h4>
</div>
<div class="readable-text" id="p363">
<p>Given that there are many ways of estimating a parameter, let’s look for ways to compare the quality of estimation methods. Suppose the parameter we want to estimate had a ground truth value. Statisticians think about how well an estimation method can recover that true value. Specifically, they care about the bias and consistency of an estimation method. An estimator is a random variable because it comes from data (and data has a distribution), which means an estimator has a distribution. An estimator is unbiased if the mean of that distribution is equal to the true value of the parameter it is estimating. Consistency means that the more data you have, the closer the estimate is to the true value of the parameter. In practice, the consistency of the estimator is more important than whether it is unbiased.</p>
</div>
<div class="readable-text intended-text" id="p364">
<p>Computer scientists know that while consistency is nice in theory, getting an estimation method to work with “more data” is easier said than done. They care about the computational qualities of an estimator in relation to the amount of data. Does the estimator scale with the data? Is it parallelizable? An estimator may be consistent, but when its running on an iPhone app, will it converge to the true value in milliseconds and not eat up the battery’s charge in the process?</p>
</div>
<div class="readable-text intended-text" id="p365">
<p>This book decouples understanding causal logic from the statistical and computational properties of estimators of causal parameters. We will focus on the causal logic and rely on libraries like DoWhy that make the statistical and computational calculations easy to do.</p>
</div>
<div class="readable-text" id="p366">
<h4 class="readable-text-h4 sigil_not_in_toc">Goodness-of-fit vs. cross-validation </h4>
</div>
<div class="readable-text" id="p367">
<p>When we estimate parameters, we can calculate various statistics to tell us how well we’ve done. One class of statistics is called <em>goodness-of-fit statistics</em>. Statisticians define goodness-of-fit as statistics that quantify how well the model fits the data used to train the model. Here’s another definition: goodness-of-fit statistics tell you how well your model pretends to be the DGP for the data you used to train your model. However, as we saw, there are multiple possible DGPs for a given data set. Goodness-of-fit won’t provide causal information that can distinguish the true DGP.</p>
</div>
<div class="readable-text intended-text" id="p368">
<p>Cross-validation statistics generally indicate how well your model predicts data it was not trained on. It is possible to have a model with a decent goodness-of-fit relative to other models, but that still predicts poorly. Machine learning is usually concerned with the task of prediction and so favors cross-validation. However, a model can be a good predictor and provide completely bogus causal inferences.</p>
</div>
<div class="readable-text" id="p369">
<h2 class="readable-text-h2" id="sigil_toc_id_49"><span class="num-string">2.4</span> Determinism and subjective probability</h2>
</div>
<div class="readable-text" id="p370">
<p>This section will venture into the philosophical underpinnings we’ll need for probabilistic causal modeling. In this book, we’ll use probabilistic models to model causal models. When training the model, we might want to use Bayesian parameter estimation procedures. When doing causal inference, we might want to use a probabilistic inference algorithm. When we do causal decision-making, we might want to use Bayesian decision theory. Further, <em>structural causal models</em> (chapter 6) have a rigid requirement on where randomness can occur in the model. That means being clear about the differences between Bayesianism, uncertainty, randomness, probabilistic modeling, and probabilistic inference is important.</p>
</div>
<div class="readable-text intended-text" id="p371">
<p>The first key point is to view the DGP as deterministic. The second key point is to view the probability in our models of the DGP as subjective.</p>
</div>
<div class="readable-text" id="p372">
<h3 class="readable-text-h3" id="sigil_toc_id_50"><span class="num-string">2.4.1</span> Determinism</h3>
</div>
<div class="readable-text" id="p373">
<p>The earlier code for the rock-throwing DGP is entirely <em>deterministic</em>; given the initial conditions, the output is certain. Consider our definition of physical probability again: if I throw a die, why is the outcome random?</p>
</div>
<div class="readable-text intended-text" id="p374">
<p>If I had a superhuman level of dexterity, perception, and mental processing power, I could mentally calculate the die roll’s physics and know the outcome with certainty. This philosophical idea of determinism essentially says that the DGP is deterministic. Eighteenth-century French scholar Pierre-Simon Laplace explained determinism with a thought experiment called <em>Laplace’s demon</em>. Laplace imagined some entity (the demon) that knew every atom’s precise location and momentum in the universe. With that knowledge, that entity would know the future state of the universe with complete deterministic certainty because it could calculate them from the laws of (Newtonian) mechanics. In other words, given all the causes, the effect is 100% entirely determined and not at all random.</p>
</div>
<div class="readable-text intended-text" id="p375">
<p>To be clear, some systems, when we look closely enough, have inherently stochastic elements (e.g., quantum mechanics, biochemistry, etc.). However, this philosophical view of modeling will apply to most things we’ll care to model.</p>
</div>
<div class="readable-text" id="p376">
<h3 class="readable-text-h3" id="sigil_toc_id_51"><span class="num-string">2.4.2</span> Subjective probability</h3>
</div>
<div class="readable-text" id="p377">
<p>In our physical interpretation of probability, when I roll a die, probability represents my lack of the demon’s superhuman knowledge of the location and momentum of all the die’s particles as it is rolling. In other words, when I build probability models of the DGP, the probability reflects my lack of knowledge. This philosophical idea is called <em>subjective probability </em>or<em> Bayesian probability</em>. The argument goes beyond Bayes rule and Bayesian statistical estimation to say that probability in the model represents the modeler’s lack of complete knowledge about the DGP and does not represent inherent randomness in the DGP.</p>
</div>
<div class="readable-text intended-text" id="p378">
<p>Subjective probability expands our “random physical process” interpretation of probability. The physical interpretation of probability works well for simple physical processes like rolling a die, flipping a coin, or shuffling a deck of cards. But, of course, we will want to model many phenomena that are difficult to think of as repeatable physical processes. For example, how the mind turns thoughts into speech, or how an increased flow of fresh water into the ocean due to climate change is threatening to tip the global system of ocean currents. In these cases, we will still model these phenomena using random generation. The probabilities used in the random generation reflect that while we, as modelers, may know some details about the data-generating process, we’ll never have the superhuman deterministic level of detail.</p>
</div>
<div class="readable-text" id="p379">
<h2 class="readable-text-h2" id="sigil_toc_id_52">Summary</h2>
</div>
<ul>
<li class="readable-text" id="p380"> A random variable is a variable whose possible values are numerical outcomes of a random phenomenon. </li>
<li class="readable-text" id="p381"> A probability distribution function is a function that maps the random variable outcomes to a probability value. A joint probability distribution function maps each combination of <em>X</em> and <em>Y</em> outcomes to a probability value. </li>
<li class="readable-text" id="p382"> We derive the chain rule, the law of total probability, and Bayes rule from the fundamental axioms of probability. These are useful rules in modeling. </li>
<li class="readable-text" id="p383"> A Markovian assumption means each variable in an ordering of variables only depends on those that come directly before in the order. This is a common simplifying assumption in statistical modeling, but it plays a large role in causal modeling. </li>
<li class="readable-text" id="p384"> Canonical classes of distributions are mathematically well-described representations of distributions. They provide us with primitives that make probabilistic modeling flexible and relatively easy. </li>
<li class="readable-text" id="p385"> Canonical distributions are instantiated with a set of parameters, such as location, scale, rate, and shape parameters. </li>
<li class="readable-text" id="p386"> When we build models, knowing what variables are independent or conditionally independent dramatically simplifies the model. In causal modeling, independence and conditional independence will be vital in separating correlation from causation. </li>
<li class="readable-text" id="p387"> The expected value of a random variable with a finite number of outcomes is the weighted average of all possible outcomes, where the weight is the probability of that outcome. </li>
<li class="readable-text" id="p388"> Probability is just a value. We need to give that value an interpretation. The physical definition of probability maps probability to the proportion of times an outcome would occur if a physical process could be run repeatedly ad infinitum. </li>
<li class="readable-text" id="p389"> In contrast to the physical interpretation of probability, the Bayesian view of subjective probability interprets probability in terms of belief, or conversely, uncertainty. </li>
<li class="readable-text" id="p390"> When coding a random process, Pyro allows you to use canonical distributions as primitives in constructing nuanced random process models. </li>
<li class="readable-text" id="p391"> Monte Carlo algorithms use random generation to estimate expectations from a distribution of interest. </li>
<li class="readable-text" id="p392"> Popular inference algorithms include graphical model-based algorithms, probability weighting, MCMC, and variational inference. </li>
<li class="readable-text" id="p393"> Canonical distributions and random processes can serve as proxies for populations we wish to model and for which we want to make inferences. Conditional probability is an excellent way to model heterogeneous subpopulations. </li>
<li class="readable-text" id="p394"> Different canonical distributions are used to model different phenomena, such as counts, bell curves, and waiting times.  </li>
<li class="readable-text" id="p395"> Generating from random processes is a good model of real-life sampling of independent and identically distributed data. </li>
<li class="readable-text" id="p396"> Given a dataset, multiple data generating processes (DGPs) could have potentially generated that dataset. This fact connects to the challenge of parsing causality from correlation. </li>
<li class="readable-text" id="p397"> Statistical independence tests validate independence and conditional independence claims about the underlying distribution. </li>
<li class="readable-text" id="p398"> There are several methods for learning model parameters, including maximum likelihood estimation and Bayesian estimation. </li>
<li class="readable-text" id="p399"> Determinism suggests that if we knew everything about a system, we could predict its outcome with zero error. Subjective probability is the idea that probability represents the modeler’s lack of that complete knowledge about the system. Adopting these philosophical perspectives will serve us in understanding causal AI. </li>
<li class="readable-text" id="p400"> A great way to build models is to factorize a joint distribution, simplify the factors with conditional independence, and then implement factors as random processes. </li>
<li class="readable-text" id="p401"> A powerful modeling technique is to use probability distributions to model populations, particularly when you care about heterogeneity in those populations. </li>
<li class="readable-text" id="p402"> When we use probability distributions to model populations, we can map generating from random processes to sampling from the population. </li>
<li class="readable-text" id="p403"> While traditional statistical modeling models the observational joint distribution or the full joint distribution, causal modeling models the DGP. </li>
</ul>
</div></body></html>