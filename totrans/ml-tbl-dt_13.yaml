- en: 11 Building a machine learning pipeline
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 11 构建机器学习流程
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: An overview of machine learning pipelines
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习流程概述
- en: Prerequisites for running a machine learning pipeline in Vertex AI
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Vertex AI中运行机器学习流程的先决条件
- en: 'Model training and deployment: local implementation vs. machine learning pipeline
    implementation'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型训练和部署：本地实现与机器学习流程实现
- en: Defining a machine learning pipeline to train and deploy a model
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义一个机器学习流程以训练和部署模型
- en: Updating the model training code to work with a machine learning pipeline
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新模型训练代码以与机器学习流程一起工作
- en: Using generative AI to help create the machine learning pipeline
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用生成式AI帮助创建机器学习流程
- en: In chapter 10, we went through the steps to deploy a deep learning model trained
    on tabular data. We deployed the model in a web application, first with the model
    running entirely on our local system and then having the model deployed to a Vertex
    AI endpoint. In this chapter, we will go through the further steps to automate
    the training and deployment process by using a machine learning (ML) pipeline
    in Vertex AI. We will start by going over the setup steps necessary for a ML pipeline,
    including defining a Vertex AI dataset. Next, we will contrast the local model
    training and deployment we have seen from chapter 10 with model training and deployment
    using an ML pipeline. We will proceed to review the code specifically for the
    ML pipeline itself, along with the updates to the existing code required for the
    model training code to work in the context of an ML pipeline. Finally, we will
    examine some of the ways that we can apply generative AI and get useful help from
    its outputs in the workflow for creating a ML pipeline. The code described in
    this chapter is available at [https://mng.bz/DM4n](https://mng.bz/DM4n).
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在第10章中，我们介绍了部署基于表格数据训练的深度学习模型的步骤。我们首先在本地系统中运行模型，然后将模型部署到Vertex AI端点。在本章中，我们将进一步介绍通过在Vertex
    AI中使用机器学习（ML）流程来自动化训练和部署过程的步骤。我们将首先概述设置ML流程所需的步骤，包括定义Vertex AI数据集。接下来，我们将对比第10章中看到的本地模型训练和部署与使用ML流程进行模型训练和部署。然后，我们将审查ML流程本身的代码，以及更新现有代码以使模型训练代码在ML流程的上下文中工作所需的更新。最后，我们将探讨一些我们可以应用生成式AI并在创建ML流程的工作流程中获得有用帮助的方法。本章中描述的代码可在[https://mng.bz/DM4n](https://mng.bz/DM4n)找到。
- en: 11.1 Introduction to ML pipelines
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.1 机器学习流程简介
- en: 'Consider the steps that we have covered so far in this book to prepare a deep
    learning model trained on tabular data:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到本书中我们已经涵盖的步骤来准备一个基于表格数据的深度学习模型：
- en: Process the data to deal with problems such as missing values, columns containing
    two distinct kinds of data, and numeric data expressed as strings
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理数据以解决诸如缺失值、包含两种不同类型数据列和以字符串表示的数值数据等问题
- en: Train the model using the processed data
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用处理后的数据训练模型
- en: Deploy the trained model so that it can be used by an application
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将训练好的模型部署以便应用程序可以使用
- en: Suppose we needed to go through this process repeatedly for the Kuala Lumpur
    real estate problem. This is a reasonable expectation because the real estate
    market will keep changing as prices develop, interest rates change, and macroeconomic
    factors affect the demand for real estate. Rather than running the various notebooks
    and deployment steps manually for each end-to-end cycle from raw data to deployed
    model, it would be better to have a coded solution that we could run as a unit
    repeatedly and consistently. An ML pipeline gives us this exactly, and in this
    section, we will go through an example illustrating how to set up a simple, end-to-end
    pipeline for the Kuala Lumpur real estate problem.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们需要反复进行这个过程来解决吉隆坡房地产问题。这是一个合理的预期，因为房地产市场会随着价格发展、利率变化和宏观经济因素影响房地产需求而不断变化。与其为从原始数据到部署模型的每个端到端周期手动运行各种笔记本和部署步骤，不如有一个可以作为一个单元反复和一致运行的编码解决方案。一个机器学习流程正好提供了这个功能，在本节中，我们将通过一个示例来说明如何为吉隆坡房地产问题设置一个简单、端到端的流程。
- en: 11.1.1 Three kinds of pipelines
  id: totrans-15
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.1.1 三种类型的流程
- en: 'Before getting into the details of an ML pipeline, it is worth noting that
    the term *pipeline* has been overloaded with different meanings over time. At
    the moment, there are at least three distinct meanings for the term *pipeline*
    that are predominant in the world of ML/data science:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解ML管道的细节之前，值得注意的是，术语“管道”随着时间的推移被赋予了不同的含义。目前，在ML/数据科学领域，至少有三个不同的“管道”含义占主导地位：
- en: '*Training/inference pipeline*—This pipeline ensures that data transformations,
    such as assigning text to tokens or assigning values in a categorical column to
    numeric identifiers, are done consistently in the training and inference steps.
    The preprocessing Keras layers in the Kuala Lumpur model constitute this kind
    of pipeline because they ensure, for example, that the transformations done on
    the processed data prior to training exactly match the transformations done on
    the data points entered in `home.html` in the web deployment.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*训练/推理管道*——这个管道确保数据转换，如将文本分配给标记或将分类列中的值分配给数值标识符，在训练和推理步骤中是一致的。吉隆坡模型中的预处理Keras层构成了这种类型的管道，因为它们确保，例如，在训练之前对处理过的数据进行的转换与在Web部署中`home.html`中输入的数据点进行的转换完全匹配。'
- en: '*Data pipeline*—This pipeline deals with anomalies in the input training data,
    such as missing values or schema problems. It can overlap the pipeline described
    in the previous point, but it performs a distinct task. In the context of Google
    Cloud, Dataflow and Cloud Data Fusion are examples of products that can perform
    data pipeline tasks. You don’t need to know about Dataflow or Cloud Data Fusion
    for the purposes of this chapter, but if you are curious, you can check out the
    documentation: [https://cloud.google.com/dataflow/docs](https://cloud.google.com/dataflow/docs)
    and [https://cloud.google.com/data-fusion/docs](https://cloud.google.com/data-fusion/docs).'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据管道*——这个管道处理输入训练数据中的异常，如缺失值或模式问题。它可以与前面提到的管道重叠，但它执行一个不同的任务。在Google Cloud的上下文中，Dataflow和Cloud
    Data Fusion是能够执行数据管道任务的产品的例子。在本章的目的上，您不需要了解Dataflow或Cloud Data Fusion，但如果您好奇，可以查看文档：[https://cloud.google.com/dataflow/docs](https://cloud.google.com/dataflow/docs)
    和 [https://cloud.google.com/data-fusion/docs](https://cloud.google.com/data-fusion/docs)。'
- en: '*ML pipeline*—This is a pipeline that automates various steps such as training,
    deploying, and monitoring the model. TFX and KubeFlow are the two approaches that
    are available in Vertex AI for implementing ML pipelines.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ML管道*——这是一种自动化各种步骤的管道，例如训练、部署和监控模型。TFX和KubeFlow是Vertex AI中用于实现ML管道的两种方法。'
- en: Figure 11.1 shows how each of these three kinds of pipelines fits into the end-to-end
    ML workflow.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1展示了这三种类型的管道如何适应端到端ML工作流程。
- en: '![](../Images/CH11_F01_Ryan2.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F01_Ryan2.png)'
- en: Figure 11.1 Three kinds of pipelines and how they relate
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1 三种管道及其关系
- en: 'Figure 11.1 illustrates the following characteristics of the pipelines:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1说明了管道的以下特征：
- en: The ML pipeline can encompass the entire workflow, from raw data to monitoring
    the deployed model. The rationale for this is that the ML pipeline is intended
    to automate the complete process when the model needs to be retrained and redeployed.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习（ML）管道可以涵盖整个工作流程，从原始数据到监控部署的模型。这样做的原因是，ML管道旨在在模型需要重新训练和重新部署时自动化整个流程。
- en: The distinction between a data pipeline and a training/inference pipeline is
    that the training/inference pipeline handles transformations that need to be applied
    to new data points to which we want to apply the trained model to get predictions,
    such as replacing categorical values with numeric identifiers. The same transformations
    need to be applied to the prepared data prior to training the model.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据管道与训练/推理管道的区别在于，训练/推理管道处理需要对新数据点应用以应用训练模型进行预测的转换，例如将分类值替换为数值标识符。在训练模型之前，必须对准备好的数据应用相同的转换。
- en: As we saw in the Keras custom layers solution to the Airbnb NYC price prediction
    problem in chapter 3, the training/inference pipeline can be distinct from the
    model training process. In the Keras customer layers solution, the training/inference
    pipeline was implemented using Scikit-learn pipeline structures and custom classes,
    both of which need to be applied to data prior to model training and prior to
    applying new data points to the trained model to get predictions. In chapter 9,
    on the other hand, we saw how the same processing could be incorporated directly
    into the Keras model.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正如我们在第3章中解决Airbnb纽约市价格预测问题的Keras自定义层解决方案中看到的那样，训练/推理管道可以与模型训练过程分开。在Keras自定义层解决方案中，训练/推理管道是通过Scikit-learn管道结构和自定义类实现的，这两个都需要在模型训练之前以及在新数据点应用于训练模型以获取预测之前应用于数据。另一方面，在第9章中，我们看到了如何将相同的处理直接集成到Keras模型中。
- en: Data pipelines can exist outside the context of the ML workflow. The same data
    pipeline tools, such as Dataflow and Cloud Data Fusion, that can be used in ML
    workflows in Google Cloud can be part of applications that don’t include ML.
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据管道可以存在于机器学习工作流程之外。在Google Cloud中用于机器学习工作流程的相同数据管道工具，如Dataflow和Cloud Data Fusion，也可以是包含机器学习的应用程序的一部分。
- en: Now that we have described three different kinds of pipelines, in the next section,
    we will start to explore how to create an ML pipeline for the Kuala Lumpur real
    estate price prediction problem in Google Cloud using Kubeflow.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经描述了三种不同类型的管道，在下一节中，我们将开始探讨如何在Google Cloud中使用Kubeflow创建一个针对吉隆坡房地产价格预测问题的机器学习管道。
- en: 11.1.2 Overview of Vertex AI ML pipelines
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.1.2 Vertex AI ML管道概述
- en: In chapter 10, we went through the process of deploying the Kuala Lumpur real
    estate price prediction model to a Vertex AI endpoint.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在第10章中，我们介绍了将吉隆坡房地产价格预测模型部署到Vertex AI端点的过程。
- en: 'To create an ML pipeline for the Kuala Lumpur price prediction model, we are
    going to start with the steps described in the Vertex AI documentation: [https://mng.bz/lYW6](https://mng.bz/lYW6).'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个针对吉隆坡价格预测模型的机器学习管道，我们将从Vertex AI文档中描述的步骤开始：[https://mng.bz/lYW6](https://mng.bz/lYW6)。
- en: 'The following is an overview of the steps:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个步骤概述：
- en: 'Set up a *service account*. A service account is an account used by an application
    to take actions in Google Cloud. When we imported the Keras model into Google
    Cloud and deployed it to an endpoint, we used our own ID to perform these actions.
    Since the ML pipeline will be an automated script, we need a service account to
    allow the script to perform actions without depending directly on manual intervention
    from any individual. See the Google Cloud documentation for more details on service
    accounts: [https://mng.bz/BXA0](https://mng.bz/BXA0).'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置一个*服务帐户*。服务帐户是一个应用程序用于在Google Cloud中执行操作所使用的帐户。当我们将Keras模型导入Google Cloud并部署到端点时，我们使用自己的ID来执行这些操作。由于机器学习管道将是一个自动化脚本，我们需要一个服务帐户来允许脚本在没有直接依赖任何个人的手动干预的情况下执行操作。有关服务帐户的更多详细信息，请参阅Google
    Cloud文档：[https://mng.bz/BXA0](https://mng.bz/BXA0)。
- en: Get a service account key for the service account and provide the service account
    with the required access to run the ML pipeline.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取服务帐户密钥，并为服务帐户提供运行机器学习管道所需的访问权限。
- en: Create a pipeline script to invoke the Vertex AI SDK.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个管道脚本来调用Vertex AI SDK。
- en: Adapt the model training notebook to be a standalone Python script that can
    be run in a prebuilt Vertex AI container.
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将模型训练笔记本调整为独立的Python脚本，以便在预构建的Vertex AI容器中运行。
- en: Run the pipeline script to run the training script inside a container and generate
    a trained model.
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行管道脚本来在容器中运行训练脚本并生成训练好的模型。
- en: In the subsequent sections, we will go through these steps to create an ML pipeline
    for the Kuala Lumpur real estate prediction model.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将逐步介绍如何为吉隆坡房地产预测模型创建一个机器学习（ML）管道。
- en: 11.2 ML pipeline preparation steps
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.2 ML管道准备步骤
- en: Before we can run the ML pipeline to train and deploy a model, we need to set
    up the Google Cloud objects the pipeline needs. In this section, we will set up
    a service account and introduce the Cloud Shell, an instance that is available
    directly in Google Cloud that we can use to enter commands. We will also upload
    our dataset to Google Cloud Storage and use the uploaded dataset to create a Vertex
    AI dataset.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们可以运行机器学习管道来训练和部署模型之前，我们需要设置管道所需的Google Cloud对象。在本节中，我们将设置一个服务帐户并介绍Cloud Shell，这是一个直接在Google
    Cloud中可用的实例，我们可以使用它来输入命令。我们还将上传我们的数据集到Google Cloud Storage，并使用上传的数据集创建一个Vertex
    AI数据集。
- en: 11.2.1 Creating a service account for the ML pipeline
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2.1 为ML管道创建服务账户
- en: Since we want to be able to run the ML pipeline automatically without manual
    intervention, we need to set up a service account to run the pipeline.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们希望能够在没有人工干预的情况下自动运行ML管道，我们需要设置一个服务账户来运行管道。
- en: 'To create a service account, follow these steps:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个服务账户，请按照以下步骤操作：
- en: 1.  Select IAM & Admin -> Service Accounts from the overall Google Cloud Console
    menu, as shown in figure 11.2.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 从整体Google Cloud控制台菜单中选择“IAM & Admin”->“服务账户”，如图11.2所示。
- en: '![](../Images/CH11_F02_Ryan2.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F02_Ryan2.png)'
- en: Figure 11.2 Selecting Service Accounts in the Google Cloud Console
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.2 在Google Cloud控制台中选择服务账户
- en: 2.  In the Service Accounts page, select Create Service Account, as shown in
    figure 11.3.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 在“服务账户”页面，选择“创建服务账户”，如图11.3所示。
- en: '![](../Images/CH11_F03_Ryan2.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F03_Ryan2.png)'
- en: Figure 11.3 Creating a service account
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.3 创建服务账户
- en: '3.  In the Create service account page, enter a name for the service account
    and click Create and Continue, as shown in figure 11.4\. Note that the service
    account ID gets filled in automatically and that an email ID for the service account
    is shown in the form `service-account-id@project-id.iam.gserviceaccount.com`—in
    this case: `ml-tabular-pipeline@first-project-ml-tabular.iam.gserviceaccount.com`'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 3. 在“创建服务账户”页面，输入服务账户的名称，然后点击“创建并继续”，如图11.4所示。请注意，服务账户ID会自动填写，并且服务账户的电子邮件ID以`service-account-id@project-id.iam.gserviceaccount.com`的形式显示——在本例中：`ml-tabular-pipeline@first-project-ml-tabular.iam.gserviceaccount.com`
- en: '![](../Images/CH11_F04_Ryan2.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F04_Ryan2.png)'
- en: Figure 11.4 Setting a service account name
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.4 设置服务账户名称
- en: 4.  Select Vertex AI User in the Role field and click Done, as shown in figure
    11.5.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 4. 在“角色”字段中选择“Vertex AI用户”，然后点击“完成”，如图11.5所示。
- en: '![](../Images/CH11_F05_Ryan2.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F05_Ryan2.png)'
- en: Figure 11.5 Giving the service account Vertex AI user role
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5 授予服务账户Vertex AI用户角色
- en: Now that we have created a service account and given it access to Vertex AI,
    in the next section we can create a service account key.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了一个服务账户并授予它对Vertex AI的访问权限，在下一节中我们可以创建一个服务账户密钥。
- en: 11.2.2 Creating a service account key
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2.2 创建服务账户密钥
- en: The ML pipeline uses a service account key to authenticate the service account
    used to run the ML pipeline.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: ML管道使用服务账户密钥来验证用于运行ML管道的服务账户。
- en: 'To create a service account key, follow these steps:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建服务账户密钥，请按照以下步骤操作：
- en: 1.  In the Service accounts page, click on the email address for the service
    account that you just created, as shown in figure 11.6.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 在“服务账户”页面，点击如图11.6所示的刚刚创建的服务账户的电子邮件地址。
- en: '![](../Images/CH11_F06_Ryan2.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F06_Ryan2.png)'
- en: Figure 11.6 Selecting the service account
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.6 选择服务账户
- en: 2.  Select the Keys tab and click Add key -> Create new key, as shown in figure
    11.7.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 选择“密钥”选项卡，然后点击“添加密钥”->“创建新密钥”，如图11.7所示。
- en: '![](../Images/CH11_F07_Ryan2.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F07_Ryan2.png)'
- en: Figure 11.7 Creating a service account key
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.7 创建服务账户密钥
- en: 3.  Select JSON and click Create, as shown in figure 11.8.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 3. 选择“JSON”，然后点击“创建”，如图11.8所示。
- en: '![](../Images/CH11_F08_Ryan2.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F08_Ryan2.png)'
- en: Figure 11.8 Downloading the service account key
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.8 下载服务账户密钥
- en: 'A JSON file containing the service account key is created and downloaded to
    your local system with a name that looks like: `first-project-ml-tabular-039ff1f820a8.json`.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 创建了一个包含服务账户密钥的JSON文件，并将其以类似`first-project-ml-tabular-039ff1f820a8.json`的名称下载到您的本地系统。
- en: 11.2.3 Granting the service account access to the Compute Engine default service
    account
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2.3 授予服务账户对Compute Engine默认服务账户的访问权限
- en: When you set up your project in Google Cloud, a Compute Engine default service
    account was created. This account has an email address like `PROJECT_NUMBER-compute@developer.gserviceaccount.com`.
    For more details on the Compute Engine default service account, see the documentation
    ([https://mng.bz/dXdN](https://mng.bz/dXdN)).
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在Google Cloud中设置你的项目时，会自动创建一个Compute Engine默认服务账户。此账户有一个类似`PROJECT_NUMBER-compute@developer.gserviceaccount.com`的电子邮件地址。有关Compute
    Engine默认服务账户的更多详细信息，请参阅文档（[https://mng.bz/dXdN](https://mng.bz/dXdN)）。
- en: 'We need to give the service account that we set up in the preceding sections
    access to the Compute Engine default service account to run the ML pipeline. Follow
    these steps to set up this access to the Compute Engine default service account:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要给在前几节中设置的服务账户访问Compute Engine默认服务账户的权限来运行ML管道。按照以下步骤设置对此Compute Engine默认服务账户的访问权限：
- en: 1.  In the Service accounts page, click the copy icon beside the email address
    for the service account you just created (you will need this in the next step)
    and then click the email address of the Compute Engine default service account,
    as shown in figure 11.9.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 在“服务帐户”页面，点击您刚刚创建的服务帐户旁边的复制图标（您将在下一步需要它），然后点击Compute Engine默认服务帐户的电子邮件地址，如图11.9所示。
- en: '![](../Images/CH11_F09_Ryan2.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F09_Ryan2.png)'
- en: Figure 11.9 Compute Engine default service account
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.9 Compute Engine默认服务帐户
- en: 2.  Click the Permissions tab and click Grant Access, as shown in figure 11.10.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 点击“权限”选项卡，然后点击“授予访问权限”，如图11.10所示。
- en: '![](../Images/CH11_F10_Ryan2.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F10_Ryan2.png)'
- en: Figure 11.10 Granting access to the Compute Engine default service account
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.10 授予Compute Engine默认服务帐户访问权限
- en: 3.  In the Grant access page, paste the email ID of the service account that
    you created in the New Principals field, select Service Account User in the Role
    field, and click Save, as shown in figure 11.11.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 3. 在“授予访问权限”页面，将您在“新主体”字段中创建的服务帐户的电子邮件ID粘贴到其中，在“角色”字段中选择“服务帐户用户”，然后点击“保存”，如图11.11所示。
- en: '![](../Images/CH11_F11_Ryan2.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F11_Ryan2.png)'
- en: Figure 11.11 Specifying access to the Compute Engine default service account
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.11 指定对Compute Engine默认服务帐户的访问权限
- en: Now that we have completed the steps to set up the service account for the ML
    pipeline, we can continue with the setup of the pipeline.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了设置ML管道服务帐户的步骤，我们可以继续设置管道。
- en: 11.2.4 Introduction to Cloud Shell
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2.4 Cloud Shell简介
- en: 'So far, all the actions that we have taken in Google Cloud have been in the
    Console UI. Google Cloud also includes the Cloud Shell, which is a self-contained
    instance that lets you run command line commands to interact with Google Cloud.
    In addition to the command line interface, you can use the Cloud Shell Editor
    to edit files in the Cloud Shell filesystem. With Cloud Shell, you get the function
    of a local Linux instance combined with the convenience of a web-based environment
    that is integrated with Google Cloud resources. Cloud Shell is particularly well-suited
    for prototyping and working through tutorials. We will use the Cloud Shell in
    the next few steps of setting up the ML pipeline. For additional details about
    Cloud Shell, see the documentation: [https://cloud.google.com/shell](https://cloud.google.com/shell).'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们在Google Cloud中采取的所有操作都是在控制台UI中进行的。Google Cloud还包括Cloud Shell，这是一个自包含的实例，允许您运行命令行命令以与Google
    Cloud交互。除了命令行界面外，您还可以使用Cloud Shell编辑器编辑Cloud Shell文件系统中的文件。使用Cloud Shell，您将获得本地Linux实例的功能，同时结合了与Google
    Cloud资源集成的基于Web的环境的便利性。Cloud Shell特别适合原型设计和完成教程。我们将使用Cloud Shell在设置ML管道的下一步中。有关Cloud
    Shell的更多详细信息，请参阅文档：[https://cloud.google.com/shell](https://cloud.google.com/shell)。
- en: To start the Cloud Shell, click on the Activate Cloud Shell icon at the top
    of the Google Cloud Console, as shown in figure 11.12.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动Cloud Shell，请点击Google Cloud控制台顶部的“激活Cloud Shell”图标，如图11.12所示。
- en: '![](../Images/CH11_F12_Ryan2.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F12_Ryan2.png)'
- en: Figure 11.12 Activating Cloud Shell icon
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.12 激活Cloud Shell图标
- en: When you click on the Activate Cloud Shell icon, the Cloud Shell terminal opens
    at the bottom of the console with your home directory as the current directory,
    as shown in figure 11.13.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 当您点击激活Cloud Shell图标时，Cloud Shell终端将在控制台底部打开，您的家目录作为当前目录，如图11.13所示。
- en: '![](../Images/CH11_F13_Ryan2.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F13_Ryan2.png)'
- en: Figure 11.13 Cloud Console with Cloud Shell activated
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.13 Cloud Console已激活Cloud Shell
- en: You can run commands directly in the Cloud Shell Terminal, including standard
    Linux commands and Google Cloud-specific commands. You can click Open Editor to
    edit files in the Cloud Shell file system, as shown in figure 11.14\. To get back
    to the Cloud Shell Terminal, click on Open Terminal.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以直接在Cloud Shell终端中运行命令，包括标准Linux命令和Google Cloud特定命令。您可以通过点击“打开编辑器”来编辑Cloud
    Shell文件系统中的文件，如图11.14所示。要返回Cloud Shell终端，请点击“打开终端”。
- en: '![](../Images/CH11_F14_Ryan2.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F14_Ryan2.png)'
- en: Figure 11.14 Cloud Shell Editor
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.14 Cloud Shell编辑器
- en: 'Now that we have taken a brief tour of the Cloud Shell, we can continue with
    the next step of setting up the ML pipeline: making the service account key available
    to the pipeline.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经简要了解了Cloud Shell，我们可以继续下一步设置ML管道：使服务帐户密钥对管道可用。
- en: 11.2.5 Uploading the service account key
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2.5 上传服务帐户密钥
- en: 'In this section, we will use the Cloud Shell to upload the service account
    key JSON file and then set an environment variable to point to the location of
    the service account key:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用 Cloud Shell 上传服务账户密钥 JSON 文件，然后设置一个环境变量以指向服务账户密钥的位置：
- en: '1.  In Cloud Shell, set your home directory as the current directory, create
    a new directory called `ml_pipeline`, and then set that new directory as your
    current directory:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 在 Cloud Shell 中，将您的家目录设置为当前目录，创建一个名为 `ml_pipeline` 的新目录，然后将该新目录设置为当前目录：
- en: '[PRE0]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 2.  To upload the service account key, select the three dots in the Cloud Shell
    toolbar and select Upload, as shown in figure 11.15.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 要上传服务账户密钥，选择 Cloud Shell 工具栏中的三个点，然后选择上传，如图 11.15 所示。
- en: '![](../Images/CH11_F15_Ryan2.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F15_Ryan2.png)'
- en: Figure 11.15 Uploading a file in Cloud Shell
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.15 在 Cloud Shell 中上传文件
- en: 3.  In the Upload page, update Destination Directory to be the `ml_pipeline`
    directory in your home directory, click Choose Files, and select the service account
    key JSON file that you downloaded in section 11.2.2 and click Upload, as shown
    in figure 11.16.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 3. 在上传页面，将目标目录更新为您的家目录中的 `ml_pipeline` 目录，点击选择文件，并选择您在 11.2.2 节中下载的服务账户密钥 JSON
    文件，然后点击上传，如图 11.16 所示。
- en: '![](../Images/CH11_F16_Ryan2.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F16_Ryan2.png)'
- en: Figure 11.16 Setting upload parameters
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.16 设置上传参数
- en: '4.  Validate the upload by making `~/ml_pipeline` your current directory and
    using the `ls` command to ensure that the JSON service account key is now in this
    directory:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 4. 通过将 `~/ml_pipeline` 设置为当前目录，并使用 `ls` 命令确保 JSON 服务账户密钥现在位于此目录中，来验证上传：
- en: '[PRE1]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '5.  Set the environment variable `GOOGLE_APPLICATION_CREDENTIALS` to the fully
    qualified filename of the service account key JSON file. In the following example,
    replace the fully qualified filename with that for your own service account key
    JSON file:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 5. 将环境变量 `GOOGLE_APPLICATION_CREDENTIALS` 设置为服务账户密钥 JSON 文件的完整文件名。在以下示例中，将完整文件名替换为您自己的服务账户密钥
    JSON 文件名：
- en: '[PRE2]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '6.  Confirm the value of the `GOOGLE_APPLICATION_CREDENTIALS` environment variable
    with the following command and validate that it is set to the fully qualified
    path of your service account key file:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 6. 使用以下命令确认 `GOOGLE_APPLICATION_CREDENTIALS` 环境变量的值，并验证它是否设置为您的服务账户密钥文件的完整路径：
- en: '[PRE3]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Now that we have uploaded the service account key and set the environment variable
    to point to the location of the service account key, we are ready to get into
    the key step of defining the ML pipeline.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经上传了服务账户密钥并设置了环境变量以指向服务账户密钥的位置，我们就可以进入定义 ML 流程的关键步骤了。
- en: 11.2.6 Uploading the cleaned-up dataset to a Google Cloud Storage bucket
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2.6 将清洗后的数据集上传到 Google Cloud Storage 存储桶
- en: 'To simplify the pipeline, we will upload the processed dataset generated by
    the data preparation notebook ([https://mng.bz/rKjB](https://mng.bz/rKjB)) to
    a Cloud Storage bucket so that it is accessible to the rest of the ML pipeline.
    In a real-world application, we would incorporate the data cleanup steps into
    the ML pipeline, but for the sake of simplicity, we will start the pipeline with
    the data already cleaned up. Follow the steps in this section to upload the cleaned-up
    dataset to Google Cloud Storage:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化流程，我们将上传由数据准备笔记本生成的处理后的数据集到 Cloud Storage 存储桶，以便其余的 ML 流程可以访问。在实际应用中，我们会将数据清理步骤集成到
    ML 流程中，但为了简化，我们将从已经清理好的数据开始流程。按照本节中的步骤上传清洗后的数据集到 Google Cloud Storage：
- en: 1.  Upload the CSV version of the cleaned-up dataset to the same bucket that
    you created to upload the model.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 将清洗后的数据集的 CSV 版本上传到您创建用于上传模型的同一个存储桶。
- en: 2.  From the Google Cloud Console main menu, select Cloud Storage -> Buckets,
    as shown in figure 11.17.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 从 Google Cloud Console 主菜单中选择 Cloud Storage -> 存储桶，如图 11.17 所示。
- en: '![](../Images/CH11_F17_Ryan2.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F17_Ryan2.png)'
- en: Figure 11.17 Setting upload parameters
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.17 设置上传参数
- en: 3.  In the Buckets page, select the bucket you created in chapter 10 to contain
    the trained model. In the Bucket details page, select Create Folder, as shown
    in figure 11.18.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 3. 在存储桶页面，选择您在第 10 章中创建的存储桶以包含训练模型。在存储桶详细信息页面，选择创建文件夹，如图 11.18 所示。
- en: '![](../Images/CH11_F18_Ryan2.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F18_Ryan2.png)'
- en: Figure 11.18 Creating a folder
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.18 创建文件夹
- en: 4.  Enter `processed_dataset` in the name field and click Create.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 4. 在名称字段中输入 `processed_dataset` 并点击创建。
- en: 5.  Select the new folder that you just created, as shown in figure 11.19.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 5. 选择您刚刚创建的新文件夹，如图 11.19 所示。
- en: '![](../Images/CH11_F19_Ryan2.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/CH11_F19_Ryan2.png)'
- en: Figure 11.19 Selecting the folder
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.19 选择文件夹
- en: 6.  Click Upload Files and select the CSV file containing the processed version
    of the Kuala Lumpur dataset (output of the data preparation notebook).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 6. 点击上传文件并选择包含吉隆坡数据集处理版本的 CSV 文件（数据准备笔记本的输出）。
- en: 7.  You will see the file in the Bucket details page when the upload is complete.
    Click the three dots, then Copy gsutil URI, as shown in figure 11.20.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 7. 当上传完成时，你将在存储桶详细信息页面中看到该文件。点击三个点，然后复制 gsutil URI，如图 11.20 所示。
- en: '![](../Images/CH11_F20_Ryan2.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/CH11_F20_Ryan2.png)'
- en: Figure 11.20 Copying gsutil URI
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.20 复制 gsutil URI
- en: 'The gsutil Uniform Resource Identifer (URI) value will look like this: `gs://first-project-ml-tabular-bucket/processed_dataset/kl_real_estate_output.csv`'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: gsutil 统一资源标识符 (URI) 值将如下所示：`gs://first-project-ml-tabular-bucket/processed_dataset/kl_real_estate_output.csv`
- en: Now that we have uploaded the cleaned-up dataset to a Google Cloud Storage bucket,
    we can use it to create a Vertex AI dataset.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将清洗后的数据集上传到 Google Cloud Storage 存储桶中，我们可以用它来创建一个 Vertex AI 数据集。
- en: 11.2.7 Creating a Vertex AI managed dataset
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.2.7 创建 Vertex AI 管理数据集
- en: 'The ML pipeline invokes the Vertex AI SDK to train the model; it identifies
    the dataset used to train the model as a Vertex AI managed dataset. To learn more
    about Vertex AI managed datasets, see the documentation: [https://mng.bz/VVRP](https://mng.bz/VVRP).'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习管道调用 Vertex AI SDK 来训练模型；它将用于训练模型的数据库识别为 Vertex AI 管理数据集。要了解更多关于 Vertex
    AI 管理数据集的信息，请参阅文档：[https://mng.bz/VVRP](https://mng.bz/VVRP)。
- en: 'The Vertex AI SDK automatically does the following to make the managed dataset
    available to the training script:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex AI SDK 自动执行以下操作，使管理数据集可供训练脚本使用：
- en: Copies the content of the dataset to Cloud Storage.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据集的内容复制到云存储。
- en: Divides the dataset into training, validation, and testing subsets. The proportion
    of the dataset for each subset is set in the pipeline config file `pipeline_config.yml`,
    as shown in figure 11.2.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据集划分为训练、验证和测试子集。每个子集的数据集比例在管道配置文件 `pipeline_config.yml` 中设置，如图 11.2 所示。
- en: '![](../Images/CH11_F21_Ryan2.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/CH11_F21_Ryan2.png)'
- en: Figure 11.21 Proportions for train, validation, and test in the pipeline configuration
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.21 管道配置中的训练、验证和测试比例
- en: Divides each of the subsets into multiple CSV files. Figure 11.22 shows an example
    of what the CSV files for the dataset look like in Cloud Storage.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将每个子集划分为多个 CSV 文件。图 11.22 展示了数据集在云存储中 CSV 文件的一个示例。
- en: '![](../Images/CH11_F22_Ryan2.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/CH11_F22_Ryan2.png)'
- en: Figure 11.22 Processed dataset in Google Cloud Storage
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.22 Google Cloud Storage 中的处理后的数据集
- en: Now that we have seen how the dataset gets set up in Cloud Storage, let’s go
    through the steps to create a Vertex AI dataset for the training data.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了数据集在云存储中的设置过程，让我们来了解一下创建用于训练数据的 Vertex AI 数据集的步骤。
- en: 1.  In Vertex AI, select Datasets. In the Datasets page, click Create as shown
    in figure 11.23.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 在 Vertex AI 中选择“数据集”。在数据集页面，点击创建，如图 11.23 所示。
- en: '![](../Images/CH11_F23_Ryan2.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/CH11_F23_Ryan2.png)'
- en: Figure 11.23 Creating a dataset
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.23 创建数据集
- en: 2.  In the Create dataset page, set `kuala-lumpur-real-estate` as the dataset
    name, select the Tabular tab, select Regression/Classification, and click Create,
    as shown in figure 11.24.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 在创建数据集页面，将 `kuala-lumpur-real-estate` 设置为数据集名称，选择表格选项卡，选择回归/分类，然后点击创建，如图
    11.24 所示。
- en: '![](../Images/CH11_F24_Ryan2.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/CH11_F24_Ryan2.png)'
- en: Figure 11.24 Specifying dataset details
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.24 指定数据集详细信息
- en: 3.  In the Source tab, select Select CSV file from Cloud Storage. In Import
    file path, click Browse, select the Cloud Storage bucket location where you uploaded
    the processed training file in the previous section, and click Continue, as shown
    in figure 11.25.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 3. 在“源”选项卡中，选择从云存储选择 CSV 文件。在导入文件路径中，点击浏览，选择上一节中上传处理后的训练文件所在的云存储桶位置，然后点击继续，如图
    11.25 所示。
- en: '![](../Images/CH11_F25_Ryan2.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/CH11_F25_Ryan2.png)'
- en: Figure 11.25 Specifying the source for the dataset
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.25 指定数据集的源
- en: 4.  Note the ID value of the dataset that you just created, as shown in figure
    11.26.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 4. 注意你刚刚创建的数据集的 ID 值，如图 11.26 所示。
- en: '![](../Images/CH11_F26_Ryan2.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/CH11_F26_Ryan2.png)'
- en: Figure 11.26 Dataset ID in Google Cloud Console
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.26 Google Cloud 控制台中的数据集 ID
- en: This is the value that needs to be set for `dataset_id` in the pipeline config
    file `pipeline_config.yml`, as shown in figure 11.27.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这是需要在管道配置文件 `pipeline_config.yml` 中设置的 `dataset_id` 的值，如图 11.27 所示。
- en: '![](../Images/CH11_F27_Ryan2.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![图像](../Images/CH11_F27_Ryan2.png)'
- en: Figure 11.27 `dataset_id` in the pipeline config file
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.27 管道配置文件中的`dataset_id`
- en: Congratulations! You have set up a Vertex AI managed dataset for the dataset
    that the model training portion of the ML pipeline will use to train the model.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！您已经为机器学习管道中模型训练部分将用于训练模型的那个数据集设置了Vertex AI托管数据集。
- en: 11.3 Defining the ML pipeline
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11.3 定义机器学习管道
- en: 'So far in this chapter, we have completed the following preparation steps for
    the ML pipeline:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本章中，我们已经完成了以下机器学习管道的准备工作：
- en: 1.  Created a service account and a service account key
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 创建了一个服务账户和服务账户密钥
- en: 2.  Uploaded the service account key to the directory where we will run the
    pipeline script
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 2. 将服务账户密钥上传到我们将运行管道脚本的目录
- en: 3.  Uploaded the cleaned-up dataset to Cloud Storage
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 3. 将清理后的数据集上传到云存储
- en: 4.  Created a Vertex AI-managed dataset from the cleaned-up dataset
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 4. 从清理后的数据集中创建了一个Vertex AI管理的数据集
- en: In this section, we will take the elements we prepared in the preceding section
    and use them to create an ML pipeline that takes in a preprocessed dataset at
    one end and produces a trained model deployed with a Vertex AI endpoint at the
    other end.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用上一节中准备好的元素来创建一个机器学习管道，该管道在一端接收预处理后的数据集，并在另一端通过Vertex AI端点部署训练好的模型。
- en: 11.3.1 Local implementation vs. ML pipeline
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.1 本地实现与机器学习管道
- en: Before we continue with defining the ML pipeline, let’s contrast the ML pipeline
    with the local setup to train the Kuala Lumpur real estate price prediction model
    that we implemented in chapter 10\. Figure 11.28 shows this contrast and highlights
    some of the differences between the two implementations.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们继续定义机器学习管道之前，让我们将机器学习管道与本地设置进行对比，以训练我们在第10章中实现的吉隆坡房地产价格预测模型。图11.28显示了这种对比并突出了两种实现之间的差异。
- en: '![](../Images/CH11_F28_Ryan2.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F28_Ryan2.png)'
- en: Figure 11.28 Training on a local system vs. training with an ML pipeline
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.28 在本地系统上训练与使用机器学习管道训练
- en: Figure 11.28 contrasts the structure of the training process for an entirely
    local implementation compared to the training process using an ML pipeline. The
    key ways that the ML pipeline implementation differs from the local system implementation
    of the solution are
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.28对比了完全本地实现与使用机器学习管道的训练过程的结构。机器学习管道实现与本地系统实现解决方案的关键区别在于
- en: The data cleanup process is identical. In a real-world production pipeline,
    we would move this data processing step into the Vertex AI environment and make
    it part of the ML pipeline, but to make the ML pipeline as simple as possible,
    we skip that step for our ML pipeline implementation and start the pipeline with
    the cleaned-up dataset.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据清理过程是相同的。在现实世界的生产管道中，我们会将这个数据处理步骤移动到Vertex AI环境中，并使其成为机器学习管道的一部分，但为了使机器学习管道尽可能简单，我们在我们的机器学习管道实现中跳过这一步骤，并从清理后的数据集开始管道。
- en: In the local implementation, the data cleanup process output is a pickle file.
    To avoid compatibility problems, we switched to a CSV file for the ML pipeline.
    The ML pipeline takes the contents of this CSV file and splits them into train,
    validation, and test subsets, each of which is segmented into multiple CSV files
    in Cloud Storage.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本地实现中，数据清理过程的输出是一个pickle文件。为了避免兼容性问题，我们切换到CSV文件用于机器学习管道。机器学习管道将这个CSV文件的内容分割成训练、验证和测试子集，每个子集在云存储中分割成多个CSV文件。
- en: The training code in the ML pipeline implementation is in a Python `.py` file
    (the *model training script*) rather than a notebook. Significant updates to the
    training code to make it work in a container environment are described in the
    following section.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习管道实现中的训练代码在一个Python `.py` 文件（*模型训练脚本*）中，而不是笔记本中。在下一节中描述了为了使其在容器环境中工作而对训练代码进行的重大更新。
- en: In the ML pipeline implementation, the model training config file is in Cloud
    Storage so that its location can be shared by the pipeline script as a parameter
    for the model training script.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在机器学习管道实现中，模型训练配置文件位于云存储中，这样管道脚本就可以将其位置作为参数与模型训练脚本共享。
- en: The pipeline script is a new component in the ML pipeline. This script sets
    up the input necessary for the model training script, uses the Vertex AI SDK to
    create a container for the model training script, and invokes the script to do
    the model training.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管道脚本是在机器学习管道中的新组件。此脚本设置模型训练脚本所需的输入，使用Vertex AI SDK为模型训练脚本创建一个容器，并调用脚本进行模型训练。
- en: The pipeline config file is a new component in the ML pipeline. This config
    file contains parameters for the pipeline script, including the built-in Vertex
    AI containers to use for the ML pipeline; the proportion of the cleaned-up dataset
    for each of the training, validation, and testing subsets; the dataset ID; and
    the location of the code for the training script.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管道配置文件是 ML 管道中的新组件。此配置文件包含管道脚本的参数，包括用于 ML 管道的内置 Vertex AI 容器；每个训练、验证和测试子集的清理数据集比例；数据集
    ID；以及训练脚本代码的位置。
- en: The trained model is automatically put in the model registry in the ML pipeline
    implementation and deployed to a Vertex AI endpoint. In the local system implementation,
    we manually uploaded the model to Cloud Storage and then deployed it to an endpoint.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练好的模型会自动放入 ML 管道实现中的模型注册库，并部署到 Vertex AI 端点。在本地系统实现中，我们手动将模型上传到云存储，然后部署到端点。
- en: The endpoint that is the result of both the local system implementation and
    the ML pipeline implementation can be plugged into our web deployment simply by
    updating the `endpoint_id` parameter in the Flask server config file, as shown
    in figure 11.29.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 端点即本地系统实现和机器学习（ML）管道实现的结果，可以通过更新 Flask 服务器配置文件中的 `endpoint_id` 参数简单地插入到我们的网络部署中，如图
    11.29 所示。
- en: '![](../Images/CH11_F29_Ryan2.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F29_Ryan2.png)'
- en: Figure 11.29 Web deployment with endpoint from local or ML pipeline
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.29 使用本地或 ML 管道端点的网络部署
- en: 'For more details on the workflow for training a custom model on Vertex AI,
    see the documentation: [https://mng.bz/xKjW](https://mng.bz/xKjW).'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 关于在 Vertex AI 上训练自定义模型的流程的更多详细信息，请参阅文档：[https://mng.bz/xKjW](https://mng.bz/xKjW)。
- en: 11.3.2 Introduction to containers
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.2 容器简介
- en: One key point of an ML pipeline in Vertex AI is using containers to make the
    model training process easy to automate and flexible. In this section, we will
    briefly introduce containers and their benefits to the ML pipeline. If you are
    already familiar with the concept of containers and Docker, you can skip this
    section.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: Vertex AI 中 ML 管道的一个关键点是使用容器使模型训练过程易于自动化和灵活。在本节中，我们将简要介绍容器及其对 ML 管道的益处。如果您已经熟悉容器和
    Docker 的概念，可以跳过本节。
- en: 'A container is a software construct that allows you to package an application
    with its dependencies so that you can run the application predictably and efficiently
    across a range of environments. Google Cloud uses Docker containers. A detailed
    description of containers is beyond the scope of this book, but we need to spend
    some time looking at them to understand why they are used for ML pipelines and
    what constraints they place on our code. For more details on containers, see the
    Docker site: [https://www.docker.com/resources/what-container/](https://www.docker.com/resources/what-container/).'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 容器是一种软件构造，允许您将应用程序及其依赖项打包在一起，以便您可以在各种环境中可预测和高效地运行应用程序。Google Cloud 使用 Docker
    容器。关于容器的详细描述超出了本书的范围，但我们需要花一些时间来了解它们为什么用于 ML 管道以及它们对我们代码施加的限制。有关容器的更多详细信息，请参阅
    Docker 网站：[https://www.docker.com/resources/what-container/](https://www.docker.com/resources/what-container/)。
- en: 11.3.3 Benefits of using containers in an ML pipeline
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.3 在 ML 管道中使用容器的优势
- en: 'Using containers to package the training code means that we don’t have to worry
    about the Python libraries that are required for the training because the container
    comes with all the required Python libraries already set up. Also, the code is
    easy to reproduce anywhere. Vertex AI provides a range of prebuilt container images
    for the most popular machine learning frameworks, including PyTorch, TensorFlow,
    and XGBoost. We use TensorFlow prebuilt containers for our ML pipeline. See the
    Vertex AI documentation for details on prebuilt containers:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 使用容器打包训练代码意味着我们不必担心训练所需的 Python 库，因为容器已经预装了所有必需的 Python 库。此外，代码在任何地方都易于重现。Vertex
    AI 为最流行的机器学习框架（包括 PyTorch、TensorFlow 和 XGBoost）提供了一系列预构建容器镜像。我们为我们的 ML 管道使用 TensorFlow
    预构建容器。有关预构建容器的详细信息，请参阅 Vertex AI 文档：
- en: '*Prebuilt containers for training custom models*—[https://mng.bz/AQ8z](https://mng.bz/AQ8z)'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*用于训练自定义模型的预构建容器*—[https://mng.bz/AQ8z](https://mng.bz/AQ8z)'
- en: '*Prebuilt containers for prediction*—[https://mng.bz/ZlRP](https://mng.bz/ZlRP)'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*用于预测的预构建容器*—[https://mng.bz/ZlRP](https://mng.bz/ZlRP)'
- en: 'If our training ends up becoming more demanding (either in terms of how quickly
    a training cycle needs to be completed or the compute resources needed to complete
    a training cycle of a given duration), we can take advantage of the containerized
    nature of the training to distribute training across multiple compute engines.
    For a simple problem like the Kuala Lumpur real estate price prediction problem,
    a single node is more than sufficient to do the training, but bigger applications
    can really benefit from distributed training. A detailed explanation of all the
    options that are available for distributed training with Vertex AI is beyond the
    scope of this book. Check out the documentation if you are interested in more
    details: [https://mng.bz/RVmK](https://mng.bz/RVmK).'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的训练最终变得更加复杂（无论是从训练周期需要完成的速度还是完成给定持续时间训练周期所需的计算资源方面），我们可以利用训练的容器化特性来将训练分布在多个计算引擎上。对于像吉隆坡房地产价格预测这样的简单问题，单个节点就足以进行训练，但更大的应用确实可以从分布式训练中受益。关于使用
    Vertex AI 进行分布式训练的所有可用选项的详细解释超出了本书的范围。如果您想了解更多细节，请查看文档：[https://mng.bz/RVmK](https://mng.bz/RVmK)。
- en: 11.3.4 Introduction to adapting code to run in a container
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.4 容器中运行代码的介绍
- en: Now that we have reviewed some of the benefits of using containers for the training
    process, we can look at changes that are required to run the training code in
    a container. To understand the difference between running code in a nonvirtualized
    environment and in a container, it helps to think of the container as its own
    self-contained machine where the code runs. In particular, code running in a container
    will not, by default, have access to the file system of the environment from which
    the container is managed. Figure 11.30 shows how the model training notebook interacts
    with files in the filesystem.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经回顾了使用容器进行训练过程的一些好处，我们可以看看运行训练代码在容器中所需的变化。为了理解在非虚拟化环境中运行代码和在容器中运行代码之间的区别，将容器视为一个自包含的机器，其中代码运行，这有助于理解。特别是，在容器中运行的代码默认情况下无法访问管理容器的环境文件系统。图
    11.30 展示了模型训练笔记本如何与文件系统中的文件交互。
- en: '![](../Images/CH11_F30_Ryan2.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F30_Ryan2.png)'
- en: Figure 11.30 Training code interactions with external files
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.30 训练代码与外部文件的交互
- en: When the training code runs in a container, it can’t get access to files on
    an external local filesystem. Instead, the artifacts that the model training script
    uses are stored in Cloud Storage, and the locations for these artifacts in Cloud
    Storage are passed to the model training script as URIs. Figure 11.31 gives an
    example of how to interpret a Google Cloud Storage URI.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 当训练代码在容器中运行时，它无法访问外部本地文件系统中的文件。相反，模型训练脚本使用的工件存储在云存储中，这些工件在云存储中的位置作为 URI 传递给模型训练脚本。图
    11.31 给出了如何解释 Google Cloud Storage URI 的示例。
- en: '![](../Images/CH11_F31_Ryan2.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F31_Ryan2.png)'
- en: Figure 11.31 Interpreting a Google Cloud Storage URI
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.31 解释 Google Cloud Storage URI
- en: 'In the ML pipeline, we use two methods to pass URIs to the training script
    running in a container: via the environment variables set in the container by
    the Vertex AI SDK and via the argument list of the `job.run` call in the pipeline
    script, as shown in figure 11.32.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习流程中，我们使用两种方法将 URI 传递给在容器中运行的训练脚本：通过 Vertex AI SDK 在容器中设置的环境变量，以及通过流程脚本中
    `job.run` 调用的参数列表，如图 11.32 所示。
- en: '![](../Images/CH11_F32_Ryan2.png)'
  id: totrans-197
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F32_Ryan2.png)'
- en: Figure 11.32 Training code interactions with content in Cloud Storage
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.32 训练代码与云存储中的内容的交互
- en: The location of the training data (split into training, validation, and test
    subsets) is automatically assigned to environment variables that get set in the
    container when it is set up by the pipeline script. This is standard for all Vertex
    AI containers; see the documentation at [https://mng.bz/2y70](https://mng.bz/2y70).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 训练数据的位置（分为训练、验证和测试子集）会自动分配给环境变量，这些变量在流程脚本设置容器时在容器中设置。这对于所有 Vertex AI 容器都是标准的；请参阅[https://mng.bz/2y70](https://mng.bz/2y70)上的文档。
- en: 'The way that the URI for the config file is passed to the model training script
    is not the default for Vertex AI. If we had a training script that had a small
    number of arguments, we could create an `argparser` list that contains the argument
    values and pass that list to the model training script. The config file for our
    application is too complex for this to be efficient, so instead of passing each
    argument individually, we pass a single argument: the URI for the Cloud Storage
    location where we have saved a copy of the config file. With that, all the model
    training script needs to do is get the Cloud Storage location from the argument
    list and ingest the YAML file from there. Once the arguments have been pulled
    into the config dictionary in the model training script, the rest of the code
    that uses them can work unchanged. This is a major benefit.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 将配置文件的URI传递给模型训练脚本的方式不是Vertex AI的默认方式。如果我们有一个只有少量参数的训练脚本，我们可以创建一个包含参数值的`argparser`列表，并将其传递给模型训练脚本。由于我们的应用程序配置文件过于复杂，这样做效率不高，所以我们不是逐个传递参数，而是传递一个单一参数：我们保存配置文件副本的云存储位置的URI。有了这个，模型训练脚本所需做的只是从参数列表中获取云存储位置，并从那里获取YAML文件。一旦参数被拉入模型训练脚本中的配置字典，使用它们的其余代码可以保持不变。这是一个主要的好处。
- en: 11.3.5 Updating the training code to work in a container
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.5 更新训练代码以在容器中工作
- en: In this section, we will review how we changed the model training notebook ([https://mng.bz/1XJj](https://mng.bz/1XJj))
    that we ran in Colab in chapter 9 to get a model to predict Kuala Lumpur property
    prices. By making these changes, we convert the model training notebook into a
    training script that can run in a Vertex AI built-in container.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将回顾我们如何将第9章中在Colab中运行的模型训练笔记本（[https://mng.bz/1XJj](https://mng.bz/1XJj)）修改为预测吉隆坡房地产价格的模型。通过这些修改，我们将模型训练笔记本转换为一个可以在Vertex
    AI内置容器中运行的训练脚本。
- en: 'The following are the key changes we made to the training notebook to create
    the training script:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是我们对训练笔记本所做的关键更改，以创建训练脚本：
- en: Removed extraneous library imports and associated code. For example, we don’t
    need to generate a diagram of the model when we run the training script, so we
    removed the code associated with `plot_model`.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除了不必要的库导入和相关代码。例如，当我们运行训练脚本时，我们不需要生成模型的图表，所以我们移除了与`plot_model`相关的代码。
- en: Removed code that splits the dataset into training, validation, and testing
    subsets. In the ML pipeline, the Vertex AI SDK takes care of splitting the dataset
    prior to the testing script being started.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除了将数据集拆分为训练、验证和测试子集的代码。在ML管道中，Vertex AI SDK会在测试脚本启动之前负责拆分数据集。
- en: Added code to interpret the `job.run` argument list, as shown in the following
    listing.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加了代码来解释`job.run`参数列表，如下所示。
- en: Listing 11.1 Loading the saved Keras model
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.1 加载保存的Keras模型
- en: '[PRE4]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: ① Defines an argparser object for the arguments passed by the Vertex AI SDK
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: ① 定义一个argparser对象，用于Vertex AI SDK传递的参数
- en: ② Adds the config_bucket argument to the argparser object
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: ② 将config_bucket参数添加到argparser对象中
- en: ③ Ingests the arguments passed by the Vertex AI SDK as a dictionary
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 将Vertex AI SDK传递的参数作为字典获取
- en: ④ Gets the config file URI from the argument dictionary
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 从参数字典中获取配置文件URI
- en: Updated the code that ingests the training config file so that it ingests the
    contents of the config file from the Cloud Storage URI passed by the pipeline
    script (`config_bucket` from listing 11.1) rather than from the local file system.
    As shown in the following listing, the URI for the config file in Cloud Storage
    (`config_bucket`) is used to copy the config file from Cloud Storage to a file
    in the container, and then the contents of that file are copied into the dictionary
    `config`.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新了获取训练配置文件的代码，使其从通过管道脚本传递的云存储URI（列表11.1中的`config_bucket`）获取配置文件的内容，而不是从本地文件系统获取。如下所示，云存储中的配置文件URI（`config_bucket`）用于将配置文件从云存储复制到容器中的一个文件，然后该文件的
    内容被复制到字典`config`中。
- en: Listing 11.2 Ingesting the training config file via the URI argument
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.2 通过URI参数获取训练配置文件
- en: '[PRE5]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: ① Gets the bucket prefix of config_bucket
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: ① 获取config_bucket的存储桶前缀
- en: ② Gets the file path suffix of config_buckett
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: ② 获取config_buckett的文件路径后缀
- en: ③ Defines a storage.Client object
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 定义一个storage.Client对象
- en: ④ Creates a storage object for the bucket
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: ④ 为存储桶创建一个存储对象
- en: ⑤ Creates a storage object for the file
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: ⑤ 为文件创建一个存储对象
- en: ⑥ Sets the name of the config file copy in the container
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: ⑥ 设置容器中配置文件副本的名称
- en: ⑦ Downloads the file from Cloud Storage to the container
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: ⑧ Reads the contents of the container version of the config file into a dictionary
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: Copied the values of the AIP environment variables that the Vertex AI SDK sets
    in the container. These environment variables contain URI patterns for the CSV
    files that the SDK creates in Google Storage that contain the train, validation,
    and test subsets of the dataset.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Listing 11.3 Copying AIP environment variable values
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: ① Gets the URI for the location to save the trained model
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: ② Gets the URI for the training dataset CSVs
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: ③ Gets the URI for the validation dataset CSVs
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: ④ Gets the URI for the testing dataset CSVs
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Created dataframes for each of the patterns from the AIP environment variables.
    For each of these environment variables, we parsed the URI, got the list of matching
    files CSV blobs in Cloud Storage, and reassembled them into a single dataframe.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Listing 11.4 Creating a dataframe for subsets of the dataset
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: ① For each file pattern, gets the bucket prefix
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: ② Gets the CSV file pattern
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: ③ Defines a storage.Client object
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: ④ Gets the list of CSVs in the bucket that match the pattern
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Gets a list of the fully qualified URIs for the CSVs that match the pattern
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Creates a dataframe containing the contents of all the CSVs that match the
    pattern
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: 'Saved the trained model to a location specified by `OUTPUT_MODEL_DIR`, the
    URI set by the Vertex AI SDK as the location for saving the model:'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: With these changes, the rest of the training code works running in a container.
    Now that we have gone through the updates required to create the training script,
    in the next section we will go through the key parts of the pipeline script that
    sets up the container that the training script runs in.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: 11.3.6 The pipeline script
  id: totrans-243
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that we have gone through the training script, we can examine the code that
    makes up the pipeline script. You can see the complete pipeline script code at
    [https://mng.bz/PdRn](https://mng.bz/PdRn).
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: The key parts of the pipeline script are
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: 'Ingest the pipeline config file: [https://mng.bz/JYdV](https://mng.bz/JYdV).'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Set the arguments for the training script:'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Create a `CustomTrainingJob` object that specifies the location of the training
    script `script_path`, the prebuilt image to use for training `container_uri`,
    and any additional Python libraries that need to be installed in the training
    container requirements, as shown in the following listing.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Listing 11.5 Creating a `CustomTrainingJob` object
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: ① Sets the prebuilt Vertex AI container image to run the training script
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: ② Defines the list of any additional requirements to be installed in the container
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: ③ Sets the prebuilt Vertex AI container image to use for prediction
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the path for the managed dataset used for training (using the dataset
    ID for the managed dataset that you created in section 11.2.7) and create a `TabularDataset`
    object using that path:'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Run the job defined previously, specifying the dataset created here; the proportion
    of the dataset to use for training, validation, and test; and the `machine_type`
    to use for the training.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行之前定义的作业，指定在此创建的数据集；用于训练、验证和测试的数据集比例；以及用于训练的`machine_type`。
- en: Listing 11.6 Running the job
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.6 运行作业
- en: '[PRE12]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: ① Associates the job with the managed dataset
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: ① 将作业与托管数据集关联
- en: ② Sets proportions of the dataset to use for training, validation, and testing
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: ② 设置用于训练、验证和测试的数据集比例
- en: ③ Sets the argument list (which contains the URI for the testing script config
    file)
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 设置参数列表（其中包含测试脚本配置文件的URI）
- en: Create an endpoint and deploy the model trained in the training script to that
    endpoint.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个端点，并将训练脚本中训练的模型部署到该端点。
- en: Listing 11.7 Deploying the trained model to an endpoint
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.7 将训练好的模型部署到端点
- en: '[PRE13]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: ① Sets characteristics of the endpoint
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: ① 设置端点的特征
- en: ② Creates the endpoint
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: ② 创建端点
- en: ③ Deploys the model to the endpoint
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 将模型部署到端点
- en: The following listing is the main function of the pipeline script that invokes
    the functions to run the pipeline.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以下列表是管道脚本的主函数，它调用了运行管道的函数。
- en: Listing 11.8 Main function of the pipeline script
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 列表11.8 管道脚本的主函数
- en: '[PRE14]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: ① Sets characteristics of the endpoint
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: ① 设置端点的特征
- en: ② Creates the endpoint
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: ② 创建端点
- en: ③ Deploys the model to the endpoint
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: ③ 将模型部署到端点
- en: 'To run the pipeline script, do the following:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 运行管道脚本，请按照以下步骤操作：
- en: Clone [https://github.com/lmassaron/ml_on_tabular_data](https://github.com/lmassaron/ml_on_tabular_data)
    in a new directory in Cloud Shell and make `chapter_11` the current directory.
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Cloud Shell的新目录中克隆[https://github.com/lmassaron/ml_on_tabular_data](https://github.com/lmassaron/ml_on_tabular_data)，并将`chapter_11`设置为当前目录。
- en: Update the pipeline config file to ensure that `project_id` and `region` match
    the settings for your project, `dataset_id` matches the ID for your managed dataset,
    `staging_path` matches your staging path, and `config_bucket_path` matches the
    location in Cloud Storage, where you copied the training script config file, as
    shown in figure 11.33.
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新管道配置文件，确保`project_id`和`region`与您的项目设置匹配，`dataset_id`与您的托管数据集ID匹配，`staging_path`与您的暂存路径匹配，以及`config_bucket_path`与云存储中您复制训练脚本配置文件的路径匹配，如图11.33所示。
- en: '![](../Images/CH11_F33_Ryan2.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F33_Ryan2.png)'
- en: Figure 11.33 Training code interactions with content in Cloud Storage
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.33 训练代码与云存储中内容的交互
- en: 'In the root directory where you cloned the repo, enter the following command:'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在您克隆仓库的根目录中，输入以下命令：
- en: '[PRE15]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Note that running the entire pipeline script can take 10 minutes or more. If
    the script fails, you will get a message that includes a link to the log file
    containing diagnostic messages about the training run. If the script succeeds,
    the output will end with the pipeline completed and the time taken to run it.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，运行整个管道脚本可能需要10分钟或更长时间。如果脚本失败，您将收到一条包含包含有关训练运行诊断信息的日志文件链接的消息。如果脚本成功，输出将以管道完成和运行时间结束。
- en: 11.3.7 Testing the model trained in the pipeline
  id: totrans-283
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.3.7 测试管道中训练的模型
- en: Once you have run the pipeline script to run the ML pipeline to train and deploy
    a model, you can use the resulting Vertex AI endpoint to exercise the model in
    the same web deployment framework that we used in chapter 10\. Note that testing
    the endpoint using this simple web deployment does not match what you would do
    in a production environment. However, using the same web deployment that we used
    in chapter 10 simplifies the testing process for this exercise.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您运行了管道脚本以运行机器学习管道来训练和部署模型，您就可以使用生成的Vertex AI端点在我们在第10章中使用的相同Web部署框架中测试模型。请注意，使用这种简单的Web部署测试端点并不符合您在生产环境中会做的事情。然而，使用我们在第10章中使用的相同Web部署简化了此练习的测试过程。
- en: The steps to test the model trained in the pipeline are
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 测试管道中训练的模型的步骤是
- en: 1.  In the Google Cloud Console, go to the Vertex AI Endpoints. Copy the ID
    for the deployment that was created by the ML pipeline, as shown in figure 11.34.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 1. 在Google Cloud控制台中，转到Vertex AI端点。复制由机器学习管道创建的部署ID，如图11.34所示。
- en: '![](../Images/CH11_F34_Ryan2.png)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F34_Ryan2.png)'
- en: Figure 11.34 Endpoint ID for the model generated by the pipeline
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.34 由管道生成的模型端点ID
- en: '2.  In the same local system where you tested the initial endpoint deployment
    with Flask in chapter 10, paste the endpoint ID that you just copied into the
    value of the `endpoint_id parameter` in the `flask_web_deploy_config.yml` config
    file and save the file:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '3.  On your local system, start the Flask server module:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 4.  Once the Flask server module is running, go to `localhost:5000` in a browser.
    `home.html` will be rendered as shown in figure 11.35\. When you click on Get
    prediction, the model trained and deployed at a Vertex AI endpoint by the ML pipeline
    will be invoked (see figure 11.35).
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F35_Ryan2.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
- en: Figure 11.35 Home.html
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: Note that the TensorFlow level used in the prebuilt container that you used
    for the model training has to match the TensorFlow level in the environment where
    you run the web application to test the endpoint. For example, if we want to exercise
    the endpoint deployment in an environment that has TensorFlow 2.9, then in the
    pipeline config file, we need to specify a value for `train_image` (the prebuilt
    training container) that is consistent with that level of TensorFlow level, such
    as `us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-9:latest`.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: 'If you get a protobuf error when you run the pipeline script in Cloud Shell,
    try running the following command to specify the protobuf level:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: If you want to experiment with different training configurations, you can update
    the training config file, upload it to Cloud Storage (ensuring that the value
    of `config_bucket_path` in the pipeline config file matches the URI for the training
    config file), and rerun the pipeline script. You can use the web application to
    exercise the new model by updating the value of `endpoint_id` in the pipeline
    config file to match the endpoint ID of the new endpoint and repeating the steps
    in this section. By encapsulating multiple steps in the ML workflow in an ML pipeline,
    we make it easy to get repeatable results and experiment with new settings.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: 11.4 Using generative AI to help create the ML pipeline
  id: totrans-300
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So far in this chapter, we have seen how we use a combination of actions in
    Google Cloud and manual scripting to set up a basic ML pipeline to train and deploy
    a model trained on tabular data. In this section, we’ll explore how we can use
    the generative AI capabilities in Gemini for Google Cloud, introduced in chapter
    10, to simplify or automate some of these actions. As we saw in chapter 10, there
    are four ways that Gemini for Google Cloud can help us:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: Answer questions about Google Cloud.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generate code from text.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interpret code. That is, given a piece of code, generate text that explains
    what the code does. We can use this capability to help us understand the code
    that we are adapting from other places. We can use this capability to document
    the code that we are writing ourselves.
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summarize log entries to help debug problems.
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 11.4.1 Using Gemini for Google Cloud to answer questions about the ML pipeline
  id: totrans-306
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As we saw in chapter 10, we can use the generative AI capabilities in Gemini
    for Google Cloud to get answers to questions about Google Cloud. The following
    are some examples of questions about creating an ML pipeline that Gemini for Google
    Cloud could help us to answer:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第10章中看到的，我们可以使用Gemini for Google Cloud中的生成式AI功能来获取有关Google Cloud的问题的答案。以下是一些关于创建ML流水线的问题的示例，Gemini
    for Google Cloud可以帮助我们回答：
- en: 'What is an ML pipeline? While Gemini for Google Cloud is trained specifically
    for Google Cloud, it is able to answer broad questions about technology, such
    as this one. Note that the answer shown in figure 11.36 is generally applicable
    and not limited to just Google Cloud. The citations come from a variety of credible
    sources, including the documentation for TensorFlow and Scikit-learn:'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是ML流水线？虽然Gemini for Google Cloud是专门针对Google Cloud进行训练的，但它能够回答关于技术等广泛的问题，如这个问题。请注意，图11.36中显示的答案是普遍适用的，并不仅限于Google
    Cloud。引用来自各种可信来源，包括TensorFlow和Scikit-learn的文档：
- en: What is an ML pipeline? ([https://mng.bz/wJjP](https://mng.bz/wJjP))
  id: totrans-309
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是ML流水线？([https://mng.bz/wJjP](https://mng.bz/wJjP))
- en: Building a data pipeline ([https://cs230.stanford.edu/blog/datapipeline/](https://cs230.stanford.edu/blog/datapipeline/))
  id: totrans-310
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建数据流水线 ([https://cs230.stanford.edu/blog/datapipeline/](https://cs230.stanford.edu/blog/datapipeline/))
- en: ML pipelines with Scikit-learn ([https://mng.bz/qxjr](https://mng.bz/qxjr))
  id: totrans-311
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于Scikit-learn的ML流水线 ([https://mng.bz/qxjr](https://mng.bz/qxjr))
- en: '![](../Images/CH11_F36_Ryan2.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F36_Ryan2.png)'
- en: Figure 11.36 Gemini for Google Cloud answers the question “what is an ML pipeline?”
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.36 Gemini for Google Cloud回答了“什么是ML流水线？”的问题
- en: What is a Vertex AI pipeline? When we take the same question and qualify it,
    as shown in figure 11.37, Gemini for Google Cloud gives us an answer that is specific
    to the ML pipeline implementation in Google Cloud.
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vertex AI流水线是什么？当我们对同一个问题进行限定，如图11.37所示，Gemini for Google Cloud会给我们一个针对Google
    Cloud中ML流水线实现的特定答案。
- en: '![](../Images/CH11_F37_Ryan2.png)'
  id: totrans-315
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F37_Ryan2.png)'
- en: Figure 11.37 Gemini for Google Cloud answers the question “what is a Vertex
    AI pipeline?”
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.37 Gemini for Google Cloud回答了“什么是Vertex AI流水线？”的问题
- en: What are Vertex AI prebuilt containers for training custom models? Finally,
    let’s try asking a question related to a specific task we tackled in this chapter.
    As you can see in figure 11.38, the answer provided by Gemini for Google Cloud
    describes both what prebuilt containers for training custom models are as well
    as the point of using them.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vertex AI预构建容器用于训练自定义模型是什么？最后，让我们尝试提出一个与本章节中我们解决的问题相关的具体问题。如图11.38所示，Gemini
    for Google Cloud提供的答案既描述了用于训练自定义模型的预构建容器是什么，也说明了使用它们的目的。
- en: '![](../Images/CH11_F38_Ryan2.png)'
  id: totrans-318
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F38_Ryan2.png)'
- en: Figure 11.38 Gemini for Google Cloud answers the question “what are Vertex AI
    prebuilt containers for training custom models?”
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.38 Gemini for Google Cloud回答了“Vertex AI预构建容器用于训练自定义模型是什么？”的问题
- en: In this section, we have seen how we can use Gemini for Google Cloud to answer
    questions, both general and specific, about building an ML pipeline. In the next
    section, we’ll look at how we use Gemini for Google Cloud to generate the code
    required for the ML pipeline.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们看到了如何使用Gemini for Google Cloud回答有关构建ML流水线的一般性和具体问题。在下一节中，我们将探讨如何使用Gemini
    for Google Cloud生成ML流水线所需的代码。
- en: 11.4.2 Using Gemini for Google Cloud to generate code for the ML pipeline
  id: totrans-321
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.2 使用Gemini for Google Cloud生成ML流水线的代码
- en: Now that we have seen how Gemini for Google Cloud can answer questions about
    creating an ML pipeline, let’s explore how the generative AI capabilities in Gemini
    for Google Cloud can help us to create the code related to the ML pipeline.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了Gemini for Google Cloud如何回答有关创建ML流水线的问题，让我们探索Gemini for Google Cloud中的生成式AI功能如何帮助我们创建与ML流水线相关的代码。
- en: 'Gemini for Google Cloud is enabled in several IDEs supported by Google Cloud,
    including VS Code, Cloud Workstations, and Cloud Shell Editor. In this section,
    we will use Gemini for Google Cloud in the context of Cloud Shell Editor. If you
    need a refresher on Cloud Shell Editor, see the overview documentation: [https://mng.bz/7pvv](https://mng.bz/7pvv).'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud的Gemini支持在多个Google Cloud支持的IDE中启用，包括VS Code、Cloud Workstations和Cloud
    Shell Editor。在本节中，我们将使用Cloud Shell Editor中的Gemini for Google Cloud。如果您需要刷新Cloud
    Shell Editor的知识，请参阅概述文档：[https://mng.bz/7pvv](https://mng.bz/7pvv)。
- en: 'We will see how Gemini for Google Cloud is able to generate the code for functions
    in the pipeline script: [https://mng.bz/PdRn](https://mng.bz/PdRn) Using the function
    signatures and introductory comments from this script, we will see what Gemini
    for Google Cloud generates.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到 Gemini for Google Cloud 如何在管道脚本中生成函数的代码：[https://mng.bz/PdRn](https://mng.bz/PdRn)
    使用此脚本的函数签名和介绍性注释，我们将看到 Gemini for Google Cloud 生成了什么。
- en: 'To begin with, if you have not done so already, follow the documentation to
    enable Gemini Code Assist in Cloud Shell Editor: [https://mng.bz/mGja](https://mng.bz/mGja).'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，如果你还没有这样做，请按照文档说明在 Cloud Shell 编辑器中启用 Gemini 代码助手：[https://mng.bz/mGja](https://mng.bz/mGja)。
- en: Once you have enabled Gemini Code Assist in Cloud Shell Editor, open a new Python
    file in Cloud Shell Editor and enter the signature and introductory comment for
    the `get_pipeline_config` function, as shown in the following listing.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你在 Cloud Shell 编辑器中启用了 Gemini 代码助手，就在 Cloud Shell 编辑器中打开一个新的 Python 文件，并输入
    `get_pipeline_config` 函数的签名和介绍性注释，如下所示。
- en: Listing 11.9 Signature for `get_pipeline_config`
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 11.9 `get_pipeline_config` 的签名
- en: '[PRE19]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Note that this code snippet does not include the logic of the function.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，此代码片段不包括函数的逻辑。
- en: To get Gemini for Google Cloud to generate code to complete this function, simply
    press Enter. Gemini for Google Cloud generates provisional code in italics, as
    shown in the figure 11.39.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 要让 Gemini for Google Cloud 为此函数生成代码以完成它，只需按 Enter 键。如图 11.39 所示，Gemini for Google
    Cloud 以斜体生成临时代码。
- en: '![](../Images/CH11_F39_Ryan2.png)'
  id: totrans-331
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F39_Ryan2.png)'
- en: Figure 11.39 First set of provisional code generated by Gemini for Google Cloud
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.39 Gemini for Google Cloud 生成的第一组临时代码
- en: Press Tab to accept this provisional code and then press Enter again to get
    the next set of code generated, as shown in figure 11.40.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 按 Tab 键接受此临时代码，然后再次按 Enter 键以获取下一组生成的代码，如图 11.40 所示。
- en: '![](../Images/CH11_F40_Ryan2.png)'
  id: totrans-334
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/CH11_F40_Ryan2.png)'
- en: Figure 11.40 Second set of provisional code generated by Gemini for Google Cloud
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.40 Gemini for Google Cloud 生成的第二组临时代码
- en: Press Tab again to accept this second set of provisional code. The resulting
    function is shown in the following listing.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 再次按 Tab 键以接受这组第二组临时代码。结果函数如下所示。
- en: Listing 11.10 `get_pipeline_config` function
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 11.10 `get_pipeline_config` 函数
- en: '[PRE20]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: ① First set of code generated by Gemini for Google Cloud
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: ① Gemini for Google Cloud 生成的第一组代码
- en: ② Second set of code generated by Gemini for Google Cloud
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: ② Gemini for Google Cloud 生成的第二组代码
- en: The code in listing 11.10 is not identical to the hand-written code for the
    `get_pipeline_config` function, as shown in the following listing.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 11.10 中的代码与 `get_pipeline_config` 函数的手写代码不完全相同，如下所示。
- en: 'Listing 11.11 get_`pipeline`_`config` function: handwritten version'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 11.11 `get_pipeline_config` 函数：手写版本
- en: '[PRE21]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: ① Handwritten code includes exception handling for the file opening operation
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: ① 手写代码包括文件打开操作的异常处理
- en: ② Handwritten code includes 'r' parameter with the file open
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: ② 手写代码包括文件打开时的 'r' 参数
- en: 'Comparing the code generated by Gemini for Google Cloud in listing 11.10 with
    the hand-written code in listing 11.11, we can see two differences:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 将列表 11.10 中 Gemini for Google Cloud 生成的代码与列表 11.11 中的手写代码进行比较，我们可以看到两个差异：
- en: The handwritten code includes exception handling to deal with problems opening
    the config file.
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手写代码包括异常处理以处理打开配置文件时的问题。
- en: The handwritten code includes the `'r'` parameter in the file open operation.
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 手写代码在文件打开操作中包括 `'r'` 参数。
- en: The `get_pipeline_config` function is trivial, but, nevertheless, Gemini for
    Google Cloud was able to generate working code for the function.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '`get_pipeline_config` 函数很简单，但无论如何，Gemini for Google Cloud 都能够为该函数生成可工作的代码。'
- en: Some additional considerations for Gemini for Google Cloud code generations
    are
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Gemini for Google Cloud 代码生成的额外考虑
- en: You don’t have to accept the provisional code generations from Gemini for Google
    Cloud all at once. To accept the provisional code token-by-token, press CTRL +
    Right Arrow to accept a single token.
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你不必一次性接受 Gemini for Google Cloud 生成的所有临时代码。要逐个接受临时代码标记，请按 CTRL + 右箭头以接受单个标记。
- en: To reject the entire provisional code generation and start again, press ESC,
    and the entire set of provisional code will be erased.
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要拒绝整个临时代码生成并重新开始，请按 ESC 键，整个临时代码集将被清除。
- en: When you ask Gemini for Google Cloud to generate code multiple times with the
    exact same input, you aren’t guaranteed to get identical code generated. For instance,
    in the `get_pipeline_config` example, sometimes Gemini for Google Cloud generated
    the function in two steps, as shown in this section, and sometimes it generated
    the entire function, including the `return` statement, in a single step.
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当您多次使用完全相同的输入请求 Gemini for Google Cloud 生成代码时，并不能保证生成的代码完全相同。例如，在 `get_pipeline_config`
    示例中，有时 Gemini for Google Cloud 会分两步生成函数，如图中所示，有时它会一次性生成整个函数，包括 `return` 语句。
- en: Now that we have used generative AI to generate code, we’ll see how we can use
    it to explain code in the next section.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经使用生成式 AI 生成代码，在下一节中，我们将看到如何用它来解释代码。
- en: 11.4.3 Using Gemini for Google Cloud to explain code for the ML pipeline
  id: totrans-355
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.3 使用 Gemini for Google Cloud 解释 ML 管道代码
- en: Now that we have seen an example of how Gemini for Google Cloud can generate
    code, let’s exercise its ability to interpret code.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了 Gemini for Google Cloud 生成代码的例子，让我们来练习它解释代码的能力。
- en: To get Gemini for Google Cloud to interpret a code snippet, copy the code in
    the following listing (the `main` function from the pipeline script) into a new
    file in Cloud Shell Editor.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 要让 Gemini for Google Cloud 解释一段代码片段，请将以下列表中的代码（管道脚本的 `main` 函数）复制到 Cloud Shell
    编辑器中的新文件中。
- en: Listing 11.12 `get_pipeline_config` function
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 11.12 `get_pipeline_config` 函数
- en: '[PRE22]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Once you have pasted the code in listing 11.13 into a file, select it and then
    select the Gemini for Google Cloud Smart Actions icon from the Cloud Shell Editor
    toolbar (see figure 11.41).
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您将列表 11.13 中的代码粘贴到文件中，请选择它，然后从 Cloud Shell 编辑器工具栏中选择 Gemini for Google Cloud
    Smart Actions 图标（见图 11.41）。
- en: '![](../Images/CH11_F41_Ryan2.png)'
  id: totrans-361
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F41_Ryan2.png)'
- en: Figure 11.41 Gemini for Google Cloud Smart Actions icon
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.41 Gemini for Google Cloud Smart Actions 图标
- en: In the menu that appears, select Explain, as shown in figure 11.42.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 在出现的菜单中，选择“解释”，如图 11.42 所示。
- en: '![](../Images/CH11_F42_Ryan2.png)'
  id: totrans-364
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F42_Ryan2.png)'
- en: Figure 11.42 Gemini for Google Cloud Smart Actions icon
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.42 Gemini for Google Cloud Smart Actions 图标
- en: When you select this, the explanation for the code appears in the left pane
    of Cloud Shell Editor, as shown in figure 11.43.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 当您选择此选项时，代码的解释将出现在 Cloud Shell 编辑器的左侧面板中，如图 11.43 所示。
- en: '![](../Images/CH11_F43_Ryan2.png)'
  id: totrans-367
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F43_Ryan2.png)'
- en: Figure 11.43 Code explanation
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.43 代码解释
- en: The code explanation capacity of Gemini for Google Cloud can be applied to a
    wide variety of code, including Python, Java, and JavaScript code. You can use
    the code explanations to understand code that you aren’t familiar with and to
    recommend documentation for your own code.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: Gemini for Google Cloud 的代码解释能力可以应用于各种代码，包括 Python、Java 和 JavaScript 代码。您可以使用代码解释来理解不熟悉的代码，并为您的代码推荐文档。
- en: So far in this section, we have seen how we can use the generative AI capabilities
    in Gemini for Google Cloud to answer questions, generate code, and explain code.
    In the next subsection, we’ll see how we can use Gemini for Google Cloud to help
    to summarize log entries.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本节中，我们已经看到了如何使用 Gemini for Google Cloud 中的生成式 AI 功能来回答问题、生成代码和解释代码。在下一小节中，我们将看到如何使用
    Gemini for Google Cloud 来帮助总结日志条目。
- en: 11.4.4 Using Gemini for Google Cloud to summarize log entries
  id: totrans-371
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 11.4.4 使用 Gemini for Google Cloud 总结日志条目
- en: Google Cloud includes a log that you can use to track the behavior of your environment
    and debug problems. Sometimes, however, the log entries can be hard to interpret.
    Gemini for Google Cloud can help you understand the point of a log entry by summarizing
    it. In this subsection, we’ll go through how you can use Gemini for Google Cloud
    to get the most out of Google Cloud logs.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud 包含一个日志，您可以使用它来跟踪环境的行为并调试问题。然而，有时日志条目可能难以解释。Gemini for Google Cloud
    可以通过总结来帮助您理解日志条目的要点。在本小节中，我们将介绍如何使用 Gemini for Google Cloud 充分利用 Google Cloud
    日志。
- en: 'To exercise this capability of Gemini for Google Cloud, we will try to use
    the foundation model tuning in Vertex AI. Foundation model tuning lets us take
    a pretrained model and tune it with a dataset in the JSONL (JSON Lines: [https://jsonlines.org/](https://jsonlines.org/))
    dataset. See the documentation for more details on tuning text models in Vertex
    AI: [https://mng.bz/5goO](https://mng.bz/5goO).'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 为了练习 Gemini for Google Cloud 的这一功能，我们将尝试使用 Vertex AI 中的基础模型调优。基础模型调优允许我们使用 JSONL（JSON
    Lines：[https://jsonlines.org/](https://jsonlines.org/)）数据集中的数据集对预训练模型进行调优。有关在
    Vertex AI 中调优文本模型的更多详细信息，请参阅文档：[https://mng.bz/5goO](https://mng.bz/5goO)。
- en: To prepare for the example in this section, create a new folder called `staging`
    in the Cloud Storage bucket that you created in chapter 10.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准备本节中的示例，在您在第10章中创建的云存储桶中创建一个名为`staging`的新文件夹。
- en: In Vertex AI in the Google Cloud Console, select Vertex AI Studio -> Language.
    In the Language page, select Tune and Distill and then select Create Tuned Model,
    as shown in figure 11.44.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 在Google Cloud控制台的Vertex AI中，选择Vertex AI Studio -> 语言。在语言页面上，选择调整和精炼，然后选择创建调整模型，如图11.44所示。
- en: '![](../Images/CH11_F44_Ryan2.png)'
  id: totrans-376
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F44_Ryan2.png)'
- en: Figure 11.44 Vertex AI Studio language page
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.44 Vertex AI Studio语言页面
- en: 'In the Tuning Method pane of the Create Tuned Model page:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建调整模型页面的调整方法面板中：
- en: Specify a name for your model in the Tuned model name field.
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在“调整模型名称”字段中指定您的模型名称。
- en: Specify the URI for the staging folder that you created at the beginning of
    this section in the Output Directory field.
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在输出目录字段中指定您在本节开头创建的存档文件夹的URI。
- en: Click Continue.
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击“继续”。
- en: See figure 11.45.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 见图11.45。
- en: '![](../Images/CH11_F45_Ryan2.png)'
  id: totrans-383
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F45_Ryan2.png)'
- en: Figure 11.45 Tuning method pane of the Create a tuned model page
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.45 创建调整模型页面的调整方法面板
- en: 'In the Tuning dataset pane of the Create Tuned Model page, do the following:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建调整模型页面的调整数据集面板中，执行以下操作：
- en: Select Existing File on Cloud Storage.
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在云存储中选择“现有文件”。
- en: 'Enter the URI for this sample JSONL file `cloud-samples-data/vertex-ai/model-evaluation/peft_train_sample.jsonl`
    in the Cloud storage file path field. See the documentation for details about
    JSONL samples: [https://mng.bz/6ene](https://mng.bz/6ene).'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在“云存储文件路径”字段中输入此样本JSONL文件的URI `cloud-samples-data/vertex-ai/model-evaluation/peft_train_sample.jsonl`。有关JSONL样本的详细信息，请参阅文档：[https://mng.bz/6ene](https://mng.bz/6ene)。
- en: Click Start Tuning.
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击“开始调整”。
- en: See figure 11.46.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 见图11.46。
- en: '![](../Images/CH11_F46_Ryan2.png)'
  id: totrans-390
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F46_Ryan2.png)'
- en: Figure 11.46 Tuning dataset pane of the Create a tuned model page
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.46 创建调整模型页面中的调整数据集面板
- en: Once you click Start tuning, you will see a list of tuned models with the status
    of your model showing as Running, as shown in figure 11.47.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦点击“开始调整”，你将看到一系列调整后的模型列表，其中你的模型状态显示为“运行中”，如图11.47所示。
- en: '![](../Images/CH11_F47_Ryan2.png)'
  id: totrans-393
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F47_Ryan2.png)'
- en: Figure 11.47 Tuning job status
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.47 调整作业状态
- en: When the tuning job is complete, the status will change to Succeeded, as shown
    in figure 11.48.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 当调整作业完成时，状态将更改为“成功”，如图11.48所示。
- en: '![](../Images/CH11_F48_Ryan2.png)'
  id: totrans-396
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F48_Ryan2.png)'
- en: Figure 11.48 Tuning job status showing a completed tuning job
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.48 显示完成调整作业状态的调整作业状态
- en: If the tuning job does not succeed, that’s fine. The goal of this particular
    exercise is to examine an error, so it’s okay if the operation fails for some
    reason.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 如果调整作业没有成功，那没关系。这个特定练习的目标是检查一个错误，所以如果由于某些原因操作失败，那是可以的。
- en: Once the tuning job is complete, put “logs explorer” in the search field at
    the top of the Console to get to the Logs Explorer page. This page provides many
    options for inspecting the logs generated by Google Cloud. For now, we just want
    to look at one of the errors. To view the errors, select Error in the bottom left
    of the Logs Explorer page, as shown in figure 11.49.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 调整作业完成后，在控制台顶部的搜索字段中输入“logs explorer”以进入日志资源管理器页面。此页面提供了检查由Google Cloud生成的日志的许多选项。现在，我们只想查看一个错误。要查看错误，请如图11.49所示，在日志资源管理器页面的左下角选择“错误”。
- en: '![](../Images/CH11_F49_Ryan2.png)'
  id: totrans-400
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F49_Ryan2.png)'
- en: Figure 11.49 Tuning job status showing a completed tuning job
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.49 显示完成调整作业状态的调整作业状态
- en: The Query Results pane at the bottom of the page shows the errors, as shown
    in figure 11.50.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 页面底部的查询结果面板显示了错误，如图11.50所示。
- en: '![](../Images/CH11_F50_Ryan2.png)'
  id: totrans-403
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F50_Ryan2.png)'
- en: Figure 11.50 Query results pane showing errors
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.50 显示错误的查询结果面板
- en: Select one of these error entries to expand it and click on Explain This Log
    Entry as shown in figure 11.51.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 选择这些错误条目之一以展开它，并点击如图11.51所示的“解释此日志条目”。
- en: '![](../Images/CH11_F51_Ryan2.png)'
  id: totrans-406
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F51_Ryan2.png)'
- en: Figure 11.51 Expanded error entry
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.51 展开的错误条目
- en: On the right, Gemini for Google Cloud shows an explanation of the error, as
    shown in figure 11.52.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 在右侧，Gemini for Google Cloud显示了错误解释，如图11.52所示。
- en: '![](../Images/CH11_F52_Ryan2.png)'
  id: totrans-409
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH11_F52_Ryan2.png)'
- en: Figure 11.52 Error explanation
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.52 错误解释
- en: The explanation provided by Gemini for Google Cloud summarizes the nested entries
    in the log and makes it easier to read and interpret. Note that the explanation
    that you will see will depend on the error that you select from the log.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: 11.4.5 Tuning a foundation model in Vertex AI
  id: totrans-412
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the previous subsection, we saw how to use the generative AI capabilities
    in Gemini for Google Cloud to interpret error logs. It’s worth taking a closer
    look at the action that we triggered to generate logs that we could examine with
    Gemini for Google Cloud. Here is a summary of what we did:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
- en: 'We started with one of the foundation models available in Vertex AI, `text-bison`.
    This model is designed for various natural language tasks like content creation
    and classification. See the documentation for more details on `text-bison`: [https://mng.bz/oKrZ](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/text).'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We applied supervised tuning to adapt the `text-bison` foundation model to
    a particular use case—our case classifying medical transcripts. To learn more
    about supervised tuning of foundation models in Vertex AI, see the documentation:
    [https://mng.bz/nR15](https://mng.bz/nR15).'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The dataset that we used for tuning contained medical diagnosis transcripts
    paired with the classification for the transcript, as shown in the following listing.
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Listing 11.13 Example record from tuning dataset
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-418
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: ① Medical transcript
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: ② Classification
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
- en: The URI for this dataset is `gs://cloud-samples-data/vertex-ai/model-evaluation/peft_train_sample.jsonl`.
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once the tuning process is complete, you can exercise the tuned model in Vertex
    AI Studio by selecting Language -> Tune and Distill and then selecting Test in
    the row for the model you tuned in the previous subsection, as shown in figure
    11.53.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F53_Ryan2.png)'
  id: totrans-423
  prefs: []
  type: TYPE_IMG
- en: Figure 11.53 Selecting the tuned model in Vertex AI Studio
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: The prompt editor opens with your tuned model selected as the model, as shown
    in figure 11.54.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F54_Ryan2.png)'
  id: totrans-426
  prefs: []
  type: TYPE_IMG
- en: Figure 11.54 Prompt editor with the tuned model selected
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: 'Exercise the tuned model by entering the following text in the Prompt field
    and clicking Submit:'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-429
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Note the response, as shown in figure 11.55.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F55_Ryan2.png)'
  id: totrans-431
  prefs: []
  type: TYPE_IMG
- en: Figure 11.55 Sleep medicine response
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
- en: Now change the model back to the foundation model `text-bison@001`, as shown
    in figure 11.56, and click Submit again.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH11_F56_Ryan2.png)'
  id: totrans-434
  prefs: []
  type: TYPE_IMG
- en: Figure 11.56 Changing the model back to text-bison@001
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: What’s the difference between the response you get from the prompt with the
    tuned model and the untuned foundation model? With the tuned model, you get all
    the capability of the foundation model along with appropriate responses for the
    medical transcript classification use case.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: 'If you examine the dataset that we used to tune the foundation model (with
    the URI `gs://cloud-samples-data/vertex-ai/model-evaluation/peft_train_sample.jsonl`)
    you will notice that it is, in fact, a tabular dataset with two columns: one containing
    medical transcription notes and the other containing a category for the notes,
    such as “cardiovascular / pulmonary,” “chiropractic,” or “pain management.” So
    far in this book, we have examined how generative AI can be applied to the workflow
    for machine learning on tabular data. The example we used in the log interpretation
    exercise demonstrates a different kind of relationship between tabular data and
    generative AI: tabular data being part of the workflow for generative AI. A detailed
    examination of this subject is beyond the scope of this book, but we think that
    the role of tabular data in generative AI workflows is an underresearched area
    that could yield significant benefits in getting the most out of generative AI.'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have seen how we can use Gemini for Google Cloud’s generative
    AI capabilities to answer questions about ML pipelines, generate some of the code
    required to create one, explain the code that makes up an ML pipeline, and explain
    log messages.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-439
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Several set-up tasks need to be completed before setting up an ML pipeline in
    Vertex AI.
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A service account needs to be created, and the service account key needs to
    be uploaded to the directory where you run the pipeline script.
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The dataset that will be used to train the model in the pipeline needs to be
    uploaded to a Google Cloud Storage bucket. This bucket location then needs to
    be used to define a Vertex AI dataset that will be used as an argument to the
    Vertex AI SDK in the pipeline script.
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The training script running in a Vertex AI prebuilt container does not have
    access to the file system outside of the container, so the training dataset and
    the training config file for the ML pipeline implementation are in Cloud Storage,
    and their locations are passed to the training script as URIs.
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The training code from the training notebook that we ran in Colab in chapter
    9 needs to be adapted to run in a container. For example, the training script
    needs to be updated to use the Cloud Storage locations for the config file, the
    training data, and the location where the trained model should be saved.
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The pipeline script invokes a series of functions from the Vertex AI SDK to
    create the container the training script runs in, to run the training script,
    and to deploy the trained model to a Vertex AI endpoint.
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use the same web application that you used to exercise the local deployment
    in chapter 10 to exercise the endpoint deployment generated by the ML pipeline.
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use Gemini for Google Cloud (the generative AI toolkit incorporated
    in Google Cloud) at various steps of the ML pipeline creation process to answer
    questions, generate code from text, interpret code, and explain log messages.
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
