- en: '1 Big picture: What are LLMs?'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: What Generative Pretrained Transformers and large language models are
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How LLMs work in plain language
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How humans and machines represent languages differently
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why tools like ChatGPT perform so well
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the limitations and concerns of using LLMs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The hype around terms such as machine learning (ML), deep learning (DL), and
    artificial intelligence (AI) has reached record levels. Much of the initial public
    exposure to these terms was driven by a product called ChatGPT, a form of generative
    AI built by a company called OpenAI. We now see generative AI offerings such as
    Gemini from Google, Copilot from Microsoft, Llama from Meta, Claude from Anthropic,
    and newcomers like DeepSeek in the daily news. Seemingly overnight, the ability
    of computers to talk, learn, and perform complex tasks has taken a dramatic leap
    forward. New generative AI companies are forming, and existing firms are publicly
    investing billions of dollars in the field. The technology in this space is evolving
    at a maddening pace.
  prefs: []
  type: TYPE_NORMAL
- en: This book aims to help you make sense of this new world by dispelling the mystery
    behind what makes ChatGPT and related technologies work. We will cover the knowledge
    necessary to understand their inner workings and how the components (data and
    algorithms) stack together to create the tools we use. We’ll also discuss various
    cases where this technology can form the cornerstone of a broader system and others
    where systems based on large language models (LLMs) may be a poor choice.
  prefs: []
  type: TYPE_NORMAL
- en: After reading this book, you’ll understand what generative AI like ChatGPT really
    *is*, what it can and can’t do, and, importantly, the “why” behind its limitations.
    With this knowledge, you’ll be a more effective consumer of this family of technology,
    whether as a user, a software developer, or a business decision maker in organizations
    deciding whether and, if so, how to incorporate it into your products or operations.
    This foundation will also serve as a launchpad for deeper study into the field
    by providing knowledge that will allow you to understand in-depth research and
    other works.
  prefs: []
  type: TYPE_NORMAL
- en: 1.1 Generative AI in context
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: First, we need to get more specific about what we are discussing when we talk
    about LLMs, GPTs, and the various tools that rely on them. The GPT in ChatGPT
    stands for *Generative Pretrained Transformer*. Each of these words bears a particular
    meaning in the context of ChatGPT. We’ll dedicate future chapters to discussing
    what *pretrained* and *transformer* mean, but we start here by discussing what
    *generative* means in this context.
  prefs: []
  type: TYPE_NORMAL
- en: AI chatbots like ChatGPT are a form of *generative* AI. Broadly, generative
    AI is software capable of creating, or generating, various media (e.g., text,
    images, audio, and video) based on data it has observed in the past and influenced
    by what people consider to be pleasing and accurate output. For example, if ChatGPT
    is prompted with “Write a haiku about snow falling on pines,” it will use all
    of the data it was trained with about haikus, snow, pines, and other forms of
    poetry to generate a novel haiku as shown in figure [1.1](#fig__gptHaiku)
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH01_F01_Boozallen.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.1 A simple haiku generated by ChatGPT
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Fundamentally, these systems are machine learning models that *generate* new
    output, so generative AI is an appropriate description. Some possible inputs and
    outputs are demonstrated in figure [1.2](#fig__whatIsGenerativeAI). While ChatGPT
    deals primarily with text as input and output, it also has more experimental support
    for different data types, such as audio and images. However, from our definition,
    you can imagine that many different kinds of algorithms and tasks fall into the
    description of generative AI.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH01_F02_Boozallen.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.2 Generative AI takes some input (numbers, text, images) and produces
    a new output (usually text or images). Any combination of input or output options
    is possible, and the nature of the output depends on what the algorithm was trained
    for. It could be to add detail, rewrite something to be shorter, extrapolate missing
    portions, and more.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Going a level deeper, ChatGPT is dealing with human text, and so it would also
    be fair to call it a model of human language—or a *language model* if you are
    a cool person who does work in the field known as *natural language processing*
    (NLP). The field of NLP intersects both computer science and linguistics and explores
    the technology that helps computers understand, manipulate, and create human language.
    Some of the first efforts in the field of NLP emerged in the 1940s when researchers
    hoped to build machines that could automatically translate between languages.
    As a result, NLP and language models have been around for a very long time. So
    what makes the new generative AI tools different? The most salient difference
    is that ChatGPT and similar algorithms are much larger than what people have historically
    built and are trained on much greater amounts of data.
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, the name *large language models* (LLMs) has become quite popular
    to describe GPT and similar types of machine learning models. GPT describes a
    specific type of LLM developed by OpenAI, and other companies use similar technologies
    to build their own LLMs and AI chatbots. More broadly, LLMs are machine learning
    models trained on large amounts of linguistic data.
  prefs: []
  type: TYPE_NORMAL
- en: A diagram of these relationships can be seen in figure [1.3](#fig__what_is_generative_heiarchy).
    ChatGPT, Copilot, Claude, and Gemini are some of the products that operate via
    text and are built using LLMs. LLMs use techniques from AI and NLP. The primary
    component of an LLM is a transformer, which we will explain in detail in chapter
    3.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH01_F03_Boozallen.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.3 A high-level map of the various terms you’ll become familiar with
    and how they relate. Generative AI is a description of functionality: the function
    of generating content and using tech- niques from AI to accomplish that goal.'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Note Vision and language are not the only options for generative AI. Audio generation
    (think text-to-speech, such as when your GPS speaks out the street names), playing
    board games like chess, and even protein folding have used generative AI. This
    book will stick mostly to text and language since those are the primary data types
    employed by GPTs and LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: As the name *large* implies, these models are not small. ChatGPT specifically
    is rumored [1] to contain 1.76 trillion parameters that are used to dictate the
    way it behaves. Each parameter is typically stored as a floating point number
    (a number with a decimal point) that uses 4 bytes for storage. That means the
    model itself takes 7 terabytes to hold in memory. This size is larger than most
    people’s computers could fit in RAM, let alone inside the most powerful graphics
    processing units (GPUs) with 80 gigabytes of memory. GPUs are special-purpose
    hardware components that excel in performing the mathematical operations that
    make LLMs possible. Currently, many GPUs are required when making LLMs, so we
    are already discussing a lot of computational infrastructure and complexity over
    multiple machines to build an LLM. In contrast, more run-of-the-mill language
    models would be 2 GB or less in most cases—over 5,000![equation image](../Images/eq-chapter-1-21-1.png)
    smaller, a much more reasonable size when considering building and using such
    a model on more standard hardware.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing LLMs
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Many researchers are investigating ways to make LLMs consume less memory. Sometimes,
    this includes techniques that require less than 4 bytes to store a parameter utilizing
    a method called “mixed-precision” [2]. This approach stores some LLM parameters
    using 2 bytes or fewer and presents a tradeoff between accuracy and memory efficiency.
    In the end, the effect on accuracy is often negligible. This optimization is one
    of many that researchers make to make LLMs more resource efficient.
  prefs: []
  type: TYPE_NORMAL
- en: GPU alternatives
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: While GPUs are currently the most frequently used hardware to train LLMs, they
    aren’t the only option available. Increasingly, companies are developing special-purpose
    hardware that offers general advantages for training machine learning models.
    For example, in 2018, Google made its Tensor Processing Unit (TPU) [3] available
    for public use as a part of the Google Cloud Platform (GCP). While TPUs generally
    have less computing capacity than GPUs, their specialized architecture allows
    them to perform better than GPUs for specific machine learning tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 1.2 What you will learn
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Throughout this book, we will explain how LLMs work and equip you with the vocabulary
    needed to understand them. Once you’ve finished reading, you will have a conversational
    understanding of what an LLM is and the critical steps involved in its operation.
    Additionally, you will have some perspective on what an LLM reasonably can do,
    especially the considerations related to deploying or using one. We will discuss
    salient points about the fundamental limitations of LLMs and provide tips on how
    to design around them or when LLMs and, more broadly, generative AI should be
    avoided entirely.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that the details of how transformers are combined to build ChatGPT,
    Claude, or Gemini are nuanced, and this book primarily focuses on what all of
    these systems have in common. In fact, we can’t know some of the actual differences
    between these LLMs because although commercial LLM providers have shared a great
    deal of information about their models, they have not shared some pieces of information,
    likely considered trade secrets.
  prefs: []
  type: TYPE_NORMAL
- en: 'Due to the effect that transformer-based LLMs will have on the world, we’re
    purposely focusing on a wide audience for this book. Programmers of all backgrounds,
    executives, managers, sales staff, artists, writers, publishers, and many more
    will have to interact with or have their jobs affected by LLMs over the coming
    years. So we are going to assume you, dear reader, have a minimal coding background
    but are familiar with the basic constructs of coding: logic, functions, and maybe
    even some data structures. You also do not need to be a mathematician; we will
    show you a bit of math where it is helpful, but it will be optional in building
    an understanding of how LLMs work.'
  prefs: []
  type: TYPE_NORMAL
- en: This approach means that very little code will be presented in this book. If
    you want to dive directly into building and using an LLM, other books in the Manning
    catalog, such as Sebastian Raschka’s *Build a Large Language Model from Scratch*
    (2024) or Edward Raff’s *Inside Deep Learning* (2022), will complement the material
    presented here. However, if you want to understand why the LLM you are using has
    unusual outputs, how your team might be able to use an LLM, or where to avoid
    using an LLM, or if you have a colleague with little machine learning background
    who needs to get conversationally competent, this is the book you and your colleague
    need.
  prefs: []
  type: TYPE_NORMAL
- en: 'In particular, the first part of this book focuses on what LLMs do: their inputs
    and outputs, converting inputs to outputs, and how we constrain the nature of
    those outputs. In the second part, we focus on what humans do: how people interact
    with technology and what risks this creates for using generative AI. Similarly,
    we’ll discuss some ethical considerations that arise when using and building LLMs.'
  prefs: []
  type: TYPE_NORMAL
- en: Training LLMs is expensive
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Training an LLM is not realistically possible for most people; it is a ![equation
    image](../Images/eq-chapter-1-33-1.png) investment at a minimum and would be a
    $100 million effort to try to compete with OpenAI. At the same time, the resources
    available for training LLMs are constantly evolving. As a result, instead of walking
    you through what training an LLM looks like today, we focus on content with a
    longer shelf life—helpful knowledge that we believe will be valid years from now
    instead of example code that could be out of date in just a few months.
  prefs: []
  type: TYPE_NORMAL
- en: 1.3 Introducing how LLMs work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Generative AI (GAI or GenAI) is poised to change how we produce and interact
    with information. The introduction of ChatGPT in November 2022 highlighted the
    capabilities of modern AI and fascinated a significant portion of the world. Currently,
    you can sign up for free at [https://chat.openai.com/](https://chat.openai.com/)
    to try it out.
  prefs: []
  type: TYPE_NORMAL
- en: If you enter the text prompt “Summarize the following text in two sentences,”
    followed by all of the introductory text from this chapter, you will get something
    similar to the following.
  prefs: []
  type: TYPE_NORMAL
- en: “The recent surge in attention towards artificial intelligence, particularly
    large language models (LLMs) like ChatGPT from OpenAI, has highlighted their vast
    capabilities in natural language processing. This book aims to provide readers
    with a conversational understanding of LLMs, their operational intricacies, potential
    applications, limitations, and the ethical considerations surrounding their use
    while assuming only a basic familiarity with coding concepts and minimal mathematical
    background. That’s pretty impressive, and to a casual audience, it may seem like
    this capability has come out of nowhere.”
  prefs: []
  type: TYPE_NORMAL
- en: When you visit OpenAI’s website and sign up for ChatGPT, you may notice an option
    similar to that shown in figure [1.4](#fig__gpt_option). As the name GPT-4 implies,
    Open AI is, as of this writing, working on its fourth generation of GPT models.
    LLMs like GPT-4 are a well-established area of ML research in creating algorithms
    that can synthesize and react to information and produce outputs that appear human
    generated. This ability unlocks several areas of interaction between people and
    machines that previously existed only in science fiction. The strength of the
    language representation encoded into ChatGPT enables convincing dialog, instruction
    following, summary generation, question answering, content creation, and many
    more applications. Indeed, it is likely that many possible applications of this
    technology do not yet exist because our gut reaction is to think of our current
    problems rather than new capabilities or products that could exist.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH01_F04_Boozallen.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.4 When you sign up for OpenAI’s ChatGPT, you have two options: the
    GPT-3.5 model, which you can use for free, or the GPT-4 model, which costs money.'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The critical factor for you, the reader, is that this technology did not come
    out of nowhere but is the result of steady progress over the past decade of dramatic
    year-over-year improvements in machine learning. Consequently, we already know
    quite a lot about how LLMs work and the ways that they can fail.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are assuming a minimal background so that you can give this book to your
    friends and family. (One of the authors is hopeful that they can give this book
    to their mother, who is very proud of them even if she does not know precisely
    what their job is.) As a result, we need to cover a potentially large gap in the
    background before we dive in. This first chapter aims to give you that background
    so the next chapter can begin the process of answering this question: How on earth
    did a computer summarize the introduction of this book?'
  prefs: []
  type: TYPE_NORMAL
- en: 1.4 What is intelligence, anyway?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Artificial intelligence* is an excellent name from a marketing perspective,
    although it was originally used as the name for an entire field of academic research.
    This practice has led to a subtle problem that gives people a false mental model
    of how AI works. We are going to try to avoid reinforcing this model. To explain
    why, we will discuss why artificial intelligence is not such a great name. We
    can demonstrate this easily by considering a simple question: What is intelligence?'
  prefs: []
  type: TYPE_NORMAL
- en: You might think that something like an intelligence quotient (IQ) test would
    help us answer that question. IQ tests have a strong correlation with numerous
    outcomes like school performance, but they do not give us an objective definition
    of intelligence. Studies show that some amount of nature (hereditary) and nurture
    (environment) affect a person’s IQ. It should also seem suspicious that we can
    boil down intelligence into something as simple as one number—after all, we often
    scold people for being only “book smart” but not “street smart.” Even if we knew
    what intelligence was, what would make it artificial? Does intelligence have manufactured
    flavorings and food colorings?
  prefs: []
  type: TYPE_NORMAL
- en: The bottom line is that IQ tests measure your ability to perform a finite set
    of capabilities, mostly some specific types of logic puzzles under time constraints,
    but they don’t help us understand the fundamental nature of intelligence. The
    truth is that there is no perfect understanding of what intelligence is.
  prefs: []
  type: TYPE_NORMAL
- en: The field of AI has long been trying to get computers, which are rigid, deterministic,
    rule-following machines, to perform specific tasks that humans can do but can’t
    give precise definitions or instructions to do. For example, if we want a computer
    to count to 1,000 and print out every number divisible by 5, we can write detailed
    instructions that almost any programmer can convert to code. But if I ask you
    to write a program that attempts to detect if an arbitrary picture has a cat in
    it, that’s quite a different challenge. You need to somehow precisely define what
    a cat is and then all the minutia of how to detect one. How exactly do we write
    code to find and differentiate between cat whiskers and dog whiskers? How do we
    successfully recognize a cat when it does not have whiskers? When it comes down
    to it, it isn’t easy to do.
  prefs: []
  type: TYPE_NORMAL
- en: However, because AI and ML have focused on these hard-to-specify tasks that
    humans can perform, describing AI and ML algorithms using analogies has become
    especially common. To get a computer to detect cats, we provide thousands upon
    thousands of examples of images that are cats and images that are not cats. We
    then run one of many various algorithms with a specific, detailed, mathematical
    process for differentiating cats from the rest of the world. But in the technical
    vocabulary, we call this process *learning*. When the model fails to detect a
    cat in a new image because it is a lion and lions were not in the original list
    of cats, we often say that the model didn’t *understand* lions.
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, whenever we try to explain something to friends, we often use analogies
    to shared concepts that we are both familiar with. Because AI and ML are broadly
    focused on replicating human abilities to perform tasks, the analogies often use
    language that implies the literal cognitive functions of a human. As LLMs demonstrate
    capabilities at a level close to what humans can do, these analogies become more
    troublesome than helpful because people read too deeply into them and begin to
    believe that they mean more than they do.
  prefs: []
  type: TYPE_NORMAL
- en: For this reason, we will be careful with our analogies and caution the reader
    about following any analogies too far. Some terms, like *learning*, are technical
    jargon worth understanding, but we want you to be on your guard about what they
    might imply. In some cases, analogies are still helpful in this book, but we will
    try to be explicit about the boundaries of how to interpret such analogies.
  prefs: []
  type: TYPE_NORMAL
- en: 1.5 How humans and machines represent language differently
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What does it mean to represent language? We humans implicitly start to learn
    how to represent language shortly after birth through interaction with others
    and the world around us. We proceed through formal education to develop an understanding
    of the components, underlying structures, and rules that govern language and its
    use. Our internal representation of language has been studied extensively. While
    some laws of language have been uncovered, many are still up for debate. ChatGPT’s
    internal representation of language is based on portions of this knowledge. It
    is enabled using the concepts of *artificial neural networks*, also known as deep
    learning (another dangerous analogy), which are combinations of data structures
    and algorithms that are patterned loosely after human brain structures. However,
    our understanding of the ways the mind works is incomplete. While the neural networks
    that power LLMs are a mere simplification of the human brain structure, their
    power lies in their ability to capture and encode language in a useful way to
    generate language and interact with people.
  prefs: []
  type: TYPE_NORMAL
- en: Note Abstractions of the brain’s structure have proven useful across many domains.
    Neural networks have demonstrated incredible progress in language, vision, learning,
    and pattern recognition. The convergence of advancements in neural machine learning
    algorithms, the extreme proliferation of digital data, and an explosion of computer
    hardware, such as GPUs, have led to the advancements that make ChatGPT possible
    today.
  prefs: []
  type: TYPE_NORMAL
- en: The critical detail to take from this discussion is that you, as a human, have
    an innate understanding of language you have learned over time. Your learning
    and use of language are interactive. Through evolution, we all seem to have relatively
    consistent ways of learning and communicating with each other. To find out more
    about this concept, look into the theory of universal grammar introduced by linguist
    Noam Chomsky. Unlike people, LLMs have a representation of language that is learned
    via a static process. When you have a conversation with Claude or ChatGPT, it
    mechanically participates in a dialog with you despite having never been in a
    conversation before.
  prefs: []
  type: TYPE_NORMAL
- en: The representation of language an LLM learns can be high quality, but it is
    not error-free. It is manipulable in that we can alter the behavior of LLMs in
    specific ways to limit what they are aware of or what they produce. Understanding
    that LLMs represent language using relationships inferred from examples helps
    us maintain realistic expectations. If you are going to use an LLM, how dangerous
    is it if it is wrong? How can you work with the representation of language to
    build a product or avoid a bad outcome? These are some of the high-level concerns
    we will discuss throughout this book.
  prefs: []
  type: TYPE_NORMAL
- en: 1.6 Generative Pretrained Transformers and friends
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The terminology *Generative Pretrained Transformer* was invented by OpenAI to
    talk about a new type of model they introduced in 2018 that incorporates a type
    of neural network component known as a transformer. While the original GPT model
    (GPT-1) is no longer used, the core underlying ideas of pretraining and transformers
    have become core pillars of the recent revolution in generative AI and tools like
    Claude, Gemini, Llama, and Copilot.
  prefs: []
  type: TYPE_NORMAL
- en: It is also essential to recognize that these GPT-based AI tools are only one
    example of an expansive domain of algorithmic research and application of LLMs.
    Outside of the release of ChatGPT, we have observed an incredible proliferation
    of LLMs. Some LLMs, like those released by EleutherAI and the BigScience Research
    Workshop, are freely available to the public to advance research and explore applications.
    Corporations like Meta, Microsoft, and Google, as we’ve mentioned, have released
    other LLMs with more restrictive licensing terms. Publicly available LLMs that
    anyone can use to build an application or system, sometimes called *foundation
    models*, have created a vibrant community of researchers, hobbyists, and companies
    exploring the applications, limitations, and opportunities LLMs and generative
    AI create. The concepts we teach in this book apply nearly uniformly to all LLMs.
    Each of these produce output using structures similar, if not identical, to those
    found in ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: It may seem impossible for one book to contain a general summary applicable
    to many models. However, it is possible for a few reasons, one of the most important
    being that we will not go to the level of depth necessary to code an LLM yourself
    from scratch. Naturally, there are parts of ChatGPT and other commercial LLMs
    that remain trade secrets. As a result, our scope and descriptions are intentionally
    generalized to the most common aspects of all generative LLMs today.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second reason we can give such a broadly applicable summary is the nature
    of LLMs. While it’s true that many tweaks can be made to how they are built and
    operate, researchers in the field consistently find that the details that matter
    the most are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: How large is the model, and can you make it larger?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How much data was used to build the model, and can you get more?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These points can be frustrating for researchers who like to think they have
    vital insights or designs that meaningfully improve how these LLMs work and operate
    because, in many cases, the same improvement could be obtained just as easily
    by “making it bigger” or building a model with more data or more parameters instead.
    Increasing the size of both the models and the data pools is a crucial component
    of many ethical concerns around using and building LLMs, which we will discuss
    in chapter [9](../Text/chapter-9.html).
  prefs: []
  type: TYPE_NORMAL
- en: 1.7 Why LLMs perform so well
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We discuss the details of how LLMs work in the coming chapters, but it is also
    worth sharing here a key lesson learned by researching ML algorithms. For many
    years, getting better performance from your algorithm for whatever task you were
    trying to do often meant getting clever about designing your algorithm. You would
    study your problem, the data, and the math and attempt to derive valuable truths
    about the world that you could then encode into your algorithm. If you did a good
    job, your performance improved, you required less data, and all was good in the
    world. Many classic deep learning algorithms you may hear about, like convolutional
    neural networks (CNNs) and long short-term memory (LSTM) networks, are, at a high
    level, the result of people thinking hard and getting clever. Even simpler “shallow”
    ML algorithms, such as XGBoost, that do not rely on neural networks or deep learning
    were created using clever algorithm design.
  prefs: []
  type: TYPE_NORMAL
- en: LLMs demonstrate a more recent trend. Instead of getting clever about thealgorithm,
    they keep it simple and implement a *naive* algorithm that simply captures relationships
    between pieces of information. In many ways, LLMs have fewer beliefs about the
    world forcibly baked into the algorithm. Fundamentally, this provides more flexibility.
    How could this be a good idea if I told you the opposite approach was how people
    improved algorithms? The difference is that LLMs and similar techniques are just
    bigger, massively so. They are trained on far more data and with far more ability
    to capture more relationships between more words in more sentences; this brute-force
    approach appears to have outpaced classic ML methods in performance. This idea
    is illustrated in figure [1.5](#fig__whatChanged).
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH01_F05_Boozallen.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.5 If the cleverness of an algorithm is based on how much information
    you encode into the design, older techniques often increase performance by being
    cleverer than their predecessors. As reflected by the size of the circles, LLMs
    have mostly chosen a “dumber” approach of using more data and parameters and imposing
    minimal constraints on what the algorithm can learn.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As we have already stated, bigger is not better by every metric. These models
    are currently a logistical and computational challenge to deploy. Many real-world
    constraints, including response time, power draw, battery drain, and maintainability,
    are all negatively affected. So it is only a narrow definition of “performance”
    by which LLMs have improved.
  prefs: []
  type: TYPE_NORMAL
- en: Still, the lesson on the value of “going bigger” over “getting clever” is worth
    considering. Sometimes, in your design of a machine learning solution, even if
    you are using an LLM, the best answer may be “Let’s just go get a lot more data.”
  prefs: []
  type: TYPE_NORMAL
- en: '1.8 LLMs in action: The good, bad, and scary'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Throughout this book, we will give examples of how LLMs can fail, often in hilarious
    or silly ways. The point of these illustrations isn’t to say that LLMs are incapable
    of performing a task. With changes to the input, setup, or random luck, you can
    often get LLMs to work better.
  prefs: []
  type: TYPE_NORMAL
- en: The point of such illustrations is to show you how LLMs can fail, often on things
    so simple that a child can do them better. As you read through this book and interact
    with LLMs yourself, these illustrations should give you pause and lead you to
    the thought, “If I use ChatGPT for a hard task, but it fails on easy ones, am
    I setting myself up for failure?” The answer may often be an emphatic *yes*! Using
    LLMs safely requires a degree of skepticism or doubt about the outputs, work to
    verify and validate correctness, and the ability to adapt accordingly. If you
    use an LLM for a task you cannot do yourself, you risk exposing yourself to errant
    results you can’t verify personally. We will continually weave this point and
    how to deal with it into the conversation as we discuss how to use LLMs more throughout
    the book.
  prefs: []
  type: TYPE_NORMAL
- en: It is easy to imagine many ways that LLMs can potentially make our lives easier
    when it does work—answering all your emails, summarizing long documents, and explaining
    new concepts. What does not come naturally to many is how things can go wrong
    and quickly become dangerous.
  prefs: []
  type: TYPE_NORMAL
- en: 'This kind of adversarial thinking can often be prompted with an initial example:
    say you want to learn how to make a bomb. If you ask ChatGPT that question, you
    get the sanitized answer, “Sorry, I can’t assist with that request. If you’re
    in crisis or need help, please contact local authorities or professionals who
    can help.” However, researchers have recently shown how to get ChatGPT and many
    other commercial LLMs to answer the question without hesitation, among many other
    dangerous requests for information [4].'
  prefs: []
  type: TYPE_NORMAL
- en: One might argue that if someone is so clever as to figure out how to trick the
    LLM, they could probably get whatever dangerous information they want from another
    source. This is likely true, but at the same time, it fails to account for the
    scale of automation in LLMs and generative AI tools. No AI or ML algorithm is
    perfect, and if millions of people ask questions, LLMs might produce a dangerous
    response 0.01% of the time. ChatGPT has over 100 million users [5], so that is
    10,000 dangerous responses. The problem worsens when you consider what a malicious
    actor might begin to automate. We will discuss this problem further in the second
    half of the book.
  prefs: []
  type: TYPE_NORMAL
- en: We look forward to your joining us in exploring how LLMs work. In the end, you’ll
    have a detailed understanding of many things to consider when employing LLMs’
    revolutionary capabilities in your business or daily life.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ChatGPT is a type of large language model, which is itself in the larger family
    of generative AI/ML. Generative models produce new output, and LLMs are unique
    in the quality of their output but are extremely costly to make and use.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs are loosely patterned after an incomplete understanding of human brain
    function and language learning. This is used as inspiration in design, but it
    does not mean the models have the same abilities or weaknesses as humans.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Intelligence is a multifaceted and hard-to-quantify concept, making it difficult
    to say whether LLMs are intelligent. It is easier to think about LLMs and their
    potential use in terms of capabilities and reliability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Human language must be converted to and from an LLM’s internal representation.
    How this representation is formed will change what an LLM learns and influence
    how you can build solutions using LLMs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
