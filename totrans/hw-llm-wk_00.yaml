- en: '1 Big picture: What are LLMs?'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 1 整体图景：什么是LLMs？
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: What Generative Pretrained Transformers and large language models are
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式预训练变换器和大型语言模型是什么
- en: How LLMs work in plain language
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以通俗易懂的语言解释LLMs的工作原理
- en: How humans and machines represent languages differently
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 人类和机器如何不同地表示语言
- en: Why tools like ChatGPT perform so well
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么像ChatGPT这样的工具表现如此出色
- en: Understanding the limitations and concerns of using LLMs
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解使用LLMs的局限性和担忧
- en: The hype around terms such as machine learning (ML), deep learning (DL), and
    artificial intelligence (AI) has reached record levels. Much of the initial public
    exposure to these terms was driven by a product called ChatGPT, a form of generative
    AI built by a company called OpenAI. We now see generative AI offerings such as
    Gemini from Google, Copilot from Microsoft, Llama from Meta, Claude from Anthropic,
    and newcomers like DeepSeek in the daily news. Seemingly overnight, the ability
    of computers to talk, learn, and perform complex tasks has taken a dramatic leap
    forward. New generative AI companies are forming, and existing firms are publicly
    investing billions of dollars in the field. The technology in this space is evolving
    at a maddening pace.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）、深度学习（DL）和人工智能（AI）等术语的炒作已经达到了历史最高水平。这些术语最初对公众的曝光很大程度上是由一个名为ChatGPT的产品驱动的，这是一种由OpenAI公司构建的生成式AI。现在，我们可以在日常新闻中看到来自Google的Gemini、来自Microsoft的Copilot、来自Meta的Llama、来自Anthropic的Claude以及像DeepSeek这样的新来者等生成式AI产品。似乎一夜之间，计算机说话、学习和执行复杂任务的能力有了巨大的飞跃。新的生成式AI公司正在形成，现有公司也在公开投资数十亿美元进入这个领域。这个领域的科技正在以令人疯狂的速度发展。
- en: This book aims to help you make sense of this new world by dispelling the mystery
    behind what makes ChatGPT and related technologies work. We will cover the knowledge
    necessary to understand their inner workings and how the components (data and
    algorithms) stack together to create the tools we use. We’ll also discuss various
    cases where this technology can form the cornerstone of a broader system and others
    where systems based on large language models (LLMs) may be a poor choice.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本书旨在通过揭示ChatGPT及相关技术工作原理背后的神秘面纱，帮助您理解这个新世界。我们将涵盖理解其内部工作原理以及组件（数据和算法）如何堆叠在一起以创建我们使用的工具所需的知识。我们还将讨论这种技术如何成为更广泛系统的基石，以及在其他情况下，基于大型语言模型（LLMs）的系统可能不是最佳选择的各种案例。
- en: After reading this book, you’ll understand what generative AI like ChatGPT really
    *is*, what it can and can’t do, and, importantly, the “why” behind its limitations.
    With this knowledge, you’ll be a more effective consumer of this family of technology,
    whether as a user, a software developer, or a business decision maker in organizations
    deciding whether and, if so, how to incorporate it into your products or operations.
    This foundation will also serve as a launchpad for deeper study into the field
    by providing knowledge that will allow you to understand in-depth research and
    other works.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读本书后，您将了解生成式AI如ChatGPT真正**是什么**，它能做什么，不能做什么，以及它局限性的“为什么”。有了这些知识，您将成为这个技术家族更有效的消费者，无论是作为用户、软件开发者，还是决定是否以及如何将其纳入产品或运营的组织中的业务决策者。这个基础也将作为深入研究该领域的跳板，提供知识，让您能够深入理解研究和其他作品。
- en: 1.1 Generative AI in context
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.1 上下文中的生成式AI
- en: First, we need to get more specific about what we are discussing when we talk
    about LLMs, GPTs, and the various tools that rely on them. The GPT in ChatGPT
    stands for *Generative Pretrained Transformer*. Each of these words bears a particular
    meaning in the context of ChatGPT. We’ll dedicate future chapters to discussing
    what *pretrained* and *transformer* mean, but we start here by discussing what
    *generative* means in this context.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，当我们谈论LLMs、GPTs以及依赖它们的各种工具时，我们需要更具体地了解我们讨论的内容。ChatGPT中的GPT代表**生成式预训练变换器**。这些词在ChatGPT的上下文中都有特定的含义。我们将在未来的章节中讨论**预训练**和**变换器**的含义，但在这里，我们先讨论一下在这个上下文中**生成式**的含义。
- en: AI chatbots like ChatGPT are a form of *generative* AI. Broadly, generative
    AI is software capable of creating, or generating, various media (e.g., text,
    images, audio, and video) based on data it has observed in the past and influenced
    by what people consider to be pleasing and accurate output. For example, if ChatGPT
    is prompted with “Write a haiku about snow falling on pines,” it will use all
    of the data it was trained with about haikus, snow, pines, and other forms of
    poetry to generate a novel haiku as shown in figure [1.1](#fig__gptHaiku)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于ChatGPT的AI聊天机器人是生成式AI的一种形式。广义上，生成式AI是能够根据过去观察到的数据以及受人们认为令人愉悦和准确输出影响的软件，生成或创建各种媒体（例如，文本、图像、音频和视频）。例如，如果ChatGPT被提示“写一首关于松树上雪的俳句”，它将使用所有关于俳句、雪、松树和其他诗歌形式的训练数据来生成一个新颖的俳句，如图[1.1](#fig__gptHaiku)所示。
- en: '![figure](../Images/CH01_F01_Boozallen.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F01_Boozallen.png)'
- en: Figure 1.1 A simple haiku generated by ChatGPT
  id: totrans-14
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.1 ChatGPT生成的一个简单的俳句
- en: Fundamentally, these systems are machine learning models that *generate* new
    output, so generative AI is an appropriate description. Some possible inputs and
    outputs are demonstrated in figure [1.2](#fig__whatIsGenerativeAI). While ChatGPT
    deals primarily with text as input and output, it also has more experimental support
    for different data types, such as audio and images. However, from our definition,
    you can imagine that many different kinds of algorithms and tasks fall into the
    description of generative AI.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，这些系统是生成新输出的机器学习模型，因此生成式AI是一个恰当的描述。一些可能的输入和输出在图[1.2](#fig__whatIsGenerativeAI)中得到了展示。虽然ChatGPT主要处理文本作为输入和输出，但它也支持更多实验性的不同数据类型，如音频和图像。然而，根据我们的定义，你可以想象许多不同类型的算法和任务都符合生成式AI的描述。
- en: '![figure](../Images/CH01_F02_Boozallen.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F02_Boozallen.png)'
- en: Figure 1.2 Generative AI takes some input (numbers, text, images) and produces
    a new output (usually text or images). Any combination of input or output options
    is possible, and the nature of the output depends on what the algorithm was trained
    for. It could be to add detail, rewrite something to be shorter, extrapolate missing
    portions, and more.
  id: totrans-17
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.2 生成式AI接收一些输入（数字、文本、图像）并产生新的输出（通常是文本或图像）。输入或输出选项的任何组合都是可能的，输出的性质取决于算法训练的目标。它可能是添加细节、缩短内容、推断缺失的部分等等。
- en: Going a level deeper, ChatGPT is dealing with human text, and so it would also
    be fair to call it a model of human language—or a *language model* if you are
    a cool person who does work in the field known as *natural language processing*
    (NLP). The field of NLP intersects both computer science and linguistics and explores
    the technology that helps computers understand, manipulate, and create human language.
    Some of the first efforts in the field of NLP emerged in the 1940s when researchers
    hoped to build machines that could automatically translate between languages.
    As a result, NLP and language models have been around for a very long time. So
    what makes the new generative AI tools different? The most salient difference
    is that ChatGPT and similar algorithms are much larger than what people have historically
    built and are trained on much greater amounts of data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 深入一层，ChatGPT处理的是人类文本，因此也可以公平地称其为人类语言模型——如果你是一个在被称为“自然语言处理”（NLP）领域的酷炫人士，你可能会称其为“语言模型”。NLP领域与计算机科学和语言学相交，探索帮助计算机理解、操作和创建人类语言的技术。NLP领域的早期努力出现在20世纪40年代，当时研究人员希望构建能够自动在不同语言之间进行翻译的机器。因此，NLP和语言模型已经存在很长时间了。那么，是什么让新的生成式AI工具与众不同呢？最显著的区别是，ChatGPT和类似的算法比人们历史上构建的规模要大得多，并且是在更大的数据量上训练的。
- en: For this reason, the name *large language models* (LLMs) has become quite popular
    to describe GPT and similar types of machine learning models. GPT describes a
    specific type of LLM developed by OpenAI, and other companies use similar technologies
    to build their own LLMs and AI chatbots. More broadly, LLMs are machine learning
    models trained on large amounts of linguistic data.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，“大型语言模型”（LLMs）这个名字被广泛用来描述GPT和类似类型的机器学习模型。GPT描述的是由OpenAI开发的一种特定类型的LLM，其他公司使用类似的技术来构建自己的LLMs和AI聊天机器人。更广泛地说，LLMs是在大量语言数据上训练的机器学习模型。
- en: A diagram of these relationships can be seen in figure [1.3](#fig__what_is_generative_heiarchy).
    ChatGPT, Copilot, Claude, and Gemini are some of the products that operate via
    text and are built using LLMs. LLMs use techniques from AI and NLP. The primary
    component of an LLM is a transformer, which we will explain in detail in chapter
    3.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这些关系的图示可以在图[1.3](#fig__what_is_generative_heiarchy)中看到。ChatGPT、Copilot、Claude和Gemini是一些通过文本操作的产品，它们使用LLMs构建。LLMs使用来自AI和NLP的技术。LLM的主要组件是一个转换器，我们将在第3章中详细解释。
- en: '![figure](../Images/CH01_F03_Boozallen.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F03_Boozallen.png)'
- en: 'Figure 1.3 A high-level map of the various terms you’ll become familiar with
    and how they relate. Generative AI is a description of functionality: the function
    of generating content and using tech- niques from AI to accomplish that goal.'
  id: totrans-22
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.3：你将熟悉的各种术语及其相互关系的高级图示。生成式人工智能是对功能性的描述：生成内容并使用AI技术实现该目标的功能。
- en: Note Vision and language are not the only options for generative AI. Audio generation
    (think text-to-speech, such as when your GPS speaks out the street names), playing
    board games like chess, and even protein folding have used generative AI. This
    book will stick mostly to text and language since those are the primary data types
    employed by GPTs and LLMs.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，视觉和语言并不是生成式人工智能的唯一选择。音频生成（例如，当你的GPS说出街道名称时的文本到语音），玩像国际象棋这样的棋类游戏，甚至蛋白质折叠都使用了生成式人工智能。这本书将主要关注文本和语言，因为这些都是GPTs和LLMs使用的主要数据类型。
- en: As the name *large* implies, these models are not small. ChatGPT specifically
    is rumored [1] to contain 1.76 trillion parameters that are used to dictate the
    way it behaves. Each parameter is typically stored as a floating point number
    (a number with a decimal point) that uses 4 bytes for storage. That means the
    model itself takes 7 terabytes to hold in memory. This size is larger than most
    people’s computers could fit in RAM, let alone inside the most powerful graphics
    processing units (GPUs) with 80 gigabytes of memory. GPUs are special-purpose
    hardware components that excel in performing the mathematical operations that
    make LLMs possible. Currently, many GPUs are required when making LLMs, so we
    are already discussing a lot of computational infrastructure and complexity over
    multiple machines to build an LLM. In contrast, more run-of-the-mill language
    models would be 2 GB or less in most cases—over 5,000![equation image](../Images/eq-chapter-1-21-1.png)
    smaller, a much more reasonable size when considering building and using such
    a model on more standard hardware.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 正如名称“大型”所暗示的，这些模型并不小。ChatGPT据传言[1]包含1.76万亿个参数，这些参数用于决定其行为方式。每个参数通常存储为一个使用4个字节进行存储的浮点数（带有小数点的数字）。这意味着模型本身需要7个太字节来在内存中存储。这个大小比大多数人的电脑能放入RAM中的大小都要大，更不用说在拥有80GB内存的最强大的图形处理单元（GPU）内部了。GPU是专门的硬件组件，擅长执行使LLMs成为可能的各种数学运算。目前，制作LLMs需要许多GPU，因此我们已经在讨论多个机器上的大量计算基础设施和复杂性，以构建一个LLM。相比之下，大多数常规语言模型在大多数情况下不会超过2GB——超过5,000![equation
    image](../Images/eq-chapter-1-21-1.png)更小，在考虑在更标准的硬件上构建和使用此类模型时，这是一个更加合理的尺寸。
- en: Optimizing LLMs
  id: totrans-25
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 优化LLMs
- en: Many researchers are investigating ways to make LLMs consume less memory. Sometimes,
    this includes techniques that require less than 4 bytes to store a parameter utilizing
    a method called “mixed-precision” [2]. This approach stores some LLM parameters
    using 2 bytes or fewer and presents a tradeoff between accuracy and memory efficiency.
    In the end, the effect on accuracy is often negligible. This optimization is one
    of many that researchers make to make LLMs more resource efficient.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 许多研究人员正在探索让大型语言模型（LLMs）消耗更少内存的方法。有时，这包括使用名为“混合精度”的方法，该方法需要少于4个字节来存储一个参数的技术[2]。这种方法使用2个字节或更少的存储空间来存储一些LLM参数，并在精度和内存效率之间做出权衡。最终，对精度的影响通常是可以忽略不计的。这种优化是研究人员为了使LLMs更加资源高效而做出的许多优化之一。
- en: GPU alternatives
  id: totrans-27
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: GPU替代方案
- en: While GPUs are currently the most frequently used hardware to train LLMs, they
    aren’t the only option available. Increasingly, companies are developing special-purpose
    hardware that offers general advantages for training machine learning models.
    For example, in 2018, Google made its Tensor Processing Unit (TPU) [3] available
    for public use as a part of the Google Cloud Platform (GCP). While TPUs generally
    have less computing capacity than GPUs, their specialized architecture allows
    them to perform better than GPUs for specific machine learning tasks.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然GPU目前是训练LLM最常用的硬件，但并非唯一的选择。越来越多的公司正在开发专门用于训练机器学习模型的专用硬件，这些硬件提供了训练机器学习模型的一般优势。例如，2018年，谷歌将其Tensor
    Processing Unit (TPU) [3]作为谷歌云平台（GCP）的一部分向公众开放。虽然TPU的算力通常低于GPU，但它们的专用架构使它们在特定的机器学习任务上比GPU表现更好。
- en: 1.2 What you will learn
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 你将学到什么
- en: Throughout this book, we will explain how LLMs work and equip you with the vocabulary
    needed to understand them. Once you’ve finished reading, you will have a conversational
    understanding of what an LLM is and the critical steps involved in its operation.
    Additionally, you will have some perspective on what an LLM reasonably can do,
    especially the considerations related to deploying or using one. We will discuss
    salient points about the fundamental limitations of LLMs and provide tips on how
    to design around them or when LLMs and, more broadly, generative AI should be
    avoided entirely.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，我们将解释LLM是如何工作的，并为你提供理解它们所需的词汇。阅读完毕后，你将对LLM是什么以及其操作中的关键步骤有一个对话式的理解。此外，你将对LLM合理能做什么有一些看法，特别是与部署或使用LLM相关的考虑。我们将讨论LLM的基本限制的显著点，并提供如何绕过它们或何时应完全避免使用LLM以及更广泛的生成式AI的建议。
- en: Keep in mind that the details of how transformers are combined to build ChatGPT,
    Claude, or Gemini are nuanced, and this book primarily focuses on what all of
    these systems have in common. In fact, we can’t know some of the actual differences
    between these LLMs because although commercial LLM providers have shared a great
    deal of information about their models, they have not shared some pieces of information,
    likely considered trade secrets.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，如何将变压器组合起来构建ChatGPT、Claude或Gemini的细节是微妙的，本书主要关注这些系统共有的特点。实际上，我们无法了解这些LLM之间的一些实际差异，因为尽管商业LLM提供商已经分享了他们模型的大量信息，但他们没有分享一些信息，这些信息可能被认为是商业机密。
- en: 'Due to the effect that transformer-based LLMs will have on the world, we’re
    purposely focusing on a wide audience for this book. Programmers of all backgrounds,
    executives, managers, sales staff, artists, writers, publishers, and many more
    will have to interact with or have their jobs affected by LLMs over the coming
    years. So we are going to assume you, dear reader, have a minimal coding background
    but are familiar with the basic constructs of coding: logic, functions, and maybe
    even some data structures. You also do not need to be a mathematician; we will
    show you a bit of math where it is helpful, but it will be optional in building
    an understanding of how LLMs work.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 由于基于Transformer的LLM将对世界产生的影响，我们故意将本书的受众范围扩大。所有背景的程序员、高管、经理、销售人员、艺术家、作家、出版商以及许多其他人在未来几年内将不得不与LLM互动或他们的工作将受到LLM的影响。因此，我们假设你，亲爱的读者，有最少的编码背景，但熟悉编码的基本结构：逻辑、函数，甚至可能是一些数据结构。你也不必是数学家；我们将展示一些有助于理解LLM工作原理的数学知识，但在构建对LLM工作原理的理解时，这些知识将是可选的。
- en: This approach means that very little code will be presented in this book. If
    you want to dive directly into building and using an LLM, other books in the Manning
    catalog, such as Sebastian Raschka’s *Build a Large Language Model from Scratch*
    (2024) or Edward Raff’s *Inside Deep Learning* (2022), will complement the material
    presented here. However, if you want to understand why the LLM you are using has
    unusual outputs, how your team might be able to use an LLM, or where to avoid
    using an LLM, or if you have a colleague with little machine learning background
    who needs to get conversationally competent, this is the book you and your colleague
    need.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法意味着本书中将展示的代码非常少。如果你想直接进入构建和使用LLM，Manning目录中的其他书籍，如Sebastian Raschka的《从零开始构建大型语言模型》（2024）或Edward
    Raff的《深度学习内部》（2022），将补充这里所展示的内容。然而，如果你想了解你使用的LLM为什么会有不寻常的输出，你的团队如何可能使用LLM，或者在哪里避免使用LLM，或者如果你有一个对机器学习背景了解有限的同事需要具备对话能力，这本书就是你和你同事需要的。
- en: 'In particular, the first part of this book focuses on what LLMs do: their inputs
    and outputs, converting inputs to outputs, and how we constrain the nature of
    those outputs. In the second part, we focus on what humans do: how people interact
    with technology and what risks this creates for using generative AI. Similarly,
    we’ll discuss some ethical considerations that arise when using and building LLMs.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 尤其是本书的第一部分专注于 LLM 做什么：它们的输入和输出，将输入转换为输出，以及我们如何约束这些输出的性质。在第二部分，我们将关注人类做什么：人们如何与技术互动，以及使用生成式
    AI 会带来哪些风险。同样，我们还将讨论在使用和构建 LLM 时出现的某些伦理考量。
- en: Training LLMs is expensive
  id: totrans-35
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 训练 LLM 是昂贵的
- en: Training an LLM is not realistically possible for most people; it is a ![equation
    image](../Images/eq-chapter-1-33-1.png) investment at a minimum and would be a
    $100 million effort to try to compete with OpenAI. At the same time, the resources
    available for training LLMs are constantly evolving. As a result, instead of walking
    you through what training an LLM looks like today, we focus on content with a
    longer shelf life—helpful knowledge that we believe will be valid years from now
    instead of example code that could be out of date in just a few months.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大多数人来说，训练一个 LLM 并不现实；这至少是一个![方程式图片](../Images/eq-chapter-1-33-1.png)的投资，而与
    OpenAI 竞争可能需要10亿美元。与此同时，用于训练 LLM 的资源正在不断演变。因此，我们不是带你了解今天训练 LLM 的样子，而是关注那些具有更长保质期的内容——我们认为这些知识在未来几年内仍然有效，而不是那些可能几个月后就过时的示例代码。
- en: 1.3 Introducing how LLMs work
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 介绍 LLM 的工作原理
- en: Generative AI (GAI or GenAI) is poised to change how we produce and interact
    with information. The introduction of ChatGPT in November 2022 highlighted the
    capabilities of modern AI and fascinated a significant portion of the world. Currently,
    you can sign up for free at [https://chat.openai.com/](https://chat.openai.com/)
    to try it out.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式人工智能（GAI 或 GenAI）正准备改变我们生产和交互信息的方式。2022 年 11 月 ChatGPT 的推出凸显了现代 AI 的能力，并吸引了世界上很大一部分人的兴趣。目前，你可以在
    [https://chat.openai.com/](https://chat.openai.com/) 上免费注册尝试。
- en: If you enter the text prompt “Summarize the following text in two sentences,”
    followed by all of the introductory text from this chapter, you will get something
    similar to the following.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你输入文本提示“用两句话总结以下文本”，然后跟上是本章的所有介绍性文本，你将得到类似以下的内容。
- en: “The recent surge in attention towards artificial intelligence, particularly
    large language models (LLMs) like ChatGPT from OpenAI, has highlighted their vast
    capabilities in natural language processing. This book aims to provide readers
    with a conversational understanding of LLMs, their operational intricacies, potential
    applications, limitations, and the ethical considerations surrounding their use
    while assuming only a basic familiarity with coding concepts and minimal mathematical
    background. That’s pretty impressive, and to a casual audience, it may seem like
    this capability has come out of nowhere.”
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: “近期人工智能领域，尤其是像 OpenAI 的 ChatGPT 这样的大型语言模型（LLM）的关注度激增，凸显了它们在自然语言处理方面的巨大能力。本书旨在向读者提供对
    LLM 的对话式理解，包括它们的操作复杂性、潜在应用、局限性以及使用它们时涉及的伦理考量，同时假设读者对编码概念有基本的了解，并具备最少的数学背景。这相当令人印象深刻，对于普通观众来说，这种能力可能似乎是从天而降。”
- en: When you visit OpenAI’s website and sign up for ChatGPT, you may notice an option
    similar to that shown in figure [1.4](#fig__gpt_option). As the name GPT-4 implies,
    Open AI is, as of this writing, working on its fourth generation of GPT models.
    LLMs like GPT-4 are a well-established area of ML research in creating algorithms
    that can synthesize and react to information and produce outputs that appear human
    generated. This ability unlocks several areas of interaction between people and
    machines that previously existed only in science fiction. The strength of the
    language representation encoded into ChatGPT enables convincing dialog, instruction
    following, summary generation, question answering, content creation, and many
    more applications. Indeed, it is likely that many possible applications of this
    technology do not yet exist because our gut reaction is to think of our current
    problems rather than new capabilities or products that could exist.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 当你访问 OpenAI 的网站并注册 ChatGPT 时，你可能注意到一个类似于图 [1.4](#fig__gpt_option) 中所示的选择项。正如
    GPT-4 这个名字所暗示的，截至本文写作时，Open AI 正在开发其第四代 GPT 模型。像 GPT-4 这样的 LLM 是机器学习研究中一个确立的领域，它旨在创建能够综合和反应信息并产生看似由人类生成的输出的算法。这种能力解锁了人与人之间机器互动的几个领域，这些领域以前仅存在于科幻小说中。ChatGPT
    中编码的语言表示的强大能力使得对话、指令遵循、摘要生成、问答、内容创作以及更多应用成为可能。实际上，许多可能的应用技术可能尚未存在，因为我们的直觉反应是思考我们当前的问题，而不是可能存在的新能力或产品。
- en: '![figure](../Images/CH01_F04_Boozallen.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH01_F04_Boozallen.png)'
- en: 'Figure 1.4 When you sign up for OpenAI’s ChatGPT, you have two options: the
    GPT-3.5 model, which you can use for free, or the GPT-4 model, which costs money.'
  id: totrans-43
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 1.4 当你注册 OpenAI 的 ChatGPT 时，你有两个选择：你可以免费使用的 GPT-3.5 模型，或者需要付费的 GPT-4 模型。
- en: The critical factor for you, the reader, is that this technology did not come
    out of nowhere but is the result of steady progress over the past decade of dramatic
    year-over-year improvements in machine learning. Consequently, we already know
    quite a lot about how LLMs work and the ways that they can fail.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 对你，即读者来说，关键因素是这项技术并非凭空出现，而是过去十年中机器学习逐年显著进步的结果。因此，我们已经对 LLM 的工作方式和它们可能失败的方式有了相当的了解。
- en: 'We are assuming a minimal background so that you can give this book to your
    friends and family. (One of the authors is hopeful that they can give this book
    to their mother, who is very proud of them even if she does not know precisely
    what their job is.) As a result, we need to cover a potentially large gap in the
    background before we dive in. This first chapter aims to give you that background
    so the next chapter can begin the process of answering this question: How on earth
    did a computer summarize the introduction of this book?'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们假设有一个最小的背景，这样你就可以把这本书给你的朋友和家人。（其中一位作者希望他们能将这本书送给他们的母亲，尽管她不知道他们的确切工作是什么，但她为他们感到非常自豪。）因此，在我们深入之前，我们需要填补一个可能很大的背景差距。第一章旨在为你提供这个背景，以便下一章可以开始回答这个问题：电脑究竟是如何总结这本书的引言的？
- en: 1.4 What is intelligence, anyway?
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.4 什么才是真正的智能？
- en: '*Artificial intelligence* is an excellent name from a marketing perspective,
    although it was originally used as the name for an entire field of academic research.
    This practice has led to a subtle problem that gives people a false mental model
    of how AI works. We are going to try to avoid reinforcing this model. To explain
    why, we will discuss why artificial intelligence is not such a great name. We
    can demonstrate this easily by considering a simple question: What is intelligence?'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 从营销角度来看，“人工智能”是一个很好的名字，尽管它最初被用作一个整个学术研究领域的名称。这种做法导致了一个微妙的问题，给人们造成了关于 AI 工作方式的错误心理模型。我们将尽力避免强化这种模型。为了解释原因，我们将讨论为什么“人工智能”不是一个很好的名字。我们可以通过考虑一个简单的问题来轻松证明这一点：什么是智能？
- en: You might think that something like an intelligence quotient (IQ) test would
    help us answer that question. IQ tests have a strong correlation with numerous
    outcomes like school performance, but they do not give us an objective definition
    of intelligence. Studies show that some amount of nature (hereditary) and nurture
    (environment) affect a person’s IQ. It should also seem suspicious that we can
    boil down intelligence into something as simple as one number—after all, we often
    scold people for being only “book smart” but not “street smart.” Even if we knew
    what intelligence was, what would make it artificial? Does intelligence have manufactured
    flavorings and food colorings?
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会认为像智商测试这样的东西可以帮助我们回答那个问题。智商测试与许多结果有很强的相关性，如学校表现，但它们并没有给我们一个客观的智能定义。研究表明，一些自然（遗传）和环境因素会影响一个人的智商。我们也应该怀疑，我们能否将智能简化为一个如此简单的数字——毕竟，我们经常批评人们只是“书本上的聪明”，而不是“街头上的聪明”。即使我们知道了智能是什么，什么会使其变得人工化？智能有制造的风味和食品色素吗？
- en: The bottom line is that IQ tests measure your ability to perform a finite set
    of capabilities, mostly some specific types of logic puzzles under time constraints,
    but they don’t help us understand the fundamental nature of intelligence. The
    truth is that there is no perfect understanding of what intelligence is.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，智商测试衡量的是你执行有限能力的能力，主要是时间限制下的某些特定类型的逻辑谜题，但它们并不能帮助我们理解智能的根本性质。事实是，对智能的理解并不完美。
- en: The field of AI has long been trying to get computers, which are rigid, deterministic,
    rule-following machines, to perform specific tasks that humans can do but can’t
    give precise definitions or instructions to do. For example, if we want a computer
    to count to 1,000 and print out every number divisible by 5, we can write detailed
    instructions that almost any programmer can convert to code. But if I ask you
    to write a program that attempts to detect if an arbitrary picture has a cat in
    it, that’s quite a different challenge. You need to somehow precisely define what
    a cat is and then all the minutia of how to detect one. How exactly do we write
    code to find and differentiate between cat whiskers and dog whiskers? How do we
    successfully recognize a cat when it does not have whiskers? When it comes down
    to it, it isn’t easy to do.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能领域长期以来一直在尝试让计算机，这些是僵化、确定性、遵循规则的机器，执行人类可以执行但无法给出精确定义或指令的具体任务。例如，如果我们想让计算机数到1000并打印出所有能被5整除的数字，我们可以编写详细的指令，几乎任何程序员都可以将其转换为代码。但如果我们要求你编写一个尝试检测任意图片中是否有猫的程序，那将是一个完全不同的挑战。你需要以某种方式精确地定义什么是猫，然后是检测猫的所有细节。我们如何编写代码来找到和区分猫胡须和狗胡须？当猫没有胡须时，我们如何成功地识别它？归根结底，这并不容易做到。
- en: However, because AI and ML have focused on these hard-to-specify tasks that
    humans can perform, describing AI and ML algorithms using analogies has become
    especially common. To get a computer to detect cats, we provide thousands upon
    thousands of examples of images that are cats and images that are not cats. We
    then run one of many various algorithms with a specific, detailed, mathematical
    process for differentiating cats from the rest of the world. But in the technical
    vocabulary, we call this process *learning*. When the model fails to detect a
    cat in a new image because it is a lion and lions were not in the original list
    of cats, we often say that the model didn’t *understand* lions.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于人工智能和机器学习专注于这些难以界定的任务，即人类可以执行的任务，因此使用类比来描述人工智能和机器学习算法变得特别常见。为了让计算机检测到猫，我们提供了成千上万张是猫和不是猫的图片示例。然后我们运行许多算法之一，这些算法具有一个特定、详细、数学化的过程，用于区分猫和其他物体。但在技术术语中，我们称这个过程为*学习*。当模型在新的图像中未能检测到猫，因为它是一只狮子，而狮子不在原始的猫的列表中时，我们经常说模型没有*理解*狮子。
- en: Indeed, whenever we try to explain something to friends, we often use analogies
    to shared concepts that we are both familiar with. Because AI and ML are broadly
    focused on replicating human abilities to perform tasks, the analogies often use
    language that implies the literal cognitive functions of a human. As LLMs demonstrate
    capabilities at a level close to what humans can do, these analogies become more
    troublesome than helpful because people read too deeply into them and begin to
    believe that they mean more than they do.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，每当我们要向朋友解释某事时，我们通常会使用我们双方都熟悉的共同概念进行类比。因为人工智能和机器学习广泛关注复制人类执行任务的能力，所以这些类比经常使用暗示人类直接认知功能的语言。随着大型语言模型（LLMs）展示出接近人类所能做到的能力，这些类比变得比有帮助更麻烦，因为人们过于深入地解读它们，并开始相信它们意味着比实际更多的东西。
- en: For this reason, we will be careful with our analogies and caution the reader
    about following any analogies too far. Some terms, like *learning*, are technical
    jargon worth understanding, but we want you to be on your guard about what they
    might imply. In some cases, analogies are still helpful in this book, but we will
    try to be explicit about the boundaries of how to interpret such analogies.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们将谨慎使用类比，并提醒读者不要过度追随任何类比。一些术语，如*学习*，是值得理解的术语，但我们希望您对它们可能意味着什么保持警惕。在某些情况下，这本书中的类比仍然是有帮助的，但我们将尝试明确解释如何解释这些类比的范围。
- en: 1.5 How humans and machines represent language differently
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.5 人类与机器如何不同地表示语言
- en: What does it mean to represent language? We humans implicitly start to learn
    how to represent language shortly after birth through interaction with others
    and the world around us. We proceed through formal education to develop an understanding
    of the components, underlying structures, and rules that govern language and its
    use. Our internal representation of language has been studied extensively. While
    some laws of language have been uncovered, many are still up for debate. ChatGPT’s
    internal representation of language is based on portions of this knowledge. It
    is enabled using the concepts of *artificial neural networks*, also known as deep
    learning (another dangerous analogy), which are combinations of data structures
    and algorithms that are patterned loosely after human brain structures. However,
    our understanding of the ways the mind works is incomplete. While the neural networks
    that power LLMs are a mere simplification of the human brain structure, their
    power lies in their ability to capture and encode language in a useful way to
    generate language and interact with people.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 表示语言意味着什么？我们人类在出生后不久通过与周围的人和世界的互动，隐式地开始学习如何表示语言。我们通过正规教育来发展对语言及其使用的组成部分、底层结构和规则的理解。我们对语言的内部表示已经被广泛研究。虽然已经发现了某些语言定律，但许多仍然有待辩论。ChatGPT对语言的内部表示基于这些知识的一部分。它是通过使用*人工神经网络*的概念实现的，也称为深度学习（另一个危险的类比），这些是模仿人类大脑结构的数据结构和算法的组合。然而，我们对心智工作方式的了解是不完整的。虽然为LLMs提供动力的神经网络只是人类大脑结构的简化，但它们的强大之处在于它们能够以有用的方式捕捉和编码语言，以生成语言并与人们互动。
- en: Note Abstractions of the brain’s structure have proven useful across many domains.
    Neural networks have demonstrated incredible progress in language, vision, learning,
    and pattern recognition. The convergence of advancements in neural machine learning
    algorithms, the extreme proliferation of digital data, and an explosion of computer
    hardware, such as GPUs, have led to the advancements that make ChatGPT possible
    today.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 注意 大脑结构的抽象在许多领域都已被证明是有用的。神经网络在语言、视觉、学习和模式识别方面取得了惊人的进步。神经机器学习算法的进步、数字数据的极端增长以及如GPU等计算机硬件的爆炸性增长，共同导致了今天ChatGPT成为可能的技术进步。
- en: The critical detail to take from this discussion is that you, as a human, have
    an innate understanding of language you have learned over time. Your learning
    and use of language are interactive. Through evolution, we all seem to have relatively
    consistent ways of learning and communicating with each other. To find out more
    about this concept, look into the theory of universal grammar introduced by linguist
    Noam Chomsky. Unlike people, LLMs have a representation of language that is learned
    via a static process. When you have a conversation with Claude or ChatGPT, it
    mechanically participates in a dialog with you despite having never been in a
    conversation before.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 从这次讨论中，我们需要关注的关键细节是，作为人类，你天生就理解你随着时间的推移所学习的语言。你的学习和语言使用是互动的。通过进化，我们似乎都有相对一致的学习和相互沟通的方式。要了解更多关于这个概念的信息，可以查阅语言学家诺姆·乔姆斯基提出的普遍语法理论。与人类不同，LLMs通过静态过程学习语言表示。当你与Claude或ChatGPT进行对话时，它机械地参与与你进行的对话，尽管它以前从未参与过任何对话。
- en: The representation of language an LLM learns can be high quality, but it is
    not error-free. It is manipulable in that we can alter the behavior of LLMs in
    specific ways to limit what they are aware of or what they produce. Understanding
    that LLMs represent language using relationships inferred from examples helps
    us maintain realistic expectations. If you are going to use an LLM, how dangerous
    is it if it is wrong? How can you work with the representation of language to
    build a product or avoid a bad outcome? These are some of the high-level concerns
    we will discuss throughout this book.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: LLM学习的语言表示可能质量很高，但并非没有错误。它是可操纵的，我们可以以特定方式改变LLMs的行为，以限制它们所了解的内容或它们产生的结果。理解LLMs通过从示例中推断出的关系来表示语言，有助于我们保持现实的期望。如果你打算使用LLM，如果它出错，会有多危险？你如何与语言表示一起工作来构建产品或避免不良结果？这些问题是我们将在本书中讨论的一些高级问题。
- en: 1.6 Generative Pretrained Transformers and friends
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.6 生成式预训练转换器和朋友们
- en: The terminology *Generative Pretrained Transformer* was invented by OpenAI to
    talk about a new type of model they introduced in 2018 that incorporates a type
    of neural network component known as a transformer. While the original GPT model
    (GPT-1) is no longer used, the core underlying ideas of pretraining and transformers
    have become core pillars of the recent revolution in generative AI and tools like
    Claude, Gemini, Llama, and Copilot.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: “生成式预训练转换器”这个术语是由OpenAI发明的，用于描述他们在2018年引入的一种新型模型，该模型包含一种称为转换器的神经网络组件。虽然原始的GPT模型（GPT-1）不再使用，但预训练和转换器的核心思想已成为最近生成式AI革命以及Claude、Gemini、Llama和Copilot等工具的核心支柱。
- en: It is also essential to recognize that these GPT-based AI tools are only one
    example of an expansive domain of algorithmic research and application of LLMs.
    Outside of the release of ChatGPT, we have observed an incredible proliferation
    of LLMs. Some LLMs, like those released by EleutherAI and the BigScience Research
    Workshop, are freely available to the public to advance research and explore applications.
    Corporations like Meta, Microsoft, and Google, as we’ve mentioned, have released
    other LLMs with more restrictive licensing terms. Publicly available LLMs that
    anyone can use to build an application or system, sometimes called *foundation
    models*, have created a vibrant community of researchers, hobbyists, and companies
    exploring the applications, limitations, and opportunities LLMs and generative
    AI create. The concepts we teach in this book apply nearly uniformly to all LLMs.
    Each of these produce output using structures similar, if not identical, to those
    found in ChatGPT.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 认识到这些基于GPT的人工智能工具只是LLMs（大型语言模型）算法研究和应用广泛领域的一个例子，这一点同样至关重要。除了ChatGPT的发布，我们还观察到LLMs的惊人增长。一些LLMs，如EleutherAI和BigScience
    Research Workshop发布的LLMs，对公众免费开放，以推进研究和探索应用。正如我们提到的，Meta、Microsoft和Google等公司已经发布了具有更严格许可条款的其他LLMs。任何人都可以使用的公开LLMs，有时被称为*基础模型*，已经创造了一个充满活力的研究、爱好者和公司社区，他们正在探索LLMs和生成式AI的应用、局限性和机遇。本书中教授的概念几乎普遍适用于所有LLMs。这些LLMs都使用与ChatGPT中找到的结构相似，如果不是完全相同的方式来产生输出。
- en: It may seem impossible for one book to contain a general summary applicable
    to many models. However, it is possible for a few reasons, one of the most important
    being that we will not go to the level of depth necessary to code an LLM yourself
    from scratch. Naturally, there are parts of ChatGPT and other commercial LLMs
    that remain trade secrets. As a result, our scope and descriptions are intentionally
    generalized to the most common aspects of all generative LLMs today.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 对于一本书来说，似乎不可能包含适用于许多模型的通用总结。然而，由于以下几个原因，这是可能的，其中最重要的一个原因是，我们不会深入到足以从零开始自己编写LLM代码的程度。自然地，ChatGPT和其他商业LLMs的部分仍然属于商业机密。因此，我们的范围和描述有意地概括了今天所有生成型LLMs最常见方面。
- en: 'The second reason we can give such a broadly applicable summary is the nature
    of LLMs. While it’s true that many tweaks can be made to how they are built and
    operate, researchers in the field consistently find that the details that matter
    the most are the following:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以给出这样一个广泛适用的总结的第二个原因是LLMs（大型语言模型）的本质。虽然确实可以对它们的建设和运行方式进行调整，但该领域的学者们一致发现，最重要的细节如下：
- en: How large is the model, and can you make it larger?
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型有多大，你能否使其更大？
- en: How much data was used to build the model, and can you get more?
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建模型所使用的数据量有多少，你能否获得更多？
- en: These points can be frustrating for researchers who like to think they have
    vital insights or designs that meaningfully improve how these LLMs work and operate
    because, in many cases, the same improvement could be obtained just as easily
    by “making it bigger” or building a model with more data or more parameters instead.
    Increasing the size of both the models and the data pools is a crucial component
    of many ethical concerns around using and building LLMs, which we will discuss
    in chapter [9](../Text/chapter-9.html).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 对于那些认为自己拥有重要见解或设计，能够实质性改进这些LLMs的工作和运行方式的学者来说，这些点可能会令人沮丧，因为在许多情况下，通过“使其更大”或构建一个拥有更多数据或更多参数的模型，同样可以轻易地获得相同的改进。增加模型和数据集的大小是围绕使用和构建LLMs的许多伦理问题中的一个关键组成部分，我们将在第[9](../Text/chapter-9.html)章中讨论。
- en: 1.7 Why LLMs perform so well
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.7 为什么LLMs表现如此出色
- en: We discuss the details of how LLMs work in the coming chapters, but it is also
    worth sharing here a key lesson learned by researching ML algorithms. For many
    years, getting better performance from your algorithm for whatever task you were
    trying to do often meant getting clever about designing your algorithm. You would
    study your problem, the data, and the math and attempt to derive valuable truths
    about the world that you could then encode into your algorithm. If you did a good
    job, your performance improved, you required less data, and all was good in the
    world. Many classic deep learning algorithms you may hear about, like convolutional
    neural networks (CNNs) and long short-term memory (LSTM) networks, are, at a high
    level, the result of people thinking hard and getting clever. Even simpler “shallow”
    ML algorithms, such as XGBoost, that do not rely on neural networks or deep learning
    were created using clever algorithm design.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的章节中讨论LLMs的工作细节，但在这里也值得分享一个通过研究机器学习算法所学到的重要教训。多年来，从你的算法中获得更好的性能，无论你试图完成什么任务，通常意味着你需要巧妙地设计你的算法。你会研究你的问题、数据以及数学，并试图推导出关于世界的有价值真理，然后将其编码到你的算法中。如果你做得好，你的性能会提高，你需要的数据会更少，世界上的所有事情都会变得很好。你可能听说过的许多经典深度学习算法，如卷积神经网络（CNNs）和长短期记忆（LSTM）网络，在高度上，是人们深思熟虑和巧妙设计的成果。甚至更简单的“浅层”机器学习算法，如不依赖神经网络或深度学习的XGBoost，也是通过巧妙的算法设计创建的。
- en: LLMs demonstrate a more recent trend. Instead of getting clever about thealgorithm,
    they keep it simple and implement a *naive* algorithm that simply captures relationships
    between pieces of information. In many ways, LLMs have fewer beliefs about the
    world forcibly baked into the algorithm. Fundamentally, this provides more flexibility.
    How could this be a good idea if I told you the opposite approach was how people
    improved algorithms? The difference is that LLMs and similar techniques are just
    bigger, massively so. They are trained on far more data and with far more ability
    to capture more relationships between more words in more sentences; this brute-force
    approach appears to have outpaced classic ML methods in performance. This idea
    is illustrated in figure [1.5](#fig__whatChanged).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs展示了一个更近期的趋势。它们不是在算法上变得聪明，而是保持简单，实现一个*天真*的算法，该算法简单地捕捉信息片段之间的关系。在许多方面，LLMs在算法中强制嵌入的世界观更少。从根本上说，这提供了更多的灵活性。如果你告诉我相反的方法是人们改进算法的方式，这怎么会是一个好主意？区别在于LLMs和类似的技术只是更大，大得多。它们在更多的数据上训练，并且有更大的能力捕捉更多句子中更多单词之间的关系；这种蛮力方法似乎在性能上超过了经典的ML方法。这个想法在图[1.5](#fig__whatChanged)中得到了说明。
- en: '![figure](../Images/CH01_F05_Boozallen.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH01_F05_Boozallen.png)'
- en: Figure 1.5 If the cleverness of an algorithm is based on how much information
    you encode into the design, older techniques often increase performance by being
    cleverer than their predecessors. As reflected by the size of the circles, LLMs
    have mostly chosen a “dumber” approach of using more data and parameters and imposing
    minimal constraints on what the algorithm can learn.
  id: totrans-71
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图1.5 如果算法的聪明程度取决于你编码到设计中的信息量，那么旧技术通常通过比前辈更聪明来提高性能。正如圆圈的大小所反映的，LLMs主要选择了一种“更愚蠢”的方法，即使用更多的数据和参数，并对算法可以学习的内容施加最小的限制。
- en: As we have already stated, bigger is not better by every metric. These models
    are currently a logistical and computational challenge to deploy. Many real-world
    constraints, including response time, power draw, battery drain, and maintainability,
    are all negatively affected. So it is only a narrow definition of “performance”
    by which LLMs have improved.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们已经指出的，并不是每个指标都表明“更大”就是更好。这些模型目前部署起来是一个物流和计算上的挑战。许多现实世界的限制，包括响应时间、功耗、电池消耗和可维护性，都受到了负面影响。因此，LLMs的“性能”只是一种狭义的定义。
- en: Still, the lesson on the value of “going bigger” over “getting clever” is worth
    considering. Sometimes, in your design of a machine learning solution, even if
    you are using an LLM, the best answer may be “Let’s just go get a lot more data.”
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，关于“做大”比“聪明”更有价值的教训是值得考虑的。有时，在设计机器学习解决方案时，即使你使用LLM，最好的答案可能是“让我们去获取更多的数据。”
- en: '1.8 LLMs in action: The good, bad, and scary'
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.8 LLMs在行动中：好的、坏的、和可怕的
- en: Throughout this book, we will give examples of how LLMs can fail, often in hilarious
    or silly ways. The point of these illustrations isn’t to say that LLMs are incapable
    of performing a task. With changes to the input, setup, or random luck, you can
    often get LLMs to work better.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，我们将提供LLMs可能失败的一些例子，通常以滑稽或愚蠢的方式。这些例子的目的并不是说LLMs无法执行任务。通过改变输入、设置或随机运气，你通常可以使LLMs工作得更好。
- en: The point of such illustrations is to show you how LLMs can fail, often on things
    so simple that a child can do them better. As you read through this book and interact
    with LLMs yourself, these illustrations should give you pause and lead you to
    the thought, “If I use ChatGPT for a hard task, but it fails on easy ones, am
    I setting myself up for failure?” The answer may often be an emphatic *yes*! Using
    LLMs safely requires a degree of skepticism or doubt about the outputs, work to
    verify and validate correctness, and the ability to adapt accordingly. If you
    use an LLM for a task you cannot do yourself, you risk exposing yourself to errant
    results you can’t verify personally. We will continually weave this point and
    how to deal with it into the conversation as we discuss how to use LLMs more throughout
    the book.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这些例子的目的是向您展示LLMs如何失败，通常是在一些非常简单的事情上，以至于孩子都能做得更好。当你阅读这本书并亲自与LLMs互动时，这些例子应该让你停下来，并引导你思考，“如果我使用ChatGPT来完成一项艰巨的任务，但它却在简单的事情上失败了，我是不是在为自己设置失败？”答案可能经常是肯定的！安全地使用LLMs需要一定程度的对输出的怀疑或质疑，需要验证和验证正确性，以及相应地适应的能力。如果你使用LLM来完成你自己无法完成的任务，你可能会暴露自己于无法亲自验证的错误结果。随着我们在书中讨论如何更广泛地使用LLMs，我们将不断将这一点以及如何处理它融入到对话中。
- en: It is easy to imagine many ways that LLMs can potentially make our lives easier
    when it does work—answering all your emails, summarizing long documents, and explaining
    new concepts. What does not come naturally to many is how things can go wrong
    and quickly become dangerous.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: 'This kind of adversarial thinking can often be prompted with an initial example:
    say you want to learn how to make a bomb. If you ask ChatGPT that question, you
    get the sanitized answer, “Sorry, I can’t assist with that request. If you’re
    in crisis or need help, please contact local authorities or professionals who
    can help.” However, researchers have recently shown how to get ChatGPT and many
    other commercial LLMs to answer the question without hesitation, among many other
    dangerous requests for information [4].'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: One might argue that if someone is so clever as to figure out how to trick the
    LLM, they could probably get whatever dangerous information they want from another
    source. This is likely true, but at the same time, it fails to account for the
    scale of automation in LLMs and generative AI tools. No AI or ML algorithm is
    perfect, and if millions of people ask questions, LLMs might produce a dangerous
    response 0.01% of the time. ChatGPT has over 100 million users [5], so that is
    10,000 dangerous responses. The problem worsens when you consider what a malicious
    actor might begin to automate. We will discuss this problem further in the second
    half of the book.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: We look forward to your joining us in exploring how LLMs work. In the end, you’ll
    have a detailed understanding of many things to consider when employing LLMs’
    revolutionary capabilities in your business or daily life.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: ChatGPT is a type of large language model, which is itself in the larger family
    of generative AI/ML. Generative models produce new output, and LLMs are unique
    in the quality of their output but are extremely costly to make and use.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LLMs are loosely patterned after an incomplete understanding of human brain
    function and language learning. This is used as inspiration in design, but it
    does not mean the models have the same abilities or weaknesses as humans.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Intelligence is a multifaceted and hard-to-quantify concept, making it difficult
    to say whether LLMs are intelligent. It is easier to think about LLMs and their
    potential use in terms of capabilities and reliability.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Human language must be converted to and from an LLM’s internal representation.
    How this representation is formed will change what an LLM learns and influence
    how you can build solutions using LLMs.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
