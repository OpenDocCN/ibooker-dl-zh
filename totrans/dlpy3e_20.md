# 结论

> 原文：[`deeplearningwithpython.io/chapters/chapter20_conclusion`](https://deeplearningwithpython.io/chapters/chapter20_conclusion)

我们将从这本书应该吸取的总体观点开始。这应该会刷新你对所学的一些概念的记忆。然后，我们将为你提供一份关于进一步学习机器学习和跟上新技术进展的资源与策略的简要列表。

成为有效的 AI 实践者是一个旅程，完成这本书只是你在这个旅程上的第一步。我想确保你意识到这一点，并准备好独立迈出下一步。

## 复习中的关键概念

本节简要总结了本书的关键要点。如果你需要快速复习以帮助回忆所学内容，可以阅读这几页。

### 人工智能的多种方法

首先，深度学习并不等同于人工智能（AI），甚至也不等同于机器学习：

+   *人工智能*（AI）是一个古老而广泛的领域，通常可以理解为“所有尝试自动化人类认知过程”的尝试。这可以从非常基础的，如 Excel 电子表格，到非常高级的，如能够行走和说话的人形机器人。

+   *机器学习* 是人工智能的一个特定子领域，旨在通过仅从训练数据中接触来自动开发程序（称为 *模型*）。将数据转化为程序的过程称为 *学习*。尽管机器学习已经存在很长时间了，但它直到 20 世纪 90 年代才开始起飞，并在 21 世纪初成为人工智能的主导形式。

+   *深度学习* 是机器学习众多分支之一，其中的模型是几何变换的长链，依次应用。这些操作被组织成称为 *层* 的模块：深度学习模型通常是层的堆叠——或者更普遍地说，是层的图。这些层由 *权重* 参数化，这些权重是在训练期间学习的参数。模型的 *知识* 存储在其权重中，学习过程包括找到这些权重的“良好值”——这些值最小化 *损失函数*。因为考虑的几何变换链是可微分的，所以通过 *梯度下降* 高效地更新权重以最小化损失函数。

+   *生成式 AI* 是深度学习的一个特定子集，其中的模型能够生成文本、图像、视频或声音。这些模型通常非常大——拥有数十亿个参数。它们以自监督的方式进行训练；也就是说，它们被训练来重建输入中人工缺失或损坏的部分——例如，去噪图像、预测句子中的下一个单词等。这个过程使得模型能够学习其输入空间的复杂“映射”（嵌入流形），这些映射可以用于采样新的输入。这些模型随着 ChatGPT 或 Midjourney 等产品的兴起，将 AI 带入了“消费者”时代。

尽管深度学习只是机器学习众多方法中的一种，但它并不与其他方法处于同等地位。深度学习是一次突破性的成功。原因如下。

### 深度学习在机器学习领域中的特殊性

在短短几年内，深度学习在一系列历史上被认为对计算机来说极其困难的任务上取得了巨大的突破，尤其是在机器感知领域：从图像、视频、声音中提取有用信息等。在提供足够的训练数据（特别是由人类适当标注的训练数据）的情况下，深度学习使得从感知数据中提取几乎任何人类能够提取的内容成为可能。因此，有时人们会说深度学习“解决了感知”问题——尽管这仅适用于对感知的狭义定义。

由于其前所未有的技术成功，深度学习独自引发了第三次，也是迄今为止最大的*AI 夏天*：一个对 AI 领域充满兴趣、投资和炒作的时期。当这本书正在撰写时，我们正处于这个时期。这个时期是否会在近期结束，以及结束之后会发生什么，是人们争论的话题。有一点是肯定的：与之前的 AI 夏天形成鲜明对比的是，深度学习为大大小小的科技公司带来了巨大的商业价值，并成为巨大的消费者成功，实现了人类水平的语音识别、聊天机器人助手、逼真的图像生成、人类水平的机器翻译等。炒作可能会（并且很可能）消退，但深度学习持续的经济和技术影响将保持。从这个意义上说，深度学习可以与互联网相提并论：它可能在几年内过度炒作，但从长远来看，它仍将是一场重大的革命，将改变我们的经济和我们的生活。

我对深度学习特别乐观的一个原因是，即使在未来十年内我们不再取得任何技术进步，将现有的算法应用于每一个适用的问题也将对大多数行业产生颠覆性的影响。深度学习无异于一场革命，由于资源投入和人力投入的指数级增长，进展正在以惊人的速度发生。从目前的情况来看，未来看起来光明，尽管短期预期有些过于乐观；将深度学习发挥到其潜能的极致可能需要数十年的时间。

### 如何思考深度学习

深度学习最令人惊讶的事情是它的简单性。十五年前，没有人预料到我们会通过使用简单的参数模型，并通过梯度下降进行训练，在机器感知和自然语言处理问题上取得如此惊人的成果。现在看来，你所需要的只是足够大的参数模型，在足够多的例子上用梯度下降进行训练。正如费曼曾经关于宇宙所说，“它并不复杂，只是有很多。”^([[1]](#footnote-1))

在深度学习中，一切都是向量；也就是说，一切都是几何空间中的一个*点*。模型输入（文本、图像等）和目标首先被*向量化*——转换成初始输入向量空间和目标向量空间。深度学习模型中的每一层都对通过它的数据进行一次简单的几何变换。模型中层的链式操作形成了一个复杂的几何变换，分解成一系列简单的变换。这个复杂变换试图将输入空间映射到目标空间，一次映射一个点。这个变换由层的权重参数化，这些权重根据模型当前的表现进行迭代更新。这个几何变换的一个关键特性是它必须是*可微分的*，这对于我们通过梯度下降学习其参数是必要的。直观地说，这意味着从输入到输出的几何变形必须是平滑和连续的——这是一个重要的约束。

将这种复杂的几何变换应用于输入数据的过程可以通过想象一个人试图展开一个纸团来在 3D 中进行可视化：皱巴巴的纸团是模型开始时的输入数据流形。人对纸团进行的每一次操作都类似于一层简单几何变换的操作。完整的展开动作序列是整个模型的复杂变换。深度学习模型是用于展开高维数据复杂流形的数学机器。

这就是深度学习的魔力——将意义转化为向量，转化为几何空间，然后逐步学习复杂的几何变换，将一个空间映射到另一个空间。你所需要的只是足够高维度的空间来捕捉原始数据中找到的所有关系范围。

整个事情的关键在于两个核心思想：即*意义来源于事物之间的成对关系*（在语言中的单词之间、在图像中的像素之间等等）以及*这些关系可以通过距离函数来捕捉*。但请注意，大脑是否通过几何空间来实现意义是一个完全独立的问题。从计算的角度来看，向量空间是高效的，但可以很容易地设想出用于智能的不同数据结构——特别是图。神经网络最初是从使用图作为编码意义的方式这一想法中产生的，这就是为什么它们被称为*神经网络*；周围的研究领域曾经被称为*联结主义*。如今，“神经网络”这个名字纯粹是出于历史原因——这是一个极其误导性的名字，因为它们既不是神经的，也不是网络的。特别是，神经网络几乎与大脑没有什么关系。一个更合适的名字可能是*层次表示学习*或*分层表示学习*，或者甚至可以是深度*可微模型*或*链式几何变换*，以强调连续几何空间操作是其核心。

### 关键使能技术

当前正在展开的技术革命并非始于任何单一的重大突破发明。相反，就像任何其他革命一样，它是大量使能因素积累的结果——最初缓慢，然后突然。在深度学习的情况下，我们可以指出以下关键因素：

+   算法创新的逐步发展，最初持续了二十年（从反向传播开始），然后在 2012 年之后，随着更多研究努力投入到深度学习中，发生得越来越快。2017 年，Transformer 架构是一个重大的突破。

+   大量图像、视频和文本数据的可用性，这是实现足够大的模型在足够大的数据上训练所必需的。这反过来又是消费互联网的兴起和摩尔定律应用于存储媒体的产物。如今，最先进的语言模型是在整个互联网的大部分数据上训练的。

+   快速、高度并行计算硬件的可用性，尤其是 NVIDIA 生产的 GPU——首先是游戏 GPU，然后是专为深度学习从头设计的芯片。早期，NVIDIA 首席执行官黄仁勋注意到了深度学习的兴起，并决定将公司的未来押宝在其上，这带来了巨大的回报。

+   一系列复杂的软件层，使得这种计算能力对人类可用：CUDA 语言，以及像 TensorFlow、JAX 和 PyTorch 这样的框架，它们执行自动微分，还有 Keras，它使得深度学习对大多数人变得容易。

在未来，深度学习将不仅被研究人员、研究生和具有学术背景的工程师等专业人士使用；它将成为每个开发者的工具箱中的工具，就像今天的网络技术一样。每个人都需要构建智能应用：就像今天每个企业都需要一个网站一样，每个产品都需要智能地理解用户生成数据。实现这一未来将需要我们构建使深度学习极其容易使用且对任何具有基本编码能力的人可用的工具。Keras 已经是在这个方向上的第一步。

### 通用机器学习工作流程

能够访问一个极其强大的工具，用于创建将任何输入空间映射到任何目标空间的模型，这很好，但机器学习工作流程中的难点通常是在设计和训练这些模型之前（以及对于生产模型，之后）的所有事情。理解问题域，以便确定要尝试预测什么，给定什么数据，以及如何衡量成功，是任何成功应用机器学习的先决条件，这不是像 Keras 和 TensorFlow 这样的高级工具能帮你的。作为提醒，以下是第六章中描述的典型机器学习工作流程的简要总结：

+   *定义问题。* 可用哪些数据，你试图预测什么？你需要收集更多数据或雇佣人员手动标记数据集吗？

+   *确定一种可靠地衡量你目标成功的方法。* 对于简单任务，这可能只是预测精度，但在许多情况下，它将需要复杂、特定领域的指标。

+   *准备你将用于评估你的模型的验证过程。* 特别是，你应该定义一个训练集、一个验证集和一个测试集。验证集和测试集的标签不应泄露到训练数据中：例如，在时间预测中，验证数据和测试数据应在训练数据之后。

+   *通过将其转换为向量和进行预处理（如归一化等）使数据向量化，以便更容易地由神经网络接近。*

+   *开发一个能够击败平凡常识基线的第一个模型，从而证明机器学习可以在你的问题上工作。* 这可能并不总是如此！

+   *通过调整超参数和添加正则化来逐步细化你的模型架构。仅基于验证数据上的性能进行更改，而不是测试数据或训练数据。记住，你应该让你的模型过度拟合（从而确定一个比所需更大的模型容量级别），然后才开始添加正则化或缩小模型。在调整超参数时要警惕验证集过度拟合——你的超参数可能最终会过度专门化到验证集。避免这一点正是保留单独测试集的目的！

+   *在生产环境中部署你的最终模型——作为一个 Web API，作为 JavaScript 或 C++应用程序的一部分，在嵌入式设备上等。持续监控其在真实世界数据上的性能，并使用你的发现来改进模型的下一版本！*

### 关键网络架构

在阅读完这本书后，你应该熟悉以下网络架构家族：*密集连接网络*、*卷积网络*、*循环网络*、*扩散模型*和*变换器*。每种模型都针对特定的数据模态：网络架构编码了关于数据结构的*假设*——一个*假设空间*，在其中将进行寻找良好模型的搜索。一个给定的架构是否适用于一个给定的问题完全取决于数据结构与网络架构假设之间的匹配。

这些不同的网络类型可以很容易地组合起来以实现更大的多模态模型，就像你组合乐高积木一样。从某种意义上说，深度学习层是信息处理的乐高积木。表 20.1 展示了输入和输出模态之间的映射以及适当的网络架构的快速概述。

| 输入 | 输出 | 模型 |
| --- | --- | --- |
| 向量数据 | 类别概率，回归值 | 密集连接网络 |
| 时间序列数据 | 类别概率，回归值 | RNN，变换器 |
| 图像 | 类别概率，回归值 | 卷积神经网络 |
| 文本 | 类别概率，回归值 | 变换器 |
| 文本，图像 | 文本 | 变换器 |
| 文本，图像 | 图像 | VAE，扩散模型 |

表 20.1：不同数据类型的模型架构

现在我们快速回顾一下每种网络架构的具体特点。

#### 密集连接网络

密集连接网络是一系列`Dense`层，旨在处理向量数据（其中每个样本是一个数值或分类属性的向量）。这类网络假设输入特征没有特定的结构：它们被称为*密集连接*，因为`Dense`层的单元与其他所有单元相连。该层试图映射任何两个输入特征之间的关系；这与例如 2D 卷积层不同，后者只关注*局部*关系。

密集连接网络最常用于分类数据（例如，输入特征是属性列表的情况），例如第四章中使用的波士顿房价数据集。它们也用作大多数网络的最终分类或回归阶段。例如，第八章中介绍的卷积神经网络通常以一个或两个`Dense`层结束，第十三章中的循环神经网络也是如此。

记住，要执行**二分类**，请在您的层堆栈中添加一个具有单个单元和`sigmoid`激活的`Dense`层，并使用`binary_crossentropy`作为损失。您的目标应该是 0 或 1：

```py
import keras
from keras import layers

inputs = keras.Input(shape=(num_input_features,))
x = layers.Dense(32, activation="relu")(inputs)
x = layers.Dense(32, activation="relu")(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(inputs, outputs)
model.compile(optimizer="rmsprop", loss="binary_crossentropy") 
```

要执行**单标签分类分类**（其中每个样本恰好有一个类别，没有更多），请在您的层堆栈中添加一个具有与类别数量相等的单元数的`Dense`层，并使用`softmax`激活。如果您的目标是 one-hot 编码，请使用`categorical_crossentropy`作为损失；如果它们是整数，请使用`sparse_categorical_crossentropy`：

```py
inputs = keras.Input(shape=(num_input_features,))
x = layers.Dense(32, activation="relu")(inputs)
x = layers.Dense(32, activation="relu")(x)
outputs = layers.Dense(num_classes, activation="softmax")(x)
model = keras.Model(inputs, outputs)
model.compile(optimizer="rmsprop", loss="categorical_crossentropy") 
```

要执行**多标签分类分类**（其中每个样本可以有多个类别），请在您的层堆栈中添加一个具有与类别数量相等的单元数和`sigmoid`激活的`Dense`层，并使用`binary_crossentropy`作为损失。您的目标应该是 k-hot 编码：

```py
inputs = keras.Input(shape=(num_input_features,))
x = layers.Dense(32, activation="relu")(inputs)
x = layers.Dense(32, activation="relu")(x)
outputs = layers.Dense(num_classes, activation="sigmoid")(x)
model = keras.Model(inputs, outputs)
model.compile(optimizer="rmsprop", loss="binary_crossentropy") 
```

要执行对连续值向量的**回归**，请在您的层堆栈中添加一个具有与您试图预测的值数量相等的单元数的`Dense`层，并且没有激活。可以用于回归的损失函数有很多种——最常见的是`mean_squared_error`（均方误差）：

```py
inputs = keras.Input(shape=(num_input_features,))
x = layers.Dense(32, activation="relu")(inputs)
x = layers.Dense(32, activation="relu")(x)
outputs = layers.Dense(num_values)(x)
model = keras.Model(inputs, outputs)
model.compile(optimizer="rmsprop", loss="mse") 
```

#### 卷积神经网络

卷积层通过将相同的几何变换应用于输入张量中的不同空间位置（*块*）来观察空间局部模式。这导致的结果是*平移不变性*，使得卷积层在数据效率和模块化方面非常高效。这个想法适用于任何维度的空间：1D（连续序列）、2D（图像）、3D（体积）等等。您可以使用`Conv1D`层处理序列，`Conv2D`层处理图像，`Conv3D`层处理体积。作为一种更轻量、更高效的卷积层替代方案，您还可以使用*深度可分离卷积*层，例如`SeparableConv2D`。

*卷积神经网络*，或称*卷积网络*，由一系列卷积和最大池化层组成。池化层允许您在空间上对数据进行下采样，这对于在特征数量增加时保持特征图的大小合理，并允许后续卷积层“看到”更大的输入空间范围是必要的。卷积神经网络通常以`Flatten`操作或全局池化层结束，将空间特征图转换为向量，然后通过`Dense`层实现分类或回归。

这是一个典型的图像分类网络（在这种情况下是分类分类）使用`SeparableConv2D`层：

```py
inputs = keras.Input(shape=(height, width, channels))
x = layers.SeparableConv2D(32, 3, activation="relu")(inputs)
x = layers.SeparableConv2D(64, 3, activation="relu")(x)
x = layers.MaxPooling2D(2)(x)
x = layers.SeparableConv2D(64, 3, activation="relu")(x)
x = layers.SeparableConv2D(128, 3, activation="relu")(x)
x = layers.MaxPooling2D(2)(x)
x = layers.SeparableConv2D(64, 3, activation="relu")(x)
x = layers.SeparableConv2D(128, 3, activation="relu")(x)
x = layers.GlobalAveragePooling2D()(x)
x = layers.Dense(32, activation="relu")(x)
outputs = layers.Dense(num_classes, activation="softmax")(x)
model = keras.Model(inputs, outputs)
model.compile(optimizer="rmsprop", loss="categorical_crossentropy") 
```

当构建一个非常深的卷积神经网络时，通常还会添加*批归一化*层以及*残差连接*——两种有助于梯度信息在网络中平滑流动的架构模式。

#### Transformers

Transformer 查看一组向量（如词向量）并使用*神经注意力*将每个向量转换为一个表示，该表示了解集合中其他向量提供的*上下文*。当所涉及的集合是一个有序序列时，你也可以使用*位置编码*来创建能够同时考虑全局上下文和词序的 Transformer，这些 Transformer 可以比 RNN 或 1D 卷积神经网络更有效地处理长文本段落。

Transformer 可以用于任何集合处理或序列处理任务，包括文本分类，但它们在*序列到序列学习*方面特别出色，例如将源语言的段落翻译成目标语言。

序列到序列 Transformer 由两部分组成：

+   一个`TransformerEncoder`，它将输入向量序列转换为具有上下文感知和顺序感知的输出向量序列

+   一个`TransformerDecoder`，它接受`TransformerEncoder`的输出以及一个目标序列，并预测目标序列中的下一个应该是什么。

如果你只处理单个向量（或集合）序列，你将只使用`TransformerEncoder`。

以下是一个将源序列映射到目标序列的序列到序列 Transformer（这种设置可以用于机器翻译或问答，例如）：

```py
from keras_hub.layers import TokenAndPositionEmbedding
from keras_hub.layers import TransformerDecoder, TransformerEncoder

# Source sequence
encoder_inputs = keras.Input(shape=(src_seq_length,), dtype="int64")
x = TokenAndPositionEmbedding(vocab_size, src_seq_length, embed_dim)(
    encoder_inputs
)
encoder_outputs = TransformerEncoder(intermediate_dim=256, num_heads=8)(x)
# Target sequence so far
decoder_inputs = keras.Input(shape=(dst_seq_length,), dtype="int64")
x = TokenAndPositionEmbedding(vocab_size, dst_seq_length, embed_dim)(
    decoder_inputs
)
x = TransformerDecoder(intermediate_dim=256, num_heads=8)(x, encoder_outputs)
# Predictions for target sequence one step in the future
decoder_outputs = layers.Dense(vocab_size, activation="softmax")(x)
transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)
transformer.compile(optimizer="adamw", loss="categorical_crossentropy") 
```

这是一个用于整数序列二分类的独立`TransformerEncoder`：

```py
inputs = keras.Input(shape=(seq_length,), dtype="int64")
x = TokenAndPositionEmbedding(vocab_size, seq_length, embed_dim)(inputs)
x = TransformerEncoder(intermediate_dim=256, num_heads=8)(x)
x = layers.GlobalMaxPooling1D()(x)
outputs = layers.Dense(1, activation="sigmoid")(x)
model = keras.Model(inputs, outputs)
model.compile(optimizer="adamw", loss="binary_crossentropy") 
```

#### 循环神经网络

*循环神经网络*（RNNs）通过逐个时间步处理输入序列并在整个过程中保持状态（状态通常是向量或向量集）来工作。在感兴趣的模式不是通过时间平移不变的序列（例如，近期过去比遥远过去更重要的时间序列数据）的情况下，应优先使用 1D 卷积神经网络。

Keras 中有三个 RNN 层：`SimpleRNN`、`GRU`和`LSTM`。对于大多数实际用途，你应该使用`GRU`或`LSTM`。`LSTM`是两者中更强大的，但成本也更高；你可以将`GRU`视为它的一个更简单、更便宜的替代品。

要堆叠多个 RNN 层，每个层在堆栈中的最后一层之前都应该返回其输出的完整序列（每个输入时间步将对应一个输出时间步）；如果你没有堆叠任何更多的 RNN 层，那么通常只返回最后一个输出，它包含有关整个序列的信息。

以下是一个用于向量序列二分类的单个 RNN 层：

```py
inputs = keras.Input(shape=(num_timesteps, num_features))
x = layers.LSTM(32)(inputs)
outputs = layers.Dense(num_classes, activation="sigmoid")(x)
model = keras.Model(inputs, outputs)
model.compile(optimizer="rmsprop", loss="binary_crossentropy") 
```

这是一种用于二进制分类向量序列的堆叠 RNN 层：

```py
inputs = keras.Input(shape=(num_timesteps, num_features))
x = layers.LSTM(32, return_sequences=True)(inputs)
x = layers.LSTM(32, return_sequences=True)(x)
x = layers.LSTM(32)(x)
outputs = layers.Dense(num_classes, activation="sigmoid")(x)
model = keras.Model(inputs, outputs)
model.compile(optimizer="rmsprop", loss="binary_crossentropy") 
```

## 深度学习的局限性

构建深度学习模型就像玩乐高积木：只要你有合适的训练数据，并且映射可以通过合理的连续几何变换实现，层就可以组合起来将本质上任何事物映射到任何事物。

然而，这里有一个问题——这种映射往往无法以通用的方式学习。深度学习模型像庞大的插值模式数据库一样运行。它们的模式匹配能力也是它们的根本弱点：

+   *它们在适应新颖事物方面存在根本性的困难。* 由于它们的参数在训练后是固定的，它们只能检索或复制与训练数据相似的图案。面对显著超出这种熟悉分布的输入——无论底层任务多么简单——它们的性能会急剧下降，因为它们缺乏超越记忆经验的流畅泛化机制。这解释了为什么即使是大型模型在新型任务或熟悉问题的简单变化（如 ARC-AGI 任务）上也失败。

+   *它们对措辞和其他干扰因素非常敏感。* 深度学习模型对输入呈现的表面变化表现出高度敏感性，例如微小的措辞变化（考虑 LLM 中的提示敏感性）或难以察觉的扰动（考虑视觉中的对抗样本），这表明缺乏稳健、类似人类的理解。

+   *它们通常无法学习可泛化的算法。* 深度学习模型的连续、几何性质使它们在本质上不适合学习精确、离散、逐步的算法，例如那些是经典计算机科学的核心。模型通过插值而不是实现稳健、可泛化的程序来近似这些过程。

你应该始终抵制将深度学习模型拟人化的诱惑。它们的性能建立在点 wise 统计模式上，而不是类似人类的经验基础上，这使得它们在遇到训练数据之外的偏差时变得脆弱。

简单地扩大模型规模和训练数据就能导致通用智能的叙述已被证明是不充分的。虽然扩大规模增强了在相当于记忆测试的基准测试上的性能，但它未能解决深度学习的根本局限性，这些局限性源于将静态、插值曲线拟合到数据的核心范式。五年来的指数级扩大基础 LLM 并没有克服这些限制，因为底层方法保持不变。

到 2024 年，这一认识推动了向测试时适应（TTA）的转变，其中模型在推理阶段进行搜索或微调以适应新问题。虽然 TTA 方法已经取得了重大突破，例如 OpenAI 的 o3 在 2024 年底在 ARC-AGI-1 上超越了人类基线，但这种性能是以极端的计算成本为代价的。高效、类似人类的适应仍然是一个完全未解决的问题，而稍微困难的 ARC-AGI-2 基准至今仍未解决。我们仍然需要进一步的概念进步，而不仅仅是扩展或蛮力搜索。

## 前方可能是什么

解决类似人类流畅智能（和 ARC-AGI-2）需要超越当前方法固有的局限性。虽然深度学习在*价值中心抽象*方面表现出色，这有助于模式识别和直觉，但它本质上缺乏*程序中心抽象*的能力，这是离散推理、规划和因果理解的基础。人类智能无缝地整合了这两者——未来的 AI 必须做到同样。

未来可能的关键发展可能包括

+   *混合模型* — 未来的模型可能会将学习到的算法模块（提供推理和符号操作）与深度学习模块（提供感知和直觉）集成。这些系统可能会学习动态地使用编程原语，如控制流、变量、递归和复杂的数据结构。

+   *深度学习引导的程序搜索* — 程序综合——自动发现满足规格的可执行代码——为程序中心抽象提供了一条途径。然而，它对低效的离散搜索的依赖是一个主要瓶颈。一个关键进步将是使用深度学习来引导这一搜索，利用关于程序结构的直觉来有效地导航程序的大量组合空间，就像人类开发者使用经验和直觉来缩小他们的选择范围一样。

+   *模块化重组和终身学习* — 我们将远离从头开始训练的单一、端到端模型。相反，未来的 AI 系统将使用大量可重用、模块化的组件库，这些组件可以在许多问题之间重新部署，并从经验中获取。这些库将包括“几何”（基于深度学习）和“算法”模块。面对新问题时，这样的 AI 系统将检索相关模块，并将它们动态地重新组合成适应当前情况的新模型。每当系统在问题解决循环中作为副产品开发出可重用组件时，新组件就会被添加到库中，可供系统未来可能遇到的每个任务使用。

最终，开发出类似人类流畅智能的 AI 需要将连续模式识别与离散、符号程序相结合，并完全接受即时适应的范式。

## 在快速发展的领域中保持最新

在此书的最后一页翻过之后，我想给您一些建议，关于如何继续学习和更新您的知识和技能。正如我们所知，现代深度学习领域，尽管有着几十年的漫长而缓慢的史前时期，但至今只有几年历史。自 2013 年以来，随着资金和研究人员的指数级增长，整个领域现在正以极快的速度发展。您在这本书中学到的知识不会永远相关，而且这也不是您整个职业生涯所需的所有知识。

幸运的是，有很多免费的在线资源供您使用，以保持最新状态并拓宽您的视野。以下是一些资源。

### 使用 Kaggle 进行实战练习

获取实战经验的有效方法之一是尝试在 Kaggle（[`kaggle.com`](https://kaggle.com)）上参加机器学习竞赛。唯一真正学习的方法是通过实践和实际编码——这正是本书的哲学，而 Kaggle 竞赛是这一哲学的自然延续。在 Kaggle 上，您会发现一系列不断更新的数据科学竞赛，其中许多涉及深度学习，由对获得他们最复杂机器学习问题新解决方案感兴趣的公司准备。为顶尖参赛者提供了相当大的现金奖励。

通过参加几场比赛，也许作为团队的一部分，您将更加熟悉书中描述的一些高级最佳实践的实际应用，特别是超参数调整、避免验证集过拟合和模型集成。

### 在 arXiv 上了解最新的发展

与其他一些科学领域相比，深度学习研究完全在公开中进行。论文在完成之后立即公开和免费提供，许多相关软件也是开源的。arXiv（[`arxiv.org`](https://arxiv.org)）——发音为“archive”（X 代表希腊字母χ）——是一个开放获取的预印本服务器，用于物理、数学和计算机科学研究论文。它已成为了解机器学习和深度学习前沿的既定方式。大多数深度学习研究人员在完成论文后不久就会将其上传到 arXiv。这允许他们在等待会议接受（可能需要几个月）之前就树立一个旗帜并宣布一个特定的发现，这在研究速度快和领域竞争激烈的背景下是必要的。这也使得该领域能够以极快的速度发展：所有新的发现都立即对所有人和所有人可见，并在此基础上进行构建。

一个重要的缺点是，每天在 arXiv 上发布的论文数量巨大，以至于甚至无法浏览它们，而且它们未经同行评审，这使得很难识别出那些既重要又高质量的论文。在噪声中找到信号具有挑战性，而且这种挑战性正在日益增加。但一些工具可以帮助：特别是，你可以使用 Google Scholar ([`scholar.google.com`](https://scholar.google.com))来跟踪你最喜欢的作者发表的论文。

### 探索 Keras 生态系统

截至 2025 年初，Keras 已有超过 250 万用户，并且仍在增长，Keras 拥有庞大的教程、指南和相关开源项目生态系统：

+   你使用 Keras 的主要参考资料是[`keras.io`](https://keras.io)上的在线文档。特别是，你可以在[`keras.io/guides`](https://keras.io/guides)找到广泛的开发者指南，你可以在[`keras.io/examples`](https://keras.io/examples)找到数十个高质量的 Keras 代码示例。务必查看它们！

+   Keras 的源代码可以在[`github.com/keras-team/keras`](https://github.com/keras-team/keras)找到，Keras Hub 可以在[`github.com/keras-team/keras-hub`](https://github.com/keras-team/keras-hub)找到。

+   你可以在 X（前身为 Twitter）上关注弗朗索瓦（@fchollet）和马特（@mattdangerw）。

## 最后的话

这就是《Python 深度学习》的结束！我希望你已经学到了一些关于机器学习、深度学习、Keras，甚至是一般认知的知识。学习是一个终身的旅程，尤其是在人工智能领域，我们手头的未知远多于确定性。所以请继续学习、质疑和研究。永远不要停止。因为即使到目前为止已经取得的进步，人工智能中的许多基本问题仍然没有答案。许多问题甚至还没有得到适当的提出。

### 脚注

1.  理查德·费曼，访谈，*从另一个角度看世界*，约克郡电视台，1972 年 [[↩]](#footnote-link-1)
