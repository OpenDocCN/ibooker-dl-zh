["```py\npip install --upgrade tensorflow_hub\n```", "```py\nimport tensorflow_hub as hub\n```", "```py\nmodel = hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim128/2\")\n```", "```py\nembeddings = model([\"The rain in Spain.\", \"falls\",\n                      \"mainly\", \"In the plain!\"])\n```", "```py\nprint(embeddings.shape)\n```", "```py\n(4, 128)\n```", "```py\nprint(embeddings[0])\n```", "```py\n    import tensorflow as tf\n    import tensorflow_hub as hub\n    import numpy as np\n    import matplotlib.pylab as plt\n    ```", "```py\n    data_dir = tf.keras.utils.get_file(\n        'flower_photos',\n    'https://storage.googleapis.com/download.tensorflow.org/\n    example_images/flower_photos.tgz',\n        untar=True)\n    ```", "```py\n    !ls -lrt /root/.keras/datasets/flower_photos\n    ```", "```py\n    total 620\n    -rw-r----- 1 270850 5000 418049 Feb  9  2016 LICENSE.txt\n    drwx------ 2 270850 5000  45056 Feb 10  2016 tulips\n    drwx------ 2 270850 5000  40960 Feb 10  2016 sunflowers\n    drwx------ 2 270850 5000  36864 Feb 10  2016 roses\n    drwx------ 2 270850 5000  53248 Feb 10  2016 dandelion\n    drwx------ 2 270850 5000  36864 Feb 10  2016 daisy\n    ```", "```py\n    pixels =224\n    BATCH_SIZE = 32\n    IMAGE_SIZE = (pixels, pixels)\n    NUM_CLASSES = 5\n    ```", "```py\n    datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n    dataflow_kwargs = dict(target_size=IMAGE_SIZE, \n    batch_size=BATCH_SIZE,\n    interpolation=\"bilinear\")\n\n    valid_datagen = tf.keras.preprocessing.image.\n    ImageDataGenerator(\n        **datagen_kwargs)\n    valid_generator = valid_datagen.flow_from_directory(\n        data_dir, subset=\"validation\", shuffle=False, \n        **dataflow_kwargs)\n    ```", "```py\n    train_datagen = valid_datagen\n    train_generator = train_datagen.flow_from_directory(\n        data_dir, subset=\"training\", shuffle=True, \n        **dataflow_kwargs)\n    ```", "```py\n    labels_idx = (train_generator.class_indices)\n    idx_labels = dict((v,k) for k,v in labels_idx.items())\n    ```", "```py\n    idx_labels\n\n    {0: 'daisy', 1: 'dandelion', 2: 'roses', 3: 'sunflowers',\n    4: 'tulips'}\n    ```", "```py\nmodel = tf.keras.Sequential([\n     tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\nhub.KerasLayer(\"https://tfhub.dev/google/imagenet/resnet_v1_101/\nfeature_vector/4\", trainable=False),\n     tf.keras.layers.Dense(NUM_CLASSES, activation='softmax', \nname = 'flower_class') \n])\n\nmodel.build([None, 224, 224, 3]) !!C04!!\n```", "```py\nmodel.compile(\n  optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9),\nloss=tf.keras.losses.CategoricalCrossentropy(\nfrom_logits=True, \nlabel_smoothing=0.1),\nmetrics=['accuracy'])\n```", "```py\nsteps_per_epoch = train_generator.samples // \ntrain_generator.batch_size\nvalidation_steps = valid_generator.samples // \nvalid_generator.batch_size\n```", "```py\nmodel.fit(\n    train_generator,\n    epochs=5, steps_per_epoch=steps_per_epoch,\n    validation_data=valid_generator,\n    validation_steps=validation_steps)\n```", "```py\n{0: 'daisy', 1: 'dandelion', 2: 'roses', 3: 'sunflowers', \n4: 'tulips'}\n```", "```py\nsample_test_images, ground_truth_labels = next(valid_generator)\n\nprediction = model.predict(sample_test_images)\n```", "```py\narray([[9.9994004e-01, 9.4704428e-06, 3.8405190e-10, 5.0486942e-05,\n        1.0701914e-08],\n       [5.9500107e-06, 3.1842374e-06, 3.5622744e-08, 9.9999082e-01,\n        3.0683900e-08],\n       [9.9994218e-01, 5.9974178e-07, 5.8693445e-10, 5.7049790e-05,\n        9.6709634e-08],\n       ...,\n       [3.1268091e-06, 9.9986601e-01, 1.5343730e-06, 1.2935932e-04,\n        2.7383029e-09],\n       [4.8439368e-05, 1.9247003e-05, 1.8034354e-01, 1.6394027e-02,\n        8.0319476e-01],\n       [4.9799957e-07, 9.9232978e-01, 3.5823192e-08, 7.6697678e-03,\n        1.7666844e-09]], dtype=float32)\n```", "```py\npredicted_idx = tf.math.argmax(prediction, axis = -1)\n```", "```py\nprint (predicted_idx)\n\n<tf.Tensor: shape=(731,), dtype=int64, numpy=\narray([0, 3, 0, 1, 0, 4, 4, 1, 2, 3, 4, 1, 4, 0, 4, 3, 1, 4, 4, 0,\n       \u2026\n       3, 2, 1, 4, 1])>\n```", "```py\ndef find_label(idx):\n    return idx_labels[idx]\n```", "```py\nfind_label_batch = np.vectorize(find_label)\n```", "```py\nresult = find_label_batch(predicted_idx)\n```", "```py\nimport pandas as pd\npredicted_label = result_class.tolist()\nfile_name = valid_generator.filenames\n\nresults=pd.DataFrame({\"File\":file_name,\n                      \"Prediction\":predicted_label})\n```", "```py\ny_actual = pd.Series(valid_generator.classes)\ny_predicted = pd.Series(predicted_idx)\n```", "```py\npd.crosstab(y_actual, y_predicted, rownames = ['Actual'],\ncolnames=['Predicted'], margins=True)\n```", "```py\nfrom sklearn.metrics import classification_report\nreport = classification_report(truth, predicted_results)\nprint(report)\n              precision    recall  f1-score   support\n\n           0       0.90      0.94      0.92       126\n           1       0.93      0.87      0.90       179\n           2       0.85      0.86      0.85       128\n           3       0.85      0.88      0.86       139\n           4       0.86      0.86      0.86       159\n\n    accuracy                           0.88       731\n   macro avg       0.88      0.88      0.88       731\nweighted avg       0.88      0.88      0.88       731\n```", "```py\nbase_model = tf.keras.applications.ResNet101V2(\ninput_shape = (224, 224, 3), \ninclude_top = False, \nweights = 'imagenet')\n```", "```py\nmodel2 = tf.keras.Sequential([\n  base_model,\n  tf.keras.layers.GlobalAveragePooling2D(),\n  tf.keras.layers.Dense(NUM_CLASSES, \n  activation = 'softmax', \n  name = 'flower_class')\n])\n```", "```py\nmodel2.compile(\n  optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9),\n  loss=tf.keras.losses.CategoricalCrossentropy(\n  from_logits=True, label_smoothing=0.1),\n  metrics=['accuracy']\n)\n\nmodel2.fit(\n    train_generator,\n    epochs=5, steps_per_epoch=steps_per_epoch,\n    validation_data=valid_generator,\n    validation_steps=validation_steps)\n```", "```py\nprint(\"Number of layers in the base model: \", \n       len(base_model.layers))\nbase_model.trainable = True\n\nNumber of layers in the base model:  377\n```", "```py\nfine_tune_at = 370\n\nfor layer in base_model.layers[: fine_tune_at]:\n  layer.trainable = False\n```", "```py\nmodel3 = tf.keras.Sequential([\n  base_model,\n  tf.keras.layers.GlobalAveragePooling2D(),\n  tf.keras.layers.Dense(NUM_CLASSES, \n  activation = 'softmax', \n  name = 'flower_class')\n])\n```", "```py\nmodel3.compile(\n  optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9),\n  loss=tf.keras.losses.CategoricalCrossentropy(\n  from_logits=True, \n  label_smoothing=0.1),\n  metrics=['accuracy']\n)\n```", "```py\nfine_tune_epochs = 5\nsteps_per_epoch = train_generator.samples // \ntrain_generator.batch_size\nvalidation_steps = valid_generator.samples // \nvalid_generator.batch_size\nmodel3.fit(\n    train_generator,\n    epochs=fine_tune_epochs, \n    steps_per_epoch=steps_per_epoch,\n    validation_data=valid_generator,\n    validation_steps=validation_steps)\n```"]