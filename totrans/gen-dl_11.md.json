["```py\nbash scripts/download_kaggle_data.sh nunenuh pytorch-challange-flower-dataset\n```", "```py\ntrain_data = utils.image_dataset_from_directory(\n    \"/app/data/pytorch-challange-flower-dataset/dataset\",\n    labels=None,\n    image_size=(64, 64),\n    batch_size=None,\n    shuffle=True,\n    seed=42,\n    interpolation=\"bilinear\",\n) ![1](Images/1.png)\n\ndef preprocess(img):\n    img = tf.cast(img, \"float32\") / 255.0\n    return img\n\ntrain = train_data.map(lambda x: preprocess(x)) ![2](Images/2.png)\ntrain = train.repeat(5) ![3](Images/3.png)\ntrain = train.batch(64, drop_remainder=True) ![4](Images/4.png)\n```", "```py\ndef linear_diffusion_schedule(diffusion_times):\n    min_rate = 0.0001\n    max_rate = 0.02\n    betas = min_rate + tf.convert_to_tensor(diffusion_times) * (max_rate - min_rate)\n    alphas = 1 - betas\n    alpha_bars = tf.math.cumprod(alphas)\n    signal_rates = alpha_bars\n    noise_rates = 1 - alpha_bars\n    return noise_rates, signal_rates\n\nT = 1000\ndiffusion_times = [x/T for x in range(T)] ![1](Images/1.png)\nlinear_noise_rates, linear_signal_rates = linear_diffusion_schedule(\n    diffusion_times\n) ![2](Images/2.png)\n```", "```py\ndef cosine_diffusion_schedule(diffusion_times): ![1](Images/1.png)\n    signal_rates = tf.cos(diffusion_times * math.pi / 2)\n    noise_rates = tf.sin(diffusion_times * math.pi / 2)\n    return noise_rates, signal_rates\n\ndef offset_cosine_diffusion_schedule(diffusion_times): ![2](Images/2.png)\n    min_signal_rate = 0.02\n    max_signal_rate = 0.95\n    start_angle = tf.acos(max_signal_rate)\n    end_angle = tf.acos(min_signal_rate)\n\n    diffusion_angles = start_angle + diffusion_times * (end_angle - start_angle)\n\n    signal_rates = tf.cos(diffusion_angles)\n    noise_rates = tf.sin(diffusion_angles)\n\n    return noise_rates, signal_rates\n```", "```py\nclass DiffusionModel(models.Model):\n    def __init__(self):\n        super().__init__()\n        self.normalizer = layers.Normalization()\n        self.network = unet\n        self.ema_network = models.clone_model(self.network)\n        self.diffusion_schedule = cosine_diffusion_schedule\n\n    ...\n\n    def denoise(self, noisy_images, noise_rates, signal_rates, training):\n        if training:\n            network = self.network\n        else:\n            network = self.ema_network\n        pred_noises = network(\n            [noisy_images, noise_rates**2], training=training\n        )\n        pred_images = (noisy_images - noise_rates * pred_noises) / signal_rates\n\n        return pred_noises, pred_images\n\n    def train_step(self, images):\n        images = self.normalizer(images, training=True) ![1](Images/1.png)\n        noises = tf.random.normal(shape=tf.shape(images)) ![2](Images/2.png)\n        batch_size = tf.shape(images)[0]\n        diffusion_times = tf.random.uniform(\n            shape=(batch_size, 1, 1, 1), minval=0.0, maxval=1.0\n        ) ![3](Images/3.png)\n        noise_rates, signal_rates = self.cosine_diffusion_schedule(\n            diffusion_times\n        ) ![4](Images/4.png)\n        noisy_images = signal_rates * images + noise_rates * noises ![5](Images/5.png)\n        with tf.GradientTape() as tape:\n            pred_noises, pred_images = self.denoise(\n                noisy_images, noise_rates, signal_rates, training=True\n            ) ![6](Images/6.png)\n            noise_loss = self.loss(noises, pred_noises)  ![7](Images/7.png)\n        gradients = tape.gradient(noise_loss, self.network.trainable_weights)\n        self.optimizer.apply_gradients(\n            zip(gradients, self.network.trainable_weights)\n        ) ![8](Images/8.png)\n        self.noise_loss_tracker.update_state(noise_loss)\n\n        for weight, ema_weight in zip(\n            self.network.weights, self.ema_network.weights\n        ):\n            ema_weight.assign(0.999 * ema_weight + (1 - 0.999) * weight) ![9](Images/9.png)\n\n        return {m.name: m.result() for m in self.metrics}\n\n    ...\n```", "```py\nnoisy_images = layers.Input(shape=(64, 64, 3)) ![1](Images/1.png)\nx = layers.Conv2D(32, kernel_size=1)(noisy_images) ![2](Images/2.png)\n\nnoise_variances = layers.Input(shape=(1, 1, 1)) ![3](Images/3.png)\nnoise_embedding = layers.Lambda(sinusoidal_embedding)(noise_variances) ![4](Images/4.png)\nnoise_embedding = layers.UpSampling2D(size=64, interpolation=\"nearest\")(\n    noise_embedding\n) ![5](Images/5.png)\n\nx = layers.Concatenate()([x, noise_embedding]) ![6](Images/6.png)\n\nskips = [] ![7](Images/7.png)\n\nx = DownBlock(32, block_depth = 2)([x, skips]) ![8](Images/8.png)\nx = DownBlock(64, block_depth = 2)([x, skips])\nx = DownBlock(96, block_depth = 2)([x, skips])\n\nx = ResidualBlock(128)(x) ![9](Images/9.png)\nx = ResidualBlock(128)(x)\n\nx = UpBlock(96, block_depth = 2)([x, skips]) ![10](Images/10.png)\nx = UpBlock(64, block_depth = 2)([x, skips])\nx = UpBlock(32, block_depth = 2)([x, skips])\n\nx = layers.Conv2D(3, kernel_size=1, kernel_initializer=\"zeros\")(x) ![11](Images/11.png)\n\nunet = models.Model([noisy_images, noise_variances], x, name=\"unet\") ![12](Images/12.png)\n```", "```py\ndef sinusoidal_embedding(x):\n    frequencies = tf.exp(\n        tf.linspace(\n            tf.math.log(1.0),\n            tf.math.log(1000.0),\n            16,\n        )\n    )\n    angular_speeds = 2.0 * math.pi * frequencies\n    embeddings = tf.concat(\n        [tf.sin(angular_speeds * x), tf.cos(angular_speeds * x)], axis=3\n    )\n    return embeddings\n```", "```py\ndef ResidualBlock(width):\n    def apply(x):\n        input_width = x.shape[3]\n        if input_width == width: ![1](Images/1.png)\n            residual = x\n        else:\n            residual = layers.Conv2D(width, kernel_size=1)(x)\n        x = layers.BatchNormalization(center=False, scale=False)(x) ![2](Images/2.png)\n        x = layers.Conv2D(\n            width, kernel_size=3, padding=\"same\", activation=activations.swish\n        )(x) ![3](Images/3.png)\n        x = layers.Conv2D(width, kernel_size=3, padding=\"same\")(x)\n        x = layers.Add()([x, residual]) ![4](Images/4.png)\n        return x\n\n    return apply\n```", "```py\ndef DownBlock(width, block_depth):\n    def apply(x):\n        x, skips = x\n        for _ in range(block_depth):\n            x = ResidualBlock(width)(x) ![1](Images/1.png)\n            skips.append(x) ![2](Images/2.png)\n        x = layers.AveragePooling2D(pool_size=2)(x) ![3](Images/3.png)\n        return x\n\n    return apply\n\ndef UpBlock(width, block_depth):\n    def apply(x):\n        x, skips = x\n        x = layers.UpSampling2D(size=2, interpolation=\"bilinear\")(x) ![4](Images/4.png)\n        for _ in range(block_depth):\n            x = layers.Concatenate()([x, skips.pop()]) ![5](Images/5.png)\n            x = ResidualBlock(width)(x) ![6](Images/6.png)\n        return x\n\n    return apply\n```", "```py\nmodel = DiffusionModel() ![1](Images/1.png)\nmodel.compile(\n    optimizer=optimizers.experimental.AdamW(learning_rate=1e-3, weight_decay=1e-4),\n    loss=losses.mean_absolute_error,\n) ![2](Images/2.png)\n\nmodel.normalizer.adapt(train) ![3](Images/3.png)\n\nmodel.fit(\n    train,\n    epochs=50,\n) ![4](Images/4.png)\n```", "```py\nclass DiffusionModel(models.Model):\n\n...\n\n    def reverse_diffusion(self, initial_noise, diffusion_steps):\n        num_images = initial_noise.shape[0]\n        step_size = 1.0 / diffusion_steps\n        current_images = initial_noise\n        for step in range(diffusion_steps): ![1](Images/1.png)\n            diffusion_times = tf.ones((num_images, 1, 1, 1)) - step * step_size ![2](Images/2.png)\n            noise_rates, signal_rates = self.diffusion_schedule(diffusion_times) ![3](Images/3.png)\n            pred_noises, pred_images = self.denoise(\n                current_images, noise_rates, signal_rates, training=False\n            ) ![4](Images/4.png)\n            next_diffusion_times = diffusion_times - step_size ![5](Images/5.png)\n            next_noise_rates, next_signal_rates = self.diffusion_schedule(\n                next_diffusion_times\n            ) ![6](Images/6.png)\n            current_images = (\n                next_signal_rates * pred_images + next_noise_rates * pred_noises\n            ) ![7](Images/7.png)\n        return pred_images ![8](Images/8.png)\n```", "```py\nclass DiffusionModel(models.Model):\n\n...\n\n    def denormalize(self, images):\n        images = self.normalizer.mean + images * self.normalizer.variance**0.5 ![1](Images/1.png)\n        return tf.clip_by_value(images, 0.0, 1.0)\n\n    def generate(self, num_images, diffusion_steps):\n        initial_noise = tf.random.normal(shape=(num_images, 64, 64, 3)) ![1](Images/1.png)\n        generated_images = self.reverse_diffusion(initial_noise, diffusion_steps) ![2](Images/2.png)\n        generated_images = self.denormalize(generated_images) ![3](Images/3.png)\n        return generated_images\n```"]