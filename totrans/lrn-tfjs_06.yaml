- en: Chapter 5\. Introducing Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: “Where does he get those wonderful toys?”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: —Jack Nicholson (*Batman*)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Now you’re in the big leagues. Way back in [Chapter 2](ch02.html#the_chapter_2)
    you accessed a fully trained model, but you didn’t need to understand tensors
    at all. Here in [Chapter 5](#the_chapter_5), you will get to utilize your tensor
    skills to work directly with your models, with no training wheels.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you’re going to dive into utilizing the brain of most machine learning.
    Models can seem like a black box. Generally, they expect a specific tensor shape
    in, and a specific tensor shape comes out. For instance, let’s say you’ve trained
    a dog or cat classifier. The input might be a 32 x 32 3D RGB tensor, and the output
    might be a single tensor value of zero to one to indicate the prediction. Even
    if you don’t know the inner workings of such a device, at the least, consuming
    and utilizing models with a defined structure should be simple.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will:'
  prefs: []
  type: TYPE_NORMAL
- en: Utilize trained models to predict a variety of answers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identify the benefits of our existing tensor manipulation skills
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn about Google’s TFHub.dev hosting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn about object localization
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learn how to overlay a bounding box to identify some aspect of an image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter will teach you direct access to models. You won’t be dependent
    on cute wrapper libraries for coddling. If you want, you’ll even be able to write
    your own wrapper library around existing TensorFlow.js models. Armed with the
    skills in this chapter, you can start applying breakthrough machine learning models
    to any website.
  prefs: []
  type: TYPE_NORMAL
- en: Loading Models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We know we need to get our models into memory and preferably into GPU-accelerated
    memory like tensors, but from where? As a blessing and a curse, the answer is
    “anywhere!” Loading files is common in software, so it corresponds to a variety
    of answers in TensorFlow.js.
  prefs: []
  type: TYPE_NORMAL
- en: To compound this problem, TensorFlow.js supports two different model formats.
    Fortunately, this assortment of options isn’t complicated. You just need to know
    what kind of model you need and from where you’ll be accessing it.
  prefs: []
  type: TYPE_NORMAL
- en: Currently, there are two model types in TensorFlow.js, each with their own benefits
    and costs. The simplest and most extensible model is called a *Layers model*.
    This model format lets you inspect, modify, and even take a model apart for adjustment.
    The format is perfect for retuning and adjusting later. The other model format
    is a *Graph model*. Graph models are generally more optimized as well as computationally
    efficient. The cost of using a Graph model is that the model is even more “black
    box,” and due to its optimizations, it’s more difficult to inspect or modify.
  prefs: []
  type: TYPE_NORMAL
- en: Model types are simple. If you’re loading a Layers model, you’ll need to use
    the method `loadLayersModel`, and if you’re loading a GraphDef model, you’ll need
    to use the method `loadGraphModel`. There are benefits and drawbacks to these
    two model types, but that’s beyond the scope of this chapter. The key takeaway
    is that there’s little complexity in loading the desired model type; it’s just
    a question of which type and then using the corresponding method. The most important
    facet is the first parameter, which is the location of the model data.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: By the end of this book, you’ll have a pretty solid understanding of the critical
    differences between a Layers and a Graph model type. Each time a model is introduced,
    take note of which one was used.
  prefs: []
  type: TYPE_NORMAL
- en: This section explains the diversity of options for model locations and the simple
    unifying URI syntax that binds them.
  prefs: []
  type: TYPE_NORMAL
- en: Loading Models Via Public URL
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Loading models with a public URL is the most common method of accessing a model
    in TensorFlow.js. As you remember in [Chapter 2](ch02.html#the_chapter_2), when
    you loaded the Toxicity detection model, you downloaded several shards of the
    file in small 4 MB cacheable chunks from a public network. The model knew the
    location of the file to download. This is done with a single URL to a single file.
    The model file that was originally requested was a simple JavaScript Object Notation
    (JSON) file, and the subsequent files were weights for the neural network that
    were identified from that JSON file.
  prefs: []
  type: TYPE_NORMAL
- en: 'Loading TensorFlow.js models from a URL requires actively hosted adjacent model
    files (the same relative folder). This means that once you give a path for a model’s
    JSON file, it usually references the weights in successive files at the same directory
    level. The desired structure looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Moving or denying access to these extra files will cause your model to be unusable
    and error. Depending on the security and configuration of your server environment,
    this can be a bit of a sticking point. Therefore, you should always verify that
    each file has proper URL access.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We’ve covered three major ways to run TensorFlow.js so far. They are simple
    hosted with 200 OK!, NPM packed with Parcel, and server hosted with Node.js. Before
    we tell you how to properly load models for these situations, can you identify
    which of these will have complications?
  prefs: []
  type: TYPE_NORMAL
- en: 200 OK! Web Server for Chrome examples will have no issues because everything
    in the folder is hosted with no optimization or security. Parcel gives us some
    bells and whistles with transforms, error logging, HMR, and bundling. With those
    features, our JSON and weight files are not passed into the distribution, aka
    `dist` folder, without some coaching.
  prefs: []
  type: TYPE_NORMAL
- en: In Parcel.js 2.0 (which is not officially out at the time of this writing),
    you’ll have more options for static files, but for now, there is a simple solution
    that works for Parcel 1.x that we’ll be using. You can install a plug-in called
    `parcel-plugin-static-files-copy` to green-light model files for local static
    hosting. The code used in the associated repo for this book utilizes this plug-in.
  prefs: []
  type: TYPE_NORMAL
- en: The plug-in works by effectively making any files placed in the `static` directory
    publicly accessible from the root URL. For example, a *model.json* file placed
    in *static/model* would be accessible as *localhost:1234/model/model.json*.
  prefs: []
  type: TYPE_NORMAL
- en: Whatever web solution you use, you’ll need to verify that the security and bundling
    of the model files work for you. For unprotected public folders, this is as simple
    as uploading all the files to services like Amazon Web Services (AWS) and Simple
    Storage Service (S3). You’ll need to make the entire bucket public, or each adjacent
    file will have to explicitly be made public. It’s important to verify you can
    access the JSON *and* the BIN files. The error messages for missing or restricted
    shards of a model are perplexing. You’ll see a `404`, but errors continue on to
    a secondary and more cryptic error like that shown in [Figure 5-1](#no_file).
  prefs: []
  type: TYPE_NORMAL
- en: '![Screenshot of the error of missing bin files.](assets/ltjs_0501.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5-1\. Error: JSON available but no bin files'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Create React App is a popular tool for simple React websites. If you use Create
    React App, files in the `public` folder will be accessible from the root URL out
    of the box. Think of `public` like our Parcel solution’s `static` folder. Both
    work great and have been tested for model hosting.
  prefs: []
  type: TYPE_NORMAL
- en: Loading Models from Other Locations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Models don’t have to be in public URLs. TensorFlow has methods to allow you
    to load from [local browser storage](https://oreil.ly/BHYc1), [IndexedDB storage](https://oreil.ly/MHYA4),
    and, in the case of Node.js, local filesystem access to model files.
  prefs: []
  type: TYPE_NORMAL
- en: One significant benefit of this is that you can locally cache a model you loaded
    from a public URL so your app can be offline-ready. Other reasons include speed,
    security, or simply because you can.
  prefs: []
  type: TYPE_NORMAL
- en: Browser files
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Local browser storage and IndexedDB storage are two web APIs for saving files
    specified to a particular page. Unlike cookies, which store a small piece of data
    like a single variable, `Window.localStorage` and the IndexedDB API are client-side
    storage capable of handling files among other significant structured data across
    browser sessions.
  prefs: []
  type: TYPE_NORMAL
- en: Public URLs have the `http` and `https` schemes; however, these methods utilize
    different schemes in the URI. To load a model from local storage, you would use
    a `localstorage://model-name` URI, and to load a model from IndexedDB, you would
    use a `indexeddb://model-name` URI.
  prefs: []
  type: TYPE_NORMAL
- en: Besides the supplied methods, there’s no limit to the various locations you
    can store and retrieve a TensorFlow.js model. At the end of the day, it’s just
    data that you need, so you can load a model with any custom `IOHandler`. For instance,
    there has even been [proof-of-concept work on converting models completely to
    JSON files](https://github.com/infinitered/tfjs-runway) with the weights encoded
    so you can call `require` as needed from any location, even via a bundler.
  prefs: []
  type: TYPE_NORMAL
- en: Filesystem files
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To access files on a filesystem, you’ll need to use a Node.js server that has
    permission to get at the desired files. Browsers are sandboxed and cannot currently
    use this feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fortunately, it’s similar to the previous API. Use the *file:* scheme to identify
    a path to a given file like so: *[*file://path/to/model.json*](file://path/to/model.json).*
    Just like in the browser examples, the ancillary files must be in the same folder
    and accessible.'
  prefs: []
  type: TYPE_NORMAL
- en: Our First Consumed Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you’re familiar with the mechanics of loading a model into memory,
    you can utilize models in your projects. This was automated for you when you used
    the Toxicity model in [Chapter 2](ch02.html#the_chapter_2), but now, with your
    familiarity with tensors and model access, you can handle a model without all
    the protective package code.
  prefs: []
  type: TYPE_NORMAL
- en: You need a simple model to use for the first example. As you recall, you encoded
    a board of tic-tac-toe as an exercise in [Chapter 3](ch03.html#the_chapter_3).
    Let’s build from the foundation of your existing knowledge and not only encode
    a tic-tac-toe match but also pass that information into a trained model for analysis.
    The trained model will then predict and return an answer for the best next move.
  prefs: []
  type: TYPE_NORMAL
- en: Your goal for this section will be to ask the AI model what moves it recommends
    for the three board states illustrated in [Figure 5-2](#ttt_states).
  prefs: []
  type: TYPE_NORMAL
- en: '![Three example game states](assets/ltjs_0502.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-2\. Three game states
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Each of these games is in a different situation:'
  prefs: []
  type: TYPE_NORMAL
- en: Scenario A
  prefs: []
  type: TYPE_NORMAL
- en: This is blank and allows the AI to make the first move.
  prefs: []
  type: TYPE_NORMAL
- en: Scenario B
  prefs: []
  type: TYPE_NORMAL
- en: This is O’s turn, and we expect the AI to block the potential loss by playing
    in the top-right square.
  prefs: []
  type: TYPE_NORMAL
- en: Scenario C
  prefs: []
  type: TYPE_NORMAL
- en: This is X’s move, and we expect the AI to move in the top-middle and claim victory!
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see what the AI recommends, by encoding these three states and printing
    the output of the model.
  prefs: []
  type: TYPE_NORMAL
- en: Loading, Encoding, and Asking a Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You’ll be using the simple URL for loading the model. This model will be a Layers
    model. That means you will use `tf.loadLayersModel` and the path to the locally
    hosted model files to load. For this example, the model file will be hosted at
    *model/ttt_model.json*.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The trained tic-tac-toe model for this example can be accessed in the associated
    [GitHub](https://github.com/GantMan/learn-tfjs) for this book. The JSON file is
    2 KB, and the weights file (*ttt_model.weights.bin*) is 22 KB in size. This 24
    KB load for a tic-tac-toe solver isn’t bad at all!
  prefs: []
  type: TYPE_NORMAL
- en: To transcribe the game board state, there will be a slight difference in encoding.
    You’ll need to tell the AI which team it’s playing for. You’ll also need an AI
    that can be X and O agnostic. Because scenario B is asking the AI for advice on
    O and not X, we need a flexible system for encoding. Instead of X always meaning
    1, assign the AI to 1 and the adversary to -1\. This way we can put the AI in
    a situation where it’s playing X or O. [Table 5-1](#tictactoe_value_table) shows
    each possible value for the lookup.
  prefs: []
  type: TYPE_NORMAL
- en: Table 5-1\. Grid-to-number conversion
  prefs: []
  type: TYPE_NORMAL
- en: '| Board value |  | Tensor value |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AI |  | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| Opponent |  | -1 |'
  prefs: []
  type: TYPE_TB
- en: '| Empty |  | 0 |'
  prefs: []
  type: TYPE_TB
- en: All three games need to be encoded and then stacked into a single tensor to
    pass to the AI model. The model then supplies three answers, one for each situation.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the full process:'
  prefs: []
  type: TYPE_NORMAL
- en: Load the model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Encode the three separate game states.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Stack the states into a single tensor.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ask the model to print the results.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Stacking input to a model is a common practice and allows your model to handle
    any number of predictions in accelerated memory.
  prefs: []
  type: TYPE_NORMAL
- en: Stacking increases the dimensionality of the result. Performing this action
    on 1D tensors creates a 2D tensor, and so on. In this instance, you have three
    board states represented in 1D tensors, so stacking them will create a `[3, 9]`
    rank-two tensor. Most models support stacking or batching for their input, and
    the output will be similarly stacked with matching answers to the input indices.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code, which can be found at [*chapter5/simple/simple-ttt-model* in the
    GitHub repo](https://oreil.ly/38zZx), looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_introducing_models_CO1-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Use `tf.ready`, which resolves when TensorFlow.js is ready. No DOM access is
    needed.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_introducing_models_CO1-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Though the model is two files, only the JSON file needs to be identified. It
    knows about and loads any additional model files.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_introducing_models_CO1-3)'
  prefs: []
  type: TYPE_NORMAL
- en: The `loadLayersModel` model resolves with the fully loaded model.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_introducing_models_CO1-4)'
  prefs: []
  type: TYPE_NORMAL
- en: An empty board is nine zeros, which represents scenario A.
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](assets/5.png)](#co_introducing_models_CO1-5)'
  prefs: []
  type: TYPE_NORMAL
- en: Encoded as X equal to `-1` for scenario B.
  prefs: []
  type: TYPE_NORMAL
- en: '[![6](assets/6.png)](#co_introducing_models_CO1-6)'
  prefs: []
  type: TYPE_NORMAL
- en: Encoded as X equal to `1` for scenario C.
  prefs: []
  type: TYPE_NORMAL
- en: '[![7](assets/7.png)](#co_introducing_models_CO1-7)'
  prefs: []
  type: TYPE_NORMAL
- en: Use `tf.stack` to combine three 1D tensors into a single 2D tensor.
  prefs: []
  type: TYPE_NORMAL
- en: '[![8](assets/8.png)](#co_introducing_models_CO1-8)'
  prefs: []
  type: TYPE_NORMAL
- en: Use `.predict` to ask the model to identify the best next moves.
  prefs: []
  type: TYPE_NORMAL
- en: '[![9](assets/9.png)](#co_introducing_models_CO1-9)'
  prefs: []
  type: TYPE_NORMAL
- en: The original output was going to be shaped as `[3, 9]`, but it’s a good situation
    where reshaping the output makes it more readable. Print the result in three 3
    x 3 grids so we can read them like game boards.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: When using `loadLayersModel` and even `loadGraphModel`, the TensorFlow.js library
    is depending on the presence of the `fetch` web API. If you’re using this method
    in Node.js, you’ll need to polyfill `fetch` with a package like [node-fetch](https://oreil.ly/rwPMW).
  prefs: []
  type: TYPE_NORMAL
- en: The aforementioned code successfully converts the three matches to tensors in
    a format that the AI model expects, and then runs these values through the model’s
    `predict()` method for analysis. The results are printed to the console and look
    like what we see in [Figure 5-3](#ttt_result).
  prefs: []
  type: TYPE_NORMAL
- en: '![Result of tic-tac-toe model](assets/ltjs_0503.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-3\. The resulting [3, 3, 3] shaped tensor from our code
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The method that does all the magic is the model’s `predict()` function. The
    function lets the model know to generate output predictions for the given input.
  prefs: []
  type: TYPE_NORMAL
- en: Interpreting the Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For some people this resulting tensor makes complete sense, and for others,
    you might need a moment of context. The resulting answers are again in probabilities
    of the next best moves. The highest number wins.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this to be a proper probability, the answers need to sum up to 100%, and
    they do. Let’s take a look at the empty tic-tac-toe board result shown here in
    scenario 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: If you were to be silly like me and enter these nine values into your calculator
    (TI-84 Plus CE for life!), they would sum up to the number 1\. That means each
    corresponding value is a percentage vote for that spot. We can see the four corners
    all have a significant (nearly 25%) portion of the result. This makes sense, because
    strategically starting in a corner is the best move possible in tic-tac-toe, followed
    by the middle, which has the next highest value.
  prefs: []
  type: TYPE_NORMAL
- en: 'Because the bottom right has 27% of the vote, this would be the AI’s most likely
    move. Let’s see how the AI performs in another scenario. If you recall, in scenario
    B from [Figure 5-2](#ttt_states), the AI would need to move in the top right to
    block. The resulting tensor from the AI is shown here in scenario 2:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The top-right value is 99%, so the model has correctly blocked the given threat.
    One funny aspect of a machine learning model is that the other moves still have
    values, including spaces that are already taken.
  prefs: []
  type: TYPE_NORMAL
- en: 'The last scenario was an encoded tensor to see if the model would strike and
    win tic-tac-toe. The results are shown here in scenario 3 of the predicted batch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The result is 99% (rounded) certain that top middle is the best move, which
    is correct. No other move even comes close. All three predicted results seem to
    be not only functioning moves, but also the correct move for a given state.
  prefs: []
  type: TYPE_NORMAL
- en: You have successfully loaded and interacted with a model to have it provide
    results. With the skills you just attained, you could write your own tic-tac-toe
    game app. I imagine there’s not much demand for tic-tac-toe games on the internet,
    but if provided a trained model of the same structure, you could use the AI to
    make all kinds of games!
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Most models will have some associated documentation to help you identify the
    proper inputs and outputs, but Layers models have properties that you can access
    if you need help. The expected input shape can be seen at `model.input.shape`,
    and the output can be seen at `model.outputShape`. These properties do not exist
    on Graph models.
  prefs: []
  type: TYPE_NORMAL
- en: Cleaning the Board After
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The TensorFlow.js model in this example is wrapped in a `tidy` and will automatically
    free memory after the code has completed. In most situations, you will not be
    done with your model so quickly. It’s important to note that you must call `.dispose()`
    on models, just like you do tensors. Models are accelerated the same way, and
    therefore they have the same cleanup cost.
  prefs: []
  type: TYPE_NORMAL
- en: Reloading web pages tends to clear tensors, but long-running Node.js servers
    will have to monitor and verify that tensors and models are disposed of.
  prefs: []
  type: TYPE_NORMAL
- en: Our First TensorFlow Hub Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now that you’ve properly encoded, loaded, and processed a small amount of data
    through a custom model, you should take a moment to push the envelope. In this
    section, you’ll load a significantly larger model from TensorFlow Hub, and you’ll
    process an image. Tic-tac-toe was an input of nine values, whereas most images
    are tensors with thousands of values.
  prefs: []
  type: TYPE_NORMAL
- en: The model you’ll be loading will be one of the biggest and most impressive models
    out there, Inception v3\. The Inception model is an impressive network first created
    in 2015\. This third version has been, impressively, trained on hundreds of thousands
    of images. Weighing in at a whopping 91.02 MB, this model can classify 1,001 different
    objects. The MobileNet-wrapped NPM package from the Chapter Challenge in [Chapter 2](ch02.html#the_chapter_2)
    is awesome, but not nearly as powerful as what you’re about to use.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring TFHub
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Google has begun hosting models like Inception v3 for free on its own CDN.
    In situations for this large model size, it’s quite useful to have a reliable
    and impressive versioned CDN for models like we often do for JavaScript. You can
    access hundreds of trained and ready-to-go models for TensorFlow and TensorFlow.js
    in one location at [*https://tfhub.dev*](https://tfhub.dev). TensorFlow.js has
    a special way to identify when your model is hosted on TFHub; we just add `{ fromTFHub:
    true }` to our configuration after we’ve identified our model URL.'
  prefs: []
  type: TYPE_NORMAL
- en: As you peruse TFHub, you can see a variety of publishers and explanations for
    each model. These explanations are critical, because as we’ve already identified,
    models are quite specific on what they expect for input and what they will supply
    for output. We can learn more about Inception v3 on [its associated TFHub page](https://oreil.ly/Utstp).
    This model was built by Google, and the version it provides has been extensively
    trained. If you’re hungry for more information, it’s not a bad idea to scan through
    the [published paper on the model](https://arxiv.org/abs/1512.00567).
  prefs: []
  type: TYPE_NORMAL
- en: 'On the TFHub page, you get both of those critical insights for using a model.
    First, the expected input image sizes should be 299 x 299, have values `0-1`,
    and be batched just like we did in the previous tic-tac-toe example. Second, the
    result that the model returns is a single-dimensional tensor with 1,001 values,
    with the largest being the most likely (similar to the nine values returned by
    tic-tac-toe). It might sound confusing, but the page uses some statistics-based
    terminology to express this:'
  prefs: []
  type: TYPE_NORMAL
- en: The output is a batch of logits vectors. The indices into the logits are the
    num_classes = 1001 classes of the classification from the original training.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Returning a numeric result is useful, but as always, we have to map this back
    to a useful label. In tic-tac-toe we mapped the index to a location on the board,
    and in this case, we map the index of a value to the corresponding label that
    follows the same index. The TFHub page [shares a TXT file](https://oreil.ly/bzUeD)
    of all the necessary labels in their correct order, which you will use to create
    an array to interpret the predicted results.
  prefs: []
  type: TYPE_NORMAL
- en: Wiring Up Inception v3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now you know the Inception v3 model classifies photos, and you have the input
    and output specification. It’s like a larger version of the tic-tac-toe problem.
    However, there will be new hurdles. For instance, printing 1,001 numbers won’t
    be helpful information. You’ll need to use `topk` to parse the giant tensor back
    into a useful context.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code is available in the [*chapter5/simple/simple-tfhub* in the
    GitHub repo](https://oreil.ly/X7TpN) folder. The code depends on a mysterious
    image that has the `id` `mystery`. Ideally, the AI can solve the mystery for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#comarker1)'
  prefs: []
  type: TYPE_NORMAL
- en: This is the URL to the TFHub for the Inception model.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#comarker2)'
  prefs: []
  type: TYPE_NORMAL
- en: Load the graph model and set `fromTFHub` to true.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#comarker3)'
  prefs: []
  type: TYPE_NORMAL
- en: The image is resized to 299 x 299.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#comarker4)'
  prefs: []
  type: TYPE_NORMAL
- en: Convert the `fromPixels` results to values between 0 and 1 (normalizing the
    data).
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](assets/5.png)](#comarker5)'
  prefs: []
  type: TYPE_NORMAL
- en: Convert the 3D tensor to a single batch 4D tensor like the model expects.
  prefs: []
  type: TYPE_NORMAL
- en: '[![6](assets/6.png)](#comarker6)'
  prefs: []
  type: TYPE_NORMAL
- en: Predict on the image.
  prefs: []
  type: TYPE_NORMAL
- en: '[![7](assets/7.png)](#comarker7)'
  prefs: []
  type: TYPE_NORMAL
- en: The print is so big it gets trimmed.
  prefs: []
  type: TYPE_NORMAL
- en: '[![8](assets/8.png)](#comarker8)'
  prefs: []
  type: TYPE_NORMAL
- en: Recover the top three values as our guesses.
  prefs: []
  type: TYPE_NORMAL
- en: '[![9](assets/9.png)](#comarker9)'
  prefs: []
  type: TYPE_NORMAL
- en: Print the top three prediction indices.
  prefs: []
  type: TYPE_NORMAL
- en: '[![10](assets/10.png)](#comarker10)'
  prefs: []
  type: TYPE_NORMAL
- en: Map the indices to their labels and print them. `INCEPTION_CLASSES` is an array
    of labels that maps to the model output.
  prefs: []
  type: TYPE_NORMAL
- en: In the associated code for this chapter, you’ll find three images that you can
    set as the mystery image in this section. Inception v3 impressively identifies
    all three correctly. Take a look at the captured results in [Figure 5-4](#tape_player).
  prefs: []
  type: TYPE_NORMAL
- en: '![Inception correctly identifying a tape player](assets/ltjs_0504.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-4\. Resulting classification of an image from Inception v3
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see from the photo, Inception’s first choice was a “tape player,”
    which I would say is very accurate. Second, it saw a “cassette player,” and to
    be honest I don’t know how that’s different from a “tape player,” but I’m no mega-model.
    Lastly, the third highest value was a “radio,” which is what I would have said.
  prefs: []
  type: TYPE_NORMAL
- en: It’s not often you need a large model like this, but as new models get added
    to TFHub, you know you have options. Peruse the existing models every so often.
    You’ll see quite a few on image classification. Classifying images is one of the
    more impressive tasks of beginning AI, but why stop there?
  prefs: []
  type: TYPE_NORMAL
- en: Our First Overlayed Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, the models you’ve been working with have simple output. Tic-tac-toe
    identified your next move, Inception classified a photo, and just to round things
    out, you’ll implement a classic visual effect in movies that feature AI, the bounding
    box that identifies an object in a photo. Rather than classifying an entire photo,
    the AI highlights a specific bounding box within a photo, like in [Figure 5-5](#detection).
  prefs: []
  type: TYPE_NORMAL
- en: '![A bounding box for a balloon image](assets/ltjs_0505.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-5\. Bounding box overlay
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Normally, the bounding box output of a model is fairly complex because it handles
    a variety of classes and overlapping boxes. Usually, the model leaves you to use
    some math to properly clean up the results. Rather than dealing with that, let’s
    just focus on drawing a single rectangle on predicted output in TensorFlow.js.
    This is sometimes called *object localization*.
  prefs: []
  type: TYPE_NORMAL
- en: The model for this final exercise will be a pet face detector. The model will
    do its best to give us a bounding set of coordinates for where it thinks the pet’s
    face is located. It’s not generally hard to talk people into looking at cute dogs
    and cats, but this model could have all kinds of applications. Once you have the
    location of a pet’s face, you could use that data to train additional models,
    like recognizing pets or checking if their cute noses need a boop. You know…science!
  prefs: []
  type: TYPE_NORMAL
- en: The Localization Model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This model was trained on a public dataset called the [Oxford-IIIT Pet Dataset](https://oreil.ly/Pz0D9).
    The small, 2-ish MB model expects a 256 x 256 `Float32` input RGB image of a pet
    and outputs four numbers to identify a bounding box around the pet’s face. The
    four numbers in the 1D tensor are the top-left point and the bottom-right point.
  prefs: []
  type: TYPE_NORMAL
- en: The points are represented as values between 0 and 1, as a percentage of the
    image. You can define a rectangle with the model result information, as shown
    in [Figure 5-6](#result_points).
  prefs: []
  type: TYPE_NORMAL
- en: '![Display of how 4 values become two points](assets/ltjs_0506.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-6\. Four values into two points
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The beginning of the code will be similar to the previous code. You’ll start
    off by converting the image to a tensor and running it through the model. The
    following code can be found in [*chapter5/simple/simple-object-localization* in
    the GitHub repo](https://oreil.ly/zkSfM).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Labeling the Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now you can draw the result coordinates as a rectangle over the image. Drawing
    detections is a common task in TensorFlow.js. The basics of drawing a tensor result
    over an image require you to place the image in a container and then position
    an absolute canvas over that image. Now when you draw to the canvas, you’ll be
    drawing over the image.^([1](ch05.html#idm45049246250312)) From a side view, the
    layout will resemble [Figure 5-7](#canvas_overlay).
  prefs: []
  type: TYPE_NORMAL
- en: '![3D view of DOM](assets/ltjs_0507.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-7\. Stacking view of the canvas
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'For this lesson, the CSS has been embedded directly in the HTML for ease. The
    image and canvas layout looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_introducing_models_CO2-1)'
  prefs: []
  type: TYPE_NORMAL
- en: The containing `div` is relative positioned and locked at 80% the page height.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_introducing_models_CO2-2)'
  prefs: []
  type: TYPE_NORMAL
- en: The canvas is placed over the image with an absolute position.
  prefs: []
  type: TYPE_NORMAL
- en: For a simple rectangle, you can use the canvas context’s `strokeRect` method.
    The `strokeRect` method doesn’t take two points like the model returns. It takes
    a starting point and then a width and height. To convert the model points to width
    and height, you can just subtract each vertex to get a distance. [Figure 5-8](#width_calculation)
    shows a visual representation of this calculation.
  prefs: []
  type: TYPE_NORMAL
- en: '![calculating width and height explanation](assets/ltjs_0508.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-8\. Width and height are calculated as the difference between Xs and
    Ys
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Armed with the starting point, the width and height of the overlaid rectangle,
    you can draw it to scale on the canvas with a few lines of code. Remember, the
    tensor output is a percentage and will need to be scaled in each dimension.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_introducing_models_CO3-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Make the detection canvas the same size as the image it’s over.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_introducing_models_CO3-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Grab the bounding box result.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_introducing_models_CO3-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Scale the starting point X and Y back to the image.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_introducing_models_CO3-4)'
  prefs: []
  type: TYPE_NORMAL
- en: Find the width of the box by subtracting X[1] from X[2] and then scaling it
    by the image width. The same goes for Y[1] and Y[2].
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](assets/5.png)](#co_introducing_models_CO3-5)'
  prefs: []
  type: TYPE_NORMAL
- en: Now use the canvas 2D context to draw the desired rectangle.
  prefs: []
  type: TYPE_NORMAL
- en: The result is a perfectly placed bounding box at the given points. See for yourself
    in [Figure 5-9](#pet_faces).
  prefs: []
  type: TYPE_NORMAL
- en: '![Identifying pet face locations](assets/ltjs_0509.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-9\. Pet face localization
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: A misconception when running this project might be that the detection and drawing
    you’ve experienced are slow. This is false. It’s noticeable that when the page
    loads, there’s a delay before the bounding box appears; however, the delay you’re
    experiencing includes loading a model and loading it into accelerated memory of
    some type (sometimes called *model warmup*). Though doing so is a bit outside
    the goals of this chapter, if you were to call `model.predict` and draw again,
    you would see results in microseconds. The canvas + TensorFlow.js structure you
    created in this final section can easily support 60+ frames per second on a desktop
    computer.
  prefs: []
  type: TYPE_NORMAL
- en: Models that have plenty of bounding boxes and labels use similar `strokeRect`
    calls to outline the location of identified objects. There’s a wide variety of
    models, and each of them identify various aspects of images. The practice of modifying
    the canvas to draw information over an image comes in handy in the TensorFlow.js
    world.
  prefs: []
  type: TYPE_NORMAL
- en: Chapter Review
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Knowing the input and output of models is key. In this chapter, you finally
    saw data all the way through. You converted input, passed it into a trained model,
    and interpreted the results. Models can take a wide array of inputs and provide
    equally wide outputs. Now, regardless of what a model requires, you have some
    impressive experience to draw from.
  prefs: []
  type: TYPE_NORMAL
- en: 'Chapter Challenge: Cute Faces'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine our pet face localization was the first step in a larger process. Let’s
    pretend you were identifying pet faces to then pass the pet’s face to another
    model that would look for a tongue to see if the pet was hot and panting. It’s
    common to organize multiple models in a pipeline like this, with each tuned to
    their own specific purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Given a pet’s face location from the previous code, write the additional code
    to extract the pet’s face and prep it for a model that requires a 96 x 96 image
    input. Your answer will be a single batched crop like [Figure 5-10](#pup_face).
  prefs: []
  type: TYPE_NORMAL
- en: '![Just the face of the dog](assets/ltjs_0510.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5-10\. The goal [1, 96, 96, 3] tensor of just the face
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Though this exercise is to crop the pet’s face for a secondary model, it could
    just as easily have been a “pet anonymizer” that required you to blur the pet’s
    face. The applications of AI in the browser are limitless.
  prefs: []
  type: TYPE_NORMAL
- en: You can find the answer to this challenge in [Appendix B](app02.html#appendix_b).
  prefs: []
  type: TYPE_NORMAL
- en: Review Questions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s review the lessons you’ve learned from the code you’ve written in this
    chapter. Take a moment to answer the following questions:'
  prefs: []
  type: TYPE_NORMAL
- en: What are the types of models you can load in TensorFlow.js?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Do you need to know the number of shards a model is broken into?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Other than public URLs, name another place you can load models from.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does `loadLayersModel` return?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do you clean the memory of a loaded model?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the expected input shape of the Inception v3 model?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What canvas context method should you use to draw an empty rectangle?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When loading a model from TFHub, what parameter must you pass to your load method?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Solutions to these questions are available in [Appendix A](app01.html#book_appendix).
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch05.html#idm45049246250312-marker)) You don’t have to use the canvas;
    you can move a DOM object if you’d like, but the canvas provides simple and complex
    animations with significant speed.
  prefs: []
  type: TYPE_NORMAL
