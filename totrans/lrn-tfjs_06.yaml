- en: Chapter 5\. Introducing Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章。介绍模型
- en: “Where does he get those wonderful toys?”
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “他从哪里弄来那些美妙的玩具？”
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: —Jack Nicholson (*Batman*)
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: —杰克·尼科尔森（*蝙蝠侠*）
- en: Now you’re in the big leagues. Way back in [Chapter 2](ch02.html#the_chapter_2)
    you accessed a fully trained model, but you didn’t need to understand tensors
    at all. Here in [Chapter 5](#the_chapter_5), you will get to utilize your tensor
    skills to work directly with your models, with no training wheels.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经进入大联盟。在[第2章](ch02.html#the_chapter_2)中，您访问了一个完全训练好的模型，但您根本不需要了解张量。在这里的[第5章](#the_chapter_5)，您将能够利用您的张量技能直接与您的模型一起工作，没有训练轮。
- en: Finally, you’re going to dive into utilizing the brain of most machine learning.
    Models can seem like a black box. Generally, they expect a specific tensor shape
    in, and a specific tensor shape comes out. For instance, let’s say you’ve trained
    a dog or cat classifier. The input might be a 32 x 32 3D RGB tensor, and the output
    might be a single tensor value of zero to one to indicate the prediction. Even
    if you don’t know the inner workings of such a device, at the least, consuming
    and utilizing models with a defined structure should be simple.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您将开始利用大多数机器学习的大脑。模型可能看起来像黑匣子。通常，它们期望特定的张量形状输入，并输出特定的张量形状。例如，假设您已经训练了一个狗或猫分类器。输入可能是一个32
    x 32的3D RGB张量，输出可能是一个从零到一的单个张量值，表示预测。即使您不了解这种设备的内部工作原理，至少使用具有定义结构的模型应该是简单的。
- en: 'We will:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将：
- en: Utilize trained models to predict a variety of answers
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用训练好的模型来预测各种答案
- en: Identify the benefits of our existing tensor manipulation skills
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别我们现有张量操作技能的好处
- en: Learn about Google’s TFHub.dev hosting
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解谷歌的TFHub.dev托管
- en: Learn about object localization
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解对象定位
- en: Learn how to overlay a bounding box to identify some aspect of an image
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习如何叠加边界框以识别图像的某些方面
- en: This chapter will teach you direct access to models. You won’t be dependent
    on cute wrapper libraries for coddling. If you want, you’ll even be able to write
    your own wrapper library around existing TensorFlow.js models. Armed with the
    skills in this chapter, you can start applying breakthrough machine learning models
    to any website.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将教您直接访问模型。您不会依赖于可爱的包装库来照顾。如果愿意，您甚至可以围绕现有的TensorFlow.js模型编写自己的包装库。掌握了本章的技能，您可以开始将突破性的机器学习模型应用于任何网站。
- en: Loading Models
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加载模型
- en: We know we need to get our models into memory and preferably into GPU-accelerated
    memory like tensors, but from where? As a blessing and a curse, the answer is
    “anywhere!” Loading files is common in software, so it corresponds to a variety
    of answers in TensorFlow.js.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道我们需要将模型加载到内存中，最好是加载到像张量这样的GPU加速内存中，但是从哪里加载？作为一种祝福和诅咒，答案是“任何地方！”在软件中加载文件是很常见的，因此在TensorFlow.js中有各种答案。
- en: To compound this problem, TensorFlow.js supports two different model formats.
    Fortunately, this assortment of options isn’t complicated. You just need to know
    what kind of model you need and from where you’ll be accessing it.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了加剧这个问题，TensorFlow.js支持两种不同的模型格式。幸运的是，这些选项的组合并不复杂。您只需要知道需要哪种类型的模型以及从哪里访问它。
- en: Currently, there are two model types in TensorFlow.js, each with their own benefits
    and costs. The simplest and most extensible model is called a *Layers model*.
    This model format lets you inspect, modify, and even take a model apart for adjustment.
    The format is perfect for retuning and adjusting later. The other model format
    is a *Graph model*. Graph models are generally more optimized as well as computationally
    efficient. The cost of using a Graph model is that the model is even more “black
    box,” and due to its optimizations, it’s more difficult to inspect or modify.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，TensorFlow.js中有两种模型类型，每种类型都有其自己的优缺点。最简单且最可扩展的模型称为*层模型*。这种模型格式允许您检查、修改甚至拆解模型以进行调整。该格式非常适合重新调整和调整。另一种模型格式是*图模型*。图模型通常更加优化和计算效率更高。使用图模型的成本是模型更加“黑匣子”，由于其优化，更难以检查或修改。
- en: Model types are simple. If you’re loading a Layers model, you’ll need to use
    the method `loadLayersModel`, and if you’re loading a GraphDef model, you’ll need
    to use the method `loadGraphModel`. There are benefits and drawbacks to these
    two model types, but that’s beyond the scope of this chapter. The key takeaway
    is that there’s little complexity in loading the desired model type; it’s just
    a question of which type and then using the corresponding method. The most important
    facet is the first parameter, which is the location of the model data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 模型类型很简单。如果要加载层模型，您需要使用方法`loadLayersModel`，如果要加载GraphDef模型，则需要使用方法`loadGraphModel`。这两种模型类型各有利弊，但这超出了本章的范围。关键是加载所需模型类型几乎没有复杂性；只是一个问题是哪种类型，然后使用相应的方法。最重要的方面是第一个参数，即模型数据的位置。
- en: Tip
  id: totrans-18
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: By the end of this book, you’ll have a pretty solid understanding of the critical
    differences between a Layers and a Graph model type. Each time a model is introduced,
    take note of which one was used.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书结束时，您将对层模型和图模型类型之间的关键差异有相当扎实的理解。每次引入一个模型时，请注意使用了哪种模型。
- en: This section explains the diversity of options for model locations and the simple
    unifying URI syntax that binds them.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 本节解释了模型位置的多样性选项以及将它们绑定在一起的简单统一URI语法。
- en: Loading Models Via Public URL
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过公共URL加载模型
- en: Loading models with a public URL is the most common method of accessing a model
    in TensorFlow.js. As you remember in [Chapter 2](ch02.html#the_chapter_2), when
    you loaded the Toxicity detection model, you downloaded several shards of the
    file in small 4 MB cacheable chunks from a public network. The model knew the
    location of the file to download. This is done with a single URL to a single file.
    The model file that was originally requested was a simple JavaScript Object Notation
    (JSON) file, and the subsequent files were weights for the neural network that
    were identified from that JSON file.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 使用公共URL加载模型是在TensorFlow.js中访问模型的最常见方法。正如您在[第2章](ch02.html#the_chapter_2)中记得的那样，当您加载毒性检测模型时，您从公共网络下载了文件的几个片段，每个片段大小为4
    MB，可以缓存。模型知道要下载文件的位置。这是通过单个URL到单个文件完成的。最初请求的模型文件是一个简单的JavaScript对象表示（JSON）文件，随后的文件是从该JSON文件中识别出的神经网络的权重。
- en: 'Loading TensorFlow.js models from a URL requires actively hosted adjacent model
    files (the same relative folder). This means that once you give a path for a model’s
    JSON file, it usually references the weights in successive files at the same directory
    level. The desired structure looks like this:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 从URL加载TensorFlow.js模型需要主动托管相邻的模型文件（相同的相对文件夹）。这意味着一旦您为模型的JSON文件提供路径，它通常会引用同一目录级别的连续文件中的权重。期望的结构如下：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Moving or denying access to these extra files will cause your model to be unusable
    and error. Depending on the security and configuration of your server environment,
    this can be a bit of a sticking point. Therefore, you should always verify that
    each file has proper URL access.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 移动或拒绝访问这些额外文件将导致您的模型无法使用并出现错误。根据服务器环境的安全性和配置，这可能是一个难点。因此，您应始终验证每个文件是否具有适当的URL访问权限。
- en: Note
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: We’ve covered three major ways to run TensorFlow.js so far. They are simple
    hosted with 200 OK!, NPM packed with Parcel, and server hosted with Node.js. Before
    we tell you how to properly load models for these situations, can you identify
    which of these will have complications?
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经介绍了三种运行TensorFlow.js的主要方法。它们是简单的200 OK！托管、使用Parcel打包的NPM和使用Node.js托管的服务器。在我们告诉您如何为这些情况正确加载模型之前，您能否确定哪种方法会出现问题？
- en: 200 OK! Web Server for Chrome examples will have no issues because everything
    in the folder is hosted with no optimization or security. Parcel gives us some
    bells and whistles with transforms, error logging, HMR, and bundling. With those
    features, our JSON and weight files are not passed into the distribution, aka
    `dist` folder, without some coaching.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 200 OK！Chrome的Web服务器示例不会出现问题，因为文件夹中的所有内容都是无优化或安全性地托管的。Parcel为我们提供了一些功能，如转换、错误日志记录、HMR和捆绑。有了这些功能，我们的JSON和权重文件不会被传递到分发文件夹，也就是`dist`文件夹，除非进行一些调整。
- en: In Parcel.js 2.0 (which is not officially out at the time of this writing),
    you’ll have more options for static files, but for now, there is a simple solution
    that works for Parcel 1.x that we’ll be using. You can install a plug-in called
    `parcel-plugin-static-files-copy` to green-light model files for local static
    hosting. The code used in the associated repo for this book utilizes this plug-in.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在Parcel.js 2.0中（在撰写本文时尚未正式发布），您将有更多选项用于静态文件，但目前，有一个简单的解决方案适用于我们将使用的Parcel 1.x。您可以安装一个名为`parcel-plugin-static-files-copy`的插件，以允许本地静态托管模型文件。本书相关存储库中使用的代码利用了这个插件。
- en: The plug-in works by effectively making any files placed in the `static` directory
    publicly accessible from the root URL. For example, a *model.json* file placed
    in *static/model* would be accessible as *localhost:1234/model/model.json*.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 该插件通过有效地使放置在`static`目录中的任何文件从根URL公开访问。例如，放置在*static/model*中的*model.json*文件将可以作为*localhost:1234/model/model.json*访问。
- en: Whatever web solution you use, you’ll need to verify that the security and bundling
    of the model files work for you. For unprotected public folders, this is as simple
    as uploading all the files to services like Amazon Web Services (AWS) and Simple
    Storage Service (S3). You’ll need to make the entire bucket public, or each adjacent
    file will have to explicitly be made public. It’s important to verify you can
    access the JSON *and* the BIN files. The error messages for missing or restricted
    shards of a model are perplexing. You’ll see a `404`, but errors continue on to
    a secondary and more cryptic error like that shown in [Figure 5-1](#no_file).
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您使用哪种Web解决方案，都需要验证模型文件的安全性和捆绑是否适合您。对于未受保护的公共文件夹，只需将所有文件上传到像Amazon Web Services（AWS）和Simple
    Storage Service（S3）这样的服务即可。您需要使整个存储桶公开，或者每个相邻文件都必须明确公开。验证您可以访问JSON *和* BIN文件是很重要的。缺少或受限制的模型片段的错误消息令人困惑。您会看到一个`404`，但错误会继续到第二个更加难以理解的错误，就像[图5-1](#no_file)中所示的那样。
- en: '![Screenshot of the error of missing bin files.](assets/ltjs_0501.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![缺少bin文件的错误截图。](assets/ltjs_0501.png)'
- en: 'Figure 5-1\. Error: JSON available but no bin files'
  id: totrans-33
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-1\. 错误：JSON可用但没有bin文件
- en: Tip
  id: totrans-34
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Create React App is a popular tool for simple React websites. If you use Create
    React App, files in the `public` folder will be accessible from the root URL out
    of the box. Think of `public` like our Parcel solution’s `static` folder. Both
    work great and have been tested for model hosting.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Create React App是一个用于简单React网站的流行工具。如果您使用Create React App，`public`文件夹中的文件将默认从根URL访问。将`public`视为我们Parcel解决方案的`static`文件夹。两者都非常有效，并已经为模型托管进行了测试。
- en: Loading Models from Other Locations
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从其他位置加载模型
- en: Models don’t have to be in public URLs. TensorFlow has methods to allow you
    to load from [local browser storage](https://oreil.ly/BHYc1), [IndexedDB storage](https://oreil.ly/MHYA4),
    and, in the case of Node.js, local filesystem access to model files.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 模型不必位于公共URL中。TensorFlow有方法允许您从[本地浏览器存储](https://oreil.ly/BHYc1)、[IndexedDB存储](https://oreil.ly/MHYA4)以及在Node.js中，本地文件系统访问模型文件。
- en: One significant benefit of this is that you can locally cache a model you loaded
    from a public URL so your app can be offline-ready. Other reasons include speed,
    security, or simply because you can.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个重要的好处是，您可以从公共URL加载的模型在本地缓存，以便您的应用程序可以脱机准备。其他原因包括速度、安全性，或者仅仅是因为您可以。
- en: Browser files
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 浏览器文件
- en: Local browser storage and IndexedDB storage are two web APIs for saving files
    specified to a particular page. Unlike cookies, which store a small piece of data
    like a single variable, `Window.localStorage` and the IndexedDB API are client-side
    storage capable of handling files among other significant structured data across
    browser sessions.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 本地浏览器存储和IndexedDB存储是两种用于保存指定页面的文件的Web API。与存储小数据片段（如单个变量）的cookie不同，`Window.localStorage`和IndexedDB
    API是客户端存储，能够处理文件等其他重要结构化数据跨浏览器会话。
- en: Public URLs have the `http` and `https` schemes; however, these methods utilize
    different schemes in the URI. To load a model from local storage, you would use
    a `localstorage://model-name` URI, and to load a model from IndexedDB, you would
    use a `indexeddb://model-name` URI.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 公共URL具有`http`和`https`方案；但是，这些方法在URI中使用不同的方案。要从本地存储加载模型，您将使用`localstorage://model-name`
    URI，要从IndexedDB加载模型，您将使用`indexeddb://model-name` URI。
- en: Besides the supplied methods, there’s no limit to the various locations you
    can store and retrieve a TensorFlow.js model. At the end of the day, it’s just
    data that you need, so you can load a model with any custom `IOHandler`. For instance,
    there has even been [proof-of-concept work on converting models completely to
    JSON files](https://github.com/infinitered/tfjs-runway) with the weights encoded
    so you can call `require` as needed from any location, even via a bundler.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 除了提供的方法外，您可以存储和检索TensorFlow.js模型的位置没有限制。归根结底，您只需要数据，因此您可以使用任何自定义的`IOHandler`加载模型。例如，甚至已经有[将模型完全转换为JSON文件的概念验证工作](https://github.com/infinitered/tfjs-runway)，权重已编码，因此您可以根据需要从任何位置调用`require`，甚至通过捆绑器。
- en: Filesystem files
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 文件系统文件
- en: To access files on a filesystem, you’ll need to use a Node.js server that has
    permission to get at the desired files. Browsers are sandboxed and cannot currently
    use this feature.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问文件系统中的文件，您需要使用一个具有权限获取所需文件的Node.js服务器。浏览器被沙箱化，目前无法使用此功能。
- en: 'Fortunately, it’s similar to the previous API. Use the *file:* scheme to identify
    a path to a given file like so: *[*file://path/to/model.json*](file://path/to/model.json).*
    Just like in the browser examples, the ancillary files must be in the same folder
    and accessible.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，这与以前的API类似。使用*file:*方案来标识给定文件的路径，就像这样：[*file://path/to/model.json*](file://path/to/model.json)。就像在浏览器示例中一样，辅助文件必须位于同一文件夹中并且可访问。
- en: Our First Consumed Model
  id: totrans-46
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们第一个使用的模型
- en: Now that you’re familiar with the mechanics of loading a model into memory,
    you can utilize models in your projects. This was automated for you when you used
    the Toxicity model in [Chapter 2](ch02.html#the_chapter_2), but now, with your
    familiarity with tensors and model access, you can handle a model without all
    the protective package code.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您熟悉了将模型加载到内存的机制，您可以在项目中使用模型。当您在[第2章](ch02.html#the_chapter_2)中使用毒性模型时，这对您进行了自动化，但是现在，您熟悉了张量和模型访问，可以处理一个模型，而无需所有保护包代码。
- en: You need a simple model to use for the first example. As you recall, you encoded
    a board of tic-tac-toe as an exercise in [Chapter 3](ch03.html#the_chapter_3).
    Let’s build from the foundation of your existing knowledge and not only encode
    a tic-tac-toe match but also pass that information into a trained model for analysis.
    The trained model will then predict and return an answer for the best next move.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要一个简单的模型用于第一个示例。正如您所记得的，您在[第3章](ch03.html#the_chapter_3)中将井字棋棋盘编码为练习。让我们从您现有知识的基础上构建，不仅编码一个井字棋比赛，还将该信息传递到训练模型进行分析。训练模型将预测并返回最佳下一步的答案。
- en: Your goal for this section will be to ask the AI model what moves it recommends
    for the three board states illustrated in [Figure 5-2](#ttt_states).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的目标是询问AI模型推荐哪些移动，这些移动在[图5-2](#ttt_states)中有所说明。
- en: '![Three example game states](assets/ltjs_0502.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![三个示例游戏状态](assets/ltjs_0502.png)'
- en: Figure 5-2\. Three game states
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-2。三个游戏状态
- en: 'Each of these games is in a different situation:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 这些游戏中的每一个处于不同的情况：
- en: Scenario A
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 情景A
- en: This is blank and allows the AI to make the first move.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这是空白的，允许AI进行第一步。
- en: Scenario B
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 情景B
- en: This is O’s turn, and we expect the AI to block the potential loss by playing
    in the top-right square.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在轮到O走棋了，我们期望AI通过在右上角的方格中下棋来阻止潜在的失败。
- en: Scenario C
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 情景C
- en: This is X’s move, and we expect the AI to move in the top-middle and claim victory!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在轮到X走棋了，我们期望AI在顶部中间移动并取得胜利！
- en: Let’s see what the AI recommends, by encoding these three states and printing
    the output of the model.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看AI推荐什么，通过对这三种状态进行编码并打印模型的输出。
- en: Loading, Encoding, and Asking a Model
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 加载、编码和询问模型
- en: You’ll be using the simple URL for loading the model. This model will be a Layers
    model. That means you will use `tf.loadLayersModel` and the path to the locally
    hosted model files to load. For this example, the model file will be hosted at
    *model/ttt_model.json*.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 您将使用简单的URL来加载模型。这个模型将是一个Layers模型。这意味着您将使用`tf.loadLayersModel`和路径到本地托管模型文件来加载。在本例中，模型文件将托管在*model/ttt_model.json*。
- en: Note
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The trained tic-tac-toe model for this example can be accessed in the associated
    [GitHub](https://github.com/GantMan/learn-tfjs) for this book. The JSON file is
    2 KB, and the weights file (*ttt_model.weights.bin*) is 22 KB in size. This 24
    KB load for a tic-tac-toe solver isn’t bad at all!
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 本示例的训练井字棋模型可以在本书的相关[GitHub](https://github.com/GantMan/learn-tfjs)中访问。JSON文件大小为2
    KB，权重文件(*ttt_model.weights.bin*)大小为22 KB。对于一个井字棋求解器来说，这24 KB的负载并不算太大！
- en: To transcribe the game board state, there will be a slight difference in encoding.
    You’ll need to tell the AI which team it’s playing for. You’ll also need an AI
    that can be X and O agnostic. Because scenario B is asking the AI for advice on
    O and not X, we need a flexible system for encoding. Instead of X always meaning
    1, assign the AI to 1 and the adversary to -1\. This way we can put the AI in
    a situation where it’s playing X or O. [Table 5-1](#tictactoe_value_table) shows
    each possible value for the lookup.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Table 5-1\. Grid-to-number conversion
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '| Board value |  | Tensor value |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
- en: '| AI |  | 1 |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
- en: '| Opponent |  | -1 |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
- en: '| Empty |  | 0 |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
- en: All three games need to be encoded and then stacked into a single tensor to
    pass to the AI model. The model then supplies three answers, one for each situation.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the full process:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: Load the model.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Encode the three separate game states.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Stack the states into a single tensor.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ask the model to print the results.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Stacking input to a model is a common practice and allows your model to handle
    any number of predictions in accelerated memory.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Stacking increases the dimensionality of the result. Performing this action
    on 1D tensors creates a 2D tensor, and so on. In this instance, you have three
    board states represented in 1D tensors, so stacking them will create a `[3, 9]`
    rank-two tensor. Most models support stacking or batching for their input, and
    the output will be similarly stacked with matching answers to the input indices.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: 'The code, which can be found at [*chapter5/simple/simple-ttt-model* in the
    GitHub repo](https://oreil.ly/38zZx), looks like this:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![1](assets/1.png)](#co_introducing_models_CO1-1)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: Use `tf.ready`, which resolves when TensorFlow.js is ready. No DOM access is
    needed.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_introducing_models_CO1-2)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: Though the model is two files, only the JSON file needs to be identified. It
    knows about and loads any additional model files.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_introducing_models_CO1-3)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: The `loadLayersModel` model resolves with the fully loaded model.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_introducing_models_CO1-4)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: An empty board is nine zeros, which represents scenario A.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](assets/5.png)](#co_introducing_models_CO1-5)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: Encoded as X equal to `-1` for scenario B.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '[![6](assets/6.png)](#co_introducing_models_CO1-6)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Encoded as X equal to `1` for scenario C.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '[![7](assets/7.png)](#co_introducing_models_CO1-7)'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Use `tf.stack` to combine three 1D tensors into a single 2D tensor.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[![8](assets/8.png)](#co_introducing_models_CO1-8)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Use `.predict` to ask the model to identify the best next moves.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: '[![9](assets/9.png)](#co_introducing_models_CO1-9)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: The original output was going to be shaped as `[3, 9]`, but it’s a good situation
    where reshaping the output makes it more readable. Print the result in three 3
    x 3 grids so we can read them like game boards.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: When using `loadLayersModel` and even `loadGraphModel`, the TensorFlow.js library
    is depending on the presence of the `fetch` web API. If you’re using this method
    in Node.js, you’ll need to polyfill `fetch` with a package like [node-fetch](https://oreil.ly/rwPMW).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: The aforementioned code successfully converts the three matches to tensors in
    a format that the AI model expects, and then runs these values through the model’s
    `predict()` method for analysis. The results are printed to the console and look
    like what we see in [Figure 5-3](#ttt_result).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '![Result of tic-tac-toe model](assets/ltjs_0503.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
- en: Figure 5-3\. The resulting [3, 3, 3] shaped tensor from our code
  id: totrans-103
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The method that does all the magic is the model’s `predict()` function. The
    function lets the model know to generate output predictions for the given input.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Interpreting the Results
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For some people this resulting tensor makes complete sense, and for others,
    you might need a moment of context. The resulting answers are again in probabilities
    of the next best moves. The highest number wins.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: 'For this to be a proper probability, the answers need to sum up to 100%, and
    they do. Let’s take a look at the empty tic-tac-toe board result shown here in
    scenario 1:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 为了得到一个正确的概率，答案需要相加得到100%，而它们确实相加得到了。让我们看看在这里显示的空井字棋板结果在情景1中：
- en: '[PRE2]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: If you were to be silly like me and enter these nine values into your calculator
    (TI-84 Plus CE for life!), they would sum up to the number 1\. That means each
    corresponding value is a percentage vote for that spot. We can see the four corners
    all have a significant (nearly 25%) portion of the result. This makes sense, because
    strategically starting in a corner is the best move possible in tic-tac-toe, followed
    by the middle, which has the next highest value.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你像我这样傻乎乎地把这九个值输入到你的计算器（TI-84 Plus CE永远是我的最爱！），它们会相加得到数字1。这意味着每个对应的值都是该位置的百分比投票。我们可以看到四个角都有一个显著（接近25%）的结果。这是有道理的，因为在井字棋中，从一个角开始是最好的策略，其次是中间，它有次高的价值。
- en: 'Because the bottom right has 27% of the vote, this would be the AI’s most likely
    move. Let’s see how the AI performs in another scenario. If you recall, in scenario
    B from [Figure 5-2](#ttt_states), the AI would need to move in the top right to
    block. The resulting tensor from the AI is shown here in scenario 2:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 因为底部右侧有27%的投票，这将是AI最有可能的移动。让我们看看AI在另一个情景中的表现。如果你还记得，在[图5-2](#ttt_states)的情景B中，AI需要移动到右上角来阻止。AI的结果张量在情景2中显示：
- en: '[PRE3]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The top-right value is 99%, so the model has correctly blocked the given threat.
    One funny aspect of a machine learning model is that the other moves still have
    values, including spaces that are already taken.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 顶部右侧的值为99%，所以模型正确地阻止了给定的威胁。机器学习模型的一个有趣之处是其他移动仍然有值，包括已经被占据的空格。
- en: 'The last scenario was an encoded tensor to see if the model would strike and
    win tic-tac-toe. The results are shown here in scenario 3 of the predicted batch:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一个情景是一个编码的张量，用来查看模型是否能够获胜井字棋。预测批次的结果在情景3中显示：
- en: '[PRE4]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The result is 99% (rounded) certain that top middle is the best move, which
    is correct. No other move even comes close. All three predicted results seem to
    be not only functioning moves, but also the correct move for a given state.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是99%（四舍五入）确定顶部中间是最佳移动，这是正确的。其他移动甚至都不接近。所有三个预测结果似乎不仅是有效的移动，而且是给定状态下的正确移动。
- en: You have successfully loaded and interacted with a model to have it provide
    results. With the skills you just attained, you could write your own tic-tac-toe
    game app. I imagine there’s not much demand for tic-tac-toe games on the internet,
    but if provided a trained model of the same structure, you could use the AI to
    make all kinds of games!
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经成功地加载并与一个模型进行交互，让它提供结果。凭借你刚刚获得的技能，你可以编写自己的井字棋游戏应用。我想互联网上对井字棋游戏的需求不会很大，但如果提供了相同结构的训练模型，你可以使用AI制作各种游戏！
- en: Tip
  id: totrans-117
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Most models will have some associated documentation to help you identify the
    proper inputs and outputs, but Layers models have properties that you can access
    if you need help. The expected input shape can be seen at `model.input.shape`,
    and the output can be seen at `model.outputShape`. These properties do not exist
    on Graph models.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数模型都会有一些相关的文档，帮助你识别正确的输入和输出，但Layers模型有一些属性，如果需要帮助，你可以访问这些属性。期望的输入形状可以在`model.input.shape`中看到，输出可以在`model.outputShape`中看到。这些属性在Graph模型上不存在。
- en: Cleaning the Board After
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 清理棋盘后
- en: The TensorFlow.js model in this example is wrapped in a `tidy` and will automatically
    free memory after the code has completed. In most situations, you will not be
    done with your model so quickly. It’s important to note that you must call `.dispose()`
    on models, just like you do tensors. Models are accelerated the same way, and
    therefore they have the same cleanup cost.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，TensorFlow.js模型被包装在一个`tidy`中，并且在代码完成后会自动释放内存。在大多数情况下，你不会这么快完成你的模型。重要的是要注意，你必须像处理张量一样调用`.dispose()`来处理模型。模型被加速处理方式相同，因此它们有相同的清理成本。
- en: Reloading web pages tends to clear tensors, but long-running Node.js servers
    will have to monitor and verify that tensors and models are disposed of.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 重新加载网页通常会清除张量，但长时间运行的Node.js服务器将不得不监视和验证张量和模型是否被处理。
- en: Our First TensorFlow Hub Model
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们的第一个TensorFlow Hub模型
- en: Now that you’ve properly encoded, loaded, and processed a small amount of data
    through a custom model, you should take a moment to push the envelope. In this
    section, you’ll load a significantly larger model from TensorFlow Hub, and you’ll
    process an image. Tic-tac-toe was an input of nine values, whereas most images
    are tensors with thousands of values.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经正确地编码、加载和处理了少量数据通过一个自定义模型，你应该花一点时间挑战自己。在这一部分，你将加载一个规模更大的模型从TensorFlow Hub，并处理一张图片。井字棋是九个值的输入，而大多数图片是包含数千个值的张量。
- en: The model you’ll be loading will be one of the biggest and most impressive models
    out there, Inception v3\. The Inception model is an impressive network first created
    in 2015\. This third version has been, impressively, trained on hundreds of thousands
    of images. Weighing in at a whopping 91.02 MB, this model can classify 1,001 different
    objects. The MobileNet-wrapped NPM package from the Chapter Challenge in [Chapter 2](ch02.html#the_chapter_2)
    is awesome, but not nearly as powerful as what you’re about to use.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 你将要加载的模型是目前最大和最令人印象深刻的模型之一，Inception v3。Inception模型是一个令人印象深刻的网络，最初在2015年创建。这第三个版本已经训练了数十万张图片。这个模型有91.02
    MB，可以对1,001种不同的对象进行分类。来自[第2章](ch02.html#the_chapter_2)的Chapter Challenge中的MobileNet-wrapped
    NPM包很棒，但不像你即将使用的模型那样强大。
- en: Exploring TFHub
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索TFHub
- en: 'Google has begun hosting models like Inception v3 for free on its own CDN.
    In situations for this large model size, it’s quite useful to have a reliable
    and impressive versioned CDN for models like we often do for JavaScript. You can
    access hundreds of trained and ready-to-go models for TensorFlow and TensorFlow.js
    in one location at [*https://tfhub.dev*](https://tfhub.dev). TensorFlow.js has
    a special way to identify when your model is hosted on TFHub; we just add `{ fromTFHub:
    true }` to our configuration after we’ve identified our model URL.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: As you peruse TFHub, you can see a variety of publishers and explanations for
    each model. These explanations are critical, because as we’ve already identified,
    models are quite specific on what they expect for input and what they will supply
    for output. We can learn more about Inception v3 on [its associated TFHub page](https://oreil.ly/Utstp).
    This model was built by Google, and the version it provides has been extensively
    trained. If you’re hungry for more information, it’s not a bad idea to scan through
    the [published paper on the model](https://arxiv.org/abs/1512.00567).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: 'On the TFHub page, you get both of those critical insights for using a model.
    First, the expected input image sizes should be 299 x 299, have values `0-1`,
    and be batched just like we did in the previous tic-tac-toe example. Second, the
    result that the model returns is a single-dimensional tensor with 1,001 values,
    with the largest being the most likely (similar to the nine values returned by
    tic-tac-toe). It might sound confusing, but the page uses some statistics-based
    terminology to express this:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: The output is a batch of logits vectors. The indices into the logits are the
    num_classes = 1001 classes of the classification from the original training.
  id: totrans-129
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Returning a numeric result is useful, but as always, we have to map this back
    to a useful label. In tic-tac-toe we mapped the index to a location on the board,
    and in this case, we map the index of a value to the corresponding label that
    follows the same index. The TFHub page [shares a TXT file](https://oreil.ly/bzUeD)
    of all the necessary labels in their correct order, which you will use to create
    an array to interpret the predicted results.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: Wiring Up Inception v3
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now you know the Inception v3 model classifies photos, and you have the input
    and output specification. It’s like a larger version of the tic-tac-toe problem.
    However, there will be new hurdles. For instance, printing 1,001 numbers won’t
    be helpful information. You’ll need to use `topk` to parse the giant tensor back
    into a useful context.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code is available in the [*chapter5/simple/simple-tfhub* in the
    GitHub repo](https://oreil.ly/X7TpN) folder. The code depends on a mysterious
    image that has the `id` `mystery`. Ideally, the AI can solve the mystery for us:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[![1](assets/1.png)](#comarker1)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: This is the URL to the TFHub for the Inception model.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#comarker2)'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Load the graph model and set `fromTFHub` to true.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#comarker3)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: The image is resized to 299 x 299.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#comarker4)'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Convert the `fromPixels` results to values between 0 and 1 (normalizing the
    data).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](assets/5.png)](#comarker5)'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: Convert the 3D tensor to a single batch 4D tensor like the model expects.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '[![6](assets/6.png)](#comarker6)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Predict on the image.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '[![7](assets/7.png)](#comarker7)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: The print is so big it gets trimmed.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[![8](assets/8.png)](#comarker8)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Recover the top three values as our guesses.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '[![9](assets/9.png)](#comarker9)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Print the top three prediction indices.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '[![10](assets/10.png)](#comarker10)'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: Map the indices to their labels and print them. `INCEPTION_CLASSES` is an array
    of labels that maps to the model output.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: In the associated code for this chapter, you’ll find three images that you can
    set as the mystery image in this section. Inception v3 impressively identifies
    all three correctly. Take a look at the captured results in [Figure 5-4](#tape_player).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '![Inception correctly identifying a tape player](assets/ltjs_0504.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
- en: Figure 5-4\. Resulting classification of an image from Inception v3
  id: totrans-157
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see from the photo, Inception’s first choice was a “tape player,”
    which I would say is very accurate. Second, it saw a “cassette player,” and to
    be honest I don’t know how that’s different from a “tape player,” but I’m no mega-model.
    Lastly, the third highest value was a “radio,” which is what I would have said.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: It’s not often you need a large model like this, but as new models get added
    to TFHub, you know you have options. Peruse the existing models every so often.
    You’ll see quite a few on image classification. Classifying images is one of the
    more impressive tasks of beginning AI, but why stop there?
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Our First Overlayed Model
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, the models you’ve been working with have simple output. Tic-tac-toe
    identified your next move, Inception classified a photo, and just to round things
    out, you’ll implement a classic visual effect in movies that feature AI, the bounding
    box that identifies an object in a photo. Rather than classifying an entire photo,
    the AI highlights a specific bounding box within a photo, like in [Figure 5-5](#detection).
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '![A bounding box for a balloon image](assets/ltjs_0505.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
- en: Figure 5-5\. Bounding box overlay
  id: totrans-163
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Normally, the bounding box output of a model is fairly complex because it handles
    a variety of classes and overlapping boxes. Usually, the model leaves you to use
    some math to properly clean up the results. Rather than dealing with that, let’s
    just focus on drawing a single rectangle on predicted output in TensorFlow.js.
    This is sometimes called *object localization*.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: The model for this final exercise will be a pet face detector. The model will
    do its best to give us a bounding set of coordinates for where it thinks the pet’s
    face is located. It’s not generally hard to talk people into looking at cute dogs
    and cats, but this model could have all kinds of applications. Once you have the
    location of a pet’s face, you could use that data to train additional models,
    like recognizing pets or checking if their cute noses need a boop. You know…science!
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: The Localization Model
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This model was trained on a public dataset called the [Oxford-IIIT Pet Dataset](https://oreil.ly/Pz0D9).
    The small, 2-ish MB model expects a 256 x 256 `Float32` input RGB image of a pet
    and outputs four numbers to identify a bounding box around the pet’s face. The
    four numbers in the 1D tensor are the top-left point and the bottom-right point.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: The points are represented as values between 0 and 1, as a percentage of the
    image. You can define a rectangle with the model result information, as shown
    in [Figure 5-6](#result_points).
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '![Display of how 4 values become two points](assets/ltjs_0506.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
- en: Figure 5-6\. Four values into two points
  id: totrans-170
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The beginning of the code will be similar to the previous code. You’ll start
    off by converting the image to a tensor and running it through the model. The
    following code can be found in [*chapter5/simple/simple-object-localization* in
    the GitHub repo](https://oreil.ly/zkSfM).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Labeling the Detection
  id: totrans-173
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now you can draw the result coordinates as a rectangle over the image. Drawing
    detections is a common task in TensorFlow.js. The basics of drawing a tensor result
    over an image require you to place the image in a container and then position
    an absolute canvas over that image. Now when you draw to the canvas, you’ll be
    drawing over the image.^([1](ch05.html#idm45049246250312)) From a side view, the
    layout will resemble [Figure 5-7](#canvas_overlay).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '![3D view of DOM](assets/ltjs_0507.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
- en: Figure 5-7\. Stacking view of the canvas
  id: totrans-176
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'For this lesson, the CSS has been embedded directly in the HTML for ease. The
    image and canvas layout looks like this:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[![1](assets/1.png)](#co_introducing_models_CO2-1)'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: The containing `div` is relative positioned and locked at 80% the page height.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_introducing_models_CO2-2)'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: The canvas is placed over the image with an absolute position.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 画布以绝对位置放置在图像上。
- en: For a simple rectangle, you can use the canvas context’s `strokeRect` method.
    The `strokeRect` method doesn’t take two points like the model returns. It takes
    a starting point and then a width and height. To convert the model points to width
    and height, you can just subtract each vertex to get a distance. [Figure 5-8](#width_calculation)
    shows a visual representation of this calculation.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 对于简单的矩形，您可以使用画布上下文的`strokeRect`方法。`strokeRect`方法不像模型返回的那样需要两个点。它需要一个起点，然后是宽度和高度。要将模型点转换为宽度和高度，您只需减去每个顶点以获得距离。[图5-8](#width_calculation)显示了这种计算的可视化表示。
- en: '![calculating width and height explanation](assets/ltjs_0508.png)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![计算宽度和高度的解释](assets/ltjs_0508.png)'
- en: Figure 5-8\. Width and height are calculated as the difference between Xs and
    Ys
  id: totrans-185
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-8。宽度和高度是X和Y之间的差异计算
- en: Armed with the starting point, the width and height of the overlaid rectangle,
    you can draw it to scale on the canvas with a few lines of code. Remember, the
    tensor output is a percentage and will need to be scaled in each dimension.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 使用起点、覆盖矩形的宽度和高度，您可以用几行代码在画布上按比例绘制它。记住，张量输出是一个百分比，需要在每个维度上进行缩放。
- en: '[PRE8]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[![1](assets/1.png)](#co_introducing_models_CO3-1)'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_introducing_models_CO3-1)'
- en: Make the detection canvas the same size as the image it’s over.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 使检测画布与其所覆盖的图像大小相同。
- en: '[![2](assets/2.png)](#co_introducing_models_CO3-2)'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_introducing_models_CO3-2)'
- en: Grab the bounding box result.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 获取边界框结果。
- en: '[![3](assets/3.png)](#co_introducing_models_CO3-3)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_introducing_models_CO3-3)'
- en: Scale the starting point X and Y back to the image.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 将起点X和Y缩放回图像。
- en: '[![4](assets/4.png)](#co_introducing_models_CO3-4)'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_introducing_models_CO3-4)'
- en: Find the width of the box by subtracting X[1] from X[2] and then scaling it
    by the image width. The same goes for Y[1] and Y[2].
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 通过从X[1]减去X[2]来找到框的宽度，然后通过图像宽度进行缩放。Y[1]和Y[2]也是如此。
- en: '[![5](assets/5.png)](#co_introducing_models_CO3-5)'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_introducing_models_CO3-5)'
- en: Now use the canvas 2D context to draw the desired rectangle.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 现在使用画布的2D上下文来绘制所需的矩形。
- en: The result is a perfectly placed bounding box at the given points. See for yourself
    in [Figure 5-9](#pet_faces).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 结果是在给定点处完美放置的边界框。自己看看[图5-9](#pet_faces)。
- en: '![Identifying pet face locations](assets/ltjs_0509.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![识别宠物脸部位置](assets/ltjs_0509.png)'
- en: Figure 5-9\. Pet face localization
  id: totrans-200
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-9。宠物脸部定位
- en: A misconception when running this project might be that the detection and drawing
    you’ve experienced are slow. This is false. It’s noticeable that when the page
    loads, there’s a delay before the bounding box appears; however, the delay you’re
    experiencing includes loading a model and loading it into accelerated memory of
    some type (sometimes called *model warmup*). Though doing so is a bit outside
    the goals of this chapter, if you were to call `model.predict` and draw again,
    you would see results in microseconds. The canvas + TensorFlow.js structure you
    created in this final section can easily support 60+ frames per second on a desktop
    computer.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行此项目时的一个误解可能是您经历的检测和绘制很慢。这是错误的。很明显，当页面加载时，边界框出现之前会有延迟；然而，您正在经历的延迟包括加载模型并将其加载到某种加速内存中（有时称为*模型预热*）。尽管这有点超出了本章的目标，但如果您调用`model.predict`并再次绘制，您会在微秒内看到结果。您在本节中创建的画布+TensorFlow.js结构可以轻松支持桌面计算机上每秒60帧以上。
- en: Models that have plenty of bounding boxes and labels use similar `strokeRect`
    calls to outline the location of identified objects. There’s a wide variety of
    models, and each of them identify various aspects of images. The practice of modifying
    the canvas to draw information over an image comes in handy in the TensorFlow.js
    world.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 具有大量边界框和标签的模型使用类似的`strokeRect`调用来勾画识别对象的位置。有各种各样的模型，它们各自识别图像的各个方面。在TensorFlow.js世界中，修改画布以在图像上绘制信息的实践非常有用。
- en: Chapter Review
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 章节回顾
- en: Knowing the input and output of models is key. In this chapter, you finally
    saw data all the way through. You converted input, passed it into a trained model,
    and interpreted the results. Models can take a wide array of inputs and provide
    equally wide outputs. Now, regardless of what a model requires, you have some
    impressive experience to draw from.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 了解模型的输入和输出是关键。在本章中，您最终看到了数据的全部过程。您转换了输入，将其传递给经过训练的模型，并解释了结果。模型可以接受各种各样的输入并提供同样广泛的输出。现在，无论模型需要什么，您都有一些令人印象深刻的经验可以借鉴。
- en: 'Chapter Challenge: Cute Faces'
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 章节挑战：可爱的脸
- en: Imagine our pet face localization was the first step in a larger process. Let’s
    pretend you were identifying pet faces to then pass the pet’s face to another
    model that would look for a tongue to see if the pet was hot and panting. It’s
    common to organize multiple models in a pipeline like this, with each tuned to
    their own specific purpose.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，我们的宠物脸部定位是更大过程中的第一步。假设您正在识别宠物脸部，然后将宠物脸部传递给另一个模型，该模型将寻找舌头以查看宠物是否发热和喘气。通常会像这样在管道中组织多个模型，每个模型都调整到自己特定的目的。
- en: Given a pet’s face location from the previous code, write the additional code
    to extract the pet’s face and prep it for a model that requires a 96 x 96 image
    input. Your answer will be a single batched crop like [Figure 5-10](#pup_face).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 根据上一段代码中宠物脸部的位置，编写额外的代码来提取宠物的脸并为需要96 x 96图像输入的模型做准备。您的答案将是一个批量裁剪，如[图5-10](#pup_face)。
- en: '![Just the face of the dog](assets/ltjs_0510.png)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![只有狗的脸](assets/ltjs_0510.png)'
- en: Figure 5-10\. The goal [1, 96, 96, 3] tensor of just the face
  id: totrans-209
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-10。目标[1, 96, 96, 3]张量，只包含脸部
- en: Though this exercise is to crop the pet’s face for a secondary model, it could
    just as easily have been a “pet anonymizer” that required you to blur the pet’s
    face. The applications of AI in the browser are limitless.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个练习是为了裁剪宠物的脸以供第二个模型使用，但它也可以很容易地成为一个“宠物匿名化器”，需要您模糊宠物的脸。浏览器中的人工智能应用是无限的。
- en: You can find the answer to this challenge in [Appendix B](app02.html#appendix_b).
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[附录 B](app02.html#appendix_b)中找到这个挑战的答案。
- en: Review Questions
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 复习问题
- en: 'Let’s review the lessons you’ve learned from the code you’ve written in this
    chapter. Take a moment to answer the following questions:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下你在本章编写的代码中学到的教训。花点时间回答以下问题：
- en: What are the types of models you can load in TensorFlow.js?
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在TensorFlow.js中可以加载哪些类型的模型？
- en: Do you need to know the number of shards a model is broken into?
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你需要知道一个模型被分成了多少个碎片吗？
- en: Other than public URLs, name another place you can load models from.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 除了公共URL之外，还有哪些地方可以加载模型？
- en: What does `loadLayersModel` return?
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`loadLayersModel` 返回什么？'
- en: How do you clean the memory of a loaded model?
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何清除已加载模型的内存？
- en: What is the expected input shape of the Inception v3 model?
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Inception v3模型的预期输入形状是什么？
- en: What canvas context method should you use to draw an empty rectangle?
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用哪个画布上下文方法可以绘制一个空矩形？
- en: When loading a model from TFHub, what parameter must you pass to your load method?
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从TFHub加载模型时，你必须向加载方法传递哪个参数？
- en: Solutions to these questions are available in [Appendix A](app01.html#book_appendix).
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题的解决方案可以在[附录 A](app01.html#book_appendix)中找到。
- en: ^([1](ch05.html#idm45049246250312-marker)) You don’t have to use the canvas;
    you can move a DOM object if you’d like, but the canvas provides simple and complex
    animations with significant speed.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch05.html#idm45049246250312-marker)) 你不一定要使用画布；如果你愿意，你可以移动一个DOM对象，但是画布提供了简单和复杂的动画，速度很快。
