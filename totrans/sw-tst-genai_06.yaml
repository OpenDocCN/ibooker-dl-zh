- en: 5 Test planning with AI support
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 5 使用AI支持的测试规划
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: How the value of models is associated with the use of LLMs
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的价值如何与LLMs的使用相关联
- en: Using models with LLMs in test planning
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在测试规划中使用LLMs和模型
- en: Evaluating the suitability of suggestions generated by LLMs
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估LLMs生成的建议的适用性
- en: 'Now that we’ve started to see how large language models (LLMs) can help support
    quality in development, it’s time to tackle the question of whether LLMs can generate
    test cases. On the surface, the answer is simple: yes, they can. But the deeper
    and more important question is why would you want them to generate test cases?
    What are we hoping to achieve by generating swathes of test cases without thought
    or direction? Just because we can create test cases doesn’t necessarily mean it’s
    the right thing to do in a given situation.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到大型语言模型（LLMs）如何帮助支持开发中的质量，是时候解决LLMs能否生成测试用例的问题了。表面上，答案很简单：是的，它们可以。但更深层次、更重要的问题是，你为什么想要它们生成测试用例？通过无思考或无方向地生成大量的测试用例，我们希望实现什么？仅仅因为我们能够创建测试用例，并不意味着在特定情况下这样做是正确的。
- en: 'The motivation behind the question comes from a desire to use LLMs to direct
    the required testing for a feature, an epic, or a project. Although LLMs may be
    valuable in terms of advising us what testing we should carry out, there are concerns
    about how trusting we should be and how much we should rely on LLMs. Much like
    other activities we’ve explored and will explore, there is a balance to be struck.
    On one hand, we must keep a healthy skepticism in place whenever we use LLMs to
    aid in testing, but we shouldn’t outright dismiss their potential value (as long
    as we keep that critical eye for when they might lead us astray). Therefore, this
    chapter will explore two questions at the core of how LLMs can guide the direction
    of the testing, focusing on how test planning is conducted:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 提出这个问题的动机来自于使用LLMs来指导对一个功能、史诗或项目的所需测试的愿望。尽管LLMs在建议我们应该进行哪些测试方面可能很有价值，但我们仍然担心我们应该有多大的信任度以及我们应该依赖LLMs的程度。就像我们探索和将要探索的其他活动一样，我们需要找到一个平衡点。一方面，当我们使用LLMs来辅助测试时，我们必须保持健康的怀疑态度，但我们也不应该完全否定它们的潜在价值（只要我们保持对它们可能误导我们的批判性眼光）。因此，本章将探讨两个核心问题，即LLMs如何指导测试的方向，重点关注测试规划是如何进行的：
- en: Can LLMs support us in our test planning?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLMs能否支持我们的测试规划？
- en: How can LLMs be used effectively to support said planning?
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何有效地使用LLMs来支持此类规划？
- en: Specifically, we’ll be looking at the activities we need to carry out when determining
    what type of testing is necessary for a feature, an epic, or a project. To do
    this, we’ll examine what test planning looks like in a modern software development
    team. But before that, we will identify how LLMs can best support us during the
    planning phase.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，我们将探讨在确定一个功能、史诗或项目所需的测试类型时我们需要执行的活动。为此，我们将考察现代软件开发团队中的测试规划是什么样的。但在那之前，我们将确定LLMs如何在规划阶段为我们提供最佳支持。
- en: 5.1 Defining test planning in modern testing
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.1 定义现代测试中的测试规划
- en: 'For most of us, a test plan implies detailed documentation that attempts to
    meticulously define how we will carry out our testing. But if you are someone
    who works in a modern, agile, software development team, ask yourself: When was
    the last time you documented a test plan for upcoming work? If so, what did it
    look like?'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们大多数人来说，测试计划意味着详细文档，试图细致地定义我们将如何执行我们的测试。但如果你是现代敏捷软件开发团队的一员，问问自己：你上次为即将到来的工作记录测试计划是什么时候？如果是的话，它看起来像什么？
- en: Test planning these days comes in a myriad of forms. Some of us might say that
    we haven’t written a test plan for a long time, and others might capture key details
    in a one-page test plan or rely on acceptance criteria to determine what testing
    takes place. Others may still create formal test plans following stringent test
    plan templates. Whether our planning is conducted formally or informally, what
    drives a test plan are the risks to our product and project, and this relationship
    is illustrated in figure 5.1.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的测试规划形式多种多样。有些人可能说他们很久没有写测试计划了，有些人可能在一页测试计划中捕捉关键细节，或者依赖验收标准来确定进行哪些测试。其他人可能仍然按照严格的测试计划模板创建正式的测试计划。无论我们的规划是正式的还是非正式的，推动测试计划的是我们的产品和项目风险，这种关系在图5.1中得到了说明。
- en: '![](../../OEBPS/Images/CH05_F01_Winteringham2.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH05_F01_Winteringham2.png)'
- en: Figure 5.1 A diagram showing the relationship of risk and test planning
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.1 显示风险和测试规划之间关系的图表
- en: Therefore, when we are planning the testing we intend to carry out, our core
    goal is to define and mitigate specific, measurable risks. The risks we define
    inform us of what testing we will do, and depending on the type of intended testing,
    we can consider different test ideas.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，当我们规划要进行的测试时，我们的核心目标是定义和减轻具体、可衡量的风险。我们定义的风险告诉我们将进行哪些测试，并且根据预期的测试类型，我们可以考虑不同的测试想法。
- en: 5.1.1 Test planning, LLMs, and area of effect
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1.1 测试计划、LLM和影响范围
- en: Considering that risk is at the core of our testing, we need to establish a
    relationship with LLMs that helps elevate a risk-based planning approach, while
    ensuring that we aren’t too biased by an LLM’s output. A lot of discussion has
    been around how LLMs can be used to direct our testing by having them generate
    test cases for us. (For the sake of this discussion, we’ll include both automated
    and nonautomated test cases.) But just because an LLM can generate test cases
    doesn’t mean that they are necessary or relevant to mitigating the risks we care
    about. The result may be that some suggested test cases are of value, but using
    an LLM greatly increases the risk of running wasteful or misleading testing.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到风险是我们测试的核心，我们需要与LLM建立一种关系，这有助于提升基于风险规划的方法，同时确保我们不会过度依赖LLM的输出。关于如何使用LLM来指导我们的测试，有很多讨论，即通过让他们为我们生成测试用例。
    (为了讨论的需要，我们将包括自动和非自动测试用例。) 但仅仅因为LLM可以生成测试用例，并不意味着它们对于减轻我们关心的风险是必要的或相关的。结果可能是，一些建议的测试用例是有价值的，但使用LLM大大增加了进行浪费性或误导性测试的风险。
- en: We want to be directed and efficient in our testing, so focusing on using an
    LLM to support us in identifying risks is key. First, it opens up how we conduct
    our testing. Asking an LLM to generate test cases ties us to one type of testing
    activity, and although there is a case for using test cases as part of a holistic
    strategy of different testing techniques, we shouldn’t rely on a monoculture of
    test cases alone. Instead, we should focus on risks to explore different concerns
    we might have without the bias of choosing a testing technique. Once we understand
    what risks we care about, we can select a suitable testing activity to mitigate
    said risks.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望测试过程既具有指导性又高效，因此，专注于使用LLM来支持我们识别风险是关键。首先，它开辟了我们的测试方式。要求LLM生成测试用例将我们绑定到一种测试活动类型，尽管使用测试用例作为不同测试技术整体策略的一部分是有道理的，但我们不应仅依赖于测试用例的单一文化。相反，我们应该关注风险，探索我们可能有的不同关注点，而不受选择测试技术的偏见。一旦我们了解了我们关心的风险，我们就可以选择合适的测试活动来减轻这些风险。
- en: Second, and most importantly, focusing on risk changes the way we use an LLM.
    In figure 5.2, the area of effect model demonstrates how we can tell the LLM what
    features we are focusing on and what risks we have identified already.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，最重要的是，关注风险改变了我们使用LLM的方式。在图5.2中，影响范围模型展示了我们如何告诉LLM我们关注的特性和我们已经识别出的风险。
- en: '![](../../OEBPS/Images/CH05_F02_Winteringham2.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH05_F02_Winteringham2.png)'
- en: Figure 5.2 Area of the effect model demonstrating the core roles of the human
    and the LLM as an assistant
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.2 影响范围模型展示了人类和LLM作为助手的核心角色
- en: As demonstrated in the figure, the LLM serves as an assistant that expands our
    ideas around risk and potentially help us uncover new risks that hadn’t been considered
    already, helping us expand our risk coverage, while ensuring we control the direction
    of our testing.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如图中所示，LLM（大型语言模型）充当助手，扩展我们关于风险的想法，并可能帮助我们揭示尚未考虑的新风险，帮助我们扩大风险覆盖范围，同时确保我们控制测试的方向。
- en: 5.2 Focused prompts with the use of models
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.2 使用模型进行专注提示
- en: If we want to use LLMs to help us identify risks, we need to be aware of the
    hazards of an overreliance on them when determining what to focus on. To better
    understand this, let’s take a look at a common example of how LLMs are said to
    help with testing, why they can be problematic, and how we can better direct our
    use of LLMs to increase their value and decrease the risk of misdirected testing.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想使用LLM帮助我们识别风险，我们需要意识到在确定关注点时过度依赖它们的危害。为了更好地理解这一点，让我们看看一个常见的例子，即LLM据说如何帮助进行测试，为什么它们可能存在问题，以及我们如何更好地指导LLM的使用，以增加其价值并降低误导测试的风险。
- en: 5.2.1 Weak prompts mean weak suggestions
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.1 弱提示意味着弱建议
- en: Throughout Part 1 of this book, we’ve seen how poorly framed prompts such as
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的第一部分，我们看到了如何处理不当的提示，例如
- en: '|'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-MW.png)'
- en: '| Create tests for a file upload feature |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 为文件上传功能创建测试 |'
- en: 'return a generic list of actionable results not rooted in a context, which
    means that they require a large amount of reworking or risk affecting the quality
    of our testing (reduced in size for readability):'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 返回一个非基于上下文的通用操作结果列表，这意味着它们需要大量的修改，或者可能会影响我们测试的质量（为了可读性，已缩减大小）：
- en: '|'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-openai.png)'
- en: '| Implementing a file upload feature can introduce several risks, including:  
    1.  Security Risks:   −   Malicious Files: Users might upload files containing
    malware or viruses, which can infect the system and compromise security.   −  
    Injection Attacks: If the system doesn’t properly validate file types and content,
    it could be vulnerable to injection attacks such as cross-site scripting (XSS)
    or SQL injection.   −   Denial of Service (DoS) Attacks: Attackers may upload
    large or numerous files to overwhelm the system’s storage or processing capacity,
    leading to a denial of service.   2.  Privacy Risks:   −   Sensitive Data Exposure:
    Users might inadvertently upload files containing sensitive information, such
    as personal identification, financial data, or confidential documents.   −   Data
    Leakage: Improper handling of uploaded files could result in unintended exposure
    of data, especially if the files are accessible to unauthorized users.   3.  Compliance
    Risks:   −   Regulatory Compliance: Failure to comply with regulations like GDPR
    or HIPAA regarding the handling of personal or sensitive data could result in
    legal consequences.   −   Copyright Infringement: Users may upload copyrighted
    material without permission, exposing the platform to potential legal actions
    for copyright infringement.   4.  Performance Risks:   −   Bandwidth and Storage:
    Large file uploads can consume significant bandwidth and storage resources, potentially
    impacting system performance and scalability.   −   Concurrency: Multiple users
    uploading large files simultaneously could strain server resources and degrade
    system responsiveness. |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 实现文件上传功能可能会引入一些风险，包括：   1.  安全风险：   −   恶意文件：用户可能会上传包含恶意软件或病毒的文件，这可能会感染系统并危害安全。  
    −   注入攻击：如果系统未能正确验证文件类型和内容，它可能会容易受到跨站脚本（XSS）或SQL注入等注入攻击的攻击。   −   拒绝服务（DoS）攻击：攻击者可能会上传大量或多个文件来耗尽系统的存储或处理能力，导致服务拒绝。  
    2.  隐私风险：   −   敏感数据泄露：用户可能会无意中上传包含敏感信息的文件，如个人身份信息、财务数据或机密文件。   −   数据泄露：不当处理上传的文件可能会导致数据意外泄露，尤其是如果文件对未经授权的用户可访问。  
    3.  合规风险：   −   法规合规：未能遵守GDPR或HIPAA等法规，关于处理个人或敏感数据，可能会导致法律后果。   −   侵权：用户可能未经许可上传受版权保护的材料，使平台面临潜在的版权侵权法律诉讼。  
    4.  性能风险：   −   带宽和存储：大文件上传可能会消耗大量的带宽和存储资源，可能会影响系统性能和可扩展性。   −   并发：多个用户同时上传大文件可能会对服务器资源造成压力，并降低系统响应速度。
    |'
- en: If we put garbage in, we get garbage out, and if we’re not critical of how we’re
    interacting with LLMs, then trouble will ensue. We already know that to obtain
    value successfully from an LLM, we need to create prompts that are specific to
    the problem we want solved. When generating suitable risks, the challenge is being
    able to create those specific prompts for a complex system. The skills required
    to get to this point don’t lie in our ability to write a prompt but to break down
    a system into more manageable chunks. By doing this, we can then create more targeted
    and focused prompts. So, the question then turns to breaking a system down to
    create better prompts.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们输入垃圾，我们就会得到垃圾输出，如果我们不对我们与LLM的交互方式持批判态度，那么麻烦就会随之而来。我们已经知道，要从LLM中成功获得价值，我们需要创建针对我们想要解决的问题的具体提示。在生成合适的风险时，挑战在于能够为复杂系统创建这些特定的提示。达到这一点的技能不在于我们编写提示的能力，而在于将系统分解成更易于管理的块。通过这样做，我们就可以创建更具有针对性和专注性的提示。因此，问题转变为如何将系统分解以创建更好的提示。
- en: 5.2.2 What are models and why can they help
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2.2 模型是什么以及为什么它们能有所帮助
- en: Before we go into the process of using models to help us with our prompting,
    let’s clarify what is meant by models. When we use the term *model* in the context
    of testing and software development in general, we are referring to an abstract
    representation of some information. It can be something that is visualized (for
    example, a data flow diagram of an application), or it can be something held in
    our mind. We say that it is abstract because although it is based on information
    found in reality, a model usually simplifies, accentuates, or ignores certain
    aspects of the information it’s based upon. It provides a partial representation
    of the truth. This is why the aphorism “All models are wrong, but some are useful,”
    based on a quote from George Box, is used when discussing models. Models tend
    to be used to focus on specific attributes or concepts within a wider context.
    This might seem like criticism, but when put to good use, it can help us with
    problem-solving. For example, consider the model of an application shown in figure
    5.3.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们进入使用模型帮助我们进行提示的过程之前，让我们明确一下“模型”的含义。当我们使用“模型”这个词来指测试和软件开发时，我们是指某些信息的抽象表示。它可以是可视化的（例如，应用程序的数据流图），或者它可以是存储在我们心中的东西。我们说它是抽象的，因为尽管它基于现实中的信息，但模型通常简化、强调或忽略其基于的信息的某些方面。它提供了一个部分的真实图景。这就是为什么在讨论模型时使用乔治·博克斯的引言“所有模型都是错误的，但有些是有用的”这个格言的原因。模型倾向于用于关注更广泛背景下的特定属性或概念。这可能会被视为批评，但当它被良好地利用时，它可以帮助我们解决问题。例如，考虑图5.3中所示的应用程序模型。
- en: '![](../../OEBPS/Images/CH05_F03_Winteringham2.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH05_F03_Winteringham2.png)'
- en: Figure 5.3 A basic visualization of a model of a system
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.3 系统模型的基本可视化
- en: This visual model of an application has been designed to help its reader ascertain
    the dependencies between APIs. Notice how it doesn’t contain every detail of the
    platform. The APIs are abstracted into boxes that summarize the details of what
    code lives inside each API, and the front end of the system is simply summarized
    into a box titled ”User interface.” This model is flawed because it doesn’t give
    us an accurate picture of every aspect of the platform, but it is still useful
    because it accentuates the details that the reader cares about—the relationships
    between APIs on a platform. If the reader wants to understand APIs dependencies,
    then this model has value. However, if the reader wants to understand the implementation
    of the front end or the specific behavior of functions within each API, the model
    is worthless.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这个应用程序的视觉模型被设计用来帮助读者确定API之间的依赖关系。注意它并没有包含平台的所有细节。API被抽象为盒子，总结了每个API内部代码的细节，而系统的前端则简单地总结为名为“用户界面”的盒子。这个模型是有缺陷的，因为它没有给我们提供一个关于平台每个方面的准确图景，但它仍然是有用的，因为它强调了读者关心的细节——平台上的API之间的关系。如果读者想了解API的依赖关系，那么这个模型是有价值的。然而，如果读者想了解前端的具体实现或每个API内函数的具体行为，这个模型就毫无价值了。
- en: So, when creating a model, we lean into the idea of a model giving us only a
    partial picture by highlighting the information we want and discarding other details.
    This approach to modeling systems can help us make our prompts generate suggested
    risks that are more contextual and valuable.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在创建模型时，我们倾向于只通过突出我们想要的信息并丢弃其他细节来获得一个部分图景。这种系统建模的方法可以帮助我们使提示生成更具情境性和价值的建议风险。
- en: 5.3 Combining models and LLMs to assist test planning
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.3 结合模型和LLM以协助测试规划
- en: Now that you better understand the dangers of creating prompts that aren’t focused
    on a specific part of a system, let’s look at how we can mitigate this risk by
    using models. To demonstrate our model-based approach, let’s imagine we are using
    an LLM to help inform our test-planning process.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 既然你更好地理解了创建不专注于系统特定部分的提示的危险，让我们看看我们如何通过使用模型来减轻这种风险。为了展示我们的基于模型的策略，让我们假设我们正在使用一个LLM来帮助我们进行测试规划过程。
- en: 5.3.1 Creating a model to identify prompts
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.1 创建一个用于识别提示的模型
- en: Unsurprisingly, our first step is to create a model of the application. We’ll
    explore different formats we can use to create models shortly, but in the meantime,
    let’s imagine we’ve created a model that looks like the one shown in figure 5.4.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 毫不奇怪，我们的第一步是创建一个应用程序的模型。我们将在稍后探讨我们可以使用的不同格式来创建模型，但在此期间，让我们假设我们已经创建了一个类似于图5.4所示的模型。
- en: '![](../../OEBPS/Images/CH05_F04_Winteringham2.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH05_F04_Winteringham2.png)'
- en: Figure 5.4 A visual model of an application
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.4 应用程序的可视模型
- en: 'The model uses a data flow diagram to outline how data is handled in the process
    of requesting a collection of bookings from API. The model itself is not of an
    entire system, but of a specific piece of functionality that exists in a wider
    B&B/hotel booking management system. To break down what the model is specifying,
    when an administrator wants to see the lists of bookings stored in the database,
    the following steps take place:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 模型使用数据流图来概述在从API请求一系列预订的过程中数据是如何处理的。模型本身不是一个完整的系统，而是存在于更广泛的B&B/酒店预订管理系统中的一个特定功能部分。为了分解模型所指定的内容，当管理员想要查看存储在数据库中的预订列表时，以下步骤会发生：
- en: A request is sent to view the list of bookings, and a token is attached to the
    request.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 发送一个请求以查看预订列表，并将令牌附加到请求上。
- en: The token is then extracted from the initial request and sent to be validated
    against a list of valid sessions.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，令牌从初始请求中提取出来，并送去做验证，以对比有效会话列表。
- en: If the token is confirmed as a valid session, then a positive response is returned
    to part of the system that is managing the view bookings request.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果令牌被确认为一个有效的会话，那么一个积极的响应将被返回到管理视图预订请求的部分系统。
- en: The list of bookings is then collated and sent back to the administrator.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预订列表随后被汇总并发送回管理员。
- en: 'Considering this flow, let’s first look at the type of response we might get
    from an LLM if we were to build a prompt that attempts to encompass everything
    in the model at once. First, we would create a prompt:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这个流程，让我们首先看看如果我们构建一个尝试一次性包含模型中所有内容的提示，我们可能会从LLM（大型语言模型）得到什么样的响应。首先，我们会创建一个提示：
- en: '|'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-MW.png)'
- en: '| You are an expert software tester. Generate a list of risks for an application
    that uses session-based tokens to authorize access to view a list of bookings.
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 你是一位软件测试专家。为使用基于会话的令牌来授权访问查看预订列表的应用程序生成一份风险列表。 |'
- en: 'When the prompt is sent to an LLM, such as ChatGPT, we receive something like
    the following response:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 当提示被发送到一个LLM，例如ChatGPT时，我们会收到如下类似的响应：
- en: '|'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-openai.png)'
- en: '| Session Token Generation Flaws: The process of generating session tokens
    may have vulnerabilities, such as predictable token patterns, leading to token
    guessing attacks.Session Token Leakage: Session tokens might inadvertently get
    exposed in logs, error messages, or through insecure transmission channels, potentially
    leading to unauthorized access.Session Token Storage: Improper storage of session
    tokens, such as in cookies without secure flags or local storage susceptible to
    XSS attacks, could result in token theft.Session Hijacking: Lack of proper mechanisms
    to prevent session hijacking attacks, such as session fixation, where an attacker
    sets a user’s session token, or session replay attacks.Session Expiration: Inadequate
    session timeout configurations might lead to prolonged session exposures, increasing
    the window of opportunity for attackers to exploit stolen tokens.Session Fixation:
    Failure to invalidate and regenerate session tokens upon authentication events
    or significant state changes, enabling attackers to fixate sessions to known tokens.Insufficient
    Token Entropy: Session tokens generated with insufficient entropy may be susceptible
    to brute-force or dictionary attacks.Token Lifetime Management: Lack of proper
    mechanisms to manage token lifetimes, including revocation, renewal, and rotation,
    could result in prolonged exposure and increased risk of unauthorized access.Insecure
    Token Transmission: Session tokens transmitted over insecure channels, such as
    HTTP instead of HTTPS, are prone to interception and sniffing attacks.Cross-Site
    Request Forgery (CSRF): Inadequate CSRF protection could allow attackers to forge
    requests, leading to unauthorized actions using valid session tokens.Session Token
    Injection: Lack of proper input validation and output encoding might expose the
    application to session token injection attacks, allowing attackers to manipulate
    session states.Insecure Session Termination: Improper session termination mechanisms,
    such as failing to invalidate session tokens upon logout or session expiration,
    may lead to lingering session vulnerabilities.Session Data Integrity: Absence
    of integrity checks on session data may allow attackers to tamper with session
    parameters or payloads, leading to unauthorized access or data manipulation.Insufficient
    Logging and Monitoring: Inadequate logging of session-related events and insufficient
    monitoring for suspicious activities may impede timely detection and response
    to session-based attacks.Session Token Forensics: Lack of forensic capabilities
    to trace and investigate session-related incidents may hinder post-incident analysis
    and remediation efforts. |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
- en: 'The returned list looks quite long at first glance, but after reading it, there
    appear to be some problems. First, looking over the list of suggested risks, they
    are predominantly focused on security risks. Although security risks are important
    to consider, there are minimal risks focused on the interaction between the auth
    and booking components, or the compilation of the booking list. The LLM has taken
    the token portion of the prompt and focused too heavily on it. So, let’s consider
    a prompt created by focusing on a specific slice of the model we created:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 返回的列表乍一看很长，但阅读后，似乎存在一些问题。首先，查看建议的风险列表，它们主要集中在安全风险上。虽然安全风险是需要考虑的重要因素，但关于认证和预订组件之间的交互或预订列表的编制的风险却很少。LLM过于关注提示中的标记部分。因此，让我们考虑一个通过关注我们创建的模型的一个特定部分来创建的提示：
- en: '|'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-MW.png)'
- en: '| You are an expert software tester. Generate as many risks as possible for
    the behavior delimited by three hashes.###A Booking API that, once authorized,
    sends a list of bookings that are stored within a database to a user for review.###
    |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 你是一位软件测试专家。尽可能多地生成由三个井号定界的行为的风险。###一旦授权，将存储在数据库中的预订列表发送给用户进行审查的预订API### |'
- en: 'With this prompt, we’re attempting to describe a specific part of the system
    that has been captured in our model. Instead of asking for suggestions that cover
    all parts of the functionality at once, we select one part of the system to see
    if we can get better suggestions. This means that if we send this to an LLM such
    as ChatGPT, we might see the following list of suggestions (again reduced for
    readability):'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这个提示，我们试图描述系统中被我们模型捕获的特定部分。我们不是要求一次性涵盖所有功能部分的建议，而是选择系统的一个部分来查看我们是否能得到更好的建议。这意味着如果我们把这个发送给像ChatGPT这样的LLM，我们可能会看到以下建议列表（为了可读性再次进行了缩减）：
- en: '|'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-openai.png)'
- en: '|    1.  Data Security Risks:   −   Unauthorized access to sensitive booking
    data due to insufficient authentication or authorization mechanisms.   −   Risk
    of data breaches if the API doesn’t encrypt data transmission between the server
    and the user, leaving data vulnerable to interception.   −   Risk of SQL injection
    attacks if the API doesn’t sanitize inputs properly, leading to unauthorized access
    or manipulation of the database.   2.  Data Accuracy Risks:   −   Inaccurate or
    outdated booking information being transmitted to users if the API doesn’t synchronize
    properly with the database.   −   Risk of data corruption during transmission,
    leading to inconsistencies between the database and the information sent to users.  
    3.  Performance Risks:   −   Slow response times or timeouts if the API doesn’t
    handle a large volume of booking requests efficiently.   −   Risk of service degradation
    or downtime if the API cannot handle concurrent requests effectively, leading
    to performance bottlenecks.   4.  Scalability Risks:   −   Inability to handle
    increased traffic during peak booking periods, leading to system overload or crashes.  
    −   Risk of resource exhaustion if the API doesn’t scale dynamically to accommodate
    growing user demands, resulting in degraded performance.   5.  Dependency Risks:  
    −   Risk of service disruptions if the API relies on external dependencies (e.g.,
    third-party APIs, libraries, or services) that may experience downtime or changes
    in functionality.   −   Risk of version incompatibility if the API is built on
    outdated or deprecated frameworks, leading to compatibility issues with other
    systems or libraries.   6.  Error Handling Risks:   −   Inadequate error handling
    mechanisms that may result in ambiguous or misleading error messages, making it
    difficult for users to diagnose and troubleshoot issues.   −   Risk of exposing
    sensitive system information in error messages, potentially aiding attackers in
    exploiting vulnerabilities.   7.  Concurrency Risks:   −   Risk of data corruption
    or race conditions if the API doesn’t handle concurrent access to the database
    properly, leading to inconsistencies or data loss.   −   Inconsistent behavior
    or unexpected outcomes if the API doesn’t implement proper locking mechanisms
    to manage concurrent access to shared resources.   8.  Regulatory Compliance Risks:  
    −   Risk of non-compliance with data protection regulations (e.g., GDPR, HIPAA)
    if the API doesn’t adhere to industry standards for handling sensitive user data.  
    −   Potential legal consequences if the API fails to comply with industry-specific
    regulations (e.g., PCI DSS for payment data).   9.  Load Testing Risks:   −  
    Risk of performance degradation or system failure under heavy load if the API
    hasn’t been adequately tested for scalability and endurance.   −   Inaccurate
    capacity planning leading to under-provisioning or over-provisioning of resources,
    resulting in suboptimal performance or unnecessary costs.10.  Documentation Risks:  
    −   Risk of misunderstanding or misusing the API functionality if the documentation
    is incomplete, outdated, or unclear.   −   Potential delays in development or
    troubleshooting efforts if developers cannot rely on accurate and up-to-date API
    documentation. |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 1. 数据安全风险：由于认证或授权机制不足，可能导致对敏感预订数据的未授权访问。如果API没有加密服务器与用户之间的数据传输，数据可能容易受到拦截，存在数据泄露风险。如果API没有正确清理输入，存在SQL注入攻击风险，可能导致对数据库的未授权访问或篡改。'
- en: Let’s compare this response against the previous one we got from ChatGPT and
    see if there is an improvement. First, there was the problem of the initial prompt
    focusing too much on specific aspects of the functionality and ignoring other
    parts. Given that we’ve explicitly selected a distinct part of the system based
    on our model, it makes sense that a lot of focus in the new prompt response is
    on ways to test booking lists. We asked it to do that. But what stands out is
    the diversity of suggestions. In the initial prompt, most of the suggestions were
    based on different states that a token could be in; this prompt offers not only
    more suggestions, but also a mix of ideas around the correctness of bookings,
    boundaries, invalid data, and caching. Next, there was the problem of some suggestions
    being too vague to be actionable. Reviewing the suggestions that sit under each
    header, we can see they are more explicit—for example, the negative test suggestions
    mention specific types of status codes to consider.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们比较一下我们从ChatGPT那里得到的这个响应和之前的响应，看看是否有改进。首先，有一个问题就是初始提示过于关注功能的具体方面，而忽略了其他部分。鉴于我们已经根据我们的模型明确选择了一个不同的系统部分，那么新提示响应中大量关注测试预订列表的方式是有道理的。我们就是要求它这样做。但引人注目的是建议的多样性。在初始提示中，大部分建议都是基于标记可能处于的不同状态；这个提示不仅提供了更多的建议，还混合了关于预订正确性、边界、无效数据和缓存的多种想法。接下来，有一些建议过于模糊，无法采取行动。审查每个标题下的建议，我们可以看到它们更加明确——例如，负测试建议提到了需要考虑的具体状态码类型。
- en: 'The results are improved because LLMs respond better when more context is added
    to a prompt, and by using a model, we can slice up the behavior, focus on specific
    components, and capture and communicate the context in our prompt. This does mean
    we are ignoring other components in the model in favor of being focused so that
    we can communicate how a part of the system works. But if we iterate this process,
    we can change up which part of a model we want to create a prompt for. For example,
    we could run a second prompt that focuses exclusively on the token validation
    portion of the system to create a prompt like this:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 结果得到了改善，因为当在提示中添加更多上下文时，大型语言模型（LLMs）的响应更好，通过使用模型，我们可以分割行为，专注于特定的组件，并在我们的提示中捕捉和传达上下文。这确实意味着我们正在忽略模型中的其他组件，以便专注于如何传达系统的一部分工作。但如果我们迭代这个过程，我们可以改变我们想要为哪个模型部分创建提示。例如，我们可以运行一个专注于系统标记验证部分的第二个提示，创建如下提示：
- en: '|'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-MW.png)'
- en: '| You are an expert software tester. Generate as many risks as possible for
    the behavior delimited by three hashes.###An Authorization API that will take
    a token from a different API and check to see if the token is valid and in date
    before either responding positively or negatively depending on the result.###
    |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 你是一位专家软件测试员。尽可能多地生成由三个哈希符号分隔的行为的风险。###一个授权API，它将从不同的API获取令牌，并在响应积极或消极之前检查令牌是否有效且在有效期内。###
    |'
- en: 'When sent to an LLM like ChatGPT, it would return something like this:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 当发送到像ChatGPT这样的LLM时，它可能会返回如下内容：
- en: '|'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-openai.png)'
- en: '|    1.  Token Validation Failure: The Authorization API may fail to properly
    validate the token received from the different API, leading to unauthorized access.  
    2.  Expired Token: The Authorization API may not accurately detect expired tokens,
    allowing access to users who should no longer have permissions.   3.  False Positive/Negative
    Responses: There is a risk of the API providing incorrect responses, either granting
    access to unauthorized users or denying access to authorized ones.   4.  Performance
    Degradation: If the token validation process is resource-intensive, it may lead
    to performance degradation or even downtime during high traffic periods.   5. 
    Dependency Failure: If the different API providing tokens experiences downtime
    or issues, the Authorization API may not be able to perform its function correctly.  
    6.  Security Vulnerabilities: The Authorization API could be susceptible to security
    vulnerabilities such as injection attacks or improper access control mechanisms.  
    7.  Lack of Logging/Monitoring: Without proper logging and monitoring, it may
    be challenging to identify unauthorized access attempts or diagnose issues with
    token validation.   8.  Inadequate Error Handling: Poor error handling could result
    in ambiguous or misleading error messages, making it difficult for developers
    to troubleshoot integration issues.   9.  Token Spoofing: Malicious actors may
    attempt to spoof tokens to gain unauthorized access, exploiting weaknesses in
    the token validation process. 10.  Token Replay Attacks: Attackers could intercept
    valid tokens and replay them to gain unauthorized access, highlighting the importance
    of implementing measures to prevent token replay attacks. 11.  Token Expiry Race
    Condition: A race condition may occur if a token expires between the time it’s
    validated and the time access is granted, potentially allowing unauthorized access. 12. 
    Inconsistent Token Validation Logic: If the token validation logic differs between
    the Authorization API and the different API, it could lead to inconsistencies
    and unexpected behavior. 13.  Regulatory Compliance Issues: Failure to properly
    secure and validate tokens could result in non-compliance with industry regulations
    or data protection laws. 14.  Scalability Concerns: As the number of users and
    tokens increases, the scalability of the Authorization API may become a concern,
    potentially leading to performance issues or service disruptions. 15.  Integration
    Challenges: Integrating the Authorization API with the different API and other
    systems may present technical challenges, such as compatibility issues or data
    format mismatches. |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 1. 令牌验证失败：授权API可能无法正确验证从不同API接收到的令牌，导致未经授权的访问。2. 令牌过期：授权API可能无法准确检测过期的令牌，允许权限不再存在的用户访问。3.
    假阳性/假阴性响应：API可能提供不正确的响应，要么授予未经授权的用户访问权限，要么拒绝授权用户的访问。4. 性能下降：如果令牌验证过程资源密集，可能会导致在高流量期间性能下降或甚至停机。5.
    依赖性故障：如果提供令牌的不同API出现停机或问题，授权API可能无法正确执行其功能。6. 安全漏洞：授权API可能容易受到安全漏洞的影响，如注入攻击或不正确的访问控制机制。7.
    缺乏日志记录/监控：没有适当的日志记录和监控，可能难以识别未经授权的访问尝试或诊断令牌验证问题。8. 错误处理不足：较差的错误处理可能导致模糊或误导性的错误消息，使开发者难以调试集成问题。9.
    令牌欺骗：恶意行为者可能尝试欺骗令牌以获得未经授权的访问，利用令牌验证过程中的弱点。10. 令牌重放攻击：攻击者可能截获有效的令牌并重放它们以获得未经授权的访问，突出了实施防止令牌重放攻击措施的重要性。11.
    令牌过期竞争条件：如果令牌在验证和授权之间过期，可能会发生竞争条件，可能允许未经授权的访问。12. 令牌验证逻辑不一致：如果授权API和不同API之间的令牌验证逻辑不同，可能会导致不一致和意外的行为。13.
    法规遵从问题：未能正确保护和验证令牌可能导致不符合行业法规或数据保护法。14. 可扩展性担忧：随着用户和令牌数量的增加，授权API的可扩展性可能成为问题，可能导致性能问题或服务中断。15.
    集成挑战：将授权API与其他API和其他系统集成可能带来技术挑战，例如兼容性问题或数据格式不匹配。|'
- en: We would then pick suggestions from this list and add them to those we selected
    from the previous prompt response to build a list of risks that we might want
    to consider in our test planning.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从这个列表中选择建议，并将其添加到之前提示响应中选出的建议中，以构建一个我们可能在测试计划中考虑的风险列表。
- en: This demonstrates that to improve the quality of risk suggestions from an LLM,
    we need to understand system under test. Simply picking a requirement or feature
    and asking an LLM to generate risks will not work. The lack of context being provided
    to an LLM means it will rely on common patterns of behavior in similar feature
    requirements it has been trained on, which results in vague responses and hallucinations.
    To get something of value from an LLM, we need to be specific so that we provide
    rich contextual information for it to use, which we can get using models. By creating
    a model of the system, we not only improve our understanding of what we’re testing,
    but also compartmentalize parts of the system into specific areas that we can
    use to inform the type of prompts we write. We can then iterate through each part
    of the system, creating prompts to return suggestions that build up a collage
    of risks that are more relevant and more targeted on specific components and how
    they might behave.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明，为了提高LLM风险建议的质量，我们需要理解正在测试的系统。仅仅选择一个需求或特性，并要求LLM生成风险，是不会奏效的。提供给LLM的上下文不足意味着它将依赖于在类似特性需求中训练出的常见行为模式，这会导致模糊的回答和幻觉。要从LLM中获得有价值的东西，我们需要具体，以便为它提供丰富的上下文信息，我们可以通过模型来获取。通过创建系统的模型，我们不仅提高了对我们正在测试内容的理解，还将系统的部分划分为特定的区域，我们可以利用这些区域来指导我们编写的提示类型。然后，我们可以迭代系统的每个部分，创建提示以返回建议，构建一个更相关、更针对特定组件及其可能行为的风险拼贴画。
- en: All of this can once again be summarized using the area of effect model, as
    shown in figure 5.5.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都可以再次使用影响区域模型来总结，如图5.5所示。
- en: '![](../../OEBPS/Images/CH05_F05_Winteringham2.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH05_F05_Winteringham2.png)'
- en: Figure 5.5 Area of effect model showing the skills required to get valuable
    outputs from an LLM
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.5 影响区域模型，展示了从LLM获得有价值输出的所需技能
- en: The area of effect model shows how our modeling and analysis skills are what
    drive the LLM’s ability to provide value. If our understanding is weak, then so
    are our prompts, which means the results we get will be weak.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 影响区域模型展示了我们的建模和分析技能是如何驱动LLM（大型语言模型）提供价值的能力的。如果我们对系统的理解薄弱，那么我们的提示也会薄弱，这意味着我们得到的结果也会薄弱。
- en: Activity 5.1
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 活动5.1
- en: Pick a part of a system you are testing and create a model of how it works.
    Either create a data flow diagram or pick a different modeling technique. Once
    you’ve created your model, pick a specific part of the model and use it to create
    a targeted prompt to generate suggested risks.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 选择你正在测试的系统的一部分，并创建一个表示其工作原理的模型。你可以创建一个数据流图，或者选择不同的建模技术。一旦你创建了模型，选择模型的一个特定部分，并使用它来创建一个有针对性的提示，以生成建议的风险。
- en: 5.3.2 Experimenting with different model types
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3.2 尝试不同的模型类型
- en: In the example we have just explored, we used a data flow diagram approach to
    model how our system worked. However, as mentioned before, models are flawed,
    meaning the model we used previously helped us identify potential prompts from
    the perspective of how data is being handled in our application, but it omits
    other perspectives in the process. It’s therefore useful to experiment with different
    types of models to help us consider how our application works from different perspectives,
    which allows us to prompt an LLM to suggest a wide range of risks to use. So,
    let’s take a look at a few different types of modeling techniques to help us expand
    our work.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们刚刚探讨的例子中，我们使用数据流图方法来模拟我们的系统是如何工作的。然而，如前所述，模型是有缺陷的，这意味着我们之前使用的模型帮助我们从数据在应用程序中处理的角度识别出潜在的提示，但它忽略了过程中的其他视角。因此，尝试不同的模型类型对我们考虑从不同视角了解我们的应用程序是有用的，这使我们能够提示LLM提出广泛的风险建议。因此，让我们看看几种不同的建模技术，以帮助我们扩展我们的工作。
- en: Formal modeling techniques
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 正式建模技术
- en: When using the data flow diagram format (DTD), we employ explicit symbols and
    rules that belong to that format so that our model can visually explain what is
    happening as clearly as possible. DTDs, however, are just one of many different
    types of formal models that we can borrow and steal from to create models that
    work for us. For example, UML, or Unified Modeling Language, contains many different
    modeling approaches to look at an application from different perspectives. Structural
    UML diagrams such as component diagrams can be used to break down a system’s architecture
    and help us use LLMs to generate risks focused on specific parts of the system.
    For example, figure 5.6 demonstrates how we might interpret our booking list functionality
    as a component diagram.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用数据流图格式（DTD）时，我们采用该格式所属的显式符号和规则，以便我们的模型可以尽可能清晰地直观解释正在发生的事情。然而，DTD只是许多不同类型的正式模型中的一种，我们可以借鉴和窃取来创建适合我们的模型。例如，UML（统一建模语言）包含许多不同的建模方法，可以从不同的角度看待应用程序。结构化的UML图，如组件图，可以用来分解系统的架构，并帮助我们使用LLM（大型语言模型）生成针对系统特定部分的关注风险。例如，图5.6展示了我们如何将预订列表功能解释为组件图。
- en: '![](../../OEBPS/Images/CH05_F06_Winteringham2.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH05_F06_Winteringham2.png)'
- en: Figure 5.6 A component diagram of the booking list functionality
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.6 预订列表功能组件图
- en: 'It would result in a prompt that looks something like this:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这将导致一个类似于以下提示的信息：
- en: '|'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/logo-MW.png)'
- en: '| You are an expert software tester. Generate as many risks as possible for
    the behavior delimited by three hashes.###A `BookingRequest` class that sends
    out a request to an Auth API to confirm whether `BookingService` can complete
    its request### |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 你是一位软件测试专家。尽可能多地生成由三个井号定界的行为的潜在风险。###一个`BookingRequest`类向Auth API发送请求以确认`BookingService`能否完成其请求###
    |'
- en: We can also use behavioral diagrams such as sequence and use case diagrams to
    help us capture user flows through a system and create prompts that generate user-focused
    prompts (for example, a model like the one in figure 5.7).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用行为图，如序列图和用例图，来帮助我们捕捉系统中的用户流程，并创建生成以用户为中心的提示的提示（例如，如图5.7所示的模型）。
- en: '![](../../OEBPS/Images/CH05_F07_Winteringham2.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH05_F07_Winteringham2.png)'
- en: Figure 5.7 A user flow diagram of the booking list functionality
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.7 预订列表功能用户流程图
- en: 'It might help us create a prompt like this:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能有助于我们创建如下所示的提示：
- en: '|'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/logo-MW.png)'
- en: '| You are an expert software tester. Generate as many risks as possible for
    the behavior delimited by three hashes.###A user wants to view a list of bookings
    after logging into an application. They have logged in with the correct credentials
    and are requesting the booking list before their authorization has expired.###
    |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 你是一位软件测试专家。尽可能多地生成由三个井号定界的行为的潜在风险。###用户在登录应用程序后想要查看预订列表。他们已使用正确的凭证登录，并在授权过期之前请求预订列表###
    |'
- en: The options for formal-based models and diagrams are vast, so experimentation
    is recommended. Exploring how different models work and what types of prompting
    they trigger can help us determine the ones more suitable for us. We can also
    use what we learn from formal modeling techniques to build custom models that
    work for us.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 基于正式模型的选项和图表非常丰富，因此建议进行实验。探索不同模型的工作方式和它们能触发哪些类型的提示，可以帮助我们确定更适合我们的模型。我们还可以利用从正式建模技术中学到的知识来构建适合我们的自定义模型。
- en: Mental models
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 心智模型
- en: Although different formal modeling techniques can help us analyze our system
    from different perspectives, it is an expensive activity to carry out. Taking
    the time to model a system in different ways takes time and requires us to carry
    out extensive research to build up enough knowledge to frame our application in
    different ways. However, we can approach interpretations of models from another
    angle, in which we focus on changing our perception of a single model using heuristics.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管不同的正式建模技术可以帮助我们从不同的角度分析我们的系统，但进行这项活动是代价高昂的。花时间以不同的方式对系统进行建模需要时间，并要求我们进行广泛的研究，以积累足够的知识来以不同的方式构建我们的应用程序。然而，我们可以从另一个角度来处理模型解释，即我们通过启发式方法来改变对单个模型的认识。
- en: 'If we return to figure 5.7, the model is designed to walk us through the flow
    of how conditional actions determine what happens next. So, we create prompts
    that focus on those conditions because that’s what the model is designed to highlight.
    But what if we were to change our perception by adopting a different mental model?
    One example would be to use the mnemonic SFDIPOT, sometimes known as San Francisco
    Depot. Created by James Bach as part of the Heuristic Test Strategy Model ([https://mng.bz/o0lN](https://mng.bz/o0lN)),
    SFDIPOT is designed to help us consider a product from different perspectives;
    each letter in the mnemonic stands for a different perspective:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们回到图5.7，该模型旨在引导我们了解条件动作如何决定接下来发生什么。因此，我们创建专注于这些条件的提示，因为这是模型设计用来强调的。但如果我们通过采用不同的心智模型来改变我们的看法呢？一个例子是使用SFDIPOT记忆法，有时也称为旧金山车站。James
    Bach作为启发式测试策略模型的一部分创建了这个记忆法（[https://mng.bz/o0lN](https://mng.bz/o0lN)），SFDIPOT旨在帮助我们从不同的角度考虑产品；记忆法中的每个字母代表不同的视角：
- en: '*Structure*—What the product is made of'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*结构*—产品的构成'
- en: '*Function*—What the product does'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*功能*—产品做什么'
- en: '*Data*—What the product processes'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*数据*—产品处理的内容'
- en: '*Interfaces*—Ways in which the product can be interacted with'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*接口*—产品可以交互的方式'
- en: '*Platform*—What the product depends on'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*平台*—产品所依赖的'
- en: '*Operations*—How the product will be used'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*操作*—产品将如何被使用'
- en: '*Time*—How time affects the product'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*时间*—时间如何影响产品'
- en: 'Although this mnemonic can be used on a strategic level, we can also apply
    it to smaller sections of a system, as shown in figure 5.7\. We can use these
    different types of perspectives to re-evaluate our product through different lenses.
    For example, we might review figure 5.7 by asking how time might affect our functionality.
    It might inspire a prompt such as the following, which sets out initial instructions
    to generate risks and use the delimiter tactic:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这个记忆法可以在战略层面上使用，我们也可以将其应用于系统的较小部分，如图5.7所示。我们可以使用这些不同类型的视角通过不同的角度重新评估我们的产品。例如，我们可能会通过询问时间可能会如何影响我们的功能来审查图5.7。这可能会激发以下提示，该提示规定了生成风险和使用分隔符策略的初始指令：
- en: '|'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-MW.png)'
- en: '| You are an expert software tester. Generate as many risks as possible for
    the behavior delimited by three hashes.Focus on risks around the speed at which
    the user is using the system (fast or slow) and the amount of users who are using
    the system at a point in time. |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 你是一位软件测试专家。尽可能多地生成由三个井号定界的行为的风险。关注用户使用系统速度（快或慢）以及某一时刻使用系统的用户数量方面的风险。 |'
- en: 'We can use the time to think of tactics to avoid off-topic suggestions:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以利用这段时间来思考如何避免离题的建议：
- en: '|'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-MW.png)'
- en: '| Check that each suggestion matches the time conditions before outputting
    them. |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 在输出之前检查每个建议是否符合时间条件。 |'
- en: 'Then we’ll provide the context to work from:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将提供工作的背景：
- en: '|'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-MW.png)'
- en: '| ###A user wants to view a list of bookings after logging into an application.
    They have logged in with the correct credentials and are requesting the booking
    list before their authorization has expired.### |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| ###用户在登录应用程序后想要查看预订列表。他们已使用正确的凭证登录，并在授权过期之前请求预订列表。### |'
- en: 'Using a prompt like this can result in the following response:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 使用这样的提示可能会得到以下回应：
- en: '|'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-openai.png)'
- en: '|    1.  Single User - Normal Speed: One user logs in, accesses the booking
    list immediately after successful login, ensuring it displays within an acceptable
    response time.   2.  Single User - Slow Speed: A single user, with a slower internet
    connection, logs in and requests the booking list, examining how the system handles
    a delayed response.   3.  Multiple Users - Normal Speed: Multiple users simultaneously
    log in and request the booking list within a short time frame to observe if the
    system slows down or if there’s any impact on response time due to concurrent
    requests.   4.  Multiple Users - Slow Speed: Simulate multiple users accessing
    the system with slower connections, attempting to view the booking list concurrently
    to assess the system’s performance under slower network conditions and concurrent
    user requests.   5.  User Authorization Timing: A user attempts to access the
    booking list right before their authorization expires to verify if the system
    allows access or handles the request appropriately in this critical time window.  
    6.  Expiry of Authorization During Access: Simulate a scenario where a user’s
    authorization expires while they are viewing the booking list to ensure the system
    handles this expiration gracefully without crashing or showing sensitive information
    after the authorization has lapsed.   7.  Heavy Load Scenario: Generate a heavy
    load by increasing the number of simultaneous users significantly and assess how
    the system manages to provide the booking list without compromising response time
    or crashing due to the load.   8.  Concurrent Access and Authorization Renewal:
    Multiple users access the system simultaneously while some of their authorizations
    are expiring and getting renewed. This test verifies the system’s behavior when
    dealing with concurrent access and authorization renewal processes.   9.  Intermittent
    User Access: Users log in at different intervals, some requesting the booking
    list immediately after login while others perform various activities first. This
    test ensures that the system maintains consistent response times despite varied
    user behaviors. 10.  Randomized Access Timing: Randomly timed user requests for
    the booking list to emulate real-world scenarios, testing how the system copes
    with unpredictable and irregular access patterns. |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 1. 单用户 - 正常速度：一个用户登录后，立即访问预订列表，确保在可接受的响应时间内显示。2. 单用户 - 慢速速度：一个用户，拥有较慢的互联网连接，登录并请求预订列表，检查系统如何处理延迟响应。3.
    多用户 - 正常速度：多个用户在短时间内同时登录并请求预订列表，以观察系统是否会变慢或由于并发请求而对响应时间产生影响。4. 多用户 - 慢速速度：模拟多个用户使用较慢的连接访问系统，尝试同时查看预订列表，以评估系统在较慢网络条件和并发用户请求下的性能。5.
    用户授权时效：用户在授权即将到期之前尝试访问预订列表，以验证系统是否允许访问或在此关键时间窗口内适当地处理请求。6. 访问期间授权过期：模拟用户在查看预订列表时授权过期的情况，以确保系统优雅地处理此过期，不会在授权过期后崩溃或显示敏感信息。7.
    高负载场景：通过显著增加同时用户的数量来生成高负载，评估系统如何在不牺牲响应时间或因负载而崩溃的情况下提供预订列表。8. 并发访问和授权更新：多个用户同时访问系统，其中一些用户的授权正在过期并得到更新。此测试验证系统在处理并发访问和授权更新过程时的行为。9.
    间歇性用户访问：用户在不同时间间隔登录，一些用户在登录后立即请求预订列表，而另一些用户先执行各种活动。此测试确保系统在用户行为各异的情况下保持一致的响应时间。10.
    随机访问时间：随机时间用户请求预订列表，以模拟现实世界场景，测试系统如何应对不可预测和不规则的访问模式。|'
- en: The results of this response are much more focused on how a user or users might
    interact with a system. They are also much more detailed than some of the earlier
    high-level suggestions of load testing. The prompt includes explicit information
    about how the system is expected to work, but we’ve added focus for the prompt
    based on a shifted perspective of how we think the functionality in figure 5.7
    would work over time.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 此响应的结果更多地关注用户或用户如何与系统交互。它们也比早期一些高级负载测试的建议更为详细。提示中包含关于系统预期如何工作的明确信息，但我们已经根据对图5.7中功能随时间工作方式的转变视角，为提示添加了重点。
- en: Using heuristics such as SFDIPOT means we can quickly iterate over the same
    part of a model, but also shift our perspectives and read models in different
    ways to help us identify new instructions we can add to our prompts.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 使用SFDIPOT等启发式方法意味着我们可以快速迭代模型的部分，但也可以改变我们的视角，以不同的方式阅读模型，帮助我们识别可以添加到提示中的新指令。
- en: Activity 5.2
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 活动 5.2
- en: Create a new model using a different modeling technique of the same feature
    modeled in the earlier activity, or use the mental modeling technique to re-evaluate
    your existing model. Use them to come up with new prompts that can suggest unique
    ideas for the previous prompts that you created.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 使用与早期活动中建模的相同特征的不同建模技术创建一个新的模型，或者使用心智建模技术重新评估现有的模型。使用它们来提出新的提示，这些建议可以为之前创建的提示提供独特想法。
- en: 5.4 LLMs and test cases
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5.4 LLMs 和测试用例
- en: We began this chapter by asking whether LLMs can be used to generate test cases.
    Instead, we’ve taken a journey using risk as our guide to determine what type
    of testing we might do. The purpose was to show that we are in control of the
    direction we want our testing to take. Based on the risks that we identified and
    the ones suggested by an LLM, we might determine that the testing we carry out
    doesn’t need to rely on test cases at all.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们以询问是否可以使用 LLM 生成测试用例开始本章。相反，我们通过以风险为指南进行了一次旅行，以确定我们可能进行的测试类型。目的是表明我们在控制我们希望测试采取的方向。根据我们识别的风险和
    LLM 提出的风险，我们可能会确定我们进行的测试根本不需要依赖测试用例。
- en: 'However, if our planning has identified that test cases are indeed required,
    whether they are run manually or through automation, we have done the due diligence
    in identifying smaller, more focused segments of a feature through modeling that
    we can use in our prompts. For example, we might create a prompt that combines
    the modeling work we’ve done earlier, risks we’ve identified, and even example
    test cases we’ve already captured. We use the delimiter tactic to outline two
    sections of data:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们的规划确定确实需要测试用例，无论是手动运行还是通过自动化，我们已经通过建模识别了更小、更集中的功能段，这些段可以在我们的提示中使用。例如，我们可能会创建一个提示，结合我们之前所做的建模工作、我们已识别的风险，甚至是我们已经捕获的示例测试用例。我们使用分隔策略来概述两个数据部分：
- en: '|'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![logo-MW](../../OEBPS/Images/logo-MW.png)'
- en: '| You are an expert software tester. Generate suggested test cases based on
    the behavior delimited by three hashes and the test cases delimited by three back
    ticks.Focus on risks around the speed at which the user is using the system (fast
    or slow) and the amount of users who are using the system at a point in time.
    |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 你是一位专家软件测试员。基于由三个井号分隔的行为和由三个反引号分隔的测试用例，生成建议的测试用例。关注用户使用系统的速度（快或慢）以及在任何时间点使用系统的用户数量。
    |'
- en: 'We can take the time to think to stop repetition and focus on risk:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以花时间思考以停止重复并专注于风险：
- en: '|'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![logo-MW](../../OEBPS/Images/logo-MW.png)'
- en: '| Check that each suggestion matches the proposed risks before outputting them
    and that they are not a repeat of the test cases found in the section delimited
    by three backticks. |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 在输出之前检查每个建议是否与提出的风险相匹配，并且它们不是在由三个反引号分隔的区域内找到的测试用例的重复。 |'
- en: 'We then provide a capture area in the delimited section:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们随后在分隔区域内提供一个捕获区域：
- en: '|'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![logo-MW](../../OEBPS/Images/logo-MW.png)'
- en: '| ###A user wants to view a list of bookings after logging into an application.
    They have logged in with the correct credentials and are requesting the booking
    list before their authorization has expired.### |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| ### 用户在登录应用程序后想要查看预订列表。他们已使用正确的凭证登录，并在授权过期之前请求预订列表。### |'
- en: 'Finally, we provide test cases in delimited section:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们在分隔区域内提供测试用例：
- en: '|'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![logo-MW](../../OEBPS/Images/logo-MW.png)'
- en: '| [PRE0] |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| [PRE0] |'
- en: 'When sent to ChatGPT, it returned the following proposed test cases for me:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 当将内容发送到 ChatGPT 时，它为我返回了以下建议的测试用例：
- en: '|'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![logo-openai](../../OEBPS/Images/logo-openai.png)'
- en: '| Test Case 4: Single User - Fast Speed:   •   Test accessing the booking list
    immediately after logging in with valid credentials, but at a very fast pace.  
    •   Verify that the system can handle rapid requests without causing errors or
    unexpected behavior.Test Case 5: Multiple Concurrent Users - Normal Speed:   •  
    Have multiple users log in simultaneously and request the booking list.   •  
    Ensure that each user receives the correct booking list without delays or interference
    from other users’ requests.Test Case 6: Authorization Expiry:   •   Login with
    valid credentials and wait until the authorization expires.   •   Attempt to access
    the booking list again.   •   Verify that the system denies access or prompts
    the user to reauthenticate instead of displaying the booking list. |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 测试案例 4：单个用户 - 快速速度：   •   使用有效凭据登录后立即以非常快的速度访问预订列表。   •   验证系统是否能够处理快速请求而不会导致错误或意外行为。测试案例
    5：多个并发用户 - 正常速度：   •   让多个用户同时登录并请求预订列表。   •   确保每个用户都能及时接收到正确的预订列表，而不会受到其他用户请求的延迟或干扰。测试案例
    6：授权过期：   •   使用有效凭据登录并等待授权过期。   •   再次尝试访问预订列表。   •   验证系统拒绝访问或提示用户重新认证，而不是显示预订列表。
    |'
- en: Again, the goal here isn’t to blindly generate an exhaustive list of test cases
    but to critically evaluate what is suggested and see if it generates useful, novel
    ideas or inspires us to identify new test cases of our own.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这里的目的是不是盲目地生成一个详尽的测试案例列表，而是批判性地评估所提出的建议，看看它是否产生了有用、新颖的想法，或者激发我们识别自己新的测试案例。
- en: 5.4.1 Having a healthy skepticism of generated risks and test cases
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4.1 对生成的风险和测试案例保持健康的怀疑态度
- en: Codifying explicit steps about how to approach the testing of an application
    is no match for the complex, intuitive testing we do as humans. Test cases can
    help to a certain point, especially in the automation space, but we must avoid
    a monoculture of test cases that runs the risk of affecting the quality of our
    products rather than helping improve it. Therefore, we must be mindful that LLMs
    provide value as an assistant to our test-planning activities and are not an authority
    on what to test. The alternative is overrelying on LLMs to do our work, which
    makes users naively think that they can be trusted completely to replicate our
    testing, which in turn may make us generate thousands of test cases rapidly without
    thought and/or value. However, the danger doesn’t stem from LLMs alone. Instead,
    we must think carefully and methodically about what we are asking LLMs to create
    for us and be skeptical of what is returned.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 将如何测试应用程序的明确步骤编纂成法典，无法与人类复杂、直观的测试相媲美。测试案例可以在一定程度上帮助，尤其是在自动化领域，但我们必须避免测试案例的单调文化，这可能会影响我们产品的质量而不是帮助提高它。因此，我们必须意识到，LLM（大型语言模型）作为我们测试计划活动的助手提供价值，而不是测试权威。另一种选择是过度依赖LLM来完成我们的工作，这会让用户天真地认为它们可以完全信赖来复制我们的测试，这反过来又可能使我们迅速生成数千个测试案例，而缺乏思考和/或价值。然而，危险并不仅仅来自LLM。相反，我们必须仔细、系统地思考我们要求LLM为我们创建的内容，并对返回的内容持怀疑态度。
- en: Summary
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Test planning can range from informal notes to formal documentation on how testing
    will take place.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试计划可以从非正式笔记到关于如何进行测试的正式文档。
- en: All test planning, however, is rooted in the risks we care about in our testing.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然而，所有的测试计划都根植于我们在测试中关心的风险。
- en: Generic and vague prompting can harm our planning rather than assist it. Instead,
    we need to develop more accurate and specific prompting to generate useful suggestions.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 泛泛而谈的提示可能会损害我们的计划，而不是帮助它。相反，我们需要开发更准确和具体的提示来生成有用的建议。
- en: Using visual and mental models can help us break down a system to create better
    prompts.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用视觉和心智模型可以帮助我们分解系统以创建更好的提示。
- en: All models are flawed, but this can be used to our advantage to create models
    that accentuate details we care about to help us solve problems.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有模型都有缺陷，但我们可以利用这一点来创建强调我们关心的细节的模型，以帮助我们解决问题。
- en: Creating models allows us to break down a feature or segment of a system to
    better understand how its parts work.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建模型允许我们将功能或系统的一部分分解，以更好地理解其各部分是如何工作的。
- en: Building prompts based on specific parts of a model can help us produce valuable,
    accurate, and actionable suggestions.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于模型特定部分构建提示可以帮助我们产生有价值、准确和可操作的建议。
- en: We can use a range of different modeling techniques to obtain different perspectives
    on a system’s behavior.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们可以使用不同的建模技术来获得对系统行为的不同视角。
- en: Experimenting with different formal modeling approaches can help us generate
    different types of prompts.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尝试不同的形式化建模方法可以帮助我们生成不同类型的提示。
- en: Reviewing a single model with different mental models can help us shift our
    own internal biases and perspectives regarding what types of prompts to write.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用不同的心理模型来审查单个模型可以帮助我们改变自己关于编写哪些类型提示的内部偏见和观点。
- en: We should focus on what to test and use LLMs to suggest ideas, not the other
    way around.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们应该关注测试什么，并使用大型语言模型（LLMs）来提出想法，而不是反过来。
