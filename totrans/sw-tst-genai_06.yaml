- en: 5 Test planning with AI support
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs: []
  type: TYPE_NORMAL
- en: How the value of models is associated with the use of LLMs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using models with LLMs in test planning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evaluating the suitability of suggestions generated by LLMs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now that we’ve started to see how large language models (LLMs) can help support
    quality in development, it’s time to tackle the question of whether LLMs can generate
    test cases. On the surface, the answer is simple: yes, they can. But the deeper
    and more important question is why would you want them to generate test cases?
    What are we hoping to achieve by generating swathes of test cases without thought
    or direction? Just because we can create test cases doesn’t necessarily mean it’s
    the right thing to do in a given situation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The motivation behind the question comes from a desire to use LLMs to direct
    the required testing for a feature, an epic, or a project. Although LLMs may be
    valuable in terms of advising us what testing we should carry out, there are concerns
    about how trusting we should be and how much we should rely on LLMs. Much like
    other activities we’ve explored and will explore, there is a balance to be struck.
    On one hand, we must keep a healthy skepticism in place whenever we use LLMs to
    aid in testing, but we shouldn’t outright dismiss their potential value (as long
    as we keep that critical eye for when they might lead us astray). Therefore, this
    chapter will explore two questions at the core of how LLMs can guide the direction
    of the testing, focusing on how test planning is conducted:'
  prefs: []
  type: TYPE_NORMAL
- en: Can LLMs support us in our test planning?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can LLMs be used effectively to support said planning?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specifically, we’ll be looking at the activities we need to carry out when determining
    what type of testing is necessary for a feature, an epic, or a project. To do
    this, we’ll examine what test planning looks like in a modern software development
    team. But before that, we will identify how LLMs can best support us during the
    planning phase.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1 Defining test planning in modern testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'For most of us, a test plan implies detailed documentation that attempts to
    meticulously define how we will carry out our testing. But if you are someone
    who works in a modern, agile, software development team, ask yourself: When was
    the last time you documented a test plan for upcoming work? If so, what did it
    look like?'
  prefs: []
  type: TYPE_NORMAL
- en: Test planning these days comes in a myriad of forms. Some of us might say that
    we haven’t written a test plan for a long time, and others might capture key details
    in a one-page test plan or rely on acceptance criteria to determine what testing
    takes place. Others may still create formal test plans following stringent test
    plan templates. Whether our planning is conducted formally or informally, what
    drives a test plan are the risks to our product and project, and this relationship
    is illustrated in figure 5.1.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH05_F01_Winteringham2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 A diagram showing the relationship of risk and test planning
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, when we are planning the testing we intend to carry out, our core
    goal is to define and mitigate specific, measurable risks. The risks we define
    inform us of what testing we will do, and depending on the type of intended testing,
    we can consider different test ideas.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1.1 Test planning, LLMs, and area of effect
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Considering that risk is at the core of our testing, we need to establish a
    relationship with LLMs that helps elevate a risk-based planning approach, while
    ensuring that we aren’t too biased by an LLM’s output. A lot of discussion has
    been around how LLMs can be used to direct our testing by having them generate
    test cases for us. (For the sake of this discussion, we’ll include both automated
    and nonautomated test cases.) But just because an LLM can generate test cases
    doesn’t mean that they are necessary or relevant to mitigating the risks we care
    about. The result may be that some suggested test cases are of value, but using
    an LLM greatly increases the risk of running wasteful or misleading testing.
  prefs: []
  type: TYPE_NORMAL
- en: We want to be directed and efficient in our testing, so focusing on using an
    LLM to support us in identifying risks is key. First, it opens up how we conduct
    our testing. Asking an LLM to generate test cases ties us to one type of testing
    activity, and although there is a case for using test cases as part of a holistic
    strategy of different testing techniques, we shouldn’t rely on a monoculture of
    test cases alone. Instead, we should focus on risks to explore different concerns
    we might have without the bias of choosing a testing technique. Once we understand
    what risks we care about, we can select a suitable testing activity to mitigate
    said risks.
  prefs: []
  type: TYPE_NORMAL
- en: Second, and most importantly, focusing on risk changes the way we use an LLM.
    In figure 5.2, the area of effect model demonstrates how we can tell the LLM what
    features we are focusing on and what risks we have identified already.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH05_F02_Winteringham2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 Area of the effect model demonstrating the core roles of the human
    and the LLM as an assistant
  prefs: []
  type: TYPE_NORMAL
- en: As demonstrated in the figure, the LLM serves as an assistant that expands our
    ideas around risk and potentially help us uncover new risks that hadn’t been considered
    already, helping us expand our risk coverage, while ensuring we control the direction
    of our testing.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Focused prompts with the use of models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If we want to use LLMs to help us identify risks, we need to be aware of the
    hazards of an overreliance on them when determining what to focus on. To better
    understand this, let’s take a look at a common example of how LLMs are said to
    help with testing, why they can be problematic, and how we can better direct our
    use of LLMs to increase their value and decrease the risk of misdirected testing.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2.1 Weak prompts mean weak suggestions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Throughout Part 1 of this book, we’ve seen how poorly framed prompts such as
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Create tests for a file upload feature |'
  prefs: []
  type: TYPE_TB
- en: 'return a generic list of actionable results not rooted in a context, which
    means that they require a large amount of reworking or risk affecting the quality
    of our testing (reduced in size for readability):'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Implementing a file upload feature can introduce several risks, including:  
    1.  Security Risks:   −   Malicious Files: Users might upload files containing
    malware or viruses, which can infect the system and compromise security.   −  
    Injection Attacks: If the system doesn’t properly validate file types and content,
    it could be vulnerable to injection attacks such as cross-site scripting (XSS)
    or SQL injection.   −   Denial of Service (DoS) Attacks: Attackers may upload
    large or numerous files to overwhelm the system’s storage or processing capacity,
    leading to a denial of service.   2.  Privacy Risks:   −   Sensitive Data Exposure:
    Users might inadvertently upload files containing sensitive information, such
    as personal identification, financial data, or confidential documents.   −   Data
    Leakage: Improper handling of uploaded files could result in unintended exposure
    of data, especially if the files are accessible to unauthorized users.   3.  Compliance
    Risks:   −   Regulatory Compliance: Failure to comply with regulations like GDPR
    or HIPAA regarding the handling of personal or sensitive data could result in
    legal consequences.   −   Copyright Infringement: Users may upload copyrighted
    material without permission, exposing the platform to potential legal actions
    for copyright infringement.   4.  Performance Risks:   −   Bandwidth and Storage:
    Large file uploads can consume significant bandwidth and storage resources, potentially
    impacting system performance and scalability.   −   Concurrency: Multiple users
    uploading large files simultaneously could strain server resources and degrade
    system responsiveness. |'
  prefs: []
  type: TYPE_TB
- en: If we put garbage in, we get garbage out, and if we’re not critical of how we’re
    interacting with LLMs, then trouble will ensue. We already know that to obtain
    value successfully from an LLM, we need to create prompts that are specific to
    the problem we want solved. When generating suitable risks, the challenge is being
    able to create those specific prompts for a complex system. The skills required
    to get to this point don’t lie in our ability to write a prompt but to break down
    a system into more manageable chunks. By doing this, we can then create more targeted
    and focused prompts. So, the question then turns to breaking a system down to
    create better prompts.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2.2 What are models and why can they help
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before we go into the process of using models to help us with our prompting,
    let’s clarify what is meant by models. When we use the term *model* in the context
    of testing and software development in general, we are referring to an abstract
    representation of some information. It can be something that is visualized (for
    example, a data flow diagram of an application), or it can be something held in
    our mind. We say that it is abstract because although it is based on information
    found in reality, a model usually simplifies, accentuates, or ignores certain
    aspects of the information it’s based upon. It provides a partial representation
    of the truth. This is why the aphorism “All models are wrong, but some are useful,”
    based on a quote from George Box, is used when discussing models. Models tend
    to be used to focus on specific attributes or concepts within a wider context.
    This might seem like criticism, but when put to good use, it can help us with
    problem-solving. For example, consider the model of an application shown in figure
    5.3.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH05_F03_Winteringham2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.3 A basic visualization of a model of a system
  prefs: []
  type: TYPE_NORMAL
- en: This visual model of an application has been designed to help its reader ascertain
    the dependencies between APIs. Notice how it doesn’t contain every detail of the
    platform. The APIs are abstracted into boxes that summarize the details of what
    code lives inside each API, and the front end of the system is simply summarized
    into a box titled ”User interface.” This model is flawed because it doesn’t give
    us an accurate picture of every aspect of the platform, but it is still useful
    because it accentuates the details that the reader cares about—the relationships
    between APIs on a platform. If the reader wants to understand APIs dependencies,
    then this model has value. However, if the reader wants to understand the implementation
    of the front end or the specific behavior of functions within each API, the model
    is worthless.
  prefs: []
  type: TYPE_NORMAL
- en: So, when creating a model, we lean into the idea of a model giving us only a
    partial picture by highlighting the information we want and discarding other details.
    This approach to modeling systems can help us make our prompts generate suggested
    risks that are more contextual and valuable.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3 Combining models and LLMs to assist test planning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that you better understand the dangers of creating prompts that aren’t focused
    on a specific part of a system, let’s look at how we can mitigate this risk by
    using models. To demonstrate our model-based approach, let’s imagine we are using
    an LLM to help inform our test-planning process.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3.1 Creating a model to identify prompts
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unsurprisingly, our first step is to create a model of the application. We’ll
    explore different formats we can use to create models shortly, but in the meantime,
    let’s imagine we’ve created a model that looks like the one shown in figure 5.4.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH05_F04_Winteringham2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.4 A visual model of an application
  prefs: []
  type: TYPE_NORMAL
- en: 'The model uses a data flow diagram to outline how data is handled in the process
    of requesting a collection of bookings from API. The model itself is not of an
    entire system, but of a specific piece of functionality that exists in a wider
    B&B/hotel booking management system. To break down what the model is specifying,
    when an administrator wants to see the lists of bookings stored in the database,
    the following steps take place:'
  prefs: []
  type: TYPE_NORMAL
- en: A request is sent to view the list of bookings, and a token is attached to the
    request.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The token is then extracted from the initial request and sent to be validated
    against a list of valid sessions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the token is confirmed as a valid session, then a positive response is returned
    to part of the system that is managing the view bookings request.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The list of bookings is then collated and sent back to the administrator.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Considering this flow, let’s first look at the type of response we might get
    from an LLM if we were to build a prompt that attempts to encompass everything
    in the model at once. First, we would create a prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| You are an expert software tester. Generate a list of risks for an application
    that uses session-based tokens to authorize access to view a list of bookings.
    |'
  prefs: []
  type: TYPE_TB
- en: 'When the prompt is sent to an LLM, such as ChatGPT, we receive something like
    the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Session Token Generation Flaws: The process of generating session tokens
    may have vulnerabilities, such as predictable token patterns, leading to token
    guessing attacks.Session Token Leakage: Session tokens might inadvertently get
    exposed in logs, error messages, or through insecure transmission channels, potentially
    leading to unauthorized access.Session Token Storage: Improper storage of session
    tokens, such as in cookies without secure flags or local storage susceptible to
    XSS attacks, could result in token theft.Session Hijacking: Lack of proper mechanisms
    to prevent session hijacking attacks, such as session fixation, where an attacker
    sets a user’s session token, or session replay attacks.Session Expiration: Inadequate
    session timeout configurations might lead to prolonged session exposures, increasing
    the window of opportunity for attackers to exploit stolen tokens.Session Fixation:
    Failure to invalidate and regenerate session tokens upon authentication events
    or significant state changes, enabling attackers to fixate sessions to known tokens.Insufficient
    Token Entropy: Session tokens generated with insufficient entropy may be susceptible
    to brute-force or dictionary attacks.Token Lifetime Management: Lack of proper
    mechanisms to manage token lifetimes, including revocation, renewal, and rotation,
    could result in prolonged exposure and increased risk of unauthorized access.Insecure
    Token Transmission: Session tokens transmitted over insecure channels, such as
    HTTP instead of HTTPS, are prone to interception and sniffing attacks.Cross-Site
    Request Forgery (CSRF): Inadequate CSRF protection could allow attackers to forge
    requests, leading to unauthorized actions using valid session tokens.Session Token
    Injection: Lack of proper input validation and output encoding might expose the
    application to session token injection attacks, allowing attackers to manipulate
    session states.Insecure Session Termination: Improper session termination mechanisms,
    such as failing to invalidate session tokens upon logout or session expiration,
    may lead to lingering session vulnerabilities.Session Data Integrity: Absence
    of integrity checks on session data may allow attackers to tamper with session
    parameters or payloads, leading to unauthorized access or data manipulation.Insufficient
    Logging and Monitoring: Inadequate logging of session-related events and insufficient
    monitoring for suspicious activities may impede timely detection and response
    to session-based attacks.Session Token Forensics: Lack of forensic capabilities
    to trace and investigate session-related incidents may hinder post-incident analysis
    and remediation efforts. |'
  prefs: []
  type: TYPE_TB
- en: 'The returned list looks quite long at first glance, but after reading it, there
    appear to be some problems. First, looking over the list of suggested risks, they
    are predominantly focused on security risks. Although security risks are important
    to consider, there are minimal risks focused on the interaction between the auth
    and booking components, or the compilation of the booking list. The LLM has taken
    the token portion of the prompt and focused too heavily on it. So, let’s consider
    a prompt created by focusing on a specific slice of the model we created:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| You are an expert software tester. Generate as many risks as possible for
    the behavior delimited by three hashes.###A Booking API that, once authorized,
    sends a list of bookings that are stored within a database to a user for review.###
    |'
  prefs: []
  type: TYPE_TB
- en: 'With this prompt, we’re attempting to describe a specific part of the system
    that has been captured in our model. Instead of asking for suggestions that cover
    all parts of the functionality at once, we select one part of the system to see
    if we can get better suggestions. This means that if we send this to an LLM such
    as ChatGPT, we might see the following list of suggestions (again reduced for
    readability):'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '|    1.  Data Security Risks:   −   Unauthorized access to sensitive booking
    data due to insufficient authentication or authorization mechanisms.   −   Risk
    of data breaches if the API doesn’t encrypt data transmission between the server
    and the user, leaving data vulnerable to interception.   −   Risk of SQL injection
    attacks if the API doesn’t sanitize inputs properly, leading to unauthorized access
    or manipulation of the database.   2.  Data Accuracy Risks:   −   Inaccurate or
    outdated booking information being transmitted to users if the API doesn’t synchronize
    properly with the database.   −   Risk of data corruption during transmission,
    leading to inconsistencies between the database and the information sent to users.  
    3.  Performance Risks:   −   Slow response times or timeouts if the API doesn’t
    handle a large volume of booking requests efficiently.   −   Risk of service degradation
    or downtime if the API cannot handle concurrent requests effectively, leading
    to performance bottlenecks.   4.  Scalability Risks:   −   Inability to handle
    increased traffic during peak booking periods, leading to system overload or crashes.  
    −   Risk of resource exhaustion if the API doesn’t scale dynamically to accommodate
    growing user demands, resulting in degraded performance.   5.  Dependency Risks:  
    −   Risk of service disruptions if the API relies on external dependencies (e.g.,
    third-party APIs, libraries, or services) that may experience downtime or changes
    in functionality.   −   Risk of version incompatibility if the API is built on
    outdated or deprecated frameworks, leading to compatibility issues with other
    systems or libraries.   6.  Error Handling Risks:   −   Inadequate error handling
    mechanisms that may result in ambiguous or misleading error messages, making it
    difficult for users to diagnose and troubleshoot issues.   −   Risk of exposing
    sensitive system information in error messages, potentially aiding attackers in
    exploiting vulnerabilities.   7.  Concurrency Risks:   −   Risk of data corruption
    or race conditions if the API doesn’t handle concurrent access to the database
    properly, leading to inconsistencies or data loss.   −   Inconsistent behavior
    or unexpected outcomes if the API doesn’t implement proper locking mechanisms
    to manage concurrent access to shared resources.   8.  Regulatory Compliance Risks:  
    −   Risk of non-compliance with data protection regulations (e.g., GDPR, HIPAA)
    if the API doesn’t adhere to industry standards for handling sensitive user data.  
    −   Potential legal consequences if the API fails to comply with industry-specific
    regulations (e.g., PCI DSS for payment data).   9.  Load Testing Risks:   −  
    Risk of performance degradation or system failure under heavy load if the API
    hasn’t been adequately tested for scalability and endurance.   −   Inaccurate
    capacity planning leading to under-provisioning or over-provisioning of resources,
    resulting in suboptimal performance or unnecessary costs.10.  Documentation Risks:  
    −   Risk of misunderstanding or misusing the API functionality if the documentation
    is incomplete, outdated, or unclear.   −   Potential delays in development or
    troubleshooting efforts if developers cannot rely on accurate and up-to-date API
    documentation. |'
  prefs: []
  type: TYPE_TB
- en: Let’s compare this response against the previous one we got from ChatGPT and
    see if there is an improvement. First, there was the problem of the initial prompt
    focusing too much on specific aspects of the functionality and ignoring other
    parts. Given that we’ve explicitly selected a distinct part of the system based
    on our model, it makes sense that a lot of focus in the new prompt response is
    on ways to test booking lists. We asked it to do that. But what stands out is
    the diversity of suggestions. In the initial prompt, most of the suggestions were
    based on different states that a token could be in; this prompt offers not only
    more suggestions, but also a mix of ideas around the correctness of bookings,
    boundaries, invalid data, and caching. Next, there was the problem of some suggestions
    being too vague to be actionable. Reviewing the suggestions that sit under each
    header, we can see they are more explicit—for example, the negative test suggestions
    mention specific types of status codes to consider.
  prefs: []
  type: TYPE_NORMAL
- en: 'The results are improved because LLMs respond better when more context is added
    to a prompt, and by using a model, we can slice up the behavior, focus on specific
    components, and capture and communicate the context in our prompt. This does mean
    we are ignoring other components in the model in favor of being focused so that
    we can communicate how a part of the system works. But if we iterate this process,
    we can change up which part of a model we want to create a prompt for. For example,
    we could run a second prompt that focuses exclusively on the token validation
    portion of the system to create a prompt like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| You are an expert software tester. Generate as many risks as possible for
    the behavior delimited by three hashes.###An Authorization API that will take
    a token from a different API and check to see if the token is valid and in date
    before either responding positively or negatively depending on the result.###
    |'
  prefs: []
  type: TYPE_TB
- en: 'When sent to an LLM like ChatGPT, it would return something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '|    1.  Token Validation Failure: The Authorization API may fail to properly
    validate the token received from the different API, leading to unauthorized access.  
    2.  Expired Token: The Authorization API may not accurately detect expired tokens,
    allowing access to users who should no longer have permissions.   3.  False Positive/Negative
    Responses: There is a risk of the API providing incorrect responses, either granting
    access to unauthorized users or denying access to authorized ones.   4.  Performance
    Degradation: If the token validation process is resource-intensive, it may lead
    to performance degradation or even downtime during high traffic periods.   5. 
    Dependency Failure: If the different API providing tokens experiences downtime
    or issues, the Authorization API may not be able to perform its function correctly.  
    6.  Security Vulnerabilities: The Authorization API could be susceptible to security
    vulnerabilities such as injection attacks or improper access control mechanisms.  
    7.  Lack of Logging/Monitoring: Without proper logging and monitoring, it may
    be challenging to identify unauthorized access attempts or diagnose issues with
    token validation.   8.  Inadequate Error Handling: Poor error handling could result
    in ambiguous or misleading error messages, making it difficult for developers
    to troubleshoot integration issues.   9.  Token Spoofing: Malicious actors may
    attempt to spoof tokens to gain unauthorized access, exploiting weaknesses in
    the token validation process. 10.  Token Replay Attacks: Attackers could intercept
    valid tokens and replay them to gain unauthorized access, highlighting the importance
    of implementing measures to prevent token replay attacks. 11.  Token Expiry Race
    Condition: A race condition may occur if a token expires between the time it’s
    validated and the time access is granted, potentially allowing unauthorized access. 12. 
    Inconsistent Token Validation Logic: If the token validation logic differs between
    the Authorization API and the different API, it could lead to inconsistencies
    and unexpected behavior. 13.  Regulatory Compliance Issues: Failure to properly
    secure and validate tokens could result in non-compliance with industry regulations
    or data protection laws. 14.  Scalability Concerns: As the number of users and
    tokens increases, the scalability of the Authorization API may become a concern,
    potentially leading to performance issues or service disruptions. 15.  Integration
    Challenges: Integrating the Authorization API with the different API and other
    systems may present technical challenges, such as compatibility issues or data
    format mismatches. |'
  prefs: []
  type: TYPE_TB
- en: We would then pick suggestions from this list and add them to those we selected
    from the previous prompt response to build a list of risks that we might want
    to consider in our test planning.
  prefs: []
  type: TYPE_NORMAL
- en: This demonstrates that to improve the quality of risk suggestions from an LLM,
    we need to understand system under test. Simply picking a requirement or feature
    and asking an LLM to generate risks will not work. The lack of context being provided
    to an LLM means it will rely on common patterns of behavior in similar feature
    requirements it has been trained on, which results in vague responses and hallucinations.
    To get something of value from an LLM, we need to be specific so that we provide
    rich contextual information for it to use, which we can get using models. By creating
    a model of the system, we not only improve our understanding of what we’re testing,
    but also compartmentalize parts of the system into specific areas that we can
    use to inform the type of prompts we write. We can then iterate through each part
    of the system, creating prompts to return suggestions that build up a collage
    of risks that are more relevant and more targeted on specific components and how
    they might behave.
  prefs: []
  type: TYPE_NORMAL
- en: All of this can once again be summarized using the area of effect model, as
    shown in figure 5.5.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH05_F05_Winteringham2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.5 Area of effect model showing the skills required to get valuable
    outputs from an LLM
  prefs: []
  type: TYPE_NORMAL
- en: The area of effect model shows how our modeling and analysis skills are what
    drive the LLM’s ability to provide value. If our understanding is weak, then so
    are our prompts, which means the results we get will be weak.
  prefs: []
  type: TYPE_NORMAL
- en: Activity 5.1
  prefs: []
  type: TYPE_NORMAL
- en: Pick a part of a system you are testing and create a model of how it works.
    Either create a data flow diagram or pick a different modeling technique. Once
    you’ve created your model, pick a specific part of the model and use it to create
    a targeted prompt to generate suggested risks.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3.2 Experimenting with different model types
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the example we have just explored, we used a data flow diagram approach to
    model how our system worked. However, as mentioned before, models are flawed,
    meaning the model we used previously helped us identify potential prompts from
    the perspective of how data is being handled in our application, but it omits
    other perspectives in the process. It’s therefore useful to experiment with different
    types of models to help us consider how our application works from different perspectives,
    which allows us to prompt an LLM to suggest a wide range of risks to use. So,
    let’s take a look at a few different types of modeling techniques to help us expand
    our work.
  prefs: []
  type: TYPE_NORMAL
- en: Formal modeling techniques
  prefs: []
  type: TYPE_NORMAL
- en: When using the data flow diagram format (DTD), we employ explicit symbols and
    rules that belong to that format so that our model can visually explain what is
    happening as clearly as possible. DTDs, however, are just one of many different
    types of formal models that we can borrow and steal from to create models that
    work for us. For example, UML, or Unified Modeling Language, contains many different
    modeling approaches to look at an application from different perspectives. Structural
    UML diagrams such as component diagrams can be used to break down a system’s architecture
    and help us use LLMs to generate risks focused on specific parts of the system.
    For example, figure 5.6 demonstrates how we might interpret our booking list functionality
    as a component diagram.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH05_F06_Winteringham2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.6 A component diagram of the booking list functionality
  prefs: []
  type: TYPE_NORMAL
- en: 'It would result in a prompt that looks something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| You are an expert software tester. Generate as many risks as possible for
    the behavior delimited by three hashes.###A `BookingRequest` class that sends
    out a request to an Auth API to confirm whether `BookingService` can complete
    its request### |'
  prefs: []
  type: TYPE_TB
- en: We can also use behavioral diagrams such as sequence and use case diagrams to
    help us capture user flows through a system and create prompts that generate user-focused
    prompts (for example, a model like the one in figure 5.7).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH05_F07_Winteringham2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.7 A user flow diagram of the booking list functionality
  prefs: []
  type: TYPE_NORMAL
- en: 'It might help us create a prompt like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| You are an expert software tester. Generate as many risks as possible for
    the behavior delimited by three hashes.###A user wants to view a list of bookings
    after logging into an application. They have logged in with the correct credentials
    and are requesting the booking list before their authorization has expired.###
    |'
  prefs: []
  type: TYPE_TB
- en: The options for formal-based models and diagrams are vast, so experimentation
    is recommended. Exploring how different models work and what types of prompting
    they trigger can help us determine the ones more suitable for us. We can also
    use what we learn from formal modeling techniques to build custom models that
    work for us.
  prefs: []
  type: TYPE_NORMAL
- en: Mental models
  prefs: []
  type: TYPE_NORMAL
- en: Although different formal modeling techniques can help us analyze our system
    from different perspectives, it is an expensive activity to carry out. Taking
    the time to model a system in different ways takes time and requires us to carry
    out extensive research to build up enough knowledge to frame our application in
    different ways. However, we can approach interpretations of models from another
    angle, in which we focus on changing our perception of a single model using heuristics.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we return to figure 5.7, the model is designed to walk us through the flow
    of how conditional actions determine what happens next. So, we create prompts
    that focus on those conditions because that’s what the model is designed to highlight.
    But what if we were to change our perception by adopting a different mental model?
    One example would be to use the mnemonic SFDIPOT, sometimes known as San Francisco
    Depot. Created by James Bach as part of the Heuristic Test Strategy Model ([https://mng.bz/o0lN](https://mng.bz/o0lN)),
    SFDIPOT is designed to help us consider a product from different perspectives;
    each letter in the mnemonic stands for a different perspective:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Structure*—What the product is made of'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Function*—What the product does'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Data*—What the product processes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Interfaces*—Ways in which the product can be interacted with'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Platform*—What the product depends on'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Operations*—How the product will be used'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Time*—How time affects the product'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Although this mnemonic can be used on a strategic level, we can also apply
    it to smaller sections of a system, as shown in figure 5.7\. We can use these
    different types of perspectives to re-evaluate our product through different lenses.
    For example, we might review figure 5.7 by asking how time might affect our functionality.
    It might inspire a prompt such as the following, which sets out initial instructions
    to generate risks and use the delimiter tactic:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| You are an expert software tester. Generate as many risks as possible for
    the behavior delimited by three hashes.Focus on risks around the speed at which
    the user is using the system (fast or slow) and the amount of users who are using
    the system at a point in time. |'
  prefs: []
  type: TYPE_TB
- en: 'We can use the time to think of tactics to avoid off-topic suggestions:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Check that each suggestion matches the time conditions before outputting
    them. |'
  prefs: []
  type: TYPE_TB
- en: 'Then we’ll provide the context to work from:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| ###A user wants to view a list of bookings after logging into an application.
    They have logged in with the correct credentials and are requesting the booking
    list before their authorization has expired.### |'
  prefs: []
  type: TYPE_TB
- en: 'Using a prompt like this can result in the following response:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '|    1.  Single User - Normal Speed: One user logs in, accesses the booking
    list immediately after successful login, ensuring it displays within an acceptable
    response time.   2.  Single User - Slow Speed: A single user, with a slower internet
    connection, logs in and requests the booking list, examining how the system handles
    a delayed response.   3.  Multiple Users - Normal Speed: Multiple users simultaneously
    log in and request the booking list within a short time frame to observe if the
    system slows down or if there’s any impact on response time due to concurrent
    requests.   4.  Multiple Users - Slow Speed: Simulate multiple users accessing
    the system with slower connections, attempting to view the booking list concurrently
    to assess the system’s performance under slower network conditions and concurrent
    user requests.   5.  User Authorization Timing: A user attempts to access the
    booking list right before their authorization expires to verify if the system
    allows access or handles the request appropriately in this critical time window.  
    6.  Expiry of Authorization During Access: Simulate a scenario where a user’s
    authorization expires while they are viewing the booking list to ensure the system
    handles this expiration gracefully without crashing or showing sensitive information
    after the authorization has lapsed.   7.  Heavy Load Scenario: Generate a heavy
    load by increasing the number of simultaneous users significantly and assess how
    the system manages to provide the booking list without compromising response time
    or crashing due to the load.   8.  Concurrent Access and Authorization Renewal:
    Multiple users access the system simultaneously while some of their authorizations
    are expiring and getting renewed. This test verifies the system’s behavior when
    dealing with concurrent access and authorization renewal processes.   9.  Intermittent
    User Access: Users log in at different intervals, some requesting the booking
    list immediately after login while others perform various activities first. This
    test ensures that the system maintains consistent response times despite varied
    user behaviors. 10.  Randomized Access Timing: Randomly timed user requests for
    the booking list to emulate real-world scenarios, testing how the system copes
    with unpredictable and irregular access patterns. |'
  prefs: []
  type: TYPE_TB
- en: The results of this response are much more focused on how a user or users might
    interact with a system. They are also much more detailed than some of the earlier
    high-level suggestions of load testing. The prompt includes explicit information
    about how the system is expected to work, but we’ve added focus for the prompt
    based on a shifted perspective of how we think the functionality in figure 5.7
    would work over time.
  prefs: []
  type: TYPE_NORMAL
- en: Using heuristics such as SFDIPOT means we can quickly iterate over the same
    part of a model, but also shift our perspectives and read models in different
    ways to help us identify new instructions we can add to our prompts.
  prefs: []
  type: TYPE_NORMAL
- en: Activity 5.2
  prefs: []
  type: TYPE_NORMAL
- en: Create a new model using a different modeling technique of the same feature
    modeled in the earlier activity, or use the mental modeling technique to re-evaluate
    your existing model. Use them to come up with new prompts that can suggest unique
    ideas for the previous prompts that you created.
  prefs: []
  type: TYPE_NORMAL
- en: 5.4 LLMs and test cases
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We began this chapter by asking whether LLMs can be used to generate test cases.
    Instead, we’ve taken a journey using risk as our guide to determine what type
    of testing we might do. The purpose was to show that we are in control of the
    direction we want our testing to take. Based on the risks that we identified and
    the ones suggested by an LLM, we might determine that the testing we carry out
    doesn’t need to rely on test cases at all.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, if our planning has identified that test cases are indeed required,
    whether they are run manually or through automation, we have done the due diligence
    in identifying smaller, more focused segments of a feature through modeling that
    we can use in our prompts. For example, we might create a prompt that combines
    the modeling work we’ve done earlier, risks we’ve identified, and even example
    test cases we’ve already captured. We use the delimiter tactic to outline two
    sections of data:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| You are an expert software tester. Generate suggested test cases based on
    the behavior delimited by three hashes and the test cases delimited by three back
    ticks.Focus on risks around the speed at which the user is using the system (fast
    or slow) and the amount of users who are using the system at a point in time.
    |'
  prefs: []
  type: TYPE_TB
- en: 'We can take the time to think to stop repetition and focus on risk:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Check that each suggestion matches the proposed risks before outputting them
    and that they are not a repeat of the test cases found in the section delimited
    by three backticks. |'
  prefs: []
  type: TYPE_TB
- en: 'We then provide a capture area in the delimited section:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| ###A user wants to view a list of bookings after logging into an application.
    They have logged in with the correct credentials and are requesting the booking
    list before their authorization has expired.### |'
  prefs: []
  type: TYPE_TB
- en: 'Finally, we provide test cases in delimited section:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| [PRE0] |'
  prefs: []
  type: TYPE_TB
- en: 'When sent to ChatGPT, it returned the following proposed test cases for me:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Test Case 4: Single User - Fast Speed:   •   Test accessing the booking list
    immediately after logging in with valid credentials, but at a very fast pace.  
    •   Verify that the system can handle rapid requests without causing errors or
    unexpected behavior.Test Case 5: Multiple Concurrent Users - Normal Speed:   •  
    Have multiple users log in simultaneously and request the booking list.   •  
    Ensure that each user receives the correct booking list without delays or interference
    from other users’ requests.Test Case 6: Authorization Expiry:   •   Login with
    valid credentials and wait until the authorization expires.   •   Attempt to access
    the booking list again.   •   Verify that the system denies access or prompts
    the user to reauthenticate instead of displaying the booking list. |'
  prefs: []
  type: TYPE_TB
- en: Again, the goal here isn’t to blindly generate an exhaustive list of test cases
    but to critically evaluate what is suggested and see if it generates useful, novel
    ideas or inspires us to identify new test cases of our own.
  prefs: []
  type: TYPE_NORMAL
- en: 5.4.1 Having a healthy skepticism of generated risks and test cases
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Codifying explicit steps about how to approach the testing of an application
    is no match for the complex, intuitive testing we do as humans. Test cases can
    help to a certain point, especially in the automation space, but we must avoid
    a monoculture of test cases that runs the risk of affecting the quality of our
    products rather than helping improve it. Therefore, we must be mindful that LLMs
    provide value as an assistant to our test-planning activities and are not an authority
    on what to test. The alternative is overrelying on LLMs to do our work, which
    makes users naively think that they can be trusted completely to replicate our
    testing, which in turn may make us generate thousands of test cases rapidly without
    thought and/or value. However, the danger doesn’t stem from LLMs alone. Instead,
    we must think carefully and methodically about what we are asking LLMs to create
    for us and be skeptical of what is returned.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Test planning can range from informal notes to formal documentation on how testing
    will take place.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All test planning, however, is rooted in the risks we care about in our testing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generic and vague prompting can harm our planning rather than assist it. Instead,
    we need to develop more accurate and specific prompting to generate useful suggestions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using visual and mental models can help us break down a system to create better
    prompts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All models are flawed, but this can be used to our advantage to create models
    that accentuate details we care about to help us solve problems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating models allows us to break down a feature or segment of a system to
    better understand how its parts work.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building prompts based on specific parts of a model can help us produce valuable,
    accurate, and actionable suggestions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can use a range of different modeling techniques to obtain different perspectives
    on a system’s behavior.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Experimenting with different formal modeling approaches can help us generate
    different types of prompts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reviewing a single model with different mental models can help us shift our
    own internal biases and perspectives regarding what types of prompts to write.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We should focus on what to test and use LLMs to suggest ideas, not the other
    way around.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
