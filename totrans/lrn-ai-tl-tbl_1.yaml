- en: Chapter 1\. AI in the Tableau Platform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Artificial intelligence isn’t new. It’s been around since the famous mathematician
    Alan Turing first asked, “Can machines think?” in his well known 1950 paper “Computing
    Machinery and Intelligence.” AI was formalized into an academic area for research,
    study, and innovation (according to many academics and historians in the field)
    in 1956\. In the beginning, we can imagine that the goals of AI were to replicate
    or emulate human intelligence and decision making. This may have been best stated
    by computer scientist John McCarthy, who coined the term *artificial intelligence*:
    “Every aspect of learning or any other feature of intelligence can in principle
    be so precisely described that a machine can be made to simulate it.” Many would
    add that computers could (in theory and now in practice) handle complex operations—sometimes
    much more complex (particularly mathematical ones) than humans could.'
  prefs: []
  type: TYPE_NORMAL
- en: Since that time, AI has slowly woven itself into every area of our lives. The
    idea of being bested by a computer at chess is nothing new. In fact, AI’s place
    in any sort of strategic game now feels common and expected. More recent and prolific
    applications of AI would include recommendation engines, such as those determining
    what to watch next on Netflix or what to buy on Amazon. Voice assistants like
    Apple’s Siri that can translate your speech into some type of action also qualify
    as AI. And then there are self-driving vehicles like Google’s Waymo that take
    the idea of *autopilot*, a concept that’s been around for roughly 100 years, to
    a brand-new paradigm.
  prefs: []
  type: TYPE_NORMAL
- en: So much of AI has depended on the capabilities of computers. Early computers
    were limited in the information and knowledge that they could hold. And similarly,
    even if they had access to the knowledge, the computational and processing power
    necessary to access, retrieve, and serve up that information was massive. But
    in the early 2000s, the pace of innovation with computer hardware caught up with
    the needs of AI. Multiple processors and multithreading proliferated, smartphones
    became prominent fixtures in our everyday lives, and cloud computing became the
    new normal.
  prefs: []
  type: TYPE_NORMAL
- en: AI in Analytics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As advancements in computer hardware became more prominent, the domain of analytics
    started to see its own advancements. In particular, this meant the inclusion of
    more advanced methods of mathematical analysis. *Multivariate analysis* became
    more pervasive in business applications as more knowledge workers could lean on
    computers to help with the complex mathematical computations. *Predictive analytics*
    and the ways in which something could be predicted expanded from the simple linear
    regression model of old to much more robust and sophisticated methods. Classification
    methods, like *k-means clustering* (available in Tableau) were possible. Machine
    learning (ML), both *supervised*, where the input and output are provided to the
    model, and *unsupervised*, where models are given the freedom to derive their
    own patterns, came into prominence. A computer could now be given a massive amount
    of data and draw conclusions with varying levels of aid and decision input from
    humans.
  prefs: []
  type: TYPE_NORMAL
- en: Then came *natural language processing* (NLP). As mentioned in the Preface,
    Ask Data was released by Tableau in 2018, allowing users to ask a question and
    get an answer, but speech recognition and transcription tools have been living
    in the business world for much longer. *Sentiment analysis*—or the process of
    scoring language to determine whether it is positive, negative, or neutral—started
    becoming mainstream. Computer languages like Python and R became prominent, and
    the practice of data science and the emergence of the data scientist reached a
    fever pitch in the 2010s, along with the term *big data*.
  prefs: []
  type: TYPE_NORMAL
- en: 2018 also heralded the first *generative pre-trained transformer* (GPT) technologies,
    a type of *large language model* (LLM), by OpenAI, the company that soon became
    known for its famous ChatGPT chatbot, capable of having coherent and improvised
    conversations with humans, and its generative digital art tool DALL-E. I was introduced
    to both technologies in 2022\. I signed up for the early invitation-only beta
    of DALL-E and loved creating digital art that would have been previously out of
    my own reach (like melting bar charts in the style of Salvador Dali, and Darth
    Vader walking Princess Leia down the aisle as a heartfelt watercolor vignette
    (see [Figure 1-1](#ch01_figure_1_1732595607196098)). AI-generated sonnets, poems,
    parodies, and rote business communications started popping up as novelties at
    my workplace. My then-boss jokingly posted his ChatGPT-created professional biography
    which included glowing praise of who he was but was also littered with inaccuracies
    and accolades that he had never received. Generative and creative AI had officially
    arrived.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/lait_0101.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-1\. AI-generated art created using DALL-E (left) and MidJourney (right)
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The technology and structure underpinning LLMs and GPTs are in full use in both
    Tableau Pulse and Tableau Agent, the focal points of this book. Both rely heavily
    on LLMs. In Pulse, an LLM is used to summarize the insights and serve them up
    in a meaningful way. With Tableau Agent, you get direct interaction and results
    based on your input into a chat box. This is a very privileged position for technology
    to have in our domain, and as such, it’s important for analytics professionals
    to understand how AI technology works as much as possible. Referring to generative
    AI as opaque or enigmatic technology isn’t acceptable when you’re serving up information
    to end users to make business-critical and sometimes life-or-death decisions based
    on data.
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI Explained
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A good way to think about how LLMs and GPTs function is to start by thinking
    about words as a set of coordinates, called *word vectors*. Similar to latitude
    and longitude, imagine that each word has an elaborate set of coordinates determining
    where it is located in the universe of words. Unlike the confines of the three
    dimensions that we experience in the physical world, each word in the universe
    of words has a very large number of dimensions (300+). Moreover, each word can
    be represented multiple times in the universe based on what it represents. Good
    examples of this are *homonyms*, words that are spelled the same but have different
    meanings, like the word *hide*, which can mean an animal skin pelt and can also
    mean to position something out of sight. It’s easy to imagine that there are two
    separate coordinates for these two concepts, just as there are (at least) two
    definitions of *hide* in a dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: 'LLMs are trained on copious amounts of text, called *training data**,* which
    they go through to systematically assign coordinates to each word in the universe.
    Those coordinates have a natural proximity to other words that are closely related,
    and you can further imagine that those coordinates can shift slightly with each
    additional new passage of text received. Eventually, from a mathematical angle,
    there are diminishing returns on this—similar to limits in calculus: as you approach
    infinity, the coordinate of a word eventually settles at a final location within
    the word universe.'
  prefs: []
  type: TYPE_NORMAL
- en: Alongside the coordinates of words is the GPT, or transformer, process of the
    model. I like to explain this process in terms of *layers*. These layers (for
    example, GPT-3 from OpenAI has 96 layers) go through the text input called a *prompt*
    it receives, categorizes the words within the prompt, and eventually aims at comprehending
    it. All of this is somewhat opaque, because humans haven’t dictated to the models
    at which layer different actions should be taken. From what has been observed,
    it appears that most models start by understanding the sentence syntax and role
    (noun/verb/adjective/pronoun) each word takes on. After those initial layers are
    done, more contextual layers process the prompt. I try to think of this as what
    humans innately and effortlessly do. When you start reading a book, you get a
    grounding in the words, and eventually, once you’ve read enough, your brain starts
    imagining the whole scene. [Figure 1-2](#ch01_figure_2_1732595607196141) demonstrates
    how an LLM may process a simple sentence through the transformer layers.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/lait_0102.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-2\. An example of how an LLM processes a sentence
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'After the prompt is processed comes the heart of the model’s generation: a
    prediction of what should come next. Again, this is not unlike what humans might
    also innately do on their own. If someone asks you what your favorite ice-cream
    flavor is, at the very least you are limited by the list of flavors you are aware
    of (possible predictions). In addition to that list, you rely on your own experiences
    with each of these flavors, and that eventually leads you to a single answer.
    Maybe it’s hard to land on one flavor, or you might be mentally scoring each flavor
    to get to a result. Maybe vanilla is your favorite “safe” flavor because it’s
    hard to get vanilla wrong, but you experience more pleasure and delight when eating
    mint chocolate chip. Maybe Ben and Jerry’s Cherry Garcia is your guilty pleasure,
    but not every ice-cream parlor has that on the menu. It is possible to answer
    the question differently depending entirely on the question’s *context*: who is
    asking, your recent ice-cream experiences, where you are, what you are craving.
    The models resolve this by relying on interpreting the context of the prompt and
    what they have learned from the training data. And it’s important to say, the
    model’s training data is far beyond the scope of what any one human knows, so
    it quite often has a very broad understanding of the possible answers.'
  prefs: []
  type: TYPE_NORMAL
- en: Remember, the whole act of processing the syntax and sentence structure of the
    prompt through comprehension and context is completely dependent on the information
    the model has on hand. The predictions it is able to generate are from the information
    it’s been given, which has been presented in sentences written by humans. So in
    particular, when we apply LLMs to a narrow field like coding or analytics, the
    model is relying entirely on what humans have already done. This isn’t to say
    that there aren’t original outputs (dare I say thoughts) or creativity in the
    process. In fact, one of the reasons I like generative AI for creating art is
    that it is not bounded by practicality. DALL-E may generate beautiful images that
    include an extra hand or misspelled word, because the prediction model has resolved
    to output the “best result.” A human artist would never paint an extra limb unless
    it was highly intentional, even if it better conveyed the idea behind the overall
    piece of art.
  prefs: []
  type: TYPE_NORMAL
- en: Given how LLMs function, we must treat their prediction method as a double-edged
    sword. It can be contaminated by human bias innate in the text, limited by the
    information it has been given, and may predict an output that is nonsensical or
    factually inaccurate. It may also provide answers or results that are uniquely
    different from what a human (or meticulously crafted algorithm) completing the
    same task may produce.
  prefs: []
  type: TYPE_NORMAL
- en: Risks and Considerations with AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are three big areas of risk and consideration I want to discuss:'
  prefs: []
  type: TYPE_NORMAL
- en: Model bias
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model hallucination
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Worker displacement
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s important to discuss these because they will inevitably come up on your
    organization’s journey to include generative AI tools in your analytics practice.
    Knowing what these issues are up front arms you with the knowledge your organization
    needs to make responsible and informed decisions about these tools.
  prefs: []
  type: TYPE_NORMAL
- en: Model Bias
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You’ve already learned that a model can be biased based on the information
    it has been trained on or has access to. But a model can also be biased based
    on how the algorithm was designed. A relatively easy example to understand is
    an algorithm that has been tuned to over-rely on information that shows up frequently
    or more recently. When that is applied to the question *Who is the most popular
    singer?*, the result might be *Taylor Swift* based on the success of her recent
    *Eras* tour and how often her music is requested and served up. But looking at
    the question over a longer span of time could surface a different answer: *Frank
    Sinatra*, who released an astounding 59 studio albums over his 50+ year career.
    You can imagine how that question gets murkier when you’re applying it directly
    to data or statistical information. The question *What has caused the decline
    in sales?* (after looking at a chart of trending sales values) could yield different
    answers based on whether the model considers only the data points observed in
    the chart or has access to the entire history of sales.'
  prefs: []
  type: TYPE_NORMAL
- en: User interaction is another tricky part which will naturally influence what
    the model produces. If the model knows that you are the manager of the electronics
    department or if you’ve asked many questions that tilt toward electronics, it
    will likely produce an output more directly related to electronics. This could
    produce an answer that is accurate, but perhaps not the largest or most direct
    root cause of the example question *What has caused the decline in sales?* I often
    see this unfold in my own interactions with ChatGPT, where I’ll ask for something
    in a list format, and from then on it has trouble breaking out of a pattern of
    listing items, even if my follow-up requests aren’t best resolved with lists.
    ChatGPT also tends to use similar language or structure to what I am providing,
    which, again, seems logical (we humans often tend to adopt the same words and
    style of those around us) but works against getting an unbiased response.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, there are social prejudices, stereotypes, and representation biases
    to contend with. These can appear by a model parroting back the most popular prejudices
    that have woven their way into the body of human knowledge. A fairly benign example
    is the word *nurse*. When you read that word, your mental image of a nurse is
    likely a woman. But you could extrapolate that act out to something more analytically
    oriented. For example, you seek help in creating a formula to predict how sales
    will perform, and the model defaults to recommending a linear regression because
    of its popularity in analytics. In a nonharmful way, the model may simply be providing
    the most common way to address your data. However, the model’s response could
    also be negating a more sound and reasoned method that would be more appropriate
    for addressing your data, leaving you with a method that may not be the right
    fit for your situation.
  prefs: []
  type: TYPE_NORMAL
- en: Model Hallucination
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Model hallucination* is a model’s return of a result that is not factually
    accurate or not grounded in reality. The example of the extra limb added to a
    generated image of a human figure mentioned earlier comes to mind, or fake legal
    cases used as supporting evidence in a new defense, or the production of seemingly
    valid numerical facts that are totally made up. All these possibilities can be
    generated by models, and they are especially dangerous when the task at hand is
    to use underlying supporting data as evidence to draw a conclusion. This is true
    particularly in data analytics, where there isn’t one defining fact or figure
    that can accurately capture the nuance and complexity of reality.'
  prefs: []
  type: TYPE_NORMAL
- en: You can see model hallucination play out when you ask AI to explain how it arrived
    at an answer. Since the whole model is opaque technology that provides predictions,
    the sound reasoning that you may be familiar with receiving from a human is typically
    not available. You can also see model hallucinations and limitations when it outputs
    what you know to be a wrong answer and you try to coax the AI into arriving at
    the right answer. [Figure 1-3](#ch01_figure_3_1732595607196167) shows a conversation
    I recently had with ChatGPT about the popular TV show *Survivor* and the phrase
    its host uses at challenges. In this exchange, the model initially provides a
    factually incorrect answer, including the word “guys” at the end of the phrase.
    Only after redirecting the model to consider more information, like that it was
    updated in a recent season, does it return the factually accurate answer. This
    isn’t hard to imagine, since there were 40 seasons of Survivor where “guys” was
    part of the phrasing, likely influencing the model more heavily to include the
    word “guys” and ignoring more recent history.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/lait_0103.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-3\. A discussion with ChatGPT about Jeff Probst
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Since the hallucination phenomenon tends to be more prominent in ambiguous situations—when
    the question itself may be unclear, the training data is insufficient, or extrapolation
    is required—it’s crucial to remain skeptical. These scenarios are common in the
    world of analytics, where understanding the reasoning behind insights is essential.
    Historically, human experience and intuition have been key to overcoming these
    challenges—an ability AI lacks, making it harder to fully trust its conclusions
    without deeper scrutiny.
  prefs: []
  type: TYPE_NORMAL
- en: Worker Displacement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: AI holds the promise, danger, and fear of displacing humans who are doing the
    work. In data analytics, there is a very real sense that if an end user can interact
    directly with AI to get the analytics and insights they need, the utility of the
    analytics professional is displaced. It can be frightening to consider what your
    actual job is if the AI can—with a few simple text commands—do tasks like building
    charts, curating data sets, or constructing complex queries that have been your
    full-time job. One of AI’s major marketing pitches is that AI will improve efficiency,
    but *improved efficiency* almost always means that someone will be made redundant
    in the process.
  prefs: []
  type: TYPE_NORMAL
- en: Although the prospect of AI taking away jobs may seem scary and inevitable,
    this is an area where data professionals must be loud advocates and have confidence
    in the body of work they have produced. The charge of data analytics hasn’t changed.
    The analyst’s responsibility and purpose have always been to ensure that the analytics
    being produced can be trusted and is useful. If anything, that purpose becomes
    much more necessary when computers start doing the work unsupervised.
  prefs: []
  type: TYPE_NORMAL
- en: The tasks of data analytics can and will change with this shift. But remember
    that new tasks will usher in new jobs and responsibilities, much like the story
    I shared with you in the Preface of how improvements to Tableau Desktop’s connectivity
    to multiple databases changed my requests from standalone data sets to requests
    for direct access to databases. It is still the responsibility of the data professional
    to manage the analytics, manage the access, manage the information produced, and
    manage the data products that are available to audiences. And in an applied situation,
    such as when Tableau Agent starts producing charts automatically, the analyst
    must still ensure that the chart constructed is accurate. The learned human skills
    and knowledge to make that discernment don’t disappear over time; they become
    even more mission critical.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, a reverse force is working in humans’ favor. One of the most often-heard
    soundbites in data analytics is how many people are *underserved* with data and
    analytics. A disparity exists between the massive amounts of data being collected
    and the availability and comprehension of said data to workers. So if anything,
    it would be sound to reason that the audiences for data analytics are bound to
    grow as tools for easier access become available to them. And if you’re a true
    zealot like me, obsessed with democratizing availability of data for decision
    making, it is an exciting time to be the sherpa of this practice to a broader
    group of people.
  prefs: []
  type: TYPE_NORMAL
- en: Trusting AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This discussion of the risks associated with LLMs and generative AI leads naturally
    to a discussion of how Tableau and Salesforce handle trust and risk mitigation.
    The primary arbiter of trust with these technologies is called the *Einstein Trust
    Layer*. You can consider this layer as an intermediary between your enterprise
    data and the LLM models (at the time of writing, Tableau uses OpenAI’s GPT-3.5
    Turbo) that generate summaries and respond to your prompts/queries. [Figure 1-4](#ch01_figure_4_1732595607196190)
    shows the relationships among Tableau Cloud, the Einstein Trust Layer, and LLM
    models.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/lait_0104.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-4\. The relationships among Tableau Cloud, Einstein Trust Layer, and
    LLMs
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The key components of the Einstein Trust Layer include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Secure data retrieval
  prefs: []
  type: TYPE_NORMAL
- en: Access controls and permissions are built into the Tableau platform. These controls
    are managed by administrators and creators and dictate who has access to data
    sources, dashboards, and Pulse metrics. During the process of interacting with
    AI, these controls are checked and verified prior to generating a response or
    serving up an insight.
  prefs: []
  type: TYPE_NORMAL
- en: Dynamic grounding
  prefs: []
  type: TYPE_NORMAL
- en: The LLMs are enriched with context related to your business. Additionally, when
    Pulse metrics are served up, templates are used as guidelines for the prompt response.
    This process includes very clear instructions to the LLM model on not guessing,
    using neutral language, and handling the numerical values it receives. It also
    gives clear instructions on the format of the response, like the inclusion of
    time period comparisons.
  prefs: []
  type: TYPE_NORMAL
- en: Data masking
  prefs: []
  type: TYPE_NORMAL
- en: To eliminate passing of protected information, like *personally identifiable
    information* (PII), sensitive values or words (such as a customer’s name) are
    *tokenized*. In the case of a customer’s name, the name isn’t sent to the model,
    but instead a substitute token or string of text is used. Upon serving up the
    result, the token is then translated back to the PII it represented.
  prefs: []
  type: TYPE_NORMAL
- en: Toxicity detection
  prefs: []
  type: TYPE_NORMAL
- en: This is the process of scoring prompt results or generated summaries for harmful
    information, which includes language that exhibits hate, violence, identity, or
    sexual content. Each response is scored, and if it is overly toxic, it will not
    be served back to the end user.
  prefs: []
  type: TYPE_NORMAL
- en: Auditing
  prefs: []
  type: TYPE_NORMAL
- en: An audit trail is created and stored in Salesforce’s Data Cloud associated with
    the prompt or information processed by the LLM. This includes the user who initiated
    the prompt, the body of the prompt (both masked and unmasked), a categorization
    of whether PII was found in the prompt, the toxicity score, and any user feedback
    associated with the output they receive.
  prefs: []
  type: TYPE_NORMAL
- en: Zero retention
  prefs: []
  type: TYPE_NORMAL
- en: After the prompt is resolved, the prompt itself is purged from the system. This
    ensures that the LLM doesn’t retain the prompt as future information it has “learned”
    to influence the next response or the overall model.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Beyond the Einstein Trust Layer, all data is encrypted both at rest and in transit.
    Salesforce uses OpenAI’s GPT models and has agreements in place that dictate OpenAI
    will not store or retain any information or prompts that are fed into the models.
    And if you’re deeply curious, all these services are hosted on Amazon Web Services
    (AWS), which exists globally across many availability regions. For a deeper dive
    or explanation, watch [this Salesforce presentation](https://oreil.ly/zExox) on
    the topic.
  prefs: []
  type: TYPE_NORMAL
- en: Competitors and AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As this chapter comes to a close, I want to touch on how competitors to Tableau
    are imagining and implementing AI into their business intelligence (BI) platforms.
    While many options certainly are available for comparison, I’ve chosen to focus
    on Microsoft Power BI (PBI) and Google Looker.
  prefs: []
  type: TYPE_NORMAL
- en: AI in Power BI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Microsoft Power BI has three distinct types of AI features:'
  prefs: []
  type: TYPE_NORMAL
- en: Advanced analytics assisted by AI
  prefs: []
  type: TYPE_NORMAL
- en: This feature includes baked-in advanced analysis types available to those working
    in PBI without the need to code. Of note is anomaly detection, which scans data
    presented in a visualization or data set and provides statistical results aimed
    at finding anything out of the ordinary. Two advanced data exploration options,
    take the form of interactive charts. One is called *key influencers*, an AI-driven
    visual aimed at finding primary drivers, and the other is a decomposition tree.
    The *decomposition tree* breaks a metric into the (likely) hierarchical dimensions
    and categories that exist within a data set. Sentiment analysis and forecasting
    are also available as no-code solutions.
  prefs: []
  type: TYPE_NORMAL
- en: AI assistance for analytics creation
  prefs: []
  type: TYPE_NORMAL
- en: Very similar to Tableau Agent, this is an interactive AI chatbot that can help
    developers create Data Analysis Expressions (DAX) code, a formula expression language.
    There are also areas throughout Microsoft Office products, like Teams and SharePoint,
    which can take suggested starting visualizations or analytical questions and automatically
    build them in PBI.
  prefs: []
  type: TYPE_NORMAL
- en: Natural language query (NLQ)
  prefs: []
  type: TYPE_NORMAL
- en: This is nearly identical to the concept of Ask Data or interacting with Tableau
    Pulse. Here users can formulate questions that are turned into queries and return
    visualizations and results. The distinction to remember is that the input is coming
    from a nontechnical business user.
  prefs: []
  type: TYPE_NORMAL
- en: AI in Looker
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Google’s listed and upcoming AI capabilities nearly mirror what I’ve already
    described for Tableau and Power BI. Of note, they are focusing on the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Duet AI assistant
  prefs: []
  type: TYPE_NORMAL
- en: An AI assistant designed to help analytics creators make visualizations and
    access data. Notably, this includes methods to translate natural language requests
    into its own proprietary query language, LookML.
  prefs: []
  type: TYPE_NORMAL
- en: AI-powered visualizations
  prefs: []
  type: TYPE_NORMAL
- en: Again, this is technology designed for a business user to automatically create
    visualizations based on information and data they have access to.
  prefs: []
  type: TYPE_NORMAL
- en: Summarized insights
  prefs: []
  type: TYPE_NORMAL
- en: While there aren’t many specifics on how or where this will be implemented,
    this is fundamentally similar to the insight summaries served up in Tableau Pulse.
  prefs: []
  type: TYPE_NORMAL
- en: Of note in discussing these competitors are the AI models that are the engines.
    Microsoft has a large stake in OpenAI and utilizes that company’s models or variations
    of its models. Google, on the other hand, leans on its own proprietary LLMs—namely,
    Gemini (formerly Bard).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, you’ve learned about AI in the analytics space. Key applications
    of AI in analytics include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: More sophisticated analysis methods, like predictive multivariate models and
    sentiment analysis (scoring of text as positive/negative/neutral)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Natural language processing and querying (NLP and NLQ), which allow users to
    ask questions in normal (human) language and receive analytical results
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative AI that summarizes information and surfaces interesting insights
    to end users
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AI assistance that makes building analytics easier
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To help you understand the latest AI tools in this book, the chapter unpacked
    how LLMs function:'
  prefs: []
  type: TYPE_NORMAL
- en: They consume large amounts of text and categorize words across a copious number
    of dimensions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prompts and text inputs are processed in layers called *transformers*. These
    models tend to first resolve sentence structure and ultimately reach comprehension
    and context of the input.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Humans control what training data is fed into the models as well as guidelines
    for processing that information. However, much of what occurs within the LLM is
    unknown and left to the model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'It is important to remember that LLMs and generative AI are essentially very
    sophisticated prediction engines. They rely heavily on the training data they
    receive. The output is influenced in how the LLM was constructed and whatever
    instructions it was given. Additionally, there are some inherent risks to be aware
    of when working with generative AI:'
  prefs: []
  type: TYPE_NORMAL
- en: Model bias
  prefs: []
  type: TYPE_NORMAL
- en: An LLM can have bias built in from the training data it receives. The model
    relies on information that has already been recorded by humans. In particular,
    there can be biases around societal issues (like diversity), and responses can
    be heavily influenced by user input.
  prefs: []
  type: TYPE_NORMAL
- en: Model hallucination
  prefs: []
  type: TYPE_NORMAL
- en: An LLM could respond with a factually made up or erroneous result. This typically
    occurs in ambiguous situations or where extrapolation is involved—both of which
    occur frequently in analytics.
  prefs: []
  type: TYPE_NORMAL
- en: Worker displacement
  prefs: []
  type: TYPE_NORMAL
- en: Although it can cause worry to consider how analytics roles may change, the
    bedrock of analytical skills you hold are necessary to ensure that the AI-derived
    results are grounded in sound analytical reasoning.
  prefs: []
  type: TYPE_NORMAL
- en: 'Tableau and Salesforce aim at creating trust while using AI-powered tools via
    the Einstein Trust Layer. This layer acts as a go-between for enterprise data
    and the LLM engines processing prompts. The six facets of this trust layer are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Secure data retrieval
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dynamic grounding
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data masking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Toxicity detection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Auditing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zero retention
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'And finally, two major competitors of Tableau, Microsoft Power BI and Google
    Looker, show common themes in the utility of AI in the analytics space, namely:
    AI assistance in analytics creation, advanced mathematical analyses, summarized
    insights, and natural language query.'
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 2](ch02.html#ch02_getting_started_with_tableau_pulse_1732595607647464),
    I’ll show you how to get started with Tableau Pulse. I’ll break down how to activate
    it in your Tableau environment, how to build your first metric, and more. By the
    end of the chapter, you’ll have the confidence and knowledge to start deploying
    your own metrics for business users to start following. And with the history of
    Tableau and knowledge of LLMs you received here, you will be able to accurately
    convey AI’s role and the risks when using it in Tableau.
  prefs: []
  type: TYPE_NORMAL
