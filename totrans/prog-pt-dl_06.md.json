["```py\ngit clone https://github.com/karoldvl/ESC-50\n```", "```py\ncurl https://github.com/karoldvl/ESC-50/archive/master.zip\n```", "```py\n1-100032-A-0.wav\n```", "```py\nimport IPython.display as display\ndisplay.Audio('ESC-50/audio/1-100032-A-0.wav')\n```", "```py\nimport glob\nfrom collections import Counter\n\nesc50_list = [f.split(\"-\")[-1].replace(\".wav\",\"\")\n        for f in\n        glob.glob(\"ESC-50/audio/*.wav\")]\nCounter(esc50_list)\n```", "```py\nCounter({'15': 40,\n     '22': 40,\n     '36': 40,\n     '44': 40,\n     '23': 40,\n     '31': 40,\n     '9': 40,\n     '13': 40,\n     '4': 40,\n     '3': 40,\n     '27': 40,\n     \u2026})\n```", "```py\nyum install sox\n```", "```py\napt intall sox\n```", "```py\nconda install -c derickl torchaudio\npip install torchaudio\n```", "```py\nclass ESC50(Dataset):\n\n    def __init__(self,path):\n        # Get directory listing from path\n        files = Path(path).glob('*.wav')\n        # Iterate through the listing and create a list of tuples (filename, label)\n        self.items = [(f,int(f.name.split(\"-\")[-1]\n                    .replace(\".wav\",\"\"))) for f in files]\n        self.length = len(self.items)\n\n    def __getitem__(self, index):\n        filename, label = self.items[index]\n        audio_tensor, sample_rate = torchaudio.load(filename)\n        return audio_tensor, label\n\n    def __len__(self):\n        return self.length\n```", "```py\ntest_esc50 = ESC50(PATH_TO_ESC50)\ntensor, label = list(test_esc50)[0]\n\ntensor\ntensor([-0.0128, -0.0131, -0.0143,  ...,  0.0000,  0.0000,  0.0000])\n\ntensor.shape\ntorch.Size([220500])\n\nlabel\n'15'\n```", "```py\nexample_loader = torch.utils.data.DataLoader(test_esc50, batch_size = 64,\nshuffle = True)\n```", "```py\nmv 1* ../train\nmv 2* ../train\nmv 3* ../train\nmv 4* ../valid\nmv 5* ../test\n```", "```py\nfrom pathlib import Path\n\nbs=64\nPATH_TO_ESC50 = Path.cwd() / 'esc50'\npath =  'test.md'\ntest\n\ntrain_esc50 = ESC50(PATH_TO_ESC50 / \"train\")\nvalid_esc50 = ESC50(PATH_TO_ESC50 / \"valid\")\ntest_esc50  = ESC50(PATH_TO_ESC50 / \"test\")\n\ntrain_loader = torch.utils.data.DataLoader(train_esc50, batch_size = bs,\n                shuffle = True)\nvalid_loader = torch.utils.data.DataLoader(valid_esc50, batch_size = bs,\n                shuffle = True)\ntest_loader  = torch.utils.data.DataLoader(test_esc50, batch_size = bs,\n                shuffle = True)\n```", "```py\nclass AudioNet(nn.Module):\n    def __init__(self):\n        super(AudioNet, self).__init__()\n        self.conv1 = nn.Conv1d(1, 128, 80, 4)\n        self.bn1 = nn.BatchNorm1d(128)\n        self.pool1 = nn.MaxPool1d(4)\n        self.conv2 = nn.Conv1d(128, 128, 3)\n        self.bn2 = nn.BatchNorm1d(128)\n        self.pool2 = nn.MaxPool1d(4)\n        self.conv3 = nn.Conv1d(128, 256, 3)\n        self.bn3 = nn.BatchNorm1d(256)\n        self.pool3 = nn.MaxPool1d(4)\n        self.conv4 = nn.Conv1d(256, 512, 3)\n        self.bn4 = nn.BatchNorm1d(512)\n        self.pool4 = nn.MaxPool1d(4)\n        self.avgPool = nn.AvgPool1d(30)\n        self.fc1 = nn.Linear(512, 10)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = F.relu(self.bn1(x))\n        x = self.pool1(x)\n        x = self.conv2(x)\n        x = F.relu(self.bn2(x))\n        x = self.pool2(x)\n        x = self.conv3(x)\n        x = F.relu(self.bn3(x))\n        x = self.pool3(x)\n        x = self.conv4(x)\n        x = F.relu(self.bn4(x))\n        x = self.pool4(x)\n        x = self.avgPool(x)\n        x = x.permute(0, 2, 1)\n        x = self.fc1(x)\n        return F.log_softmax(x, dim = 2)\n```", "```py\naudio_net = AudioNet()\naudio_net.to(device)\n```", "```py\naudio_net.save(\"audionet.pth\")\nimport torch.optim as optim\noptimizer = optim.Adam(audionet.parameters(), lr=0.001)\nlogs,losses = find_lr(audio_net, nn.CrossEntropyLoss(), optimizer)\nplt.plot(logs,losses)\n```", "```py\nlr = 1e-5\nmodel.load(\"audionet.pth\")\nimport torch.optim as optim\noptimizer = optim.Adam(audionet.parameters(), lr=lr)\n```", "```py\ntrain(audio_net, optimizer, torch.nn.CrossEntropyLoss(),\ntrain_data_loader, valid_data_loader, epochs=20)\n```", "```py\nsample_data, sr = librosa.load(\"ESC-50/train/1-100032-A-0.wav\", sr=None)\nspectrogram = librosa.feature.melspectrogram(sample_data, sr=sr)\n```", "```py\nlibrosa.display.specshow(spectrogram, sr=sr, x_axis='time', y_axis='mel')\n```", "```py\nlog_spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n```", "```py\nclass ESC50Spectrogram(Dataset):\n\ndef __init__(self,path):\n    files = Path(path).glob('*.wav')\n    self.items = [(f,int(f.name.split(\"-\")[-1].replace(\".wav\",\"\")))\n                   for f in files]\n    self.length = len(self.items)\n    self.transforms = torchvision.transforms.Compose(\n                 [torchvision.transforms.ToTensor()])\n\ndef __getitem__(self, index):\n    filename, label = self.items[index]\n    audio_tensor, sample_rate = librosa.load(filename, sr=None)\n    spectrogram = librosa.feature.melspectrogram(audio_tensor, sr=sample_rate)\n    log_spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n    librosa.display.specshow(log_spectrogram, sr=sample_rate,\n                             x_axis='time', y_axis='mel')\n    plt.gcf().canvas.draw()\n    audio_data = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n    audio_data = audio_data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n    return (self.transforms(audio_data), label)\n\ndef __len__(self):\n    return self.length\n```", "```py\noldESC50 = ESC50(\"ESC-50/train/\")\nstart_time = time.process_time()\noldESC50.__getitem__(33)\nend_time = time.process_time()\nold_time = end_time - start_time\n\nnewESC50 = ESC50Spectrogram(\"ESC-50/train/\")\nstart_time = time.process_time()\nnewESC50.__getitem__(33)\nend_time = time.process_time()\nnew_time = end_time - start_time\n\nold_time = 0.004786839000075815\nnew_time = 0.39544327499993415\n```", "```py\nimport functools\n\nclass ESC50Spectrogram(Dataset):\n #skipping init code\n\n    @functools.lru_cache(maxsize=<size of dataset>)\n    def __getitem__(self, index):\n```", "```py\ndef precompute_spectrograms(path, dpi=50):\n    files = Path(path).glob('*.wav')\n    for filename in files:\n        audio_tensor, sample_rate = librosa.load(filename, sr=None)\n        spectrogram = librosa.feature.melspectrogram(audio_tensor, sr=sr)\n        log_spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n        librosa.display.specshow(log_spectrogram, sr=sr, x_axis='time',\n                                 y_axis='mel')\n        plt.gcf().savefig(\"{}{}_{}.png\".format(filename.parent,dpi,\n                          filename.name),dpi=dpi)\n```", "```py\nfrom PIL import Image\n\n    class PrecomputedESC50(Dataset):\n        def __init__(self,path,dpi=50, transforms=None):\n            files = Path(path).glob('{}*.wav.png'.format(dpi))\n            self.items = [(f,int(f.name.split(\"-\")[-1]\n            .replace(\".wav.png\",\"\"))) for f in files]\n            self.length = len(self.items)\n            if transforms=None:\n                self.transforms =\n                torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n            else:\n                self.transforms = transforms\n\n        def __getitem__(self, index):\n            filename, label = self.items[index]\n            img = Image.open(filename)\n            return (self.transforms(img), label)\n\n        def __len__(self):\n            return self.length\n```", "```py\nstart_time = time.process_time()\nb.__getitem__(33)\nend_time = time.process_time()\nend_time - start_time\n>> 0.0031465259999094997\n```", "```py\nfrom torchvision import models\nspec_resnet = models.ResNet50(pretrained=True)\n\nfor param in spec_resnet.parameters():\n    param.requires_grad = False\n\nspec_resnet.fc = nn.Sequential(nn.Linear(spec_resnet.fc.in_features,500),\nnn.ReLU(),\nnn.Dropout(), nn.Linear(500,50))\n```", "```py\nesc50pre_train = PreparedESC50(PATH, transforms=torchvision.transforms\n.Compose([torchvision.transforms.ToTensor(),\ntorchvision.transforms.Normalize\n(mean=[0.485, 0.456, 0.406],\nstd=[0.229, 0.224, 0.225])]))\n\nesc50pre_valid = PreparedESC50(PATH, transforms=torchvision.transforms\n.Compose([torchvision.transforms.ToTensor(),\ntorchvision.transforms.Normalize\n(mean=[0.485, 0.456, 0.406],\nstd=[0.229, 0.224, 0.225])]))\n\nesc50_train_loader = (esc50pre_train, bs, shuffle=True)\nesc50_valid_loader = (esc50pre_valid, bs, shuffle=True)\n```", "```py\nspec_resnet.save(\"spec_resnet.pth\")\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(spec_resnet.parameters(), lr=lr)\nlogs,losses = find_lr(spec_resnet, loss_fn, optimizer)\nplt.plot(logs, losses)\n```", "```py\noptimizer = optim.Adam(spec_resnet.parameters(), lr=[1e-2,1e-4,1e-8])\n\ntrain(spec_resnet, optimizer, nn.CrossEntropyLoss(),\nesc50_train_loader, esc50_val_loader,epochs=5,device=\"cuda\")\n```", "```py\nfor param in spec_resnet.parameters():\n    param.requires_grad = True\n\noptimizer = optim.Adam(spec_resnet.parameters(), lr=[1e-2,1e-4,1e-8])\n\ntrain(spec_resnet, optimizer, nn.CrossEntropyLoss(),\nesc50_train_loader, esc50_val_loader,epochs=20,device=\"cuda\")\n\n> Epoch 19, accuracy = 0.80\n```", "```py\naudio_tensor, rate = torchaudio.load(\"test.wav\")\naudio_tensor.shape\ntrimmed_tensor = torchaudio.transforms.PadTrim(max_len=1000)(audio_orig)\n```", "```py\nclass ESC50WithPitchChange(Dataset):\n\n    def __init__(self,path):\n        # Get directory listing from path\n        files = Path(path).glob('*.wav')\n        # Iterate through the listing and create a list of tuples (filename, label)\n        self.items = [(f,f.name.split(\"-\")[-1].replace(\".wav\",\"\")) for f in files]\n        self.length = len(self.items)\n        self.E = torchaudio.sox_effects.SoxEffectsChain()\n        self.E.append_effect_to_chain(\"pitch\", [0.5])\n\n    def __getitem__(self, index):\n        filename, label = self.items[index]\n        self.E.set_input_file(filename)\n        audio_tensor, sample_rate = self.E.sox_build_flow_effects()\n        return audio_tensor, label\n\n    def __len__(self):\n        return self.length\n```", "```py\nclass FrequencyMask(object):\n    \"\"\"\n Example:\n >>> transforms.Compose([\n >>>     transforms.ToTensor(),\n >>>     FrequencyMask(max_width=10, use_mean=False),\n >>> ])\n\n \"\"\"\n\n    def __init__(self, max_width, use_mean=True):\n        self.max_width = max_width\n        self.use_mean = use_mean\n\n    def __call__(self, tensor):\n        \"\"\"\n Args:\n tensor (Tensor): Tensor image of\n size (C, H, W) where the frequency\n mask is to be applied.\n\n Returns:\n Tensor: Transformed image with Frequency Mask.\n \"\"\"\n        start = random.randrange(0, tensor.shape[2])\n        end = start + random.randrange(1, self.max_width)\n        if self.use_mean:\n            tensor[:, start:end, :] = tensor.mean()\n        else:\n            tensor[:, start:end, :] = 0\n        return tensor\n\n    def __repr__(self):\n        format_string = self.__class__.__name__ + \"(max_width=\"\n        format_string += str(self.max_width) + \")\"\n        format_string += 'use_mean=' + (str(self.use_mean) + ')')\n\n        return format_string\n```", "```py\ntensor[:, start:end, :] = tensor.mean()\n```", "```py\ntorchvision.transforms.Compose([FrequencyMask(max_width=10, use_mean=False),\ntorchvision.transforms.ToPILImage()])(torch.rand(3,250,200))\n```", "```py\nclass TimeMask(object):\n    \"\"\"\n Example:\n >>> transforms.Compose([\n >>>     transforms.ToTensor(),\n >>>     TimeMask(max_width=10, use_mean=False),\n >>> ])\n\n \"\"\"\n\n    def __init__(self, max_width, use_mean=True):\n        self.max_width = max_width\n        self.use_mean = use_mean\n\n    def __call__(self, tensor):\n        \"\"\"\n Args:\n tensor (Tensor): Tensor image of\n size (C, H, W) where the time mask\n is to be applied.\n\n Returns:\n Tensor: Transformed image with Time Mask.\n \"\"\"\n        start = random.randrange(0, tensor.shape[1])\n        end = start + random.randrange(0, self.max_width)\n        if self.use_mean:\n            tensor[:, :, start:end] = tensor.mean()\n        else:\n            tensor[:, :, start:end] = 0\n        return tensor\n\n    def __repr__(self):\n        format_string = self.__class__.__name__ + \"(max_width=\"\n        format_string += str(self.max_width) + \")\"\n        format_string += 'use_mean=' + (str(self.use_mean) + ')')\n        return format_string\n```", "```py\ntensor[:, :, start:end] = 0\n```", "```py\ntorchvision.transforms.Compose([TimeMask(max_width=10, use_mean=False),\ntorchvision.transforms.ToPILImage()])(torch.rand(3,250,200))\n```", "```py\nclass PrecomputedTransformESC50(Dataset):\n    def __init__(self,path,dpi=50):\n        files = Path(path).glob('{}*.wav.png'.format(dpi))\n        self.items = [(f,f.name.split(\"-\")[-1].replace(\".wav.png\",\"\"))\n                      for f in files]\n        self.length = len(self.items)\n        self.transforms = transforms.Compose([\n    transforms.ToTensor(),\n    RandomApply([FrequencyMask(self.max_freqmask_width)]p=0.5),\n    RandomApply([TimeMask(self.max_timemask_width)]p=0.5)\n])\n\n    def __getitem__(self, index):\n        filename, label = self.items[index]\n        img = Image.open(filename)\n        return (self.transforms(img), label)\n\n    def __len__(self):\n        return self.length\n```"]