- en: 2 Parsing payments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Working with generative AI to parse an ACH file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unit testing in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Agile concepts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter explains the fundamentals of files formatted by an Automated Clearing
    House (ACH). You will work on parsing an initial sample file to better understand
    some of the record layouts used, as well as the software development practice
    of unit testing. You will also expand your knowledge of generative AI and see
    how to apply it to a real-world problem.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Modernizing our legacy software
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have gone through PI planning and have been assigned our project,
    we will begin working on our first spike. In SAFe, spikes are a type of story,
    often referred to as an enabler story. A variety of enabler story categories may
    be used (e.g., exploration, architectural, infrastructure, and compliance). In
    our case, our story may be classified as an exploration type or a research spike.
    However, the details are not as important as our activities because the particulars
    may vary between Agile frameworks. Essentially, this story aims to provide the
    team with some experience working in Python and learning about the ACH file layout
    so that we can understand prospective solutions better.
  prefs: []
  type: TYPE_NORMAL
- en: 'The stories assigned to the team in this sprint can shed light on the business
    needs driving the modernization effort. The current ACH system runs on the mainframe
    system, and it is highly coupled with the existing architecture. This coupling
    prevents the system from being maintained easily. The business has been keeping
    metrics on various key performance indicators (KPIs):'
  prefs: []
  type: TYPE_NORMAL
- en: '*Release cadenc**e*—Shows how often the development teams release new features
    and updates'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Defect backlo**g*—Shows the number of defects identified during development
    and release'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Escaped defect**s*—Shows the number of defects identified after the software
    has been released'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Customer satisfactio**n*—Indicates how happy the customer is with our product/service'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These metrics have shown that there has been a steady increase in the time it
    takes to make regulatory enhancements and general bug fixes as the system’s code
    base has grown in both size and complexity.
  prefs: []
  type: TYPE_NORMAL
- en: Currently, we do not have any knowledge of ACH files, and understanding and
    navigating the COBOL code will take time; moreover, we may need to request access.
    The team will have to gain insight into the COBOL code so that they can better
    assist in converting functionality from one area to another. In the interim, the
    team is supposed to tackle the project from the ground up. The team also has first
    access to generative AI tools to help evaluate their use since the company is
    looking into using Gen AI to improve productivity. Our manager believes that the
    team is in a unique position to evaluate the tools to help us with this effort.
  prefs: []
  type: TYPE_NORMAL
- en: The company gave us access to both premium ChatGPT and GitHub Copilot membership.
    They have also asked that we test out the free version of ChatGPT because, if
    the free version is comparable to the premium one, they would much rather save
    some money. In addition, our manager has reminded us not to paste any proprietary
    or confidential information into ChatGPT because that would be a potential violation
    of the nondisclosure agreement (NDA) we have in place. This means we cannot paste
    the COBOL code and convert it to Python or ask ChatGPT to interpret existing code.
    Instead, we should focus on isolating, sanitizing, and generalizing code samples
    before plugging them into ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our plan is to do a little research on what exactly an ACH is and what type
    of format we’ll be working with. We are familiar with JSON as we have done a fair
    amount of web-based work before. Either way, we are excited to get moving on to
    this project: getting into some code and working on a project is why we wanted
    this job in the first place, so let’s begin!'
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Understanding the ACH
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The ACH network allows banks and credit unions to transfer money without establishing
    a separate relationship. Given that there are over 10,000 banks and credit unions
    in the United States, that is quite an undertaking! So, how does it work?
  prefs: []
  type: TYPE_NORMAL
- en: 'A common type of ACH transaction is known as Prearranged Payment and Deposit
    (PPD). It is often used for direct deposit of paychecks (and recurring bill payments,
    gym memberships, and social security payments, to name a few). Let us say our
    employer has an account at bank X. Every two weeks or twice a month, they need
    to pay us, but we use a different bank, bank Y. To get the money to you, a few
    days before payday, our employer or their payroll processor will create a file
    containing the information needed to execute the payment. It includes the amount
    of our take-home pay, our account number, and a *routing transit number.* A routing
    transit number is a unique number that identifies a bank—in this case, the bank
    of the end recipient of the transaction: bank Y. The payroll processor will transmit
    the file containing the employee wages info to bank X. Bank X accepts the file
    and combines it with other files they receive. Next, it sends one file to either
    the Federal Reserve or a private company called The Clearing House. These two
    entities are known as *ACH operators* *or* *clearing houses*. ACH operators accept
    files from thousands of banks, sort the transactions based on their routing transit
    numbers, and create new files for each bank receiving transactions. These files
    are then transmitted to the banks, which then receive and post the transactions.'
  prefs: []
  type: TYPE_NORMAL
- en: ACH files use a format defined by Nacha, the organization that sets standards
    for the ACH network. Figure 2.1 shows the ACH processing flow.
  prefs: []
  type: TYPE_NORMAL
- en: '![A diagram of a company  Description automatically generated](../Images/CH02_F01_Kardell.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1  ACH processing flow
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 2.3 Parsing an ACH file
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So, we have been assigned a story to parse an ACH file and store it in the database.
    The story has subtasks for parsing each of the record formats found in an ACH
    file, as well as storing the results in a database.
  prefs: []
  type: TYPE_NORMAL
- en: The ACH file standard was created in the 1970s and has undergone various updates
    and expansions since then. This is great because it means that plenty of information
    is available on the standard. We start by doing some research on ACH, finding
    that an ACH file is a fixed-width ASCII file with each line being 94 characters
    long. These lines are known as records, and each record consists of fields that
    are at fixed positions. A fixed-width file with records at fixed positions should
    mean parsing is a relatively straightforward task.
  prefs: []
  type: TYPE_NORMAL
- en: Digging a little bit further, we see that there are six types of ACH records
    that may be present in a file. It seems there are a few types of header records,
    and each has a trailer record known as a control record that wraps up the data.
    We also find an overview of the record types and file structure (see figure 2.2).
    Further details on the records and their corresponding fields (such as the position,
    whether it is required, etc.) are available at [https://achdevguide.nacha.org/ach-file-details](https://achdevguide.nacha.org/ach-file-details).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH02_F02_Kardell.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2  ACH file layout
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Figure 2.2 gives us an idea of the file structure; however, let’s also look
    at a sample file that we will be working with so we can get a better idea of what
    a file may look like. Figure 2.3 may look a bit daunting, but once we break down
    the records into their fields, it is relatively straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH02_F03_Kardell.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.3  Example ACH file
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Based on the structure and file sample, we know that we will have to parse
    the following record types:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Type* *1*—A file header record with a single record per file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Type* *5*—A batch header record with multiple batches per file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Type* *6*—Entry records, with multiple entries per batch'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Type 7*—Addenda records with zero or multiple records per entry record'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Type* *8*—A batch control record that encloses the entry and addenda records'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Type* *9*—A file trailer record that encloses all the batch records'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While we have not gotten access to the legacy COBOL code, a team member found
    a confluence (a wiki provided by Atlassian) site with the flow chart that provides
    some insight into the processing of an ACH file (figure 2.4).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH02_F04_Kardell.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.4  ACH processing flow
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Your first task is to check your favorite search engine to see what is available.
    You may find some existing packages (`pyNacha`, `py-nacha`, and `pynacha`). Those
    appear to be various projects exploring how to create and parse ACH files. Further
    digging also shows some of these projects came from `carta-ach`, which again came
    from `python-ach`. These projects have been forked many times, but most appear
    to have not been updated for some time. As they are not actively maintained, it
    may not be wise to base your project on them. However, they appear to have a permissive
    MIT license (more on licensing concerns later), so we could possibly fork a project
    to get started. We can also lean on some of our generative AI tools for some help
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.1 Asking ChatGPT to parse an ACH file
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can start by asking ChatGPT the question, “Can you write a Python program
    to parse an ACH file?”When we try this in ChatGPT 3.5, it gives us the basics
    of an `ACH` class that can parse a file, as shown in the next listing.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.1  ACH parser from ChatGPT 3.5
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Defines a class named ACHParser'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 The __init__ function is used as a constructor for our class.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Reads the entire file'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Determines the first character and stores it in record_code'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Performs processing based on the record_code; notice there is no record_code
    5 or 8.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The program does not look too bad; however, despite our current limited knowledge
    of ACH, we can see that it has some problems:'
  prefs: []
  type: TYPE_NORMAL
- en: Missing a record type code of `5`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Missing a record type code of `8`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `record_type` lables are incorrect, as `6` is listed as a `batch` instead
    of an `entry`, and `7` is listed as `entry` instead of `addenda`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We try switching over to the updated ChatGPT 4 and ask it the same question.
    We are presented with the code shown in the following listing. Again, keep in
    mind that the nondeterministic nature of LLMs may lead to different results.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.2  ACH parser from ChatGPT 4
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '#1 An empty array to store ACH records into'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Each record_type is stored as a dictionary; some of the fields were provided
    by ChatGPT.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 ChatGPT 4 did generate a record type 8 this time.'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 ACH records are added to our array.'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 The records are returned.'
  prefs: []
  type: TYPE_NORMAL
- en: '#6 The returned records are printed out using a for-each loop.'
  prefs: []
  type: TYPE_NORMAL
- en: This program seems to be a little more built out. We see the batch control record
    (record type 8) this time, and some of the lines have a sample parsing done as
    well. This seems to be a good start; however, we want to keep the program testable.
    If we separate the parsing logic into separate functions, we can pass both well-formatted
    records and invalid data to the function to test it. Let’s see if we can get ChatGPT
    to do that somewhat tedious process.
  prefs: []
  type: TYPE_NORMAL
- en: 'We simply ask ChatGPT:'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Prompt-Icon.png)** Can you update the above program so
    that the parsing of each record type is a separate function?'
  prefs: []
  type: TYPE_NORMAL
- en: The program is updated to break each of the record types into its own function.
    The relevant changes are shown in the following listing. Notice that we have been
    provided with parser functions (`parse_file_header`, `parse_batch_header`, etc.)
    and that these have been stubbed out by ChatGPT (meaning we will have to provide
    implementation details to parse the actual data).
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.3  Parsing with separate functions
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Defines needed parsing functions in a dictionary'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Retrieves the appropriate function based on the first character we stored
    in record_type'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Calls the parse function with the appropriate data'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Calls the parse function with the appropriate data'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 One of the sample stubs for the parser_functions'
  prefs: []
  type: TYPE_NORMAL
- en: In the tests/data folder, there is also a sample.ach file (as we saw in figure
    2.2) that we can plug into these sample programs to examine how they process the
    file and play around with the results. Now it would be a good time to take a break
    and run the sample ACH file through these programs to see how they work. This
    is helpful if we do not quite understand ACH file processing yet or if we are
    unfamiliar with some of the constructs used in the Python program.
  prefs: []
  type: TYPE_NORMAL
- en: It is a powerful tool to help us get started. Many developers have templates,
    shells, or skeleton programs they use to get started with particular tasks. Or
    they may choose a particular program to copy and paste. Of course, the problem
    with copying/pasting is that you may inevitably miss something and introduce a
    compile-time problem or bug that you then need to troubleshoot. The same thing
    can happen when using a template to start your program.
  prefs: []
  type: TYPE_NORMAL
- en: These templates or code produced from generative AI can be useful, especially
    if we are willing to look at the code and learn from it. Maybe we will learn a
    new way to do something or maybe we will find a new technique to apply. Still,
    maybe we find a bug in the produced code. The point is that it can be a helpful
    tool as long as we use it and do not take the output for granted; the code produced
    must be treated as our own code, meaning it should be tested and verified through
    our unit testing and quality assurance (QA) process.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.2 Parsing an ACH file with Copilot
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'After seeing what ChatGPT has to offer us, let’s use Copilot to see whether
    it can get us closer. We first enter the following into an empty Python script:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/Prompt-Icon.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'It does an okay job, but not quite what we wanted, so we try again with an
    updated prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/Prompt-Icon.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'As we are typing, the “for each NACHA record type and return a list of transactions”
    is automatically populated. We then enter an expanded comment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/Prompt-Icon.png)'
  prefs: []
  type: TYPE_IMG
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: This prompt gives us the following output, with the full listing available in
    copilot_ach_parse_with_functions.py.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.4  Copilot ACH parser
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Incorrectly calls a parse_ach_batch_header routine when this is the file
    header record'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 The batch header record is being parsed incorrectly as a batch control record.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 The batch control record is listed incorrectly as file control.'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Missing an elif statement for file control records (type 9)'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 A ValueError is raised when we do not have a valid ACH record type.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see that it created a class and functions to parse individual record
    types. However, we also see multiple problems:'
  prefs: []
  type: TYPE_NORMAL
- en: Record type 1 is calling a parse routine for `parse_ach_batch_header`, whereas
    it should be parsed as a file header.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Record type 5 is calling a parse routine for `parse_ach_batch_control`, whereas
    it should have been parsed as a batch header.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Record type 8 is calling a parse routine for `parse_ach_file_control`, whereas
    it should have been parsed as a batch control.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The file trailer record (record type 9) is missing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, while this code also gives us another viable template, it does not necessarily
    produce something right out of the box to use. One helpful thing that it does
    provide is code to raise a `ValueError` with `invalid` `ACH` `record` `type`,
    so we would certainly run into an error right away when we try to load a test
    ACH file as the missing type 9 should cause an error on any well-formatted ACH
    file.
  prefs: []
  type: TYPE_NORMAL
- en: '2.3.3 Generative AI: Trust but verify'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Certainly, both ChatGPT and Copilot are able to get us started with meaningful
    templates we can expand on later. However, they both have some problems generating
    the code, which highlights the importance of verification mentioned earlier. We
    must understand the produced code and not just take for granted that it is correct.
    This is especially important when we expect code to apply business rules and logic
    to the functions we want to generate. For instance, when using generative AI to
    assist in creating purely functional code—such as a button to submit a form or
    read a file—it will be immediately obvious if there is a syntax error or if it
    does not perform according to specifications, as it will not compile. However,
    if it is missing a record type or has some other problem, it could introduce bugs
    that are harder to find, especially if we don’t understand those business rules.
    We make this point multiple times only to drive home the importance of generative
    AI being a powerful tool but still only a tool. Think of the process of building
    a chair. We can build a chair with just a hand saw or we can have a shop full
    of the latest and greatest tools, but if we do not know how to use them, we will
    likely end up sitting on the floor.
  prefs: []
  type: TYPE_NORMAL
- en: So, how do we go about verifying the code that generative AI produces for us?
    By using extreme programming (XP) development practices such as test-driven development
    (TDD). We previously mentioned the need for reliable high-quality software in
    FinTech.
  prefs: []
  type: TYPE_NORMAL
- en: 'TDD boils down to the concept of writing tests before code by letting tests
    drive our development. One of the benefits is that we have highly testable code.
    We will use the TDD principles throughout this book and show various ways to automate
    our tests. Regardless of whether we decide to adopt a test-driven approach to
    our development practice, there are real benefits to thinking about how our code
    is tested. Questions such as the following are always considered when using a
    TDD approach:'
  prefs: []
  type: TYPE_NORMAL
- en: Is this code that needs to be tested, or will we need to regression-test this
    code?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do I test this code?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How will others understand this code?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The answers to these questions are usually found through unit tests, and when
    thinking about unit tests, we should be thinking about TDD.
  prefs: []
  type: TYPE_NORMAL
- en: We can also make use of our Integrated Development Environment (IDE) and any
    available plugins it may come with. These tools may include customizable formatting
    options and default highlighting of syntax problems. As soon as our development
    team grows beyond just one person, there are real benefits to enforcing some standards
    in our code.
  prefs: []
  type: TYPE_NORMAL
- en: Our company will likely provide us with the tools to use. These may help identify
    problems with generated code right away. Tools such as Snyk which can scan our
    code for vulnerabilities are discussed in chapter 3\. At the very least, we want
    to ensure that the code meets our company’s policies and standards.
  prefs: []
  type: TYPE_NORMAL
- en: Reduce cognitive load with formatting and linters
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Cognitive load can be interpreted as the amount of information we need to keep
    in our brains while coding. There are many ways to reduce cognitive load within
    your code. Providing consistency within the code helps reduce cognitive load.
    It also helps with scanning tools, onboarding, and avoiding errors.
  prefs: []
  type: TYPE_NORMAL
- en: Developers have enough to worry about even without the concerns regarding code
    formatting, comments, and similar. If we believe the number of spaces (or tabs)
    to indent a line would not get anyone riled up, we are in for a rude awakening.
    Seemingly trivial formatting decisions or coding practices may cause heated debates.
    Hopefully, many problems have been put to rest by the adoption of opinionated
    formatters, such as black when using Python and linters when using SonarLint.
  prefs: []
  type: TYPE_NORMAL
- en: We may find that legacy software in FinTech written in languages such as COBOL
    or RPG was constrained by line lengths of 80 or 132 characters and, in some flavors,
    required starting code in a specific column (specifically COBOL). Similar requirements
    are also present in RPG and other early languages. While modern languages have
    pretty much done away with those types of restrictions, developers quickly learned
    that maybe there was too much freedom. Today, many programming languages have
    various formatters that enforce some structure into our code, often forcing your
    code to adhere to a standard developed for the language. Whether it is Perl (perltidy),
    Go (gofmt), or JavaScript (Prettier), or Python (black), formatters are another
    tool we should investigate as soon as we start learning a new language.
  prefs: []
  type: TYPE_NORMAL
- en: Linters play a similar role by ensuring our code stays clean and does not fall
    into common language pitfalls such as identifying unused imports, unused variables,
    invalid comparisons, and problematic casting, to name a few. SonarLint is a popular
    linter available for many languages and IDEs. It also provides integration into
    SonarQube, a product that helps identify and manage problems. Other linters are
    also available, such as ESLint when working with JavaScript or TypeScript.
  prefs: []
  type: TYPE_NORMAL
- en: Both formatters and linters can be built into your IDE or are available through
    plugins within the IDE. So, it is not a big inconvenience to start using them.
    However, ensure that you are using something approved by the team and that it
    is configured correctly. These tools can also be helpful in making you a better
    programmer overall, as they often tell us why this is the best practice and how
    to avoid it. We often find ourselves reading why SonarLint has flagged something
    or looking up additional examples or further information on best practices because
    the linters flagged something.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4 Automated testing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Regardless of whether we are coding the initial script to parse the ACH file
    by hand or getting started with a generative AI tool, we want to ensure that we
    are using unit tests. We prefer a TDD approach and will often find that we favor
    it. However, we do not have to strictly subscribe to that approach to receive
    the benefits. We are looking for short development cycles, mixing testing and
    coding. We should have a pretty good idea at this point that parsing an ACH file
    properly is going to be somewhat complex task. However, reading a file and ensuring
    that we have all the lines is not an insurmountable task, and we should be able
    to achieve it easily enough. So, why not start with a unit test that ensures we
    received all the lines from the file?
  prefs: []
  type: TYPE_NORMAL
- en: A continuing theme is the need for high-quality software and verifying our results,
    especially in the context of generated code. This section explores the use of
    unit testing with `pytest` to help validate both generated code and the code we
    built ourselves. We also discuss the need for smaller and faster feedback cycles
    while coding, and we will try to apply that to our code here as well.
  prefs: []
  type: TYPE_NORMAL
- en: Even before we try to write tests for parsing individual fields from the record
    types, we may want to ask ourselves questions such as
  prefs: []
  type: TYPE_NORMAL
- en: Can I read a file?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How many records are in the file?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can I parse a record of type 1? How about a record of type 5?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We start small with the initial steps and then go deeper into the actual functionality
    of our code. In the following sections, we will start with a well-formatted sample
    file and work our way through it by creating tests. Each section will illustrate
    the creation of a small unit test to validate our well-formatted file.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4.1 Testing the number of records read
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We will test the number of records read from our ACH file before we start addressing
    any problems that we may have noticed in our generated code. This testing covers
    the first two bullet points we listed at the beginning of this section. Verifying
    the number of records may seem trivial, but it helps put us in the mindset of
    testing our code and helps verify that we are indeed accomplishing this critical
    task. Our unit test needs to verify the number of records from the file. We can
    get the record out by opening the file in most editors, or we can employ a command
    line to get the number of lines by using `wc` `-l` in Unix or a `Get-Content`
    and `Measure-Object` in PowerShell. If we are unsure how to get the number of
    lines from a file, we may want to ask generative AI if it has any ideas and maybe
    even learn a new trick or two!
  prefs: []
  type: TYPE_NORMAL
- en: Depending on how we got here, our test may be failing because of one of those
    missing record types or because of some other error such as an incorrect file
    path, permissions, or any number of other reasons. Now, as an exercise, it would
    be good to work on getting this first test up and running before we continue with
    the code. Otherwise, we can just continue by using the sample code provided on
    GitHub.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4.2 Parsing the records
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can find information about the ACH layout at [https://achdevguide.nacha.org/ach-file-overview](https://achdevguide.nacha.org/ach-file-overview).
    Let’s recall some of the main aspects of the file format:'
  prefs: []
  type: TYPE_NORMAL
- en: It is a fixed-width ASCII file.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Records are 94 characters in length.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each line is known as a record.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each record contains fields that are at fixed positions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Order of records and fields matters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This format makes processing and validating files more interesting. We do not
    have an XML Schema Definition that we can utilize. Nor do we have the freedom
    of formatting that XML and JSON provide.
  prefs: []
  type: TYPE_NORMAL
- en: Although it has constraints compared to other file formats, it was in use before
    the other formats were born. It would be an interesting challenge for us to ensure
    we process the file correctly and handle some of the tasks in daily ACH processing.
    We create a new Python project in our IDE and use the response from ChatGPT 4
    as our starting point.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.5  Starting point for our ACH parser
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: We created a basic folder structure for the project consisting of
  prefs: []
  type: TYPE_NORMAL
- en: '`ach_processor`—Where our Python module lives'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docs`—Where any necessary documentation lives'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tests`—Where our unit tests live'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`venv`—Our virtual environment (to keep our project and dependencies separated)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`README.md`—A markdown document to get into more details about the project
    and structure'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`requirements.txt`—A list of required Python dependencies that can be used
    by a CI/CD pipeline to build the project'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Listing 2.6  Project folder structure
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: After setting up the project, we run the `black` command to format the source
    code. With PyCharm, the IDE was smart enough to see the package installed and
    prompted us to set up Black from within the IDE since `black` was supported out
    of the box.
  prefs: []
  type: TYPE_NORMAL
- en: With that accomplished, we can begin working on parsing the ACH records. At
    this point, with our exploratory spike, we are only looking to simply parse the
    records. Input validation is an important aspect of processing any type of data
    as it is defensive coding.
  prefs: []
  type: TYPE_NORMAL
- en: Defensive coding
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Defensive coding is a proactive approach to dealing with unanticipated input,
    errors, and general misuse that occur when users get their hands on your software.
    For instance, if you ask your user to enter a number between 1 and 5, they are
    likely to enter anything but the numbers 1, 2, 3, 4, or 5\. You can expect them
    to enter a, b, %, 1231482, nonprintable characters, and a wide range of other
    inputs!
  prefs: []
  type: TYPE_NORMAL
- en: The practices of input validation, error handling, fail-safe defaults, output
    sanitization, logging/monitoring, and static analysis are some aspects of defensive
    coding. As we move on with the project, we will keep these principles in mind.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4.3 File header record (type 1)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A file header record contains important information about the institution the
    file came from and what it is destined for. Some file details, such as creation
    date and time, can also help determine whether the file has been loaded before,
    although we will rely on hashing the contents of the file as well.
  prefs: []
  type: TYPE_NORMAL
- en: A powerful feature of ChatGPT is the ability to remember conversations; if we
    are signed into ChatGPT, we can go in and ask it to expand the parsing of the
    `parse_file_header` routine. This will give us another good starting point, and
    then we can even go in and ask it to create a unit test for the header record
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: However, when we tried this approach, we ran into a few problems such as the
    file creation date being eight positions instead of six (it used a four-digit
    year). The record itself was not 94 bytes long, which also gave an error during
    parsing. We used the sample.ach file and that header record as an expected result
    and then ran the `pytest` against that.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the unit test and break it down (listing 2.7). We start by defining
    the function name, and by convention, the name begins with `test_`, which helps
    identify the function as something for `pytest` to pick up and run.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we have our sample line that is going to be passed to the parse routine.
    We also use `expected_result`, which is defined as a dictionary. We could also
    embed this directly into our `assert` statement, but for clarity, it is often
    easier to break it. By using a dictionary, we also employ our IDE. For instance,
    PyCharm provides a nice comparison window if this test fails, where we can see
    where the difference is. We then define the parser and call the routine with our
    `sample_header`.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we have an `assert`, which is where the actual check is done. If the
    result is not the same as the `expected_result`, we will see the error message.
    We can include as many `assert` statements as necessary. For instance, we may
    assert the response of an HTTP call was successful prior to checking fields that
    we expected to be returned.
  prefs: []
  type: TYPE_NORMAL
- en: The subsequent parsing of other records will also follow this code pattern,
    so whether we code it by hand, copy/paste, or use generative AI, we should be
    able to come up with similar tests for the other record formats.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.7  `pytest` for parsing a file header record
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Defines a record that we want to test the parser against'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Defines a dictionary that contains the parsed fields'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Creates an instance of our AchFileProcessor class'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 Calls the function to parse the file header and return a result. This method
    is meant to be private, but for ease of testing, we are accessing it directly.'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Compares the returned result to the expected result; this causes pytest
    to throw an error if they do not match.'
  prefs: []
  type: TYPE_NORMAL
- en: We could certainly have told ChatGPT to create unit tests for us as well. As
    mentioned earlier, we are looking to “trust but verify” when it comes to using
    these tools. It may be possible to generate both the code and the tests, but given
    that we are also trying to understand ACH better, that may be counterproductive.
    For instance, if the tool generated a bad function for us to parse the file, it
    may also be likely to generate incorrect unit tests. We may end up with unit tests
    that appear to pass and validate the code only to find they are both wrong. When
    generating the code, we can understand it better by writing the unit tests ourselves
    (or generate the unit tests and write the code).
  prefs: []
  type: TYPE_NORMAL
- en: Still, there are benefits to seeing what may be generated when asking for unit
    tests. We prompt ChatGPT with
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Prompt-Icon.png)** Given the python function below to
    parse a Nacha ACH File Header, please provide unit tests for it.'
  prefs: []
  type: TYPE_NORMAL
- en: We are presented with the following.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.8  ChatGPT generated `pytests`
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '#1 pytest.raises can be used to validate that specific errors are thrown, which
    is great for testing edge cases and exception conditions.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Extra white space caused invalid values to be used—most obvious was the
    record_size switching from 094 to “A 0”.'
  prefs: []
  type: TYPE_NORMAL
- en: We can see that these unit tests cover incorrect lengths of lines, invalid type,
    and extra whitespace. The invalid type and incorrect length lines may be useful
    tests, but we are unsure what happened with the extra whitespace test. It looks
    as if it was meant to add trailing space, but it also added spaces within the
    record itself. Since this is a fixed-length record, this will obviously lead to
    validation errors later. Still, it did provide us with some direction for additional
    tests when we get to that point. In addition, we saw how we may validate expected
    errors using the `pytest.raises` syntax.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, right now, we are following the happy path, not trying to focus too
    much on the input validation. We simply want to see whether we can get an ACH
    file parsed at this stage.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4.4 Batch header record (type 5)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As the name implies, batch header records indicate the start of a batch for
    a particular company. There can be multiple batches per file and all the entry
    and addenda records that are contained within the batch belong to that company.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the parsing of the batch header record, we can return to the IDE and let
    Copilot get us started, and then also ask it to help us define a `pytest` as well.
    We use the following prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Prompt-Icon.png)** # Define a test function to test parsing
    an ACH batch header record using `AchFileProcessor._parse_batch_header()`.'
  prefs: []
  type: TYPE_NORMAL
- en: We can review that in `test_parsing_file_header.py`.
  prefs: []
  type: TYPE_NORMAL
- en: While the initial function to parse the batch header looks reasonable, the `pytest`
    itself needs more work in terms of the `sample_batch_header` that gets passed
    to the _`parse_batch_header`. The line is 181 characters long, which is more than
    the fixed 94 bytes required by the format. It looks as if the name of each field
    was put into the position of the test record. Also, on further inspection, we
    find that it does not include all the fields in the record format. However, when
    we began typing the name of the field, we were impressed to see the field was
    populated and used the data from the sample, although with mixed results.
  prefs: []
  type: TYPE_NORMAL
- en: Still, it is a very impressive result and more than enough to get us started
    and complete a passing test using the sample.ach file we have been working with.
    After working on the parsing routine and the expected result, we were able to
    pass another test.
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, you were able to parse this record and add a unit test on your own.
    If not, no worries—there are still more types ahead and plenty of chances to give
    it a try! Even though it might be jumping the gun, we also want to look at behavior-driven
    development (BDD) and show a few sample tests that could be used if we were looking
    into that type of approach.
  prefs: []
  type: TYPE_NORMAL
- en: What is behavior-driven development?
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Behavior-driven development is an approach to developing software where we create
    tests around the behavior of the software, and then use them as part of the acceptance
    criteria for determining whether a project is complete. What makes this type of
    testing unique is that all stakeholders work closely together to develop these
    scenarios. Formalizing these user requirements helps ensure that we build a project
    that meets users’ expectations.
  prefs: []
  type: TYPE_NORMAL
- en: Each BDD test is described by a series of `given`/`when`/`then` statements that
    directly relate to desired functionality. We can run these tests from our IDE
    just like we did with our unit tests. The difference is just in the approach to
    designing the tests and the level at which they execute.
  prefs: []
  type: TYPE_NORMAL
- en: As we progress through the project, we will look to expand our BDD testing;
    for now, we create a very simple test that confirms we have successfully parsed
    the record type field. While we have a unit test that confirms this already, it
    will make for a simple introduction to setting up a BDD-style test.
  prefs: []
  type: TYPE_NORMAL
- en: We first define a feature file, which identifies the feature that we are testing
    along with various test scenarios. The feature file is written in a human-readable
    language so that anyone can make sense of it. The `batch_header.feature` is included
    in the code and shown in the next listing.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.9  Parsing an ACH batch header
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: We define the feature and then a simple scenario of “We have a record type 5.”
    The scenario can be named anything, but obviously, we want to convey what this
    test is going to do. The `when` and `then` statements are where the real work
    happens—in our example, *when* we are parsing the header record, and *then* we
    want to ensure we have a record type of 5.
  prefs: []
  type: TYPE_NORMAL
- en: Once we have that information, our next step is to wire the feature file together
    with what are known as *step definitions*. This is how we translate the human-readable
    text into something that we can execute with `pytest`. For brevity, we will show
    a sample of the “then” step definition. The rest of the code is available in `test_batch_header.py`
    for you to browse.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.10  Behavior-driven development testing in Python
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: We decorate the function with `@then` and parse the text string. Within that
    string, we have `{type_5}`. This is a dynamic value that will be pulled in from
    the feature file. So, while we used “the record type should be 5,” the 5 becomes
    a parameter to the function, and we could easily create other scenarios where
    we test other values. We then define the function, passing it the value we parse,
    a record (which is a Python fixture—more on that later), and an `assert` statement
    that we have seen before. This can then be run along with any other test, and
    we are done coding when this test passes. Of course, we already coded this, but
    in later chapters, we will work to define these scenarios beforehand, when we
    work on features. We could potentially come up with additional scenarios for each
    field or simply expand the “then” portion of our test to include multiple `then`
    statements for each field.
  prefs: []
  type: TYPE_NORMAL
- en: 2.5 Entry detail record (type 6)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The entry detail records contain individual transaction data, including the
    account number and amount to credit or debit the account. Keep in mind that the
    parsing of the records can vary slightly, based on the type of records being processed.
    The batch header record contains the type of entry records present in the batch,
    and this is known as the standard entry class (SEC) code.
  prefs: []
  type: TYPE_NORMAL
- en: The parsing of an entry detail record proved more challenging for ChatGPT and
    in our formulation of the prompts for it. Initially, we tried the expanded prompt
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Prompt-Icon.png)** Fully define the _`parse_entry_detail`
    method and provide a `pytest` to validate it.'
  prefs: []
  type: TYPE_NORMAL
- en: While ChatpGPT did provide a method and `pytest`, it failed to meaningfully
    parse the record. We tried again with
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Prompt-Icon.png)** Please the full layout for the NACHA
    Type 6 record.'
  prefs: []
  type: TYPE_NORMAL
- en: Then ChatGPT started calling the type 6 record an addenda record and parsing
    it with the fields associated with that record. We realized that there are different
    types of entry details records (CCD, CTX, PPD, etc.), so we tried to redirect
    with
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Prompt-Icon.png)** Please use the full layout for the
    NACHA Type 6 CCD record.'
  prefs: []
  type: TYPE_NORMAL
- en: While the system correctly identified the type as a cash concentration disbursement,
    it still referred to the entry as an addenda record.
  prefs: []
  type: TYPE_NORMAL
- en: Using Copilot produced better results, populating the correct field names as
    we typed and allowing us to quickly create a template that took just a little
    updating to make the test pass. However, the underlying theme we have seen so
    far is that while both tools are powerful, they need us to validate the results
    and not plug them in blindly. Thus, we can see that knowing the domain is important
    if we want to be able to validate our results.
  prefs: []
  type: TYPE_NORMAL
- en: 2.5.1 Addenda record (type 7)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The addenda record contains additional payment-related information that applies
    to the entry detail record. There may be multiple addenda records per entry detail
    record.
  prefs: []
  type: TYPE_NORMAL
- en: When Copilot was prompted with
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Prompt-Icon.png)** Define a function to parse a Nacha
    Addenda Record.'
  prefs: []
  type: TYPE_NORMAL
- en: it produced several code suggestions. The following listing shows the closest
    valid suggestion. It uses all the required fields, but the offsets are not quite
    right.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.11  Parsing function for an addenda record
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In addition to the general parsing being incorrect, we would prefer to use snake
    case for the dictionary keys. We can try refining the prompt again by defining
    a function to parse a Nacha addenda record using a dictionary and snake case for
    the keys. This provides the keys with the formatting we prefer, but we still need
    to update the offsets.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.12  Parsing function for an addenda record using the snake case
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: To get the correct parsing, we need to adjust `type_code`, `payment_related_information`,
    and `addenda_sequence_number`. The following listing shows the updated return
    statement that could be used.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.13  Updated return statement with corrected fields
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 2.5.2 Batch control record (type 8)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The batch control record is the trailer record for each batch and is a required
    record. We use fields from the record, such as total debit/credit amount and the
    record count, to validate that we received the correct batch contents. The following
    listing shows that Copilot took a different approach to parsing this record.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.14  Copilot parsing a batch control record
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This code looks a bit of overengineered because the nature of this widely used
    fixed-position file format means that the field positions will not be changing.
    As a matter of personal preference, we like to see the actual offsets being used,
    as shown listing 2.12\. The offsets will also make our job easier when dealing
    with errors in parsing a record. Having the field as `'entry_detail_sequence_number':`
    `record[87:94]` means we know where the field `entry_detail_sequence_number` begins
    and ends. We are also willing to allow these magic numbers to exist in the code
    because they are limited to this specific area and not sprinkled throughout the
    code. Of course, we could also create variables named `BEGIN_ENTRY_DETAIL_SEQUENCE_NUMBER_POS`
    and `END_ENTRY_DETAIL_SEQUENCE_NUMBER_POS` and use them if we find a compelling
    reason. Now, let us take a look at parsing the file trailer record.
  prefs: []
  type: TYPE_NORMAL
- en: 2.5.3 File trailer record (type 9)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The final record in an ACH file is the file trailer record (also known as a
    file control record). The file trailer record provides fields such as batch count
    and entry/addenda count we use to validate the file was received correctly. Note
    that the format required the number of records to be a multiple of 10\. So, you
    may find files or software that will pad created ACH files out with records that
    consist of all 9s. However, most software does not require this to be done anymore.
  prefs: []
  type: TYPE_NORMAL
- en: In the following listing, we are back to Copilot parsing the records as we would
    expect. The fields were all cast integers.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.15  Parsing the file trailer record
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: While this code parses the records correctly, we are missing the last field,
    which is marked as reserved. So, while it may not be necessary at this time, we
    may still want to consider including it just for the sake of completeness.
  prefs: []
  type: TYPE_NORMAL
- en: We may also want to create a sample BDD test because, conceivably, subject matter
    experts (SMEs) may provide us with specific use cases for parsing this record
    (or any of these records). A BDD style test may look like the following listing.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.16  BDD style test for type 9—file trailer record
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 2.5.4 Passed!
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Wow, we made it! That was a whirlwind of coding and testing. Even with generative
    AI helping out, that was a lot to take in. Let us now recap what we have just
    accomplished. We started using small development cycles to build unit tests to
    validate the parsing of the various ACH record types. It is important to understand
    that we started by breaking the program created by generative AI into functions
    (we had asked ChatGPT to do this for us before we started). Having generative
    AI create functions allowed us to create unit tests more easily for each record
    type. Otherwise, we would have had to figure out a way to determine if the records
    were parsed correctly and check them after the file was loaded.
  prefs: []
  type: TYPE_NORMAL
- en: Each time, we started by creating a unit test that should fail and then coded
    just enough to make it pass. At this point, we should be relatively familiar with
    the process and ready to apply the same concept to other parts of our project.
  prefs: []
  type: TYPE_NORMAL
- en: 2.6 The not-so-happy path
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Congratulations! We just finished parsing what is very likely our first ACH
    file. We concentrated on what is sometimes referred to as “the happy path.” This
    is where everything goes as expected, without throwing any kind of errors. We
    used a single well-formatted ACH file throughout our parsing to illustrate the
    process.
  prefs: []
  type: TYPE_NORMAL
- en: We should now also consider the not-so-happy path, which is probably what we
    are more likely to encounter in our day-to-day coding. Our not-so-happy path will
    cover some of the problems that can occur when loading a file. There are scenarios
    where the file or a batch may be rejected or where an entry can trigger a rejection.
    We will examine exceptions and handling/recovering from problems with ACH files
    further in chapter 9\. For now, we just want to touch on some of the possibilities.
  prefs: []
  type: TYPE_NORMAL
- en: We will identify some of the possible rejection scenarios and provide sample
    ACH files and `pytests` to code for them. When a file is rejected, we often must
    go back to the originator to request a new one. If any transactions have posted,
    they may need to be reversed as part of the rejection process. For now, we are
    focusing more on identifying bad files than recovering from them. Of course, we
    will provide a finished example that addresses the `pytests`, if you want to skip
    ahead. Obviously, we would encourage you to work through these scenarios as the
    particular scenarios we have chosen do not require extensive knowledge of ACH
    processing.
  prefs: []
  type: TYPE_NORMAL
- en: We will also be adding further validation later, as the project expands. For
    now, we are just expanding our proof of concept.
  prefs: []
  type: TYPE_NORMAL
- en: 2.6.1 File rejection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: ACH files can be rejected when formatted incorrectly. Remember that the order
    of the records is important. An ACH file consists of batches, and each batch contains
    entry and addenda records. Both a batch and the entire file have trailer records.
    All the records should be 94 characters long. So, for the first scenario, we want
    to tackle dealing with a file where records may not be the correct length.
  prefs: []
  type: TYPE_NORMAL
- en: Why would a file be produced with records shorter than 94 bytes? Before SFTP
    (Secure File Transfer Protocol) became common, we would encounter this when ftp
    was set to truncate trailing spaces. While ftp is not as prevalent as before,
    it could still be used internally to transfer files, so the original use case
    may be valid. In addition, files may be routed and retransmitted or even created/updated
    on someone’s computer. As banks merge and acquire each other, these file problems
    may still pop up. Since the Nacha spec requires 94-byte records, we will seek
    to enforce that. We have included ACH_Parser_v3 containing empty unit tests to
    help us validate our changes.
  prefs: []
  type: TYPE_NORMAL
- en: For each of these challenges, we expect the parser to accumulate a list of errors.
    This list should hopefully keep the parsing code relatively simple because we
    are not worried about input errors at this point. This approach also has the added
    benefit of being able to validate the expected results in our unit tests. If we
    know our file has two short lines, we should also expect two of those error messages.
    For now, we will only log an error message if it is a string, but you may expand
    your project or choose another approach.
  prefs: []
  type: TYPE_NORMAL
- en: Code challenge; benefit 1
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We started with a relatively simple program to parse our ACH file. Going back
    and handling these changes will help us gather some real-world experience because
    we are likely going to be maintaining and updating existing code more than writing
    code from the ground up.
  prefs: []
  type: TYPE_NORMAL
- en: 'The relatively simple change to check for a record length forces us to deal
    with exceptions and think about how we might want to identify, format, and store
    them. It also presents us with some choices in how we code this: Do we continue
    to store this unparsed record along with the other records? If not, where does
    it go, and how does a user know which record had an error?'
  prefs: []
  type: TYPE_NORMAL
- en: Seemingly mundane choices can sometimes have a significant influence down the
    road. So, this is just something to keep in mind and watch for as we work through
    the program.
  prefs: []
  type: TYPE_NORMAL
- en: 2.6.2 Batch rejection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Individual batches may also be rejected from a file, and one reason is that
    the trace numbers are not ascending. A trace number appears on each entry detail
    record (type 6). As the name implies, these trace numbers provide a way to identify
    an ACH transaction within a batch. The first eight digits of a trace number are
    the routing number of the Originating Depository Financial Institution (ODFI)—in
    other words, what bank or financial institution the transaction came from—and
    the last seven digits of the trace number are in ascending order (but not necessarily
    sequential).
  prefs: []
  type: TYPE_NORMAL
- en: A unique trace number provides a means to reconcile and report on these ACH
    transactions and the ability to trace a transaction through the payment system
    for both regulatory and compliance reasons. We can now expand the ACH parser to
    consider these trace numbers. Again ACH_Parser_v3 has some unit tests that we
    can use to verify whether our program parsed the file correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Code challenge; benefit 2
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This challenge gets a little more complicated in how we will choose where and
    when to handle these exceptions. We started off with our functions being named
    _`parse_entry_detail`. If we choose to update the code to handle verification
    in that parse routine, will we update that function name since it is no longer
    just parsing? Will one routine call another, or will we call two routines or just
    use one routine? Do we parse the record first and then check the trace number,
    or do we check it before parsing the whole record?
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, we want to make changes with surgical precision for both time and
    complexity reasons. Other times, we may opt for a shotgun approach when there
    are multiple things that must be accomplished. Either way, you should still be
    working in short cycles, making sure to test often.
  prefs: []
  type: TYPE_NORMAL
- en: 2.6.3 Entry rejection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An entry may be rejected if the addenda flag is not consistent with the existence
    of an addenda record. The entry detail record contains a flag indicating whether
    the next record is an addenda record. Addenda records include additional information
    for ACH transactions and are sometimes required for specific SEC codes. With only
    94 bytes to work with, it is sometimes necessary to have addenda records to pass
    additional information about the transaction along.
  prefs: []
  type: TYPE_NORMAL
- en: Code challenge; benefit 3
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Coding this challenge requires us to look ahead or look behind as we need to
    be able to determine whether we expect an addenda record. This goes back to making
    decisions and then deal with them later.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, the existing code had read all the lines and then used a `for-each`
    loop to iterate through them. Having the `for-each` loop is handy, but now we
    potentially need a way to index our list of lines. If we need to conserve memory
    because we expect large ACH files, we may not want to read all the lines in, and
    therefore, we would have to take another approach to finding an addenda record.
  prefs: []
  type: TYPE_NORMAL
- en: This is all part of the software development process. Thinking about and planning
    our changes will help us address some of these challenges and hopefully future-proof
    our code.
  prefs: []
  type: TYPE_NORMAL
- en: When we come across a bad design choice that we or a co-worker have made, learn
    from it. Even if it is annoying and makes you rework a lot of code, you can take
    something away from the experience!
  prefs: []
  type: TYPE_NORMAL
- en: 2.7 Interpreting the code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Depending on your experience with Python, you may have some questions about
    the code that was produced as part of this example. The following sections examine
    the code in more detail to provide additional insight into the Python code we
    have written, covering the Python `switch` statement, type hints, and secure coding.
  prefs: []
  type: TYPE_NORMAL
- en: 2.7.1 Where’s my switch statement?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are six record types for ACH that we need to parse. If you have some programming
    experience, you have likely come across the `if`/`if` `else`/`else` construct
    for flow control. In Python, we would see this as
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: At some point, we probably also coded rather large `if` statements with multiple
    conditions before someone introduced you to a `switch/case` statement. Early in
    Python (circa 2006), support for `switch`/`case` statements was debated and finally
    rejected. However, as of Python 3.10, there is support for the match statement
    (h[ttps://peps.python.org/pep-0634/](https://peps.python.org/pep-0634/)), which
    provides the means to create a `switch` statement, as shown in the next listing.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.17  Creating a `switch` statement using `match`
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Uses the match keyword to create cases for the record_type field'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Each condition has a case statement.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 The default case is identified with an underscore.'
  prefs: []
  type: TYPE_NORMAL
- en: With millions of lines of Python code written before the `match` construct became
    available, generative AI is likely to show you the `if`/`elif` or another common
    practice of creating a Dictionary to store the choices as was done in the sample
    program.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.18  Using a Dictionary
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Defines a Dictionary of functions that can be called'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Retrieves the function from the Dictionary based on the record_type'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Calls the parser for the given line and appends the results to the records
    variable'
  prefs: []
  type: TYPE_NORMAL
- en: This code declares the functions for each type and calls the appropriate function.
    One thing that would make us favor another approach is that we cannot see whether
    the parameters should be passed to the function. We may not even be able to tell
    if they are functions. One way to handle this is using type hints.
  prefs: []
  type: TYPE_NORMAL
- en: 2.7.2 Type hints
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Type hints have been around since Python 3.5 and were defined in [https://peps.python.org/pep-0484](https://peps.python.org/pep-0484).
    While Python uses duck typing, the addition of type hints can help make the code
    more maintainable. In our opinion, it goes back to having to choose between freedom
    to code and the code longevity. When writing Python code, it is great not to be
    constrained by static typing; instead, we can focus more on the code. However,
    as more Python code comes into existence, or when we must start looking at other
    people’s code, we want some of those guides. So, while Python does not enforce
    type hints at runtime, there are tools that can be used to do static type checking
    based on these type hints, as well as just the benefits of documentation.
  prefs: []
  type: TYPE_NORMAL
- en: We also wonder whether the popularity of Python and the migration of developers
    to it from other languages have also brought some of their baggage. We believe
    these additions to the language are important, and as they have gone through the
    Python Enhancement Proposal (PEP) process, the community agrees. Of course, our
    backgrounds are in statically typed languages, so these make sense. If we came
    from LISP or Scheme, would we want to see a bunch of parentheses added to the
    language?
  prefs: []
  type: TYPE_NORMAL
- en: 'Our original problem with the dictionary approach to flow control was that
    we did not have a way to tell what parameters could be passed to the functions
    we were calling. We can update the `parser_functions` to use type-hinting:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The variable `parser_functions` is now defined as a Dictionary that contains
    a string (`str`) for the record type and a `Callable` that represents the function
    being called. The `Callable` takes a list of parameters, and in this case, we
    see it takes one string that is denoted by `[str]` and that it returns a dictionary
    of strings, which is our parsed record.
  prefs: []
  type: TYPE_NORMAL
- en: After seeing the type hint for this, maybe we decide to rewrite our code to
    take advantage of one of those other constructs because that seems confusing!
    By embracing the use of type hints, we could then move to static type checkers
    such as mypy, Pyright, and Pyre. In our opinion, static type checking is a must-have
    for enterprise applications where there are large teams or the project is long-lived
    (and we assume they will be). Other developers diving into the code base for the
    first time or after a hiatus on the project will find them immensely helpful.
    Of course, Python is going to remain a dynamically typed language (see [https://mng.bz/oKEM](https://mng.bz/oKEM)),
    but the proliferation of tools and their adoption should show that there is at
    least some benefit to type checking.
  prefs: []
  type: TYPE_NORMAL
- en: 2.7.3 Secure coding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There has been concern that generative AI may not be producing code that is
    secure or code that is even good. This is not only true for generative AI but
    also for humans: we all make mistakes. Going back to our tool analogy, we need
    to remember that generative AI is just another tool we should be using, which
    is why we advocate the use of formatting and linters to help identify problems
    within our code.'
  prefs: []
  type: TYPE_NORMAL
- en: Corporations use a number of tools available on the market to scan their code
    looking for flaws and security holes. These tools include Fortify on Demand, Veracode,
    Snyk, and Amazon’s CodeWhisperer. The primary goal of this software is to look
    for insecure coding patterns. They often use the OWASP 10, SANS Top 25, and other
    lists as guides to the problems they identify.
  prefs: []
  type: TYPE_NORMAL
- en: Many times, these are incorporated into a CI/CD pipeline; however, we also have
    options for handling them inside our IDE as well. Since The Fantastic Fintech
    Company uses JetBrains, we can take advantage of some of their included features.
    For instance, in our requirements.txt for our Python project, PyCharm will detect
    vulnerabilities in our dependencies (see figure 2.5). We can see the Common Vulnerabilities
    and Exposures (CVE) ID and a short description of the vulnerability.
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer error  Description automatically generated](../Images/CH02_F05_Kardell.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.5  An example dependency
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: By clicking More actions, we can simply choose to update to a newer version,
    as shown in figure 2.6\. Of course, this action would require further application
    testing, but it is certainly nice to be alerted to potential problems before our
    code even makes it to the CI/CD pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer error  Description automatically generated](../Images/CH02_F06_Kardell.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.6 Options to handle vulnerability
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Chances are most companies have either adopted a static analysis tool or are
    currently evaluating them. Having the ability to allow developers to view and
    troubleshoot problems directly in the IDE is another way to boost productivity.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We explored how to incorporate generative AI into our development workflow,
    learning what to ask (prompt engineering) and how to clarify our intent (problem
    formulation).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We focused on modernizing an ACH system running on legacy mainframe architecture
    using metrics such as release cadence and defect backlog.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We utilized ChatGPT and GitHub Copilot to understand ACH file layouts better
    while ensuring that no confidential data is exposed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ACH network facilitates seamless money transfers between banks, and it is commonly
    used for transactions such as payroll and bill payment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ACH files are fixed-width ASCII files with specific record types that require
    careful parsing of file header, batch header, entry details, addenda, batch control,
    and file trailer records.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ACH parsing can be validated using unit tests with TDD to obtain reliable, high-quality
    software.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linters and formatters such as SonarLint and black can be used to enforce coding
    standards and reduce cognitive load.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scenarios in which ACH files may have errors can be handled using robust code
    that accounts for unexpected inputs and edge cases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Type hints can be implemented in Python for enhanced code clarity and maintainability,
    which helps easier collaboration and onboarding.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Security concerns can be addressed by using static analysis tools to identify
    coding vulnerabilities and ensure compliance with security standards.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter reiterated the importance of robust testing practices, iterative
    development, and early detection of potential problems using IDE plugins.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
