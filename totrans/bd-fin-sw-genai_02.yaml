- en: 2 Parsing payments
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2 解析支付
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Working with generative AI to parse an ACH file
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用生成式AI解析ACH文件
- en: Unit testing in Python
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Python进行单元测试
- en: Agile concepts
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 敏捷概念
- en: This chapter explains the fundamentals of files formatted by an Automated Clearing
    House (ACH). You will work on parsing an initial sample file to better understand
    some of the record layouts used, as well as the software development practice
    of unit testing. You will also expand your knowledge of generative AI and see
    how to apply it to a real-world problem.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章解释了由自动清算所（ACH）格式化的文件的基本原理。你将解析一个初始样本文件，以更好地了解一些使用的记录布局，以及单元测试的软件开发实践。你还将扩展你对生成式AI的知识，并了解如何将其应用于现实世界的问题。
- en: 2.1 Modernizing our legacy software
  id: totrans-6
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 现代化我们的遗留软件
- en: Now that we have gone through PI planning and have been assigned our project,
    we will begin working on our first spike. In SAFe, spikes are a type of story,
    often referred to as an enabler story. A variety of enabler story categories may
    be used (e.g., exploration, architectural, infrastructure, and compliance). In
    our case, our story may be classified as an exploration type or a research spike.
    However, the details are not as important as our activities because the particulars
    may vary between Agile frameworks. Essentially, this story aims to provide the
    team with some experience working in Python and learning about the ACH file layout
    so that we can understand prospective solutions better.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了PI规划并分配了我们的项目，我们将开始着手我们的第一个spike。在SAFe中，spike是一种故事类型，通常被称为启用故事。可以使用多种启用故事类别（例如，探索、架构、基础设施和合规）。在我们的情况下，我们的故事可能被归类为探索类型或研究spike。然而，细节并不像我们的活动那样重要，因为具体细节可能在不同敏捷框架之间有所不同。本质上，这个故事旨在为团队提供一些在Python中工作以及了解ACH文件布局的经验，以便我们更好地理解预期的解决方案。
- en: 'The stories assigned to the team in this sprint can shed light on the business
    needs driving the modernization effort. The current ACH system runs on the mainframe
    system, and it is highly coupled with the existing architecture. This coupling
    prevents the system from being maintained easily. The business has been keeping
    metrics on various key performance indicators (KPIs):'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在这次迭代中分配给团队的故事可以揭示推动现代化努力的商业需求。当前的ACH系统运行在主机系统上，并且与现有架构高度耦合。这种耦合使得系统难以维护。业务一直在跟踪各种关键绩效指标（KPIs）：
- en: '*Release cadenc**e*—Shows how often the development teams release new features
    and updates'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*发布节奏*——显示开发团队发布新功能和更新的频率'
- en: '*Defect backlo**g*—Shows the number of defects identified during development
    and release'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*缺陷回溯*——显示在开发和发布过程中识别出的缺陷数量'
- en: '*Escaped defect**s*—Shows the number of defects identified after the software
    has been released'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*逃逸缺陷*——显示软件发布后识别出的缺陷数量'
- en: '*Customer satisfactio**n*—Indicates how happy the customer is with our product/service'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*客户满意度*——表明客户对我们产品/服务的满意度'
- en: These metrics have shown that there has been a steady increase in the time it
    takes to make regulatory enhancements and general bug fixes as the system’s code
    base has grown in both size and complexity.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标显示，随着系统代码库在规模和复杂性上的增长，进行监管增强和一般性错误修复所需的时间一直在稳步增加。
- en: Currently, we do not have any knowledge of ACH files, and understanding and
    navigating the COBOL code will take time; moreover, we may need to request access.
    The team will have to gain insight into the COBOL code so that they can better
    assist in converting functionality from one area to another. In the interim, the
    team is supposed to tackle the project from the ground up. The team also has first
    access to generative AI tools to help evaluate their use since the company is
    looking into using Gen AI to improve productivity. Our manager believes that the
    team is in a unique position to evaluate the tools to help us with this effort.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，我们对ACH文件没有任何了解，理解和导航COBOL代码将需要时间；此外，我们可能需要请求访问权限。团队将需要深入了解COBOL代码，以便他们能更好地协助将功能从一个区域转换到另一个区域。在此期间，团队应从项目的基础开始着手。团队还首次获得访问生成式AI工具的权限，以帮助评估其使用情况，因为公司正在考虑使用生成式AI来提高生产力。我们的经理认为，团队处于一个独特的位置，可以评估这些工具以帮助我们完成这项工作。
- en: The company gave us access to both premium ChatGPT and GitHub Copilot membership.
    They have also asked that we test out the free version of ChatGPT because, if
    the free version is comparable to the premium one, they would much rather save
    some money. In addition, our manager has reminded us not to paste any proprietary
    or confidential information into ChatGPT because that would be a potential violation
    of the nondisclosure agreement (NDA) we have in place. This means we cannot paste
    the COBOL code and convert it to Python or ask ChatGPT to interpret existing code.
    Instead, we should focus on isolating, sanitizing, and generalizing code samples
    before plugging them into ChatGPT.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 公司为我们提供了高级ChatGPT和GitHub Copilot会员的访问权限。他们还要求我们测试ChatGPT的免费版本，因为如果免费版本与高级版本相当，他们更愿意节省一些钱。此外，我们的经理提醒我们不要将任何专有或机密信息粘贴到ChatGPT中，因为这可能会违反我们现有的保密协议（NDA）。这意味着我们无法粘贴COBOL代码并将其转换为Python，或者要求ChatGPT解释现有代码。相反，我们应该在将代码样本插入ChatGPT之前，专注于隔离、净化和泛化代码样本。
- en: 'Our plan is to do a little research on what exactly an ACH is and what type
    of format we’ll be working with. We are familiar with JSON as we have done a fair
    amount of web-based work before. Either way, we are excited to get moving on to
    this project: getting into some code and working on a project is why we wanted
    this job in the first place, so let’s begin!'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的计划是研究一下ACH究竟是什么，以及我们将要处理哪种类型的格式。我们熟悉JSON，因为我们之前已经做过相当多的基于Web的工作。无论如何，我们都对开始这个项目感到兴奋：进入一些代码并开展工作是我们当初想要这份工作的原因，所以让我们开始吧！
- en: 2.2 Understanding the ACH
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 理解ACH
- en: The ACH network allows banks and credit unions to transfer money without establishing
    a separate relationship. Given that there are over 10,000 banks and credit unions
    in the United States, that is quite an undertaking! So, how does it work?
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ACH网络允许银行和信用合作社在不建立单独关系的情况下转账。鉴于美国有超过10,000家银行和信用合作社，这是一项相当大的任务！那么，它是如何工作的呢？
- en: 'A common type of ACH transaction is known as Prearranged Payment and Deposit
    (PPD). It is often used for direct deposit of paychecks (and recurring bill payments,
    gym memberships, and social security payments, to name a few). Let us say our
    employer has an account at bank X. Every two weeks or twice a month, they need
    to pay us, but we use a different bank, bank Y. To get the money to you, a few
    days before payday, our employer or their payroll processor will create a file
    containing the information needed to execute the payment. It includes the amount
    of our take-home pay, our account number, and a *routing transit number.* A routing
    transit number is a unique number that identifies a bank—in this case, the bank
    of the end recipient of the transaction: bank Y. The payroll processor will transmit
    the file containing the employee wages info to bank X. Bank X accepts the file
    and combines it with other files they receive. Next, it sends one file to either
    the Federal Reserve or a private company called The Clearing House. These two
    entities are known as *ACH operators* *or* *clearing houses*. ACH operators accept
    files from thousands of banks, sort the transactions based on their routing transit
    numbers, and create new files for each bank receiving transactions. These files
    are then transmitted to the banks, which then receive and post the transactions.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 一种常见的ACH交易类型被称为预先安排的支付和存款（PPD）。它通常用于直接存款支付工资（以及定期账单支付、健身房会员费和社会保障支付等）。假设我们的雇主在银行X有账户。每两周或每月两次，他们需要向我们支付工资，但我们使用的是另一家银行，银行Y。为了在发薪日前几天将钱转到你那里，我们的雇主或他们的工资处理器将创建一个包含执行支付所需信息的文件。它包括我们的实发工资金额、我们的账户号码和一个*路由转换号*。路由转换号是一个唯一数字，用于识别一家银行——在这种情况下，交易最终接收方的银行：银行Y。工资处理器会将包含员工工资信息的文件传输给银行X。银行X接受该文件，并将其与其他收到的文件合并。接下来，它将一个文件发送到联邦储备银行或一家名为The
    Clearing House的私人公司。这两个实体被称为*ACH运营商*或*清算所*。ACH运营商接受来自数千家银行的文件，根据其路由转换号对交易进行分类，并为每个接收交易的银行创建新文件。然后，这些文件被传输到银行，银行随后接收并处理这些交易。
- en: ACH files use a format defined by Nacha, the organization that sets standards
    for the ACH network. Figure 2.1 shows the ACH processing flow.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: ACH文件使用由Nacha定义的格式，Nacha是制定ACH网络标准的组织。图2.1显示了ACH处理流程。
- en: '![A diagram of a company  Description automatically generated](../Images/CH02_F01_Kardell.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![公司图示 描述自动生成](../Images/CH02_F01_Kardell.png)'
- en: Figure 2.1  ACH processing flow
  id: totrans-22
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.1 ACH处理流程
- en: 2.3 Parsing an ACH file
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 解析ACH文件
- en: So, we have been assigned a story to parse an ACH file and store it in the database.
    The story has subtasks for parsing each of the record formats found in an ACH
    file, as well as storing the results in a database.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们被分配了一个任务，解析一个ACH文件并将其存储在数据库中。这个任务包括对ACH文件中发现的每种记录格式的解析子任务，以及将结果存储在数据库中。
- en: The ACH file standard was created in the 1970s and has undergone various updates
    and expansions since then. This is great because it means that plenty of information
    is available on the standard. We start by doing some research on ACH, finding
    that an ACH file is a fixed-width ASCII file with each line being 94 characters
    long. These lines are known as records, and each record consists of fields that
    are at fixed positions. A fixed-width file with records at fixed positions should
    mean parsing is a relatively straightforward task.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: ACH文件标准是在20世纪70年代创建的，自那时以来经历了各种更新和扩展。这很好，因为它意味着关于标准的很多信息都是可用的。我们从对ACH的研究开始，发现ACH文件是一个固定宽度的ASCII文件，每行94个字符长。这些行被称为记录，每个记录由固定位置的字段组成。具有固定位置记录的固定宽度文件应该意味着解析是一个相对简单的任务。
- en: Digging a little bit further, we see that there are six types of ACH records
    that may be present in a file. It seems there are a few types of header records,
    and each has a trailer record known as a control record that wraps up the data.
    We also find an overview of the record types and file structure (see figure 2.2).
    Further details on the records and their corresponding fields (such as the position,
    whether it is required, etc.) are available at [https://achdevguide.nacha.org/ach-file-details](https://achdevguide.nacha.org/ach-file-details).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 深入挖掘，我们发现文件中可能存在六种类型的ACH记录。似乎有一些类型的标题记录，每种都有称为控制记录的尾记录来封装数据。我们还找到了记录类型和文件结构的概述（见图2.2）。关于记录及其对应字段（如位置、是否必需等）的更多详细信息可在[https://achdevguide.nacha.org/ach-file-details](https://achdevguide.nacha.org/ach-file-details)找到。
- en: '![](../Images/CH02_F02_Kardell.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH02_F02_Kardell.png)'
- en: Figure 2.2  ACH file layout
  id: totrans-28
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.2  ACH文件布局
- en: Figure 2.2 gives us an idea of the file structure; however, let’s also look
    at a sample file that we will be working with so we can get a better idea of what
    a file may look like. Figure 2.3 may look a bit daunting, but once we break down
    the records into their fields, it is relatively straightforward.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.2给我们提供了文件结构的概念；然而，让我们也看看我们将要工作的样本文件，这样我们可以更好地了解文件可能的样子。图2.3可能看起来有点令人畏惧，但一旦我们将记录分解为字段，它就相对简单易懂。
- en: '![](../Images/CH02_F03_Kardell.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH02_F03_Kardell.png)'
- en: Figure 2.3  Example ACH file
  id: totrans-31
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.3  示例ACH文件
- en: 'Based on the structure and file sample, we know that we will have to parse
    the following record types:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 根据结构和文件样本，我们知道我们不得不解析以下记录类型：
- en: '*Type* *1*—A file header record with a single record per file'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*类型* *1*—一个文件头记录，每个文件只有一个记录'
- en: '*Type* *5*—A batch header record with multiple batches per file'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*类型* *5*—一个文件头记录，每个文件有多个批次'
- en: '*Type* *6*—Entry records, with multiple entries per batch'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*类型* *6*—条目记录，每个批次有多个条目'
- en: '*Type 7*—Addenda records with zero or multiple records per entry record'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*类型 7*—附加记录，每个条目记录可以有零个或多个记录'
- en: '*Type* *8*—A batch control record that encloses the entry and addenda records'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*类型* *8*—一个批次控制记录，包含条目和附加记录'
- en: '*Type* *9*—A file trailer record that encloses all the batch records'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*类型* *9*—一个文件尾记录，包含所有批次记录'
- en: While we have not gotten access to the legacy COBOL code, a team member found
    a confluence (a wiki provided by Atlassian) site with the flow chart that provides
    some insight into the processing of an ACH file (figure 2.4).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们还没有获得对传统COBOL代码的访问权限，但团队成员发现了一个康纳菲斯（由Atlassian提供的wiki）网站，该网站提供了一个流程图，提供了对ACH文件处理的一些见解（图2.4）。
- en: '![](../Images/CH02_F04_Kardell.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH02_F04_Kardell.png)'
- en: Figure 2.4  ACH processing flow
  id: totrans-41
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.4  ACH处理流程
- en: Your first task is to check your favorite search engine to see what is available.
    You may find some existing packages (`pyNacha`, `py-nacha`, and `pynacha`). Those
    appear to be various projects exploring how to create and parse ACH files. Further
    digging also shows some of these projects came from `carta-ach`, which again came
    from `python-ach`. These projects have been forked many times, but most appear
    to have not been updated for some time. As they are not actively maintained, it
    may not be wise to base your project on them. However, they appear to have a permissive
    MIT license (more on licensing concerns later), so we could possibly fork a project
    to get started. We can also lean on some of our generative AI tools for some help
    as well.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 你的第一个任务是检查你的首选搜索引擎以查看有什么可用。你可能会找到一些现有的包（`pyNacha`、`py-nacha` 和 `pynacha`）。这些似乎是一些探索如何创建和解析
    ACH 文件的不同项目。进一步的挖掘也显示，其中一些项目来自 `carta-ach`，而 `carta-ach` 又来自 `python-ach`。这些项目已经被多次分叉，但大多数似乎已经有一段时间没有更新了。由于它们没有得到积极维护，因此基于它们的项目可能不是明智的选择。然而，它们似乎有一个宽松的
    MIT 许可证（关于许可问题的更多内容稍后讨论），因此我们可能可以分叉一个项目以开始。我们还可以利用一些我们的生成式 AI 工具来获得一些帮助。
- en: 2.3.1 Asking ChatGPT to parse an ACH file
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.1 向 ChatGPT 请求解析 ACH 文件
- en: We can start by asking ChatGPT the question, “Can you write a Python program
    to parse an ACH file?”When we try this in ChatGPT 3.5, it gives us the basics
    of an `ACH` class that can parse a file, as shown in the next listing.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以先向 ChatGPT 提出问题：“你能写一个 Python 程序来解析 ACH 文件吗？”当我们尝试在 ChatGPT 3.5 中这样做时，它给出了一个可以解析文件的
    `ACH` 类的基本结构，如下一个列表所示。
- en: Listing 2.1  ACH parser from ChatGPT 3.5
  id: totrans-45
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 2.1  ChatGPT 3.5 的 ACH 解析器
- en: '[PRE0]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '#1 Defines a class named ACHParser'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 定义了一个名为 ACHParser 的类'
- en: '#2 The __init__ function is used as a constructor for our class.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 `__init__` 函数用作我们类的构造函数。'
- en: '#3 Reads the entire file'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 读取整个文件'
- en: '#4 Determines the first character and stores it in record_code'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 确定第一个字符并将其存储在 `record_code` 中。'
- en: '#5 Performs processing based on the record_code; notice there is no record_code
    5 or 8.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 根据记录代码进行基于记录的处理；注意没有记录代码 5 或 8。'
- en: 'The program does not look too bad; however, despite our current limited knowledge
    of ACH, we can see that it has some problems:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 程序看起来还不错；然而，尽管我们对 ACH 的了解有限，但我们可以看出它有一些问题：
- en: Missing a record type code of `5`.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺少记录类型代码 `5`。
- en: Missing a record type code of `8`.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺少记录类型代码 `8`。
- en: The `record_type` lables are incorrect, as `6` is listed as a `batch` instead
    of an `entry`, and `7` is listed as `entry` instead of `addenda`.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`record_type` 标签不正确，因为 `6` 被列为 `batch` 而不是 `entry`，而 `7` 被列为 `entry` 而不是 `addenda`。'
- en: We try switching over to the updated ChatGPT 4 and ask it the same question.
    We are presented with the code shown in the following listing. Again, keep in
    mind that the nondeterministic nature of LLMs may lead to different results.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尝试切换到更新的 ChatGPT 4 并向它提出相同的问题。我们看到了以下列表中显示的代码。再次提醒，由于大型语言模型的不确定性，可能会导致不同的结果。
- en: Listing 2.2  ACH parser from ChatGPT 4
  id: totrans-57
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 2.2  ChatGPT 4 的 ACH 解析器
- en: '[PRE1]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '#1 An empty array to store ACH records into'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 一个空数组，用于存储 ACH 记录。'
- en: '#2 Each record_type is stored as a dictionary; some of the fields were provided
    by ChatGPT.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 每个记录类型都存储为一个字典；其中一些字段是由 ChatGPT 提供的。'
- en: '#3 ChatGPT 4 did generate a record type 8 this time.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 这次 ChatGPT 4 生成了记录类型 8。'
- en: '#4 ACH records are added to our array.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 将 ACH 记录添加到我们的数组中。'
- en: '#5 The records are returned.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 返回记录。'
- en: '#6 The returned records are printed out using a for-each loop.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 使用 for-each 循环打印出返回的记录。'
- en: This program seems to be a little more built out. We see the batch control record
    (record type 8) this time, and some of the lines have a sample parsing done as
    well. This seems to be a good start; however, we want to keep the program testable.
    If we separate the parsing logic into separate functions, we can pass both well-formatted
    records and invalid data to the function to test it. Let’s see if we can get ChatGPT
    to do that somewhat tedious process.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这个程序似乎更完善了一些。我们看到这次有批控制记录（记录类型 8），并且一些行还进行了样本解析。这似乎是一个不错的开始；然而，我们希望保持程序的可测试性。如果我们将解析逻辑分离到单独的函数中，我们就可以向函数传递格式良好的记录和无效数据来测试它。让我们看看
    ChatGPT 是否能完成这个有点繁琐的过程。
- en: 'We simply ask ChatGPT:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只是简单地询问 ChatGPT：
- en: '**![image](../Images/Prompt-Icon.png)** Can you update the above program so
    that the parsing of each record type is a separate function?'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '**![图片](../Images/Prompt-Icon.png)** 你能更新上述程序，使得每个记录类型的解析都是一个单独的函数吗？'
- en: The program is updated to break each of the record types into its own function.
    The relevant changes are shown in the following listing. Notice that we have been
    provided with parser functions (`parse_file_header`, `parse_batch_header`, etc.)
    and that these have been stubbed out by ChatGPT (meaning we will have to provide
    implementation details to parse the actual data).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 程序更新为将每种记录类型拆分为其自己的函数。相关更改在以下列表中显示。请注意，我们已经提供了解析函数（`parse_file_header`、`parse_batch_header`
    等），并且这些函数已被 ChatGPT 存根（意味着我们将需要提供实现细节以解析实际数据）。
- en: Listing 2.3  Parsing with separate functions
  id: totrans-69
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 2.3  使用单独的函数进行解析
- en: '[PRE2]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#1 Defines needed parsing functions in a dictionary'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 在字典中定义所需的解析函数'
- en: '#2 Retrieves the appropriate function based on the first character we stored
    in record_type'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 根据我们存储在 record_type 中的第一个字符检索适当的函数'
- en: '#3 Calls the parse function with the appropriate data'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 使用适当的 数据调用解析函数'
- en: '#4 Calls the parse function with the appropriate data'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 使用适当的数据调用解析函数'
- en: '#5 One of the sample stubs for the parser_functions'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 解析函数的样本存根之一'
- en: In the tests/data folder, there is also a sample.ach file (as we saw in figure
    2.2) that we can plug into these sample programs to examine how they process the
    file and play around with the results. Now it would be a good time to take a break
    and run the sample ACH file through these programs to see how they work. This
    is helpful if we do not quite understand ACH file processing yet or if we are
    unfamiliar with some of the constructs used in the Python program.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在 tests/data 文件夹中，还有一个样本.ach 文件（如图 2.2 所示），我们可以将其插入到这些样本程序中，以检查它们如何处理文件并玩转结果。现在是一个很好的时候，休息一下，运行样本
    ACH 文件通过这些程序，看看它们是如何工作的。如果我们还不完全理解 ACH 文件处理，或者如果我们对 Python 程序中使用的某些结构不熟悉，这将很有帮助。
- en: It is a powerful tool to help us get started. Many developers have templates,
    shells, or skeleton programs they use to get started with particular tasks. Or
    they may choose a particular program to copy and paste. Of course, the problem
    with copying/pasting is that you may inevitably miss something and introduce a
    compile-time problem or bug that you then need to troubleshoot. The same thing
    can happen when using a template to start your program.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 它是一个强大的工具，可以帮助我们开始。许多开发者都有模板、外壳或骨架程序，他们使用这些程序开始特定的任务。或者他们可能选择一个特定的程序进行复制粘贴。当然，复制/粘贴的问题是你可能会不可避免地遗漏某些内容，并引入编译时问题或错误，然后你需要进行故障排除。当使用模板开始你的程序时，同样的事情也可能发生。
- en: These templates or code produced from generative AI can be useful, especially
    if we are willing to look at the code and learn from it. Maybe we will learn a
    new way to do something or maybe we will find a new technique to apply. Still,
    maybe we find a bug in the produced code. The point is that it can be a helpful
    tool as long as we use it and do not take the output for granted; the code produced
    must be treated as our own code, meaning it should be tested and verified through
    our unit testing and quality assurance (QA) process.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这些模板或由生成式 AI 生成的代码可能很有用，特别是如果我们愿意查看代码并从中学习的话。也许我们会学会一种新的做事方式，或者也许我们会找到一种新的应用技术。尽管如此，也许我们会在生成的代码中找到错误。关键是，只要我们使用它，并且不把输出视为理所当然；生成的代码必须像我们自己的代码一样，这意味着它应该通过我们的单元测试和质量保证（QA）流程进行测试和验证。
- en: 2.3.2 Parsing an ACH file with Copilot
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.2 使用 Copilot 解析 ACH 文件
- en: 'After seeing what ChatGPT has to offer us, let’s use Copilot to see whether
    it can get us closer. We first enter the following into an empty Python script:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在看到 ChatGPT 提供的内容后，让我们使用 Copilot 来看看它是否能让我们更接近目标。我们首先将以下内容输入到一个空的 Python 脚本中：
- en: '![](../Images/Prompt-Icon.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/Prompt-Icon.png)'
- en: '[PRE3]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'It does an okay job, but not quite what we wanted, so we try again with an
    updated prompt:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 它做得还不错，但并不完全符合我们的期望，所以我们再次尝试，使用更新的提示：
- en: '![](../Images/Prompt-Icon.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/Prompt-Icon.png)'
- en: '[PRE4]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'As we are typing, the “for each NACHA record type and return a list of transactions”
    is automatically populated. We then enter an expanded comment:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们键入时，“对于每个 NACHA 记录类型并返回一个交易列表”会自动填充。然后我们输入一个扩展的注释：
- en: '![](../Images/Prompt-Icon.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/Prompt-Icon.png)'
- en: '[PRE5]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This prompt gives us the following output, with the full listing available in
    copilot_ach_parse_with_functions.py.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这个提示给出了以下输出，完整的列表可以在 copilot_ach_parse_with_functions.py 中找到。
- en: Listing 2.4  Copilot ACH parser
  id: totrans-90
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 2.4  Copilot ACH 解析器
- en: '[PRE6]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#1 Incorrectly calls a parse_ach_batch_header routine when this is the file
    header record'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 当这是文件头记录时，错误地调用了 parse_ach_batch_header 例程'
- en: '#2 The batch header record is being parsed incorrectly as a batch control record.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 批头记录被错误地解析为批控制记录。'
- en: '#3 The batch control record is listed incorrectly as file control.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 批控制记录被错误地列在文件控制中。'
- en: '#4 Missing an elif statement for file control records (type 9)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 缺少文件控制记录（类型 9）的 elif 语句'
- en: '#5 A ValueError is raised when we do not have a valid ACH record type.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 当我们没有有效的 ACH 记录类型时，会引发 ValueError。'
- en: 'We can see that it created a class and functions to parse individual record
    types. However, we also see multiple problems:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到它创建了一个类和函数来解析单个记录类型。然而，我们也看到了多个问题：
- en: Record type 1 is calling a parse routine for `parse_ach_batch_header`, whereas
    it should be parsed as a file header.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录类型 1 正在调用 `parse_ach_batch_header` 的解析例程，而它本应被解析为文件头。
- en: Record type 5 is calling a parse routine for `parse_ach_batch_control`, whereas
    it should have been parsed as a batch header.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录类型 5 正在调用 `parse_ach_batch_control` 的解析例程，而它本应被解析为批头。
- en: Record type 8 is calling a parse routine for `parse_ach_file_control`, whereas
    it should have been parsed as a batch control.
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录类型 8 正在调用 `parse_ach_file_control` 的解析例程，而它本应被解析为批控制。
- en: The file trailer record (record type 9) is missing.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件尾记录（记录类型 9）缺失。
- en: So, while this code also gives us another viable template, it does not necessarily
    produce something right out of the box to use. One helpful thing that it does
    provide is code to raise a `ValueError` with `invalid` `ACH` `record` `type`,
    so we would certainly run into an error right away when we try to load a test
    ACH file as the missing type 9 should cause an error on any well-formatted ACH
    file.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，虽然这段代码也给我们提供了一个可行的模板，但它并不一定会直接产生可以直接使用的成果。它提供的一个有用功能是代码，用于引发一个带有 `invalid`
    `ACH` `record` `type` 的 `ValueError`，因此当我们尝试加载一个缺少类型 9 的测试 ACH 文件时，任何格式良好的 ACH
    文件都会立即引发错误。
- en: '2.3.3 Generative AI: Trust but verify'
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.3 生成式 AI：信任但验证
- en: Certainly, both ChatGPT and Copilot are able to get us started with meaningful
    templates we can expand on later. However, they both have some problems generating
    the code, which highlights the importance of verification mentioned earlier. We
    must understand the produced code and not just take for granted that it is correct.
    This is especially important when we expect code to apply business rules and logic
    to the functions we want to generate. For instance, when using generative AI to
    assist in creating purely functional code—such as a button to submit a form or
    read a file—it will be immediately obvious if there is a syntax error or if it
    does not perform according to specifications, as it will not compile. However,
    if it is missing a record type or has some other problem, it could introduce bugs
    that are harder to find, especially if we don’t understand those business rules.
    We make this point multiple times only to drive home the importance of generative
    AI being a powerful tool but still only a tool. Think of the process of building
    a chair. We can build a chair with just a hand saw or we can have a shop full
    of the latest and greatest tools, but if we do not know how to use them, we will
    likely end up sitting on the floor.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，ChatGPT 和 Copilot 都能帮助我们开始使用有意义的模板，我们可以在以后进行扩展。然而，它们在生成代码时都存在一些问题，这突出了之前提到的验证的重要性。我们必须理解生成的代码，而不仅仅是假设它是正确的。这在我们期望代码将业务规则和逻辑应用到我们想要生成的函数时尤为重要。例如，当使用生成式
    AI 帮助创建纯功能代码时——例如提交表单或读取文件的按钮——如果存在语法错误或不符合规格，它将无法编译，这将立即变得明显。然而，如果缺少记录类型或存在其他问题，它可能会引入更难发现的错误，特别是如果我们不了解那些业务规则。我们多次强调这一点，只是为了强调生成式
    AI 是一个强大的工具，但仍然只是一个工具。想想制作椅子的过程。我们可以只用一把手锯来制作椅子，或者我们可以有一个装满最新最棒工具的工坊，但如果我们不知道如何使用它们，我们很可能会坐在地上。
- en: So, how do we go about verifying the code that generative AI produces for us?
    By using extreme programming (XP) development practices such as test-driven development
    (TDD). We previously mentioned the need for reliable high-quality software in
    FinTech.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何验证生成式 AI 为我们生成的代码呢？通过使用极限编程（XP）开发实践，如测试驱动开发（TDD）。我们之前提到了在金融科技中需要可靠的高质量软件。
- en: 'TDD boils down to the concept of writing tests before code by letting tests
    drive our development. One of the benefits is that we have highly testable code.
    We will use the TDD principles throughout this book and show various ways to automate
    our tests. Regardless of whether we decide to adopt a test-driven approach to
    our development practice, there are real benefits to thinking about how our code
    is tested. Questions such as the following are always considered when using a
    TDD approach:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: TDD（测试驱动开发）的核心概念是在编写代码之前先编写测试，让测试引导我们的开发。其中一个好处是我们拥有高度可测试的代码。在这本书中，我们将使用TDD原则，并展示各种自动化测试的方法。无论我们是否决定采用测试驱动的开发实践，思考我们的代码是如何被测试的都有实际的好处。在使用TDD方法时，以下问题总是会被考虑：
- en: Is this code that needs to be tested, or will we need to regression-test this
    code?
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这段代码是需要测试的吗，还是我们需要对这个代码进行回归测试？
- en: How do I test this code?
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我该如何测试这段代码？
- en: How will others understand this code?
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 别人会如何理解这段代码？
- en: The answers to these questions are usually found through unit tests, and when
    thinking about unit tests, we should be thinking about TDD.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题的答案通常通过单元测试来找到，当考虑单元测试时，我们应该考虑TDD。
- en: We can also make use of our Integrated Development Environment (IDE) and any
    available plugins it may come with. These tools may include customizable formatting
    options and default highlighting of syntax problems. As soon as our development
    team grows beyond just one person, there are real benefits to enforcing some standards
    in our code.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以利用我们的集成开发环境（IDE）及其可能附带的各种插件。这些工具可能包括可定制的格式化选项和默认的语法问题高亮显示。一旦我们的开发团队人数超过一个人，强制执行一些代码标准就具有实际的好处。
- en: Our company will likely provide us with the tools to use. These may help identify
    problems with generated code right away. Tools such as Snyk which can scan our
    code for vulnerabilities are discussed in chapter 3\. At the very least, we want
    to ensure that the code meets our company’s policies and standards.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的公司可能会提供给我们使用的一些工具。这些工具可以帮助我们立即识别生成的代码中的问题。例如，在第3章中讨论的Snyk这样的工具可以扫描我们的代码以查找漏洞。至少，我们希望确保代码符合我们公司的政策和标准。
- en: Reduce cognitive load with formatting and linters
  id: totrans-113
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 通过格式化和代码检查器减少认知负荷
- en: Cognitive load can be interpreted as the amount of information we need to keep
    in our brains while coding. There are many ways to reduce cognitive load within
    your code. Providing consistency within the code helps reduce cognitive load.
    It also helps with scanning tools, onboarding, and avoiding errors.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 认知负荷可以理解为我们在编码时需要在脑海中保持的信息量。有许多方法可以在代码中减少认知负荷。在代码中提供一致性有助于减少认知负荷。它还有助于扫描工具、入职培训和避免错误。
- en: Developers have enough to worry about even without the concerns regarding code
    formatting, comments, and similar. If we believe the number of spaces (or tabs)
    to indent a line would not get anyone riled up, we are in for a rude awakening.
    Seemingly trivial formatting decisions or coding practices may cause heated debates.
    Hopefully, many problems have been put to rest by the adoption of opinionated
    formatters, such as black when using Python and linters when using SonarLint.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 即使没有关于代码格式、注释和类似问题的担忧，开发者也有足够的事情要担心。如果我们认为缩进一行所需的空格（或制表符）数量不会引起任何人的不满，那么我们可能会得到一个令人震惊的教训。看似微不足道的格式化决策或编码实践可能会引起激烈的辩论。希望，通过采用有偏见的格式化工具，如使用Python时的black和在使用SonarLint时的代码检查器，许多问题已经得到了解决。
- en: We may find that legacy software in FinTech written in languages such as COBOL
    or RPG was constrained by line lengths of 80 or 132 characters and, in some flavors,
    required starting code in a specific column (specifically COBOL). Similar requirements
    are also present in RPG and other early languages. While modern languages have
    pretty much done away with those types of restrictions, developers quickly learned
    that maybe there was too much freedom. Today, many programming languages have
    various formatters that enforce some structure into our code, often forcing your
    code to adhere to a standard developed for the language. Whether it is Perl (perltidy),
    Go (gofmt), or JavaScript (Prettier), or Python (black), formatters are another
    tool we should investigate as soon as we start learning a new language.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能会发现，在金融科技领域用COBOL或RPG等语言编写的遗留软件受到80或132个字符行长的限制，在某些版本中，还需要在特定列（特别是COBOL）中开始代码。类似的限制也存在于RPG和其他早期语言中。虽然现代语言在很大程度上已经摆脱了这些类型的限制，但开发者很快意识到可能自由度太大。今天，许多编程语言都有各种格式化工具，这些工具强制我们的代码遵循为该语言开发的标准。无论是Perl（perltidy）、Go（gofmt）、JavaScript（Prettier）还是Python（black），格式化工具都是我们在开始学习新语言时应立即调查的工具。
- en: Linters play a similar role by ensuring our code stays clean and does not fall
    into common language pitfalls such as identifying unused imports, unused variables,
    invalid comparisons, and problematic casting, to name a few. SonarLint is a popular
    linter available for many languages and IDEs. It also provides integration into
    SonarQube, a product that helps identify and manage problems. Other linters are
    also available, such as ESLint when working with JavaScript or TypeScript.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Linters通过确保我们的代码保持清洁并避免常见的语言陷阱（例如识别未使用的导入、未使用的变量、无效的比较和有问题的类型转换等）来发挥类似的作用。SonarLint是一种流行的linters，适用于许多语言和IDE。它还提供了与SonarQube的集成，这是一个帮助识别和管理问题的产品。其他linters也可用，例如在处理JavaScript或TypeScript时使用的ESLint。
- en: Both formatters and linters can be built into your IDE or are available through
    plugins within the IDE. So, it is not a big inconvenience to start using them.
    However, ensure that you are using something approved by the team and that it
    is configured correctly. These tools can also be helpful in making you a better
    programmer overall, as they often tell us why this is the best practice and how
    to avoid it. We often find ourselves reading why SonarLint has flagged something
    or looking up additional examples or further information on best practices because
    the linters flagged something.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 格式化工具和linters可以集成到您的IDE中，或者通过IDE中的插件提供。因此，开始使用它们并不是一件麻烦事。然而，请确保您使用的是团队批准的工具，并且配置正确。这些工具还可以帮助我们成为更好的程序员，因为它们经常告诉我们为什么这是最佳实践以及如何避免它。我们经常发现自己正在阅读为什么SonarLint标记了某些内容，或者查找有关最佳实践的额外示例或更多信息，因为linters标记了某些内容。
- en: 2.4 Automated testing
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4 自动化测试
- en: Regardless of whether we are coding the initial script to parse the ACH file
    by hand or getting started with a generative AI tool, we want to ensure that we
    are using unit tests. We prefer a TDD approach and will often find that we favor
    it. However, we do not have to strictly subscribe to that approach to receive
    the benefits. We are looking for short development cycles, mixing testing and
    coding. We should have a pretty good idea at this point that parsing an ACH file
    properly is going to be somewhat complex task. However, reading a file and ensuring
    that we have all the lines is not an insurmountable task, and we should be able
    to achieve it easily enough. So, why not start with a unit test that ensures we
    received all the lines from the file?
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 无论我们是手动编写解析ACH文件的初始脚本，还是使用生成式AI工具开始，我们都希望确保我们正在使用单元测试。我们更喜欢TDD方法，并且经常会发现我们更倾向于这种方法。然而，我们不必严格遵循这种方法来获得好处。我们寻求的是短的开发周期，混合测试和编码。此时，我们应有相当好的想法，即正确解析ACH文件将是一项相当复杂的任务。然而，读取文件并确保我们拥有所有行并不是一个无法克服的任务，我们应该能够足够容易地完成它。那么，为什么不从确保我们从文件中收到了所有行的单元测试开始呢？
- en: A continuing theme is the need for high-quality software and verifying our results,
    especially in the context of generated code. This section explores the use of
    unit testing with `pytest` to help validate both generated code and the code we
    built ourselves. We also discuss the need for smaller and faster feedback cycles
    while coding, and we will try to apply that to our code here as well.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 一个持续的主题是需要高质量的软件和验证我们的结果，尤其是在生成代码的背景下。本节探讨了使用`pytest`进行单元测试以帮助验证生成的代码和我们自己编写的代码。我们还讨论了在编码时需要更小、更快的反馈循环的需求，并且我们将尝试在我们的代码中应用这一点。
- en: Even before we try to write tests for parsing individual fields from the record
    types, we may want to ask ourselves questions such as
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们尝试为从记录类型中解析单个字段编写测试之前，我们可能需要问自己一些问题，例如
- en: Can I read a file?
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我能读取文件吗？
- en: How many records are in the file?
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件中有多少条记录？
- en: Can I parse a record of type 1? How about a record of type 5?
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我能解析类型1的记录吗？类型5的呢？
- en: We start small with the initial steps and then go deeper into the actual functionality
    of our code. In the following sections, we will start with a well-formatted sample
    file and work our way through it by creating tests. Each section will illustrate
    the creation of a small unit test to validate our well-formatted file.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从初始步骤开始，然后深入到我们代码的实际功能。在接下来的章节中，我们将从一个格式良好的示例文件开始，通过创建测试来逐步处理它。每个部分都将展示如何创建一个小型单元测试来验证我们的格式良好的文件。
- en: 2.4.1 Testing the number of records read
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4.1 测试读取的记录数量
- en: We will test the number of records read from our ACH file before we start addressing
    any problems that we may have noticed in our generated code. This testing covers
    the first two bullet points we listed at the beginning of this section. Verifying
    the number of records may seem trivial, but it helps put us in the mindset of
    testing our code and helps verify that we are indeed accomplishing this critical
    task. Our unit test needs to verify the number of records from the file. We can
    get the record out by opening the file in most editors, or we can employ a command
    line to get the number of lines by using `wc` `-l` in Unix or a `Get-Content`
    and `Measure-Object` in PowerShell. If we are unsure how to get the number of
    lines from a file, we may want to ask generative AI if it has any ideas and maybe
    even learn a new trick or two!
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始解决可能在我们生成的代码中注意到的任何问题之前，我们将测试从我们的ACH文件中读取的记录数量。这项测试涵盖了我们在本节开头列出的前两个要点。验证记录数量可能看似微不足道，但它有助于我们进入测试代码的心态，并帮助我们验证我们确实完成了这项关键任务。我们的单元测试需要验证文件中的记录数量。我们可以通过在大多数编辑器中打开文件来获取记录，或者我们可以使用Unix中的`wc
    -l`或PowerShell中的`Get-Content`和`Measure-Object`来获取行数。如果我们不确定如何从文件中获取行数，我们可能想询问生成式AI是否有任何想法，也许还能学到一两个新技巧！
- en: Depending on how we got here, our test may be failing because of one of those
    missing record types or because of some other error such as an incorrect file
    path, permissions, or any number of other reasons. Now, as an exercise, it would
    be good to work on getting this first test up and running before we continue with
    the code. Otherwise, we can just continue by using the sample code provided on
    GitHub.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们到达这里的方式，我们的测试可能因为缺少某种记录类型或其他错误（如错误的文件路径、权限等）而失败。现在，作为一个练习，在我们继续编写代码之前，最好先确保这个第一个测试能够正常运行。否则，我们也可以继续使用GitHub上提供的示例代码。
- en: 2.4.2 Parsing the records
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4.2 解析记录
- en: 'You can find information about the ACH layout at [https://achdevguide.nacha.org/ach-file-overview](https://achdevguide.nacha.org/ach-file-overview).
    Let’s recall some of the main aspects of the file format:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://achdevguide.nacha.org/ach-file-overview](https://achdevguide.nacha.org/ach-file-overview)找到有关ACH布局的信息。让我们回顾一下文件格式的一些主要方面：
- en: It is a fixed-width ASCII file.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是一个固定宽度的ASCII文件。
- en: Records are 94 characters in length.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录长度为94个字符。
- en: Each line is known as a record.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每一行都被称为一条记录。
- en: Each record contains fields that are at fixed positions.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每条记录包含位于固定位置的字段。
- en: Order of records and fields matters.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录和字段的顺序很重要。
- en: This format makes processing and validating files more interesting. We do not
    have an XML Schema Definition that we can utilize. Nor do we have the freedom
    of formatting that XML and JSON provide.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这种格式使得处理和验证文件更有趣。我们没有可以利用的XML Schema Definition。我们也没有像XML和JSON那样提供格式化的自由。
- en: Although it has constraints compared to other file formats, it was in use before
    the other formats were born. It would be an interesting challenge for us to ensure
    we process the file correctly and handle some of the tasks in daily ACH processing.
    We create a new Python project in our IDE and use the response from ChatGPT 4
    as our starting point.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然与其他文件格式相比有约束，但它是在其他格式出现之前就已经在使用了。对我们来说，确保正确处理文件并处理日常 ACH 处理中的某些任务将是一个有趣的挑战。我们在
    IDE 中创建一个新的 Python 项目，并使用 ChatGPT 4 的响应作为起点。
- en: Listing 2.5  Starting point for our ACH parser
  id: totrans-139
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 2.5  ACH 解析器的起点
- en: '[PRE7]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We created a basic folder structure for the project consisting of
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为项目创建了一个基本的文件夹结构，包括
- en: '`ach_processor`—Where our Python module lives'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ach_processor`—我们的 Python 模块所在之处'
- en: '`docs`—Where any necessary documentation lives'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`docs`—存放任何必要文档的地方'
- en: '`tests`—Where our unit tests live'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tests`—存放我们的单元测试的地方'
- en: '`venv`—Our virtual environment (to keep our project and dependencies separated)'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`venv`—我们的虚拟环境（用于将项目及其依赖项分离）'
- en: '`README.md`—A markdown document to get into more details about the project
    and structure'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`README.md`—一个 Markdown 文档，可以了解更多关于项目和结构的信息'
- en: '`requirements.txt`—A list of required Python dependencies that can be used
    by a CI/CD pipeline to build the project'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`requirements.txt`—一个 Python 依赖项列表，CI/CD 管道可以使用它来构建项目'
- en: Listing 2.6  Project folder structure
  id: totrans-148
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 2.6  项目文件夹结构
- en: '[PRE8]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: After setting up the project, we run the `black` command to format the source
    code. With PyCharm, the IDE was smart enough to see the package installed and
    prompted us to set up Black from within the IDE since `black` was supported out
    of the box.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置好项目后，我们运行 `black` 命令来格式化源代码。使用 PyCharm 时，IDE 足够智能，能够看到已安装的包，并提示我们在 IDE 内设置
    Black，因为 `black` 是开箱即用的。
- en: With that accomplished, we can begin working on parsing the ACH records. At
    this point, with our exploratory spike, we are only looking to simply parse the
    records. Input validation is an important aspect of processing any type of data
    as it is defensive coding.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 完成这些后，我们可以开始处理 ACH 记录。在这个阶段，通过我们的探索性峰值，我们只是简单地解析记录。输入验证是处理任何类型数据的重要方面，因为它属于防御性编程。
- en: Defensive coding
  id: totrans-152
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 防御性编程
- en: Defensive coding is a proactive approach to dealing with unanticipated input,
    errors, and general misuse that occur when users get their hands on your software.
    For instance, if you ask your user to enter a number between 1 and 5, they are
    likely to enter anything but the numbers 1, 2, 3, 4, or 5\. You can expect them
    to enter a, b, %, 1231482, nonprintable characters, and a wide range of other
    inputs!
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 防御性编程是一种积极主动的方法，用于处理用户在使用你的软件时可能出现的未预料到的输入、错误和一般性误用。例如，如果你要求用户输入一个介于 1 和 5 之间的数字，他们很可能会输入除了
    1、2、3、4 或 5 之外的任何数字。你可以预料到他们会输入 a、b、%、1231482、不可打印字符以及广泛的其它输入！
- en: The practices of input validation, error handling, fail-safe defaults, output
    sanitization, logging/monitoring, and static analysis are some aspects of defensive
    coding. As we move on with the project, we will keep these principles in mind.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 输入验证、错误处理、安全默认值、输出清理、日志/监控以及静态分析等实践是防御性编程的一些方面。随着项目的进行，我们将牢记这些原则。
- en: 2.4.3 File header record (type 1)
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4.3 文件头记录（类型 1）
- en: A file header record contains important information about the institution the
    file came from and what it is destined for. Some file details, such as creation
    date and time, can also help determine whether the file has been loaded before,
    although we will rely on hashing the contents of the file as well.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 文件头记录包含有关文件来源机构和目的的重要信息。一些文件细节，如创建日期和时间，也可以帮助确定文件是否已被加载过，尽管我们还将依赖于对文件内容的哈希处理。
- en: A powerful feature of ChatGPT is the ability to remember conversations; if we
    are signed into ChatGPT, we can go in and ask it to expand the parsing of the
    `parse_file_header` routine. This will give us another good starting point, and
    then we can even go in and ask it to create a unit test for the header record
    as well.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 'ChatGPT 的一个强大功能是能够记住对话；如果我们登录了 ChatGPT，我们可以进去要求它扩展 `parse_file_header` 例程的解析。这将给我们另一个良好的起点，然后我们甚至可以进去要求它为头记录创建单元测试。 '
- en: However, when we tried this approach, we ran into a few problems such as the
    file creation date being eight positions instead of six (it used a four-digit
    year). The record itself was not 94 bytes long, which also gave an error during
    parsing. We used the sample.ach file and that header record as an expected result
    and then ran the `pytest` against that.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，当我们尝试这种方法时，我们遇到了一些问题，例如文件创建日期是八位而不是六位（它使用了四位年份）。记录本身不是94字节长，这也导致了解析错误。我们使用了sample.ach文件和该头记录作为期望结果，然后针对该结果运行了`pytest`。
- en: Let’s look at the unit test and break it down (listing 2.7). We start by defining
    the function name, and by convention, the name begins with `test_`, which helps
    identify the function as something for `pytest` to pick up and run.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看单元测试并将其分解（列表2.7）。我们首先定义函数名，按照惯例，名称以`test_`开头，这有助于识别该函数是`pytest`要拾取并运行的。
- en: Next, we have our sample line that is going to be passed to the parse routine.
    We also use `expected_result`, which is defined as a dictionary. We could also
    embed this directly into our `assert` statement, but for clarity, it is often
    easier to break it. By using a dictionary, we also employ our IDE. For instance,
    PyCharm provides a nice comparison window if this test fails, where we can see
    where the difference is. We then define the parser and call the routine with our
    `sample_header`.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们有将要传递给解析例程的样本行。我们也使用`expected_result`，它被定义为一个字典。我们也可以直接将其嵌入到`assert`语句中，但为了清晰起见，通常更容易将其分开。通过使用字典，我们也利用了我们的集成开发环境（IDE）。例如，如果这个测试失败，PyCharm提供了一个很好的比较窗口，我们可以看到差异在哪里。然后我们定义解析器，并使用我们的`sample_header`调用例程。
- en: Finally, we have an `assert`, which is where the actual check is done. If the
    result is not the same as the `expected_result`, we will see the error message.
    We can include as many `assert` statements as necessary. For instance, we may
    assert the response of an HTTP call was successful prior to checking fields that
    we expected to be returned.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有一个`assert`语句，这是实际检查发生的地方。如果结果与`expected_result`不同，我们将看到错误信息。我们可以包含尽可能多的`assert`语句。例如，我们可能需要在检查我们期望返回的字段之前，断言HTTP调用的响应是成功的。
- en: The subsequent parsing of other records will also follow this code pattern,
    so whether we code it by hand, copy/paste, or use generative AI, we should be
    able to come up with similar tests for the other record formats.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 对其他记录的后续解析也将遵循此代码模式，因此无论我们手动编写、复制粘贴还是使用生成式AI，我们都应该能够为其他记录格式生成类似的测试。
- en: Listing 2.7  `pytest` for parsing a file header record
  id: totrans-163
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.7  `pytest`解析文件头记录
- en: '[PRE9]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '#1 Defines a record that we want to test the parser against'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 定义了一个我们想要测试解析器的记录'
- en: '#2 Defines a dictionary that contains the parsed fields'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 定义了一个包含解析字段的字典'
- en: '#3 Creates an instance of our AchFileProcessor class'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 创建了我们的AchFileProcessor类的实例'
- en: '#4 Calls the function to parse the file header and return a result. This method
    is meant to be private, but for ease of testing, we are accessing it directly.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 调用函数来解析文件头并返回结果。这个方法原本是私有的，但为了便于测试，我们直接访问它。'
- en: '#5 Compares the returned result to the expected result; this causes pytest
    to throw an error if they do not match.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 将返回的结果与期望的结果进行比较；如果不匹配，pytest将抛出错误。'
- en: We could certainly have told ChatGPT to create unit tests for us as well. As
    mentioned earlier, we are looking to “trust but verify” when it comes to using
    these tools. It may be possible to generate both the code and the tests, but given
    that we are also trying to understand ACH better, that may be counterproductive.
    For instance, if the tool generated a bad function for us to parse the file, it
    may also be likely to generate incorrect unit tests. We may end up with unit tests
    that appear to pass and validate the code only to find they are both wrong. When
    generating the code, we can understand it better by writing the unit tests ourselves
    (or generate the unit tests and write the code).
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 我们当然可以告诉ChatGPT为我们创建单元测试。如前所述，当我们使用这些工具时，我们寻求“信任但验证”。可能可以同时生成代码和测试，但鉴于我们还在努力更好地理解ACH，这可能适得其反。例如，如果工具为我们生成了一个解析文件的糟糕函数，它也可能生成错误的单元测试。我们可能会得到看似通过并验证代码的单元测试，但最终发现它们都是错误的。在生成代码时，通过自己编写单元测试（或生成单元测试并编写代码），我们可以更好地理解它。
- en: Still, there are benefits to seeing what may be generated when asking for unit
    tests. We prompt ChatGPT with
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，查看在请求单元测试时可能生成的内容是有好处的。我们向ChatGPT提示
- en: '**![image](../Images/Prompt-Icon.png)** Given the python function below to
    parse a Nacha ACH File Header, please provide unit tests for it.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '**![图片](../Images/Prompt-Icon.png)** 给定以下 Python 函数来解析 Nacha ACH 文件头部，请为此提供单元测试。'
- en: We are presented with the following.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们看到了以下内容。
- en: Listing 2.8  ChatGPT generated `pytests`
  id: totrans-174
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 2.8  ChatGPT 生成的 `pytests`
- en: '[PRE10]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#1 pytest.raises can be used to validate that specific errors are thrown, which
    is great for testing edge cases and exception conditions.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 可以使用 `pytest.raises` 来验证是否抛出了特定的错误，这对于测试边缘情况和异常条件非常有用。'
- en: '#2 Extra white space caused invalid values to be used—most obvious was the
    record_size switching from 094 to “A 0”.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 额外的空白导致了无效值的使用——最明显的是记录大小从 094 切换到“A 0”。'
- en: We can see that these unit tests cover incorrect lengths of lines, invalid type,
    and extra whitespace. The invalid type and incorrect length lines may be useful
    tests, but we are unsure what happened with the extra whitespace test. It looks
    as if it was meant to add trailing space, but it also added spaces within the
    record itself. Since this is a fixed-length record, this will obviously lead to
    validation errors later. Still, it did provide us with some direction for additional
    tests when we get to that point. In addition, we saw how we may validate expected
    errors using the `pytest.raises` syntax.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到这些单元测试涵盖了行长度不正确、无效类型和额外的空白。无效类型和不正确的长度行可能是有用的测试，但我们不确定额外空白测试发生了什么。看起来它是想添加尾随空格，但它也在记录本身中添加了空格。由于这是一个固定长度的记录，这显然会导致后续的验证错误。尽管如此，它确实为我们提供了在达到那个点时进行额外测试的一些方向。此外，我们还看到了如何使用
    `pytest.raises` 语法来验证预期错误。
- en: Of course, right now, we are following the happy path, not trying to focus too
    much on the input validation. We simply want to see whether we can get an ACH
    file parsed at this stage.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，目前我们正遵循快乐路径，不是过多关注输入验证。我们只想看看我们是否能在这一阶段解析 ACH 文件。
- en: 2.4.4 Batch header record (type 5)
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4.4 批次头部记录（类型 5）
- en: As the name implies, batch header records indicate the start of a batch for
    a particular company. There can be multiple batches per file and all the entry
    and addenda records that are contained within the batch belong to that company.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 正如其名所示，批次头部记录表示特定公司的批次开始。每个文件可以有多个批次，并且批次中包含的所有条目和附加记录都属于该公司。
- en: 'For the parsing of the batch header record, we can return to the IDE and let
    Copilot get us started, and then also ask it to help us define a `pytest` as well.
    We use the following prompt:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 对于批次头部记录的解析，我们可以回到 IDE，让 Copilot 帮助我们开始，然后也可以要求它帮助我们定义一个 `pytest`。我们使用的提示如下：
- en: '**![image](../Images/Prompt-Icon.png)** # Define a test function to test parsing
    an ACH batch header record using `AchFileProcessor._parse_batch_header()`.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '**![图片](../Images/Prompt-Icon.png)** # 定义一个测试函数以测试使用 `AchFileProcessor._parse_batch_header()`
    解析 ACH 批次头部记录。'
- en: We can review that in `test_parsing_file_header.py`.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在 `test_parsing_file_header.py` 中查看这一点。
- en: While the initial function to parse the batch header looks reasonable, the `pytest`
    itself needs more work in terms of the `sample_batch_header` that gets passed
    to the _`parse_batch_header`. The line is 181 characters long, which is more than
    the fixed 94 bytes required by the format. It looks as if the name of each field
    was put into the position of the test record. Also, on further inspection, we
    find that it does not include all the fields in the record format. However, when
    we began typing the name of the field, we were impressed to see the field was
    populated and used the data from the sample, although with mixed results.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然解析批次头部的初始函数看起来合理，但 `pytest` 本身需要更多的工作，特别是在将 `sample_batch_header` 传递给 `_parse_batch_header`
    时。这一行有 181 个字符，超过了格式要求的固定 94 字节。看起来每个字段的名称都被放入了测试记录的位置。另外，经过进一步检查，我们发现它并没有包含记录格式中的所有字段。然而，当我们开始输入字段名称时，我们惊讶地看到字段被填充并使用了样本数据，尽管结果参差不齐。
- en: Still, it is a very impressive result and more than enough to get us started
    and complete a passing test using the sample.ach file we have been working with.
    After working on the parsing routine and the expected result, we were able to
    pass another test.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，这仍然是一个非常令人印象深刻的结果，足以让我们开始并使用我们一直在使用的 sample.ach 文件完成一个通过测试。在处理解析例程和预期结果后，我们能够通过另一个测试。
- en: Hopefully, you were able to parse this record and add a unit test on your own.
    If not, no worries—there are still more types ahead and plenty of chances to give
    it a try! Even though it might be jumping the gun, we also want to look at behavior-driven
    development (BDD) and show a few sample tests that could be used if we were looking
    into that type of approach.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 希望您能够自己解析这个记录并添加单元测试。如果不能，不要担心——还有更多类型等待尝试，有很多机会去尝试！尽管这可能有些过早，但我们还想看看行为驱动开发（BDD），并展示一些如果我们在考虑这种类型方法时可能会用到的示例测试。
- en: What is behavior-driven development?
  id: totrans-188
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 什么是行为驱动开发？
- en: Behavior-driven development is an approach to developing software where we create
    tests around the behavior of the software, and then use them as part of the acceptance
    criteria for determining whether a project is complete. What makes this type of
    testing unique is that all stakeholders work closely together to develop these
    scenarios. Formalizing these user requirements helps ensure that we build a project
    that meets users’ expectations.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 行为驱动开发是一种软件开发方法，我们围绕软件的行为创建测试，然后将其用作确定项目是否完成的验收标准的一部分。这种类型测试的独特之处在于，所有利益相关者都紧密合作来开发这些场景。将这些用户需求正式化有助于确保我们构建的项目符合用户的期望。
- en: Each BDD test is described by a series of `given`/`when`/`then` statements that
    directly relate to desired functionality. We can run these tests from our IDE
    just like we did with our unit tests. The difference is just in the approach to
    designing the tests and the level at which they execute.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 每个BDD测试都通过一系列`given`/`when`/`then`语句来描述，这些语句直接关联到期望的功能。我们可以像对待单元测试一样，从我们的IDE中运行这些测试。区别仅在于测试的设计方法和执行级别。
- en: As we progress through the project, we will look to expand our BDD testing;
    for now, we create a very simple test that confirms we have successfully parsed
    the record type field. While we have a unit test that confirms this already, it
    will make for a simple introduction to setting up a BDD-style test.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们项目的进展，我们将寻求扩展我们的BDD测试；目前，我们创建一个非常简单的测试来确认我们已经成功解析了记录类型字段。虽然我们已经有了一个确认这一点的单元测试，但这将是一个简单介绍如何设置BDD风格测试的好方法。
- en: We first define a feature file, which identifies the feature that we are testing
    along with various test scenarios. The feature file is written in a human-readable
    language so that anyone can make sense of it. The `batch_header.feature` is included
    in the code and shown in the next listing.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先定义一个功能文件，它标识了我们正在测试的功能以及各种测试场景。功能文件是用一种可读的语言编写的，以便任何人都能理解它。《batch_header.feature》包含在代码中，将在下一个列表中展示。
- en: Listing 2.9  Parsing an ACH batch header
  id: totrans-193
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.9  解析ACH批次头
- en: '[PRE11]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We define the feature and then a simple scenario of “We have a record type 5.”
    The scenario can be named anything, but obviously, we want to convey what this
    test is going to do. The `when` and `then` statements are where the real work
    happens—in our example, *when* we are parsing the header record, and *then* we
    want to ensure we have a record type of 5.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义了功能，然后是一个简单的场景：“我们有一个记录类型5。”场景可以命名为任何名称，但显然，我们希望传达这个测试将要做什么。`when`和`then`语句是实际工作发生的地方——在我们的例子中，*当*我们在解析头记录时，*然后*我们想要确保我们有一个类型为5的记录。
- en: Once we have that information, our next step is to wire the feature file together
    with what are known as *step definitions*. This is how we translate the human-readable
    text into something that we can execute with `pytest`. For brevity, we will show
    a sample of the “then” step definition. The rest of the code is available in `test_batch_header.py`
    for you to browse.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了这些信息，下一步就是将功能文件与所谓的*步骤定义*连接起来。这就是我们将可读文本转换为可以用`pytest`执行的方法。为了简洁，我们将展示“then”步骤定义的一个示例。其余的代码在`test_batch_header.py`中可供您浏览。
- en: Listing 2.10  Behavior-driven development testing in Python
  id: totrans-197
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.10  Python中的行为驱动开发测试
- en: '[PRE12]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We decorate the function with `@then` and parse the text string. Within that
    string, we have `{type_5}`. This is a dynamic value that will be pulled in from
    the feature file. So, while we used “the record type should be 5,” the 5 becomes
    a parameter to the function, and we could easily create other scenarios where
    we test other values. We then define the function, passing it the value we parse,
    a record (which is a Python fixture—more on that later), and an `assert` statement
    that we have seen before. This can then be run along with any other test, and
    we are done coding when this test passes. Of course, we already coded this, but
    in later chapters, we will work to define these scenarios beforehand, when we
    work on features. We could potentially come up with additional scenarios for each
    field or simply expand the “then” portion of our test to include multiple `then`
    statements for each field.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 `@then` 装饰器来装饰函数并解析文本字符串。在这个字符串中，我们有 `{type_5}`。这是一个动态值，将从特征文件中提取。因此，虽然我们使用了“记录类型应该是5”，但5成为函数的参数，我们可以轻松地创建其他场景来测试其他值。然后我们定义函数，传递给它我们解析的值、一个记录（这是一个Python
    fixture——稍后会更详细地介绍）以及一个我们之前见过的 `assert` 语句。然后这个测试可以与其他任何测试一起运行，当这个测试通过时，我们就完成了编码。当然，我们之前已经编写了这段代码，但在后面的章节中，我们将努力在处理功能之前定义这些场景。我们可能为每个字段提出额外的场景，或者简单地扩展测试中的“then”部分，为每个字段包含多个
    `then` 语句。
- en: 2.5 Entry detail record (type 6)
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.5 条目详细记录（类型 6）
- en: The entry detail records contain individual transaction data, including the
    account number and amount to credit or debit the account. Keep in mind that the
    parsing of the records can vary slightly, based on the type of records being processed.
    The batch header record contains the type of entry records present in the batch,
    and this is known as the standard entry class (SEC) code.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 条目详细记录包含单个交易数据，包括账户号码和需要贷记或借记账户的金额。请注意，根据正在处理的记录类型，记录的解析可能会有所不同。批次标题记录包含批次中存在的条目记录类型，这被称为标准条目类（SEC）代码。
- en: The parsing of an entry detail record proved more challenging for ChatGPT and
    in our formulation of the prompts for it. Initially, we tried the expanded prompt
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 解析条目详细记录对ChatGPT来说更具挑战性，并且在我们为其制定的提示中也是如此。最初，我们尝试了扩展提示
- en: '**![image](../Images/Prompt-Icon.png)** Fully define the _`parse_entry_detail`
    method and provide a `pytest` to validate it.'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '**![image](../Images/Prompt-Icon.png)** 完全定义 `_`parse_entry_detail` 方法并提供一个
    `pytest` 来验证它。'
- en: While ChatpGPT did provide a method and `pytest`, it failed to meaningfully
    parse the record. We tried again with
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然ChatpGPT提供了方法和 `pytest`，但它未能有意义地解析记录。我们再次尝试
- en: '**![image](../Images/Prompt-Icon.png)** Please the full layout for the NACHA
    Type 6 record.'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '**![image](../Images/Prompt-Icon.png)** 请使用NACHA类型6记录的完整布局。'
- en: Then ChatGPT started calling the type 6 record an addenda record and parsing
    it with the fields associated with that record. We realized that there are different
    types of entry details records (CCD, CTX, PPD, etc.), so we tried to redirect
    with
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，ChatGPT开始将类型6记录称为附加记录，并使用与该记录相关的字段来解析它。我们意识到存在不同类型的条目详细记录（CCD、CTX、PPD等），因此我们尝试通过
- en: '**![image](../Images/Prompt-Icon.png)** Please use the full layout for the
    NACHA Type 6 CCD record.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '**![image](../Images/Prompt-Icon.png)** 请使用NACHA类型6 CCD记录的完整布局。'
- en: While the system correctly identified the type as a cash concentration disbursement,
    it still referred to the entry as an addenda record.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然系统正确地将类型识别为现金集中支付，但它仍然将条目称为附加记录。
- en: Using Copilot produced better results, populating the correct field names as
    we typed and allowing us to quickly create a template that took just a little
    updating to make the test pass. However, the underlying theme we have seen so
    far is that while both tools are powerful, they need us to validate the results
    and not plug them in blindly. Thus, we can see that knowing the domain is important
    if we want to be able to validate our results.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Copilot产生了更好的结果，我们在键入时填充了正确的字段名称，并允许我们快速创建一个只需要稍作更新即可通过测试的模板。然而，到目前为止，我们看到的潜在主题是，虽然这两个工具都很强大，但它们需要我们验证结果，而不是盲目地插入。因此，我们可以看到，如果我们想能够验证我们的结果，了解领域知识是很重要的。
- en: 2.5.1 Addenda record (type 7)
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.5.1 附加记录（类型 7）
- en: The addenda record contains additional payment-related information that applies
    to the entry detail record. There may be multiple addenda records per entry detail
    record.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 附加记录包含适用于条目详细记录的额外付款相关信息。每个条目详细记录可能有多个附加记录。
- en: When Copilot was prompted with
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 当Copilot被提示时
- en: '**![image](../Images/Prompt-Icon.png)** Define a function to parse a Nacha
    Addenda Record.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '**![图片](../Images/Prompt-Icon.png)** 定义一个函数来解析Nacha附加记录。'
- en: it produced several code suggestions. The following listing shows the closest
    valid suggestion. It uses all the required fields, but the offsets are not quite
    right.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 它产生了几个代码建议。下面的列表显示了最接近的有效建议。它使用了所有必需的字段，但偏移量并不完全正确。
- en: Listing 2.11  Parsing function for an addenda record
  id: totrans-215
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.11  附加记录解析函数
- en: '[PRE13]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: In addition to the general parsing being incorrect, we would prefer to use snake
    case for the dictionary keys. We can try refining the prompt again by defining
    a function to parse a Nacha addenda record using a dictionary and snake case for
    the keys. This provides the keys with the formatting we prefer, but we still need
    to update the offsets.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 除了一般的解析不正确外，我们更愿意使用蛇形命名法作为字典键。我们可以通过定义一个函数来再次细化提示，该函数使用字典和蛇形命名法解析Nacha附加记录。这为我们提供了我们偏好的键格式，但我们仍然需要更新偏移量。
- en: Listing 2.12  Parsing function for an addenda record using the snake case
  id: totrans-218
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.12  使用蛇形命名法的附加记录解析函数
- en: '[PRE14]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: To get the correct parsing, we need to adjust `type_code`, `payment_related_information`,
    and `addenda_sequence_number`. The following listing shows the updated return
    statement that could be used.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 为了得到正确的解析，我们需要调整`type_code`、`payment_related_information`和`addenda_sequence_number`。下面的列表显示了可以使用的更新后的返回语句。
- en: Listing 2.13  Updated return statement with corrected fields
  id: totrans-221
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.13  更新后的返回语句，包含已修正的字段
- en: '[PRE15]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 2.5.2 Batch control record (type 8)
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.5.2 批次控制记录（类型8）
- en: The batch control record is the trailer record for each batch and is a required
    record. We use fields from the record, such as total debit/credit amount and the
    record count, to validate that we received the correct batch contents. The following
    listing shows that Copilot took a different approach to parsing this record.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 批次控制记录是每个批次的尾记录，是一个必需的记录。我们使用记录中的字段，如总借记/贷记金额和记录计数，来验证我们是否收到了正确的批次内容。下面的列表显示了Copilot在解析此记录时采取了不同的方法。
- en: Listing 2.14  Copilot parsing a batch control record
  id: totrans-225
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.14  Copilot解析批次控制记录
- en: '[PRE16]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This code looks a bit of overengineered because the nature of this widely used
    fixed-position file format means that the field positions will not be changing.
    As a matter of personal preference, we like to see the actual offsets being used,
    as shown listing 2.12\. The offsets will also make our job easier when dealing
    with errors in parsing a record. Having the field as `'entry_detail_sequence_number':`
    `record[87:94]` means we know where the field `entry_detail_sequence_number` begins
    and ends. We are also willing to allow these magic numbers to exist in the code
    because they are limited to this specific area and not sprinkled throughout the
    code. Of course, we could also create variables named `BEGIN_ENTRY_DETAIL_SEQUENCE_NUMBER_POS`
    and `END_ENTRY_DETAIL_SEQUENCE_NUMBER_POS` and use them if we find a compelling
    reason. Now, let us take a look at parsing the file trailer record.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '这段代码看起来有点过度设计，因为这种广泛使用的固定位置文件格式的本质意味着字段位置不会发生变化。就个人喜好而言，我们更喜欢看到实际使用的偏移量，如列表2.12所示。偏移量也会使我们在处理解析记录中的错误时工作更轻松。将字段定义为`''entry_detail_sequence_number'':
    ` `record[87:94]`意味着我们知道字段`entry_detail_sequence_number`的开始和结束位置。我们也愿意让这些魔法数字存在于代码中，因为它们仅限于这个特定区域，而不是散布在整个代码中。当然，我们也可以创建名为`BEGIN_ENTRY_DETAIL_SEQUENCE_NUMBER_POS`和`END_ENTRY_DETAIL_SEQUENCE_NUMBER_POS`的变量，并在找到令人信服的理由时使用它们。现在，让我们来看看解析文件尾记录。'
- en: 2.5.3 File trailer record (type 9)
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.5.3 文件尾记录（类型9）
- en: The final record in an ACH file is the file trailer record (also known as a
    file control record). The file trailer record provides fields such as batch count
    and entry/addenda count we use to validate the file was received correctly. Note
    that the format required the number of records to be a multiple of 10\. So, you
    may find files or software that will pad created ACH files out with records that
    consist of all 9s. However, most software does not require this to be done anymore.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在ACH文件中的最后一个记录是文件尾记录（也称为文件控制记录）。文件尾记录提供了诸如批次计数和条目/附加条目计数等字段，我们使用这些字段来验证文件是否正确接收。请注意，所需的格式要求记录数必须是10的倍数。因此，你可能会发现文件或软件会使用全部为9的记录来填充创建的ACH文件。然而，大多数软件现在不再需要这样做。
- en: In the following listing, we are back to Copilot parsing the records as we would
    expect. The fields were all cast integers.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的列表中，我们又回到了Copilot按照我们预期的样子解析记录。所有字段都被转换为整数。
- en: Listing 2.15  Parsing the file trailer record
  id: totrans-231
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.15  解析文件尾记录
- en: '[PRE17]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: While this code parses the records correctly, we are missing the last field,
    which is marked as reserved. So, while it may not be necessary at this time, we
    may still want to consider including it just for the sake of completeness.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这段代码正确地解析了记录，但我们缺少最后一个字段，该字段被标记为保留。因此，尽管现在可能并不必要，但我们仍然可能想要考虑为了完整性而包括它。
- en: We may also want to create a sample BDD test because, conceivably, subject matter
    experts (SMEs) may provide us with specific use cases for parsing this record
    (or any of these records). A BDD style test may look like the following listing.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可能想要创建一个示例BDD测试，因为，理论上，主题专家（SMEs）可能会为我们提供解析此记录（或任何这些记录）的特定用例。BDD风格的测试可能看起来像以下列表。
- en: Listing 2.16  BDD style test for type 9—file trailer record
  id: totrans-235
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.16  类型9的BDD风格测试——文件尾记录
- en: '[PRE18]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 2.5.4 Passed!
  id: totrans-237
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.5.4 通过了！
- en: Wow, we made it! That was a whirlwind of coding and testing. Even with generative
    AI helping out, that was a lot to take in. Let us now recap what we have just
    accomplished. We started using small development cycles to build unit tests to
    validate the parsing of the various ACH record types. It is important to understand
    that we started by breaking the program created by generative AI into functions
    (we had asked ChatGPT to do this for us before we started). Having generative
    AI create functions allowed us to create unit tests more easily for each record
    type. Otherwise, we would have had to figure out a way to determine if the records
    were parsed correctly and check them after the file was loaded.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 哇，我们做到了！那是一阵编码和测试的狂潮。即使有生成式AI的帮助，这也需要很多吸收。现在让我们回顾一下我们刚刚完成的事情。我们开始使用小开发周期来构建单元测试，以验证各种ACH记录类型的解析。重要的是要理解，我们是将生成式AI创建的程序分解成函数开始的（在我们开始之前，我们要求ChatGPT为我们做这件事）。让生成式AI创建函数使我们能够更容易地为每种记录类型创建单元测试。否则，我们就必须想出一种方法来确定记录是否被正确解析，并在文件加载后进行检查。
- en: Each time, we started by creating a unit test that should fail and then coded
    just enough to make it pass. At this point, we should be relatively familiar with
    the process and ready to apply the same concept to other parts of our project.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 每次我们都是从创建一个应该失败的单元测试开始，然后编写足够的代码使其通过。在这个时候，我们应该相对熟悉这个过程，并准备好将其应用到项目的其他部分。
- en: 2.6 The not-so-happy path
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.6 不太愉快的路径
- en: Congratulations! We just finished parsing what is very likely our first ACH
    file. We concentrated on what is sometimes referred to as “the happy path.” This
    is where everything goes as expected, without throwing any kind of errors. We
    used a single well-formatted ACH file throughout our parsing to illustrate the
    process.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！我们刚刚解析了我们很可能的第一个ACH文件。我们专注于有时被称为“愉快的路径”的部分。这是所有事情都按预期进行，没有抛出任何错误的地方。我们在整个解析过程中使用了一个格式良好的单个ACH文件来展示这个过程。
- en: We should now also consider the not-so-happy path, which is probably what we
    are more likely to encounter in our day-to-day coding. Our not-so-happy path will
    cover some of the problems that can occur when loading a file. There are scenarios
    where the file or a batch may be rejected or where an entry can trigger a rejection.
    We will examine exceptions and handling/recovering from problems with ACH files
    further in chapter 9\. For now, we just want to touch on some of the possibilities.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在也应该考虑不太愉快的路径，这可能是我们在日常编码中更有可能遇到的。我们的不太愉快的路径将涵盖在加载文件时可能发生的一些问题。存在文件或批次可能被拒绝或条目可能触发拒绝的场景。我们将在第9章中进一步探讨异常处理和从ACH文件问题中恢复。目前，我们只想简要提及一些可能性。
- en: We will identify some of the possible rejection scenarios and provide sample
    ACH files and `pytests` to code for them. When a file is rejected, we often must
    go back to the originator to request a new one. If any transactions have posted,
    they may need to be reversed as part of the rejection process. For now, we are
    focusing more on identifying bad files than recovering from them. Of course, we
    will provide a finished example that addresses the `pytests`, if you want to skip
    ahead. Obviously, we would encourage you to work through these scenarios as the
    particular scenarios we have chosen do not require extensive knowledge of ACH
    processing.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将确定一些可能的拒绝场景，并提供用于编码这些场景的示例ACH文件和`pytests`。当一个文件被拒绝时，我们通常必须回到原始发送者那里请求一个新的文件。如果有任何交易已经过账，它们可能需要在拒绝过程中进行撤销。目前，我们更专注于识别坏文件，而不是从它们中恢复。当然，如果您想跳过，我们会提供一个解决`pytests`的完整示例。显然，我们会鼓励您通过这些场景，因为我们选择的特定场景不需要对ACH处理有广泛的知识。
- en: We will also be adding further validation later, as the project expands. For
    now, we are just expanding our proof of concept.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 随着项目的扩展，我们还将添加进一步的验证。目前，我们只是在扩展我们的概念验证。
- en: 2.6.1 File rejection
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.6.1 文件拒绝
- en: ACH files can be rejected when formatted incorrectly. Remember that the order
    of the records is important. An ACH file consists of batches, and each batch contains
    entry and addenda records. Both a batch and the entire file have trailer records.
    All the records should be 94 characters long. So, for the first scenario, we want
    to tackle dealing with a file where records may not be the correct length.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 当格式不正确时，ACH文件可以被拒绝。记住记录的顺序很重要。一个ACH文件由批次组成，每个批次包含条目和附加记录。一个批次和整个文件都有尾记录。所有记录都应该是94个字符长。因此，对于第一个场景，我们希望处理可能不是正确长度的记录的文件。
- en: Why would a file be produced with records shorter than 94 bytes? Before SFTP
    (Secure File Transfer Protocol) became common, we would encounter this when ftp
    was set to truncate trailing spaces. While ftp is not as prevalent as before,
    it could still be used internally to transfer files, so the original use case
    may be valid. In addition, files may be routed and retransmitted or even created/updated
    on someone’s computer. As banks merge and acquire each other, these file problems
    may still pop up. Since the Nacha spec requires 94-byte records, we will seek
    to enforce that. We have included ACH_Parser_v3 containing empty unit tests to
    help us validate our changes.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么会产生记录长度小于94字节的文件？在SFTP（安全文件传输协议）变得普遍之前，当ftp设置为截断尾部空格时，我们会遇到这种情况。虽然ftp不像以前那样普遍，但它仍然可以用于内部文件传输，因此原始用例可能是有效的。此外，文件可能被路由和重新传输，甚至可能在某人的计算机上创建/更新。随着银行的合并和收购，这些问题可能仍然会出现。由于Nacha规范要求94字节的记录，我们将寻求强制执行这一点。我们已经包含了包含空单元测试的ACH_Parser_v3，以帮助我们验证我们的更改。
- en: For each of these challenges, we expect the parser to accumulate a list of errors.
    This list should hopefully keep the parsing code relatively simple because we
    are not worried about input errors at this point. This approach also has the added
    benefit of being able to validate the expected results in our unit tests. If we
    know our file has two short lines, we should also expect two of those error messages.
    For now, we will only log an error message if it is a string, but you may expand
    your project or choose another approach.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这些挑战中的每一个，我们期望解析器累积一个错误列表。这个列表应该希望使解析代码相对简单，因为我们目前并不担心输入错误。这种方法还有一个额外的优点，就是能够在单元测试中验证预期的结果。如果我们知道我们的文件有两行短，我们也应该期待两条错误信息。目前，我们只会在错误信息是一个字符串时记录它，但你可能需要扩展你的项目或选择另一种方法。
- en: Code challenge; benefit 1
  id: totrans-249
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 代码挑战；优点1
- en: We started with a relatively simple program to parse our ACH file. Going back
    and handling these changes will help us gather some real-world experience because
    we are likely going to be maintaining and updating existing code more than writing
    code from the ground up.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从一个相对简单的程序开始解析我们的ACH文件。回到并处理这些更改将帮助我们积累一些实际经验，因为我们很可能会更多地维护和更新现有代码，而不是从头编写代码。
- en: 'The relatively simple change to check for a record length forces us to deal
    with exceptions and think about how we might want to identify, format, and store
    them. It also presents us with some choices in how we code this: Do we continue
    to store this unparsed record along with the other records? If not, where does
    it go, and how does a user know which record had an error?'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 检查记录长度的相对简单更改迫使我们处理异常，并思考我们可能希望如何识别、格式化和存储它们。这也给我们带来了如何编码的一些选择：我们是否继续将这个未解析的记录与其他记录一起存储？如果不是，它去哪里了，用户如何知道哪个记录有错误？
- en: Seemingly mundane choices can sometimes have a significant influence down the
    road. So, this is just something to keep in mind and watch for as we work through
    the program.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来微不足道的选择有时会对未来产生重大影响。所以，这仅仅是我们需要注意和留意的事情，在我们处理程序时。
- en: 2.6.2 Batch rejection
  id: totrans-253
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.6.2 批量拒绝
- en: Individual batches may also be rejected from a file, and one reason is that
    the trace numbers are not ascending. A trace number appears on each entry detail
    record (type 6). As the name implies, these trace numbers provide a way to identify
    an ACH transaction within a batch. The first eight digits of a trace number are
    the routing number of the Originating Depository Financial Institution (ODFI)—in
    other words, what bank or financial institution the transaction came from—and
    the last seven digits of the trace number are in ascending order (but not necessarily
    sequential).
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 单个批次也可能被文件拒绝，其中一个原因是跟踪号不是递增的。跟踪号出现在每个条目详细记录（类型 6）上。正如其名所示，这些跟踪号提供了一种在批次内识别 ACH
    交易的方法。跟踪号的前八位是发起存款金融机构（ODFI）的路线号——换句话说，交易来自哪家银行或金融机构——跟踪号的最后七位是递增的（但不一定是连续的）。
- en: A unique trace number provides a means to reconcile and report on these ACH
    transactions and the ability to trace a transaction through the payment system
    for both regulatory and compliance reasons. We can now expand the ACH parser to
    consider these trace numbers. Again ACH_Parser_v3 has some unit tests that we
    can use to verify whether our program parsed the file correctly.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 唯一的跟踪号提供了一种对 ACH 交易进行核对和报告的手段，以及通过支付系统追踪交易的能力，这对于监管和合规原因都是必要的。我们现在可以扩展 ACH 解析器以考虑这些跟踪号。再次，ACH_Parser_v3
    有一些单元测试，我们可以使用它们来验证我们的程序是否正确解析了文件。
- en: Code challenge; benefit 2
  id: totrans-256
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 代码挑战；好处 2
- en: This challenge gets a little more complicated in how we will choose where and
    when to handle these exceptions. We started off with our functions being named
    _`parse_entry_detail`. If we choose to update the code to handle verification
    in that parse routine, will we update that function name since it is no longer
    just parsing? Will one routine call another, or will we call two routines or just
    use one routine? Do we parse the record first and then check the trace number,
    or do we check it before parsing the whole record?
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这个挑战在如何选择处理这些异常的位置和时间上变得更加复杂。我们最初以函数名为 _`parse_entry_detail`_ 开始。如果我们选择更新代码以在该解析例程中处理验证，我们会更新该函数名，因为它不再只是解析吗？一个例程会调用另一个例程，还是我们会调用两个例程或只使用一个例程？我们是先解析记录然后检查跟踪号，还是先检查跟踪号然后再解析整个记录？
- en: Sometimes, we want to make changes with surgical precision for both time and
    complexity reasons. Other times, we may opt for a shotgun approach when there
    are multiple things that must be accomplished. Either way, you should still be
    working in short cycles, making sure to test often.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们可能因为时间和复杂性的原因，希望以手术般的精确度进行更改。其他时候，我们可能选择散弹枪方法，当有多个任务必须完成时。无论哪种方式，你都应该仍然在短周期内工作，确保经常测试。
- en: 2.6.3 Entry rejection
  id: totrans-259
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.6.3 条目拒绝
- en: An entry may be rejected if the addenda flag is not consistent with the existence
    of an addenda record. The entry detail record contains a flag indicating whether
    the next record is an addenda record. Addenda records include additional information
    for ACH transactions and are sometimes required for specific SEC codes. With only
    94 bytes to work with, it is sometimes necessary to have addenda records to pass
    additional information about the transaction along.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 如果附加标志与附加记录的存在不一致，则条目可能会被拒绝。条目详细记录包含一个标志，指示下一个记录是否是附加记录。附加记录包括 ACH 交易的其他信息，有时对于特定的
    SEC 代码是必需的。由于只有 94 个字节可以工作，有时需要附加记录来传递有关交易的其他附加信息。
- en: Code challenge; benefit 3
  id: totrans-261
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 代码挑战；好处 3
- en: Coding this challenge requires us to look ahead or look behind as we need to
    be able to determine whether we expect an addenda record. This goes back to making
    decisions and then deal with them later.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 编写这个挑战需要我们向前或向后看，因为我们需要能够确定是否期望有一个附加记录。这回到了做出决定然后稍后处理它们。
- en: For instance, the existing code had read all the lines and then used a `for-each`
    loop to iterate through them. Having the `for-each` loop is handy, but now we
    potentially need a way to index our list of lines. If we need to conserve memory
    because we expect large ACH files, we may not want to read all the lines in, and
    therefore, we would have to take another approach to finding an addenda record.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，现有的代码已经读取了所有行，然后使用 `for-each` 循环遍历它们。拥有 `for-each` 循环很方便，但现在我们可能需要一个方法来索引我们的行列表。如果我们需要节省内存，因为我们预计会有大的
    ACH 文件，我们可能不想读取所有行，因此，我们就必须采取另一种方法来找到附加记录。
- en: This is all part of the software development process. Thinking about and planning
    our changes will help us address some of these challenges and hopefully future-proof
    our code.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 这都是软件开发过程的一部分。思考和规划我们的变更将帮助我们解决一些这些挑战，并希望使我们的代码面向未来。
- en: When we come across a bad design choice that we or a co-worker have made, learn
    from it. Even if it is annoying and makes you rework a lot of code, you can take
    something away from the experience!
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们遇到我们或同事做出的不良设计选择时，要从中学到东西。即使它令人烦恼并让你重写大量代码，你也能从这次经历中学到一些东西！
- en: 2.7 Interpreting the code
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.7 解释代码
- en: Depending on your experience with Python, you may have some questions about
    the code that was produced as part of this example. The following sections examine
    the code in more detail to provide additional insight into the Python code we
    have written, covering the Python `switch` statement, type hints, and secure coding.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你对Python的经验，你可能会对作为本示例一部分生成的代码有一些疑问。以下章节将更详细地检查代码，以提供对我们所编写的Python代码的额外见解，包括Python的`switch`语句、类型提示和安全的编码。
- en: 2.7.1 Where’s my switch statement?
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.7.1 我的`switch`语句在哪里？
- en: There are six record types for ACH that we need to parse. If you have some programming
    experience, you have likely come across the `if`/`if` `else`/`else` construct
    for flow control. In Python, we would see this as
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 对于ACH，我们需要解析六种记录类型。如果你有一些编程经验，你很可能遇到过用于流程控制的`if`/`if` `else`/`else`结构。在Python中，我们会看到这作为
- en: '[PRE19]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: At some point, we probably also coded rather large `if` statements with multiple
    conditions before someone introduced you to a `switch/case` statement. Early in
    Python (circa 2006), support for `switch`/`case` statements was debated and finally
    rejected. However, as of Python 3.10, there is support for the match statement
    (h[ttps://peps.python.org/pep-0634/](https://peps.python.org/pep-0634/)), which
    provides the means to create a `switch` statement, as shown in the next listing.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在某个时候，我们可能也编写了相当大的`if`语句，包含多个条件，在有人向你介绍`switch/case`语句之前。在Python早期（大约2006年），对`switch`/`case`语句的支持被讨论并最终被拒绝。然而，截至Python
    3.10，支持`match`语句（[https://peps.python.org/pep-0634/](https://peps.python.org/pep-0634/)），它提供了创建`switch`语句的手段，如下一列表所示。
- en: Listing 2.17  Creating a `switch` statement using `match`
  id: totrans-272
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.17  使用`match`创建`switch`语句
- en: '[PRE20]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '#1 Uses the match keyword to create cases for the record_type field'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 使用match关键字为record_type字段创建情况'
- en: '#2 Each condition has a case statement.'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 每个条件都有一个情况语句。'
- en: '#3 The default case is identified with an underscore.'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 默认情况用下划线标识。'
- en: With millions of lines of Python code written before the `match` construct became
    available, generative AI is likely to show you the `if`/`elif` or another common
    practice of creating a Dictionary to store the choices as was done in the sample
    program.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在`match`构造可用之前，已经编写了数百万行Python代码，生成式AI可能会向你展示`if`/`elif`或其他常见的创建字典以存储选择的实践，就像在示例程序中所做的那样。
- en: Listing 2.18  Using a Dictionary
  id: totrans-278
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.18  使用字典
- en: '[PRE21]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '#1 Defines a Dictionary of functions that can be called'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 定义一个可以调用的函数字典'
- en: '#2 Retrieves the function from the Dictionary based on the record_type'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 根据record_type从字典中检索函数'
- en: '#3 Calls the parser for the given line and appends the results to the records
    variable'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 调用给定行的解析器并将结果追加到记录变量中'
- en: This code declares the functions for each type and calls the appropriate function.
    One thing that would make us favor another approach is that we cannot see whether
    the parameters should be passed to the function. We may not even be able to tell
    if they are functions. One way to handle this is using type hints.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码声明了每种类型的函数并调用相应的函数。有一件事可能会让我们倾向于另一种方法，那就是我们无法看到参数是否应该传递给函数。我们甚至可能无法确定它们是否是函数。处理这个问题的一种方法就是使用类型提示。
- en: 2.7.2 Type hints
  id: totrans-284
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.7.2 类型提示
- en: Type hints have been around since Python 3.5 and were defined in [https://peps.python.org/pep-0484](https://peps.python.org/pep-0484).
    While Python uses duck typing, the addition of type hints can help make the code
    more maintainable. In our opinion, it goes back to having to choose between freedom
    to code and the code longevity. When writing Python code, it is great not to be
    constrained by static typing; instead, we can focus more on the code. However,
    as more Python code comes into existence, or when we must start looking at other
    people’s code, we want some of those guides. So, while Python does not enforce
    type hints at runtime, there are tools that can be used to do static type checking
    based on these type hints, as well as just the benefits of documentation.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 类型提示自Python 3.5以来一直存在，并在[https://peps.python.org/pep-0484](https://peps.python.org/pep-0484)中定义。虽然Python使用鸭子类型，但类型提示的添加可以帮助使代码更易于维护。在我们看来，这回到了在编码自由和代码持久性之间做出选择的问题。在编写Python代码时，不受静态类型约束是件好事；相反，我们可以更多地关注代码。然而，随着越来越多的Python代码出现，或者当我们必须开始查看他人的代码时，我们希望有一些这样的指南。因此，尽管Python在运行时不强制执行类型提示，但有一些工具可以根据这些类型提示以及仅基于文档的好处来进行静态类型检查。
- en: We also wonder whether the popularity of Python and the migration of developers
    to it from other languages have also brought some of their baggage. We believe
    these additions to the language are important, and as they have gone through the
    Python Enhancement Proposal (PEP) process, the community agrees. Of course, our
    backgrounds are in statically typed languages, so these make sense. If we came
    from LISP or Scheme, would we want to see a bunch of parentheses added to the
    language?
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还想知道Python的流行以及开发者从其他语言迁移到Python是否也带来了一些他们的负担。我们认为这些语言特性的添加很重要，并且随着它们通过了Python增强提案（PEP）流程，社区也同意这一点。当然，我们的背景是在静态类型语言中，所以这些是有意义的。如果我们来自LISP或Scheme，我们会希望看到语言中添加一大堆括号吗？
- en: 'Our original problem with the dictionary approach to flow control was that
    we did not have a way to tell what parameters could be passed to the functions
    we were calling. We can update the `parser_functions` to use type-hinting:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在采用字典方法进行流控制时遇到的原问题是，我们没有一种方法来确定可以传递给我们所调用的函数的参数。我们可以更新`parser_functions`以使用类型提示：
- en: '[PRE22]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The variable `parser_functions` is now defined as a Dictionary that contains
    a string (`str`) for the record type and a `Callable` that represents the function
    being called. The `Callable` takes a list of parameters, and in this case, we
    see it takes one string that is denoted by `[str]` and that it returns a dictionary
    of strings, which is our parsed record.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 变量`parser_functions`现在被定义为包含一个字符串（`str`）作为记录类型和一个表示被调用函数的`Callable`的字典。`Callable`接受一系列参数，在这种情况下，我们看到它接受一个用`[str]`表示的字符串，并且它返回一个字符串字典，这是我们解析的记录。
- en: After seeing the type hint for this, maybe we decide to rewrite our code to
    take advantage of one of those other constructs because that seems confusing!
    By embracing the use of type hints, we could then move to static type checkers
    such as mypy, Pyright, and Pyre. In our opinion, static type checking is a must-have
    for enterprise applications where there are large teams or the project is long-lived
    (and we assume they will be). Other developers diving into the code base for the
    first time or after a hiatus on the project will find them immensely helpful.
    Of course, Python is going to remain a dynamically typed language (see [https://mng.bz/oKEM](https://mng.bz/oKEM)),
    but the proliferation of tools and their adoption should show that there is at
    least some benefit to type checking.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在看到这个类型提示之后，我们可能决定重写我们的代码以利用那些其他构造之一，因为这看起来很混乱！通过采用类型提示的使用，我们就可以转向静态类型检查器，如mypy、Pyright和Pyre。在我们看来，静态类型检查对于有大型团队或项目长期存在的企业应用来说是必不可少的（我们假设它们将是）。其他第一次或中断项目后进入代码库的开发者会发现它们非常有帮助。当然，Python将保持动态类型语言（见[https://mng.bz/oKEM](https://mng.bz/oKEM)），但工具的普及和它们的采用应该表明类型检查至少有一些好处。
- en: 2.7.3 Secure coding
  id: totrans-291
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.7.3 安全编码
- en: 'There has been concern that generative AI may not be producing code that is
    secure or code that is even good. This is not only true for generative AI but
    also for humans: we all make mistakes. Going back to our tool analogy, we need
    to remember that generative AI is just another tool we should be using, which
    is why we advocate the use of formatting and linters to help identify problems
    within our code.'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 人们担心生成式AI可能不会生成安全或甚至良好的代码。这不仅适用于生成式AI，也适用于人类：我们都会犯错误。回到我们的工具类比，我们需要记住生成式AI只是我们应使用的另一个工具，这就是我们为什么提倡使用格式化和linters来帮助我们识别代码中的问题。
- en: Corporations use a number of tools available on the market to scan their code
    looking for flaws and security holes. These tools include Fortify on Demand, Veracode,
    Snyk, and Amazon’s CodeWhisperer. The primary goal of this software is to look
    for insecure coding patterns. They often use the OWASP 10, SANS Top 25, and other
    lists as guides to the problems they identify.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 企业使用市场上可用的多种工具来扫描其代码，寻找缺陷和安全漏洞。这些工具包括Fortify on Demand、Veracode、Snyk和亚马逊的CodeWhisperer。这些软件的主要目标是寻找不安全的编码模式。他们经常使用OWASP
    10、SANS Top 25和其他列表作为他们识别问题的指南。
- en: Many times, these are incorporated into a CI/CD pipeline; however, we also have
    options for handling them inside our IDE as well. Since The Fantastic Fintech
    Company uses JetBrains, we can take advantage of some of their included features.
    For instance, in our requirements.txt for our Python project, PyCharm will detect
    vulnerabilities in our dependencies (see figure 2.5). We can see the Common Vulnerabilities
    and Exposures (CVE) ID and a short description of the vulnerability.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 许多时候，这些操作被纳入CI/CD管道中；然而，我们也有选项在IDE内部处理它们。由于The Fantastic Fintech Company使用JetBrains，我们可以利用他们的一些内置功能。例如，在我们的Python项目的要求.txt文件中，PyCharm将检测我们的依赖项中的漏洞（见图2.5）。我们可以看到通用漏洞和暴露（CVE）ID和漏洞的简要描述。
- en: '![A screenshot of a computer error  Description automatically generated](../Images/CH02_F05_Kardell.png)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![计算机错误截图  自动生成的描述](../Images/CH02_F05_Kardell.png)'
- en: Figure 2.5  An example dependency
  id: totrans-296
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.5  一个示例依赖项
- en: By clicking More actions, we can simply choose to update to a newer version,
    as shown in figure 2.6\. Of course, this action would require further application
    testing, but it is certainly nice to be alerted to potential problems before our
    code even makes it to the CI/CD pipeline.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 通过点击更多操作，我们可以简单地选择更新到较新版本，如图2.6所示。当然，这个操作需要进一步的应用程序测试，但在我们的代码甚至进入CI/CD管道之前就提醒潜在问题当然是非常好的。
- en: '![A screenshot of a computer error  Description automatically generated](../Images/CH02_F06_Kardell.png)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![计算机错误截图  自动生成的描述](../Images/CH02_F06_Kardell.png)'
- en: Figure 2.6 Options to handle vulnerability
  id: totrans-299
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.6  处理漏洞的选项
- en: Chances are most companies have either adopted a static analysis tool or are
    currently evaluating them. Having the ability to allow developers to view and
    troubleshoot problems directly in the IDE is another way to boost productivity.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 很可能大多数公司都已经采用或正在评估静态分析工具。允许开发者直接在IDE中查看和调试问题，是提高生产力的另一种方式。
- en: Summary
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: We explored how to incorporate generative AI into our development workflow,
    learning what to ask (prompt engineering) and how to clarify our intent (problem
    formulation).
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们探讨了如何将生成式AI纳入我们的开发工作流程，学习如何提问（提示工程）以及如何明确我们的意图（问题制定）。
- en: We focused on modernizing an ACH system running on legacy mainframe architecture
    using metrics such as release cadence and defect backlog.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们专注于使用如发布节奏和缺陷积压等指标来现代化运行在旧式主机架构上的ACH系统。
- en: We utilized ChatGPT and GitHub Copilot to understand ACH file layouts better
    while ensuring that no confidential data is exposed.
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们利用ChatGPT和GitHub Copilot来更好地理解ACH文件布局，同时确保不泄露任何机密数据。
- en: ACH network facilitates seamless money transfers between banks, and it is commonly
    used for transactions such as payroll and bill payment.
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ACH网络促进了银行之间无缝的资金转账，它通常用于工资支付和账单支付等交易。
- en: ACH files are fixed-width ASCII files with specific record types that require
    careful parsing of file header, batch header, entry details, addenda, batch control,
    and file trailer records.
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ACH文件是具有特定记录类型的固定宽度ASCII文件，需要仔细解析文件头、批次头、条目详情、附加信息、批次控制和文件尾记录。
- en: ACH parsing can be validated using unit tests with TDD to obtain reliable, high-quality
    software.
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用单元测试和TDD来验证ACH解析，以获得可靠、高质量的软件。
- en: Linters and formatters such as SonarLint and black can be used to enforce coding
    standards and reduce cognitive load.
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用SonarLint和black等linters和formatters来强制执行编码标准并减少认知负荷。
- en: Scenarios in which ACH files may have errors can be handled using robust code
    that accounts for unexpected inputs and edge cases.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于可能存在错误的ACH文件场景，可以使用考虑意外输入和边缘情况的稳健代码来处理。
- en: Type hints can be implemented in Python for enhanced code clarity and maintainability,
    which helps easier collaboration and onboarding.
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在Python中实现类型提示可以增强代码的清晰度和可维护性，这有助于更轻松的协作和入职。
- en: Security concerns can be addressed by using static analysis tools to identify
    coding vulnerabilities and ensure compliance with security standards.
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以通过使用静态分析工具来识别编码漏洞并确保符合安全标准来解决安全担忧。
- en: This chapter reiterated the importance of robust testing practices, iterative
    development, and early detection of potential problems using IDE plugins.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本章重申了稳健测试实践、迭代开发和利用IDE插件早期发现潜在问题的重要性。
