["```py\ndef print_query_classification(query, classification_field=\"category\",\n      classification_limit=5, keywords_field=\"body\", min_occurrences=5):\n\n  nodes_to_traverse = [{\"field\": keywords_field, #1\n                        \"values\": [query]},  #1\n                       {\"field\": classification_field, #2\n                        \"min_occurrences\": min_occurrences,  #3\n                        \"limit\": classification_limit}]  #4\n\n  traversal = skg.traverse(*nodes_to_traverse)  #5\n  print_classifications(query, traversal)  #6\n\nskg = get_skg(get_engine().get_collection(\"stackexchange\"))\n\nprint_query_classification(\"docker\", classification_limit=3)\nprint_query_classification(\"airplane\", classification_limit=1)\nprint_query_classification(\"airplane AND crash\", classification_limit=2)\nprint_query_classification(\"vitamins\", classification_limit=2)\nprint_query_classification(\"alien\", classification_limit=1)\nprint_query_classification(\"passport\", classification_limit=1)\nprint_query_classification(\"driver\", classification_limit=2)\nprint_query_classification(\"driver AND taxi\", classification_limit=2)\nprint_query_classification(\"driver AND install\", classification_limit=2)\n```", "```py\nQuery: docker\n  Classifications:\n    devops  0.87978\n\nQuery: airplane\n  Classifications:\n    travel  0.33334\n\nQuery: airplane AND crash\n  Classifications:\n    scifi  0.02149\n    travel  0.00475\n\nQuery: vitamins\n  Classifications:\n    health  0.48681\n    cooking  0.09441\n\nQuery: alien\n  Classifications:\n    scifi  0.62541\n\nQuery: passport\n  Classifications:\n    travel  0.82883\n\nQuery: driver\n  Classifications:\n    travel  0.38996\n    devops  0.08917\n\nQuery: driver AND taxi\n  Classifications:\n    travel  0.24184\n    scifi  -0.13757\n\nQuery: driver AND install\n  Classifications:\n    devops  0.22277\n    travel  -0.00675\n```", "```py\ndef print_query_disambigutaion(query,\n      context_field=\"category\", context_limit=5,\n      keywords_field=\"body\", keywords_limit=10, min_occurrences=5):\n\n  nodes_to_traverse = [{\"field\": keywords_field,  #1\n                        \"values\": [query]}, #1\n                       {\"field\": context_field,  #2\n                        \"min_occurrences\": min_occurrences, #2\n                        \"limit\": context_limit}, #2\n                       {\"field\": keywords_field,  #3\n                        \"min_occurrences\": min_occurrences, #3\n                        \"limit\": keywords_limit}] #3\n\n  traversal = skg.traverse(*nodes_to_traverse)\n  print_disambigutaions(query, traversal)\n```", "```py\nprint_query_disambigutaion(\"server\")\nprint_query_disambigutaion(\"driver\", context_limit=2)\nprint_query_disambigutaion(\"chef\", context_limit=2)\n```", "```py\nprint_disambigutaion_request(\"chef\", context_limit=2)\n```", "```py\n{\"limit\": 0,\n \"params\": {\"q\": \"*\",\n            \"fore\": \"{!${defType} v=$q}\",\n            \"back\": \"*\",\n            \"defType\": \"edismax\",\n            \"f0_0_query\": \"chef\"}, #1\n \"facet\": {\n   \"f0_0\": {\n     \"type\": \"query\",\n     \"query\": \"{!edismax qf=body v=$f0_0_query}\", #1\n     \"field\": \"body\",\n     \"sort\": {\"relatedness\": \"desc\"},\n     \"facet\": {\"relatedness\": {\"type\": \"func\",\n                               \"func\": \"relatedness($fore,$back)\"},\n       \"f1_0\": {\n         \"type\": \"terms\",\n         \"field\": \"category\", #2\n         \"mincount\": 5, \"limit\": 2,\n         \"sort\": {\"relatedness\": \"desc\"},\n         \"facet\": {\"relatedness\": {\"type\": \"func\",\n                                   \"func\": \"relatedness($fore,$back)\"},\n           \"f2_0\": {\n             \"type\": \"terms\",  #3\n             \"field\": \"body\", #3\n             \"mincount\": 5, \"limit\": 10,\n             \"sort\": {\"relatedness\": \"desc\"},\n             \"facet\": {\"relatedness\":{\"type\": \"func\",\n                                      \"func\": \"relatedness($fore,$back)\"}}\n}}}}}}}\n```", "```py\nsignals_collection = engine.get_collection(\"signals\")\ncreate_view_from_collection(signals_collection, \"signals\") #1\nquery = \"\"\"SELECT LOWER(searches.target) AS keyword, searches.user\n           FROM signals AS searches  #2\n           WHERE searches.type='query'\"\"\"  #2\nspark.sql(query).createOrReplaceTempView(\"user_searches\")  #2\nprint_keyword_user_pairs()\n```", "```py\nNumber of keyword user pairs: 725459\n\nKeyword user pairs derived from signals:\nUser \"u10\" searched for \"joy stick\"\nUser \"u10\" searched for \"xbox\"\nUser \"u10\" searched for \"xbox360\"\n```", "```py\nquery = \"\"\"SELECT k1.keyword AS keyword1, k2.keyword AS keyword2,\n           COUNT(DISTINCT k1.user) users_cooc  #1\n           FROM user_searches k1\n           JOIN user_searches k2 ON k1.user = k2.user\n           WHERE k1.keyword > k2.keyword  #2\n           GROUP BY k1.keyword, k2.keyword\"\"\"  #3\nspark.sql(query).createOrReplaceTempView(\"keywords_users_cooc\")\nquery = \"\"\"SELECT keyword, COUNT(DISTINCT user) users_occ FROM\n           user_searches GROUP BY keyword\"\"\"\nspark.sql(query).createOrReplaceTempView(\"keywords_users_oc\")\nprint_keyword_cooccurrences()\n```", "```py\n+-----------+---------+\n|    keyword|users_occ|\n+-----------+---------+\n|     lcd tv|     8449|\n|       ipad|     7749|\n|hp touchpad|     7144|\n|  iphone 4s|     4642|\n|   touchpad|     4019|\n|     laptop|     3625|\n|    laptops|     3435|\n|      beats|     3282|\n|       ipod|     3164|\n| ipod touch|     2992|\n+-----------+---------+\n\nNumber of co-occurring keyword searches: 244876\n\n+-------------+---------------+----------+\n|     keyword1|       keyword2|users_cooc|\n+-------------+---------------+----------+\n|green lantern|captain america|        23|\n|    iphone 4s|         iphone|        21|\n|       laptop|      hp laptop|        20|\n|         thor|captain america|        18|\n|         bose|          beats|        17|\n|    iphone 4s|       iphone 4|        17|\n|   skullcandy|          beats|        17|\n|      laptops|         laptop|        16|\n|      macbook|            mac|        16|\n|         thor|  green lantern|        16|\n+-------------+---------------+----------+\n```", "```py\nquery = \"\"\"\nSELECT k1.keyword AS k1, k2.keyword AS k2, k1_k2.users_cooc,\nk1.users_occ AS n_users1, k2.users_occ AS n_users2,\nLOG(POW(k1_k2.users_cooc, 2) /  #1\n    (k1.users_occ * k2.users_occ)) AS pmi2  #1\nFROM keywords_users_cooc AS k1_k2\nJOIN keywords_users_oc AS k1 ON k1_k2.keyword1 = k1.keyword\nJOIN keywords_users_oc AS k2 ON k1_k2.keyword2 = k2.keyword\"\"\"\nspark.sql(query).createOrReplaceTempView(\"user_related_keywords_pmi\")\n\nspark.sql(\"\"\"SELECT k1, k2, users_cooc, n_users1,\n                    n_users2, ROUND(pmi2, 3) AS pmi2\n             FROM user_related_keywords_pmi\n             WHERE users_cooc > 5 ORDER BY pmi2 DESC, k1 ASC\"\"\").show(10)\n```", "```py\n+-----------------+--------------------+----------+--------+--------+------+\n|               k1|                  k2|users_cooc|n_users1|n_users2|  pmi2|\n+-----------------+--------------------+----------+--------+--------+------+\n|  iphone 4s cases|      iphone 4 cases|        10|     158|     740|-7.064|\n|     sony laptops|          hp laptops|         8|     209|     432|-7.252|\n|otterbox iphone 4|            otterbox|         7|     122|     787| -7.58|\n|    green lantern|     captain america|        23|     963|    1091|-7.594|\n|          kenwood|              alpine|        13|     584|     717|-7.815|\n|      sony laptop|         dell laptop|        10|     620|     451|-7.936|\n|   wireless mouse|           godfather|         6|     407|     248|-7.939|\n|       hp laptops|        dell laptops|         6|     432|     269| -8.08|\n|      mp3 players|        dvd recorder|         6|     334|     365|-8.128|\n|          quicken|portable dvd players|         6|     281|     434|-8.128|\n+-----------------+--------------------+----------+--------+--------+------+\n```", "```py\nquery = \"\"\"\nSELECT *, (r1 + r2 / (r1 * r2)) / 2 AS comp_score  #1\nFROM (\n  SELECT *,\n  RANK() OVER (PARTITION BY 1  #2\n               ORDER BY users_cooc DESC) r1, #2\n  RANK() OVER (PARTITION BY 1  #3\n               ORDER BY pmi2 DESC) r2  #3\n  FROM user_related_keywords_pmi)\"\"\"\nspark.sql(query).createOrReplaceTempView(\"users_related_keywords_comp_score\")\n\nspark.sql(\"\"\"SELECT k1, k2, users_cooc, ROUND(pmi2, 3) as pmi2,\n             r1, r2, ROUND(comp_score, 3) as comp_score\n             FROM users_related_keywords_comp_score\n             ORDER BY comp_score ASC, pmi2 ASC\"\"\").show(20)\n```", "```py\n+-------------+---------------+----------+-------+---+------+----------+\n|           k1|             k2|users_cooc|   pmi2| r1|    r2|comp_score|\n+-------------+---------------+----------+-------+---+------+----------+\n|green lantern|captain america|        23| -7.594|  1|  8626|       1.0|\n|    iphone 4s|         iphone|        21|-10.217|  2| 56156|      1.25|\n|       laptop|      hp laptop|        20| -9.133|  3| 20383|     1.667|\n|         thor|captain america|        18| -8.483|  4| 13190|     2.125|\n|    iphone 4s|       iphone 4|        17|-10.076|  5| 51964|       2.6|\n|         bose|          beats|        17|-10.074|  5| 51916|       2.6|\n|   skullcandy|          beats|        17| -9.001|  5| 18792|       2.6|\n|      laptops|         laptop|        16|-10.792|  8| 80240|     4.063|\n|      macbook|            mac|        16| -9.891|  8| 45464|     4.063|\n|         thor|  green lantern|        16| -8.594|  8| 14074|     4.063|\n|   headphones|   beats by dre|        15| -9.989| 11| 49046|     5.545|\n|  macbook pro|        macbook|        15| -9.737| 11| 39448|     5.545|\n|  macbook air|        macbook|        15| -9.443| 11| 26943|     5.545|\n|   ipod touch|           ipad|        13|-11.829| 14|200871|     7.036|\n|       ipad 2|           ipad|        13|-11.765| 14|196829|     7.036|\n|         nook|         kindle|        13| -9.662| 14| 36232|     7.036|\n|  macbook pro|    macbook air|        13| -9.207| 14| 21301|     7.036|\n|      kenwood|         alpine|        13| -7.815| 14|  9502|     7.036|\n| beats by dre|          beats|        12|-10.814| 19| 82811|     9.526|\n|      macbook|          apple|        12|-10.466| 19| 62087|     9.526|\n+-------------+---------------+----------+-------+---+------+----------+\n```", "```py\nquery = \"\"\"SELECT LOWER(searches.target) AS keyword, searches.user AS user,\n           clicks.target AS product FROM signals AS searches\n           RIGHT JOIN signals AS clicks  #1\n           ON searches.query_id = clicks.query_id  #1\n           WHERE searches.type = 'query'  #1\n           AND clicks.type = 'click'\"\"\"  #1\nspark.sql(query).createOrReplaceTempView(\"keyword_click_product\")\nprint_signals_format()\n```", "```py\nOriginal signals format:\n+-------------------+-----------+----------------+-----------+-----+-------+\n|                 id|   query_id|     signal_time|     target| type|   user|\n+-------------------+-----------+----------------+-----------+-----+-------+\n|000001e9-2e5a-4a...|u112607_0_1|2020-04-18 16:33|        amp|query|u112607|\n|00001666-1748-47...|u396779_0_1|2019-10-16 10:22|Audio stand|query|u396779|\n|000029d2-197d-4a...|u466396_0_1|2020-05-07 11:39|alarm clock|query|u466396|\n+-------------------+-----------+----------------+-----------+-----+-------+\n\nSimplified signals format:\n+-------------+----+------------+\n|      keyword|user|     product|\n+-------------+----+------------+\n|    joy stick| u10|097855018120|\n|         xbox| u10|885370235876|\n|virgin mobile|u100|799366521679|\n+-------------+----+------------+\n```", "```py\nquery = \"\"\"\nSELECT k1.keyword AS k1, k2.keyword AS k2, SUM(p1) n_users1, sum(p2) n_users2,\nSUM(p1 + p2) AS users_cooc, COUNT(1) n_products FROM (\n  SELECT keyword, product, COUNT(1) AS p1 FROM keyword_click_product\n  GROUP BY keyword, product) AS k1 JOIN (\n  SELECT keyword, product, COUNT(1) AS p2 FROM keyword_click_product\n  GROUP BY keyword, product) AS k2 ON k1.product = k2.product\nWHERE k1.keyword > k2.keyword GROUP BY k1.keyword, k2.keyword\"\"\"\nspark.sql(query).createOrReplaceTempView(\"keyword_click_product_cooc\")\nprint_keyword_pair_data()\n```", "```py\nNumber of co-occurring queries: 1579710\n\n+--------------+-------------+--------+--------+----------+----------+\n|            k1|           k2|n_users1|n_users2|users_cooc|n_products|\n+--------------+-------------+--------+--------+----------+----------+\n|       laptops|       laptop|    3251|    3345|      6596|       187|\n|       tablets|       tablet|    1510|    1629|      3139|       155|\n|        tablet|         ipad|    1468|    7067|      8535|       146|\n|       tablets|         ipad|    1359|    7048|      8407|       132|\n|       cameras|       camera|     637|     688|      1325|       116|\n|          ipad|        apple|    6706|    1129|      7835|       111|\n|      iphone 4|       iphone|    1313|    1754|      3067|       108|\n|    headphones|  head phones|    1829|     492|      2321|       106|\n|        ipad 2|         ipad|    2736|    6738|      9474|        98|\n|     computers|     computer|     536|     392|       928|        98|\n|iphone 4 cases|iphone 4 case|     648|     810|      1458|        95|\n|       netbook|       laptop|    1017|    2887|      3904|        94|\n|        laptop|    computers|    2794|     349|      3143|        94|\n|       netbook|      laptops|    1018|    2781|      3799|        91|\n|    headphones|    headphone|    1617|     367|      1984|        90|\n|        laptop|           hp|    2078|     749|      2827|        89|\n|        tablet|    computers|    1124|     449|      1573|        89|\n|       laptops|    computers|    2734|     331|      3065|        88|\n|           mac|        apple|    1668|    1218|      2886|        88|\n|     tablet pc|       tablet|     296|    1408|      1704|        87|\n+--------------+-------------+--------+--------+----------+----------+\n```", "```py\nquery = \"\"\"SELECT keyword, COUNT(1) AS n_users FROM keyword_click_product\n           GROUP BY keyword\"\"\"\nspark.sql(query).createOrReplaceTempView(\"keyword_click_product_oc\")\nprint_keyword_popularity()\n```", "```py\nKeyword searches that resulted in clicks: 13744\n\n+------------+-------+\n|     keyword|n_users|\n+------------+-------+\n|        ipad|   7554|\n| hp touchpad|   4829|\n|      lcd tv|   4606|\n|   iphone 4s|   4585|\n|      laptop|   3554|\n|       beats|   3498|\n|     laptops|   3369|\n|        ipod|   2949|\n|  ipod touch|   2931|\n|      ipad 2|   2842|\n|      kindle|   2833|\n|    touchpad|   2785|\n|   star wars|   2564|\n|      iphone|   2430|\n|beats by dre|   2328|\n|     macbook|   2313|\n|  headphones|   2270|\n|        bose|   2071|\n|         ps3|   2041|\n|         mac|   1851|\n+------------+-------+\n```", "```py\nquery = \"\"\"SELECT k1, k2, n_users1, n_users2, ROUND(pmi2, 3) AS pmi2,\n           ROUND(comp_score, 3) AS comp_score\n           FROM product_related_keywords_comp_score\n           ORDER BY comp_score ASC\"\"\"\ndataframe = spark.sql(query)\nprint(\"Number of co-occurring queries:\", dataframe.count(), \"\\n\")\ndataframe.show(20)\n```", "```py\nNumber of co-occurring queries: 1579710\n\n+----------+-----------+--------+--------+-----+----------+\n|        k1|         k2|n_users1|n_users2| pmi2|comp_score|\n+----------+-----------+--------+--------+-----+----------+\n|      ipad|hp touchpad|    7554|    4829|1.232|       1.0|\n|    ipad 2|       ipad|    2842|    7554|1.431|      1.25|\n|    tablet|       ipad|    1818|    7554|1.669|     1.667|\n|  touchpad|       ipad|    2785|    7554|1.223|     2.125|\n|   tablets|       ipad|    1627|    7554|1.749|       2.6|\n|     ipad2|       ipad|    1254|    7554|1.903|     3.083|\n|      ipad|      apple|    7554|    1814|  1.5|     3.571|\n|  touchpad|hp touchpad|    2785|    4829|1.394|     4.063|\n|      ipad|  hp tablet|    7554|    1421|1.594|     4.556|\n|ipod touch|       ipad|    2931|    7554|0.863|      5.05|\n|      ipad|      i pad|    7554|     612|2.415|     5.545|\n|    kindle|       ipad|    2833|    7554|0.828|     6.042|\n|    laptop|       ipad|    3554|    7554|0.593|     6.538|\n|      ipad| apple ipad|    7554|     326|2.916|     7.036|\n|    ipad 2|hp touchpad|    2842|    4829|1.181|     7.533|\n|   laptops|     laptop|    3369|    3554| 1.29|     8.031|\n|      ipad|         hp|    7554|    1125|1.534|     8.529|\n|     ipads|       ipad|     254|    7554|3.015|     9.028|\n|      ipad|  htc flyer|    7554|    1834|1.016|     9.526|\n|      ipad|    i pad 2|    7554|     204| 3.18|    10.025|\n+----------+-----------+--------+--------+-----+----------+\n```", "```py\n+------------+-------+\n|     keyword|n_users|\n+------------+-------+\n|        ipad|   7554|\n| hp touchpad|   4829|\n|      lcd tv|   4606|\n|   iphone 4s|   4585|\n|      laptop|   3554|\n|        ... |   ... |\n+------------+-------+\n```", "```py\nproducts_collection = engine.get_collection(\"products\")\nquery = \"moden\"\nresults = engine.spell_check(products_collection, query)\nprint(results)\n```", "```py\n{'modes': 421, 'model': 159, 'modern': 139, 'modem': 56, 'mode6': 9}\n```", "```py\ndef get_search_queries():\n  query = \"\"\"SELECT searches.user AS user,\n             LOWER(TRIM(searches.target)) As query  #1\n             FROM signals AS searches WHERE searches.type = 'query'\n             GROUP BY searches.target, user\"\"\"  #2\n  return spark.sql(query).collect()\n```", "```py\nfrom nltk import tokenize, corpus, download  #1\ndownload('stopwords') #1\nstop_words = set( #1\n  corpus.stopwords.words(\"english\")) #1\n\ndef is_term_valid(term, minimum_length=4): #2\n  return (term not in stop_words and\n          len(term) >= minimum_length and\n          not term.isdigit())\n\ndef tokenize_query(query):  #3\n  return tokenize.RegexpTokenizer(r'\\w+').tokenize(query) #3\n\ndef valid_keyword_occurrences(searches, tokenize=True):\n  word_list = defaultdict(int)\n  for search in searches:\n    query = search[\"query\"]\n    terms = tokenize_query(query) if tokenize else [query]  #3\n    for term in terms:  #4\n      if is_term_valid(term):  #4\n        word_list[term] += 1  #4\n  return word_list\n```", "```py\ndef calculate_quantiles(word_list):\n  quantiles_to_check = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n  quantile_values = numpy.quantile(numpy.array(list(word_list.values())),\n                                   quantiles_to_check)\n  return dict(zip(quantiles_to_check, quantile_values))\n\nquery_signals = get_search_queries()\nword_list = valid_keyword_occurrences(query_signals, tokenize=True)\nquantiles = calculate_quantiles(word_list)\ndisplay(quantiles)\n```", "```py\n{0.1: 5.0,\n 0.2: 6.0,\n 0.3: 8.0,\n 0.4: 12.0,\n 0.5: 16.0,\n 0.6: 25.0,\n 0.7: 47.0,\n 0.8: 142.20000000000027,\n 0.9: 333.2000000000007}\n```", "```py\ndef create_spelling_candidates(word_list):\n  quantiles = calculate_quantiles(word_list)\n  misspellings = {\"misspelling\": [],\n                  \"misspell_counts\": [],\n                  \"misspell_length\": [],\n                  \"initial\": []}\n  corrections = {\"correction\": [],\n                 \"correction_counts\": [],\n                 \"correction_length\": [],\n                 \"initial\": []}\n  for key, value in word_list.items():\n    if value <= quantiles[0.2]:  #1\n      misspellings[\"misspelling\"].append(key) #1\n      misspellings[\"misspell_counts\"].append(value)  #2\n      misspellings[\"misspell_length\"].append(len(key))  #3\n      misspellings[\"initial\"].append(key[0])  #4\n    if value >= quantiles[0.8]: #5\n      corrections[\"correction\"].append(key) #5\n      corrections[\"correction_counts\"].append(value) #5\n      corrections[\"correction_length\"].append(len(key)) #5\n      corrections[\"initial\"].append(key[0])  #5\n  return (pandas.DataFrame(misspellings), pandas.DataFrame(corrections))\n```", "```py\ndef good_match(word_length_1, word_length_2, edit_dist):\n  min_length = min(word_length_1, word_length_2)\n  return ((min_length < 8 and edit_dist == 1) or\n          (min_length >= 8 and min_length < 11 and edit_dist <= 2) or\n          (min_length >= 11 and edit_dist == 3))\n```", "```py\nfrom nltk import edit_distance\n\ndef calculate_spelling_corrections(word_list):\n  (misspellings, corrections) = create_spelling_candidates(word_list)\n  matches_candidates = pandas.merge(misspellings,  #1\n                       corrections, on=\"initial\")  #1\n  matches_candidates[\"edit_dist\"] = matches_candidates.apply(\n    lambda row: edit_distance(row.misspelling,  #2\n                      row.correction), axis=1)  #2\n  matches_candidates[\"good_match\"] = matches_candidates.apply(\n    lambda row: good_match(row.misspell_length, #3\n                           row.correction_length,  #3\n                           row.edit_dist),axis=1)  #3\n  cols = [\"misspelling\", \"correction\", \"misspell_counts\",\n          \"correction_counts\", \"edit_dist\"]\n  matches = matches_candidates[matches_candidates[\"good_match\"]] \\\n    .drop([\"initial\", \"good_match\"],axis=1) \\\n    .groupby(\"misspelling\").first().reset_index() \\  #4\n    .sort_values(by=[\"correction_counts\", \"misspelling\",  #4\n                     \"misspell_counts\"],  #4\n                 ascending=[False, True, False])[cols] #4\n  return matches\n\nquery_signals = get_search_queries()\nword_list = valid_keyword_occurrences(query_signals, tokenize=True)\ncorrections = calculate_spelling_corrections(word_list)\ndisplay(corrections.head(20)) #5\n```", "```py\nmisspelling   correction  misspell_counts correction_counts edit_dist\n50   iphone3       iphone      6               16854             1\n61   laptopa       laptop      6               14119             1\n62   latop         laptop      5               14119             1\n...\n76   moden         modem       5               3590              1\n77   modum         modem       6               3590              1\n135  tosheba       toshiba     6               3432              1\n34   gates         games       6               3239              1\n84   phono         phone       5               3065              1\n```", "```py\nquery_signals = get_search_queries()\nword_list = valid_keyword_occurrences(query_signals, tokenize=False)\ncorrections = calculate_spelling_corrections(word_list)\ndisplay(corrections.head(20))\n```", "```py\nmisspelling    correction   misspell_counts  correction_counts edit_dist\n181 ipad.          ipad         6                7749              1\n154 hp touchpad 32 hp touchpad  5                7144              3\n155 hp toucpad     hp touchpad  6                7144              1\n153 hp tochpad     hp touchpad  6                7144              1\n190 iphone s4      iphone 4s    5                4642              2\n193 iphone4 s      iphone 4s    5                4642              2\n194 iphones 4s     iphone 4s    5                4642              1\n412 touchpaf       touchpad     5                4019              1\n406 tochpad        touchpad     6                4019              1\n407 toichpad       touchpad     6                4019              1\n229 latop          laptop       5                3625              1\n228 laptopa        laptops      6                3435              1\n237 loptops        laptops      5                3435              1\n205 ipods touch    ipod touch   6                2992              1\n204 ipod tuch      ipod touch   6                2992              1\n165 i pod tuch     ipod touch   5                2992              2\n173 ipad 2         ipad 2       6                2807              1\n215 kimdle         kindle       5                2716              1\n206 ipone          iphone       6                2599              1\n192 iphone3        iphone       6                2599              1\n```"]