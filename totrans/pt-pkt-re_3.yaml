- en: Chapter 3\. Deep Learning Development with PyTorch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3章. 使用PyTorch进行深度学习开发
- en: Now that you have your development environment running and a good understanding
    of tensors and their operations, we can start developing and deploying deep learning
    models with PyTorch. This chapter provides a quick reference to the basic NN development
    process and the PyTorch code needed to execute it.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您的开发环境已经运行，并且对张量及其操作有了很好的理解，我们可以开始使用PyTorch开发和部署深度学习模型。本章提供了基本NN开发过程和执行所需的PyTorch代码的快速参考。
- en: First we’ll review the overall process, then we’ll dive into each stage and
    look at some sample PyTorch code that implements each function. We’ll build off
    what you learned in [Chapter 2](ch02.xhtml#Chapter_2) to load your data into tensors
    and apply data transforms that convert your tensors to suitable inputs for your
    model.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 首先我们将回顾整体过程，然后深入每个阶段，查看一些实现每个功能的示例PyTorch代码。我们将在[第2章](ch02.xhtml#Chapter_2)学到的基础上，将数据加载到张量中，并应用数据转换，将张量转换为模型的合适输入。
- en: You’ll build a deep learning model and train the model using a common training
    loop structure. Then, you’ll test your model’s performance and tweak hyperparameters
    to improve your results and training speed. Finally, we’ll explore ways to deploy
    your model to prototype systems or production. At each stage, I’ll provide commonly
    used PyTorch code for you to use as a reference as you develop your own deep learning
    models.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 您将构建一个深度学习模型，并使用常见的训练循环结构对模型进行训练。然后，您将测试模型的性能，并调整超参数以改善结果和训练速度。最后，我们将探讨将模型部署到原型系统或生产环境的方法。在每个阶段，我将提供常用的PyTorch代码作为您开发自己的深度学习模型的参考。
- en: Future chapters in this book will provide additional examples and cover more
    advanced topics, such as customization, optimization, acceleration, distributed
    training, and advanced deployment. For now, we’ll focus on the basic NN development
    process.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的未来章节将提供更多示例，并涵盖更高级的主题，如定制、优化、加速、分布式训练和高级部署。现在，我们将专注于基本NN开发过程。
- en: The Overall Process
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 整体过程
- en: Although everyone builds their deep learning models in a different way, the
    overall process is pretty much the same. Regardless of whether you are conducting
    supervised learning with labeled data, unsupervised learning with unlabeled data,
    or semisupervised learning with a mixture of both, a basic pipeline is used to
    train, test, and deploy your deep learning models. I will assume that you have
    some familiarity with deep learning model development, but before we get started,
    let’s review the basic deep learning training process. Then I’ll show how you
    can implement this process in PyTorch.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管每个人构建深度学习模型的方式都不同，但整个过程基本上是相同的。无论您是使用带标签数据进行监督学习，使用无标签数据进行无监督学习，还是使用两者混合的半监督学习，都会使用基本的流程来训练、测试和部署您的深度学习模型。我假设您对深度学习模型开发有一定了解，但在开始之前，让我们回顾一下基本的深度学习训练过程。然后我将展示如何在PyTorch中实现这个过程。
- en: '[Figure 3-1](#fig_basic_process) illustrates the most common tasks in deep
    learning development. The first stage is the data preparation stage, in which
    we will load data from an external source and convert it to the appropriate format
    for model training. This data could be images, videos, speech recordings, audio
    files, text, general tabular data, or any combination of these.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图3-1展示了深度学习开发中最常见的任务。第一阶段是数据准备阶段，在这个阶段，我们将从外部来源加载数据，并将其转换为适合模型训练的格式。这些数据可以是图像、视频、语音录音、音频文件、文本、一般的表格数据，或者它们的任意组合。
- en: First, we load this data and convert it to numeric values in the form of tensors.
    The tensors will act as inputs during the model training stage; however, before
    they are passed in, the tensors are usually preprocessed via transforms and grouped
    into batches for better training performance. Thus, the data preparation stage
    takes generic data and converts it to batches of tensors that can be passed into
    your NN model.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们加载这些数据，并将其转换为张量形式的数值。这些张量将在模型训练阶段作为输入；然而，在传入之前，这些张量通常会通过转换进行预处理，并分组成批次以提高训练性能。因此，数据准备阶段将通用数据转换为可以传入NN模型的张量批次。
- en: 'Next, in the model experimentation and development stage, we will design an
    NN model, train the model with our training data, test its performance, and optimize
    our hyperparameters to improve performance to a desired level. To do so, we will
    separate our dataset into three parts: one for training, one for validation, and
    one for testing. We’ll design an NN model and train its parameters with our training
    data. PyTorch provides elegantly designed modules and classes in the `torch.nn`
    module to help you create and train your NNs. We will define a loss function and
    optimizer from a selection of the many built-in PyTorch functions. Then we’ll
    perform backpropagation and update the model parameters in our training loop.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在模型实验和开发阶段，我们将设计一个NN模型，使用训练数据训练模型，测试其性能，并优化我们的超参数以提高性能到期望水平。为此，我们将将数据集分为三部分：一部分用于训练，一部分用于验证，一部分用于测试。我们将设计一个NN模型，并使用训练数据训练其参数。PyTorch在`torch.nn`模块中提供了优雅设计的模块和类，帮助您创建和训练您的NN。我们将从众多内置的PyTorch函数中定义损失函数和优化器。然后，我们将执行反向传播，并在训练循环中更新模型参数。
- en: '![“Basic Deep Learning Development Process”](Images/ptpr_0301.PNG)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![“基本深度学习开发过程”](Images/ptpr_0301.PNG)'
- en: Figure 3-1\. The basic deep learning development process
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-1. 基本深度学习开发过程
- en: Within each epoch, we’ll also validate our model by passing in validation data,
    measuring performance, and potentially tuning hyperparameters. Finally, we’ll
    test our model by passing in test data and measuring the model’s performance against
    unseen data. In practice, validation and test loops may be optional, but we show
    them here for completeness.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个epoch内，我们还将通过传入验证数据来验证我们的模型，衡量性能，并可能调整超参数。最后，我们将通过传入测试数据来测试我们的模型，并根据未知数据的性能来衡量模型的表现。在实践中，验证和测试循环可能是可选的，但我们在这里展示它们以确保完整性。
- en: The last stage of deep learning model development is the model deployment stage.
    In this stage, we have a fully trained model—so what do we do with it? If you
    are a deep learning research scientist conducting experiments, you may want to
    simply save the model to a file and load it for further research and experimentation,
    or you may want to provide access to it via a repository like PyTorch Hub. You
    may also want to deploy it to an edge device or local server to demonstrate a
    prototype or a proof of concept.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型开发的最后阶段是模型部署阶段。在这个阶段，我们有一个完全训练好的模型——那么我们该怎么办呢？如果您是进行实验的深度学习研究科学家，您可能只想将模型保存到文件中，以便进一步研究和实验，或者您可能希望通过PyTorch
    Hub等存储库提供对其的访问。您还可以将其部署到边缘设备或本地服务器，以演示原型或概念验证。
- en: On the other hand, if you are a software developer or systems engineer, you
    may want to deploy your model to a product or service. In this case, you can deploy
    your model to a production environment on a cloud server or deploy it to an edge
    device or mobile phone. When deploying trained models, the model often requires
    additional postprocessing. For example, you may classify a batch of images, but
    you only want to report the most confident result. The model deployment stage
    also handles any postprocessing that is needed to go from your model’s output
    values to the final solution.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，如果您是软件开发人员或系统工程师，您可能希望将模型部署到产品或服务中。在这种情况下，您可以将模型部署到云服务器上的生产环境，或将其部署到边缘设备或手机上。在部署经过训练的模型时，模型通常需要额外的后处理。例如，您可能要对一批图像进行分类，但只想报告最有信心的结果。模型部署阶段还处理从模型的输出值到最终解决方案所需的任何后处理。
- en: Now that we’ve explored the overall development process, let’s dive into each
    part and show how PyTorch can help you develop deep learning models.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了整个开发过程，让我们深入每个部分，展示PyTorch如何帮助您开发深度学习模型。
- en: Data Preparation
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据准备
- en: The first stage of deep learning development starts with data preparation. In
    this stage, we acquire data to train and test our NN models and convert it to
    a tensor of numbers that our PyTorch models can process. The size of the dataset
    and the data itself are important to developing good models; however, generating
    good datasets is beyond the scope of this book.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习开发的第一阶段始于数据准备。在这个阶段，我们获取数据来训练和测试我们的NN模型，并将其转换为数字张量，以便我们的PyTorch模型可以处理。数据集的大小和数据本身对于开发良好的模型很重要；然而，生成良好的数据集超出了本书的范围。
- en: In this section, I’ll assume that you’ve already determined the data is good,
    so I’ll focus on describing how to load the data, apply transforms, and batch
    the data using PyTorch’s built-in capabilities. First I’ll show how you can prepare
    image data with the `torchvision` package, then we’ll explore PyTorch resources
    for preparing other types of data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我将假设您已经确定数据是好的，因此我将重点介绍如何使用PyTorch的内置功能加载数据、应用转换并对数据进行批处理。首先我将展示如何使用`torchvision`包准备图像数据，然后我们将探索PyTorch资源以准备其他类型的数据。
- en: Data Loading
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据加载
- en: PyTorch provides powerful built-in classes and utilities, such as the `Dataset`,
    `DataLoader`, and `Sampler` classes, for loading various types of data. The `Dataset`
    class defines how to access and preprocess data from a file or data sources. The
    `Sampler` class defines how to sample data from a dataset in order to create batches,
    while the `DataLoader` class combines a dataset with a sampler and allows you
    to iterate over a set of batches.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch提供了强大的内置类和实用程序，如`Dataset`、`DataLoader`和`Sampler`类，用于加载各种类型的数据。`Dataset`类定义了如何从文件或数据源访问和预处理数据。`Sampler`类定义了如何从数据集中采样数据以创建批次，而`DataLoader`类将数据集与采样器结合在一起，允许您迭代一组批次。
- en: PyTorch libraries such as Torchvision and Torchtext also provide classes to
    support specialized data like computer vision and natural language data. The `torchvision.datasets`
    module is a good example of how to utilize built-in classes to load data. The
    `torchvision.datasets` module provides a number of subclasses to load image data
    from popular academic datasets.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch库如Torchvision和Torchtext还提供支持专门数据的类，如计算机视觉和自然语言数据。`torchvision.datasets`模块是如何利用内置类加载数据的一个很好的例子。`torchvision.datasets`模块提供了许多子类来从流行的学术数据集加载图像数据。
- en: 'One of these popular datasets is CIFAR-10\. The CIFAR-10 dataset was collected
    by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton during their research for
    the Canadian Institute for Advanced Research (CIFAR). It consists of 50,000 training
    images and 10,000 test images of 10 possible objects: airplanes, cars, birds,
    cats, deer, dogs, frogs, horses, ships, and trucks. The following code shows how
    to use CIFAR-10 to create a training dataset:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 其中一个流行的数据集是CIFAR-10。CIFAR-10数据集是由Alex Krizhevsky、Vinod Nair和Geoffrey Hinton在为加拿大高级研究所（CIFAR）进行研究时收集的。它包含50,000个训练图像和10,000个测试图像，涵盖了10种可能的对象：飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船和卡车。以下代码展示了如何使用CIFAR-10创建一个训练数据集：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The `train` parameter determines whether we load the training data or the testing
    data, and setting `download` to `True` will download the data for us if we don’t
    have it already.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '`train`参数确定我们加载训练数据还是测试数据，将`download`设置为`True`将为我们下载数据（如果我们还没有）。'
- en: 'Let’s explore the `train_data` dataset object. We can access information about
    the dataset using its methods and attributes as shown in the following code:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索`train_data`数据集对象。我们可以使用其方法和属性访问有关数据集的信息，如下面的代码所示：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![1](Images/1.png)](#comarker11)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#comarker11)'
- en: Printing the object returns its general information.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 打印对象会返回其一般信息。
- en: '[![2](Images/2.png)](#comarker22)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#comarker22)'
- en: Check the number of data samples with `len()`.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`len()`检查数据样本的数量。
- en: '[![3](Images/3.png)](#comarker33)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#comarker33)'
- en: The data is a NumPy array of 50,000 32 × 32-pixel color images.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 数据是一个包含50,000个32×32像素彩色图像的NumPy数组。
- en: '[![4](Images/4.png)](#comarker44)'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#comarker44)'
- en: The targets are a list of 50,000 data labels.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 目标是一个包含50,000个数据标签的列表。
- en: '[![5](Images/5.png)](#comarker55)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](Images/5.png)](#comarker55)'
- en: You can map numeric labels to class names using `classes`.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用`classes`将数值标签映射到类名。
- en: '[![6](Images/6.png)](#comarker66)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](Images/6.png)](#comarker66)'
- en: You can map class names to index values using `class_to_idx`.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用`class_to_idx`将类名映射到索引值。
- en: 'Let’s take a closer look at the `train_data` dataset’s data and labels. We
    can access a data sample using an index, as shown in the following code:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仔细看看`train_data`数据集的数据和标签。我们可以使用索引访问数据样本，如下面的代码所示：
- en: '[PRE2]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As you can see in the code, `train_data[0]` returns a tuple with two elements—the
    data and the label. Let’s examine the data first:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如代码中所示，`train_data[0]`返回一个包含两个元素的元组——数据和标签。让我们先检查数据：
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The data consists of a PIL image object. PIL is a common image format that uses
    the Pillow library to store image pixel values in the format of height × width
    × channels. A color image has three channels (RGB) for red, green, and blue. The
    data format is good to know because we may need to convert this format for our
    model if the model expects a different format (more on this later).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 数据由一个PIL图像对象组成。PIL是一种常见的图像格式，使用Pillow库以高度×宽度×通道的格式存储图像像素值。彩色图像有三个通道（RGB）分别为红色、绿色和蓝色。了解数据格式很重要，因为如果模型期望不同的格式，我们可能需要转换这种格式（稍后会详细介绍）。
- en: '[Figure 3-2](#fig_pil_image) shows the PIL image. It’s a little blurry because
    the resolution is only 32 × 32, but can you tell what it is?'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[图3-2](#fig_pil_image)显示了PIL图像。由于分辨率只有32×32，所以有点模糊，但你能猜出是什么吗？'
- en: '![“Sample Image”](Images/ptpr_0302.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![“示例图像”](Images/ptpr_0302.png)'
- en: Figure 3-2\. Sample image
  id: totrans-46
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-2\. 示例图像
- en: 'Let’s examine the label:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查标签：
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In the code, the `label` is an integer value representing the class of the image
    (e.g., airplane, dog, etc.). We can use the `classes` attribute to see that an
    index of 6 corresponds to a frog.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，`label`是一个表示图像类别的整数值（例如，飞机、狗等）。我们可以使用`classes`属性查看索引6对应于青蛙。
- en: 'We can also load the test data into another dataset object called `test_data`.
    Changing the root folder and setting the `train` flag to `False` will do the trick,
    as shown in the following code:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以将测试数据加载到另一个名为`test_data`的数据集对象中。更改根文件夹并将`train`标志设置为`False`即可，如下面的代码所示：
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The `test_data` dataset is similar to the `train_data` dataset. However, there
    are only 10,000 images in the test dataset. Try accessing some of the methods
    from the dataset class and the attributes on the `test_data` dataset yourself.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '`test_data`数据集与`train_data`数据集类似。但是测试数据集中只有10,000张图像。尝试访问数据集类的一些方法和`test_data`数据集上的属性。'
- en: Data Transforms
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据转换
- en: In the data loading step, we pulled data from its source and created dataset
    objects that contain information about the dataset and the data itself. However,
    the data might need to be adjusted before it is passed into the NN model for training
    and testing. For example, data values may be normalized to assist training, augmented
    to create larger datasets, or converted from one type of object to a tensor.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据加载步骤中，我们从数据源中提取数据并创建包含有关数据集和数据本身信息的数据集对象。但是，在将数据传递到NN模型进行训练和测试之前，数据可能需要进行调整。例如，数据值可能需要归一化以帮助训练，进行增强以创建更大的数据集，或者从一种对象类型转换为张量。
- en: These adjustments are accomplished by applying *transforms*. The beauty of using
    transforms in PyTorch is that you can define a sequence of transforms and apply
    it when the data is accessed. Later, in [Chapter 5](ch05.xhtml#Chapter_5), you’ll
    see how you can even apply transforms on a CPU in parallel with your training
    on a GPU.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这些调整是通过应用*transforms*来完成的。在PyTorch中使用transforms的美妙之处在于你可以定义一系列transforms并在访问数据时应用它。稍后在[第5章](ch05.xhtml#Chapter_5)中，你将看到如何在CPU上并行应用transforms，同时在GPU上进行训练。
- en: 'In the following code example, we’ll define our transforms and create our `train_data`
    dataset using these transforms:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码示例中，我们将定义我们的transforms并使用这些transforms创建我们的`train_data`数据集：
- en: '[PRE6]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[![1](Images/1.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO1-1)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO1-1)'
- en: The mean and standard deviation values here were predetermined based on the
    dataset itself.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的均值和标准差值是根据数据集本身预先确定的。
- en: '[![2](Images/2.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO1-2)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO1-2)'
- en: Set the `transform` parameter when creating the dataset.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 创建数据集时设置`transform`参数。
- en: We define a set of transforms using the `transforms.Compose()` class. This class
    accepts a list of transforms and applies them in sequence. Here we randomly crop
    and flip images, convert them to tensors, and normalize the tensor values to predetermined
    means and standard deviations.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`transforms.Compose()`类定义一组transforms。这个类接受一个transforms列表并按顺序应用它们。这里我们随机裁剪和翻转图像，将它们转换为张量，并将张量值归一化为预定的均值和标准差。
- en: The transforms are passed to the dataset class during instantiation and become
    part of the dataset object. The transforms are applied whenever the dataset object
    is accessed, returning a new result consisting of the transformed data.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: transforms在实例化数据集类时传递，并成为数据集对象的一部分。每当访问数据集对象时都会应用transforms，返回一个由转换后的数据组成的新结果。
- en: 'We can view the transforms by printing the dataset or its `transforms` attribute,
    as shown in the following code:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过打印数据集或其`transforms`属性来查看transforms，如下面的代码所示：
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We can access the data using indexing, as shown in the next code block. PyTorch
    automatically applies the transforms when the data is accessed, so the output
    data will be different from what we saw earlier:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用索引访问数据，如下一个代码块所示。PyTorch在访问数据时会自动应用transforms，因此输出数据将与之前看到的不同：
- en: '[PRE8]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: As you can see, the data output is now a tensor of size 3 × 32 × 32\. It has
    also been randomly cropped, horizontally flipped, and normalized. [Figure 3-3](#fig_image_transformed)
    shows the image after applying the transforms.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，数据输出现在是一个大小为3×32×32的张量。它也已经被随机裁剪、水平翻转和归一化。[图3-3](#fig_image_transformed)显示了应用transforms后的图像。
- en: '![“Image After Transforms”](Images/ptpr_0303.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![“变换后的图像”](Images/ptpr_0303.png)'
- en: Figure 3-3\. Image after transforms
  id: totrans-70
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图3-3。变换后的图像
- en: The colors may look strange because of the normalization, but this actually
    helps NN models do a better job of classifying the images.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 颜色可能看起来奇怪是因为归一化，但这实际上有助于神经网络模型更好地对图像进行分类。
- en: 'We can define a different set of transforms for testing and apply them to our
    test data as well. In the case of test data, we do not want to crop or flip the
    image, but we do need to convert the image to tensors and normalize the tensor
    values, as shown in the following code:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以为测试定义不同的变换集，并将其应用于我们的测试数据。在测试数据的情况下，我们不希望裁剪或翻转图像，但我们确实需要将图像转换为张量并对张量值进行归一化，如下所示：
- en: '[PRE9]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Data Batching
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据批处理
- en: Now that we have defined the transforms and created the datasets, we can access
    data samples one at a time. However, when you train your model, you will want
    to pass in small batches of data at each iteration, as we will see in [“Model
    Development”](#model-dev-section). Sending data in batches not only allows more
    efficient training but also takes advantage of the parallel nature of GPUs to
    accelerate training.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了变换并创建了数据集，我们可以逐个访问数据样本。然而，当训练模型时，您将希望在每次迭代中传递小批量的数据，正如我们将在[“模型开发”](#model-dev-section)中看到的。将数据分批不仅可以实现更高效的训练，还可以利用GPU的并行性加速训练。
- en: Batch processing can easily be implemented using the `torch.utils.data.DataLoader`
    class. Let’s start with an example of how Torchvision uses this class, and then
    we’ll cover it in more detail.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 批处理可以很容易地使用`torch.utils.data.DataLoader`类实现。让我们从Torchvision如何使用这个类的示例开始，然后我们将更详细地介绍它。
- en: 'In the following code, we create a dataloader for `train_data` that we can
    use to load a batch of samples and apply our transforms:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的代码中，我们为`train_data`创建一个数据加载器，可以用来加载一批样本并应用我们的变换：
- en: '[PRE10]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: We use a batch size of 16 samples and shuffle our dataset so that the dataloader
    retrieves a random sampling of the data.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用批量大小为16个样本，并对数据集进行洗牌，以便数据加载器检索数据的随机抽样。
- en: The dataloader object combines a dataset and a sampler, and provides an iterable
    over the given dataset. In other words, your training loop can use this object
    to sample your dataset and apply transforms one batch at a time instead of applying
    them for the complete dataset at once. This considerably improves efficiency and
    speed when training and testing models.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 数据加载器对象结合了数据集和采样器，并为给定数据集提供了一个可迭代的对象。换句话说，您的训练循环可以使用此对象对数据集进行抽样，并一次一个批次地应用变换，而不是一次性地对整个数据集应用变换。这在训练和测试模型时显著提高了效率和速度。
- en: 'The following code shows how to retrieve a batch of samples from the `trainloader`:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了如何从`trainloader`中检索一批样本：
- en: '[PRE11]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We need to use `iter()` to cast the `trainloader` to an iterator and then use
    `next()` to iterate over the data one more time. This is only necessary when accessing
    one batch. As we’ll see later, our training loops will access the dataloader directly
    without the need for `iter()` and `next()`. After checking the sizes of the data
    and labels, we see they return batches of size 16.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要使用`iter()`将`trainloader`转换为迭代器，然后使用`next()`再次迭代数据。这仅在访问一个批次时才是必要的。正如我们将在后面看到的，我们的训练循环将直接访问数据加载器，而无需使用`iter()`和`next()`。检查数据和标签的大小后，我们看到它们返回大小为16的批次。
- en: 'We can create a dataloader for our `test_data` dataset as shown in the following
    code:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以为我们的`test_data`数据集创建一个数据加载器，如下所示：
- en: '[PRE12]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Here, we set `shuffle` to `False` since there’s usually no need to shuffle the
    test data and researchers like to see repeatable test results.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将`shuffle`设置为`False`，因为通常不需要对测试数据进行洗牌，研究人员希望看到可重复的测试结果。
- en: General Data Preparation (torch.utils.data)
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通用数据准备（torch.utils.data）
- en: So far, I’ve shown you how to load, transform, and batch image data using Torchvision.
    However, you can use PyTorch to prepare other types of data as well. PyTorch libraries
    such as Torchtext and Torchaudio provide dataset and dataloader classes for text
    and audio data, and new external libraries are being developed all the time.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我已经向您展示了如何使用Torchvision加载、转换和批处理图像数据。然而，您也可以使用PyTorch准备其他类型的数据。PyTorch库如Torchtext和Torchaudio为文本和音频数据提供了数据集和数据加载器类，新的外部库也在不断开发中。
- en: PyTorch also provides a submodule called `torch.utils.data` that you can use
    to create your own dataset and dataloader classes like the ones you saw in Torchvision.
    It consists of `Dataset`, `Sampler`, and `DataLoader` classes.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch还提供了一个名为`torch.utils.data`的子模块，您可以使用它来创建自己的数据集和数据加载器类，就像您在Torchvision中看到的那样。它包括`Dataset`、`Sampler`和`DataLoader`类。
- en: Dataset classes
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据集类
- en: PyTorch supports map- and iterable-style dataset classes. A *map-style dataset*
    is derived from the abstract class `torch.utils.data.Dataset`. It implements the
    `getitem()` and `len()` functions, and represents a map from (possibly nonintegral)
    indices/keys to data samples. For example, such a dataset, when accessed with
    `dataset[idx]`, could read the idx-th image and its corresponding label from a
    folder on the disk. Map-style datasets are more commonly used than iterable-style
    datasets, and all datasets that represent a map made from keys or data samples
    should use this subclass.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch支持映射和可迭代样式的数据集类。*映射样式数据集*源自抽象类`torch.utils.data.Dataset`。它实现了`getitem()`和`len()`函数，并表示从（可能是非整数）索引/键到数据样本的映射。例如，当使用`dataset[idx]`访问这样的数据集时，可以从磁盘上的文件夹中读取第idx个图像及其对应的标签。映射样式数据集比可迭代样式数据集更常用，所有表示由键或数据样本制成的映射的数据集都应该使用这个子类。
- en: Tip
  id: totrans-92
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: The simplest way to create your own dataset class is to subclass the map-style
    `torch.utils.data.Dataset` class and override the `getitem()` and `len()` functions
    with your own code.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 创建自己的数据集类的最简单方法是子类化映射样式的`torch.utils.data.Dataset`类，并使用自己的代码重写`getitem()`和`len()`函数。
- en: All subclasses should overwrite `getitem()`, which fetches a data sample for
    a given key. Subclasses can also optionally overwrite `len()`, which returns the
    size of the dataset by many `Sampler` implementations and the default options
    of `DataLoader`.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 所有子类都应该重写`getitem()`，它为给定键获取数据样本。子类也可以选择重写`len()`，它返回数据集的大小，由许多`Sampler`实现和`DataLoader`的默认选项使用。
- en: An *iterable-style dataset*, on the other hand, is derived from the `torch.utils.data.IterableDataset`
    abstract class. It implements the `iter()` protocol and represents an iterable
    over data samples. This type of dataset is typically used when reading data from
    a database or a remote server, as well as data generated in real time. Iterable
    datasets are useful when random reads are expensive or uncertain, and when the
    batch size depends on fetched data.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，*可迭代样式数据集*派生自`torch.utils.data.IterableDataset`抽象类。它实现了`iter()`协议，并表示数据样本的可迭代。当从数据库或远程服务器读取数据以及实时生成数据时，通常使用这种类型的数据集。当随机读取昂贵或不确定时，以及批次大小取决于获取的数据时，可迭代数据集非常有用。
- en: 'PyTorch’s `torch.utils.data` submodule also provides dataset operations to
    convert, combine, or split dataset objects. These operations include the following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch的`torch.utils.data`子模块还提供了数据集操作，用于转换、组合或拆分数据集对象。这些操作包括以下内容：
- en: '`TensorDataset(*tensors*)`'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`TensorDataset(*tensors*)`'
- en: Creates a dataset object from a tensor
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 从张量创建数据集对象
- en: '`ConcatDataset(*datasets*)`'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`ConcatDataset(*datasets*)`'
- en: Creates a dataset from multiple datasets
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 从多个数据集创建数据集
- en: '`ChainDataset(*datasets*)`'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '`ChainDataset(*datasets*)`'
- en: Chains multiple `IterableDatasets`
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 多个`IterableDatasets`链接
- en: '`Subset(*dataset*, *indices*)`'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`Subset(*dataset*, *indices*)`'
- en: Creates a subset of a dataset from specified indices
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 从指定索引创建数据集的子集
- en: Sampler classes
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 采样器类
- en: In addition to dataset classes PyTorch also provides sampler classes, which
    offer a way to iterate over indices of dataset samples. Sampler are derived from
    the `torch.utils.data.Sampler` base class.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 除了数据集类，PyTorch还提供了采样器类，它们提供了一种迭代数据集样本索引的方法。采样器派生自`torch.utils.data.Sampler`基类。
- en: Every `Sampler` subclass needs to implement an `iter()` method to provide a
    way to iterate over indices of dataset elements and a `len()` method that returns
    the length of the returned iterators. [Table 3-1](#table_dataset_samplers) provides
    a list of available samplers for your reference.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 每个`Sampler`子类都需要实现一个`iter()`方法，以提供迭代数据元素索引的方法，以及一个返回迭代器长度的`len()`方法。[表3-1](#table_dataset_samplers)提供了可用采样器的列表供参考。
- en: Table 3-1\. Dataset samplers (`torch.utils.data`)
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-1\. 数据集采样器（`torch.utils.data`）
- en: '| Sampler | Description |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| Sampler | 描述 |'
- en: '| --- | --- |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `SequentialSampler(`*`data_source`*`)` | Samples data in sequence |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| `SequentialSampler(`*`data_source`*`)` | 按顺序采样数据 |'
- en: '| `RandomSampler(`*`data_source, replacement=False,`* *`num_samples=None,`*
    *`generator=None`*`)` | Samples data randomly |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| `RandomSampler(`*`data_source, replacement=False,`* *`num_samples=None,`*
    *`generator=None`*`)` | 随机采样数据 |'
- en: '| `SubsetRandomSampler(`*`indices,`* *`generator=None`*`)` | Samples data randomly
    from a subset of the dataset |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| `SubsetRandomSampler(`*`indices,`* *`generator=None`*`)` | 从数据集的子集中随机采样数据
    |'
- en: '| `WeightedRandomSampler(`*`weights,`* *`num_samples,`* *`replacement=True,`*
    *`generator=None`*`)` | Samples randomly from a weighted distribution |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| `WeightedRandomSampler(`*`weights,`* *`num_samples,`* *`replacement=True,`*
    *`generator=None`*`)` | 从加权分布中随机采样 |'
- en: '| `BatchSampler(`*`sampler, batch_size, drop_last`*`)` | Returns a batch of
    samples |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| `BatchSampler(`*`sampler, batch_size, drop_last`*`)` | 返回一批样本 |'
- en: '| `distributed.DistributedSampler(`*`dataset,`* *`num_replicas=None,`* *`rank=None,`*
    *`shuffle=True,`* *`seed=0`*`)` | Samples across distributed datasets |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| `distributed.DistributedSampler(`*`dataset,`* *`num_replicas=None,`* *`rank=None,`*
    *`shuffle=True,`* *`seed=0`*`)` | 在分布式数据集上采样 |'
- en: Samplers are usually not used directly. They are often passed to dataloaders
    to define the way the dataloader samples the dataset.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 通常不直接使用采样器。它们通常传递给数据加载器，以定义数据加载器对数据集进行采样的方式。
- en: DataLoader classes
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: DataLoader类
- en: The `Dataset` class returns a dataset object that includes data and information
    about the data. The `Sampler` class returns the actual data itself in a specified
    or random fashion. The `DataLoader` class combines a dataset with a sampler and
    returns an iterable.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '`Dataset`类返回一个包含数据和数据信息的数据集对象。`Sampler`类以指定或随机的方式返回实际数据本身。`DataLoader`类将数据集与采样器结合起来，并返回一个可迭代对象。'
- en: 'The dataset and sampler objects are not iterables, meaning you cannot run a
    `for` loop on them. The dataloader object solves this problem. We used the `DataLoader`
    class to construct a dataloader object for our CIFAR-10 example earlier in this
    chapter. The `DataLoader` prototype is shown in the following code:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集和采样器对象不是可迭代的，这意味着您不能在它们上运行`for`循环。数据加载器对象解决了这个问题。我们在本章前面的CIFAR-10示例中使用`DataLoader`类构建了一个数据加载器对象。以下是`DataLoader`的原型：
- en: '[PRE13]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The `dataset`, `batch_size`, `shuffle`, and `sampler` parameters are the most
    commonly used. The `num_workers` parameter is often used to increase the number
    of CPU processes that generate batches in parallel. The rest of the parameters
    are used only for advanced cases.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '`dataset`、`batch_size`、`shuffle`和`sampler`参数是最常用的。`num_workers`参数通常用于增加生成批次的CPU进程数量。其余参数仅用于高级情况。'
- en: If you write your own dataset class, all you need to do is call the built-in
    `DataLoader` to generate an iterable for your data. There is no need to create
    a dataloader class from scratch.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您编写自己的数据集类，您只需要调用内置的`DataLoader`来为您的数据生成一个可迭代对象。无需从头开始创建数据加载器类。
- en: This section provided a quick reference to the data preparation capabilities
    of PyTorch. Now that you understand how you can load, transform, and batch your
    data with PyTorch, you can begin to use your data to develop and train deep learning.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了PyTorch数据准备功能的快速参考。现在您了解了如何使用PyTorch加载、转换和批处理数据，可以开始使用您的数据来开发和训练深度学习。
- en: Model Development
  id: totrans-125
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型开发
- en: Most research and development is focused on developing new and innovative deep
    learning models. The model development process consists of several steps. At this
    point, I assume that you have created good datasets and have prepared them for
    processing by your model.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数研究和开发都集中在开发新颖的深度学习模型上。模型开发过程包括几个步骤。在这一点上，我假设您已经创建了良好的数据集，并已经准备好让模型处理。
- en: The first step in the process is model design, in which you design one or more
    model architectures and initialize the model’s parameters (e.g., weights and biases.)
    It’s common practice to start with an existing design and then modify it or create
    your own. I’ll show you how to do both in this section.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 过程中的第一步是模型设计，您将设计一个或多个模型架构并初始化模型的参数（例如权重和偏差）。通常的做法是从现有设计开始，然后修改它或创建自己的设计。我将在本节中向您展示如何做这两种操作。
- en: The next step is training. During training you’ll pass training data through
    your model, measure the error or loss, and adjust the parameters to improve the
    results.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是训练。在训练过程中，您将通过模型传递训练数据，测量误差或损失，并调整参数以改善结果。
- en: During validation, you’ll measure the performance of your model against validation
    data that was not used during training. This helps to guard against *overfitting*,
    where the model performs well against training data but does not generalize to
    other input data.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在验证过程中，您将测量模型在未在训练中使用的验证数据上的性能。这有助于防止*过拟合*，即模型在训练数据上表现良好，但不能泛化到其他输入数据。
- en: Finally, the model development process often concludes with testing. Testing
    is when you measure the performance of your trained model against previously unseen
    data. This section provides a quick reference on how to accomplish the steps and
    substeps of model development in PyTorch.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，模型开发过程通常以测试结束。测试是指您测量经过训练的模型在之前未见数据上的性能。本节提供了如何在PyTorch中完成模型开发的步骤和子步骤的快速参考。
- en: Model Design
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型设计
- en: Model design research has expanded significantly over the past decade, in all
    industries and fields. Thousands of papers are written every year in areas like
    computer vision, natural language processing, speech recognition, and audio processing
    to solve problems such as early cancer detection and innovate new technologies
    such as self-driving cars. As a result, there are many different types of model
    architectures to choose from, depending on the problem you’re trying to solve.
    You may even create some of your own!
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的十年中，模型设计研究在所有行业和领域都有了显著的扩展。每年都会有成千上万篇论文涉及计算机视觉、自然语言处理、语音识别和音频处理等领域，以解决早期癌症检测等问题，并创新出自动驾驶汽车等新技术。因此，根据您要解决的问题，可以选择许多不同类型的模型架构。您甚至可以创建一些自己的模型！
- en: Using existing and pretrained models
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用现有和预训练模型
- en: Most users begin model development by selecting an existing model. Maybe you
    would like to start off with an existing design and make minor modifications or
    experiment with small improvements before designing your own architecture. You
    can also use models or parts of an existing model that have already been trained
    with tons of data.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数用户开始模型开发时会选择一个现有的模型。也许您想要从现有设计开始，进行轻微修改或尝试小的改进，然后再设计自己的架构。您还可以使用已经用大量数据训练过的现有模型或模型部分。
- en: PyTorch provides many resources to leverage existing model designs and pretrained
    NNs. One example resource is the PyTorch-based `torchvision` library for computer
    vision. The `torchvision.models` subpackage contains definitions of models for
    addressing different tasks, including image classification, pixelwise semantic
    segmentation, object detection, instance segmentation, person keypoint detection,
    and video classification.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch提供了许多资源来利用现有的模型设计和预训练的神经网络。一个示例资源是基于PyTorch的`torchvision`库，用于计算机视觉。`torchvision.models`子包含有不同任务的模型定义，包括图像分类、像素级语义分割、目标检测、实例分割、人体关键点检测和视频分类。
- en: Let’s say we want to use the famous VGG16 model for our design. VGG16 (also
    called OxfordNet) is a convolutional NN architecture named after the Visual Geometry
    Group from Oxford, who developed it. It was submitted to the Large Scale Visual
    Recognition Challenge in 2014 and achieved 92.7% top-5 test accuracy on ImageNet,
    a very large dataset of 14 million hand-annotated images.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想要在设计中使用著名的VGG16模型。VGG16（也称为OxfordNet）是一种卷积神经网络架构，以牛津大学的视觉几何组命名，他们开发了这个模型。它在2014年提交到大规模视觉识别挑战，并在ImageNet上取得了92.7%的前5测试准确率，ImageNet是一个包含1400万手工注释图像的非常庞大的数据集。
- en: 'We can easily create a pretrained VGG16 model as shown in the following code:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以轻松地创建一个预训练的VGG16模型，如下面的代码所示：
- en: '[PRE14]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: By default, the model will be untrained and have randomly initialized weights.
    However, in our situation we want to use a pretrained model, so we set `pretrained
    = True`. This downloads the weights that were pretrained with the ImageNet dataset
    and initializes our model’s weights with these values.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，模型将是未经训练的，并且具有随机初始化的权重。但是，在我们的情况下，我们希望使用预训练模型，因此我们设置`pretrained = True`。这将下载在ImageNet数据集上预训练的权重，并使用这些值初始化我们模型的权重。
- en: 'You can view the sequence of layers contained in the VGG16 model by printing
    the model. The VGG16 model consists of three parts: `features`, `avgpool`, and
    `classifier`. It’s too large to print all the layers here, so we’ll just print
    the `classifier` part:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过打印模型来查看VGG16模型中包含的层序列。VGG16模型由三部分组成：`features`、`avgpool`和`classifier`。这里无法打印所有层，所以我们只打印`classifier`部分：
- en: '[PRE15]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '`Linear`, `ReLU`, and `Dropout` are `torch.nn` modules. `torch.nn` is used
    to create NN layers, activations, loss functions, and other NN components. Don’t
    worry about it too much right now; we’ll cover it in more detail in the next section.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '`Linear`、`ReLU`和`Dropout`是`torch.nn`模块。`torch.nn`用于创建神经网络层、激活函数、损失函数和其他神经网络组件。现在不要太担心它；我们将在下一节中详细介绍。'
- en: There are many famous untrained and pretrained models available, including AlexNet,
    VGG, ResNet, Inception, and MobileNet, to name a few. Refer to [the Torchvision
    model documentation](https://pytorch.tips/torchvision-models) for a complete list
    of models and details regarding their use.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多著名的未经训练和经过预训练的模型可用，包括AlexNet、VGG、ResNet、Inception和MobileNet等。请参考[Torchvision模型文档](https://pytorch.tips/torchvision-models)获取完整的模型列表以及有关它们使用的详细信息。
- en: 'PyTorch Hub is another excellent resource for existing and pretrained PyTorch
    models. You can load models from another repository using the `torch.hub.load()`
    API. The following code shows how you would load a model from PyTorch Hub:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch Hub是另一个用于现有和预训练PyTorch模型的优秀资源。您可以使用`torch.hub.load()`API从另一个存储库加载模型。以下代码显示了如何从PyTorch
    Hub加载模型：
- en: '[PRE16]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Here we load a model called WaveGlow that is used to generate speech from the
    NVIDIA DeepLearningExamples repository.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们加载一个名为WaveGlow的模型，用于从NVIDIA DeepLearningExamples存储库生成语音。
- en: 'You can find a list of PyTorch Hub repositories at [the main PyTorch Hub site.](https://pytorch.tips/pytorch-hub)
    To explore all the available API endpoints of a particular repository you can
    use the `torch.hub.list()` function on the repository, as shown in the following
    code:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[主PyTorch Hub网站](https://pytorch.tips/pytorch-hub)找到PyTorch Hub存储库的列表。要探索特定存储库的所有可用API端点，您可以在存储库上使用`torch.hub.list()`函数，如下面的代码所示：
- en: '[PRE17]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This lists all the models available in the *nvidia/DeepLearningExamples:torchhub*
    repo, including WaveGlow, Tacotron 2, SSD, and others. Try using `hub.list()`
    on other repositories that support PyTorch Hub to see what other preexisting models
    you can find.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这列出了*nvidia/DeepLearningExamples:torchhub*存储库中所有可用的模型，包括WaveGlow、Tacotron 2、SSD等。尝试在支持PyTorch
    Hub的其他存储库上使用`hub.list()`，看看您可以找到哪些其他现有模型。
- en: Loading preexisting and pretrained models from Python libraries like Torchvision
    and from repositories through PyTorch Hub allows you to build off previous research
    for your own work. Later in this chapter, I will show you how to deploy your models
    to packages and repositories so that others can access or build off your own research
    and development.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 从Python库（如Torchvision）和通过PyTorch Hub从存储库加载现有和预训练模型，可以让您在自己的工作中建立在以前的研究基础上。在本章后面，我将向您展示如何将您的模型部署到包和存储库中，以便其他人可以访问或基于您自己的研究和开发。
- en: The PyTorch NN module (torch.nn)
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PyTorch NN模块（torch.nn）
- en: 'One of the most powerful features of PyTorch is its Python module `torch.nn`,
    which makes it easy to design and experiment with new models. The following code
    illustrates how you can create a simple model with `torch.nn`. In this example,
    we will create a fully connected model called SimpleNet. It consists of an input
    layer, a hidden layer, and an output layer that takes in 2,048 input values and
    returns 2 output values for classification:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch最强大的功能之一是其Python模块`torch.nn`，它使得设计和尝试新模型变得容易。以下代码说明了如何使用`torch.nn`创建一个简单模型。在这个例子中，我们将创建一个名为SimpleNet的全连接模型。它包括一个输入层、一个隐藏层和一个输出层，接收2,048个输入值并返回2个用于分类的输出值：
- en: '[PRE18]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[![1](Images/1.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO2-1)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO2-1)'
- en: Typically creates layers as class attributes
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 通常将层创建为类属性
- en: '[![2](Images/2.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO2-2)'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO2-2)'
- en: Calls the base class’s `__init__()` function to initialize parameters
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 调用基类的`__init__()`函数来初始化参数
- en: '[![3](Images/3.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO2-3)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO2-3)'
- en: Required to define how the model processes data
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 需要定义模型如何处理数据
- en: Creating a model in PyTorch is said to be very “Pythonic,” meaning it creates
    objects in the preferred Python fashion. We first create a new subclass called
    `SimpleNet` that inherits from the `nn.Module` class, and then we define the `__init__()`
    and `forward()` methods. The `__init__()` function initializes the model parameters
    and the `forward()` function defines how data is passed through our model.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在PyTorch中创建模型被认为是非常“Pythonic”的，意味着它以首选的Python方式创建对象。我们首先创建一个名为`SimpleNet`的新子类，它继承自`nn.Module`类，然后我们定义`__init__()`和`forward()`方法。`__init__()`函数初始化模型参数，而`forward()`函数定义了数据如何通过我们的模型传递。
- en: In `__init__()`, we call the `super()` function to execute the parent `nn.Module`
    class’s `__init__()` method to initialize the class parameters. Then we define
    some layers using the `nn.Linear` module.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在`__init__()`中，我们调用`super()`函数来执行父`nn.Module`类的`__init__()`方法以初始化类参数。然后我们使用`nn.Linear`模块定义一些层。
- en: The `forward()` function defines how data is passed through the network. In
    the `forward()` function, we first use `view()` to reshape the input into a 2,048-element
    vector, then we process the input through each layer and apply `relu()` activation
    functions. Finally, we apply the `softmax()` function and return the output.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '`forward()`函数定义了数据如何通过网络传递。在`forward()`函数中，我们首先使用`view()`将输入重塑为一个包含2,048个元素的向量，然后我们通过每一层处理输入并应用`relu()`激活函数。最后，我们应用`softmax()`函数并返回输出。'
- en: Warning
  id: totrans-163
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: PyTorch uses the term *module* to describe an NN layer or block. Python uses
    this term to describe a library package that you can import. In this book, I’ll
    stick to the PyTorch usage and will use the term *Python module* to describe a
    Python library module.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch使用术语*module*来描述NN层或块。Python使用这个术语来描述一个可以导入的库包。在本书中，我将坚持使用PyTorch的用法，并使用术语*Python模块*来描述Python库模块。
- en: So far, we’ve defined what layers or modules are contained in our SimpleNet
    model, how they are connected, and how the parameters are initialized (through
    `super().init()`).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经定义了SimpleNet模型中包含的层或模块，它们是如何连接的，以及参数是如何初始化的（通过`super().init()`）。
- en: 'The following code shows how to create the model by instantiating the model
    object, called `simplenet`:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了如何通过实例化名为`simplenet`的模型对象来创建模型：
- en: '[PRE19]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[![1](Images/1.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO3-1)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO3-1)'
- en: Instantiate or create the model.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化或创建模型。
- en: '[![2](Images/2.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO3-2)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO3-2)'
- en: Run data through the model (forward pass).
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 通过模型运行数据（前向传递）。
- en: If we print the model, we can see how it’s structured. Executing our model is
    as simple as calling the model object as a function. We pass in the inputs, and
    the model runs the forward pass and returns the outputs.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们打印模型，我们可以看到它的结构。执行我们的模型就像调用模型对象作为函数一样简单。我们传入输入，模型运行前向传递并返回输出。
- en: 'This simple model demonstrates the following decisions you need to make during
    model design:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 这个简单的模型展示了在模型设计过程中需要做出的以下决策：
- en: Module definition
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 模块定义
- en: How will you define the layers of your NN? How will you combine these layers
    into building blocks? In the example, we chose three linear or fully connected
    layers.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 您将如何定义您的NN的层？您将如何将这些层组合成构建块？在这个例子中，我们选择了三个线性或全连接层。
- en: Activation functions
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 激活函数
- en: Which activation functions will you use at the end of each layer or module?
    In the example, we chose to use `relu` activation for the input and hidden layers
    and `softmax` for the output layer.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 您将在每个层或模块的末尾使用哪些激活函数？在这个例子中，我们选择在输入和隐藏层使用`relu`激活，在输出层使用`softmax`。
- en: Module connections
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 模块连接
- en: How will your modules be connected to each other? In the example, we chose to
    simply connect each linear layer in sequence.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 您的模块将如何连接在一起？在这个例子中，我们选择简单地按顺序连接每个线性层。
- en: Output selection
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 输出选择
- en: What output values and formats will be returned? In this example, we return
    two values from the `softmax()` function.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 将返回什么输出值和格式？在这个例子中，我们从`softmax()`函数返回两个值。
- en: The simplicity, flexibility, and Pythonic nature of this paradigm are what make
    PyTorch so popular for deep learning research. PyTorch’s `torch.nn` Python module
    includes classes for creating the building blocks, layers, and activation functions
    required for NN model design. Let’s walk through the different types of building
    blocks available in PyTorch.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 这种范式的简单性、灵活性和Python风格是PyTorch在深度学习研究中如此受欢迎的原因。PyTorch的`torch.nn` Python模块包括用于创建NN模型设计所需的构建块、层和激活函数的类。让我们来看看PyTorch中可用的不同类型的构建块。
- en: '[Table 3-2](#table_nn_containers) provides a list of *NN containers*. You can
    use the container classes to create higher-level sets of building blocks. For
    example, you can use `Sequential` to create a sequence of layers in one block.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '[表3-2](#table_nn_containers)提供了一个*NN容器*列表。您可以使用容器类来创建更高级别的构建块集。例如，您可以使用`Sequential`在一个块中创建一系列层。'
- en: Table 3-2\. PyTorch NN containers
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-2\. PyTorch NN容器
- en: '| Class | Description |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 类 | 描述 |'
- en: '| --- | --- |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `Module` | The base class for all NN modules |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| `Module` | 所有NN模块的基类 |'
- en: '| `Sequential` | A sequential container |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| `Sequential` | 一个顺序容器 |'
- en: '| `ModuleList` | A container that holds submodules in a list |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| `ModuleList` | 一个以列表形式保存子模块的容器 |'
- en: '| `ModuleDict` | A container that holds submodules in a dictionary |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| `ModuleDict` | 一个以字典形式保存子模块的容器 |'
- en: '| `ParameterList` | A container that holds parameters in a list |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| `ParameterList` | 一个以列表形式保存参数的容器 |'
- en: '| `ParameterDict` | A container that holds parameters in a dictionary |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| `ParameterDict` | 一个以字典形式保存参数的容器 |'
- en: Note
  id: totrans-193
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: '`nn.Module` is the base class for all NN building blocks. Your NN may consist
    of a single module or multiple modules containing other modules that may also
    contain modules, creating a hierarchy of building blocks.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '`nn.Module`是所有NN构建块的基类。您的NN可能由单个模块或包含其他模块的多个模块组成，这些模块也可能包含模块，从而创建构建块的层次结构。'
- en: '[Table 3-3](#table_nn_linear) lists a few *linear layers* supported by `torch.nn`.
    `Linear` is commonly used for fully connected layers.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '[表3-3](#table_nn_linear)列出了`torch.nn`支持的一些*线性层*。`Linear`通常用于全连接层。'
- en: Table 3-3\. PyTorch NN linear layers
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-3\. PyTorch NN线性层
- en: '| Class | Description |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| 类 | 描述 |'
- en: '| --- | --- |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `nn.Identity` | A placeholder identity operator that is argument-insensitive
    |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Identity` | 一个占位符身份运算符，不受参数影响 |'
- en: '| `nn.Linear` | A layer that applies a linear transformation to the incoming
    data |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Linear` | 将线性变换应用于传入数据的层 |'
- en: '| `nn.Bilinear` | A layer that applies a bilinear transformation to the incoming
    data |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Bilinear` | 将双线性变换应用于传入数据的层 |'
- en: '[Table 3-4](#table_nn_convolutional) lists several *convolutional layers* supported
    by `torch.nn`. Convolutional layers are used often in deep learning to apply filters
    to data at various stages. As you can see in the table, PyTorch has built-in support
    for 1D, 2D, and 3D convolutions as well as transposed and folded variations.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '[表3-4](#table_nn_convolutional)列出了`torch.nn`支持的几种*卷积层*。卷积层在深度学习中经常用于在各个阶段对数据应用滤波器。正如您在表中看到的，PyTorch内置支持1D、2D和3D卷积以及转置和折叠变体。'
- en: Table 3-4\. PyTorch NN convolutional layers
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-4\. PyTorch NN卷积层
- en: '| Class | Description |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| 类 | 描述 |'
- en: '| --- | --- |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `nn.Conv1d` | Applies a 1D convolution over an input signal composed of several
    input planes |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Conv1d` | 在由多个输入平面组成的输入信号上应用1D卷积 |'
- en: '| `nn.Conv2d` | Applies a 2D convolution over an input signal composed of several
    input planes |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Conv2d` | 在由多个输入平面组成的输入信号上应用2D卷积 |'
- en: '| `nn.Conv3d` | Applies a 3D convolution over an input signal composed of several
    input planes |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Conv3d` | 在由多个输入平面组成的输入信号上应用3D卷积 |'
- en: '| `nn.ConvTranspose1d` | Applies a 1D transposed convolution operator over
    an input image composed of several input planes |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| `nn.ConvTranspose1d` | 在由多个输入平面组成的输入图像上应用1D转置卷积运算符 |'
- en: '| `nn.ConvTranspose2d` | Applies a 2D transposed convolution operator over
    an input image composed of several input planes |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| `nn.ConvTranspose2d` | 在由多个输入平面组成的输入图像上应用2D转置卷积运算符 |'
- en: '| `nn.ConvTranspose3d` | Applies a 3D transposed convolution operator over
    an input image composed of several input planes |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| `nn.ConvTranspose3d` | 对由多个输入平面组成的输入图像应用3D转置卷积运算符 |'
- en: '| `nn.Unfold` | Extracts sliding local blocks from a batched-input tensor |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Unfold` | 从批量输入张量中提取滑动本地块 |'
- en: '| `nn.Fold` | Combines an array of sliding local blocks into a large containing
    tensor |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Fold` | 将滑动本地块的数组组合成一个大的包含张量 |'
- en: '[Table 3-5](#table_nn_pooling) shows the *pooling layers* available in `torch.nn`.
    Pooling is often used to downsample or reduce the complexity of output layers.
    PyTorch supports 1D, 2D, and 3D pooling and max or average pooling methods, including
    their adaptive variations.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '[表3-5](#table_nn_pooling)显示了`torch.nn`中可用的*池化层*。池化通常用于下采样或减少输出层的复杂性。PyTorch支持1D、2D和3D池化以及最大或平均池化方法，包括它们的自适应变体。'
- en: Table 3-5\. PyTorch NN pooling layers
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-5. PyTorch NN池化层
- en: '| Class | Description |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| 类 | 描述 |'
- en: '| --- | --- |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `nn.MaxPool1d` | Applies a 1D max pooling over an input signal composed of
    several input planes |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| `nn.MaxPool1d` | 对由多个输入平面组成的输入信号应用1D最大池化 |'
- en: '| `nn.MaxPool2d` | Applies a 2D max pooling over an input signal composed of
    several input planes |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| `nn.MaxPool2d` | 对由多个输入平面组成的输入信号应用2D最大池化 |'
- en: '| `nn.MaxPool3d` | Applies a 3D max pooling over an input signal composed of
    several input planes |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| `nn.MaxPool3d` | 对由多个输入平面组成的输入信号应用3D最大池化 |'
- en: '| `nn.MaxUnpool1d` | Computes a partial inverse of `MaxPool1d` |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| `nn.MaxUnpool1d` | 计算`MaxPool1d`的部分逆操作 |'
- en: '| `nn.MaxUnpool2d` | Computes a partial inverse of `MaxPool2d` |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '| `nn.MaxUnpool2d` | 计算`MaxPool2d`的部分逆操作 |'
- en: '| `nn.MaxUnpool3d` | Computes a partial inverse of `MaxPool3d` |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| `nn.MaxUnpool3d` | 计算`MaxPool3d`的部分逆操作 |'
- en: '| `nn.AvgPool1d` | Applies a 1D average pooling over an input signal composed
    of several input planes |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| `nn.AvgPool1d` | 对由多个输入平面组成的输入信号应用1D平均池化 |'
- en: '| `nn.AvgPool2d` | Applies a 2D average pooling over an input signal composed
    of several input planes |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| `nn.AvgPool2d` | 对由多个输入平面组成的输入信号应用2D平均池化 |'
- en: '| `nn.AvgPool3d` | Applies a 3D average pooling over an input signal composed
    of several input planes |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| `nn.AvgPool3d` | 对由多个输入平面组成的输入信号应用3D平均池化 |'
- en: '| `nn.FractionalMaxPool2d` | Applies a 2D fractional max pooling over an input
    signal composed of several input planes |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| `nn.FractionalMaxPool2d` | 对由多个输入平面组成的输入信号应用2D分数最大池化 |'
- en: '| `nn.LPPool1d` | Applies a 1D power-average pooling over an input signal composed
    of several input planes |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| `nn.LPPool1d` | 对由多个输入平面组成的输入信号应用1D幂平均池化 |'
- en: '| `nn.LPPool2d` | Applies a 2D power-average pooling over an input signal composed
    of several input planes |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| `nn.LPPool2d` | 对由多个输入平面组成的输入信号应用2D幂平均池化 |'
- en: '| `nn.AdaptiveMaxPool1d` | Applies a 1D adaptive max pooling over an input
    signal composed of several input planes |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| `nn.AdaptiveMaxPool1d` | 对由多个输入平面组成的输入信号应用1D自适应最大池化 |'
- en: '| `nn.AdaptiveMaxPool2d` | Applies a 2D adaptive max pooling over an input
    signal composed of several input planes |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| `nn.AdaptiveMaxPool2d` | 对由多个输入平面组成的输入信号应用2D自适应最大池化 |'
- en: '| `nn.AdaptiveMaxPool3d` | Applies a 3D adaptive max pooling over an input
    signal composed of several input planes |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| `nn.AdaptiveMaxPool3d` | 对由多个输入平面组成的输入信号应用3D自适应最大池化 |'
- en: '| `nn.AdaptiveAvgPool1d` | Applies a 1D adaptive average pooling over an input
    signal composed of several input planes |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| `nn.AdaptiveAvgPool1d` | 对由多个输入平面组成的输入信号应用1D自适应平均池化 |'
- en: '| `nn.AdaptiveAvgPool2d` | Applies a 2D adaptive average pooling over an input
    signal composed of several input planes |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| `nn.AdaptiveAvgPool2d` | 对由多个输入平面组成的输入信号应用2D自适应平均池化 |'
- en: '| `nn.AdaptiveAvgPool3d` | Applies a 3D adaptive average pooling over an input
    signal composed of several input planes |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| `nn.AdaptiveAvgPool3d` | 对由多个输入平面组成的输入信号应用3D自适应平均池化 |'
- en: '[Table 3-6](#table_nn_padding) lists the available *padding layers*. Padding
    fills in missing data when the layer outputs increase in size. PyTorch supports
    1D, 2D, and 3D padding, and can pad your data with reflections, replications,
    zeros, or constants.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '[表3-6](#table_nn_padding)列出了可用的*填充层*。填充在图层输出增加尺寸时填充缺失数据。PyTorch支持1D、2D和3D填充，并可以使用反射、复制、零或常数填充数据。'
- en: Table 3-6\. PyTorch NN padding layers
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-6. PyTorch NN填充层
- en: '| Class | Description |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| 类 | 描述 |'
- en: '| --- | --- |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `nn.ReflectionPad1d` | Pads the input tensor using the reflection of the
    input boundary |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| `nn.ReflectionPad1d` | 使用输入边界的反射填充输入张量 |'
- en: '| `nn.ReflectionPad2d` | Pads the input tensor using the reflection of the
    input boundary for 2D inputs |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| `nn.ReflectionPad2d` | 使用输入边界的反射填充输入张量的2D输入 |'
- en: '| `nn.ReplicationPad1d` | Pads the input tensor using the replication of the
    input boundary |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '| `nn.ReplicationPad1d` | 使用输入边界的复制填充输入张量 |'
- en: '| `nn.ReplicationPad2d` | Pads the input tensor using the replication of the
    input boundary for 2D inputs |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| `nn.ReplicationPad2d` | 使用输入边界的复制填充输入张量的2D输入 |'
- en: '| `nn.ReplicationPad3d` | Pads the input tensor using the replication of the
    input boundary for 3D inputs |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| `nn.ReplicationPad3d` | 使用输入边界的复制填充输入张量的3D输入 |'
- en: '| `nn.ZeroPad2d` | Pads the input tensor boundaries with zeros |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| `nn.ZeroPad2d` | 使用零填充输入张量的边界 |'
- en: '| `nn.ConstantPad1d` | Pads the input tensor boundaries with a constant value
    |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| `nn.ConstantPad1d` | 使用常数值填充输入张量的边界 |'
- en: '| `nn.ConstantPad2d` | Pads the input tensor boundaries with a constant value
    for 2D inputs |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| `nn.ConstantPad2d` | 使用常数值填充2D输入的边界 |'
- en: '| `nn.ConstantPad3d` | Pads the input tensor boundaries with a constant value
    for 3D inputs |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| `nn.ConstantPad3d` | 使用常数值填充3D输入的边界 |'
- en: '[Table 3-7](#table_nn_dropout) lists the available layers for *dropout*. Dropout
    is often used to reduce complexity, speed up training, and introduce some regularization
    to prevent overfitting. PyTorch supports dropout for 1D, 2D, and 3D layers, and
    provides support for alpha dropout as well.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '[表3-7](#table_nn_dropout)列出了*dropout*的可用层。Dropout通常用于减少复杂性、加快训练速度，并引入一些正则化以防止过拟合。PyTorch支持1D、2D和3D层的dropout，并提供对alpha
    dropout的支持。'
- en: Table 3-7\. PyTorch NN dropout layers
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-7\. PyTorch NN dropout层
- en: '| Class | Description |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| 类 | 描述 |'
- en: '| --- | --- |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `nn.Dropout` | During training, randomly zeros out some of the elements of
    the input tensor with probability *p* using samples from a Bernoulli distribution
    |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Dropout` | 在训练期间，使用来自伯努利分布的样本，以概率*p*随机将输入张量的一些元素归零 |'
- en: '| `nn.Dropout2d` | Randomly zeros out entire channels for 2D inputs |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Dropout2d` | 对2D输入随机归零整个通道 |'
- en: '| `nn.Dropout3d` | Randomly zeros out entire channels for 3D inputs |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Dropout3d` | 对3D输入随机归零整个通道 |'
- en: '| `nn.AlphaDropout` | Applies alpha dropout over the input |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| `nn.AlphaDropout` | 对输入应用alpha dropout |'
- en: '[Table 3-8](#table_nn_normalization) provides a list of classes that support
    *normalization*. Normalization is performed between some layers to prevent vanishing
    or exploding gradients by keeping intermediate layer inputs within a certain range.
    It can also help speed up the training process. PyTorch supports normalization
    for 1D, 2D, and 3D inputs and provides normalization methods such as batch, instance,
    group, and sync normalization.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '[表3-8](#table_nn_normalization) 提供了支持*归一化*的类列表。在某些层之间执行归一化以防止梯度消失或爆炸，通过保持中间层输入在一定范围内来实现。它还可以帮助加快训练过程。PyTorch支持1D、2D和3D输入的归一化，并提供批次、实例、组和同步归一化等归一化方法。'
- en: Table 3-8\. PyTorch NN normalization layers
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-8\. PyTorch NN归一化层
- en: '| Class | Description |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| 类 | 描述 |'
- en: '| --- | --- |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `nn.BatchNorm1d` | Applies batch normalization over a 2D or 3D input (a mini-batch
    of 1D inputs with an optional additional channel dimension), as described in the
    paper “Batch Normalization: Accelerating Deep Network Training by Reducing Internal
    Covariate Shift” |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| `nn.BatchNorm1d` | 对2D或3D输入（带有可选额外通道维度的1D输入的小批量）应用批次归一化，如论文“通过减少内部协变量转移加速深度网络训练的批次归一化”中所述
    |'
- en: '| `nn.BatchNorm2d` | Applies batch normalization over a 4D input (a mini-batch
    of 2D inputs with an additional channel dimension), as described in the paper
    “Batch Normalization” |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| `nn.BatchNorm2d` | 对4D输入（带有额外通道维度的2D输入的小批量）应用批次归一化，如论文“批次归一化”中所述 |'
- en: '| `nn.BatchNorm3d` | Applies batch normalization over a 5D input (a mini-batch
    of 3D inputs with an additional channel dimension), as described in the paper
    “Batch Normalization” |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| `nn.BatchNorm3d` | 对5D输入（带有额外通道维度的3D输入的小批量）应用批次归一化，如论文“批次归一化”中所述 |'
- en: '| `nn.GroupNorm` | Applies group normalization over a mini-batch of inputs
    as described in the paper “Group Normalization” |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| `nn.GroupNorm` | 对输入的小批量应用组归一化，如论文“组归一化”中所述 |'
- en: '| `nn.SyncBatchNorm` | Applies batch normalization over an *n*-dimensional
    input (a mini-batch of [*n*–2]D inputs with an additional channel dimension),
    as described in the paper “Batch Normalization” |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| `nn.SyncBatchNorm` | 对*n*维输入（带有额外通道维度的[*n*–2]D输入的小批量）应用批次归一化，如论文“批次归一化”中所述
    |'
- en: '| `nn.InstanceNorm1d` | Applies instance normalization over a 3D input (a mini-batch
    of 1D inputs with an optional additional channel dimension), as described in the
    paper “Instance Normalization: The Missing Ingredient for Fast Stylization” |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| `nn.InstanceNorm1d` | 对3D输入（带有可选额外通道维度的1D输入的小批量）应用实例归一化，如论文“实例归一化：快速风格化的缺失成分”中所述
    |'
- en: '| `nn.InstanceNorm2d` | Applies instance normalization over a 4D input (a mini-batch
    of 2D inputs with an additional channel dimension), as described in the paper
    “Instance Normalization” |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| `nn.InstanceNorm2d` | 对4D输入（带有额外通道维度的2D输入的小批量）应用实例归一化，如论文“实例归一化”中所述 |'
- en: '| `nn.InstanceNorm3d` | Applies instance normalization over a 5D input (a mini-batch
    of 3D inputs with an additional channel dimension), as described in the paper
    “Instance Normalization” |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| `nn.InstanceNorm3d` | 对5D输入（带有额外通道维度的3D输入的小批量）应用实例归一化，如论文“实例归一化”中所述 |'
- en: '| `nn.LayerNorm` | Applies layer normalization over a mini-batch of inputs,
    as described in the paper “Layer Normalization” |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| `nn.LayerNorm` | 对输入的小批量应用层归一化，如论文“层归一化”中所述 |'
- en: '| `nn.LocalResponseNorm` | Applies local response normalization over an input
    signal composed of several input planes, in which channels occupy the second dimension
    |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| `nn.LocalResponseNorm` | 对由多个输入平面组成的输入信号应用局部响应归一化，其中通道占据第二维 |'
- en: '[Table 3-9](#table_nn_recurrent) shows the *recurrent layers* used for recurrent
    neural networks (RNNs). RNNs are often used to process time series or sequence-based
    data. PyTorch has built-in support for RNN, long short-term memory (LSTM), and
    gated recurrent unit (GRU) layers as well as classes for RNN, LSTM, and GRU individual
    cells.'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '[表3-9](#table_nn_recurrent) 显示了用于循环神经网络（RNN）的*循环层*。RNN经常用于处理时间序列或基于序列的数据。PyTorch内置支持RNN、长短期记忆（LSTM）和门控循环单元（GRU）层，以及用于RNN、LSTM和GRU单元的类。'
- en: Table 3-9\. PyTorch NN recurrent layers
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-9\. PyTorch NN循环层
- en: '| Class | Description |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| 类 | 描述 |'
- en: '| --- | --- |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `nn.RNNBase` | The RNN base class |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| `nn.RNNBase` | RNN基类 |'
- en: '| `nn.RNN` | A layer that applies a multilayer Elman RNN with \Tanh or ReLU
    nonlinearity to an input sequence |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| `nn.RNN` | 应用多层Elman RNN（使用\Tanh或ReLU非线性）到输入序列的层 |'
- en: '| `nn.LSTM` | A layer that applies a multilayer LSTM RNN to an input sequence
    |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| `nn.LSTM` | 应用多层LSTM RNN到输入序列的层 |'
- en: '| `nn.GRU` | A layer that applies a multilayer GRU RNN to an input sequence
    |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| `nn.GRU` | 应用多层GRU RNN到输入序列的层 |'
- en: '| `nn.RNNCell` | An Elman RNN cell with tanh or ReLU nonlinearity |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| `nn.RNNCell` | 具有tanh或ReLU非线性的Elman RNN单元 |'
- en: '| `nn.LSTMCell` | An LSTM cell |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| `nn.LSTMCell` | 一个LSTM单元 |'
- en: '| `nn.GRUCell` | A GRU cell |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| `nn.GRUCell` | 一个GRU单元 |'
- en: '[Table 3-10](#table_nn_transformer) lists the *transformer layers* used for
    transformer networks. Transformer networks are often considered the state of the
    art for processing sequence data. PyTorch supports the complete `Transformer`
    model class in addition to providing the `Encoder` and `Decoder` submodules in
    stack and layer formats.'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '[表3-10](#table_nn_transformer) 列出了用于变压器网络的*变压器层*。变压器网络通常被认为是处理序列数据的最先进技术。PyTorch支持完整的`Transformer`模型类，还提供了以堆栈和层格式提供的`Encoder`和`Decoder`子模块。'
- en: Table 3-10\. PyTorch NN transformer layers
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-10. PyTorch NN变压器层
- en: '| Class | Description |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| 类 | 描述 |'
- en: '| --- | --- |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `nn.Transformer` | A transformer model |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Transformer` | 一个变压器模型 |'
- en: '| `nn.TransformerEncoder` | A stack of *N* encoder layers |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| `nn.TransformerEncoder` | *N*个编码器层的堆叠 |'
- en: '| `nn.TransformerDecoder` | A stack of *N* decoder layers |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| `nn.TransformerDecoder` | *N*个解码器层的堆叠 |'
- en: '| `nn.TransformerEncoderLayer` | A layer made up of a self-attention (attn)
    and feed-forward network |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| `nn.TransformerEncoderLayer` | 由自我注意（attn）和前馈网络组成的层 |'
- en: '| `nn.TransformerDecoderLayer` | A layer made up of a self-attn, multihead-attn,
    and feed-forward network |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| `nn.TransformerDecoderLayer` | 由自我注意、多头注意和前馈网络组成的层 |'
- en: '[Table 3-11](#table_nn_sparse) contains a list of *sparse layers*. PyTorch
    provides built-in support for text data embeddings as well as sparse layers for
    cosine similarity and pairwise distance, often used in recommendation engine algorithms.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '[表3-11](#table_nn_sparse) 包含了一系列*稀疏层*。PyTorch提供了对文本数据嵌入的内置支持，以及用于余弦相似度和两两距离的稀疏层，这些在推荐引擎算法中经常使用。'
- en: Table 3-11\. PyTorch NN sparse layers and distance functions
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-11. PyTorch NN稀疏层和距离函数
- en: '| Class | Description |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| 类 | 描述 |'
- en: '| --- | --- |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `nn.Embedding` | Stores the embeddings of a fixed dictionary and size |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Embedding` | 存储固定字典和大小的嵌入 |'
- en: '| `nn.EmbeddingBag` | Computes sums or means of “bags” of embeddings without
    instantiating the intermediate embeddings |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| `nn.EmbeddingBag` | 计算“包”嵌入的和或平均值，而不实例化中间嵌入 |'
- en: '| `nn.CosineSimilarity` | Returns the cosine similarity between *x*[1] and
    *x*[2​] computed along a dimension |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| `nn.CosineSimilarity` | 返回沿一个维度计算的*x*[1]和*x*[2]之间的余弦相似度 |'
- en: '| `nn.PairwiseDistance` | Computes the batchwise pairwise distance between
    the vectors *v*[1] and *v*[2] using the *p*-norm |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| `nn.PairwiseDistance` | 使用*p*-范数计算向量*v*[1]和*v*[2]之间的批次两两距离 |'
- en: '[Table 3-12](#table_nn_vision) contains a list of *vision layers* to support
    computer vision. They include layers to shuffle pixels and perform several upsampling
    algorithms.'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '[表3-12](#table_nn_vision) 包含了支持计算机视觉的*视觉层*列表。它们包括用于洗牌像素和执行多种上采样算法的层。'
- en: Table 3-12\. PyTorch NN vision layers
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-12. PyTorch NN视觉层
- en: '| Class | Description |'
  id: totrans-301
  prefs: []
  type: TYPE_TB
  zh: '| 类 | 描述 |'
- en: '| --- | --- |'
  id: totrans-302
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `nn.PixelShuffle` | Rearranges elements in a tensor of shape (∗, <math alttext="upper
    C times r squared"><mrow><mi>C</mi> <mo>×</mo> <msup><mi>r</mi> <mn>2</mn></msup></mrow></math>
    , *H*, *W*) to a tensor of shape (∗, *C*, <math alttext="upper H times r"><mrow><mi>H</mi>
    <mo>×</mo> <mi>r</mi></mrow></math> , <math alttext="upper W times r"><mrow><mi>W</mi>
    <mo>×</mo> <mi>r</mi></mrow></math> ) |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '| `nn.PixelShuffle` | 将形状为(∗, <math alttext="upper C times r squared"><mrow><mi>C</mi>
    <mo>×</mo> <msup><mi>r</mi> <mn>2</mn></msup></mrow></math> , *H*, *W*)的张量重新排列为形状为(∗,
    *C*, <math alttext="upper H times r"><mrow><mi>H</mi> <mo>×</mo> <mi>r</mi></mrow></math>
    , <math alttext="upper W times r"><mrow><mi>W</mi> <mo>×</mo> <mi>r</mi></mrow></math>
    )的张量 |'
- en: '| `nn.Upsample` | Upsamples the given multichannel 1D (temporal), 2D (spatial),
    or 3D (volumetric) data |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Upsample` | 上采样给定的多通道1D（时间）、2D（空间）或3D（体积）数据 |'
- en: '| `nn.UpsamplingNearest2d` | Applies a 2D nearest neighbor upsampling to an
    input signal composed of several input channels |'
  id: totrans-305
  prefs: []
  type: TYPE_TB
  zh: '| `nn.UpsamplingNearest2d` | 对由多个输入通道组成的输入信号应用2D最近邻上采样 |'
- en: '| `nn.UpsamplingBilinear2d` | Applies a 2D bilinear upsampling to an input
    signal composed of several input channels |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
  zh: '| `nn.UpsamplingBilinear2d` | 对由多个输入通道组成的输入信号应用2D双线性上采样 |'
- en: '[Table 3-13](#table_nn_activations) provides a list of all the *activations*
    available in `torch.nn`. Activation functions are often applied to layer outputs
    to introduce nonlinearities into a model. PyTorch supports traditional activations
    such as sigmoid, tanh, softmax, and ReLU as well as more recent functions such
    as leaky ReLU. More functions are being added as researchers design and apply
    new activations in their publications.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '[表3-13](#table_nn_activations) 提供了`torch.nn`中所有*激活函数*的列表。激活函数通常应用于层输出，以引入模型中的非线性。PyTorch支持传统的激活函数，如sigmoid、tanh、softmax和ReLU，以及最近的函数，如leaky
    ReLU。随着研究人员设计和应用新的激活函数，更多的函数正在被添加到其中。'
- en: Table 3-13\. PyTorch NN nonlinear activations
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-13. PyTorch NN非线性激活
- en: '| Class | Description |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
  zh: '| 类 | 描述 |'
- en: '| --- | --- |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `nn.ELU` | Applies the exponential linear unit function element-wise |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| `nn.ELU` | 逐元素应用指数线性单元函数 |'
- en: '| `nn.Hardshrink` | Applies the hard shrinkage function element-wise |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Hardshrink` | 逐元素应用硬收缩函数 |'
- en: '| `nn.Hardsigmoid` | Applies the hard sigmoid function element-wise |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Hardsigmoid` | 逐元素应用硬sigmoid函数 |'
- en: '| `nn.Hardtanh` | Applies the hardtanh function element-wise |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Hardtanh` | 逐元素应用hardtanh函数 |'
- en: '| `nn.Hardswish` | Applies the hardswish function element-wise |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Hardswish` | 逐元素应用hardswish函数 |'
- en: '| `nn.LeakyReLU` | Applies the leaky rectified linear unit function element-wise
    |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| `nn.LeakyReLU` | 逐元素应用泄漏修正线性单元函数 |'
- en: '| `nn.LogSigmoid` | Applies the logarithmic sigmoid function element-wise |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| `nn.LogSigmoid` | 逐元素应用对数sigmoid函数 |'
- en: '| `nn.MultiheadAttention` | Allows the model to jointly attend to information
    from different representation subspaces |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| `nn.MultiheadAttention` | 允许模型同时关注来自不同表示子空间的信息 |'
- en: '| `nn.PReLU` | Applies the parametric rectified linear unit function element-wise
    |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| `nn.PReLU` | 逐元素应用参数化修正线性单元函数 |'
- en: '| `nn.ReLU` | Applies the rectified linear unit function element-wise |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| `nn.ReLU` | 逐元素应用修正线性单元函数 |'
- en: '| `nn.ReLU6` | Applies the rectified linear unit function with a maximum |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| `nn.ReLU6` | 应用带有最大值的修正线性单元函数 |'
- en: '| `nn.RReLU` | Applies the randomized leaky rectified liner unit function element-wise
    |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| `nn.RReLU` | 逐元素应用随机泄漏修正线性单元函数 |'
- en: '| `nn.SELU` | Applies the scaled exponential linear unit function element-wise
    |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| `nn.SELU` | 逐元素应用缩放指数线性单元函数 |'
- en: '| `nn.CELU` | Applies the continuously differentiable exponential linear unit
    function element-wise |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| `nn.CELU` | 逐元素应用连续可微指数线性单元函数 |'
- en: '| `nn.GELU` | Applies the Gaussian error linear unit function |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| `nn.GELU` | 应用高斯误差线性单元函数 |'
- en: '| `nn.Sigmoid` | Applies the sigmoid function element-wise |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Sigmoid` | 逐元素应用sigmoid函数 |'
- en: '| `nn.Softplus` | Applies the softplus function element-wise |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Softplus` | 逐元素应用softplus函数 |'
- en: '| `nn.Softshrink` | Applies the soft shrinkage function element-wise |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Softshrink` | 逐元素应用软收缩函数 |'
- en: '| `nn.Softsign` | Applies the softsign function element-wise |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Softsign` | 逐元素应用softsign函数 |'
- en: '| `nn.Tanh` | Applies the hyperbolic tangent function element-wise |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Tanh` | 逐元素应用双曲正切函数 |'
- en: '| `nn.Tanhshrink` | Applies the hyperbolic tangent function with shrinkage
    element-wise |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Tanhshrink` | 逐元素应用带收缩的双曲正切函数 |'
- en: '| `nn.Threshold` | Establishes the threshold of each element of the input tensor
    |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Threshold` | 设定输入张量的每个元素的阈值 |'
- en: '| `nn.Softmin` | Applies the softmin function to an *n*-dimensional input tensor
    to rescale them so the elements of the *n*-dimensional output tensor lie in the
    range [0, 1] and sum to 1 |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Softmin` | 将softmin函数应用于*n*维输入张量，以便将*n*维输出张量的元素重新缩放到[0,1]范围，并总和为1 |'
- en: '| `nn.Softmax` | Applies the softmax function to an *n*-dimensional input tensor
    to rescale them so the elements of the *n*-dimensional output tensor lie in the
    range [0,1] and sum to 1 |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Softmax` | 将softmax函数应用于*n*维输入张量，以便将*n*维输出张量的元素重新缩放到[0,1]范围，并总和为1 |'
- en: '| `nn.Softmax2d` | Applies the softmax function to features in each spatial
    location |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '| `nn.Softmax2d` | 将softmax函数应用于每个空间位置的特征 |'
- en: '| `nn.LogSoftmax` | Applies the log(softmax(*x*)) function to an *n*-dimensional
    input tensor |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '| `nn.LogSoftmax` | 将log(softmax(*x*))函数应用于*n*维输入张量 |'
- en: '| `nn.AdaptiveLogSoftmaxWithLoss` | Gives an efficient softmax approximation,
    as described in “Efficient Softmax Approximation for GPUs” by Edouard Grave et
    al. |'
  id: totrans-337
  prefs: []
  type: TYPE_TB
  zh: '| `nn.AdaptiveLogSoftmaxWithLoss` | 提供了一个高效的softmax近似，如Edouard Grave等人在“Efficient
    Softmax Approximation for GPUs”中描述的 |'
- en: As you can see, the PyTorch `torch.nn` module supports a robust set of NN layers
    and activation functions. You can use its classes to create everything from simple
    sequential models to complex multiple hierarchical networks, generative adversarial
    networks (GANs), transformer networks, RNNs, and more.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，PyTorch的`torch.nn`模块支持一组强大的NN层和激活函数。您可以使用其类来创建从简单的顺序模型到复杂的多层次网络、生成对抗网络（GANs）、变换器网络、RNN等各种模型。
- en: Now that you know how to design your model, let’s explore how you can train
    and test your own NN model designs with PyTorch.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经知道如何设计您的模型，让我们探讨如何使用PyTorch训练和测试您自己的NN模型设计。
- en: Training
  id: totrans-340
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练
- en: During model design, you defined your NN modules, their parameters, and how
    they are connected to each other. In PyTorch, your model design is implemented
    as a model object derived from the `torch.nn.Module` class. You can call the object
    to pass data into the model and generate outputs based on the model architecture
    and the current values of its parameters.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型设计过程中，您定义了NN模块、它们的参数以及它们之间的连接方式。在PyTorch中，您的模型设计被实现为一个从`torch.nn.Module`类派生的模型对象。您可以调用该对象将数据传递到模型中，并根据模型架构和其参数的当前值生成输出。
- en: The next step in model development is to train your model with your training
    data. Training a model involves nothing more than estimating the model’s parameters,
    passing in data, and adjusting the parameters to achieve a more accurate representation
    of how the data is generally modeled.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 模型开发的下一步是使用训练数据训练您的模型。训练模型仅涉及估计模型的参数、传递数据和调整参数以获得对数据一般建模更准确的表示。
- en: In other words, you set the parameters to some values, pass through data, and
    then compare the model’s outputs with true outputs to measure the error. The goal
    is to change the parameters and repeat the process until the error is minimized
    and the model’s outputs are the same as the true outputs.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，您设置参数为某些值，通过数据，然后将模型的输出与真实输出进行比较以测量误差。目标是改变参数并重复该过程，直到误差最小化且模型的输出与真实输出相同。
- en: Fundamental training loop
  id: totrans-344
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基本训练循环
- en: One of the key advantages of PyTorch over other machine learning frameworks
    is its flexibility, especially when creating customized training loops. In this
    chapter, we’ll explore a fundamental training loop commonly used for supervised
    learning.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch相对于其他机器学习框架的一个关键优势是其灵活性，特别是在创建自定义训练循环时。在本章中，我们将探讨一个常用于监督学习的基本训练循环。
- en: In this example, we will train the LeNet5 model with the CIFAR-10 dataset that
    we used earlier in this chapter. The LeNet5 model is a simple convolutional NN
    developed by Yann LeCun and his team at Bell Labs in the 1990s to classify hand-written
    digits. (Unbeknownst to me at the time, I actually worked for Bell Labs in the
    same building in Holmdel, NJ, while this work was being performed.)
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们将使用本章前面使用过的CIFAR-10数据集训练LeNet5模型。LeNet5模型是由Yann LeCun及其团队在1990年代在贝尔实验室开发的一个简单的卷积NN，用于分类手写数字。（当时我并不知道，我实际上在新泽西州霍尔姆德尔的同一栋建筑物中为贝尔实验室工作，而这项工作正在进行中。）
- en: 'A modernized version of the LeNet5 model can be created using the following
    code:'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用以下代码创建现代化的LeNet5模型版本：
- en: '[PRE20]'
  id: totrans-348
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[![1](Images/1.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO4-1)'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO4-1)'
- en: Define the model class.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 定义模型类。
- en: '[![2](Images/2.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO4-2)'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO4-2)'
- en: Use a GPU if it’s available.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 如果有GPU可用，请使用。
- en: '[![3](Images/3.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO4-3)'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO4-3)'
- en: Create the model and move it to a GPU (if available).
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 创建模型并将其移动到GPU（如果可用）。
- en: As shown in the preceding code, our LeNet5 model uses two convolutional layers
    and three fully connected or linear layers. It has been modernized with max pooling
    and ReLU activations. We’ll also utilize a GPU for training in this example, if
    we can, to speed up training. Here, we create the model object, called `model`.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的代码所示，我们的LeNet5模型使用了两个卷积层和三个全连接或线性层。它已经通过最大池化和ReLU激活进行了现代化。在这个例子中，我们还将利用GPU进行训练，以加快训练速度。在这里，我们创建了名为`model`的模型对象。
- en: Next, we need to define the loss function (which is also called the *criterion*)
    and the optimizer algorithm. The loss function determines how we measure the performance
    of our model and computes the loss or error between predictions and truth. We’ll
    attempt to minimize the loss by adjusting the model parameters during training.
    The optimizer defines how we update our model’s parameters during training.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要定义损失函数（也称为*标准*）和优化器算法。损失函数确定我们如何衡量模型的性能，并计算预测与真相之间的损失或错误。我们将尝试通过调整模型参数来最小化损失。优化器定义了我们在训练过程中如何更新模型参数。
- en: 'To define the loss function and the optimizer, we use the `torch.optim` and
    `torch.nn` packages as shown in the following code:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 为了定义损失函数和优化器，我们使用`torch.optim`和`torch.nn`包，如下面的代码所示：
- en: '[PRE21]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[![1](Images/1.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO5-1)'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO5-1)'
- en: Be sure to pass in the `model.parameters()` for your model.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 确保传入`model.parameters()`作为您的模型。
- en: For this example, we use the `CrossEntropyLoss()` function and the stochastic
    gradient descent (SGD) optimizer. Cross entropy loss is frequently used for classification
    problems. The SGD algorithm is also commonly used as an optimizer function. Choosing
    a loss function and an optimizer is beyond the scope of this book; however, we’ll
    examine many built-in PyTorch loss functions and optimizers later in this chapter.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用`CrossEntropyLoss()`函数和随机梯度下降（SGD）优化器。交叉熵损失经常用于分类问题。SGD算法也常用作优化器函数。选择损失函数和优化器超出了本书的范围；但是，我们将在本章后面检查许多内置的PyTorch损失函数和优化器。
- en: Warning
  id: totrans-362
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: PyTorch optimizers require that you pass in the model parameters using the `parameters()`
    method (i.e., `model.parameters()`). It’s a common mistake to forget the `()`.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch优化器要求您使用`parameters()`方法传入模型参数（即`model.parameters()`）。忘记`()`是一个常见错误。
- en: 'The following PyTorch code demonstrates the fundamental training loop:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 以下PyTorch代码演示了基本的训练循环：
- en: '[PRE22]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[![1](Images/1.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO6-1)'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO6-1)'
- en: Outer training loop; loop over 10 epochs.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 外部训练循环；循环10个epochs。
- en: '[![2](Images/2.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO6-2)'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO6-2)'
- en: Move inputs and labels to GPU if available.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 如果可用，将输入和标签移动到GPU。
- en: '[![3](Images/3.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO6-3)'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO6-3)'
- en: Zero out gradients before each backpropagation pass, or they’ll accumulate.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 在每次反向传播之前将梯度清零，否则它们会累积。
- en: '[![4](Images/4.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO6-4)'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO6-4)'
- en: Perform forward pass.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 执行前向传播。
- en: '[![5](Images/5.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO6-5)'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](Images/5.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO6-5)'
- en: Compute loss.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 计算损失。
- en: '[![6](Images/6.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO6-6)'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](Images/6.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO6-6)'
- en: Perform backpropagation; compute gradients.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 执行反向传播；计算梯度。
- en: '[![7](Images/7.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO6-7)'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: '[![7](Images/7.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO6-7)'
- en: Adjust parameters based on gradients.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 根据梯度调整参数。
- en: '[![8](Images/8.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO6-8)'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: '[![8](Images/8.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO6-8)'
- en: Accumulate batch loss so we can average over the epoch.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 累积批量损失，以便我们可以在整个epoch上进行平均。
- en: The training loop consists of two loops. In the outer loop, we will process
    the entire set of training data during every iteration or epoch. However, instead
    of waiting to process the entire dataset before updating the model’s parameters,
    we process smaller batches of data, one batch at a time. The inner loop loops
    over each batch.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 训练循环由两个循环组成。在外部循环中，我们将在每次迭代或epoch中处理整个训练数据集。然而，我们不会等到处理完整个数据集后再更新模型参数，而是一次处理一个较小的数据批次。内部循环遍历每个批次。
- en: Warning
  id: totrans-383
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: By default, PyTorch accumulates the gradients during each call to `loss.backward()`
    (i.e., the backward pass). This is convenient while training some types of NNs,
    such as RNNs; however, it is not desired for convolutional neural networks (CNNs).
    In most cases, you will need to call `optimizer.zero_grad()` to zero the gradients
    before doing backpropagation so the optimizer updates the model parameters correctly.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，PyTorch在每次调用`loss.backward()`（即反向传播）时累积梯度。这在训练某些类型的NNs（如RNNs）时很方便；然而，对于卷积神经网络（CNNs）来说并不理想。在大多数情况下，您需要调用`optimizer.zero_grad()`来将梯度归零，以便在进行反向传播之前优化器正确更新模型参数。
- en: For each batch, we pass the batch (called `inputs`) into the model. It runs
    the forward pass and returns the computed outputs. Next, we compare the model
    outputs (called `outputs`) with the true values from the training dataset (called
    `labels`) using `criterion()` to compute the error or loss.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个批次，我们将批次（称为`inputs`）传递到模型中。它运行前向传播并返回计算的输出。接下来，我们使用`criterion()`将模型输出（称为`outputs`）与训练数据集中的真实值（称为`labels`）进行比较，以计算错误或损失。
- en: Next, we adjust the model parameters (i.e., the weights and biases of the NN)
    to reduce the loss. To do so, we first perform backpropagation with `loss.backward()`
    to compute the gradients and then run the optimizer with `optimizer.step()` to
    update the parameters based on the computed gradients.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们调整模型参数（即NN的权重和偏差）以减少损失。为此，我们首先使用`loss.backward()`执行反向传播来计算梯度，然后使用`optimizer.step()`运行优化器来根据计算的梯度更新参数。
- en: This is the fundamental process used for training NN models. Implementations
    may vary, but you can use this example as a quick reference when creating your
    own training loops. When designing the training loop, you will need to decide
    how data will be processed or batched, what loss function to use, and what optimizer
    algorithm to run.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: 这是训练NN模型使用的基本过程。实现可能有所不同，但您可以在创建自己的训练循环时使用此示例作为快速参考。在设计训练循环时，您需要决定如何处理或分批数据，使用什么损失函数以及运行什么优化算法。
- en: You can use one of PyTorch’s built-in loss functions and optimizer algorithms,
    or you can create your own.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用PyTorch内置的损失函数和优化算法之一，也可以创建自己的。
- en: Loss functions
  id: totrans-389
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 损失函数
- en: PyTorch includes many built-in loss functions in the `torch.nn` Python module.
    [Table 3-14](#table_loss_functions) provides a list of available loss functions.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch在`torch.nn` Python模块中包含许多内置的损失函数。[表3-14](#table_loss_functions)提供了可用损失函数的列表。
- en: Table 3-14\. Loss functions
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-14. 损失函数
- en: '| Loss function | Description |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: 损失函数 | 描述 |
- en: '| --- | --- |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `nn.L1Loss()` | Creates a criterion that measures the mean absolute error
    (MAE) between each element in the input *x* and target *y* |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| `nn.L1Loss()` | 创建一个标准，用于测量输入*x*和目标*y*中每个元素的平均绝对误差（MAE） |'
- en: '| `nn.MSELoss()` | Creates a criterion that measures the mean squared error
    (squared L2 norm) between each element in the input *x* and target *y* |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| `nn.MSELoss()` | 创建一个标准，测量输入*x*和目标*y*中每个元素的均方误差（平方L2范数） |'
- en: '| `nn.CrossEntropyLoss()` | Combines `nn.LogSoftmax()` and `nn.NLLLoss()` in
    a single class |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| `nn.CrossEntropyLoss()` | 将`nn.LogSoftmax()`和`nn.NLLLoss()`结合在一个类中 |'
- en: '| `nn.CTCLoss()` | Calculates the connectionist temporal classification loss
    |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| `nn.CTCLoss()` | 计算连接主义时间分类损失 |'
- en: '| `nn.NLLLoss()` | Calculates the negative log likelihood loss |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| `nn.NLLLoss()` | 计算负对数似然损失 |'
- en: '| `nn.PoissonNLLLoss()` | Calculates the negative log likelihood loss with
    a Poisson distribution of the target |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| `nn.PoissonNLLLoss()` | 使用泊松分布计算目标的负对数似然损失 |'
- en: '| `nn.KLDivLoss()` | Measures the Kullback–Leibler divergence loss |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| `nn.KLDivLoss()` | 用于测量Kullback-Leibler散度损失 |'
- en: '| `nn.BCELoss()` | Creates a criterion that measures the binary cross entropy
    between the target and the output |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| `nn.BCELoss()` | 创建一个标准，测量目标和输出之间的二元交叉熵 |'
- en: '| `nn.BCEWithLogitsLoss()` | Combines a sigmoid layer and the `nn.BCELoss()`
    in a single class |'
  id: totrans-402
  prefs: []
  type: TYPE_TB
  zh: '| `nn.BCEWithLogitsLoss()` | 将sigmoid层和`nn.BCELoss()`结合在一个类中 |'
- en: '| `nn.MarginRankingLoss()` | Creates a criterion that measures the loss when
    given inputs *x*¹, *x*², two 1D mini-batch tensors, and a label 1D mini-batch
    tensor *y* (containing 1 or –1) |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '| `nn.MarginRankingLoss()` | 创建一个标准，用于在给定输入*x*¹、*x*²（两个1D小批量张量）和标签1D小批量张量*y*（包含1或-1）时测量损失
    |'
- en: '| `nn.HingeEmbeddingLoss()` | Measures the loss when given an input tensor
    *x* and a label tensor *y* (containing 1 or –1) |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '| `nn.HingeEmbeddingLoss()` | 在给定输入张量*x*和标签张量*y*（包含1或-1）时测量损失 |'
- en: '| `nn.MultiLabelMarginLoss()` | Creates a criterion that optimizes a multiclass
    classification hinge loss (i.e., a margin-based loss) between input *x* (a 2D
    mini-batch tensor) and output *y* (a 2D tensor of target class indices) |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| `nn.MultiLabelMarginLoss()` | 创建一个标准，用于优化多类分类的铰链损失（即基于边界的损失），输入为*x*（一个2D小批量张量）和输出*y*（一个目标类别索引的2D张量）
    |'
- en: '| `nn.SmoothL1Loss()` | Creates a criterion that uses a squared term if the
    absolute element-wise error falls below 1 or an L1 term otherwise |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| `nn.SmoothL1Loss()` | 创建一个标准，如果绝对元素误差低于1，则使用平方项，否则使用L1项 |'
- en: '| `nn.SoftMarginLoss()` | Creates a criterion that optimizes a two-class classification
    logistic loss between input tensor *x* and target tensor *y* (containing 1 or
    –1) |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| `nn.SoftMarginLoss()` | 创建一个标准，优化输入张量*x*和目标张量*y*（包含1或-1）之间的两类分类逻辑损失 |'
- en: '| `nn.MultiLabelSoftMarginLoss()` | Creates a criterion that optimizes a multilabel
    one-versus-all loss based on the maximum entropy |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '| `nn.MultiLabelSoftMarginLoss()` | 创建一个标准，基于最大熵优化多标签一对所有损失 |'
- en: '| `nn.CosineEmbeddingLoss()` | Creates a criterion that measures the loss given
    input tensors *x*¹, *x*² and a tensor labeled *y* with values 1 or –1 |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '| `nn.CosineEmbeddingLoss()` | 创建一个标准，给定输入张量*x*¹、*x*²和标记为1或-1的张量*y*时测量损失 |'
- en: '| `nn.MultiMarginLoss()` | Creates a criterion that optimizes a multiclass
    classification hinge loss |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| `nn.MultiMarginLoss()` | 创建一个标准，优化多类分类的铰链损失 |'
- en: '| `nn.TripletMarginLoss()` | Creates a criterion that measures the triplet
    loss when given input tensors *x*¹, *x*², *x*³ and a margin with a value greater
    than 0 |'
  id: totrans-411
  prefs: []
  type: TYPE_TB
  zh: '| `nn.TripletMarginLoss()` | 创建一个标准，给定输入张量*x*¹、*x*²、*x*³和大于0的边界值时测量三元组损失 |'
- en: Warning
  id: totrans-412
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: The `CrossEntropyLoss()` function includes the softmax calculation, which is
    usually performed in the last step of an NN classifier model. When using `CrossEntropyLoss()`,
    do not include `Softmax()` in the output layer of your model definition.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: '`CrossEntropyLoss()`函数包括softmax计算，通常在NN分类器模型的最后一步执行。在使用`CrossEntropyLoss()`时，不要在模型定义的输出层中包含`Softmax()`。'
- en: Optimizer algorithms
  id: totrans-414
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优化算法
- en: PyTorch also includes many built-in optimizer algorithms in the `torch.optim`
    Python submodule. [Table 3-15](#table_optimizers) lists the available optimizer
    algorithms and their descriptions.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch还在`torch.optim` Python子模块中包含许多内置的优化器算法。[表3-15](#table_optimizers)列出了可用的优化器算法及其描述。
- en: Table 3-15\. Optimizer algorithms
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 表3-15. 优化器算法
- en: '| Algorithm | Description |'
  id: totrans-417
  prefs: []
  type: TYPE_TB
  zh: '| Algorithm | 描述 |'
- en: '| --- | --- |'
  id: totrans-418
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `Adadelta()` | An adaptive learning rate method |'
  id: totrans-419
  prefs: []
  type: TYPE_TB
  zh: '| `Adadelta()` | 自适应学习率方法 |'
- en: '| `Adagrad()` | An adaptive gradient algorithm |'
  id: totrans-420
  prefs: []
  type: TYPE_TB
  zh: '| `Adagrad()` | 自适应梯度算法 |'
- en: '| `Adam()` | A method for stochastic optimization |'
  id: totrans-421
  prefs: []
  type: TYPE_TB
  zh: '| `Adam()` | 随机优化方法 |'
- en: '| `AdamW()` | An Adam variant proposed in [“Decoupled Weight Decay Regularization”](https://arxiv.org/abs/1711.05101)
    |'
  id: totrans-422
  prefs: []
  type: TYPE_TB
  zh: '| `AdamW()` | 一种Adam变体，提出于[“解耦权重衰减正则化”](https://arxiv.org/abs/1711.05101) |'
- en: '| `SparseAdam()` | A version of Adam suitable for sparse tensors |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '| `SparseAdam()` | 适用于稀疏张量的Adam版本 |'
- en: '| `Adamax()` | A variant of Adam based on the infinity norm |'
  id: totrans-424
  prefs: []
  type: TYPE_TB
  zh: '| `Adamax()` | 基于无穷范数的Adam变体 |'
- en: '| `ASGD()` | Averaged stochastic gradient descent |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '| `ASGD()` | 平均随机梯度下降 |'
- en: '| `LBFGS()` | A limited-memory implementation of the BFGS algorithm, heavily
    inspired by [minFunc](https://www.cs.ubc.ca/~schmidtm/Software/minFunc.html) |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '| `LBFGS()` | BFGS算法的有限内存实现，受[minFunc](https://www.cs.ubc.ca/~schmidtm/Software/minFunc.html)启发
    |'
- en: '| `RMSprop()` | Root mean square propagation |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
  zh: '| `RMSprop()` | 均方根传播 |'
- en: '| `Rprop()` | Resilient backpropagation |'
  id: totrans-428
  prefs: []
  type: TYPE_TB
  zh: '| `Rprop()` | 弹性反向传播 |'
- en: '| `SGD()` | Stochastic gradient descent |'
  id: totrans-429
  prefs: []
  type: TYPE_TB
  zh: '| `SGD()` | 随机梯度下降 |'
- en: The `torch.optim` Python submodule supports most commonly used algorithms. The
    interface is general enough so new ones can also be easily integrated in the future.
    Visit [the `torch.optim` documentation](https://pytorch.org/docs/stable/optim.html)
    for more details on how to configure the algorithms and adjust their learning
    rates.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.optim` Python子模块支持大多数常用算法。接口足够通用，因此将来也可以轻松集成新算法。访问[torch.optim文档](https://pytorch.org/docs/stable/optim.html)以获取有关如何配置算法和调整学习率的更多详细信息。'
- en: Validation
  id: totrans-431
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 验证
- en: Now that we have trained our model and attempted to minimize the loss, how can
    we evaluate its performance? How do we know that our model will generalize and
    work with data it has never seen before?
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经训练了我们的模型并尝试最小化损失，我们如何评估其性能？我们如何知道我们的模型将泛化并与以前未见过的数据一起工作？
- en: Model development often includes validation and testing loops to ensure that
    overfitting does not occur and that the model will perform well against unseen
    data. Let’s address validation first. Here, I’ll provide you with a quick reference
    for how you can add validation to your training loops with PyTorch.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 模型开发通常包括验证和测试循环，以确保不会发生过拟合，并且模型将针对未见数据表现良好。让我们首先讨论验证。在这里，我将为您提供一个如何使用PyTorch将验证添加到训练循环中的快速参考。
- en: Typically, we will reserve a portion of the training data for validation. The
    validation data will not be used to train the NN; instead, we’ll use it to test
    the performance of the model at the end of each epoch.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们会保留一部分训练数据用于验证。验证数据不会用于训练NN；相反，我们将在每个时代结束时使用它来测试模型的性能。
- en: Validation is good practice when training your models. It’s commonly performed
    when adjusting hyperparameters. For example, maybe we want to slow down the learning
    rate after five epochs.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练模型时进行验证是一个好的实践。在调整超参数时通常会执行验证。例如，也许我们想在五个时代后降低学习率。
- en: 'Before we perform validation, we need to split our training dataset into a
    training dataset and a validation dataset, as shown in the following code:'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行验证之前，我们需要将训练数据集分成训练数据集和验证数据集，如下所示：
- en: '[PRE23]'
  id: totrans-437
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We use the `random_split()` function from `torch.utils.data` to reserve 10,000
    of our 50,000 training images for validation. Once we create our `train_set` and
    `val_set`, we create our dataloaders for each one.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`torch.utils.data`中的`random_split()`函数，将我们的50,000个训练图像中的10,000个保留用于验证。一旦创建了`train_set`和`val_set`，我们为每个创建数据加载器。
- en: 'We then define our model, loss function (or criterion), and optimizer, as shown
    here:'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们定义我们的模型、损失函数（或标准）和优化器，如下所示：
- en: '[PRE24]'
  id: totrans-440
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The following code shows the previous fundamental training example with validation
    added:'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了先前的基本训练示例，并添加了验证：
- en: '[PRE25]'
  id: totrans-442
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[![1](Images/1.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO7-1)'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO7-1)'
- en: Configure the model for training.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 为训练配置模型。
- en: '[![2](Images/2.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO7-2)'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO7-2)'
- en: Configure the model for testing.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 为测试配置模型。
- en: Validation occurs at every epoch after the training data has been processed.
    During validation, the model is passed data that was not used in training and
    that has not yet been seen by the model. We only perform the forward pass during
    validation.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 在处理训练数据后，每个时代都会进行验证。在验证期间，模型会传递尚未用于训练且尚未被模型看到的数据。我们只在验证期间执行前向传递。
- en: Note
  id: totrans-448
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Running the `.train()` or `.eval()` method on your model object puts the model
    in training or testing mode, respectively. Calling these methods is only necessary
    if your model operates differently for training and evaluation. For example, dropout
    and batch normalization are used in training but not in validation or testing.
    It’s good practice to call `.train()` and `.eval()` in your loops.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型对象上运行`.train()`或`.eval()`方法会将模型分别置于训练或测试模式。只有在模型在训练和评估时操作不同的情况下才需要调用这些方法。例如，训练中使用了dropout和批量归一化，但在验证或测试中没有使用。在循环中调用`.train()`和`.eval()`是一个好的实践。
- en: 'If the loss decreases for validation data, then the model is doing well. However,
    if the training loss decreases but the validation loss does not, then there’s
    a good chance the model is overfitting. Look at your results from the previous
    training loop. You should have similar results to the following:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 如果验证数据的损失减少，那么模型表现良好。然而，如果训练损失减少而验证损失没有减少，那么模型很可能出现过拟合。查看前一个训练循环的结果。您应该有类似以下结果：
- en: '[PRE26]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: As you can see, our model is training well and does not seem to be overfitting,
    since both the training loss and the validation loss are decreasing. If we train
    the model for more epochs, we may get even better results.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，我们的模型训练良好，似乎没有过拟合，因为训练损失和验证损失都在减少。如果我们训练模型更多的epochs，我们可能会获得更好的结果。
- en: We’re not quite finished, though. Our model may still be overfitting. We might
    have just gotten lucky with our choice of hyperparameters, leading to good validation
    results. As a further test against overfitting, we will run some test data through
    our model.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，我们还没有完成。我们的模型可能仍然存在过拟合的问题。我们可能只是在选择超参数时运气好，导致验证结果良好。为了进一步测试是否存在过拟合，我们将一些测试数据通过我们的模型运行。
- en: The model has never seen the test data during training, nor has the test data
    had any influence on the hyperparameters. Let’s see how we perform against the
    test dataset.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在训练期间从未见过测试数据，测试数据也没有对超参数产生任何影响。让我们看看我们在测试数据集上的表现如何。
- en: Testing
  id: totrans-455
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试
- en: 'CIFAR-10 provides its own test dataset, and we created `test_data` and a testloader
    earlier in the chapter. Let’s run the test data through our test loop, as shown
    in the following code:'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: CIFAR-10提供了自己的测试数据集，我们在本章前面创建了`test_data`和一个testloader。让我们通过我们的测试循环运行测试数据，如下所示的代码：
- en: '[PRE27]'
  id: totrans-457
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[![1](Images/1.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO8-1)'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO8-1)'
- en: Set the model to evaluation mode for testing.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型设置为测试模式。
- en: '[![2](Images/2.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO8-2)'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO8-2)'
- en: Predict the outcomes for each batch.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 预测每个批次的结果。
- en: '[![3](Images/3.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO8-3)'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO8-3)'
- en: Select the class index with the highest probability.
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: 选择具有最高概率的类索引。
- en: '[![4](Images/4.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO8-4)'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO8-4)'
- en: Compare the prediction to the true label and count the number of correct predictions.
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: 将预测与真实标签进行比较并计算正确预测的数量。
- en: '[![5](Images/5.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO8-5)'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](Images/5.png)](#co_deep_learning_development___span_class__keep_together__with_pytorch__span__CO8-5)'
- en: Compute the percentage of correct predictions (accuracy).
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 计算正确预测的百分比（准确率）。
- en: Our initial test results after 10 epochs of training show a 63% accuracy rate
    against the test data. That’s not a bad start; see if you can improve the accuracy
    by training over more epochs.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在训练10个epochs后的初始测试结果显示，在测试数据上的准确率为63%。这不是一个坏的开始；看看您是否可以通过训练更多epochs来提高准确率。
- en: You now know how to create training, validation, and test loops using PyTorch.
    Feel free to use this code as a reference when creating your own loops.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您知道如何使用PyTorch创建训练、验证和测试循环。在创建自己的循环时，可以随时使用此代码作为参考。
- en: Now that you have a fully trained model, let’s explore what you can do with
    it in the model deployment stage.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经有了一个完全训练好的模型，让我们探索在模型部署阶段可以做些什么。
- en: Model Deployment
  id: totrans-471
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型部署
- en: Depending upon your goals, there are many options for saving or deploying your
    trained models. If you are conducting deep learning research, you may want to
    save your models in such a way that you can repeat your experiments or access
    them later for presentations and publishing papers. You may also wish to publish
    your models as part of a Python package like Torchvision or release them to a
    repository like PyTorch Hub so that other researchers can access your work.
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的目标，有许多选项可用于保存或部署您的训练模型。如果您正在进行深度学习研究，您可能希望以一种可以重复实验或稍后访问以进行演示和发表论文的方式保存模型。您还可以希望将模型发布为像Torchvision这样的Python软件包的一部分，或将其发布到PyTorch
    Hub这样的存储库，以便其他研究人员可以访问您的工作。
- en: On the development side, you may want to deploy your trained NN model to a production
    environment or integrate your model with a product or service. This could be a
    prototype system, edge device, or mobile device. You may also want to deploy it
    to a local production server or a cloud server that provides an API endpoint that
    a system can use. Whatever your goal, PyTorch provides capabilities to help you
    deploy your models as you wish.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 在开发方面，您可能希望将训练好的NN模型部署到生产环境中，或将模型与产品或服务集成。这可能是一个原型系统、边缘设备或移动设备。您还可以将其部署到本地生产服务器或提供系统可以使用的API端点的云服务器。无论您的目标是什么，PyTorch都提供了能力来帮助您按照您的意愿部署模型。
- en: Saving Models
  id: totrans-474
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保存模型
- en: One of the simplest things you can do is save your trained model for future
    use. When you want to run your model against new inputs, you can simply load it
    and call the model with the new values.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的事情之一是保存训练好的模型以备将来使用。当您想对新输入运行模型时，您只需加载它并使用新值调用模型。
- en: 'The following code illustrates the recommended way to save and load a trained
    model. It uses the `state_dict()` method, which creates a dictionary object that
    maps each layer to its parameter tensor. In other words, we only need to save
    the model’s learned parameters. We already have the model’s design defined in
    our model class, so we don’t need to save the architecture. When we load the model,
    we use the constructor to create a “blank model,” and then we use `load_state_dict()`
    to set the parameters for each layer:'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码演示了保存和加载训练模型的推荐方法。它使用`state_dict()`方法，该方法创建一个字典对象，将每个层映射到其参数张量。换句话说，我们只需要保存模型的学习参数。我们已经在模型类中定义了模型的设计，因此不需要保存架构。当我们加载模型时，我们使用构造函数创建一个“空白模型”，然后使用`load_state_dict()`为每个层设置参数：
- en: '[PRE28]'
  id: totrans-477
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Note that `load_state_dict()` requires a dictionary object, not a path to a
    saved `state_dict` object. You must use `torch.load()` to deserialize the saved
    *state_dict* file before passing it to `load_state_dict()`.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`load_state_dict()`需要一个字典对象，而不是一个保存的`state_dict`对象的路径。在将其传递给`load_state_dict()`之前，您必须使用`torch.load()`对保存的*state_dict*文件进行反序列化。
- en: Note
  id: totrans-479
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: A common PyTorch convention is to save models using either a *.pt* or *.pth*
    file extension.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的PyTorch约定是使用*.pt*或*.pth*文件扩展名保存模型。
- en: You can save and load the entire model using `torch.save(`*`PATH`*`)` and `model
    = torch.load(`*`PATH`*`)` too. Although this is more intuitive, it is not recommended
    because the serialization process is bound to the exact file path and directory
    structure used to define the model class. Your code can break if you refactor
    your class code and try to load the model in other projects. Saving and loading
    the `state_dict` object instead will give you more flexibility to restore the
    model later.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以使用`torch.save(`*`PATH`*`)`和`model = torch.load(`*`PATH`*`)`保存和加载整个模型。尽管这更直观，但不建议这样做，因为序列化过程与用于定义模型类的确切文件路径和目录结构绑定。如果您重构类代码并尝试在其他项目中加载模型，您的代码可能会出现问题。相反，保存和加载`state_dict`对象将为您提供更多灵活性，以便稍后恢复模型。
- en: Deploying to PyTorch Hub
  id: totrans-482
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署到PyTorch Hub
- en: PyTorch Hub is a pretrained model repository designed to facilitate research
    reproducibility. Earlier in this chapter, I showed you how to load a preexisting
    or pretrained model from PyTorch Hub. Now, I’ll show you how to publish your pretrained
    models, including model definitions and pretrained weights, to a GitHub repository
    by adding a simple *hubconf.py* file. The *hubconf.py* file defines the code dependencies
    and provides one or more endpoints to the PyTorch API.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch Hub是一个预训练模型存储库，旨在促进研究的可重复性。在本章的前面，我向您展示了如何从PyTorch Hub加载预先存在的或预训练的模型。现在，我将向您展示如何通过添加一个简单的*hubconf.py*文件将您的预训练模型（包括模型定义和预训练权重）发布到GitHub存储库。*hubconf.py*文件定义了代码依赖关系，并为PyTorch
    API提供一个或多个端点。
- en: 'In most cases just importing the right function will be sufficient, but you
    can define the entry point explicitly. The following code shows how you would
    load a model from PyTorch Hub using the VGG16 endpoint:'
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，只需导入正确的函数就足够了，但您也可以明确定义入口点。以下代码显示了如何使用VGG16端点从PyTorch Hub加载模型：
- en: '[PRE29]'
  id: totrans-485
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Now, if you had created VGG16 and wanted to deploy it to PyTorch Hub, all you
    would need to do is include the following *hubconf.py* file in the root of your
    repository. The *hubconf.py* configuration file sets `torch` as a dependency.
    Any function defined in this file will act as an endpoint, so simply importing
    the VGG16 function does the job:'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果您已经创建了VGG16并希望将其部署到PyTorch Hub，您只需要在存储库的根目录中包含以下*hubconf.py*文件。*hubconf.py*配置文件将`torch`设置为依赖项。此文件中定义的任何函数都将充当端点，因此只需导入VGG16函数即可完成任务：
- en: '[PRE30]'
  id: totrans-487
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'If you want to explicitly define the endpoint, you can write a function like
    the one in the following code:'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想明确定义端点，可以编写如下代码中的函数：
- en: '[PRE31]'
  id: totrans-489
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: And that’s it! Researchers around the world will rejoice as they easily load
    your pretrained models from PyTorch Hub.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！全世界的研究人员将因为能够轻松从PyTorch Hub加载您的预训练模型而感到高兴。
- en: Deploying to Production
  id: totrans-491
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署到生产环境
- en: Saving models to files and repositories may be fine when you’re conducting research;
    however, to solve most problems, we must integrate our models into products and
    services. This is often called “deploying to production.” There are many ways
    to do this, and PyTorch has built-in capabilities to support them. Deploying to
    production is a comprehensive topic that will be discussed in depth in [Chapter 7](ch07.xhtml#deploying_pytorch_to_production).
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 将模型保存到文件和存储库可能在进行研究时是可以的；然而，为了解决大多数问题，我们必须将我们的模型集成到产品和服务中。这通常被称为“部署到生产环境”。有许多方法可以做到这一点，PyTorch具有内置功能来支持它们。部署到生产环境是一个全面的主题，将在[第7章](ch07.xhtml#deploying_pytorch_to_production)中深入讨论。
- en: This chapter covered a lot of ground, exploring the deep learning development
    process and providing a quick reference to the PyTorch capabilities for implementing
    each step. The next chapter presents additional reference designs that you can
    use for projects involving transfer learning, sentiment analysis, and generative
    learning .
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了很多内容，探讨了深度学习开发过程，并提供了一个快速参考，介绍了PyTorch在实现每个步骤时的能力。下一章将介绍更多的参考设计，您可以在涉及迁移学习、情感分析和生成学习的项目中使用。
