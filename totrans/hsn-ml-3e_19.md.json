["```py\nimport tensorflow as tf\n\nencoder = tf.keras.Sequential([tf.keras.layers.Dense(2)])\ndecoder = tf.keras.Sequential([tf.keras.layers.Dense(3)])\nautoencoder = tf.keras.Sequential([encoder, decoder])\n\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.5)\nautoencoder.compile(loss=\"mse\", optimizer=optimizer)\n```", "```py\nX_train = [...]  # generate a 3D dataset, like in Chapter 8\nhistory = autoencoder.fit(X_train, X_train, epochs=500, verbose=False)\ncodings = encoder.predict(X_train)\n```", "```py\nstacked_encoder = tf.keras.Sequential([\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(30, activation=\"relu\"),\n])\nstacked_decoder = tf.keras.Sequential([\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(28 * 28),\n    tf.keras.layers.Reshape([28, 28])\n])\nstacked_ae = tf.keras.Sequential([stacked_encoder, stacked_decoder])\n\nstacked_ae.compile(loss=\"mse\", optimizer=\"nadam\")\nhistory = stacked_ae.fit(X_train, X_train, epochs=20,\n                         validation_data=(X_valid, X_valid))\n```", "```py\nimport numpy as np\n\ndef plot_reconstructions(model, images=X_valid, n_images=5):\n    reconstructions = np.clip(model.predict(images[:n_images]), 0, 1)\n    fig = plt.figure(figsize=(n_images * 1.5, 3))\n    for image_index in range(n_images):\n        plt.subplot(2, n_images, 1 + image_index)\n        plt.imshow(images[image_index], cmap=\"binary\")\n        plt.axis(\"off\")\n        plt.subplot(2, n_images, 1 + n_images + image_index)\n        plt.imshow(reconstructions[image_index], cmap=\"binary\")\n        plt.axis(\"off\")\n\nplot_reconstructions(stacked_ae)\nplt.show()\n```", "```py\nfrom sklearn.manifold import TSNE\n\nX_valid_compressed = stacked_encoder.predict(X_valid)\ntsne = TSNE(init=\"pca\", learning_rate=\"auto\", random_state=42)\nX_valid_2D = tsne.fit_transform(X_valid_compressed)\n```", "```py\nplt.scatter(X_valid_2D[:, 0], X_valid_2D[:, 1], c=y_valid, s=10, cmap=\"tab10\")\nplt.show()\n```", "```py\nclass DenseTranspose(tf.keras.layers.Layer):\n    def __init__(self, dense, activation=None, **kwargs):\n        super().__init__(**kwargs)\n        self.dense = dense\n        self.activation = tf.keras.activations.get(activation)\n\n    def build(self, batch_input_shape):\n        self.biases = self.add_weight(name=\"bias\",\n                                      shape=self.dense.input_shape[-1],\n                                      initializer=\"zeros\")\n        super().build(batch_input_shape)\n\n    def call(self, inputs):\n        Z = tf.matmul(inputs, self.dense.weights[0], transpose_b=True)\n        return self.activation(Z + self.biases)\n```", "```py\ndense_1 = tf.keras.layers.Dense(100, activation=\"relu\")\ndense_2 = tf.keras.layers.Dense(30, activation=\"relu\")\n\ntied_encoder = tf.keras.Sequential([\n    tf.keras.layers.Flatten(),\n    dense_1,\n    dense_2\n])\n\ntied_decoder = tf.keras.Sequential([\n    DenseTranspose(dense_2, activation=\"relu\"),\n    DenseTranspose(dense_1),\n    tf.keras.layers.Reshape([28, 28])\n])\n\ntied_ae = tf.keras.Sequential([tied_encoder, tied_decoder])\n```", "```py\nconv_encoder = tf.keras.Sequential([\n    tf.keras.layers.Reshape([28, 28, 1]),\n    tf.keras.layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\"),\n    tf.keras.layers.MaxPool2D(pool_size=2),  # output: 14 \u00d7 14 x 16\n    tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation=\"relu\"),\n    tf.keras.layers.MaxPool2D(pool_size=2),  # output: 7 \u00d7 7 x 32\n    tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\"),\n    tf.keras.layers.MaxPool2D(pool_size=2),  # output: 3 \u00d7 3 x 64\n    tf.keras.layers.Conv2D(30, 3, padding=\"same\", activation=\"relu\"),\n    tf.keras.layers.GlobalAvgPool2D()  # output: 30\n])\nconv_decoder = tf.keras.Sequential([\n    tf.keras.layers.Dense(3 * 3 * 16),\n    tf.keras.layers.Reshape((3, 3, 16)),\n    tf.keras.layers.Conv2DTranspose(32, 3, strides=2, activation=\"relu\"),\n    tf.keras.layers.Conv2DTranspose(16, 3, strides=2, padding=\"same\",\n                                    activation=\"relu\"),\n    tf.keras.layers.Conv2DTranspose(1, 3, strides=2, padding=\"same\"),\n    tf.keras.layers.Reshape([28, 28])\n])\nconv_ae = tf.keras.Sequential([conv_encoder, conv_decoder])\n```", "```py\ndropout_encoder = tf.keras.Sequential([\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(30, activation=\"relu\")\n])\ndropout_decoder = tf.keras.Sequential([\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(28 * 28),\n    tf.keras.layers.Reshape([28, 28])\n])\ndropout_ae = tf.keras.Sequential([dropout_encoder, dropout_decoder])\n```", "```py\nsparse_l1_encoder = tf.keras.Sequential([\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(300, activation=\"sigmoid\"),\n    tf.keras.layers.ActivityRegularization(l1=1e-4)\n])\nsparse_l1_decoder = tf.keras.Sequential([\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(28 * 28),\n    tf.keras.layers.Reshape([28, 28])\n])\nsparse_l1_ae = tf.keras.Sequential([sparse_l1_encoder, sparse_l1_decoder])\n```", "```py\nkl_divergence = tf.keras.losses.kullback_leibler_divergence\n\nclass KLDivergenceRegularizer(tf.keras.regularizers.Regularizer):\n    def __init__(self, weight, target):\n        self.weight = weight\n        self.target = target\n\n    def __call__(self, inputs):\n        mean_activities = tf.reduce_mean(inputs, axis=0)\n        return self.weight * (\n            kl_divergence(self.target, mean_activities) +\n            kl_divergence(1. - self.target, 1. - mean_activities))\n```", "```py\nkld_reg = KLDivergenceRegularizer(weight=5e-3, target=0.1)\nsparse_kl_encoder = tf.keras.Sequential([\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(300, activation=\"sigmoid\",\n                          activity_regularizer=kld_reg)\n])\nsparse_kl_decoder = tf.keras.Sequential([\n    tf.keras.layers.Dense(100, activation=\"relu\"),\n    tf.keras.layers.Dense(28 * 28),\n    tf.keras.layers.Reshape([28, 28])\n])\nsparse_kl_ae = tf.keras.Sequential([sparse_kl_encoder, sparse_kl_decoder])\n```", "```py\nclass Sampling(tf.keras.layers.Layer):\n    def call(self, inputs):\n        mean, log_var = inputs\n        return tf.random.normal(tf.shape(log_var)) * tf.exp(log_var / 2) + mean\n```", "```py\ncodings_size = 10\n\ninputs = tf.keras.layers.Input(shape=[28, 28])\nZ = tf.keras.layers.Flatten()(inputs)\nZ = tf.keras.layers.Dense(150, activation=\"relu\")(Z)\nZ = tf.keras.layers.Dense(100, activation=\"relu\")(Z)\ncodings_mean = tf.keras.layers.Dense(codings_size)(Z)  # \u03bc\ncodings_log_var = tf.keras.layers.Dense(codings_size)(Z)  # \u03b3\ncodings = Sampling()([codings_mean, codings_log_var])\nvariational_encoder = tf.keras.Model(\n    inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])\n```", "```py\ndecoder_inputs = tf.keras.layers.Input(shape=[codings_size])\nx = tf.keras.layers.Dense(100, activation=\"relu\")(decoder_inputs)\nx = tf.keras.layers.Dense(150, activation=\"relu\")(x)\nx = tf.keras.layers.Dense(28 * 28)(x)\noutputs = tf.keras.layers.Reshape([28, 28])(x)\nvariational_decoder = tf.keras.Model(inputs=[decoder_inputs], outputs=[outputs])\n```", "```py\n_, _, codings = variational_encoder(inputs)\nreconstructions = variational_decoder(codings)\nvariational_ae = tf.keras.Model(inputs=[inputs], outputs=[reconstructions])\n```", "```py\nlatent_loss = -0.5 * tf.reduce_sum(\n    1 + codings_log_var - tf.exp(codings_log_var) - tf.square(codings_mean),\n    axis=-1)\nvariational_ae.add_loss(tf.reduce_mean(latent_loss) / 784.)\n```", "```py\nvariational_ae.compile(loss=\"mse\", optimizer=\"nadam\")\nhistory = variational_ae.fit(X_train, X_train, epochs=25, batch_size=128,\n                             validation_data=(X_valid, X_valid))\n```", "```py\ncodings = tf.random.normal(shape=[3 * 7, codings_size])\nimages = variational_decoder(codings).numpy()\n```", "```py\ncodings = np.zeros([7, codings_size])\ncodings[:, 3] = np.linspace(-0.8, 0.8, 7)  # axis 3 looks best in this case\nimages = variational_decoder(codings).numpy()\n```", "```py\ncodings_size = 30\n\nDense = tf.keras.layers.Dense\ngenerator = tf.keras.Sequential([\n    Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n    Dense(150, activation=\"relu\", kernel_initializer=\"he_normal\"),\n    Dense(28 * 28, activation=\"sigmoid\"),\n    tf.keras.layers.Reshape([28, 28])\n])\ndiscriminator = tf.keras.Sequential([\n    tf.keras.layers.Flatten(),\n    Dense(150, activation=\"relu\", kernel_initializer=\"he_normal\"),\n    Dense(100, activation=\"relu\", kernel_initializer=\"he_normal\"),\n    Dense(1, activation=\"sigmoid\")\n])\ngan = tf.keras.Sequential([generator, discriminator])\n```", "```py\ndiscriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\ndiscriminator.trainable = False\ngan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n```", "```py\nbatch_size = 32\ndataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(buffer_size=1000)\ndataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)\n```", "```py\ndef train_gan(gan, dataset, batch_size, codings_size, n_epochs):\n    generator, discriminator = gan.layers\n    for epoch in range(n_epochs):\n        for X_batch in dataset:\n            # phase 1 - training the discriminator\n            noise = tf.random.normal(shape=[batch_size, codings_size])\n            generated_images = generator(noise)\n            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n            discriminator.train_on_batch(X_fake_and_real, y1)\n            # phase 2 - training the generator\n            noise = tf.random.normal(shape=[batch_size, codings_size])\n            y2 = tf.constant([[1.]] * batch_size)\n            gan.train_on_batch(noise, y2)\n\ntrain_gan(gan, dataset, batch_size, codings_size, n_epochs=50)\n```", "```py\ncodings = tf.random.normal(shape=[batch_size, codings_size])\ngenerated_images = generator.predict(codings)\n```", "```py\ncodings_size = 100\n\ngenerator = tf.keras.Sequential([\n    tf.keras.layers.Dense(7 * 7 * 128),\n    tf.keras.layers.Reshape([7, 7, 128]),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2,\n                                    padding=\"same\", activation=\"relu\"),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2DTranspose(1, kernel_size=5, strides=2,\n                                    padding=\"same\", activation=\"tanh\"),\n])\ndiscriminator = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(64, kernel_size=5, strides=2, padding=\"same\",\n                           activation=tf.keras.layers.LeakyReLU(0.2)),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Conv2D(128, kernel_size=5, strides=2, padding=\"same\",\n                           activation=tf.keras.layers.LeakyReLU(0.2)),\n    tf.keras.layers.Dropout(0.4),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n])\ngan = tf.keras.Sequential([generator, discriminator])\n```", "```py\nX_train_dcgan = X_train.reshape(-1, 28, 28, 1) * 2. - 1. # reshape and rescale\n```", "```py\ndef variance_schedule(T, s=0.008, max_beta=0.999):\n    t = np.arange(T + 1)\n    f = np.cos((t / T + s) / (1 + s) * np.pi / 2) ** 2\n    alpha = np.clip(f[1:] / f[:-1], 1 - max_beta, 1)\n    alpha = np.append(1, alpha).astype(np.float32)  # add \u03b1\u2080 = 1\n    beta = 1 - alpha\n    alpha_cumprod = np.cumprod(alpha)\n    return alpha, alpha_cumprod, beta  # \u03b1\u209c , \u03b1\u0305\u209c , \u03b2\u209c for t = 0 to T\n\nT = 4000\nalpha, alpha_cumprod, beta = variance_schedule(T)\n```", "```py\ndef prepare_batch(X):\n    X = tf.cast(X[..., tf.newaxis], tf.float32) * 2 - 1  # scale from \u20131 to +1\n    X_shape = tf.shape(X)\n    t = tf.random.uniform([X_shape[0]], minval=1, maxval=T + 1, dtype=tf.int32)\n    alpha_cm = tf.gather(alpha_cumprod, t)\n    alpha_cm = tf.reshape(alpha_cm, [X_shape[0]] + [1] * (len(X_shape) - 1))\n    noise = tf.random.normal(X_shape)\n    return {\n        \"X_noisy\": alpha_cm ** 0.5 * X + (1 - alpha_cm) ** 0.5 * noise,\n        \"time\": t,\n    }, noise\n```", "```py\ndef prepare_dataset(X, batch_size=32, shuffle=False):\n    ds = tf.data.Dataset.from_tensor_slices(X)\n    if shuffle:\n        ds = ds.shuffle(buffer_size=10_000)\n    return ds.batch(batch_size).map(prepare_batch).prefetch(1)\n\ntrain_set = prepare_dataset(X_train, batch_size=32, shuffle=True)\nvalid_set = prepare_dataset(X_valid, batch_size=32)\n```", "```py\ndef build_diffusion_model():\n    X_noisy = tf.keras.layers.Input(shape=[28, 28, 1], name=\"X_noisy\")\n    time_input = tf.keras.layers.Input(shape=[], dtype=tf.int32, name=\"time\")\n    [...]  # build the model based on the noisy images and the time steps\n    outputs = [...]  # predict the noise (same shape as the input images)\n    return tf.keras.Model(inputs=[X_noisy, time_input], outputs=[outputs])\n```", "```py\nmodel = build_diffusion_model()\nmodel.compile(loss=tf.keras.losses.Huber(), optimizer=\"nadam\")\nhistory = model.fit(train_set, validation_data=valid_set, epochs=100)\n```", "```py\ndef generate(model, batch_size=32):\n    X = tf.random.normal([batch_size, 28, 28, 1])\n    for t in range(T, 0, -1):\n        noise = (tf.random.normal if t > 1 else tf.zeros)(tf.shape(X))\n        X_noise = model({\"X_noisy\": X, \"time\": tf.constant([t] * batch_size)})\n        X = (\n            1 / alpha[t] ** 0.5\n            * (X - beta[t] / (1 - alpha_cumprod[t]) ** 0.5 * X_noise)\n            + (1 - alpha[t]) ** 0.5 * noise\n        )\n    return X\n\nX_gen = generate(model)  # generated images\n```"]