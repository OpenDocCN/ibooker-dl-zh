- en: 5 Knowledge graph learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Building and working with knowledge graphs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing open information extraction to generate knowledge graphs from text
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discovering arbitrary semantic relationships with semantic knowledge graphs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Query expansion and rewriting using knowledge graphs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interpreting documents with knowledge graphs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the last chapter, we primarily focused on learning the similarity between
    queries and documents based on users’ behavioral signals. In chapter 2, we also
    discussed how textual document content, instead of being “unstructured data”,
    is more like a giant graph of hyper-structured data containing a rich graph of
    semantic relationships connecting the many character sequences, terms, and phrases
    that exist across our collections of documents.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll demonstrate how to use this giant graph of semantic relationships
    within our content to better interpret domain-specific terminology. We’ll accomplish
    this by using both traditional knowledge graphs, which enable explicit modeling
    of relationships within a domain, and semantic knowledge graphs, which enable
    real-time inference of nuanced semantic relationships within a domain.
  prefs: []
  type: TYPE_NORMAL
- en: A semantic knowledge graph is a simple kind of *language model* (a language
    model represents a probability distribution over sequences of words). We’ll use
    a semantic knowledge graph as a stepping stone to understanding large language
    models (LLMs) in later chapters. LLMs are deep neural networks typically trained
    on billions of parameters and massive amounts of data (often much of the known
    internet) to model a general representation of human knowledge. Semantic knowledge
    graphs, however, are queryable language models representing only the relationships
    that are actually within your search index. While semantic knowledge graphs don’t
    contain the ability to reason in general about language, they can be very powerful
    for domain-specific contextual inference, as we’ll see.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll also play with several fun datasets in this chapter, to show some variety
    in how knowledge graphs can be built and applied to improve query understanding
    across different domains.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1 Working with knowledge graphs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In section 2.4, we introduced the idea of *knowledge graphs* and discussed how
    they relate to other types of knowledge models, such as ontologies, taxonomies,
    synonyms, and alternative labels. Knowledge graphs, if you recall, integrate each
    of those other types of knowledge models, so we’ll be referring to them all collectively
    as “knowledge graphs” as we build throughout this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: A knowledge graph (or any graph, for that matter) is represented through the
    concept of nodes (also known as *vertices*) and edges. A *node* is an entity represented
    in the knowledge graph (such as a term, person, place, thing, or concept), whereas
    an *edge* represents a relationship between two nodes. Figure 5.1 shows an example
    of a graph displaying nodes and edges.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH05_F01_Grainger.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 A graph structure. Graphs are composed of nodes (also known as “vertices”)
    that represent entities and of edges that represent a node’s relationship with
    another node. Graphs provide a way to model knowledge and infer new insights by
    traversing (or “following”) the edges between nodes.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In this figure, you can see four nodes representing authors, one node representing
    a research paper they wrote together, one node representing the academic conference
    at which the paper was presented and published, and then nodes representing the
    city, province, country, and dates during which the conference was held. By traversing
    (or “following”) the independent edges between nodes, you might infer that one
    of the authors was in Montreal, Canada in October 2016\. While any structure with
    nodes and edges like this is considered a graph, this particular graph represents
    factual knowledge and is therefore also considered a knowledge graph.
  prefs: []
  type: TYPE_NORMAL
- en: There are numerous ways to build and represent knowledge graphs, both through
    explicitly modeling data as nodes and edges and through dynamically materializing
    (discovering) nodes and edges from your data in real time. The latter is what’s
    known as a *semantic knowledge graph*. In this chapter, we’ll walk through various
    examples including building an explicit knowledge graph by hand, autogenerating
    an explicit knowledge graph, and using a semantic knowledge graph that is already
    present within your search index.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get started with knowledge graphs, you have essentially three options:'
  prefs: []
  type: TYPE_NORMAL
- en: Build a knowledge graph from scratch using a graph database (Neo4j, Apache TinkerPop,
    ArangoDB, etc.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plug in a preexisting knowledge graph (ConceptNet, DBpedia, a large language
    model, etc.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autogenerate a knowledge graph from your data, using your content directly to
    extract knowledge
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each approach has its strengths and weaknesses, though the approaches are not
    necessarily mutually exclusive. If you are building a general-knowledge search
    engine (such as a web search engine), utilizing a preexisting knowledge graph
    or large language model is a great place to start. If your search engine is more
    domain-specific, however, your domain-specific entities and terminology may not
    be present in a preexisting graph, requiring you to create a custom knowledge
    graph.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will focus primarily on the third option: autogenerating
    a knowledge graph from your content. The other two techniques are already covered
    well in external materials, using technologies like SPARQL, RDF Triples, and Apache
    Jena or preexisting knowledge graphs like DBpedia and Yago. You will still need
    to be able to override your knowledge graph and add custom content, so we will
    include examples of how you can integrate both explicitly defined knowledge graphs
    (built with a specific list of predefined relationships) and implicitly defined
    knowledge graphs (autogenerated relationships discovered dynamically from the
    data) into your search platform.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Using our search engine as a knowledge graph
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many organizations spend considerable resources building out knowledge graphs
    for their organizations but have trouble integrating them within their search
    engines. We have fortunately chosen a default search engine implementation (Apache
    Solr) for our examples that has explicit graph traversal capabilities built in,
    so there is no need to pull in a new, external system to implement or traverse
    our knowledge graphs.
  prefs: []
  type: TYPE_NORMAL
- en: While there may be some advantages to using an external graph database, such
    as Neo4J or ArangoDB, that supports more sophisticated graph traversal semantics,
    using an external system like this makes coordinating requests, keeping data in
    sync, and infrastructure management more complex. Additionally, because some kinds
    of graph operations can only be done effectively in the search engine (like the
    semantic knowledge graph traversals using an inverted index, which we’ll encounter
    shortly), using the search engine as a unified platform for both search and knowledge
    graph capabilities reduces the number of systems we’ll need to manage.
  prefs: []
  type: TYPE_NORMAL
- en: We will focus extensively on implementing a semantic search system in chapter
    7, including semantic query parsing, phrase extraction, misspelling detection,
    synonym expansion, and query rewriting, all of which will be modeled into an explicitly
    built knowledge graph. Since the purpose of the current chapter is to focus on
    knowledge graph *learning*, we’ll save most of the discussion of query-time integration
    pattens until chapter 7 when we can tie everything from this chapter and chapter
    6 together into the appropriate knowledge graph structure.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3 Automatically extracting knowledge graphs from content
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While you’ll need to be able to modify nodes and edges in your knowledge graphs,
    manually maintaining a large-scale knowledge graph is very challenging. Manually
    maintained knowledge graphs require substantial subject matter expertise, must
    be actively kept up to date with changing information, and are subject to the
    biases and errors of those maintaining them.
  prefs: []
  type: TYPE_NORMAL
- en: '*Open information extraction* is an evolving area of natural language processing
    (NLP) research. Open information extraction aims to extract facts directly from
    your text content. This is often done using NLP libraries and language models
    to parse sentences and assess the dependency graph between them. A *dependency
    graph* is a breakdown of the parts of speech for each word and phrase in a sentence,
    along with an indication of which words refer to which other words.'
  prefs: []
  type: TYPE_NORMAL
- en: More recent approaches to knowledge graph extraction tend to use LLMs specifically
    trained for entity extraction, such as UniRel (unified representation and interaction
    for joint relational triple extraction) and REBEL (relation extraction by end-to-end
    language generation). LLM-based approaches are likely to become the standard for
    knowledge graph extraction over time due to their ability to represent and extract
    more nuanced relationships between entities than traditional dependency graph–based
    approaches. For the sake of learning in this chapter, however, we’ll focus on
    the dependency graph–based approach, as it will provide a better foundation for
    understanding the mechanics of knowledge graph extraction from text and the ability
    to craft custom relationship extraction patterns. You can always switch to a more
    advanced LLM-driven approach later if it better suits your needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we’ll use a language model and dependency graphs to extract
    two different types of relationships: arbitrary relationships and hyponym relationships.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.3.1 Extracting arbitrary relationships from text
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Given the hyper-structured nature of text and the rich relationships expressed
    within typical sentences and paragraphs, it stands to reason that we should be
    able to identify the subjects and objects of sentences and how they are related.
    In this section, we’ll focus on extracting arbitrary relationships between the
    entities described within the sentences of our text content.
  prefs: []
  type: TYPE_NORMAL
- en: By analyzing the nouns and verbs within a sentence, it is often possible to
    infer a fact that is present in the sentence and map that fact into an RDF triple
    (also known as a semantic triple). The Resource Description Framework (RDF) is
    a data model used to represent graphs and relationships. An *RDF triple* is a
    three-part data structure representing a subject (starting node), relationship
    (edge), and object (ending node). For example, in the sentence “Colin attends
    Riverside High School”, the verb “attends” can be extracted as a relationship
    type connecting the subject (“Colin”) with the object (“Riverside High School”).
    The RDF triple is therefore `("Colin", "attends",` `"Riverside High School")`.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.1 walks through an example of using the Python-based spaCy library
    to extract facts from text content. SpaCy is a popular natural language processing
    library that ships with state-of-the-art statistical neural network models for
    part-of-speech tagging, dependency parsing, text categorization, and named-entity
    recognition.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.1 Extracting relationships and resolving co-references
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Resolves entities, such as replacing pronouns with nouns'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Classifies parts of speech for the text'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Generates RDF triples'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 The spaCy-experimental model used for co-reference resolution'
  prefs: []
  type: TYPE_NORMAL
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the example code has taken the text content, parsed it into
    sentences, and then determined the subjects, relationships, and objects within
    those sentences. Those RDF triples can then be saved into an explicitly built
    knowledge graph and traversed.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.2 provides a visualization of this extracted graph. Though this example
    is basic, advanced algorithms can extract facts from more sophisticated linguistic
    patterns. We are using the spaCy library in the code example, which uses a deep-learning-based
    neural language model to detect parts of speech, phrases, dependencies, and co-references
    within the input text. The mechanism we then employ to parse those linguistic
    outputs into RDF triples is more rules-based, following known semantic patterns
    within the English language.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, when parsing arbitrary verbs into relationships this way, the
    extracted relationships can become quite noisy. Since verbs conjugate differently,
    have synonyms, and have overlapping meanings, it is often necessary to prune,
    merge, and otherwise clean up any list of arbitrary extracted relationships.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, some relationship types are much simpler, such as statistical relationships
    (“is related to”) and hyponyms (“is a”). We’ll spend the rest of the chapter focusing
    primarily on using these two special types, starting with hyponyms.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH05_F02_Grainger.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 Extracted knowledge graph. The nodes and edges in this graph were
    automatically extracted from textual content based upon part-of-speech patterns.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 5.3.2 Extracting hyponyms and hypernyms from text
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While it can be challenging mapping arbitrary verbs to clean lists of relationships
    within a knowledge graph, extracting hyponyms and hypernyms can be much easier.
    *Hyponyms* are entities that maintain an “is a” or “is instance of” relationship
    with a more general form of the entities, with the more general form being called
    a *hypernym*. For example, for the relationships between the terms “phillips head”,
    “screwdriver”, and “tool”, we would say that “phillips head” is a hyponym of “screwdriver”,
    that “tool” is a hypernym of “screwdriver”, and that “screwdriver” is both a hypernym
    of “phillips head” and a hyponym of “tool”.
  prefs: []
  type: TYPE_NORMAL
- en: 'One common and fairly accurate way to extract hyponym/hypernym relationships
    from text is through the use of Hearst patterns, described by Marti Hearst in
    “Automatic Acquisition of Hyponyms from Large Text Corpora” (in *COLING 1992 Volume
    2: The 14th International Conference on Computational Linguistics*, 1992). These
    patterns describe common linguistic templates that reliably indicate the presence
    of hyponyms within sentences. The following listing demonstrates a few examples
    of such patterns.'
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.2 Hearst patterns that identify semantic relationships
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Each of these five simple patterns is represented as a Python tuple, with the
    first entry being a *regular expression* and the second being a position within
    the pattern match (i.e., `first` or `last`). If you are unfamiliar with regular
    expressions, they provide a common and powerful syntax for pattern matching within
    strings. Anywhere you see the *NP* characters, this stands for the existence of
    a *noun phrase* within a sentence. The position specified in the second element
    of the tuple (`first` or `last`) indicates which noun phrase in the sentence represents
    the hypernym, with all other noun phrases matching the pattern considered the
    hyponyms.
  prefs: []
  type: TYPE_NORMAL
- en: In the following listing, we run through almost 50 of these Hearst patterns
    to match many combinations of “is a” relationships within our content.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.3 Extracting hyponym relationships using Hearst patterns
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this listing, by focusing on extracting a fixed type of
    relationship (and the most prevalent one—the “is a” relationship), we can generate
    a nice, clean list of taxonomical facts with the more specific term (the hyponym)
    pointing to the more general term (the hypernym) with an `is_a` edge. Figure 5.3
    demonstrates this generated graph visually.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH05_F03_Grainger.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.3 Knowledge graph derived from Hearst patterns. We can see that all
    nodes are connected to other nodes through an `is_a` edge.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The inconsistency and noise that exists with arbitrary relationship extraction
    is significantly reduced by utilizing Hearst patterns. We could still have ambiguity
    about the relationship between similar terms (for example, misspellings, alternative
    spellings, known phrases, or synonyms), but those are much easier to resolve.
    In fact, we’ll spend the entire next chapter discussing how to learn this kind
    of domain-specific language from your signals and content to use it when interpreting
    incoming user queries.
  prefs: []
  type: TYPE_NORMAL
- en: Although it can be useful to extract information from our text into an explicit
    knowledge graph for later traversal, the reality is that this kind of extraction
    is a lossy process, as the representation of the items gets disconnected from
    the originating context of those items within our content (the surrounding text
    and documents containing the text). In the next section, we’ll introduce an entirely
    different kind of knowledge graph—a semantic knowledge graph—that is optimized
    to enable real-time traversal and ranking of the relationships between terms and
    phrases within our content without having to be explicitly built and without separating
    terms from their original textual context.
  prefs: []
  type: TYPE_NORMAL
- en: 5.4 Learning intent by traversing semantic knowledge graphs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In chapter 2, sections 2.1 and 2.2, we discussed the myth of text content being
    “unstructured data” and how, in reality, text documents represent hyper-structured
    data. We discussed the distributional hypothesis (“a word shall be known by the
    company it keeps”) and walked through how character sequences, terms, phrases,
    and other arbitrary term sequences can be thought of as fuzzy foreign keys relating
    similar concepts between documents. We also discussed how these links between
    documents can be thought of as edges in a giant graph of relationships, enabling
    us to learn the contextual meaning of the terms and entities present within our
    corpus of documents.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ll introduce a semantic knowledge graph, a tool and technique
    that will enable us to traverse that giant graph of semantic relationships present
    within our documents.
  prefs: []
  type: TYPE_NORMAL
- en: 5.4.1 What is a semantic knowledge graph?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *semantic knowledge graph* (SKG) is a “compact, auto-generated model for real-time
    traversal and ranking of any relationship within a domain”.[¹](#footnote-113)
    We can think of an SKG as a search engine that, instead of matching and ranking
    documents, finds and ranks *terms* that best match a query.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, if we indexed a collection of documents about health topics and
    searched for `advil`, instead of returning documents that contain the term for
    the pain reliever “advil”, an SKG would automatically (with no manual list creation
    or data modeling required) return values like these:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Such results can be thought of as “dynamic synonyms”, but instead of the terms
    having the same meaning, they are more like conceptually related terms. You could
    expand a lexical search engine query for `advil` to include these other terms
    to improve the recall of your search results or to boost documents that conceptually
    match the meaning of “advil”, instead of just the string containing the five characters
    `a`, `d`, `v`, `i`, `l`.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to finding related terms, an SKG can traverse between fields in
    your inverted index (“find the most-related skills to this job title”), traverse
    multiple levels deep (“find the most-related job titles to this query and then
    find the most-related skills for this query and each of those job titles”), and
    use any arbitrary query you can send to the search engine as a node in the graph
    traversal to find semantically related terms in any field.
  prefs: []
  type: TYPE_NORMAL
- en: The use cases for SKGs are diverse. They can be used for query expansion, generating
    content-based recommendations, query classification, query disambiguation, anomaly
    detection, data cleansing, and predictive analytics. We’ll explore several of
    these in the remainder of this chapter, but let’s first set up some datasets for
    testing our SKG.
  prefs: []
  type: TYPE_NORMAL
- en: 5.4.2 Indexing the datasets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An SKG works best on datasets where there is more overlap of terms being used
    together across documents. The more often two words tend to appear within documents,
    the better we can determine whether those terms appear statistically more often
    than we would expect.
  prefs: []
  type: TYPE_NORMAL
- en: Although Wikipedia is often a good starting dataset for many use cases, it usually
    has a single page about a major topic that is supposed to be authoritative, so
    there isn’t significant overlap across most documents, making Wikipedia a poor
    dataset for this use case. In contrast, most other websites where users submit
    the content (questions, forum posts, job postings, social media posts, reviews)
    tend to have excellent datasets for an SKG use case.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this chapter, we have selected two primary datasets: a jobs dataset (job
    board postings) and a series of Stack Exchange data dumps including posts from
    the following forums:'
  prefs: []
  type: TYPE_NORMAL
- en: health
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: scifi
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: devops
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: travel
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: cooking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 5.4.3 Structure of an SKG
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To best utilize an SKG, it is useful to understand how the graph works based
    on its underlying structure.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike a traditional knowledge graph, which must be explicitly modeled into
    nodes and edges, an SKG is *materialized* from the underlying inverted index of
    your search engine. This means that all you need to do to produce an SKG is to
    index documents into a search engine. No extra data modeling is required.
  prefs: []
  type: TYPE_NORMAL
- en: The inverted index and a corresponding forward index then serve as the underlying
    data structure that enables real-time traversal and ranking of any arbitrary semantic
    relationships present within your collection of documents.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.4 demonstrates how documents get added into both the forward index
    and the inverted index. On the left of the figure, you can see three documents,
    each of which has a `job_title` field, a `desc` field, and a `skills` field. The
    right side of the figure shows how these documents are mapped into your search
    engine. We see that the inverted index maps each field to a list of terms, and
    then maps each term to a postings list containing a list of documents (along with
    positions in the documents, as well as some other data not included in the figure).
    This makes it quick and efficient to look up any term in any field and find the
    set of all documents containing that term.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH05_F04_Grainger.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.4 Inverted index and forward index. Documents get added to an inverted
    index, which maps documents to lists of terms, and to a forward index, which maps
    terms back to lists of documents. Having the ability to map both directions will
    prove important for graph traversal and relationship discovery.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'In addition to the well-known inverted index, you can also see the less-well-known
    *forward index* in the center of figure 5.4\. A forward index can be thought of
    as an *uninverted index*: for each field, it maps each document to a list of terms
    contained within that document. A forward index is what search engines use to
    generate *facets* (also called *aggregations*) on search results, which show the
    top values per field from a set of documents. In Lucene-based search engines like
    Solr, OpenSearch, and Elasticsearch, a forward index is usually generated at index
    time for a field by enabling a feature called *doc values* on the field. Alternatively,
    Apache Solr also allows you to generate the same forward index by “uninverting”
    the inverted index in memory at query time, enabling faceting even on fields for
    which doc values weren’t added to the index.'
  prefs: []
  type: TYPE_NORMAL
- en: If you have the ability to search for arbitrary queries and find sets of documents
    through an inverted index (traversing from terms to documents), and you also have
    the ability to take arbitrary sets of documents and look up terms in those documents
    (traversing from documents to terms), this means that by doing two traversals
    (terms to documents to terms) you can find all of the related terms that appear
    across any documents matching the query. Figure 5.5 demonstrates how such a traversal
    can occur, including a data structure view, a set-theory view, and a graph view.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH05_F05_Grainger.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.5 Three representations of an SKG. The data structure view shows terms
    mapped to sets of documents, the set-theory view shows how the intersection of
    sets of documents forms the relationship between them, and the graph view shows
    the nodes and edges.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In the data structure view, which represents our inverted and forward indices,
    we see how terms are related to documents based on whether they appear within
    them. Those relationship links are only present if there is an intersection between
    the docs that any two nodes (terms, in this case) appear within in the set-theory
    view. The graph view, finally, demonstrates a third view into the same underlying
    data structures, but in this case we see nodes (instead of document sets) and
    edges (instead of intersecting document sets). Essentially, the SKG exists as
    an abstraction on top of the inverted index that is already built and updated
    anytime the search engine indexes content.
  prefs: []
  type: TYPE_NORMAL
- en: We typically consider the primary function of search engines to be accepting
    a query, finding matching documents, and returning those documents in a relevance-ranked
    order. We devoted all of chapter 3 to discussing this process, walking through
    matching (sections 3.2.4–3.2.6), TF-IDF ranking (section 3.1), and the commonly
    used BM25 ranking function (section 3.2.1). However, with an SKG, we focus on
    matching and ranking related *terms*, as opposed to related documents.
  prefs: []
  type: TYPE_NORMAL
- en: Any arbitrary query (anything you can resolve to a document set) can be a node
    in your graph, and you can traverse from that node to any other term (or arbitrary
    query) in any document field. Additionally, since each traversal of an edge between
    two nodes uses both an inverted index (terms to docs) and a forward index (docs
    to terms), it is trivial to chain these traversals together into a multilevel
    graph traversal, as shown in figure 5.6.
  prefs: []
  type: TYPE_NORMAL
- en: In the figure, the data structure view shows a traversal from a skill node (`Java`)
    to a layer of other skills nodes (`Java`, `Oncology`, `Hibernate`, and `Scala`),
    to a layer of job title nodes (`Software Engineer`, `Data Scientist`, and `Java
    Developer`). You can see that not all nodes are connected—the node for `Oncology`,
    for example, does not appear in the graph view because none of the original nodes
    can connect to it through any edges—there are no overlapping documents.
  prefs: []
  type: TYPE_NORMAL
- en: Given that not all possible nodes are going to be relevant for any given traversal,
    it is also important that SKGs be able to score and assign a weight to the relationships
    between nodes so that those edges can be prioritized during any graph traversal.
    We will cover the scoring and assignment of weights to edges in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 5.4.4 Calculating edge weights to measure the relatedness of nodes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Given that the primary function of an SKG is to discover relevant semantic relationships
    between nodes, the ability to calculate *semantic similarity* is critical. But
    what exactly is semantic similarity?
  prefs: []
  type: TYPE_NORMAL
- en: If you recall, the distributional hypothesis, introduced in section 2.3, says
    that words appearing together in the same contexts and with similar distributions
    tend to share similar meanings. Intuitively, this makes sense—the terms “pain”
    or “swelling” will be more likely to occur in documents that also mention “advil”,
    “ibuprofen”, or “ice pack” than in some random documents. Interestingly, though,
    “ice pack” may also occur in documents containing terms like “cooler”, “road trip”,
    or “cold”, whereas “advil” and “ibuprofen” likely would not.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH05_F06_Grainger.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.6 Multilevel graph traversal. In the data structure view, we see two
    traversals: through the inverted index and then the forward index each time. In
    the graph structure view, we see the corresponding two-level traversal: from skills
    to skills to job titles.'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: These examples show words (and their contexts) with similar meanings, but let’s
    also consider words like “a”, “the”, “of”, “and”, “if”, “they”, and countless
    other very common stop words. These words will also appear heavily within the
    same contexts of “pain”, “swelling”, “advil”, “ibuprofen”, or any of the other
    words we examined. This points to the second part of the distributional hypothesis—that
    the words must also occur with similar distributions. In essence, this means that
    given some number of documents containing a first term, any second term tends
    to be semantically similar to the first term if it co-occurs in the same documents
    as the first term more often than it co-occurs in documents with other random
    terms.
  prefs: []
  type: TYPE_NORMAL
- en: Practically, since “the” or “a” tend to co-occur commonly with almost all other
    terms, they are not considered semantically similar to those terms even though
    their level of co-occurrence is high. Terms like “pain” and “ibuprofen”, however,
    occur together statistically way more often than either term appears with random
    other terms, so they are considered semantically similar.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following equation demonstrates one way to calculate the semantic relatedness
    of a term to a set of documents:'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/grainger-ch5-eqs-0x.png)'
  prefs: []
  type: TYPE_IMG
- en: where
  prefs: []
  type: TYPE_NORMAL
- en: '`x` is a query (usually a term or term sequence) for which the relatedness
    is calculated relative to another query, the foreground query `fg`. `D[x]` is
    the set of documents matching the query `x`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`D[fg]` is the set of documents matching the foreground query `fg`. The relatedness
    of `x` is calculated relative to this foreground set.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`D[bg]` is the set of documents matching the background query `bg`. This `bg`
    query should be uncorrelated with `x` and `fg` and is usually set to match the
    entire collection of documents `D` or a random sample from `D`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`P[x]` is the probability of finding `x` in a random document in the background
    set, calculated as ![equation image](../Images/eq-chapter-5-102-1.png)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This `relatedness` calculation (conceptually similar to a z-score in a normal
    distribution) relies on the concept of a “foreground” set of documents and a “background”
    set of documents and enables the distribution of the term `x` to be statistically
    compared between the two sets. For example, if the foreground set was all documents
    matching the query `pain`, and the background set was all documents, then the
    relatedness of the term “advil” would be a measure of how much more often “advil”
    occurs in documents also containing the word “pain” (foreground set) versus in
    any random document (background set). It’s most common to normalize the relatedness
    score using a sigmoid function to map values between –1.0 and 1.0, with 0.0 indicating
    no relationship between the terms. For simplicity, we’ll rely on this normalized
    range of values in the code and all subsequent examples.
  prefs: []
  type: TYPE_NORMAL
- en: If two terms are highly related, their relatedness will be a positive number
    approaching 1.0\. If the terms are highly unrelated (meaning they tend to occur
    in divergent domains only), the score would be closer to –1.0\. Finally, terms
    that aren’t semantically related at all—like stop words—will tend to have a relatedness
    score close to zero.
  prefs: []
  type: TYPE_NORMAL
- en: Apache Solr has SKG capabilities built directly into its faceting API. Faceting
    provides the ability to traverse from terms to sets of documents to terms, and
    a relatedness aggregation function (`RelatednessAgg`) implements the semantic
    similarity calculation we just described. The following listing demonstrates searching
    for semantically related terms to “advil” within the Stack Exchange health dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.4 Discovering semantically related terms to `advil`
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '#1 The field in which to find values for the starting node'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Our starting node is the query “advil”.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Reduces noise by excluding terms not found at least this many times'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 How many nodes (terms) will be returned'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Performs the graph traversal'
  prefs: []
  type: TYPE_NORMAL
- en: '#6 Prints the results of the SKG traversal'
  prefs: []
  type: TYPE_NORMAL
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, of all the terms within the forum posts in the Stack Exchange
    health dataset, the ranked order of the most semantically related terms to `advil`
    was a list of similar painkillers. This is the magic of using the distributional
    hypothesis to discover and rank terms by semantic similarity—it provides us with
    the ability to automatically discover relationships in real time that can be used
    to further improve our understanding of incoming queries.
  prefs: []
  type: TYPE_NORMAL
- en: The following is a Solr SKG request, which uses Solr’s JSON faceting API and
    ability to sort on a function—the `relatedness` calculation we just discussed.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The `skg.traverse(*nodes_to_traverse)` function in listing 5.4 abstracts away
    this engine-specific syntax, but if you’re trying to understand the nuances of
    how your specific search engine or vector database internally handles these kinds
    of knowledge graph traversals, you can inspect the function in the notebooks.
    We’ll mostly show the `skg.traverse` abstraction going forward, but you can always
    call the `skg.transform_ request(*nodes_to_traverse)` function directly to see
    and debug the internal, engine-specific request.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’ll discuss how we can apply the related terms returned
    from this SKG traversal to improve query relevance.
  prefs: []
  type: TYPE_NORMAL
- en: 5.4.5 Using SKGs for query expansion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Matching and ranking solely on the keywords entered during a search doesn’t
    always provide sufficient context to find and rank the best results. In these
    cases, you can significantly improve the quality of search results by dynamically
    expanding or otherwise augmenting queries to include conceptually related terms.
    In this section, we’ll walk through how you can generate these related terms,
    and we’ll demonstrate several strategies for applying the terms to enhance the
    quality of your search results.
  prefs: []
  type: TYPE_NORMAL
- en: Given its ability to start with any keyword or query and to find other highly
    related terms in any field, one obvious use case for an SKG is to dynamically
    expand queries to include related terms. This kind of expansion is sometimes referred
    to as *sparse lexical expansion*, as it operates on sparse vectors of query tokens
    made of term-based (lexical) features. One well-known technique for implementing
    this kind of query expansion is SPLADE (the Sparse Lexical and Expansion model),
    which we’ll cover in section 7.4.3\. Semantic knowledge graphs also provide a
    great way to generate contextual, sparse lexical expansions and have the benefit
    that they require no additional fine-tuning to your dataset. This enables documents
    to match even if they don’t necessarily contain the exact keywords entered by
    the user, but they do contain other terms that carry a very similar meaning. For
    example, instead of a user’s query for `advil`, an expanded query with boosted
    terms generated by the SKG might look something like `advil` `OR` `motrin^0.59897`
    `OR` `aleve^0.4662` `OR` `ibuprofen^0.3824` `OR` `.` `.` `.`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s walk through the steps for implementing this kind of query expansion,
    using a dataset from a different domain this time (the Stack Exchange scifi dataset).
    The following listing shows the first step in this process: searching for an obscure
    term (as a node in the SKG) and finding related other terms (as related nodes
    in the SKG). In this case, we’ll use the query for `vibranium` as our starting
    node.'
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.5 Discovering context for the unknown term “vibranium”
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Response:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: For anyone unfamiliar with the term “vibranium”, it is a strong, fictional metal
    that exists in Marvel comic books and movies (best popularized through the 2018
    Hollywood hit *Black Panther*). The most related terms that came back were related
    to “Wakandan” and “Wakanda”, the fictional culture and country from which vibranium
    originates, “adamantium”, another strong (fictional) metal from Marvel comics,
    and the names “Maclain” and “Klaw”, characters in the Marvel comic books that
    are heavily associated with the metal vibranium. Maclain created the vibranium
    “alloy” used to make Captain “America’s” shield, hence the relatedness of those
    words.
  prefs: []
  type: TYPE_NORMAL
- en: An autogenerated knowledge graph is very effective at identifying related pieces
    of information. By using an SKG and expanding your query to include additional
    related context, you can drastically improve the recall of your search requests.
    By boosting results that best match your query conceptually (as opposed to just
    the text), you may also be able to improve the precision of your top-ranked search
    results.
  prefs: []
  type: TYPE_NORMAL
- en: The following listing demonstrates an example of translating this original query,
    along with the SKG output, into an expanded query.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.6 Expanding a query with nodes in an SKG
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Expanded query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In this case, we are doing a simple Boolean OR search for any of the keywords
    related to the original query `vibranium`, boosting the original query term’s
    weight by a factor of 5x and weighting each subsequent term’s effect on the relevance
    score based upon its semantic similarity score. The choice to boost the original
    term by 5x is arbitrary—you can choose any value here to assign a relative relevance
    boost compared to the other (expanded) terms.
  prefs: []
  type: TYPE_NORMAL
- en: You might also notice that the term “vibranium” appears twice—first as the original
    term, and then again as an expanded term (since the term is *also* the most semantically
    similar to itself). This will almost always be the case if you are searching for
    individual keywords, but since your query might have phrases or other constructs
    that make the original query different from the returned terms (if any), it is
    usually a good idea to include the original query as part of the expanded (rewritten)
    query, so the user’s actual query is always represented in the results.
  prefs: []
  type: TYPE_NORMAL
- en: Although the prior expanded query should rank the results reasonably well (prioritizing
    documents matching multiple related terms), it is also heavily focused on *recall*
    (expanding to include anything relevant) as opposed to *precision* (ensuring everything
    included is relevant). An augmented query can be constructed in many ways, depending
    on your primary goals.
  prefs: []
  type: TYPE_NORMAL
- en: Rewritten queries can perform a simple expansion, require a minimum percentage
    or number of terms to match, require specific terms like the original query to
    match, or even just change the ranking of the same initial results set. The following
    listing demonstrates several examples, using minimum match thresholds and percentages,
    which can tilt the scale between precision and recall as needed.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.7 Different query augmentation strategies
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Let’s look at the final search queries for each of the preceding query expansion
    techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 'Simple query expansion: `simple_expansion`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This simple query expansion is the same as previously described, matching any
    documents containing either the original query or any of the semantically related
    terms.
  prefs: []
  type: TYPE_NORMAL
- en: 'Increased-precision, reduced-recall query: `increased_conceptual_precision`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This increased-precision, reduced-recall example specifies a “minimum match”
    threshold of 30%, meaning that for a document to match, it must contain at least
    30% (rounded down) of the terms in the query.
  prefs: []
  type: TYPE_NORMAL
- en: 'Increased precision of top results, no reduction in recall: `increased_precision_
    same_recall`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: This increased-precision, same-recall query requires the term “vibranium” to
    match, and it will rank documents higher when other expansion terms match, leading
    to an increase in precision for the top results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Slightly increased-recall query: `slightly_increased_recall`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This slightly increased recall query requires two terms to match, but it does
    not explicitly require the original query, so it can expand to other documents
    that are conceptually similar but don’t necessarily contain the original query
    term. Since the term “vibranium” is repeated twice, any documents containing just
    “vibranium” will also match.
  prefs: []
  type: TYPE_NORMAL
- en: 'Same results, better conceptual ranking: `same_results_better_ranking`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This final query returns the same documents as the original query for `vibranium`,
    but it ranks them differently according to how well they match the semantically
    similar terms from the knowledge graph. This ensures the keyword exists in all
    matched documents and that all documents containing the user’s query are returned,
    while also greatly improving ranking by boosting more contextually relevant documents.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, there are an unlimited number of possible query permutations you
    can explore when rewriting your query to include enhanced semantic context, but
    the preceding examples should provide a good sense of the kinds of options available
    and the tradeoffs you’ll want to consider.
  prefs: []
  type: TYPE_NORMAL
- en: 5.4.6 Using SKGs for content-based recommendations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the last section, we explored how we could augment queries by discovering
    and using related nodes from the SKG, including multiple ways of structuring rewritten
    queries to optimize for precision, recall, or even improved conceptual ranking
    over the same results. In addition to expanding queries with semantically related
    terms, it’s also possible to use the SKG to generate content-based recommendations
    by translating documents into queries based on the semantic similarity of the
    terms within the documents.
  prefs: []
  type: TYPE_NORMAL
- en: Since nodes in the SKG can represent any arbitrary query, we can take terms
    from documents and model them as arbitrary nodes to be scored relative to some
    known context about the document. This means we can take dozens or hundreds of
    terms from a document, score them all relative to the topic of the document, and
    then use the most semantically similar terms to generate a query best representing
    the nuanced, contextual meaning of the document.
  prefs: []
  type: TYPE_NORMAL
- en: The following listing walks through an example of translating a document classified
    as “star wars” and ranking all the terms in the document relative to that topic.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.8 Calculating how related document terms are to “star wars”
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Scored nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In these results, you can see a list of terms from the document that is nicely
    ordered based upon semantic similarity to the topic of “star wars”. Terms with
    lower scores will have no relatedness or negative relatedness with the specified
    topic. The following listing filters terms with at least a relatedness above `0.25`
    to get a very clean list of relevant terms from the document.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.9 Generating a recommendation query from scored phrases
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Expanded query:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The next listing demonstrates the last step in this process—running the search
    to return the top documents most semantically similar to the original document.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.10 Running the content-based recommendations query
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: What we have just created is a content-based recommendations algorithm. When
    there’s an insufficient amount of user behavioral signals for signal-based recommendations
    like collaborative filtering (see section 4.2.3), a content-based approach can
    generate recommendations that are still context- and domain-aware.
  prefs: []
  type: TYPE_NORMAL
- en: The example in this section generated a content-based recommendations query
    based on terms found in the starting document, but it is worth keeping in mind
    that the SKG is not restricted to using the terms passed in. You could add an
    extra level to the traversal to find additional terms that are semantically related
    to the terms in the original document, but not actually contained within it. This
    can be particularly useful for niche topics where not enough documents match the
    recommendations query—traversing further will open new possibilities for exploration.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we’ll take a quick step beyond the “is related to” graph
    relationships and see if we can use the SKG to also generate and traverse some
    more interesting edges.
  prefs: []
  type: TYPE_NORMAL
- en: 5.4.7 Using SKGs to model arbitrary relationships
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Thus far, all our SKG traversals have used an “is related to” relationship.
    That is to say, we’ve been finding the strength of the semantic relationship between
    two words or phrases using the `relatedness` function, but we have only measured
    that the nodes are “related”, not *how* they are related. What if we could find
    other kinds of edges between nodes instead of just “is related to” type edges?
  prefs: []
  type: TYPE_NORMAL
- en: If you recall, the nodes in an SKG are materialized on the fly by executing
    a query that matches a set of documents. If the node you start with is `engineer`,
    that node is internally represented as the set of all documents containing the
    word “engineer”. If the node is labeled as `software engineer`, that node is internally
    represented as the set of all documents containing the term “software” intersected
    with all documents containing the term “engineer”. If the search is for `"software
    engineer" OR java` then it is internally represented as the union of the set of
    all documents containing the term “software” one position before the term “engineer”
    (a phrase) with the set of all documents containing the term “java”. All queries,
    regardless of their complexity, are internally represented as a set of documents.
  prefs: []
  type: TYPE_NORMAL
- en: You may also recall that an edge is formed by finding the set of documents containing
    both nodes. This means that *both* nodes and edges are internally represented
    using the same mechanism—a set of documents. Practically speaking, this means
    that if we can construct a node using a query that approximates an interesting
    relationship (as opposed to an entity), we can relate two nodes together through
    the “relationship node” in a similar way to how an edge would be used to relate
    the nodes together in a traditional graph structure.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s work through an example. Revisiting our scifi dataset, let’s say we wanted
    to ask a question about Jean Grey, one of the popular characters from Marvel Comics’
    X-Men franchise. Specifically, let’s say that we wanted to figure out who was
    in love with Jean Grey.
  prefs: []
  type: TYPE_NORMAL
- en: We can accomplish this by using a starting node of `jean grey`, traversing to
    the node `in love with`, and then requesting the top related terms associated
    with `in love with` within the context of `jean grey`. Listing 5.11 demonstrates
    this query. By traversing through a node designed to capture an explicit linguistic
    relationship (`in love with`, in this case), we can use the intermediate node
    to model an edge between the starting and terminating nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 5.11 Materializing an edge through a “relationship node”
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'In case you’re unfamiliar with these characters, here’s the relevant background
    on Jean Grey: she has recurring relationships with two mutants, one named Cyclops
    (real name: Scott Summers) and one named Wolverine. Additionally, and unknown
    to most fans, two of Jean Grey’s mentors, Professor Charles Xavier and Magneto,
    were known to have a love interest in Jean Grey at points throughout the comic
    books.'
  prefs: []
  type: TYPE_NORMAL
- en: If we examine the results from listing 5.11, we’ll see all of these expected
    names listed. The first two terms, “jean” and “grey”, are the most related, since
    we are searching for `in love with` relative to `jean grey`. Her name is going
    to be highly semantically related to itself. The next two terms, “summers” and
    “cyclops”, both refer to the same person, Jean’s most prominent love interest.
    Then we see “xavier” and “wolverine”, and the last result in the list is “magneto”.
    Figure 5.7 illustrates some of the underlying graph relationships for this traversal.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH05_F07_Grainger.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.7 Traversing arbitrarily defined edge types. By materializing a new
    node with the combined context of both the originating node (`"jean grey"`) and
    a new node (`"in love with"`), we can traverse from that combined node (`"jean
    grey" + "in love with"`) to other nodes. This is equivalent to saying we are traversing
    from `"jean grey"` through an edge of `"in love with"` to the other nodes.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: By using an intermediate node (i.e., `in love with`) to model a relationship
    between other nodes, we can form any arbitrarily typed edge between nodes, as
    long as we can express that edge as a search query.
  prefs: []
  type: TYPE_NORMAL
- en: While the results of our graph traversal in listing 5.11 were pretty good, we
    do see the terms “x” (presumably from “x-men”) and “mutant” also showing up. Jean
    Grey and all the other listed people are mutants in the X-Men comics, which is
    why these terms are so semantically related. However, these terms are not great
    answers to the question “Who is in love with Jean Grey?”
  prefs: []
  type: TYPE_NORMAL
- en: 'This brings up an important point: the SKG is a statistical knowledge graph.
    The existence of the `in love with` relationship is purely based upon statistical
    correlations of terms within our collection, so just as with any ontology learning
    approach, there is going to be noise. That said, for an autogenerated graph with
    no explicit modeling of entities, these results are quite good.'
  prefs: []
  type: TYPE_NORMAL
- en: If we wanted to improve the quality of these results, one of the easiest things
    to do would be to run preprocessing on the content to identify entities (people,
    places, and things) and index those instead of just single-term keywords. This
    would cause actual people’s names (e.g., “Scott Summers”, “Charles Xavier”, “Jean
    Grey”) to be returned instead of just individual keywords (“summers”, “xavier”,
    “jean”, “grey”).
  prefs: []
  type: TYPE_NORMAL
- en: It is also worth pointing out that the traversal of relationships depends entirely
    on whether those relationships were discussed in the underlying corpus of documents.
    In this case, plenty of forum posts discuss each of these peoples’ relationships
    with Jean Grey. Had insufficient documents existed, the results returned may have
    been poor or nonexistent. To avoid noise in our results, we set a `min_occurrences`
    threshold of `25`, indicating that at least 25 documents must exist discussing
    `jean grey`, `in love with`, and the other nodes found and scored. We recommend
    setting a `min_occurrences` to some number greater than 1 to avoid false positives.
  prefs: []
  type: TYPE_NORMAL
- en: While traversing arbitrary linguistic relationships like “in love with” can
    be useful from an exploratory standpoint, it is usually sufficient from a query
    understanding standpoint to stick with the default “is related to” relationship
    and use the relatedness scores between terms for most semantic search use cases.
    It can still be useful to traverse through multiple levels of relationships to
    generate better context, however. Specifically, it can be useful to traverse from
    a term to a classification field to provide some additional context, and then
    to related meanings of the term within that category. We’ll cover this strategy
    in more detail in chapter 6, where we’ll focus on disambiguating terms with multiple
    meanings.
  prefs: []
  type: TYPE_NORMAL
- en: 5.5 Using knowledge graphs for semantic search
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: By providing the ability to accept arbitrary queries and dynamically discover
    related terms in a context-sensitive way, SKGs become a key tool for query interpretation
    and relevance ranking. We’ve seen that not only can SKGs help interpret and expand
    queries, they can also provide the abilities to classify queries and keywords
    in real time and to disambiguate multiple meanings of the terms in each query.
  prefs: []
  type: TYPE_NORMAL
- en: Early in the chapter, we also explored how to build explicit knowledge graphs
    through open information extraction techniques. What may not be obvious yet is
    how to parse arbitrary incoming queries and look up the appropriate context and
    entities in the knowledge graph. We’ll spend the majority of chapter 7 covering
    how to build an end-to-end semantic search system that can parse queries and integrate
    these knowledge graph capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: There are still some critical kinds of relationships we need to add to our knowledge
    graph that are important for search engines, such as misspellings, synonyms, and
    domain-specific phrases. We’ll cover how to automatically learn each of these
    sources of domain-specific terminology from user signals or content in the next
    chapter, which focuses on learning domain-specific language.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Knowledge graphs model the relationships between entities within your domain
    and can be built explicitly with known relationships or can be extracted dynamically
    from your content.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Open information extraction, the process of extracting facts from your content
    (subject, relationship, object triples) can be used to learn arbitrary relationships
    (which typically results in noisy data) or to extract hyponym and hypernym relationships
    (less noisy) from text into an explicit knowledge graph.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Semantic knowledge graphs (SKGs) enable the traversal and ranking of arbitrary
    semantic relationships between any content within your search index. This allows
    you to use your indexed content directly as a knowledge graph and language model
    without any additional data modeling required.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Content-based recommendations that don’t rely on user signals can be generated
    by ranking the most semantically interesting terms and phrases from documents
    and using them as a query to find and rank other related documents.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SKGs enable a better understanding of user intent by powering domain-sensitive
    and context-sensitive relationship discovery and query expansion.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[[1]](#ftnote-113) Grainger, et al., “The Semantic Knowledge Graph: A compact,
    auto-generated model for real-time traversal and ranking of any relationship within
    a domain.” In *2016 IEEE International Conference on Data Science and Advanced
    Analytics (DSAA)*, pp. 420–429\. IEEE, 2016.'
  prefs: []
  type: TYPE_NORMAL
