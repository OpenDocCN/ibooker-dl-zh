- en: Chapter 5\. Image Classification
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第5章 图像分类
- en: Now that you understand what deep learning is, what it’s for, and how to create
    and deploy a model, it’s time for us to go deeper! In an ideal world, deep learning
    practitioners wouldn’t have to know every detail of how things work under the
    hood. But as yet, we don’t live in an ideal world. The truth is, to make your
    model really work, and work reliably, there are a lot of details you have to get
    right, and a lot of details that you have to check. This process requires being
    able to look inside your neural network as it trains and as it makes predictions,
    find possible problems, and know how to fix them.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您了解了深度学习是什么、它的用途以及如何创建和部署模型，现在是时候深入了！在理想的世界中，深度学习从业者不必了解每个细节是如何在底层工作的。但事实上，我们还没有生活在理想的世界中。事实是，要使您的模型真正起作用并可靠地工作，您必须正确处理很多细节，并检查很多细节。这个过程需要能够在训练神经网络时查看内部情况，找到可能的问题，并知道如何解决它们。
- en: So, from here on in the book, we are going to do a deep dive into the mechanics
    of deep learning. What is the architecture of a computer vision model, an NLP
    model, a tabular model, and so on? How do you create an architecture that matches
    the needs of your particular domain? How do you get the best possible results
    from the training process? How do you make things faster? What do you have to
    change as your datasets change?
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，从本书开始，我们将深入研究深度学习的机制。计算机视觉模型的架构是什么，自然语言处理模型的架构是什么，表格模型的架构是什么等等？如何创建一个与您特定领域需求匹配的架构？如何从训练过程中获得最佳结果？如何加快速度？随着数据集的变化，您必须做出哪些改变？
- en: 'We will start by repeating the same basic applications that we looked at in
    the first chapter, but we are going to do two things:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从重复第一章中查看的相同基本应用程序开始，但我们将做两件事：
- en: Make them better.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 让它们变得更好。
- en: Apply them to a wider variety of types of data.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将它们应用于更多类型的数据。
- en: To do these two things, we will have to learn all of the pieces of the deep
    learning puzzle. This includes different types of layers, regularization methods,
    optimizers, how to put layers together into architectures, labeling techniques,
    and much more. We are not just going to dump all of these things on you, though;
    we will introduce them progressively as needed, to solve actual problems related
    to the projects we are working on.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 为了做这两件事，我们将不得不学习深度学习难题的所有部分。这包括不同类型的层、正则化方法、优化器、如何将层组合成架构、标记技术等等。但我们不会一次性把所有这些东西都扔给你；我们将根据需要逐步引入它们，以解决与我们正在处理的项目相关的实际问题。
- en: From Dogs and Cats to Pet Breeds
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从狗和猫到宠物品种
- en: 'In our very first model, we learned how to classify dogs versus cats. Just
    a few years ago, this was considered a very challenging task—but today, it’s far
    too easy! We will not be able to show you the nuances of training models with
    this problem, because we get a nearly perfect result without worrying about any
    of the details. But it turns out that the same dataset also allows us to work
    on a much more challenging problem: figuring out what breed of pet is shown in
    each image.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的第一个模型中，我们学会了如何区分狗和猫。就在几年前，这被认为是一个非常具有挑战性的任务——但今天，这太容易了！我们将无法向您展示训练模型时的细微差别，因为我们在不担心任何细节的情况下获得了几乎完美的结果。但事实证明，同一数据集还允许我们解决一个更具挑战性的问题：找出每张图像中显示的宠物品种是什么。
- en: In [Chapter 1](ch01.xhtml#chapter_intro), we presented the applications as already-solved
    problems. But this is not how things work in real life. We start with a dataset
    that we know nothing about. We then have to figure out how it is put together,
    how to extract the data we need from it, and what that data looks like. For the
    rest of this book, we will be showing you how to solve these problems in practice,
    including all of the intermediate steps necessary to understand the data that
    we are working with and test your modeling as you go.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一章中，我们将应用程序呈现为已解决的问题。但这不是实际情况下的工作方式。我们从一个我们一无所知的数据集开始。然后我们必须弄清楚它是如何组合的，如何从中提取我们需要的数据，以及这些数据是什么样子的。在本书的其余部分，我们将向您展示如何在实践中解决这些问题，包括理解我们正在处理的数据以及在进行建模时测试的所有必要中间步骤。
- en: 'We already downloaded the Pets dataset, and we can get a path to this dataset
    using the same code as in [Chapter 1](ch01.xhtml#chapter_intro):'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经下载了宠物数据集，并且可以使用与第一章相同的代码获取到该数据集的路径：
- en: '[PRE0]'
  id: totrans-11
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now if we are going to understand how to extract the breed of each pet from
    each image, we’re going to need to understand how this data is laid out. Such
    details of data layout are a vital piece of the deep learning puzzle. Data is
    usually provided in one of these two ways:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们要理解如何从每个图像中提取每只宠物的品种，我们需要了解数据是如何布局的。数据布局的细节是深度学习难题的重要组成部分。数据通常以以下两种方式之一提供：
- en: Individual files representing items of data, such as text documents or images,
    possibly organized into folders or with filenames representing information about
    those items
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 表示数据项的个别文件，例如文本文档或图像，可能组织成文件夹或具有表示有关这些项信息的文件名
- en: A table of data (e.g., in CSV format) in which each row is an item and may include
    filenames providing connections between the data in the table and data in other
    formats, such as text documents and images
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据表（例如，以CSV格式）中的数据，其中每行是一个项目，可能包括文件名，提供表中数据与其他格式（如文本文档和图像）中数据之间的连接
- en: There are exceptions to these rules—particularly in domains such as genomics,
    where there can be binary database formats or even network streams—but overall
    the vast majority of the datasets you’ll work with will use some combination of
    these two formats.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些例外情况——特别是在基因组学等领域，可能存在二进制数据库格式或甚至网络流——但总体而言，您将处理的绝大多数数据集将使用这两种格式的某种组合。
- en: 'To see what is in our dataset, we can use the `ls` method:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看数据集中的内容，我们可以使用`ls`方法：
- en: '[PRE1]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can see that this dataset provides us with *images* and *annotations* directories.
    The [website](https://oreil.ly/xveoN) for the dataset tells us that the *annotations*
    directory contains information about where the pets are rather than what they
    are. In this chapter, we will be doing classification, not localization, which
    is to say that we care about what the pets are, not where they are. Therefore,
    we will ignore the *annotations* directory for now. So, let’s have a look inside
    the *images* directory:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到这个数据集为我们提供了*images*和*annotations*目录。数据集的[网站](https://oreil.ly/xveoN)告诉我们*annotations*目录包含有关宠物所在位置而不是它们是什么的信息。在本章中，我们将进行分类，而不是定位，也就是说我们关心的是宠物是什么，而不是它们在哪里。因此，我们暂时会忽略*annotations*目录。那么，让我们来看看*images*目录里面的内容：
- en: '[PRE3]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Most functions and methods in fastai that return a collection use a class called
    `L`. This class can be thought of as an enhanced version of the ordinary Python
    `list` type, with added conveniences for common operations. For instance, when
    we display an object of this class in a notebook, it appears in the format shown
    here. The first thing that is shown is the number of items in the collection,
    prefixed with a `#`. You’ll also see in the preceding output that the list is
    suffixed with an ellipsis. This means that only the first few items are displayed—which
    is a good thing, because we would not want more than 7,000 filenames on our screen!
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在fastai中，大多数返回集合的函数和方法使用一个名为`L`的类。这个类可以被认为是普通Python `list`类型的增强版本，具有用于常见操作的附加便利。例如，当我们在笔记本中显示这个类的对象时，它会以这里显示的格式显示。首先显示的是集合中的项目数，前面带有`#`。在前面的输出中，你还会看到列表后面有省略号。这意味着只显示了前几个项目，这是件好事，因为我们不希望屏幕上出现超过7000个文件名！
- en: 'By examining these filenames, we can see how they appear to be structured.
    Each filename contains the pet breed, then an underscore (`_`), a number, and
    finally the file extension. We need to create a piece of code that extracts the
    breed from a single `Path`. Jupyter notebooks make this easy, because we can gradually
    build up something that works, and then use it for the entire dataset. We do have
    to be careful to not make too many assumptions at this point. For instance, if
    you look carefully, you may notice that some of the pet breeds contain multiple
    words, so we cannot simply break at the first `_` character that we find. To allow
    us to test our code, let’s pick out one of these filenames:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 通过检查这些文件名，我们可以看到它们似乎是如何结构化的。每个文件名包含宠物品种，然后是一个下划线（`_`），一个数字，最后是文件扩展名。我们需要创建一段代码，从单个`Path`中提取品种。Jupyter笔记本使这变得容易，因为我们可以逐渐构建出可用的东西，然后用于整个数据集。在这一点上，我们必须小心不要做太多假设。例如，如果你仔细观察，你可能会注意到一些宠物品种包含多个单词，因此我们不能简单地在找到的第一个`_`字符处中断。为了让我们能够测试我们的代码，让我们挑选出一个这样的文件名：
- en: '[PRE5]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The most powerful and flexible way to extract information from strings like
    this is to use a *regular expression*, also known as a *regex*. A regular expression
    is a special string, written in the regular expression language, which specifies
    a general rule for deciding whether another string passes a test (i.e., “matches”
    the regular expression), and also possibly for plucking a particular part or parts
    out of that other string. In this case, we need a regular expression that extracts
    the pet breed from the filename.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 从这样的字符串中提取信息的最强大和灵活的方法是使用*regular expression*，也称为*regex*。正则表达式是一种特殊的字符串，用正则表达式语言编写，它指定了一个一般规则，用于决定另一个字符串是否通过测试（即“匹配”正则表达式），并且可能用于从另一个字符串中提取特定部分。在这种情况下，我们需要一个正则表达式从文件名中提取宠物品种。
- en: We do not have the space to give you a complete regular expression tutorial
    here, but many excellent ones are online, and we know that many of you will already
    be familiar with this wonderful tool. If you’re not, that is totally fine—this
    is a great opportunity for you to rectify that! We find that regular expressions
    are one of the most useful tools in our programming toolkit, and many of our students
    tell us that this is one of the things they are most excited to learn about. So
    head over to Google and search for “regular expressions tutorial” now, and then
    come back here after you’ve had a good look around. The [book’s website](https://book.fast.ai)
    also provides a list of our favorites.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有空间在这里为您提供完整的正则表达式教程，但有许多优秀的在线教程，我们知道你们中的许多人已经熟悉这个神奇的工具。如果你不熟悉，那完全没问题——这是一个让你纠正的绝佳机会！我们发现正则表达式是我们编程工具包中最有用的工具之一，我们的许多学生告诉我们，这是他们最兴奋学习的事情之一。所以赶紧去谷歌搜索“正则表达式教程”吧，然后在你看得很开心之后回到这里。[书籍网站](https://book.fast.ai)也提供了我们喜欢的教程列表。
- en: Alexis Says
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 亚历克西斯说
- en: 'Not only are regular expressions dead handy, but they also have interesting
    roots. They are “regular” because they were originally examples of a “regular”
    language, the lowest rung within the Chomsky hierarchy. This is a grammar classification
    developed by linguist Noam Chomsky, who also wrote *Syntactic Structures*, the
    pioneering work searching for the formal grammar underlying human language. This
    is one of the charms of computing: the hammer you reach for every day may have,
    in fact, come from a spaceship.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 正则表达式不仅非常方便，而且还有有趣的起源。它们之所以被称为“regular”，是因为它们最初是“regular”语言的示例，这是乔姆斯基层次结构中最低的一级。这是语言学家诺姆·乔姆斯基开发的一种语法分类，他还写了《句法结构》，这是一项寻找人类语言基础形式语法的开创性工作。这是计算的魅力之一：你每天使用的工具可能实际上来自太空船。
- en: 'When you are writing a regular expression, the best way to start is to try
    it against one example at first. Let’s use the `findall` method to try a regular
    expression against the filename of the `fname` object:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 当你编写正则表达式时，最好的方法是首先针对一个示例尝试。让我们使用`findall`方法来对`fname`对象的文件名尝试一个正则表达式：
- en: '[PRE6]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This regular expression plucks out all the characters leading up to the last
    underscore character, as long as the subsequent characters are numerical digits
    and then the JPEG file extension.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这个正则表达式提取出所有字符，直到最后一个下划线字符，只要后续字符是数字，然后是JPEG文件扩展名。
- en: 'Now that we confirmed the regular expression works for the example, let’s use
    it to label the whole dataset. fastai comes with many classes to help with labeling.
    For labeling with regular expressions, we can use the `RegexLabeller` class. In
    this example, we use the data block API that we saw in [Chapter 2](ch02.xhtml#chapter_production)
    (in fact, we nearly always use the data block API—it’s so much more flexible than
    the simple factory methods we saw in [Chapter 1](ch01.xhtml#chapter_intro)):'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们确认了正则表达式对示例的有效性，让我们用它来标记整个数据集。fastai提供了许多类来帮助标记。对于使用正则表达式进行标记，我们可以使用`RegexLabeller`类。在这个例子中，我们使用了数据块API，我们在[第2章](ch02.xhtml#chapter_production)中看到过（实际上，我们几乎总是使用数据块API——它比我们在[第1章](ch01.xhtml#chapter_intro)中看到的简单工厂方法更灵活）：
- en: '[PRE8]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'One important piece of this `DataBlock` call that we haven’t seen before is
    in these two lines:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这个`DataBlock`调用中一个重要的部分是我们以前没有见过的这两行：
- en: '[PRE9]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: These lines implement a fastai data augmentation strategy that we call *presizing*.
    Presizing is a particular way to do image augmentation that is designed to minimize
    data destruction while maintaining good performance.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这些行实现了一个我们称之为*预调整*的fastai数据增强策略。预调整是一种特殊的图像增强方法，旨在最大限度地减少数据破坏，同时保持良好的性能。
- en: Presizing
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 预调整
- en: We need our images to have the same dimensions, so that they can collate into
    tensors to be passed to the GPU. We also want to minimize the number of distinct
    augmentation computations we perform. The performance requirement suggests that
    we should, where possible, compose our augmentation transforms into fewer transforms
    (to reduce the number of computations and the number of lossy operations) and
    transform the images into uniform sizes (for more efficient processing on the
    GPU).
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要我们的图像具有相同的尺寸，这样它们可以整合成张量传递给GPU。我们还希望最小化我们执行的不同增强计算的数量。性能要求表明，我们应该尽可能将我们的增强变换组合成更少的变换（以减少计算数量和损失操作的数量），并将图像转换为统一尺寸（以便在GPU上更有效地处理）。
- en: The challenge is that, if performed after resizing down to the augmented size,
    various common data augmentation transforms might introduce spurious empty zones,
    degrade data, or both. For instance, rotating an image by 45 degrees fills corner
    regions of the new bounds with emptiness, which will not teach the model anything.
    Many rotation and zooming operations will require interpolating to create pixels.
    These interpolated pixels are derived from the original image data but are still
    of lower quality.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 挑战在于，如果在调整大小到增强尺寸之后执行各种常见的数据增强变换，可能会引入虚假的空白区域，降低数据质量，或两者兼而有之。例如，将图像旋转45度会在新边界的角落区域填充空白，这不会教会模型任何东西。许多旋转和缩放操作将需要插值来创建像素。这些插值像素是从原始图像数据派生的，但质量较低。
- en: 'To work around these challenges, presizing adopts two strategies that are shown
    in [Figure 5-1](#presizing):'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这些挑战，预调整采用了[图5-1](#presizing)中显示的两种策略：
- en: Resize images to relatively “large” dimensions—that is, dimensions significantly
    larger than the target training dimensions.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将图像调整为相对“大”的尺寸，即明显大于目标训练尺寸。
- en: Compose all of the common augmentation operations (including a resize to the
    final target size) into one, and perform the combined operation on the GPU only
    once at the end of processing, rather than performing the operations individually
    and interpolating multiple times.
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将所有常见的增强操作（包括调整大小到最终目标大小）组合成一个，并在GPU上一次性执行组合操作，而不是单独执行操作并多次插值。
- en: The first step, the resize, creates images large enough that they have spare
    margin to allow further augmentation transforms on their inner regions without
    creating empty zones. This transformation works by resizing to a square, using
    a large crop size. On the training set, the crop area is chosen randomly, and
    the size of the crop is selected to cover the entire width or height of the image,
    whichever is smaller. In the second step, the GPU is used for all data augmentation,
    and all of the potentially destructive operations are done together, with a single
    interpolation at the end.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 第一步是调整大小，创建足够大的图像，使其内部区域有多余的边距，以允许进一步的增强变换而不会产生空白区域。这个转换通过调整大小为一个正方形，使用一个大的裁剪尺寸来实现。在训练集上，裁剪区域是随机选择的，裁剪的大小被选择为覆盖图像宽度或高度中较小的那个。在第二步中，GPU用于所有数据增强，并且所有潜在破坏性操作都一起完成，最后进行单次插值。
- en: '![Presizing on the training set](Images/dlcf_0501.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![训练集上的预调整](Images/dlcf_0501.png)'
- en: Figure 5-1\. Presizing on the training set
  id: totrans-46
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-1。训练集上的预调整
- en: 'This picture shows the two steps:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这张图片展示了两个步骤：
- en: '*Crop full width or height*: This is in `item_tfms`, so it’s applied to each
    individual image before it is copied to the GPU. It’s used to ensure all images
    are the same size. On the training set, the crop area is chosen randomly. On the
    validation set, the center square of the image is always chosen.'
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*裁剪全宽或全高*：这在`item_tfms`中，因此它应用于每个单独的图像，然后再复制到GPU。它用于确保所有图像具有相同的尺寸。在训练集上，裁剪区域是随机选择的。在验证集上，总是选择图像的中心正方形。'
- en: '*Random crop and augment*: This is in `batch_tfms`, so it’s applied to a batch
    all at once on the GPU, which means it’s fast. On the validation set, only the
    resize to the final size needed for the model is done here. On the training set,
    the random crop and any other augmentations are done first.'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*随机裁剪和增强*：这在`batch_tfms`中，因此它一次在GPU上应用于整个批次，这意味着速度快。在验证集上，只有调整大小到模型所需的最终大小。在训练集上，首先进行随机裁剪和任何其他增强。'
- en: To implement this process in fastai, you use `Resize` as an item transform with
    a large size, and `RandomResizedCrop` as a batch transform with a smaller size.
    `RandomResizedCrop` will be added for you if you include the `min_scale` parameter
    in your `aug_transforms` function, as was done in the `DataBlock` call in the
    previous section. Alternatively, you can use `pad` or `squish` instead of `crop`
    (the default) for the initial `Resize`.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 要在fastai中实现此过程，您可以使用`Resize`作为具有大尺寸的项目转换，以及`RandomResizedCrop`作为具有较小尺寸的批处理转换。如果在`aug_transforms`函数中包含`min_scale`参数，`RandomResizedCrop`将为您添加，就像在上一节中的`DataBlock`调用中所做的那样。或者，您可以在初始`Resize`中使用`pad`或`squish`而不是`crop`（默认值）。
- en: '[Figure 5-2](#fasai_data_augmentation) shows the difference between an image
    that has been zoomed, interpolated, rotated, and then interpolated again (which
    is the approach used by all other deep learning libraries), shown here on the
    right, and an image that has been zoomed and rotated as one operation and then
    interpolated once (the fastai approach), shown here on the left.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '[图5-2](#fasai_data_augmentation)显示了一个图像经过缩放、插值、旋转，然后再次插值（这是所有其他深度学习库使用的方法），显示在右侧，以及一个图像经过缩放和旋转作为一个操作，然后插值一次（fastai方法），显示在左侧。'
- en: '![](Images/dlcf_0502.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_0502.png)'
- en: Figure 5-2\. A comparison of fastai’s data augmentation strategy (left) and
    the traditional approach (right)
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-2。fastai数据增强策略（左）与传统方法（右）的比较
- en: You can see that the image on the right is less well defined and has reflection
    padding artifacts in the bottom-left corner; also, the grass at the top left has
    disappeared entirely. We find that, in practice, using presizing significantly
    improves the accuracy of models and often results in speedups too.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到右侧的图像定义不够清晰，在左下角有反射填充伪影；此外，左上角的草完全消失了。我们发现，在实践中，使用预调整显著提高了模型的准确性，通常也会加快速度。
- en: The fastai library also provides simple ways to check how your data looks right
    before training your model, which is an extremely important step. We’ll look at
    those next.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: fastai库还提供了简单的方法来检查您的数据在训练模型之前的外观，这是一个非常重要的步骤。我们将在下一步中看到这些。
- en: Checking and Debugging a DataBlock
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查和调试DataBlock
- en: We can never just assume that our code is working perfectly. Writing a `DataBlock`
    is like writing a blueprint. You will get an error message if you have a syntax
    error somewhere in your code, but you have no guarantee that your template is
    going to work on your data source as you intend. So, before training a model,
    you should always check your data.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们永远不能假设我们的代码完美运行。编写`DataBlock`就像编写蓝图一样。如果您的代码中有语法错误，您将收到错误消息，但是您无法保证您的模板会按照您的意图在数据源上运行。因此，在训练模型之前，您应该始终检查您的数据。
- en: 'You can do this using the `show_batch` method:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`show_batch`方法来执行此操作：
- en: '[PRE10]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '![](Images/dlcf_05in01.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_05in01.png)'
- en: 'Take a look at each image, and check that each one seems to have the correct
    label for that breed of pet. Often, data scientists work with data with which
    they are not as familiar as domain experts may be: for instance, I actually don’t
    know what a lot of these pet breeds are. Since I am not an expert on pet breeds,
    I would use Google images at this point to search for a few of these breeds, and
    make sure the images look similar to what I see in this output.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 查看每个图像，并检查每个图像是否具有正确的宠物品种标签。通常，数据科学家使用的数据可能不如领域专家熟悉：例如，我实际上不知道这些宠物品种中的许多是什么。由于我不是宠物品种的专家，我会在这一点上使用谷歌图像搜索一些这些品种，并确保图像看起来与我在输出中看到的相似。
- en: 'If you made a mistake while building your `DataBlock`, you likely won’t see
    it before this step. To debug this, we encourage you to use the `summary` method.
    It will attempt to create a batch from the source you give it, with a lot of details.
    Also, if it fails, you will see exactly at which point the error happens, and
    the library will try to give you some help. For instance, one common mistake is
    to forget to use a `Resize` transform, so you end up with pictures of different
    sizes and are not able to batch them. Here is what the summary would look like
    in that case (note that the exact text may have changed since the time of writing,
    but it will give you an idea):'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在构建`DataBlock`时出现错误，您可能在此步骤之前不会看到它。为了调试这个问题，我们鼓励您使用`summary`方法。它将尝试从您提供的源创建一个批次，并提供大量细节。此外，如果失败，您将准确地看到错误发生的位置，并且库将尝试为您提供一些帮助。例如，一个常见的错误是忘记使用`Resize`转换，因此最终得到不同大小的图片并且无法将它们整理成批次。在这种情况下，摘要将如下所示（请注意，自撰写时可能已更改确切文本，但它将给您一个概念）：
- en: '[PRE11]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: You can see exactly how we gathered the data and split it, how we went from
    a filename to a *sample* (the tuple (image, category)), then what item transforms
    were applied and how it failed to collate those samples in a batch (because of
    the different shapes).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到我们如何收集数据并拆分数据，如何从文件名转换为*样本*（元组（图像，类别）），然后应用了哪些项目转换以及如何在批处理中无法整理这些样本（因为形状不同）。
- en: Once you think your data looks right, we generally recommend the next step should
    be using it to train a simple model. We often see people put off the training
    of an actual model for far too long. As a result, they don’t find out what their
    baseline results look like. Perhaps your problem doesn’t require lots of fancy
    domain-specific engineering. Or perhaps the data doesn’t seem to train the model
    at all. These are things that you want to know as soon as possible.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您认为数据看起来正确，我们通常建议下一步应该使用它来训练一个简单的模型。我们经常看到人们将实际模型的训练推迟得太久。结果，他们不知道他们的基准结果是什么样的。也许您的问题不需要大量花哨的领域特定工程。或者数据似乎根本无法训练模型。这些都是您希望尽快了解的事情。
- en: 'For this initial test, we’ll use the same simple model that we used in [Chapter 1](ch01.xhtml#chapter_intro):'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个初始测试，我们将使用与[第1章](ch01.xhtml#chapter_intro)中使用的相同简单模型：
- en: '[PRE13]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '| epoch | train_loss | valid_loss | error_rate | time |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| epoch | train_loss | valid_loss | error_rate | time |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 1.491732 | 0.337355 | 0.108254 | 00:18 |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1.491732 | 0.337355 | 0.108254 | 00:18 |'
- en: '| epoch | train_loss | valid_loss | error_rate | time |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| epoch | train_loss | valid_loss | error_rate | time |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 0.503154 | 0.293404 | 0.096076 | 00:23 |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0.503154 | 0.293404 | 0.096076 | 00:23 |'
- en: '| 1 | 0.314759 | 0.225316 | 0.066306 | 00:23 |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.314759 | 0.225316 | 0.066306 | 00:23 |'
- en: As we’ve briefly discussed before, the table shown when we fit a model shows
    us the results after each epoch of training. Remember, an epoch is one complete
    pass through all of the images in the data. The columns shown are the average
    loss over the items of the training set, the loss on the validation set, and any
    metrics that we requested—in this case, the error rate.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前简要讨论过的，当我们拟合模型时显示的表格展示了每个训练周期后的结果。记住，一个周期是对数据中所有图像的完整遍历。显示的列是训练集中项目的平均损失、验证集上的损失，以及我们请求的任何指标——在这种情况下是错误率。
- en: Remember that *loss* is whatever function we’ve decided to use to optimize the
    parameters of our model. But we haven’t actually told fastai what loss function
    we want to use. So what is it doing? fastai will generally try to select an appropriate
    loss function based on the kind of data and model you are using. In this case,
    we have image data and a categorical outcome, so fastai will default to using
    *cross-entropy loss*.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住*损失*是我们决定用来优化模型参数的任何函数。但是我们实际上并没有告诉fastai我们想要使用什么损失函数。那么它在做什么呢？fastai通常会根据您使用的数据和模型类型尝试选择适当的损失函数。在这种情况下，我们有图像数据和分类结果，所以fastai会默认使用*交叉熵损失*。
- en: Cross-Entropy Loss
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交叉熵损失
- en: '*Cross-entropy loss* is a loss function that is similar to the one we used
    in the previous chapter, but (as we’ll see) has two benefits:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*交叉熵损失*是一个类似于我们在上一章中使用的损失函数，但是（正如我们将看到的）有两个好处：'
- en: It works even when our dependent variable has more than two categories.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使我们的因变量有两个以上的类别，它也能正常工作。
- en: It results in faster and more reliable training.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这将导致更快速、更可靠的训练。
- en: To understand how cross-entropy loss works for dependent variables with more
    than two categories, we first have to understand what the actual data and activations
    that are seen by the loss function look like.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解交叉熵损失如何处理具有两个以上类别的因变量，我们首先必须了解损失函数看到的实际数据和激活是什么样子的。
- en: Viewing Activations and Labels
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查看激活和标签
- en: 'Let’s take a look at the activations of our model. To get a batch of real data
    from our `DataLoaders`, we can use the `one_batch` method:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们模型的激活。要从我们的`DataLoaders`中获取一批真实数据，我们可以使用`one_batch`方法：
- en: '[PRE14]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'As you see, this returns the dependent and independent variables, as a mini-batch.
    Let’s see what is contained in our dependent variable:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所见，这返回了因变量和自变量，作为一个小批量。让我们看看我们的因变量中包含什么：
- en: '[PRE15]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Our batch size is 64, so we have 64 rows in this tensor. Each row is a single
    integer between 0 and 36, representing our 37 possible pet breeds. We can view
    the predictions (the activations of the final layer of our neural network) by
    using `Learner.get_preds`. This function takes either a dataset index (0 for train
    and 1 for valid) or an iterator of batches. Thus, we can pass it a simple list
    with our batch to get our predictions. It returns predictions and targets by default,
    but since we already have the targets, we can effectively ignore them by assigning
    to the special variable `_`:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的批量大小是64，因此在这个张量中有64行。每行是一个介于0和36之间的整数，代表我们37种可能的宠物品种。我们可以通过使用`Learner.get_preds`来查看预测（我们神经网络最后一层的激活）。这个函数默认返回预测和目标，但由于我们已经有了目标，我们可以通过将其赋值给特殊变量`_`来有效地忽略它们：
- en: '[PRE17]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The actual predictions are 37 probabilities between 0 and 1, which add up to
    1 in total:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 实际预测是37个介于0和1之间的概率，总和为1：
- en: '[PRE19]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: To transform the activations of our model into predictions like this, we used
    something called the *softmax* activation function.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将我们模型的激活转换为这样的预测，我们使用了一个叫做*softmax*的激活函数。
- en: Softmax
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Softmax
- en: In our classification model, we use the softmax activation function in the final
    layer to ensure that the activations are all between 0 and 1, and that they sum
    to 1.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的分类模型中，我们在最后一层使用softmax激活函数，以确保激活值都在0到1之间，并且它们总和为1。
- en: 'Softmax is similar to the sigmoid function, which we saw earlier. As a reminder,
    sigmoid looks like this:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Softmax类似于我们之前看到的sigmoid函数。作为提醒，sigmoid看起来像这样：
- en: '[PRE21]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '![](Images/dlcf_05in02.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_05in02.png)'
- en: We can apply this function to a single column of activations from a neural network
    and get back a column of numbers between 0 and 1, so it’s a very useful activation
    function for our final layer.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这个函数应用于神经网络的一个激活列，并得到一个介于0和1之间的数字列，因此对于我们的最后一层来说，这是一个非常有用的激活函数。
- en: 'Now think about what happens if we want to have more categories in our target
    (such as our 37 pet breeds). That means we’ll need more activations than just
    a single column: we need an activation *per category*. We can create, for instance,
    a neural net that predicts 3s and 7s that returns two activations, one for each
    class—this will be a good first step toward creating the more general approach.
    Let’s just use some random numbers with a standard deviation of 2 (so we multiply
    `randn` by 2) for this example, assuming we have six images and two possible categories
    (where the first column represents 3s and the second is 7s):'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在想象一下，如果我们希望目标中有更多类别（比如我们的37种宠物品种）。这意味着我们需要比单个列更多的激活：我们需要一个激活*每个类别*。例如，我们可以创建一个预测3和7的神经网络，返回两个激活，每个类别一个——这将是创建更一般方法的一个很好的第一步。让我们只是使用一些标准差为2的随机数（因此我们将`randn`乘以2）作为示例，假设我们有六个图像和两个可能的类别（其中第一列代表3，第二列代表7）：
- en: '[PRE22]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'We can’t just take the sigmoid of this directly, since we don’t get rows that
    add to 1 (we want the probability of being a 3 plus the probability of being a
    7 to add up to 1):'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不能直接对这个进行sigmoid运算，因为我们得不到行相加为1的结果（我们希望3的概率加上7的概率等于1）：
- en: '[PRE24]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'In [Chapter 4](ch04.xhtml#chapter_mnist_basics), our neural net created a single
    activation per image, which we passed through the `sigmoid` function. That single
    activation represented the model’s confidence that the input was a 3. Binary problems
    are a special case of classification problem, because the target can be treated
    as a single Boolean value, as we did in `mnist_loss`. But binary problems can
    also be thought of in the context of the more general group of classifiers with
    any number of categories: in this case, we happen to have two categories. As we
    saw in the bear classifier, our neural net will return one activation per category.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第4章](ch04.xhtml#chapter_mnist_basics)中，我们的神经网络为每个图像创建了一个单一激活，然后通过`sigmoid`函数传递。这个单一激活代表了模型对输入是3的置信度。二进制问题是分类问题的一种特殊情况，因为目标可以被视为单个布尔值，就像我们在`mnist_loss`中所做的那样。但是二进制问题也可以在任意数量的类别的分类器的更一般上下文中考虑：在这种情况下，我们碰巧有两个类别。正如我们在熊分类器中看到的，我们的神经网络将为每个类别返回一个激活。
- en: So in the binary case, what do those activations really indicate? A single pair
    of activations simply indicates the *relative* confidence of the input being a
    3 versus being a 7\. The overall values, whether they are both high or both low,
    don’t matter—all that matters is which is higher, and by how much.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 那么在二进制情况下，这些激活实际上表示什么？一对激活仅仅表示输入是3还是7的*相对*置信度。总体值，无论它们是高还是低，都不重要，重要的是哪个更高，以及高多少。
- en: 'We would expect that since this is just another way of representing the same
    problem, we would be able to use `sigmoid` directly on the two-activation version
    of our neural net. And indeed we can! We can just take the *difference* between
    the neural net activations, because that reflects how much more sure we are of
    the input being a 3 than a 7, and then take the sigmoid of that:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 我们期望，由于这只是表示相同问题的另一种方式，我们应该能够直接在我们的神经网络的两个激活版本上使用`sigmoid`。事实上我们可以！我们只需取神经网络激活之间的*差异*，因为这反映了我们对输入是3还是7更有把握的程度，然后取其sigmoid：
- en: '[PRE26]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The second column (the probability of it being a 7) will then just be that
    value subtracted from 1\. Now, we need a way to do all this that also works for
    more than two columns. It turns out that this function, called `softmax`, is exactly
    that:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 第二列（它是7的概率）将是该值从1中减去的值。现在，我们需要一种适用于多于两列的方法。事实证明，这个名为`softmax`的函数正是这样的：
- en: '[PRE28]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Jargon: Exponential Function (exp)'
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 术语：指数函数（exp）
- en: Defined as `e**x`, where `e` is a special number approximately equal to 2.718\.
    It is the inverse of the natural logarithm function. Note that `exp` is always
    positive and increases *very* rapidly!
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 定义为`e**x`，其中`e`是一个特殊的数字，约等于2.718。它是自然对数函数的倒数。请注意，`exp`始终为正，并且增长*非常*迅速！
- en: 'Let’s check that `softmax` returns the same values as `sigmoid` for the first
    column, and those values subtracted from 1 for the second column:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查`softmax`是否为第一列返回与`sigmoid`相同的值，以及这些值从1中减去的值为第二列：
- en: '[PRE29]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '`softmax` is the multi-category equivalent of `sigmoid`—we have to use it anytime
    we have more than two categories and the probabilities of the categories must
    add to 1, and we often use it even when there are just two categories, just to
    make things a bit more consistent. We could create other functions that have the
    properties that all activations are between 0 and 1, and sum to 1; however, no
    other function has the same relationship to the sigmoid function, which we’ve
    seen is smooth and symmetric. Also, we’ll see shortly that the softmax function
    works well hand in hand with the loss function we will look at in the next section.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`softmax`是`sigmoid`的多类别等价物——每当我们有超过两个类别且类别的概率必须加起来为1时，我们必须使用它，即使只有两个类别，我们通常也会使用它，只是为了使事情更加一致。我们可以创建其他具有所有激活在0和1之间且总和为1的属性的函数；然而，没有其他函数与我们已经看到是平滑且对称的sigmoid函数具有相同的关系。此外，我们很快将看到softmax函数与我们将在下一节中看到的损失函数密切配合。'
- en: If we have three output activations, such as in our bear classifier, calculating
    softmax for a single bear image would then look like something like [Figure 5-3](#bear_softmax).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们有三个输出激活，就像在我们的熊分类器中一样，为单个熊图像计算softmax看起来会像[图5-3](#bear_softmax)那样。
- en: '![Bear softmax example](Images/dlcf_0503.png)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![熊softmax示例](Images/dlcf_0503.png)'
- en: Figure 5-3\. Example of softmax on the bear classifier
  id: totrans-123
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-3. 熊分类器上softmax的示例
- en: 'What does this function do in practice? Taking the exponential ensures all
    our numbers are positive, and then dividing by the sum ensures we are going to
    have a bunch of numbers that add up to 1\. The exponential also has a nice property:
    if one of the numbers in our activations `x` is slightly bigger than the others,
    the exponential will amplify this (since it grows, well…exponentially), which
    means that in the softmax, that number will be closer to 1.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，这个函数是做什么的呢？取指数确保我们所有的数字都是正数，然后除以总和确保我们将得到一堆加起来等于1的数字。指数还有一个很好的特性：如果我们激活中的某个数字略大于其他数字，指数将放大这个差异（因为它呈指数增长），这意味着在softmax中，该数字将更接近1。
- en: Intuitively, the softmax function *really* wants to pick one class among the
    others, so it’s ideal for training a classifier when we know each picture has
    a definite label. (Note that it may be less ideal during inference, as you might
    want your model to sometimes tell you it doesn’t recognize any of the classes
    that it has seen during training, and not pick a class because it has a slightly
    bigger activation score. In this case, it might be better to train a model using
    multiple binary output columns, each using a sigmoid activation.)
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地，softmax函数*真的*想要在其他类别中选择一个类别，因此在我们知道每张图片都有一个明确标签时，训练分类器时是理想的选择。（请注意，在推断过程中可能不太理想，因为有时您可能希望模型告诉您它在训练过程中看到的类别中没有识别出任何一个，并且不选择一个类别，因为它的激活分数略高。在这种情况下，最好使用多个二进制输出列来训练模型，每个列使用sigmoid激活。）
- en: Softmax is the first part of the cross-entropy loss—the second part is log likelihood.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Softmax是交叉熵损失的第一部分，第二部分是对数似然。
- en: Log Likelihood
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对数似然
- en: 'When we calculated the loss for our MNIST example in the preceding chapter,
    we used this:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中为我们的MNIST示例计算损失时，我们使用了这个：
- en: '[PRE31]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Just as we moved from sigmoid to softmax, we need to extend the loss function
    to work with more than just binary classification—it needs to be able to classify
    any number of categories (in this case, we have 37 categories). Our activations,
    after softmax, are between 0 and 1, and sum to 1 for each row in the batch of
    predictions. Our targets are integers between 0 and 36.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 就像我们从sigmoid到softmax的转变一样，我们需要扩展损失函数，使其能够处理不仅仅是二元分类，还需要能够对任意数量的类别进行分类（在本例中，我们有37个类别）。我们的激活，在softmax之后，介于0和1之间，并且对于预测批次中的每一行，总和为1。我们的目标是介于0和36之间的整数。
- en: 'In the binary case, we used `torch.where` to select between `inputs` and `1-inputs`.
    When we treat a binary classification as a general classification problem with
    two categories, it becomes even easier, because (as we saw in the previous section)
    we now have two columns containing the equivalent of `inputs` and `1-inputs`.
    So, all we need to do is select from the appropriate column. Let’s try to implement
    this in PyTorch. For our synthetic 3s and 7s example, let’s say these are our
    labels:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在二元情况下，我们使用`torch.where`在`inputs`和`1-inputs`之间进行选择。当我们将二元分类作为具有两个类别的一般分类问题处理时，它变得更容易，因为（正如我们在前一节中看到的）现在有两列包含等同于`inputs`和`1-inputs`的内容。因此，我们只需要从适当的列中进行选择。让我们尝试在PyTorch中实现这一点。对于我们合成的3和7的示例，假设这些是我们的标签：
- en: '[PRE32]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'And these are the softmax activations:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是softmax激活：
- en: '[PRE33]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[PRE34]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Then for each item of `targ`, we can use that to select the appropriate column
    of `sm_acts` using tensor indexing, like so:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 然后对于每个“targ”项，我们可以使用它来使用张量索引选择“sm_acts”的适当列，如下所示：
- en: '[PRE35]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'To see exactly what’s happening here, let’s put all the columns together in
    a table. Here, the first two columns are our activations, then we have the targets,
    the row index, and finally the result shown in the preceding code:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 为了准确了解这里发生了什么，让我们将所有列放在一起放在一个表中。这里，前两列是我们的激活，然后是目标，行索引，最后是前面代码中显示的结果：
- en: '| 3 | 7 | targ | idx | loss |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 7 | targ | idx | loss |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0.602469 | 0.397531 | 0 | 0 | 0.602469 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| 0.602469 | 0.397531 | 0 | 0 | 0.602469 |'
- en: '| 0.502065 | 0.497935 | 1 | 1 | 0.497935 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| 0.502065 | 0.497935 | 1 | 1 | 0.497935 |'
- en: '| 0.133188 | 0.866811 | 0 | 2 | 0.133188 |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| 0.133188 | 0.866811 | 0 | 2 | 0.133188 |'
- en: '| 0.99664 | 0.00336017 | 1 | 3 | 0.00336017 |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 0.99664 | 0.00336017 | 1 | 3 | 0.00336017 |'
- en: '| 0.595949 | 0.404051 | 1 | 4 | 0.404051 |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| 0.595949 | 0.404051 | 1 | 4 | 0.404051 |'
- en: '| 0.366118 | 0.633882 | 0 | 5 | 0.366118 |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 0.366118 | 0.633882 | 0 | 5 | 0.366118 |'
- en: Looking at this table, you can see that the final column can be calculated by
    taking the `targ` and `idx` columns as indices into the two-column matrix containing
    the `3` and `7` columns. That’s what `sm_acts[idx, targ]` is doing.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个表中可以看出，最后一列可以通过将“targ”和“idx”列作为索引，指向包含“3”和“7”列的两列矩阵来计算。这就是`sm_acts[idx, targ]`的作用。
- en: The really interesting thing here is that this works just as well with more
    than two columns. To see this, consider what would happen if we added an activation
    column for every digit (0 through 9), and then `targ` contained a number from
    0 to 9\. As long as the activation columns sum to 1 (as they will, if we use softmax),
    we’ll have a loss function that shows how well we’re predicting each digit.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 这里真正有趣的是，这种方法同样适用于超过两列的情况。想象一下，如果我们为每个数字（0到9）添加一个激活列，然后“targ”包含从0到9的数字。只要激活列总和为1（如果我们使用softmax，它们将是这样），我们将有一个损失函数，显示我们预测每个数字的准确程度。
- en: We’re picking the loss only from the column containing the correct label. We
    don’t need to consider the other columns, because by the definition of softmax,
    they add up to 1 minus the activation corresponding to the correct label. Therefore,
    making the activation for the correct label as high as possible must mean we’re
    also decreasing the activations of the remaining columns.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们只从包含正确标签的列中选择损失。我们不需要考虑其他列，因为根据softmax的定义，它们加起来等于1减去与正确标签对应的激活。因此，使正确标签的激活尽可能高必须意味着我们也在降低其余列的激活。
- en: 'PyTorch provides a function that does exactly the same thing as `sm_acts[range(n),
    targ]` (except it takes the negative, because when applying the log afterward,
    we will have negative numbers), called `nll_loss` (*NLL* stands for *negative
    log likelihood*):'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch提供了一个与`sm_acts[range(n), targ]`完全相同的函数（除了它取负数，因为之后应用对数时，我们将得到负数），称为`nll_loss`（*NLL*代表*负对数似然*）：
- en: '[PRE37]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: '[PRE39]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Despite its name, this PyTorch function does not take the log. We’ll see why
    in the next section, but first, let’s see why taking the logarithm can be useful.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它的名字是这样的，但这个PyTorch函数并不取对数。我们将在下一节看到原因，但首先，让我们看看为什么取对数会有用。
- en: Taking the log
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 取对数
- en: 'The function we saw in the previous section works quite well as a loss function,
    but we can make it a bit better. The problem is that we are using probabilities,
    and probabilities cannot be smaller than 0 or greater than 1\. That means our
    model will not care whether it predicts 0.99 or 0.999\. Indeed, those numbers
    are very close together—but in another sense, 0.999 is 10 times more confident
    than 0.99\. So, we want to transform our numbers between 0 and 1 to instead be
    between negative infinity and infinity. There is a mathematical function that
    does exactly this: the *logarithm* (available as `torch.log`). It is not defined
    for numbers less than 0 and looks like this:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中我们看到的函数作为损失函数效果很好，但我们可以让它更好一些。问题在于我们使用的是概率，概率不能小于0或大于1。这意味着我们的模型不会在乎它是预测0.99还是0.999。确实，这些数字非常接近，但从另一个角度来看，0.999比0.99自信程度高10倍。因此，我们希望将我们的数字从0到1转换为从负无穷到无穷。有一个数学函数可以做到这一点：*对数*（可用`torch.log`）。它对小于0的数字没有定义，并且如下所示：
- en: '[PRE41]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '![](Images/dlcf_05in03.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_05in03.png)'
- en: 'Does “logarithm” ring a bell? The logarithm function has this identity:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: “对数”这个词让你想起了什么吗？对数函数有这个恒等式：
- en: '[PRE42]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'In this case, we’re assuming that `log(y,b)` returns *log y base b*. However,
    PyTorch doesn’t define `log` this way: `log` in Python uses the special number
    `e` (2.718…) as the base.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们假设`log(y,b)`返回*log y以b为底*。然而，PyTorch并没有这样定义`log`：Python中的`log`使用特殊数字`e`（2.718…）作为底。
- en: 'Perhaps a logarithm is something that you have not thought about for the last
    20 years or so. But it’s a mathematical idea that is going to be really critical
    for many things in deep learning, so now would be a great time to refresh your
    memory. The key thing to know about logarithms is this relationship:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 也许对数是您在过去20年中没有考虑过的东西。但对于深度学习中的许多事情来说，对数是一个非常关键的数学概念，所以现在是一个很好的时机来刷新您的记忆。关于对数的关键事情是这样的关系：
- en: '[PRE43]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: When we see it in that format, it looks a bit boring; but think about what this
    really means. It means that logarithms increase linearly when the underlying signal
    increases exponentially or multiplicatively. This is used, for instance, in the
    Richter scale of earthquake severity and the dB scale of noise levels. It’s also
    often used on financial charts, where we want to show compound growth rates more
    clearly. Computer scientists love using logarithms, because it means that modification,
    which can create really, really large and really, really small numbers, can be
    replaced by addition, which is much less likely to result in scales that are difficult
    for our computers to handle.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们以这种格式看到它时，它看起来有点无聊；但想想这实际上意味着什么。这意味着当基础信号呈指数或乘法增长时，对数会线性增加。例如，在地震严重程度的里氏震级和噪音级别的分贝尺中使用。它也经常用于金融图表中，我们希望更清楚地显示复合增长率。计算机科学家喜欢使用对数，因为这意味着可以用加法代替修改，这样可以避免产生计算机难以处理的难以处理的规模。
- en: Sylvain Says
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Sylvain说
- en: It’s not just computer scientists who love logs! Until computers came along,
    engineers and scientists used a special ruler called a *slide rule* that did multiplication
    by adding logarithms. Logarithms are widely used in physics, for multiplying very
    big or very small numbers, and many other fields.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 不仅是计算机科学家喜欢对数！在计算机出现之前，工程师和科学家使用一种称为*滑尺*的特殊尺子，通过添加对数来进行乘法运算。对数在物理学中被广泛用于乘法非常大或非常小的数字，以及许多其他领域。
- en: Taking the mean of the positive or negative log of our probabilities (depending
    on whether it’s the correct or incorrect class) gives us the *negative log likelihood*
    loss. In PyTorch, `nll_loss` assumes that you already took the log of the softmax,
    so it doesn’t do the logarithm for you.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 对我们的概率取正对数或负对数的平均值（取决于是否是正确或不正确的类）给出了*负对数似然*损失。在PyTorch中，`nll_loss`假设您已经对softmax取了对数，因此不会为您执行对数运算。
- en: Confusing Name, Beware
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 令人困惑的名称，注意
- en: The “nll” in `nll_loss` stands for “negative log likelihood,” but it doesn’t
    actually take the log at all! It assumes you have *already* taken the log. PyTorch
    has a function called `log_softmax` that combines `log` and `softmax` in a fast
    and accurate way. `nll_loss` is designed to be used after `log_softmax`.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '`nll_loss`中的“nll”代表“负对数似然”，但实际上它根本不进行对数运算！它假设您已经*已经*进行了对数运算。PyTorch有一个名为`log_softmax`的函数，以快速准确的方式结合了`log`和`softmax`。`nll_loss`设计用于在`log_softmax`之后使用。'
- en: 'When we first take the softmax, and then the log likelihood of that, that combination
    is called *cross-entropy loss*. In PyTorch, this is available as `nn.CrossEntropyLoss`
    (which, in practice, does `log_softmax` and then `nll_loss`):'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们首先进行softmax，然后对其进行对数似然，这种组合被称为*交叉熵损失*。在PyTorch中，这可以通过`nn.CrossEntropyLoss`来实现（实际上执行`log_softmax`然后`nll_loss`）：
- en: '[PRE44]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'As you see, this is a class. Instantiating it gives you an object that behaves
    like a function:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，这是一个类。实例化它会给您一个像函数一样行为的对象：
- en: '[PRE45]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'All PyTorch loss functions are provided in two forms, the class form just shown
    as well as a plain functional form, available in the `F` namespace:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 所有PyTorch损失函数都以两种形式提供，刚刚显示的类形式以及在`F`命名空间中提供的普通函数形式：
- en: '[PRE47]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Either one works fine and can be used in any situation. We’ve noticed that most
    people tend to use the class version, and that’s more often used in PyTorch’s
    official docs and examples, so we’ll tend to use that too.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 两者都可以正常工作，并且可以在任何情况下使用。我们注意到大多数人倾向于使用类版本，并且在PyTorch的官方文档和示例中更常见，因此我们也会倾向于使用它。
- en: 'By default, PyTorch loss functions take the mean of the loss of all items.
    You can use `reduction=''none''` to disable that:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，PyTorch损失函数取所有项目的损失的平均值。您可以使用`reduction='none'`来禁用这一点：
- en: '[PRE49]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Sylvain Says
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Sylvain说
- en: An interesting feature about cross-entropy loss appears when we consider its
    gradient. The gradient of `cross_entropy(a,b)` is `softmax(a)-b`. Since `softmax(a)`
    is the final activation of the model, that means that the gradient is proportional
    to the difference between the prediction and the target. This is the same as mean
    squared error in regression (assuming there’s no final activation function such
    as that added by `y_range`), since the gradient of `(a-b)**2` is `2*(a-b)`. Because
    the gradient is linear, we won’t see sudden jumps or exponential increases in
    gradients, which should lead to smoother training of models.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们考虑交叉熵损失的梯度时，一个有趣的特性就出现了。`cross_entropy(a,b)`的梯度是`softmax(a)-b`。由于`softmax(a)`是模型的最终激活，这意味着梯度与预测和目标之间的差异成比例。这与回归中的均方误差相同（假设没有像`y_range`添加的最终激活函数），因为`(a-b)**2`的梯度是`2*(a-b)`。由于梯度是线性的，我们不会看到梯度的突然跳跃或指数增加，这应该导致模型的平滑训练。
- en: We have now seen all the pieces hidden behind our loss function. But while this
    puts a number on how well (or badly) our model is doing, it does nothing to help
    us know if it’s any good. Let’s now see some ways to interpret our model’s predictions.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经看到了隐藏在我们损失函数背后的所有部分。但是，虽然这可以对我们的模型表现如何（好或坏）进行评估，但它对于帮助我们知道它是否好并没有任何帮助。现在让我们看看一些解释我们模型预测的方法。
- en: Model Interpretation
  id: totrans-187
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型解释
- en: It’s very hard to interpret loss functions directly, because they are designed
    to be things computers can differentiate and optimize, not things that people
    can understand. That’s why we have metrics. These are not used in the optimization
    process, but just to help us poor humans understand what’s going on. In this case,
    our accuracy is looking pretty good already! So where are we making mistakes?
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 直接解释损失函数非常困难，因为它们被设计为计算机可以区分和优化的东西，而不是人类可以理解的东西。这就是为什么我们有指标。这些指标不用于优化过程，而只是帮助我们这些可怜的人类理解发生了什么。在这种情况下，我们的准确率已经看起来相当不错！那么我们在哪里犯了错误呢？
- en: 'We saw in [Chapter 1](ch01.xhtml#chapter_intro) that we can use a confusion
    matrix to see where our model is doing well and where it’s doing badly:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第1章](ch01.xhtml#chapter_intro)中看到，我们可以使用混淆矩阵来查看模型表现好和表现不佳的地方：
- en: '[PRE51]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '![](Images/dlcf_05in04.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_05in04.png)'
- en: 'Oh, dear—in this case, a confusion matrix is very hard to read. We have 37
    pet breeds, which means we have 37×37 entries in this giant matrix! Instead, we
    can use the `most_confused` method, which just shows us the cells of the confusion
    matrix with the most incorrect predictions (here, with at least 5 or more):'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 哦，亲爱的——在这种情况下，混淆矩阵很难阅读。我们有37种宠物品种，这意味着在这个巨大矩阵中有37×37个条目！相反，我们可以使用`most_confused`方法，它只显示混淆矩阵中预测错误最多的单元格（这里至少有5个或更多）：
- en: '[PRE52]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[PRE53]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Since we are not pet breed experts, it is hard for us to know whether these
    category errors reflect actual difficulties in recognizing breeds. So again, we
    turn to Google. A little bit of Googling tells us that the most common category
    errors shown here are breed differences that even expert breeders sometimes disagree
    about. So this gives us some comfort that we are on the right track.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们不是宠物品种专家，很难知道这些类别错误是否反映了识别品种时的实际困难。因此，我们再次求助于谷歌。一点点搜索告诉我们，这里显示的最常见的类别错误是即使是专家育种者有时也会对其存在分歧的品种差异。因此，这让我们有些安慰，我们正在走在正确的道路上。
- en: We seem to have a good baseline. What can we do now to make it even better?
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 我们似乎有一个良好的基线。现在我们可以做些什么来使它变得更好呢？
- en: Improving Our Model
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 改进我们的模型
- en: We will now look at a range of techniques to improve the training of our model
    and make it better. While doing so, we will explain a little bit more about transfer
    learning and how to fine-tune our pretrained model as best as possible, without
    breaking the pretrained weights.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将探讨一系列技术，以改进我们模型的训练并使其更好。在此过程中，我们将更详细地解释迁移学习以及如何尽可能最好地微调我们的预训练模型，而不破坏预训练权重。
- en: The first thing we need to set when training a model is the learning rate. We
    saw in the previous chapter that it needs to be just right to train as efficiently
    as possible, so how do we pick a good one? fastai provides a tool for this.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练模型时，我们需要设置的第一件事是学习率。我们在上一章中看到，它需要恰到好处才能尽可能高效地训练，那么我们如何选择一个好的学习率呢？fastai提供了一个工具来帮助。
- en: The Learning Rate Finder
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 学习率查找器
- en: One of the most important things we can do when training a model is to make
    sure that we have the right learning rate. If our learning rate is too low, it
    can take many, many epochs to train our model. Not only does this waste time,
    but it also means that we may have problems with overfitting, because every time
    we do a complete pass through the data, we give our model a chance to memorize
    it.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练模型时，我们可以做的最重要的事情之一是确保我们有正确的学习率。如果我们的学习率太低，训练模型可能需要很多个epoch。这不仅浪费时间，还意味着我们可能会出现过拟合的问题，因为每次完整地遍历数据时，我们都给了模型记住数据的机会。
- en: 'So let’s just make our learning rate really high, right? Sure, let’s try that
    and see what happens:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 那么我们就把学习率调得很高，对吗？当然，让我们试试看会发生什么：
- en: '[PRE54]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '| epoch | train_loss | valid_loss | error_rate | time |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| epoch | train_loss | valid_loss | error_rate | time |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 8.946717 | 47.954632 | 0.893775 | 00:20 |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 8.946717 | 47.954632 | 0.893775 | 00:20 |'
- en: '| epoch | train_loss | valid_loss | error_rate | time |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| epoch | train_loss | valid_loss | error_rate | time |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 7.231843 | 4.119265 | 0.954668 | 00:24 |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 7.231843 | 4.119265 | 0.954668 | 00:24 |'
- en: That doesn’t look good. Here’s what happened. The optimizer stepped in the correct
    direction, but it stepped so far that it totally overshot the minimum loss. Repeating
    that multiple times makes it get further and further away, not closer and closer!
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来不太好。发生了什么呢。优化器朝着正确的方向迈出了一步，但它迈得太远，完全超过了最小损失。多次重复这样的过程会使其越来越远，而不是越来越接近！
- en: 'What do we do to find the perfect learning rate—not too high and not too low?
    In 2015, researcher Leslie Smith came up with a brilliant idea, called the *learning
    rate finder*. His idea was to start with a very, very small learning rate, something
    so small that we would never expect it to be too big to handle. We use that for
    one mini-batch, find what the losses are afterward, and then increase the learning
    rate by a certain percentage (e.g., doubling it each time). Then we do another
    mini-batch, track the loss, and double the learning rate again. We keep doing
    this until the loss gets worse, instead of better. This is the point where we
    know we have gone too far. We then select a learning rate a bit lower than this
    point. Our advice is to pick either of these:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们该如何找到完美的学习率——既不太高也不太低？在2015年，研究员Leslie Smith提出了一个绝妙的想法，称为*学习率查找器*。他的想法是从一个非常非常小的学习率开始，一个我们永远不会认为它太大而无法处理的学习率。我们用这个学习率进行一个mini-batch，找到之后的损失，然后按一定百分比增加学习率（例如每次加倍）。然后我们再做另一个mini-batch，跟踪损失，并再次加倍学习率。我们一直这样做，直到损失变得更糟，而不是更好。这是我们知道我们走得太远的时候。然后我们选择一个比这个点稍低的学习率。我们建议选择以下任一：
- en: One order of magnitude less than where the minimum loss was achieved (i.e., the
    minimum divided by 10)
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比最小损失达到的地方少一个数量级（即最小值除以10）
- en: The last point where the loss was clearly decreasing
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后一次损失明显减少的点
- en: 'The learning rate finder computes those points on the curve to help you. Both
    these rules usually give around the same value. In the first chapter, we didn’t
    specify a learning rate, using the default value from the fastai library (which
    is 1e-3):'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '![](Images/dlcf_05in05.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
- en: '[PRE56]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[PRE57]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'We can see on this plot that in the range 1e-6 to 1e-3, nothing really happens
    and the model doesn’t train. Then the loss starts to decrease until it reaches
    a minimum, and then increases again. We don’t want a learning rate greater than
    1e-1, as it will cause training to diverge (you can try for yourself), but 1e-1
    is already too high: at this stage, we’ve left the period where the loss was decreasing
    steadily.'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: 'In this learning rate plot, it appears that a learning rate around 3e-3 would
    be appropriate, so let’s choose that:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '| epoch | train_loss | valid_loss | error_rate | time |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
- en: '| 0 | 1.071820 | 0.427476 | 0.133965 | 00:19 |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
- en: '| epoch | train_loss | valid_loss | error_rate | time |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0.738273 | 0.541828 | 0.150880 | 00:24 |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0.401544 | 0.266623 | 0.081867 | 00:24 |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
- en: Logarithmic Scale
  id: totrans-229
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The learning rate finder plot has a logarithmic scale, which is why the middle
    point between 1e-3 and 1e-2 is between 3e-3 and 4e-3\. This is because we care
    mostly about the order of magnitude of the learning rate.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s interesting that the learning rate finder was discovered only in 2015,
    while neural networks have been under development since the 1950s. Throughout
    that time, finding a good learning rate has been, perhaps, the most important
    and challenging issue for practitioners. The solution does not require any advanced
    math, giant computing resources, huge datasets, or anything else that would make
    it inaccessible to any curious researcher. Furthermore, Smith was not part of
    some exclusive Silicon Valley lab, but was working as a naval researcher. All
    of this is to say: breakthrough work in deep learning absolutely does not require
    access to vast resources, elite teams, or advanced mathematical ideas. Lots of
    work remains to be done that requires just a bit of common sense, creativity,
    and tenacity.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have a good learning rate to train our model, let’s look at how
    we can fine-tune the weights of a pretrained model.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: Unfreezing and Transfer Learning
  id: totrans-233
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We discussed briefly in [Chapter 1](ch01.xhtml#chapter_intro) how transfer learning
    works. We saw that the basic idea is that a pretrained model, trained potentially
    on millions of data points (such as ImageNet), is fine-tuned for another task.
    But what does this really mean?
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: We now know that a convolutional neural network consists of many linear layers
    with a nonlinear activation function between each pair, followed by one or more
    final linear layers with an activation function such as softmax at the very end.
    The final linear layer uses a matrix with enough columns such that the output
    size is the same as the number of classes in our model (assuming that we are doing
    classification).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: This final linear layer is unlikely to be of any use for us when we are fine-tuning
    in a transfer learning setting, because it is specifically designed to classify
    the categories in the original pretraining dataset. So when we do transfer learning,
    we remove it, throw it away, and replace it with a new linear layer with the correct
    number of outputs for our desired task (in this case, there would be 37 activations).
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: This newly added linear layer will have entirely random weights. Therefore,
    our model prior to fine-tuning has entirely random outputs. But that does not
    mean that it is an entirely random model! All of the layers prior to the last
    one have been carefully trained to be good at image classification tasks in general.
    As we saw in the images from the [Zeiler and Fergus paper](https://oreil.ly/aTRwE)
    in [Chapter 1](ch01.xhtml#chapter_intro) (see Figures [1-10](ch01.xhtml#img_layer1)
    through [1-13](ch01.xhtml#img_layer4)), the first few layers encode general concepts,
    such as finding gradients and edges, and later layers encode concepts that are
    still useful for us, such as finding eyeballs and fur.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 这个新添加的线性层将完全随机的权重。因此，在微调之前，我们的模型具有完全随机的输出。但这并不意味着它是一个完全随机的模型！最后一个层之前的所有层都经过精心训练，以便在一般的图像分类任务中表现良好。正如我们在[Zeiler和Fergus论文](https://oreil.ly/aTRwE)中看到的那样，在[第1章](ch01.xhtml#chapter_intro)中（参见图[1-10](ch01.xhtml#img_layer1)到[1-13](ch01.xhtml#img_layer4)），前几层编码了一般概念，比如找到梯度和边缘，后面的层编码了对我们仍然有用的概念，比如找到眼球和毛发。
- en: We want to train a model in such a way that we allow it to remember all of these
    generally useful ideas from the pretrained model, use them to solve our particular
    task (classify pet breeds), and adjust them only as required for the specifics
    of our particular task.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望以这样的方式训练模型，使其能够记住预训练模型中的所有这些通常有用的想法，用它们来解决我们的特定任务（分类宠物品种），并仅根据我们特定任务的具体要求进行调整。
- en: 'Our challenge when fine-tuning is to replace the random weights in our added
    linear layers with weights that correctly achieve our desired task (classifying
    pet breeds) without breaking the carefully pretrained weights and the other layers.
    A simple trick can allow this to happen: tell the optimizer to update the weights
    in only those randomly added final layers. Don’t change the weights in the rest
    of the neural network at all. This is called *freezing* those pretrained layers.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在微调时，我们的挑战是用能够正确实现我们所需任务（分类宠物品种）的权重替换我们添加的线性层中的随机权重，而不破坏精心预训练的权重和其他层。一个简单的技巧可以实现这一点：告诉优化器仅更新那些随机添加的最终层中的权重。根本不要改变神经网络的其他部分的权重。这被称为*冻结*那些预训练的层。
- en: 'When we create a model from a pretrained network, fastai automatically freezes
    all of the pretrained layers for us. When we call the `fine_tune` method, fastai
    does two things:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们从预训练网络创建模型时，fastai会自动为我们冻结所有预训练层。当我们调用`fine_tune`方法时，fastai会做两件事：
- en: Trains the randomly added layers for one epoch, with all other layers frozen
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练随机添加的层一个周期，同时冻结所有其他层
- en: Unfreezes all the layers, and trains them for the number of epochs requested
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解冻所有层，并根据请求的周期数进行训练
- en: 'Although this is a reasonable default approach, it is likely that for your
    particular dataset, you may get better results by doing things slightly differently.
    The `fine_tune` method has parameters you can use to change its behavior, but
    it might be easiest for you to just call the underlying methods directly if you
    want to get custom behavior. Remember that you can see the source code for the
    method by using the following syntax:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这是一个合理的默认方法，但对于您的特定数据集，您可能通过稍微不同的方式做事情来获得更好的结果。`fine_tune`方法有一些参数可以用来改变其行为，但如果您想获得自定义行为，直接调用底层方法可能更容易。请记住，您可以使用以下语法查看该方法的源代码：
- en: '[PRE59]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'So let’s try doing this manually ourselves. First of all, we will train the
    randomly added layers for three epochs, using `fit_one_cycle`. As mentioned in
    [Chapter 1](ch01.xhtml#chapter_intro), `fit_one_cycle` is the suggested way to
    train models without using `fine_tune`. We’ll see why later in the book; in short,
    what `fit_one_cycle` does is to start training at a low learning rate, gradually
    increase it for the first section of training, and then gradually decrease it
    again for the last section of training:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我们尝试手动操作。首先，我们将使用`fit_one_cycle`训练随机添加的层三个周期。正如在[第1章](ch01.xhtml#chapter_intro)中提到的，`fit_one_cycle`是在不使用`fine_tune`的情况下训练模型的建议方法。我们将在本书后面看到原因；简而言之，`fit_one_cycle`的作用是以低学习率开始训练，逐渐增加学习率进行第一部分的训练，然后在最后一部分的训练中逐渐降低学习率：
- en: '[PRE60]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '| epoch | train_loss | valid_loss | error_rate | time |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| epoch | train_loss | valid_loss | error_rate | time |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 1.188042 | 0.355024 | 0.102842 | 00:20 |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1.188042 | 0.355024 | 0.102842 | 00:20 |'
- en: '| 1 | 0.534234 | 0.302453 | 0.094723 | 00:20 |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.534234 | 0.302453 | 0.094723 | 00:20 |'
- en: '| 2 | 0.325031 | 0.222268 | 0.074425 | 00:20 |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.325031 | 0.222268 | 0.074425 | 00:20 |'
- en: 'Then we’ll unfreeze the model:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们将解冻模型：
- en: '[PRE61]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'and run `lr_find` again, because having more layers to train, and weights that
    have already been trained for three epochs, means our previously found learning
    rate isn’t appropriate anymore:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 并再次运行`lr_find`，因为有更多层要训练，而且已经训练了三个周期的权重，意味着我们之前找到的学习率不再合适：
- en: '[PRE62]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '[PRE63]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: '![](Images/dlcf_05in06.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_05in06.png)'
- en: 'Note that the graph is a little different from when we had random weights:
    we don’t have that sharp descent that indicates the model is training. That’s
    because our model has been trained already. Here we have a somewhat flat area
    before a sharp increase, and we should take a point well before that sharp increase—for
    instance, 1e-5\. The point with the maximum gradient isn’t what we look for here
    and should be ignored.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，图表与随机权重时有所不同：我们没有那种表明模型正在训练的陡峭下降。这是因为我们的模型已经训练过了。在这里，我们有一个相对平坦的区域，然后是一个急剧增加的区域，我们应该选择在那个急剧增加之前的一个点，例如1e-5。具有最大梯度的点不是我们在这里寻找的，应该被忽略。
- en: 'Let’s train at a suitable learning rate:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以适当的学习率进行训练：
- en: '[PRE64]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '| epoch | train_loss | valid_loss | error_rate | time |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| epoch | train_loss | valid_loss | error_rate | time |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 0.263579 | 0.217419 | 0.069012 | 00:24 |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0.263579 | 0.217419 | 0.069012 | 00:24 |'
- en: '| 1 | 0.253060 | 0.210346 | 0.062923 | 00:24 |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.253060 | 0.210346 | 0.062923 | 00:24 |'
- en: '| 2 | 0.224340 | 0.207357 | 0.060217 | 00:24 |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.224340 | 0.207357 | 0.060217 | 00:24 |'
- en: '| 3 | 0.200195 | 0.207244 | 0.061570 | 00:24 |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0.200195 | 0.207244 | 0.061570 | 00:24 |'
- en: '| 4 | 0.194269 | 0.200149 | 0.059540 | 00:25 |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 0.194269 | 0.200149 | 0.059540 | 00:25 |'
- en: '| 5 | 0.173164 | 0.202301 | 0.059540 | 00:25 |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 0.173164 | 0.202301 | 0.059540 | 00:25 |'
- en: This has improved our model a bit, but there’s more we can do. The deepest layers
    of our pretrained model might not need as high a learning rate as the last ones,
    so we should probably use different learning rates for those—this is known as
    using *discriminative* learning rates.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 这稍微改进了我们的模型，但我们还可以做更多。预训练模型的最深层可能不需要像最后一层那样高的学习率，因此我们可能应该为这些层使用不同的学习率——这被称为使用*区分性*学习率。
- en: Discriminative Learning Rates
  id: totrans-270
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 区分性学习率
- en: Even after we unfreeze, we still care a lot about the quality of those pretrained
    weights. We would not expect that the best learning rate for those pretrained
    parameters would be as high as for the randomly added parameters, even after we
    have tuned those randomly added parameters for a few epochs. Remember, the pretrained
    weights have been trained for hundreds of epochs, on millions of images.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们解冻后，我们仍然非常关心那些预训练权重的质量。我们不会期望那些预训练参数的最佳学习率与随机添加参数的学习率一样高，即使在我们为随机添加参数调整了几个轮数之后。请记住，预训练权重已经在数百个轮数中，在数百万张图像上进行了训练。
- en: In addition, do you remember the images we saw in [Chapter 1](ch01.xhtml#chapter_intro),
    showing what each layer learns? The first layer learns very simple foundations,
    like edge and gradient detectors; these are likely to be just as useful for nearly
    any task. The later layers learn much more complex concepts, like “eye” and “sunset,”
    which might not be useful in your task at all (maybe you’re classifying car models,
    for instance). So it makes sense to let the later layers fine-tune more quickly
    than earlier layers.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您还记得我们在[第1章](ch01.xhtml#chapter_intro)中看到的图像吗？显示每个层学习的内容？第一层学习非常简单的基础知识，如边缘和梯度检测器；这些对于几乎任何任务都可能非常有用。后面的层学习更复杂的概念，如“眼睛”和“日落”，这些对您的任务可能完全没有用（也许您正在对汽车型号进行分类）。因此，让后面的层比前面的层更快地微调是有道理的。
- en: 'Therefore, fastai’s default approach is to use discriminative learning rates.
    This technique was originally developed in the ULMFiT approach to NLP transfer
    learning that we will introduce in [Chapter 10](ch10.xhtml#chapter_nlp). Like
    many good ideas in deep learning, it is extremely simple: use a lower learning
    rate for the early layers of the neural network, and a higher learning rate for
    the later layers (and especially the randomly added layers). The idea is based
    on insights developed by [Jason Yosinski et al.](https://oreil.ly/j3640), who
    showed in 2014 that with transfer learning, different layers of a neural network
    should train at different speeds, as seen in [Figure 5-4](#yosinski).'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，fastai的默认方法是使用区分性学习率。这种技术最初是在我们将在[第10章](ch10.xhtml#chapter_nlp)中介绍的NLP迁移学习的ULMFiT方法中开发的。就像深度学习中的许多好主意一样，这个方法非常简单：对神经网络的早期层使用较低的学习率，对后期层（尤其是随机添加的层）使用较高的学习率。这个想法基于[Jason
    Yosinski等人](https://oreil.ly/j3640)在2014年展示的见解，即在迁移学习中，神经网络的不同层应该以不同的速度训练，如[图5-4](#yosinski)所示。
- en: '![Impact of different layers and training methods on transfer learning (Yosinski)](Images/dlcf_0504.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![不同层和训练方法对迁移学习的影响（Yosinski）](Images/dlcf_0504.png)'
- en: Figure 5-4\. Impact of different layers and training methods on transfer learning
    (courtesy of Jason Yosinski et al.)
  id: totrans-275
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图5-4。不同层和训练方法对迁移学习的影响（由Jason Yosinski等人提供）
- en: 'fastai lets you pass a Python `slice` object anywhere that a learning rate
    is expected. The first value passed will be the learning rate in the earliest
    layer of the neural network, and the second value will be the learning rate in
    the final layer. The layers in between will have learning rates that are multiplicatively
    equidistant throughout that range. Let’s use this approach to replicate the previous
    training, but this time we’ll set only the *lowest* layer of our net to a learning
    rate of 1e-6; the other layers will scale up to 1e-4\. Let’s train for a while
    and see what happens:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: fastai允许您在任何需要学习率的地方传递Python `slice`对象。传递的第一个值将是神经网络最早层的学习率，第二个值将是最后一层的学习率。中间的层将在该范围内等距地乘法地具有学习率。让我们使用这种方法复制先前的训练，但这次我们只将我们网络的*最低*层的学习率设置为1e-6；其他层将增加到1e-4。让我们训练一段时间，看看会发生什么：
- en: '[PRE65]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '| epoch | train_loss | valid_loss | error_rate | time |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| 轮数 | 训练损失 | 验证损失 | 错误率 | 时间 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 1.145300 | 0.345568 | 0.119756 | 00:20 |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1.145300 | 0.345568 | 0.119756 | 00:20 |'
- en: '| 1 | 0.533986 | 0.251944 | 0.077131 | 00:20 |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.533986 | 0.251944 | 0.077131 | 00:20 |'
- en: '| 2 | 0.317696 | 0.208371 | 0.069012 | 00:20 |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.317696 | 0.208371 | 0.069012 | 00:20 |'
- en: '| epoch | train_loss | valid_loss | error_rate | time |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| 轮数 | 训练损失 | 验证损失 | 错误率 | 时间 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 0.257977 | 0.205400 | 0.067659 | 00:25 |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0.257977 | 0.205400 | 0.067659 | 00:25 |'
- en: '| 1 | 0.246763 | 0.205107 | 0.066306 | 00:25 |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.246763 | 0.205107 | 0.066306 | 00:25 |'
- en: '| 2 | 0.240595 | 0.193848 | 0.062246 | 00:25 |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.240595 | 0.193848 | 0.062246 | 00:25 |'
- en: '| 3 | 0.209988 | 0.198061 | 0.062923 | 00:25 |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0.209988 | 0.198061 | 0.062923 | 00:25 |'
- en: '| 4 | 0.194756 | 0.193130 | 0.064276 | 00:25 |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 0.194756 | 0.193130 | 0.064276 | 00:25 |'
- en: '| 5 | 0.169985 | 0.187885 | 0.056157 | 00:25 |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 0.169985 | 0.187885 | 0.056157 | 00:25 |'
- en: '| 6 | 0.153205 | 0.186145 | 0.058863 | 00:25 |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 0.153205 | 0.186145 | 0.058863 | 00:25 |'
- en: '| 7 | 0.141480 | 0.185316 | 0.053451 | 00:25 |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 0.141480 | 0.185316 | 0.053451 | 00:25 |'
- en: '| 8 | 0.128564 | 0.180999 | 0.051421 | 00:25 |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 0.128564 | 0.180999 | 0.051421 | 00:25 |'
- en: '| 9 | 0.126941 | 0.186288 | 0.054127 | 00:25 |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 0.126941 | 0.186288 | 0.054127 | 00:25 |'
- en: '| 10 | 0.130064 | 0.181764 | 0.054127 | 00:25 |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 0.130064 | 0.181764 | 0.054127 | 00:25 |'
- en: '| 11 | 0.124281 | 0.181855 | 0.054127 | 00:25 |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| 11 | 0.124281 | 0.181855 | 0.054127 | 00:25 |'
- en: Now the fine-tuning is working great!
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 现在微调效果很好！
- en: 'fastai can show us a graph of the training and validation loss:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: fastai可以展示训练和验证损失的图表：
- en: '[PRE66]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: '![](Images/dlcf_05in07.png)'
  id: totrans-300
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_05in07.png)'
- en: As you can see, the training loss keeps getting better and better. But notice
    that eventually the validation loss improvement slows and sometimes even gets
    worse! This is the point at which the model is starting to overfit. In particular,
    the model is becoming overconfident of its predictions. But this does *not* mean
    that it is getting less accurate, necessarily. Take a look at the table of training
    results per epoch, and you will often see that the accuracy continues improving,
    even as the validation loss gets worse. In the end, what matters is your accuracy,
    or more generally your chosen metrics, not the loss. The loss is just the function
    we’ve given the computer to help us to optimize.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: Another decision you have to make when training the model is how long to train
    for. We’ll consider that next.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: Selecting the Number of Epochs
  id: totrans-303
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Often you will find that you are limited by time, rather than generalization
    and accuracy, when choosing how many epochs to train for. So your first approach
    to training should be to simply pick a number of epochs that will train in the
    amount of time that you are happy to wait for. Then look at the training and validation
    loss plots, as shown previously, and in particular your metrics. If you see that
    they are still getting better even in your final epochs, you know that you have
    not trained for too long.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, you may well see that the metrics you have chosen are really
    getting worse at the end of training. Remember, it’s not just that we’re looking
    for the validation loss to get worse, but the actual metrics. Your validation
    loss will first get worse during training because the model gets overconfident,
    and only later will get worse because it is incorrectly memorizing the data. We
    care in practice about only the latter issue. Remember, our loss function is something
    that we use to allow our optimizer to have something it can differentiate and
    optimize; it’s not the thing we care about in practice.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: Before the days of 1cycle training, it was common to save the model at the end
    of each epoch, and then select whichever model had the best accuracy out of all
    of the models saved in each epoch. This is known as *early stopping*. However,
    this is unlikely to give you the best answer, because those epochs in the middle
    occur before the learning rate has had a chance to reach the small values, where
    it can really find the best result. Therefore, if you find that you have overfit,
    what you should do is retrain your model from scratch, and this time select a
    total number of epochs based on where your previous best results were found.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: If you have the time to train for more epochs, you may want to instead use that
    time to train more parameters—that is, use a deeper architecture.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: Deeper Architectures
  id: totrans-308
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In general, a model with more parameters can model your data more accurately.
    (There are lots and lots of caveats to this generalization, and it depends on
    the specifics of the architectures you are using, but it is a reasonable rule
    of thumb for now.) For most of the architectures that we will be seeing in this
    book, you can create larger versions of them by simply adding more layers. However,
    since we want to use pretrained models, we need to make sure that we choose a
    number of layers that have already been pretrained for us.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: This is why, in practice, architectures tend to come in a small number of variants.
    For instance, the ResNet architecture that we are using in this chapter comes
    in variants with 18, 34, 50, 101, and 152 layers, pretrained on ImageNet. A larger
    (more layers and parameters; sometimes described as the *capacity* of a model)
    version of a ResNet will always be able to give us a better training loss, but
    it can suffer more from overfitting, because it has more parameters to overfit
    with.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: In general, a bigger model has the ability to better capture the real underlying
    relationships in your data, as well as to capture and memorize the specific details
    of your individual images.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: 'However, using a deeper model is going to require more GPU RAM, so you may
    need to lower the size of your batches to avoid an *out-of-memory error*. This
    happens when you try to fit too much inside your GPU and looks like this:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: You may have to restart your notebook when this happens. The way to solve it
    is to use a smaller batch size, which means passing smaller groups of images at
    any given time through your model. You can pass the batch size you want to the
    call by creating your `DataLoaders` with `bs=`.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: The other downside of deeper architectures is that they take quite a bit longer
    to train. One technique that can speed things up a lot is *mixed-precision training*.
    This refers to using less-precise numbers (*half-precision floating point*, also
    called *fp16*) where possible during training. As we are writing these words in
    early 2020, nearly all current NVIDIA GPUs support a special feature called *tensor
    cores* that can dramatically speed up neural network training, by 2–3×. They also
    require a lot less GPU memory. To enable this feature in fastai, just add `to_fp16()`
    after your `Learner` creation (you also need to import the module).
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: 'You can’t really know the best architecture for your particular problem ahead
    of time—you need to try training some. So let’s try a ResNet-50 now with mixed
    precision:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '| epoch | train_loss | valid_loss | error_rate | time |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
- en: '| 0 | 1.427505 | 0.310554 | 0.098782 | 00:21 |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0.606785 | 0.302325 | 0.094723 | 00:22 |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
- en: '| 2 | 0.409267 | 0.294803 | 0.091340 | 00:21 |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
- en: '| epoch | train_loss | valid_loss | error_rate | time |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0.261121 | 0.274507 | 0.083897 | 00:26 |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0.296653 | 0.318649 | 0.084574 | 00:26 |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
- en: '| 2 | 0.242356 | 0.253677 | 0.069012 | 00:26 |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
- en: '| 3 | 0.150684 | 0.251438 | 0.065629 | 00:26 |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
- en: '| 4 | 0.094997 | 0.239772 | 0.064276 | 00:26 |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
- en: '| 5 | 0.061144 | 0.228082 | 0.054804 | 00:26 |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
- en: You’ll see here we’ve gone back to using `fine_tune`, since it’s so handy! We
    can pass `freeze_epochs` to tell fastai how many epochs to train for while frozen.
    It will automatically change learning rates appropriately for most datasets.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: In this case, we’re not seeing a clear win from the deeper model. This is useful
    to remember—bigger models aren’t necessarily better models for your particular
    case! Make sure you try small models before you start scaling up.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  id: totrans-333
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned some important practical tips, both for getting
    your image data ready for modeling (presizing, data block summary) and for fitting
    the model (learning rate finder, unfreezing, discriminative learning rates, setting
    the number of epochs, and using deeper architectures). Using these tools will
    help you to build more accurate image models, more quickly.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: We also discussed cross-entropy loss. This part of the book is worth spending
    plenty of time on. You aren’t likely to need to implement cross-entropy loss from
    scratch yourself in practice, but it’s important you understand the inputs to
    and output from that function, because it (or a variant of it, as we’ll see in
    the next chapter) is used in nearly every classification model. So when you want
    to debug a model, or put a model in production, or improve the accuracy of a model,
    you’re going to need to be able to look at its activations and loss, and understand
    what’s going on, and why. You can’t do that properly if you don’t understand your
    loss function.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: If cross-entropy loss hasn’t “clicked” for you just yet, don’t worry—you’ll
    get there! First, go back to the preceding chapter and make sure you really understand
    `mnist_loss`. Then work gradually through the cells of the notebook for this chapter,
    where we step through each piece of cross-entropy loss. Make sure you understand
    what each calculation is doing and why. Try creating some small tensors yourself
    and pass them into the functions, to see what they return.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember: the choices made in the implementation of cross-entropy loss are
    not the only possible choices that could have been made. Just as when we looked
    at regression we could choose between mean squared error and mean absolute difference
    (L1), we could change the details here too. If you have other ideas for possible
    functions that you think might work, feel free to give them a try in this chapter’s
    notebook! (Fair warning, though: you’ll probably find that the model will be slower
    to train and less accurate. That’s because the gradient of cross-entropy loss
    is proportional to the difference between the activation and the target, so SGD
    always gets a nicely scaled step for the weights.)'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 记住：在实现交叉熵损失时所做的选择并不是唯一可能的选择。就像我们在回归中可以在均方误差和平均绝对差（L1）之间进行选择一样，这里也可以改变细节。如果您对可能有效的其他函数有其他想法，请随时在本章的笔记本中尝试！（但要注意：您可能会发现模型训练速度较慢，准确性较低。这是因为交叉熵损失的梯度与激活和目标之间的差异成比例，因此SGD始终会为权重提供一个很好的缩放步长。）
- en: Questionnaire
  id: totrans-338
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问卷调查
- en: Why do we first resize to a large size on the CPU, and then to a smaller size
    on the GPU?
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么我们首先在CPU上调整大小到较大尺寸，然后在GPU上调整到较小尺寸？
- en: If you are not familiar with regular expressions, find a regular expression
    tutorial and some problem sets, and complete them. Have a look on the book’s website
    for suggestions.
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您不熟悉正则表达式，请查找正则表达式教程和一些问题集，并完成它们。查看书籍网站以获取建议。
- en: What are the two ways in which data is most commonly provided for most deep
    learning datasets?
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于大多数深度学习数据集，数据通常以哪两种方式提供？
- en: Look up the documentation for `L` and try using a few of the new methods that
    it adds.
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查阅`L`的文档，并尝试使用它添加的一些新方法。
- en: Look up the documentation for the Python `pathlib` module and try using a few
    methods of the `Path` class.
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 查阅Python `pathlib`模块的文档，并尝试使用`Path`类的几种方法。
- en: Give two examples of ways that image transformations can degrade the quality
    of the data.
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 给出两个图像转换可能降低数据质量的示例。
- en: What method does fastai provide to view the data in a `DataLoaders`?
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: fastai提供了哪种方法来查看`DataLoaders`中的数据？
- en: What method does fastai provide to help you debug a `DataBlock`?
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: fastai提供了哪种方法来帮助您调试`DataBlock`？
- en: Should you hold off on training a model until you have thoroughly cleaned your
    data?
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在彻底清理数据之前，是否应该暂停训练模型？
- en: What are the two pieces that are combined into cross-entropy loss in PyTorch?
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在PyTorch中，交叉熵损失是由哪两个部分组合而成的？
- en: What are the two properties of activations that softmax ensures? Why is this
    important?
  id: totrans-349
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: softmax确保的激活函数的两个属性是什么？为什么这很重要？
- en: When might you want your activations to not have these two properties?
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 何时可能希望激活函数不具有这两个属性？
- en: Calculate the `exp` and `softmax` columns of [Figure 5-3](#bear_softmax) yourself
    (i.e., in a spreadsheet, with a calculator, or in a notebook).
  id: totrans-351
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自己计算[图5-3](#bear_softmax)中的`exp`和`softmax`列（即在电子表格、计算器或笔记本中）。
- en: Why can’t we use `torch.where` to create a loss function for datasets where
    our label can have more than two categories?
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么我们不能使用`torch.where`为标签可能有多于两个类别的数据集创建损失函数？
- en: What is the value of log(–2)? Why?
  id: totrans-353
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: log（-2）的值是多少？为什么？
- en: What are two good rules of thumb for picking a learning rate from the learning
    rate finder?
  id: totrans-354
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择学习率时有哪两个好的经验法则来自学习率查找器？
- en: What two steps does the `fine_tune` method do?
  id: totrans-355
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`fine_tune`方法执行了哪两个步骤？'
- en: In Jupyter Notebook, how do you get the source code for a method or function?
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Jupyter Notebook中，如何获取方法或函数的源代码？
- en: What are discriminative learning rates?
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是区分性学习率？
- en: How is a Python `slice` object interpreted when passed as a learning rate to
    fastai?
  id: totrans-358
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当将Python `slice`对象作为学习率传递给fastai时，它是如何解释的？
- en: Why is early stopping a poor choice when using 1cycle training?
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么在使用1cycle训练时，提前停止是一个不好的选择？
- en: What is the difference between `resnet50` and `resnet101`?
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`resnet50`和`resnet101`之间有什么区别？'
- en: What does `to_fp16` do?
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`to_fp16`是做什么的？'
- en: Further Research
  id: totrans-362
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步研究
- en: Find the paper by Leslie Smith that introduced the learning rate finder, and
    read it.
  id: totrans-363
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 找到Leslie Smith撰写的介绍学习率查找器的论文，并阅读。
- en: See if you can improve the accuracy of the classifier in this chapter. What’s
    the best accuracy you can achieve? Look on the forums and the book’s website to
    see what other students have achieved with this dataset and how they did it.
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 看看是否可以提高本章分类器的准确性。您能达到的最佳准确性是多少？查看论坛和书籍网站，看看其他学生在这个数据集上取得了什么成就以及他们是如何做到的。
