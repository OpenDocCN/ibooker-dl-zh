<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd"><html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <title>chapter-9</title>
  <link href="../../stylesheet.css" rel="stylesheet" type="text/css" />
 </head>
 <body>
  <div class="readable-text" id="p1"> 
   <h1 class=" readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">9</span> </span><span class="chapter-title-text">RAG development framework and further exploration</span></h1> 
  </div> 
  <div class="introduction-summary"> 
   <h3 class="introduction-header"><span class="CharOverride-1">This chapter covers</span></h3> 
   <ul> 
    <li class="readable-text" id="p2"><span class="CharOverride-2">A recap of the concepts covered in this book using a six-stage RAG development framework</span></li> 
    <li class="readable-text" id="p3"><span class="CharOverride-2">Areas for further exploration</span></li> 
   </ul> 
  </div> 
  <div class="readable-text" id="p4"> 
   <p>The previous eight chapters covered a wide breadth of retrieval-augmented generation (RAG), including a conceptual foundation, critical components, evaluation methods, advanced techniques, the operations stack, and essential variants of RAG. By now, you should be equipped with the necessary information required to develop RAG systems. </p> 
  </div> 
  <div class="readable-text intended-text" id="p5"> 
   <p>This concluding chapter summarizes the discussion and recaps all the previously discussed concepts. To accomplish this, we put all the different aspects of developing RAG systems together and came up with a RAG development framework. Across the six stages of this RAG development framework, we recap the concepts covered in this book along with some best practices. This framework not only covers the technical aspects but also looks at the development process holistically.</p> 
  </div> 
  <div class="readable-text intended-text" id="p6"> 
   <p>RAG is a rapidly evolving technique. At the end of this chapter, we also discuss some of the ideas that you can explore further. Some of these approaches to incorporating context may compete with the RAG technique, while others may be complementary. </p> 
  </div> 
  <div class="readable-text intended-text" id="p7"> 
   <p>By the end of this chapter, you should </p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p8">Have reviewed and consolidated your understanding of key RAG concepts.</li> 
   <li class="readable-text" id="p9">Get a solid understanding of the RAG development framework. </li> 
   <li class="readable-text" id="p10">Be ready to build and deploy RAG systems.</li> 
  </ul> 
  <div class="readable-text" id="p11"> 
   <p>Often, the problem statements that the developer of a RAG system is presented with will be open ended. For example, an e-commerce platform wants to develop a buying assistant, or the marketing function wants a research agent to track and summarize competitive information. So, how does one navigate from an open-ended problem statement to a fully developed RAG system? It becomes very important that this journey is guided by a thought process. For this purpose, let’s define and discuss a framework for developing RAG systems.</p> 
  </div> 
  <div class="readable-text" id="p12"> 
   <h2 class=" readable-text-h2"><span class="num-string">9.1</span> RAG development framework</h2> 
  </div> 
  <div class="readable-text" id="p13"> 
   <p>The process of developing RAG systems is not very different from developing an application that uses a machine learning model. We have seen that a RAG system can be complex and include several components. It goes beyond the elements such as models, data, and retrievers. It requires a service infrastructure to make the system available to users. Evaluation, monitoring, and maintaining the systems becomes as important as developing and deploying them. It all begins with an understanding of requirements and a conceptual design. To address all these aspects, a RAG development framework that will assist us in building RAG systems is proposed here. This framework involves the following six stages: </p> 
  </div> 
  <ol> 
   <li class="readable-text" id="p14"><em>Initiatio</em><em>n</em>—This stage involves understanding the problem statement, aligning the stakeholders, gathering system requirements, and analyzing these requirements to draft a high-level system architecture.</li> 
   <li class="readable-text" id="p15"><em>Desig</em><em>n</em>—At this stage, design choices for RAG pipelines are made, and the suite of tools to develop the system is developed. In addition, different layers of the RAG operations stack are conceptualized.</li> 
   <li class="readable-text" id="p16"><em>Developmen</em><em>t</em>—This stage involves developing a working prototype of the desired RAG system. All required models are trained, and the required APIs are developed. This stage leads to the creation of the knowledge base and the development of the application orchestration layer.</li> 
   <li class="readable-text" id="p17"><em>Evaluation</em>—During this stage, the retrieval and generation components are evaluated, along with testing the end-to-end system performance. At the end of this stage, the system is ready for deployment.</li> 
   <li class="readable-text" id="p18"><em>Deploymen</em><em>t</em>—During this stage, the system is made available to end users. The deployment strategy is also decided at this stage.</li> 
   <li class="readable-text" id="p19"><em>Maintenanc</em><em>e</em>—This final stage is an ongoing one that involves system monitoring, incorporating user feedback, and keeping abreast of technological enhancements.</li> 
  </ol> 
  <div class="readable-text" id="p20"> 
   <p>Bear in mind that the RAG development framework is not a linear process, but flexible, iterative, and cyclic. Figure 9.1 illustrates the cyclic nature of the six stages of the RAG development framework, showing the key artifacts of each stage.</p> 
  </div> 
  <div class="browsable-container figure-container " id="p21">  
   <img src="../Images/CH09_F01_Kimothi.png" alt="A diagram of a process

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 9.1</span><span class=""> </span><span class="">The six stages of the RAG development framework are iterative and cyclic. At each stage, specific artifacts can be created.</span></h5>
  </div> 
  <div class="readable-text" id="p22"> 
   <p>Each of the stages involves certain activities. We look at these activities one by one and discuss the best practices associated with them. We begin with the initiation stage.</p> 
  </div> 
  <div class="readable-text" id="p23"> 
   <h3 class=" readable-text-h3"><span class="num-string">9.1.1</span> Initiation stage: Defining and scoping the RAG system</h3> 
  </div> 
  <div class="readable-text" id="p24"> 
   <p>The journey toward a successful RAG system begins with the initial interactions with the stakeholders. This is an opportunity to gain an in-depth understanding of the problem statement and the user requirements. It is an exploratory stage and sets the direction of the project.</p> 
  </div> 
  <div class="readable-text" id="p25"> 
   <h4 class=" readable-text-h4">Use case identification</h4> 
  </div> 
  <div class="readable-text" id="p26"> 
   <p>A lot of the choices a developer will make in the development process of a RAG system depend heavily on the use case being addressed. Even a basic understanding of the industry domain/function and a simple definition of the use case is enough to answer crucial starting questions about the system. The requirement of a RAG system needs to be assessed here. Recall from chapter 1 the challenges that RAG solves: RAG overcomes training data limitations, knowledge cut-off date, and LLM hallucinations to bring factual accuracy, reliability, and trust to the system. It is important to assess whether these RAG benefits are pivotal to the use case. There can be LLM applications that may not even require RAG. Here are some questions you may need to ask at this stage: </p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p27">Does the system require data that may not be present in the training set of an available LLM?</li> 
   <li class="readable-text" id="p28">Does the system require data that is current or updates frequently?</li> 
   <li class="readable-text" id="p29">Does the system need to quote or generate facts? How crucial is the accuracy of the generated facts?</li> 
   <li class="readable-text" id="p30">Will the users benefit if the sources are cited?</li> 
  </ul> 
  <div class="readable-text" id="p31"> 
   <p>A use case evaluation card as the one shown in figure 9.2 can help in assessing whether a RAG system is required to solve the use case. Use cases such as creative writing, language translation, sentiment analysis, grammar correction, and so forth do not generally require a RAG system unless some nuance of the use case warrants it. </p> 
  </div> 
  <div class="readable-text intended-text" id="p32"> 
   <p>Apart from this, the industry domain and function can also give an early indication of the system requirements. For example, use cases from the healthcare and finance domain may require more security and compliance measures, while a use case from sports may require processing of quickly updating information. </p> 
  </div> 
  <div class="readable-text intended-text" id="p33"> 
   <p>This initial assessment of the use case may provide early insights, but a detailed understanding and analysis of the requirements is necessary before proceeding further.</p> 
  </div> 
  <div class="readable-text" id="p34"> 
   <h4 class=" readable-text-h4">Gathering of requirements</h4> 
  </div> 
  <div class="readable-text" id="p35"> 
   <p>Developing the right RAG system means meeting the stakeholders’ needs and wants. Understanding these needs and wants is a crucial step. Gaining this understanding is an interactive and investigative process. Most stakeholders and end users may have limited knowledge about technology and how a RAG system is built. It is therefore important to know what a successful application would mean to them. These requirements can range from the features needed in the system to the expected scale and the </p> 
  </div> 
  <div class="browsable-container figure-container " id="p36">  
   <img src="../Images/CH09_F02_Kimothi.png" alt="A chart of a system

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 9.2</span><span class=""> </span><span class="">A use case evaluation card with the evaluating questions can help in assessing whether a RAG system is required to address the use case.</span> </h5>
  </div> 
  <div class="readable-text" id="p37"> 
   <p>desired performance of the system. A good way to gather requirements may be to look at them through different lenses, such as </p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p38"><em>Business objective</em><em>s</em>—These requirements relate to the main business reasons for building these systems, such as increasing click-through rates, saving process costs, improving customer satisfaction, and so forth. Technical developers may not directly be responsible for business metrics, but these business metrics can act as the leading light in the development process of the system.  </li> 
   <li class="readable-text" id="p39"><em>User need</em><em>s</em>—These are the core requirements of the users for whom the system is being developed. Expressing these needs helps in determining the inputs and outputs of the system along with other functionalities such as multilingual support and source citation. These needs are also key in determining the types of user queries that the RAG system can expect. </li> 
   <li class="readable-text" id="p40"><em>Functional requirement</em><em>s</em>—These are the core functionalities of the system, such as the supported data types, number of documents to be retrieved and length/tone/style of generation, and similar. Functional requirements are influenced by user needs and business objectives. They are also the main influencers of the development process.</li> 
   <li class="readable-text" id="p41"><em>Non-functional requirement</em><em>s</em>—These are requirements about the performance, scalability, reliability, security, and privacy of the system. There may be additional requirements such as legal and compliance, especially for regulated industries.</li> 
   <li class="readable-text" id="p42"><em>Constraint</em><em>s</em>—One should also focus on any constraints that the system should be cognizant of, such as access to the internet, availability of data, cost, and integration with existing systems. </li> 
  </ul> 
  <div class="readable-text" id="p43"> 
   <p>A customer service system, for example, may be envisioned to reduce customer query resolution time, requiring quick response time and a constraint of integrating with existing customer support platforms. An illustrative requirement document for the above can look like the one shown in figure 9.3, detailing out different types of requirements. </p> 
  </div> 
  <div class="browsable-container figure-container " id="p44">  
   <img src="../Images/CH09_F03_Kimothi.png" alt="A screenshot of a customer support system

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 9.3</span><span class=""> </span><span class="">An illustrative requirements document for a customer support system requiring RAG </span></h5>
  </div> 
  <div class="readable-text" id="p45"> 
   <h4 class=" readable-text-h4">Requirements analysis</h4> 
  </div> 
  <div class="readable-text" id="p46"> 
   <p>Eliciting requirements from the stakeholders is a major activity in the initiation stage. These raw requirements then need to be analyzed. The requirements should be clear, precise, and quantifiable so that they can lead to specific development steps. For example, a non-functional need for a quick response may be too vague. Instead, a better requirement is that 90% of queries should be responded to within 2 seconds. Similarly, a constraint of limited internet connectivity can lead the developer to believe that a completely offline system is required. Such vagueness in the requirements needs to be addressed in further interactions with the stakeholders.  </p> 
  </div> 
  <div class="readable-text intended-text" id="p47"> 
   <p>At this stage, it is also important to define the success criteria on which the system will be evaluated. A few success metrics need to be defined and agreed on. For developers, these success metrics should be different from the business objectives since business outcomes may depend on factors beyond their control. Latency, throughput, percentage of queries resolved, and similar, are good criteria for success metrics. Figure 9.4 presents an illustrative requirements document after an analysis of the success metrics. It is an improvement on the previous requirement document shown in figure 9.3.</p> 
  </div> 
  <div class="browsable-container figure-container " id="p48">  
   <img src="../Images/CH09_F04_Kimothi.png" alt="A screenshot of a customer support system

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 9.4</span><span class=""> </span><span class="">Illustrative requirements document with success metrics defined and requirements analyzed for clarity and precision</span></h5>
  </div> 
  <div class="readable-text" id="p49"> 
   <h4 class=" readable-text-h4">High-level architecture</h4> 
  </div> 
  <div class="readable-text" id="p50"> 
   <p>Once the requirements are understood well, the initiation stage can be deemed complete. It is good practice to close the initiation stage with a high-level architecture diagram that can be used as a starting point for the design stage. This architecture can be used to bring alignment among stakeholders and discuss the requirements further. The focus of this high-level architecture is to illustrate the system inputs and outputs. Since data plays such a crucial role in a RAG system, this high-level architecture should also include the data component. As illustrated in figure 9.5, for a multichannel customer support system, the system must allow inputs and outputs from and to different channels.</p> 
  </div> 
  <div class="browsable-container figure-container " id="p51">  
   <img src="../Images/CH09_F05_Kimothi.png" alt="A diagram of a product portal

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 9.5</span><span class=""> </span><span class="">High-level architecture of a proposed customer support bot highlighting inputs and outputs, along with the data, human-in-the-loop, and cache layers</span></h5>
  </div> 
  <div class="readable-text" id="p52"> 
   <p>A first go/no-go decision or the going forward strategic call can be taken on the completion of the initiation stage. Once the stakeholders are aligned, all the RAG operations layers for the system can be designed in the next stage.</p> 
  </div> 
  <div class="readable-text" id="p53"> 
   <h2 class=" readable-text-h2"><span class="num-string">9.2</span> Design stage: Layering the RAGOps stack</h2> 
  </div> 
  <div class="readable-text" id="p54"> 
   <p>With a clear understanding of the use case and the requirements, developers can start planning for the development. In the design stage, the high-level architecture is refined to map out RAGOps stack, and the choices around tools and technology are made. At this stage, we design the indexing and generation pipelines along with other components such as caching, guardrails, and the like.</p> 
  </div> 
  <div class="readable-text" id="p55"> 
   <h3 class=" readable-text-h3"><span class="num-string">9.2.1</span> Indexing pipeline design</h3> 
  </div> 
  <div class="readable-text" id="p56"> 
   <p>In the requirement-gathering step, we identify the data sources. During the design stage, we double-click on these data sources to identify the nature of the source systems, file types, and nature of the data itself to determine the development steps for the knowledge base. Recall from chapter 3 that the knowledge base is created for a RAG system via the indexing pipeline. Components such as data loading, chunking, embeddings, and storage form the indexing pipeline. In chapter 7, we also discussed that the data layer of the RAGOps stack enables this by extracting, transforming, and loading the data. Figure 9.6 summarizes the indexing pipeline components and the data layer.</p> 
  </div> 
  <div class="browsable-container figure-container " id="p57">  
   <img src="../Images/CH09_F06_Kimothi.png" alt="A diagram of data processing

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 9.6</span><span class=""> </span><span class="">The indexing pipeline of the RAG system is executed using the data layer in the RAGOps stack.</span></h5>
  </div> 
  <div class="readable-text" id="p58"> 
   <p>Now let’s look at some important points of consideration that will help us when making the choices for the indexing pipeline design. </p> 
  </div> 
  <div class="readable-text" id="p59"> 
   <h4 class=" readable-text-h4">Data ingestion</h4> 
  </div> 
  <div class="readable-text" id="p60"> 
   <p>When you’re working with less data, like a few PDF files or a couple of websites, <em>data ingestion</em> is a relatively simple step. However, in production-grade systems, the complexity increases with the scale of the data. Special attention needs to be given to the source systems and the file formats. Here are a few questions about connecting to source systems that will help in designing the data ingestion component:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p61">Which source systems will the data layer need to connect to? </li> 
   <li class="readable-text" id="p62">Are the connectors readily available? If yes, which tools or services are required to establish these connections?</li> 
   <li class="readable-text" id="p63">Which connectors will need to be developed? Which technology will these connectors be developed on?</li> 
   <li class="readable-text" id="p64">Is access to open internet required? How will the system connect to the internet?</li> 
  </ul> 
  <div class="readable-text" id="p65"> 
   <p>The following group of questions is about parsing files:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p66">Which file formats will be ingested?</li> 
   <li class="readable-text" id="p67">How will the web pages be scraped, if required? </li> 
   <li class="readable-text" id="p68">Do we have the necessary parsers for the different file types? </li> 
   <li class="readable-text" id="p69">Is some special parsing technique required to be developed? </li> 
   <li class="readable-text" id="p70">Can there be more than one modality of data in a single file? </li> 
  </ul> 
  <div class="readable-text" id="p71"> 
   <p>The answers to these questions will determine the tools you will need to use for ingesting data and the parts that will need to be developed.</p> 
  </div> 
  <div class="readable-text" id="p72"> 
   <h4 class=" readable-text-h4">Data transformation</h4> 
  </div> 
  <div class="readable-text" id="p73"> 
   <p>Once the data is ingested, the <em>transformation step</em> converts the data into a suitable format for the knowledge base. In the data transformation step, the data will first be cleaned and pre-processed. A good practice is also to extract metadata information. Sometimes, other preprocessing steps such as PII data redaction or resolving conflicting information are required.  </p> 
  </div> 
  <div class="readable-text intended-text" id="p74"> 
   <p>After pre-processing, the data will be chunked using a suitable chunking technique. Chunk size, overlap size, and the chunking strategy should be decided at this stage. Chunking can be fixed size, structure driven, semantic chunking, or agentic chunking. </p> 
  </div> 
  <div class="readable-text intended-text" id="p75"> 
   <p>Once the chunks are created, they need to be transformed for retrieval. We have discussed approaches such as embeddings and knowledge graphs. For use cases that require relational understanding between chunks, knowledge graphs should be explored. The creation of vector embeddings is almost mandatory in all RAG systems. To create vector embeddings, pre-trained embeddings models can be used. However, sometimes, due to the peculiarity of the domain, embedding models may need to be fine-tuned. </p> 
  </div> 
  <div class="readable-text intended-text" id="p76"> 
   <p>Let’s now look at some of the questions that should be considered at this stage. The first group of questions is about pre-processing:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p77">How noisy is the data? What algorithms and techniques can be used to clean up the data?</li> 
   <li class="readable-text" id="p78">Is structured data like tables or JSON present? </li> 
   <li class="readable-text" id="p79">Is metadata readily available, or should it be extracted?</li> 
   <li class="readable-text" id="p80">What algorithms or models should be used for metadata extraction? (Note: All models sit in the model library of the model layer of the RAGOps stack.)</li> 
   <li class="readable-text" id="p81">Does the data contain sensitive information that needs to be masked or redacted? What techniques will be used to execute this?</li> 
   <li class="readable-text" id="p82">Are there any other data protocols or guidelines that need to be followed?</li> 
  </ul> 
  <div class="readable-text" id="p83"> 
   <p>When it comes to chunking, consider asking the following questions:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p84">Is the chunk size pre-determined? If not, what chunk sizes should be experimented with?</li> 
   <li class="readable-text" id="p85">Is the data in a format that will warrant structured chunking? </li> 
   <li class="readable-text" id="p86">What techniques and models will be employed for semantic chunking, if required?</li> 
   <li class="readable-text" id="p87">Is a chunking agent readily available, or will it need to be built? Which models, algorithms, and tools will be used by the chunking agent?</li> 
  </ul> 
  <div class="readable-text" id="p88"> 
   <p>The following group of questions covers graphRAG:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p89">Is a hierarchical indexing structure required? </li> 
   <li class="readable-text" id="p90">Do we need to extract entities and relationships for relational context? Do we have the necessary budget?</li> 
   <li class="readable-text" id="p91">What approaches are we going to take for entity-relationship extraction? </li> 
   <li class="readable-text" id="p92">Are we using any frameworks for graph extraction?</li> 
   <li class="readable-text" id="p93">Which models are going to be used?</li> 
  </ul> 
  <div class="readable-text" id="p94"> 
   <p>As for embeddings, ask the following:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p95">Which embeddings model will we use? Are there any domain-specific embeddings models available that will be more useful?</li> 
   <li class="readable-text" id="p96">Are multimodal embeddings required?</li> 
   <li class="readable-text" id="p97">Do we need to fine-tune embeddings for our use case? Do we have the training data for fine-tuning? How will the training data be sourced?</li> 
  </ul> 
  <div class="readable-text" id="p98"> 
   <p>Data transformation steps require significant thought and effort. This is also where significant costs can be incurred, especially in using agents and employing graphRAG.</p> 
  </div> 
  <div class="readable-text" id="p99"> 
   <h4 class=" readable-text-h4">Data storage</h4> 
  </div> 
  <div class="readable-text" id="p100"> 
   <p>The final component of the data layer is the storage. Depending on the choices made during the data transformation, the storage will comprise vector stores, graph databases, and document stores (if necessary). At this stage, we should also keep in mind that a cache store may be required in the application that can be a part of the data layer. We will discuss caching separately. Some of the questions pertinent to data storage are </p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p101">Can all data be stored in a single collection, or are multiple collections required?</li> 
   <li class="readable-text" id="p102">Can we manage the vector database or do we require a managed service?</li> 
   <li class="readable-text" id="p103">What is the current scale of data and how is it likely to grow?</li> 
   <li class="readable-text" id="p104">Which vector database will we use?</li> 
   <li class="readable-text" id="p105">Do we need a graph database? Which graph database will we use? </li> 
   <li class="readable-text" id="p106">Do we need to store raw documents or images? Which document store will we use for this purpose?</li> 
  </ul> 
  <div class="readable-text" id="p107"> 
   <p>With the storage in place, the creation of the knowledge base can be executed. It is important to note that the choices at this stage should be flexible. You should also keep options available for tools, services and libraries that can be experimented with during development. You’ll also have to estimate the costs associated with different steps of this stage and ensure that the stakeholders are aligned with these costs.</p> 
  </div> 
  <div class="readable-text intended-text" id="p108"> 
   <p>With the data layer of the RAGOps stack, the design of the indexing pipeline is complete. You may also note that the indexing pipeline also interacts with the model layer where embeddings models and LLMs along with other task specific algorithms sit.</p> 
  </div> 
  <div class="readable-text" id="p109"> 
   <h3 class=" readable-text-h3"><span class="num-string">9.2.2</span> Generation pipeline design</h3> 
  </div> 
  <div class="readable-text" id="p110"> 
   <p>We have discussed that the real-time interaction of the user with the knowledge base is facilitated by the generation pipeline. In chapter 4, we developed the three main components of the generation pipeline—the retrievers, augmentation via prompts, and generation using LLMs. Apart from these three components, query optimization in the pre-retrieval stage and context optimization in the post-retrieval stage are advanced components of the generation pipeline. Sometimes, even post-generation, response optimization is conducted to better align the responses. The generation pipeline is powered by the model layer of the RAGOps stage, which has the LLMs, the retrievers, embeddings models, and other task-specific models. The generation pipeline is brought alive by the app orchestration layer of the RAGOps stack. Let’s discuss the design of the generation pipeline in the following six steps: query optimization (pre-retrieval), retrieval, context optimization (post-retrieval), augmentation, generation, and response optimization (post-generation).</p> 
  </div> 
  <div class="readable-text" id="p111"> 
   <h4 class=" readable-text-h4">Query optimization</h4> 
  </div> 
  <div class="readable-text" id="p112"> 
   <p>Query optimization techniques are employed to help retrieval better align with the query. Several techniques are employed for transforming and rewriting queries. For agentic RAG, query routing is an important aspect of this step. Some of the questions to help finalize the nature of query optimization are</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p113">How many types of queries can the user ask? Do each of these query types require different downstream processes?</li> 
   <li class="readable-text" id="p114">Are there multiple collections in the knowledge base that need to be selected before the search?</li> 
   <li class="readable-text" id="p115">Are user queries expected to be short or generic?</li> 
   <li class="readable-text" id="p116">Are users looking for precise responses?</li> 
   <li class="readable-text" id="p117">How much processing time can be afforded to query optimization?</li> 
   <li class="readable-text" id="p118">Which models and techniques will be used for query optimization?</li> 
  </ul> 
  <div class="readable-text" id="p119"> 
   <p>Query optimization is optional but may be unavoidable when the data in the knowledge base is voluminous. It must also be noted that query optimization can add to the latency of the system.</p> 
  </div> 
  <div class="readable-text" id="p120"> 
   <h4 class=" readable-text-h4">Retrieval</h4> 
  </div> 
  <div class="readable-text" id="p121"> 
   <p>Retrieval is a pivotal component of RAG systems. There are many retrieval techniques and strategies discussed in this book. The quality of the RAG system hinges on the accuracy of the retrieval component. You may use a dense embeddings similarity match for simple RAG systems. In more complex systems, you will need to use hybrid, iterative, or adaptive retrieval strategies. The questions to ask at this stage are</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p122">Does our retrieval component need high precision, high recall, or both? </li> 
   <li class="readable-text" id="p123">Can the queries be resolved with a simple similarity match? </li> 
   <li class="readable-text" id="p124">Do we need graph retrieval? </li> 
   <li class="readable-text" id="p125">Will searching through the entire data be prohibitively long? Do we need filtering?</li> 
   <li class="readable-text" id="p126">Will a single pass retrieve all necessary documents?</li> 
   <li class="readable-text" id="p127">Will the information from the retrieved documents lead to more questions?</li> 
   <li class="readable-text" id="p128">Which models and techniques will we use for adaptive, recursive, or iterative retrieval?</li> 
   <li class="readable-text" id="p129">Which retrieval algorithms should we try? </li> 
   <li class="readable-text" id="p130">Are there any providers or libraries that we will leverage? </li> 
   <li class="readable-text" id="p131">How will we estimate the cost of retrieval?</li> 
   <li class="readable-text" id="p132">How many documents should be retrieved for acceptable levels of coverage?</li> 
   <li class="readable-text" id="p133">Does ranking in retrieved results matter?</li> 
  </ul> 
  <div class="readable-text" id="p134"> 
   <p>Retrieval, especially in large knowledge bases, can lead to significant latency and should be optimized for speed and accuracy.</p> 
  </div> 
  <div class="readable-text" id="p135"> 
   <h4 class=" readable-text-h4">Context optimization</h4> 
  </div> 
  <div class="readable-text" id="p136"> 
   <p>Once the results are retrieved from the knowledge base, they need to be sent to the LLM for generation along with the original user query. However, once the results are retrieved to sharpen the context, certain optimization techniques such as re-ranking and compression can be applied. These techniques filter, compress, and optimize the retrieved information to reduce noise and increase the precision of the context. To validate the need for context optimization, a few questions can be asked: </p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p137">Will the amount of information retrieved overwhelm the LLM? </li> 
   <li class="readable-text" id="p138">Will the retrieved information fit the context window of the LLM?</li> 
   <li class="readable-text" id="p139">Is there a possibility of the retrieved information being noisy?</li> 
   <li class="readable-text" id="p140">Have a lot of documents been retrieved? Do we need to discard a few?</li> 
   <li class="readable-text" id="p141">Which techniques can be used to sharpen the retrieve context to the query?</li> 
   <li class="readable-text" id="p142">Are there any services or libraries that we can use?</li> 
   <li class="readable-text" id="p143">Can we afford the time taken for this optimization?</li> 
  </ul> 
  <div class="readable-text" id="p144"> 
   <p>Optimizations like this are very helpful in making the context precise and improving the overall quality of the RAG system, but they do add to the processing time and cost.</p> 
  </div> 
  <div class="readable-text" id="p145"> 
   <h4 class=" readable-text-h4">Augmentation</h4> 
  </div> 
  <div class="readable-text" id="p146"> 
   <p>Augmentation is the process of adding the retrieved context to the original query in a prompt that can be sent to the LLM for generation. While it may seem a simple step, there can be many nuances to it. All the use case context along with the retrieved context also needs to be passed. Sometimes, you may need to pass examples of desired responses or the thought process. In cases where you need to use the LLMs internal parametric knowledge, this can also be specified in the prompt. Key questions to ask at this stage are</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p147">What is the system prompt or the overall persona that we need the LLM to take?</li> 
   <li class="readable-text" id="p148">Does the response require nuanced analysis? Can that be passed as a chain of thought?</li> 
   <li class="readable-text" id="p149">Do we want to restrict the responses to the context only?</li> 
   <li class="readable-text" id="p150">What kind of examples should be given?</li> 
   <li class="readable-text" id="p151">Will different query types need different prompting techniques?</li> 
  </ul> 
  <div class="readable-text" id="p152"> 
   <p>Augmentation is done through prompts, and prompts can be managed by the prompt layer of the RAGOps stack. Prompting affects the cost and latency since the LLM-s processing depends on the number of tokens passed in the prompt.</p> 
  </div> 
  <div class="readable-text" id="p153"> 
   <h4 class=" readable-text-h4">Generation</h4> 
  </div> 
  <div class="readable-text" id="p154"> 
   <p>Generation is a core component of all generative AI apps and contains an LLM that takes a prompt as input and generates a response. The nature of the LLM determines the efficacy and efficiency of the RAG system to a large extent. There are several choices that you will need to make: </p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p155">Should an open source model be used? Do we have the skills and resources to use them?</li> 
   <li class="readable-text" id="p156">Should a proprietary managed LLM be used? </li> 
   <li class="readable-text" id="p157">Will we need to fine-tune an LLM for our use case? </li> 
   <li class="readable-text" id="p158">How large a model do we need? What capabilities do we need to address?</li> 
   <li class="readable-text" id="p159">How can we estimate the cost of the generation component? </li> 
   <li class="readable-text" id="p160">Are there any deployment constraints to be considered? </li> 
   <li class="readable-text" id="p161">Will the models need optimization for deployment?</li> 
   <li class="readable-text" id="p162">Are there any security implications to be considered?</li> 
   <li class="readable-text" id="p163">Are there any ethical or legal implications to be considered? </li> 
  </ul> 
  <div class="readable-text" id="p164"> 
   <p>The selected LLMs will sit in the model library. All training fine-tuning activities and optimization are carried out in the model layer of the RAGOps stack. LLMs can be costly to train and use. Using the right LLM is key to the success of the RAG system.</p> 
  </div> 
  <div class="readable-text" id="p165"> 
   <h4 class=" readable-text-h4">Response optimization</h4> 
  </div> 
  <div class="readable-text" id="p166"> 
   <p>Sometimes, the response from the generation component may be further processed before presenting the results to the user. This can range from evaluating the response for relevance to checking the format and appending the responses with the retrieved sources. Some questions that can help with the assessment at this stage are </p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p167">Does the response from the LLM be presented to the user as is? </li> 
   <li class="readable-text" id="p168">Is there any kind of verification that the responses need to go through?</li> 
   <li class="readable-text" id="p169">What is the impact of a sub-optimal result?</li> 
   <li class="readable-text" id="p170">Are there any workflows that need to be triggered based on the responses?</li> 
  </ul> 
  <div class="readable-text" id="p171"> 
   <p>Response optimizations are highly subjective and closely coupled to the use case, but it is a consideration that should not be overlooked. </p> 
  </div> 
  <div class="readable-text intended-text" id="p172"> 
   <p>With these seven steps, the generation pipeline design is complete. The model library and the training/fine-tuning components of the RAGOps stack can be covered with the necessary tools, platforms, and algorithms. The orchestration of the generation pipeline can also be finalized depending on the choices made during this stage. The prompt layer can also be addressed after finalizing the augmentation techniques. Figure 9.7 shows the generation pipeline design with the overarching question of each step.</p> 
  </div> 
  <div class="browsable-container figure-container " id="p173">  
   <img src="../Images/CH09_F07_Kimothi.png" alt="A diagram of a system

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 9.7</span><span class=""> </span><span class="">Key questions need to be answered to make the choices for the generation pipeline.</span></h5>
  </div> 
  <div class="readable-text" id="p174"> 
   <p>This completes the design choices of the core RAG pipelines. The model, prompt, and the orchestration layers are largely complete by this stage. But there are more design considerations regarding security, guardrails, caching, and other use case requirements.</p> 
  </div> 
  <div class="readable-text" id="p175"> 
   <h3 class=" readable-text-h3"><span class="num-string">9.2.3</span> Other design considerations</h3> 
  </div> 
  <div class="readable-text" id="p176"> 
   <p>While well-designed core RAG pipelines complete the critical layers of the RAG system, other system considerations and business requirements also need to be addressed: </p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p177">What kind of guardrails are required in the system? Should the user queries be restricted? Is there any kind of information that should not be output?</li> 
   <li class="readable-text" id="p178">Is it possible and useful to cache certain kinds of responses? </li> 
   <li class="readable-text" id="p179">Do we need human supervision or action at any stage in the system?</li> 
   <li class="readable-text" id="p180">How will the models be protected from adverse attacks?</li> 
   <li class="readable-text" id="p181">Is there any approval workflow required in the system?</li> 
   <li class="readable-text" id="p182">Are users looking for explainability?</li> 
  </ul> 
  <div class="readable-text" id="p183"> 
   <p>These questions will help address the essential and enhancement layers of the RAGOps stack. You should be able to have a complete view of the necessary components, tools, platforms, and libraries for the development of the RAG system. The last choice to be made is on deployment options.</p> 
  </div> 
  <div class="readable-text intended-text" id="p184"> 
   <p>You can choose between a managed deployment on the cloud, a self-hosted deployment on a private cloud, a bare metal server, or local/edge machines. The choice will largely be driven by the business constraints but can have an effect on the design choices of the pipelines. Fully managed deployment favors managed services for storage and compute to reduce development complexity and ensure scalability, self-hosted solutions need a special focus on a design with modularity and optimization techniques to handle limited infrastructure, and in edge deployment, you should emphasize lightweight components and efficient retrieval strategies due to resource constraints.</p> 
  </div> 
  <div class="readable-text intended-text" id="p185"> 
   <p>With all these design elements finalized, experimentation can begin for the development of the RAG system.</p> 
  </div> 
  <div class="readable-text" id="p186"> 
   <h3 class=" readable-text-h3"><span class="num-string">9.2.4</span> Development stage: Building modular RAG pipelines</h3> 
  </div> 
  <div class="readable-text" id="p187"> 
   <p>The development stage of the RAG development framework focuses on implementing the design choices into a functional RAG system. The ideal way would be to build the RAG pipelines in a modular fashion, which involves decomposing the system into distinct, interchangeable components, each responsible for a specific function. This approach enhances flexibility, scalability, and maintainability, allowing for tailored configurations to meet diverse application requirements. A few activities in the development stage involve training and fine-tuning models; creating APIs or microservices for different components; and creating an orchestration layer using different tools, services, and libraries.</p> 
  </div> 
  <div class="readable-text" id="p188"> 
   <h4 class=" readable-text-h4">Model training and fine-tuning LLMs</h4> 
  </div> 
  <div class="readable-text" id="p189"> 
   <p>For most systems, a pre-trained foundation LLM and embeddings models will meet the requirement. There may be instances where you may need to fine-tune models for domain adaptation. In rare cases, you may choose to train language models from scratch. In such cases, the development of RAG systems may take a back seat, and training the models will be the core of the development effort. You can follow a progressive approach when deciding whether to fine-tune embeddings models and LLMs.</p> 
  </div> 
  <div class="readable-text intended-text" id="p190"> 
   <p>When creating embeddings using a pre-trained model, you will need to assess if a similarity search yields relevant results. To do this, you can also create ground truth data. The ground truth data can be a set of manually curated search queries and their matching documents. If the embeddings model can retrieve the documents accurately, you may use the pre-trained model. If not, you can either look for another embeddings model more suited for the use case domain or fine-tune the pre-trained embeddings model for the use case domain.</p> 
  </div> 
  <div class="readable-text intended-text" id="p191"> 
   <p>Similarly, if a pre-trained LLM generates desired results by prompting alone, you can use the model as is. In cases where you desire a specific style, vocabulary, or tonality, you can choose to fine-tune a model. </p> 
  </div> 
  <div class="readable-text intended-text" id="p192"> 
   <p>If the system warrants other models such as query classification, harmful content detection, usefulness, and similar, they will also need to be trained.</p> 
  </div> 
  <div class="readable-text" id="p193"> 
   <h4 class=" readable-text-h4">Module development</h4> 
  </div> 
  <div class="readable-text" id="p194"> 
   <p>Different RAG pipeline components should be developed as independent modules in the form of packages, APIs, or other modular frameworks. Some of the modules can be </p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p195"><em>Data loading and parsin</em><em>g</em>—Responsible for connecting to the source system and parsing file formations</li> 
   <li class="readable-text" id="p196"><em>Metadata extractio</em><em>n</em>—Responsible for extracting and tagging metadata</li> 
   <li class="readable-text" id="p197"><em>Chunkin</em><em>g</em>—Responsible for creating chunks from documents</li> 
   <li class="readable-text" id="p198"><em>Embedding</em><em>s</em>—Responsible for converting chunks into vector embeddings</li> 
   <li class="readable-text" id="p199"><em>Storag</em><em>e</em>—Responsible for storing embeddings into vector databases</li> 
   <li class="readable-text" id="p200"><em>Query optimizatio</em><em>n</em>—Responsible for aligning user query with retrievers</li> 
   <li class="readable-text" id="p201"><em>Retrieva</em><em>l</em>—Responsible for efficient retrieval of documents</li> 
   <li class="readable-text" id="p202"><em>Augmentatio</em><em>n</em>—Responsible for maintaining and invoking the prompt library</li> 
   <li class="readable-text" id="p203"><em>Generatio</em><em>n</em>—Responsible for using the LLMs to generate responses</li> 
   <li class="readable-text" id="p204"><em>Memor</em><em>y</em>—Responsible for storing conversations, user preferences, and similar</li> 
  </ul> 
  <div class="readable-text" id="p205"> 
   <p>These are only a few examples. Modularity will be dependent on the complexity of the components. For example, if you are convinced that fixed-size chunking is sufficient for your use case, you may not develop an independent chunking module. Conversely, if you assume that LLMs may need to be changed as the system evolves with the technology, you can create the generation module that allows for quick and easy replacement of models. Figure 9.8 recalls the modular RAG design discussed in chapter 6.</p> 
  </div> 
  <div class="readable-text" id="p206"> 
   <h4 class=" readable-text-h4">Orchestration</h4> 
  </div> 
  <div class="readable-text" id="p207"> 
   <p>Finally, you will develop the orchestration layer that will manage the interaction among the different modules that you have developed. This enables the workflow of your RAGsystem. This workflow should be flexible enough to adapt with feedback for different query types. </p> 
  </div> 
  <div class="browsable-container figure-container " id="p208">  
   <img src="../Images/CH09_F08_Kimothi.png" alt="A diagram of a computer

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 9.8</span><span class=""> </span><span class="">Modular structure allows for flexibility and scalability of individual components.</span></h5>
  </div> 
  <div class="readable-text intended-text" id="p209"> 
   <p>You will also have access to various managed services, frameworks, libraries, and tools that you can integrate with any of the modules. For example, LangChain is a framework that provides libraries for most components of a RAG framework. You can use these libraries for quick and easy development. However, for components that you desire more control over, you may need to build the functionality from scratch.</p> 
  </div> 
  <div class="readable-text intended-text" id="p210"> 
   <p>Development is an experimentation-driven iterative process. To finalize the different components of the RAG system, you will need to evaluate them and benchmark them against the goals you had set in the initiation stage. </p> 
  </div> 
  <div class="readable-text" id="p211"> 
   <h3 class=" readable-text-h3"><span class="num-string">9.2.5</span> Evaluation stage: Validating and optimizing the RAG system</h3> 
  </div> 
  <div class="readable-text" id="p212"> 
   <p>Evaluation of the RAG system is a key component of its development process. All the different strategies, tools, and frameworks must be evaluated against some set of benchmarks. The actual business effect can only be measured post-deployment, but some metrics can be evaluated at the development stage. We can look at these metrics in two broad categories.</p> 
  </div> 
  <div class="readable-text" id="p213"> 
   <h4 class=" readable-text-h4">RAG components</h4> 
  </div> 
  <div class="readable-text" id="p214"> 
   <p>The purpose of evaluating the RAG system is to assess the performance of different RAG components. To this end, there can be retriever-specific, generation-specific, and overall RAG evaluation metrics. Here is a summary of these metrics discussed in chapter 5. We begin with retriever-specific metrics:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p215"><em>Accuracy</em> is typically defined as the proportion of correct predictions (both true positives and true negatives) among the total number of cases examined.</li> 
   <li class="readable-text" id="p216"><em>Precision</em> focuses on the quality of the retrieved results. It measures the proportion of retrieved documents relevant to the user query. It answers the question, “Of all the documents that were retrieved, how many were relevant?”</li> 
   <li class="readable-text" id="p217"><em>Precision@k</em> is a variation of precision that measures the proportion of relevant documents among the top ‘k’ retrieved results. It is particularly important because it focuses on the top results rather than all the retrieved documents. For RAG, it is important because only the top results are most likely to be used for augmentation.</li> 
   <li class="readable-text" id="p218"><em>Recall</em> focuses on the coverage that the retriever provides. It measures the proportion of the relevant documents retrieved from all the relevant documents in the corpus. It answers the question, “Of all the relevant documents, how many were retrieved?”</li> 
   <li class="readable-text" id="p219"><em>F1-score</em> is the harmonic mean of precision and recall. It provides a single metric that balances both the quality and coverage of the retriever.</li> 
   <li class="readable-text" id="p220"><em>Mean reciprocal rank, or MRR</em>, is particularly useful in evaluating the rank of the relevant document. It measures the reciprocal of the ranks of the first relevant document in the list of results. MRR is calculated over a set of queries.</li> 
   <li class="readable-text" id="p221"><em>Mean average precision, or MAP,</em> is a metric that combines precision and recall at different cut-off levels of ‘k’ (i.e. the cut-off number for the top results). It calculates a measure called average precision and then averages it across all queries.</li> 
   <li class="readable-text" id="p222"><em>nDCG</em> evaluates the ranking quality by considering the position of relevant documents in the result list and assigning higher scores to relevant documents appearing earlier.</li> 
  </ul> 
  <div class="readable-text" id="p223"> 
   <p>Here is the summary of generation specific metrics:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p224"><em>Coherence</em> assesses the logical flow and clarity of the response, ensuring that the information is presented in an understandable and organized manner.</li> 
   <li class="readable-text" id="p225"><em>Conciseness</em> evaluates whether the response is succinct and to the point, avoiding unnecessary verbosity, while still conveying complete information. </li> 
  </ul> 
  <div class="readable-text" id="p226"> 
   <p>We conclude with a summary of overall RAG metrics:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p227"><em>Context relevance</em> assesses the proportion of retrieved information relevant to the user query.</li> 
   <li class="readable-text" id="p228"><em>Faithfulness </em>or<em> groundedness</em> assesses the proportion of the claims in the response that are backed by the retrieved context.</li> 
   <li class="readable-text" id="p229"><em>Hallucination rate</em><strong> </strong>calculates the proportion of generated claims in the response that are not present in the retrieved context.</li> 
   <li class="readable-text" id="p230"><em>Coverage</em> measures the number of relevant claims in the context and calculates the proportion of relevant claims present in the generated response.</li> 
   <li class="readable-text" id="p231"><em>Answer relevance</em> assesses the overall effectiveness of the system by calculating the relevance of the final response to the original question.</li> 
  </ul> 
  <div class="readable-text" id="p232"> 
   <p>Recall the triad of RAG evaluation from chapter 5. Figure 9.9 shows the pairwise interaction between the user query, retrieved context, and the generated response, which calculates the RAG specific metrics.</p> 
  </div> 
  <div class="browsable-container figure-container " id="p233">  
   <img src="../Images/CH09_F09_Kimothi.png" alt="A diagram of a customer relationship management

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 9.9</span><span class=""> </span><span class="">The triad of RAG evaluation proposed by TruEra</span></h5>
  </div> 
  <div class="readable-text" id="p234"> 
   <p>To calculate some of these metrics, a ground truth dataset is required. Ground truth is information known to be real or true. In RAG, and the generative AI domain in general, ground truth is a prepared set of prompt–context–response or question–context–response examples, akin to labeled data in supervised machine learning parlance. Ground truth data created for your knowledge base can be used for the evaluation of your RAG system. </p> 
  </div> 
  <div class="readable-text intended-text" id="p235"> 
   <p>You can measure these metrics for different components. For example, you can check if context relevance increases by replacing a hybrid retrieval strategy with an adaptive one. You can also check the effectiveness of query and context optimization. You can also compare two service providers for a particular component.</p> 
  </div> 
  <div class="readable-text" id="p236"> 
   <h4 class=" readable-text-h4">System performance</h4> 
  </div> 
  <div class="readable-text" id="p237"> 
   <p>System performance metrics relate to the non-functional requirements of the system, which affect the usability of the system more than the accuracy of the system. Some of these metrics are </p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p238"><em>Latenc</em><em>y</em>—Measures the time taken from receiving a query to delivering a response. Low latency is crucial for user satisfaction, especially in real-time applications.</li> 
   <li class="readable-text" id="p239"><em>Throughpu</em><em>t</em>—Indicates the number of queries the system can handle within a specific time frame. Higher throughput reflects the system’s ability to manage large volumes of requests efficiently.</li> 
   <li class="readable-text" id="p240"><em>Resource utilizatio</em><em>n</em>—Assesses the efficiency of CPU and GPU usage during operations. Optimal utilization ensures cost-effectiveness and prevents resource bottlenecks. </li> 
   <li class="readable-text" id="p241"><em>Cost per query</em> calculates the average expense incurred for processing each query, encompassing infrastructure, energy, and maintenance costs.</li> 
  </ul> 
  <div class="readable-text" id="p242"> 
   <p>Latency and cost get special attention in LLM-based systems. This is because of the inherent nature of the LLM architecture. RAG adds to both latency and cost. Therefore, the impact of additional components like filtering during retrieval, optimizations, and retrieval strategies should be evaluated from this lens. Sometimes the stakeholders may also ask you to evaluate some use case-specific metrics, and that should also be a part of this evaluation stage.</p> 
  </div> 
  <div class="readable-text intended-text" id="p243"> 
   <p>When your system is thoroughly evaluated and improved to meet all the benchmarks, it is ready to go. You can now deploy it to make it available to the intended users.</p> 
  </div> 
  <div class="readable-text" id="p244"> 
   <h3 class=" readable-text-h3"><span class="num-string">9.2.6</span> Deployment stage: Launching and scaling the RAG system</h3> 
  </div> 
  <div class="readable-text" id="p245"> 
   <p>Once the system is ready to ship, it needs to be deployed into a production server accessible by the intended users. There are a few deployment techniques that are popular for software systems, which can also be used for RAG systems.</p> 
  </div> 
  <div class="readable-text" id="p246"> 
   <h4 class=" readable-text-h4">Blue–green deployment</h4> 
  </div> 
  <div class="readable-text" id="p247"> 
   <p>Blue–green deployment maintains two separate environments named blue and green. The existing system is in the blue environment, and the new RAG system is put in the green. Once the green environment is tested and verified, all traffic is directed to the green environment, and the blue environment is deactivated. The advantage of this blue–green deployment is that it is possible to test the production environment without affecting the live traffic. Consequently, there is zero downtime and an easy option for a rollback if any problem is encountered. However, it is a costly option since the entire production environment is duplicated. Indexing pipelines can be updated in the green environment without affecting the live system. Changes to retrieval strategies or embeddings models can be safely validated before production use.</p> 
  </div> 
  <div class="readable-text" id="p248"> 
   <h4 class=" readable-text-h4">Canary deployment</h4> 
  </div> 
  <div class="readable-text" id="p249"> 
   <p>Canary deployment gradually releases the new RAG system to a small number of users. If it performs well with these users, it is expanded to all users. Canary deployment allows for real-time user feedback that enables early detection of problems. However, it adds feedback and monitoring complexity and multiple versions to manage. It can test changes in retrieval algorithms, embeddings, or generation models on limited queries or specific regions.</p> 
  </div> 
  <div class="readable-text" id="p250"> 
   <h4 class=" readable-text-h4">Rolling deployment</h4> 
  </div> 
  <div class="readable-text" id="p251"> 
   <p>Rolling deployment is used when there are multiple production servers. The new RAG system is deployed to one server incrementally at a time before moving to the next. So, there is no complete downtime and only a part of the system is offline at one time. It may become complex if problems arise mid-deployment. The rollback can become tedious when some servers are updated, while others are not.</p> 
  </div> 
  <div class="readable-text" id="p252"> 
   <h4 class=" readable-text-h4">Shadow deployment</h4> 
  </div> 
  <div class="readable-text" id="p253"> 
   <p>Shadow deployment mirrors live traffic to a new version of the system running alongside the old one, without exposing the new RAG system’s responses to users. By doing this, the system can be tested without affecting the users. However, it requires duplication of the infrastructure much like the blue–green deployment.</p> 
  </div> 
  <div class="readable-text" id="p254"> 
   <h4 class=" readable-text-h4">A/B testing</h4> 
  </div> 
  <div class="readable-text" id="p255"> 
   <p>A/B testing involves deploying two versions of the RAG system (A and B) to separate subsets of users and comparing their performance to determine the better option. This can also be done for new systems. It enables direct comparison and provides clear insights into performance. However, it requires robust mechanisms to split traffic and collect performance metrics. It allows for experimenting with different LLMs or retrieval strategies and variations in prompting and augmentation techniques.</p> 
  </div> 
  <div class="readable-text" id="p256"> 
   <h4 class=" readable-text-h4">Interleaving experiments</h4> 
  </div> 
  <div class="readable-text" id="p257"> 
   <p><em>Interleaving experiments</em> compare two RAG systems by blending their outputs into a single result set shown to users. Results from both systems are interleaved, and user interactions are attributed to the originating system to determine which performs better. This approach provides fast feedback and reduces bias by comparing systems under identical conditions. However, the attribution of user engagement to the correct system can be complex. </p> 
  </div> 
  <div class="readable-text intended-text" id="p258"> 
   <p>The choices for the deployment strategy can depend on factors like such as tolerance, and using strategies such as shadow, canary, and blue–green can mitigate risks in mission-critical systems. It also depends on the scale, and rolling deployments make sense for large-scale systems. Small new RAG systems can be also deployed all at once. </p> 
  </div> 
  <div class="readable-text intended-text" id="p259"> 
   <p>Now that the system is available to the users, you will start getting real-time feedback, and the success and failure of the system will also depend on how you react to the feedback. To measure and improve the system, continuous monitoring is required.</p> 
  </div> 
  <div class="readable-text" id="p260"> 
   <h3 class=" readable-text-h3"><span class="num-string">9.2.7</span> Maintenance stage: Ensuring reliability and adaptability</h3> 
  </div> 
  <div class="readable-text" id="p261"> 
   <p>Deploying a RAG system into production is only the first milestone in the journey toward an evolved contextual AI system. Explicit user feedback, evolving technology, and changing user behavior present previously unexplored challenges that the system may encounter. It is therefore essential to be continually vigilant and monitor the system performance. There are several reasons why a RAG system may fail in production. There are operational reasons such as compute resource constraints, sudden spikes in load, and malicious attacks. The reason can also be a shift in the type of data in the knowledge base or a change in user queries. It is therefore essential to measure a few metrics: </p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p262">RAG component metrics that were evaluated before deployment need to be continuously monitored for degradation.</li> 
   <li class="readable-text" id="p263">Changes in user behavior can be tracked by analyzing the nature of user queries.</li> 
   <li class="readable-text" id="p264">System performance metrics such as latency, throughput, and similar should also be continuously monitored.</li> 
   <li class="readable-text" id="p265">Additional metrics such as error rates, system downtime, malicious attacks, and similar should also be tracked.</li> 
   <li class="readable-text" id="p266">User engagement metrics such as customer satisfaction scores or repeat engagement can indicate the usability of the system.</li> 
   <li class="readable-text" id="p267">Business metrics such as revenue effects and cost savings should also be tracked.</li> 
  </ul> 
  <div class="readable-text" id="p268"> 
   <p>This development framework completed its cycle with maintenance. However, it is not a linear process. New requirements and business objectives will emerge. This will re-initiate the development cycle for an improved RAG system. This development framework will prove to be a good reference resource while building RAG systems. </p> 
  </div> 
  <div class="readable-text intended-text" id="p269"> 
   <p>We conclude this book and end the discussion on RAG in the next section with some additional considerations to keep in mind as the generative AI domain evolves.</p> 
  </div> 
  <div class="readable-text" id="p270"> 
   <h2 class=" readable-text-h2"><span class="num-string">9.3</span> Ideas for further exploration</h2> 
  </div> 
  <div class="readable-text" id="p271"> 
   <p>Like any technology, even with RAG, there are some complementary and some competing ideas that coexist. You may hear about these techniques and sometimes be challenged to defend the use of RAG. There are also common points of failure for RAG systems that need attention.</p> 
  </div> 
  <div class="readable-text" id="p272"> 
   <h3 class=" readable-text-h3"><span class="num-string">9.3.1</span> Fine-tuning within RAG</h3> 
  </div> 
  <div class="readable-text" id="p273"> 
   <p>Supervised fine-tuning (SFT) of LLMs has become a popular method to customize and adapt foundation models for specific objectives. There has been a growing debate in the applied AI community around the application of fine-tuning or RAG to accomplish tasks. While RAG enhances the non-parametric memory of a foundation model without changing the parameters, SFT changes the parameters of a foundation model and therefore influences the parametric memory. RAG and SFT should be considered as complementary, rather than competing, techniques because both address different parts of a generative AI system. You may prefer fine-tuning over RAG if there is a change required in the writing style, tonality, and vocabulary of the LLM responses. In their paper “Retrieval-Augmented Generation for Large Language Models: A Survey” (<a href="https://arxiv.org/abs/2312.10997"><span class="Hyperlink">https:</span><span class="Hyperlink">/</span><span class="Hyperlink">/arxiv.org/abs/2312.10997</span></a>), Gao and colleagues plot the evolution of prompt engineering to RAG and fine-tuning. This is illustrated in figure 9.10, demonstrating the need for fine-tuning with the increase in the need for model adaptation.</p> 
  </div> 
  <div class="browsable-container figure-container " id="p274">  
   <img src="../Images/CH09_F10_Kimothi.png" alt="A diagram of a diagram

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 9.10</span><span class=""> </span><span class="">Prompt engineering requires low modifications to the model and external knowledge, focusing on harnessing the capabilities of LLMs themselves. Fine-tuning, however, involves further training the model. Source: </span><a href="https://arxiv.org/abs/2312.10997"><span class=""><span class="Hyperlink CharOverride-4">https://arxiv.org/abs/2312.10997</span></span></a><span class="">.</span></h5>
  </div> 
  <div class="readable-text" id="p275"> 
   <p>Fine-tuning methods for both retrievers and generators hold immense potential for significantly improving RAG performance. Retriever fine-tuning enhances the ability of retrieval models to accurately capture semantic nuances relevant to specific domains, using methods such as contrastive learning, supervised embedding fine-tuning, LM-<br />supervised retrieval, or reward-based fine-tuning. Generator fine-tuning complements this by adapting language models through methods such as fusion-in-decoder (FiD), prompt tuning, latent fusion techniques, and parameter-efficient fine-tuning (PEFT). Combining these approaches within a hybrid fine-tuning framework can align the retrieval and generation components more effectively, leading to higher accuracy, reduced hallucinations, and improved adaptability to domain-specific tasks.</p> 
  </div> 
  <div class="readable-text" id="p276"> 
   <h3 class=" readable-text-h3"><span class="num-string">9.3.2</span> Long-context windows in LLMs</h3> 
  </div> 
  <div class="readable-text" id="p277"> 
   <p>Context windows in LLMs keep growing significantly with iteration. As of this writing, Claude 3.5 sonnet supports a window of up to 200,000 tokens, while GPT-4o, O1, and variants can process 128,000 tokens. Google Gemini 1.5 leads with a massive 1-million-token context window. It is possible that when you read this book, there may be models with even longer context windows. So, in a lot of cases, we can just pass the entire context such as a long document to the model as part of the prompt. This would eliminate the need for chunking, indexing, and retrieval in cases where the knowledge base is not too large. In their paper, “Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach” (<a href="https://arxiv.org/abs/2407.16833"><span class="Hyperlink">https:</span><span class="Hyperlink">/</span><span class="Hyperlink">/arxiv.org/abs/2407.16833</span></a>), Li and colleagues systematically compare RAG and LLMs with long-context windows. They demonstrate that long-context LLMs outperform RAG with a few exceptions. However, processing long contexts directly with LLMs can be computationally expensive. RAG is significantly more cost-efficient owing to processing shorter inputs. A hybrid approach such as SELF-ROUTE proposed in the same paper uses model self-reflection to decide whether a query can be answered with retrieved chunks or if it needs the full context. Figure 9.11 illustrates the SELF-ROUTE approach, in which the model receives the query with the retrieved chunks and determines whether the query can be answered based on this information. If yes, it generates the answer. If no, the full context is provided to the model, and the model generates the final answer.</p> 
  </div> 
  <div class="browsable-container figure-container " id="p278">  
   <img src="../Images/CH09_F11_Kimothi.png" alt="A diagram of a diagram

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 9.11</span><span class=""> </span><span class="">A hybrid approach utilizing RAG and long context in LLMs can lead to better performance without adversely increasing the costs.</span></h5>
  </div> 
  <div class="readable-text" id="p279"> 
   <h3 class=" readable-text-h3"><span class="num-string">9.3.3</span> Managed solutions</h3> 
  </div> 
  <div class="readable-text" id="p280"> 
   <p>With the growing popularity of RAG and its significance in generative AI applications, many service providers offer managed RAG pipelines in which several RAG components can be configured without the need for custom development. For example, knowledge bases are an Amazon Bedrock capability that facilitates implementation of the entire RAG workflow. Azure AI Search provides indexing and query capabilities, with the infrastructure of the Azure cloud, and Vertex AI RAG Engine is a component of Google’s Vertex AI platform that facilitates RAG. There are also independent service providers such as CustomGPT, Needle AI, Ragie, and so forth that provide managed RAG pipelines. As with managed solutions across technologies, the factors to consider are cost, applicability to the use case, flexibility, and control over components. </p> 
  </div> 
  <div class="readable-text" id="p281"> 
   <h3 class=" readable-text-h3"><span class="num-string">9.3.4</span> Difficult queries</h3> 
  </div> 
  <div class="readable-text" id="p282"> 
   <p>Some key reasons for failures in RAG systems are related to the types of queries. As RAG developers, it is important to keep focusing on these query types so that the technique can be improved. Some of these are </p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p283"><em>Multi-step reasonin</em><em>g</em>—RAG struggles with queries needing multi-hop retrieval (e.g., “What nationality is the performer of song XXX?”). </li> 
   <li class="readable-text" id="p284"><em>General querie</em><em>s</em>—Vague or broad questions are hard to retrieve relevant chunks for (e.g., “What does the group think about XXX?”)</li> 
   <li class="readable-text" id="p285"><em>Complex or long querie</em><em>s</em>—Complex queries challenge the retriever’s understanding.</li> 
   <li class="readable-text" id="p286"><em>Implicit querie</em><em>s</em>—Questions requiring comprehensive context understanding can’t be addressed by RAG alone.</li> 
  </ul> 
  <div class="readable-text" id="p287"> 
   <p>We have come a long way in our discussion on RAG. This chapter provided an exhaustive summary of the contents of this book, from the benefit of RAG to the best practices in building RAG systems. At the risk of repetition, RAG is an important and evolving technique in the field of generative AI. I hope you had a good time reading this book. I’ll leave you with the following closing thoughts: </p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p288">Remember to remain familiar with the principles of contextual AI powered by RAG.</li> 
   <li class="readable-text" id="p289">Have faith in your ability to build complex RAG systems.</li> 
   <li class="readable-text" id="p290">Always bear in mind the development challenges and strategies to overcome them.</li> 
   <li class="readable-text" id="p291">Understand the ethical and legal concerns around generative AI.</li> 
   <li class="readable-text" id="p292">Be on top of the rapidly changing trends.</li> 
  </ul> 
  <div class="readable-text" id="p293"> 
   <h2 class=" readable-text-h2">Summary</h2> 
  </div> 
  <div class="readable-text" id="p294"> 
   <h3 class=" readable-text-h3">RAG development framework</h3> 
  </div> 
  <ul> 
   <li class="readable-text" id="p295">The RAG development framework provides a structured approach to building, deploying, and maintaining retrieval-augmented generation systems.</li> 
   <li class="readable-text" id="p296">It addresses the complexity of RAG systems by incorporating six iterative and cyclic stages: initiation, design, development, evaluation, deployment, and maintenance.</li> 
   <li class="readable-text" id="p297">The framework emphasizes both the technical and operational aspects of RAG system development.</li> 
  </ul> 
  <div class="readable-text" id="p298"> 
   <h3 class=" readable-text-h3">RAG development framework stages</h3> 
  </div> 
  <ul> 
   <li class="readable-text" id="p299"><strong>Initiation stage</strong><strong></strong> 
    <ul> 
     <li>Focuses on understanding the problem statement, aligning stakeholders, and gathering requirements.</li> 
     <li>Emphasizes use case identification and assessing the need for RAG, using tools like use case evaluation cards.</li> 
     <li>Involves requirements gathering across business, functional, and non-functional needs.</li> 
     <li>Concludes with drafting a high-level architecture diagram for alignment and strategic decision-making. </li> 
    </ul> </li> 
   <li class="readable-text" id="p300"><strong>Design stage</strong> 
    <ul> 
     <li>Transforms high-level architecture into detailed pipeline designs for indexing and generation.</li> 
     <li>Incorporates choices around chunking, embeddings, and retrieval strategies.</li> 
     <li>Addresses additional considerations such as guardrails, caching, security, and deployment strategies. </li> 
    </ul> </li> 
   <li class="readable-text" id="p301"><strong>Development stage</strong> 
    <ul> 
     <li>Implements modular RAG pipelines, enabling flexibility, scalability, and maintainability.</li> 
     <li>Activities include training/fine-tuning models, creating independent modules (e.g., chunking, retrieval, generation), and building orchestration layers.</li> 
    </ul> </li> 
   <li class="readable-text" id="p302"><strong>Evaluation stage</strong> 
    <ul> 
     <li>Validates RAG system components and overall performance using metrics such as context relevance, faithfulness, precision, recall, latency, and cost per query.</li> 
     <li>Employs ground truth datasets for benchmarking and optimization.</li> 
    </ul> </li> 
   <li class="readable-text" id="p303"><strong>Deployment stage</strong> 
    <ul> 
     <li>Includes deployment strategies like blue-green, canary, rolling, and A/B testing to ensure smooth transitions and minimal disruption.</li> 
     <li>Emphasizes real-time user feedback and system scalability.</li> 
    </ul> </li> 
   <li class="readable-text" id="p304"><strong>Maintenance stage</strong> 
    <ul> 
     <li>Ensures system reliability through continuous monitoring of component metrics, user behavior, and performance metrics.</li> 
     <li>Adapts to evolving use cases, technological advancements, and user feedback.</li> 
    </ul> </li> 
  </ul> 
  <div class="readable-text" id="p305"> 
   <h3 class=" readable-text-h3">Best practices in RAG development</h3> 
  </div> 
  <ul> 
   <li class="readable-text" id="p306">Modular design improves adaptability and ease of updates.</li> 
   <li class="readable-text" id="p307">Ground truth datasets are essential for accurate evaluation and fine-tuning.</li> 
   <li class="readable-text" id="p308">Deployment strategies should align with system criticality, scale, and risk tolerance.</li> 
   <li class="readable-text" id="p309">Regularly monitor for changes in user behavior, data, and performance to maintain reliability.</li> 
  </ul> 
  <div class="readable-text" id="p310"> 
   <h3 class=" readable-text-h3">Ideas for further exploration</h3> 
  </div> 
  <ul> 
   <li class="readable-text" id="p311"><strong>RAG vs. fine-tuning</strong> 
    <ul> 
     <li>RAG complements fine-tuning by enhancing non-parametric memory, while fine-tuning adapts parametric memory for style, tonality, and vocabulary.</li> 
     <li>Use cases may benefit from hybrid approaches, depending on specific needs.</li> 
    </ul> </li> 
   <li class="readable-text" id="p312"><strong> Long-context windows in LLMs</strong> 
    <ul> 
     <li>Advances in LLMs (e.g., 200k+ token contexts) can reduce reliance on chunking and retrieval for smaller knowledge bases.</li> 
     <li>Hybrid models such as SELF-ROUTE combine RAG with long-context processing to optimize cost and accuracy. </li> 
    </ul> </li> 
   <li class="readable-text" id="p313"><strong>Managed solutions</strong> 
    <ul> 
     <li>Services such as Amazon Bedrock, Azure AI Search, and Google Vertex AI RAG Engine offer prebuilt RAG pipelines, simplifying deployment and reducing development effort.</li> 
    </ul> </li> 
   <li class="readable-text" id="p314"><strong>Handling difficult queries</strong> 
    <ul> 
     <li>Multi-step reasoning, general queries, and implicit questions remain challenges for RAG systems.</li> 
    </ul> </li> 
  </ul>
 </body>
</html>