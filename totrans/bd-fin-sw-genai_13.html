<html><head></head><body>
<div id="sbo-rt-content"><div class="readable-text" id="p1">
<h1 class="readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">11</span> </span><span class="chapter-title-text">International ACH transactions and OFAC scanning</span></h1>
</div>
<div class="introduction-summary">
<h3 class="introduction-header"><span class="CharOverride-1">This chapter covers</span><span class="CharOverride-1"/></h3>
<ul>
<li class="readable-text" id="p2"><span class="CharOverride-2">IAT batches</span></li>
<li class="readable-text" id="p3"><span class="CharOverride-2">Enhancing the project to process IAT batches</span></li>
<li class="readable-text" id="p4"><span class="CharOverride-2">The OFAC list</span></li>
<li class="readable-text" id="p5"><span class="CharOverride-2">Scanning ACH files to stay in compliance</span></li>
</ul>
</div>
<div class="readable-text" id="p6">
<p>This chapter covers the final sprint of our program iteration. Of course, the business unit will get together for another PI planning session, and the process will start all over again. In this sprint, we are tasked with enhancing the project to expand beyond domestic ACH transactions and deal with batches containing international ACH transactions (IAT), which enable sending money electronically between accounts in different countries. Along with IAT processing, there is the need to ensure the financial institution is not sending transactions to individuals or countries that are currently under restrictions or sanctioned by the US government. Specifically, the Office of Foreign Asset Control (OFAC) provides a list of “Specially Designated Nationals,” also known as the SDN list, which is a register of individuals and companies whose assets are blocked, and dealing with them is prohibited.</p>
</div>
<div class="readable-text" id="p7">
<h2 class="readable-text-h2"><span class="num-string">11.1</span> Sprint planning</h2>
</div>
<div class="readable-text" id="p8">
<p>In this final sprint, we have a big request by the line of business, which is to enable IAT ACH transactions. In the original scope of our project, we were told that the financial institution was not going to take on the additional risk of processing international transactions. Therefore, the database was not designed to support these types of transactions. However, recently, the financial institution has been attempting to pursue larger business customers and has had trouble attracting them because such customers require the ability to receive and transfer funds internationally. </p>
</div>
<div class="readable-text intended-text" id="p9">
<p>As it often happens when meeting customer demands, we now have to update the dashboard to be able to support these types of transactions, which means including additional tables to the database, parsing of the file, and scanning of the customers involved to stay in compliance. Figure 11.1 provides a timeline for the proposed tasks associated with this sprint. Having a timeline that we can provide to other stakeholders can be helpful when addressing questions about the tasks we will be working on during the sprint and our schedule.</p>
</div>
<div class="browsable-container figure-container" id="p10">
<img alt="A diagram of a software project  Description automatically generated" height="503" src="../Images/CH11_F01_Kardell.png" style="width: 100%; max-width: max-content;" width="471"/>
<h5 class="figure-container-h5"><span class="">Figure 11.1</span><span class=""> </span><span class="">Timeline for IAT ACH transaction processing</span></h5>
</div>
<div class="readable-text" id="p11">
<p>With the sprint planning in place, we can move forward with work to support international ACH transactions.</p>
</div>
<div class="readable-text" id="p12">
<h2 class="readable-text-h2"><span class="num-string">11.2</span> International ACH transactions</h2>
</div>
<div class="readable-text" id="p13">
<p>Until this point, we have dealt with Prearranged Payment and Deposit Entry (PPD) batches. As you know, PPD batches are commonly used for direct deposits of payroll and pension payments. We may also remember that ACH started as a way of processing payments for domestic transactions in the early 1970s. With the expansion of the ACH system, support for IAT began in 2009, and the capabilities for ACH were expanded beyond domestic transactions. So, what is so different about IAT batches that we need to dedicate an entire sprint to add support for processing them? First and foremost, the IAT batches must conform to the 94-character limit imposed on all ACH records. As we will see in this section, this affects the way data must be transmitted.</p>
</div>
<div class="readable-text" id="p14">
<h3 class="readable-text-h3"><span class="num-string">11.2.1</span> IAT batches: An overview</h3>
</div>
<div class="readable-text" id="p15">
<p>Before we dive into supporting IAT batches, we first need to understand how a batch may be laid out. Figure 11.2 shows a sample batch we will work with to better understand the data involved. This batch represents an individual named Elena Santiago from Bilbao, Spain, sending a gift of $1.00 to a friend named David Wiliams from her account at Iberia Global Bank to his checking account at Futuristic FinTech.</p>
</div>
<div class="browsable-container figure-container" id="p16">
<img alt="A white background with black numbers and letters  Description automatically generated" height="237" src="../Images/CH11_F02_Kardell.png" style="width: 100%; max-width: max-content;" width="859"/>
<h5 class="figure-container-h5"><span class="">Figure 11.2</span><span class=""> </span><span class="">Sample IAT batch</span></h5>
</div>
<div class="readable-text" id="p17">
<p>That is a fair amount of information packed into the batch, so let’s take a moment to unpack it (figure 11.3), and then we can jump into the code.</p>
</div>
<div class="readable-text" id="p18">
<p>As shown in figure 11.4, the batch is marked as an IAT, with a Company Entry Description of GIFT. The FF3 is the Foreign Exchange Indicator, while the FF means fixed-to-fixed. The originated amount is the same as the one being received, and the 3 indicates that the Foreign Exchange Reference is spaces. The USDUSD represents the originating currency code (USD) and the destination currency code (USD), respectively.</p>
</div>
<div class="readable-text" id="p19">
<p>The entry record contains the number of addenda records that were passed (figure 11.5). We expect to see seven (0007) addenda records passed, which also happen to be a type 7. Another important field is obviously the amount—the $1.00 that was sent in this case.</p>
</div>
<div class="browsable-container figure-container" id="p20">
<img alt="A screenshot of a computer  Description automatically generated" height="297" src="../Images/CH11_F03_Kardell.png" style="width: 100%; max-width: max-content;" width="872"/>
<h5 class="figure-container-h5"><span class="">Figure 11.3</span><span class=""> </span><span class="">Routing number and account</span></h5>
</div>
<div class="browsable-container figure-container" id="p21">
<img alt="A computer screen with text  Description automatically generated" height="298" src="../Images/CH11_F04_Kardell.png" style="width: 100%; max-width: max-content;" width="888"/>
<h5 class="figure-container-h5"><span class="">Figure 11.4</span><span class=""> </span><span class="">IAT batch header</span></h5>
</div>
<div class="browsable-container figure-container" id="p22">
<img alt="A screen shot of a computer  Description automatically generated" height="300" src="../Images/CH11_F05_Kardell.png" style="width: 100%; max-width: max-content;" width="872"/>
<h5 class="figure-container-h5"><span class="">Figure 11.5</span><span class=""> </span><span class="">IAT entry record</span></h5>
</div>
<div class="readable-text" id="p23">
<p>There are between 7 and 12 addenda records per record when dealing with IAT entries. This is different from what we have dealt with when parsing PPD batches, as we had an indicator for an optional addenda record. While that addenda indicator is still present on an IAT entry, it will always be set to 1.</p>
</div>
<div class="readable-text intended-text" id="p24">
<p>To keep things relatively simple, we will only consider the seven mandatory addenda records. They all start with a 7 to indicate an addenda record, followed by an addenda type code in the next two positions, producing the mandator records range from 710 to 716:</p>
</div>
<ul>
<li class="readable-text" id="p25"><em>71</em><em>0</em>—Foreign payment amount and receiver’s name</li>
<li class="readable-text" id="p26"><em>711</em>—Originator’s name and street</li>
<li class="readable-text" id="p27"><em>712</em>—Originator’s city, state, country, and postal code</li>
<li class="readable-text" id="p28"><em>71</em><em>3</em>—ODFI name, ID, and branch</li>
<li class="readable-text" id="p29"><em>71</em><em>4</em>—RDFI name, ID, and branch</li>
<li class="readable-text" id="p30"><em>71</em><em>5</em>—Receiver’s ID number and street</li>
<li class="readable-text" id="p31"><em>71</em><em>6</em>—Receiver’s city, state, country and postal code</li>
</ul>
<div class="readable-text" id="p32">
<p>Equipped with new knowledge, let’s create some IAT batches.</p>
</div>
<div class="readable-text" id="p33">
<h2 class="readable-text-h2"><span class="num-string">11.3</span> Creating IAT batches</h2>
</div>
<div class="readable-text" id="p34">
<p>Before we can start making changes and parsing a file, we must have a file. We have a sample provided in figure 11.2, and that, combined with the existing code we have to produce ACH files, should be more than enough to build from. If you reference the <a href="https://achdevguide.nacha.org/ach-file-details"><span class="Hyperlink">https:</span><span class="Hyperlink">/</span><span class="Hyperlink">/achdevguide.nacha.org/ach-file-details</span></a> and <a href="https://mng.bz/eyOv"><span class="Hyperlink">https:</span><span class="Hyperlink">/</span><span class="Hyperlink">/mng.bz/eyOv</span></a> as guides, you can see that we may be dealing with a few different layouts. </p>
</div>
<div class="readable-text intended-text" id="p35">
<p>When we dig into the details, we’ll find we are working with new records and formats. This means that when creating files specifically, we need to consider whether we have an IAT batch and create a file accordingly. We already have the code within our ach_file_creation.feature and test_create_ach_files.py to deal with creating batches with a specified Standard Entry Class (SEC) code such as the line <code>And</code> <code>I</code> <code>want</code> <code>to</code> <code>have</code> <code>1</code> <code>batch</code> <code>with</code> <code>ACH</code> <code>credits</code> <code>and</code> <code>debits</code> <code>and</code> <code>a</code> <code>standard</code> <code>entry</code> <code>class</code> <code>code</code> <code>of</code> <code>"PPD"</code>, which drives the creating of the batch. We must update our method <code>create_batch_header</code> to take the SEC code into consideration. So, as shown in the following listing, we start by defaulting (hardcoding) on some of the values. As usual, we go back when we need them to be dynamic and handle them at that point.</p>
</div>
<div class="browsable-container listing-container" id="p36">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.1<span class="CharOverride-3"> </span>Updated <code>create_batch_header</code></h5>
<div class="code-area-container">
<pre class="code-area">def create_batch_header(setup_info, batch_number):
…
    if setup_info["standard_entry_class"] == "IAT":
        batch_header = (
            f"5{setup_info['service_class_code']}"
            f"                "  #1
            f"FF"  #2
            f"3"  #3
            "               "  #4
            "US"  #5
            f"{setup_info['company_id']}"  #6
            f"{setup_info["standard_entry_class"]}"  #7
            "GIFT      "  #8
            "USD"  #9
            "USD"  #10
            f"{setup_info.get('effective_entry_date',  #11
<span class="CharOverride-6">➥</span>today_yymmdd)}"  
            f"{setup_info.get('settlement_date',day_of_year)}"  #12
            f"{setup_info.get('originator_status_code','1')}"  #13
            f"{setup_info.get('odfi','06100001')}"  #14
            f"{setup_info.get('batch_number', batch_number)}\n"
        )
    else:
… #15
    return batch_header</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">IAT indicator</span>
<br/>#2 
     <span class="CharOverride-5">Foreign exchange indicator</span>
<br/>#3 
     <span class="CharOverride-5">Foreign exchange reference indicator</span>
<br/>#4 
     <span class="CharOverride-5">Foreign exchange reference</span>
<br/>#5 
     <span class="CharOverride-5">ISO destination country code</span>
<br/>#6 
     <span class="CharOverride-5">Originator identification</span>
<br/>#7 
     <span class="CharOverride-5">Standard entry class code</span>
<br/>#8 
     <span class="CharOverride-5">Company entry description</span>
<br/>#9 
     <span class="CharOverride-5">ISO originating currency code</span>
<br/>#10 
     <span class="CharOverride-5">ISO destination currency code</span>
<br/>#11 
     <span class="CharOverride-5">Effective entry date</span>
<br/>#12 
     <span class="CharOverride-5">Settlement date</span>
<br/>#13 
     <span class="CharOverride-5">Originator status code</span>
<br/>#14 
     <span class="CharOverride-5">Originating DFI identification</span>
<br/>#15 
     <span class="CharOverride-5">Previous creation logic of the batch header</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p37">
<p>Since the SEC code is stored as part of our unit test information, we can reference it wherever necessary, and we will need it again when writing out the entries for an IAT batch. As described in the previous section, every entry record for an IAT record contains at least seven addenda records. We follow the same pattern, using the SEC code to create a new method that will take care of creating the needed entry and addenda records keeping things hardcoded for the most part and allowing for dynamic values. The code to create files is now over 500 lines long, and we should start to consider where refactoring is possible to clean it up. The logic to create specific types of files is a good candidate for refactoring since those details do not necessarily need to be part of this process.</p>
</div>
<div class="readable-text intended-text" id="p38">
<p>For now, however, the code should suffice for our initial file creation. The feature in the following listing should look familiar to our other file-creation steps. This is a good thing as it means our grammar is generic enough to handle some variations. Of course, we have some work to do to really make things dynamic, but we have more than enough information to create the files.</p>
</div>
<div class="browsable-container listing-container" id="p39">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.2<span class="CharOverride-3"> </span>Creating an ACH IAT file</h5>
<div class="code-area-container">
<pre class="code-area">  Scenario: Create an ACH for for IAT
    Given I want to create an ACH file named "iat.ach"
    And I want to have an immediate destination of "990000013"
    And I want to have an immediate origin of "987654321"
    And I want to have 1 batch with ACH credits only
<span class="CharOverride-6">➥</span> and a standard entry class code of "IAT"
    And I want 1 entries per batch with random amounts between 100 and 100
    And I want to use individual names of "James Smith,
<span class="CharOverride-6">➥</span> Sarah Johnson, David Williams, Emma Martinez, Olivia Thomas"
    And I want to have company name "My Company"
<span class="CharOverride-6">➥</span> and company id "1234567890"
    When my ACH is created
    Then I should have a file of the same name
    And there should be 1 batch in the file
    And there should be 1 entries in the file</pre>
</div>
</div>
<div class="readable-text" id="p40">
<p>With an ACH file containing an IAT batch available, we can start working on the necessary tables and structure to support storing the file.</p>
</div>
<div class="readable-text" id="p41">
<h3 class="readable-text-h3"><span class="num-string">11.3.1</span> Database changes</h3>
</div>
<div class="readable-text" id="p42">
<p>We need to add a minimum of nine tables to the database to support IAT processing. We are only considering the new batch header format, entry format, and the required addenda records. The layout of our tables in the database mimics the layout of the ACH records. Let’s take a look at some of the tables. Remember that our database structure relies on having both unparsed and parsed records, the idea being that our system will eventually expand to process the files asynchronously once they have been uploaded. Since no new record numbers have been introduced, we do not need to expand anything regarding the unparsed records as IAT will still fit nicely into that structure. If we want to have our parsed records stored (and we do), we need to add the nine tables.</p>
</div>
<div class="readable-text intended-text" id="p43">
<p>Let’s take a look at the <code>ach_iat_batch_headers</code> table in listing 11.3. Notice how it still has a foreign key reference to the <code>ach_records_type_5</code> table. Also, the majority of the fields are stored as <code>VARCHAR</code>, because as an initial iteration, we are looking to take a simple approach to the structure. In future iterations, fields such as <code>service_class_code</code> and <code>effective_entry_date</code> could be updated to <code>NUMERIC</code> or <code>DATE</code>, respectively. Those constraints will help ensure the integrity of the record and are worth dealing with.</p>
</div>
<div class="browsable-container listing-container" id="p44">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.3<span class="CharOverride-3"> </span>IAT batch headers table</h5>
<div class="code-area-container">
<pre class="code-area">CREATE TABLE ach_iat_batch_headers
(
    ach_records_type_5_id          UUID UNIQUE NOT NULL #1
         REFERENCES ach_records_type_5 (ach_records_type_5_id)  #2
                                             ON DELETE CASCADE   #2
                                             ON UPDATE CASCADE, 
    record_type_code               VARCHAR(1)  NOT NULL, #2
    service_class_code             VARCHAR(3)  NOT NULL, 
    iat_indicator                  VARCHAR(16) NOT NULL, 
    foreign_exchange_indicator     VARCHAR(2)  NOT NULL, #3
    foreign_exchange_ref_indicator VARCHAR(1)  NOT NULL, 
    foreign_exchange_reference     VARCHAR(15) NOT NULL, 
    iso_destination_country_code   VARCHAR(2)  NOT NULL, 
    originator_id                  VARCHAR(10) NOT NULL, 
    standard_entry_class_code      VARCHAR(3)  NOT NULL, 
    company_entry_description      VARCHAR(10) NOT NULL, 
    iso_originating_currency_code  VARCHAR(3)  NOT NULL, 
    iso_destination_currency_code  VARCHAR(3)  NOT NULL, 
    effective_entry_date           VARCHAR(6)  NOT NULL, 
    settlement_date                VARCHAR(3)  NOT NULL, 
    originator_status_code         VARCHAR(1)  NOT NULL, 
    originating_dfi_identification VARCHAR(8)  NOT NULL, 
    batch_number                   NUMERIC(7)  NOT NULL 
);</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">The foreign key for the </span>
<span class="CharOverride-5">batch header with CASCADEs for the deletes and updates</span>
<br/>#2 
     <span class="CharOverride-5">The rest of the fields required to support the parsing of the ACH record. Consider using more specific data types to ensure the record is formatted correctly by enforcing correct typing at the database level.</span>
<br/>#3 
     <span class="CharOverride-5">The rest of the fields required to support the parsing of the ACH record. Consider using more specific data types to ensure the record is formatted correctly by enforcing correct typing at the database level.</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p45">
<p>The rest of the tables are handled in much the same way, but we should be aware of a couple of design choices and standards we may need to consider when dealing with the addenda records. As an example, let’s use the addenda record that contains the originator’s city, state, country, and postal code. This addenda record has a record type code of 7 (because it is an addenda record) and an addenda type code of 12 (because that is what Nacha decided).</p>
</div>
<div class="readable-text intended-text" id="p46">
<p>First, we need to name our tables. So, should we use the <code>ach_iat_originator_address_info</code> or <code>ach_iat_addenda_712_records</code> or some variation on that? In general, it does not matter unless we go with a name that is extreme (i.e., too long or too short and cryptic). We originally went with <code>ach_iat_addenda_712_records </code>because the 712 will be at the beginning of every line for those types of addenda records in the file, and we can key off that when trying to remember the name of our table. It also saves us from having to know what that type of addenda we are dealing with (i.e., whether this is the originator address or receiver address). Of course, there may be some complaints about the table name, such as</p>
</div>
<ul>
<li class="readable-text" id="p47">It contains the word addenda and a 7 which is redundant, as a type 7 record is always an addenda</li>
<li class="readable-text" id="p48">It does not separate the 7 and 12 with an underscore even though they are two separate fields</li>
<li class="readable-text" id="p49">It uses the word records, and previously, tables using “records” contained unparsed records</li>
</ul>
<div class="readable-text" id="p50">
<p>We point these out to highlight the importance of consistency and standards. The closer we stay to established standards, the more consistent we are likely to be. Given that we wanted to try to adhere to a standard, we implemented the following:</p>
</div>
<ul>
<li class="readable-text" id="p51">Use <code>_details</code> for tables that contained the parsed records</li>
<li class="readable-text" id="p52">Use <code>_records</code> for tables that contained the unparsed records</li>
<li class="readable-text" id="p53">Use the prefix <code>ach_ppd</code>, <code>ach_iat</code>, and so on for tables that dealt with specific ACH formats, as we were not always consistent with where the name <code>ppd</code> was used in the table</li>
</ul>
<div class="readable-text" id="p54">
<p>Thus, we ended up with names such as <code>ach_iat_entry_details</code> and <code>ach_iat_addenda_10_details</code>.</p>
</div>
<div class="readable-text intended-text" id="p55">
<p>Next, let’s tackle the table itself. Listing 11.4 shows the <code>ach_iat_addenda_712_records</code> table. Some of these IAT addenda records are unique to the ACH standards because they contain fields that are delimited within the fixed records. Strange, huh?</p>
</div>
<div class="readable-text intended-text" id="p56">
<p>Previously, other formats were strictly a fixed-length record. So, we could say those 15 characters are the name and will be stored in the name field. With some of these addenda records, we have a fixed length field, such as the 35 character “Originator City &amp; State/Province,” which contains both the city and state. The data elements are delimited by an asterisk <code>*</code>, and the backslash <code>\</code> is the terminator for the last element. This results in a table that has seven fields (excluding the UUID), whereas the record has six fields. Note that one of the fields is reserved and not in use, and therefore, it is not represented in the table. Consequently, these parsed fields are represented in the table by individual fields. We left each individual field at the maximum field size, so although the originators city/state are both contained in one field of 35 characters, we kept both the city and state fields in the table at 35 bytes to avoid confusion.</p>
</div>
<div class="browsable-container listing-container" id="p57">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.4<span class="CharOverride-3"> </span>Table for IAT addenda type 12</h5>
<div class="code-area-container">
<pre class="code-area">CREATE TABLE ach_iat_addenda_712_records
(
    ach_records_type_7_id        UUID UNIQUE NOT NULL 
            REFERENCES ach_records_type_7 (ach_records_type_7_id) 
            ON DELETE CASCADE ON UPDATE CASCADE,
    record_type_code             VARCHAR(1)  NOT NULL,
    addenda_type_code            NUMERIC(2)  NOT NULL DEFAULT 12, #1
    originator_city              VARCHAR(35), #2
    originator_state             VARCHAR(35),  #3
    originator_country           VARCHAR(35),  #3
    originator_postal_code       VARCHAR(35), 
    entry_detail_sequence_number NUMERIC(7)  NOT NULL
);</pre>
<div class="code-annotations-overlay-container">
     #1 
     <strong>Defaults the addenda_type_code to be a 12 as it must always be a 12 for this record</strong>
<br/>#2 
     <strong>Leaves these records as VARCHAR(35), although we could consider enforcing a stricter data type</strong>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p58">
<p>This code provides the pattern for how all the IAT tables were dealt with. Next, we look at how the records are parsed.</p>
</div>
<div class="readable-text" id="p59">
<h2 class="readable-text-h2"><span class="num-string">11.4</span> IAT record parsing</h2>
</div>
<div class="readable-text" id="p60">
<p>To parse the records, we use the file creation steps we built earlier to create a sample file and then use unit test to build the needed code to parse the various records and store them in the database (listing 11.5). We have our sample record that we are looking to parse—the expected result. We set up the necessary records for testing by calling <code>setup_iat_addenda_test</code>, which simply adds the needed headers and entry records to the database so that all the foreign keys work as expected. Then, we call the <code>_parse_iat_addenda_712</code> and the class <code>AchIat712AddendaSql</code>. It can sometimes be tempting to simply define the <code>expected_result</code> based on the return value when we are sure our logic is correct. We would advise against that and make sure the record is parsed in another way, whether that is by hand or with another tool so that the results are independently verified.</p>
</div>
<div class="browsable-container listing-container" id="p61">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.5<span class="CharOverride-3"> </span>Unit testing the parse routine for Type 12 addenda</h5>
<div class="code-area-container">
<pre class="code-area">class TestParsingIat712AddendaRecords:

    TABLE_NAME: str = "ach_iat_addenda_712_records"

    @pytest.fixture(autouse=True)   #1
    def setup_teardown_method(self):  #1
        SqlUtils.truncate_all()  #1
        yield  #1

    def test_parse_iat_addenda_712_records(self):
        sample_addenda_record = "712BILBAO*BIZKAIA\ #2
<span class="CharOverride-6">➥</span>                    ES*48001\                        #2
<span class="CharOverride-6">➥</span>                  0000001" 

record
        expected_result = { #3
            "record_type_code": Literal["7"],  #3
            "addenda_type_code": 12,  #3
            "originator_city": "BILBAO",  #3
            "originator_state": "BIZKAIA",  #3
            "originator_country": "ES",  #3
            "originator_postal_code": "48001",  #3
            "entry_detail_sequence_number": 1,  #3
        }  #3

        _, ach_records_type_7_id = #4
            SqlUtils.setup_iat_addenda_test(  #4
               sample_addenda_record  #4
            )  #4

        parser = AchFileProcessor() #5
        parser._parse_iat_addenda_712(ach_records_type_7_id,  #5
                                      sample_addenda_record) 

        sql = AchIat712AddendaSql() #6
        retrieved_record =  #7
           sql.get_record(ach_records_type_7_id).model_dump(  #7
               exclude={"ach_records_type_7_id"}  #7
           )  #7

        assert SqlUtils.get_row_count_of_1( #7
            self.TABLE_NAME  #7
        ), f"Expected 1 row in {self.TABLE_NAME}"  #7
        assert (  #7
            retrieved_record == expected_result  #7
        ), f"Expected {expected_result}, #7
<span class="CharOverride-6">➥</span> but got {retrieved_record}"  #7</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">The fixture to ensure the database is empty; we have autouse set to True so there is no need to include it in our test methods as it will automatically be executed.</span>
<br/>#2 
     <span class="CharOverride-5">A sample addenda record taken from our test ACH file</span>
<br/>#3 
     <span class="CharOverride-5">The dictionary of the expected result to validate the retrieved record</span>
<br/>#4 
     <span class="CharOverride-5">Sets up the needed database records so the constraints are satisfied</span>
<br/>#5 
     <span class="CharOverride-5">Parses the record, which will also add it to the database</span>
<br/>#6 
     <span class="CharOverride-5">Retrieves the record, excluding the UUID field. Since the UUID is assigned by the database, we cannot hardcode it in our expected results.</span>
<br/>#7 
     <span class="CharOverride-5">Performs asserts to ensure there is only one row and that the record matches our expected value that was previously defined</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p62">
<p>The previous unit test will fail until we have built the required functionality. We will work through the required pieces of code to establish a pattern. All the unit tests for this will follow a similar approach. The first missing method that we encounter is the <code>_parse_iat_addenda_712</code> method, as in the following listing. Although it is straightforward, we do have to populate the <code>expected_record_types</code>, which helps the parser determine when records are out of sequence. </p>
</div>
<div class="readable-text intended-text" id="p63">
<p>We want to keep verification in mind when we get to updating the processing logic for our ACH file because we will need to determine whether we have received all the required records and ensure that there are no duplicate addenda records. </p>
</div>
<div class="browsable-container listing-container" id="p64">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.6<span class="CharOverride-3"> </span>The <code>_parse_iat_addenda_712</code> record</h5>
<div class="code-area-container">
<pre class="code-area">def _parse_iat_addenda_712(self, ach_records_type_7_id: UUID, line: str):
     self.expected_record_types = ["6", "7", "8"] #1

     ach_iat_addenda_record = #2
        AchRecordProcessor().parse_iat_addenda_712(  #3
           ach_records_type_7_id, line  #3
        ) 
        AchIat712AddendaSql()#3
           .insert_record(ach_iat_addenda_record) </pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">The expected record types that can be passed to us</span>
<br/>#2 
     <span class="CharOverride-5">The parsing is actually done with the AchRecordProcessor. At this point, we may also consider moving some of our parsing routines to new classes.</span>
<br/>#3 
     <span class="CharOverride-5">With the parsed record, we need to insert it into the database.</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p65">
<p>Next, we create the method <code>parse_iat_addenda_712</code>. This task could also involve its own separate unit tests since the purpose of that class is twofold. First, it consolidates the actual parsing logic into a central location, which reduces the code in our ACH file processor and allows clearer understanding of the ACH processing flow. Second, it allows us to test the parsing logic in isolation without the need for a bunch of setup in the database. </p>
</div>
<div class="readable-text intended-text" id="p66">
<p>However, the parsing is not overly complicated and will be tested by this overall process, so for the time being, we will not worry about it having its own unit test. The following listing shows the code for parsing the IAT addenda.</p>
</div>
<div class="browsable-container listing-container" id="p67">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.7<span class="CharOverride-3"> </span>Parsing the IAT addenda record</h5>
<div class="code-area-container">
<pre class="code-area">def parse_iat_addenda_712(
        self, ach_records_type_7_id, line
    ) -&gt; AchIat712AddendaSchema:
   regex = r"([^*]+)\*([^\\]+)\\" #1
   match = re.match(regex, line[3:38]) #2
   if not match:  #2
      raise ValueError("Error parsing originator  #2
<span class="CharOverride-6">➥</span> city and state")  #2
   originator_city, originator_state = match.groups()  #2

   match = re.match(regex, line[38:73]) #3
   if not match:  #3
      raise ValueError("Error parsing originator country   #3
                                and postal code")  #3
   originator_country, originator_postal_code = match.groups()  #3

   return AchIat712AddendaSchema( #4
      ach_records_type_7_id=ach_records_type_7_id,  #4
      record_type_code=line[0],  #4
      addenda_type_code=line[1:3],  #4
      originator_city=originator_city.strip(),  #4
      originator_state=originator_state.strip(),  #4
      originator_country=originator_country.strip(),  #4
      originator_postal_code=originator_postal_code.strip(),  #4
      entry_detail_sequence_number=line[87:94],  #4
   )  #4</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">Creates a regular expression that will parse the delimited fields within the record</span>
<br/>#2 
     <span class="CharOverride-5">Ensures we have matches and extracts them for the city and state</span>
<br/>#3 
     <span class="CharOverride-5">Ensures we have matches and extracts them for the country and postal code</span>
<br/>#4 
     <span class="CharOverride-5">Parses the record and returns it as part of our schema</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p68">
<p>Moving on, we need to define the schema used for these records. As shown in listing 11.8, we provide a minimum layout that matches what we expect to insert into the database. </p>
</div>
<div class="browsable-container listing-container" id="p69">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.8<span class="CharOverride-3"> </span>IAT addenda 712 schema</h5>
<div class="code-area-container">
<pre class="code-area">class AchIat712AddendaSchema(BaseModel):
    ach_records_type_7_id: UUID
    record_type_code: str = Literal["7"]
    addenda_type_code: int = Literal[12]
    originator_city: str = Field(..., max_length=35)
    originator_state: str = Field(..., max_length=35)
    originator_country: str = Field(..., max_length=35)
    originator_postal_code: str = Field(..., max_length=35)
    entry_detail_sequence_number: int = Field(..., ge=0)</pre>
</div>
</div>
<div class="readable-text" id="p70">
<p>The final step is to create a class to handle the SQL logic for inserting and retrieving the record.</p>
</div>
<div class="browsable-container listing-container" id="p71">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.9<span class="CharOverride-3"> </span>IAT addenda type 12 SQL</h5>
<div class="code-area-container">
<pre class="code-area">class AchIat712AddendaSql: #1
 #2
    def insert_record(self,  #2
                      ach_iat_addenda: AchIat712AddendaSchema): 
        with get_db_connection() as conn: #2
            conn.execute(                 #3
                """  #3
                   INSERT INTO ach_iat_addenda_712_records (  #3
                            ach_records_type_7_id, addenda_type_code,  #3
                            originator_city, originator_state,  #3
                            originator_country, originator_postal_code,  #3
                            entry_detail_sequence_number )  #3
                        VALUES ( %(ach_records_type_7_id)s,  #3
      %(addenda_type_code)s, %(originator_city)s,  #3
      %(originator_state)s,  #3
      %(originator_country)s, %(originator_postal_code)s,   #3
      %(entry_detail_sequence_number)s)  #3
                """,  #3
                ach_iat_addenda.model_dump(), #4
            )
… #5</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">Defines a class and method to insert our record schema</span>
<br/>#2 
     <span class="CharOverride-5">Obtains a database connection</span>
<br/>#3 
     <span class="CharOverride-5">SQL to insert the fields and values for our model</span>
<br/>#4 
     <span class="CharOverride-5">Creates a dictionary of the schema to use with the INSERT statement</span>
<br/>#5 
     <span class="CharOverride-5">The rest of the methods, specifically getting a </span>
<span class="CharOverride-5">record by the UUID</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p72">
<p>With that, we should be able to go back and ensure all the import statements are in place and then run our unit test successfully. Assuming we are parsing the record correctly (for both the expected and the actual record), we should have a passing unit test. </p>
</div>
<div class="callout-container sidebar-container">
<div class="readable-text" id="p73">
<h5 class="callout-container-h5 readable-text-h5">Unit testing IAT challenge</h5>
</div>
<div class="readable-text" id="p74">
<p>This pattern needs to be repeated for all the new database records, and now is a great time to take a break and write some code. We have sample files. It is now just a matter of working through parsing the remaining records. If the previous code examples still seem a bit daunting, we could also start at a smaller scale by creating unit tests for <code>AchRecordProcessor</code>, which is solely responsible for parsing the ACH record with no database interaction. The simpler requirements for testing the <code>Ach­RecordParser</code> should mean that it takes less work to set up our unit tests. Once the parsing is verified at that level, we can take a step back to see the bigger picture and begin writing unit tests that involve the database, as outlined in this section.</p>
</div>
</div>
<div class="readable-text" id="p75">
<p>While we should have all the parsing validated at this stage, we still need to update our <code>ach_file_processor</code> to handle the IAT batch and make use of all this wonderful code we just wrote.</p>
</div>
<div class="readable-text" id="p76">
<h2 class="readable-text-h2"><span class="num-string">11.5</span> IAT file processing</h2>
</div>
<div class="readable-text" id="p77">
<p>At this point, we have built the pieces of our IAT processing. We should feel fairly confident that we can handle the individual records and parsing them. Now, we need to be able to incorporate the parsing of an actual IAT batch within a file. We need to keep in mind that the work we did in previous sections tested individual pieces. For instance, we know that when we call the <code>_parse_iat_batch_header</code> method and pass it an IAT batch header record, it will be parsed and stored in the database. However, the method is not called in the current flow of loading an ACH file through the <code>POST</code> call. As we work on adding the functionality to the parser, we should keep some goals and requirements in mind:</p>
</div>
<ul>
<li class="readable-text" id="p78">Parsing a PPD batch still works as expected.</li>
<li class="readable-text" id="p79">Addenda records are all present.</li>
<li class="readable-text" id="p80">Addenda records are in the correct order.</li>
</ul>
<div class="readable-text" id="p81">
<p>In the next section, we begin ensuring that we have unit tests before we start making changes to the actual code.</p>
</div>
<div class="readable-text" id="p82">
<h3 class="readable-text-h3"><span class="num-string">11.5.1</span> Unit testing</h3>
</div>
<div class="readable-text" id="p83">
<p>We hope it is obvious that after adding the IAT batches, we should still be able to load PPD batches. So, do not forget to test and verify that we have not broken anything with the addition of IAT processing. This means that we want to ensure we implement some regression testing—the last thing we want to do is spend all our time working on the new processing and not validate the previous work.</p>
</div>
<div class="readable-text intended-text" id="p84">
<p>With that in mind, the first order of business is to create a test_loading_pdd_files file and ensure that we have the correct record count when loading a PPD batch. We start with simple tests to get the count of the unparsed records. We test for the individual record counts and the total number of records, ensuring that we did not write any exceptions, as shown in the following listing.</p>
</div>
<div class="browsable-container listing-container" id="p85">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.10<span class="CharOverride-3"> </span>Testing PPD batches</h5>
<div class="code-area-container">
<pre class="code-area">def test_good_unparsed_records_only(self, parser):
    filename = "ppd-mixed.ach"  #1
    dir_path = os.path.dirname(os.path.realpath(__file__)) #2
    file_path = os.path.join(dir_path, "data", filename) 

    expected_exceptions_result: int = 0 #3
    expected_total_records_result: int = 14 

    ach_file_id = SqlUtils. #4
<span class="CharOverride-6">➥</span>create_ach_file_record(filename, "123456789")  #4
 #4
    parser.parse(ach_file_id, file_path)  #4
    exceptions = SqlUtils.get_exceptions()  #4

    with SqlUtils.get_db() as conn:   #5
        record_count_type1 = conn.execute(  #5
            "SELECT COUNT(*) FROM ach_records_type_1"  #5
        ).fetchone()[0]  #5
…                     #5
        record_count_type9 = conn.execute(  #5
            "SELECT COUNT(*) FROM ach_records_type_9"  #5
        ).fetchone()[0]  #5

        total_record_count = ( #6
            record_count_type1  #6
            + record_count_type5  #6
            + record_count_type6  #6
            + record_count_type7  #6
            + record_count_type8  #6
            + record_count_type9  #6
        )  #6

        assert record_count_type1 == 1, #7
                f"Expected 1, but got {record_count_type1}"  #7
…  #7
        assert (  #7
            total_record_count == expected_total_records_result  #7
        ), f"Expected {expected_total_records_result}, but got  #7
{total_record_count}"  #7
…  #7</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">Defines a file name since it will be used in a few different places during the test</span>
<br/>#2 
     <span class="CharOverride-5">Ensures we can reference the file</span>
<br/>#3 
     <span class="CharOverride-5">Sets up some initial expected values</span>
<br/>#4 
     <span class="CharOverride-5">Sets up the test, parses the file, and returns any exceptions</span>
<br/>#5 
     <span class="CharOverride-5">Queries the database to get record counts for each of the tables that stores our unparsed records. This test contains a lot of repetitive code to obtain the count for each type.</span>
<br/>#6 
     <span class="CharOverride-5">Adds the record counts together to get the total count, but it is somewhat redundant since we are testing the counts individually as well. However, how many times we would be asked about a total count if this was not here?</span>
<br/>#7 
     <span class="CharOverride-5">Asserts the record counts are correct</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p86">
<p>The previous test works well enough, but as it tends to happen with our development, we repurposed some other test to create the new one and ended up copying/pasting code to get the additional record counts and <code>assert</code> statement. In fact, Copilot is nice enough to fill in some of the code for us, so we did not even have to do much copying/pasting. There is one problem, though—we should be treating our test code as a first-class citizen, giving it the same attention we gave to our production code.</p>
</div>
<div class="readable-text intended-text" id="p87">
<p>Let’s look at how we might rework the above code to make it more concise and easier to understand. The changes in the following listing shortened the code from 53 to 45 lines, and while that is not the only metric, we should use it for judging whether code is good or bad. Early on in our careers, we were told by one of our mentors that it felt more productive when they were removing code rather than writing it. </p>
</div>
<div class="browsable-container listing-container" id="p88">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.11<span class="CharOverride-3"> </span>Refactored unit test for unparsed records</h5>
<div class="code-area-container">
<pre class="code-area">with SqlUtils.get_db(row_factory=dict_row) as conn: #1
    record_counts = conn.execute(
    """
    SELECT 
        record_count_type1, #2
        record_count_type5,  #2
        record_count_type6,  #2
        record_count_type7,  #2
        record_count_type8,  #2
        record_count_type9,  #2
        record_count_type1 + record_count_type5 +  #3
        record_count_type6 + record_count_type7 +   #3
        record_count_type8 + record_count_type9   #3
                             AStotal_record_count  #3
    FROM ( #4
     SELECT 
       (SELECT COUNT(*) FROM ach_records_type_1)  
                          AS record_count_type1, 
       (SELECT COUNT(*) FROM ach_records_type_5)  
                          AS record_count_type5, #5
       (SELECT COUNT(*) FROM ach_records_type_6)  
                          AS record_count_type6, 
       (SELECT COUNT(*) FROM ach_records_type_7)  
                          AS record_count_type7, 
       (SELECT COUNT(*) FROM ach_records_type_8)  
                          AS record_count_type8, 
       (SELECT COUNT(*) FROM ach_records_type_9)  
AS record_count_type9 
        ) AS counts 
   """
   ).fetchone() #6
   record_counts["exception_count"] = len(exceptions) #7

assert expected_results == record_counts #8</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">Updates the get_db </span>
<span class="CharOverride-5">call to use a row_factory of dict_row</span>
<br/>#2 
     <span class="CharOverride-5">The record counts for each of our ACH tables</span>
<br/>#3 
     <span class="CharOverride-5">Computes the </span>
<span class="CharOverride-5">total records</span>
<br/>#4 
     <span class="CharOverride-5">The queries to get the counts of each row</span>
<br/>#5 
     <span class="CharOverride-5">The queries to get the counts of each row</span>
<br/>#6 
     <span class="CharOverride-5">Gets the single result</span>
<br/>#7 
     <span class="CharOverride-5">Adds the exception count into the record_counts dictionary</span>
<br/>#8 
     <span class="CharOverride-5">Compares the two dictionaries</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p89">
<p>We have a similar query to verify that parsed records exist in the table for all the parsed records as well. Ideally, we would expect an exception to be in the table if we had any problems parsing, but in case we have not yet coded for that or perhaps missed a condition that would cause a parse error, it is good to check these tables as well.</p>
</div>
<div class="browsable-container listing-container" id="p90">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.12<span class="CharOverride-3"> </span>Unit test for parsed PPD records</h5>
<div class="code-area-container">
<pre class="code-area">SELECT 
   record_count_type1, #1
   record_count_type5,  #1
   record_count_type6,  #1
   record_count_type7,  #1
   record_count_type8,  #1
   record_count_type9,  #1
   record_count_type1 + record_count_type5 +   #1
   record_count_type6 + record_count_type7 +  #1
   record_count_type8 + record_count_type9   #1
                                         AS total_record_count  #1
FROM (
   SELECT #2
      (SELECT COUNT(*) FROM ach_file_headers)  #2
                            AS record_count_type1,  #2
      (SELECT COUNT(*) FROM ach_batch_headers)  #2
                            AS record_count_type5,  #2
      (SELECT COUNT(*) FROM ach_entry_ppd_details)  #2
                                      AS record_count_type6,  #2
      (SELECT COUNT(*) FROM ach_addenda_ppd_records)  #2
                                      AS record_count_type7,  #2
      (SELECT COUNT(*) FROM ach_batch_control_records)  #2
                                      AS record_count_type8,  #2
      (SELECT COUNT(*) FROM ach_file_control_records)  #2
                                      AS record_count_type9  #2
   ) AS counts   #2</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">The selection logic can remain the same.</span>
<br/>#2 
     <span class="CharOverride-5">Note that the counts are now occurring on the parsed records and that the tables are specific to PPD batches.</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p91">
<p>Our goal was to ensure that we had enough tests to validate the files processed successfully. We should now be confident that the file has been processed in the database, that their unit tests may validate those database fields, and that the files were parsed correctly. Remember from chapter 2 that we should test not only the happy path (success) but also the not-so-happy path (error handling). For now, we have enough to move forward with a similar test for IAT processing. </p>
</div>
<div class="readable-text intended-text" id="p92">
<p>We can create a similar test for unparsed records that loads a file containing an IAT batch instead. We created one and named it (rather unimaginatively) iat.ach. The processing for an IAT file does not change when we consider only the unparsed records, and that is partially why we needed to test both the unparsed and parsed records. Of course, we still tested the unparsed records with a unit test, but the real work is for the IAT parsed records, as in the following listing.</p>
</div>
<div class="browsable-container listing-container" id="p93">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.13<span class="CharOverride-3"> </span>Unit test for parsed IAT records</h5>
<div class="code-area-container">
<pre class="code-area">SELECT #1
   record_count_type1, record_count_type5, record_count_type6,  #1
   record_count_type710, record_count_type711,  #1
   record_count_type712, record_count_type713,  #1
   record_count_type714, record_count_type715,   #1
   record_count_type716, record_count_type8,  #1
   record_count_type9, record_count_type1 +  #1
   record_count_type5 + record_count_type6 +  #1
   record_count_type710 + record_count_type711 +  #1
   record_count_type712 + record_count_type713 +  #1
   record_count_type714 + record_count_type715 +  #1
   record_count_type716 + record_count_type8 +   #1
                  record_count_type9 AS total_record_count  #1
FROM ( #2
   SELECT  #2
      (SELECT COUNT(*) FROM ach_file_headers)  #2
                                     AS record_count_type1,  #2
      (SELECT COUNT(*) FROM ach_iat_batch_headers)  #2
                                     AS record_count_type5,  #2
      (SELECT COUNT(*) FROM ach_iat_entry_details)  #2
                                     AS record_count_type6,  #2
      (SELECT COUNT(*) FROM ach_iat_addenda_710_records)  #2
                                     AS record_count_type710,  #2
      (SELECT COUNT(*) FROM ach_iat_addenda_711_records)  #2
                                     AS record_count_type711,  #2
      (SELECT COUNT(*) FROM ach_iat_addenda_712_records)  #2
                                     AS record_count_type712,  #2
      (SELECT COUNT(*) FROM ach_iat_addenda_713_records)  #2
                                     AS record_count_type713,  #2
      (SELECT COUNT(*) FROM ach_iat_addenda_714_records)  #2
                                     AS record_count_type714,  #2
      (SELECT COUNT(*) FROM ach_iat_addenda_715_records)  #2
                                     AS record_count_type715,  #2
      (SELECT COUNT(*) FROM ach_iat_addenda_716_records)  #2
                                     AS record_count_type716,  #2
      (SELECT COUNT(*) FROM ach_batch_control_records)  #2
                                     AS record_count_type8,  #2
      (SELECT COUNT(*) FROM ach_file_control_records)  #2
                                     AS record_count_type9  #2
) AS record_counts  #2</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">We select the desired records and sum them up to get the total count, which we also verified by pulling up the file (since it is just a text file) in any editor and reviewing the record counts.</span>
<br/>#2 
     <span class="CharOverride-5">We need to include the IAT addenda tables. Keep in mind the batch header, entry details, and addenda records will be different from PPD batches.</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p94">
<p>The previous test will fail because we have not yet updated the file parsing to make use of these detail tables. However, we are now confident that we have both PPD and IAT parsing covered by unit tests, which means we can move ahead to using these new IAT detail tables.</p>
</div>
<div class="readable-text" id="p95">
<h3 class="readable-text-h3"><span class="num-string">11.5.2</span> Updating file processing</h3>
</div>
<div class="readable-text" id="p96">
<p>With our passing PPD file load and the failing IAT file load, we begin working through the changes needed to support IAT. As we make changes, we will constantly be rerunning the unit tests to ensure that we are making progress with parsing IAT files and that we have not inadvertently broken anything. Since an ACH file is processed sequentially, the first record we need to address is the batch header record. We add a new field named <code>batch_type</code> that we will use when parsing the batch header. The following listing shows the simple <code>if</code>/<code>elif</code>/<code>else</code> processing that we have added, just calling the appropriate routine based on the SEC code and logging an exception when having a header we do not recognize.</p>
</div>
<div class="browsable-container listing-container" id="p97">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.14<span class="CharOverride-3"> </span>Calling the appropriate parsing routine</h5>
<div class="code-area-container code-area-with-html">
<pre class="code-area"><strong>if line[50:53] == "IAT":   </strong>#1
<strong>    self._parse_iat_batch_header(ach_record_id, line) </strong> #2
<strong>    self.batch_type = "IAT" </strong>
<strong>elif line[50:53] == "PPD": </strong>#2
    self._parse_batch_header(ach_record_id, line)  #3
<strong>    self.batch_type = "PPD" </strong> #3
<strong>else: </strong>#3
<strong>    self._add_exception( </strong> #4
<strong>        AchExceptionSchema( </strong> #4
<strong>            ach_files_id=ach_file_id, </strong> #4
<strong>            record_number=sequence_number, </strong> #4
<strong>            exception_code=AchExceptions.INVALID_BATCH_TYPE.value, </strong> #4
<strong>        ), </strong> #4
<strong>        line, </strong> #4
<strong>    ) </strong> #4</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">The SEC code is in the same position, regardless of whether the batch header is for IAT or PPD. This line sets the batch_type flag appropriately for the SEC type.</span>
<br/>#2 
     <span class="CharOverride-5">Previously, we just </span>
<span class="CharOverride-5">called the </span>
<span class="CharOverride-5">_parse_batch_header method. Now, we ensure that we are dealing </span>
<span class="CharOverride-5">with a PPD batch.</span>
<br/>#3 
     <span class="CharOverride-5">We would like to log an exception when processing, and we have an unrecognized SEC code. This could be because of an invalid formatted file or a code we do not support yet.</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p98">
<p>With the proper parsing of the batch header, we should be making it a bit farther in our testing of IAT processing, and of course, PPD processing should not be broken. The next record we encounter is the type 6 record. With the introduction of the <code>batch_type</code> variable, it should follow the same pattern. Notice that we continue to write the unparsed record to the database like before. However, the need to parse the record and write it to the appropriate table depends on the <code>batch_type</code> flag. The following listing shows the required updates.</p>
</div>
<div class="browsable-container listing-container" id="p99">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.15<span class="CharOverride-3"> </span>Parsing entry details</h5>
<div class="code-area-container">
<pre class="code-area">case "6": #1
    ach_record = AchRecordType6Schema(  #1
        ach_records_type_5_id=current_batch_header_id,  #1
        unparsed_record=line,  #1
        sequence_number=sequence_number,  #1
    )  #1
    ach_record_id = AchRecordsSqlType6()  #1
<span class="CharOverride-6">➥</span>.insert_record(ach_record)  #1
    if self.batch_type == "IAT": #2
        self._parse_iat_entry_detail(  #2
            ach_file_id=ach_file_id,  #2
            current_batch_header_id=current_batch_header_id,  #2
            ach_records_type_6_id=ach_record_id,  #2
            sequence_number=sequence_number,  #2
            line=line,  #2
        )  #2
    elif self.batch_type == "PPD": #3
        self._parse_entry_ppd_detail(  #3
            ach_file_id=ach_file_id,  #3
            current_batch_header_id=current_batch_header_id,  #3
            ach_records_type_6_id=ach_record_id,  #3
            sequence_number=sequence_number,  #3
            line=line,  #3
        )  #3
    else: #4
        self._add_exception( #4
            AchExceptionSchema( #4
                ach_files_id=ach_file_id,  #4
                record_number=sequence_number,  #4
                exception_code=AchExceptions.INVALID_SEC.value,  #4
            ),  #4
            line,  #4
        )  #4</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">The writing of our unparsed records is independent of the batch type we are working with.</span>
<br/>#2 
     <span class="CharOverride-5">When the batch_type is set to IAT, we will call the appropriate method to parse </span>
<span class="CharOverride-5">the entry.</span>
<br/>#3 
     <span class="CharOverride-5">The parameters </span>
<span class="CharOverride-5">for IAT and PPD parsing are exactly the same. Only the fields that need </span>
<span class="CharOverride-5">to be parsed are different. </span>
<br/>#4 
     <span class="CharOverride-5">Adds an exception when we encounter an unexpected batch_type</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p100">
<p>Parsing the addenda records is only slightly more complicated than parsing the batch header and entry detail records. This is because we now also deal with the different addenda record types being in the expected order. Similar to the <code>expected_record_type</code> variable, we also introduce an <code>expected_addenda_type</code> variable. Let’s jump straight to the method where we parse a specific addenda type record, as shown in the following listing. Here, it is standard processing with the addition of the new <code>expected_addenda_type</code>. The next record we expect is another addenda record (type 7), and it should be of addenda type 11.</p>
</div>
<div class="browsable-container listing-container" id="p101">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.16<span class="CharOverride-3"> </span>The <code>_parse_iat_addenda_710</code> method</h5>
<div class="code-area-container">
<pre class="code-area">def _parse_iat_addenda_710(self, ach_records_type_7_id: UUID, line: str):
     self.expected_record_types = ["7"] #1
     self.expected_addenda_type = "11" #2

     ach_iat_addenda_record = AchRecordProcessor().parse_iat_addenda_710(
         ach_records_type_7_id, line
     )
     AchIat710AddendaSql().insert_record(ach_iat_addenda_record)</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">The expected_record should be another addenda record.</span>
<br/>#2 
     <span class="CharOverride-5">The expected_addenda_type should be the next sequence as the records are required to be in a specific order. Note that we only expect one type of record, so there is no need for an array as with the expected_record_type.</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p102">
<p>All the addenda records will parse the same way, with the <code>expected_addenda_type</code> being set to the next record. But what happens when we get to the final addenda type (type 16)? The following listing shows how we reset our expected types once we reach that last record.</p>
</div>
<div class="browsable-container listing-container" id="p103">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.17<span class="CharOverride-3"> </span>Resetting the expected types</h5>
<div class="code-area-container">
<pre class="code-area">self.expected_record_types = ["6", "7", "8"] #1
self.expected_addenda_type = "" #2</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">There are some optional addenda records for IAT processing, so it is possible to encounter those, as well as a new entry or the end of the batch.</span>
<br/>#2 
     <span class="CharOverride-5">There are no more mandatory addenda records, so the expected_addenda_type can be set to an empty string.</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p104">
<p>Now that we know how to parse the addenda records, it should be easy to put together how these individual methods would be called—as they follow a similar approach to how we parse the record types. The process is shown in the following listing.</p>
</div>
<div class="browsable-container listing-container" id="p105">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.18<span class="CharOverride-3"> </span>Parsing the addenda records</h5>
<div class="code-area-container">
<pre class="code-area">   def _parse_iat_addenda( #1
        self, ach_records_type_7_id: UUID,  #1
        line: str, sequence_number  #1
    ): 
        addenda_type = line[1:3] #2

        if addenda_type != self.expected_addenda_type: #3
            self._add_exception( 
                AchExceptionSchema( 
                    ach_files_id=ach_records_type_7_id, 
                    record_number=sequence_number, 
                    exception_code= 
                       AchExceptions.UNEXPECTED_ADDENDA_TYPE.value, 
                ) 
            ) 
            Return 

        if addenda_type == "10": #4
            self._parse_iat_addenda_710(ach_records_type_7_id, line)  #5
…  #5
        elif addenda_type == "16":  #5
            self._parse_iat_addenda_716(ach_records_type_7_id, line)  #5
        else:  #5
            self._add_exception(  #5
                AchExceptionSchema(  #5
                    ach_files_id=ach_records_type_7_id,  #5
                    record_number=sequence_number,  #5
                    exception_code=  #5
                        AchExceptions.INVALID_IAT_ADDENDA_TYPE.value,  #5
                )  #5
            )  #5</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">Defines our method for parsing. This is an umbrella that will call the other methods to parse specific records.</span>
<br/>#2 
     <span class="CharOverride-5">Extracts the addenda type since we will be using it repeatedly</span>
<br/>#3 
     <span class="CharOverride-5">If the addenda type is not what we expected, we need to log an exception.</span>
<br/>#4 
     <span class="CharOverride-5">Depending on the addenda type we are working with, calls the appropriate method. It logs a different exception if we have an unexpected addenda type.</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p106">
<p>With that, we should be able to parse files containing both IAT and PPD batches. Having these extra tables for IAT batches will have an effect on some of our APIs. In the next section, we will take a brief look at exactly what is affected.</p>
</div>
<div class="readable-text" id="p107">
<h2 class="readable-text-h2"><span class="num-string">11.6</span> Effects on the dashboard</h2>
</div>
<div class="readable-text" id="p108">
<p>How does the addition of IAT processing affect the functionality of our dashboard? That question would likely require more discussion with the business. From an ACH standards perspective, it is certainly possible to have IAT batches in the same file as PPD batches. However, the fields and interesting information for an IAT batch may be different, and certainly, the introduction of new tables plays into how the components function. Whether it makes sense for our components to include all batches or just select batches may be a business decision with input from end-users. For now, let’s look at how we can fit the IAT batches into our current dashboard components.</p>
</div>
<div class="readable-text" id="p109">
<h3 class="readable-text-h3"><span class="num-string">11.6.1</span> The get_batches method</h3>
</div>
<div class="readable-text" id="p110">
<p>The <code>/{file_id}/batches</code> endpoint calls the <code>get_batches</code> method, which will need to be updated to incorporate the IAT batch headers. We know that the <code>ach_records_type_5_id</code> will exist in only one of the batch header tables. We employ that and the <code>COALESCE</code> command to use a field from the <code>ach_batch_headers</code> and if that is <code>NULL</code>, to use the <code>ach_iat_batch_headers</code> value instead. This works under the assumption that a field will not unexpectedly be <code>NULL</code>. The fields in question are all marked as <code>NOT NULL</code> in the database. Whether they stay that way indefinitely is another matter. For the time being, the following listing shows how we can update our query without being too invasive to the current API.</p>
</div>
<div class="browsable-container listing-container" id="p111">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.19<span class="CharOverride-3"> </span>Updated <code>get_batches</code></h5>
<div class="code-area-container">
<pre class="code-area">SELECT COALESCE(abh.company_name, '') AS company_name, #1
       COALESCE(abh.company_identification,       #2
       aibh.originating_dfi_identification) AS company_id,
       art5.ach_records_type_5_id AS id,
       COALESCE(abh.batch_number, aibh.batch_number) #3
                                           AS batch_number, 
       abcd.total_debit_entry_dollar_amount AS debit_total,
       abcd.total_credit_entry_dollar_amount AS credit_total, 
       abcd.entry_addenda_count 
  FROM ach_files AS af
…
LEFT JOIN ach_batch_headers AS abh #4
                USING (ach_records_type_5_id)  #4
LEFT JOIN ach_iat_batch_headers AS aibh  #4
                USING (ach_records_type_5_id)  #4
    WHERE af.ach_files_id = %s
 ORDER BY COALESCE(abh.originating_dfi_identification,  #5
                   aibh.originating_dfi_identification); </pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">We do not have access to a company name for IAT from the header record.</span>
<br/>#2 
     <span class="CharOverride-5">If the company_identification is not available, uses the originating_dfi_identification</span>
<br/>#3 
     <span class="CharOverride-5">Picks the appropriate </span>
<span class="CharOverride-5">batch_number from the batch</span>
<br/>#4 
     <span class="CharOverride-5">Uses LEFT JOIN because the batch header is for one table or the other</span>
<br/>#5 
     <span class="CharOverride-5">Sorts by the appropriate identification number</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p112">
<p>As shown here, we can sometimes get away with updating the existing query; however, that is not the case in all situations. In fact, it is probably an exception. The next section discusses what to do when the query is too large or complicated to incorporate both PPD and IAT.</p>
</div>
<div class="readable-text" id="p113">
<h3 class="readable-text-h3"><span class="num-string">11.6.2</span> Batch entries</h3>
</div>
<div class="readable-text" id="p114">
<p>Gathering the batch entries from the endpoint <code>/{file_id}/batches/{batch_id}/entries</code> requires some work. The query to build the <code>AchBatchEntriesResponse</code> was sizeable, and it may make more sense to leave the current query in place and create a new query specific to IAT transaction entries. Therefore, we will take the <code>get_entries</code> method, move the existing query to a method <code>_get_ppd_entries</code>, and create a new <code>_get_iat_entries</code>. The results of the split are shown in the following listing.</p>
</div>
<div class="browsable-container listing-container" id="p115">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.20<span class="CharOverride-3"> </span>Updated <code>get_entries</code></h5>
<div class="code-area-container">
<pre class="code-area">@staticmethod
def get_entries(
    ach_file_id: UUID, ach_batch_id: UUID
    ) -&gt; list[AchBatchEntriesResponse]:
    if AchFileSql._is_iat_batch(ach_file_id, ach_batch_id): #1
        return AchFileSql._get_iat_entries #2
<span class="CharOverride-6">➥</span>(ach_file_id, ach_batch_id) 
    else:
        return AchFileSql._get_ppd_entries(ach_file_id, #3
                                           ach_batch_id) </pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">Method to determine whether the specified batch in the file is an IAT batch</span>
<br/>#2 
     <span class="CharOverride-5">Method to return the IAT entries for a given file and batch</span>
<br/>#3 
     <span class="CharOverride-5">The previous SQL query has been moved to its own method.</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p116">
<p>There are some slight changes when creating the <code>AchBatchEntriesResponse</code> for IAT records. With the original query for PPD records to get the addenda count, we had to gather that information ourselves. With an IAT batch, that information is part of the entry record; however, we still gather the count in the same fashion, in part to keep the queries similar, but more importantly, because we may want to perform verification on the field in the future, and this approach provides the mechanism to do that (listing 11.21).</p>
</div>
<div class="browsable-container listing-container" id="p117">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.21<span class="CharOverride-3"> </span>Query from <code>_get_iat_entries</code></h5>
<div class="code-area-container">
<pre class="code-area">WITH addenda_records_for_entry AS (
   SELECT art6.ach_records_type_6_id,
   COUNT(art7.*) AS addenda_count #1
   FROM ach_files AS af
…
   LEFT JOIN ach_records_type_7 AS art7 USING (ach_records_type_6_id)
   WHERE af.ach_files_id = %s
      AND art5.ach_records_type_5_id = %s
      GROUP BY (art6.ach_records_type_6_id)
)
SELECT art6.ach_records_type_6_id AS id,
       aied.transaction_code,
…
       aia10d.receiving_name AS individual_name, #2
       aied.amount, #3
       CONCAT(
          '*************',
          RIGHT(LPAD#D
<span class="CharOverride-6">➥</span>(aied.foreign_receivers_account_number, 4, '0'), 4) #4
       ) AS account_number_last_4,
       arfe.addenda_count
…
      INNER JOIN ach_iat_entry_details AS aied  #5
                  USING (ach_records_type_6_id)  #5
      INNER JOIN addenda_records_for_entry AS arfe  #5
                  USING (ach_records_type_6_id)  #5
      INNER JOIN ach_iat_addenda_10_details AS aia10d   #5
                  USING (ach_records_type_7_id)  #5
…</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">We get the number of addenda records, which is also available on the record type 6 for IAT transactions. Eventually, we could use this approach to validate the addenda count that was passed.</span>
<br/>#2 
     <span class="CharOverride-5">We pass the receiving_name back as the individual_name to conform to our response, which needs to be retrieved from the addenda type 10 record.</span>
<br/>#3 
     <span class="CharOverride-5">Pulls the amount from the IAT entry record</span>
<br/>#4 
     <span class="CharOverride-5">The entry record </span>
<span class="CharOverride-5">also has the account number.</span>
<br/>#5 
     <span class="CharOverride-5">Joins the necessary </span>
<span class="CharOverride-5">IAT tables</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p118">
<p>Whether we incorporate IAT into the current dashboard or create brand new components is going to be a matter or preference by the business and users. One aspect that is not up for negotiation is remaining compliant with government regulations. The next section discusses how to address some regulatory concerns.</p>
</div>
<div class="readable-text" id="p119">
<h2 class="readable-text-h2"><span class="num-string">11.7</span> OFAC scanning</h2>
</div>
<div class="readable-text" id="p120">
<p>Financial institutions are subject to various regulations and compliance on a daily basis. Regulations such as the PATRIOT Act and Know Your Customer (KYC) hold the financial institution responsible for failing to report potential money laundering and terrorist-financing activities. The Office of Foreign Asset Control (OFAC) provides a “Specially Designated Nationals” list, or a SDN list, that includes individuals, companies, and assets such as ships/planes that are prohibited to do business with, and institutions may face penalties.</p>
</div>
<div class="readable-text intended-text" id="p121">
<p>Note that there are other lists, as well as countries in general, that institutions are prohibited from doing business with. Doing business with any of these sanctioned entities can cost the bank significantly. A list of entities that violated US regulations and their associated fines is available at <a href="https://mng.bz/pKN8"><span class="Hyperlink">https:</span><span class="Hyperlink">/</span><span class="Hyperlink">/mng.bz/pKN8</span></a>. </p>
</div>
<div class="readable-text intended-text" id="p122">
<p>While there are third-party packages that specialize in this type of scanning, over the next few sections, we implement basic scanning for our dashboard to get a feel for the process. If you are interested in ML/AI and analytics, this is a great opportunity to dive in and build some comprehensive detection!</p>
</div>
<div class="readable-text" id="p123">
<h3 class="readable-text-h3"><span class="num-string">11.7.1</span> Sanctioned individuals and countries</h3>
</div>
<div class="readable-text" id="p124">
<p>There are XML files available for download from the OFAC website at <a href="https://sanctionslist.ofac.treas.gov/Home/SdnList"><span class="Hyperlink">https:</span><span class="Hyperlink">/</span><span class="Hyperlink">/sanctionslist.ofac.treas.gov/Home/SdnList</span></a> and an online search tool as well at <a href="https://sanctionssearch.ofac.treas.gov/"><span class="Hyperlink">https:</span><span class="Hyperlink">/</span><span class="Hyperlink">/sanctionssearch.ofac.treas.gov/</span></a>. Either of these is a great way to start familiarizing ourselves with the information available when working with sanctioned individuals.</p>
</div>
<div class="readable-text intended-text" id="p125">
<p>For our purposes, we create a table that contains names and aliases for made-up individuals to avoid any potential problems with using actual data from the list. We also create a list of made-up countries we should also scan for. As we saw from the civil penalties, many times, companies find themselves in trouble just by doing business with companies/individuals in other countries. Listing 11.22 shows the <code>create</code> statements for tables to hold individual names as well as countries.</p>
</div>
<div class="browsable-container listing-container" id="p126">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.22<span class="CharOverride-3"> </span>Creating tables for OFAC scanning</h5>
<div class="code-area-container">
<pre class="code-area">CREATE TABLE sdn_list
(
    sdn_id          UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    first_name      VARCHAR(255) NOT NULL,
    middle_name     VARCHAR(255) DEFAULT NULL,
    last_name       VARCHAR(255) NOT NULL,
    alias           VARCHAR(255) DEFAULT NULL,
    created_at      TIMESTAMP    NOT NULL DEFAULT NOW(),
    updated_at      TIMESTAMP    NOT NULL DEFAULT NOW()
);

CREATE TABLE sanctioned_countries
(
    sanctioned_country_id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    country_name          VARCHAR(255) NOT NULL,
    country_code          VARCHAR(2)   NOT NULL,
    created_at            TIMESTAMP    NOT NULL DEFAULT NOW(),
    updated_at            TIMESTAMP    NOT NULL DEFAULT NOW()
);</pre>
</div>
</div>
<div class="readable-text" id="p127">
<p>Next, we populate the tables when the database is created, as shown in the following listing. Do not forget to add the <code>sdn_list</code> and <code>sanctioned_countries</code> tables to the <code>truncate_all</code> utilities method as you do not want this default data cleared during unit testing.</p>
</div>
<div class="browsable-container listing-container" id="p128">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.23<span class="CharOverride-3"> </span>Populating the new tables</h5>
<div class="code-area-container">
<pre class="code-area">INSERT INTO 
sdn_list(first_name, middle_name, last_name, alias) 
VALUES ('Cash', DEFAULT, 'Steeler', 'Heister');
INSERT INTO 
sdn_list(first_name, middle_name, last_name, alias) 
VALUES ('Penny', DEFAULT, 'Pincher', 'Embezzler');
INSERT INTO 
sdn_list(first_name, middle_name, last_name, alias) 
VALUES ('Ben', 'E', 'Factor', '');
INSERT INTO 
sdn_list(first_name, middle_name, last_name, alias) 
VALUES ('Lou', DEFAULT, 'Pole', 'Evader');
INSERT INTO 
sdn_list(first_name, middle_name, last_name, alias) 
VALUES ('Mallory', DEFAULT, 'Practice', 'Biller');

INSERT INTO 
sanctioned_countries(country_name, country_code) 
VALUES ('Bribeland', 'BL');
INSERT INTO 
sanctioned_countries(country_name, country_code) 
VALUES ('Scamistan', 'SC');
INSERT INTO 
sanctioned_countries(country_name, country_code) 
VALUES ('Embezzlvania', 'EV');
INSERT INTO 
sanctioned_countries(country_name, country_code) 
VALUES ('Swindleland', 'SW');
INSERT INTO 
sanctioned_countries(country_name, country_code) 
VALUES ('Greedonia', 'GD');</pre>
</div>
</div>
<div class="readable-text" id="p129">
<p>With our data populated, we can now move on to building the API for scanning.</p>
</div>
<div class="readable-text" id="p130">
<h3 class="readable-text-h3"><span class="num-string">11.7.2</span> Scanning for individuals</h3>
</div>
<div class="readable-text" id="p131">
<p>Before we build an API, let’s define the query that will return the results for the OFAC scan. For our needs, we will be scanning all our loaded files whenever someone clicks on the OFAC Scanning link in our UI. However, this feature will not be practical later when we have larger lists of suspects, more complex scanning algorithms, and more files loaded. We are going to discuss some strategies to handle this problem, but for now, let’s break down the query we used to gather the results.</p>
</div>
<div class="readable-text intended-text" id="p132">
<p>As you know, the goal is to search for individual names on incoming ACH trans­actions and match them against known individuals on the lists provided by OFAC. Up until this point, when searching, we have used SQL keywords such as <code>ILIKE</code> and the <code>%</code> wildcard. Now, we get a little more advanced by introducing fuzzy matching to our query. By installing the <code>fuzzystrmatch</code> into our Postgres database, as in the following listing, we get additional search options.</p>
</div>
<div class="browsable-container listing-container" id="p133">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.24<span class="CharOverride-3"> </span>Installing <code>fuzzystrmatch</code></h5>
<div class="code-area-container">
<pre class="code-area">CREATE EXTENSION IF NOT EXISTS "fuzzystrmatch";</pre>
</div>
</div>
<div class="readable-text" id="p134">
<p>This extension provides phonetic matching algorithms such as Soundex and Meta­phone, as well as the Levenshtein distance algorithm, for measuring the similarity between two strings. These algorithms can help us create a more robust searching algorithm because, rather than searching for an exact or partial match, we can now expand our search to names that may by misspelt or slightly altered by a nefarious individual so that they can still perform transactions. Even though we are introducing feature for IAT transactions, it can be incorporated into any transactions done at a financial institution. Often, this (and various other checks) are done when a customer opens an account, and the database is often periodically scanned for any individuals. Therefore, we start with creating a common table expression (CTE) to gather names for PPD transactions. The main problem is to ensure we are collecting the names from the appropriate record, with ACH PPD transactions that will be on the type 6 record. </p>
</div>
<div class="readable-text intended-text" id="p135">
<p>In the following listing, we want to only select distinct names to minimize some of the searching across batches if we have multiple names. We may want to consider additional information in case we have a false positive in regard to one customer but not another. We also used <code>REPLACE</code> to remove any spaces from the name, but could also use <code>REGEXP_REPLACE(aepd.individual_name,</code> <code>'[^a-zA-Z0-9]',</code> <code>'',</code> <code>'g')</code> if we wanted to deal with any punctuation.</p>
</div>
<div class="browsable-container listing-container" id="p136">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.25<span class="CharOverride-3"> </span>Collecting individual names from PPD transactions</h5>
<div class="code-area-container">
<pre class="code-area">WITH ach_ppd_collected_names AS (
    SELECT DISTINCT aped.individual_name, #1
           REPLACE(aped.individual_name, ' ', '')  #2
                            AS cleaned_individual_name, 
                    art1.ach_files_id, #3
                    art5.ach_records_type_5_id 
    FROM ach_files #4
    INNER JOIN ach_records_type_1 AS art1 
                     USING (ach_files_id) 
    INNER JOIN ach_records_type_5 AS art5  
                                 USING (ach_records_type_1_id) 
    INNER JOIN ach_records_type_6 AS art6  
                                 USING (ach_records_type_5_id) 
    INNER JOIN ach_ppd_entry_details AS aped  
                                 USING (ach_records_type_6_id) 
    GROUP BY art1.ach_files_id, art5.ach_records_type_5_id, #5
                      individual_name, cleaned_individual_name 
),</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">Use SELECT DISTINCT because </span>
<span class="CharOverride-5">we do not want duplicate </span>
<span class="CharOverride-5">searches; one name will suffice.</span>
<br/>#2 
     <span class="CharOverride-5">Simple replacement to remove spaces, but nothing else. Use REGEXP_REPLACE for more complicated removal.</span>
<br/>#3 
     <span class="CharOverride-5">The record to find the particular transaction</span>
<br/>#4 
     <span class="CharOverride-5">Necessary JOINs to get down to the individual name</span>
<br/>#5 
     <span class="CharOverride-5">Necessary GROUP BY statements because of the SELECT DISTINCT statement</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p137">
<p>A similar CTE is required for IAT names, as shown in the following listing. As for some of our other IAT processing, we need to retrieve the name from the addenda record instead of the entry record. We return the <code>receiving_name</code> as the individual name to maintain alignment between the CTEs.</p>
</div>
<div class="browsable-container listing-container" id="p138">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.26<span class="CharOverride-3"> </span>Collecting individual names from IAT transactions</h5>
<div class="code-area-container">
<pre class="code-area">ach_iat_collected_names AS (
    SELECT DISTINCT aia10d.receiving_name #1
                                        AS individual_name, 
                    REPLACE(aia10d.receiving_name, ' ', '') #2
                           AS cleaned_individual_name, 
                    art1.ach_files_id, #3
                    art5.ach_records_type_5_id 
    FROM ach_files #4
    INNER JOIN ach_records_type_1 AS art1  #4
               USING (ach_files_id)  #4
    INNER JOIN ach_records_type_5 AS art5  #4
               USING (ach_records_type_1_id)  #4
    INNER JOIN ach_records_type_6 AS art6  #4
               USING (ach_records_type_5_id)  #4
    INNER JOIN ach_records_type_7 AS art7  #4
               USING (ach_records_type_6_id)  #4
    INNER JOIN ach_iat_addenda_10_details AS aia10d   #4
                                          USING (ach_records_type_7_id)  #4
    GROUP BY art1.ach_files_id, art5.ach_records_type_5_id, #5
             individual_name, cleaned_individual_name 
)</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">At this time, we do not want duplicate searches because one name will suffice. We need to rename the field to individual_name or find a common name for the field.</span>
<br/>#2 
     <span class="CharOverride-5">Simple replacement to remove spaces, but nothing else. Use REGEXP_REPLACE for more complicated removal.</span>
<br/>#3 
     <span class="CharOverride-5">The record to find the particular transaction</span>
<br/>#4 
     <span class="CharOverride-5">Necessary JOINs to get down to the individual name</span>
<br/>#5 
     <span class="CharOverride-5">Necessary GROUP BY statements because of the SELECT DISTINCT statement</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p139">
<p>The next CTE is used to collect the names of our suspects (listing 11.27). For display purposes, we handle concatenating the name together, keeping in mind the possibility of the <code>middle_name</code> being <code>NULL</code> with <code>CONCAT_WS</code>. Otherwise, using a standard <code>CONCAT</code> function will result in two blank spaces between the first and last names. Of course, there are ways to handle this situation if the RDMS we are using does not have a function such as <code>CONCAT_WS</code>.</p>
</div>
<div class="browsable-container listing-container" id="p140">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.27<span class="CharOverride-3"> </span>Collecting the SDN names</h5>
<div class="code-area-container">
<pre class="code-area">sdn_names AS (
    SELECT
        CONCAT_WS(' ', first_name, middle_name, last_name) #1
                                              AS sdn_name  
        REPLACE(
           CONCAT(first_name, middle_name, last_name), ' ', '')  #2
                                               AS cleaned_sdn_name, 
        alias, #3
        REPLACE(alias, ' ', '') as cleaned_sdn_alias 
    FROM sdn_list
)</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">The CONCAT_WS will skip NULL fields. It works </span>
<span class="CharOverride-5">perfectly for combining the first, middle, and last </span>
<span class="CharOverride-5">names into something we can use for display.</span>
<br/>#2 
     <span class="CharOverride-5">Concatenates the names and removes any spaces</span>
<br/>#3 
     <span class="CharOverride-5">A similar approach </span>
<span class="CharOverride-5">for the alias</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p141">
<p>With the names of our customers and suspects gathered, we can now start comparing them. The first method we use is the function <code>LEVENSHTEIN</code> to compute the distance, which considers the number of additions, deletions, and updates needed to convert one string into another. We convert string into a number between 0 and 100, where 0 is no match and 100 is an exact match.</p>
</div>
<div class="readable-text intended-text" id="p142">
<p>The other method is the <code>DAITCH_MOKOTOFF</code> function, used in listing 11.28. This function allows phonetic matching of names, attempting to determine if names sound alike. There are some additional algorithms available in the <code>fuzzystrmatch</code> module. In addition, there are other commercial searching algorithms. In a production environment, we would need additional pieces of information such as the alias, address, and similar to reduce the number of false positives that we may create by simply finding a phonetic match. However, using these methods is a good starting point.</p>
</div>
<div class="browsable-container listing-container" id="p143">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.28<span class="CharOverride-3"> </span>Computing similarity scores for IAT individuals</h5>
<div class="code-area-container">
<pre class="code-area">computed_similarity_iat AS (
    SELECT
        ach_files_id, 
        ach_records_type_5_id AS ach_batch_id, 
        sdn.sdn_name,
        aicn.individual_name,
        alias,
        (1 - (LEVENSHTEIN(cleaned_individual_name, #1
sdn.cleaned_sdn_name)::FLOAT  #1
/ GREATEST(LENGTH(cleaned_individual_name),  #1
LENGTH(sdn.cleaned_sdn_name)))) * 100  #1
AS similarity_score,  #1
        CASE #2
           WHEN DAITCH_MOKOTOFF(cleaned_individual_name) &amp;&amp;  
               DAITCH_MOKOTOFF(sdn.cleaned_sdn_name) THEN TRUE 
           ELSE FALSE 
        END AS daitch_mokotoff_match_name,
        CASE
           WHEN daitch_mokotoff(cleaned_individual_name) &amp;&amp;
               DAITCH_MOKOTOFF (sdn.cleaned_sdn_alias) THEN TRUE
           ELSE FALSE
        END AS daitch_mokotoff_match_alias
    FROM ach_iat_collected_names aicn
    CROSS JOIN sdn_names sdn #3</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">Converts the value returned by the LEVENSHTEIN function into a percentage that is easier to understand for end-users</span>
<br/>#2 
     <span class="CharOverride-5">Returns whether the </span>
<span class="CharOverride-5">names matched using the </span>
<span class="CharOverride-5">DAITCH_MOKOTOFF algorithm</span>
<br/>#3 
     <span class="CharOverride-5">We use CROSS JOIN so that every name is compared.</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p144">
<p>We select all results returned from both queries, as shown in the following listing.</p>
</div>
<div class="browsable-container listing-container" id="p145">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.29<span class="CharOverride-3"> </span>Combining the results</h5>
<div class="code-area-container">
<pre class="code-area">computed_similarity AS (
    SELECT * FROM computed_similarity_ppd #1
    UNION ALL              #1
    SELECT * FROM computed_similarity_iat  #1
)</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">Pulls together all our computed scoring and matches</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p146">
<p>Finally, we filter the results as shown in the following listing, adding a unique row number for each row being returned to act as an identifier. There are many ways in which to optimize this and increase the performance of the queries. However, the clarity of gathering the names, comparing them, combining, and then filtering makes the process easier to follow in this example. We will discuss some strategies for actually producing this report when we discuss presenting of the OFAC results.</p>
</div>
<div class="browsable-container listing-container" id="p147">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.30<span class="CharOverride-3"> </span>Filtering the results</h5>
<div class="code-area-container">
<pre class="code-area">SELECT ROW_NUMBER() #1
   OVER (ORDER BY ach_files_id, ach_batch_id) AS id, *  #1
FROM computed_similarity  #1
WHERE similarity_score &gt;= 80 #2
   OR daitch_mokotoff_match_name = TRUE  #3
    OR daitch_mokotoff_match_alias = TRUE  #3
ORDER BY similarity_score DESC</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">Use the ROW_NUMBER function to generate a unique id for the row.</span>
<br/>#2 
     <span class="CharOverride-5">Filters the results, returning only matches of a certain threshold </span>
<span class="CharOverride-5">or the ones that phonetically match the name or alias</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p148">
<p>We now have a good idea of what we will be returning based on the results we see when working with this query. We create a way for users to access these results in the next section.</p>
</div>
<div class="readable-text" id="p149">
<h2 class="readable-text-h2"><span class="num-string">11.8</span> Application programming interface</h2>
</div>
<div class="readable-text" id="p150">
<p>We now have two essential pieces: the data that exists in the database and a way to produce desired results. We continue to follow the well-established pattern for creating an API, starting with a unit test and working on the necessary pieces to ensure it passes.</p>
</div>
<div class="readable-text" id="p151">
<h3 class="readable-text-h3"><span class="num-string">11.8.1</span> Unit test</h3>
</div>
<div class="readable-text" id="p152">
<p>The unit test in the following listing loads one of our previously created files. Here we are concentrating on loading the data from a file called ofac_elemental_resources.ach and validating our API. Having previously created and loaded the database with the same file using the dashboard (or another unit test), we already know that our query should return three matches. So, the unit test simply needs to ensure the database is clean, load the file, and grab the results.</p>
</div>
<div class="browsable-container listing-container" id="p153">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.31<span class="CharOverride-3"> </span>Unit test for OFAC API</h5>
<div class="code-area-container">
<pre class="code-area">class TestOfacApi:
    client: TestClient = TestClient(app)
    ach_files_id: Optional[str] = None

    # Get the directory of our file
    current_file_dir = Path(__file__).resolve().parent

    @pytest.fixture(autouse=True) #1
    def mock_client_host(self):  #1
        with patch(  #1
            "fastapi.Request.client",  #1
            new_callable=lambda: type("Client", (),  #1
                             {"host": "127.0.0.1"}),  #1
        ):  #1
            Yield  #1

    def get_absolute_path(self, relative_path): #2
        return self.current_file_dir / relative_path 

    def setup_method(self, _method: Callable) -&gt; None: #3
        ach_file = "ofac_elemental_resources.ach"  #3
        absolute_path = self.get_absolute_path(  #3
            Path("../data/ofac_elemental_resources.ach")  #3
        )  #3
        SqlUtils.truncate_all()  #3
        self.ach_files_id = SqlUtils.create_ach_file_record(  #3
            ach_file, str(randint(1, 99999999))  #3
        )  #3
        AchFileProcessor().parse  #3
<span class="CharOverride-6">➥</span>(self.ach_files_id, absolute_path)  #3

    def test_get_ofac_api_for_ppd_batches(self): #4
        <span>response = self.client.get("/api/v1/files/ofac") </span> #5
<span>        assert response.status_code == 200, response.text </span> #5
<span>        </span>assert len(response.json()) == 3,  #5
<span class="CharOverride-6">➥</span> "Should have 3 matches"  #5</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">Ensures a host and IP address are passed with the client as our logging requires that</span>
<br/>#2 
     <span class="CharOverride-5">Ensures that we are picking the correct file</span>
<br/>#3 
     <span class="CharOverride-5">Prior to making our API call, we need to clear the database and load the file.</span>
<br/>#4 
     <span class="CharOverride-5">Once we have the database set up and the client ready to make a request, we can pull the OFAC results from the API and ensure they are correct. We are only doing a quick check of the number of items returned, but want to dive deeper into the results to ensure the expected data is returned.</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p154">
<p>Having the unit test defined allows us to continually check that our code returns the desired results. Let’s make sure that happens!</p>
</div>
<div class="readable-text" id="p155">
<h3 class="readable-text-h3"><span class="num-string">11.8.2</span> Creating the endpoint</h3>
</div>
<div class="readable-text" id="p156">
<p>We first want to create the endpoint for the test (listing 11.32). We want to define the path users will be accessing. This endpoint was defined within the fiels.py router definition, which prefixes everything with <code>/api/v1/files</code>, so the path parameter only shows <code>/ofac</code>. Otherwise, we are simply returning an empty list, which should be enough to ensure that our unit test passes the first assert with a <code>200</code>-response code.</p>
</div>
<div class="browsable-container listing-container" id="p157">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.32<span class="CharOverride-3"> </span>Barebones endpoint</h5>
<div class="code-area-container">
<pre class="code-area">@router.get( #1
    path="/ofac",  #1
)  #1
@log_message("Performed OFAC Scan on loaded ACH files") 
async def read_files(request: Request): #2
    return [] </pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">Defines the path and a log message</span>
<br/>#2 
     <span class="CharOverride-5">Simply returns an empty list to ensure we receive a 200-response code and are able to pass the first assert statement in our unit test</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p158">
<p>After we have the barebones endpoint working, we can fill in the blanks with a return type and call an actual method to send back the results, as shown in the following listing. </p>
</div>
<div class="browsable-container listing-container" id="p159">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.33<span class="CharOverride-3"> </span>Updated endpoint</h5>
<div class="code-area-container">
<pre class="code-area">@router.get( #1
    path="/ofac",  #1
    response_model=list[OfacScanResults],  #1
    summary="Scan for OFAC issues in loaded ACH Files",  #1
    description=  #1
<span class="CharOverride-6">➥</span>"Perform an OFAC scan and return the results",  #1
    response_description="Results of OFAC scan.",  #1
    tags=["OFAC"],  #1
)  #1
@log_message("Performed OFAC Scan on loaded ACH files")  #1
async def read_files(request: Request) #2
<span class="CharOverride-6">➥</span> -&gt; list[OfacScanResults]:  #2
    return OfacSql().get_scan_results() </pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">Our API is documented and ready for users from one of our documentation endpoints.</span>
<br/>#2 
     <span class="CharOverride-5">We have defined the type of data we intend to return and a method to create it.</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p160">
<p>The endpoint will no longer work because of the newly added objects of <span class="_Code-Char">O</span><code>facScan­Results</code> and <code>OfacSql</code>, which we will define next.</p>
</div>
<div class="readable-text" id="p161">
<h3 class="readable-text-h3"><span class="num-string">11.8.3</span> Finishing the API</h3>
</div>
<div class="readable-text" id="p162">
<p>With the API and the SQL to power it already defined, we only need to complete two housekeeping steps to finish the API and have a passing unit test. First, we want to define the <code>OfacScanResults</code>, as shown in the following listing. This is the natural progression from the data returned in our <code>SQL</code> query to its Pydantic equivalent.</p>
</div>
<div class="browsable-container listing-container" id="p163">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.34<span class="CharOverride-3"> </span>The <code>OfacScanResults</code> source</h5>
<div class="code-area-container">
<pre class="code-area">class OfacScanResults(BaseModel):
    id: int = Field(title="ID", description="The ID of the result")
    ach_files_id: UUID4 = Field(title="ACH Files ID",   #1
                           description="The ACH Files ID")  #2
    ach_batch_id: UUID4 = Field(title="ACH Batch ID",   #2
                           description="The ACH Batch ID") 
    sdn_name: str = Field(title="SDN Name",  #2
<span class="CharOverride-6">➥</span> description="The SDN Name")  #2
    individual_name: str = Field(  #2
        title="Individual Name",   #2
<span class="CharOverride-6">➥</span>description="The Individual Name"  #2
    )  #2
    alias: str = Field(title="Alias",   #2
                      description="The Alias from the SDN List")  #2
    similarity_score: Decimal = Field( #3
        title="Similarity Score",   #4
                      description="The Similarity Score"  #4
    ) #C
    daitch_mokotoff_match_name: bool = Field(  #4
        title="Daitch Mokotoff Match Name",   #4
        description="Daitch Mokotoff Match Name"  #4
    )  #4
    daitch_mokotoff_match_alias: bool = Field(  #4
        title="Daitch Mokotoff Match Alias",   #4
        description="Daitch Mokotoff Match Alias"  #4
    )  #4</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">With these fields, users can jump directly to the file or batch that contained the match for further research.</span>
<br/>#2 
     <span class="CharOverride-5">The name/alias of the suspect and the name it matched from the ACH file</span>
<br/>#3 
     <span class="CharOverride-5">The numeric score that was computed. For now, it is the Levenshtein score but could potentially reflect a score computed from a more complicated algorithm.</span>
<br/>#4 
     <span class="CharOverride-5">These Boolean values are intended to show a check mark or some other indicator that the record was matched by this method as well.</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p164">
<p>With a place to store the results of our query, all that is needed is to create the <code>OfacSql</code> class and the associated <code>get_scan_results</code> method (listing 11.35). This will execute the SQL we created earlier, so this should be straightforward.</p>
</div>
<div class="browsable-container listing-container" id="p165">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.35<span class="CharOverride-3"> </span>The <code>OfacSql</code> class</h5>
<div class="code-area-container">
<pre class="code-area">class OfacSql:
    def get_scan_results(self) -&gt; list[OfacScanResults]:
        with get_db_connection(row_factory=class_row(OfacScanResults)) 
                                                               as conn:
            result = conn.execute(
                """
…   #1
                """,
                [],
            ).fetchall()#2

        return result #3</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">The SQL query we designed previously</span>
<br/>#2 
     <span class="CharOverride-5">Gets all the results from the query</span>
<br/>#3 
     <span class="CharOverride-5">Returns the results</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p166">
<p>At this point, the API should is functional, and we should have a passing unit test. We should also circle back and update our unit test to ensure that we are diving into the results and validating some of the fields as we were originally checking the size of an array. In theory, any endpoint that returned three items would pass that test. Next, we look at the final piece of the puzzle—presenting of our results.</p>
</div>
<div class="readable-text" id="p167">
<h2 class="readable-text-h2"><span class="num-string">11.9</span> User interface</h2>
</div>
<div class="readable-text" id="p168">
<p>With the data and the ability to retrieve it in place, the final step is to present the information to the user. Staying with our general approach, we create a page responsible for making an API call, the outcome of which is passed down to a component that will display formatted results. Figure 11.6 shows the result of pulling a sample report. The report provides the name of the suspect, their alias, and the customer’s name. We also include the score (how close of a match) and whether the system matched the name or alias. There are also options to find the file or the batch that include the suspected customer.</p>
</div>
<div class="browsable-container figure-container" id="p169">
<img alt="A screenshot of a computer  Description automatically generated" height="398" src="../Images/CH11_F06_Kardell.png" style="width: 100%; max-width: max-content;" width="835"/>
<h5 class="figure-container-h5"><span class="">Figure 11.6</span><span class=""> </span><span class="">Sample OFAC report screen</span></h5>
</div>
<div class="readable-text" id="p170">
<h3 class="readable-text-h3"><span class="num-string">11.9.1</span> The OFAC page</h3>
</div>
<div class="readable-text" id="p171">
<p>As shown in the following listing, we start by creating the main page and retrieving the data from the API. We could start by creating a placeholder page like in previous sections and ensuring that we can navigate to it before we try to populate the data. In this instance, since we have used similar approaches for exceptions (chapter 9) and company information (chapter 10), we jump right to building the page. The IDE should complain because we do not have an <code>OfacResponse</code> or <code>OfacRecords</code> component, but we will tackle those next.</p>
</div>
<div class="browsable-container listing-container" id="p172">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.36<span class="CharOverride-3"> </span>Sample page and API call</h5>
<div class="code-area-container">
<pre class="code-area">export default function OfacPage() {

    const [entries, setEntries] = useState&lt;OfacResponse[]&gt;([]);

    useEffect(() =&gt; {
        const apiUrl = process.env.NEXT_PUBLIC_API_URL ?? ''; #1
        axios.get&lt;OfacResponse[]&gt;(`${apiUrl}/files/ofac`, {  #1
            headers: {  #1
                'Content-Type': 'application/json'  #1
            }  #1
        }) #1
            .then(response =&gt; {  #1
                setEntries(response.data);  #1
            })  #1
…
    return ( #2
…  #2
                    &lt;OfacRecords records={entries}/&gt;  #2
…  #2
    );  #2</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">Uses axios to make the API request for an OFAC scan</span>
<br/>#2 
     <span class="CharOverride-5">Passes the results to our component to display them nicely for the user</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p173">
<p>As mentioned, this has become somewhat of a boilerplate process. Depending on the task at hand and how many pages need to be created, we may sometimes create those placeholders just to get a feel for the navigation and flow. Or we may choose to add pages as we begin working. We should be flexible in our approach.</p>
</div>
<div class="readable-text" id="p174">
<h3 class="readable-text-h3"><span class="num-string">11.9.2</span> OFAC components</h3>
</div>
<div class="readable-text" id="p175">
<p>We must create the <code>OfacResponse</code> to hold the API results. As we have worked with generative AI, we found that it can really help improve our productivity by generating some of this boilerplate code. We may use it to generate a Pydantic definition from a SQL <code>CREATE</code> <code>TABLE</code> statement. Then, we generate the TypeScript interface from the Pydantic class, which usually does a good job of capturing the needed fields. The following listing shows the <code>OfacResponse</code> interface.</p>
</div>
<div class="browsable-container listing-container" id="p176">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.37<span class="CharOverride-3"> </span>The <code>OfacResponse </code>interface</h5>
<div class="code-area-container">
<pre class="code-area"><code>export interface OfacResponse {</code>
<code>  id: number;</code>
<code>  ach_files_id: string;</code>
<code>  ach_batch_id: string;</code>
<code>  sdn_name: string;</code>
<code>  individual_name: string;</code>
<code>  alias: string | null;</code>
<code>  similarity_score: number;</code>
<code>  daitch_mokotoff_match_name: boolean;</code>
<code>  daitch_mokotoff_match_alias: boolean;</code>
<code>}</code></pre>
</div>
</div>
<div class="readable-text" id="p177">
<p>We now look at creating the component itself using a MUI DataGrid like we did for previous components in our dashboard.</p>
</div>
<div class="browsable-container listing-container" id="p178">
<h5 class="listing-container-h5 browsable-container-h5">Listing 11.38<span class="CharOverride-3"> </span>The <code>OfacRecords</code> component</h5>
<div class="code-area-container">
<pre class="code-area">interface OfacRecordsProps {
    records: OfacResponse[];
}

export default function OfacRecords({records}: 
<span class="CharOverride-6">➥</span>Readonly&lt;OfacRecordsProps&gt;) {

    const columns: GridColDef[] = [
        {
            field: 'ach_files_id', #1
            headerName: '',  #1
            width: 100,  #1
            renderCell: (params) =&gt; (  #1
                &lt;Link href={`/fileDetails/${params.value}`}   #1
                      color="inherit"&gt;  #1
                    View File  #1
                &lt;/Link&gt;  #1
            ),
        },
        {
            field: 'ach_batch_id', #2
            headerName: '',  #2
            width: 100,  #2
            renderCell: (params) =&gt; (  #2
                &lt;Link   #2
href={`/fileDetails  #2
       /${params.row.ach_files_id}/batchDetails  #2
       /${params.value}`}   #2
                      color="inherit"&gt;  #2
                    View batch  #2
                &lt;/Link&gt;  #2
            ), 
        },
…
        {field: 'similarity_score',  #3
                   headerName: 'Score', width: 75,   #4
                   renderCell: (params) =&gt; (  #4
                &lt;Typography&gt;{Math.floor(params.value)}&lt;/Typography&gt;  #4
            )},  #4
        {
            field: 'daitch_mokotoff_match_name', #4
            headerName: 'Name Match', 
            width: 100, 
            renderCell: (params) =&gt; ( #5
… 
                   {params.value ?  
                       &lt;CheckCircle sx={{color: "green"}}/&gt; : null} 
… 
        },
        {
            field: 'daitch_mokotoff_match_alias', #6
            <span>headerName: 'Alias Match', </span> #6
<span>            width: 100, </span> #6
<span>            renderCell: (params) =&gt; ( </span> #6
<span>… </span> #6
<span>                    {params.value ?  </span> #6
<span>                         &lt;CheckCircle sx={{color: "green"}}/&gt; : null} </span> #6
<span>… </span> #6
<span>        },</span>
<span>    ];</span>
<span>…</span>
<span>                        &lt;DataGrid columns={columns} rows={records}/&gt; </span>#7
…</pre>
<div class="code-annotations-overlay-container">
     #1 
     <span class="CharOverride-5">The ach_files_id is used to create a link users can click to navigate to the file where the match was.</span>
<br/>#2 
     <span class="CharOverride-5">To navigate to the batch that has </span>
<span class="CharOverride-5">the match, we need to pull the </span>
<span class="CharOverride-5">ach_files_id from the row object, as well as the params.value, although we could have also used the </span>
<span class="CharOverride-5">params.row.ach_batch_id field.</span>
<br/>#3 
     <span class="CharOverride-5">Displays the similarity score; we use Math.floor to remove any decimals just as a display preference.</span>
<br/>#4 
     <span class="CharOverride-5">Based on the Boolean flag that was passed, displays a green circle with a check mark or nothing</span>
<br/>#5 
     <span class="CharOverride-5">Based on the Boolean flag that was passed, displays a green circle with a check mark or nothing </span>
<br/>#6 
     <span class="CharOverride-5">When the alias was matched, displays a green circle with a check mark</span>
<br/>#7 
     <span class="CharOverride-5">The columns and rows we defined are passed to the DataGrid componenet.</span>
<br/>
</div>
</div>
</div>
<div class="readable-text" id="p179">
<p>With the component created, we should be able to pull the results of an OFAC scan and display them in our component. That should be sufficient to meet the requirements for the story. In the next section, we wrap up the OFAC searching by outlining some potential problems.</p>
</div>
<div class="readable-text" id="p180">
<h3 class="readable-text-h3"><span class="num-string">11.9.3</span> OFAC results</h3>
</div>
<div class="readable-text" id="p181">
<p>We now have a component that can present the results of an OFAC scan and have met the requirements for our story. This will more than likely suffice for the short term, but in a production environment, we will have to address some of the design choices made.</p>
</div>
<div class="readable-text intended-text" id="p182">
<p>First, the scan is done dynamically whenever the page is loaded. While this works great for limited data, the page will likely slow to a crawl in a production environment. The SDN list contains over 15,000 records, and each will be scanned for every ACH transaction we have. Remember that there is a large volume of payments flowing through the ACH system (currently over 31 billion payments per year), and while we will not be required to scan them all, apparently, it may result in a lot of scanning. The situation will also be exacerbated when we have multiple users trying to view the reports, since each page requests results in another scan.</p>
</div>
<div class="readable-text intended-text" id="p183">
<p>Second, there is no way to save or export our results. Because the scanning is done upon request (when a user visits the page) using the data currently stored in the database, we do not have a way to pull previous scan results. The SDN and other lists provided by OFAC are revised constantly with individuals being added, removed, and updated. The scans we do today may yield different results tomorrow, which can be a compliance nightmare in the current setup. If the SDN list changes, and we can no longer show that a particular individual was matched on a certain date or transaction, we may find ourselves facing penalties, as outlined at the beginning of the chapter.</p>
</div>
<div class="readable-text intended-text" id="p184">
<p>Third, in production environments, scanning is typically done at the time of the file load in an ACH environment. The database can also be periodically scanned to identify potential customers and transactions that may be in violation. All these scans produce a copy of the results that can be reviewed and archived in cold storage for later retrieval as needed. Scanning at the time of the load can help reduce constant requests that burden the system while providing real-time feedback on suspicious activity. However, for large files, this operation can still take some time, and with our current architecture, we would likely want to introduce a status for the file, so that some of these tasks could be done asynchronously.</p>
</div>
<div class="readable-text intended-text" id="p185">
<p>Those are just a few of the challenges we may face with OFAC scanning, mentioning nothing of creating a more complex algorithm to detect suspicious activity. Although it presents several challenges, we can review them as opportunities to explore other areas of ACH, finance, compliance, and security that we need to touch on with this subject.</p>
</div>
<div class="readable-text intended-text" id="p186">
<p>In this chapter, we explored a new ACH layout for international ACH transactions. The introduction of this new type of transaction for our dashboard also caused an increased risk for our organization by potentially violating US laws and regulations for dealing with sanctioned individuals. To remain in compliance and reduce our risk, we explored scanning our ACH file for customers that may be on a list of sanctioned individuals provided by OFAC. To accomplish all this, we enhanced the parsing of our ACH files, performed fuzzy matching on customer names, provided an API to power it all, and presented the results in a UI component. </p>
</div>
<div class="readable-text" id="p187">
<h2 class="readable-text-h2">Summary</h2>
</div>
<ul>
<li class="readable-text" id="p188">International ACH transactions (IAT) introduce unique regulatory requirements and require precise formatting, which underscores the need for careful planning and compliance verification in financial systems.</li>
<li class="readable-text" id="p189">Expanding database structures to accommodate IAT involves integrating new tables tailored for specific ACH components, reinforcing the importance of planning for system scalability.</li>
<li class="readable-text" id="p190">Generating IAT batches requires adapting current solutions to handle additional header and entry information, highlighting the complexity of international transaction standards.</li>
<li class="readable-text" id="p191">Comprehensive unit testing ensures new IAT functionalities align with existing PPD processes, while preventing disruptions, showcasing the importance of regression testing in software development.</li>
<li class="readable-text" id="p192">Streamlining code through refactoring enhances maintainability and reduces redundancy, indicating the continual need for codebase optimization as projects evolve.</li>
<li class="readable-text" id="p193">Integrating IAT processing in dashboards requires understanding both technical constraints and user needs, which emphasizes cross-functional alignment in feature development.</li>
<li class="readable-text" id="p194">Designing APIs to handle IAT data ensures consistent data retrieval and processing, demonstrating the necessity for flexible yet robust system interfaces.</li>
<li class="readable-text" id="p195">OFAC compliance is crucial when processing IAT to mitigate risks associated with sanctioned individuals, which highlights the role of regulatory adherence in transaction processing.</li>
<li class="readable-text" id="p196">Implementing fuzzy matching algorithms aids in detecting minor variations in suspect names, thus increasing accuracy in identifying sanctioned transactions.</li>
<li class="readable-text" id="p197">Effective UI components for OFAC results delivery underscore the value of clear, actionable insights for users navigating complex compliance landscapes.</li>
<li class="readable-text" id="p198">Persisting scan results addresses compliance demands by providing traceable audit trails, which stresses the need for reliable data storage and retrieval in financial applications.</li>
<li class="readable-text" id="p199">The addition of IAT processing elevates organizational risk awareness, which underscores the critical need for stringent compliance frameworks to navigate international regulations effectively.</li>
</ul>
</div></body></html>