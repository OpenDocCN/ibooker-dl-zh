# 第一章。TensorFlow 2 简介

TensorFlow 长期以来一直是最受欢迎的开源 Python 机器学习（ML）库。它是由 Google Brain 团队作为内部工具开发的，但在 2015 年以 Apache 许可证发布。从那时起，它已经发展成一个充满重要资产的生态系统，用于模型开发和部署。今天，它支持各种特定设计用于处理数据摄入和转换、特征工程、模型构建和服务等任务的 API 和模块。

TensorFlow 变得越来越复杂。本书的目的是帮助简化数据科学家或 ML 工程师在端到端模型开发过程中需要执行的常见任务。本书不关注数据科学和算法；相反，这里的示例使用预构建的模型作为教授相关概念的工具。

本书适用于具有构建 ML 模型的基本经验和知识的读者。强烈建议具备一定的 Python 编程能力。如果您从头到尾阅读本书，您将获得关于端到端模型开发过程和涉及的主要任务的大量知识，包括数据工程、摄入和准备；模型训练；以及服务模型。

本书中示例的源代码是在 Google Colaboratory（简称 Colab）和运行 macOS Big Sur，版本 11.2.3 的 MacBook Pro 上开发和测试的。使用的 TensorFlow 版本是 2.4.1，Python 版本是 3.7。

# TensorFlow 2 的改进

随着 TensorFlow 的发展，它的复杂性也在增加。新用户学习 TensorFlow 的曲线是陡峭的，因为需要记住许多不同的方面。*我如何准备数据进行摄入和训练？如何处理不同的数据类型？对于不同的处理方法需要考虑什么？*这些只是您在 ML 旅程初期可能遇到的一些基本问题。

一个特别难以适应的概念是*惰性执行*，这意味着 TensorFlow 实际上不会处理您的数据，直到您明确告诉它执行整个代码。这个想法是为了加快性能。您可以将 ML 模型看作一组节点和边（换句话说，一个图）。当您在路径中运行计算并通过节点转换数据时，结果只有数据路径中的计算被执行。换句话说，您不必计算每个计算，只需计算数据通过图从输入到输出的路径中直接位于的计算。如果数据的形状和格式在一个节点和下一个节点之间没有正确匹配，当您编译模型时将会出现错误。在传递数据结构或张量形状时，很难调查您在哪里犯了错误以进行调试。

通过 TensorFlow 1.*x*，惰性执行是构建和训练 ML 模型的方式。然而，从 TensorFlow 2 开始，*急切执行*是构建和训练模型的默认方式。这种改变使得调试代码和尝试不同的模型架构变得更加容易。急切执行还使得学习 TensorFlow 变得更加容易，因为您将立即在执行每行代码时看到任何错误。您不再需要在调试和测试输入数据是否具有正确形状之前构建整个模型图。这是使 TensorFlow 2 比以前版本更易于使用的几个主要功能和改进之一。

## Keras API

Keras 是由 AI 研究员 François Chollet 创建的开源、高级、深度学习 API 或框架。它与多个 ML 库兼容。

*高级*意味着在更低级别上有另一个实际执行计算的框架，事实上确实如此。这些低级框架包括 TensorFlow、Theano 和 Microsoft 认知工具包（CNTK）。Keras 的目的是为那些想要利用低级框架构建深度学习模型的用户提供更简单的语法和编码风格。

2015 年，Chollet 加入 Google 后，Keras 逐渐成为 TensorFlow 采用的基石。2019 年，随着 TensorFlow 团队推出 2.0 版本，正式采用了 Keras 作为 TensorFlow 的一流 API，即`tf.keras`，用于所有未来版本。从那时起，TensorFlow 已经将`tf.keras`与许多其他重要模块集成在一起。例如，它与`tf.io` API 无缝配合，用于读取分布式训练数据。它还与`tf.data.Dataset`类一起工作，用于流式传输训练数据，这些数据太大，无法容纳在一台计算机中。本书在所有章节中都使用这些模块。

今天，TensorFlow 用户主要依赖`tf.keras` API 来快速轻松地构建深度模型。快速获得训练例程的便利性使得更多时间可以用来尝试不同的模型架构和调整模型和训练例程中的参数。

## TensorFlow 中的可重用模型

学术研究人员已经构建和测试了许多 ML 模型，所有这些模型在其架构上都很复杂。用户学习如何构建这些模型并不现实。这就引入了*迁移学习*的概念，其中为一个任务开发的模型被重用来解决另一个任务，即用户定义的任务。这基本上归结为将用户数据转换为适当的数据结构，以便模型输入和输出。

自然地，这些模型及其潜在用途引起了极大的兴趣。因此，应大众需求，许多模型已经在开源生态系统中可用。TensorFlow 创建了一个仓库，TensorFlow Hub，向公众提供这些复杂模型的免费访问。如果您感兴趣，您可以尝试这些模型，而无需自己构建它们。在第四章中，您将学习如何从 TensorFlow Hub 下载和使用模型。一旦您这样做了，您只需要了解模型在输入时期望的数据结构，并添加一个适合您预测目标的最终输出层。TensorFlow Hub 中的每个模型都包含简洁的文档，为您提供构建输入数据所需的信息。

另一个获取预构建模型的地方是`tf.keras.applications`模块，它是 TensorFlow 分发的一部分。在第四章中，您将学习如何使用此模块来利用预构建模型处理您自己的数据。

# 使常用操作变得简单

TensorFlow 2 中的所有这些改进使得许多重要操作更容易实现。即便如此，从头到尾构建和训练一个 ML 模型并不是一项简单的任务。本书将向您展示如何处理 TensorFlow 2 模型训练过程的每个方面，从一开始。以下是其中一些操作。

## 开源数据

集成到 TensorFlow 2 中的一个方便的包是[TensorFlow 数据集库](https://oreil.ly/0nt9T)。这是一个由精心策划的开源数据集组成的集合，可供使用。该库包含图像、文本、音频、视频等多种格式的数据集。有些是 NumPy 数组，而其他的是数据集结构。该库还提供了如何使用 TensorFlow 加载这些数据集的文档。通过在其产品中分发各种开源数据集，TensorFlow 团队真正为用户节省了搜索、集成和重塑训练数据以适应 TensorFlow 工作负载的麻烦。本书中将使用的一些开源数据集是用于结构化数据分类的[*泰坦尼克*数据集](https://oreil.ly/GWCN1)和用于图像分类的[CIFAR-10 数据集](https://oreil.ly/uwQUm)。

## 处理分布式数据集

首先，您必须处理如何处理训练数据的问题。许多教学示例使用 TensorFlow 中的预构建训练数据，以其原生格式，例如小型 pandas DataFrame 或 NumPy 数组，这些数据可以很好地适应计算机的内存。然而，在更现实的情况下，您可能需要处理比计算机内存更多的训练数据。从 SQL 数据库读取的表的大小很容易达到几十亿字节。即使您有足够的内存将其加载到 pandas DataFrame 或 NumPy 数组中，您的 Python 运行时在计算过程中可能会耗尽内存并崩溃。

通常将大量数据保存为多个文件，常见格式为 CSV（逗号分隔值）或文本。因此，您不应尝试在 Python 运行时加载每个文件。处理分布式数据集的正确方法是创建一个引用，指向*所有*文件的位置。第二章将向您展示如何使用`tf.io` API，该 API 提供一个包含文件路径和名称列表的对象。无论数据大小和文件数量如何，这都是处理训练数据的首选方式。

## 数据流式传输

您打算如何将数据传递给模型进行训练？这是一个重要的技能，但许多流行的教学示例通过将整个 NumPy 数组传递到模型训练例程中来处理。就像加载大型训练数据一样，如果尝试将大型 NumPy 数组传递给模型进行训练，您将遇到内存问题。

更好的处理方式是通过*数据流*。不是一次性传递整个训练数据，而是为模型训练提供一个子集或批量数据进行流式传输。在 TensorFlow 中，这被称为您的*数据集*。在第二章中，您还将学习如何从`tf.io`对象创建数据集。数据集对象可以从各种本地数据结构创建。在第三章中，您将看到如何从 CSV 文件和图像创建`tf.data.Dataset`对象。

通过`tf.io`和`tf.data.Dataset`的组合，您将为模型训练设置一个数据处理工作流程，而无需在 Python 运行时内存中读取或打开任何数据文件。

## 数据工程

为了使模型能够学习模式，您需要对训练数据应用数据或特征工程任务。根据数据类型，有不同的方法可以做到这一点。

如果您正在处理表格数据，可能在不同列中有不同的值或数据类型。在第三章中，您将看到如何使用 TensorFlow 的`feature_column` API 对训练数据进行标准化。它可以帮助您正确标记哪些列是数值列，哪些是分类列。

对于图像数据，您将有不同的任务。例如，数据集中的所有图像必须具有相同的尺寸。此外，像素值通常被归一化或缩放到[0, 1]范围。对于这些任务，`tf.keras`提供了`ImageDataGenerator`类，用于标准化图像尺寸并为您归一化像素值。

## 迁移学习

TensorFlow Hub 为所有人提供了预构建的开源模型。在第四章中，您将学习如何使用 Keras 层 API 访问 TensorFlow Hub。此外，`tf.keras`附带了这些预构建模型的清单，可以使用`tf.keras.applications`模块调用。在第四章中，您将学习如何使用此模块进行迁移学习。

## 模型风格

使用`tf.keras`可以以多种方式实现模型。这是因为一些深度学习模型架构或模式比其他更复杂。对于常见用途，*符号 API*风格，按顺序设置模型架构，可能足够了。另一种风格是*命令式 API*，其中您将模型声明为一个类，因此每次调用模型对象时，都会创建该类的一个实例。这要求您了解类继承的工作原理（我将在第六章中讨论）。如果您的编程背景源自面向对象的编程语言，如 C++或 Java，那么这个 API 可能对您更自然。使用命令式 API 方法的另一个原因是将模型架构代码与其余工作流程分开。在第六章中，您将学习如何设置和使用这两种 API 风格。

## 监控训练过程

监控您的模型在每个*epoch*（即一次通过训练集）中是如何训练和验证的是模型训练的一个重要方面。在每个 epoch 结束时进行验证步骤是您可以采取的最简单的措施，以防止*模型过拟合*，这是一种现象，模型开始记忆训练数据模式而不是按预期学习特征。在第七章中，您将学习如何使用各种*回调*来保存每个 epoch 的模型权重和偏差。我还将指导您如何设置和使用 TensorBoard 来可视化训练过程。

## 分布式训练

即使您知道如何处理分布式数据和文件并将其流式传输到模型训练例程中，但如果发现训练需要不切实际的时间呢？这就是*分布式训练*可以帮助的地方。它需要一组硬件加速器，例如图形处理单元（GPU）或张量处理单元（TPU）。这些加速器可以通过许多公共云提供商获得。您还可以在 Google Colab 中免费使用一个 GPU 或 TPU（而不是集群）；您将学习如何使用`tf.distribute.MirroredStrategy`类，简化和减少设置分布式训练的繁重工作，在第八章的第一部分示例中进行操作。

在`tf.distribute.MirroredStrategy`之前发布的 Horovod API 来自 Uber 工程团队，是一个相对复杂的替代方案。它专门用于在计算集群上运行训练例程。要学习如何使用 Horovod，您需要使用基于云的计算平台 Databricks，在第八章的第二部分示例中进行操作。这将帮助您学习如何重构您的代码以分发和分片数据以供 Horovod API 使用。

## 为您的 TensorFlow 模型提供服务

一旦您构建了模型并成功训练了它，现在是时候将模型持久化或存储起来，以便可以提供给处理用户输入。您将看到使用`tf.saved_model` API 保存您的模型是多么容易。

通常，模型由 Web 服务托管。这就是 TensorFlow Serving 出现的地方：它是一个框架，包装您的模型并通过 HTTP 公开为 Web 服务调用。在第九章中，您将学习如何使用 TensorFlow Serving Docker 镜像来托管您的模型。

## 改进培训体验

最后，第十章讨论了评估和改进模型训练过程的一些重要方面。您将学习如何使用 TensorFlow 模型分析模块来查看模型偏差的问题。该模块提供了一个交互式仪表板，称为公平性指标，旨在揭示模型偏差。使用 Jupyter Notebook 环境和您在第三章中训练的*泰坦尼克号*数据集上的模型，您将看到公平性指标是如何工作的。

`tf.keras` API 带来的另一个改进是使超参数调整更加方便。*超参数*是与模型训练例程或模型架构相关的属性。调整它们通常是一个繁琐的过程，因为它涉及彻底搜索参数空间。在第十章中，您将看到如何使用 Keras Tuner 库和一个称为 Hyperband 的高级搜索算法来进行超参数调整工作。

# 总结

TensorFlow 2 是对以前版本的重大改进。其最重要的改进是将`tf.keras` API 指定为使用 TensorFlow 的推荐方式。这个 API 与`tf.io`和`tf.data.Dataset`无缝配合，用于端到端的模型训练过程。这些改进加快了模型构建和调试的速度，因此您可以尝试模型训练的其他方面，比如尝试不同的架构或进行更有效的超参数搜索。所以，让我们开始吧。
