["```py\n12.1 Activation Optimization\n12.2 Neural Style\n```", "```py\nmodel = vgg16.VGG16(weights='imagenet', include_top=False)\nlayer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n```", "```py\ninput_img = model.input\nneuron_index  = 1\nlayer_output = layer_dict['block3_conv1'].output\nloss = K.mean(layer_output[:, neuron_index, :, :])\n```", "```py\ngrads = K.gradients(loss, input_img)[0]\ngrads = normalize(grads)\niterate = K.function([input_img], [loss, grads])\n```", "```py\nfor i in range(20):\n    loss_value, grads_value = iterate([input_img_data])\n    input_img_data += grads_value * step\n```", "```py\ndef visstd(a, s=0.1):\n    a = (a - a.mean()) / max(a.std(), 1e-4) * s + 0.5\n    return np.uint8(np.clip(a, 0, 1) * 255)\n```", "```py\nlayers = ['block%d_conv%d' % (i, (i + 1) // 2) for i in range(1, 6)]\n```", "```py\ngrid = []\nlayers = [layer_dict['block%d_conv%d' % (i, (i + 1) // 2)]\n          for i in range(1, 6)]\nfor layer in layers:\n    row = []\n    neurons = random.sample(range(max(x or 0\n                            for x in layers[0].output_shape)\n    for neuron in tqdm(neurons), sample_size), desc=layer.name):\n        loss = K.mean(layer.output[:, neuron, :, :])\n        grads = normalize(K.gradients(loss, input_img)[0])\n        iterate = K.function([input_img], [loss, grads])\n        img_data = np.random.uniform(size=(1, 3, 128, 128, 3)) + 128.\n        for i in range(20):\n            loss_value, grads_value = iterate([img_data])\n            img_data += grads_value\n        row.append((loss_value, img_data[0]))\n    grid.append([cell[1] for cell in\n                islice(sorted(row, key=lambda t: -t[0]), 10)])\n```", "```py\nimg_grid = PIL.Image.new('RGB',\n                         (8 * 100 + 4, len(layers) * 100 + 4), (180, 180, 180))\nfor y in range(len(layers)):\n    for x in range(8):\n        sub = PIL.Image.fromarray(\n                 visstd(grid[y][x])).crop((16, 16, 112, 112))\n        img_grid.paste(sub,\n                       (x * 100 + 4, (y * 100) + 4))\ndisplay(img_grid)\n```", "```py\nimg_data = np.random.uniform(size=(1, 3, size, size)) + 128.\n```", "```py\nfor octave in range(20):\n    if octave>0:\n        size = int(size * 1.1)\n        img_data = resize_img(img_data, (size, size))\n    for i in range(10):\n        loss_value, grads_value = iterate([img_data])\n        img_data += grads_value\n    clear_output()\n    showarray(visstd(img_data[0]))\n```", "```py\nsuccessive_shapes = [tuple(int(dim / (octave_scale ** i))\n                     for dim in original_shape)\n                     for i in range(num_octave - 1, -1, -1)]\n\noriginal_img = np.copy(img)\nshrunk_original_img = resize_img(img, successive_shapes[0])\n\nfor shape in successive_shapes:\n    print('Processing image shape', shape)\n    img = resize_img(img, shape)\n    for i in range(20):\n        loss_value, grads_value = iterate([img])\n        img += grads_value\n    upscaled_shrunk_original_img = resize_img(shrunk_original_img, shape)\n    same_size_original = resize_img(original_img, shape)\n    lost_detail = same_size_original - upscaled_shrunk_original_img\n\n    img += lost_detail\n    shrunk_original_img = resize_img(original_img, shape)\n```", "```py\nsettings = {\n        'block3_pool': 0.1,\n        'block4_pool': 1.2,\n        'block5_pool': 1.5,\n}\n```", "```py\nloss = K.variable(0.)\nfor layer_name, coeff in settings.items():\n    x = layer_dict[layer_name].output\n    scaling = K.prod(K.cast(K.shape(x), 'float32'))\n    if K.image_data_format() == 'channels_first':\n        loss += coeff * K.sum(K.square(x[:, :, 2: -2, 2: -2])) / scaling\n    else:\n        loss += coeff * K.sum(K.square(x[:, 2: -2, 2: -2, :])) / scaling\n```", "```py\n    for i in range(20):\n        loss_value, grads_value = iterate([img])\n        img += grads_value * 0.10\n```", "```py\ndef gram_matrix(x):\n    if K.image_data_format() != 'channels_first':\n        x = K.permute_dimensions(x, (2, 0, 1))\n    features = K.batch_flatten(x)\n    return K.dot(features, K.transpose(features))\n\ndef style_loss(layer_1, layer_2):\n    gr1 = gram_matrix(layer_1)\n    gr2 = gram_matrix(layer_1)\n    return K.sum(K.square(gr1 - gr2))\n```", "```py\nstyle_image = K.variable(preprocess_image(style_image_path,\n                                          target_size=(1024, 768)))\nresult_image = K.placeholder(style_image.shape)\ninput_tensor = K.concatenate([result_image,\n                              style_image], axis=0)\n\nmodel = vgg16.VGG16(input_tensor=input_tensor,\n                    weights='imagenet', include_top=False)\n```", "```py\nloss = K.variable(0.)\nfor layer in model.layers:\n    if '_conv' in layer.name:\n        output = layer.output\n        loss += style_loss(output[0, :, :, :], output[1, :, :, :])\n```", "```py\nclass Evaluator(object):\n    def __init__(self, loss_total, result_image):\n        grads = K.gradients(loss_total, result_image)\n        outputs = [loss_total] + grads\n        self.iterate = K.function([result_image], outputs)\n        self.shape = result_image.shape\n\n        self.loss_value = None\n        self.grads_values = None\n\n    def loss(self, x):\n        outs = self.iterate([x.reshape(self.shape)])\n        self.loss_value = outs[0]\n        self.grad_values = outs[-1].flatten().astype('float64')\n        return self.loss_value\n\n    def grads(self, x):\n        return np.copy(self.grad_values)\n```", "```py\nimage, min_val, _ = fmin_l_bfgs_b(evaluator.loss, image.flatten(),\n                                  fprime=evaluator.grads, maxfun=20)\n```", "```py\nreturn K.dot(features - 1, K.transpose(features - 1))\n```", "```py\ndef gram_matrix_mean(x):\n    x = K.mean(x, axis=1)\n    x = K.mean(x, axis=1)\n    features = K.batch_flatten(x)\n    return K.dot(features - 1,\n                 K.transpose(features - 1)) / x.shape[0].value\n```", "```py\ndef total_variation_loss(x, exp=1.25):\n    _, d1, d2, d3 = x.shape\n    a = K.square(x[:, :d1 - 1, :d2 - 1, :] - x[:, 1:, :d2 - 1, :])\n    b = K.square(x[:, :d1 - 1, :d2 - 1, :] - x[:, :d1 - 1, 1:, :])\n    return K.sum(K.pow(a + b, exp))\n```", "```py\nloss_variation = total_variation_loss(result_image, h, w) / 5000\nloss_with_variation = loss_variation + loss_style\nevaluator_with_variation = Evaluator(loss_with_variation, result_image)\n```", "```py\ndef content_loss(base, combination):\n    return K.sum(K.square(combination - base))\n```", "```py\nw, h = load_img(base_image_path).size\nbase_image = K.variable(preprocess_image(base_image_path))\nstyle_image = K.variable(preprocess_image(style2_image_path, target_size=(h, w)))\ncombination_image = K.placeholder(style_image.shape)\ninput_tensor = K.concatenate([base_image,\n                              style_image,\n                              combination_image], axis=0)\n```", "```py\nloss_content = content_loss(feature_outputs[-1][0, :, :, :],\n                            feature_outputs[-1][2, :, :, :])\n```", "```py\nloss_style = K.variable(0.)\nfor idx, layer_features in enumerate(feature_outputs):\n    loss_style += style_loss(layer_features[1, :, :, :],\n                             layer_features[2, :, :, :]) * (0.5 ** idx)\n```", "```py\nloss_content /= 40\nloss_variation /= 10000\nloss_total = loss_content + loss_variation + loss_style\n```", "```py\nloss_style_summer = K.variable(0.)\nloss_style_winter = K.variable(0.)\nfor idx, layer_features in enumerate(feature_outputs):\n    loss_style_summer += style_loss(layer_features[1, :, :, :],\n                                    layer_features[-1, :, :, :]) * (0.5 ** idx)\n    loss_style_winter += style_loss(layer_features[2, :, :, :],\n                                    layer_features[-1, :, :, :]) * (0.5 ** idx)\n```", "```py\nsummerness = K.placeholder()\nloss_total = (loss_content + loss_variation +\n              loss_style_summer * summerness +\n              loss_style_winter * (1 - summerness))\n```", "```py\ncombined_evaluator = Evaluator(loss_total, combination_image,\n                               loss_content=loss_content,\n                               loss_variation=loss_variation,\n                               loss_style=loss_style)\niterate = K.function([combination_image, summerness],\n                     combined_evaluator.iterate.outputs)\ncombined_evaluator.iterate = lambda inputs: iterate(inputs + [0.5])\n```"]