["```py\nreviews_collection = engine.create_collection(\"reviews\")\nreviews_data = reviews.load_dataframe(\"data/reviews/reviews.csv\")\nreviews_collection.write(reviews_data)\n```", "```py\nWiping \"reviews\" collection\nCreating \"reviews\" collection\nStatus: Success\n\nLoading Reviews...\nroot\n |-- id: string (nullable = true)\n |-- business_name: string (nullable = true)\n |-- city: string (nullable = true)\n |-- state: string (nullable = true)\n |-- content: string (nullable = true)\n |-- categories: string (nullable = true)\n |-- stars_rating: integer (nullable = true)\n |-- location_coordinates: string (nullable = true)\n\nSuccessfully written 192138 documents\n```", "```py\nstart_reviews_search_webserver()\n\n%%html\n<iframe src=\"http://localhost:2345/search\" width=100% height=\"800\"/>\n```", "```py\nentities_dataframe = from_csv(\"data/reviews/entities.csv\", log=False)\ndisplay_entities(entities_dataframe, limit=20)\n```", "```py\nEntities\n+---+--------------------+--------------------+-----------------+----------+\n| id|        surface_form|      canonical_form|             type|popularity|\n+---+--------------------+--------------------+-----------------+----------+\n|  1|                near| {location_distance}|semantic_function|        90|\n|  2|                  in| {location_distance}|semantic_function|       100|\n|  3|                  by| {location_distance}|semantic_function|        90|\n|  4|                  by|{text_within_one_...|semantic_function|        10|\n|  5|                near|     {text_distance}|semantic_function|        10|\n|  6|             popular|           {popular}|semantic_function|       100|\n|  7|                 top|           {popular}|semantic_function|       100|\n|  8|                best|           {popular}|semantic_function|       100|\n|  9|                good|           {popular}|semantic_function|       100|\n| 10|              violet|              violet|            color|       100|\n| 11|       violet crowne|       violet crowne|            brand|       100|\n| 12|violet crowne cha...|violet crowne cha...|    movie_theater|       100|\n| 13|        violet crown|       violet crowne|            brand|       100|\n| 14|violet crown char...|violet crowne cha...|    movie_theater|       100|\n| 15|            haystack| haystack conference|            event|       100|\n| 16|       haystack conf| haystack conference|            event|       100|\n| 17| haystack conference| haystack conference|            event|       100|\n| 18|            heystack| haystack conference|            event|       100|\n| 19|       heystack conf| haystack conference|            event|       100|\n| 20| heystack conference| haystack conference|            event|       100|\n+---+--------------------+--------------------+-----------------+----------+\nonly showing top 20 rows\n\n... Entities continued\n+---+----------------------------------------------+\n|id |semantic_function                             |\n+---+----------------------------------------------+\n|1  |location_distance(query, position)            |\n|2  |location_distance(query, position)            |\n|3  |location_distance(query, position)            |\n|4  |text_within_one_edit_distance(query, position)|\n|5  |text_distance(query, position)                |\n|6  |popularity(query, position)                   |\n|7  |popularity(query, position)                   |\n|8  |popularity(query, position)                   |\n|9  |popularity(query, position)                   |\n+---+----------------------------------------------+\n```", "```py\nentities_collection = engine.create_collection(\"entities\")  #1\nentities_dataframe = from_csv(\"data/reviews/entities.csv\")\ncities_dataframe = cities.load_dataframe(\"data/reviews/cities.csv\")\nentities_collection.write(entities_dataframe)  #2\nentities_collection.write(cities_dataframe)  #2\n```", "```py\nWiping \"entities\" collection\nCreating \"entities\" collection\nStatus: Success\nLoading data/reviews/entities.csv\nSchema:\nroot\n |-- id: integer (nullable = true)\n |-- surface_form: string (nullable = true)\n |-- canonical_form: string (nullable = true)\n |-- type: string (nullable = true)\n |-- popularity: integer (nullable = true)\n |-- semantic_function: string (nullable = true)\n\nLoading Geonames...\nSuccessfully written 21 documents\nSuccessfully written 137581 documents\n```", "```py\nadd_tag_type_commands = [{\n  \"add-field-type\": {\n    \"name\": \"tag\",  #1\n    \"class\": \"solr.TextField\", #1\n    \"postingsFormat\": \"FST50\", #1\n    \"omitNorms\": \"true\",\n    \"omitTermFreqAndPositions\": \"true\",\n    \"indexAnalyzer\": {\n      \"tokenizer\": {\"class\": \"solr.StandardTokenizerFactory\"},\n      \"filters\": [\n        {\"class\": \"solr.EnglishPossessiveFilterFactory\"},\n        {\"class\": \"solr.ASCIIFoldingFilterFactory\"},\n        {\"class\": \"solr.LowerCaseFilterFactory\"},\n        {\"class\": \"solr.ConcatenateGraphFilterFactory\",  #2\n         \"preservePositionIncrements\": \"false\"}]},  #2\n    \"queryAnalyzer\": {\n      \"tokenizer\": {\"class\": \"solr.StandardTokenizerFactory\"},\n      \"filters\": [{\"class\": \"solr.EnglishPossessiveFilterFactory\"},\n                  {\"class\": \"solr.ASCIIFoldingFilterFactory\"},\n                  {\"class\": \"solr.LowerCaseFilterFactory\"}]}}\n  },\n\n  {\"add-field\": {\"name\": \"name_tag\", \"type\": \"tag\",  #3\n                 \"stored\": \"false\"}},  #3\n  {\"add-copy-field\": {\"source\": \"surface_form\",  #4\n                      \"dest\": [\"name_tag\"]}}] #4\n\nadd_tag_request_handler_config = {\n  \"add-requesthandler\": {  #5\n    \"name\": \"/tag\",  #5\n    \"class\": \"solr.TaggerRequestHandler\",  #5\n    \"defaults\": {\n      \"field\": \"name_tag\",  #5\n      \"json.nl\": \"map\",\n      \"sort\": \"popularity desc\",  #6\n      \"matchText\": \"true\",\n      \"fl\": \"id,surface_form,canonical_form,type,semantic_function,\n      ↪popularity,country,admin_area,*_p\"\n    }}}\n```", "```py\nquery = \"top kimchi near charlotte\"\nentities_collection = engine.get_collection(\"entities\")\nextractor = get_entity_extractor(entities_collection)\nquery_entities = extractor.extract_entities(query)\nprint(query_entities)\n```", "```py\n{\"query\": \"top kimchi near charlotte\",\n \"tags\": [\n  {\"startOffset\": 0, \"endOffset\": 3, \"matchText\": \"top\", \"ids\": [\"7\"]},\n  {\"startOffset\": 11, \"endOffset\":15, \"matchText\":\"near\", \"ids\":[\"1\",\"5\"]},\n  {\"startOffset\": 16, \"endOffset\": 25, \"matchText\": \"charlotte\",\n   \"ids\": [\"4460243\", \"4612828\", \"4680560\", \"4988584\", \"5234793\"]}],\n \"entities\": [\n  {\"id\":\"1\", \"surface_form\":\"near\", \"canonical_form\":\"{location_distance}\",\n   \"type\": \"semantic_function\", \"popularity\": 90,\n   \"semantic_function\": \"location_distance(query, position)\"},\n  {\"id\": \"5\", \"surface_form\": \"near\", \"canonical_form\": \"{text_distance}\",\n   \"type\": \"semantic_function\", \"popularity\": 10,\n   \"semantic_function\": \"text_distance(query, position)\"},\n  {\"id\": \"7\", \"surface_form\": \"top\", \"canonical_form\": \"{popular}\",\n   \"type\": \"semantic_function\", \"popularity\": 100,\n   \"semantic_function\": \"popularity(query, position)\"},\n  {\"id\":\"4460243\", \"canonical_form\":\"Charlotte\", \"surface_form\":\"Charlotte\",\n   \"admin_area\": \"NC\", \"popularity\": 827097, \"type\": \"city\",\n   \"location_coordinates\": \"35.22709,-80.84313\"},\n  {\"id\":\"4612828\", \"canonical_form\":\"Charlotte\", \"surface_form\":\"Charlotte\",\n   \"admin_area\": \"TN\", \"popularity\": 1506, \"type\": \"city\",\n   \"location_coordinates\": \"36.17728,-87.33973\"},\n  {\"id\":\"4680560\", \"canonical_form\":\"Charlotte\", \"surface_form\":\"Charlotte\",\n   \"admin_area\": \"TX\", \"popularity\": 1815, \"type\": \"city\",\n   \"location_coordinates\": \"28.86192,-98.70641\"},\n  {\"id\":\"4988584\", \"canonical_form\":\"Charlotte\", \"surface_form\":\"Charlotte\",\n   \"admin_area\": \"MI\", \"popularity\": 9054, \"type\": \"city\",\n   \"location_coordinates\": \"42.56365,-84.83582\"},\n  {\"id\":\"5234793\", \"canonical_form\":\"Charlotte\", \"surface_form\":\"Charlotte\",\n   \"admin_area\": \"VT\", \"popularity\": 3861, \"type\": \"city\",\n   \"location_coordinates\": \"44.30977,-73.26096\"}]}\n```", "```py\ndef generate_tagged_query(extracted_entities):  #1\n  query = extracted_entities[\"query\"]\n  last_end = 0\n  tagged_query = \"\"\n  for tag in extracted_entities[\"tags\"]:\n    next_text = query[last_end:tag[\"startOffset\"]].strip()\n    if len(next_text) > 0:\n      tagged_query += \" \" + next_text\n    tagged_query += \" {\" + tag[\"matchText\"] + \"}\"  #2\n    last_end = tag[\"endOffset\"]\n  if last_end < len(query):\n    final_text = query[last_end:len(query)].strip()\n    if len(final_text):\n      tagged_query += \" \" + final_text\n  return tagged_query\n\ntagged_query = generate_tagged_query(query_entities)\nprint(tagged_query)\n```", "```py\n{top} kimchi {near} {charlotte}\n```", "```py\ndef generate_query_tree(extracted_entities):\n  query = extracted_entities[\"query\"]\n  entities = {entity[\"id\"]: entity for entity  #1\n              in extracted_entities[\"entities\"]}  #1\n  query_tree = []\n  last_end = 0\n\n  for tag in extracted_entities[\"tags\"]:\n    best_entity = entities[tag[\"ids\"][0]]  #2\n    for entity_id in tag[\"ids\"]:  #2\n      if (entities[entity_id][\"popularity\"] >  #2\n          best_entity[\"popularity\"]):  #2\n        best_entity = entities[entity_id] #2\n\n    next_text = query[last_end:tag[\"startOffset\"]].strip()\n    if next_text:\n      query_tree.append({\"type\": \"keyword\",  #3\n                         \"surface_form\": next_text,  #3\n                         \"canonical_form\": next_text})  #3\n    query_tree.append(best_entity)  #4\n    last_end = tag[\"endOffset\"] \n\n  if last_end < len(query):  #5\n    final_text = query[last_end:len(query)].strip()  #5\n    if final_text:  #5\n      query_tree.append({\"type\": \"keyword\",  #5\n                         \"surface_form\": final_text,  #5\n                         \"canonical_form\": final_text})  #5\n  return query_tree\n\nparsed_query = generate_query_tree(query_entities)\ndisplay(parsed_query)\n```", "```py\n[{\"semantic_function\": \"popularity(query, position)\", \"popularity\": 100,\n  \"id\": \"7\", \"surface_form\": \"top\", \"type\": \"semantic_function\",\n  \"canonical_form\": \"{popular}\"},\n {\"type\": \"keyword\", \"surface_form\": \"kimchi\", \"canonical_form\": \"kimchi\"},\n {\"semantic_function\":\"location_distance(query, position)\", \"popularity\":90,\n  \"id\": \"1\", \"surface_form\": \"near\", \"type\": \"semantic_function\",\n  \"canonical_form\": \"{location_distance}\"},\n {\"country\": \"US\", \"admin_area\": \"NC\", \"popularity\": 827097,\n  \"id\": \"4460243\", \"surface_form\": \"Charlotte\", \"type\": \"city\",\n  \"location_coordinates\": \"35.22709,-80.84313\",\n  \"canonical_form\": \"Charlotte\"}]\n```", "```py\nSemantic Function Entities\n+-------+-------------------+----------+----------------------------------+\n|surface|canonical_form     |popularity|semantic_function                 |\n+-------+-------------------+----------+----------------------------------+\n|near   |{location_distance}|90        |location_distance(query, position)|\n|in     |{location_distance}|100       |location_distance(query, position)|\n|by     |{location_distance}|90        |location_distance(query, position)|\n|by     |{text_within_on...}|10        |text_within_one_edit_distance(...)|\n|near   |{text_distance}    |10        |text_distance(query, position)    |\n|popular|{popular}          |100       |popularity(query, position)       |\n|top    |{popular}          |100       |popularity(query, position)       |\n|best   |{popular}          |100       |popularity(query, position)       |\n|good   |{popular}          |100       |popularity(query, position)       |\n+-------+-------------------+----------+----------------------------------+\n```", "```py\ndef popularity(query, position):\n  if len(query[\"query_tree\"]) -1 > position:  #1\n    query[\"query_tree\"][position] = {\n      \"type\": \"transformed\",\n      \"syntax\": \"solr\",\n      \"query\": '+{!func v=\"mul(if(stars_rating,stars_rating,0),20)\"}'}  #2\n    return True  #3\n  return False  #3\n```", "```py\ndef location_distance(query, position):\n  if len(query[\"query_tree\"]) -1 > position:  #1\n    next_entity = query[\"query_tree\"][position + 1] #1\n    if next_entity[\"type\"] == \"city\": #2\n\n      query[\"query_tree\"].pop(position + 1)  #3\n      query[\"query_tree\"][position] = {  #4\n        \"type\": \"transformed\",  #4\n        \"syntax\": \"solr\",  #4\n        \"query\": create_geo_filter(  #4\n          next_entity['location_coordinates'],  #4\n          \"location_coordinates\", 50)}  #4\n      return True\n  return False  #5\n\ndef create_geo_filter(coordinates, field, distance_KM):\n  return f'+{!geofilt d={distance_KM} sfield=\"{field}\" pt=\"{coordinates}\"}'\n```", "```py\ndef process_semantic_functions(query_tree):\n  position = 0  #1\n  while position < len(query_tree):  #2\n    node = query_tree[position]  #2\n    if node[\"type\"] == \"semantic_function\":\n      query = {\"query_tree\": query_tree}  #1\n      command_successful = eval(node[\"semantic_function\"]) #3\n      if not command_successful:  #4\n        node[\"type\"] = \"invalid_semantic_function\"  #4\n    position += 1\n  return query_tree\n```", "```py\ndef get_enrichments(collection, keyword, limit=4):\n  enrichments = {}\n  nodes_to_traverse = [{\"field\": \"content\",  #1\n                        \"values\": [keyword],  #1\n                        \"default_operator\": \"OR\"},  #1\n                       [{\"name\": \"related_terms\",  #2\n                         \"field\": \"content\", #2\n                         \"limit\": limit},  #2\n                        {\"name\": \"doc_type\", #3\n                         \"field\": \"doc_type\", #3\n                         \"limit\": 1}]]  #3\n  skg = get_semantic_knowledge_graph(collection)\n  traversals = skg.traverse(*nodes_to_traverse)\n  if \"traversals\" not in traversals[\"graph\"][0][\"values\"][keyword]:\n    return enrichments  #4\n\n  nested_traversals = traversals[\"graph\"][0][\"values\"] \\\n                                [keyword][\"traversals\"]\n\n  doc_types = list(filter(lambda t: t[\"name\"] == \"doc_type\", #5\n                          nested_traversals))  #5\n  if doc_types:  #5\n    enrichments[\"category\"] = next(iter(doc_types[0][\"values\"]))  #5\n\n  related_terms = list(filter(lambda t: t[\"name\"] == \"related_terms\",  #6\n                              nested_traversals))  #6\n  if related_terms:  #6\n    term_vector = \"\"  #6\n    for term, data in related_terms[0][\"values\"].items():  #6\n      term_vector += f'{term}^{round(data[\"relatedness\"], 4)} '  #6\n    enrichments[\"term_vector\"] = term_vector.strip()  #6\n\n  return enrichments\n\nquery = \"kimchi\"  #7\nget_enrichments(reviews_collection, query)  #7\n```", "```py\n{\"category\": \"Korean\",\n \"term_vector\": \"kimchi^0.9193 korean^0.7069 banchan^0.6593 bulgogi^0.5497\"}\n```", "```py\n{\"category\": \"Barbeque\",\n \"term_vector\": \"bbq^0.9191 ribs^0.6187 pork^0.5992 brisket^0.5691\"}\n```", "```py\n{\"category\": \"Korean\",\n \"term_vector\": \"korean^0.7754 bbq^0.6716 banchan^0.5534 sariwon^0.5211\"}\n```", "```py\n{\"category\": \"Italian\",\n \"term_vector\": \"lasagna^0.9193 alfredo^0.3992 pasta^0.3909 \n               ↪italian^0.3742\"}\n```", "```py\n{\"category\": \"Karaoke\",\n \"term_vector\": \"karaoke^0.9193 sing^0.6423 songs^0.5256 song^0.4118\"}\n```", "```py\n{\"category\": \"Fast Food\",\n \"term_vector\": \"drive^0.7428 through^0.6331 mcdonald's^0.2873 \n                ↪window^0.2643\"}\n```", "```py\ndef enrich(collection, query_tree):\n  query_tree = process_semantic_functions(query_tree)  #1\n  for item in query_tree:\n\n    if item[\"type\"] == \"keyword\":  #2\n      enrichments = get_enrichments(collection, item[\"surface_form\"]) #2\n      if enrichments:  #3\n        item[\"type\"] = \"skg_enriched\"  #3\n        item[\"enrichments\"] = enrichments  #3\n  return query_tree\n```", "```py\nfrom spladerunner import Expander\nexpander = Expander('Splade_PP_en_v1', 128) #1\nqueries = [\"kimchi\", \"bbq\", \"korean bbq\",\n           \"lasagna\", \"karaoke\", \"drive through\"]\n\nfor query in queries:\n  sparse_vec = expander.expand(query,  #2\n                  outformat=\"lucene\")[0]  #3\n  print(sparse_vec)\n```", "```py\n{\"kim\": 3.11, \"##chi\": 3.04, \"ki\": 1.52, \",\": 0.92, \"who\": 0.72,\n \"brand\": 0.56, \"genre\": 0.46, \"chi\": 0.45, \"##chy\": 0.45, \n \"company\": 0.41,  \"only\": 0.39, \"take\": 0.31, \"club\": 0.25,\n \"species\": 0.22, \"color\": 0.16, \"type\": 0.15, \"but\": 0.13, \n \"dish\": 0.12, \"hotel\": 0.11, \"music\": 0.09, \"style\": 0.08, \n \"name\": 0.06, \"religion\": 0.01}\n```", "```py\n{\"bb\": 2.78, \"grill\": 1.85, \"barbecue\": 1.36, \"dinner\": 0.91, \n \"##q\": 0.78, \"dish\": 0.77, \"restaurant\": 0.65, \"sport\": 0.46,\n \"food\": 0.34, \"style\": 0.34, \"eat\": 0.24, \"a\": 0.23, \"genre\": 0.12, \n \"definition\": 0.09}\n```", "```py\n{\"korean\": 2.84, \"korea\": 2.56, \"bb\": 2.23, \"grill\": 1.58, \"dish\": 1.21,\n \"restaurant\": 1.18, \"barbecue\": 0.79, \"kim\": 0.67, \"food\": 0.64,\n \"dinner\": 0.39, \"restaurants\": 0.32, \"japanese\": 0.31, \"eat\": 0.27,\n \"hotel\": 0.16, \"famous\": 0.11, \"brand\": 0.11, \"##q\": 0.06, \"diner\": 0.02}\n```", "```py\n{\"las\": 2.87, \"##ag\": 2.85, \"##na\": 2.39, \",\": 0.84, \"she\": 0.5,\n \"species\": 0.34, \"hotel\": 0.33, \"club\": 0.31, \"location\": 0.3,\n \"festival\": 0.29, \"company\": 0.27, \"her\": 0.2, \"city\": 0.12, \n \"genre\": 0.05}\n```", "```py\n{\"kara\": 3.04, \"##oke\": 2.87, \"music\": 1.31, \"lara\": 1.07, \n \"song\": 1.03, \"dance\": 0.97, \"style\": 0.94, \"sara\": 0.81, \n \"genre\": 0.75, \"dress\": 0.48, \"dish\": 0.44, \"singer\": 0.37, \n \"hannah\": 0.36, \"brand\": 0.31, \"who\": 0.29, \"culture\": 0.21, \n \"she\": 0.17, \"mix\": 0.17, \"popular\": 0.12, \"girl\": 0.12,\n \"kelly\": 0.08, \"wedding\": 0.0}\n```", "```py\n{\"through\": 2.94, \"drive\": 2.87, \"driving\": 2.34, \"past\": 1.75,\n \"drives\": 1.65, \"thru\": 1.44, \"driven\": 1.22, \"enter\": 0.81,\n \"drove\": 0.81, \"pierce\": 0.75, \"in\": 0.72, \"by\": 0.71, \"into\": 0.64,\n \"travel\": 0.59, \"mark\": 0.51, \";\": 0.44, \"clear\": 0.41,\n \"transport\": 0.41, \"route\": 0.39, \"within\": 0.36, \"vehicle\": 0.3, \n \"via\": 0.15}\n```", "```py\ndef transform_query(query_tree):\n  for i, item in enumerate(query_tree):\n    match item[\"type\"]:\n      case \"transformed\":  #1\n        continue  #1\n      case \"skg_enriched\":  #2\n        enrichments = item[\"enrichments\"]  #2\n        if \"term_vector\" in enrichments:  #2\n          query_string = enrichments[\"term_vector\"]  #2\n          if \"category\" in enrichments: #2\n            query_string += f' +doc_type:\"{enrichments[\"category\"]}\"'  #2\n          transformed_query =   #2\n          ↪'+{!edismax v=\"' + escape_quotes(query_string) + '\"}'  #2\n        else:  #2\n          continue  #2\n      case \"color\":  #3\n        transformed_query = f'+colors:\"{item[\"canonical_form\"]}\"'\n      case \"known_item\" | \"event\":  #3\n        transformed_query = f'+name:\"{item[\"canonical_form\"]}\"'\n      case \"city\":  #3\n        transformed_query = f'+city:\"{str(item[\"canonical_form\"])}\"'\n      case \"brand\":  #3\n        transformed_query = f'+brand:\"{item[\"canonical_form\"]}\"'\n      case _:  #4\n        transformed_query = \"+{!edismax v=\\\"\" +  #4\n        ↪escape_quotes(item[\"surface_form\"]) + \"\\\"}\"  #4\n    query_tree[i] = {\"type\": \"transformed\",  #5\n                     \"syntax\": \"solr\",  #5\n                     \"query\": transformed_query}  #5\n  return query_tree\n\nenriched_query_tree = enrich(reviews_collection, query_tree)\nprocessed_query_tree = transform_query(enriched_query_tree)\ndisplay(processed_query_tree)\n```", "```py\n[{\"type\": \"transformed\",\n  \"syntax\": \"solr\",\n  \"query\": \"+{!func v=\\\"mul(if(stars_rating,stars_rating,0),20)\\\"}\"},\n {\"type\": \"transformed\",\n  \"syntax\": \"solr\",\n  \"query\": \"{!edismax v=\\\"kimchi^0.9193 korean^0.7069 banchan^0.6593\n  ↪+doc_type:\\\\\\\"Korean\\\\\\\"\\\"}\"},\n {\"type\": \"transformed\",\n  \"syntax\": \"solr\",\n  \"query\": \"+{!geofilt d=50 sfield=\\\"location_coordinates\\\"\n  ↪pt=\\\"35.22709,-80.84313\\\"}\"}]\n```", "```py\ndef to_query(query_tree):\n  return [[node[\"query\"] for node in query_tree]\n\ntransformed_query = to_query(query_tree)\nreviews_collection = engine.get_collection(\"reviews\")\nreviews_collection.search(query=transformed_query)\n```"]