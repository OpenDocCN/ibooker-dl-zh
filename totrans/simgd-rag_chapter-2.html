<?xml version="1.0" encoding="utf-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd"><html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <title>chapter-2</title>
  <link href="../../stylesheet.css" rel="stylesheet" type="text/css" />
 </head>
 <body>
  <div class="readable-text" id="p1"> 
   <h1 class=" readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">2</span> </span><span class="chapter-title-text"><span class="CharOverride-1"></span>RAG systems and their design</span></h1> 
  </div> 
  <div class="introduction-summary"> 
   <h3 class="introduction-header"><span class="CharOverride-2">This chapter covers</span></h3> 
   <ul> 
    <li class="readable-text" id="p2"><span class="CharOverride-3">The concept and design of RAG systems</span></li> 
    <li class="readable-text" id="p3"><span class="CharOverride-3">An overview of the indexing pipeline</span></li> 
    <li class="readable-text" id="p4"><span class="CharOverride-3">An overview of the generation pipeline</span></li> 
    <li class="readable-text" id="p5"><span class="CharOverride-3">An initial look at RAG evaluation</span></li> 
    <li class="readable-text" id="p6"><span class="CharOverride-3">A high-level look at the RAG operations stack</span></li> 
   </ul> 
  </div> 
  <div class="readable-text" id="p7"> 
   <p>The first chapter explored the core principles behind retrieval-augmented generation (RAG) and the large language model (LLM) challenges addressed by it. To construct a RAG system, several components need to be assembled. This process includes the creation and maintenance of the non-parametric memory, or a knowledge base, for the system. Another pipeline facilitates real-time interaction by sending the prompts to and accepting the response from the LLM, with retrieval and augmentation steps in the middle. Evaluation is yet another critical component, ensuring the effectiveness and accuracy of the system. All these components are supported by layers of the operations stack.</p> 
  </div> 
  <div class="readable-text intended-text" id="p8"> 
   <p>Chapter 2 discusses the design of a RAG system, examining the steps involved and the need for two different pipelines. We will call the pipeline that creates the knowledge base the “indexing pipeline.” The other pipeline that allows real-time interaction with the LLM will be referred to as the “generation pipeline.” We will discuss their individual components, such as data loading, embeddings, vector stores, retrievers, and more. Additionally, we will get an understanding of how the evaluation of RAG systems is conducted and introduce the RAG operations (RAGOps) stack that powers such systems.</p> 
  </div> 
  <div class="readable-text intended-text" id="p9"> 
   <p>This chapter will introduce you to various components discussed in detail in the coming chapters. By the end of chapter 2, you will have acquired a deep understanding of the components of a RAG system and will be ready to dive deep into the different components. By the end of the chapter, you should</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p10">Be able to understand the several components of the RAG system design.</li> 
   <li class="readable-text" id="p11">Set yourself up for a deeper exploration of the indexing pipeline—the generation pipelines, RAG evaluation methods, and the RAGOps stack.</li> 
  </ul> 
  <div class="readable-text" id="p12"> 
   <h2 class=" readable-text-h2"><span class="num-string">2.1</span> What does a RAG system look like?</h2> 
  </div> 
  <div class="readable-text" id="p13"> 
   <p>By now, we have come to know that RAG is a vital component of the systems that use LLMs to solve their use cases. But, what is that system like? To illustrate, let’s revisit the example used at the beginning chapter 1 (“Who won the 2023 Cricket World Cup?”) and lay out the steps we undertook to enable ChatGPT to provide us with the accurate response.</p> 
  </div> 
  <div class="readable-text intended-text" id="p14"> 
   <p>The initial step was asking the question itself: “Who won the 2023 Cricket World Cup?” Following this, we manually searched for sources on the internet that might have information regarding the answer to the question. We found one (Wikipedia, in our example) and extracted a relevant paragraph from the source. Subsequently, we added the relevant paragraph to our original question, pasted the question and the retrieved paragraph together in the prompt to ChatGPT, and got a factually correct response: “Australia won the 2023 Cricket World Cup.”</p> 
  </div> 
  <div class="readable-text intended-text" id="p15"> 
   <p>This process can be distilled into five steps, and our system needs to facilitate all of them:</p> 
  </div> 
  <ol> 
   <li class="readable-text" id="p16">User asks a question.</li> 
   <li class="readable-text" id="p17">The system searches for information relevant to the input question.</li> 
   <li class="readable-text" id="p18">The information relevant to the input question is fetched, or retrieved, and added to the input question.</li> 
   <li class="readable-text" id="p19">This question and information are passed to an LLM.</li> 
   <li class="readable-text" id="p20">The LLM responds with a contextual answer.</li> 
  </ol> 
  <div class="readable-text" id="p21"> 
   <p>If you recall, we have already described this process in chapter 1. Let’s visualize it in the context of these five steps as shown in figure 2.1. This workflow will be called the “generation pipeline” since it generates the answer. </p> 
  </div> 
  <div class="browsable-container figure-container " id="p22">  
   <img src="../Images/CH02_F01_Kimothi.png" alt="A diagram of a process

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 2.1</span><span class=""> </span><span class="">Generation pipeline covering the five RAG steps. The journey from query to the response involves search and retrieval, augmentation, and generation.</span></h5>
  </div> 
  <div class="readable-text" id="p23"> 
   <p>This pipeline enables real-time contextual interaction with the LLM. There are, of course, several intricacies in each of the five steps needed to create the generation pipeline. Some decisions need to be made about the design of the retriever and the LLM choice. The construction of prompts will also affect the quality of the response. We will discuss prompt construction in chapter 3. We first must address a critical pre-requisite step before this generation pipeline can be put in place. For that, some key questions regarding the external source of information need to be answered. We will also need to know, in advance, where to look and then establish connections to all these disparate sources:</p> 
  </div> 
  <ul> 
   <li class="readable-text buletless-item" id="p24">What is the location of the external source of information? 
    <ul> 
     <li>Is it the open internet? Or are there some documents in the company’s internal data storage? Is the information present in some third-party databases? Are there multiple sources we want to use? </li> 
     <li>Why is this important?</li> 
    </ul> </li> 
   <li class="readable-text buletless-item" id="p25">What is the nature of the information at the source? 
    <ul> 
     <li>Are these Word documents or PDF files? Is the information accessed via an API, and the response is in JSON format? Will we find answers in one document, or is the information distributed in multiple documents? </li> 
     <li>Why is this important? </li> 
    </ul> </li> 
  </ul> 
  <div class="readable-text" id="p26"> 
   <p>We will also need to know the format and nature of data storage to be able to extract the information from the source files.</p> 
  </div> 
  <div class="readable-text intended-text" id="p27"> 
   <p>When data is stored across multiple sources, such as the internet and an internal data lake, the system must connect to each source, search for relevant information in various formats, and organize it according to the original query. Every time a question is asked, this process of connecting, extracting, and parsing will have to be repeated. Information from different sources may lead to factual inconsistencies that will have to be resolved in real time. Searching through all the information might be prohibitively time-consuming. This will, therefore, prove to be a highly suboptimal, unscalable process that may not yield the desired results. A RAG system will work best if the information from different sources is</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p28">Collected in a single location.</li> 
   <li class="readable-text" id="p29">Stored in a single format.</li> 
   <li class="readable-text" id="p30">Broken down into small pieces of information.</li> 
  </ul> 
  <div class="readable-text" id="p31"> 
   <p>The need for a consolidated knowledge base arises from the disparate nature of external data sources. To address this requirement, we need to undertake a series of steps to create and maintain a well-structured knowledge base. This, again, is a five-step process:</p> 
  </div> 
  <ol> 
   <li class="readable-text" id="p32">Connect to previously identified external sources.</li> 
   <li class="readable-text" id="p33">Extract documents and parse text from them.</li> 
   <li class="readable-text" id="p34">Break down long pieces of text into smaller, manageable pieces.</li> 
   <li class="readable-text" id="p35">Convert these small pieces into a suitable format.</li> 
   <li class="readable-text" id="p36">Store this information.</li> 
  </ol> 
  <div class="readable-text" id="p37"> 
   <p>These steps, which facilitate the creation of this knowledge base, form the <em>indexing pipeline</em>. The indexing pipeline is shown in figure 2.2.</p> 
  </div> 
  <div class="readable-text" id="p38"> 
   <p>In addition to creating the knowledge base, the indexing pipeline plays a crucial role in maintaining and updating it with the latest information to ensure its relevance and accuracy. Before the knowledge base is created by the indexing pipeline, there is nowhere for the generation pipeline to search for information. It is the indexing pipeline that lays the foundation for the subsequent operation of the generation pipeline. Therefore, setting up the indexing pipeline comes before the generation pipeline can be activated. </p> 
  </div> 
  <div class="readable-text intended-text" id="p39"> 
   <p>Together, these pipelines form the backbone of a RAG system, enabling seamless interaction with users and delivering contextually relevant responses. Figure 2.3 shows the indexing and generation pipelines working together to form the skeleton of a RAG system.</p> 
  </div> 
  <div class="readable-text" id="p40"> 
   <p>We have established the flow of a RAG system that includes two pipelines. Conceptually, this is the complete flow. However, to build such systems to be used in the real world, more components are required. The next section reimagines this flow along with other considerations and creates a design for RAG systems.</p> 
  </div> 
  <div class="browsable-container figure-container " id="p41">  
   <img src="../Images/CH02_F02_Kimothi.png" alt="A diagram of a diagram

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 2.2</span><span class=""> </span><span class="">Indexing pipeline covering the steps to create the knowledge base for RAG. This involves connecting to the source, parsing, splitting, converting, and storing information.</span></h5>
  </div> 
  <div class="browsable-container figure-container " id="p42">  
   <img src="../Images/CH02_F03_Kimothi.png" alt="A diagram of a knowledge base

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 2.3</span><span class=""> </span><span class="">The indexing and generation pipelines together make a RAG system. The indexing pipeline is an offline process, while the generation pipeline facilitates real-time interaction with the knowledge base.</span></h5>
  </div> 
  <div class="readable-text" id="p43"> 
   <h2 class=" readable-text-h2"><span class="num-string">2.2</span> Design of RAG systems</h2> 
  </div> 
  <div class="readable-text" id="p44"> 
   <p>We saw how RAG systems are created by the indexing and generation pipelines. These two pipelines include several parts themselves. Like all software applications, production-ready RAG systems require more than just the basic components. We need to think about accuracy, observability, scalability, and other important factors. This book discusses some of these components at length. Figure 2.4 presents a rough layout of a RAG system. Apart from the indexing and generation component, we’ll add layers for infrastructure, security, evaluation, etc.</p> 
  </div> 
  <div class="browsable-container figure-container " id="p45">  
   <img src="../Images/CH02_F04_Kimothi.png" alt="A diagram of a company

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 2.4</span><span class=""> </span><span class="">Components of a production-ready RAG system</span></h5>
  </div> 
  <div class="readable-text" id="p46"> 
   <p>Let’s look at the main components of a RAG system. The first four components complete the indexing pipeline:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p47"><em>Data-loading componen</em><em>t</em>—Connects to external sources, and extracts and parses data</li> 
   <li class="readable-text" id="p48"><em>Data-splitting componen</em><em>t</em>—Breaks down large pieces of text into smaller, manageable parts</li> 
   <li class="readable-text" id="p49"><em>Data conversion componen</em><em>t</em>—Converts text data into a more suitable format</li> 
   <li class="readable-text" id="p50"><em>Storage componen</em><em>t</em>—Stores the data to create a knowledge base for the system</li> 
  </ul> 
  <div class="readable-text" id="p51"> 
   <p>These next three components complete the generation pipeline:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p52"><em>Retriever</em><em>s</em>—Responsible for searching and fetching information from the storage</li> 
   <li class="readable-text" id="p53"><em>LLM setu</em><em>p</em>—Responsible for generating the response to the input</li> 
   <li class="readable-text" id="p54"><em>Prompt management</em>—Enables the augmentation of the retrieved information to the original input</li> 
  </ul> 
  <div class="readable-text" id="p55"> 
   <p>The evaluation component measures the accuracy and reliability of the system before and after deployment. The monitoring component tracks the performance of the RAG system and helps detect failures. Other components include caching, which helps store previously generated responses to expedite retrieval for similar queries; guardrails, to ensure compliance with policy, regulation, and social responsibility; and security, to protect LLMs against breaches such as prompt injection, data poisoning, and similar. All the layers are supported by a service infrastructure. </p> 
  </div> 
  <div class="readable-text intended-text" id="p56"> 
   <p>All these components are managed and controlled by a central orchestration layer, which is responsible for their interaction and sequencing. It provides a unified interface for managing and monitoring workflows and processes.</p> 
  </div> 
  <div class="readable-text intended-text" id="p57"> 
   <p>The following sections provide an overview of these components before we examine them in depth in subsequent chapters.</p> 
  </div> 
  <div class="readable-text" id="p58"> 
   <h2 class=" readable-text-h2"><span class="num-string">2.3</span> Indexing pipeline</h2> 
  </div> 
  <div class="readable-text" id="p59"> 
   <p>We discussed how the indexing pipeline facilitates the creation of the knowledge base used in the real-time generation pipeline. For practical purposes, the indexing pipeline is an offline or asynchronous pipeline. What this means is that the indexing pipeline is not activated in real time when the user is asking a question. Rather, it creates the knowledge base in advance and updates it at predefined intervals. The indexing pipeline comprises four main components, as seen in figure 2.5.</p> 
  </div> 
  <div class="browsable-container figure-container " id="p60">  
   <img src="../Images/CH02_F05_Kimothi.png" alt="A close-up of a diagram

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 2.5</span><span class=""> </span><span class="">Four components of the indexing pipeline facilitate the creation of the knowledge base.</span></h5>
  </div> 
  <div class="readable-text" id="p61"> 
   <p>Let’s delve deeper into each:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p62"><em>Data splitting (text splitting</em><em>)</em><em>—</em>Breaking down text into smaller segments enhances the system’s ability to process and analyze information efficiently. These smaller pieces in natural language processing (NLP) parlance are commonly referred to as “chunks.” The process of splitting large text documents into smaller chunks is called “chunking.” We will discuss the need for chunking and various chunking strategies in chapter 3.</li> 
   <li class="readable-text" id="p63"><em>Data conversion (embeddings</em><em>)</em><em>—</em>Textual data must be converted to a numerical format for search and retrieval computations in RAG systems. There are different ways of implementing this conversion. For all practical purposes, a data format called “embeddings” works best for search and retrieval. You will learn more about embeddings and different embedding models in chapter 3.</li> 
   <li class="readable-text" id="p64"><em>Data storag</em><em>e</em><em>—</em>Once the data is ready in the desired format (embeddings), it needs to be stored in persistent (permanent) memory so that the real-time generation pipeline can access data whenever a user asks a question. Data is stored in specialized databases known as “vector databases,” which are best suited for search and retrieval of embeddings. Chapter 3 explores various vector databases and factors influencing their suitability for RAG systems.</li> 
  </ul> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p65"> 
    <h5 class=" callout-container-h5 readable-text-h5">Do you always need an indexing pipeline?</h5> 
   </div> 
   <div class="readable-text" id="p66"> 
    <p>Offline indexing pipelines are typically used when a knowledge base with a large amount of data is built for repeated usage (e.g., many enterprise documents, manuals, etc.). However, there are some cases in which the generation pipeline connects to a third-party API to receive information related to the user question. </p> 
   </div> 
   <div class="readable-text" id="p67"> 
    <p>For example, imagine an application built for users seeking travel advice based on the weather forecast. An important component of this application will be fetching the weather details for the users’ location. Suppose the system uses a third-party API service that can respond with a location’s weather details when provided with the location in the input. This weather information is then passed to the LLM to generate the advice. </p> 
   </div> 
   <div class="readable-text" id="p68"> 
    <p>This application can also be thought of as a RAG system. But there is a difference. This system has outsourced the search and retrieval operation to the third-party API. It is the third party that maintains the data. For such systems, the indexing pipeline is not required to be built since the search and retrieval happens outside the system. Another example is applications that ask the user to input external information, like document summarizers. The search operation here is outsourced to the user. </p> 
   </div> 
   <div class="readable-text" id="p69"> 
    <p>Therefore, systems that use augment external information to the prompts but do not necessarily search and retrieve information themselves, do not warrant the creation of a knowledge base, and therefore, do not have an indexing pipeline. Some will argue that such systems are not RAG systems in the first place. </p> 
   </div> 
  </div> 
  <div class="readable-text" id="p70"> 
   <h2 class=" readable-text-h2"><span class="num-string">2.4</span> Generation pipeline</h2> 
  </div> 
  <div class="readable-text" id="p71"> 
   <p>Building on the foundation established by the indexing pipeline, the generation pipeline facilitates real-time interactions in RAG systems. It is the generation pipeline that facilitates the retrieval, augmentation, and generation in the system. When a user asks a question, the generation pipeline processes the query, retrieves relevant information, and generates a response—all without the user directly interacting with the underlying indexing pipeline. The generation pipeline is enabled by three components, as seen in figure 2.6.</p> 
  </div> 
  <div class="browsable-container figure-container " id="p72">  
   <img src="../Images/CH02_F06_Kimothi.png" alt="A screenshot of a computer

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 2.6</span><span class=""> </span><span class="">Three components of the generation pipeline enable the real-time query-response process of a RAG system.</span></h5>
  </div> 
  <div class="readable-text" id="p73"> 
   <p>Let’s consider each of these in some more detail:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p74"><em>The retriever—</em>This is arguably the most critical component of the entire system. Using advanced search algorithms, the retriever scans the knowledge base to identify and retrieve the most relevant information based on the user’s query. The overall effectiveness of the entire system relies heavily on the accuracy of the retriever. Also, search is a computationally heavy operation and may take time. Therefore, the retriever also contributes heavily to the overall latency of the system. We will discuss different retrievers and retrieval strategies in chapters 4 and 6.</li> 
   <li class="readable-text" id="p75"><em>Prompt management—</em>Once the relevant information is retrieved by the retriever, it needs to be combined, or augmented, with the original user query. Now, this may seem like a simple task at first glance. However, the construction of the prompt makes significant difference to the quality of the generated response. This component also falls in the gambit of prompt engineering. We will explore different prompting and prompt management strategies in chapter 4.</li> 
   <li class="readable-text" id="p76"><em>LLM setu</em><em>p</em><em>—</em>At the end, LLMs are responsible for generating the final response. A RAG system may rely on more than one LLM. The LLMs can be the foundation (base) models that have been pretrained and generally available either open source, like those by Meta or Mistral, or through a managed service, like OpenAI or Anthropic. LLMs can also be fine-tuned for specific tasks. Fine-tuning involves training pre-existing LLMs on specific datasets or tasks to improve performance and adaptability for specialized applications. In rare cases, the developer may decide to train their LLMs. We will discuss LLMs in depth in chapter 4.</li> 
  </ul> 
  <div class="readable-text" id="p77"> 
   <h2 class=" readable-text-h2"><span class="num-string">2.5</span> Evaluation and monitoring</h2> 
  </div> 
  <div class="readable-text" id="p78"> 
   <p>Indexing and generation pipelines complete the system from a usage perspective. With these two pipelines in place, at least in theory, a user can start interacting with the system and get responses. However, in this case, we have no measure of the system quality. Is the system performing accurately, or is it still prone to hallucinations? Is the information that is being fetched by the retriever the most relevant to the query? To answer these questions, we have to put in place an evaluation framework. This framework helps in evaluating the quality of the system before it is released and then for continuous monitoring and improvement.</p> 
  </div> 
  <div class="readable-text intended-text" id="p79"> 
   <p>Building on the advancements of LLMs, RAG represents a recent innovation in NLP. Metrics such as relevance scores, recall, and precision are commonly used to evaluate the effectiveness of RAG systems. One framework that intuitively guides a comprehensive evaluation is the triad of RAG metrics proposed by TruEra (<a href="https://mng.bz/Mw22"><span class="Hyperlink">https:</span><span class="Hyperlink">/</span><span class="Hyperlink">/mng.bz/Mw22</span></a>). It looks at the RAG evaluation through three dimensions, as shown in <br />figure 2.7.</p> 
  </div> 
  <div class="readable-text" id="p80"> 
   <p>The workflow involves checks in between each step—prompt, context, and answer. Let’s take a closer look:</p> 
  </div> 
  <div class="browsable-container figure-container " id="p81">  
   <img src="../Images/CH02_F07_Kimothi.png" alt="A diagram of a customer relationship management

AI-generated content may be incorrect." style="width: 100%; max-width: max-content;" /> 
   <h5 class=" figure-container-h5"><span class="">Figure 2.7</span><span class=""> </span><span class="">The triad of RAG evaluation proposed by TruEra. The three pivotal dimensions of RAG evaluation are the query, context, and response.</span></h5>
  </div> 
  <ul> 
   <li class="readable-text" id="p82"><em>Between the retrieved information (context) and the user query (prompt</em><em>)</em><em>—</em>Is the information being searched and retrieved by the retriever the most relevant to the question the user has asked? The consequence of irrelevant information being retrieved is that no matter how good the LLM is, if the information being augmented is not good, the response will be suboptimal.</li> 
   <li class="readable-text" id="p83"><em>Between the final response (answer) and the retrieved information (context</em><em>)</em>—Does the LLM consider all the retrieved information while generating responses? Even </li> 
   <li class="readable-text" id="p84">though RAG is aimed at reducing hallucinations, the system might still ignore the retrieved information. There are several reasons for it, which will be discussed in subsequent chapters.</li> 
   <li class="readable-text" id="p85"><em>Between the final response (answer) and the user query (prompt</em><em>)</em><em>—</em>Is the final response in line with the question the user had originally asked? To assess the overall effectiveness of the system, the relevance of the final response to the original question is necessary.</li> 
  </ul> 
  <div class="readable-text" id="p86"> 
   <p>There are several metrics that help assess each of these three dimensions. For some of the metrics, a ground truth dataset is warranted. Ground truth datasets provide a benchmark for evaluating the accuracy and effectiveness of RAG systems by comparing generated responses to manually curated references. We will take a deeper look at these metrics and the ground truth dataset in chapter 5. </p> 
  </div> 
  <div class="readable-text intended-text" id="p87"> 
   <p>Continuous evaluation of metrics during live operation can identify the types of queries the system struggles to answer accurately. Qualitative feedback can also be collected from the user on the generated responses.</p> 
  </div> 
  <div class="readable-text" id="p88"> 
   <h2 class=" readable-text-h2"><span class="num-string">2.6</span> The RAGOps Stack</h2> 
  </div> 
  <div class="readable-text" id="p89"> 
   <p>RAG, and LLM-based apps in general, are being powered by an evolving operations stack. Various providers offer infrastructure components such as data storage platforms, model hosting services, and application orchestration frameworks. The infrastructure can be understood in several layers:</p> 
  </div> 
  <ol> 
   <li class="readable-text" id="p90"><em>Data laye</em><em>r</em>—Tools and platforms used to process and store data in the form of embeddings</li> 
   <li class="readable-text" id="p91"><em>Model laye</em><em>r</em>—Providers of proprietary or open source LLMs</li> 
   <li class="readable-text" id="p92"><em>Prompt laye</em><em>r</em>—Tools offering maintenance and evaluation of prompts</li> 
   <li class="readable-text" id="p93"><em>Evaluation laye</em><em>r</em>—Tools and frameworks providing evaluation metrics for RAG</li> 
   <li class="readable-text" id="p94"><em>App orchestratio</em><em>n</em>—Frameworks that facilitate invocation of different components of the system</li> 
   <li class="readable-text" id="p95"><em>Deployment laye</em><em>r</em>—Cloud providers and platforms for deploying RAG apps</li> 
   <li class="readable-text" id="p96"><em>Application laye</em><em>r</em>—Hosting services for RAG apps</li> 
   <li class="readable-text" id="p97"><em>Monitoring laye</em><em>r</em>—Platforms offering continuous monitoring of RAG apps</li> 
  </ol> 
  <div class="readable-text" id="p98"> 
   <p>Chapter 7 explores the various layers of infrastructure that support RAG systems.</p> 
  </div> 
  <div class="readable-text" id="p99"> 
   <h2 class=" readable-text-h2"><span class="num-string">2.7</span> Caching, guardrails, security, and other layers</h2> 
  </div> 
  <div class="readable-text" id="p100"> 
   <p>Finally, there are certain other components frequently used in RAG systems. These components address the problems of system latency, regulatory and ethical compliances among other aspects.</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p101"><em>Cachin</em><em>g</em>—Caching is the process in which certain data is stored in cache memory for faster retrieval. LLM caching is slightly different from regular caching. The LLM responses to queries are stored in a semantic cache. Next time a similar query is asked, the response from the cache is retrieved instead of sending the query through the complete RAG pipeline. This approach improves the performance of the system by reducing the time it takes to respond, the cost of LLM inferencing, and the load on the LLM service.</li> 
   <li class="readable-text" id="p102"><em>Guardrail</em><em>s</em>—For several use cases, in practice, there will be a set of boundaries within which the output needs to be generated. Guardrails are a predefined set of rules added in the system to comply with policies, regulations, and ethical guidelines. </li> 
   <li class="readable-text" id="p103"><em>Securit</em><em>y</em>—LLMs and LLM-based applications have witnessed new threats, such as prompt injections, data poisoning, sensitive information disclosure, and others. With evolving threats, the security infrastructure also needs to evolve to address concerns around security and data privacy of RAG systems. </li> 
  </ul> 
  <div class="readable-text" id="p104"> 
   <p>RAGOps has also been evolving fast. Logging and tracing, model versioning, and feedback layers are some of the RAGOps stack components. </p> 
  </div> 
  <div class="readable-text intended-text" id="p105"> 
   <p>This chapter provided an overview of the key components of RAG systems, including the indexing and generation pipelines, evaluation and monitoring, and service infrastructure. By understanding these components, you are now equipped to delve deeper into each of these components and the intricacies of RAG systems in subsequent chapters. In the next chapter, we will start building the indexing pipeline to create a knowledge base of our RAG system.</p> 
  </div> 
  <div class="readable-text" id="p106"> 
   <h2 class=" readable-text-h2">Summary</h2> 
  </div> 
  <ul> 
   <li class="readable-text" id="p107">A RAG-enabled system consists of two main pipelines: the indexing and the generation pipeline.</li> 
   <li class="readable-text" id="p108">The indexing pipeline is responsible for creating and maintaining the knowledge base, which involves data loading, text splitting, data conversion (embeddings), and data storage in a vector database.</li> 
   <li class="readable-text" id="p109">The generation pipeline manages real-time interactions by retrieving information, augmenting queries, and generating responses using an LLM.</li> 
   <li class="readable-text" id="p110">Evaluation and monitoring are crucial components for the assessment of system performance, covering the relevance between the retrieved information and query, the final response and retrieved information, and the final response and the original query.</li> 
   <li class="readable-text" id="p111">The service infrastructure for RAG systems includes layers for data, models, prompts, evaluation, app orchestration, deployment, application hosting, and monitoring.</li> 
   <li class="readable-text" id="p112">Additional components such as caching, guardrails, and security measures are often employed to improve performance, ensure compliance, and address potential threats. </li> 
  </ul>
 </body>
</html>