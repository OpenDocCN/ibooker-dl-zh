- en: Appendix B. Answer Keys
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chapter 3 Answer Key
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'C: Content moderation is the AI workload specifically designed to detect and
    filter harmful or inappropriate content online. Regarding the other choices, knowledge
    mining extracts insights from large datasets, generative AI produces new content,
    and document intelligence focuses on data extraction from documents.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: AI personalization aims to recommend content that aligns with a user’s preferences
    and behavior, enhancing their experience by making interactions more relevant.
    Generating new images (choice B) is a function of generative AI, not personalization.
    Detecting harmful content (choice C) falls under content moderation, which focuses
    on safety rather than tailoring content. Analyzing human language (choice D) is
    part of natural language processing, not personalization.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: Natural language processing (NLP) is the AI workload dedicated to analyzing,
    interpreting, and generating human language. Content moderation (choice B) focuses
    on identifying and filtering inappropriate material, not understanding language.
    Computer vision (choice C) deals with recognizing and interpreting images and
    videos not text. Document intelligence (choice D) is used to extract information
    from documents but is not specialized in analyzing or generating language itself.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Computer vision is the AI workload that uses Optical Character Recognition
    (OCR) to extract text from images. NLP focuses on analyzing language rather than
    image content, knowledge mining derives insights from data but not from images,
    and generative AI creates new content without performing OCR or text extraction
    tasks.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Knowledge mining is the AI workload used to uncover insights from unstructured
    data like text and videos. Document intelligence (choice A) focuses on processing
    structured documents, not broad unstructured data analysis. Computer vision (choice
    C) handles interpreting images and videos but does not extract generalized insights.
    NLP (choice D) specializes in language tasks and is not designed for mining insights
    across various types of unstructured data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Generative AI is the workload designed to create entirely new content such
    as text and images. While NLP can process and generate human language, it doesn’t
    focus on producing original multimedia content. Similarly, knowledge mining is
    used for extracting insights, and document intelligence works with existing documents—neither
    of which involves generating new material.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: The Analyze Text API is the Azure AI Content Safety tool used specifically
    to detect harmful content in text. In contrast, the Analyze Image API focuses
    on scanning images, the Custom Categories API helps define new content categories
    without scanning text, and the Moderate Text API provides broader moderation but
    not targeted harmful content detection like Analyze Text does.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: Fairness is the responsible AI principle that ensures systems operate safely
    and equitably across all demographic groups. Transparency (choice B) focuses on
    making AI systems understandable to users, not necessarily on eliminating bias.
    Inclusiveness (choice C) aims to make AI accessible to a broad range of users
    but does not guarantee fairness in outcomes. Accountability (choice D) ensures
    developers are responsible for the AI’s behavior but does not specifically address
    equal treatment across groups.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Computer vision is the AI workload focused on analyzing and interpreting
    visual content like images and videos. NLP (choice A) is concerned with language
    processing, not visual analysis. Knowledge mining (choice B) uncovers insights
    from data but does not specialize in interpreting visual content. Generative AI
    (choice D) creates new content, such as text or images, but is not primarily focused
    on analyzing existing visual media.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: Document intelligence is the AI workload specifically designed to process
    large volumes of documents and extract key information. In contrast, NLP focuses
    on understanding and generating human language, generative AI creates new content
    rather than processing documents, and content moderation filters harmful material
    without handling document data extraction.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 4 Answer Key
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'C: The primary purpose of regression analysis in machine learning is to predict
    a numerical outcome based on input variables. Classification (choice A) categorizes
    data into distinct classes rather than predicting continuous values. Clustering
    (choice B) groups similar data points without making numerical predictions. Image
    and video analysis (choice D) are tasks handled by deep learning models, not regression
    analysis.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Predicting house prices based on features is an example of supervised learning
    because it involves using labeled data to train a model to predict specific outcomes.
    In contrast, K-means and customer segmentation are unsupervised methods that group
    data without predefined labels, and anomaly detection can fall under unsupervised
    or semisupervised learning depending on the context.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Logistic regression is the algorithm commonly used to predict probabilities
    between two classes in binary classification tasks. Linear regression (choice
    A) predicts continuous values, not probabilities. Decision trees (choice C) can
    classify data but do not inherently output probability scores. K-means (choice
    D) is used for clustering similar data points, not for classification or probability
    prediction.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: The F1 score involves a balance between precision and recall, offering a
    single metric that accounts for both false positives and false negatives. Distinguishing
    between classes (choice A) is typically measured by the area under the curve (AUC),
    not the F1 score. The average of prediction errors (choice B) is evaluated using
    mean error metrics like MSE or MAE, which apply to regression tasks. Total accuracy
    (choice D) measures overall correctness but does not specifically balance precision
    and recall like the F1 score does.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Inferencing is the step in the machine learning workflow where the trained
    model is used to generate predictions on new data. Training is focused on developing
    the model’s ability to learn patterns, validation is used to evaluate performance,
    and data preparation involves cleaning and organizing data for use in the model—none
    of which directly produce predictions like inferencing does.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: K-means clustering is associated with unsupervised learning, where the algorithm
    groups data based on similarities without relying on labeled examples. Supervised
    learning (choice A) requires labeled data for training, while semisupervised learning
    (choice B) uses a mix of labeled and unlabeled data. Reinforcement learning (choice
    C) focuses on learning through actions and rewards, not clustering or grouping
    data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: The coefficient of determination (*R²*) measures how well a regression model
    explains the variation in the data. Mean squared error (MSE) (choice A) focuses
    on the magnitude of large prediction errors rather than explanatory power. Root
    mean squared error (RMSE) (choice C) reports prediction errors in the original
    units of the data. Mean absolute error (MAE) (choice D) averages the absolute
    differences between predictions and actual values but does not indicate how much
    variance the model explains.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Predictive imputation addresses missing data by estimating values based
    on patterns found in the available data. Mean imputation (choice A) simply replaces
    missing values with the mean, without considering underlying relationships. Removal
    of incomplete data (choice C) can introduce bias and reduce the dataset’s quality.
    Data normalization (choice D) adjusts the scale of data but does not handle missing
    values.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: The primary goal of classification in machine learning is to assign data
    points to predefined categories based on labeled data. Identifying hidden patterns
    in unlabeled data (choice A) is the purpose of clustering, not classification.
    Predicting numerical outcomes (choice B) is handled by regression tasks. Generating
    new content (choice D) is a function of generative AI, not classification.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Clustering is the machine learning technique used to group similar data
    points without relying on labels. Regression (choice A) focuses on predicting
    numerical values rather than grouping data. Classification (choice B) requires
    labeled examples to assign data points to predefined categories. Deep learning
    (choice D) handles complex tasks like image or speech recognition but is not specifically
    focused on grouping unlabeled data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 5 Answer Key
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'B: Regression is the machine learning technique commonly used to predict a
    numerical outcome based on known variables. Classification (choice A) assigns
    data to categories rather than predicting continuous values. Clustering (choice
    C) groups similar data points without making predictions. Deep learning (choice
    D) can perform many tasks but is not specifically focused on straightforward numerical
    prediction like regression is.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Mean absolute error (MAE) measures the average error in predictions, treating
    all deviations equally regardless of whether they are positive or negative. Mean
    squared error (MSE) (choice A) exaggerates larger errors by squaring them. The
    coefficient of determination (*R²*) (choice B) measures how well the model explains
    the variance in the data, not the size of errors. Root mean squared error (RMSE)
    (choice D) reports errors in original units but still emphasizes larger errors
    through squaring.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Logistic regression is the most commonly used algorithm for estimating the
    probability of a binary outcome as it outputs values between 0 and 1 to represent
    class probabilities. K-means clustering is not suited for this task since it groups
    data without predicting probabilities. Linear regression estimates continuous
    values and is not designed for classification, while decision trees can classify
    but do not inherently provide probability estimates.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Azure’s Automated Machine Learning (AutoML) primarily supports supervised
    learning, focusing on tasks such as classification and regression that require
    labeled data. It does not specialize in reinforcement learning or unsupervised
    learning approaches like clustering, and it does not directly implement genetic
    algorithms. AutoML is designed to automate the process of building and tuning
    models within supervised learning frameworks.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: In a multiclass classification problem, the one-vs-rest (OVR) approach is
    used to build a separate binary classifier for each class, allowing the model
    to distinguish one class from all others. K-means is a clustering method and not
    suitable for classification tasks. The multinomial algorithm handles all classes
    within a single model, and while logistic regression can be adapted for multiclass
    problems, it isn’t inherently designed for building multiple binary classifiers
    like OVR.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: AutoML is the Azure Machine Learning feature that automates the process
    of trying multiple algorithms and tuning hyperparameters to find the best model.
    Custom script execution (choice A) requires manual coding without automated model
    selection. Dataset storage (choice C) is intended for organizing and managing
    data, not for training or selecting models. Deployment pipelines (choice D) are
    used to manage and automate the deployment of models, not to choose or optimize
    them.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Recall is the evaluation metric that measures the proportion of actual positives
    correctly identified by a classification model. Accuracy (choice A) accounts for
    all correct predictions, not just positives. Precision (choice B) measures how
    many predicted positives are actually correct, rather than capturing all actual
    positives. The F1 score (choice D) combines precision and recall into a single
    metric but does not focus solely on true positive identification.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Clustering is the machine learning technique used to group data points based
    on similarities without relying on prior labels. Supervised learning (choice A)
    requires labeled data for training. Classification (choice B) assigns data to
    predefined categories, not natural groupings. Regression (choice D) predicts numerical
    outcomes instead of organizing data into clusters based on feature similarity.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Mean squared error (MSE) is the regression metric that measures the average
    of the squared differences between predicted and actual values. Mean absolute
    error (MAE) (choice A) calculates the average of absolute differences without
    squaring them. Root mean squared error (RMSE) (choice B) takes the square root
    of the MSE rather than reporting the squared differences directly. The *R²* score
    (choice D) measures how much variance is explained by the model, not the average
    error magnitude.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Neural networks are deep learning structures made up of multiple layers
    that process data to make complex predictions. Support vector machines (SVMs)
    (choice A) are single-layer algorithms focused mainly on classification. Decision
    trees (choice B) use a branching structure to make decisions, not layered processing.
    K-nearest neighbors (choice D) make predictions by calculating distances to nearby
    points, without using a layered architecture.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 6 Answer Key
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'B: Pixels are the fundamental building blocks of digital images in computer
    vision, forming a grid of individual colored points. While filters can modify
    these pixels, they do not constitute the image itself. Neural networks analyze
    the data contained in pixels, and labels help categorize images, but neither represents
    the structure of the image grid like pixels do.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Bounding boxes are used in object detection to pinpoint and outline the
    location of objects within an image. OCR (choice A) is designed to read text from
    images, not to find object locations. Facial detection (choice C) specifically
    identifies human faces but does not localize other types of objects. Image classification
    (choice D) categorizes what is present in an image but does not determine where
    the objects are located.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: The primary purpose of convolution in computer vision is to identify patterns
    in pixel data such as edges, textures, and shapes. It is not used for tasks like
    color inversion or image resizing, and it does not directly assign labels. Instead,
    convolution serves as a key feature extraction step that precedes higher-level
    tasks like classification or labeling.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Azure AI Vision is the service that specifically handles computer vision
    tasks such as object detection and facial analysis. Azure Cognitive Search is
    focused on finding and organizing data, Azure Machine Learning supports general
    machine learning workflows but lacks specialization in visual tasks, and Azure
    Kubernetes Service is used for container orchestration, not for processing visual
    data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Convolutional neural networks (CNNs) are the most commonly used neural networks
    for computer vision tasks like image classification due to their ability to extract
    features through convolutional layers. Recurrent neural networks (RNNs) are better
    suited for sequential data like text or time series. Generative adversarial networks
    (GANs) are primarily used for image generation, not classification, and transformers
    are typically applied in natural language processing and multimodal tasks.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Pooling layers are the component of a convolutional neural network (CNN)
    that reduce the size of feature maps while preserving important details. Convolutional
    layers (choice A) extract features but do not reduce feature map size. Fully connected
    layers (choice B) connect neurons across layers but do not resize feature maps.
    Activation functions (choice D) introduce nonlinearity to the model but do not
    alter the dimensions of feature maps.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Optical Character Recognition (OCR) is the computer vision technique used
    to read and interpret text within images. Image classification (choice A) categorizes
    the overall content of an image but does not extract text. Facial detection (choice
    C) identifies human faces without interpreting text information. Object detection
    (choice D) finds objects within images but does not focus on reading or understanding
    text.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: The primary ethical concern associated with facial detection and analysis
    in AI is privacy and consent issues. This arises from the potential for collecting
    and using facial data without individuals’ informed consent. Other considerations
    like color accuracy and computational costs are technical rather than ethical.
    While limited datasets can affect model performance, they are not the main ethical
    issue.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: In Azure’s AI Vision Studio, a confidence score is provided alongside object
    detection results to indicate how certain the model is about its predictions.
    This score quantifies the model’s level of confidence in identifying an object.
    Pixel count does not relate to confidence, bounding box color is a visual aid,
    and file type has no relevance to the model’s certainty in its detection.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Activation functions in convolutional neural networks (CNNs) play a crucial
    role in the image recognition process by helping to assign probabilities to predictions,
    enabling the model to make final decisions. They introduce nonlinearity into the
    network, which is essential for learning complex patterns. While edge detection
    and image size reduction are handled by convolutional and pooling layers respectively,
    and color processing is unrelated, activation functions are key to producing meaningful
    classification outputs.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 7 Answer Key
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'C: Azure AI Translator is the Azure service designed to instantly translate
    text into multiple languages. Azure AI Language (choice A) focuses on analyzing
    and understanding text rather than translating it. Azure AI Speech (choice B)
    is used to convert spoken language to text and vice versa, not for written text
    translation. Azure AI Sentiment (choice D) analyzes the emotional tone of text
    but does not provide translation services.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: The primary function of named entity recognition (NER) in natural language
    processing (NLP) is to identify and categorize specific entities like names, dates,
    and locations. Sentiment analysis (choice A) focuses on interpreting the emotional
    tone of text, not recognizing entities. Language detection (choice B) identifies
    the language used but does not extract entities. Key phrase extraction (choice
    D) highlights main ideas or themes.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: The real-time speech-to-text feature in Azure AI Speech provides instant
    transcription of live audio into text. Text-to-speech (choice A) generates spoken
    output from written text rather than transcribing live audio. Summarization (choice
    B) condenses written content and is unrelated to audio transcription. Custom Translator
    (choice D) customizes text translation but does not handle converting live speech
    to text.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Tokenization in natural language processing (NLP) refers to the process
    of breaking down text into individual words or phrases, known as tokens, to make
    the text analyzable. It does not involve assigning identifiers to entities or
    converting text to speech, which are separate functions. Additionally, language
    detection identifies the language used in the text but does not segment it into
    meaningful components as tokenization does.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Azure’s key phrase extraction feature identifies and highlights the main
    concepts or themes within a piece of text. Categorizing specific entities (choice
    A) is the role of named entity recognition (NER), not key phrase extraction. Language
    detection (choice C) determines the language of a document but does not identify
    key ideas. Sentiment analysis (choice D) evaluates the emotional tone of the text
    rather than focusing on its main concepts.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: PII detection is the Azure NLP feature designed to identify and redact sensitive
    information such as Social Security numbers. Language detection (choice A) identifies
    the language of the text but does not detect sensitive details. Key phrase extraction
    (choice B) highlights main topics or themes rather than recognizing sensitive
    data. Sentiment analysis (choice D) evaluates the emotional tone of the text,
    not the presence of personally identifying information.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Stop-word removal is the NLP process that eliminates common words like “the”
    and “an” that add little semantic value to the text. Lemmatization (choice A)
    reduces words to their root forms but does not remove them. Tokenization (choice
    C) splits text into individual words or tokens without filtering out common terms.
    Frequency analysis (choice D) measures how often words occur but does not eliminate
    nonessential words.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Entity linking in Azure AI Language Studio automatically connects entities
    like “Paris” to specific references, helping distinguish between similar terms
    such as “Paris, France” and “Paris Hilton.” Entity recognition (choice A) identifies
    entities but does not link them to specific references. Language detection (choice
    C) determines the language of the text rather than linking entities. Summarization
    (choice D) condenses text but does not associate entities with unique references.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: The Fast Transcription API in Azure AI Speech is designed to provide quick,
    synchronous transcription of audio files. Translation (choice A) is handled by
    Azure AI Translator, not the Fast Transcription API. Sentiment detection (choice
    C) is unrelated to this feature and focuses on analyzing emotional tone. Text-to-speech
    conversion (choice D) generates spoken output from text rather than transcribing
    audio into text.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Summarization in Azure is used to create concise summaries by extracting
    key sentences from large volumes of text. Text-to-speech (choice A) converts written
    text into audio but does not summarize it. Language detection (choice C) identifies
    the language of the text rather than condensing its content. Entity recognition
    (choice D) identifies specific entities like names or places but does not extract
    or summarize main ideas.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 8 Answer Key
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'B: DALL-E is the Azure generative AI feature that creates unique images based
    on text prompts. Semantic search (choice A) retrieves information based on meaning
    but does not generate images. Content moderation (choice C) is used to detect
    inappropriate content, not to create visuals. Lifelike dialogue creation (choice
    D) focuses on producing realistic conversations rather than generating images.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: The purpose of embeddings in transformer models is to encode semantic relationships
    between words, creating a meaningful representation of language that helps the
    model understand context and meaning. They are not used for detecting harmful
    content, which is handled by content moderation tools, nor are they responsible
    for directly translating languages or generating personalized recommendations,
    which rely on different mechanisms and data inputs.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: The encoder block is the component of a transformer model responsible for
    interpreting the context of input text. While embeddings help represent relationships
    between words and self-attention highlights important word connections, it is
    the encoder block that processes the input data in a contextual manner. The decoder
    block, by contrast, focuses on generating new sequences of text rather than understanding
    the input.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Contextual question answering is the AI workload designed to provide natural
    and accurate responses to customer questions and inquiries. Image generation (choice
    A) focuses on creating visuals from prompts rather than responding to questions.
    Summarization (choice B) condenses lengthy content but does not engage in conversation.
    Personalized recommendations (choice D) tailor content for users but are not meant
    for interactive dialogue.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: In Azure’s AI, multihead attention refers to analyzing relationships between
    words from multiple perspectives within a transformer model. Token generation
    (choice A) is a separate function handled by the decoder block. Anomaly detection
    (choice B) identifies unusual patterns in data. Translation (choice D) involves
    converting text between languages and is distinct from the multihead attention
    mechanism.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Large language models (LLMs) commonly require high memory and storage due
    to their size and the amount of data they are trained on. In contrast, small language
    models (SLMs) typically offer faster response times, consume less energy, and
    are easier to deploy on premises.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: The primary advantage of using Azure OpenAI’s Model Catalog is gaining access
    to a variety of pretrained, high-performance models for different applications.
    Fast training times (choice A) are not a feature of the Model Catalog, as it focuses
    on ready-to-use models. Exclusive use of OpenAI models (choice C) is not accurate,
    as the catalog includes a broader range of models. It is also not limited to image
    generation (choice D), supporting many different AI tasks.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: The safety system layer in Azure’s generative AI helps mitigate risks by
    filtering out harmful or inappropriate content in real time. This function is
    distinct from setting user expectations, which belongs to the UX layer, and it
    does not involve improving model embeddings or providing semantic search capabilities.
    Its primary role is to enhance content safety during AI output generation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: The decoder block in a transformer model is responsible for generating the
    output sequence based on the encoded input. While the encoder interprets the context
    of the input data, the decoder uses this information to produce coherent and contextually
    relevant output. Tasks like embedding words into vectors and attending to token
    relationships are handled separately by other components such as embedding layers
    and self-attention mechanisms.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: The recommended strategy by Microsoft for responsible deployment of generative
    AI is to implement a phased rollout with an incident response plan. This approach
    allows for gradual scaling, careful monitoring, and effective error management.
    Relying only on automated testing is insufficient without manual oversight. Planning
    for incidents ensures risks are addressed proactively and responsibly.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Practice Exam Answer Key
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'B: The primary responsible AI principle to focus on when developing an AI system
    for evaluating loan applications is fairness. Fairness ensures that decisions
    are made based on relevant financial data and are free from bias or discrimination.
    While transparency helps explain decisions, privacy safeguards user data, and
    reliability supports consistent performance, these aspects are secondary to the
    ethical necessity of fair and unbiased lending practices.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: The most appropriate AI workload for making a museum’s digital archive of
    historical documents searchable is knowledge mining. This workload is specifically
    designed to index large collections of content and make them easily searchable
    and discoverable. In contrast, computer vision focuses on image processing, conversational
    AI supports interactive dialogue, and sentiment analysis identifies emotional
    tone—none of which are suited for enabling document searchability.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: The correct sequence of risk management when implementing a new AI system
    for public use is identification, measurement, and mitigation. This order ensures
    that potential risks are first recognized, then evaluated for their severity and
    impact, and finally addressed through appropriate mitigation strategies. Starting
    with mitigation or attempting to measure risks before identifying them is illogical
    and ineffective.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Microsoft retired the emotion recognition AI service due to ethical concerns
    about its accuracy and the risk of discriminatory use. Facial detection (choice
    A) remains available and focuses only on locating faces, not analyzing emotions.
    Object detection (choice C) is still an active service providing key computer
    vision functionality. Language translation (choice D) continues to be offered,
    supporting communication needs without raising similar ethical concerns.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: Text analytics is the most suitable AI workload for automatically categorizing
    and analyzing property descriptions, as it is specifically designed to handle
    and extract insights from written content. In contrast, computer vision is intended
    for image data, speech services process audio, and face recognition is unrelated
    to text analysis. These other workloads do not support the textual processing
    required for this use case.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Before deploying harm-mitigation strategies in an AI implementation framework,
    impact measurement must be completed. Measuring the extent and severity of potential
    harm is essential for developing effective mitigation plans. Conducting user testing
    or deploying the system beforehand could result in avoidable risks, and marketing
    analysis is secondary to ensuring user safety and system responsibility.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: The most suitable AI workload for analyzing customer feedback across multiple
    retail locations is language understanding. This workload is specifically designed
    to process and interpret text-based input, making it ideal for extracting insights
    from written customer reviews. In contrast, computer vision focuses on image analysis,
    face verification is unrelated to text, and speech synthesis generates spoken
    output rather than analyzing written content.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: For an autonomous drone delivery service handling medical supplies, the
    most critical responsible AI principle to prioritize is reliability and safety.
    Ensuring that the system operates safely and reliably is essential, as it directly
    impacts human health. While principles like inclusiveness, transparency, and fairness
    are also important, they are secondary to the need for consistent, safe delivery
    of sensitive and potentially life-saving materials.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: Conversational AI is the best solution for handling customer inquiries in
    multiple languages 24-7, providing real-time, multilingual interaction capabilities.
    Knowledge mining (choice B) focuses on indexing and retrieving information from
    documents but cannot engage in conversations. Image analysis (choice C) is designed
    for processing visual content, not text-based customer inquiries. Text analytics
    (choice D) can analyze text but does not support real-time, interactive communication
    needed for customer service.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: The principle of transparency is addressed when an organization documents
    its AI model’s capabilities and limitations. Transparency ensures users clearly
    understand what the AI system can and cannot do. While accountability assigns
    responsibility, reliability focuses on consistent system performance, and security
    protects against threats, none of these directly involve making the system’s functions
    and boundaries understandable to users like transparency does.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: The first step in implementing an AI governance framework for a new healthcare
    application is to identify potential harms. This foundational step ensures that
    risks are clearly understood before any protective measures, such as deploying
    security, training the model, or conducting user testing, are introduced. Addressing
    potential harms early supports responsible development and safeguards user wellbeing
    throughout the AI system’s lifecycle.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: The most appropriate machine learning approach for grouping shoppers based
    on browsing patterns is unsupervised learning, as it is designed to uncover patterns
    in unlabeled data. Supervised learning is not suitable here because it requires
    labeled outcomes, which are not present. Semisupervised learning combines both
    labeled and unlabeled data, which is unnecessary for this task, and reinforcement
    learning focuses on reward-based interactions, making it inappropriate for customer
    segmentation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: In this model, temperature serves as a feature because it is an input variable
    used to help predict the crop yield. It is not the label or output variable, which
    refers to the actual yield being predicted. Additionally, temperature is not a
    parameter, as parameters are internal values the model learns during training,
    not external input data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: The dataset should be split into training and validation sets before model
    training to ensure unbiased and accurate evaluation of the model’s performance.
    Splitting the data after training or during evaluation hinders the ability to
    assess the model effectively and waiting until deployment is too late in the workflow.
    Proper early splitting allows the validation set to serve its purpose in measuring
    how well the model generalizes to unseen data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: In a healthcare scenario focused on predicting the risk of patient readmission—a
    binary classification task—accuracy is the most appropriate metric for evaluating
    model performance. Accuracy measures the proportion of correct predictions, which
    is well-suited for classification problems. Metrics like MSE and *R²* are suited
    for regression tasks, while the silhouette score applies to clustering, making
    them unsuitable for this type of analysis.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Overfitting occurs when a machine learning model performs exceptionally
    well on training data but poorly on test data, indicating that it has memorized
    the training examples rather than learned general patterns. This gap in performance
    is a classic sign of overfitting. In contrast, poor performance on both sets points
    to underfitting, equal performance suggests proper generalization, and better
    test performance than training performance is highly unusual and may indicate
    data leakage.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: The first step when creating a pipeline in Azure Machine Learning Designer
    is to create the pipeline infrastructure. This foundational step is essential
    as it enables the addition of other components like data transformation modules
    and datasets. Configuring compute resources and importing data are tasks that
    follow the establishment of the pipeline structure, making them dependent on this
    initial setup.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: The most appropriate type of machine learning problem for predicting delivery
    times based on variables like distance, traffic, and weather conditions is regression,
    as it estimates continuous numerical values. Classification is used to predict
    categories rather than numerical outcomes, clustering groups of similar data points
    without making predictions, and anomaly detection focuses on identifying unusual
    patterns, not producing predictive estimates.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: The correct sequence for developing a machine learning model in Azure Machine
    Learning is workspace creation, data preparation, training, and then deployment.
    Creating the workspace is the essential first step, as it provides the environment
    to manage all assets and activities. Data preparation and model training depend
    on this foundation, and deployment logically follows once the model is trained.
    Performing these steps out of order—such as deploying before training or preparing
    data before setting up a workspace—would interrupt the workflow.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: When a model performs poorly on both the training and validation datasets,
    it likely indicates underfitting. This suggests that the model is too simple to
    capture the underlying patterns in the data. In contrast, overfitting would show
    strong performance on training data but poor performance on validation data. Data
    leakage typically results in unrealistically strong validation performance, and
    a perfect fit would demonstrate high accuracy across both datasets.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: An inference pipeline in Azure Machine Learning Designer should be created
    after successfully training the model, as it is used to deploy the model and generate
    predictions on new data. Creating it before or during training is not feasible
    since the model must be finalized first. Additionally, inference pipelines are
    built long after the data preparation phase, making it a distinct step in the
    deployment process.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: The most appropriate approach for identifying groups of similar insurance
    claims without predefined categories is clustering. Clustering is a type of unsupervised
    learning that detects natural groupings in unlabeled data. Unlike linear regression
    and time-series analysis, which are used for predicting values, or classification,
    which requires labeled categories, clustering is ideal for discovering patterns
    when categories are not known in advance.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: The best Azure AI Service for detecting guest comments in various languages
    and routing them appropriately is language detection. This service can identify
    the language of the text before any additional processing takes place, which is
    essential in a multilingual context. Other services like text analytics, sentiment
    analysis, and entity recognition provide valuable text insights but do not perform
    language identification, making them unsuitable as the first step in this scenario.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: The most appropriate service for extracting mentions of medical conditions,
    treatments, and dosages from clinical trial documents is named entity recognition
    (NER). NER is specifically designed to identify and categorize detailed entities
    within text and can be customized for domains like healthcare. Other options such
    as key phrase extraction and general text analytics are too broad for this level
    of detail, and sentiment analysis is focused on emotional tone, not extracting
    specific medical information.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: When Azure AI Language Detection processes text in an unsupported language,
    it returns a NaN (not a number) confidence score, indicating that the service
    cannot confidently determine the language. It does not return an empty string,
    produce an error code, or default to a preset language like English.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: The most appropriate translation approach for an international law firm
    looking to preserve the formatting and structure of legal contracts is asynchronous
    batch translation. This method ensures that document-specific layouts are maintained
    during translation. In contrast, real-time translation does not retain formatting,
    custom neural voice is designed for speech synthesis, and text-to-speech only
    converts text into audio without providing document translation capabilities.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: The ideal service combination for a startup developing a multilingual virtual
    assistant is Language understanding and Translator. This pairing enables the assistant
    to both comprehend user inputs and translate across multiple languages. Other
    options, such as Speech Service and Face API, or text analytics and computer vision,
    do not support the necessary language processing capabilities. Likewise, Form
    recognizer is designed for document extraction and is not suitable for understanding
    conversational language.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Content filtering in Azure OpenAI is specifically designed to prevent the
    model from generating harmful or inappropriate content. Entity linking (choice
    A) connects entities to knowledge bases but does not filter outputs. Language
    detection (choice B) identifies the language of text but does not monitor for
    inappropriate material. Speech recognition (choice D) converts spoken language
    to text but does not provide any content filtering capabilities.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: The most suitable service for creating audiobooks in multiple languages
    with natural-sounding voices is custom neural voice. This service is specifically
    designed to generate realistic speech output across different languages. In contrast,
    text analytics only analyzes written content, language understanding interprets
    meaning without producing speech, and entity recognition focuses on identifying
    named entities rather than generating audio.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: To create a custom translation model tailored to industry-specific terminology,
    parallel sentence pairs are essential. These consist of aligned text in both the
    source and target languages, allowing the model to learn accurate translations
    within a specific domain. Large general datasets lack the necessary precision
    for specialized terms, while speech samples and image annotations are unrelated
    to text-based translation tasks and thus not applicable.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: The most appropriate service for a media company needing to automatically
    generate subtitles for live broadcasts is speech-to-text. This service is capable
    of producing real-time transcriptions from spoken language, making it ideal for
    creating live subtitles. In contrast, text analytics focuses on understanding
    written content, Custom Translator handles text-based language translation rather
    than transcription, and language understanding helps interpret meanings but does
    not convert audio to text.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: The correct answer is text embeddings as they allow for measuring semantic
    similarity between pieces of text, which is essential for identifying and avoiding
    duplicate customer support tickets. The other options do not serve this purpose.
    Sentiment analysis detects emotional tone, language detection identifies the language
    used, and named entity recognition (NER) extracts proper names and entities, none
    of which help compare text for similarity.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Speaker recognition can identify and differentiate between individual voices
    in audio recordings, which is essential for telehealth consultations. The other
    options are not suitable. Language detection only identifies the language used,
    text analytics processes written text rather than audio, and entity linking connects
    related entities in text but doesn’t work with speaker identification.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Object detection can identify and count multiple animals within each frame
    of drone footage, which is essential for wildlife monitoring. Image classification
    is limited to identifying the main subject without detecting multiple objects.
    OCR is designed for recognizing text, not animals, and facial detection is tailored
    for identifying human faces, not wildlife.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Face recognition, OCR, and landmark detection are not appropriate for analyzing
    parking spaces as they serve different purposes such as identifying faces, extracting
    text, or recognizing landmarks. In contrast, semantic segmentation is suitable
    because it can classify each pixel in an image, allowing the system to distinguish
    between empty and occupied parking spots accurately.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Azure AI Vision provides both *bounding box coordinates* and a *confidence
    score* for each object it detects in an image. These two elements are essential.
    The bounding box defines the object’s location, while the confidence score reflects
    the system’s certainty in its identification. Other options like metadata, size,
    or color information alone are insufficient for accurate and reliable object detection.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: The correct choice is custom vision because it allows the museum to train
    a model specifically to recognize famous paintings. Celebrity recognition is designed
    for identifying people, not artwork, while facial detection is limited to human
    faces, and OCR is only useful for extracting text, not recognizing images.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: The correct answer is emotion recognition, which Azure Face API no longer
    supports due to ethical concerns around privacy and potential misuse. In contrast,
    capabilities like facial detection, facial verification, and face location are
    still supported as they are essential for core functionalities such as identifying
    and locating faces within images. This change reflects Microsoft’s commitment
    to responsible AI practices.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: Form recognizer with OCR can extract both printed and handwritten text from
    documents, making it ideal for processing handwritten loan applications. Facial
    detection and landmark detection are unrelated to document analysis, while DALL-E
    is designed for generating images, not interpreting text. Therefore, those options
    wouldn’t meet the financial institution’s needs.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: DALL-E is designed to generate new images or create variations of existing
    ones, making it suitable for image variation tasks. It does not have capabilities
    for face recognition, text extraction, or object counting, which fall under different
    types of computer vision or AI services. Its main strength lies in creative image
    generation and manipulation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Liveness detection is designed to determine if a person is physically present,
    helping distinguish between a live person and a photo or video. Facial detection
    simply identifies the presence of a face without confirming if it’s live. Object
    detection and image classification focus on recognizing or categorizing items
    in images, not verifying human presence or authenticity.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Handwritten text recognition is specifically designed to extract and convert
    handwritten content into machine-readable text, making it suitable for digitizing
    historical letters. Image classification and object detection focus on identifying
    or locating elements within images but do not extract written content. Facial
    detection is unrelated to document processing and cannot assist with text conversion.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: DALL-E generates images based on natural language descriptions, allowing
    users to create visuals simply by describing them in text. It does not require
    an existing image to start, nor does it use programming code or audio files as
    inputs. The model is designed to interpret and visualize textual prompts into
    original artwork.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Spatial analysis is designed to monitor and understand movement patterns
    in physical spaces without identifying individuals, making it well-suited for
    privacy-conscious environments like retail stores. Face recognition focuses on
    identifying people, which raises privacy concerns. OCR is used for reading text,
    not tracking movement, and landmark detection relates to recognizing specific
    locations, not human behavior in a store.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: GPT models are well-suited for generating test cases for REST APIs because
    they can understand natural language and code structures. DALL-E and Stable Diffusion
    focus on image generation and are not designed for working with code. Whisper
    specializes in transcribing spoken language into text, making it irrelevant for
    this task.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Copilot solutions are designed to assist with content creation in specific
    domains, making them well-suited for tasks like writing email campaigns. Chatbots
    specialize in interactive conversations but aren’t optimized for generating marketing
    content. Translation services are limited to converting text between languages,
    and Content Moderator focuses on reviewing content rather than creating it.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Including a tone specification in a system message helps guide the AI to
    respond with a formal tone, ensuring consistency in communication style. API keys
    are used only for authentication and have no influence on how responses are phrased.
    Model version determines system capabilities but not stylistic output, and response
    length affects how much is said, not how it’s said.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Content filtering in a generative AI solution should occur at the safety
    system layer, which is designed to manage and moderate outputs for appropriateness
    and compliance. The user interface layer is focused on display, the model layer
    is responsible for generating content, and the network layer deals with transmitting
    data—none of which are intended to enforce safety or filtering rules.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Python is widely supported by AI models for tasks like generating database
    queries thanks to its readability and popularity in the development community.
    Assembly and machine code are too low-level and complex for practical AI-generated
    output, while COBOL is considered outdated and lacks broad support in modern AI
    systems.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: Zero-shot learning enables AI models to generate content based on general
    understanding, even when no prior examples are provided. Supervised learning depends
    on labeled training data, transfer learning builds on knowledge from related tasks,
    and reinforcement learning relies on reward feedback to guide learning.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Content safety filters play a crucial role in healthcare by helping ensure
    that generative AI systems produce appropriate and nonharmful outputs. Features
    like real-time translation, image generation, and speech synthesis support communication
    and presentation but do not directly address safety concerns during content creation
    or deployment.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Copilots are most effective when assisting developers with repetitive coding
    tasks, helping to boost productivity and reduce effort on routine work. They are
    not intended to fully replace developers, handle complex security audits, or conduct
    performance tuning, which require deeper analysis and specialized tools or expertise.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: System messages are used to define the behavior and tone of the AI, helping
    maintain consistency across different prompts by setting clear instructions. Changing
    API keys, increasing model size, or altering network settings has no effect on
    the consistency of the responses, as these factors do not influence how instructions
    are applied during content generation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Implementing a copilot in a specialized industrial setting requires training
    the model with domain-specific data to ensure it can provide relevant and accurate
    support. A web interface may help with accessibility but doesn’t contribute to
    domain understanding. Public datasets often lack the depth needed for niche applications,
    and social media integration is generally unrelated to industrial use cases.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Grounding with reference data helps Azure OpenAI models generate more accurate
    and factual responses by linking outputs to trusted information sources. Speed
    optimization, network configuration, and user interface design may improve system
    performance or usability, but they do not address the issue of hallucination in
    model-generated content.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
