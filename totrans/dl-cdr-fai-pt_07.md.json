["```py\npath = untar_data(URLs.MNIST_SAMPLE)\n```", "```py\npath.ls()\n```", "```py\n(#9) [Path('cleaned.csv'),Path('item_list.txt'),Path('trained_model.pkl'),Path('\n > models'),Path('valid'),Path('labels.csv'),Path('export.pkl'),Path('history.cs\n > v'),Path('train')]\n```", "```py\n(path/'train').ls()\n```", "```py\n(#2) [Path('train/7'),Path('train/3')]\n```", "```py\nthrees = (path/'train'/'3').ls().sorted()\nsevens = (path/'train'/'7').ls().sorted()\nthrees\n```", "```py\n(#6131) [Path('train/3/10.png'),Path('train/3/10000.png'),Path('train/3/10011.pn\n > g'),Path('train/3/10031.png'),Path('train/3/10034.png'),Path('train/3/10042.p\n > ng'),Path('train/3/10052.png'),Path('train/3/1007.png'),Path('train/3/10074.p\n > ng'),Path('train/3/10091.png')...]\n```", "```py\nim3_path = threes[1]\nim3 = Image.open(im3_path)\nim3\n```", "```py\narray(im3)[4:10,4:10]\n```", "```py\narray([[  0,   0,   0,   0,   0,   0],\n       [  0,   0,   0,   0,   0,  29],\n       [  0,   0,   0,  48, 166, 224],\n       [  0,  93, 244, 249, 253, 187],\n       [  0, 107, 253, 253, 230,  48],\n       [  0,   3,  20,  20,  15,   0]], dtype=uint8)\n```", "```py\ntensor(im3)[4:10,4:10]\n```", "```py\ntensor([[  0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,  29],\n        [  0,   0,   0,  48, 166, 224],\n        [  0,  93, 244, 249, 253, 187],\n        [  0, 107, 253, 253, 230,  48],\n        [  0,   3,  20,  20,  15,   0]], dtype=torch.uint8)\n```", "```py\nim3_t = tensor(im3)\ndf = pd.DataFrame(im3_t[4:15,4:22])\ndf.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')\n```", "```py\nseven_tensors = [tensor(Image.open(o)) for o in sevens]\nthree_tensors = [tensor(Image.open(o)) for o in threes]\nlen(three_tensors),len(seven_tensors)\n```", "```py\n(6131, 6265)\n```", "```py\nshow_image(three_tensors[1]);\n```", "```py\nstacked_sevens = torch.stack(seven_tensors).float()/255\nstacked_threes = torch.stack(three_tensors).float()/255\nstacked_threes.shape\n```", "```py\ntorch.Size([6131, 28, 28])\n```", "```py\nlen(stacked_threes.shape)\n```", "```py\n3\n```", "```py\nstacked_threes.ndim\n```", "```py\n3\n```", "```py\nmean3 = stacked_threes.mean(0)\nshow_image(mean3);\n```", "```py\nmean7 = stacked_sevens.mean(0)\nshow_image(mean7);\n```", "```py\na_3 = stacked_threes[1]\nshow_image(a_3);\n```", "```py\ndist_3_abs = (a_3 - mean3).abs().mean()\ndist_3_sqr = ((a_3 - mean3)**2).mean().sqrt()\ndist_3_abs,dist_3_sqr\n```", "```py\n(tensor(0.1114), tensor(0.2021))\n```", "```py\ndist_7_abs = (a_3 - mean7).abs().mean()\ndist_7_sqr = ((a_3 - mean7)**2).mean().sqrt()\ndist_7_abs,dist_7_sqr\n```", "```py\n(tensor(0.1586), tensor(0.3021))\n```", "```py\nF.l1_loss(a_3.float(),mean7), F.mse_loss(a_3,mean7).sqrt()\n```", "```py\n(tensor(0.1586), tensor(0.3021))\n```", "```py\ndata = [[1,2,3],[4,5,6]]\narr = array (data)\ntns = tensor(data)\n```", "```py\narr  # numpy\n```", "```py\narray([[1, 2, 3],\n       [4, 5, 6]])\n```", "```py\ntns  # pytorch\n```", "```py\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n```", "```py\ntns[1]\n```", "```py\ntensor([4, 5, 6])\n```", "```py\ntns[:,1]\n```", "```py\ntensor([2, 5])\n```", "```py\ntns[1,1:3]\n```", "```py\ntensor([5, 6])\n```", "```py\ntns+1\n```", "```py\ntensor([[2, 3, 4],\n        [5, 6, 7]])\n```", "```py\ntns.type()\n```", "```py\n'torch.LongTensor'\n```", "```py\ntns*1.5\n```", "```py\ntensor([[1.5000, 3.0000, 4.5000],\n        [6.0000, 7.5000, 9.0000]])\n```", "```py\nvalid_3_tens = torch.stack([tensor(Image.open(o))\n                            for o in (path/'valid'/'3').ls()])\nvalid_3_tens = valid_3_tens.float()/255\nvalid_7_tens = torch.stack([tensor(Image.open(o))\n                            for o in (path/'valid'/'7').ls()])\nvalid_7_tens = valid_7_tens.float()/255\nvalid_3_tens.shape,valid_7_tens.shape\n```", "```py\n(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))\n```", "```py\ndef mnist_distance(a,b): return (a-b).abs().mean((-1,-2))\nmnist_distance(a_3, mean3)\n```", "```py\ntensor(0.1114)\n```", "```py\nvalid_3_dist = mnist_distance(valid_3_tens, mean3)\nvalid_3_dist, valid_3_dist.shape\n```", "```py\n(tensor([0.1050, 0.1526, 0.1186,  ..., 0.1122, 0.1170, 0.1086]),\n torch.Size([1010]))\n```", "```py\ntensor([1,2,3]) + tensor([1,1,1])\n```", "```py\ntensor([2, 3, 4])\n```", "```py\n(valid_3_tens-mean3).shape\n```", "```py\ntorch.Size([1010, 28, 28])\n```", "```py\ndef is_3(x): return mnist_distance(x,mean3) < mnist_distance(x,mean7)\n```", "```py\nis_3(a_3), is_3(a_3).float()\n```", "```py\n(tensor(True), tensor(1.))\n```", "```py\nis_3(valid_3_tens)\n```", "```py\ntensor([True, True, True,  ..., True, True, True])\n```", "```py\naccuracy_3s =      is_3(valid_3_tens).float() .mean()\naccuracy_7s = (1 - is_3(valid_7_tens).float()).mean()\n\naccuracy_3s,accuracy_7s,(accuracy_3s+accuracy_7s)/2\n```", "```py\n(tensor(0.9168), tensor(0.9854), tensor(0.9511))\n```", "```py\ndef pr_eight(x,w) = (x*w).sum()\n```", "```py\ndef f(x): return x**2\n```", "```py\nplot_function(f, 'x', 'x**2')\n```", "```py\nplot_function(f, 'x', 'x**2')\nplt.scatter(-1.5, f(-1.5), color='red');\n```", "```py\nxt = tensor(3.).requires_grad_()\n```", "```py\nyt = f(xt)\nyt\n```", "```py\ntensor(9., grad_fn=<PowBackward0>)\n```", "```py\nyt.backward()\n```", "```py\nxt.grad\n```", "```py\ntensor(6.)\n```", "```py\nxt = tensor([3.,4.,10.]).requires_grad_()\nxt\n```", "```py\ntensor([ 3.,  4., 10.], requires_grad=True)\n```", "```py\ndef f(x): return (x**2).sum()\n\nyt = f(xt)\nyt\n```", "```py\ntensor(125., grad_fn=<SumBackward0>)\n```", "```py\nyt.backward()\nxt.grad\n```", "```py\ntensor([ 6.,  8., 20.])\n```", "```py\nw -= w.grad * lr\n```", "```py\ntime = torch.arange(0,20).float(); time\n```", "```py\ntensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n > 14., 15., 16., 17., 18., 19.])\n```", "```py\nspeed = torch.randn(20)*3 + 0.75*(time-9.5)**2 + 1\nplt.scatter(time,speed);\n```", "```py\ndef f(t, params):\n    a,b,c = params\n    return a*(t**2) + (b*t) + c\n```", "```py\ndef mse(preds, targets): return ((preds-targets)**2).mean()\n```", "```py\nparams = torch.randn(3).requires_grad_()\n```", "```py\npreds = f(time, params)\n```", "```py\ndef show_preds(preds, ax=None):\n    if ax is None: ax=plt.subplots()[1]\n    ax.scatter(time, speed)\n    ax.scatter(time, to_np(preds), color='red')\n    ax.set_ylim(-300,100)\n```", "```py\nshow_preds(preds)\n```", "```py\nloss = mse(preds, speed)\nloss\n```", "```py\ntensor(25823.8086, grad_fn=<MeanBackward0>)\n```", "```py\nloss.backward()\nparams.grad\n```", "```py\ntensor([-53195.8594,  -3419.7146,   -253.8908])\n```", "```py\nparams.grad * 1e-5\n```", "```py\ntensor([-0.5320, -0.0342, -0.0025])\n```", "```py\nparams\n```", "```py\ntensor([-0.7658, -0.7506,  1.3525], requires_grad=True)\n```", "```py\nlr = 1e-5\nparams.data -= lr * params.grad.data\nparams.grad = None\n```", "```py\npreds = f(time,params)\nmse(preds, speed)\n```", "```py\ntensor(5435.5366, grad_fn=<MeanBackward0>)\n```", "```py\nshow_preds(preds)\n```", "```py\ndef apply_step(params, prn=True):\n    preds = f(time, params)\n    loss = mse(preds, speed)\n    loss.backward()\n    params.data -= lr * params.grad.data\n    params.grad = None\n    if prn: print(loss.item())\n    return preds\n```", "```py\nfor i in range(10): apply_step(params)\n```", "```py\n5435.53662109375\n1577.4495849609375\n847.3780517578125\n709.22265625\n683.0757446289062\n678.12451171875\n677.1839599609375\n677.0025024414062\n676.96435546875\n676.9537353515625\n```", "```py\n_,axs = plt.subplots(1,4,figsize=(12,3))\nfor ax in axs: show_preds(apply_step(params, False), ax)\nplt.tight_layout()\n```", "```py\ntrain_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n```", "```py\ntrain_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\ntrain_x.shape,train_y.shape\n```", "```py\n(torch.Size([12396, 784]), torch.Size([12396, 1]))\n```", "```py\ndset = list(zip(train_x,train_y))\nx,y = dset[0]\nx.shape,y\n```", "```py\n(torch.Size([784]), tensor([1]))\n```", "```py\nvalid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\nvalid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\nvalid_dset = list(zip(valid_x,valid_y))\n```", "```py\ndef init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()\n```", "```py\nweights = init_params((28*28,1))\n```", "```py\nbias = init_params(1)\n```", "```py\n(train_x[0]*weights.T).sum() + bias\n```", "```py\ntensor([20.2336], grad_fn=<AddBackward0>)\n```", "```py\ndef linear1(xb): return xb@weights + bias\npreds = linear1(train_x)\npreds\n```", "```py\ntensor([[20.2336],\n        [17.0644],\n        [15.2384],\n        ...,\n        [18.3804],\n        [23.8567],\n        [28.6816]], grad_fn=<AddBackward0>)\n```", "```py\ncorrects = (preds>0.0).float() == train_y\ncorrects\n```", "```py\ntensor([[ True],\n        [ True],\n        [ True],\n        ...,\n        [False],\n        [False],\n        [False]])\n```", "```py\ncorrects.float().mean().item()\n```", "```py\n0.4912068545818329\n```", "```py\nweights[0] *= 1.0001\n```", "```py\npreds = linear1(train_x)\n((preds>0.0).float() == train_y).float().mean().item()\n```", "```py\n0.4912068545818329\n```", "```py\n(y_new \u2013 y_old) / (x_new \u2013 x_old)\n```", "```py\ntrgts  = tensor([1,0,1])\nprds   = tensor([0.9, 0.4, 0.2])\n```", "```py\ndef mnist_loss(predictions, targets):\n    return torch.where(targets==1, 1-predictions, predictions).mean()\n```", "```py\ntorch.where(trgts==1, 1-prds, prds)\n```", "```py\ntensor([0.1000, 0.4000, 0.8000])\n```", "```py\nmnist_loss(prds,trgts)\n```", "```py\ntensor(0.4333)\n```", "```py\nmnist_loss(tensor([0.9, 0.4, 0.8]),trgts)\n```", "```py\ntensor(0.2333)\n```", "```py\ndef sigmoid(x): return 1/(1+torch.exp(-x))\n```", "```py\nplot_function(torch.sigmoid, title='Sigmoid', min=-4, max=4)\n```", "```py\ndef mnist_loss(predictions, targets):\n    predictions = predictions.sigmoid()\n    return torch.where(targets==1, 1-predictions, predictions).mean()\n```", "```py\ncoll = range(15)\ndl = DataLoader(coll, batch_size=5, shuffle=True)\nlist(dl)\n```", "```py\n[tensor([ 3, 12,  8, 10,  2]),\n tensor([ 9,  4,  7, 14,  5]),\n tensor([ 1, 13,  0,  6, 11])]\n```", "```py\nds = L(enumerate(string.ascii_lowercase))\nds\n```", "```py\n(#26) [(0, 'a'),(1, 'b'),(2, 'c'),(3, 'd'),(4, 'e'),(5, 'f'),(6, 'g'),(7,\n > 'h'),(8, 'i'),(9, 'j')...]\n```", "```py\ndl = DataLoader(ds, batch_size=6, shuffle=True)\nlist(dl)\n```", "```py\n[(tensor([17, 18, 10, 22,  8, 14]), ('r', 's', 'k', 'w', 'i', 'o')),\n (tensor([20, 15,  9, 13, 21, 12]), ('u', 'p', 'j', 'n', 'v', 'm')),\n (tensor([ 7, 25,  6,  5, 11, 23]), ('h', 'z', 'g', 'f', 'l', 'x')),\n (tensor([ 1,  3,  0, 24, 19, 16]), ('b', 'd', 'a', 'y', 't', 'q')),\n (tensor([2, 4]), ('c', 'e'))]\n```", "```py\nfor x,y in dl:\n    pred = model(x)\n    loss = loss_func(pred, y)\n    loss.backward()\n    parameters -= parameters.grad * lr\n```", "```py\nweights = init_params((28*28,1))\nbias = init_params(1)\n```", "```py\ndl = DataLoader(dset, batch_size=256)\nxb,yb = first(dl)\nxb.shape,yb.shape\n```", "```py\n(torch.Size([256, 784]), torch.Size([256, 1]))\n```", "```py\nvalid_dl = DataLoader(valid_dset, batch_size=256)\n```", "```py\nbatch = train_x[:4]\nbatch.shape\n```", "```py\ntorch.Size([4, 784])\n```", "```py\npreds = linear1(batch)\npreds\n```", "```py\ntensor([[-11.1002],\n        [  5.9263],\n        [  9.9627],\n        [ -8.1484]], grad_fn=<AddBackward0>)\n```", "```py\nloss = mnist_loss(preds, train_y[:4])\nloss\n```", "```py\ntensor(0.5006, grad_fn=<MeanBackward0>)\n```", "```py\nloss.backward()\nweights.grad.shape,weights.grad.mean(),bias.grad\n```", "```py\n(torch.Size([784, 1]), tensor(-0.0001), tensor([-0.0008]))\n```", "```py\ndef calc_grad(xb, yb, model):\n    preds = model(xb)\n    loss = mnist_loss(preds, yb)\n    loss.backward()\n```", "```py\ncalc_grad(batch, train_y[:4], linear1)\nweights.grad.mean(),bias.grad\n```", "```py\n(tensor(-0.0002), tensor([-0.0015]))\n```", "```py\ncalc_grad(batch, train_y[:4], linear1)\nweights.grad.mean(),bias.grad\n```", "```py\n(tensor(-0.0003), tensor([-0.0023]))\n```", "```py\nweights.grad.zero_()\nbias.grad.zero_();\n```", "```py\ndef train_epoch(model, lr, params):\n    for xb,yb in dl:\n        calc_grad(xb, yb, model)\n        for p in params:\n            p.data -= p.grad*lr\n            p.grad.zero_()\n```", "```py\n(preds>0.0).float() == train_y[:4]\n```", "```py\ntensor([[False],\n        [ True],\n        [ True],\n        [False]])\n```", "```py\ndef batch_accuracy(xb, yb):\n    preds = xb.sigmoid()\n    correct = (preds>0.5) == yb\n    return correct.float().mean()\n```", "```py\nbatch_accuracy(linear1(batch), train_y[:4])\n```", "```py\ntensor(0.5000)\n```", "```py\ndef validate_epoch(model):\n    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n    return round(torch.stack(accs).mean().item(), 4)\n```", "```py\nvalidate_epoch(linear1)\n```", "```py\n0.5219\n```", "```py\nlr = 1.\nparams = weights,bias\ntrain_epoch(linear1, lr, params)\nvalidate_epoch(linear1)\n```", "```py\n0.6883\n```", "```py\nfor i in range(20):\n    train_epoch(linear1, lr, params)\n    print(validate_epoch(linear1), end=' ')\n```", "```py\n0.8314 0.9017 0.9227 0.9349 0.9438 0.9501 0.9535 0.9564 0.9594 0.9618 0.9613\n > 0.9638 0.9643 0.9652 0.9662 0.9677 0.9687 0.9691 0.9691 0.9696\n```", "```py\nlinear_model = nn.Linear(28*28,1)\n```", "```py\nw,b = linear_model.parameters()\nw.shape,b.shape\n```", "```py\n(torch.Size([1, 784]), torch.Size([1]))\n```", "```py\nclass BasicOptim:\n    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n\n    def step(self, *args, **kwargs):\n        for p in self.params: p.data -= p.grad.data * self.lr\n\n    def zero_grad(self, *args, **kwargs):\n        for p in self.params: p.grad = None\n```", "```py\nopt = BasicOptim(linear_model.parameters(), lr)\n```", "```py\ndef train_epoch(model):\n    for xb,yb in dl:\n        calc_grad(xb, yb, model)\n        opt.step()\n        opt.zero_grad()\n```", "```py\nvalidate_epoch(linear_model)\n```", "```py\n0.4157\n```", "```py\ndef train_model(model, epochs):\n    for i in range(epochs):\n        train_epoch(model)\n        print(validate_epoch(model), end=' ')\n```", "```py\ntrain_model(linear_model, 20)\n```", "```py\n0.4932 0.8618 0.8203 0.9102 0.9331 0.9468 0.9555 0.9629 0.9658 0.9673 0.9687\n > 0.9707 0.9726 0.9751 0.9761 0.9761 0.9775 0.978 0.9785 0.9785\n```", "```py\nlinear_model = nn.Linear(28*28,1)\nopt = SGD(linear_model.parameters(), lr)\ntrain_model(linear_model, 20)\n```", "```py\n0.4932 0.852 0.8335 0.9116 0.9326 0.9473 0.9555 0.9624 0.9648 0.9668 0.9692\n > 0.9712 0.9731 0.9746 0.9761 0.9765 0.9775 0.978 0.9785 0.9785\n```", "```py\ndls = DataLoaders(dl, valid_dl)\n```", "```py\nlearn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\n                loss_func=mnist_loss, metrics=batch_accuracy)\n```", "```py\nlearn.fit(10, lr=lr)\n```", "```py\ndef simple_net(xb):\n    res = xb@w1 + b1\n    res = res.max(tensor(0.0))\n    res = res@w2 + b2\n    return res\n```", "```py\nw1 = init_params((28*28,30))\nb1 = init_params(30)\nw2 = init_params((30,1))\nb2 = init_params(1)\n```", "```py\nplot_function(F.relu)\n```", "```py\nsimple_net = nn.Sequential(\n    nn.Linear(28*28,30),\n    nn.ReLU(),\n    nn.Linear(30,1)\n)\n```", "```py\nlearn = Learner(dls, simple_net, opt_func=SGD,\n                loss_func=mnist_loss, metrics=batch_accuracy)\n```", "```py\nlearn.fit(40, 0.1)\n```", "```py\nplt.plot(L(learn.recorder.values).itemgot(2));\n```", "```py\nlearn.recorder.values[-1][2]\n```", "```py\n0.982826292514801\n```", "```py\ndls = ImageDataLoaders.from_folder(path)\nlearn = cnn_learner(dls, resnet18, pretrained=False,\n                    loss_func=F.cross_entropy, metrics=accuracy)\nlearn.fit_one_cycle(1, 0.1)\n```"]