<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><div class="readable-text" id="p1"> 
   <h1 class=" readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">3</span> </span> <span class="chapter-title-text">Planning for improvement</span></h1> 
  </div> 
  <div class="introduction-summary"> 
   <h3 class="introduction-header">This chapter covers</h3> 
   <ul> 
    <li class="readable-text" id="p2">Building a cross-functional team that achieves conversational AI success</li> 
    <li class="readable-text" id="p3">Defining success through business goals, key metrics, and user pain points</li> 
    <li class="readable-text" id="p4">Analyzing effectiveness using outcomes and metrics to guide improvements</li> 
    <li class="readable-text" id="p5">Implementing structured processes for identifying, reporting, triaging, and prioritizing problems</li> 
   </ul> 
  </div> 
  <div class="readable-text" id="p6"> 
   <p>Every conversational AI solution should be built with success in mind, and success is defined differently depending on the type of chatbot involved. For instance, question-answering bots must deliver prompt, accurate responses while minimizing follow-up interactions. Process-oriented or transactional bots must guide users efficiently toward specific goals. Routing agents must seamlessly direct users to appropriate destinations.</p> 
  </div> 
  <div class="readable-text intended-text" id="p7"> 
   <p>However, misunderstanding user intent, excessive complexity, and immediate opt-outs can hinder progress and cause user pain. Addressing these challenges improves a chatbot’s performance and helps it achieve success. Organizations that continuously improve their chatbots are most likely to deliver optimal outcomes. </p> 
  </div> 
  <div class="readable-text intended-text" id="p8"> 
   <p>Combining diverse expertise within cross-functional teams is crucial for continuous improvement. The team members can drive change through their unique perspectives, skills, and insights. However, the team needs to agree on how to improve their solution.</p> 
  </div> 
  <div class="readable-text intended-text" id="p9"> 
   <p>The conversational analyst wants to simplify the dialogues, but the business wants to convey specific information. Who is right? In this chapter, we’ll show how a team at MediWorld, a fictional company, adapted and improved their chatbot. Their team started by enhancing their question-answering bot, but as user needs evolved, they transitioned to developing additional capabilities for a process-oriented bot.</p> 
  </div> 
  <div class="readable-text" id="p10"> 
   <h2 class=" readable-text-h2"><span class="num-string">3.1</span> Knowing when you need to improve</h2> 
  </div> 
  <div class="readable-text" id="p11"> 
   <p>Imagine the following scenario: </p> 
  </div> 
  <div class="readable-text" id="p12"> 
   <p><em>MediWorld, a large drug store, had call centers overloaded with questions about the pandemic. They deployed a chatbot to provide information related to COVID-19. The bot detected a focused set of intents about the virus and responded with reliable information. </em></p> 
  </div> 
  <div class="readable-text" id="p13"> 
   <p>Figure 3.1 illustrates PharmaBot efficiently recognizing these intents. <span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p14">  
   <img alt="figure" src="../Images/CH03_F01_Freed2.png" width="928" height="232"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 3.1</span> PharmaBot efficiently detected informational intents from user queries. </h5>
  </div> 
  <div class="readable-text" id="p15"> 
   <p><em>When vaccine availability was imminent, the nature of customer questions changed dramatically. Suddenly, everyone had a slew of different questions:</em></p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p16"> <em>Will I be eligible for the vaccine?</em> </li> 
   <li class="readable-text" id="p17"> <em>Can I get a vaccine appointment?</em> </li> 
   <li class="readable-text" id="p18"> <em>When can I get my second dose?</em> </li> 
   <li class="readable-text" id="p19"> <em>Do I have to call for an appointment, or can I set it up here?</em> </li> 
   <li class="readable-text" id="p20"> <em>Can I travel after my shot?</em> </li> 
  </ul> 
  <div class="readable-text" id="p21"> 
   <p><em>PharmaBot was initially weak at understanding these questions, frequently responding, “Sorry, I’m not sure what you’re asking. Please rephrase your question.” Users were frustrated and dissatisfied, and more conversations ended up in the call center after failing in the bot. There was also an increase in immediate opt-outs, reflecting an apparent disconnect between user expectations and PharmaBot’s capacity to address the evolving landscape. MediWorld’s team set out to improve the bot, but they first had to agree on what “improve” meant.</em></p> 
  </div> 
  <div class="readable-text print-book-callout" id="p22"> 
   <p><span class="print-book-callout-head">Note </span> The need for continuous improvement has never been more critical, as evolving user expectations and technological advancements demand constant refinement and adaptation. Bridget van Kralingen quipped, “The last best experience that anyone has anywhere becomes the minimum expectation for the experience they want everywhere.” Improvement requirements may come from internal sources (such as support of new features) or external sources (where an event drives new questions never seen before).</p> 
  </div> 
  <div class="readable-text" id="p23"> 
   <p>Recognizing the need to improve in conversational AI is pivotal to ensuring its effectiveness and relevance. A virtual assistant is not a static solution; its performance must evolve with user behavior, business needs, and advancements in technology. Signs that improvements are necessary often emerge through key performance indicators (KPIs) such as low containment rates, high fallback intent usage, or frequent agent escalations. Planning practical improvements starts with building a cross-functional team, defining clear success criteria, analyzing outcomes, and implementing structured processes for issue management.</p> 
  </div> 
  <div class="readable-text intended-text" id="p24"> 
   <p>When deciding when to start improving your conversational AI, best practices recommend beginning as soon as you notice recurring problems, declining engagement rates, or unmet business goals. A proactive approach can prevent small problems from escalating into larger problems. Establishing regular review cycles ensures that improvements align with evolving user expectations and organizational objectives.</p> 
  </div> 
  <div class="readable-text intended-text" id="p25"> 
   <p>Start your improvement journey by planning a comprehensive data collection strategy even before the first deployment. Remember, just having log files doesn’t automatically reveal the pain points. It’s essential to be methodical in identifying trends and patterns across user interactions. Many teams tend to fix isolated problems without considering the overall volume or frequency of those problems. While it may seem productive to address one-off problems, this rarely leads to meaningful improvements in overall performance. By focusing on systemic problems with significant effect, you can ensure your efforts are always directed toward tangible progress, making you feel focused and committed.</p> 
  </div> 
  <div class="readable-text intended-text" id="p26"> 
   <p>Remember, measuring performance before and after deploying changes is equally important. Establish baseline metrics before implementing fixes, and compare them with post-deployment data to assess whether the changes delivered the expected improvements. If the results don’t align with your expectations, don’t worry. Analyze the root cause further and iterate on your solution to effectively address any gaps or unforeseen problems. This process will give you the reassurance and confidence that your efforts are leading to tangible progress.</p> 
  </div> 
  <div class="readable-text" id="p27"> 
   <h2 class=" readable-text-h2"><span class="num-string">3.2</span> Your cross-functional team</h2> 
  </div> 
  <div class="readable-text" id="p28"> 
   <p>MediWorld recognized the critical role of its PharmaBot in providing timely and accurate customer support. A multidisciplinary team of conversational analysts, customer support experts, and data analysts came together to assess and enhance PharmaBot’s performance. This group aimed not only at addressing existing challenges but also proactively anticipating and meeting the evolving needs of the user base:</p> 
  </div> 
  <div class="readable-text" id="p29"> 
   <p><em>Developers at MediWorld focused on refining PharmaBot’s natural language processing capabilities. They found ways to enhance the chatbot’s understanding of user queries so it could provide precise and context-aware responses. </em></p> 
  </div> 
  <div class="readable-text intended-text" id="p30"> 
   <p><em>Simultaneously, lead call center agents shared valuable insights from the calls transferred to them, shedding light on common pain points and frequently asked questions. </em></p> 
  </div> 
  <div class="readable-text intended-text" id="p31"> 
   <p><em>The MediWorld data analysts delved into user interaction data. They identified areas where the chatbot “failed” and categorized those failures by the last task attempted by the bot.</em></p> 
  </div> 
  <div class="readable-text" id="p32"> 
   <p>Figure 3.2 shows the kinds of insights that each group brought to the table.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p33">  
   <img alt="figure" src="../Images/CH03_F02_Freed2.png" width="814" height="323"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 3.2</span> The team identified areas for improvement using their diverse skills, setting the stage for an effective improvement plan.</h5>
  </div> 
  <div class="readable-text" id="p34"> 
   <p>Let’s look beyond the PharmaBot example and focus on teams typically involved in a conversational AI improvement plan. The specific roles, responsibilities, and team size can vary based on your organization’s size, its goals, and the complexity of the chatbot. In smaller projects, individuals may take on multiple roles. Chapter 1 introduced a “dream team” for building conversational AI (figure 1.5). A similar diverse group is needed to improve and refine existing chatbots. While the structure of this team may differ across organizations, it generally consists of three key subteams, all working together. </p> 
  </div> 
  <div class="readable-text intended-text" id="p35"> 
   <p>First is the support and maintenance team for the chatbot. This team is tasked with analyzing and evaluating the chatbot’s performance. Additionally, they serve as technical subject matter experts (SMEs). They know the existing intents the chatbot handles, the training data for those intents, and the dialogue flows in the chatbot. They can implement code and technical changes. Their roles and tasks are outlined in table 3.1.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p36"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 3.1</span> The chatbot support and maintenance team</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Role 
       </div></th> 
      <th> 
       <div>
         Tasks 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  Data analyst/data engineer <br/></td> 
      <td>  Analyzes user interactions and feedback to make informed recommendations regarding changes, fixes, and enhancements. <br/></td> 
     </tr> 
     <tr> 
      <td>  Chatbot developer/ conversational analyst <br/></td> 
      <td>  Implements technical changes and enhancements to the chatbot. These may include new integrations (more of a developer role) or updates to the dialogues and actions of the chatbot (conversational analyst). <br/></td> 
     </tr> 
     <tr> 
      <td>  Quality assurance (QA) tester <br/></td> 
      <td>  Validates that a change, fix, or enhancement produces the desired outcome and does not result in any unexpected or negative outcomes. Testing may be manual or involve automated testing tools. <br/></td> 
     </tr> 
     <tr> 
      <td>  Project manager <br/></td> 
      <td>  Coordinates tasks; ensures that the continuous improvement process stays on schedule. <br/></td> 
     </tr> 
     <tr> 
      <td>  Other SMEs <br/></td> 
      <td>  Provide specialized knowledge in specific areas of the chatbot ecosystem; they may be brought on board as needed. For example, security experts assess potential threats and recommend appropriate security measures or remediation strategies to ensure the chatbot remains secure and resilient against evolving risks. <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p37"> 
   <p>The second subteam is business stakeholders. They collectively ensure that the chatbot improvements align with the broader organizational goals and the business needs. Business stakeholders ensure that the chatbot is technically proficient and aligned with organizational goals, user needs, and legal standards. This team is broken down in table 3.2.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p38"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 3.2</span> The chatbot’s business stakeholders</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Role 
       </div></th> 
      <th> 
       <div>
         Tasks 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  Executive leadership <br/></td> 
      <td>  Involved in aligning the improvements or the priorities of the improvements with overall business strategies <br/></td> 
     </tr> 
     <tr> 
      <td>  Customer service <br/></td> 
      <td>  Responsible for the business processes and workflows that the bot is addressing <br/></td> 
     </tr> 
     <tr> 
      <td>  Product manager (of the chatbot) <br/></td> 
      <td>  Responsible for overseeing the chatbot’s development and strategic direction, ensuring it meets business objectives <br/></td> 
     </tr> 
     <tr> 
      <td>  IT department <br/></td> 
      <td>  Provides technical support and infrastructure for the chatbot’s development, deployment, and maintenance <br/></td> 
     </tr> 
     <tr> 
      <td>  Operation manager <br/></td> 
      <td>  Collaborates to integrate the chatbot into operational processes, streamlining workflows <br/></td> 
     </tr> 
     <tr> 
      <td>  Legal and compliance teams <br/></td> 
      <td>  Ensure the improvements comply with industry regulations and legal requirements <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p39"> 
   <p>The final subteam is the governance team. Their role is to ensure that the chatbot’s deployment, use, and continuous improvement align with organizational policies, standards, and ethical considerations. They are identified in table 3.3.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p40"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 3.3</span> The chatbot’s governance team</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Role 
       </div></th> 
      <th> 
       <div>
         Tasks 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  Corporate ethics/compliance focal <br/></td> 
      <td>  Addresses ethical concerns about the chatbot’s behavior and decision-making as well as AI model risk management. They also ensure that their guidelines for responsible AI are followed through the improvement phase. <br/></td> 
     </tr> 
     <tr> 
      <td>  Governing executive team <br/></td> 
      <td>  Has the final say on prioritizing the system roadmap, backlog, and all costs (support or business team) associated with the system. <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p41"> 
   <p>Having a diverse and cross-functional improvement team ensures that different perspectives and expertise contribute to the development and oversight of the chatbot initiative. Regular meetings, clear communication channels, and documentation of governance policies are essential for the team’s effectiveness. Again, the specific stakeholders involved may vary based on the nature and scope of the project.</p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p42"> 
    <h5 class=" callout-container-h5 readable-text-h5">Exercises</h5> 
   </div> 
   <ol> 
    <li class="readable-text" id="p43"> Think about your last chatbot implementation, and list all the stakeholders you had. Discuss the stakeholder perspectives on the common goal of improving the chatbot and how this goal aligns with their specific objectives. Consider the potential conflicts between stakeholder interests and strategies for resolving them. </li> 
    <li class="readable-text" id="p44"> Alternatively, use MediWorld’s PharmaBot as an example, and consider the various stakeholders and their goals. </li> 
   </ol> 
  </div> 
  <div class="readable-text" id="p45"> 
   <h2 class=" readable-text-h2"><span class="num-string">3.3</span> Driving to the same goal</h2> 
  </div> 
  <div class="readable-text" id="p46"> 
   <p>Even within a single improvement team, different members may have conflicting priorities about what should be addressed first. Consider the following scenario: </p> 
  </div> 
  <div class="readable-text" id="p47"> 
   <p><em>When the PharmaBot team first met, they couldn’t agree on where to start. Everyone brought their “must-fix” lists. Some were hunches, some were informed by reading a few transcripts, and some came from detailed analysis. The team aligned on understanding the frequency of the problems: Do they come up in every conversation, or are they one-offs? Issue frequency was a key component in prioritizing fixes and enhancements, helping MediWorld enhance the performance of its chatbot. </em></p> 
  </div> 
  <div class="readable-text intended-text" id="p48"> 
   <p><em>Developers and data analysts advocated for refining PharmaBot’s natural language processing abilities, analyzing recent interactions to identify areas for improvement in understanding complex and context-dependent questions. Meanwhile, the lead call center agents emphasized the need for PharmaBot to offer more detailed and empathetic responses, focusing on recurring user concerns they had encountered. </em></p> 
  </div> 
  <div class="readable-text" id="p49"> 
   <p>A data-driven approach helps with prioritization. Addressing the most common pain points will lead to an immediate and tangible improvement in the overall user experience. Figure 3.2 demonstrated how multiple team members can contribute diverse observations and insights. Each member brought a unique perspective from their respective roles and expertise.</p> 
  </div> 
  <div class="readable-text" id="p50"> 
   <h3 class=" readable-text-h3"><span class="num-string">3.3.1</span> <em>Revisit business goals</em></h3> 
  </div> 
  <div class="readable-text" id="p51"> 
   <p>Conversational AI improvement team members must agree on the common goals of the improvement. The first critical step is reaching a consensus on what success means—the team must revisit the original business objectives that prompted the implementation of the chatbot. For instance, a question-answering bot must consistently respond quickly and accurately to user questions. A process-oriented bot must help users efficiently achieve their goals, like scheduling appointments or checking accounts. A routing agent must direct users to the place or specialist that can fulfill their needs based on their inquiry. Evaluating chatbot performance against these goals involves metrics such as response accuracy, user satisfaction, and the bot’s ability to handle a broad range of relevant topics and use cases.</p> 
  </div> 
  <div class="readable-text intended-text" id="p52"> 
   <p>As the business landscape evolves, adaptability becomes paramount. Changes in user expectations or technological advancements may necessitate enhancements or strategic shifts to maintain optimal chatbot performance. Therefore, the team must continuously reassess and refine the chatbot strategy, ensuring it remains aligned with the overarching organizational and user objectives. This iterative process caters to the evolving needs of the business and its users.</p> 
  </div> 
  <div class="readable-text" id="p53"> 
   <h4 class=" readable-text-h4">From business outcomes to metrics</h4> 
  </div> 
  <div class="readable-text" id="p54"> 
   <p>Defining the right metrics starts with understanding how business goals evolve over time. Consider the following scenario: </p> 
  </div> 
  <div class="readable-text" id="p55"> 
   <p><em>The PharmaBot team needed to align their efforts with the importance of efficient vaccine distribution and accessibility. While the original business goal was to answer questions and reduce the burden on their call centers, the business goals have changed to distributing vaccines effectively and automating the appointment-making process, which require different metrics. </em></p> 
  </div> 
  <div class="readable-text" id="p56"> 
   <p>When in doubt, consider your users—what do they need, and how do those needs drive business? What were the original business goals? What did users want? How are the two aligned? Recognize that these answers may shift over time. Figure 3.3 shows PharmaBot’s first business goal: providing accurate and up-to-date information about the new pandemic. Accuracy was the key metric.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p57">  
   <img alt="figure" src="../Images/CH03_F03_Freed2.png" width="894" height="174"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 3.3</span> PharmaBot started as a simple Q&amp;A bot. Many question varieties got the same answer.</h5>
  </div> 
  <div class="readable-text" id="p58"> 
   <p>Once a stable base was in place, the PharmaBot team added complexity and intelligence to the Q&amp;A bot. They detected entities (contextual elements relevant to an intent) to provide more targeted answers to their users and improve accuracy, as figure 3.4 demonstrates.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p59">  
   <img alt="figure" src="../Images/CH03_F04_Freed2.png" width="906" height="174"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 3.4</span> Q&amp;A got more complex by detecting entities in user utterances, leading to more specific answers within a common intent.</h5>
  </div> 
  <div class="readable-text" id="p60"> 
   <p>Then external influences changed the business objectives again. Vaccine availability shifted the nature of the bot. Instead of interacting with a pure Q&amp;A about the virus, users wanted to act directly through the bot to schedule vaccine appointments. This required process-oriented flows to collect multiple pieces of information. Figure 3.5 shows the start of this process flow.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p61">  
   <img alt="figure" src="../Images/CH03_F05_Freed2.png" width="927" height="96"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 3.5</span> Some question types do not have a single static answer but require a full process flow to satisfy.</h5>
  </div> 
  <div class="readable-text" id="p62"> 
   <p>These new capabilities brought complexity. Automating testing and vaccine appointments required integration with scheduling systems and databases. This brought heightened emphasis on security and privacy measures. Protecting users’ personal information, adhering to healthcare regulations, and ensuring secure transactions became paramount.</p> 
  </div> 
  <div class="readable-text intended-text" id="p63"> 
   <p>Not all conversational AI solutions have to deal with this evolution, at least not at the pace PharmaBot required. Managing a chatbot’s evolution requires thoughtful consideration of the costs and benefits associated with each aspect of the chatbot’s transformation.</p> 
  </div> 
  <div class="readable-text intended-text" id="p64"> 
   <p>The primary business goals for any conversational AI solution revolve around enhancing overall business outcomes. Every business has a goal or goals for the conversational system, which comes down to two key factors: revenue generation and cost reduction. These goals translate into metrics such as increased conversion rates, higher average order value (AOV), and enhanced customer lifetime value (CLV) for revenue growth. On the cost side, metrics like reduced average handling time (AHT), lower operational costs, and improved first-contact resolution (FCR) reflect cost savings. Organizations expect a measurable return on their investment (ROI), and these performance metrics guide continuous improvement efforts, aligning the conversational AI’s success directly with key business outcomes.</p> 
  </div> 
  <div class="readable-text intended-text" id="p65"> 
   <p>The business goals must be translated into measurable metrics. This allows a quantifiable assessment of how well the conversational AI meets its goals. The examples in table 3.4 demonstrate how businesses in various industries can define measurable metrics aligned with their specific goals. </p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p66"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 3.4</span> Sample metrics derived from business goals in various industries</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Business goal 
       </div></th> 
      <th> 
       <div>
         Resulting metrics 
       </div></th> 
      <th> 
       <div>
         Bot type 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  Increase online sales, and reduce customer service costs. <br/></td> 
      <td>  Percentage of checkouts completed by the chatbot without human intervention: Achieving 75% of automated checkouts, leading to a reduction of 100,000 customer service inquiries per day, resulting in a daily cost savings of $500,000. <br/></td> 
      <td>  Question answering <br/></td> 
     </tr> 
     <tr> 
      <td>  Improve customer support efficiency, and minimize service disruptions. <br/></td> 
      <td>  Percentage of inquiries successfully routed to the appropriate department or specialist: 90% of inquiries directed to the relevant support team without the need for manual intervention, leading to a decrease of 40,000 support tickets per day, resulting in a daily cost savings of $700,000. <br/></td> 
      <td>  Routing agent <br/></td> 
     </tr> 
     <tr> 
      <td>  Enhance booking experience, and decrease support costs. <br/></td> 
      <td>  Percentage of automated booking confirmations without agent intervention: Achieving 70% of automated booking confirmations, reducing 80,000 support inquiries per day, resulting in a daily cost savings of $640,000. <br/></td> 
      <td>  Process- oriented <br/></td> 
     </tr> 
     <tr> 
      <td>  Improve patient engagement, and optimize appointment scheduling. <br/></td> 
      <td>  Percentage of appointments scheduled autonomously by the virtual assistant: 90% of appointments are booked autonomously, reducing 30,000 manual scheduling tasks per day, resulting in a daily cost savings of $700,000. <br/></td> 
      <td>  Process- oriented <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p67"> 
   <p>Conversational metrics need clear links to business value to prove a return on investment. Metrics like call center deflection and routing accuracy reduce costs. Metrics like customer satisfaction lead to increased revenue when satisfied customers consume more services. The PharmaBot team achieved both cost savings and revenue growth by automating appointment scheduling. </p> 
  </div> 
  <div class="readable-text" id="p68"> 
   <h4 class=" readable-text-h4">Additional business drivers</h4> 
  </div> 
  <div class="readable-text" id="p69"> 
   <p>Beyond aligning with the core business goals discussed in the previous section, organizations should consider additional factors that drive value from conversational AI. Successful AI implementations do more than just support high-level objectives—they actively enhance customer engagement, optimize sales strategies, and reduce operational costs. </p> 
  </div> 
  <div class="readable-text intended-text" id="p70"> 
   <p>Conversational AI can strengthen customer interactions, guide sales, and suggest relevant products. Analyzing chatbot-driven conversion rates is crucial for refining strategies. Businesses that explore AI-driven features for upselling and cross-selling can maximize revenue opportunities. From an operational perspective, conversational AI helps by handling routine tasks, freeing human agents to focus on complex activities. Automating processes improves efficiency, reduces support costs, and enhances satisfaction with quicker responses.</p> 
  </div> 
  <div class="readable-text intended-text" id="p71"> 
   <p>A thorough analysis can uncover opportunities for improvement and for optimizing chatbot performance. As technology evolves, businesses should expand chatbot functions for ongoing cost reduction and operational excellence.</p> 
  </div> 
  <div class="readable-text intended-text" id="p72"> 
   <p>Competitor analysis, evaluating features like natural language understanding and personalized experiences, can guide continuous improvement. Regular updates enable adaptation to change in the competitive landscape, driving innovation for positive business outcomes.</p> 
  </div> 
  <div class="readable-text" id="p73"> 
   <h3 class=" readable-text-h3"><span class="num-string">3.3.2</span> Effectiveness</h3> 
  </div> 
  <div class="readable-text" id="p74"> 
   <p>When determining improvement priorities, another key factor to consider is the chatbot’s effectiveness. Does the chatbot do what it was intended to do? While the concept of “effectiveness” is simple (does it work as expected?), it goes beyond task completion. It involves providing a positive and efficient experience for users. </p> 
  </div> 
  <div class="readable-text intended-text" id="p75"> 
   <p>Let’s continue with our scenario, where the team is now looking at their dashboard showing chatbot metrics. Most chatbot development platforms have a simple analytics dashboard containing KPIs summarizing how users engage with the chatbots. These dashboards typically contain data on the number of conversations, chatbot confidence, and conversation duration. They may also include the most frequently asked questions or intents. </p> 
  </div> 
  <div class="readable-text intended-text" id="p76"> 
   <p>Figure 3.6 shows the analytics dashboard created for PharmaBot. While it shows some of the KPIs, it does not express PharmaBot’s effectiveness. The total number of conversations helps us understand traffic, but it does not help assess how many people successfully completed the chats or how far they went. <span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p77">  
   <img alt="figure" src="../Images/CH03_F06_Freed2.png" width="924" height="342"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 3.6</span> PharmaBot’s basic analytic dashboard shows a usage summary but cannot give insight into what users like (or don’t like) about the bot. </h5>
  </div> 
  <div class="readable-text" id="p78"> 
   <p><em>The team sought to determine the current assistance rate. Basic analytics gave them information on total inquiries per day, but they needed help figuring out how many of these were successful. The team needed to go beyond the mere quantity of conversations. Everyone knew that user demand was increasing. Was PharmaBot meeting the new demand? They needed to figure out how to measure the bot’s effectiveness and find ways to optimize its performance. The team found that 45% of all conversations transferred to the call center. This “containment” metric influenced the cost to the business. What could they do with this number?</em></p> 
  </div> 
  <div class="readable-text" id="p79"> 
   <p>In the PharmaBot team’s case, one key metric for measuring effectiveness was containment. <em>Contained conversations </em>are when the chatbot can fully handle a user query on its own; <em>uncontained conversations</em> require a human to be involved. The <em>containment rate</em> is calculated as the number of contained conversations divided by the number of total conversations. This metric provides a high-level measure of chatbot performance, as illustrated in figure 3.7.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p80">  
   <img alt="figure" src="../Images/CH03_F07_Freed2.png" width="913" height="335"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 3.7</span> Basic daily dashboard showing a simple business metric: containment. This metric is tracked daily but still does not give deep insights into bot performance.</h5>
  </div> 
  <div class="readable-text" id="p81"> 
   <p>PharmaBot’s dashboard implies a simple definition of success: “Contained calls are successful.” This mental model is summarized in figure 3.8. However, while containment is a valuable metric, it does not tell explain why users succeed (or fail) when interacting with the bot. A more detailed analysis is needed to gain deeper insights.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p82">  
   <img alt="figure" src="../Images/CH03_F08_Freed2.png" width="787" height="142"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 3.8</span> The simplest outcome definition. This does not give insight into how the bot can be improved.</h5>
  </div> 
  <div class="readable-text" id="p83"> 
   <h4 class=" readable-text-h4">Conversation outcomes</h4> 
  </div> 
  <div class="readable-text" id="p84"> 
   <p>To better understand how conversation outcomes affect chatbot improvement, let’s go back to our example scenario. The PharmaBot maintenance team needed to move beyond high-level performance metrics and analyze the actual conversation outcomes. Containment alone didn’t capture the full picture—it only told them whether or not a conversation stayed with the bot. But what really happened in those conversations? Here’s how they conducted an in-depth review of the conversations:</p> 
  </div> 
  <div class="readable-text" id="p85"> 
   <p><em>The team dived into a sea of transcripts to understand what happened in the conversations. How did they end? The team discovered a myriad of endings—successful completions, abandoned conversations, and a perplexing number of transfers.</em></p> 
  </div> 
  <div class="readable-text intended-text" id="p86"> 
   <p><em>The data analyst observed different flavors of success. First, the expected case where the PharmaBot responds well to the query and the user is satisfied. Second, there are handoffs to the call center due to business rules, like when the user lives in a state where MediWorld cannot do SMS confirmations. These handoffs are also successful, as they align with what PharmaBot set out to do: collect required information so a human specialist doesn’t have to. The team agreed that they needed to document these two kinds of cases separately. They labeled them as “Automated Resolution” and “Intentional Transfer.”</em></p> 
  </div> 
  <div class="readable-text intended-text" id="p87"> 
   <p><em>Then there were definite failure scenarios. Users asked for a human agent after the bot misunderstood them. The bot also automatically transferred users when it misunderstood them consecutively. And some users disconnected midway through appointment scheduling.</em></p> 
  </div> 
  <div class="readable-text intended-text" id="p88"> 
   <p><em>Lastly, the PharmaBot team found conversations where the users didn’t even try. Users were either silently disconnecting after the bot’s greeting or starting the conversation with the utterance “agent.” One team member remarked, “Perhaps there’s a psychological factor at play here: some users don’t want to engage with a bot. Let’s separate these conversations too.”</em></p> 
  </div> 
  <div class="readable-text intended-text" id="p89"> 
   <p><em>The team finally developed a nuanced categorization system: Success (automated resolution and intentional transfer), Failure (abandonment and escalation), Bot not wanted (immediate disconnect and immediate escalation).</em></p> 
  </div> 
  <div class="readable-text intended-text" id="p90"> 
   <p><em>Once the categorization system was in place, counting the conversations in each bucket was easy. The PharmaBot team was starting to really understand their bot’s performance.</em></p> 
  </div> 
  <div class="readable-text" id="p91"> 
   <p>Defining detailed conversation outcomes related to your metrics will give you insights into your solution’s performance. Conversation outcomes describe how user interactions with the chatbot conclude, categorizing whether the chatbot resolved the query, required human assistance, or resulted in an incomplete session. Defining these outcomes is critical to assessing and improving your solution against your business goals. Once your solution is deployed, analyze your conversation logs, and classify them against the outcome model.</p> 
  </div> 
  <div class="readable-text intended-text" id="p92"> 
   <p>Figure 3.9 shows a new detailed outcome model. It starts with containment on the left, and then it breaks down contained (and non-contained) outcomes with detailed reasons. Finally, these reasons are mapped back to success and failure categories. The reasons help us understand what went right and wrong in the bot. For instance, conversations may not be contained due to “failure”: maybe the user opted out or the bot repeatedly didn’t understand. Some conversations are intentionally transferred to humans following the underlying business process—those aren’t failures.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p93">  
   <img alt="figure" src="../Images/CH03_F09_Freed2.png" width="899" height="354"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 3.9</span> Breaking down why conversations are not contained gives more insight into bot performance and shows you where your bot needs improvement. One way to achieve this is by using detailed outcome classifications, which define the specific results of chatbot interactions. These classifications categorize conversations based on their resolution, user experience, and next steps. </h5>
  </div> 
  <div class="readable-text" id="p94"> 
   <p>Now that we’ve introduced the idea of a granular outcome model, considering how (where and why) a conversation might end, let’s look at the same metrics dashboard we saw in figure 3.7. Instead of looking at 45% containment, we can better understand the conversations. On the dashboard of figure 3.10, we replaced the containment rate chart with a success-rate chart, indicating success/failure/not wanted as the highest-level categories. <span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p95">  
   <img alt="figure" src="../Images/CH03_F10_Freed2.png" width="907" height="324"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 3.10</span> Enhancing the summary dashboard with a success rate. Not all contained calls are successful; not all transferred calls are failures.</h5>
  </div> 
  <div class="readable-text" id="p96"> 
   <p>In fact, you may want to illustrate the details of the outcomes as well. In figure 3.11, we show what this might look like. This approach enables you to quickly break down high-level outcomes into detailed outcomes, which could help you get stakeholder buy-in on improvements too.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p97">  
   <img alt="figure" src="../Images/CH03_F11_Freed2.png" width="861" height="431"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 3.11</span> The detailed outcome model depicts conversation outcomes and outcome details aggregated over a set time period. This provides much greater insight into bot performance than a binary “contained or not contained” model.</h5>
  </div> 
  <div class="readable-text" id="p98"> 
   <p>The detailed outcome model’s strength comes from its flexibility. Every conversational AI project can define its own unique outcome categorization. The model depicted in figure 3.11 is a useful sample implementation. As always, adjust this model for your needs. For example, if your chatbot does not have a human handoff, you can omit the escalation and transfer outcomes.</p> 
  </div> 
  <div class="readable-text intended-text" id="p99"> 
   <p>Here are some suggested categorizations for common types of conversational AI solutions.</p> 
  </div> 
  <div class="readable-text" id="p100"> 
   <p>For Q&amp;A bots:</p> 
  </div> 
  <ul> 
   <li class="readable-text buletless-item" id="p101"> Success—Conversation completion scenarios: 
    <ul> 
     <li> Automated resolution—The Q&amp;A bot successfully answers the user’s inquiry or provides relevant information without human intervention. </li> 
    </ul></li> 
   <li class="readable-text buletless-item" id="p102"> Failure—The interaction fails to achieve the desired outcome: 
    <ul> 
     <li> Abandoned—The user leaves the conversation before getting a good answer, possibly due to frustration or dissatisfaction with the bot’s responses. </li> 
     <li> Escalated—The Q&amp;A bot does not understand the user, and the interaction is escalated to a human agent for further assistance. This could occur by user request, or the bot may automatically escalate after multiple consecutive misunderstandings. </li> 
    </ul></li> 
   <li class="readable-text buletless-item" id="p103"> Chatbot not wanted: 
    <ul> 
     <li> Immediate disconnect—The user exits the conversation without ever sending a message to the bot. </li> 
     <li> Immediate escalation—The user’s first utterance to the bot is a request for a human agent. </li> 
    </ul></li> 
  </ul> 
  <div class="readable-text" id="p104"> 
   <p>For a transactional or process-oriented bot:</p> 
  </div> 
  <ul> 
   <li class="readable-text buletless-item" id="p105"> Success—Conversation completion scenarios: 
    <ul> 
     <li> Automated resolution—The process-oriented bot successfully completes the user’s intended task, such as booking an appointment, without human intervention. </li> 
     <li> Intentional transfer—If required by business rules, the bot transfers the interaction to a human agent, even though no “errors” were encountered. </li> 
    </ul></li> 
   <li class="readable-text buletless-item" id="p106"> Failure—The interaction fails to achieve the desired outcome: 
    <ul> 
     <li> Abandoned—The user abandons the conversation midway through the transaction, possibly due to complexity or confusion with the bot’s interface. </li> 
     <li> Escalated—The bot starts but cannot complete a process flow due to misunderstanding the user or the user’s request for a human agent. </li> 
    </ul></li> 
   <li class="readable-text buletless-item" id="p107"> Chatbot not wanted: 
    <ul> 
     <li> Immediate disconnect—The user exits the conversation without ever sending a message to the bot. </li> 
     <li> Immediate escalation—The user’s first utterance to the bot is a request for a human agent. </li> 
    </ul></li> 
  </ul> 
  <div class="readable-text" id="p108"> 
   <p>For a routing agent:</p> 
  </div> 
  <ul> 
   <li class="readable-text buletless-item" id="p109"> Success—Conversation completion scenarios: 
    <ul> 
     <li> Intentional transfer—The routing agent successfully directs the user to the correct department or specialist, potentially passing all information collected so far. A routing agent may have 0% containment and be working very well! </li> 
    </ul></li> 
   <li class="readable-text buletless-item" id="p110"> Failure—The interaction fails to achieve the desired outcome: 
    <ul> 
     <li> Abandoned—The user exits the conversation before being routed by the bot. </li> 
     <li> Escalated—The routing agent cannot gather enough information to route the user, either through misunderstanding or a user request for a human agent. </li> 
    </ul></li> 
   <li class="readable-text buletless-item" id="p111"> Chatbot not wanted: 
    <ul> 
     <li> Immediate disconnect—The user exits the conversation without ever sending a message to the bot. The user cannot be automatically routed. </li> 
     <li> Immediate escalation: The user’s first utterance to the bot is a request for a human agent, bypassing all automated routing. </li> 
    </ul></li> 
  </ul> 
  <div class="readable-text" id="p112"> 
   <p>When you categorize conversations like this, the number of conversations in each category helps you assess the effectiveness of the chatbot implementation and identify areas for improvement. </p> 
  </div> 
  <div class="readable-text intended-text" id="p113"> 
   <p>The detailed outcome model should be integrated with the conversational design. A great method is defining milestones for each of the bot’s “happy path” questions. Figure 3.12 shows this design for PharmaBot. The “Schedule appointment” milestone, shown in the shaded box, signifies a key step in which the bot completes the scheduling process. “Help with anything else?” is also shaded, indicating that the bot is ready to assist further after completing a primary task.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p114">  
   <img alt="figure" src="../Images/CH03_F12_Freed2.png" width="838" height="517"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 3.12</span> High-level design of PharmaBot with milestones for significant parts of the conversation. “Schedule appointment” and “Help with anything else?” are both marked as successful paths.</h5>
  </div> 
  <div class="readable-text" id="p115"> 
   <p>The FAQ intents have only one milestone (the FAQ response), whereas the process flow for appointments gathers multiple data points. The milestones that declare successful completions should be marked.</p> 
  </div> 
  <div class="readable-text intended-text" id="p116"> 
   <p>The detailed outcome model is most powerful when it’s overlaid with the design. When each conversation has an outcome and a “last milestone,” you can quickly find insights. In figure 3.13, we see PharmaBot’s metrics over time for failed conversations, including the last deployment date.</p> 
  </div> 
  <div class="browsable-container figure-container" id="p117">  
   <img alt="figure" src="../Images/CH03_F13_Freed2.png" width="802" height="407"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 3.13</span> When the outcome model and conversation design are overlaid, insights become apparent. This chart breaks down failed conversations by the last step before failure, helping identify where users struggle most. The different categories—such as appointment scheduling, intent detection, and zip code entry—show their relative contributions to overall failures over time. The spike after “Changes deployed” highlights the effect of recent updates, offering insights into areas needing further optimization.<span class="aframe-location"/></h5>
  </div> 
  <div class="readable-text" id="p118"> 
   <p>The PharmaBot team can further drill down into the failed conversations to view the detailed outcomes of abandoned and escalated. Combining the outcome model and the conversation design can jumpstart your data-driven analysis. It can tell you where to start your investigation.</p> 
  </div> 
  <div class="readable-text intended-text" id="p119"> 
   <p>The detailed outcome model in figure 3.11 provides deeper insights into user experience by revealing where and why conversations fail. In this case, the outcome is failure, and the primary reason is user escalation. However, looking at the specific points where users escalated—the last step before failure—provides actionable insights. The breakdown in the chart highlights key escalation points: during appointment scheduling, intent detection, member ID collection, and zip code entry. After changes were deployed, failures at the intent detection step dropped significantly, while failures in member ID and zip code collection saw slight declines. However, appointment scheduling failures spiked, indicating a new area of friction. This level of analysis allows the team to prioritize improvements effectively, ensuring that their fixes target the most pressing user pain points. While containment rate is often used as a high-level measure of effectiveness, it does not tell the full story—some containments may still result in poor user experiences, and some transfers may be necessary for a successful outcome. The outcome model in figure 3.13 helps the conversational AI team distinguish between these cases and refine the bot accordingly.</p> 
  </div> 
  <div class="readable-text" id="p120"> 
   <h4 class=" readable-text-h4">Customer satisfaction</h4> 
  </div> 
  <div class="readable-text" id="p121"> 
   <p>In the outcome model, we infer customer satisfaction through conversational outcomes. This is a quick method, but it’s indirect and can leave out some details. It can be useful to be more direct with customer satisfaction. </p> 
  </div> 
  <div class="readable-text intended-text" id="p122"> 
   <p>Customer satisfaction can be measured by gathering direct feedback from users. Thumbs up or down or a numeric satisfaction score are standard. The only drawback with these metrics is that the user response rate is often low—many users hate giving feedback—although unsatisfied users are more likely to take the chance to complain. </p> 
  </div> 
  <div class="readable-text intended-text" id="p123"> 
   <p>You can implement surveys after the chatbot concludes an interaction. The survey could include questions about ease of use, helpfulness, and overall satisfaction with the bot. In addition, net promoter score (NPS) surveys may also be presented to users. Keep the survey brief: the longer the survey, the less likely users are to complete it. </p> 
  </div> 
  <div class="readable-text intended-text" id="p124"> 
   <p>You can also assess customer satisfaction by reviewing a sample of conversations. The review can include chat logs or summaries from human agents who completed the conversation. These logs and summaries may even be categorized using large language models. Table 3.5 shows the types of feedback you can look for in each type of conversational outcome.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p125"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 3.5</span> Linking feedback to conversation outcome details</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Conversation outcome details 
       </div></th> 
      <th> 
       <div>
         User feedback 
       </div></th> 
      <th> 
       <div>
         Notes and caveats 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  Automated resolution (success) <br/></td> 
      <td>  Positive feedback or none <br/></td> 
      <td>  Users may give positive feedback to conclude an interaction (“thanks!”). But this is unlikely: most users disconnect once they get what they need. <br/></td> 
     </tr> 
     <tr> 
      <td>  Transfer (success) <br/></td> 
      <td>  Positive verbal feedback or no feedback. Not in chatlogs. <br/></td> 
      <td>  Users may give verbal feedback to the human agent about the bot, not to the chatbot directly. <br/></td> 
     </tr> 
     <tr> 
      <td>  Abandoned (failure) <br/></td> 
      <td>  Negative feedback or none (disconnection before a process completes) <br/></td> 
      <td>  User’s last comment to the bot may have negative sentiment (“I hate this!”). But many users won’t bother expressing their frustration—they just disconnect. <br/></td> 
     </tr> 
     <tr> 
      <td>  Escalated by user (failure) <br/></td> 
      <td>  Negative feedback <br/></td> 
      <td>  Users who request an agent mid- <br/>  process flow are unhappy (“get me to an agent!”). <br/></td> 
     </tr> 
     <tr> 
      <td>  Escalated by bot (failure) <br/></td> 
      <td>  None <br/></td> 
      <td>  When the bot initiates the escalation, we can’t prove the user was unhappy, but we could reasonably assume so. <br/></td> 
     </tr> 
     <tr> 
      <td>  Immediate disconnect (chatbot not wanted) <br/></td> 
      <td>  No feedback provided (no engagement) <br/></td> 
      <td>  Users who immediately disconnect may hate all chatbots, may hate your chatbot, or may have connected to it by accident. You can’t know for sure. <br/></td> 
     </tr> 
     <tr> 
      <td>  Immediate escalation (chatbot not wanted) <br/></td> 
      <td>  No feedback provided, or verbal negative feedback is given expressing desire for human assistance instead of chatbot use <br/></td> 
      <td>  Users who immediately escalate may hate all chatbots, may hate your chatbot, or may just prefer humans. You can’t know for sure. <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p126"> 
   <h3 class=" readable-text-h3"><span class="num-string">3.3.3</span> Coverage</h3> 
  </div> 
  <div class="readable-text" id="p127"> 
   <p>As part of improving chatbot effectiveness, identifying gaps in what the bot can handle (or, in other words, its <em>coverage</em>) is just as important as addressing escalations. In the ongoing analysis, it became clear that some user questions weren’t being misunderstood—they simply weren’t covered by the bot’s existing knowledge. The scenario continues as the team uncovers these gaps and works to expand PharmaBot’s capabilities: </p> 
  </div> 
  <div class="readable-text" id="p128"> 
   <p><em>The team prioritized tackling escalations first, since they have the biggest effect on the metrics. They analyzed transcripts from escalated conversations, and patterns started to emerge. Users often escalated right after the bot didn’t understand them. The data analyst cross-referenced these instances against the dialogue flow and suggested where they could improve the bot’s natural language processing capabilities. During this analysis, they found several questions that PharmaBot was not equipped to answer:</em></p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p129"> <em>“I heard about rare side effects. How can I distinguish between post-vaccine symptoms and something more serious that requires medical attention?”</em> </li> 
   <li class="readable-text" id="p130"> <em>“If I missed the recommended second dose of my COVID-19 vaccine by a few days, will it still be effective, or do I need to start over?”</em> </li> 
   <li class="readable-text" id="p131"> <em>“I’m pregnant, and I’m unsure about getting the COVID-19 vaccine. Can you provide information on the safety and potential benefits for pregnant individuals?”</em> </li> 
   <li class="readable-text" id="p132"> <em>“I’ve been diagnosed with an autoimmune condition. Can I still receive the COVID-19 vaccine, and are there any additional precautions I should take?”</em> </li> 
   <li class="readable-text" id="p133"> <em>“I’ve read conflicting information about the long-term effects of COVID-19 vaccines. What is known about their safety over an extended period, and are there ongoing studies?”</em> </li> 
  </ul> 
  <div class="readable-text" id="p134"> 
   <p><em>For questions like these, PharmaBot responded with “Sorry, I do not understand,” even after users tried to rephrase their questions. The team looked for clusters of questions with similar characteristics to see what the bot should be trained on next. Along with other intents, a group of inquiries related to vaccine safety emerged. </em></p> 
  </div> 
  <div class="readable-text" id="p135"> 
   <p>Coverage measures how many user questions the chatbot attempts to answer effectively. A chatbot with low coverage either lacks training data for key topics or struggles with overlapping and ambiguous intents, where similar questions confuse the model and prevent it from confidently selecting the correct response.</p> 
  </div> 
  <div class="readable-text intended-text" id="p136"> 
   <p>The team must analyze user interactions to improve coverage, identifying gaps where the chatbot fails to provide meaningful responses. This process involves assessing transcripts, tracking failed queries, and pinpointing recurring user needs currently unsupported. Addressing these gaps may require refining training data, restructuring intent classification, or introducing alternative approaches such as retrieval-augmented generation (RAG).</p> 
  </div> 
  <div class="readable-text intended-text" id="p137"> 
   <p>Several methods can enhance chatbot coverage, each addressing different challenges:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p138"> Chapter 5 explores improving weak understanding by refining training data, addressing missing intents, and optimizing labeling strategies. </li> 
   <li class="readable-text" id="p139"> Chapter 6 discusses how to bypass intent limitations using retrieval-based techniques combined with generative AI (RAG) to provide more dynamic and informed responses. </li> 
   <li class="readable-text" id="p140"> Chapter 7 demonstrates how generative AI can generate additional training and testing data to expand the chatbot’s ability to handle diverse queries. </li> 
  </ul> 
  <div class="readable-text" id="p141"> 
   <p>Regardless of the approach, improving chatbot coverage requires continuous analysis of real-world interactions. Examining user utterances, identifying common failure points, and iterating on the bot’s design ensures it evolves to meet users’ needs more effectively. </p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p142"> 
    <h5 class=" callout-container-h5 readable-text-h5">Exercises</h5> 
   </div> 
   <ol> 
    <li class="readable-text buletless-item" id="p143"> Consider the following chatbots and their business goals. Devise suitable metrics and goals for each chatbot type to evaluate their effectiveness and performance: 
     <ul> 
      <li> Bot 1—Customer support bot for an e-commerce website (Q&amp;A bot) </li> 
      <li> Bot 2—Banking bot for account management (transactional or process-oriented bot) </li> 
      <li> Bot 3—Customer service bot for a telecom company (routing bot) </li> 
     </ul></li> 
    <li class="readable-text buletless-item" id="p144"> Review the following scenarios found in the PharmaBot chatlogs. Based on the PharmaBot’s response to each scenario, assign an outcome from the model. Once you’ve assigned outcomes to each scenario, reflect on any patterns or trends you observe regarding the bot’s performance and areas for potential improvement. Recall that the conversation outcomes are success, failure, and chatbot not wanted. The outcome details are automated resolution (success), intentional transfer (success), abandoned (failure), escalated (failure), immediate disconnect (chatbot not wanted), and immediate escalation (chatbot not wanted): 
     <ul> 
      <li> Scenario 1<strong> </strong> </li> 
     </ul></li> 
   </ol> 
   <div class="browsable-container listing-container" id="p145"> 
    <div class="code-area-container"> 
     <pre class="code-area">User: "I heard about rare side effects. How can I distinguish between post-vaccine symptoms and something more serious that requires medical attention?" 
PharmaBot: "Hello! It's essential to be informed about potential side effects. Common side effects of COVID-19 vaccines include soreness at the injection site, fatigue, and mild fever. However, it's crucial to seek medical attention immediately if you experience severe symptoms like difficulty breathing or chest pain." 
User: "Thanks for the information, but what if I'm unsure whether my symptoms are severe enough to warrant medical attention?" 
PharmaBot: "If you're unsure, it's always better to err on the side of caution and consult a healthcare professional. They can assess your symptoms and provide guidance tailored to your specific situation." 
PharmaBot: "Would you like me to connect you with a healthcare professional to discuss your concerns further?" 
User: "Yes, please. That would be helpful." 
PharmaBot: "Great! Please hold for a moment while I transfer you to a human agent who can provide personalized assistance. Your health is our top priority." 
PharmaBot: (Initiates transfer to a human agent)</pre>  
    </div> 
   </div> 
   <ol style="list-style: none;"> 
    <li class=" buletless-item"> 
     <ul> 
      <li class="readable-text" id="p146"> Scenario 2 </li> 
     </ul></li> 
   </ol> 
   <div class="browsable-container listing-container" id="p147"> 
    <div class="code-area-container"> 
     <pre class="code-area">User: "If I missed the recommended second dose of my COVID-19 vaccine by a few days, will it still be effective, or do I need to start over?" 
PharmaBot: "Hello! It's important to follow the recommended vaccination schedule for optimal protection. If you've missed the second dose by a few days, it's best to contact your healthcare provider for guidance on the next steps." 
User: "I see. Will the delayed second dose affect the effectiveness of the vaccine?" 
PharmaBot: "The delay may impact the vaccine's effectiveness, but receiving the second dose as soon as possible is essential. Your healthcare provider can assess your individual situation and advise accordingly." 
User: "Got it, I'll contact my doctor for advice. Thanks for your help!" 
PharmaBot: "You're welcome! It's always best to consult with a healthcare professional for personalized guidance. If you have any more questions, feel free to ask."</pre>  
    </div> 
   </div> 
   <ol style="list-style: none;"> 
    <li class=" buletless-item"> 
     <ul> 
      <li class="readable-text" id="p148"> Scenario 3 </li> 
     </ul></li> 
   </ol> 
   <div class="browsable-container listing-container" id="p149"> 
    <div class="code-area-container"> 
     <pre class="code-area">User: "Hi there. I have a question about the COVID-19 vaccine." 
PharmaBot: "Hello! I'm here to help. What would you like to know about the COVID-19 vaccine?" 
User: "Agent" 
PharmaBot: "Of course! Let me connect you with one of our human agents who can assist you further." 
PharmaBot: (Initiates transfer to a human agent)</pre>  
    </div> 
   </div> 
   <ol style="list-style: none;"> 
    <li class=" buletless-item"> 
     <ul> 
      <li class="readable-text" id="p150"> Scenario 4 </li> 
     </ul></li> 
   </ol> 
   <div class="browsable-container listing-container" id="p151"> 
    <div class="code-area-container"> 
     <pre class="code-area">User: "Can you tell me about the ingredients in the COVID-19 vaccine?" 
PharmaBot: "Sorry, I don't understand. Could you please rephrase your question?" 
User: "What are the components of the COVID-19 vaccine?" 
PharmaBot: "I'm sorry, I still didn't quite get that. Can you try asking in a different way?" 
User: "What is the composition of the COVID-19 vaccine?" 
PharmaBot: "I'm having trouble understanding your question. Could you provide more context or try asking in simpler terms?" 
User: (hangs up)</pre>  
    </div> 
   </div> 
  </div> 
  <div class="readable-text" id="p152"> 
   <h2 class=" readable-text-h2"><span class="num-string">3.4</span> Identifying and resolving problems</h2> 
  </div> 
  <div class="readable-text" id="p153"> 
   <p>Identifying problems is crucial to continuously improving a conversational AI. The chatbot team needs a methodology for working through problems, including how to find problems, how to reason through them as a group, and how to determine when they are resolved. This methodology will allow the team to work toward a common goal. </p> 
  </div> 
  <div class="readable-text" id="p154"> 
   <h3 class=" readable-text-h3"><span class="num-string">3.4.1</span> Finding problems</h3> 
  </div> 
  <div class="readable-text" id="p155"> 
   <p>The best way to start finding problems is by examining trends in your conversation outcomes. It’s great to see successful conversations, but focus on the failed and “bot not wanted” conversations. Dig into the outcomes that have upward trends. As shown earlier, these outcomes are most insightful when overlaid on your conversational design. What was the last thing the user did before the negative outcome? Figure 3.14 dashboard helped the PharmaBot team.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p156">  
   <img alt="figure" src="../Images/CH03_F14_Freed2.png" width="802" height="407"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 3.14</span> A dashboard that breaks down an outcome by the last step taken, observed over time.</h5>
  </div> 
  <div class="readable-text" id="p157"> 
   <p>Ideally, your analysis tool can count and plot conversations by</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p158"> Conversation outcome </li> 
   <li class="readable-text" id="p159"> Last step taken in the conversation </li> 
   <li class="readable-text" id="p160"> Date and/or time of conversation </li> 
  </ul> 
  <div class="readable-text" id="p161"> 
   <p>Your conversational AI platform may already track these data points. Other platforms may need to be instrumented by adding context variables into key parts of your dialogue flow. With these metrics in place, teams can uncover unexpected user behaviors that affect chatbot performance. For example, when the PharmaBot team analyzed escalated conversations, they discovered a surprising pattern:</p> 
  </div> 
  <div class="readable-text" id="p162"> 
   <p><em>The PharmaBot team drilled into escalated conversations. They found many failures when PharmaBot asked users if their appointment was for vaccines or testing. Many users replied “yes”—a response that didn’t align with the expected format.</em></p> 
  </div> 
  <div class="readable-text intended-text" id="p163"> 
   <p><em>Recognizing the importance of understanding user behavior, the team realized that the bot’s inability to interpret this ambiguous “yes” response was causing frustration among users. Some even said “yes” again when PharmaBot repeated the question. This was a surprising source of both abandoned and escalated conversations. </em></p> 
  </div> 
  <div class="readable-text" id="p164"> 
   <p>Once a problem area is found, you can start designing a solution. The design is affected by how many ways the problem is encountered and can be addressed. In the “unexpected yes” scenario, there are two ways out: handle the “yes,” or try to get users to stop saying it.</p> 
  </div> 
  <div class="readable-text intended-text" id="p165"> 
   <p>Let’s look at a few more ways to find problems.</p> 
  </div> 
  <div class="readable-text" id="p166"> 
   <h4 class=" readable-text-h4">Qualitative problem exploration </h4> 
  </div> 
  <div class="readable-text" id="p167"> 
   <p>While metrics and conversation logs provide valuable insights, some chatbot problems are difficult to detect through quantitative analysis alone. Launching a qualitative improvement effort by collecting and analyzing user feedback allows you to uncover more user pain points. Let’s look at how the PharmaBot team went about their surveys:</p> 
  </div> 
  <div class="readable-text" id="p168"> 
   <p><em>To uncover deeper user frustrations, the PharmaBot team launched a qualitative improvement effort by collecting and analyzing direct user feedback. They encouraged users to share detailed descriptions of their challenges and expectations through a survey. Once the feedback was collected, the team categorized it to identify common pain points, as shown in table 3.6.</em></p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p169"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 3.6</span> Survey responses leading to identified pain points (part 1)</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         User 
       </div></th> 
      <th> 
       <div>
         Survey response 
       </div></th> 
      <th> 
       <div>
         Identified problem 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  1 <br/></td> 
      <td>  I tried asking about vaccine eligibility in different states, but the bot couldn’t provide clear information. Not knowing if I qualify for the vaccine when I plan to travel is frustrating. The responses seemed generic and didn’t address the complexity of eligibility criteria in various locations <br/></td> 
      <td>  PharmaBot understood the basic intent (eligibility) but failed to provide state-specific information. The chatbot did not consider the user’s location or the state they inquired about, leading to an unhelpful response. <br/></td> 
     </tr> 
     <tr> 
      <td>  2 <br/></td> 
      <td>  I attempted to schedule a vaccine appointment, but the process felt confusing. The bot’s instructions were unclear, and I felt unsure if my appointment was successfully booked. It would be helpful if the bot could provide more guidance throughout the scheduling process. <br/></td> 
      <td>  The scheduling workflow lacked clarity, causing users to feel uncertain about whether their appointment was successfully booked. <br/></td> 
     </tr> 
     <tr> 
      <td>  3 <br/></td> 
      <td>  (No survey response given; the user left the chat) <br/></td> 
      <td>  Overcomplicated steps discouraged users from completing the process. User 3 did not get to the survey. <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p170"> 
   <p>Unlike conversation logs, qualitative feedback provides direct insight into user frustrations—you don’t have to infer what went wrong. Combined with corresponding conversation transcripts, this feedback creates a clearer picture for the improvement team, making diagnosing and addressing chatbot deficiencies easier.</p> 
  </div> 
  <div class="readable-text intended-text" id="p171"> 
   <p>Recruiting users to provide actionable feedback can significantly enhance chatbot performance and user satisfaction. However, most users are reluctant to leave feedback. Providing small incentives or even a simple, genuine thank-you can encourage participation. If feedback is a key part of your improvement strategy, consider implementing a system that creates a win-win situation for both users and your team.</p> 
  </div> 
  <div class="readable-text print-book-callout" id="p172"> 
   <p><span class="print-book-callout-head">WARNING </span> The provided examples offer valuable insights into specific user challenges, but they may not be statistically significant. Don’t rush into solutions based on isolated instances. Look for repeated occurrences of the identified problems to gauge the scale and effect of each one.</p> 
  </div> 
  <div class="readable-text" id="p173"> 
   <h4 class=" readable-text-h4">Quantitative evaluation for issue discovery</h4> 
  </div> 
  <div class="readable-text" id="p174"> 
   <p>While qualitative feedback helps uncover user frustrations, it can also reveal measurable, functional problems. Challenges like slow response times or confusing dialogue flows can be quantified through conversation logs, which help teams diagnose problems and prioritize improvements. Let’s continue with our scenario to see what other problems were found: </p> 
  </div> 
  <div class="readable-text" id="p175"> 
   <p><em>In addition to finding descriptive </em><em>problems</em><em>, the PharmaBot team uncovered some addressable functional </em><em>problems</em><em>. A sample </em><em>problem</em><em> is shown in table 3.7.</em></p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p176"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 3.7</span> Survey responses leading to identified pain points (part 2)</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         User 
       </div></th> 
      <th> 
       <div>
         Survey response 
       </div></th> 
      <th> 
       <div>
         Identified problem 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  4 <br/></td> 
      <td>  It took the bot nearly 5 minutes to tell me about vaccine appointment availability. The delay was quite inconvenient, especially when trying to plan my schedule. A faster response would have been more helpful. I went to the bot to avoid being on hold! <br/></td> 
      <td>  Excessive response time frustrated users and diminished the chatbot’s value as a faster alternative to traditional customer support. <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p177"> 
   <p>Problems like this can be identified by analyzing the time taken for each step in a conversational log. You can track the average and maximum times taken at each step. Outliers may indicate poorly performing backend systems or confusing questions that users spend a lot of time thinking about.</p> 
  </div> 
  <div class="readable-text intended-text" id="p178"> 
   <p>This analysis could even be done on a subset of conversations. For instance, a slowly responding API is more likely to cause users to disconnect. Dive into the abandoned conversations, reviewing what the users were saying and how long the individual steps took. This kind of analysis can be done without asking users directly for feedback.</p> 
  </div> 
  <div class="readable-text intended-text" id="p179"> 
   <p>By identifying specific challenges associated with the conversation flow, analysts can target improvements in the conversational system effectively.</p> 
  </div> 
  <div class="readable-text" id="p180"> 
   <h3 class=" readable-text-h3"><span class="num-string">3.4.2</span> Group review</h3> 
  </div> 
  <div class="readable-text" id="p181"> 
   <p><em>After reviewing their conversational outcome metrics and user feedback, the PharmaBot team compiled a list of concrete </em><em>problems</em><em>. Now they must build their improvement plan, starting with prioritizing the </em><em>problems</em><em>. </em></p> 
  </div> 
  <div class="readable-text" id="p182"> 
   <h4 class=" readable-text-h4">Triaging the problems</h4> 
  </div> 
  <div class="readable-text" id="p183"> 
   <p>With these metrics in place, teams can uncover unexpected user behaviors that affect chatbot performance. For example, when the PharmaBot team analyzed escalated conversations, they discovered a surprising pattern: </p> 
  </div> 
  <div class="readable-text" id="p184"> 
   <p><em>The most critical </em>problem<em> identified in PharmaBot was the frequent misunderstanding of user queries, particularly in differentiating those about COVID-19 testing and vaccine-related appointments. Users got frustrated when the bot didn’t understand, frequently ending conversations in abandonment or escalation. The call center agents agreed that they heard this </em>problem<em> when listening to frustrated users. Analytics confirmed the high volumes of this </em>problem<em>. </em></p> 
  </div> 
  <div class="readable-text intended-text" id="p185"> 
   <p><em>The team agreed to address this high-priority problem. The business goal was to complete setting up appointments without human agent intervention. They had found a recurring pattern of why appointment completion failed: the bot was confused about what type of appointment the user wanted, and users felt misunderstood—many of the transactions failed. The bot caused pain points of both not understanding and being too complex.</em></p> 
  </div> 
  <div class="readable-text" id="p186"> 
   <p>To move forward after finding problems, teams must systematically evaluate and prioritize the problems based on their perceived value and expected effect on the system. This involves assessing factors such as how frequently the problem occurred, the cost of implementing a fix, and the potential benefits of resolving the problem. By taking a structured approach to prioritization, they can ensure that improvements deliver the most value with the resources available. In the PharmaBot scenario, the highest priority was given to fixing the misunderstanding around appointment types, as this directly affected the ability to complete the booking workflow, a core business objective. Figure 3.15 illustrates a sample assessment of a problem. For a more thorough depiction, insights might include the volume of the problem, conversational outcomes, affected user complexity of remedy, other affected flows, and more. <span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p187">  
   <img alt="figure" src="../Images/CH03_F15_Freed2.png" width="842" height="146"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 3.15</span> Analysis of an increase in escalated conversations within the Schedule Appointment flow, identifying a potential cause (new wording directing users to agents) and providing recommendations to improve</h5>
  </div> 
  <div class="readable-text" id="p188"> 
   <p>The problem analysis depicted in figure 3.15 can contribute to a broader triage process by helping prioritize chatbot improvements based on effect and resolution complexity. Each problem is documented similarly, with insights into the problem, likely causes, and proposed solutions. In a full triage process, many such problem entries are evaluated based on effect, frequency, and resolution effort to determine prioritization. The best prioritization practices consider value, proposed outcomes, and expected return. You must do a cost/benefit analysis. Benefits may be direct (improving containment) or indirect (improving the user experience). Costs may include time, effort, and complexity of the fix, and fixes that require buy-in from multiple departments will take longer. The expected return considers both benefits and costs, scaled by the volume of conversations affected. The goal is to focus on areas where the expected return justifies the investment of time and resources. An example of an expected return calculation for a problem is shown in figure 3.16. <span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p189">  
   <img alt="figure" src="../Images/CH03_F16_Freed2.png" width="900" height="362"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 3.16</span> Assessment of the cost of users reaching call center agents after abandoning their chatbot conversations in frustration</h5>
  </div> 
  <div class="readable-text" id="p190"> 
   <p>The cost effect can be easily calculated when a given dialogue flow is handled by a human agent instead of through the chatbot. This calculation considers the agent cost per call, the total number of calls per day, and the rate of conversations transferred to human agents. The priority of this problem is much easier to assign when it’s backed by this financial effect. This calculation can be repeated for all problem types. Remember that some costs are indirect: for example, a rude bot can lower customer satisfaction, making it challenging to quantify the financial effect. </p> 
  </div> 
  <div class="readable-text intended-text" id="p191"> 
   <p>Effort is another important prioritization driver. Just as there is a cost to the problem itself, there is also a cost to implementing the fix. Effort refers to the time, resources, and complexity involved in the implementation. The key is to balance the problem’s importance with the implementation speed. The best problems to fix are high effect and low effort. First, address those problems that have a high effect but can easily be done. Figure 3.17 categorizes improvement opportunities based on their effect and the effort required to implement them.</p> 
  </div> 
  <div class="browsable-container figure-container" id="p192">  
   <img alt="figure" src="../Images/CH03_F17_Freed2.png" width="665" height="263"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 3.17</span> An effect-effort matrix visualizes the relationship between the effort required and the potential effect of a proposed change.</h5>
  </div> 
  <div class="readable-text" id="p193"> 
   <p>High-priority items have high effect and low effort, followed by medium-priority items yielding incremental results. Low-priority items are those with low effect and high effort, and they are poorer candidates for fixing. This matrix can help teams prioritize their efforts effectively, focusing on changes that offer the greatest potential effect with the least amount of effort.</p> 
  </div> 
  <div class="readable-text intended-text" id="p194"> 
   <p>We can dive deeper into the categories presented in the matrix. For each category, we can provide sample problems, the user pain point they cause, and why they might occur. Table 3.8 starts with some high-effect and low-effort problems, and table 3.9 shows example high-effect, high-effort problems. Table 3.10 outlines some medium-effect, high-effort problems.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p195"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 3.8</span> Example high-effect and low-effort problems</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Problem 
       </div></th> 
      <th> 
       <div>
         User pain point 
       </div></th> 
      <th> 
       <div>
         Why the problem might occur 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  Incorrect or insufficient dialogue response <br/></td> 
      <td>  Chatbot doesn’t understand <br/></td> 
      <td>  Incorrect response due to poor intent recognition, input validation, or not adapting to the user’s context <br/></td> 
     </tr> 
     <tr> 
      <td>  Poor dialogue response <br/></td> 
      <td>  Chatbot is too complex <br/></td> 
      <td>  Format and/or text does not convey the information clearly. <br/></td> 
     </tr> 
     <tr> 
      <td>  Broken dialogue trees <br/></td> 
      <td>  Chatbot doesn’t work <br/></td> 
      <td>  The chatbot fails to function properly due to incorrect or misconfigured conditions and transitions within the conversation flow. These errors occur when the logic determining how the chatbot moves from one step to another (“jumps”) is flawed or has not been thoroughly tested. As a result, users may experience dead ends, irrelevant responses, or abrupt conversation drops, negatively affecting containment and user satisfaction. <br/></td> 
     </tr> 
     <tr> 
      <td>  Flow enhancements <br/></td> 
      <td>  Chatbot is too complex <br/></td> 
      <td>  Processes have particularly complex steps that users can’t easily complete. This is especially likely in long conversations. <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p196"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 3.9</span> Example high-effect, high-effort problems</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Problem 
       </div></th> 
      <th> 
       <div>
         User pain point 
       </div></th> 
      <th> 
       <div>
         Why the problem might occur 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  User unable to complete flow <br/></td> 
      <td>  Chatbot is too complex <br/></td> 
      <td>  Failures occur across many different steps in a process flow, necessitating a completely redesigned flow. <br/></td> 
     </tr> 
     <tr> 
      <td>  User questions are not addressed at all <br/></td> 
      <td>  Chatbot doesn’t understand <br/></td> 
      <td>  Insufficient intents are implemented to cover user demand. This may require adding search or retrieval-augmented generation to handle infrequent question types. <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p197"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 3.10</span> Example medium-effect, high-effort problems</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Problem 
       </div></th> 
      <th> 
       <div>
         User pain point 
       </div></th> 
      <th> 
       <div>
         Why the problem might occur 
       </div></th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  Incomplete dialogue response (due to failed API) <br/></td> 
      <td>  Chatbot doesn’t understand <br/></td> 
      <td>  Incomplete response due to API failure. The bot may not support all API request or response variations. <br/></td> 
     </tr> 
     <tr> 
      <td>  Intent confusion <br/></td> 
      <td>  Chatbot doesn’t understand <br/></td> 
      <td>  Intent confusion can occur when the training data is imbalanced, meaning that certain intents have too few or too many example utterances, leading to misclassification. Additionally, discrepancies between training data and real-world user queries can make it difficult for the chatbot to recognize the correct intent. <br/></td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p198"> 
   <p>These categorizations are not hard and fast. You should adjust the relative prioritization of changes based on the frequency with which the problems occur. </p> 
  </div> 
  <div class="readable-text" id="p199"> 
   <h4 class=" readable-text-h4">Solutioning the high-level fix </h4> 
  </div> 
  <div class="readable-text" id="p200"> 
   <p>Once a high-priority problem is identified, the next crucial step is <em>solutioning</em>—outlining a high-level fix to rectify the problem. This involves a collaborative effort with the team working together to formulate a comprehensive solution. To ensure a structured approach, the team must address three fundamental questions: Who will be responsible for implementing the fix? What changes need to be made? How will the solution be implemented? The “who” encompasses the specific roles and responsibilities of the team that implements the fix. The “what” defines the nature of the solution, whether it involves refining the bot’s natural language processing capabilities, improving contextual understanding, or implementing a more sophisticated intent recognition system. The “how” outlines the technical approach and methodologies required for the implementation.</p> 
  </div> 
  <div class="readable-text intended-text" id="p201"> 
   <p>Additionally, the team must determine the development effort involved, considering factors such as coding complexity, integration requirements, and potential dependencies on external systems. This solutioning phase is crucial for devising a well-informed plan for continuous improvement.</p> 
  </div> 
  <div class="readable-text" id="p202"> 
   <h4 class=" readable-text-h4">Assigning priorities to all fixes</h4> 
  </div> 
  <div class="readable-text" id="p203"> 
   <p>A prioritized fix table is an indispensable tool for steering improvement initiatives. The table encapsulates a structured approach by assigning priority numbers, articulating concise descriptions of identified problems, proposing recommended changes, quantifying the potential effect on the user experience, and providing direct links to associated GitHub issues. This comprehensive framework not only streamlines the development process but also facilitates efficient communication and collaboration among team members. Figure 3.18 shows a sample prioritized fix table. <span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p204">  
   <img alt="figure" src="../Images/CH03_F18_Freed2.png" width="927" height="275"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 3.18</span> A sample prioritized fix table </h5>
  </div> 
  <div class="readable-text" id="p205"> 
   <p>Each column of the table plays a critical role in organizing and addressing problems effectively:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p206"> <em>Priority</em><em> </em>—Helps establish the urgency of each problem, ensuring that critical problems are addressed first. </li> 
   <li class="readable-text" id="p207"> <em>Description</em><em> </em>—Provides a brief but clear overview of the identified problem. </li> 
   <li class="readable-text" id="p208"> <em>Recommended change</em><em> </em>—Specifies the proposed solution or modification to rectify the problem, guiding development efforts. </li> 
   <li class="readable-text" id="p209"> <em>Value/effect</em><em> </em>—Quantifies the expected improvement in user satisfaction or usability resulting from the recommended change, aiding in prioritization. </li> 
   <li class="readable-text" id="p210"> <em>ID</em><em> </em>—Establishes a direct link to the corresponding problem in the project’s issue tracker, such as a GitHub repository. This streamlines collaboration and tracks progress on the resolution of each problem. The GitHub issue may also provide further elaboration, progress, and status on the problem.  </li> 
  </ul> 
  <div class="readable-text" id="p211"> 
   <h3 class=" readable-text-h3"><span class="num-string">3.4.3</span> Determining acceptance criteria</h3> 
  </div> 
  <div class="readable-text" id="p212"> 
   <p>Once the key problems have priorities and a high-level solution, the next step is to define the fix’s acceptance criteria. Simply, how will we know when this problem has been resolved? Acceptance criteria are useful for validating functionality in the development environment and verifying improvements in production.</p> 
  </div> 
  <div class="readable-text intended-text" id="p213"> 
   <p>For instance, when PharmaBot could not handle “yes” to “Is your appointment for vaccines or testing?” the acceptance criteria might look like this:</p> 
  </div> 
  <ol> 
   <li class="readable-text" id="p214"> When PharmaBot asks users to choose between vaccines and testing, and they say “vaccines,” they get vaccine appointments. </li> 
   <li class="readable-text" id="p215"> When PharmaBot asks users to choose between vaccines and testing, and they say “testing,” they get testing appointments. </li> 
   <li class="readable-text" id="p216"> When PharmaBot asks users to choose between vaccines and testing, and they say “yes,” it asks them to confirm that they want vaccine appointments. </li> 
  </ol> 
  <div class="readable-text" id="p217"> 
   <p>These acceptance criteria help the testing team validate current functionality (criteria 1 and 2) and new functionality (criteria 3). The fix can’t be deployed until it meets the acceptance criteria. </p> 
  </div> 
  <div class="readable-text intended-text" id="p218"> 
   <p>Once the fix is deployed, the team can verify that the number of conversations ending (and failing) with “yes” to the “vaccine or testing” question dramatically decreases or disappears altogether—for example, did the original metrics improve? Clear and measurable standards ensure your team is aligned with user expectations and project goals, setting the stage for successful bot improvement.</p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p219"> 
    <h5 class=" callout-container-h5 readable-text-h5">Exercises</h5> 
   </div> 
   <ol> 
    <li class="readable-text" id="p220"> The following sample problems are related to conversational AI implementation, each with varying degrees of complexity. Your task is to prioritize these problems based on their effect on the conversational AI system’s effectiveness and efficiency, considering both qualitative and quantitative volume metrics. Assess the complexity of the problem as an input to your prioritization. The examples cover various industries, as the improvement and prioritization efforts are applicable across chatbot types and domains. 
     <ol style="list-style: lower-alpha"> 
      <li> Inaccurate response generation: </li> 
     </ol> 
     <ul> 
      <li> Description: The chatbot occasionally provides inaccurate or irrelevant responses to user queries, leading to user dissatisfaction and confusion. </li> 
      <li> Effect: High—It affects user experience and trust in the chatbot’s capabilities. </li> 
      <li> Volume metric: Frequency of inaccurate daily responses (e.g., 15% of total responses). </li> 
     </ul></li> 
   </ol> 
   <div class="browsable-container listing-container" id="p221"> 
    <div class="code-area-container"> 
     <pre class="code-area">Sample Chat: 
User: "Can you tell me about the vaccine side effects?" 
Chatbot: "The COVID-19 vaccine is safe and effective."
User: "But I heard about people experiencing severe reactions.   Can you provide more information?" 
Chatbot: "The vaccine is safe and effective."
Users: (hangs up)</pre>  
    </div> 
   </div> 
   <ol style="list-style: none;"> 
    <li style="list-style: none;"> 
     
	<ol class=" faux-ol-li" style="list-style: none;"> 
      <li class="readable-text faux-li has-faux-ol-li-counter" id="p222"><span class="faux-ol-li-counter">b. </span> Slow response time:  
     
		<ul style="list-style: circle"> 
      <li> Description: The chatbot takes too long to generate responses, leading to user frustration and impatience, especially in time-sensitive situations. </li> 
      <li> Effect: Moderate—it negatively affects user satisfaction and engagement with the chatbot. </li> 
      <li> Volume metric: Percentage of user queries with misunderstood language per day (e.g., 8% of total queries). </li> 
     </ul>
		</li> 
     </ol></li> 
   </ol> 



   <div class="browsable-container listing-container" id="p223"> 
    <div class="code-area-container"> 
     <pre class="code-area">Sample Chat: 
User: "Can you give me the scoop on the COVID jab?" 
Chatbot: "I'm sorry, I don't understand what you are asking. Could you please rephrase your question?"</pre>  
    </div> 
   </div> 
   <ol style="list-style: none;"> 
    <li style="list-style: none;"> 
     <ol class=" faux-ol-li" style="list-style: none;"> 
      <li class="readable-text faux-li has-faux-ol-li-counter" id="p224"><span class="faux-ol-li-counter">c. </span> Limited language understanding: 
     <ul style="list-style: circle"> 
      <li> Description: The chatbot struggles to understand queries that use colloquial language, slang, or complex syntax, resulting in misinterpretation and inadequate responses. </li> 
      <li> Effect: Moderate—it restricts the bot’s ability to engage with users effectively, leading to frustration and reduced user satisfaction. </li> 
      <li> Volume metric: Average response time in seconds per user query (e.g., 8 seconds). </li> 
     </ul>
</li> 
     </ol> </li> 
   </ol> 
   <div class="browsable-container listing-container" id="p225"> 
    <div class="code-area-container"> 
     <pre class="code-area">Sample Chat: 
User: "Can you provide information about COVID testing locations?" (Long pause, user hangs up.)</pre>  
    </div> 
   </div> 
   <ol style="list-style: none;"> 
    <li style="list-style: none;"> 
     <ol class=" faux-ol-li" style="list-style: none;"> 
      <li class="readable-text faux-li has-faux-ol-li-counter" id="p226"><span class="faux-ol-li-counter">d. </span> Inconsistent integration with backend systems:  
     <ul style="list-style: circle"> 
      <li> Description: The chatbot experiences inconsistencies in integrating with backend systems, resulting in incomplete or incorrect information being provided to users. </li> 
      <li> Effect: High—it undermines the chatbot’s reliability and erodes user trust in its ability to provide accurate information. </li> 
      <li> Volume metric: Percentage of conversations with backend integration errors per day (e.g., 12% of total conversations). </li> 
     </ul></li> 
     </ol></li> 
   </ol> 
   <div class="browsable-container listing-container" id="p227"> 
    <div class="code-area-container"> 
     <pre class="code-area">Sample Chat: 
User: "Can you check if there are any vaccine appointments available tomorrow?" 
Chatbot: "I'm sorry, I'm experiencing some technical difficulties. Please try again later."</pre>  
    </div> 
   </div> 
   <ol class=" faux-ol-li" style="list-style: none;"> 
    <li class="readable-text faux-li has-faux-ol-li-counter" id="p228"><span class="faux-ol-li-counter">2. </span> Use sample conversations from your latest implementation, and repeat the preceding exercise with the data from your chatbot. </li> 
   </ol> 
  </div> 
  <div class="readable-text" id="p229"> 
   <h2 class=" readable-text-h2"><span class="num-string">3.5</span> Developing and delivering fixes</h2> 
  </div> 
  <div class="readable-text" id="p230"> 
   <p>Continuous improvement is often achieved through fixed-duration iterations, commonly known as sprints. Sprint iterations range from one to four weeks, depending on your organization’s preference. While the prioritized fix table provides a general roadmap, the sprint plan specifically defines the next batch of functions to be delivered to users. The sprint plan is affected by resource availability: how much work you can develop and test in a time frame. It also prepares stakeholders for what they can next expect from your solution. </p> 
  </div> 
  <div class="readable-text" id="p231"> 
   <h3 class=" readable-text-h3"><span class="num-string">3.5.1</span> Sprint planning</h3> 
  </div> 
  <div class="readable-text" id="p232"> 
   <p>This process establishes a systematic approach to issue tracking and resolution. It serves as the cornerstone for a well-coordinated, agile development journey, ensuring that your bot evolves in alignment with the proposed solutions and within the designated timelines. Various tools, such as kanban boards, exist to visualize the state of a sprint throughout its duration. The most basic sprint visualization should include the problems being worked on and their status in the plan or execution cycle. Figure 3.19 shows one visualization that augments the fix table (figure 3.18) with two additional columns: status and the timeline, indicating the planned sprint.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p233">  
   <img alt="figure" src="../Images/CH03_F19_Freed2.png" width="927" height="286"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 3.19</span> A prioritized table, including development sprints. Further columns, including UAT times and expected deployment dates, may be added.</h5>
  </div> 
  <div class="readable-text" id="p234"> 
   <h3 class=" readable-text-h3"><span class="num-string">3.5.2</span> Measure again</h3> 
  </div> 
  <div class="readable-text" id="p235"> 
   <p><em>PharmaBot’s team worked hard on improvements. When these improvements moved to production, the team monitored the metrics they expected to influence. By tracking failure outcomes against their past two deployments, they confirmed the fixes worked as expected.</em></p> 
  </div> 
  <div class="readable-text" id="p236"> 
   <p>Figure 3.20 shows the dashboard the PharmaBot team used. <span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p237">  
   <img alt="figure" src="../Images/CH03_F20_Freed2.png" width="818" height="410"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 3.20</span> Tracking conversation outcomes against the deployment of changes</h5>
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p238"> 
    <h5 class=" callout-container-h5 readable-text-h5">Exercises</h5> 
   </div> 
   <ol> 
    <li class="readable-text buletless-item" id="p239"> Sprint planning is crucial in addressing fixes and improvements in PharmaBot’s development and delivery process. In these exercises, you will simulate a sprint planning session to prioritize fixes and enhancements for PharmaBot’s iterative development cycle. You have two conversational analysts, a part-time backend developer, and a tester: 
     <ul> 
      <li> Review the prioritized fix table you created in the previous exercise. </li> 
      <li> Consider the capacity and velocity of the development team and allocate resources. </li> 
      <li> Create a sprint plan. Using a kanban board or similar tool, create a sprint plan that includes the prioritized fixes and enhancements, along with estimated effort and expected completion times. Consider adding columns for status and sprint inclusion to track progress and ensure transparency throughout the sprint. </li> 
      <li> Discuss expected deployment dates for the fixes and enhancements planned for the sprint. </li> 
     </ul></li> 
   </ol> 
  </div> 
  <div class="readable-text" id="p240"> 
   <h2 class=" readable-text-h2">Summary</h2> 
  </div> 
  <ul> 
   <li class="readable-text" id="p241"> The continuous improvement cycle for conversational systems is an ongoing, iterative process. </li> 
   <li class="readable-text" id="p242"> All improvements should drive toward the predefined business goals and user satisfaction. </li> 
   <li class="readable-text" id="p243"> Meticulous metric definition, the right choice of monitoring tools, and a commitment to best practices are key. </li> 
   <li class="readable-text" id="p244"> Use the “right” metrics relevant to your bot rather than those that are easiest to measure. </li> 
   <li class="readable-text" id="p245"> Detailed conversation outcomes allow you to target a specific set of conversations for improvement. </li> 
   <li class="readable-text" id="p246"> Several factors can determine a problem’s priority, such as its frequency of occurrence, the expected improvement and complexity of a fix, and the team’s capacity. </li> 
   <li class="readable-text" id="p247"> Regression testing and the analysis of improvements are critical to ensuring improvements have occurred. </li> 
  </ul>
 </div></div></body></html>