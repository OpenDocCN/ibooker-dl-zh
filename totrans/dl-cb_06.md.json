["```py\n06.1 Question matching\n```", "```py\nxml_7z = utils.get_file(\n    fname='travel.stackexchange.com.7z',\n    origin=('https://ia800107.us.archive.org/27/'\n            'items/stackexchange/travel.stackexchange.com.7z'),\n)\n```", "```py\ndef extract_stackexchange(filename, limit=1000000):\n    json_file = filename + 'limit=%s.json' % limit\n\n    rows = []\n    for i, line in enumerate(os.popen('7z x -so \"%s\" Posts.xml'\n                             % filename)):\n        line = str(line)\n        if not line.startswith('  <row'):\n            continue\n\n        if i % 1000 == 0:\n            print('\\r%05d/%05d' % (i, limit), end='', flush=True)\n\n        parts = line[6:-5].split('\"')\n        record = {}\n        for i in range(0, len(parts), 2):\n            k = parts[i].replace('=', '').strip()\n            v = parts[i+1].strip()\n            record[k] = v\n        rows.append(record)\n\n        if len(rows) > limit:\n            break\n\n    with open(json_file, 'w') as fout:\n        json.dump(rows, fout)\n\n    return rows\n\nrows = download_stackexchange()\n```", "```py\ndf = pd.DataFrame.from_records(rows)\ndf = df.set_index('Id', drop=False)\ndf['Title'] = df['Title'].fillna('').astype('str')\ndf['Tags'] = df['Tags'].fillna('').astype('str')\ndf['Body'] = df['Body'].fillna('').astype('str')\ndf['Id'] = df['Id'].astype('int')\ndf['PostTypeId'] = df['PostTypeId'].astype('int')\n```", "```py\nlist(df[df['ViewCount'] > 2500000]['Title'])\n```", "```py\n['How to horizontally center a &lt;div&gt; in another &lt;div&gt;?',\n 'What is the best comment in source code you have ever encountered?',\n 'How do I generate random integers within a specific range in Java?',\n 'How to redirect to another webpage in JavaScript/jQuery?',\n 'How can I get query string values in JavaScript?',\n 'How to check whether a checkbox is checked in jQuery?',\n 'How do I undo the last commit(s) in Git?',\n 'Iterate through a HashMap',\n 'Get selected value in dropdown list using JavaScript?',\n 'How do I declare and initialize an array in Java?']\n```", "```py\nfrom keras.preprocessing.text import Tokenizer\nVOCAB_SIZE = 50000\n\ntokenizer = Tokenizer(num_words=VOCAB_SIZE)\ntokenizer.fit_on_texts(df['Body'] + ' ' + df['Title'])\n```", "```py\ndf['title_tokens'] = tokenizer.texts_to_sequences(df['Title'])\ndf['body_tokens'] = tokenizer.texts_to_sequences(df['Body'])\n```", "```py\ntitle = layers.Input(shape=(None,), dtype='int32', name='title')\nbody = layers.Input(shape=(None,), dtype='int32', name='body')\n```", "```py\n embedding = layers.Embedding(\n        mask_zero=True,\n        input_dim=vocab_size,\n        output_dim=embedding_size\n    )\n\nmask = layers.Masking(mask_value=0)\ndef _combine_sum(v):\n    return K.sum(v, axis=2)\n\nsum_layer = layers.Lambda(_combine_sum)\n```", "```py\ntitle_sum = sum_layer(mask(embedding(title)))\nbody_sum = sum_layer(mask(embedding(body)))\n```", "```py\nsim = layers.dot([title_sum, word_sum], normalize=True, axes=1)\n```", "```py\nsim_model = models.Model(inputs=[title,body], outputs=[sim])\nsim_model.compile(loss='mse', optimizer='rmsprop')\n```", "```py\ndef data_generator(batch_size, negative_samples=1):\n    questions = df[df['PostTypeId'] == 1]\n    all_q_ids = list(questions.index)\n\n    batch_x_a = []\n    batch_x_b = []\n    batch_y = []\n\n    def _add(x_a, x_b, y):\n        batch_x_a.append(x_a[:MAX_DOC_LEN])\n        batch_x_b.append(x_b[:MAX_DOC_LEN])\n        batch_y.append(y)\n\n    while True:\n        questions = questions.sample(frac=1.0)\n\n        for i, q in questions.iterrows():\n            _add(q['title_tokens'], q['body_tokens'], 1)\n\n            negative_q = random.sample(all_q_ids, negative_samples)\n            for nq_id in negative_q:\n                _add(q['title_tokens'],\n                     df.at[nq_id, 'body_tokens'], 0)\n\n            if len(batch_y) >= batch_size:\n                yield ({\n                    'title': pad_sequences(batch_x_a, maxlen=None),\n                    'body': pad_sequences(batch_x_b, maxlen=None),\n                }, np.asarray(batch_y))\n\n                batch_x_a = []\n                batch_x_b = []\n                batch_y = []\n```", "```py\nsim_model.fit_generator(\n    data_generator(batch_size=128),\n    epochs=10,\n    steps_per_epoch=1000\n)\n```", "```py\nembedding_model = models.Model(inputs=[title], outputs=[title_sum])\n```", "```py\nquestions = df[df['PostTypeId'] == 1]['Title'].reset_index(drop=True)\nquestion_tokens = pad_sequences(tokenizer.texts_to_sequences(questions))\n\nclass EmbeddingWrapper(object):\n    def __init__(self, model):\n        self._questions = questions\n        self._idx_to_question = {i:s for (i, s) in enumerate(questions)}\n        self._weights = model.predict({'title': question_tokens},\n                                      verbose=1, batch_size=1024)\n        self._model = model\n        self._norm = np.sqrt(np.sum(self._weights * self._weights\n                                    + 1e-5, axis=1))\n\n    def nearest(self, question, n=10):\n        tokens = tokenizer.texts_to_sequences([sentence])\n        q_embedding = self._model.predict(np.asarray(tokens))[0]\n        q_norm= np.sqrt(np.dot(q_embedding, q_embedding))\n        dist = np.dot(self._weights, q_embedding) / (q_norm * self._norm)\n\n        top_idx = np.argsort(dist)[-n:]\n        return pd.DataFrame.from_records([\n            {'question': self._r[i], \u2018similarity': float(dist[i])}\n            for i in top_idx\n        ])\n```", "```py\nlookup = EmbeddingWrapper(model=sum_embedding_trained)\nlookup.nearest('Python Postgres object relational model')\n```"]