- en: Chapter 10\. Building Neural Networks with PyTorch
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第 10 章\. 使用 PyTorch 构建神经网络
- en: PyTorch is a powerful open source deep learning library developed by Facebook’s
    AI Research lab (FAIR, now called Meta AI). It is the Python successor of the
    Torch library, originally written in the Lua programming language. With PyTorch,
    you can build all sorts of neural network models and train them at scale using
    GPUs (or other hardware accelerators, as we will see). In many ways it is similar
    to NumPy, except it also supports hardware acceleration and autodiff (see [Chapter 9](ch09.html#ann_chapter)),
    and includes optimizers and ready-to-use neural net components.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 是由 Facebook 的 AI 研究实验室（FAIR，现称为 Meta AI）开发的一个强大的开源深度学习库。它是用 Lua 编程语言编写的
    Torch 库的 Python 后继者。使用 PyTorch，您可以构建各种神经网络模型，并使用 GPU（或我们将会看到的其他硬件加速器）进行大规模训练。在许多方面，它与
    NumPy 类似，但它还支持硬件加速和自动微分（见[第 9 章](ch09.html#ann_chapter)），并包括优化器和现成的神经网络组件。
- en: 'When PyTorch was released in 2016, Google’s TensorFlow library was by far the
    most popular: it was fast, it scaled well, and it could be deployed across many
    platforms. But its programming model was complex and static, making it difficult
    to use and debug. In contrast, PyTorch was designed from the ground up to provide
    a more flexible, Pythonic approach to building neural networks. In particular,
    as you will see, it uses dynamic computation graphs (also known as define-by-run),
    making it intuitive and easy to debug. PyTorch is also beautifully coded and documented,
    and focuses on its core task: making it easy to build and train high-performance
    neural networks. Last but not least, it leans strongly into the open source culture
    and benefits from an enthusiastic and dedicated community, and a rich ecosystem.
    In September 2022, PyTorch’s governance was even transferred to the PyTorch Foundation,
    a subsidiary of the Linux Foundation. All these qualities resonated well with
    researchers: PyTorch quickly became the most used framework in academia, and once
    a majority of deep learning papers were based on PyTorch, a large part of the
    industry was gradually converted as well.⁠^([1](ch10.html#id2228))'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当 PyTorch 在 2016 年发布时，谷歌的 TensorFlow 库无疑是最受欢迎的：它运行速度快，扩展性好，并且可以在许多平台上部署。但它的编程模型复杂且静态，使得使用和调试变得困难。相比之下，PyTorch
    是从头开始设计的，旨在提供一种更灵活、更 Pythonic 的方法来构建神经网络。特别是，正如您将看到的，它使用动态计算图（也称为运行时定义），这使得它直观且易于调试。PyTorch
    的代码和文档也非常精美，专注于其核心任务：使构建和训练高性能神经网络变得容易。最后但同样重要的是，它强烈倾向于开源文化，并受益于一个热情且专注的社区，以及丰富的生态系统。2022
    年 9 月，PyTorch 的治理权甚至转移到了 Linux 基金会的子公司 PyTorch 基金会。所有这些品质都与研究人员产生了共鸣：PyTorch 迅速成为学术界最常用的框架，一旦大多数深度学习论文都基于
    PyTorch，行业的大部分也逐渐转向了它。⁠^([1](ch10.html#id2228))
- en: In this chapter, you will learn how to train, evaluate, fine-tune, optimize,
    and save neural nets with PyTorch. We will start by getting familiar with the
    core building blocks of PyTorch, namely tensors and autograd, next we will test
    the waters by building and training a simple linear regression model, and then
    we will upgrade this model to a multilayer neural network, first for regression,
    then for classification. Along the way, we will see how to build custom neural
    networks with multiple inputs or outputs. Finally, we will discuss how to automatically
    fine-tune hyperparameters using the Optuna library, and how to optimize and export
    your models. Hop on board, we’re diving into deep learning!
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将学习如何使用 PyTorch 训练、评估、微调、优化和保存神经网络。我们将首先熟悉 PyTorch 的核心构建块，即张量和 autograd，然后我们将通过构建和训练一个简单的线性回归模型来试水，接着我们将把这个模型升级为一个多层神经网络，首先是用于回归，然后是用于分类。在这个过程中，我们将看到如何构建具有多个输入或输出的自定义神经网络。最后，我们将讨论如何使用
    Optuna 库自动微调超参数，以及如何优化和导出您的模型。快上船吧，我们将深入探索深度学习！
- en: Note
  id: totrans-4
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'Colab runtimes come with a recent version of PyTorch preinstalled. However,
    if you prefer to install it on your own machine, please see the installation instructions
    at [*https://homl.info/install-p*](https://homl.info/install-p): this involves
    installing Python, many libraries, and a GPU driver (if you have one).'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: Colab 运行时预装了最新版本的 PyTorch。然而，如果您更愿意在自己的机器上安装它，请参阅[*https://homl.info/install-p*](https://homl.info/install-p)上的安装说明：这包括安装
    Python、许多库以及 GPU 驱动器（如果您有的话）。
- en: PyTorch Fundamentals
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: PyTorch 基础
- en: 'The core data structure of PyTorch is the *tensor*.⁠^([2](ch10.html#id2229))
    It’s a multidimensional array with a shape and a data type, used for numerical
    computations. Isn’t that exactly like a NumPy array? Well, yes, it is! But a tensor
    also has two extra features: it can live on a GPU (or other hardware accelerators,
    as we will see), and it supports auto-differentiation. Every neural network we
    will build from now on will input and output tensors (much like Scikit-Learn models
    input and output NumPy arrays). So let’s start by looking at how to create and
    manipulate tensors.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 的核心数据结构是 *张量*。⁠^([2](ch10.html#id2229)) 它是一个具有形状和数据类型的多维数组，用于数值计算。这不就是和
    NumPy 数组一模一样吗？嗯，是的！但张量还有两个额外特性：它可以存在于 GPU（或我们将会看到的其他硬件加速器）上，并且支持自动微分。从现在开始，我们将构建的每一个神经网络都将输入和输出张量（就像
    Scikit-Learn 模型输入和输出 NumPy 数组一样）。所以，让我们先看看如何创建和操作张量。
- en: PyTorch Tensors
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PyTorch 张量
- en: 'First, let’s import the PyTorch library:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们导入 PyTorch 库：
- en: '[PRE0]'
  id: totrans-10
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next you can create a PyTorch tensor much like you would create a NumPy array.
    For example, let’s create a 2 × 3 array:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您可以创建一个 PyTorch 张量，就像创建 NumPy 数组一样。例如，让我们创建一个 2 × 3 的数组：
- en: '[PRE1]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Just like a NumPy array, a tensor can contain floats, integers, booleans, or
    complex numbers—just one data type per tensor. If you initialize a tensor with
    values of different types, then the most general one will be selected (i.e., complex
    > float > integer > bool). You can also select the data type explicitly when creating
    the tensor, for example `dtype=torch.float16` for 16-bit floats. Note that tensors
    of strings or objects are not supported.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 就像 NumPy 数组一样，张量可以包含浮点数、整数、布尔值或复数——每个张量只包含一种数据类型。如果您使用不同类型的数据初始化张量，则将选择最通用的一种（即复数
    > 浮点数 > 整数 > 布尔值）。您也可以在创建张量时显式选择数据类型，例如使用 `dtype=torch.float16` 创建 16 位浮点数。请注意，不支持字符串或对象张量。
- en: 'You can get a tensor’s shape and data type like this:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以像这样获取张量的形状和数据类型：
- en: '[PRE2]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Indexing works just like for NumPy arrays:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 索引的工作方式与 NumPy 数组相同：
- en: '[PRE3]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You can also run all sorts of computations on tensors, and the API is conveniently
    similar to NumPy’s: for example, there’s `torch.abs()`, `torch.cos()`, `torch.exp()`,
    `torch.max()`, `torch.mean()`, `torch.sqrt()`, and so on. PyTorch tensors also
    have methods for most of these operations, so you can write `X.exp()` instead
    of `torch.exp(X)`. Let’s try a few operations:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以在张量上运行各种计算，API 与 NumPy 的非常相似：例如，有 `torch.abs()`、`torch.cos()`、`torch.exp()`、`torch.max()`、`torch.mean()`、`torch.sqrt()`
    等等。PyTorch 张量也有这些操作的大部分方法，因此您可以编写 `X.exp()` 而不是 `torch.exp(X)`。让我们尝试几个操作：
- en: '[PRE4]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: PyTorch prefers the argument name `dim` in operations such as `max()`, but it
    also supports `axis` (as in NumPy or Pandas).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 在 `max()` 等操作中更喜欢使用 `dim` 参数名，但它也支持 `axis`（如 NumPy 或 Pandas）。
- en: 'You can also convert a tensor to a NumPy array using the `numpy()` method,
    and create a tensor from a NumPy array:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用 `numpy()` 方法将张量转换为 NumPy 数组，并从 NumPy 数组创建张量：
- en: '[PRE5]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Notice that the default precision for floats is 32 bits in PyTorch, whereas
    it’s 64 bits in NumPy. It’s generally better to use 32 bits in deep learning because
    this takes half the RAM and speeds up computations, and neural nets do not actually
    need the extra precision offered by 64-bit floats. So when calling the `torch.tensor()`
    function to convert a NumPy array to a tensor, it’s best to specify `dtype=torch.float32`.
    Alternatively, you can use `torch.FloatTensor()` which automatically converts
    the array to 32 bits:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在 PyTorch 中浮点数的默认精度是 32 位，而 NumPy 中是 64 位。在深度学习中通常使用 32 位更好，因为这只需要一半的 RAM
    并加快计算速度，而神经网络实际上并不需要 64 位浮点数提供的额外精度。因此，在调用 `torch.tensor()` 函数将 NumPy 数组转换为张量时，最好指定
    `dtype=torch.float32`。或者，您可以使用 `torch.FloatTensor()`，它将数组自动转换为 32 位：
- en: '[PRE6]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Tip
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: 'Both `torch.tensor()` and `torch.FloatTensor()` make a copy of the given NumPy
    array. If you prefer, you can use `torch.​from_numpy()` which creates a tensor
    on the CPU that just uses the NumPy array’s data directly, without copying it.
    But beware: modifying the NumPy array will also modify the tensor, and vice versa.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '`torch.tensor()` 和 `torch.FloatTensor()` 都会复制给定的 NumPy 数组。如果您愿意，可以使用 `torch.from_numpy()`
    创建一个张量，该张量在 CPU 上直接使用 NumPy 数组的数据，而不进行复制。但请注意：修改 NumPy 数组也会修改张量，反之亦然。'
- en: 'You can also modify a tensor in place using indexing and slicing, as with a
    NumPy array:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以使用索引和切片修改张量，就像 NumPy 数组一样：
- en: '[PRE7]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'PyTorch’s API provides many in-place operations, such as `abs_()`, `sqrt_()`,
    and `zero_()`, which modify the input tensor directly: they can sometimes save
    some memory and speed up your models. For example, the `relu_()` method applies
    the ReLU activation function in place by replacing all negative values with 0s:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch的API提供了许多原地操作，如`abs_()`、`sqrt_()`和`zero_()`，它们直接修改输入张量：它们有时可以节省一些内存并加快你的模型速度。例如，`relu_()`方法通过将所有负值替换为0s来原地应用ReLU激活函数：
- en: '[PRE8]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Tip
  id: totrans-32
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: PyTorch’s in-place operations are easy to spot at a glance because their name
    always ends with an underscore. With very few exceptions (e.g., `zero_()`), removing
    the underscore gives you the regular operation (e.g., `abs_()` is in place, `abs()`
    is not).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch的原地操作很容易一眼看出，因为它们的名字总是以下划线结尾。除了极少数例外（例如，`zero_()`），去掉下划线会得到常规操作（例如，`abs_()`是原地操作，`abs()`不是）。
- en: We will cover many more operations as we go, but now let’s look at how to use
    hardware acceleration to make computations much faster.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们继续前进，我们将介绍更多操作，但现在让我们看看如何使用硬件加速来使计算更快。
- en: Hardware Acceleration
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 硬件加速
- en: 'PyTorch tensors can be copied easily to the GPU, assuming your machine has
    a compatible GPU, and you have the required libraries installed. On Colab, all
    you need to do is ensure that you are using a GPU runtime: for this, go to the
    Runtime menu and select “Change runtime type”, then make sure a GPU is selected
    (e.g., an Nvidia T4 GPU). The GPU runtime will automatically have the appropriate
    PyTorch library installed—compiled with GPU support—as well as the appropriate
    GPU drivers and related libraries (e.g., Nvidia’s CUDA and cuDNN libraries).⁠^([3](ch10.html#id2249))
    If you prefer to run the code on your own machine, you will need to ensure that
    you have all the drivers and libraries required. Please follow the instructions
    at [*https://homl.info/install-p*](https://homl.info/install-p).'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你的机器配备有兼容的GPU，并且已经安装了所需的库，PyTorch张量可以轻松地复制到GPU上。在Colab上，你只需确保你正在使用GPU运行时：为此，前往运行时菜单并选择“更改运行时类型”，然后确保已选择GPU（例如，Nvidia
    T4 GPU）。GPU运行时将自动安装适当的PyTorch库——带有GPU支持的编译库——以及适当的GPU驱动程序和相关库（例如，Nvidia的CUDA和cuDNN库）。⁠^([3](ch10.html#id2249))
    如果你更喜欢在自己的机器上运行代码，你需要确保你拥有所有所需的驱动程序和库。请遵循[*https://homl.info/install-p*](https://homl.info/install-p)上的说明。
- en: 'PyTorch has excellent support for Nvidia GPUs, as well as several other hardware
    accelerators:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch对Nvidia GPU以及几个其他硬件加速器提供了出色的支持：
- en: Apple’s *Metal Performance Shaders* (MPS) to accelerate computations on Apple
    silicon such as the M1, M2, and later chips, as well as some Intel Macs with a
    compatible GPU.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 苹果的*Metal Performance Shaders* (MPS)用于加速在M1、M2等苹果硅芯片以及一些配备兼容GPU的Intel Mac上的计算。
- en: AMD Instinct accelerators and AMD Radeon GPUs, through the ROCm software stack,
    or via DirectML on Windows.
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过ROCm软件堆栈或Windows上的DirectML，AMD Instinct加速器和AMD Radeon GPU。
- en: Intel GPUs and CPUs on Linux and Windows via Intel’s oneAPI.
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过Intel的oneAPI在Linux和Windows上使用Intel GPU和CPU。
- en: Google TPUs via the `torch_xla` library.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过`torch_xla`库使用Google TPUs。
- en: 'Let’s check whether PyTorch can access an Nvidia GPU or Apple’s MPS, otherwise
    let’s fall back to the CPU:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查PyTorch是否可以访问Nvidia GPU或苹果的MPS，否则就回退到CPU：
- en: '[PRE9]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Warning
  id: totrans-44
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Deep learning generally requires a *lot* of compute power, especially once we
    start diving into computer vision and natural language processing, in the following
    chapters. You will need a reasonably powerful machine, but most importantly you
    will need a hardware accelerator (or several). If you don’t have one, you can
    try using Colab or Kaggle; they offer runtimes with free GPUs. Or consider using
    other cloud services. Otherwise, prepare to be very, very patient.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习通常需要大量的计算能力，尤其是在我们开始深入研究计算机视觉和自然语言处理时，在接下来的章节中。你需要一台相当强大的机器，但最重要的是你需要一个硬件加速器（或多个）。如果你没有，你可以尝试使用Colab或Kaggle；它们提供带有免费GPU的运行时。或者考虑使用其他云服务。否则，请做好耐心等待的准备。
- en: 'On a Colab GPU runtime, `device` will be equal to `"cuda"`. Now let’s create
    a tensor on that GPU. To do that, one option is to create the tensor on the CPU,
    then copy it to the GPU using the `to()` method:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在Colab的GPU运行时，`device`将等于`"cuda"`。现在让我们在那个GPU上创建一个张量。为此，一个选项是在CPU上创建张量，然后使用`to()`方法将其复制到GPU上：
- en: '[PRE10]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Tip
  id: totrans-48
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: The `cpu()` and `cuda()` methods are short for `to("cpu")` and `to("cuda")`,
    respectively.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '`cpu()`和`cuda()`方法分别是`to("cpu")`和`to("cuda")`的简称。'
- en: 'You can always tell which device a tensor lives on by looking at its `device`
    attribute:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过查看张量的`device`属性来始终知道它位于哪个设备上：
- en: '[PRE11]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Alternatively, we can create the tensor directly on the GPU using the `device`
    argument:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，我们可以使用`device`参数直接在GPU上创建张量：
- en: '[PRE12]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Tip
  id: totrans-54
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: 'If you have multiple Nvidia GPUs, you can refer to the desired GPU by appending
    the GPU index: `"cuda:0"` (or just `"cuda"`) for GPU #0, `"cuda:1"` for GPU #1,
    and so on.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '如果你有多块Nvidia GPU，你可以通过附加GPU索引来引用所需的GPU：`"cuda:0"`（或仅`"cuda"`）表示GPU #0，`"cuda:1"`表示GPU
    #1，以此类推。'
- en: 'Once the tensor is on the GPU, we can run operations on it normally, and they
    will all take place on the GPU:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦张量在GPU上，我们就可以在它上面运行操作，并且所有操作都会在GPU上执行：
- en: '[PRE13]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note that the result `R` also lives on the GPU. This means we can perform multiple
    operations on the GPU without having to transfer data back and forth between the
    CPU and the GPU. This is crucial in deep learning because data transfer between
    devices can often become a performance bottleneck.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，结果`R`也位于GPU上。这意味着我们可以在GPU上执行多个操作，而无需在CPU和GPU之间来回传输数据。这在深度学习中至关重要，因为设备之间的数据传输往往可能成为性能瓶颈。
- en: 'How much does a GPU accelerate the computations? Well it depends on the GPU,
    of course: the more expensive ones are dozens of times faster than the cheap ones.
    But speed alone is not the only important factor: the data throughput is also
    crucial, as we just saw. If your model is compute heavy (e.g., a very deep neural
    net), the GPU’s speed and amount of RAM will typically matter most, but if it
    is a shallower model, then pumping the training data into the GPU might become
    the bottleneck. Let’s run a little test to compare the speed of a matrix multiplication
    running on the CPU versus the GPU:⁠^([4](ch10.html#id2258))'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: GPU能加速计算到什么程度？当然，这取决于GPU：昂贵的GPU比便宜的GPU快几十倍。但速度并不是唯一重要的因素：数据吞吐量也同样关键，正如我们刚才看到的。如果你的模型计算密集（例如，一个非常深的神经网络），GPU的速度和RAM量通常最为重要，但如果模型较浅，那么将训练数据泵入GPU可能会成为瓶颈。让我们运行一个小测试来比较在CPU和GPU上运行的矩阵乘法的速度：⁠^([4](ch10.html#id2258))
- en: '[PRE14]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Wow! The GPU gave us a 29× speed boost! And that’s just using the free Nvidia
    T4 GPU on Colab; imagine the speedup we could get using a more powerful GPU. Now
    try playing around with the matrix size: you will notice that the speedup is much
    less impressive on smaller matrices (e.g., it’s just 2× for 100 × 100 matrices).
    That’s because GPUs work by breaking large operations into smaller operations
    and running them in parallel across thousands of cores. If the task is small,
    it cannot be broken up into that many pieces, and the performance gain is therefore
    smaller. In fact, when running many tiny tasks, it can sometimes be faster to
    just run the operations on the CPU.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！GPU给了我们29倍的加速！而且这只是在Colab上使用免费的Nvidia T4 GPU；想象一下使用更强大的GPU我们能得到多大的加速。现在尝试调整矩阵大小：你将注意到在较小的矩阵上（例如，100
    × 100矩阵仅为2×）加速效果并不那么令人印象深刻。这是因为GPU通过将大操作分解成小操作并在数千个核心上并行运行来工作。如果任务很小，就不能分解成那么多部分，因此性能提升较小。实际上，当运行许多小任务时，有时直接在CPU上运行操作可能会更快。
- en: All right, now that we’ve seen what tensors are and how to use them on the CPU
    or the GPU, let’s look at PyTorch’s auto-differentiation feature.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在我们已经看到了张量是什么以及如何在CPU或GPU上使用它们，让我们看看PyTorch的自动微分功能。
- en: Autograd
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Autograd
- en: 'PyTorch comes with an efficient implementation of reverse-mode auto-differentiation
    (introduced in [Chapter 9](ch09.html#ann_chapter) and detailed in [Appendix A](app01.html#autodiff_appendix)),
    called *autograd*, which stands for automatic gradients. It is quite easy to use.
    For example, consider a simple function, f(*x*) = *x*². Differential calculus
    tells us that the derivative of this function is *f’*(*x*) = 2*x*. If we evaluate
    f(5) and f''(5), we get 25 and 10, respectively. Let’s see if PyTorch agrees:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch提供了一个高效的反向模式自动微分实现（在第9章中介绍，在第A附录中详细说明），称为*autograd*，代表自动梯度。它非常容易使用。例如，考虑一个简单的函数，f(*x*)
    = *x*²。微分学告诉我们这个函数的导数是*f’*(*x*) = 2*x*。如果我们评估f(5)和f'(5)，我们分别得到25和10。让我们看看PyTorch是否同意：
- en: '[PRE15]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Great, we got the correct results: `f` is 25, and `x.grad` is 10! Note that
    the `backward()` function automatically computed the gradient f''(*x*) at the
    same point *x* = 5.0\. Let’s go through this code line by line:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 太好了，我们得到了正确的结果：`f`是25，而`x.grad`是10！请注意，`backward()`函数自动计算了在相同点*x* = 5.0处的梯度f'(*x*)。让我们逐行分析这段代码：
- en: 'First, we created a tensor `x`, equal to 5.0, and we told PyTorch that it’s
    a variable (not a constant) by specifying `requires_grad=True`. Knowing this,
    PyTorch will automatically keep track of all operations involving `x`: this is
    needed because PyTorch must capture the computation graph in order to run backprop
    on it and obtain the derivative of `f` with regard to `x`. In this computation
    graph, the tensor `x` is a *leaf node*.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们创建了一个等于 5.0 的张量 `x`，并通过指定 `requires_grad=True` 告诉 PyTorch 它是一个变量（而不是一个常数）。了解这一点后，PyTorch
    将自动跟踪所有涉及 `x` 的操作：这是必需的，因为 PyTorch 必须捕获计算图，以便对其运行反向传播并获取 `f` 关于 `x` 的导数。在这个计算图中，张量
    `x` 是一个 *叶节点*。
- en: 'Then we compute `f = x ** 2`. The result is a tensor equal to 25.0, the square
    of 5.0\. But wait, there’s more to it: `f` also carries a `grad_fn` attribute
    which represents the operation that created this tensor (`**`, power, hence the
    name `PowBackward0`), and which tells PyTorch how to backpropagate the gradients
    through this particular operation. This `grad_fn` attribute is how PyTorch keeps
    track of the computation graph.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后我们计算 `f = x ** 2`。结果是等于 25.0 的张量，这是 5.0 的平方。但是等等，还有更多：`f` 还携带一个 `grad_fn`
    属性，它表示创建此张量的操作（`**`，幂运算，因此命名为 `PowBackward0`），并告诉 PyTorch 如何通过此特定操作反向传播梯度。这个 `grad_fn`
    属性是 PyTorch 跟踪计算图的方式。
- en: 'Next, we call `f.backward()`: this backpropagates the gradients through the
    computation graph, starting with `f`, and all the way back to the leaf nodes (just
    `x` in this case).'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们调用 `f.backward()`：这会将梯度通过计算图反向传播，从 `f` 开始，一直回溯到叶节点（在这个例子中就是 `x`）。
- en: 'Lastly, we can just read the `x` tensor’s `grad` attribute, which was computed
    during backprop: this gives us the derivative of `f` with regard to `x`. Ta-da!'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们只需读取 `x` 张量的 `grad` 属性，该属性是在反向传播过程中计算的：这给出了 `f` 关于 `x` 的导数。哇塞！
- en: PyTorch creates a new computation graph on the fly during each forward pass,
    as the operations are executed. This allows PyTorch to support very dynamic models
    containing loops and conditionals.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 在每次前向传播过程中都会动态创建一个新的计算图，因为操作正在执行。这使得 PyTorch 能够支持包含循环和条件语句的非常动态的模型。
- en: Warning
  id: totrans-72
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: The way PyTorch accumulates gradients in each variable’s `grad` attribute can
    be surprising at first, especially coming from TensorFlow or JAX. In these frameworks,
    computing the gradients of `f` with regard to `x` just returns the gradients,
    without affecting `x`. In PyTorch, if you call `backward()` on a tensor, it will
    accumulate the gradients in every variable that was used to compute it. So if
    you call `backward()` on two tensors `t1` and `t2` that both used the same variable
    `v`, then `v.grad` will be the sum of their gradients.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 在每个变量的 `grad` 属性中累积梯度的方式一开始可能会让人感到惊讶，尤其是对于来自 TensorFlow 或 JAX 的用户。在这些框架中，计算
    `f` 关于 `x` 的梯度只会返回梯度，而不会影响 `x`。在 PyTorch 中，如果你对一个张量调用 `backward()`，它将累积用于计算它的每个变量的梯度。所以如果你对两个都使用了相同变量
    `v` 的张量 `t1` 和 `t2` 调用 `backward()`，那么 `v.grad` 将是它们梯度的总和。
- en: 'After computing the gradients, you generally want to perform a gradient descent
    step by subtracting a fraction of the gradients from the model variables (at least
    when training a neural network). In our simple example, running gradient descent
    will gradually push `x` toward 0, since that’s the value that minimizes f(*x*)
    = *x*². To do a gradient descent step, you must temporarily disable gradient tracking
    since you don’t want to track the gradient descent step itself in the computation
    graph (in fact, PyTorch would raise an exception if you tried to run an in-place
    operation on a tracked variable). This can be done by placing the gradient descent
    step inside a `torch.no_grad()` context, like this:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 计算梯度后，你通常想要通过从模型变量中减去梯度的一部分来执行梯度下降步骤（至少在训练神经网络时是这样）。在我们的简单例子中，运行梯度下降将逐渐将 `x`
    推向 0，因为这是使 f(*x*) = *x*² 最小的值。要进行梯度下降步骤，你必须暂时禁用梯度跟踪，因为你不希望在计算图中跟踪梯度下降步骤本身（实际上，如果你尝试在跟踪变量上运行原地操作，PyTorch
    会引发异常）。这可以通过将梯度下降步骤放在 `torch.no_grad()` 上下文中来完成，如下所示：
- en: '[PRE16]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The variable `x` gets decremented by 0.1 * 10.0 = 1.0, down from 5.0 to 4.0.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 变量 `x` 减少了 0.1 * 10.0 = 1.0，从 5.0 减少到 4.0。
- en: 'Another way to avoid gradient computation is to use the variable’s `detach()`
    method: this creates a new tensor detached from the computation graph, with `requires_grad=False`,
    but still pointing to the same data in memory. You can then update this detached
    tensor:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 避免梯度计算的另一种方法是使用变量的 `detach()` 方法：这创建了一个新的与计算图分离的张量，`requires_grad=False`，但仍然指向内存中的相同数据。然后你可以更新这个分离的张量：
- en: '[PRE17]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Since `x_detached` and `x` share the same memory, modifying `x_detached` also
    modifies `x`.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `x_detached` 和 `x` 共享相同的内存，修改 `x_detached` 也会修改 `x`。
- en: The `detach()` method can be handy when you need to run some computation on
    a tensor without affecting the gradients (e.g., for evaluation or logging), or
    when you need fine-grained control over which operations should contribute to
    gradient computation. Using `no_grad()` is generally preferred when performing
    inference or doing a gradient descent step, as it provides a convenient context-wide
    method to disable gradient tracking.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 当你需要在一个张量上运行一些计算而不影响梯度（例如，用于评估或记录）或当你需要精细控制哪些操作应该对梯度计算做出贡献时，`detach()` 方法会很有用。在执行推理或进行梯度下降步骤时，通常更喜欢使用
    `no_grad()`，因为它提供了一个方便的上下文方法来禁用梯度跟踪。
- en: 'Lastly, before you repeat the whole process (forward pass + backward pass +
    gradient descent step), it’s essential to zero out the gradients of every model
    parameter (you don’t need a `no_grad()` context for this since the gradient tensor
    has `requires_grad=False`):'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在你重复整个过程（前向传播 + 反向传播 + 梯度下降步骤）之前，将每个模型参数的梯度置零是至关重要的（由于梯度张量 `requires_grad=False`，你不需要
    `no_grad()` 上下文）：
- en: '[PRE18]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Warning
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: If you forget to zero out the gradients at each training iteration, the `backward()`
    method will just accumulate them, causing incorrect gradient descent updates.
    Since there won’t be any explicit error, just low performance (and perhaps infinite
    or NaN values), this issue may be hard to debug.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你忘记在每个训练迭代中将梯度置零，`backward()` 方法将只是累积它们，导致梯度下降更新不正确。由于不会出现任何明确的错误，只是性能低下（可能还有无限或
    NaN 值），这个问题可能很难调试。
- en: 'Putting everything together, the whole training loop looks like this:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有这些放在一起，整个训练循环看起来像这样：
- en: '[PRE19]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'If you want to use in-place operations to save memory and speed up your models
    a bit by avoiding unnecessary copy operations, you have to be careful: in-place
    operations don’t always play nicely with autograd. Firstly, as we saw earlier,
    you cannot apply an in-place operation to a leaf node (i.e., a tensor with `requires_grad=True`),
    as PyTorch wouldn’t know where to store the computation graph. For example `x.cos_()`
    or `x += 1` would cause a `RuntimeError`. Secondly, consider the following code,
    which computes z(*t*) = exp(*t*) + 1 at *t* = 2 and then tries to compute the
    gradients:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想要使用原地操作来节省内存并稍微加快你的模型速度，避免不必要的复制操作，你必须小心：原地操作并不总是与自动微分很好地配合。首先，正如我们之前看到的，你不能对一个叶节点（即具有
    `requires_grad=True` 的张量）应用原地操作，因为 PyTorch 不会知道在哪里存储计算图。例如 `x.cos_()` 或 `x +=
    1` 会引发 `RuntimeError`。其次，考虑以下代码，它在 `t = 2` 时计算 z(*t*) = exp(*t*) + 1，然后尝试计算梯度：
- en: '[PRE20]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Oh no! Although `z` is computed correctly, the last line causes a `RuntimeError`,
    complaining that “one of the variables needed for gradient computation has been
    modified by an in-place operation”. Indeed, the intermediate result `z = t.exp()`
    was lost when we ran the in-place operation `z += 1`, so when the backward pass
    reached the exponential operation, the gradients could not be computed. A simple
    fix is to replace `z += 1` with `z = z + 1`. It looks similar, but it’s no longer
    an in-place operation: a new tensor is created and assigned to the same variable,
    but the original tensor is unchanged and recorded in the computation graph of
    the final tensor.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 哦不！虽然 `z` 被正确计算，但最后一行引发了 `RuntimeError`，抱怨“用于梯度计算的一个变量已被原地操作修改”。确实，当我们运行原地操作
    `z += 1` 时，中间结果 `z = t.exp()` 被丢失，所以当反向传播到达指数操作时，无法计算梯度。一个简单的修复是将 `z += 1` 替换为
    `z = z + 1`。它看起来很相似，但它不再是原地操作：创建了一个新的张量并将其分配给相同的变量，但原始张量保持不变，并记录在最终张量的计算图中。
- en: 'Surprisingly, if you replace `exp()` with `cos()` in the previous code example,
    the gradients will be computed correctly: no error! Why is that? Well, the outcome
    depends on the way each operation is implemented:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 令人惊讶的是，如果你在之前的代码示例中将 `exp()` 替换为 `cos()`，梯度将会被正确计算：没有错误！这是为什么？嗯，结果取决于每个操作是如何实现的：
- en: Some operations—such as `exp()`, `relu()`, `rsqrt()`, `sigmoid()`, `sqrt()`,
    `tan()`, and `tanh()`—save their outputs in the computation graph during the forward
    pass, then use these outputs to compute the gradients during the backward pass.⁠^([5](ch10.html#id2274))
    This means that you must not modify such an operation’s output in place, or you
    will get an error during the backward pass (as we just saw).
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些操作，例如`exp()`、`relu()`、`rsqrt()`、`sigmoid()`、`sqrt()`、`tan()`和`tanh()`，在正向传播期间将它们的输出保存到计算图中，然后在反向传播期间使用这些输出来计算梯度。⁠^([5](ch10.html#id2274))
    这意味着您不能原地修改此类操作的输出，否则在反向传播期间将得到错误（正如我们刚才看到的）。
- en: Other operations—such as `abs()`, `cos()`, `log()`, `sin()`, `square()`, and
    `var()`—save their inputs instead of their output.⁠^([6](ch10.html#id2275)) Such
    an operation doesn’t care if you modify its output in place, but you must not
    modify its inputs in place before the backward pass (e.g., to compute something
    else based on the same inputs).
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其他操作，例如`abs()`、`cos()`、`log()`、`sin()`、`square()`和`var()`，保存它们的输入而不是输出。⁠^([6](ch10.html#id2275))
    这样的操作不关心您是否原地修改了它的输出，但您必须在反向传播之前不要原地修改它的输入（例如，基于相同的输入计算其他内容）。
- en: Some operations—such as `max()`, `min()`, `norm()`, `prod()`, `sgn()`, and `std()`—save
    both the inputs and the outputs, so you must not modify either of them in place
    before the backward pass.
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些操作，例如`max()`、`min()`、`norm()`、`prod()`、`sgn()`和`std()`，保存输入和输出，因此在反向传播之前您不能原地修改它们中的任何一个。
- en: Lastly, a few operations—such as `ceil()`, `floor()`, `mean()`, `round()`, and
    `sum()`—save neither their inputs nor their outputs.⁠^([7](ch10.html#id2276))
    You can safely modify them in place.
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，一些操作，例如`ceil()`、`floor()`、`mean()`、`round()`和`sum()`，既不保存它们的输入也不保存它们的输出。⁠^([7](ch10.html#id2276))
    您可以安全地原地修改它们。
- en: Tip
  id: totrans-95
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Implement your models first without any in-place operations, then if you need
    to save some memory or speed up your model a bit, you can try converting some
    of the most costly operations to their in-place counterparts. Just make sure that
    your model still outputs the same result for a given input, and also make sure
    you don’t modify in place a tensor needed for backprop (you will get a `RuntimeError`
    in this case).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 首先在不进行原地操作的情况下实现您的模型，然后如果您需要节省一些内存或稍微加快模型的速度，您可以尝试将一些最昂贵的操作转换为它们的原地对应操作。只需确保您的模型对于给定的输入仍然输出相同的结果，并且确保您在反向传播之前不要修改用于反向传播的张量（在这种情况下，您将得到一个`RuntimeError`）。
- en: 'OK, let’s step back a bit. We’ve discussed all the fundamentals of PyTorch:
    how to create tensors and use them to perform all sorts of computations, how to
    accelerate the computations with a GPU, and how to use autograd to compute gradients
    for gradient descent. Great! Now let’s apply what we’ve learned so far by building
    and training a simple linear regression model with PyTorch.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，让我们稍微回顾一下。我们已经讨论了PyTorch的所有基础知识：如何创建张量并使用它们执行各种计算，如何使用GPU加速计算，以及如何使用自动微分来计算梯度下降的梯度。太棒了！现在让我们通过使用PyTorch构建和训练一个简单的线性回归模型来应用我们迄今为止所学的内容。
- en: Implementing Linear Regression
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现线性回归
- en: We will start by implementing linear regression using tensors and autograd directly,
    then we will simplify the code using PyTorch’s high-level API, and also add GPU
    support.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先直接使用张量和自动微分实现线性回归，然后我们将使用PyTorch的高级API简化代码，并添加GPU支持。
- en: Linear Regression Using Tensors and Autograd
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用张量和自动微分进行线性回归
- en: 'Let’s tackle the same California housing dataset as in [Chapter 9](ch09.html#ann_chapter).
    I will assume you have already downloaded it using `sklearn.datasets.fetch_california_housing()`,
    and you have split it into a training set (`X_train` and `y_train`), a validation
    set (`X_valid` and `y_valid`), and a test set (`X_test` and `y_test`), using `sklearn.model_selection.train_test_split()`.
    Next, let’s convert it to tensors and normalize it. We could use a `StandardScaler`
    for this, like we did in [Chapter 9](ch09.html#ann_chapter), but let’s just use
    tensor operations instead, to get a bit of practice:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们处理与[第9章](ch09.html#ann_chapter)中相同的加利福尼亚住房数据集。我将假设您已经使用`sklearn.datasets.fetch_california_housing()`下载了它，并且您已经使用`sklearn.model_selection.train_test_split()`将其分为训练集（`X_train`和`y_train`）、验证集（`X_valid`和`y_valid`）和测试集（`X_test`和`y_test`）。接下来，让我们将其转换为张量并进行归一化。我们可以使用`StandardScaler`来完成这项工作，就像我们在[第9章](ch09.html#ann_chapter)中所做的那样，但让我们只使用张量操作来练习一下：
- en: '[PRE21]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Let’s also convert the targets to tensors. Since our predictions will be column
    vectors (i.e., matrices with a single column), we need to ensure that our targets
    are also column vectors.⁠^([8](ch10.html#id2281)) Unfortunately, the NumPy arrays
    representing the targets are one-dimensional, so we need to reshape the tensors
    to column vectors by adding a second dimension of size 1:⁠^([9](ch10.html#id2282))
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们也把目标转换为张量。由于我们的预测将是列向量（即只有一列的矩阵），我们需要确保我们的目标也是列向量。⁠^([8](ch10.html#id2281))
    不幸的是，表示目标的NumPy数组是一维的，因此我们需要通过添加一个大小为1的第二个维度来重塑张量成为列向量。⁠^([9](ch10.html#id2282))
- en: '[PRE22]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now that the data is ready, let’s create the parameters of our linear regression
    model:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据已经准备好了，让我们创建线性回归模型的参数：
- en: '[PRE23]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: We now have a weights parameter `w` (a column vector with one weight per input
    dimension, in this case 8), and a bias parameter `b` (a single scalar). The weights
    are initialized randomly, while the bias is initialized to zero. We could have
    initialized the weights to zero as well in this case, but when we get to neural
    networks it will be important to initialize the weights randomly to break the
    symmetry between neurons (as explained in [Chapter 9](ch09.html#ann_chapter)),
    so we might as well get into the habit now.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个权重参数`w`（一个列向量，每个输入维度有一个权重，在这种情况下是8），以及一个偏置参数`b`（一个单一的标量）。权重随机初始化，而偏置初始化为零。在这种情况下，我们也可以将权重初始化为零，但当我们到达神经网络时，将权重随机初始化以打破神经元之间的对称性（如[第9章](ch09.html#ann_chapter)中解释的那样）将变得很重要，所以我们现在就养成这个习惯。
- en: Warning
  id: totrans-108
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: We called `torch.manual_seed()` to ensure that the results are reproducible.
    However, PyTorch does not guarantee perfectly reproducible results across different
    releases, platforms, or devices, so if you do not run the code in this chapter
    with PyTorch 2.8.0 on a Colab runtime with an Nvidia T4 GPU, you may get different
    results. Moreover, since a GPU splits each operation into multiple chunks and
    runs them in parallel, the order in which these chunks finish may vary across
    runs, and this may slightly affect the result due to floating-point precision
    errors. These minor differences may compound during training, and lead to very
    different models. To avoid this, you can tell PyTorch to use only deterministic
    algorithms by calling `torch.use_deterministic_algorithms(True)` and setting `torch.backends.cudnn.benchmark
    = False`. However, deterministic algorithms are often slower than stochastic ones,
    and some operations don’t have a deterministic version at all, so you will get
    an error if your code tries to use one.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们调用了`torch.manual_seed()`来确保结果可重现。然而，PyTorch不能保证在不同版本、平台或设备上具有完全可重现的结果，所以如果你不在使用PyTorch
    2.8.0的Colab运行时和带有Nvidia T4 GPU的情况下运行本章的代码，你可能会得到不同的结果。此外，由于GPU将每个操作分成多个块并并行运行，这些块完成顺序可能会因运行而异，这可能会由于浮点精度误差而略微影响结果。这些细微的差异在训练过程中可能会累积，导致模型非常不同。为了避免这种情况，你可以通过调用`torch.use_deterministic_algorithms(True)`并设置`torch.backends.cudnn.benchmark
    = False`来告诉PyTorch只使用确定性算法。然而，确定性算法通常比随机算法慢，而且某些操作根本就没有确定性版本，所以如果你的代码尝试使用它，你会得到一个错误。
- en: 'Next, let’s train our model, very much like we did in [Chapter 4](ch04.html#linear_models_chapter),
    except we will use autodiff to compute the gradients rather than using a closed-form
    equation. For now we will use batch gradient descent (BGD), using the full training
    set at each training step:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们训练我们的模型，这与我们在[第4章](ch04.html#linear_models_chapter)中做的方法非常相似，只是我们将使用自动微分来计算梯度，而不是使用闭式方程。目前我们将使用批量梯度下降（BGD），在每个训练步骤中使用整个训练集：
- en: '[PRE24]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Let’s walk through this code:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐步分析这段代码：
- en: First we define the `learning_rate` hyperparameter. You can experiment with
    different values to find a value that converges fast and gives a precise result.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，我们定义`learning_rate`超参数。你可以尝试不同的值，以找到一个收敛快且结果精确的值。
- en: Next, we run 20 epochs. We could implement early stopping to find the right
    moment to stop and avoid overfitting, like we did in [Chapter 4](ch04.html#linear_models_chapter),
    but we will keep things simple for now.
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们运行20个epoch。我们可以实现提前停止来找到停止的正确时机，避免过拟合，就像我们在[第4章](ch04.html#linear_models_chapter)中做的那样，但现在我们将保持简单。
- en: 'Next, we run the forward pass: we compute the predictions `y_pred`, and the
    mean squared error `loss`.'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们运行前向传播：我们计算预测值`y_pred`和均方误差`loss`。
- en: Then we run `loss.backward()` to compute the gradients of the loss with regard
    to every model parameter. This is autograd in action.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后我们运行`loss.backward()`来计算损失相对于每个模型参数的梯度。这是自动微分的作用。
- en: Next, we use the gradients `b.grad` and `w.grad` to perform a gradient descent
    step. Notice that we’re running this code inside a `with torch.no_grad()` context,
    as discussed earlier.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们使用梯度 `b.grad` 和 `w.grad` 执行梯度下降步骤。请注意，我们像之前讨论的那样，在这个 `with torch.no_grad()`
    上下文中运行这段代码。
- en: Once we’ve done the gradient descent step, we reset the gradients to zero (very
    important!).
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦我们完成了梯度下降步骤，我们将梯度重置为零（非常重要！）。
- en: Lastly, we print the epoch number and the current loss at each epoch. The `item()`
    method extracts the value of a scalar tensor.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们在每个时期打印时期编号和当前的损失。`item()` 方法提取标量张量的值。
- en: 'And that’s it; if you run this code, you should see the training loss going
    down like this:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样；如果你运行这段代码，你应该看到训练损失像这样下降：
- en: '[PRE25]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Congratulations, you just trained your first model using PyTorch! You can now
    use the model to make predictions for some new data `X_new` (which must be represented
    as a PyTorch tensor). For example, let’s make predictions for the first three
    instances in the test set:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜，你刚刚使用 PyTorch 训练了你的第一个模型！你现在可以使用这个模型对新数据 `X_new` 进行预测（这些数据必须表示为 PyTorch 张量）。例如，让我们对测试集中的前三个实例进行预测：
- en: '[PRE26]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Tip
  id: totrans-124
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: 'It’s best to use a `with torch.no_grad()` context during inference: PyTorch
    will consume less RAM and run faster since it won’t have to keep track of the
    computation graph.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在推理期间最好使用 `with torch.no_grad()` 上下文：由于 PyTorch 不需要跟踪计算图，它将消耗更少的 RAM 并运行得更快。
- en: Implementing linear regression using PyTorch’s low-level API wasn’t too hard,
    but using this approach for more complex models would get really messy and difficult.
    So PyTorch offers a higher-level API to simplify all this. Let’s rewrite our model
    using this higher-level API.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 PyTorch 的低级 API 实现线性回归并不太难，但使用这种方法为更复杂的模型会变得非常混乱且困难。因此，PyTorch 提供了一个高级 API
    来简化所有这些。让我们使用这个高级 API 重新编写我们的模型。
- en: Linear Regression Using PyTorch’s High-Level API
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 PyTorch 的高级 API 进行线性回归
- en: 'PyTorch provides an implementation of linear regression in the `torch.nn.Linear`
    class, so let’s use it:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 在 `torch.nn.Linear` 类中提供了一个线性回归的实现，所以让我们使用它：
- en: '[PRE27]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'The `nn.Linear` class (short for `torch.nn.Linear`) is one of many *modules*
    provided by PyTorch. Each module is a subclass of the `nn.Module` class. To build
    a simple linear regression model, a single `nn.Linear` module is all you need.
    However, for most neural networks you will need to assemble many modules, as we
    will see later in this chapter, so you can think of modules as math LEGO^® bricks.
    Many modules contain model parameters. For example, the `nn.Linear` module contains
    a `bias` vector (with one bias term per neuron), and a `weight` matrix (with one
    row per neuron and one column per input dimension, which is the transpose of the
    weight matrix we used earlier and in [Equation 9-2](ch09.html#neural_network_layer_equation)).
    Since our model has a single neuron (because `out_features=1`), the `bias` vector
    contains a single bias term, and the `weight` matrix contains a single row. These
    parameters are accessible directly as attributes of the `nn.Linear` module:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '`nn.Linear` 类（简称 `torch.nn.Linear`）是 PyTorch 提供的许多 *模块* 之一。每个模块都是 `nn.Module`
    类的子类。要构建一个简单的线性回归模型，只需要一个 `nn.Linear` 模块。然而，对于大多数神经网络，你将需要组装许多模块，正如我们将在本章后面看到的那样，所以你可以将模块视为数学乐高积木。许多模块包含模型参数。例如，`nn.Linear`
    模块包含一个 `bias` 向量（每个神经元一个偏置项），以及一个 `weight` 矩阵（每个神经元一行，每个输入维度一列，这是之前我们使用的权重矩阵的转置，并在
    [方程 9-2](ch09.html#neural_network_layer_equation) 中提到）。由于我们的模型只有一个神经元（因为 `out_features=1`），`bias`
    向量包含一个单独的偏置项，`weight` 矩阵包含一行。这些参数可以直接作为 `nn.Linear` 模块的属性访问：'
- en: '[PRE28]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Notice that both parameters were automatically initialized randomly (which
    is why we used `manual_seed()` to get reproducible results). These parameters
    are instances of the `torch.nn.Parameter` class, which is a subclass of the `tensor.Tensor`
    class: this means that you can use them exactly like normal tensors. A module’s
    `parameters()` method returns an iterator over all of the module’s attributes
    of type `Parameter`, as well as all the parameters of all its submodules, recursively
    (if it has any). It does *not* return regular tensors, even those with `requires_grad=True`.
    That’s the main difference between a regular tensor and a `Parameter`:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这两个参数都是自动随机初始化的（这就是为什么我们使用了`manual_seed()`来获得可重复的结果）。这些参数是`torch.nn.Parameter`类的实例，它是`tensor.Tensor`类的子类：这意味着你可以像使用普通张量一样使用它们。模块的`parameters()`方法返回一个迭代器，遍历模块的所有类型为`Parameter`的属性，以及所有子模块的所有参数（如果有的话），递归地（如果有）。它**不**返回常规张量，即使那些带有`requires_grad=True`的张量。这是常规张量和`Parameter`之间的主要区别：
- en: '[PRE29]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: There’s also a `named_parameters()` method that returns an iterator over pairs
    of parameter names and values.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有一个`named_parameters()`方法，它返回一个参数名称和值的对迭代器。
- en: 'A module can be called just like a regular function. For example, let’s make
    some predictions for the first two instances in the training set (since the model
    is not trained yet, its parameters are random and the predictions are terrible):'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 模块可以像常规函数一样被调用。例如，让我们为训练集中的前两个实例进行一些预测（因为模型尚未训练，其参数是随机的，预测非常糟糕）：
- en: '[PRE30]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: When we use a module as a function, PyTorch internally calls the module’s `forward()`
    method. In the case of the `nn.Linear` module, the `forward()` method computes
    `X @ self.weight.T + self.bias` (where `X` is the input). That’s just what we
    need for linear regression!
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将模块作为函数使用时，PyTorch内部调用模块的`forward()`方法。在`nn.Linear`模块的情况下，`forward()`方法计算`X
    @ self.weight.T + self.bias`（其中`X`是输入）。这正是线性回归所需要的！
- en: Notice that the result contains the `grad_fn` attribute, showing that autograd
    did its job and tracked the computation graph while the model was making its predictions.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，结果包含`grad_fn`属性，表明autograd完成了其工作，并在模型进行预测时跟踪了计算图。
- en: Tip
  id: totrans-139
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: If you pass a custom function to a module’s `register_forward_hook()` method,
    it will be called automatically every time the module itself is called. This is
    particularly handy for logging or debugging. To remove a hook, just call the `remove()`
    method on the object returned by `register_forward_hook()`. Note that hooks only
    work if you call the model like a function, not if you call its `forward()` method
    directly (which is why you should never do that). You can also register functions
    to run during the backward pass using `register_backward_hook()`.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将自定义函数传递给模块的`register_forward_hook()`方法，它将在每次模块本身被调用时自动被调用。这对于记录或调试特别有用。要移除钩子，只需在`register_forward_hook()`返回的对象上调用`remove()`方法。请注意，钩子仅在将模型作为函数调用时才起作用，而不是直接调用其`forward()`方法（这就是为什么你不应该这样做）。你还可以使用`register_backward_hook()`注册在反向传播期间运行的函数。
- en: 'Now that we have our model, we need to create an optimizer to update the model
    parameters, and we must also choose a loss function:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了我们的模型，我们需要创建一个优化器来更新模型参数，并且我们必须选择一个损失函数：
- en: '[PRE31]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: PyTorch provides a few different optimizers (we will discuss them in the next
    chapter). Here we’re using the simple stochastic gradient descent (SGD) optimizer,
    which can be used for SGD, mini-batch GD, or batch gradient descent. To initialize
    it, we must give it the model parameters and the learning rate.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch提供了一些不同的优化器（我们将在下一章中讨论它们）。在这里，我们使用简单的随机梯度下降（SGD）优化器，它可以用于SGD、小批量GD或批量梯度下降。为了初始化它，我们必须提供模型参数和学习率。
- en: 'For the loss function, we create an instance of the `nn.MSELoss` class: this
    is also a module, so we can use it like a function, giving it the predictions
    and the targets, and it will compute the MSE. The `nn` module contains many other
    loss functions and other neural net tools, as we will see. Next, let’s write a
    small function to train our model:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 对于损失函数，我们创建了一个`nn.MSELoss`类的实例：这也是一个模块，所以我们可以像函数一样使用它，给它提供预测和目标，然后它会计算均方误差。`nn`模块包含许多其他损失函数和其他神经网络工具，我们将在后面看到。接下来，让我们编写一个小的函数来训练我们的模型：
- en: '[PRE32]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Compare this training loop with our earlier training loop: it’s very similar,
    but we’re now using higher-level constructs rather than working directly with
    tensors and autograd. Here are a few things to note:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 将这个训练循环与我们的早期训练循环进行比较：它们非常相似，但现在我们使用的是高级构造而不是直接与张量和autograd交互。以下是一些需要注意的事项：
- en: In PyTorch, the loss function object is commonly referred to as the *criterion*,
    to distinguish it from the loss value itself (which is computed at each training
    iteration using the criterion). In this example, it’s the `MSELoss` instance.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在PyTorch中，损失函数对象通常被称为*criterion*，以区分它本身（在每次训练迭代中使用*criterion*计算）。在这个例子中，它是`MSELoss`实例。
- en: The `optimizer.step()` line corresponds to the two lines that updated `b` and
    `w` in our earlier code.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`optimizer.step()`这一行对应于我们早期代码中更新`b`和`w`的两行。'
- en: And of course the `optimizer.zero_grad()` line corresponds to the two lines
    that zeroed out `b.grad` and `w.grad`. Notice that we don’t need to use `with
    torch.no_grad()` here since this is done automatically by the optimizer, inside
    the `step()` and `zero_grad()` functions.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当然，`optimizer.zero_grad()`这一行对应于我们早期代码中使`b.grad`和`w.grad`归零的两行。请注意，我们在这里不需要使用`with
    torch.no_grad()`，因为这是由优化器自动在`step()`和`zero_grad()`函数内部完成的。
- en: Note
  id: totrans-150
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'Most people prefer to call `zero_grad()` *before* calling `loss.backward()`,
    rather than after: this might be a bit safer in case the gradients are nonzero
    when calling the function, but in general it makes no difference since gradients
    are automatically initialized to `None`.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数人更喜欢在调用`loss.backward()`之前调用`zero_grad()`，而不是之后：如果调用函数时梯度不为零，这可能会更安全一些，但总的来说，由于梯度会自动初始化为`None`，所以这并没有什么区别。
- en: Now let’s call this function to train our model!
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们调用这个函数来训练我们的模型！
- en: '[PRE33]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'All good; the model is trained, and you can now use it to make predictions
    by simply calling it like a function (preferably inside a `no_grad()` context,
    as we saw earlier):'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些都很好；模型已经训练完成，你现在可以像调用函数一样使用它来做出预测（最好在`no_grad()`上下文中调用，就像我们之前看到的）：
- en: '[PRE34]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'These predictions are similar to the ones our previous model made, but not
    exactly the same. That’s because the `nn.Linear` module initializes the parameters
    slightly differently: it uses a uniform random distribution from $minus StartFraction
    StartRoot 2 EndRoot Over 4 EndFraction$ to $plus StartFraction StartRoot 2 EndRoot
    Over 4 EndFraction$ for both the weights and the bias term (we will discuss initialization
    methods in [Chapter 11](ch11.html#deep_chapter)).'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这些预测与我们的先前模型做出的预测相似，但并不完全相同。这是因为`nn.Linear`模块初始化参数的方式略有不同：它使用从$minus StartFraction
    StartRoot 2 EndRoot Over 4 EndFraction$到$plus StartFraction StartRoot 2 EndRoot
    Over 4 EndFraction$的均匀随机分布来初始化权重和偏置项（我们将在[第11章](ch11.html#deep_chapter)中讨论初始化方法）。
- en: Now that you are familiar with PyTorch’s high-level API, you are ready to go
    beyond linear regression and build a multilayer perceptron (introduced in [Chapter 9](ch09.html#ann_chapter)).
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经熟悉了PyTorch的高级API，你就可以超越线性回归并构建多层感知器（在第9章[ann_chapter](ch09.html#ann_chapter)中介绍）。
- en: Implementing a Regression MLP
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 实现回归MLP
- en: 'PyTorch provides a helpful `nn.Sequential` module that chains multiple modules:
    when you call this module with some inputs, it feeds these inputs to the first
    module, then feeds the output of the first module to the second module, and so
    on. Most neural networks contain stacks of modules, and in fact many neural networks
    are just one big stack of modules: this makes the `nn.Sequential` module one of
    the most useful modules in PyTorch. The MLP we want to build is just that: a simple
    stack of modules—two hidden layers and one output layer. So let’s build it using
    the `nn.Sequential` module:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch提供了一个有用的`nn.Sequential`模块，可以将多个模块链接起来：当你用一些输入调用这个模块时，它会将这些输入传递给第一个模块，然后将第一个模块的输出传递给第二个模块，依此类推。大多数神经网络包含模块堆叠，实际上许多神经网络只是模块的一个大堆叠：这使得`nn.Sequential`模块成为PyTorch中最有用的模块之一。我们想要构建的MLP正是这样：一个简单的模块堆叠——两个隐藏层和一个输出层。所以让我们使用`nn.Sequential`模块来构建它：
- en: '[PRE35]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Let’s go through each layer:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐层分析：
- en: 'The first layer must have the right number of inputs for our data: `n_features`
    (equal to 8 in our case). However, it can have any number of outputs: let’s pick
    50 (that’s a hyperparameter we can tune).'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一层必须具有适合我们数据的正确输入数量：`n_features`（在我们的例子中等于8）。然而，它可以有任意数量的输出：让我们选择50（这是一个我们可以调整的超参数）。
- en: Next we have an `nn.ReLU` module, which implements the ReLU activation function
    for the first hidden layer. This module does not contain any model parameters,
    and it acts itemwise so the shape of its output is equal to the shape of its input.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接下来，我们有一个`nn.ReLU`模块，它实现了第一隐藏层的ReLU激活函数。此模块不包含任何模型参数，并且逐项操作，因此其输出形状等于其输入形状。
- en: 'The second hidden layer must have the same number of inputs as the output of
    the previous layer: in this case, 50\. However, it can have any number of outputs.
    It’s common to use the same number of output dimensions in all hidden layers,
    but in this example I used 40 to make it clear that the output of one layer must
    match the input of the next layer.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第二隐藏层必须具有与前一层的输出相同的输入数量：在这种情况下，50。然而，它可以有任意数量的输出。在所有隐藏层中使用相同数量的输出维度是常见的，但在本例中我使用了40，以便清楚地表明一层的输出必须匹配下一层的输入。
- en: Then again, an `nn.ReLU` module to implement the second hidden layer’s activation
    function.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然后，再次使用`nn.ReLU`模块来实现第二隐藏层的激活函数。
- en: 'Finally, the output layer must have 40 inputs, but this time its number of
    outputs is not free: it must match the targets’ dimensionality. Since our targets
    have a single dimension, we must have just one output dimension in the output
    layer.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，输出层必须有40个输入，但这次其输出数量不是自由的：它必须匹配目标的维度。由于我们的目标只有一个维度，因此输出层必须只有一个输出维度。
- en: 'Now let’s train the model just like we did before:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们像之前一样训练模型：
- en: '[PRE36]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: That’s it, you can tell your friends you trained your first neural network with
    PyTorch! However, we are still using batch gradient descent, computing the gradients
    over the entire training set at each iteration. This works with small datasets,
    but if we want to be able to scale up to large datasets and large models, we need
    to switch to mini-batch gradient descent.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样，你可以告诉你的朋友你已经用PyTorch训练了你的第一个神经网络！然而，我们仍然在使用批量梯度下降，在每个迭代中计算整个训练集的梯度。这对于小型数据集来说是可以的，但如果我们想要能够扩展到大型数据集和大型模型，我们需要切换到小批量梯度下降。
- en: Implementing Mini-Batch Gradient Descent Using DataLoaders
  id: totrans-170
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用DataLoader实现小批量梯度下降
- en: 'To help implement mini-batch GD, PyTorch provides a class named `DataLoader`
    in the `torch.utils.data` module. It can efficiently load batches of data of the
    desired size, and shuffle the data at each epoch if we want it to. The `DataLoader`
    expects the dataset to be represented as an object with at least two methods:
    `__len__(self)` to get the number of samples in the dataset, and `__getitem__(self,
    index)` to load the sample at the given index (including the target).'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助实现小批量梯度下降，PyTorch在`torch.utils.data`模块中提供了一个名为`DataLoader`的类。它可以高效地加载所需大小的一批数据，如果我们想要的话，还可以在每个epoch中打乱数据。`DataLoader`期望数据集以至少具有两个方法的对象表示：`__len__(self)`用于获取数据集中的样本数量，`__getitem__(self,
    index)`用于加载给定索引处的样本（包括目标）。
- en: 'In our case, the training set is available in the `X_train` and `y_train` tensors,
    so we first need to wrap these tensors in a dataset object with the required API.
    To help with this, PyTorch provides a `TensorDataset` class. So let’s build a
    `TensorDataset` to wrap our training set, and a `DataLoader` to pull batches from
    this dataset. During training, we want the dataset to be shuffled, so we specify
    `shuffle=True`:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，训练集包含在`X_train`和`y_train`张量中，因此我们首先需要将这些张量包装在具有所需API的数据集对象中。为此，PyTorch提供了一个`TensorDataset`类。所以让我们构建一个`TensorDataset`来包装我们的训练集，并创建一个`DataLoader`来从这个数据集中提取批次。在训练过程中，我们希望数据集被打乱，所以我们指定`shuffle=True`：
- en: '[PRE37]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Now that we have a larger model and we have the tools to train it one batch
    at a time, it’s a good time to start using hardware acceleration. It’s really
    quite simple: we just need to move the model to the GPU, which will move all of
    its parameters to the GPU RAM, and then at the start of each iteration during
    training we must copy each batch to the GPU. To move the model, we can just use
    its `to()` method, just like we did with tensors:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个更大的模型，并且我们有工具可以一次训练一个批次，现在是时候开始使用硬件加速了。这实际上非常简单：我们只需要将模型移动到GPU上，这将将其所有参数移动到GPU
    RAM中，然后在训练的每个迭代的开始时，我们必须将每个批次复制到GPU上。要移动模型，我们可以使用它的`to()`方法，就像我们处理张量一样：
- en: '[PRE38]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: We can also create the loss function and optimizer, as earlier (but using a
    lower learning rate, such as 0.02).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以创建损失函数和优化器，就像之前一样（但使用较低的学习率，例如0.02）。
- en: Warning
  id: totrans-177
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Some optimizers have some internal state, as we will see in [Chapter 11](ch11.html#deep_chapter).
    The optimizer will usually allocate its state on the same device as the model
    parameters, so it’s important to create the optimizer *after* you have moved the
    model to the GPU.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 一些优化器有一些内部状态，我们将在[第11章](ch11.html#deep_chapter)中看到。优化器通常会在与模型参数相同的设备上分配其状态，因此在你将模型移动到
    GPU 后创建优化器是很重要的。
- en: 'Now let’s create a `train()` function to implement mini-batch GD:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们创建一个 `train()` 函数来实现小批量 GD：
- en: '[PRE39]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'At every epoch, the function iterates through the whole training set, one batch
    at a time, and processes each batch just like earlier. But what about the very
    first line: `model.train()`? Well, this switches the model and all of its submodules
    to *training mode*. For now, this makes no difference at all, but it will be important
    in [Chapter 11](ch11.html#deep_chapter) when we start using layers that behave
    differently during training and evaluation (e.g., `nn.Dropout` or `nn.BatchNorm1d`).
    Whenever you want to use the model outside of training (e.g., for evaluation,
    or to make predictions on new instances), you must first switch the model to *evaluation
    mode* by running `model.eval()`. Note that `model.training` holds a boolean that
    indicates the current mode.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个时代，函数会逐批迭代整个训练集，一次处理一个批次，就像之前一样。但是，关于第一行：`model.train()` 呢？嗯，这会将模型及其所有子模块切换到**训练模式**。目前，这并没有什么区别，但在[第11章](ch11.html#deep_chapter)中，当我们开始使用在训练和评估期间表现不同的层（例如，`nn.Dropout`
    或 `nn.BatchNorm1d`）时，它将变得很重要。每次你想在训练之外使用模型（例如，用于评估或对新实例进行预测）时，你必须首先通过运行 `model.eval()`
    将模型切换到**评估模式**。请注意，`model.training` 包含一个布尔值，表示当前模式。
- en: Tip
  id: totrans-182
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: PyTorch itself does not provide a training loop implementation; you have to
    build it yourself. As we just saw, it’s not that long, and many people enjoy the
    freedom, clarity, and control this provides. However, if you would prefer to use
    a well-tested, off-the-shelf training loop with all the bells and whistles you
    need (such as multi-GPU support), then you can use a library such as PyTorch Lightning,
    FastAI, Catalyst, or Keras. These libraries are built on top of PyTorch and include
    a training loop and many other features (Keras supports PyTorch since version
    3, and also supports TensorFlow and JAX). Check them out!
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 本身不提供训练循环的实现；你必须自己构建它。正如我们刚才看到的，这并不长，许多人喜欢这种提供的自由、清晰和控制。然而，如果你更喜欢使用经过良好测试的现成训练循环，并且包含你需要的所有功能（例如，多GPU支持），那么你可以使用像
    PyTorch Lightning、FastAI、Catalyst 或 Keras 这样的库。这些库建立在 PyTorch 之上，包括训练循环和许多其他功能（Keras
    自版本 3 开始支持 PyTorch，同时也支持 TensorFlow 和 JAX）。查看它们吧！
- en: 'Now let’s call this `train()` function to train our model on the GPU:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们调用这个 `train()` 函数来在 GPU 上训练我们的模型：
- en: '[PRE40]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'It worked great: we actually reached a much lower loss in the same number of
    epochs! However, you probably noticed that each epoch was much slower. There are
    two easy tweaks you can make to considerably speed up training:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 它工作得很好：我们实际上在相同的周期数中达到了更低的损失！然而，你可能注意到了每个周期都要慢得多。你可以进行两个简单的调整来显著加快训练速度：
- en: 'If you are using a CUDA device, you should generally set `pin_memory=True`
    when creating the data loader: this will allocate the data in *page-locked memory*
    which guarantees a fixed physical memory location in the CPU RAM, and therefore
    allows direct memory access (DMA) transfers to the GPU, eliminating an extra copy
    operation that would otherwise be needed. While this could use more CPU RAM since
    the memory cannot be swapped out to disk, it typically results in significantly
    faster data transfers and thus faster training. When transferring a tensor to
    the GPU using its `to()` method, you may also set `non_blocking=True` to avoid
    blocking the CPU during the data transfer (this only works if `pin_memory=True`).'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你使用 CUDA 设备，在创建数据加载器时通常应该设置 `pin_memory=True`：这将数据分配在**页锁定内存**中，这保证了在 CPU
    RAM 中的固定物理内存位置，因此允许直接内存访问（DMA）传输到 GPU，消除了否则需要的额外复制操作。虽然这可能会使用更多的 CPU RAM，因为内存不能交换到磁盘上，但它通常会导致数据传输速度显著加快，从而加快训练速度。在用其
    `to()` 方法将张量传输到 GPU 时，你也可以设置 `non_blocking=True` 以避免在数据传输期间阻塞 CPU（这仅在 `pin_memory=True`
    时有效）。
- en: The current training loop waits until a batch has been fully processed before
    it loads the next batch. You can often speed up training by pre-fetching the next
    batches on the CPU while the GPU is still working on the current batch. For this,
    set the data loader’s `num_workers` argument to the number of processes you want
    to use for data loading and preprocessing. The optimal number depends on your
    platform, hardware, and workload, so you should experiment with different values.
    You can also tweak the number of batches that each worker pre-fetches by setting
    the data loader’s `prefetch_factor` argument. Note that the overhead of spawning
    and synchronizing workers can often slow down training rather than speed it up
    (especially on Windows). In this case, you can try setting `persistent_workers=True`
    to reuse the same workers across epochs.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当前的训练循环会在完全处理完一个批次之后才加载下一个批次。你可以在GPU仍在处理当前批次的同时，在CPU上预取下一个批次来加快训练速度。为此，将数据加载器的`num_workers`参数设置为你要用于数据加载和预处理的进程数。最佳数值取决于你的平台、硬件和工作负载，因此你应该尝试不同的值。你还可以通过设置数据加载器的`prefetch_factor`参数来调整每个工作进程预取的批次数量。请注意，启动和同步工作进程的开销可能会使训练速度变慢而不是变快（尤其是在Windows上）。在这种情况下，你可以尝试设置`persistent_workers=True`来跨epoch重用相同的工人。
- en: 'OK, time to step back a bit: you know the PyTorch fundamentals (tensors and
    autograd), you can build neural nets using PyTorch’s high-level API, and train
    them using mini-batch gradient descent, with the help of an optimizer, a criterion,
    and a data loader. The next step is to learn how to evaluate your model.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，现在让我们稍微退后一步：你知道PyTorch的基础知识（张量和自动微分），你可以使用PyTorch的高级API构建神经网络，并使用优化器、损失函数和数据加载器通过小批量梯度下降来训练它们。下一步是学习如何评估你的模型。
- en: Model Evaluation
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型评估
- en: 'Let’s write a function to evaluate the model. It takes the model and a `DataLoader`
    for the dataset that we want to evaluate the model on, as well as a function to
    compute the metric for a given batch, and lastly a function to aggregate the batch
    metrics (by default, it just computes the mean):'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们编写一个函数来评估模型。它接受模型以及一个用于评估模型的数据集的`DataLoader`，以及一个用于计算给定批次的度量函数，最后是一个用于聚合批次度量的函数（默认情况下，它只是计算平均值）：
- en: '[PRE41]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Now let’s build a `TensorDataset` and a `DataLoader` for our validation set,
    and pass it to our `evaluate()` function to compute the validation MSE:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们为我们的验证集构建一个`TensorDataset`和一个`DataLoader`，并将其传递给我们的`evaluate()`函数来计算验证MSE：
- en: '[PRE42]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'It works fine. But now suppose we want to use the RMSE instead of the MSE (as
    we saw in [Chapter 2](ch02.html#project_chapter), it can be easier to interpret).
    PyTorch does not have a built-in function for that, but it’s easy enough to write:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 它运行正常。但现在假设我们想使用RMSE而不是MSE（如我们在[第2章](ch02.html#project_chapter)中看到的，它可能更容易解释）。PyTorch没有内置该函数，但编写它很容易：
- en: '[PRE43]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'But wait a second! The RMSE should be equal to the square root of the MSE;
    however, when we compute the square root of the MSE that we found earlier, we
    get a different result:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 但等等！RMSE应该等于MSE的平方根；然而，当我们计算我们之前找到的MSE的平方根时，我们得到一个不同的结果：
- en: '[PRE44]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: The reason is that instead of calculating the RMSE over the whole validation
    set, we computed it over each batch and then computed the mean of all these batch
    RMSEs. That’s not mathematically equivalent to computing the RMSE over the whole
    validation set. To solve this, we can use the MSE as our `metric_fn`, and use
    the `aggregate_fn` to compute the square root of the mean MSE:⁠^([10](ch10.html#id2337))
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 原因是，我们不是在整个验证集上计算RMSE，而是对每个批次进行计算，然后计算所有这些批次RMSE的平均值。这从数学上不等同于在整个验证集上计算RMSE。为了解决这个问题，我们可以使用MSE作为我们的`metric_fn`，并使用`aggregate_fn`来计算平均MSE的平方根：⁠^([10](ch10.html#id2337))
- en: '[PRE45]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: That’s much better!
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 这好多了！
- en: 'Rather than implement metrics yourself, you may prefer to use the TorchMetrics
    library (made by the same team as PyTorch Lightning), which provides many well-tested
    *streaming metrics*. A streaming metric is an object that keeps track of a given
    metric, and can be updated one batch at a time. The TorchMetrics library is not
    preinstalled on Colab, so we have to run `%pip install torchmetrics`, then we
    can implement the `evaluate_tm()` function, like this:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 与其自己实现度量，你可能更愿意使用TorchMetrics库（由PyTorch Lightning团队制作），它提供了许多经过良好测试的*流度量*。流度量是一个跟踪给定度量的对象，可以逐批更新。TorchMetrics库在Colab上没有预安装，因此我们必须运行`%pip
    install torchmetrics`，然后我们可以实现`evaluate_tm()`函数，如下所示：
- en: '[PRE46]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Then we can create an RMSE streaming metric, move it to the GPU, and use it
    to evaluate the validation set:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以创建一个 RMSE 流量指标，将其移动到 GPU 上，并使用它来评估验证集：
- en: '[PRE47]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Sure enough, we get the correct result! Now try updating the `train()` function
    to evaluate your model’s performance during training, both on the training set
    (during each epoch) and on the validation set (at the end of each epoch). As always,
    if the performance on the training set is much better than on the validation set,
    your model is probably overfitting the training set, or there is a bug, such as
    a data mismatch between the training set and the validation set. This is easier
    to detect if you plot and analyze the learning curves, much like we did in [Chapter 4](ch04.html#linear_models_chapter).
    For this you can use Matplotlib, or a visualization tool such as TensorBoard (see
    the notebook for an example).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 果然，我们得到了正确的结果！现在尝试更新 `train()` 函数，以评估模型在训练过程中的性能，包括在训练集（在每个 epoch 期间）和验证集（在每个
    epoch 结束时）。像往常一样，如果训练集上的性能远好于验证集，那么你的模型可能过度拟合了训练集，或者存在一个错误，比如训练集和验证集之间的数据不匹配。如果你绘制并分析学习曲线，这会更容易检测到，就像我们在
    [第 4 章](ch04.html#linear_models_chapter) 中做的那样。为此，你可以使用 Matplotlib 或 TensorBoard
    这样的可视化工具（参见笔记本中的示例）。
- en: Now you know how to build, train, and evaluate a regression MLP using PyTorch,
    and how to use the trained model to make predictions. Great! But so far we have
    only looked at simple sequential models, composed of a sequence of linear layers
    and ReLU activation functions. How would you build a more complex, nonsequential
    model? For this, we will need to build custom modules.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道了如何使用 PyTorch 构建、训练和评估一个回归 MLP，以及如何使用训练好的模型进行预测。太棒了！但到目前为止，我们只看了简单的顺序模型，由一系列线性层和
    ReLU 激活函数组成。你将如何构建一个更复杂、非顺序的模型呢？为此，我们需要构建自定义模块。
- en: Building Nonsequential Models Using Custom Modules
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用自定义模块构建非顺序模型
- en: One example of a nonsequential neural network is a *Wide & Deep* neural network.
    This neural network architecture was introduced in a 2016 paper by Heng-Tze Cheng
    et al.⁠^([11](ch10.html#id2340)) It connects all or part of the inputs directly
    to the output layer, as shown in [Figure 10-1](#wide_deep_diagram). This architecture
    makes it possible for the neural network to learn both deep patterns (using the
    deep path) and simple rules (through the short path). The short path can also
    be used to provide manually engineered features to the neural network. In contrast,
    a regular MLP forces all the data to flow through the full stack of layers; thus,
    simple patterns in the data may end up being distorted by this sequence of transformations.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 非顺序神经网络的一个例子是 *宽 & 深度* 神经网络。这种神经网络架构是在 2016 年由 Heng-Tze Cheng 等人发表的一篇论文中提出的。它将所有或部分输入直接连接到输出层，如图
    [图 10-1](#wide_deep_diagram) 所示。这种架构使得神经网络能够学习深度模式（使用深度路径）和简单规则（通过短路径）。短路径也可以用来向神经网络提供手动工程化的特征。相比之下，一个常规的
    MLP 强制所有数据都通过完整的层堆栈；因此，数据中的简单模式可能会被这个变换序列扭曲。
- en: '![Diagram illustrating a Wide & Deep neural network architecture, showing both
    wide and deep paths connecting inputs directly and through hidden layers, converging
    at a concat layer before the output layer.](assets/hmls_1001.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![展示宽度与深度神经网络架构的示意图，显示宽路径和深路径直接连接输入并通过隐藏层，在输出层之前的拼接层前汇聚。](assets/hmls_1001.png)'
- en: Figure 10-1\. Wide & Deep neural network
  id: totrans-211
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-1\. 宽度与深度神经网络
- en: 'Let’s build such a neural network to tackle the California housing dataset.
    Because this wide and deep architecture is nonsequential, we have to create a
    custom module. It’s easier than it sounds: just create a class derived from `torch.nn.Module`,
    then create all the layers you need in the constructor (after calling the base
    class’s `__init__()` method), and define how these layers should be used by the
    module in the `forward()` method:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们构建这样一个神经网络来处理加利福尼亚住房数据集。因为这个宽度和深度架构是非顺序的，我们必须创建一个自定义模块。这比听起来容易：只需创建一个从 `torch.nn.Module`
    派生的类，然后在构造函数中（在调用基类的 `__init__()` 方法之后）创建所有需要的层，并在 `forward()` 方法中定义这些层应该如何被模块使用：
- en: '[PRE48]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Notice that we can use any kind of module inside our custom module: in this
    example, we use an `nn.Sequential` module to build the “deep” part of our model
    (it’s actually not that deep; this is just a toy example). It’s the same MLP as
    earlier, except we separated the output layer because we need to feed it the concatenation
    of the model’s inputs and the deep part’s outputs. For this same reason, the output
    layer now has 40 + `n_features` inputs instead of just 40.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，我们可以在自定义模块内部使用任何类型的模块：在这个例子中，我们使用 `nn.Sequential` 模块来构建模型中的“深度”部分（实际上并不深；这只是一个玩具示例）。它与之前的
    MLP 相同，只是我们分离了输出层，因为我们需要将模型输入和深度部分的输出连接起来输入。出于同样的原因，输出层现在有 40 + `n_features` 个输入，而不是仅仅
    40 个。
- en: In the `forward()` method, we just feed the input `X` to the deep stack, concatenate
    the input and the deep stack’s output, and feed the result to the output layer.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `forward()` 方法中，我们只需将输入 `X` 输送到深度堆叠中，连接输入和深度堆叠的输出，然后将结果输入到输出层。
- en: Note
  id: totrans-216
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Modules have a `children()` method that returns an iterator over the module’s
    submodules (nonrecursively). There’s also a `named_children()` method. If your
    model has a variable number of submodules, you should store them in an `nn.ModuleList`
    or an `nn.ModuleDict`, which are returned by the `children()` and `named_children()`
    methods (as opposed to regular Python lists and dicts). Similarly, if your model
    has a variable number of parameters, you should store them in an `nn.ParameterList`
    or an `nn.ParameterDict` to ensure they are returned by the `parameters()` and
    `named_parameters()` methods.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 模块有一个 `children()` 方法，它返回模块子模块（非递归）的迭代器。还有一个 `named_children()` 方法。如果你的模型具有可变数量的子模块，你应该将它们存储在
    `nn.ModuleList` 或 `nn.ModuleDict` 中，这些是由 `children()` 和 `named_children()` 方法返回的（与常规
    Python 列表和字典不同）。同样，如果你的模型具有可变数量的参数，你应该将它们存储在 `nn.ParameterList` 或 `nn.ParameterDict`
    中，以确保它们由 `parameters()` 和 `named_parameters()` 方法返回。
- en: 'Now we can create an instance of our custom module, move it to the GPU, train
    it, evaluate it, and use it exactly like our previous models:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以创建自定义模块的一个实例，将其移动到 GPU 上，对其进行训练、评估，并像我们之前的模型一样使用它：
- en: '[PRE49]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'But what if you want to send a subset of the features through the wide path
    and a different subset (possibly overlapping) through the deep path, as illustrated
    in [Figure 10-2](#multiple_inputs_diagram)? In this case, one approach is to split
    the inputs inside the `forward()` method, for example:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果你想要将特征子集通过宽路径发送，而将不同的子集（可能重叠）通过深度路径发送，如图 [图 10-2](#multiple_inputs_diagram)
    所示，那会怎样？在这种情况下，一种方法是在 `forward()` 方法内部拆分输入，例如：
- en: '[PRE50]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: This works fine; however, in many cases it’s preferable to just let the model
    take two separate tensors as input. Let’s see why and how.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 这工作得很好；然而，在许多情况下，直接让模型接受两个独立的张量作为输入更为可取。让我们看看为什么以及如何做到这一点。
- en: Building Models with Multiple Inputs
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用多个输入构建模型
- en: 'Some models require multiple inputs that cannot easily be combined into a single
    tensor. For example, the inputs may have a different number of dimensions (e.g.,
    when you want to feed both images and text to the neural network). To make our
    Wide & Deep model take two separate inputs, as shown in [Figure 10-2](#multiple_inputs_diagram),
    we must start by changing the model’s `forward()` method:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 一些模型需要多个输入，这些输入不能轻易地合并成一个张量。例如，输入可能具有不同的维度数量（例如，当你想将图像和文本同时输入到神经网络中时）。为了让我们的
    Wide & Deep 模型接受两个独立的输入，如图 [图 10-2](#multiple_inputs_diagram) 所示，我们必须首先更改模型的 `forward()`
    方法：
- en: '[PRE51]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '![Diagram illustrating the flow of a neural network with wide and deep inputs,
    concatenated before feeding into the output layer.](assets/hmls_1002.png)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![说明具有宽度和深度输入的神经网络流程的图，在输入到输出层之前进行连接。](assets/hmls_1002.png)'
- en: Figure 10-2\. Handling multiple inputs
  id: totrans-227
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 10-2\. 处理多个输入
- en: 'Next, we need to create datasets that return the wide and deep inputs separately:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要创建返回宽度和深度输入的单独数据集：
- en: '[PRE52]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Since the data loaders now return three tensors instead of two at each iteration,
    we need to update the main loop in the evaluation and training functions:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据加载器现在在每个迭代中返回三个张量而不是两个，我们需要更新评估和训练函数中的主循环：
- en: '[PRE53]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'Alternatively, since the order of the inputs matches the order of the `forward()`
    method’s arguments, we can use Python’s `*` operator to unpack all the inputs
    returned by the `data_loader` and pass them to the model. The advantage of this
    implementation is that it will work with models that take any number of inputs,
    not just two, as long as the order is correct:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，由于输入的顺序与`forward()`方法参数的顺序匹配，我们可以使用Python的`*`操作符来解包`data_loader`返回的所有输入，并将它们传递给模型。这种实现的优势是，只要顺序正确，它将适用于接受任何数量输入的模型，而不仅仅是两个输入：
- en: '[PRE54]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'When your model has many inputs, it’s easy to make a mistake and mix up the
    order of the inputs, which can lead to hard-to-debug issues. To avoid this, it
    can be a good idea to name each input. For this, you can define a custom dataset
    that returns a dictionary from input names to input values, like this:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的模型有多个输入时，很容易出错并混淆输入的顺序，这可能导致难以调试的问题。为了避免这种情况，给每个输入命名可能是一个好主意。为此，你可以定义一个自定义数据集，它从输入名称到输入值返回一个字典，如下所示：
- en: '[PRE55]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Then create the datasets and data loaders:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 然后创建数据集和数据加载器：
- en: '[PRE56]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Once again, we also need to update the main loop in the evaluation and training
    functions:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，我们还需要更新评估和训练函数中的主循环：
- en: '[PRE57]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Alternatively, since all the input names match the `forward()` method’s argument
    names, we can use Python’s `**` operator to unpack all the tensors in the `inputs`
    dictionary and pass them as named arguments to the model: `y_pred = model(**inputs)`.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，由于所有输入名称都与`forward()`方法的参数名称匹配，我们可以使用Python的`**`操作符来解包`inputs`字典中的所有张量，并将它们作为命名参数传递给模型：`y_pred
    = model(**inputs)`.
- en: Now that you know how to build sequential and nonsequential models with one
    or more inputs, let’s look at models with multiple outputs.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经知道了如何构建具有一个或多个输入的顺序和非顺序模型，让我们来看看具有多个输出的模型。
- en: Building Models with Multiple Outputs
  id: totrans-242
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用多个输出的构建模型
- en: 'There are many use cases where you may need a neural net with multiple outputs:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，你可能需要一个具有多个输出的神经网络：
- en: The task may demand it. For instance, you may want to locate and classify the
    main object in a picture. This is both a regression task and a classification
    task.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 任务可能需要这样做。例如，你可能想在图片中定位和分类主要对象。这既是回归任务也是分类任务。
- en: Similarly, you may have multiple independent tasks based on the same data. Sure,
    you could train one neural network per task, but in many cases you will get better
    results on all tasks by training a single neural network with one output per task.
    This is because the neural network can learn features in the data that are useful
    across tasks. For example, you could perform *multitask classification* on pictures
    of faces, using one output to classify the person’s facial expression (smiling,
    surprised, etc.) and another output to identify whether they are wearing glasses
    or not.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 类似地，你可能基于相同的数据有多个独立任务。当然，你可以为每个任务训练一个神经网络，但在许多情况下，通过为每个任务训练一个具有单个输出的单个神经网络，你将在所有任务上获得更好的结果。这是因为神经网络可以在数据中学习到对多个任务都有用的特征。例如，你可以在人脸图片上执行*多任务分类*，一个输出用于分类人的面部表情（微笑、惊讶等），另一个输出用于识别他们是否戴眼镜。
- en: Another use case is regularization (i.e., a training constraint whose objective
    is to reduce overfitting and thus improve the model’s ability to generalize).
    For example, you may want to add an auxiliary output in a neural network architecture
    (see [Figure 10-3](#multiple_outputs_diagram)) to ensure that the underlying part
    of the network learns something useful on its own, without relying on the rest
    of the network.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个用例是正则化（即一个训练约束，其目标是减少过拟合，从而提高模型泛化的能力）。例如，你可能想在神经网络架构中添加一个辅助输出（见[图10-3](#multiple_outputs_diagram)），以确保网络的底层部分能够独立地学习到有用的东西，而不依赖于网络的其他部分。
- en: '![Diagram illustrating a neural network with an auxiliary output layer added
    for regularization, showcasing the flow from input layers through hidden layers
    to main and auxiliary outputs.](assets/hmls_1003.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![说明添加辅助输出层以进行正则化的神经网络图，展示了从输入层通过隐藏层到主输出和辅助输出的流程。](assets/hmls_1003.png)'
- en: Figure 10-3\. Handling multiple outputs, in this example to add an auxiliary
    output for regularization
  id: totrans-248
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-3\. 处理多个输出，本例中为正则化添加辅助输出
- en: 'Let’s add an auxiliary output to our Wide & Deep model to ensure the deep part
    can make good predictions on its own. Since the deep stack’s output dimension
    is 40, and the targets have a single dimension, we must add an `nn.Linear` layer
    for the auxiliary output to go from 40 dimensions down to 1\. We also need to
    make the `forward()` method compute the auxiliary output, and return both the
    main output and the auxiliary output:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在Wide & Deep模型中添加一个辅助输出，以确保深度部分可以独立做出良好的预测。由于深度堆栈的输出维度是40，而目标只有一个维度，我们必须添加一个`nn.Linear`层，将辅助输出从40维度降低到1。我们还需要确保`forward()`方法计算辅助输出，并返回主要输出和辅助输出：
- en: '[PRE58]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Next, we need to update the main loop in the training function:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要更新训练函数中的主循环：
- en: '[PRE59]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Notice that the model now returns both the main predictions `y_pred` and the
    auxiliary predictions `y_pred_aux`. In this example, we can use the same targets
    and the same loss function to compute the main output’s loss and the auxiliary
    output’s loss. In other cases, you may have different targets and loss functions
    for each output, in which case you would need to create a custom dataset to return
    all the necessary targets. Once we have a loss for each output, we must combine
    them into a single loss that will be minimized by gradient descent. In general,
    this final loss is just a weighted sum of all the output losses. In this example,
    we use a higher weight for the main loss (0.8), because that’s what we care about
    the most, and a lower weight for the auxiliary loss (0.2). This ratio is a regularization
    hyperparameter that you can tune.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，现在模型返回了主要预测`y_pred`和辅助预测`y_pred_aux`。在这个例子中，我们可以使用相同的目标和相同的损失函数来计算主要输出的损失和辅助输出的损失。在其他情况下，你可能需要对每个输出有不同的目标和损失函数，在这种情况下，你需要创建一个自定义数据集来返回所有必要的目标。一旦我们为每个输出有了损失，我们必须将它们组合成一个单一的损失，这个损失将通过梯度下降来最小化。一般来说，这个最终的损失只是所有输出损失的加权总和。在这个例子中，我们为主要的损失（0.8）使用更高的权重，因为我们最关心这个，而辅助损失（0.2）使用较低的权重。这个比率是一个正则化超参数，你可以调整它。
- en: 'We also need to update the main loop in the evaluation function. However, in
    this case we can just ignore the auxiliary output, since we only really care about
    the main output—the auxiliary output is just there for regularization during training:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要更新评估函数中的主循环。然而，在这种情况下，我们可以忽略辅助输出，因为我们真正关心的是主要输出——辅助输出只是用于训练期间的正则化：
- en: '[PRE60]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: Voilà! You can now build and train all sorts of neural net architectures, combining
    predefined modules and custom modules in any way you please, and with any number
    of inputs and outputs. The flexibility of neural networks is one of their main
    qualities. But so far we have only tackled a regression task, so let’s now turn
    to classification.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 哇！现在你可以构建和训练各种神经网络架构，以任何你想要的方式组合预定义模块和自定义模块，以及任何数量的输入和输出。神经网络的可塑性是它们的主要品质之一。但到目前为止，我们只处理了回归任务，所以现在让我们转向分类。
- en: Building an Image Classifier with PyTorch
  id: totrans-257
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PyTorch构建图像分类器
- en: As in [Chapter 9](ch09.html#ann_chapter), we will tackle the Fashion MNIST dataset,
    so the first thing we need to do is to download the dataset. We could use the
    `fetch_openml()` function like we did in [Chapter 9](ch09.html#ann_chapter), but
    we will show another method instead, using the TorchVision library.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 如同[第9章](ch09.html#ann_chapter)中所述，我们将处理Fashion MNIST数据集，所以我们需要做的第一件事是下载数据集。我们可以使用与第9章相同的`fetch_openml()`函数，但我们将展示另一种方法，使用TorchVision库。
- en: Using TorchVision to Load the Dataset
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用TorchVision加载数据集
- en: 'The TorchVision library is an important part of the PyTorch ecosystem: it provides
    many tools for computer vision, including utility functions to download common
    datasets, such as MNIST or Fashion MNIST, as well as pretrained models for various
    computer vision tasks (see [Chapter 12](ch12.html#cnn_chapter)), functions to
    transform images (e.g., crop, rotate, resize, etc.), and more. It is preinstalled
    on Colab, so let’s go ahead and use it to load Fashion MNIST. It is already split
    into a training set (60,000 images) and a test set (10,000 images), but we’ll
    hold out the last 5,000 images from the training set for validation, using PyTorch’s
    `random_split()` function:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: TorchVision库是PyTorch生态系统的重要组成部分：它提供了许多计算机视觉工具，包括下载常见数据集的实用函数，例如MNIST或Fashion
    MNIST，以及各种计算机视觉任务的预训练模型（见[第12章](ch12.html#cnn_chapter)），图像转换函数（例如裁剪、旋转、调整大小等），等等。它在Colab上预先安装，所以让我们继续使用它来加载Fashion
    MNIST。它已经分为训练集（60,000张图像）和测试集（10,000张图像），但我们将从训练集的最后5,000张图像中保留用于验证，使用PyTorch的`random_split()`函数：
- en: '[PRE61]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: After the imports and before loading the datasets, we create a `toTensor` object.
    What’s that about? Well, by default, the `FashionMNIST` class loads images as
    PIL (Python Image Library) images, with integer pixel values ranging from 0 to
    255\. But we need PyTorch float tensors instead, with scaled pixel values. Luckily,
    TorchVision datasets accept a `transform` argument which lets you pass a preprocessing
    function that will get executed on the fly whenever the data is accessed (there’s
    also a `target_transform` argument if you need to preprocess the targets). TorchVision
    provides many transform objects that you can use for this (most of these transforms
    are PyTorch modules).
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在导入之后和加载数据集之前，我们创建了一个`toTensor`对象。这是怎么回事？嗯，默认情况下，`FashionMNIST`类以PIL（Python
    Image Library）图像的形式加载图像，像素值从0到255的整数。但我们需要PyTorch浮点张量，具有缩放的像素值。幸运的是，TorchVision数据集接受一个`transform`参数，允许你传递一个预处理函数，该函数将在数据访问时即时执行（如果需要预处理目标，还有一个`target_transform`参数）。TorchVision提供了许多可用于此的转换对象（这些转换中的大多数都是PyTorch模块）。
- en: 'In this code, we create a `Compose` transform to chain two transforms: a `ToImage`
    transform followed by a `ToDtype` transform. `ToImage` converts various formats—including
    PIL images, NumPy arrays, and tensors—to TorchVision’s `Image` class, which is
    a subclass of `Tensor`. The `ToDtype` transform converts the data type, in this
    case to 32-bit floats. We also set its `scale` argument to `True` to ensure the
    values get scaled between 0.0 and 1.0.⁠^([12](ch10.html#id2370))'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码中，我们创建了一个`Compose`转换来链式调用两个转换：一个`ToImage`转换后跟一个`ToDtype`转换。`ToImage`转换将各种格式（包括PIL图像、NumPy数组和张量）转换为TorchVision的`Image`类，它是`Tensor`的子类。`ToDtype`转换将数据类型转换为32位浮点数。我们还将其`scale`参数设置为`True`，以确保值在0.0和1.0之间缩放。⁠^([12](ch10.html#id2370))
- en: Note
  id: totrans-264
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Version 1 of TorchVision’s transforms API is still available for backward compatibility
    and can be imported using `import` `torchvision.transforms`, However, you should
    use version 2 (`torchvision.transformers.v2`) instead, since it’s faster and has
    more features.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: TorchVision转换API的版本1仍然可用于向后兼容，可以使用`import` `torchvision.transforms`导入，但是你应该使用版本2（`torchvision.transformers.v2`），因为它更快，并且具有更多功能。
- en: 'Next, we load the dataset: first the training and validation data, then the
    test data. The `root` argument is the path to the directory where TorchVision
    will create a subdirectory for the Fashion MNIST dataset. The `train` argument
    indicates whether you want to load the training set (`True` by default) or the
    test set. The `download` argument indicates whether to download the dataset if
    it cannot be found locally (`False` by default). And we also set `transform=toTensor`
    to use our custom preprocessing pipeline.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们加载数据集：首先加载训练和验证数据，然后加载测试数据。`root`参数是TorchVision将创建Fashion MNIST数据集子目录的目录路径。`train`参数表示你是否想加载训练集（默认为`True`）或测试集。`download`参数表示如果本地找不到数据集是否下载（默认为`False`）。我们还设置了`transform=toTensor`以使用我们的自定义预处理管道。
- en: 'As usual, we must create data loaders:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 如往常一样，我们必须创建数据加载器：
- en: '[PRE62]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Now let’s look at the first image in the training set:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看训练集中的第一张图像：
- en: '[PRE63]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'In [Chapter 9](ch09.html#ann_chapter), each image was represented by a 1D array
    containing 784 pixel intensities, but now each image tensor has 3 dimensions,
    and its shape is: `[1, 28, 28]`. The first dimension is the *channel* dimension.
    For grayscale images, there is a single channel (color images usually have three
    channels, as we will see in [Chapter 12](ch12.html#cnn_chapter)). The other two
    dimensions are the height and width dimensions. For example, `X_sample[0, 2, 4]`
    represents the pixel located in channel 0, row 2, column 4\. In Fashion MNIST,
    a larger value means a darker pixel.'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第9章](ch09.html#ann_chapter)中，每个图像由一个包含784个像素强度的1D数组表示，但现在每个图像张量有3个维度，其形状为：`[1,
    28, 28]`。第一个维度是通道维度。对于灰度图像，有一个单独的通道（彩色图像通常有三个通道，我们将在[第12章](ch12.html#cnn_chapter)中看到）。其他两个维度是高度和宽度维度。例如，`X_sample[0,
    2, 4]`表示位于通道0、行2、列4的像素。在Fashion MNIST中，较大的值表示较暗的像素。
- en: Warning
  id: totrans-272
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: PyTorch expects the channel dimension to be first, while many other libraries,
    such as Matplotlib, PIL, TensorFlow, OpenCV, or Scikit-Image, expect it to be
    last. Always make sure to move the channel dimension to the right place, depending
    on the library you are using. `ToImage` already took care of moving the channel
    dimension to the first position, otherwise we could have used the `torch.permute()`
    function.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch期望通道维度是第一个，而许多其他库，例如Matplotlib、PIL、TensorFlow、OpenCV或Scikit-Image，期望它是最后一个。务必确保根据你使用的库将通道维度移动到正确的位置。`ToImage`已经处理了将通道维度移动到第一个位置的问题，否则我们可以使用`torch.permute()`函数。
- en: 'As for the targets, they are integers from 0 to 9, and we can interpret them
    using the same `class_names` array as in [Chapter 9](ch09.html#ann_chapter). In
    fact, many datasets—including `FashionMNIST`—have a `classes` attribute containing
    the list of class names. For example, here’s how we can tell that the sample image
    represents an ankle boot:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 对于目标，它们是0到9的整数，我们可以使用与[第9章](ch09.html#ann_chapter)中相同的`class_names`数组来解释它们。实际上，许多数据集——包括`FashionMNIST`——都有一个包含类名列表的`classes`属性。例如，以下是判断样本图像代表一双踝靴的方法：
- en: '[PRE64]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Building the Classifier
  id: totrans-276
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建分类器
- en: 'Let’s build a custom module for a classification MLP with two hidden layers:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为具有两个隐藏层的分类MLP构建一个自定义模块：
- en: '[PRE65]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'There are a few things to note in this code:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 在此代码中需要注意以下几点：
- en: First, the model is composed of a single sequence of layers, which is why we
    used the `nn.Sequential` module. We did not have to create a custom module; we
    could have written `model = nn.Sequential(...)` instead, but it’s generally preferable
    to wrap your models in custom modules, as it makes your code easier to deploy
    and reuse, and it’s also easier to tune the hyperparameters.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，模型由一个单一的层序列组成，这就是为什么我们使用了`nn.Sequential`模块。我们不必创建自定义模块；我们可以用`model = nn.Sequential(...)`来代替，但通常更倾向于将模型包裹在自定义模块中，因为它使得你的代码更容易部署和重用，并且也更容易调整超参数。
- en: 'The model starts with an `nn.Flatten` layer: this layer does not have any parameters,
    it just reshapes each input sample to a single dimension, which is needed for
    the `nn.Linear` layers. For example, a batch of 32 Fashion MNIST images has a
    shape of `[32, 1, 28, 28]`, but after going through the `nn.Flatten` layer, it
    ends up with a shape of `[32, 784]` (since 28 × 28 = 784).'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型从`nn.Flatten`层开始：这个层没有任何参数，它只是将每个输入样本重塑为单维，这对于`nn.Linear`层是必需的。例如，一个包含32个Fashion
    MNIST图像的批次具有形状`[32, 1, 28, 28]`，但经过`nn.Flatten`层后，最终形状变为`[32, 784]`（因为28×28=784）。
- en: The first hidden layer must have the correct number of inputs (28 × 28 = 784),
    and the output layer must have the correct number of outputs (10, one per class).
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一个隐藏层必须有正确的输入数量（28×28=784），输出层必须有正确的输出数量（10，每个类别一个）。
- en: We use a ReLU activation function after each hidden layer, and no activation
    function at all after the output layer.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在每个隐藏层之后使用ReLU激活函数，在输出层之后不使用任何激活函数。
- en: Since this is a multiclass classification task, we use `nn.CrossEntropyLoss`.
    It accepts either class indices as targets (as in this example), or class probabilities
    (such as one-hot vectors).
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于这是一个多类分类任务，我们使用`nn.CrossEntropyLoss`。它接受类索引作为目标（如本例所示），或者类概率（如one-hot向量）。
- en: Tip
  id: totrans-285
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: 'Shape errors are quite common, especially when getting started, so you should
    familiarize yourself with the error messages: try removing the `nn.Flatten` module,
    or try messing with the shape of the inputs and/or labels, and see the errors
    you get.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 形状错误相当常见，尤其是在入门阶段，因此你应该熟悉错误信息：尝试移除`nn.Flatten`模块，或者尝试修改输入和/或标签的形状，并查看你得到的错误。
- en: But wait! Didn’t we say in [Chapter 9](ch09.html#ann_chapter) that we should
    use the softmax activation function on the output layer for multiclass classification
    tasks? Well it turns out that PyTorch’s `nn.CrossEntropyLoss` computes the cross-entropy
    loss directly from the logits (i.e., the class scores, introduced in [Chapter 4](ch04.html#linear_models_chapter)),
    rather than from the class probabilities. This bypasses some costly computations
    during training (e.g., logarithms and exponentials that cancel out), saving both
    compute and RAM. It’s also more numerically stable. However, the downside is that
    the model must output logits, which means that we will have to call the softmax
    function manually on the logits whenever we want class probabilities, as we will
    see shortly.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 但等等！在第9章中我们不是说过，在多类分类任务中，我们应该在输出层使用softmax激活函数吗？实际上，PyTorch的`nn.CrossEntropyLoss`直接从logits（即类分数，在第4章中介绍）计算交叉熵损失，而不是从类概率计算。这绕过了训练期间的一些昂贵的计算（例如，对数和指数相互抵消），节省了计算和RAM。它也更具数值稳定性。然而，缺点是模型必须输出logits，这意味着我们将在需要类概率时手动在logits上调用softmax函数，正如我们很快就会看到的。
- en: 'Now we can train the model as usual (e.g., using the `train()` function with
    an `SGD` optimizer). To evaluate the model, we can use the `Accuracy` streaming
    metric from the `torchmetrics` library, and move it to the GPU:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以像往常一样训练模型（例如，使用带有`SGD`优化器的`train()`函数）。为了评估模型，我们可以使用`torchmetrics`库中的`Accuracy`流式指标，并将其移动到GPU：
- en: '[PRE66]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: Warning
  id: totrans-290
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Training the model will take a few minutes with a GPU (or much longer without
    one). Handling images requires significantly more compute and memory than handling
    low-dimensional data.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 使用GPU训练模型将花费几分钟（如果没有GPU，则可能需要更长的时间）。处理图像比处理低维数据需要显著更多的计算和内存。
- en: The model reaches around 92.8% accuracy on the training set, and 87.2% accuracy
    on the validation set (the results might differ a bit depending on the hardware
    accelerator you use). This means there’s a little bit of overfitting going on,
    so you may want to reduce the number of neurons or add some regularization (see
    [Chapter 11](ch11.html#deep_chapter)).
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 模型在训练集上达到约92.8%的准确率，在验证集上达到87.2%的准确率（根据你使用的硬件加速器的不同，结果可能会有所不同）。这意味着存在一点过拟合，因此你可能想要减少神经元数量或添加一些正则化（参见[第11章](ch11.html#deep_chapter)）。
- en: 'Now that the model is trained, we can use it to make predictions on new images.
    As an example, let’s make predictions for the first batch in the validation set,
    and look at the results for the first three images:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 现在模型已经训练好了，我们可以用它来对新图像进行预测。例如，让我们对验证集的第一批中的第一个样本进行预测，并查看前三个图像的结果：
- en: '[PRE67]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: For each image, the predicted class is the one with the highest logit. In this
    example, all three predictions are correct!
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个图像，预测的类别是具有最高logits的类别。在这个例子中，所有三个预测都是正确的！
- en: 'But what if we want the model’s estimated probabilities? For this, we need
    to compute the softmax of the logits manually, since the model does not include
    the softmax activation function on the output layer, as we discussed earlier.
    We could create an `nn.Softmax` module and pass it the logits, but we can also
    just call the `softmax()` function, which is just one of many functions you will
    find in the `torch.nn.functional` module (by convention, this module is usually
    imported as `F`). It doesn’t make much difference, it just avoids creating a module
    instance that we don’t need:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果我们想得到模型的估计概率呢？为此，我们需要手动计算logits的softmax，因为模型在输出层没有包含softmax激活函数，正如我们之前讨论的那样。我们可以创建一个`nn.Softmax`模块，并将logits传递给它，但也可以直接调用`softmax()`函数，这是你将在`torch.nn.functional`模块中找到的许多函数之一（按照惯例，这个模块通常被导入为`F`）。这并没有太大的区别，只是避免了创建我们不需要的模块实例：
- en: '[PRE68]'
  id: totrans-297
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Just like in [Chapter 9](ch09.html#ann_chapter), the model is very confident
    about the first two predictions: 91.1% and 99.6%, respectively.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 就像在[第9章](ch09.html#ann_chapter)中提到的，模型对前两个预测非常有信心：分别为91.1%和99.6%。
- en: Tip
  id: totrans-299
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: If you wish to apply label smoothing during training, just set the `label_smoothing`
    hyperparameter of the `nn.CrossEntropyLoss` to the amount of smoothing you wish,
    between 0 and 1 (e.g., 0.05).
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在训练期间应用标签平滑，只需将`nn.CrossEntropyLoss`的`label_smoothing`超参数设置为所需的平滑量，介于0和1之间（例如，0.05）。
- en: 'It can often be useful to get the model’s top *k* predictions. For this, we
    can use the `torch.topk()` function, which returns a tuple containing both the
    top *k* values and their indices:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 有时获取模型的 top *k* 预测结果非常有用。为此，我们可以使用 `torch.topk()` 函数，该函数返回一个包含 top *k* 值及其索引的元组：
- en: '[PRE69]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: For the first image, the model’s best guess is class 7 (Sneaker) with 91.1%
    confidence, its second best guess is class 9 (Ankle boot) with 8.8% confidence,
    and so on.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第一张图片，模型的最佳猜测是类别 7（运动鞋），置信度为 91.1%，其次最佳猜测是类别 9（踝靴），置信度为 8.8%，依此类推。
- en: Tip
  id: totrans-304
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: The Fashion MNIST dataset is balanced, meaning it has the same number of instances
    of each class. When dealing with an unbalanced dataset, you should generally give
    more weight to the rare classes and less weight to the frequent ones, or else
    your model will be biased toward the more frequent classes. You can do this by
    setting the `weight` argument of the `nn.CrossEntropyLoss`. For example, if there
    are three classes with 900, 700, and 400 instances, respectively (i.e., 2000 instances
    in total), then the respective weights should be 2000/900, 2000/700, and 2000/400\.
    It’s preferable to normalize these weights to ensure they add up to 1, so in this
    example you would set `weight=torch.tensor([0.2205, 0.2835, 0.4961])`.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: Fashion MNIST 数据集是平衡的，这意味着它每个类别的实例数量相同。当处理不平衡的数据集时，你应该通常给予罕见类别更多的权重，而对于频繁出现的类别则给予较少的权重，否则你的模型将偏向于更频繁出现的类别。你可以通过设置
    `nn.CrossEntropyLoss` 的 `weight` 参数来实现这一点。例如，如果有三个类别，分别有 900、700 和 400 个实例（即总共
    2000 个实例），那么相应的权重应该是 2000/900、2000/700 和 2000/400。最好将这些权重归一化，以确保它们的总和为 1，因此在这个例子中，你会设置
    `weight=torch.tensor([0.2205, 0.2835, 0.4961])`。
- en: 'Your PyTorch superpowers are growing: you can now build, train, and evaluate
    both regression and classification neural nets. The next step is to learn how
    to fine-tune the model hyperparameters.'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 你的 PyTorch 超能力正在增长：你现在可以构建、训练和评估回归和分类神经网络。下一步是学习如何微调模型超参数。
- en: Fine-Tuning Neural Network Hyperparameters with Optuna
  id: totrans-307
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Optuna 微调神经网络超参数
- en: We discussed how to manually pick reasonable values for your model’s hyperparameters
    in [Chapter 9](ch09.html#ann_chapter), but what if you want to go further and
    automatically search for good hyperparameter values? One option is to convert
    your PyTorch model to a Scikit-Learn estimator, either by writing your own custom
    estimator class or by using a wrapper library such as Skorch ([*https://skorch.readthedocs.io*](https://skorch.readthedocs.io)),
    and then use `GridSearchCV` or `RandomizedSearchCV` to fine-tune the hyperparameters,
    as you did in [Chapter 2](ch02.html#project_chapter). However, you will usually
    get better results by using a dedicated fine-tuning library such as Optuna ([*https://optuna.org*](https://optuna.org)),
    Ray Tune ([*https://docs.ray.io*](https://docs.ray.io)), or Hyperopt ([*https://hyperopt.github.io/hyperopt*](https://hyperopt.github.io/hyperopt)).
    These libraries offer several powerful tuning strategies, and they’re highly customizable.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 [第 9 章](ch09.html#ann_chapter) 中讨论了如何手动选择合理的模型超参数值，但如果你想要更进一步并自动搜索好的超参数值呢？一个选择是将你的
    PyTorch 模型转换为 Scikit-Learn 估算器，无论是通过编写自己的自定义估算器类，还是通过使用 Skorch 这样的包装库（[*https://skorch.readthedocs.io*](https://skorch.readthedocs.io)），然后使用
    `GridSearchCV` 或 `RandomizedSearchCV` 来微调超参数，就像你在 [第 2 章](ch02.html#project_chapter)
    中所做的那样。然而，通常使用像 Optuna ([*https://optuna.org*](https://optuna.org))、Ray Tune ([*https://docs.ray.io*](https://docs.ray.io))
    或 Hyperopt ([*https://hyperopt.github.io/hyperopt*](https://hyperopt.github.io/hyperopt))
    这样的专用微调库会得到更好的结果。这些库提供了几种强大的调优策略，并且它们高度可定制。
- en: 'Let’s look at an example using Optuna. It is not preinstalled on Colab, so
    we need to install it using `%pip install optuna` (if you prefer to run the code
    locally, please follow the installation instructions at [*https://homl.info/install-p*](https://homl.info/install-p)).
    Let’s tune the learning rate and the number of neurons in the hidden layers (for
    simplicity, we will use the same number of neurons in both hidden layers). First,
    we need to define a function that Optuna will call many times to perform hyperparameter
    tuning: this function must take a `Trial` object and use it to ask Optuna for
    hyperparameter values, and then use these hyperparameter values to build and train
    a model. Finally, the function must evaluate the model (typically on the validation
    set) and return the metric:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过 Optuna 的一个示例来了解一下。它在 Colab 上没有预安装，所以我们需要使用 `%pip install optuna` 来安装它（如果你更喜欢在本地运行代码，请按照
    [*https://homl.info/install-p*](https://homl.info/install-p) 上的安装说明进行操作）。现在，让我们调整学习率和隐藏层中的神经元数量（为了简单起见，我们将使用相同数量的神经元在两个隐藏层中）。首先，我们需要定义一个函数，Optuna
    将多次调用该函数以执行超参数调整：这个函数必须接受一个 `Trial` 对象，并使用它来请求 Optuna 的超参数值，然后使用这些超参数值来构建和训练一个模型。最后，该函数必须评估模型（通常在验证集上）并返回指标：
- en: '[PRE70]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'The `suggest_float()` and `suggest_int()` methods let us ask Optuna for a good
    hyperparameter value in a given range (Optuna also provides a `suggest_categorical()`
    method). For the `learning_rate` hyperparameter, we ask for a value between 10^(–5)
    and 10^(–1), and since we don’t know what the optimal scale is, we add `log=True`:
    this will make Optuna sample values from a log distribution, which makes it explore
    all possible scales. If we used the default uniform distribution instead, Optuna
    would be very unlikely to explore tiny values.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '`suggest_float()` 和 `suggest_int()` 方法让我们请求 Optuna 在给定范围内提供一个好的超参数值（Optuna
    还提供了一个 `suggest_categorical()` 方法）。对于 `learning_rate` 超参数，我们请求一个介于 10^(–5) 和 10^(–1)
    之间的值，由于我们不知道最优的尺度是多少，我们添加 `log=True`：这将使 Optuna 从对数分布中采样值，这使得它能够探索所有可能的尺度。如果我们使用默认的均匀分布，Optuna
    很可能不会探索很小的值。'
- en: 'To start hyperparameter tuning, we create a `Study` object and call its `optimize()`
    method, passing it the objective function we just defined, as well as the number
    of trials to run (i.e., the number of times Optuna should call the objective function).
    Since our objective function returns a score—higher is better—we set `direction="maximize"`
    when creating the study (by default, Optuna tries to *minimize* the objective).
    To ensure reproducibility, we also set PyTorch’s random seed, as well as the random
    seed used by Optuna’s sampler:'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始超参数调整，我们创建一个 `Study` 对象并调用它的 `optimize()` 方法，将我们刚刚定义的目标函数以及要运行的试验次数（即 Optuna
    应该调用目标函数的次数）传递给它。由于我们的目标函数返回一个分数——越高越好——我们在创建研究时将 `direction="maximize"` 设置为（默认情况下，Optuna
    尝试 *最小化* 目标）。为了确保可重复性，我们还设置了 PyTorch 的随机种子，以及 Optuna 的采样器使用的随机种子：
- en: '[PRE71]'
  id: totrans-313
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'By default, Optuna uses the *Tree-structured Parzen Estimator* (TPE) algorithm
    to optimize the hyperparameters: this is a sequential model-based optimization
    algorithm, meaning it learns from past results to better select promising hyperparameters.
    In other words, Optuna starts with random hyperparameter values, but it progressively
    focuses its search on the most promising regions of the hyperparameter space.
    This allows Optuna to find much better hyperparameters than random search in the
    same amount of time.'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Optuna 使用 *树结构帕累托估计器*（TPE）算法来优化超参数：这是一个基于序列模型的优化算法，意味着它从过去的结果中学习以更好地选择有希望的超参数。换句话说，Optuna
    以随机的超参数值开始，但它逐渐将搜索重点放在超参数空间中最有希望的区域内。这使得 Optuna 能够在相同的时间内找到比随机搜索更好的超参数。
- en: Tip
  id: totrans-315
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: You can add more hyperparameters to the search space, such as the batch size,
    the type of optimizer, the number of hidden layers, or the type of activation
    function, but remember that the search space will grow exponentially as you add
    more hyperparameters, so make sure it’s worth the extra search time and compute.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以向搜索空间添加更多的超参数，例如批量大小、优化器的类型、隐藏层的数量或激活函数的类型，但请记住，随着你添加更多的超参数，搜索空间将以指数级增长，所以请确保这值得额外的搜索时间和计算。
- en: 'Once Optuna is done, you can look at the best hyperparameters it found, as
    well as the corresponding validation accuracy:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 Optuna 完成，你可以查看它找到的最佳超参数，以及相应的验证准确率：
- en: '[PRE72]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: This is slightly better than the performance we got earlier. If you increase
    `n_trials` up to 50 or more, you will get much better results, but of course it
    will take hours to run. You can also just run `optimize()` repeatedly and stop
    once you are happy with the performance.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 这比我们之前得到的表现略好。如果你将`n_trials`增加到50或更多，你会得到更好的结果，但当然这需要数小时才能运行。你也可以反复运行`optimize()`，直到你对性能满意为止。
- en: Optuna can also run trials in parallel across multiple machines, which can offer
    a near linear speed boost. For this, you will need to set up a SQL database (e.g.,
    SQLite or PostgreSQL), and set the `storage` parameter of the `create_study()`
    function to point to that database. You also need to set the study’s name via
    the `study_name` parameter, and set `load_if_exists=True`. After that, you can
    copy your hyperparameter tuning script to multiple machines, and run it on each
    one (if you are using random seeds, make sure they are different on each machine).
    The scripts will work in parallel, reading and writing the trial results to the
    database. This has the additional benefit of keeping a full log of all your experiment
    results.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: Optuna还可以在多台机器上并行运行试验，这可以提供接近线性的速度提升。为此，你需要设置一个SQL数据库（例如，SQLite或PostgreSQL），并将`create_study()`函数的`storage`参数设置为指向该数据库。你还需要通过`study_name`参数设置研究的名称，并将`load_if_exists=True`。之后，你可以将你的超参数调整脚本复制到多台机器上，并在每台机器上运行它（如果你使用随机种子，确保每台机器上的种子都不同）。这些脚本将并行工作，将试验结果读取和写入数据库。这还有一个额外的优点，就是可以保留所有实验结果的完整日志。
- en: 'You may have noticed that we assumed that the `objective()` function had direct
    access to the training set and validation, presumably via global variables. In
    general, it’s much cleaner to pass them as extra arguments to the `objective()`
    function, for example, like this:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，我们假设`objective()`函数可以直接访问训练集和验证集，这可能是通过全局变量实现的。通常，将它们作为额外的参数传递给`objective()`函数会更干净，例如，像这样：
- en: '[PRE73]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: 'To set the extra arguments (the dataset loaders in this case), we just create
    a lambda function when needed and pass it to the `optimize()` method. Alternatively,
    you can use the `functools.partial()` function which creates a thin wrapper function
    around the given callable to provide default values for any number of arguments:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 要设置额外的参数（在这个例子中是数据集加载器），我们只需在需要时创建一个lambda函数，并将其传递给`optimize()`方法。或者，你可以使用`functools.partial()`函数，它会在给定的可调用对象周围创建一个薄包装函数，为任意数量的参数提供默认值：
- en: '[PRE74]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'It’s often possible to quickly tell that a trial is absolutely terrible: for
    example, when the loss shoots up during the first epoch, or when the model barely
    improves during the first few epochs. In such a case, it’s a good idea to interrupt
    training early to avoid wasting time and compute. You can simply return the model’s
    current validation accuracy and hope that Optuna will learn to avoid this region
    of hyperparameter space. Alternatively, you can interrupt training by raising
    the `optuna.TrialPruned` exception: this tells Optuna to ignore this trial altogether.
    In many cases, this leads to a more efficient search because it avoids polluting
    Optuna’s search algorithm with many noisy model evaluations.'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 通常可以很快地判断一个试验是否绝对糟糕：例如，当损失在第一个epoch期间急剧上升，或者当模型在前几个epoch中几乎没有改进时。在这种情况下，提前中断训练以避免浪费时间是很明智的。你可以简单地返回模型当前的验证准确率，并希望Optuna学会避免这个超参数空间区域。或者，你可以通过引发`optuna.TrialPruned`异常来中断训练：这告诉Optuna完全忽略这个试验。在许多情况下，这会导致更有效的搜索，因为它避免了将许多噪声模型评估污染Optuna的搜索算法。
- en: 'Optuna comes with several `Pruner` classes that can detect and prune bad trials.
    For example, the `MedianPruner` will prune trials whose performance is below the
    median performance, at regular intervals during training. It starts pruning after
    a given number of trials have completed, controlled by `n_startup_trials` (5 by
    default). For each trial after that, it lets training start for a few epochs,
    controlled by `n_warmup_steps` (0 by default); then every few epochs (controlled
    by `interval_steps`), it ensures that the model’s performance is better than the
    median performance at the same epoch in past trials. To use this pruner, create
    an instance and pass it to the `create_study()` method:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: Optuna附带几个`Pruner`类，可以检测并修剪不良的试验。例如，`MedianPruner`将在训练期间定期修剪性能低于中位数的试验。它将在完成指定数量的试验后开始修剪，由`n_startup_trials`（默认为5）控制。在此之后的每个试验，它都会让训练开始几个epoch，由`n_warmup_steps`（默认为0）控制；然后每隔几个epoch（由`interval_steps`控制），它确保模型的性能优于过去试验中同一epoch的中位数性能。要使用此修剪器，创建一个实例并将其传递给`create_study()`方法：
- en: '[PRE75]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Then in the `objective()` function, add the following code so it runs after
    each epoch:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 然后在`objective()`函数中，添加以下代码以便在每个epoch之后运行：
- en: '[PRE76]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: The `report()` method informs Optuna of the current validation accuracy and
    epoch, so it can determine whether the trial should be pruned. If `trial.should_prune()`
    returns `True`, we raise a `TrialPruned` exception.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: '`report()`方法通知Optuna当前的验证准确率和epoch，以便它可以确定试验是否应该被修剪。如果`trial.should_prune()`返回`True`，我们将引发`TrialPruned`异常。'
- en: Tip
  id: totrans-331
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Optuna has many other features well worth exploring, such as visualization tools,
    persistence tools for trial results and other artifacts, a dashboard for human-in-the-loop
    optimization, and many other algorithms for hyperparameter search and trial pruning.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: Optuna还有许多其他值得探索的功能，例如可视化工具、试验结果和其他艺术品的持久化工具、人机交互优化仪表板，以及许多其他用于超参数搜索和试验修剪的算法。
- en: 'Once you are happy with the hyperparameters, you can train the model on the
    full training set (i.e., the training set plus the validation set), then evaluate
    it on the test set. Hopefully, it will perform great! If it does, you will want
    to save the model, then load it and use it in production: that’s the final topic
    of this chapter.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你对超参数满意，你就可以在完整的训练集（即训练集加上验证集）上训练模型，然后在其上评估它。希望它表现良好！如果它确实表现良好，你将想要保存模型，然后加载它并在生产中使用：这是本章的最后一个主题。
- en: Saving and Loading PyTorch Models
  id: totrans-334
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保存和加载PyTorch模型
- en: 'The simplest way to save a PyTorch model is to use the `torch.save()` method,
    passing it the model and the filepath. The model object is serialized using Python’s
    `pickle` module (which can convert objects into a sequence of bytes), then the
    result is compressed (zip) and saved to disk. The convention is to use the `.pt`
    or `.pth` extension for PyTorch files:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 保存PyTorch模型最简单的方法是使用`torch.save()`方法，传递模型和文件路径。模型对象使用Python的`pickle`模块进行序列化（可以将对象转换为字节序列），然后结果被压缩（zip）并保存到磁盘。惯例是使用`.pt`或`.pth`扩展名保存PyTorch文件：
- en: '[PRE77]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'Simple! Now you can load the model (e.g., in your production code) just as
    easily:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 简单！现在你可以像这样轻松地加载模型（例如，在你的生产代码中）：
- en: '[PRE78]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: Warning
  id: totrans-339
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: If your model uses any custom functions or classes (e.g., `ImageClassifier`),
    then `torch.save()` only saves references to them, not the code itself. Therefore
    you must ensure that any custom code is loaded in the Python environment before
    calling `torch.load()`. Also make sure to use the same version of the code to
    avoid any mismatch issues.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的模型使用了任何自定义函数或类（例如，`ImageClassifier`），则`torch.save()`只保存它们的引用，而不是代码本身。因此，你必须确保在调用`torch.load()`之前在Python环境中加载任何自定义代码。还请确保使用相同的代码版本，以避免任何不匹配问题。
- en: 'Setting `weights_only=False` ensures that the whole model object is loaded
    rather than just the model parameters. Then you can use the loaded model for inference.
    Don’t forget to switch to evaluation mode first using the `eval()` method:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 将`weights_only=False`设置为`False`确保加载整个模型对象，而不仅仅是模型参数。然后你可以使用加载的模型进行推理。别忘了首先使用`eval()`方法切换到评估模式：
- en: '[PRE79]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'This is nice and easy, but unfortunately this approach has some very serious
    drawbacks:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 这很简单，也很容易，但不幸的是，这种方法有一些非常严重的缺点：
- en: 'Firstly, pickle’s serialization format is notoriously insecure. While `torch.save()`
    doesn’t save custom code, the pickle format supports it, so a hacker could inject
    malicious code in a saved PyTorch model: this code would be run automatically
    by the `pickle` module when the model is loaded. So always make sure you fully
    trust the model’s source before you load it this way.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，pickle 的序列化格式臭名昭著地不安全。虽然 `torch.save()` 不会保存自定义代码，但 pickle 格式支持它，因此黑客可以在保存的
    PyTorch 模型中注入恶意代码：当模型被加载时，这段代码会被 `pickle` 模块自动运行。因此，在以这种方式加载模型之前，请务必确保您完全信任模型的来源。
- en: Second, pickle is somewhat brittle. It can vary depending on the Python version
    (e.g., there were big changes between Python 3.7 and 3.8), and it saves specific
    filepaths to locate code, which can break if the loading environment has a different
    folder structure.
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，pickle 有点脆弱。它可能取决于 Python 版本（例如，Python 3.7 和 3.8 之间有重大变化），并且它保存特定的文件路径来定位代码，如果加载环境有不同的文件夹结构，这可能会导致破坏。
- en: 'To avoid these issues, it is recommended to save and load the model weights
    only, rather than the full model object:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免这些问题，建议只保存和加载模型权重，而不是完整的模型对象：
- en: '[PRE80]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'The state dictionary returned by the `state_dict()` method is just a Python
    `OrderedDict` containing an entry for each parameter returned by the `named_parameters()`
    method. It also contains buffers, if the model has any: a buffer is just a regular
    tensor that was registered with the model (or any of its submodules) using the
    `register_buffer()` method. Buffers hold extra data that needs to be stored along
    with the model, but that is not a model parameter. We will see an example in [Chapter 11](ch11.html#deep_chapter)
    with the batch-norm layer.'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: '`state_dict()` 方法返回的状态字典只是一个包含每个由 `named_parameters()` 方法返回的参数条目的 Python `OrderedDict`。如果模型有任何缓冲区，它也包含缓冲区：缓冲区只是一个使用
    `register_buffer()` 方法注册到模型（或其任何子模块）的常规张量。缓冲区持有需要与模型一起存储的额外数据，但不是模型参数。我们将在 [第
    11 章](ch11.html#deep_chapter) 中的批归一化层示例中看到。'
- en: 'To load these weights, we must first create a model with the exact same structure,
    then load the weights using `torch.load()` with `weights_only=True`, and finally
    call the model’s `load_state_dict()` method with the loaded weights:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载这些权重，我们首先必须创建一个具有完全相同结构的模型，然后使用 `torch.load()` 并将 `weights_only=True` 加载权重，最后调用模型的
    `load_state_dict()` 方法并传入加载的权重：
- en: '[PRE81]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: 'The saved model contains only data, and the `load()` function makes sure of
    that, so this is safe, and also much less likely to break between Python versions
    or to cause any deployment issue. However, it only works if you are able to create
    the exact same model architecture before loading the state dictionary. For this,
    you need to know the number of layers, the number of neurons per layer, and so
    on. It’s a good idea to save this information along with the state dictionary:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 保存的模型只包含数据，`load()` 函数确保了这一点，因此这是安全的，并且也远不太可能在 Python 版本之间出现破坏，或者导致任何部署问题。然而，这仅在你能够在加载状态字典之前创建出完全相同的模型架构时才有效。为此，您需要知道层数、每层的神经元数量等等。将此信息与状态字典一起保存是个好主意：
- en: '[PRE82]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: 'You can then load this dictionary, construct the model based on the saved hyperparameters,
    and load the state dictionary into this model:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以加载这个字典，根据保存的超参数构建模型，并将状态字典加载到这个模型中：
- en: '[PRE83]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: If you want to be able to continue training where it left off, you will also
    need to save the optimizer’s state dictionary, its hyperparameters, and any other
    training information you may need, such as the current epoch and the loss history.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想能够从上次停止的地方继续训练，您还需要保存优化器的状态字典、其超参数以及您可能需要的任何其他训练信息，例如当前周期和损失历史。
- en: Tip
  id: totrans-356
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: The `safetensors` library by Hugging Face is another popular way to save model
    weights safely.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face 的 `safetensors` 库是另一种流行的安全保存模型权重的途径。
- en: 'There is yet another way to save and load your model: by first converting it
    to TorchScript. This also makes it possible to speed up your model’s inference.'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 还有另一种保存和加载模型的方法：首先将其转换为 TorchScript。这也有助于加快模型推理的速度。
- en: Compiling and Optimizing a PyTorch Model
  id: totrans-359
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 编译和优化 PyTorch 模型
- en: 'PyTorch comes with a very nice feature: it can automatically convert your model’s
    code to *TorchScript*, which you can think of as a statically typed subset of
    Python. There are two main benefits:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 提供了一个非常棒的功能：它可以自动将您的模型代码转换为 *TorchScript*，您可以将它视为 Python 的一个静态类型子集。有两个主要好处：
- en: First, TorchScript code can be compiled and optimized to produce significantly
    faster models. For example, multiple operations can often be fused into a single,
    more efficient operation. Operations on constants (e.g., 2 * 3) can be replaced
    with their result (e.g., 6); this is called *constant folding*. Unused code can
    be pruned, and so on.
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，TorchScript 代码可以被编译和优化，以产生显著更快的模型。例如，多个操作通常可以融合成一个更有效的单个操作。对常量的操作（例如，2 *
    3）可以用其结果（例如，6）替换；这称为 *常量折叠*。未使用的代码可以被剪枝，等等。
- en: Secondly, TorchScript can be serialized, saved to disk, and then loaded and
    executed in Python or in a C++ environment using the LibTorch library. This makes
    it possible to run PyTorch models on a wide range of devices, including embedded
    devices.
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，TorchScript 可以被序列化，保存到磁盘上，然后使用 LibTorch 库在 Python 或 C++ 环境中加载和执行。这使得在包括嵌入式设备在内的广泛设备上运行
    PyTorch 模型成为可能。
- en: 'There are two ways to convert a PyTorch model to TorchScript. The first way
    is called *tracing*. PyTorch just runs your model with some sample data, logs
    every operation that takes place, and then converts this log to TorchScript. This
    is done using the `torch.jit.trace()` function:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 将 PyTorch 模型转换为 TorchScript 有两种方法。第一种方法称为 *跟踪*。PyTorch 只用一些样本数据运行你的模型，记录发生的每个操作，然后将此日志转换为
    TorchScript。这是通过使用 `torch.jit.trace()` 函数来完成的：
- en: '[PRE84]'
  id: totrans-364
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: This generally works well with static models whose `forward()` method doesn’t
    use conditionals or loops. However, if you try to trace a model that includes
    an `if` or `match` statement, then only the branch that is actually executed will
    be captured by TorchScript, which is generally not what you want. Similarly, if
    you use tracing with a model that contains a loop, then the TorchScript code will
    contain one copy of the operations within that loop for each iteration that was
    actually executed. Again, not what you generally want.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常适用于 `forward()` 方法不使用条件或循环的静态模型。然而，如果你尝试跟踪包含 `if` 或 `match` 语句的模型，那么只有实际执行的分支将被
    TorchScript 捕获，这通常不是你想要的。同样，如果你使用跟踪一个包含循环的模型，那么 TorchScript 代码将包含每个实际执行的迭代中该循环内的操作的一个副本。这也不是你通常想要的。
- en: 'For such dynamic models, you will probably want to try another approach named
    *scripting*. In this case, PyTorch actually parses your Python code directly and
    converts it to TorchScript. This method supports `if` statements and `while` loops
    properly, as long as the conditions are tensors. It also supports `for` loops
    when iterating over tensors. However, it only works on a subset of Python. For
    example, you cannot use global variables, Python generators (`yield`), complex
    list comprehensions, variable length function arguments (`*args` or `**kwargs`),
    or `match` statements. Moreover, types must be fixed (a function cannot return
    an integer in some cases and a float in others), and you can only call other functions
    if they also respect these rules, so no standard library, no third-party libraries,
    etc. (see the documentation for the full list of constraints). This sounds daunting,
    but for most real-world models, these rules are actually not too hard to respect,
    and you can save your model like this:'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这样的动态模型，你可能想尝试另一种名为 *脚本化* 的方法。在这种情况下，PyTorch 实际上直接解析你的 Python 代码并将其转换为 TorchScript。此方法正确支持
    `if` 语句和 `while` 循环，只要条件是张量。它还支持在迭代张量时使用 `for` 循环。然而，它只适用于 Python 的一个子集。例如，你不能使用全局变量，Python
    生成器 (`yield`)，复杂的列表推导式，可变长度函数参数 (`*args` 或 `**kwargs`)，或 `match` 语句。此外，类型必须是固定的（在某些情况下，一个函数不能返回整数，而在其他情况下返回浮点数），并且只有当其他函数也遵守这些规则时，你才能调用其他函数，因此没有标准库，没有第三方库等。（有关约束条件的完整列表，请参阅文档）。这听起来可能很令人畏惧，但对于大多数现实世界的模型，这些规则实际上并不难遵守，你可以这样保存你的模型：
- en: '[PRE85]'
  id: totrans-367
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: 'Regardless of whether you use tracing or scripting to produce your TorchScript
    model, you can then further optimize it:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你使用跟踪还是脚本生成你的 TorchScript 模型，你都可以进一步优化它：
- en: '[PRE86]'
  id: totrans-369
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: TorchScript models can only be used for inference, not for training, since the
    TorchScript environment doesn’t support gradient tracking or parameter updates.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 TorchScript 环境不支持梯度跟踪或参数更新，TorchScript 模型只能用于推理，而不能用于训练。
- en: 'Finally, you can save a TorchScript model using its `save()` method:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你可以使用其 `save()` 方法保存一个 TorchScript 模型：
- en: '[PRE87]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'And then load it using the `torch.jit.load()` function:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 然后使用 `torch.jit.load()` 函数加载它：
- en: '[PRE88]'
  id: totrans-374
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: 'One important caveat: TorchScript is no longer under active development—bugs
    are fixed but no new features are added. It still works fine and it remains one
    of the best ways to run your PyTorch models in a C++ environment,⁠^([13](ch10.html#id2420))
    but since the release of PyTorch 2.0 in March 2023, the PyTorch team has been
    focusing its efforts on a new set of compilation tools centered around the `torch.compile()`
    function, which you can use very easily:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的注意事项：TorchScript不再处于积极开发状态——错误被修复，但没有添加新功能。它仍然运行良好，并且仍然是你在C++环境中运行PyTorch模型的最佳方式之一⁠^([13](ch10.html#id2420))，但自2023年3月PyTorch
    2.0发布以来，PyTorch团队已经将精力集中在围绕`torch.compile()`函数的新编译工具集上，你可以非常容易地使用它：
- en: '[PRE89]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: 'The resulting model can now be used normally, and it will automatically be
    compiled and optimized when you use it. This is called Just-In-Time (JIT) compilation,
    as opposed to Ahead-Of-Time (AOT) compilation. Under the hood, `torch.compile()`
    relies on *TorchDynamo* (or *Dynamo* for short) which hooks directly into Python
    bytecode to capture the model’s computation graph at inference time. Having access
    to the bytecode allows Dynamo to efficiently and reliably capture the computation
    graph, properly handling conditionals and loops, while also benefiting from dynamic
    information that can be used to better optimize the model. The actual compilation
    and optimization is performed by default by a backend component named *TorchInductor*,
    which in turn relies on the Triton language to generate highly efficient GPU code
    (Nvidia only), or on the OpenMP API for CPU optimization. PyTorch 2.x offers a
    few other optimization backends, including the XLA backend for Google’s TPU devices:
    just set `device="xla"` when calling `torch.compile()`.'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的模型现在可以正常使用，当你使用它时，它将自动编译和优化。这被称为即时（JIT）编译，与提前（AOT）编译相对。在底层，`torch.compile()`依赖于*TorchDynamo*（或简称*Dynamo*），它直接钩入Python字节码以在推理时捕获模型的计算图。访问字节码允许Dynamo高效且可靠地捕获计算图，正确处理条件语句和循环，同时还能从可用于更好地优化模型动态信息中受益。实际的编译和优化默认由名为*TorchInductor*的后端组件执行，它反过来依赖于Triton语言生成高度高效的GPU代码（仅限Nvidia），或依赖于OpenMP
    API进行CPU优化。PyTorch 2.x提供了一些其他优化后端，包括用于Google TPU设备的XLA后端：在调用`torch.compile()`时只需设置`device="xla"`即可。
- en: 'With that, you now have all the tools you need to start building and training
    complex and efficient neural networks. I hope you enjoyed this introduction to
    PyTorch! We covered a lot, but the adventure is only beginning: in the next chapter
    we will discuss techniques to train very deep nets. After that, we will dive into
    other popular neural network architectures: convolutional neural networks for
    image processing, recurrent neural networks for sequential data, transformers
    for text (and much more), autoencoders for representation learning, and generative
    adversarial networks and diffusion models to generate data.⁠^([14](ch10.html#id2429))
    Then we will visit reinforcement learning to train autonomous agents, and finally,
    we will learn more about deploying and optimizing your PyTorch models. Let’s go!'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你已经拥有了开始构建和训练复杂高效神经网络所需的所有工具。我希望你喜欢这个PyTorch的入门介绍！我们涵盖了很多内容，但冒险才刚刚开始：在下一章中，我们将讨论训练非常深的网络的技术。之后，我们将深入研究其他流行的神经网络架构：用于图像处理的卷积神经网络，用于序列数据的循环神经网络，用于文本（以及更多）的转换器，用于表示学习的自编码器，以及用于生成数据的生成对抗网络和扩散模型⁠^([14](ch10.html#id2429))。然后我们将探讨强化学习以训练自主代理，最后，我们将学习更多关于部署和优化你的PyTorch模型的知识。让我们开始吧！
- en: Exercises
  id: totrans-379
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 练习
- en: PyTorch is similar to NumPy is many ways, but it offers some extra features.
    Can you name the most important ones?
  id: totrans-380
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PyTorch在许多方面与NumPy相似，但它提供了一些额外的功能。你能说出最重要的几个吗？
- en: What is the difference between `torch.exp()` and `torch.exp_()`, or between
    `torch.relu()` and `torch.relu_()`?
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`torch.exp()`和`torch.exp_()`，或者`torch.relu()`和`torch.relu_()`之间的区别是什么？'
- en: What are two ways to create a new tensor on the GPU?
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在GPU上创建一个新的张量有两种方法？
- en: What are three ways to perform tensor computations without using autograd?
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 有三种方法可以在不使用autograd的情况下执行张量计算？
- en: Will the following code cause a `RuntimeError`? What if you replace the second
    line with `z = t.cos_().exp()`? And what if you replace it with `z = t.exp().cos_()`?
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下代码会导致`RuntimeError`吗？如果你将第二行替换为`z = t.cos_().exp()`会怎样？如果你将其替换为`z = t.exp().cos_()`又会怎样？
- en: '[PRE90]'
  id: totrans-385
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE90]'
- en: How about the following code, will it cause an error? And what if you replace
    the third line with `w = v.cos_() * v.sin()`? Will `w` have the same value in
    both cases?
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下代码会导致错误吗？如果你将第三行替换为`w = v.cos_() * v.sin()`，两种情况下`w`的值会相同吗？
- en: '[PRE91]'
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE91]'
- en: Suppose you create a `Linear(100, 200)` module. How many neurons does it have?
    What is the shape of is `weight` and `bias` parameters? What input shape does
    it expect? What output shape does it produce?
  id: totrans-388
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设你创建了一个`Linear(100, 200)`模块。它有多少个神经元？它的`weight`和`bias`参数的形状是什么？它期望什么输入形状？它产生什么输出形状？
- en: What are the main steps of a PyTorch training loop?
  id: totrans-389
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PyTorch训练循环的主要步骤是什么？
- en: Why is it recommended to create the optimizer *after* the model is moved to
    the GPU?
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么建议在模型移动到GPU之后创建优化器？
- en: What `DataLoader` options should you generally set to speed up training when
    using a GPU?
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用GPU时，你应该通常设置哪些`DataLoader`选项来加快训练速度？
- en: What are the main classification losses provided by PyTorch, and when should
    you use each of them?
  id: totrans-392
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PyTorch提供了哪些主要的分类损失，你应在何时使用它们？
- en: Why is it important to call `model.train()` before training and `model.eval()`
    before evaluation?
  id: totrans-393
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么在训练之前调用`model.train()`和在评估之前调用`model.eval()`很重要？
- en: What is the difference between `torch.jit.trace()` and `torch.jit.script()`?
  id: totrans-394
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`torch.jit.trace()`和`torch.jit.script()`之间的区别是什么？'
- en: Use autograd to find the gradient vector of f(*x*, *y*) = sin(*x*² *y*) at the
    point (*x*, *y*) = (1.2, 3.4).
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用autograd找到函数f(*x*, *y*) = sin(*x*² *y*)在点(*x*, *y*) = (1.2, 3.4)处的梯度向量。
- en: Create a custom `Dense` module that replicates the functionality of an `nn.Linear`
    module followed by an `nn.ReLU` module. Try implementing it first using the `nn.Linear`
    and `nn.ReLU` modules, and then reimplement it using `nn.Parameter` and the `relu()`
    function.
  id: totrans-396
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个自定义的`Dense`模块，它复制了`nn.Linear`模块后跟`nn.ReLU`模块的功能。首先尝试使用`nn.Linear`和`nn.ReLU`模块实现它，然后使用`nn.Parameter`和`relu()`函数重新实现它。
- en: 'Build and train a classification MLP on the CoverType dataset:'
  id: totrans-397
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在CoverType数据集上构建和训练一个分类MLP：
- en: Load the dataset using `sklearn.datasets.fetch_covtype()` and create a custom
    PyTorch `Dataset` for this data.
  id: totrans-398
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`sklearn.datasets.fetch_covtype()`加载数据集，并为这些数据创建一个自定义的PyTorch `Dataset`。
- en: Create data loaders for training, validation, and testing.
  id: totrans-399
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建用于训练、验证和测试的数据加载器。
- en: Build a custom MLP module to tackle this classification task. You can optionally
    use the custom `Dense` module from the previous exercise.
  id: totrans-400
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 构建一个自定义的MLP模块来处理这个分类任务。你可以选择使用之前练习中的自定义`Dense`模块。
- en: Train this model on the GPU, and try to reach 93% accuracy on the test set.
    For this, you will likely have to perform hyperparameter search to find the right
    number of layers and neurons per layer, a good learning rate and batch size, and
    so on. You can optionally use Optuna for this.
  id: totrans-401
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在GPU上训练这个模型，并尝试在测试集上达到93%的准确率。为此，你可能需要进行超参数搜索，以找到正确的层数和每层的神经元数量、良好的学习率和批量大小等。你可以选择使用Optuna来完成这项工作。
- en: Solutions to these exercises are available at the end of this chapter’s notebook,
    at [*https://homl.info/colab-p*](https://homl.info/colab-p).
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 这些练习的解决方案可以在本章笔记本的末尾找到，在[*https://homl.info/colab-p*](https://homl.info/colab-p)。
- en: ^([1](ch10.html#id2228-marker)) To be fair, most of TensorFlow’s usability issues
    were fixed in version 2, and Google also launched JAX, which is well designed
    and extremely fast, so PyTorch still has some healthy competition. The good news
    is that the APIs of all these libraries have converged quite a bit, so switching
    from one to the other is much easier than it used to be.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch10.html#id2228-marker)) 公平地说，TensorFlow的大多数可用性问题都在版本2中得到了解决，而且谷歌还推出了JAX，这是一个设计良好且速度极快的工具，因此PyTorch仍然有一些健康的竞争。好消息是，所有这些库的API已经相当一致，因此从一种切换到另一种要容易得多。
- en: '^([2](ch10.html#id2229-marker)) There are things called tensors in mathematics
    and physics, but ML tensors are simpler: they’re really just multidimensional
    arrays for numerical computations, plus a few extra features.'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch10.html#id2229-marker)) 在数学和物理学中存在称为张量的东西，但ML张量更简单：它们实际上是用于数值计算的多元数组，加上一些额外的功能。
- en: ^([3](ch10.html#id2249-marker)) CUDA is Nvidia’s proprietary platform to run
    code on its CUDA-compatible GPUs, and cuDNN is a library built on CUDA to accelerate
    various deep neural network architectures.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: ^([3](ch10.html#id2249-marker)) CUDA是Nvidia为其兼容CUDA的GPU运行代码的专有平台，cuDNN是基于CUDA构建的库，用于加速各种深度神经网络架构。
- en: ^([4](ch10.html#id2258-marker)) The `%timeit` magic command only works in Jupyter
    notebooks and Colab, as well as in the iPython shell; in a regular Python shell
    or program, you can use the `timeit.timeit()` function instead.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: ^([4](ch10.html#id2258-marker)) `%timeit` 魔法命令仅在 Jupyter 笔记本、Colab 以及 iPython
    shell 中有效；在常规 Python shell 或程序中，您可以使用 `timeit.timeit()` 函数代替。
- en: '^([5](ch10.html#id2274-marker)) For example, since the derivative of exp(*x*)
    is equal to exp(*x*), it makes a lot of sense to store the output of this operation
    in the computation graph during the forward pass, then use this output during
    the backward pass to get the gradients: no need to store additional data, and
    no need to recompute exp(*x*).'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: ^([5](ch10.html#id2274-marker)) 例如，由于 exp(*x*) 的导数等于 exp(*x*)，在正向传播期间将这个操作的输出保存在计算图中是非常有意义的，然后在反向传播期间使用这个输出来获取梯度：无需存储额外的数据，也无需重新计算
    exp(*x*)。
- en: ^([6](ch10.html#id2275-marker)) For example, the derivative of abs(*x*) is –1
    when *x* < 0 and +1 when *x* > 0\. If this operation saved its output in the computation
    graph, the backward pass would be unable to know whether *x* was positive or negative
    (since abs(*x*) is always positive), so it wouldn’t be able to compute the gradients.
    This is why this operation must save its input instead.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: ^([6](ch10.html#id2275-marker)) 例如，当 *x* < 0 时，abs(*x*) 的导数是 -1，而当 *x* > 0 时，导数是
    +1。如果这个操作将输出保存在计算图中，反向传播将无法知道 *x* 是正数还是负数（因为 abs(*x*) 总是正数），因此它将无法计算梯度。这就是为什么这个操作必须保存其输入的原因。
- en: ^([7](ch10.html#id2276-marker)) For example, the derivative of floor(*x*) is
    always zero (at least for noninteger inputs), so the `floor()` operation just
    saves the shape of the inputs during the forward pass, then during the backward
    pass it produces gradients of the same shape but full of zeros. For integer inputs,
    autograd also returns zeros instead of NaN.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: ^([7](ch10.html#id2276-marker)) 例如，floor(*x*) 的导数始终为零（至少对于非整数输入），因此 `floor()`
    操作在正向传播期间只保存输入的形状，然后在反向传播期间产生具有相同形状但充满零的梯度。对于整数输入，autograd 也返回零而不是 NaN。
- en: ^([8](ch10.html#id2281-marker)) Column vectors (shape [*m*, 1]) and row vectors
    (shape [1, *m*]) are often preferred over 1D vectors (shape [*m*]) in machine
    learning, as they avoid ambiguity in some operations, such as matrix multiplication
    or broadcasting, and they make the code more consistent whether there’s just one
    feature or more.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: ^([8](ch10.html#id2281-marker)) 在机器学习中，列向量（形状 [*m*, 1]）和行向量（形状 [1, *m*]）通常比
    1D 向量（形状 [*m*]）更受欢迎，因为它们避免了某些操作中的歧义，例如矩阵乘法或广播，并且使代码在只有一个特征或更多特征时更加一致。
- en: ^([9](ch10.html#id2282-marker)) Just like in NumPy, the `reshape()` method allows
    you to specify –1 for one of the dimensions. This dimension’s size is automatically
    calculated to ensure the new tensor has the same number of cells as the original.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: ^([9](ch10.html#id2282-marker)) 就像在 NumPy 中一样，`reshape()` 方法允许您为其中一个维度指定 -1。这个维度的尺寸将自动计算，以确保新的张量具有与原始张量相同数量的单元格。
- en: ^([10](ch10.html#id2337-marker)) The mean of the batch MSEs is equal to the
    overall MSE since all batches have the same size. Well, except the last batch,
    which is often smaller, but this makes very little difference.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: ^([10](ch10.html#id2337-marker)) 批量 MSE 的平均值等于整体 MSE，因为所有批次的尺寸都相同。嗯，除了最后一个批次，它通常更小，但这影响非常小。
- en: '^([11](ch10.html#id2340-marker)) Heng-Tze Cheng et al., [“Wide & Deep Learning
    for Recommender Systems”](https://homl.info/widedeep), *Proceedings of the First
    Workshop on Deep Learning for Recommender Systems* (2016): 7–10.'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: ^([11](ch10.html#id2340-marker)) Heng-Tze Cheng 等人，[“Wide & Deep Learning for
    Recommender Systems”](https://homl.info/widedeep)，*第一届全国深度学习推荐系统研讨会论文集*（2016）：7–10。
- en: ^([12](ch10.html#id2370-marker)) TorchVision includes a `ToTensor` transform
    which does all this, but it’s deprecated so it’s recommended to use this pipeline
    instead.
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: ^([12](ch10.html#id2370-marker)) TorchVision 包含一个 `ToTensor` 转换，它执行所有这些操作，但它已被弃用，因此建议使用此管道。
- en: ^([13](ch10.html#id2420-marker)) Another popular option is exporting your PyTorch
    model to the open ONNX standard using `torch.onnx.export()`. The ONNX model can
    then be used for inference in a wide variety of environments.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: ^([13](ch10.html#id2420-marker)) 另一个流行的选项是使用 `torch.onnx.export()` 将 PyTorch
    模型导出到开放的 ONNX 标准。然后，ONNX 模型可以在各种环境中用于推理。
- en: ^([14](ch10.html#id2429-marker)) A few extra ANN architectures are presented
    in the online notebook at [*https://homl.info/extra-anns*](https://homl.info/extra-anns).
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: ^([14](ch10.html#id2429-marker)) 在在线笔记本 [*https://homl.info/extra-anns*](https://homl.info/extra-anns)
    中展示了几个额外的 ANN 架构。
