<html><head></head><body>
<div id="sbo-rt-content"><div class="readable-text" id="p1">
<h1 class="readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">1</span> </span> <span class="chapter-title-text">Introducing AI-powered search</span></h1>
</div>
<div class="introduction-summary">
<h3 class="introduction-header sigil_not_in_toc">This chapter covers </h3>
<ul>
<li class="readable-text" id="p2">What is AI-powered search?</li>
<li class="readable-text" id="p3">Understanding user intent</li>
<li class="readable-text" id="p4">How AI-powered search works</li>
<li class="readable-text" id="p5">Content and behavioral intelligence</li>
<li class="readable-text" id="p6">Architecting an AI-powered search engine</li>
</ul>
</div>
<div class="readable-text" id="p7">
<p>The search box has become the default user interface for interacting with data in most modern applications. If you think of every major app or website you use daily, one of the first things you likely do on each visit is enter a query to find the content or actions most relevant to you.</p>
</div>
<div class="readable-text intended-text" id="p8">
<p>When you’re not explicitly searching, you may instead be consuming streams of content customized to your tastes and interests. Whether these be video recommendations, items for purchase, prioritized emails, news articles, or other content, you’re likely still looking at filtered or ranked results and given the option to either page through or explicitly filter the content with your own query.</p>
</div>
<div class="readable-text intended-text" id="p9">
<p>For most people, the phrase “search engine” brings up thoughts of a website like Google, Bing, or Baidu that enables queries based on a crawl of the entire public internet. However, the reality is that search is now available in nearly all our digital interactions every day across the numerous websites and applications we use.</p>
</div>
<div class="readable-text intended-text" id="p10">
<p>These search engines are far from static. We’re seeing commercial technologies like OpenAI’s ChatGPT, Anthropic’s Claude, and Google’s Gemini, as well as hundreds of other more open large language models (LLMs), like Meta’s Llama and Mistral’s Mixtral, with source code and model weights published for public use. These all serve as models of the world’s information that can generate interpretations and responses to arbitrary queries. These models are being actively integrated into major search engines and will continue to heavily influence the evolution of AI-powered search.</p>
</div>
<div class="readable-text intended-text" id="p11">
<p>While the expected response from a search box may have historically been to return “ten blue links”—a list of ranked documents for a user to investigate further to find information in response to their query—expectations for the intelligence level of search technologies have skyrocketed in recent years.</p>
</div>
<div class="readable-text intended-text" id="p12">
<p>Users today expect search technology to be </p>
</div>
<ul>
<li class="readable-text" id="p13"> <em>Domain-aware</em><em> </em>—Search technology should understand the entities, terminology, categories, and attributes of each specific use case and corpus of documents, not just use generic statistics on strings of text. </li>
<li class="readable-text" id="p14"> <em>Contextual and personalized</em><em> </em>—It should be able to take into account user context (location, last search, profile, previous interactions, user recommendations, and user classification), query context (other keywords, similar searches), and domain context (inventory, business rules, domain-specific terminology) to better interpret user intent. </li>
<li class="readable-text" id="p15"> <em>Conversational</em><em> </em>—It should be able to interact in natural language and guide users through a multi-step discovery process while learning and remembering relevant new information along the way. </li>
<li class="readable-text" id="p16"> <em>Multi-modal</em><em> </em>—It should be able to resolve queries issued by text, voice, images, video, or other content types, and to use those queries to also search across the other content types. </li>
<li class="readable-text" id="p17"> <em>Intelligent</em><em> </em>—It should be able to deliver predictive type-ahead and to understand what users mean (spelling correction, phrase and attribute detection, intent classification, conceptual searching) to deliver the right answers at the right time and to constantly get smarter. </li>
<li class="readable-text" id="p18"> <em>Assistive</em><em> </em>—It should move beyond delivering just links to delivering answers, summaries, explanations, and available actions. </li>
</ul>
<div class="readable-text" id="p19">
<p>Many of these capabilities are enabled by LLMs, while others are driven by analyzing user behavior and building domain-specific personalization profiles, knowledge graphs, and ranking models.</p>
</div>
<div class="readable-text intended-text" id="p20">
<p>Search interfaces are also evolving to include more chatbot and conversational information discovery sessions as LLMs become more ubiquitous, but even today’s best models struggle with hallucinating (making up bad answers) and going off the rails unless tethered to an actual information source, such as a search engine index, to reliably find and return information from trusted sources. <em>Retrieval augmented generation (RAG)</em>, the technique of using a search engine or vector database as a knowledge source to provide LLMs accurate and up-to-date information as context, is one of the most reliable techniques for improving the accuracy of generative AI models today. </p>
</div>
<div class="readable-text intended-text" id="p21">
<p>The goal of AI-powered search is to use automated machine learning techniques to deliver on all these desired capabilities. While many organizations start with basic text search and spend many years trying to manually optimize synonym lists, business rules, ontologies, field weights, and countless other aspects of their search configuration, some are beginning to realize that most of this process can be automated.</p>
</div>
<div class="readable-text intended-text" id="p22">
<p>Throughout the book, you’ll learn to implement many key AI-powered search techniques, such as</p>
</div>
<ul>
<li class="readable-text" id="p23"> Using LLMs for query interpretation, embeddings, question answering, and results summarization </li>
<li class="readable-text" id="p24"> Fine-tuning LLMs for search and question answering </li>
<li class="readable-text" id="p25"> Collecting and using user signals for crowdsourced relevance </li>
<li class="readable-text" id="p26"> Signals-boosting models </li>
<li class="readable-text" id="p27"> Knowledge graph learning from both signals and content </li>
<li class="readable-text" id="p28"> Semantic knowledge graphs </li>
<li class="readable-text" id="p29"> Query intent classification and query-sense disambiguation </li>
<li class="readable-text" id="p30"> Personalized search and recommendations </li>
<li class="readable-text" id="p31"> Machine-learned ranking (learning to rank) </li>
<li class="readable-text" id="p32"> Click models for implicit relevance feedback </li>
<li class="readable-text" id="p33"> Avoiding bias in ranking models through active learning </li>
<li class="readable-text" id="p34"> Hybrid search and multimodal search across text, images, and mixed content types </li>
<li class="readable-text" id="p35"> Semantic search using both knowledge graphs and LLMs </li>
</ul>
<div class="readable-text" id="p36">
<p>This book is an example-driven guide through the most applicable machine learning algorithms and techniques commonly used to build intelligent search systems. We’ll not only walk through key concepts but will also provide reusable code examples to cover data collection and processing techniques, as well as the self-learning query interpretation and relevance strategies employed to deliver AI-powered search capabilities across today’s leading organizations—hopefully soon to include your own!</p>
</div>
<div class="readable-text" id="p37">
<h2 class="readable-text-h2" id="sigil_toc_id_6"><span class="num-string">1.1</span> What is AI-powered search?</h2>
</div>
<div class="readable-text" id="p38">
<p>Prior to November 2022, when OpenAI released ChatGPT to the world as a generalizable algorithm that non-technical users could talk with to solve many problems, the definition of “artificial intelligence” was a bit nebulous to the general public. It was understood to include things like self-driving cars, autonomous robots, and other futuristic technologies that made computers appear to be intelligent, but AI appeared to many to be more of a marketing buzzword than a well-defined term. A more concrete definition has existed in the software industry for years, however. </p>
</div>
<div class="readable-text intended-text" id="p39">
<p>In the context of software development, the term <em>artificial intelligence</em> generally describes any computer program that can perform a task that previously required human intelligence. That program often includes machine learning techniques, allowing it to learn from data and improve its performance over time. That said, even rules-based systems that do not involve machine learning techniques but generate human-like feedback have also traditionally been considered “AI” systems. We’ll adopt this more general definition of AI in this book, though we’ll be primarily discussing the machine-learning aspects of AI.</p>
</div>
<div class="readable-text intended-text" id="p40">
<p>The term <em>search</em> (or <em>search engine</em>) is likewise considered by the general public to refer to web search engines like Google or Bing. In software development, the term is also used to describe any technology that enables users to query for and find information. Search typically involves at least two critical steps—finding documents that match a query (<em>matching</em>) and then ordering those documents by relevance to the query (<em>ranking</em>). Search can also include many preprocessing steps to better understand the query, and postprocessing steps to extract answers or summarize results from the matched documents. Search is often the primary way users find information, whether conducting general web search, product search, enterprise search, video/image search, or any of hundreds of other common use cases for finding and ranking information. It is also the primary way generative AI systems quickly find updated factual content to use as context for their prompts. </p>
</div>
<div class="readable-text intended-text" id="p41">
<p> But what is AI-powered search, and how does it differ from traditional “search”? Many buzzwords such as “AI”, “machine learning”, “data science”, and “deep learning” are often thrown around interchangeably, and it’s important to understand the distinctions and how they overlap with AI-powered search. Figure 1.1 demonstrates the important relationships between these related areas.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p42">
<img alt="figure" height="355" src="../Images/CH01_F01_Grainger.png" width="421"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 1.1</span> AI-powered search includes all the technologies and techniques at the intersection of the fields of search and AI. These overlap heavily with and use the fields of data science, machine learning, and deep learning. </h5>
</div>
<div class="readable-text intended-text" id="p43">
<p><em> Machine learning</em> is a subset of AI that focuses on using data to train models to perform tasks based on insights learned from the training data. Deep learning is a further subset of machine learning that focuses on training artificial neural networks—algorithms that partially mimic the structure of the human brain—to learn to solve complex problems. In figure 1.1, notice that deep learning is a fully contained subset of machine learning, which is then a fully contained subset of artificial intelligence. Data science is a discipline that overlaps heavily with AI and search, but it also contains other distinct focus areas, so it is not completely a superset or subset of either.</p>
</div>
<div class="readable-text intended-text" id="p44">
<p>Our focus in this book is specifically on the intersection of search (also known as <em>information retrieval</em>) and AI, and in particular on the application of machine learning and deep learning techniques to improve the relevance of search results and to automate the process of tuning search relevance. Building AI-powered search involves many well-known machine learning techniques, but also many that are specific to information retrieval and the search domain. Figure 1.2 provides a categorized list of some key AI-powered search techniques we’ll cover in this book, broken down by whether they are deep learning techniques, other machine learning techniques not requiring deep learning, or other artificial intelligence techniques not requiring machine learning. <span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p45">
<img alt="figure" height="560" src="../Images/CH01_F02_Grainger.png" width="994"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 1.2</span> Specific AI-powered search techniques, broken down by whether they are deep learning techniques, other machine learning techniques not requiring deep learning, or other artificial intelligence techniques not requiring machine learning</h5>
</div>
<div class="readable-text" id="p46">
<p>In the AI-only category, question-answering systems, virtual assistants, chatbots, and rules-based relevancy are all examples of AI techniques that are often built using machine learning, but which do not <em>require</em> machine learning. Many have built chatbots based entirely on rules to understand different user utterances and intents, and likewise question-answering systems can be built solely on rules and ontologies. That said, machine learning is often used to learn these kinds of rules and ontologies, so the lines between these categories are often blurred.</p>
</div>
<div class="readable-text intended-text" id="p47">
<p>When algorithms begin to use data to train models, we enter into the machine learning subcategory of AI-powered search. We use behavioral signals from search engine users (clicks, likes, add-to-carts, purchases, etc.) to build models that can learn to better rank documents. This can include signals-boosting models (top documents per query or category), collaborative filtering models that generate recommendations or personalize search results, and ranking classifiers (learning to rank) that learn from content and behavioral signals to better rank results. Machine learning is also used to learn knowledge graphs, which are graphs of entities, concepts, and their relationships that can be used to better understand the domain and to better interpret user queries. Semantic search (search on meaning, not just keywords) can be enabled by such knowledge graphs, along with traditional natural language processing approaches, query intent classification, document clustering, and other techniques driven by user queries, documents, and user behavioral signals.</p>
</div>
<div class="readable-text intended-text" id="p48">
<p>Finally, in the deep learning subcategory of AI-powered search, we see the use of neural networks to build models that can understand user queries and documents, as well as rank and summarize search results. Here, text is used to train LLMs to understand the meaning of words and phrases, to generate answers to questions, and to generate summaries of documents. LLMs are a type of <em>foundation model</em> that can interpret text content and are often trained on massive amounts of text from the internet. Foundation models can also be trained on other types of content beyond just text (images, audio, video) to enable multimodal search across those content types: text-to-image search, text-to-audio, image-to-video, and so on. LLMs are also used to generate <em>embeddings</em>, which are vector representations of content that represent the content’s meaning. Since a search engine’s primary job is to find and rank content similar to an incoming query, these embeddings enable a sophisticated ability to search on a query’s meaning and significantly improve query understanding and ranking. Further fine-tuning of foundation models on specific goals or domain-specific datasets will also make them significantly better at understanding the nuances of those domains or use cases. </p>
</div>
<div class="readable-text intended-text" id="p49">
<p>Foundation models compress a large amount of human knowledge (often much of the internet), providing them with a broad understanding across most domains. This compression of knowledge, however, is a lossy compression—the original data is not stored, and specific facts and concepts can be easily confused. Foundation models are well known to hallucinate answers to questions, making them generally unreliable for answering factual questions. As a result, in addition to search engines using foundation models to improve query understanding and ranking, we’re also seeing them used heavily for RAG—where search serves as a knowledge source that foundation models can rely on for accurate and up-to-date information as context for generative AI tasks.</p>
</div>
<div class="readable-text intended-text" id="p50">
<p>We’ll cover each of these AI-powered search techniques in detail throughout this book. But first, let’s discuss the goals of AI-powered search and how it differs from traditional search. </p>
</div>
<div class="readable-text" id="p51">
<h2 class="readable-text-h2" id="sigil_toc_id_7"><span class="num-string">1.2</span> Understanding user intent</h2>
</div>
<div class="readable-text" id="p52">
<p>To deliver AI-powered search, we’ll need a cohesive understanding of the dimensions involved in interpreting user intent and returning content matching that intent. Within the field of information retrieval, search engines and recommendation engines are the two most popular technologies employed to deliver the relevant content required to satisfy users’ information need. Many organizations think of search engines and recommendation engines as separate technologies solving different use cases. Commonly, different teams within the same organization—often with different skill sets—work independently on separate search engines and recommendation engines. In this section, we’ll discuss why separating search and recommendations into independent functions and teams can often lead to less-than-ideal outcomes. </p>
</div>
<div class="readable-text" id="p53">
<h3 class="readable-text-h3" id="sigil_toc_id_8"><span class="num-string">1.2.1</span> What is a search engine?</h3>
</div>
<div class="readable-text" id="p54">
<p>A search engine is typically thought of as a technology for explicitly entering queries and receiving a response (figure 1.3). It is usually exposed to end users through a text box into which a user can enter keywords or questions. The results are often returned in a list, alongside additional filtering options that enable further refinement of the initial query. Using this mechanism, search is used as a tool for direct discovery of relevant content. When a user is finished with their search session, they can usually issue a new query and start with a blank slate, ignoring the context of previous searches. <span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p55">
<img alt="figure" height="610" src="../Images/CH01_F03_Grainger.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 1.3</span> A typical search experience, with a user entering a query and seeing search results with filtering options to support further refinement of the search results</h5>
</div>
<div class="readable-text" id="p56">
<p>A search engine is one of the most cross-functional kinds of systems within the software engineering world. Most underlying search engine technology is designed to operate in a massively scalable way, serving large volumes of queries against millions, billions, or even trillions of documents, and delivering results in hundreds of milliseconds or less. In many cases, real-time processing and near-real-time searching on newly ingested data is required, and all of this must be parallelizable across numerous servers to scale out and meet such high-performance requirements.</p>
</div>
<div class="readable-text intended-text" id="p57">
<p>Implementing search engines also requires substantial work building search-specific data structures like an inverted index or ANN-based vector store, an understanding of linear algebra and vector similarity scoring, experience with text analysis and natural language processing, and knowledge of numerous search-specific types of data models and capabilities (spell checking, autosuggest, faceting, text highlighting, embeddings, and so on).</p>
</div>
<div class="readable-text intended-text" id="p58">
<p>For a search engine to fully interpret user intent, it’s critical that you combine a thorough understanding of your content, your users, and your domain. We’ll revisit why this is important after briefly discussing the related topic of recommendation engines. </p>
</div>
<div class="readable-text" id="p59">
<h3 class="readable-text-h3" id="sigil_toc_id_9"><span class="num-string">1.2.2</span> What do recommendation engines offer?</h3>
</div>
<div class="readable-text" id="p60">
<p>Most people think of recommendation engines (or “recommendation systems”) as systems that don’t accept direct user input and instead deliver content based upon what the engine learns about them, calculating best matches for their interests and behaviors. These interests are inferred in a variety of ways through user preferences, user behavior, viewed content, and so on. This lack of direct user input for recommendation engines stands in direct contrast with search engines, which are traditionally thought of as technology that requires explicit user-driven queries. </p>
</div>
<div class="readable-text intended-text" id="p61">
<p>If you routinely visit Amazon.com or any other major e-commerce website, you are no doubt familiar with recommendation engine sections stating that “based on your interest in this item, you may also like . . .” or otherwise just recommending a list of items based upon your collective browsing and purchase history, like the example in figure 1.4. These recommendations often drive significant revenue for companies, and they help customers discover relevant, personalized, and related content that often complements what they are searching for explicitly.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p62">
<img alt="figure" height="488" src="../Images/CH01_F04_Grainger.png" width="1100"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 1.4</span> Recommendations based upon users expressing interest in similar items</h5>
</div>
<div class="readable-text intended-text" id="p63">
<p>Recommendation algorithms can roughly be divided into three categories:</p>
</div>
<ul>
<li class="readable-text" id="p64"> <em>Content-based recommenders</em><em> </em>—These match based on attributes of items or users </li>
<li class="readable-text" id="p65"> <em>Behavior-based recommenders</em><em> </em>—These match based upon the overlap of interactions from similar users with similar items </li>
<li class="readable-text" id="p66"> <em>Multimodal recommenders</em><em> </em>—These perform hybrid matching based on both similar content-based attributes and overlapping behavior-based interactions. </li>
</ul>
<div class="readable-text" id="p67">
<h3 class="readable-text-h3" id="sigil_toc_id_10"><span class="num-string">1.2.3</span> The personalization spectrum between search and recommendations</h3>
</div>
<div class="readable-text" id="p68">
<p>The key difference between search engines and recommendation engines is that search engines are typically guided by users and match the users’ explicitly entered queries, whereas recommendation engines typically accept no direct user input and instead recommend—based upon already-known or inferred knowledge—what a user may want to see next. </p>
</div>
<div class="readable-text intended-text" id="p69">
<p>But these two systems are really two sides of the same coin, and treating them as separate systems creates a false dichotomy. The goal, in both cases, is to understand what a user is looking for and to deliver relevant results to meet that user’s information need. A broad range of personalization capabilities lies within the spectrum between search and recommendation systems.</p>
</div>
<div class="readable-text intended-text" id="p70">
<p>Assuming you have both explicit queries and a user-specific personalization profile available when trying to find content for your end users, you can do any of the following:</p>
</div>
<ul>
<li class="readable-text" id="p71"> <em>Traditional keyword search</em><em> </em>—Ignore the profile and only use explicit inputs. </li>
<li class="readable-text" id="p72"> <em>Personalized search</em><em> </em>—Use the profile implicitly along with other explicit user input. </li>
<li class="readable-text" id="p73"> <em>User-guided recommendations</em><em> </em>—Use the profile explicitly and provide the user with the ability to adjust it. </li>
<li class="readable-text" id="p74"> <em>Traditional recommendations</em><em> </em>—Use the profile explicitly with no ability for a user to adjust it. </li>
</ul>
<div class="readable-text" id="p75">
<p>Figure 1.5 shows this personalization spectrum.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p76">
<img alt="figure" height="276" src="../Images/CH01_F05_Grainger.png" width="893"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 1.5</span> The personalization spectrum, showing traditional keyword search and traditional recommendations as two ends of a larger continuum</h5>
</div>
<div class="readable-text" id="p77">
<p>While the two ends of this personalization spectrum represent the extremes, they are also the two most common approaches. Unfortunately, one of the biggest mistakes we see in many organizations is teams built around the belief that search and recommendations are separate problems. This often leads to data science teams building complicated personalization and segmentation models only capable of recommendations and not search, and engineering teams building large-scale keyword matching engines that can’t easily take advantage of the robust models built by the recommendations teams.</p>
</div>
<div class="readable-text intended-text" id="p78">
<p>More often than not, the recommendation teams are staffed by data scientists with minimal information retrieval background, and the search teams are often staffed by engineers with minimal data science background. Due to Conway’s law (“organizations which design systems … are constrained to produce designs which are copies of the communication structures of these organizations”), this ultimately results in challenges solving problems along the personalization spectrum (particularly in the middle) that need the best from both teams. In this book, we focus on the shared techniques that make it possible for search to become smarter and for recommendations to become more flexible through a unified approach. AI-powered search platforms need to be able to continuously learn from both your users and your content and then enable your users to guide the results so they continue to improve. </p>
</div>
<div class="readable-text" id="p79">
<h3 class="readable-text-h3" id="sigil_toc_id_11"><span class="num-string">1.2.4</span> Semantic search and knowledge graphs</h3>
</div>
<div class="readable-text" id="p80">
<p>We presented search and recommendations as a personalization spectrum in figure 1.5, with personalized search and user-guided recommendations in between, but there’s one more dimension that is critical for building a good AI-powered search system—a deep understanding of the given domain. It’s not enough to match on keywords and to recommend content based upon how users collectively interact with documents. The engine must also learn as much as it can about the domain. This includes </p>
</div>
<ul>
<li class="readable-text" id="p81"> Learning all the important domain-specific phrases, synonyms, and related terms </li>
<li class="readable-text" id="p82"> Identifying entities in documents and queries </li>
<li class="readable-text" id="p83"> Generating a knowledge graph that relates those entities </li>
<li class="readable-text" id="p84"> Disambiguating the many nuanced meanings represented by domain-specific terminology </li>
<li class="readable-text" id="p85"> Being able to effectively parse, interpret, and conceptually match the nuanced intent of users within your domain. </li>
</ul>
<div class="readable-text" id="p86">
<p>Figure 1.6 shows an example of semantic parsing of a query, with the goal being to search for “things” (known entities) instead of “strings” (just text matching).</p>
</div>
<div class="browsable-container figure-container" id="p87">
<img alt="figure" height="389" src="../Images/CH01_F06_Grainger.png" width="900"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 1.6</span> Semantic parsing of a query, demonstrating an understanding of the entities (“things”) represented by query terms</h5>
</div>
<div class="readable-text intended-text" id="p88">
<p>To make their searches smarter, many companies spend considerable money employing large teams to manually create dictionaries and knowledge graphs to identify the relationships between entities in their users’ queries. This book focuses on a more scalable approach: building an AI-powered search engine that can automatically learn these relationships continuously. We also dive into additional techniques for semantic search, including dense vector search on embeddings and generative search using LLMs. <span class="aframe-location"/></p>
</div>
<div class="readable-text" id="p89">
<h3 class="readable-text-h3" id="sigil_toc_id_12"><span class="num-string">1.2.5</span> Understanding the dimensions of user intent</h3>
</div>
<div class="readable-text" id="p90">
<p>We’ve discussed the important roles of traditional keyword search, recommendations, and the personalization spectrum in between. We also discussed the need for semantic search to provide domain-specific understanding of your content and your users’ queries. All of these are key pillars of a singular, larger goal: fully understanding user intent. Figure 1.7 demonstrates the interplay between each of these key pillars of user intent. </p>
</div>
<div class="readable-text intended-text" id="p91">
<p>The top-left circle in figure 1.7 represents <em>content understanding</em>—the ability to find the right content based on keywords, language patterns, and known attribute matching. The top-right circle represents <em>user understanding</em>—the ability to understand each user’s specific preferences and use those to return more personalized results. Finally, the lower circle represents <em>domain understanding</em>—the ability to interpret words, phrases, concepts, entities, and nuanced interpretations and relationships between each of these within your own domain-specific context. </p>
</div>
<div class="browsable-container figure-container" id="p92">
<img alt="figure" height="503" src="../Images/CH01_F07_Grainger.png" width="1009"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 1.7</span> The dimensions of user intent: a combination of content understanding, user understanding, and domain understanding</h5>
</div>
<div class="readable-text intended-text" id="p93">
<p>A query only in the content understanding circle represents traditional <em>keyword search</em>, enabling matching on keywords but without using any domain or user-specific context. A query only in the user understanding circle would be recommendations from collaborative filtering, with no ability for the user to override the inputs and no understanding of the domain or content of the underlying documents. A query only in the domain understanding circle might be a structured query on known tags, categories, or entities, or even a browse-like interface that allowed for exploration of a <em>knowledge graph</em> of these domain-specific entities and their relationships, but without any user-specific personalization or ability to find arbitrary terms, phrases, and content. <span class="aframe-location"/></p>
</div>
<div class="readable-text intended-text" id="p94">
<p>When traditional keyword search and recommendations overlap, we get <em>personalized search</em> or guided recommendations. When traditional keyword search and knowledge graphs overlap, we get <em>semantic search</em>: a smart, domain-specific search experience. Finally, when recommendations and knowledge graphs overlap, we get smarter <em>domain-aware recommendations</em> that match on crowdsourced user interactions across similar documents and also on a domain-specific understanding of the important attributes of those documents. </p>
</div>
<div class="readable-text intended-text" id="p95">
<p>The holy grail for AI-powered search is to harness the intersection of all three categories: semantic search, personalized search, and domain-aware recommendations. That is to say, to truly understand user intent, we need all of the following:</p>
</div>
<ul>
<li class="readable-text" id="p96"> An expert understanding of the domain the user is searching </li>
<li class="readable-text" id="p97"> An expert understanding of the user and their preferences </li>
<li class="readable-text" id="p98"> An expert ability to match and rank arbitrary queries against any content </li>
</ul>
<div class="readable-text" id="p99">
<p>AI-powered search starts with the three pillars of user intent (content, domain, and user), and then employs intelligent algorithms to constantly learn and improve in each of these areas. This learning includes techniques like automatically learning ranking criteria, automatically learning user preferences, and automatically learning knowledge graphs and language models of the represented domain. At the end of the day, a balanced combination of these three approaches provides the key to optimal understanding of users and their query intent, which is the end goal of our AI-powered search system. </p>
</div>
<div class="readable-text" id="p100">
<h2 class="readable-text-h2" id="sigil_toc_id_13"><span class="num-string">1.3</span> How does AI-powered search work?</h2>
</div>
<div class="readable-text" id="p101">
<p>We laid out our end goal of matching user intent through content understanding, user understanding, and domain understanding. With that background established, let’s wrap up this chapter with an overview of the actual components needed to deliver an AI-powered search platform. Search intelligence typically matures along a predictable progression iteratively over time, as shown in figure 1.8. Basic keyword search is a typical starting point for organizations. Once in production, they realize their search relevancy needs to be improved, and they start manually tuning field weights, boosts, text and language analysis, and introducing additional features and functions. <span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p102">
<img alt="figure" height="377" src="../Images/CH01_F08_Grainger.png" width="772"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 1.8</span> The typical search intelligence progression, from basic keyword search to a full self-learning search platform</h5>
</div>
<div class="readable-text" id="p103">
<p>Eventually, they realize they need to inject domain understanding into their search capabilities, at which point organizations begin to invest in synonym lists, taxonomies, lists of known entities, and domain-specific business rules. While these all help, organizations eventually also discover that relevant search is very much dependent upon successfully interpreting user queries and understanding user intent, so they begin investing in techniques for query classification, semantic query parsing, knowledge graphs, personalization, and other attempts to correctly interpret user queries.</p>
</div>
<div class="readable-text intended-text" id="p104">
<p>Because these tasks yield improvements, this success often results in the creation of large teams investing significant time manually tuning lists and parameters, and eventually organizations may realize that it is possible (and more expedient) to automate as much of that process as possible through learning from user signals, user testing (A/B testing, offline relevancy simulations, and active learning), and building of machine-learned relevancy models. The end goal is to completely automate each of these steps along the search intelligence progression and enable the engine to be self-learning.</p>
</div>
<div class="readable-text" id="p105">
<h3 class="readable-text-h3" id="sigil_toc_id_14"><span class="num-string">1.3.1</span> The core search foundation</h3>
</div>
<div class="readable-text" id="p106">
<p>The first step in building a search platform is almost always to get traditional keyword search working (the “content understanding” part in figure 1.7). Teams often spend years tuning and improving this step, and a whole discipline called <em>relevance engineering</em> has arisen that has historically focused significant effort into understanding content; improving content for search; adjusting boosts, query parameters, and query functions; and otherwise trying to maximize the relevance of the traditional search experience. For a deep dive into this world of relevance engineering and tuning traditional keyword search relevance, we recommend the book <em>Relevant Search</em> by Doug Turnbull and John Berryman (Manning, 2016). </p>
</div>
<div class="readable-text intended-text" id="p107">
<p>As relevance engineers become more sophisticated, their work often moves into the realms of user understanding and recommendations, as well as into domain-understanding and semantic search. The rise of large language models has made it easy in recent years to implement out-of-the-box semantic search, but getting to the next level in optimizing the relevance and matching requires much more sophisticated approaches, as you’ll learn throughout this book. Our focus in <em>AI-Powered Search</em> will be on automating the process of learning and optimizing search relevance so it operates as a continuous feedback loop. We essentially want to automate much of the relevance engineer’s job, relying on algorithms, where possible, to continually learn optimal matching and ranking strategies.</p>
</div>
<div class="readable-text intended-text" id="p108">
<p>So, what characteristics differentiate a well-tuned search engine from an AI-powered search engine? A well-tuned search engine is the foundation upon which AI-powered search is built, but AI-powered search goes far beyond that, continuously learning and improving through reflected intelligence. <em>Reflected intelligence</em> is the idea of using continual feedback loops of user input, content updates, and user interactions with content to continually learn and improve the quality of your search application. </p>
</div>
<div class="readable-text" id="p109">
<h3 class="readable-text-h3" id="sigil_toc_id_15"><span class="num-string">1.3.2</span> Reflected intelligence through feedback loops</h3>
</div>
<div class="readable-text" id="p110">
<p>Feedback loops are critical to building an AI-powered search solution. Imagine if your entire education (elementary school through to your highest degree) had consisted of nothing more than you reading textbooks: no teachers to ask questions, no exams to test your knowledge and provide feedback, and no classmates or others with which to interact, study, or collaborate. You would have probably hit endless walls where you were unable to fully grasp certain concepts or even understand what you were reading, and you would have understood many ideas incorrectly and never had the opportunity to realize this or to adjust your assumptions. </p>
</div>
<div class="readable-text intended-text" id="p111">
<p>Search engines often operate this same way. Smart engineers push data to the search engine and tune certain features and feature weights, but the engine just reads those configurations and acts upon them the same way every time for repeated user queries. Search engines are the perfect kind of system for interactive learning, however, when we introduce feedback loops.</p>
</div>
<div class="readable-text intended-text" id="p112">
<p>Figure 1.9 shows the typical flow of information through a search feedback loop. First, a user issues a query. This query executes a search, which returns results, such as a specific answer, a list of answers, or a list of links to pages, to an end user. Once presented with the list, the user then takes one or more actions. These actions usually start with clicks on documents, but those clicks can ultimately lead to adding an item to a shopping cart and purchasing it (e-commerce), giving the item a thumbs up or thumbs down (media consumption website), liking or commenting on the result (social media website), or any number of other context-specific actions.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p113">
<img alt="figure" height="319" src="../Images/CH01_F09_Grainger.png" width="639"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 1.9</span> Reflected intelligence through feedback loops</h5>
</div>
<div class="readable-text" id="p114">
<p>These actions can then be used to generate an improved relevance ranking model for future searches. Your search application can automatically adjust the ranking of future search results, delivering an improved search experience for the next user’s search. </p>
</div>
<div class="readable-text" id="p115">
<h3 class="readable-text-h3" id="sigil_toc_id_16"><span class="num-string">1.3.3</span> Signals boosting, collaborative filtering, and learning to rank</h3>
</div>
<div class="readable-text" id="p116">
<p>The searches, clicks, likes, add to carts, purchases, comments, and other interactions with your search application are critical data that you need to capture. We collectively refer to these data points as <em>signals</em>. Signals provide a constant stream of feedback to your search application, recording every meaningful interaction with your end users. These digital moments can then be used by machine learning algorithms to generate models to power user understanding, content understanding, and domain understanding. </p>
</div>
<div class="readable-text intended-text" id="p117">
<p>Figure 1.10 shows the data flow for the collection and processing of signals in a typical AI-powered search application. You can see signals being collected for each search, as well as resulting clicks and purchases. Unique signals can also be recorded for any other kind of user interaction (add-to-cart, facet click, bookmark, hover, or even page dwell time).</p>
</div>
<div class="browsable-container figure-container" id="p118">
<img alt="figure" height="594" src="../Images/CH01_F10_Grainger.png" width="1026"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 1.10</span> Signal collection and processing data flow</h5>
</div>
<div class="readable-text" id="p119">
<p>Signals are one of the two sources of data that power the intelligence engine of an AI-powered search application, with the other being content. Many AI-powered search algorithms incorporate signals feedback loops to build reflected intelligence models. Some of these key types of reflected intelligence algorithms include</p>
</div>
<ul>
<li class="readable-text" id="p120"> Popularized relevance—<em>Signals-boosting</em> algorithms create models that use aggregated signals to boost the rankings of the most important documents for your most popular queries.  </li>
<li class="readable-text" id="p121"> Personalized relevance—<em>Collaborative filtering</em> algorithms create models using matrix factorization or similar techniques that use signals to generate recommendations and user profiles to personalize search results for each user.  </li>
<li class="readable-text" id="p122"> Generalized relevance—<em>Learning to rank</em> algorithms train <em>ranking classifiers</em> to perform machine-learned ranking based on relevance judgments generated from user-signals-based click models. This process learns a set of features and ranking weights that can be applied generally to all queries—even ones that have not been previously seen.  </li>
</ul>
<div class="readable-text" id="p123">
<p>These algorithms enable your search application to learn from user interactions and to automatically adjust rankings for future search results, delivering an improved search experience for the next users’ searches. </p>
</div>
<div class="readable-text" id="p124">
<h3 class="readable-text-h3" id="sigil_toc_id_17"><span class="num-string">1.3.4</span> Content and domain intelligence</h3>
</div>
<div class="readable-text" id="p125">
<p>While signals provide a constant stream of usage and feedback data to your search application, your content is also a rich source of information that can be incorporated in your feedback loops. For example, if someone searches for a particular keyword, the other keywords and top categories in the documents returned serve as valuable data points. Those data points can be used to tag or categorize the query and can be shown to other end users (as facets, for example), leading to further interactions that generate signals from which the engine can learn. </p>
</div>
<div class="readable-text intended-text" id="p126">
<p>The content of your documents forms a representative textual model of your domain. Entities, domain-specific terminology, and the sentences contained within your documents serve as a rich, semantic graph. That graph can be utilized to drive powerful conceptual and semantic search that better understands your domain. We’ll dive more deeply into understanding your content in chapter 2, and into semantic search capabilities using this rich semantic knowledge graph (SKG) in chapter 5. </p>
</div>
<div class="readable-text intended-text" id="p127">
<p>In recent years, LLMs have revolutionized how search engines can interpret queries and responses. LLMs are deep neural networks trained on massive amounts of text data. They can recognize, translate, summarize, predict, and generate new data based on incoming prompts and any additional context provided. Often, LLMs are trained on text, receive a prompt as text, and return a response as text, though similar multimodal models can also be trained on images, audio, other data, or all the above. LLMs often contain billions of parameters within the neural network, and this number is likely to continue to grow in the future so long as model performance continues to improve with more parameters.</p>
</div>
<div class="readable-text intended-text" id="p128">
<p>Today’s most successful LLMs are based on the Transformer architecture, introduced by Google researchers in 2017, which applies the concept of “attention” to language learning (“Attention is All You Need”, Ashish Vaswani et al.). Massive amounts of textual data are fed into a neural network, and a representation of the words and their relationships within each context are modeled using unsupervised learning. Once the model is built, it’s able to interpret an incoming string of text, a <em>prompt</em>, as a context and to encode the context into embeddings, which are numerical vector representations of the meaning of the prompt. In addition to being able to encode prompts into embeddings, Transformers also contain a decoder layer, which can convert embeddings back into text. Transformers can be used to solve many kinds of problems, from similarity search on embeddings (text search, image search, etc.), to question answering, to classification, to summarization of content, and even to generation of new content (writing, code, poems, images, etc.). </p>
</div>
<div class="readable-text intended-text" id="p129">
<p>Transformers are context-sensitive. An LLM tuned for question answering might respond to the prompt “What is the difference between a capital and capitol?” with the answer “A capital is a city or town that serves as the seat of government for a state or country. A capitol is a building in which a state legislature meets.” However, the same LLM may respond to the question “What is the difference between a capital and lowercase word?” with the following context-based answer: “The difference between a capital and lowercase word is that a capital letter is used at the beginning of a sentence or proper nouns, while a lowercase letter is used for all other letters in a word.”</p>
</div>
<div class="readable-text intended-text" id="p130">
<p>Many LLMs are open sourced, but for optimal output quality, LLMs benefit from being fine-tuned for the task at hand with domain-specific content and prompts. Fine-tuning is the act of taking a pretrained model, which already has a strong general understanding of language and general concepts, and “teaching” it about new content and tasks. The original pretrained models are often referred to as <em>foundation models</em>, as they form the foundation upon which the domain-specific fine-tuning will be applied. The process of fine-tuning usually takes a small fraction of the time necessary to train the original LLM. Some LLMs have been trained on so much data and such a wide variety of data (such as a comprehensive web crawl of the internet) that they can perform quite well without retraining, but retraining for the task at hand almost always improves performance. </p>
</div>
<div class="readable-text" id="p131">
<h3 class="readable-text-h3" id="sigil_toc_id_18"><span class="num-string">1.3.5</span> Generative AI and retrieval augmented generation</h3>
</div>
<div class="readable-text" id="p132">
<p>Generative AI is accelerating at a rapid pace, and search engines both benefit from it and serve as a key component of generative AI systems. LLMs (and other foundation models) serve as reasoning engines, having enough knowledge of the world to interpret language and generally reason about most concepts, but without the ability to reliably recall factual information without the risk of hallucinating (making up false information). </p>
</div>
<div class="readable-text intended-text" id="p133">
<p>As a result, search engines are used in retrieval augmented generation (RAG) pipelines as a knowledge source for LLMs, allowing relevant context to be retrieved and passed to the LLM to ensure it has up-to-date and accurate data from which to answer. This entire book is effectively about using AI to optimize the “retrieval” part of RAG, and we’ll cover the “generative” part in chapter 15. </p>
</div>
<div class="readable-text intended-text" id="p134">
<p>While RAG makes search engines a critical component of generative AI systems, LLMs also serve as critical components of search engines. LLMs can be used to interpret queries, generate embeddings for vector search, generate summaries of search results, and even generate answers to questions directly from search results.</p>
</div>
<div class="readable-text intended-text" id="p135">
<p>The transition from traditional information retrieval to these new <em>generative search</em> capabilities is shown in figure 1.11. For decades, traditional search has returned a list of search results (“ten blue links”), showing the top-ranked documents most relevant for a query. For queries on entities and well-known topics, search engines often show precalculated info boxes with summary information or show predetermined answers to known questions. Search engines often also extract words, sentences, or paragraph snippets out of search results to answer questions instead of forcing users to open and read the search results to find the answer. This process is known as <em>extractive question answering</em>, and it is a more targeted form of search, since it additionally searches and ranks answers found within documents. </p>
</div>
<div class="browsable-container figure-container" id="p136">
<img alt="figure" height="254" src="../Images/CH01_F11_Grainger.png" width="907"/>
<h5 class="figure-container-h5 sigil_not_in_toc"><span class="num-string">Figure 1.11</span> The transition from traditional information retrieval to generative search</h5>
</div>
<div class="readable-text" id="p137">
<p>However, there’s a fine line between extracting answers from search results and synthesizing new content to return in the results, and this is where we transition into the realm of generative search. <em>Results summarization</em> is the process of rewriting search results into a more concise and readable format, often combining information from multiple sources and even providing citations for the sources within the summarized response. <em>Abstractive question answering</em> is the process of generating answers to questions by synthesizing information from one or more ranked search results into an answer to a user’s question. The difference between extractive question answering and abstractive question answering is that extractive question answering finds relevant content within documents to return as answers (“extracting it”), whereas abstractive question answering writes a synthesized response by interpreting results and generating an answer that may look different than what’s written in any of the documents. <em>New content generation</em> is also possible within a generative search experience, such as responding to queries with creative new prose, code, poems, images, or other content, based on the keywords or prompts being submitted by users. </p>
</div>
<div class="readable-text intended-text" id="p138">
<p>In summary, generative AI and AI-powered search are tightly intertwined. Generative AI is a critical component of “AI-powered search” (powering answer generation and results summarization), and AI-powered search is a critical component of “search-powered AI” (RAG). Both heavily utilize LLMs and other foundation models, and both are critical components of intelligent and accurate AI systems. </p>
</div>
<div class="readable-text" id="p139">
<h3 class="readable-text-h3" id="sigil_toc_id_19"><span class="num-string">1.3.6</span> Curated vs. black-box AI</h3>
</div>
<div class="readable-text" id="p140">
<p>Like LLMs, many modern AI techniques rely heavily on deep learning based on artificial neural networks. Unfortunately, it is often challenging for a human to understand the specific factors that go into any particular prediction or output from a deep learning model due to the internal complexity of the learned model. </p>
</div>
<div class="readable-text intended-text" id="p141">
<p>This sometimes results in a “black-box AI” system, where the results may be correct or impressive, but they are not easy to debug or correct when the model makes an incorrect judgment. An entire field of <em>explainable AI</em> (sometimes called <em>interpretable AI</em> or <em>transparent AI</em>) has arisen out of a need to be able to understand, curate, and trust these models. </p>
</div>
<div class="readable-text intended-text" id="p142">
<p>In this book, we’ll cover deep learning approaches to search, such as dense vector search on embeddings, question answering, synthetic training data generation, and results summarization using LLMs. We’ll mostly focus our efforts, however, on creating intelligence that can be expressed in human terms and then corrected and augmented by human intelligence. You can think of this as “AI-assisted human curation”, or as “human-assisted AI”, but either way, the overriding philosophy of this book is to use AI to automate the process of search intelligence while keeping the human in the loop with the ability to take control and augment or override the system.</p>
</div>
<div class="readable-text intended-text" id="p143">
<p>As a learning exercise, this approach also leads to a deeper, intuitive understanding of how search ranking and relevance work, and how you can integrate many different AI-driven approaches without forfeiting control of the system. </p>
</div>
<div class="readable-text" id="p144">
<h3 class="readable-text-h3" id="sigil_toc_id_20"><span class="num-string">1.3.7</span> Architecture for an AI-powered search engine</h3>
</div>
<div class="readable-text" id="p145">
<p>The architecture for an AI-powered search engine often requires numerous building blocks to be assembled to form a smart end-to-end system. You start with a core search engine like Apache Solr, OpenSearch, or one of the other search engines or vector databases identified in appendix B. You then feed your searchable content into the engine, running various transformations to make it more useful. These index-time transformations might include changes like these:</p>
</div>
<ul>
<li class="readable-text" id="p146"> Interpreting the meaning of your documents into embeddings using LLMs </li>
<li class="readable-text" id="p147"> Classifying the document, adding the classification as a field </li>
<li class="readable-text" id="p148"> Normalizing field values </li>
<li class="readable-text" id="p149"> Extracting entities from text, adding entities in separate fields </li>
<li class="readable-text" id="p150"> Clustering content, adding clusters as a field </li>
<li class="readable-text" id="p151"> Detecting and annotating phrases </li>
<li class="readable-text" id="p152"> Pulling in additional data from a knowledge graph, external API, or other data source </li>
<li class="readable-text" id="p153"> Performing part of speech (POS) detection and other natural language processing steps  </li>
<li class="readable-text" id="p154"> Extracting facts (such as RDF triples) </li>
<li class="readable-text" id="p155"> Applying other machine learning models or ETL rules to enrich the document </li>
</ul>
<div class="readable-text" id="p156">
<p>Once the data is in the engine, your goal is to make it available for searching. This requires query pipelines, which can interpret incoming queries; identify concepts, phrases, and entities; correct misspellings; expand the query to include related terms, synonyms, concepts, or embedding representations; and then rewrite the query so your core engine can find the most relevant results. Individual search documents may then be returned to the end user, summaries of results may be generated from language models, or answers may be explicitly extracted from the results.</p>
</div>
<div class="readable-text intended-text" id="p157">
<p>Much of this query intelligence requires a robust understanding of your domain, however. This requires running batch jobs on your content and user signals to learn patterns and derive domain-specific intelligence. What are the most common misspellings from your users, and what do they choose as the correct spelling among multiple candidates? When a user searches for specific queries, which documents should be boosted as the most popular? For unknown queries, what is the ideal ranking among all the attributes or features available for matching?</p>
</div>
<div class="readable-text intended-text" id="p158">
<p>We need access to most of these answers at query time (either precomputed or quickly computable) because we expect queries to return within milliseconds to seconds. This requires a job processing framework (we use Apache Spark in this book) and a workflow scheduling mechanism to keep the jobs running in sequence.</p>
</div>
<div class="readable-text intended-text" id="p159">
<p>You’ll also need a mechanism for collecting the constant stream of incoming user signals (capturing them on the frontend application and then storing them in your search engine or other backend datastore).</p>
</div>
<div class="readable-text intended-text" id="p160">
<p>The signals will then be used to generate all kinds of models—from signals boosting models that boost the most popular items for top queries, to learning to rank models that apply a generalizable ranking function to all queries, to personalization models that output user-specific recommendations and personalization preferences for each user or segment of users.</p>
</div>
<div class="readable-text intended-text" id="p161">
<p>AI-powered search is way more than just using the latest LLM to interpret queries. It’s about engineering an end-to-end system for continuous learning. Ultimately, you’ll end up with a system that receives constant streams of document changes and user signals, continually processes those streams to improve models, and then constantly adjusts future search results and measures the effect of changes in order to deliver more intelligent results. That is the key behind AI-powered search: implementing a process of continual learning and improvement based upon real user interactions, updating content patterns, and evolving models to optimally understand current user intent and to deliver an ever-improving search experience. </p>
</div>
<div class="readable-text" id="p162">
<h2 class="readable-text-h2" id="sigil_toc_id_21">Summary</h2>
</div>
<ul>
<li class="readable-text" id="p163"> Expectations for search sophistication are evolving with the rise of LLMs, with end users expecting search to now be domain-aware, contextual and personalized, conversational, multimodal, intelligent, and assistive. </li>
<li class="readable-text" id="p164"> Search and recommendations are the two extreme ends of a continuous personalization spectrum within information retrieval, and it’s important to consider the opportunities in between to optimize relevance. </li>
<li class="readable-text" id="p165"> Correctly interpreting user intent requires simultaneous understanding of your content, your user and their preferences, and the knowledge domain in which your platform operates. </li>
<li class="readable-text" id="p166"> Optimal search relevance lies at the intersection of personalized search (traditional keyword search plus collaborative recommendations), semantic search (traditional keyword search plus knowledge graphs), and domain-aware recommendations (collaborative recommendations plus knowledge graphs). </li>
<li class="readable-text" id="p167"> AI-powered search operates on and learns from two key types of data: content and user signals. </li>
<li class="readable-text" id="p168"> Search and generative AI go hand in hand. Generative search capabilities, such as RAG, are a critical component of modern generative AI systems (to prevent hallucinations); and generative AI capabilities, such as results summarization, are critical components of modern search engines (to return better answers). </li>
<li class="readable-text" id="p169"> Reflected intelligence—the use of feedback loops to continually collect signals, tune results, and measure improvements—is the engine that enables AI-powered search to learn and constantly improve. </li>
</ul>
</div></body></html>