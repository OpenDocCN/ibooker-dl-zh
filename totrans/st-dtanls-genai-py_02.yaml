- en: 3 Descriptive analysis and statistical inference supported by generative AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Using generative AI to design analytics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Descriptive analytics of collected data using generative AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Utilizing generative AI to select appropriate inference analytics methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using generative AI to obtain complete code solutions for data transformation,
    visualization, and modeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The work described in the previous chapter was challenging and strenuous but
    absolutely necessary. You ensured that the data is of acceptable quality and that
    you understand its meaning. Your understanding of the data may still change as
    analysis uncovers nuances and intricacies of the underlying process, but you should
    have a solid foundation by now.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will walk through the first part of an in-depth business
    analysis, the end-to-end descriptive analysis, learning how generative AI can
    help us at each step. And it can help a lot, from answering questions related
    to available data to providing real business insights. We will start with high-level
    analysis planning, touch on even more data preparation (surprise!), and then describe
    and visualize the data, searching for business-relevant information. We will also
    apply more advanced statistical modeling tools to our data, hoping to infer more
    insight from it.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Research questions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the first chapter, we explained how you can use generative AI to help specify
    the business goal of your analysis. As we said then, your goals should usually
    be determined by the business stakeholders. In the second chapter, you did a primary
    cleanup of your data and investigated the contents of available data sources.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now make millions for your company! That’s your role, no? Well, actually,
    no. At least, it *shouldn’t* be. Your role is to inform decisions made by business
    stakeholders. But to do that, you need to translate the business questions into
    research questions. The plural here is not by accident. Usually, you’ll discover
    that answering a single business question requires answering multiple research
    questions. Take a simple question: “How do we make more money?” To answer that,
    you may go down the following path: “Who spends the most money with us?”, followed
    by “Can they buy more of our product?”, or “Where do we find similar people?”
    Or, as the dollar saved is worth ten dollars earned: “What step in our production
    produces the most scrap?”, followed by “What production parameters could we optimize
    to reduce this?”'
  prefs: []
  type: TYPE_NORMAL
- en: The possibilities are endless, and you’re limited only by your imagination and
    data availability. That’s why knowing your data is so important! Business stakeholders
    usually think in terms of business processes. A person managing a supply chain
    would love to lay their hands on a prediction of product demand across different
    regions to minimize overstocking and understocking issues. A person responsible
    for alloy casting would love to have a tool that calculates optimal ratios of
    different substrate materials to get the final product. They understand the supply
    chain or metal mixing process; they might not appreciate the complexity of integrating
    regional sales trends and global economic indicators, or the need for confirmed
    quality and trace element analysis that are crucial for creating robust models.
    They don’t necessarily know the limitations and possibilities inherent to your
    data sources.
  prefs: []
  type: TYPE_NORMAL
- en: The key point here is that you will rarely answer the business question you’ve
    been presented with. More often than not, you will need to break it down and translate
    it into a series of research questions, and only after their analysis will you
    synthetize the final answer. In the first chapter, we showed you an iterative
    way of defining the analysis scope. Even if it seems you defined your scope just
    a short while ago, the moment you’ve finished cleaning and assessing your data
    inventory is a good time to look at the problem with fresh eyes. Maybe some questions
    you thought were answerable aren’t, and perhaps new opportunities have arisen.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we were writing this book, we asked generative AI what information it would
    want from us to help us formulate research questions about the dataset we have
    at hand (think of a situation when a business stakeholder drops data on your lap
    with a short request “do something about it”; it happens). What we got back was
    a handy checklist, which should help you structure your thinking about what questions
    are and aren’t answerable in the context of your data environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Data dictionary*—A brief description of each variable in your dataset, including
    its type (e.g., continuous, ordinal, or nominal), measurement scale (e.g., interval,
    ratio), and any potential coding or transformation applied.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Data sources and context*—The origin of the data, the context in which it
    was collected, and any relevant background information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Data collection and sampling methods*—How the data was collected, any sampling
    methods applied, and any potential biases or limitations in the data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Domain knowledge*—Any specific domain knowledge or expertise you have about
    the subject matter of the dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Goals and interests*—Goals and interests for this analysis, such as identifying
    patterns, making predictions, evaluating a policy, understanding relationships
    between variables, and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Stakeholders*—Stakeholders who will benefit from the insights generated from
    your analysis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Temporal and spatial aspects*—Temporal or spatial components that may affect
    the research questions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Previous research*—Any knowledge of prior research or studies conducted using
    similar data or in the same domain.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Limitations and constraints*—Any limitations or constraints in the data or
    the analysis process that might affect the research questions you can explore.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collecting all this information at this stage will allow you to design an analytics
    process that won’t suddenly stop midway when you realize you are missing a critical
    bit of required data.
  prefs: []
  type: TYPE_NORMAL
- en: With all this information at hand, you may come up with a bunch of research
    questions, answers to which you will be able to synthesize into the answer to
    your business question. But are they really all relevant questions? Fortunately,
    you have access to a tool with hundreds of combined years of analytical experience.
    With its help, you can make sure you didn’t omit any relevant issues and check
    that all the research questions you are thinking of asking are indeed relevant
    to the analyzed business issue. Such help will be of exceptional value if your
    boss sends you an email with a pile of files and asks you to extract all possible
    insights from them.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see how a generative AI advisor tackles the problem of overly general
    business problems in the context of available data. We will use our example dataset
    of Brazilian e-commerce, specifically the data description, and ask generative
    AI about possible related research questions. Please note that, due to the size
    of the request, it’s presented in full as appendix A.
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**Propose research questions for the analysis
    of the following set of data:'
  prefs: []
  type: TYPE_NORMAL
- en: '1\. Data description and dictionaries: Data is composed of 8 DataFrames described
    in detail below:'
  prefs: []
  type: TYPE_NORMAL
- en: BORING DETAILS RELATED TO POINTS 1–5 (see appendix A)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '6\. Goals and interests: I would like to increase the business efficiency of
    the e-commerce shop which produced this data.'
  prefs: []
  type: TYPE_NORMAL
- en: '7\. Temporal and spatial aspects: Data comes from Brazil and describes orders
    from 2016 to 2018.'
  prefs: []
  type: TYPE_NORMAL
- en: '8\. Previous research: Unknown.'
  prefs: []
  type: TYPE_NORMAL
- en: '9\. Limitations and constraints: We would like to focus on descriptive analytics
    and avoid Machine Learning methods beyond linear or logistic regression.'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Response.png)**Based on the provided information, here
    are some potential research questions for your analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: What are the most popular product categories in terms of revenue, and how do
    their sales performance vary across different regions in Brazil?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does the average product price, freight value, and payment value differ
    across different product categories and regions?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the distribution of review scores across different product categories?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How does the order status (e.g., delivered, shipped, etc.) vary across different
    regions, product categories, and sellers?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the relationship between product attributes (e.g., weight, dimensions)
    and overhead costs (e.g., shipping costs)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What factors (e.g., delivery time, price, product attributes) contribute to
    differences in the average review score?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do different payment methods and the number of payment installments affect
    order completion rates and customer satisfaction?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the impact of delivery time (actual vs. estimated) on customer satisfaction
    and review scores?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Are there any significant differences in sales performance and customer satisfaction
    between sellers from different cities or states?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These research questions focus on descriptive analytics and should help you
    gain insights into the factors that influence sales performance, customer satisfaction,
    and overall business efficiency for the e-commerce shop.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, you can identify multiple areas of interest within seconds!
    While our initial inquiry didn’t specify objectives beyond enhancing business
    value, performing the suggested analytics should provide business stakeholders
    with information, allowing them to make significant steps toward the overarching
    goal of increasing business efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: I found 1,000 ways of not doing something  It would be best to talk to the business
    at this stage. They should think about whether such an insight will help them
    and if they want to prioritize it. Most importantly, this list will hopefully
    spark some new ideas about what kind of analysis they could immediately use to
    generate value.
  prefs: []
  type: TYPE_NORMAL
- en: This list is good enough for us to use as a base for our analysis. Of course,
    we might expect more of a typical analysis, like the Net Promoter Score (the most
    common method of measuring client satisfaction), but the result is not bad, not
    bad at all!
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Analysis design
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once you have a clear goal, you’ll probably feel energized and may be tempted
    to jump into creating pivot tables and charts . . . Sit down, sip a coffee, and
    wait until that feeling passes. In chapter 1, we advised you to *first* prepare
    a protocol of what your analysis will look like, what the possible results are,
    and what the *meaning* of each of these possible results would be. This element
    of experiment design is often overlooked, even in the academic research world,
    but you don’t want to learn from the worst. Getting some results and trying to
    fit a theory to them may result in worthless science fiction research papers (not
    to be mistaken with a respectable literature genre in which we’ve authored some
    titles ourselves); in business reality, this may lead to significant financial
    losses. Always plan ahead. No result should come as a surprise. Prepare a complete
    list of possible results and their meaning in the context of your business case.
    For example, if the current price is higher than the purchase price, sell; if
    they are equal, hold; otherwise buy.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, no protocol is set in stone. You will likely revise it after preprocessing
    your data (you may find that not all planned analyses are possible, or new ideas
    might strike you while scrolling through the data). Your stakeholders may change
    their priorities or focus areas when you’re halfway through. Even in this book
    we ignore our own advice—the speed of GenAI development outpaced our typing abilities,
    so we had to revisit parts of this book a couple of times. Pretending that we
    followed the assumed path would be a straight-up lie.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, cases where playing analysis by ear is justified are less common
    than the popularity of this approach. The sad fact is that as rare as proper experiment
    design is in an academic environment, it’s even rarer outside of it. You won’t
    find many good materials to guide you through the process. Even in the data (or
    text) corpus on which most generative AIs are trained, the cases where analytics
    design includes prior result analysis are most likely rare and far between, as
    none of the tested AI advisors considered it worth mentioning.
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**Can you propose a design of the analysis
    that would answer all these questions based on the provided data?'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Response.png)**To answer the proposed research questions,
    you can follow this general design for your analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Data Preparation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Merge relevant DataFrames to create a comprehensive dataset:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Merge `df_product_category_translation` with `df_products` to get product category
    names in English.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Merge `df_orders`, `df_customers`, and `df_order_items` using `customer_ id`
    and `order_id`.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Merge the resulting DataFrame with `df_products` using `product_id`.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Merge the DataFrame with `df_order_payments` using `order_id`.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Merge the DataFrame with `df_order_reviews` using `order_id`.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Merge the DataFrame with `df_sellers` using `seller_id`.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Clean the dataset:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Handle missing values (e.g., impute, drop, or leave as is, depending on the
    context).
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Convert data types if necessary (e.g., timestamps, floats, and integers).
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Create new variables, such as delivery time difference (actual vs. estimated),
    if needed.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Descriptive Analysis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compute summary statistics for key variables (e.g., sales volume, revenue, product
    attributes, and review scores).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Create visualizations to explore patterns and trends in the data (e.g., bar
    charts, line charts, scatter plots, and heatmaps).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Conduct cross-tabulations and comparisons across different categories (e.g.,
    regions, product categories, and sellers).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Inferential Analysis:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Test for statistically significant differences between groups (e.g., using t-tests,
    ANOVA, or chi-square tests).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform correlation analyses to identify relationships between variables (e.g.,
    product attributes and sales performance).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Conduct linear or logistic regression analyses to identify predictors of key
    outcomes (e.g., sales volume, revenue, and customer satisfaction).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Interpretation and Discussion:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Summarize key findings from the descriptive and inferential analyses.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Discuss potential explanations for the observed patterns and relationships.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Identify potential limitations of the analysis and areas for future research.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Conclusion and Recommendations:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw conclusions based on the analysis findings.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Provide actionable recommendations to improve the e-commerce shop’s business
    efficiency.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Following this general design for your analysis will help you systematically
    answer the proposed research questions using the provided data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us share a little story, or actually more than a dozen we encountered,
    fitting the same scenario: The analyst performs a regression analysis to explore
    the relationship between social media advertising spend and sales. The results
    indicate a statistically significant correlation between the amount spent on social
    media ads and increased sales. The company decides to increase social media spending,
    only to find out their return on investment (RoI) is in the negative. To make
    things worse, the budget diverted to social media campaigns weakened other business
    functions. That is a typical example of a poor analytics design with a perfectly
    avoidable outcome.'
  prefs: []
  type: TYPE_NORMAL
- en: It is not our goal to follow in the footsteps of Don Quixote, pursuing lofty
    ideals that we will never obtain, but you should spend some time inquiring about
    the possible results of different types of analytics and their meanings. In some
    cases, predicting all possible outcomes is not feasible. For example, you don’t
    want to come up with all possible variants of a chart you’re expected to generate.
    But you should have a general idea of expected shapes or traces. We touched upon
    this previously when we discussed data cleaning. You need to understand what’s
    expected to notice what’s relevant that’s unexpected. In some analyses, you should
    spend more time thinking about the meaning of the results. A good example here
    would be correlation analysis.
  prefs: []
  type: TYPE_NORMAL
- en: What does correlation mean from the business perspective? How big a correlation
    is actually *meaningfu**l*?(Do not mistake this for statistical significance,
    as did the protagonists of the earlier story.) When calculating regression, what
    is the predictive power you require? There are no ready-to-use templates to be
    filled out. Your domain knowledge and understanding of the business will allow
    you to distinguish between valuable and misleading insights. Generative AI can
    help you, but don’t expect it to do all the heavy lifting for you. You need to
    talk to your business people to be able to deeply integrate domain knowledge into
    your analytical pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: In the generative AI’s proposed design, there is one popularity-bias-driven
    element—the content of point 3.a, the methods for statistical testing. We’ll explain
    our gripe with that particular point in the introduction to section 3.5\.
  prefs: []
  type: TYPE_NORMAL
- en: Other than that, the execution of this plan may indeed extract some insight
    from the data we meticulously cleaned.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Descriptive data analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many people approach data analysis (both stakeholders and naive newcomers to
    the job), with quite high expectations. Wouldn’t it be great to just drop all
    your company’s data into a magical box and receive back a set of simple instructions,
    like “Fire Sue from the third floor, as her micromanagement style kills the soul
    and effectiveness of her team. While you’re firing people, don’t forget Joe from
    packaging, as he’s the reason behind 20% of your returns”? Or, “Add the pink *Buy
    now!* button in the left-right corner of your landing page, and you’ll get 61.73%
    more sales in the first week”?
  prefs: []
  type: TYPE_NORMAL
- en: 'Going from data to information to insight is a process. It can be somewhat
    automated or sped up by the tools, but a lot of data analysis is just that—*a**nalyzin**g*:
    a detailed examination of the elements or structure of the data. Despite the best
    efforts of AI-focused companies, the part where someone needs to describe data
    elements and structure is not going anywhere, primarily because it offers an overview
    of business performance. Various statistical measures and visualization techniques
    enable you to identify patterns, relationships, and anomalies within datasets.
    You can use descriptive analytics to understand your business operations, customer
    behavior, and market dynamics better, laying a solid foundation for informed decision-making
    and future analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: It doesn’t matter if you work for an organization, big or small. Analyzing data
    from a restaurant, you may use this approach to identify the most ordered items
    versus those rarely ordered. While working in the corporate office of the restaurant
    chain, you may use it to determine the most popular items by location and time
    of day. This insight could then guide decisions around stock management, staff
    scheduling, and targeted promotions, ultimately enhancing operational efficiency
    and customer satisfaction. Despite its simplicity, descriptive analytics is crucial
    in paving your way toward more advanced analytics methods, such as predictive
    and prescriptive analytics.
  prefs: []
  type: TYPE_NORMAL
- en: You should describe your data using *nomen omen* descriptive statistics, including
    mean, median, mode, standard deviation, and percentile values. You should also
    prepare visualizations like bar charts, histograms, and scatter plots to further
    enhance your ability to identify and examine patterns and trends within the data.
  prefs: []
  type: TYPE_NORMAL
- en: Four of the nine research questions initially proposed by generative AI can
    be addressed using these methods. We will do just that in the following subsections.
    The other five will require a somewhat different toolbox, presented in section
    3.4.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.1 Popularity of product categories
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Recall the question provided by ChatGPT: “What are the most popular product
    categories in terms of revenue, and how do their sales performance vary across
    different regions in Brazil?” If working with e-commerce data makes you stifle
    your yawn, don’t worry. The same methodology is helpful in many business areas.
    Let’s explore some examples where this approach can provide you with valuable
    insights:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Retail, e-commerce, and manufacturing*—Beyond product categories, this method
    can be applied to understand customer segments’ buying behavior across different
    regions or time periods, such as analyzing seasonal trends in purchasing or the
    effect of marketing campaigns on various demographics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Healthcare*—In healthcare, similar techniques can be used to analyze the distribution
    of disease incidence or treatment outcomes across different geographical areas
    and demographic groups. This can help in resource allocation, understanding disease
    spread patterns, and tailoring public health interventions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Financial services*—For banks and financial institutions, analyzing the distribution
    of loan or credit card defaults by product type and geographic region can help
    in risk management and in designing targeted financial products.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Supply chain and logistics*—Here, the method can be used to analyze the performance
    of different logistics routes or transportation methods, categorizing them by
    cost, efficiency, or environmental impact across various regions. This can aid
    in optimizing routes, reducing costs, and improving sustainability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Telecommunications*—Analyzing the usage patterns of different service plans
    or products (e.g., data plans, voice plans) across regions can help in tailoring
    offerings, improving network infrastructure, and identifying new market opportunities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Utilities and energy*—In this sector, analyzing consumption patterns of different
    energy sources (e.g., electricity, gas) across regions can inform infrastructure
    development, energy conservation efforts, and pricing strategies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Tourism and hospitality*—Understanding the preferences for different types
    of accommodations or travel experiences across various tourist demographics can
    help businesses tailor their services, optimize pricing strategies, and improve
    customer satisfaction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Real estate*—Analyzing the performance of different types of properties (e.g.,
    residential versus commercial) across regions can inform investment strategies,
    property development, and marketing efforts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Education*—Evaluating the performance of different educational programs or
    courses across demographic groups can help educational institutions tailor their
    offerings, improve student outcomes, and optimize resource allocations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Government and public policy*—Governments can use this method to analyze various
    policy impacts across regions, such as the effectiveness of economic incentives,
    public health initiatives, or infrastructure projects, enabling more informed
    decision-making.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For each of these examples, the method we’ll look at next can help you uncover
    patterns and insights that might not be immediately apparent. You can really support
    your businesses by categorizing data across meaningful dimensions (like product
    categories, service types, or demographic segments) and analyzing their performance
    across different regions or groups.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get back to work. We will start with the simple task of testing which
    product categories bring the most revenue. It’s a fundamental analysis required
    for product portfolio optimization. We can apply the same methodology to evaluate
    the performance of different groups quickly.
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**Provide me with a complete Python code solution
    required to answer this question on the most common product categories in the
    dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Response.png)**To answer the question about the most common
    product categories in the dataset, you can follow these steps in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: Import necessary libraries
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Read and merge the required DataFrames
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform the analysis to find the most common product categories
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Display the results
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here’s the complete Python code solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: This code will read the data, merge the DataFrames, count the occurrences of
    each product category, and display the top 10 most common categories.
  prefs: []
  type: TYPE_NORMAL
- en: 'Generative AI failed to understand what question we were referring to. We hoped
    it would recall the question it itself proposed just two prompts earlier: “What
    are the most popular product categories in terms of sales volume and revenue,
    and how do their sales performance vary across different regions in Brazil?” Instead,
    it provided us with unhelpful output related to identifying the most common product
    categories instead of their sales performance. Let this be a warning that you
    shouldn’t always rely on generative AI to recall your conversation correctly if
    your prompt is vague.'
  prefs: []
  type: TYPE_NORMAL
- en: Tomayto, tomahto  Sometimes, the difference between the question you asked and
    the question generative AI answered might be minute and hard to spot, but inferring
    any insight from the answer to a question that’s different than you asked may
    have far-reaching implications.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try to be more specific.
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**Provide me with a complete Python code solution
    required to answer the question, “What are the most popular product categories
    in terms of sales volume and revenue, and how do their sales performance vary
    across different regions in Brazil?”'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Response.png)**To answer this question, you need to follow
    these steps in Python:'
  prefs: []
  type: TYPE_NORMAL
- en: Import necessary libraries
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Read and merge the required DataFrames
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Perform the analysis to find the most popular product categories in terms of
    sales volume and revenue and how their sales performance varies across different
    regions in Brazil
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Display the results
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here’s the complete Python code solution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Replace the file names `df_products.csv`, `df_product_category_translation .csv`,
    `df_order_items.csv`, `df_orders.csv`, and `df_customers.csv` with the appropriate
    file names for your dataset. This code will read the data, merge the DataFrames,
    analyze the sales volume and revenue for each product category across different
    regions in Brazil, and display the results.
  prefs: []
  type: TYPE_NORMAL
- en: The interesting fact is that, following the language of the conversation, ChatGPT
    assumed we would be interested in English names of categories rather than Portuguese,
    even though it itself is fluent in both languages.
  prefs: []
  type: TYPE_NORMAL
- en: The resulting DataFrame has 54 columns. If only generative AI would suggest
    a way to make interpreting the results easier, right? Well, yes and no. It is
    important to remember that we don’t leave our own analytical skills at the front
    door when we let generative AI help us out. Any experienced data analyst could
    tell you that a large DataFrame such as this will benefit from the visualization
    of the results. So before we go further with the steps proposed by generative
    AI, we’ll take a moment to get some visuals.
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**Can you propose visualization methods for
    `sales_by_region` DataFrame, which would allow answering the posed research question?'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Response.png)**Certainly! To visualize the `sales_by_region`
    DataFrame and answer the research question effectively, you can use the following
    visualization methods:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Bar plot: You can create a grouped bar plot to compare sales volume and revenue
    for each product category across different regions in Brazil. The x-axis will
    represent the regions, and the y-axis will represent the sales volume and revenue.
    You can use different colors for each product category to distinguish them.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '2\. Heatmap: Another way to visualize the sales performance across different
    regions in Brazil is by using a heatmap. You can create a pivot table with regions
    as rows, product categories as columns, and sales volume and revenue as values.
    Then, you can use a heatmap to represent the sales performance using a color gradient.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: These visualization methods will help you better understand the sales performance
    of different product categories across various regions in Brazil.
  prefs: []
  type: TYPE_NORMAL
- en: 'This code, instead of producing graphs, resulted in a warning and the following
    error message:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We present this transcript as a warning. Bugs and problems *are* to be expected.
    Getting generative AI to debug the code can take some effort, as appendix B shows.
    However, this exercise resulted in two conclusions worth presenting here:'
  prefs: []
  type: TYPE_NORMAL
- en: Generative AIs may provide you with incorrect code, and more than once at that.
    We can still use them to debug the code (with more or less success, depending
    on the language), as it may take less time than learning all the intricacies of
    syntax from the ground up yourself.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You should not leave the debugging process to generative AI completely, as it
    doesn’t have access to the results. Looking for oddities in the output and informing
    your AI advisor about them significantly speeds up the process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Thanks to the provided code, we were able to generate four figures: two bar
    plots and two heatmaps.'
  prefs: []
  type: TYPE_NORMAL
- en: The bar plots may not be suitable for adding to a presentation destined for
    an SD projector. In figure 3.1 you can find one of them; the second one is almost
    identical. To make it fit the page, we dropped the legend containing 71 categories
    (they are still present on the figure generated in the accompanying Jupyter notebook).
    It’s still unreadable, but that’s hardly generative AI’s fault. We are trying
    to visualize almost six thousand data points, after all!
  prefs: []
  type: TYPE_NORMAL
- en: To make this figure more consumable, we can ask our AI advisor to break it down
    by state or product group, but we’ll end up with dozens of charts. Let’s check
    if using heatmaps will save us this trouble. A visualization of the same data
    is presented in figure 3.2\. Both heatmaps are available in the Jupyter Notebook
    in the book’s GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: Unfortunately, the generated heatmap is not much more readable, is it? We printed
    this indecipherable image in this book as valuable learning material.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F01_Siwiak3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1 Bar plot of sales volume by product category and region
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F02_Siwiak3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.2 Heatmap of sales revenue by product category and region
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: You will see unreadable graphics in your work every now and then. If you’re
    asked to prepare “something that will fit a PowerPoint slide,” it can really ruin
    your day. In such a case, you need to consider whether you face an inherent issue,
    like the number of bars in figure 3.1, or if the visual clutter can be remedied
    with a simple reformatting. If you’re unsure how to tweak your visualization software’s
    settings, generative AI is there for you! You should get the solution and an explanation
    to help you in your future work.
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**Can you modify the heatmap code so the numbers
    in the matrix are printed in a smaller font?'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Response.png)**Sure! You can adjust the font size of the
    numbers in the heatmap by using the `annot_kws` parameter within the `sns.heatmap`
    function. You can set the font size to a specific value as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: In this example, I set the font size to 6\. You can change this value as needed
    to achieve the desired appearance.
  prefs: []
  type: TYPE_NORMAL
- en: Before we proceed to present the result, we need to note that the `revenue_df`
    DataFrame mentioned in the code was defined in the previously mentioned appendix
    B, where we show a long and winding road to the correct code. This time, however,
    things progressed as expected. The result is presented in figure 3.3.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F03_Siwiak3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.3 Heatmap of sales revenue by product category by state, reformatted
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The overall result is now possible to analyze. Maybe not so much in terms of
    reading individual numbers, but that’s precisely the purpose of the heatmap. It’s
    meant to pinpoint outliers in the dimensional distribution.
  prefs: []
  type: TYPE_NORMAL
- en: The other visualization proposed is stacked bar plots, which are included in
    the book’s GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: At this stage, we are well equipped with visualizations for drawing business
    conclusions on the most popular product categories. Following our AI advisor’s
    guidance, we will now move on to research their performance.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.2 Performance of products in their categories and regions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As a reminder, based on our data availability, our generative AI advisor proposed
    the following approach to measuring performance: “How does the average product
    price, freight value, and payment value differ across different product categories
    and regions?” The information on the performance and behavior of products across
    categories and different locations is a trove of information for the business.
    Using this methodology, you may support decisions driving sales and marketing
    efforts. For example, best practices from best-performing regions could be used
    to boost the efficiency of weaker ones, or some products could be dropped and
    replaced by more profitable ones.'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, this one application wouldn’t be worth reading about unless you’re
    genuinely excited by marketing. Fortunately, by applying this analytical framework,
    you can explore a lot of different variables to extract insights across various
    industries. Here are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Customer lifetime value* *(CLV)* *and acquisition cost*—In industries like
    e-commerce, telecommunications, or financial services, analyzing the relationship
    between the CLV and the cost of acquiring customers across different products
    or services and regions can help optimize marketing spend and target customer
    segments more effectively.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Service response time and customer satisfaction*—For service-oriented sectors
    like healthcare, logistics, or customer support, examining how response times
    relate to customer satisfaction across different service categories and regions
    can pinpoint areas for improvement and guide resource allocation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Inventory turnover and sales performance*—In retail and manufacturing, analyzing
    the relationship between inventory turnover rates and sales performance across
    product categories and regions can help manage inventory more efficiently, reduce
    holding costs, and identify demand patterns.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Renewable energy production and consumption*—In the utilities and energy sector,
    examining the relationship between renewable energy production (e.g., solar, wind)
    and consumption across different regions can inform infrastructure investments
    and sustainability initiatives.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Occupancy rates and rental yields*—In real estate, particularly within the
    hospitality and residential sectors, analyzing the relationship between occupancy
    rates and rental yields across different property types and locations can aid
    investment decisions and pricing strategies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Utilization rates and operational costs*—For transportation and logistics,
    looking at how vehicle or asset utilization rates relate to operational costs
    across different regions or routes can optimize operations and improve profitability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*R&D spend and innovation outcomes*—In technology and pharmaceutical industries,
    analyzing the relationship between R&D spending and outcomes such as patent filings
    or product launches across different categories can guide investment strategies
    and innovation focus.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Digital marketing spend and engagement metrics*—For businesses investing in
    digital marketing, examining how spending relates to engagement metrics (e.g.,
    click-through rates, conversion rates) across different campaigns or regions can
    optimize marketing strategies and budget allocation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Workforce training investment and productivity gains*—In sectors with significant
    human capital, such as education, healthcare, or manufacturing, analyzing the
    relationship between investment in workforce training and productivity gains across
    different departments or locations can inform talent development strategies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Sustainability initiatives and corporate performance*—Across industries, examining
    the relationship between investments in sustainability initiatives (e.g., carbon
    footprint reduction, waste management) and corporate performance metrics (e.g.,
    profitability, brand perception) can guide corporate social responsibility efforts
    and investment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each of these examples applies the analytical approach of exploring relationships
    and variations across categories and regions to different variables.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at how we can capture performance differences between categories,
    as they may be valuable for business decision-making.
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**Provide me with a complete Python code solution
    required to answer the question, “What are the most popular product categories
    in terms of sales volume and revenue, and how do their sales performance vary
    across different regions in Brazil?”'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Response.png)**To answer this question, you can use the
    merged DataFrame that you created earlier and perform a `groupby` operation on
    product categories and regions. You will then calculate the average product price,
    freight value, and payment value for each group.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the Python code to achieve this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The `average_values` DataFrame will contain the average product price, freight
    value, and payment value for each product category and region (state). You can
    further analyze this DataFrame using various visualization techniques, such as
    bar charts or heatmaps, to better understand the differences across product categories
    and regions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We presented the received answer in its entirety, as there are three noteworthy
    elements:'
  prefs: []
  type: TYPE_NORMAL
- en: The first is generative AI’s ability to predict our next steps and suggest visualization
    techniques.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second is that it considers the readability of the column names.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The last one is, unfortunately, that it used the wrong name of the DataFrame.
    We never defined a `merged_data` DataFrame.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We want you to pay attention now. You could assume that the `merged_data` DataFrame
    is just `df_merge` from the previous example. But, as we repeat over and over,
    cultivate your paranoia! If there is any doubt, you should double- and triple-check
    to make sure what you are analyzing is indeed what you intend to analyze!
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**Can you write the columns that should be
    in the `merged_data` DataFrame you used?'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Response.png)**Certainly! Based on the data we discussed
    earlier, the `merged_data` DataFrame should contain the following columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '`product_category_name_english` (`str`) - category name in English'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`customer_state` (`str`) - customer state'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`price` (`float64`) - item price'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`freight_value` (`float64`) - item freight value (if an order has more than
    one item, the freight value is split between items)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`payment_value` (`float64`) - transaction value'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To create the `merged_data` DataFrame, you would need to merge the necessary
    DataFrames, as discussed earlier in the conversation. Here’s a quick recap of
    how to create the `merged_data` DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: Merge `df_order_items` with `df_orders` on `order_id`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Merge the result with `df_product_category_translation` on `product_category_name`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Merge the result with `df_customers` on `customer_id`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Merge the result with `df_order_payments` on `order_id`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The resulting `merged_data` DataFrame should contain the columns listed above,
    which can be used to answer the question related to average product price, freight
    value, and payment value across different product categories and regions.
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, `merged_data`, hallucinated by ChatGPT, and `df_merged`, which
    we actually have, do differ, and significantly! You would get an error if you
    tried to run the original code simply by replacing `merged_data` with `df_merged`.
  prefs: []
  type: TYPE_NORMAL
- en: Keeping the bells ringing  The longer the conversation, the more likely generative
    AI is to lose track of nuances of the conversation. To ensure the proper contextual
    awareness of your AI advisor, when you notice it hallucinating about provided
    data structures, paste it a reminder with a detailed description of the data in
    question, or move on to a new conversation session.
  prefs: []
  type: TYPE_NORMAL
- en: Remember, that’s not the worst-case scenario. Errors that break the code are
    simple to spot. Errors where things go smoothly, but the results are based on
    wrong data, are a different kettle of fish. Consider this fair warning.
  prefs: []
  type: TYPE_NORMAL
- en: The resulting DataFrame has 1,356 rows. Yet again, we should probably think
    of visualizing the result.
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**Could you propose a visualization method
    suitable for data in the generated `average_values` DataFrame?'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Response.png)**Given the structure of the `average_values`
    DataFrame, you can create:'
  prefs: []
  type: TYPE_NORMAL
- en: A scatterplot matrix (pair plot) to visualize the relationships between `average_
    product_price`, `average_freight_value`, and `average_payment_value` across different
    product categories and states. You can use seaborn’s `pairplot` function for this
    purpose.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here’s the code to create a scatterplot matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This will give you a scatterplot matrix that shows the relationships between
    the average product price, average freight value, and average payment value for
    each product category in each state. The points in the scatterplots will be colored
    according to the state.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Three separate bar plots - one for each value of interest (average product
    price, average freight value, and average payment value). These bar plots will
    display the product categories on the x-axis and the corresponding values on the
    y-axis, with each bar representing a state.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here’s Python code to create these bar plots using the seaborn library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The resulting scatterplot is presented as figure 3.4, and one of the bar charts
    is presented as figure 3.5\.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F04_Siwiak3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.4 Scatterplot of relationships between average payment values, average
    freight values, and average product prices
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F05_Siwiak3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.5 Grouped bar plot showing the relation of average product price per
    category per region
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The piece of code responsible for explicitly naming the chart axes didn’t work
    correctly. Fortunately, the DataFrame column names used by matplotlib as a default
    are informative enough. We left it as is to drive home a more general point: Sometimes,
    in your work, especially under time pressure, you’ll be tempted to “save time”
    on naming conventions. Quickly, all variables will become `x,` `tmp`, or `var1`—it’s
    a terrible habit. You’ll agree with us after you open a file you wrote two months
    ago. You’re saving seconds now to lose literally hours later. Using informative
    variable names is a time saver. Of course, being too verbose won’t do much for
    your code readability either. A variable named `second_attempt_to_average_the_sales_in_Joe_Smiths_analysis_
    of_his_shop` may be overkill.'
  prefs: []
  type: TYPE_NORMAL
- en: The resulting figure 3.5 may take some time (and a magnifying glass or two)
    to analyze, but it should suffice to provide some business insight into product
    performance. If you lack a magnifying glass of sufficient magnitude, we will discuss
    utilizing generative AI to cluster product categories in the next section, where
    we’ll analyze product perception.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.3 Review scores distribution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The value of knowing the distribution of review scores is relatively apparent.
    It’s critical feedback about how the products are perceived by the people paying
    for them. As we mentioned before, there are certain methods and measures for representing
    overall client satisfaction as a single number. Still, we’ll forget about them
    for the time being (pretending we are working on unknown data) and try to answer
    the question proposed by our AI advisor: “What is the distribution of review scores
    across different product categories?”'
  prefs: []
  type: TYPE_NORMAL
- en: If you feel like skipping this exercise because you know how to make a bar chart
    of a single variable in Excel, you can skip it. We’re not rediscovering the wheel
    here. However, if you feel like spending a minute learning how generative AI can
    help you work on the granularity of your results, read on!
  prefs: []
  type: TYPE_NORMAL
- en: Repetition is a mother of learning  We previously wrote about the issues with
    how far back generative AI can reach in its conversation context analysis. Every
    now and then, you should clarify whether it remembers all the details correctly.
    If there is a problem, you can remind it of the full data description instead
    of correcting one variable after another.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s see if generative AI will provide any helpful twists to this simple exercise.
    After jogging generative AI’s memory on the structure of the involved DataFrames
    (as presented in appendix A), we received the following answer to our question.
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**How should I extract information on the
    distribution of review scores, and how does it vary across different product categories
    and sellers?'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Response.png)**To analyze the distribution of review scores
    across different product categories and sellers, you can follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Merge the required DataFrames: You may need to merge the `reviews`, `orders`,
    `order_items`, and `products` DataFrames to obtain a combined DataFrame containing
    review scores, product categories, and seller information.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Group the combined DataFrame by product categories and sellers: Use the `groupby()`
    function to group the data by `product_category_name_english` and `seller_id`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Calculate the distribution of review scores: Use the `value_counts()` function
    to compute the count of each review score within each group.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here’s the code to perform the above steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Now, the `review_score_distribution` DataFrame contains the distribution of
    review scores for each combination of product category and seller. To visualize
    this data, you could use a stacked bar chart, heatmap, or other suitable visualization
    method, depending on your preference.
  prefs: []
  type: TYPE_NORMAL
- en: The code worked as advertised, but the problem is that we again beat our own
    record, and now we have a DataFrame with 14,503 rows. We’re going to need visualizations
    again if we’re to make any sense of this.
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**How should I visualize the `review_score_distribution`
    DataFrame to get to meaningful conclusions?'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Response.png)**For visualizing the `review_score_distribution`
    DataFrame, you can use a grouped bar chart, where the x-axis represents the product
    categories, the y-axis represents the count of reviews, and different colors or
    patterns represent the different review scores. This will allow you to see how
    review scores are distributed across product categories and compare their performance
    in terms of customer satisfaction.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a code snippet using Seaborn to create a grouped bar chart:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: This plot will give you an idea of how different product categories perform
    in terms of customer reviews. Keep in mind that this plot might be quite large
    and hard to read depending on the number of product categories in your dataset.
    You may want to filter or aggregate the data further to focus on specific categories
    or review score ranges.
  prefs: []
  type: TYPE_NORMAL
- en: It looks like generative AI was able to estimate that the size of the results
    will be bigger than the previous ones. Figure 3.6 shows that it wasn’t wrong.
    At this time, the advised course of action would be a trip to a stakeholder, who
    will receive this analysis and a solid heart-to-heart. They could decide to accept
    the oversized chart and promise never to print it, or they could propose an aggregation
    meaningful to them.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F06_Siwiak3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.6 Grouped bar plot showing review score counts by product category
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: For the sake of argument, we will assume that this analysis is being prepared
    for an elevator pitch and, as such, cannot be approved in advance. Let’s divide
    the reviews into positive (4 or 5 points) and negative (1, 2, 3 points), with
    us arbitrarily deciding what scores are considered positive (and negative). Getting
    the code from generative AI is straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.1 Generating a grouped bar plot
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: As shown in figure 3.7, the result is a bit more readable than figure 3.6\.
    With “bit” being the key word.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F07_Siwiak3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.7 Grouped bar plot showing aggregated review score counts by product
    category
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: If it’s genuinely going to serve as an elevator pitch, we need to do better.
    That means we’ll need to aggregate product categories. However, our dataset doesn’t
    have an ontology categorizing products into even broader categories. Fortunately,
    generative AI is really good at providing first approximations in this type of
    task.
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**I would like to add the aggregation by product
    category. Propose the grouping and explanation of the grouping decision for the
    following list of categories:'
  prefs: []
  type: TYPE_NORMAL
- en: '[<HERE WE PROVIDED A FULL LIST OF CATEGORIES>]'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Response.png)**One way to group the product categories
    is by considering their main industry or area of interest. This can make the visualization
    more manageable and reveal trends at a higher level. Here’s a proposed grouping
    for the given list of categories:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Home & Furniture: `[''bed_bath_table'',` `''furniture_bedroom'',` `''furniture_
    decor'',` `''furniture_living_room'',` `''furniture_mattress_and_upholstery'',`
    `''kitchen_dining_laundry_garden_furniture'',` `''home_confort'', ''home_ comfort_2'',
    ''home_construction'', ''housewares'']`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Electronics & Computers: `[''audio'', ''computers'', ''computers_accessories'',
    ''electronics'', ''telephony'', ''tablets_printing_image'']`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Fashion: `[''fashio_female_clothing'',` `''fashion_bags_accessories'', ''fashion_childrens_clothes'',`
    `''fashion_male_clothing'',` `''fashion_ shoes'',` `''fashion_sport'',` `''fashion_underwear_beach'']`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Entertainment: `[''art'',` `''arts_and_craftmanship'',` `''books_general_ interest'',
    ''books_imported'',` `''books_technical'',` `''cds_dvds_musicals'',` `''christmas_supplies'',`
    `''consoles_games'',` `''cool_stuff'', ''cine_photo'',` `''dvds_blu_ray'',` `''music'',`
    `''musical_instruments'', ''toys'',` `''watches_ gifts'']`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sports & Leisure: `[''sports_leisure'',` `''garden_tools'']`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Health & Beauty: `[''health_beauty'',` `''perfumery'']`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Baby & Kids: `[''baby'',` `''diapers_and_hygiene'',` `''fashion_childrens_
    clothes'']`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Office & Industry: `[''agro_industry_and_commerce'',` `''industry_commerce_
    and_business'',` `''office_furniture'',` `''stationery'']`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Home Appliances: `[''air_conditioning'',` `''home_appliances'',` `''home_ appliances_2'',`
    `''small_appliances'',` `''small_appliances_home_oven_and_ coffee'']`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Tools & Construction: `[''construction_tools_construction'',` `''construction_
    tools_lights'',` `''construction_tools_safety'',` `''costruction_tools_ garden'',
    ''costruction_tools_tools'']`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Auto & Accessories: `[''auto'',` `''fixed_telephony'']`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Food & Drink: `[''food'',` `''food_drink'',` `''drinks'']`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Miscellaneous: `[''flowers'',` `''la_cuisine'',` `''luggage_accessories'',`
    `''market_place'', ''party_supplies'', ''pet_shop'', ''security_and_services'',
    ''signaling_and_security'']`'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You can create a new column in the `review_score_distribution` DataFrame to
    represent these groupings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Now you can visualize the aggregated review score distribution for these groupings
    using a grouped bar chart or a stacked bar chart, as discussed earlier.
  prefs: []
  type: TYPE_NORMAL
- en: Our generative AI advisor presented an impressive level of understanding of
    the task. If you are interested in our discussion with ChatGPT on placing `fixed_telephony`
    in “Auto & Accessories” and making it a complete `category_mapping` dictionary,
    we propose reading appendix C.
  prefs: []
  type: TYPE_NORMAL
- en: As seen in figure 3.8, the result is much more comprehensible than previous
    versions.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F08_Siwiak3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.8 Grouped bar plot showing aggregated review score counts by product
    categories aggregated into product groups
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Having secured analyzable results of the review score distribution, we can now
    move on to the last of the descriptive analyses—the description of order statuses
    and their distributions.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.4 Order status
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are multiple reasons to research order statuses, from identifying problems
    with logging systems to improving the user experience. To answer the question,
    “How does the order status (e.g., delivered, shipped, etc.) vary across different
    regions, product categories, and sellers?” we will extract information about types
    of order statuses across categories and regions. Later, in section 3.4, we will
    do a more advanced regression analysis on delivery times.
  prefs: []
  type: TYPE_NORMAL
- en: This will be a recurring theme in your work. You will take a first glance at
    the data when cleaning it, a second during descriptive analytics, and sometimes
    then decide what data is rich enough to drive data modeling. This may seem inconsistent
    with our previous remarks about having a strict protocol, but that’s not the case.
    Your protocol should be flexible enough to allow for evaluation and decisions.
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI will readily provide the code needed to merge the necessary DataFrames
    to get the required information in one place, and then to group and analyze the
    data.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.2 Preparing DataFrame with order statuses
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The code is simple enough to work without a hitch. A glance at the resulting
    DataFrame shows that some orders have the status of *approved* but have apparently
    never shipped. This could be investigated further.
  prefs: []
  type: TYPE_NORMAL
- en: However, with a result including 7,524 rows, we need something worth a thousand
    words to analyze these results. Fortunately, in data analytics, as we prove over
    and over again, the power of generative AI goes way beyond code generation.
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**What type of visualization would you propose
    for the previously generated `status_ distribution_sorted` DataFrame?'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Response.png)**For the `status_distribution_sorted` DataFrame,
    a stacked bar chart would be an appropriate visualization. This will allow you
    to display the distribution of order statuses for each product category while
    also making it easy to compare the total number of orders among product categories.'
  prefs: []
  type: TYPE_NORMAL
- en: To create a stacked bar chart, we need to use the pandas `plot` function with
    the `kind='bar'`, `vstacked=True` parameters. First, we need to reshape the `status_
    distribution_sorted` DataFrame into a format suitable for creating a stacked bar
    chart.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the code to create the stacked bar chart for the `status_distribution_
    sorted` DataFrame:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This code pivots the `status_distribution_sorted` DataFrame, creating a new
    DataFrame with the product categories as the index and order statuses as columns.
    It then creates a stacked bar chart using the plot function with `kind='bar'`
    and `stacked=True` parameters. The remaining lines adjust the figure size, font
    size, and rotation of the x-axis labels for better readability.
  prefs: []
  type: TYPE_NORMAL
- en: The result of this code is presented in figure 3.9\.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F09_Siwiak3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.9 Stacked bar plot showing order status delivery counts per product
    category
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Though it might be challenging to discern from the chart, due to its scale,
    the lion’s share of statuses are marked as “delivered,” irrespective of the product
    category. The occurrences of other statuses are minimal in comparison.
  prefs: []
  type: TYPE_NORMAL
- en: If we were to just going to generate another bar chart, we wouldn’t bother you
    with reading this section. Let’s try to go beyond the obvious and add our own
    twist to the question proposed by our AI advisor.
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**Are there any patterns in order delivery
    time based on the customer’s and seller’s location?'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Response.png)**To analyze patterns in order delivery time
    based on customer’s and seller’s location, we can first calculate the delivery
    time for each order and then visualize the relationship between delivery time,
    customer’s location, and seller’s location.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculate delivery time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We will use the `df_orders` DataFrame and calculate the delivery time as the
    difference between `order_delivered_customer_date` and `order_purchase_ timestamp`.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '2\. Merge necessary columns from `df_customers` and `df_sellers` DataFrames
    with `df_orders`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '3\. Visualize the relationship between delivery time, customer’s location,
    and seller’s location:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A suitable visualization method for this purpose is a scatter plot, where we
    can use the customer’s state and seller’s state on the x and y axes, respectively,
    and color the points based on the delivery time.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: This visualization will help us identify any patterns or trends in delivery
    time based on the customer’s and seller’s locations. Keep in mind that this is
    a high-level overview, and further analysis may be required to draw more specific
    conclusions.
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, this time we received the end-to-end solution. From merging required
    DataFrames, to feature engineering (creating a completely new column), to visualization!
    That’s impressive.
  prefs: []
  type: TYPE_NORMAL
- en: In the notebook in our GitHub repository, you’ll notice that the initial visualization
    is less than impressive. The data distribution is clearly skewed toward low values,
    while high-value outliers “hijacked” the upper part of the color range, leaving
    the vast majority of results barely distinguishable. In addition, the order of
    regions on both axes is random. However, it wasn’t much work to get code to deal
    with these problems.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.3 Creating a log-scaled heatmap
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Applying generative AI’s suggestion to use the logarithmic scale solved the
    “blueiness” problem we encountered, and the alphabetical order of regions makes
    finding relevant pairs much easier. As you can see in figure 3.10, the result
    is a perfectly analyzable image; we will conduct the analysis itself in chapter
    4\. For now, it’s enough to see that there are indeed differences in delivery
    times depending on the region.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F10_Siwiak3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.10 Scatterplot of delivery times from one state to another, colored
    by a log-norm scale, with identical order of elements on both axes
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: “when we talk about tastes and colors, there is nothing to be disputed” Certain
    elements of human perception may be hard for a computer program to notice. If
    done properly, things like the distribution of colors or order of elements will
    enhance the human ability to absorb the information presented. You can try to
    get some theoretical background and sound advice from generative AI, but the responsibility
    for the clarity and readability of the final results is on you.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you learned that generative AI can provide you with the code
    required to perform all the necessary elements of descriptive analytics. It’s
    not error-free, but you must remember that LLMs do not run actual calculations
    or transformations, despite being computer programs. They generate answers based
    on their understanding of the language patterns involved in mathematical reasoning
    rather than by performing a numerical calculation. The accuracy of the provided
    answers depends on how well-represented related mathematical patterns are in the
    data they were trained on. However, descriptive analysis is relatively easy. Let’s
    see how well our AI advisor fares when facing more demanding tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Inferential analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, you mainly visualized data, grouping it this way or
    another along the way. Luckily (from the business decision-making perspective),
    or unluckily (from your workload perspective), there is more to descriptive analysis
    than bar and line charts. More even than scatterplots.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine that your organization has recently implemented a novel marketing strategy
    aimed at increasing product sales. The plan was rolled out across several regions
    with distinct market dynamics and consumer behaviors. To evaluate the strategy’s
    effectiveness, you need to determine not only whether sales have increased post-implementation
    but also if the observed changes can be attributed directly to the marketing efforts
    rather than external factors or mere chance. Furthermore, you’re tasked with identifying
    which specific strategy elements were most effective in different regions and
    among various demographic groups.
  prefs: []
  type: TYPE_NORMAL
- en: The toolbox you need to open for more advanced problems is called inferential
    or inference statistics. *Inference analysis* is a branch of statistics that focuses
    on drawing conclusions about a population based on data obtained from a sample
    (inferring things about the population based on what you find in the sample—it
    does what it says on the tin, really). It is grounded in probability theory and
    employs various statistical tests and methods to estimate population parameters,
    test hypotheses, and assess the strength and direction of relationships between
    variables.
  prefs: []
  type: TYPE_NORMAL
- en: The following sections will test generative AI’s ability to guide us through
    this statistics-laced minefield.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.1 Before you begin
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unfortunately, we need to put on our Don Quixote cap (or helmet) for a moment.
    The methods we will show you are not very popular, and you may rightfully ask
    yourself, why don’t we use methods we’ll find in most textbooks or websites? There
    are a couple of reasons for that.
  prefs: []
  type: TYPE_NORMAL
- en: First, we perceive our role as pointing you to ways of doing things right, where
    right means analyzing your data in a way that allows you to draw correct conclusions.
  prefs: []
  type: TYPE_NORMAL
- en: The second reason results from the availability of generative AI. Where previously
    you’d need to spend a considerable amount of time learning the intricacies of
    statistics to even begin to do things right, you now have, at your fingertips,
    all the required knowledge and a tool to parse and explain it to you in a way
    you’ll feel comfortable with. Plus, this tool will provide the complete code to
    perform the analysis as a bonus.
  prefs: []
  type: TYPE_NORMAL
- en: The importance of using confidence intervals in inference analysis
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In section 3.1, we mentioned that we disagree with generative AI’s popularity-based
    approach to selecting methods for evaluating the results of statistical analyses.
    We realize that for the majority of our readers, the concept on which we base
    the following analyses may be new, so we’ll present an overview here.
  prefs: []
  type: TYPE_NORMAL
- en: We already mentioned that the role of inference analysis is to draw conclusions
    about the population from the sample. Imagine we wanted to know the average monthly
    spending of our company’s customers on some product category (one they may also
    buy outside of our company). Since it’s not feasible to survey all our customers,
    we may decide to randomly select 100 customers and calculate their average spending.
    Let’s assume the result turned out to be $200.
  prefs: []
  type: TYPE_NORMAL
- en: The sample might not perfectly represent our entire customer base. We would
    then calculate the *confidence interval* (CI) to account for potential variability.
    A 95% confidence interval for average monthly spending might be between $180 and
    $220\. This means that we can be 95% confident that the *true* average spending
    of all customers on this product category lies within that range. In other words,
    if we repeat the sampling and CI calculation 100 times, 95 of the calculated confidence
    intervals will contain the true mean.
  prefs: []
  type: TYPE_NORMAL
- en: Confidence intervals offer certain advantages over more widely used null hypothesis
    significance testing (NHST), or p-value, as they provide a range of plausible
    values for the population parameter, allowing for a more comprehensive understanding
    of the effect size and its uncertainty.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, confidence intervals contribute to a better interpretation of the
    results and more informed decision-making. This is why, despite the general, popularity-driven
    consensus approach proposed initially by ChatGPT, we modified the proposed analysis
    design for the questions we will discuss in following subsections and explicitly
    asked our AI advisor to focus on methods utilizing confidence intervals.
  prefs: []
  type: TYPE_NORMAL
- en: An important note on the completeness of the data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We use inference statistics here because we know that the data we have is a
    sample of a bigger set. If you work with a full dataset, such as all the customers
    you have and all the transactions made, there is no need to calculate confidence
    intervals for the purpose of historical data analysis, as your sample *is* your
    population. However, inference statistics will come in handy if you want to use
    your data for any kind of predictive analytics.
  prefs: []
  type: TYPE_NORMAL
- en: We are now equipped to plunge back into analyzing our e-commerce data.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.2 Relationship between product attributes and shipping costs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The question, “What is the relationship between product attributes (e.g., weight,
    dimensions) and overhead costs (e.g., shipping costs)?” posed by our AI advisor
    may seem a little naive, but it will help us build an intuition about the power
    of confidence-interval–based linear regression. The importance of this tool is
    impossible to overestimate. You will encounter it when working in various fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Economics*—Economists use linear regression to understand the relationship
    between economic indicators, such as GDP growth and unemployment rates, or inflation
    and interest rates. Confidence intervals in these regressions help policymakers
    assess the reliability of these relationships when making fiscal or monetary policy
    decisions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Finance*—In finance, linear regression is used to model the relationship between
    the risk and return of assets, as described by the capital asset pricing model
    (CAPM). Analysts use confidence intervals to gauge the precision of beta coefficients,
    which measure the sensitivity of asset returns to market movements, thereby informing
    investment strategies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Healthcare*—Researchers employ linear regression to study the relationship
    between various risk factors (e.g., smoking, diet, physical activity) and health
    outcomes (e.g., heart disease, diabetes). Confidence intervals around the regression
    coefficients provide insights into the significance and reliability of these factors,
    guiding public health recommendations and patient treatment plans.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Marketing**—*Marketing analysts use linear regression to understand how different
    aspects of marketing strategies (e.g., advertising spend, promotional activities)
    influence sales or customer behavior. Confidence intervals help in assessing the
    strength of these relationships, optimizing marketing budgets, and tailoring strategies
    to maximize ROI.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Real estate*—Linear regression models are used to predict property prices
    based on features such as size, location, and amenities. Confidence intervals
    around the predictions provide potential buyers and sellers with a range of expected
    prices, aiding in negotiation and decision-making processes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Environmental science*—Scientists apply linear regression to model the impact
    of human activities on environmental indicators, such as CO[2] emissions and global
    temperature rise, or the effect of environmental variables on biodiversity. Confidence
    intervals help quantify the uncertainty in these models, crucial for environmental
    policy and conservation strategies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Manufacturing*—In the manufacturing sector, linear regression is used to model
    the relationship between production processes (e.g., temperature, pressure, material
    properties) and product quality or yield. Confidence intervals allow engineers
    to understand the variability in these processes and to optimize them for better
    outcomes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Education*—Researchers use linear regression to explore the impact of educational
    interventions (e.g., class size, teaching methods, technology use) on student
    performance. Confidence intervals provide a measure of the effectiveness and reliability
    of these interventions, informing educational policy and practice.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Sports analytics*—Linear regression is applied in sports analytics to evaluate
    the performance of players based on various metrics (e.g., scoring, defensive
    actions) and their impact on game outcomes. Confidence intervals around these
    estimates help teams make strategic decisions about player training and game tactics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Technology and innovation*—In technology companies, linear regression can
    analyze the relationship between features of a product or service and user engagement
    or satisfaction. Confidence intervals around these relationships guide product
    development, feature prioritization, and customer experience strategies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In our opinion, quantitatively checking how much one thing depends on the other
    is irreplaceable in any decision-making process. Fortunately, generative AI can
    help you go through the whole process quickly and efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**How can I check if there is a relationship
    between product attributes (e.g., weight, dimensions) and shipping costs?'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Response.png)**To investigate the relationship between
    product attributes (e.g., weight, dimensions) and shipping costs, you can use
    a linear regression model with confidence intervals. First, let’s combine the
    necessary data from the `df_products` and `df_order_items` DataFrames:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, let’s build a linear regression model for each of the product attributes
    (weight and volume) against the shipping cost (freight value):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, you can visualize the relationships and their confidence intervals:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: By examining the plots and their 95% confidence intervals, you can determine
    whether there’s a relationship between the product attributes and shipping costs.
    A narrow confidence interval around the fitted line indicates a stronger relationship
    between the variables, while a wider interval suggests more uncertainty in the
    relationship.
  prefs: []
  type: TYPE_NORMAL
- en: Our AI advisor proposed a complete solution. It engineered the required DataFrame,
    built regression models, and proposed a visualization of results. The latter turned
    out to be way more cluttered than we could hope, but it is presented in figure
    3.11 nevertheless.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F11_Siwiak3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.11 Scatterplot of the relationship between (a) freight value and product
    weight, and (b) freight value and volume
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: There are interesting vertical lines of data points at 30,000 g and 25,000 cm³
    in figure 3.11\. We guess it’s caused by some standard package sizes used by delivery
    companies across Brazil.
  prefs: []
  type: TYPE_NORMAL
- en: The other thing worth discussing is that the confidence interval is so narrow
    that it’s not even visible in the picture. That means, from the statistical point
    of view, that the line most likely is where we drew it—we have so much data that
    we can be sure about our estimation’s precision. That doesn’t mean this regression
    is immediately useful, though.
  prefs: []
  type: TYPE_NORMAL
- en: The results are spread wide around the regression line. Its predictive power
    seems to be low, to say the least. If we have a package of 20 kg, for example,
    we can estimate its freight value to be anywhere between 0 and 200 BRL (it’s our
    assumption that that’s the monetary unit the data provider uses).
  prefs: []
  type: TYPE_NORMAL
- en: How much wood would the woodchuck chuck?  The main value of regressions is their
    ability to predict dependent variables based on a set of independent variables.
    To assess the performance of a regression model, we may employ various metrics,
    such as mean absolute error (MAE), mean squared error (MSE), root mean squared
    error (RMSE), and R² (coefficient of determination). These metrics provide insights
    into the model’s accuracy, the magnitude of the errors, and the proportion of
    the variance in the dependent variable explained by the independent variables.
    Additionally, residual analysis and diagnostic plots can be used to examine the
    model’s assumptions, such as linearity, homoscedasticity, and the normality of
    residuals.
  prefs: []
  type: TYPE_NORMAL
- en: 'We promised you a quantitative analysis of the dependency, and we’re not going
    to stop at drawing a chart this time. These are several commonly used metrics
    that you’ll want to look at when analyzing regression data (especially in the
    context of its predictive power):'
  prefs: []
  type: TYPE_NORMAL
- en: '*Mean absolute error* *(MAE)* —The average of the absolute differences between
    predicted and actual values. It gives an idea of how wrong the predictions are.
    A smaller MAE indicates better predictive performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Mean squared error* *(MSE)* —The average of the squared differences between
    predicted and actual values. It tends to penalize large errors more than small
    ones. A smaller MSE indicates better predictive performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Root mean squared error* *(RMSE)* —The square root of the MSE. It has the
    same units as the dependent variable and is more interpretable than the MSE. A
    smaller RMSE indicates better predictive performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*R*²—R² measures the proportion of variance in the dependent variable that
    can be explained by the independent variable(s). A higher R² value indicates better
    predictive performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As usual, accepting the help of generative AI is the quickest way to get code
    that calculates all of these values.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.4 Predicting product weight or volume influence on freight value
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The proposed code should provide us with the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The results show that just about 35 percent of the variability in the freight
    value is explained by product weight or volume. It may be interesting to see if
    combining the two would increase the available predictive power.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.5 Predicting product weight and volume influence on freight value
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The results may seem a bit daunting, but if you feel daring, generative AI should
    help you understand all of the following parameters.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Note  You can learn a lot about the measurements and parameters used in statistics
    from the perspective of someone dealing with money, rather than basic science,
    from *Mostly Harmless Econometrics* by Joshua Angrist and Jörn-Steffen Pischke
    (Princeton University Press, 2009).
  prefs: []
  type: TYPE_NORMAL
- en: The critical information here should be R², which tells you that almost 40%
    of the variability in freight value can be explained by product weight and volume
    variability. This means that by controlling and optimizing these two variables,
    you can impact the freight value. If the freight value is an essential factor
    of the overall cost of the product, this result could lead to the conclusion that
    it would be worth trying to reduce the weight or size of products without reducing
    their functionality or quality. This could lead to freight cost savings.
  prefs: []
  type: TYPE_NORMAL
- en: Beggars can’t be choosers  As we explained in chapter 2, the quality of results
    depends heavily on the quality and accessibility of data. Given a choice, you
    should avoid proposing business solutions based on data with the spread seen in
    figure 3.11\. The observed effects are also not too significant. However, the
    key phrase is “given a choice.” Sometimes you will not have any better data, and
    your business may require any support it can get. Relying on even imperfect results
    like these may mean the difference between letting the business sink and giving
    it a fighting chance.
  prefs: []
  type: TYPE_NORMAL
- en: We will spend a bit more time drawing conclusions from this result in chapter
    4\. For now, we’ll turn our attention back to the review score.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.3 Relationship between product, transaction, shipping attributes, and the
    review score
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Your boss would be proud of you if they saw you doing what we will do in this
    section— merge the three research questions proposed by our AI advisor into one:'
  prefs: []
  type: TYPE_NORMAL
- en: “What factors (e.g., delivery time, price, product attributes) contribute to
    differences in the average review score?”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “How do different payment methods and the number of payment installments affect
    order completion rates and customer satisfaction?”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “What is the impact of delivery time (actual vs. estimated) on customer satisfaction
    and review scores?”
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The method of answering them is identical, so why waste time (which is money)
    doing the same work three times? Well, that would only work if you don’t care
    too much about the reliability and accuracy of the results. That’s an important
    lesson: even if you technically can do something, it doesn’t mean you should.'
  prefs: []
  type: TYPE_NORMAL
- en: Less is more  In regression analysis, you could hope that the more independent
    variables you drop into the model, the better the result, but that is not necessarily
    the case. Too many variables may muddy the water, so to speak, as they can result
    in either overfitting the model or causing issues related to multicollinearity.
    Overfitting means your model starts to fit the noise, rather than the underlying
    patterns, and it usually occurs when you have too many parameters in relation
    to the number of observations. Multicollinearity occurs when two or more predictor
    variables are highly correlated—the estimated coefficients may then become unstable
    and sensitive to minor changes in the data. This instability makes it difficult
    to reliably interpret which variables are genuinely impactful and how much they
    contribute to explaining the dependent variable.
  prefs: []
  type: TYPE_NORMAL
- en: We have only limited information on the product and transaction process. We
    also know already that the majority of transactions are finished when they are
    delivered. This should prepare us not to expect great success in finding a correlation
    between these factors and the level of happiness expressed by the customers in
    their reviews. However, we think the techniques for investigating such relationships
    are worth learning about.
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**What inferential statistics should I use
    to research how the average review score varies across different product categories,
    and what factors (e.g., delivery time and its difference vs. estimation, price,
    product, and payment attributes) contribute to these differences?'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Response.png)**To use inferential statistics to research
    how the average review score varies across different product categories and how
    factors like delivery time, price, and product attributes contribute to these
    differences, you can follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Prepare the data:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a DataFrame containing the necessary columns: product category, review
    score, delivery time, price, and product attributes (e.g., weight, dimensions).'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Merge the necessary DataFrames to obtain this information.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Ensure there are no missing values and convert categorical variables to numerical
    format if required.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Perform ordinal logistic regression:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Since the review score is an ordinal variable (1-5), you can use ordinal logistic
    regression to model the relationship between the review score and the factors
    of interest (product category, delivery time, price, and product attributes).
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: To do this, you can use the `mord.LogisticAT` model from the mord package.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Fit the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Split the data into training and testing sets.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Fit the ordinal logistic regression model on the training data.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Evaluate the model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use the model to predict the review scores on the test data.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the accuracy of the predictions using a confusion matrix and other
    metrics like precision, recall, and F1-score.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Analyze the model’s coefficients to determine the importance of each factor
    in predicting the review score.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here’s a sample code to help you get started:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: With this approach, you can explore the relationship between the average review
    score and various factors using ordinal logistic regression.
  prefs: []
  type: TYPE_NORMAL
- en: If the comment in the code saying “`assuming you have already merged necessary
    DataFrames into analysis_df`,” was not a red flag for you, we’ve done a poor job
    so far. Whenever you see any assumptions on the part of the generative AI, you
    need to shiver, curse under your breath, and double-check them. We won’t include
    the whole conversation we had, trying to specify what generative AI hallucinated
    `analysis_df` to be. You can see the final code in listing 3.6.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.6 Preparation of the `analysis_df` DataFrame
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The DataFrame resulting from the preceding code will be devoid of all unnecessary
    information about identifiers, geographic locations, and timestamps, as they will
    not be used in this particular analysis and would be unnecessary noise. We want
    to focus on variables of interest and their impact on review score.
  prefs: []
  type: TYPE_NORMAL
- en: The result of the logistic regression analysis is relatively easy to read.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: This accuracy means that you can explain 43% of the variability in review scores.
  prefs: []
  type: TYPE_NORMAL
- en: Right on the money?  Misinterpretation or overestimation of a model’s accuracy
    can be very costly. A confusion matrix is a table layout that visualizes the performance
    of a classification algorithm, typically used in supervised learning. In binary
    prediction, it displays the number of correct and incorrect predictions made by
    the model, comparing them to the actual outcomes. The matrix is organized into
    four quadrants representing true positives (TP), true negatives (TN), false positives
    (FP; also known as type I errors), and false negatives (FN; also known as type
    II errors). By assessing the matrix, we can estimate the rate of type I errors,
    which occur when the model incorrectly classifies a positive instance as negative,
    and type II errors, which occur when the model incorrectly classifies a negative
    instance as positive. You’ll find more information on error types in chapter 5.
  prefs: []
  type: TYPE_NORMAL
- en: In a multivariate confusion matrix, such as the preceding one, each row represents
    the actual class, while each column represents the predicted class. The elements
    on the main diagonal of the matrix correspond to the correctly classified instances
    for each class, while the off-diagonal elements indicate misclassifications. To
    get a better intuition, let’s take a look at our classification of reviews and
    focus on the third column in the matrix, representing predictions of score three.
    In 109 cases, the classifier correctly assigned the score. It also misclassified
    71 actual threes as twos, 401 as ones, 100 as fours, and 208 as fives.
  prefs: []
  type: TYPE_NORMAL
- en: To make analysis easier, let’s ask generative AI for the code linking the received
    result with the remaining variables.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.7 Connecting prediction results with variable names
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code snippet should work as advertised and return us this simple
    answer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: The interpretation of coefficients resulting from the ordinal regression is
    similar to the interpretation of results we obtained from the linear regression,
    if not so straightforward. The resulting numbers represent the change in log-odds
    of being in a higher category of the outcome variable for a one-unit increase
    in the corresponding predictor variable, holding other variables constant. In
    simpler terms, when we’re predicting something with a specific order, like “low,”
    “medium,” and “high,” the coefficients give us information about how our prediction
    changes with input changes.
  prefs: []
  type: TYPE_NORMAL
- en: For example, let’s say we want to predict a happiness level based on how many
    hours you sleep. The coefficient would tell us how much the odds of being “more
    happy” (moving up a level from “low” to “medium” or “medium” to “high”) change
    for each extra hour of sleep you get. All of this is assuming that nothing else
    in your environment has changed. So, if the number (coefficient) is positive,
    that means getting more sleep increases the odds of being “more happy.” If it’s
    negative, more sleep decreases the odds. The bigger the number, the stronger the
    effect.
  prefs: []
  type: TYPE_NORMAL
- en: From the research perspective, it’s not ideal to evaluate sleep’s influence
    on your happiness if the increased sleep results from holidays from stressful
    work. Still, we’re not always given perfect testing conditions. The method described
    here could allow you to identify the influence of sleep if you provide multiple
    conditions and your mood record as input.
  prefs: []
  type: TYPE_NORMAL
- en: We will discuss how our coefficients translate to business insights in chapter
    4.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.4 Differences in sales performance and customer satisfaction between sellers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, our focus will be on the differences between groups of sellers.
    We’ll try to answer the question, “are there any significant differences in sales
    performance and customer satisfaction between sellers from different cities or
    states?”
  prefs: []
  type: TYPE_NORMAL
- en: 'As it’s later in the chapter and you may be eager to move on to the next one,
    let’s take a look at where this approach could be successfully applied. Who knows,
    maybe something here will be of interest to you:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Healthcare performance analysis*—Comparing patient outcomes (e.g., recovery
    rates, satisfaction scores) between different hospitals or healthcare providers
    to identify quality disparities and areas for improvement.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Educational achievement gaps*—Analyzing differences in student performance
    (e.g., test scores, graduation rates) across schools or districts to uncover educational
    inequalities and target interventions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Marketing campaign effectiveness*—Evaluating the impact of different marketing
    campaigns across regions or demographics to determine which strategies are most
    effective in enhancing brand awareness or sales.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Human resource management*—Comparing employee satisfaction and performance
    metrics across different company locations or departments to identify best practices
    and areas needing attention.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Financial services comparison*—Analyzing loan approval rates or default rates
    across different branches to assess risk management effectiveness and customer
    service quality.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Supply chain efficiency*—Comparing delivery times or inventory turnover rates
    across different distribution centers to optimize logistics and supply chain management.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Product quality control*—Analyzing return rates or customer complaints for
    products manufactured at different facilities to identify quality control issues.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Environmental policy impact*—Comparing pollution levels or conservation outcomes
    across regions before and after the implementation of environmental policies to
    assess their effectiveness.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Retail chain performance*—Evaluating sales volumes or customer loyalty scores
    across different store locations to identify high-performing stores and understand
    factors contributing to their success.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Public policy and social programs*—Assessing the effectiveness of social programs
    (e.g., unemployment aid, public health initiatives) in different communities by
    comparing outcome metrics like employment rates or health indicators.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before we jump into the analysis, we need to expose you to the method called
    bootstrapping.
  prefs: []
  type: TYPE_NORMAL
- en: Bootstrap methods are a powerful resampling technique you can use to estimate
    confidence intervals, especially when the underlying data distribution is unknown
    or difficult to determine analytically. The bootstrap approach involves generating
    multiple random samples with replacements from the original dataset, each of the
    same size as the original sample. This means that while constructing each sample,
    every data point from the original dataset can be selected multiple times, and
    the number of data points in each new sample matches the number in the original
    dataset. A statistic of interest (e.g., mean, median, or regression coefficient)
    is calculated for each generated sample. These calculated statistics form a bootstrap
    distribution for estimating the population parameter’s confidence interval. A
    bootstrap distribution is essentially a frequency distribution of a statistic—like
    the mean or a regression coefficient—computed across multiple resampled datasets.
  prefs: []
  type: TYPE_NORMAL
- en: What does this mean in practice? Imagine you work for a company manufacturing
    extremely expensive equipment, such as quantum electronics. They need to make
    destruction tests to estimate safety parameters, such as the temperature the product
    can withstand. Destroying too many samples would literally bankrupt them, but
    let’s assume they can afford to overheat 50 pieces of equipment. The engineers
    run the test 50 times and come to you with 50 breakpoint temperatures. The reliability
    of a simple average calculation isn’t sufficient to satisfy the needs of clients,
    who want to know exactly how critical the cooling requirements are. Remember,
    we’re talking about huge costs for the products, but also huge costs for ensuring
    safe operational requirements. Safety margins are good and nice, but widening
    them too much can make your product unfeasible for clients.
  prefs: []
  type: TYPE_NORMAL
- en: Enter bootstrapping. You create “new” test batches by randomly selecting 50
    scores from your original test results, with replacement. In other words, some
    scores may be selected multiple times and others not at all, simulating a new
    batch of tests under identical conditions. You repeat this resampling process
    many times—let’s say 10,000 times—each time calculating the average score of the
    resampled batch. This extensive repetition produces a wide range of possible breakpoint
    temperatures, reflecting the natural variability in your equipment’s durability.
    The collection of these 10,000 breakpoint temperatures forms your bootstrap distribution.
    This distribution gives you a statistical model of what the average durability
    score for your quantum electronics equipment might look like, based on your actual
    testing data. Given this bootstrap distribution, you can determine the middle
    95% (or 99%, or 99.9%) of the average breakpoint temperatures as your confidence
    interval. This interval provides a statistically sound estimate of where the true
    average breakpoint temperature of your equipment lies, offering insights into
    its performance and how it might hold up in real-world use.
  prefs: []
  type: TYPE_NORMAL
- en: 'The bootstrap method shines in situations where traditional assumptions (like
    the normal distribution of the data) may not hold, or where sample sizes are too
    small to rely on the asymptotic properties of estimators (e.g., the simple calculation
    of a mean). Here are a few examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Startup performance metrics*—Early-stage startups often have limited data
    on customer behavior, revenues, or engagement metrics. Bootstrap methods can help
    estimate the variability and confidence intervals of key performance indicators
    (KPIs) like average revenue per user (ARPU) or customer lifetime value (CLV),
    providing valuable insights for decision-making despite small sample sizes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Drug efficacy in clinical trials*—In clinical trials, especially early-phase
    trials with small sample sizes, the distribution of treatment effects can be skewed
    or multimodal due to heterogeneous responses among participants. Bootstrap methods
    allow for the estimation of confidence intervals around the median treatment effect
    or other non-normally distributed outcomes, offering a more robust understanding
    of the drug’s efficacy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Environmental impact studies*—Environmental data, such as pollution levels
    or species counts, often exhibit skewed distributions due to the presence of extreme
    values (e.g., very high pollution levels on certain days). Bootstrap methods can
    provide reliable confidence intervals for median pollution levels or mean species
    counts, which are more informative and robust for policy-making than simple means.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Economic policy evaluation*—Evaluating the impact of economic policies on
    outcomes such as employment rates or GDP growth often involves dealing with complex,
    non-normal distributions of effects across different regions or industries. Bootstrap
    confidence intervals can offer a more nuanced understanding of policy impacts,
    helping policymakers identify the range of potential outcomes and the reliability
    of estimated effects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In each of these scenarios, the bootstrap method’s ability to provide reliable
    confidence intervals without relying on strict assumptions about the data’s distribution
    is invaluable. It allows researchers and practitioners to draw more confident
    conclusions from their data, even in challenging analytical contexts.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s move from quantum electronics and economic policies into more commonly
    encountered customer satisfaction issues. In the case of customer satisfaction,
    you will often operate on opinions collected from just a sample of the total number
    of customers. Only some customers will leave a review or answer a survey. Businesses
    should know, reliably, their customers’ opinions across different categories.
  prefs: []
  type: TYPE_NORMAL
- en: 'Chapters 5 and 6 will discuss analyzing the reviews’ texts. Here, we’ll ask
    generative AI to prepare bootstrap-based confidence intervals for two numerical
    values important from the business perspective: average price and average customer
    review.'
  prefs: []
  type: TYPE_NORMAL
- en: We will limit our attention to a single category of products. From the computational
    perspective, it doesn’t matter if we drop in the whole DataFrame or a filtered
    selection. We would like, however, to point your attention to the importance of
    the business meaning of the analysis. In a real-life scenario, even selecting
    a single category—in our case, “health and beauty”—wouldn’t be granular enough.
    Luxury and commodity products differ greatly in both prices and expectations.
    Mixing them does not offer sufficient insight into the market situation. Mixing
    them all together with car sales would muddy the waters even more, don’t you think?
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get to the code.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 3.8 Calculating confidence intervals for sales and review scores by
    state
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, going through data harmonization, statistical modeling, and
    visualization results in quite a substantial amount of code. Fortunately, generative
    AIs are capable of not only providing the code, but also commenting it in an informative
    way.
  prefs: []
  type: TYPE_NORMAL
- en: The confidence intervals calculated for our examples are presented in figure
    3.12.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F12_Siwiak3.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.12 Confidence intervals of (a) the average sales price and (b) the
    review score, both per state
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We would like to repeat that, while doing the full-scale analysis, you should
    prepare separate charts for each product category, or dig even deeper, to avoid
    comparing apples with oranges or visual clutter.
  prefs: []
  type: TYPE_NORMAL
- en: 'A Word on software efficiency  There are two main elements of increasing program
    efficiency. One is to optimize code execution, and we write about that at length
    in chapter 7\. The other one, oftentimes no less important, is the parameterization
    of the algorithm used. Bootstrap methods balance two main parameters: the number
    of resamplings and the accuracy of the confidence interval. If you analyze really
    big data, before you jump into the technical aspects of optimization, you should
    try to understand whether the parameters of the algorithm you are using don’t
    offer ways of getting to your goal faster. Or at least closer to your goal. That’s
    another bonus of learning about parameters—you can usually understand the results
    better if you know what the assumptions behind each of them are.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can see some interesting differences in the results, but we’ll leave interpreting
    the results for chapter 4\. For now, we would like to leave you with a riddle:
    Why, when working with our example, does it make sense to use bootstrapping and
    calculate confidence intervals for our prices, and why would it most likely not
    make sense if you worked with your business data?'
  prefs: []
  type: TYPE_NORMAL
- en: Having read this section, you should now be able to use inferential statistics
    and its different methods in your analytical work. In this chapter, you broke
    down the data and identified multiple relationships between different parameters.
    You used different visualization tools, like heatmaps and scatter plots, as well
    as regression analysis, to see how some parameters correlate with others.
  prefs: []
  type: TYPE_NORMAL
- en: Correlation does not imply causation  Sleeping with shoes on correlates with
    headaches in the morning, ice cream sales correlate with violent crimes, hair
    color correlates with ice-skating skills. These examples demonstrate that seeing
    a correlation is just a first stop in explaining observed phenomena. Often the
    correlation is caused by a third factor influencing your observed parameters.
    Sleeping with shoes on and headaches go hand in hand with alcohol overuse, ice
    cream sales and violent crimes result from heat waves, while blond hair is more
    often found in countries where you can find ice outside every now and then. *Never*
    assume causation on the basis of observed correlation without identifying a logical
    link between the observations.
  prefs: []
  type: TYPE_NORMAL
- en: There are many more methods in descriptive analytics, but after reading this
    chapter, you should be able to use generative AI to quickly identify and implement
    the best analytical tools for your dataset. All you need to do is to honestly
    and precisely describe the data you have available, and as honestly and as precisely
    as you can (which could mean not at all!), describe the goal of your analytics.
  prefs: []
  type: TYPE_NORMAL
- en: You should also be aware of generative AI’s weaknesses. The most notable one
    is its tendency to hallucinate when asked about topics and data defined too long
    before the prompt. Also, the provided code always needs to be tested. Applying
    this “trust, but verify” approach, generative AI can substantially improve and
    accelerate your analysis process.
  prefs: []
  type: TYPE_NORMAL
- en: Things to ask generative AI
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: What research questions related to the provided data can be asked?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What analysis design would lead to answering the following question?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What statistical method is best to analyze <available data>?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide me with code to <data transformation>.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How should I visualize <data structure>.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Provide me with a solution answering the following question: . . .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modify the code to change the visualization format.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Generative AI may be excellent at suggesting proper analytical tools and providing
    end-to-end analytical strategies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative AI will first suggest the most popular methods, but they can provide
    competent support in the implementation of more niche ones too.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative AI may supplement analysis with market-specific information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feeding generative AI with results to get insights requires caution and sometimes
    re-engineering of the output.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative AI can offer sound business insights.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You need to control the context awareness of generative AIs and be wary of their
    hallucinations. Jog their memories from time to time.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code provided by generative AI needs careful testing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
