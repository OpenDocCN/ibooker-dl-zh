- en: 'Chapter 4\. Under the Hood: Training a Digit Classifier'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Having seen what it looks like to train a variety of models in [Chapter 2](ch02.xhtml#chapter_production),
    let’s now look under the hood and see exactly what is going on. We’ll start by
    using computer vision to introduce fundamental tools and concepts for deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: To be exact, we’ll discuss the roles of arrays and tensors and of broadcasting,
    a powerful technique for using them expressively. We’ll explain stochastic gradient
    descent (SGD), the mechanism for learning by updating weights automatically. We’ll
    discuss the choice of a loss function for our basic classification task, and the
    role of mini-batches. We’ll also describe the math that a basic neural network
    is doing. Finally, we’ll put all these pieces together.
  prefs: []
  type: TYPE_NORMAL
- en: In future chapters, we’ll do deep dives into other applications as well, and
    see how these concepts and tools generalize. But this chapter is about laying
    foundation stones. To be frank, that also makes this one of the hardest chapters,
    because of how these concepts all depend on each other. Like an arch, all the
    stones need to be in place for the structure to stay up. Also like an arch, once
    that happens, it’s a powerful structure that can support other things. But it
    requires some patience to assemble.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s begin. The first step is to consider how images are represented in a computer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pixels: The Foundations of Computer Vision'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To understand what happens in a computer vision model, we first have to understand
    how computers handle images. We’ll use one of the most famous datasets in computer
    vision, [MNIST](https://oreil.ly/g3RDg), for our experiments. MNIST contains images
    of handwritten digits, collected by the National Institute of Standards and Technology
    and collated into a machine learning dataset by Yann Lecun and his colleagues.
    Lecun used MNIST in 1998 in [LeNet-5](https://oreil.ly/LCNEx), the first computer
    system to demonstrate practically useful recognition of handwritten digit sequences.
    This was one of the most important breakthroughs in the history of AI.
  prefs: []
  type: TYPE_NORMAL
- en: 'For this initial tutorial, we are just going to try to create a model that
    can classify any image as a 3 or a 7\. So let’s download a sample of MNIST that
    contains images of just these digits:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see what’s in this directory by using `ls`, a method added by fastai.
    This method returns an object of a special fastai class called `L`, which has
    all the same functionality of Python’s built-in `list`, plus a lot more. One of
    its handy features is that, when printed, it displays the count of items before
    listing the items themselves (if there are more than 10 items, it shows just the
    first few):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The MNIST dataset follows a common layout for machine learning datasets: separate
    folders for the training set and the validation (and/or test) set. Let’s see what’s
    inside the training set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'There’s a folder of 3s, and a folder of 7s. In machine learning parlance, we
    say that “3” and “7” are the *labels* (or targets) in this dataset. Let’s take
    a look in one of these folders (using `sorted` to ensure we all get the same order
    of files):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'As we might expect, it’s full of image files. Let’s take a look at one now.
    Here’s an image of a handwritten number 3, taken from the famous MNIST dataset
    of handwritten numbers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](Images/dlcf_04in01.png)'
  prefs: []
  type: TYPE_IMG
- en: Here we are using the `Image` class from the *Python Imaging Library* (PIL),
    which is the most widely used Python package for opening, manipulating, and viewing
    images. Jupyter knows about PIL images, so it displays the image for us automatically.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a computer, everything is represented as a number. To view the numbers that
    make up this image, we have to convert it to a *NumPy array* or a *PyTorch tensor*.
    For instance, here’s what a section of the image looks like converted to a NumPy
    array:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The `4:10` indicates we requested the rows from index 4 (inclusive) to 10 (noninclusive),
    and the same for the columns. NumPy indexes from top to bottom and from left to
    right, so this section is located near the top-left corner of the image. Here’s
    the same thing as a PyTorch tensor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'We can slice the array to pick just the part with the top of the digit in it,
    and then use a Pandas DataFrame to color-code the values using a gradient, which
    shows us clearly how the image is created from the pixel values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '![](Images/dlcf_04in02.png)'
  prefs: []
  type: TYPE_IMG
- en: You can see that the background white pixels are stored as the number 0, black
    is the number 255, and shades of gray are between the two. The entire image contains
    28 pixels across and 28 pixels down, for a total of 768 pixels. (This is much
    smaller than an image that you would get from a phone camera, which has millions
    of pixels, but is a convenient size for our initial learning and experiments.
    We will build up to bigger, full-color images soon.)
  prefs: []
  type: TYPE_NORMAL
- en: 'So, now you’ve seen what an image looks like to a computer, let’s recall our
    goal: create a model that can recognize 3s and 7s. How might you go about getting
    a computer to do that?'
  prefs: []
  type: TYPE_NORMAL
- en: Stop and Think!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before you read on, take a moment to think about how a computer might be able
    to recognize these two digits. What kinds of features might it be able to look
    at? How might it be able to identify these features? How could it combine them?
    Learning works best when you try to solve problems yourself, rather than just
    reading somebody else’s answers; so step away from this book for a few minutes,
    grab a piece of paper and pen, and jot some ideas down.
  prefs: []
  type: TYPE_NORMAL
- en: 'First Try: Pixel Similarity'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So, here is a first idea: how about we find the average pixel value for every
    pixel of the 3s, then do the same for the 7s. This will give us two group averages,
    defining what we might call the “ideal” 3 and 7\. Then, to classify an image as
    one digit or the other, we see which of these two ideal digits the image is most
    similar to. This certainly seems like it should be better than nothing, so it
    will make a good baseline.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Jargon: Baseline'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A simple model that you are confident should perform reasonably well. It should
    be simple to implement and easy to test, so that you can then test each of your
    improved ideas and make sure they are always better than your baseline. Without
    starting with a sensible baseline, it is difficult to know whether your super-fancy
    models are any good. One good approach to creating a baseline is doing what we
    have done here: think of a simple, easy-to-implement model. Another good approach
    is to search around to find other people who have solved problems similar to yours,
    and download and run their code on your dataset. Ideally, try both of these!'
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 for our simple model is to get the average of pixel values for each of
    our two groups. In the process of doing this, we will learn a lot of neat Python
    numeric programming tricks!
  prefs: []
  type: TYPE_NORMAL
- en: Let’s create a tensor containing all of our 3s stacked together. We already
    know how to create a tensor containing a single image. To create a tensor containing
    all the images in a directory, we will first use a Python list comprehension to
    create a plain list of the single image tensors.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use Jupyter to do some little checks of our work along the way—in this
    case, making sure that the number of returned items seems reasonable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: List Comprehensions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'List and dictionary comprehensions are a wonderful feature of Python. Many
    Python programmers use them every day, including the authors of this book—they
    are part of “idiomatic Python.” But programmers coming from other languages may
    have never seen them before. A lot of great tutorials are just a web search away,
    so we won’t spend a long time discussing them now. Here is a quick explanation
    and example to get you started. A list comprehension looks like this: `new_list
    = [f(o) for o in a_list if o>0]`. This will return every element of `a_list` that
    is greater than 0, after passing it to the function `f`. There are three parts
    here: the collection you are iterating over (`a_list`), an optional filter (`if
    o>0`), and something to do to each element (`f(o)`). It’s not only shorter to
    write, but also way faster than the alternative ways of creating the same list
    with a loop.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll also check that one of the images looks OK. Since we now have tensors
    (which Jupyter by default will print as values), rather than PIL images (which
    Jupyter by default will display images), we need to use fastai’s `show_image`
    function to display it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '![](Images/dlcf_04in03.png)'
  prefs: []
  type: TYPE_IMG
- en: For every pixel position, we want to compute the average over all the images
    of the intensity of that pixel. To do this, we first combine all the images in
    this list into a single three-dimensional tensor. The most common way to describe
    such a tensor is to call it a *rank-3 tensor*. We often need to stack up individual
    tensors in a collection into a single tensor. Unsurprisingly, PyTorch comes with
    a function called `stack` that we can use for this purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Some operations in PyTorch, such as taking a mean, require us to *cast* our
    integer types to float types. Since we’ll be needing this later, we’ll also cast
    our stacked tensor to `float` now. Casting in PyTorch is as simple as writing
    the name of the type you wish to cast to, and treating it as a method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally, when images are floats, the pixel values are expected to be between
    0 and 1, so we will also divide by 255 here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Perhaps the most important attribute of a tensor is its *shape*. This tells
    you the length of each axis. In this case, we can see that we have 6,131 images,
    each of size 28×28 pixels. There is nothing specifically about this tensor that
    says that the first axis is the number of images, the second is the height, and
    the third is the width—the semantics of a tensor are entirely up to us, and how
    we construct it. As far as PyTorch is concerned, it is just a bunch of numbers
    in memory.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *length* of a tensor’s shape is its rank:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'It is really important for you to commit to memory and practice these bits
    of tensor jargon: *rank* is the number of axes or dimensions in a tensor; *shape*
    is the size of each axis of a tensor.'
  prefs: []
  type: TYPE_NORMAL
- en: Alexis Says
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Watch out because the term “dimension” is sometimes used in two ways. Consider
    that we live in “three-dimensional space,” where a physical position can be described
    by a vector `v`, of length 3\. But according to PyTorch, the attribute `v.ndim`
    (which sure looks like the “number of dimensions” of `v`) equals one, not three!
    Why? Because `v` is a vector, which is a tensor of rank one, meaning that it has
    only one *axis* (even if that axis has a length of three). In other words, sometimes
    dimension is used for the size of an axis (“space is three-dimensional”), while
    other times it is used for the rank, or the number of axes (“a matrix has two
    dimensions”). When confused, I find it helpful to translate all statements into
    terms of rank, axis, and length, which are unambiguous terms.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also get a tensor’s rank directly with `ndim`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Finally, we can compute what the ideal 3 looks like. We calculate the mean of
    all the image tensors by taking the mean along dimension 0 of our stacked, rank-3
    tensor. This is the dimension that indexes over all the images.
  prefs: []
  type: TYPE_NORMAL
- en: 'In other words, for every pixel position, this will compute the average of
    that pixel over all images. The result will be one value for every pixel position,
    or a single image. Here it is:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '![](Images/dlcf_04in04.png)'
  prefs: []
  type: TYPE_IMG
- en: According to this dataset, this is the ideal number 3! (You may not like it,
    but this is what peak number 3 performance looks like.) You can see how it’s very
    dark where all the images agree it should be dark, but it becomes wispy and blurry
    where the images disagree.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s do the same thing for the 7s, but put all the steps together at once
    to save time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '![](Images/dlcf_04in05.png)'
  prefs: []
  type: TYPE_IMG
- en: Let’s now pick an arbitrary 3 and measure its *distance* from our “ideal digits.”
  prefs: []
  type: TYPE_NORMAL
- en: Stop and Think!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How would you calculate how similar a particular image is to each of our ideal
    digits? Remember to step away from this book and jot down some ideas before you
    move on! Research shows that recall and understanding improve dramatically when
    you are engaged with the learning process by solving problems, experimenting,
    and trying new ideas yourself.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a sample 3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '![](Images/dlcf_04in06.png)'
  prefs: []
  type: TYPE_IMG
- en: How can we determine its distance from our ideal 3? We can’t just add up the
    differences between the pixels of this image and the ideal digit. Some differences
    will be positive, while others will be negative, and these differences will cancel
    out, resulting in a situation where an image that is too dark in some places and
    too light in others might be shown as having zero total differences from the ideal.
    That would be misleading!
  prefs: []
  type: TYPE_NORMAL
- en: 'To avoid this, data scientists use two main ways to measure distance in this
    context:'
  prefs: []
  type: TYPE_NORMAL
- en: Take the mean of the *absolute value* of differences (absolute value is the
    function that replaces negative values with positive values). This is called the
    *mean absolute difference* or *L1 norm*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Take the mean of the *square* of differences (which makes everything positive)
    and then take the *square root* (which undoes the squaring). This is called the
    *root mean squared error* (RMSE) or *L2 norm*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s OK to Have Forgotten Your Math
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this book, we generally assume that you have completed high school math,
    and remember at least some of it—but everybody forgets some things! It all depends
    on what you happen to have had reason to practice in the meantime. Perhaps you
    have forgotten what a *square root* is, or exactly how they work. No problem!
    Anytime you come across a math concept that is not explained fully in this book,
    don’t just keep moving on; instead, stop and look it up. Make sure you understand
    the basic idea, how it works, and why we might be using it. One of the best places
    to refresh your understanding is Khan Academy. For instance, Khan Academy has
    a great [introduction to square roots](https://oreil.ly/T7mxH).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try both of these now:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: In both cases, the distance between our 3 and the “ideal” 3 is less than the
    distance to the ideal 7, so our simple model will give the right prediction in
    this case.
  prefs: []
  type: TYPE_NORMAL
- en: 'PyTorch already provides both of these as *loss functions*. You’ll find these
    inside `torch.nn.functional`, which the PyTorch team recommends importing as `F`
    (and is available by default under that name in fastai):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Here, `MSE` stands for *mean squared error*, and `l1` refers to the standard
    mathematical jargon for *mean absolute value* (in math it’s called the *L1 norm*).
  prefs: []
  type: TYPE_NORMAL
- en: Sylvain Says
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Intuitively, the difference between L1 norm and mean squared error (MSE) is
    that the latter will penalize bigger mistakes more heavily than the former (and
    be more lenient with small mistakes).
  prefs: []
  type: TYPE_NORMAL
- en: Jeremy Says
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When I first came across this L1 thingie, I looked it up to see what on earth
    it meant. I found on Google that it is a *vector norm* using *absolute value*,
    so I looked up “vector norm” and started reading: *Given a vector space V over
    a field F of the real or complex numbers, a norm on V is a nonnegative-valued
    any function p: V → \[0,+∞) with the following properties: For all a ∈ F and all
    u, v ∈ V, p(u + v) ≤ p(u) + p(v)…*Then I stopped reading. “Ugh, I’ll never understand
    math!” I thought, for the thousandth time. Since then, I’ve learned that every
    time these complex mathy bits of jargon come up in practice, it turns out I can
    replace them with a tiny bit of code! Like, the *L1 loss* is just equal to `(a-b).abs().mean()`,
    where `a` and `b` are tensors. I guess mathy folks just think differently than
    I do…I’ll make sure in this book that every time some mathy jargon comes up, I’ll
    give you the little bit of code it’s equal to as well, and explain in common-sense
    terms what’s going on.'
  prefs: []
  type: TYPE_NORMAL
- en: We just completed various mathematical operations on PyTorch tensors. If you’ve
    done numeric programming in PyTorch before, you may recognize these as being similar
    to NumPy arrays. Let’s have a look at those two important data structures.
  prefs: []
  type: TYPE_NORMAL
- en: NumPy Arrays and PyTorch Tensors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[NumPy](https://numpy.org) is the most widely used library for scientific and
    numeric programming in Python. It provides similar functionality and a similar
    API to that provided by PyTorch; however, it does not support using the GPU or
    calculating gradients, which are both critical for deep learning. Therefore, in
    this book, we will generally use PyTorch tensors instead of NumPy arrays, where
    possible.'
  prefs: []
  type: TYPE_NORMAL
- en: '(Note that fastai adds some features to NumPy and PyTorch to make them a bit
    more similar to each other. If any code in this book doesn’t work on your computer,
    it’s possible that you forgot to include a line like this at the start of your
    notebook: `from` `fastai.vision.all import *`.)'
  prefs: []
  type: TYPE_NORMAL
- en: But what are arrays and tensors, and why should you care?
  prefs: []
  type: TYPE_NORMAL
- en: Python is slow compared to many languages. Anything fast in Python, NumPy, or
    PyTorch is likely to be a wrapper for a compiled object written (and optimized)
    in another language—specifically, C. In fact, *NumPy arrays and PyTorch tensors
    can finish computations many thousands of times faster than using pure Python*.
  prefs: []
  type: TYPE_NORMAL
- en: A NumPy array is a multidimensional table of data, with all items of the same
    type. Since that can be any type at all, they can even be arrays of arrays, with
    the innermost arrays potentially being different sizes—this is called a *jagged
    array*. By “multidimensional table,” we mean, for instance, a list (dimension
    of one), a table or matrix (dimension of two), a table of tables or cube (dimension
    of three), and so forth. If the items are all of simple type such as integer or
    float, NumPy will store them as a compact C data structure in memory. This is
    where NumPy shines. NumPy has a wide variety of operators and methods that can
    run computations on these compact structures at the same speed as optimized C,
    because they are written in optimized C.
  prefs: []
  type: TYPE_NORMAL
- en: A PyTorch tensor is nearly the same thing as a NumPy array, but with an additional
    restriction that unlocks additional capabilities. It’s the same in that it, too,
    is a multidimensional table of data, with all items of the same type. However,
    the restriction is that a tensor cannot use just any old type—it has to use a
    single basic numeric type for all components. As a result, a tensor is not as
    flexible as a genuine array of arrays. For example, a PyTorch tensor cannot be
    jagged. It is always a regularly shaped multidimensional rectangular structure.
  prefs: []
  type: TYPE_NORMAL
- en: The vast majority of methods and operators supported by NumPy on these structures
    are also supported by PyTorch, but PyTorch tensors have additional capabilities.
    One major capability is that these structures can live on the GPU, in which case
    their computation will be optimized for the GPU and can run much faster (given
    lots of values to work on). In addition, PyTorch can automatically calculate derivatives
    of these operations, including combinations of operations. As you’ll see, it would
    be impossible to do deep learning in practice without this capability.
  prefs: []
  type: TYPE_NORMAL
- en: Sylvain Says
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you don’t know what C is, don’t worry: you won’t need it at all. In a nutshell,
    it’s a low-level (low-level means more similar to the language that computers
    use internally) language that is very fast compared to Python. To take advantage
    of its speed while programming in Python, try to avoid as much as possible writing
    loops, and replace them by commands that work directly on arrays or tensors.'
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps the most important new coding skill for a Python programmer to learn
    is how to effectively use the array/tensor APIs. We will be showing lots more
    tricks later in this book, but here’s a summary of the key things you need to
    know for now.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create an array or tensor, pass a list (or list of lists, or list of lists
    of lists, etc.) to `array` or `tensor`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: All the operations that follow are shown on tensors, but the syntax and results
    for NumPy arrays are identical.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can select a row (note that, like lists in Python, tensors are 0-indexed,
    so 1 refers to the second row/column):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Or a column, by using `:` to indicate *all of the first axis* (we sometimes
    refer to the dimensions of tensors/arrays as *axes*):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'You can combine these with Python slice syntax (`[*start*:*end*]`, with *`end`*
    being excluded) to select part of a row or column:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'And you can use the standard operators, such as `+`, `-`, `*`, and `/`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Tensors have a type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'And will automatically change that type as needed; for example, from `int`
    to `float`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: So, is our baseline model any good? To quantify this, we must define a metric.
  prefs: []
  type: TYPE_NORMAL
- en: Computing Metrics Using Broadcasting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recall that a *metric* is a number that is calculated based on the predictions
    of our model and the correct labels in our dataset, in order to tell us how good
    our model is. For instance, we could use either of the functions we saw in the
    previous section, mean squared error or mean absolute error, and take the average
    of them over the whole dataset. However, neither of these are numbers that are
    very understandable to most people; in practice, we normally use *accuracy* as
    the metric for classification models.
  prefs: []
  type: TYPE_NORMAL
- en: As we’ve discussed, we want to calculate our metric over a *validation set*.
    This is so that we don’t inadvertently overfit—that is, train a model to work
    well only on our training data. This is not really a risk with the pixel similarity
    model we’re using here as a first try, since it has no trained components, but
    we’ll use a validation set anyway to follow normal practices and to be ready for
    our second try later.
  prefs: []
  type: TYPE_NORMAL
- en: To get a validation set, we need to remove some of the data from training entirely,
    so it is not seen by the model at all. As it turns out, the creators of the MNIST
    dataset have already done this for us. Do you remember how there was a whole separate
    directory called *valid*? That’s what this directory is for!
  prefs: []
  type: TYPE_NORMAL
- en: 'So to start, let’s create tensors for our 3s and 7s from that directory. These
    are the tensors we will use to calculate a metric measuring the quality of our
    first-try model, which measures distance from an ideal image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: It’s good to get in the habit of checking shapes as you go. Here we see two
    tensors, one representing the 3s validation set of 1,010 images of size 28×28,
    and one representing the 7s validation set of 1,028 images of size 28×28.
  prefs: []
  type: TYPE_NORMAL
- en: We ultimately want to write a function, `is_3`, that will decide whether an
    arbitrary image is a 3 or a 7\. It will do this by deciding which of our two “ideal
    digits” that arbitrary image is closer to. For that we need to define a notion
    of *distance*—that is, a function that calculates the distance between two images.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can write a simple function that calculates the mean absolute error using
    an expression very similar to the one we wrote in the last section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: This is the same value we previously calculated for the distance between these
    two images, the ideal 3 `mean_3` and the arbitrary sample 3 `a_3`, which are both
    single-image tensors with a shape of `[28,28]`.
  prefs: []
  type: TYPE_NORMAL
- en: But to calculate a metric for overall accuracy, we will need to calculate the
    distance to the ideal 3 for *every* image in the validation set. How do we do
    that calculation? We could write a loop over all of the single-image tensors that
    are stacked within our validation set tensor, `valid_3_tens`, which has a shape
    of `[1010,28,28]` representing 1,010 images. But there is a better way.
  prefs: []
  type: TYPE_NORMAL
- en: 'Something interesting happens when we take this exact same distance function,
    designed for comparing two single images, but pass in as an argument `valid_3_tens`,
    the tensor that represents the 3s validation set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Instead of complaining about shapes not matching, it returned the distance for
    every single image as a vector (i.e., a rank-1 tensor) of length 1,010 (the number
    of 3s in our validation set). How did that happen?
  prefs: []
  type: TYPE_NORMAL
- en: 'Take another look at our function `mnist_distance`, and you’ll see we have
    there the subtraction `(a-b)`. The magic trick is that PyTorch, when it tries
    to perform a simple subtraction operation between two tensors of different ranks,
    will use *broadcasting*: it will automatically expand the tensor with the smaller
    rank to have the same size as the one with the larger rank. Broadcasting is an
    important capability that makes tensor code much easier to write.'
  prefs: []
  type: TYPE_NORMAL
- en: 'After broadcasting so the two argument tensors have the same rank, PyTorch
    applies its usual logic for two tensors of the same rank: it performs the operation
    on each corresponding element of the two tensors, and returns the tensor result.
    For instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'So in this case, PyTorch treats `mean3`, a rank-2 tensor representing a single
    image, as if it were 1,010 copies of the same image, and then subtracts each of
    those copies from each 3 in our validation set. What shape would you expect this
    tensor to have? Try to figure it out yourself before you look at the answer here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: We are calculating the difference between our ideal 3 and each of the 1,010
    3s in the validation set, for each of 28×28 images, resulting in the shape `[1010,28,28]`.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a couple of important points about how broadcasting is implemented,
    which make it valuable not just for expressivity but also for performance:'
  prefs: []
  type: TYPE_NORMAL
- en: PyTorch doesn’t *actually* copy `mean3` 1,010 times. It *pretends* it were a
    tensor of that shape, but doesn’t allocate any additional memory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It does the whole calculation in C (or, if you’re using a GPU, in CUDA, the
    equivalent of C on the GPU), tens of thousands of times faster than pure Python
    (up to millions of times faster on a GPU!).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is true of all broadcasting and elementwise operations and functions done
    in PyTorch. *It’s the most important technique for you to know to create efficient
    PyTorch code.*
  prefs: []
  type: TYPE_NORMAL
- en: Next in `mnist_distance` we see `abs`. You might be able to guess now what this
    does when applied to a tensor. It applies the method to each individual element
    in the tensor, and returns a tensor of the results (that is, it applies the method
    *elementwise*). So in this case, we’ll get back 1,010 absolute values.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, our function calls `mean((-1,-2))`. The tuple `(-1,-2)` represents
    a range of axes. In Python, `-1` refers to the last element, and `-2` refers to
    the second-to-last. So in this case, this tells PyTorch that we want to take the
    mean ranging over the values indexed by the last two axes of the tensor. The last
    two axes are the horizontal and vertical dimensions of an image. After taking
    the mean over the last two axes, we are left with just the first tensor axis,
    which indexes over our images, which is why our final size was `(1010)`. In other
    words, for every image, we averaged the intensity of all the pixels in that image.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll be learning lots more about broadcasting throughout this book, especially
    in [Chapter 17](ch17.xhtml#chapter_foundations), and will be practicing it regularly
    too.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use `mnist_distance` to figure out whether an image is a 3 by using
    the following logic: if the distance between the digit in question and the ideal
    3 is less than the distance to the ideal 7, then it’s a 3\. This function will
    automatically do broadcasting and be applied elementwise, just like all PyTorch
    functions and operators:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s test it on our example case:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Note that when we convert the Boolean response to a float, we get `1.0` for
    `True` and `0.0` for `False`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thanks to broadcasting, we can also test it on the full validation set of 3s:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can calculate the accuracy for each of the 3s and 7s, by taking the
    average of that function for all 3s and its inverse for all 7s:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'This looks like a pretty good start! We’re getting over 90% accuracy on both
    3s and 7s, and we’ve seen how to define a metric conveniently using broadcasting.
    But let’s be honest: 3s and 7s are very different-looking digits. And we’re classifying
    only 2 out of the 10 possible digits so far. So we’re going to need to do better!'
  prefs: []
  type: TYPE_NORMAL
- en: To do better, perhaps it is time to try a system that does some real learning—one
    that can automatically modify itself to improve its performance. In other words,
    it’s time to talk about the training process and SGD.
  prefs: []
  type: TYPE_NORMAL
- en: Stochastic Gradient Descent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Do you remember the way that Arthur Samuel described machine learning, which
    we quoted in [Chapter 1](ch01.xhtml#chapter_intro)?
  prefs: []
  type: TYPE_NORMAL
- en: Suppose we arrange for some automatic means of testing the effectiveness of
    any current weight assignment in terms of actual performance and provide a mechanism
    for altering the weight assignment so as to maximize the performance. We need
    not go into the details of such a procedure to see that it could be made entirely
    automatic and to see that a machine so programmed would “learn” from its experience.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As we discussed, this is the key to allowing us to have a model that can get
    better and better—that can learn. But our pixel similarity approach does not really
    do this. We do not have any kind of weight assignment, or any way of improving
    based on testing the effectiveness of a weight assignment. In other words, we
    can’t really improve our pixel similarity approach by modifying a set of parameters.
    To take advantage of the power of deep learning, we will first have to represent
    our task in the way that Samuel described it.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of trying to find the similarity between an image and an “ideal image,”
    we could instead look at each individual pixel and come up with a set of weights
    for each, such that the highest weights are associated with those pixels most
    likely to be black for a particular category. For instance, pixels toward the
    bottom right are not very likely to be activated for a 7, so they should have
    a low weight for a 7, but they are likely to be activated for an 8, so they should
    have a high weight for an 8\. This can be represented as a function and set of
    weight values for each possible category—for instance, the probability of being
    the number 8:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: Here we are assuming that `X` is the image, represented as a vector—in other
    words, with all of the rows stacked up end to end into a single long line. And
    we are assuming that the weights are a vector `W`. If we have this function, we
    just need some way to update the weights to make them a little bit better. With
    such an approach, we can repeat that step a number of times, making the weights
    better and better, until they are as good as we can make them.
  prefs: []
  type: TYPE_NORMAL
- en: We want to find the specific values for the vector `W` that cause the result
    of our function to be high for those images that are 8s, and low for those images
    that are not. Searching for the best vector `W` is a way to search for the best
    function for recognizing 8s. (Because we are not yet using a deep neural network,
    we are limited by what our function can do—we are going to fix that constraint
    later in this chapter.)
  prefs: []
  type: TYPE_NORMAL
- en: 'To be more specific, here are the steps required to turn this function into
    a machine learning classifier:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Initialize* the weights.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each image, use these weights to *predict* whether it appears to be a 3
    or a 7.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Based on these predictions, calculate how good the model is (its *loss*).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the *gradient*, which measures for each weight how changing that weight
    would change the loss.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Step* (that is, change) all the weights based on that calculation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Go back to step 2 and *repeat* the process.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Iterate until you decide to *stop* the training process (for instance, because
    the model is good enough or you don’t want to wait any longer).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These seven steps, illustrated in [Figure 4-1](#gradient_descent), are the key
    to the training of all deep learning models. That deep learning turns out to rely
    entirely on these steps is extremely surprising and counterintuitive. It’s amazing
    that this process can solve such complex problems. But, as you’ll see, it really
    does!
  prefs: []
  type: TYPE_NORMAL
- en: '![Graph showing the steps for Gradient Descent](Images/dlcf_0401.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-1\. The gradient descent process
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'There are many ways to do each of these seven steps, and we will be learning
    about them throughout the rest of this book. These are the details that make a
    big difference for deep learning practitioners, but it turns out that the general
    approach to each one follows some basic principles. Here are a few guidelines:'
  prefs: []
  type: TYPE_NORMAL
- en: Initialize
  prefs: []
  type: TYPE_NORMAL
- en: We initialize the parameters to random values. This may sound surprising. There
    are certainly other choices we could make, such as initializing them to the percentage
    of times that pixel is activated for that category—but since we already know that
    we have a routine to improve these weights, it turns out that just starting with
    random weights works perfectly well.
  prefs: []
  type: TYPE_NORMAL
- en: Loss
  prefs: []
  type: TYPE_NORMAL
- en: This is what Samuel referred to when he spoke of *testing the effectiveness
    of any current weight assignment in terms of actual performance*. We need a function
    that will return a number that is small if the performance of the model is good
    (the standard approach is to treat a small loss as good and a large loss as bad,
    although this is just a convention).
  prefs: []
  type: TYPE_NORMAL
- en: Step
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple way to figure out whether a weight should be increased a bit or decreased
    a bit would be just to try it: increase the weight by a small amount, and see
    if the loss goes up or down. Once you find the correct direction, you could then
    change that amount by a bit more, or a bit less, until you find an amount that
    works well. However, this is slow! As we will see, the magic of calculus allows
    us to directly figure out in which direction, and by roughly how much, to change
    each weight, without having to try all these small changes. The way to do this
    is by calculating *gradients*. This is just a performance optimization; we would
    get exactly the same results by using the slower manual process as well.'
  prefs: []
  type: TYPE_NORMAL
- en: Stop
  prefs: []
  type: TYPE_NORMAL
- en: Once we’ve decided how many epochs to train the model for (a few suggestions
    for this were given in the earlier list), we apply that decision. For our digit
    classifier, we would keep training until the accuracy of the model started getting
    worse, or we ran out of time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before applying these steps to our image classification problem, let’s illustrate
    what they look like in a simpler case. First we will define a very simple function,
    the quadratic—let’s pretend that this is our loss function, and `x` is a weight
    parameter of the function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a graph of that function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: '![](Images/dlcf_04in07.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The sequence of steps we described earlier starts by picking a random value
    for a parameter, and calculating the value of the loss:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: '![](Images/dlcf_04in08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Now we look to see what would happen if we increased or decreased our parameter
    by a little bit—the *adjustment*. This is simply the slope at a particular point:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A graph showing the squared function with the slope at one point](Images/dlcf_04in09.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can change our weight by a little in the direction of the slope, calculate
    our loss and adjustment again, and repeat this a few times. Eventually, we will
    get to the lowest point on our curve:'
  prefs: []
  type: TYPE_NORMAL
- en: '![An illustration of gradient descent](Images/dlcf_04in10.png)'
  prefs: []
  type: TYPE_IMG
- en: This basic idea goes all the way back to Isaac Newton, who pointed out that
    we can optimize arbitrary functions in this way. Regardless of how complicated
    our functions become, this basic approach of gradient descent will not significantly
    change. The only minor changes we will see later in this book are some handy ways
    we can make it faster, by finding better steps.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating Gradients
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The one magic step is the bit where we calculate the gradients. As we mentioned,
    we use calculus as a performance optimization; it allows us to more quickly calculate
    whether our loss will go up or down when we adjust our parameters up or down.
    In other words, the gradients will tell us how much we have to change each weight
    to make our model better.
  prefs: []
  type: TYPE_NORMAL
- en: You may remember from your high school calculus class that the *derivative*
    of a function tells you how much a change in its parameters will change its result.
    If not, don’t worry; lots of us forget calculus once high school is behind us!
    But you will need some intuitive understanding of what a derivative is before
    you continue, so if this is all very fuzzy in your head, head over to Khan Academy
    and complete the [lessons on basic derivatives](https://oreil.ly/nyd0R). You won’t
    have to know how to calculate them yourself; you just have to know what a derivative
    is.
  prefs: []
  type: TYPE_NORMAL
- en: 'The key point about a derivative is this: for any function, such as the quadratic
    function we saw in the previous section, we can calculate its derivative. The
    derivative is another function. It calculates the change, rather than the value.
    For instance, the derivative of the quadratic function at the value 3 tells us
    how rapidly the function changes at the value 3\. More specifically, you may recall
    that gradient is defined as *rise/run*; that is, the change in the value of the
    function, divided by the change in the value of the parameter. When we know how
    our function will change, we know what we need to do to make it smaller. This
    is the key to machine learning: having a way to change the parameters of a function
    to make it smaller. Calculus provides us with a computational shortcut, the derivative,
    which lets us directly calculate the gradients of our functions.'
  prefs: []
  type: TYPE_NORMAL
- en: One important thing to be aware of is that our function has lots of weights
    that we need to adjust, so when we calculate the derivative, we won’t get back
    one number, but lots of them—a gradient for every weight. But there is nothing
    mathematically tricky here; you can calculate the derivative with respect to one
    weight and treat all the other ones as constant, and then repeat that for each
    other weight. This is how all of the gradients are calculated, for every weight.
  prefs: []
  type: TYPE_NORMAL
- en: We mentioned just now that you won’t have to calculate any gradients yourself.
    How can that be? Amazingly enough, PyTorch is able to automatically compute the
    derivative of nearly any function! What’s more, it does it very fast. Most of
    the time, it will be at least as fast as any derivative function that you can
    create by hand. Let’s see an example.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s pick a tensor value at which we want gradients:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: Notice the special method `requires_grad_`? That’s the magical incantation we
    use to tell PyTorch that we want to calculate gradients with respect to that variable
    at that value. It is essentially tagging the variable, so PyTorch will remember
    to keep track of how to compute gradients of the other direct calculations on
    it that you will ask for.
  prefs: []
  type: TYPE_NORMAL
- en: Alexis Says
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This API might throw you off if you’re coming from math or physics. In those
    contexts, the “gradient” of a function is just another function (i.e., its derivative),
    so you might expect gradient-related APIs to give you a new function. But in deep
    learning, “gradient” usually means the *value* of a function’s derivative at a
    particular argument value. The PyTorch API also puts the focus on the argument,
    not the function you’re actually computing the gradients of. It may feel backward
    at first, but it’s just a different perspective.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we calculate our function with that value. Notice how PyTorch prints not
    just the value calculated, but also a note that it has a gradient function it’ll
    be using to calculate our gradients when needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we tell PyTorch to calculate the gradients for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: The “backward” here refers to *backpropagation*, which is the name given to
    the process of calculating the derivative of each layer. We’ll see how this is
    done exactly in [Chapter 17](ch17.xhtml#chapter_foundations), when we calculate
    the gradients of a deep neural net from scratch. This is called the *backward
    pass* of the network, as opposed to the *forward pass*, which is where the activations
    are calculated. Life would probably be easier if `backward` was just called `calculate_grad`,
    but deep learning folks really do like to add jargon everywhere they can!
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now view the gradients by checking the `grad` attribute of our tensor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: If you remember your high school calculus rules, the derivative of `x**2` is
    `2*x`, and we have `x=3`, so the gradients should be `2*3=6`, which is what PyTorch
    calculated for us!
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we’ll repeat the preceding steps, but with a vector argument for our function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'And we’ll add `sum` to our function so it can take a vector (i.e., a rank-1
    tensor) and return a scalar (i.e., a rank-0 tensor):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: Our gradients are `2*xt`, as we’d expect!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'The gradients tell us only the slope of our function; they don’t tell us exactly
    how far to adjust the parameters. But they do give us some idea of how far: if
    the slope is very large, that may suggest that we have more adjustments to do,
    whereas if the slope is very small, that may suggest that we are close to the
    optimal value.'
  prefs: []
  type: TYPE_NORMAL
- en: Stepping with a Learning Rate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Deciding how to change our parameters based on the values of the gradients
    is an important part of the deep learning process. Nearly all approaches start
    with the basic idea of multiplying the gradient by some small number, called the
    *learning rate* (LR). The learning rate is often a number between 0.001 and 0.1,
    although it could be anything. Often people select a learning rate just by trying
    a few, and finding which results in the best model after training (we’ll show
    you a better approach later in this book, called the *learning rate finder*).
    Once you’ve picked a learning rate, you can adjust your parameters using this
    simple function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: This is known as *stepping* your parameters, using an *optimization step*.
  prefs: []
  type: TYPE_NORMAL
- en: If you pick a learning rate that’s too low, it can mean having to do a lot of
    steps. [Figure 4-2](#descent_small) illustrates that.
  prefs: []
  type: TYPE_NORMAL
- en: '![An illustration of gradient descent with a LR too low](Images/dlcf_0402.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-2\. Gradient descent with low LR
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: But picking a learning rate that’s too high is even worse—it can result in the
    loss getting *worse*, as we see in [Figure 4-3](#descent_div)!
  prefs: []
  type: TYPE_NORMAL
- en: '![An illustration of gradient descent with a LR too high](Images/dlcf_0403.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-3\. Gradient descent with high LR
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If the learning rate is too high, it may also “bounce” around, rather than diverging;
    [Figure 4-4](#descent_bouncy) shows how this results in taking many steps to train
    successfully.
  prefs: []
  type: TYPE_NORMAL
- en: '![An illustation of gradient descent with a bouncy LR](Images/dlcf_0404.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-4\. Gradient descent with bouncy LR
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Now let’s apply all of this in an end-to-end example.
  prefs: []
  type: TYPE_NORMAL
- en: An End-to-End SGD Example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ve seen how to use gradients to minimize our loss. Now it’s time to look
    at an SGD example and see how finding a minimum can be used to train a model to
    fit data better.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s start with a simple, synthetic example model. Imagine you were measuring
    the speed of a roller coaster as it went over the top of a hump. It would start
    fast, and then get slower as it went up the hill; it would be slowest at the top,
    and it would then speed up again as it went downhill. You want to build a model
    of how the speed changes over time. If you were measuring the speed manually every
    second for 20 seconds, it might look something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: '![](Images/dlcf_04in11.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We’ve added a bit of random noise, since measuring things manually isn’t precise.
    This means it’s not that easy to answer the question: what was the roller coaster’s
    speed? Using SGD, we can try to find a function that matches our observations.
    We can’t consider every possible function, so let’s use a guess that it will be
    quadratic; i.e., a function of the form `a*(time**2)+(b*time)+c`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We want to distinguish clearly between the function’s input (the time when
    we are measuring the coaster’s speed) and its parameters (the values that define
    *which* quadratic we’re trying). So let’s collect the parameters in one argument
    and thus separate the input, `t`, and the parameters, `params`, in the function’s
    signature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: In other words, we’ve restricted the problem of finding the best imaginable
    function that fits the data to finding the best *quadratic* function. This greatly
    simplifies the problem, since every quadratic function is fully defined by the
    three parameters `a`, `b`, and `c`. Thus, to find the best quadratic function,
    we need to find only the best values for `a`, `b`, and `c`.
  prefs: []
  type: TYPE_NORMAL
- en: If we can solve this problem for the three parameters of a quadratic function,
    we’ll be able to apply the same approach for other, more complex functions with
    more parameters—such as a neural net. Let’s find the parameters for `f` first,
    and then we’ll come back and do the same thing for the MNIST dataset with a neural
    net.
  prefs: []
  type: TYPE_NORMAL
- en: 'We need to define first what we mean by “best.” We define this precisely by
    choosing a *loss function*, which will return a value based on a prediction and
    a target, where lower values of the function correspond to “better” predictions.
    For continuous data, it’s common to use *mean squared error*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s work through our seven-step process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 1: Initialize the parameters'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'First, we initialize the parameters to random values and tell PyTorch that
    we want to track their gradients using `requires_grad_`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 2: Calculate the predictions'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Next, we calculate the predictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s create a little function to see how close our predictions are to our
    targets, and take a look:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: '![](Images/dlcf_04in12.png)'
  prefs: []
  type: TYPE_IMG
- en: This doesn’t look very close—our random parameters suggest that the roller coaster
    will end up going backward, since we have negative speeds!
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 3: Calculate the loss'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We calculate the loss as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: Our goal is now to improve this. To do that, we’ll need to know the gradients.
  prefs: []
  type: TYPE_NORMAL
- en: 'Step 4: Calculate the gradients'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The next step is to calculate the gradients, or an approximation of how the
    parameters need to change:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use these gradients to improve our parameters. We’ll need to pick a
    learning rate (we’ll discuss how to do that in practice in the next chapter; for
    now, we’ll just use 1e-5 or 0.00001):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 5: Step the weights'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now we need to update the parameters based on the gradients we just calculated:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: Alexis Says
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Understanding this bit depends on remembering recent history. To calculate the
    gradients, we call `backward` on the `loss`. But this `loss` was itself calculated
    by `mse`, which in turn took `preds` as an input, which was calculated using `f`
    taking as an input `params`, which was the object on which we originally called
    `required_grads_`—which is the original call that now allows us to call `backward`
    on `loss`. This chain of function calls represents the mathematical composition
    of functions, which enables PyTorch to use calculus’s chain rule under the hood
    to calculate these gradients.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see if the loss has improved:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'And take a look at the plot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: '![](Images/dlcf_04in13.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We need to repeat this a few times, so we’ll create a function to apply one
    step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: 'Step 6: Repeat the process'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now we iterate. By looping and performing many improvements, we hope to reach
    a good result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: 'The loss is going down, just as we hoped! But looking only at these loss numbers
    disguises the fact that each iteration represents an entirely different quadratic
    function being tried, on the way to finding the best possible quadratic function.
    We can see this process visually if, instead of printing out the loss function,
    we plot the function at every step. Then we can see how the shape is approaching
    the best possible quadratic function for our data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: '![](Images/dlcf_04in14.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Step 7: Stop'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We just decided to stop after 10 epochs arbitrarily. In practice, we would watch
    the training and validation losses and our metrics to decide when to stop, as
    we’ve discussed.
  prefs: []
  type: TYPE_NORMAL
- en: Summarizing Gradient Descent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that you’ve seen what happens in each step, let’s take another look at our
    graphical representation of the gradient descent process ([Figure 4-5](#gradient_descent_process))
    and do a quick recap.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graph showing the steps for Gradient Descent](Images/dlcf_0405.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-5\. The gradient descent process
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: At the beginning, the weights of our model can be random (training *from scratch*)
    or come from a pretrained model (*transfer learning*). In the first case, the
    output we will get from our inputs won’t have anything to do with what we want,
    and even in the second case, it’s likely the pretrained model won’t be very good
    at the specific task we are targeting. So the model will need to *learn* better
    weights.
  prefs: []
  type: TYPE_NORMAL
- en: We begin by comparing the outputs the model gives us with our targets (we have
    labeled data, so we know what result the model should give) using a *loss function*,
    which returns a number that we want to make as low as possible by improving our
    weights. To do this, we take a few data items (such as images) from the training
    set and feed them to our model. We compare the corresponding targets using our
    loss function, and the score we get tells us how wrong our predictions were. We
    then change the weights a little bit to make it slightly better.
  prefs: []
  type: TYPE_NORMAL
- en: To find how to change the weights to make the loss a bit better, we use calculus
    to calculate the *gradients*. (Actually, we let PyTorch do it for us!) Let’s consider
    an analogy. Imagine you are lost in the mountains with your car parked at the
    lowest point. To find your way back to it, you might wander in a random direction,
    but that probably wouldn’t help much. Since you know your vehicle is at the lowest
    point, you would be better off going downhill. By always taking a step in the
    direction of the steepest downward slope, you should eventually arrive at your
    destination. We use the magnitude of the gradient (i.e., the steepness of the
    slope) to tell us how big a step to take; specifically, we multiply the gradient
    by a number we choose called the *learning rate* to decide on the step size. We
    then *iterate* until we have reached the lowest point, which will be our parking
    lot; then we can *stop*.
  prefs: []
  type: TYPE_NORMAL
- en: All of what we just saw can be transposed directly to the MNIST dataset, except
    for the loss function. Let’s now see how we can define a good training objective.
  prefs: []
  type: TYPE_NORMAL
- en: The MNIST Loss Function
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We already have our `x`s—that is, our independent variables, the images themselves.
    We’ll concatenate them all into a single tensor, and also change them from a list
    of matrices (a rank-3 tensor) to a list of vectors (a rank-2 tensor). We can do
    this using `view`, which is a PyTorch method that changes the shape of a tensor
    without changing its contents. `-1` is a special parameter to `view` that means
    “make this axis as big as necessary to fit all the data”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'We need a label for each image. We’ll use `1` for 3s and `0` for 7s:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: 'A `Dataset` in PyTorch is required to return a tuple of `(x,y)` when indexed.
    Python provides a `zip` function that, when combined with `list`, provides a simple
    way to get this functionality:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we need an (initially random) weight for every pixel (this is the *initialize*
    step in our seven-step process):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: 'The function `weights*pixels` won’t be flexible enough—it is always equal to
    0 when the pixels are equal to 0 (i.e., its *intercept* is 0). You might remember
    from high school math that the formula for a line is `y=w*x+b`; we still need
    the `b`. We’ll initialize it to a random number too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: In neural networks, the `w` in the equation `y=w*x+b` is called the *weights*,
    and the `b` is called the *bias*. Together, the weights and bias make up the *parameters*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Jargon: Parameters'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The *weights* and *biases* of a model. The weights are the `w` in the equation
    `w*x+b`, and the biases are the `b` in that equation.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now calculate a prediction for one image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: While we could use a Python `for` loop to calculate the prediction for each
    image, that would be very slow. Because Python loops don’t run on the GPU, and
    because Python is a slow language for loops in general, we need to represent as
    much of the computation in a model as possible using higher-level functions.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, there’s an extremely convenient mathematical operation that calculates
    `w*x` for every row of a matrix—it’s called *matrix multiplication*. [Figure 4-6](#matmul)
    shows what matrix multiplication looks like.
  prefs: []
  type: TYPE_NORMAL
- en: '![Matrix multiplication](Images/dlcf_0406.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4-6\. Matrix multiplication
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This image shows two matrices, `A` and `B`, being multiplied together. Each
    item of the result, which we’ll call `AB`, contains each item of its corresponding
    row of `A` multiplied by each item of its corresponding column of `B`, added together.
    For instance, row 1, column 2 (the yellow dot with a red border) is calculated
    as <math alttext="a Subscript 1 comma 1 Baseline asterisk b Subscript 1 comma
    2 plus a Subscript 1 comma 2 Baseline asterisk b Subscript 2 comma 2"><mrow><msub><mi>a</mi>
    <mrow><mn>1</mn><mo>,</mo><mn>1</mn></mrow></msub> <mo>*</mo> <msub><mi>b</mi>
    <mrow><mn>1</mn><mo>,</mo><mn>2</mn></mrow></msub> <mo>+</mo> <msub><mi>a</mi>
    <mrow><mn>1</mn><mo>,</mo><mn>2</mn></mrow></msub> <mo>*</mo> <msub><mi>b</mi>
    <mrow><mn>2</mn><mo>,</mo><mn>2</mn></mrow></msub></mrow></math> . If you need
    a refresher on matrix multiplication, we suggest you take a look at the [“Intro
    to Matrix Multiplication”](https://oreil.ly/w0XKS) on Khan Academy, since this
    is the most important mathematical operation in deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Python, matrix multiplication is represented with the `@` operator. Let’s
    try it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: The first element is the same as we calculated before, as we’d expect. This
    equation, `batch @ weights + bias`, is one of the two fundamental equations of
    any neural network (the other one is the *activation function*, which we’ll see
    in a moment).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s check our accuracy. To decide if an output represents a 3 or a 7, we
    can just check whether it’s greater than 0, so our accuracy for each item can
    be calculated (using broadcasting, so no loops!) as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: 'Now let’s see what the change in accuracy is for a small change in one of the
    weights:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE125]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE126]'
  prefs: []
  type: TYPE_PRE
- en: As we’ve seen, we need gradients in order to improve our model using SGD, and
    in order to calculate gradients we need a *loss function* that represents how
    good our model is. That is because the gradients are a measure of how that loss
    function changes with small tweaks to the weights.
  prefs: []
  type: TYPE_NORMAL
- en: So, we need to choose a loss function. The obvious approach would be to use
    accuracy, which is our metric, as our loss function as well. In this case, we
    would calculate our prediction for each image, collect these values to calculate
    an overall accuracy, and then calculate the gradients of each weight with respect
    to that overall accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, we have a significant technical problem here. The gradient of
    a function is its *slope*, or its steepness, which can be defined as *rise over
    run*—that is, how much the value of the function goes up or down, divided by how
    much we changed the input. We can write this mathematically as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: This gives a good approximation of the gradient when `x_new` is very similar
    to `x_old`, meaning that their difference is very small. But accuracy changes
    at all only when a prediction changes from a 3 to a 7, or vice versa. The problem
    is that a small change in weights from `x_old` to `x_new` isn’t likely to cause
    any prediction to change, so `(y_new – y_old)` will almost always be 0. In other
    words, the gradient is 0 almost everywhere.
  prefs: []
  type: TYPE_NORMAL
- en: A very small change in the value of a weight will often not change the accuracy
    at all. This means it is not useful to use accuracy as a loss function—if we do,
    most of the time our gradients will be 0, and the model will not be able to learn
    from that number.
  prefs: []
  type: TYPE_NORMAL
- en: Sylvain Says
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In mathematical terms, accuracy is a function that is constant almost everywhere
    (except at the threshold, 0.5), so its derivative is nil almost everywhere (and
    infinity at the threshold). This then gives gradients that are 0 or infinite,
    which are useless for updating the model.
  prefs: []
  type: TYPE_NORMAL
- en: Instead, we need a loss function that, when our weights result in slightly better
    predictions, gives us a slightly better loss. So what does a “slightly better
    prediction” look like, exactly? Well, in this case, it means that if the correct
    answer is a 3, the score is a little higher, or if the correct answer is a 7,
    the score is a little lower.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s write such a function now. What form does it take?
  prefs: []
  type: TYPE_NORMAL
- en: The loss function receives not the images themselves, but the predictions from
    the model. So let’s make one argument, `prds`, of values between 0 and 1, where
    each value is the prediction that an image is a 3\. It is a vector (i.e., a rank-1
    tensor) indexed over the images.
  prefs: []
  type: TYPE_NORMAL
- en: The purpose of the loss function is to measure the difference between predicted
    values and the true values—that is, the targets (aka labels). Let’s therefore
    make another argument, `trgts`, with values of 0 or 1 that tells whether an image
    actually is a 3 or not. It is also a vector (i.e., another rank-1 tensor) indexed
    over the images.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, suppose we had three images that we knew were a 3, a 7, and a
    3\. And suppose our model predicted with high confidence (`0.9`) that the first
    was a 3, with slight confidence (`0.4`) that the second was a 7, and with fair
    confidence (`0.2`), but incorrectly, that the last was a 7\. This would mean our
    loss function would receive these values as its inputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s a first try at a loss function that measures the distance between `predictions`
    and `targets`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: We’re using a new function, `torch.where(a,b,c)`. This is the same as running
    the list comprehension `[b[i] if a[i] else c[i] for i in range(len(a))]`, except
    it works on tensors, at C/CUDA speed. In plain English, this function will measure
    how distant each prediction is from 1 if it should be 1, and how distant it is
    from 0 if it should be 0, and then it will take the mean of all those distances.
  prefs: []
  type: TYPE_NORMAL
- en: Read the Docs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It’s important to learn about PyTorch functions like this, because looping over
    tensors in Python performs at Python speed, not C/CUDA speed! Try running `help(torch.where)`
    now to read the docs for this function, or, better still, look it up on the PyTorch
    documentation site.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try it on our `prds` and `trgts`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE130]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE131]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see that this function returns a lower number when predictions are
    more accurate, when accurate predictions are more confident (higher absolute values),
    and when inaccurate predictions are less confident. In PyTorch, we always assume
    that a lower value of a loss function is better. Since we need a scalar for the
    final loss, `mnist_loss` takes the mean of the previous tensor:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE133]'
  prefs: []
  type: TYPE_PRE
- en: 'For instance, if we change our prediction for the one “false” target from `0.2`
    to `0.8`, the loss will go down, indicating that this is a better prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE135]'
  prefs: []
  type: TYPE_PRE
- en: One problem with `mnist_loss` as currently defined is that it assumes that predictions
    are always between 0 and 1\. We need to ensure, then, that this is actually the
    case! As it happens, there is a function that does exactly that—let’s take a look.
  prefs: []
  type: TYPE_NORMAL
- en: Sigmoid
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `sigmoid` function always outputs a number between 0 and 1\. It’s defined
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs: []
  type: TYPE_PRE
- en: 'PyTorch defines an accelerated version for us, so we don’t really need our
    own. This is an important function in deep learning, since we often want to ensure
    that values are between 0 and 1\. This is what it looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE137]'
  prefs: []
  type: TYPE_PRE
- en: '![](Images/dlcf_04in15.png)'
  prefs: []
  type: TYPE_IMG
- en: As you can see, it takes any input value, positive or negative, and smooshes
    it into an output value between 0 and 1\. It’s also a smooth curve that only goes
    up, which makes it easier for SGD to find meaningful gradients.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s update `mnist_loss` to first apply `sigmoid` to the inputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs: []
  type: TYPE_PRE
- en: Now we can be confident our loss function will work, even if the predictions
    are not between 0 and 1\. All that is required is that a higher prediction corresponds
    to higher confidence.
  prefs: []
  type: TYPE_NORMAL
- en: Having defined a loss function, now is a good moment to recapitulate why we
    did this. After all, we already had a metric, which was overall accuracy. So why
    did we define a loss?
  prefs: []
  type: TYPE_NORMAL
- en: The key difference is that the metric is to drive human understanding and the
    loss is to drive automated learning. To drive automated learning, the loss must
    be a function that has a meaningful derivative. It can’t have big flat sections
    and large jumps, but instead must be reasonably smooth. This is why we designed
    a loss function that would respond to small changes in confidence level. This
    requirement means that sometimes it does not really reflect exactly what we are
    trying to achieve, but is rather a compromise between our real goal and a function
    that can be optimized using its gradient. The loss function is calculated for
    each item in our dataset, and then at the end of an epoch, the loss values are
    all averaged and the overall mean is reported for the epoch.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics, on the other hand, are the numbers that we care about. These are the
    values that are printed at the end of each epoch that tell us how our model is
    doing. It is important that we learn to focus on these metrics, rather than the
    loss, when judging the performance of a model.
  prefs: []
  type: TYPE_NORMAL
- en: SGD and Mini-Batches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have a loss function suitable for driving SGD, we can consider some
    of the details involved in the next phase of the learning process, which is to
    change or update the weights based on the gradients. This is called an *optimization
    step*.
  prefs: []
  type: TYPE_NORMAL
- en: To take an optimization step, we need to calculate the loss over one or more
    data items. How many should we use? We could calculate it for the whole dataset
    and take the average, or we could calculate it for a single data item. But neither
    of these is ideal. Calculating it for the whole dataset would take a long time.
    Calculating it for a single item would not use much information, so it would result
    in an imprecise and unstable gradient. You’d be going to the trouble of updating
    the weights, but taking into account only how that would improve the model’s performance
    on that single item.
  prefs: []
  type: TYPE_NORMAL
- en: 'So instead we compromise: we calculate the average loss for a few data items
    at a time. This is called a *mini-batch*. The number of data items in the mini-batch
    is called the *batch size*. A larger batch size means that you will get a more
    accurate and stable estimate of your dataset’s gradients from the loss function,
    but it will take longer, and you will process fewer mini-batches per epoch. Choosing
    a good batch size is one of the decisions you need to make as a deep learning
    practitioner to train your model quickly and accurately. We will talk about how
    to make this choice throughout this book.'
  prefs: []
  type: TYPE_NORMAL
- en: Another good reason for using mini-batches rather than calculating the gradient
    on individual data items is that, in practice, we nearly always do our training
    on an accelerator such as a GPU. These accelerators perform well only if they
    have lots of work to do at a time, so it’s helpful if we can give them lots of
    data items to work on. Using mini-batches is one of the best ways to do this.
    However, if you give them too much data to work on at once, they run out of memory—making
    GPUs happy is also tricky!
  prefs: []
  type: TYPE_NORMAL
- en: As you saw in our discussion of data augmentation in [Chapter 2](ch02.xhtml#chapter_production),
    we get better generalization if we can vary things during training. One simple
    and effective thing we can vary is what data items we put in each mini-batch.
    Rather than simply enumerating our dataset in order for every epoch, instead what
    we normally do is randomly shuffle it on every epoch, before we create mini-batches.
    PyTorch and fastai provide a class that will do the shuffling and mini-batch collation
    for you, called `DataLoader`.
  prefs: []
  type: TYPE_NORMAL
- en: 'A `DataLoader` can take any Python collection and turn it into an iterator
    over many batches, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE139]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE140]'
  prefs: []
  type: TYPE_PRE
- en: 'For training a model, we don’t just want any Python collection, but a collection
    containing independent and dependent variables (the inputs and targets of the
    model). A collection that contains tuples of independent and dependent variables
    is known in PyTorch as a `Dataset`. Here’s an example of an extremely simple `Dataset`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE141]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE142]'
  prefs: []
  type: TYPE_PRE
- en: 'When we pass a `Dataset` to a `DataLoader` we will get back many batches that
    are themselves tuples of tensors representing batches of independent and dependent
    variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE143]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE144]'
  prefs: []
  type: TYPE_PRE
- en: We are now ready to write our first training loop for a model using SGD!
  prefs: []
  type: TYPE_NORMAL
- en: Putting It All Together
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It’s time to implement the process we saw in [Figure 4-1](#gradient_descent).
    In code, our process will be implemented something like this for each epoch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE145]'
  prefs: []
  type: TYPE_PRE
- en: 'First, let’s reinitialize our parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE146]'
  prefs: []
  type: TYPE_PRE
- en: 'A `DataLoader` can be created from a `Dataset`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE147]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE148]'
  prefs: []
  type: TYPE_PRE
- en: 'We’ll do the same for the validation set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE149]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s create a mini-batch of size 4 for testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE150]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE151]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE152]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE153]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE154]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE155]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can calculate the gradients:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE156]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE157]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s put that all in a function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE158]'
  prefs: []
  type: TYPE_PRE
- en: 'And test it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE159]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE160]'
  prefs: []
  type: TYPE_PRE
- en: 'But look what happens if we call it twice:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE161]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE162]'
  prefs: []
  type: TYPE_PRE
- en: 'The gradients have changed! The reason for this is that `loss.backward` *adds*
    the gradients of `loss` to any gradients that are currently stored. So, we have
    to set the current gradients to 0 first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE163]'
  prefs: []
  type: TYPE_PRE
- en: In-Place Operations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Methods in PyTorch whose names end in an underscore modify their objects *in
    place*. For instance, `bias.zero_` sets all elements of the tensor `bias` to 0.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our only remaining step is to update the weights and biases based on the gradient
    and learning rate. When we do so, we have to tell PyTorch not to take the gradient
    of this step too—otherwise, things will get confusing when we try to compute the
    derivative at the next batch! If we assign to the `data` attribute of a tensor,
    PyTorch will not take the gradient of that step. Here’s our basic training loop
    for an epoch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE164]'
  prefs: []
  type: TYPE_PRE
- en: 'We also want to check how we’re doing, by looking at the accuracy of the validation
    set. To decide if an output represents a 3 or a 7, we can just check whether it’s
    greater than 0\. So our accuracy for each item can be calculated (using broadcasting,
    so no loops!) as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE165]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE166]'
  prefs: []
  type: TYPE_PRE
- en: 'That gives us this function to calculate our validation accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE167]'
  prefs: []
  type: TYPE_PRE
- en: 'We can check it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE168]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE169]'
  prefs: []
  type: TYPE_PRE
- en: 'And then put the batches together:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE170]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE171]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE172]'
  prefs: []
  type: TYPE_PRE
- en: 'That’s our starting point. Let’s train for one epoch and see if the accuracy
    improves:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE173]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE174]'
  prefs: []
  type: TYPE_PRE
- en: 'Then do a few more:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE175]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE176]'
  prefs: []
  type: TYPE_PRE
- en: Looking good! We’re already about at the same accuracy as our “pixel similarity”
    approach, and we’ve created a general-purpose foundation we can build on. Our
    next step will be to create an object that will handle the SGD step for us. In
    PyTorch, it’s called an *optimizer*.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an Optimizer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Because this is such a general foundation, PyTorch provides some useful classes
    to make it easier to implement. The first thing we can do is replace our `linear`
    function with PyTorch’s `nn.Linear` module. A *module* is an object of a class
    that inherits from the PyTorch `nn.Module` class. Objects of this class behave
    identically to standard Python functions, in that you can call them using parentheses,
    and they will return the activations of a model.
  prefs: []
  type: TYPE_NORMAL
- en: '`nn.Linear` does the same thing as our `init_params` and `linear` together.
    It contains both the *weights* and *biases* in a single class. Here’s how we replicate
    our model from the previous section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE177]'
  prefs: []
  type: TYPE_PRE
- en: 'Every PyTorch module knows what parameters it has that can be trained; they
    are available through the `parameters` method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE178]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE179]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use this information to create an optimizer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE180]'
  prefs: []
  type: TYPE_PRE
- en: 'We can create our optimizer by passing in the model’s parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE181]'
  prefs: []
  type: TYPE_PRE
- en: 'Our training loop can now be simplified:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE182]'
  prefs: []
  type: TYPE_PRE
- en: 'Our validation function doesn’t need to change at all:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE183]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE184]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s put our little training loop in a function, to make things simpler:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE185]'
  prefs: []
  type: TYPE_PRE
- en: 'The results are the same as in the previous section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE186]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE187]'
  prefs: []
  type: TYPE_PRE
- en: 'fastai provides the `SGD` class that, by default, does the same thing as our
    `BasicOptim`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE188]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE189]'
  prefs: []
  type: TYPE_PRE
- en: 'fastai also provides `Learner.fit`, which we can use instead of `train_model`.
    To create a `Learner`, we first need to create a `DataLoaders`, by passing in
    our training and validation `DataLoader`s:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE190]'
  prefs: []
  type: TYPE_PRE
- en: 'To create a `Learner` without using an application (such as `cnn_learner`),
    we need to pass in all the elements that we’ve created in this chapter: the `DataLoaders`,
    the model, the optimization function (which will be passed the parameters), the
    loss function, and optionally any metrics to print:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE191]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can call `fit`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE192]'
  prefs: []
  type: TYPE_PRE
- en: '| epoch | train_loss | valid_loss | batch_accuracy | time |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0.636857 | 0.503549 | 0.495584 | 00:00 |'
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0.545725 | 0.170281 | 0.866045 | 00:00 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 | 0.199223 | 0.184893 | 0.831207 | 00:00 |'
  prefs: []
  type: TYPE_TB
- en: '| 3 | 0.086580 | 0.107836 | 0.911187 | 00:00 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 | 0.045185 | 0.078481 | 0.932777 | 00:00 |'
  prefs: []
  type: TYPE_TB
- en: '| 5 | 0.029108 | 0.062792 | 0.946516 | 00:00 |'
  prefs: []
  type: TYPE_TB
- en: '| 6 | 0.022560 | 0.053017 | 0.955348 | 00:00 |'
  prefs: []
  type: TYPE_TB
- en: '| 7 | 0.019687 | 0.046500 | 0.962218 | 00:00 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 | 0.018252 | 0.041929 | 0.965162 | 00:00 |'
  prefs: []
  type: TYPE_TB
- en: '| 9 | 0.017402 | 0.038573 | 0.967615 | 00:00 |'
  prefs: []
  type: TYPE_TB
- en: As you can see, there’s nothing magic about the PyTorch and fastai classes.
    They are just convenient prepackaged pieces that make your life a bit easier!
    (They also provide a lot of extra functionality we’ll be using in future chapters.)
  prefs: []
  type: TYPE_NORMAL
- en: With these classes, we can now replace our linear model with a neural network.
  prefs: []
  type: TYPE_NORMAL
- en: Adding a Nonlinearity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So far, we have a general procedure for optimizing the parameters of a function,
    and we have tried it out on a boring function: a simple linear classifier. A linear
    classifier is constrained in terms of what it can do. To make it a bit more complex
    (and able to handle more tasks), we need to add something nonlinear (i.e., different
    from ax+b) between two linear classifiers—this is what gives us a neural network.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the entire definition of a basic neural network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE193]'
  prefs: []
  type: TYPE_PRE
- en: That’s it! All we have in `simple_net` is two linear classifiers with a `max`
    function between them.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, `w1` and `w2` are weight tensors, and `b1` and `b2` are bias tensors;
    that is, parameters that are initially randomly initialized, just as we did in
    the previous section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE194]'
  prefs: []
  type: TYPE_PRE
- en: The key point is that `w1` has 30 output activations (which means that `w2`
    must have 30 input activations, so they match). That means that the first layer
    can construct 30 different features, each representing a different mix of pixels.
    You can change that `30` to anything you like, to make the model more or less
    complex.
  prefs: []
  type: TYPE_NORMAL
- en: 'That little function `res.max(tensor(0.0))` is called a *rectified linear unit*,
    also known as *ReLU*. We think we can all agree that *rectified linear unit* sounds
    pretty fancy and complicated…But actually, there’s nothing more to it than `res.max(tensor(0.0))`—in
    other words, replace every negative number with a zero. This tiny function is
    also available in PyTorch as `F.relu`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE195]'
  prefs: []
  type: TYPE_PRE
- en: '![](Images/dlcf_04in16.png)'
  prefs: []
  type: TYPE_IMG
- en: Jeremy Says
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There is an enormous amount of jargon in deep learning, including terms like
    *rectified linear unit*. The vast majority of this jargon is no more complicated
    than can be implemented in a short line of code, as we saw in this example. The
    reality is that for academics to get their papers published, they need to make
    them sound as impressive and sophisticated as possible. One way that they do that
    is to introduce jargon. Unfortunately, this results in the field becoming far
    more intimidating and difficult to get into than it should be. You do have to
    learn the jargon, because otherwise papers and tutorials are not going to mean
    much to you. But that doesn’t mean you have to find the jargon intimidating. Just
    remember, when you come across a word or phrase that you haven’t seen before,
    it will almost certainly turn out to be referring to a very simple concept.
  prefs: []
  type: TYPE_NORMAL
- en: The basic idea is that by using more linear layers, we can have our model do
    more computation, and therefore model more complex functions. But there’s no point
    in just putting one linear layout directly after another one, because when we
    multiply things together and then add them up multiple times, that could be replaced
    by multiplying different things together and adding them up just once! That is
    to say, a series of any number of linear layers in a row can be replaced with
    a single linear layer with a different set of parameters.
  prefs: []
  type: TYPE_NORMAL
- en: But if we put a nonlinear function between them, such as `max`, this is no longer
    true. Now each linear layer is somewhat decoupled from the other ones and can
    do its own useful work. The `max` function is particularly interesting, because
    it operates as a simple `if` statement.
  prefs: []
  type: TYPE_NORMAL
- en: Sylvain Says
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Mathematically, we say the composition of two linear functions is another linear
    function. So, we can stack as many linear classifiers as we want on top of each
    other, and without nonlinear functions between them, it will just be the same
    as one linear classifier.
  prefs: []
  type: TYPE_NORMAL
- en: Amazingly enough, it can be mathematically proven that this little function
    can solve any computable problem to an arbitrarily high level of accuracy, if
    you can find the right parameters for `w1` and `w2` and if you make these matrices
    big enough. For any arbitrarily wiggly function, we can approximate it as a bunch
    of lines joined together; to make it closer to the wiggly function, we just have
    to use shorter lines. This is known as the *universal approximation theorem*.
    The three lines of code that we have here are known as *layers*. The first and
    third are known as *linear layers*, and the second line of code is known variously
    as a *nonlinearity*, or *activation function*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Just as in the previous section, we can replace this code with something a
    bit simpler by taking advantage of PyTorch:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE196]'
  prefs: []
  type: TYPE_PRE
- en: '`nn.Sequential` creates a module that will call each of the listed layers or
    functions in turn.'
  prefs: []
  type: TYPE_NORMAL
- en: '`nn.ReLU` is a PyTorch module that does exactly the same thing as the `F.relu`
    function. Most functions that can appear in a model also have identical forms
    that are modules. Generally, it’s just a case of replacing `F` with `nn` and changing
    the capitalization. When using `nn.Sequential`, PyTorch requires us to use the
    module version. Since modules are classes, we have to instantiate them, which
    is why you see `nn.ReLU` in this example.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Because `nn.Sequential` is a module, we can get its parameters, which will
    return a list of all the parameters of all the modules it contains. Let’s try
    it out! As this is a deeper model, we’ll use a lower learning rate and a few more
    epochs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE197]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE198]'
  prefs: []
  type: TYPE_PRE
- en: 'We’re not showing the 40 lines of output here to save room; the training process
    is recorded in `learn.recorder`, with the table of output stored in the `values`
    attribute, so we can plot the accuracy over training:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE199]'
  prefs: []
  type: TYPE_PRE
- en: '![](Images/dlcf_04in17.png)'
  prefs: []
  type: TYPE_IMG
- en: 'And we can view the final accuracy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE200]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE201]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, we have something that is rather magical:'
  prefs: []
  type: TYPE_NORMAL
- en: A function that can solve any problem to any level of accuracy (the neural network)
    given the correct set of parameters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A way to find the best set of parameters for any function (stochastic gradient
    descent)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This is why deep learning can do such fantastic things. Believing that this
    combination of simple techniques can really solve any problem is one of the biggest
    steps that we find many students have to take. It seems too good to be true—surely
    things should be more difficult and complicated than this? Our recommendation:
    try it out! We just tried it on the MNIST dataset, and you’ve seen the results.
    And since we are doing everything from scratch ourselves (except for calculating
    the gradients), you know that there is no special magic hiding behind the scenes.'
  prefs: []
  type: TYPE_NORMAL
- en: Going Deeper
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There is no need to stop at just two linear layers. We can add as many as we
    want, as long as we add a nonlinearity between each pair of linear layers. As
    you will learn, however, the deeper the model gets, the harder it is to optimize
    the parameters in practice. Later in this book, you will learn about some simple
    but brilliantly effective techniques for training deeper models.
  prefs: []
  type: TYPE_NORMAL
- en: We already know that a single nonlinearity with two linear layers is enough
    to approximate any function. So why would we use deeper models? The reason is
    performance. With a deeper model (one with more layers), we do not need to use
    as many parameters; it turns out that we can use smaller matrices, with more layers,
    and get better results than we would get with larger matrices and few layers.
  prefs: []
  type: TYPE_NORMAL
- en: That means that we can train the model more quickly, and it will take up less
    memory. In the 1990s, researchers were so focused on the universal approximation
    theorem that few were experimenting with more than one nonlinearity. This theoretical
    but not practical foundation held back the field for years. Some researchers,
    however, did experiment with deep models, and eventually were able to show that
    these models could perform much better in practice. Eventually, theoretical results
    were developed that showed why this happens. Today, it is extremely unusual to
    find anybody using a neural network with just one nonlinearity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is what happens when we train an 18-layer model using the same approach
    we saw in [Chapter 1](ch01.xhtml#chapter_intro):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE202]'
  prefs: []
  type: TYPE_PRE
- en: '| epoch | train_loss | valid_loss | accuracy | time |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0.082089 | 0.009578 | 0.997056 | 00:11 |'
  prefs: []
  type: TYPE_TB
- en: Nearly 100% accuracy! That’s a big difference compared to our simple neural
    net. But as you’ll learn in the remainder of this book, there are just a few little
    tricks you need to use to get such great results from scratch yourself. You already
    know the key foundational pieces. (Of course, even when you know all the tricks,
    you’ll nearly always want to work with the prebuilt classes provided by PyTorch
    and fastai, because they save you from having to think about all the little details
    yourself.)
  prefs: []
  type: TYPE_NORMAL
- en: Jargon Recap
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Congratulations: you now know how to create and train a deep neural network
    from scratch! We’ve gone through quite a few steps to get to this point, but you
    might be surprised at how simple it really is.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we are at this point, it is a good opportunity to define, and review,
    some jargon and key concepts.
  prefs: []
  type: TYPE_NORMAL
- en: 'A neural network contains a lot of numbers, but they are only of two types:
    numbers that are calculated, and the parameters that these numbers are calculated
    from. This gives us the two most important pieces of jargon to learn:'
  prefs: []
  type: TYPE_NORMAL
- en: Activations
  prefs: []
  type: TYPE_NORMAL
- en: Numbers that are calculated (both by linear and nonlinear layers)
  prefs: []
  type: TYPE_NORMAL
- en: Parameters
  prefs: []
  type: TYPE_NORMAL
- en: Numbers that are randomly initialized, and optimized (that is, the numbers that
    define the model)
  prefs: []
  type: TYPE_NORMAL
- en: We will often talk in this book about activations and parameters. Remember that
    they have specific meanings. They are numbers. They are not abstract concepts,
    but they are actual specific numbers that are in your model. Part of becoming
    a good deep learning practitioner is getting used to the idea of looking at your
    activations and parameters, and plotting them and testing whether they are behaving
    correctly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our activations and parameters are all contained in *tensors*. These are simply
    regularly shaped arrays—for example, a matrix. Matrices have rows and columns;
    we call these the *axes* or *dimensions*. The number of dimensions of a tensor
    is its *rank*. There are some special tensors:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Rank-0: scalar'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rank-1: vector'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rank-2: matrix'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A neural network contains a number of layers. Each layer is either *linear*
    or *nonlinear*. We generally alternate between these two kinds of layers in a
    neural network. Sometimes people refer to both a linear layer and its subsequent
    nonlinearity together as a single layer. Yes, this is confusing. Sometimes a nonlinearity
    is referred to as an *activation function*.
  prefs: []
  type: TYPE_NORMAL
- en: '[Table 4-1](#dljargon1) summarizes the key concepts related to SGD.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 4-1\. Deep learning vocabulary
  prefs: []
  type: TYPE_NORMAL
- en: '| Term | Meaning |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| ReLU | Function that returns 0 for negative numbers and doesn’t change positive
    numbers. |'
  prefs: []
  type: TYPE_TB
- en: '| Mini-batch | A small group of inputs and labels gathered together in two
    arrays. A gradient descent step is updated on this batch (rather than a whole
    epoch). |'
  prefs: []
  type: TYPE_TB
- en: '| Forward pass | Applying the model to some input and computing the predictions.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Loss | A value that represents how well (or badly) our model is doing. |'
  prefs: []
  type: TYPE_TB
- en: '| Gradient | The derivative of the loss with respect to some parameter of the
    model. |'
  prefs: []
  type: TYPE_TB
- en: '| Backward pass | Computing the gradients of the loss with respect to all model
    parameters. |'
  prefs: []
  type: TYPE_TB
- en: '| Gradient descent | Taking a step in the direction opposite to the gradients
    to make the model parameters a little bit better. |'
  prefs: []
  type: TYPE_TB
- en: '| Learning rate | The size of the step we take when applying SGD to update
    the parameters of the model. |'
  prefs: []
  type: TYPE_TB
- en: '*Choose Your Own Adventure* Reminder'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Did you choose to skip over Chapters [2](ch02.xhtml#chapter_production) and
    [3](ch03.xhtml#chapter_ethics), in your excitement to peek under the hood? Well,
    here’s your reminder to head back to [Chapter 2](ch02.xhtml#chapter_production)
    now, because you’ll be needing to know that stuff soon!
  prefs: []
  type: TYPE_NORMAL
- en: Questionnaire
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: How is a grayscale image represented on a computer? How about a color image?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How are the files and folders in the `MNIST_SAMPLE` dataset structured? Why?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Explain how the “pixel similarity” approach to classifying digits works.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a list comprehension? Create one now that selects odd numbers from a
    list and doubles them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a rank-3 tensor?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between tensor rank and shape? How do you get the rank
    from the shape?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are RMSE and L1 norm?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can you apply a calculation on thousands of numbers at once, many thousands
    of times faster than a Python loop?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a 3×3 tensor or array containing the numbers from 1 to 9\. Double it.
    Select the bottom-right four numbers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is broadcasting?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Are metrics generally calculated using the training set or the validation set?
    Why?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is SGD?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why does SGD use mini-batches?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the seven steps in SGD for machine learning?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do we initialize the weights in a model?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is loss?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why can’t we always use a high learning rate?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a gradient?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Do you need to know how to calculate gradients yourself?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why can’t we use accuracy as a loss function?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw the sigmoid function. What is special about its shape?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between a loss function and a metric?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the function to calculate new weights using a learning rate?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does the `DataLoader` class do?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Write pseudocode showing the basic steps taken in each epoch for SGD.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create a function that, if passed two arguments `[1,2,3,4]` and `'abcd'`, returns
    `[(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')]`. What is special about that output
    data structure?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does `view` do in PyTorch?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the bias parameters in a neural network? Why do we need them?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does the `@` operator do in Python?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does the `backward` method do?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Why do we have to zero the gradients?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What information do we have to pass to `Learner`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Show Python or pseudocode for the basic steps of a training loop.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is ReLU? Draw a plot of it for values from `-2` to `+2`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is an activation function?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What’s the difference between `F.relu` and `nn.ReLU`?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The universal approximation theorem shows that any function can be approximated
    as closely as needed using just one nonlinearity. So why do we normally use more?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further Research
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Create your own implementation of `Learner` from scratch, based on the training
    loop shown in this chapter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Complete all the steps in this chapter using the full MNIST datasets (for all
    digits, not just 3s and 7s). This is a significant project and will take you quite
    a bit of time to complete! You’ll need to do some of your own research to figure
    out how to overcome obstacles you’ll meet on the way.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
