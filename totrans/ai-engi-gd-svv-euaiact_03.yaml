- en: Chapter 3\. Data and AI Governance and AI Engineering
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The first chapter of this book introduced the EU AI Act and laid the foundation
    for understanding trustworthy AI as its primary motivation. We then explored the
    engineering aspects of the ML development process and examined the synergy between
    the CRISP-ML(Q) lifecycle model and the technical components of MLOps, highlighting
    how this integration supports the development of trustworthy AI through structured
    processes, transparency, and reproducibility. Here, we will focus on compliance
    from an organizational perspective, considering the interplay between data and
    AI governance, risk management, and conformity with the EU AI Act.
  prefs: []
  type: TYPE_NORMAL
- en: The Importance of Data and AI Governance in the EU AI Act Era
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s start with three notable real-world examples that illustrate how poor
    data governance and AI governance practices have led to significant failures of
    AI products:'
  prefs: []
  type: TYPE_NORMAL
- en: IBM Watson for Oncology
  prefs: []
  type: TYPE_NORMAL
- en: The development of Watson for Oncology (launched in 2016) faced significant
    criticism due to the system recommending [unsafe and incorrect cancer treatments](https://oreil.ly/iCQ0B).
    This was attributed to incomplete and biased training data that included only
    a small number of synthetic cancer cases rather than real clinical data, resulting
    in flawed recommendations and limited clinical relevance. Internal documents and
    customer feedback highlighted a lack of transparency, systemic issues, and dissatisfaction
    with the product’s recommendations. This case emphasizes the critical need for
    high-quality, accurate, and relevant data in AI training.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon’s AI recruiting tool
  prefs: []
  type: TYPE_NORMAL
- en: In 2018, Amazon developed an experimental AI recruiting tool to automate candidate
    screening. However, the system was found to exhibit [bias against women](https://oreil.ly/L2cEr),
    due to the AI model being trained on 10 years’ worth of resumes that had come
    overwhelmingly from male candidates. This led to it downgrading resumes containing
    the word “women’s” and penalizing candidates from all-women’s colleges. This result
    highlighted the lack of sufficient auditing of the training data and model for
    demographic bias and led to Amazon scrapping the tool entirely. This case underscores
    the need for careful data screening and debiasing in AI applications.
  prefs: []
  type: TYPE_NORMAL
- en: iTutor Group’s AI recruiting tool
  prefs: []
  type: TYPE_NORMAL
- en: In 2023, iTutor Group used AI-powered recruiting software that automatically
    rejected female applicants aged 55 and older and male applicants aged 60 and older.
    The system’s screening criteria were based on age, leading to discriminatory practices.
    As a result, the US Equal Employment Opportunity Commission (EEOC) filed a suit
    against iTutor Group, which [the company settled](https://oreil.ly/66rkj) by agreeing
    to pay $365,000 and implement new anti-discrimination policies. This case highlights
    the need for oversight and bias prevention in AI recruiting tools.​
  prefs: []
  type: TYPE_NORMAL
- en: These and other [famous AI disasters](https://oreil.ly/l3E9Y) illustrate the
    critical need for rigorous data governance practices, including ensuring data
    quality, representativeness, and transparency. Thorough data quality assessments,
    robust data protection measures, and ethical considerations in AI development
    and deployment are essential. Comprehensive bias testing across diverse populations
    is particularly important in sensitive areas such as healthcare and education,
    and ongoing monitoring and auditing of AI systems in production are necessary
    to identify and address issues early.
  prefs: []
  type: TYPE_NORMAL
- en: Data and AI governance play a vital role in the age of the EU AI Act. Organizations
    must have robust data and AI governance frameworks in place to meet the Act’s
    strict requirements related to data quality, documentation, transparency, human
    oversight, and risk management. Moreover, effective governance is essential for
    identifying, assessing, and mitigating the risks associated with AI systems, which
    can pose threats to fundamental rights, safety, and the environment if not properly
    managed.
  prefs: []
  type: TYPE_NORMAL
- en: Strong data and AI governance promote responsible and ethical AI development,
    in line with the EU AI Act’s aim to foster the development of trustworthy AI that
    upholds EU values and principles. This approach enables organizations to innovate
    with AI while safeguarding privacy and other fundamental rights.
  prefs: []
  type: TYPE_NORMAL
- en: Transparency and explainability in AI systems are not just technical challenges
    but legal and ethical requirements. The examples mentioned here underscore the
    critical need for rigorous data governance practices, including ensuring data
    quality, representativeness, transparency, and ethical considerations in AI development
    and deployment. Next, we’ll take a closer look at what those practices entail.
  prefs: []
  type: TYPE_NORMAL
- en: Overview of Data Governance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At the heart of the EU AI Act lies a motivation to create AI systems that are
    not just powerful but trustworthy. Data governance is a pretty dry topic to describe,
    so I recommend you start by reviewing the metaphorical framework in the following
    sidebar to make the abstract concepts more tangible.
  prefs: []
  type: TYPE_NORMAL
- en: Data Governance Defined
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we saw in [Chapter 1](ch01.html#chapter_1_understanding_the_ai_regulations_1748539916832819),
    data governance is a data management function that guarantees the availability,
    usability, integrity, and security of the data collected and used in an organization.
    While the core principles of data governance remain consistent across industries,
    the specific focus and implementation can vary based on industry needs and regulatory
    requirements. For instance, data governance in healthcare encompasses “the overall
    administration, through clearly defined procedures and plans, that assures the
    availability, integrity, security, and usability of the structured and unstructured
    data available to an organization while ensuring compliance with regulations such
    as HIPAA.”^([1](ch03.html#id469)) Here, the focus is on ensuring patient data
    privacy and security and maintaining compliance with healthcare regulations (e.g.,
    HIPAA).
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, data governance in banking involves “establishing policies,
    procedures, and controls for data quality, privacy, and security; implementing
    data management technologies and systems; and ensuring that data across the organization
    is consistent, accessible, and properly used.”^([2](ch03.html#id471)) Here, the
    focus is on ensuring data accuracy for risk assessment and management, complying
    with financial regulations (e.g., Basel III, the Dodd-Frank Act), and protecting
    sensitive financial information.
  prefs: []
  type: TYPE_NORMAL
- en: The Data Engineering Lifecycle and Data Governance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One way to understand the data governance framework is to apply governance concepts
    across each stage of the typical data engineering lifecycle, as depicted in [Figure 3-1](#chapter_3_figure_1_1748539918097843).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/taie_0301.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-1\. The data governance process across the stages of the data engineering
    lifecycle (adapted from [Fundamentals of Data Engineering](https://oreil.ly/2JPXv)
    by Joe Reis and Matt Housley [O’Reilly])
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The data engineering lifecycle comprises the following stages: data generation,
    storage, ingestion, transformation, and serving. Let’s take a closer look at how
    governance applies to each of those stages.'
  prefs: []
  type: TYPE_NORMAL
- en: Data generation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At the start of the data engineering lifecycle, data is created or collected
    from various source systems (applications, databases, Internet of Things devices,
    etc.). In the data generation stage, data governance processes focus on establishing
    data quality standards and validation rules.
  prefs: []
  type: TYPE_NORMAL
- en: Usually, at this point you define metadata requirements and implement data collection
    policies compliant with privacy regulations. Additionally, within the organization,
    data ownership is defined and corresponding roles are assigned. For example, an
    organization can implement automated data quality checks at the point of data
    creation, ensuring that customer data adheres to predefined formats and completeness
    criteria.
  prefs: []
  type: TYPE_NORMAL
- en: Ingestion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the next phase, data is moved from the source systems into centralized storage
    or processing systems. Data governance processes focus on data lineage tracking,
    implementing data classification, and tagging. An important part of data governance
    is monitoring data quality during ingestion and maintaining audit logs of data
    movement. Often, organizations automatically tag incoming data with source information
    and sensitivity levels. This enables easier tracking and management of data throughout
    its lifecycle.
  prefs: []
  type: TYPE_NORMAL
- en: Transformation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: During the transformation stage of the data engineering lifecycle, raw data
    is cleaned, normalized, aggregated, and converted into formats suitable for analysis.
    At this point, data governance ensures that data quality rules are enforced. You
    should maintain data lineage throughout all transformations and apply version
    control to data models.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine a retail company processing customer purchase data. Here, data governance
    tasks might include data quality (error) checks, such as verifying that email
    formats are valid and there are no duplicate entries, and data cleaning procedures
    such as removing inconsistencies in product names. All extract–transform–load
    (ETL) processes should be documented, and changes to the customer data model should
    go through a formal approval process. In addition, it’s essential to ensure compliance
    with data privacy regulations during transformations.
  prefs: []
  type: TYPE_NORMAL
- en: Storage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Next, the transformed data is stored in systems such as data lakes, data warehouses,
    or other cloud-based storage solutions. At this stage, data governance involves
    defining data retention policies, implementing access controls and encryption,
    and ensuring proper data backups. Maintaining data lineage and audit trails is
    also essential for accountability and traceability.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, organizations may implement role-based access controls and encrypt
    sensitive data at rest to protect personal information in compliance with the
    GDPR. Scheduling regular data backups and disaster recovery tests are also common
    practices to ensure data resilience and availability.
  prefs: []
  type: TYPE_NORMAL
- en: Serving
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the final stage of the data engineering lifecycle, serving, processed data
    and insights are made available to end users, applications, or external partners
    for consumption and analysis. Data governance requires that organizations control
    access to data based on user roles and permissions and implement data masking
    for sensitive information. Monitoring data usage, access patterns, and compliance
    with data sharing agreements is also essential. Many organizations implement self-service
    data portals that allow users to access datasets appropriate to their roles or
    use cases, with sensitive information automatically masked, redacted, or anonymized
    based on predefined governance rules.
  prefs: []
  type: TYPE_NORMAL
- en: Organizations can ensure data quality, security, and compliance by applying
    these governance processes across the data engineering lifecycle. This approach
    to data governance helps AI engineers understand the importance of maintaining
    data integrity and security throughout the entire data pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating Data Governance into MLOps
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As you learned in [Chapter 2](ch02.html#chapter_2_ai_engineering_a_proactive_compliance_catalyst_1748539917637495),
    the MLOps Stack Canvas provides a comprehensive blueprint for designing the end-to-end
    technical infrastructure needed to develop, deploy, and maintain machine learning
    applications in a robust, scalable, and governed manner. It facilitates cost estimation,
    planning, and decision making for operationalizing machine learning across the
    entire lifecycle. By extending the MLOps Stack Canvas with data governance considerations
    (which you will do here), you can ensure that data is managed responsibly and
    complies with relevant regulations throughout the ML lifecycle. This holistic
    approach to MLOps and data governance enables organizations to build trustworthy,
    compliant, and sustainable ML systems.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a look at how we can incorporate data governance into each of the
    MLOps Stack Canvas’s components.
  prefs: []
  type: TYPE_NORMAL
- en: Value Proposition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When you formulate a general value proposition for the MLOps platform you’re
    building, be sure to include data governance goals and compliance requirements
    in the value proposition. Consider how data governance enhances the overall value
    of the ML project.
  prefs: []
  type: TYPE_NORMAL
- en: 'A useful way to track the success of data governance integration into the AI
    lifecycle is to define and track particular metrics, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Policy compliance rate
  prefs: []
  type: TYPE_NORMAL
- en: The percentage of data management activities that comply with established policies
    and standards.
  prefs: []
  type: TYPE_NORMAL
- en: Regulatory compliance
  prefs: []
  type: TYPE_NORMAL
- en: The percentage of data processes and policies that comply with relevant regulations.
  prefs: []
  type: TYPE_NORMAL
- en: Audit compliance rate
  prefs: []
  type: TYPE_NORMAL
- en: The success rate of internal and external audits in terms of compliance with
    data governance policies.
  prefs: []
  type: TYPE_NORMAL
- en: Incident response time
  prefs: []
  type: TYPE_NORMAL
- en: The average time taken to respond to data governance–related incidents or issues.
  prefs: []
  type: TYPE_NORMAL
- en: Data audit results
  prefs: []
  type: TYPE_NORMAL
- en: The number of audit findings related to data governance and the severity of
    these findings.
  prefs: []
  type: TYPE_NORMAL
- en: Training and certification levels
  prefs: []
  type: TYPE_NORMAL
- en: The number of employees who have completed data governance training and certifications.
  prefs: []
  type: TYPE_NORMAL
- en: Cost of poor data quality
  prefs: []
  type: TYPE_NORMAL
- en: The financial impact of data quality issues, including costs associated with
    correcting errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Useful metrics to consider to track data usage, quality, and security include:'
  prefs: []
  type: TYPE_NORMAL
- en: Data accessibility
  prefs: []
  type: TYPE_NORMAL
- en: The ease with which authorized users can access the data they need. Collect
    feedback from users on the ease of accessing and using the data.
  prefs: []
  type: TYPE_NORMAL
- en: Data usage frequency
  prefs: []
  type: TYPE_NORMAL
- en: The number of times datasets are accessed or used within a specific period.
  prefs: []
  type: TYPE_NORMAL
- en: Data accuracy
  prefs: []
  type: TYPE_NORMAL
- en: The percentage of data entries that are correct.
  prefs: []
  type: TYPE_NORMAL
- en: Data completeness
  prefs: []
  type: TYPE_NORMAL
- en: The percentage of missing values or incomplete data entries.
  prefs: []
  type: TYPE_NORMAL
- en: Data consistency
  prefs: []
  type: TYPE_NORMAL
- en: The percentage of data that is uniform and consistent across different databases.
  prefs: []
  type: TYPE_NORMAL
- en: Data timeliness
  prefs: []
  type: TYPE_NORMAL
- en: The time it takes for data to be updated and available for use.
  prefs: []
  type: TYPE_NORMAL
- en: Data validity
  prefs: []
  type: TYPE_NORMAL
- en: The percentage of data entries that meet the specified format, type, or range.
  prefs: []
  type: TYPE_NORMAL
- en: Number of data breaches
  prefs: []
  type: TYPE_NORMAL
- en: The count of security incidents involving unauthorized access to data.
  prefs: []
  type: TYPE_NORMAL
- en: Time to detect and mitigate security threats
  prefs: []
  type: TYPE_NORMAL
- en: The average time to detect and address data security threats.
  prefs: []
  type: TYPE_NORMAL
- en: Data Sources and Data Versioning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In addition to the standard tasks for the Data Sources and Data Versioning
    component in the MLOps Stack Canvas, you should also implement the following governance-related
    tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Identify, catalog, and classify data sources based on sensitivity, privacy,
    and regulatory requirements. Define roles and responsibilities for data access
    (e.g., data owners, stewards, consumers).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish data access controls and permissions based on data classification,
    such as personally identifiable information (PII), protected health information
    (PHI), and payment card industry (PCI) data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish a data taxonomy and metadata schema for consistent data organization
    and labeling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement data lineage to track data origin and transformations and ensure data
    provenance, including information about data sources, ownership, and quality,
    to enable traceability and reproducibility.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish sustainable data documentation processes to document data origin,
    transformations, and dependencies throughout the data lifecycle.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure data versioning aligns with data retention policies and compliance needs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To implement data lineage and provenance, you can utilize tools to capture and
    visualize data flows and dependencies automatically. Examples include OpenLineage,
    Apache Atlas, Cloudera Navigator, and Talend Data Fabric.
  prefs: []
  type: TYPE_NORMAL
- en: To implement data version control to track and manage changes to datasets over
    time, you can use a tool like DVC, Pachyderm, lakeFS, or Delta Lake.
  prefs: []
  type: TYPE_NORMAL
- en: For implementing data privacy and compliance solutions to ensure adherence to
    regulations (e.g., GDPR, HIPAA), tools such as Privitar, OneTrust, BigID, and
    Informatica can be helpful.
  prefs: []
  type: TYPE_NORMAL
- en: Data quality and validation frameworks to ensure data accuracy, completeness,
    and consistency include Apache Griffin, Deequ, Great Expectations, and Monte Carlo.
  prefs: []
  type: TYPE_NORMAL
- en: Data Analysis and Experiment Management
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Incorporating data governance into the Data Analysis and Experiment Management
    component of the MLOps Stack Canvas involves the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Enforce data privacy and security measures during analysis and experimentation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define strict access controls for data and experimental artifacts, and implement
    privacy controls (such as redaction, pseudonymization, or anonymization) for sensitive
    data used in experiments. Use role-based access control systems to ensure only
    authorized personnel can access sensitive data and critical experiment configurations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For reproducibility and compliance, maintain audit trails of data usage in experiments.
    Use version control systems not only for code, but also for experiment configurations
    and datasets. All changes should be logged with user information, timestamps,
    and descriptions to provide a clear and complete audit trail.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuously monitor experiments and data handling practices to ensure compliance
    with internal policies and external regulations (e.g., GDPR, HIPAA). This might
    involve automated checks or periodic reviews.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use experiment tracking and management platforms like MLflow, Weights
    & Biases, or Neptune.ai to manage and govern metadata—including data lineage,
    versioning, and governance information—and artifacts. These tools (and others,
    such as TensorBoard) also support logging and visualizing metrics, hyperparameters,
    and outcomes. They help streamline the experimentation process and guarantee that
    all metadata is captured systematically.
  prefs: []
  type: TYPE_NORMAL
- en: Feature Store and Workflows
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When extending the Feature Store and Workflows component of the MLOps Stack
    Canvas to include data governance, several key processes and tools should be implemented
    to support compliance, reproducibility, and proper management of features:'
  prefs: []
  type: TYPE_NORMAL
- en: Secure and govern the feature store by cataloging features with metadata such
    as creation date, creator, and usage rights. Thoroughly document feature engineering
    workflows to ensure compliance with data privacy regulations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish policies and guidelines for feature creation, storage, and usage to
    comply with data protection regulations (e.g., GDPR, HIPAA).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement access controls and authentication for the feature store. Define policies
    for granting, reviewing, and revoking access to features based on user roles and
    responsibilities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maintain feature lineage and track data sources, transformations, and feature
    dependencies for auditing and reproducibility. For feature provenance, include
    the creation date, version, and owner.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish data retention policies for features that align with regulatory requirements.
    For data minimization purposes, create and store only features that are necessary.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Document all features, providing clear descriptions and justifications for each.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some feature store platforms have built-in governance capabilities such as access
    control, versioning, and lineage tracking. Examples include Feast, Hopsworks,
    AWS SageMaker Feature Store, and Google Cloud Vertex AI Feature Store. You can
    implement data lineage and provenance to capture and visualize feature dependencies
    and transformations using tools like OpenLineage, Apache Atlas, Cloudera Navigator,
    or Talend Data Fabric.
  prefs: []
  type: TYPE_NORMAL
- en: Foundations (Reflecting DevOps)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Organizations can embed data governance throughout the development and deployment
    lifecycle by integrating appropriate processes and tools into the DevOps Foundations
    component of the MLOps Stack Canvas. Consider the following best practices:'
  prefs: []
  type: TYPE_NORMAL
- en: Integrate data governance policies and processes into DevOps practices by adding
    data governance checks and automated compliance checks for data handling to CI/CD
    pipelines.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement data security measures, such as data masking, encryption, tokenization,
    and other minimization controls, to enforce data security and privacy in CI/CD
    pipelines.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Protect sensitive data throughout the build, test, and deployment processes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish secure data handling practices and access controls within the CI/CD
    workflow.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automate data quality checks and validations as part of your DevOps workflows,
    incorporating data quality gates in CI/CD pipelines to maintain integrity and
    consistency.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set up automated data profiling and anomaly detection mechanisms to identify
    data quality issues. Include data profiling reports as artifacts in CI/CD pipelines
    for easy access and review.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'CI/CT/CD: ML Pipeline Orchestration'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Here are some steps you can take to maintain data integrity, compliance, and
    reliability throughout the ML pipeline when incorporating data governance into
    the CI/CT/CD component of the MLOps Stack Canvas:'
  prefs: []
  type: TYPE_NORMAL
- en: Integrate data validation and quality checks into ML pipelines.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automate data bias and fairness assessments during model training.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement data drift detection and alerting within the CI/CD workflow. Establish
    baseline data distributions and monitor for significant deviations over time,
    triggering automated alerts and notifications when data drift exceeds predefined
    thresholds.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define metrics and thresholds to evaluate the fairness and representativeness
    of the training data (e.g., demographic parity, equal opportunity, disparate impact).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automate bias detection and mitigation techniques to ensure models are trained
    on unbiased data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To evaluate and mitigate bias in training data, you can use tools such as IBM
    AI Fairness 360 or Google’s What-If Tool. Tools to implement data drift detection
    and monitoring platforms to identify and alert on data drift in the ML pipeline
    include Evidently AI, Arthur AI, and Fiddler AI. You can also utilize MLOps platforms
    that have built-in data governance features, such as MLflow on Databricks, Kubeflow,
    AWS SageMaker, or the Google Cloud AI Platform.
  prefs: []
  type: TYPE_NORMAL
- en: Model Registry and Model Versioning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Extending the Model Registry and Model Versioning component of the MLOps Stack
    Canvas to include data governance requires the implementation of proper management,
    versioning, and governance practices for ML models (we’ll look at AI model governance
    later in this chapter). Here are some best practices:'
  prefs: []
  type: TYPE_NORMAL
- en: Maintain a centralized model registry with governance metadata (e.g., data used,
    compliance checks).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement access controls and permissions for the model registry.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure the model registry includes data lineage and provenance information.
    Implement a process for tracking model lineage, including data sources, hyperparameters,
    training artifacts, and who trained the ML models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish a model versioning strategy aligned with the data versioning and governance
    policies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maintain a comprehensive version history of models in the registry, along with
    the associated governance metadata.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrating data governance and model management practices fosters transparency,
    accountability, and trust in the ML models deployed in production environments.
    To capture and visualize the relationships between models, data, and other artifacts,
    you can use data lineage and provenance tools such as OpenLineage, Datakin, Pachyderm,
    and Marquez. To track and monitor model governance activities and maintain audit
    trails, use tools like Apache Ranger, Privacera, Immuta, or Informatica.
  prefs: []
  type: TYPE_NORMAL
- en: Model Deployment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Incorporating data governance into model deployment involves deploying models
    in a controlled environment where performance can be monitored against criteria
    such as fairness and privacy impact. Consider the following activities to integrate
    data governance into your model deployment practices:'
  prefs: []
  type: TYPE_NORMAL
- en: Implement staged deployment practices like canary releases to evaluate compliance
    in production settings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use data privacy and anonymization platforms to protect sensitive data during
    model inference and deployment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Track and audit data usage throughout the deployment process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automate data compliance checks as part of the deployment workflow.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Model governance and orchestration frameworks such as Kubeflow, MLflow, Apache
    Airflow, and Seldon Core can be used to manage and automate the deployment process
    in compliance with data governance policies.
  prefs: []
  type: TYPE_NORMAL
- en: Prediction Serving
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Integrating data governance into the Prediction Serving component involves
    controlling how models are served while ensuring compliance with data protection
    regulations. To achieve this, you should:'
  prefs: []
  type: TYPE_NORMAL
- en: Validate that production data meets governance standards (input data validation).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement measures to protect sensitive predictions (output data protection).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Encrypt prediction inputs and outputs both in transit and at rest.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enforce data access controls and authentication for prediction requests.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitor and audit data usage during prediction serving for compliance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish data retention policies for input data and predictions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish a process for protecting sensitive data during prediction serving.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use data masking, anonymization, tokenization, and data minimization techniques
    to safeguard PII or other sensitive data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Audit and log prediction requests and responses.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Capture metadata such as timestamp, input data, and prediction results for each
    prediction request.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Store audit logs securely and make them accessible for compliance and monitoring
    purposes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuously monitor prediction quality and fairness.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement mechanisms to detect and alert on any deviations in prediction quality,
    performance, or fairness metrics and regularly assess the prediction serving system
    for potential biases or discriminatory outcomes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data privacy and protection tools such as HashiCorp Vault, AWS Key Management
    Service (KMS), Azure Key Vault, and Google Cloud Data Loss Prevention (DLP) can
    be used to safeguard sensitive data during prediction serving. To capture and
    store prediction request and response metadata, you can use auditing and logging
    frameworks such as Elastic Stack, Splunk, Fluentd, AWS CloudTrail, or Google Cloud
    Audit Logs. For tracking prediction quality, performance, and fairness metrics,
    consider tools such as Prometheus, Grafana, Datadog, New Relic, AWS CloudWatch,
    or Google Cloud Monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: Model, Data, and Application Monitoring
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To incorporate data governance into the ML model, data, and system monitoring
    part of the MLOps Stack Canvas, extend your monitoring capabilities to include
    governance metrics such as data quality, model drift, and compliance with data
    usage policies. The following tasks are recommended:'
  prefs: []
  type: TYPE_NORMAL
- en: Monitor data quality, bias, and drift in production ML systems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set up alerts and notifications for data governance violations and anomalies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Continuously audit data usage and access to ensure compliance with relevant
    regulations. Establish processes for investigating and remediating governance
    issues.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Track operational metrics (e.g., latency, throughput, resource utilization)
    alongside governance-specific metrics defined in the value proposition.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Establish governance policies and thresholds for acceptable operational performance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement alerts and escalation procedures for operational issues that affect
    model availability, reliability, or compliance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This monitoring component should aggregate and unify all relevant metrics, thresholds,
    and alerts from the other parts of the MLOps Stack Canvas to provide a comprehensive
    view of system health and governance compliance.
  prefs: []
  type: TYPE_NORMAL
- en: Operational monitoring and alerting tools such as Prometheus, Grafana, Datadog,
    New Relic, and Elastic Stack can be used to track system performance, resource
    utilization, and availability. Platforms like PagerDuty, OpsGenie, ​​Splunk On-Call,
    and xMatters help organizations respond to ML system issues and compliance breaches
    quickly. These tools reduce incident response times and improve overall system
    reliability.
  prefs: []
  type: TYPE_NORMAL
- en: Metadata Management
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Metadata management for AI system compliance engineering is such a large and
    important topic that it deserves a separate book. The Metadata Management section
    of the MLOps Stack Canvas spans the entire AI system lifecycle, capturing information
    about datasets, models, experiments, deployments, and more to support ML governance,
    reproducibility, and comparability.
  prefs: []
  type: TYPE_NORMAL
- en: 'Integrating data governance into metadata management requires developing a
    unified strategy that provides greater visibility into data lineage, model history,
    and EU AI Act compliance. You will need to:'
  prefs: []
  type: TYPE_NORMAL
- en: Establish a metadata schema and taxonomy to standardize data labeling and organization.
    Include fields such as model purpose, data sources, performance metrics, compliance
    checks, and approval status.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Capture and store governance-related metadata (e.g., data and model lineage
    and provenance, compliance checks, and access logs).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consistently capture and maintain governance and ML metadata to create a comprehensive
    audit trail for every model version. Use that metadata to support compliance reporting
    and lifecycle tracking.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Document and catalog metadata associated with datasets, features, models, and
    experiments. Experiment metadata should include data lineage, versioning, and
    governance information.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enable metadata integration and interoperability across tools and lifecycle
    stages. Develop processes to harmonize metadata across ML development, deployment,
    and monitoring systems, facilitating traceability and regulatory alignment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are various tools and platforms available to support metadata management
    across the ML lifecycle. These include:'
  prefs: []
  type: TYPE_NORMAL
- en: Metadata management platforms that capture, store, and govern metadata across
    ML systems, such as Alation, Collibra, Informatica Enterprise Data Catalog, and
    Apache Atlas
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data lineage and provenance tools to track and visualize the flow and dependencies
    of data and metadata, such as OpenLineage, Datakin, Nexla, and Octopai
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Centralized metadata catalogs or repositories that enable discovery, search,
    and access to ML system metadata, such as Amundsen, DataHub, Metacat, and Datum
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compliance and audit tools to enforce governance policies and assess the adherence
    of metadata to standards, such as Collibra Governance, Informatica Axon, and Apache
    Ranger
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: APIs and integration frameworks to support interoperability and data exchange
    between ML tools and platforms, such as OpenMetadata, Egeria, and Apache Kafka
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By deeply embedding data governance into each component of the MLOps Stack Canvas,
    you guarantee that data governance is not an afterthought but a fundamental aspect
    of the machine learning lifecycle. This approach not only helps you meet regulatory
    requirements but also builds trust with stakeholders by promoting the ethical
    use of data and models.
  prefs: []
  type: TYPE_NORMAL
- en: Data governance is tightly linked to AI governance, and understanding this relationship
    is especially important in the context of the EU AI Act. AI systems are only as
    good and as safe as the data they are trained on. Weak data governance will cause
    AI governance to fall short. We’ll turn our attention to this critical topic next.
  prefs: []
  type: TYPE_NORMAL
- en: Overview of AI Governance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The introduction of the EU AI Act has caused enterprises to increasingly prioritize
    AI governance. To explain what this entails, let’s return to the earlier metaphor
    of a high-end restaurant kitchen, where data represents the ingredients and AI
    is the collection of sophisticated cooking utensils and equipment.
  prefs: []
  type: TYPE_NORMAL
- en: AI Governance Defined
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The objective of AI governance is to establish and maintain a framework that
    ensures AI systems are developed, deployed, and used responsibly, ethically, and
    in alignment with organizational goals and values. AI governance covers various
    aspects, including AI algorithms, decision making based on AI predictions, security,
    and data privacy. It operates as an ecosystem within the enterprise, involving
    people, processes, and policies.
  prefs: []
  type: TYPE_NORMAL
- en: AI governance is a key responsibility of the company’s leadership and oversight
    bodies such as AI ethics boards. These individuals are accountable for defining
    policies and guidelines, implementing AI risk management processes, and establishing
    monitoring and auditing mechanisms. Other stakeholders include AI and data science
    teams, legal and compliance teams, business unit leaders, risk management teams,
    external advisors and auditors, and customers and end users.
  prefs: []
  type: TYPE_NORMAL
- en: A strong AI governance framework includes AI training and awareness programs
    to provide guardrails and guidance for AI development and use across the organization.
    AI governance policies may cover ethical AI principles, AI risk assessment and
    mitigation, data governance and privacy protection, model development and deployment
    standards, transparency and explainability requirements, AI model monitoring and
    evaluation processes, and ML-centric incident response procedures. As this suggests,
    robust data governance provides the foundation for effective AI governance.
  prefs: []
  type: TYPE_NORMAL
- en: The AI System Lifecycle and AI Governance
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ensuring AI systems are developed and used responsibly, ethically, and in alignment
    with organization goals and values requires a holistic approach involving people,
    processes, and technologies. Organizations can integrate AI governance checkpoints
    throughout the entire AI system development lifecycle to create ethical, transparent,
    fair, and accountable AI systems. The key is to make AI governance an integral
    part of the development process rather than an afterthought. [Table 3-1](#chapter_3_table_1_1748539918103855)
    shows how the AI governance principles outlined earlier map to the corresponding
    phases of the CRISP-ML(Q) framework discussed in [Chapter 2](ch02.html#chapter_2_ai_engineering_a_proactive_compliance_catalyst_1748539917637495).
  prefs: []
  type: TYPE_NORMAL
- en: Table 3-1\. Integrating AI governance into each phase of CRISP-ML(Q)
  prefs: []
  type: TYPE_NORMAL
- en: '| CRISP-ML(Q) phase | AI governance principles | Relevance to the EU AI Act
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Business and data understanding | Human-centered design: Ensure the AI project
    aligns with human needs and values. Involve stakeholders from various departments
    to validate the AI project’s goals. | The EU AI Act promotes human-centric and
    trustworthy AI (Article 1). Ensuring alignment with human needs during this phase
    contributes to achieving this objective. |'
  prefs: []
  type: TYPE_TB
- en: '| Ethical and responsible AI practices: Conduct an ethical impact assessment
    to identify potential risks and harms. | The Act prohibits certain harmful AI
    practices (Article 5) and outlines specific requirements for high-risk AI systems
    (Article 6). Conducting an ethical impact assessment aligns with its risk-based
    approach. |'
  prefs: []
  type: TYPE_TB
- en: '| Privacy and data security: Implement data governance practices during data
    collection and verification. | Article 10 mandates data quality and governance
    for high-risk AI systems. Establishing robust data governance practices in this
    phase is crucial for compliance. |'
  prefs: []
  type: TYPE_TB
- en: '| Fairness and inclusiveness: When defining success criteria, include metrics
    for fairness and inclusiveness. Examine the data for potential biases that could
    lead to unfair outcomes. | Article 10 also requires addressing potential biases
    in data for high-risk systems. Incorporating fairness metrics in this phase helps
    ensure compliance and mitigate potential discrimination. |'
  prefs: []
  type: TYPE_TB
- en: '| Accountability: Define clear roles and responsibilities for the AI project.
    | The EU AI Act demands accountability by requiring providers to demonstrate compliance
    with its requirements. Defining clear roles in this phase supports establishing
    accountability throughout the AI system lifecycle. |'
  prefs: []
  type: TYPE_TB
- en: '| Data preparation | Privacy and data security: Implement robust data protection
    measures during data cleaning and transformation. Where necessary, apply data
    anonymization or pseudonymization techniques. Ensure that data handling complies
    with relevant privacy regulations. | Article 10 requires data governance for high-risk
    AI, while Article 27 concerns GDPR compliance. Article 59 provides provisions
    for further processing of personal data under specific conditions, which may be
    relevant in this phase. |'
  prefs: []
  type: TYPE_TB
- en: '| Fairness and inclusiveness: Address class imbalances and potential biases
    in the data. | Article 10 mandates addressing potential biases in data for high-risk
    AI systems. This phase offers a critical opportunity to mitigate bias and ensure
    fairness. |'
  prefs: []
  type: TYPE_TB
- en: '| Reproducibility: Document all data preparation steps and use version control
    for datasets. | Article 11 mandates the provision of technical documentation to
    support reproducibility and enable the traceability of data preparation steps.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Transparency and explainability: Keep detailed records of any data transformations
    or feature engineering steps. | Article 13 emphasizes transparency and explainability
    for high-risk AI systems. Maintaining detailed records in this phase supports
    fulfilling these requirements. |'
  prefs: []
  type: TYPE_TB
- en: '| Modeling | Safety, security, and dependability: Choose modeling techniques
    appropriate for the application’s level of risk and implement safeguards against
    potential vulnerabilities. | The Act requires a risk management system (Article
    9) and specific provisions for the accuracy, robustness, and cybersecurity of
    high-risk AI systems (Article 15). Implementing safeguards in this phase is crucial
    for achieving compliance. |'
  prefs: []
  type: TYPE_TB
- en: '| Fairness and inclusiveness: Monitor and mitigate any biases that emerge during
    the modeling process. Use fairness-aware machine learning techniques if necessary.
    | Articles 10 and 50 highlight the importance of addressing bias and promoting
    fairness. Monitoring and mitigating bias during model engineering is essential
    for compliance. |'
  prefs: []
  type: TYPE_TB
- en: '| Transparency and explainability: Implement model documentation practices
    (e.g., model cards and dataset sheets). | Article 13 mandates transparency and
    explainability for high-risk AI systems. Implementing documentation practices
    in this phase contributes to fulfilling these requirements. |'
  prefs: []
  type: TYPE_TB
- en: '| Reproducibility: Ensure that the modeling process is fully documented and
    reproducible. This includes recording random seeds, hyperparameters, and model
    architectures. | Article 11 sets requirements for technical documentation, supporting
    reproducibility and allowing for auditing and verification of the modeling process.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Robustness: Develop models that are robust to variations in input data and
    potential adversarial attacks. | Robustness is a key requirement for high-risk
    AI systems under Article 15\. Developing robust models in this phase is essential
    for compliance. |'
  prefs: []
  type: TYPE_TB
- en: '| Evaluation | Human-centered design and oversight: Involve domain experts
    in interpreting model results and assessing potential impacts. | Human oversight
    is a crucial aspect of the EU AI Act, particularly for high-risk systems (Articles
    14 and 26). Involving domain experts in this phase aligns with this principle.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Fairness and inclusiveness: Conduct thorough testing for fairness across
    different subgroups. | Focusing on fairness and inclusiveness is essential for
    identifying, assessing, and mitigating risks associated with AI systems. This
    is relevant to Articles 10 and 50, highlighting the importance of addressing bias
    and promoting fairness. |'
  prefs: []
  type: TYPE_TB
- en: '| Transparency and explainability: Use model interpretation techniques to understand
    and communicate how the model arrives at its decisions. | Transparency and explainability
    are central to the Act, with Article 13 focusing on high-risk systems and Article
    86 providing a right to explanation for individuals affected by AI decisions.
    Using interpretation techniques in this phase supports compliance. |'
  prefs: []
  type: TYPE_TB
- en: '| Robustness: Perform extensive testing of the model’s performance under various
    conditions, including edge cases and potential adversarial scenarios. | Robustness
    is a key requirement for high-risk AI systems under Article 15\. Comprehensive
    testing in this phase helps ensure the model’s resilience and compliance. |'
  prefs: []
  type: TYPE_TB
- en: '| Accountability and redress: Establish clear criteria for model performance
    and define processes for handling cases where the model fails to meet these criteria.
    | Article 20 addresses corrective actions. Establishing criteria and processes
    for redress in this phase contributes to meeting these obligations. |'
  prefs: []
  type: TYPE_TB
- en: '| Deployment | Human oversight: Establish human-in-the-loop processes for high-stakes
    decisions. Design the deployment process to allow for human oversight and intervention
    when necessary. | Articles 14 and 26 mandate human oversight, particularly for
    high-risk systems. Implementing human-in-the-loop processes during deployment
    is essential for compliance. |'
  prefs: []
  type: TYPE_TB
- en: '| Safety, security, and dependability: Implement safeguards to protect the
    deployed model from tampering or unauthorized access. | Article 15 addresses security
    and robustness. Implementing safeguards during deployment ensures ongoing compliance.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Transparency and explainability: Provide clear documentation on how the model
    should be used, including its limitations and potential biases. | Transparency
    is crucial under the EU AI Act. Providing clear documentation during deployment
    contributes to meeting this requirement. |'
  prefs: []
  type: TYPE_TB
- en: '| Accountability and redress: Log model inputs/outputs for auditing purposes.
    Establish clear lines of responsibility for the model’s outputs and decisions.
    Set up mechanisms for users to challenge or appeal decisions made by the AI system.
    | The Act requires recordkeeping (Article 12), places obligations on providers
    (Article 16), outlines corrective actions (Article 20), and grants a right to
    appeal AI decisions (Article 85). |'
  prefs: []
  type: TYPE_TB
- en: '| Monitoring and maintenance | Human oversight: Regularly review model performance
    and decisions with human experts. | Human oversight is a continuous requirement
    for high-risk systems. Regular reviews with experts contribute to fulfilling this
    obligation. |'
  prefs: []
  type: TYPE_TB
- en: '| Safety and dependability: Monitor for data/concept drift and model performance
    degradation. Continuously evaluate the model’s performance and security, updating
    as necessary to address any emerging vulnerabilities. | The EU AI Act mandates
    risk management (Article 9) and robustness and security (Article 15). Continuous
    monitoring and updates align with these requirements. |'
  prefs: []
  type: TYPE_TB
- en: '| Fairness and inclusiveness: Track fairness metrics in production. Regularly
    check for any emerging biases or unfair outcomes as the model operates on new
    data. | Articles 10 and 50 emphasize addressing bias. Monitoring fairness metrics
    in this phase helps ensure ongoing compliance. |'
  prefs: []
  type: TYPE_TB
- en: '| Accountability and redress: Establish processes for addressing and correcting
    model errors or biases. Implement a feedback loop to incorporate lessons learned
    from the model’s real-world performance into future iterations. | Continuously
    improving the model within ethical boundaries may be guided by codes of practice
    (Article 56). |'
  prefs: []
  type: TYPE_TB
- en: The integration of AI governance and MLOps is discussed in [Appendix C](app03.html#appendix_c_the_integration_of_ai_governance_and_mlops_1748539915562039).
  prefs: []
  type: TYPE_NORMAL
- en: To further demonstrate why data and AI governance are interleaved and should
    be considered holistically, let’s consider an example. Suppose an EU-based company
    develops an AI model for job candidate screening (a high-risk AI use case under
    the EU AI Act). Without data governance, it may unknowingly train the model on
    biased data (e.g., historical hiring patterns favoring one gender), leading to
    discriminatory decisions. Without AI governance, it may deploy the model without
    proper transparency, testing, or monitoring. This would result in noncompliance
    with the EU AI Act, risking fines, reputational damage, and harm to individuals.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, if both data and AI governance are integrated:'
  prefs: []
  type: TYPE_NORMAL
- en: The dataset will be assessed for fairness, diversity, and quality.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The model will be explainable, monitored, and thoroughly documented.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The organization will be able to demonstrate compliance and maintain trust.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Emerging Trends in Data and AI Governance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The evolving landscape of data and AI governance highlights the need for more
    advanced, automated, and ethical approaches to managing and using data and AI
    technologies. Organizations that adapt to these trends will likely gain a competitive
    advantage in leveraging their data assets while ensuring compliance and security.
    Let’s look at the five most notable trends in data and AI governance:'
  prefs: []
  type: TYPE_NORMAL
- en: Focus on ethics, trust, and enhanced data privacy
  prefs: []
  type: TYPE_NORMAL
- en: There’s a growing emphasis on building trust in AI systems through ethical practices.
    This includes addressing concerns about fairness, bias, privacy, and the potential
    misuse of AI technologies. In the age of generative AI, organizations are increasingly
    developing and implementing ethical frameworks for AI governance to address issues
    such as large language model hallucinations and to implement corresponding safety
    guardrails. These frameworks address issues of bias, fairness, and transparency
    in AI systems and ensure adherence to the organization’s own ethical values and
    industry-specific standards.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, amid growing privacy concerns—especially around AI—companies are
    placing more focus on data privacy measures. This includes strengthening data
    protection policies and increasing transparency about data usage.
  prefs: []
  type: TYPE_NORMAL
- en: Adoption of AI in data management and proactive compliance automation
  prefs: []
  type: TYPE_NORMAL
- en: AI and ML technologies are being integrated into data governance processes to
    automate data governance tasks, enhance data quality, and provide predictive analytics.
    This trend enables more efficient data processing and improved scalability in
    data management. Furthermore, AI is increasingly used to automate and improve
    compliance processes, including risk forecasting, regulatory change management,
    and real-time monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: Focus on data lineage and provenance in AI
  prefs: []
  type: TYPE_NORMAL
- en: With the rise of generative AI, there’s an increased emphasis on tracing data
    lineage throughout AI models. This trend is crucial for error detection, analysis,
    and ensuring regulatory compliance in AI applications. I expect proactive data
    and AI governance frameworks to emerge based on data lineage and active metadata.
  prefs: []
  type: TYPE_NORMAL
- en: Shift left data and AI governance
  prefs: []
  type: TYPE_NORMAL
- en: Companies are prioritizing a “shift left” approach, implementing data governance
    and security measures early in the data collection and processing stages. This
    proactive approach simplifies data security, improves data quality, and addresses
    issues early on.
  prefs: []
  type: TYPE_NORMAL
- en: Decentralized data governance
  prefs: []
  type: TYPE_NORMAL
- en: There’s currently a shift toward more decentralized governance structures. This
    allows for greater autonomy and agility within domain teams while maintaining
    overall organizational standards. With the growing emphasis on “data as a product”
    thinking and data contracts, many companies are adopting this approach to data
    governance.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter discussed the data and AI governance processes required for compliance
    with the EU AI Act. The Act emphasizes the importance of robust data and AI governance
    frameworks. Data governance ensures high-quality, representative data for training
    AI models, which is crucial for both regulatory compliance and the development
    of trustworthy AI systems. AI governance frameworks provide the oversight and
    controls needed to align AI development with business strategy, regulatory requirements,
    and ethical principles. Both data and AI governance are essential for managing
    the risks associated with AI use, which is central to business strategy, compliance,
    and trustworthiness. Transparency and accountability, core principles of governance,
    are not only required by the EU AI Act but are fundamental to trustworthy AI.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, I will outline the classification framework for AI system
    risk. For high-risk and limited-risk AI systems, planning AI engineering processes
    to ensure compliance with the EU AI Act is critical. When integrating ethical
    and compliance aspects into the AI system development process, it’s also vital
    to structure team topologies to include dedicated ethics, compliance, and governance
    roles.
  prefs: []
  type: TYPE_NORMAL
- en: ^([1](ch03.html#id469-marker)) OvalEdge Team, “The Importance of Data Governance
    in Healthcare,” OvalEdge, March 22, 2023, [*https://oreil.ly/dXnvR*](https://oreil.ly/dXnvR).
  prefs: []
  type: TYPE_NORMAL
- en: '^([2](ch03.html#id471-marker)) Yuriy Voloshynskyy, “Data Governance in Banking
    and Finance: A Complete Guide,” N-iX, March 27, 2024, [*https://oreil.ly/dHAXj*](https://oreil.ly/dHAXj).'
  prefs: []
  type: TYPE_NORMAL
