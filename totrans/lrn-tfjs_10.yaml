- en: Chapter 9\. Classification Models and Data Analysis
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第9章。分类模型和数据分析
- en: “Forethought spares afterthought.”
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: “先见之明，后事之师。”
- en: ''
  id: totrans-2
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: —Amelia Barr
  id: totrans-3
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: —Amelia Barr
- en: There’s a reason you don’t just dump data into a model. Neural networks operate
    at intense speeds and perform complex calculations the same way humans can have
    an instantaneous reaction. However, for both humans and machine learning models,
    a reaction rarely contains a reasoned context. Dealing with dirty and confusing
    data creates subpar models, if anything at all. In this chapter, you’ll explore
    the process of identifying, loading, cleaning, and refining data to improve the
    training accuracy of a model in TensorFlow.js.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 你不仅仅是把数据丢进模型中是有原因的。神经网络以极快的速度运行并执行复杂的计算，就像人类可以瞬间做出反应一样。然而，对于人类和机器学习模型来说，反应很少包含合理的上下文。处理脏乱和令人困惑的数据会导致次优的模型，甚至什么都不会得到。在这一章中，你将探索识别、加载、清理和优化数据的过程，以提高TensorFlow.js模型的训练准确性。
- en: 'We will:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将：
- en: Identify how to make a classification model
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定如何创建分类模型
- en: Learn how to handle CSV data
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习如何处理CSV数据
- en: Learn about Danfo.js and DataFrames
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解Danfo.js和DataFrames
- en: Identify how to get messy data into training (wrangle your data)
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定如何将混乱的数据输入训练中（整理你的数据）
- en: Practice graphing and analyzing data
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 练习绘制和分析数据
- en: Learn about machine learning notebooks
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解机器学习笔记本
- en: Expose core concepts of feature engineering
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 揭示特征工程的核心概念
- en: When you finish this chapter, you’ll feel confident in gathering large amounts
    of data, analyzing it, and testing your intuitions by using context to create
    features that help models train.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 当你完成这一章时，你将有信心收集大量数据，分析数据，并通过使用上下文来创建有助于模型训练的特征来测试你的直觉。
- en: In this chapter, you’ll build a *Titanic* life-or-death classifier. Will Miss
    Kate Connolly, a 30-year-old woman with a third-class ticket, survive? Let’s train
    a model to take that information and give us a likelihood of survival.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，你将构建一个*Titanic*生死分类器。30岁的Kate Connolly小姐，持有三等舱票，会生还吗？让我们训练一个模型来获取这些信息，并给出生还的可能性。
- en: Classification Models
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分类模型
- en: So far, you’ve trained a model that outputs numbers. Most of the models you’ve
    consumed behave a bit differently from the ones you’ve created. In [Chapter 8](ch08.html#the_chapter_8)
    you implemented linear regression, but in this chapter, you will implement a classification
    model (sometimes called *logistic regression*).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你训练了一个输出数字的模型。你消化的大多数模型与你创建的模型有些不同。在[第8章](ch08.html#the_chapter_8)中，你实现了线性回归，但在这一章中，你将实现一个分类模型（有时称为*逻辑回归*）。
- en: The Toxicity, MobileNet, and even Tic-Tac-Toe models output a single choice
    among a collection of options. They do so with a group of numbers that sum to
    one, rather than a single number that has no range. This is a common structure
    for classification models. A model that is made to identify three different options
    will give us numbers that correspond with each option.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 毒性、MobileNet，甚至井字棋模型输出一种选择，从一组选项中选择。它们使用一组总和为一的数字，而不是一个没有范围的单个数字。这是分类模型的常见结构。一个旨在识别三种不同选项的模型将给出与每个选项对应的数字。
- en: 'Models that attempt to predict classifications require some kind of mapping
    from output values to their associated classes. This is most commonly done with
    outputting their probability, like you’ve seen in classification models so far.
    To create a model that does this, you only need to implement special activation
    functions on the final layer:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 试图预测分类的模型需要一种将输出值映射到其相关类别的方法。到目前为止，在分类模型中，最常见的方法是输出它们的概率。要创建一个执行此操作的模型，你只需要在最终层实现特殊的激活函数：
- en: Tip
  id: totrans-19
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Remember that activation functions help your neural network behave in a nonlinear
    fashion. Each activation function causes a layer to behave nonlinearly in a desired
    way, and the final layer’s activation translates directly to the output. It’s
    important to make sure you learn what activation will give you the model output
    you’re seeking.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，激活函数帮助你的神经网络以非线性方式运行。每个激活函数使得一个层以所需的非线性方式运行，最终层的激活直接转化为输出。重要的是确保你学会了哪种激活函数会给你所需的模型输出。
- en: The activation function you’ve seen over and over in models used in this book
    is called a *softmax* activation. That’s the group of values that sum to one.
    For example, if your model would have a True/False output, you’d expect a model
    to output two values, with one identifying probability `true` and the other for
    `false`. For example, a softmax for this model could output `[0.66, 0.34]` with
    some rounding.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中使用的模型中，你一遍又一遍看到的激活函数被称为*softmax*激活。这是一组值，它们的总和为一。例如，如果你的模型需要一个True/False输出，你会期望模型输出两个值，一个用于识别`true`的概率，另一个用于`false`。例如，对于这个模型，softmax可能输出`[0.66,
    0.34]`，经过一些四舍五入。
- en: This can scale to N values for N classifications *as long as classes are mutually
    exclusive*. When designing the model, you would enforce softmax in the final layer,
    and the number of outputs would be the number of categories you’re looking to
    support. To achieve the True or False result, your model architecture would have
    two outputs with a softmax activation on the final layer.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以扩展到N个值的N个分类*只要类别是互斥的*。在设计模型时，你会在最终层强制使用softmax，并且输出的数量将是你希望支持的类别数量。为了实现True或False的结果，你的模型架构将在最终层上使用softmax激活，有两个输出。
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'What if you were trying to detect several things from your input? For example,
    a chest X-ray could be positive for both pneumonia and emphysema. Softmax wouldn’t
    work in that case, as the outputs have to sum to one, and confidence in one would
    have to fight against another. In this case, there’s an activation that enforces
    each node to be a value between zero and one, so you can achieve probability per
    node. The activation is called the *sigmoid* activation. This can scale to N values
    for N classifications that are not exclusive. That means you could achieve a True/False
    model (binary classification) by having a single output with `sigmoid` where close
    to zero is false, and close to one is true:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您试图从输入中检测几件事情会发生什么？例如，胸部X光可能同时对肺炎和肺气肿呈阳性。在这种情况下，Softmax不起作用，因为输出必须总和为一，对一个的信心必须与另一个对抗。在这种情况下，有一种激活可以强制每个节点的值在零和一之间，因此您可以实现每个节点的概率。这种激活称为
    *sigmoid* 激活。这可以扩展到N个值，用于N个不相互排斥的分类。这意味着您可以通过具有 `sigmoid` 的单个输出来实现真/假模型（二元分类），其中接近零为假，接近一为真：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Yes, these activation names are strange, but they aren’t complicated. You could
    easily lose a day in a YouTube rabbit hole by researching the math behind how
    these activation functions work. But most importantly, understand how they are
    used in classification. Here in [Table 9-1](#binary_classification_example_table)
    you’ll see some examples.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，这些激活名称很奇怪，但它们并不复杂。您可以通过研究这些激活函数的工作原理背后的数学，在YouTube的兔子洞中轻松度过一天。但最重要的是，了解它们在分类中的用法。在
    [表9-1](#binary_classification_example_table) 中，您将看到一些示例。
- en: Table 9-1\. Binary classification examples
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 表9-1\. 二元分类示例
- en: '| Activation | Output | Analysis of results |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 激活 | 输出 | 结果分析 |'
- en: '| --- | --- | --- |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| sigmoid | `[0.999999]` | 99% sure it is True |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| sigmoid | `[0.999999]` | 99% 确定是真的 |'
- en: '| softmax | `[0.99, 0.01]` | 99% sure it is True |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| softmax | `[0.99, 0.01]` | 99% 确定是真的 |'
- en: '| sigmoid | `[0.100000]` | 10% sure of True (so 90% False) |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| sigmoid | `[0.100000]` | 10% 确定是真的（因此90% 是假的） |'
- en: '| softmax | `[0.10, 0.90]` | 90% sure it is False |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| softmax | `[0.10, 0.90]` | 90% 确定是假的 |'
- en: The difference between when you would use `softmax` versus `sigmoid` goes away
    when you are handling True/False. There’s no real difference in which activation
    you choose for your final layer because there’s nothing that one could exclude.
    In this chapter, we’ll be using sigmoid in the last layer for simplicity.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 当您处理真/假时，您使用 `softmax` 与 `sigmoid` 的区别消失。在选择最终层的激活时，您选择哪种激活没有真正的区别，因为没有一种可以排除另一种。在本章中，我们将在最后一层使用sigmoid以简化。
- en: If you were trying to classify multiple things, you’d need to make an intelligent
    choice between `sigmoid` or `softmax`. This book will reiterate and clarify the
    use of these activation functions where applicable.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您试图对多个事物进行分类，您需要在 `sigmoid` 或 `softmax` 之间做出明智的选择。本书将重申和澄清这些激活函数的使用情况。
- en: The Titanic
  id: totrans-36
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 泰坦尼克号
- en: On April 15, 1912, the “unsinkable” RMS *Titanic* (see [Figure 9-1](#titanic))
    sank. This tragedy is popularized throughout history books, tales of hubris, and
    even a feature film starring Leonardo DiCaprio and Kate Winslet. This tragic event
    is awe-inspiring with a hint of morbid curiosity. If you visit the *Titanic* exhibit
    at the Luxor in Las Vegas, your ticket assigns you the name of a passenger, and
    tells you your ticket price, your cabin class, and several other things about
    your life. As you peruse the ship and the accommodations, you can experience it
    through the eyes of the person on your ticket. At the end of the exhibit, you
    find out if the person printed on your ticket survived.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 1912年4月15日，“不沉的” RMS *泰坦尼克号*（请参见 [图9-1](#titanic)）沉没了。这场悲剧在历史书籍中广为流传，充满了傲慢的故事，甚至有一部由莱昂纳多·迪卡普里奥和凯特·温丝莱特主演的电影。这场悲剧充满了一丝令人敬畏的死亡好奇。如果您在拉斯维加斯卢克索的
    *泰坦尼克号* 展览中，您的门票会分配给您一位乘客的名字，并告诉您您的票价、舱位等等关于您生活的几件事。当您浏览船只和住宿时，您可以通过您门票上的人的眼睛体验它。在展览结束时，您会发现您门票上印刷的人是否幸存下来。
- en: '![The Titanic profile](assets/ltjs_0901.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![泰坦尼克号概况](assets/ltjs_0901.png)'
- en: Figure 9-1\. The RMS Titanic
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-1\. RMS泰坦尼克号
- en: Was it 100% random who lived and who didn’t? Anyone familiar with the history
    or who’s watched the movie knows it was no coin flip. Maybe you can train a model
    to find patterns in the data. Thankfully, the guest log and the survivor list
    are available for us to use.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 谁生存谁没有是100%随机的吗？熟悉历史或看过电影的人都知道这不是一个抛硬币的事情。也许您可以训练一个模型来发现数据中的模式。幸运的是，客人日志和幸存者名单可供我们使用。
- en: Titanic Dataset
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 泰坦尼克数据集
- en: As with most things these days, the data has been transcribed to a digital format.
    The *Titanic* manifest is available in comma-separated values (CSV) form. This
    tabular data can be read by any spreadsheet software. There are lots of copies
    of the *Titanic* dataset available, and they generally have the same information.
    The CSV files that we’ll be using can be found in the associated code for this
    chapter in the [extra folder](https://oreil.ly/ry4Pf).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 与大多数事物一样，数据现在已转录为数字格式。 *泰坦尼克* 名单以逗号分隔的值（CSV）形式可用。这种表格数据可以被任何电子表格软件读取。有很多副本的
    *泰坦尼克* 数据集可用，并且它们通常具有相同的信息。我们将使用的CSV文件可以在本章的相关代码中的 [额外文件夹](https://oreil.ly/ry4Pf)
    中找到。
- en: This *Titanic* dataset contains column data shown in [Table 9-2](#titanic_data_table).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 *泰坦尼克* 数据集包含在 [表9-2](#titanic_data_table) 中显示的列数据。
- en: Table 9-2\. Titanic data
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 表9-2\. 泰坦尼克数据
- en: '| Column | Definition | Legend |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 列 | 定义 | 图例 |'
- en: '| --- | --- | --- |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| survival | Survived | 0 = No, 1 = Yes |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 生存 | 生存 | 0 = 否，1 = 是 |'
- en: '| pclass | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| pclass | 票类 | 1 = 1等，2 = 2等，3 = 3等 |'
- en: '| sex | Sex |  |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 性别 | 性别 |  |'
- en: '| Age | Age in years |  |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 年龄 | 年龄 |  |'
- en: '| sibsp | Number of siblings or spouses aboard |  |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 兄弟姐妹或配偶数量 | 兄弟姐妹或配偶在船上的数量 |  |'
- en: '| parch | Number of parents or children aboard |  |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 父母或子女数量 | 父母或子女在船上的数量 |  |'
- en: '| ticket | Ticket number |  |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 票号 | 票号 |  |'
- en: '| fare | Passenger fare |  |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 票价 | 乘客票价 |  |'
- en: '| cabin | Cabin number |  |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 船舱 | 船舱号码 |  |'
- en: '| embarked | Port of embarkation | C = Cherbourg, Q = Queenstown, S = Southampton
    |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| embarked | 登船港口 | C = 瑟堡, Q = 昆士敦, S = 南安普敦 |'
- en: So how do you get this CSV data into tensor form? One way would be to read the
    CSV file and convert each of the inputs into a tensor representation for training.
    This sounds like quite a significant task, especially when you’re looking to experiment
    with what columns and formats would be most useful for training your model.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 那么如何将这些CSV数据转换为张量形式呢？一种方法是读取CSV文件，并将每个输入转换为张量表示进行训练。当您试图尝试哪些列和格式对训练模型最有用时，这听起来是一个相当重要的任务。
- en: In the Python community, a popular way to load, modify, and train with data
    is to use a library called [Pandas](https://pandas.pydata.org). This open source
    library is prevalent for data analysis. While this is quite useful for Python
    developers, there is a significant need for a similar tool in JavaScript.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在Python社区中，一种流行的加载、修改和训练数据的方法是使用一个名为[Pandas](https://pandas.pydata.org)的库。这个开源库在数据分析中很常见。虽然这对Python开发人员非常有用，但JavaScript中存在类似工具的需求很大。
- en: Danfo.js
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Danfo.js
- en: '[Danfo.js](https://danfo.jsdata.org) is an open source JavaScript alternative
    to Pandas. The API of Danfo.js is purposefully kept close to Pandas to capitalize
    on informational experience sharing. Even the function names in Danfo.js are `snake_case`
    instead of the standard JavaScript `camelCase` format. This means that you can
    utilize years of tutorials for Pandas in Danfo.js with minimal translation.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[Danfo.js](https://danfo.jsdata.org)是Pandas的JavaScript开源替代品。Danfo.js的API被故意保持与Pandas接近，以便利用信息体验共享。甚至Danfo.js中的函数名称都是`snake_case`而不是标准的JavaScript`camelCase`格式。这意味着您可以在Danfo.js中最小地进行翻译，利用Pandas的多年教程。'
- en: We’ll be using Danfo.js to read the *Titanic* CSV and modify it into TensorFlow.js
    tensors. To get started, you will need to add Danfo.js to a project.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Danfo.js来读取*Titanic* CSV并将其修改为TensorFlow.js张量。要开始，您需要将Danfo.js添加到项目中。
- en: 'To install the Node version of Danfo.js, you will run the following:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 要安装Danfo.js的Node版本，您将运行以下命令：
- en: '[PRE2]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You can then `require` Danfo.js if you’re using simple Node.js, or you can
    `import` if you’ve configured your code to use ES6+:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用简单的Node.js，则可以`require` Danfo.js，或者如果您已经配置了代码以使用ES6+，则可以`import`：
- en: '[PRE3]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note
  id: totrans-66
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Danfo.js can run in the browser, too. This chapter depends on printing information
    more than usual, so it makes sense to utilize the full terminal window and rely
    on the simplicity of Node.js for access to local files.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Danfo.js也可以在浏览器中运行。本章依赖于比平常更多的打印信息，因此利用完整的终端窗口并依赖Node.js的简单性来访问本地文件是有意义的。
- en: Danfo.js is powered by TensorFlow.js behind the scenes, but it provides common
    data reading and processing utilities.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Danfo.js在幕后由TensorFlow.js提供支持，但它提供了常见的数据读取和处理实用程序。
- en: Preparing for the Titanic
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为泰坦尼克号做准备
- en: One of the most common criticisms of machine learning is that it comes off as
    a golden goose. You may think the next steps are to hook a model up to the CSV
    files, click Train, and then take the day off to enjoy a walk in the park. While
    efforts are being made daily to improve automation in machine learning, data is
    rarely in a format that is “ready to go.”
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习最常见的批评之一是它看起来像一个金鹅。您可能认为接下来的步骤是将模型连接到CSV文件，点击“训练”，然后休息一天，去公园散步。尽管每天都在努力改进机器学习的自动化，但数据很少以“准备就绪”的格式存在。
- en: The *Titanic* data in this chapter contains alluring Train and Test CSV files.
    However, using Danfo.js, we’ll quickly see the provided data is far from ready
    to be loaded into tensors. It’s the goal of this chapter for you to identify data
    in this shape and prepare it appropriately.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中的*Titanic*数据包含诱人的Train和Test CSV文件。然而，使用Danfo.js，我们很快就会看到提供的数据远未准备好加载到张量中。本章的目标是让您识别这种形式的数据并做好适当的准备。
- en: Reading the CSV
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 读取CSV
- en: The CSV file is loaded into a construct called a DataFrame. The DataFrame is
    like a spreadsheet with columns of potentially different types and rows of individual
    entries that fit those types, like a series of objects.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: CSV文件被加载到一个称为DataFrame的结构中。DataFrame类似于带有可能不同类型列和适合这些类型的行的电子表格，就像一系列对象。
- en: DataFrames have the ability to print their contents to the console, as well
    as plenty of other helper functions to review and edit the contents programmatically.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame有能力将其内容打印到控制台，以及许多其他辅助函数以编程方式查看和编辑内容。
- en: 'Let’s review the following code, which reads the CSV into a DataFrame and then
    prints a few rows to the console:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下以下代码，它将CSV文件读入DataFrame，然后在控制台上打印几行：
- en: '[PRE4]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[![1](assets/1.png)](#co_classification_models_and_data_analysis_CO1-1)'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_classification_models_and_data_analysis_CO1-1)'
- en: The `read_csv` method can read from a URL or a local file URI.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '`read_csv`方法可以从URL或本地文件URI中读取。'
- en: '[![2](assets/2.png)](#co_classification_models_and_data_analysis_CO1-2)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_classification_models_and_data_analysis_CO1-2)'
- en: The DataFrame can be limited to the head of five rows and then printed.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame可以限制为前五行，然后打印。
- en: The CSV being loaded is the training data, and the `print()` command logs the
    contents of a DataFrame to the console. The results are displayed in the console,
    as shown in [Figure 9-2](#danfo_table).
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 正在加载的CSV是训练数据，`print()`命令将DataFrame的内容记录到控制台。结果显示在控制台中，如[图9-2](#danfo_table)所示。
- en: '![Head printout](assets/ltjs_0902.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![Head printout](assets/ltjs_0902.png)'
- en: Figure 9-2\. Printing the CSV DataFrame head
  id: totrans-83
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-2。打印CSV DataFrame头
- en: 'Upon examining the content of the data, you might notice some strange entries,
    especially in the `Cabin` column, that say `NaN`. These represent missing data
    in the dataset. This is one of the reasons you can’t hook the CSV directly to
    a model: it’s important to identify how to handle the missing information. We’ll
    assess this issue shortly.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在检查数据内容时，您可能会注意到一些奇怪的条目，特别是在`Cabin`列中，显示为`NaN`。这些代表数据集中的缺失数据。这是您不能直接将CSV连接到模型的原因之一：重要的是要确定如何处理缺失信息。我们将很快评估这个问题。
- en: 'Danfo.js and Pandas have many useful commands to help you familiarize yourself
    with the data you’ve loaded. One popular method is to call `.describe()`, which
    attempts to analyze the contents of each column as a report:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Danfo.js和Pandas有许多有用的命令，可以帮助您熟悉加载的数据。一个流行的方法是调用`.describe()`，它试图分析每列的内容作为报告：
- en: '[PRE5]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: If you print the DataFrame’s `describe` data, you’ll see that the CSV you’ve
    loaded has 891 entries, as well as a printout of their max, min, median, etc.,
    so you can validate the information. The printed table looks like [Figure 9-3](#danfo_describe).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如果打印DataFrame的`describe`数据，您将看到您加载的CSV有891个条目，以及它们的最大值、最小值、中位数等的打印输出，以便您验证信息。打印的表格看起来像[图9-3](#danfo_describe)。
- en: '![Describe printout](assets/ltjs_0903.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![描述打印输出](assets/ltjs_0903.png)'
- en: Figure 9-3\. Describing the DataFrame
  id: totrans-89
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-3。描述DataFrame
- en: Some columns have been removed from [Figure 9-3](#danfo_describe) because they
    contain non-numeric data. This is something you will solve in Danfo.js easily.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 一些列已从[图9-3](#danfo_describe)中删除，因为它们包含非数字数据。这是您将在Danfo.js中轻松解决的问题。
- en: Investigating the CSV
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 调查CSV
- en: This CSV reflects the real world of data, where there’s often missing information.
    Before training, you’ll need to handle this.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这个CSV反映了数据的真实世界，其中经常会有缺失信息。在训练之前，您需要处理这个问题。
- en: 'You can find all missing fields with `isna()`, which will return `true` or
    `false` for each missing field. You can then sum or count these values to get
    results. The following is the code that will report empty cells or properties
    of the dataset:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用`isna()`找到所有缺失字段，它将为每个缺失字段返回`true`或`false`。然后，您可以对这些值进行求和或计数以获得结果。以下是将报告数据集的空单元格或属性的代码：
- en: '[PRE6]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'With the results you can see the following:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 通过结果，您可以看到以下内容：
- en: 'Empty `Age` values: 177 (20%)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 空的`Age`数值：177（20%）
- en: 'Empty `Cabin` values: 687 (77%)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 空的`Cabin`数值：687（77%）
- en: 'Empty `Embarked` values: 2 (0.002%)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 空的`Embarked`数值：2（0.002%）
- en: From a small glance at how much data is missing, you can see you’re not getting
    around cleaning this data. It’s going to be critical to solve the missing-values
    problem, removing useless columns like `PassengerId` and ultimately encoding the
    non-numeric columns you want to keep.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 从对缺失数据量的简短查看中，您可以看到您无法避免清理这些数据。解决缺失值问题将至关重要，删除像`PassengerId`这样的无用列，并最终对您想保留的非数字列进行编码。
- en: So you don’t have to do it twice, you might as well combine the CSV files, clean
    them, and then create two new CSV files that are ready for training and testing.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 为了不必重复操作，您可以将CSV文件合并、清理，然后创建两个准备好用于训练和测试的新CSV文件。
- en: 'Currently, these are the steps:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，这些是步骤：
- en: Combine the CSV files.
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 合并CSV文件。
- en: Clean the DataFrame.
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 清理DataFrame。
- en: Re-create the CSV files from the DataFrame.
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从DataFrame重新创建CSV文件。
- en: Combining CSVs
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 合并CSV
- en: To combine the CSVs, you’ll create two DataFrames and then concatenate them
    along an axis like you would for tensors. You may feel your tensor training guiding
    you on the path with managing and cleaning data, and that’s no mistake. While
    the terminology can differ slightly, the concepts and intuition you’ve accumulated
    from the previous chapters will serve you well.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 要合并CSV文件，您将创建两个DataFrame，然后沿着轴连接它们，就像对张量一样。您可能会感觉到张量训练引导您管理和清理数据的路径，并且这并非偶然。尽管术语可能略有不同，但您从前几章积累的概念和直觉将对您有所帮助。
- en: '[PRE7]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[![1](assets/1.png)](#co_classification_models_and_data_analysis_CO2-1)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_classification_models_and_data_analysis_CO2-1)'
- en: Prints “Train Size 891”
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 打印“训练集大小为891”
- en: '[![2](assets/2.png)](#co_classification_models_and_data_analysis_CO2-2)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_classification_models_and_data_analysis_CO2-2)'
- en: Prints “Test Size 418”
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 打印“测试集大小为418”
- en: '[![3](assets/3.png)](#co_classification_models_and_data_analysis_CO2-3)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_classification_models_and_data_analysis_CO2-3)'
- en: Displays a table with the count 1,309
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 显示一个包含1,309的表
- en: With familiar syntax, you’ve loaded two CSV files and combined them into a singular
    DataFrame named `mega`, which you can now clean.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 使用熟悉的语法，您已经加载了两个CSV文件，并将它们合并成一个名为`mega`的DataFrame，现在您可以对其进行清理。
- en: Cleaning CSVs
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 清理CSV
- en: 'Here is where you’ll handle blanks and identify what data is actually useful.
    There are three operations that you need to do to properly prepare the CSV data
    for training:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您将处理空白并确定哪些数据实际上是有用的。您需要执行三个操作来正确准备用于训练的CSV数据：
- en: Prune the features.
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修剪特征。
- en: Handle the blanks.
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理空白。
- en: Migrate to numbers.
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 迁移到数字。
- en: Pruning features means removing features that have little to no influence on
    the outcome of the result. For this, you can experiment, graph the data, or simply
    use your personal intuition. To prune the features, you can use the DataFrame’s
    `.drop` function. The `.drop` function can remove entire columns or specified
    rows from a DataFrame.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 修剪特征意味着删除对结果影响很小或没有影响的特征。为此，您可以尝试实验、绘制数据图表，或者简单地运用您的个人直觉。要修剪特征，您可以使用DataFrame的`.drop`函数。`.drop`函数可以从DataFrame中删除整个列或指定的行。
- en: For this dataset, we will be dropping the columns that have little influence,
    such as the passenger’s name, ID, ticket, and cabin. You might argue that many
    of those features could be quite significant, and you’d be right. However, we’ll
    leave you to research these features outside the confines of this book.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个数据集，我们将删除对结果影响较小的列，例如乘客的姓名、ID、票和舱位。您可能会认为其中许多特征可能非常重要，您是对的。但是，我们将让您在本书之外的范围内研究这些特征。
- en: '[PRE8]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: To handle blanks, you can fill or remove rows. Filling empty rows is a craft
    called *imputation*. While this is a great skill to read up on, it can get complicated.
    We’ll be taking the easy road in this chapter and merely removing any row that
    has missing values. To remove any rows with empty data, we can use the `dropna()`
    function.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 要处理空白，您可以填充或删除行。填充空行是一种称为*插补*的技术。虽然这是一个很好的技能可以深入研究，但它可能会变得复杂。在本章中，我们将采取简单的方法，仅删除任何具有缺失值的行。要删除任何具有空数据的行，我们可以使用`dropna()`函数。
- en: Warning
  id: totrans-124
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: It’s critical that this is done *after* dropping columns. Otherwise, the 77%
    missing data from the `Cabin` column will destroy the dataset.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在删除列之后*之后*完成的至关重要。否则，`Cabin`列中77%的缺失数据将破坏数据集。
- en: 'You can drop all empty rows with this code:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下代码删除所有空行：
- en: '[PRE9]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The result of this code drops the dataset from 1,309 to 1,043 rows. Consider
    this an experiment in laziness.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码的结果将数据集从1,309行减少到1,043行。将其视为一种懒惰的实验。
- en: Lastly, you are left with two columns that have strings instead of numbers (`Embarked`
    and `Sex`). These will need to be converted to numbers.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您剩下两列是字符串而不是数字（`Embarked`和`Sex`）。这些需要转换为数字。
- en: 'The `Embarked` values, for review, are: C = Cherbourg, Q = Queenstown, S =
    Southampton. There are several ways this can be encoded. One is to encode them
    with a numeric equivalent. Danfo.js has a `LabelEncoder`, which can read an entire
    column and then transform the values to a numeric encoded equivalent. `LabelEncoder`
    encodes labels with values between `0` and `n-1` classes. To encode the `Embarked`
    column, you can use this code:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '`Embarked`的值，供参考，分别是：C = 瑟堡，Q = 昆士敦，S = 南安普敦。有几种方法可以对其进行编码。一种方法是用数字等价物对其进行编码。Danfo.js有一个`LabelEncoder`，它可以读取整个列，然后将值转换为数字编码的等价物。`LabelEncoder`将标签编码为介于`0`和`n-1`之间的值。要对`Embarked`列进行编码，您可以使用以下代码：'
- en: '[PRE10]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[![1](assets/1.png)](#co_classification_models_and_data_analysis_CO3-1)'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_classification_models_and_data_analysis_CO3-1)'
- en: Create a new `LabelEncoder` instance.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个新的`LabelEncoder`实例。
- en: '[![2](assets/2.png)](#co_classification_models_and_data_analysis_CO3-2)'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_classification_models_and_data_analysis_CO3-2)'
- en: Fit that instance to encode the contents of the `Embarked` column.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 适合对`Embarked`列的内容进行编码的实例。
- en: '[![3](assets/3.png)](#co_classification_models_and_data_analysis_CO3-3)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_classification_models_and_data_analysis_CO3-3)'
- en: Transform the column to values and immediately overwrite the current column
    with the generated one.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 将列转换为值，然后立即用生成的列覆盖当前列。
- en: '[![4](assets/4.png)](#co_classification_models_and_data_analysis_CO3-4)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_classification_models_and_data_analysis_CO3-4)'
- en: Print the top five rows to verify the replacement occurred.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 打印前五行以验证替换是否发生。
- en: Your intuition might be surprised with the ability to overwrite columns of a
    DataFrame like in step 3\. This is one of the many benefits of dealing with DataFrames
    over tensors, even though TensorFlow.js tensors power Danfo.js behind the scenes.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会对像第3步那样覆盖DataFrame列的能力感到惊讶。这是处理DataFrame而不是张量的许多好处之一，尽管TensorFlow.js张量在幕后支持Danfo.js。
- en: Now you can do the same thing to encode the `male` / `female` strings with the
    same trick. (Note that we’re simplifying sex to a binary for the purposes of the
    model and based on the data available in the passenger manifest.) Once done, your
    entire dataset is now numeric. If you call `describe` on the DataFrame, it will
    present all the columns, rather than just a few.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可以使用相同的技巧对`male` / `female`字符串进行编码。（请注意，出于模型目的和乘客名单中可用数据的考虑，我们将性别简化为二进制。）完成后，您的整个数据集现在是数字的。如果在DataFrame上调用`describe`，它将呈现所有列，而不仅仅是几列。
- en: Saving new CSVs
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 保存新的CSV文件
- en: Now that you’ve created a usable dataset for training, you’ll need to return
    the two CSV files, which had a friendly test-and-train split.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经创建了一个可用于训练的数据集，您需要返回两个CSV文件，这两个文件进行了友好的测试和训练拆分。
- en: You can resplit the DataFrame using Danfo.js’s `.sample`. The `.sample` method
    randomly selects N rows from a DataFrame. From there, you can create the test
    set as the remaining unselected values. To remove the sampled values, you can
    drop rows by index rather than an entire column.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用Danfo.js的`.sample`重新拆分DataFrame。`.sample`方法会从DataFrame中随机选择N行。从那里，您可以将剩余的未选择值创建为测试集。要删除已抽样的值，您可以按索引而不是整个列删除行。
- en: 'The DataFrame object has a `to_csv` converter, which optionally takes a parameter
    of what file to write. The `to_csv` command writes the parameter file and returns
    a promise, which resolves to the CSV contents. The entire code to resplit the
    DataFrame and write two files could go like this:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame对象具有`to_csv`转换器，可选择性地接受要写入的文件参数。`to_csv`命令会写入参数文件并返回一个promise，该promise解析为CSV内容。重新拆分DataFrame并写入两个文件的整个代码可能如下所示：
- en: '[PRE11]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Now you have two files, one with 800 rows and the other with 243 for testing.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您有两个文件，一个包含800行，另一个包含243行用于测试。
- en: Training on Titanic Data
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 泰坦尼克号数据的训练
- en: There’s one last step you’ll need to handle before training on the data, and
    that’s the classic machine learning labeled input and expected output (X and Y,
    respectively). This means you’ll need to separate the answers (the `Survived`
    column) from the other inputs. For this, you can use `iloc` to declare the index
    of columns to make new DataFrames.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 在对数据进行训练之前，您需要处理最后一步，即经典的机器学习标记输入和预期输出（X和Y，分别）。这意味着您需要将答案（`Survived`列）与其他输入分开。为此，您可以使用`iloc`声明要创建新DataFrame的列的索引。
- en: Since the first column is the `Survived` column, you’ll make your X skip that
    column and grab all the rest. You’ll identify from index one to the end of the
    DataFrame. This is written as `1:`. You could write `1:9`, which would grab the
    same set, but the `1:` means “everything after index zero.” The `iloc` index format
    represents the range you’re selecting for your DataFrame subset.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 由于第一列是`Survived`列，您将使X跳过该列并抓取其余所有列。您将从DataFrame的索引一到末尾进行识别。这写作`1:`。您可以写`1:9`，这将抓取相同的集合，但`1:`表示“从索引零之后的所有内容”。`iloc`索引格式表示您为DataFrame子集选择的范围。
- en: The Y values, or *answers,* are selected by grabbing the `Survived` column.
    Since this is a single column, there’s no need to use `iloc`. *Don’t forget to
    do the same for the test dataset*.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: Y值，或*答案*，是通过抓取`Survived`列来选择的。由于这是单列，无需使用`iloc`。*不要忘记对测试数据集执行相同操作*。
- en: 'Machine learning models expect tensors, and since Danfo.js is built on TensorFlow.js,
    it’s trivial to convert a DataFrame to a tensor. When all is said and done, you
    can convert a DataFrame by accessing the `.tensor` property:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型期望张量，而由于 Danfo.js 建立在 TensorFlow.js 上，将 DataFrame 转换为张量非常简单。最终，您可以通过访问`.tensor`属性将
    DataFrame 转换为张量。
- en: '[PRE12]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The values are ready to be fed into a model for training.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值已准备好被馈送到一个用于训练的模型中。
- en: The model I used for this problem after very little research was a sequential
    Layers model with three hidden layers and an output of one tensor with sigmoid
    activation.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 我在这个问题上使用的模型经过很少的研究后是一个具有三个隐藏层和一个具有 Sigmoid 激活的输出张量的序列层模型。
- en: 'The model is composed like so:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的组成如下：
- en: '[PRE13]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[![1](assets/1.png)](#co_classification_models_and_data_analysis_CO4-1)'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_classification_models_and_data_analysis_CO4-1)'
- en: Each layer is utilizing ReLU activation up until the final layer.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 每一层都使用 ReLU 激活，直到最后一层。
- en: '[![2](assets/2.png)](#co_classification_models_and_data_analysis_CO4-2)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_classification_models_and_data_analysis_CO4-2)'
- en: This line tells the model to initialize weights based on an algorithm rather
    than simply setting the model’s initial weights to complete randomness. This sometimes
    helps a model start much closer to the answer. It’s not critical in this case,
    but it’s a useful feature of TensorFlow.js.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 这一行告诉模型根据算法初始化权重，而不是简单地将模型的初始权重设置为完全随机。这有时可以帮助模型更接近答案。在这种情况下并不是关键，但这是 TensorFlow.js
    的一个有用功能。
- en: '[![3](assets/3.png)](#co_classification_models_and_data_analysis_CO4-3)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_classification_models_and_data_analysis_CO4-3)'
- en: The final layer uses sigmoid activation to print a number between zero and one
    (survived or did not survive).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一层使用 Sigmoid 激活来打印一个介于零和一之间的数字（生存或未生存）。
- en: '[![4](assets/4.png)](#co_classification_models_and_data_analysis_CO4-4)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](assets/4.png)](#co_classification_models_and_data_analysis_CO4-4)'
- en: When training a binary classifier, it’s prudent to evaluate loss with a fancy
    named function that works with binary classification.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练二元分类器时，最好使用一个与二元分类一起工作的花哨命名的函数来评估损失。
- en: '[![5](assets/5.png)](#co_classification_models_and_data_analysis_CO4-5)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](assets/5.png)](#co_classification_models_and_data_analysis_CO4-5)'
- en: This displays accuracy in logs, not just loss.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了日志中的准确性，而不仅仅是损失。
- en: 'When you `fit` the model to the data, you can identify the testing data and
    get results on data the model has never seen before. This helps you stop from
    overfitting:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 当您将模型`fit`到数据时，您可以识别测试数据，并获得模型以前从未见过的数据的结果。这有助于防止过拟合：
- en: '[PRE14]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[![1](assets/1.png)](#co_classification_models_and_data_analysis_CO5-1)'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_classification_models_and_data_analysis_CO5-1)'
- en: Provide the data that the model should use to validate on each epoch.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 提供模型应该在每个 epoch 上验证的数据。
- en: Note
  id: totrans-172
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The training configuration displayed in the previous `fit` method does not take
    advantage of callbacks. If you’re training on `tfjs-node`, you will automatically
    see training results printed to the console. If you use `tfjs`, you’ll need to
    add an `onEpochEnd` callback to print the training and validation accuracy. Examples
    of both are provided in the associated [source code for this chapter](https://oreil.ly/39p7V).
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的`fit`方法中显示的训练配置没有利用回调。如果您在`tfjs-node`上训练，您将自动看到训练结果打印到控制台。如果您使用`tfjs`，您需要添加一个`onEpochEnd`回调来打印训练和验证准确性。这两者的示例都在相关的[本章源代码](https://oreil.ly/39p7V)中提供。
- en: 'After training for 100 epochs, this model was 83% accurate with the training
    data and 83% accurate with the validation from the test set. Technically, the
    results will vary in each training, but they should be nearly the same: `acc=0.827
    loss=0.404 val_acc=0.831 val_loss=0.406`.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练了100个 epoch 后，这个模型在训练数据上的准确率为83%，在测试集的验证上也是83%。从技术上讲，每次训练的结果会有所不同，但它们应该几乎相同：`acc=0.827
    loss=0.404 val_acc=0.831 val_loss=0.406`。
- en: The model has identified some patterns and beaten pure chance (50% accuracy).
    Lots of people stop here and celebrate creating a model that works 83% of the
    time with little or no effort. However, this is also a great opportunity to identify
    the benefits of Danfo.js and feature engineering.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型已经识别出一些模式，并击败了纯粹的机会（50%准确率）。很多人在这里停下来庆祝创造一个几乎没有努力就能工作83%的模型。然而，这也是一个很好的机会来认识
    Danfo.js 和特征工程的好处。
- en: Feature Engineering
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 特征工程
- en: If you glance around the internet, 80% is a common accuracy score for the *Titanic*
    dataset. We’ve beaten that score with no real effort. However, there’s still room
    for improving the model, and that comes directly from improving the data.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在互联网上浏览一下，80%是*Titanic*数据集的一个常见准确率分数。我们已经超过了这个分数，而且没有真正的努力。然而，仍然有改进模型的空间，这直接来源于改进数据。
- en: Was throwing blank data a good choice? Are there correlations that exist that
    could be better emphasized? Were the patterns properly organized for the model?
    The better you can prechew and organize the data, the better the model will be
    at finding and emphasizing patterns. Lots of breakthroughs in machine learning
    have come from techniques that simplify patterns before they are passed to the
    neural network.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 抛出空白数据是一个好选择吗？存在可以更好强调的相关性吗？模式是否被正确组织为模型？您能预先处理和组织数据得越好，模型就越能找到和强调模式。许多机器学习的突破都来自于在将模式传递给神经网络之前简化模式的技术。
- en: This is where the “just dump the data” flatlines, and feature engineering grows.
    Danfo.js lets you level up your features by analyzing patterns and emphasizing
    key features. You can do this in your interactive Node.js read evaluate print
    loop (REPL), or you can even utilize web pages that have been constructed for
    evaluation and feedback loops.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这是“只是倾倒数据”停滞不前的地方，特征工程开始发展。Danfo.js 让您通过分析模式和强调关键特征来提升您的特征。您可以在交互式的 Node.js
    读取求值打印循环（REPL）中进行这项工作，或者甚至可以利用为评估和反馈循环构建的网页。
- en: Let’s try to improve the model above 83% by determining and adding features
    to the data using a Danfo.js Notebook, called Dnotebook.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试通过确定并向数据添加特征来提高上述模型的准确率至83%以上，使用一个名为 Dnotebook 的 Danfo.js Notebook。
- en: Dnotebook
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Dnotebook
- en: A Danfo Notebook, or [Dnotebook](https://dnotebook.jsdata.org), is an interactive
    web page for experimenting, prototyping, and customizing data with Danfo.js. The
    Python equivalent is called a Jupyter Notebook. The data science you can achieve
    with this notebook will significantly help your models.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: Danfo笔记本，或[Dnotebook](https://dnotebook.jsdata.org)，是一个交互式网页，用于使用Danfo.js实验、原型设计和定制数据。Python的等价物称为Jupyter笔记本。您可以通过这个笔记本实现的数据科学将极大地帮助您的模型。
- en: We’ll be using a Dnotebook to create and share live code, as well as take advantage
    of the built-in charting capabilities to find critical features and correlations
    in the *Titanic* dataset.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Dnotebook来创建和共享实时代码，以及利用内置的图表功能来查找*泰坦尼克号*数据集中的关键特征和相关性。
- en: 'Install Dnotebook by creating a global command:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 通过创建全局命令来安装Dnotebook：
- en: '[PRE15]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: When you run `$ dnotebook`, you’ll automatically run a local server and open
    a page to the local notebook site, which looks a bit like [Figure 9-4](#dnotebook).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 当您运行`$ dnotebook`时，将自动运行本地服务器并打开一个页面到本地笔记本站点，它看起来有点像[图9-4](#dnotebook)。
- en: '![Dnotebook fresh screenshot](assets/ltjs_0904.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![Dnotebook新鲜截图](assets/ltjs_0904.png)'
- en: Figure 9-4\. Fresh Dnotebook running
  id: totrans-188
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-4。正在运行的新鲜Dnotebook
- en: Each Dnotebook cell can be code or text. The text is Markdown-formatted. The
    code can print output, and variables that are initialized with no `const` or `let`
    can survive across cells. See the example illustrated in [Figure 9-5](#dnotebook_vars).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 每个Dnotebook单元格可以是代码或文本。文本采用Markdown格式。代码可以打印输出，并且未使用`const`或`let`初始化的变量可以在单元格之间保留。请参见[图9-5](#dnotebook_vars)中的示例。
- en: '![Dnotebook demo screenshot](assets/ltjs_0905.png)'
  id: totrans-190
  prefs: []
  type: TYPE_IMG
  zh: '![Dnotebook演示截图](assets/ltjs_0905.png)'
- en: Figure 9-5\. Using Dnotebook cells
  id: totrans-191
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-5。使用Dnotebook单元格
- en: The notebook in [Figure 9-5](#dnotebook_vars) can be downloaded and loaded from
    the *explaining_vars.json* file in this chapter’s [*extra/dnotebooks*](https://oreil.ly/pPvQu)
    folder. This makes it friendly for experimenting, saving, and sharing.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '[图9-5](#dnotebook_vars)中的笔记本可以从本章的[*extra/dnotebooks*](https://oreil.ly/pPvQu)文件夹中的*explaining_vars.json*文件中下载并加载。这使得它适合用于实验、保存和共享。'
- en: Titanic Visuals
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 泰坦尼克号视觉
- en: If you can find correlations in the data, you can emphasize them as additional
    features in the training data and ideally improve the model’s accuracy. Using
    the Dnotebook, you can visualize your data and add comments along the way. This
    is an excellent resource for analyzing the dataset. We’ll load the two CSV files
    and combine them, and then we’ll print the results directly in the notebook.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您可以在数据中找到相关性，您可以将其作为训练数据中的附加特征强调，并在理想情况下提高模型的准确性。使用Dnotebook，您可以可视化数据并在途中添加评论。这是分析数据集的绝佳资源。我们将加载两个CSV文件并将它们组合，然后直接在笔记本中打印结果。
- en: You can create your own notebook, or you can load the JSON for the displayed
    notebook from the associated source code. Any method is fine as long as you’re
    able to follow along with what is displayed in [Figure 9-6](#dnotebook_load).
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以创建自己的笔记本，或者可以从相关源代码加载显示的笔记本的JSON。只要您能够跟上[图9-6](#dnotebook_load)中显示的内容，任何方法都可以。
- en: '![instructional code screenshot](assets/ltjs_0906.png)'
  id: totrans-196
  prefs: []
  type: TYPE_IMG
  zh: '![指导性代码截图](assets/ltjs_0906.png)'
- en: Figure 9-6\. Loading the CSVs and combining them in the Dnotebook
  id: totrans-197
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-6。加载CSV并在Dnotebook中组合它们
- en: The `load_csv` command is similar to the `read_csv` command, but it shows a
    friendly spinner in the web page while loading the CSV content. You may also notice
    the use of a `table` command. The `table` command is similar to the DataFrame’s
    `print()` except that it generates an HTML table of the output for the notebook,
    as you see in [Figure 9-6](#dnotebook_load).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '`load_csv`命令类似于`read_csv`命令，但在加载CSV内容时在网页上显示友好的加载动画。您可能还注意到了`table`命令的使用。`table`命令类似于DataFrame的`print()`，只是它为笔记本生成了输出的HTML表格，就像您在[图9-6](#dnotebook_load)中看到的那样。'
- en: Now that you have the data, let’s look for essential distinctions that we can
    emphasize for our model. In the movie *Titanic*, they were shouting “Women and
    children first” when loading the lifeboats. Was that what really happened? One
    idea is to check the survival rate of men versus women. You can do this by using
    `groupby`. And then you can print the average (mean) of each group.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经有了数据，让我们寻找可以强调的重要区别，以供我们的模型使用。在电影《泰坦尼克号》中，当装载救生艇时他们大声喊着“妇女和儿童优先”。那真的发生了吗？一个想法是检查男性与女性的幸存率。您可以通过使用`groupby`来做到这一点。然后您可以打印每个组的平均值。
- en: '[PRE16]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: And *voila!* You can see that 83% of females survived, whereas only 14% of males
    survived, as illustrated in [Figure 9-7](#dnotebook_male_v_female).
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 而且*哇啊！*您可以看到83%的女性幸存下来，而只有14%的男性幸存下来，正如[图9-7](#dnotebook_male_v_female)中所示。
- en: '![screenshot of survival rates](assets/ltjs_0907.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![幸存率截图](assets/ltjs_0907.png)'
- en: Figure 9-7\. Females were more likely to survive
  id: totrans-203
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-7。女性更有可能幸存
- en: 'You might wonder if there were perhaps just more females aboard the *Titanic*
    and whether that accounts for the skewed results, so you can quickly check that
    using `count()` instead of using `mean()` like you did a moment ago:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会想知道也许只是因为*泰坦尼克号*上有更多女性，这就解释了倾斜的结果，所以您可以快速使用`count()`来检查，而不是像刚才那样使用`mean()`：
- en: '[PRE17]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: By the printed results, you can see there were far more men who survived despite
    the survival ratio leaning toward female. This means sex was an excellent indicator
    of chance of survival, so it would be a good feature to emphasize.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 通过打印的结果，您可以看到尽管幸存比例偏向女性，但幸存的男性要多得多。这意味着性别是幸存机会的一个很好的指标，因此应该强调这一特征。
- en: The real advantage of using Dnotebook is that it leverages Danfo.js charts.
    For instance, what if we’d like to see a histogram of the survivors? Rather than
    grouping users, you can query for all survivors and then plot the results.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Dnotebook的真正优势在于它利用了Danfo.js图表。例如，如果我们想看到幸存者的直方图，而不是分组用户，您可以查询所有幸存者，然后绘制结果。
- en: 'To query for survivors, you can use the DataFrame’s query method:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 要查询幸存者，您可以使用DataFrame的query方法：
- en: '[PRE18]'
  id: totrans-209
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Then, to print a chart in Dnotebooks, you can use the built-in `viz` command,
    which requires an ID and callback for populating the generated DIV in the notebook.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，要在Dnotebooks中打印图表，您可以使用内置的`viz`命令，该命令需要一个ID和回调函数，用于填充笔记本中生成的DIV。
- en: 'The histogram can be created with the following:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 直方图可以使用以下方式创建：
- en: '[PRE19]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The notebook will then display the resulting graph, as shown in [Figure 9-8](#dnotebook_age_hist).
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 然后笔记本将显示生成的图表，如[图9-8](#dnotebook_age_hist)所示。
- en: '![screenshot of survival histogram](assets/ltjs_0908.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![存活直方图的屏幕截图](assets/ltjs_0908.png)'
- en: Figure 9-8\. Survivor age histogram
  id: totrans-215
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-8\. 幸存者年龄直方图
- en: Here you can see significant survival rates of children over the elderly. Again,
    it might be worth determining the quantities and percentages of each, but it appears
    that specific buckets or bins of age groups fared better than others. This gives
    us a second way to possibly improve our model.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，您可以看到儿童的显着存活率高于老年人。再次，确定每个年龄组的数量和百分比可能值得，但似乎特定的年龄组或区间比其他年龄组表现更好。这给了我们可能改进模型的第二种方法。
- en: Let’s use the information we now have and take another shot at beating our record
    of 83% accuracy.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们利用我们现在拥有的信息，再次尝试打破83%准确率的记录。
- en: Creating Features (aka Preprocessing)
  id: totrans-218
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建特征（又称预处理）
- en: Growing up, I was told the more neurons you can activate for a memory, the stronger
    that memory will be, so remember the smell, the colors, and the facts together.
    Let’s see if the same goes for neural networks. We’ll move passenger sex to two
    inputs, and we’ll create a grouping of ages often called *bucketing* or *binning*.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在成长过程中，我被告知激活的神经元越多，记忆就会越强烈，因此请记住气味、颜色和事实。让我们看看神经网络是否也是如此。我们将乘客性别移动到两个输入，并创建一个经常称为*分桶*或*分箱*的年龄分组。
- en: The first thing we’ll do is move sex from one column to two columns. This is
    often called *one-hot encoding*. Currently, the `Sex` has a numeric encoding.
    A one-hot encoded version of the sex of a passenger would convert `0` to `[1,
    0]` and `1` to `[0, 1]`, successfully moving the value to two columns/units. Once
    converted, you remove the `Sex` column and insert two columns that look like [Figure 9-9](#danfo_one_hot_encoded).
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要做的第一件事是将性别从一列移动到两列。这通常称为*独热编码*。目前，`Sex`具有数字编码。乘客性别的独热编码版本将`0`转换为`[1, 0]`，将`1`转换为`[0,
    1]`，成功地将值移动到两列/单元。转换后，您删除`Sex`列并插入两列，看起来像[图9-9](#danfo_one_hot_encoded)。
- en: '![Danfo One-Hot Coded](assets/ltjs_0909.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![Danfo One-Hot Coded](assets/ltjs_0909.png)'
- en: Figure 9-9\. Describing sex one-hot encoded
  id: totrans-222
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图9-9\. 描述性别独热编码
- en: 'To one-hot encode, Danfo.js and Pandas have a `get_dummies` method that turns
    one column into several where only one of them has the value of 1\. In TensorFlow.js,
    the method for one-hot encoding is called `oneHot`, but here in Danfo.js, `get_dummies`
    is paying homage to the binary variables, which are often called *dummy variables*
    in statistics. Once you have the result encoded, you then use `drop` and `addColumn`
    to do the switch:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 要进行独热编码，Danfo.js和Pandas都有一个`get_dummies`方法，可以将一列转换为多个列，其中只有一个列的值为1。在TensorFlow.js中，进行独热编码的方法称为`oneHot`，但在Danfo.js中，`get_dummies`是向二进制变量致敬的方法，统计学中通常称为*虚拟变量*。编码结果后，您可以使用`drop`和`addColumn`进行切换：
- en: '[PRE20]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[![1](assets/1.png)](#co_classification_models_and_data_analysis_CO6-1)'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](assets/1.png)](#co_classification_models_and_data_analysis_CO6-1)'
- en: Using `get_dummies` to encode the column
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`get_dummies`对列进行编码
- en: '[![2](assets/2.png)](#co_classification_models_and_data_analysis_CO6-2)'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](assets/2.png)](#co_classification_models_and_data_analysis_CO6-2)'
- en: Using an `inplace` drop on the `Sex` column
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Sex`列上使用`inplace`删除
- en: '[![3](assets/3.png)](#co_classification_models_and_data_analysis_CO6-3)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](assets/3.png)](#co_classification_models_and_data_analysis_CO6-3)'
- en: Adding the new column, switching title to male/female
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 添加新列，将标题切换为男性/女性
- en: 'Next, you can create buckets for ages using the `apply` method. The `apply`
    method lets you run conditional code on the entire column. For our needs, we’ll
    define a function of significant age groups we saw in our charts, like so:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您可以使用`apply`方法为年龄创建桶。`apply`方法允许您在整个列上运行条件代码。根据我们的需求，我们将定义一个在我们的图表中看到的重要年龄组的函数，如下所示：
- en: '[PRE21]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Then you can create and add a whole new column for these buckets using the
    `ageToBucket` function you defined:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以使用您定义的`ageToBucket`函数创建并添加一个完全新的列来存储这些桶：
- en: '[PRE22]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This adds a whole column of values ranging from zero to two.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 这添加了一个值范围从零到二的整列。
- en: Lastly, we can normalize our data to be numbers between zero and one. Scaling
    the values normalizes the differences between values so the model can identify
    patterns and scale differences that were warped in the original numbers.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以将我们的数据归一化为介于零和一之间的数字。缩放值会使值之间的差异归一化，以便模型可以识别模式和缩放原始数字中扭曲的差异。
- en: Note
  id: totrans-237
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Think of normalization as a feature. If you were working with 10 different currencies
    from various countries, it could be confusing to comprehend. Normalizing scales
    inputs so they all have relative magnitudes of influence.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 将归一化视为一种特征。如果您正在处理来自各个国家的10种不同货币，可能会感到困惑。归一化会缩放输入，使它们具有相对影响的大小。
- en: '[PRE23]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: From here, you can write out two CSV files for training and get started! Another
    option is that you could write a single CSV file, and rather than setting `validationData`
    with specific X and Y values, you can set a property called `validationSplit`,
    which will break off a percentage of the data for validation. This saves us a
    bit of time and headache, so let’s train the model using `validationSplit` instead
    of explicitly passing in `validationData`.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，您可以为训练编写两个CSV文件并开始！另一个选项是您可以编写一个单独的CSV文件，而不是使用特定的X和Y值设置`validationData`，您可以设置一个名为`validationSplit`的属性，该属性将为验证数据拆分出一定比例的数据。这样可以节省我们一些时间和麻烦，所以让我们使用`validationSplit`来训练模型，而不是显式传递`validationData`。
- en: 'The resulting `fit` looks like this:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的`fit`如下所示：
- en: '[PRE24]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The model trains with the new data for 100 epochs, and if you’re using `tfjs-node`,
    you can see the results printed even though there’s no callback defined.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 模型使用新数据进行100个时代的训练，如果您使用`tfjs-node`，即使没有定义回调函数，也可以看到打印的结果。
- en: Feature Engineered Training Results
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征工程训练结果
- en: Last time, the model accuracy revolved around 83%. Now, using the same model
    structure but adding a few features, we reached 87% for training accuracy and
    87% for validation accuracy. Specifically, my results were `acc=0.867 loss=0.304
    val_acc=0.871 val_loss=0.370`.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 上次，模型准确率约为83%。现在，使用相同的模型结构但添加了一些特征，我们达到了87%的训练准确率和87%的验证准确率。具体来说，我的结果是`acc=0.867
    loss=0.304 val_acc=0.871 val_loss=0.370`。
- en: The accuracy increased, and the loss values are lower than before. What’s really
    great is that both the accuracy and the validation accuracy are aligned, so it
    is unlikely that the model is overfitting. This is generally one of the better
    *Titanic* dataset scores for a neural network. For such a strange problem, creating
    a fairly accurate model has served the purpose of explaining what it’s like to
    pull useful information out of data.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 准确性提高了，损失值低于以前。真正了不起的是，准确性和验证准确性都是对齐的，因此模型不太可能过拟合。这通常是神经网络在泰坦尼克号数据集中的较好得分之一。对于这样一个奇怪的问题，创建一个相当准确的模型已经达到了解释如何从数据中提取有用信息的目的。
- en: Reviewing Results
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 审查结果
- en: Solving the *Titanic* problem to achieve 87% accuracy took some finesse. You
    might still be wondering if the result could be improved, and the answer is most
    assuredly “yes” because others have posted more impressive scores to leaderboards.
    In situations without leaderboards, a common method for evaluating if there’s
    room for growth is to compare against what an educated human could score if given
    the same problem.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 解决泰坦尼克号问题以达到87%的准确率需要一些技巧。您可能仍然在想结果是否可以改进，答案肯定是“是”，因为其他人已经在排行榜上发布了更令人印象深刻的分数。在没有排行榜的情况下，评估是否有增长空间的常见方法是与一个受过教育的人在面对相同问题时的得分进行比较。
- en: If you’re a high-score junkie, the Chapter Challenge will be useful in improving
    the already impressive model we’ve created. Be sure to practice engineering features
    rather than overtraining and thus overfitting the model to essentially memorize
    the answers.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您是一个高分狂热者，章节挑战将有助于改进我们已经创建的令人印象深刻的模型。一定要练习工程特征，而不是过度训练，从而使模型过度拟合以基本上记住答案。
- en: Finding important values, normalizing features, and emphasizing significant
    correlations is a useful skill in machine learning training, and now you can do
    so with Danfo.js.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 查找重要值、归一化特征和强调显著相关性是机器学习训练中的一项有用技能，现在您可以使用Danfo.js来实现这一点。
- en: Chapter Review
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 章节回顾
- en: So what happened to the individual we identified at the start of this chapter?
    Miss Kate Connolly, a 30-year-old woman with a third-class ticket, *did* survive
    the *Titanic*, and the model agreed.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 那么在本章开始时我们识别的那个个体发生了什么？凯特·康诺利小姐，一个30岁的持有三等舱票的女人，*确实*幸存了泰坦尼克号事故，模型也认同。
- en: Did we pass up some epic opportunity to increase the accuracy of the machine
    learning model? Perhaps we should have filled empty values with `-1` instead of
    deleting them? Maybe we should have examined the cabin structure of the *Titanic*?
    Or perhaps we should have looked at `parch`, `sibsp`, and `pclass` to create a
    new column for people who were traveling alone in third class? “I’ll never let
    go!”
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们是否错过了一些提高机器学习模型准确性的史诗机会？也许我们应该用“-1”填充空值而不是删除它们？也许我们应该研究一下泰坦尼克号的船舱结构？或者我们应该查看`parch`、`sibsp`和`pclass`，为独自旅行的三等舱乘客创建一个新列？“我永远不会放手！”
- en: Not all data can be cleaned and featured like this *Titanic* dataset was, but
    it was a useful adventure in data science for machine learning. There are plenty
    of CSVs available out there, and being confident in loading, understanding, and
    processing them is key to building novel models. Tools like Danfo.js enable you
    to process these mountains of data, and you can now add this to your machine learning
    tool chest.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有数据都可以像泰坦尼克号数据集那样被清理和特征化，但这对于机器学习来说是一次有用的数据科学冒险。有很多CSV文件可用，自信地加载、理解和处理它们对于构建新颖模型至关重要。像Danfo.js这样的工具使您能够处理这些海量数据，现在您可以将其添加到您的机器学习工具箱中。
- en: Note
  id: totrans-255
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If you’re already a fan of other JavaScript notebooks like [ObservableHQ.com](https://observablehq.com),
    Danfo.js can be imported and easily integrated with those as well.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您已经是其他JavaScript笔记本的粉丝，比如[ObservableHQ.com](https://observablehq.com)，Danfo.js也可以导入并与这些笔记本轻松集成。
- en: Working with data is a mixed bag. Some problems are more clear-cut and don’t
    require any adjustment to the features at all. If you’re interested, you should
    take a look at a simpler dataset like [the Palmer Penguins](https://oreil.ly/CiNv5).
    These penguins are significantly distinguishable into their species based on the
    shape and size of their bill. Another easy win is the Iris dataset mentioned in
    [Chapter 7](ch07.html#the_chapter_7).
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 处理数据是一件复杂的事情。有些问题更加明确，根本不需要对特征进行任何调整。如果您感兴趣，可以看看像[帕尔默企鹅](https://oreil.ly/CiNv5)这样的更简单的数据集。这些企鹅根据它们的嘴的形状和大小明显地区分为不同的物种。另一个简单的胜利是第7章中提到的鸢尾花数据集。
- en: 'Chapter Challenge: Ship Happens'
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 章节挑战：船只发生了什么
- en: Did you know that not a single reverend survived the sinking of the *Titanic*?
    A bucket/bin of titles like Mr., Mrs., Ms., Rev., etc. might be useful to the
    learning of the model. These *honorifics*—yes, that’s what they are called—could
    be collected and analyzed from the `Name` column that was discarded.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 您知道在泰坦尼克号沉没中没有一个牧师幸存下来吗？像先生、夫人、小姐、牧师等这样的头衔桶/箱可能对模型的学习有用。这些*敬称*——是的，就是它们被称为的——可以从被丢弃的`Name`列中收集和分析。
- en: In this Chapter Challenge, use Danfo.js to identify the honorifics used on the
    *Titanic* and their associated survival rates. This is an excellent opportunity
    for you to get comfortable with Dnotebooks.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个章节挑战中，使用Danfo.js识别在泰坦尼克号上使用的敬称及其相关的生存率。这是一个让您熟悉Dnotebooks的绝佳机会。
- en: You can find the answer to this challenge in [Appendix B](app02.html#appendix_b).
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[附录B](app02.html#appendix_b)中找到这个挑战的答案。
- en: Review Questions
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 审查问题
- en: 'Let’s review the lessons you’ve learned from the code you’ve written in this
    chapter. Take a moment to answer the following questions:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下你在本章编写的代码中学到的教训。花点时间回答以下问题：
- en: What kind of activation function would you use for a rock-paper-scissors classifier?
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于一个石头-剪刀-布分类器，你会使用什么样的激活函数？
- en: How many nodes would you put in the final layer of a sigmoid “Dog or Not” model?
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在一个sigmoid“狗还是不是狗”模型的最终层中会放置多少个节点？
- en: What is the command to load an interactive, locally hosted notebook that has
    Danfo.js built in?
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 加载一个具有内置Danfo.js的交互式本地托管笔记本的命令是什么？
- en: How do you combine the data of two CSVs with the same columns?
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何将具有相同列的两个CSV文件的数据合并？
- en: What command would you use to one-hot encode a single column into multiple columns?
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你会使用什么命令将单个列进行独热编码成多个列？
- en: What can you use to scale all the values of a DataFrame between 0 and 1?
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用什么来将DataFrame的所有值在0和1之间进行缩放？
- en: Solutions to these exercises are available in [Appendix A](app01.html#book_appendix).
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 这些练习的解决方案可以在[附录A](app01.html#book_appendix)中找到。
