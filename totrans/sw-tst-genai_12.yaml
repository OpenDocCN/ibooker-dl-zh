- en: 10 Introducing customized LLMs
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 10 介绍定制化LLM
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: How a lack of context affects an LLM’s performance
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缺乏上下文如何影响大型语言模型（LLM）的性能
- en: How RAG works and its value
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAG的工作原理及其价值
- en: How the fine-tuning of LLMs works and its value
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM微调的工作原理及其价值
- en: Comparing RAG and fine-tuning approaches
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比较RAG和微调方法
- en: Over the past few chapters, we saw how to hone our skills to identify distinct,
    focused tasks that large language models (LLMs) can support. Combined with a range
    of prompt-engineering techniques, we’ve been successful in getting LLMs to return
    responses that are valuable for our testing activities. However, despite the lessons
    we learned, the responses we receive might still not be completely aligned with
    our needs and context. Although it would be foolish to think that we can completely
    align an LLM with our context, there are more advanced options that can be utilized
    along with prompt engineering to further maximize the output of an LLM in support
    of our testing. So, in this final part, we’re going to examine ways in which we
    can enhance LLMs so that they can become more embedded in our context, specifically
    focusing on retrieval-augmented generation (RAG) and fine-tuning. But before we
    dig into the specific details and actions of how these approaches work, we’ll
    first examine why more commonly used LLMs such as ChatGPT, Claude, and Gemini
    may struggle to tune to our context and then slowly familiarize ourselves with
    the more advanced topics of RAG and fine-tuning, comparing them to determine which
    one is more suitable in a given situation.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的几章中，我们看到了如何磨练我们的技能，以识别大型语言模型（LLMs）可以支持的不同、专注的任务。结合一系列提示工程技巧，我们已经成功地让LLMs返回对我们测试活动有价值的响应。然而，尽管我们学到了教训，我们收到的响应可能仍然不完全符合我们的需求和上下文。尽管认为我们可以完全使LLM与我们的上下文一致是愚蠢的，但我们可以利用更多高级选项，与提示工程结合使用，以进一步最大化LLM的输出，以支持我们的测试。因此，在本部分最后，我们将探讨如何增强LLMs，使它们能够更多地嵌入我们的上下文，特别是关注检索增强生成（RAG）和微调。但在深入探讨这些方法的具体细节和行动之前，我们将首先检查为什么更常用的LLMs，如ChatGPT、Claude和Gemini，可能难以调整到我们的上下文，然后逐渐熟悉RAG和微调等更高级的主题，比较它们以确定在特定情况下哪一个更适合。
- en: 10.1 The challenge with LLMs and context
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.1 LLMs和上下文的挑战
- en: We learned that the key challenge of working with LLMs is getting them to respond
    with an output that
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 我们了解到，与LLM一起工作的关键挑战是让他们以输出响应，
- en: Is relevant to our context
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与我们的上下文相关
- en: Follows the rules of our prompt
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遵循我们的提示规则
- en: Contains no hallucinations
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不包含幻觉
- en: The prompt-engineering techniques we’ve used have helped us achieve these goals
    so far. For example, if we return to our example prompt from chapter 5, we can
    see a weak prompt such as
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们所使用的提示工程技巧帮助我们实现了这些目标。例如，如果我们回到第5章的示例提示，我们可以看到一个弱的提示，例如
- en: '|'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-MW.png)'
- en: '| Create tests for a file upload feature |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '| 创建文件上传功能的测试 |'
- en: 'which returns a weak response with quite generalized results:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回一个弱响应，具有相当通用的结果：
- en: '|'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-openai.png)'
- en: '|    1.  Test for File Upload Functionality:   •   Test Case 1.1: Upload a
    Valid File   −   Input: Choose a file with a valid format (e.g., .jpg, .pdf).  
    −   Expected Outcome: The file is successfully uploaded, and a confirmation message
    is displayed.   •   Test Case 1.2: Attempt to Upload an Invalid File   −   Input:
    Choose a file with an invalid format (e.g., .exe, .xhtml).   −   Expected Outcome:
    An error message is displayed, indicating that the file format is not supported.  
    2.  Test for File Size Limit:   •   Test Case 2.1: Upload a File Below the Size
    Limit   −   Input: Choose a file smaller than the maximum allowed size.   −  
    Expected Outcome: The file is successfully uploaded, and a confirmation message
    is displayed.   •   Test Case 2.2: Attempt to Upload a File Exceeding the Size
    Limit   −   Input: Choose a file larger than the maximum allowed size.   −   Expected
    Outcome: An error message is displayed, indicating that the file exceeds the maximum
    size limit. |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 1. 测试文件上传功能：   • 测试用例1.1：上传有效的文件   − 输入：选择一个有效格式的文件（例如，.jpg, .pdf）。   − 预期结果：文件成功上传，并显示确认消息。  
    • 测试用例1.2：尝试上传无效的文件   − 输入：选择一个无效格式的文件（例如，.exe, .xhtml）。   − 预期结果：显示错误消息，指出文件格式不受支持。  
    2. 测试文件大小限制：   • 测试用例2.1：上传小于最大允许大小的文件。   − 输入：选择一个小于最大允许大小的文件。   − 预期结果：文件成功上传，并显示确认消息。  
    • 测试用例2.2：尝试上传超过大小限制的文件。   − 输入：选择一个大于最大允许大小的文件。   − 预期结果：显示错误消息，指出文件超过最大大小限制。
    |'
- en: However, a prompt with more detail and the right prompt-engineering tactics
    can result in a more optimal response. A prompt such as
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，一个更详细且使用正确提示工程策略的提示可以导致更优化的响应。例如，一个提示
- en: '|'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![MW 标志](../../OEBPS/Images/logo-MW.png)'
- en: '| You are an expert software tester. Generate as many test cases as possible
    for the behavior delimited by three hashes.###An Authorization API that will take
    a token from a different API and check to see if the token is valid and in date
    before either responding positively or negatively depending on the result.###
    |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| 你是一位软件测试专家。为以下由三个井号分隔的行为生成尽可能多的测试用例。###一个授权API，它将从不同的API获取令牌并检查该令牌是否有效且在有效期内，然后根据结果积极或消极地响应。###
    |'
- en: returns more specific results, such as
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 返回更具体的结果，如
- en: '|'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![OpenAI 标志](../../OEBPS/Images/logo-openai.png)'
- en: '|    1.  Valid Token Check:   •   Test with a valid token that is within the
    expiration date. Expected result: API responds positively.   2.  Expired Token
    Check:   •   Test with a valid token that has expired. Expected result: API responds
    negatively.   3.  Invalid Token Check:   •   Test with an invalid token format
    (e.g., incorrect characters, wrong length). Expected result: API responds negatively.  
    4.  Empty Token Check:   •   Test with an empty token input. Expected result:
    API responds negatively or returns an appropriate error message.   5.  Null Token
    Check:   •   Test with a null token input. Expected result: API responds negatively
    or returns an appropriate error message. |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 1. 有效的令牌检查：   • 使用在有效期内有效的令牌进行测试。预期结果：API响应积极。   2. 过期令牌检查：   • 使用已过期的有效令牌进行测试。预期结果：API响应消极。  
    3. 无效令牌检查：   • 使用无效的令牌格式进行测试（例如，字符错误，长度不正确）。预期结果：API响应消极。   4. 空令牌检查：   • 使用空令牌输入进行测试。预期结果：API响应消极或返回适当的错误信息。  
    5. 空值令牌检查：   • 使用空值令牌输入进行测试。预期结果：API响应消极或返回适当的错误信息。 |'
- en: 'Our second prompt is more successful because we’ve shared more of our context
    within as well as used specific prompt engineering tactics. Therefore, if we want
    to get the most out of an LLM, we not only need to rely on good prompt-engineering
    techniques, but also provide the most relevant context possible. The reasons for
    this are twofold:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第二个提示更成功，因为我们不仅分享了更多的上下文，还使用了特定的提示工程策略。因此，如果我们想最大限度地利用LLM（大型语言模型），我们不仅需要依赖良好的提示工程技巧，还需要提供尽可能相关的上下文。原因有两点：
- en: It is more than likely that an LLM has not been trained on our context. Therefore,
    an LLM has no increased weighting or bias toward our context.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 很可能LLM（大型语言模型）没有在我们的上下文中接受过训练。因此，LLM对我们上下文没有增加的权重或偏见。
- en: An LLM is trained on such a massive amount of generalized data that when asked
    a generic question, it will rely on stronger, more generalized patterns it has
    identified from the training process.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM（大型语言模型）接受过如此大量的通用数据训练，当被问及一个通用问题时，它将依赖于从训练过程中识别出的更强、更通用的模式。
- en: 'So, if we want to get the best out of an LLM, on the surface, the answer seems
    simple enough: provide it with as much context detail as possible (which we have
    been doing to some degree already). However, if we were to do this, we’d quickly
    run into some limitations around the amount we can send in a prompt.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们想从 LLM 中获得最佳效果，表面上，答案似乎很简单：尽可能提供更多的上下文细节（我们已经在某种程度上这样做）。然而，如果我们这样做，我们很快就会遇到在提示中可以发送的上下文量的一些限制。
- en: 10.1.1 Tokens, context windows, and limitations
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.1 令牌、上下文窗口和限制
- en: Before we talk about this prompting limitation, there are some other concepts
    around LLMs that we need to be aware of—namely, tokens and context windows. Understanding
    these two aspects of LLMs will help us appreciate why current LLMs have an upper
    limit on how much context can be provided and how that affects our strategies
    of use.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们讨论这个提示限制之前，还有一些关于 LLM 的概念我们需要了解——即令牌和上下文窗口。理解这两个方面的 LLM 将帮助我们理解为什么当前的 LLM
    在可以提供的上下文量上有上限，以及这如何影响我们的使用策略。
- en: Tokens
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 令牌
- en: 'Imagine we are sending the following prompt to an LLM:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们正在向一个 LLM 发送以下提示：
- en: '|'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-MW.png)'
- en: '| List me five of the most populated cities in the world. |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 列出世界上人口最多的五个城市。 |'
- en: 'How does an LLM, which can only interpret information using machine code, parse
    this prompt and return a response? This is done through a process known as *tokenization,*
    in which natural language text is converted into matching integers that can be
    read by an LLM. To understand how this works, let’s consider our populated cities
    prompt. If we were to put this through the tokenization process, the sentence
    would be sliced into smaller, discrete parts. For example, our prompt could be
    broken into 12 sections:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一个只能使用机器码解释信息的 LLM 如何解析这个提示并返回响应？这是通过一个称为 *分词* 的过程完成的，在这个过程中，自然语言文本被转换成 LLM
    可以读取的匹配整数。为了理解这是如何工作的，让我们考虑我们的城市人口提示。如果我们将其通过分词过程，这个句子将被切割成更小的、离散的部分。例如，我们的提示可以被分成
    12 个部分：
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As we can see, each word in the sentence and the period at the end have been
    sliced into their own smaller sections, known as *tokens.* Notice how they also
    include the whitespace to the left of each word. It’s a general rule of thumb
    that each word in a sentence is split into its token; however, some tokenizers
    (the tools used for making this conversion) can sometimes break up larger words
    into individual tokens or group smaller words together.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，句子中的每个单词以及句尾的句号都被切分成更小的部分，这些部分被称为 *令牌*。注意它们还包括每个单词左侧的空白。一般来说，句子中的每个单词都会被分割成其对应的令牌；然而，一些分词器（用于进行这种转换的工具）有时会将较大的单词分割成单独的令牌，或者将较小的单词组合在一起。
- en: 'Once a sentence has been sliced into tokens, each one is converted into an
    integer with a unique number being used as an identifier for each word. For example,
    completing the tokenization of our prompt would result in a list of numbers (the
    commas and whitespace have been added to help readability):'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦句子被切割成令牌，每个令牌都会被转换成一个整数，使用一个唯一的数字作为每个单词的标识符。例如，完成我们的提示的分词将产生一个数字列表（逗号和空白已被添加以帮助可读性）：
- en: '|'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-openai.png)'
- en: '|'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '|'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'Each number in this list correlates to a specific slice taken from our prompt.
    For example, the token `the` has an id of 279 and we can see that it appears twice
    in the list for each instance when `the` was used in the sentence. Once the prompt
    has completed the tokenization process, the model we use is then able to process
    the list of integers and start determining how to respond. Then the process of
    tokenization is used again to create the response text we receive from a model,
    so our model might respond with a series of integers:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 列表中的每个数字都与从我们的提示中提取的特定切片相关联。例如，令牌 `the` 的 ID 为 279，我们可以看到它在列表中出现了两次，每次 `the`
    在句子中使用时都会出现。一旦提示完成分词过程，我们使用的模型就能够处理整数列表并开始确定如何回应。然后，分词过程再次被用来创建我们从模型收到的响应文本，因此我们的模型可能会以一系列整数的形式回应：
- en: '|'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-openai.png)'
- en: '|'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '[PRE2]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '|'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'When converted back into text, it would result in the following response (line
    breaks are also included in the integer list, and each mention of iteration of
    11 is a line break):'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 当转换回文本时，它会产生以下响应（行中断也包含在整数列表中，每次提到迭代 11 都是一个行中断）：
- en: '|'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-openai.png)'
- en: '| Tokyo, JapanDelhi, IndiaShanghai, ChinaSão Paulo, BrazilMumbai, India |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 东京，日本 | 德里，印度 | 上海，中国 | 圣保罗，巴西 | 孟买，印度 |'
- en: Experimenting with tokenizers
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试不同的标记化器
- en: To better understand how the tokenization process works and how words, numbers,
    and symbols are sliced, we can experiment with preview tools for tokenizing such
    as the one at [https://gpt-tokenizer.dev/](https://gpt-tokenizer.dev/).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解标记化过程是如何工作的，以及单词、数字和符号是如何被分割的，我们可以尝试使用标记化预览工具，例如[https://gpt-tokenizer.dev/](https://gpt-tokenizer.dev/)。
- en: So, tokens are an important aspect of LLMs because they inform us not just of
    how a model can parse a prompt and form a response, but also of how large a prompt
    can be sent to said model before we run into problems. This brings us to context
    windows and the crux of our context challenge.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，标记是LLM（大型语言模型）的一个重要方面，因为它们不仅告诉我们模型如何解析提示并形成响应，还告诉我们在我们遇到问题之前可以向该模型发送多长的提示。这引出了上下文窗口和我们的上下文挑战的核心。
- en: Context windows
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文窗口
- en: Given that the tokenization process takes natural language and turns it into
    a series of numbers for an LLM to process, the longer a prompt is, the more tokens
    there are to process. The problem with prompts that have larger sets of tokens
    is that it affects how effectively an LLM processes our prompt and the resources
    it consumes. The larger a prompt, the more complex it becomes to generate a response,
    which means more hardware usage. All of this will come at a cost, either in hosting
    fees if utilizing a private LLM or API costs for sending prompts (platforms such
    as OpenAI charge based on the number of sent and received tokens).
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 由于标记化过程将自然语言转换为LLM可以处理的数字序列，提示越长，需要处理的标记就越多。具有大量标记的提示的问题在于它会影响LLM处理我们的提示的有效性以及它消耗的资源。提示越大，生成响应就越复杂，这意味着更多的硬件使用。所有这些都会产生成本，无论是使用私有LLM的托管费用还是发送提示的API费用（例如，OpenAI根据发送和接收的标记数量收费）。
- en: Add to this that a larger context window doesn’t necessarily mean a better-performing
    LLM, and we start to see that providers of LLMs have a tradeoff to make. As a
    result, LLMs will likely have some sort of limitation built into the model on
    the number of tokens it can receive at a given time. This is known as a model’s
    `context` `window`. Different models contain different-sized context windows,
    which are sometimes also referred to as the context length. All of this depends
    on the type of model that has been trained, the hardware it is running on, and
    how it has been deployed with other supporting applications. For example, OpenAI’s
    ChatGPT 4 is estimated to have a context window of 128k tokens, whereas that for
    Meta’s Llama-2 is 4k (before modifications are made). Therefore, when it comes
    to determining which LLM to use in a given situation, we must be aware of the
    context length. Choosing a model that is limited in size to save cost might limit
    what context we can add to a prompt.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 再加上更大的上下文窗口并不一定意味着LLM性能更好，我们开始看到LLM提供商需要在某些方面做出权衡。因此，LLM可能会在模型中内置某种类型的限制，限制它在特定时间内可以接收的标记数量。这被称为模型的`上下文`
    `窗口`。不同的模型包含不同大小的上下文窗口，有时也被称为上下文长度。所有这些都取决于所训练的模型类型、运行它的硬件以及它与其他支持应用程序的部署方式。例如，OpenAI的ChatGPT
    4据估计具有128k标记的上下文窗口，而Meta的Llama-2为4k（在修改之前）。因此，在确定在特定情况下使用哪个LLM时，我们必须意识到上下文长度。选择一个为了节省成本而限制大小的模型可能会限制我们可以添加到提示中的上下文。
- en: Not all context windows are the same
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有上下文窗口都相同
- en: One thing to note when discussing context windows is that just because a model
    is able to take, for example, a 128k token request, it doesn’t mean that the response
    will have the same limitations. In fact, it may be that the response has a much
    smaller window to help keep costs down. This won’t necessarily affect our learning
    in the following chapters, but it’s a useful detail to keep in mind when expecting
    a model to return a large response.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 讨论上下文窗口时需要注意的一点是，即使模型能够接收例如128k标记的请求，这并不意味着响应会有相同的限制。事实上，可能响应有一个更小的窗口来帮助降低成本。这不一定会影响我们接下来章节的学习，但这是一个在期望模型返回大型响应时值得记住的细节。
- en: 10.1.2 Embedding context as a solution
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1.2 将上下文作为解决方案
- en: Now that we understand that LLMs interpret our requests through tokenization
    and that the size of tokens we can send to an LLM is limited, we can start to
    see the problem we face when adding further context to our prompts. Although LLMs
    are developing rapidly, becoming more efficient and offering larger context windows,
    it’s simply not cost-effective to, for example, add a complete code base of an
    application with prompt’s instructions. We’d either end up hitting the upper limits
    of a model’s capabilities or burning our budget at a rapid pace. Instead, to maximize
    accuracy, we need to consider how we embed context into our prompts and our LLMs
    in an intelligent way. Fortunately, there has been a lot of work in the AI community
    that we can use to embed our context further in a way that improves accuracy and
    doesn’t break the bank (or the model) in the process.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们了解到LLMs通过分词来解释我们的请求，并且我们可以发送给LLM的token大小是有限的，我们就可以开始看到当我们向提示中添加更多上下文时所面临的问题。尽管LLMs正在快速发展，变得更加高效，并提供了更大的上下文窗口，但例如添加一个应用程序的完整代码库作为提示的指令，这并不划算。我们可能会达到模型能力的上限，或者快速烧光我们的预算。相反，为了最大化准确性，我们需要考虑如何以智能的方式将上下文嵌入到我们的提示和LLMs中。幸运的是，AI社区已经做了很多工作，我们可以利用这些工作来进一步嵌入上下文，从而提高准确性，同时不会让我们的预算（或模型）受损。
- en: 10.2 Embedding context further into prompts and LLMs
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10.2 将上下文进一步嵌入到提示和LLMs中
- en: 'To improve the ability to increase an LLM’s exposure to our context, we can
    utilize one of two techniques. The first is RAG, and the second, fine-tuning.
    Throughout the remaining chapters, we’ll explore how these two approaches work,
    how they differ from one another, and how we can determine which is a more suitable
    approach to improving an LLM’s responses. Although both approaches are different
    in application, the end goal of both is similar: to help us improve a model’s
    performance by allowing us to add more context to an LLM’s workflow. Retrieval-augmented
    generation looks to solve the problem by focusing on ways in which we can enhance
    our prompting, whereas fine-tuning looks to bake our context directly into the
    model itself. Let’s take a look at both briefly so that we can become more familiar
    with them and determine which approach is more suitable in a given situation.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高LLM接触我们上下文的能力，我们可以利用两种技术之一。第一种是RAG，第二种是微调。在接下来的章节中，我们将探讨这两种方法是如何工作的，它们之间有何不同，以及我们如何确定哪种方法更适合提高LLM的响应。尽管这两种方法在应用上不同，但它们的最终目标相似：通过允许我们向LLM的工作流程添加更多上下文，帮助我们提高模型的表现。检索增强生成试图通过关注我们如何增强提示的方式来解决问题，而微调则试图将我们的上下文直接嵌入到模型本身中。让我们简要地看看这两种方法，以便我们更加熟悉它们，并确定在特定情况下哪种方法更合适。
- en: 10.2.1 RAG
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.1 RAG
- en: As we learned earlier, if an LLM has limitations in the size of a prompt it
    can receive due to a context window, it’s inadvisable to attempt to throw all
    our context into a single prompt hoping that it will improve an LLM’s response.
    However, that doesn’t mean we can’t be selective with the type of context we provide
    in a prompt. What this means is that accuracy can be improved in an LLM not by
    brute-forcing our context onto an LLM, but by crafting our prompts so that they
    contain all the relevant information about our context to support our instructions.
    In more concrete terms, this means that if we wanted an LLM to generate boilerplate
    page objects for an automated check, it would be better to provide the specific
    HTML for a page and any relevant code for said page than add the entire code base
    to a prompt.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们之前所学的，如果一个LLM由于上下文窗口的限制而在接收提示的大小上存在限制，那么试图将所有上下文都放入一个提示中，希望它能改善LLM的响应，是不明智的。然而，这并不意味着我们不能在选择我们提供的提示中的上下文类型时有所选择。这意味着，在LLM中提高准确性，不是通过将我们的上下文强行施加到LLM上，而是通过精心设计我们的提示，使它们包含关于我们上下文的全部相关信息，以支持我们的指令。更具体地说，这意味着如果我们想让LLM为自动化检查生成模板页面对象，提供页面的特定HTML和任何相关的代码会比将整个代码库添加到提示中更好。
- en: 'On the surface, this seems like an effective and simple approach: write our
    prompt, find the relevant supporting information, combine the two into a final
    prompt, and send it to an LLM. The problem though is that this can be a labor-intensive
    activity, researching and determining what information to add and what to ignore.
    Fortunately, this is where RAG can help us. As shown in figure 10.1, RAG works
    by automating the process of embedding relevant information into our prompts through
    using our prompt’s initial instructions to determine what information to add to
    our prompt.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 表面上看，这似乎是一个有效且简单的方法：编写我们的提示，找到相关的支持信息，将两者合并成最终的提示，然后发送给LLM。然而，问题在于这可能是一项劳动密集型活动，需要研究和确定要添加什么信息以及要忽略什么信息。幸运的是，这正是RAG能帮助我们的地方。如图10.1所示，RAG通过使用提示的初始指令来自动化将相关信息嵌入到我们的提示中的过程，以确定要添加到我们的提示中的信息。
- en: '![](../../OEBPS/Images/CH10_F01_Winteringham2.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH10_F01_Winteringham2.png)'
- en: Figure 10.1 A high-level workflow diagram for RAG
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.1 RAG的高级工作流程图
- en: 'To help us better understand the process, let’s return to our Page-object-generation
    prompt example. With a RAG framework, the approach would work like this:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助我们更好地理解这个过程，让我们回到我们的Page-object-generation提示示例。使用RAG框架，方法将是这样进行的：
- en: A corpus of information will have been created. In our example, it may contain
    labeled HTML documents for each page of our application.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 信息语料库将被创建。在我们的例子中，它可能包含我们应用程序每一页的标记HTML文档。
- en: A prompt is created in which we ask for an LLM to generate a Page object for
    our booking listing page.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建了一个提示，要求LLM为我们预订列表页面生成一个页面对象。
- en: Our RAG framework analyzes our prompt and programmatically finds the most relevant
    document in our corpus of HTML documents. If the RAG framework is working correctly,
    it will determine that the HTML document that contains the booking listing is
    the most relevant.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们的RAG框架会分析我们的提示，并在我们的HTML文档语料库中程序化地找到最相关的文档。如果RAG框架工作正常，它将确定包含预订列表的HTML文档是最相关的。
- en: The most relevant HTML document is added to the prompt that we initially created,
    and the prompt is then sent to an LLM to return a response.
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将最相关的HTML文档添加到我们最初创建的提示中，然后将提示发送给LLM以返回响应。
- en: The RAG helps us contextualize our prompts further by analyzing what we’re asking
    and then automatically identifying the right type of context. What makes this
    useful is that it helps us create a prompt with the information that is of most
    use for an LLM to create a more accurate response than if the information didn’t
    exist. It’s also a useful approach because RAG allows us to embed any type of
    data that is easy to parse and search for relevancy, whether it’s code, documentation,
    database entries, or raw metrics. We also can control how relevancy is determined,
    meaning that we still have control over the type of information that might be
    added to a prompt.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: RAG通过分析我们所询问的内容，然后自动识别正确的上下文类型，帮助我们进一步地语境化我们的提示。这使得它非常有用，因为它帮助我们创建一个包含对LLM来说最有用的信息的提示，从而生成比没有这些信息更准确的响应。这同样是一种有用的方法，因为RAG允许我们嵌入任何易于解析和搜索相关性的数据类型，无论是代码、文档、数据库条目还是原始指标。我们还可以控制相关性的确定方式，这意味着我们仍然对可能添加到提示中的信息类型有控制权。
- en: For these reasons and its relative ease of setup, RAG has become a popular approach
    to enhancing our interaction with LLMs. Once we begin to appreciate how RAG works,
    we can begin to see how it might be useful in a testing context. We’ve already
    explored the idea of using RAG to extract sections of a code base to support prompts
    that are looking to create automation, but it can also be used to support queries
    around risk analysis, understanding how our products work and generating test
    ideas. There is also the potential to use testing artifacts in RAG frameworks,
    such as exploratory testing notes, test scripts, or automation code, to bolster
    the prompting ideas we explored in the previous chapters. At its core, if the
    data we want to use can be stored in a consistent format and easily queried, then
    it has the potential to be used in a RAG framework.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些原因以及其相对容易的设置，RAG已成为增强我们与LLMs互动的一种流行方法。一旦我们开始欣赏RAG的工作原理，我们就可以开始看到它在测试环境中的潜在用途。我们已经探讨了使用RAG提取代码库部分以支持旨在创建自动化的提示的想法，但它也可以用于支持关于风险评估、理解我们的产品如何工作以及生成测试想法的查询。还有在RAG框架中使用测试工件的可能性，例如探索性测试笔记、测试脚本或自动化代码，以加强我们在前几章中探讨的提示想法。从本质上讲，如果我们想要使用的数据可以以一致的形式存储并轻松查询，那么它有潜力被用于RAG框架中。
- en: 10.2.2 Fine-tuning LLMs
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.2 微调LLMs
- en: Although RAG focuses on ways to enhance a prompt by adding targeted contextual
    material, fine-tuning focuses on enhancing the model we’re using itself. Fine-tuning
    utilizes a collection of tools and techniques used to further train a model that
    has already been initially trained in hope that it will bias the model further
    toward the data it has been fine-tuned on, as summarized in figure 10.2.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然RAG侧重于通过添加有针对性的上下文材料来增强提示，但微调侧重于增强我们使用的模型本身。微调利用一系列工具和技术，用于进一步训练一个已经初步训练过的模型，希望它能进一步使模型偏向于它已经被微调的数据，如图10.2所示。
- en: '![](../../OEBPS/Images/CH10_F02_Winteringham2.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/CH10_F02_Winteringham2.png)'
- en: Figure 10.2 A visualization outlining the difference between training and fine-tuning
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.2 展示了训练和微调之间的差异的可视化
- en: 'As the figure shows, fine-tuning takes place against a model that has already
    been trained on a large corpus of data. For example, the free version of ChatGPT
    is a fine-tuned version of OpenAI’s gpt-3.5-turbo model. gpt-3.5 went through
    a series of training processes to get its core abilities, but when interacted
    with, it lacks the tone and characteristics of a chatbot. For example, after sending
    the following prompt to gpt-3.5 (before fine-tuning):'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如图中所示，微调是在已经在大规模数据集上训练过的模型上进行的。例如，ChatGPT的免费版本是OpenAI的gpt-3.5-turbo模型的微调版本。gpt-3.5经历了一系列的训练过程以获得其核心能力，但与人类互动时，它缺乏聊天机器人的语气和特征。例如，在向gpt-3.5（在微调之前）发送以下提示后：
- en: '|'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-MW.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-MW.png)'
- en: '| You are an expert travel agent. Give me a list of the top three places to
    visit in London. |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 你是一位专业的旅行代理人。为我列出伦敦前三个必游之地。 |'
- en: 'I received the following response:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我收到了以下回应：
- en: '|'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-openai.png)'
- en: '|    1.  The British Museum - This iconic museum houses a vast collection of
    art and artifacts from all corners of the globe, including the Rosetta Stone and
    the controversial Elgin Marbles. It is a must-visit for history and culture enthusiasts.  
    2.  The Tower of London - This historic fortress on the banks of the River Thames
    has served as a royal palace, prison, and armory. Visitors can explore the Crown
    Jewels, see the famous ravens, and learn about the Tower’s fascinating history.  
    3.  The West End - London’s renowned theater district is home to world-class productions
    and musicals. Take in a show at one of the many historic venues like the Royal
    Opera House or the National Theatre, and experience the magic of London’s vibrant
    performing arts scene. |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 1. 大英博物馆 - 这座标志性的博物馆收藏了来自全球各地的艺术和文物，包括罗塞塔石碑和有争议的伊林大理石。它是历史和文化爱好者的必游之地。  
    2. 伦敦塔 - 这座位于泰晤士河岸的历史堡垒曾作为皇家宫殿、监狱和军械库。游客可以探索王冠珠宝，看到著名的乌鸦，并了解伦敦塔迷人的历史。   3. 西区
    - 伦敦著名的剧院区是世界上最顶级制作和音乐剧的家园。在皇家歌剧院或国家剧院等众多历史场馆之一观看演出，体验伦敦充满活力的表演艺术场景。 |'
- en: 'Whereas, upon sending the prompt to ChatGPT (a fine-tuned version of gpt-3.5),
    I received the following response:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，当我将提示发送给ChatGPT（gpt-3.5的微调版本）时，我收到了以下回应：
- en: '|'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '![](../../OEBPS/Images/logo-openai.png)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![](../../OEBPS/Images/logo-openai.png)'
- en: '| Absolutely! London offers a plethora of attractions, but here are three must-visit
    places:   1.  The British Museum: It’s a treasure trove of human history and culture,
    housing millions of artifacts spanning centuries and continents. From the Rosetta
    Stone to the Egyptian mummies and the Elgin Marbles, the British Museum is a fascinating
    journey through civilizations.   2.  The Tower of London: Steeped in history and
    legend, the Tower of London is an iconic fortress that has served as a royal palace,
    prison, and treasury over the centuries. Visitors can explore its ancient walls,
    marvel at the Crown Jewels, and hear tales of famous prisoners and executions.  
    3.  Westminster Abbey: A masterpiece of Gothic architecture, Westminster Abbey
    is not only a place of worship but also the site of royal coronations, weddings,
    and burials. Visitors can admire its stunning stained glass windows, intricate
    stone carvings, and the tombs of famous figures like Isaac Newton, Charles Darwin,
    and Elizabeth I.These attractions offer a rich glimpse into London’s history,
    culture, and heritage. |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: 绝对没错！伦敦提供了众多景点，但以下这三个地方是必游之地：   1. 大英博物馆：它是人类历史和文化的宝库，收藏着跨越数个世纪和大陆的数百万件文物。从罗塞塔石碑到埃及木乃伊和伊辛大理石，大英博物馆是一段穿越文明的迷人之旅。  
    2. 伦敦塔：历史悠久，充满传说，伦敦塔是一座标志性的堡垒，在几个世纪中曾作为皇家宫殿、监狱和金库使用。游客可以探索其古老的城墙，惊叹于王冠珠宝，并聆听著名囚犯和处决的故事。  
    3. 威斯敏斯特教堂：哥特式建筑的杰作，威斯敏斯特教堂不仅是礼拜场所，也是皇家加冕、婚礼和葬礼的地点。游客可以欣赏其令人惊叹的彩色玻璃窗、精致的石雕，以及艾萨克·牛顿、查尔斯·达尔文和伊丽莎白一世等著名人物的陵墓。这些景点为伦敦的历史、文化和遗产提供了丰富的视角。
    |
- en: Factually, they are similar. But looking at the second response, we can see
    that it has a bit more flavor to it. It has a more casual and friendly tone, all
    of which comes from the fine-tuning process it has undergone to make it feel more
    chat-like.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，它们是相似的。但观察第二个回答，我们可以看到它多了些风味。它有更随和、友好的语气，这一切都归功于它经过精心调整的过程，使其更具对话感。
- en: Qualities such as ChatGPT’s more casual tone are achieved by training a model
    with a curated dataset in hope of biasing its internal parameters toward a desired
    tone, style, or specific context. To recap, a model consists of millions or billions
    of parameters that determine the probability of which word should come after another
    word or collection of words. These parameters are in place when a fine-tuning
    session is started, and the fine-tuning process seeks to influence the parameters
    further toward an end goal. We’ll talk about this more in chapter 11, but we can
    see how this approach works in figure 10.3.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于ChatGPT更随和的语气这样的品质，是通过使用精心挑选的数据集来训练模型，希望将其内部参数偏向于期望的语气、风格或特定上下文来实现的。总结一下，一个模型由数百万或数十亿个参数组成，这些参数决定了哪个词应该跟在另一个词或一组词之后。当开始微调会话时，这些参数已经存在，微调过程旨在进一步影响这些参数，使其更接近最终目标。我们将在第11章中更详细地讨论这个问题，但我们可以从图10.3中看到这种方法是如何工作的。
- en: Fine-tuning takes information from a data set and uses it to form a prompt sent
    to our model that is being fine-tuned. The response is then evaluated against
    an expected response. If the responses don’t align, the model is tweaked so that
    its chances of an aligned response the next time are increased. This is then done
    thousands of, or perhaps millions of, times to slowly tune a model closer to our
    end goal of how we want the fine-tuned model to respond, which means that a very
    large corpus of data is required to successfully train a model.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 微调是从数据集中提取信息，并使用这些信息形成发送给正在微调的模型的提示。然后，将响应与预期响应进行比较。如果响应不一致，模型将进行调整，以便在下一次提高产生一致响应的机会。这个过程可能需要成千上万次，甚至数百万次，以逐渐调整模型，使其更接近我们希望微调模型达到的目标，这意味着需要一个非常大的数据集才能成功训练模型。
- en: Applying fine-tuning to a model can have a range of benefits. We have already
    seen them in the fine-tuning of GPT into ChatGPT, but we’ve also taken advantage
    of fine-tuned GPT models in the form of GitHub Copilot. These examples demonstrate
    the range of uses that fine-tuning can provide in a testing context. Thus, we
    can tune models based on natural language text that might come from documentation
    or testing artifacts. This could be used to embed domain language into its responses
    and promote responses that are more tuned to our context. They can also be tuned
    on our code base to help us with additional risk analysis, comprehension of what
    our code is doing, or acting as a more aligned code assistant.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '将微调应用于模型可以带来一系列好处。我们已经在将GPT微调到ChatGPT中看到了它们，但我们还利用了微调后的GPT模型，以GitHub Copilot的形式出现。这些例子展示了微调在测试环境中可以提供的各种用途。因此，我们可以根据可能来自文档或测试工件的自然语言文本来调整模型。这可以用来将领域语言嵌入其响应中，并促进更符合我们上下文的响应。它们也可以在我们的代码库上进行调整，以帮助我们进行额外的风险评估、理解我们的代码在做什么，或者作为更一致的代码助手。 '
- en: When discussing fine-tuning, we need to be careful not to fall into the trap
    of thinking we’re teaching a model about our context. LLMs don’t think like humans
    do. But, as an analogy, teaching a model about our context is a close one. The
    challenge is that it’s not an exact process, meaning that multiple iterations
    are likely required to get the result we want, and as our context changes, further
    tuning sessions would likely be required.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 当讨论微调时，我们需要小心不要陷入这样的陷阱：认为我们在教模型关于我们的上下文。大型语言模型（LLMs）并不像人类那样思考。但是，作为一个类比，教模型关于我们的上下文是非常接近的。挑战在于这并不是一个精确的过程，这意味着可能需要多次迭代才能得到我们想要的结果，并且随着我们的上下文变化，可能还需要进一步的调整会话。
- en: '![](../../OEBPS/Images/CH10_F03_Winteringham2.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH10_F03_Winteringham2.png)'
- en: Figure 10.3 A visual model of how fine-tuning works
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.3 微调工作原理的视觉模型
- en: 10.2.3 Comparing the two approaches
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.3 比较两种方法
- en: Knowing which approach to take depends very much on the goals we want to achieve,
    and the constraints put upon us. The two approaches aren’t entirely the same.
    But if we ever come into a position where we need to decide which approach to
    take, it can be beneficial to use some general attributes to help us determine
    the pros and cons of each.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 采取哪种方法很大程度上取决于我们想要实现的目标，以及施加在我们身上的限制。这两种方法并不完全相同。但如果我们处于需要决定采取哪种方法的位置，使用一些一般属性来帮助我们确定每种方法的优缺点是有益的。
- en: Learning curve
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 学习曲线
- en: Although learning new skills is always relative to a person’s abilities and
    skillsets, for those of us who have followed along with the book so far, getting
    comfortable with RAG frameworks is a smaller learning leap than fine-tuning. It
    can be argued that using a RAG framework is a form of advanced prompt engineering
    and many off-the-shelf tools are available that can be used to jump into using
    RAG with minimum effort.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管学习新技能总是与个人的能力和技能集相关，但对于那些一直跟随本书学习的人来说，熟悉RAG框架的学习跳跃比微调要小。可以认为，使用RAG框架是一种高级提示工程，并且有许多现成的工具可以用来以最小的努力开始使用RAG。
- en: Fine-tuning, however, has a steeper learning curve because it is a collection
    of different actions, tools, and considerations that are much larger in scope
    than using RAG. In the chapter on fine-tuning, you’ll learn different steps to
    take in curating and preparing data for tuning, executing a fine-tuning session,
    and evaluating success. Each part requires knowledge of tools, frameworks, and
    approaches to complete each step. Fortunately, the ecosystem around fine-tuning
    is making the fine-tuning process more accessible and easy to get started with.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，微调的学习曲线更陡峭，因为它是一系列不同的动作、工具和考虑因素，其范围比使用RAG要大得多。在微调章节中，你将学习在准备数据以进行微调、执行微调会话和评估成功时采取的不同步骤。每个部分都需要了解工具、框架和方法来完成每个步骤。幸运的是，微调周围的生态系统正在使微调过程更加易于访问和开始。
- en: Cost
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 成本
- en: 'There are two aspects to cost that we need to consider: tooling and talent.
    As we’ve learned, the learning curve for RAG can be easier than that for fine-tuning.
    This means that the associated costs around training or hiring talent around implementing
    RAG are potentially lesser. As for tooling, the cost to get initially set up with
    RAG can be quite low. However, costs for RAG framework tools and the use of third-party
    LLMs can cause costs to balloon, especially if we are being charged for the number
    of tokens sent and received via an LLM API platform.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要考虑成本的两个方面：工具和人才。正如我们所学的，RAG的学习曲线可能比微调更容易。这意味着围绕实施RAG的培训或雇佣人才的关联成本可能更低。至于工具，RAG框架工具的初始设置成本可能相当低。然而，RAG框架工具和第三方LLMs的使用可能会使成本激增，尤其是如果我们通过LLM
    API平台按发送和接收的令牌数量收费的话。
- en: Unlike the popular RAG frameworks, a lot of fine-tuning tools are open source,
    which can make initial investment in tooling cheaper. Platforms are appearing
    that make the fine-tuning process easier, but they do come at a price. For tooling,
    the cost can be found more in the hardware needed to support fine-tuning. Running
    tuning sessions requires substantial CPU, GPU, and RAM resources, and if we want
    to tune at scale, then more investment is required. There is also the cost of
    hosting a tuned model once it’s ready for use. Finally, as fine-tuning consists
    of a combination of activities, training or hiring can be much more expensive,
    depending on how much detail we want to go into each part of the tuning process.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 与流行的RAG框架不同，许多微调工具是开源的，这可以使工具的初始投资更便宜。出现了一些平台，它们使微调过程更容易，但它们确实有代价。对于工具而言，成本更多地体现在支持微调所需的硬件上。运行微调会话需要大量的CPU、GPU和RAM资源，如果我们想要大规模微调，那么就需要更多的投资。此外，一旦微调模型准备好使用，还需要考虑托管成本。最后，由于微调是由一系列活动组合而成的，因此培训或雇佣的成本可能非常高，这取决于我们想要在每个微调过程部分中达到多少细节。
- en: Speed to production
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 生产速度
- en: 'Given the tools available to support a RAG framework out of the box, getting
    RAG set up and running can be rather fast. When iterating with RAG, the focus
    will be on the following two areas: the prompt we want to send to our LLM (that
    includes the additional data) and the data we want to store and extract relevant
    information from when required. Although there is a lot of space for improvement,
    getting these aspects of a RAG framework set up to an initial satisfactory state
    doesn’t take too much time.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到支持RAG框架的现有工具，RAG的设置和运行可以相当快。当与RAG迭代时，重点将放在以下两个领域：我们想要发送给我们的LLM的提示（包括附加数据）以及我们想要存储并从所需数据中提取相关信息的数据。尽管有很多改进的空间，但将RAG框架的这些方面设置到初始令人满意的状态并不需要太多时间。
- en: Fine-tuning, however, can be relatively slower because there are more activities
    involved. For example, curating and preparing data sets for fine-tuning can be
    a complex activity in its own right. Depending on hardware, fine-tuning can also
    take time to complete with even small tunings taking many hours. Add to this that
    we would likely need to run multiple tunes because we tweak tuning and model settings,
    as well as the data set we are using, so it can take a while before we reach a
    satisfactory tuned model.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，微调可能相对较慢，因为涉及的活动更多。例如，为微调准备数据集本身可能是一项复杂的活动。根据硬件的不同，微调也可能需要时间来完成，即使是小的调整也可能需要数小时。再加上我们可能需要运行多个微调，因为我们调整微调、模型设置以及我们使用的数据集，所以我们可能需要一段时间才能达到一个令人满意的微调模型。
- en: Control
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 控制
- en: Although most of the comparisons so far have been favorable toward RAG frameworks,
    those benefits do have a tradeoff. When we refer to control as a quality characteristic
    of using LLMs, this implies how much influence we have on improving the process,
    what insight we have into how a model is performing, and what control we have
    over the LLM behavior. Also, there are considerations for privacy controls as
    well.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管到目前为止的大多数比较都倾向于RAG框架，但这些好处确实有代价。当我们提到控制作为使用LLMs的质量特征时，这暗示了我们有多大程度的影响力来改进过程，我们对模型性能有多深的洞察，以及我们对LLM行为的控制程度。此外，还需要考虑隐私控制的问题。
- en: Most of the RAG tools available for purchase are hosted on platforms that can
    be quite opaque. This can mean there is less control over how data is stored for
    retrieval or how the relevancy algorithms work. For example, one technology that
    is used in RAG is vector databases. How data is stored and relationships maintained
    in vector databases can be out of our control but have a big influence on what
    relevant data is returned. Add to this that a lot of these tools tend to encourage
    us to use platforms such as OpenAI’s API, then we have even less control over
    which models we want to use and how an LLM will respond.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数可购买的RAG工具都托管在可能相当不透明的平台上。这可能意味着对数据存储和检索方式或相关性算法的控制较少。例如，RAG中使用的一种技术是向量数据库。数据在向量数据库中的存储和关系维护可能超出我们的控制，但这对返回的相关数据有很大影响。再加上许多这些工具倾向于鼓励我们使用像OpenAI的API这样的平台，那么我们对想要使用的模型以及LLM如何响应的控制就更少了。
- en: Fine-tuning is very much about experimentation, which means we must have full
    control over all aspects of how the tuning is done. Because fine-tuning contains
    many steps, we have a lot of control over what happens within each part of the
    process. We have control over what data we want to use and what format it should
    be in, and we can control which type of model we want to tune and how. Furthermore,
    because the result is a tuned model that can be deployed elsewhere, we have a
    lot more control over where a model is deployed and who has access to it, making
    it more suitable for enterprise-based applications.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 微调非常依赖于实验，这意味着我们必须完全控制微调的所有方面。因为微调包含许多步骤，所以我们可以在过程的每个部分都有很多控制权。我们可以控制我们想要使用的数据以及它的格式，我们可以控制我们想要调整的模型类型及其调整方式。此外，因为结果是可以在其他地方部署的调整后的模型，所以我们有更多控制权来决定模型部署的位置以及谁可以访问它，这使得它更适合企业级应用。
- en: These comparisons help us get a flavor of how the two approaches compare, which
    has been summarized in figure 10.4.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这些比较帮助我们了解两种方法的比较，这在图10.4中已总结。
- en: Of course, these comparisons are highly context-dependent, but they do demonstrate
    that RAG can be a faster, more cost-effective approach to take on first. However,
    if we want more control over how we want an LLM to respond, then turning to fine-tuning
    can reward us further if we’re willing to invest.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这些比较高度依赖于上下文，但它们确实表明RAG可以是一个更快、更经济的初步方法。然而，如果我们想要对LLM的响应有更多的控制，那么如果我们愿意投入，转向微调可以给我们带来更多的回报。
- en: 10.2.4 Combining RAG and fine-tuning
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2.4 结合RAG和微调
- en: We’ve explored how these two approaches differ, but before we conclude the chapter,
    it’s worth stating that these two techniques are not mutually exclusive. Given
    that RAG focuses on prompts, whereas fine-tuning focuses on changes to a model,
    both can be combined to further improve responses. The tradeoff is that much more
    complexity is introduced into building, training, and debugging. It is much more
    expensive to bring a tuned model inside a RAG framework to production, and if
    it doesn’t work as expected (or desired), how do we determine what needs our attention?
    This is the challenge of working with indeterministic systems, whether we choose
    to focus on RAG, fine-tuning, or a combination of both. The approach to evaluating
    an LLM’s use as a testing assistant requires constant, healthy skepticism.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经探讨了这两种方法的不同之处，但在我们结束本章之前，值得指出的是，这两种技术并不是相互排斥的。鉴于RAG侧重于提示，而微调侧重于对模型的调整，两者可以结合起来进一步提高响应质量。代价是引入了更多的复杂性，在构建、训练和调试过程中。将调整后的模型引入RAG框架进行生产要昂贵得多，而且如果它没有按预期（或希望）工作，我们如何确定需要我们关注的问题？这是与不确定性系统一起工作的挑战，无论我们选择专注于RAG、微调还是两者的结合。评估LLM作为测试助手的使用方法需要持续的、健康的怀疑态度。
- en: '![](../../OEBPS/Images/CH10_F04_Winteringham2.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../../OEBPS/Images/CH10_F04_Winteringham2.png)'
- en: Figure 10.4 A quick comparison of RAG and fine-tuning
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.4 RAG和微调的快速比较
- en: Summary
  id: totrans-126
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: One of the key challenges of using LLMs is getting them to return context-sensitive,
    valuable results.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用LLM的一个关键挑战是让它们返回上下文相关的、有价值的结果。
- en: To get a well-aligned response, an LLM needs to be given as much relevant context
    as possible.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要获得一个良好对齐的响应，一个大型语言模型（LLM）需要尽可能多地提供相关上下文。
- en: LLMs interpret natural language text by turning text into numbers, known as
    tokens, through the tokenization process.
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM通过将文本转换为称为标记的数字来解释自然语言文本，这一过程称为标记化。
- en: Based on the sophistication of an LLM model and the hardware it is run on, an
    LLM will only be able to take a certain number of tokens at a given time.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据LLM模型复杂性和运行它的硬件，LLM在给定时间内只能接受一定数量的标记。
- en: The number of tokens an LLM can take at a given time is known as the context
    window.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM在给定时间内可以接受的标记数量称为上下文窗口。
- en: Because LLMs have a limited context window, we must come up with different strategies
    to allow us to embed context in without incurring massive costs.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于LLM的上下文窗口有限，我们必须想出不同的策略，以便在不产生巨大成本的情况下嵌入上下文。
- en: Two approaches that can be used to improve context awareness are retrieval-augmented
    generation (RAG) and fine-tuning.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以用来提高上下文感知度的两种方法是检索增强生成（RAG）和微调。
- en: RAG is a process in which additional relevant information is added to a prompt
    to improve an LLM’s response.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAG是一个过程，其中将额外的相关信息添加到提示中，以改善LLM的响应。
- en: RAG works by connecting to a corpus of data and finding the most relevant material
    based on the provided prompt query. It’s then all combined into a single prompt
    for an LLM.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAG通过连接到一个数据语料库，并根据提供的提示查询找到最相关的材料。然后，所有这些材料都被组合成一个用于LLM的单个提示。
- en: Fine-tuning utilizes training techniques to tune an already trained model with
    additional data.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微调利用训练技术使用额外的数据调整已经训练好的模型。
- en: Fine-tuning allows us to modify the tone or detail or way in which an LLM responds.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微调允许我们修改LLM响应的语气、细节或方式。
- en: Fine-tuning can help us promote our context within an LLM’s parameters and make
    it more context-sensitive to our needs.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微调可以帮助我们在LLM的参数中推广我们的上下文，使其对我们的需求更加敏感。
- en: Learning how to utilize RAG frameworks tends to be faster and easier than fine-tuning.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习如何利用RAG框架通常比微调更快、更容易。
- en: Fine-tuning requires knowledge of different processes and tools to carry out
    the full fine-tuning process.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微调需要了解不同的流程和工具来执行完整的微调过程。
- en: Cost of tooling and talent for RAG is relatively lower than that for fine-tuning.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAG的工具和人才成本相对低于微调。
- en: Existing RAG platforms make it easy to get set up and running with RAG.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 现有的RAG平台使得设置和运行RAG变得容易。
- en: Fine-tuning requires more investment in time to get a model ready for production.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微调需要更多的时间投资来使模型准备好生产。
- en: Fine-tuning offers much more control than RAG in terms of the model or framework
    we use at the end.
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与我们最终使用的模型或框架相比，微调比RAG提供了更多的控制。
- en: RAG and fine-tuning can be used together.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RAG和微调可以一起使用。
