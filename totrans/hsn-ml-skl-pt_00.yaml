- en: Preface
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In 2006, Geoffrey Hinton et al. published [a paper](https://homl.info/hinton2006)⁠⁠^([1](preface01.html#id742))
    showing how to train a deep neural network capable of recognizing handwritten
    digits with state-of-the-art precision (>98%). They branded this technique “deep
    learning”. A deep neural network is a (very) simplified model of our cerebral
    cortex, composed of a stack of layers of artificial neurons. Training a deep neural
    net was widely considered impossible at the time,⁠^([2](preface01.html#id744))
    and most researchers had abandoned the idea in the late 1990s. This paper revived
    the interest of the scientific community, and before long many new papers demonstrated
    that deep learning was not only possible, but capable of mind-blowing achievements
    that no other machine learning (ML) technique could hope to match (with the help
    of tremendous computing power and great amounts of data). This enthusiasm soon
    extended to many other areas of machine learning.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'A decade later, machine learning had already conquered many industries, ranking
    web results, recommending videos to watch and products to buy, sorting items on
    production lines, sometimes even driving cars. Machine learning often made the
    headlines, for example when DeepMind’s AlphaFold machine learning system solved
    a long-standing protein-folding problem that had stomped researchers for decades.
    But most of the time, machine learning was just working discretely in the background.
    However, another decade later came the rise of AI assistants: from ChatGPT in
    2022, Gemini, Claude, and Grok in 2023, and many others since then. AI has now
    truly taken off and it is rapidly transforming every single industry: what used
    to be sci-fi is now very real.⁠^([3](preface01.html#id745))'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Machine Learning in Your Projects
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So, naturally you are excited about machine learning and would love to join
    the party! Perhaps you would like to give your homemade robot a brain of its own?
    Make it recognize faces? Or learn to walk around?
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: 'Or maybe your company has tons of data (user logs, financial data, production
    data, machine sensor data, hotline stats, HR reports, etc.), and more than likely
    you could unearth some hidden gems if you just knew where to look. With machine
    learning, you could accomplish the following [and much more](https://homl.info/usecases):'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: Segment customers and find the best marketing strategy for each group.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recommend products for each client based on what similar clients bought.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detect which transactions are likely to be fraudulent.
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Forecast next year’s revenue.
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Predict peak workloads and suggest optimal staffing levels.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build a chatbot to assist your customers.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whatever the reason, you have decided to learn machine learning and implement
    it in your projects. Great idea!
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: Objective and Approach
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This book assumes that you know close to nothing about machine learning. Its
    goal is to give you the concepts, tools, and intuition you need to implement programs
    capable of *learning from data*.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover a large number of techniques, from the simplest and most commonly
    used (such as linear regression) to some of the deep learning techniques that
    regularly win competitions. For this, we will be using Python—the leading language
    for data science and machine learning—as well as open source and production-ready
    Python frameworks:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '[Scikit-Learn](https://scikit-learn.org) is very easy to use, yet it implements
    many machine learning algorithms efficiently, so it makes for a great entry point
    to learning machine learning. It was created by David Cournapeau in 2007, then
    led by a team of researchers at the French Institute for Research in Computer
    Science and Automation (Inria), and recently Probabl.ai.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PyTorch](https://pytorch.org) is a powerful and flexible library for deep
    learning. It makes it possible to train and run all sorts of neural networks efficiently,
    and it can distribute the computations across multiple GPUs (graphics processing
    units). PyTorch (PT) was developed by Facebook’s AI Research lab (FAIR) and first
    released in 2016\. It evolved from Torch, an older framework coded in Lua. In
    2022, PyTorch was transitioned to the PyTorch Foundation, under the Linux Foundation,
    to promote community-driven development.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'We will also use these open source machine learning libraries along the way:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '[XGBoost](https://xgboost.readthedocs.io) in [Chapter 6](ch06.html#ensembles_chapter)
    to implement a powerful technique called *gradient boosting*.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Hugging Face](https://huggingface.co) libraries in Chapters [13](ch13.html#rnn_chapter)
    and [15](ch15.html#transformer_chapter) to download datasets and pretrained models,
    including transformer models. Transformers are incredibly powerful and versatile,
    and they are the main building block of virtually all AI assistants today.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Gymnasium](https://gymnasium.farama.org) in [Chapter 19](ch19.html#rl_chapter)
    for reinforcement learning (i.e., training autonomous agents).'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The book favors a hands-on approach, growing an intuitive understanding of machine
    learning through concrete working examples and just a little bit of theory.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: While you can read this book without picking up your laptop, I highly recommend
    you experiment with the code examples.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: Code Examples
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'All the code examples in this book are open source and available online at
    [*https://github.com/ageron/handson-mlp*](https://github.com/ageron/handson-mlp),
    as Jupyter notebooks. These are interactive documents containing text, images,
    and executable code snippets (Python in our case). The easiest and quickest way
    to get started is to run these notebooks using Google Colab: this is a free service
    that allows you to run any Jupyter notebook directly online without having to
    install anything on your machine. All you need is a web browser and a Google account.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-27
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In this book, I will assume that you are using Google Colab, but I have also
    tested the notebooks on other online platforms such as Kaggle and Binder, so you
    can use those if you prefer. Alternatively, you can install the required libraries
    and tools (or the Docker image for this book) and run the notebooks directly on
    your own machine. See the instructions at [*https://homl.info/install-p*](https://homl.info/install-p).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我将假设你正在使用Google Colab，但我已经测试了其他在线平台上的笔记本，例如Kaggle和Binder，所以如果你更喜欢这些，你也可以使用它们。或者，你可以安装所需的库和工具（或本书的Docker镜像）并在自己的机器上直接运行笔记本。请参阅[*https://homl.info/install-p*](https://homl.info/install-p)中的说明。
- en: This book is here to help you get your job done. If you wish to use additional
    content beyond the code examples, and that use falls outside the scope of fair
    use guidelines, (such as selling or distributing content from O’Reilly books,
    or incorporating a significant amount of material from this book into your product’s
    documentation), please reach out to O’Reilly for permission, at [*permissions@oreilly.com*](mailto:permissions@oreilly.com).
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书旨在帮助你完成工作。如果你希望使用超出代码示例的额外内容，并且这种使用超出了合理使用指南的范围（例如，销售或分发O’Reilly书籍的内容，或者将本书的大量内容纳入你的产品文档中），请联系O’Reilly获取许可，邮箱为[*permissions@oreilly.com*](mailto:permissions@oreilly.com)。
- en: 'We appreciate, but generally do not require, attribution. An attribution usually
    includes the title, author, publisher, and ISBN. For example: “*Hands-On Machine
    Learning with Scikit-Learn and PyTorch* by Aurélien Geron. Copyright 2026 Aurélien
    Geron, 979-8-341-60798-9.”'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢，但通常不需要署名。署名通常包括标题、作者、出版社和ISBN。例如：“*《使用Scikit-Learn和PyTorch动手学习机器学习》* 作者：Aurélien
    Geron。版权所有2026年Aurélien Geron，979-8-341-60798-9。”
- en: Prerequisites
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 前置条件
- en: This book assumes that you have some Python programming experience. If you don’t
    know Python yet, [*https://learnpython.org*](https://learnpython.org) is a great
    place to start. The official tutorial on [Python.org](https://docs.python.org/3/tutorial)
    is also quite good.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 本书假设你有一些Python编程经验。如果你还不了解Python，[*https://learnpython.org*](https://learnpython.org)是一个很好的起点。Python.org上的官方教程[Python.org](https://docs.python.org/3/tutorial)也非常不错。
- en: This book also assumes that you are familiar with Python’s main scientific libraries—in
    particular, [NumPy](https://numpy.org), [pandas](https://pandas.pydata.org), and
    [Matplotlib](https://matplotlib.org). If you have never used these libraries,
    don’t worry; they’re easy to learn, and I’ve created a tutorial for each of them.
    You can access them online at [*https://homl.info/tutorials-p*](https://homl.info/tutorials-p).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 本书还假设你熟悉Python的主要科学库——特别是[NumPy](https://numpy.org)、[pandas](https://pandas.pydata.org)和[Matplotlib](https://matplotlib.org)。如果你从未使用过这些库，不要担心；它们很容易学习，我为每个库都创建了一个教程。你可以在[*https://homl.info/tutorials-p*](https://homl.info/tutorials-p)在线访问它们。
- en: Moreover, if you want to fully understand how the machine learning algorithms
    work (not just how to use them), then you should have at least a basic understanding
    of a few math concepts, especially linear algebra. Specifically, you should know
    what vectors and matrices are, and how to perform some simple operations like
    adding vectors, or transposing and multiplying matrices. If you need a quick introduction
    to linear algebra (it’s really not rocket science!), I provide a tutorial at [*https://homl.info/tutorials-p*](https://homl.info/tutorials-p).
    You will also find a tutorial on differential calculus, which may be helpful to
    understand how neural networks are trained, but it’s not entirely essential to
    grasp the important concepts. This book also uses other mathematical concepts
    occasionally, such as exponentials and logarithms, a bit of probability theory,
    and some basic concepts from statistics, but nothing too advanced. If you need
    help on any of these, please check out [*https://khanacademy.org*](https://khanacademy.org),
    which offers many excellent and free math courses online.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果你想全面理解机器学习算法是如何工作的（而不仅仅是如何使用它们），那么你应该至少对几个数学概念有基本的了解，特别是线性代数。具体来说，你应该知道什么是向量矩阵，以及如何执行一些简单的操作，比如向量相加，或者矩阵转置和乘法。如果你需要快速了解线性代数（这真的不是火箭科学！），我在[*https://homl.info/tutorials-p*](https://homl.info/tutorials-p)提供了一个教程。你还会找到一个关于微分学的教程，这可能有助于理解神经网络是如何训练的，但这不是掌握重要概念所必需的。本书偶尔也会使用其他数学概念，例如指数和对数，一点概率理论，以及一些基本的统计学概念，但都不是太高级。如果你需要这方面的帮助，请查看[*https://khanacademy.org*](https://khanacademy.org)，它提供了许多优秀且免费的在线数学课程。
- en: Roadmap
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 路线图
- en: 'This book is organized in two parts. [Part I, “The Fundamentals of Machine
    Learning”](part01.html#fundamentals_part), covers the following topics:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: What machine learning is, what problems it tries to solve, and the main categories
    and fundamental concepts of its systems
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The steps in a typical machine learning project
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning by fitting a model to data
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Minimizing a cost function (i.e., a measure of prediction errors)
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling, cleaning, and preparing data
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selecting and engineering features (i.e., data fields)
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selecting a model and tuning hyperparameters using cross-validation (e.g., training
    many model variants and choosing the one that performs best on data it didn’t
    see during training)
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The challenges of machine learning, in particular underfitting and overfitting
    (the bias/variance trade-off)
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The most common learning algorithms: linear and polynomial regression, logistic
    regression, *k*-nearest neighbors, decision trees, random forests, and ensemble
    methods'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reducing the dimensionality of the training data to fight the “curse of dimensionality”
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other unsupervised learning techniques, including clustering, density estimation,
    and anomaly detection
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Part II, “Neural Networks and Deep Learning”](part02.html#neural_nets_part),
    covers the following topics:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: What neural nets are and what they’re good for
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building and training deep neural nets using PyTorch
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The most important neural net architectures: feedforward neural nets for tabular
    data; convolutional nets for computer vision; recurrent nets and long short-term
    memory (LSTM) nets for sequence processing; encoder-decoders, transformers, state
    space models (SSMs), and hybrid architectures for natural language processing,
    vision, and more; autoencoders, generative adversarial networks (GANs), and diffusion
    models for generative learning'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to build an agent (e.g., a bot in a game) that can learn good strategies
    through trial and error, using reinforcement learning
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loading and preprocessing large amounts of data efficiently
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first part is based mostly on Scikit-Learn; the second part uses mostly
    PyTorch.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: Caution
  id: totrans-55
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Don’t jump into deep waters too hastily: deep learning is no doubt one of the
    most exciting areas in machine learning, but you should master the fundamentals
    first. Moreover, many problems can be solved quite well using simpler techniques
    such as random forests and ensemble methods (discussed in [Part I](part01.html#fundamentals_part)).
    Deep learning is best suited for complex problems such as image recognition, speech
    recognition, or natural language processing, and it often requires a lot of data,
    computing power, and patience (unless you can leverage a pretrained neural network,
    as you will see).'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: If you are particularly interested in one topic and want to reach it as quickly
    as possible, [Figure P-1](#chapter_dependencies_diagram) will show you which chapters
    you must read first, and which ones you can safely skip.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '![Diagram illustrating the dependencies between chapters in a machine learning
    book, showing which chapters must be read first before others.](assets/hmls_0001.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
- en: Figure P-1\. Chapter dependencies
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Changes Between the TensorFlow and PyTorch Versions
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'I wrote three TensorFlow (TF) editions of this book, published by O’Reilly
    in 2017, 2019, and 2022\. TF was the leading deep learning library for many years,
    used internally by Google and therefore optimized for production at scale. But
    PyTorch has gradually taken the lead, owing to its simplicity, flexibility and
    openness: it now dominates research papers and open source projects, which means
    that most new models are available in PyTorch first. As a result, the industry
    has also gradually shifted toward PyTorch.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: In recent years, Google has reduced its investments in TensorFlow, and focused
    more on JAX, another excellent deep learning library with a great mix of qualities
    for both research and production. However, its adoption is still low compared
    to PyTorch.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: This is why I chose to use PyTorch this time around! O’Reilly and I decided
    to make it the first edition of a new PyTorch series rather than the fourth edition
    of the original series. This leaves the door open for a JAX series or perhaps
    a new edition for the TF series (time will tell if either are needed).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have already read the latest TensorFlow version of this book, here are
    the main changes you will find in this book (see [*https://homl.info/changes-p*](https://homl.info/changes-p)
    for more details):'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: All the code in the book was updated to recent library versions.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All the code in [Part II](part02.html#neural_nets_part) was migrated from TensorFlow
    and Keras to PyTorch. There were significant changes in all of these chapters.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TensorFlow-specific content was removed, including former Chapters 12 and 13,
    and former Appendices C and D.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 10](ch10.html#pytorch_chapter) now introduces PyTorch.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'I also added three new chapters on transformers:'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 15](ch15.html#transformer_chapter) covers transformers for natural
    language processing, including how to build a chatbot.'
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 16](ch16.html#vit_chapter) presents vision transformers and multimodal
    transformers.'
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Chapter 17](ch17.html#speedup_chapter), available online at [*https://homl.info/*](https://homl.info/),
    discusses several advanced techniques to speed up and scale up transformers. This
    includes FlashAttention, mixture of experts (MoE), low-rank adaptation (LoRA),
    and many more.'
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are also three new appendices: [Appendix B](app02.html#precision_appendix)
    explains how to shrink models so they can run faster and fit on smaller devices,
    “Relative Positional Encoding” discusses advanced positional encoding techniques
    for transformers, and “State-Space Models (SSMs)” presents state-space models.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To make room for the newer content, the chapter on support vector machines (SVMs)
    was [moved online](https://homl.info) and renamed “Support Vector Machines”; the
    last two appendices are also online at the same URL, and the deployment chapter
    was partially merged into [Chapter 10](ch10.html#pytorch_chapter).
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了为新内容腾出空间，关于支持向量机（SVMs）的章节已被[移至线上](https://homl.info)并更名为“支持向量机”；最后两个附录也位于同一网址，部署章节部分合并到了[第10章](ch10.html#pytorch_chapter)。
- en: The three editions of the TensorFlow/Keras version of this book are nicknamed
    homl1, homl2, and homl3\. This book, which is the first edition of the PyTorch
    version, is nicknamed homlp. Try saying that three times in a row.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书的TensorFlow/Keras版本有三个版本，分别被称为homl1、homl2和homl3。这是PyTorch版本的第一个版本，被称为homlp。试着连续说三次。
- en: Note
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: 'Most of the changes compared to the latest TensorFlow edition are in the second
    part of the book. If you have read homl3, then don’t expect big changes in the
    first part of the book: the fundamental concepts of machine learning haven’t changed
    since 2022.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 与最新版本的TensorFlow相比，大部分变化都在书的第二部分。如果你已经阅读了homl3，那么不要期待书中第一部分有大的变化：自2022年以来，机器学习的基本概念没有变化。
- en: Other Resources
  id: totrans-78
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他资源
- en: Many excellent resources are available to learn about machine learning. For
    example, Andrew Ng’s [ML course on Coursera](https://homl.info/ngcourse) is amazing,
    although it requires a significant time investment.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多优秀的资源可以学习机器学习。例如，安德鲁·吴在Coursera上的[ML课程](https://homl.info/ngcourse)非常出色，尽管它需要大量的时间投入。
- en: There are also many interesting websites about machine learning, including Scikit-Learn’s
    exceptional [User Guide](https://homl.info/skdoc). You may also enjoy [Dataquest](https://dataquest.io),
    which provides very nice interactive tutorials, and countless ML blogs and YouTube
    channels.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 还有许多关于机器学习的有趣网站，包括Scikit-Learn的杰出[用户指南](https://homl.info/skdoc)。你也许也会喜欢[Dataquest](https://dataquest.io)，它提供了非常棒的交互式教程，以及无数的机器学习博客和YouTube频道。
- en: 'There are many other introductory books about machine learning. In particular:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多关于机器学习的入门书籍。特别是：
- en: Joel Grus’s [*Data Science from Scratch*](https://homl.info/grusbook), 2nd edition
    (O’Reilly), presents the fundamentals of machine learning and implements some
    of the main algorithms in pure Python (from scratch, as the name suggests).
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 乔尔·格鲁斯的[*《从零开始的数据科学》*](https://homl.info/grusbook)，第2版（O'Reilly），介绍了机器学习的基础知识，并使用纯Python（从头开始，正如书名所示）实现了一些主要算法。
- en: 'Stephen Marsland’s *Machine Learning: An Algorithmic Perspective*, 2nd edition
    (Chapman & Hall), is a great introduction to machine learning, covering a wide
    range of topics in depth with code examples in Python (also from scratch, but
    using NumPy).'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 史蒂芬·马尔斯兰德的*《机器学习：算法视角》*，第2版（Chapman & Hall），是机器学习的优秀入门书籍，深入探讨了广泛的主题，并使用Python（也是从头开始，但使用NumPy）提供了代码示例。
- en: Sebastian Raschka’s *Machine Learning with PyTorch and Scikit-Learn*, 1st edition
    (Packt Publishing), is also a great introduction to machine learning using Scikit-Learn
    and PyTorch.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 塞巴斯蒂安·拉斯奇卡的*《使用PyTorch和Scikit-Learn进行机器学习》*，第1版（Packt Publishing），也是使用Scikit-Learn和PyTorch进行机器学习的优秀入门书籍。
- en: François Chollet’s *Deep Learning with Python*, 3rd edition (Manning), is a
    very practical book that covers a large range of topics in a clear and concise
    way, as you might expect from the author of the excellent Keras library. It favors
    code examples over mathematical theory.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 弗朗索瓦·肖莱特的*《用Python进行深度学习》*，第3版（Manning），是一本非常实用的书籍，以清晰简洁的方式涵盖了广泛的主题，正如你从优秀的Keras库的作者那里所期望的那样。它更倾向于代码示例而不是数学理论。
- en: Andriy Burkov’s [*The Hundred-Page Machine Learning Book*](https://themlbook.com)
    (self-published) is very short but covers an impressive range of topics, introducing
    them in approachable terms without shying away from the math equations.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安德烈·布尔科夫的[*《百页机器学习书》*](https://themlbook.com)（自出版）非常简短，但涵盖了令人印象深刻的主题范围，以易于理解的方式介绍了这些主题，并没有回避数学方程式。
- en: Yaser S. Abu-Mostafa, Malik Magdon-Ismail, and Hsuan-Tien Lin’s *Learning from
    Data* (AMLBook) is a more theoretical approach to ML that provides deep insights,
    in particular on the bias/variance trade-off (see [Chapter 4](ch04.html#linear_models_chapter)).
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 亚瑟·S·阿布-穆斯塔法、马利克·马戈德-伊斯拉伊尔和许安-天林的*《从数据中学习》*（AMLBook）是ML的一种更理论的方法，提供了深刻的见解，特别是在偏差/方差权衡方面（见[第4章](ch04.html#linear_models_chapter)）。
- en: 'Stuart Russell and Peter Norvig’s *Artificial Intelligence: A Modern Approach*,
    4th edition (Pearson), is a great (and huge) book covering an incredible amount
    of topics, including machine learning. It helps put ML into perspective.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stuart Russell 和 Peter Norvig 的 *《人工智能：现代方法》* 第四版 (Pearson) 是一本涵盖大量主题（包括机器学习）的伟大（且庞大）的书籍。它有助于将机器学习置于正确的视角。
- en: Jeremy Howard and Sylvain Gugger’s [*Deep Learning for Coders with fastai and
    PyTorch*](https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/)
    (O’Reilly) provides a wonderfully clear and practical introduction to deep learning
    using the fastai and PyTorch libraries.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jeremy Howard 和 Sylvain Gugger 的 [*《使用 fastai 和 PyTorch 的编码者深度学习》*](https://learning.oreilly.com/library/view/deep-learning-for/9781492045519/)
    (O’Reilly) 提供了一个清晰且实用的深度学习入门介绍，使用了 fastai 和 PyTorch 库。
- en: Andrew Ng’s *Machine Learning Yearning* is a free ebook that provides a thoughtful
    exploration of machine learning, focusing on the practical considerations of building
    and deploying models, including data quality and long-term maintenance.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Andrew Ng 的 *《机器学习求索》* 是一本免费的电子书，深入思考了机器学习，重点关注构建和部署模型的实际考虑因素，包括数据质量和长期维护。
- en: 'Lewis Tunstall, Leandro von Werra, and Thomas Wolf’s [*Natural Language Processing
    with Transformers: Building Language Applications with Hugging Face*](https://learning.oreilly.com/library/view/natural-language-processing/9781098136789/)
    (O’Reilly) is a great practical dive into transformers using popular libraries
    by Hugging Face.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lewis Tunstall、Leandro von Werra 和 Thomas Wolf 的 [*《使用 Hugging Face 的 Transformer
    自然语言处理：构建语言应用》*](https://learning.oreilly.com/library/view/natural-language-processing/9781098136789/)
    (O’Reilly) 是一个关于使用 Hugging Face 流行库的 Transformer 的实用深入探讨。
- en: Jay Alammar and Maarten Grootendorst’s *Hands-On Large Language Models* is a
    beautifully illustrated book on LLMs, covering everything you need to know to
    understand, train, fine-tune, and use LLMs across a wide variety of tasks.
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jay Alammar 和 Maarten Grootendorst 的 *《动手学习大型语言模型》* 是一本关于 LLM 的精美插图书籍，涵盖了理解、训练、微调和使用
    LLM 在各种任务中的所有必要知识。
- en: Finally, joining ML competition websites such as [Kaggle.com](https://kaggle.com)
    will allow you to practice your skills on real-world problems, with help and insights
    from some of the best ML professionals out there.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，加入像 [Kaggle.com](https://kaggle.com) 这样的机器学习竞赛网站，将允许你在真实世界的问题上练习你的技能，并获得一些最好的机器学习专业人士的帮助和见解。
- en: Conventions Used in This Book
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 本书使用的约定
- en: 'The following typographical conventions are used in this book:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 本书使用的排版约定：
- en: '*Italic*'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '*斜体*'
- en: Indicates new terms, URLs, email addresses, filenames, and file extensions.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 表示新术语、URL、电子邮件地址、文件名和文件扩展名。
- en: '`Constant width`'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '`常宽`'
- en: Used for program listings, as well as within paragraphs to refer to program
    elements such as variable or function names, databases, data types, environment
    variables, statements, and keywords.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 用于程序列表，以及段落中引用程序元素，如变量或函数名称、数据库、数据类型、环境变量、语句和关键字。
- en: '**`Constant width bold`**'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**`常宽粗体`**'
- en: Shows commands or other text that should be typed literally by the user.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 显示用户应逐字输入的命令或其他文本。
- en: '*`Constant width italic`*'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '*`常宽斜体`*'
- en: Shows text that should be replaced with user-supplied values or by values determined
    by context.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 显示应替换为用户提供的值或由上下文确定的值的文本。
- en: Punctuation
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 标点符号
- en: To avoid any confusion, punctuation appears outside of quotes throughout the
    book. My apologies to the purists.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免任何混淆，本书中所有引号外的标点符号都位于引号之外。对那些讲究的人士表示歉意。
- en: Tip
  id: totrans-106
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: This element signifies a tip or suggestion.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示提示或建议。
- en: Note
  id: totrans-108
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注释
- en: This element signifies a general note.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示一般注释。
- en: Warning
  id: totrans-110
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: This element indicates a warning or caution.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 此元素表示警告或注意事项。
- en: O’Reilly Online Learning
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: O’Reilly 在线学习
- en: Note
  id: totrans-113
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注释
- en: For more than 40 years, [*O’Reilly Media*](https://oreilly.com) has provided
    technology and business training, knowledge, and insight to help companies succeed.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 超过 40 年来，[*O’Reilly 媒体*](https://oreilly.com) 为公司提供技术培训和业务培训、知识和见解，以帮助公司成功。
- en: Our unique network of experts and innovators share their knowledge and expertise
    through books, articles, and our online learning platform. O’Reilly’s online learning
    platform gives you on-demand access to live training courses, in-depth learning
    paths, interactive coding environments, and a vast collection of text and video
    from O’Reilly and 200+ other publishers. For more information, visit [*https://oreilly.com*](https://oreilly.com).
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们独特的专家和创新者网络通过书籍、文章和我们的在线学习平台分享他们的知识和专业知识。O’Reilly的在线学习平台为您提供按需访问实时培训课程、深入的学习路径、交互式编码环境以及来自O’Reilly和200多家其他出版商的大量文本和视频。更多信息，请访问[*https://oreilly.com*](https://oreilly.com)。
- en: How to Contact Us
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何联系我们
- en: 'Please address comments and questions concerning this book to the publisher:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 请将有关本书的评论和问题寄给出版社：
- en: O’Reilly Media, Inc.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: O’Reilly Media, Inc.
- en: 141 Stony Circle, Suite 195
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 141 Stony Circle, Suite 195
- en: Santa Rosa, CA 95401
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Santa Rosa, CA 95401
- en: 800-889-8969 (in the United States or Canada)
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 800-889-8969（在美国或加拿大）
- en: 707-827-7019 (international or local)
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 707-827-7019（国际或本地）
- en: 707-829-0104 (fax)
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 707-829-0104（传真）
- en: '[*support@oreilly.com*](mailto:support@oreilly.com)'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*support@oreilly.com*](mailto:support@oreilly.com)'
- en: '[*https://oreilly.com/about/contact.html*](https://oreilly.com/about/contact.html)'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*https://oreilly.com/about/contact.html*](https://oreilly.com/about/contact.html)'
- en: We have a web page for this book, where we list errata, examples, and any additional
    information. You can access this page at [*https://oreil.ly/hands-on-machine-learning*](https://oreil.ly/hands-on-machine-learning).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为这本书有一个网页，上面列出了勘误、示例和任何其他附加信息。您可以通过[*https://oreil.ly/hands-on-machine-learning*](https://oreil.ly/hands-on-machine-learning)访问此页面。
- en: For news and information about our books and courses, visit [*https://oreilly.com*](https://oreilly.com).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 想了解我们书籍和课程的新闻和信息，请访问[*https://oreilly.com*](https://oreilly.com)。
- en: 'Find us on LinkedIn: [*https://linkedin.com/company/oreilly-media*](https://linkedin.com/company/oreilly-media)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在LinkedIn上找到我们：[*https://linkedin.com/company/oreilly-media*](https://linkedin.com/company/oreilly-media)
- en: 'Watch us on YouTube: [*https://youtube.com/oreillymedia*](https://youtube.com/oreillymedia)'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在YouTube上关注我们：[*https://youtube.com/oreillymedia*](https://youtube.com/oreillymedia)
- en: Acknowledgments
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 致谢
- en: Never in my wildest dreams did I imagine that the three TensorFlow editions
    of this book would reach such a large audience. I received so many messages from
    readers, many asking questions, some kindly pointing out errata, and most sending
    me encouraging words. I cannot express how grateful I am to all these readers
    for their tremendous support. Thank you all so very much! Please do not hesitate
    to [file issues on GitHub](https://homl.info/issues-p) if you find errors in the
    code examples (or just to ask questions), or to submit [errata](https://homl.info/errata-p)
    if you find errors in the text. Some readers also shared how this book helped
    them get their first job, or how it helped them solve a concrete problem they
    were working on. I find such feedback incredibly motivating. If you find this
    book helpful, I would love it if you could share your story with me, either privately
    (e.g., via [LinkedIn](https://linkedin.com/in/aurelien-geron)) or publicly (e.g.,
    tweet me at @aureliengeron or write an [Amazon review](https://homl.info/amazon-p)).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在我梦寐以求的时刻，我也没想到这本书的三个TensorFlow版本能吸引如此庞大的读者群。我收到了许多读者的消息，许多人提问，有些人友好地指出错误，大多数人给我送来了鼓励的话语。我无法表达我对所有这些读者巨大支持的感激之情。非常感谢大家！如果您在代码示例中找到错误（或只是想提问），请毫不犹豫地[在GitHub上提交问题](https://homl.info/issues-p)，或者如果您在文本中找到错误，请提交[勘误](https://homl.info/errata-p)。一些读者还分享了这本书如何帮助他们找到第一份工作，或者如何帮助他们解决他们正在工作的具体问题。我发现这样的反馈非常鼓舞人心。如果您觉得这本书有用，我非常希望您能与我分享您的经历，无论是私下（例如，通过[LinkedIn](https://linkedin.com/in/aurelien-geron)）还是公开（例如，在@aureliengeron上发推文或写[Amazon评论](https://homl.info/amazon-p))）。
- en: 'Huge thanks as well to all the generous people who offered their time and expertise
    to review this book, correcting errors and making countless suggestions. They
    made this book so much better: Jeremy Howard, Haesun Park, Omar Sanseviero, Lewis
    Tunstall, Leandro Von Werra, and Sam Witteveen reviewed the table of contents
    and helped me refine the scope of the book. Hesam Hassani, Ashu Jha, Meetu Malhotra,
    and Ammar Mohanna reviewed the first part, while Ulf Bissbort, Louis-Francois
    Bouchard, Luba Elliot, Thomas Lacombe, Tarun Narayanan, Marco Tabor, and my dear
    brother Sylvain reviewed the second part. Special thanks to Haesun Park, who reviewed
    every single chapter. You are all amazing!'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: Of course, this book would not exist without the fantastic staff at O’Reilly.
    I am especially indebted to Michele Cronin, who reviewed every chapter and supported
    me weekly for a whole year. I am also deeply grateful to Nicole Butterfield for
    leading this project and helping refine the book’s scope, and to the production
    team—particularly Beth Kelly and Kristen Brown—who did a remarkable job. I want
    to acknowledge Sonia Saruba for her countless careful copyedits, Kate Dullea for
    making my diagrams much prettier, and Susan Thompson for the beautiful orangutan
    on the cover.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'Last but not least, I am infinitely grateful to my beloved wife, Emmanuelle,
    and to our three wonderful children—Alexandre, Rémi, and Gabrielle—for encouraging
    me to work so hard on this book. Their insatiable curiosity was priceless: explaining
    some of the most difficult concepts in this book to my wife and children helped
    me clarify my own thoughts and directly improved many parts of it. Plus, they
    kept bringing me cookies and coffee. Who could ask for more?'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '^([1](preface01.html#id742-marker)) Geoffrey E. Hinton et al., “A Fast Learning
    Algorithm for Deep Belief Nets”, *Neural Computation* 18 (2006): 1527–1554.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: ^([2](preface01.html#id744-marker)) Despite the fact that Yann LeCun’s deep
    convolutional neural networks had worked well for image recognition since the
    1990s, although they were not as general-purpose.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: ^([3](preface01.html#id745-marker)) Geoffrey Hinton was awarded the 2018 Turing
    Award (with Yann LeCun and Yoshua Bengio) and the 2024 Nobel Prize in Physics
    (with John Hopfield) for early work on neural networks back in the 1980s. DeepMind’s
    founder and CEO Demis Hassabis and director John Jumper were awarded the 2024
    Nobel Prize in Chemistry for their work on AlphaFold. They shared this Nobel Prize
    with another protein researcher, David Baker.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
