<html><head></head><body>
  <div class="readable-text" id="p1"> 
   <h1 class=" readable-text-h1" id="chp__what_is_gpt"> <span class="chapter-title-numbering"><span class="num-string">1</span></span> <span class="title-text"> Big picture: What are LLMs?</span> </h1> 
  </div> 
  <div class="introduction-summary"> 
   <h3 class="introduction-header">This chapter covers</h3> 
   <ul> 
    <li class="readable-text" id="p2">What Generative Pretrained Transformers and large language models are</li> 
    <li class="readable-text" id="p3">How LLMs work in plain language </li> 
    <li class="readable-text" id="p4">How humans and machines represent languages differently </li> 
    <li class="readable-text" id="p5">Why tools like ChatGPT perform so well</li> 
    <li class="readable-text" id="p6">Understanding the limitations and concerns of using LLMs </li> 
   </ul> 
  </div> 
  <div class="readable-text" id="p7"> 
   <p>The hype around terms such as machine learning (ML), deep learning (DL), and artificial intelligence (AI) has reached record levels. Much of the initial public exposure to these terms was driven by a product called ChatGPT, a form of generative AI built by a company called OpenAI. We now see generative AI offerings such as Gemini from Google, Copilot from Microsoft, Llama from Meta, Claude from Anthropic, and newcomers like DeepSeek in the daily news. Seemingly overnight, the ability of computers to talk, learn, and perform complex tasks has taken a dramatic leap forward. New generative AI companies are forming, and existing firms are publicly investing billions of dollars in the field. The technology in this space is evolving at a maddening pace.</p> 
  </div> 
  <div class="readable-text" id="p8"> 
   <p>This book aims to help you make sense of this new world by dispelling the mystery behind what makes ChatGPT and related technologies work. We will cover the knowledge necessary to understand their inner workings and how the components (data and algorithms) stack together to create the tools we use. We’ll also discuss various cases where this technology can form the cornerstone of a broader system and others where systems based on large language models (LLMs) may be a poor choice.</p> 
  </div> 
  <div class="readable-text" id="p9"> 
   <p>After reading this book, you’ll understand what generative AI like ChatGPT really <em>is</em>, what it can and can’t do, and, importantly, the “why” behind its limitations. With this knowledge, you’ll be a more effective consumer of this family of technology, whether as a user, a software developer, or a business decision maker in organizations deciding whether and, if so, how to incorporate it into your products or operations. This foundation will also serve as a launchpad for deeper study into the field by providing knowledge that will allow you to understand in-depth research and other works.</p> 
  </div> 
  <div class="readable-text" id="p10"> 
   <h2 class=" readable-text-h2" id="generative-ai-in-context"><span class="num-string browsable-reference-id">1.1</span> Generative AI in context</h2> 
  </div> 
  <div class="readable-text" id="p11"> 
   <p>First, we need to get more specific about what we are discussing when we talk about LLMs, GPTs, and the various tools that rely on them. The GPT in ChatGPT stands for <em>Generative Pretrained Transformer</em>. Each of these words bears a particular meaning in the context of ChatGPT. We’ll dedicate future chapters to discussing what <em>pretrained</em> and <em>transformer</em> mean, but we start here by discussing what <em>generative</em> means in this context. </p> 
  </div> 
  <div class="readable-text" id="p12"> 
   <p>AI chatbots like ChatGPT are a form of <em>generative</em> AI. Broadly, generative AI is software capable of creating, or generating, various media (e.g., text, images, audio, and video) based on data it has observed in the past and influenced by what people consider to be pleasing and accurate output. For example, if ChatGPT is prompted with “Write a haiku about snow falling on pines,” it will use all of the data it was trained with about haikus, snow, pines, and other forms of poetry to generate a novel haiku as shown in figure <a href="#fig__gptHaiku">1.1</a></p> 
  </div> 
  <div class="browsable-container figure-container" id="p13">  
   <img alt="figure" src="../Images/CH01_F01_Boozallen.png"/> 
   <h5 class=" figure-container-h5" id="fig__gptHaiku"><span class="num-string">Figure <span class="browsable-reference-id">1.1</span></span> A simple haiku generated by ChatGPT</h5>
  </div> 
  <div class="readable-text" id="p14"> 
   <p>Fundamentally, these systems are machine learning models that <em>generate</em> new output, so generative AI is an appropriate description. Some possible inputs and outputs are demonstrated in figure <a href="#fig__whatIsGenerativeAI">1.2</a>. While ChatGPT deals primarily with text as input and output, it also has more experimental support for different data types, such as audio and images. However, from our definition, you can imagine that many different kinds of algorithms and tasks fall into the description of generative AI. </p> 
  </div> 
  <div class="browsable-container figure-container" id="p15">  
   <img alt="figure" src="../Images/CH01_F02_Boozallen.png"/> 
   <h5 class=" figure-container-h5" id="fig__whatIsGenerativeAI"><span class="num-string">Figure <span class="browsable-reference-id">1.2</span></span> Generative AI takes some input (numbers, text, images) and produces a new output (usually text or images). Any combination of input or output options is possible, and the nature of the output depends on what the algorithm was trained for. It could be to add detail, rewrite something to be shorter, extrapolate missing portions, and more. </h5>
  </div> 
  <div class="readable-text" id="p16"> 
   <p>Going a level deeper, ChatGPT is dealing with human text, and so it would also be fair to call it a model of human language—or a <em>language model</em> if you are a cool person who does work in the field known as <em>natural language processing</em> (NLP). The field of NLP intersects both computer science and linguistics and explores the technology that helps computers understand, manipulate, and create human language. Some of the first efforts in the field of NLP emerged in the 1940s when researchers hoped to build machines that could automatically translate between languages. As a result, NLP and language models have been around for a very long time. So what makes the new generative AI tools different? The most salient difference is that ChatGPT and similar algorithms are much larger than what people have historically built and are trained on much greater amounts of data. </p> 
  </div> 
  <div class="readable-text" id="p17"> 
   <p>For this reason, the name <em>large language models</em> (LLMs) has become quite popular to describe GPT and similar types of machine learning models. GPT describes a specific type of LLM developed by OpenAI, and other companies use similar technologies to build their own LLMs and AI chatbots. More broadly, LLMs are machine learning models trained on large amounts of linguistic data.</p> 
  </div> 
  <div class="readable-text" id="p18"> 
   <p>A diagram of these relationships can be seen in figure <a href="#fig__what_is_generative_heiarchy">1.3</a>. ChatGPT, Copilot, Claude, and Gemini are some of the products that operate via text and are built using LLMs. LLMs use techniques from AI and NLP. The primary component of an LLM is a transformer, which we will explain in detail in chapter 3.</p> 
  </div> 
  <div class="browsable-container figure-container" id="p19">  
   <img alt="figure" src="../Images/CH01_F03_Boozallen.png"/> 
   <h5 class=" figure-container-h5" id="fig__what_is_generative_heiarchy"><span class="num-string">Figure <span class="browsable-reference-id">1.3</span></span> A high-level map of the various terms you’ll become familiar with and how they relate. Generative AI is a description of functionality: the function of generating content and using tech- niques from AI to accomplish that goal.</h5>
  </div> 
  <div class="readable-text print-book-callout" id="p20"> 
   <p> <span class="print-book-callout-head">Note</span> Vision and language are not the only options for generative AI. Audio generation (think text-to-speech, such as when your GPS speaks out the street names), playing board games like chess, and even protein folding have used generative AI. This book will stick mostly to text and language since those are the primary data types employed by GPTs and LLMs. </p> 
  </div> 
  <div class="readable-text" id="p21"> 
   <p>As the name <em>large</em> implies, these models are not small. ChatGPT specifically is rumored [1] to contain 1.76 trillion parameters that are used to dictate the way it behaves. Each parameter is typically stored as a floating point number (a number with a decimal point) that uses 4 bytes for storage. That means the model itself takes 7 terabytes to hold in memory. This size is larger than most people’s computers could fit in RAM, let alone inside the most powerful graphics processing units (GPUs) with 80 gigabytes of memory. GPUs are special-purpose hardware components that excel in performing the mathematical operations that make LLMs possible. Currently, many GPUs are required when making LLMs, so we are already discussing a lot of computational infrastructure and complexity over multiple machines to build an LLM. In contrast, more run-of-the-mill language models would be 2 GB or less in most cases—over 5,000<span><img alt="equation image" src="../Images/eq-chapter-1-21-1.png"/></span> smaller, a much more reasonable size when considering building and using such a model on more standard hardware.</p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p22"> 
    <h5 class=" callout-container-h5 readable-text-h5">Optimizing LLMs</h5> 
   </div> 
   <div class="readable-text" id="p23"> 
    <p> Many researchers are investigating ways to make LLMs consume less memory. Sometimes, this includes techniques that require less than 4 bytes to store a parameter utilizing a method called “mixed-precision” [2]. This approach stores some LLM parameters using 2 bytes or fewer and presents a tradeoff between accuracy and memory efficiency. In the end, the effect on accuracy is often negligible. This optimization is one of many that researchers make to make LLMs more resource efficient.</p> 
   </div> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p24"> 
    <h5 class=" callout-container-h5 readable-text-h5">GPU alternatives</h5> 
   </div> 
   <div class="readable-text" id="p25"> 
    <p> While GPUs are currently the most frequently used hardware to train LLMs, they aren’t the only option available. Increasingly, companies are developing special-purpose hardware that offers general advantages for training machine learning models. For example, in 2018, Google made its Tensor Processing Unit (TPU) [3] available for public use as a part of the Google Cloud Platform (GCP). While TPUs generally have less computing capacity than GPUs, their specialized architecture allows them to perform better than GPUs for specific machine learning tasks.</p> 
   </div> 
  </div> 
  <div class="readable-text" id="p26"> 
   <h2 class=" readable-text-h2" id="what-you-will-learn"><span class="num-string browsable-reference-id">1.2</span> What you will learn</h2> 
  </div> 
  <div class="readable-text" id="p27"> 
   <p>Throughout this book, we will explain how LLMs work and equip you with the vocabulary needed to understand them. Once you’ve finished reading, you will have a conversational understanding of what an LLM is and the critical steps involved in its operation. Additionally, you will have some perspective on what an LLM reasonably can do, especially the considerations related to deploying or using one. We will discuss salient points about the fundamental limitations of LLMs and provide tips on how to design around them or when LLMs and, more broadly, generative AI should be avoided entirely.</p> 
  </div> 
  <div class="readable-text" id="p28"> 
   <p>Keep in mind that the details of how transformers are combined to build ChatGPT, Claude, or Gemini are nuanced, and this book primarily focuses on what all of these systems have in common. In fact, we can’t know some of the actual differences between these LLMs because although commercial LLM providers have shared a great deal of information about their models, they have not shared some pieces of information, likely considered trade secrets.</p> 
  </div> 
  <div class="readable-text" id="p29"> 
   <p>Due to the effect that transformer-based LLMs will have on the world, we’re purposely focusing on a wide audience for this book. Programmers of all backgrounds, executives, managers, sales staff, artists, writers, publishers, and many more will have to interact with or have their jobs affected by LLMs over the coming years. So we are going to assume you, dear reader, have a minimal coding background but are familiar with the basic constructs of coding: logic, functions, and maybe even some data structures. You also do not need to be a mathematician; we will show you a bit of math where it is helpful, but it will be optional in building an understanding of how LLMs work.</p> 
  </div> 
  <div class="readable-text" id="p30"> 
   <p>This approach means that very little code will be presented in this book. If you want to dive directly into building and using an LLM, other books in the Manning catalog, such as Sebastian Raschka’s <em>Build a Large Language Model from Scratch</em> (2024) or Edward Raff’s <em>Inside Deep Learning</em> (2022), will complement the material presented here. However, if you want to understand why the LLM you are using has unusual outputs, how your team might be able to use an LLM, or where to avoid using an LLM, or if you have a colleague with little machine learning background who needs to get conversationally competent, this is the book you and your colleague need. </p> 
  </div> 
  <div class="readable-text" id="p31"> 
   <p>In particular, the first part of this book focuses on what LLMs do: their inputs and outputs, converting inputs to outputs, and how we constrain the nature of those outputs. In the second part, we focus on what humans do: how people interact with technology and what risks this creates for using generative AI. Similarly, we’ll discuss some ethical considerations that arise when using and building LLMs.</p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p32"> 
    <h5 class=" callout-container-h5 readable-text-h5">Training LLMs is expensive</h5> 
   </div> 
   <div class="readable-text" id="p33"> 
    <p> Training an LLM is not realistically possible for most people; it is a <span><img alt="equation image" src="../Images/eq-chapter-1-33-1.png"/></span> investment at a minimum and would be a $100 million effort to try to compete with OpenAI. At the same time, the resources available for training LLMs are constantly evolving. As a result, instead of walking you through what training an LLM looks like today, we focus on content with a longer shelf life—helpful knowledge that we believe will be valid years from now instead of example code that could be out of date in just a few months.</p> 
   </div> 
  </div> 
  <div class="readable-text" id="p34"> 
   <h2 class=" readable-text-h2" id="introducing-how-llms-work"><span class="num-string browsable-reference-id">1.3</span> Introducing how LLMs work</h2> 
  </div> 
  <div class="readable-text" id="p35"> 
   <p>Generative AI (GAI or GenAI) is poised to change how we produce and interact with information. The introduction of ChatGPT in November 2022 highlighted the capabilities of modern AI and fascinated a significant portion of the world. Currently, you can sign up for free at <a href="https://chat.openai.com/">https://chat.openai.com/</a> to try it out.</p> 
  </div> 
  <div class="readable-text" id="p36"> 
   <p>If you enter the text prompt “Summarize the following text in two sentences,” followed by all of the introductory text from this chapter, you will get something similar to the following.</p> 
  </div> 
  <div class="readable-text" id="p37"> 
   <p>“The recent surge in attention towards artificial intelligence, particularly large language models (LLMs) like ChatGPT from OpenAI, has highlighted their vast capabilities in natural language processing. This book aims to provide readers with a conversational understanding of LLMs, their operational intricacies, potential applications, limitations, and the ethical considerations surrounding their use while assuming only a basic familiarity with coding concepts and minimal mathematical background. That’s pretty impressive, and to a casual audience, it may seem like this capability has come out of nowhere.”</p> 
  </div> 
  <div class="readable-text" id="p38"> 
   <p>When you visit OpenAI’s website and sign up for ChatGPT, you may notice an option similar to that shown in figure <a href="#fig__gpt_option">1.4</a>. As the name GPT-4 implies, Open AI is, as of this writing, working on its fourth generation of GPT models. LLMs like GPT-4 are a well-established area of ML research in creating algorithms that can synthesize and react to information and produce outputs that appear human generated. This ability unlocks several areas of interaction between people and machines that previously existed only in science fiction. The strength of the language representation encoded into ChatGPT enables convincing dialog, instruction following, summary generation, question answering, content creation, and many more applications. Indeed, it is likely that many possible applications of this technology do not yet exist because our gut reaction is to think of our current problems rather than new capabilities or products that could exist.</p> 
  </div> 
  <div class="browsable-container figure-container" id="p39">  
   <img alt="figure" src="../Images/CH01_F04_Boozallen.png"/> 
   <h5 class=" figure-container-h5" id="fig__gpt_option"><span class="num-string">Figure <span class="browsable-reference-id">1.4</span></span> When you sign up for OpenAI’s ChatGPT, you have two options: the GPT-3.5 model, which you can use for free, or the GPT-4 model, which costs money. </h5>
  </div> 
  <div class="readable-text" id="p40"> 
   <p>The critical factor for you, the reader, is that this technology did not come out of nowhere but is the result of steady progress over the past decade of dramatic year-over-year improvements in machine learning. Consequently, we already know quite a lot about how LLMs work and the ways that they can fail.</p> 
  </div> 
  <div class="readable-text" id="p41"> 
   <p>We are assuming a minimal background so that you can give this book to your friends and family. (One of the authors is hopeful that they can give this book to their mother, who is very proud of them even if she does not know precisely what their job is.) As a result, we need to cover a potentially large gap in the background before we dive in. This first chapter aims to give you that background so the next chapter can begin the process of answering this question: How on earth did a computer summarize the introduction of this book?</p> 
  </div> 
  <div class="readable-text" id="p42"> 
   <h2 class=" readable-text-h2" id="what-is-intelligence-anyway"><span class="num-string browsable-reference-id">1.4</span> What is intelligence, anyway?</h2> 
  </div> 
  <div class="readable-text" id="p43"> 
   <p><em>Artificial intelligence</em> is an excellent name from a marketing perspective, although it was originally used as the name for an entire field of academic research. This practice has led to a subtle problem that gives people a false mental model of how AI works. We are going to try to avoid reinforcing this model. To explain why, we will discuss why artificial intelligence is not such a great name. We can demonstrate this easily by considering a simple question: What is intelligence?</p> 
  </div> 
  <div class="readable-text" id="p44"> 
   <p>You might think that something like an intelligence quotient (IQ) test would help us answer that question. IQ tests have a strong correlation with numerous outcomes like school performance, but they do not give us an objective definition of intelligence. Studies show that some amount of nature (hereditary) and nurture (environment) affect a person’s IQ. It should also seem suspicious that we can boil down intelligence into something as simple as one number—after all, we often scold people for being only “book smart” but not “street smart.” Even if we knew what intelligence was, what would make it artificial? Does intelligence have manufactured flavorings and food colorings?</p> 
  </div> 
  <div class="readable-text" id="p45"> 
   <p>The bottom line is that IQ tests measure your ability to perform a finite set of capabilities, mostly some specific types of logic puzzles under time constraints, but they don’t help us understand the fundamental nature of intelligence. The truth is that there is no perfect understanding of what intelligence is.</p> 
  </div> 
  <div class="readable-text" id="p46"> 
   <p>The field of AI has long been trying to get computers, which are rigid, deterministic, rule-following machines, to perform specific tasks that humans can do but can’t give precise definitions or instructions to do. For example, if we want a computer to count to 1,000 and print out every number divisible by 5, we can write detailed instructions that almost any programmer can convert to code. But if I ask you to write a program that attempts to detect if an arbitrary picture has a cat in it, that’s quite a different challenge. You need to somehow precisely define what a cat is and then all the minutia of how to detect one. How exactly do we write code to find and differentiate between cat whiskers and dog whiskers? How do we successfully recognize a cat when it does not have whiskers? When it comes down to it, it isn’t easy to do.</p> 
  </div> 
  <div class="readable-text" id="p47"> 
   <p>However, because AI and ML have focused on these hard-to-specify tasks that humans can perform, describing AI and ML algorithms using analogies has become especially common. To get a computer to detect cats, we provide thousands upon thousands of examples of images that are cats and images that are not cats. We then run one of many various algorithms with a specific, detailed, mathematical process for differentiating cats from the rest of the world. But in the technical vocabulary, we call this process <em>learning</em>. When the model fails to detect a cat in a new image because it is a lion and lions were not in the original list of cats, we often say that the model didn’t <em>understand</em> lions. </p> 
  </div> 
  <div class="readable-text" id="p48"> 
   <p>Indeed, whenever we try to explain something to friends, we often use analogies to shared concepts that we are both familiar with. Because AI and ML are broadly focused on replicating human abilities to perform tasks, the analogies often use language that implies the literal cognitive functions of a human. As LLMs demonstrate capabilities at a level close to what humans can do, these analogies become more troublesome than helpful because people read too deeply into them and begin to believe that they mean more than they do.</p> 
  </div> 
  <div class="readable-text" id="p49"> 
   <p>For this reason, we will be careful with our analogies and caution the reader about following any analogies too far. Some terms, like <em>learning</em>, are technical jargon worth understanding, but we want you to be on your guard about what they might imply. In some cases, analogies are still helpful in this book, but we will try to be explicit about the boundaries of how to interpret such analogies. </p> 
  </div> 
  <div class="readable-text" id="p50"> 
   <h2 class=" readable-text-h2" id="how-humans-and-machines-represent-language-differently"><span class="num-string browsable-reference-id">1.5</span> How humans and machines represent language differently</h2> 
  </div> 
  <div class="readable-text" id="p51"> 
   <p>What does it mean to represent language? We humans implicitly start to learn how to represent language shortly after birth through interaction with others and the world around us. We proceed through formal education to develop an understanding of the components, underlying structures, and rules that govern language and its use. Our internal representation of language has been studied extensively. While some laws of language have been uncovered, many are still up for debate. ChatGPT’s internal representation of language is based on portions of this knowledge. It is enabled using the concepts of <em>artificial neural networks</em>, also known as deep learning (another dangerous analogy), which are combinations of data structures and algorithms that are patterned loosely after human brain structures. However, our understanding of the ways the mind works is incomplete. While the neural networks that power LLMs are a mere simplification of the human brain structure, their power lies in their ability to capture and encode language in a useful way to generate language and interact with people.</p> 
  </div> 
  <div class="readable-text print-book-callout" id="p52"> 
   <p> <span class="print-book-callout-head">Note</span> Abstractions of the brain’s structure have proven useful across many domains. Neural networks have demonstrated incredible progress in language, vision, learning, and pattern recognition. The convergence of advancements in neural machine learning algorithms, the extreme proliferation of digital data, and an explosion of computer hardware, such as GPUs, have led to the advancements that make ChatGPT possible today. </p> 
  </div> 
  <div class="readable-text" id="p53"> 
   <p>The critical detail to take from this discussion is that you, as a human, have an innate understanding of language you have learned over time. Your learning and use of language are interactive. Through evolution, we all seem to have relatively consistent ways of learning and communicating with each other. To find out more about this concept, look into the theory of universal grammar introduced by linguist Noam Chomsky. Unlike people, LLMs have a representation of language that is learned via a static process. When you have a conversation with Claude or ChatGPT, it mechanically participates in a dialog with you despite having never been in a conversation before.</p> 
  </div> 
  <div class="readable-text" id="p54"> 
   <p>The representation of language an LLM learns can be high quality, but it is not error-free. It is manipulable in that we can alter the behavior of LLMs in specific ways to limit what they are aware of or what they produce. Understanding that LLMs represent language using relationships inferred from examples helps us maintain realistic expectations. If you are going to use an LLM, how dangerous is it if it is wrong? How can you work with the representation of language to build a product or avoid a bad outcome? These are some of the high-level concerns we will discuss throughout this book.</p> 
  </div> 
  <div class="readable-text" id="p55"> 
   <h2 class=" readable-text-h2" id="generative-pretrained-transformers-and-friends"><span class="num-string browsable-reference-id">1.6</span> Generative Pretrained Transformers and friends</h2> 
  </div> 
  <div class="readable-text" id="p56"> 
   <p>The terminology <em>Generative Pretrained Transformer</em> was invented by OpenAI to talk about a new type of model they introduced in 2018 that incorporates a type of neural network component known as a transformer. While the original GPT model (GPT-1) is no longer used, the core underlying ideas of pretraining and transformers have become core pillars of the recent revolution in generative AI and tools like Claude, Gemini, Llama, and Copilot.</p> 
  </div> 
  <div class="readable-text" id="p57"> 
   <p>It is also essential to recognize that these GPT-based AI tools are only one example of an expansive domain of algorithmic research and application of LLMs. Outside of the release of ChatGPT, we have observed an incredible proliferation of LLMs. Some LLMs, like those released by EleutherAI and the BigScience Research Workshop, are freely available to the public to advance research and explore applications. Corporations like Meta, Microsoft, and Google, as we’ve mentioned, have released other LLMs with more restrictive licensing terms. Publicly available LLMs that anyone can use to build an application or system, sometimes called <em>foundation models</em>, have created a vibrant community of researchers, hobbyists, and companies exploring the applications, limitations, and opportunities LLMs and generative AI create. The concepts we teach in this book apply nearly uniformly to all LLMs. Each of these produce output using structures similar, if not identical, to those found in ChatGPT.</p> 
  </div> 
  <div class="readable-text" id="p58"> 
   <p>It may seem impossible for one book to contain a general summary applicable to many models. However, it is possible for a few reasons, one of the most important being that we will not go to the level of depth necessary to code an LLM yourself from scratch. Naturally, there are parts of ChatGPT and other commercial LLMs that remain trade secrets. As a result, our scope and descriptions are intentionally generalized to the most common aspects of all generative LLMs today.</p> 
  </div> 
  <div class="readable-text" id="p59"> 
   <p>The second reason we can give such a broadly applicable summary is the nature of LLMs. While it’s true that many tweaks can be made to how they are built and operate, researchers in the field consistently find that the details that matter the most are the following:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p60">How large is the model, and can you make it larger?</li> 
   <li class="readable-text" id="p61">How much data was used to build the model, and can you get more?</li> 
  </ul> 
  <div class="readable-text" id="p62"> 
   <p>These points can be frustrating for researchers who like to think they have vital insights or designs that meaningfully improve how these LLMs work and operate because, in many cases, the same improvement could be obtained just as easily by “making it bigger” or building a model with more data or more parameters instead. Increasing the size of both the models and the data pools is a crucial component of many ethical concerns around using and building LLMs, which we will discuss in chapter <a href="../Text/chapter-9.html">9</a>.</p> 
  </div> 
  <div class="readable-text" id="p63"> 
   <h2 class=" readable-text-h2" id="why-llms-perform-so-well"><span class="num-string browsable-reference-id">1.7</span> Why LLMs perform so well</h2> 
  </div> 
  <div class="readable-text" id="p64"> 
   <p>We discuss the details of how LLMs work in the coming chapters, but it is also worth sharing here a key lesson learned by researching ML algorithms. For many years, getting better performance from your algorithm for whatever task you were trying to do often meant getting clever about designing your algorithm. You would study your problem, the data, and the math and attempt to derive valuable truths about the world that you could then encode into your algorithm. If you did a good job, your performance improved, you required less data, and all was good in the world. Many classic deep learning algorithms you may hear about, like convolutional neural networks (CNNs) and long short-term memory (LSTM) networks, are, at a high level, the result of people thinking hard and getting clever. Even simpler “shallow” ML algorithms, such as XGBoost, that do not rely on neural networks or deep learning were created using clever algorithm design.</p> 
  </div> 
  <div class="readable-text" id="p65"> 
   <p>LLMs demonstrate a more recent trend. Instead of getting clever about thealgorithm, they keep it simple and implement a <em>naive</em> algorithm that simply captures relationships between pieces of information. In many ways, LLMs have fewer beliefs about the world forcibly baked into the algorithm. Fundamentally, this provides more flexibility. How could this be a good idea if I told you the opposite approach was how people improved algorithms? The difference is that LLMs and similar techniques are just bigger, massively so. They are trained on far more data and with far more ability to capture more relationships between more words in more sentences; this brute-force approach appears to have outpaced classic ML methods in performance. This idea is illustrated in figure <a href="#fig__whatChanged">1.5</a>.</p> 
  </div> 
  <div class="browsable-container figure-container" id="p66">  
   <img alt="figure" src="../Images/CH01_F05_Boozallen.png"/> 
   <h5 class=" figure-container-h5" id="fig__whatChanged"><span class="num-string">Figure <span class="browsable-reference-id">1.5</span></span> If the cleverness of an algorithm is based on how much information you encode into the design, older techniques often increase performance by being cleverer than their predecessors. As reflected by the size of the circles, LLMs have mostly chosen a “dumber” approach of using more data and parameters and imposing minimal constraints on what the algorithm can learn.</h5>
  </div> 
  <div class="readable-text" id="p67"> 
   <p>As we have already stated, bigger is not better by every metric. These models are currently a logistical and computational challenge to deploy. Many real-world constraints, including response time, power draw, battery drain, and maintainability, are all negatively affected. So it is only a narrow definition of “performance” by which LLMs have improved.</p> 
  </div> 
  <div class="readable-text" id="p68"> 
   <p>Still, the lesson on the value of “going bigger” over “getting clever” is worth considering. Sometimes, in your design of a machine learning solution, even if you are using an LLM, the best answer may be “Let’s just go get a lot more data.”</p> 
  </div> 
  <div class="readable-text" id="p69"> 
   <h2 class=" readable-text-h2" id="llms-in-action-the-good-bad-and-scary"><span class="num-string browsable-reference-id">1.8</span> LLMs in action: The good, bad, and scary</h2> 
  </div> 
  <div class="readable-text" id="p70"> 
   <p>Throughout this book, we will give examples of how LLMs can fail, often in hilarious or silly ways. The point of these illustrations isn’t to say that LLMs are incapable of performing a task. With changes to the input, setup, or random luck, you can often get LLMs to work better.</p> 
  </div> 
  <div class="readable-text" id="p71"> 
   <p>The point of such illustrations is to show you how LLMs can fail, often on things so simple that a child can do them better. As you read through this book and interact with LLMs yourself, these illustrations should give you pause and lead you to the thought, “If I use ChatGPT for a hard task, but it fails on easy ones, am I setting myself up for failure?” The answer may often be an emphatic <em>yes</em>! Using LLMs safely requires a degree of skepticism or doubt about the outputs, work to verify and validate correctness, and the ability to adapt accordingly. If you use an LLM for a task you cannot do yourself, you risk exposing yourself to errant results you can’t verify personally. We will continually weave this point and how to deal with it into the conversation as we discuss how to use LLMs more throughout the book.</p> 
  </div> 
  <div class="readable-text" id="p72"> 
   <p>It is easy to imagine many ways that LLMs can potentially make our lives easier when it does work—answering all your emails, summarizing long documents, and explaining new concepts. What does not come naturally to many is how things can go wrong and quickly become dangerous.</p> 
  </div> 
  <div class="readable-text" id="p73"> 
   <p>This kind of adversarial thinking can often be prompted with an initial example: say you want to learn how to make a bomb. If you ask ChatGPT that question, you get the sanitized answer, “Sorry, I can’t assist with that request. If you’re in crisis or need help, please contact local authorities or professionals who can help.” However, researchers have recently shown how to get ChatGPT and many other commercial LLMs to answer the question without hesitation, among many other dangerous requests for information [4].</p> 
  </div> 
  <div class="readable-text" id="p74"> 
   <p>One might argue that if someone is so clever as to figure out how to trick the LLM, they could probably get whatever dangerous information they want from another source. This is likely true, but at the same time, it fails to account for the scale of automation in LLMs and generative AI tools. No AI or ML algorithm is perfect, and if millions of people ask questions, LLMs might produce a dangerous response 0.01% of the time. ChatGPT has over 100 million users [5], so that is 10,000 dangerous responses. The problem worsens when you consider what a malicious actor might begin to automate. We will discuss this problem further in the second half of the book.</p> 
  </div> 
  <div class="readable-text" id="p75"> 
   <p>We look forward to your joining us in exploring how LLMs work. In the end, you’ll have a detailed understanding of many things to consider when employing LLMs’ revolutionary capabilities in your business or daily life.</p> 
  </div> 
  <div class="readable-text" id="p76"> 
   <h2 class=" readable-text-h2" id="summary">Summary</h2> 
  </div> 
  <ul> 
   <li class="readable-text" id="p77">ChatGPT is a type of large language model, which is itself in the larger family of generative AI/ML. Generative models produce new output, and LLMs are unique in the quality of their output but are extremely costly to make and use.</li> 
   <li class="readable-text" id="p78">LLMs are loosely patterned after an incomplete understanding of human brain function and language learning. This is used as inspiration in design, but it does not mean the models have the same abilities or weaknesses as humans.</li> 
   <li class="readable-text" id="p79">Intelligence is a multifaceted and hard-to-quantify concept, making it difficult to say whether LLMs are intelligent. It is easier to think about LLMs and their potential use in terms of capabilities and reliability.</li> 
   <li class="readable-text" id="p80">Human language must be converted to and from an LLM’s internal representation. How this representation is formed will change what an LLM learns and influence how you can build solutions using LLMs. </li> 
  </ul>
 </body></html>