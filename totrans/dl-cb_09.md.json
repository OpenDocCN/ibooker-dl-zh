["```py\n09.1 Reusing a pretrained image recognition network\n09.2 Images as embeddings\n09.3 Retraining\n```", "```py\nmodel = VGG16(weights='imagenet', include_top=True)\nmodel.summary()\n```", "```py\nimg = Image.open('data/cat.jpg')\nw, h = img.size\ns = min(w, h)\ny = (h - s) // 2\nx = (w - s) // 2\nimg = img.crop((x, y, s, s))\n```", "```py\ntarget_size = max(model.layers[0].input_shape)\nimg = img.resize((target_size, target_size), Image.ANTIALIAS)\nimshow(np.asarray(img))\n```", "```py\nnp_img = image.img_to_array(img)\nimg_batch = np.expand_dims(np_img, axis=0)\npre_processed = preprocess_input(img_batch)\npre_processed.shape\n```", "```py\n(1, 224, 224, 3)\n```", "```py\nfeatures = model.predict(pre_processed)\nfeatures.shape\n```", "```py\n(1, 1000)\n```", "```py\ndecode_predictions(features, top=5)\n```", "```py\n[[(u'n02124075', u'Egyptian_cat', 0.14703247),\n  (u'n04040759', u'radiator', 0.12125628),\n  (u'n02123045', u'tabby', 0.097638465),\n  (u'n03207941', u'dishwasher', 0.047418527),\n  (u'n02971356', u'carton', 0.047036409)]]\n```", "```py\nflickr = flickrapi.FlickrAPI(FLICKR_KEY, FLICKR_SECRET, format='parsed-json')\nres = flickr.photos.search(text='\"cat\"', per_page='10', sort='relevance')\nphotos = res['photos']['photo']\n```", "```py\ndef flickr_url(photo, size=''):\n    url = 'http://farm{farm}.staticflickr.com/{server}/{id}_{secret}{size}.jpg'\n    if size:\n        size = '_' + size\n    return url.format(size=size, **photo)\n```", "```py\ntags = ['<img src=\"{}\" width=\"150\" style=\"display:inline\"/>'\n        .format(flickr_url(photo)) for photo in photos]\nHTML(''.join(tags))\n```", "```py\ndef fetch_photo(dir_name, photo):\n    urlretrieve(flickr_url(photo), os.path.join(dir_name, photo['id'] + '.jpg'))\n\ndef fetch_image_set(query, dir_name=None, count=250, sort='relevance'):\n    res = flickr.photos.search(text='\"{}\"'.format(query),\n                               per_page=count, sort=sort)['photos']['photo']\n    dir_name = dir_name or query\n    if not os.path.exists(dir_name):\n        os.makedirs(dir_name)\n    with multiprocessing.Pool() as p:\n        p.map(partial(fetch_photo, dir_name), res)\n\nfetch_image_set('cat')\n```", "```py\nfetch_image_set('dog')\n```", "```py\nimages = [image.load_img(p, target_size=(224, 224))\n          for p in glob('cat/*jpg') + glob('dog/*jpg')]\nvector = np.asarray([image.img_to_array(img) for img in images])\n```", "```py\nbase_model = VGG16(weights='imagenet')\nmodel = Model(inputs=base_model.input,\n              outputs=base_model.get_layer('fc2').output)\n```", "```py\nvectors = model.predict(vector)\nvectors.shape\n```", "```py\nX_train, X_test, y_train, y_test = train_test_split(\n    p, [1] * 250 + [0] * 250, test_size=0.20, random_state=42)\n\nclf = svm.SVC(kernel='rbf')\nclf.fit(X_train, y_train)\nsum(1 for p, t in zip(clf.predict(X_test), y_test) if p != t)\n```", "```py\nmm = {tuple(a): b for a, b in zip(p, glob('cat/*jpg') + glob('dog/*jpg'))}\nwrong = [mm[tuple(a)] for a, p, t in zip(X_test,\n                                         clf.predict(X_test),\n                                         y_test) if p != t]\n\nfor x in wrong:\n    display(Image(x, width=150))\n```", "```py\nfetch_image_set('cat', dir_name='maybe_cat', count=100, sort='recent')\n```", "```py\nmaybe_cat_fns = glob('maybe_cat/*jpg')\nmaybe_cats = [image.load_img(p, target_size=(224, 224))\n              for p in maybe_cat_fns]\nmaybe_cat_vectors = np.asarray([image.img_to_array(img)\n                                for img in maybe_cats])\n```", "```py\ncentroid = maybe_cat_vectors.sum(axis=0) / len(maybe_cats)\n```", "```py\ndiffs = maybe_cat_vectors - centroid\ndistances = numpy.linalg.norm(diffs, axis=1)\n```", "```py\nsorted_idxs = np.argsort(distances)\nfor worst_cat_idx in sorted_idxs[-10:]:\n    display(Image(maybe_cat_fns[worst_cat_idx], width=150))\n```", "```py\nto_drop = 90\nsorted_idxs_i = sorted_idxs\nfor i in range(5):\n    centroid_i = maybe_cat_vectors[sorted_idxs_i[:-to_drop]].sum(axis=0) /\n        (len(maybe_cat_fns) - to_drop)\n    distances_i = numpy.linalg.norm(maybe_cat_vectors - centroid_i, axis=1)\n    sorted_idxs_i = np.argsort(distances_i)\n```", "```py\nbase_model = InceptionV3(weights='imagenet', include_top=False)\nfor layer in base_model.layers:\n    layer.trainable = False\n```", "```py\npool_2d = GlobalAveragePooling2D(name='pool_2d')(base_model.output)\ndense = Dense(1024, name='dense', activation='relu')(pool_2d)\npredictions = Dense(len(idx_to_labels), activation='softmax')(dense)\nmodel = Model(inputs=base_model.input, outputs=predictions)\nmodel.compile(optimizer='rmsprop',\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n```", "```py\npet_images_fn = [fn for fn in os.listdir('pet_images') if fn.endswith('.jpg')]\nlabels = []\nidx_to_labels = []\nlabel_to_idx = {}\nfor fn in pet_images_fn:\n    label, _ = fn.rsplit('_', 1)\n    if not label in label_to_idx:\n        label_to_idx[label] = len(idx_to_labels)\n        idx_to_labels.append(label)\n    labels.append(label_to_idx[label])\n```", "```py\ndef fetch_pet(pet):\n    img = image.load_img('pet_images/' + pet, target_size=(299, 299))\n    return image.img_to_array(img)\nimg_vector = np.asarray([fetch_pet(pet) for pet in pet_images_fn])\n```", "```py\ny = np.zeros((len(labels), len(idx_to_labels)))\nfor idx, label in enumerate(labels):\n    y[idx][label] = 1\n```", "```py\nmodel.fit(\n    img_vector, y,\n    batch_size=128,\n    epochs=30,\n    verbose=2\n)\n```", "```py\nunfreeze = False\nfor layer in base_model.layers:\n    if unfreeze:\n        layer.trainable = True\n    if layer.name == 'mixed9':\n        unfreeze = True\nmodel.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n              loss='categorical_crossentropy', metrics=['accuracy'])\n```", "```py\nmodel.fit(\n    img_vector, y,\n    batch_size=128,\n    epochs=15,\n    verbose=2\n)\n```"]