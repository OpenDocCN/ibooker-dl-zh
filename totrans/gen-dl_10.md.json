["```py\nfrom tensorflow.keras import datasets\n(x_train, _), (x_test, _) = datasets.mnist.load_data()\n```", "```py\ndef preprocess(imgs):\n    imgs = (imgs.astype(\"float32\") - 127.5) / 127.5\n    imgs = np.pad(imgs , ((0,0), (2,2), (2,2)), constant_values= -1.0)\n    imgs = np.expand_dims(imgs, -1)\n    return imgs\n\nx_train = preprocess(x_train)\nx_test = preprocess(x_test)\nx_train = tf.data.Dataset.from_tensor_slices(x_train).batch(128)\nx_test = tf.data.Dataset.from_tensor_slices(x_test).batch(128)\n```", "```py\nebm_input = layers.Input(shape=(32, 32, 1))\nx = layers.Conv2D(\n    16, kernel_size=5, strides=2, padding=\"same\", activation = activations.swish\n)(ebm_input) ![1](Images/1.png)\nx = layers.Conv2D(\n    32, kernel_size=3, strides=2, padding=\"same\", activation = activations.swish\n)(x)\nx = layers.Conv2D(\n    64, kernel_size=3, strides=2, padding=\"same\", activation = activations.swish\n)(x)\nx = layers.Conv2D(\n    64, kernel_size=3, strides=2, padding=\"same\", activation = activations.swish\n)(x)\nx = layers.Flatten()(x)\nx = layers.Dense(64, activation = activations.swish)(x)\nebm_output = layers.Dense(1)(x) ![2](Images/2.png)\nmodel = models.Model(ebm_input, ebm_output) ![3](Images/3.png)\n```", "```py\ndef generate_samples(model, inp_imgs, steps, step_size, noise):\n    imgs_per_step = []\n    for _ in range(steps): ![1](Images/1.png)\n        inp_imgs += tf.random.normal(inp_imgs.shape, mean = 0, stddev = noise) ![2](Images/2.png)\n        inp_imgs = tf.clip_by_value(inp_imgs, -1.0, 1.0)\n        with tf.GradientTape() as tape:\n            tape.watch(inp_imgs)\n            out_score = -model(inp_imgs) ![3](Images/3.png)\n        grads = tape.gradient(out_score, inp_imgs) ![4](Images/4.png)\n        grads = tf.clip_by_value(grads, -0.03, 0.03)\n        inp_imgs += -step_size * grads ![5](Images/5.png)\n        inp_imgs = tf.clip_by_value(inp_imgs, -1.0, 1.0)\n        return inp_imgs\n```", "```py\nclass Buffer:\n    def __init__(self, model):\n        super().__init__()\n        self.model = model\n        self.examples = [\n            tf.random.uniform(shape = (1, 32, 32, 1)) * 2 - 1\n            for _ in range(128)\n        ] ![1](Images/1.png)\n\n    def sample_new_exmps(self, steps, step_size, noise):\n        n_new = np.random.binomial(128, 0.05) ![2](Images/2.png)\n        rand_imgs = (\n            tf.random.uniform((n_new, 32, 32, 1)) * 2 - 1\n        )\n        old_imgs = tf.concat(\n            random.choices(self.examples, k=128-n_new), axis=0\n        ) ![3](Images/3.png)\n        inp_imgs = tf.concat([rand_imgs, old_imgs], axis=0)\n        inp_imgs = generate_samples(\n            self.model, inp_imgs, steps=steps, step_size=step_size, noise = noise\n        ) ![4](Images/4.png)\n        self.examples = tf.split(inp_imgs, 128, axis = 0) + self.examples ![5](Images/5.png)\n        self.examples = self.examples[:8192]\n        return inp_imgs\n```", "```py\nclass EBM(models.Model):\n    def __init__(self):\n        super(EBM, self).__init__()\n        self.model = model\n        self.buffer = Buffer(self.model)\n        self.alpha = 0.1\n        self.loss_metric = metrics.Mean(name=\"loss\")\n        self.reg_loss_metric = metrics.Mean(name=\"reg\")\n        self.cdiv_loss_metric = metrics.Mean(name=\"cdiv\")\n        self.real_out_metric = metrics.Mean(name=\"real\")\n        self.fake_out_metric = metrics.Mean(name=\"fake\")\n\n    @property\n    def metrics(self):\n        return [\n            self.loss_metric,\n            self.reg_loss_metric,\n            self.cdiv_loss_metric,\n            self.real_out_metric,\n            self.fake_out_metric\n        ]\n\n    def train_step(self, real_imgs):\n        real_imgs += tf.random.normal(\n            shape=tf.shape(real_imgs), mean = 0, stddev = 0.005\n        ) ![1](Images/1.png)\n        real_imgs = tf.clip_by_value(real_imgs, -1.0, 1.0)\n        fake_imgs = self.buffer.sample_new_exmps(\n            steps=60, step_size=10, noise = 0.005\n        ) ![2](Images/2.png)\n        inp_imgs = tf.concat([real_imgs, fake_imgs], axis=0)\n        with tf.GradientTape() as training_tape:\n            real_out, fake_out = tf.split(self.model(inp_imgs), 2, axis=0) ![3](Images/3.png)\n            cdiv_loss = tf.reduce_mean(fake_out, axis = 0) - tf.reduce_mean(\n                real_out, axis = 0\n            ) ![4](Images/4.png)\n            reg_loss = self.alpha * tf.reduce_mean(\n                real_out ** 2 + fake_out ** 2, axis = 0\n            ) ![5](Images/5.png)\n            loss = reg_loss + cdiv_loss\n        grads = training_tape.gradient(loss, self.model.trainable_variables) ![6](Images/6.png)\n        self.optimizer.apply_gradients(\n            zip(grads, self.model.trainable_variables)\n        )\n        self.loss_metric.update_state(loss)\n        self.reg_loss_metric.update_state(reg_loss)\n        self.cdiv_loss_metric.update_state(cdiv_loss)\n        self.real_out_metric.update_state(tf.reduce_mean(real_out, axis = 0))\n        self.fake_out_metric.update_state(tf.reduce_mean(fake_out, axis = 0))\n        return {m.name: m.result() for m in self.metrics}\n\n    def test_step(self, real_imgs): ![7](Images/7.png)\n        batch_size = real_imgs.shape[0]\n        fake_imgs = tf.random.uniform((batch_size, 32, 32, 1)) * 2 - 1\n        inp_imgs = tf.concat([real_imgs, fake_imgs], axis=0)\n        real_out, fake_out = tf.split(self.model(inp_imgs), 2, axis=0)\n        cdiv = tf.reduce_mean(fake_out, axis = 0) - tf.reduce_mean(\n            real_out, axis = 0\n        )\n        self.cdiv_loss_metric.update_state(cdiv)\n        self.real_out_metric.update_state(tf.reduce_mean(real_out, axis = 0))\n        self.fake_out_metric.update_state(tf.reduce_mean(fake_out, axis = 0))\n        return {m.name: m.result() for m in self.metrics[2:]}\n\nebm = EBM()\nebm.compile(optimizer=optimizers.Adam(learning_rate=0.0001), run_eagerly=True)\nebm.fit(x_train, epochs=60, validation_data = x_test,)\n```", "```py\nstart_imgs = np.random.uniform(size = (10, 32, 32, 1)) * 2 - 1\ngen_img = generate_samples(\n    ebm.model,\n    start_imgs,\n    steps=1000,\n    step_size=10,\n    noise = 0.005,\n    return_img_per_step=True,\n)\n```"]