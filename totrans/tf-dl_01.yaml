- en: Chapter 1\. Introduction to Deep Learning
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第1章 深度学习简介
- en: Deep learning has revolutionized the technology industry. Modern machine translation,
    search engines, and computer assistants are all powered by deep learning. This
    trend will only continue as deep learning expands its reach into robotics, pharmaceuticals,
    energy, and all other fields of contemporary technology. It is rapidly becoming
    essential for the modern software professional to develop a working knowledge
    of the principles of deep learning.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习已经彻底改变了技术行业。现代机器翻译、搜索引擎和计算机助手都是由深度学习驱动的。随着深度学习将其影响扩展到机器人技术、制药业、能源以及当代技术的所有其他领域，这一趋势只会继续发展。对于现代软件专业人员来说，发展对深度学习原理的工作知识正在迅速变得至关重要。
- en: In this chapter, we will introduce you to the history of deep learning, and
    to the broader impact deep learning has had on the research and commercial communities.
    We will next cover some of the most famous applications of deep learning. This
    will include both prominent machine learning architectures and fundamental deep
    learning primitives. We will end by giving a brief perspective of where deep learning
    is heading over the next few years before we dive into TensorFlow in the next
    few chapters.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将向您介绍深度学习的历史，以及深度学习对研究和商业社区产生的更广泛影响。接下来，我们将介绍一些最著名的深度学习应用。这将包括突出的机器学习架构和基本的深度学习原语。最后，我们将简要展望深度学习在未来几年将走向何方，然后在接下来的几章中深入探讨TensorFlow。
- en: Machine Learning Eats Computer Science
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习正在吞噬计算机科学
- en: Until recently, software engineers went to school to learn a number of basic
    algorithms (graph search, sorting, database queries, and so on). After school,
    these engineers would go out into the real world to apply these algorithms to
    systems. Most of today’s digital economy is built on intricate chains of basic
    algorithms laboriously glued together by generations of engineers. Most of these
    systems are not capable of adapting. All configurations and reconfigurations have
    to be performed by highly trained engineers, rendering systems brittle.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 直到最近，软件工程师们去学校学习了许多基本算法（图搜索、排序、数据库查询等）。毕业后，这些工程师会走出校门，将这些算法应用到系统中。如今的数字经济大部分是建立在由几代工程师辛苦拼凑在一起的复杂基本算法链上的。大多数这些系统无法自适应。所有的配置和重新配置都必须由经过高度训练的工程师执行，使系统变得脆弱。
- en: Machine learning promises to change the field of software development by enabling
    systems to adapt dynamically. Deployed machine learning systems are capable of
    learning desired behaviors from databases of examples. Furthermore, such systems
    can be regularly retrained as new data comes in. Very sophisticated software systems,
    powered by machine learning, are capable of dramatically changing their behavior
    without major changes to their code (just to their training data). This trend
    is only likely to accelerate as machine learning tools and deployment become easier
    and easier.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习承诺通过使系统能够动态适应来改变软件开发领域。部署的机器学习系统能够从示例数据库中学习所需的行为。此外，这些系统可以在新数据到来时定期重新训练。由机器学习驱动的非常复杂的软件系统能够在不对其代码进行重大更改的情况下显着改变其行为（只需对其训练数据进行更改）。随着机器学习工具和部署变得越来越简单，这一趋势只会加速发展。
- en: As the behavior of software-engineered systems changes, the roles of software
    engineers will change as well. In some ways, this transformation will be analogous
    to the transformation following the development of programming languages. The
    first computers were painstakingly programmed. Networks of wires were connected
    and interconnected. Then punchcards were set up to enable the creation of new
    programs without hardware changes to computers. Following the punchcard era, the
    first assembly languages were created. Then higher-level languages like Fortran
    or Lisp. Succeeding layers of development have created very high-level languages
    like Python, with intricate ecosystems of precoded algorithms. Much modern computer
    science even relies on autogenerated code. Modern app developers use tools like
    Android Studio to autogenerate much of the code they’d like to make. Each successive
    wave of simplification has broadened the scope of computer science by lowering
    barriers to entry.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 随着软件工程系统行为的改变，软件工程师的角色也将发生变化。在某种程度上，这种转变将类似于在开发编程语言之后发生的转变。最初的计算机是经过艰苦编程的。电线网络被连接和互连。然后设置了打孔卡，以便在不更改计算机硬件的情况下创建新程序。在打孔卡时代之后，第一个汇编语言被创建。然后是高级语言如Fortran或Lisp。随后的开发层次创建了像Python这样的非常高级语言，具有复杂的预编码算法生态系统。现代计算机科学甚至依赖于自动生成的代码。现代应用程序开发人员使用诸如Android
    Studio之类的工具自动生成他们想要制作的大部分代码。每一波简化的连续浪潮都通过降低进入门槛扩大了计算机科学的范围。
- en: Machine learning promises to lower barriers even further; programmers will soon
    be able to change the behavior of systems by altering training data, possibly
    without writing a single line of code. On the user side, systems built on spoken
    language and natural language understanding such as Alexa and Siri will allow
    nonprogrammers to perform complex computations. Furthermore, ML powered systems
    are likely to become more *robust* against errors. The capacity to retrain models
    will mean that codebases can shrink and that maintainability will increase. In
    short, machine learning is likely to completely upend the role of software engineers.
    Today’s programmers will need to understand how machine learning systems learn,
    and will need to understand the classes of errors that arise in common machine
    learning systems. Furthermore, they will need to understand the design patterns
    that underlie machine learning systems (very different in style and form from
    classical software design patterns). And, they will need to know enough tensor
    calculus to understand why a sophisticated deep architecture may be misbehaving
    during learning. It’s not an understatement to say that understanding machine
    learning (theory and practice) will become a fundamental skill that every computer
    scientist and software engineer will need to understand for the coming decade.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习承诺进一步降低障碍；程序员很快将能够通过改变训练数据来改变系统的行为，可能甚至不需要编写一行代码。在用户端，基于口语和自然语言理解的系统，如Alexa和Siri，将允许非程序员执行复杂的计算。此外，由ML驱动的系统可能会更加*鲁棒*，抵抗错误。重新训练模型的能力意味着代码库可以缩小，可维护性将增加。简而言之，机器学习很可能会彻底颠覆软件工程师的角色。今天的程序员将需要了解机器学习系统学习的方式，并需要了解常见机器学习系统中出现的错误类别。此外，他们需要了解支撑机器学习系统的设计模式（与传统软件设计模式在风格和形式上非常不同）。而且，他们需要了解足够的张量微积分，以了解为什么一个复杂的深度架构在学习过程中可能会出现问题。毫不夸张地说，理解机器学习（理论和实践）将成为未来十年每个计算机科学家和软件工程师都需要掌握的基本技能。
- en: In the remainder of this chapter, we will provide a whirlwind tour of the basics
    of modern deep learning. The remainder of this book will go into much greater
    depth on all the topics we touch on here.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的其余部分，我们将快速介绍现代深度学习的基础知识。本书的其余部分将更深入地讨论我们在这里提到的所有主题。
- en: Deep Learning Primitives
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习基元
- en: Most deep architectures are built by combining and recombining a limited set
    of architectural primitives. Such primitives, typically called neural network
    layers, are the foundational building blocks of deep networks. In the rest of
    this book, we will provide in-depth introductions to such layers. However, in
    this section, we will provide a brief overview of the common modules that are
    found in many deep networks. This section is not meant to provide a thorough introduction
    to these modules. Rather, we aim to provide a rapid overview of the building blocks
    of sophisticated deep architectures to whet your appetite. The art of deep learning
    consists of combining and recombining such modules and we want to show you the
    alphabet of the language to start you on the path to deep learning expertise.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数深度架构是通过组合和重组一组有限的架构基元构建的。这些基元通常称为神经网络层，是深度网络的基础构建模块。在本书的其余部分，我们将深入介绍这些层。然而，在本节中，我们将简要概述许多深度网络中常见的模块。本节并不旨在对这些模块进行全面介绍。相反，我们的目标是快速概述复杂深度架构的基本构建模块，以激发您的兴趣。深度学习的艺术在于组合和重组这些模块，我们希望向您展示语言的字母表，让您开始深度学习专业知识之路。
- en: Fully Connected Layer
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 全连接层
- en: A fully connected network transforms a list of inputs into a list of outputs.
    The transformation is called fully connected since any input value can affect
    any output value. These layers will have many learnable parameters, even for relatively
    small inputs, but they have the large advantage of assuming no structure in the
    inputs. This concept is illustrated in [Figure 1-1](#ch1-fcnet).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 一个全连接网络将一系列输入转换为一系列输出。这种转换被称为全连接，因为任何输入值都可以影响任何输出值。即使对于相对较小的输入，这些层也会有许多可学习的参数，但它们具有一个很大的优势，即假设输入中没有结构。这个概念在[图1-1](#ch1-fcnet)中有所说明。
- en: '![images/FCLayer@2x.png](assets/tfdl_0101.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![images/FCLayer@2x.png](assets/tfdl_0101.png)'
- en: Figure 1-1\. A fully connected layer. Inbound arrows represent inputs, while
    outbound arrows represent outputs. The thickness of interconnecting lines represents
    the magnitude of learned weights. The fully connected layer transforms inputs
    into outputs via the learned rule.
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-1. 一个全连接层。入站箭头代表输入，出站箭头代表输出。互连线的粗细代表学习权重的大小。全连接层通过学习规则将输入转换为输出。
- en: Convolutional Layer
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 卷积层
- en: A convolutional network assumes special spatial structure in its input. In particular,
    it assumes that inputs that are close to each other spatially are semantically
    related. This assumption makes most sense for images, since pixels close to one
    another are likely semantically linked. As a result, convolutional layers have
    found wide use in deep architectures for image processing. This concept is illustrated
    in [Figure 1-2](#ch1-convnet).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积网络假设其输入具有特殊的空间结构。特别是，它假设在空间上彼此接近的输入在语义上是相关的。这种假设对于图像来说最有意义，因为彼此接近的像素很可能在语义上是相关的。因此，卷积层在深度架构中用于图像处理的广泛应用。这个概念在[图1-2](#ch1-convnet)中有所说明。
- en: Just like fully connected layers transform lists to lists, convolutional layers
    transform images into images. As a result, convolutional layers can be used to
    perform complex image transformations, such as applying artistic filters to images
    in photo apps.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 就像全连接层将列表转换为列表一样，卷积层将图像转换为图像。因此，卷积层可用于执行复杂的图像转换，例如在照片应用程序中应用艺术滤镜。
- en: '![images/depthcol.jpeg](assets/tfdl_0102.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![images/depthcol.jpeg](assets/tfdl_0102.png)'
- en: Figure 1-2\. A convolutional layer. The red shape on the left represents the
    input data, while the blue shape on the right represents the output. In this particular
    case, the input is of shape (32, 32, 3). That is, the input is a 32-pixel-by-32-pixel
    image with three RGB color channels. The highlighted region in the red input is
    a “local receptive field,” a group of inputs that are processed together to create
    the highlighted region in the blue output.
  id: totrans-19
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Recurrent Neural Network Layers
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Recurrent neural network (RNN) layers are primitives that allow neural networks
    to learn from sequences of inputs. This layer assumes that the input evolves from
    step to step following a defined update rule that can be learned from data. This
    update rule presents a prediction of the next state in the sequence given all
    the states that have come previously. An RNN is illustrated in [Figure 1-3](#ch1-rnn).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: An RNN layer can learn this update rule from data. As a result, RNNs are very
    useful for tasks such as language modeling, where engineers seek to build systems
    that can predict the next word users will type from history.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: '![images/rnn.jpg](assets/tfdl_0103.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
- en: Figure 1-3\. A recurrent neural network (RNN). Inputs are fed into the network
    at the bottom, and outputs extracted at the top. W represents the learned transformation
    (shared at all timesteps). The network is represented conceptually on the left
    and is unrolled on the right to demonstrate how inputs from different timesteps
    are processed.
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Long Short-Term Memory Cells
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The RNN layers presented in the previous section are capable of learning arbitrary
    sequence-update rules in theory. In practice, however, such layers are incapable
    of learning influences from the distant past. Such distant influences are crucial
    for performing solid language modeling since the meaning of a complex sentence
    can depend on the relationship between far-away words. The long short-term memory
    (LSTM) cell is a modification to the RNN layer that allows for signals from deeper
    in the past to make their way to the present. An LSTM cell is illustrated in [Figure 1-4](#ch1-lstm).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '![images/Long_Short_Term_Memory.png](assets/tfdl_0104.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
- en: Figure 1-4\. A long short-term memory (LSTM) cell. Internally, the LSTM cell
    has a set of specially designed operations that attain much of the learning power
    of the vanilla RNN while preserving influences from the past. Note that the illustration
    depicts one LSTM variant of many.
  id: totrans-28
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Deep Learning Architectures
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There have been hundreds of different deep learning models that combine the
    deep learning primitives presented in the previous section. Some of these architectures
    have been historically important. Others were the first presentations of novel
    designs that influenced perceptions of what deep learning could do.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we present a selection of different deep learning architectures
    that have proven influential for the research community. We want to emphasize
    that this is an episodic history that makes no attempt to be exhaustive. There
    are certainly important models in the literature that have not been presented
    here.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: LeNet
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The LeNet architecture is arguably the first prominent “deep” convolutional
    architecture. Introduced in 1988, it was used to perform optical character recoginition
    (OCR) for documents. Although it performed its task admirably, the computational
    cost of the LeNet was extreme for the computer hardware available at the time,
    so the design languished in (relative) obscurity for a few decades after its creation.
    This architecture is illustrated in [Figure 1-5](#ch1-lenet).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '![images/lenet_architecture.png](assets/tfdl_0105.png)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
- en: Figure 1-5\. The LeNet architecture for image processing. Introduced in 1988,
    it was arguably the first deep convolutional model for image processing.
  id: totrans-35
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: AlexNet
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The ImageNet Large Scale Visual Recognition Challenge (ILSVRC) was first organized
    in 2010 as a test of the progress made in visual recognition systems. The organizers
    made use of Amazon Mechanical Turk, an online platform to connect workers to requesters,
    to catalog a large collection of images with associated lists of objects present
    in the image. The use of Mechanical Turk permitted the curation of a collection
    of data significantly larger than those gathered previously.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: The first two years the challenge ran, more traditional machine-learned systems
    that relied on systems like HOG and SIFT features (hand-tuned visual feature extraction
    methods) triumphed. In 2012, the AlexNet architecture, based on a modification
    of LeNet run on powerful graphics processing units (GPUs), entered and dominated
    the challenge with error rates half that of the nearest competitors. This victory
    dramatically galvanized the (already nascent) trend toward deep learning architectures
    in computer vision. The AlexNet architecture is illustrated in [Figure 1-6](#ch1-lenet2).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: '![images/alexnet.jpg](assets/tfdl_0106.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
- en: Figure 1-6\. The AlexNet architecture for image processing. This architecture
    was the winning entry in the ILSVRC 2012 challenge and galvanized a resurgence
    of interest in convolutional architectures.
  id: totrans-40
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: ResNet
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since 2012, convolutional architectures consistently won the ILSVRC challenge
    (along with many other computer vision challenges). Each year the contest was
    held, the winning architecture increased in depth and complexity. The ResNet architecture,
    winner of the ILSVRC 2015 challenge, was particularly notable; ResNet architectures
    extended up to 130 layers deep, in contrast to the 8-layer AlexNet architecture.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: Very deep networks historically were challenging to learn; when networks grow
    this deep, they run into the vanishing gradients problem. Signals are attenuated
    as they progress through the network, leading to diminished learning. This attenuation
    can be explained mathematically, but the effect is that each additional layer
    multiplicatively reduces the strength of the signal, leading to caps on the effective
    depth of networks.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: 'The ResNet introduced an innovation that controlled this attenuation: the bypass
    connection. These connections allow part of the signal from deeper layers to pass
    through undiminished, enabling significantly deeper networks to be trained effectively.
    The ResNet bypass connection is illustrated in [Figure 1-7](#ch1-resnetcell).'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: '![images/resnetb.jpg](assets/tfdl_0107.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
- en: Figure 1-7\. The ResNet cell. The identity connection on the righthand side
    permits an unmodified version of the input to pass through the cell. This modification
    allows for the effective training of very deep convolutional architectures.
  id: totrans-46
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Neural Captioning Model
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As practitioners became more comfortable with the use of deep learning primitives,
    they experimented with mixing and matching primitive modules to create higher-order
    systems that could perform more complex tasks than basic object detection. Neural
    captioning systems automatically generate captions for the contents of images.
    They do so by combining a convolutional network, which extracts information from
    images, with an LSTM layer that generates a descriptive sentence for the image.
    The entire system is trained *end-to-end*. That is, the convolutional network
    and the LSTM network are trained together to achieve the desired goal of generating
    descriptive sentences for provided images.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: This end-to-end training is one of the key innovations powering modern deep
    learning systems since it lessens the need for complicated preprocessing of inputs.
    Image captioning models that don’t use deep learning would have to use complicated
    image featurization methods such as SIFT, which can’t be trained alongside the
    caption generator.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: A neural captioning model is illustrated in [Figure 1-8](#ch1-neuralcaption).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
- en: '![images/neural_captioning.png](assets/tfdl_0108.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
- en: Figure 1-8\. A neural captioning architecture. Relevant input features are extracted
    from the input image using a convolutional network. Then a recurrent network is
    used to generate a descriptive sentence.
  id: totrans-52
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-8。一个神经字幕架构。使用卷积网络从输入图像中提取相关的输入特征。然后使用递归网络生成一个描述性句子。
- en: Google Neural Machine Translation
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Google神经机器翻译
- en: Google’s neural machine translation (Google-NMT) system uses the paradigm of
    end-to-end training to build a production translation system, which takes sentences
    from the source language directly to the target language. The Google-NMT system
    depends on the fundamental building block of the LSTM, which it stacks over a
    dozen times and trains on an extremely large dataset of translated sentences.
    The final architecture provided for a breakthrough advance in machine-translation
    by cutting the gap between human and machine translations by up to 60%. The Google-NMT
    architecture is illustrated in [Figure 1-9](#ch1-gnmt).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌的神经机器翻译（Google-NMT）系统使用端到端训练的范例来构建一个生产翻译系统，直接将源语言的句子翻译成目标语言。Google-NMT系统依赖于LSTM的基本构建块，它将LSTM叠加了十几次，并在一个极其庞大的翻译句子数据集上进行训练。最终的架构通过将人类和机器翻译之间的差距缩小了多达60%，为机器翻译带来了突破性的进展。Google-NMT架构在[图1-9](#ch1-gnmt)中有所说明。
- en: '![images/google-nmt-lstm.png](assets/tfdl_0109.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![images/google-nmt-lstm.png](assets/tfdl_0109.png)'
- en: Figure 1-9\. The Google neural machine translation system uses a deep recurrent
    architecture to process the input sentence and a second deep recurrent architecture
    to generate the translated output sentence.
  id: totrans-56
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-9。Google神经机器翻译系统使用深度递归架构来处理输入句子，并使用第二个深度递归架构生成翻译后的输出句子。
- en: One-Shot Models
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一次性模型
- en: One-shot learning is perhaps the most interesting new idea in machine/deep learning.
    Most deep learning techniques typically require very large amounts of data to
    learn meaningful behavior. The AlexNet architecture, for example, made use of
    the large ILSVRC dataset to learn a visual object detector. However, much work
    in cognitive science has indicated that humans can learn complex concepts from
    just a few examples. Take the example of baby learning about giraffes for the
    first time. A baby shown a single giraffe at the zoo might be capable of learning
    to recognize all giraffes she sees from then on.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一次性学习可能是机器/深度学习中最有趣的新想法。大多数深度学习技术通常需要大量的数据来学习有意义的行为。例如，AlexNet架构利用大型ILSVRC数据集来学习视觉对象检测器。然而，认知科学的许多研究表明，人类可以从很少的例子中学习复杂的概念。以婴儿第一次了解长颈鹿为例。在动物园里看到一只长颈鹿的婴儿可能有能力从那时起认出她以后看到的所有长颈鹿。
- en: Recent progress in deep learning has started to invent architectures capable
    of similar learning feats. Given only a few examples of a concept (but given ample
    sources of side information), such systems can learn to make meaningful predictions
    with very few datapoints. One recent paper (by an author of this book) used this
    idea to demonstrate that one-shot architectures can learn even in contexts babies
    can’t, such as in medical drug discovery. A one-shot architecture for drug discovery
    is illustrated in [Figure 1-10](#ch1-oneshot).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的最新进展已经开始发明能够实现类似学习成就的架构。只给出一个概念的几个例子（但给出了丰富的附加信息来源），这样的系统可以学习在非常少的数据点上进行有意义的预测。最近的一篇论文（本书的作者之一）使用这个想法来证明一次性架构甚至可以在婴儿无法学习的情境中学习，比如在医药发现中。一种用于药物发现的一次性架构在[图1-10](#ch1-oneshot)中有所说明。
- en: '![images/schematic_v2.png](assets/tfdl_0110.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![images/schematic_v2.png](assets/tfdl_0110.png)'
- en: Figure 1-10\. The one-shot architecture uses a type of convolutional network
    to transform each molecule into a vector. The vector for styrene oxide is compared
    with vectors from the experimental dataset. The label for the most similar datapoint
    (tosylic acid) is imputed for the query.
  id: totrans-61
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-10。一次性架构使用一种卷积网络将每个分子转换为一个向量。对苯环氧的向量与实验数据集中的向量进行比较。最相似数据点的标签（对甲苯磺酸）被用于查询。
- en: AlphaGo
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AlphaGo
- en: Go is an ancient board game, widely influential in Asia. Computer Go has been
    a major challenge for computer science since the late 1960s. Techniques that enabled
    the computer chess system Deep Blue to beat chess grandmaster Garry Kasparov in
    1997 don’t scale to Go. Part of the issue is that Go has a much bigger board than
    chess; Go boards are of size 19 × 19 as opposed to 8 × 8 for chess. Since far
    more moves are possible per step, the game tree of possible Go moves expands much
    more quickly, rendering brute force search with contemporary computer hardware
    insufficient for adequate Go gameplay. [Figure 1-11](#ch1-goboard) illustrates
    a Go board.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 围棋是一种古老的棋盘游戏，在亚洲具有广泛的影响力。自20世纪60年代末以来，计算机围棋一直是计算机科学的一项重大挑战。使计算机国际象棋系统深蓝在1997年击败国际象棋大师加里·卡斯帕罗夫的技术并不适用于围棋。问题的一部分在于围棋的棋盘比国际象棋大得多；围棋棋盘的大小为19×19，而国际象棋为8×8。由于每步可能有更多的走法，可能的围棋走法树扩展得更快，使得使用当代计算机硬件进行
    brute force 搜索对于足够的围棋游戏来说是不够的。[图1-11](#ch1-goboard)展示了一个围棋棋盘。
- en: '![images/go_board.jpg](assets/tfdl_0111.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![images/go_board.jpg](assets/tfdl_0111.png)'
- en: Figure 1-11\. An illustration of a Go board. Players alternately place white
    and black pieces on a 19 × 19 grid.
  id: totrans-65
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-11。围棋棋盘的插图。玩家交替在一个19×19的网格上放置白色和黑色的棋子。
- en: Master level computer Go was finally achieved by AlphaGo from Google DeepMind.
    AlphaGo proved capable of defeating one of the world’s strongest Go champions,
    Lee Sedol, in a five-game match. Some of the key ideas from AlphaGo include the
    use of a deep value network and deep policy network. The value network provides
    an estimate of the value of a board position. Unlike chess, it’s very difficult
    to guess whether white or black is winning in Go from the board state. The value
    network solves this problem by learning to make this prediction from game outcomes.
    The policy network, on the other hand, helps estimate the best move to take given
    a current board state. The combination of these two techniques with Monte Carlo
    Tree search (a classical search method) helped overcome the large branching factor
    in Go games. The basic AlphaGo architecture is illustrated in [Figure 1-12](#ch1-goboard2).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌DeepMind的AlphaGo最终实现了大师级别的计算机围棋。AlphaGo证明了自己能够在五局比赛中击败世界上最强的围棋冠军李世石。AlphaGo的一些关键思想包括使用深度价值网络和深度策略网络。价值网络提供了对棋盘位置价值的估计。与国际象棋不同，从棋盘状态很难猜测黑白哪方正在赢得围棋比赛。价值网络通过学习从比赛结果中做出这种预测来解决这个问题。另一方面，策略网络帮助估计在当前棋盘状态下采取的最佳走法。这两种技术与蒙特卡洛树搜索（一种经典搜索方法）的结合帮助克服了围棋游戏中的大分支因子。基本的AlphaGo架构在[图1-12](#ch1-goboard2)中有所说明。
- en: '![images/value_policy.jpg](assets/tfdl_0112.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![images/value_policy.jpg](assets/tfdl_0112.png)'
- en: Figure 1-12\. A) Depiction of AlphaGo’s architecture. Initially a policy network
    to select moves is trained on a dataset of expert games. This policy is then refined
    by self-play. “RL” indicates reinforcement learning and “SL” indicates supervised
    learning. B) Both the policy and value networks operate on representations of
    the game board.
  id: totrans-68
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-12。A）AlphaGo架构的描述。最初，一个用于选择走法的策略网络在专家比赛数据集上进行训练。然后通过自我对弈来完善这个策略。“RL”表示强化学习，“SL”表示监督学习。B）策略网络和价值网络都在游戏棋盘的表示上运行。
- en: Generative Adversarial Networks
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成对抗网络
- en: Generative adversarial networks (GANs) are a new type of deep network that uses
    two competing neural networks, the generator and the adversary (also called the
    discriminator), which duel against each other. The generator tries to draw samples
    from a training distribution (for example, tries to generate realistic images
    of birds). The discriminator works on differentiating samples drawn from the generator
    from true data samples. (Is a particular bird a real image or generator-created?)
    This “adversarial” training for GANs seems capable of generating image samples
    of considerably higher fidelity than other techniques and may be useful for training
    effective discriminators with limited data. A GAN architecture is illustrated
    in [Figure 1-13](#ch1-gan).
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 生成对抗网络（GANs）是一种新型的深度网络，使用两个相互竞争的神经网络，生成器和对手（也称为鉴别器），它们相互对抗。生成器试图从训练分布中抽取样本（例如，尝试生成逼真的鸟类图像）。鉴别器则致力于区分从生成器抽取的样本和真实数据样本。（特定的鸟类是真实图像还是生成器创建的？）这种GAN的“对抗”训练似乎能够生成比其他技术更高保真度的图像样本，并且可能有助于使用有限数据训练有效的鉴别器。GAN架构在[图1-13](#ch1-gan)中有所说明。
- en: '![images/gen_adv.jpg](assets/tfdl_0113.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![images/gen_adv.jpg](assets/tfdl_0113.png)'
- en: Figure 1-13\. A conceptual depiction of a generative adversarial network (GAN).
  id: totrans-72
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-13。生成对抗网络（GAN）的概念描述。
- en: GANs have proven capable of generating very realistic images, and will likely
    power the next generation of computer graphics tools. Samples from such systems
    are now approaching photorealism. However, many theoretical and practical caveats
    still remain to be worked out with these systems and much research is still needed.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: GAN已经证明能够生成非常逼真的图像，并可能推动下一代计算机图形工具的发展。这些系统生成的样本现在接近照片级逼真。然而，这些系统仍然存在许多理论和实际的问题需要解决，仍然需要进行大量的研究。
- en: Neural Turing Machines
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 神经图灵机
- en: Most of the deep learning systems presented so far have learned complex functions
    with limited domains of applicability; for example, object detection, image captioning,
    machine translation, or Go game-play. But, could we perhaps have deep architectures
    that learn general algorithmic concepts such as sorting, addition, or multiplication?
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，所提出的大多数深度学习系统学习了具有有限适用领域的复杂函数；例如，目标检测、图像描述、机器翻译或围棋对弈。但是，我们是否可以有学习排序、加法或乘法等一般算法概念的深度架构呢？
- en: The Neural Turing machine (NTM) is a first attempt at making a deep learning
    architecture capable of learning arbitrary algorithms. This architecture adds
    an external memory bank to an LSTM-like system, to allow the deep architecture
    to make use of scratch space to compute more sophisticated functions. At the moment,
    NTM-like architectures are still quite limited, and only capable of learning simple
    algorithms. Nevertheless, NTM methods remain an active area of research and future
    advances may transform these early demonstrations into practical learning tools.
    The NTM architecture is conceptually illustrated in [Figure 1-14](#ch1-ntm2).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 神经图灵机（NTM）是第一次尝试制作一个能够学习任意算法的深度学习架构。该架构向类似LSTM的系统添加了一个外部存储器，以允许深度架构利用临时空间来计算更复杂的函数。目前，类似NTM的架构仍然相当有限，只能学习简单的算法。然而，NTM方法仍然是一个活跃的研究领域，未来的进展可能会将这些早期的演示转变为实用的学习工具。NTM架构在[图1-14](#ch1-ntm2)中有所说明。
- en: '![images/neural-turing-machine-tutorial.jpg](assets/tfdl_0114.png)'
  id: totrans-77
  prefs: []
  type: TYPE_IMG
  zh: '![images/neural-turing-machine-tutorial.jpg](assets/tfdl_0114.png)'
- en: Figure 1-14\. A conceptual depiction of a Neural Turing machine. It adds an
    external memory bank to which the deep architecture reads and writes.
  id: totrans-78
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-14。神经图灵机的概念描述。它添加了一个外部存储器，深度架构可以读取和写入其中。
- en: Deep Learning Frameworks
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习框架
- en: Researchers have been implementing software packages to facilitate the construction
    of neural network (deep learning) architectures for decades. Until the last few
    years, these systems were mostly special purpose and only used within an academic
    group. This lack of standardized, industrial-strength software made it difficult
    for non-experts to use neural networks extensively.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 研究人员几十年来一直在实施软件包，以便更容易地构建神经网络（深度学习）架构。直到最近几年，这些系统大多是专用的，仅在学术团体内部使用。这种缺乏标准化的、工业强度的软件使得非专家难以广泛使用神经网络。
- en: This situation has changed dramatically over the last few years. Google implemented
    the DistBelief system in 2012 and made use of it to construct and deploy many
    simpler deep learning architectures. The advent of DistBelief, and similar packages
    such as Caffe, Theano, Torch, Keras, MxNet, and so on have widely spurred industry
    adoption.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这种情况在过去几年发生了巨大变化。谷歌在2012年实施了DistBelief系统，并利用它构建和部署了许多更简单的深度学习架构。DistBelief的出现，以及类似的软件包如Caffe、Theano、Torch、Keras、MxNet等广泛推动了行业的采用。
- en: TensorFlow draws upon this rich intellectual history, and builds upon some of
    these packages (Theano in particular) for design principles. TensorFlow (and Theano)
    in particular use the concept of tensors as the fundamental underlying primitive
    powering deep learning systems. This focus on tensors distinguishes these packages
    from systems such as DistBelief or Caffe, which don’t allow the same flexibility
    for building sophisticated models.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow借鉴了这一丰富的知识历史，并基于其中一些软件包（特别是Theano）的设计原则进行了构建。TensorFlow（和Theano）特别使用张量的概念作为支持深度学习系统的基本基元。这种对张量的关注使这些软件包与DistBelief或Caffe等系统有所区别，后者不允许为构建复杂模型提供相同的灵活性。
- en: While the rest of this book will focus on TensorFlow, understanding the underlying
    principles should enable you to take the lessons learned and apply them with little
    difficulty to alternative deep learning frameworks.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本书的其余部分将专注于TensorFlow，但理解其基本原理应该使您能够轻松地将所学到的经验应用于其他深度学习框架。
- en: Limitations of TensorFlow
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TensorFlow的局限性
- en: One of the major current weaknesses of TensorFlow is that constructing a new
    deep learning architecture is relatively slow (on the order of multiple seconds
    to initialize an architecture). As a result, it’s not convenient in TensorFlow
    to construct some sophisticated deep architectures that change their structure
    dynamically. One such architecture is the TreeLSTM, which uses syntactic parse
    trees of English sentences to perform tasks that require understanding of natural
    language. Since each sentence has a different parse tree, each sentence requires
    a slightly different architecture. [Figure 1-15](#ch1-ntm) illustrates the TreeLSTM
    architecture.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow目前的一个主要弱点是构建新的深度学习架构相对较慢（初始化一个架构需要几秒钟的时间）。因此，在TensorFlow中构建一些动态改变结构的复杂深度架构并不方便。其中一种架构是TreeLSTM，它利用英语句子的句法解析树执行需要理解自然语言的任务。由于每个句子都有不同的解析树，因此每个句子需要稍微不同的架构。[图1-15](#ch1-ntm)展示了TreeLSTM架构。
- en: '![images/treelstm.png](assets/tfdl_0115.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![images/treelstm.png](assets/tfdl_0115.png)'
- en: Figure 1-15\. A conceptual depiction of a TreeLSTM architecture. The shape of
    the tree is different for each input datapoint, so a different computational graph
    must be constructed for each example.
  id: totrans-87
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图1-15。TreeLSTM架构的概念描述。每个输入数据点的树形状都不同，因此必须为每个示例构建不同的计算图。
- en: While such models can be implemented in TensorFlow, doing so requires significant
    ingenuity due to the limitations of the current TensorFlow API. New frameworks
    such as Chainer, DyNet, and PyTorch promise to remove these barriers by making
    the construction of new architectures lightweight enough so that models like the
    TreeLSTM can be constructed easily. Luckily, TensorFlow developers are already
    working on extensions to the base TensorFlow API (such as TensorFlow Eager) that
    will enable easier construction of dynamic architectures.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然这样的模型可以在TensorFlow中实现，但由于当前TensorFlow API的限制，这样做需要相当大的创造力。新的框架如Chainer、DyNet和PyTorch承诺通过使构建新架构足够轻便，以便像TreeLSTM这样的模型可以轻松构建来消除这些障碍。幸运的是，TensorFlow开发人员已经在扩展基本TensorFlow
    API（如TensorFlow Eager）上进行了工作，这将使动态架构的构建更加容易。
- en: One takeaway is that progress in deep learning frameworks is rapid, and today’s
    novel system can be tomorrow’s old news. However, the fundamental principles of
    the underlying tensor calculus date back centuries, and will stand readers in
    good stead regardless of future changes in programming models. This book will
    emphasize using TensorFlow as a vehicle for developing an intuitive knowledge
    of the underlying tensor calculus.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 一个要点是，深度学习框架的进展是迅速的，今天的新系统可能会成为明天的老旧消息。然而，底层张量计算的基本原理可以追溯到几个世纪前，并且无论未来编程模型如何变化，都将使读者受益匪浅。本书将强调使用TensorFlow作为开发对底层张量计算的直观了解的工具。
- en: Review
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回顾
- en: In this chapter, we’ve explained why deep learning is a subject of critical
    importance for the modern software engineer and taken a whirlwind tour of a number
    of deep architectures. In the next chapter, we will start exploring TensorFlow,
    Google’s framework for constructing and training deep architectures. In the chapters
    after that, we will dive deep into a number of practical examples of deep architectures.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们解释了为什么深度学习对现代软件工程师至关重要，并快速浏览了许多深度架构。在下一章中，我们将开始探索TensorFlow，谷歌用于构建和训练深度架构的框架。在接下来的章节中，我们将深入探讨一些深度架构的实际示例。
- en: Machine learning (and deep learning in particular), like much of computer science,
    is a very empirical discipline. It’s only really possible to understand deep learning
    through significant practical experience. For that reason, we’ve included a number
    of in-depth case studies throughout the remainder of this book. We encourage you
    to delve into these examples and to get your hands dirty experimenting with your
    own ideas using TensorFlow. It’s never enough to understand algorithms only theoretically!
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（尤其是深度学习），就像计算机科学的大部分领域一样，是一门非常经验主义的学科。只有通过大量的实践经验才能真正理解深度学习。因此，在本书的剩余部分中，我们包含了许多深入的案例研究。我们鼓励您深入研究这些例子，并动手尝试使用TensorFlow实验您自己的想法。仅仅理论上理解算法是远远不够的！
