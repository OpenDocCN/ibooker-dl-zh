["```py\nimport torch\n\ndef create_sliding_windows(data, window_size, shift=1):\n    # Convert input to tensor if it isn't already\n    if not isinstance(data, torch.Tensor):\n        data = torch.tensor(data)\n\n    # Calculate number of valid windows\n    n = len(data)\n    num_windows = max(0, (n – window_size) // shift + 1)\n\n    # Create strided view of data\n    windows = data.unfold(0, window_size, shift)\n\n    return windows\n\n# Example usage:\ndata = torch.arange(10)\nwindows = create_sliding_windows(data, window_size=5, shift=1)\n\n# Print each window\nfor window in windows:\n    print(window.numpy())\n\n```", "```py\n[0 1 2 3 4]\n[1 2 3 4 5]\n[2 3 4 5 6]\n[3 4 5 6 7]\n[4 5 6 7 8]\n[5 6 7 8 9]\n\n```", "```py\nimport torch\n\ndef create_sliding_windows_with_target(data, window_size, shift=1):\n    # Convert input to tensor if it isn't already\n    if not isinstance(data, torch.Tensor):\n        data = torch.tensor(data, dtype=torch.float32)\n\n    # Create windows using unfold\n    windows = data.unfold(0, window_size, shift)\n\n    # Split each window into features\n    features = windows[:, :–1]  # All elements except the last\n    targets = windows[:, –1:]   # Just the last element\n\n    return features, targets\n\n# Example usage:\ndata = torch.arange(10)\nfeatures, targets = create_sliding_windows_with_target(data, window_size=5, \n                                                             shift=1)\n\n# Print each window's features and target\nfor x, y in zip(features, targets):\n    print(f\"Features: {x.numpy()}, Target: {y.numpy()}\")\n\n```", "```py\n[0 1 2 3] [4]\n[1 2 3 4] [5]\n[2 3 4 5] [6]\n[3 4 5 6] [7]\n[4 5 6 7] [8]\n[5 6 7 8] [9]\n```", "```py\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# Create dataset\ndata = torch.arange(10)\nfeatures, targets = create_sliding_windows_with_target(data, window_size=5, \n                                                             shift=1)\n\n# Combine features and targets into a dataset\ndataset = TensorDataset(features, targets)\n\n# Create DataLoader with shuffling and batching\nbatch_size = 2\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Example iteration\nfor batch_features, batch_targets in dataloader:\n    print(f\"Batch features shape: {batch_features.shape}\")\n    print(f\"Features:\\n{batch_features}\")\n    print(f\"Targets:\\n{batch_targets}\\n\")\n\n```", "```py\ntensor([[5, 6, 7, 8],\n        [0, 1, 2, 3]])\nTargets:\ntensor([[9],\n        [4]])\n\nFeatures:\ntensor([[1, 2, 3, 4],\n        [3, 4, 5, 6]])\nTargets:\ntensor([[5],\n        [7]])\n\nFeatures:\ntensor([[4, 5, 6, 7],\n        [2, 3, 4, 5]])\nTargets:\ntensor([[8],\n        [6]])\n\n```", "```py\nimport numpy as np\ndef trend(time, slope=0):\n    return slope * time\n\ndef seasonal_pattern(season_time):\n    return np.where(season_time < 0.4,\n                    np.cos(season_time * 2 * np.pi),\n                    1 / np.exp(3 * season_time))\n\ndef seasonality(time, period, amplitude=1, phase=0):\n    season_time = ((time + phase) % period) / period\n    return amplitude * seasonal_pattern(season_time)\n\ndef noise(time, noise_level=1, seed=None):\n    rnd = np.random.RandomState(seed)\n    return rnd.randn(len(time)) * noise_level\n\ntime = np.arange(4 * 365 + 1, dtype=\"float32\")\nseries = trend(time, 0.1)\nbaseline = 10\namplitude = 20\nslope = 0.09\nnoise_level = 5\n\nseries = baseline + trend(time, slope)\nseries += seasonality(time, period=365, amplitude=amplitude)\nseries += noise(time, noise_level, seed=42)\n\n```", "```py\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\n\n# Convert the numpy series to a PyTorch tensor\nseries_tensor = torch.tensor(series, dtype=torch.float32)\n\n# Create windowed dataset with 30-day windows (predicting next day)\nwindow_size = 30\nfeatures, targets = create_sliding_windows_with_target(\n    series_tensor, window_size=window_size, shift=1)\n\n# Create PyTorch Dataset and DataLoader\ndataset = TensorDataset(features, targets)\nbatch_size = 32\ntrain_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Print some information about the dataset\nprint(f\"Series length: {len(series)}\")\nprint(f\"Number of windows: {len(features)}\")\nprint(f\"Feature shape: {features.shape}\")  # Should be (num_windows, \n                                                        window_size-1)\nprint(f\"Target shape: {targets.shape}\")    # Should be (num_windows, 1)\n\n# Show a few examples\nprint(\"\\nFirst few windows:\")\nfor i in range(3):\n    print(f\"\\nWindow {i+1}:\")\n    print(f\"Features (previous {window_size-1} days): {features[i].numpy()}\")\n    print(f\"Target (next day): {targets[i].item():.2f}\")\n```", "```py\nSeries length: 1461\nNumber of windows: 1432\nFeature shape: torch.Size([1432, 29])\nTarget shape: torch.Size([1432, 1])\n\nFirst few windows:\n\nWindow 1:\nFeatures (previous 29 days): [32.48357  29.395714 33.40659  37.858486 \n 29.14184  29.20528  38.32948  34.322147 28.183279 33.283253 28.287313 \n 28.303862 31.864614 21.104889 22.057411 27.875519 25.622026 32.25094  \n 26.127428 23.588236 37.95459  29.468477 30.900469 23.39905  27.755371 \n 30.980967 24.615065 32.186863 27.23822 ]\nTarget (next day): 28.71\n\nWindow 2:\nFeatures (previous 29 days): [29.395714 33.40659  37.858486 29.14184  \n 29.20528  38.32948  34.322147 28.183279 33.283253 28.287313 28.303862 \n 31.864614 21.104889 22.057411 27.875519 25.622026 32.25094  26.127428 \n 23.588236 37.95459  29.468477 30.900469 23.39905  27.755371 30.980967 \n 24.615065 32.186863 27.23822  28.710733]\nTarget (next day): 27.08\n\nWindow 3:\nFeatures (previous 29 days): [33.40659  37.858486 29.14184  29.20528  \n 38.32948  34.322147 28.183279 33.283253 28.287313 28.303862 31.864614 \n 21.104889 22.057411 27.875519 25.622026 32.25094  26.127428 23.588236 \n 37.95459  29.468477 30.900469 23.39905  27.755371 30.980967 24.615065 \n 32.186863 27.23822  28.710733 27.083256]\nTarget (next day): 39.27\n```", "```py\ntrain_size = 1000 \ntotal_windows = len(full_dataset)\ntrain_indices = list(range(train_size))\nval_indices = list(range(train_size, total_windows))\n\n# Create training and validation datasets using Subset\ntrain_dataset = Subset(full_dataset, train_indices)\nval_dataset = Subset(full_dataset, val_indices)\n\n# Create DataLoaders\nbatch_size = 32\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n```", "```py\nfeatures, target = train_dataset[0]\nprint(\"First window:\")\nprint(f\"Features shape: {features.shape}\")\nprint(f\"Features: {features.numpy()}\")\nprint(f\"Target: {target.item()}\\n\")\n\n```", "```py\nFirst window:\nFeatures shape: torch.Size([29])\nFeatures: [32.48357  29.395714 33.40659  37.858486 29.14184  29.20528  38.32948\n 34.322147 28.183279 33.283253 28.287313 28.303862 31.864614 21.104889\n 22.057411 27.875519 25.622026 32.25094  26.127428 23.588236 37.95459\n 29.468477 30.900469 23.39905  27.755371 30.980967 24.615065 32.186863\n 27.23822 ]\nTarget: 28.71073341369629\n\n```", "```py\n# Define the model\nclass TimeSeriesModel(nn.Module):\n    def __init__(self, window_size):\n        super(TimeSeriesModel, self).__init__()\n        # window_size-1 because our features are window_size-1\n        self.network = nn.Sequential(\n            nn.Linear(window_size-1, 10),  \n            nn.ReLU(),\n            nn.Linear(10, 10),\n            nn.ReLU(),\n            nn.Linear(10, 1)\n        )\n\n    def forward(self, x):\n        return self.network(x)\n\n```", "```py\n# Initialize model, loss function, and optimizer\nmodel = TimeSeriesModel(window_size)\ncriterion = nn.MSELoss()\noptimizer = optim.Adam(model.parameters())\n```", "```py\nfor batch_features, batch_targets in train_loader:\n    batch_features = batch_features.to(device)\n    batch_targets = batch_targets.to(device)\n\n    # Forward pass\n    outputs = model(batch_features)\n    loss = criterion(outputs, batch_targets)\n\n    # Backward pass and optimize\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    train_loss += loss.item()\n```", "```py\n# Validation phase\nmodel.eval()\nval_loss = 0\nwith torch.no_grad():\n    for batch_features, batch_targets in val_loader:\n        batch_features = batch_features.to(device)\n        batch_targets = batch_targets.to(device)\n\n        outputs = model(batch_features)\n        val_loss += criterion(outputs, batch_targets).item()\n\n# Calculate average losses\ntrain_loss /= len(train_loader)\nval_loss /= len(val_loader)\n\ntrain_losses.append(train_loss)\nval_losses.append(val_loss)\n```", "```py\nfor batch_features, batch_targets in val_loader:\n    batch_features = batch_features.to(device)\n    predictions = model(batch_features)\n    val_predictions.extend(predictions.cpu().numpy())\n    val_targets.extend(batch_targets.numpy())\n```", "```py\n# Make predictions\nmodel.eval()\nwith torch.no_grad():\n    # Get predictions for validation set\n    val_predictions = []\n    val_targets = []\n    for batch_features, batch_targets in val_loader:\n        batch_features = batch_features.to(device)\n        outputs = model(batch_features)\n        val_predictions.extend(outputs.cpu().numpy())\n        val_targets.extend(batch_targets.numpy())\n\n# Plot predictions vs actual for validation set\nplt.figure(figsize=(15, 6))\nplt.plot(val_targets, label='Actual', color=\"lightgrey\")\nplt.plot(val_predictions, label='Predicted', color=\"red\")\nplt.title('Predictions vs Actual Values (Validation Set)')\nplt.xlabel('Time')\nplt.ylabel('Value')\nplt.legend()\nplt.grid(True)\nplt.show()\n```", "```py\nval_predictions_tensor = torch.tensor(val_predictions)\nval_targets_tensor = torch.tensor(val_targets)\nmae_torch = torch.mean(torch.abs(\n                       val_predictions_tensor – val_targets_tensor))\nprint(f\"Validation MAE (PyTorch): {mae_torch:.4f}\")\n\n```", "```py\noptimizer = optim.Adam(model.parameters())\n```", "```py\noptimizer = optim.Adam(model.parameters(), lr=0.01) \n```", "```py\nscheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n```"]