["```py\nconda install -c anaconda flask\npip install flask\n```", "```py\nfrom torchvision import models\n\nCatfishClasses = [\"cat\",\"fish\"]\n\nCatfishModel = models.ResNet50()\nCatfishModel.fc = nn.Sequential(nn.Linear(transfer_model.fc.in_features,500),\n                  nn.ReLU(),\n                  nn.Dropout(), nn.Linear(500,2))\n```", "```py\nfrom flask import Flask, jsonify\nfrom . import CatfishModel\nfrom torchvision import transforms\nimport torch\nimport os\n\ndef load_model():\n  return model\n\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef status():\n  return jsonify({\"status\": \"ok\"})\n\n@app.route(\"/predict\", methods=['GET', 'POST'])\ndef predict():\n  img_url = request.image_url\n  img_tensor = open_image(BytesIO(response.content))\n  prediction = model(img_tensor)\n  predicted_class = CatfishClasses[torch.argmax(prediction)]\n  return jsonify({\"image\": img_url, \"prediction\": predicted_class})\n\nif __name__ == '__main__':\n  app.run(host=os.environ[\"CATFISH_HOST\"], port=os.environ[\"CATFISH_PORT\"])\n```", "```py\nCATFISH_HOST=127.0.0.1 CATFISH_PORT=8080 python catfish_server.py\n```", "```py\ndef load_model():\n  m = CatfishModel()\n  location = os.environ[\"CATFISH_MODEL_LOCATION\"]\n  m.load_state_dict(torch.load(location))\n  return m\n```", "```py\nexport CATFISH_MODEL_LOCATION=catfishweights.pt\n```", "```py\nFROM continuumio/miniconda3:latest\n\nARG model_parameter_location\nARG model_parameter_name\nARG port\nARG host\n\nENV CATFISH_PORT=$port\nENV CATFISH_HOST=$host\nENV CATFISH_MODEL_LOCATION=/app/$model_parameter_name\n\nRUN conda install -y flask \\\n  && conda install -c pytorch  torchvision \\\n  && conda install waitress\nRUN mkdir -p /app\n\nCOPY ./model.py /app\nCOPY ./server.py /app\nCOPY $model_location/$model_weights_name /app/\nCOPY ./run-model-service.sh /\n\nEXPOSE $port\n\nENTRYPOINT [\"/run-model-service.sh\"]\n```", "```py\n#!/bin/bash\n#run-model-service.sh\ncd /app\nwaitress-serve --call 'catfish_server:create_app'\n```", "```py\ndocker build -t catfish-service .\n```", "```py\n>docker images\nREPOSITORY               TAG                            IMAGE ID\ncatfish-service          latest                         e5de5ad808b6\n```", "```py\ndocker run catfish-service -p 5000:5000\n```", "```py\nls -l\ntotal 641504\n-rw------- 1 ian ian 178728960 Feb  4  2018 resnet101-5d3b4d8f.pth\n-rw------- 1 ian ian 241530880 Feb 18  2018 resnet152-b121ed2d.pth\n-rw------- 1 ian ian  46827520 Sep 10  2017 resnet18-5c106cde.pth\n-rw------- 1 ian ian  87306240 Dec 23  2017 resnet34-333f7ec4.pth\n-rw------- 1 ian ian 102502400 Oct  1  2017 resnet50-19c8e357.pth\n```", "```py\nfrom urllib.request import urlopen\nfrom shutil import copyfileobj\nfrom tempfile import NamedTemporaryFile\n\ndef load_model():\n  m = CatfishModel()\n  parameter_url = os.environ[\"CATFISH_MODEL_LOCATION\"]\n  with urlopen(url) as fsrc, NamedTemporaryFile() as fdst:\n    copyfileobj(fsrc, fdst)\n    m.load_state_dict(torch.load(fdst))\n  return m\n```", "```py\nFROM continuumio/miniconda3:latest\n\nARG port\nARG host\n\nENV CATFISH_PORT=$port\nRUN conda install -y flask \\\n  && conda install -c pytorch torch torchvision \\\n  && conda install waitress\nRUN mkdir -p /app\n\nCOPY ./model.py /app\nCOPY ./server.py /app\nCOPY ./run-model-service.sh /\n\nEXPOSE $port\n\nENTRYPOINT [\"/run-model-service.sh\"]\n```", "```py\ndocker run catfish-service --env CATFISH_MODEL_LOCATION=[URL]\n```", "```py\nimport uuid\nimport logging\nlogging.basicConfig(level=logging.INFO)\n\ndef predict():\n  img_url = request.image_url\n  img_tensor = open_image(BytesIO(response.content))\n  start_time = time.process_time()\n  prediction = model(img_tensor)\n  end_time = time.process_time()\n  predicted_class = CatfishClasses[torch.argmax(prediction)]\n  send_to_log(\n    {\"image\": img_url,\n    \"prediction\": predicted_class},\n    \"predict_tensor\": prediction,\n    \"img_tensor\": img_tensor,\n    \"predict_time\": end_time-start_time,\n    \"uuid\":uuid.uuid4()\n    })\n  return jsonify({\"image\": img_url, \"prediction\": predicted_class})\n\ndef send_to_log(log_line):\n  logger.info(log_line)\n```", "```py\ngcloud login\ngcloud components install kubectl\n```", "```py\ngcloud projects create ml-k8s --set-as-default\n```", "```py\ndocker build -t gcr.io/ml-k8s/catfish-service:v1 .\ngcloud auth configure-docker\ndocker push gcr.io/ml-k8s/catfish-service:v1\n```", "```py\ngcloud container clusters create ml-cluster --num-nodes=2\n```", "```py\nkubectl run catfish-service\n--image=gcr.io/ml-k8s/catfish-service:v1\n--port 5000\n--env CATFISH_MODEL_LOCATION=[URL]\n```", "```py\nNAME                                  READY STATUS  RESTARTS  AGE\ngcr.io/ml-k8s/catfish-service:v1      1/1   Running 0 4m15s\n```", "```py\nkubectl expose deployment catfish-service\n--type=LoadBalancer\n--port 80\n--target-port 5000\n```", "```py\nkubectl get service\n\nNAME               CLUSTER-IP      EXTERNAL-IP     PORT(S)          AGE\ncatfish-service    10.3.251.122    203.0.113.0     80:30877/TCP     3d\n```", "```py\nkubectl logs catfish-service-xxdsd\n>> log response\n```", "```py\nkubectl scale deployment hello-web --replicas=3\n```", "```py\nkubectl delete pod [PODNAME]\nkubectl get pods\n```", "```py\ndocker build -t gcr.io/ml-k8s/catfish-service:v2 .\ndocker push gcr.io/ml-k8s/catfish-service:v2\n```", "```py\nkubectl set image deployment/catfish-service\n  catfish-service=gcr.io/ml-k8s/catfish-service:v2\n```", "```py\nkubectl delete service catfish-service\ngcloud container clusters delete ml-k8s\n```", "```py\nmodel = torchvision.models.AlexNet()\ntraced_model = torch.jit.trace(model,\n                torch.rand(1, 3, 224, 224))\n```", "```py\nTracerWarning: Trace had nondeterministic nodes. Nodes:\n%input.15 :\nFloat(1, 9216) = aten::dropout(%input.14, %174, %175),\nscope: AlexNet/Sequential[classifier]/Dropout[0]\n%input.18 :\nFloat(1, 4096) = aten::dropout(%input.17, %184, %185),\nscope: AlexNet/Sequential[classifier]/Dropout[3]\n\nThis may cause errors in trace checking.\nTo disable trace checking, pass check_trace=False to torch.jit.trace()\n\n_check_trace([example_inputs], func, executor_options,\nmodule, check_tolerance, _force_outplace)\n/home/ian/anaconda3/lib/\npython3.6/site-packages/torch/jit/__init__.py:642:\nTracerWarning: Output nr 1. of the traced function does not\nmatch the corresponding output of the Python function. Detailed error:\n\nNot within tolerance rtol=1e-05 atol=1e-05 at input[0, 22]\n(0.010976361110806465 vs. -0.005604125093668699)\nand 996 other locations (99.00%)\n_check_trace([example_inputs], func,\nexecutor_options, module, check_tolerance\n_force_outplace)\n```", "```py\nprint(traced_model)\n\nTracedModule[AlexNet](\n(features): TracedModule[Sequential](\n  (0): TracedModule[Conv2d]()\n  (1): TracedModule[ReLU]()\n  (2): TracedModule[MaxPool2d]()\n  (3): TracedModule[Conv2d]()\n  (4): TracedModule[ReLU]()\n  (5): TracedModule[MaxPool2d]()\n  (6): TracedModule[Conv2d]()\n  (7): TracedModule[ReLU]()\n  (8): TracedModule[Conv2d]()\n  (9): TracedModule[ReLU]()\n  (10): TracedModule[Conv2d]()\n  (11): TracedModule[ReLU]()\n  (12): TracedModule[MaxPool2d]()\n)\n(classifier): TracedModule[Sequential](\n  (0): TracedModule[Dropout]()\n  (1): TracedModule[Linear]()\n  (2): TracedModule[ReLU]()\n  (3): TracedModule[Dropout]()\n  (4): TracedModule[Linear]()\n  (5): TracedModule[ReLU]()\n  (6): TracedModule[Linear]()\n  )\n)\n```", "```py\ndef forward(self,\n  input_1: Tensor) -> Tensor:\n  input_2 = torch._convolution(input_1, getattr(self.features, \"0\").weight,\n  getattr(self.features, \"0\").bias,\n  [4, 4], [2, 2], [1, 1], False, [0, 0], 1, False, False, True)\n  input_3 = torch.threshold_(input_2, 0., 0.)\n  input_4, _0 = torch.max_pool2d_with_indices\n  (input_3, [3, 3], [2, 2], [0, 0], [1, 1], False)\n  input_5 = torch._convolution(input_4, getattr\n  (self.features, \"3\").weight, getattr(self.features, \"3\").bias,\n  [1, 1], [2, 2], [1, 1], False, [0, 0], 1, False, False, True)\n  input_6 = torch.threshold_(input_5, 0., 0.)\n  input_7, _1 = torch.max_pool2d_with_indices\n  (input_6, [3, 3], [2, 2], [0, 0], [1, 1], False)\n  input_8 = torch._convolution(input_7, getattr(self.features, \"6\").weight,\n  getattr\n  (self.features, \"6\").bias,\n  [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True)\n  input_9 = torch.threshold_(input_8, 0., 0.)\n  input_10 = torch._convolution(input_9, getattr\n  (self.features, \"8\").weight, getattr(self.features, \"8\").bias,\n  [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True)\n  input_11 = torch.threshold_(input_10, 0., 0.)\n  input_12 = torch._convolution(input_11, getattr\n  (self.features, \"10\").weight, getattr(self.features, \"10\").bias,\n  [1, 1], [1, 1], [1, 1], False, [0, 0], 1, False, False, True)\n  input_13 = torch.threshold_(input_12, 0., 0.)\n  x, _2 = torch.max_pool2d_with_indices\n  (input_13, [3, 3], [2, 2], [0, 0], [1, 1], False)\n  _3 = ops.prim.NumToTensor(torch.size(x, 0))\n  input_14 = torch.view(x, [int(_3), 9216])\n  input_15 = torch.dropout(input_14, 0.5, False)\n  _4 = torch.t(getattr(self.classifier, \"1\").weight)\n  input_16 = torch.addmm(getattr(self.classifier, \"1\").bias,\n    input_15, _4, beta=1, alpha=1)\n  input_17 = torch.threshold_(input_16, 0., 0.)\n  input_18 = torch.dropout(input_17, 0.5, False)\n  _5 = torch.t(getattr(self.classifier, \"4\").weight)\n  input_19 = torch.addmm(getattr(self.classifier, \"4\").bias,\n    input_18, _5, beta=1, alpha=1)\n  input = torch.threshold_(input_19, 0., 0.)\n  _6 = torch.t(getattr(self.classifier, \"6\").weight)\n  _7 = torch.addmm(getattr(self.classifier, \"6\").bias, input,\n    _6, beta=1, alpha=1)\n  return _7\n```", "```py\ntorch.jit.save(traced_model, \"traced_model\")\n```", "```py\nimport torch\n\ndef example(x, y):\n  if x.min() > y.min():\n      r = x\n  else:\n      r = y\n  return r\n```", "```py\n@torch.jit.script\ndef example(x, y):\n    if x.min() > y.min():\n        r = x\n    else:\n        r = y\n    return r\n```", "```py\nclass FeaturesCNNNet(torch.jit.ScriptModule):\n    def __init__(self, num_classes=2):\n        super(FeaturesCNNNet, self).__init__()\n        self.features = torch.jit.trace(nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=3, stride=2)\n        ), torch.rand(1,3,224,224))\n\n    @torch.jit.script_method\n    def forward(self, x):\n        x = self.features(x)\n        return x\n```", "```py\ndef maybe_a_string_or_int(x):\n  if x > 3:\n    return \"bigger than 3!\"\n  else\n    return 2\n```", "```py\n@torch.jit.script\ndef add_int(x,y):\n  return x + y\n\nprint(add_int.code)\n>> def forward(self,\n  x: Tensor,\n  y: Tensor) -> Tensor:\n  return torch.add(x, y, alpha=1)\n```", "```py\n@torch.jit.script\ndef add_int(x: int, y: int) -> int:\n  return x + y\nprint(add_int.code)\n>> def forward(self,\n  x: int,\n  y: int) -> int:\nreturn torch.add(x, y)\n```", "```py\n@torch.jit.script\nclass BadClass:\n  def __init__(self, x)\n    self.x = x\n\n  def set_y(y)\n    self.y = y\n```", "```py\napt install cmake g++\n```", "```py\nyum install cmake g++\n```", "```py\n  wget https://download.pytorch.org/libtorch/cpu/libtorch-shared-with-deps-latest.zip\n```", "```py\ncmake_minimum_required(VERSION 3.0 FATAL_ERROR)\nproject(helloworld)\n\nfind_package(Torch REQUIRED)\n\nadd_executable(helloworld helloworld.cpp)\ntarget_link_libraries(helloworld \"${TORCH_LIBRARIES}\")\nset_property(TARGET helloword PROPERTY CXX_STANDARD 11)\n```", "```py\n#include <torch/torch.h>\n#include <iostream>\n\nint main() {\n  torch::Tensor tensor = torch::ones({2, 2});\n  std::cout << tensor << std::endl;\n}\n```", "```py\nmkdir build\ncd build\ncmake -DCMAKE_PREFIX_PATH=/absolute/path/to/libtorch ..\ncd ..\n```", "```py\nmake\n./helloworld\n\n1  1\n1  1\n[ Variable[CPUType]{2,2} ]\n```", "```py\ncnn_model = CNNNet()\ncnn_model.eval()\ncnn_traced = torch.jit.trace(cnn_model, torch.rand([1,3,224,224]))\ntorch.jit.save(cnn_traced, \"cnnnet\")\n```", "```py\ncmake_minimum_required(VERSION 3.0 FATAL_ERROR)\nproject(load-cnn)\n\nfind_package(Torch REQUIRED)\n\nadd_executable(load-cnn.cpp load-cnn.cpp)\ntarget_link_libraries(load-cnn \"${TORCH_LIBRARIES}\")\nset_property(TARGET load-cnn PROPERTY CXX_STANDARD 11)\n```", "```py\n#include <torch/script.h>\n#include <iostream>\n#include <memory>\n\nint main(int argc, const char* argv[]) {\n\n  std::shared_ptr<torch::jit::script::Module> module = torch::jit::load(\"cnnnet\");\n\n  assert(module != nullptr);\n  std::cout << \"model loaded ok\\n\";\n\n  // Create a vector of inputs.\n  std::vector<torch::jit::IValue> inputs;\n  inputs.push_back(torch::rand({1, 3, 224, 224}));\n\n  at::Tensor output = module->forward(inputs).toTensor();\n\n  std::cout << output << '\\n'\n}\n```", "```py\nmkdir build\ncd build\ncmake -DCMAKE_PREFIX_PATH=/absolute/path/to/libtorch ..\ncd ..\nmake\n./load-cnn\n\n0.1775\n0.9096\n[ Variable[CPUType]{2} ]\n```"]