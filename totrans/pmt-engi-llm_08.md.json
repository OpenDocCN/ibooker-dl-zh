["```py\n[{\"role\": \"system\", \"content\" : \"You are a helpful AI.”},\n```", "```py\n{\"role\": \"user\", \"content\" : \"I want to suggest to Fiona \nan idea for her next book to read.”\n```", "```py\nPlease ask any questions you need to arrive at an informed\nsuggestion.\"}, {\"role\": \"assistant\", \"content\" : \"Of course! \nThe following information might be useful: What books did \nshe read last?”},\n```", "```py\n{\"role\": \"user\", \"content\" : \"Harry Potter, Lioness \nRampant, Mr Lemoncello’s Library”},\n```", "```py\n{\"role\": \"assistant\", \"content\" : \"What did she post on \nsocial media recently?”}, {\"role\": \"user\", \"content\" : […]\n```", "```py\n{\"role\": \"assistant\", \"content\" : \"I believe this is all \nthe information I need to select a single best candidate \nbook suggestion.”},\n```", "```py\n{\"role\": \"user\", \"content\" : \"Excellent! So based on \nthis, which book should I suggest to her?”}]\n```", "```py).\n\n*   If you want to display model output to the user directly, Markdown is very easy to render.\n\n*   Markdown’s hyperlink feature allows the model to include links that are easy to parse, which can help you verify sources and retrieve content programmatically.\n\nAdditionally, it’s common to give a table of contents at the beginning of the Markdown file, and that can be quite useful. A table of contents can serve as a useful part of the introduction for a long prompt because it helps models orient themselves just as much as it helps people. It can also be a great tool for controlling the completion, in two ways:\n\n1.  For chain-of-thought prompting or managing overly verbose models, you can use a scratchpad approach. Adding sections like `# Ideas` or `# Analysis` before `# Conclusion` in the table of contents helps guide the model to a more informed conclusion while allowing you to ignore the earlier sections.\n\n2.  You can easily signal when the model’s response should end by adding a section like `# Appendix` or `# Further Reading` after the conclusion. Setting `# Further Reading` as a stop sequence ensures the model finishes its task, conserving compute resources.\n\nBoth use cases for the table of contents are demonstrated in [Figure 6-3](#ch06a_figure_3_1728442733835211). Note that since this is an example, the amount of context is less than what the model would need to give a proper answer to such a question. Also, LLMs aren’t oracles: with the appropriate context, a model can be a good tool for ideation, but there’s no reason its opinion should count for more than Jerry’s in Accounting.\n\n![A screenshot of a computer  Description automatically generated](assets/pefl_0603.png)\n\n###### Figure 6-3\\. A Markdown report using a table of contents (completion obtained using OpenAI’s text-davinci-003)\n\n## The Structured Document\n\nStructured documents follow a formal specification that allows you to make strong assumptions about the form of the completion. This makes parsing easier, including the parsing of complex outputs.\n\nA great example of this is found in Anthropic’s Artifacts prompt. Artifacts will come up again in the final chapter of this book, but for now, you should know that Artifacts are self-contained documents that the user and assistant collaborate on. Examples of Artifacts are Python scripts, small React apps, mermaid diagrams, and scalable vector graphics (SVG) diagrams. Artifacts are presented in the UI as text in a pane to the right of the conversation, and in the case of React, Mermaid, and SVG, they are rendered into functioning or visual prototypes.\n\nAn abridged version of the Artifacts prompt is shown in [Table 6-3](#ch06a_table_3_1728442733843157) ([this prompt was extracted by @elder_plinius](https://oreil.ly/Lwsp1)). To make Artifacts work, the prompt uses an XML document structure that clearly delineates the pieces of the interaction. The `artifacts_info` prompt holds the equivalent of the system message, explaining how artifacts work. It includes an `examples` section with several `example` blocks. Each example has a `user_query` and an `assistant_response`.\n\nThings get most interesting inside the `assistant_response`. First, the assistant starts its response, and then an `antThinking` block is injected so that the assistant can “think” about whether the user’s request should make use of an Artifact or just be handled as a normal conversation. If the decision is to use an Artifact, then the text will include an `antArtifact` block that contains the text of the Artifact. Notice that the `antArtifact` tag also includes attributes such as the title of the Artifact and the language used.\n\nTable 6-3\\. The Anthropic structured prompt used for generating Artifacts (abridged)\n\n| Prompt | `The assistant can create and reference Artifacts during conversations. Artifacts are for substantial, self-contained content that users might modify or reuse, and they are displayed in a separate UI window for clarity.``Here are some examples of correct usage of Artifacts by other AI assistants:` \n```", "```py\n\n`The assistant should always take care to not produce Artifacts that would be highly hazardous to human health or wellbeing if misused, even if is asked to produce them for seemingly benign reasons.``</artifacts_info>``Claude is now being connected with a human.``<user_query>`**`Can you help me create a Python script to factor a number into its prime factors?`**`</user_query>``<assistant_response>` |\n| Completion | `Sure! Here's a Python script that factors a number into its prime factors:``<antThinking>This code is self-contained and is likely to be reused or modified. Therefore, I'm creating a new Artifact.</antThinking>``<antArtifact identifier=\"prime-factor-script\"``type=\"application/vnd.ant.code\" language=\"python\"``title=\"Python script for factoring numbers into prime factors\"> def prime_factors(n):` \n```", "```py\n\n |\n\nAs a result of setting up this structured pattern in the prompt, it becomes much easier to parse out information from the response. In particular, `antThinking` is parsed out and hidden from the user, and `antArtifact` is extracted and placed into the Artifact pane, under the title specified in the attributes. (In [Chapter 7](ch07.html#ch07_taming_the_model_1728407187651669), we get into much more detail about how content can be extracted from the completions.)\n\nLike conversation transcripts, structured documents can come in many different formats. The Little Red Riding Hood principle suggests that you use formats that are readily available in training data. The most suitable formats are XML and YAML. Both are common in technical documents where precision is of the essence, and both can be used in many different domains. In both cases, the whole document is hierarchically ordered into normally named elements, which can have several subelements.\n\nIn [XML](https://oreil.ly/NvPU4) (see [Table 6-3](#ch06a_table_3_1728442733843157)), the document consists of a series of tags that are opened and closed. The tag may have attributes and has content that may contain subtags. Choose XML if your individual elements are relatively short, and if they are multiline, indentation doesn’t matter. But you might need to be careful about escape sequences: there are five in XML: `&quot` (“), `&apos` ('), `&lt` (<), `&gt` (>), and `&amp` (&). XML also allows you to add HTML-style comments as`<!-- this is a comment -->`, which can occasionally be useful for “editorial” hints for the model.\n\nIn [YAML](https://yaml.org), the document consists of a series of named fields or unnamed bullet points whose hierarchy levels are tracked by their indentation. This indentation tracking can be quite annoying because you need to get it right to be able to use standard parsers, but it’s helpful in cases where you need to be very precise about indentation, such as with code or formatted text. In particular, the syntax `fieldname: |2` opens a multiline text field that preserves indentation, as illustrated in [Figure 6-4](#ch06a_figure_4_1728442733835231). Note that in such text fields, you don’t need to escape anything, which is nice. You’ll notice that such a text field is finished by encountering a line with smaller indentation than the text field’s “zero” indentation. Also note that the highlight boxes indicate the value of the content fields, including leading whitespace.\n\n![](assets/pefl_0604.png)\n\n###### Figure 6-4\\. Text fields specifying indented content in YAML\n\nAnother markup language that should feature heavily in any LLM’s training set is JSON (or its variant, JSON Lines). At one point, we would have recommended against using JSON since it is very escape heavy and less readable. However, OpenAI in particular has put a lot of effort into making its models generate JSON accurately because JSON powers their tools API. Therefore, for OpenAI at least, JSON is still a reasonably good choice.\n\n# Formatting Snippets\n\nThe way you format snippet text depends a lot on your document. In an advice conversation transcript, you can format snippet information into the back-and-forth turns of the conversation. For instance, say your application retrieves this weather forecast data:\n\n```", "```py\n\nThat information can be packaged as the advice seeker asking a clarifying question and the assistant answering with the following information:\n\n```", "```py\n\nIn an analytic report, you normally want to state your knowledge in natural language. Results of API calls require you to know what the API returns, and then you can format the string into a sentence. Often, it’s useful to include the results of individual API calls as individual sections, like this:\n\n```", "```py\n\nFinally, if you use a structured document, your life is often easy: just serialize all relevant fields of the object you have in memory that represents your piece of knowledge:\n\n```", "```py\n\nNo matter what type of document you use, a useful form of communicating background context can be a pretty explicitly stated side remark (e.g., “As an aside, …”). For example, in GitHub Copilot code completions, where our document template was in the form of a source code file, we found we could usefully include code from other files using a code comment stating explicitly that some quoted snippet was included for comparison reasons, like so:\n\n```", "```py\n\nAn aside provides a strong hint to the model, but without requiring it to use the side remark in a certain way or at all.\n\nWhen formatting your snippets, the things to aim for are as follows:\n\nModularity\n\nYou want your snippets to be strings that can be inserted into or removed from the prompt with relative ease. Ideally, your document is like a list (a conversation with turns) or a tree (a report with hierarchical sections; a structured document), so that snippets are easier to handle as items in the list or leaves of the tree.\n\nNaturalness\n\nThe snippet should feel like an organic part of your document and be formatted as such. If you’re letting the LLM complete source code, any natural language information should be formatted as a comment rather than dumped between the code lines verbatim. If your document template is a conversation or a report, then data should be interpolated into a natural text that sounds appropriate for the document (see the preceding weather examples).\n\nBrevity\n\nIf you can communicate relevant context with fewer tokens, great!\n\nInertness\n\nYou’d like to compute the token length of a snippet only once, so the tokenization of one snippet shouldn’t affect the tokenization of the previous or next snippet.\n\n## More on Inertness\n\nThe last bit, inertness, depends on your tokenizer, which might use different tokens to tokenize a composite string A + B than to tokenize each string individually. That can easily increase or decrease the number of tokens needed to tokenize a composite string (see [Table 6-4](#ch06a_table_4_1728442733843184)).\n\nPasting strings together doesn’t mean the arrays of tokens just get concatenated. Token IDs have been obtained for OpenAI’s [GPT-3.5-and-later tokenizer](https://oreil.ly/Cu9Q4), but both examples also work for the [GPT-3-and-before tokenizer](https://oreil.ly/HyQNe) used in many non-OpenAI LLMs.\n\nTable 6-4\\. Token count isn’t additive\n\n|   | Example 1 | Example 2 |\n| --- | --- | --- |\n| Strings | “be” + “am” ➜ “beam” | “cat” + “tail” ➜ “cattail” |\n| Tokens | [be] + [am] ➜ [beam] | [cat] + [tail] ➜ [c], [att], [ail] |\n| Token ids | 1395 + 309 ➜ 54971 | 4719 + 14928 ➜ 66, 1617, 607 |\n| Token count | 1 + 1 ➜ 1 | 1 + 1 ➜ 3 |\n\nIt’s generally a good idea to separate individual prompt elements with whitespace to prevent them from merging unexpectedly. However, be aware of potential issues: GPT tokenizers often include tokens that start with a blank space but not ones that end with it. To avoid problems, prefer prompt elements that start with a space rather than ending with one. Additionally, GPT tokenizers combine multiple newline characters, so it’s best to ensure that your snippets either never start or never end with a newline. Avoiding newlines at the beginning of snippets is usually easier for app developers.\n\n## Formatting Few-Shot Examples\n\nWhen formatting snippets for few-shot examples, you usually have a choice. One option is to designate them explicitly as examples, as shown here:\n\n```"]