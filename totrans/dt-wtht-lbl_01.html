<html><head></head><body>

  <div class="readable-text" id="p1"> 
   <h1 class=" readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">1</span> </span> <span class="chapter-title-text">Introduction to machine learning</span></h1> 
  </div> 
  <div class="introduction-summary"> 
   <h3 class="introduction-header">This chapter covers</h3> 
   <ul> 
    <li class="readable-text" id="p2">An introduction to data, types of datasets, quality, and sources</li> 
    <li class="readable-text" id="p3">Machine learning and types of machine learning algorithms</li> 
    <li class="readable-text" id="p4">An overview of different types of algorithms</li> 
   </ul> 
  </div> 
  <div class="readable-text" id="p5"> 
   <blockquote>
    <div>
     There are only patterns, patterns on top of patterns, patterns that affect other patterns. Patterns hidden by patterns. Patterns within patterns.  
     <div class=" quote-cite">
       —Chuck Palahniuk 
     </div>
    </div>
   </blockquote> 
  </div> 
  <div class="readable-text" id="p6"> 
   <p>There is a saying going around: “Data is the new electricity.” Data is indeed transforming our world, much like electricity has; nobody can deny that. But like electricity, we must remember that data must be properly harnessed to utilize its value. We have to clean the data and analyze and visualize it, and only then can we develop insights from it. The fields of data science, machine learning (ML), and AI are helping us to better harness data and extract trends and patterns so we can make more insightful and balanced decisions in our activities and business. </p> 
  </div> 
  <div class="readable-text intended-text" id="p7"> 
   <p>In this book, we unravel the puzzles of data and see how we can find the patterns hidden within. We will be studying a branch of ML referred to as <em>unsupervised learning</em>. Unsupervised learning solutions are one of the most influential approaches and are changing the face of the industry. They are utilized in banking and finance, retail, insurance, manufacturing, aviation, medical sciences, telecom, and almost every other sector. </p> 
  </div> 
  <div class="readable-text intended-text" id="p8"> 
   <p>Throughout the book, we discuss concepts of ML with a focus on unsupervised learning—the building blocks of algorithms, their nuts and bolts, background processes, and mathematical foundation. We will examine concepts, study best practices, analyze common errors and pitfalls, and use a case study–based approach that complements the learning. At the same time, we develop actual Python code for solving such problems. All the codes are accompanied by step-by-step explanations and comments. </p> 
  </div> 
  <div class="readable-text intended-text" id="p9"> 
   <p>By the time you finish this book, you will have a very good understanding of unsupervised technique-based ML, various algorithms, the mathematics and statistical foundation on which the algorithm rests, business use cases, Python implementation, and best practices. </p> 
  </div> 
  <div class="readable-text intended-text" id="p10"> 
   <p>This first chapter is designed to introduce the concepts of ML. We’ll begin by discussing the concepts fundamental to all data analysis and ML: data itself, how it is managed, and what constitutes good-quality data. We’ll then move on to discuss data analysis in the context of ML and deep learning, consider different types of ML algorithms, and wrap up by considering the technical toolkit recommended for getting hands-on with the content in this book. Welcome to the first chapter and all the very best!</p> 
  </div> 
  <div class="readable-text" id="p11"> 
   <h2 class=" readable-text-h2"><span class="num-string">1.1</span> Technical toolkit </h2> 
  </div> 
  <div class="readable-text" id="p12"> 
   <p>The following tools are used for different facets of the project:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p13"> <em>Data engineering</em><em> </em>—Hadoop, Spark, Scala, Java, C++, SQL, Redshift, Azure, PySpark </li> 
   <li class="readable-text" id="p14"> <em>Data analysis</em><em> </em>—SQL, R, Python, Excel </li> 
   <li class="readable-text" id="p15"> <em>ML</em><em> </em>—SQL, R, Python, Excel, Weka, Julia, MATLAB, SPSS, SAS </li> 
   <li class="readable-text" id="p16"> <em>Visualization</em><em> </em>—Tableau, Power BI, Qlik, COGNOS </li> 
   <li class="readable-text" id="p17"> <em>Model deployment</em><em> </em>—Docker, Flask, Amazon S3 </li> 
   <li class="readable-text" id="p18"> <em>Cloud services</em><em> </em>—Azure, AWS, GCP </li> 
  </ul> 
  <div class="readable-text" id="p19"> 
   <p>In this book, we are going to use Python. You are advised to install the latest version of Python on your system. At least version 3.5+ is advisable, though the latest version as of this writing is 3.13. We will also use Jupyter Notebook, so installing Anaconda on your system is advisable. </p> 
  </div> 
  <div class="readable-text print-book-callout" id="p20"> 
   <p><span class="print-book-callout-head">Note </span> All the codes and datasets will be checked in at the GitHub repository: <a href="https://github.com/vverdhan/DataWithoutLabels">https://github.com/vverdhan/DataWithoutLabels</a>. You are expected to replicate them and try to reproduce the results.</p> 
  </div> 
  <div class="readable-text" id="p21"> 
   <h2 class=" readable-text-h2"><span class="num-string">1.2</span> Data, data types, data management, and quality</h2> 
  </div> 
  <div class="readable-text" id="p22"> 
   <p>We begin by introducing the protagonist of this book: <em>data</em>. Data can be thought of as facts and statistics that are collected for performing any kind of analysis or study. But data also has its own traits, attributes, quality measures, and management principles. It is stored, exported, loaded, transformed, and measured. In that sense, data is a tangible “thing” in its own regard, and it must be handled properly to correctly utilize it. To do that, we must properly understand data.</p> 
  </div> 
  <div class="readable-text intended-text" id="p23"> 
   <p>Let’s start with the fundamentals: the definition of data. Once we’ve defined data, we will proceed to discuss different types of data, their respective examples, and the attributes of data that make it useful and of good quality. </p> 
  </div> 
  <div class="readable-text" id="p24"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.2.1</span> What is data?</h3> 
  </div> 
  <div class="readable-text" id="p25"> 
   <p>Data is ubiquitous. You make a phone call using a mobile network; as you do, you are generating data. You book a flight ticket and hotel for an upcoming vacation; data is being created. Our day-to-day activity-generated data might include performing a bank transaction, surfing social media, or shopping websites online. That data is transformed from one form to another, stored, cleaned, managed, and analyzed. So what actually is it?</p> 
  </div> 
  <div class="readable-text intended-text" id="p26"> 
   <p>Formally put, data is a collection of facts, observations, measures, text, numbers, images, and videos. A dataset might be clean (i.e., organized to be free from errors, inconsistencies, and irrelevant information) or unclean, be ordered (e.g., alphabetically) or unordered, or have mixed data types or all one type. As mentioned, data in itself is not useful until we clean it, arrange it, analyze it, and draw insights from it. We can visualize the transition from raw to more useful forms in figure 1.1.<span class="aframe-location"/> </p> 
  </div> 
  <div class="browsable-container figure-container" id="p27">  
   <img alt="figure" src="../Images/CH01_F01_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 1.1</span> How we can transform raw data to become information, knowledge, and, finally, insights that can be used in business to drive decisions and actions</h5>
  </div> 
  <div class="readable-text" id="p28"> 
   <p>Raw data is converted to information when we can find distinctions in it. When we relate the terms and “connect the dots,” the same piece of information becomes knowledge. Insight is the stage where we can find the major centers and significant points. An insight should be actionable, succinct, and direct. For example, if a customer retention team of a telecom operator is told that customers who do not make a call for nine days have a 30% higher chance of churn than those who make calls, this will be a useful insight that they can work on and try to resolve. Similarly, if a line technician in a manufacturing plant is informed that using mold X results in 60% more defects than using mold Y, they will refrain from using the poorly performing mold in the future. An insight is quite useful for a business team because they can consider it and take corrective measures.</p> 
  </div> 
  <div class="readable-text" id="p29"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.2.2</span> Various types of data</h3> 
  </div> 
  <div class="readable-text" id="p30"> 
   <p>As we’ve discussed, data is generated by much of our day-to-day activity. We can broadly classify that data into different <em>types</em>, as shown in figure 1.2.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p31">  
   <img alt="figure" src="../Images/CH01_F02_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 1.2</span> The divisions and subdivisions of data</h5>
  </div> 
  <div class="readable-text" id="p32"> 
   <p>Data can be divided into quantitative and qualitative categories, which are further subclassified:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p33"> <em>Qualitative data </em>is the data type that cannot be measured or weighed—for example, taste, color, odor, fitness, name, etc. They can only be observed subjectively. Formally put, when we categorize something or make a classification for it, the data generated is qualitative in nature. Examples are colors in a rainbow, cities in a country, quality of a product, gender, etc. They are also called <em>categorical</em> variables. Qualitative data can be further subcategorized into binary, nominal, and ordinal datasets: 
    <ul> 
     <li> <em>Binary</em> data, as the name suggests, has only two classes that are mutually exclusive to each other. Examples are yes/no, dry/wet, hard/soft, good/bad, true/false, etc.  </li> 
     <li> <em>Nominal</em> data can be described as the type of data that, though categorized, does not have any sequence or order. Examples are distinct languages that are spoken in a country, colors in a rainbow, types of services available to a customer, cities in a country, etc.  </li> 
     <li> <em>Ordinal </em>data is similar to nominal data, except we can order it in a sequence. Examples are fast/medium/slow, positive/neutral/negative, etc.  </li> 
    </ul> </li> 
   <li class="readable-text" id="p34"> <em>Quantitative </em>data is all the types of data points that can be measured, weighed, scaled, recorded, etc. Examples are height, revenue, number of customers, demand quantity, area, volume, etc. They are the most common form of data and allow mathematical and statistical operations. Quantitative data is further subcategorized as discrete and continuous: 
    <ul> 
     <li> <em>Discrete</em> data is precise, to the point, and represented as integers. For example, the number of passengers in a plane or the population of a city cannot be in decimals. </li> 
     <li> <em>Continuous </em>data points can take any value, usually in a range. For example, height can take decimal values or the price of a product need not be an integer. </li> 
    </ul> </li> 
  </ul> 
  <div class="readable-text" id="p35"> 
   <p>Any data point will generally will fall into one of these classes, based on its properties. There is one more logical grouping that can be done using source and usage, which makes a lot of sense while solving business problems. This grouping allows us to design solutions customized to the data type. </p> 
  </div> 
  <div class="readable-text intended-text" id="p36"> 
   <p>Depending on the source and usage, we can also think of data in two broad classes: structured and unstructured data. A dataset that can be represented in a row-column structure easily is a <em>structured</em> dataset. For example, transactions made by five customers in a retail store can be stored, as shown in table 1.1.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p37"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 1.1</span> An example of a structured dataset with attributes like amount, date, city, items, etc. </h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         Customer ID 
       </div> </th> 
      <th> 
       <div>
         Transaction date 
       </div> </th> 
      <th> 
       <div>
         Amount ($) 
       </div> </th> 
      <th> 
       <div>
         No. of items 
       </div> </th> 
      <th> 
       <div>
         Payment mode 
       </div> </th> 
      <th> 
       <div>
         City 
       </div> </th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  1001 <br/> </td> 
      <td>  01-June-2024 <br/> </td> 
      <td>  100 <br/> </td> 
      <td>  5 <br/> </td> 
      <td>  Cash <br/> </td> 
      <td>  New Delhi <br/> </td> 
     </tr> 
     <tr> 
      <td>  1002 <br/> </td> 
      <td>  02-June-2024 <br/> </td> 
      <td>  101 <br/> </td> 
      <td>  6 <br/> </td> 
      <td>  Card <br/> </td> 
      <td>  New York <br/> </td> 
     </tr> 
     <tr> 
      <td>  1003 <br/> </td> 
      <td>  03-June-2024 <br/> </td> 
      <td>  102 <br/> </td> 
      <td>  7 <br/> </td> 
      <td>  Card <br/> </td> 
      <td>  London <br/> </td> 
     </tr> 
     <tr> 
      <td>  1004 <br/> </td> 
      <td>  04-June-2024 <br/> </td> 
      <td>  103 <br/> </td> 
      <td>  8 <br/> </td> 
      <td>  Cash <br/> </td> 
      <td>  Dublin <br/> </td> 
     </tr> 
     <tr> 
      <td>  1005 <br/> </td> 
      <td>  05-June-2024 <br/> </td> 
      <td>  104 <br/> </td> 
      <td>  9 <br/> </td> 
      <td>  Cash <br/> </td> 
      <td>  Tokyo <br/> </td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p38"> 
   <p>In table 1.1, for each unique customer ID, we have the transaction date, the amount spent in dollars, the number of items purchased, the mode of payment, and the city in which the transaction was made. Such a data type can be extended to employee details, call records, banking transactions, etc. </p> 
  </div> 
  <div class="readable-text print-book-callout" id="p39"> 
   <p><span class="print-book-callout-head">Note</span>  Most of the data used in analysis and model building is structured. Structured data is easier to store, analyze, and visualize in the form of graphs and charts. </p> 
  </div> 
  <div class="readable-text" id="p40"> 
   <p>Many algorithms and techniques cater to structured data—in normal real-world language, we refer to structured data primarily. Unstructured data is not easily sorted into a row-column structure. It can be text, audio, image, or video. Figure 1.3 shows examples of unstructured data and their respective sources, as well as the primary types of unstructured data: text, images, audio, and video along with their examples.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p41">  
   <img alt="figure" src="../Images/CH01_F03_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 1.3</span> Unstructured data, along with its various types and examples. This data is usually complex to analyze and generally requires deep learning-based algorithms.</h5>
  </div> 
  <div class="readable-text" id="p42"> 
   <p>Computers and processors understand only binary numbers. So these unstructured data points still need to be represented as numbers so that we can perform mathematical and statistical calculations on them. For example, an image is made up of pixels. If it is a colored image, each pixel will have RGB (red, green, blue) values and each RGB can take a value (0–255). Hence, we will be able to represent an image as a matrix on which further mathematical calculations can be made. Text, audio, and video can be represented similarly.</p> 
  </div> 
  <div class="readable-text print-book-callout" id="p43"> 
   <p><span class="print-book-callout-head">Note</span>  In general, deep learning-based solutions like convolutional neural networks (CNN) and recurrent neural networks (RNN) are used for unstructured data. We are going to work on text and explore CNN and RNN at a later stage in the book.</p> 
  </div> 
  <div class="readable-text" id="p44"> 
   <p>Unstructured data can be understood through an example: consider a picture of a vacuum cleaner, as shown in figure 1.4. A portion of the image can be represented as a matrix and will look like the matrix seen in the figure. This example is only for illustration purposes and doesn’t show actual values. <span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p45">  
   <img alt="figure" src="../Images/CH01_F04_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 1.4</span> An example of how unstructured data can be represented as a matrix to analyze. The matrix on the right is only an illustration and not the actual numbers.</h5>
  </div> 
  <div class="readable-text" id="p46"> 
   <p>Similarly, we can have representations of text, audio, or video data. Due to the size and large number of dimensions typically present in such data, this kind of unstructured data is complex to process and model, and hence, in general, deep learning-based models serve that purpose.</p> 
  </div> 
  <div class="readable-text intended-text" id="p47"> 
   <p>In addition to the broad types of data we’ve discussed so far, we can have more categories like ratios or scales, which can be used to define the relationship of one variable with another. All these data points (whether structured or unstructured) are defined by the way they are generated in real life. </p> 
  </div> 
  <div class="readable-text intended-text" id="p48"> 
   <p>All of these data points have to be captured, stored, and managed. There are quite a few tools available for managing data, which we will discuss in due course. But before that, let’s examine one of the most crucial but often less talked about subjects: <em>data quality</em>. </p> 
  </div> 
  <div class="readable-text" id="p49"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.2.3</span> Data quality</h3> 
  </div> 
  <div class="readable-text" id="p50"> 
   <p>“Garbage in, garbage out”—this principle summarizes the importance of good-quality data. If the data is dirty or incorrect and lacks any business relationship between variables, we will not be able to solve the business problem at hand. But what is the meaning of “good quality”? Imagine you want to predict rainfall this year based on last year’s daily rainfall measurements. A good-quality dataset for this task would be as complete as possible (very few missing days of rainfall measurements). It would be relevant and valid (e.g., covering the same local area as where you are making your predictions), the measurements would be accurate, and the data would be readily available for you to access and use without permission problems. A bad dataset, in contrast, might have lots of “holes” in the data, might have been taken in an area distant from the site you wish to study (making it less relevant), or might be difficult to access. As you can no doubt gather, good-quality data facilitates good-quality outputs, while bad data quality actively hinders your work and will likely result in a poor outcome. The major components of data quality are shown in figure 1.5. Let’s explore them one by one.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p51">  
   <img alt="figure" src="../Images/CH01_F05_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 1.5</span> Data quality is of paramount importance; attributes of good-quality data are shown.</h5>
  </div> 
  <div class="readable-text" id="p52"> 
   <p>The major attributes of good-quality data are</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p53"> <em>Completeness</em><em> </em>—We would expect our dataset to be proper and not missing any values. For example, if we are working on sales data for a year, good data will have all the values for all 12 months. Then it will be a complete data source. The completeness of a dataset ensures that we are not missing an important variable or data point. </li> 
   <li class="readable-text" id="p54"> <em>Validity</em><em> </em>—The validity of data is its conformance to the properties, characteristics, and variations that are present and being analyzed in our use case. Validity indicates if the observation and measurement we have captured are reliable and valid. For example, if the scope of the study is for 2015–2019, then using 2014 data will be invalid. </li> 
   <li class="readable-text" id="p55"> <em>Accuracy</em><em> </em>—Accuracy is an attribute focusing on the correctness of data. If we have inaccurate data, we will generate inaccurate insights, and actions will be faulty. It is a good practice to start the project by generating key performance indicators (KPIs) and comparing them with the numbers reported by the business to check the authenticity of the data available to us. </li> 
   <li class="readable-text" id="p56"> <em>Representativeness</em><em> </em>—This is one of the most important attributes of the data and often the most undermined. Representation of data means that the data in use truly captures the business need and is not biased. If the dataset is biased or is not representative enough, the model generated will not be able to make predictions on the new and unseen data, and the entire effort will go down the drain. </li> 
   <li class="readable-text" id="p57"> <em>Availability</em><em> </em>—Nonavailability of data is a challenge we face often. Data might not be available for the business problem, and then we face a dilemma on whether to continue the use case. Sometimes we face operational challenges and do not have access to the database or permission problems, or data might not be available at all for a particular variable since it is not captured. In such cases, we have to work with the data available and use surrogate variables. For example, imagine we are working on a demand generation problem. We want to predict how many customers can be expected during the upcoming sales season for a particular store. But we do not record the number of customers visiting for a few months. We can then use revenue as a surrogate field and synthesize the missing data points. </li> 
   <li class="readable-text" id="p58"> <em>Consistency</em><em> </em>—Here we check whether the data points are consistent across systems and interfaces. It should not be the case that one system is reporting a different revenue figure while another system is showing a completely different value. When faced with such a problem, we generate the respective KPIs as per the data available and seek guidance from the business team. </li> 
   <li class="readable-text" id="p59"> <em>Timeliness</em><em> </em>—Timeliness simply means that we have all the data that is required at this point. If the dataset is not available now but might become available in the future, then it might be prudent to wait. </li> 
   <li class="readable-text" id="p60"> <em>Integrity</em><em> </em>—The data tables and variables we have are interlinked and interrelated to each other. For example, an employee’s details can be spread over multiple tables that are linked to each other using the employee’s ID. Data integrity addresses this requirement and ensures that all such relations between the tables and respective entities are consistent. </li> 
  </ul> 
  <div class="readable-text" id="p61"> 
   <p>The quality of data is of paramount importance. In pragmatic day-to-day business, often we do <em>not</em> get good-quality data. Due to multiple challenges, good, clean data that is accessible, consistent, representative, and complete is seldom found. </p> 
  </div> 
  <div class="readable-text intended-text" id="p62"> 
   <p>Degradation in quality can be due to challenges during data capturing and collection, exporting or loading, transformations done, etc. A few of the possibilities are as follows:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p63"> We can get integers as names, or special characters like “#$!&amp;” in a few columns, or null values, blanks, or not a number (NaN) as some of the values.  </li> 
   <li class="readable-text" id="p64"> There may be duplicates in the records. </li> 
   <li class="readable-text" id="p65"> Outliers may occur. This is a nuisance we deal with quite a lot. For example, let’s say that the average daily transactions are 1,000 for an online retailer. One fine day, due to a server problem, there were no transactions done. It is an outlier situation. Or, one fine day, the number of transactions was 1,000,000. It is again an example of an outlier. Outliers can bias the algorithms we create. </li> 
   <li class="readable-text" id="p66"> There may be seasonal variations and movements concerning the time of the day and days of the week—all of them should be representative enough in the dataset. </li> 
   <li class="readable-text" id="p67"> Inconsistencies in the date format can lead to multiple challenges when we try to merge multiple data sources. For example, source 1 might be using DD/MM/YYYY while another might be using MM/DD/YYYY. This is taken care of during the data loading step itself. </li> 
  </ul> 
  <div class="readable-text" id="p68"> 
   <p>All these aberrations and quality problems should be addressed and cleaned thoroughly. We will be solving these data problems throughout the book and sharing the best practices to be followed.</p> 
  </div> 
  <div class="readable-text print-book-callout" id="p69"> 
   <p><span class="print-book-callout-head">Note</span>  The quality of your raw data and the rigor shown during the cleaning process directly affect the quality of your final analysis and the maturity of your solution.</p> 
  </div> 
  <div class="readable-text" id="p70"> 
   <p>We have now defined the major attributes of data. We next study the broad process and techniques used for data engineering and management.</p> 
  </div> 
  <div class="readable-text" id="p71"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.2.4</span> Data engineering and management</h3> 
  </div> 
  <div class="readable-text" id="p72"> 
   <p>A strong data engineering process and mature data management practice are prerequisites for a successful ML model solution. Whether you come from a data engineering or data science background, each goes hand in hand; a data engineer would be well served by understanding the basics of data science, and vice versa. Figure 1.6 provides a high-level overview of what the engineering process and management practice might look like. The end-to-end journey of data is described—right from the process of data capturing, data pipeline, and data loading to the point it is ready for analysis.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p73">  
   <img alt="figure" src="../Images/CH01_F06_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 1.6</span> Data engineering paves the way for data analysis. It involves data loading, transformation, enrichment, cleaning, preparation, etc., which leads to the creation of data ready for analysis.</h5>
  </div> 
  <div class="readable-text" id="p74"> 
   <p>In the data engineering step, data is cleansed, conformed, reshaped, transformed, and ingested. Generally, we have a server where the final data is hosted and is ready for access. The most used process is the creation of an export, transform, load (ETL) process. Then we make the data ready for analysis. We create new variables, treat null values, enrich the data with methods, and then finally proceed to the analysis/model-building stage. </p> 
  </div> 
  <div class="readable-text intended-text" id="p75"> 
   <p>Many times, we find that terms like data analysis, data science, machine learning, data mining, artificial intelligence, business intelligence, big data, etc., are used quite interchangeably in business. It is a good idea to clarify them, which is the topic of the next section. There are plenty of tools available for each respective function that we are discussing. We will also understand the role of software engineering in this entire journey.</p> 
  </div> 
  <div class="readable-text" id="p76"> 
   <h2 class=" readable-text-h2"><span class="num-string">1.3</span> Data analysis, ML, AI, and business intelligence</h2> 
  </div> 
  <div class="readable-text" id="p77"> 
   <p>ML and AI are relatively new fields, and as such, there is little standardization and differentiation in the scope of their work. This has resulted in unclear definitions and demarcation of these fields. We examine these fields—where they overlap, where they differ, and how one empowers the other. Each of the functions empowers and complements the other, as visualized in figure 1.7. <span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p78">  
   <img alt="figure" src="../Images/CH01_F07_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 1.7</span> How the various fields are interlinked with each other and how they are dependent on each other</h5>
  </div> 
  <div class="readable-text" id="p79"> 
   <p>After the business problem has been defined and scoped properly, we start with the technical process. Data mining and data engineering start the whole process by providing the data required for analysis. It also exports, transforms, cleans, and loads the data so that it can be consumed by all of the respective functions. Business intelligence and visualizations use this data to generate reports and dashboards. Data analytics generates insights and trends using data. Data science stands on the pillars of data analysis, statistics, business intelligence, data visualization, ML, and data mining. ML creates statistical and mathematical models, and AI further pushes the capabilities. </p> 
  </div> 
  <div class="readable-text intended-text" id="p80"> 
   <p>ML uses traditional coding. The coding is performed in traditional languages (such as Python), and hence, all the logic and rules of computer science and software engineering are valid in ML too. ML helps us make sense of data that we are otherwise not able to comprehend. The most fascinating advantage of ML is its ability to work on very complex and high-dimensional data points like video, audio, image, text, or complex datasets generated by sensors. It allows us to think beyond the obvious. Now AI can achieve feats that were previously thought impossible. This level of pattern recognition and learning has resulted in technological breakthroughs such as self-driving cars, chatbots conversing like humans, speech-to-text conversion and translation to another language, automated grading of essays, photo captioning, etc. With the advent of generative AI, using large language models like ChatGPT, we can create images, videos, and text based on the prompt given by the user. And that is just the start!</p> 
  </div> 
  <div class="readable-text" id="p81"> 
   <h2 class=" readable-text-h2"><span class="num-string">1.4</span> Nuts and bolts of ML</h2> 
  </div> 
  <div class="readable-text" id="p82"> 
   <p>Consider this: if a child has to be taught how to open a door, we show them the exact steps quite a few times. The child tries to open it but fails. They try again and fail again. But with each subsequent try, the child improvises their approach. And, after some time, the child can open the door. Another example is when we learn to drive: we make mistakes, we learn from them, and we improve. ML works similarly, wherein the statistical algorithm looks at the historical data and finds patterns and insights. The algorithm uncovers relationships and anomalies, trends and deviations, similarities and differences—and then shares actionable results with us. </p> 
  </div> 
  <div class="readable-text intended-text" id="p83"> 
   <p>Formally put, ML can be called a branch or a study of computer algorithms that works on historical data to generate insights and helps in making data-driven decisions. The algorithms are based on statistical and mathematical foundations and hence have a sound logical explanation. ML algorithms require coding, which can be done in any of the languages and tools available such as Python, R, SPSS, SAS, MATLAB, Weka, Julia, Java, etc. It also requires a domain understanding of the business.</p> 
  </div> 
  <div class="readable-text intended-text" id="p84"> 
   <p>Whenever you are doing some online shopping for clothing and the website recommends accessories that go along with it or you are booking an airplane ticket and the travel operator shows you a customized deal as per your needs and plan, most of the time, ML is working in the background. It has learned your preferences and compared them with your historical trends. It is also looking for similarities you have with other customers who behave almost the same. Based on all that analysis, the algorithm is making an intelligent recommendation to you. Quite fascinating, right?</p> 
  </div> 
  <div class="readable-text intended-text" id="p85"> 
   <p>Why exactly is ML so good at finding patterns? We humans can analyze only two or maybe three dimensions simultaneously; for example, we can pick up a pattern between two or three interacting variables. But what if there are 50 different variables all interacting? We wouldn’t have a chance. An ML algorithm can work on 50, 60, or maybe 100s of dimensions simultaneously. It can work on any type of data, structured or unstructured, and it can help in the automation of tasks. Hence, it generates patterns and insights quite difficult for a human mind to visualize.</p> 
  </div> 
  <div class="readable-text intended-text" id="p86"> 
   <p>ML, like any other project, requires a team of experts who work closely with each other and complement each other’s skill sets. As shown in figure 1.8, an ML project requires the following roles:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p87"> <em>Business team</em><em> </em>—Business stakeholders and subject matter experts define the business problem for the project. They own the solution, have a clear understanding of the ask, and have a clear measurable goal in sight. They course-correct the team in case of confusion and serve as experts who have a deep understanding of the business processes and operations. They are marketing managers, product owners, process engineers, quality experts, risk analysts, portfolio leads, etc. It is imperative that business stakeholders are closely knit into the team from day one. They help in course correction of the overall direction. </li> 
   <li class="readable-text" id="p88"> <em>Operations team</em><em> </em>—This team comprises the scrum master, project manager, business analysts, etc. The role of the team can be compared to a typical project management team, which tracks the progress, maintains the records, reports the day-to-day activities, and keeps the entire project on track. They create user stories and act as a bridge between the business team and the data team.<span class="aframe-location"/> </li> 
  </ul> 
  <div class="browsable-container figure-container" id="p89">  
   <img alt="figure" src="../Images/CH01_F08_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 1.8</span> Team required for a data science project and the respective interactions of them with each other—truly a team effort</h5>
  </div> 
  <ul> 
   <li class="readable-text" id="p90"> <em>Data team</em><em> </em>—The core team that creates the solution, does the coding, and generates the output in the form of a model, dashboard, report, and insights is the data team. It comprises three main pillars: the data engineering team, the UI/visualization team, and the data science team. Their functions are as follows: 
    <ul> 
     <li> The data engineering team is responsible for building, maintaining, integrating, and ingesting all the data points. They do a periodic data refresh and act as a prime custodian of data. They use ETL, SQL, AWS, Kafka, PySpark, etc.  </li> 
     <li> The UI/visualization team builds dashboards, reports, interactive modules, and web applications. They use SQL, Tableau, Qlik, Power BI, and others.  </li> 
     <li> The data science team is responsible for all the data analysis and model-building tasks. They discover patterns and insights, test hypotheses, and generate the final output that is to be finally consumed by all. The final output can be an ML model that will be used to solve the business problem. In situations where an ML model is not possible, the team might generate actionable insights that can be useful for the business. This team requires SQL, Python, R, SAS, SPSS, etc., to complete their job.  </li> 
     <li> The DevOps team is generally a part of the data engineering team, or they can exist as a separate entity. They focus on the operationalization of the ML model. Remember: if your ML model is not being used, it is just a shiny piece of software sitting on a shelf. The UI/UX team will lead the development of the final product layer where the ML-based outputs will be surfaced to the end user. User experience is often ignored, and without an interactive and engaging user experience, ML will not be used to its full potential.  </li> 
    </ul> </li> 
  </ul> 
  <div class="readable-text list-body-item" id="p91"> 
   <p>The team sometimes has a testing team as well to assess the functionality, various use cases, and overall look and feel of the application. </p> 
  </div> 
  <div class="readable-text" id="p92"> 
   <p>Having discussed the typical team structure for a data science project, we will now examine the broad steps involved in a data science project. </p> 
  </div> 
  <div class="readable-text intended-text" id="p93"> 
   <p>A data science project runs like any other project that has deadlines, stages, testing, phases, etc. The raw material is the data that passes through various phases to be cleaned, analyzed, and modeled.</p> 
  </div> 
  <div class="readable-text intended-text" id="p94"> 
   <p>Figure 1.9 shows an illustration of a data science project’s stages. It starts with a business problem definition of the project. The business problem must be concise, clear, measurable, and achievable. Table 1.2 depicts an example of a bad (ill-defined) and a good business problem.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p95">  
   <img alt="figure" src="../Images/CH01_F09_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 1.9</span> A data science project is like any other project, having stages and deadlines, dependencies, and processes.</h5>
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p96"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 1.2</span> Examples of how to define a business problem to make it clear, concise, and measurable</h5> 
   <table> 
    <thead> 
     <tr> 
      <th colspan="2"> 
       <div>
         Examples 
       </div> </th> 
     </tr> 
     <tr> 
      <th> 
       <div>
         Ill-defined business problems 
       </div> </th> 
      <th> 
       <div>
         Good business problems 
       </div> </th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  Increase the production <br/>Decrease the cost <br/> </td> 
      <td>  Optimize the various cost heads (A, B, C, and D) and identify the most optimal combination to decrease the cost by 1.2% in the next six months <br/> </td> 
     </tr> 
     <tr> 
      <td>  Increase the revenue by 80% in one month <br/>Automate the entire process <br/> </td> 
      <td>  From the various factors of defects in the process (X, Y, Z), identify the most significant factors to reduce the defect % by 1.8% in the next three months <br/> </td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p97"> 
   <p>Then we move to the data discovery phase, during which we list all the data sources and host them. All the various datasets, like customer details, purchase histories, social media data, portfolios, etc., are identified and accessed. The data tables that are to be used are finalized in this step, and most of the time, we create a database for us to work, test, and learn.</p> 
  </div> 
  <div class="readable-text intended-text" id="p98"> 
   <p>We then go ahead with data preprocessing. It involves cleaning data like the removal of null values, outliers, duplicates, junk values, etc. The previous step and this one can take 60% to 70% of the project time.</p> 
  </div> 
  <div class="readable-text intended-text" id="p99"> 
   <p>We create a few reports and generate initial insights during the exploratory data analysis phase. These insights are discussed with the business stakeholders, and they guide course correction.</p> 
  </div> 
  <div class="readable-text intended-text" id="p100"> 
   <p>The data is now ready for modeling. Quite a few versions of the solution are tested. Then, depending on the requirements, we choose the best version. Generally, parameters like accuracy and statistical measures like precision and recall drive the selection of the model. We will be exploring the process of choosing the best model and terms like precision and recall in later chapters of the book. Once we choose the final model, we are ready to deploy the model in the production environment, where it will work on unseen data.</p> 
  </div> 
  <div class="readable-text intended-text" id="p101"> 
   <p>These are the broad steps in an ML project. Like any other project, there is a code repository, best practices, coding standards, common errors, pitfalls, etc., which we will discuss throughout the book. </p> 
  </div> 
  <div class="readable-text" id="p102"> 
   <h2 class=" readable-text-h2"><span class="num-string">1.5</span> Types of ML algorithms</h2> 
  </div> 
  <div class="readable-text" id="p103"> 
   <p>ML models affect decision-making and follow a statistical approach to solve a business problem. They work on historical data and find patterns and trends in it. The raw material is the historical data, which is analyzed and modeled to generate a predictive algorithm. The historical data available and the sort of problem that needs to be solved informs the ML approach that should be taken. ML algorithms can be split broadly into four classes: supervised learning, unsupervised learning, semisupervised learning, and reinforcement learning, as depicted in figure 1.10. We will examine each of the four types in detail, with a focus on unsupervised learning—the topic of this book.</p> 
  </div> 
  <div class="readable-text intended-text" id="p104"> 
   <p>You might have heard about generative AI (GenAI) in the news. GenAI-based solutions generally start with unsupervised and may include supervised or reinforcement learning to specialize the model for certain tasks. We will discuss GenAI further throughout the book.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p105">  
   <img alt="figure" src="../Images/CH01_F10_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 1.10</span> ML algorithms can be classified as supervised learning algorithms, unsupervised learning algorithms, semisupervised learning algorithms, and reinforcement learning algorithms.</h5>
  </div> 
  <div class="readable-text" id="p106"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.5.1</span> Supervised learning </h3> 
  </div> 
  <div class="readable-text" id="p107"> 
   <p>Formally put, supervised models are statistical models that use both the input data and the desired output to predict the future. The output is the value that we wish to predict and is referred to as the <em>target variable,</em> and the data used to make that prediction is called <em>training data</em>. The target variable is sometimes referred to as the <em>label</em>. The various attributes or variables present in the data are called <em>independent variables</em>. Each of the historical data points or a <em>training example</em> contains these independent variables and the corresponding target variable. Supervised learning algorithms make a prediction for unseen future data. The accuracy of the solution depends on the training done and patterns learned from the labeled historical data. An example is described in the next section. </p> 
  </div> 
  <div class="readable-text intended-text" id="p108"> 
   <p>Supervised learning problems are used in demand prediction, credit card fraud detection, customer churn prediction, premium estimation, etc. They are heavily used across domains like retail, telecom, banking and finance, aviation, insurance, and more and for functions like marketing, CRM, quality, supply chain, pricing, and so on.</p> 
  </div> 
  <div class="readable-text intended-text" id="p109"> 
   <p>Supervised learning algorithms can be further broken into regression algorithms and classification algorithms. Let’s consider each of these in turn.</p> 
  </div> 
  <div class="readable-text" id="p110"> 
   <h4 class=" readable-text-h4">Regression algorithms</h4> 
  </div> 
  <div class="readable-text" id="p111"> 
   <p>Regression algorithms are supervised learning algorithms—that is, they require target variables that need to be predicted. These algorithms are used to predict the values of a <em>continuous</em> <em>variable</em>. Examples include revenue, amount of rainfall, number of transactions, production yield, and so on. In supervised classification problems, we predict a categorical variable like whether it will rain (yes/no), whether the credit card transaction is fraudulent or genuine, and so on. This is the main difference between classification and regression problems. </p> 
  </div> 
  <div class="readable-text intended-text" id="p112"> 
   <p>Let us understand the regression problem with an example. Say we assume that the weight of a person is only dependent on height and not on other parameters like gender, ethnicity, diet, etc. In such a case, we want to predict the weight of a person based on height. The dataset and the graph plotted for the same data will look like figure 1.11.</p> 
  </div> 
  <div class="readable-text intended-text" id="p113"> 
   <p>A regression model will be able to find the inherent patterns in the data and fit a mathematical equation describing the relationship. It can then take height as an input and predict the weight. Here, height is the independent variable, and weight is the dependent variable or the target variable or the label we want to predict.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p114">  
   <img alt="figure" src="../Images/CH01_F11_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 1.11</span> Data and plot of relationship between height and weight that is used for regression problem</h5>
  </div> 
  <div class="readable-text" id="p115"> 
   <p>There are quite a few algorithms available for regression problems. Some of the major ones are as follows (although this list is certainly not exhaustive):</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p116"> Linear regression </li> 
   <li class="readable-text" id="p117"> Decision tree </li> 
   <li class="readable-text" id="p118"> Random forest </li> 
   <li class="readable-text" id="p119"> k-nearest neighbor </li> 
   <li class="readable-text" id="p120"> Boosting algorithm </li> 
   <li class="readable-text" id="p121"> Neural network </li> 
  </ul> 
  <div class="readable-text" id="p122"> 
   <p>We can use any of the algorithms to solve this problem. We will explore more by using linear regression to solve a problem. </p> 
  </div> 
  <div class="readable-text intended-text" id="p123"> 
   <p>The linear regression algorithm models the relationship between dependent variables and target variables by assuming a linear relationship between them. The linear regression algorithm would result in a mathematical equation for the problem, shown in equation 1.1:</p> 
  </div> 
  <div class="browsable-container equation-container" id="p124"> 
   <h5 class=" browsable-container-h5">(1.1)</h5> 
   <p>Weight = <em class="obliqued">β</em><sub>0</sub> * height + <em class="obliqued">β</em><sub>1</sub></p> 
  </div> 
  <div class="readable-text" id="p125"> 
   <p>Generally put, linear regression is used to fit a mathematical equation depicting the relationship between dependent and independent variables, shown as equation 1.2:</p> 
  </div> 
  <div class="browsable-container equation-container" id="p126"> 
   <h5 class=" browsable-container-h5">(1.2)</h5> 
   <p>Y = <em class="obliqued">β</em><sub>0</sub> + <em class="obliqued">β</em><sub>1</sub> x<sub>1</sub> + <em class="obliqued">β</em><sub>2</sub>x<sub>2</sub> + ….+ <em class="obliqued">ε</em></p> 
  </div> 
  <div class="readable-text" id="p127"> 
   <p>Here, <em>Y</em> is the target variable that we want to predict; <em>x</em><sub>1</sub> is the first independent variable; <em>x</em><sub>2</sub> is the second independent variable; <em class="obliqued">ε</em> is the error term in the equation; and <em class="obliqued">β</em><sub>0 </sub>is the intercept of the equation.</p> 
  </div> 
  <div class="readable-text intended-text" id="p128"> 
   <p>A simple visualization for a linear regression problem is shown in figure 1.12. Here we have the x and Y variables where x is the independent variable and Y is the target variable. The objective of the linear regression problem is to find the <em>line of best fit,</em> which can explain the randomness present in the data. <span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p129">  
   <img alt="figure" src="../Images/CH01_F12_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 1.12</span> Raw data that needs to be modeled (left). Using regression, a line of best fit is identified (right).</h5>
  </div> 
  <div class="readable-text" id="p130"> 
   <p>Equation 1.2 is used to make predictions for the unseen data. There are variations in linear regression too, like simple linear regression, multiple linear regression, nonlinear regression, etc. Depending on the data at hand, we choose the correct algorithm. A complex dataset might require a nonlinear relationship between the various variables. </p> 
  </div> 
  <div class="readable-text intended-text" id="p131"> 
   <p>The next type of regression algorithm we shall explore is tree-based solutions. For tree-based algorithms like decision trees, random forests, etc., the algorithm will start from the top and then, like an <code>if</code>/<code>else</code> block, will split iteratively to create nodes and subnodes until we reach a terminal node (see figure 1.13). In the decision tree diagram, we start from the top with the root node, and then we perform splitting until we reach the endpoint, which is the terminal node.</p> 
  </div> 
  <div class="readable-text intended-text" id="p132"> 
   <p>Decision trees are simple to comprehend and implement, and they are fast to train. Their usability lies in the fact that they are intuitive enough to understand without much technical background.</p> 
  </div> 
  <div class="browsable-container figure-container" id="p133">  
   <img alt="figure" src="../Images/CH01_F13_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 1.13</span> A decision tree has a root node, and after splitting, we get a decision node and a terminal node, which is the final node and cannot be split further.</h5>
  </div> 
  <div class="readable-text" id="p134"> 
   <p>There are other famous regression algorithms like k-nearest neighbor, gradient boosting, and deep learning–based solutions. Different regression algorithms are best suited to specific contexts. </p> 
  </div> 
  <div class="readable-text intended-text" id="p135"> 
   <p>To understand the effect of regression use cases, let’s consider a few business-relevant use cases that are implemented in the industry:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p136"> An airport operations team is assessing staffing requirements and wants to estimate the amount of passenger traffic expected. The estimate will help the team prepare a plan regarding future resource requirements and will help in the optimization of the resources required. Regression algorithms can help in predicting the number of passengers. </li> 
   <li class="readable-text" id="p137"> A retailer wants to understand the expected demand for the upcoming sales season so it can plan the inventory. This will result in cost savings and avoid stock-outs. Regression algorithms can help in such planning. </li> 
   <li class="readable-text" id="p138"> A manufacturing plant wishes to improve the yield from the existing use of various molds and raw materials. The regression solutions can suggest the best combination of molds and predict the expected yield. </li> 
   <li class="readable-text" id="p139"> A bank offers credit cards to its customers. Consider how the credit limit offered to new customers is calculated. Based on the attributes of customers like age, occupation, income, and previous transaction history, regression algorithms can help in suggesting credit limits at a customer level. </li> 
   <li class="readable-text" id="p140"> An insurance company wants to come up with a premium table for its customers using historical claims. The risk can be assessed based on the historical data around driver details, car information, etc. Regression can surely help with such problems. </li> 
  </ul> 
  <div class="readable-text" id="p141"> 
   <p>Regression problems form the foundation of supervised learning problems and are quite heavily used in the industry. Along with classification algorithms, they serve as a go-to solution for most of the predictive problems used in real-world business.</p> 
  </div> 
  <div class="readable-text" id="p142"> 
   <h4 class=" readable-text-h4">Classification algorithms</h4> 
  </div> 
  <div class="readable-text" id="p143"> 
   <p>Classification algorithms are used to predict the values of a categorical variable, which is the dependent variable. This target variable can be binary (yes/no, good/bad, fraud/genuine, pass/fail, etc.) or multiclass (such as positive/negative/neutral or yes/no/don’t know). Classification algorithms will ascertain whether the target event will happen by generating a probability score for the target variable. </p> 
  </div> 
  <div class="readable-text intended-text" id="p144"> 
   <p>After the model has been trained on historical data, a classification algorithm will generate a probability score for the unseen dataset, which can be used to make the final decision. Depending on the number of classes present in the target variable, our business decision will vary. Let’s have a look at a use case for classification problems.</p> 
  </div> 
  <div class="readable-text intended-text" id="p145"> 
   <p>Consider this: a telecom operator is facing a problem with its decreasing subscriber base. The number of existing subscribers is shrinking, and the telecom operator would like to arrest this churn of subscribers. For this purpose, an ML model is envisioned. </p> 
  </div> 
  <div class="readable-text intended-text" id="p146"> 
   <p>In this case, the historical data or the training data available for model building might look like table 1.3. These data points are only for illustration purposes and are not exhaustive. There can be many other significant variables available.</p> 
  </div> 
  <div class="browsable-container browsable-table-container framemaker-table-container" id="p147"> 
   <h5 class=" browsable-container-h5"><span class="num-string">Table 1.3</span> Example of a structured dataset for a telecom operator showing multiple data attributes</h5> 
   <table> 
    <thead> 
     <tr> 
      <th> 
       <div>
         ID 
       </div> </th> 
      <th> 
       <div>
         Revenue ($) 
       </div> </th> 
      <th> 
       <div>
         Duration of service (years) 
       </div> </th> 
      <th> 
       <div>
         Avg. cost 
       </div> </th> 
      <th> 
       <div>
         Monthly usage (days) 
       </div> </th> 
      <th> 
       <div>
         Churned (Y/N) 
       </div> </th> 
     </tr> 
    </thead> 
    <tbody> 
     <tr> 
      <td>  1001 <br/> </td> 
      <td>  100 <br/> </td> 
      <td>  1.1 <br/> </td> 
      <td>  0.10 <br/> </td> 
      <td>  10 <br/> </td> 
      <td>  Y <br/> </td> 
     </tr> 
     <tr> 
      <td>  1002 <br/> </td> 
      <td>  200 <br/> </td> 
      <td>  4.1 <br/> </td> 
      <td>  0.09 <br/> </td> 
      <td>  25 <br/> </td> 
      <td>  N <br/> </td> 
     </tr> 
     <tr> 
      <td>  1003 <br/> </td> 
      <td>  300 <br/> </td> 
      <td>  5.2 <br/> </td> 
      <td>  0.05 <br/> </td> 
      <td>  28 <br/> </td> 
      <td>  N <br/> </td> 
     </tr> 
     <tr> 
      <td>  1004 <br/> </td> 
      <td>  200 <br/> </td> 
      <td>  0.9 <br/> </td> 
      <td>  0.25 <br/> </td> 
      <td>  11 <br/> </td> 
      <td>  Y <br/> </td> 
     </tr> 
     <tr> 
      <td>  1005 <br/> </td> 
      <td>  100 <br/> </td> 
      <td>  0.5 <br/> </td> 
      <td>  0.45 <br/> </td> 
      <td>  12 <br/> </td> 
      <td>  Y <br/> </td> 
     </tr> 
    </tbody> 
   </table> 
  </div> 
  <div class="readable-text" id="p148"> 
   <p>In the example in table 1.3, the dataset comprises the past usage data of subscribers. The last column (Churned) depicts if that subscriber churned out of the system or not. For example, subscriber 1001 churned while 1002 did not. Hence, the business problem is to build an ML model based on this historical data and predict if a new unseen customer will churn or not. </p> 
  </div> 
  <div class="readable-text intended-text" id="p149"> 
   <p>Here, the churned status (yes/no) is the target variable. It is also referred to as the dependent variable. The other attributes like revenue, duration, average cost, monthly usage, etc., are independent variables that are used to create the ML model. The historical data is called the training data. Before the training of the model, the trained supervised learning model will generate prediction probabilities for a new customer. </p> 
  </div> 
  <div class="readable-text intended-text" id="p150"> 
   <p>There are quite a few algorithms available for classification problems; the major ones are as follows:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p151"> Logistic regression </li> 
   <li class="readable-text" id="p152"> Decision tree </li> 
   <li class="readable-text" id="p153"> Random forest </li> 
   <li class="readable-text" id="p154"> k-nearest neighbor </li> 
   <li class="readable-text" id="p155"> Naïve Bayes </li> 
   <li class="readable-text" id="p156"> Support vector machine </li> 
   <li class="readable-text" id="p157"> Boosting algorithms </li> 
   <li class="readable-text" id="p158"> Neural networks </li> 
  </ul> 
  <div class="readable-text" id="p159"> 
   <p>One of the most popular classification algorithms is logistic regression. Logistic regression uses a logit function to model the classification problem. If we are solving for a binary classification problem, it will be binary logistic regression or multiple logistic regression. Similar to linear regression, logistic regression also fits an equation, albeit it uses a sigmoid function to generate the probability score for the event to happen. </p> 
  </div> 
  <div class="readable-text intended-text" id="p160"> 
   <p>A sigmoid function is a mathematical function that has a characteristic S-shaped curve or a sigmoid curve. The mathematical equation of a sigmoid function is shown in equation 3.1:</p> 
  </div> 
  <div class="browsable-container equation-container" id="p161"> 
   <h5 class=" browsable-container-h5">(1.3)</h5> 
   <p><em>S</em>(<em>x</em>) = 1/(1 + <em>e</em><sup>–</sup><sup><em>x</em></sup>)</p> 
  </div> 
  <div class="readable-text" id="p162"> 
   <p>which can be rewritten as equation 1.4</p> 
  </div> 
  <div class="browsable-container equation-container" id="p163"> 
   <h5 class=" browsable-container-h5">(1.4)</h5> 
   <p><em>S</em>(<em>x</em>) = <em>e</em><sup><em>x</em></sup>/(<em>e</em><sup><em>x</em></sup> + 1)</p> 
  </div> 
  <div class="readable-text" id="p164"> 
   <p>Logistic regression uses the sigmoid function. The equation used in the logistic regression problem is shown in equation 1.5:</p> 
  </div> 
  <div class="browsable-container equation-container" id="p165"> 
   <h5 class=" browsable-container-h5">(1.5)</h5> 
   <p>log (p/1 – p) = <em class="obliqued">β</em><sub>0</sub> + <em class="obliqued">β</em><sub>1</sub> x<sub>1</sub> </p> 
  </div> 
  <div class="readable-text" id="p166"> 
   <p>where <em>p</em> is the probability of the event happening; <em class="obliqued">β</em><sub>0 </sub>is the intercept term; <em class="obliqued">β</em><sub>1</sub> is the coefficient for the independent variable <em>x</em><sub>1</sub>; log(<em>p</em>/1 – <em>p</em>) is called the logit; and (<em>p</em>/1 – <em>p</em>) is the odds. As depicted in figure 1.14, if we try to fit a linear regression equation for the probability function, it will not do a good job. We want to obtain the probability scores (i.e., a value between 0 and 1). The linear regression will not only return values between 0 and 1 but also probability scores that are greater than 1 or less than 0. Hence, we have a sigmoid function at right in the figure, which generates probability scores for us between 0 and 1 only.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p167">  
   <img alt="figure" src="../Images/CH01_F14_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 1.14</span> A linear regression model will not be able to do justice (left); hence, we have logistic regression for classification. Linear regression can generate probability scores more than 1 or less than 0 too, which is mathematically incorrect, whereas the sigmoid function generates probability scores between 0 and 1 only (right).</h5>
  </div> 
  <div class="readable-text" id="p168"> 
   <p>The logistic regression algorithm is one of the most widely used techniques for classification problems. It is easy to train and deploy and is often the benchmark algorithm whenever we start any supervised classification learning project. </p> 
  </div> 
  <div class="readable-text intended-text" id="p169"> 
   <p>Tree-based algorithms like decision trees and random forests can also be used for classification problems. The other algorithms are also used as per the requirements.</p> 
  </div> 
  <div class="readable-text" id="p170"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.5.2</span> Unsupervised algorithms</h3> 
  </div> 
  <div class="readable-text" id="p171"> 
   <p>Imagine you are given some paper labels, as shown in figure 1.15. The task is to arrange them by similarity. Now, there are multiple approaches to that problem. You can use color, shape, or size. Here, we do not have any label to guide this arrangement. This is what makes unsupervised algorithms different. <span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p172">  
   <img alt="figure" src="../Images/CH01_F15_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 1.15</span> Example of various shapes that can be grouped together using different parameters</h5>
  </div> 
  <div class="readable-text" id="p173"> 
   <p> Formally put, unsupervised learning only takes the input data and then finds patterns in it without referencing the target variable. An unsupervised learning algorithm therefore reacts based on the presence or lack of patterns in the dataset. </p> 
  </div> 
  <div class="readable-text" id="p174"> 
   <p>Unsupervised learning is hence used for pattern detection, exploring the insights in the dataset and understanding the structure of it, segmentation, and anomaly detection.</p> 
  </div> 
  <div class="readable-text intended-text" id="p175"> 
   <p>We can understand unsupervised learning algorithms by looking at figure 1.16. The figure on the left shows the raw data points represented in a vector space diagram. On the right is the clustering, which will be done using an unsupervised learning algorithm.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p176">  
   <img alt="figure" src="../Images/CH01_F16_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 1.16</span> An unsupervised learning algorithm finds patterns in the data on the left and results in clusters on the right. </h5>
  </div> 
  <div class="readable-text" id="p177"> 
   <p>Some use cases for unsupervised algorithms are as follows:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p178"> A retail group wants to understand its customers better. The task is to improve the customer’s stickiness, revenue, number of visits, basket size, etc. Customer segmentation using unsupervised learning can be done here. Depending on the customer’s attributes like revenue, number of visits, last visit date, age since joining, demographic attributes, etc., the segmentation will result in clusters that can be targeted personally. The result will be improved customer experience, increased customer lifetime value, etc. </li> 
   <li class="readable-text" id="p179"> A network provider needs to create an anomaly detection system. The historical data will serve as the anomalies data. The unsupervised learning algorithm will be able to find patterns, and the outliers will be given out by the algorithm. The distinguished anomalies will be the ones that need to be addressed. </li> 
   <li class="readable-text" id="p180"> A medical product company wishes to find if there are any underlying patterns in the image data of its patients. If there are any patterns and factors, those patients can be treated better, and maybe they require a different approach. Unsupervised learning can help with the image data, which will help address the patients’ needs better. </li> 
   <li class="readable-text" id="p181"> A digital marketing company wants to understand the “unknowns” in the incoming customer data like social media interactions, page clicks, comments, stars, etc. This understanding will help improve customers’ recommendations and overall purchasing experience. </li> 
  </ul> 
  <div class="readable-text" id="p182"> 
   <p>Unsupervised learning algorithms offer flexibility and performance when it comes to finding patterns. They are usable for all kinds of data—the core topic of this book—including structured data, text, or images. </p> 
  </div> 
  <div class="readable-text intended-text" id="p183"> 
   <p>The major unsupervised learning algorithms are</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p184"> Clustering algorithms </li> 
   <li class="readable-text" id="p185"> k-means clustering </li> 
   <li class="readable-text" id="p186"> Hierarchical clustering </li> 
   <li class="readable-text" id="p187"> DBSCAN clustering </li> 
   <li class="readable-text" id="p188"> Spectral clustering </li> 
   <li class="readable-text" id="p189"> Principal component analysis </li> 
   <li class="readable-text" id="p190"> Singular value decomposition </li> 
   <li class="readable-text" id="p191"> Association rules </li> 
   <li class="readable-text" id="p192"> t-distributed stochastic neighbor embedding </li> 
   <li class="readable-text" id="p193"> Autoencoders </li> 
  </ul> 
  <div class="readable-text" id="p194"> 
   <p>We cover all these algorithms in detail in the coming chapters. We will examine the mathematical concepts, the hidden processes, Python implementation, and the best practices throughout the book. Let’s first understand the basic process by means of a case study. </p> 
  </div> 
  <div class="readable-text intended-text" id="p195"> 
   <p>A retailer wants to develop a deeper understanding of its consumer base and then wants to offer personalized recommendations, promotions, discounts, offers, etc. The entire customer dataset should be segmented using attributes like persona, previous purchase, response, external data, and so on (see figure 1.17). <span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p196">  
   <img alt="figure" src="../Images/CH01_F17_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 1.17</span> Steps in an unsupervised learning algorithm from data sources to the final solution ready for deployment</h5>
  </div> 
  <div class="readable-text" id="p197"> 
   <p>For the use case, the steps in an unsupervised learning project are as follows:</p> 
  </div> 
  <ol> 
   <li class="readable-text" id="p198"> We start the project by defining the business problem. We wish to understand the customer base better. A customer segmentation approach can be a good solution. We want segments that are distinguishable using mathematical KPIs. </li> 
   <li class="readable-text" id="p199"> This is the data discovery phase. All the various datasets, like customer details, purchase histories, social media data, portfolios, etc., are identified and accessed. The data tables to be used are finalized in this step. Then, all the data tables are generally loaded into a common database, which we will use to analyze, test, and learn. </li> 
   <li class="readable-text" id="p200"> Now we have access to the data. The next step is to clean it and make it usable. We treat all the null values, NaN, junk values, duplicates, etc. </li> 
   <li class="readable-text" id="p201"> Once the data is clean and ready to be used, we perform an exploratory data analysis of it. Usually, during exploratory analysis, we identify patterns, cyclicity, aberrations, max-min range, standard deviation, etc. The outputs of the exploratory data analysis stage will be insights and understandings. We will also generate a few graphs and charts, as shown in figure 1.18. </li> 
   <li class="readable-text" id="p202"> We begin with the unsupervised approach now. We want to implement clustering methods, and hence we can try a few clustering methods like k-means, hierarchical clustering, etc. The clustering algorithms will result in homogeneous segments of customers based on their various attributes. </li> 
  </ol> 
  <div class="browsable-container figure-container" id="p203">  
   <img alt="figure" src="../Images/CH01_F18_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 1.18</span> Examples of the graphs and charts from the exploratory data analysis of the data</h5>
  </div> 
  <div class="readable-text list-body-item" id="p204"> 
   <p>In the case study, we will be working on the past two to three years of data, which is the training data. Since we are using an unsupervised approach, there is no target variable here. The algorithm will merge the customer segments that behave alike using their transactional patterns, their demographic patterns, and their purchase preferences. It will look like the results in figure 1.19.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p205">  
   <img alt="figure" src="../Images/CH01_F19_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 1.19</span> Output of the clustering algorithm where we can segment customers using various attributes</h5>
  </div> 
  <ol class=" faux-ol-li" style="list-style: none;"> 
   <li class="readable-text faux-li has-faux-ol-li-counter" id="p206"><span class="faux-ol-li-counter">6. </span> We now check how the various algorithms have performed; in other words, we will compare the accuracy of each algorithm. The final clustering algorithm chosen will result in homogeneous segments of customers, which can be targeted and offered customized offers. </li> 
   <li class="readable-text faux-li has-faux-ol-li-counter" id="p207"><span class="faux-ol-li-counter">7. </span> We discuss the results with the business stakeholders and make iterations based on the feedback. </li> 
   <li class="readable-text faux-li has-faux-ol-li-counter" id="p208"><span class="faux-ol-li-counter">8. </span> We deploy the solution in the production environment and are ready to work on new unseen datasets. </li> 
  </ol> 
  <div class="readable-text" id="p209"> 
   <p>These are the broad steps in an unsupervised problem. Algorithm creation and selection are tedious tasks. We will be studying these in detail later in the book.</p> 
  </div> 
  <div class="readable-text intended-text" id="p210"> 
   <p>GenAI most often starts with an unsupervised stage. This stage enables the model to learn patterns, structures, and relationships without explicit labels. It is sometimes referred to as the pretraining stage. Once the model has been pretrained, we move to the supervised stage. Here, the pretrained model is tailored to a specific task or domain using a labeled dataset.</p> 
  </div> 
  <div class="readable-text" id="p211"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.5.3</span> Semisupervised algorithms</h3> 
  </div> 
  <div class="readable-text" id="p212"> 
   <p>Semisupervised learning is a middle path of the supervised and unsupervised approaches. The primary reason for a semisupervised approach is the lack of availability of a complete <em>labeled</em> dataset for training. Formally put, the semisupervised approach uses both supervised and unsupervised approaches: supervised to classify the data points and unsupervised to group them together. </p> 
  </div> 
  <div class="readable-text intended-text" id="p213"> 
   <p>In semisupervised learning, we train initially on a smaller number of labeled data points available using a supervised algorithm. Then we use it to label or <em>pseudo-label</em> new data points. The two datasets (labeled and pseudo-labeled) are combined, and we use this dataset for further analysis. </p> 
  </div> 
  <div class="readable-text intended-text" id="p214"> 
   <p>Semisupervised algorithms are used in cases where the dataset is partially available, like images in the medical industry. If we are creating a cancer detection solution by analyzing the images of patients, we will likely not have enough sample sets of training images. Here, the semisupervised approach can be helpful.</p> 
  </div> 
  <div class="readable-text" id="p215"> 
   <h3 class=" readable-text-h3"><span class="num-string">1.5.4</span> Reinforcement learning</h3> 
  </div> 
  <div class="readable-text" id="p216"> 
   <p>Imagine you are playing a game of chess with a computer, and it goes like this:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p217"> <em>Round 1</em><em> </em>—You win after 5 moves. </li> 
   <li class="readable-text" id="p218"> <em>Round 2</em><em> </em>—You win after 8 moves. </li> 
   <li class="readable-text" id="p219"> <em>Round 3</em><em> </em>—You win after 14 moves. </li> 
   <li class="readable-text" id="p220"> <em>Round 4</em><em> </em>—You win after 21 moves. </li> 
   <li class="readable-text" id="p221"> <em>Round 5</em><em> </em>—The computer wins! </li> 
  </ul> 
  <div class="readable-text" id="p222"> 
   <p>What is happening here is the algorithm is training itself iteratively depending on each interaction and then correcting/improving itself. </p> 
  </div> 
  <div class="readable-text intended-text" id="p223"> 
   <p>Formally, reinforcement learning solutions are self-sustained solutions that train themselves using a sequence of trial and error. One sequence follows the other. The heart of reinforcement learning is reward signals. If the action is positive, the reward is positive, indicating to continue. If the action is negative, the reward will penalize the activity. Hence, the solution will always correct itself and move ahead, thereby improving itself iteratively. </p> 
  </div> 
  <div class="readable-text intended-text" id="p224"> 
   <p>Self-driving cars are the best examples of reinforcement learning algorithms. They detect when they should turn left or right, when to move, and when to stop. Modern video games also employ reinforcement learning algorithms. Reinforcement learning allows us to break the barriers of technology and imagine things that were earlier thought impossible.</p> 
  </div> 
  <div class="readable-text intended-text" id="p225"> 
   <p>With this, we have covered the different types of ML algorithms. Together, they are harnessing the true power of data and creating a long-lasting effect on our lives. But the heart of the solutions is the technology, which we have not discussed yet. We now move to the technology stack required to make these solutions tick.</p> 
  </div> 
  <div class="callout-container sidebar-container"> 
   <div class="readable-text" id="p226"> 
    <h5 class=" callout-container-h5 readable-text-h5">Exercise 1.1</h5> 
   </div> 
   <div class="readable-text" id="p227"> 
    <p>Use these questions to check your understanding:</p> 
   </div> 
   <ol> 
    <li class="readable-text" id="p228"> Why is ML so powerful that it is being used very heavily now? </li> 
    <li class="readable-text" id="p229"> What are the different types of ML algorithms, and how are they different from each other? </li> 
    <li class="readable-text" id="p230"> What are the steps in an ML project? </li> 
    <li class="readable-text" id="p231"> What is the role of data engineering, and why is it important? </li> 
    <li class="readable-text" id="p232"> What are the various tools available for ML? </li> 
   </ol> 
  </div> 
  <div class="readable-text" id="p233"> 
   <h2 class=" readable-text-h2"><span class="num-string">1.6</span> Concluding thoughts</h2> 
  </div> 
  <div class="readable-text" id="p234"> 
   <p>A common question is: Which is better, R or Python? Both are fantastic languages. Both are heavily used. But after the introduction of TensorFlow, Keras’s libraries on AI, the balance has slightly tilted in favor of Python.</p> 
  </div> 
  <div class="readable-text intended-text" id="p235"> 
   <p>You’ve now taken your first step in the journey toward learning unsupervised machine learning techniques. It is time to wrap up.</p> 
  </div> 
  <div class="readable-text intended-text" id="p236"> 
   <p>ML and AI are indeed pathbreaking. They are changing the way we travel, order food, plan, buy, see a doctor, order prescriptions—they are making a dent everywhere. ML is indeed a powerful capability that is paving the path for the future and is proving much better than existing technology stacks when it comes to pattern identification, anomaly detection, customizations, and automation of tasks. Autonomous driving, cancer detection, fraud identification, facial recognition, image captioning, and chatbots are only a few examples where ML and AI are outperforming traditional technologies. And now is the best time to enter this field. This sector is attracting investments from almost all business functions. The field has created thousands of job opportunities across the spectrum.</p> 
  </div> 
  <div class="readable-text intended-text" id="p237"> 
   <p>At the same time, the field lacks trained professionals: data analysts, data engineers, visualization experts, data scientists, and data practitioners. They are all rare breeds now. The field requires a regular supply of budding talents who will become the leaders of tomorrow and will make data-driven decisions. We have only scratched the surface of understanding the power of data—there are still miles to be covered.</p> 
  </div> 
  <div class="readable-text intended-text" id="p238"> 
   <p>In the following chapter, we will dive deeper into the unsupervised learning concepts of clustering. The mathematical and statistical foundations, a pragmatic case study, and Python implementation are discussed. The discussion includes the simpler clustering algorithms: k-means clustering, hierarchical clustering, and DBSCAN. In the later chapters of the book, we will study more complex clustering topics like Gaussian mixture modeling clustering, time series clustering, fuzzy clustering, etc. </p> 
  </div> 
  <div class="readable-text" id="p239"> 
   <h2 class=" readable-text-h2">Summary</h2> 
  </div> 
  <ul> 
   <li class="readable-text" id="p240"> Data can be conceptualized as an interconnected set of facts and statistics necessary for analysis, characterized by unique traits and governed by specific management principles. </li> 
   <li class="readable-text" id="p241"> Real-world activities such as mobile calls, online transactions, and social media interactions continually generate data, underscoring its omnipresence in modern life. </li> 
   <li class="readable-text" id="p242"> Raw data requires cleaning, organization, and analysis to be converted effectively into information and insights that can drive business decisions and actions. </li> 
   <li class="readable-text" id="p243"> Data can be broadly classified into structured datasets, which follow a clear row-column format, and unstructured datasets, like text and images, which require more advanced analysis techniques. </li> 
   <li class="readable-text" id="p244"> To analyze unstructured data, we typically transform it into numerical representations, often utilizing deep learning models such as CNNs and RNNs. </li> 
   <li class="readable-text" id="p245"> A clear, concise, achievable, and measurable business problem is a vital step to ensure the success of a data science project. </li> 
   <li class="readable-text" id="p246"> High-quality data is essential for reliable analysis and is characterized by attributes such as completeness, validity, accuracy, representativeness, availability, consistency, timeliness, and integrity. </li> 
   <li class="readable-text" id="p247"> Effective data engineering and management are crucial for preparing data for analysis involving techniques like ETL processes and data cleaning. </li> 
   <li class="readable-text" id="p248"> The role of UI/UX is of paramount importance to ensure adoption and usage by the end consumers; otherwise, ML will just be a shiny piece sitting on a shelf. </li> 
   <li class="readable-text" id="p249"> Interconnected fields like data analysis, ML, AI, and business intelligence each play a critical role in processing and deriving insights from data. </li> 
   <li class="readable-text" id="p250"> Supervised learning is an ML approach that uses existing data to predict future outcomes, common in tasks like demand prediction and fraud detection. </li> 
   <li class="readable-text" id="p251"> Supervised learning is divided into regression and classification tasks, each with numerous available algorithms to model quantitative or categorical outcomes, respectively. </li> 
   <li class="readable-text" id="p252"> Unsupervised learning algorithms discover patterns and relationships in data independently of predefined target variables, useful in activities like segmentation and anomaly detection. </li> 
   <li class="readable-text" id="p253"> Variants of unsupervised learning algorithms include clustering techniques and methods for reducing data dimensionality, offering flexibility and performance in pattern recognition. </li> 
   <li class="readable-text" id="p254"> Semisupervised learning bridges supervised and unsupervised methods and is effective when dealing with datasets that are partially labeled. </li> 
   <li class="readable-text" id="p255"> Reinforcement learning involves systems that learn by trial and error, rewarding desired outcomes, and are applied in dynamic decision-making tasks, such as autonomous vehicle navigation. </li> 
   <li class="readable-text" id="p256"> Technological solutions are at the heart of modern data-driven strategies, and understanding the technological stack is essential to maximize the effect and benefits of data solutions. </li> 
  </ul>
 </body></html>