<html><head></head><body><section data-pdf-bookmark="Chapter 8. Using Your Data as a Differentiator" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch08_using_your_data_as_a_differentiator_1740182052172518">&#13;
<h1><span class="label">Chapter 8. </span>Using Your Data as a Differentiator</h1>&#13;
&#13;
<p>In the last chapter, we spent some time giving you a point of view on the power (and potential) of small language models (SLMs)<a contenteditable="false" data-primary="small language models (SLMs)" data-type="indexterm" id="id1043"/>. We introduced the notion that one model doesn’t have to—and won’t—rule them all. We outlined how humongous models are clunky to operate, expensive, and center power on the few (vendors) that can afford to build them. But, what’s more, they won’t help you take advantage of your data (unless you give it away) to generate value tailored to your business—in short, they help you to be an AI User as opposed to an AI Value Creator<a contenteditable="false" data-primary="AI Value Creator" data-secondary="SLMs as tool for" data-type="indexterm" id="id1044"/>. We posit, and will continue to prove, how highly focused models can do some incredible things. We want to see an AI future that is open; hence, we oppose the notion that one super LLM (large language model) should rule them all.</p>&#13;
&#13;
<p>A fundamental premise of this book is the only way for you to become an AI Value Creator is to first see your data as a dormant superpower. To maximize what you can do with AI and create value, we believe big bets must be placed on fostering a collaborative ecosystem across your company that can put your data to work, creating value for <em>you</em>. In fact, we think this notion is so important, it literally became the title of this book: <em>AI Value Creators</em>.</p>&#13;
&#13;
<p>In this chapter, we look at how developers and domain experts in your company can leverage new techniques in model customization to contribute to your company’s Gen AI models, driving defensible and differentiated AI innovation for <em>your</em> business: create value.</p>&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="Customizing Open Source for the Enterprise: A New Way of Looking at Enterprise Data" data-type="sect1"><div class="sect1" id="ch08_customizing_open_source_for_the_enterprise_a_new_1740182052172650">&#13;
<h1 class="less_space">Customizing Open Source for the Enterprise: A New Way of Looking at Enterprise Data</h1>&#13;
&#13;
<p>As we noted earlier in this book, less than 1% of enterprise data resides in today’s LLMs. And if you’re going to become the AI Value Creator that this book was written to help you become, you’re going to have to work in your most valuable asset (your enterprise data) and have it part of your LLM strategy—ultimately unlocking a plethora of value creation opportunities.</p>&#13;
&#13;
<p>To really understand how profound this is, let’s time-travel back to the origin of our digital world, an origin that was understood and conceptualized almost 350 years ago by Gottfried Wilhelm Leibniz<a contenteditable="false" data-primary="Leibniz, Gottfried Wilhelm" data-type="indexterm" id="id1045"/>. Even back then, Leibniz already understood that you could take the information that was available around us in the form of language or mathematics and encode it in a binary representation. (Leibniz not only created binary math<a contenteditable="false" data-primary="binary math" data-type="indexterm" id="id1046"/>, but he also help to create calculus, so we can see why some of you may not be fans.) He famously said, “To create everything, one thing is sufficient.” Leibniz clearly knew the value and the power of representing information differently (in this case, binary notation). Fast-forward to today and you’ll easily note that the last few decades have seen a tremendous amount of value creation and business transformation driven by the evolution and expressiveness of our world’s data representations<a contenteditable="false" data-primary="data representations" data-type="indexterm" id="xi_datarepresentations89906"/>. For example, today, taste and smells have data representations, ultimately represented by numbers that further translate into just ones and zeros by the time a computer starts working on the data. In fact, perfume and flavor houses literally discover and propose new products using vectors to represent lemon-fresh or honey butter. Think about it. Who but AI could have ever thought of creating Everything Bagel ice cream! Truth be told, long before LLMs came along, wine and perfume descriptions have been entertaining us with their poetic (and often ridiculous) creativity for years. Because let’s be honest, who really smells “a whisper of sun-kissed elderflower on a dewy morning” or tastes “hints of melancholy with a bold finish of existential crisis”? Going forward, expect the creativity to go to new (polite for “potentially even more ridiculous”) levels thanks to LLMs.</p>&#13;
&#13;
<section data-pdf-bookmark="The Original Eras Tour: Looking Back a Few Decades on Data Representations" data-type="sect2"><div class="sect2" id="ch08_the_original_eras_tour_looking_back_a_few_decades_1740182052172720">&#13;
<h2>The Original Eras Tour: Looking Back a Few Decades on <span class="keep-together">Data Representations</span></h2>&#13;
&#13;
<p>Over the last decades<a contenteditable="false" data-primary="data representations" data-secondary="historical perspective" data-type="indexterm" id="xi_datarepresentationshistoricalperspective81235"/>, new representations of data have created completely new opportunities and capabilities for all businesses and industries. We thought it worthwhile to spend some time on this topic to help you fully appreciate an LLM’s value for your enterprise—<em>especially </em>when it’s nuanced with your data. The point is that your enterprise data can be folded into this new data representation (an LLM) that can make your data usable in ways that only movies could have imagined just a few years ago, and that can bring enormous amounts of value to your company.</p>&#13;
&#13;
<p>When you think about it, aside from the weights in a model, AI is just compressed data. It’s just a new representation of that data and, as it turns out, over the last decades, there have been various epochs of data representations, each one unlocking a new era of value creation. This current AI revolution has <em>a lot </em>to do with the power of data representations and the power of being able to encode incredible amounts of information, of every possible form, inside these new, incredibly capable “vessels” that are foundation models (LLMs). Here is how we see some of those data representation eras over the years.</p>&#13;
&#13;
<section data-pdf-bookmark="Up to the 1980s: Expert systems" data-type="sect3"><div class="sect3" id="ch08_up_to_the_1980s_expert_systems_1740182052172786">&#13;
<h3>Up to the 1980s: Expert systems</h3>&#13;
&#13;
<p>These were (and since they are still used today<a contenteditable="false" data-primary="expert systems, data representations" data-type="indexterm" id="id1047"/>, perhaps we should have written “are”) <em>handcrafted symbolic representations of our data</em>. Data was encoded in a relational database, which created a new way in which businesses could organize and connect to data in a way they couldn’t easily do before. This era had a very profound impact on business. Suddenly, a company could automate things like payroll, transactions could connect to inventories, and other core processes. Along the way, expert systems were created. Humans wrote rules for logical business flows with connected structured data. A great example is fraud detection or supply chain management—and many companies still use this method today—there’s a rule and if breached, a flag appears or an action is undertaken.</p>&#13;
&#13;
<p>Rules are great for a subset of things, but they aren’t all that creative and there are always exceptions, so they can only really get so much right. On the backend of a rules-based system is a lot of manual effort to maintain and build those rules. A new rule must be written for each individual situation. (This is why we call this representational era handcrafted. For example, storing data in a relational database required a DBA to handcraft a schema to receive it. Humans do a lot of the work and a lot of the thinking around the design of that work too.) Perhaps a way to spot potential credit card fraud at a gas station was with a $1 purchase...new rule. Over time, that rule got diluted as a predictor, and some other indicator proved useful...new rule. It’s a simple example, but it used to happen all the time (or it didn’t, and companies would get frustrated). In the end, these systems worked as long as the rules were right. But over time, there were so many variations and rules that most of these systems collapsed on themselves. Now think about today’s digital economy—how can a rules-based system respond to threats from increased access points and complex transactions, identify signals left by perpetrators hidden in noisy and ephemeral daily activity, or respond to coordinated attacks with consolidated monitoring in a timely fashion? They can’t.</p>&#13;
</div></section>&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="1980s to ~2010: Machine learning" data-type="sect3"><div class="sect3" id="ch08_section_1980s_to_2010_machine_learning_1740182052172846">&#13;
<h3 class="less_space">1980s to ~2010: Machine learning</h3>&#13;
&#13;
<p>Now we move<a contenteditable="false" data-primary="machine learning, data representations" data-type="indexterm" id="id1048"/> into an era of <em>more task-specific, less handcrafted feature representations of our data</em>. How did this happen? Because as more data became available, there was a shift toward data-driven approaches. It was a really big thing back then, because machines started to generate their own rules from that data and learn new representations of our world by being shown examples of it, as opposed to being given hand-coded rules (programmatically). Very cool! Many of these techniques are still used by data scientists today; for example, decision trees, support vector machines (SVMs), k-nearest neighbor, and more. This era was about learning how to get computers to help build features and getting those machines to learn from their insights. Those learnings were good, perhaps great. And while machines (with the help of humans) were using data in new ways, new representations and encoding mechanisms emerged—for example, graph-based representations of data (represented as networks with nodes and edges). Suddenly, the world starting using this new data representation and found a way to traverse it and it became critical to businesses doing things like internet search, social media, and connecting people and groups.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="2010 to ~2017: Deep learning" data-type="sect3"><div class="sect3" id="ch08_section_2010_to_2017_deep_learning_1740182052172903">&#13;
<h3>2010 to ~2017: Deep learning</h3>&#13;
&#13;
<p>Now we move into the big data era<a contenteditable="false" data-primary="deep learning" data-type="indexterm" id="id1049"/> (remember those 3 Vs: volume, velocity, and variety). Computers could now access more data than ever. Now computers didn’t just discover but could create new data representations. Enter the world of <em>task-specific learned feature </em><em>representations of our data</em>. In this era, the world got access to massive amounts of compute (thanks to the cloud and GPUs) and ever-increasing amounts of data (thanks to the internet). Computers created and built feature representations, but everything was still heavily reliant on human expertise and loads of manual efforts. Things like the availability of resources to process more data and a lack of capabilities to build more complex models were still “getting in the way.” For example, AI for natural language processing (NLP) didn’t have much of a memory beyond a few words.</p>&#13;
&#13;
<p>This was the start of the deep learning era. There are many things beyond the scope of this book, like activation functions, that came to life to help this era. We had the synergistic combination of more and more data (starting from the big data era, when the world was busy collecting data) and compute (namely, it was discovered the GPUs we used for gaming could provide powerful processing capabilities because of the way they handle matrix math, which is the math deep learning does). Now some very cool things started to happen in this era, perhaps not magical (yet...that’s the next phase). All that math-computer power (GPUs to build the representations) got mixed with a consumability model (the cloud) and suddenly anyone could build AI models for less than the cost of a cheap cup of coffee. In this era, computers started to learn from massive amounts of data and build out task-specific feature representations; for example, computer vision to detect anomalies in an X-ray or a defect in a weld point on a production line, and so on. Some of those feature representations were wildly complex and the computers invented new composite features, like mixing together gender, location, height, and profession into a coarsified feature that would describe something.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Today: Foundation models (aka LLMs)" data-type="sect3"><div class="sect3" id="ch08_today_foundation_models_1740182052172957">&#13;
<h3>Today: Foundation models (aka LLMs)</h3>&#13;
&#13;
<p>Today, we can <em>encode any knowledge form and work with that data<a contenteditable="false" data-primary="foundation models (FMs)" data-secondary="data representations" data-type="indexterm" id="xi_foundationmodelsFMsdatarepresentations83083"/> in ways we never imagined</em>.</p>&#13;
&#13;
<p>Like we said earlier, foundation models are all about the power to encode incredible amounts of information of every possible form inside these new incredible model types. Our world has entered the era of LLMs where the approach not only takes advantage of massive compute capability and all that data, but a new technology (self-supervised learning at scale—thanks to transformers) drastically reduced the amount of curated labeled data needed to train a model. This is a massive departure from the past.</p>&#13;
&#13;
<p>Specifically, this new data representation is trained on vast, immense datasets and can fulfill a broad range of general tasks. These new data representations (LLMs) serve as the base or building blocks for crafting more specialized applications. Their flexibility and massive size set them apart from the previous era’s representations, which were trained on limited datasets to accomplish specific tasks.</p>&#13;
&#13;
<p>These new data representations are created by taking training data and breaking it down into smaller chunks, which are referred<a contenteditable="false" data-primary="tokens, data representation" data-type="indexterm" id="id1050"/> to as <em>tokens</em> (a token can be a word or a fragment of a word). This process creates trillions of these tokens, which are then converted into a vector, and those vectors<a contenteditable="false" data-primary="vectors" data-type="indexterm" id="id1051"/> are used to represent the tokens in a form an AI can understand. But these tokens can be anything, and as you’ve learned earlier, that means the data stored inside doesn’t have to be words—it can be anything (code, images, sound, taste and smell profiles, and more). As these tokens (not converted to vectors) pass through the layers of the neural network during training, a series of mathematical operations, which are mostly made up of matrix multiplications and a few other simple operations, are applied—but this is all done at a massive scale. During this build phase, data is combined and recombined across changing sequences of these tokens. In fact, information from different modalities (audio and text) can be combined into the same foundation model during training. A great example of this is OpenAI’s latest GPT that combines the power of text and image generation (from their DALL-E model) in one place.</p>&#13;
&#13;
<p>During training, network parameters get adjusted so the outputted LLMs get better and better at representing the sequences of the input tokens. And as it goes through this training process, the model learns more and more of the structure of the data it’s being trained on, its nuances, and the knowledge and correlations within. Again, it’s not really magic; it’s just math, human ingenuity, and a lot of computing power.</p>&#13;
&#13;
<p>Now the power of this new data representation, which is encoded within an LLM, derives its capability from its scale (the sheer amount of data that can be brought into it), from its connectivity of the data (semantic connections are made across wide <span class="keep-together">disparate</span> input data, which makes them very expressive), and from its <span class="keep-together">multimodality</span>.</p>&#13;
&#13;
<p>Now here’s our observation and the reason for this chapter. Over the last couple of years, we’ve witnessed these representations pretty much take all the public data that’s available in the world and pull it inside an LLM. For the sake of argument, let’s assume 100% of that kind of data has made its way into an LLM. Now contrast this with our previously shared estimate that barely 1% of enterprise data has made its way into an off-the-shelf LLM. This is a very interesting contrast: almost all public data has made its way in, and almost all enterprise data has not<a contenteditable="false" data-primary="" data-startref="xi_datarepresentationshistoricalperspective81235" data-type="indexterm" id="id1052"/><a contenteditable="false" data-primary="" data-startref="xi_foundationmodelsFMsdatarepresentations83083" data-type="indexterm" id="id1053"/>.</p>&#13;
</div></section>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Stand Up and Represent!...Your Data" data-type="sect1"><div class="sect1" id="ch08_stand_up_and_represent_your_data_1740182052173071">&#13;
<h1>Stand Up and Represent!...Your Data</h1>&#13;
&#13;
<p>By this point in the book<a contenteditable="false" data-primary="data representations" data-secondary="steps to deployment of" data-type="indexterm" id="xi_datarepresentationsstepstodeploymentof84237"/>, you should have a sense of just how much of an inflection point the era of AI really is. Data collected at enormous volumes is a problem well-solved (understanding it is a different problem), and compute is available en masse—these forces synergized with new AI techniques that made for a perfect storm for AI disruption. So how do you get started putting your data to work? As we discussed in <a data-type="xref" href="ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635">Chapter 5</a>, you have to start with a trusted LLM. Once you’ve identified a base model that you can trust, it’s time to get your enterprise data into this era’s data-powerful representation. Finally, you deploy your customized model and scale and create value with your AI. So, let’s talk about these three steps.</p>&#13;
&#13;
<section data-pdf-bookmark="Step 1: It All Starts with Trust" data-type="sect2"><div class="sect2" id="ch08_step_1_it_all_starts_with_trust_1740182052173140">&#13;
<h2>Step 1: It All Starts with Trust</h2>&#13;
&#13;
<p>Do not underestimate this turning point for AI: everything in AI will be different<a contenteditable="false" data-primary="foundation models (FMs)" data-secondary="selecting a trusted model to build from" data-type="indexterm" id="xi_foundationmodelsFMsselectingatrustedmodeltobuildfrom84596"/> from here on out because of this latest representational format.</p>&#13;
&#13;
<p>Ultimately, to create value from your enterprise data, the very first step has nothing to do with your data at all. Your first step will be to select a trusted model—think of it as a “value” vessel, or foundation—to build upon. This step is critical because your enterprise data will be added on top of this starting point, so it’ll be quite beneficial to know what is already inside that foundation, the “recipe” used to make it, and how it works. This all goes back to <a data-type="xref" href="ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974">Chapter 1</a>, where we told you to ask your LLM vendor questions like, “What data did you use to train your model?” and consider answers like “It’s none of your business” and “We don’t know” as unacceptable. Again, is this really any different than where you choose to build a house? The foundation has to be solid. Does your foundation (LLM) contain copyright infringement, hate, anger, profanity (HAP), bias, racism, pornography, and more? If today’s LLMs are compressed representations of the <span class="keep-together">internet</span>, and you believe everything on the internet is true, there is no harmful content, and you have none of these concerns, then you’re good to go! Have you ever gone through a Reddit thread and seen the toxicity in some of those groups? (And it’s far worse in the rooms we don’t go into.) Is that what you want to mix your precious data with when you try to put it to work? This will be at the core of the model that will ultimately be enriched to represent your business!</p>&#13;
&#13;
<p>Let’s get into the why, building on the same water quality analogy we used in <a data-type="xref" href="ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635">Chapter 5</a> when we discussed the importance of transparency of data lineage in an LLM. Imagine that we give you a glass of water (an LLM) and your intent is to add lemon juice and sugar (we’ll consider this your enterprise data) with the goal of making lemonade. If we gave you an opaque glass full of water (an LLM for which you know nothing about the data, and when you ask where did we get the water from, you’re not given any straight answers), would you feel comfortable using it with your fresh lemons and expensive organic cane sugar? Think about it: the glass is opaque, you can’t even see inside it! The water inside that glass could pure spring water, but it could also be cloudy and murky puddle water, or even contaminated water! If you couldn’t see inside that glass, would you still drink what’s inside it after adding tons of high-quality sugar and lemon to it? Probably not, so why would you do this with one of your company’s most previous assets—your data?</p>&#13;
&#13;
<p>Similarly, with LLMs, it is nearly impossible to isolate or constrain a model to give responses informed by the enterprise data that you added and have it ignore all that cloudy murky water (data) that’s in the glass. Sure, techniques like retrieval-augmented generation (RAG) and fine-turning can help, but even when your model is customized, it is most likely still going to inherit some degree of performance and safety (or lack thereof) characteristics from the base model you used as a starting point.</p>&#13;
&#13;
<p>In this analogy, it’s important that <em>the glass you’re handed to make lemonade is transparent</em> so that you can see inside of it. You need to know where the water is coming from that serves as the base for your lemonade so that when you mix your ingredients together, you have a good idea of what’s going to happen, how it will look, and how it’s going to taste. It’s the same when you want to put your data to work with an LLM. You need a base model that is transparent in terms of what data was used and the recipe used to make it. That way, when you add your data to it, you do so confidently, safely, and securely.</p>&#13;
&#13;
<p>Another aspect of transparency is having broad commercial rights and freedom of action<a contenteditable="false" data-primary="legal considerations" data-secondary="creating your business AI model" data-type="indexterm" id="id1054"/> for the final model that is created. Remember, this chapter <em>is not</em> a chapter about model providers; it is a chapter about <em>your</em> data. You need to have permissive rights for your enhanced model so that when you encode your information into the model you choose for your business, you have <em>full freedom of action</em> to do what you need to do for your business. And, because you’re building on top of a model that has public data from the outside world, it should also be vendor indemnified from legal claims.</p>&#13;
&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>As we talked<a contenteditable="false" data-primary="indemnification due diligence" data-type="indexterm" id="id1055"/> about in <a data-type="xref" href="ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635">Chapter 5</a>, ensure you do your due diligence around what indemnifications your LLM comes with. Today, every vendor out there is offering some sort of indemnification, but you need to know that every vendor’s indemnification protections are different. Some don’t indemnify on what’s created, some fully indemnify, some limit the size of the indemnification, some don’t indemnify on the output but do in the usage of, and so on. Yes, you’re going to have to get your legal team involved.</p>&#13;
</div>&#13;
&#13;
&#13;
<section data-pdf-bookmark="The IBM commercial—in Granite you should trust" data-type="sect3"><div class="sect3" id="ch08_the_ibm_commercial_in_granite_you_should_trust_1740182052173200">&#13;
<h3>The IBM commercial—in Granite you should trust</h3>&#13;
&#13;
<p>We will say it again: we hope you agree that almost all of this book has been anything but about IBM<a contenteditable="false" data-primary="Granite" data-type="indexterm" id="xi_Granite858114"/><a contenteditable="false" data-primary="IBM" data-secondary="Granite" data-type="indexterm" id="xi_IBMGranite858114"/><a contenteditable="false" data-primary="models" data-secondary="IBM Granite" data-type="indexterm" id="xi_modelsIBMGranite858114"/>. We hope you’ve appreciated the care we took to build your AI acumen, frame out the use cases, and note the things to watch out for and the things you’ll want to ensure you’ve got straightened out as you embark on your AI journey—with but one or two tiny IBM commercials. With that said, we thought we’d afford ourselves a page or two to focus on an open source model you’ll notice we haven’t spent much time on: IBM Granite. We’re very proud of the IBM Granite series because it hits on the very things we’ve discussed: transparency in the data used to train the models (check out the pages of details on the training data used in Granite 3 in its technical report<sup><a data-type="noteref" href="ch08.html#id1056" id="id1056-marker">1</a></sup>); the models are released in the open with a no-nonsense permissive Apache 2.0 license; and most importantly, the Granite family is designed to have cost-efficient, fit-for-purpose models that can be further customized with enterprise data (we will dive into the details a little later in this chapter).</p>&#13;
&#13;
<p><a data-type="xref" href="#ch08_figure_1_1740182052159344">Figure 8-1</a> shows the breadth of models in the IBM Granite 3 family (and by the time you read this book, Granite 4 will likely be released, or close to it).</p>&#13;
&#13;
<p>Here is a high-level overview of what the models in <a data-type="xref" href="#ch08_figure_1_1740182052159344">Figure 8-1</a> are meant for and why they matter:</p>&#13;
&#13;
<dl>&#13;
	<dt>Granite Language</dt>&#13;
	<dd>&#13;
	<p>These are your bread-and-butter workhorse LLMs for enterprise language tasks. These models deliver top performance for their size and are designed to be further customized using techniques like PEFT and InstructLab.</p>&#13;
	</dd>&#13;
	<dt>Granite Vision</dt>&#13;
	<dd>&#13;
	<p>These are multimodal models that are specialized on vision <em>understanding</em> tasks (image + prompt in, text out). Think of these for any document understanding, chart Q&amp;A, like having an LLM explain trend lines and opine on things in a bar graph, or even multimodal RAG tasks.</p>&#13;
	</dd>&#13;
	<dt>Granite Guardian</dt>&#13;
	<dd>&#13;
	<p>These are “guardrail” models (we discussed these in <a data-type="xref" href="ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635">Chapter 5</a>) that sit alongside any deployed LLM (not just Granite) and help monitor inputs to and outputs from the model, making sure there is no harmful or biased content, hallucinations, etc.</p>&#13;
	</dd>&#13;
	<dt>Granite Embedding</dt>&#13;
	<dd>&#13;
	<p>These models convert large amounts of language and code into vector embeddings or numeric representations—this is very useful for enabling RAG <span class="keep-together">workflows</span>.</p>&#13;
	</dd>&#13;
	<dt>Granite Time Series</dt>&#13;
	<dd>&#13;
	<p>These are very small, GenAI-based forecasting models. Instead of being trained on large amounts of language, these models were trained on large amounts of time series data points to get their predictive superpowers.</p>&#13;
	</dd>&#13;
	<dt>Granite Geospatial</dt>&#13;
	<dd>&#13;
	<p>These Earth Science multimodal models were developed in collaboration with NASA to predict everything from weather forecasts to the amount of biomass in a satellite image.</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<figure><div class="figure" id="ch08_figure_1_1740182052159344"><img src="assets/aivc_0801.png"/>&#13;
<h6><span class="label">Figure 8-1. </span>Snapshot of the IBM Granite model family</h6>&#13;
</div></figure>&#13;
&#13;
<p>The key tenets of IBM’s Granite models are transparency<a contenteditable="false" data-primary="transparency" data-secondary="IBM Granite" data-type="indexterm" id="id1057"/> and flexibility<a contenteditable="false" data-primary="" data-startref="xi_foundationmodelsFMsselectingatrustedmodeltobuildfrom84596" data-type="indexterm" id="id1058"/>. Every Granite model is released with full disclosure of the data used in training and under an Apache 2.0 license to provide users the maximum level of freedom of action to use and deploy them for their business<a contenteditable="false" data-primary="" data-startref="xi_Granite858114" data-type="indexterm" id="id1059"/><a contenteditable="false" data-primary="" data-startref="xi_opensourceAIselectingafoundationmodel846114" data-type="indexterm" id="id1060"/><a contenteditable="false" data-startref="xi_IBMGranite858114" data-type="indexterm" id="id1061"/><a contenteditable="false" data-primary="" data-startref="xi_modelsIBMGranite858114" data-type="indexterm" id="id1062"/>. It is this commitment to transparency and openness that awarded Granite one of the highest scores in <a href="https://oreil.ly/FQHb5">Stanford’s Transparency Index ranking of LLM providers</a>.</p>&#13;
&#13;
&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Step 2: Representing your Enterprise Data within an LLM" data-type="sect2"><div class="sect2" id="ch08_step_2_representing_your_enterprise_data_within_a_1740182052173263">&#13;
<h2>Step 2: Representing your Enterprise Data within an LLM</h2>&#13;
&#13;
<p>Once you have selected a trusted model starting point (in our analogy, this is your transparent glass filled with pristine water that you will use to make lemonade), the next step is to select the method by which you will add your enterprise data to that foundation (the sugar and lemons that turn water into lemonade)<a contenteditable="false" data-primary="large language models (LLMs)" data-secondary="representing data within" data-type="indexterm" id="xi_largelanguagemodelsLLMsrepresentingdatawithin893185"/>. There are multiple techniques available, including these common patterns:</p>&#13;
&#13;
<dl>&#13;
	<dt>Retrieval-augmented generation (RAG)</dt>&#13;
	<dd>&#13;
	<p>You might already be familiar with RAG<a contenteditable="false" data-primary="retrieval-augmented generation (RAG)" data-type="indexterm" id="id1063"/><a contenteditable="false" data-primary="RAG (retrieval-augmented generation)" data-type="indexterm" id="id1064"/>, as it is one of the top patterns deployed in enterprises today. We alluded to this pattern throughout this book, but it’s worth explicitly talking about it here because it’s a pretty common mechanism to add enterprise data to an LLM. In a RAG pattern, once a query is submitted by a user, that query is used to retrieve relevant enterprise information from (typically) a database using essentially a similarity match between the text in the query and the text in the database. (This database is typically a vector database that <span class="keep-together">supports</span> semantic searching, but it could be a traditional relational database too, or a hybrid version of the two, and even files on an object storage service, among other options.) Then the original user query is concatenated with the retrieved information (often called the grounding context<a contenteditable="false" data-primary="grounding context, RAG" data-type="indexterm" id="id1065"/>) into a prompt that is fed to the LLM. The LLM can now use both its vast knowledge accrued in training alongside the retrieved information provided in the prompt to answer the question. As you may have inferred, in a RAG pattern, the model weights are not touched at all, and this has some upsides and downsides to it. RAG is an exceptional technique, especially when it is important to have the very latest information available whenever answering a user query (it is much easier to update a supporting database with the latest and greatest details than to retrain or fine-tune a model with the updated information). However, RAG does have several downsides. First, there are lots of dependencies and complexities that have to be managed; RAG is not just a model, it’s a system. Another is that every time you want the model to answer a question—for example, about some internal HR policy—you need to provide the entire text of that HR policy to the LLM (this also drives up inferencing costs, over and over again). Related to this is the fact that an LLM never really internalizes the information that is provided in a RAG workflow, which is to say it isn’t learning new concepts and applying them in new ways across various tasks.</p>&#13;
	</dd>&#13;
	<dt>Fine-tuning<strong> </strong></dt>&#13;
	<dd>&#13;
	<p>Another common approach for customizing an LLM with enterprise data is fine-tuning<a contenteditable="false" data-primary="fine-tuning LLM with enterprise data" data-type="indexterm" id="xi_finetuningLLMwithenterprisedata8101100"/><a contenteditable="false" data-primary="models" data-secondary="fine-tuning with enterprise data" data-type="indexterm" id="xi_modelsfinetuningwithenterprisedata8101100"/>. Fine-tuning is where the actual weights of the model are updated based on new data (those input/output training pairs we’ve referred to throughout this book). This approach can be done with far less compute than retraining the original model from scratch and with less data. This technique offers a more reasonable starting point for AI Value Creators to start customizing their models. There are many different types of fine-tuning techniques. One is called supervised fine-tuning (SFT), where all the parameters are updated, and another is called parameter-efficient fine-tuning (PEFT) where only a portion of the parameters are updated. There are also methods like low-rank adaptation (LoRA) where an external (to the LLM) module of parameters is trained to work with the base model. LoRAs are convenient because these modules can then be removed when they are not needed or swapped out for new modules when the model is doing a different task. For example, perhaps you run a role-playing game (RPG) company and build a LoRA adapter on top of your LLM for game dialog and nonplayer character interaction, but another LoRA adapter gets subbed in for storytelling and narration. LoRA adapters have their drawbacks too—as you can imagine, if you wanted 50 fine-tuned customizations, then you’re managing the lifecycle of 50 different adapters. We’d also speculate that since they use very low-rank matrices, at some point their data capacity might be limited.</p>&#13;
&#13;
	<p>At the end of the day, the fine-tuning method you’ll eventually choose depends on your performance goals and cost constraints. The more parameters you target, the better the performance, but the more expensive it will be to train the model. While fine-tuning provides a way to intrinsically improve a model based on proprietary data, models that are fine-tuned also suffer<a contenteditable="false" data-primary="catastrophic forgetting" data-type="indexterm" id="id1066"/> from what is called <em>catastrophic forgetting</em>. This basically means that once you fine-tune a model on a task, the model becomes a specialist in it; that is to say, it is very good at that task, but it loses (forgets) some of its ability as a generalist to try and execute tasks it used to know how to do. This means, for every task you want to train your model on, you need to maintain a separate, fine-tuned version of that model (or in the case of LoRAs, a separate LoRA adapter for each important task).</p>&#13;
	</dd>&#13;
	<dt>InstructLab</dt>&#13;
	<dd>&#13;
	<p>InstructLab<a contenteditable="false" data-primary="InstructLab" data-type="indexterm" id="xi_InstructLab810629"/><a contenteditable="false" data-primary="teacher model" data-type="indexterm" id="xi_teachermodel810629"/> is an open source form of fine-tuning cooked up at Red Hat that was specifically designed for infusing proprietary enterprise knowledge back into an LLM in a collaborative manner while maintaining the LLM’s general-purpose capabilities.</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="Introducing InstructLab" data-type="sect3"><div class="sect3" id="ch08_introducing_instructlab_1740182052173326">&#13;
<h3 class="less_space">Introducing InstructLab</h3>&#13;
&#13;
<p>The open source <a href="https://instructlab.ai">InstructLab</a> method for tuning LLMs was designed from the start to address the challenges faced by AI practitioners who want to specialize and deploy LLMs for <a href="https://github.com/instructlab">specific business needs</a>. Not only does InstructLab facilitate specializing a model on domain-specific data, the goal of InstructLab is to make contributing to LLMs as easy as a developer might contribute to any other software project. InstructLab came about to try and bridge some of the gaps between how open source software works and how open source AI was working, and it now has both an open source presence and enterprise offering supported by Red Hat.</p>&#13;
&#13;
<p>InstructLab aims to shape the future of GenAI by providing a framework to enable teams and communities to contribute knowledge and skill to existing LLMs in an accessible way. Core to InstructLab is a novel model alignment method<a contenteditable="false" data-primary="model alignment method" data-type="indexterm" id="id1067"/><a contenteditable="false" data-primary="Large-scale Alignment for chatBots (LAB)" data-type="indexterm" id="id1068"/><a contenteditable="false" data-primary="LAB (Large-scale Alignment for chatBots)" data-type="indexterm" id="id1069"/> called <em>Large-scale Alignment for chatBots</em> (LAB).<sup><a data-type="noteref" href="ch08.html#id1070" id="id1070-marker">2</a></sup></p>&#13;
&#13;
<p>As we alluded to in the previous section, there are many communities rapidly embracing and extending permissively licensed open source AI models<a contenteditable="false" data-primary="open source AI" data-secondary="friction points for using" data-type="indexterm" id="id1071"/>, but they’ve all been faced with three main points of friction that is a problem well solved for traditional open source software, namely:</p>&#13;
&#13;
<dl>&#13;
	<dt>There’s no way to contribute back to those base LLMs directly</dt>&#13;
	<dd>&#13;
	<p>Enhancements show up as forks (search around and you’ll find an uncontrollable, ever-populating massive herd of Llamas—one-off, fine-tuned versions of the Llama LLM—roaming our GenAI world), and this forces you to choose a “best-fit” model that isn’t easily extensible. Also, these forks are expensive for model creators to maintain because what happens when the “parent” Llama changes? How do you get those enhancements? And we didn’t even account for sifting through the massive Llama herd to figure out which Llama is right for you.</p>&#13;
	</dd>&#13;
	<dt>There’s a high barrier to entry if you want to contribute back into a model</dt>&#13;
	<dd>&#13;
	<p>Did you do something special? Came up with some incredible new idea—and it works? You have to learn how to fork, train, and refine models to see your idea forward, which requires a heck of a lot of expertise.</p>&#13;
	</dd>&#13;
	<dt>There is no direct community governance and no best practices around review, curation, and distribution of forked models</dt>&#13;
	<dd>&#13;
	<p>Ever watch five-year-old kids play soccer? Enough said.</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<p>InstructLab solves these problems because it gives you the tools to create and merge contributions (skills and/or knowledge artifacts) to an LLM, without requiring a team with deep AI engineering skills at your disposal.</p>&#13;
</div></section>&#13;
&#13;
&#13;
<section data-pdf-bookmark="Dipping your toe into the InstructLab pool" data-type="sect3"><div class="sect3" id="ch08_dipping_your_toe_into_the_instructlab_pool_1740182052173385">&#13;
<h3>Dipping your toe into the InstructLab pool</h3>&#13;
&#13;
<p>InstructLab’s technology gives upstream models with sufficient infrastructure resources the ability to create regular builds of their customized models—not by rebuilding and retraining the entire model, but by infusing new skills and/or knowledge into it. It does this through a combination of three key processes that we cover in this section:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>A taxonomy-driven data curation methodology</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Synthetic data generation—at scale</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>An instruction-tuning method that has multiple phases and avoids catastrophic forgetting</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="ch08_the_lingo_1740182052173438">&#13;
<h1>The Lingo</h1>&#13;
&#13;
<p>In open source, <em>upstream </em>refers to the original primary source of a project<a contenteditable="false" data-primary="upstream, open source LLM" data-type="indexterm" id="id1072"/> (the original Llama in our example). It’s where the core work happens. Other versions<a contenteditable="false" data-primary="forks, open source LLM" data-type="indexterm" id="id1073"/> derived from it are known as <em>forks</em>. A model’s upstream is the main authoritative version of the model family. If forkers want to get their enhancements into the upstream version, they need to initiate<a contenteditable="false" data-primary="pull request, open source LLM" data-type="indexterm" id="id1074"/> a <em>pull </em>request (coder talk for sending changes to the upstream main project) that must be approved by the upstream model’s maintainers. This process, which is central to open source, ensures that the core model<a contenteditable="false" data-primary="downstream, open source LLM" data-type="indexterm" id="id1075"/> is current and benefits from the <em>downstream </em>(forks and derivatives of the main project) enhancements made by the broader community; what’s more, it gives that community a way to push back upstream benefits to improve the overall project. Basically, it’s letting an LLM like Llama get thousands of times better rather than having the thousands of different Llama models in that ever-expanding herd from our earlier analogy. A group of <em>committers </em>and <em>project maintainers </em>decide which forks<a contenteditable="false" data-primary="committers, forks in a model" data-type="indexterm" id="id1076"/><a contenteditable="false" data-primary="project maintainers, forks in model" data-type="indexterm" id="id1077"/> go back to the model. And when you’re deeply involved in a project and have contributed lots of fixes or improvements to it, you can work your way up to becoming one of those people who has the ultimate say in where a project (or model in this case) is heading.</p>&#13;
</div></aside>&#13;
&#13;
<p>The InstructLab project provides tools for developers to add and merge new skills and/or knowledge into any open LLM through a GitHub workflow—right from their laptop.</p>&#13;
&#13;
<p>Through the InstructLab project, shown in <a data-type="xref" href="#ch08_figure_3_1740182052159414">Figure 8-2</a>, teams can contribute LAB alignment “recipes” for new skills and/or knowledge (your enterprise data) through a pull request to an InstructLab project. All accepted skills and/or knowledge recipes are subsequently added on top of a given pretrained starter during the model alignment phase by the InstructLab project maintainers (be they with a public model or private within your company).</p>&#13;
&#13;
<figure><div class="figure" id="ch08_figure_3_1740182052159414"><img alt="A diagram of a diagram of a diagram  Description automatically generated" src="assets/aivc_0802.png"/>&#13;
<h6><span class="label">Figure 8-2. </span>InstructLab offers a new way to make community contributions additive</h6>&#13;
</div></figure>&#13;
&#13;
<p>Enabling contributions in the alignment phase of model development, rather than investing resources into the time-consuming process of pretraining new base models, allows for an agile iterative development process well suited for collaboration within your company (or in an open community, perhaps around an industry, where a consortium of businesses are working together to create a model bespoke to their industry). We’ve seen it firsthand. Pretraining an LLM can take months and thousands of superexpensive GPUs, evaporating water and what’s in your wallet. In contrast, using InstructLab, a given LLM can often be aligned using fine-tuning methods in less than a day’s time, allowing for a much more rapid update release cycle.</p>&#13;
</div></section>&#13;
&#13;
&#13;
<section data-pdf-bookmark="Can you smell what’s cooking? Skill and knowledge recipes" data-type="sect3"><div class="sect3" id="ch08_can_you_smell_what_s_cooking_skill_and_knowledge_1740182052173503">&#13;
<h3>Can you smell what’s cooking? Skill and knowledge recipes</h3>&#13;
&#13;
<p class="fix_tracking">At its core, a skill or knowledge recipe<a contenteditable="false" data-primary="skill and knowledge recipes" data-type="indexterm" id="xi_skillandknowledgerecipes815954"/><a contenteditable="false" data-primary="synthetic data" data-type="indexterm" id="xi_syntheticdata815954"/> is just a simple set of instructions on how to programmatically generate large amounts of labeled synthetic data (again, AI helping AI) that exemplifies a given skill set or area of knowledge. Each recipe is comprised of a short description of a skill or knowledge gap, and then five, or more, handcrafted examples. In the case of a knowledge recipe, the input would also include a knowledge source, such as a company’s benefits manual in an HR use case, that covers the desired topic.</p>&#13;
&#13;
<p>These recipes are provided in the form of a prompt to a larger teacher model (InstructLab debuted with Mixtral-Instruct as its teacher model), which is used to generate a large volume of corresponding synthetic data. Why synthetic data? It’s a critical component of InstructLab because many companies do not have enough targeted data to train (using InstructLab or more standard PEFT methods) something as big as an LLM on their ultra-specific tasks. Synthetic data is also how InstructLab turns large corpuses of unstructured enterprise data into a structured dataset that can be used to train your model. Once this data is generated, it can be used to fine-tune your LLM to teach it the missing skills or knowledge you want to push upstream into your company’s model.</p>&#13;
&#13;
<p>Using synthetic data to align a model isn’t a novel idea on its own. In fact, there are multiple examples of synthetic data being used to align models, including examples of model distillation<a contenteditable="false" data-primary="model distillation" data-type="indexterm" id="id1078"/><a contenteditable="false" data-primary="distillation, model" data-type="indexterm" id="id1079"/> (as we discussed in <a data-type="xref" href="ch07.html#ch07_where_this_technology_is_headed_one_model_will_not_1740182051667482">Chapter 7</a>). For example, Vicuna-13B was trained on synthetic data generated from GPT-4. But again, there’s a problem. OpenAI’s terms and conditions do not support the use of GPT-4 for the creation of commercially competitive models, which<em> makes the viability of these models questionable. </em>There are other models that we could point you to as well, but they all require closed models like GPT-4 as their teacher model to generate the required synthetic data. And right here is when you get to how open source drives technology forward. What makes the LAB method so appealing is that it proves that permissibly licensed open source models (of which Apache 2.0 is an example) can be used as teacher models and still drive state-of-the-art (SOTA) model performance.</p>&#13;
&#13;
<p>To date, all skill and/or knowledge recipes contributed to the InstructLab project are mapped out in a logical, hierarchical InstructLab taxonomy<a contenteditable="false" data-primary="taxonomy, classifying data into" data-type="indexterm" id="xi_taxonomyclassifyingdatainto8163159"/>. In simple terms, you can think of a taxonomy as a tree structure that organizes things into categories and subcategories (see <a data-type="xref" href="#ch08_figure_3_1740182052159414">Figure 8-2</a>). For InstructLab, a taxonomy classifies data samples into smaller groups (each branch is further divided into more specific levels) that ultimately support different tasks (leaves on a branch). This gives developers a visual framework not just to identify skills and knowledge that might help a project, but also a way to spot and fill gaps with new knowledge and skills they want to contribute.</p>&#13;
&#13;
<aside data-type="sidebar" epub:type="sidebar"><div class="sidebar" id="ch08_instructlab_learns_like_humans_learn_1740182052173565">&#13;
<h1>InstructLab Learns Like Humans Learn</h1>&#13;
&#13;
<p>It’s outside the scope of this book to get into the weeds on how knowledge and skills work in InstructLab, but it’s worth a moment here. Just like learning in our own lives, InstructLab’s approach is similar. For example, its taxonomy has knowledge, and (just like in your life) knowledge can be found in books, and that’s indeed one source of knowledge for InstructLab. In order to do some pretty complex tasks, we humans need to have a core set of foundational skills that we can add to our knowledge, and InstructLab is no different. For example, before you can ask an AI to use net present value (NPV) as input into whether something is a good investment or not, it needs core math skills like exponents, order of operations, and time value of money (TVM) concepts. Finally, just like humans, it combines knowledge and foundational skills to do complex tasks—these are called compositional skills in InstructLab. If your LLM is part of an agentic workflow that needs to write a recommendation report based on NPV, it would need all the stuff we just talked about; it needs to know math, how to write, nuances, and more.</p>&#13;
</div></aside>&#13;
&#13;
<p>InstructLab’s taxonomy also helps ensure that a diverse set of synthetic data is generated to cover all the different subtasks that might be desired when contributing a recipe for any one high-level task.</p>&#13;
&#13;
<p>Consider an LLM assisting an agent with the task of writing social media posts, like our agentic example in the last chapter. How you post on X (formerly known as Twitter) is different from LinkedIn or Instagram. Some platforms need short forms because of character limits; emojis are more prevalent in others; some platforms are very image-based, while others call for more business acumen. These are writing skills specific to social media. In the InstructLab taxonomy snippet shown in <a data-type="xref" href="#ch08_figure_4_1740182052159436">Figure 8-3</a>, if a contributor was trying to improve a model’s ability to write social media posts, they could contribute to the <em>social_media</em> branch (or create a new one if it didn’t exist) that falls under the <em>freeform </em>branch, which falls under the <em>writing </em>branch in the skills taxonomy. Their contributions would be synthetic data recipes for each targeted social media outlet. Want to make your AI become a poet? Give it different poetry examples and create skills that are specific to haiku, one for sonnet, another for limerick, and so on.</p>&#13;
&#13;
<figure><div class="figure" id="ch08_figure_4_1740182052159436"><img alt="A diagram of a person's face  AI-generated content may be incorrect." src="assets/aivc_0803.png"/>&#13;
<h6><span class="label">Figure 8-3. </span>An example of an InstructLab skills taxonomy for writing</h6>&#13;
</div></figure>&#13;
&#13;
<p>LAB’s unique training regimen assimilates this new data during the alignment phase instead of the expensive pretraining phase where most LLMs are infused with their core knowledge and capabilities. And again, this training protocol also mitigates catastrophic forgetting. Quite simply, the way InstructLab works ensures that newly added knowledge won’t overwrite what the model learned before.</p>&#13;
&#13;
<p>When all synthetic data recipes have been submitted and added to a project’s taxonomy, InstructLab’s training and generation pipeline runs all the recipes to generate synthetic data. It then filters that generated data down to include only high-quality samples, and, using a novel phased fine-tuning approach, aligns each of the starter models (the student models) using the generated synthetic data, thereby infusing the model with all of the contributed skills and knowledge<a contenteditable="false" data-primary="" data-startref="xi_taxonomyclassifyingdatainto8163159" data-type="indexterm" id="id1080"/>. Since a picture is worth a thousand words, as they say, we’ve summarized this entire workflow in <a data-type="xref" href="#ch08_figure_5_1740182052159457">Figure 8-4</a>.</p>&#13;
&#13;
<figure><div class="figure" id="ch08_figure_5_1740182052159457"><img alt="A diagram of a diagram of a cube  Description automatically generated with medium confidence" src="assets/aivc_0804.png"/>&#13;
<h6><span class="label">Figure 8-4. </span>How Large-scale Alignment for chatBots (LAB) works</h6>&#13;
</div></figure>&#13;
</div></section> &#13;
&#13;
<section data-pdf-bookmark="Harnessing the power of the community" data-type="sect3"><div class="sect3" id="ch08_harnessing_the_power_of_the_community_1740182052173621">&#13;
<h3>Harnessing the power of the community</h3>&#13;
&#13;
<p>To drive rapid innovation, the open source<a contenteditable="false" data-primary="open source AI" data-secondary="InstructLab as contributor" data-type="indexterm" id="xi_opensourceAIInstructLabascontributor818158"/> version of InstructLab has committed to a periodic training and release cycle for community-trained models. The latest versions of the InstructLab models are made publicly available on Hugging Face, which, as you know from the first part of this book, is the heartbeat of the world’s largest organized AI community. Hugging Face’s reach gives the community the ability to download an InstructLab-tuned model, experiment with it, and find gaps in its performance. Once identified, community members can build and contribute their own skill and knowledge recipes back to the InstructLab project through a pull request. As you’d expect with traditional open source projects, InstructLab committers and project maintainers review contributions and merge all accepted contributions back to the main model once a week. Of course, for your own private models, you can do all of this within your company and operate in the same manner.</p>&#13;
&#13;
<p>To support developers who are using and contributing to InstructLab models, the InstructLab project includes a command-line interface tool<a contenteditable="false" data-primary="Language Model Development Kit (LMDK)" data-type="indexterm" id="id1081"/><a contenteditable="false" data-primary="LMDK (Language Model Development Kit)" data-type="indexterm" id="id1082"/> called the <em>Language Model Development Kit</em> (LMDK). LMDK implements the InstructLab workflow on a contributor’s laptop.<strong> </strong>Think of it as a test kitchen for trying out and submitting new recipes for generating synthetic data to teach an LLM new skills. Now a developer is up and running in an instant, and perhaps they start experimenting with a local <span class="keep-together">version</span> of their open sourced LLM (like Granite). They may find some gaps or areas in the model’s performance they want to improve, cook up some knowledge or skill recipes to fill them in, and voilà! This entire process (as shown in <a data-type="xref" href="#ch08_figure_6_1740182052159477">Figure 8-5</a>) acts like a flywheel for rapid open source AI innovation.</p>&#13;
&#13;
<figure><div class="figure" id="ch08_figure_6_1740182052159477"><img alt="A diagram of a process  AI-generated content may be incorrect." src="assets/aivc_0805.png"/>&#13;
<h6><span class="label">Figure 8-5. </span>The InstructLab innovation cycle: a flywheel for rapid open source <span class="keep-together">innovation</span></h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="A day in the life of an InstructLab contributor" data-type="sect3"><div class="sect3" id="ch08_a_day_in_the_life_of_an_instructlab_contributor_1740182052173704">&#13;
<h3>A day in the life of an InstructLab contributor</h3>&#13;
&#13;
<p>As we said earlier, it’s outside the scope of this book to take you through the whole InstructLab process, but there are a lot of <a href="https://oreil.ly/1MOTp">tutorials</a> you can easily find with step-by-step instructions that will turn you into a hero contributor in no time.</p>&#13;
&#13;
<p><a data-type="xref" href="#ch08_figure_5_1740182052159457">Figure 8-4</a> gave you an idea of the aspects of being an InstructLab contributor, and as you’ve figured out by now, it all starts with a skills recipe. The following code shows you what a rhyming skill recipe actually looks like (it’s written in YAML):</p>&#13;
&#13;
<pre data-type="programlisting">&#13;
version: 2&#13;
task_description: 'Teach the model how to rhyme.'&#13;
created_by: rob-paul-kate&#13;
seed_examples:&#13;
  - question: "What are 5 words that rhyme with boring?"&#13;
    answer: "snoring, pouring, storing, scoring, and exploring."&#13;
  - question: "What are 5 words that rhyme with dog?"&#13;
    answer: "log, cog, frog, bog, and smog."&#13;
  - question: "What are 5 words that rhyme with happy?"&#13;
    answer: "snappy, crappy, scrappy, unhappy, and sappy."&#13;
  - question: "What are 5 words that rhyme with bank?"&#13;
    answer: "shank, crank, prank, sank, and drank."&#13;
  - question: "What are 5 words that rhyme with fake?"&#13;
    answer: "bake, lake, break, make, and earthquake."</pre>&#13;
&#13;
<p class="pagebreak-before">Next, using the local version of InstructLab’s synthetic data generator, you’d create your own synthetic alignment data for the skill or knowledge you are building. This data can then be used to align your own local version of your model and quickly test it to see if your contribution is closing a gap. You can keep experimenting with this process until your model can perform the task you’re after. Once your recipe is <span class="keep-together">perfected</span> in LMDK, you submit it as a pull request to the InstructLab taxonomy on GitHub, as you would any other open source or internal software project. Next, a group of committers accept or deny submissions, updating the final taxonomy with the new YAML files. (Again, this scenario could be publicly external or fully internal to your company.)</p>&#13;
&#13;
<p>The final step of InstructLab is the build process, which can be run on a regular basis, periodically updating your LLM with (for example) the latest and greatest contributions from your developer community<a contenteditable="false" data-primary="" data-startref="xi_opensourceAIInstructLabascontributor818158" data-type="indexterm" id="id1083"/>. In this build process, all of the synthetic data generated to date gets aggregated and is used in a multistage training process designed to maximize performance and reduce issues like catastrophic forgetting. When the new build of your model is available, you now have an LLM, customized on all of the enterprise data submitted by your developers and domain SMEs<a contenteditable="false" data-primary="" data-startref="xi_largelanguagemodelsLLMsrepresentingdatawithin893185" data-type="indexterm" id="id1084"/><a contenteditable="false" data-primary="" data-startref="xi_finetuningLLMwithenterprisedata8101100" data-type="indexterm" id="id1085"/><a contenteditable="false" data-primary="" data-startref="xi_InstructLab810629" data-type="indexterm" id="id1086"/><a contenteditable="false" data-primary="" data-startref="xi_skillandknowledgerecipes815954" data-type="indexterm" id="id1087"/><a contenteditable="false" data-primary="cloud native platform, deployment of model on" data-type="indexterm" id="id1088"/><a contenteditable="false" data-primary="" data-startref="xi_modelsfinetuningwithenterprisedata8101100" data-type="indexterm" id="id1089"/><a contenteditable="false" data-primary="" data-startref="xi_syntheticdata815954" data-type="indexterm" id="id1090"/><a contenteditable="false" data-primary="models" data-secondary="deployment on cloud native platform" data-type="indexterm" id="id1091"/><a contenteditable="false" data-primary="" data-startref="xi_teachermodel810629" data-type="indexterm" id="id1092"/>.</p>&#13;
&#13;
<p>While we are still in the early days of InstructLab, we are seeing that this end-to-end process of specializing small models on enterprise data can drive both performance (higher is better) improvements <em>and</em> significant cost reductions, when compared to using a large general-purpose model alone, as shown in <a data-type="xref" href="#ch08_figure_7_1740182052159496">Figure 8-6</a>.</p>&#13;
&#13;
&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
&#13;
<p>In scenarios that involve highly sensitive organizational <span class="keep-together">information—such</span> as employee health or disciplinary records—embedding that sensitive data directly into an LLM likely isn’t something you want to do. Instead, you can use your data to customize your LLM via InstructLab and align it closely with your company’s branding, style, cultural values, etc., and separately store that sensitive information securely within a RAG system with controlled access. This approach allows your tailored LLM to seamlessly and securely access sensitive data only when needed, ensuring both enhanced communication and strict data confidentiality. Likewise, if you had data in a domain that was constantly changing or where the use case required the most up-to-date data, RAG likely makes more sense for that data too.</p>&#13;
</div>&#13;
&#13;
<figure><div class="figure" id="ch08_figure_7_1740182052159496"><img alt="A graph of sales and sales  Description automatically generated with medium confidence" src="assets/aivc_0806.png"/>&#13;
<h6><span class="label">Figure 8-6. </span>Demonstrating the impact of InstructLab</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Step 3: The Grand Finale: Deployment and Experimentation" data-type="sect2"><div class="sect2" id="ch08_step_3_the_grand_finale_deployment_on_a_cloud_na_1740182052173766">&#13;
<h2>Step 3: The Grand Finale: Deployment and Experimentation</h2>&#13;
&#13;
<p>There’s no sense in having a trusted LLM enriched with your data if no one in your company can use it. This makes the final step all about deploying your new-age data representation value creation asset. So, what’s needed to make this real? A lot of experimentation. If you think back to every previous transformative technology (like the internet), history has shown there is also a transition point from experimenting to deploying at scale.</p>&#13;
&#13;
<p>There is incredible excitement, anticipation, and expectation surrounding GenAI and agents in our world today. We see applications and APIs that can impact hundreds of millions of consumers. Indeed, the type of excitement being generated could be compared to the advent of the internet browser (that Netscape moment we talked about in <a data-type="xref" href="ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974">Chapter 1</a>). But, if you think about this internet comparison, enterprise value wasn’t unlocked the instant Netscape came out. It wasn’t until the internet glued together everything: from inventories to supply chains all the way to the frontend and omnichannel. We think AI will undergo that same evolution: +AI to AI+.</p>&#13;
&#13;
<p>To unlock AI’s value in the enterprise, you need to be able to target the same deployment at scale across an enterprise. But to get there, you will need a governed environment that allows for experimentation, customizing your models through key workflows like RAG, fine-tuning, and InstructLab, and then transitioning those models to deployment at scale.</p>&#13;
&#13;
<p>Importantly, as your customized models are now representations of valuable enterprise intellectual property (IP), there are key business decisions that will need to be made at the time of deployment. Decisions like: can you trust your model to live in the cloud, or is the data that is represented by your model sensitive enough that it can only be deployed on premises? Do you need those proactive and reactive guardrails we talked about in <a data-type="xref" href="ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635">Chapter 5</a> to make sure your applications using these models are not abused? Do you need to actively monitor the performance and safety of your deployments? And as GenAI permeates throughout your enterprise, you’re expanding the surface attack area for digital exploitation, so (again, from <a data-type="xref" href="ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635">Chapter 5</a>) you’re going to have to think about adversarial attacks and other new ways bad actors might try to exploit your digital masterpiece<a contenteditable="false" data-primary="" data-startref="xi_datarepresentations89906" data-type="indexterm" id="id1093"/><a contenteditable="false" data-primary="" data-startref="xi_datarepresentationsstepstodeploymentof84237" data-type="indexterm" id="id1094"/>.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="The Future Is Open, Collaborative, and Customizable" data-type="sect1"><div class="sect1" id="ch08_the_future_is_open_1740182052173822">&#13;
<h1>The Future Is Open, Collaborative, and Customizable</h1>&#13;
&#13;
<p>Much of the internet is built on open source software. Every day, whether you realize it or not, you’re interacting with a Linux operating system, and an Apache web server is helping you accomplish your goals. Today, open source software also powers smartphones running on Android operating systems and the Secure Sockets Layer (SSL) cryptographic protocol that secures millions of financial transactions every day. We’re telling you that open, community-built, and enterprise-customized LLMs can bring some of the same benefits. Putting LLM weights out for the world to see gives everyone the chance to innovate, test, refine, and shape the future of this powerful technology. Allowing builders to understand the data provenance fosters trust and provides explainability.</p>&#13;
&#13;
<p>Transparent open source software makes systems more stable and secure. That can lead to faster, more predictable release cycles, and safer AI-related software. Improving LLM trust and transparency is one of the top goals of the InstructLab project.</p>&#13;
&#13;
<p>Open source software also encourages the kind of healthy competition that prevents one or two companies from monopolizing the industry. When everyone is allowed to participate, innovation thrives and costs to consumers typically drop.</p>&#13;
&#13;
<p>You’ve now unlocked the secret to turning your data into your competitive superpower. But before you dash off to dominate your industry (or at least impress your colleagues), let’s wrap up by gazing into our non-AI powered crystal ball (it’s just our thoughts, we don’t really have one) and take an educated guess at what wild adventures await the ever-evolving landscape of Gen AI and agents.</p>&#13;
</div></section>&#13;
<div data-type="footnotes"><p data-type="footnote" id="id1056"><sup><a href="ch08.html#id1056-marker">1</a></sup> Granite Team, IBM, “Granite 3.0 Language Models,” 2023, <a href="https://ibm.biz/granite-report"><em>https://ibm.biz/granite-report</em>.</a></p><p data-type="footnote" id="id1070"><sup><a href="ch08.html#id1070-marker">2</a></sup> Shivchander Sudalairaj et al., “LAB: Large-Scale Alignment for ChatBots,” preprint, arXiv, April 29, 2024, <a href="https://arxiv.org/abs/2403.01081"><em>https://arxiv.org/abs/2403.01081</em></a>. </p></div></div></section></body></html>