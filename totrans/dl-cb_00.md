# 前言

# 深度学习简史

当前深度学习热潮的根源出奇地早，可以追溯到上世纪 50 年代。虽然“智能机器”的模糊想法可以在小说和推测中找到更早的踪迹，但上世纪 50 年代和 60 年代见证了第一批基于生物神经元极为简化模型的“人工神经网络”的引入。在这些模型中，由弗兰克·罗森布拉特提出的感知器系统引起了特别的兴趣（和炒作）。连接到一个简单的“摄像头”电路，它可以学会区分不同类型的物体。尽管第一个版本是在 IBM 计算机上作为软件运行的，但随后的版本都是在纯硬件上完成的。

对多层感知器（MLP）模型的兴趣在 60 年代持续。这种情况在 1969 年马文·明斯基和西摩·帕普特出版了他们的书《感知器》（麻省理工学院出版社）后发生了变化。这本书中包含了一个证明，证明了线性感知器无法对非线性函数（XOR）的行为进行分类。尽管证明存在局限性（在书出版时存在非线性感知器模型，作者甚至有所提及），但其出版标志着对神经网络模型的资金投入急剧下降。直到 1980 年代，研究才得以恢复，新一代研究人员崛起。

随着计算能力的增加以及反向传播技术的发展（自上世纪 60 年代以来以各种形式存在，但直到 80 年代才得到普遍应用），引发了对神经网络的兴趣再次高涨。计算机不仅有能力训练更大的网络，而且我们还有技术可以高效地训练更深层次的网络。第一个卷积神经网络将这些见解与哺乳动物大脑的视觉识别模型相结合，首次实现了能够高效识别复杂图像（如手写数字和人脸）的网络。卷积网络通过将相同的“子网络”应用于图像的不同位置，并将这些结果聚合到更高级的特征中来实现这一点。在第十二章中，我们将更详细地探讨这一点。

在 90 年代和 21 世纪初，对神经网络的兴趣再次下降，因为更“可理解”的模型如支持向量机（SVM）和决策树变得流行。SVM 在当时许多数据源中被证明是优秀的分类器，特别是当与人工设计的特征结合时。在计算机视觉中，“特征工程”变得流行。这涉及构建图片中小元素的特征检测器，并手动将它们组合成识别更复杂形式的东西。后来发现，深度学习网络学会识别非常相似的特征，并学会以非常相似的方式将它们组合起来。在第十二章中，我们探索了这些网络的一些内部工作，并可视化它们学到的内容。

随着 2000 年代末期通用图形处理单元（GPU）上的通用编程的出现，神经网络架构能够在竞争中取得巨大进步。GPU 包含数千个小处理器，可以并行进行数万亿次操作。最初是为计算机游戏开发的，用于实时渲染复杂的 3D 场景，结果表明相同的硬件可以并行训练神经网络，实现速度提高 10 倍或更高的因素。

另一件事是互联网提供了非常大的训练集。在此之前，研究人员通常使用数千张图像来训练分类器，现在他们可以访问数千万甚至数亿张图像。结合更大的网络，神经网络有了展示自己的机会。这种主导地位在接下来的几年中持续存在，通过改进的技术和将神经网络应用于图像识别之外的领域，包括翻译、语音识别和图像合成。

# 为什么现在？

尽管计算能力的激增和更好的技术导致了对神经网络的兴趣增加，但我们也看到了在*可用性*方面取得了巨大进步。特别是，像 TensorFlow、Theano 和 Torch 这样的深度学习框架允许非专家构建复杂的神经网络来解决他们自己的机器学习问题。这使得以前需要数月甚至数年的手工编码和头撞桌子的努力（编写高效的 GPU 内核很难！）的任务变成了任何人都可以在一个下午（或者实际上几天）完成的事情。增加的可用性极大地增加了可以处理深度学习问题的研究人员数量。像 Keras 这样的框架具有更高级别的抽象，使得任何具有 Python 工作知识和一些工具的人都可以运行一些有趣的实验，正如本书所示。

“为什么现在”第二个重要因素是大型数据集已经对每个人都可用。是的，Facebook 和 Google 可能仍然拥有访问数十亿张图片、用户评论等的优势，但数百万项数据集可以从各种来源获得。在第一章中，我们将看看各种选择，在整本书中，每个章节的示例代码通常会在第一个配方中显示如何获取所需的训练数据。

与此同时，私营公司已经开始生产和收集数量级更多的数据，这使得整个深度学习领域突然变得商业上非常有趣。一个可以区分猫和狗的模型是很好的，但一个可以通过考虑所有历史销售数据使销售额增加 15%的模型对于一家公司来说可能是生死攸关的区别。

# 你需要了解什么？

如今，深度学习有各种平台、技术和编程语言可供选择。在本书中，所有示例都是用 Python 编写的，大部分代码依赖于出色的 Keras 框架。示例代码作为一套 Python 笔记本在 GitHub 上可用，每章一个。因此，具有以下工作知识将有所帮助：

Python

首选 Python 3，但 Python 2.7 也可以工作。我们使用各种辅助库，所有这些库都可以使用 pip 轻松安装。代码通常很简单，因此即使是相对新手也应该能够跟上操作。

Keras

机器学习的大部分繁重工作几乎完全由 Keras 完成。Keras 是 TensorFlow 或 Theano 的抽象，两者都是深度学习框架。Keras 使得以一种非常可读的方式定义神经网络变得容易。所有代码都经过了 TensorFlow 的测试，但也应该可以与 Theano 一起工作。

NumPy、SciPy、scikit-learn

这些有用且广泛的库在许多配方中随意使用。大多数情况下，从上下文中应该清楚发生了什么，但对它们进行快速了解也不会有害。

Jupyter Notebook

笔记本是分享代码的一种非常好的方式；它们允许在浏览器中查看代码、代码输出和注释的混合。

每个章节都有一个包含工作代码的对应笔记本。书中的代码经常省略了导入等细节，因此最好从 Git 获取代码并启动本地笔记本。首先检出代码并进入新目录：

```py
git clone https://github.com/DOsinga/deep_learning_cookbook.git
cd deep_learning_cookbook
```

然后为项目设置一个虚拟环境：

```py
python3 -m venv venv3
source venv3/bin/activate
```

并安装依赖项：

```py
pip install -r requirements.txt
```

如果您有 GPU 并希望使用它，您需要卸载`tensorflow`并安装`tensorflow-gpu`，您可以使用 pip 轻松完成：

```py
pip uninstall tensorflow
pip install tensorflow-gpu
```

你还需要设置一个兼容的 GPU 库，这可能有点麻烦。

最后，启动 IPython 笔记本服务器：

```py
jupyter notebook
```

如果一切正常，这应该会自动打开一个包含每章笔记本概述的网页浏览器。随意尝试代码；您可以使用 Git 轻松撤消您所做的任何更改，如果您想返回到基线：

```py
git checkout <*notebook_to_reset*>.ipynb
```

每章的第一部分列出了该章相关的笔记本，笔记本按章节编号，因此通常很容易找到您要找的内容。在笔记本文件夹中，您还会找到另外三个目录：

数据

包含各种笔记本所需的数据，主要是开放数据集的样本或您自己生成会太繁琐的内容。

生成的

用于存储中间数据。

动物园

每章包含一个子目录，其中保存了该章节的已保存模型。如果您没有时间实际训练模型，仍然可以通过从这里加载模型来运行模型。

# 本书结构

第一章提供了有关神经网络如何运作、从哪里获取数据以及如何预处理数据以便更容易消化的深入信息。第二章是关于遇到困难以及如何应对的内容。神经网络极其难以调试，本章中关于如何使其行为良好的技巧和窍门在阅读本书其余以项目为导向的配方时将会派上用场。如果您心急，可以跳过本章，等到遇到困难时再回来阅读。

第三章到第十五章围绕媒体进行分组，从文本处理开始，然后是图像处理，最后是第十五章中的音乐处理。每一章描述一个项目，分为各种配方。通常，一章将以数据获取配方开始，然后是几个配方，以实现章节目标，并包含一个数据可视化配方。

第十六章是关于在生产中使用模型。在笔记本中运行实验很好，但最终我们希望与实际用户分享我们的结果，并在真实服务器或移动设备上运行我们的模型。本章介绍了各种选择。

# 本书中使用的约定

本书中使用以下排版约定：

*斜体*

指示新术语、URL、电子邮件地址、文件名和文件扩展名。

`等宽字体`

用于程序清单，以及在段落中引用程序元素，如变量或函数名称、数据库、数据类型、环境变量、语句和关键字。

*`等宽斜体`*

显示应替换为用户提供的值或由上下文确定的值的文本。

###### 提示

此元素表示提示或建议。

###### 注意

此元素表示一般说明。

# 附带代码

本书的每一章都附带一个或多个 Python 笔记本，其中包含章节中提到的示例代码。您可以阅读章节而不运行代码，但在阅读时使用笔记本会更有趣。代码可以在[*https://github.com/DOsinga/deep_learning_cookbook*](https://github.com/DOsinga/deep_learning_cookbook)找到。

要使配方中的示例代码运行起来，请在 shell 中执行以下命令：

```py
git clone https://github.com/DOsinga/deep_learning_cookbook.git
cd deep_learning_cookbook
python3 -m venv venv3
source venv3/bin/activate
pip install -r requirements.txt
jupyter notebook
```

本书旨在帮助您完成工作。所有附带笔记本中的代码都在宽松的 Apache 许可证 2.0 下许可。

我们感激，但不要求归属。归属通常包括标题、作者、出版商和 ISBN。例如：“*Deep Learning Cookbook* by Douwe Osinga (O’Reilly)。版权所有 2018 年 Douwe Osinga，978-1-491-99584-6。”

# O’Reilly Safari

###### 注

[*Safari*](http://oreilly.com/safari)（前身为 Safari Books Online）是一个面向企业、政府、教育工作者和个人的基于会员制的培训和参考平台。

会员可以访问来自 250 多家出版商的数千本书籍、培训视频、学习路径、交互式教程和策划播放列表，包括 O’Reilly Media、哈佛商业评论、Prentice Hall 专业、Addison-Wesley 专业、微软出版社、Sams、Que、Peachpit 出版社、Adobe、Focal Press、思科出版社、约翰威利和儿子、Syngress、摩根考夫曼、IBM 红皮书、Packt、Adobe 出版社、FT 出版社、Apress、Manning、新骑手、麦格劳希尔、琼斯和巴特利特以及课程技术等。

有关更多信息，请访问[*http://oreilly.com/safari*](http://oreilly.com/safari)。

# 如何联系我们

请将有关本书的评论和问题发送给出版商：

+   O’Reilly Media, Inc.

+   1005 Gravenstein Highway North

+   加利福尼亚州塞巴斯托波尔 95472

+   800-998-9938（美国或加拿大）

+   707-829-0515（国际或本地）

+   707-829-0104（传真）

我们为这本书创建了一个网页，列出了勘误、示例和任何额外信息。您可以在[*http://bit.ly/deep-learning-cookbook*](http://bit.ly/deep-learning-cookbook)上访问此页面。

要就本书发表评论或提出技术问题，请发送电子邮件至*bookquestions@oreilly.com*。

有关我们的书籍、课程、会议和新闻的更多信息，请访问我们的网站[*http://www.oreilly.com*](http://www.oreilly.com)。

在 Facebook 上找到我们：[*http://facebook.com/oreilly*](http://facebook.com/oreilly)

在 Twitter 上关注我们：[*http://twitter.com/oreillymedia*](http://twitter.com/oreillymedia)

在 YouTube 上观看我们：[*http://www.youtube.com/oreillymedia*](http://www.youtube.com/oreillymedia)

# 致谢

从学者在[*https://arxiv.org*](https://arxiv.org)上（预）发布论文分享新想法，到黑客在 GitHub 上编写这些想法的代码，再到公共和私人机构发布数据集供任何人使用，机器学习领域充满了欢迎新人的人和组织，使入门变得如此容易。开放数据、开源和开放获取出版——如果没有机器学习分享文化，这本书就不会存在。

这本书中所呈现的想法是真实的，这本书中的代码更是如此。从头开始编写一个机器学习模型很难，因此笔记本中的几乎所有模型都基于其他地方的代码。这是完成任务的最佳方式——找到一个与您想要的类似的模型，并逐步更改它，确保每一步都仍然有效。

特别感谢我的朋友和这本书的合著者 Russell Power。除了帮助撰写这篇序言，第六章和第七章，他在检查书籍和相关代码的技术可靠性方面发挥了重要作用。此外，他作为许多想法的 sounding board，对于一些想法，其中一些已经被纳入了书中，他是一个宝贵的资产。

然后是我的可爱妻子，她是第一道防线，当章节逐渐形成时，她负责校对。她有一种神奇的能力，能够发现文本中的错误，即使这些错误不是她的母语，也不是她之前是专家的主题。

*requirements.in*文件列出了本书中使用的开源软件包。衷心感谢所有这些项目的所有贡献者。对于 Keras，感谢更加深刻，因为几乎所有的代码都是基于该框架的，并且经常借鉴其示例。

这本书的例子代码和想法来自这些软件包和许多博客文章。特别是：

[第二章，*摆脱困境*]

这一章节借鉴了 Slav Ivanov 的博客文章[“37 Reasons Why Your Neural Network Is Not Working”]。

[第三章，*使用词嵌入计算文本相似性*]

感谢 Google 发布其 Word2vec 模型。

Radim Řehůřek 的 Gensim 支持本章，部分代码基于这个伟大项目的示例。

[第五章，*生成文本的风格*]

这一章节在很大程度上借鉴了 Andrej Karpathy 的博客文章[“递归神经网络的不合理有效性”]。那篇博客文章重新激发了我对神经网络的兴趣。

可视化灵感来自 Motoki Wu 的[“递归神经网络的可视化”]。

[第六章，*问题匹配*]

这一章节在一定程度上受到了 Kaggle 上 Quora Question Pairs 挑战的启发。

[第八章，*序列到序列映射*]

示例代码是从 Keras 的一个示例中复制的，但应用在一个稍微不同的数据集上。

[第十一章，*检测多个图像*]

这一章基于 Yann Henon 的[*keras_frcnn*]。

[第十二章，*图像风格*]

这借鉴了[“How Convolutional Neural Networks See the World”]和当然也包括 Google 的[DeepDream]。

[第十三章，*使用自动编码器生成图像*]

代码和想法基于 Nicholas Normandin 的[条件变分自动编码器]。

[第十四章，*使用深度网络生成图标*]

Keras 的自动编码器训练代码基于 Qin Yongliang 的[DCGAN-Keras]。

[第十五章，*音乐和深度学习*]

这受到了 Heitor Guimarães 的[*gtzan.keras*]的启发。
