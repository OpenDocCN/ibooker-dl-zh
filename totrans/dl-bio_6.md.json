["```py\nimport jax\nfrom dlfb.localization.dataset.utils import get_dataset\nfrom dlfb.utils.context import assets\n\nrng = jax.random.PRNGKey(42)\nrng, rng_frames = jax.random.split(rng, 2)\n\ndataset = get_dataset(data_path=assets(\"localization/datasets\"))\nn_frames = 16\ndataset.plot_random_frames(n=n_frames, rng=rng_frames);\n\n```", "```py\nselected_protein = \"ACTB\"\ndataset.plot_random_frames(\n  n=n_frames, with_labels=False, rng=rng_frames, gene_symbols=[selected_protein]\n);\n\n```", "```py\ndataset.plot_random_frames(n=1, with_labels=False, rng=rng_frames);\n\n```", "```py\nclass DatasetBuilder:\n  \"\"\"Builds a dataset with splits for learning.\"\"\"\n\n  def __init__(self, data_path: str, force_recreate: bool = False):\n    self.images = ImageLoader(data_path).load(force_recreate=force_recreate)\n    self.labels = LabelLoader(data_path).load(force_recreate=force_recreate)\n\n  def build(\n    self,\n    rng: jax.Array,\n    splits: dict[str, float],\n    exclusive_by: str = \"fov_id\",\n    n_proteins: int | None = None,\n    max_frames: int | None = None,\n  ) -> dict[str, Dataset]:\n    \"\"\"Retrieve a dataset of proteins split into learning sets.\"\"\"\n    validate_splits(splits)\n\n    if not n_proteins:\n      n_proteins = self.labels.get_n_proteins()\n\n    # Sample frames from chosen proteins.\n    rng, rng_proteins = jax.random.split(rng, num=2)\n    frames = self.labels.get_frames_of_random_proteins(rng_proteins, n_proteins)\n\n    n_frames = frames.shape[0]\n    if max_frames is not None and n_frames > max_frames:\n      # Limit number of frames used.\n      frames = frames.head(max_frames)\n      n_frames = max_frames\n\n    # Get random entities to exclusively be assigned across splits\n    rng, rng_perm = jax.random.split(rng, 2)\n    set_ids = jnp.array(frames[exclusive_by].to_numpy(np.int32))\n    shuffled_set_ids = jax.random.permutation(rng_perm, jnp.unique(set_ids))\n\n    # Assign consecutive ids to proteins across all frames\n    frame_ids = jnp.array(frames[\"frame_id\"].to_numpy(np.int32))\n    lookup_with_protein_encoding = self._encode_proteins_across_frames(\n      self.labels.lookup.iloc[frame_ids.tolist()]\n    )\n\n    # Assemble the dataset by splits considering exclusive sets\n    dataset_splits, start = {}, 0\n    for name, size in self._get_split_sizes(\n      splits, n_sets=len(shuffled_set_ids)\n    ):\n      mask = jnp.isin(set_ids, shuffled_set_ids[start : (start + size)])\n      dataset_splits[name] = Dataset(\n        images=self.images,\n        labels=Labels(\n          lookup=lookup_with_protein_encoding.loc[\n            frame_ids[mask].tolist()\n          ].reset_index(drop=True)\n        ),\n      )\n      start += size\n\n    return dataset_splits\n\n  def _get_split_sizes(self, splits, n_sets):\n    \"\"\"Convert split fractional sizes to absolute counts.\"\"\"\n    names = list(splits.keys())\n    sizes = [int(n_sets * splits[name]) for name in names[:-1]]\n    sizes.append(n_sets - sum(sizes))  # Ensure total adds up\n    for name, size in zip(names, sizes):\n      yield name, size\n\n  def _encode_proteins_across_frames(self, lookup) -> pd.DataFrame:\n    \"\"\"Encode protein labels across dataset to consecutive integers.\"\"\"\n    protein_ids_in_frames = lookup[\"protein_id\"].to_list()\n    unique_protein_ids = sorted(set(protein_ids_in_frames))\n    mapping = pd.DataFrame(\n      [\n        {\"protein_id\": id_, \"code\": idx}\n        for idx, id_ in enumerate(unique_protein_ids)\n      ]\n    )\n    return lookup.merge(mapping, how=\"left\", on=\"protein_id\").set_index(\n      \"frame_id\", drop=False\n    )\n\n```", "```py\nfrom dlfb.localization.dataset import Dataset\nfrom dlfb.localization.dataset.builder import DatasetBuilder\nfrom dlfb.utils.context import assets\n\nbuilder = DatasetBuilder(data_path=assets(\"localization/datasets\"))\n\nrng, rng_dataset = jax.random.split(rng, 2)\ndataset: dict[str, Dataset] = builder.build(\n  rng=jax.random.PRNGKey(42),\n  splits={\"train\": 0.80, \"valid\": 0.10, \"test\": 0.10},\n  exclusive_by=\"fov_id\",\n  n_proteins=50,\n)\n\n```", "```py\nclass LocalizationModel(nn.Module):\n  \"\"\"VQ-VAE model with a fully connected output head.\"\"\"\n\n  embedding_dim: int\n  num_embeddings: int\n  commitment_cost: float\n  num_classes: int | None\n  dropout_rate: float\n  classification_head_layers: int\n\n  def setup(self):\n    \"\"\"Builds the encoder, decoder, quantizer, and output head.\"\"\"\n    self.encoder = Encoder(latent_dim=self.embedding_dim)\n    self.vector_quantizer = VectorQuantizer(\n      num_embeddings=self.num_embeddings,\n      embedding_dim=self.embedding_dim,\n      commitment_cost=self.commitment_cost,\n    )\n    self.decoder = Decoder(latent_dim=self.embedding_dim)\n    self.classification_head = ClassificationHead(\n      num_classes=self.num_classes,\n      dropout_rate=self.dropout_rate,\n      layers=self.classification_head_layers,\n    )\n\n  def __call__(self, x: jax.Array, is_training: bool):\n    \"\"\"Runs a forward pass.\"\"\"\n    ze = self.encoder(x)\n    zq, perplexity, codebook_loss, commitment_loss = self.vector_quantizer(ze)\n    decoded = self.decoder(zq)\n    logits = self.classification_head(\n      zq.reshape((zq.shape[0], -1)), is_training\n    )\n    return decoded, perplexity, codebook_loss, commitment_loss, logits\n\n  def create_train_state(\n    self, rng: jax.Array, dummy_input: jax.Array, tx\n  ) -> TrainState:\n    \"\"\"Initializes training state.\"\"\"\n    rng, rng_init, rng_dropout = jax.random.split(rng, 3)\n    variables = self.init(rng_init, dummy_input, is_training=False)\n    return TrainState.create(\n      apply_fn=self.apply, params=variables[\"params\"], tx=tx, key=rng_dropout\n    )\n\n  def get_encoding_indices(self, x: jax.Array) -> jax.Array:\n    \"\"\"Returns nearest codebook indices for input.\"\"\"\n    ze = self.encoder(x)\n    encoding_indices = self.vector_quantizer.get_closest_codebook_indices(ze)\n    return encoding_indices\n\n```", "```py\nclass Encoder(nn.Module):\n  \"\"\"Convolutional encoder producing latent feature maps.\"\"\"\n\n  latent_dim: int\n\n  def setup(self):\n    \"\"\"Initializes convolutional and residual layers.\"\"\"\n    self.conv1 = nn.Conv(\n      self.latent_dim // 2, kernel_size=(4, 4), strides=(2, 2), padding=1\n    )\n    self.conv2 = nn.Conv(\n      self.latent_dim, kernel_size=(4, 4), strides=(2, 2), padding=1\n    )\n    self.conv3 = nn.Conv(\n      self.latent_dim, kernel_size=(3, 3), strides=(1, 1), padding=1\n    )\n    self.res_block1 = ResnetBlock(self.latent_dim)\n    self.res_block2 = ResnetBlock(self.latent_dim)\n\n  def __call__(self, x):\n    \"\"\"Forward pass applying convolution and residual blocks to input.\"\"\"\n    x = self.conv1(x)\n    x = nn.relu(x)\n    x = self.conv2(x)\n    x = nn.relu(x)\n    x = self.conv3(x)\n    x = self.res_block1(x)\n    x = self.res_block2(x)\n    return x\n\nclass ResnetBlock(nn.Module):\n  \"\"\"Residual convolutional block with GroupNorm and Swish activation.\"\"\"\n\n  latent_dim: int\n\n  def setup(self):\n    \"\"\"Initializes normalization and convolutional layers.\"\"\"\n    self.norm1 = nn.GroupNorm()\n    self.conv1 = nn.Conv(\n      self.latent_dim, kernel_size=(3, 3), strides=(1, 1), padding=1\n    )\n    self.norm2 = nn.GroupNorm()\n    self.conv2 = nn.Conv(\n      self.latent_dim, kernel_size=(3, 3), strides=(1, 1), padding=1\n    )\n\n  def __call__(self, x):\n    \"\"\"Applies two conv layers with Swish activation and skip connection.\"\"\"\n    h = nn.swish(self.norm1(x))\n    h = self.conv1(h)\n    h = nn.swish(self.norm2(h))\n    h = self.conv2(h)\n    return x + h\n\n```", "```py\nclass VectorQuantizer(nn.Module):\n  \"\"\"Vector quantization module for VQ-VAE.\"\"\"\n\n  num_embeddings: int\n  embedding_dim: int\n  commitment_cost: float\n\n  def setup(self):\n    \"\"\"Initializes the codebook as trainable parameters.\"\"\"\n    self.codebook = self.param(\n      \"codebook\",\n      nn.initializers.lecun_uniform(),\n      (self.embedding_dim, self.num_embeddings),\n    )\n\n  def __call__(self, inputs: jax.Array):\n    \"\"\"Applies quantization and returns outputs with losses and perplexity.\"\"\"\n    quantized, encoding_indices = self.quantize(inputs)\n    codebook_loss, commitment_loss = self.compute_losses(inputs, quantized)\n    perplexity = self.calculate_perplexity(encoding_indices)\n    ste = self.get_straight_through_estimator(quantized, inputs)\n    return ste, perplexity, codebook_loss, commitment_loss\n\n  def quantize(self, inputs: jax.Array):\n    \"\"\"Snaps inputs to nearest codebook entries.\"\"\"\n    encoding_indices = self.get_closest_codebook_indices(inputs)\n    flat_quantized = jnp.take(self.codebook, encoding_indices, axis=1).swapaxes(\n      1, 0\n    )\n    quantized = jnp.reshape(flat_quantized, inputs.shape)\n    return quantized, encoding_indices\n\n  def get_closest_codebook_indices(self, inputs: jax.Array) -> jax.Array:\n    \"\"\"Returns indices of closest codebook vectors.\"\"\"\n    distances = self.calculate_distances(inputs)\n    return jnp.argmin(distances, 1)\n\n  def calculate_distances(self, inputs: jax.Array) -> jax.Array:\n    \"\"\"Computes Euclidean distances between inputs and codebook vectors.\"\"\"\n    flat_inputs = jnp.reshape(inputs, (-1, self.embedding_dim))\n    distances = (\n      jnp.sum(jnp.square(flat_inputs), 1, keepdims=True)\n      - 2 * jnp.matmul(flat_inputs, self.codebook)\n      + jnp.sum(jnp.square(self.codebook), 0, keepdims=True)\n    )\n    return distances\n\n  def compute_losses(self, inputs: jax.Array, quantized: jax.Array):\n    \"\"\"Computes codebook and commitment losses.\"\"\"\n    codebook_loss = jnp.mean(jnp.square(quantized - lax.stop_gradient(inputs)))\n    commitment_loss = self.commitment_cost * jnp.mean(\n      jnp.square(lax.stop_gradient(quantized) - inputs)\n    )\n    return codebook_loss, commitment_loss\n\n  def calculate_perplexity(self, encoding_indices: jax.Array) -> jax.Array:\n    \"\"\"Computes codebook usage perplexity.\"\"\"\n    encodings = jax.nn.one_hot(\n      encoding_indices,\n      self.num_embeddings,\n    )\n    avg_probs = jnp.mean(encodings, 0)\n    perplexity = jnp.exp(-jnp.sum(avg_probs * jnp.log(avg_probs + 1e-10)))\n    return perplexity\n\n  @staticmethod\n  def get_straight_through_estimator(\n    quantized: jax.Array, inputs: jax.Array\n  ) -> jax.Array:\n    \"\"\"Applies straight-through estimator to pass gradients through\n quantization.\n \"\"\"\n\n    ste = inputs + lax.stop_gradient(quantized - inputs)\n    return ste\n\n```", "```py\n  def __call__(self, inputs: jax.Array):\n    \"\"\"Applies quantization and returns outputs with losses and perplexity.\"\"\"\n    quantized, encoding_indices = self.quantize(inputs)\n    codebook_loss, commitment_loss = self.compute_losses(inputs, quantized)\n    perplexity = self.calculate_perplexity(encoding_indices)\n    ste = self.get_straight_through_estimator(quantized, inputs)\n    return ste, perplexity, codebook_loss, commitment_loss\n\n```", "```py\n  def quantize(self, inputs: jax.Array):\n    \"\"\"Snaps inputs to nearest codebook entries.\"\"\"\n    encoding_indices = self.get_closest_codebook_indices(inputs)\n    flat_quantized = jnp.take(self.codebook, encoding_indices, axis=1).swapaxes(\n      1, 0\n    )\n    quantized = jnp.reshape(flat_quantized, inputs.shape)\n    return quantized, encoding_indices\n\n  def calculate_distances(self, inputs: jax.Array) -> jax.Array:\n    \"\"\"Computes Euclidean distances between inputs and codebook vectors.\"\"\"\n    flat_inputs = jnp.reshape(inputs, (-1, self.embedding_dim))\n    distances = (\n      jnp.sum(jnp.square(flat_inputs), 1, keepdims=True)\n      - 2 * jnp.matmul(flat_inputs, self.codebook)\n      + jnp.sum(jnp.square(self.codebook), 0, keepdims=True)\n    )\n    return distances\n\n```", "```py\n  def compute_losses(self, inputs: jax.Array, quantized: jax.Array):\n    \"\"\"Computes codebook and commitment losses.\"\"\"\n    codebook_loss = jnp.mean(jnp.square(quantized - lax.stop_gradient(inputs)))\n    commitment_loss = self.commitment_cost * jnp.mean(\n      jnp.square(lax.stop_gradient(quantized) - inputs)\n    )\n    return codebook_loss, commitment_loss\n\n```", "```py\n  def calculate_perplexity(self, encoding_indices: jax.Array) -> jax.Array:\n    \"\"\"Computes codebook usage perplexity.\"\"\"\n    encodings = jax.nn.one_hot(\n      encoding_indices,\n      self.num_embeddings,\n    )\n    avg_probs = jnp.mean(encodings, 0)\n    perplexity = jnp.exp(-jnp.sum(avg_probs * jnp.log(avg_probs + 1e-10)))\n    return perplexity\n\n```", "```py\n  @staticmethod\n  def get_straight_through_estimator(\n    quantized: jax.Array, inputs: jax.Array\n  ) -> jax.Array:\n    \"\"\"Applies straight-through estimator to pass gradients through\n quantization.\n \"\"\"\n    ste = inputs + lax.stop_gradient(quantized - inputs)\n    return ste\n\n```", "```py\nclass Decoder(nn.Module):\n  \"\"\"Decoder module for reconstructing input from quantized representations.\"\"\"\n\n  latent_dim: int\n\n  def setup(self) -> None:\n    \"\"\"Initializes residual blocks and upsampling layers.\"\"\"\n    self.res_block1 = ResnetBlock(self.latent_dim)\n    self.res_block2 = ResnetBlock(self.latent_dim)\n    self.upsample1 = Upsample(latent_dim=self.latent_dim // 2, upfactor=2)\n    self.upsample2 = Upsample(latent_dim=1, upfactor=2)\n\n  def __call__(self, x: jax.Array) -> jax.Array:\n    \"\"\"Applies the decoder to input and returns the reconstructed output.\"\"\"\n    x = self.res_block1(x)\n    x = self.res_block2(x)\n    x = self.upsample1(x)\n    x = nn.relu(x)\n    x = self.upsample2(x)\n    return x\n\nclass Upsample(nn.Module):\n  \"\"\"Upsampling block using bilinear interpolation followed by convolution.\"\"\"\n\n  latent_dim: int\n  upfactor: int\n\n  def setup(self) -> None:\n    \"\"\"Initializes the convolutional layer for post-interpolation refinement.\"\"\"\n    self.conv = nn.Conv(\n      self.latent_dim, kernel_size=(3, 3), strides=(1, 1), padding=1\n    )\n\n  def __call__(self, x: jax.Array) -> jax.Array:\n    \"\"\"Upsamples input using bilinear interpolation and applies convolution.\"\"\"\n    batch, height, width, channels = x.shape\n    hidden_states = jax.image.resize(\n      x,\n      shape=(\n        batch,\n        height * self.upfactor,\n        width * self.upfactor,\n        channels,\n      ),\n      method=\"bilinear\",\n    )\n    x = self.conv(hidden_states)\n    return x\n\n```", "```py\nclass ClassificationHead(nn.Module):\n  \"\"\"Fully connected MLP head with optional dropout.\"\"\"\n\n  num_classes: int\n  dropout_rate: float\n  layers: int\n\n  @nn.compact\n  def __call__(self, x: jax.Array, is_training: bool) -> jax.Array:\n    for i in range(self.layers - 1):\n      x = nn.Dense(features=1000)(x)\n      x = nn.relu(x)\n      x = nn.Dropout(rate=self.dropout_rate)(x, deterministic=not is_training)\n\n    x = nn.Dense(features=self.num_classes)(x)\n    return x\n\n```", "```py\n@restorable\ndef train(\n  state: TrainState,\n  rng: jax.Array,\n  dataset_splits: dict[str, Dataset],\n  num_epochs: int,\n  batch_size: int,\n  classification_weight: float,\n  eval_every: int = 10,\n) -> tuple[TrainState, dict[str, dict[str, list[dict[str, float]]]]]:\n  \"\"\"Train the VQ-VAE model with optional classification.\"\"\"\n  # Setup metrics logging\n  metrics = MetricsLogger()\n\n  epochs = tqdm(range(num_epochs))\n  for epoch in epochs:\n    epochs.set_description(f\"Epoch {epoch + 1}\")\n    rng, rng_batch = jax.random.split(rng, 2)\n\n    # Perform a training step on a batch of train data and log metrics.\n    for batch in dataset_splits[\"train\"].get_batches(\n      rng_batch, batch_size=batch_size\n    ):\n      rng, rng_dropout = jax.random.split(rng, 2)\n      state, batch_metrics = train_step(\n        state, batch, rng_dropout, classification_weight\n      )\n      metrics.log_step(split=\"train\", **batch_metrics)\n\n    # Evaluate on the validation split\n    if epoch % eval_every == 0:\n      rng, rng_batch = jax.random.split(rng, 2)\n      for batch in dataset_splits[\"valid\"].get_batches(\n        rng_batch, batch_size=batch_size\n      ):\n        batch_metrics = eval_step(state, batch, classification_weight)\n        metrics.log_step(split=\"valid\", **batch_metrics)\n\n    metrics.flush(epoch=epoch)\n    epochs.set_postfix_str(metrics.latest([\"total_loss\"]))\n\n  return state, metrics.export()\n\n```", "```py\ndef get_batches(\n    self,\n    rng: jax.Array,\n    batch_size: int,\n  ):\n    \"\"\"Yields batches of image and label data for training or evaluation.\"\"\"\n    frame_ids = self.labels.get_frame_ids()\n\n    n_frames = len(frame_ids)\n    batches_per_epoch = n_frames // batch_size\n\n    # Shuffle data.\n    _, rng_perm = jax.random.split(rng, num=2)\n    shuffled_idx = jax.random.permutation(rng_perm, n_frames)\n\n    # The model has a softmax layer and expects consecutive integers.\n    all_labels = self.labels.lookup[[\"frame_id\", \"code\"]].set_index(\"frame_id\")\n\n    for idx_set in shuffled_idx[: batches_per_epoch * batch_size].reshape(\n      (batches_per_epoch, batch_size)\n    ):\n      frame_id_set = frame_ids[idx_set]\n      yield {\n        \"frame_ids\": frame_id_set,\n        \"images\": self.images.frames[frame_id_set],\n        \"labels\": all_labels.loc[frame_id_set][\"code\"].to_numpy(dtype=int),\n      }\n\n```", "```py\n@jax.jit\ndef train_step(\n  state: TrainState,\n  batch: dict[str, jax.Array],\n  rng_dropout: jax.Array,\n  classification_weight: float,\n) -> tuple[TrainState, dict[str, float]]:\n  \"\"\"Train for a single step.\"\"\"\n\n  def calculate_loss(params: dict) -> tuple[jax.Array, dict[str, float]]:\n    \"\"\"Forward pass and loss computation.\"\"\"\n    (\n      x_recon,\n      perplexity,\n      codebook_loss,\n      commitment_loss,\n      logits,\n    ) = state.apply_fn(\n      {\"params\": params},\n      batch[\"images\"],\n      is_training=True,\n      rngs={\"dropout\": rng_dropout},\n    )\n\n    loss_components = {\n      \"recon_loss\": optax.squared_error(\n        predictions=x_recon, targets=batch[\"images\"]\n      ).mean(),\n      \"codebook_loss\": codebook_loss,\n      \"commitment_loss\": commitment_loss,\n      \"classification_loss\": classification_weight\n      * optax.softmax_cross_entropy_with_integer_labels(\n        logits=logits, labels=batch[\"labels\"]\n      ).mean(),\n    }\n\n    metrics = {\n      \"total_loss\": sum_loss_components(**loss_components),\n      \"perplexity\": perplexity,\n      \"accuracy\": accuracy_score(batch[\"labels\"], y_pred=logits.argmax(-1)),\n      **loss_components,\n    }\n    return metrics[\"total_loss\"], metrics\n\n  # Compute gradients and apply update.\n  grad_fn = jax.value_and_grad(calculate_loss, has_aux=True)\n  (_, metrics), grads = grad_fn(state.params)\n  state = state.apply_gradients(grads=grads)\n  return state, metrics\n\n```", "```py\nfrom dlfb.localization.dataset.utils import count_unique_proteins\nfrom dlfb.localization.model import LocalizationModel\nfrom dlfb.localization.train import train\n\nmodel = LocalizationModel(\n  num_classes=count_unique_proteins(dataset_splits),\n  embedding_dim=64,\n  num_embeddings=512,\n  commitment_cost=0.25,\n  dropout_rate=0.45,\n  classification_head_layers=2,\n)\n\n```", "```py\nrng, rng_init, rng_train = jax.random.split(rng, 3)\n\nstate, metrics = train(\n  state=model.create_train_state(\n    rng=rng_init,\n    dummy_input=dataset_splits[\"train\"].get_dummy_input(),\n    tx=optax.adam(0.001),\n  ),\n  rng=rng_train,\n  dataset_splits=dataset_splits,\n  num_epochs=10,\n  batch_size=256,\n  classification_weight=1,\n  eval_every=1,\n  store_path=assets(\"localization/models/small\"),\n)\n\n```", "```py\nfrom dlfb.localization.inspect.reconstruction import show_reconstruction\n\nshow_reconstruction(dataset[\"valid\"], state, n=8, rng=rng_frames);\n\n```", "```py\nfrom dlfb.localization.inspect.metrics import plot_losses\n\nplot_losses(metrics);\n\n```", "```py\nfrom dlfb.localization.inspect.metrics import plot_perplexity\n\nplot_perplexity(metrics);\n\n```", "```py\nstate_alt, metrics_alt = train(\n  state=model.create_train_state(\n    rng=rng_init,\n    dummy_input=dataset_splits[\"train\"].get_dummy_input(),\n    tx=optax.adam(0.001),\n  ),\n  rng=rng_train,\n  dataset_splits=dataset_splits,\n  num_epochs=10,\n  batch_size=256,\n  classification_weight=0,  # i.e. the protein id are ignored\n  eval_every=1,\n  store_path=assets(\"localization/models/small_alt\"),\n)\n\n```", "```py\nplot_perplexity(metrics_alt);\n\n```", "```py\nshow_reconstruction(dataset[\"valid\"], state_alt, n=8, rng=rng_frames);\n\n```", "```py\ndef get_frame_embeddings(\n  state: TrainState,\n  dataset_split: Dataset,\n  batch_size: int = 256,\n) -> dict[str, np.ndarray]:\n  \"\"\"Returns per-frame histograms of codebook encoding indices.\"\"\"\n  num_embeddings = get_num_embeddings(state)\n  frame_ids, frame_histograms = [], []\n\n  rng = jax.random.PRNGKey(42)\n  for batch in dataset_split.get_batches(rng, batch_size):\n    frame_ids.append(batch[\"frame_ids\"])\n    encoding_indices = pluck_encodings(state, batch)\n\n    # Reshape and count codebook usage per frame.\n    frame_histograms.append(\n      np.apply_along_axis(\n        lambda x: np.histogram(x, bins=np.arange(0, num_embeddings + 0.5))[0],\n        axis=1,\n        arr=jnp.reshape(encoding_indices, (batch_size, -1)),\n      )\n    )\n\n  return {\n    \"frame_ids\": np.concatenate(frame_ids),\n    \"frame_histograms\": np.concatenate(frame_histograms, axis=0),\n  }\n\n```", "```py\nfrom dlfb.localization.inspect.embeddings.clustering import (\n  calculate_projection,\n  plot_projection,\n)\nfrom dlfb.localization.inspect.embeddings.utils import get_frame_embeddings\n\nframe_embeddings = {}\nfor name, s in zip([\"no_head\", \"with_head\"], [state_alt, state]):\n  frame_embeddings[name] = get_frame_embeddings(s, dataset_splits[\"valid\"])\n\nprojection = calculate_projection(frame_embeddings)\nplot_projection(\n  projection,\n  dataset_splits[\"valid\"],\n  titles=[\"No ClassificationHead\", \"With ClassificationHead\"],\n);\n\n```", "```py\ndef cluster_feature_spectrums(\n  protein_histograms: np.ndarray, n_clusters: int\n) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n  \"\"\"Cluster proteins based on similarity in codebook usage patterns.\"\"\"\n  corr_idx_idx = np_pearson_cor(protein_histograms, protein_histograms)\n  tree = linkage(\n    corr_idx_idx,\n    method=\"average\",\n    metric=\"euclidean\",\n    optimal_ordering=True,\n  )\n  encoding_clusters = fcluster(tree, n_clusters, criterion=\"maxclust\")\n  return corr_idx_idx, tree, encoding_clusters\n\n```", "```py\nfrom dlfb.localization.inspect.embeddings.feature_spectrum import (\n  plot_encoding_corr_heatmap,\n)\nfrom dlfb.localization.inspect.embeddings.utils import aggregate_proteins\n\nprotein_ids, protein_histograms = aggregate_proteins(\n  dataset_splits[\"valid\"], **frame_embeddings[\"with_head\"]\n)\ncorr_idx_idx, tree, encoding_clusters = cluster_feature_spectrums(\n  protein_histograms, n_clusters=8\n)\nplot_encoding_corr_heatmap(corr_idx_idx, tree, encoding_clusters);\n\n```", "```py\nfrom dlfb.localization.inspect.embeddings.feature_spectrum import (\n  plot_stacked_histrograms,\n)\nfrom dlfb.localization.inspect.embeddings.utils import aggregate_localizations\n\nlocalizations, localization_histograms = aggregate_localizations(\n  dataset_splits[\"valid\"], protein_ids, protein_histograms\n)\nplot_stacked_histrograms(\n  localizations, localization_histograms, tree, encoding_clusters\n);\n\n```", "```py\ndataset_splits = DatasetBuilder(\n  data_path=assets(\"localization/datasets\")\n).build(\n  rng=rng_dataset,\n  splits={\"train\": 0.80, \"valid\": 0.10, \"test\": 0.10},\n  n_proteins=500,  # a larger number of proteins\n)\n\nmodel = LocalizationModel(\n  num_classes=count_unique_proteins(dataset_splits),\n  embedding_dim=64,\n  num_embeddings=512,\n  commitment_cost=0.25,\n  dropout_rate=0.45,\n  classification_head_layers=2,\n)\n\nstate, metrics = train(\n  state=model.create_train_state(\n    rng=rng_init,\n    dummy_input=dataset_splits[\"train\"].get_dummy_input(),\n    tx=optax.adam(0.001),\n  ),\n  rng=rng_train,\n  dataset_splits=dataset_splits,\n  num_epochs=10,\n  batch_size=256,\n  classification_weight=1,\n  eval_every=1,\n  store_path=assets(\"localization/models/large\"),\n)\n\n```", "```py\nfrom dlfb.localization.inspect.embeddings.feature_spectrum import (\n  plot_stacked_histrograms,\n)\nfrom dlfb.localization.inspect.embeddings.utils import (\n  aggregate_localizations,\n  aggregate_proteins,\n  cluster_feature_spectrums,\n  get_frame_embeddings,\n)\n\nframe_embeddings = get_frame_embeddings(state, dataset_splits[\"valid\"])\nprotein_ids, protein_histograms = aggregate_proteins(\n  dataset_splits[\"valid\"], **frame_embeddings\n)\n_, tree, encoding_clusters = cluster_feature_spectrums(\n  protein_histograms, n_clusters=12\n)\nlocalizations, localization_histograms = aggregate_localizations(\n  dataset_splits[\"valid\"], protein_ids, protein_histograms\n)\nplot_stacked_histrograms(\n  localizations, localization_histograms, tree, encoding_clusters\n);\n\n```", "```py\nfrom dlfb.localization.inspect.embeddings.clustering import (\n  calculate_projection,\n  plot_projection,\n)\n\nprojection = calculate_projection(frame_embeddings)\nplot_projection(\n  projection,\n  dataset_splits[\"valid\"],\n  subset_mode=\"single\",  # Only show frames with single localization\n  titles=[\"Localization UMAP Projection\"],\n);\n\n```"]