- en: 7 Accelerating and improving UI automation using AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs: []
  type: TYPE_NORMAL
- en: How to create UI automation rapidly using GitHub Copilot and ChatGPT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to improve UI automation rapidly using GitHub Copilot and ChatGPT
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If there is one area in the software testing industry that has garnered the
    most attention regarding the use of AI tools, it’s UI automation. As large language
    models (LLMs) began capturing attention, people in the testing world quickly focused
    on how UI automated checks could be easily generated through tools such as Copilot
    and ChatGPT. The possibilities and ideas around using AI tools for UI automation
    have been expanding rapidly. But although the enthusiasm for these tools is significant,
    and tool vendors and automators alike rush to use AI, we must be mindful of where
    and how AI can be of use.
  prefs: []
  type: TYPE_NORMAL
- en: Success with AI in creating automation is as much about knowing *when* to use
    AI tooling as it is about knowing *how* to use it. For this reason, this chapter
    focuses on how to break down the process of creating and maintaining automated
    checks and discover where AI tools can speed up our processes, while ensuring
    that we still deliver valuable automation.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1 Rapidly creating UI automation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Head to ChatGPT and ask it to generate a Selenium test in Java that automates
    a login page, and it will happily oblige. This might seem like an effective path
    to take, but let’s take a look at a brief example of this process and see what
    happens. For the prompt, we can use
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Assuming the role of a test automator, create an automated test using Selenium
    and Java that automates and validates the log in process for an application |'
  prefs: []
  type: TYPE_TB
- en: It will return a code example such as
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: The code looks correct and would likely compile. But if we were to bring this
    code into our automation framework, we should ask ourselves, “How much of this
    would we need to change to make it work with our product under test?” Chances
    are we would need to
  prefs: []
  type: TYPE_NORMAL
- en: Remove the `Driver` instantiation to use our own driver factory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Point the check to the correct application by updating `driver.get`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Move the `findElements` methods to relevant Page objects.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Update the selectors so that they are using the ones that align with our product.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Update the assertion to meet our assumptions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before we know it, we’ve ended up replacing nearly all the code suggested by
    ChatGPT, which doesn’t feel like an efficient use of our time. This is because
    although tools such as ChatGPT and Copilot can rapidly generate code on demand,
    they lack the context of our systems. That is, if we ask these tools to create
    our automated checks with little input provided, the result will be code that
    requires extensive rework. Instead, we want to take a more symbiotic approach,
    using AI tools in targeted ways to help us with specific tasks in creating automated
    UI checks.
  prefs: []
  type: TYPE_NORMAL
- en: Consider the visualization in figure 7.1, which breaks down the various components
    included in a common automated check that works on the UI layer.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, there are many moving parts—from the framework itself, which
    handles the dependencies and reporting of automated checks, to the various activities
    that an automated check carries out to create state, interact with a UI, and assert
    against expectations. Each of these parts can be guided using AI, so, rather than
    attempting to rely on an AI to create everything at once, we focus on specific
    tasks throughout building and maintaining of our automated check and use LLMs
    to speed up the process.
  prefs: []
  type: TYPE_NORMAL
- en: AI compared to record and playback tools
  prefs: []
  type: TYPE_NORMAL
- en: A valid question to ask is how the use of AI differs from record and playback
    tools and their ability to record our actions and convert them into code. If we
    were to use LLMs to generate automated checks, then the difference wouldn’t be
    great. In fact, record and playback tools would likely be better because they
    are interacting with the system and implicitly learning about the product’s context
    and rules during recording.
  prefs: []
  type: TYPE_NORMAL
- en: However, one limitation of record and playback is when they encounter more complex
    frameworks that will be arranged using approaches such as Page Object and Screenplay
    patterns to make them more maintainable. Record and playback tools tend to output
    resulting code as a script run by itself, separate from others. When that script
    needs to be integrated into the framework, we will likely need to rework and reorganize
    our initial script dramatically, which brings us back to the initial problem—slow
    progress in creating automated UI checks.
  prefs: []
  type: TYPE_NORMAL
- en: What this chapter proposes is that we use LLMs in very specific situations,
    targeting specific actions. If we want to rapidly create Page objects, then an
    LLM can help us with that task—its output can be quickly plugged into a wider
    framework with minimum rework.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH07_F01_Winteringham2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 A visual representation of the component parts of an automated UI
    check
  prefs: []
  type: TYPE_NORMAL
- en: To demonstrate this process, let’s take a look at how we can use tools such
    as Copilot and ChatGPT in our automation workflow, selecting specific actions
    that AI tools can assist with, by building an automated check for the website
    [https://automationintesting.online](https://automationintesting.online), which
    is a mock bed-and-breakfast booking site that can be used to practice various
    testing and automation activities.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we check whether a message is shown in the admin section of
    the website. To do this, we’ll need to codify the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Launch a browser.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Head to [automationintesting.online](https://automationintesting.online).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Complete the Contact Us form on the home page.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Head to the Admin section of the site and log in.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Load the Message section and confirm that the created message appears.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This process is summarized in figure 7.2.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH07_F02_Winteringham2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 Visual representation of the automated UI check that will be created
  prefs: []
  type: TYPE_NORMAL
- en: Although the example itself is nothing spectacular, what we’ll learn is that
    we can accelerate our work using AI tools as we complete each step—so let’s begin.
    For reference, you can review the code that was generated for this example on
    GitHub ([https://mng.bz/4pXB](https://mng.bz/4pXB)).
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Copilot
  prefs: []
  type: TYPE_NORMAL
- en: This chapter assumes that you have installed and configured the Copilot plugin
    within your IDE. If you haven’t already completed the setup process, you can find
    installation instructions in appendix B.
  prefs: []
  type: TYPE_NORMAL
- en: Activity 7.1
  prefs: []
  type: TYPE_NORMAL
- en: Follow the steps in this chapter to see whether you can generate a similar automated
    check. As always, remember that the output that comes from ChatGPT and Copilot
    may differ from what has been captured in the following example.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1.1 Setting up a project
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We’ll carry out the example in this section in Java. This is a useful language
    to demonstrate the value of using AI tools, because Java is known for its reliance
    on boilerplate code (a great place in which LLMs can help build for us). For our
    first step, we need to create a new Maven project and, once the project is created,
    add the following dependencies into our `pom.xml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Now we have everything we need to start developing our automated check.
  prefs: []
  type: TYPE_NORMAL
- en: With our dependencies in place, we can create the necessary packages—`com.example`
    and our `Test` class—which we’ll name `MessageTest`. From here, we can begin to
    use Copilot to build our automated check, but we need to prompt Copilot with some
    information to begin the process. So first we add in a `WebDriver` variable inside
    our `MessageTest` class
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'followed by the code comment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The combination of code and comment acts sufficiently as a prompt to trigger
    the following response from Copilot:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a good start, but it’s missing the driver instantiation and `BeforeAll`
    hook, which we can add to the next line below the `WebDriverManager` call:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'which gives us the following Before hook:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'To tweak or not to tweak prompts: Making the efficient choice'
  prefs: []
  type: TYPE_NORMAL
- en: Another observation about working with prompts to generate desired output is
    that it can be tempting to want to tweak a prompt multiple times to produce the
    right output, which can be time consuming. In the previous example, the code comment
    was likely not clear enough for Copilot to produce the complete code snippet we
    required. The options then are to improve the prompt or add the missing sections
    of code that are required. In this context, adding the required code made sense.
    I knew what I required, and spending time tweaking the prompt would have been
    wasteful. However, if my knowledge of what I wanted was shallower, then I might
    have chosen to tweak the prompt further. Efficiency is created by being aware
    of what is the right choice to make at a given time.
  prefs: []
  type: TYPE_NORMAL
- en: We have our `BeforeAll` hook in place, so next we want to create a teardown
    hook, which we can do by adding the annotation
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: prompting Copilot to return
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Our second prompt is arguably more accurate than the first one because we are
    beginning to flesh out the context in which Copilot can be prompted. The more
    we add to our codebase, the more potential Copilot has to accurately add in what
    we want. Finally, to verify that everything is working, let’s add in a bare-bones
    `@Test` to ensure that everything is running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: So far, so good. We’ve set up our project and our initial test with the support
    of Copilot. We’ve also observed that, initially, Copilot is lacking details to
    help recommend the correct lines of code. But as we develop, we’ll start to observe
    its accuracy improve. This is a great start—now let’s see how tools such as ChatGPT
    can help speed up our work even more.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1.2 Creating our initial check with ChatGPT support
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With the framework in place, we can turn our attention to completing the Contact
    Us form on the home page. To help contextualize what we’ll be working with, see
    figure 7.3.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH07_F03_Winteringham2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.3 The Contact Us form on the website under test
  prefs: []
  type: TYPE_NORMAL
- en: The figure shows multiple form fields to complete and a Submit button, all of
    which we will need to codify in our automated check. To do this, we’ll need to
    create a Page object that captures each of the elements, which we’ll use in our
    check to populate and submit the form. This process is a laborious one (and one
    that I personally find to be time consuming and boring, which are the types of
    emotional triggers explored in chapter 1). So, how can we speed up the process
    of creating Page objects? We could use Copilot to help us author our classes,
    but the process of identifying each CSS selector for each element has the potential
    to take up a lot of time. Instead, let’s take a look at how we could use a prompt
    in ChatGPT to rapidly create our Page object for us.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s take a look at a prompt that can be used to trigger ChatGPT to
    generate our Page object (you can copy and paste the prompt into ChatGPT: [https://mng.bz/QVpm](https://mng.bz/QVpm)).
    We set out instructions with the delimiter tactic:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| You are an expert Java Developer. Convert the HTML delimited by three hashes
    into a Java Selenium Page object using the `PageFactory` library and `@FindBy`
    annotations. |'
  prefs: []
  type: TYPE_TB
- en: 'We provide HTML in the delimited section:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 'Breaking down the prompt, we can observe that it takes this form:'
  prefs: []
  type: TYPE_NORMAL
- en: Clear instructions at the start, informing ChatGPT of what we want to achieve
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A list of constraints that specifies clear instructions for what we expect from
    ChatGPT, stating which libraries and methods we’d like to explicitly use when
    creating our Page object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To create the Page object, we take the prompt we have just explored and add
    the HTML from our Contact form to the bottom before pasting it into ChatGPT. Again,
    feel free to use the already created prompt available on GitHub at [https://mng.bz/QVpm](https://mng.bz/QVpm):'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 'Entering this prompt into ChatGPT yields the following code for our Page object:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT has not only successfully created a class that includes all the necessary
    methods required to complete and submit the contact form, but this was also done
    rapidly after a single prompt. In this example, the class was quite small, but
    regular Page objects can be pretty large. The time taken to write and maintain
    Page objects is compounded by the amount we require. So, by using ChatGPT to rapidly
    generate our code for us, we can continue developing our automated check faster.
  prefs: []
  type: TYPE_NORMAL
- en: Testability and AI tools
  prefs: []
  type: TYPE_NORMAL
- en: Even with AI tools, the testability of a product influences a tool’s effectiveness.
    The way in which the HTML for the Contact Us form has been created can be said
    to have a high *testability.* The HTML is semantically correct, and it contains
    clear, stable HTML attributes in the `input` and `textarea` elements that ChatGPT
    can predict to put into the created class. If, however, the HTML we are working
    with requires us to identify more complex selectors, perhaps due to autogenerated
    IDs or a lack of HTML elements, then the performance of our prompt may not be
    as effective, requiring us to update and tweak our Page object to better suit
    our needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'With our Page object created, we can head back to `MessageTest` and tab through
    Copilot’s suggestions to create our necessary Contact Us form-filling code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Copilot has read our object and helped us map out filling in the form. But
    although it can read the methods that exist in `ContactFormPage` and predict what’s
    next, it lacks context on validation rules for each form field, which affects
    the test data it creates. Unlike in the previous chapter, in which test data was
    accurately set based on expectations, the data returned is generic and will cause
    problems. For example, the validation rule set for the Phone Number field requires
    11 or more digits to be entered, so our predicted test data would cause our automated
    test to fail. Therefore, let’s update the `enterPhone` parameter with data that
    will pass the phone number validation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'With our message created, we now want to log in, which can be achieved by following
    a pattern similar to the one we have just followed. First, we create the necessary
    code to head to the Admin page:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, returning to our current chat with ChatGPT, we can reuse our earlier
    prompt to create a Page object for the admin login page, this time simply referring
    to the original prompt and providing it with new HTML to generate our class:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Follow the previous prompt again, but this time use the following HTML:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 'This yields the following `LoginPage` code to add to our project:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we create the `LoginPage` class in our code, fixing our missing imports,
    and then return to `MessageTest` and use Copilot to create our login step by tabbing
    through suggestions to produce the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we can execute one more loop of using ChatGPT and Copilot to complete
    our automated test by first adding the necessary code to navigate to the message
    page:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we create our final Page object, this time tweaking our prompt to ChatGPT
    to create a method that returns a count of messages:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Follow the prompt again, this time I require a method that returns me the
    count of messages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 'It returns the following `MessagePage` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 'Like before, we create a `MessagePage` class in our codebase, fix our imports,
    and return to `MessageTest` to let Copilot predict the following code to complete
    our automated check:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 7.1.3 Filling in gaps from generated code
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This completes our automated check, but if we were to run this code, it would
    likely result in the failure of the automated check. The failure occurs because,
    to get the message count, we must wait for the count to load, which is missing
    from our automated check. Although this failure differs from the incorrect test
    data being added by Copilot we experienced earlier, the reason for our current
    problem is similar. ChatGPT predicts the code we require based on what the prompt
    is asking and the HTML provided. It lacks the ability to understand what parts
    of our system may require waits in place to prevent an automated check from failing.
    However, we can resolve this problem by returning to ChatGPT and submitting the
    prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Can you improve the `MessagePage` class and have it wait for the message
    list to load |'
  prefs: []
  type: TYPE_TB
- en: 'ChatGPT responds with an updated version of `MessagePage`:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 'This is a step forward in improving our automated check, but it also demonstrates
    again how ChatGPT is trained on older versions of libraries and APIs. If we copy
    this code over to our check, we’ll see that `WebDriverWait` makes errors because
    it no longer takes integers—a change that came in after ChatGPT was trained on
    Selenium material. So, we need to update `WebDriverWait` to take a `Duration`
    parameter instead:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, to improve the feedback we get from our automated test, we update
    the assertion suggested by Copilot to a more informative one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: With all this in place, assuming there are no extra messages on the platform,
    we can run the check and see it pass. The key behavior to observe is how we used
    Copilot and ChatGPT to rapidly build our automated check. Instead of sending a
    prompt to ChatGPT such as
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Create an automated test for a contact us form and check if the message has
    been created |'
  prefs: []
  type: TYPE_TB
- en: which would result in quite a generic output requiring a lot of modification,
    we worked through each step of our automated check using Copilot and ChatGPT to
    rapidly create parts of the check, switching between tools to help us solve specific
    problems. If we return to our area-of-effect model, this approach is summarized
    in figure 7.4.
  prefs: []
  type: TYPE_NORMAL
- en: The model shows us that if we are able to identify the specific actions that
    occur in an automated check—like determining what state a check requires or what
    assertions to make—then we can use an LLM effectively with said actions. As demonstrated
    in the example, ChatGPT and Copilot (and other LLM tools) are incredibly fast
    at predicting and generating code for our automation. However, they lack access
    to the context of the product we’re automating. Problems such as incorrect test
    data and missing waits require us to lead the creation of automation, with AI
    tools offering support where we need it most.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH07_F04_Winteringham2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.4 Area-of-effect model showing the skills an individual and tooling
    bring to the development of automated checks
  prefs: []
  type: TYPE_NORMAL
- en: Activity 7.2
  prefs: []
  type: TYPE_NORMAL
- en: 'Use Copilot and ChatGPT to create your own automated check with [https://automationintesting.online](https://automationintesting.online).
    This time, create an automated check that does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Logs in to the admin section of the site
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creates a new room
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asserts that the room appears on the home page
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the prompts shared in the example to generate your own Page objects, or
    build your own prompts that might be more effective.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2 Improving existing UI automation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our initial example demonstrated how we can work with LLM tools to rapidly create
    new automated checks, but what about existing checks? Working with automation
    means handling automated checks that fail due to flakiness or rapid changes within
    the product under test. How can LLM tools help us improve our automation rapidly,
    while ensuring they still deliver value? Let’s go back to the automated check
    we have just created and see how the patterns of use for LLMs can help us make
    more robust automated checks.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2.1 Updating state management to use an appropriate layer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If we assess what our automated check is focused on, we can see that the goal
    is to check whether messages can be seen in the Admin panel. What this means for
    our state management is that we don’t need to create our message through the UI.
    It’s slow and potentially brittle. So, let’s instead take a look at how we can
    create the message with an API call so that we can improve our automated check
    and learn how to use LLMs to build API calls.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our goal is to capture the HTTP request sent when creating a message via the
    Contact Us page and codify that into our automated test. So, our first step is
    to capture the HTTP request as a `curl` command by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open up Dev Tools within our browser.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select the Network tab.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Manually send a message via the Contact Us form in the UI.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Locate the HTTP request on the Network tab and then copy the request to a `curl`
    command (right-click the request in Dev Tools).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'With our command located, we can once again build a prompt that will convert
    our `curl` request into the required Java code using the following prompt. We
    first set out instructions for prompt and use delimiter tactic:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Convert the following `curl` request delimited by triple hashes into Java
    using the following rules:   1.  The request is encapsulated in a method   2. 
    The method will use spring framework to send the HTTP request   3.  The HTTP response
    doesn’t need parsing   4.  The method will take a POJO that represents the HTTP
    payload as a parameter |'
  prefs: []
  type: TYPE_TB
- en: 'We provide the `curl` request in the delimited section:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to the prompt we used to create Page objects, this prompt sets out
    what we want ChatGPT to do in the initial sentence before adding specific instructions
    to help ChatGPT predict the correct code we require—for example, stating that
    the method wants the body payload parameter to come in the format of a POJO (Plain
    Old Java Object), ensuring that ChatGPT generates a solution that utilizes Java
    classes to construct our payload, rather than a JSON object stored within a large
    String that would be hard to parse and maintain. Passing the prompt in with the
    `curl` request added to the bottom of the prompt will yield the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: 'This predicted code requires new dependencies to be added to our project, which
    we can request from ChatGPT with the following prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| What dependencies are required for this method? |'
  prefs: []
  type: TYPE_TB
- en: which results in ChatGPT returning
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: We can then add the dependency into our `pom.xml`, ensuring that we are using
    the latest versions, followed by copying the HTTP request code into our framework
    in a new package named `requests`. I opted to rename the class from `HttpRequestSender`
    to `MessageRequest`.
  prefs: []
  type: TYPE_NORMAL
- en: 'This gives us the required code to send a request, but because we informed
    ChatGPT that `sendRequest` would take a POJO parameter for the body of our request,
    we next need ChatGPT to create the code to build our POJO. To do this, we return
    to our existing chat with ChatGPT and add the following prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Create me a POJO for `MessagePayload` including constructors and getter and
    setter methods |'
  prefs: []
  type: TYPE_TB
- en: 'The prompt makes it clear that we require constructors and getter/setter methods
    because these will be necessary for creating and sending our HTTP request. Sending
    the prompt to ChatGPT yields the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Because we provided the `curl` request in the initial prompt, ChatGPT can predict
    what the code for our POJO should look like to create a message to send via HTTP,
    which can then be copied over to a `MessagePayload` class in the `requests` package
    of our project.
  prefs: []
  type: TYPE_NORMAL
- en: 'With our classes in place to create a message payload and send a request to
    the `POST /message/` endpoint, we can then return to our `MessageTest` and use
    Copilot to improve our check. First, we remove the following section of our check:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'and start typing `MessagePayload` to trigger Copilot to add the following code
    as a replacement:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar to when we used Copilot to generate code for creating a message in
    the UI, running the automated check for the first time will result in a failure.
    The check will run and then receive a 400-status code because the predicted test
    data didn’t match the validation rules again. Therefore, to ensure that our message
    matches the necessary validation rules, we need to update the following methods
    with correct test data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Once these test data parameters are updated, we should now see the automated
    check pass again.
  prefs: []
  type: TYPE_NORMAL
- en: This example demonstrates that we can use LLM tools to help us update specific
    aspects of our automated checks to make them more robust, but it requires us to
    have a good analytical eye for which areas of our checks require improvement.
    This is because we have knowledge of both our automated checks and our system
    under test, which is lacking in the tools we’ve used so far. For example, if we
    were to give ChatGPT the prompt
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-MW.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Suggest ways in which this automated test can be improved to make it less
    flakey |'
  prefs: []
  type: TYPE_TB
- en: 'and then add our automated check code to the prompt, these would be the returned
    suggestions (in summary):'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/logo-openai.png)'
  prefs: []
  type: TYPE_IMG
- en: '|    •   Add explicit waits   •   Use stable locators   •   Handle asynchronous
    operations   •   Isolate the test   •   Retry failed actions   •   Check for error
    conditions   •   Review and update the test environment |'
  prefs: []
  type: TYPE_TB
- en: These are all legitimate considerations, but they are generic problems and don’t
    necessarily give us enough information to solve specific problems. So instead,
    we frame the process of improvement, looking to tools to help us rapidly generate
    the necessary code.
  prefs: []
  type: TYPE_NORMAL
- en: Activity 7.3
  prefs: []
  type: TYPE_NORMAL
- en: Using ChatGPT and Copilot, try turning the login process into an API call as
    well. For this exercise, you will need to create the code to
  prefs: []
  type: TYPE_NORMAL
- en: Send credentials to `POST /auth/login`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extract the `token` value from the HTTP response
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Store the `token` value as a cookie in the browser before heading to the message
    page
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 7.2.2 Getting into the groove with AI tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This chapter demonstrated that regardless of whether we are building UI automation,
    API automation, or something entirely different, the pattern of success with AI
    is always the same. Our deep understanding of the design and structure of automated
    checks informs us when and where to use AI tools to help us with specific tasks
    to create and maintain valuable automation. The marketing around AI automation
    would have us believe that our role in creating automated checks is limited when
    AI is involved. But if we want automation that helps us create high-quality products,
    then our best course of action is to build a relationship with AI tools that places
    our skillset at the core of the work.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Attempting to generate a whole automated UI test using only a tool such as ChatGPT
    will likely require a lot of rework. Instead, we want to use AI tools selectively
    at specific points of the UI automation process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Starting a new project with a tool such as Copilot can yield varying results.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The more detail we add to our project, the more accurate Copilot will be.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the right type of prompt, we can rapidly generate Page objects in ChatGPT
    by providing it with HTML and instructions to convert it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can rapidly generate automated checks by combining ChatGPT and Copilot (or
    similar tools).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The output of AI tools is not 100% accurate, because it lacks context—for example,
    with test data or using up-to-date methods from libraries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Success with AI tools when creating automated checks comes from using AI tools
    to complete specific tasks within the creation process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We lead the creation process, identifying when AI tools can help us speed it
    up.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we are able to identify improvements to specific elements of an automated
    check, we can employ AI tools to make the improvements faster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we ask LLMs to evaluate our checks and offer improvements, we get generic
    answers in return.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We can use the same process of using AI tools on specific tasks within our automated
    checks to maintain them.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
