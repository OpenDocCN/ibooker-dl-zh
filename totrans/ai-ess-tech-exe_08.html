<html><head></head><body>
<div id="book-content">
<div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 8. Looking at Data: Our Your Secret Weapon"><div class="chapter" id="id30">
<h1><span class="label">Chapter 8. </span>Looking at Data: <span class="keep-together"><span class="strikethrough">Our</span> Your Secret Weapon</span></h1>

<p>We’ve touched on the importance of having metrics that are specific
to your business and a systematic process for measuring and reviewing
them.</p>
<p>In this chapter, I want to share a recent experience that highlights a crucial
lesson for AI projects:</p>
<blockquote>
<p>There’s no substitute for examining your data
firsthand.</p></blockquote>
<p>I was recently working with a company that automates HR functions
like recruiting and onboarding. Their engineering team had developed an
evaluation suite with various metrics to measure the AI’s performance.
One metric in particular caught my attention: the <em>edit distance</em>
between the AI-generated email and the recruiter’s final version. In
case you haven’t heard of it, edit distance is a measurement of how
similar two texts are. This metric seemed like it would be a good one—it’s business-specific, and it can be systematically measured.</p>
<p>The team had found that the average edit distance between the
AI-generated emails and the recruiter’s final version was 12%. This
seemed like a good result, but the team was struggling with user adoption. It turned out that the metric was hiding a critical flaw.</p>

<section data-type="sect1" data-pdf-bookmark="Look at the Raw Data"><div class="sect1" id="id97">
<h1>Look at the Raw Data</h1>
<p>In my experience, the best way to understand a metric is to look at
the raw data. It might sound simple, but it’s a secret weapon that
almost always uncovers something unexpected.</p>
<p>I asked to review some of these emails myself, and what I found was
shocking: for the most part, the AI-generated emails were perfectly
reasonable. Instead, it was actually the human edits that were causing
problems! The “improvements” that humans made often introduced
grammatical errors, wordiness, and unclear messaging.</p>
<p>The assumption that human edits would always improve the emails was a
fundamental flaw in the edit-distance metric. This discovery took me
just a few hours. The team was stunned by how quickly I identified this
issue that had eluded them for so long.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="You (Yes, You) Need to Review Data"><div class="sect1" id="id98">
<h1>You (Yes, You) Need to Review Data</h1>
<p>In my consulting engagements, I <em>always</em> train executives on
reviewing data. This approach is the main reason our clients see <a href="https://oreil.ly/ECo1I">tangible
results</a>.</p>
<p><em>Understanding the nuances of your AI systems isn’t just the
domain of technicians and engineers—it’s a critical responsibility for
executives.</em></p>
<p>As an executive, you’re in a unique position to bridge the gap
between technical capabilities and business objectives. AI systems often
interact with users in natural language, making the data more accessible
than you might think. By personally reviewing AI interactions, you
can:</p>
<dl>
<dt>Ensure alignment with business values</dt><dd>Verify that
the AI represents your brand and communicates in a manner consistent
with your company’s ethos.</dd>
<dt>Uncover hidden issues</dt><dd>Spot user experience
problems, interface issues, or workflow bottlenecks that aggregated
reports might miss.</dd>
<dt>Provide valuable feedback</dt><dd>Your critiques can
directly improve the AI’s performance, much like coaching a new
employee.</dd>
</dl>
<p>Below, we provide you with a toolkit that provides a systematic
approach to reviewing data.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Step 1: Set Up a User-Centric Data Viewer"><div class="sect1" id="id99">
<h1>Step 1: Set Up a User-Centric Data Viewer</h1>


<p>To effectively review AI interactions, you need to see them as your
users do. Technical logs and observability platforms are filled with
jargon and irrelevant details that can obscure the real user
<span class="keep-together">experience</span>.</p>


<section data-type="sect2" data-pdf-bookmark="Actions"><div class="sect2" id="id100">
<h2>Actions</h2>
<dl>
<dt>Collaborate with your team</dt><dd>Discuss the need for a
data viewer that mirrors the user interface your customers interact
with.</dd>
<dt>Eliminate technical distractions</dt><dd>Ensure the viewer
focuses solely on the AI-user interactions without backend codes, logs,
or intermediate AI processing steps.</dd>
<dt>Simplify access</dt><dd>The data viewer should be easily
accessible—consider bookmarking it or setting it as your homepage for
quick access.</dd>
</dl>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Requirements"><div class="sect2" id="id101">
<h2>Requirements</h2>

<p>Start with the simplest thing that could possibly work. Here are some requirements that you should keep in mind:</p>
<dl>
<dt>Start with a spreadsheet</dt><dd>For simpler applications,
a well-organized spreadsheet can be a quick and effective solution.</dd>
<dt>Prioritize visual clarity</dt><dd>The data viewer should
present information clearly, using visuals where appropriate to enhance
understanding.</dd>
<dt>Include key context</dt><dd>Make sure each interaction
includes relevant details like timestamps, user segments, or any
categorization that helps in understanding the context.</dd>
</dl>
</div></section>


<section data-type="sect2" data-pdf-bookmark="Example of a Data Viewer"><div class="sect2" id="id102">
<h2>Example of a Data Viewer</h2>

<p><a data-type="xref" href="#fig0801">Figure 8-1</a> shows a real example of a data viewer used by the CTO of Rechat,
that allows him to quickly look at pertinent data. This kind of thing
can be built in just a few hours.</p>

<figure><div id="fig0801" class="figure">
<img src="assets/aete_08in01.png" width="1531" height="1366"/>
<h6><span class="label">Figure 8-1. </span>A user-centric LLM annotation tool<sup><a data-type="noteref" id="id132-marker" href="ch08.html#id132">1</a></sup></h6>
</div></figure>





<p>You don’t need to build anything as fancy as this, but it shows that
it can be done. As an in-between step, I often use <a href="https://airtable.com">Airtable</a> for this task. Remember, do
the simplest thing that could possibly work, including a simple
spreadsheet.</p>

</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Step 2: Establish a Daily Data Review Routine"><div class="sect1" id="id103">
<h1>Step 2: Establish a Daily Data Review Routine</h1>

<p>Consistent, hands-on review keeps you connected to your AI’s
performance and user experience. By dedicating a small portion of your
day, you can catch issues early and guide your team more
effectively.</p>


<section data-type="sect2" data-pdf-bookmark="Actions"><div class="sect2" id="id104">
<h2>Actions</h2>
<dl>
<dt>Schedule time on your calendar</dt><dd>Treat data review
as a critical meeting with yourself—block out 15–20 minutes daily.</dd>
<dt>Focus on failure modes</dt><dd>Prioritize reviewing
interactions where the AI may have underperformed or failed to meet user
needs.</dd>
<dt>Review a representative sample</dt><dd>Don’t just look at
problems; include successful interactions to understand what works
well.</dd>
</dl>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Tips for Setting Up a Daily Data Review Routine"><div class="sect2" id="id105">
<h2>Tips for Setting Up a Daily Data Review Routine</h2>
<p>The most successful leaders I’ve worked with incorporate the following into their routine:</p>
<dl>
<dt>Set themes for each day</dt><dd>Focus on different
features or user segments each day to cover more ground over time.</dd>
<dt>Use random sampling</dt><dd>To avoid bias, randomly select
interactions to review alongside targeted ones.</dd>
<dt>Keep notes handy</dt><dd>Maintain a journal or digital
note where you can jot down immediate thoughts or patterns you
notice.</dd>
</dl>
</div></section>

</div></section>

<section data-type="sect1" data-pdf-bookmark="Step 3: Categorize Data for Efficient Review"><div class="sect1" id="id106">
<h1>Step 3: Categorize Data for Efficient Review</h1>

<p>Organizing data into categories helps you spot patterns, understand
context, and make your review process more efficient. It allows you to
focus on specific areas that are critical to your business objectives.
<em>Your team needs to categorize this data prior to you reviewing
it.</em></p>


<div data-type="warning" epub:type="warning">
<h1>Categorize Before You Review</h1>
<p>If the data is not categorized, it will be hard to navigate and
analyze. This categorization can be automated with code that inserts
tags into the data, with LLMs, or with a combination of both.</p>
</div>

<section data-type="sect2" data-pdf-bookmark="Actions"><div class="sect2" id="id107">
<h2>Actions</h2>
<dl>
<dt>Categorize by features, tools, and skills</dt><dd>Identify
the different functionalities your AI offers, such as email drafting,
scheduling, or contact searching.</dd>
<dt>Define scenarios</dt><dd>List specific conditions the AI
must handle, like “Contact Not Found,” “User Provided Invalid Date,” or
“Multiple Contacts Found.”</dd>
<dt>Create a matrix or table</dt><dd>Use a visual aid to map
out categories and scenarios for quick reference.</dd>
</dl>
<p><a data-type="xref" href="#table0801">Table 8-1</a> shows an example of a matrix of features and scenarios that you
might use to categorize interactions with an AI.</p>

<table id="table0801">
<caption><span class="label">Table 8-1. </span>Example features and scenarios matrix</caption>

<thead>
<tr class="header">
<th>Feature</th>
<th>Scenario</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Contact Search</strong></td>
<td>Contact Found</td>
<td>Successfully retrieved the correct contact information.</td>
</tr>
<tr class="even">
<td><strong>Contact Search</strong></td>
<td>Contact Not Found</td>
<td>No matching contact; AI should suggest creating a new contact or
check for typos.</td>
</tr>
<tr class="odd">
<td><strong>Contact Search</strong></td>
<td>Multiple Contacts Found</td>
<td>Multiple contacts match the query; AI should present options for the
user to select.</td>
</tr>
<tr class="even">
<td><strong>Email Writing</strong></td>
<td>Successful Send</td>
<td>Email drafted and sent without issues.</td>
</tr>
<tr class="odd">
<td><strong>Email Writing</strong></td>
<td>Formatting Errors</td>
<td>Issues with email layout, style, or inserted errors by nonnative
speakers worsening content.</td>
</tr>
<tr class="even">
<td><strong>Scheduling</strong></td>
<td>Successful Booking</td>
<td>Meeting scheduled correctly with all details accurate.</td>
</tr>
<tr class="odd">
<td><strong>Scheduling</strong></td>
<td>Invalid Date Input</td>
<td>User provides an invalid date; AI should recognize and prompt for
correction.</td>
</tr>
<tr class="even">
<td><strong>Scheduling</strong></td>
<td>Conflicting Appointments</td>
<td>Scheduling conflicts detected; AI should notify user and suggest
alternatives.</td>
</tr>
<tr class="odd">
<td><strong>Data Entry</strong></td>
<td>Error Handling</td>
<td>AI encounters errors during data input; should provide clear
guidance to the user.</td>
</tr>
<tr class="even">
<td><strong>General Query</strong></td>
<td>Unhandled Questions</td>
<td>AI doesn’t understand the query; should ask for clarification or
redirect appropriately.</td>
</tr>
</tbody>
</table>

<p><a data-type="xref" href="#table0802">Table 8-2</a> shows an example of applying the previous matrix to actual data.</p>


<table id="table0802">
<caption><span class="label">Table 8-2. </span>Example data with features and scenario grouping applied</caption>

<thead>
<tr class="header">
<th>Interaction ID</th>
<th>Feature</th>
<th>Scenario</th>
<th>User query</th>
<th>AI response</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>001</td>
<td>Contact Search</td>
<td>Contact Not Found</td>
<td>“Find John’s contact info.”</td>
<td>“No contact found for ‘John’. Would you like to create a new
contact?”</td>
</tr>
<tr class="even">
<td>002</td>
<td>Scheduling</td>
<td>User Provided Invalid Date</td>
<td>“Schedule a meeting on April 31st.”</td>
<td>“April has only 30 days. Please provide a valid date.”</td>
</tr>
<tr class="odd">
<td>003</td>
<td>Scheduling</td>
<td>User Provided Time in the Past</td>
<td>“Set up a call yesterday at 3 PM.”</td>
<td>“Cannot schedule meetings in the past. Please choose a future
time.”</td>
</tr>
<tr class="even">
<td>004</td>
<td>Contact Search</td>
<td>Multiple Contacts Found</td>
<td>“Get Alex’s email address.”</td>
<td>“Multiple contacts named ‘Alex’ found: Alex Smith, Alex Johnson.
Please specify.”</td>
</tr>
<tr class="odd">
<td>005</td>
<td>Scheduling</td>
<td>Conflict with Existing Event</td>
<td>“Book a meeting with Mark at 2 PM tomorrow.”</td>
<td>“You already have a meeting scheduled at 2 PM tomorrow. Would you
like to reschedule?”</td>
</tr>
<tr class="even">
<td>006</td>
<td>Email Writing</td>
<td>Attachment Missing</td>
<td>“Send the report to the team.”</td>
<td>“Please attach the report file before sending the email.”</td>
</tr>
<tr class="odd">
<td>007</td>
<td>Data Entry</td>
<td>Invalid Input Format</td>
<td>“Update sales figures to ‘ten thousand’.”</td>
<td>“Please provide the sales figures in numeric format.”</td>
</tr>
<tr class="even">
<td>008</td>
<td>Contact Search</td>
<td>User Provided Incomplete Info</td>
<td>“Find contact with phone number 555-1234.”</td>
<td>“Multiple contacts have that number. Can you provide a name?”</td>
</tr>
<tr class="odd">
<td>009</td>
<td>General Query</td>
<td>Unhandled Question</td>
<td>“What’s the weather today?”</td>
<td>“I’m sorry, but I cannot provide weather information.”</td>
</tr>
</tbody>
</table>
<p>Here is a more detailed explanation of this table’s updated scenarios:</p>

<dl>
<dt><strong>Contact Search</strong></dt>
<dd><dl>
<dt>Contact Not Found</dt><dd>The user searches for a
contact that doesn’t exist in the system.</dd>
<dt>Multiple Contacts Found</dt><dd>The search query
matches more than one contact, requiring user clarification.</dd>
<dt>User Provided Incomplete Info</dt><dd>Insufficient
details are provided to uniquely identify a contact.</dd>
</dl></dd>
<dt><strong>Scheduling</strong></dt><dd>
<dl>
<dt>User Provided Invalid Date</dt><dd>The user specifies a
date that doesn’t exist, such as “April 31st”.</dd>
<dt>User Provided Time in the Past</dt><dd>The user attempts
to schedule an event in the past.</dd>
<dt>Conflict with Existing Event</dt><dd>The requested time
slot conflicts with another event on the user’s calendar.</dd>
</dl></dd>
<dt><strong>Email Writing</strong></dt><dd>
<dl>
<dt>Attachment Missing</dt><dd>The user mentions an attachment
but doesn’t include it; the AI should prompt for it.</dd>
</dl></dd>
<dt><strong>Data Entry</strong></dt><dd>
<dl>
<dt>Invalid Input Format</dt><dd>The user provides data in an
incorrect format; the AI should request proper formatting.</dd>
</dl></dd>
<dt><strong>General Query</strong></dt><dd>
<dl>
<dt>Unhandled Question</dt><dd>The AI receives a query outside
its capabilities and should gracefully inform the user.</dd>
</dl></dd>
</dl>

<div data-type="tip"><h6>Tip</h6>
<p>The examples above illustrate the AI doing the right thing. The point
of this example is to show example categories and scenarios, rather than
show you examples of AI failures.</p>
</div>

</div></section>

<section data-type="sect2" class="pagebreak-before" data-pdf-bookmark="Tips for Effective Categorization"><div class="sect2" id="id108">
<h2 class="less_space">Tips for Effective Categorization</h2>
<p>Here are ways to make sure your categories are effective:</p>
<dl>
<dt>Use specific scenarios</dt><dd>Clearly define conditions
that the AI must handle, which helps in assessing its performance in
various situations. By fleshing out these scenarios, you can pinpoint
areas for improvement and ensure that the AI responds appropriately to
user needs.</dd>
<dt>Reflect real user behavior</dt><dd>Include scenarios that
represent common user mistakes or <span class="keep-together">challenges</span>.</dd>
<dt>Use color coding</dt><dd>Assign colors to different
scenarios for quicker visual scanning.</dd>
<dt>Leverage filters</dt><dd>If you’re ‘using a spreadsheet or data
viewer, use filter functions to focus on specific scenarios or
features.</dd>
<dt>Update regularly</dt><dd>As new features are added or
scenarios emerge, update your categories to keep them relevant.</dd>
</dl>
</div></section>

</div></section>

<section data-type="sect1" data-pdf-bookmark="Step 4: Conduct Binary Evaluations"><div class="sect1" id="id109">
<h1>Step 4: Conduct Binary Evaluations</h1>


<p>Simplifying your evaluation to a Yes or No question—“Did the AI solve
the customer’s problem?”—helps you make quick, decisive assessments
without getting bogged down in complexity.</p>



<section data-type="sect2" data-pdf-bookmark="Actions"><div class="sect2" id="id110">
<h2>Actions</h2>
<dl>
<dt>Ask the key question</dt><dd>For each interaction,
determine whether the AI met the user’s needs.</dd>
<dt>Avoid complex scoring systems</dt><dd>Resist the urge to
rate on a scale; keep it simple to maintain consistency.</dd>
<dt>Document your decision</dt><dd>Clearly mark each
interaction as a success or failure.</dd>
</dl>
</div></section>


<section data-type="sect2" data-pdf-bookmark="Tips for Effective Binary Evaluations"><div class="sect2" id="id111">
<h2>Tips for Effective Binary Evaluations</h2>

<p>Simplifying your evaluation to a Yes or No question can be difficult at first. Here are some tips to help you get started:</p>
<dl>
<dt>Consistency is key</dt><dd>Use the same criteria for each
evaluation to ensure fairness and reliability.</dd>
<dt>Trust your instincts</dt><dd>Your business acumen is
valuable—don’t second-guess your initial judgment.</dd>
<dt>Note ambiguities</dt><dd>If an interaction isn’t a clear
Yes or No, make a note and consider discussing it with your team for
clarity.</dd>
</dl>
</div></section>

</div></section>

<section data-type="sect1" data-pdf-bookmark="Step 5: Write Constructive Critiques"><div class="sect1" id="id112">
<h1>Step 5: Write Constructive Critiques</h1>

<p>Detailed, actionable feedback is essential for improving your AI
system. Think of it as coaching an employee—the more specific you are,
the better the AI can become.</p>



<section data-type="sect2" data-pdf-bookmark="Actions"><div class="sect2" id="id113">
<h2>Actions</h2>
<dl>
<dt>Frame feedback as instructions</dt><dd>Write critiques as
if you’re guiding a new team member on how to improve.</dd>
<dt>Be specific</dt><dd>Point out exactly what went wrong, and
suggest how it could be corrected.</dd>
<dt>Highlight positive outcomes</dt><dd>Occasionally note why
certain interactions were successful to reinforce good performance.</dd>
</dl>
</div></section>

<section data-type="sect2" class="pagebreak-before" data-pdf-bookmark="Example Critiques"><div class="sect2" id="id114">
<h2 class="less_space">Example Critiques</h2>
<p><a data-type="xref" href="#table0803">Table 8-3</a> contains an example of a data review log with detailed critiques that
you might write.</p>

<table class="striped" id="table0803">
<caption><span class="label">Table 8-3. </span>Example critiques</caption>

<thead>
<tr class="header">
<th>Date</th>
<th>ID</th>
<th>Feature</th>
<th>Scenario</th>
<th>Problem solved? (Y/N)</th>
<th>Critique</th>
<th>Metrics aligned? (Y/N)</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2023-10-11</td>
<td>005</td>
<td>Contact Search</td>
<td>Multiple Contacts Found</td>
<td>N</td>
<td><strong>Critique</strong>: “When the user searched for ‘Alex’, the
AI found multiple contacts, named ‘Alex Johnson’ and ‘Alex Smith’, but did
not prompt the user to select the correct one. Next time, please display
the list of matching contacts and ask the user to choose one.”</td>
<td>N</td>
<td>Discuss with team</td>
</tr>
<tr class="even">
<td>2023-10-11</td>
<td>006</td>
<td>Scheduling</td>
<td>Invalid Date Input</td>
<td>N</td>
<td><strong>Critique</strong>: “The user tried to schedule a meeting on
‘February 30th’, which is an invalid date. The AI should recognize this
and inform the user that the date doesn’t exist, then prompt them to
provide a valid date for scheduling.”</td>
<td>Y</td>
<td>Improvement needed</td>
</tr>
<tr class="odd">
<td>2023-10-11</td>
<td>007</td>
<td>Email Writing</td>
<td>Edits Worsening Content</td>
<td>N</td>
<td><strong>Critique</strong>: “After drafting an email, the AI accepted
user edits that introduced grammatical errors and unclear phrasing. The
AI should assist users by suggesting corrections to maintain
professionalism and clarity in communications, especially when edits
reduce quality.”</td>
<td>N</td>
<td>Needs attention</td>
</tr>
<tr class="even">
<td>2023-10-11</td>
<td>008</td>
<td>Data Entry</td>
<td>Error Handling</td>
<td>N</td>
<td><strong>Critique</strong>: “The AI encountered an error when
updating sales figures but only displayed a generic error message. It
should provide specific details about the error and guide the user on
how to correct the input or whom to contact for support.”</td>
<td>Y</td>
<td>Error specifics</td>
</tr>
<tr class="odd">
<td>2023-10-11</td>
<td>009</td>
<td>General Query</td>
<td>Unhandled Questions</td>
<td>N</td>
<td><strong>Critique</strong>: “The user asked for ‘company’s quarterly
revenue growth’, but the AI responded with ‘I can’t assist with that
request.’ Instead, the AI should recognize this as a request for
financial data and either provide the information or guide the user to
the appropriate resource.”</td>
<td>N</td>
<td>Expand knowledge</td>
</tr>
<tr class="even">
<td>2023-10-11</td>
<td>010</td>
<td>Scheduling</td>
<td>Conflicting Appointments</td>
<td>N</td>
<td><strong>Critique</strong>: “When scheduling a meeting at 3 PM on
Thursday, the AI didn’t alert the user of an existing appointment at
that time. The AI should check the user’s calendar for conflicts and
suggest alternative times if necessary.”</td>
<td>N</td>
<td>Calendar sync needed</td>
</tr>
<tr class="odd">
<td>2023-10-11</td>
<td>011</td>
<td>Contact Search</td>
<td>Contact Not Found</td>
<td>Y</td>
<td><strong>Praise</strong>: “Good job informing the user that ‘Emma
Thompson’ was not found and offering to create a new contact. This helps
keep contact lists up-to-date and assists the user efficiently.”</td>
<td>Y</td>
<td>Positive example</td>
</tr>
</tbody>
</table>

<p>Here is further explanation of this table’s critiques:</p>


<dl>
<dt>Interaction ID 005</dt><dd>The AI failed to handle a situation with
multiple contacts. The critique guides the AI to prompt the user for
selection next time.</dd>
<dt>Interaction ID 006</dt><dd>The AI didn’t recognize an invalid date. The
critique instructs the AI to validate dates and provide corrective
prompts.</dd>
<dt>Interaction ID 007</dt><dd>The AI allowed edits that worsened the
content. The critique emphasizes maintaining communication quality and
suggests proactive assistance.</dd>
<dt>Interaction ID 008</dt><dd>The AI’s error handling was insufficiently
informative. The critique advises providing specific error details and
user guidance.</dd>
<dt>Interaction ID 009</dt><dd>The AI didn’t handle a general query
appropriately. The critique encourages expanding the AI’s knowledge base
or redirecting the user effectively.</dd>
<dt>Interaction ID 010</dt><dd>The AI missed a scheduling conflict. The
critique suggests implementing calendar checks and conflict
notifications.</dd>
<dt>Interaction ID 011</dt><dd>Highlighting successful interactions
reinforces good practices and provides models for desired AI behavior.
However, you should focus your critiques more on failures.</dd>
</dl>

<div data-type="tip"><h6>Tip</h6>
<p><a data-type="xref" href="#table0803">Table 8-3</a> contains a column named “Metrics aligned? (Y/N)”. We
will discuss metrics in the next step.</p>
</div>

</div></section>

<section data-type="sect2" data-pdf-bookmark="Tips for Writing Constructive Critiques"><div class="sect2" id="id115">
<h2>Tips for Writing Constructive Critiques</h2>
<p>Here are some ways to maximize the impact of your critiques:</p>
<dl>
<dt>Use clear language</dt><dd>Avoid technical jargon; focus
on the user experience.</dd>
<dt>Be objective</dt><dd>Focus on the interaction, not the
technology behind it.</dd>
<dt>Prioritize impact</dt><dd>Spend more time on critiques
that could significantly improve user satisfaction or business
outcomes.</dd>
</dl>
</div></section>

</div></section>

<section data-type="sect1" data-pdf-bookmark="Step 6: Cross-Reference Metrics"><div class="sect1" id="id116">
<h1>Step 6: Cross-Reference Metrics</h1>

<p>Metrics are only valuable if they align with real-world outcomes. By
comparing your evaluations with the associated metrics, you ensure that
your team measures what truly matters.</p>


<section data-type="sect2" data-pdf-bookmark="Actions"><div class="sect2" id="id117">
<h2>Actions</h2>
<dl>
<dt>Compare evaluations with metrics</dt><dd>For each
interaction, look at the metrics your team has <span class="keep-together">recorded</span>.</dd>
<dt>Sanity-check the metrics</dt><dd>Ask yourself whether the
metrics accurately reflect the success or failure of the
interaction.</dd>
<dt>Provide feedback on metrics</dt><dd>If you notice
discrepancies, discuss them with your team to refine the measurement
approaches.</dd>
</dl>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Example"><div class="sect2" id="id118">
<h2>Example</h2>
<ul>
<li><em>Interaction ID</em>: 003</li>
<li><em>Your Evaluation</em>: Problem Not Solved</li>
<li><em>Metric Reported</em>: Success (Score of 90%)</li>
<li><em>Discrepancy</em>: “The AI didn’t recognize an invalid
date, but the metric indicates a high success rate. This suggests the
metric isn’t capturing date validation errors.”</li>
</ul>
</div></section>

<section data-type="sect2" data-pdf-bookmark="Tips on Cross-Referencing Metrics"><div class="sect2" id="id119">
<h2>Tips on Cross-Referencing Metrics</h2>
<p>Here are some tactics to make sure the metrics are aligned with the data you are reviewing:</p>
<dl>
<dt>Understand key metrics</dt><dd>Familiarize yourself with
the metrics your team uses to evaluate AI.</dd>
<dt>Look for patterns</dt><dd>If certain metrics misalign with
your evaluations, it indicates a need for metric refinement.</dd>
<dt>Collaborate on solutions</dt><dd>Work with your team to
adjust metrics to better align with user satisfaction and business
goals.</dd>
</dl>
</div></section>

</div></section>

<section data-type="sect1" data-pdf-bookmark="Step 7: Share Insights and Lead by Example"><div class="sect1" id="id120">
<h1>Step 7: Share Insights and Lead by Example</h1>

<p>Your active involvement signals to your team the importance of data
review and continuous improvement. It fosters a culture where everyone
is engaged in improving AI performance.</p>


<section data-type="sect2" data-pdf-bookmark="Actions"><div class="sect2" id="id121">
<h2>Actions</h2>
<dl>
<dt>Share your findings</dt><dd>Present interesting insights
or issues during team meetings or via email updates.</dd>
<dt>Encourage open dialogue</dt><dd>Invite team members to
discuss their observations and <span class="keep-together">suggestions</span>.</dd>
<dt>Celebrate successes and learn from failures</dt><dd>Acknowledge both the AI’s strengths and areas for <span class="keep-together">improvement</span>.</dd>
</dl>
</div></section>


<section data-type="sect2" data-pdf-bookmark="Getting Your Team Onboard With Data Review"><div class="sect2" id="id122">
<h2>Getting Your Team Onboard With Data Review</h2>
<p>Here are simple steps you can take to make sure your team incorporates data review into their work:</p>
<dl>
<dt>Lead by example</dt><dd>Your commitment will inspire
others to take data review <span class="keep-together">seriously</span>.</dd>
<dt>Create a feedback loop</dt><dd>Establish regular meetings
or channels where data review insights can be shared and acted
upon.</dd>
<dt>Recognize contributions</dt><dd>Highlight team members who
make significant improvements based on data review.</dd>
</dl>

</div></section>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Recap of the Process"><div class="sect1" id="id123">
<h1>Recap of the Process</h1>

<p><a data-type="xref" href="#fig0802">Figure 8-2</a> is a flowchart that summarizes the data review process.</p>

<figure><div id="fig0802" class="figure">
<img src="assets/aete_08in02.png" alt="" width="914" height="1943"/>
<h6><span class="label">Figure 8-2. </span>The data review process</h6>
</div></figure>


<p class="pagebreak-before">Here is further explanation of the flowchart:</p>

<dl>
<dt>Start daily data review</dt><dd><p>Begin your dedicated
time for reviewing AI interactions.</p></dd>
<dt>Access user-centric data viewer</dt><dd><p>Use the tool
that mirrors the user experience to view AI interactions without
technical distractions.</p></dd>
<dt>Select interactions to review</dt><dd><p>Choose a mix of
interactions, focusing on failure modes and challenging
scenarios.</p></dd>
<dt>View interactions in user interface</dt><dd><p>Examine the
AI’s behavior as the user sees it, within the actual user
interface.</p></dd>
<dt>Conduct binary evaluation</dt><dd><p>Determine if the AI
solved the user’s problem (Yes/No).</p></dd>
<dt>Problem solved?</dt><dd>
<ul>
<li><p><em>Yes</em>: Note the success and consider what worked
well.</p></li>
<li><p><em>No</em>: Write a detailed critique as if coaching a
new employee.</p></li>
</ul></dd>
<dt>Cross-reference with metrics</dt><dd><p>Compare your
evaluation with the team’s metrics for that <span class="keep-together">interaction</span>.</p></dd>
<dt>Metrics align?</dt><dd>
<ul>
<li><p><em>Yes</em>: Proceed to the next interaction.</p></li>
<li><p><em>No</em>: Provide feedback to the team about
discrepancies.</p></li>
</ul></dd>
<dt>Identify patterns and insights</dt><dd><p>Look for
recurring issues or successes to understand broader trends.</p></dd>
<dt>Share findings with team</dt><dd><p>Communicate your
insights, fostering collaboration and continuous improvement.</p></dd>
<dt>End daily review</dt><dd><p>Conclude your session,
confident that you’ve contributed valuable feedback.</p></dd>
</dl>

</div></section>

<section data-type="sect1" data-pdf-bookmark="Common Pitfalls to Avoid"><div class="sect1" id="id124">
<h1>Common Pitfalls to Avoid</h1>

<p>Getting this process right takes time and practice. Here are some
common pitfalls to avoid:</p>
<table>
<thead>
<tr class="header">
<th>Pitfall</th>
<th>Issue</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1. Relying solely on technical tools</td>
<td>Observability platforms and technical logs are designed for
engineers and can be overwhelming.</td>
<td>Use a user-centric data viewer that presents interactions as
customers experience them.</td>
</tr>
<tr class="even">
<td>2. Avoiding data review due to friction</td>
<td>Complexity and technical barriers can discourage regular data
review.</td>
<td>Simplify the process with easy-to-access tools and a streamlined
workflow.</td>
</tr>
<tr class="odd">
<td>3. Trying to outsource data review</td>
<td>Delegating this task entirely to others or relying on AI to review
AI can miss critical insights.</td>
<td>Personally engage in data review to leverage your unique
perspective.</td>
</tr>
<tr class="even">
<td>4. Overcomplicating evaluations</td>
<td>Using complex scoring systems can create inconsistency and
confusion.</td>
<td>Stick to a simple Yes or No evaluation to maintain clarity.</td>
</tr>
<tr class="odd">
<td>5. Ignoring failure modes</td>
<td>Focusing only on successes doesn’t address areas needing
improvement.</td>
<td>Prioritize reviewing and critiquing interactions where the AI failed
to meet expectations.</td>
</tr>
<tr class="even">
<td>6. Not providing specific feedback</td>
<td>Vague critiques are less actionable and don’t guide
improvement.</td>
<td>Offer detailed, specific feedback as you would to a human
employee.</td>
</tr>
</tbody>
</table>

</div></section>

 <section data-type="sect1" data-pdf-bookmark="Best Practices for Effective Data Review"><div class="sect1" id="id125">
<h1>Best Practices for Effective Data Review</h1>

<p>In addition to common pitfalls, here are some best practices to
follow:</p>
<dl>
<dt>Stay user-focused</dt><dd>Always consider interactions
from the user’s perspective.</dd>
<dt>Be consistent</dt><dd>Regular reviews yield better
insights over time.</dd>
<dt>Collaborate with your team</dt><dd>Use your findings to
guide team efforts and improvements.</dd>
</dl>

</div></section>

<section data-type="sect1" class="pagebreak-before" data-pdf-bookmark="Conclusion"><div class="sect1" id="id126">
<h1 class="less_space">Conclusion</h1>
<p>Embracing a hands-on approach to AI data review empowers you to:</p>
<dl>
<dt>Align AI performance with business goals</dt><dd>Ensure
your AI systems are meeting the needs of your customers and representing
your brand effectively.</dd>
<dt>Enhance AI capabilities</dt><dd>Your feedback directly
contributes to improving the AI, much like mentoring a high-potential
employee.</dd>
<dt>Lead by example</dt><dd>Foster a culture of continuous
improvement within your team.</dd>
<dt>Inform strategy</dt><dd>Use data review insights to shape
AI strategy and priorities.</dd>
</dl>
<p>By integrating this data review process into your routine, you’re not
just overseeing an AI system—you’re actively shaping a powerful tool
that can significantly enhance your organization’s performance. Your
hands-on involvement ensures that the AI aligns with your vision and
delivers genuine value to your customers.</p>
<p>Remember, your AI is like a super-employee capable of exponential
impact. Investing time in its development and alignment is not just
beneficial—it’s essential.</p>
</div></section>

<div data-type="footnotes"><p data-type="footnote" id="id132"><sup><a href="ch08.html#id132-marker">1</a></sup> From my blog post, <a href="https://hamel.dev/blog/posts/evals">“Your AI Product Needs Evals”</a>.</p></div></div></section></div>
</div>
</body></html>