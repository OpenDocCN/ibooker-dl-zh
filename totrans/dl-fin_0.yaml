- en: Chapter 1\. Introducing Data Science and Trading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The best way to begin learning about complex topics is to slowly build up momentum
    until you start completing the puzzle. Understanding deep learning for finance
    requires a certain knowledge in basic and intermediate data science topics as
    well as financial markets and their structure.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter lays the building blocks needed to have a thorough understanding
    of data science and its uses, but also of financial markets and how trading and
    forecasting can benefit from data science.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of the chapter, you should know what data science is, what its applications
    are, and how you can use it in finance to extract value.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Data
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is impossible to understand the field of data science without understanding
    the types and structures of data first. After all, the first word for the name
    of this immense field is *data*. So what is data? And more importantly, what can
    you do with it?
  prefs: []
  type: TYPE_NORMAL
- en: '*Data* in its simplest and purest form is a collection of raw information that
    can be of any type (numerical, text, boolean, etc.).'
  prefs: []
  type: TYPE_NORMAL
- en: The final aim of collecting data is decision-making. This is done through a
    complex process which ranges from the act of gathering and processing data to
    interpreting it and using the results to make a decision.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take an example of using data to make a decision. Suppose you have a portfolio
    composed of five different equal-weighted dividend-paying stocks as detailed in
    table 1-1.
  prefs: []
  type: TYPE_NORMAL
- en: Table 1-1\. Dividend table
  prefs: []
  type: TYPE_NORMAL
- en: '| Stock | Dividend yield |'
  prefs: []
  type: TYPE_TB
- en: '| A | 5.20% |'
  prefs: []
  type: TYPE_TB
- en: '| B | 3.99% |'
  prefs: []
  type: TYPE_TB
- en: '| C | 4.12% |'
  prefs: []
  type: TYPE_TB
- en: '| D | 6.94% |'
  prefs: []
  type: TYPE_TB
- en: '| E | 5.55% |'
  prefs: []
  type: TYPE_TB
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: A *dividend* is the payment made to shareholders from a company’s profits. The
    *dividend yield* is the amount distributed in monetary units over the current
    share price of the company.
  prefs: []
  type: TYPE_NORMAL
- en: 'Analyzing this data can help you understand the average dividend yield you
    are receiving from your portfolio. The average is basically the sum divided by
    the quantity, and it gives a quick snapshot of the overall dividend yield of the
    portfolio:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper A v e r a g e d i v i d e n d y i e l d equals StartFraction
    5.20 percent-sign plus 3.99 percent-sign plus 4.12 percent-sign plus 6.94 percent-sign
    plus 5.55 percent-sign Over 5 EndFraction equals 5.16 percent-sign"><mrow><mi>A</mi>
    <mi>v</mi> <mi>e</mi> <mi>r</mi> <mi>a</mi> <mi>g</mi> <mi>e</mi> <mi>d</mi> <mi>i</mi>
    <mi>v</mi> <mi>i</mi> <mi>d</mi> <mi>e</mi> <mi>n</mi> <mi>d</mi> <mi>y</mi> <mi>i</mi>
    <mi>e</mi> <mi>l</mi> <mi>d</mi> <mo>=</mo> <mfrac><mrow><mn>5</mn><mo>.</mo><mn>20</mn><mo>%</mo><mo>+</mo><mn>3</mn><mo>.</mo><mn>99</mn><mo>%</mo><mo>+</mo><mn>4</mn><mo>.</mo><mn>12</mn><mo>%</mo><mo>+</mo><mn>6</mn><mo>.</mo><mn>94</mn><mo>%</mo><mo>+</mo><mn>5</mn><mo>.</mo><mn>55</mn><mo>%</mo></mrow>
    <mn>5</mn></mfrac> <mo>=</mo> <mn>5</mn> <mo>.</mo> <mn>16</mn> <mo>%</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the average dividend yield of your portfolio is 5.16%. This information
    can help you compare your average dividend yield to other portfolios so that you
    know if you have to make any adjustments.
  prefs: []
  type: TYPE_NORMAL
- en: Another metric you can calculate is the number of stocks held in the portfolio.
    This may provide a first information brick in constructing a wall of diversification.
    Even though these two pieces of information (average dividend yield and the number
    of stocks in the portfolio) are very simple, complex data analysis begins with
    simple metrics and may sometimes not require sophisticated models to properly
    interpret the on-going events.
  prefs: []
  type: TYPE_NORMAL
- en: The two metrics you have calculated in the previous example are called the *average*
    (or mean) and the *count* (or number of elements). They are also part of a field
    called *descriptive statistics* which is also itself part of data science.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take another example of data analysis for inferential purposes. Suppose
    you have calculated a yearly correlation measure between two currency pairs and
    you want to predict whether the next yearly correlation will be positive or negative.
    Table 1-2 has the details of the calculations.
  prefs: []
  type: TYPE_NORMAL
- en: Table 1-2\. Correlation table
  prefs: []
  type: TYPE_NORMAL
- en: '| Year | Correlation |'
  prefs: []
  type: TYPE_TB
- en: '| 2015 | Positive |'
  prefs: []
  type: TYPE_TB
- en: '| 2016 | Positive |'
  prefs: []
  type: TYPE_TB
- en: '| 2017 | Positive |'
  prefs: []
  type: TYPE_TB
- en: '| 2018 | Negative |'
  prefs: []
  type: TYPE_TB
- en: '| 2019 | Positive |'
  prefs: []
  type: TYPE_TB
- en: '| 2020 | Positive |'
  prefs: []
  type: TYPE_TB
- en: '| 2021 | Positive |'
  prefs: []
  type: TYPE_TB
- en: '| 2022 | Positive |'
  prefs: []
  type: TYPE_TB
- en: '| 2023 | Positive |'
  prefs: []
  type: TYPE_TB
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '*Correlation* is a measure of the linear reliance between two time series.
    A *positive correlation* generally means that the two time series move on average
    in the same direction, while a *negative correlation* generally means that the
    two time series move on average in opposite directions.'
  prefs: []
  type: TYPE_NORMAL
- en: 'From table 1-2, the historical correlations between the two currency pairs
    were mostly positive with around 88% of the time. Taking into account historical
    observations, you can say that there is an 88% probability that the next correlation
    measure will be positive. This also means that there is a 12% probability that
    the next correlation measure will be negative:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper E left-parenthesis upper P o s i t i v e c o r r e l a
    t i o n right-parenthesis equals eight-ninths equals 88.88 percent-sign"><mrow><mi>E</mi>
    <mrow><mo>(</mo> <mi>P</mi> <mi>o</mi> <mi>s</mi> <mi>i</mi> <mi>t</mi> <mi>i</mi>
    <mi>v</mi> <mi>e</mi> <mi>c</mi> <mi>o</mi> <mi>r</mi> <mi>r</mi> <mi>e</mi> <mi>l</mi>
    <mi>a</mi> <mi>t</mi> <mi>i</mi> <mi>o</mi> <mi>n</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mfrac><mn>8</mn> <mn>9</mn></mfrac> <mo>=</mo> <mn>88</mn> <mo>.</mo> <mn>88</mn>
    <mo>%</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This is another simplistic example of how to use data to infer observations
    and make decisions. Of course, the assumption here is that historical results
    reflect exactly the future results, which is unlikely in real life, but occasionally,
    to predict the future, all you have is the past.
  prefs: []
  type: TYPE_NORMAL
- en: Now, before discussing data science, let’s review what types of data there can
    be and segment them into different groups.
  prefs: []
  type: TYPE_NORMAL
- en: '*Numerical data*'
  prefs: []
  type: TYPE_NORMAL
- en: This type of data is composed of numbers that reflect a certain type of information
    that is collected at regular or irregular intervals. Examples can include market
    data (OHLC^([1](ch01.xhtml#idm46147473036608)), volume, spread, etc.) and financial
    statements data (assets, revenue, costs, etc.).
  prefs: []
  type: TYPE_NORMAL
- en: '*Categorical data*'
  prefs: []
  type: TYPE_NORMAL
- en: Data that can be organized into groups or categories using names or labels.
    It is qualitative rather than quantitative. For example, the blood type of patients
    is a type of categorical data.
  prefs: []
  type: TYPE_NORMAL
- en: '*Text data*'
  prefs: []
  type: TYPE_NORMAL
- en: Text data is on the rise during the recent years with the development of *natural
    language processing* (NLP). Machine learning models use text data to translate,
    interpret, and analyze the sentiment of the text. Furthermore, you can even use
    the models to create an algorithm that outputs structured paragraphs.
  prefs: []
  type: TYPE_NORMAL
- en: Visual data
  prefs: []
  type: TYPE_NORMAL
- en: Images and videos are also considered data, and you can process and transform
    them into valuable information. For example, a *convolutional neural network* (CNN)
    is a type of algorithm that can recognize and categorize photos by labels (for
    example, labeling cat photos as cats).
  prefs: []
  type: TYPE_NORMAL
- en: Audio data
  prefs: []
  type: TYPE_NORMAL
- en: Audio data is very valuable and can help save time on transcriptions. For example,
    you can use algorithms on audio to create captions and automatic subtitles. You
    can also create models that interpret the sentiment of the speaker using the tone
    and the volume.
  prefs: []
  type: TYPE_NORMAL
- en: 'You are likely to encounter the following data when dealing with Python:'
  prefs: []
  type: TYPE_NORMAL
- en: Integers
  prefs: []
  type: TYPE_NORMAL
- en: These are whole numbers, which can be either positive or negative. Examples
    are −8 and 745\. They are, however, limited to between −2147483648 and 2147483647.
  prefs: []
  type: TYPE_NORMAL
- en: Floats
  prefs: []
  type: TYPE_NORMAL
- en: These are real numbers with decimal points such as 18.54 and 311.52.
  prefs: []
  type: TYPE_NORMAL
- en: Strings
  prefs: []
  type: TYPE_NORMAL
- en: These are words stored in a variable. More scientifically, they are a set of
    structured characters (text). In Python, you write strings between single or double
    quotes.
  prefs: []
  type: TYPE_NORMAL
- en: Boolean
  prefs: []
  type: TYPE_NORMAL
- en: These are true or false statements to evaluate a condition.
  prefs: []
  type: TYPE_NORMAL
- en: '*Data science* is an transdisciplinary field that tries to extract intelligence
    and conclusions from data using different techniques and models, be they simple
    or complex. The process of data science is composed of many phases besides to
    just analyzing data. The following summarizes the different stages of data science:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Data gathering*: This process involves the acquisition of data from reliable
    and accurate sources. A widely known quote in computer science generally credited
    to George Fueschel goes as follows "*Garbage in, garbage out*“, and it sums up
    the need to have quality data that you can rely on for proper analysis. Basically,
    if you have inaccurate or faulty data, then all your process would be invalid
    and it would be waste of time.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Data preprocessing*: Occasionally, when you acquire data, it can be in a raw
    form that needs preparation for the data science models in the data analysis step
    to come. For example, dropping some unnecessary data, handling missing data, or
    eliminating invalid and duplicate data are part of the preprocessing phase. Other
    more complex examples can include *normalization* and *denoising* of data. The
    aim of this step is to get the data ready for analysis.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Data exploration*: This is the first step in data analysis, and it is a basic
    statistical exploration in order to find trends and different properties so that
    you have a preliminary idea on the expected behavior. One example is to check
    for data stationarity, a concept discussed in detail throughout the book.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Data visualization*: This is an important step that is an add-on to the previous
    step. It includes creating visualizations such as histograms and heatmaps to help
    identify patterns and trends and make the interpretation easier.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Data analysis*: This is the long-awaited step which is basically the main
    focus of the data science process. This is where you *fit* the data using different
    learning models so that they interpret and predict the future outcome based on
    the given parameters.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Data interpretation*: This phase deals with the feedback and conclusions after
    the models have performed their jobs. *Optimization* may also be a part of this
    phase which then loops back to phase 5 in order to run the models again with the
    updated parameters before interpreting them again and evaluating the performance.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: To sum up the previous points, data science comprises many steps that start
    with acquiring the data through interpreting and optimizing the models that predict
    the future values of the data.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take a simple example in Python that applies the data science process
    discussed in the previous six steps. Suppose you want to analyze and predict the
    VIX, a volatility time series indicator published by the CBOE on a daily basis.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: There is a hidden step that I refer to as *step zero* which is the idea and
    the intuition for the whole process. You wouldn’t be applying the process if you
    didn’t have a motive first. For example, believing that inflation numbers may
    drive the returns of certain commodities is an idea and a motive to start exploring
    the data in search for real numbers that prove this hypothesis.
  prefs: []
  type: TYPE_NORMAL
- en: The first step is data gathering, which in this case can be automated using
    Python. The next code block connects to the website of the Federal Reserve of
    Saint Louis and downloads the historical data of the VIX between January 1990
    and January 2023.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The *VIX* stands for the *volatility index* and it represents the implied volatility
    of the S&P 500 index. It has been available since 1993 and is issued by the Chicago
    Board Options Exchange (CBOE).
  prefs: []
  type: TYPE_NORMAL
- en: Because it is meant to measure the level of fear or uncertainty in the stock
    market, the VIX is frequently referred to as the *fear index*. The index is a
    percentage and is computed using the pricing of options on the S&P 500 index.
    A higher VIX value correlates with a greater market turbulence and uncertainty,
    whereas a lower value correlates with greater stability on average.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that Chapter 3 is entirely dedicated into introducing Python and harnessing
    its power. For the moment, you do not have to understand the code as it is not
    yet the learning outcome:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The code uses the `pandas` library to import the `DataReader` function, which
    fetches historical data online from a variety of sources such as Yfinance and
    Fred. The `DataReader` function takes the name of the data as a first argument,
    followed by the source, and the dates. The output of `print(vix.tail())`is shown
    in table 1-3:'
  prefs: []
  type: TYPE_NORMAL
- en: Table 1-3\. Output of the code
  prefs: []
  type: TYPE_NORMAL
- en: '| DATE            VIXCLS   |'
  prefs: []
  type: TYPE_TB
- en: '| 2023-01-17   19.36 |'
  prefs: []
  type: TYPE_TB
- en: '| 2023-01-18   20.34 |'
  prefs: []
  type: TYPE_TB
- en: '| 2023-01-19   20.52 |'
  prefs: []
  type: TYPE_TB
- en: '| 2023-01-20   19.85 |'
  prefs: []
  type: TYPE_TB
- en: '| 2023-01-23   19.81 |'
  prefs: []
  type: TYPE_TB
- en: 'Let’s move on to the second step: data preprocessing. I divide this part into
    checking for invalid data and transforming the data so that it is ready for use.
    When dealing with time series, especially downloaded time series, you may sometimes
    encounter NaN values which are not numbers as there has not been a proper input
    in their respective cells.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '*NaN* stands for *Not a Number* and it occurs due to missing, invalid, or corrupt
    data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can deal with NaN values in many ways. For the sake of this example, let’s
    see the simplest way of dealing with these invalid values, which is to eliminate
    them. But first, let’s write a simple code that outputs the number of NaN values
    in the dataframe so that you have an idea on how many values you will delete:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The code uses the `isnull()` method and sums the number it gets which gives
    out the number of NaN values. The output of the previous code snippet is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that you have an idea of how many rows you will delete, you can use the
    following code to drop the NaN rows, thus cleaning up the dataframe from any invalid
    inputs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The second part of the second step is to transform the data. Data science models
    typically like *stationary* data which is data with stable statistical properties
    such as the mean and the standard deviation.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The concept of *stationarity* and the required statistics metrics are discussed
    in detail in Chapter 2\. For now, all you need to know is that it is likely that
    you will have to transform your raw data into stationary data when using data
    science models.
  prefs: []
  type: TYPE_NORMAL
- en: 'To transform the VIX data into stationary data, you can simply take the differences
    from one value relative to the previous value. This is similar to taking price
    data and transforming it into returns data. The following code snippet takes the
    VIX dataframe previously defined and transforms it into a theoretically implied^([2](ch01.xhtml#idm46147477936176))
    stationary data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The third step is data exploration, which is all about understanding the data
    you have in front you, statistically speaking. As you will see statistical metrics
    in detail in the next chapter, I’ll limit the discussion to just calculating the
    mean of the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *mean* is simply the value that can represent the other values in the dataset
    if they were to elect a leader. It is the sum of the values divided by their quantity.
    The mean is the simplest stat in the descriptive statistics world and it is definitely
    the most used one. The following formula shows the mathematical representation
    of the mean of a set of values:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="x overbar equals StartFraction 1 Over n EndFraction sigma-summation
    Underscript i equals 1 Overscript i Endscripts x Subscript i"><mrow><mover><mi>x</mi>
    <mo>¯</mo></mover> <mo>=</mo> <mfrac><mn>1</mn> <mi>n</mi></mfrac> <msubsup><mo>∑</mo>
    <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>i</mi></msubsup> <msub><mi>x</mi>
    <mi>i</mi></msub></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Using `pandas`, you can easily calculate the mean of the dataset as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The output of the previous code snippet is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The next step is data visualization, which is mostly considered as the fun
    step. Let’s chart the VIX’s differenced values through time. The following code
    snippet plots the VIX data shown in Figure 1-1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '![](Images/dlf_0101.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1-1\. Change in VIX since early 2022
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Steps 5 and 6, data analysis and data interpretation, are what you are going
    to study thoroughly in this book, so let’s skip them for now and concentrate on
    the introductory part of data science.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s go back to the invalid or missing data problem before moving on. Sometimes,
    data is incomplete and has missing cells. Even though this has the potential to
    hinder the predictive ability of the algorithm, it should not stop you from continuing
    the analysis as there are quick fixes that help lessen the negative impact of
    the empty cells. For instance, consider table 1-4:'
  prefs: []
  type: TYPE_NORMAL
- en: Table 1-4\. Quarterly GDP
  prefs: []
  type: TYPE_NORMAL
- en: '| Quarter | GDP  |'
  prefs: []
  type: TYPE_TB
- en: '| Q1 2020 | 0.9% |'
  prefs: []
  type: TYPE_TB
- en: '| Q2 2020 | 1.2% |'
  prefs: []
  type: TYPE_TB
- en: '| Q3 2020 | 0.5% |'
  prefs: []
  type: TYPE_TB
- en: '| Q4 2020 | 0.4% |'
  prefs: []
  type: TYPE_TB
- en: '| Q1 2021 | **#N/A** |'
  prefs: []
  type: TYPE_TB
- en: '| Q2 2021 | 1.0% |'
  prefs: []
  type: TYPE_TB
- en: '| Q3 2021 | 1.1% |'
  prefs: []
  type: TYPE_TB
- en: '| Q4 2021 | 0.6% |'
  prefs: []
  type: TYPE_TB
- en: 'The table contains the quartely gross domestic product (GDP) of a hypothetical
    country. Notice how the table is missing the Q1 value of 2021\. There are three
    basic ways to solve this issue:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Delete the cell that contains the missing value:* This is the technique used
    in the previous example of the data science process. It simply considers that
    the time stamp does not exist. It is the simplest fix.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Assume that the missing cell is equal to the previous cell:* This technique
    assumes that the current missing value equals the value previous to it. It is
    also a simple fix that has the aim of smoothing the data instead of completely
    ignoring the issue.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Calculate a mean or a median of the cells around the empty value:* This technique
    takes smoothing one step further and assumes that the missing value is equal to
    the mean between the previous and the next value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data science englobes a range of mathematical and statistical concepts. It entails
    a deep understanding of machine learning algorithms, such as decision trees, random
    forests, and neural networks. These concepts are discussed in detail but also
    in an easy-to-grasp manner so that technical and non-technical readers can benefit
    from their intuition. Many models are assumed to be black boxes and there is a
    hint of truth in this, but the job of a data scientist is to first understand
    the models before interpreting their results. This helps in understanding the
    limitations of the said models.
  prefs: []
  type: TYPE_NORMAL
- en: This book uses Python as the go-to programming language to create the algorithms.
    As mentioned, Chapter 3 introduces Python and the required knowledge to know how
    to manipulate and analyze the data, but also provides the foundations to create
    the different models which, as you will see, are simpler than you might expect.
  prefs: []
  type: TYPE_NORMAL
- en: Before moving on to the next section, let’s have a look at the concepts of data
    storage. After all, data is valuable, but you need to store it somewhere where
    it is easily fetched and analyzed.
  prefs: []
  type: TYPE_NORMAL
- en: '*Data storage* refers to the techniques and areas used to store and organize
    data for future analysis. Data is stored in many formats, among them the common
    ones such as CSV and XLSX files. Other types of formats may include XML, JSON,
    and even JPG for images. The format is chosen according to the structure and organization
    of the data.'
  prefs: []
  type: TYPE_NORMAL
- en: Data can also be stored in clouds or on-premise depending on the capacity of
    storage and the costs. For example, you may want to choose to keep your historical
    1-minute Apple stock data in a cloud so that you save space on your local computer
    as opposed to keeping them in a CSV file.​
  prefs: []
  type: TYPE_NORMAL
- en: 'When dealing with time series in Python, you are mostly going to deal with
    two types of data storages: arrays and data frames. Let’s take a look at what
    they are:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Arrays*'
  prefs: []
  type: TYPE_NORMAL
- en: An *array* is used to store elements of the same kind. Typically, a homogeneous
    data set (such as numbers) is best kept in an array. This occurs when you perform
    back-tests with no need of time stamps. The most used library to handle arrays
    in Python is `numpy`.
  prefs: []
  type: TYPE_NORMAL
- en: Data frames
  prefs: []
  type: TYPE_NORMAL
- en: A *data frame *is a 2-dimensional data structure that can hold data of various
    types (such as float, string, and so on). It can be compared to a table with columns
    and rows. This occurs when you perform back-tests with a need for time stamps
    in tandem with their respective values. The most used library to handle data frames
    in Python is `pandas`.
  prefs: []
  type: TYPE_NORMAL
- en: In general, arrays should be used whenever a homogeneous data collection needs
    to be efficiently stored. When dealing with heterogeneous data or needing to edit
    and analyze data in a tabular manner, you should use data frames.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Data science is continuously evolving. New storage methods are being developed
    by time in an attempt to make them more efficient and increase their capacity
    and speed.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Data Science
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data science has rapidly become an essential part in technology and progress.
    Algorithms rely on information provided from data science tools to perform their
    tasks. But what are algorithms?
  prefs: []
  type: TYPE_NORMAL
- en: An *algorithm* is a set of ordered procedures, that have the aim of completing
    a certain activity or address a particular issue. Algorithms can be as simple
    as flipping a coin or as sophisticated as the Risch algorithm ^([3](ch01.xhtml#idm46147479689328)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a very simple algorithm that updates a charting platform with the
    necessary financial data:'
  prefs: []
  type: TYPE_NORMAL
- en: Connect the server and the online data provider.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copy the financial data with the most recent time stamp.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Paste the data into the charting platform.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Loop back to the first step and redo the whole process.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'That is the nature of algorithms: performing a certain set of instructions
    with a finite or an infinite goal.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The six data science stages that you saw in the previous section can also be
    considered an algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Trading strategies are also algorithms as they have clear rules for the initiation
    and liquidation of positions. An example of a trading strategy is market arbitrage.
  prefs: []
  type: TYPE_NORMAL
- en: '*Arbitrage* is a type of trading strategy that aims to profit from price differences
    of the same asset quoted on different exchanges. These price differences are anomalies
    that are erased by arbitrageurs through their buying and selling activities. Consider
    a stock that is traded on exchange A and exchange B in different countries (for
    simplicity reasons, the two countries use the same currency). Naturally, the stock
    must trade at the same price on both exchanges. When this condition does not hold,
    arbitrageurs come out of their lairs to hunt.'
  prefs: []
  type: TYPE_NORMAL
- en: 'They buy the stock on the cheaper exchange and immediately sell it on the more
    expensive exchange, thus ensuring a virtually risk-free profit. These operations
    are performed at lightning speed as differences do not last long due to the sheer
    power and speed of arbitrageurs. Here’s a clear example:'
  prefs: []
  type: TYPE_NORMAL
- en: The stock’s price at exchange A = $10.00
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The stock’s price at exchange B = $10.50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The algorithm of the arbitrageur in this case will perform the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Buy the stock on exchange A for $10.00.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Sell the stock immediately on exchange B for $10.50.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pocket the difference ($0.50) and repeat until the gap is closed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Trading and execution algorithms can be highly complex and require specialized
    knowledge and a certain market edge.
  prefs: []
  type: TYPE_NORMAL
- en: 'Up until now, you should be aware of the main uses of data science: data interpretation
    and prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: Data interpretation
  prefs: []
  type: TYPE_NORMAL
- en: Also commonly referred to as *business intelligence* or simply *data intelligence*.
    The aim of deploying the algorithms is to understand the whats and hows of data.
  prefs: []
  type: TYPE_NORMAL
- en: Data prediction
  prefs: []
  type: TYPE_NORMAL
- en: Also commonly referred to as *predictive analytics* or simply *forecasting*.
    The aim of deploying the algorithms is to understand the whats next of data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The main aim of using learning algorithms in financial markets is mainly to
    predict data so that you take an informed trading decision with the aim of capital
    appreciation at a success rate higher than random. This is done through many simple
    and complex algorithm that I discuss in this book. These learning algorithms or
    models can be categorized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning
  prefs: []
  type: TYPE_NORMAL
- en: '*Supervised learning algorithms* are models that require labeled data to function.
    This means that you must provide data so that the model trains itself on these
    past values and understands the hidden patterns with the aim of being able to
    deliver future outputs when encountering new data. Examples of supervised learning
    include *linear regression algorithms* and *autoregressive integrated moving average*
    (ARIMA) models. More complex models include *support vector regression algorithms*
    (SVR) and *neural networks*. Adding several layers to neural networks transforms
    them into a deep learning model with a high aptitude of analyzing complex multi-layered
    data. All of these algorithms are discussed in greater depth later in the book.'
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning
  prefs: []
  type: TYPE_NORMAL
- en: Unsupervised learning algorithms are models that do not require labeled data
    to function. This means that they can do the job with unlabelled data since they
    are built to find hidden patterns on their own. Examples include *clustering*
    algorithms and *principal component analysis* (PCA).
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning algorithms are models that do not require data at all
    as they discover their environment and learn from it on their own. As opposed
    to supervised and unsupervised learning models, reinforcement learning models
    gain knowledge through feedback obtained from the environment via a reward system.
    Since this is generally applied to situations in which an agent interacts with
    the environment and learns to adopt behaviors that maximize the reward over time,
    it may not be the go-to algorithm for time series regression. On the other hand,
    it can be used to develop a policy that can apply to time series data to create
    predictions.
  prefs: []
  type: TYPE_NORMAL
- en: As you may have noticed, the book’s title is *Deep Learning for Finance*. This
    means that in addition to other learning models, I will be spending a sizable
    portion of the book discussing deep learning models and coding trading strategies
    using them. This also means that the focus of the book is mainly discussing neural
    networks and their different variations.
  prefs: []
  type: TYPE_NORMAL
- en: Deep supervised learning models (such as deep neural networks) can learn hierarchical
    representations of the data because they include many layers, with each layer
    extracting features at a different level of abstraction. As a result, hidden and
    complex patterns are learned by deep models that may be difficult for shallow
    (not deep) models to learn.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, shallow supervised learning models (like linear regression)
    have a limited ability to learn complex non-linear relationships. But, they require
    less computational effort and are therefore faster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Data science algorithms are deployed pretty much everywhere nowadays and not
    just in finance. Examples include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Business analytics*: Optimizing pricing, predicting customer turnover, or
    improving marketing initiatives using data analysis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Healthcare*: Improving patient outcomes, finding innovative therapies, or
    lowering healthcare costs through in-depth analysis of patient data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Sports*: Sports data analysis to enhance team performance, player scouting,
    or bets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Research*: Analyzing data to support scientific investigation, prove theories,
    or gain new knowledge.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, when someone talks about data science applications, it helps to know what
    a data scientist does.
  prefs: []
  type: TYPE_NORMAL
- en: A data scientist must evaluate and understand complex data in order to get insights
    and provide guidance for decision-making. Common tasks involved in this include
    developing statistical models, applying machine learning techniques, and visualizing
    data. They support the implementation of data-driven solutions and also inform
    stakeholders of their results.
  prefs: []
  type: TYPE_NORMAL
- en: A data engineer, on the other hand, is in charge of building and maintaining
    the infrastructure and tools needed to support data science projects. This entails
    tasks including constructing and executing data pipelines, optimizing data storage
    and retrieval, and building and maintaining big data-processing systems. They
    also work closely with data scientists to make sure they acquire the data they
    need for their study.
  prefs: []
  type: TYPE_NORMAL
- en: In other words, a data scientist is more concerned with the interpretation and
    analysis of data, whereas a data engineer is more concerned with the tools and
    infrastructure needed to gather, store, and analyze data.
  prefs: []
  type: TYPE_NORMAL
- en: 'By now you should understand everything you need to get you started with data
    science. Let’s introduce the second main topic of the book: financial markets.
    After all, this book aims to show how to create data science models and algorithms
    and apply them on financial data in order to extract predictive value from them.'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Financial Markets and Trading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The aim of this book is to present a hands-on approach onto applying different
    learning models to create different trading strategies. It is therefore imperative
    to gain a solid knowledge on how trading and financial markets work.
  prefs: []
  type: TYPE_NORMAL
- en: '*Financial markets* are places where people can trade financial instruments,
    such as stocks, bonds, and currencies. The act of buying and selling is referred
    to as *trading*. The main, but not only, aim of buying a financial instrument
    is capital appreciation. The buyer believes that the value of the instrument is
    greater than its price, therefore the buyer buys the stock (*goes long*) and sells
    whenever they believe that the current price equals the current value. In contrast,
    traders can also make money if the price of the instrument goes down. This process
    is referred to as *short selling* and is common in certain markets such as futures
    and foreign exchange (FX).'
  prefs: []
  type: TYPE_NORMAL
- en: The process of short selling entails borrowing the financial instrument from
    a third party, selling it on the market, and buying it back, before returning
    it to the third party. Ideally, as you expect the price of the instrument to drop,
    you would buy it back cheaper (after the price decrease) and give it back to the
    third party at the market price thus pocketing the difference.
  prefs: []
  type: TYPE_NORMAL
- en: Long (buy) position example
  prefs: []
  type: TYPE_NORMAL
- en: A trader expects the share price of Microsoft to increase over the next couple
    of months due to improved technological regulations, which would increase the
    earnings. They therefore buy a number of shares at $250 and aim to sell them at
    $500\. The trader is therefore long Microsoft stock (also referred to as being
    *bullish*).
  prefs: []
  type: TYPE_NORMAL
- en: Short (sell) position example
  prefs: []
  type: TYPE_NORMAL
- en: A trader expects the share price of Lockheed Martin to decrease over the next
    couple of days due to signals from a technical strategy. They therefore sell short
    a number of shares at $450 and aim to buy them back at $410\. The trader is therefore
    short Lockheed Martin stock (called being *bearish*).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Markets that are trending upwards are referred to as bullish markets. Derived
    from the word *bull* and its aggressive nature, being bullish is related to optimism,
    euphoria, and greed. On the other hand, markets that are trending downwards are
    referred to as bearish markets. Derived from the word *bear* and its defensive
    nature, being bearish is related to pessimism, panic, and fear.
  prefs: []
  type: TYPE_NORMAL
- en: Financial instruments may come in their raw (physical) form or what is also
    known as *spot* and also in derivatives form. *Derivatives* are products that
    traders use to trade markets in certain ways. For example, a *forward* or a *futures* contract
    is a derivative contract where a buyer locks in a price for an asset to buy it
    at a later time.
  prefs: []
  type: TYPE_NORMAL
- en: Another type of derivatives is an option. An *option* is the right but not the
    obligation to buy a certain asset at a specific price in the future by paying
    a premium now (the option’s price). When a buyer wants to buy the underlying stock,
    they exercise their option to do so; otherwise, they may let the option expire.
  prefs: []
  type: TYPE_NORMAL
- en: Trading activity may also occur for hedging purposes as it is not limited to
    just speculation. An example of this would be AirFrance (the main French airline
    company) hedging its business operations by buying oil futures. Buying oil futures
    protects AirFrance from rising oil prices which may hurt its main operations (aviation).
    The rising costs from using fuel to power the planes are offset by the gains from
    the futures. This allows the airline to focus on its main business. This whole
    process is called *hedging*.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s take an example to make things clearer, let’s say an airline company expects
    to consume a certain amount of fuel in the next six months, but they are worried
    about the potential increase in oil prices over that period. To protect against
    this price risk, the airline can enter into a futures contract to purchase oil
    at a fixed price on a future date.
  prefs: []
  type: TYPE_NORMAL
- en: If the price of oil increases during that time, the airline would still be able
    to purchase the oil at the lower, fixed price agreed upon in the futures contract.
    On the other hand, if the price of oil decreases, the airline would be obligated
    to pay the higher, fixed price, but the lower market price for the oil would offset
    that cost.
  prefs: []
  type: TYPE_NORMAL
- en: In this way, the airline can mitigate the risk of price fluctuations in the
    oil market and stabilize their fuel costs. This can help the airline to better
    manage its budget and forecast its future earnings.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the aim is to make financial gains from the trading operations
    -- it aims to simply stabilize its costs by locking in a known price for oil.
  prefs: []
  type: TYPE_NORMAL
- en: 'Typically, financial instruments are grouped in asset classes based on their
    type:'
  prefs: []
  type: TYPE_NORMAL
- en: Stock markets
  prefs: []
  type: TYPE_NORMAL
- en: A stock market is an exchange place (electronic or physical) where companies
    issue shares of stock to raise money for business. When people buy shares of a
    company’s stock, they become part owners of that company and may become entitled
    to dividends according the company’s policy. Depending on the type of stocks,
    they can also gain the right to vote in board meetings.
  prefs: []
  type: TYPE_NORMAL
- en: Fixed income
  prefs: []
  type: TYPE_NORMAL
- en: Governments and businesses can borrow money in the fixed income market. When
    a person purchases a bond, they are effectively lending money to the borrower,
    who has agreed to repay the loan along with interest. Depending on the borrower’s
    creditworthiness and the prevailing interest rates, the bond’s value may increase
    or decrease.
  prefs: []
  type: TYPE_NORMAL
- en: Currencies
  prefs: []
  type: TYPE_NORMAL
- en: The FX market, also referred to as the currencies market, is a place where people
    may purchase and sell various currencies. A currency’s value can increase or decrease
    based on a variety of variables, including the economy, interest rates, and political
    stability of the nation.
  prefs: []
  type: TYPE_NORMAL
- en: Commodities
  prefs: []
  type: TYPE_NORMAL
- en: Agricultural products, gold, oil, and other physical assets with industrial
    or other uses are referred to as *commodities*. They typically offer a means to
    profit from global economic trends as well as being a form of hedge against inflation.
  prefs: []
  type: TYPE_NORMAL
- en: Alternative investments
  prefs: []
  type: TYPE_NORMAL
- en: In the world of finance, non-traditional investments such as real estate, private
    equity, and hedge funds are referred to as *alternative asset classes*. These
    alternative asset classes have the potential to offer better returns than traditional
    assets and offer the benefit of diversity, but they also tend to be less liquid
    and may be more difficult to evaluate. It’s crucial to remember that each of these
    asset classes has unique qualities and various levels of risk, so investors should
    do their homework before investing in any of these assets.
  prefs: []
  type: TYPE_NORMAL
- en: Financial markets allow businesses and governments to raise money they need
    to operate. They also provide opportunities for investors to make money speculating
    and investing in interesting opportunities. Trading activities provide liquidity
    to the markets which makes the price more efficient and less costly. In other
    words, the more the market is liquid, the less are the costs to trade in it as
    the number of orders makes it less likely to heavily impact the market when trading.
    But how do markets really work? What causes the price to go up and down?
  prefs: []
  type: TYPE_NORMAL
- en: '*Market microstructure* is the research that deals with the trading of securities
    in financial markets. It looks at how trading works as well as how traders, investors,
    and market makers behave. Understanding price formation and the variables that
    affect trading costs is the aim of market microstructure research.'
  prefs: []
  type: TYPE_NORMAL
- en: Order flow, liquidity, market effectiveness, and price discovery are just a
    few of the many subjects covered by market microstructure research. Additionally,
    it looks at how various trading techniques, including limit orders, market orders,
    and algorithmic trading, affect market dynamics. *Liquidity* is possibly the most
    important market microstructure concept. It describes how easily an asset may
    be bought or sold without materially changing its price. Liquidity can vary between
    financial instruments and over time. It can be impacted by a number of variables,
    including trading volume and volatility.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, market efficiency is a crucial component of market microstructure
    research. Research in this area has demonstrated that some markets are more efficient
    than others and that elements like insider trading, price manipulation, and information
    asymmetry can have an impact on prices. Market efficiency is revisited in Chapter
    4, which deals with technical analysis, a key analysis field in trading.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, I want to discuss another important area of market microstructure: *price
    discovery*. This refers to the method used to set prices in a market. Prices can
    be affected by elements like order flow, market maker activity, and the presence
    of various trading methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Imagine you want to buy a sizable number of shares in two stocks: stock A and
    stock B. Stock A is very liquid while stock B is very illiquid. If you want to
    execute the buy order on stock A, you are likely to get filled at the desired
    market price with minimal impact if any. However, with stock B, you are likely
    to get a worse price as there is not enough sellers willing to sell at your desired
    buy price, and therefore, as you create more demand from your orders, the price
    rises to match the sellers’ prices and thus, you will buy at a higher (worse)
    price. This is the impact liquidity can have on your trading.'
  prefs: []
  type: TYPE_NORMAL
- en: Applications of Data Science in Finance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let’s begin peeking into the main areas of data science for finance. Every
    field has its challenges and problems that need simple and complex solutions.
    Finance is no different. Recent years have seen a gigantic leap in using data
    science to improve the world of finance, from the corporate world to the markets
    world. Let’s discuss some of these areas:'
  prefs: []
  type: TYPE_NORMAL
- en: Financial fraud detection
  prefs: []
  type: TYPE_NORMAL
- en: Financial transactions can be examined for patterns and anomalies using data
    science models, which attempt to spot possible fraud. By examining transaction
    data from credit cards to spot odd or suspect spending patterns, one way to use
    data science to stop financial fraud is to find unusual or suspicious patterns
    of expenditures. This can involve making numerous minor purchases quickly after
    one another or making significant or frequent purchases from the same store. On
    the basis of this data, machine learning algorithms are trained to find anomalies
    that point to fraudulent conduct.
  prefs: []
  type: TYPE_NORMAL
- en: Risk management
  prefs: []
  type: TYPE_NORMAL
- en: To examine financial data and spot potential risks to portfolios, data science
    approaches might be applied. This can assist financial institutions in managing
    their risk exposure and making better-informed decisions. Analysis of market data
    to forecast changes in stock prices and other financial indicators is one example
    of applying data science for risk management in finance. This can involve analyzing
    vast amounts of historical data using methods like statistical modeling, machine
    learning, and artificial intelligence in order to spot patterns and trends that
    can be used to forecast the state of the market in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Credit scoring
  prefs: []
  type: TYPE_NORMAL
- en: Data science can be used to examine financial data and credit history, forecast
    a person’s or a company’s creditworthiness, and make loan decisions. Utilizing
    financial data, such as income and credit history, to forecast a person’s creditworthiness
    is one example of applying data science for credit score research. This can involve
    developing a prediction model that can use a number of indicators, such as prior
    credit performance, income, and job history, in order to evaluate a person’s likelihood
    of repaying a loan using techniques like statistical modeling and machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: Natural Language Processing (NLP)
  prefs: []
  type: TYPE_NORMAL
- en: In order to make better judgments, NLP analyzes and extracts insights from unstructured
    financial data, such as news articles, reports, and social media posts. A famous
    example of NLP is using the sentiment of the text to extract possible trading
    opportunities stemming from the intentions and feelings of the market participants
    and experts. NLP falls into the field of sentiment analysis (with help from machine
    learning).
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data science keeps growing every day with new techniques and models appearing
    regularly that aim to improve the interpretation of data. This chapter has provided
    a simple introduction to what you need to know about data science and how you
    can use it in finance.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter presents the required knowledge in statistics, probability,
    and math that you may need when trying to understand data science models. Even
    though the aim of the book is to present a hands-on approach of creating and applying
    the different models using Python, it helps for you to understand what you’re
    dealing with instead of blindly applying them onto data.
  prefs: []
  type: TYPE_NORMAL
- en: If you need a Python refresher, see Chapter 3, which is a basic introduction.
    It sets the foundations to what’s to come next in the book. You do not need to
    become a Python master to perform data science but you must understand code and
    what it refers to, and especially how to debug and detect errors in the code.
  prefs: []
  type: TYPE_NORMAL
- en: '^([1](ch01.xhtml#idm46147473036608-marker)) OHLC refers to the four essential
    pieces of market data: open price, high price, low price, and close price.'
  prefs: []
  type: TYPE_NORMAL
- en: ^([2](ch01.xhtml#idm46147477936176-marker)) The reason I am saying implied is
    because stationarity must be verified through statistical checks that you will
    see in the next chapter. At the moment, the assumption is that differencing the
    data gives stationary time series.
  prefs: []
  type: TYPE_NORMAL
- en: ^([3](ch01.xhtml#idm46147479689328-marker)) The Rish algorithm is an indefinite
    integration technique used to find antiderivatives.
  prefs: []
  type: TYPE_NORMAL
