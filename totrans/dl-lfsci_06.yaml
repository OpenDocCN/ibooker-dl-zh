- en: Chapter 6\. Deep Learning for Genomics
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章。基因组学的深度学习
- en: 'At the heart of every living organism is its genome: the molecules of DNA containing
    all the instructions to make the organism’s working parts. If a cell is a computer,
    then its genome sequence is the software it executes. And if DNA can be seen as
    software, information meant to be processed by a computer, surely we can use our
    own computers to analyze that information and understand how it functions?'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 每个生物体的核心是其基因组：包含制造生物体工作部分的所有指令的DNA分子。如果一个细胞是一台计算机，那么它的基因组序列就是它执行的软件。如果DNA可以被视为软件，信息是计算机处理的，那么我们肯定可以使用我们自己的计算机来分析这些信息并理解它是如何运作的？
- en: But of course, DNA is not just an abstract storage medium. It is a physical
    molecule that behaves in complicated ways. It also interacts with thousands of
    other molecules, all of which play important roles in maintaining, copying, directing,
    and carrying out the instructions contained in the DNA. The genome is a huge and
    complex machine made up of thousands of parts. We still have only a poor understanding
    of how most of those parts work, to say nothing of how they all come together
    as a working whole.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，DNA不仅仅是一个抽象的存储介质。它是一种行为复杂的物理分子。它还与成千上万的其他分子相互作用，所有这些分子都在维持、复制、指导和执行DNA中包含的指令方面发挥重要作用。基因组是一个由成千上万部分组成的巨大而复杂的机器。我们对大多数这些部分如何工作仍知之甚少，更不用说它们如何作为一个整体运作了。
- en: This brings us to the twin fields of *genetics* and *genomics*. Genetics treats
    DNA as abstract information. It looks at patterns of inheritance, or seeks correlations
    across populations, to discover the connections between DNA sequences and physical
    traits. Genomics, on the other hand, views the genome as a physical machine. It
    tries to understand the pieces that make up that machine and the ways they work
    together. The two approaches are complementary, and deep learning can be a powerful
    tool for both of them.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这将引出*遗传学*和*基因组学*这两个领域。遗传学将DNA视为抽象信息。它研究遗传模式，或者在人群中寻找相关性，以发现DNA序列和生理特征之间的联系。另一方面，基因组学将基因组视为一个物理机器。它试图理解构成该机器的部分以及它们如何协同工作。这两种方法是互补的，深度学习可以成为它们两者的强大工具。
- en: DNA, RNA, and Proteins
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DNA、RNA和蛋白质
- en: Even if you are not a biologist, at some point in your education you probably
    studied the basics of how genomes operate. We will first review the simplified
    picture of genomics that is usually taught in introductory classes. Then we will
    describe some of the ways in which the real world is more complicated.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你不是生物学家，在你的教育过程中，你可能也学习过基因组是如何运作的基础知识。我们将首先回顾通常在入门课程中教授的基因组的简化图景。然后我们将描述现实世界更为复杂的一些方面。
- en: 'DNA is a polymer: a long chain of repeating units strung together. In the case
    of DNA, there are four units (called *bases*) that can appear: adenine, cytosine,
    guanine, and thymine, which are abbreviated as A, C, G, and T (see [Figure 6-1](#dna-structure-bases)).
    Nearly all the information about how to make a living organism is ultimately encoded
    in the specific pattern of these four repeating units that make up its genome.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: DNA是一种聚合物：一长串重复单元串在一起。在DNA的情况下，有四种可能出现的单元（称为*碱基*）：腺嘌呤、胞嘧啶、鸟嘌呤和胸腺嘧啶，简称为A、C、G和T（参见[图6-1](#dna-structure-bases)）。关于如何制造生物体的几乎所有信息最终都编码在构成其基因组的这四种重复单元的特定模式中。
- en: '![](Images/dlls_0601.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlls_0601.png)'
- en: 'Figure 6-1\. Structure of a DNA molecule. It consists of two chains, each made
    of many A, C, G, and T bases. The two chains are complementary: every C in one
    chain is paired with a G in the other, and every A in one chain is paired with
    a T in the other. (Source: [Wikimedia](https://en.wikipedia.org/wiki/Molecular_Structure_of_Nucleic_Acids:_A_Structure_for_Deoxyribose_Nucleic_Acid#/media/File:DNA-structure-and-bases.png).)'
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-1\. DNA分子的结构。它由许多A、C、G和T碱基组成的两条链组成。这两条链是互补的：一条链中的每个C与另一条链中的G配对，一条链中的每个A与另一条链中的T配对。
    (来源：[Wikimedia](https://en.wikipedia.org/wiki/Molecular_Structure_of_Nucleic_Acids:_A_Structure_for_Deoxyribose_Nucleic_Acid#/media/File:DNA-structure-and-bases.png).)
- en: If DNA is the software, proteins are the most important hardware. Proteins are
    tiny machines that do almost all the work in a cell. Proteins are also polymers,
    made up of repeating units called *amino acids*. There are 20 main amino acids,
    and their physical properties vary widely. Some are large while others are small.
    Some have an electric charge while others do not. Some tend to attract water while
    others tend to repel it. When just the right set of amino acids is strung together
    in just the right order, it will spontaneously fold up into a 3D shape, all the
    pieces positioned just right to let it function as a machine.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果DNA是软件，那么蛋白质就是最重要的硬件。蛋白质是微小的机器，在细胞中几乎完成所有工作。蛋白质也是聚合物，由称为*氨基酸*的重复单元组成。有20种主要氨基酸，它们的物理性质差异很大。有些大，而有些小。有些带有电荷，而有些没有。有些倾向于吸引水，而有些倾向于排斥水。当恰到好处的氨基酸集合以恰到好处的顺序串在一起时，它将自发地折叠成一个三维形状，所有部分都被正确地定位，以使其作为一个机器发挥作用。
- en: One of the main functions of DNA is to record the sequences of amino acids for
    an organism’s proteins. It does this in a simple, straightforward way. Particular
    stretches of DNA directly correspond to particular proteins. Each sequence of
    three DNA bases (called a *codon*) corresponds to one amino acid. For example,
    the pattern AAA indicates the amino acid lysine, while the pattern GCC indicates
    the amino acid alanine.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: DNA的主要功能之一是记录生物体蛋白质的氨基酸序列。它以一种简单直接的方式做到这一点。特定的DNA片段直接对应于特定的蛋白质。每个三个DNA碱基序列（称为*密码子*）对应一个氨基酸。例如，模式AAA表示氨基酸赖氨酸，而模式GCC表示氨基酸丙氨酸。
- en: Going from DNA to protein involves another molecule, RNA, that serves as an
    intermediate representation to carry information from one part of the cell to
    another. RNA is yet another polymer and is chemically very similar to DNA. It
    too has four bases that can be chained together in arbitrary orders. To create
    a protein, the information must be copied twice. First the DNA sequence is *transcribed*
    into an equivalent RNA sequence, and then the RNA molecule is *translated* into
    a protein molecule. The RNA molecule that carries the information is called a
    *messenger RNA*, or mRNA for short.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 从DNA到蛋白质涉及另一种分子，RNA，它作为中间表示来携带信息从细胞的一部分到另一部分。RNA是另一种聚合物，化学上与DNA非常相似。它也有四种碱基，可以以任意顺序链接在一起。要创建蛋白质，信息必须被复制两次。首先，DNA序列被*转录*成等效的RNA序列，然后RNA分子被*翻译*成蛋白质分子。携带信息的RNA分子称为*信使RNA*，简称mRNA。
- en: This tells us *how* proteins get made, but not *when*. A human cell has many
    thousands of different proteins it can make. Surely it doesn’t just churn out
    copies of all of them, all the time? Clearly there must be some sort of regulatory
    mechanism to control which proteins get made when. In the conventional picture,
    this is done by special proteins called *transcription factors (TFs)*. Each TF
    recognizes and binds to a particular DNA sequence. Depending on the particular
    TF and the location where it binds, it can either increase or decrease the rate
    at which nearby genes are transcribed.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这告诉我们蛋白质是如何制造的，但没有告诉我们*何时*。人类细胞可以制造许多不同的蛋白质。它肯定不会一直生产所有这些蛋白质的副本，对吧？显然必须有某种调节机制来控制何时制造哪些蛋白质。在传统观念中，这是由称为*转录因子（TFs）*的特殊蛋白质完成的。每个TF识别并结合到特定的DNA序列。根据特定的TF和其结合位置，它可以增加或减少附近基因的转录速率。
- en: This gives a simple, easy-to-understand picture of how a genome works. The job
    of DNA is to encode proteins. Stretches of DNA (called *genes*) code for proteins
    using a simple, well-defined code. DNA is converted to RNA, which serves only
    as an information carrier. The RNA is then converted into proteins, which do all
    the real work. The whole process is very elegant, the sort of thing a talented
    engineer might have designed. And for many years, this picture was believed to
    be mostly correct. So, take a moment to enjoy it before we spoil the view by revealing
    that reality is actually far messier and far more complicated.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这提供了一个简单、易于理解的基因组工作方式的图像。DNA的工作是编码蛋白质。DNA的一段（称为*基因*）使用简单、明确定义的密码编码蛋白质。DNA被转录为RNA，它只作为信息载体。然后RNA被转化为蛋白质，蛋白质才是真正的工作。整个过程非常优雅，就像一个有才华的工程师设计的东西。多年来，人们一直相信这种图像基本上是正确的。所以，在我们揭示现实实际上更加混乱和复杂之前，花点时间享受一下吧。
- en: And Now for the Real World
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 现在进入真实世界
- en: Now it’s time to talk about how genomes *really* work. The picture described
    in the previous section is simple and elegant, but unfortunately it has little
    connection to reality. This section will go through a lot of information very
    quickly, but don’t worry about remembering or understanding all of it. The important
    thing is just to get a sense of the incredible complexity of living organisms.
    We will return to some of these subjects later in the chapter and discuss them
    in more detail.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候谈论基因组*真正*的工作方式了。在前一节中描述的图像简单而优雅，但不幸的是它与现实几乎没有联系。本节将快速介绍大量信息，但不用担心记住或理解所有内容。重要的是要对生物体的令人难以置信的复杂性有所感知。我们将在本章的后面回到其中一些主题，并进行更详细的讨论。
- en: Let’s begin by considering DNA molecules (called *chromosomes*). In bacteria,
    which have relatively small genomes, DNA exists as simple free-floating molecules.
    But eukaryotes (a group that includes amoebas, humans, and everything in between)
    have much larger genomes. To fit inside the cell, each chromosome must be packed
    into a very small space. This is accomplished by winding it around proteins called
    *histones*. But if all the DNA is tightly packed away, how can it be transcribed?
    The answer, of course, is that it can’t. Before a gene can be transcribed, the
    stretch of DNA containing it first must be unwound. How does the cell know which
    DNA to unwind? The answer is still poorly understood. It is believed to involve
    various types of chemical modification to the histone molecules, and proteins
    that recognize particular modifications. Clearly there is a regulatory mechanism
    involved, but many of the details are still unknown. We will return to this subject
    shortly.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从考虑DNA分子（称为*染色体*）开始。在细菌中，DNA存在为简单的自由漂浮分子。但真核生物（包括变形虫、人类和中间所有生物）拥有更大的基因组。为了适应细胞内，每个染色体必须被打包到非常小的空间中。这是通过将其缠绕在称为*组蛋白*的蛋白质周围来实现的。但如果所有DNA都被紧密打包起来，它如何被转录呢？答案当然是不能。在基因可以被转录之前，首先必须解开包含它的DNA片段。细胞如何知道哪些DNA需要解开呢？答案仍然不明确。据信涉及各种类型的组蛋白分子的化学修饰，以及识别特定修饰的蛋白质。显然涉及到一种调节机制，但许多细节仍然未知。我们将很快回到这个主题。
- en: DNA itself can be chemically modified through a process called *methylation*.
    The more highly a stretch of DNA is methylated, the less likely it is to be transcribed,
    so this is another regulatory mechanism the cell can use to control the production
    of proteins. But how does it control which regions of DNA are methylated? This
    too is still poorly understood.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: DNA本身可以通过一种称为*甲基化*的过程进行化学修饰。DNA的一段被高度甲基化，就越不可能被转录，因此这是细胞可以用来控制蛋白质产生的另一种调节机制。但它如何控制哪些DNA区域被甲基化呢？这也仍然不明确。
- en: In the previous section we said that a particular stretch of DNA corresponds
    to a particular protein. That is correct for bacteria, but in eukaryotes the situation
    is more complicated. After the DNA is transcribed into a messenger RNA, that RNA
    often is edited to remove sections and connect (or *splice*) the remaining parts
    (called *exons*) back together again. The RNA sequence that finally gets translated
    into a protein may therefore be different from the original DNA sequence. In addition,
    many genes have multiple *splice variants*—different ways of removing sections
    to form the final sequence. This means a single stretch of DNA can actually code
    for several different proteins!
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在前一节中，我们说特定的DNA片段对应于特定的蛋白质。这对细菌来说是正确的，但在真核生物中情况更加复杂。在DNA被转录成信使RNA后，该RNA经常被编辑以去除部分并连接（或*剪接*）剩余部分（称为*外显子*）。最终被翻译成蛋白质的RNA序列可能与原始DNA序列不同。此外，许多基因具有多个*剪接变体*
    - 去除部分以形成最终序列的不同方式。这意味着单个DNA片段实际上可以编码多种不同的蛋白质！
- en: Is all of this starting to sound very complicated? Well, keep reading, because
    we’ve barely started! Evolution selects for mechanisms that work, without any
    concern for whether they are simple or easy to understand. It leads to very complicated
    systems, and understanding them requires us to confront that complexity.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些听起来开始变得非常复杂了吗？好吧，继续阅读，因为我们才刚刚开始！进化选择能够起作用的机制，而不关心它们是否简单或易于理解。这导致了非常复杂的系统，理解它们需要我们面对这种复杂性。
- en: 'In the conventional picture RNA is viewed as just an information carrier, but
    even from the early days of genomics, biologists knew that was not entirely correct.
    The job of translating mRNA to proteins is performed by *ribosomes*, complicated
    molecular machines made partly of proteins and partly of RNA. Another key role
    in translation is performed by molecules called *transfer RNAs* (or tRNAs for
    short). These are the molecules that define the “genetic code,” recognizing patterns
    of three bases in mRNA and adding the correct amino acid to the growing protein.
    So, for over half a century we’ve known there were at least three kinds of RNA:
    mRNA, ribosomal RNA, and tRNA.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统观念中，RNA被视为仅仅是一个信息载体，但即使在基因组学的早期，生物学家们就知道这并不完全正确。将mRNA翻译成蛋白质的工作是由*核糖体*完成的，这是由部分蛋白质和部分RNA组成的复杂分子机器。翻译中的另一个关键角色是由称为*转运RNA*（或简称tRNA）的分子执行的。这些分子定义了“遗传密码”，识别mRNA中的三个碱基的模式，并将正确的氨基酸添加到不断增长的蛋白质中。因此，半个多世纪以来，我们已经知道至少有三种RNA：mRNA，核糖体RNA和tRNA。
- en: 'But RNA still had lots of tricks up its sleeve. It is a surprisingly versatile
    molecule. Over the last few decades, many other types of RNA have been discovered.
    Here are some examples:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 但RNA仍然有许多窍门。它是一种令人惊讶地多才多艺的分子。在过去的几十年中，发现了许多其他类型的RNA。以下是一些例子：
- en: '*Micro RNAs* (miRNAs) are short pieces of RNA that bind to a messenger RNA
    and prevent it from being translated into proteins. This is a very important regulatory
    mechanism in some types of animals, especially mammals.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*微小RNA*（miRNAs）是一种短的RNA片段，它们结合到信使RNA上，阻止其被翻译成蛋白质。这是一种在某些动物，尤其是哺乳动物中非常重要的调节机制。'
- en: '*Short interfering RNA* (siRNA) is another type of RNA that binds to mRNA and
    prevents it from being translated. It’s similar to miRNA, but siRNAs are double
    stranded (unlike miRNAs, which are single stranded), and some of the details of
    how they function are different. We will discuss siRNA in more detail later in
    the chapter.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*短干扰RNA*（siRNA）是另一种类型的RNA，它结合到mRNA上并阻止其被翻译。它类似于miRNA，但siRNA是双链的（不像miRNA是单链的），它们的一些功能细节是不同的。我们将在本章后面更详细地讨论siRNA。'
- en: '*Ribozymes* are RNA molecules that can act as enzymes to catalyze chemical
    reactions. Chemistry is the foundation of everything that happens in a living
    cell, so catalysts are vital to life. Usually this job is done by proteins, but
    we now know it sometimes is done by RNA.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*核酶*是可以作为酶来催化化学反应的RNA分子。化学是生命细胞中发生的一切的基础，因此催化剂对生命至关重要。通常这项工作由蛋白质完成，但我们现在知道有时也由RNA完成。'
- en: '*Riboswitches* are RNA molecules that consist of two parts. One part acts as
    a messenger RNA, while the other part is capable of binding to a small molecule.
    When it binds, that can either enable or prevent translation of the mRNA. This
    is yet another regulatory mechanism by which protein production can be adjusted
    based on the concentration of particular small molecules in the cell.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*核糖开关*是由两部分组成的RNA分子。一部分充当信使RNA，而另一部分能够结合到小分子上。当它结合时，可以启用或阻止mRNA的翻译。这是另一种调节机制，可以根据细胞中特定小分子的浓度来调整蛋白质的产生。'
- en: Of course, all these different types of RNA must be manufactured, and the DNA
    must contain instructions on how to make them. So, DNA is more than just a string
    of encoded protein sequences. It also contains RNA sequences, plus binding sites
    for transcription factors and other regulatory molecules, plus instructions for
    how messenger RNAs should be spliced, plus various chemical modifications that
    influence how it is wound around histones and which genes get transcribed.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，所有这些不同类型的RNA都必须被制造出来，DNA必须包含如何制造它们的说明。因此，DNA不仅仅是一串编码蛋白质序列的字符串。它还包含RNA序列，以及转录因子和其他调节分子的结合位点，以及有关如何剪接信使RNA的说明，以及影响其如何缠绕在组蛋白周围以及哪些基因被转录的各种化学修饰。
- en: Now consider what happens after the ribosome finishes translating the mRNA into
    a protein. Some proteins can spontaneously fold into the correct 3D shape, but
    many others require help from other proteins called *chaperones*. It is also very
    common for proteins to need additional chemical modifications after they are translated.
    Then the finished protein must be transported to the correct location in the cell
    to do its job, and finally degraded when it is no longer needed. Each of these
    processes is controlled by additional regulatory mechanisms, and involves interactions
    with lots of other molecules.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在考虑核糖体将mRNA翻译成蛋白质后会发生什么。一些蛋白质可以自发地折叠成正确的三维形状，但许多其他蛋白质需要其他蛋白质（称为*分子伴侣*）的帮助。在翻译后，蛋白质通常需要额外的化学修饰。然后，成品蛋白质必须被运送到细胞的正确位置以完成其工作，并在不再需要时最终被降解。每个这些过程都受到额外的调节机制的控制，并涉及与许多其他分子的相互作用。
- en: If this all sounds overwhelming, that’s because it is! A living organism is
    far more complicated than any machine ever created by humans. The thought of trying
    to understand it *should* intimidate you!
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这一切听起来令人不知所措，那是因为它确实如此！一个活体生物比人类创造的任何机器都要复杂得多。试图理解它应该让你感到害怕！
- en: But this is also why machine learning is such a powerful tool. We have huge
    amounts of data, generated by a process that is both mind-bogglingly complex and
    poorly understood. We want to discover subtle patterns buried in the data. This
    is exactly the sort of problem that deep learning excels at!
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 但这也是为什么机器学习是如此强大的工具。我们有大量数据，这些数据是由一个复杂且不被充分理解的过程生成的。我们希望发现数据中隐藏的微妙模式。这正是深度学习擅长的问题类型！
- en: 'In fact, deep learning is *uniquely* well suited to the problem. Classical
    statistical techniques struggle to represent the complexity of the genome. They
    often are based around simplifying assumptions. For example, they look for linear
    relationships between variables, or they try to model a variable as depending
    on only a small number of other variables. But genomics involves complex nonlinear
    relationships between hundreds of variables: exactly the sort of relationship
    that can be effectively described by a deep neural network.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，深度学习非常适合这个问题。传统的统计技术很难表示基因组的复杂性。它们通常基于简化的假设。例如，它们寻找变量之间的线性关系，或者试图将一个变量建模为仅取决于少数其他变量。但基因组涉及数百个变量之间的复杂非线性关系：这正是深度神经网络可以有效描述的关系类型。
- en: Transcription Factor Binding
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 转录因子结合
- en: As an example of applying deep learning to genomics, let’s consider the problem
    of predicting transcription factor binding. Recall that TFs are proteins that
    bind to DNA. When they bind, they influence the probability of nearby genes being
    transcribed into RNA. But how does a TF know where to bind? Like so much of genomics,
    this question has a simple answer followed by lots of complications.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 以将深度学习应用于基因组学为例，让我们考虑预测转录因子结合的问题。回想一下，TF是结合到DNA的蛋白质。当它们结合时，它们会影响附近基因被转录成RNA的概率。但是TF如何知道在哪里结合？像基因组学的许多问题一样，这个问题有一个简单的答案，然后是许多复杂性。
- en: To a first approximation, every TF has a specific DNA sequence called its *binding
    site motif* that it binds to. Binding site motifs tend to be short, usually 10
    bases or less. Wherever a TF’s motif appears in the genome, the TF will bind to
    it.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一次近似中，每个转录因子都有一个特定的DNA序列，称为其*结合位点基序*，它会与之结合。结合位点基序往往很短，通常为10个碱基或更少。无论TF的基序出现在基因组的哪个位置，TF都会与之结合。
- en: In practice, though, motifs are not completely specific. A TF may be able to
    bind to many similar but not identical sequences. Some bases within the motif
    may be more important than others. This is often modeled as a *position weight
    matrix* that specifies how much preference the TF has for each possible base at
    each position within the motif. Of course, that assumes every position within
    the motif is independent, which is not always true. Sometimes even the length
    of a motif can vary. And although binding is primarily determined by the bases
    within the motif, the DNA to either side of it can also have some influence.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，基序并不完全特异。一个TF可能能够结合许多相似但不完全相同的序列。基序内的一些碱基可能比其他碱基更重要。这通常被建模为*位置权重矩阵*，指定TF对基序内每个位置的每个可能碱基的偏好程度。当然，这假设基序内的每个位置都是独立的，这并不总是正确的。有时，甚至基序的长度也会有所变化。虽然结合主要由基序内的碱基决定，但基序两侧的DNA也可能会产生一些影响。
- en: And that’s just considering the sequence! Other aspects of the DNA can also
    be important. Many TFs are influenced by the physical shape of the DNA, such as
    how tightly the double helix is twisted. If the DNA is methylated, that can influence
    TF binding. And remember that most DNA in eukaryotes is tightly packed away, wound
    around histones. TFs can only bind to the portions that have been unwound.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这只考虑了序列！DNA的其他方面也可能很重要。许多TF受到DNA的物理形状的影响，例如双螺旋的紧密程度。如果DNA被甲基化，那可能会影响TF的结合。请记住，真核生物中的大多数DNA都被紧密包裹在组蛋白周围。TF只能结合到已经展开的部分。
- en: Other molecules also play important roles. TFs often interact with other molecules,
    and those interactions can affect DNA binding. For example, a TF may bind to a
    second molecule to form a complex, and that complex then binds to a different
    DNA motif than the TF would on its own.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 其他分子也发挥着重要作用。TF经常与其他分子相互作用，这些相互作用可能会影响DNA结合。例如，TF可能会与第二个分子结合形成一个复合物，然后该复合物会与TF单独结合到不同的DNA基序。
- en: Biologists have spent decades untangling these details and designing models
    for TF binding. Instead of doing that, let’s see if we can use deep learning to
    learn a model directly from data.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 生物学家花费了数十年来解开这些细节并设计TF结合的模型。让我们看看是否可以使用深度学习直接从数据中学习模型，而不是做这些工作。
- en: A Convolutional Model for TF Binding
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: TF结合的卷积模型
- en: For this example, we will use experimental data on a particular transcription
    factor called JUND. An experiment was done to identify every place in the human
    genome where it binds. To keep things manageable, we only include the data from
    chromosome 22, one of the smallest human chromosomes. It is still over 50 million
    bases long, so that gives us a reasonable amount of data to work with. The full
    chromosome has been split up into short segments, each 101 bases long, and each
    segment has been labeled to indicate whether it does or does not include a site
    where JUND binds. We will try to train a model that predicts those labels based
    on the sequence of each segment.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个例子，我们将使用一个名为JUND的特定转录因子的实验数据。进行了一个实验来识别人类基因组中它结合的每个位置。为了使事情更容易处理，我们只包括染色体22的数据，这是最小的人类染色体之一。它仍然有超过5000万个碱基，因此我们有足够的数据来处理。整个染色体已经被分成短片段，每个片段长101个碱基，并且每个片段已被标记以指示是否包含JUND结合的位置。我们将尝试训练一个模型，根据每个片段的序列来预测这些标签。
- en: The sequences are represented with one-hot encoding. For each base we have four
    numbers, of which one is set to 1 and the others are set to 0\. Which of the four
    numbers is set to 1 indicates whether the base is an A, C, G, or T.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这些序列是用一位热编码表示的。对于每个碱基，我们有四个数字，其中一个设置为1，其他设置为0。哪个数字设置为1表示碱基是A、C、G还是T。
- en: 'To process the data we will use a convolutional neural network, just like we
    did for recognizing handwritten digits in [Chapter 3](ch03.xhtml#machine_learning_with_deepchem).
    In fact, you will see the two models are remarkably similar to each other. This
    time we will use 1D convolutions, since we are dealing with 1D data (DNA sequences)
    instead of 2D data (images), but the basic components of the model will be the
    same: inputs, a series of convolutional layers, one or more dense layers to compute
    the output, and a cross entropy loss function.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理数据，我们将使用一个卷积神经网络，就像我们在[第3章](ch03.xhtml#machine_learning_with_deepchem)中识别手写数字时所做的那样。实际上，您会发现这两个模型在很大程度上相似。这次我们将使用1D卷积，因为我们处理的是1D数据（DNA序列）而不是2D数据（图像），但模型的基本组件将是相同的：输入，一系列卷积层，一个或多个密集层来计算输出，以及一个交叉熵损失函数。
- en: 'Let’s start by creating a `TensorGraph` and defining the inputs:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从创建一个`TensorGraph`并定义输入开始：
- en: '[PRE0]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Notice the sizes of the inputs. For each sample, we have a feature vector of
    size 101 (the number of bases) by 4 (the one-hot encoding of each base). We also
    have a single number for the label (either 0 or 1, to indicate whether it contains
    a binding site) and a single number for the weight. Using weights in the loss
    function is critical for this example, because the data is very unbalanced. Less
    than 1% of all samples include a binding site. That means the model could trivially
    get better than 99% accuracy by just outputting 0 for every sample. We prevent
    this by giving the positive samples higher weights than the negative ones.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 注意输入的大小。对于每个样本，我们有一个大小为101（碱基数）乘以4（每个碱基的一位热编码）的特征向量。我们还有一个标签的单个数字（0或1，表示是否包含结合位点）和一个权重的单个数字。在这个例子中使用损失函数中的权重是至关重要的，因为数据非常不平衡。不到1%的所有样本包含结合位点。这意味着模型可以通过只为每个样本输出0来轻松获得超过99%的准确率。我们通过给正样本比负样本更高的权重来防止这种情况。
- en: 'Next we create a stack of three convolutional layers, all with identical parameters:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个具有相同参数的三个卷积层的堆叠：
- en: '[PRE1]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: We specify 10 for the width of the convolutional kernels, and that each layer
    should include 15 filters (that is, outputs). The first layer takes the raw features
    (four numbers per base) as input. It looks at spans of 10 consecutive bases, so
    40 input values in total. For each span, it multiplies those 40 values by a convolutional
    kernel to produce 15 output values. The second layer again looks at spans of 10
    bases, but this time the inputs are the 15 values computed by the first layer.
    It computes a new set of 15 values for each base, and so on.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们指定卷积核的宽度为10，并且每个层应包括15个滤波器（即输出）。第一层以原始特征（每个碱基四个数字）作为输入。它查看连续10个碱基的跨度，因此总共有40个输入值。对于每个跨度，它将这40个值乘以一个卷积核以产生15个输出值。第二层再次查看10个碱基的跨度，但这次的输入是第一层计算的15个值。它为每个碱基计算一组新的15个值，依此类推。
- en: To prevent overfitting, we add a dropout layer after each convolutional layer.
    The dropout probability is set to 0.5, meaning that 50% of all output values are
    randomly set to 0.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 为了防止过拟合，我们在每个卷积层后添加一个dropout层。dropout概率设置为0.5，意味着50%的所有输出值会被随机设置为0。
- en: 'Next we use a dense layer to compute the output:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们使用一个密集层来计算输出：
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We want the output to be between 0 and 1 so we can interpret it as the probability
    a particular sample contains a binding site. The dense layer can produce arbitrary
    values, not limited to any particular range. We therefore pass it through a logistic
    sigmoid function to compress it to the desired range. The input to this function
    is often referred to as *logits*. The name refers to the mathematical logit function,
    which is the inverse function of the logistic sigmoid.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望输出在0到1之间，这样我们可以将其解释为特定样本包含结合位点的概率。密集层可以产生任意值，不限于任何特定范围。因此，我们通过一个逻辑sigmoid函数将其压缩到所需的范围。这个函数的输入通常被称为*对数几率*。这个名称指的是数学对数几率函数，它是逻辑sigmoid的反函数。
- en: 'Finally, we compute the cross entropy for each sample and multiply by the weights
    to get the loss:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们计算每个样本的交叉熵并乘以权重以获得损失：
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Notice that for reasons of numerical stability, the cross entropy layer takes
    logits as input instead of the output of the sigmoid function.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，出于数值稳定性的原因，交叉熵层以对数几率作为输入，而不是逻辑sigmoid函数的输出。
- en: 'Now we are ready to train and evaluate the model. We use ROC AUC as our evaluation
    metric. After every 10 epochs of training, we evaluate the model on both the training
    and validation sets:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们准备训练和评估模型。我们使用ROC AUC作为我们的评估指标。在每10个训练周期之后，我们在训练集和验证集上评估模型：
- en: '[PRE4]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The result is shown in [Figure 6-2](#evolution_of_roc_auc_during_training_for_the_training).
    The validation set performance peaks at about 0.75 after 50 epochs, then decreases
    slightly. The training set performance continues to increase, eventually leveling
    off at around 0.87\. This tells us that training beyond 50 epochs just leads to
    overfitting, and we should halt training at that point:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示在[图6-2](#evolution_of_roc_auc_during_training_for_the_training)中。验证集性能在50个epochs后达到约0.75的峰值，然后略有下降。训练集性能继续增加，最终在约0.87左右趋于稳定。这告诉我们，超过50个epochs的训练只会导致过拟合，我们应该在那一点停止训练：
- en: '![Evolution of ROC AUC scores during training for the training set (dashed)
    and validation set (solid).](Images/dlls_0602.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![训练集（虚线）和验证集（实线）训练期间ROC AUC分数的演变。](Images/dlls_0602.png)'
- en: Figure 6-2\. Evolution of ROC AUC scores during training for the training set
    (dashed) and validation set (solid).
  id: totrans-59
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-2。训练集（虚线）和验证集（实线）训练期间ROC AUC分数的演变。
- en: 'A ROC AUC score of 0.75 is not bad, but also not wonderful. Possibly we could
    increase it by improving the model. There are lots of hyperparameters we could
    try changing: the number of convolutional layers, the kernel width for each layer,
    the number of filters in each layer, the dropout rate, etc. We could try lots
    of combinations for them, and we might find one with better performance.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ROC AUC分数为0.75并不算糟糕，但也不是很好。可能我们可以通过改进模型来提高它。我们可以尝试改变许多超参数：卷积层的数量，每层的核宽度，每层的滤波器数量，dropout率等。我们可以尝试许多组合，也许会找到一个性能更好的组合。
- en: 'But we also know there are fundamental limits to how well this model can ever
    work. The only input it looks at is the DNA sequence, and TF binding also depends
    on lots of other factors: accessibility, methylation, shape, the presence of other
    molecules, etc. Any model that ignores those factors will be limited in how accurate
    its predictions can ever be. So now let’s try adding a second input and see if
    it helps.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们也知道，这个模型能够工作的好坏存在根本限制。它只看到DNA序列作为输入，而TF结合还取决于许多其他因素：可访问性、甲基化、形状、其他分子的存在等。任何忽略这些因素的模型在预测准确性方面都会受到限制。所以现在让我们尝试添加第二个输入，看看是否有帮助。
- en: Chromatin Accessibility
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 染色质可访问性
- en: 'The name *chromatin* refers to everything that makes up a chromosome: DNA,
    histones, and various other proteins and RNA molecules. *Chromatin accessibility*
    refers to how accessible each part of the chromosome is to outside molecules.
    When the DNA is tightly wound around histones, is becomes inaccessible to transcription
    factors and other molecules. They cannot reach it, and the DNA is effectively
    inactive. When it unwinds from the histones, it becomes accessible again and resumes
    its role as a central part of the cell’s machinery.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 名称*染色质*指的是构成染色体的一切：DNA、组蛋白和各种其他蛋白质和RNA分子。*染色质可访问性*指的是染色体的每个部分对外部分子的可访问程度。当DNA紧密缠绕在组蛋白周围时，对转录因子和其他分子是不可访问的。它们无法接触到它，DNA实际上是不活跃的。当它从组蛋白中解开时，它再次变得可访问，并恢复其作为细胞机器中心部分的角色。
- en: Chromatin accessibility is neither uniform nor static. It varies between types
    of cells and stages of a cell’s life cycle. It can be affected by environmental
    conditions. It is one of the tools a cell uses to regulate the activity of its
    genome. Any gene can be turned off by packing away the area of the chromosome
    where it is located.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 染色质可访问性既不是均匀的也不是静态的。它在细胞类型和细胞生命周期阶段之间变化。它可以受到环境条件的影响。这是细胞用来调节其基因组活动的工具之一。任何基因都可以通过将其所在染色体区域包装起来而关闭。
- en: Accessibility also is constantly changing as DNA winds and unwinds in response
    to events in the cell. Instead of thinking of accessibility as a binary choice
    (accessible or inaccessible), it is better to think of it as a continuous variable
    (what fraction of the time each region is accessible).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 可访问性也在DNA对细胞内事件的反应中不断变化。与将可访问性视为二元选择（可访问或不可访问）不同，将其视为连续变量（每个区域可访问的时间比例）更好。
- en: The data we analyzed in the last section came from experiments on a particular
    kind of cell called HepG2\. The experiments identified locations in the genome
    where the transcription factor JUND was bound. The results were influenced by
    chromatin accessibility. If a particular region is almost always inaccessible
    in HepG2 cells, the experiment was very unlikely to find JUND bound there, even
    if the DNA sequence would otherwise be a perfect binding site. So, let’s try incorporating
    accessibility into our model.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一节分析的数据来自对一种名为HepG2的细胞的实验。实验确定了基因组中转录因子JUND结合的位置。结果受染色质可访问性的影响。如果HepG2细胞中的某个特定区域几乎总是不可访问，即使DNA序列本来是一个完美的结合位点，实验也很难在那里找到JUND结合。因此，让我们尝试将可访问性纳入我们的模型。
- en: 'First let’s load some data on accessibility. We have it in a text file where
    each line corresponds to one sample from our dataset (a 101-base stretch of chromosome
    22). A line contains the sample ID followed by a number that measures how accessible
    that region tends to be in HepG2 cells. We’ll load it into a Python dictionary:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 首先让我们加载一些关于可访问性的数据。我们将其保存在一个文本文件中，其中每一行对应于我们数据集中的一个样本（染色体22的101个碱基片段）。一行包含样本ID，后面跟着一个数字，表示该区域在HepG2细胞中通常有多可访问。我们将其加载到一个Python字典中：
- en: '[PRE5]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now to build the model. We will use almost exactly the same model as in the
    previous section with just two minor changes. First, we need a second feature
    input for the accessibility values. It has one number for each sample:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在开始构建模型。我们将几乎完全使用与上一节相同的模型，只有两个小改变。首先，我们需要一个第二个特征输入来表示可访问性数值。每个样本都有一个数字：
- en: '[PRE6]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now we need to incorporate the accessibility value into the calculation. There
    are many ways we might do this. For the purposes of this example, we will use
    a particularly simple method. In the previous section, we flattened the output
    of the last convolution layer, then used it as the input to a dense layer that
    calculated the output.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要将可访问性值纳入计算中。我们可以以许多方式做到这一点。在本例中，我们将使用一种特别简单的方法。在前一节中，我们将最后一个卷积层的输出展平，然后将其用作计算输出的密集层的输入。
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'This time we will do the same thing, but also append the accessibility to the
    output of the convolution:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这次我们将做同样的事情，但也将可访问性附加到卷积的输出中：
- en: '[PRE8]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: That’s all there is to the model! Now it’s time to train it.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 模型就是这样了！现在是训练的时候了。
- en: 'At this point we run into a difficulty: our model has two different `Feature`
    layers! Up until now, our models have had exactly one `Feature` layer, one `Label`
    layer, and possibly one `Weights` layer. We trained them by calling `fit(dataset)`,
    which automatically connected the correct data to each layer: the dataset’s `X`
    field for the features, `y` for the labels, and `w` for the weights. But that
    clearly can’t work when the model has more than one set of features.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一点上，我们遇到了一个困难：我们的模型有两个不同的“特征”层！到目前为止，我们的模型只有一个“特征”层，一个“标签”层，可能还有一个“权重”层。我们通过调用“fit(dataset)”来训练它们，这会自动将正确的数据连接到每个层：特征的数据集“X”字段，标签的“y”字段，权重的“w”字段。但是当模型具有多个特征集时，这显然行不通。
- en: 'This situation is handled by using a more advanced feature of DeepChem. Instead
    of passing a dataset to the model, we can write a Python generator function that
    iterates over batches. Each batch is represented by a dictionary whose keys are
    input layers, and whose values are the NumPy arrays to use for them:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用DeepChem的更高级功能来处理这种情况。我们可以编写一个Python生成器函数，该函数会迭代批次。每个批次由一个字典表示，其键是输入层，其值是用于这些层的NumPy数组：
- en: '[PRE9]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Notice how the dataset takes care of iterating through batches for us. It provides
    the data for each batch, from which we can construct whatever inputs the model
    requires.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 注意数据集如何为我们迭代批次。它为每个批次提供数据，我们可以从中构建模型所需的任何输入。
- en: 'Training and evaluation now proceed exactly as before. We use alternate forms
    of the methods that take a generator instead of a dataset:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在训练和评估过程与以前完全相同。我们使用了接受生成器而不是数据集的方法的替代形式：
- en: '[PRE10]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The result is shown in [Figure 6-3](#evolution_of_roc_auc_during_training_for_the_training_set_dashed).
    Both the training and validation set scores are improved compared to the model
    that ignored chromatin accessibility. ROC AUC score now reaches 0.91 for the training
    set and 0.80 for the validation set.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示在[图6-3](#evolution_of_roc_auc_during_training_for_the_training_set_dashed)中。与忽略染色质可访问性的模型相比，训练集和验证集的分数都有所提高。ROC
    AUC分数现在达到了训练集的0.91和验证集的0.80。
- en: '![Evolution of ROC AUC scores during training for the training set (dashed)
    and validation set (solid) when including chromatin accessibility as an input.](Images/dlls_0603.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![在包括染色质可访问性作为输入时，训练集（虚线）和验证集（实线）的ROC AUC分数在训练期间的演变。](Images/dlls_0603.png)'
- en: Figure 6-3\. Evolution of ROC AUC scores during training for the training set
    (dashed) and validation set (solid) when including chromatin accessibility as
    an input.
  id: totrans-84
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-3。在包括染色质可访问性作为输入时，训练集（虚线）和验证集（实线）的ROC AUC分数在训练期间的演变。
- en: RNA Interference
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RNA干扰
- en: For our final example, let’s turn to RNA. Much like DNA, this is a polymer composed
    of four repeating units called bases. In fact, three of the four bases are almost
    identical to their DNA versions, differing only in having one extra oxygen atom.
    The fourth base is a little more different. In place of thymine (T), RNA has a
    base called uracil (U). When a DNA sequence is transcribed into RNA, every T is
    replaced by a U.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的最后一个示例，让我们转向RNA。与DNA类似，这是由称为碱基的四个重复单元组成的聚合物。实际上，四个碱基中的三个与它们的DNA版本几乎相同，只是多了一个氧原子。第四个碱基有些不同。RNA中没有胸腺嘧啶（T），而是有一种称为尿嘧啶（U）的碱基。当DNA序列被转录成RNA时，每个T都会被U替换。
- en: The bases G and C are *complementary* to each other, in the sense that they
    have a strong tendency to bond to each other. Likewise, the bases A and T (or
    U) are complementary. If you have two strands of DNA or RNA, and every base in
    one is complementary to the corresponding base in the other, the two strands will
    tend to stick together. This fact plays a key role in lots of biological processes,
    including both transcription and translation, as well as DNA replication when
    a cell is dividing.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 碱基G和C彼此*互补*，即它们有很强的结合倾向。同样，碱基A和T（或U）是互补的。如果你有两条DNA或RNA链，其中一条中的每个碱基与另一条中对应的碱基互补，那么这两条链就会倾向于粘在一起。这个事实在许多生物过程中起着关键作用，包括转录和翻译，以及细胞分裂时的DNA复制。
- en: It also is central to something called *RNA interference*.  This phenomenon
    was only discovered in the 1990s, and the discovery led to a Nobel Prize in 2006\.
    A short piece of RNA whose sequence is complementary to part of a messenger RNA
    can bind to that mRNA. When this happens, it “silences” the mRNA and prevents
    it from being translated into a protein. The molecule that does the silencing
    is called a short interfering RNA (siRNA).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这也是所谓的*RNA干扰*的核心。这种现象直到1990年代才被发现，这一发现导致了2006年的诺贝尔奖。一小段RNA，其序列与信使RNA的一部分互补，可以结合到该mRNA上。当这种情况发生时，它会“沉默”mRNA，防止其被翻译成蛋白质。执行沉默的分子称为短干扰RNA（siRNA）。
- en: Except there is much more to the process than that. RNA interference is a complex
    biological mechanism, not just a side effect of two isolated RNA strands happening
    to stick together. It begins with the siRNA binding to a collection of proteins
    called the *RNA-induced silencing complex* (RISC). The RISC uses the siRNA as
    a template to search out matching mRNAs in the cell and degrade them. This serves
    both as a mechanism for regulating gene expression and as a defense against viruses.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，这个过程还有更多内容。RNA干扰是一个复杂的生物机制，不仅仅是两个孤立的RNA链碰巧粘在一起的副作用。它始于siRNA结合到一组被称为*RNA诱导沉默复合物*（RISC）的蛋白质。RISC使用siRNA作为模板来搜索细胞中匹配的mRNA并降解它们。这既是调节基因表达的机制，也是对抗病毒的防御。
- en: It also is a powerful tool for biology and medicine. It lets you temporarily
    “turn off” any gene you want. You can use it to treat a disease, or to study what
    happens when a gene is disabled. Just identify the mRNA you want to block, select
    any short segment of it, and create a siRNA molecule with the complementary sequence.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这也是生物学和医学的强大工具。它让你暂时“关闭”任何你想要的基因。你可以用它来治疗疾病，或者研究当一个基因被禁用时会发生什么。只需识别你想要阻断的mRNA，选择任何短片段，并创建一个具有互补序列的siRNA分子。
- en: Except that (of course!) it isn’t as simple as that. You can’t really just pick
    any segment of the mRNA at random, because (of course!) RNA molecules aren’t just
    abstract patterns of four letters. They are physical objects with distinct properties,
    and those properties depend on the sequence. Some RNA molecules are more stable
    than others. Some bind their complementary sequences more strongly than others.
    Some fold into shapes that make it harder for the RISC to bind them. This means
    that some siRNA sequences work better than others, and if you want to use RNA
    interference as a tool, you need to know how to select a good one!
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，事情并不像那么简单。你不能随意选择mRNA的任何片段，因为RNA分子并不只是四个字母的抽象模式。它们是具有独特属性的物理对象，这些属性取决于序列。一些RNA分子比其他的更稳定。一些与它们的互补序列结合得更紧密。一些折叠成形状，使得RISC更难与它们结合。这意味着一些siRNA序列比其他的更有效，如果你想将RNA干扰作为一种工具使用，你需要知道如何选择一个好的！
- en: Biologists have developed lots of heuristics for selecting siRNA sequences.
    They will say, for example, that the very first base should be either an A or
    G, that G and C bases should make up between 30% and 50% of the sequence, and
    so on. These heuristics are helpful, but let’s see if we can do better using machine
    learning.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 生物学家已经开发了许多用于选择siRNA序列的经验法则。例如，他们会说，第一个碱基应该是A或G，G和C碱基应该占序列的30%到50%，等等。这些经验法则是有帮助的，但让我们看看是否可以利用机器学习做得更好。
- en: We’ll train our model using a library of 2,431 siRNA molecules, each 21 bases
    long.^([1](ch06.xhtml#idm45806168574584)) Every one of them has been tested experimentally
    and labeled with a value between 0 and 1, indicating how effective it is at silencing
    its target gene. Small values indicate ineffective molecules, while larger values
    indicate more effective ones. The model takes the sequence as input and tries
    to predict the effectiveness.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个包含2,431个siRNA分子的库来训练我们的模型，每个分子长21个碱基。每一个都经过实验测试，并标记为0到1之间的值，表示它在沉默目标基因方面的有效性。较小的值表示无效的分子，而较大的值表示更有效的分子。模型以序列作为输入，并尝试预测有效性。
- en: 'Here is the code to build the model:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 这是构建模型的代码：
- en: '[PRE11]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This is very similar to the model we used for TF binding, with just a few differences.
    Because we are working with shorter sequences and training on less data, we have
    reduced the size of the model. There are only 2 convolutional layers, and 10 filters
    per layer instead of 15\. There also is no need for weights, since we want every
    sample to contribute equally during optimization.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 这与我们用于TF结合的模型非常相似，只是有一些区别。因为我们使用较短的序列并在较少的数据上进行训练，所以我们减小了模型的大小。只有2个卷积层，每层有10个滤波器，而不是15个。也不需要权重，因为我们希望在优化过程中每个样本都能做出贡献。
- en: We also use a different loss function. The model for TF binding was a classification
    model. Every label was either 0 or 1, and we tried to predict which of those two
    discrete values it was. But this one is a regression model. The labels are continuous
    numbers, and the model tries to match them as closely as possible. We therefore
    use the <math><msub><mi>L</mi> <mn>2</mn></msub></math> distance as our loss function,
    which tries to minimize the mean squared difference between the true and predicted
    labels.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还使用了不同的损失函数。TF结合的模型是一个分类模型。每个标签要么是0，要么是1，我们试图预测这两个离散值中的哪一个。但这个模型是一个回归模型。标签是连续的数字，模型试图尽可能地匹配它们。因此，我们使用<math><msub><mi>L</mi>
    <mn>2</mn></msub></math>距离作为我们的损失函数，它试图最小化真实标签和预测标签之间的均方差。
- en: 'Here is the code to train the model:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这是训练模型的代码：
- en: '[PRE12]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: For TF binding, we used ROC AUC as our evaluation metric, which measures how
    accurately the model can divide the data into two classes. That is appropriate
    for a classification problem, but it doesn’t make sense for a regression problem,
    so instead we use the Pearson correlation coefficient. This is a number between
    –1 and 1, where 0 means the model provides no information at all and 1 means the
    model perfectly reproduces the experimental data.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 对于TF结合，我们使用ROC AUC作为我们的评估指标，它衡量模型如何将数据分成两类。这对于分类问题是合适的，但对于回归问题来说没有意义，因此我们使用皮尔逊相关系数。这是一个介于-1和1之间的数字，其中0表示模型根本没有提供信息，1表示模型完美地重现了实验数据。
- en: The result is shown in [Figure 6-4](#evolution_of_the_pearson_correlation_coefficient_during_training_for_the_training_set_dashed_and_validation_set_solid).
    The validation set score peaks at 0.65 after 50 epochs. The training set score
    continues to increase, but since there is no further improvement to the validation
    set score this is just overfitting. Given the simplicity of the model and the
    limited amount of training data, a correlation coefficient of 0.65 is quite good.
    More complex models trained on larger datasets do slightly better, but this is
    already very respectable performance.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示在[图6-4](#evolution_of_the_pearson_correlation_coefficient_during_training_for_the_training_set_dashed_and_validation_set_solid)中。验证集得分在50个epochs后达到0.65的峰值。训练集得分继续增加，但由于验证集得分没有进一步提高，这只是过拟合。考虑到模型的简单性和有限的训练数据量，相关系数0.65已经相当不错。在更大数据集上训练的更复杂模型稍微更好，但这已经是非常可观的表现了。
- en: '![Evolution of the Pearson correlation coefficient during training for the
    training set (dashed) and validation set (solid).](Images/dlls_0604.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![在训练过程中Pearson相关系数的演变，包括训练集（虚线）和验证集（实线）。](Images/dlls_0604.png)'
- en: Figure 6-4\. Evolution of the Pearson correlation coefficient during training
    for the training set (dashed) and validation set (solid).
  id: totrans-103
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图6-4\. 在训练过程中Pearson相关系数的演变，包括训练集（虚线）和验证集（实线）。
- en: Conclusion
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: A genome is an enormously complicated machine, with a vast number of parts all
    working together to direct and carry out the manufacture of proteins and other
    molecules. Deep learning is a powerful tool for studying it. Neural networks can
    pick out the subtle patterns in genomic data, providing insight into how the genome
    functions as well as making predictions about it.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 基因组是一个极其复杂的机器，有大量的部分共同工作，指导和执行蛋白质和其他分子的制造。深度学习是研究它的强大工具。神经网络可以挑出基因组数据中微妙的模式，提供对基因组功能的洞察，同时也可以对其进行预测。
- en: Even more than most other areas of the life sciences, genomics produces huge
    amounts of experimental data. For example, a single human genome sequence includes
    more than six billion bases. Traditional statistical techniques struggle to find
    the signal buried in all that data. They often require simplifying assumptions
    that do not reflect the complexity of genomic regulation. Deep learning is uniquely
    suited to processing this data and advancing our understanding of the core functions
    of living cells.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 与生命科学的大多数其他领域相比，基因组学产生了大量的实验数据。例如，单个人类基因组序列包含超过60亿个碱基。传统的统计技术很难在所有这些数据中找到信号。它们经常需要简化假设，这些假设并不能反映基因组调控的复杂性。深度学习非常适合处理这些数据，并推动我们对生命细胞核心功能的理解。
- en: ^([1](ch06.xhtml#idm45806168574584-marker)) Huesken, D., J. Lange, C. Mickanin,
    J. Weiler, F. Asselbergs, J. Warner, B. Meloon, S. Engel, A. Rosenberg, D. Cohen,
    M. Labow, M. Reinhardt, F. Natt, and J. Hall, “Design of a Genome-Wide siRNA Library
    Using an Artificial Neural Network.” *Nature Biotechnology* 23:995–1001\. 2005\.
    *[https://doi.org/10.1038/nbt1118](https://doi.org/10.1038/nbt1118)*.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch06.xhtml#idm45806168574584-marker)) Huesken, D., J. Lange, C. Mickanin,
    J. Weiler, F. Asselbergs, J. Warner, B. Meloon, S. Engel, A. Rosenberg, D. Cohen,
    M. Labow, M. Reinhardt, F. Natt, and J. Hall, “Design of a Genome-Wide siRNA Library
    Using an Artificial Neural Network.” *Nature Biotechnology* 23:995–1001\. 2005\.
    *[https://doi.org/10.1038/nbt1118](https://doi.org/10.1038/nbt1118)*.
