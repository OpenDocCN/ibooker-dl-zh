<html><head></head><body><section data-pdf-bookmark="Appendix A. Designing AI-Powered Applications" data-type="appendix" epub:type="appendix"><div class="appendix" id="appendix_a_designing_ai_powered_applications_1748539915159206">
<h1><span class="label">Appendix A. </span>Designing AI-Powered Applications</h1>

<p>This appendix explores a general approach to designing <em>AI-powered applications</em>—software applications<a contenteditable="false" data-primary="designing AI-powered applications" data-type="indexterm" id="daipa-1"/> that incorporate machine learning models to power one or more of their core features.</p>

<p>In recent years, there has been growing interest in the concept of “AI products”<a contenteditable="false" data-primary="AI product" data-type="indexterm" id="id669"/> and the application of <a href="https://oreil.ly/NKBgD">“product thinking”</a> to ML- and AI-enabled systems. This approach focuses on AI capabilities not just as technical components, but as integral features that solve real user problems. <a data-type="xref" href="#appendix_a_figure_1_1748539915146872">Figure A-1</a> shows an example of an AI product: the O’Reilly Learning Platform’s generative AI assistant, <em>Answers</em>. This assistant is designed to help users interact with book content and conduct research across the publisher’s book corpus using natural language queries.</p>


<p>I define an AI product as a software solution that:</p>

<dl>
	<dt>Delivers value</dt>
	<dd>
	<p>AI products provide meaningful value to users, stakeholders, or systems, whether by automating tasks, enabling new capabilities, improving efficiency, reducing costs, enhancing user experience and interactivity, boosting productivity, or generating new content.</p>
	</dd>
	<dt>Incorporates AI technologies</dt>
	<dd>
	<p>AI products utilize technologies such as machine learning, deep learning, natural language processing (NLP), and computer vision to enable or enhance <span class="keep-together">functionality</span>.</p>
	</dd>
	<dt>Interacts and adapts</dt>
	<dd>
	<p>AI systems can interpret and respond to inputs (such as data, user interactions, or other systems) in a way that is perceived as intelligent, and often they can learn from those interactions and adapt and improve over time.</p>
	</dd>
	<dt>Integrates operationally</dt>
	<dd>
	<p>AI systems can be integrated into broader systems or processes, whether software systems (like mobile or web apps) or real-world processes (e.g., in manufacturing or customer service).</p>
	</dd>
</dl>


<figure><div class="figure" id="appendix_a_figure_1_1748539915146872"><img src="assets/taie_a001.png"/>
<h6><span class="label">Figure A-1. </span>An example of an AI product</h6>
</div></figure>

<p>In general, AI enhances software products, but it is seldom the product itself. Next, we’ll turn our attention to the design process for AI products. Note that in this context, I use the terms <em>AI products</em> and <em>AI systems</em> interchangeably.</p>

<section data-pdf-bookmark="Backward Thinking for Designing AI Systems" data-type="sect1"><div class="sect1" id="appendix_a_backward_thinking_for_designing_ai_systems_1748539915159483">
<h1>Backward Thinking for Designing AI Systems</h1>

<p>It’s important to start an AI endeavor with the business goal in mind, because only about <a href="https://oreil.ly/Ha6oK">10% of AI PoCs</a> succeed in production. Often, alignment to the business problem—<a href="https://oreil.ly/MRKCZ">solving real users’ pain points</a>—is the reason for this success.</p>

<p><em>Backward thinking</em> provides a strategic framework for scoping, planning, and executing ML projects. <a href="https://oreil.ly/Si4EX">Starting with the end in mind</a> helps maximize the chances of delivering a useful solution while avoiding common pitfalls like poorly defined objectives, irrelevant features, and misaligned architectures.</p>

<p class="pagebreak-before">It does, however, require a clear and accurate vision of the end goal, making it less suitable for exploratory research where the exact objectives are uncertain or in cases where problem decomposition is particularly complex.</p>

<p>Key benefits of a backward-thinking approach include:</p>

<dl>
	<dt>Clear scope up front</dt>
	<dd>
	<p>Starting with the desired outcome and working backward helps to define project requirements, feasibility, and success metrics. This prevents scope creep and keeps development focused.</p>
	</dd>
	<dt>Business-aligned AI products</dt>
	<dd>
	<p>By tying AI development to concrete goals, backward thinking ensures that the end product delivers real value and solves the original business problem.</p>
	</dd>
	<dt>Minimum viable data</dt>
	<dd>
	<p>Working backward from the desired output helps clarify which input features and datasets are needed.</p>
	</dd>
	<dt>Narrowed solution space</dt>
	<dd>
	<p>With a well-defined end goal, developers can research and select among model architectures that have been proven to work well for similar problems in the past.</p>
	</dd>
	<dt>Iterative-incremental development</dt>
	<dd>
	<p>Backward thinking encourages starting with simple prototypes, rapidly testing ideas, and incrementally increasing complexity. This agile approach surfaces issues early and allows for faster iterations.</p>
	</dd>
</dl>
</div></section>

<section data-pdf-bookmark="The Machine Learning Canvas" data-type="sect1"><div class="sect1" id="appendix_a_the_machine_learning_canvas_1748539915159571">
<h1>The Machine Learning Canvas</h1>

<p>To apply the backward-thinking<a contenteditable="false" data-primary="designing AI-powered applications" data-secondary="Machine Learning Canvas" data-type="indexterm" id="daipa-mlc-1"/> approach in practice, teams can use a strategic planning tool<a contenteditable="false" data-primary="Machine Learning Canvas" data-type="indexterm" id="ml-c-1"/> such as the <a href="https://oreil.ly/32fj3">Machine Learning Canvas</a> (see <a data-type="xref" href="#appendix_a_figure_2_1748539915146912">Figure A-2</a>). This framework helps anticipate hidden costs, identify bottlenecks, specify requirements, and create a clear roadmap for an ML project.</p>



<p>By aligning stakeholders on the end goal and value proposition from the outset, the Machine Learning Canvas helps ensure that the ML solution is designed to address user needs, rather than being solely technology-driven.</p>



<p>Throughout the planning process, the canvas keeps the focus on end-user value, placing the user and their needs and the overall software architecture requirements at the center of all decision making and technology choices. One of its key benefits is its structured approach to defining the ML task and prediction requirements. In addition, the canvas prompts early identification of data requirements and constraints, helping teams assess feasibility and start planning for data collection and labeling. Crucially, filling it out helps teams to consider how models will be used, monitored, and updated over time. This holistic view encourages a more thorough, forward-looking approach to ML project planning and execution.</p>

<figure><div class="figure" id="appendix_a_figure_2_1748539915146912"><img src="assets/taie_a002.png"/>
<h6><span class="label">Figure A-2. </span>The Machine Learning Canvas, developed by Louis Dorard (source: <a href="https://oreil.ly/32fj3"><em>https://oreil.ly/32fj3</em></a>)</h6>
</div></figure>

<p>The canvas also serves as a tool for collaboration between different roles, such as data scientists, software engineers, and AI product managers. Its visual format enables a shared understanding of the project and its requirements, facilitating teamwork and communication.</p>

<p>Importantly, the canvas supports rapid iteration, enabling teams to update it easily as they gain a better understanding of the problem space or encounter new constraints. Finally, it serves as a useful documentation artifact, offering a high-level overview that preserves institutional knowledge for current and future team members.</p>

<p>Let’s go through the 10 building blocks of the Machine Learning Canvas, starting with the Value Proposition section.</p>

<section data-pdf-bookmark="Value Proposition" data-type="sect2"><div class="sect2" id="appendix_a_value_proposition_1748539915159649">
<h2>Value Proposition</h2>

<p>In accordance with backward thinking, we start with the business question. When creating an AI product with a business- and human-centered approach, the most important considerations are: Who are our users? What values do they hold? What problems are we solving for them?</p>

<p>The Value Proposition section of the Machine Learning Canvas is where these questions are addressed. It should emphasize the importance of understanding and addressing critical user needs or business objectives, identifying the target audience, and articulating the specific value that the system will provide. A clear value proposition should define the target audience, address their significant need or challenge, articulate the offered value, and highlight what sets the offering apart from competitors. Here’s a suggested template for an effective value proposition statement:</p>

<ul class="simplelist">
	<li>
	<p><strong>For</strong> [target customer]</p>
	</li>
	<li>
	<p><strong>w</strong><strong>ho</strong> [statement of the need or opportunity].</p>
	</li>
	<li>
	<p><strong>The</strong> [product name] is a [product category]</p>
	</li>
	<li>
	<p><strong>t</strong><strong>hat</strong> [statement of key benefit—compelling reason to buy or use].</p>
	</li>
	<li>
	<p><strong>Unlike</strong> [primary competitive alternative]</p>
	</li>
	<li>
	<p><strong>o</strong><strong>ur AI product</strong> [statement of primary differentiation].</p>
	</li>
</ul>

<p>Using this template helps to clearly outline the target audience, the main problems the product solves, its competitive edge, and the unique benefits it offers. This structured approach enables effective communication of the value proposition to potential users.</p>

<p>Here’s an illustrative example to demonstrate how the template can be implemented for a hypothetical AI-powered personal finance app, SmartFinance, indicating who the target audience is, how it satisfies those users’ needs, and its unique benefits/how it distinguishes itself from traditional solutions:</p>

<ul class="simplelist">
	<li>
	<p><strong>For</strong> individuals seeking to optimize their finances</p>
	</li>
	<li>
	<p><strong>w</strong><strong>ho</strong> need a simple, effective way to track spending, budget, and save money.</p>
	</li>
	<li>
	<p><strong>The</strong> SmartFinance app is an AI-powered personal finance app</p>
	</li>
	<li>
	<p><strong>t</strong><strong>hat</strong> provides personalized budgeting and saving recommendations based on your spending habits and financial goals.</p>
	</li>
	<li>
	<p><strong>Unlike</strong> traditional banking apps or manual budgeting methods</p>
	</li>
	<li>
	<p><strong>o</strong><strong>ur AI product</strong> uses advanced AI algorithms to analyze your financial data and offers actionable insights to improve your financial health, tailored to your unique circumstances.</p>
	</li>
</ul>

<p>It’s worth putting in the time to deeply understand the user or business problem—otherwise, you risk jumping to solutions without thoroughly grasping the challenge. To craft a compelling value proposition statement, spend some time with the Value Proposition Canvas, shown in <a data-type="xref" href="#appendix_a_figure_3_1748539915146937">Figure A-3</a>.</p>

<figure><div class="figure" id="appendix_a_figure_3_1748539915146937"><img src="assets/taie_a003.png"/>
<h6><span class="label">Figure A-3. </span>The Value Proposition Canvas (source: <a href="https://oreil.ly/4pA9C"><em>https://oreil.ly/4pA9C</em></a>)</h6>
</div></figure>

<p>The Value Proposition Canvas<a contenteditable="false" data-primary="Value Proposition Canvas" data-type="indexterm" id="id670"/> is designed to help organizations create products and services that align with customer needs. It enables teams to better understand user pain points and address them effectively by comparing identified needs and challenges with the value being offered, ensuring a strong fit between what customers want and what is delivered. Developed by Alexander Osterwalder as an extension of his <a href="https://oreil.ly/bhN5J">Business Model Canvas</a>, it places a specific focus on understanding customers and crafting compelling value propositions. The Value Proposition Canvas has two sides: the Customer Profile on the right outlines customer jobs, challenges (pains), and benefits (gains), while the Value Map on the left illustrates how the proposed products or services create value by generating benefits and reducing challenges. The objective is to align the Customer Profile with the Value Map, guaranteeing that the value proposition meaningfully addresses key customer needs.</p>

<p>After clarifying the target audience, their problems, and that AI is the most suitable solution, the next step is to identify the success criteria. Let’s transition to the Machine Learning Canvas’s next building block: Monitoring.</p>
</div></section>

<section data-pdf-bookmark="Monitoring" data-type="sect2"><div class="sect2" id="appendix_a_monitoring_1748539915159706">
<h2>Monitoring</h2>

<p>The Monitoring section of the canvas should outline the metrics that are important for assessing value creation and determining the impact of the ML system in production. Since the model will function as a component within a broader software system, taking a holistic perspective on the success of the AI product is essential. This calls for a diverse set of metrics, which can be categorized as follows:</p>

<dl>
	<dt>Business metrics</dt>
	<dd>
	<p>Assess the business value generated from decisions influenced by the ML model’s predictions. Ultimately, value is created through decision making, with predictions serving as inputs to improve those decisions. Examples of business metrics include conversion rate, revenue growth, and cost reduction. For instance, in financial operations involving extensive cloud usage, infrastructure cost is a key efficiency metric for technical teams.</p>
	</dd>
	<dt>AI product health metrics</dt>
	<dd>
	<p>Vital for managing an AI product’s effectiveness and long-term viability. A key focus area is measuring user engagement—for example, frequency and depth of interactions with AI features, as well as daily and monthly active users (DAU and MAU). Retention metrics, such as churn rate and cohort analysis, are essential for gauging user commitment and product stickiness over time. Another important metric is net promoter score (NPS), which measures customer loyalty and satisfaction by asking users how likely they are to recommend the AI product to others on a scale of 0–10.</p>
	</dd>
	<dt>AI technical metrics</dt>
	<dd>
	<p>Evaluate the effectiveness of the AI model. Important metrics include model degradation, data drift, concept drift, accuracy, and standard performance measures like F1 score, precision, and recall.</p>
	</dd>
	<dt>System technical metrics</dt>
	<dd>
	<p>Provide insights into the overall behavior of the system. Metrics such as robustness, scalability, and throughput are essential for understanding the system’s technical health.</p>
	</dd>
</dl>

<p>Including metrics from all of these categories in the Monitoring section of the canvas enables a comprehensive analysis of the AI product’s success, capturing business impact, user engagement, and technical performance.</p>

<p>The remaining parts of the Machine Learning Canvas reflect the two main phases of every ML project: the training and prediction phases. Let’s begin with the latter.</p>
</div></section>

<section data-pdf-bookmark="The Prediction Phase" data-type="sect2"><div class="sect2" id="appendix_a_the_prediction_phase_1748539915159767">
<h2>The Prediction Phase</h2>

<p>Following the backward thinking strategy, start by planning how the machine learning model will be integrated into the larger software system. The Prediction section of the Machine Learning Canvas should reflect how the model will be used, even before it has been trained. The objective is to prototype and evaluate how the AI system will solve the business problem defined earlier.</p>

<section data-pdf-bookmark="Prediction Task" data-type="sect3"><div class="sect3" id="appendix_a_prediction_task_1748539915159825">
<h3>Prediction Task</h3>

<p>When working on a machine learning task, you need to define the input, output, and problem type. Inputs represent real-world objects or features, and outputs are the answers to specific questions the model aims to predict. In supervised learning, the system learns from example inputs paired with known outputs. The output is usually provided after a certain time delay, and predictive models are trained to predict it in advance.</p>

<p>When defining a prediction task, consider existing human baselines and alternative prediction methods. These can provide valuable insights for data preparation and model building. When creating a new model without an existing production method, start by establishing a basic benchmark—something intuitive and easy to calculate. This “heuristic” benchmark might be based on constants, rules of thumb, or aggregate statistics.</p>

<p>Avoid using a simple machine learning model, such as linear regression, as your benchmark; instead, opt for a more interpretable and easily explainable approach. For example, for anomaly detection, you might decide to use the 99th percentile value calculated from the training dataset as a heuristic benchmark. In a recommendation system, you could suggest the most popular item in the category of the customer’s last purchase.</p>
</div></section>

<section data-pdf-bookmark="Decisions" data-type="sect3"><div class="sect3" id="appendix_a_decisions_1748539915159879">
<h3>Decisions</h3>

<p>In any prediction-based system, value is ultimately delivered through the decisions it informs. AI’s successful alignment with business goals depends on how well the ML model integrates into the complete workflow—the model provides predictions or probabilities, but the real impact comes from how those predictions are used.</p>

<p>To connect the work in the Prediction Task part of the canvas to actionable outcomes, you need to consider how the predictions will influence decisions. How will those predictions generate the intended business value? Asking, “What if I had perfect predictions?” can make it easier to reflect on this before investing a significant amount of time in model building.</p>

<p class="pagebreak-before"><a data-type="xref" href="#appendix_a_table_1_1748539915151631">Table A-1</a> provides examples that clarify the distinction between predictions and decisions. Prediction generally involves estimating or forecasting unknown values based on data, while decision making involves taking actions informed by those <span class="keep-together">predictions</span>.</p>

<table class="striped" id="appendix_a_table_1_1748539915151631">
	<caption><span class="label">Table A-1. </span>The distinction between predictions and decisions in machine learning contexts</caption>
	<thead>
		<tr>
			<th>Use case</th>
			<th>Prediction</th>
			<th>Illustrative decision</th>
		</tr>
	</thead>
	<tbody>
		<tr>
			<td>
			<p>Credit scoring</p>
			</td>
			<td>
			<p>Probability that a customer will default on a loan</p>
			</td>
			<td>
			<p>If the probability of defaulting is greater than 20%, reject the loan application.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Healthcare</p>
			</td>
			<td>
			<p>Probability that a patient has a particular disease based on symptoms and test results</p>
			</td>
			<td>
			<p>If the probability exceeds a defined threshold, recommend a specific treatment plan or further diagnostic testing.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Retail inventory management</p>
			</td>
			<td>
			<p>Forecasted demand for a product in the next month</p>
			</td>
			<td>
			<p>If the predicted demand exceeds current inventory levels by 10%, order additional stock.</p>
			</td>
		</tr>
		<tr>
			<td>
			<p>Automated trading</p>
			</td>
			<td>
			<p>Forecasted price movement of a stock in the next 10 minutes based on market data</p>
			</td>
			<td>
			<p>If the stock is predicted to rise by more than 2%, buy a specified number of shares.</p>
			</td>
		</tr>
	</tbody>
</table>

<p>Decisions always follow predictions. In this way, prediction results and subsequent actions are integrated into the broader workflow. Simply put, you can describe how the ML model is embedded into business processes by defining the upstream tasks, identifying the ML-driven solution, and specifying the downstream tasks. See <a data-type="xref" href="#appendix_a_figure_4_1748539915146963">Figure A-4</a> for a visualization of workflow integration.</p>

<figure><div class="figure" id="appendix_a_figure_4_1748539915146963"><img src="assets/taie_a004.png"/>
<h6><span class="label">Figure A-4. </span>Workflow integration canvas to specify the upstream and downstream tasks or processes and the usage of the ML model output (source: idalab.de)</h6>
</div></figure>
</div></section>

<section data-pdf-bookmark="Making Predictions" data-type="sect3"><div class="sect3" id="appendix_a_making_predictions_1748539915159935">
<h3>Making Predictions</h3>

<p>Filling out the Decisions part of the canvas helped you determine how predictions and decisions should be made. This section specifies the requirements for prediction serving. <em>Serving</em> refers to the process of deploying a trained machine learning model into a production environment, where it can receive input data and generate predictions or outputs. The goal of any serving architecture is to meet requirements for consistent and efficient outputs (considering performance, availability, and operational SLAs, as well as prediction volume), while minimizing unnecessary features, complexity, and cost.</p>

<p>The information you provide in this part of the canvas serves as the foundation for designing the serving architecture, which is always use case–specific. What is the expected frequency and volume of predictions? Are there constraints related to data recency or the time required to compute features?</p>

<p>Answering the question of how predictions should be computed will clarify the preferred prediction consumption paradigm, such as batch or real-time. Batch model serving processes data in batches periodically, while real-time serving generates predictions on individual data points as they arrive. For example, batch serving might be used for demand forecasting, where a model periodically analyzes historical sales data to predict future product demand for inventory planning. Real-time model serving might be used in anomaly detection, where IoT sensor data streams are monitored continuously to identify issues as they arise. Real-time serving is necessary when low-latency responses are needed to trigger actions or immediately enhance user <span class="keep-together">experiences</span>.</p>

<p>The appropriate serving architecture—whether batch, real-time, or hybrid—depends on latency, throughput, and scalability needs. It may also require optimizing the model for efficient inference using techniques such as quantization, pruning, or distillation. Compute resources (e.g., CPU/GPU) must be provisioned, and scaling strategies may need to be implemented to meet performance demands. Serving mechanisms might include exposing models via REST APIs, Kubernetes deployments, or serverless functions, depending on the infrastructure.</p>

<p>It’s crucial to understand these technical aspects to ensure robust and reliable machine learning model deployment and serving in production environments. To that end, you should answer questions such as:</p>

<ol>
	<li>
	<p>When do we need to generate predictions?</p>
	</li>
	<li>
	<p>What latency and frequency constraints do we have?</p>
	</li>
	<li>
	<p>Where will predictions be generated?</p>
	</li>
	<li>
	<p>What does the prediction generation (serving) pipeline look like?</p>
	</li>
</ol>

<p>By completing this part of the canvas, you will determine whether you need real-time or batch predictions and identify the serving metrics to monitor in production. Next, you’ll outline your strategy for deploying the model into production.</p>
</div></section>

<section data-pdf-bookmark="Impact Simulation" data-type="sect3"><div class="sect3" id="appendix_a_impact_simulation_1748539915159988">
<h3>Impact Simulation</h3>

<p>This part of the canvas focuses on establishing methods and metrics to evaluate the system before deployment. The goal is to answer the question, “How well would the system perform on these test cases?” It’s important for the simulation to be reliable, which means it should be tested on scenarios that are representative of real-world use cases.</p>

<p>Similarly, during training, the data should accurately reflect the conditions the system will face in production. However, you shouldn’t give the system too much prior information about what it will be tested on. When selecting a test set, it is crucial to ensure that it produces meaningful, interpretable results within the AI system’s domain. A common approach is to use the most recent data as a test set, to assess how well the system would have performed if it had been deployed days, weeks, or months earlier.</p>

<p>In the Impact Simulation section of the Machine Learning Canvas, you should answer the following questions:</p>

<ol>
	<li>
	<p>How will we evaluate system performance pre-deployment?</p>
	</li>
	<li>
	<p>What metrics best reflect value generation?</p>
	</li>
	<li>
	<p>What should the model audit pipeline look like?</p>
	</li>
	<li>
	<p>What model governance steps are needed?</p>
	</li>
	<li>
	<p>What model guards need to be implemented?</p>
	</li>
</ol>

<p>It’s essential to evaluate the system’s performance prior to deploying it into production. You should use both offline metrics (accuracy, precision, recall, F1 score, etc.) and online metrics (conversion rate, latency, availability, etc.) for this. These metrics will help you determine how the model performs in real-world scenarios and whether it meets the desired business objectives.</p>
</div></section>
</div></section>

<section data-pdf-bookmark="The Training Phase" data-type="sect2"><div class="sect2" id="appendix_a_the_training_phase_1748539915160046">
<h2>The Training Phase</h2>

<p>As mentioned previously, every ML project consists of two main phases: training and prediction. We covered the prediction phase in the previous section; now it’s time to consider training. This phase includes all the tasks involved in building an ML model: data preparation, new data collection, feature engineering, and training (and retraining) the model itself. Following the backward thinking process, you have finally arrived at the true origin of any ML system—data.</p>

<section data-pdf-bookmark="Data Sources" data-type="sect3"><div class="sect3" id="appendix_a_data_sources_1748539915160104">
<h3>Data Sources</h3>

<p>AI systems fundamentally rely on data. Creating an inventory of all possible data sources is one of the most critical steps in an ML project, because data availability often determines the project’s feasibility and success.</p>

<p>Key questions to address about data sources include:</p>

<ol>
	<li>
	<p>What internal and external data sources can we leverage?</p>
	</li>
	<li>
	<p>How can we access and collect this data?</p>
	</li>
	<li>
	<p>What will the data ingestion pipeline look like?</p>
	</li>
</ol>

<p>The output of this step should be a list of potential data sources, relevant APIs, and access methods. If the required data isn’t currently accessible, this may signal the need for a separate data engineering project to enable model development. This stage often reveals hidden costs that may make an ML project unfeasible.</p>

<p>The <a href="https://oreil.ly/hsXsZ">Data Landscape Canvas</a> by Datentreiber is a useful tool for conducting a data inventory in your organization. It might also be used as part of the workshop for AI product design.</p>
</div></section>

<section data-pdf-bookmark="Data Collection" data-type="sect3"><div class="sect3" id="appendix_a_data_collection_1748539915160158">
<h3>Data Collection</h3>

<p>Data usually mirrors the world. As the world changes, ML models need to be updated to reflect these changes. This is done by collecting and incorporating new data. Retraining a model involves both gathering and labeling this new data. In this section of the Machine Learning Canvas, you should clarify how data will be continuously gathered and labeled.</p>

<p>The following questions are essential for ensuring a reliable retraining process:</p>

<ol>
	<li>
	<p>How is new data for model rebuilding collected?</p>
	</li>
	<li>
	<p>What is the labeling process?</p>
	</li>
	<li>
	<p>What does the data collection pipeline look like?</p>
	</li>
	<li>
	<p>What does the data preprocessing pipeline look like?</p>
	</li>
</ol>

<p>Completing this section increases the project’s feasibility and helps you anticipate the cost of building the necessary data infrastructure.</p>
</div></section>

<section data-pdf-bookmark="Building Models" data-type="sect3"><div class="sect3" id="appendix_a_building_models_1748539915160212">
<h3>Building Models</h3>

<p>In this section of the Machine Learning Canvas, you reflect on architectural decisions for the model training subsystem (in addition to the model serving subsystem). Here, you should answer the following questions:</p>

<ol>
	<li>
	<p>How frequently do we need to update models?</p>
	</li>
	<li>
	<p>How many models do we need in production?</p>
	</li>
	<li>
	<p>What time and computing constraints do we have for model training?</p>
	</li>
	<li>
	<p>What does the ML model retraining pipeline look like?</p>
	</li>
</ol>

<p>The output should be a clear set of requirements for the model-building process. It’s important to recognize that the frequency and approach to model training depend on several factors. Different strategies can be used depending on the use case, data velocity, and business needs:</p>

<ul>
	<li>
	<p><em>Ad hoc model building </em>involves training models on demand to answer specific business questions or address unexpected issues. For example, a retailer might analyze recent sales data using clustering to identify emerging customer segments for a targeted marketing campaign. Ad hoc analysis allows organizations to quickly gain insights from data to adapt to changing circumstances. These models are typically one-off and not put into regular production.</p>
	</li>
	<li>
	<p><em>Scheduled model building</em> involves updating ML models at regular intervals to ensure continued accuracy as new data becomes available, without the need for manual intervention. The update frequency depends on the rate of data change and business requirements. For example, for an ecommerce demand forecasting model, weekly updates might be sufficient for business needs.</p>
	</li>
	<li>
	<p>In <em>event-driven model building</em>, models are automatically trained in response to triggers such as data volume thresholds or drops in accuracy. For example, a fraud detection model might be retrained when the percentage of flagged transactions exceeds a specified threshold, indicating model drift. Event-based approaches require robust MLOps infrastructure to monitor performance and orchestrate retraining workflows.</p>
	</li>
</ul>

<p>Outlining the complexity and frequency of model training helps guide the design and implementation of the training subsystem and ensures alignment with the operational requirements of the ML system.</p>
</div></section>

<section data-pdf-bookmark="Features" data-type="sect3"><div class="sect3" id="appendix_a_features_1748539915160263">
<h3>Features</h3>

<p>The final building block of the ML project is feature engineering. This part focuses on creating input representations from raw data sources that will be available at prediction time. Key questions to consider include:</p>

<ol>
	<li>
	<p>What attributes of the input data are useful for the ML task?</p>
	</li>
	<li>
	<p>Will we need additional features that are not present in the raw sources?</p>
	</li>
	<li>
	<p>How can we represent the raw data as features?</p>
	</li>
	<li>
	<p>What strategies can we implement to handle sensitive data such as PII?</p>
	</li>
	<li>
	<p>How are sensitive attributes (race, color, gender, religion, origin, age, pregnancy, family status) protected?</p>
	</li>
	<li>
	<p>To what extent might features become discriminatory in the AI product?</p>
	</li>
	<li>
	<p>What does the feature engineering pipeline look like?</p>
	</li>
</ol>

<p>The output should be a list of potential features to extract from the raw data or obtain from elsewhere. You should also consider aspects such as data preprocessing, feature creation complexity, feature selection and dimensionality reduction, and evaluation routines, because all of these impact the architecture of the feature engineering <span class="keep-together">subsystem</span>.</p>

<p>Domain knowledge plays a crucial role in feature engineering for machine learning projects, as it guides the selection and transformation of meaningful features. Involving subject matter experts in the feature design process increases the likelihood of building a reliable<a contenteditable="false" data-primary="designing AI-powered applications" data-secondary="Machine Learning Canvas" data-startref="daipa-mlc-1" data-type="indexterm" id="id671"/> and effective<a contenteditable="false" data-primary="designing AI-powered applications" data-startref="daipa-1" data-type="indexterm" id="id672"/> AI product<a contenteditable="false" data-primary="Machine Learning Canvas" data-startref="ml-c-1" data-type="indexterm" id="id673"/>.</p>
</div></section>
</div></section>
</div></section>
</div></section></body></html>