["```py\n$ sudo apt update\n$ sudo apt install python3-pip\n```", "```py\n$ sudo apt install python3.8-venv\n$ mkdir <new directory for venv>\n$ python -m venv <path to venv directory>\n```", "```py\n$ source <path to venv>/bin/activate\n```", "```py\n$ python -m ensurepip --upgrade\n```", "```py\n$ mkdir <new directory>\n$ python -m venv <path to venv directory>\n```", "```py\n$ source <path to venv>/bin/activate\n```", "```py\n$ conda create --name <name of env> python=<your version of python>\n```", "```py\n$ conda activate <your env name>\n```", "```py\n$ pip install jupyterlab\n$ pip install notebook\n```", "```py\n$ conda install -c conda-forge jupyterlab\n$ conda install -c conda-forge notebook\n```", "```py\n$ pip install ipywidgets\n$ conda install -c conda-forge ipywidgets\n```", "```py\n$ jupyter nbextension install --user --py widgetsnbextension\n$ jupyter nbextension enable --user --py widgetsnbextension\n```", "```py\n$git clone https://github.com/Optimization-Algorithms-Book/Code-Listings.git  \n```", "```py\nimport sys\nsys.path.insert(0, '../')\n```", "```py\nfrom google.colab import drive\ndrive.mount('/content/drive')\n```", "```py\n$pip install optalgotools \n```", "```py\nfrom optalgotools.problems import TSP\nfrom optalgotools.algorithms import SimulatedAnnealing\n```", "```py\n$pip install scipy\n```", "```py\nimport numpy as np\nimport scipy\nfrom scipy.optimize import linprog\n\nc = -np.array([5,12])                                            ①\n\nlhs_constraints=([3,2],                                          ②\n                 [1,3])                                          ③\n\nrhs_constraints=([160,                                           ④\n                  200])                                          ⑤\n\nbounds = [(0, scipy.inf), (0, scipy.inf)]                        ⑥\n\nresults = linprog(c=c, A_ub=lhs_constraints, b_ub=rhs_constraints,\n➥ bounds=bounds, method='highs-ds')                             ⑦\n\nprint('LP Solution:')                                            ⑧\nprint(f'Profit: = {-round(results.fun,2)} $')                    ⑧\nprint(f'Make {round(results.x[0],0)} small sets, and make        ⑧\n{round(results.x[1],0)} large sets')                             ⑧\n```", "```py\nLP Solution:\nProfit: = 811.43 $\nMake 11.0 small sets, and make 63.0 large sets\n```", "```py\n$pip install pulp\n```", "```py\n#!pip install pulp\nfrom pulp import LpMaximize, LpProblem, LpVariable, lpSum, LpStatus\n\nmodel = LpProblem(name='ChessSet', sense=LpMaximize)                      ①\n\nx1 = LpVariable('SmallSet', lowBound = 0, upBound =  None, cat='Integer') ②\nx2 = LpVariable('LargeSet', lowBound = 0, upBound =  None, cat='Integer') ②\n\nmodel += (3*x1 + 2*x2 <=160, 'Machining time constraint')                 ③\nmodel += (  x1 + 3*x2 <= 200, 'Weight constraint')                        ③\n\nprofit= 5*x1 + 12*x2                                                      ④\nmodel.setObjective(profit)                                                ④\n\nmodel.solve()                                                             ⑤\n\nprint('LP Solution:')                                                     ⑥\nprint(f'Profit: = {model.objective.value()} $')                           ⑥\nprint(f'Make {x1.value()} small sets, and make {x2.value()} large sets')  ⑥\n```", "```py\n$pip install networkx\n```", "```py\nimport matplotlib.pyplot as plt\nimport networkx as nx\nimport networkx.algorithms.approximation as nx_app\nimport math\n\nplt.figure(figsize=(10, 7))\n\nG = nx.random_geometric_graph(20, radius=0.4, seed=4)                   ①\npos = nx.get_node_attributes(G, \"pos\")\n\npos[0] = (0.5, 0.5)                                                     ②\n\nH = G.copy()                                                            ③\n\nfor i in range(len(pos)):                                               ④\n    for j in range(i + 1, len(pos)):                                    ④\n        dist = math.hypot(pos[i][0] - pos[j][0], pos[i][1] - pos[j][1]) ④\n        dist = dist                                                     ④\n        G.add_edge(i, j, weight=dist)                                   ④\n\ncycle = nx_app.christofides(G, weight=\"weight\")                         ⑤\nedge_list = list(nx.utils.pairwise(cycle))\n\nnx.draw_networkx_edges(H, pos, edge_color=\"blue\", width=0.5)            ⑥\n\nnx.draw_networkx(                                                       ⑦\n    G,                                                                  ⑦\n    pos,                                                                ⑦\n    with_labels=True,                                                   ⑦\n    edgelist=edge_list,                                                 ⑦\n    edge_color=\"red\",                                                   ⑦\n    node_size=200,                                                      ⑦\n    width=3,                                                            ⑦\n)                                                                       ⑦\n\nprint(\"The route of the salesman is:\", cycle)                           ⑧\nplt.show() \n```", "```py\n$ conda config --prepend channels conda-forge\n$ conda create -n ox --strict-channel-priority osmnx\n$ conda activate ox\n```", "```py\nimport osmnx as ox\n\nplace_name = \"Times Square, NY\"                                 ①\n\ngraph = ox.graph_from_address(place_name, network_type='drive') ②\n\nox.plot_graph(graph,figsize=(10,10))                            ③\n```", "```py\nec = ['y' if data['oneway'] else 'w' for u, v, key, data in graph.edges(keys=True, data=True)]\nfig, ax = ox.plot_graph(graph, figsize=(10,10), node_size=0, edge_color=ec, edge_linewidth=1.5, edge_alpha=0.7)\n```", "```py\nnodes, edges = o.graph_to_gdfs(graph)\nnodes.head(5)\n```", "```py\nlist(graph.nodes(data=True))[1]\nlist(graph.edges(data=True))[0]\n```", "```py\nprint(edges['highway'].value_counts())\n```", "```py\nsecondary                      236\nresidential                    120\nprimary                         83\nunclassified                    16\nmotorway_link                   12\ntertiary                        10\nmotorway                         7\nliving_street                    3\n[unclassified, residential]      1\n[motorway_link, primary]         1\ntrunk                            1\n```", "```py\nnew_graph = ox.graph_from_gdfs(nodes,edges)\nox.plot_graph(new_graph,figsize=(10,10))\n```", "```py\nox.plot_graph(graph, figsize=(10,10), show=False, save=True, close=True, \nfilepath='./data/TimesSquare.png')                                    ①\nox.plot_graph(graph, figsize=(10,10), show=False, save=True, close=True, \nfilepath='./data/TimesSquare.svg')                                    ②\nox.save_graph_xml(graph, filepath='./data/TimesSquare.osm')           ③\nox.save_graph_geopackage(graph, filepath='./data/TimesSquare.gpkg')   ④\nox.save_graphml(graph, filepath='./data/TimesSquare.graphml')         ⑤\nox.save_graph_shapefile(graph, filepath='./data/TimesSquare')         ⑥\n```", "```py\n$conda install geopandas or $pip install geopandas\n```", "```py\nimport geopandas as gpd\nimport requests\nimport os\n\nbase_url = \"https://raw.githubusercontent.com/Optimization-Algorithms-\n➥Book/Code-Listings/05766c64c5e83dcd6788cc4415b462e2f82e0ccf/\n➥Appendix%20B/data/OntarioHealth/\"                                 ①\n\nfiles = [\"Ontario_Health_Regions.shp\", \"Ontario_Health_Regions.shx\",\n➥ \"Ontario_Health_Regions.dbf\", \"Ontario_Health_Regions.prj\"]      ②\n\nfor file in files:                                                  ③\n    response = requests.get(base_url + file)                        ③\n    with open(file, 'wb') as f:                                     ③\n        f.write(response.content)                                   ③\n\nontario =  gpd.read_file(\"Ontario_Health_Regions.shp\")              ④\n\nfor file in files:                                                  ⑤\n    os.remove(file)                                                 ⑤\n\nprint(ontario.head())                                               ⑥\n```", "```py\n#!pip install contextily\nimport contextily as ctx\nax=ontario.plot(cmap='jet', edgecolor='black', column='REGION', alpha=0.5,\n➥ legend=True, figsize=(10,10))\nax.set_title(\"EPSG:4326, WGS 84\")\nctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik,\n➥ crs=ontario.crs.to_string())\n```", "```py\n#!pip install folium\nimport folium\n\nontario = ontario.to_crs(epsg=4326)                               ①\n\nm = folium.Map(location=[43.67621,-79.40530],zoom_start=7,\n➥ tiles='cartodbpositron', scrollWheelZoom=False, dragging=True) ②\n\nfor index, row in ontario.iterrows():                             ③\n    sim_geo = gpd.GeoSeries(row['geometry']).simplify(tolerance=0.001)\n    geo_j = sim_geo.to_json()\n    geo_j = folium.GeoJson(data=geo_j,\n➥ name=row['REGION'],style_function=lambda x: {'fillColor': 'black'})\n    folium.Popup(row['REGION']).add_to(geo_j)\n    geo_j.add_to(m)\n\nm                                                                 ④\n```", "```py\n#!pip install pyswarms\nimport pyswarms as ps\nfrom pyswarms.utils.functions import single_obj as fx\nfrom pyswarms.utils.plotters import plot_cost_history, plot_contour,\n➥ plot_surface\nfrom pyswarms.utils.plotters.formatters import Mesher, Designer\nimport matplotlib.pyplot as plt\nfrom IPython.display import Image                                     ①\n\noptions = {'c1':0.5, 'c2':0.3, 'w':0.9}                               ②\noptimizer = ps.single.GlobalBestPSO(n_particles=50, dimensions=2,\n\n➥ options=options)                                                   ③\n\noptimizer.optimize(fx.sphere, iters=100)                              ④\n\nplot_cost_history(optimizer.cost_history)                             ⑤\nplt.show()\n\nm = Mesher(func=fx.sphere, limits=[(-1,1), (-1,1)])                   ⑥\nd = Designer(limits=[(-1,1), (-1,1), (-0.1,1)], label=['x-axis', 'y-axis',\n➥ 'z-axis'])                                                         ⑦\n\nanimation = plot_contour(pos_history=optimizer.pos_history, mesher=m,\n➥ designer=d, mark=(0,0))                                            ⑧\nanimation.save('solution.gif', writer='imagemagick', fps=10)\nImage(url='solution.gif')                                             ⑨\n```", "```py\n#!pip install scikit-opt\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sko.SA import SA\n\nobj_func = lambda x: np.sin(x[0]) * np.cos(x[1])                    ①\n\nsa = SA(func=obj_func, x0=np.array([-3, -3]), T_max=1, T_min=1e-9, L=300,\n➥ max_stay_counter=150)                                            ②\nbest_x, best_y = sa.run()\nprint('best_x:', best_x, 'best_y', best_y)\n\nplt.plot(pd.DataFrame(sa.best_y_history).cummin(axis=0))            ③\nplt.show()\n```", "```py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sko.PSO import PSO_TSP\n\nnum_points = len(city_names)                                            ①\npoints_coordinate = city_names                                          ①\npairwise_distances = distances                                          ①\n\ndef cal_total_distance(routine):                                        ②\n    num_points, = routine.shape\n    return sum([pairwise_distances[routine[i % num_points], routine[(i + 1)\n➥ % num_points]] for i in range(num_points)])\n\npso_tsp = PSO_TSP(func=cal_total_distance, n_dim=num_points, size_pop=200,\n➥ max_iter=800, w=0.8, c1=0.1, c2=0.1)                                 ③\nbest_points, best_distance = pso_tsp.run()                              ③\nbest_points_ = np.concatenate([best_points, [best_points[0]]])\n\nprint('best_distance', best_distance)                                   ④\nprint('route', best_points_)                                            ④\n```", "```py\n#!pip install networkx\nimport matplotlib.pyplot as plt\nimport networkx as nx\nfrom networkx.algorithms import approximation as approx\n\nG=nx.Graph()                                                              ①\n\nfor i in range(len(city_names)):                                          ②\n    for j in range(1,len(city_names)):                                    ②\n        G.add_weighted_edges_from({(city_names[i], city_names[j],         ②\n➥ distances[i][j])})                                                     ②\n        G.remove_edges_from(nx.selfloop_edges(G))                         ②\n\npos = nx.spring_layout(G)                                                 ③\n\ncycle = approx.simulated_annealing_tsp(G, \"greedy\", source=city_names[0]) ④\nedge_list = list(nx.utils.pairwise(cycle))                                ④\ncost = sum(G[n][nbr][\"weight\"] for n, nbr in nx.utils.pairwise(cycle))    ④\n\nprint(\"The route of the salesman is:\", cycle, \"with cost of \", cost)      ⑤\n```", "```py\n#!pip install deap\nfrom deap import base, creator, tools, algorithms\nimport random\nimport numpy as np\n\ncreator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))                ①\ncreator.create(\"Individual\", list, fitness=creator.FitnessMin)             ①\n\ntoolbox = base.Toolbox()                                                   ②\ntoolbox.register(\"permutation\", random.sample, range(len(city_names)),     ②\n➥ len(city_names))                                                        ②\ntoolbox.register(\"individual\", tools.initIterate, creator.Individual,      ②\n➥ toolbox.permutation)                                                    ②\ntoolbox.register(\"population\", tools.initRepeat, list, toolbox.individual) ②\n\ndef eval_tsp(individual):                                                  ③\n    total_distance = 0\n    for i in range(len(individual)):\n        city_1 = individual[i]\n        city_2 = individual[(i + 1) % len(individual)]\n        total_distance += distances[city_1][city_2]\n    return total_distance,\n\ntoolbox.register(\"evaluate\", eval_tsp)                                     ④\ntoolbox.register(\"mate\", tools.cxOrdered)                                  ⑤\ntoolbox.register(\"mutate\", tools.mutShuffleIndexes, indpb=0.05)            ⑥\ntoolbox.register(\"select\", tools.selTournament, tournsize=3)               ⑦\n\npop = toolbox.population(n=50)                                             ⑧\nhof = tools.HallOfFame(1)                                                  ⑨\nstats = tools.Statistics(lambda ind: ind.fitness.values)\nstats.register(\"avg\", np.mean)\nstats.register(\"min\", np.min)\nstats.register(\"max\", np.max)\n\npop, log = algorithms.eaSimple(pop, toolbox, cxpb=0.5, mutpb=0.2, ngen=50,\n➥ stats=stats, halloffame=hof,verbose=True)                               ⑩\n\nbest_individual = hof[0] \nprint(\"Best solution:\")                                                    ⑪\nprint(\"  - Fitness: \", eval_tsp(best_individual))                          ⑪\nprint(\"  - Route: \", [city_names[i] for i in best_individual])             ⑪\n```", "```py\n#!pip install --upgrade --user ortools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom ortools.constraint_solver import pywrapcp\nfrom ortools.constraint_solver import routing_enums_pb2\n\ndistances2=np.asarray(distances, dtype = 'int')                           ①\n\ndata = {}                                                                 ②\ndata['distance_matrix'] = distances                                       ②\ndata['num_vehicles'] = 1                                                  ②\ndata['depot'] = 0                                                         ②\n\nmanager = pywrapcp.RoutingIndexManager(len(data['distance_matrix']),\n➥ data['num_vehicles'], data['depot'])                                   ③\nrouting = pywrapcp.RoutingModel(manager)                                  ③\ndef distance_callback(from_index, to_index):                              ④\n    from_node = manager.IndexToNode(from_index)\n    to_node = manager.IndexToNode(to_index)\n    return data['distance_matrix'][from_node][to_node]\n\ntransit_callback_index = routing.RegisterTransitCallback(distance_callback)   \n\nrouting.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n\nsearch_parameters = pywrapcp.DefaultRoutingSearchParameters()\nsearch_parameters.local_search_metaheuristic = (\n    routing_enums_pb2.LocalSearchMetaheuristic.TABU_SEARCH)               ⑤\nsearch_parameters.time_limit.seconds = 30\nsearch_parameters.log_search = True\n\ndef print_solution(manager, routing, solution):                           ⑥\n    print('Objective: {} meters'.format(solution.ObjectiveValue()))\n    index = routing.Start(0)\n    plan_output = 'Route for vehicle 0:\\n'\n    route_distance = 0\n    while not routing.IsEnd(index):\n        plan_output += ' {} ->'.format(manager.IndexToNode(index))\n        previous_index = index\n        index = solution.Value(routing.NextVar(index))\n        route_distance += routing.GetArcCostForVehicle(previous_index,\n➥ index, 0)\n    plan_output += ' {}\\n'.format(manager.IndexToNode(index))\n    print(plan_output)\n    plan_output += 'Route distance: {}meters\\n'.format(route_distance)\n\nsolution = routing.SolveWithParameters(search_parameters)\nif solution:\n    print_solution(manager, routing, solution)\n```", "```py\n$ pip install node2vec\n```", "```py\n$ git clone https://github.com/aditya-grover/node2vec\n$ cd node2vec\n$ pip install -e .\n```", "```py\nimport networkx as nx\nfrom node2vec import Node2Vec\n\nG = nx.karate_club_graph()                                                ①\n\nnode2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=200,\n➥ workers=4)                                                             ②\n\nmodel = node2vec.fit(window=10, min_count=1, batch_words=4)               ③\n\nrepresentations_all = model.wv.vectors                                    ④\n\nrepresentations_specific = model.wv['1']                                  ⑤\n\nprint(representations_specifi)                                            ⑥\n```", "```py\nfrom sklearn.manifold import TSNE                                         ①\nimport matplotlib.pyplot as plt\n\ntsne = TSNE(n_components=2, learning_rate='auto', init='random',\n➥ perplexity=3)                                                          ②\nreduced_representations = tsne.fit_transform(representations_all)         ②\n\nplt.scatter(reduced_representations[:, 0], reduced_representations[:, 1]) ③\nplt.show()                                                                ③\n```", "```py\n$ pip install karateclub\n```", "```py\nfrom karateclub import DeepWalk, Node2Vec                   ①\nfrom sklearn.decomposition import PCA                       ②\nimport networkx as nx \nimport matplotlib.pyplot as plt\nG=nx.karate_club_graph()                                    ③\n\nmodel=DeepWalk(dimensions=128, walk_length=100)             ④\nmodel.fit(G)                                                ④\n\nembedding=model.get_embedding()                             ⑤\n\nofficer=[]                                                  ⑥\nmr=[]                                                       ⑥\nfor i in G.nodes:                                           ⑥\n  t=G.nodes[i]['club']\n  officer.append(True if t=='Officer' else False)\n  mr.append(False if t=='Officer' else True)\n\nnodes=list(range(len(G)))\nX=embedding[nodes]\n\npca=PCA(n_components=2)                                     ⑦\npca_out=pca.fit_transform(X)                                ⑦\n\nplt.figure(figsize=(15, 10))                                ⑧\nplt.scatter(pca_out[:,0][officer],pca_out[:,1][officer])    ⑧\nplt.scatter(pca_out[:,0][mr],pca_out[:,1][mr])              ⑧\nplt.show()                                                  ⑧\n```", "```py\n$pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.13.0+cpu.html\n```", "```py\nimport networkx as nx\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch_geometric.datasets import KarateClub\nfrom torch_geometric.utils import to_networkx\nfrom torch.nn import Linear\nfrom torch_geometric.nn import GCNConv\n\ndataset = KarateClub()                                             ①\ndata = dataset[0]\n\nclass GCN(torch.nn.Module):                                        ②\n    def __init__(self):\n        super().__init__()\n        torch.manual_seed(1234)\n        self.conv1 = GCNConv(dataset.num_features, 4)\n        self.conv2 = GCNConv(4, 4)\n        self.conv3 = GCNConv(4, 2)\n        self.classifier = Linear(2, dataset.num_classes)\n\n    def forward(self, x, edge_index):\n        h = self.conv1(x, edge_index)\n        h = h.tanh()\n        h = self.conv2(h, edge_index)\n        h = h.tanh()\n        h = self.conv3(h, edge_index)\n        h = h.tanh()                                                ③\n        out = self.classifier(h)                                    ④\n\n        return out, h\n\nmodel = GCN()                                                       ⑤\n\ncriterion = torch.nn.CrossEntropyLoss()                             ⑥\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)           ⑦\noptimizer.zero_grad()\n\nfor epoch in range(401):\n    out, h = model(data.x, data.edge_index)                         ⑧\n\n    loss = criterion(out[data.train_mask], data.y[data.train_mask]) ⑨\n    loss.backward()                                                 ⑩\n    optimizer.step()                                                ⑪\n\nh = h.detach().cpu().numpy()                                        ⑫\n\nplt.figure(figsize=(15, 10))                                        ⑬\nplt.scatter(h[:, 0], h[:, 1], s=140, c=data.y, cmap=\"Set2\")         ⑬\n```", "```py\n#!pip install gym[all]            ①\nimport gym\nenv = gym.make('MountainCar-v0')  ②\n```", "```py\n$git clone https://github.com/flow-project/flow.git\n$cd flow\n$conda env create –f environment.yml\n$conda activate flow\n$python setup.py develop\n```", "```py\n$pip install –e .\n```"]