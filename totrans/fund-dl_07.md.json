["```py\nimport torch.nn as nn\n\nlayer = nn.Conv2d(in_channels = 3,\n                  out_channels = 64,\n                  kernel_size = (5, 5),\n                  stride = 2,\n                  padding = 1\n                  )\n```", "```py\nclass MNISTConvNet(nn.Module):\n  def __init__(self):\n    super(MNISTConvNet, self).__init__()\n    self.conv1 = nn.Sequential(\n        nn.Conv2d(1, 32, 5, padding='same'),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n    )\n    self.conv2 = nn.Sequential(\n        nn.Conv2d(32, 64, 5, padding='same'),\n        nn.ReLU(),\n        nn.MaxPool2d(2)\n    )\n    self.fc1 = nn.Sequential(\n        nn.Flatten(),\n        nn.Linear(7*7*64, 1024),\n        nn.Dropout(0.5),\n        nn.Linear(1024, 10)\n    )\n\n  def forward(self, x):\n    x = self.conv1(x)\n    x = self.conv2(x)\n    return self.fc1(x)\n\n```", "```py\nlr = 1e-4\nnum_epochs = 40\n\nmodel = MNISTConvNet()\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=lr)\n\nfor epochs in range(num_epochs):\n  running_loss = 0.0\n  num_correct = 0\n  for inputs, labels in trainloader:\n    optimizer.zero_grad()\n    outputs = model(inputs)\n    loss = loss_fn(outputs, labels)\n    loss.backward()\n    running_loss += loss.item()\n    optimizer.step()\n    _, idx = outputs.max(dim=1)\n    num_correct += (idx == labels).sum().item()\n  print('Loss: {} Accuracy: {}'.format(running_loss/len(trainloader),\n        num_correct/len(trainloader)))\n\n```", "```py\nfrom torchvision import transforms\n\ntransform = transforms.Normalize(mean = (0.1307,),\n                                 std = (0.3081,)\n                                 )\n\n```", "```py\ntransform = transforms.Compose([\n      transforms.RandomCrop(224),\n      transforms.RandomHorizontalFlip(),\n      transforms.ColorJitter(brightness=0,\n                             contrast=0,\n                             saturation=0,\n                             hue=0),\n      transforms.ToTensor(),\n      transforms.Normalize(mean = (0.1307,),\n                           std = (0.3081,)\n                           )\n      ])\n\n```", "```py\nlayer = nn.BatchNorm2d(num_features=32,\n                       eps=1e-05,\n                       momentum=0.1,\n                       affine = True,\n                       track_running_stats = True)\n\n```", "```py\nlayer = nn.BatchNorm1d(num_features=32)\n\n```", "```py\nlayer = nn.GroupNorm(num_groups=1,\n                     num_channels=32)\n\n```", "```py\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.block1 = nn.Sequential(\n            nn.Conv2d(1, 32, 3, 1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(32, 64, 3, 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(2),\n            nn.Dropout(0.25),\n        )\n        self.block2 = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(9216, 128),\n            nn.BatchNorm1d(128),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(128,10),\n            nn.BatchNorm1d(10)\n        )\n\n    def forward(self, x):\n        x = self.block1(x)\n        return self.block2(x)\n\n```", "```py\nfrom torchvision.models import resnet34\n\nmodel = resnet34()\n\n```", "```py\nclass ResidualBlock(nn.Module):\n  def __init__(self, in_layers, out_layers, downsample=None):\n    super(ResidualBlock, self).__init__()\n    self.conv1 = nn.Conv2d(in_layers, out_layers,\n                           kernel_size=3, stride=1, padding=1)\n    self.bn1 = nn.BatchNorm2d(out_layers)\n    self.conv2 = nn.Conv2d(out_layers, out_layers,\n                           kernel_size=3, stride=1, padding=1)\n    self.bn2 = nn.BatchNorm2d(out_layers)\n    self.downsample = downsample\n    self.relu = nn.ReLU(inplace=True)\n\n  def forward(self, inp):\n    # Residual block\n    out = self.conv1(inp)\n    out = self.bn1(out)\n    out = self.relu(out)\n    out = self.conv2(out)\n    out = self.bn2(out)\n\n    if self.downsample:\n      inp = self.downsample(inp)\n\n    # Shortcut connection\n    out += inp\n    return out\n\n```", "```py\ndownsample = nn.Sequential(\n      nn.Conv2d(64, 128, kernel_size=1, stride=1, bias=False),\n      nn.BatchNorm2d(128)\n    )\n\n```", "```py\nclass ResNet34(nn.Module):\n  def __init__(self):\n    super(ResNet34, self).__init__()\n\n    self.conv1 = nn.Sequential(\n      nn.Conv2d(3, 64, kernel_size=7,\n                stride=2, padding=3, bias=False),\n      nn.BatchNorm2d(64),\n      nn.ReLU(),\n      nn.MaxPool2d(kernel_size=3,\n                   stride=2, padding=1)\n    )\n\n    # Note that each ResidualBlock has 2 conv layers\n    # 3 blocks in a row, 6 conv layers\n    self.comp1 = nn.Sequential(\n      ResidualBlock(64, 64),\n      ResidualBlock(64, 64),\n      ResidualBlock(64, 64)\n    )\n\n    # 4 blocks in a row, 8 conv layers\n    downsample1 = nn.Sequential(\n      nn.Conv2d(64, 128, kernel_size=1,\n             stride=1, bias=False),\n      nn.BatchNorm2d(128)\n    )\n    self.comp2 = nn.Sequential(\n      ResidualBlock(64, 128, downsample=downsample1),\n      ResidualBlock(128, 128),\n      ResidualBlock(128, 128),\n      ResidualBlock(128, 128)\n    )\n\n    # 6 blocks in a row, 12 conv layers\n    downsample2 = nn.Sequential(\n      nn.Conv2d(128, 256, kernel_size=1, stride=1, bias=False),\n      nn.BatchNorm2d(256)\n    )\n    self.comp3 = nn.Sequential(\n      ResidualBlock(128, 256, downsample=downsample2),\n      ResidualBlock(256, 256),\n      ResidualBlock(256, 256),\n      ResidualBlock(256, 256),\n      ResidualBlock(256, 256),\n      ResidualBlock(256, 256),\n    )\n\n    # 3 blocks in a row, 6 conv layers\n    downsample3 = nn.Sequential(\n      nn.Conv2d(256, 512, kernel_size=1, stride=1, bias=False),\n      nn.BatchNorm2d(512)\n    )\n    self.comp4 = nn.Sequential(\n      ResidualBlock(256, 512, downsample=downsample3),\n      ResidualBlock(512, 512),\n      ResidualBlock(512, 512)   \n    )\n\n    self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n    # ImageNet classifier: 1000 classes\n    self.fc = nn.Linear(512, 1000)\n\n  def forward(self, inp):\n    out = self.conv1(inp)\n\n    out = self.comp1(out)\n    out = self.comp2(out)\n    out = self.comp3(out)\n    out = self.comp4(out)\n\n    out = self.avgpool(out)\n    out = torch.flatten(out, 1)\n    out = self.fc(out)\n\n    return out\n\n```"]