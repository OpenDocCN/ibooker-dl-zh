["```py\n14.1 Importing Icons\n14.2 Icon Autoencoding\n14.3 Icon GAN\n14.4 Icon RNN\n```", "```py\n7z x Icons8App_for_Mac_OS.dmg\n```", "```py\ncd Icons8\\ v5.6.3\n7z x Icons8.app\n```", "```py\ntar xvf icons.tar\n```", "```py\n# Adjust to your local path:\npath = '/some/path/Downloads/Icons8 v5.6.3/icons'\ndb = plyvel.DB(path)\n\nfor key, value in db:\n    print(key)\n    print(value[:400])\n    break\n```", "```py\n> b'icon_1'\nb'TSAF\\x03\\x00\\x02\\x00\\x07\\x00\\x00\\x00\\x00\\x00\\x00\\x00$\\x00\\x00\\x00\n\\x18\\x00\\x00\\x00\\r\\x00\\x00\\x00-\\x08id\\x00\\x08Messaging\\x00\\x08categ\nory\\x00\\x19\\x00\\x03\\x00\\x00\\x00\\x08Business\\x00\\x05\\x01\\x08User\nInterface\\x00\\x08categories\\x00\\x18\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x08\nBasic Elements\\x00\\x05\\x04\\x01\\x05\\x01\\x08Business\nCommunication\\x00\\x05\\x03\\x08subcategories\\x00\\x19\\x00\\r\\x00\\x00\\x00\n\\x08contacts\\x00\\x08phone book\\x00\\x08contacts\nbook\\x00\\x08directory\\x00\\x08mail\\x00\\x08profile\\x00\\x08online\\x00\n\\x08email\\x00\\x08records\\x00\\x08alphabetical\\x00\\x08sim\\x00\\x08phone\nnumbers\\x00\\x08categorization\\x00\\x08tags\\x00\\x0f9\\x08popularity\\x00\n\\x18\\x00\\x00\\x02\\x00\\x00\\x00\\x1c\\x00\\x00\\x00\\xe8\\x0f\\x00\\x00<?xml\nversion=\"1.0\" encoding=\"utf-8\"?>\\n<!-- Generato'\n```", "```py\nsplitter = re.compile(b'[\\x00-\\x09]')\n\ndef parse_value(value):\n    res = {}\n    prev = ''\n    for elem in splitter.split(value):\n        if not elem:\n            continue\n        try:\n            elem = elem.decode('utf8')\n        except UnicodeDecodeError:\n            continue\n        if elem in ('category', 'name', 'platform',\n                    'canonical_name', 'svg', 'svg.simplified'):\n            res[elem] = prev\n        prev = elem\n    return res\n```", "```py\nicons = {}\nfor _, value in db:\n    res = parse_value(value)\n    if res.get('platform') == 'ios':\n        name = res.get('name')\n        if not name:\n            name = res.get('canonical_name')\n            if not name:\n                continue\n            name = name.lower().replace(' ', '_')\n        icons[name] = res\n```", "```py\nsaved = []\nfor icon in icons.values():\n    icon = dict(icon)\n    if not 'svg' in icon:\n        continue\n    svg = icon.pop('svg')\n    try:\n        drawing = svg2rlg(BytesIO(svg.encode('utf8')))\n    except ValueError:\n        continue\n    except AttributeError:\n        continue\n    open('icons/svg/%s.svg' % icon['name'], 'w').write(svg)\n    p = renderPM.drawToPIL(drawing)\n    for size in SIZES:\n        resized = p.resize((size, size), Image.ANTIALIAS)\n        resized.save('icons/png%s/%s.png' % (size, icon['name']))\n    saved.append(icon)\njson.dump(saved, open('icons/index.json', 'w'), indent=2)\n```", "```py\ndef load_icons(train_size=0.85):\n    icon_index = json.load(open('icons/index.json'))\n    x = []\n    img_rows, img_cols = 32, 32\n    for icon in icon_index:\n        if icon['name'].endswith('_filled'):\n            continue\n        img_path = 'icons/png32/%s.png' % icon['name']\n        img = load_img(img_path, grayscale=True,\n                       target_size=(img_rows, img_cols))\n        img = img_to_array(img)\n        x.append(img)\n    x = np.asarray(x) / 255\n    x_train, x_val = train_test_split(x, train_size=train_size)\n    return x_train, x_val\n```", "```py\ninput_img = Input(shape=(32, 32, 1))\nchannels = 4\nx = input_img\nfor i in range(5):\n    left = Conv2D(channels, (3, 3),\n                  activation='relu', padding='same')(x)\n    right = Conv2D(channels, (2, 2),\n                  activation='relu', padding='same')(x)\n    conc = Concatenate()([left, right])\n    x = MaxPooling2D((2, 2), padding='same')(conc)\n    channels *= 2\n\n x = Dense(channels)(x)\n encoder_hidden = Flatten()(x)\n```", "```py\nz_mean = Dense(latent_space_depth,\n               activation='linear')(encoder_hidden)\nz_log_var = Dense(latent_space_depth,\n                  activation='linear')(encoder_hidden)\n\ndef KL_loss(y_true, y_pred):\n    return (0.001 * K.sum(K.exp(z_log_var)\n            + K.square(z_mean) - 1 - z_log_var, axis=1))\n\ndef reconstruction_loss(y_true, y_pred):\n    y_true = K.batch_flatten(y_true)\n    y_pred = K.batch_flatten(y_pred)\n    return binary_crossentropy(y_true, y_pred)\n\n    def total_loss(y_true, y_pred):\n        return (reconstruction_loss(y_true, y_pred)\n                + KL_loss(y_true, y_pred))\n```", "```py\nz = Lambda(sample_z,\n           output_shape=(latent_space_depth, ))([z_mean, z_log_var])\ndecoder_in = Input(shape=(latent_space_depth,))\n\nd_x = Reshape((1, 1, latent_space_depth))(decoder_in)\ne_x = Reshape((1, 1, latent_space_depth))(z)\nfor i in range(5):\n    conv = Conv2D(channels, (3, 3), activation='relu', padding='same')\n    upsampling = UpSampling2D((2, 2))\n    d_x = conv(d_x)\n    d_x = upsampling(d_x)\n    e_x = conv(e_x)\n    e_x = upsampling(e_x)\n    channels //= 2\n\nfinal_conv = Conv2D(1, (3, 3), activation='sigmoid', padding='same')\nauto_decoded = final_conv(e_x)\ndecoder_out = final_conv(d_x)\n```", "```py\ndef truncate_to_batch(x):\n    l = x.shape[0]\n    return x[:l - l % batch_size, :, :, :]\n\nx_train_trunc = truncate_to_batch(x_train)\nx_test_trunc = truncate_to_batch(x_test)\nx_train_trunc.shape, x_test_trunc.shape\n```", "```py\ndef augment(icons):\n    aug_icons = []\n    for icon in icons:\n        for flip in range(4):\n            for rotation in range(4):\n                aug_icons.append(icon)\n                icon = np.rot90(icon)\n            icon = np.fliplr(icon)\n    return np.asarray(aug_icons)\n```", "```py\nx_train_aug = augment(x_train)\nx_test_aug = augment(x_test)\n```", "```py\ninp = Input(shape=(latent_size,))\nx = Reshape((1, 1, latent_size))(inp)\n\nchannels = latent_size\npadding = 'valid'\nstrides = 1\nfor i in range(4):\n    x = Conv2DTranspose(channels, kernel_size=4,\n                        strides=strides, padding=padding)(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU(.2)(x)\n\n    channels //= 2\n    padding = 'same'\n    strides = 2\n\nx = Conv2DTranspose(1, kernel_size=4, strides=1, padding='same')(x)\nimage_out = Activation('tanh')(x)\n\nmodel = Model(inputs=inp, outputs=image_out)\n```", "```py\ninp = Input(shape=(32, 32, 1))\nx = inp\n\nchannels = 16\n\nfor i in range(4):\n    layers = []\n    conv = Conv2D(channels, 3, strides=2, padding='same')(x)\n    if i:\n        conv = BatchNormalization()(conv)\n    conv = LeakyReLU(.2)(conv)\n    layers.append(conv)\n    bv = Lambda(lambda x: K.mean(K.abs(x[:] - K.mean(x, axis=0)),\n                          axis=-1,\n                          keepdims=True))(conv)\n    layers.append(bv)\n    channels *= 2\n    x = Concatenate()(layers)\n\nx = Conv2D(128, 2, padding='valid')(x)\nx = Flatten(name='flatten')(x)\n\nfake = Dense(1, activation='sigmoid', name='generation')(x)\n\nm = Model(inputs=inp, outputs=fake)\n```", "```py\nnoise = Input(shape=g.input_shape[1:])\nreal_data = Input(shape=d.input_shape[1:])\n\ngenerated = g(noise)\ngscore = d(generated)\nrscore = d(real_data)\n```", "```py\ndloss = (- K.mean(K.log((1 - gscore) + .1 * K.log((1 - rscore)\n         + .9 * K.log((rscore)))\ngloss = - K.mean(K.log((gscore))\n```", "```py\noptimizer = tf.train.AdamOptimizer(1e-4, beta1=0.2)\ngrad_loss_wd = optimizer.compute_gradients(dloss, d.trainable_weights)\nupdate_wd = optimizer.apply_gradients(grad_loss_wd)\ngrad_loss_wg = optimizer.compute_gradients(gloss, g.trainable_weights)\nupdate_wg = optimizer.apply_gradients(grad_loss_wg)\n```", "```py\nother_parameter_updates = [get_internal_updates(m) for m in [d, g]]\ntrain_step = [update_wd, update_wg, other_parameter_updates]\nlosses = [dloss, gloss]\nlearning_phase = K.learning_phase()\n```", "```py\n def gan_feed(sess,batch_image, z_input):\n       feed_dict = {\n           noise: z_input,\n           real_data: batch_image,\n           learning_phase: True,\n       }\n       loss_values, = sess.run([losses], feed_dict=feed_dict)\n```", "```py\nsess = K.get_session()\nl = x_train.shape[0]\nl -= l % BATCH_SIZE\nfor i in range(epochs):\n    np.random.shuffle(x_train)\n    for batch_start in range(0, l, BATCH_SIZE):\n        batch = x_train[batch_start: batch_start + BATCH_SIZE]\n        z_input = np.random.normal(loc=0.,\n                                   scale=1.,\n                                   size=(BATCH_SIZE, LATENT_SIZE))\n        losses = gan_feed(sess, batch, z_input)\n```", "```py\ndef generate_images(count):\n    noise = np.random.normal(loc=0.,\n                             scale=1.,\n                             size=(count, LATENT_SIZE))\n    for tile in gm.predict([noise]).reshape((count, 32, 32)):\n        tile = (tile * 300).clip(0, 255).astype('uint8')\n        yield PIL.Image.fromarray(tile)\n```", "```py\ndef poster(w_count, h_count):\n    overview = PIL.Image.new('RGB',\n                             (w_count * 34 + 2, h_count * 34 + 2),\n                             (128, 128, 128))\n    for idx, img in enumerate(generate_images(w_count * h_count)):\n        x = idx % w_count\n        y = idx // w_count\n        overview.paste(img, (x * 34 + 2, y * 34 + 2))\n    return overview\n```", "```py\n        clear_output(wait=True)\n        f = BytesIO()\n        poster(8, 5).save(f, 'png')\n        display(Image(data=f.getvalue()))\n```", "```py\ndef encode_icon(img, icon_size):\n    size_last_x = 0\n    encoded = []\n    for y in range(icon_size):\n        for x in range(icon_size):\n            p = img.getpixel((x, y))\n            if img.getpixel((x, y)) < 192:\n                encoded.append(x)\n                size_last_x = len(encoded)\n        encoded.append(icon_size)\n    return encoded[:size_last_x]\n```", "```py\ndef decode_icon(encoded, icon_size):\n    y = 0\n    for idx in encoded:\n        if idx == icon_size:\n            y += 1\n        elif idx == icon_size + 1:\n            break\n        else:\n            x = idx\n            yield x, y\n\n    icon = PIL.Image.new('L', (32, 32), 'white')\n    for x, y in decode_icon(sofar, 32):\n        if y < 32:\n            icon.putpixel((x, y), 0)\n```", "```py\ndef make_array(icons):\n    res = []\n    for icon in icons:\n        res.extend(icon)\n        res.append(33)\n    return np.asarray(res)\n\ndef load_icons(train_size=0.90):\n    icon_index = json.load(open('icons/index.json'))\n    x = []\n    img_rows, img_cols = 32, 32\n    for icon in icon_index:\n        if icon['name'].endswith('_filled'):\n            continue\n        img_path = 'icons/png32/%s.png' % icon['name']\n        x.append(encode_icon(PIL.Image.open(img_path), 32))\n    x_train, x_val = train_test_split(x, train_size=train_size)\n    x_train = make_array(x_train)\n    x_val = make_array(x_val)\n    return x_train, x_val\n\nx_train, x_test = load_icons()\n```", "```py\ndef icon_rnn_model(num_chars, num_layers, num_nodes=512, dropout=0.1):\n    input = Input(shape=(None, num_chars), name='input')\n    prev = input\n    for i in range(num_layers):\n        lstm = LSTM(num_nodes, return_sequences=True,\n                    name='lstm_layer_%d' % (i + 1))(prev)\n        if dropout:\n            prev = Dropout(dropout)(lstm)\n        else:\n            prev = lstm\n    dense = TimeDistributed(Dense(num_chars,\n                                  name='dense',\n                                  activation='softmax'))(prev)\n    model = Model(inputs=[input], outputs=[dense])\n    optimizer = RMSprop(lr=0.01)\n    model.compile(loss='categorical_crossentropy',\n                  optimizer=optimizer,\n                  metrics=['accuracy'])\n    return model\n\nmodel = icon_rnn_model(34, num_layers=2, num_nodes=256, dropout=0)\n```", "```py\ndef generate_icons(model, num=2, diversity=1.0):\n    start_index = random.randint(0, len(x_test) - CHUNK_SIZE - 1)\n    generated = x_test[start_index: start_index + CHUNK_SIZE]\n    while num > 0:\n        x = np.zeros((1, len(generated), 34))\n        for t, char in enumerate(generated):\n            x[0, t, char] = 1.\n        preds = model.predict(x, verbose=0)[0]\n        preds = np.asarray(preds[len(generated) - 1]).astype('float64')\n        exp_preds = np.exp(np.log(preds) / diversity)\n```", "```py\n            if next_index == 33:\n                icon = PIL.Image.new('L', (32, 32), 'white')\n                for x, y in decode_icon(sofar, 32):\n                    if y < 32:\n                        icon.putpixel((x, y), 0)\n                yield icon\n                num -= 1\n            else:\n                sofar.append(next_index)\n```", "```py\ncols = 10\nrows = 10\noverview = PIL.Image.new('RGB',\n                         (cols * 36 + 4, rows * 36 + 4),\n                         (128, 128, 128))\nfor idx, icon in enumerate(generate_icons(model, num=cols * rows)):\n    x = idx % cols\n    y = idx // cols\n    overview.paste(icon, (x * 36 + 4, y * 36 + 4))\noverview\n```"]