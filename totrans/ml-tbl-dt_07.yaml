- en: 6 Advanced feature processing methods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs: []
  type: TYPE_NORMAL
- en: Processing features with more advanced methods
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selecting useful features for lighter, more understandable models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimizing hyperparameters to make your models shine in performance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mastering the specific characteristics and options from gradient boosting decision
    trees
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ve now discussed decision trees, their characteristics, their limitations,
    and all their ensemble models, both those based on random resamplings, such as
    random forests, and those based on boosting, such as gradient boosting. Since
    boosting solutions are considered the state of the art in tabular data modeling,
    we have explained how it works and optimized its predictions at length. In particular,
    we have presented a couple of solid gradient boosting implementations, XGBoost
    and LightGBM, that are proving the best solutions available to a data scientist
    dealing with tabular data.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will deal with more general topics regarding classical machine
    learning. However, we will focus on gradient boosting decision trees (GBDTs),
    especially XGBoost. In the chapter, we discuss more advanced methods for feature
    processing, such as multivariate imputation of missing values, target encoding
    for reducing high categorical features to simple numeric ones, and a general way
    to figure out how to transform or elaborate your features based on how they relate
    to the target. We will propose a few ways to reduce the number of your features
    to the essential and optimize your hyperparameters depending on the computational
    resources available and the model you have chosen. The chapter will then close
    with a section on only advanced methods and options related to GBDTs.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1 Processing features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are any number of problems you may face when dealing with real-world tabular
    datasets, and all the methods we’ve discussed so far will produce substandard
    results if you aren’t adjusting your techniques to address the realities of your
    data. Here, we’ll consider a few such problems, such as dealing with missing values
    in the smartest way possible, transforming categorical features with a large number
    of unique values, and finding a way to reprocess your features after you have
    trained your model to squeeze out even more performance. This isn’t an exhaustive
    list, of course, but it should give you some practice in spotting problems and
    planning an appropriate approach.
  prefs: []
  type: TYPE_NORMAL
- en: As in the previous chapter, for our explanations and examples, we will rely
    again on the Airbnb NYC dataset to present practical examples to tackle the most
    challenging task in tabular data problems. The following listing reprises the
    data and some key functions and classes we will use again in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.1 Reprising the Airbnb NYC dataset
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: ① List of excluded columns for feature processing
  prefs: []
  type: TYPE_NORMAL
- en: ② List of categorical columns with low cardinality to be one-hot encoded
  prefs: []
  type: TYPE_NORMAL
- en: ③ List of categorical columns with high cardinality to be ordinally encoded
  prefs: []
  type: TYPE_NORMAL
- en: ④ List of continuous feature columns
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Creates a binary target indicating whether the price is above the mean (unbalanced
    binary target)
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Creates a binary target indicating whether the price is above the median (balanced
    binary target)
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Creates a multiclass target by quantile binning the price into five classes
  prefs: []
  type: TYPE_NORMAL
- en: ⑧ Sets the target for regression as the price column
  prefs: []
  type: TYPE_NORMAL
- en: ⑨ Creates a column transformer that applies different transformations to different
    groups of features
  prefs: []
  type: TYPE_NORMAL
- en: ⑩ Creates a column transformer suitable for linear models
  prefs: []
  type: TYPE_NORMAL
- en: We refer to the explanations presented in the previous chapter for all the details
    about what the code does. The only addition is a column transformer designed explicitly
    for linear models. This transformer handles just low cardinality categorical features
    by performing one-hot encoding, leaving high cardinality categorical ones apart.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1.1 Multivariate missing data imputation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Having missing data in your tabular dataset is a blocking problem because, apart
    from GBDTs solutions such as XGBoost, LightGBM, and Scikit-learn’s HistGradientBoosting,
    classical machine learning algorithms do not have any native support for missing
    values. In addition, even if your GBDTs algorithm of choice can handle missingness,
    as explained in the next section, you may still find directly imputing the missing
    values more effective because you can check beforehand how each feature or specific
    case is handled.
  prefs: []
  type: TYPE_NORMAL
- en: In chapter 2, we discussed simple imputation methods, such as using the mean
    or the median, and the usefulness of building missing indicators, thus enabling
    algorithms to spot missing patterns that are present more easily. This section
    will provide more details about these techniques and multivariate imputation.
  prefs: []
  type: TYPE_NORMAL
- en: First, unless missing cases depend on unobserved variables such as features
    you don’t have access to, missing data can be categorized as
  prefs: []
  type: TYPE_NORMAL
- en: '*Missing completely at random* (MCAR)—In this scenario, data missingness is
    unrelated to observed and unobserved variables. The missingness occurs randomly
    across the dataset.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Missing at random* (MAR)—MAR assumes that observed variables, not the unobserved
    ones, can explain the missingness. In other words, the probability of missingness
    solely depends on the observed data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When the missing cases depend on the unobserved values of the missing data itself,
    you fall into the case of missing not at random (MNAR), which requires quite a
    specialized treatment that is not a topic of this book. However, suppose you understand
    the mechanism behind some missing not at random missing data, such as when you
    don’t get information in the census about people who are too rich (because of
    privacy) or too poor (because of a general lack of access). In that case, you
    can try to gather new features that hint at their wealth to add to your dataset
    and fall back to the MAR case.
  prefs: []
  type: TYPE_NORMAL
- en: Generally, you often have cases where missing data is MCAR or MAR. In both cases,
    apart from simple imputation using an expected value that works perfectly with
    MCAR, you can better reconstruct your missing data through multivariate imputation.
    *Multivariate imputation* is a method that uses the correlations among predictors
    in a dataset to impute missing values. It involves building a series of models
    to estimate the missing values based on the relationships between variables. In
    this approach, each model treats a feature with missing values as the target variable
    (by modeling only its known values) and uses the remaining features as predictors.
    The resulting model is then used to determine what values to replace the missing
    values in the target. You may set how the algorithm cycles through the features
    to impute. You usually use the default setting, starting from the features with
    less missing data and progressing to those with more missing values, which is
    preferred and most effective.
  prefs: []
  type: TYPE_NORMAL
- en: 'To handle missing values in the predictors, an initial imputation step is performed
    using a simple mean or another basic imputation method. Then, through multiple
    iterations, the imputation process refines the initial estimates by incorporating
    the results from the imputing models. This iterative process continues until the
    imputed values reach a state of stability, where further iterations do not lead
    to significant changes. Multivariate imputation is implemented in Scikit-learn
    by `IterativeImputer` ([https://mng.bz/MDZQ](https://mng.bz/MDZQ)). Inspired by
    the R MICE package (Multivariate Imputation by Chained Equations: [https://mng.bz/avEj](https://mng.bz/avEj)),
    it allows both for multivariate imputation and multiple imputations, a common
    approach in statistics and social sciences where, instead of a single imputed
    value, you get a distribution of plausible replacements. Multiple imputations
    are possible with `IterativeImputer` by running it multiple times with the `sample_posterior`
    parameter set to True, using a different random seed each time.'
  prefs: []
  type: TYPE_NORMAL
- en: However, multivariate imputation is the favored choice in data science tabular
    data applications because it allows building models based on single but precise
    estimations. In our example, we take the Airbnb NYC dataset’s continuous features
    and randomly remove 5% of the data, thus mimicking an MCAR situation. Afterward,
    we run a `SimpleImputer`, replacing missing values with a mean and an `IterativeImputer`.
    Finally, we compare, using the mean absolute error (MAE), the features reconstructed
    by each method against the original values.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.2 Multivariate imputation
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: ① Imports IterativeImputer, which is still experimental and under improvement
    in Scikit-learn
  prefs: []
  type: TYPE_NORMAL
- en: ② Creates a copy of continuous feature data
  prefs: []
  type: TYPE_NORMAL
- en: ③ Creates a mask to randomly mark missing values
  prefs: []
  type: TYPE_NORMAL
- en: ④ Uses a SimpleImputer instance with mean imputation strategy
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Instantiates a RandomForestRegressor for iterative imputation
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Creates an IterativeImputer instance with max_iter and tol are the stopping
    criteria
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Imputes missing data using iterative imputation
  prefs: []
  type: TYPE_NORMAL
- en: ⑧ Calculates MAE for imputed data and original data
  prefs: []
  type: TYPE_NORMAL
- en: 'The result provided by the command `print(mae)` is a table that compares the
    simple imputation with the multivariate imputation method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The comparison results demonstrate that the multivariate method, specifically
    the `IterativeImputer`, consistently yields lower MAE values than the simple imputation
    method, even after a single iteration. This indicates that `IterativeImputer`
    is more effective at replacing missing values with fewer errors. To obtain even
    better estimations, you can increase the `max_iter` to a higher number and leave
    the algorithm to decide if to stop earlier based on the tol values, a tolerance
    threshold used to check if the results are stable. Increasing the `max_iter` will
    lead to longer imputation times because, as an imputing model, we are using a
    random forests algorithm. Random forests are usually the most effective way to
    handle multivariate estimations (a method known in the R community as *MissForest*:
    [https://rpubs.com/lmorgan95/MissForest](https://rpubs.com/lmorgan95/MissForest)).
    However, you can choose faster methods based on linear models or k-nearest neighbors
    by simply replacing the `estimator` in the `IterativeImputer`:'
  prefs: []
  type: TYPE_NORMAL
- en: BayesianRidge—Regularized linear regression simply using `BayesianRidge()`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RandomForestRegressor—For forests of randomized trees regression, you can set
    `n_estimators`, `max_depth`, and `max_features` to create shallower trees and
    thus accelerate the imputation process such as `RandomForestRegressor(n_estimators=30,`
    `max_depth=6,` `max_samples=0.5)`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nystroem + Ridge—A pipeline with the expansion of a degree 2 polynomial kernel
    and regularized linear regression by combining different Scikit-learn commands:
    `make_pipeline(Nystroem(kernel="polynomial",` `degree=2,` `random_state=0),` `Ridge(alpha=1e3))`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: KNeighborsRegressor—A k-nearest neighbors imputation approach where you decide
    the number of neighbors to consider, such as `KNeighbors-Regressor(n_neighbors=5)`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The estimator you use will affect the quality of the results you obtain and
    the computation time. As a start, `BayesianRidge` is the default choice and also
    the fastest. If you have more time, `RandomForestRegressor` will provide you with
    better estimates. By jointly inputting multiple variables, `IterativeImputer`
    captures the dependencies between variables more accurately at the price of more
    computations and written code. For a straightforward, out-of-the-box solution,
    some GBDT implementations provide native support for handling missing values,
    which we will discover in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1.2 Handling missing data with GBDTs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Both XGBoost and LightGBM algorithms (and Scikit-learn’s HistGradientBoosting)
    handle missing values similarly by assigning them to the side that minimizes the
    loss function the most in each split. XGBoost introduced this technique with its
    sparsity-aware split finding algorithm, which provides a default direction to
    use when data is missing, either because it is missing or stored in a sparse matrix
    where only non-zero values are kept.
  prefs: []
  type: TYPE_NORMAL
- en: Consequently, don’t forget that XGBoost will treat the zeros in a sparse matrix
    as missing and apply its specific algorithm to handle missing data. Hence, on
    the one hand, you may find it convenient when analyzing one-hot encoded matrices
    of categorical variables with high cardinality to create them as sparse matrices
    because that will save you a lot of memory and computations. On the other hand,
    you may notice that XGBoost returns completely different models if you analyze
    some data represented as a dense matrix or as a sparse matrix.
  prefs: []
  type: TYPE_NORMAL
- en: The difference is in what happens when XGBoost encounters a missing example.
    During training, the algorithm learns at each split point whether samples with
    missing values should go to the left or right branching based on the resulting
    gain. When making predictions, samples with missing values are assigned to the
    appropriate child accordingly. This allows the algorithm to split on the feature
    value’s missingness pattern if it is predictive. If there are no missing values
    for a given feature during training, then samples with missing values are assigned
    to whichever child has the most samples.
  prefs: []
  type: TYPE_NORMAL
- en: You can use the missing parameter to specify what value XGBoost will have to
    consider as missing. This parameter is set to NaN by default, but you can decide
    on any value you want.
  prefs: []
  type: TYPE_NORMAL
- en: Another critical thing to remember about XGBoost is that the `gblinear` booster,
    using linear models as base learners, treats missing values as zeros. Suppose
    you standardize your numeric features, as is often used with linear models. In
    that case, the `gblinear` booster will treat missing values as the average value
    for that feature because the average takes the zero value in a standardized variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'LightGBM employs a similar approach (see [https://github.com/microsoft/LightGBM/issues/2921](https://github.com/microsoft/LightGBM/issues/2921)),
    using specific parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: LightGBM enables the missing value to be handled by default. Turn it off by
    setting `use_missing=false`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LightGBM uses NA (NaN) to represent missing values by default. Change it to
    use zero by setting `zero_as_missing=true`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When `zero_as_missing=false` (default), the unrecorded values in sparse matrices
    (and LightSVM) are treated as zeros.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When `zero_as_missing=true`, NA and zeros (including unrecorded values in sparse
    matrices [and LightSVM]) are treated as missing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This strategy for handling missing data works well on average, especially if
    your data is MCAR. This means the pattern of missing instances is completely random
    and unrelated to any other feature or hidden underlying process. The situation
    is different with MAR when missingness is related to other features’ values but
    not to the values of the feature itself and NMAR, where there is a systematic
    pattern of missing values related to the feature itself and other features. In
    MAR and NMAR cases, the best solution is to try to impute these values by other
    means because the XGBoost and LightGBM strategy for missing data may reveal itself
    as underperforming.
  prefs: []
  type: TYPE_NORMAL
- en: There are alternatives to imputing missing data, however. For instance, you
    can create missing data indicators, which are binary features valued in correspondence
    to missing instances in a variable. Missing data indicators can prove quite valuable
    if your data is not completely missing at random, and they can work with any classical
    machine learning algorithm. Another popular solution with decision trees is to
    assign missing values to an extreme value (usually a negative extreme value) not
    used by any variable in the dataset. If you use exact splits, not histogram-based
    ones, where values are reduced into bins, missing data replaced by extreme values
    can prove an efficient and easy solution.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1.3 Target encoding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Categorical features, usually represented in a dataset as strings, can be efficiently
    dealt with through different strategies. We already mentioned one-hot-encoding
    in chapter 2 and chapter 4\. As one-hot-encoding, all the other strategies for
    categorical features, whether presenting low or high cardinality, require *encoding*,
    a procedure to transform data numerically into a suitable format for machine learning
    algorithms. Although there are some similarities, encoding is not to be confused
    with *embeddings*, which is a procedure to reduce high-dimensional data, such
    as text or images, into a lower-dimensional space while preserving certain characteristics
    or relationships of the original data. Embeddings are typically learned through
    neural network-based models and are briefly touched on in our book.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Scikit learn package offers a couple of encoding solutions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`OneHotEncoder`—For one-hot encoding (i.e., transforming each unique string
    value into a binary feature), which is the solution we have up so far used'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`OrdinalEncoder`—For ordinal encoding (i.e., transforming the string values
    in a feature into ordered numeric ones; there is also `LabelEncoder`, but it works
    the same, and it is mainly for transforming categorical targets)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generally, one-hot encoding works fine both for linear models and tree-based
    models, and ordinal encoding works fine for more complex tree-based models, such
    as random forests and GBDTs, because trees can recursively split on the categorical
    feature and finally find a set of partitions useful for predictions. However,
    problems arise with high cardinality categoricals when using one-hot or ordinal
    encoding. High cardinality is a weak point for both linear and tree-based models.
    When one-hot encoded, high cardinality categoricals produce sparse matrices that
    cannot easily be turned into dense ones because of memory limitations. In addition,
    decision trees with many branching levels may need help splitting ordinally encoded
    high cardinality categorical features into meaningful partitions for prediction.
  prefs: []
  type: TYPE_NORMAL
- en: There is no commonly fixed standard to declare when a categorical is high cardinality
    because that also depends on how many rows your dataset has and how large one-hot
    encoded features your computer memory could handle. However, high cardinality
    categorical features generally include IDs, zip codes, and product or geographical
    names with many unique values. For instance, a reasonable threshold could be over
    512, but it may be lower depending on the dataset. Using the rule of thumb that
    the number of classes in a feature should not exceed 5%–10% of the total rows
    in the dataset, 512 may be too high for smaller datasets. In such circumstances,
    standard practice, especially from data science competitions such as Kaggle’s,
    suggests resorting to *target encoding* (also known as *mean encoding*).
  prefs: []
  type: TYPE_NORMAL
- en: 'First presented in the paper by Micci-Barreca, “A Preprocessing Scheme for
    High-Cardinality Attributes in Classification and Prediction Problems” (ACM SIGKDD
    Explorations Newsletter 3.1, 2001), target encoding is simply a way to transform
    the values in a categorical feature into their corresponding expected target values.
    If your problem is a regression, target encoding will use the average target value
    corresponding to that value in the dataset, with a classification problem: conditional
    probability or odds ratio. Such a process, bringing about the risk of overfitting
    for the model when the category has few examples in the dataset, is mitigated
    by using a weighted average between the expected value for that category (posterior
    probability of the target) and the average expected value of all the dataset (the
    prior probability of the target over all the training data).'
  prefs: []
  type: TYPE_NORMAL
- en: Target encoding is available in the category-encoders package ([https://mng.bz/gave](https://mng.bz/gave)),
    a Scikit-learn compatible project as the target TargetEncoder class ([https://mng.bz/5glq](https://mng.bz/5glq)),
    and you can install it by a `pip` `install` `category_encoders` command in the
    shell. In the TargetEncoder class, you have to specify a smoothing parameter (to
    be fixed at a value above zero) to balance between the posterior probability of
    the target and the prior probability all over the training data. The best smoothing
    parameter for your data has to be found by experimentation, or you can rely on
    another similar encoder, the James Steiner encoder, which guesses the best way
    to smooth your expected target values based on the variance conditioned by the
    category you want to encode ([https://mng.bz/5glq](https://mng.bz/5glq)). The
    James Stenier encoder makes stronger assumptions about your data. You have to
    decide among different ways to estimate conditional variance by the model parameter
    (for regression problems, it is advisable to use “independent” and for classification
    ones, “binary”). Still, it lifts you from experimenting with different blending
    thresholds as if it were a hyperparameter.
  prefs: []
  type: TYPE_NORMAL
- en: In our example, we use the `neighborhood` feature, which has over 200 unique
    values, and the latitude and longitude coordinates after mapping them into a 100
    x 100 grid space. The mapping returns a feature presenting over 2,000 distinct
    values, which makes it a high cardinality categorical feature without any doubt.
    In listing 6.3, we first bin latitude and longitude and then combine them by summing
    them in a way that results in a distinct code for every bin combination of latitude
    and longitude. Binning is obtained by dividing the range between the feature’s
    minimum and maximum value into equal parts. Also, the code snippet performs binning
    on two separate features, resulting in sets of integer values for each feature.
    The values of one feature are multiplied by a power of 10, which is larger than
    the maximum value of the other feature. This ensures that a unique value is always
    obtained when the two sets of values are summed, regardless of the specific values
    being summed.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.3 Creating a high cardinality categorical feature
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: ① Function to convert numerical data into categorical bins
  prefs: []
  type: TYPE_NORMAL
- en: ② Converts latitude and longitude to categorical coordinates
  prefs: []
  type: TYPE_NORMAL
- en: ③ Prints the number of unique values in the high-cardinality categorical features
  prefs: []
  type: TYPE_NORMAL
- en: 'The code snippet closes by checking the number of unique values for each feature
    among the high cardinality ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: With two categorical features considered high cardinality, we can add to our
    preprocessing pipeline the `TargetEncoder` from category-encoders.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.4 Using target encoding in the pipeline
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: ① Initializes TargetEncoder for high cardinality categorical features
  prefs: []
  type: TYPE_NORMAL
- en: ② Smoothes value to blend prior and posterior probabilities
  prefs: []
  type: TYPE_NORMAL
- en: ③ Initializes XGBoost classifier with specific hyperparameters
  prefs: []
  type: TYPE_NORMAL
- en: ④ Defines ColumnTransformer for preprocessing features with TargetEncoder for
    high cardinality categorical features
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Creates a pipeline that combines preprocessing and modeling
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Performs five-fold cross-validation and obtaining evaluation metrics
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Prints mean accuracy, fit time, and prediction time from cross-validation
  prefs: []
  type: TYPE_NORMAL
- en: 'When executed, the code procedures the results for running XGBoost on the problem
    with the extra help of the high cardinality categorical features. The results
    point to a slight improvement in the accuracy. Later in this chapter, we will
    investigate the weight of the contribution by target encoding when examining the
    explainability:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Although target encoding is a convenient procedure because it may quickly transform
    any categorical into a numeric feature, in doing so, you have to pay attention
    to keeping all important information from your data. Target encoding renders further
    modeling of any interaction between features impossible. Let’s say, for instance,
    that you are working on an advertising response dataset with click results for
    many websites and advertising formats. If you encode both features, having transformed
    two high cardinality categoricals with potentially thousands and thousands of
    values, you may easily create any kind of classical model. However, after encoding,
    your model, whether linear or tree-based, won’t be able to grasp any possible
    interaction between the encoded features. In this case, the solution is to create
    a new feature beforehand, combining the two high cardinality categorical features
    and then target encode their combination.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hence, as for other tools, we should consider the pros and cons of this advanced
    encoding technicality. In our experience, depending on the situation, before resorting
    to target encoding, there are a few options for classic machine learning algorithms
    and for gradient boosting for dealing with high cardinality categorical features:'
  prefs: []
  type: TYPE_NORMAL
- en: Just dropping problematic categorical features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a OneHotEncoder
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using an OrdinalEncoder and treating categories as ordered equidistant quantities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using an OrdinalEncoder and relying on the native category support of gradient
    boosting histogram-based algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using target encoding as a last resort
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dropping features is only sometimes considered. However, we already mentioned
    in chapter 2 how you can evaluate how a nominal feature can contribute to predicting
    a target utilizing Cramer’s V measure of association.
  prefs: []
  type: TYPE_NORMAL
- en: When confronted with a high cardinality categorical feature, opting for one-hot
    encoding is almost necessary for linear models. When dealing with other models,
    such as decision trees and their ensembles, there might be a more suitable approach.
    This is because one-hot encoding creates an additional feature for each category
    value of the categorical feature. This leads to an increased number of split points
    that the tree-based model must consider during fitting. Consequently, using one-hot
    encoded data requires more depth in a decision tree to achieve an equivalent split
    that could be achieved with a single split point using a different way of handling
    the categorical feature.
  prefs: []
  type: TYPE_NORMAL
- en: For an ordinal encoder, the categories are encoded as 0, 1, 2, and so on, treating
    them as continuous features. While this approach can be misleading for linear
    models, it works effectively for decision trees. Decision trees can accurately
    split the data based on ordinal encoding, separating the categories according
    to their relationship with the target variable. This happens with XGBoost, which
    treats all the features as numerical, continuous features.
  prefs: []
  type: TYPE_NORMAL
- en: If we decide to use the native support for categorical features, this option
    is available in LightGBM and in the version of XGBoost provided by the H2O.ai
    library ([https://mng.bz/6e75](https://mng.bz/6e75)). Native categorical support
    allows these models to handle categorical features more effectively, without converting
    them into numerical values. In that case, since native handling requires sorting
    categories, we expect the algorithm to be slightly slower when using native handling
    of categorical features with respect to treating categories as ordinal numbers.
    In the native category support, the sorting of the categories of a feature is
    based on the associated target variance for each category. Once the sorting has
    happened, the feature can be used as a continuous numerical attribute.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1.4 Transforming numerical data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Decision trees can automatically handle nonlinearities and interactions in data.
    This is because they can split a variable at any point into two parts and then
    further split them repeatedly. This property comes in particularly handy for handling
    subtle and deep interactions in the data, with a caveat, because decision trees
    are quite rough approximators. Under the aspect of precisely modeling complex
    relationships in data, neural networks with enough examples are better approximators.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.1 shows how a bagged ensemble of decision trees can approximate a nonlinear
    function. The result is an approximation constructed by a set of if-then-else
    decision rules that recursively divide the space. However, noise in the data can
    result in inaccuracies in certain parts of the space. In contrast, a neural network
    with the same number of nodes as the trees used in the bagged decision trees can
    provide a smoother and more accurate curve estimation.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH06_F01_Ryan2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.1 Comparison of predictions between a neural network and a bagged trees
    ensemble for a random dataset with a noisy sine function
  prefs: []
  type: TYPE_NORMAL
- en: Since GBDT is also based on decision trees, it may similarly struggle in shaping
    nonlinear functions using binary splits. Consequently, when using GBDT, and you
    know specific nonlinearities or interactions, it benefits you to explicitly define
    them by using transformations toward linear forms, binning or discretization,
    and precomputed interactions between features. For nonlinearities, transformations
    help reduce the number of splits. In addition, computing specific interactions
    beforehand also reduces the number of splits, which occur at better split points.
  prefs: []
  type: TYPE_NORMAL
- en: However, before applying such transformations, you need to understand your data.
    Linearities and nonlinearities, even if there is no relationship with the target,
    can be easily spotted after you complete fitting your training data by a partial
    dependence plot (PDP). This model-agnostic chart technique explains how features
    and targets are related through the model you have trained.
  prefs: []
  type: TYPE_NORMAL
- en: PDPs display how the target output changes based on specific input features
    while ignoring the effects of other input features. In other words, it shows us
    the average expected prediction if we set a certain value on all the data points
    of the specific input feature we are examining. The assumption underlying the
    analysis is that the input we represent by a PDP is independent of other features.
    Under such conditions, the PDP represents how the input feature directly affects
    the target. However, this assumption is often violated in practice, meaning that
    the input feature we are examining is usually not completely independent of the
    other features. As a result, the plot typically shows how the target value changes
    as we vary the value of the input feature, while also reflecting the average effects
    of the other features in the model.
  prefs: []
  type: TYPE_NORMAL
- en: In listing 6.5, we explore PDPs’ possible usage and limitations. Given an XGBoost
    model trained on our Airbnb NYC dataset, we demonstrate how our target changes
    regarding our numeric features, trying to spot any nonlinearities or other characteristics
    of the modeled data. The four resulting charts are plotted using matplotlib axes
    and are to be analyzed.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.5 Partial dependence plot
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: ① Creates a model pipeline combining data processing and XGBoost classifier
  prefs: []
  type: TYPE_NORMAL
- en: ② Creates a 2 × 2 subplot layout
  prefs: []
  type: TYPE_NORMAL
- en: ③ Creates a partial dependence plot of the average effect
  prefs: []
  type: TYPE_NORMAL
- en: ④ A list specifying features for the plot
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Adds a red dashed line at y=0.5 on each subplot, a reference line for interpretation
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.2 shows the four charts. The dashed line marks the classification threshold
    for one (above or equal to 0.5) and zero (below 0.5). The solid line describes
    the relationship between the feature value on the x-axis and the target probability
    on the y-axis. The tick marks on the x-axes point out the distribution deciles
    of the feature, hinting at ranges denser (where the ticks are next to each other)
    with values and at those sparser (where the ticks are farther from each other).
    Ranges sparser with values are less reliable in their estimates. For instance,
    `minimum_nights` and `calculated_host_listings_count` display a nonlinear pattern,
    whereas `number_of_reviews` and `availability_365` oscillate stationary.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH06_F02_Ryan2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.2 A panel of PDPs for numeric features
  prefs: []
  type: TYPE_NORMAL
- en: Given such results, you may evaluate to try to transform `minimum_nights` and
    `calculated_host_listings_count` using transformative functions by trial and error,
    such as
  prefs: []
  type: TYPE_NORMAL
- en: Square or cubic transformations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Square root or cube root
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Log or exponent transformations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tangent, sine, and cosine transformations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inverse, squared inverse, cubed inverse, square root inverse, cube root inverse
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Log inverse, exponent inverse, tangent inverse, sine inverse, cosine inverse
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, before rushing to test transformation, it is important to verify if
    the obtained PDP average curve represents that feature’s behavior under all circumstances.
    You can verify that using individual conditional expectation (ICE) plots. ICE
    plots are the single components of the PDP curve. You can obtain ICE plots with
    a slight change in the previous code.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.6 ICE plots
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: ① Creates a partial dependence plot showing both individual and average effects
  prefs: []
  type: TYPE_NORMAL
- en: ② Uses a random subset of 30% of data for plotting efficiency
  prefs: []
  type: TYPE_NORMAL
- en: After running the code, you may examine the results, as seen in figure 6.3\.
    You can see the same PDP average curve as before, represented with a dashed lighter
    line, and a sample of 30 curves taken randomly from the sample. Suppose you can
    verify that the sampled curves are being clustered together, approximately reproducing
    the shape of the average curve. In that case, you have a confirmation that the
    average PDP curve is representative of the behavior of the feature with respect
    to the target. Otherwise, as in our example, if the single curve appears different
    and dispersed, the other features somehow mediate the feature’s relationship because
    of collinearity or interactions, and you cannot benefit much from transforming
    the feature.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH06_F03_Ryan2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.3 A panel of ICE plots for numeric features
  prefs: []
  type: TYPE_NORMAL
- en: Up to now, we have just used PDP for numeric features. Still, you can also apply
    them to binary and categorical features after encoding them by one-hot encoding.
    In this case, you have first to compute the curve value by the stand-alone function
    `partial_dependence` and afterward represent the obtained values as bars (for
    PDP average curves) or boxplots (for PDP and ICE curves together). In the following
    listing, we extract the necessary values and create a box plot representation
    for the single levels of the `neighbourhood_group`.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.7 Partial dependence plot for binary features
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: ① Imports the partial_dependence function that computes the curve values
  prefs: []
  type: TYPE_NORMAL
- en: ② Creates a box plot of individual ICE curves
  prefs: []
  type: TYPE_NORMAL
- en: ③ Adds a red dashed line at y = 0.5 on each subplot, a reference line for interpretation
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.4 shows the result, providing insights on how a flat’s location in
    Manhattan is usually associated with higher prices. The other locations are associated
    with lower prices, according to the model. However, Brooklyn shows the largest
    variability, with sometimes higher prices similar to Manhattan, clearly depending
    on other factors related to the exact position or characteristics of the flat.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH06_F04_Ryan2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.4 For each binary feature, the boxplot associated target values obtained
    by PDP
  prefs: []
  type: TYPE_NORMAL
- en: As with numeric features, PDP curves also provide useful insight on how to power
    up your model. For instance, they can be used to aggregate the levels of a categorical
    feature that behave the same—in our example, Bronx, Staten Island, and probably
    also Queens.
  prefs: []
  type: TYPE_NORMAL
- en: PDPs show us what we can expect from the target output based on the input features
    we’re interested in. They also help us understand the relationship between the
    target response and the input feature of interest, whether linear or nonlinear.
    By observing the shape of the curve drawn by the analysis, we can also figure
    out what transformation could linearize it. When providing the `features` parameter
    of the `PartialDependenceDisplay` function with tuples of features, the function
    will output a contour map showing the conjoint effects of two specific features.
    Discovering interactions this way is long and tedious, especially if you have
    many features to explore. A solution would be to automatically discover the potential
    interactions and then test them with the PDP conjoint chart. Detecting interactions
    automatically using XGBoost is straightforward by using a project such as XGBoost
    Feature Interactions Reshaped (XGBFIR; [https://github.com/limexp/xgbfir](https://github.com/limexp/xgbfir)).
    The following listing shows an example you can run after installing the package
    by `pip` `install` `xgbfir` on a command shell.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.8 Discovering interactions by XGBFIR
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: ① Generates a report with xgbfir and saves it to an Excel file
  prefs: []
  type: TYPE_NORMAL
- en: ② Reads the Excel file created in the previous steps
  prefs: []
  type: TYPE_NORMAL
- en: ③ Extracts and sorts based on split gain the “Interaction” and “Gain” columns
    from the feature interaction report
  prefs: []
  type: TYPE_NORMAL
- en: ④ Generates a partial dependence plot for the features “minimum_nights” and
    “calculated_host_listings_count”
  prefs: []
  type: TYPE_NORMAL
- en: The code will print a series of interactions. If you work with a linear model,
    each interaction returned by XGBFIR should be tested because they could enhance
    your model’s performance. If you work with decision trees, you can ignore the
    ones that involve a binary feature and concentrate on only numeric ones. An example
    is the interaction between `minimum_nights` and `calculated_host_listings_count`.
    Figure 6.5 shows how combining them with specific values is strongly associated
    with a positive target response.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH06_F05_Ryan2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.5 Conjoint PDP for two numeric features
  prefs: []
  type: TYPE_NORMAL
- en: In such cases, combining the numeric features by multiplying them will optimize
    your GDBT model much faster and more effectively.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2 Selecting features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Feature selection is not always necessary. Still, when it is, it plays a vital
    role in identifying the most valuable features for training among the existing
    set of features, whether they derive directly from the data extraction or are
    the product of your feature engineering work. By employing effective feature selection
    techniques, you can pinpoint and retain the most relevant features that contribute
    significantly to the machine learning process.
  prefs: []
  type: TYPE_NORMAL
- en: In chapter 2, section 2.2.3, we discussed avoiding collecting irrelevant and
    redundant features for the tasks based on your knowledge of the problem and exploratory
    data analysis. In the subsequent chapters, we discussed machine learning algorithms
    that handle irrelevant and redundant features.
  prefs: []
  type: TYPE_NORMAL
- en: In classic machine learning, we have a large set of algorithms, including the
    family of linear models, that are particularly susceptible to irrelevant and redundant
    features, reducing performance and accuracy. Uninformative and noisy features,
    deemed irrelevant because they lack a meaningful association with the target of
    the learning task, can pose significant challenges for linear models. This is
    due to the possibility of random alignment between the feature values and the
    target, which can mislead the algorithm and assign undue importance to these features.
    Linear models utilize all the features provided, making them particularly vulnerable
    since the more noisy features there are, the more the results will be degraded.
    Ensembles based on decision trees are instead less affected by irrelevant and
    redundant features because they automatically select what features to use and
    ignore. This also happens with deep learning. However, deep learning may not be
    as robust as decision tree ensemble methods when dealing with noisy or irrelevant
    features on tabular data. For optimal performance under such conditions, large
    amounts of data are required, as well as careful choice of architecture, such
    as using dropout, regularization, or batch normalization layers, and tuning of
    learning rates.
  prefs: []
  type: TYPE_NORMAL
- en: Feature selection benefits classic machine learning algorithms such as linear
    models. However, it is also valuable in the case of decision tree-based ensembles
    and deep learning architectures, and it should not be ignored that it makes a
    machine learning process faster because of fewer columns to handle. By selecting
    the features before training, these complex algorithms can achieve improved clarity
    and ease of explanation by distilling the most relevant and informative features
    and enabling a clearer understanding of the underlying patterns and relationships
    captured by the models. This simplification enhances interpretability and facilitates
    the communication of the algorithm’s decision-making process.
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we discuss and test a few solutions that can work
    well, stand-alone or sequentially, to select only essential features for solving
    your tabular data problem with the best results. We discuss algorithms for figuring
    out both relevant features (the all-relevant set), which may lead to redundant
    but useful sets of features, from algorithms to select minimal subsets of features
    (the nonredundant set) that produce models comparable to the set of relevant features
    but with the added advantage of increased interpretability due to a fewer number
    of features.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.1 Stability selection for linear models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Stability selection* is based on the idea that if you use a variable selection
    procedure, you won’t always get the same results if you subsample or bootstrap
    your data because of variability in the process itself. For instance, if you use
    L1 regularization for feature selection in a linear model, you may find that different
    samples may return different non-zero coefficients, especially for highly correlated
    features.'
  prefs: []
  type: TYPE_NORMAL
- en: As we have discussed, the L1 regularization penalty results in sparsity in the
    coefficient estimates. It works by adding a penalty term to the loss function,
    the sum of the absolute values of the coefficients. Such a penalty term imposes
    a constraint on the sum of the absolute magnitudes of the coefficients, promoting
    some coefficients to become exactly zero. Consequently, the L1 regularization
    can effectively select features by shrinking some coefficients to zero and excluding
    the corresponding features from the model. In the presence of highly correlated
    features, the L1 regularization may face difficulty selecting a unique set of
    features due to their similarity in their contributions to the target variable.
    Here, chance plays a role in the fact that certain features get non-zero coefficients
    depending on what data you have in your sample. However, this can be used to our
    advantage.
  prefs: []
  type: TYPE_NORMAL
- en: By introducing randomness through data sampling, stability selection aims to
    identify features that consistently appear important across multiple subsets,
    indicating their robustness and reducing the likelihood of selecting features
    by chance or noise. Stability selection will provide a useful set of features,
    not a minimal one. By ruling out unimportant features, stability selection ensures
    that all the relevant features are identified, thus making it a perfect algorithm
    for the first step in reducing the number of your features.
  prefs: []
  type: TYPE_NORMAL
- en: Presented in the paper by Meinshausen and Büehlmann ([https://arxiv.org/abs/0809.2932](https://arxiv.org/abs/0809.2932)),
    for some time, stability selection has been offered as part of Scikit-learn and
    then maintained among the Scikit-learn compatible projects. We can easily replicate
    its procedures using Scikit-learn’s `BaggingClassifier` with `LogisticRegression`
    with L1 regularization for a classification problem. You can also adopt the same
    code for regression problems, using `BaggingRegressor` with the L1 regression
    class, `Lasso`.
  prefs: []
  type: TYPE_NORMAL
- en: In our implementation, we test a series of C values for the L1 logistic regression
    against bootstrap resamples. The procedure creates a series of logistic regression
    coefficients that we can sum, average, or count how many times they differ from
    zero. Given that we are using a mix of binary and continuous features, we find
    it more useful to count the times the coefficient associated with a variable has
    an absolute value above a threshold. Thus, we can finally deem all the features
    that, most of the time, tend to have a relevant coefficient as relevant, which
    can affect the resulting prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.9 Stability selection
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: ① Generates a grid of lambda values using a logarithmic scale for use in L1
    regularization
  prefs: []
  type: TYPE_NORMAL
- en: ② Creates a Logistic Regression estimator with L1 (Lasso) penalty
  prefs: []
  type: TYPE_NORMAL
- en: ③ Creates a BaggingClassifier that uses the Logistic Regression estimator as
    its base model
  prefs: []
  type: TYPE_NORMAL
- en: ④ Standardizes after data processing renders all the coefficients comparable,
    no matter the scale
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Sets a small value as epsilon for a threshold
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Sets a threshold value for selecting significant coefficients
  prefs: []
  type: TYPE_NORMAL
- en: 'The output highlights both the distributions of relevant coefficients and the
    selected features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Stability selection offers several advantages. It can handle high-dimensional
    data, avoid overfitting by incorporating randomness, and provide a measure of
    feature importance that considers the selection process’s stability. It is commonly
    used in applications with large features, such as genomics, text mining, or image
    analysis. On the other hand, the selection algorithm is limited to classic machine
    learning algorithms that use L1 regularization and return a set of coefficients,
    which are among the ones we discussed before: logistic regression and lasso regression.
    You can extend the concept proposed by stability selection by using feature importance
    (many ensemble models estimate feature importance), such as done in Scikit-learn
    by the command `SelectFromModel` ([https://mng.bz/oKej](https://mng.bz/oKej)),
    but things will get trickier because you’ll have to figure how what makes an importance
    estimate relevant and what selection threshold to use. In the next section, we
    reprise how feature importance works, and we present Boruta. Using a solid automatic
    feature selection procedure, this algorithm can figure out the relevant features
    for a decision-tree ensemble, such as random forests or gradient boosting.'
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.2 Shadow features and Boruta
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Boruta is a smart procedure for determining whether a feature is relevant in
    a machine learning problem by relying on the internal parameters of the model,
    such as coefficients in linear models or importance values based on gain, such
    as in decision trees and their ensembles. It was first published in “Feature Selection
    with the Boruta Package” by Miron B. Kursa and Witold R. Rudnicki [*Journal of
    Statistical Software* 36 (2010): 1-13]; for a copy of the article, see [https://www.jstatsoft.org/article/view/v036i11](https://www.jstatsoft.org/article/view/v036i11).'
  prefs: []
  type: TYPE_NORMAL
- en: Boruta, although innovative, presents quite a few analogies with stability selection.
    It can be used only with decision tree-based ensembles. To measure the relevance
    of a feature, as in stability selection, we look for non-zero coefficients. In
    Boruta, we count the times when the importance of a feature exceeds the highest
    importance obtained by shadow features. We call them hits. Shadow features are
    random versions of the feature themselves (basically shuffled features), which,
    given that they are random, should attain any importance just by chance. If any
    feature cannot exceed the same importance of a shadow feature, it cannot be considered
    more predictive than any random sequence of values.
  prefs: []
  type: TYPE_NORMAL
- en: A threshold for selection, usually a minimum number of occurrences of non-zero
    coefficients in stability selection, is given in Boruta by how the number of hits
    translates into a binomial distribution. A significance threshold for retaining
    or dropping a feature test according to the distribution if the number of hits
    can prove that the feature is consistently better than any random construct.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.10 shows an example using Boruta to select all the relevant features
    for an XGBoost classification on the Airbnb NYC dataset. Boruta in the BorutaPy
    implementation ([https://github.com/scikit-learn-contrib/boruta_py](https://github.com/scikit-learn-contrib/boruta_py))
    has some limitations because, apart from working only with tree-based models,
    such as random forests or gradient boosting (no matter what the implementation
    is), it cannot work with pipelines. Hence, we first had to transform the data
    and then run Boruta on the transformed features as we were training the final
    model. Boruta takes as key parameters the estimator—that is, the model you want
    to use, the number of decision trees in the ensemble, and the `n_estimators` hyperparameter,
    which can be left empty, set to an integer, or set to “auto” where the number
    of trees is decided upon the size of the dataset. Other important parameters in
    Boruta are `max_iter`, the number of rounds of testing, usually set to 100, and
    the alpha threshold for the binomial test, which can be increased from 0.05 to
    allow for more features to be retained or decreased for more features to be discarded.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.10 Boruta selection
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: ① Transforms the input data, performing any necessary preprocessing steps
  prefs: []
  type: TYPE_NORMAL
- en: ② Initializes a BorutaPy feature selection object using an XGBoost classifier
  prefs: []
  type: TYPE_NORMAL
- en: ③ Fits the Boruta feature selector
  prefs: []
  type: TYPE_NORMAL
- en: ④ Retrieves a Boolean mask of selected features determined by the Boruta feature
    selector
  prefs: []
  type: TYPE_NORMAL
- en: 'After a few iterations, you should get the results of only a single feature
    discarded as not relevant to the problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The same procedure can be executed using LightGBM as predictor, instead of
    XGBoost:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: ① Initializes a BorutaPy feature selection object using the provided LightGBM
    classifier
  prefs: []
  type: TYPE_NORMAL
- en: 'The result is reached after only 9 iterations, and this time, we have an increased
    number of rejected features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: LightGBM not only converges more quickly, but the way it splits allows, in this
    problem, the creation of a performing model with many fewer features than XGBoost.
  prefs: []
  type: TYPE_NORMAL
- en: In our example, we have trained on all the available data. Still, you can use
    Boruta even in a cross-validation loop, where you can consolidate a result for
    the dataset by using all the selected features in all the folds or by only those
    selected at least a minimum number of times across the folds.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.3 Forward and backward selection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One limitation of Boruta is that it selects all the relevant features for your
    problem but not the essential ones. This means you may end up with a list with
    redundant and highly correlated features that can be cut to a shorter selection.
    After applying Boruta, we suggest resorting to a sequential feature selection
    procedure, as implemented in the Scikit-learn function `SequentialFeatureSelector`.
    This procedure adds by forward selection or removes by backward elimination features
    from your selection based on their performance on the prediction in a greedy fashion—that
    is, always picking up the best-performing choice, based on the cross-validation
    score, in terms of addition or discard. The technique relies on the learning algorithm
    and its objective function. Hence, its selection will always be among the best
    possible. Since it is a greedy procedure, there is always the risk of choosing
    a local optimum set.
  prefs: []
  type: TYPE_NORMAL
- en: Sequential selection is a very effective procedure in reducing the number of
    features you have to deal with. Still, it is quite time-consuming because the
    algorithm has to evaluate all the candidates at each round. In the forward procedure,
    this will turn slower and slower as you proceed because, despite having fewer
    candidates to evaluate at each round, the increasing number of features used will
    slow down the training. However, in the backward procedure, you start slow and
    tend to accelerate after discarding a number of features. The backward procedure
    may be impractical if you start from many features to evaluate and the training
    is very slow.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a stopping rule for the procedure, you may set a certain number of features,
    or you can leave the selection algorithm to find out the point at which adding
    or removing a feature bears no more improvements to the predictions. A tolerance
    threshold helps give the algorithm a certain freedom to proceed or not: the larger
    the tolerance, the more likely the algorithm will proceed in its operations, even
    if adding or removing a feature somehow deteriorates the performance.'
  prefs: []
  type: TYPE_NORMAL
- en: In listing 6.11, we apply a forward selection to an XGBoost model trained on
    the Airbnb NYC dataset. The selection algorithm is set free to determine the correct
    number of features to add, and the low tolerance (set to 0.0001 on accuracy measures
    ranging from 0 to 1) should stop it at the first signs of deterioration of the
    predictive performances.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.11 Forward selection
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: ① Initializes a KFold cross-validation splitter object with five folds
  prefs: []
  type: TYPE_NORMAL
- en: ② Creates a scoring function for use in the feature selection process
  prefs: []
  type: TYPE_NORMAL
- en: ③ Sets a tolerance value used by the sequential feature selector to determine
    convergence during the search
  prefs: []
  type: TYPE_NORMAL
- en: ④ Specifies the direction of feature selection (which is “forward” in this case)
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Retrieves a boolean mask of selected features
  prefs: []
  type: TYPE_NORMAL
- en: 'The obtained results point out to six features to be used: three binary ones,
    a high cardinality categorical, and two numeric ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We can replicate the experiment in a backward fashion by running the following
    commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: ① Specifies the direction of feature selection (which is “backward” in this
    case)
  prefs: []
  type: TYPE_NORMAL
- en: 'The resulting selection is made of nine features, many of those already seen
    in the set resulting from the forward selection:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: In our own experience, choosing a forward or backward selection depends on the
    need you may have to risk leaving out some slightly important feature from your
    chosen set. With forward addition, you are sure to keep only the essential features
    but risk leaving something marginally relevant out. With the backward elimination,
    you are assured that all the key features are in the set, allowing for some redundancy.
  prefs: []
  type: TYPE_NORMAL
- en: Besides choosing a forward or backward procedure, sequential selection will
    help you build models faster in training and prediction and will be much easier
    to interpret and maintain because of the limited number of features involved.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3 Optimizing hyperparameters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Feature engineering can improve the results you obtain from your classical machine
    learning models. Creating new features can reveal the underlying patterns and
    relationships in data that the models cannot grasp because of their limitations.
    Feature selection can improve your models’ results by removing unuseful and redundant
    features for the problem, thus reducing the noise and spurious signals in data.
    Finally, by optimizing hyperparameters, you can gain another performance boost
    and have your classical machine learning model shine on the tabular data problem
    you are dealing with.
  prefs: []
  type: TYPE_NORMAL
- en: As discussed in chapter 4, hyperparameters are those settings that work under
    the hood of all machine learning algorithms and determine how specifically they
    can work. From an abstract point of view, each machine learning algorithm potentially
    offers a limited, yet still wide, range of functional forms—that is, the mathematical
    ways you can relate your predictor variables to your outcome. Straight out of
    the box, a machine learning algorithm may less or more match the functional form
    required by your specific machine learning problem.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, if you are using a gradient boosting algorithm to solve a classification
    problem, it may be that the default number of iterations or how its trees are
    grown do not match the requirements of the problem. You may need fewer or more
    iterations and tree growth than specified by the default values. By opportunely
    setting its hyperparameters, you can find the best settings that work better with
    your problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, it is not just a matter of twiddling all the many knobs that an algorithm
    presents until it gets the results you expect. Sometimes the knobs are too many
    to be tested together, and even if you manage to test enough of them, if not done
    properly, it will result in overfitting your data and, on the contrary, obtaining
    worse results. You need a systematic approach after defining one or more evaluation
    metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: Defining a search space containing the hyperparameters whose effects you want
    to explore and the boundaries of the values to test
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a proper cross-validation scheme to ensure that you are discovering
    a solution that generalizes beyond the data you have
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing a search algorithm that, by a proper strategy, will find out in less
    time and with less cost—for instance, in terms of computations—the solution you
    need
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following subsections, under the light of different search strategies,
    we discuss the way you can accomplish tuning some of the classical machine learning
    algorithms we have seen so far.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1 Searching systematically
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Grid search works through all the possible combinations of hyperparameters’
    values. For every hyperparameter you want to test, you pick a sequence of values
    and iterate through all their combinations exhaustively. In the end, you pick
    the combination that returns the best results.
  prefs: []
  type: TYPE_NORMAL
- en: In listing 6.12, we apply it to a logistic regression model, helping to choose
    the kind of regularization and the settings of L1 and L2 regularization values.
    The most important part of the code is the search grid, which is a list containing
    one or multiple dictionaries. Instead, each dictionary is a search space, a sequence
    of hyperparameters (the keys of the dictionary) associated with a list of a generator
    of values, which are the possible values you want to test (the values of the dictionary).
    Structuring one or more search spaces is a common practice across all the optimization
    methods, whether they are from Scikit-learn or not. Just notice how the name of
    the hyperparameters are formulated in the form `model__name_of_the_hyperparameter`
    because we are optimizing a pipeline and addressing parameters that are first
    internal to the pipeline and then of the model. We will come back to this in the
    next subsection with more explanations.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.12 Grid search
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: ① A list of dictionaries specifying a search grid of hyperparameters for the
    logistic regression model
  prefs: []
  type: TYPE_NORMAL
- en: ② Initializes a GridSearchCV object using the defined search grid
  prefs: []
  type: TYPE_NORMAL
- en: ③ Prints the best hyperparameters found by the grid search
  prefs: []
  type: TYPE_NORMAL
- en: ④ Prints the best score achieved by the model using the best hyperparameters
    found during the grid search
  prefs: []
  type: TYPE_NORMAL
- en: 'After testing all the combinations, the grid search procedure returns that
    the best set of hyperparameters is just not to use any penalty at all. It returns
    the best cross-validated score in support of its report:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Grid search is effective when your hyperparameters are few; they take discrete
    values, and you can parallelize in memory the testing operations because your
    dataset is not too large.
  prefs: []
  type: TYPE_NORMAL
- en: First, the more combinations, the more tests you have to take and the longer
    and more computations you’ll have to spend. It could be a serious problem if you
    need to test many hyperparameters and suspect some of them are irrelevant for
    properly tuning your algorithm. When you add a hyperparameter to the grid search,
    you must make all the other hyperparameters cycle through it, which can turn into
    a waste of energy if the hyperparameter you are testing is irrelevant.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, if a parameter takes continuous values, you must decide how to
    turn its continuous search space into a discrete one. Usually, this is done by
    uniformly dividing the continuum of values into discrete values, but by doing
    so without any knowledge of the way the algorithm behaves with respect to that
    hyperparameter and its values may again turn into wasting multiple computations
    on testing values that cannot improve the algorithm performances.
  prefs: []
  type: TYPE_NORMAL
- en: The last aspect to consider is using multiple cores and parallelizing their
    operations. Grid search is completely unaware of the results each test obtains.
    The results are only ranked at the end, and you are offered the best result. Hence,
    grid search is fine if your algorithm naturally works on a single core. However,
    suppose your algorithm uses multiple threads and cores, such as a random forest
    or an XGBoost. In that case, you have to trade off between having the algorithm
    running at full speed or having the optimization procedure go parallel and speedier.
    Usually, the best choice is to push the algorithm to run faster by using parallel
    running. Regardless of whether you decide to take advantage of the parallelization
    capabilities of the algorithm or those of the search procedure, grid search is
    not the best-performing option when working with a multicore algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Based on our experience and the limits of the grid search strategy, we deem
    it the best fit for testing linear models since they are easily parallelizable
    and have few limited parameters, often characterized by taking Boolean or discrete
    values.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.2 Using random trials
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Important limitations when using grid search are that
  prefs: []
  type: TYPE_NORMAL
- en: You need to discretize continuous hyperparameters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If a hyperparameter is irrelevant to the problem, you are going to have many
    trials wasted as they test the space of the irrelevant feature.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For these reasons, the idea of sampling the search space randomly is rooted
    in the machine learning community. As described in the paper “Random Search for
    Hyper-Parameter Optimization” by James Bergstra and Yoshua Bengio (*Journal of
    Machine Learning Research;* [https://mng.bz/nRg8](https://mng.bz/nRg8)), random
    search optimization becomes the standard optimization when you have many hyperparameters
    and you don’t know exactly how they affect the results or how they work together.
  prefs: []
  type: TYPE_NORMAL
- en: In our example, we reprise our classification problem using an XGBoost classifier.
    XGBoost, as with other gradient boosting implementations, features several hyperparameters
    that can be deemed important, and you should try to test them to check if your
    model’s performance can be improved. In the example, we also make things a bit
    more sophisticated because we operate by the XGBoost model wrapped into a pipeline,
    thus requiring a specific way to address hyperparameters. Since each element in
    the pipeline has a name, you must address each parameter in a part of the pipeline
    by the name of the element in the pipeline, two underlines, and then the name
    of the hyperparameter. For instance, in our example, XGBoost is in a part of the
    pipeline named “xgb.” To address the hyperparameter `n_estimators` of XGBoost,
    just use the label `xgb__n_estimators` in your search space. The idea is to demonstrate
    how to optimize a model and its pipeline without testing all the possible choices
    influencing a model’s predictive performance.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.13 Random search
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: ① Creates a pipeline that combines data processing and the XGBoost classifier
  prefs: []
  type: TYPE_NORMAL
- en: ② A dictionary containing various hyperparameters with their search spaces for
    the RandomizedSearchCV
  prefs: []
  type: TYPE_NORMAL
- en: ③ Specifies the number of iterations for the random search process
  prefs: []
  type: TYPE_NORMAL
- en: ④ Specifies the number of parallel jobs to run for the search
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Prints the best hyperparameters found by the RandomizedSearchCV
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Prints the best score achieved using the best hyperparameters found during
    the random search
  prefs: []
  type: TYPE_NORMAL
- en: 'After a while (the code runs in about one hour in a Google Colab instance),
    we get the set of the best parameters and the cross-validated score obtained:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Random search optimization, in spite of its simplicity and the fact it relies
    on randomness, really works, and it provides the best optimization in many situations.
    Many AutoML systems rely on this optimization strategy when there are many hyperparameters
    to tune (see, for instance, “Google Vizier: A Service for Black-Box Optimization,”
    by D. Golovinb et al., 2017 at [https://mng.bz/8OrZ](https://mng.bz/8OrZ)). Compared
    to grid search, which works well when you have a limited set of hyperparameters
    that you expect to be impactful and a limited set of values to test, random search
    works the best when you have too many values to tune, without prior knowledge
    of how they work.'
  prefs: []
  type: TYPE_NORMAL
- en: All you have to do is rely on enough random tests to have a good combination
    emerge, which may not take long. In our experience, 30 to 60 random draws usually
    suffice for good optimization. One strong point of random search optimization
    is that it works well for complex problems and is not affected by irrelevant hyperparameters.
    The number of relevant ones determines how fast you can find a good solution.
    The algorithm is also suited for parallel search on different computers or instances
    (you pick the best result among all). Still, this positive point comes with the
    limitation that since tests are independent, they do not inform each other about
    their results.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.3 Reducing the computational burden
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Both grid search and random search do not utilize the outcomes from previous
    experiments. Grid search strictly adheres to a predefined procedure, while random
    search conducts a set of independent tests. In both cases, the prior results are
    not considered or used in any way during the search process. *Successive halving*,
    a wrapper of both strategies, can instead take advantage of knowing the prior
    results. The idea is like that of a tournament where you first hold many rounds
    and put forth few resources to test different hyperparameters’ values. Then, as
    you progress and drop the values that underperform, you invest more resources
    to test the remaining values thoroughly. Usually, the resource you initially dilute
    and then later concentrate on is the number of training examples. More examples
    imply certain results from a hyperparameter test, but it costs more computational
    power.
  prefs: []
  type: TYPE_NORMAL
- en: Available as `HalvingGridSearchCV` and `HalvingRandomSearchCV` in Scikit-learn,
    in listing 6.14, we test the random search variant to verify if we can obtain
    similar optimization results at a fraction of the time. As stated, we use the
    number of samples as a scarce resource to optimize, using just the 30% available
    at the start. In addition, we instruct the algorithm to start from 20 initial
    candidates and to decrease the number of candidates by three times at each round
    (from 20 to 6 to 2).
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.14 Halving random search
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: ① Enables the experimental HalvingRandomSearchCV module
  prefs: []
  type: TYPE_NORMAL
- en: ② Specifies that the resource being used for halving is the number of samples
  prefs: []
  type: TYPE_NORMAL
- en: ③ Sets the number of candidates that will be sampled and evaluated at the first
    iteration
  prefs: []
  type: TYPE_NORMAL
- en: ④ Determines the factor by which the number of candidates will be reduced in
    each iteration
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Sets the minimum number of resources (samples) that will be used in the halving
    process
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Sets the maximum number of resources (samples) that will be used in the halving
    process
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the results you obtain, at a fraction of the time previously
    required (in Google Colab the procedure runs in about 10 minutes):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: In our experience with this optimization strategy, the strategy is to set the
    initial round in a way that it can catch some good hyperparameters. Hence it is
    important to have the highest possible number of candidates running at a minimum
    of resources, although not so low to compromise the results of optimization. Setting
    as little as 1,000 starting samples should work sufficiently well if the factor
    parameter is reduced. This determines the proportion of candidates selected for
    each subsequent iteration to two instead of three, thus going to a longer number
    of rounds.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4 Extending your search by Bayesian methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another optimization strategy that makes informed choices is Bayesian optimization.
    Introduced in the paper “Practical Bayesian Optimization of Machine Learning Algorithms”
    by Snoek, Larochelle, and Adams ([https://arxiv.org/abs/1206.2944](https://arxiv.org/abs/1206.2944)),
    the idea behind this optimization strategy is to understand how the hyperparameters
    of a model work, by building a model of themselves. The algorithm optimizes a
    proxy function, called the surrogate function, to increase the algorithm’s performance.
    Of course, the surrogate function is updated by the feedback from the objective
    function of the machine learning model under optimization. However, the Bayesian
    optimization algorithm’s decisions are solely based on the surrogate function.
  prefs: []
  type: TYPE_NORMAL
- en: 'In particular, it is another that alternates exploration with exploitation:
    the acquisition function. The acquisition function reports how much exploring
    a certain combination of parameters is promising and how much is uncertain, based
    on the surrogate function. Exploration implies trying combinations of the parameters
    that have never been tried before, and this happens when there is much uncertainty,
    and thus consequently hope, in certain areas of the search space that need at
    least to be tried to improve the surrogate function. On the contrary, exploitation
    happens when the acquisition function ensures that the algorithm can improve performance
    when trying a certain set of hyperparameters.'
  prefs: []
  type: TYPE_NORMAL
- en: As the “Bayesian” in the name implies, and from our brief description of how
    the Bayesian optimization works under the hood, the process is influenced by prior
    expectations and subsequently corrected by posterior observations in a fine-tuning
    cycle. The surrogate function in all of this is nothing more than a model of our
    model. Usually, Gaussian processes are chosen as a model for the surrogate function.
    Still, there are alternatives, such as using tree algorithms such as random forests
    or tree-structured Parzen estimators, which are a multivariate distribution capable
    of describing the behavior of the hyperparameters in our model. Packages such
    as Scikit-optimize ([https://scikit-optimize.github.io/stable/](https://scikit-optimize.github.io/stable/))
    or KerasTuner ([https://keras.io/keras_tuner/](https://keras.io/keras_tuner/))
    use Gaussian processes, with Scikit-optimize also capable of using tree ensembles
    and KerasTuner using multiarmed bandits, as well. Optuna, an optimization framework
    developed by Preferred Networks, a Japanese AI research and development company,
    instead uses tree-structured Parzen estimators. Initially released in May 2019
    as an open-source project, Optuna is particularly popular in the Python machine
    learning community due to its simplicity, versatility, and integration with popular
    machine learning libraries such as TensorFlow, PyTorch, and Scikit-learn.
  prefs: []
  type: TYPE_NORMAL
- en: In our example, we use Optuna to improve our XGBoost classifier. When using
    Optuna, you just set up a study and provide its running parameters, such as the
    number of trials, `n_trials`, and the direction parameter if you want to minimize
    or maximize your objective function. Behind the scenes, all the heavy lifting
    is done by the objective function, which you define and returns an evaluation.
    The objective function expects just an input parameter, trial, which Optuna provides.
    By the trial parameter, you define the values of the hyperparameters to test.
    Then, you just test them as you like because it is up to you inside the objective
    function to decide if to apply a cross-validation, a simple test on a sample,
    or anything else. This flexibility also allows you to run complex optimizations
    where certain hyperparameters are used or depend on others and their values. It
    is up to you to code the procedure you want.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.15 Bayesian search with Optuna
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: ① A dictionary defining the search space for hyperparameters for Optuna
  prefs: []
  type: TYPE_NORMAL
- en: ② Creates an XGBoost classifier with hyperparameters suggested by Optuna
  prefs: []
  type: TYPE_NORMAL
- en: ③ Performs cross-validation to evaluate the model’s performance using the hyperparameters
  prefs: []
  type: TYPE_NORMAL
- en: ④ A function acting as the objective value for optimization by returning the
    mean accuracy score from cross-validation
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Creates an Optuna study object with the goal of maximizing the objective function
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Starts the optimization process using the defined objective function and a
    maximum of 60 trials
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Prints the best-achieved value of the objective function
  prefs: []
  type: TYPE_NORMAL
- en: ⑧ Prints the best hyperparameters found by Optuna
  prefs: []
  type: TYPE_NORMAL
- en: 'On a Google Colab instance, the process can take up to two hours, but the results
    are by far the best in class you can obtain from hyperparameter optimization:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'As an extra feature offered by Optuna, with a few simple additions to the previous
    code, you can store your study in a project database and restart optimization
    at any time. Optuna can integrate its optimization procedures with SQLite if,
    at the time of the creation of the study, you declare the name of the study and
    a target database:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: ① Defines the path to the SQLite database where Optuna will store study-related
    information
  prefs: []
  type: TYPE_NORMAL
- en: ② Provides a name for the Optuna study
  prefs: []
  type: TYPE_NORMAL
- en: ③ Creates an Optuna study object and connects it to the SQLite database
  prefs: []
  type: TYPE_NORMAL
- en: Regarding the specification of the SQLite storage database, `sqlite://` is a
    Uniform Resource Identifier (URI) scheme used to specify the protocol or mechanism
    for connecting to an SQLite database. In the context of the URI scheme, `sqlite://`
    indicates that the database connection will be established using the SQLite database
    engine. When using this URI scheme, the `sqlite://+` portion is followed by the
    path to the SQLite database file. In your example, `sqlite:///sqlite.db` specifies
    that the SQLite database file is named `sqlite.db` and is located in the current
    directory. The three slashes (`///`) after `sqlite:` are optional and indicate
    that the path is relative to the current directory.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the study has been completed, you can also obtain useful visualization
    regarding the results of the iterations and gain insights useful on successive
    runs of the same search. For instance, you can explore the optimization history
    and check if you have reached a plateau in the optimization or if going on with
    more iterations is advisable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Figure 6.6 shows how our optimization proceeded. After a few iterations, the
    optimization reached a good result, but then it struggled to progress through
    the rest of the available iterations. Under such conditions, further progress
    in optimization is improbable because any gains cannot be but tiny at this point.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH06_F06_Ryan2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.6 History of optimization results across the trials
  prefs: []
  type: TYPE_NORMAL
- en: 'Another useful plot depicts how the hyperparameters have been determinant in
    the resulting optimum settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Figure 6.7 shows the estimated importance of our optimization of the XGBoost
    algorithm. The results appear dominated by the `max_depth` hyperparameter and
    somehow by the subsample values. Such an outcome suggests that the algorithm is
    susceptible to the depth of the trees and that increasing the depth significantly
    affects the optimization results. This could indicate that the data contains complex
    patterns that require deeper trees to capture, and the sweet point of seven found
    by the optimization marks a point after which the algorithm starts overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH06_F07_Ryan2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.7 A plot chart of hyperparameter estimated importance during the Optuna
    optimization process
  prefs: []
  type: TYPE_NORMAL
- en: Understanding why your XGBoost (or LightGBM) behaves better under certain conditions
    differs from problem to problem. However, being able to understand why, explain
    the reasons to others (such as the stakeholders), and take steps to adjust your
    data or optimization settings is indeed an invaluable feature offered by Optuna
    in comparison to other optimization methods.
  prefs: []
  type: TYPE_NORMAL
- en: After completing the panoramic illustration on optimization techniques, we are
    left dealing with the case when you don’t want to set up anything complicated
    to make your machine learning algorithms work but you need some direction on how
    to make fast adjustments by trial and error.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.5 Manually setting hyperparameters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Despite the efficiency of the previously described optimization strategies,
    you may not be surprised to read that we know that many practitioners still tune
    the settings of their models by intuition and trial and error. Such a procedure
    seems particularly well-grounded during the experimentation phase when you try
    to make everything work reasonably as you look for ways to improve your solution
    in various iterations. A thorough optimization is, therefore, left after the processing
    and experimentation iterations have been completed.
  prefs: []
  type: TYPE_NORMAL
- en: The book’s appendices provide a comprehensive guide to the key parameters of
    the machine learning algorithms covered thus far. We begin with linear models,
    such as linear or logistic regressions, which can be effectively tuned using a
    grid search due to their limited number of parameters and ease of discretization.
    A table covers random forests and extremely randomized trees, as they share similar
    hyperparameters, being based on the same bootstrapped ensemble approach.
  prefs: []
  type: TYPE_NORMAL
- en: Regarding GBDTs, we have different sets of hyperparameters depending on the
    specific implementation. For your convenience, we have selected the most essential
    ones. Feel free to use them along with the proposed ranges for manual or automatic
    optimization. The guide starts with HistGradientBoosting and then covers XGBoost
    and LightGBM. It’s important to note that XGBoost has a larger set of relevant
    hyperparameters (you can find the complete list at [https://mng.bz/6e7e](https://mng.bz/6e7e)).
    Lastly, we include the list of hyperparameters for LightGBM, which differs slightly
    from XGBoost (you can find the complete list at [https://mng.bz/vK8q](https://mng.bz/vK8q)).
    This comprehensive guide will aid you in effectively tuning the machine learning
    algorithms and optimizing their performance based on the specific hyperparameter
    settings.
  prefs: []
  type: TYPE_NORMAL
- en: 'As for manually tuning GBDTs, the models tend to work worst out of the box,
    so you should be aware of a few tricks of the trade. Let’s begin with a 1999 paper
    titled “Greedy Function Approximation: A Gradient Boosting Machine” by Jerome
    Friedman. In this paper, Friedman discusses the tradeoff between the number of
    trees and the learning rate. It was observed that lower learning rates tend to
    result in higher optimal numbers of trees. Furthermore, it is advisable to reduce
    the learning rate when increasing the maximum depth of the decision trees in your
    model. This precautionary measure is because deeper trees introduce more complexity,
    potentially leading to overfitting. Overfitting occurs when the model becomes
    excessively tailored to the training data and performs poorly on unseen data.
    By simultaneously reducing the learning rate, you can mitigate this risk. This
    is because a lower learning rate translates to smaller and more cautious updates
    to the model. This gradual learning process allows for finer adjustments, helping
    the model strike a better balance between capturing complex relationships and
    avoiding overfitting.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another great resource for hints on manually adjusting parameters in a GBDT
    is Owen Zhang’s talk to the NYC Data Science Academy in 2015 titled “Winning Data
    Science Competitions.” Owen, previously a top competitor on Kaggle, provided a
    few interesting tips:'
  prefs: []
  type: TYPE_NORMAL
- en: Decide the number of trees to use based on the dataset size (usually in the
    range of 100 to 1,000) and keep it fixed during the optimization. Prefer fewer
    trees to more.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test the learning rate in the range from 2 to 10 divided by the number of trees.
    Hence, for 1,000 trees, test learning rates in the interval from 0.002 to 0.01.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test row sampling on 0.5, 0.75, 1.0 values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test column sampling on 0.4, 0.6, 0.8, 1.0 values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Test max tree depth on 4, 6, 8, 10 values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tune the minimum leaf weight/count as an approximate ratio of 3 over the square
    root of the percentage of the rarest class you have to predict. Therefore, if
    the class you need to predict has a 10% coverage in the data, you should set the
    minimum leaf weight/count to about 9\. This figure is calculated by dividing 3
    by the square root of 0.1 (since 10% coverage is 0.1 as a decimal).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the concluding section, we keep exploring some ideas and tricks to master
    even better GBDTs when solving tabular data problems.
  prefs: []
  type: TYPE_NORMAL
- en: 6.4 Mastering gradient boosting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Having discussed how gradient boosting works and its implementations, we close
    this chapter with suggestions about how to use gradient boosting at its best,
    understand how it works under the hood, and speed it up to cut time at training
    and prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 6.4.1 Deciding between XGBoost and LightGBM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When considering using gradient boosting for your data problem, XGBoost and
    LightGBM (along with HistGradientBoosting) are among the most popular and high-performing
    implementations of histogram gradient boosted machines. Despite their being so
    powerful, in our experience, you never can a priori go for XGBoost or LightGBM
    or just generally favor GBDTs in regards to other classical or deep learning solutions
    because of the no free lunch theorem in machine learning: there is no universal
    learning algorithm that performs best for all possible problems. Hence, stating
    that “XGBoost is all you need” for tabular data problems is surely a catchy phrase,
    but it may not always fit your specific problem or situation with data. GDBTs
    often tend to overperform other solutions for tabular data. Thus, starting with
    them, but not limited to them, is a good choice. Returning to specific implementations,
    while it is always advisable to test any algorithm on your data and make your
    own decisions, there are also a few other criteria to consider when deciding whether
    to try one implementation first or the other. We have validated them based on
    our own experience. They are summarized in table 6.1.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 6.1 Criteria to consider when using GBDTs
  prefs: []
  type: TYPE_NORMAL
- en: '| Type | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Amount of data | XGBoost works fine for all tabular problems; LightGBM, because
    of its leaf-wise splitting method that can create deeper trees, tends to overfit
    more often with smaller datasets. |'
  prefs: []
  type: TYPE_TB
- en: '| Scalability | XGBoost is more scalable and GPU ready; LightGBM struggles
    more. |'
  prefs: []
  type: TYPE_TB
- en: '| Speed of experimentation | On CPUs, LightGBM is undoubtedly faster than XGBoost.
    |'
  prefs: []
  type: TYPE_TB
- en: The availability of large amounts of data is the first criterion to consider.
    LightGBM uses leaf-wise (vertical) growth, which can result in overfitting. The
    tendency to overfit the data available explains well the algorithm’s success in
    Kaggle competitions. Hence, LightGBM works better when you have a lot of data
    available. In contrast, XGBoost builds more robust models than LightGBM on smaller
    data samples.
  prefs: []
  type: TYPE_NORMAL
- en: Another criterion to consider is whether you have access to multiple GPUs and
    strong CPUs or more limited access to computational resources. If you have plenty
    of resources, XGBoost is more scalable, making it a better option for use in institutional
    or business settings. However, if you prefer to focus on experimentation and feature
    engineering and cannot access GPUs, LightGBM makes more sense because of its faster
    training time. You can use the saved training time to improve the robustness of
    your final model. If you have limited resources, such as a stand-alone computer,
    you should consider that the training time for XGBoost increases linearly with
    the sample size, while LightGBM requires a much smaller fraction of training time.
  prefs: []
  type: TYPE_NORMAL
- en: 6.4.2 Exploring tree structures
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As previously discussed, GBDTs are complicated algorithms, not inexplicable
    or unreplicable ones. You just need to reproduce the various decision trees they
    are made of in a more performing way and combine them to obtain your fast predictions.
    Both XGboost and LightGBM allow for exploring and extracting their model’s structure.
    In listing 6.16, we take a few steps to demonstrate that. After dumping an XGBoost
    simple solution on a JSON file, we navigate inside its structure like a graph,
    using a depth-first search strategy. In depth-first search, the algorithm explores
    each branch as far as possible before backtracking.
  prefs: []
  type: TYPE_NORMAL
- en: Taking a closer look at the code in listing 6.16, you can notice that in the
    `traverse_xgb_tree` function, the code recursively explores the tree by first
    traversing the left subtree (`tree['children'][0]`) and then the right subtree
    (`tree['children'][1]`). This is evident from the recursive calls `traverse_xgb_tree(tree['children'][0])`
    and `traverse_xgb_tree(tree['children'][1])`.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.16 Extracting XGBoost tree structure
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: ① Creates an XGBoost classifier limited to 10 estimators and trees of three
    levels
  prefs: []
  type: TYPE_NORMAL
- en: ② Extracts the XGBoost model from the pipeline
  prefs: []
  type: TYPE_NORMAL
- en: ③ Dumps the XGBoost model’s information (the booster) into a JSON file
  prefs: []
  type: TYPE_NORMAL
- en: ④ Creates a plot of the first tree in the ensemble
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Retrieves the JSON structure from disk with the model’s information
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Prints the number of trees in the model and extracts the structure of the
    first tree
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Function extracting various information from a split node in the tree structure
  prefs: []
  type: TYPE_NORMAL
- en: ⑧ Function extracting information from a leaf node in the tree structure
  prefs: []
  type: TYPE_NORMAL
- en: ⑨ Function traversing the tree structure recursively to extract paths
  prefs: []
  type: TYPE_NORMAL
- en: 'The code trains a XGBoost model, saves its tree structure, processes the structure
    into a readable way, and presents the results to the user:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Figure 6.8 compares the obtained outputs with the graphical representation of
    the complete tree, as provided by the `plot_tree` from the XGBoost package itself.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH06_F08_Ryan2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.8 XGBoost’s `plot_tree` output
  prefs: []
  type: TYPE_NORMAL
- en: From the 10 trees built in the model, the code presents the first tree and,
    among the 8 different paths available from the sample to the prediction leaf,
    it represents the first path. Visually, this path is the leftmost one. The path
    is made up of different nodes in sequence. The code reports the name of the used
    feature, the split branch origin from the previous node (in XGBoost, minor always
    stands for the left branch, and major is equal to the right branch), the cut threshold,
    the gain with respect to the objective function, and the resulting reduction in
    the sample given the split of the dataset. All this information allows you to
    perfectly replicate the results of every tree of an XGBoost model.
  prefs: []
  type: TYPE_NORMAL
- en: We can also extract the same tree structure from LightGBM, though the approach
    is a bit different because the LightGBM package follows a few slightly different
    conventions. For instance, XGBoost always splits the minus than the threshold
    on the left; LightGBM instead, for each node, defines a rule using minus or major-equal
    and threshold and splits on the left if the rule is true and on the right if it
    is false.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.17 Extracting LightGBM tree structure
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: ① Extracts the tree information from the LightGBM model booster
  prefs: []
  type: TYPE_NORMAL
- en: ② Extracts the structure of the first tree from the tree information
  prefs: []
  type: TYPE_NORMAL
- en: ③ Plots the first tree in the ensemble using the plot_tree function
  prefs: []
  type: TYPE_NORMAL
- en: ④ Function extracting various information from a split node in the LightGBM
    tree structure
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Function extracting information from a leaf node in the LightGBM tree structure
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Function recursively traversing the LightGBM tree structure to extract paths
  prefs: []
  type: TYPE_NORMAL
- en: 'The results from this exploration report a path from the structure of the first
    decision tree in the ensemble:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Figure 6.9 shows the entire tree plotted by the `plot_tree` function, this time
    from the LightGBM package.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH06_F09_Ryan2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.9 LightGBM’s `plot_tree` output
  prefs: []
  type: TYPE_NORMAL
- en: The tree is plotted horizontally from left to right. We can check that the path
    returned by the code is the uppermost one, ending in leaf 0\.
  prefs: []
  type: TYPE_NORMAL
- en: 6.4.3 Speeding up by GBDTs and compiling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When the number of cases or the available features are many, even the faster
    LightGBM may take a long time to train a model on such data. At training time,
    you can overcome long waits by reducing the cases and features handled by smaller
    values of the parameter `subsample` for limiting the cases involved in building
    each decision tree and the parameter `colsample_bytree` for limiting the number
    of features considered at tree splitting time. However, reducing cases or features
    may not be optimal for getting the best results from your model. An alternative
    is using GPUs, which are widespread because they utilize deep learning models.
    GPUs can speed up training operations, especially with XGBoost, and, in a lesser
    but significant way, with LightGBM models.
  prefs: []
  type: TYPE_NORMAL
- en: 'With XGBoost, from a modeling point of view, using your GPU is quite straightforward:
    you just need to specify `"gpu_hist"` as a value for the `tree_method` parameter.
    With the new 2.0.0 version, such a method is, however, deprecated, and users can
    now instead specify the used device by the parameter `device`. You can set it
    to `"cpu"` for XGBoost to execute on CPU or `device="cuda"` as well as `device="gpu"`
    to have it run on a CUDA-powered GPU, which is the only option at the moment,
    but in the future, more GPU types will be supported. If you have multiple GPUs,
    you can specify their ordinal to choose a particular one; for instance, `device="cuda:1"`
    will execute on your second GPU device.'
  prefs: []
  type: TYPE_NORMAL
- en: For XGBoost to perform, you need at least CUDA 11.00 installed and a GPU with
    a compute capability 5.0\. If you have more GPUs available, you can specify which
    to use by the `gpu_id` parameter, which represents the GPU device ordinal reported
    by CUDA runtime (usually set to zero if you have a single GPU). In this way, XGBoost
    moves the growth of decision trees to the GPU memory and processors, thus obtaining
    a relevant speed of operations, especially feature histograms, as described in
    the paper “Accelerating the XGBoost Algorithm Using GPU Computing” by Mitchell
    and Frank ([https://peerj.com/articles/cs-127/](https://peerj.com/articles/cs-127/)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Once GPU trains a model, it can be used for prediction on a machine with a
    GPU. All you have to set is the `predictor` parameter to `gpu_predictor` or to
    `cpu_predictor` if you want to use your CPU. Selecting the predictor parameter
    to GPU can also speed up things when you have to compute SHAP values and SHAP
    interaction values for model interpretability:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Although using a GPU with XGBoost is easy, it becomes a little bit trickier
    with LightGBM. LightGBM doesn’t have an option for GPU running but rather requires
    a special version of itself to be compiled for the purpose. Depending on your
    operating system (Windows, Linux/Ubuntu, MacOS), the compilation may be less or
    more challenging. Instructions are available at [https://mng.bz/nRg5](https://mng.bz/nRg5)
    for POSIX systems and at [https://mng.bz/vK8p](https://mng.bz/vK8p) for Windows
    systems. However, if you have all the prerequisites ready on your system as stated
    by the instructions at [https://mng.bz/4aJg](https://mng.bz/4aJg), you can just
    require to directly install it using the pip install instruction on your shell
    or command prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Once everything has been installed, you need to set the parameter `device` to
    `gpu` Don’t expect astonishing performance improvements, however. As stated by
    LightGBM authors (see [https://mng.bz/vK8p](https://mng.bz/vK8p)), the best results
    are obtained on large-scale and dense datasets because of the inefficient data
    turnover that causes latencies when working on smaller datasets. In addition,
    setting a lower number of bins for the histogram algorithm will make the GPU work
    more efficiently with the LightGBM. The suggestion is to set `max_bin=15` and
    single precision, `gpu_use_dp=false`, for the best performances.
  prefs: []
  type: TYPE_NORMAL
- en: GPUs are quite useful for speeding up training, but there are more options at
    prediction time. With tree structures so readily available, as we have seen in
    the previous section, it has been possible for specific projects to use such information
    for rebuilding prediction trees using more performing programming languages such
    as C, JAVA, or LLVM that can turn your model into pure assembly code. Such tree-compiling
    projects aim for fast prediction and easier deployment. Examples are Treelite
    ([https://github.com/dmlc/treelite](https://github.com/dmlc/treelite)), which
    can read models produced by XGBoost, LightGBM, and even Scikit-learn, and lleaves
    ([https://github.com/siboehm/lleaves](https://github.com/siboehm/lleaves)), which
    is a project for LightGBM only.
  prefs: []
  type: TYPE_NORMAL
- en: 'Starting from Treelite, this project strives to be a universal model exchange
    and serialization format for decision tree forests. It compiles your GBDT into
    C or Java with the least possible dependencies, so you can easily deploy it into
    any system. To have it tested, you must install a few packages at the command
    line: `pip` `install` `tl2cgen treelite treelite_runtime`.'
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.18 XGBoost prediction speedup by Treelite
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: ① Saves the XGBoost model to a JSON file
  prefs: []
  type: TYPE_NORMAL
- en: ② Loads the XGBoost model in Treelite format from the JSON file
  prefs: []
  type: TYPE_NORMAL
- en: ③ Generates C code from the Treelite model and exports it as a shared library
  prefs: []
  type: TYPE_NORMAL
- en: ④ Transforms the input data using the preprocessing steps defined in the pipeline
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Creates a Treelite DMatrix from the transformed data, compatible with the
    exported Treelite model
  prefs: []
  type: TYPE_NORMAL
- en: The result is a compiled model that, inside a Python script, can return predictions
    in a much faster fashion. Predictors must always be transformed beforehand since
    the pipeline is not part of the compiling. Only the model is. In addition, you
    also have to convert the data in DMatrix format, the native XGBoost data format,
    before it is sent to the compiled model.
  prefs: []
  type: TYPE_NORMAL
- en: Developed by Simon Boehm, lleaves promises x10 speed up by LLVM compiling into
    assembly based on the text tree structure that can be outputted from a LightGBM
    model. After having installed the package by a `pip` `install` `leaves` instruction
    on the command line, you can obtain a speed up by following these steps.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.19 LightGBM prediction speedup by `lleaves`
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: ① Saves the LightGBM model to a text file
  prefs: []
  type: TYPE_NORMAL
- en: ② Loads the LightGBM model using the lleaves library
  prefs: []
  type: TYPE_NORMAL
- en: ③ Compiles the loaded LightGBM model into LLVM representation
  prefs: []
  type: TYPE_NORMAL
- en: ④ Transforms the input data using the preprocessing steps defined in the pipeline
  prefs: []
  type: TYPE_NORMAL
- en: Also, in this case, the model is compiled and can predict in a faster way inside
    a Python script. From a general point of view, `lleaves`, though limited only
    to LightGBM, is a compiling solution that requires many fewer settings and specifications
    from the user, resulting in a much simpler and straightforward usage.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Among processing problems, missing data is one of the most problematic. If your
    data is MCR or is just MAR because missing patterns are related to the other features,
    multivariate imputation can use the correlations among predictors in a dataset
    to impute missing values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both XGBoost and LightGBM algorithms automatically handle missing data by assigning
    them to the side that minimizes the loss function the most in each split.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When a categorical presents high cardinality because of its many labels, you
    can use target encoding, which gained popularity in Kaggle competitions. Target
    encoding is a way to transform the values in a categorical feature into their
    corresponding expected target values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PDP is a model-agnostic chart technique that explains how features and the target
    are related by means of the model you have trained. It is beneficial because it
    helps you better model the relationship between the predictive feature and the
    target if you notice it is nonlinear and complex.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: XGBoost, thanks to packages such as XGBFIR, can inform you about the most important
    interactions between predictive features.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'By employing effective feature selection techniques, you can pinpoint and retain
    the most relevant features that contribute significantly to the machine learning
    process. Standard techniques to handle feature selection are stability selection
    based on L1 regularization for linear models, iterative selection, and Boruta
    for tree ensembles:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on L1 regularization, stability selection aims to identify features that
    consistently appear as important across multiple subsets, indicating their robustness
    and reducing the likelihood of selecting features by chance or noise.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Boruta is a procedure to determine if a feature is relevant in a machine learning
    problem by relying on the internal parameters of the model, such as coefficients
    in linear models or importance values based on gain, such as in decision trees
    and their ensembles.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Iterative selection additions by forward selection, or removes by backward elimination,
    features from your selection based on their performance on the prediction in a
    greedy fashion, leaving only the essential features for your prediction.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'By optimizing hyperparameters, you can gain another performance boost to your
    classical machine learning model. Apart from manually setting the hyperparameters,
    depending on the model you are working on, grid search, random search, successive
    halving, and Bayesian optimization are popular optimization methods within the
    data science community:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grid search simply works by searching through all the possible combinations
    of hyperparameters’ values. For every hyperparameter you want to test, you pick
    a sequence of values and iterate through all their combinations exhaustively.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Random search optimization decides what values to test by randomly drawing them
    from the search space. The technique is particularly effective if you know little
    about your hyperparameters, if there are many of them, and if some are irrelevant
    but you don’t know which ones.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Successive halving is a wrapper of the previously discussed strategies. It works
    as a tournament between sets of hyperparameters, where first, they are tested
    using a few computational resources. Then, only a fraction of the best is further
    tested using more resources. In the end, there will be only one surviving set
    of hyperparameters.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Bayesian optimization uses informed search to find the best set of hyperparameters.
    It builds a model of the hyperparameter’s behavior based on prior knowledge of
    how it works on the data problem. Then it sets a series of experiments to explore
    further and refine its own internal model, exploit the previous trials, and validate
    the actual performances of a solution.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Both XGBoost and LightGBM have specific settings and options that are not commonly
    found in other machine learning algorithms, such as the possibility of extracting
    and representing their internal structure and speeding up their execution by GPU
    use and compiling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
