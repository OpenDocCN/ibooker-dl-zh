<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 9. Security, Compliance, and Governance for AI Solutions"><div class="chapter" id="chapter_nine_securitycomma_complianceco">
<h1><span class="label">Chapter 9. </span>Security, Compliance, and <span class="keep-together">Governance for AI Solutions</span></h1>
<p>On an annual basis, JPMorgan spends<a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="about priority of" id="id1717"/><a contenteditable="false" data-type="indexterm" data-primary="costs" data-secondary="cybersecurity spending" id="id1718"/><a contenteditable="false" data-type="indexterm" data-primary="JPMorgan cybersecurity spending" id="id1719"/><a contenteditable="false" data-type="indexterm" data-primary="cybersecurity" data-secondary="spending on" id="id1720"/><a contenteditable="false" data-type="indexterm" data-primary="Bank of America cybersecurity costs" id="id1721"/> more than $600 million on cybersecurity.<sup><a data-type="noteref" id="ch01fn29-marker" href="ch09.html#ch01fn29">1</a></sup> The amount is over $1 billion for Bank of America.</p>
<p>These are not outliers. Cybersecurity spending is a massive category, with the amount estimated at $183 billion—across the globe—in 2024, according to research from Gartner.<sup><a data-type="noteref" id="ch01fn30-marker" href="ch09.html#ch01fn30">2</a></sup> The firm predicts an 11.7% compound annual growth rate (CAGR) from 2023 to 2028. Some of the factors driving this include the increased threats of AI and cloud technologies.</p>
<p>For AWS, security is its top priority. This includes massive investments in protecting the platform as well as offering a wide array of services for millions of customers. <a contenteditable="false" data-type="indexterm" data-primary="exam for AIF-C01" data-secondary="topics covered" data-tertiary="security services" id="id1722"/><a contenteditable="false" data-type="indexterm" data-primary="topics covered in exam for AIF-C01" data-secondary="security services" id="id1723"/>Many of these services—like AWS IAM, Amazon GuardDuty, and AWS Config—are highlighted on the AIF-C01 exam. In this chapter, we’ll look at these tools and the broader principles of governance and security for AI systems—critical topics for passing the AWS exam.</p>
<section data-type="sect1" data-pdf-bookmark="Overview of Security, Compliance, and Governance"><div class="sect1" id="overview_of_securitycomma_governancecom">
<h1>Overview of Security, Compliance, and Governance</h1>
<p>It is common to lump together the concepts of security, governance, and compliance. Yet each has a different role, and it’s important to understand the distinctions. Here is a breakdown:</p>
<dl>
<dt>Security</dt>
<dd><p>Focusing on protecting <a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="described" id="id1724"/><a contenteditable="false" data-type="indexterm" data-primary="information security" data-seealso="security" id="id1725"/><a contenteditable="false" data-type="indexterm" data-primary="cybersecurity" data-secondary="described" data-seealso="security" id="id1726"/>data and infrastructure, its goal is to ensure confidentiality (only the right people can access information), integrity (data stays accurate and trustworthy), and availability (systems and data are accessible when needed). You’ll usually hear this function referred to as <em>information security</em> or <em>cybersecurity</em>.</p></dd>
<dt>Governance</dt>
<dd><p>This is about guiding the<a contenteditable="false" data-type="indexterm" data-primary="governance" data-secondary="described" id="id1727"/> organization wisely. It ensures the business can create value while effectively managing risk. In the context of AI, governance provides the structure that keeps innovation aligned with accountability. It helps organizations move fast without breaking things—especially when those “things” include customer trust, ethical standards, or regulatory compliance.</p></dd>
<dt>Compliance</dt>
<dd><p>This makes sure the <a contenteditable="false" data-type="indexterm" data-primary="compliance" data-secondary="described" id="id1728"/>organization follows the rules—whether they come from laws, regulations, internal policies, or industry standards. It’s about meeting requirements consistently and reliably.</p></dd>
</dl>
<p>Together, these three functions help an organization deliver on its core mission. They define the nonnegotiables—the essential safeguards that shouldn’t be compromised.</p>
<p>For the rest of the chapter, we’ll have sections for each of the three functions and what you will need to know for the exam for each of them.</p>
<section data-type="sect2" data-pdf-bookmark="Security"><div class="sect2" id="security">
<h2>Security</h2>
<p>To effectively secure AI systems, organizations employ layered strategies and specific frameworks designed to manage risk across different use cases.</p>
<section data-type="sect3" data-pdf-bookmark="Security approaches with AWS tools"><div class="sect3" id="security_approaches_with_aws_tools">
<h3>Security approaches with AWS tools</h3>
<p><em>Defense in depth</em> is a layered security<a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="AWS tools" id="c09tools"/><a contenteditable="false" data-type="indexterm" data-primary="AWS (Amazon Web Services)" data-secondary="security tools" data-seealso="security" id="c09tools2"/><a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="AWS tools" data-tertiary="defense in depth approach" id="c09tools3"/><a contenteditable="false" data-type="indexterm" data-primary="defense in depth" id="c09tools4"/><a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="layered approach" id="c09tools5"/><a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="defense in depth" id="c09tools6"/><a contenteditable="false" data-type="indexterm" data-primary="web application firewall (WAF)" id="id1729"/><a contenteditable="false" data-type="indexterm" data-primary="AWS WAF (web application firewall)" id="id1730"/><a contenteditable="false" data-type="indexterm" data-primary="firewall (AWS WAF)" id="id1731"/> approach based on the idea that no single control is foolproof. Think of it like securing your home. You might lock the front door—that’s your firewall, like AWS web application firewall (WAF) or security groups. But you also install an alarm system, which is similar to using Amazon GuardDuty or AWS Security Hub to detect and alert on threats. Add motion detectors, and you’re proactively sensing unusual activity—just like using Amazon EventBridge to trigger automated responses. And finally, you set up security cameras, which record events so you can review what happened. In AWS, this is CloudTrail or AWS Config, which provide logging and historical visibility. If one measure fails, the others help catch what slipped through. This is the essence of defense in depth on AWS.</p>
<p>This strategy—which is likely to be on the exam—becomes<a contenteditable="false" data-type="indexterm" data-primary="exam for AIF-C01" data-secondary="topics covered" data-tertiary="security services" id="id1732"/><a contenteditable="false" data-type="indexterm" data-primary="topics covered in exam for AIF-C01" data-secondary="security services" data-tertiary="defense in depth" id="id1733"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="security" id="id1734"/> especially important when you’re dealing with generative AI, where workloads often involve sensitive data, valuable intellectual property, and a fast-moving development cycle (see <a data-type="xref" href="#figure_nine_onedot_the_layers_of_securi">Figure 9-1</a>).</p>
<figure><div id="figure_nine_onedot_the_layers_of_securi" class="figure">
<img src="assets/awsc_0901.png" alt="" width="790" height="790"/>
<h6><span class="label">Figure 9-1. </span>The layers of security in AWS</h6>
</div></figure>
<p>Before setting up the layers, you should write clear, actionable policies. For example, suppose your data science team spins up training clusters often. Implement least privilege access with AWS IAM and use the Access Analyzer to flag permissions that might be too permissive. Then enforce short-lived credentials so no one ends up with long-term administrative access they don’t need.</p>
<p>Let’s look at each of these layers in more detail:</p>
<dl>
<dt>Data protection</dt>
<dd><p>For data at rest, you can<a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="layered approach" data-tertiary="data protection" id="id1735"/><a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="AWS tools" data-tertiary="data protection" id="id1736"/><a contenteditable="false" data-type="indexterm" data-primary="defense in depth" data-secondary="AWS tools" data-tertiary="data protection" id="id1737"/><a contenteditable="false" data-type="indexterm" data-primary="AWS Key Management Service (KMS)" id="id1738"/><a contenteditable="false" data-type="indexterm" data-primary="encryption of data" data-secondary="AWS Key Management Service" id="id1739"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="security and privacy" data-tertiary="encryption via AWS Key Management Service" id="id1740"/> use AWS Key Management Service (KMS) to encrypt everything—from training datasets in Amazon S3 to model checkpoints. Enable versioning in Amazon S3 so you can roll back if anything gets corrupted or tampered with.</p>
<p>For data in transit, <a contenteditable="false" data-type="indexterm" data-primary="AWS Certificate Manager (ACM)" id="id1741"/><a contenteditable="false" data-type="indexterm" data-primary="AWS Private CA for data security" id="id1742"/><a contenteditable="false" data-type="indexterm" data-primary="AWS PrivateLink" data-secondary="data security" id="id1743"/>use AWS Certificate Manager (ACM) to handle TLS certificates and AWS Private CA to issue internal certs. Route sensitive traffic through AWS PrivateLink to avoid exposing it to the public internet.</p></dd>

<dt>IAM</dt>
<dd><p>Using IAM, you should<a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="AWS tools" data-tertiary="IAM" id="id1744"/><a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="layered approach" data-tertiary="IAM" id="id1745"/><a contenteditable="false" data-type="indexterm" data-primary="defense in depth" data-secondary="AWS tools" data-tertiary="IAM" id="id1746"/><a contenteditable="false" data-type="indexterm" data-primary="AWS IAM (Identity and Access Management)" data-secondary="IAM role" id="id1747"/><a contenteditable="false" data-type="indexterm" data-primary="AWS IAM (Identity and Access Management)" data-secondary="security" id="id1748"/><a contenteditable="false" data-type="indexterm" data-primary="multi-factor authentication (MFA)" id="id1749"/><a contenteditable="false" data-type="indexterm" data-primary="MFA (multi-factor authentication)" id="id1750"/> create distinct roles for your model training, inference, and monitoring workloads. Avoid using root credentials and enable multi-factor authentication (MFA) for every human user.</p></dd>

<dt>Application protection</dt>
<dd><p>There are different ways to protect applications.<a contenteditable="false" data-type="indexterm" data-primary="application security" id="id1751"/><a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="AWS tools" data-tertiary="application protection" id="id1752"/><a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="layered approach" data-tertiary="application protection" id="id1753"/><a contenteditable="false" data-type="indexterm" data-primary="defense in depth" data-secondary="AWS tools" data-tertiary="application protection" id="id1754"/><a contenteditable="false" data-type="indexterm" data-primary="AWS Shield" data-secondary="denial-of-service attacks" id="id1755"/><a contenteditable="false" data-type="indexterm" data-primary="distributed denial of service (DDoS) protection via AWS Shield" id="id1756"/><a contenteditable="false" data-type="indexterm" data-primary="denial of service (DoS) protection via AWS Shield" id="id1757"/><a contenteditable="false" data-type="indexterm" data-primary="DoS (denial of service) protection via AWS Shield" id="id1758"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Cognito" id="id1759"/> For example, you can use AWS Shield to mitigate denial-of-service (DoS) attacks and Amazon Cognito to securely manage user sign-in and identity federation.</p>
<p>Let’s say you’re hosting a generative text API. A bad actor could try to overwhelm it with automated requests. Shield helps absorb the traffic, while Cognito enforces rate limits and authentication rules to keep access secure.</p></dd>

<dt>Threat detection and incident response</dt>
<dd><p>Things will go wrong. <a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="AWS tools" data-tertiary="threat detection and incident response" id="id1760"/><a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="layered approach" data-tertiary="threat detection and incident response" id="id1761"/><a contenteditable="false" data-type="indexterm" data-primary="threat detection" data-secondary="AWS tools" id="id1762"/><a contenteditable="false" data-type="indexterm" data-primary="defense in depth" data-secondary="AWS tools" data-tertiary="threat detection and incident response" id="id1763"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon GuardDuty" id="id1764"/><a contenteditable="false" data-type="indexterm" data-primary="AWS Security Hub" id="id1765"/>The key is catching the problems early and knowing how to respond. You can use Amazon GuardDuty to detect suspicious activity in your accounts. Combine it with AWS Security Hub to centralize alerts across services.</p>
<p>When incidents happen, automate your first steps.<a contenteditable="false" data-type="indexterm" data-primary="Amazon EventBridge" id="id1766"/><a contenteditable="false" data-type="indexterm" data-primary="AWS Lambda" data-secondary="security response automation" id="id1767"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon EC2 (Elastic Compute Cloud)" data-secondary="security response" id="id1768"/> Use Amazon EventBridge to trigger a Lambda function that quarantines suspicious Amazon EC2 instances or revokes IAM permissions automatically. This opens up more time for your team to <span class="keep-together">investigate.</span></p></dd>

<dt>Infrastructure protection</dt>
<dd><p>As part of a defense-in-depth strategy,<a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="AWS tools" data-tertiary="infrastructure protection" id="id1769"/><a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="layered approach" data-tertiary="infrastructure protection" id="id1770"/><a contenteditable="false" data-type="indexterm" data-primary="defense in depth" data-secondary="AWS tools" data-tertiary="infrastructure protection" id="id1771"/><a contenteditable="false" data-type="indexterm" data-primary="infrastructure security" id="id1772"/><a contenteditable="false" data-type="indexterm" data-primary="AWS IAM (Identity and Access Management)" data-secondary="infrastructure protection" id="id1773"/><a contenteditable="false" data-type="indexterm" data-primary="network access control lists (ACLs)" id="id1774"/><a contenteditable="false" data-type="indexterm" data-primary="policies" data-secondary="access controls" data-tertiary="network access control lists" id="id1775"/><a contenteditable="false" data-type="indexterm" data-primary="access controls" data-secondary="network access control lists" id="id1776"/><a contenteditable="false" data-type="indexterm" data-primary="ACLs (network access control lists)" id="id1777"/> the infrastructure layer acts as one of the key lines of defense. Here, the goal is to harden your environment against potential attacks by controlling access and isolating resources. For example, you can use IAM policies to tightly manage who is allowed to launch or modify infrastructure components. Network access control lists (ACLs) add another layer by restricting traffic flow between subnets, helping to contain threats if one area is compromised. Additionally, defining IAM user groups with clear boundaries ensures that only authorized roles can perform sensitive operations.</p></dd>

<dt>Network and edge protection</dt>
<dd><p>You want to establish strong protection<a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="AWS tools" data-tertiary="network and edge protection" id="id1778"/><a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="layered approach" data-tertiary="network and edge protection" id="id1779"/><a contenteditable="false" data-type="indexterm" data-primary="defense in depth" data-secondary="AWS tools" data-tertiary="network and edge protection" id="id1780"/><a contenteditable="false" data-type="indexterm" data-primary="network security" id="id1781"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Virtual Private Cloud (VPC)" data-secondary="network and edge security" id="id1782"/> on the perimeter of the network. You can use Amazon VPC to create isolated environments for each phase of your AI pipeline. Add AWS WAF to block common exploits at the edge, and restrict access to public endpoints as much as possible.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c09tools" id="id1783"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c09tools2" id="id1784"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c09tools3" id="id1785"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c09tools4" id="id1786"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c09tools5" id="id1787"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c09tools6" id="id1788"/></p></dd>
</dl>
</div></section>

<section data-type="sect3" data-pdf-bookmark="Generative AI Security Scoping Matrix"><div class="sect3" id="generative_ai_security_scoping_matrix">
<h3>Generative AI Security Scoping Matrix</h3>
<p>The Generative AI Security Scoping Matrix is<a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="Generative AI Security Scoping Matrix" id="c09matrx"/><a contenteditable="false" data-type="indexterm" data-primary="Generative AI Security Scoping Matrix (AWS)" id="c09matrx2"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="Generative AI Security Scoping Matrix" id="c09matrx3"/><a contenteditable="false" data-type="indexterm" data-primary="AI (artificial intelligence)" data-secondary="implementation scopes and security" id="c09matrx4"/> a framework developed by AWS to help organizations in assessing and implementing security controls for their generative AI workloads. It categorizes AI implementations into five distinct scopes, each representing varying levels of control and responsibility over the AI models and associated data (see <a data-type="xref" href="#figure_nine_twodot_the_generative_ai_se">Figure 9-2</a>).</p>
<figure><div id="figure_nine_twodot_the_generative_ai_se" class="figure">
<img src="assets/awsc_0902.png" alt="" width="999" height="999"/>
<h6><span class="label">Figure 9-2. </span>The Generative AI security scoping matrix</h6>
</div></figure>

<p>Let’s look at each scope in more detail:</p>
<dl>
<dt>Scope 1: Consumer applications</dt>
<dd><p>At this level, you’re using publicly available generative AI tools right out of the box—no customization, no backend access. These are tools like ChatGPT or other similar platforms that anyone can use by signing up or logging in. You’re operating entirely within the provider’s environment, with no visibility into how the model was trained or what data it used. All interactions happen through a user interface or an API, and you’re bound by the provider’s terms of service. A typical example would be an employee asking ChatGPT for creative ideas for a marketing campaign.</p></dd>

<dt>Scope 2: Enterprise applications</dt>
<dd><p>Here, you’re working with third-party software tailored for businesses, which includes embedded generative AI features. Unlike Scope 1, these tools often come with formal vendor relationships—contracts, support, and service-level agreements (SLAs). You might get more flexibility or configuration options, but the core AI model still lies firmly in the vendor’s control. A good example would be using a business-grade calendar app that leverages AI to draft meeting agendas based on your past patterns and inputs.</p></dd>

<dt>Scope 3: Pretrained models</dt>
<dd><p>In Scope 3, you’re building your own applications using preexisting AI models, accessed via APIs. The model itself lives on a third-party platform, but you control how it fits into your application, what data you feed into it, and how it interacts with your business processes. For instance, you might create a customer service chatbot that connects to Anthropic’s Claude model via Amazon Bedrock, tailoring the responses based on your input data and application flow.</p></dd>

<dt>Scope 4: Fine-tuned models</dt>
<dd><p>In this scope you’re fine-tuning an FM with your own data to better fit your specific needs. This gives you more control and also adds more responsibility—you’re shaping how the model behaves based on your proprietary information. Let’s say your marketing team wants AI-generated content that reflects your brand voice. You could fine-tune an existing model with past campaigns, customer data, and tone guidelines to generate spot-on promotional material.</p></dd>

<dt>Scope 5: Self-trained models</dt>
<dd><p>At the highest level of control, you’re building and training your own generative AI models from scratch. This means collecting the data, designing the architecture, running the training, and maintaining the whole system. You own everything—data, model, outcomes—and carry full responsibility for performance, ethics, and compliance. This scope suits organizations with highly specialized needs or strict regulatory environments. For example, a financial firm might develop its own FM trained exclusively on regulatory filings, internal reports, and market data to power licensed analytics services.</p></dd>
</dl>
<p>For each scope, AWS emphasizes five critical security disciplines:<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c09matrx" id="id1789"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c09matrx2" id="id1790"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c09matrx3" id="id1791"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c09matrx4" id="id1792"/></p>
<dl>
<dt>Governance and compliance</dt>
<dd><p>Establishing policies and procedures to manage risks and ensure adherence to regulations</p></dd>
<dt>Legal and privacy</dt>
<dd><p>Ensuring compliance with legal requirements and protecting user data privacy</p></dd>
<dt>Risk management</dt>
<dd><p>Identifying potential threats and implementing mitigation strategies</p></dd>
<dt>Controls</dt>
<dd><p>Applying security controls appropriate to the level of responsibility and risk</p></dd>
<dt>Resilience</dt>
<dd><p>Designing systems to maintain availability and recover from disruptions</p></dd>
</dl>

</div></section>
<section data-type="sect3" data-pdf-bookmark="Security for AI and Generative AI"><div class="sect3" id="security_for_ai_and_generative_ai">
<h3>Security for AI and Generative AI</h3>
<p>From protecting infrastructure<a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="AI and generative AI security" id="id1793"/><a contenteditable="false" data-type="indexterm" data-primary="AI (artificial intelligence)" data-secondary="security" data-seealso="security" id="id1794"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="security" data-seealso="security" id="id1795"/> to guarding against input manipulation, the attack surface grows in new and sometimes unexpected ways when it comes to AI and generative AI. Let’s break down five essential areas that are critical for mitigating these threats:</p>

<dl>
<dt>Threat detection</dt>
<dd><p>Threat detection in the context<a contenteditable="false" data-type="indexterm" data-primary="threat detection" id="id1796"/> of AI means actively monitoring for signs that someone—or something—is trying to compromise your systems. Attackers might use generative AI to create fake content, tamper with data, or automate parts of a broader cyberattack. To keep up, you can deploy AI-powered tools that sift through network traffic, analyze user behavior, and watch for unusual <span class="keep-together">patterns.</span></p></dd>

<dt>Vulnerability management</dt>
<dd><p>Every system has weak spots,<a contenteditable="false" data-type="indexterm" data-primary="vulnerability management" id="id1797"/> and AI is no exception. Bugs in the code, flaws in the model, and exploitable entry points—like malware-laced files or phishing attachments—can all create risk. Managing these vulnerabilities means running regular security assessments, doing penetration testing (intentionally trying to break your own system), and performing detailed code reviews. Just as importantly, stay on top of patches and updates. Unpatched software is one of the easiest ways for attackers to breach a system.</p></dd>

<dt>Infrastructure protection</dt>
<dd><p>AI relies on cloud platforms,<a contenteditable="false" data-type="indexterm" data-primary="infrastructure security" id="id1798"/> edge devices, databases, and other foundational components. If these pieces aren’t secure, your AI system isn’t either. Infrastructure protection involves setting strict access controls, isolating systems with network segmentation, and encrypting sensitive resources. You also want to design your infrastructure for resilience—so it can bounce back quickly from attacks, outages, or system failures without taking your AI offline.</p></dd>

<dt>Prompt injection resistance</dt>
<dd><p>Prompt injection is a newer type of threat,<a contenteditable="false" data-type="indexterm" data-primary="prompts" data-secondary="security issues" data-tertiary="prompt injection" id="id1799"/><a contenteditable="false" data-type="indexterm" data-primary="prompt injection" id="id1800"/><a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="prompts" data-tertiary="prompt injection" id="id1801"/> unique to generative AI. To defend against this, sanitize and validate all incoming prompts. You can also design models and training processes that are more resistant to this kind of <span class="keep-together">manipulation—essentially</span> teaching the system to ignore shady instructions.</p></dd>

<dt>Data encryption</dt>
<dd><p>Use strong encryption to <a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="security and privacy" data-tertiary="protection of data" id="id1802"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="security and privacy" data-tertiary="encryption" id="id1803"/><a contenteditable="false" data-type="indexterm" data-primary="encryption of data" id="id1804"/>protect data both when it’s stored (data at rest) and when it’s moving between systems (data in transit). Just as critical, manage your encryption keys with care. If attackers get access to them, the encryption becomes useless. Treat them like the keys to your entire operation—because in many ways, they are.</p></dd>
</dl>
</div></section>
<section data-type="sect3" data-pdf-bookmark="AWS security tools and services for AI workloads"><div class="sect3" id="aws_security_tools_and_services_for_ai">
<h3>AWS security tools and services for AI workloads</h3>
<p>AWS offers many security tools<a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="AWS tools" id="id1805"/><a contenteditable="false" data-type="indexterm" data-primary="AWS (Amazon Web Services)" data-secondary="security tools" id="id1806"/> to help you protect AI systems at every layer—from data and infrastructure to identity and access. You’ve already seen how services like AWS Security Hub and Amazon GuardDuty can centralize and automate threat detection. Let’s look at a few more services that round out your AI security toolbox.</p>
<section data-type="sect4" data-pdf-bookmark="AWS Key Management Service"><div class="sect4" id="aws_key_management_service_left_parenth">
<h4>AWS Key Management Service</h4>
<p><a contenteditable="false" data-type="indexterm" data-primary="AWS Key Management Service (KMS)" id="id1807"/><a contenteditable="false" data-type="indexterm" data-primary="encryption of data" data-secondary="AWS Key Management Service" id="id1808"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="security and privacy" data-tertiary="encryption via AWS Key Management Service" id="id1809"/>You can choose between AWS-managed keys for ease of use or create and manage your own customer keys if you need tighter control. Either way, KMS ensures your data stays protected, whether it’s at rest or in motion.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="AWS Shield Advanced"><div class="sect4" id="aws_shield_advanced">
<h4>AWS Shield Advanced</h4>
<p><a contenteditable="false" data-type="indexterm" data-primary="AWS Shield" data-secondary="firewall tools" id="id1810"/><a contenteditable="false" data-type="indexterm" data-primary="AWS WAF (web application firewall)" data-secondary="AWS Shield Advanced including" id="id1811"/><a contenteditable="false" data-type="indexterm" data-primary="web application firewall (WAF)" data-secondary="AWS Shield Advanced including" id="id1812"/><a contenteditable="false" data-type="indexterm" data-primary="AWS Firewall Manager" id="id1813"/>It includes tools like AWS WAF and AWS Firewall Manager to give you layered defense and centralized policy management.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="Amazon Macie"><div class="sect4" id="amazon_macie">
<h4>Amazon Macie</h4>
<p>Amazon Macie uses machine learning<a contenteditable="false" data-type="indexterm" data-primary="Amazon Macie" id="id1814"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="security and privacy" data-tertiary="sensitive data identified and classified" id="id1815"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="foundation models" data-tertiary="selecting data" id="id1816"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="training data" data-tertiary="selecting data" id="id1817"/><a contenteditable="false" data-type="indexterm" data-primary="privacy" data-secondary="sensitive data" data-tertiary="identified and classified" id="id1818"/><a contenteditable="false" data-type="indexterm" data-primary="personally identifiable information (PII)" data-secondary="Amazon Macie classifying" id="id1819"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="selecting for models" data-tertiary="Amazon Macie flagging sensitive data" id="id1820"/> to automatically identify and classify sensitive data across your AWS environment. It’s especially helpful for scanning S3 buckets to uncover PII, protected health information (PHI), or financial records. If you’re preparing training datasets for an AI model, Macie can flag data that needs to be removed or further secured. You can even extend this by exporting database contents to S3 and scanning that data as well.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="Zero trust and fine-grained access controls"><div class="sect4" id="zero_trust_and_fine_grained_access_cont">
<h4>Zero trust and fine-grained access controls</h4>
<p>To adopt a zero trust approach,<a contenteditable="false" data-type="indexterm" data-primary="zero trust approach" id="id1821"/><a contenteditable="false" data-type="indexterm" data-primary="policies" data-secondary="zero trust approach" id="id1822"/><a contenteditable="false" data-type="indexterm" data-primary="AWS Verified Access" id="id1823"/><a contenteditable="false" data-type="indexterm" data-primary="AWS Verified Permissions" id="id1824"/><a contenteditable="false" data-type="indexterm" data-primary="access controls" id="id1825"/><a contenteditable="false" data-type="indexterm" data-primary="policies" data-secondary="access controls" id="id1826"/> AWS offers tools like Verified Access and Verified Permissions. These services allow you to implement granular access policies without relying on traditional VPNs. They help you enforce identity-based security in a way that’s scalable and efficient.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="Amazon SageMaker Role Manager"><div class="sect4" id="amazon_sagemaker_role_manager">
<h4>Amazon SageMaker Role Manager</h4>
<p>If you’re using Amazon SageMaker,<a contenteditable="false" data-type="indexterm" data-primary="Amazon SageMaker" data-secondary="SageMaker Role Manager" data-tertiary="IAM roles" id="id1827"/><a contenteditable="false" data-type="indexterm" data-primary="AWS IAM (Identity and Access Management)" data-secondary="IAM role" id="id1828"/> the Role Manager can help you create IAM roles tailored to different machine learning roles. It includes built-in personas—like data scientist, MLOps engineer, and SageMaker <span class="keep-together">compute—that</span> come with preconfigured permissions for common tasks.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="Network security and data flow control"><div class="sect4" id="network_security_and_data_flow_control">
<h4>Network security and data flow control</h4>
<p>You can manage data ingress and egress<a contenteditable="false" data-type="indexterm" data-primary="network security" id="id1829"/><a contenteditable="false" data-type="indexterm" data-primary="AWS Network Firewall" id="id1830"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Virtual Private Cloud (VPC)" data-secondary="network and edge security" id="id1831"/><a contenteditable="false" data-type="indexterm" data-primary="policies" data-secondary="Amazon Virtual Private Cloud" id="id1832"/> at the network level with AWS Network Firewall and Amazon VPC policies. AWS Network Firewall supports deep packet inspection, letting you decrypt and inspect TLS traffic before it leaves or enters your environment. Amazon VPC gives you full control over your virtual networking environment, similar to managing your own on-premises data center. <a contenteditable="false" data-type="indexterm" data-primary="AWS PrivateLink" data-secondary="Amazon Virtual Private Cloud connected to Amazon Bedrock" id="id1833"/>To avoid exposing internal traffic to the internet, AWS PrivateLink lets you connect your VPC privately to services like Amazon Bedrock (see <a data-type="xref" href="#table_nine_onedot_summary_of_aws_securi">Table 9-1</a>).</p>
<table class="border less_space pagebreak-before" id="table_nine_onedot_summary_of_aws_securi">
<caption class="less_space"><span class="label">Table 9-1. </span>Summary of AWS security tools</caption>
<thead>
<tr>
<th>AWS service</th>
<th>Key features</th>
<th>Use cases</th>
</tr>
</thead>
<tbody>
<tr>
<td>AWS Key Management Service (KMS)</td>
<td>Encryption at rest/in transit, AWS-managed or customer-managed keys</td>
<td>Protect sensitive AI training data, manage encryption policies for datasets</td>
</tr>
<tr>
<td>AWS Shield Advanced</td>
<td>DDoS protection, integration with WAF and Network Firewall Manager, real-time attack mitigation</td>
<td>Defend AI applications exposed to the internet from DDoS disruptions</td>
</tr>
<tr>
<td>Amazon Macie</td>
<td>ML-powered sensitive data discovery, automatic classification (e.g., PII, PHI)</td>
<td>Scan S3 buckets for sensitive data before training AI models</td>
</tr>
<tr>
<td>AWS Zero Trust (Verified Access/Permissions)</td>
<td>Identity-based access control, policy-based authorization without VPN</td>
<td>Enforce least-privilege access to AI model endpoints and dashboards</td>
</tr>
<tr>
<td>Amazon SageMaker Role Manager</td>
<td>Prebuilt IAM roles for ML personas, permission customization</td>
<td>Grant data scientists and MLOps engineers appropriate access within SageMaker environments</td>
</tr>
<tr>
<td>AWS Network Firewall</td>
<td>Deep packet inspection, TLS decryption, threat prevention</td>
<td>Prevent data exfiltration or malicious traffic in AI model pipelines</td>
</tr>
<tr>
<td>Amazon VPC</td>
<td>Subnet isolation, route tables, security groups</td>
<td>Create secure AI compute environments with no public internet exposure</td>
</tr>
<tr>
<td>AWS PrivateLink</td>
<td>Private, secure access to AWS services without exposing traffic to the internet</td>
<td>Privately connect to services like Amazon Bedrock for model inference and fine-tuning workflows</td>
</tr>
</tbody>
</table>
</div></section>
</div></section>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Compliance"><div class="sect2" id="compliance">
<h2>Compliance</h2>
<p>Compliance for AI is complex,<a contenteditable="false" data-type="indexterm" data-primary="compliance" data-secondary="described" id="id1834"/> as it must align with evolving legal, ethical, and technical expectations.</p>
<p>A first step is to create<a contenteditable="false" data-type="indexterm" data-primary="compliance" data-secondary="AI governance board" id="id1835"/><a contenteditable="false" data-type="indexterm" data-primary="governance" data-secondary="AI governance board" id="id1836"/> an AI governance board or committee. This group should include people from across the organization—not just technology and data science but also legal, risk, compliance, privacy, and even customer advocacy. You want a mix of people who understand both the technology and the potential impact of how it’s used.</p>
<p>Let’s say you’re building an AI model to screen job applicants. Your AI team might be focused on performance metrics, but HR and legal can help spot bias or fairness issues early on. Having them in the room from day one avoids headaches later.</p>
<p>Once the board is in place, define clear roles and responsibilities. Who’s reviewing models before deployment? Who owns the escalation path if an issue is flagged in production? Who sets policy around what kinds of data you can and can’t use?</p>
<p class="pagebreak-before">Then move on to policies and procedures, such as with the following topics:</p>
<ul>
<li><p>Data sourcing and privacy requirements</p></li>
<li><p>Model training and evaluation standards</p></li>
<li><p>Deployment criteria and approval steps</p></li>
<li><p>Ongoing monitoring for drift, misuse, or regulatory changes</p></li>
</ul>
<section data-type="sect3" data-pdf-bookmark="Compliance standards"><div class="sect3" id="compliance_standards">
<h3>Compliance standards</h3>
<p>AWS supports over 140 <a contenteditable="false" data-type="indexterm" data-primary="compliance" data-secondary="compliance standards" id="id1837"/>security standards and compliance certifications. True, it’s up to each customer to decide how much risk they’re willing to accept. But there are certain security frameworks that are especially relevant when you’re working with AI systems:<a contenteditable="false" data-type="indexterm" data-primary="National Institute of Standards and Technology (NIST) security framework" id="id1838"/><a contenteditable="false" data-type="indexterm" data-primary="NIST (National Institute of Standards and Technology) security framework" id="id1839"/><a contenteditable="false" data-type="indexterm" data-primary="European Union Agency for Cybersecurity (ENISA) security framework" id="id1840"/><a contenteditable="false" data-type="indexterm" data-primary="ISO security standards" id="id1841"/><a contenteditable="false" data-type="indexterm" data-primary="AWS System and Organization Controls (SOC)" id="id1842"/><a contenteditable="false" data-type="indexterm" data-primary="SOC (AWS System and Organization Controls)" id="id1843"/><a contenteditable="false" data-type="indexterm" data-primary="Health Insurance Portability and Accountability Act (HIPAA) compliance" id="id1844"/><a contenteditable="false" data-type="indexterm" data-primary="HIPAA (Health Insurance Portability and Accountability Act) compliance" id="id1845"/><a contenteditable="false" data-type="indexterm" data-primary="General Data Protection Regulation (GDPR) compliance" id="id1846"/><a contenteditable="false" data-type="indexterm" data-primary="Payment Card Industry Data Security Standard (PCI DSS) compliance" id="id1847"/></p>
<dl>
<dt>National Institute of Standards and Technology (NIST)</dt>
<dd><p>The NIST 800-53 framework outlines a set of security controls used primarily by US federal agencies. Organizations following this standard go through formal assessments to confirm they’ve got the right protections in place for safeguarding sensitive information.</p></dd>
<dt>European Union Agency for Cybersecurity (ENISA)</dt>
<dd><p>ENISA plays a central role in shaping the EU’s approach to cybersecurity. It develops certification structures that build trust in digital services and infrastructure, and it works closely with EU member states to help prepare for evolving cyber threats.</p></dd>
<dt>International Organization for Standardization (ISO)</dt>
<dd><p>ISO security standards—especially those based on ISO/IEC 27002—provide a road map for managing security risks. They provide best practices and detailed controls for creating a strong information security management system (ISMS).</p></dd>
<dt>AWS System and Organization Controls (SOC)</dt>
<dd><p>SOC reports from AWS are third-party audits that verify how well AWS has implemented its compliance and security practices.</p></dd>
<dt>Health Insurance Portability and Accountability Act (HIPAA)</dt>
<dd><p>For healthcare organizations in the US, AWS supports HIPAA compliance by offering a secure environment for handling PHI. That includes everything from storing data to processing and transmitting it.</p></dd>
<dt>General Data Protection Regulation (GDPR)</dt>
<dd><p>The GDPR sets a high bar for data privacy in the European Union. It’s designed to protect personal information and gives EU residents more control over how their data is used.</p></dd>
<dt>Payment Card Industry Data Security Standard (PCI DSS)</dt>
<dd><p>PCI DSS is about protecting credit card data. Managed by the PCI Security Standards Council—a group formed by major credit card companies like Visa and Mastercard—it outlines the technical and operational requirements for keeping payment data safe.</p></dd>
</dl>
<p>Compliance is complicated,<a contenteditable="false" data-type="indexterm" data-primary="compliance" data-secondary="challenges" id="id1848"/> as it needs to align with legal, ethical, and technical expectations for how AI gets built, deployed, and used. And unlike traditional software, AI brings a few new wrinkles that complicate the picture.</p>
<p>The following are some of the challenges for AI compliance:</p>
<dl>
<dt>Complexity and lack of transparency</dt>
<dd><p>AI systems—especially LLMs and generative AI—often operate like black boxes. Their internal logic can be incredibly complex, and it’s not always clear how they generate a given output. That lack of explainability makes compliance audits harder.</p></dd>
<dt>Constant change</dt>
<dd><p>Many models evolve over time, learning from new data or adapting in production. That’s a problem for traditional compliance frameworks, which usually expect systems to behave consistently once they’re deployed.</p></dd>
<dt>Emergent capabilities</dt>
<dd><p>As AI systems grow more sophisticated, they can develop emergent capabilities—skills or behaviors the designers didn’t plan for. These aren’t bugs or features someone explicitly coded in. They’re by-products of how complex systems interact. That unpredictability means regulators and developers alike need to stay alert and flexible.</p></dd>
<dt>Accountability</dt>
<dd><p>AI systems need to be explainable, traceable, and subject to human review. Some governments are already moving in this direction. The EU’s Artificial Intelligence Act, for example, lays out requirements for transparency, risk assessments, and human oversight. In the US, cities like New York have passed laws requiring disclosure and review of automated decision-making tools.</p></dd>
</dl>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Regulated workloads"><div class="sect3" id="regulated_workloads">
<h3>Regulated workloads</h3>
<p>A regulated workload is one<a contenteditable="false" data-type="indexterm" data-primary="compliance" data-secondary="regulated workloads" id="id1849"/><a contenteditable="false" data-type="indexterm" data-primary="regulated workloads" id="id1850"/> that must follow specific compliance rules—whether legal, industry-specific, or tied to safety and liability concerns. These requirements often apply in fields like healthcare, finance, or aerospace, where systems process sensitive data or impact high-stakes decisions. If your workload falls under standards like HIPAA, GDPR, PCI DSS, or FDA regulations, it’s clearly regulated.</p>
<p>However, regulation doesn’t always look the same. It can show up in how you operate, what risks you manage, or how much oversight your system requires. A few examples include:</p>
<dl>
<dt>Processes under oversight</dt>
<dd><p>Such as submitting reports to agencies like the FDA</p></dd>
<dt>Decisions with consequences</dt>
<dd><p>Like mortgage approvals or credit scoring, where fairness and transparency <span class="keep-together">matter</span></p></dd>
<dt>Critical system usage</dt>
<dd><p>In areas where failure could risk lives, health, or infrastructure</p></dd>
<dt>Liability from AI models</dt>
<dd><p>Especially when a model’s output could lead to legal or financial repercussions</p></dd>
</dl>
<p>Some compliance expectations aren’t legally mandated but still demand attention. Frameworks like HIPAA set policies for how organizations govern data—not just how they store or transmit it. These standards may be enforced through audits, contractual obligations, or industry norms. Workloads that typically require close oversight include:</p>
<ul>
<li><p>HR systems handling confidential employee data</p></li>
<li><p>Safety systems where performance impacts human health or public safety</p></li>
<li><p>Compliance and inspection workflows used for audits or internal controls</p></li>
</ul>
<p>Not every workload comes with a legal label, so it helps to ask the right questions:</p>
<ul>
<li><p>Will this workload need to be audited?</p></li>
<li><p>Am I required to retain the data for a specific duration?</p></li>
<li><p>Are the outputs considered official records or special data types?</p></li>
<li><p>Does this workload touch data with internal classification rules—even if not formally regulated?</p></li>
</ul>
<p>If you answered yes to any of these, treat your workload as regulated. It’s better to be cautious and compliant than caught off guard later.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="AWS compliance tools"><div class="sect3" id="aws_compliance_tools">
<h3>AWS compliance tools</h3>
<p>Compliance tools in AWS<a contenteditable="false" data-type="indexterm" data-primary="compliance" data-secondary="AWS compliance tools" id="id1851"/><a contenteditable="false" data-type="indexterm" data-primary="AWS (Amazon Web Services)" data-secondary="compliance tools" id="id1852"/> are designed to help you meet regulatory, industry, and internal standards. These services streamline evidence collection, provide access to third-party audits, and identify vulnerabilities that may pose compliance risks.</p>
<section data-type="sect4" data-pdf-bookmark="AWS Audit Manager"><div class="sect4" id="aws_audit_manager">
<h4>AWS Audit Manager</h4>
<p>AWS Audit Manager automates<a contenteditable="false" data-type="indexterm" data-primary="AWS Audit Manager" id="id1853"/> evidence collection for audits by continuously evaluating your AWS environment against prebuilt or custom control frameworks like SOC 2, GDPR, HIPAA, and ISO 27001. It collects and maps data from AWS services, so you can generate audit-ready reports with less manual effort. This helps reduce the burden of preparing for audits and ensures your controls are functioning as intended.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="AWS Artifact"><div class="sect4" id="aws_artifact">
<h4>AWS Artifact</h4>
<p>AWS Artifact is a self-service portal <a contenteditable="false" data-type="indexterm" data-primary="AWS Artifact" id="id1854"/>for accessing AWS’s compliance reports and certifications. It includes documents like SOC 1/2/3 reports, ISO certifications, and PCI compliance documentation. AWS Artifact helps you understand how AWS complies with various standards, but you are still responsible for configuring and managing your environment to meet your own compliance obligations.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="Amazon Inspector"><div class="sect4" id="amazon_inspector">
<h4>Amazon Inspector</h4>
<p>Amazon Inspector is a <a contenteditable="false" data-type="indexterm" data-primary="Amazon Inspector" id="id1855"/><a contenteditable="false" data-type="indexterm" data-primary="vulnerability management" data-secondary="Amazon Inspector" id="id1856"/>vulnerability management service that continuously scans your EC2 instances, Lambda functions, and container images for known security issues. It identifies software vulnerabilities and network exposures using real-world threat intelligence from sources like the National Vulnerability Database (NVD). Findings are prioritized based on severity. This allows for addressing high-risk issues first—an important step in maintaining compliance with standards that require regular vulnerability assessments.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="AWS Trusted Advisor"><div class="sect4" id="aws_trusted_advisor">
<h4>AWS Trusted Advisor</h4>
<p>AWS Trusted Advisor evaluates<a contenteditable="false" data-type="indexterm" data-primary="AWS Trusted Advisor" id="id1857"/> your AWS account against best practices for security, fault tolerance, performance, service limits, and cost optimization. From a compliance perspective, its security checks—such as exposed ports or overly permissive IAM policies—help organizations proactively identify and address risks that might otherwise lead to compliance violations (see <a data-type="xref" href="#table_nine_twodot_summary_of_aws_servic">Table 9-2</a>).</p>
<table class="border" id="table_nine_twodot_summary_of_aws_servic">
<caption><span class="label">Table 9-2. </span>Summary of AWS services for compliance</caption>
<thead>
<tr>
<th>AWS service</th>
<th>Key features</th>
<th>Use cases</th>
</tr>
</thead>
<tbody>
<tr>
<td>AWS Audit Manager</td>
<td>Automated evidence collection, continuous assessment, prebuilt/custom control frameworks</td>
<td>Generate audit-ready reports for SOC 2, HIPAA, or ISO 27001 with reduced manual effort</td>
</tr>
<tr>
<td>AWS Artifact</td>
<td>Self-service access to AWS compliance reports and certifications</td>
<td>Download AWS’s PCI DSS, ISO, and SOC reports for use in your own compliance documentation efforts</td>
</tr>
<tr>
<td>Amazon Inspector</td>
<td>Continuous vulnerability scanning, real-time threat intelligence integration</td>
<td>Detect and prioritize EC2 or container vulnerabilities for HIPAA, PCI DSS, or ISO 27001 compliance</td>
</tr>
<tr>
<td>AWS Trusted Advisor</td>
<td>Best practice checks including security and access risks</td>
<td>Identify overly permissive IAM roles or open ports that could violate compliance policies</td>
</tr>
</tbody>
</table>
</div></section>
</div></section>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Governance"><div class="sect2" id="governance-id000030">
<h2>Governance</h2>
<p>Effective AI requires strong governance. Let’s explore what that entails in the following sections.</p>
<section data-type="sect3" data-pdf-bookmark="Data governance concepts"><div class="sect3" id="data_governance_concepts">
<h3>Data governance concepts</h3>
<p>Data governance is a specialized<a contenteditable="false" data-type="indexterm" data-primary="governance" data-secondary="data governance" id="c09dgov"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="governance" id="c09dgov2"/> domain within that broader governance umbrella. It focuses specifically on how data is collected, stored, accessed, protected, and used. It involves policies, standards, roles, and tools to ensure data quality, integrity, security, and privacy.</p>
<p>Amazon highlights six essential data management concepts that play a critical role in the development, deployment, and ongoing health of AI systems (see <a data-type="xref" href="#figure_nine_threedot_data_management_co">Figure 9-3</a>).</p>
<figure><div id="figure_nine_threedot_data_management_co" class="figure">
<img src="assets/awsc_0903.png" alt="" width="936" height="935"/>
<h6><span class="label">Figure 9-3. </span>Data management concepts</h6>
</div></figure>
<p>Let’s look at each of them:</p>
<dl>
<dt>Data lifecycles</dt>
<dd><p>The concept of a data lifecycle describes the journey data takes from the moment it’s created to the point it’s archived or deleted. For AI workloads, this includes everything from raw data collection to how that data is processed, stored, used in training and inference, and ultimately retired.</p>
<p>Each phase needs careful planning. For instance, if you collect data without clear labeling during the initial stage, you could face serious problems when it comes time to train your models. On the flip side, failing to archive or properly dispose outdated data can introduce compliance risks or inflate storage costs.</p></dd>
<dt>Data logging</dt>
<dd><p>Data logging is about keeping<a contenteditable="false" data-type="indexterm" data-primary="logging" data-secondary="data logging for governance" id="id1858"/> a detailed record of what your AI system is doing with its data. This includes capturing input and output data, model performance metrics, and key system events. This helps you debug issues, monitor ongoing performance, and trace problems when something unexpected happens.</p>
<p>Data logging is a powerful tool for transparency and accountability. When you’re trying to understand why a model made a certain prediction—or why it suddenly started underperforming—logs can often tell the full story.</p></dd>
<dt>Data residency</dt>
<dd><p>Data residency refers to<a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="data residency" id="id1859"/> where your data physically resides and where it gets processed. Some countries require that data about their citizens stay within their borders—a concept known as data sovereignty.</p>
<p>From an AI perspective, data residency decisions also affect performance. Keeping your training data close to the compute resources doing the heavy lifting can reduce latency and lower costs. But the main takeaway here is that you need to know where your data is and why it’s there, particularly if you’re working across multiple regions or cloud providers.</p></dd>
<dt>Data monitoring</dt>
<dd><p>Data monitoring is the practice<a contenteditable="false" data-type="indexterm" data-primary="monitoring" data-secondary="data monitoring" id="id1860"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="monitoring" id="id1861"/> of continuously monitoring the quality, consistency, and relevance of your data. Over time, real-world data changes, and your models can become less effective.</p>
<p>Monitoring helps catch issues like anomalies, low-quality data, or changes in distribution before they lead to performance problems. For teams managing production AI systems, this kind of oversight is crucial for preventing silent model failures and maintaining trust in the system’s outputs.</p></dd>
<dt>Data analysis</dt>
<dd><p>Data analysis involves<a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="foundation models" data-tertiary="data analysis" id="id1862"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="training data" data-tertiary="data analysis" id="id1863"/> analyzing your datasets to understand their structure, detect patterns, and uncover insights that can shape how you train and evaluate models. This usually includes methods like statistical summaries, data visualization, and exploratory data analysis (EDA).</p>
<p>Without proper analysis, you risk feeding your models data that’s incomplete, biased, or irrelevant. Solid analysis not only improves model design and feature engineering but also helps identify gaps in your dataset that could lead to blind spots in the model’s predictions.</p></dd>
<dt>Data retention</dt>
<dd><p>Data retention is about<a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="retention" id="id1864"/> deciding how long to keep your data—and why. In AI, retention policies can serve several purposes, such as meeting legal or industry <span class="keep-together">regulations,</span> preserving historical data for retraining, or managing the cost of cloud storage.</p>
<p>It’s a balancing act. Keeping data for too long can increase risks around privacy and compliance, while discarding it too quickly might eliminate valuable context needed to improve models over time.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c09dgov" id="id1865"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c09dgov2" id="id1866"/></p></dd>
</dl>
</div></section>
<section data-type="sect3" data-pdf-bookmark="AWS governance tools and services"><div class="sect3" id="aws_governance_tools_and_services">
<h3>AWS governance tools and services</h3>
<p>Governance in AWS focuses<a contenteditable="false" data-type="indexterm" data-primary="governance" data-secondary="AWS tools and services" id="id1867"/><a contenteditable="false" data-type="indexterm" data-primary="AWS (Amazon Web Services)" data-secondary="governance tools and services" id="id1868"/> on managing resources at scale, enforcing organizational policies, and ensuring consistent configurations across multiple accounts and teams. These tools help organizations maintain control, standardize environments, and align cloud usage with business and regulatory requirements.</p>
<section data-type="sect4" data-pdf-bookmark="AWS Organizations and service control policies (SCPs)"><div class="sect4" id="aws_organizations_and_service_control_p">
<h4>AWS Organizations and service control policies (SCPs)</h4>
<p>AWS Organizations enables<a contenteditable="false" data-type="indexterm" data-primary="AWS Organizations" id="id1869"/><a contenteditable="false" data-type="indexterm" data-primary="AWS Organizations" data-secondary="service control policies" id="id1870"/><a contenteditable="false" data-type="indexterm" data-primary="policies" data-secondary="AWS Organizations" id="id1871"/> centralized management of multiple AWS accounts, allowing you to group accounts, apply policies, and manage billing from a single location. Service control policies (SCPs) act as permission guardrails, defining what actions can or cannot be performed within specific accounts or organizational units—regardless of individual IAM permissions. This helps prevent accidental or unauthorized use of sensitive services or configurations across your environment.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="AWS Control Tower"><div class="sect4" id="aws_control_tower">
<h4>AWS Control Tower</h4>
<p>AWS Control Tower provides<a contenteditable="false" data-type="indexterm" data-primary="AWS Control Tower" id="id1872"/><a contenteditable="false" data-type="indexterm" data-primary="landing zones" id="id1873"/><a contenteditable="false" data-type="indexterm" data-primary="policies" data-secondary="AWS Control Tower for consistency" id="id1874"/> a way to set up and govern a secure, multiaccount AWS environment, also known as a <em>landing zone</em>. It automates account creation, configures guardrails, and sets up logging and security baselines. With Control Tower, enterprises can maintain consistent policies while enabling development teams to move quickly within defined boundaries.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="AWS Config"><div class="sect4" id="aws_config">
<h4>AWS Config</h4>
<p>AWS Config tracks and records<a contenteditable="false" data-type="indexterm" data-primary="AWS Config" id="id1875"/> configuration changes to your AWS resources. This allows you to assess compliance with desired states over time. It provides a detailed history of resource configurations and relationships, helping with troubleshooting, audit readiness, and policy enforcement. You can also define Config rules to automatically detect noncompliant resources and trigger remediations.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="AWS CloudTrail"><div class="sect4" id="aws_cloudtrail">
<h4>AWS CloudTrail</h4>
<p>While often categorized<a contenteditable="false" data-type="indexterm" data-primary="AWS CloudTrail" id="id1876"/><a contenteditable="false" data-type="indexterm" data-primary="logging" data-secondary="AWS CloudTrail" id="id1877"/> as a security and audit tool, CloudTrail also plays a governance role by logging every API call across your AWS accounts. It enables visibility into user and service activity, supports compliance investigations, and can trigger alerts based on specific actions. CloudTrail logs are critical for maintaining accountability and enforcing governance across distributed teams (see <a data-type="xref" href="#table_nine_threedot_summary_of_aws_serv">Table 9-3</a>).</p>
<table class="border" id="table_nine_threedot_summary_of_aws_serv">
<caption><span class="label">Table 9-3. </span>Summary of AWS services for governance</caption>
<thead>
<tr>
<th>AWS service</th>
<th>Key features</th>
<th>Use cases</th>
</tr>
</thead>
<tbody>
<tr>
<td>AWS Organizations<br/>and SCPs</td>
<td>Centralized account management, hierarchical structure, policy enforcement</td>
<td>Restrict use of certain services/org units regardless of IAM permissions</td>
</tr>
<tr>
<td>AWS Control Tower</td>
<td>Automates setup of multiaccount environments, applies guardrails, baseline configuration</td>
<td>Establish secure landing zones with predefined governance policies</td>
</tr>
<tr>
<td>AWS Config</td>
<td>Tracks configuration changes, resource relationships, compliance auditing</td>
<td>Identify and remediate noncompliant resources automatically</td>
</tr>
<tr>
<td>AWS CloudTrail</td>
<td>Logs API activity across AWS accounts, enables user/service activity monitoring</td>
<td>Investigate actions, support audits, and enforce accountability</td>
</tr>
</tbody>
</table>
</div></section>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Understanding data and model lineage"><div class="sect3" id="understanding_data_and_model_lineage">
<h3>Understanding data and model lineage</h3>
<p>Data and model lineage refers<a contenteditable="false" data-type="indexterm" data-primary="governance" data-secondary="model lineage" id="id1878"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="data lineage" id="id1879"/><a contenteditable="false" data-type="indexterm" data-primary="model lineage" id="id1880"/><a contenteditable="false" data-type="indexterm" data-primary="governance" data-secondary="data governance" data-tertiary="data lineage" id="id1881"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="governance" data-tertiary="data lineage" id="id1882"/> to the complete history of where your data and models come from, how they’ve changed over time, and what processes shaped them. In AI—and especially in generative AI—keeping track of this lineage is critical. It gives you a clear picture of your system’s origins, its reliability, and any potential biases baked into your data or models.</p>
<p>Understanding data and model lineage in AWS touches all three categories—compliance, security, and governance—but it aligns most directly with governance, with strong ties to compliance.</p>
<p>Next, we will look at the key components of data and model lineage.</p>
<section data-type="sect4" data-pdf-bookmark="Source citation and data origins documentation"><div class="sect4" id="source_citation_and_data_origins_docume">
<h4>Source citation and data origins documentation</h4>
<p>Source citation and data origins documentation is key for building trustworthy AI. They’re the practices that help make your system transparent, traceable, and accountable. Here’s a closer look at what each one involves:<a contenteditable="false" data-type="indexterm" data-primary="responsible AI" data-secondary="training data source citation" id="id1883"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="training data" data-tertiary="source citation" id="id1884"/><a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="data governance" data-tertiary="data source citation" id="id1885"/><a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="data governance" data-tertiary="documenting data origins" id="id1886"/><a contenteditable="false" data-type="indexterm" data-primary="responsible AI" data-secondary="training data source citation" data-tertiary="documenting data origins" id="id1887"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="training data" data-tertiary="documenting data origins" id="id1888"/></p>
<dl>
<dt>Source citation</dt>
<dd><p>In generative AI, source citation means properly acknowledging where your training data comes from. Whether you’re pulling from datasets, databases, or other resources, it’s important to document every source clearly. You’ll also want to capture any licenses, permissions, or terms of use tied to the data.</p></dd>
<dt>Documenting data origins</dt>
<dd><p>Documenting data origins goes deeper. It’s about recording every detail about how the training data was collected, curated, cleaned, and transformed. Here’s what you should document:</p>
<ul>
<li><p>How and where the data was collected</p></li>
<li><p>How the data was cleaned and curated</p></li>
<li><p>Any preprocessing steps or transformations</p></li>
</ul>
<p>By doing this, you surface any hidden biases, limitations, or quality issues early on. That insight can make or break the reliability of your model down the line.</p></dd>
</dl>
</div></section>
<section data-type="sect4" data-pdf-bookmark="Data lineage"><div class="sect4" id="data_lineage">
<h4>Data lineage</h4>
<p>When done right, data lineage makes your source citations and origin documentation much easier. We will look at some of the main approaches:</p>
<dl>
<dt>Cataloging</dt>
<dd><p>Cataloging organizes your datasets, models, and resources systematically. Think of it as building a library for your AI system: every piece of data, every model, and every license has a “book” with all its details inside.</p>
<p>A well-kept catalog improves how you manage, communicate, and audit your data and model lineage—whether internally or with outside stakeholders.</p></dd>
<dt>Model cards</dt>
<dd><p>Model cards offer a<a contenteditable="false" data-type="indexterm" data-primary="model cards" data-secondary="governance documentation" id="id1889"/> standardized way to document your machine learning models. In generative AI, a good model card tells the full story of:</p>
<ul>
<li><p>What data the model used</p></li>
<li><p>Where that data came from</p></li>
<li><p>Any licenses or terms tied to the data</p></li>
<li><p>Known biases, risks, or quality issues</p></li>
</ul>
<p>Beyond data origins, model cards also describe the model’s intended use, performance benchmarks, and limitations. They help you set the right expectations with users, support audits, and align your models with business goals.</p>
<p>If you’re using Amazon SageMaker, SageMaker Model Cards can make this process even smoother by offering a centralized space for all your model details.</p></dd>
</dl>
</div></section>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Review of data usage in generative AI"><div class="sect3" id="review_of_data_usage_in_generative_ai">
<h3>Review of data usage in generative AI</h3>
<p>Effective data governance starts<a contenteditable="false" data-type="indexterm" data-primary="governance" data-secondary="data governance" data-tertiary="data usage in generative AI" id="id1890"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="governance" data-tertiary="data usage in generative AI" id="id1891"/> with understanding the different types of data used in generative AI and who controls them. Most generative AI applications rely on three key categories: user data, fine-tuning data, and training data. Each plays a distinct role in shaping how the model performs—and each comes with different governance implications.</p>
<p>Let’s take a closer look at each type of data and how it’s typically governed.</p>
<section data-type="sect4" data-pdf-bookmark="User data"><div class="sect4" id="user_data">
<h4>User data</h4>
<p>User data includes anything<a contenteditable="false" data-type="indexterm" data-primary="user data governance" id="id1892"/> the customer or end user provides—inputs, prompts, requirements—basically, whatever the user sends into the system to generate a specific output.</p>
<p>No matter the application scope, the customer always controls their own user data. This is an important constant you can count on.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="Fine-tuning data"><div class="sect4" id="fine_tuning_data">
<h4>Fine-tuning data</h4>
<p>Fine-tuning data is used<a contenteditable="false" data-type="indexterm" data-primary="fine-tuning" data-secondary="data governance" id="id1893"/> to adapt a pretrained generative AI model to meet the specific needs of a customer or a particular domain.</p>
<p>Here’s how fine-tuning data typically works:</p>
<ul>
<li><p>It’s often a subset of the original training data or new data collected specifically from the application’s domain.</p></li>
<li><p>Fine-tuning tweaks the model’s internal settings—its parameters and weights—so it produces more relevant and personalized results for the task at hand.</p></li>
</ul>
<p>Control of the fine-tuning data depends on the application scope:</p>
<ul>
<li><p>In Scopes 1 and 2, the application provider controls the fine-tuning data.</p></li>
<li><p>In Scope 4, the customer controls the fine-tuning data.</p></li>
</ul>
<p>Knowing who controls what is critical for both governance and compliance, so it’s worth keeping this breakdown top of mind.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="Training data"><div class="sect4" id="training_data">
<h4>Training data</h4>
<p>Training data is the large,<a contenteditable="false" data-type="indexterm" data-primary="training" data-secondary="data governance" id="id1894"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="training data" data-tertiary="governance" id="id1895"/> diverse dataset used to build the model’s initial knowledge and core capabilities.</p>
<p>Here’s what you need to know about training data:</p>
<ul>
<li><p>It often includes a wide range of content—text, images, audio—depending on what the model is designed to do.</p></li>
<li><p>This data teaches the model the patterns, structures, and relationships it needs to generate new, meaningful outputs.</p></li>
</ul>
<p>When it comes to ownership:</p>
<ul>
<li><p>In Scopes 1, 2, 3, and 4, the application provider controls the training data.</p></li>
<li><p>In Scope 5, the customer controls the training data.</p></li>
</ul>
<p>The control plays a big role in how governance, security, and customization are handled across different generative AI projects.</p>
</div></section>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Secure data engineering"><div class="sect3" id="secure_data_engineering">
<h3>Secure data engineering</h3>
<p>Strong secure data engineering practices<a contenteditable="false" data-type="indexterm" data-primary="security" data-secondary="secure data engineering" id="id1896"/><a contenteditable="false" data-type="indexterm" data-primary="governance" data-secondary="secure data engineering" id="id1897"/><a contenteditable="false" data-type="indexterm" data-primary="secure data engineering" id="id1898"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="secure data engineering" id="id1899"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="security and privacy" data-tertiary="secure data engineering" id="id1900"/> are key to safe, reliable AI and generative AI systems. Let’s dive into the key areas you need to focus on.</p>
<section data-type="sect4" data-pdf-bookmark="Assessing data quality"><div class="sect4" id="assessing_data_quality">
<h4>Assessing data quality</h4>
<p>Assessing data quality starts<a contenteditable="false" data-type="indexterm" data-primary="secure data engineering" data-secondary="assessing data quality" id="id1901"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="secure data engineering" data-tertiary="assessing data quality" id="id1902"/> with setting clear metrics. You’ll want to define standards for completeness, ensuring your training data covers a broad and representative range of scenarios without major gaps or biases. Accuracy is equally important; the data must be correct, up to date, and reflect real-world situations the model will face. Timeliness, sometimes called <em>currency</em>, measures how current your data is—outdated data can quickly erode a model’s performance. Finally, consistency ensures the data remains coherent and logically sound throughout development and deployment. To enforce these standards, integrate validation checks at multiple stages of your data pipeline, perform regular data profiling, and monitor quality issues as they arise. It’s also crucial to maintain a feedback loop for continuous improvement and document detailed data lineage and metadata to keep track of your data’s journey and transformations.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="Implementing privacy-enhancing technologies"><div class="sect4" id="implementing_privacy_enhancing_technolo">
<h4>Implementing privacy-enhancing technologies</h4>
<p>Protecting user and <a contenteditable="false" data-type="indexterm" data-primary="privacy" data-secondary="privacy-enhancing technologies" id="id1903"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="security and privacy" data-tertiary="privacy-enhancing technologies" id="id1904"/><a contenteditable="false" data-type="indexterm" data-primary="secure data engineering" data-secondary="privacy-enhancing technologies" id="id1905"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="secure data engineering" data-tertiary="privacy-enhancing technologies" id="id1906"/>training data requires implementing privacy-enhancing technologies. Start with techniques like data masking, data obfuscation, or differential privacy, which help reduce the risk of exposing sensitive information even if a breach occurs. Strengthen your defenses further by using encryption, tokenization, and secure multi-party computation to safeguard data while it’s being processed or stored. These approaches work together to ensure that your data remains protected without sacrificing performance or usability.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="Data access control"><div class="sect4" id="data_access_control">
<h4>Data access control</h4>
<p>Controlling who can access<a contenteditable="false" data-type="indexterm" data-primary="access controls" id="id1907"/><a contenteditable="false" data-type="indexterm" data-primary="policies" data-secondary="access controls" id="id1908"/><a contenteditable="false" data-type="indexterm" data-primary="secure data engineering" data-secondary="data access control" id="id1909"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="secure data engineering" data-tertiary="data access control" id="id1910"/> your data—and under what circumstances—is fundamental for maintaining security. Establish a strong data governance framework with well-defined policies that govern access, use, and sharing. Implement role-based access controls and assign fine-grained permissions so that users only have access to what they truly need. Strengthen these controls by using authentication and authorization systems like single sign-on (SSO), multi-factor authentication (MFA), and IAM solutions. Keep a close eye on your system by monitoring and logging all data access activities to catch unauthorized use early. Regularly review and update permissions to align with the principle of least privilege, ensuring minimum necessary access for each role.</p>
</div></section>
<section data-type="sect4" data-pdf-bookmark="Data integrity"><div class="sect4" id="data_integrity">
<h4>Data integrity</h4>
<p>Maintaining data integrity ensures<a contenteditable="false" data-type="indexterm" data-primary="secure data engineering" data-secondary="data integrity" id="id1911"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="secure data engineering" data-tertiary="data integrity" id="id1912"/> your AI models are built on solid, trustworthy foundations. Implement validation and integrity checks throughout your data pipeline, such as schema validation, referential integrity checks, and business rule validations, to catch errors before they cause bigger issues. Always have a robust backup and recovery strategy in place so you can quickly restore data after system failures, mistakes, or disasters. Use transaction management and atomicity principles to keep data consistent and reliable during processing and transformation. Document your data’s full history by maintaining detailed data lineage and audit trails, which allow you to track every change. Finally, make a habit of regularly monitoring and testing your data integrity controls, adjusting them as needed to stay resilient against evolving risks.</p>
</div></section>
</div></section>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Conclusion"><div class="sect1" id="conclusion-id000015">
<h1>Conclusion</h1>
<p>Securing AI systems is a necessity. As organizations build more sophisticated models and adopt generative AI technologies, the stakes keep rising. Security, compliance, and governance must work hand in hand to protect sensitive data, ensure ethical practices, and meet growing regulatory demands. By taking a layered approach to defense, setting clear governance frameworks, and implementing strong data management practices, companies not only can reduce risks but also strengthen the trust of customers, partners, and regulators. In the end, building responsible AI isn’t just about avoiding problems—it’s about creating solutions that are resilient, transparent, and ready for the future.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Quiz"><div class="sect1" id="ch9quiz">
	<h1>Quiz</h1>

<p>To check your answers, please refer to the <a data-type="xref" href="app02.html#answers_ch_9">“Chapter 9 Answer Key”</a>.</p>

<ol>
<li><p>What is a key difference between governance and compliance?</p>
<ol type="a">
<li><p>Governance enforces laws, while compliance manages innovation.</p></li>
<li><p>Governance protects data, while compliance ensures ethical AI development.</p></li>
<li><p>Governance guides decision making and risk management, while compliance ensures adherence to external and internal rules.</p></li>
<li><p>Governance is optional, but compliance is legally mandatory for all companies.</p></li>
</ol>
</li>

<li><p>In AWS, what best describes the purpose of a defense-in-depth strategy?</p>
<ol type="a">
<li><p>To rely on a single strong security control.</p></li>
<li><p>To use multiple, layered security measures to catch threats that bypass one control.</p></li>
<li><p>To automate model training and inference pipelines.</p></li>
<li><p>To combine multiple security layers so if one fails, others can provide <span class="keep-together">protection.</span></p></li>
</ol>
</li>

<li><p>Which AWS services would you primarily use to protect applications against denial-of-service (DoS) attacks and manage secure user sign-ins?</p>
<ol type="a">
<li><p>Amazon GuardDuty and AWS Private CA</p></li>
<li><p>AWS Key Management Service (KMS) and AWS Certificate Manager (ACM)</p></li>
<li><p>AWS Shield and Amazon Cognito</p></li>
<li><p>Amazon Virtual Private Cloud (VPC) and AWS WAF</p></li>
</ol>
</li>
</ol>

<ol class="less_space pagebreak-before" start="4">
<li><p>Which AWS service helps route sensitive traffic privately without exposing it to the public internet?</p>
<ol type="a">
<li><p>AWS PrivateLink</p></li>
<li><p>AWS Security Hub</p></li>
<li><p>Amazon VPC</p></li>
<li><p>Amazon GuardDuty</p></li>
</ol>
</li>

<li><p>Which of the following is an example of a governance policy for AI solutions?</p>
<ol type="a">
<li><p>Building AI models without any human review</p></li>
<li><p>Using only public datasets without checking privacy concerns</p></li>
<li><p>Defining standards for data sourcing, model training, evaluation, and deployment approvals</p></li>
<li><p>Allowing unrestricted model deployment to speed innovation</p></li>
</ol>
</li>

<li><p>Which AWS-supported compliance framework is specifically focused on protecting United States healthcare information?</p>
<ol type="a">
<li><p>Payment Card Industry Data Security Standard (PCI DSS)</p></li>
<li><p>Health Insurance Portability and Accountability Act (HIPAA)</p></li>
<li><p>General Data Protection Regulation (GDPR)</p></li>
<li><p>European Union Agency for Cybersecurity (ENISA)</p></li>
</ol>
</li>
</ol>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="ch01fn29"><sup><a href="ch09.html#ch01fn29-marker">1</a></sup> Bianca Chan, <a href="https://oreil.ly/KxT8C">“Wall Street Is Worried It Can’t Keep Up with AI-Powered Cybercriminals”</a>, <em>Business Insider</em>, March 11, 2025.</p><p data-type="footnote" id="ch01fn30"><sup><a href="ch09.html#ch01fn30-marker">2</a></sup> Shailendra Upadhyay, <a href="https://oreil.ly/bpJ46">“Information Security Spending: What Does the Future Hold?”</a>, Gartner, November 27, 2024.</p></div></div></section></div></div></body></html>