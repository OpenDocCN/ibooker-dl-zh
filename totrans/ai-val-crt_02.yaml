- en: Chapter 2\. Oh, to Be an AI Value Creator
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章\. 哦，成为一名AI价值创造者
- en: In the previous chapter, we gave a set of imperatives that can instantly improve
    the odds of success for any AI journey. This all comes from our countless collective
    experiences, which range from thousands of customer engagements to TV shows such
    as *60 Minutes*, to the US White House, NATO, senior management, and even the
    Vatican! (The Vatican houses priceless artifacts in nitrogen vaults, and we—well,
    the broader IBM team—helped open those artifacts up to scholars to safely scale
    knowledge and history. While we can’t share with you the details of that deal,
    we’re confident in the afterlife.)
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们提供了一套可以立即提高任何AI之旅成功几率的强制性要求。这一切都源于我们无数的集体经验，这些经验涵盖了从数千次客户互动到电视节目如*60分钟*，再到美国白宫、北约、高级管理层，甚至梵蒂冈！（梵蒂冈在氮气保险库中存放着无价之宝，而我们——嗯，更广泛的IBM团队——帮助学者们安全地扩展知识和历史。虽然我们无法与您分享那笔交易的细节，但我们对其未来充满信心。）
- en: You also learned about the Netscape moment of today and how it’s a tsunami of
    change that will wash across your personal and professional shores. You now understand
    that just as electricity was once deemed magical even though it wasn’t, AI is
    not magic either. We nudged (OK, two-hand shoved) you into a +AI to AI+ mindset
    and gave you a rebooted for this moment AI Ladder to climb for AI success. Finally,
    we gave you some operational frameworks to classify AI budgets, pick use cases,
    and envision outcomes that either shift left or shift right your business.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 您还了解到了今天的Netscape时刻以及它如何是一场横扫您个人和职业海岸的巨浪般的变革。您现在明白，尽管电一度被认为神奇，尽管它并非如此，AI也不是魔法。我们（好吧，用双手推）您进入了一个+AI到AI+的思维模式，并为您提供了这个时刻的AI梯子，以攀登AI成功的阶梯。最后，我们为您提供了一些操作框架，用于分类AI预算、选择用例和设想结果，这些结果要么将您的业务向左或向右转变。
- en: We think [Chapter 1](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974)
    and this chapter are important because they are both about defining the right
    details to pay attention to on your AI journeys. Why? Details will matter, details
    will differentiate, and details will earn (or keep) trust. We’ll use the history
    of the Statue of Liberty as an analogy of what you’re doing in the first part
    of this book. She stands tall and green in the iconic New York harbor. Her patina
    (the green chemical reaction to copper that occurs over the course of time) helps
    her stand strong against the elements—but it really must have been something for
    immigrants to see her copper glow on the horizon as they sailed into New York’s
    port, way back when. If you get a chance, take a moment to look at her hair. If
    you search for an up-close photo, you will see intricate braiding and precisely
    styled curls on the back of her head. It is perfect hair on top of a perfect statue.
    Interestingly enough, the Statue of Liberty was built 10 years before the first
    airplane. Her sculptor, Frédéric Auguste Bartholdi, had no reason to believe anyone
    would ever see her hair—yet the details mattered because sculpture was his craft,
    and his reputation depended on those details. What does this have to do with AI?
    The decisions you make over the next few years—and how you make them—may never
    be seen in isolation or explicitly, but the details of them will matter because
    they will stand for who you are and who your team, company, and you want to be.
    Remember that.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们认为[第一章](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974)和本章都很重要，因为它们都关乎在您的AI之旅中关注正确的细节。为什么？细节很重要，细节会区分，细节会赢得（或保持）信任。我们将以自由女神像的历史作为您在本书第一部分所做事情的类比。她高耸且绿色地矗立在标志性的纽约港。她的绿锈（随着时间的推移，铜与绿色化学反应形成的绿色物质）帮助她坚强地抵抗自然元素——但当她作为移民在驶入纽约港口时，看到她铜色的光芒，那一定是一件令人印象深刻的事情。如果你有机会，花点时间看看她的头发。如果你搜索近距离的照片，你会在她头后的头发上看到复杂的编织和精确的卷曲。这是在完美雕像上的完美头发。有趣的是，自由女神像是在第一架飞机之前10年建造的。她的雕塑家弗雷德里克·奥古斯特·巴托尔迪没有理由相信任何人会看到她的头发——然而细节很重要，因为雕塑是他的工艺，他的声誉依赖于这些细节。这与AI有什么关系？您在未来几年内做出的决定——以及您如何做出这些决定——可能永远不会孤立或明确地被看到，但它们的细节很重要，因为它们将代表您是谁，以及您的团队、公司和您希望成为的人。请记住这一点。
- en: 'In this chapter, we want to introduce you to perhaps the most important AI
    destination you should have in your own personal navigation systems: *the AI Value
    Creator*. Remember, this part of the book is on the business side, so while we’ll
    give you some more insights into large language models (LLMs) with a technology
    point of view later on, we’ve got some more AI business-related stuff we want
    to ensure you think about so that you’ll have a bigger set of skills to draw from
    than those who don’t read this book.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们想向您介绍可能是您个人导航系统中最重要的AI目的地：*AI价值创造者*。记住，这本书的这一部分是关于商业的，所以虽然我们会在稍后从技术角度为您提供一些关于大型语言模型（LLMs）的见解，但我们还有一些与AI商业相关的内容，我们希望确保您思考，这样您就能比那些没有阅读这本书的人拥有更丰富的技能集。
- en: 'AI Through the Years: The AI “Time Lapse” Section'
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI岁月：AI“时间流逝”部分
- en: The term *AI* was first coined in 1956, and various generations of this technology
    (though none like this GenAI and agentic moment) have progressed and disappointed
    ever since. Some would say that AI has disappointed more than it’s delighted,
    which has caused “AI winters” from which AI has reemerged after some breakthroughs.
    If you look at the history of invention (take electricity, for example), it should
    come as no surprise that the path to AI breakthroughs has run through mass experimentation.
    While many AI experiments have failed, successful ones have had a substantial
    impact, and those successes have come from solving the problems that caused failures.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '*AI*这个术语首次在1956年被提出，尽管没有像这一代的GenAI和代理时刻那样，这一代技术的各个版本自那时以来一直在进步和失望。有些人可能会说，人工智能的失望多于它的喜悦，这导致了“人工智能寒冬”，在经历了一些突破之后，人工智能又重新崛起。如果你看看发明的历史（以电力为例），那么通往人工智能突破的道路上经过大量实验也就不足为奇了。虽然许多人工智能实验都失败了，但成功的实验产生了重大影响，而这些成功来自于解决导致失败的问题。'
- en: People have long been speculating about the possibility that machines would
    someday be able to think like a human, on their own. This has been going on since
    the late 1800s, but the idea really took root with Alan Turing’s 1950 seminal
    paper, “Computing Machinery and Intelligence.”^([1](ch02.html#id389)) Historians
    call Turing the father of AI because of this very paper. In it, he theorized that
    society could create computers that would play chess, described how those computers
    would surpass human players, and said we would make them proficient in natural
    language. He theorized that machines would eventually think.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 人们长期以来一直在推测机器有朝一日能够像人类一样独立思考的可能性。这始于19世纪末，但这个想法真正扎根于艾伦·图灵1950年的开创性论文“计算机器与智能”。^([1](ch02.html#id389))
    历史学家称图灵为人工智能之父，正是因为这篇论文。在论文中，他提出了社会可以创造出能够下棋的计算机，描述了这些计算机将超越人类玩家，并说我们将使它们精通自然语言。他理论化了机器最终会思考。
- en: Over the course of our careers at IBM, we’ve seen (and been a part of achieving)
    many of the milestones that Turing identified on the way to a “thinking” machine.
    These have included evolutions and variants of AI playing games like chess (with
    Deep Blue), *Jeopardy!*, and the board game Go, as well as debating systems. But
    Turing was just the beginning.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们职业生涯的IBM时期，我们见证了（并且是其中一部分）图灵在通往“思考”机器的道路上所识别出的许多里程碑。这些包括像国际象棋（与Deep Blue）、*Jeopardy!*和围棋这样的棋类游戏以及辩论系统的人工智能的演变和变体。但图灵只是开始。
- en: If Turing’s paper was the spark, then the big bang came just six years later
    at Dartmouth College in its Summer Research Project on Artificial Intelligence
    workshop. There, a couple of young academics got together with a couple of senior
    scientists from Bell Labs and IBM and proposed an extended summer workshop with
    just a small handful of the top people in adjacent fields to intensively consider
    artificial intelligence. That’s where the term *AI* was first used, and it marks
    the point at which AI was established as a field of research.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 如果图灵的论文是火花，那么大爆炸就在六年后在达特茅斯学院的夏季人工智能研究项目研讨会上爆发了。在那里，几位年轻的学者与贝尔实验室和IBM的几位资深科学家聚在一起，提出了一个扩展的夏季研讨会，只有少数相邻领域的顶尖人物参与，以密集地考虑人工智能。这就是*AI*这个术语首次被使用，它标志着人工智能作为研究领域的确立。
- en: In extensive detail, this team laid out many of the challenges that researchers
    have been working on ever since to develop machines that could think. Neural networks,
    self-directed learning, creativity, and more are all still relevant today.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 这个团队详细阐述了研究人员自那时以来一直在努力解决的各种挑战，以开发能够思考的机器。神经网络、自主学习、创造力等等，所有这些在今天仍然相关。
- en: For perspective, this was 1956, the same year the invention of the transistor
    won the Nobel Prize. Today, we can put over 100 billion transistors in a graphics
    processing unit (GPU) and provision legions of interconnected GPUs to provide
    the computing power needed for GenAI. Throughout the years, AI theories, techniques,
    and ideas have been developed in parallel with progress in hardware that have
    come together to dramatically reduce computing and storage costs. All of this
    is converging now to make AI very real and practical.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有更清晰的视角，这是1956年，也就是晶体管发明获得诺贝尔奖的那一年。今天，我们可以在图形处理单元（GPU）中放置超过1000亿个晶体管，并配置大量相互连接的GPU来提供生成AI所需的计算能力。多年来，AI理论、技术和想法与硬件的进步并行发展，共同显著降低了计算和存储成本。所有这些现在正汇聚在一起，使AI变得非常真实和实用。
- en: 'But we want to make this critical point: it’s not just about powerful hardware
    and clever algorithms. *Maybe the most important ingredient of generative AI*—particularly
    when it comes to your business getting the most value from it—is *your* data.
    *You can’t talk about generative AI without talking about data*. This makes hardware,
    algorithms, and data the three legs of the AI stool.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们想强调一个关键点：这不仅仅关乎强大的硬件和巧妙的算法。*也许生成式AI最重要的成分*——尤其是当你的业务想要从中获得最大价值时——是*你的*数据。*不谈论数据就无法谈论生成式AI*。这使得硬件、算法和数据成为AI三脚架的三个支柱。
- en: A Quick Bit on Foundation Models
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 关于基础模型的一些快速说明
- en: In the GenAI world, you’ll often hear about how LLMs are powering GenAI. But
    what are they? At a basic level, LLMs are new ways of representing language in
    a high-dimensional space with a large number of parameters—representations created
    by training on massive quantities of text.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在生成式AI的世界里，你经常会听到关于LLMs如何推动生成式AI的消息。但它们是什么？在基本层面上，LLMs是在高维空间中用大量参数表示语言的新方法——这些表示是通过在大量文本上训练创建的。
- en: From this perspective, much of the history of computing has been about coming
    up with new ways to represent data and extract value from it. For a long time,
    we’ve put data in tables. For example, we put employees or customers in the rows
    of a database and put their attributes in the columns. This is great for things
    like online transaction processing (OLTP) or writing checks for payments to individuals.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个角度来看，计算机历史的大部分内容都是关于想出新方法来表示数据并从中提取价值。长期以来，我们一直将数据放入表格中。例如，我们将员工或客户放入数据库的行中，并将他们的属性放入列中。这对于在线事务处理（OLTP）或为个人支付开具支票等活动来说非常好。
- en: Then, the world started representing data with graphs, and this helped us discover
    and appreciate relationships between data points like never before; for example,
    this person, business, or place was connected to these other people, businesses,
    or places. Data represented this way starts to reveal patterns. For example, companies
    use graphs to map a social network or spot anomalous purchases to help them detect
    credit card fraud. This technology is a combination of many data analysis approaches
    using various types of data repositories (a graph database is included here),
    and this is also how the People You May Know (PYMK) feature works on Facebook
    (as just one example).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，世界开始用图表来表示数据，这帮助我们以前所未有的方式发现和欣赏数据点之间的关系；例如，这个人、企业或地点与这些其他的人、企业或地点相连。以这种方式表示的数据开始揭示模式。例如，公司使用图表来绘制社交网络或发现异常购买以帮助他们检测信用卡欺诈。这项技术是多种数据分析方法的组合，使用各种类型的数据存储库（包括图数据库），这也是Facebook上“你可能认识的人”（PYMK）功能的工作原理（仅举一例）。
- en: Today, with LLMs, we’re taking lots of data that’s represented in neural networks
    that simulate (very loosely) an abstract version of brain cells. There are layers
    and layers of connections with millions, tens of billions, hundreds of billions,
    or even trillions of parameters—and suddenly, you can do some fascinating things.
    You can discover patterns so detailed that you can predict relationships with
    a lot more confidence. For example, you can predict that this word is most likely
    connected to this next word, and these two words are most likely followed by a
    specific third word—meaning you can build up, reassess, and predict again and
    again until something new is created or *generated*. Hence, the term *generative
    AI*.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，随着大型语言模型（LLMs），我们正在处理大量以神经网络形式表示的数据，这些神经网络模拟（非常松散地）大脑细胞的抽象版本。这里有层层叠叠的连接，包含数百万、数十亿、数百亿甚至数万亿个参数——突然之间，你可以做一些令人着迷的事情。你可以发现如此详细的模式，以至于你可以更有信心地预测关系。例如，你可以预测这个单词最有可能与下一个单词相关联，这两个单词最有可能后面跟着一个特定的第三个单词——这意味着你可以不断建立、重新评估和预测，直到创造出新的或*生成*的东西。因此，我们称之为*生成式AI*。
- en: 'That’s what GenAI is: the ability to look at data, discover relationships,
    and predict the likelihood of sequences with enough confidence to create or generate
    something that didn’t exist before. Text, images, videos, sounds, and really all
    types of data can be represented in a model.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是GenAI：能够观察数据、发现关系，并足够自信地预测序列的可能性，以创造出之前不存在的东西。文本、图像、视频、声音以及所有类型的数据都可以在模型中表示。
- en: We could do a limited version of all of this before with deep learning, which
    was an AI milestone in its own right. With *deep learning*, we started representing
    a massive amount of data using very large neural networks with many layers, but
    training had to happen with annotated data that humans had to manually label;
    for example, looking at a picture and noting it as a “cat” and another picture
    as a “dog.” This is called *supervised learning*. So, what was the problem? As
    you can see in [Figure 2-1](#ch02_figure_1_1740182046144175), supervised learning
    is expensive, laborious, and time consuming, so only large institutions did that
    work and only for specific tasks. If you wanted AI to summarize and translate
    text, you needed to label two very large datasets...manually (more on this in
    a moment).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习出现之前，我们只能做这些的有限版本，而深度学习本身就是人工智能的一个里程碑。通过*深度学习*，我们开始使用具有许多层的非常大的神经网络来表示大量数据，但训练必须使用人工标注的数据进行；例如，看一张图片并标注为“猫”，另一张图片标注为“狗”。这被称为*监督学习*。那么问题是什么？正如你在[图2-1](#ch02_figure_1_1740182046144175)中可以看到的，监督学习是昂贵的、费力的、耗时的，因此只有大型机构才会进行这项工作，而且只为特定的任务。如果你想让AI总结和翻译文本，你需要标注两个非常大的数据集...手动（关于这一点稍后详述）。
- en: Around 2017, a new approach appeared that was powered by an architecture called
    *transformers* (we lightly detail these in [Chapter 9](ch09.html#ch09_generative_computing_a_new_style_of_computing_1740182052619664)).
    With this approach, AI could perform a new kind of frictionless learning called
    *self-supervised learning*, in which a language model could be trained on large
    amounts of unlabeled data by hiding certain sections of the text (words, sentences,
    etc.) and asking the model to fill in the blanks (the AI lingo for this is *masking*).
    For example, if we said, “May the force,” you’d likely guess that the next three
    words are “be with you” from *Star Wars*. Although an oversimplification, this
    amazing process, when done at scale, results in the powerful data representations
    that today we call LLMs.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 大约在2017年，一种新的方法出现了，它由一种称为*transformers*（我们在[第9章](ch09.html#ch09_generative_computing_a_new_style_of_computing_1740182052619664)中简要介绍了这些）的架构驱动。使用这种方法，AI可以执行一种新的无摩擦学习，称为*自监督学习*，在这种学习中，语言模型可以通过隐藏文本的某些部分（单词、句子等）并在模型中要求填补空白（AI术语为*掩码*）来在大量的未标注数据上训练。例如，如果我们说，“愿力量与你同在”，你可能会猜测接下来的三个词是“来自《星球大战》的‘与你同在’”。虽然这是一个过度简化的例子，但这个惊人的过程，当规模扩大时，产生了今天我们称之为LLMs的强大数据表示。
- en: '![A screen shot of a computer  Description automatically generated](assets/aivc_0201.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图  描述自动生成](assets/aivc_0201.png)'
- en: Figure 2-1\. Comparing the activation energy of getting started with supervised
    learning versus self-supervised learning
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-1\. 比较使用监督学习与自监督学习开始时的活化能
- en: This is where something truly magical happened. Researchers found that instead
    of building AI models that were only suited to narrow use cases and areas of expertise
    (for example, building and painstakingly curating one dataset for summarization
    and another for translation), they could have AI that was more broadly applicable.
    Basically, these LLMs could be trained on huge volumes of internet data (today’s
    most popular LLMs are really just highly compressed representations of everything
    on the internet—which is good and bad) and thus acquire a humanlike *set* of natural
    language capabilities.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是真正神奇的地方。研究人员发现，他们不必构建仅适用于狭窄用途案例和特定专业领域的AI模型（例如，为总结构建并精心制作一个数据集，为翻译构建另一个数据集），他们可以拥有更广泛适用的AI。基本上，这些LLM可以在大量互联网数据上训练（今天的最受欢迎的LLM实际上是互联网上所有内容的极高压缩表示——这既是好事也是坏事）并因此获得类似人类的*一套*自然语言能力。
- en: 'Self-supervision at scale, combined with massive data and compute, gave the
    world AI that is generalizable and adaptable. We define these terms as follows:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在规模化的自监督、海量数据和计算能力的结合下，世界迎来了可泛化和适应性的AI。我们如下定义这些术语：
- en: Generalizable
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 可泛化
- en: This means the AI has the ability to perform well across a wide range of tasks
    and domains, often with little to no task-specific tuning. In other words, the
    same LLM that classifies the sentiment of a text document can extract people and
    places from text—an action referred to as named-entity recognition (NER)—and can
    translate, summarize, and more.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着AI能够在广泛的任务和领域内表现出色，通常无需进行特定的任务调整。换句话说，同一个用于文本文档情感分类的LLM可以提取文本中的人物和地点——这一行为被称为命名实体识别（NER），并且可以进行翻译、总结等操作。
- en: Adaptable
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 适应性
- en: This means that the AI can not only do multiple tasks but can also handle different
    use cases it wasn’t originally trained for. AI that is adaptable is also *emergent*,
    meaning it has capabilities that it was not explicitly programmed to have and
    that arise unexpectedly; for example, an LLM can answer riddles or solve logic
    puzzles it has never been trained on simply by recognizing patterns. The bottom
    line is that being able to use the same model for multiple use cases and discovering
    new capabilities in them is a powerful tool (though you are still going to want
    to steer it to become an AI Value Creator; more on that in a bit).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着AI不仅能执行多项任务，还能处理它最初训练时并未针对的不同的用例。适应性AI也是*自发的*，这意味着它具有它未被明确编程的、意外出现的功能；例如，一个LLM可以通过识别模式来回答它从未训练过的谜语或解决逻辑谜题。底线是，能够使用相同的模型处理多个用例并在其中发现新的功能是一个强大的工具（尽管你仍然希望将其引导成为AI价值创造者；关于这一点，稍后还会详细介绍）。
- en: Over the last decade, there’s been an explosion of applications for AI. (Our
    bet is that you’ve used many of them, even without knowing it. Have you used Siri
    or Alexa? Have you changed a gray sky to a sunny sky to create a picture-perfect
    moment? Have you used a translation app?) In that time, we’ve seen AI go from
    being a purely academic endeavor to being a major force that powers actions across
    a myriad of industries and affects the lives of billions each day.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去十年中，AI的应用领域爆炸式增长。（我们打赌，你可能已经使用了许多这些应用，即使你并不知道。你使用过Siri或Alexa吗？你改变过灰蒙蒙的天空，使其变得晴朗，以创造一个完美的瞬间吗？你使用过翻译应用吗？）在这段时间里，我们看到AI从纯粹学术研究转变为一个主要力量，推动着众多行业的发展，并影响着每天数十亿人的生活。
- en: In recent years, we’ve managed to build AI systems that can learn from thousands
    or millions of examples to help us better understand our world and find new solutions
    to difficult problems. These large-scale models have led to the development of
    systems that can understand us when we talk or write. These include the natural
    language processing (NLP) and natural language understanding (NLU) programs we
    use every day, from digital assistants to speech-to-text programs. Other systems,
    which are trained on things like the entire bodies of work of famous artists or
    every chemistry textbook in existence, have allowed us to build generative models
    that can create new works of art based on those artists’ styles or new compound
    formulation and docking combinations based on the history of chemical research.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，我们已经能够构建能够从数千或数百万个示例中学习的AI系统，帮助我们更好地理解我们的世界，并找到解决难题的新方法。这些大规模模型导致了能够理解我们说话或写作的系统的发展。这包括我们每天使用的自然语言处理（NLP）和自然语言理解（NLU）程序，从数字助手到语音转文字程序。其他系统，经过著名艺术家全部作品的训练或现有所有化学教科书的训练，使我们能够构建基于那些艺术家风格的生成模型，或基于化学研究历史的新的化合物配方和对接组合。
- en: While today many new AI systems are helping to solve all sorts of real-world
    problems, before GenAI, creating and deploying an AI for each new system using
    traditional methods required a considerable amount of time and resources. For
    each new application, you had to ensure that there was a large, well-labeled dataset
    for the specific task you wanted to tackle. If a dataset didn’t exist for that
    task, you had people taking hundreds or thousands of hours (perhaps more) to find
    and label appropriate images, text, or graphs for the training and validation
    datasets.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如今许多新的AI系统正帮助解决各种现实世界的问题，但在GenAI出现之前，使用传统方法为每个新系统创建和部署AI需要相当多的时间和资源。对于每个新的应用，你必须确保有一个大型的、标签清晰的特定任务数据集。如果不存在该任务的数据集，你需要人们花费数百或数千小时（甚至更多）来寻找和标记适当的图像、文本或图表，用于训练和验证数据集。
- en: What does all this mean? You can take a large, pretrained LLM—if you’re using
    it for business, you’ll want to ensure you’re starting with a model that is trustworthy—and
    add *your* institutional knowledge to turbocharge the model to *excel at your
    specific use cases* with your specific data. (We get into the ills, wills, and
    thrills of this topic in [Chapter 8](ch08.html#ch08_using_your_data_as_a_differentiator_1740182052172518).)
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着什么？你可以使用一个大型预训练的LLM——如果你用它来商业用途，你将希望确保你从一个值得信赖的模型开始——并添加*你的*机构知识来加速模型，使其*在你的特定用例中表现出色*，使用你特定的数据。（我们将在[第8章](ch08.html#ch08_using_your_data_as_a_differentiator_1740182052172518)中深入探讨这个话题的弊端、意愿和兴奋之处。）
- en: Now, if you’re feeling a bit disheartened because you’re one of those businesses
    we talked about that spent enormous amounts of time collecting and labeling data
    for your AI projects, only to have them fail because you didn’t label enough data
    (that is how it went with traditional AI), fear not! That work is not throwaway
    in this GenAI world because that proprietary industry-specific data we just mentioned
    is what you’re going to use to tailor an LLM for your business needs. It’s what
    you need to do in order to become an AI Value Creator. In fact, you’re literally
    going to take those failed AI projects from two years ago and look like a hero
    when you bring forth to your bosses how you want to steer whatever LLM you land
    on for your business. How so? First, today’s LLMs don’t contain much enterprise
    data at all (about 1%), let alone your proprietary data. In [Chapter 1](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974),
    we told you how your data is a competitive advantage, and now it’s time to put
    that data to work.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你因为你是我们之前提到的那类企业之一，花费了大量时间收集和标记AI项目的数据，但最终因为数据标记不足而失败（这就是传统AI的情况），请不要气馁！在这个GenAI世界中，这项工作并不是无用的，因为刚才提到的专有行业特定数据正是你用来定制LLM以满足商业需求的数据。这是你成为AI价值创造者所需要做的。事实上，你将真正地利用两年前失败的AI项目，并在向老板展示你如何想引导你选择的任何LLM以适应你的业务时，成为一个英雄。如何做到这一点？首先，今天的LLM几乎不包含任何企业数据（大约1%），更不用说你的专有数据了。在[第1章](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974)中，我们告诉你你的数据是竞争优势，现在是时候让这些数据发挥作用了。
- en: 'Quite simply, when you bring together the data representations of an LLM and
    steer it with your labeled data (which now, you need much less of), you end up
    with something that is tailored to your business. Think of it this way: let’s
    assume you know Spanish, and today, you’re trying to learn French. On this journey,
    there is a lot of *foundational* knowledge you already have about how language
    works, like how to conjugate verbs. Just as it’s likely easier to learn French
    if you have Spanish as a foundation, as you’ll find out in [Chapter 8](ch08.html#ch08_using_your_data_as_a_differentiator_1740182052172518),
    there’s a new open source approach (called InstructLab) that makes it easier than
    ever to fold your data into your company’s private LLM and not share it with the
    world, and that’s bound to give some ooh la la to your final results.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，当你将LLM的数据表示与你的标记数据（现在，你需要的数据量要少得多）结合起来时，你最终得到的是针对你业务量身定制的东西。可以这样想：假设你懂西班牙语，今天你正在尝试学习法语。在这个过程中，你已经有大量的*基础*知识，比如如何变位动词。正如你将在[第8章](ch08.html#ch08_using_your_data_as_a_differentiator_1740182052172518)中发现的那样，有一种新的开源方法（称为InstructLab）使得将你的数据整合到公司的私有LLM中变得比以往任何时候都容易，而且这肯定会给你的最终结果带来一些惊喜。
- en: The current thinking is usually that you can apply LLMs (hence, their name)
    to language. But this should spark the question, what is a language? Signals in
    a piece of industrial equipment are talking to you, in their own language; there
    are programming languages, which consist of communication verbiage from humans
    to instruct machines; and there are the clicks of a user navigating a website,
    software code, chemistry, and diagrammatic representations of chemicals. We’ve
    even worked with a company using AI to model taste and smell. If you squint, *everything
    starts looking like a language*, and if it’s a language, it can be learned, deciphered,
    and understood.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 当前的观点通常是，你可以将LLM（因此得名）应用于语言。但这应该引发一个问题，什么是语言？工业设备中的信号正在用它们自己的语言与你交谈；有编程语言，这是人类用来指令机器的交流术语；还有用户在网站上导航时的点击，软件代码，化学，以及化学的图示表示。我们甚至与一家使用AI来模拟味觉和嗅觉的公司合作过。如果你眯起眼睛，*一切看起来都像是一种语言*，如果它是一种语言，那么它就可以被学习、解读和理解。
- en: The takeaway is that AI can be specialized to do all kinds of things that boost
    productivity in any language. That means that AI can stretch horizontally across
    your business to HR processes, customer service, self-service, cybersecurity,
    code writing, application modernization, and so many other things that we’ll share
    with you in [Chapter 4](ch04.html#ch04_the_use_case_chapter_1740182047877425).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 要点在于，AI可以被专门化以在任何语言中完成各种提高生产力的任务。这意味着AI可以横向扩展到你的业务中，应用于HR流程、客户服务、自助服务、网络安全、代码编写、应用现代化，以及我们将在[第4章](ch04.html#ch04_the_use_case_chapter_1740182047877425)中与你分享的许多其他事情。
- en: 'Going a Little Deeper: The Evolution of Large Language Models and Comparing
    Supervised Learning with Self-Supervised Learning'
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深入探讨：大型语言模型的演变以及比较监督学习与自监督学习
- en: Large language models aren’t built the same way as traditional AI. They are
    trained using self-supervised learning, which means you don’t have to manually
    annotate a massive amount of data. Basically, you train a model by telling it
    to go read enormous amounts of data (for example, text) and when it’s done you
    end up with a large but versatile model with more humanlike language capabilities.
    AI uses mathematical models to represent the relationships in the data (like words)
    it ingests. If you give the model a few words in a prompt, it can mathematically
    predict the likelihood of words coming up in the sequence of the *Star Wars* phrase
    we shared in the last section.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型并非与传统AI以相同方式构建。它们通过自监督学习进行训练，这意味着你不需要手动标注大量数据。基本上，你通过告诉模型去阅读大量数据（例如，文本）来训练模型，当它完成时，你最终得到一个大型且多功能的模型，具有更类似人类的语言能力。AI使用数学模型来表示它所摄入的数据（如单词）中的关系。如果你在提示中给模型几个单词，它可以通过数学预测在上一节中分享的*星球大战*短语序列中出现单词的可能性。
- en: Two of the biggest things that excite us about GenAI are just how fast you can
    now build these same use cases for all the reasons summarized in [Figure 2-1](#ch02_figure_1_1740182046144175)
    and the fact that these models (as we noted in the previous section) are generalizable
    and adaptable. The best way to appreciate how GenAI flattens the time-to-value
    curve for AI projects is to go beyond labeling data and contrast GenAI with the
    traditional way in which AI use cases were brought into production.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对通用人工智能最兴奋的两件事之一就是，你现在可以如此快速地构建这些相同的用例，原因如[图2-1](#ch02_figure_1_1740182046144175)中总结的那样，以及这些模型（正如我们在上一节中提到的）是可泛化和可适应的。要欣赏通用人工智能如何使人工智能项目的价值实现时间曲线变平，最好的方法就是超越数据标注，并将通用人工智能与传统方式进行比较，后者是将人工智能用例引入生产的方式。
- en: Many of you who have been around AI for a while may feel that you’re seeing
    many use cases from the traditional AI era repeat themselves in this new GenAI
    era—and you’re right. That said, we’d be remiss if we didn’t note that while the
    initial set of GenAI use cases might be repeating themselves, there are new ones,
    and agentic AI brings plenty more. In the last decade, with the advent of deep
    learning, the world demonstrated (as a community) that you could bring incredible
    accuracy to specific tasks if you gathered enough data, labeled that data, trained
    models, and deployed them. This traditional methodology is what you see in [Figure 2-2](#ch02_figure_2_1740182046144214).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 许多在人工智能领域已经有所涉猎的人可能会觉得，在这个新的通用人工智能（GenAI）时代，他们看到了许多来自传统人工智能时代的用例在重复出现——而且你们是对的。然而，如果我们不指出，尽管最初的通用人工智能用例可能正在重复，但仍然有新的用例出现，并且具有代理能力的AI带来了更多可能性。在过去十年中，随着深度学习的出现，世界（作为一个社区）证明了如果你收集足够的数据，对数据进行标注，训练模型，并部署它们，你就能为特定任务带来令人难以置信的准确性。这种传统的方法正如你在[图2-2](#ch02_figure_2_1740182046144214)中看到的那样。
- en: Notice in [Figure 2-2](#ch02_figure_2_1740182046144214) how each model is built
    for a specific AI use case. In this example, the use cases are summarization,
    tone analysis, and entity extraction. To build these models with the traditional
    approach to AI, your company would have created a separate team for each task,
    and each team would have built a separate model to anchor the task. All those
    teams would have gone through the same painstaking process of data selection and
    curation, labeling, model development, training, validation, and so on—perhaps
    even duplicating the same data!
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 注意在[图2-2](#ch02_figure_2_1740182046144214)中，每个模型都是为特定的AI用例而构建的。在这个例子中，用例包括摘要、语气分析和实体提取。要使用传统的AI方法构建这些模型，你的公司将为每个任务创建一个单独的团队，并且每个团队都会构建一个单独的模型来锚定该任务。所有这些团队都会经历相同的数据选择和整理、标注、模型开发、训练、验证等繁琐过程——甚至可能重复使用相同的数据！
- en: '![A diagram of a diagram  Description automatically generated](assets/aivc_0202.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![一个图表的图表  描述由自动生成](assets/aivc_0202.png)'
- en: Figure 2-2\. The traditional way to build AI, by assembling many data science
    teams and getting them to do as many projects as they can
  id: totrans-43
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-2. 通过组装许多数据科学团队并让他们尽可能多地完成项目来构建AI的传统方式
- en: 'Different teams collecting data, curating it for their own use case, and going
    through the same steps other teams go through can only be described as long, hard,
    tedious, and expensive. In fact, we’d humbly suggest that how much your company
    could scale AI was really the answer to the questions: how many data science teams
    could you assemble, and how many projects could those teams carry out?'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的团队收集数据，为各自的用例整理数据，并经历与其他团队相同的步骤，这只能被描述为漫长、艰难、繁琐且昂贵。事实上，我们谦逊地建议，你的公司能够扩展AI的规模，这实际上是对以下问题的回答：你能组建多少个数据科学团队，这些团队能够完成多少个项目？
- en: Now contrast the new approach to AI (on the left side of [Figure 2-3](#ch02_figure_3_1740182046144239))
    with the traditional path to AI (on the right side of the figure). As you can
    see, instead of needing to build one AI model for each specific task (as in [Figure 2-2](#ch02_figure_2_1740182046144214)),
    you take an LLM that is likely trained by someone else (like IBM, Google, DeepSeek,
    OpenAI, or Anthropic; truth be told, few companies will build their own—rather,
    they will steer existing ones) and adapt it to many varied downstream tasks. Also,
    notice how a single LLM fuels the three use cases in [Figure 2-3](#ch02_figure_3_1740182046144239).
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在将新的AI方法（[图2-3](#ch02_figure_3_1740182046144239)的左侧）与传统的AI路径（图右侧）进行对比。正如你所看到的，你不需要为每个特定任务构建一个AI模型（如图2-2所示），而是使用一个可能由其他人（如IBM、Google、DeepSeek、OpenAI或Anthropic；说实话，很少有公司会自己构建——相反，他们将引导现有的模型）训练的LLM，并将其适应许多不同的下游任务。此外，请注意，单个LLM如何为[图2-3](#ch02_figure_3_1740182046144239)中的三个用例提供动力。
- en: '![A diagram of a model  Description automatically generated](assets/aivc_0203.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![模型图  描述自动生成](assets/aivc_0203.png)'
- en: Figure 2-3\. GenAI scales AI, reducing skill requirements, data, time, administration,
    and up-front costs
  id: totrans-47
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-3\. 通用人工智能（GenAI）扩展人工智能，降低技能要求、数据、时间、管理和前期成本
- en: Given the versatility of an LLM, companies can now use the same model to implement
    multiple business use cases. They could never really do that using traditional
    AI.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大型语言模型（LLM）的通用性，公司现在可以使用相同的模型来实现多个商业用例。他们以前根本无法使用传统人工智能做到这一点。
- en: We really want you to spend some time committing [Figure 2-3](#ch02_figure_3_1740182046144239)
    to memory because it illustrates why LLMs are becoming essential ingredients of
    the new AI workflow. Modern AI takes a very focused effort to create a *base model*
    (meaning a general-purpose LLM) and getting economies of scale from that investment.
    Creating an LLM on your own is quite a sophisticated endeavor, which is why we’re
    confident that most of you will choose one to start with and then steer it with
    your data to match your business and use case (which we tell you how to do later
    in this book).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们真的希望你能花些时间记住[图2-3](#ch02_figure_3_1740182046144239)，因为它说明了为什么LLM正成为新人工智能工作流程的必要组成部分。现代人工智能需要非常专注的努力来创建一个*基础模型*（即通用型LLM），并从这种投资中获得规模经济。自己创建一个LLM是一项相当复杂的任务，这也是为什么我们相信你们大多数人会选择从使用一个开始，然后用你们的数据来调整它，以适应你们的业务和用例（我们将在本书的后面告诉你如何做）。
- en: We’re hoping you’ve gotten a good grasp of this methodology shift, because the
    next wave of AI looks to replace the task-specific models that have dominated
    the AI landscape to date with LLMs as their core. These models are trained on
    a broad set of data that can be used for different tasks, and what’s more, with
    their self-ideation to achieve defined goals, agentic AI will follow this path
    too.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望你已经很好地掌握了这种方法论上的转变，因为下一波人工智能的发展趋势是，用LLM作为核心来取代至今主导人工智能领域的特定任务模型。这些模型在广泛的数据集上训练，可用于不同的任务，更重要的是，通过自我构思来实现既定目标，具有代理能力的AI也将遵循这条路径。
- en: That’s the takeaway. What makes LLMs so versatile is that they, as their name
    suggests, can be the foundation of many AI and agentic applications. Using self-supervised
    learning and transfer learning, these AI models can apply information they have
    learned about in one situation to another situation.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是关键所在。LLM之所以如此通用，是因为正如其名称所暗示的，它们可以是许多AI和代理应用的基石。通过使用自监督学习和迁移学习，这些AI模型可以将他们在一种情况下学到的信息应用到另一种情况下。
- en: 'The easiest way to understand transfer learning is with a traditional computer
    vision example of AI being used to identify a cat. (Again, AI and cats seem to
    go hand-in-paw—it’s like some feline aficionado felt their deep learning needed
    some deep purring.) If you taught an AI how to identify a cat, that AI would start
    with shapes and edges and gradually build layers in its neural network to identify
    a cat. At its base levels, this AI would likely be able to detect triangles (combinations
    of edges). If you think about a cat, triangles form its ears and nose and other
    parts, and once the AI could find triangles, it could go on to discover other
    cat features as it used more and more layers in its neural network to ultimately
    define the object it sees as a cat. Now, imagine you wanted to identify a sailboat.
    An AI trained to identify sailboats would start at the same place: finding edges
    and shapes. So, you could take the levels of the AI that know what triangles look
    like and transfer it for boats, you could do the same thing for potentially thousands
    of layers—and now you understand transfer learning. Whether the AI was identifying
    a cat or a sailboat, that identification of a triangle would be critical.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 理解迁移学习最简单的方法是使用传统的计算机视觉示例，即AI被用来识别一只猫。（再次，AI和猫似乎总是形影不离——这就像某个猫爱好者觉得他们的深度学习需要一些深沉的喵喵声。）如果你教一个AI如何识别一只猫，那么这个AI将从形状和边缘开始，并在其神经网络中逐渐构建层来识别猫。在其基础层面，这个AI可能能够检测三角形（边缘的组合）。如果你想想猫，三角形构成了它的耳朵、鼻子和其他部分，一旦AI能够找到三角形，它就可以继续发现其他猫的特征，因为它在其神经网络中使用了越来越多的层，最终将看到的对象定义为猫。现在，想象一下你想要识别一艘帆船。一个被训练来识别帆船的AI将从相同的地方开始：寻找边缘和形状。所以，你可以将知道三角形外观的AI层转移到帆船上，你可以对可能成千上万的层做同样的事情——现在你理解了迁移学习。无论AI是在识别猫还是帆船，那个三角形的识别都是关键的。
- en: Most of us can relate to the versatility of LLMs supporting multiple use cases
    in our everyday lives. For example, once you’ve learned how to drive a car, you’ve
    got some serious skills you can transfer to drive other cars. Sure, there are
    some nuances to get used to (like where to find the windshield wiper controls),
    and you could even run into major issues (try driving with a manual transmission
    if you’ve only ever driven an automatic), but there are still a bunch of base
    skills that transfer. Today, no one builds a convolutional neural network (CNN)
    or uses a vision transformer (ViT) for computer vision without some sort of transfer
    learning—it’s like the ultimate computer vision cheat code!
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们中的大多数人都能体会到LLMs在日常生活中支持多个用例的灵活性。例如，一旦你学会了如何开车，你就获得了一些可以转移到驾驶其他汽车上的重要技能。当然，有一些细微差别需要适应（比如在哪里找到雨刮器控制），你甚至可能会遇到重大问题（如果你只开过自动挡，尝试开手动挡），但仍然有一系列基本技能可以转移。今天，没有人在进行计算机视觉时不用某种形式的迁移学习来构建卷积神经网络（CNN）或使用视觉转换器（ViT）——这就像是终极计算机视觉作弊码！
- en: 'The takeaway? It’s simple: instead of needing to build one AI model for each
    specific task, you can train one model and adapt it to many varied downstream
    tasks. This means that companies now have the opportunity to go from a modus operandi
    of *one task: one model* to *one model: many tasks*. For example, your IT support
    chatbot and your HR self-service initiatives can use the same base model as the
    new app that will write your marketing emails and summarize contract documents.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 带走的要点是什么？很简单：不再需要为每个特定任务构建一个AI模型，你可以训练一个模型并将其适应于许多不同的下游任务。这意味着公司现在有机会从“一个任务：一个模型”的模式转变为“一个模型：多个任务”的模式。例如，你的IT支持聊天机器人和你的人力资源自助服务项目可以使用与将为你撰写营销邮件和总结合同文档的新应用相同的基模型。
- en: As shown in [Figure 2-3](#ch02_figure_3_1740182046144239), there is still work
    to do! While the data engineering and labeling chores are now minuscule, you’re
    still going to want to use your data to steer the model toward your business domain
    and its brand, style, social norms, and so on. There are many ways to do this,
    using techniques such as prompt tuning, prompt engineering, fine-tuning with parameter-efficient
    fine-tuning (PEFT) methods, and InstructLab. You’ll learn more about this in [Chapter 8](ch08.html#ch08_using_your_data_as_a_differentiator_1740182052172518),
    but all the preparatory work you must do before you put your data to work has
    greatly decreased because of LLMs.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, the eye opener here shouldn’t be the power of a model with billions
    or even trillions of parameters. Hopefully, it’s jumping off the page at you,
    but if isn’t: the productivity associated with LLMs means that businesses can
    finally scale their AI initiatives with *less* time, *less* data, *less* up-front
    money, and *less* administration. For example, in IBM’s own experience, it took
    7 years to support 12 languages using AI the traditional way—but once it adopted
    GenAI, the languages it supported jumped to 25 in just a year.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: AI Value Creation Should Be Your Destination
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When oxygen, heat, and fuel combine, we get fire. It’s basic, it’s primal,
    and it’s the key that unlocked human progress. Think about it: fire provided light,
    heat, and protection, and our ancestors used it to move to new climates and eat
    new foods. Pottery, metallurgy, chemistry, rapid transportation, and many other
    technologies all started with fire.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: But imagine if fire had been proprietary? What if the knowledge of how to make
    fire hadn’t been shared, and what if there had been just a few keepers of the
    fire? Where would we be?
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember what we told you in the Preface: we’re in a lift, shift, rift, or
    cliff moment with GenAI, and especially with agents, it’s going to shape our society
    for generations to come. This section (and the rest of the book) is going to show
    you how to become your own AI fire starter, how to take control of your AI destiny,
    and why it’s so important to see yourself as an AI Value Creator and not just
    an AI User. Finally, we’ll detail why the future of AI needs an open innovation
    ecosystem.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: 'How Do You Consume AI: Be Ye a Value Creator or a Value User?'
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When it comes to using AI, there are three modes of consumption:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: It’s baked into the software.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You use someone else’s model.
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You use an AI platform.
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'AI User: Shake (embed) and bake (into the product) the AI'
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first way to consume AI is when it’s “baked into” off-the-shelf software.
    In this approach, a software vendor creates the AI, and you put it to use. (We’re
    going to assume you’re only working with real AI in products and not “fake and
    bake” AI, since everyone claims to have AI in their products these days.) Whether
    it’s a writing assistant (like Grammarly or Jasper) that can help you strike the
    right tone in your email, or image editing software (like Adobe Photoshop or Topaz
    Photo AI) that can automatically enhance the quality of your images and videos,
    with this consumption pattern, you, as an AI User, get access to some great functionality
    that can make you more productive. Who doesn’t want that?
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 消费 AI 的第一种方式是当它“嵌入”到现成的软件中。在这种方法中，软件供应商创建 AI，然后你将其投入使用。（我们将假设你只在与产品中的真实 AI 合作，而不是“虚假和烘焙”AI，因为现在每个人都说他们的产品中都有
    AI。）无论是写作助手（如 Grammarly 或 Jasper），它能帮助你电子邮件中找到正确的语气，还是图像编辑软件（如 Adobe Photoshop
    或 Topaz Photo AI），它能自动提升你的图像和视频质量，在这种消费模式中，作为 AI 用户，你可以获得一些非常棒的功能，这可以使你更有效率。谁不想这样呢？
- en: But there’s a caveat! *You and everyone else get access to this same “magic,”*
    which means that while this form of AI might help you do your work faster and
    with better results (that’s a good thing), *it can (and will) do the same for
    anyone else* who invests time in getting skilled up in that software. In other
    words, these AI capabilities and productivity opportunities don’t become differentiators—*but*
    they do set a new, higher baseline for everyone, including your competition.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 但是有一个注意事项！*你和每个人都可以访问这种“魔法”，*这意味着虽然这种形式的 AI 可能会帮助你更快、更好地完成工作（这是好事），*但它（将会）对任何投入时间提高在该软件中技能的人做同样的事情。换句话说，这些
    AI 能力和生产力机会并没有成为差异化因素——*但是*，它们确实为每个人设定了一个新的、更高的基准，包括你的竞争对手。
- en: 'AI User: Don’t fall when you make the service call (the even bigger *but*)'
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: AI 用户：当你发起服务调用时，不要掉链子（更大的*但是*）
- en: The second model of AI consumption is when you prompt someone else’s model,
    either directly in a chat interface or through an API call. Quite simply, as you
    develop custom AI apps for your business, these apps can call out to another company’s
    GenAI service, use that company’s models, and get results. This also is a viable
    way of consuming AI.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: AI 消费的第二种模式是当你直接在聊天界面或通过 API 调用提示他人的模型。简单来说，随着你为你的业务开发定制的 AI 应用程序，这些应用程序可以调用另一家公司的
    GenAI 服务，使用该公司的模型，并获得结果。这也是一种可行的 AI 消费方式。
- en: 'The truth is, just about every single one of us has been using GenAI this way,
    and that makes us all a bunch of AI Users. But think about being an AI User for
    a moment: you are mostly limited to simply prompting someone else’s AI model (not
    your model), you have no control over the model or the data used to train it,
    and you, in almost every case, have absolutely no idea what data was used to build
    it.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，我们几乎每个人都在以这种方式使用通用人工智能（GenAI），这使得我们所有人都是一群 AI 用户。但请暂时思考一下成为 AI 用户的感觉：你主要局限于简单地提示他人的
    AI 模型（而不是你的模型），你无法控制该模型或用于训练它的数据，而且在几乎所有情况下，你根本不知道用于构建它的数据是什么。
- en: Depending on how cleverly you use the model, you can *start* to differentiate
    how you put AI to work relative to your competitors. *But* there are still more
    caveats that you need to consider—*especially* if you’re trying to be an AI Value
    Creator.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你如何巧妙地使用模型，你可以*开始*区分你相对于竞争对手如何使用 AI。*但是*，还有更多需要注意的注意事项——*尤其是*如果你试图成为一个 AI
    价值创造者的话。
- en: The first consideration is that, like with our software example, those models
    and services you tap into are available to everyone, so are you really differentiated?
    Sure, perhaps you can prompt the same model better than someone else. *But* you’re
    still accessing the same model as everyone else.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个考虑因素是，就像我们的软件示例一样，你接入的那些模型和服务对每个人都是可用的，那么你真的有差异化吗？当然，也许你比其他人更能有效地提示同一个模型。*但是*，你仍然在访问与所有人相同的模型。
- en: There’s something else *you need to be even more concerned about* when your
    app makes that call and it goes off to work some magic—it’s connecting to something
    opaque (meaning you can’t see inside it). You don’t necessarily know what’s happening
    on the other end, what the AI model is doing with your data (learning from it,
    storing it, or just looking at it), or the provenance and governance of the data
    used to build the LLM the service is built on. Depending on the use case, this
    should make you somewhat nervous because your business is still accountable for
    the final outcomes (either socially or, more and more, by law—which we get into
    in [Chapter 5](ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635)).
    And if you’re talking about AI for business—as opposed to just personal use—we
    think that should make you nervous.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 当你的应用程序发出调用并开始施展魔法时，还有另一件事你需要更加关注——那就是它连接到了一个不透明的东西（意味着你无法看到里面）。你并不一定知道另一端发生了什么，AI模型正在如何处理你的数据（从中学习、存储或只是查看），以及构建服务所基于的LLM所使用数据的来源和治理。根据用例的不同，这可能会让你感到有些不安，因为你的业务仍然要对最终结果负责（无论是从社会角度还是越来越多地，从法律角度——我们将在第5章中讨论[Chapter 5](ch05.html#ch05_live_die_buy_or_try_much_will_be_decided_by_ai_1740182048942635)）。如果你谈论的是商业AI——而不是仅仅个人使用——我们认为这应该让你感到不安。
- en: 'We want to give you something to think about as a second word of caution whenever
    you use someone else’s proprietary AI: what of the creation and accrual of value
    over the long term? In the past, we’ve seen a lot of value-extractive business
    models—if you’re on social media, you’re a part of one. Quite simply, we always
    tell people if you’re not paying for it, make no mistake about it, you’re more
    than likely the product being sold. But even if you’re paying for the service,
    indeed, you’ll get value from that service (or you wouldn’t be paying for it).
    *But* that other company is likely extracting value from your usage and from your
    data, accumulating more and more over time. It’s not our intent to call any of
    these companies by name in this book, but there is a plethora of examples of companies
    (including paid services) that benefit from your strategic data. Ironically, this
    is the very method with which those LLMs were made (scraping data on the internet,
    be that data copyrighted or not).'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望在你使用他人的专有AI时，作为第二份警告，让你思考以下问题：长期来看，价值的创造和积累是什么？在过去，我们看到了许多价值提取型的商业模式——如果你在社交媒体上，你就是其中一员。简单来说，我们总是告诉人们，如果你没有为其付费，那么请不要误会，你很可能就是被出售的产品。但即使你为这项服务付费，的确，你将从这项服务中获得价值（否则你不会为其付费）。然而，那家公司很可能正在从你的使用和你的数据中提取价值，随着时间的推移，积累得越来越多。我们并不打算在这本书中点名任何这些公司，但有大量公司（包括付费服务）从你的战略数据中获益。讽刺的是，这正是那些LLM（大型语言模型）被制作的方法（从互联网上抓取数据，无论这些数据是否受版权保护）。
- en: 'This brings up yet another question we want you to think about: if you’re an
    AI User making a call to someone else’s AI service, how much faster is their value
    growing than yours? (Hint: check out the stock price and valuation multiples of
    some of these companies we’re not naming.) Quite simply, there’s likely an imbalance
    in the relationship, and *that can have long term consequences* for your specific
    business, the overall economy, and the progress of technology.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这引发了我们希望让你思考的另一个问题：如果你是使用他人AI服务的AI用户，他们的价值增长速度是否比你快得多？（提示：查看我们未命名的这些公司的一些股价和估值倍数。）简单来说，这种关系可能存在不平衡，这可能会对你的特定业务、整体经济和技术进步产生长期影响。
- en: 'A final *but*: Do we, as a society, really want to have just a few keepers
    of the AI “fire” upon which we are all dependent? Is that what’s best for your
    individual business and for your shareholders? We think no.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是：作为社会，我们真的希望只有少数人掌握我们所有人都依赖的AI“火种”吗？这对你的个人业务和股东来说是最好的吗？我们认为不是。
- en: 'Fire starter: Becoming an AI Value Creator'
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 火种：成为人工智能价值创造者
- en: 'The third model of AI consumption is the platform model, which is the most
    comprehensive. This is how you become your own AI fire starter, and when it comes
    to becoming an AI Value Creator, we want to be clear about something up front:
    it *does not mean* you’re doing it alone or reinventing AI from scratch. You’re
    not taking years and spending millions to build your own LLMs. Of course, you
    can do that with a platform, but that will be in a very small minority of cases.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能消费的第三种模式是平台模式，这是最全面的模式。这就是你如何成为自己的AI点火者，当谈到成为AI价值创造者时，我们一开始就要明确一点：这**并不代表**你是在独自一人做这件事或者从头开始重新发明AI。你不需要花费数年时间和数百万美元来构建自己的LLMs。当然，你可以通过平台来做这件事，但这种情况将非常罕见。
- en: With an AI value creation platform, you have all the elements and ingredients
    (data, governance, and LLMs) in place to build your own AI solutions. You have
    access to a vast number of GenAI models (both open source and proprietary), or
    you can bring your own models into the platform. You have tools to improve and
    customize models to fold in your proprietary knowledge of your business without
    concerns about sharing some of your most valuable assets (your data). You can
    fine-tune the models, prompt-tune them, tailor them with InstructLab—whatever
    techniques we detail in [Chapter 8](ch08.html#ch08_using_your_data_as_a_differentiator_1740182052172518)
    you want to use to build your own tailored AI solutions. At its core, the AI Value
    Creator approach allows you to create and accrue value that is unique to your
    business. A great example of an AI Value Creator is L’Oréal, one of the world’s
    leading beauty companies. Imagine the corpus of formulation, material science,
    and preference data L’Oréal has accumulated as it nears its 120th birthday. In
    essence, L’Oréal possesses data that defines the language of makeup. It wants
    to be an AI Value Creator, so it set out to create a private AI model (in collaboration
    with IBM) to accelerate tasks like the formulation of new products, reformulation
    of existing cosmetics, and optimizations to scale-up production. If L’Oréal was
    just an AI User, it would give this data away, but instead it views its data as
    a competitive advantage and decided to put it to work to better equip L’Oréal’s
    4,000 researchers worldwide over the next several years. We think L’Oréal isn’t
    just applying AI to beauty—it’s giving it a makeover of its own. With data as
    rich as its foundations and as bold as its lipsticks, who knew AI could have such
    a great eye for color matching?
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个AI价值创造平台上，你已经拥有了构建自己AI解决方案所需的所有元素和成分（数据、治理和LLMs）。你可以访问大量的GenAI模型（包括开源和专有模型），或者你可以将你自己的模型带入平台。你拥有工具来改进和定制模型，以便融入你业务中独有的知识，而无需担心分享你最有价值的资产（你的数据）。你可以微调模型，提示调整它们，使用InstructLab来定制它们——无论你想要使用我们在[第8章](ch08.html#ch08_using_your_data_as_a_differentiator_1740182052172518)中详细介绍的哪些技术来构建你自己的定制AI解决方案。在核心上，AI价值创造者的方法允许你创造和积累对你业务独特的价值。一个AI价值创造者的绝佳例子是L’Oréal，它是世界上领先的美容公司之一。想象一下，随着L’Oréal即将迎来120岁生日，它积累的配方、材料科学和偏好数据集。本质上，L’Oréal拥有定义化妆品语言的数据库。它希望成为一个AI价值创造者，因此它着手创建一个私有AI模型（与IBM合作），以加速新产品配方、现有化妆品的重新配方和生产规模优化的任务。如果L’Oréal只是一个AI用户，它会将这些数据拱手相让，但相反，它将其数据视为竞争优势，并决定在未来几年内更好地装备其全球4,000名研究人员。我们认为L’Oréal不仅仅是将AI应用于美容，它正在为其自身进行一次改造。拥有像其基础一样丰富的数据和像其口红一样大胆的数据，谁知道AI在色彩匹配上能有如此敏锐的洞察力？
- en: 'The path forward: How to create value with AI'
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 前进的道路：如何利用AI创造价值
- en: Ultimately, we believe that most businesses should end up with a mix of all
    three models of AI consumption. You’ll use third-party software with AI embedded,
    and *sometimes* it will be totally appropriate to use someone else’s AI User to
    do something you’re trying to do. For example, perhaps you are a real estate agent
    and want a quick description of a kitchen for a new listing based on photos you’ve
    been handed. Unless you have some kind of proprietary description magic, this
    is likely a situation in which you might want to use some of the more famous models
    you’ve heard about without concern. But what if you’re classifying sentiment on
    a purchase based on thousands of sentiments you’ve gotten from three decades of
    selling houses? To fully realize the value of AI and differentiate yourself from
    competitors, you’ll want to use a platform approach (just like L’Oréal) to create
    value by using your own AI tuned to your business, and you’ll want to add the
    other AI consumption patterns where appropriate. Let’s go a bit deeper into AI
    value creation, starting with LLMs.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们相信大多数企业应该最终采用三种AI消费模式的混合。你会使用嵌入AI的第三方软件，*有时*使用他人的AI用户来完成你想要做的事情是完全合适的。例如，也许你是一名房地产经纪人，想要根据你收到的照片快速描述一套新上市的厨房。除非你有一些专有的描述魔法，否则这可能是你想要使用一些你听说过的更著名模型而无需担忧的情况。但如果你是在基于从三十年销售房屋中获得的数千条情感进行情感分类呢？为了充分实现AI的价值并区别于竞争对手，你将想要采用平台方法（就像L’Oréal一样）通过使用适合你业务的自身AI来创造价值，并且你将想要在适当的地方添加其他AI消费模式。让我们更深入地探讨AI价值创造，从LLMs开始。
- en: 'Recall that LLMs are large-scale, deep neural networks trained with lots of
    data and subsequently adapted to many downstream tasks. They might be broad, general
    models or narrower, deeper models, but the key is that they’re pretrained with
    the *expectation that you can further enhance them with your own proprietary data
    if you’re looking to become an AI Value Creator*. It’s just like when a new employee
    joins your business: they come in with some general skills as a foundation and
    the ability to learn. The more they learn about your business, the more they add
    institutional knowledge and expertise, and the more value they deliver (and likewise,
    the more hurtful it might be if they went to a competitor). The same is basically
    true of LLMs. You use your AI platform to tune them with your specific business
    data, proprietary knowledge, and expertise—and then they become more like experts
    about your business and more valuable to your business over time. You don’t want
    that sales employee you trained with insights into your accounts to start working
    for someone else, and AI Value Creators feel the same way about their data!'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，LLMs是使用大量数据进行训练的大型深度神经网络，随后适应了许多下游任务。它们可能是广泛的通用模型或更窄、更深入的模型，但关键是它们是预训练的，*预期*如果你希望成为AI价值创造者，你可以使用自己的专有数据进一步改进它们。这就像一个新员工加入你的公司一样：他们带着一些作为基础的一般技能和学习的本领。他们了解你业务越多，他们就会增加更多的机构知识和专业知识，从而提供更多的价值（同样，如果他们去了竞争对手那里，可能会造成更大的伤害）。LLMs基本上也是这样。你使用你的AI平台用你特定的业务数据、专有知识和专业知识来调整它们，然后随着时间的推移，它们就会更像你的业务专家，对你的业务更有价值。你不想看到那个训练有洞察你账户的销售员工开始为别人工作，AI价值创造者对他们的数据也有同样的感觉！
- en: And because AI Value Creators are in control of the platform, processes, and
    data, they accrue ever larger amounts of value over time. With some of the consumer
    AI on the market, we’ve already seen some of what happens when you surrender that
    control. You can get bad data that leads to bad outcomes, as well as confabulations
    or hallucinations. You could also get into some trouble for inadvertently using
    someone else’s rights-managed content (that’s what all the copyright lawsuits
    going on are about), and we’ve even seen proprietary or sensitive data being inadvertently
    leaked back into public spaces. These are just some of the reasons why, when it
    comes to AI for business, you need to know how your LLM was built, what data was
    used to train it, and the recipe used to put it all together. And this is also
    why you should prioritize exercising tight control over your sensitive data. *Strong
    AI governance is absolutely critical*.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 由于AI价值创造者控制着平台、流程和数据，随着时间的推移，他们积累的价值会越来越大。在市场上的一些消费级人工智能产品中，我们已经看到了当你放弃控制权时会发生的一些情况。你可能会得到导致不良结果的不良数据，以及虚构或幻觉。你也可能因为无意中使用他人的版权管理内容（这正是所有正在进行的版权诉讼的原因）而陷入麻烦，我们甚至看到专有或敏感数据被意外泄露回公共空间。这些都是为什么在商业人工智能领域，你需要知道你的LLM是如何构建的，用于训练它的数据是什么，以及将所有这些组合在一起的配方。这也是为什么你应该优先考虑对敏感数据进行严格控制的理由。*强大的AI治理绝对至关重要*。
- en: Look before you leap
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 跳跃之前先看看
- en: Yes, now is the time to jump into AI, but look before you leap, and ensure that
    you’re investing in a smart, safe, and sustainable approach in which your business
    and customers are the primary beneficiaries. We think this approach starts with
    an AI Value Creator persona using a trusted platform and expands from there.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，现在是时候投身于人工智能领域了，但在跃入之前，请务必确保你在投资一个智能、安全且可持续的方法，这种方法让你的企业和客户成为主要受益者。我们认为这种方法从使用一个受信任的平台并创建一个AI价值创造者角色开始，然后从这里扩展出去。
- en: 'Planning Your AI Future: A Future with Many GenAI Models'
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 规划你的AI未来：一个拥有许多生成式AI模型的未来
- en: We think there is an AI myth out there right now, or at minimum, a basic misunderstanding.
    For the general public, GenAI has seemingly come out of nowhere. A lot of people
    think that there’s just a handful of consumer-oriented AI experiences out there
    and that one model is going to win (there will be “one model to rule them all,”
    in Tolkien-speak).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们认为现在有一个AI神话，或者至少是一个基本的误解。对于公众来说，生成式AI似乎突然出现。很多人认为市场上只有少数面向消费者的AI体验，并且认为一个模型将会获胜（在托尔金的话中，将是“一个模型统治一切”）。
- en: '*We don’t think that’s going to happen*. The future of AI is not about one
    model. It’s about many models (you’ll sometimes hear this referred to as *multimodel*),
    and it’s multimodal (can work on images, text, video, sound, and so on) too. Your
    business will be using multiple fine-tuned models to achieve the best results
    when you apply them to specific use cases. Some will be off-the-shelf, some will
    be steered with your data, some will be used to judge an AI’s output (they’re
    called *judge models*), some will be used as is to ensure safety, some will be
    used for tasks that require complex reasoning, and some will be used to power
    agents. That’s why the platform approach is so important—and it’s also why we
    introduced you to the Hugging Face community in [Chapter 1](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974).'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*我们认为这种情况不会发生*。人工智能的未来不在于一个模型，而在于许多模型（你有时会听到这被称为*多模型*），它也是多模态的（可以在图像、文本、视频、声音等上工作）。当你将它们应用于特定用例时，你的企业将使用多个微调后的模型以实现最佳结果。其中一些是现成的，一些会根据你的数据进行调整，一些会被用来评估人工智能的输出（它们被称为*评估模型*），一些会直接使用以确保安全性，一些会被用于需要复杂推理的任务，还有一些会被用来驱动代理。这就是为什么平台方法如此重要的原因——这也是为什么我们在第一章中向您介绍了Hugging
    Face社区[第1章](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974)。'
- en: And as we’ve insinuated (well, we’ve outright told you, but we’re just being
    polite)—*bet on community* because the future of AI is less about proprietary
    models and more about being powered by open science and open source. Proprietary
    models will surely play a part, but so much of what is going to happen in the
    future will *not* (and should not) happen behind closed doors. It needs to (and
    will) play out in plain view, with full transparency and accountability in open
    source.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们暗示的（好吧，我们直接告诉了你，但我们只是出于礼貌）——*押注社区*，因为人工智能的未来与其说是关于专有模型，不如说是由开放科学和开源驱动的。专有模型肯定会发挥作用，但未来将要发生的事情中的许多（而且不应该）是在封闭的门后发生的。它需要（并将）在明处展开，在开源中实现完全透明和问责。
- en: Again, the energy around GenAI and agents in the open source community right
    now is phenomenal. There are distributed projects, university projects, and corporate
    efforts—all driving innovation and producing LLMs that you can tune and deploy
    for your use cases.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，目前开源社区中围绕生成式人工智能和代理的能量是惊人的。有分布式项目、大学项目和公司努力，所有这些都推动创新并产生可用于您用例的LLM。
- en: Many people are saying, “Big tech AI is the problem.” *We disagree* (and not
    because we work for a big technology company). We’d rather you widened the aperture
    and said, “Proprietary and closed AI is a potentially serious problem.” That,
    we agree with. Why are we making this point? It’s because there are vendors big
    and small (we won’t mention them by name here...we’re not trying to pick a fight)
    that are closed and proprietary, and there are companies that are large (like
    IBM and Meta) and small (like Mistral AI and DeepSeek, among others) that are
    open.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 许多人说，“大科技公司的AI是问题。”*我们不同意*（并且不是因为我们在一家大科技公司工作）。我们更希望您扩大视野，说，“专有和封闭的AI可能是一个严重的问题。”这一点我们同意。我们为什么提出这个观点？是因为有大小不一的供应商（我们在这里不提他们的名字……我们不是想挑起争端），他们是封闭和专有的，还有像IBM和Meta这样的大公司以及像Mistral
    AI和DeepSeek等小公司是开放的。
- en: For the good of society in the long term, we don’t want just one or a few winners—a
    few companies that can define what AI is and dictate how it’s used. From what
    we can see, we don’t think that’s going to happen—and that’s a good thing for
    you, your business, and society in general.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 从长远来看，为了社会的利益，我们不想只有一个或少数几个赢家——一些可以定义人工智能是什么并规定其如何被使用的公司。从我们能看到的来看，我们认为这种情况不会发生——这对您、您的业务以及社会来说都是一件好事。
- en: It’s Time to Demystify and Apply AI
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 是时候揭开人工智能的神秘面纱并应用它了
- en: As sure as it’s been said that data is the “new oil,” many have dubbed AI the
    world’s “new electricity.” In addition to GenAI making today’s AI ubiquitous and
    increasingly accessible (thanks to the prompt), AI can (and *will*, if done right)
    enhance and alter the way business is conducted around the world. Today, AI can
    be used to enable predictions with supreme accuracy, and automate business processes
    and decision making. The impact is vast, ranging from frictionless customer experiences
    to intelligent products to more efficient services. In the end, the result will
    be economic impact for companies, countries, and societies.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 正如人们常说的，数据是“新石油”，许多人将人工智能称为世界的“新电力”。除了生成式人工智能使今天的AI无处不在并越来越易于获取（多亏了提示词）之外，人工智能（如果做得正确）还可以增强和改变全球的商业运作方式。今天，人工智能可以用于实现最高准确度的预测，并自动化业务流程和决策。其影响巨大，从无缝的客户体验到智能产品再到更高效的服务。最终，结果将为公司、国家和社会带来经济影响。
- en: 'To be sure, organizations that drive mass experimentation in AI will win the
    next decade of market opportunity. To break down and help demystify AI, you need
    to consider two key elements of the category: *the componentry* and *the process*.
    In other words, you need to identify what’s behind it and how it can be adopted.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，推动人工智能大规模实验的组织将在下一个十年的市场机遇中获胜。为了打破并帮助揭开人工智能的神秘面纱，您需要考虑该类别的两个关键要素：*组件*和*过程*。换句话说，您需要确定其背后的内容以及如何采用它。
- en: The componentry
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 组件
- en: Much like how the development of the use of electricity was driven by basic
    components such as resistors, capacitors, diodes, and so on, the development of
    AI is being driven by modern software componentry that includes the components
    outlined in this section.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 正如电力的使用发展是由基本组件如电阻器、电容器、二极管等推动的，人工智能的发展正受到现代软件组件的推动，这些组件在本节中已概述。
- en: A unified, modern data fabric with an accompanying data-as-a-product point of
    view
  id: totrans-99
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 具有数据即产品观点的统一、现代数据架构
- en: 'You’ve heard us already say it several times in this book: your AI needs an
    IA. Why? Because AI feeds on data, and therefore, your data must be prepared for
    AI. (This is why it’s first on our list.) This goes beyond garbage in, garbage
    out (GIGO), although that’s even more of an issue with AI since all AI does is
    find those numerical patterns we alluded to in [Chapter 1](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974).
    This will be a problem unless you think everything on the internet is real, there’s
    no fake news, and there isn’t hate, abuse, or profanity that goes on there. In
    other words, this is a problem.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经在我们这本书中多次听到过：你的AI需要IA。为什么？因为AI依赖于数据，因此，你的数据必须为AI做好准备。（这就是为什么它在我们列表的第一位。）这不仅仅是一个垃圾进，垃圾出的（GIGO）问题，尽管由于AI所做的只是找到我们在[第1章](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974)中提到的那些数值模式，这个问题在AI中更为严重。除非你认为互联网上的一切都是真实的，没有假新闻，也没有仇恨、滥用或亵渎，否则这将是一个问题。换句话说，这是一个问题。
- en: 'A *data fabric* (when done right) covers all enterprise data with governed
    searchability and connectivity. It removes the complexity of connecting to data
    and understanding the details of the underlying technology using data intelligence.
    You’ll often hear us shout out, “Cloud is a capability, not a destination!” (Hybrid
    cloud is an approach pretty much settled on by all businesses.) In the same way,
    you use a data fabric to apply a parallel best thought process to your IA: the
    “data isn’t just in one place” mindset, which has benefits that are applicable
    everywhere.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 一个*数据编织*（如果做得正确）覆盖了所有企业数据，具有受控的搜索性和连接性。它通过数据智能消除了连接数据和理解底层技术细节的复杂性。你经常会听到我们大声疾呼：“云是一种能力，而不是一个目的地！”（混合云是几乎所有企业都基本确定的方法。）同样，你使用数据编织将并行最佳思维过程应用于你的IA：即“数据并不只在一个地方”的思维模式，这种模式的好处适用于任何地方。
- en: A data fabric acts as a logical representation of all data assets on any cloud
    (public, private, or on premises). It auto-organizes and auto-labels data across
    an enterprise (and outside the enterprise, if needed), no matter where it resides.
    It empowers shipping function to data, as opposed to data to function, and this
    optimizes compute cycles. In plain speak, that means it takes the operations you
    want to apply to data and sends them to where the data is, as opposed to getting
    all the data and pulling it into a single place to do the computations. In this
    big-data world, you can imagine how the latter won’t scale.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 数据编织作为任何云（公共、私有或本地）上所有数据资产的逻辑表示。它自动组织并自动标记企业内部（以及如果需要，企业外部）的数据，无论数据位于何处。它赋予数据流向运输功能的权力，而不是功能流向数据，从而优化计算周期。简单来说，这意味着它将你想要应用于数据的操作发送到数据所在的地方，而不是将所有数据拉到一个单一的地方进行计算。在这个大数据世界中，你可以想象后者不会扩展。
- en: Perhaps most importantly, it provides a company’s employees with governed and
    seamless access to all available data through virtualization, from the firewall
    to the edge. When you think about data fabric, think *self-service*, *ease of
    access*,and *data protection.*
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 也许最重要的是，它通过虚拟化，为公司员工提供对所有可用数据的受控和无缝访问，从防火墙到边缘。当你想到数据编织时，要想到*自助服务*、*易于访问*和*数据保护*。
- en: Ultimately, a data fabric transforms data utilization into a process of knitting
    together data across your business—and externally, if appropriate.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，数据编织将数据利用转化为在整个业务中——如果适用的话，外部——编织数据的过程。
- en: A great IA strategy includes more than the things we just mentioned, but they
    are the levers to pull—and from there, tasks like collecting data, organizing
    it, governing it, infusing it into existing AI (and non-AI) business processes,
    and more all fall into place.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一个优秀的IA策略不仅仅包括我们刚才提到的那些内容，但它们是我们可以拉动的杠杆——从那里开始，收集数据、组织数据、管理数据、将其融入现有的AI（和非AI）业务流程等任务都会井然有序地展开。
- en: A development environment and an engine
  id: totrans-106
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 开发环境和引擎
- en: A business needs a place to build, upskill, train, and run its AI models. Ideally,
    the componentry is integrated with your strategic decisions for data persistence
    (like a data lakehouse) and a governance framework—and it’s all integrated with
    shared metadata across the ecosystem. This approach also helps organizations come
    together on a common mission, language, and design process—from input to output.
    By the time you have both components in hand, your company’s data strategy will
    start to feel like magic. And while we’ve dismissed the magic myth, turbocharging
    a plan and having momentum at your back *will* feel amazing.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一家公司需要一个地方来构建、提升技能、培训和运行其AI模型。理想情况下，组件应与您的数据持久性战略（如数据湖屋）和治理框架集成，并且所有这些都与生态系统中的共享元数据集成。这种方法还有助于组织在共同的任务、语言和设计过程中团结起来——从输入到输出。当你手头有了这两个组件时，你公司的数据战略将开始感觉像魔法。虽然我们已经摒弃了魔法神话，但加速一个计划并拥有后盾的势头*确实*会感觉非常棒。
- en: The modality of human features
  id: totrans-108
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 人类特征的模式
- en: A mechanism for bringing AI models “to life” involves connecting those models
    and applications to human features like voice, language, vision, and reasoning.
    GenAI, and especially agents, is included in a lot of frictionless customer experience
    discussions that typically land on the topic of chatbots. But the term *chatbot*
    often invokes visions of typing—and while that is one modality, a natural-sounding
    voice behind an interactive voice response (IVR) is a bot, too. We’ve all interacted
    with IVRs that don’t sound human at all, but with AI, you can bring real human
    sound *and* expression to theexperience. For example, try uploading something
    into Google’s NotebookLM and asking it to generate a podcast for you—impressive
    stuff! Using AI helps turbocharge IVRs with expressive voices that let you welcome
    your customers with humanlike speech, emotions, word emphasis, and interjections.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 使AI模型“活起来”的机制涉及将这些模型和应用程序连接到人类特征，如声音、语言、视觉和推理。生成式AI，尤其是代理，在许多无缝客户体验讨论中被提及，通常聚焦于聊天机器人这个话题。但“聊天机器人”这个术语往往让人联想到打字——虽然这是一种模式，但一个自然声音的交互式语音响应（IVR）也是一个机器人。我们都与听起来完全不像是人类的IVR互动过，但有了AI，你可以将真实的人类声音*和*表情带到体验中。例如，尝试将一些内容上传到谷歌的NotebookLM，并让它为你生成播客——令人印象深刻！使用AI可以帮助加速IVR，使其具有表达性的声音，让你能用类似人类的语言、情感、词语强调和插话来欢迎你的客户。
- en: Note
  id: totrans-110
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 备注
- en: 'While we cover agentic AI in this book, we don’t specifically cover the impact
    of agents on the modality of interaction, specifically the user experience (UX).
    The designs of tomorrow will have to consider two kinds of users: humans and agents.
    The agent experience (AX) will be using APIs to compose workflows *but* now includes
    desktop interactions.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们在本书中涵盖了代理AI，但我们没有具体涵盖代理对交互模式的影响，特别是用户体验（UX）。未来的设计将不得不考虑两种用户：人类和代理。代理体验（AX）将使用API来构建工作流程*但*现在还包括桌面交互。
- en: This capability is important because whether we realize it or not, as humans,
    we convey emotions in the words we speak. We may sound empathetic when apologizing
    to one another, uncertain when we don’t know the answer to something, and cheerful
    when we convey good news. This ability to convey emotion is what makes our voices
    human, and using AI to do this can ultimately reduce customer frustration when
    dealing with today’s phone experiences.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这种能力很重要，因为无论我们是否意识到，作为人类，我们在说话时都会传达情感。当我们向对方道歉时，可能会显得有同理心；当我们不知道某个问题的答案时，可能会显得不确定；当我们传达好消息时，可能会显得愉快。这种传达情感的能力使得我们的声音具有人性，而使用AI来完成这项工作最终可以减少在处理当今电话体验时客户的挫败感。
- en: 'But here’s the big point we want you to understand (and why upskilling is such
    a hot topic): customized brand voices (even yours) can be generated in minutes,
    with no technical expertise required! Quite simply, expressive voices make customers
    feel like they are talking to a real human and not a robot, but your company will
    get the benefits of shifting left (deflecting) those costs from a live agent (who
    costs about $5 per interaction) to an AI-assisted agent (which costs about $0.25
    per interaction) for “the easy stuff.” This is such a great example of those problems
    we walk by every day that we can solve or make better with technology. If you
    own a support channel with an IVR and have no idea how easy it is to build out
    human-sounding natural interactions, you’re settling for a maze of “Press 1 to...,”
    where instead of finding the prize at the end, your clients find themselves yelling
    “Talk to someone!” into the void.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 但这里有一个我们希望您理解的重要观点（以及为什么提升技能是一个热门话题）：定制的品牌声音（甚至包括您的声音）可以在几分钟内生成，无需任何技术专长！简单来说，富有表现力的声音能让客户感觉他们是在与真人交谈，而不是机器人，但您的公司将从将成本从现场客服（每次互动成本约为5美元）转移到AI辅助客服（每次互动成本约为0.25美元）来处理“简单的事情”中获益。这是一个很好的例子，说明了我们每天都能通过技术解决或改进的问题。如果您拥有一个带有IVR的客服渠道，却不知道构建听起来像真人的人工交互有多么容易，那么您只是在满足于一个“按1键...”的迷宫，而不是在迷宫的尽头找到奖品，您的客户却在空旷的地方大喊“和人说话！”
- en: This really leads to multimodal AI, where human features become more and more
    apparent in the AI. For example, Google’s Gemini, Apple’s FERRET, Meta’s Llama,
    DeepSeek’s Janus-Pro, IBM’s Granite, and various OpenAI models all allow you to
    include a picture in a prompt, and they’ll tell you what they see. Imagine that
    you’ve been sent a picture of a package at your door from a delivery service,
    and it came with an AI-generated description that might notify you, “The corner
    of this box is damaged.” Also imagine that same package came with a prefilled
    form to submit ifthe package’s contents are damaged once you get home and open
    it. If you open your package and all is fine, great, nothing to do. And if something
    is wrong with the shipped item, the return will be as frictionless as possible—this
    is agentic AI at work! We really want you to put yourself in the picture in this
    example. While it’s true no one wants something to go wrong (like getting shipped
    a damaged item, receiving the wrong item, or having to reset a password), the
    *bigger basic truth* is that when things do go wrong, you shouldn’t present your
    customers with friction (like transferring them three times, asking them to reauthenticate
    their identity, and all the stuff that could be summarized as the WTF moments
    we seem to live weekly these days). Ironically, studies show that truly good customer
    experiences are *not just* about a business getting it right. In fact, as a business,
    you’re probably allowed to get stuff wrong (depending on the use case—if your
    business is heart surgery and you get it wrong, then there may not be a customer
    to complain, but we’re sure some lawyers will). But keeping things frictionless
    is critical, and it buys your company customer patience, understanding, loyalty,
    and more when things don’t go as planned.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这实际上导致了多模态AI的发展，其中人类特征在AI中变得越来越明显。例如，谷歌的Gemini、苹果的FERRET、Meta的Llama、DeepSeek的Janus-Pro、IBM的Granite以及各种OpenAI模型都允许您在提示中包含一张图片，并且它们会告诉您它们看到了什么。想象一下，您收到了快递服务发来的一张您门口包裹的图片，并附有AI生成的描述，可能会通知您，“这个盒子的角落损坏了。”也想象一下，同样的包裹附有一份预先填好的表格，如果您在回家打开包裹后发现货物损坏，可以提交此表格。如果您打开包裹一切正常，那就太好了，无需做什么。如果运来的物品有问题，退货将尽可能无摩擦——这就是代理AI在发挥作用！我们真的希望您在这个例子中把自己放在图片中。虽然没有人希望出现问题（比如收到损坏的货物、收到错误的物品或需要重置密码），但*更大的基本真理*是，当事情出错时，您不应该向客户展示摩擦（比如让他们转三次，要求他们重新验证身份，以及所有可以总结为我们似乎每周都在经历的WTF时刻的东西）。讽刺的是，研究表明，真正好的客户体验并不仅仅是关于企业做对事情。事实上，作为一个企业，您可能允许出错（取决于用例——如果您的业务是心脏外科手术，您做错了，可能没有客户来投诉，但我们确信会有一些律师）。但保持无摩擦至关重要，当事情不按计划进行时，这会给您的公司带来客户的耐心、理解、忠诚度以及更多。
- en: AI management and exploitation
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: AI管理和利用
- en: This enables you to confidently insert AI into any application or business process,
    but to do that, you need to understand how the model was built, what data was
    used, how to improve a model’s impact, what has changed, drift, bias, and variance.
    This is where your models live for exploitation and enable lifecycle management
    of all AI. Lastly, this component offers proof of and explainability for decisions
    made by your AI.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这使你能够自信地将AI插入任何应用程序或业务流程，但要做到这一点，你需要了解模型是如何构建的，使用了哪些数据，如何提高模型的影响，什么发生了变化，漂移、偏差和方差。这就是你的模型用于利用和实现所有AI的生命周期管理的地方。最后，这个组件为你的AI做出的决策提供了证明和可解释性。
- en: 'Think of it this way: if we were to tell you the amount of data generated every
    minute in the world, that number would be out of date the moment we saved the
    first draft of this chapter. Every time we updated this chapter, it would be instantly
    out of date. Your models are not much different, and this is referred to as *drift*.
    You need to know that AI models can start to drift the moment they go into production.
    And if your data history (the data you used to train the model) doesn’t “rhyme”
    with the data of today, that model is really going to drift away from what it
    was intended to do (like pick an opportunity) and/or start to do bad things (like
    pick up bias).'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这样想吧：如果我们告诉你每分钟全世界产生多少数据，那么当我们保存本章的第一稿时，这个数字就已经过时了。每次我们更新本章，它就会立即过时。你的模型也差不多，这被称为*漂移*。你需要知道，AI模型一旦投入生产，就可能开始漂移。如果你的数据历史（你用来训练模型的数据）与今天的数据不一致，那么这个模型实际上会偏离它原本要做的（比如选择一个机会）以及/或者开始做坏事（比如选择偏见）。
- en: Agents and assistants for the masses
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 为大众提供代理和助手
- en: 'As you work AI into your business’s nervous system, classify the AI, and attach
    it to workflows (this is +AI), you should know that agents and assistants *really*
    help you deliver serious benefits to the business. We think agents and assistants
    are where you can really democratize AI in your company (in many cases, you will
    see them integrated). Yes, it’s important to have an AI platform that lets you
    collect, organize, and store data, build GenAI models, and govern them. Super
    important. But assistants and agents are the chassis to use the power of your
    models to lift the enterprise. For example, development teams can use Microsoft
    Copilot or a flavor of IBM’s watsonx Code Assistant to power up their development
    process. Perhaps you’re designing a frictionless experience for customers using
    watsonx Assistant or Kore.ai, or perhaps you’re even orchestrating workflows using
    Aisera or watsonx Orchestrate with its library of AI agents. All of these are
    examples of real AI boosting the productivity of people in your business. We think
    that’s a critical piece of any successful AI strategy because it gives detailed
    answers to the questions: who is going to use the AI and how is it going to help
    them? Depending on your job, you’d be well served to know the answers to these
    questions—or know to ask them.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 当你将人工智能融入你企业的神经系统，对AI进行分类，并将其附加到工作流程中（这就是+AI），你应该知道代理和助手真的可以帮助你为业务带来重大利益。我们认为代理和助手是你在公司真正实现人工智能民主化的地方（在许多情况下，你会看到它们被集成）。是的，拥有一个能够让你收集、组织、存储数据，构建生成式AI模型，并对其进行管理的AI平台非常重要。超级重要。但助手和代理是利用你模型的力量提升企业的底盘。例如，开发团队可以使用Microsoft
    Copilot或IBM的watsonx Code Assistant的某个版本来提升他们的开发过程。也许你正在使用watsonx Assistant或Kore.ai为客户设计无摩擦的体验，或者也许你甚至正在使用Aisera或watsonx
    Orchestrate及其AI代理库来编排工作流程。所有这些都是真实AI提升你企业中人们生产力的例子。我们认为，这是任何成功AI策略的关键部分，因为它为以下问题提供了详细的答案：谁将使用AI以及它将如何帮助他们？根据你的工作，了解这些问题的答案——或者知道如何提出这些问题——将大有裨益。
- en: 'The process: Cake ingredients without a recipe do not make a cake'
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 流程：没有食谱的蛋糕原料做不出蛋糕
- en: With these components in hand, more organizations will be able to unlock the
    value that lies within their data. But to fully leverage AI, you must also understand
    how to adopt and implement this technology. Here’s some quick advice on some fundamental
    steps to put AI for business to work (again, you’ll get more details as you read
    this book).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有这些组件，更多的组织将能够释放他们数据中的价值。但为了充分利用AI，你还必须了解如何采用和实施这项技术。以下是一些关于将AI用于商业的基本步骤的快速建议（随着你阅读这本书，你将获得更多细节）。
- en: 'Step 1: Identify the right business opportunities for AI'
  id: totrans-122
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 第1步：确定AI合适的商业机会
- en: 'The potential areas for adoption are vast: customer service, employee and company
    productivity, manufacturing defects, supply chain spending, and many more. Anything
    that can be easily described can be programmed, and once it’s programmed, AI will
    make it better. As you learned in [Chapter 1](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974)
    (and it will really come at you in [Chapter 4](ch04.html#ch04_the_use_case_chapter_1740182047877425)),
    the opportunities are endless, *but* it’s important that you make all your efforts
    about business opportunities and outcomes, and *not* data science projects. During
    the Hadoop big-data frenzy, we saw too many clients invest massive amounts of
    budget and time into projects that didn’t deliver value to the business or weren’t
    consumable by the business. This is why GenAI is so different: it makes building
    use cases faster than ever before, and it’s consumable by the masses. Just remember,
    choose wisely.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在的应用领域非常广泛：客户服务、员工和公司生产力、制造缺陷、供应链支出等等。任何可以轻松描述的事物都可以编程，一旦编程完成，人工智能就会使其变得更好。正如你在[第1章](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974)（它将在[第4章](ch04.html#ch04_the_use_case_chapter_1740182047877425)中真正向你展示）中学到的，机会是无限的，*但是*重要的是你要把所有的努力都集中在商业机会和结果上，而不是数据科学项目上。在大数据狂热时期，我们看到了太多的客户将大量的预算和时间投入到对业务没有价值或业务无法消费的项目中。这就是为什么生成式AI如此不同：它使构建用例的速度比以往任何时候都要快，而且它可以为大众所接受。记住，要明智地选择。
- en: 'Step 2: Prepare the organization for AI'
  id: totrans-124
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 第2步：为AI准备组织
- en: Organizations will require greater capacity and expertise in many areas, from
    having the obvious data science teams all the way to having a broadened aperture
    on just what GenAI can do for your business (to avoid that whole “walking by problems
    every day that can be solved or made better with the technology” thing we keep
    talking about in this book).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 组织将在许多领域需要更大的能力和专业知识，从显而易见的数据科学团队到对生成式AI能为你的业务做什么有一个更广阔的视野（以避免我们在这本书中不断谈论的“每天走过可以解决或通过技术改进的问题”这种情况）。
- en: 'You’re going to need to do a massive upskilling around GenAI, LLMs, and agents.
    This effort isn’t about pop-quizzing your marketing copy editor on what least
    absolute shrinkage and selection operator (Lasso) regression is or what AUC stands
    for (area under the receiver operating characteristic [ROC] curve) and so on.
    Having a general base knowledge of the benefits and cautions around AI will be
    critical to getting AI to work for your company. We can’t stress this piece enough:
    you must have a plan to upskill all employees to distribute the benefits of AI
    across your company; and that’s why we dedicated a whole chapter to it—[Chapter 6](ch06.html#ch06_skills_that_thrill_1740182050334297).'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 你将需要对生成式AI、大型语言模型和智能代理进行大规模的技能提升。这项工作并不是关于对市场营销文案编辑进行关于最小绝对收缩和选择算子（Lasso）回归是什么或者AUC代表什么（接收者操作特征[ROC]曲线下的面积）等等的即兴提问。对人工智能的益处和注意事项有一般性的基础知识对于让AI为你的公司工作至关重要。我们无法强调这一点：你必须有一个计划来提升所有员工的技能，以便将AI的好处分布到整个公司；这就是为什么我们专门用了一整章来讲述它——[第6章](ch06.html#ch06_skills_that_thrill_1740182050334297)。
- en: Why is this so important? Many of today’s repetitive and manual tasks will be
    automated (shifted left), which will evolve the role of many employees. *It’s
    rare that an entire role can be done by AI, and it’s also rare that no roles could
    be enhanced by AI.* All technology is useless without the talent to put it to
    use, so you must build a team of experts who will inspire and train others—but
    you must ensure that other employees’ skills are constantly evolving. After all,
    while technology years are typically akin to dog years (1 dog year equals 7 human
    years), GenAI and agents are progressing like mouse years (1 mouse year equals
    30 human years)—you need a plan to keep up.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这为什么如此重要呢？今天许多重复性和手动任务将被自动化（左移），这将改变许多员工的角色。*很少有整个角色可以由AI完成，也很少有角色不能通过AI得到增强.*
    没有人才来使用技术，所有技术都是无用的，所以你必须组建一个专家团队来激励和培训他人——但你必须确保其他员工的技能不断进步。毕竟，虽然技术年通常相当于狗年（1狗年等于7人类年），生成式AI和智能代理的进步速度就像鼠年（1鼠年等于30人类年）——你需要一个计划来跟上。
- en: 'Step 3: Select technology and partners'
  id: totrans-128
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 第3步：选择技术和合作伙伴
- en: While it’s unlikely a CEO would personally select a company’s GenAI technology
    stack (or stacks), the implication here is more of a cultural one. An organization
    should adopt many technologies and compare, contrast, and learn through that process.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然CEO个人选择公司的GenAI技术栈（或多个技术栈）的可能性不大，但这里的含义更多的是文化上的。一个组织应该采用许多技术，并通过这个过程进行比较、对比和学习。
- en: 'We’ll give you a good tip that will save you a lot of pain: don’t fall into
    the common trap of thinking the cloud will be one place from one provider. Looking
    in the rearview mirror, it’s easy to see how that notion has been proven wrong.
    Now, we’re not saying you should have hundreds of AI vendors in your shop (they
    are popping up everywhere), but we are reminding you here that one AI model will
    not rule them all. Organizations should choose a handful of *trustworthy* partners
    that have both the skills and the technology to deliver AI. Also, we’ve italicized
    *trustworthy* here for a reason. We don’t need to get into the details here, but
    especially in tech, you’re likely familiar with good actors (upstanders) and bad
    actors (which are at best bystanders and at worst well-known malefactors). Again,
    we think trust will be the ultimate operating license, and we’ll let you think
    about who you trust from here.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 我们会给你一个很好的建议，这能让你省去很多痛苦：不要陷入一个常见的陷阱，认为云将是一个来自一个提供商的地方。从后视镜看去，很容易看出这个观点已经被证明是错误的。现在，我们不是说你应该在你的店里拥有成百上千的AI供应商（他们无处不在），但我们在这里提醒你，一个AI模型不会统治所有。组织应该选择一些*值得信赖*的合作伙伴，他们既有技能也有技术来提供AI。此外，我们在这里强调*值得信赖*的原因。我们不需要深入细节，但特别是在技术领域，你很可能熟悉好的演员（站起来的人）和坏的演员（最好的情况下是旁观者，最坏的情况下是众所周知的恶棍）。再次强调，我们认为信任将是最终的运营许可，我们将让你从这里开始思考你信任谁。
- en: 'At the end of the day, we think most success comes from partnerships—be they
    personal or professional. Think about it: Batman partnered with Robin, Bert had
    Ernie, Sherlock was nothing without Watson, and even Snooki had The Situation.
    (That last bit is for anyone who still speaks the *Jersey Shore* parlance—we’re
    hoping there aren’t many of you left, and we’re even happier if you have no idea
    what we’re talking about.)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们认为大多数成功都来自合作——无论是个人还是职业上的。想想看：蝙蝠侠与罗宾结盟，伯特有厄尼，福尔摩斯没有华生就一事无成，甚至斯努基也有她的“情况”。（最后一点是给那些仍然使用“海滩救护队”俚语的人——我们希望你们中剩下的人不多，如果你根本不知道我们在说什么，我们更高兴。）
- en: Accept failures but do so in a safe manner
  id: totrans-132
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 接受失败，但要以安全的方式进行
- en: Do you know that over 80% of traditional AI projects never made it to production?
    As you’ve read about in this chapter, GenAI should improve on those numbers because
    of the simplicity of getting it going, but you’re still going to encounter friction
    and failures (wrong completions, legislation, and so on). Perhaps you’ll try 40
    AI projects and 30 of them fail, but the 10 that work will more than compensate
    for the failures, *if* you pick the right use cases, which is why we wrote [Chapter 4](ch04.html#ch04_the_use_case_chapter_1740182047877425).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 你知道吗，超过80%的传统AI项目从未进入生产阶段？正如你在本章中读到的，由于启动的简单性，GenAI应该会改善这些数字，但你仍然会遇到摩擦和失败（错误的完成、立法等等）。也许你会尝试40个AI项目，其中30个失败，但成功的10个项目将远远弥补这些失败，*前提是你选择了正确的用例*，这也是我们撰写[第4章](ch04.html#ch04_the_use_case_chapter_1740182047877425)的原因。
- en: 'Lots of people like to say, “Fail fast and fail forward.” This implies that
    teams should quickly recognize when stuff isn’t working, learn from their mistakes,
    and move on. We think that’s too shallow when it comes to GenAI (and especially
    agents) advice for many use cases. Think about it this way: would you tell your
    university kid (for whom you are footing the bill) the same thing? We highly doubt
    it. We’d propose thinking, “Fail fast, fail forward, and fail safe,” and advise
    your kid to do that instead. This is why we think governments shouldn’t necessarily
    regulate AI (the default position for many governments) but regulate the use cases
    for AI. We think the AI behind a criminal justice sentencing system (fail fast,
    fail forward, fail safe) should be held to a much higher account and have more
    regulatory oversight than an AI that recommends what TV series you should binge-watch
    next because you loved the *Young Sheldon* show (fail fast, fail forward—no one
    is truly going to get hurt from watching *The Real Housewives of New Jersey*...well,
    perhaps a few). This is exactly why in [Chapter 1](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974)
    we said the safest place to start is with an internal automation use case.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 许多人喜欢说，“快速失败并继续前进。”这暗示团队应该迅速认识到事情不奏效时，从他们的错误中学习，并继续前进。我们认为，对于许多通用人工智能（特别是代理）用例的建议来说，这太肤浅了。想想看：你会对你的大学生（你正在为其支付账单）说同样的话吗？我们非常怀疑。我们建议思考，“快速失败，继续前进，并确保安全”，并建议你的孩子这样做。这就是为什么我们认为政府不一定需要监管人工智能（许多政府的默认立场），但应该监管人工智能的应用场景。我们认为，在刑事司法量刑系统背后的人工智能（快速失败，继续前进，确保安全）应该受到更高的问责，并比推荐你观看下一部电视剧的人工智能（快速失败，继续前进——没有人会真正因为观看《新泽西真实辣妈》而受到伤害……好吧，也许会有几个）有更多的监管监督。这就是为什么我们在[第1章](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974)中说，最安全的起点是与内部自动化用例开始。
- en: 'The culture you create has to change too. It must be ready and willing to accept
    safe failures, learn from them, and move on to the next one. For those of you
    who are leading your company’s AI projects (again, some of which are bound to
    fail), we have this great piece of advice that we came up with by hybridizing
    quotes from Michael Hyatt and Forrest Gump: on your greatest days, you’re probably
    not as smart as you think you are, but on your worst days, you’re probably not
    as dumb as you think you are either.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 你所创造的文化也必须改变。它必须准备好并愿意接受安全的失败，从失败中学习，并继续前进。对于那些领导你们公司AI项目的人来说（再次强调，其中一些注定会失败），我们有一些建议，这是通过混合迈克尔·海特和福雷斯特·甘普的引语得出来的：在你最伟大的日子里，你可能并不像你想象的那么聪明，但在你最糟糕的日子里，你可能也不像你想象的那么愚蠢。
- en: The Future of AI
  id: totrans-136
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 人工智能的未来
- en: With all the advances achieved in the last few years, the ambition of the 1950s
    has come full circle. Today’s models *do not* constitute true general intelligence
    (although reasoning models are getting us closer), but some of them can pass the
    *Turing test* (originally referred to as the *imitation game*), which is a test
    of a machine’s ability to exhibit intelligent behavior equivalent to or indistinguishable
    from that of a human.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中取得的所有进步之后，20世纪50年代的雄心壮志已经圆满实现。今天的模型**并不**构成真正的通用智能（尽管推理模型正在让我们更接近），但其中一些可以通过**图灵测试**（最初被称为**模仿游戏**），这是一个测试机器展现与人类相当或无法区分的智能行为的测试。
- en: 'So, what does this mean for all of us? Some people encounter GenAI and agents
    and think we’re at the dawn of a bright utopian age, while others think this is
    a prelude to dystopian misery. We take a moderate but positively slanted view:
    *a technology doesn’t have to be world ending to be world changing*. Like we said
    in [Chapter 1](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974),
    we don’t think it should be a surprise to anyone that technological innovations
    can help and/or hurt us (social media is a great example of this). We want you
    to know that we think both optimism and anxiety are valid, and that society has
    questioned every major innovation milestone from the Industrial Revolution onward
    (and in many cases, gotten it wrong).'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，这对我们所有人意味着什么呢？有些人遇到GenAI和代理，认为我们正处于一个光明乌托邦时代的黎明，而另一些人则认为这是通往反乌托邦痛苦的序曲。我们持一种温和但积极倾斜的观点：*一项技术不必是世界末日才能改变世界*。正如我们在[第1章](ch01.html#ch01_ai_to_ai_generative_ai_and_the_netscape_moment_1740182043982974)中所说，我们不认为技术创新能帮助我们或伤害我们（社交媒体是这一点的绝佳例子）。我们想让你知道，我们认为乐观和焦虑都是合理的，而且社会从工业革命以来一直在质疑每一个重大创新里程碑（而且在许多情况下，都犯了错误）。
- en: AI isn’t just going to be about our digital world. It’s also about our physical
    world; and applied properly, imagine what AI can do for the pace of discovery
    and innovation. It’s not just makeup; imagine what it can do for new materials
    discovery for medicine, energy, climate, and all the other pressing challenges
    we face as a species—these are the same challenges of makeup, just described with
    a different “language.” And as quantum computing evolves, we’re bound to see a
    synergy of these innovations that we can use to tackle these problem domains and
    more. Finally, what of a new kind of computing around GenAI—we’ll save that for
    [Chapter 9](ch09.html#ch09_generative_computing_a_new_style_of_computing_1740182052619664).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能不仅仅关乎我们的数字世界。它也关乎我们的物理世界；如果应用得当，想象一下人工智能可以为发现和创新的速度带来什么。它不仅仅是化妆；想象一下它可以为新材料的发现、医学、能源、气候以及我们作为物种所面临的所有其他紧迫挑战带来什么——这些都是化妆的挑战，只是用不同的“语言”描述而已。随着量子计算的发展，我们注定会看到这些创新之间的协同作用，我们可以利用这些创新来解决这些领域的问题以及更多。最后，关于围绕GenAI的新类型计算——我们将把这一点留到[第9章](ch09.html#ch09_generative_computing_a_new_style_of_computing_1740182052619664)。
- en: Ultimately, our success and that of all humanity depends on how we and the rest
    of the world approach AI.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，我们以及全人类的成功都取决于我们和世界其他地区如何对待人工智能。
- en: Let’s Get into It
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 让我们开始吧
- en: We’ve covered a lot of topics (at a high level) so far in this book, but we’ve
    basically told you that you have to do a lot of non-techie work to be great at
    AI. Maybe that feels overwhelming. It’s not our intention to make you feel that
    way, but you do need to feel a bit unsettled to move faster—to move with intent
    so that you don’t miss out. The goal of the rest of this book is to *remove barriers
    to your participation, not construct them*.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我们（在较高层次上）已经涵盖了大量的主题，但我们基本上告诉你，你必须做很多非技术性的工作才能在人工智能方面做得很好。也许这会让你感到不知所措。我们并不想让你有这样的感觉，但你确实需要感到一些不安，以便更快地行动——有目的地行动，这样你就不会错过任何东西。本书剩余部分的目标是*消除你参与的障碍，而不是构建它们*。
- en: Make no mistake about it, if you’re feeling a sense of urgency and fear about
    waiting too long and missing the moment, that’s OK. We can assure you that almost
    every other company is in the same situation, and lots of people are feeling the
    very same emotions that you are feeling right now. And trust us, we’ve heard many
    fishing stories of individuals and companies talking about their AI or how their
    products are built with AI, and like most fishing stories, many are exaggerated
    or untrue. We want to tell those people not to go telling fishing stories to those
    who know the real size of the fish, but we just smile and carry on with our day.
    That said, by reading this book, you’ll be in a position to do the same, and we’ll
    let you decide if you just smile or not.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这一点，不要有任何误解，如果你感到紧迫感和恐惧，担心等待太久而错过时机，这是正常的。我们可以向你保证，几乎每家公司都处于同样的情况，而且很多人都在经历你现在所感受到的相同情绪。而且请相信我们，我们已经听到了许多个人和公司谈论他们的AI或他们的产品是如何用AI构建的，就像大多数钓鱼故事一样，许多都是夸张的或不真实的。我们想告诉这些人不要向那些知道鱼真实大小的人讲述钓鱼故事，但我们只是微笑，继续我们的日常生活。话虽如此，通过阅读这本书，你将能够做同样的事情，我们将让你自己决定是否只是微笑。
- en: 'We can promise you (and your business) this: if you can show some restraint
    and not carelessly check the “I put AI in the business” box using fast and easy
    options (or be pressured to do so); if instead, you are thoughtful, deliberate,
    and strategic about using a platform that considers all the components you need
    (AI, data intelligence, data integration, and governance); and *most importantly,
    if you set your GPS to a destination of “AI Value Creator,”* then you’re going
    to be in a position to succeed over the long term. What’s more, like so many before
    you, your company won’t have to start over every time the winds of AI change direction.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以向你（以及你的企业）保证这一点：如果你能表现出一定的自制力，不要随意使用快速便捷的选项勾选“我在业务中应用了AI”的复选框（或者被压力迫使这样做）；如果你能够深思熟虑、审慎、有策略地使用一个考虑了所有必要组件（AI、数据智能、数据集成和治理）的平台；*最重要的是，如果你将你的GPS设定为“AI价值创造者”的目标地*，那么你将处于长期成功的位置。更重要的是，像你之前的许多人一样，你的公司不必每次AI的风向改变时都从头开始。
- en: Personally, we’re very excited about this new chapter in technology. We, all
    of us together, are going to use GenAI and agents to reshape not just our digital
    world but also our physical world. We’re going to use it to help tackle some of
    our toughest social, medical, and environmental problems, and more. We’ll do it
    through science, but also by empowering businesses—like the ones you work for
    and the one we work for—to do more faster and more responsibly. Whatever thing
    it is that your company does, AI is going to be a powerful new tool to help you
    do it better.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 个人而言，我们对科技这一新篇章感到非常兴奋。我们所有人一起，将利用通用人工智能和代理来重塑我们的数字世界，甚至我们的物理世界。我们将利用它来帮助解决我们最棘手的社会、医疗和环境问题，等等。我们将通过科学来实现这一点，但同时也将通过赋权企业——包括你所在的企业和我们所在的企业——来更快、更负责任地做事。无论你的公司做什么，人工智能都将是一个强大的新工具，帮助你做得更好。
- en: 'We’re quite certain of this: *the AI Value Creators will be the ones who make
    the biggest impact*. They will take the amazing foundational technology that is
    GenAI and use it to build entirely new solutions and workflows. That’s why it’s
    our goal to make AI accessible to everyone and put it in your hands, which is
    what this book is all about.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 我们对此非常确信：*AI价值创造者将是那些产生最大影响的人*。他们将利用令人惊叹的基础技术——通用人工智能，并利用它来构建全新的解决方案和工作流程。这就是我们的目标，让AI对每个人来说都触手可及，并将其放在你的手中，这正是本书的主题所在。
- en: '^([1](ch02.html#id389-marker)) Alan Turing, “Computing Machinery and Intelligence,”
    *Mind* 49, no. 236 (October 1950): 433‒460, [*https://doi.org/10.1093/mind/LIX.236.433*](https://doi.org/10.1093/mind/LIX.236.433).'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](ch02.html#id389-marker)) 阿兰·图灵，“计算机与智能”，《心灵》49卷第236期（1950年10月）：433‒460，[*https://doi.org/10.1093/mind/LIX.236.433*](https://doi.org/10.1093/mind/LIX.236.433).
- en: ^([2](ch02.html#id395-marker)) Noise in training data is any kind of irrelevant
    or random information, errors, or variations that do not reflect the true underlying
    patterns or relationships in the data.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: ^([2](ch02.html#id395-marker)) 训练数据中的噪声是指任何与数据真实潜在模式或关系无关的或随机的信息、错误或变化。
