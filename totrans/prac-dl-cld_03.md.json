["```py\n$ wget https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/ \ndownload/train.zip \n$ unzip train.zip\n$ mv train data\n$ cd data\n$ mkdir train val\n$ mkdir train/cat train/dog\n$ mkdir val/cat val/dog\n```", "```py\n$ ls | grep cat | sort -R | head -250 | xargs -I {} mv {} train/cat/\n$ ls | grep dog | sort -R | head -250 | xargs -I {} mv {} train/dog/\n$ ls | grep cat | sort -R | head -250 | xargs -I {} mv {} val/cat/\n$ ls | grep dog | sort -R | head -250 | xargs -I {} mv {} val/dog/\n```", "```py\nimport tensorflow as tf\nfrom tf.keras.preprocessing.image import ImageDataGenerator\nfrom tf.keras.models import Model\nfrom tf.keras.layers import Input, Flatten, Dense, Dropout,\nGlobalAveragePooling2D\nfrom tf.keras.applications.mobilenet import MobileNet, preprocess_input\nimport math\n```", "```py\nTRAIN_DATA_DIR = 'data/train_data/'\nVALIDATION_DATA_DIR = 'data/val_data/'\nTRAIN_SAMPLES = 500\nVALIDATION_SAMPLES = 500\nNUM_CLASSES = 2\nIMG_WIDTH, IMG_HEIGHT = 224, 224\nBATCH_SIZE = 64\n```", "```py\ntrain_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n                                   rotation_range=20,\n                                   width_shift_range=0.2,\n                                   height_shift_range=0.2,\n                                   zoom_range=0.2)\nval_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n```", "```py\ntrain_generator = train_datagen.flow_from_directory(\n                        TRAIN_DATA_DIR,\n                        target_size=(IMG_WIDTH, IMG_HEIGHT),\n                        batch_size=BATCH_SIZE,\n                        shuffle=True,\n                        seed=12345,\n                        class_mode='categorical')\nvalidation_generator = val_datagen.flow_from_directory(\n                        VALIDATION_DATA_DIR,\n                        target_size=(IMG_WIDTH, IMG_HEIGHT),\n                        batch_size=BATCH_SIZE,\n                        shuffle=False,\n                        class_mode='categorical')\n```", "```py\ndef model_maker():\n    base_model = MobileNet(include_top=False, input_shape =\n(IMG_WIDTH,IMG_HEIGHT,3))\n    for layer in base_model.layers[:]:\n        layer.trainable = False *`# Freeze the layers`*\n    input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n    custom_model = base_model(input)\n    custom_model = GlobalAveragePooling2D()(custom_model)\n    custom_model = Dense(64, activation='relu')(custom_model)\n    custom_model = Dropout(0.5)(custom_model)\n    predictions = Dense(NUM_CLASSES, activation='softmax')(custom_model)\n    return Model(inputs=input, outputs=predictions)\n```", "```py\nmodel = model_maker()\nmodel.compile(loss='categorical_crossentropy',\n              optimizer= tf.train.Adam(lr=0.001),\n              metrics=['acc'])\nnum_steps = math.ceil(float(TRAIN_SAMPLES)/BATCH_SIZE)              \nmodel.fit_generator(train_generator,\n                    steps_per_epoch = num_steps,\n                    epochs=10,\n                    validation_data = validation_generator,\n                    validation_steps = num_steps)\n```", "```py\n> Epoch 1/100 7/7 [====] - 5s - \nloss: 0.6888 - acc: 0.6756 - val_loss: 0.2786 - val_acc: 0.9018\n> Epoch 2/100 7/7 [====] - 5s - \nloss: 0.2915 - acc: 0.9019 - val_loss: 0.2022 - val_acc: 0.9220\n> Epoch 3/100 7/7 [====] - 4s - \nloss: 0.1851 - acc: 0.9158 - val_loss: 0.1356 - val_acc: 0.9427\n> Epoch 4/100 7/7 [====] - 4s - \nloss: 0.1509 - acc: 0.9341 - val_loss: 0.1451 - val_acc: 0.9404\n> Epoch 5/100 7/7 [====] - 4s - \nloss: 0.1455 - acc: 0.9464 - val_loss: 0.1637 - val_acc: 0.9381\n> Epoch 6/100 7/7 [====] - 4s - \nloss: 0.1366 - acc: 0.9431 - val_loss: 0.2319 - val_acc: 0.9151\n> Epoch 7/100 7/7 [====] - 4s - \nloss: 0.0983 - acc: 0.9606 - val_loss: 0.1420 - val_acc: 0.9495\n> Epoch 8/100 7/7 [====] - 4s - \nloss: 0.0841 - acc: 0.9731 - val_loss: 0.1423 - val_acc: 0.9518\n> Epoch 9/100 7/7 [====] - 4s - \nloss: 0.0714 - acc: 0.9839 - val_loss: 0.1564 - val_acc: 0.9509\n> Epoch 10/100 7/7 [====] - 5s - \nloss: 0.0848 - acc: 0.9677 - val_loss: 0.0882 - val_acc: 0.9702\n```", "```py\nmodel.save('model.h5')\n```", "```py\nfrom tf.keras.models import load_model\nmodel = load_model('model.h5')\n```", "```py\nimg_path = '../../sample_images/dog.jpg'\nimg = image.load_img(img_path, target_size=(224,224))\nimg_array = image.img_to_array(img)\nexpanded_img_array = np.expand_dims(img_array, axis=0)\npreprocessed_img = preprocess_input(expanded_img_array) *`# Preprocess the image`*\nprediction = model.predict(preprocessed_img)\nprint(prediction)\nprint(validation_generator.class_indices)\n[[0.9967706]]\n{'dog': 1, 'cat': 0}\n```", "```py\n*`# VARIABLES`*\nIMG_WIDTH, IMG_HEIGHT = 224, 224\nVALIDATION_DATA_DIR = 'data/val_data/'\nVALIDATION_BATCH_SIZE = 64\n\n*`# DATA GENERATORS`*\nvalidation_datagen = ImageDataGenerator(\n        preprocessing_function=preprocess_input)\nvalidation_generator = validation_datagen.flow_from_directory(\n        VALIDATION_DATA_DIR,\n        target_size=(IMG_WIDTH, IMG_HEIGHT),\n        batch_size=VALIDATION_BATCH_SIZE,\n        shuffle=False,\n        class_mode='categorical')\nground_truth = validation_generator.classes\n```", "```py\npredictions = model.predict_generator(validation_generator)\n```", "```py\n*`# prediction_table is a dict with index, prediction, ground truth`*\nprediction_table = {}\nfor index, val in enumerate(predictions):\n    *`# get argmax index`*\n    index_of_highest_probability = np.argmax(val)\n    value_of_highest_probability = val[index_of_highest_probability]\n    prediction_table[index] = [value_of_highest_probability,\nindex_of_highest_probability, ground_truth[index]]\nassert len(predictions) == len(ground_truth) == len(prediction_table)\n```", "```py\ndef display(sorted_indices, message):\n    similar_image_paths = []\n    distances = []\n    for name, value in sorted_indices:\n        [probability, predicted_index, gt] = value\n        similar_image_paths.append(VALIDATION_DATA_DIR + fnames[name])\n        distances.append(probability)\n    plot_images(similar_image_paths, distances, message)\n```", "```py\n*`# Most confident predictions of 'dog'`*\nindices = get_images_with_sorted_probabilities(prediction_table,\nget_highest_probability=True, label=1, number_of_items=10,\nonly_false_predictions=False)\nmessage = 'Images with the highest probability of containing dogs'\ndisplay(indices[:10], message)\n```", "```py\n*`# Least confident predictions of 'dog'`*\nindices = get_images_with_sorted_probabilities(prediction_table,\nget_highest_probability=False, label=1, number_of_items=10,\nonly_false_predictions=False)\nmessage = 'Images with the lowest probability of containing dogs'\ndisplay(indices[:10], message)\n```", "```py\n*`# Incorrect predictions of 'dog'`*\nindices = get_images_with_sorted_probabilities(prediction_table,\nget_highest_probability=True, label=1, number_of_items=10,\nonly_false_predictions=True)\nmessage = 'Images of cats with the highest probability of containing dogs'\ndisplay(indices[:10], message)\n```", "```py\n*`# Most confident predictions of 'cat'`*\nindices = get_images_with_sorted_probabilities(prediction_table,\nget_highest_probability=True, label=0, number_of_items=10,\nonly_false_predictions=False)\nmessage = 'Images with the highest probability of containing cats'\ndisplay(indices[:10], message)\n```", "```py\n*`# Least confident predictions of 'cat'`*\nindices = get_images_with_sorted_probabilities(prediction_table,\nget_highest_probability=False, label=0, number_of_items=10,\nonly_false_predictions=False)\nmessage = 'Images with the lowest probability of containing cats'\ndisplay(indices[:10], message)\n```", "```py\n*`# Incorrect predictions of 'cat'`*\nindices = get_images_with_sorted_probabilities(prediction_table,\nget_highest_probability=True, label=0, number_of_items=10,\nonly_false_predictions=True)\nmessage = 'Images of dogs with the highest probability of containing cats'\ndisplay(indices[:10], message)\n```"]