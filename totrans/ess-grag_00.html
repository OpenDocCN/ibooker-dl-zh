<html><head></head><body>
<div id="sbo-rt-content"><div class="readable-text" id="p1">
<h1 class="readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">1</span> </span> <span class="chapter-title-text">Improving LLM accuracy</span></h1>
</div>
<div class="introduction-summary">
<h3 class="introduction-header">This chapter covers</h3>
<ul>
<li class="readable-text" id="p2">Large language models</li>
<li class="readable-text" id="p3">Limitations of large language models</li>
<li class="readable-text" id="p4">Shortcomings of continuously finetuning a model</li>
<li class="readable-text" id="p5">Retrieval-augmented generation</li>
<li class="readable-text" id="p6">Combining structured and unstructured data to support all types of questions</li>
</ul>
</div>
<div class="readable-text" id="p7">
<p>Large language models (LLMs) have shown impressive abilities across a variety of domains, but they have significant limitations that affect their utility, particularly when tasked with generating accurate and up-to-date information. One widely adopted approach to addressing these limitations is retrieval-augmented generation (RAG), a workflow that combines an LLM with an external knowledge base to deliver accurate and current responses. By pulling data from trusted sources at run time, RAG can significantly reduce, though not completely eliminate, hallucinations, one of the most persistent challenges with LLMs. In addition, RAG allows systems to seamlessly bridge general knowledge with niche, domain-specific information that may not be well represented in the pretraining data of the model. Despite these advantages, RAG implementations have often focused solely on unstructured data, overlooking the potential of structured sources like knowledge graphs. </p>
</div>
<div class="readable-text intended-text" id="p8">
<p>Knowledge graphs are structured representations of entities, their attributes, and their relationships, offering a semantic framework that bridges structured and unstructured data. For instance, a customer support transcript is unstructured text, while a product catalog or user database is structured. Bridging them means enabling a system to connect conversational mentions of “my recent laptop order” to the structured record of the exact model, purchase date, and warranty status. Knowledge graphs serve as a critical component to RAG by enabling accurate, context-rich, and interconnected information retrieval—such as linking a customer query about a drug interaction to structured medical guidelines, prior case studies, and the patient’s history in real time. Integrating knowledge graphs into RAG pipelines can overcome LLM limitations, enhance data retrieval, and facilitate a holistic approach to managing and using diverse data types across domains like healthcare, finance, and technical support. </p>
</div>
<div class="readable-text intended-text" id="p9">
<p>This book is for developers, researchers, and data practitioners who want to build more robust, explainable, and capable RAG systems. You’ll learn both how to augment existing RAG architectures with knowledge graphs and how to build new GraphRAG pipelines from scratch. Along the way, you’ll gain practical skills in data modeling, graph construction, retrieval workflows, and system evaluation.</p>
</div>
<div class="readable-text intended-text" id="p10">
<p>By the end of this book, you’ll have a clear understanding of how LLMs, RAG, and knowledge graphs intersect to create robust systems capable of addressing complex queries and delivering accurate, reliable, and explainable results.</p>
</div>
<div class="readable-text" id="p11">
<h2 class="readable-text-h2"><span class="num-string">1.1</span> Introduction to LLMs</h2>
</div>
<div class="readable-text" id="p12">
<p>By now, you’ve likely encountered or heard about ChatGPT, one of the most prominent examples of conversational AI. ChatGPT is a conversational user interface developed by OpenAI and powered by LLMs, such as GPT-4 (OpenAI et al., 2024). LLMs are built on transformer architecture (Vaswani et al., 2017), which enables them to process and generate text efficiently. These models are trained on vast amounts of textual data, allowing them to learn patterns, grammar, context, and even some degree of reasoning. The training process involves feeding the model large datasets that include a diverse range of text with the primary objective of enabling the model to accurately predict the next word in a sequence. This extensive exposure enables the models to understand and generate human-like text based on the patterns they have learned from the data. For example, if you use “Never gonna” as input to an LLM, you might get a response similar to that shown in figure 1.1. </p>
</div>
<div class="readable-text intended-text" id="p13">
<p>Figure 1.1 shows an LLM processing the input “Never gonna” and generating the output “give you up.” This highlights how an LLM relies on patterns and associations it learned during training, such as those derived from common cultural references, including popular music. The quality and relevance of these responses depend significantly on the diversity and depth of the training dataset, which determines the LLM’s ability to recognize and replicate such patterns.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p14">
<img alt="figure" height="293" src="../Images/1-1.png" width="1100"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 1.1</span> LLMs are trained to predict the next word.</h5>
</div>
<div class="readable-text" id="p15">
<p>While LLMs excel at generating contextually appropriate text, they are far more than just autocomplete systems. Their remarkable ability to follow instructions and adapt to a wide range of tasks is impressive. For example, as shown in figure 1.2, you can ask ChatGPT to generate a haiku about a specific topic in a particular style. This capability illustrates not just pattern recognition but an understanding of task-specific instructions, enabling creative and nuanced outputs well beyond simple text prediction.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p16">
<img alt="figure" height="272" src="../Images/1-2.png" width="597"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 1.2</span> Writing a haiku with ChatGPT</h5>
</div>
<div class="readable-text" id="p17">
<p>The ability of LLMs to follow instructions and generate diverse, complex outputs, whether crafting a haiku or providing structured responses, goes beyond simply predicting the next word in a sequence. This ability to understand and execute detailed instructions makes LLMs uniquely suited for a wide variety of tasks. In this book, you will use this instruction-following ability to design and refine RAG pipelines. By tapping into instruction-following capabilities, you can integrate retrieval components more effectively, tailor responses to specific contexts, and optimize your systems for accuracy and usability.</p>
</div>
<div class="readable-text intended-text" id="p18">
<p>ChatGPT’s breadth of general knowledge is equally remarkable. For example, figure 1.3 illustrates ChatGPT’s response when prompted about the first manned moon landing.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p19">
<img alt="figure" height="853" src="../Images/1-3.png" width="1100"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 1.3</span> Retrieving factual information from ChatGPT</h5>
</div>
<div class="readable-text intended-text" id="p20">
<p>If you verify this response with external information from NASA or Wikipedia, you can observe that the model produces an accurate response with no false information. Such a response might give you the impression that an LLM constructs a vast database of facts from which it can retrieve when prompted. However, the model doesn’t store specific facts, events, or information from its training dataset. Instead, it develops complex mathematical representations of the language it is trained on. Remember, the LLMs are based on the transformer, which is a deep learning architecture based on neural networks to predict the next word, as shown in figure 1.4.</p>
</div>
<div class="readable-text intended-text" id="p21">
<p>Figure 1.4 illustrates a neural network predicting the next word in a sequence, similar to how LLMs function. The central part shows the network with multiple layers of neurons, connected by lines that represent the flow of information. Each connection has a weight, such as the example value 0.04, which influences the strength of the connection. During training, the model learns the values of these weights to improve its predictions. When asked about a specific historical event, an LLM doesn’t recall the event from its training data. Instead, it generates a response based on the learned weights in its neural network, similar to predicting the next word in a sequence. Therefore, while LLMs can provide seemingly knowledgeable answers, their responses are based on these learned weights rather than explicit memory. To quote Andrej Karpathy: “We kind of understand that they (LLMs) build and maintain some kind of a knowledge database, but even this knowledge base is very strange and imperfect and weird”(<a href="https://www.youtube.com/watch?v=zjkBMFhNj_gat12:40">https://www.youtube.com/watch?v=zjkBMFhNj_gat12:40</a>).<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p22">
<img alt="figure" height="763" src="../Images/1-4.png" width="1100"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 1.4</span> Neural network trained to predict the next word based on the input sequence of words </h5>
</div>
<div class="readable-text" id="p23">
<h2 class="readable-text-h2"><span class="num-string">1.2</span> Limitations of LLMs</h2>
</div>
<div class="readable-text" id="p24">
<p>LLMs represent a groundbreaking step in the evolution of AI, offering remarkable capabilities across a range of applications. Yet, as with any transformative technology, they are not without their challenges and constraints. In the following section, we will delve into some of these limitations and their implications. </p>
</div>
<div class="readable-text" id="p25">
<h3 class="readable-text-h3"><span class="num-string">1.2.1</span> Knowledge cutoff problem</h3>
</div>
<div class="readable-text" id="p26">
<p>The most obvious limitation is that LLMs are unaware of events or information not included in their training dataset. At this moment, ChatGPT is aware of information that occurred up to October 2023. For example, if you asked ChatGPT about an event in 2024, you would get a response similar to that shown in figure 1.5. </p>
</div>
<div class="readable-text intended-text" id="p27">
<p>In the context of LLMs, the <em>knowledge cutoff date</em> refers to the most recent point at which the model’s training data includes information. The model has access to a broad spectrum of text data containing information about events up to this date from diverse sources, which it utilizes to generate responses and provide information. Anything that has occurred or been published after this cutoff date is unknown to the model as it was not included in the training dataset; therefore, it cannot provide information about events, developments, or research that occurred after the cutoff date. <span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p28">
<img alt="figure" height="390" src="../Images/1-5.png" width="1100"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 1.5</span> Example of a knowledge cutoff date disclaimer</h5>
</div>
<div class="readable-text" id="p29">
<h3 class="readable-text-h3"><span class="num-string">1.2.2</span> Outdated information</h3>
</div>
<div class="readable-text" id="p30">
<p>A less obvious limitation is that LLMs can sometimes provide outdated responses. While they can deliver detailed and accurate information up until their knowledge cutoff, they may not reflect recent developments. For instance, as of late 2023, Mark Cuban sold his majority stake in the Dallas Mavericks franchise to the Adelson family and the Dumonts while retaining a minority share. This major update highlights how information that was correct in the past can become outdated. For example, in a query about the Dallas Mavericks, a response shown in figure 1.6 reflects Cuban as the sole owner, which is no longer accurate (Rader, 2023). <span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p31">
<img alt="figure" height="309" src="../Images/1-6.png" width="594"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 1.6</span> Sometimes ChatGPT responds with outdated information.</h5>
</div>
<div class="readable-text" id="p32">
<p>This highlights the importance of regularly updating training data for models or enabling them to access real-time information. With continuously evolving events and facts, even small details like ownership structures can significantly impact how we perceive an organization or individual. This limitation underlines the importance of ensuring AI systems remain accurate and relevant in dynamic environments. </p>
</div>
<div class="readable-text" id="p33">
<h3 class="readable-text-h3"><span class="num-string">1.2.3</span> Pure hallucinations</h3>
</div>
<div class="readable-text" id="p34">
<p>Another well-known limitation of LLMs is their tendency to provide assertive, confident answers—even when those answers contain incorrect or fabricated information. One might assume that, despite their knowledge cutoff dates, these models provide accurate factual data up to that point. However, even information about events that occurred before the cutoff can be unreliable. </p>
</div>
<div class="readable-text intended-text" id="p35">
<p>A striking example of this occurred when lawyers in the United States submitted bogus, fictitious legal citations to a court, unaware that they had been generated by ChatGPT (Neumeister, 2023). These kinds of confident inaccuracies are commonly known as hallucinations, where the model outputs information that sounds plausible but is factually incorrect or entirely fabricated. External references such as URLs, academic citations, or identifiers like WikiData IDs are especially prone to this behavior.</p>
</div>
<div class="readable-text intended-text" id="p36">
<p>Hallucinations occur because LLMs are not reasoning engines. They are probabilistic language models trained to predict what sounds like a good next token, based on patterns in their training data. They don’t know facts the way humans do. Rather, they generate text by guessing the most likely continuation, regardless of whether it’s true. This fundamental difference between statistical pattern matching and actual understanding is what separates LLMs from human cognition.</p>
</div>
<div class="readable-text intended-text" id="p37">
<p>To illustrate this, we can ask ChatGPT to provide the WikiData ID of the Dallas Mavericks NBA franchise. As shown in figure 1.7, the model confidently returns an identifier—but it’s incorrect.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p38">
<img alt="figure" height="182" src="../Images/1-7.png" width="457"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 1.7</span> ChatGPT can produce responses with incorrect information.</h5>
</div>
<div class="readable-text" id="p39">
<p>The model assertively replied with an ID that follows the WikiData format. However, if you verify this information, you can observe that Q152232 is the WikiData ID of the movie titled <em>Womanlight</em> (<a href="https://www.wikidata.org/wiki/Q152232">https://www.wikidata.org/wiki/Q152232</a>). Therefore, users must recognize that LLMs, while often informative, are not infallible and can produce erroneous information. It’s crucial to approach their responses critically and verify their accuracy through reliable external sources, especially in contexts where precision and factual correctness are central. </p>
</div>
<div class="readable-text" id="p40">
<h3 class="readable-text-h3"><span class="num-string">1.2.4</span> Lack of private information</h3>
</div>
<div class="readable-text" id="p41">
<p>If you were building a company chatbot using an LLM, you’d likely want it to answer questions involving internal or proprietary information that isn’t publicly available. In such cases, even if the information or events occurred before the LLM’s knowledge cutoff date, they wouldn’t have been part of its training data. As a result, the model cannot generate accurate responses for such queries, as illustrated in figure 1.8. <span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p42">
<img alt="figure" height="517" src="../Images/1-8.png" width="1042"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 1.8</span> ChatGPT didn’t have access to some private or confidential information during training.</h5>
</div>
<div class="readable-text" id="p43">
<p>One potential solution would be to make the company’s internal information publicly available in the hope that it gets included in the training dataset of an LLM. However, this approach is neither practical nor secure. Instead, we will explore and demonstrate more effective strategies to overcome these limitations while maintaining data privacy and control.</p>
</div>
<div class="callout-container sidebar-container">
<div class="readable-text" id="p44">
<h5 class="callout-container-h5 readable-text-h5">Note on other limitations of LLMs</h5>
</div>
<div class="readable-text" id="p45">
<p>While this book will focus on the limitations of LLMs in providing factually correct and up-to-date information in responses, it’s important to acknowledge that LLMs also have other restrictions. Some of these include</p>
</div>
<ul>
<li class="readable-text" id="p46"> <em>Bias in responses</em>—LLMs can sometimes generate biased responses, reflecting biases present in the training data. </li>
<li class="readable-text" id="p47"> <em>Lack of understanding and context</em>—LLMs, despite their complexity, do not truly understand the text. They process language based on patterns learned from data, which means they can miss nuances and contextual subtleties. </li>
<li class="readable-text" id="p48"> <em>Vulnerability to prompt injection</em>—LLMs are susceptible to prompt injection attacks, where malicious users craft inputs to manipulate the model into generating inappropriate, biased, or harmful responses. This vulnerability poses significant challenges for ensuring the security and integrity of LLM applications in real-world scenarios. </li>
<li class="readable-text" id="p49"> <em>Inconsistent responses</em>—LLMs can produce different answers to the same question across multiple interactions. This inconsistency arises from their probabilistic nature and lack of persistent memory, which can hinder their usefulness in applications that require stability and repeatability. </li>
</ul>
<div class="readable-text" id="p50">
<p>This book is dedicated to exploring and addressing the specific limitations of LLMs concerning the generation of factually accurate and up-to-date responses. Although we recognize other limitations of LLMs, our discussion will not cover them. </p>
</div>
</div>
<div class="readable-text" id="p51">
<h2 class="readable-text-h2"><span class="num-string">1.3</span> Overcoming the limitations of LLMs</h2>
</div>
<div class="readable-text" id="p52">
<p>LLMs are powerful tools, but they often face limitations when handling domain-specific questions or accessing specialized, up-to-date knowledge. Implementing a ChatGPT-like application in a business environment requires outputs that are both precise and factually accurate. To overcome these challenges, we can inject domain-specific knowledge into LLMs using approaches like supervised finetuning and RAG. In this section, we’ll explore how these methods work and how they can be applied to inject domain-specific knowledge into LLMs. </p>
</div>
<div class="readable-text" id="p53">
<h3 class="readable-text-h3"><span class="num-string">1.3.1</span> Supervised finetuning</h3>
</div>
<div class="readable-text" id="p54">
<p>At first, many of us thought we would overcome the limitations of LLMs with additional training. For example, we could overcome the knowledge cutoff date limitation by continuously updating the model. However, to address this limitation effectively, we first need to better understand the training of an LLM. The training of an LLM like ChatGPT can be split into the following four stages, as described by Andrew Karpathy (<a href="https://www.youtube.com/watch?v=bZQun8Y4L2A">https://www.youtube.com/watch?v=bZQun8Y4L2A</a>):</p>
</div>
<ol>
<li class="readable-text" id="p55"> <em>Pretraining</em> —The model reads a vast amount of text, often more than a trillion tokens, to learn basic language patterns. It practices predicting what word comes next in a sentence. This is the foundational step, like learning vocabulary and grammar before you can write. This is the most resource-intensive phase, which can require thousands of GPUs and can take months of continuous training. </li>
<li class="readable-text" id="p56"> <em>Supervised finetuning</em> —The model is given specific examples of high-quality conversations to improve its ability to respond like a helpful assistant. It continues to practice language but now with a focus on generating useful and accurate responses. Think of it as moving from basic language learning to practicing conversation skills. This requires significantly fewer resources than pretraining and can nowadays even run on a single laptop for smaller LLMs. </li>
<li class="readable-text" id="p57"> <em>Reward modeling</em> —The model learns to distinguish between good and bad responses by comparing different answers to the same questions. It’s like having a coach who shows the model what a good performance looks like so it can aim to replicate that quality. </li>
<li class="readable-text" id="p58"> <em>Reinforcement learning</em> —The model interacts with users or simulated environments to further refine its responses based on feedback. It’s similar to learning a sport: practicing not just by drills but by playing actual games and learning from the experience. </li>
</ol>
<div class="readable-text" id="p59">
<p>Since the pretraining phase is costly and time consuming and, therefore, not feasible for continuous updating, the idea was to use the supervised finetuning phase to overcome the limitations of LLMs. During the supervised finetuning phase, you supply the language model with specific examples of input prompts along with the corresponding desired outputs you aim for the model to produce. One such example is shown in figure 1.9. <span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p60">
<img alt="figure" height="255" src="../Images/1-9.png" width="1100"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 1.9</span> Sample record of a supervised finetuning dataset</h5>
</div>
<div class="readable-text" id="p61">
<p>Figure 1.9 shows an example of a question–answer pair that could be used to finetune an LLM. In this example, the input prompt or the question is about which team won the 2023 NBA championship, and the corresponding answer is the Denver Nuggets. The theory was that, through this example, the LLM would include this fact in its mathematical representation of the language and be able to answer questions revolving around the 2023 NBA champions. Some research studies have shown that supervised finetuning can improve LLM factuality (Tian et al., 2023). However, other studies using different methods also show that LLMs struggle to learn new factual information through finetuning (Ovadia et al., 2023).</p>
</div>
<div class="readable-text intended-text" id="p62">
<p>While supervised finetuning can enhance the overall knowledge of a model, it remains a complex and evolving field of research. As such, deploying a reliable, finetuned language model in a production environment poses significant challenges at the current stage of technological development. Fortunately, a more efficient and simpler method to address the knowledge limitations of LLMs exists.</p>
</div>
<div class="readable-text" id="p63">
<h3 class="readable-text-h3"><span class="num-string">1.3.2</span> Retrieval-augmented generation</h3>
</div>
<div class="readable-text" id="p64">
<p>The second strategy for improving LLM accuracy and overcoming its limitations is the RAG workflow, which combines an LLM with an external knowledge base to deliver accurate and up-to-date responses. Instead of depending on an LLM’s internal knowledge, relevant facts or information are provided directly in the input prompt (Lewis et al., 2020). This concept (RAG) uses the LLM’s strengths in understanding and generating natural language, while factual information is supplied in the prompt, reducing dependence on the LLM’s internal knowledge base and consequently hallucinations. </p>
</div>
<div class="readable-text intended-text" id="p65">
<p>The RAG workflow operates in two main stages:</p>
</div>
<ul>
<li class="readable-text" id="p66"> Retrieval </li>
<li class="readable-text" id="p67"> Augmented generation </li>
</ul>
<div class="readable-text" id="p68">
<p>In the retrieval stage, relevant information is located from an external knowledge base or database. During the augmented generation stage, this retrieved information is combined with the user’s input to enhance the context provided to the LLM, enabling it to generate a response grounded in reliable, external facts. The RAG workflow is illustrated in figure 1.10.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p69">
<img alt="figure" height="579" src="../Images/1-10.png" width="1012"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 1.10</span> Providing relevant information to the LLM as part of the input</h5>
</div>
<div class="readable-text" id="p70">
<p>As mentioned, LLMs are great at understanding natural language and following instructions in the prompt. In the RAG workflow, the goal shifts to task-oriented response generation, where LLMs follow a set of instructions. The process involves utilizing a retrieval tool to fetch relevant documents from a specific knowledge base. The LLM then generates answers based on the provided documents, ensuring responses are accurate, contextually relevant, and aligned with specific guidelines. This systematic approach transforms the answer generation process into a targeted task of inspecting and using the retrieved information to produce the final answer. An example of providing factual information in the input prompt is shown in figure 1.11.</p>
</div>
<div class="readable-text intended-text" id="p71">
<p>Figure 1.11 illustrates an example of how an LLM processes follows the prompt instructions of a RAG workflow. The prompt highlights the importance of using retrieved context to ensure accurate and relevant responses and can be broken down into</p>
</div>
<ul>
<li class="readable-text" id="p72"> <em>Provided context</em> —A factual statement that introduces relevant information—in this case, identifying the Denver Nuggets as the 2023 NBA champions with a 4:1 victory over the Miami Heat. This acts as the knowledge base input for the LLM. </li>
<li class="readable-text" id="p73"> <em>User query</em> —A specific question, “Who won the 2023 NBA championship?” which directs the LLM to extract relevant information from the provided context. </li>
<li class="readable-text" id="p74"> <em>Generated answer</em> —The LLM’s response is aligned with the retrieved context: “The Denver Nuggets won the 2023 NBA championship.”<span class="aframe-location"/> </li>
</ul>
<div class="browsable-container figure-container" id="p75">
<img alt="figure" height="540" src="../Images/1-11.png" width="1100"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 1.11</span> Providing relevant information to the answer as part of the prompt</h5>
</div>
<div class="readable-text" id="p76">
<p>You might wonder what the advantage of the RAG process is if the user has to provide both the context and the questions. In practice, the retrieval system operates independently from the user. The user only needs to provide the question, while the retrieval process occurs behind the scenes, as illustrated in figure 1.12.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p77">
<img alt="figure" height="589" src="../Images/1-12.png" width="927"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 1.12</span> Populating the relevant data from the user and knowledge base into the prompt template and then passing it to an LLM to generate the final answer</h5>
</div>
<div class="readable-text" id="p78">
<p>In the RAG process, the user starts by asking a question. Behind the scenes, the system turns that question into a search query and retrieves relevant information from sources like company documents, knowledge articles, or databases. Advanced retrieval algorithms find the most suitable content, which is then combined with the original question to form an enriched prompt. This prompt is sent to an LLM, which generates a response based on both the question and the retrieved context. The entire retrieval process is automatic, and no extra input is required beyond the original question from the user. This makes RAG both seamless and effective, improving factual accuracy while reducing the chance of hallucinated answers.</p>
</div>
<div class="readable-text intended-text" id="p79">
<p>The RAG approach has gained mainstream popularity due to its simplicity and efficiency. It is now also part of the ChatGPT interface, where the LLM can use Web Search to search for relevant information before generating the final answer. Users of the paid version of ChatGPT may be familiar with the RAG process as depicted in figure 1.13.<span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p80">
<img alt="figure" height="429" src="../Images/1-13.png" width="927"/>
<h5 class="figure-container-h5"><span class="num-string">Figure 1.13</span> ChatGPT uses Web Search to find relevant information to generate an up-to-date answer.</h5>
</div>
<div class="readable-text" id="p81">
<p>While the exact implementation of RAG in ChatGPT is not publicly disclosed, we can try to infer what it does under the hood. When the LLM decides, for whatever reason, that it needs to pull additional information, it can input a query into Web Search. We don’t know precisely how it navigates through search results, parses information from web pages, or decides that it has retrieved sufficient information. Nevertheless, we know that it used <code>2023</code> <code>NBA</code> <code>championship</code> <code>winner</code> keyword as input to Web Search and generated the final response based on the information available on the official NBA website (<a href="https://www.nba.com/playoffs/2023/the-finals">https://www.nba.com/playoffs/2023/the-finals</a>). </p>
</div>
<div class="readable-text" id="p82">
<h2 class="readable-text-h2"><span class="num-string">1.4</span> Knowledge graphs as the data storage for RAG applications</h2>
</div>
<div class="readable-text" id="p83">
<p>When planning to implement a RAG application, choosing the right storage solution is important. While there are many database options, we argue that knowledge graphs and graph databases are especially well suited for most RAG applications. A knowledge graph is a data structure that uses nodes to represent concepts and entities and relationships to connect these nodes. An example knowledge graph is shown in figure 1.14. <span class="aframe-location"/></p>
</div>
<div class="browsable-container figure-container" id="p84">
<img alt="figure" height="704" src="../Images/1-14.png" width="1012"/>
<h5 class="figure-container-h5"><strong><span class="num-string">Figure 1.14</span> A knowledge graph can store complex structured and unstructured data in a single database system.</strong></h5>
</div>
<div class="readable-text" id="p85">
<p>Knowledge graphs are highly versatile, capable of storing both structured information (such as employee details, task statuses, and company hierarchies) and unstructured information (such as article contents). This dual capability, as illustrated in figure 1.14, makes them uniquely suited for complex RAG applications. Structured data allows for precise and efficient querying to answer questions such as, “How many tasks are assigned to a specific employee?” or “Which employees report to a particular manager?” For example, in figure 1.14, structured data such as “Sam Altman is the CEO of OpenAI” or “John Doe has been an employee of OpenAI since 01-01-2023” can be directly queried to answer questions like “Who is the CEO of OpenAI?” or “How long has John Doe been with the company?” Similarly, structured relationships like “John Doe is assigned to a task with the status Completed” enable precise queries such as “Which tasks have been completed by employees?” or “Who is assigned to specific tasks at OpenAI?” This capability is critical for generating actionable insights from complex, interconnected data. </p>
</div>
<div class="readable-text intended-text" id="p86">
<p>On the other hand, unstructured data, such as article text, complements structured data by providing rich contextual information that adds depth and nuance. For instance, the unstructured article node in figure 1.14 provides details about a new LLM model and embeddings, but without a structured framework, it cannot answer specific queries like “How is this article related to OpenAI employees?”</p>
</div>
<div class="readable-text intended-text" id="p87">
<p>Importantly, unstructured data alone cannot answer all types of questions. While it can provide insights for open-ended or fuzzy queries, it lacks the structure needed for precise operations such as filtering, counting, or aggregating. For example, answering “How many tasks are completed within a company?” or “Which employees are assigned to tasks related to OpenAI?” requires structured relationships and attributes, as depicted in the right-hand side of figure 1.14. Without structured data, these types of queries would require exhaustive text parsing and inference, which are computationally expensive and often imprecise. By integrating structured and unstructured information in the same framework, knowledge graphs enable the seamless blending of both worlds, making them a powerful tool for answering a broad range of questions efficiently and accurately in RAG applications. Moreover, explicit connections between unstructured and structured data unlock advanced retrieval strategies such as linking entities in text to graph nodes or contextualizing structured results with source passages that would be difficult or impossible to achieve using either type of data alone. </p>
</div>
<div class="readable-text" id="p88">
<h2 class="readable-text-h2">Summary</h2>
</div>
<ul>
<li class="readable-text" id="p89"> LLMs, such as ChatGPT, are built on transformer architecture, enabling them to process and generate text efficiently by learning patterns from extensive textual data. </li>
<li class="readable-text" id="p90"> While LLMs exhibit remarkable abilities in natural language understanding and generation, they have inherent limitations, such as a knowledge cutoff, the potential to generate outdated or hallucinated information, and an inability to access private or domain-specific knowledge. </li>
<li class="readable-text" id="p91"> Continuous finetuning of LLMs to enhance their internal knowledge base is not practical due to resource constraints and the complexity of updating the models regularly. </li>
<li class="readable-text" id="p92"> RAG addresses LLM limitations by combining them with external knowledge bases, providing accurate, context-rich responses by injecting relevant facts directly into the input prompt. </li>
<li class="readable-text" id="p93"> RAG implementations have traditionally focused on unstructured data sources, limiting their scope and effectiveness for tasks requiring structured, precise, and interconnected information. </li>
<li class="readable-text" id="p94"> Knowledge graphs use nodes and relationships to represent and connect entities and concepts, integrating structured and unstructured data to provide a holistic data representation. </li>
<li class="readable-text" id="p95"> Integrating knowledge graphs into RAG workflows enhances their capability to retrieve and organize contextually relevant data, allowing LLMs to generate accurate, reliable, and explainable responses. </li>
</ul>
</div></body></html>