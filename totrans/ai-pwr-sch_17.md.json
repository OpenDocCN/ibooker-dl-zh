["```py\nThere was actually a project done on the definition of what a minimalist shoe\nis and the result was \"Footwear providing minimal interference with the \nnatural movement of the foot due to its high flexibility, low heel to toe \ndrop, weight and stack height, and the absence of motion control and stability\ndevices\". If you are looking for a simpler definition, this is what Wikipedia\nsays, Minimalist shoes are shoes intended to closely approximate barefoot \nrunning conditions. 1 They have reduced cushioning, thin soles, and are of \nlighter weight than other running shoes, allowing for more sensory contact \nfor the foot on the ground while simultaneously providing the feet with some protection from ground hazards and conditions (such as pebbles and dirt). Oneexample of minimalistic shoes would be the Vibram FiveFingers shoes which \nlook like this.\n```", "```py\nfrom transformers import AutoTokenizer, AutoModelForQuestionAnswering\nmodel_name = \"deepset/roberta-base-squad2\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name)\n```", "```py\nquestion = \"What are minimalist shoes\"\ncontext = \"\"\"There was actually a project done on the definition of what a\nminimalist shoe is and the result was \"Footwear providing minimal\ninterference with the natural movement of the foot due to its high\nflexibility, low heel to toe drop, weight and stack height, and the absence\nof motion control and stability devices\". If you are looking for a simpler\ndefinition, this is what Wikipedia says, Minimalist shoes are shoes intended\nto closely approximate barefoot running conditions. 1 They have reduced\ncushioning, thin soles, and are of lighter weight than other running shoes,\nallowing for more sensory contact for the foot on the ground while\nsimultaneously providing the feet with some protection from ground\nhazards and conditions (such as pebbles and dirt).\nOne example of minimalistic shoes would be the Vibram FiveFingers\nshoes which look like this.\"\"\"\n\ninputs = tokenizer(question, context, add_special_tokens=True,\n                   return_tensors=\"pt\")\ninput_ids = inputs[\"input_ids\"].tolist()[0]\n\noutputs = model(**inputs)\nstart_logits_norm = normalize(outputs[0].detach().numpy())\nend_logits_norm = normalize(outputs[1].detach().numpy())\n\nprint(f\"Total number of tokens: {len(input_ids)}\")\nprint(f\"Total number of start probabilities: {start_logits_norm.shape[1]}\")\nprint(f\"Total number of end probabilities: {end_logits_norm.shape[1]}\")\n```", "```py\nTotal number of tokens: 172\nTotal number of start probabilities: 172\nTotal number of end probabilities: 172\n```", "```py\nstart_tokens = []\nend_tokens = []\nterms = tokenizer.convert_ids_to_tokens(input_ids)\nstart_token_id = 0\nend_token_id = len(terms)\nfor i, term in enumerate(terms):\n  start_tokens.append(stylize(term, [0, 127, 255], start_logits_norm[0][i]))\n  end_tokens.append(stylize(term, [255, 0, 255], end_logits_norm[0][i]))\n  if start_logits_norm[0][i] == 1.0:\n    start_token_id = i\n  if end_logits_norm[0][i] == 1.0:\n    end_token_id = i + 1\n\nanswer = terms[start_token_id:end_token_id]\ndisplay(HTML(f'<h3>{clean_token(\" \".join(answer))}</h3>'))  #1\ndisplay(HTML(f'<pre>{\" \".join(start_tokens)}</pre>'))  #2\ndisplay(HTML(f'<pre>{\" \".join(end_tokens)}</pre>'))  #3\n```", "```py\n_shoes _intended _to _closely _approximate _bare foot _running _conditions\n```", "```py\nQ: What are minimalist shoes?\nA: shoes intended to closely approximate barefoot running conditions\n```", "```py\nThere was actually a project done on the definition... this is what Wikipedia\nsays, Minimalist shoes are shoes intended to closely approximate barefoot \nrunning conditions. 1 They have reduced cushioning, thin soles, ...\n```", "```py\ndef get_questions():\n  question_types = [\"who\", \"what\", \"when\",  #1\n                    \"where\", \"why\", \"how\"]  #1\n  questions = []\n  for type in question_types:\n    request = {\"query\": type,\n               \"query_fields\": [\"title\"],\n               \"return_fields\": [\"id\", \"url\", \"owner_user_id\",\n                                 \"title\", \"accepted_answer_id\"],\n               \"filters\": [(\"accepted_answer_id\", \"*\")],  #2\n               \"limit\": 10000}\n    docs = outdoors_collection.search(**request)[\"docs\"]\n    questions += [document for document in docs  #3\n                  if document[\"title\"].lower().startswith(type)]  #3\n  return questions\n```", "```py\ndef get_answers_from_questions(questions, batch_size=500):\n  answer_ids = list(set([str(q[\"accepted_answer_id\"])  #1\n                         for q in questions]))  #1\n  batches = math.ceil(len(answer_ids) / batch_size)  #2\n  answers = {}\n\n  for n in range(0, batches):  #3\n    ids = answer_ids[n * batch_size:(n + 1) * batch_size]\n    request = {\"query\": \"(\" + \" \".join(ids) + \")\",\n               \"query_fields\": \"id\",\n               \"limit\": batch_size,\n               \"filters\": [(\"post_type\", \"answer\")],\n               \"order_by\": [(\"score\", \"desc\")]}\n    docs = outdoors_collection.search(**request)[\"docs\"]\n    answers |= {int(d[\"id\"]): d[\"body\"] for d in docs}\n  return answers\n\ndef get_context_dataframe(questions):\n  answers = get_answers_from_questions(questions) #4\n  contexts = {\"id\": [], \"question\": [], \"context\": [], \"url\": []}\n  for question in questions:\n    contexts[\"id\"].append(question[\"id\"])\n    contexts[\"url\"].append(question[\"url\"])\n    contexts[\"question\"].append(question[\"title\"]),\n    if question[\"accepted_answer_id\"] in answers:\n      context = answers[question[\"accepted_answer_id\"]]\n    else:\n      context = \"Not found\"\n    contexts[\"context\"].append(context)\n  return pandas.DataFrame(contexts)\n\nquestions = get_questions()  #5\ncontexts = get_context_dataframe(questions)  #6\ndisplay(contexts[0:5])\n```", "```py\nid    question                               context\n4410  Who places the anchors that rock c...  There are two distinct styl...\n5347  Who places the bolts on rock climb...  What you're talking about i...\n20662 Who gets the bill if you activate ...  Almost always the victim ge...\n11587 What sort of crane, and what sort ...  To answer the snake part of...\n7623  What knot is this one? What are it...  Slip knot It's undoubtably ...\n```", "```py\nfrom transformers import pipeline  #1\nimport torch\nimport tqdm  #2\n\ndef get_processor_device():  #3\n  return 0 if torch.cuda.is_available() else -1  #3\n\ndef answer_questions(contexts, k=10):\n  nlp = pipeline(\"question-answering\", model=model_name,  #4\n                 tokenizer=model_name, device=device)  #4\n  guesses = []\n  for _, row in tqdm.tqdm(contexts[0:k].iterrows(), total=k):  #5\n    result = nlp({\"question\": row[\"question\"],  #6\n                  \"context\": row[\"context\"]})  #6\n    guesses.append(result)\n  return guesses\n\nmodel_name = \"deepset/roberta-base-squad2\"\ndevice = get_processor_device()  #7\n\nguesses = answer_questions(contexts, k=len(contexts))\ndisplay_guesses(guesses)\n```", "```py\nscore     start  end   answer\n0.278927  474    516   a local enthusiast or group of enthusiasts\n0.200848  81     117   the person who is creating the climb\n0.018632  14     24    the victim\n...\n0.247008  227    265   the traditional longbow made from wood\n0.480407  408    473   shoes intended to closely approximate barefoot run...\n0.563754  192    232   a tube of lightweight, stretchy material\n```", "```py\nfrom datasets import Dataset, DatasetDict\n\ndef get_training_data(filename):\n  golden_answers = pandas.read_csv(filename)\n  golden_answers = golden_answers[golden_answers[\"class\"] != None]\n  qa_data = []\n  for _, row in golden_answers.iterrows():\n    answers = row[\"gold\"].split(\"|\")\n    starts = [row[\"context\"].find(a) for a in answers]\n    missing = -1 in starts\n    if not missing:\n      row[\"title\"] = row[\"question\"]\n      row[\"answers\"] = {\"text\": answers, \"answer_start\": starts}\n      qa_data.append(row)\n  columns = [\"id\", \"url\", \"title\", \"question\", \"context\", \"answers\"]\n  df = pandas.DataFrame(qa_data, columns=columns) \\  #1\n             .sample(frac=1, random_state=0)  #1\n  train_split = int(len(df) * 0.75)  #2\n  eval_split = (int((len(df) - train_split) / 1.25) +   #3\n                train_split - 1)  #3\n  train_dataset = Dataset.from_pandas(df[:train_split])\n  test_dataset = Dataset.from_pandas(df[train_split:eval_split])\n  validation_dataset = Dataset.from_pandas(df[eval_split:])  #4\n  return DatasetDict({\"train\": train_dataset,  #5\n                      \"test\": test_dataset,  #5\n                      \"validation\": validation_dataset})  #5\n\ndatadict = get_training_data(\"data/outdoors/outdoors_golden_answers.csv\")\nmodel_path = \"data/question-answering/question-answering-training-set\"\ndatadict.save_to_disk(model_path)\n```", "```py\ndef get_processor_type():\n  gpu_device = torch.device(\"cuda:0\")\n  cpu_device = torch.device(\"cpu\")\n  return gpu_device or cpu_device\n\ndef get_processor_device():\n  return 0 if torch.cuda.is_available() else -1\n\nprint(\"Processor: \" + str(get_processor_type()))\nprint(\"Device id: \" + str(get_processor_device()))\n```", "```py\nProcessor: device(type='cuda', index=0)\nDevice id: 0\n```", "```py\n# This function adapted from:\n# https://github.com/huggingface/notebooks/blob/master/examples/\n#question_answering.ipynb\n# Copyright 2001, Hugging Face. Apache 2.0 Licensed.\nfrom datasets import load_from_disk\nfrom transformers import RobertaTokenizerFast\n\nfile = \"data/question-answering/question-answering-training-set\"\ndatadict = datasets.load_from_disk(file) #1\ntokenizer = from_pretrained(\"roberta-base\") #2\n...\n\ndef tokenize_dataset(examples):\n  maximum_tokens = 384  #3\n  document_overlap = 128  #4\n  pad_on_right = tokenizer.padding_side == \"right\" #5\n  tokenized_examples = tokenizer(  #6\n    examples[\"question\" if pad_on_right  #6\n                        else \"context\"],  #6\n    examples[\"context\" if pad_on_right  #6\n                       else \"question\"],  #6\n    truncation=\"only_second\" if pad_on_right  #6\n                             else \"only_first\",  #6\n    max_length=maximum_tokens,  #6\n    stride=document_overlap,  #6\n    return_overflowing_tokens=True,  #6\n    return_offsets_mapping=True,  #6\n    padding=\"max_length\"  #6\n  ) \n  ...  #7\n  return tokenized_examples\n\ntokenized_datasets = datadict.map(  #8\n  tokenize_dataset,  #8\n  batched=True,  #8\n  remove_columns=datadict[\"train\"].column_names)  #8\n```", "```py\nfrom transformers import RobertaForQuestionAnswering, TrainingArguments,\n                         Trainer, default_data_collator\n\nmodel = RobertaForQuestionAnswering.from_pretrained(\n  \"deepset/roberta-base-squad2\")\n\ntraining_args = TrainingArguments(\n  evaluation_strategy=\"epoch\",  #1\n  num_train_epochs=3,  #2\n  per_device_train_batch_size=16,  #3\n  per_device_eval_batch_size=64,  #4\n  warmup_steps=500,  #5\n  weight_decay=0.01, #6\n  logging_dir=\"data/question-answering/logs\",\n  output_dir=\"data/question-answering/results\")\n\ntrainer = Trainer(\n  model=model,  #7\n  args=training_args,  #8\n  data_collator=default_data_collator,\n  tokenizer=tokenizer,\n  train_dataset=tokenized_datasets[\"train\"], #9\n  eval_dataset=tokenized_datasets[\"test\"])  #10\n```", "```py\ntrainer.train()\nmodel_name = \"data/question-answering/roberta-base-squad2-fine-tuned\"\ntrainer.save_model(model_name)\n```", "```py\n[30/30 00:35, Epoch 3/3]\nEpoch   Training Loss   Validation Loss     Runtime     Samples Per Second\n1       No log          2.177553            1.008200    43.642000\n2       No log          2.011696            1.027800    42.811000\n3       No log          1.938573            1.047700    41.996000\n\nTrainOutput(global_step=30, training_loss=2.531823984781901,\n            metrics={'train_runtime': 37.1978,\n                     'train_samples_per_second': 0.806,\n                     'total_flos': 133766734473216, 'epoch': 3.0})\n```", "```py\nevaluation = trainer.evaluate(eval_dataset=tokenized_datasets[\"validation\"])\ndisplay(evaluation)\n```", "```py\n{\"eval_loss\": 1.7851890325546265,\n \"eval_runtime\": 2.9417,\n \"eval_samples_per_second\": 5.099,\n \"eval_steps_per_second\": 0.34,\n \"epoch\": 3.0}\n```", "```py\ndevice = get_processor_device()\nmodel_name = \"data/question-answering/roberta-base-squad2-fine-tuned\"\nnlp2 = pipeline(\"question-answering\", model=model_name,\n                tokenizer=model_name, device=device)\n```", "```py\ndef answer_questions(examples):\n  answers = []\n  success = 0\n  for example in examples:\n    question = {\"question\": example[\"question\"][0],\n                \"context\": example[\"context\"][0]}\n    answer = nlp2(question)\n    label = example[\"answers\"][0][\"text\"][0]\n    result = answer[\"answer\"]\n    print(question[\"question\"])\n    print(\"Label:\", label)\n    print(\"Result:\", result)\n    print(\"----------\")\n    success += 1 if label == result else 0\n    answers.append(answer)\n  print(f\"{success}/{len(examples)} correct\")\n\ndatadict[\"validation\"].set_format(type=\"pandas\", output_all_columns=True)\nvalidation_examples = [example for example in datadict[\"validation\"]]\nanswer_questions(validation_examples)\n```", "```py\nHow to get pine sap off my teeth\nLabel: Take a small amount of margarine and rub on the sap\nResult: Take a small amount of margarine and rub on the sap\n\nWhy are backpack waist straps so long?\nLabel: The most backpacks have only one size for everyone\nResult: The most backpacks have only one size for everyone\n\n...\n\nHow efficient is the Altai skis \"the Hok\"?\nLabel: you can easily glide in one direction (forward) and if you try to\n       glide backwards, the fur will \"bristle up\"\nResult: you can easily go uphill, without (much) affecting forward gliding performance\n\n7/10 Correct\n```", "```py\nnlp = spacy.load(\"en_core_web_sm\")  #1\nnlp.remove_pipe(\"ner\")\n\ndef get_query_from_question(question):\n  words = [token.text for token in nlp(question)\n           if not (token.lex.is_stop or token.lex.is_punct)]\n  return \" \".join(words)\n\ndef retriever(question):\n  contexts = {\"id\": [], \"question\": [], \"context\": [], \"url\": []}\n  query = get_query_from_question(question) #2\n  request = {\"query\": query,\n             \"query_fields\": [\"body\"],\n             \"return_fields\": [\"id\", \"url\", \"body\"],\n             \"filters\": [(\"post_type\", \"answer\")],  #3\n             \"limit\": 5}\n  docs = outdoors_collection.search(**request)[\"docs\"]\n  for doc in docs:\n    contexts[\"id\"].append(doc[\"id\"])\n    contexts[\"url\"].append(doc[\"url\"])\n    contexts[\"question\"].append(question)\n    contexts[\"context\"].append(doc[\"body\"])\n  return pandas.DataFrame(contexts)\n\nexample_contexts = retriever('What are minimalist shoes?')\ndisplay_contexts(example_contexts)\n```", "```py\nid     question                    context\n18376  What are minimalist shoes?  Minimalist shoes or \"barefoot\" shoes are shoes...\n18370  What are minimalist shoes?  There was actually a project done on the defin...\n16427  What are minimalist shoes?  One summer job, I needed shoes to walk on a ro...\n18375  What are minimalist shoes?  The answer to this question will vary on your...\n13540  What are minimalist shoes?  Barefoot Shoes Also known as minimalist shoes,...\n```", "```py\nfrom transformers import pipeline\n\ndevice = get_processor_device()\nmodel_name = \"data/question-answering/roberta-base-squad2-fine-tuned\"\nqa_nlp = pipeline(\"question-answering\", model=model_name,  #1\n                  tokenizer=model_name, device=device)  #1\n\ndef reader(contexts):\n  answers = []\n  for _, row in contexts.iterrows():  #2\n    answer = qa_nlp({\"question\": row[\"question\"],  #2\n                     \"context\": row[\"context\"]})  #2\n    answer[\"id\"] = row[\"id\"]  #3\n    answer[\"url\"] = row[\"url\"]  #3\n    answers.append(answer)  #2\n  return answers\n```", "```py\ndef reranker(answers):\n  return sorted(answers, key=lambda k: k[\"score\"], reverse=True)\n```", "```py\ndef ask(question):\n  documents = retriever(question)\n  answers = reader(documents)\n  reranked = reranker(answers)\n  print_answer(question, reranked)\n\nask('What is the best mosquito repellent?')\nask('How many miles can a person hike day?')\nask('How much water does a person need per day?')\n```", "```py\nWhat is the best mosquito repellent?\n1116   DEET (0.606)\n1056   thiamine (0.362)\n569    Free-standing bug nets (0.158)\n1076   Insect repellent is not 100% effective (0.057)\n829    bear-spray (0.05)\n\nHow many miles can a person hike day?\n17651 20-25 (0.324)\n19609 12 miles (0.164)\n19558 13 (0.073)\n13030 25-35 (0.065)\n4536 13 miles (0.022)\n\nHow much water does a person need per day?\n1629 3 liters (0.46)\n193 MINIMUM a gallon (0.235)\n20634 0.4 to 0.6 L/day (0.207)\n11679 4 litres (0.084)\n11687 carry water (0.037)\n```"]