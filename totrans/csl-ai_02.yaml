- en: 2 A primer on probabilistic generative modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A primer on probability models
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Computational probability with the pgmpy and Pyro libraries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Statistics for causality: data, populations, and models'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Distinguishing between probability models and subjective Bayesianism
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chapter 1 made the case for learning how to code causal AI. This chapter will
    introduce some fundamentals we need to tackle causal modeling with probabilistic
    machine learning, which roughly refers to machine learning techniques that use
    probability to model uncertainty and simulate data. There is a flexible suite
    of cutting-edge tools for building probabilistic machine learning models. This
    chapter will introduce the concepts from probability, statistics, modeling, inference,
    and even philosophy that we will need in order to implement key ideas from causal
    inference with the probabilistic machine learning approach.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will not provide a mathematically exhaustive introduction to these
    ideas. I’ll focus on what is needed for the rest of this book and omit the rest.
    Any data scientist seeking causal inference expertise should not neglect the practical
    nuances of probability, statistics, machine learning, and computer science. See
    the chapter notes at [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)
    for recommended resources where you can get deeper introductions or review materials.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, I’ll introduce two Python programming libraries for probabilistic
    machine learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '*pgmpy* is a library for building probabilistic graphical models. As a traditional
    graphical modeling tool, it is far less flexible and cutting-edge than Pyro but
    also easier to use and debug. What it does, it does well.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Pyro* is a general probabilistic machine learning library. It is quite flexible,
    and it leverages PyTorch’s cutting-edge gradient-based learning techniques.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pyro and pgmpy are the general modeling libraries we’ll use in this book. Other
    libraries we’ll use are designed specifically for causal inference.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Primer on probability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s review the probability theory you’ll need to work with this book. We’ll
    start with a few basic mathematical axioms and their logical extensions without
    yet adding any real-world interpretation. Let’s begin with the concrete idea of
    a simple three-sided die (these exist).
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.1 Random variables and probability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *random variable* is a variable whose possible values are the numerical outcomes
    of a random phenomenon. These values can be discrete or continuous. In this section,
    we’ll focus on the discrete case. For example, the values of a discrete random
    variable representing a three-sided die roll could be {1, 2, 3}. Alternatively,
    in a 0-indexed programming language like Python, it might be better to use {0,
    1, 2}. Similarly, a discrete random variable representing a coin flip could have
    outcomes {0, 1} or {True, False}. Figure 2.1 illustrates three-sided dice.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F01_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 Three-sided dice each represent a random variable with three discrete
    outcomes.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The typical approach to notation is to write random variables with capitals
    like *X*, *Y*, and *Z*. For example, suppose *X* represents a die roll with outcomes
    {1, 2, 3}, and the outcome represents the number on the side of the die. *X*=1
    and *X*=2 represent the events of rolling a 1 and 2 respectively. If we want to
    abstract away the specific outcome with a variable, we typically use lowercase.
    For example, I would use “*X*=*x*” (e.g., *X*=1) to represent the event “I rolled
    an ‘*x*’!” where *x* can be any value in {1, 2, 3}. See figure 2.2.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F02_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.2 *X* represents the outcome of a three-sided die roll. If the die
    roles a 2, the observed outcome is *X*=2.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Each outcome of a random variable has a *probability value*. The probability
    value is often called a *probability mass* for discrete variables and a *probability
    density* for continuous variables. For discrete variables, probability values
    are between zero and one, and summing up the probability values for each possible
    outcome yields 1\. For continuous variables, probability densities are greater
    than zero, and integrating the probability densities over each possible outcome
    yields 1.
  prefs: []
  type: TYPE_NORMAL
- en: Given a random variable with outcomes {0, 1} representing a coin flip, what
    is the probability value assigned to 0? What about 1? At this point, we just know
    the two values are between zero and one, and that they sum to one. To go beyond
    that, we have to talk about how to *interpret* probability. First, though, let’s
    hash out a few more concepts.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.2 Probability distributions and distribution functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A *probability distribution function* is a function that maps the random variable
    outcomes to a probability value. For example, if the outcome of a coin flip is
    1 (heads) and the probability value is 0.51, the distribution function maps 1
    to 0.51\. I stick to the standard notation *P*(*X*=*x*), as in *P*(*X*=1) = 0.51\.
    For longer expressions, when the random variable is obvious, I drop the capital
    letter and keep the outcome, so *P*(*X*=*x*) becomes *P*(*x*), and *P*(*X*=1)
    becomes *P*(1).
  prefs: []
  type: TYPE_NORMAL
- en: If the random variable has a finite set of discrete outcomes, we can represent
    the probability distribution with a table. For example, a random variable representing
    outcomes {1, 2, 3} might look like figure 2.3.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F03_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.3 A simple tabular representation of a discrete distribution
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In this book, I adopt the common notation *P*(*X*) to represent the probability
    distribution over all possible outcomes of *X*, while *P*(*X*=*x*) represents
    the probability value of a specific outcome. To implement a probability distribution
    as an object in pgmpy, we’ll use the `DiscreteFactor` class.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.1 Implementing a discrete distribution table in pgmpy
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '#1 A list of the names of the variables in the factor'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 The cardinality (number of possible outcomes) of each variable in the factor'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 The values each variable in the factor can take'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 A dictionary, where the key is the variable name and the value is a list
    of the names of that variable’s outcomes'
  prefs: []
  type: TYPE_NORMAL
- en: 'This code prints out the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Setting up your environment
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This code was written with pgmpy version 0.1.24 and Pyro version 1.8.6\. The
    version of pandas used was 1.5.3.
  prefs: []
  type: TYPE_NORMAL
- en: See [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)
    for links to the Jupyter notebooks for each chapter, with the code and notes on
    setting up a working environment.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.3 Joint probability and conditional probability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Often, we are interested in reasoning about more than one random variable. Suppose,
    in addition to the random variable *X* in figure 2.1, there was an additional
    random variable *Y* with two outcomes {0, 1}. Then there is a *joint probability*
    distribution function that maps each combination of *X* and *Y* to a probability
    value.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F04_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.4 A simple representation of a tabular joint probability distribution
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As a table, it could look like figure 2.4.
  prefs: []
  type: TYPE_NORMAL
- en: The `DiscreteFactor` object can represent joint distributions as well.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.2 Modeling a joint distribution in pgmpy
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Now we have two variables instead of one.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 X has 3 outcomes, Y has 2.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Now there are two variables, so we name the outcomes for both variables.'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 You can look at the printed output to see how the values are ordered of
    values.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding code prints this output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Note that the probability values sum to 1\. Further, when we marginalize (i.e.,
    “sum over” or “integrate over”) *Y* across the rows, we recover the original distribution
    *P*(*X*), (aka the marginal distribution of *X*). Summing up over the rows in
    figure 2.5 produces the marginal distribution of *X* on the bottom.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F05_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.5 Marginalizing over *Y* yields the marginal distribution of *X*.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The marginalize method will sum over the specified variables for us.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'This prints the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Setting the `inplace` argument to `False` gives us a new marginalized table
    rather than modifying the original joint distribution table.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F06_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.6 Marginalizing over *X* yields the marginal distribution of *Y*.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Similarly, when we marginalize *X* over the columns, we get *P*(*Y*). In figure
    2.6, summing over the values of *X* in the columns gives us the marginal distribution
    of *Y* on the right.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'This prints the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: I’ll use the notation *P*(*X*, *Y*) to represent joint distributions. I’ll use
    *P*(*X*=*x*, *Y*=*y*) to represent an outcome probability, and for shorthand,
    I’ll write *P*(*x*, *y*). For example, in figure 2.6, *P*(*X*=1, *Y*=0) = *P*(1,
    0) = 0.25\. We can define a joint distribution on any number of variables; if
    there were three variables {*X*, *Y*, *Z*}, I’d write the joint distribution as
    *P*(*X*, *Y*, *Z*).
  prefs: []
  type: TYPE_NORMAL
- en: In this tabular representation of the joint probability distribution, the number
    of cells increases exponentially with each additional variable. There are some
    (but not many) “canonical” joint probability distributions (such as the multivariate
    normal distribution—I’ll show more examples in section 2.1.7). For that reason,
    in multivariate settings, we tend to work with *conditional probability* distributions.
  prefs: []
  type: TYPE_NORMAL
- en: The conditional probability of *Y*, given *X*, is
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch2-eqs-0x.png)'
  prefs: []
  type: TYPE_IMG
- en: Intuitively, *P*(*Y*|*X*=1) refers to the probability distribution for Y conditional
    on *X* being 1\. In the case of tabular representations of distributions, we can
    derive the conditional distribution table by dividing the cells in the joint probability
    distribution table with the marginal probability values, as in figure 2.7\. Note
    that the columns on the conditional probability table in figure 2.7 now sum to
    1\.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F07_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.7 Derive the values of the conditional probability distribution by
    dividing the values of the joint distribution by those of the marginal distribution.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The pgmpy library allows us to do this division using the “/” operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'That line produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, you can directly specify a conditional probability distribution table
    with the `TabularCPD` class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '#1 A conditional distribution has one variable instead of ΔiscreteFactor’s
    list of variables.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 variable_card is the cardinality of Y.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Elements of the list correspond to outcomes for Y. Elements of each list
    correspond to elements of X.'
  prefs: []
  type: TYPE_NORMAL
- en: 'That produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The `variable_card` argument is the cardinality of *Y* (meaning the number of
    outcomes *Y* can take), and `evidence_card` is the cardinality of *X*.
  prefs: []
  type: TYPE_NORMAL
- en: Conditioning as an operation
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In the phrase “conditional probability,” “conditional” is an adjective. It is
    useful to think of “condition” as a verb (an action). You condition a random variable
    like *Y* on another random variable *X*. For example, in figure 2.5, I can condition
    *Y*on *X*=1, and essentially get a new random variable with the same outcome values
    as *Y* but with a probability distribution equivalent to *P*(*Y*|*X*=1).
  prefs: []
  type: TYPE_NORMAL
- en: For those with more programming experience, think of conditioning on *X* = 1
    as filtering on the event *X* == 1; for example, “what is the probability distribution
    of *Y* when *X* == 1?” Filtering in this sense is like the `WHERE` clause in a
    SQL query. *P*(*Y*) is the distribution of the rows in the *Y* table when your
    query is `SELECT` `*` `FROM` `Y`, and *P*(*Y*|*X*=1) is the distribution of the
    rows when your query is `SELECT` `*` `FROM` `Y` `WHERE X=1`.
  prefs: []
  type: TYPE_NORMAL
- en: Thinking of “conditioning” as an action helps us better understand probabilistic
    machine learning libraries. In these libraries, you have objects representing
    random variables, and conditioning is an operation applied to these objects. As
    you’ll see, the idea of conditioning as an action also contrasts nicely with the
    core causal modeling concept of “intervention,” where we “intervene” on a random
    variable.
  prefs: []
  type: TYPE_NORMAL
- en: Pyro implements conditioning as an operation with the `pyro.condition` function.
    We’ll explore this in chapter 3.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.4 The chain rule, the law of total probability, and Bayes Rule
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: From the basic axioms of probability, we can derive the chain rule of probability,
    the law of total probability, and Bayes rule. These laws of probability are especially
    important in the context of probabilistic modeling and causal modeling, so we’ll
    highlight them briefly.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *chain rule of probability* states that we can factorize a joint probability
    into the product of conditional probabilities. For example *P*(*X*, *Y*, *Z*)
    can be factorized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch2-eqs-1x.png)'
  prefs: []
  type: TYPE_IMG
- en: We can factorize in any order we like. Above, the ordering was *X*, then *Y*,
    then *Z*. However, *Y*, then *Z*, then *X*, or *Z*, then *X*, then *Y*, and other
    orderings are just as valid.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch2-eqs-2x.png)'
  prefs: []
  type: TYPE_IMG
- en: The chain rule is important from a modeling and a computational perspective.
    The challenge of implementing a single object that represents *P*(*X*, *Y*, *Z*)
    is that it needs to map each combination of possible outcomes for *X*, *Y*, and
    *Z* to a probability value. The chain rule lets us break this into three separate
    tasks for each factor in a factorization of *P*(*X*, *Y*, *Z*).
  prefs: []
  type: TYPE_NORMAL
- en: The *law of total probability* allows you to relate marginal probability distributions
    (distributions of individual variables) to joint distributions. For example, if
    we want to derive the marginal distribution of *X*, denoted *P*(*X*), from the
    distribution of *X* and *Y*, denoted *P*(*X*, *Y*), we can sum over *Y*.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch2-eqs-3x.png)'
  prefs: []
  type: TYPE_IMG
- en: In figure 2.5, we did this by summing over *Y* in the rows to get *P*(*X*).
    In the case where *X* is a continuous random variable, we integrate over *Y* rather
    than summing over *Y*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we have *Bayes rule*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch2-eqs-4x.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We derive this by taking the original definition of conditional probability
    and applying the chain rule to the numerator:'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch2-eqs-5x.png)'
  prefs: []
  type: TYPE_IMG
- en: By itself, the Bayes rule is not particularly interesting—it’s a derivation.
    The more interesting idea is *Bayesianism*, a philosophy that uses Bayes rule
    to help the modeler reason about their subjective uncertainty regarding the problems
    they are modeling. I’ll touch on this in section 2.4.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.5 Markovian assumptions and Markov kernels
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A common approach to modeling when you have chains of factors is to use *Markovian
    assumptions*. This modeling approach takes an ordering of variables and makes
    a simplifying assumption that every element in the ordering depends only on the
    element that came directly before it. For example, consider again the following
    factorization of *P*(*x*, *y*, *z*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch2-eqs-6x.png)'
  prefs: []
  type: TYPE_IMG
- en: 'If we applied a Markovian assumption, this would simplify to:'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch2-eqs-7x.png)'
  prefs: []
  type: TYPE_IMG
- en: This would let us replace *P*(*z*|*x*, *y*) with *P*(*z*|*y*), which is easier
    to model. In this book, when we have a factor from a factorization that has been
    simplified using the Markov assumption, like *P*(*z*|*y*), we’ll call it a *Markov
    kernel*.
  prefs: []
  type: TYPE_NORMAL
- en: The Markov assumption is a common simplifying assumption in statistics and machine
    learning; *Z* may *actually* still depend on *X* after accounting for *Y*, but
    we’re *assuming* that the dependence is weak and we can safely ignore it in our
    model. We’ll see that the Markovian assumption is key to graphical causality,
    where we’ll assume effects are independent of their indirect causes, given their
    direct causes.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.6 Parameters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Suppose I wanted to implement in code an abstract representation of a probability
    distribution, like the tabular distribution in figure 2.1, that I could use for
    different finite discrete outcomes. To start, if I were to model another three-sided
    die, it might have different probability values. What I want to keep is the basic
    structure as in figure 2.8.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F08_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.8 The scaffolding for a tabular probability distribution data structure
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In code, I could represent this as some object type with a constructor that
    takes two arguments, *ρ*[1] and *ρ*[2], as in figure 2.9 (“*ρ*” is the Greek letter
    “rho”).
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F09_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.9 Adding parameters to the data structure
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The reason the third probability value is a function of the other two (instead
    of a third argument, *ρ*[3]) is because the probability values must sum to one.
    The set of two values {*ρ*[1], *ρ*[2]} are the parameters of the distribution.
    In programming terms, I could create a data type that represents a table with
    three values. Then, when I want a new distribution, I could construct a new instance
    of this type with these two parameters as arguments.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, in my three-sided die example, there were three outcomes, {1, 2, 3}.
    Perhaps I want my data structure to handle a different prespecified number of
    outcomes. In that case, I’d need a parameter for the number of outcomes. Let’s
    denote that with the Greek letter kappa, *Κ*. My parameterization is {*Κ*, *ρ*[1],
    *ρ*[2], … *ρ**[Κ]*[–1]}, where *ρ**[Κ]*is 1 minus the sum of the other *ρ* parameters.
  prefs: []
  type: TYPE_NORMAL
- en: In the pgmpy classes `DiscreteFactor` and `TabularCPD`, the *ρ**’*s (rhos) are
    the list of values passed to the `values` argument, and the *Κ* corresponds to
    the values passed to the `cardinality`, `variable_card`, and `evidence_card` arguments.
    Once we have a representation of a probability distribution like `TabularCPD`,
    we can specify an instance of that distribution with a set of parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Greeks vs. Romans
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In this book, I use Roman letters (*A*, *B*, and *C*) to refer to random variables
    representing objects in the modeling domain, such as a “dice roll” or “gross domestic
    product,” and I use Greek letters for so-called *parameters*. *Parameters* in
    this context are values that characterize the probability distributions of the
    Roman-lettered variables. This distinction between Greeks and Romans is not as
    important in statistics; for example, a Bayesian statistician treats both Roman
    and Greek letters as random variables. However, in causal modeling the difference
    matters, because Roman letters can be causes and effects, while Greek letters
    serve to characterize the statistical relationship between causes and effects.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.7 Canonical classes of probability distribution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are several common classes of distribution functions. For example, the
    tabular examples we just studied are examples from the class of *categorical distributions*.
    Categorical distributions are distributions on discrete outcomes we can view as
    categories, such as {“ice cream”, “frozen yogurt”, “sherbet”}. A Bernoulli distribution
    class is a special case of the categorical class where there are only two possible
    outcomes. A discrete uniform distribution is a categorical distribution where
    all outcomes have the same probability. In implementation, categorical distributions
    are defined either on the categories directly (like “tails” and “heads”) or on
    indices to the category (like 0 and 1).
  prefs: []
  type: TYPE_NORMAL
- en: Discrete vs. continuous random variables
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: For discrete random variables, we have been using have probability distribution
    functions with the notation *P*(*X*=*x*). Probability distribution functions return
    the probability that a variable takes a specific value. With continuous random
    variables, we also have *probability density functions*, which describe the relative
    likelihood of observing any outcome within a continuous range and that integrate
    over an interval to give a probability.
  prefs: []
  type: TYPE_NORMAL
- en: When we have specific cases where discrete or continuous parameterizations matter,
    we’ll call them out and use *p*(*X*=*x*) to denote a probability density function.
    However, in this book, we’ll focus on framing our causal questions independently
    of whether we’re in a discrete or continuous setting. We’ll stick mostly to the
    probability distribution function notation *P*(*X*=*x*), but keep in mind that
    the causal ideas work in the continuous case as well.
  prefs: []
  type: TYPE_NORMAL
- en: There are other canonical distribution classes appropriate for continuous, bounded,
    or unbounded sets of variables. For example, the normal (Gaussian) distribution
    class illustrates the famous “bell curve.” I use the term “class” (or, perhaps
    more ideally, “type”) in the computer science sense because the distribution isn’t
    realized until we assign our Greek-lettered parameters. For a normal (Gaussian)
    distribution class, the probability density function is
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch2-eqs-8x.png)'
  prefs: []
  type: TYPE_IMG
- en: Here, *μ* and *σ* are the parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.10 is a popular figure that illustrates several commonly used canonical
    distributions. The arrows between the distributions highlight relationships between
    the distributions (e.g., Bernoulli is a special case of the binomial distribution)
    that we won’t dive into here.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F10_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.10 A popular common set of canonical probability distributions. The
    edges capture mathematical relationships between the distributions (that we won’t
    get into here). Light-colored distributions are discrete and dark-colored distributions
    are continuous. An arrow represents the existence of a transformation that converts
    one distribution to another.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Types of parameters
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In probabilistic modeling settings, it is useful to have an intuition for how
    to interpret canonical parameters. To that end, think of the probability in a
    distribution as a scarce resource that must be shared across all the possible
    outcomes. Some outcomes may get more than others, but at the end of the day, it
    all must sum or integrate to 1\. Parameters characterize how the finite probability
    is distributed to the outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: As an analogy, we’ll use a city with a fixed population. The parameters of the
    city determine where that population is situated. Location parameters, such as
    the normal distribution’s “*μ*” (*μ* is the mean of the normal, but not all *location
    parameters* are means), are like the pin that drops down when you search the city’s
    name in Google Maps. The pin characterizes a precise point we might call the “city
    center.” In some cities, most of the people live near the city center, and it
    gets less populated the further away from the center you go. But in other cities,
    other non-central parts of the city are densely populated. *Scale parameters*,
    like the normal’s “*σ*” (*σ* is the standard deviation of a normal distribution,
    but not all scale parameters are standard deviation parameters), determine the
    spread of the population; Los Angeles has a high scale parameter. A *shape parameter*
    (and its inverse, the *rate parameter*) affects the shape of a distribution in
    a manner that does not simply shift it (as a location parameter does) or stretch
    or shrink it (as a scale parameter does). As an example, think of the skewed shape
    of Hong Kong, which has a densely packed collection of skyscrapers in the downtown
    area, while the more residential Kowloon has shorter buildings spread over a wider
    space.
  prefs: []
  type: TYPE_NORMAL
- en: The Pyro library provides canonical distributions as modeling primitives. The
    Pyro analog to a discrete categorical distribution table is a `Categorical` object.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.3 Canonical parameters in Pyro
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Pyro includes the commonly used canonical distributions.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 The Categorical distribution takes a list of probability values, each value
    corresponding to an outcome.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This prints the following representations of the distribution objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Rather than providing a probability value, the `log_prob` method will provide
    the natural log of the probability value, because log probabilities have computational
    advantages over regular probabilities. Exponentiating (taking *e*^(*l*) where
    *l* is the log probability) converts back to the probability scale. For example,
    we can create a Bernoulli distribution object with a parameter value of 0.4.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: That distribution assigns a 0.4 probability to the value 1.0\. For numerical
    reasons, we typically work with the natural log of probability values.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the `exp` function in the math library to convert from log probability
    back to the probability scale:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Exponentiating the log probability returns the following probability value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: It is close, but not the same as 0.4 due to rounding error associated with floating-point
    precision in computer calculations.
  prefs: []
  type: TYPE_NORMAL
- en: Conditional probability with canonical distributions
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: There are few canonical distributions commonly used to characterize sets of
    individual random variables, such as random vectors or matrices. However, we can
    use the chain rule to factor a joint probability distribution into conditional
    distributions that we can represent with canonical distributions. For example,
    we could represent *Y* conditioned on *X* and *Z* with the following normal distribution,
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch2-eqs-9x.png)'
  prefs: []
  type: TYPE_IMG
- en: 'where the location parameter *μ*(*x*,*z*) is a function of *x* and *z*. An
    example is the following linear function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch2-eqs-10x.png)'
  prefs: []
  type: TYPE_IMG
- en: Other functions, such as neural networks, are possible as well. These *β* parameters
    are typically called *weight parameters* in machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.8 Visualizing distributions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In probabilistic modeling and Bayesian inference settings, we commonly conceptualize
    distributions in terms of visuals. In the discrete case, a common visualization
    is the bar plot. For example, we can visualize the probabilities in figure 2.3
    as the bar plot in figure 2.11\. Note that this is not a histogram; I’ll highlight
    the distinction in section 2.3.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F11_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.11 Visualization of a discrete probability distribution. The outcomes
    in the distribution are on the horizontal axis, and probability is on the vertical
    axis.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'We still use visualizations when the distribution has a non-finite set of outcomes.
    For example, figure 2.12 overlays two distributions functions: a discrete Poisson
    distribution and a continuous normal (Gaussian) distribution (I specified the
    two distributions in such a way that they overlapped). The discrete Poisson has
    no upper bound on outcomes (its lower bound is 0), but the probability tapers
    off for higher numbers, resulting in smaller and smaller bars until the bar becomes
    too infinitesimally small to draw. We visualize the normal distribution by simply
    drawing the probability distribution function as a curve in the figure. The normal
    has no lower or upper bound, but the further away you get from the center, the
    smaller the probability values get.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F12_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.12 A continuous normal distribution (solid line) approximates a discrete
    Poisson distribution (gray bars). Again, the outcomes are on the horizontal axis,
    and the probability values are on the vertical axis.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Visualizing conditional probability distributions involves mapping each conditioning
    variable to some element in the image. For example, in figure 2.13, *X* is discrete,
    and *Y* conditioned on *X* has a normal distribution where the location parameter
    is a function of *X*.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F13_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.13 A visualization of the conditional probability distribution of continuous
    *Y*, given discrete *X*. For different values of *X*, we get a different distribution
    of *Y*.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Since *X* is discrete, it is simplest to map *X* to color and overlay the curves
    for *P*(*Y*|*X*=1), *P*(*Y*|*X*=2), and *P*(*Y*|*X*=3). However, if we wanted
    to visualize *P*(*Y*|*X*, *Z*), we’d need to map *Z* to an aesthetic element other
    than color, such as a third axis in a pseudo-3D image or rows in a grid of images.
    But there is only so much information we can add to a 2D visualization. Fortunately,
    conditional independence helps us reduce the number of conditioning variables.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.9 Independence and conditional independence
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Two random variables are *independent* if, informally speaking, observing an
    outcome of one random variable does not affect the probability of outcomes for
    the other variable, i.e., *P*(*y*|*x*)*=**P*(*y*). We denote this as *X* ⊥ *Y*.
    If two variables are not independent, they are *dependent*.
  prefs: []
  type: TYPE_NORMAL
- en: Two dependent variables can become *conditionally independent* given other variables.
    For example, *X* ⊥ *Y* | *Z* means that *X* and *Y* may be dependent, but they
    are conditionally independent given *Z*. In other words, if *X* and *Y* are dependent,
    and *X* ⊥ *Y* | *Z*, then it is not true that *P*(*y*|*x*) ≠ *P*(*y*) but it is
    true that *P*(*y*|*x*, *z*) = *P*(*y*|*z*).
  prefs: []
  type: TYPE_NORMAL
- en: Independence is a powerful tool for simplification
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Independence is a powerful tool for simplifying representations of probability
    distributions. Consider a joint probability distribution *P*(*W*, *X*, *Y*, *Z*)
    represented as a table. The number of cells in the table would be the product
    of the number of possible outcomes each for *W*, *X*, *Y*, and *Z*. We could use
    the chain rule to break the problem up into factors {*P*(*W*), *P*(*X*|*W*), *P*(*Y*|*X*,
    *W*), *P*(*Z*|*Y*, *X*, *W*)}, but the total number of parameters across these
    factors wouldn’t change, so the aggregate complexity would be the same.
  prefs: []
  type: TYPE_NORMAL
- en: However, what if *X* ⊥ *W*? Then *P*(*X*|*W*) reduces to *P*(*X*). What if *Z*
    ⊥ *Y*|*X*? Then *P*(*Z*|*Y*, *X*, *W*) reduces to *P*(*Z*|*X*, *W*). Every time
    we can impose a pairwise conditional independence condition as a constraint on
    the joint probability distribution, we can reduce the complexity of the distribution
    by a large amount. Indeed, much of model building and evaluation in statistical
    modeling, regularization in machine learning, and deep learning techniques such
    as “drop-out” are either direct or implicit attempts to impose conditional independence
    on the joint probability distribution underlying the data.
  prefs: []
  type: TYPE_NORMAL
- en: Conditional independence and causality
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Conditional independence is fundamental to causal modeling. Causal relationships
    lead to conditional independence between correlated variables. For example, a
    child’s parents’ and grandparents’ blood types are all causes of that child’s
    blood type; these blood types are all correlated. But all you need is the parents’
    blood type, the direct causes, to fully determine the child’s blood type, as illustrated
    in figure 2.14\. In probabilistic terms, the child’s and grandparents’ blood types
    are conditionally independent, given the parents.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F14_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.14 How causality can induce conditional independence. The blood types
    of the parents cause the blood type of the child. The grandfather’s blood type
    is correlated with that of the child’s (dashed line). But the parents’ blood types
    are direct causes that fully determine that of the child. These direct causes
    render the child’s and grandfather’s blood types conditionally independent.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The fact that causality induces conditional independence allows us to learn
    and validate causal models against evidence of conditional independence. In chapter
    4, we’ll explore the relationship between conditional independence and causality
    in formal terms.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1.10 Expected value
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The *expected value* of a function of a random variable is the weighted average
    of the function’s possible output values, where the weight is the probability
    of that outcome.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch2-eqs-11x.png)![figure](../Images/ness-ch2-eqs-12x.png)'
  prefs: []
  type: TYPE_IMG
- en: In the case of a continuum of possible outcomes, the expectation is defined
    by integration.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch2-eqs-13x.png)![figure](../Images/ness-ch2-eqs-14x.png)'
  prefs: []
  type: TYPE_IMG
- en: Some of the causal quantities we’ll be interested in calculating will be defined
    in terms of expectation. Those quantities only reason about the expectation, not
    about how the expectation is calculated. It is easier to get an intuition for
    a problem when working with the basic arithmetic of discrete expectation rather
    than integral calculus in the continuous case. So, in this book, when there is
    a choice, I use examples with discrete random variables and discrete expectation.
    The causal logic in those examples all generalize to the continuous case.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many interesting mathematical properties of expectation. In this
    book, we care about the fact that conditional expectations simplify under conditional
    independence: If *X* ⊥ *Y*, then *E*(*X*|*Y*) = *E*(*X*). If *X* ⊥ *Y*|*Z*, then
    *E*(*X*|*Y*,*Z*) = *E*(*X*|*Z*). In simpler terms, if two variables (*X* and *Y*)
    are independent, our expectation for one does not change with information about
    the other. If their independence holds conditional on a third variable (*Z*),
    our expectation for one, given that we know the third variable, is unaffected
    by information about the other variable.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Other than this, the most important property is the linearity of the expectation,
    meaning that the expectation passes through linear functions. Here are some useful
    reference examples of the linearity of expectation:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For random variables *X* and *Y*: *E*(*X* + *Y*) = *E*(*X*) + *E*(*Y*) and'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch2-eqs-15x.png)'
  prefs: []
  type: TYPE_IMG
- en: 'For constants *a* and *b*: *E*(*aX* + *b*) = *aE*(*X*) + *b*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If *X* only has outcomes 0 and 1, and *E*(*Y*|*X*) = *aX* + *b*, then *E*(*Y*|*X*=1)
    – *E*(*Y*|*X*=0) = *a*. (This is true because *a**1 + *b* – (*a**0 + *b*) = *a*.
    Spoiler alert: this one is important for linear regression-based causal effect
    inference techniques.)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The mean of the random variable’s distribution is the expected value of the
    variable itself, as in *E*(*X*) (i.e., the function is the *identity function*,
    *f*(*X*) = *X*). In several canonical distributions, the mean is a simple function
    of the parameters. In some cases, such as in the normal distribution, the location
    parameter is equivalent to the expectation. But the location parameter and the
    expectation are not always the same. For example, the Cauchy distribution has
    a location parameter, but its mean is undefined.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, you’ll learn how to represent distributions and calculate
    expectations using computational methods.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Computational probability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We need to *code* probability distributions and expectations from probability
    to use them in our models. In the previous section, you saw how to code up a probability
    distribution for a three-sided die. But how do we code up *rolling* a three-sided
    die? How do we write code representing two dice rolls that are conditionally independent?
    While we’re at it, how do we get a computer to do the math that calculates an
    expectation? How do we get a computer, where everything is deterministic, to roll
    dice so that the outcome is unknown beforehand?
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.1 The physical interpretation of probability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Suppose I have a three-sided die. I have some probability values assigned to
    each outcome on the die. What do those probability values mean? How do I interpret
    them?
  prefs: []
  type: TYPE_NORMAL
- en: Suppose I repeatedly rolled the die and kept a running tally of how many times
    I saw each outcome. First, the roll is random, meaning that although I roll it
    the same way each time, I get varying results. The physical shape of the die affects
    those tallies; if one face of the die is larger than the other two, that size
    difference will affect the count. As I repeat the roll many times, the proportion
    of total times I see a given outcome converges to a number. Suppose I use that
    number for my probability value. Further, suppose I interpret that number as the
    “chance” of seeing that outcome each time I roll.
  prefs: []
  type: TYPE_NORMAL
- en: This idea is called *physical* (or *frequentist*) *probability*. Physical probability
    means imagining some repeatable physical random process that results in one outcome
    among a set of possible outcomes. We assign a probability value using the convergent
    proportion of times the outcome appears when we repeat the random process ad infinitum.
    We then interpret that probability as the propensity for that physical process
    to produce that outcome.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.2 Random generation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Given the preceding definition for physical probability, we can define random
    generation. In *random generation*, an algorithm randomly chooses an outcome from
    a given distribution. The algorithm’s choice is inspired by physical probability;
    the way it selects an outcome is such that if we ran the algorithm ad infinitum,
    the proportion of times it would choose that outcome would equal the distribution’s
    probability value for that outcome.
  prefs: []
  type: TYPE_NORMAL
- en: Computers are deterministic machines. If we repeatedly run a computer procedure
    on the same input, it will always return the same output; it cannot produce anything
    genuinely random (unless it has a random input). Computers have to use deterministic
    algorithms to emulate random generation. These algorithms are called pseudo-random
    number generators—they take a starting number, called a *random seed*, and return
    a deterministic series of numbers. Those algorithms mathematically guarantee that
    a series of numbers is statistically indistinguishable from the ideal of random
    generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'In notation, I write random generation as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch2-eqs-16x.png)'
  prefs: []
  type: TYPE_IMG
- en: This reads as “x is generated from the probability distribution of *X*.”
  prefs: []
  type: TYPE_NORMAL
- en: 'In random generation, synonyms for “generate” include “simulate” and “sample.”
    For example, in pgmpy the `sample` method in `DiscreteFactor` does random generation.
    It returns a pandas DataFrame. Note that since this is random generation, you
    will likely get different outputs when you run this code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch2-eqs-17x.png)'
  prefs: []
  type: TYPE_IMG
- en: Listing 2.4 Simulating random variates from `DiscreteFactor` in pgmpy
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '#1 n is the number of instances you wish to generate.'
  prefs: []
  type: TYPE_NORMAL
- en: This produces the table pictured in figure 2.15.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F15_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.15 Generating one instance from *P*(*X*) creates a pandas `DataFrame`
    object with one row.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: We can also generate from joint probability distributions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This produces the table pictured in figure 2.16.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F16_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.16 Generating one instance from *P*(*X**,* *Y*) creates a pandas `DataFrame`
    object with one row.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Pyro also has a `sample` method for canonical distributions:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: This generates a sample from that categorical distribution, i.e., either 0,
    1, or 2\.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 2.2.3 Coding random processes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We can write our own random processes as code when we want to generate values
    in a particular way. A random process written as code is sometimes called a *stochastic
    function*, *probabilistic subroutine*, or *probabilistic program*. For example,
    consider the joint probability distribution *P*(*X*, *Y*, *Z*). How can we randomly
    generate from this joint distribution? Unfortunately, software libraries don’t
    usually provide pseudo-random generation for arbitrary joint distributions.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can get around this by applying the chain rule and, if it exists, conditional
    independence. For example, we could factorize as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch2-eqs-18x.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Suppose that *Y* is conditionally independent of *Z* given *X*, then:'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch2-eqs-19x.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Finally, suppose we can sample from *P*(*Z*), *P*(*X*|*Z*), and *P*(*Y*|*X*)
    given the basic random generation functions in our software library. Then we can
    use this factorization to compose an algorithm for sampling:'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch2-eqs-20x.png)'
  prefs: []
  type: TYPE_IMG
- en: This is a random process that we can execute in code. First, we generate a *Z*-outcome
    *z* from *P*(*Z*). We then condition *X* on that *z*, and generate an *X*-outcome
    *x*. We do the same to generate a *Y*-outcome *y*. Finally, this procedure generates
    a tuple {*x*, *y*, *z*} from the joint distribution *P*(*X*, *Y*, *Z*).
  prefs: []
  type: TYPE_NORMAL
- en: In pgmpy, we can create a random process using the class called `BayesianNetwork`.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.5 Creating a random process in pgmpy and Pyro
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: '#1 P(Z)'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 P(X|Z=z)'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 P(X|Z=z)'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 P(Y|X=x)'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Create a BayesianNetwork object. The arguments are edges of a directed graph,
    which we’ll cover in chapter 3.'
  prefs: []
  type: TYPE_NORMAL
- en: '#6 Add the conditional probability distributions to the model.'
  prefs: []
  type: TYPE_NORMAL
- en: '#7 Create a BayesianModelSampling object from the BayesianNetwork object.'
  prefs: []
  type: TYPE_NORMAL
- en: '#8 Sample from the resulting object'
  prefs: []
  type: TYPE_NORMAL
- en: This produces one row in a pandas DataFrame, shown in figure 2.17.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F17_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.17 The `forward_sample` method simulates one instance of *X*, *Y*,
    and *Z* as a row in a pandas DataFrame.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Implementing random processes for random generation is powerful because it allows
    generating from joint distributions that we can’t represent in clear mathematical
    terms or as a single canonical distribution. For example, while pgmpy works well
    with categorical distributions, Pyro gives us the flexibility of working with
    combinations of canonical distributions.
  prefs: []
  type: TYPE_NORMAL
- en: The following listing shows a Pyro version of the previous random process. It
    has the same dependence between *Z*, *X*, and *Y*, but different canonical distributions.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.6 Working with combinations of canonical distributions in Pyro
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Represent P(Z) with a gamma distribution, and sample z.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Represent P(X|Z=z) with a Poisson distribution with location parameter z,
    and sample x.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Represent P(Y|X=x) with a Bernoulli distribution. The probability parameter
    is a function of x.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This prints out a sample set, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '*Z* comes from a gamma distribution, *X* from a Poisson distribution with mean
    parameter set to *z*, and *Y* from a Bernoulli distribution with its parameter
    set to a function of *x*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Implementing a random function with a programming language lets us use nuanced
    conditional control flow. Consider the following pseudocode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '#1 We can use control flow, like this for loop, to generate values.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 y is the sum of the values generated in the for loop. y still depends on
    x, but through nuanced control flow.'
  prefs: []
  type: TYPE_NORMAL
- en: Here, *y* is still dependent on *x*. However, it is defined as the sum of *x*
    individual random components. In Pyro, we might implement this as follows.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.7 Random processes with nuanced control flow in Pyro
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '#1 y is defined as a sum of random coin flips, so y is generated from P(Y|X=x)
    because the number of flips depends on x.'
  prefs: []
  type: TYPE_NORMAL
- en: In Pyro, best practice is to implement random processes as functions. Further,
    use the function `pyro.sample` to generate, rather than using the `sample` method
    on distribution objects. We could rewrite the preceding `random_process` code
    (listing 2.7) as follows.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.8 Using functions for random processes and `pyro.sample`
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '#1 f"y{i}" creates the names "y1", "y2", etc.'
  prefs: []
  type: TYPE_NORMAL
- en: The first argument in `pyro.sample` is a string that assigns a name to the variable
    you are sampling. The reason for that will become apparent when we start running
    inference algorithms in Pyro in chapter 3\.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.4 Monte Carlo simulation and expectation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Monte Carlo algorithms* use random generation to estimate expectations from
    a distribution of interest. The idea is simple. You have some way of generating
    from *P*(*X*). If you want *E*(*X*), generate multiple *x*’s, and take the average
    of those *x*’s. If you want *E*(*f*(*X*)), generate multiple *x*’s and apply the
    function *f*(.) to each of those *x*’s, and take the average. Monte Carlo works
    even in cases when *X* is continuous.'
  prefs: []
  type: TYPE_NORMAL
- en: In pgmpy, you use the `sample` or `forward_sample` methods to generate a pandas
    DataFrame. You can then calculate the panda’s `mean` method.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'In Pyro, we call the `random_process` function repeatedly. We can do this for
    the preceding Pyro generator with a `for` loop that generates 100 samples:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: This code repeatedly calls `random_process` in a Python list comprehension.
    Recall that Pyro extends PyTorch, and the value of y it returns is a tensor. I
    use `torch.stack` to turn this list of tensors into a single tensor. Finally,
    I call the `mean` method on the tensor to obtain the Monte Carlo estimate of *E*(*Y*).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: When I ran this code, I got a value of about 3.78, but you’ll likely get something
    slightly different.
  prefs: []
  type: TYPE_NORMAL
- en: Most things you’d want to know about a distribution can be framed in terms of
    some function *f*(*X*). For example, if you wanted to know the probability of
    *X* being greater than 10, you could simply generate a bunch of *x*’s and convert
    each *x* to 1 if it is greater than 10 and 0 otherwise. Then you’d take the average
    of the 1’s and 0’s, and the resulting value would estimate the desired probability.
  prefs: []
  type: TYPE_NORMAL
- en: To illustrate, the following code extends the previous block to calculate *E*(*Y*²).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: When calculating *E*(*f*(*X*)) for a random variable *X*, remember to get the
    Monte Carlo estimate by applying the function to the samples first, and then take
    the average. If you apply the function to the sample average, you’ll instead get
    an estimate of *f*(*E*(*X*)), which is almost always different.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.5 Programming probabilistic inference
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Suppose we implement in code a random process that generates an outcome {*x*,
    *y*, *z*} from *P*(*X*, *Y*, *Z*) as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch2-eqs-20x.png)'
  prefs: []
  type: TYPE_IMG
- en: Further, suppose we are interested in generating from *P*(*Z*|*Y*=3). How might
    we do this? Our process can sample from *P*(*Z*), *P*(*X*|*Z*), and *P*(*Y*|*Z*),
    but it is not clear how we go from these to *P*(*Z*|*Y*).
  prefs: []
  type: TYPE_NORMAL
- en: '*Probabilistic inference algorithms* generally take an outcome-generating random
    process and some target distribution as inputs. Then, they return a means of generating
    from that target distribution. This class of algorithms is often called Bayesian
    inference algorithms because the algorithms often use Bayes rule to go from *P*(*Y*|*Z*)
    to *P*(*Z*|*Y*). However, the connection to Bayes rule is not always explicit,
    so I prefer “probabilistic inference” over “Bayesian inference algorithms.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, a simple class of probabilistic inference algorithms is called
    accept/reject algorithms. Applying a simple accept/reject technique to generating
    from *P*(*Z*|*Y*=3) works as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Repeatedly generate {*x*, *y*, *z*} using our generator for *P*(*X*, *Y*, *Z*).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Throw away any generated outcome where *y* is not equal to 3\.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The resulting set of outcomes for *Z* will have the distribution *P*(*Z*|*Y*=3).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Illustrating with Pyro, let’s rewrite the previous `random_process` function
    to return *z* and *y*. After that, we’ll obtain a Monte Carlo estimate of *E*(*Z*|*Y*=3).
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.9 Monte Carlo estimation in Pyro
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '#1 This new version of random_process returns both z and y.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Generate 1000 instances of z and y using a list comprehension.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 Turn the individual z tensors into a single tensor, and then calculate the
    Monte Carlo estimate via the mean method.'
  prefs: []
  type: TYPE_NORMAL
- en: This code estimates *E*(*Z*). Since *Z* is simulated from a gamma distribution,
    the true mean *E*(*Z*) is the shape parameter 7.5 divided by the rate parameter
    1.0, which is 7.5\.
  prefs: []
  type: TYPE_NORMAL
- en: Now, to estimate *E*(*Z*|*Y*=3), we’ll filter the samples and keep only the
    samples where *Y* is 3.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'One run of this code produced `tensor(6.9088)`, but your result might be slightly
    different. That probabilistic inference algorithm works well if the outcome *Y*=3
    occurs frequently. If that outcome were rare, the algorithm would be inefficient:
    we’d have to generate many samples to get samples that meet the condition, and
    we’d be throwing away many samples.'
  prefs: []
  type: TYPE_NORMAL
- en: There are various other algorithms for probabilistic inference, but the topic
    is too rich and tangential to causal modeling for us to explore in depth. Nevertheless,
    the following algorithms are worth mentioning for what we cover in this book.
    Visit [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)
    for links to some complementary materials on inference with pgmpy and Pyro.
  prefs: []
  type: TYPE_NORMAL
- en: Probability weighting methods
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: These methods generate outcomes from a joint probability distribution and then
    weight them according to their probability in the target distribution. We can
    then use the weights to do weighted averaging via Monte Carlo estimation. Popular
    variants of this kind of inference include importance sampling and inverse probability
    reweighting, the latter of which is popular in causal inference and is covered
    in chapter 11.
  prefs: []
  type: TYPE_NORMAL
- en: Inference with probabilistic graphical models
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Probabilistic graphical models use graphs to represent conditional independence
    in a joint probability distribution. The presence of a graph enables graph-based
    algorithms to power inference. Two well-known approaches include variable elimination
    and belief propagation. In figures 2.5 and 2.6, I showed that you could “eliminate”
    a variable by summing over its columns or rows in the probability table. Variable
    elimination uses the graph structure to optimally sum over the variables you wish
    to eliminate until the resulting table represents the target distribution. In
    contrast, belief propagation is a message-passing system; the graph is used to
    form different “cliques” of neighboring variables. For example, if *P*(*Z*|*Y*=1)
    is the target distribution, *Y*=1 is a message iteratively passed back and forth
    between cliques. Each time a message is received, parameters in the clique are
    updated, and the message is passed on. Eventually, the algorithm converges, and
    we can derive a new distribution for *Z* from those updated parameters.
  prefs: []
  type: TYPE_NORMAL
- en: One of the attractive features of graph-based probabilistic inference is that
    users typically don’t implement them themselves; software like pgmpy does it for
    you. There are theoretical caveats, but they usually don’t matter in practice.
    This feature is an example of the “commodification of inference” trend I highlighted
    in chapter 1\. In this book, we’ll work with causal graphical models, a special
    type of probabilistic graphical model that works as a causal model. That gives
    us the option of applying graph-based inference for causal problems.
  prefs: []
  type: TYPE_NORMAL
- en: Variational inference
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In *variational inference*, we write code for a new stochastic process that
    generates samples from an “approximating distribution” that resembles the target
    distribution. That stochastic process has parameters that we optimize using gradient-based
    techniques now common in deep learning software. The objective function of the
    optimization tries to minimize the difference between the approximating distribution
    and the target distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Pyro is a probabilistic modeling language that treats variational inference
    as a principal inference technique. It calls the stochastic process that generates
    from the approximating distribution a “guide function,” and a savvy Pyro programmer
    gets good at writing guide functions. However, it also provides a suite of tools
    for “automatic guide generation,” another example of the commodification of inference.
  prefs: []
  type: TYPE_NORMAL
- en: Markov chain Monte Carlo
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Markov chain Monte Carlo* (MCMC) is an inference algorithm popular amongst
    computational Bayesians. These are accept/reject algorithms where each newly generated
    outcome depends on the previous (non-rejected) generated outcome. This produces
    a chain of outcomes, and the distribution of outcomes in the chain eventually
    converges to the target distribution. *Hamiltonian Monte Carlo* (HMC) is a popular
    version that doesn’t require users to implement the generator. Pyro, and similar
    libraries, such as PyMC, implement HMC and other MCMC algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: Advanced Inference Methods
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Research in generative models continues to develop new inference techniques.
    Examples include techniques such adversarial inference, inference with normalizing
    flows, and diffusion-based inference. The goal of such techniques are to efficiently
    sample from the complex distributions common in machine learning problems. Again,
    see [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)
    for references. We’ll see an example of a structural causal model that leverages
    normalizing flows in chapter 6\. The approach taken in this book is to leverage
    the “commodification of inference” trend discussed in chapter 1, such that we
    can build causal models that leverage these algorithms, as well as new algorithms
    as they are released.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 Data, populations, statistics, and models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we have talked about random variables and distributions. Now we’ll move
    on to data and statistics. Let’s start with defining some terms. You doubtless
    have an idea of what data is, but let’s define it in terms we’ve already defined
    in this chapter. *Data* is a set of recorded outcomes of a random variable or
    set of random variables. A *statistic* is anything you calculate from data. For
    example, when you train a neural network on training data, the learned weight
    parameter values are statistics, and so are the model’s predictions (since they
    depend on the training data via the weights).
  prefs: []
  type: TYPE_NORMAL
- en: The real-world causal process that generates a particular stream of data is
    called the *data generating process* (DGP). A *model* is a simplified mathematical
    description of that process. A *statistical model* is a model with parameters
    tuned such that the model aligns with statistical patterns in the data.
  prefs: []
  type: TYPE_NORMAL
- en: This section presents some of the core concepts related to data and statistics
    needed to make sense of this book.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.1 Probability distributions as models for populations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In applied statistics, we take statistical insights from data and generalize
    them to a population. Consider, for example, the MNIST digit classification problem
    described in chapter 1\. Suppose the goal of training a classification model on
    MNIST data was to deploy the model in software that digitizes written text documents.
    In this case, the population is all the digits on all the texts the software will
    see in the future.
  prefs: []
  type: TYPE_NORMAL
- en: Populations are heterogeneous, meaning members of the population vary. While
    a feature on a website might drive engagement among the population of users, on
    average, the feature might make some subpopulation of users less engaged, so you
    would want to target the feature to the right subpopulations. Marketers call this
    “segmentation.”
  prefs: []
  type: TYPE_NORMAL
- en: In another example, a medicine might not be much help on average for a broad
    population of patients, but there some subpopulation might experience benefits.
    Targeting those subpopulations is the goal of the field of precision medicine.
  prefs: []
  type: TYPE_NORMAL
- en: In probabilistic models, we use probability distributions to model populations.
    It is particularly useful to target subpopulations with conditional probability.
    For example, suppose *P*(*E*|*F*=True) represents the distribution of engagement
    numbers among all users exposed to a website feature. Then *P*(*E*|*F*=True, *G*="millennial")
    represents the subpopulation of users exposed to the feature who are also millennials.
  prefs: []
  type: TYPE_NORMAL
- en: Canonical distributions and stochastic processes as models of populations
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If we use probability distributions to model populations, what canonical distributions
    should we use for a given population? Figure 2.18 includes common distributions
    and the phenomena they typically model.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F18_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.18 Examples of common canonical distributions and the types of phenomena
    and data they typically model
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: These choices don’t come from nowhere. The canonical distributions are themselves
    derived from stochastic functions. For example, the binomial distribution is the
    result of a process where you do a series of coin flips. When something is the
    result of adding together a bunch of independent (or weakly dependent) small changes,
    you get a normal distribution. Waiting time distributions capture the distribution
    of the amount of time one must wait for an event (e.g., a device failure or a
    car accident). The exponential distribution is appropriate for waiting times when
    the amount of time you’ve already been waiting has no bearing on how much time
    you still must wait (e.g., for the amount of time it takes a radioactive atom
    to decay). If the time to event has an exponential distribution, the number of
    times that event has occurred within a fixed time period has a Poisson distribution.
  prefs: []
  type: TYPE_NORMAL
- en: A useful trick in probabilistic modeling is to think of the stochastic process
    that created your target population. Then either choose the appropriate canonical
    distribution or implement the stochastic process in code using various canonical
    distributions as primitives in the code logic. In this book, we’ll see that this
    line of reasoning aligns well with causal modeling.
  prefs: []
  type: TYPE_NORMAL
- en: Sampling, IID, and generation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Usually, our data is not the whole population but a small subset from the population.
    The act of randomly choosing an individual is called *sampling*. When the data
    is created by repeatedly sampling from the population, the resulting dataset is
    called a *random sample*. If we can view data as a *random sample*, we call that
    data *independent and identically distributed (IID)*. That means that the selection
    of each individual data point is *identical* in how it was sampled, and each sampling
    occurred *independently* of the others, and they all were sampled from the same
    population distribution. Figure 2.19 illustrates how an IID random sample is selected
    from a population.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F19_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.19 Creating a random sample by random selection from a population.
    Individuals are randomly selected from the population such that the sample distribution
    resembles the population distribution. The sample is identically and independently
    distributed (IID), meaning that sample members are selected the same way, and
    whether an individual is selected doesn’t depend on whether another individual
    was selected.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The idea of sampling and IID data illustrates the second benefit of using probability
    distributions to model populations. We can use generation from that distribution
    to model sampling from a population. We can implement a stochastic process that
    represents the DGP by first writing a stochastic process that represents the population
    and then composing it with a process that generates data from the population process,
    emulating IID sampling.
  prefs: []
  type: TYPE_NORMAL
- en: In pgmpy, this is as simple as generating more than one sample.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: This produces the table showing in figure 2.20
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F20_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.20 A pandas DataFrame created by generating ten data points from a
    model in pgmpy
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The Pyro approach for IID sampling is `pyro.plate`.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.10 Generating IID samples in Pyro
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '#1 pyro.plate is a context manager for generating conditionally independent
    samples. This instance of pyro.plate will generate 10 IIΔ samples.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Calling pyro.sample generates a single outcome y, where y is a tensor of
    10 IIΔ samples.'
  prefs: []
  type: TYPE_NORMAL
- en: Using generation to model sampling is particularly useful in machine learning,
    because often the data is not IID. In the MNIST example in chapter 1, the original
    NIST data was not IID—one block of data came from high school students and the
    other from government officers. You could capture the identity of the digit writer
    as a variable in your stochastic process. Then the data would be IID *conditional*
    on that variable.
  prefs: []
  type: TYPE_NORMAL
- en: Don’t mistake the map for the terrain
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Consider again the MNIST data. The population for that data is quite nebulous
    and abstract. If that digit classification software were licensed to multiple
    clients, the population would be a practically unending stream of digits. Generalizing
    to abstract populations is the common scenario in machine learning, as it is for
    statistics. When R.A. Fisher, the founding father of modern statistics, was designing
    experiments for testing soil types on crop growth at Rothamsted Research, he was
    trying to figure out how to generalize to the population of future crops (with
    as small a number of samples as possible).
  prefs: []
  type: TYPE_NORMAL
- en: The problem with working with nebulously large populations is that it can lead
    to the mistake of mentally conflating populations with the probability distributions.
    Do not do this. Do not mistake the map (the distribution used to model the population)
    for the terrain (the population itself).
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate, consider the following example: While writing part of this chapter,
    I was vacationing in Silves, a town in the Portuguese Algarve with a big castle,
    deep history, and great hiking. Suppose I were interested in modeling the heights
    of Silves residents.'
  prefs: []
  type: TYPE_NORMAL
- en: Officially, the population of Silves is 11,000, so let’s take that number as
    ground truth. That means there are 11,000 different height values in Silves. Suppose
    I physically went down to the national health center in Silves and got a spreadsheet
    of every resident’s height. Then the data I’d have is not a randomly sampled subset
    of the population—it is the full population itself.
  prefs: []
  type: TYPE_NORMAL
- en: I could then compute a *histogram* on that population, as shown in figure 2.21\.
    A histogram is a visualization of the counts of values (in this case, heights)
    in a population or sample. For continuous values like heights, we count how many
    values fall into a range or “bin.”
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F21_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.21 A histogram illustrating the height distribution of all Silves residents
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: This histogram represents the full population distribution. I can make it look
    more like a probability distribution by dividing the counts by the number of people,
    as in figure 2.22
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F22_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.22 Histogram of proportions of Silves residents with given height
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: One might say this distribution follows the normal (Gaussian) probability distribution,
    because we see a bell curve, and indeed, the normal is appropriate for evolutionary
    bell-shaped phenomena such as height. But that statement is not precisely true.
    To see this, consider that all normal distributions are defined for negative numbers
    (though those numbers might have an infinitesimal amount of probability density),
    whereas heights can’t be negative. What we are really doing is using the normal
    distribution as a *model*—as an *approximation* of this population distribution.
  prefs: []
  type: TYPE_NORMAL
- en: In another example, figure 2.23 shows the true distribution of the parts of
    speech in Jane Austen’s novels. Note that this is not based on a sample of pages
    from her novels; I created this visualization from the parts-of-speech distribution
    of the 725 thousand words in *all* her six completed novels.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F23_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.23 Actual distribution of word types in all of Jane Austen’s novels
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As modelers, we use canonical distributions to model the population distribution,
    but the model is not equivalent to the population distribution. This point may
    seem like trivial semantics, but in the era of big data, we often can reason about
    an entire population instead of just a random sample. For example, popular online
    social networks have hundreds of millions and sometimes billions of users. That’s
    a huge size, yet the entire population is just one database query away.
  prefs: []
  type: TYPE_NORMAL
- en: In causal modeling, being precise in how we think about modeling data and populations
    is extremely useful. Causal inferences are about the real-world attributes of
    the population, rather than just statistical trends in the data. And different
    causal questions we want to answer will require us to bake different causal assumptions
    into our models, some of which are stronger or harder to validate than others.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.2 From the observed data to the data generating process
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In causal modeling, it is important to understand how the observed data maps
    back to the joint probability distribution of the variables in the data, and how
    that joint probability distribution maps back to the DGP. Most modelers have some
    level of intuition about the relationships between these entities, but in causal
    modeling we must be explicit. This explicit understanding is important because,
    while in ordinary statistical modeling you model the joint distribution (or elements
    of it), in causal modeling you need to model the DGP.
  prefs: []
  type: TYPE_NORMAL
- en: From the observed data to the empirical joint distribution
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Suppose we had the dataset of five data points shown in table 2.1.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2.1 A simple data set with five examples
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '|  | jenny_throws_rock | brian_throws_rock | window_breaks |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1  | False  | True  | False  |'
  prefs: []
  type: TYPE_TB
- en: '| 2  | True  | False  | True  |'
  prefs: []
  type: TYPE_TB
- en: '| 3  | False  | False  | False  |'
  prefs: []
  type: TYPE_TB
- en: '| 4  | False  | False  | False  |'
  prefs: []
  type: TYPE_TB
- en: '| 5  | True  | True  | True  |'
  prefs: []
  type: TYPE_TB
- en: We can take counts of all the observed observable outcomes, as in table 2.2.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2.2 Empirical counts of each possible outcome combination
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '|  | jenny_throws_rock | brian_throws_rock | window_breaks | counts |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1  | False  | False  | False  | 2  |'
  prefs: []
  type: TYPE_TB
- en: '| 2  | True  | False  | False  | 0  |'
  prefs: []
  type: TYPE_TB
- en: '| 3  | False  | True  | False  | 1  |'
  prefs: []
  type: TYPE_TB
- en: '| 4  | True  | True  | False  | 0  |'
  prefs: []
  type: TYPE_TB
- en: '| 5  | False  | False  | True  | 0  |'
  prefs: []
  type: TYPE_TB
- en: '| 6  | True  | False  | True  | 1  |'
  prefs: []
  type: TYPE_TB
- en: '| 7  | False  | True  | True  | 0  |'
  prefs: []
  type: TYPE_TB
- en: '| 8  | True  | True  | True  | 1  |'
  prefs: []
  type: TYPE_TB
- en: Dividing by the number of outcomes (5) gives us the *empirical joint distribution*,
    shown in table 2.3.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2.3 The empirical distribution of the data
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '|  | jenny_throws_rock | brian_throws_rock | window_breaks | proportion |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1  | False  | False  | False  | 0.40  |'
  prefs: []
  type: TYPE_TB
- en: '| 2  | True  | False  | False  | 0.00  |'
  prefs: []
  type: TYPE_TB
- en: '| 3  | False  | True  | False  | 0.20  |'
  prefs: []
  type: TYPE_TB
- en: '| 4  | True  | True  | False  | 0.00  |'
  prefs: []
  type: TYPE_TB
- en: '| 5  | False  | False  | True  | 0.00  |'
  prefs: []
  type: TYPE_TB
- en: '| 6  | True  | False  | True  | 0.20  |'
  prefs: []
  type: TYPE_TB
- en: '| 7  | False  | True  | True  | 0.00  |'
  prefs: []
  type: TYPE_TB
- en: '| 8  | True  | True  | True  | 0.20  |'
  prefs: []
  type: TYPE_TB
- en: So, in the case of discrete outcomes, we go from the data to the empirical distribution
    using counts.
  prefs: []
  type: TYPE_NORMAL
- en: In the continuous case, we could calculate a histogram or a density curve or
    some other statistical representation of the empirical distribution. There are
    different statistical choices you can make about how you create those summaries,
    but these are representations of the same underlying empirical distribution.
  prefs: []
  type: TYPE_NORMAL
- en: Importantly, the empirical joint distribution is not the actual joint distribution
    of the variables in the data. For example, we see that several outcomes in the
    empirical distribution never appeared in those five data points. Is the probability
    of their occurrence zero? More likely, the probabilities were greater than zero
    but we didn’t see those outcomes, since only five points were sampled.
  prefs: []
  type: TYPE_NORMAL
- en: As an analogy, a fair die has a 1/6 probability of rolling a 1\. If you roll
    the die five times, you have a near (1–1/6)⁵=40% probability of not seeing 1 in
    any of those rolls. If that happened to you, you wouldn’t want to conclude that
    the probability of seeing a 1 is zero. If, however, you kept rolling, the proportion
    of times you saw the 1 would converge to 1/6.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE  More precisely, our frequentist interpretation of probability tells us
    to interpret probability as the proportion of times we get a 1 when we roll ad
    infinitum. Despite the “ad infinitum,” we don’t have to roll many times before
    the proportion starts converging to a number (1/6).
  prefs: []
  type: TYPE_NORMAL
- en: From the empirical joint distribution to the observational joint distribution
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The *observational joint probability* distribution is the true joint distribution
    of the variables observed in the data. Let’s suppose table 2.4 shows the true
    observational joint probability distribution of these observed variables.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2.4 Assume this is the true observational joint distribution.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '|  | jenny_throws_rock | brian_throws_rock | window_breaks | probability |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1  | False  | False  | False  | 0.25  |'
  prefs: []
  type: TYPE_TB
- en: '| 2  | True  | False  | False  | 0.15  |'
  prefs: []
  type: TYPE_TB
- en: '| 3  | False  | True  | False  | 0.15  |'
  prefs: []
  type: TYPE_TB
- en: '| 4  | True  | True  | False  | 0.05  |'
  prefs: []
  type: TYPE_TB
- en: '| 5  | False  | False  | True  | 0.00  |'
  prefs: []
  type: TYPE_TB
- en: '| 6  | True  | False  | True  | 0.10  |'
  prefs: []
  type: TYPE_TB
- en: '| 7  | False  | True  | True  | 0.10  |'
  prefs: []
  type: TYPE_TB
- en: '| 8  | True  | True  | True  | 0.20  |'
  prefs: []
  type: TYPE_TB
- en: Sampling from the joint observational distribution produces the empirical joint
    distribution, as illustrated in figure 2.24.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F24_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.24 Sampling from the observational joint distribution produces the
    observed data and empirical distribution.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Latent variables: From the observed joint distribution to the full joint distribution'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In statistical modeling, *latent variables* are variables that are not directly
    observed in the data but are included in the statistical model. Going back to
    our data example, imagine there were a fourth latent variable, “strength_of_impact”,
    shown in table 2.5.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2.5 The values in the strength_of_impact column are unseen “latent” variables.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '|  | jenny_throws_rock | brian_throws_rock | strength_of_impact | window_breaks
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1  | False  | True  | 0.6  | False  |'
  prefs: []
  type: TYPE_TB
- en: '| 2  | True  | False  | 0.6  | True  |'
  prefs: []
  type: TYPE_TB
- en: '| 3  | False  | False  | 0.0  | False  |'
  prefs: []
  type: TYPE_TB
- en: '| 4  | False  | False  | 0.0  | False  |'
  prefs: []
  type: TYPE_TB
- en: '| 5  | True  | True  | 0.8  | True  |'
  prefs: []
  type: TYPE_TB
- en: Latent variable models are common in disciplines ranging from machine learning
    to econometrics to bioinformatics. For example, in natural language processing,
    an example of a popular probabilistic latent variable model is *topic models*,
    where the observed variables represent the presence of words and phrases in a
    document, and the latent variable represents the topic of the document (e.g.,
    sports, politics, finance, etc.)
  prefs: []
  type: TYPE_NORMAL
- en: The latent variables are omitted from the observational joint probability distribution
    because, as the name implies, they are not observed. The joint probability distribution
    of both the observed and the latent variables is the full joint distribution.
    To go from the full joint distribution to the observational joint distribution,
    we marginalize over the latent variables, as shown in figure 2.25.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F25_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.25 Marginalizing the full joint distribution over the latent variables
    produces the observational joint distribution.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: From the full joint distribution to the data generating process
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: I wrote the actual DGP for the five data points using the following Python code.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 2.11 An example of a DGP in code form
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: '#1 Input variables reflect Jenny and Brian’s inclination to throw and the window’s
    strength.'
  prefs: []
  type: TYPE_NORMAL
- en: '#2 Jenny and Brian throw the rock if so inclined.'
  prefs: []
  type: TYPE_NORMAL
- en: '#3 If both Jenny and Brian throw the rock, the total strength of the impact
    is .8.'
  prefs: []
  type: TYPE_NORMAL
- en: '#4 If either Jenny or Brian throws the rock, the total strength of the impact
    is .6.'
  prefs: []
  type: TYPE_NORMAL
- en: '#5 Otherwise, no one throws and the strength of impact is 0.'
  prefs: []
  type: TYPE_NORMAL
- en: '#6 If the strength of impact is greater than the strength of the window, the
    window breaks.'
  prefs: []
  type: TYPE_NORMAL
- en: Note  In general, the DGP is unknown, and our models are making guesses about
    its structure.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example`, jenny_inclination`, `brian_inclination`, and `window_strength`
    are latent variables between 0 and 1\. `jenny_inclination` represents Jenny’s
    initial desire to throw, `brian_inclination` represents Brian’s initial desire
    to throw, and `window_strength` represents the strength of the window pane. These
    are the initial conditions that lead to one instantiation of the observed variables
    in the data: (`jenny_throws_ball`, `brian_throws_ball`, `window_breaks`).'
  prefs: []
  type: TYPE_NORMAL
- en: 'I then called the `true_dgp` function on the following five sets of latent
    variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'In other words, the following `for` loop in Python is the literal sampling
    process producing the five data points:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: The DGP is the causal process that generated the data. Note the narrative element
    that is utterly missing from the full joint probability distribution; Jenny and
    Brian throw a rock at a window if they are so inclined, and if they hit the window,
    the window may break, depending on whether one or both of them threw rocks and
    the strength of the window. The DGP entails the full joint probability distribution,
    as shown in figure 2.26\. In other words, the joint probability distribution is
    a consequence of the DGP based on *how* it generates data.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F26_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.26 The DGP entails the full joint distribution.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In summary, the DGP entails the full joint distribution, and marginalizing over
    the full joint distribution produces the observational joint distribution. Sampling
    from that distribution produces the observed data and the corresponding empirical
    joint distribution. There is a many-to-one relationship as we move down this hierarchy
    that has implications for causal modeling and inference.
  prefs: []
  type: TYPE_NORMAL
- en: Many-to-one relationships down the hierarchy
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '![figure](../Images/CH02_F27_Ness.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.27 There is a many-to-one relationship as we move down the hierarchy.
    In summary, there are multiple DGPs consistent with the observed data.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As we move down from the DGP to full joint to observational joint to empirical
    joint distribution and observed data, there is a many-to-one relationship from
    the preceding level to the subsequent level, as illustrated in figure 2.27.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, an object at one of the levels is consistent with multiple objects
    at the next level up:'
  prefs: []
  type: TYPE_NORMAL
- en: '*There could be multiple observational joint distributions consistent with
    the empirical joint distribution*. If we sample five points, then sample five
    more, we’ll get different datasets and thus different empirical distributions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*There could be multiple full joint distributions consistent with one observational
    joint distribution*. The difference between the two distributions is the latent
    variables. But what if we have different choices for the sets of latent variables?
    For example, if our observation distribution is *P*(*X*, *Y*), the full joint
    would be *P*(*X*, *Y*, *Z*, *W*) if our set of latent variables is {*Z*, *W*},
    or *P*(*X*, *Y*, *Z*, *V*) if our set of latent variables is {*Z*, *V*}.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*There could be multiple DGP’s consistent with one full joint probability distribution*.
    Suppose in our window-breaking example, Jenny had a friend Isabelle who sometimes
    egged Jenny on to throw the rock and sometimes did not, affecting Jenny’s inclination
    to throw. This DGP is different from the original, but the relationship between
    the latent variable of Isabell’s peer pressure and Jenny’s inclination to throw
    could be such that this new DGP entailed exactly the same joint probability distribution.
    As a more trivial example, suppose we looked at the distribution of a single variable
    corresponding to the sum of the roll of three dice. The DGP is rolling three dice
    and then summing them together. Two DGPs could differ in terms of the order of
    summing the dice; e.g., (first + second) + third or (first + third) + second or
    (second + third) + first. These would all yield the same distribution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Those last two many-to-one relationships are fundamental to the concept of *causal
    identifiability,* the core reason why causal inference is hard. This concept is
    the reason “correlation does not imply causation,” as the saying goes.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.3 Statistical tests for independence
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Causality imposes independence and conditional independence on variables, so
    we rely on statistical tests for conditional independence to build and validate
    causal models.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose *X* and *Y* are independent, or *X* and *Y* are conditionally independent
    given *Z*. If we have data observing *X*, *Y*, and *Z*, we can run a statistical
    test for independence. The canonical statistical independence procedure returns
    a test statistic that quantifies the statistical association between *X* and *Y*,
    and a p-value that quantifies the probability of getting that degree of association,
    or one more extreme, by pure chance when *X* and *Y* are actually conditionally
    independent given *Z*. Put simply, the test quantifies the statistical evidence
    of dependence or independence.
  prefs: []
  type: TYPE_NORMAL
- en: Evidence suggesting that someone committed a murder is not the same as the definitive
    truth that they did. Similarly, statistical evidence indicating independence between
    two variables does not equate to the actual fact of their independence. In both
    cases, evidence can point toward a conclusion without definitively proving it.
    For example, given that independence is true, the strength of the statistical
    evidence can vary on several factors, such as how much data there is. And it is
    always possible to make false conclusions from these tests.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that if *X* and *Y* are independent, then *P*(*Y*|*X*) is equivalent
    to *P*(*Y*). In predictive terms, that means *X* has no predictive power on *Y*.
    If you can’t use classical statistical tests (e.g., if *X* and *Y* are vectors)
    then you can try training a predictive model and subjectively evaluating how well
    the model predicts.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3.4 Statistical estimation of model parameters
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When we “train” or “fit” a model, we are attempting to estimate the values of
    parameters of the model, such as the weights in a regression model or neural network.
    Generally, in statistical modeling and machine learning, the goal of parameter
    estimation is modeling the observational or joint probability distribution. In
    causal modeling, the objective is modeling the DGP. The distinction is important
    for making good causal inferences.
  prefs: []
  type: TYPE_NORMAL
- en: Estimating by maximizing likelihood
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In informal terms and in the context of parameter estimation, likelihood is
    the probability of having observed the data given a candidate value of the parameter
    vector. *Maximizing likelihood* means choosing the value of the parameter vector
    that has the highest likelihood. Usually, we work with maximizing the log of the
    likelihood instead of the likelihood directly because it is mathematically and
    computationally easier to do so; the value that maximizes likelihood is the same
    as the value that maximizes log-likelihood. In special cases, such as linear regression,
    the maximum likelihood estimate has a solution we can derive mathematically, but
    in general, we must find the solution using numerical optimization techniques.
    In some models, such as neural networks, it is infeasible to find the value that
    maximizes likelihood, so we settle for a candidate that has a relatively high
    likelihood.
  prefs: []
  type: TYPE_NORMAL
- en: Estimating by minimizing other loss functions and regularization
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In machine learning, there are a variety of loss functions for estimating parameters.
    Maximizing likelihood is a special case of minimizing a loss function, namely
    the negative log-likelihood loss function.
  prefs: []
  type: TYPE_NORMAL
- en: '*Regularization* is the practice of adding additional elements to the loss
    function that steer the optimization toward better parameter values. For example,
    L2 regularization adds a value proportional to the sum of the square of the parameter
    values to the loss. Since a small increase in value leads to a larger increase
    in the square of the value, L2 regularization helps avoid exceedingly large parameter
    estimates.'
  prefs: []
  type: TYPE_NORMAL
- en: Bayesian estimation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '*Bayesian estimation* treats parameters as random variables and tries to model
    the conditional distribution of the parameters (typically called the *posterior*
    distribution) given the observed variables in the data. It does so by putting
    a “prior probability distribution” on the parameters. The prior distribution has
    its own parameters called “hyperparameters” that the modeler must specify. When
    there are latent variables in the model, Bayesian inference targets the joint
    distribution of the parameters and the latent variables conditional on the observed
    variables.'
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned before, in this book I use Greek letters for parameters and Roman
    letters for variables in the DGP, including latent variables. But for a Bayesian
    statistician, the distinction is irrelevant; both parameters and latent variables
    are unknown and thus targets of inference.
  prefs: []
  type: TYPE_NORMAL
- en: One of the main advantages of Bayesian estimation is that rather than getting
    a point value for the parameters, you get an entire conditional probability distribution
    of the parameters (more specifically, you get samples from or parameter values
    representing that distribution). That probability distribution represents uncertainty
    about the parameter values, and you can incorporate that uncertainty into predictions
    or other inferences you make from the model.
  prefs: []
  type: TYPE_NORMAL
- en: According to Bayesian philosophy, the prior distribution should capture the
    modeler’s subjective beliefs about the true value of the parameters. We’ll do
    something similar in causal modeling when we turn our beliefs about the causal
    structure and mechanisms of the DGP into causal assumptions in the model.
  prefs: []
  type: TYPE_NORMAL
- en: Statistical and computational attributes of an estimator
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Given that there are many ways of estimating a parameter, let’s look for ways
    to compare the quality of estimation methods. Suppose the parameter we want to
    estimate had a ground truth value. Statisticians think about how well an estimation
    method can recover that true value. Specifically, they care about the bias and
    consistency of an estimation method. An estimator is a random variable because
    it comes from data (and data has a distribution), which means an estimator has
    a distribution. An estimator is unbiased if the mean of that distribution is equal
    to the true value of the parameter it is estimating. Consistency means that the
    more data you have, the closer the estimate is to the true value of the parameter.
    In practice, the consistency of the estimator is more important than whether it
    is unbiased.
  prefs: []
  type: TYPE_NORMAL
- en: Computer scientists know that while consistency is nice in theory, getting an
    estimation method to work with “more data” is easier said than done. They care
    about the computational qualities of an estimator in relation to the amount of
    data. Does the estimator scale with the data? Is it parallelizable? An estimator
    may be consistent, but when its running on an iPhone app, will it converge to
    the true value in milliseconds and not eat up the battery’s charge in the process?
  prefs: []
  type: TYPE_NORMAL
- en: This book decouples understanding causal logic from the statistical and computational
    properties of estimators of causal parameters. We will focus on the causal logic
    and rely on libraries like DoWhy that make the statistical and computational calculations
    easy to do.
  prefs: []
  type: TYPE_NORMAL
- en: Goodness-of-fit vs. cross-validation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'When we estimate parameters, we can calculate various statistics to tell us
    how well we’ve done. One class of statistics is called *goodness-of-fit statistics*.
    Statisticians define goodness-of-fit as statistics that quantify how well the
    model fits the data used to train the model. Here’s another definition: goodness-of-fit
    statistics tell you how well your model pretends to be the DGP for the data you
    used to train your model. However, as we saw, there are multiple possible DGPs
    for a given data set. Goodness-of-fit won’t provide causal information that can
    distinguish the true DGP.'
  prefs: []
  type: TYPE_NORMAL
- en: Cross-validation statistics generally indicate how well your model predicts
    data it was not trained on. It is possible to have a model with a decent goodness-of-fit
    relative to other models, but that still predicts poorly. Machine learning is
    usually concerned with the task of prediction and so favors cross-validation.
    However, a model can be a good predictor and provide completely bogus causal inferences.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4 Determinism and subjective probability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section will venture into the philosophical underpinnings we’ll need for
    probabilistic causal modeling. In this book, we’ll use probabilistic models to
    model causal models. When training the model, we might want to use Bayesian parameter
    estimation procedures. When doing causal inference, we might want to use a probabilistic
    inference algorithm. When we do causal decision-making, we might want to use Bayesian
    decision theory. Further, *structural causal models* (chapter 6) have a rigid
    requirement on where randomness can occur in the model. That means being clear
    about the differences between Bayesianism, uncertainty, randomness, probabilistic
    modeling, and probabilistic inference is important.
  prefs: []
  type: TYPE_NORMAL
- en: The first key point is to view the DGP as deterministic. The second key point
    is to view the probability in our models of the DGP as subjective.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4.1 Determinism
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The earlier code for the rock-throwing DGP is entirely *deterministic*; given
    the initial conditions, the output is certain. Consider our definition of physical
    probability again: if I throw a die, why is the outcome random?'
  prefs: []
  type: TYPE_NORMAL
- en: If I had a superhuman level of dexterity, perception, and mental processing
    power, I could mentally calculate the die roll’s physics and know the outcome
    with certainty. This philosophical idea of determinism essentially says that the
    DGP is deterministic. Eighteenth-century French scholar Pierre-Simon Laplace explained
    determinism with a thought experiment called *Laplace’s demon*. Laplace imagined
    some entity (the demon) that knew every atom’s precise location and momentum in
    the universe. With that knowledge, that entity would know the future state of
    the universe with complete deterministic certainty because it could calculate
    them from the laws of (Newtonian) mechanics. In other words, given all the causes,
    the effect is 100% entirely determined and not at all random.
  prefs: []
  type: TYPE_NORMAL
- en: To be clear, some systems, when we look closely enough, have inherently stochastic
    elements (e.g., quantum mechanics, biochemistry, etc.). However, this philosophical
    view of modeling will apply to most things we’ll care to model.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4.2 Subjective probability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In our physical interpretation of probability, when I roll a die, probability
    represents my lack of the demon’s superhuman knowledge of the location and momentum
    of all the die’s particles as it is rolling. In other words, when I build probability
    models of the DGP, the probability reflects my lack of knowledge. This philosophical
    idea is called *subjective probability* or *Bayesian probability*. The argument
    goes beyond Bayes rule and Bayesian statistical estimation to say that probability
    in the model represents the modeler’s lack of complete knowledge about the DGP
    and does not represent inherent randomness in the DGP.
  prefs: []
  type: TYPE_NORMAL
- en: Subjective probability expands our “random physical process” interpretation
    of probability. The physical interpretation of probability works well for simple
    physical processes like rolling a die, flipping a coin, or shuffling a deck of
    cards. But, of course, we will want to model many phenomena that are difficult
    to think of as repeatable physical processes. For example, how the mind turns
    thoughts into speech, or how an increased flow of fresh water into the ocean due
    to climate change is threatening to tip the global system of ocean currents. In
    these cases, we will still model these phenomena using random generation. The
    probabilities used in the random generation reflect that while we, as modelers,
    may know some details about the data-generating process, we’ll never have the
    superhuman deterministic level of detail.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A random variable is a variable whose possible values are numerical outcomes
    of a random phenomenon.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A probability distribution function is a function that maps the random variable
    outcomes to a probability value. A joint probability distribution function maps
    each combination of *X* and *Y* outcomes to a probability value.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We derive the chain rule, the law of total probability, and Bayes rule from
    the fundamental axioms of probability. These are useful rules in modeling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Markovian assumption means each variable in an ordering of variables only
    depends on those that come directly before in the order. This is a common simplifying
    assumption in statistical modeling, but it plays a large role in causal modeling.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Canonical classes of distributions are mathematically well-described representations
    of distributions. They provide us with primitives that make probabilistic modeling
    flexible and relatively easy.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Canonical distributions are instantiated with a set of parameters, such as location,
    scale, rate, and shape parameters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When we build models, knowing what variables are independent or conditionally
    independent dramatically simplifies the model. In causal modeling, independence
    and conditional independence will be vital in separating correlation from causation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The expected value of a random variable with a finite number of outcomes is
    the weighted average of all possible outcomes, where the weight is the probability
    of that outcome.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Probability is just a value. We need to give that value an interpretation. The
    physical definition of probability maps probability to the proportion of times
    an outcome would occur if a physical process could be run repeatedly ad infinitum.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In contrast to the physical interpretation of probability, the Bayesian view
    of subjective probability interprets probability in terms of belief, or conversely,
    uncertainty.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When coding a random process, Pyro allows you to use canonical distributions
    as primitives in constructing nuanced random process models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monte Carlo algorithms use random generation to estimate expectations from a
    distribution of interest.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Popular inference algorithms include graphical model-based algorithms, probability
    weighting, MCMC, and variational inference.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Canonical distributions and random processes can serve as proxies for populations
    we wish to model and for which we want to make inferences. Conditional probability
    is an excellent way to model heterogeneous subpopulations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Different canonical distributions are used to model different phenomena, such
    as counts, bell curves, and waiting times.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generating from random processes is a good model of real-life sampling of independent
    and identically distributed data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Given a dataset, multiple data generating processes (DGPs) could have potentially
    generated that dataset. This fact connects to the challenge of parsing causality
    from correlation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Statistical independence tests validate independence and conditional independence
    claims about the underlying distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are several methods for learning model parameters, including maximum likelihood
    estimation and Bayesian estimation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determinism suggests that if we knew everything about a system, we could predict
    its outcome with zero error. Subjective probability is the idea that probability
    represents the modeler’s lack of that complete knowledge about the system. Adopting
    these philosophical perspectives will serve us in understanding causal AI.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A great way to build models is to factorize a joint distribution, simplify the
    factors with conditional independence, and then implement factors as random processes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A powerful modeling technique is to use probability distributions to model populations,
    particularly when you care about heterogeneity in those populations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When we use probability distributions to model populations, we can map generating
    from random processes to sampling from the population.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While traditional statistical modeling models the observational joint distribution
    or the full joint distribution, causal modeling models the DGP.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
