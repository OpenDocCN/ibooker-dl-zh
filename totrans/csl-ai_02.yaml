- en: 2 A primer on probabilistic generative modeling
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 2 概率生成建模基础
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: A primer on probability models
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概率模型基础
- en: Computational probability with the pgmpy and Pyro libraries
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用pgmpy和Pyro库进行计算概率
- en: 'Statistics for causality: data, populations, and models'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因果性统计学：数据、总体和模型
- en: Distinguishing between probability models and subjective Bayesianism
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 区分概率模型和主观贝叶斯主义
- en: Chapter 1 made the case for learning how to code causal AI. This chapter will
    introduce some fundamentals we need to tackle causal modeling with probabilistic
    machine learning, which roughly refers to machine learning techniques that use
    probability to model uncertainty and simulate data. There is a flexible suite
    of cutting-edge tools for building probabilistic machine learning models. This
    chapter will introduce the concepts from probability, statistics, modeling, inference,
    and even philosophy that we will need in order to implement key ideas from causal
    inference with the probabilistic machine learning approach.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 第一章阐述了学习如何编码因果AI的必要性。本章将介绍一些我们需要用概率机器学习来处理因果模型的基础知识，这大致指的是使用概率来模拟不确定性和模拟数据的机器学习技术。构建概率机器学习模型有一套灵活的尖端工具。本章将介绍概率、统计学、建模、推理甚至哲学中的概念，这些概念是我们用概率机器学习方法实现因果推理的关键思想。
- en: This chapter will not provide a mathematically exhaustive introduction to these
    ideas. I’ll focus on what is needed for the rest of this book and omit the rest.
    Any data scientist seeking causal inference expertise should not neglect the practical
    nuances of probability, statistics, machine learning, and computer science. See
    the chapter notes at [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)
    for recommended resources where you can get deeper introductions or review materials.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章不会对这些概念提供数学上的全面介绍。我将专注于本书其余部分所需的内容，并省略其他内容。任何寻求因果推理专长的数据科学家都不应忽视概率、统计学、机器学习和计算机科学的实际细微差别。有关推荐资源的章节注释，请参阅[https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)，您可以在那里获得更深入的介绍或复习材料。
- en: 'In this chapter, I’ll introduce two Python programming libraries for probabilistic
    machine learning:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我将介绍两个用于概率机器学习的Python编程库：
- en: '*pgmpy* is a library for building probabilistic graphical models. As a traditional
    graphical modeling tool, it is far less flexible and cutting-edge than Pyro but
    also easier to use and debug. What it does, it does well.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*pgmpy*是一个用于构建概率图模型的库。作为一个传统的图形建模工具，它比Pyro缺乏灵活性和尖端性，但更容易使用和调试。它所做的是，它做得很好。'
- en: '*Pyro* is a general probabilistic machine learning library. It is quite flexible,
    and it leverages PyTorch’s cutting-edge gradient-based learning techniques.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Pyro*是一个通用的概率机器学习库。它非常灵活，并利用PyTorch的尖端基于梯度的学习技术。'
- en: Pyro and pgmpy are the general modeling libraries we’ll use in this book. Other
    libraries we’ll use are designed specifically for causal inference.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Pyro和pgmpy是我们将在本书中使用的通用建模库。我们将使用的其他库是专门为因果推理设计的。
- en: 2.1 Primer on probability
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.1 概率基础
- en: Let’s review the probability theory you’ll need to work with this book. We’ll
    start with a few basic mathematical axioms and their logical extensions without
    yet adding any real-world interpretation. Let’s begin with the concrete idea of
    a simple three-sided die (these exist).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下您需要与本书一起工作的概率理论。我们将从一些基本的数学公理及其逻辑扩展开始，而不添加任何现实世界的解释。让我们从一个简单的三面骰子的具体想法开始（这些是存在的）。
- en: 2.1.1 Random variables and probability
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.1 随机变量和概率
- en: A *random variable* is a variable whose possible values are the numerical outcomes
    of a random phenomenon. These values can be discrete or continuous. In this section,
    we’ll focus on the discrete case. For example, the values of a discrete random
    variable representing a three-sided die roll could be {1, 2, 3}. Alternatively,
    in a 0-indexed programming language like Python, it might be better to use {0,
    1, 2}. Similarly, a discrete random variable representing a coin flip could have
    outcomes {0, 1} or {True, False}. Figure 2.1 illustrates three-sided dice.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 *随机变量* 是一个变量，其可能的值是随机现象的数值结果。这些值可以是离散的或连续的。在本节中，我们将关注离散情况。例如，代表三次掷骰子的离散随机变量的值可以是{1,
    2, 3}。或者，在Python这样的0索引编程语言中，可能最好使用{0, 1, 2}。同样，代表抛硬币的离散随机变量可以有结果{0, 1}或{True,
    False}。图2.1说明了三面骰子。
- en: '![figure](../Images/CH02_F01_Ness.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F01_Ness.png)'
- en: Figure 2.1 Three-sided dice each represent a random variable with three discrete
    outcomes.
  id: totrans-17
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.1三个面的骰子各自代表一个有三个离散结果的随机变量。
- en: The typical approach to notation is to write random variables with capitals
    like *X*, *Y*, and *Z*. For example, suppose *X* represents a die roll with outcomes
    {1, 2, 3}, and the outcome represents the number on the side of the die. *X*=1
    and *X*=2 represent the events of rolling a 1 and 2 respectively. If we want to
    abstract away the specific outcome with a variable, we typically use lowercase.
    For example, I would use “*X*=*x*” (e.g., *X*=1) to represent the event “I rolled
    an ‘*x*’!” where *x* can be any value in {1, 2, 3}. See figure 2.2.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的表示方法是使用大写字母如 *X*、*Y* 和 *Z* 来表示随机变量。例如，假设 *X* 代表一个掷骰子的结果，结果为 {1, 2, 3}，结果代表骰子面上的数字。*X*=1
    和 *X*=2 分别代表掷出1和2的事件。如果我们想用一个变量来抽象特定的结果，我们通常使用小写字母。例如，我会用 “*X*=*x*” （例如，*X*=1）来表示事件
    “我掷出了一个‘*x*’！” 其中 *x* 可以是 {1, 2, 3} 中的任何值。参见图2.2。
- en: '![figure](../Images/CH02_F02_Ness.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F02_Ness.png)'
- en: Figure 2.2 *X* represents the outcome of a three-sided die roll. If the die
    roles a 2, the observed outcome is *X*=2.
  id: totrans-20
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.2中的 *X* 代表掷一个三面骰子的结果。如果骰子掷出2，观察到的结果就是 *X*=2。
- en: Each outcome of a random variable has a *probability value*. The probability
    value is often called a *probability mass* for discrete variables and a *probability
    density* for continuous variables. For discrete variables, probability values
    are between zero and one, and summing up the probability values for each possible
    outcome yields 1\. For continuous variables, probability densities are greater
    than zero, and integrating the probability densities over each possible outcome
    yields 1.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 随机变量的每个结果都有一个 *概率值*。概率值通常被称为离散变量的 *概率质量* 和连续变量的 *概率密度*。对于离散变量，概率值介于零和一之间，将每个可能结果的概率值相加得到1。对于连续变量，概率密度大于零，并且将概率密度在所有可能结果上积分得到1。
- en: Given a random variable with outcomes {0, 1} representing a coin flip, what
    is the probability value assigned to 0? What about 1? At this point, we just know
    the two values are between zero and one, and that they sum to one. To go beyond
    that, we have to talk about how to *interpret* probability. First, though, let’s
    hash out a few more concepts.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个结果为 {0, 1} 的随机变量，代表抛硬币，0被分配的概率值是多少？1呢？到目前为止，我们只知道这两个值介于零和一之间，并且它们的和为1。要超出这个范围，我们必须讨论如何
    *解释* 概率。不过，首先让我们澄清一些更多的概念。
- en: 2.1.2 Probability distributions and distribution functions
  id: totrans-23
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.2 概率分布和分布函数
- en: A *probability distribution function* is a function that maps the random variable
    outcomes to a probability value. For example, if the outcome of a coin flip is
    1 (heads) and the probability value is 0.51, the distribution function maps 1
    to 0.51\. I stick to the standard notation *P*(*X*=*x*), as in *P*(*X*=1) = 0.51\.
    For longer expressions, when the random variable is obvious, I drop the capital
    letter and keep the outcome, so *P*(*X*=*x*) becomes *P*(*x*), and *P*(*X*=1)
    becomes *P*(1).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '*概率分布函数* 是一个将随机变量的结果映射到概率值的函数。例如，如果抛硬币的结果是1（正面）且概率值是0.51，分布函数将1映射到0.51。我坚持使用标准的表示法
    *P*(*X*=*x*)，如 *P*(*X*=1) = 0.51。对于更长的表达式，当随机变量很明显时，我省略大写字母并保留结果，所以 *P*(*X*=*x*)
    变为 *P*(*x*)，而 *P*(*X*=1) 变为 *P*(1)。'
- en: If the random variable has a finite set of discrete outcomes, we can represent
    the probability distribution with a table. For example, a random variable representing
    outcomes {1, 2, 3} might look like figure 2.3.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果随机变量有一个有限的离散结果集，我们可以用一个表格来表示概率分布。例如，一个代表结果 {1, 2, 3} 的随机变量可能看起来像图2.3。
- en: '![figure](../Images/CH02_F03_Ness.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F03_Ness.png)'
- en: Figure 2.3 A simple tabular representation of a discrete distribution
  id: totrans-27
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.3展示了离散分布的简单表格表示。
- en: In this book, I adopt the common notation *P*(*X*) to represent the probability
    distribution over all possible outcomes of *X*, while *P*(*X*=*x*) represents
    the probability value of a specific outcome. To implement a probability distribution
    as an object in pgmpy, we’ll use the `DiscreteFactor` class.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我采用常见的表示法 *P*(*X*) 来表示 *X* 所有可能结果的概率分布，而 *P*(*X*=*x*) 表示特定结果的概率值。为了在pgmpy中将概率分布实现为一个对象，我们将使用
    `DiscreteFactor` 类。
- en: Listing 2.1 Implementing a discrete distribution table in pgmpy
  id: totrans-29
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.1在pgmpy中实现离散分布表
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '#1 A list of the names of the variables in the factor'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 因子中变量的名称列表'
- en: '#2 The cardinality (number of possible outcomes) of each variable in the factor'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 因子中每个变量的基数（可能结果的数量）'
- en: '#3 The values each variable in the factor can take'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 因子中每个变量可以取的值'
- en: '#4 A dictionary, where the key is the variable name and the value is a list
    of the names of that variable’s outcomes'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 一个字典，其中键是变量名，值是该变量结果的名称列表'
- en: 'This code prints out the following:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码打印出以下内容：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Setting up your environment
  id: totrans-37
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 设置环境
- en: This code was written with pgmpy version 0.1.24 and Pyro version 1.8.6\. The
    version of pandas used was 1.5.3.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码是用pgmpy版本0.1.24和Pyro版本1.8.6编写的。使用的pandas版本是1.5.3。
- en: See [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)
    for links to the Jupyter notebooks for each chapter, with the code and notes on
    setting up a working environment.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅[https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)获取每个章节的Jupyter笔记本链接，包括代码和设置工作环境的说明。
- en: 2.1.3 Joint probability and conditional probability
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.3 联合概率和条件概率
- en: Often, we are interested in reasoning about more than one random variable. Suppose,
    in addition to the random variable *X* in figure 2.1, there was an additional
    random variable *Y* with two outcomes {0, 1}. Then there is a *joint probability*
    distribution function that maps each combination of *X* and *Y* to a probability
    value.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们感兴趣的是对多个随机变量进行推理。假设，除了图2.1中的随机变量*X*外，还有一个额外的随机变量*Y*，其有两个结果{0, 1}。那么存在一个*联合概率*分布函数，它将*X*和*Y*的每个组合映射到一个概率值。
- en: '![figure](../Images/CH02_F04_Ness.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F04_Ness.png)'
- en: Figure 2.4 A simple representation of a tabular joint probability distribution
  id: totrans-43
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.4 表格联合概率分布的简单表示
- en: As a table, it could look like figure 2.4.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 作为表格，它可能看起来像图2.4。
- en: The `DiscreteFactor` object can represent joint distributions as well.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`DiscreteFactor`对象也可以表示联合分布。'
- en: Listing 2.2 Modeling a joint distribution in pgmpy
  id: totrans-46
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.2 在pgmpy中建模联合分布
- en: '[PRE2]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#1 Now we have two variables instead of one.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 现在我们有两个变量而不是一个。'
- en: '#2 X has 3 outcomes, Y has 2.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 X有3个结果，Y有2个。'
- en: '#3 Now there are two variables, so we name the outcomes for both variables.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 现在有2个变量，因此我们为这两个变量的结果命名。'
- en: '#4 You can look at the printed output to see how the values are ordered of
    values.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 您可以通过查看打印的输出来查看值的顺序。'
- en: 'The preceding code prints this output:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码打印出以下输出：
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Note that the probability values sum to 1\. Further, when we marginalize (i.e.,
    “sum over” or “integrate over”) *Y* across the rows, we recover the original distribution
    *P*(*X*), (aka the marginal distribution of *X*). Summing up over the rows in
    figure 2.5 produces the marginal distribution of *X* on the bottom.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，概率值之和为1。此外，当我们对*Y*进行边缘化（即“求和”或“积分”）时，我们恢复原始分布*P*(*X*)，（也称为*X*的边缘分布）。图2.5中的行求和产生*X*的边缘分布。
- en: '![figure](../Images/CH02_F05_Ness.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F05_Ness.png)'
- en: Figure 2.5 Marginalizing over *Y* yields the marginal distribution of *X*.
  id: totrans-56
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.5 对*Y*进行边缘化得到*X*的边缘分布。
- en: The marginalize method will sum over the specified variables for us.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘化方法将为我们对指定的变量求和。
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This prints the following output:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打印出以下输出：
- en: '[PRE5]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Setting the `inplace` argument to `False` gives us a new marginalized table
    rather than modifying the original joint distribution table.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 将`inplace`参数设置为`False`给我们一个新的边缘化表，而不是修改原始的联合分布表。
- en: '![figure](../Images/CH02_F06_Ness.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F06_Ness.png)'
- en: Figure 2.6 Marginalizing over *X* yields the marginal distribution of *Y*.
  id: totrans-63
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.6 对*X*进行边缘化得到*Y*的边缘分布。
- en: Similarly, when we marginalize *X* over the columns, we get *P*(*Y*). In figure
    2.6, summing over the values of *X* in the columns gives us the marginal distribution
    of *Y* on the right.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，当我们对*X*进行列边缘化时，我们得到*P*(*Y*)。在图2.6中，对列中的*X*值求和给出*Y*的边缘分布。
- en: '[PRE6]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This prints the following output:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打印出以下输出：
- en: '[PRE7]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: I’ll use the notation *P*(*X*, *Y*) to represent joint distributions. I’ll use
    *P*(*X*=*x*, *Y*=*y*) to represent an outcome probability, and for shorthand,
    I’ll write *P*(*x*, *y*). For example, in figure 2.6, *P*(*X*=1, *Y*=0) = *P*(1,
    0) = 0.25\. We can define a joint distribution on any number of variables; if
    there were three variables {*X*, *Y*, *Z*}, I’d write the joint distribution as
    *P*(*X*, *Y*, *Z*).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我将使用符号*P*(*X*, *Y*)来表示联合分布。我将使用*P*(*X*=*x*, *Y*=*y*)来表示结果概率，并且为了简便，我将写*P*(*x*,
    *y*)。例如，在图2.6中，*P*(*X*=1, *Y*=0) = *P*(1, 0) = 0.25。我们可以在任意数量的变量上定义联合分布；如果有三个变量{*X*,
    *Y*, *Z*}，我将联合分布写为*P*(*X*, *Y*, *Z*)。
- en: In this tabular representation of the joint probability distribution, the number
    of cells increases exponentially with each additional variable. There are some
    (but not many) “canonical” joint probability distributions (such as the multivariate
    normal distribution—I’ll show more examples in section 2.1.7). For that reason,
    in multivariate settings, we tend to work with *conditional probability* distributions.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个联合概率分布的表格表示中，随着每个额外变量的增加，单元格的数量呈指数增长。有一些（但不多）是“规范”的联合概率分布（例如多元正态分布——我将在第2.1.7节中展示更多示例）。因此，在多元设置中，我们倾向于使用
    *条件概率* 分布。
- en: The conditional probability of *Y*, given *X*, is
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在给定 *X* 的条件下，*Y* 的条件概率是
- en: '![figure](../Images/ness-ch2-eqs-0x.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/ness-ch2-eqs-0x.png)'
- en: Intuitively, *P*(*Y*|*X*=1) refers to the probability distribution for Y conditional
    on *X* being 1\. In the case of tabular representations of distributions, we can
    derive the conditional distribution table by dividing the cells in the joint probability
    distribution table with the marginal probability values, as in figure 2.7\. Note
    that the columns on the conditional probability table in figure 2.7 now sum to
    1\.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 直观上，*P*(*Y*|*X*=1) 指的是在 *X* 为1的条件下 *Y* 的概率分布。在分布的表格表示中，我们可以通过将联合概率分布表中的单元格除以边缘概率值来推导条件分布表，如图2.7所示。注意，图2.7中条件概率表的列现在总和为1。
- en: '![figure](../Images/CH02_F07_Ness.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH02_F07_Ness.png)'
- en: Figure 2.7 Derive the values of the conditional probability distribution by
    dividing the values of the joint distribution by those of the marginal distribution.
  id: totrans-74
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.7 通过将联合分布的值除以边缘分布的值来推导条件概率分布的值。
- en: 'The pgmpy library allows us to do this division using the “/” operator:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: pgmpy库允许我们使用“/”运算符进行这个除法操作：
- en: '[PRE8]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'That line produces the following output:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 那行产生了以下输出：
- en: '[PRE9]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Also, you can directly specify a conditional probability distribution table
    with the `TabularCPD` class:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您还可以使用 `TabularCPD` 类直接指定条件概率分布表：
- en: '[PRE10]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '#1 A conditional distribution has one variable instead of ΔiscreteFactor’s
    list of variables.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 条件分布有一个变量，而不是 ΔiscreteFactor 变量列表。'
- en: '#2 variable_card is the cardinality of Y.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 variable_card 是 *Y* 的基数。'
- en: '#3 Elements of the list correspond to outcomes for Y. Elements of each list
    correspond to elements of X.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 列表中的元素对应于 *Y* 的结果。每个列表的元素对应于 *X* 的元素。'
- en: 'That produces the following output:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 这会产生以下输出：
- en: '[PRE11]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The `variable_card` argument is the cardinality of *Y* (meaning the number of
    outcomes *Y* can take), and `evidence_card` is the cardinality of *X*.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '`variable_card` 参数是 *Y* 的基数（意味着 *Y* 可以取出的结果数量），而 `evidence_card` 是 *X* 的基数。'
- en: Conditioning as an operation
  id: totrans-87
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 条件化作为一个操作
- en: In the phrase “conditional probability,” “conditional” is an adjective. It is
    useful to think of “condition” as a verb (an action). You condition a random variable
    like *Y* on another random variable *X*. For example, in figure 2.5, I can condition
    *Y*on *X*=1, and essentially get a new random variable with the same outcome values
    as *Y* but with a probability distribution equivalent to *P*(*Y*|*X*=1).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在“条件概率”这个短语中，“条件”是一个形容词。将“条件”视为动词（一个动作）是有用的。您可以通过另一个随机变量 *X* 来条件化随机变量 *Y*。例如，在图2.5中，我可以将
    *Y* 条件化为 *X*=1，本质上得到一个新的随机变量，其结果值与 *Y* 相同，但其概率分布与 *P*(*Y*|*X*=1) 相等。
- en: For those with more programming experience, think of conditioning on *X* = 1
    as filtering on the event *X* == 1; for example, “what is the probability distribution
    of *Y* when *X* == 1?” Filtering in this sense is like the `WHERE` clause in a
    SQL query. *P*(*Y*) is the distribution of the rows in the *Y* table when your
    query is `SELECT` `*` `FROM` `Y`, and *P*(*Y*|*X*=1) is the distribution of the
    rows when your query is `SELECT` `*` `FROM` `Y` `WHERE X=1`.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 对于有更多编程经验的人来说，将 *X* = 1 作为对事件 *X* == 1 的过滤来考虑；例如，“当 *X* == 1 时 *Y* 的概率分布是什么？”在这个意义上，过滤就像SQL查询中的
    `WHERE` 子句。*P*(*Y*) 是当你的查询是 `SELECT * FROM Y` 时 *Y* 表中的行分布，而 *P*(*Y*|*X*=1) 是当你的查询是
    `SELECT * FROM Y WHERE X=1` 时的行分布。
- en: Thinking of “conditioning” as an action helps us better understand probabilistic
    machine learning libraries. In these libraries, you have objects representing
    random variables, and conditioning is an operation applied to these objects. As
    you’ll see, the idea of conditioning as an action also contrasts nicely with the
    core causal modeling concept of “intervention,” where we “intervene” on a random
    variable.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 将“条件”视为一个动作有助于我们更好地理解概率机器学习库。在这些库中，你有代表随机变量的对象，条件是应用于这些对象的操作。正如你将看到的，将条件视为动作的想法也与核心因果建模概念“干预”形成鲜明对比，我们在其中“干预”一个随机变量。
- en: Pyro implements conditioning as an operation with the `pyro.condition` function.
    We’ll explore this in chapter 3.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Pyro 通过 `pyro.condition` 函数将条件操作化为一个操作。我们将在第 3 章中探讨这一点。
- en: 2.1.4 The chain rule, the law of total probability, and Bayes Rule
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.4 链式法则、全概率公式和贝叶斯法则
- en: From the basic axioms of probability, we can derive the chain rule of probability,
    the law of total probability, and Bayes rule. These laws of probability are especially
    important in the context of probabilistic modeling and causal modeling, so we’ll
    highlight them briefly.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 从概率的基本公理中，我们可以推导出概率的链式法则、全概率公式和贝叶斯法则。这些概率法则在概率建模和因果建模的背景下尤为重要，因此我们将简要介绍它们。
- en: 'The *chain rule of probability* states that we can factorize a joint probability
    into the product of conditional probabilities. For example *P*(*X*, *Y*, *Z*)
    can be factorized as follows:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '**概率的链式法则**表明我们可以将联合概率分解为条件概率的乘积。例如，*P*(*X*, *Y*, *Z*) 可以如下分解：'
- en: '![figure](../Images/ness-ch2-eqs-1x.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch2-eqs-1x.png)'
- en: We can factorize in any order we like. Above, the ordering was *X*, then *Y*,
    then *Z*. However, *Y*, then *Z*, then *X*, or *Z*, then *X*, then *Y*, and other
    orderings are just as valid.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以按任何我们喜欢的顺序进行分解。在上面的例子中，顺序是 *X*，然后是 *Y*，然后是 *Z*。然而，*Y*，然后 *Z*，然后 *X*，或者 *Z*，然后
    *X*，然后 *Y*，以及其他顺序都是同样有效的。
- en: '![figure](../Images/ness-ch2-eqs-2x.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch2-eqs-2x.png)'
- en: The chain rule is important from a modeling and a computational perspective.
    The challenge of implementing a single object that represents *P*(*X*, *Y*, *Z*)
    is that it needs to map each combination of possible outcomes for *X*, *Y*, and
    *Z* to a probability value. The chain rule lets us break this into three separate
    tasks for each factor in a factorization of *P*(*X*, *Y*, *Z*).
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '**链式法则**在建模和计算方面都具有重要意义。实现一个代表 *P*(*X*, *Y*, *Z*) 的单一对象面临的挑战是，它需要将 *X*、*Y*
    和 *Z* 的所有可能结果的组合映射到一个概率值。链式法则让我们可以将这个任务分解为对 *P*(*X*, *Y*, *Z*) 分解中每个因素的三个单独任务。'
- en: The *law of total probability* allows you to relate marginal probability distributions
    (distributions of individual variables) to joint distributions. For example, if
    we want to derive the marginal distribution of *X*, denoted *P*(*X*), from the
    distribution of *X* and *Y*, denoted *P*(*X*, *Y*), we can sum over *Y*.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '**全概率公式**允许你将边缘概率分布（单个变量的分布）与联合分布联系起来。例如，如果我们想从 *X* 和 *Y* 的分布，即 *P*(*X*, *Y*)，推导出
    *X* 的边缘分布，即 *P*(*X*)，我们可以对 *Y* 进行求和。'
- en: '![figure](../Images/ness-ch2-eqs-3x.png)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch2-eqs-3x.png)'
- en: In figure 2.5, we did this by summing over *Y* in the rows to get *P*(*X*).
    In the case where *X* is a continuous random variable, we integrate over *Y* rather
    than summing over *Y*.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在图 2.5 中，我们通过对行中的 *Y* 进行求和来得到 *P*(*X*)。在 *X* 是连续随机变量的情况下，我们通过对 *Y* 进行积分而不是求和。
- en: 'Finally, we have *Bayes rule*:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有**贝叶斯法则**：
- en: '![figure](../Images/ness-ch2-eqs-4x.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch2-eqs-4x.png)'
- en: 'We derive this by taking the original definition of conditional probability
    and applying the chain rule to the numerator:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过将条件概率的原始定义应用于分子来推导这一点：
- en: '![figure](../Images/ness-ch2-eqs-5x.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch2-eqs-5x.png)'
- en: By itself, the Bayes rule is not particularly interesting—it’s a derivation.
    The more interesting idea is *Bayesianism*, a philosophy that uses Bayes rule
    to help the modeler reason about their subjective uncertainty regarding the problems
    they are modeling. I’ll touch on this in section 2.4.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯法则本身并不特别有趣——它是一个推导。更有趣的想法是**贝叶斯主义**，这是一种哲学，它使用贝叶斯法则来帮助模型者对其建模问题中的主观不确定性进行推理。我将在第
    2.4 节中涉及这一点。
- en: 2.1.5 Markovian assumptions and Markov kernels
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.5 马氏假设和马氏核
- en: 'A common approach to modeling when you have chains of factors is to use *Markovian
    assumptions*. This modeling approach takes an ordering of variables and makes
    a simplifying assumption that every element in the ordering depends only on the
    element that came directly before it. For example, consider again the following
    factorization of *P*(*x*, *y*, *z*):'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 当你有因子链时，建模的一个常见方法是使用 *马尔可夫假设*。这种建模方法对变量进行排序，并做出简化假设，即排序中的每个元素只依赖于它直接前面的元素。例如，再次考虑以下
    *P*(*x*, *y*, *z*) 的分解：
- en: '![figure](../Images/ness-ch2-eqs-6x.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch2-eqs-6x.png)'
- en: 'If we applied a Markovian assumption, this would simplify to:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们应用马尔可夫假设，这将简化为：
- en: '![figure](../Images/ness-ch2-eqs-7x.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch2-eqs-7x.png)'
- en: This would let us replace *P*(*z*|*x*, *y*) with *P*(*z*|*y*), which is easier
    to model. In this book, when we have a factor from a factorization that has been
    simplified using the Markov assumption, like *P*(*z*|*y*), we’ll call it a *Markov
    kernel*.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这将使我们能够用 *P*(*z*|*x*, *y*) 替换 *P*(*z*|*y*)，这更容易建模。在这本书中，当我们有一个使用马尔可夫假设简化过的因子时，比如
    *P*(*z*|*y*)，我们将它称为 *马尔可夫核*。
- en: The Markov assumption is a common simplifying assumption in statistics and machine
    learning; *Z* may *actually* still depend on *X* after accounting for *Y*, but
    we’re *assuming* that the dependence is weak and we can safely ignore it in our
    model. We’ll see that the Markovian assumption is key to graphical causality,
    where we’ll assume effects are independent of their indirect causes, given their
    direct causes.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 马尔可夫假设是统计学和机器学习中常见的简化假设；在考虑 *Y* 后，*Z* 可能 *实际上* 仍然依赖于 *X*，但我们 *假设* 这种依赖性很弱，我们可以在模型中安全地忽略它。我们将看到，马尔可夫假设是图形因果的关键，在那里我们将假设效应在给定其直接原因的情况下独立于其间接原因。
- en: 2.1.6 Parameters
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.6 参数
- en: Suppose I wanted to implement in code an abstract representation of a probability
    distribution, like the tabular distribution in figure 2.1, that I could use for
    different finite discrete outcomes. To start, if I were to model another three-sided
    die, it might have different probability values. What I want to keep is the basic
    structure as in figure 2.8.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我想在代码中实现一个概率分布的抽象表示，就像图2.1中的表格分布，我可以用于不同的有限离散结果。首先，如果我要模拟另一个三面骰子，它可能具有不同的概率值。我想要保持的是如图2.8所示的基本结构。
- en: '![figure](../Images/CH02_F08_Ness.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F08_Ness.png)'
- en: Figure 2.8 The scaffolding for a tabular probability distribution data structure
  id: totrans-117
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.8 表格概率分布数据结构的框架
- en: In code, I could represent this as some object type with a constructor that
    takes two arguments, *ρ*[1] and *ρ*[2], as in figure 2.9 (“*ρ*” is the Greek letter
    “rho”).
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，我可以将其表示为一个具有两个参数的构造函数的对象类型，即 *ρ*[1] 和 *ρ*[2]，如图2.9所示（“*ρ*”是希腊字母“rho”）。
- en: '![figure](../Images/CH02_F09_Ness.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F09_Ness.png)'
- en: Figure 2.9 Adding parameters to the data structure
  id: totrans-120
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.9 向数据结构添加参数
- en: The reason the third probability value is a function of the other two (instead
    of a third argument, *ρ*[3]) is because the probability values must sum to one.
    The set of two values {*ρ*[1], *ρ*[2]} are the parameters of the distribution.
    In programming terms, I could create a data type that represents a table with
    three values. Then, when I want a new distribution, I could construct a new instance
    of this type with these two parameters as arguments.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 第三个概率值是其他两个值的函数（而不是第三个参数，*ρ*[3]），是因为概率值必须加起来等于1。值集 {*ρ*[1], *ρ*[2]} 是分布的参数。在编程术语中，我可以创建一个表示有三个值的表的类型。然后，当我想要一个新的分布时，我可以使用这两个参数作为参数构造这个类型的新实例。
- en: Finally, in my three-sided die example, there were three outcomes, {1, 2, 3}.
    Perhaps I want my data structure to handle a different prespecified number of
    outcomes. In that case, I’d need a parameter for the number of outcomes. Let’s
    denote that with the Greek letter kappa, *Κ*. My parameterization is {*Κ*, *ρ*[1],
    *ρ*[2], … *ρ**[Κ]*[–1]}, where *ρ**[Κ]*is 1 minus the sum of the other *ρ* parameters.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在我的三面骰子示例中，有三种结果，{1, 2, 3}。也许我想要我的数据结构处理不同的预指定数量的结果。在这种情况下，我需要一个表示结果数量的参数。让我们用希腊字母kappa，*Κ*来表示它。我的参数化是
    {*Κ*, *ρ*[1], *ρ*[2], … *ρ**[Κ]*[–1]}，其中 *ρ**[Κ]*是其他 *ρ* 参数总和的1减去。
- en: In the pgmpy classes `DiscreteFactor` and `TabularCPD`, the *ρ**’*s (rhos) are
    the list of values passed to the `values` argument, and the *Κ* corresponds to
    the values passed to the `cardinality`, `variable_card`, and `evidence_card` arguments.
    Once we have a representation of a probability distribution like `TabularCPD`,
    we can specify an instance of that distribution with a set of parameters.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在 pgmpy 类的 `DiscreteFactor` 和 `TabularCPD` 中，*ρ**’*s（rho）是传递给 `values` 参数的值的列表，而
    *Κ* 对应于传递给 `cardinality`、`variable_card` 和 `evidence_card` 参数的值。一旦我们有了像 `TabularCPD`
    这样的概率分布表示，我们就可以使用一组参数指定该分布的一个实例。
- en: Greeks vs. Romans
  id: totrans-124
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 希腊字母与罗马字母
- en: In this book, I use Roman letters (*A*, *B*, and *C*) to refer to random variables
    representing objects in the modeling domain, such as a “dice roll” or “gross domestic
    product,” and I use Greek letters for so-called *parameters*. *Parameters* in
    this context are values that characterize the probability distributions of the
    Roman-lettered variables. This distinction between Greeks and Romans is not as
    important in statistics; for example, a Bayesian statistician treats both Roman
    and Greek letters as random variables. However, in causal modeling the difference
    matters, because Roman letters can be causes and effects, while Greek letters
    serve to characterize the statistical relationship between causes and effects.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书中，我使用罗马字母（*A*、*B* 和 *C*）来指代建模领域中代表对象的随机变量，例如“掷骰子”或“国内生产总值”，我使用希腊字母来表示所谓的
    *参数*。在这个上下文中，*参数*是描述罗马字母变量概率分布的值。希腊字母和罗马字母之间的这种区别在统计学中并不那么重要；例如，贝叶斯统计学家将罗马和希腊字母都视为随机变量。然而，在因果建模中，这种区别很重要，因为罗马字母可以是原因和结果，而希腊字母用于表征原因和结果之间的统计关系。
- en: 2.1.7 Canonical classes of probability distribution
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.7 概率分布的典型类别
- en: There are several common classes of distribution functions. For example, the
    tabular examples we just studied are examples from the class of *categorical distributions*.
    Categorical distributions are distributions on discrete outcomes we can view as
    categories, such as {“ice cream”, “frozen yogurt”, “sherbet”}. A Bernoulli distribution
    class is a special case of the categorical class where there are only two possible
    outcomes. A discrete uniform distribution is a categorical distribution where
    all outcomes have the same probability. In implementation, categorical distributions
    are defined either on the categories directly (like “tails” and “heads”) or on
    indices to the category (like 0 and 1).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 存在几个常见的分布函数类别。例如，我们刚刚研究的表格示例是来自 *分类分布* 类别的例子。分类分布是在我们可以视为类别的离散结果上的分布，例如 {“冰淇淋”，“冷冻酸奶”，“雪芭”}。伯努利分布类是分类类的一个特殊情况，其中只有两种可能的结果。离散均匀分布是所有结果都有相同概率的分类分布。在实现中，分类分布可以直接定义在类别上（如“尾巴”和“头部”），或者定义在类别的索引上（如
    0 和 1）。
- en: Discrete vs. continuous random variables
  id: totrans-128
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 离散与连续随机变量
- en: For discrete random variables, we have been using have probability distribution
    functions with the notation *P*(*X*=*x*). Probability distribution functions return
    the probability that a variable takes a specific value. With continuous random
    variables, we also have *probability density functions*, which describe the relative
    likelihood of observing any outcome within a continuous range and that integrate
    over an interval to give a probability.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 对于离散随机变量，我们一直使用带有符号 *P*(*X*=*x*) 的概率分布函数。概率分布函数返回变量取特定值的概率。对于连续随机变量，我们也有 *概率密度函数*，它描述了在连续范围内观察任何结果的相对可能性，并且通过区间积分给出概率。
- en: When we have specific cases where discrete or continuous parameterizations matter,
    we’ll call them out and use *p*(*X*=*x*) to denote a probability density function.
    However, in this book, we’ll focus on framing our causal questions independently
    of whether we’re in a discrete or continuous setting. We’ll stick mostly to the
    probability distribution function notation *P*(*X*=*x*), but keep in mind that
    the causal ideas work in the continuous case as well.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们遇到离散或连续参数化有特定情况时，我们会将其指出并使用 *p*(*X*=*x*) 来表示概率密度函数。然而，在这本书中，我们将专注于独立于我们是在离散还是连续环境中来构建我们的因果问题。我们将主要使用概率分布函数的符号
    *P*(*X*=*x*)，但请记住，因果思想在连续情况下同样适用。
- en: There are other canonical distribution classes appropriate for continuous, bounded,
    or unbounded sets of variables. For example, the normal (Gaussian) distribution
    class illustrates the famous “bell curve.” I use the term “class” (or, perhaps
    more ideally, “type”) in the computer science sense because the distribution isn’t
    realized until we assign our Greek-lettered parameters. For a normal (Gaussian)
    distribution class, the probability density function is
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 对于连续的、有界的或无界的变量集合，还有其他适合的典型分布类别。例如，正态（高斯）分布类别展示了著名的“钟形曲线”。我在计算机科学的意义上使用术语“类别”（或者，可能更理想的是，“类型”），因为分布只有在我们分配了希腊字母参数后才会实现。对于一个正态（高斯）分布类别，概率密度函数是
- en: '![figure](../Images/ness-ch2-eqs-8x.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch2-eqs-8x.png)'
- en: Here, *μ* and *σ* are the parameters.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*μ*和*σ*是参数。
- en: Figure 2.10 is a popular figure that illustrates several commonly used canonical
    distributions. The arrows between the distributions highlight relationships between
    the distributions (e.g., Bernoulli is a special case of the binomial distribution)
    that we won’t dive into here.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.10是一个流行的图表，展示了几个常用的典型分布。分布之间的箭头突出了它们之间的关系（例如，伯努利分布是二项分布的特殊情况），我们在这里不会深入探讨。
- en: '![figure](../Images/CH02_F10_Ness.png)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F10_Ness.png)'
- en: Figure 2.10 A popular common set of canonical probability distributions. The
    edges capture mathematical relationships between the distributions (that we won’t
    get into here). Light-colored distributions are discrete and dark-colored distributions
    are continuous. An arrow represents the existence of a transformation that converts
    one distribution to another.
  id: totrans-136
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.10 一个流行的典型概率分布集合。边捕捉了分布之间的数学关系（我们不会在这里探讨）。浅色分布是离散的，深色分布是连续的。箭头表示存在一个转换，可以将一个分布转换为另一个分布。
- en: Types of parameters
  id: totrans-137
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 参数类型
- en: In probabilistic modeling settings, it is useful to have an intuition for how
    to interpret canonical parameters. To that end, think of the probability in a
    distribution as a scarce resource that must be shared across all the possible
    outcomes. Some outcomes may get more than others, but at the end of the day, it
    all must sum or integrate to 1\. Parameters characterize how the finite probability
    is distributed to the outcomes.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在概率建模环境中，对如何解释典型参数有一个直观的理解是有用的。为此，将分布中的概率视为必须分配给所有可能结果的稀缺资源。某些结果可能比其他结果得到更多，但最终，所有结果的总和或积分必须等于1。参数描述了有限概率如何分配给结果。
- en: As an analogy, we’ll use a city with a fixed population. The parameters of the
    city determine where that population is situated. Location parameters, such as
    the normal distribution’s “*μ*” (*μ* is the mean of the normal, but not all *location
    parameters* are means), are like the pin that drops down when you search the city’s
    name in Google Maps. The pin characterizes a precise point we might call the “city
    center.” In some cities, most of the people live near the city center, and it
    gets less populated the further away from the center you go. But in other cities,
    other non-central parts of the city are densely populated. *Scale parameters*,
    like the normal’s “*σ*” (*σ* is the standard deviation of a normal distribution,
    but not all scale parameters are standard deviation parameters), determine the
    spread of the population; Los Angeles has a high scale parameter. A *shape parameter*
    (and its inverse, the *rate parameter*) affects the shape of a distribution in
    a manner that does not simply shift it (as a location parameter does) or stretch
    or shrink it (as a scale parameter does). As an example, think of the skewed shape
    of Hong Kong, which has a densely packed collection of skyscrapers in the downtown
    area, while the more residential Kowloon has shorter buildings spread over a wider
    space.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 作为类比，我们将使用一个固定人口的城市。城市的参数决定了人口所在的位置。位置参数，如正态分布的“*μ*”（μ是正态分布的均值，但并非所有位置参数都是均值），就像你在谷歌地图上搜索城市名称时掉下的针。这个针表征了一个精确的点，我们可以称之为“城市中心”。在一些城市，大多数人住在城市中心附近，离中心越远人口越少。但在其他城市，城市的其他非中心区域人口密集。*尺度参数*，如正态分布的“*σ*”（σ是正态分布的标准差，但并非所有尺度参数都是标准差参数），决定了人口分布的广度；洛杉矶具有高尺度参数。*形状参数*（及其倒数，*速率参数*）以不简单是平移（如位置参数所做的那样）或拉伸或缩小（如尺度参数所做的那样）分布的方式影响分布的形状。例如，考虑香港的偏斜形状，其市中心区域密集地聚集着摩天大楼，而更住宅化的九龙则拥有更矮的建筑，分布在更广阔的空间中。
- en: The Pyro library provides canonical distributions as modeling primitives. The
    Pyro analog to a discrete categorical distribution table is a `Categorical` object.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: Pyro库提供了标准分布作为建模原语。Pyro与离散分类分布表相对应的是`Categorical`对象。
- en: Listing 2.3 Canonical parameters in Pyro
  id: totrans-141
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.3 Pyro中的标准参数
- en: '[PRE12]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '#1 Pyro includes the commonly used canonical distributions.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 Pyro包括常用的标准分布。'
- en: '#2 The Categorical distribution takes a list of probability values, each value
    corresponding to an outcome.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 分类分布接受一个概率值列表，每个值对应一个结果。'
- en: 'This prints the following representations of the distribution objects:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打印出以下分布对象的表示：
- en: '[PRE13]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Rather than providing a probability value, the `log_prob` method will provide
    the natural log of the probability value, because log probabilities have computational
    advantages over regular probabilities. Exponentiating (taking *e*^(*l*) where
    *l* is the log probability) converts back to the probability scale. For example,
    we can create a Bernoulli distribution object with a parameter value of 0.4.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 与提供概率值不同，`log_prob`方法将提供概率值的自然对数，因为对数概率在计算上比常规概率有优势。对数（取*e*^(*l*，其中*l*是对数概率））转换回概率尺度。例如，我们可以创建一个参数值为0.4的伯努利分布对象。
- en: '[PRE14]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: That distribution assigns a 0.4 probability to the value 1.0\. For numerical
    reasons, we typically work with the natural log of probability values.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 该分布将0.4的概率分配给值1.0。由于数值原因，我们通常使用概率值的自然对数进行工作。
- en: 'We can use the `exp` function in the math library to convert from log probability
    back to the probability scale:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用数学库中的`exp`函数将对数概率转换回概率尺度：
- en: '[PRE15]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Exponentiating the log probability returns the following probability value:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 对数概率进行指数运算返回以下概率值：
- en: '[PRE16]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: It is close, but not the same as 0.4 due to rounding error associated with floating-point
    precision in computer calculations.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 由于计算机计算中浮点精度相关的舍入误差，它接近但不等于0.4。
- en: Conditional probability with canonical distributions
  id: totrans-155
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用标准分布的条件概率
- en: There are few canonical distributions commonly used to characterize sets of
    individual random variables, such as random vectors or matrices. However, we can
    use the chain rule to factor a joint probability distribution into conditional
    distributions that we can represent with canonical distributions. For example,
    we could represent *Y* conditioned on *X* and *Z* with the following normal distribution,
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 很少有标准的分布被广泛用于描述单个随机变量的集合，例如随机向量或矩阵。然而，我们可以使用链式法则将联合概率分布分解为条件分布，这些条件分布可以用标准分布来表示。例如，我们可以用以下正态分布来表示*Y*在*X*和*Z*条件下的情况，
- en: '![figure](../Images/ness-ch2-eqs-9x.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch2-eqs-9x.png)'
- en: 'where the location parameter *μ*(*x*,*z*) is a function of *x* and *z*. An
    example is the following linear function:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 其中位置参数*μ*(*x*,*z*)是*x*和*z*的函数。以下是一个线性函数的例子：
- en: '![figure](../Images/ness-ch2-eqs-10x.png)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch2-eqs-10x.png)'
- en: Other functions, such as neural networks, are possible as well. These *β* parameters
    are typically called *weight parameters* in machine learning.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 其他函数，如神经网络，也是可能的。这些*β*参数在机器学习中通常被称为*权重参数*。
- en: 2.1.8 Visualizing distributions
  id: totrans-161
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.8 可视化分布
- en: In probabilistic modeling and Bayesian inference settings, we commonly conceptualize
    distributions in terms of visuals. In the discrete case, a common visualization
    is the bar plot. For example, we can visualize the probabilities in figure 2.3
    as the bar plot in figure 2.11\. Note that this is not a histogram; I’ll highlight
    the distinction in section 2.3.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在概率建模和贝叶斯推理设置中，我们通常用视觉来概念化分布。在离散情况下，一个常见的可视化是条形图。例如，我们可以将图2.3中的概率可视化成图2.11中的条形图。请注意，这并不是直方图；我将在第2.3节中强调这种区别。
- en: '![figure](../Images/CH02_F11_Ness.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F11_Ness.png)'
- en: Figure 2.11 Visualization of a discrete probability distribution. The outcomes
    in the distribution are on the horizontal axis, and probability is on the vertical
    axis.
  id: totrans-164
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.11离散概率分布的可视化。分布的输出在水平轴上，概率在垂直轴上。
- en: 'We still use visualizations when the distribution has a non-finite set of outcomes.
    For example, figure 2.12 overlays two distributions functions: a discrete Poisson
    distribution and a continuous normal (Gaussian) distribution (I specified the
    two distributions in such a way that they overlapped). The discrete Poisson has
    no upper bound on outcomes (its lower bound is 0), but the probability tapers
    off for higher numbers, resulting in smaller and smaller bars until the bar becomes
    too infinitesimally small to draw. We visualize the normal distribution by simply
    drawing the probability distribution function as a curve in the figure. The normal
    has no lower or upper bound, but the further away you get from the center, the
    smaller the probability values get.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 当分布的结果集不是有限集时，我们仍然使用可视化。例如，图2.12叠加了两个分布函数：一个离散的泊松分布和一个连续的正态（高斯）分布（我这样指定两个分布，使它们重叠）。离散泊松分布没有结果的上限（其下限是0），但随着数字的增加，概率逐渐减少，导致柱状图越来越小，直到柱状图变得极其微小而无法绘制。我们通过在图中绘制概率分布函数作为曲线来可视化正态分布。正态分布没有上下限，但离中心越远，概率值越小。
- en: '![figure](../Images/CH02_F12_Ness.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F12_Ness.png)'
- en: Figure 2.12 A continuous normal distribution (solid line) approximates a discrete
    Poisson distribution (gray bars). Again, the outcomes are on the horizontal axis,
    and the probability values are on the vertical axis.
  id: totrans-167
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.12 一个连续的正态分布（实线）近似了一个离散的泊松分布（灰色柱状图）。同样，结果值在水平轴上，概率值在垂直轴上。
- en: Visualizing conditional probability distributions involves mapping each conditioning
    variable to some element in the image. For example, in figure 2.13, *X* is discrete,
    and *Y* conditioned on *X* has a normal distribution where the location parameter
    is a function of *X*.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 可视化条件概率分布涉及将每个条件变量映射到图像中的某个元素。例如，在图2.13中，*X* 是离散的，而 *Y* 在 *X* 条件下的分布是一个正态分布，其中位置参数是
    *X* 的函数。
- en: '![figure](../Images/CH02_F13_Ness.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F13_Ness.png)'
- en: Figure 2.13 A visualization of the conditional probability distribution of continuous
    *Y*, given discrete *X*. For different values of *X*, we get a different distribution
    of *Y*.
  id: totrans-170
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.13 给定离散的 *X*，连续的 *Y* 条件概率分布的可视化。对于不同的 *X* 值，我们得到不同的 *Y* 分布。
- en: Since *X* is discrete, it is simplest to map *X* to color and overlay the curves
    for *P*(*Y*|*X*=1), *P*(*Y*|*X*=2), and *P*(*Y*|*X*=3). However, if we wanted
    to visualize *P*(*Y*|*X*, *Z*), we’d need to map *Z* to an aesthetic element other
    than color, such as a third axis in a pseudo-3D image or rows in a grid of images.
    But there is only so much information we can add to a 2D visualization. Fortunately,
    conditional independence helps us reduce the number of conditioning variables.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 *X* 是离散的，将 *X* 映射到颜色并叠加 *P*(*Y*|*X*=1)、*P*(*Y*|*X*=2) 和 *P*(*Y*|*X*=3) 的曲线是最简单的。然而，如果我们想可视化
    *P*(*Y*|*X*, *Z*)，我们需要将 *Z* 映射到除颜色之外的美学元素，例如伪3D图像中的第三个轴或图像网格中的行。但是，我们只能向2D可视化添加有限的信息。幸运的是，条件独立性帮助我们减少了条件变量的数量。
- en: 2.1.9 Independence and conditional independence
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.9 独立性与条件独立性
- en: Two random variables are *independent* if, informally speaking, observing an
    outcome of one random variable does not affect the probability of outcomes for
    the other variable, i.e., *P*(*y*|*x*)*=**P*(*y*). We denote this as *X* ⊥ *Y*.
    If two variables are not independent, they are *dependent*.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 两个随机变量如果，非正式地说，观察一个随机变量的结果不影响另一个变量的结果概率，即 *P*(*y*|*x*)* = **P*(*y*), 则它们是 *独立*
    的。我们用 *X* ⊥ *Y* 表示这一点。如果两个变量不是独立的，它们是 *相关* 的。
- en: Two dependent variables can become *conditionally independent* given other variables.
    For example, *X* ⊥ *Y* | *Z* means that *X* and *Y* may be dependent, but they
    are conditionally independent given *Z*. In other words, if *X* and *Y* are dependent,
    and *X* ⊥ *Y* | *Z*, then it is not true that *P*(*y*|*x*) ≠ *P*(*y*) but it is
    true that *P*(*y*|*x*, *z*) = *P*(*y*|*z*).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在给定其他变量的情况下，两个相关变量可以成为 *条件独立* 的。例如，*X* ⊥ *Y* | *Z* 意味着 *X* 和 *Y* 可能是相关的，但给定
    *Z* 时它们是条件独立的。换句话说，如果 *X* 和 *Y* 是相关的，并且 *X* ⊥ *Y* | *Z*，那么 *P*(*y*|*x*) ≠ *P*(*y*)
    并不成立，但 *P*(*y*|*x*, *z*) = *P*(*y*|*z*) 是成立的。
- en: Independence is a powerful tool for simplification
  id: totrans-175
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 独立性是一个强大的简化工具
- en: Independence is a powerful tool for simplifying representations of probability
    distributions. Consider a joint probability distribution *P*(*W*, *X*, *Y*, *Z*)
    represented as a table. The number of cells in the table would be the product
    of the number of possible outcomes each for *W*, *X*, *Y*, and *Z*. We could use
    the chain rule to break the problem up into factors {*P*(*W*), *P*(*X*|*W*), *P*(*Y*|*X*,
    *W*), *P*(*Z*|*Y*, *X*, *W*)}, but the total number of parameters across these
    factors wouldn’t change, so the aggregate complexity would be the same.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 独立性是简化概率分布表示的强大工具。考虑一个联合概率分布 *P*(*W*, *X*, *Y*, *Z*) 以表格形式表示。表格中的单元格数量将是 *W*、*X*、*Y*
    和 *Z* 每个可能的输出的数量的乘积。我们可以使用链式法则将问题分解为因子 {*P*(*W*), *P*(*X*|*W*), *P*(*Y*|*X*, *W*),
    *P*(*Z*|*Y*, *X*, *W*)}，但这些因子跨度的总参数数量不会改变，因此总复杂性保持不变。
- en: However, what if *X* ⊥ *W*? Then *P*(*X*|*W*) reduces to *P*(*X*). What if *Z*
    ⊥ *Y*|*X*? Then *P*(*Z*|*Y*, *X*, *W*) reduces to *P*(*Z*|*X*, *W*). Every time
    we can impose a pairwise conditional independence condition as a constraint on
    the joint probability distribution, we can reduce the complexity of the distribution
    by a large amount. Indeed, much of model building and evaluation in statistical
    modeling, regularization in machine learning, and deep learning techniques such
    as “drop-out” are either direct or implicit attempts to impose conditional independence
    on the joint probability distribution underlying the data.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果 *X* 与 *W* 正交？那么 *P*(*X*|*W*) 就简化为 *P*(*X*)。如果 *Z* 与 *Y*|*X* 正交？那么 *P*(*Z*|*Y*,
    *X*, *W*) 就简化为 *P*(*Z*|*X*, *W*)。每次我们都可以将成对的条件独立性条件作为联合概率分布的约束来施加，这样就可以大幅度降低分布的复杂性。实际上，在统计建模中的模型构建和评估、机器学习中的正则化以及“dropout”等深度学习技术，要么是直接要么是隐含地试图在数据的联合概率分布上施加条件独立性。
- en: Conditional independence and causality
  id: totrans-178
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 条件独立性和因果性
- en: Conditional independence is fundamental to causal modeling. Causal relationships
    lead to conditional independence between correlated variables. For example, a
    child’s parents’ and grandparents’ blood types are all causes of that child’s
    blood type; these blood types are all correlated. But all you need is the parents’
    blood type, the direct causes, to fully determine the child’s blood type, as illustrated
    in figure 2.14\. In probabilistic terms, the child’s and grandparents’ blood types
    are conditionally independent, given the parents.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 条件独立性是因果建模的基础。因果关系导致相关变量之间的条件独立性。例如，一个孩子的父母和祖父母的血型都是该孩子血型的原因；这些血型都是相关的。但你只需要父母的血型，即直接原因，就可以完全确定孩子的血型，如图2.14所示。在概率术语中，孩子的和祖父母的血型在给定父母的情况下条件独立。
- en: '![figure](../Images/CH02_F14_Ness.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F14_Ness.png)'
- en: Figure 2.14 How causality can induce conditional independence. The blood types
    of the parents cause the blood type of the child. The grandfather’s blood type
    is correlated with that of the child’s (dashed line). But the parents’ blood types
    are direct causes that fully determine that of the child. These direct causes
    render the child’s and grandfather’s blood types conditionally independent.
  id: totrans-181
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.14 因果性如何导致条件独立性。父母的血型导致孩子的血型。祖父的血型与孩子的血型相关（虚线）。但父母的血型是直接原因，完全决定了孩子的血型，如图2.14所示。这些直接原因使得孩子和祖父的血型在给定父母的情况下条件独立。
- en: The fact that causality induces conditional independence allows us to learn
    and validate causal models against evidence of conditional independence. In chapter
    4, we’ll explore the relationship between conditional independence and causality
    in formal terms.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 因果性导致条件独立性的事实使我们能够根据条件独立性的证据来学习和验证因果模型。在第4章中，我们将以正式术语探讨条件独立性和因果性之间的关系。
- en: 2.1.10 Expected value
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1.10 期望值
- en: The *expected value* of a function of a random variable is the weighted average
    of the function’s possible output values, where the weight is the probability
    of that outcome.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 随机变量函数的 *期望值* 是函数可能输出值的加权平均值，其中权重是该结果的概率。
- en: '![figure](../Images/ness-ch2-eqs-11x.png)![figure](../Images/ness-ch2-eqs-12x.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch2-eqs-11x.png)![figure](../Images/ness-ch2-eqs-12x.png)'
- en: In the case of a continuum of possible outcomes, the expectation is defined
    by integration.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在可能结果为连续的情况下，期望值由积分定义。
- en: '![figure](../Images/ness-ch2-eqs-13x.png)![figure](../Images/ness-ch2-eqs-14x.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch2-eqs-13x.png)![figure](../Images/ness-ch2-eqs-14x.png)'
- en: Some of the causal quantities we’ll be interested in calculating will be defined
    in terms of expectation. Those quantities only reason about the expectation, not
    about how the expectation is calculated. It is easier to get an intuition for
    a problem when working with the basic arithmetic of discrete expectation rather
    than integral calculus in the continuous case. So, in this book, when there is
    a choice, I use examples with discrete random variables and discrete expectation.
    The causal logic in those examples all generalize to the continuous case.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将要计算的一些因果量将用期望来定义。这些量只关于期望进行推理，而不是关于期望是如何计算的。与连续情况下的积分微积分相比，使用离散期望的基本算术更容易获得对问题的直观理解。因此，在这本书中，当有选择时，我使用离散随机变量和离散期望的例子。这些例子中的因果逻辑都推广到连续情况。
- en: 'There are many interesting mathematical properties of expectation. In this
    book, we care about the fact that conditional expectations simplify under conditional
    independence: If *X* ⊥ *Y*, then *E*(*X*|*Y*) = *E*(*X*). If *X* ⊥ *Y*|*Z*, then
    *E*(*X*|*Y*,*Z*) = *E*(*X*|*Z*). In simpler terms, if two variables (*X* and *Y*)
    are independent, our expectation for one does not change with information about
    the other. If their independence holds conditional on a third variable (*Z*),
    our expectation for one, given that we know the third variable, is unaffected
    by information about the other variable.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 期望有许多有趣的数学性质。在这本书中，我们关注的是在条件独立下条件期望的简化：如果 *X* ⊥ *Y*，那么 *E*(*X*|*Y*) = *E*(*X*)。如果
    *X* ⊥ *Y*|*Z*，那么 *E*(*X*|*Y*,*Z*) = *E*(*X*|*Z*)。用更简单的话说，如果两个变量 (*X* 和 *Y*) 是独立的，我们对其中一个变量的期望不会随着另一个变量的信息而改变。如果它们的独立性在第三个变量
    (*Z*) 的条件下成立，那么在知道第三个变量的情况下，我们对其中一个变量的期望不会受到另一个变量信息的影响。
- en: 'Other than this, the most important property is the linearity of the expectation,
    meaning that the expectation passes through linear functions. Here are some useful
    reference examples of the linearity of expectation:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这个之外，最重要的性质是期望的线性，意味着期望通过线性函数。以下是期望线性的一些有用的参考例子：
- en: 'For random variables *X* and *Y*: *E*(*X* + *Y*) = *E*(*X*) + *E*(*Y*) and'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于随机变量 *X* 和 *Y*：*E*(*X* + *Y*) = *E*(*X*) + *E*(*Y*) 和
- en: '![figure](../Images/ness-ch2-eqs-15x.png)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch2-eqs-15x.png)'
- en: 'For constants *a* and *b*: *E*(*aX* + *b*) = *aE*(*X*) + *b*'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于常数 *a* 和 *b*：*E*(*aX* + *b*) = *aE*(*X*) + *b*
- en: 'If *X* only has outcomes 0 and 1, and *E*(*Y*|*X*) = *aX* + *b*, then *E*(*Y*|*X*=1)
    – *E*(*Y*|*X*=0) = *a*. (This is true because *a**1 + *b* – (*a**0 + *b*) = *a*.
    Spoiler alert: this one is important for linear regression-based causal effect
    inference techniques.)'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果随机变量 *X* 只有 0 和 1 两种结果，并且 *E*(*Y*|*X*) = *aX* + *b*，那么 *E*(*Y*|*X*=1) – *E*(*Y*|*X*=0)
    = *a*。 (这是因为 *a**1 + *b* – (*a**0 + *b*) = *a*。剧透一下：这一点对于基于线性回归的因果效应推断技术非常重要。)
- en: The mean of the random variable’s distribution is the expected value of the
    variable itself, as in *E*(*X*) (i.e., the function is the *identity function*,
    *f*(*X*) = *X*). In several canonical distributions, the mean is a simple function
    of the parameters. In some cases, such as in the normal distribution, the location
    parameter is equivalent to the expectation. But the location parameter and the
    expectation are not always the same. For example, the Cauchy distribution has
    a location parameter, but its mean is undefined.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 随机变量分布的均值是变量的期望值本身，如在 *E*(*X*) 中（即函数是恒等函数，*f*(*X*) = *X*）。在几个典型分布中，均值是参数的简单函数。在某些情况下，例如在正态分布中，位置参数等同于期望。但位置参数和期望并不总是相同的。例如，柯西分布有一个位置参数，但它的均值是未定义的。
- en: In the next section, you’ll learn how to represent distributions and calculate
    expectations using computational methods.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将学习如何使用计算方法来表示分布和计算期望。
- en: 2.2 Computational probability
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.2 计算概率
- en: We need to *code* probability distributions and expectations from probability
    to use them in our models. In the previous section, you saw how to code up a probability
    distribution for a three-sided die. But how do we code up *rolling* a three-sided
    die? How do we write code representing two dice rolls that are conditionally independent?
    While we’re at it, how do we get a computer to do the math that calculates an
    expectation? How do we get a computer, where everything is deterministic, to roll
    dice so that the outcome is unknown beforehand?
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要*编码*概率分布和期望值，从概率到我们的模型中使用。在上一节中，你看到了如何为三面骰子编码概率分布。但我们是怎样编码*掷*三面骰子的？我们如何编写代码来表示两个条件独立的骰子掷出的结果？在此同时，我们如何让计算机做计算期望值的数学运算？我们如何让一个所有事情都是确定性的计算机掷骰子，使得结果在掷之前是未知的？
- en: 2.2.1 The physical interpretation of probability
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.1 概率的物理解释
- en: Suppose I have a three-sided die. I have some probability values assigned to
    each outcome on the die. What do those probability values mean? How do I interpret
    them?
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我有一个三面骰子。我为骰子上的每个结果分配了一些概率值。这些概率值意味着什么？我如何解释它们？
- en: Suppose I repeatedly rolled the die and kept a running tally of how many times
    I saw each outcome. First, the roll is random, meaning that although I roll it
    the same way each time, I get varying results. The physical shape of the die affects
    those tallies; if one face of the die is larger than the other two, that size
    difference will affect the count. As I repeat the roll many times, the proportion
    of total times I see a given outcome converges to a number. Suppose I use that
    number for my probability value. Further, suppose I interpret that number as the
    “chance” of seeing that outcome each time I roll.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我反复掷骰子，并记录每次看到每个结果出现的次数。首先，掷骰子是随机的，这意味着尽管我每次都以相同的方式掷骰子，但结果却各不相同。骰子的物理形状会影响这些计数；如果骰子的一个面比其他两个面大，那么这种大小差异会影响计数。当我重复掷骰子多次后，我看到某个特定结果的比例会收敛到一个数字。假设我用这个数字作为我的概率值。进一步，假设我将这个数字解释为每次掷骰子看到该结果的机会。
- en: This idea is called *physical* (or *frequentist*) *probability*. Physical probability
    means imagining some repeatable physical random process that results in one outcome
    among a set of possible outcomes. We assign a probability value using the convergent
    proportion of times the outcome appears when we repeat the random process ad infinitum.
    We then interpret that probability as the propensity for that physical process
    to produce that outcome.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 这个想法被称为*物理*（或*频率主义*）*概率*。物理概率意味着想象一个可重复的物理随机过程，该过程在可能的结果集中产生一个结果。我们使用在无限次重复随机过程时出现该结果的比例来分配概率值。然后我们将那个概率解释为该物理过程产生该结果的趋势。
- en: 2.2.2 Random generation
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.2 随机生成
- en: Given the preceding definition for physical probability, we can define random
    generation. In *random generation*, an algorithm randomly chooses an outcome from
    a given distribution. The algorithm’s choice is inspired by physical probability;
    the way it selects an outcome is such that if we ran the algorithm ad infinitum,
    the proportion of times it would choose that outcome would equal the distribution’s
    probability value for that outcome.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 根据前面的物理概率定义，我们可以定义随机生成。在*随机生成*中，算法从给定的分布中随机选择一个结果。算法的选择受到物理概率的启发；它选择结果的方式是，如果我们无限次地运行该算法，它选择该结果的比例将等于该分布对该结果的概率值。
- en: Computers are deterministic machines. If we repeatedly run a computer procedure
    on the same input, it will always return the same output; it cannot produce anything
    genuinely random (unless it has a random input). Computers have to use deterministic
    algorithms to emulate random generation. These algorithms are called pseudo-random
    number generators—they take a starting number, called a *random seed*, and return
    a deterministic series of numbers. Those algorithms mathematically guarantee that
    a series of numbers is statistically indistinguishable from the ideal of random
    generation.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机是确定性的机器。如果我们对相同的输入反复运行计算机程序，它总是会返回相同的输出；它不能产生真正的随机（除非它有随机输入）。计算机必须使用确定性算法来模拟随机生成。这些算法被称为伪随机数生成器——它们从一个起始数字开始，称为*随机种子*，并返回一系列确定性的数字。这些算法在数学上保证一系列数字在统计上与理想随机生成的概念不可区分。
- en: 'In notation, I write random generation as follows:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在符号表示中，我这样写随机生成：
- en: '![figure](../Images/ness-ch2-eqs-16x.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch2-eqs-16x.png)'
- en: This reads as “x is generated from the probability distribution of *X*.”
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 这读作“x是从 *X* 的概率分布中生成的。”
- en: 'In random generation, synonyms for “generate” include “simulate” and “sample.”
    For example, in pgmpy the `sample` method in `DiscreteFactor` does random generation.
    It returns a pandas DataFrame. Note that since this is random generation, you
    will likely get different outputs when you run this code:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在随机生成中，“生成”的同义词包括“模拟”和“采样”。例如，在 pgmpy 中，`DiscreteFactor` 的 `sample` 方法执行随机生成。它返回一个
    pandas DataFrame。请注意，由于这是随机生成，当你运行此代码时，你可能会得到不同的输出：
- en: '![figure](../Images/ness-ch2-eqs-17x.png)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch2-eqs-17x.png)'
- en: Listing 2.4 Simulating random variates from `DiscreteFactor` in pgmpy
  id: totrans-211
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.4 在 pgmpy 中从 `DiscreteFactor` 模拟随机变量
- en: '[PRE17]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '#1 n is the number of instances you wish to generate.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 n 是你希望生成的实例数量。'
- en: This produces the table pictured in figure 2.15.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这生成了图2.15所示的表格。
- en: '![figure](../Images/CH02_F15_Ness.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F15_Ness.png)'
- en: Figure 2.15 Generating one instance from *P*(*X*) creates a pandas `DataFrame`
    object with one row.
  id: totrans-216
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.15 从 *P*(*X*) 生成一个实例创建了一个包含一行数据的 pandas `DataFrame` 对象。
- en: We can also generate from joint probability distributions.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们也可以从联合概率分布中生成。
- en: '[PRE18]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: This produces the table pictured in figure 2.16.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这生成了图2.16所示的表格。
- en: '![figure](../Images/CH02_F16_Ness.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F16_Ness.png)'
- en: Figure 2.16 Generating one instance from *P*(*X**,* *Y*) creates a pandas `DataFrame`
    object with one row.
  id: totrans-221
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.16 从 *P*(*X**, * *Y*) 生成一个实例创建了一个包含一行数据的 pandas `DataFrame` 对象。
- en: 'Pyro also has a `sample` method for canonical distributions:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: Pyro 还有一个用于规范分布的 `sample` 方法：
- en: '[PRE19]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This generates a sample from that categorical distribution, i.e., either 0,
    1, or 2\.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 这生成了一个从该分类分布的样本，即0、1或2。
- en: '[PRE20]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 2.2.3 Coding random processes
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.3 编码随机过程
- en: We can write our own random processes as code when we want to generate values
    in a particular way. A random process written as code is sometimes called a *stochastic
    function*, *probabilistic subroutine*, or *probabilistic program*. For example,
    consider the joint probability distribution *P*(*X*, *Y*, *Z*). How can we randomly
    generate from this joint distribution? Unfortunately, software libraries don’t
    usually provide pseudo-random generation for arbitrary joint distributions.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们想要以特定方式生成值时，可以将自己的随机过程编写为代码。将随机过程编写为代码有时被称为 *随机函数*、*概率子程序* 或 *概率程序*。例如，考虑联合概率分布
    *P*(*X*, *Y*, *Z*)。我们如何从这个联合分布中随机生成？遗憾的是，软件库通常不提供对任意联合分布的伪随机生成。
- en: 'We can get around this by applying the chain rule and, if it exists, conditional
    independence. For example, we could factorize as follows:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过应用链式法则和，如果存在的话，条件独立性来解决这个问题。例如，我们可以如下分解：
- en: '![figure](../Images/ness-ch2-eqs-18x.png)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch2-eqs-18x.png)'
- en: 'Suppose that *Y* is conditionally independent of *Z* given *X*, then:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 假设 *Y* 在给定 *X* 的条件下与 *Z* 条件独立，那么：
- en: '![figure](../Images/ness-ch2-eqs-19x.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch2-eqs-19x.png)'
- en: 'Finally, suppose we can sample from *P*(*Z*), *P*(*X*|*Z*), and *P*(*Y*|*X*)
    given the basic random generation functions in our software library. Then we can
    use this factorization to compose an algorithm for sampling:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，假设我们可以从 *P*(*Z*)、*P*(*X*|*Z*) 和 *P*(*Y*|*X*) 中采样，给定我们软件库中的基本随机生成函数。然后我们可以使用这种分解来组合一个采样算法：
- en: '![figure](../Images/ness-ch2-eqs-20x.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch2-eqs-20x.png)'
- en: This is a random process that we can execute in code. First, we generate a *Z*-outcome
    *z* from *P*(*Z*). We then condition *X* on that *z*, and generate an *X*-outcome
    *x*. We do the same to generate a *Y*-outcome *y*. Finally, this procedure generates
    a tuple {*x*, *y*, *z*} from the joint distribution *P*(*X*, *Y*, *Z*).
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个我们可以在代码中执行的随机过程。首先，我们从 *P*(*Z*) 中生成一个 *Z*-结果 *z*。然后我们根据那个 *z* 条件化 *X*，并生成一个
    *X*-结果 *x*。我们以相同的方式生成一个 *Y*-结果 *y*。最后，这个程序从联合分布 *P*(*X*, *Y*, *Z*) 中生成一个元组 {*x*,
    *y*, *z*}。
- en: In pgmpy, we can create a random process using the class called `BayesianNetwork`.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在 pgmpy 中，我们可以使用名为 `BayesianNetwork` 的类创建随机过程。
- en: Listing 2.5 Creating a random process in pgmpy and Pyro
  id: totrans-236
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.5 在 pgmpy 和 Pyro 中创建随机过程
- en: '[PRE21]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '#1 P(Z)'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 P(Z)'
- en: '#2 P(X|Z=z)'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 P(X|Z=z)'
- en: '#3 P(X|Z=z)'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 P(X|Z=z)'
- en: '#4 P(Y|X=x)'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 P(Y|X=x)'
- en: '#5 Create a BayesianNetwork object. The arguments are edges of a directed graph,
    which we’ll cover in chapter 3.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 创建一个贝叶斯网络对象。参数是有向图的边，我们将在第3章中介绍。'
- en: '#6 Add the conditional probability distributions to the model.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 将条件概率分布添加到模型中。'
- en: '#7 Create a BayesianModelSampling object from the BayesianNetwork object.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '#7 从贝叶斯网络对象创建一个贝叶斯模型采样对象。'
- en: '#8 Sample from the resulting object'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '#8 从结果对象中采样'
- en: This produces one row in a pandas DataFrame, shown in figure 2.17.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在 pandas DataFrame 中产生一行，如图 2.17 所示。
- en: '![figure](../Images/CH02_F17_Ness.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F17_Ness.png)'
- en: Figure 2.17 The `forward_sample` method simulates one instance of *X*, *Y*,
    and *Z* as a row in a pandas DataFrame.
  id: totrans-248
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 2.17 `forward_sample` 方法模拟了 *X*、*Y* 和 *Z* 作为一个 pandas DataFrame 中的行。
- en: Implementing random processes for random generation is powerful because it allows
    generating from joint distributions that we can’t represent in clear mathematical
    terms or as a single canonical distribution. For example, while pgmpy works well
    with categorical distributions, Pyro gives us the flexibility of working with
    combinations of canonical distributions.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 实现随机生成过程的随机过程非常强大，因为它允许从我们无法用清晰数学术语或单个典型分布表示的联合分布中生成。例如，虽然 pgmpy 与分类分布配合得很好，但
    Pyro 给我们提供了使用典型分布组合的灵活性。
- en: The following listing shows a Pyro version of the previous random process. It
    has the same dependence between *Z*, *X*, and *Y*, but different canonical distributions.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表显示了先前随机过程的 Pyro 版本。它具有 *Z*、*X* 和 *Y* 之间的相同依赖关系，但具有不同的典型分布。
- en: Listing 2.6 Working with combinations of canonical distributions in Pyro
  id: totrans-251
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 2.6 在 Pyro 中使用典型分布的组合
- en: '[PRE22]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '#1 Represent P(Z) with a gamma distribution, and sample z.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 使用伽马分布表示 P(Z)，并采样 z。'
- en: '#2 Represent P(X|Z=z) with a Poisson distribution with location parameter z,
    and sample x.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 使用泊松分布表示 P(X|Z=z)，位置参数为 z，并采样 x。'
- en: '#3 Represent P(Y|X=x) with a Bernoulli distribution. The probability parameter
    is a function of x.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 使用伯努利分布表示 P(Y|X=x)。概率参数是 x 的函数。'
- en: 'This prints out a sample set, such as the following:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打印出一个示例集，例如以下内容：
- en: '[PRE23]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '*Z* comes from a gamma distribution, *X* from a Poisson distribution with mean
    parameter set to *z*, and *Y* from a Bernoulli distribution with its parameter
    set to a function of *x*.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '*Z* 来自伽马分布，*X* 来自均值为 *z* 的泊松分布，而 *Y* 来自参数设置为 *x* 函数的伯努利分布。'
- en: 'Implementing a random function with a programming language lets us use nuanced
    conditional control flow. Consider the following pseudocode:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 使用编程语言实现随机函数让我们可以使用细微的条件控制流。考虑以下伪代码：
- en: '[PRE24]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '#1 We can use control flow, like this for loop, to generate values.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 我们可以使用控制流，如这个 for 循环，来生成值。'
- en: '#2 y is the sum of the values generated in the for loop. y still depends on
    x, but through nuanced control flow.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 y 是 for 循环中生成的值的总和。y 仍然依赖于 x，但通过细微的控制流。'
- en: Here, *y* is still dependent on *x*. However, it is defined as the sum of *x*
    individual random components. In Pyro, we might implement this as follows.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*y* 仍然依赖于 *x*。然而，它被定义为 *x* 个单个随机成分的总和。在 Pyro 中，我们可能这样实现它。
- en: Listing 2.7 Random processes with nuanced control flow in Pyro
  id: totrans-264
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 2.7 Pyro 中具有细微控制流的随机过程
- en: '[PRE25]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '#1 y is defined as a sum of random coin flips, so y is generated from P(Y|X=x)
    because the number of flips depends on x.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 y 被定义为随机抛硬币的总和，因此 y 是从 P(Y|X=x) 生成的，因为抛掷次数取决于 x。'
- en: In Pyro, best practice is to implement random processes as functions. Further,
    use the function `pyro.sample` to generate, rather than using the `sample` method
    on distribution objects. We could rewrite the preceding `random_process` code
    (listing 2.7) as follows.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Pyro 中，最佳实践是将随机过程实现为函数。此外，使用 `pyro.sample` 函数生成，而不是使用分布对象的 `sample` 方法。我们可以将前面的
    `random_process` 代码（列表 2.7）重写如下。
- en: Listing 2.8 Using functions for random processes and `pyro.sample`
  id: totrans-268
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 2.8 使用函数进行随机过程和 `pyro.sample`
- en: '[PRE26]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '#1 f"y{i}" creates the names "y1", "y2", etc.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 f"y{i}" 创建了 "y1"、"y2" 等名称。'
- en: The first argument in `pyro.sample` is a string that assigns a name to the variable
    you are sampling. The reason for that will become apparent when we start running
    inference algorithms in Pyro in chapter 3\.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '`pyro.sample` 的第一个参数是一个字符串，用于为你要采样的变量分配一个名称。当我们开始在第三章中运行 Pyro 的推理算法时，原因将变得明显。'
- en: 2.2.4 Monte Carlo simulation and expectation
  id: totrans-272
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.4 蒙特卡洛模拟和期望
- en: '*Monte Carlo algorithms* use random generation to estimate expectations from
    a distribution of interest. The idea is simple. You have some way of generating
    from *P*(*X*). If you want *E*(*X*), generate multiple *x*’s, and take the average
    of those *x*’s. If you want *E*(*f*(*X*)), generate multiple *x*’s and apply the
    function *f*(.) to each of those *x*’s, and take the average. Monte Carlo works
    even in cases when *X* is continuous.'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '*蒙特卡洛算法* 使用随机生成来估计从感兴趣的概率分布中的期望值。这个想法很简单。你有一些从 *P*(*X*) 中生成的方法。如果你想 *E*(*X*)，生成多个
    *x*，然后取这些 *x* 的平均值。如果你想 *E*(*f*(*X*))，生成多个 *x*，并将函数 *f*(.) 应用到每个 *x* 上，然后取平均值。蒙特卡洛算法甚至在
    *X* 是连续的情况下也能工作。'
- en: In pgmpy, you use the `sample` or `forward_sample` methods to generate a pandas
    DataFrame. You can then calculate the panda’s `mean` method.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在 pgmpy 中，你使用 `sample` 或 `forward_sample` 方法来生成一个 pandas DataFrame。然后你可以计算 pandas
    的 `mean` 方法。
- en: '[PRE27]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'In Pyro, we call the `random_process` function repeatedly. We can do this for
    the preceding Pyro generator with a `for` loop that generates 100 samples:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Pyro 中，我们反复调用 `random_process` 函数。我们可以使用一个生成 100 个样本的 `for` 循环来对前面的 Pyro 生成器做这件事：
- en: '[PRE28]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: This code repeatedly calls `random_process` in a Python list comprehension.
    Recall that Pyro extends PyTorch, and the value of y it returns is a tensor. I
    use `torch.stack` to turn this list of tensors into a single tensor. Finally,
    I call the `mean` method on the tensor to obtain the Monte Carlo estimate of *E*(*Y*).
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码在 Python 列表推导式中反复调用 `random_process`。回想一下，Pyro 扩展了 PyTorch，它返回的 y 值是一个张量。我使用
    `torch.stack` 将这些张量列表转换成一个单独的张量。最后，我在这个张量上调用 `mean` 方法来获得 *E*(*Y*) 的蒙特卡洛估计。
- en: '[PRE29]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: When I ran this code, I got a value of about 3.78, but you’ll likely get something
    slightly different.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 当我运行这段代码时，我得到了大约 3.78 的值，但你可能会得到一个略有不同的值。
- en: Most things you’d want to know about a distribution can be framed in terms of
    some function *f*(*X*). For example, if you wanted to know the probability of
    *X* being greater than 10, you could simply generate a bunch of *x*’s and convert
    each *x* to 1 if it is greater than 10 and 0 otherwise. Then you’d take the average
    of the 1’s and 0’s, and the resulting value would estimate the desired probability.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 你想要了解的关于分布的大部分内容都可以用某个函数 *f*(*X*) 来表达。例如，如果你想了解 *X* 大于 10 的概率，你可以简单地生成一些 *x*，并将每个大于
    10 的 *x* 转换为 1，否则为 0。然后你取 1 和 0 的平均值，得到的值将估计所需的概率。
- en: To illustrate, the following code extends the previous block to calculate *E*(*Y*²).
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，以下代码扩展了前面的代码块来计算 *E*(*Y*²)。
- en: '[PRE30]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: When calculating *E*(*f*(*X*)) for a random variable *X*, remember to get the
    Monte Carlo estimate by applying the function to the samples first, and then take
    the average. If you apply the function to the sample average, you’ll instead get
    an estimate of *f*(*E*(*X*)), which is almost always different.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 当计算随机变量 *X* 的 *E*(*f*(*X*)) 时，记得先应用函数到样本上，然后取平均值来获得蒙特卡洛估计。如果你先对样本平均数应用函数，你将得到
    *f*(*E*(*X*)) 的估计，这几乎总是不同的。
- en: 2.2.5 Programming probabilistic inference
  id: totrans-285
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2.5 编程概率推理
- en: 'Suppose we implement in code a random process that generates an outcome {*x*,
    *y*, *z*} from *P*(*X*, *Y*, *Z*) as follows:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们用代码实现一个随机过程，从 *P*(*X*, *Y*, *Z*) 中生成结果 {*x*, *y*, *z*}，如下所示：
- en: '![figure](../Images/ness-ch2-eqs-20x.png)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch2-eqs-20x.png)'
- en: Further, suppose we are interested in generating from *P*(*Z*|*Y*=3). How might
    we do this? Our process can sample from *P*(*Z*), *P*(*X*|*Z*), and *P*(*Y*|*Z*),
    but it is not clear how we go from these to *P*(*Z*|*Y*).
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，假设我们感兴趣的是从 *P*(*Z*|*Y*=3) 中生成。我们该如何做呢？我们的过程可以从 *P*(*Z*)、*P*(*X*|*Z*) 和 *P*(*Y*|*Z*)
    中采样，但并不清楚我们如何从这些概率分布中得到 *P*(*Z*|*Y*)。
- en: '*Probabilistic inference algorithms* generally take an outcome-generating random
    process and some target distribution as inputs. Then, they return a means of generating
    from that target distribution. This class of algorithms is often called Bayesian
    inference algorithms because the algorithms often use Bayes rule to go from *P*(*Y*|*Z*)
    to *P*(*Z*|*Y*). However, the connection to Bayes rule is not always explicit,
    so I prefer “probabilistic inference” over “Bayesian inference algorithms.”'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '*概率推理算法* 通常将生成结果的随机过程和一些目标分布作为输入。然后，它们返回从该目标分布生成的方法。这类算法通常被称为贝叶斯推理算法，因为算法通常使用贝叶斯规则从
    *P*(*Y*|*Z*) 转换到 *P*(*Z*|*Y*)。然而，与贝叶斯规则的联系并不总是明确的，所以我更喜欢“概率推理”而不是“贝叶斯推理算法”。'
- en: 'For example, a simple class of probabilistic inference algorithms is called
    accept/reject algorithms. Applying a simple accept/reject technique to generating
    from *P*(*Z*|*Y*=3) works as follows:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一类简单的概率推理算法被称为接受/拒绝算法。将简单的接受/拒绝技术应用于从 *P*(*Z*|*Y*=3) 中生成的工作原理如下：
- en: Repeatedly generate {*x*, *y*, *z*} using our generator for *P*(*X*, *Y*, *Z*).
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重复使用我们的 *P*(*X*, *Y*, *Z*) 生成器生成 {*x*, *y*, *z*}。
- en: Throw away any generated outcome where *y* is not equal to 3\.
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 丢弃任何生成的结果，其中 *y* 不等于 3。
- en: The resulting set of outcomes for *Z* will have the distribution *P*(*Z*|*Y*=3).
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于 *Z* 的结果集将具有分布 *P*(*Z*|*Y*=3)。
- en: Illustrating with Pyro, let’s rewrite the previous `random_process` function
    to return *z* and *y*. After that, we’ll obtain a Monte Carlo estimate of *E*(*Z*|*Y*=3).
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Pyro 举例，让我们重写之前的 `random_process` 函数以返回 *z* 和 *y*。之后，我们将获得 *E*(*Z*|*Y*=3)
    的蒙特卡洛估计。
- en: Listing 2.9 Monte Carlo estimation in Pyro
  id: totrans-295
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 2.9 Pyro 中的蒙特卡洛估计
- en: '[PRE31]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '#1 This new version of random_process returns both z and y.'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 这个新的 random_process 版本返回了 z 和 y。'
- en: '#2 Generate 1000 instances of z and y using a list comprehension.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 使用列表推导生成 1000 个 z 和 y 的实例。'
- en: '#3 Turn the individual z tensors into a single tensor, and then calculate the
    Monte Carlo estimate via the mean method.'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 将单个 z 张量合并成一个张量，然后通过均值方法计算蒙特卡洛估计。'
- en: This code estimates *E*(*Z*). Since *Z* is simulated from a gamma distribution,
    the true mean *E*(*Z*) is the shape parameter 7.5 divided by the rate parameter
    1.0, which is 7.5\.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码估计 *E*(*Z*)。由于 *Z* 是从伽马分布中模拟的，所以 *Z* 的真实均值 *E*(*Z*) 是形状参数 7.5 除以速率参数 1.0，即
    7.5。
- en: Now, to estimate *E*(*Z*|*Y*=3), we’ll filter the samples and keep only the
    samples where *Y* is 3.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了估计 *E*(*Z*|*Y*=3)，我们将过滤样本，只保留 *Y* 为 3 的样本。
- en: '[PRE32]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'One run of this code produced `tensor(6.9088)`, but your result might be slightly
    different. That probabilistic inference algorithm works well if the outcome *Y*=3
    occurs frequently. If that outcome were rare, the algorithm would be inefficient:
    we’d have to generate many samples to get samples that meet the condition, and
    we’d be throwing away many samples.'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码的一次运行产生了 `tensor(6.9088)`，但你的结果可能略有不同。如果结果 *Y*=3 发生频率较高，这个概率推理算法效果良好。如果这个结果很少见，算法将效率低下：我们需要生成许多样本以获得满足条件的样本，并且我们会丢弃许多样本。
- en: There are various other algorithms for probabilistic inference, but the topic
    is too rich and tangential to causal modeling for us to explore in depth. Nevertheless,
    the following algorithms are worth mentioning for what we cover in this book.
    Visit [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)
    for links to some complementary materials on inference with pgmpy and Pyro.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 对于概率推理，有各种其他算法，但这个主题对于我们深入探讨因果建模来说太丰富了，也太偏离主题了。尽管如此，以下算法值得我们在此书中提及。访问 [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)
    获取有关使用 pgmpy 和 Pyro 进行推理的一些补充材料的链接。
- en: Probability weighting methods
  id: totrans-305
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 概率权重方法
- en: These methods generate outcomes from a joint probability distribution and then
    weight them according to their probability in the target distribution. We can
    then use the weights to do weighted averaging via Monte Carlo estimation. Popular
    variants of this kind of inference include importance sampling and inverse probability
    reweighting, the latter of which is popular in causal inference and is covered
    in chapter 11.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法从联合概率分布生成结果，然后根据其在目标分布中的概率对其进行加权。然后我们可以使用这些权重通过蒙特卡洛估计进行加权平均。这类推理的流行变体包括重要性采样和逆概率重新加权，后者在因果推理中很受欢迎，并在第
    11 章中介绍。
- en: Inference with probabilistic graphical models
  id: totrans-307
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用概率图模型进行推理
- en: Probabilistic graphical models use graphs to represent conditional independence
    in a joint probability distribution. The presence of a graph enables graph-based
    algorithms to power inference. Two well-known approaches include variable elimination
    and belief propagation. In figures 2.5 and 2.6, I showed that you could “eliminate”
    a variable by summing over its columns or rows in the probability table. Variable
    elimination uses the graph structure to optimally sum over the variables you wish
    to eliminate until the resulting table represents the target distribution. In
    contrast, belief propagation is a message-passing system; the graph is used to
    form different “cliques” of neighboring variables. For example, if *P*(*Z*|*Y*=1)
    is the target distribution, *Y*=1 is a message iteratively passed back and forth
    between cliques. Each time a message is received, parameters in the clique are
    updated, and the message is passed on. Eventually, the algorithm converges, and
    we can derive a new distribution for *Z* from those updated parameters.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 概率图模型使用图来表示联合概率分布中的条件独立性。图的存在使得基于图的算法能够进行推理。两种知名的方法包括变量消除和信念传播。在图2.5和2.6中，我展示了你可以通过在概率表的列或行上求和来“消除”一个变量。变量消除使用图结构来最优地求和你要消除的变量，直到结果表代表目标分布。相比之下，信念传播是一个消息传递系统；图被用来形成相邻变量的不同“团”。例如，如果
    *P*(*Z*|*Y*=1) 是目标分布，*Y*=1 是在团之间迭代传递的消息。每次收到消息时，团中的参数都会更新，然后消息被传递下去。最终，算法收敛，我们可以从这些更新的参数中推导出
    *Z* 的新分布。
- en: One of the attractive features of graph-based probabilistic inference is that
    users typically don’t implement them themselves; software like pgmpy does it for
    you. There are theoretical caveats, but they usually don’t matter in practice.
    This feature is an example of the “commodification of inference” trend I highlighted
    in chapter 1\. In this book, we’ll work with causal graphical models, a special
    type of probabilistic graphical model that works as a causal model. That gives
    us the option of applying graph-based inference for causal problems.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图的概率推理的一个吸引人的特点是，用户通常不需要自己实现它们；像 pgmpy 这样的软件会为你完成。虽然有一些理论上的注意事项，但在实践中通常并不重要。这个特性是我在第一章中强调的“推理商品化”趋势的一个例子。在这本书中，我们将使用因果图模型，这是一种特殊的概率图模型，它作为一个因果模型工作。这给了我们应用基于图的推理来解决因果问题的选项。
- en: Variational inference
  id: totrans-310
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 变分推理
- en: In *variational inference*, we write code for a new stochastic process that
    generates samples from an “approximating distribution” that resembles the target
    distribution. That stochastic process has parameters that we optimize using gradient-based
    techniques now common in deep learning software. The objective function of the
    optimization tries to minimize the difference between the approximating distribution
    and the target distribution.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *变分推理* 中，我们为一个新的随机过程编写代码，该过程从类似于目标分布的“近似分布”生成样本。这个随机过程具有参数，我们使用深度学习软件中常见的基于梯度的技术来优化这些参数。优化的目标函数试图最小化近似分布与目标分布之间的差异。
- en: Pyro is a probabilistic modeling language that treats variational inference
    as a principal inference technique. It calls the stochastic process that generates
    from the approximating distribution a “guide function,” and a savvy Pyro programmer
    gets good at writing guide functions. However, it also provides a suite of tools
    for “automatic guide generation,” another example of the commodification of inference.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: Pyro 是一种概率建模语言，它将变分推理视为主要的推理技术。它将来自近似分布的随机过程称为“引导函数”，一个熟练的 Pyro 程序员会擅长编写引导函数。然而，它还提供了一套“自动引导函数生成”的工具，这是推理商品化的另一个例子。
- en: Markov chain Monte Carlo
  id: totrans-313
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 马尔可夫链蒙特卡洛
- en: '*Markov chain Monte Carlo* (MCMC) is an inference algorithm popular amongst
    computational Bayesians. These are accept/reject algorithms where each newly generated
    outcome depends on the previous (non-rejected) generated outcome. This produces
    a chain of outcomes, and the distribution of outcomes in the chain eventually
    converges to the target distribution. *Hamiltonian Monte Carlo* (HMC) is a popular
    version that doesn’t require users to implement the generator. Pyro, and similar
    libraries, such as PyMC, implement HMC and other MCMC algorithms.'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '*马尔可夫链蒙特卡洛*（MCMC）是计算贝叶斯主义者中流行的一种推理算法。这些是接受/拒绝算法，其中每个新生成的结果都依赖于前一个（非拒绝）生成的结果。这产生了一系列结果，链中结果分布最终收敛到目标分布。*哈密顿蒙特卡洛*（HMC）是一个不需要用户实现生成器的流行版本。Pyro以及类似的库，如PyMC，实现了HMC和其他MCMC算法。'
- en: Advanced Inference Methods
  id: totrans-315
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 高级推理方法
- en: Research in generative models continues to develop new inference techniques.
    Examples include techniques such adversarial inference, inference with normalizing
    flows, and diffusion-based inference. The goal of such techniques are to efficiently
    sample from the complex distributions common in machine learning problems. Again,
    see [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)
    for references. We’ll see an example of a structural causal model that leverages
    normalizing flows in chapter 6\. The approach taken in this book is to leverage
    the “commodification of inference” trend discussed in chapter 1, such that we
    can build causal models that leverage these algorithms, as well as new algorithms
    as they are released.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型的研究持续发展新的推理技术。例如，包括对抗推理、基于正态流的推理和基于扩散的推理等技术。这些技术的目标是高效地从机器学习问题中常见的复杂分布中进行采样。再次，参见[https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)获取参考文献。在第6章中，我们将看到一个利用正态流的因果模型示例。本书采用的方法是利用第1章中讨论的“推理商品化”趋势，这样我们就可以构建利用这些算法的因果模型，以及随着发布的新算法。
- en: 2.3 Data, populations, statistics, and models
  id: totrans-317
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.3 数据、总体、统计和模型
- en: So far, we have talked about random variables and distributions. Now we’ll move
    on to data and statistics. Let’s start with defining some terms. You doubtless
    have an idea of what data is, but let’s define it in terms we’ve already defined
    in this chapter. *Data* is a set of recorded outcomes of a random variable or
    set of random variables. A *statistic* is anything you calculate from data. For
    example, when you train a neural network on training data, the learned weight
    parameter values are statistics, and so are the model’s predictions (since they
    depend on the training data via the weights).
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了随机变量和分布。现在我们将转向数据和统计。让我们先定义一些术语。你无疑对数据有一个概念，但让我们用本章中已经定义的术语来定义它。*数据*是一组随机变量或随机变量集的记录结果。*统计量*是从数据中计算出的任何东西。例如，当你使用训练数据训练神经网络时，学到的权重参数值是统计量，模型的预测也是如此（因为它们通过权重依赖于训练数据）。
- en: The real-world causal process that generates a particular stream of data is
    called the *data generating process* (DGP). A *model* is a simplified mathematical
    description of that process. A *statistical model* is a model with parameters
    tuned such that the model aligns with statistical patterns in the data.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 生成特定数据流的现实世界因果过程被称为*数据生成过程*（DGP）。*模型*是对该过程的简化数学描述。*统计模型*是一个参数经过调整以使模型与数据中的统计模式相匹配的模型。
- en: This section presents some of the core concepts related to data and statistics
    needed to make sense of this book.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了与数据和相关统计有关的一些核心概念，这些概念对于理解本书至关重要。
- en: 2.3.1 Probability distributions as models for populations
  id: totrans-321
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.1 概率分布作为总体模型
- en: In applied statistics, we take statistical insights from data and generalize
    them to a population. Consider, for example, the MNIST digit classification problem
    described in chapter 1\. Suppose the goal of training a classification model on
    MNIST data was to deploy the model in software that digitizes written text documents.
    In this case, the population is all the digits on all the texts the software will
    see in the future.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用统计学中，我们从数据中提取统计洞察并将其推广到总体。例如，考虑第1章中描述的MNIST数字分类问题。假设在MNIST数据上训练分类模型的目的是将模型部署到软件中，该软件将数字化文本文档。在这种情况下，总体是软件未来将看到的所有文本中的所有数字。
- en: Populations are heterogeneous, meaning members of the population vary. While
    a feature on a website might drive engagement among the population of users, on
    average, the feature might make some subpopulation of users less engaged, so you
    would want to target the feature to the right subpopulations. Marketers call this
    “segmentation.”
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 人口是异质的，这意味着人口中的成员各不相同。虽然网站上的某个功能可能会提高用户群体的参与度，但平均而言，该功能可能会使某些亚群体用户的参与度降低，因此你希望将该功能定位到正确的亚群体。营销人员称之为“细分”。
- en: In another example, a medicine might not be much help on average for a broad
    population of patients, but there some subpopulation might experience benefits.
    Targeting those subpopulations is the goal of the field of precision medicine.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一个例子中，一种药物可能对广大患者群体平均来说帮助不大，但某些亚群体可能会体验到好处。针对这些亚群体是精准医学领域的目标。
- en: In probabilistic models, we use probability distributions to model populations.
    It is particularly useful to target subpopulations with conditional probability.
    For example, suppose *P*(*E*|*F*=True) represents the distribution of engagement
    numbers among all users exposed to a website feature. Then *P*(*E*|*F*=True, *G*="millennial")
    represents the subpopulation of users exposed to the feature who are also millennials.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在概率模型中，我们使用概率分布来模拟人口。针对亚群体使用条件概率特别有用。例如，假设 *P*(*E*|*F*=True) 表示所有接触到网站功能的用户中的参与度数字分布。那么
    *P*(*E*|*F*=True, *G*="millennial") 表示接触到该功能的用户中也是千禧一代的亚群体。
- en: Canonical distributions and stochastic processes as models of populations
  id: totrans-326
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 经典分布和随机过程作为人口模型
- en: If we use probability distributions to model populations, what canonical distributions
    should we use for a given population? Figure 2.18 includes common distributions
    and the phenomena they typically model.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用概率分布来模拟人口，对于给定的人口，我们应该使用哪些经典分布？图2.18包括了常见的分布以及它们通常模拟的现象。
- en: '![figure](../Images/CH02_F18_Ness.png)'
  id: totrans-328
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F18_Ness.png)'
- en: Figure 2.18 Examples of common canonical distributions and the types of phenomena
    and data they typically model
  id: totrans-329
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.18 常见经典分布的示例及其通常模拟的现象和数据类型
- en: These choices don’t come from nowhere. The canonical distributions are themselves
    derived from stochastic functions. For example, the binomial distribution is the
    result of a process where you do a series of coin flips. When something is the
    result of adding together a bunch of independent (or weakly dependent) small changes,
    you get a normal distribution. Waiting time distributions capture the distribution
    of the amount of time one must wait for an event (e.g., a device failure or a
    car accident). The exponential distribution is appropriate for waiting times when
    the amount of time you’ve already been waiting has no bearing on how much time
    you still must wait (e.g., for the amount of time it takes a radioactive atom
    to decay). If the time to event has an exponential distribution, the number of
    times that event has occurred within a fixed time period has a Poisson distribution.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 这些选择并非凭空而来。经典分布本身是从随机函数中推导出来的。例如，二项分布是连续一系列抛硬币的结果。当某事物是许多独立（或弱相关）的小变化相加的结果时，你会得到正态分布。等待时间分布捕捉了一个人必须等待某个事件（例如，设备故障或车祸）所需时间的分布。指数分布适用于等待时间，当你已经等待的时间对你还需要等待的时间没有影响时（例如，放射性原子衰变所需的时间）。如果事件发生的时间具有指数分布，那么在固定时间段内该事件发生的次数具有泊松分布。
- en: A useful trick in probabilistic modeling is to think of the stochastic process
    that created your target population. Then either choose the appropriate canonical
    distribution or implement the stochastic process in code using various canonical
    distributions as primitives in the code logic. In this book, we’ll see that this
    line of reasoning aligns well with causal modeling.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在概率建模中，一个有用的技巧是思考创建目标人口所涉及的随机过程。然后可以选择适当的经典分布，或者使用代码实现随机过程，在代码逻辑中将各种经典分布作为原语。在这本书中，我们将看到这种推理与因果建模非常吻合。
- en: Sampling, IID, and generation
  id: totrans-332
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 样本、独立同分布和生成
- en: Usually, our data is not the whole population but a small subset from the population.
    The act of randomly choosing an individual is called *sampling*. When the data
    is created by repeatedly sampling from the population, the resulting dataset is
    called a *random sample*. If we can view data as a *random sample*, we call that
    data *independent and identically distributed (IID)*. That means that the selection
    of each individual data point is *identical* in how it was sampled, and each sampling
    occurred *independently* of the others, and they all were sampled from the same
    population distribution. Figure 2.19 illustrates how an IID random sample is selected
    from a population.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，我们的数据不是整个群体的全部，而是来自群体的小子集。随机选择个体的行为被称为*抽样*。当数据是通过反复从群体中抽样创建时，得到的数据集被称为*随机样本*。如果我们能将数据视为*随机样本*，我们称这些数据为*独立同分布（IID）*。这意味着每个数据点的选择在抽样方式上是*相同*的，每个抽样都是独立于其他抽样发生的，并且它们都是从相同的群体分布中抽样的。图2.19说明了如何从群体中选取一个IID随机样本。
- en: '![figure](../Images/CH02_F19_Ness.png)'
  id: totrans-334
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F19_Ness.png)'
- en: Figure 2.19 Creating a random sample by random selection from a population.
    Individuals are randomly selected from the population such that the sample distribution
    resembles the population distribution. The sample is identically and independently
    distributed (IID), meaning that sample members are selected the same way, and
    whether an individual is selected doesn’t depend on whether another individual
    was selected.
  id: totrans-335
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.19 通过从群体中随机选择创建随机样本。个体是从群体中随机选择的，使得样本分布类似于群体分布。样本是同质且独立分布的（IID），这意味着样本成员是以相同的方式选择的，并且是否选择某个个体并不取决于是否选择了另一个个体。
- en: The idea of sampling and IID data illustrates the second benefit of using probability
    distributions to model populations. We can use generation from that distribution
    to model sampling from a population. We can implement a stochastic process that
    represents the DGP by first writing a stochastic process that represents the population
    and then composing it with a process that generates data from the population process,
    emulating IID sampling.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 抽样和IID数据的理念说明了使用概率分布来模拟群体的第二个好处。我们可以使用从该分布生成的方法来模拟从群体中抽样。我们可以通过首先编写表示群体的随机过程，然后将其与生成群体过程数据的进程组合，来表示DGP，从而模拟IID抽样。
- en: In pgmpy, this is as simple as generating more than one sample.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 在pgmpy中，这就像生成多个样本一样简单。
- en: '[PRE33]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: This produces the table showing in figure 2.20
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 这产生了显示在图2.20中的表格
- en: '![figure](../Images/CH02_F20_Ness.png)'
  id: totrans-340
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F20_Ness.png)'
- en: Figure 2.20 A pandas DataFrame created by generating ten data points from a
    model in pgmpy
  id: totrans-341
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.20 由pgmpy中的模型生成十个数据点创建的pandas DataFrame
- en: The Pyro approach for IID sampling is `pyro.plate`.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: Pyro进行IID抽样的方法是`pyro.plate`。
- en: Listing 2.10 Generating IID samples in Pyro
  id: totrans-343
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.10 在Pyro中生成IID样本
- en: '[PRE34]'
  id: totrans-344
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '#1 pyro.plate is a context manager for generating conditionally independent
    samples. This instance of pyro.plate will generate 10 IIΔ samples.'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 pyro.plate是一个用于生成条件独立样本的上下文管理器。这个pyro.plate实例将生成10个IIΔ样本。'
- en: '#2 Calling pyro.sample generates a single outcome y, where y is a tensor of
    10 IIΔ samples.'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 调用pyro.sample生成一个单个结果y，其中y是一个包含10个IIΔ样本的张量。'
- en: Using generation to model sampling is particularly useful in machine learning,
    because often the data is not IID. In the MNIST example in chapter 1, the original
    NIST data was not IID—one block of data came from high school students and the
    other from government officers. You could capture the identity of the digit writer
    as a variable in your stochastic process. Then the data would be IID *conditional*
    on that variable.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 使用生成来模拟抽样在机器学习中特别有用，因为数据通常不是IID。在第1章的MNIST示例中，原始NIST数据不是IID——一块数据来自高中生，另一块来自政府官员。你可以在你的随机过程中将数字作者的标识作为一个变量来捕捉。然后，数据就会在该变量上成为IID
    *条件*。
- en: Don’t mistake the map for the terrain
  id: totrans-348
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 不要把地图误认为是地形
- en: Consider again the MNIST data. The population for that data is quite nebulous
    and abstract. If that digit classification software were licensed to multiple
    clients, the population would be a practically unending stream of digits. Generalizing
    to abstract populations is the common scenario in machine learning, as it is for
    statistics. When R.A. Fisher, the founding father of modern statistics, was designing
    experiments for testing soil types on crop growth at Rothamsted Research, he was
    trying to figure out how to generalize to the population of future crops (with
    as small a number of samples as possible).
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 再次考虑MNIST数据。该数据的人口相当模糊和抽象。如果该数字分类软件被多个客户许可，人口将是一个实际上无休止的数字流。在机器学习和统计学中，将数据推广到抽象的人口是常见场景，正如R.A.
    Fisher这位现代统计学奠基人在Rothamsted Research设计用于测试土壤类型对作物生长影响的实验时，他试图弄清楚如何将样本推广到未来作物的总体（尽可能少的样本数量）。
- en: The problem with working with nebulously large populations is that it can lead
    to the mistake of mentally conflating populations with the probability distributions.
    Do not do this. Do not mistake the map (the distribution used to model the population)
    for the terrain (the population itself).
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 与模糊庞大的群体合作的问题在于，这可能导致将群体与概率分布心理上混淆的错误。不要这样做。不要将地图（用于模拟群体的分布）误认为是地形（群体本身）。
- en: 'To illustrate, consider the following example: While writing part of this chapter,
    I was vacationing in Silves, a town in the Portuguese Algarve with a big castle,
    deep history, and great hiking. Suppose I were interested in modeling the heights
    of Silves residents.'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明，考虑以下例子：在撰写本章的部分内容时，我在葡萄牙阿尔加维的Silves度假，这是一个拥有大城堡、深厚历史和绝佳徒步旅行地点的小镇。假设我对模拟Silves居民的身高感兴趣。
- en: Officially, the population of Silves is 11,000, so let’s take that number as
    ground truth. That means there are 11,000 different height values in Silves. Suppose
    I physically went down to the national health center in Silves and got a spreadsheet
    of every resident’s height. Then the data I’d have is not a randomly sampled subset
    of the population—it is the full population itself.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 官方上，Silves的人口为11,000，所以让我们以这个数字作为基准真实值。这意味着Silves有11,000个不同的身高值。假设我亲自去到Silves的国家卫生中心，获取了一份每个居民身高的电子表格。那么我所拥有的数据不是随机抽样的人口子集——而是整个群体本身。
- en: I could then compute a *histogram* on that population, as shown in figure 2.21\.
    A histogram is a visualization of the counts of values (in this case, heights)
    in a population or sample. For continuous values like heights, we count how many
    values fall into a range or “bin.”
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 我可以对这一人群计算一个 *直方图*，如图2.21所示。直方图是人口或样本中值（在这种情况下，为身高）计数的可视化。对于连续值，如身高，我们计算有多少值落在某个范围或“区间”内。
- en: '![figure](../Images/CH02_F21_Ness.png)'
  id: totrans-354
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F21_Ness.png)'
- en: Figure 2.21 A histogram illustrating the height distribution of all Silves residents
  id: totrans-355
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.21 显示所有Silves居民身高分布的直方图
- en: This histogram represents the full population distribution. I can make it look
    more like a probability distribution by dividing the counts by the number of people,
    as in figure 2.22
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 这个直方图代表了整个群体分布。我可以通过将计数除以人数来使其看起来更像一个概率分布，如图2.22所示。
- en: '![figure](../Images/CH02_F22_Ness.png)'
  id: totrans-357
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F22_Ness.png)'
- en: Figure 2.22 Histogram of proportions of Silves residents with given height
  id: totrans-358
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.22 Silves居民给定身高的比例直方图
- en: One might say this distribution follows the normal (Gaussian) probability distribution,
    because we see a bell curve, and indeed, the normal is appropriate for evolutionary
    bell-shaped phenomena such as height. But that statement is not precisely true.
    To see this, consider that all normal distributions are defined for negative numbers
    (though those numbers might have an infinitesimal amount of probability density),
    whereas heights can’t be negative. What we are really doing is using the normal
    distribution as a *model*—as an *approximation* of this population distribution.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 某人可能会说这个分布遵循正态（高斯）概率分布，因为我们看到了一个钟形曲线，而且确实，正态分布适用于像身高这样的进化钟形现象。但这个说法并不完全准确。为了理解这一点，考虑所有正态分布都是为负数定义的（尽管这些数字可能只有极小的概率密度），而身高不能是负数。我们真正做的是使用正态分布作为一个
    *模型*——作为对这个群体分布的 *近似*。
- en: In another example, figure 2.23 shows the true distribution of the parts of
    speech in Jane Austen’s novels. Note that this is not based on a sample of pages
    from her novels; I created this visualization from the parts-of-speech distribution
    of the 725 thousand words in *all* her six completed novels.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一个例子中，图 2.23 展示了简·奥斯汀小说中词类的真实分布。请注意，这并非基于她小说中页面的样本；我是从她所有六部完成小说中的 725,000
    个词的词类分布中创建了这个可视化。
- en: '![figure](../Images/CH02_F23_Ness.png)'
  id: totrans-361
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH02_F23_Ness.png)'
- en: Figure 2.23 Actual distribution of word types in all of Jane Austen’s novels
  id: totrans-362
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图 2.23 简·奥斯汀所有小说中词类的实际分布
- en: As modelers, we use canonical distributions to model the population distribution,
    but the model is not equivalent to the population distribution. This point may
    seem like trivial semantics, but in the era of big data, we often can reason about
    an entire population instead of just a random sample. For example, popular online
    social networks have hundreds of millions and sometimes billions of users. That’s
    a huge size, yet the entire population is just one database query away.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 作为模型师，我们使用规范分布来建模人群分布，但模型并不等同于人群分布。这个观点可能看起来像是微不足道的语义，但在大数据时代，我们经常可以推理整个群体，而不仅仅是随机样本。例如，流行的在线社交网络有数亿甚至数十亿用户。这是一个巨大的规模，而整个群体只需一个数据库查询即可获得。
- en: In causal modeling, being precise in how we think about modeling data and populations
    is extremely useful. Causal inferences are about the real-world attributes of
    the population, rather than just statistical trends in the data. And different
    causal questions we want to answer will require us to bake different causal assumptions
    into our models, some of which are stronger or harder to validate than others.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 在因果建模中，我们思考如何建模数据和人群的精确性非常有用。因果推断是关于人群的真实世界属性，而不仅仅是数据中的统计趋势。而我们想要回答的不同因果问题将需要我们将不同的因果假设融入我们的模型中，其中一些比其他假设更强或更难验证。
- en: 2.3.2 From the observed data to the data generating process
  id: totrans-365
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.2 从观察数据到数据生成过程
- en: In causal modeling, it is important to understand how the observed data maps
    back to the joint probability distribution of the variables in the data, and how
    that joint probability distribution maps back to the DGP. Most modelers have some
    level of intuition about the relationships between these entities, but in causal
    modeling we must be explicit. This explicit understanding is important because,
    while in ordinary statistical modeling you model the joint distribution (or elements
    of it), in causal modeling you need to model the DGP.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 在因果建模中，了解观察数据如何映射到数据中变量的联合概率分布，以及该联合概率分布如何映射回数据生成过程（DGP）非常重要。大多数模型师对这些实体之间的关系有一定程度的直觉，但在因果建模中我们必须明确。这种明确的理解很重要，因为在普通统计建模中，你模型的是联合分布（或其元素），而在因果建模中，你需要模型的是数据生成过程（DGP）。
- en: From the observed data to the empirical joint distribution
  id: totrans-367
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 从观察数据到经验联合分布
- en: Suppose we had the dataset of five data points shown in table 2.1.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个如表 2.1 所示的五个数据点的数据集。
- en: Table 2.1 A simple data set with five examples
  id: totrans-369
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 2.1 一个包含五个示例的简单数据集
- en: '|  | jenny_throws_rock | brian_throws_rock | window_breaks |'
  id: totrans-370
  prefs: []
  type: TYPE_TB
  zh: '|  | jenny_throws_rock | brian_throws_rock | window_breaks |'
- en: '| --- | --- | --- | --- |'
  id: totrans-371
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 1  | False  | True  | False  |'
  id: totrans-372
  prefs: []
  type: TYPE_TB
  zh: '| 1  | False  | True  | False |'
- en: '| 2  | True  | False  | True  |'
  id: totrans-373
  prefs: []
  type: TYPE_TB
  zh: '| 2  | True  | False  | True  |'
- en: '| 3  | False  | False  | False  |'
  id: totrans-374
  prefs: []
  type: TYPE_TB
  zh: '| 3  | False  | False  | False |'
- en: '| 4  | False  | False  | False  |'
  id: totrans-375
  prefs: []
  type: TYPE_TB
  zh: '| 4  | False  | False  | False |'
- en: '| 5  | True  | True  | True  |'
  id: totrans-376
  prefs: []
  type: TYPE_TB
  zh: '| 5  | True  | True  | True  |'
- en: We can take counts of all the observed observable outcomes, as in table 2.2.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以对所有观察到的可观察结果进行计数，如表 2.2 所示。
- en: Table 2.2 Empirical counts of each possible outcome combination
  id: totrans-378
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 2.2 每种可能结果组合的经验计数
- en: '|  | jenny_throws_rock | brian_throws_rock | window_breaks | counts |'
  id: totrans-379
  prefs: []
  type: TYPE_TB
  zh: '|  | jenny_throws_rock | brian_throws_rock | window_breaks | counts |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-380
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 1  | False  | False  | False  | 2  |'
  id: totrans-381
  prefs: []
  type: TYPE_TB
  zh: '| 1  | False  | False  | False  | 2  |'
- en: '| 2  | True  | False  | False  | 0  |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| 2  | True  | False  | False  | 0  |'
- en: '| 3  | False  | True  | False  | 1  |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
  zh: '| 3  | False  | True  | False  | 1  |'
- en: '| 4  | True  | True  | False  | 0  |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| 4  | True  | True  | False  | 0  |'
- en: '| 5  | False  | False  | True  | 0  |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
  zh: '| 5  | False  | False  | True  | 0  |'
- en: '| 6  | True  | False  | True  | 1  |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
  zh: '| 6  | True  | False  | True  | 1  |'
- en: '| 7  | False  | True  | True  | 0  |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
  zh: '| 7  | False  | True  | True  | 0  |'
- en: '| 8  | True  | True  | True  | 1  |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
  zh: '| 8  | True  | True  | True  | 1  |'
- en: Dividing by the number of outcomes (5) gives us the *empirical joint distribution*,
    shown in table 2.3.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 将结果数量（5）除以得到 *经验联合分布*，如表 2.3 所示。
- en: Table 2.3 The empirical distribution of the data
  id: totrans-390
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表2.3 数据的经验分布
- en: '|  | jenny_throws_rock | brian_throws_rock | window_breaks | proportion |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
  zh: '|  | jenny_throws_rock | brian_throws_rock | window_breaks | proportion |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 1  | False  | False  | False  | 0.40  |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| 1  | False  | False  | False  | 0.40  |'
- en: '| 2  | True  | False  | False  | 0.00  |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| 2  | True  | False  | False  | 0.00  |'
- en: '| 3  | False  | True  | False  | 0.20  |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| 3  | False  | True  | False  | 0.20  |'
- en: '| 4  | True  | True  | False  | 0.00  |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| 4  | True  | True  | False  | 0.00  |'
- en: '| 5  | False  | False  | True  | 0.00  |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| 5  | False  | False  | True  | 0.00  |'
- en: '| 6  | True  | False  | True  | 0.20  |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| 6  | True  | False  | True  | 0.20  |'
- en: '| 7  | False  | True  | True  | 0.00  |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| 7  | False  | True  | True  | 0.00  |'
- en: '| 8  | True  | True  | True  | 0.20  |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| 8  | True  | True  | True  | 0.20  |'
- en: So, in the case of discrete outcomes, we go from the data to the empirical distribution
    using counts.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在离散结果的情况下，我们通过计数从数据到经验分布。
- en: In the continuous case, we could calculate a histogram or a density curve or
    some other statistical representation of the empirical distribution. There are
    different statistical choices you can make about how you create those summaries,
    but these are representations of the same underlying empirical distribution.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 在连续情况下，我们可以计算经验分布的直方图、密度曲线或其他统计表示。你可以选择不同的统计方法来创建这些汇总，但这些都是同一基础经验分布的表示。
- en: Importantly, the empirical joint distribution is not the actual joint distribution
    of the variables in the data. For example, we see that several outcomes in the
    empirical distribution never appeared in those five data points. Is the probability
    of their occurrence zero? More likely, the probabilities were greater than zero
    but we didn’t see those outcomes, since only five points were sampled.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是，经验联合分布不是数据中变量的实际联合分布。例如，我们看到经验分布中的一些结果在这五个数据点中从未出现过。它们出现的概率为零吗？更有可能的是，这些概率大于零，但我们没有看到这些结果，因为只采样了五个点。
- en: As an analogy, a fair die has a 1/6 probability of rolling a 1\. If you roll
    the die five times, you have a near (1–1/6)⁵=40% probability of not seeing 1 in
    any of those rolls. If that happened to you, you wouldn’t want to conclude that
    the probability of seeing a 1 is zero. If, however, you kept rolling, the proportion
    of times you saw the 1 would converge to 1/6.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 作为类比，一个公平的骰子掷出1的概率是1/6。如果你掷骰子五次，你几乎有（1–1/6）⁵=40%的概率在任何一次掷骰子中都不会看到1。如果你真的这样做了，你不会想得出看到1的概率为零的结论。然而，如果你继续掷骰子，看到1的比例会收敛到1/6。
- en: NOTE  More precisely, our frequentist interpretation of probability tells us
    to interpret probability as the proportion of times we get a 1 when we roll ad
    infinitum. Despite the “ad infinitum,” we don’t have to roll many times before
    the proportion starts converging to a number (1/6).
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 备注：更精确地说，我们关于概率的频率主义解释告诉我们，将概率解释为当我们无限次掷骰子时得到1的比例。尽管是“无限次”，但在比例开始收敛到一个数字（1/6）之前，我们不需要掷很多次。
- en: From the empirical joint distribution to the observational joint distribution
  id: totrans-406
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 从经验联合分布到观测联合分布
- en: The *observational joint probability* distribution is the true joint distribution
    of the variables observed in the data. Let’s suppose table 2.4 shows the true
    observational joint probability distribution of these observed variables.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: '**观测联合概率**分布是数据中观察到的变量的真实联合分布。假设表2.4显示了这些观察变量的真实观测联合概率分布。'
- en: Table 2.4 Assume this is the true observational joint distribution.
  id: totrans-408
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表2.4 假设这是真实的观测联合分布。
- en: '|  | jenny_throws_rock | brian_throws_rock | window_breaks | probability |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '|  | jenny_throws_rock | brian_throws_rock | window_breaks | probability |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 1  | False  | False  | False  | 0.25  |'
  id: totrans-411
  prefs: []
  type: TYPE_TB
  zh: '| 1  | False  | False  | False  | 0.25  |'
- en: '| 2  | True  | False  | False  | 0.15  |'
  id: totrans-412
  prefs: []
  type: TYPE_TB
  zh: '| 2  | True  | False  | False  | 0.15  |'
- en: '| 3  | False  | True  | False  | 0.15  |'
  id: totrans-413
  prefs: []
  type: TYPE_TB
  zh: '| 3  | False  | True  | False  | 0.15  |'
- en: '| 4  | True  | True  | False  | 0.05  |'
  id: totrans-414
  prefs: []
  type: TYPE_TB
  zh: '| 4  | True  | True  | False  | 0.05  |'
- en: '| 5  | False  | False  | True  | 0.00  |'
  id: totrans-415
  prefs: []
  type: TYPE_TB
  zh: '| 5  | False  | False  | True  | 0.00  |'
- en: '| 6  | True  | False  | True  | 0.10  |'
  id: totrans-416
  prefs: []
  type: TYPE_TB
  zh: '| 6  | True  | False  | True  | 0.10  |'
- en: '| 7  | False  | True  | True  | 0.10  |'
  id: totrans-417
  prefs: []
  type: TYPE_TB
  zh: '| 7  | False  | True  | True  | 0.10  |'
- en: '| 8  | True  | True  | True  | 0.20  |'
  id: totrans-418
  prefs: []
  type: TYPE_TB
  zh: '| 8  | True  | True  | True  | 0.20  |'
- en: Sampling from the joint observational distribution produces the empirical joint
    distribution, as illustrated in figure 2.24.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 从联合观测分布中采样产生经验联合分布，如图2.24所示。
- en: '![figure](../Images/CH02_F24_Ness.png)'
  id: totrans-420
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F24_Ness.png)'
- en: Figure 2.24 Sampling from the observational joint distribution produces the
    observed data and empirical distribution.
  id: totrans-421
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.24 从观测联合分布中采样产生观测数据和经验分布。
- en: 'Latent variables: From the observed joint distribution to the full joint distribution'
  id: totrans-422
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 潜在变量：从观测联合分布到完整联合分布
- en: In statistical modeling, *latent variables* are variables that are not directly
    observed in the data but are included in the statistical model. Going back to
    our data example, imagine there were a fourth latent variable, “strength_of_impact”,
    shown in table 2.5.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计建模中，*潜在变量* 是那些在数据中未直接观察到但在统计模型中包含的变量。回到我们的数据示例，假设有一个第四个潜在变量，“冲击力强度”，如表2.5所示。
- en: Table 2.5 The values in the strength_of_impact column are unseen “latent” variables.
  id: totrans-424
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表2.5 强度_of_impact列中的值是未见的“潜在”变量。
- en: '|  | jenny_throws_rock | brian_throws_rock | strength_of_impact | window_breaks
    |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '|  | jenny_throws_rock | brian_throws_rock | strength_of_impact | window_breaks
    |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 1  | False  | True  | 0.6  | False  |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
  zh: '| 1  | False  | True  | 0.6  | False  |'
- en: '| 2  | True  | False  | 0.6  | True  |'
  id: totrans-428
  prefs: []
  type: TYPE_TB
  zh: '| 2  | True  | False  | 0.6  | True  |'
- en: '| 3  | False  | False  | 0.0  | False  |'
  id: totrans-429
  prefs: []
  type: TYPE_TB
  zh: '| 3  | False  | False  | 0.0  | False  |'
- en: '| 4  | False  | False  | 0.0  | False  |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '| 4  | False  | False  | 0.0  | False  |'
- en: '| 5  | True  | True  | 0.8  | True  |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '| 5  | True  | True  | 0.8  | True  |'
- en: Latent variable models are common in disciplines ranging from machine learning
    to econometrics to bioinformatics. For example, in natural language processing,
    an example of a popular probabilistic latent variable model is *topic models*,
    where the observed variables represent the presence of words and phrases in a
    document, and the latent variable represents the topic of the document (e.g.,
    sports, politics, finance, etc.)
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在变量模型在从机器学习到计量经济学到生物信息学等学科中都很常见。例如，在自然语言处理中，一个流行的概率潜在变量模型是*主题模型*，其中观测变量代表文档中单词和短语的出现，潜在变量代表文档的主题（例如，体育、政治、金融等）。
- en: The latent variables are omitted from the observational joint probability distribution
    because, as the name implies, they are not observed. The joint probability distribution
    of both the observed and the latent variables is the full joint distribution.
    To go from the full joint distribution to the observational joint distribution,
    we marginalize over the latent variables, as shown in figure 2.25.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 潜在变量被省略在观测联合概率分布中，因为正如其名所示，它们没有被观察到。观测变量和潜在变量的联合概率分布是完整的联合分布。要从完整的联合分布到观测联合分布，我们需要对潜在变量进行边缘化，如图2.25所示。
- en: '![figure](../Images/CH02_F25_Ness.png)'
  id: totrans-434
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F25_Ness.png)'
- en: Figure 2.25 Marginalizing the full joint distribution over the latent variables
    produces the observational joint distribution.
  id: totrans-435
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.25 对潜在变量进行边缘化处理，得到观测联合分布。
- en: From the full joint distribution to the data generating process
  id: totrans-436
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 从完整联合分布到数据生成过程
- en: I wrote the actual DGP for the five data points using the following Python code.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用以下Python代码编写了五个数据点的实际DGP。
- en: Listing 2.11 An example of a DGP in code form
  id: totrans-438
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表2.11 代码形式的DGP示例
- en: '[PRE35]'
  id: totrans-439
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '#1 Input variables reflect Jenny and Brian’s inclination to throw and the window’s
    strength.'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 输入变量反映了珍妮和布莱恩扔石头的意愿以及窗户的强度。'
- en: '#2 Jenny and Brian throw the rock if so inclined.'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 如果愿意，珍妮和布莱恩会扔石头。'
- en: '#3 If both Jenny and Brian throw the rock, the total strength of the impact
    is .8.'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 如果珍妮和布莱恩都扔石头，总冲击力为 .8。'
- en: '#4 If either Jenny or Brian throws the rock, the total strength of the impact
    is .6.'
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 如果珍妮或布莱恩扔石头，总冲击力为 .6。'
- en: '#5 Otherwise, no one throws and the strength of impact is 0.'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 否则，没有人扔石头，冲击力为0。'
- en: '#6 If the strength of impact is greater than the strength of the window, the
    window breaks.'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 如果冲击力大于窗户的强度，窗户会破碎。'
- en: Note  In general, the DGP is unknown, and our models are making guesses about
    its structure.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：一般来说，DGP是未知的，我们的模型正在对其结构进行猜测。
- en: 'In this example`, jenny_inclination`, `brian_inclination`, and `window_strength`
    are latent variables between 0 and 1\. `jenny_inclination` represents Jenny’s
    initial desire to throw, `brian_inclination` represents Brian’s initial desire
    to throw, and `window_strength` represents the strength of the window pane. These
    are the initial conditions that lead to one instantiation of the observed variables
    in the data: (`jenny_throws_ball`, `brian_throws_ball`, `window_breaks`).'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，`jenny_inclination`、`brian_inclination`和`window_strength`是介于0和1之间的潜在变量。`jenny_inclination`代表Jenny的初始投掷欲望，`brian_inclination`代表Brian的初始投掷欲望，`window_strength`代表窗户玻璃的强度。这些都是导致数据中观测变量一个实例化的初始条件：(`jenny_throws_ball`、`brian_throws_ball`、`window_breaks`)。
- en: 'I then called the `true_dgp` function on the following five sets of latent
    variables:'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 我随后在以下五组潜在变量上调用了`true_dgp`函数：
- en: '[PRE36]'
  id: totrans-449
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'In other words, the following `for` loop in Python is the literal sampling
    process producing the five data points:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，以下Python中的`for`循环是产生五个数据点的实际采样过程：
- en: '[PRE37]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: The DGP is the causal process that generated the data. Note the narrative element
    that is utterly missing from the full joint probability distribution; Jenny and
    Brian throw a rock at a window if they are so inclined, and if they hit the window,
    the window may break, depending on whether one or both of them threw rocks and
    the strength of the window. The DGP entails the full joint probability distribution,
    as shown in figure 2.26\. In other words, the joint probability distribution is
    a consequence of the DGP based on *how* it generates data.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: DGP是生成数据的因果过程。注意，全联合概率分布中完全缺失的叙事元素；如果Jenny和Brian有投掷石头的倾向，他们会向窗户投掷石头，如果他们击中了窗户，窗户可能会破裂，这取决于他们是否投掷了石头以及窗户的强度。DGP包含完整的联合概率分布，如图2.26所示。换句话说，联合概率分布是基于*如何*生成数据而由DGP产生的结果。
- en: '![figure](../Images/CH02_F26_Ness.png)'
  id: totrans-453
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F26_Ness.png)'
- en: Figure 2.26 The DGP entails the full joint distribution.
  id: totrans-454
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.26 DGP包含完整的联合分布。
- en: In summary, the DGP entails the full joint distribution, and marginalizing over
    the full joint distribution produces the observational joint distribution. Sampling
    from that distribution produces the observed data and the corresponding empirical
    joint distribution. There is a many-to-one relationship as we move down this hierarchy
    that has implications for causal modeling and inference.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，DGP包含完整的联合分布，对完整联合分布进行边缘化产生观测联合分布。从这个分布中进行采样产生观测数据和相应的经验联合分布。当我们向下移动这个层次结构时，存在多对一的关系，这对因果建模和推理有影响。
- en: Many-to-one relationships down the hierarchy
  id: totrans-456
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 层次结构中的多对一关系
- en: '![figure](../Images/CH02_F27_Ness.png)'
  id: totrans-457
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH02_F27_Ness.png)'
- en: Figure 2.27 There is a many-to-one relationship as we move down the hierarchy.
    In summary, there are multiple DGPs consistent with the observed data.
  id: totrans-458
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图2.27 当我们向下移动到层次结构时，存在多对一的关系。总之，存在多个与观测数据一致的DGP。
- en: As we move down from the DGP to full joint to observational joint to empirical
    joint distribution and observed data, there is a many-to-one relationship from
    the preceding level to the subsequent level, as illustrated in figure 2.27.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们从DGP移动到完整的联合分布、观测联合分布和经验联合分布以及观测数据时，前一级别到后一级别之间存在多对一的关系，如图2.27所示。
- en: 'Similarly, an object at one of the levels is consistent with multiple objects
    at the next level up:'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，一个级别的对象与下一个级别上的多个对象是一致的：
- en: '*There could be multiple observational joint distributions consistent with
    the empirical joint distribution*. If we sample five points, then sample five
    more, we’ll get different datasets and thus different empirical distributions.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可能存在多个与经验联合分布一致的观测联合分布*。如果我们采样五个点，然后再采样五个点，我们将得到不同的数据集，从而得到不同的经验分布。'
- en: '*There could be multiple full joint distributions consistent with one observational
    joint distribution*. The difference between the two distributions is the latent
    variables. But what if we have different choices for the sets of latent variables?
    For example, if our observation distribution is *P*(*X*, *Y*), the full joint
    would be *P*(*X*, *Y*, *Z*, *W*) if our set of latent variables is {*Z*, *W*},
    or *P*(*X*, *Y*, *Z*, *V*) if our set of latent variables is {*Z*, *V*}.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可能存在多个与一个观测联合分布一致的完整联合分布*。这两个分布之间的区别是潜在变量。但如果我们对潜在变量的集合有不同的选择呢？例如，如果我们的观测分布是*P*(*X*,
    *Y*)，那么如果我们的潜在变量集合是{*Z*, *W*}，完整的联合分布将是*P*(*X*, *Y*, *Z*, *W*)，或者如果我们的潜在变量集合是{*Z*,
    *V*}，完整的联合分布将是*P*(*X*, *Y*, *Z*, *V*)。'
- en: '*There could be multiple DGP’s consistent with one full joint probability distribution*.
    Suppose in our window-breaking example, Jenny had a friend Isabelle who sometimes
    egged Jenny on to throw the rock and sometimes did not, affecting Jenny’s inclination
    to throw. This DGP is different from the original, but the relationship between
    the latent variable of Isabell’s peer pressure and Jenny’s inclination to throw
    could be such that this new DGP entailed exactly the same joint probability distribution.
    As a more trivial example, suppose we looked at the distribution of a single variable
    corresponding to the sum of the roll of three dice. The DGP is rolling three dice
    and then summing them together. Two DGPs could differ in terms of the order of
    summing the dice; e.g., (first + second) + third or (first + third) + second or
    (second + third) + first. These would all yield the same distribution.'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可能存在多个与一个完整的联合概率分布一致的 DGP（数据生成过程）*。假设在我们的窗口破坏例子中，珍妮有一个朋友伊莎贝尔，有时会怂恿珍妮扔石头，有时则不会，这影响了珍妮扔石头的倾向。这个
    DGP 与原始的 DGP 不同，但伊莎贝尔的同伴压力的潜在变量与珍妮扔石头倾向之间的关系可能是这样的，即这个新的 DGP 导致了完全相同的联合概率分布。作为一个更简单的例子，假设我们观察的是三个骰子点数之和的分布。DGP
    是掷三个骰子然后将它们相加。两个 DGP 可以在求和的顺序上有所不同；例如，(第一个 + 第二个) + 第三个或(第一个 + 第三个) + 第二个或(第二个
    + 第三个) + 第一个。这些都会得到相同的分布。'
- en: Those last two many-to-one relationships are fundamental to the concept of *causal
    identifiability,* the core reason why causal inference is hard. This concept is
    the reason “correlation does not imply causation,” as the saying goes.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 那最后两个多对一关系是因果可识别性概念的基础，这是因果推理之所以困难的核心原因。正如俗话所说，这个概念是“相关性不等于因果性”的原因。
- en: 2.3.3 Statistical tests for independence
  id: totrans-465
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.3 独立性统计测试
- en: Causality imposes independence and conditional independence on variables, so
    we rely on statistical tests for conditional independence to build and validate
    causal models.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
  zh: 因果性将独立性和条件独立性强加给变量，因此我们依赖于条件独立性统计测试来构建和验证因果模型。
- en: Suppose *X* and *Y* are independent, or *X* and *Y* are conditionally independent
    given *Z*. If we have data observing *X*, *Y*, and *Z*, we can run a statistical
    test for independence. The canonical statistical independence procedure returns
    a test statistic that quantifies the statistical association between *X* and *Y*,
    and a p-value that quantifies the probability of getting that degree of association,
    or one more extreme, by pure chance when *X* and *Y* are actually conditionally
    independent given *Z*. Put simply, the test quantifies the statistical evidence
    of dependence or independence.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
  zh: 假设 *X* 和 *Y* 是独立的，或者给定 *Z*，*X* 和 *Y* 是条件独立的。如果我们有观察 *X*、*Y* 和 *Z* 的数据，我们可以运行一个独立性统计测试。标准的统计独立性程序返回一个测试统计量，该统计量量化了
    *X* 和 *Y* 之间的统计关联，以及一个 p 值，该 p 值量化了在 *X* 和 *Y* 实际上给定 *Z* 条件独立的情况下，仅通过纯偶然得到这种程度或更极端的关联的概率。简单来说，这个测试量化了依赖性或独立性的统计证据。
- en: Evidence suggesting that someone committed a murder is not the same as the definitive
    truth that they did. Similarly, statistical evidence indicating independence between
    two variables does not equate to the actual fact of their independence. In both
    cases, evidence can point toward a conclusion without definitively proving it.
    For example, given that independence is true, the strength of the statistical
    evidence can vary on several factors, such as how much data there is. And it is
    always possible to make false conclusions from these tests.
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 表明有人犯下谋杀的证据并不等同于他们确实犯下谋杀的确定性事实。同样，表明两个变量之间独立性的统计证据并不等同于它们实际独立的实际事实。在这两种情况下，证据可以指向一个结论，但并不一定能最终证明它。例如，给定独立性是真实的，统计证据的强度可以因几个因素而异，例如数据的数量。而且，从这些测试中得出错误结论总是可能的。
- en: Remember that if *X* and *Y* are independent, then *P*(*Y*|*X*) is equivalent
    to *P*(*Y*). In predictive terms, that means *X* has no predictive power on *Y*.
    If you can’t use classical statistical tests (e.g., if *X* and *Y* are vectors)
    then you can try training a predictive model and subjectively evaluating how well
    the model predicts.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，如果 *X* 和 *Y* 是独立的，那么 *P*(*Y*|*X*) 等同于 *P*(*Y*)。在预测术语中，这意味着 *X* 对 *Y* 没有预测能力。如果你不能使用经典统计测试（例如，如果
    *X* 和 *Y* 是向量），那么你可以尝试训练一个预测模型并主观评估模型预测的好坏。
- en: 2.3.4 Statistical estimation of model parameters
  id: totrans-470
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3.4 模型参数的统计估计
- en: When we “train” or “fit” a model, we are attempting to estimate the values of
    parameters of the model, such as the weights in a regression model or neural network.
    Generally, in statistical modeling and machine learning, the goal of parameter
    estimation is modeling the observational or joint probability distribution. In
    causal modeling, the objective is modeling the DGP. The distinction is important
    for making good causal inferences.
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们“训练”或“拟合”一个模型时，我们试图估计模型参数的值，例如回归模型或神经网络中的权重。在统计建模和机器学习中，参数估计的目标是建模观测或联合概率分布。在因果建模中，目标是建模DGP。这种区别对于做出良好的因果推断非常重要。
- en: Estimating by maximizing likelihood
  id: totrans-472
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 通过最大化似然估计
- en: In informal terms and in the context of parameter estimation, likelihood is
    the probability of having observed the data given a candidate value of the parameter
    vector. *Maximizing likelihood* means choosing the value of the parameter vector
    that has the highest likelihood. Usually, we work with maximizing the log of the
    likelihood instead of the likelihood directly because it is mathematically and
    computationally easier to do so; the value that maximizes likelihood is the same
    as the value that maximizes log-likelihood. In special cases, such as linear regression,
    the maximum likelihood estimate has a solution we can derive mathematically, but
    in general, we must find the solution using numerical optimization techniques.
    In some models, such as neural networks, it is infeasible to find the value that
    maximizes likelihood, so we settle for a candidate that has a relatively high
    likelihood.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
  zh: 在非正式的术语和参数估计的背景下，似然是在给定参数向量候选值的情况下观察数据的概率。*最大化似然*意味着选择具有最高似然性的参数向量值。通常，我们通过最大化似然的对数而不是似然本身来进行工作，因为这从数学和计算上更容易实现；最大化似然的价值与最大化对数似然的价值相同。在特殊情况下，例如线性回归，最大似然估计有我们可以通过数学推导出的解，但在一般情况下，我们必须使用数值优化技术来找到解。在某些模型中，例如神经网络，找到最大化似然性的值是不切实际的，所以我们满足于一个相对似然性较高的候选值。
- en: Estimating by minimizing other loss functions and regularization
  id: totrans-474
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 通过最小化其他损失函数和正则化估计
- en: In machine learning, there are a variety of loss functions for estimating parameters.
    Maximizing likelihood is a special case of minimizing a loss function, namely
    the negative log-likelihood loss function.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，有各种损失函数用于估计参数。最大化似然是最小化损失函数的一个特例，即负对数似然损失函数。
- en: '*Regularization* is the practice of adding additional elements to the loss
    function that steer the optimization toward better parameter values. For example,
    L2 regularization adds a value proportional to the sum of the square of the parameter
    values to the loss. Since a small increase in value leads to a larger increase
    in the square of the value, L2 regularization helps avoid exceedingly large parameter
    estimates.'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: '*正则化*是指在损失函数中添加额外的元素，以引导优化过程向更好的参数值靠拢。例如，L2正则化将参数值的平方和的值添加到损失中。由于值的微小增加会导致值的平方增加更大，因此L2正则化有助于避免参数估计过大。'
- en: Bayesian estimation
  id: totrans-477
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 贝叶斯估计
- en: '*Bayesian estimation* treats parameters as random variables and tries to model
    the conditional distribution of the parameters (typically called the *posterior*
    distribution) given the observed variables in the data. It does so by putting
    a “prior probability distribution” on the parameters. The prior distribution has
    its own parameters called “hyperparameters” that the modeler must specify. When
    there are latent variables in the model, Bayesian inference targets the joint
    distribution of the parameters and the latent variables conditional on the observed
    variables.'
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: '*贝叶斯估计*将参数视为随机变量，并试图根据数据中观察到的变量来建模参数的条件分布（通常称为*后验分布*）。它是通过在参数上放置一个“先验概率分布”来实现的。先验分布有自己的参数，称为“超参数”，模型必须指定这些超参数。当模型中有潜在变量时，贝叶斯推理的目标是在给定观察变量的条件下，参数和潜在变量的联合分布。'
- en: As mentioned before, in this book I use Greek letters for parameters and Roman
    letters for variables in the DGP, including latent variables. But for a Bayesian
    statistician, the distinction is irrelevant; both parameters and latent variables
    are unknown and thus targets of inference.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，在这本书中，我使用希腊字母表示参数，罗马字母表示DGP中的变量，包括潜在变量。但对于贝叶斯统计学家来说，这种区别无关紧要；参数和潜在变量都是未知的，因此是推理的目标。
- en: One of the main advantages of Bayesian estimation is that rather than getting
    a point value for the parameters, you get an entire conditional probability distribution
    of the parameters (more specifically, you get samples from or parameter values
    representing that distribution). That probability distribution represents uncertainty
    about the parameter values, and you can incorporate that uncertainty into predictions
    or other inferences you make from the model.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 贝叶斯估计的一个主要优点是，你得到的不是参数的点值，而是参数的整个条件概率分布（更具体地说，你得到的是代表该分布的样本或参数值）。这个概率分布代表了参数值的不确定性，你可以将这种不确定性纳入模型预测或其他从模型中得出的推论中。
- en: According to Bayesian philosophy, the prior distribution should capture the
    modeler’s subjective beliefs about the true value of the parameters. We’ll do
    something similar in causal modeling when we turn our beliefs about the causal
    structure and mechanisms of the DGP into causal assumptions in the model.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 根据贝叶斯哲学，先验分布应该捕捉模型对参数真实值的主体信念。当我们把对DGP的因果结构和机制的信念转化为模型中的因果假设时，我们将在因果建模中做类似的事情。
- en: Statistical and computational attributes of an estimator
  id: totrans-482
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 估计器的统计和计算属性
- en: Given that there are many ways of estimating a parameter, let’s look for ways
    to compare the quality of estimation methods. Suppose the parameter we want to
    estimate had a ground truth value. Statisticians think about how well an estimation
    method can recover that true value. Specifically, they care about the bias and
    consistency of an estimation method. An estimator is a random variable because
    it comes from data (and data has a distribution), which means an estimator has
    a distribution. An estimator is unbiased if the mean of that distribution is equal
    to the true value of the parameter it is estimating. Consistency means that the
    more data you have, the closer the estimate is to the true value of the parameter.
    In practice, the consistency of the estimator is more important than whether it
    is unbiased.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 由于估计参数有多种方法，让我们寻找比较估计方法质量的方法。假设我们想要估计的参数有一个真实值。统计学家思考估计方法如何很好地恢复这个真实值。具体来说，他们关心估计方法的偏差和一致性。估计器是一个随机变量，因为它来自数据（数据有分布），这意味着估计器有一个分布。如果该分布的均值等于它所估计的参数的真实值，则估计器是无偏的。一致性意味着你拥有的数据越多，估计值就越接近参数的真实值。在实践中，估计器的一致性比它是否无偏更重要。
- en: Computer scientists know that while consistency is nice in theory, getting an
    estimation method to work with “more data” is easier said than done. They care
    about the computational qualities of an estimator in relation to the amount of
    data. Does the estimator scale with the data? Is it parallelizable? An estimator
    may be consistent, but when its running on an iPhone app, will it converge to
    the true value in milliseconds and not eat up the battery’s charge in the process?
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机科学家知道，虽然理论上一致性很好，但要使估计方法能够处理“更多数据”比说起来容易。他们关心估计器的计算质量与数据量的关系。估计器是否随着数据量的增加而扩展？它是否可并行化？一个估计器可能是一致的，但当它在iPhone应用上运行时，它是否会在毫秒内收敛到真实值，而不会在这个过程中耗尽电池电量？
- en: This book decouples understanding causal logic from the statistical and computational
    properties of estimators of causal parameters. We will focus on the causal logic
    and rely on libraries like DoWhy that make the statistical and computational calculations
    easy to do.
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 这本书将理解因果逻辑与因果参数估计器的统计和计算属性解耦。我们将专注于因果逻辑，并依赖像DoWhy这样的库，这些库使得统计和计算计算变得容易进行。
- en: Goodness-of-fit vs. cross-validation
  id: totrans-486
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 拟合优度与交叉验证
- en: 'When we estimate parameters, we can calculate various statistics to tell us
    how well we’ve done. One class of statistics is called *goodness-of-fit statistics*.
    Statisticians define goodness-of-fit as statistics that quantify how well the
    model fits the data used to train the model. Here’s another definition: goodness-of-fit
    statistics tell you how well your model pretends to be the DGP for the data you
    used to train your model. However, as we saw, there are multiple possible DGPs
    for a given data set. Goodness-of-fit won’t provide causal information that can
    distinguish the true DGP.'
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们估计参数时，我们可以计算各种统计量来告诉我们我们做得如何。一类统计量被称为**拟合优度统计量**。统计学家将拟合优度定义为量化模型与用于训练模型的所用数据拟合程度的统计量。这里还有一个定义：拟合优度统计量告诉你你的模型在多大程度上假装是用于训练模型的数据的DGP。然而，正如我们所看到的，对于给定的数据集，存在多个可能的DGP。拟合优度不会提供区分真实DGP的因果信息。
- en: Cross-validation statistics generally indicate how well your model predicts
    data it was not trained on. It is possible to have a model with a decent goodness-of-fit
    relative to other models, but that still predicts poorly. Machine learning is
    usually concerned with the task of prediction and so favors cross-validation.
    However, a model can be a good predictor and provide completely bogus causal inferences.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证统计通常表明你的模型在未接受过训练的数据上的预测效果如何。可能存在一个模型相对于其他模型具有相当好的拟合度，但仍然预测效果不佳。机器学习通常关注预测任务，因此倾向于使用交叉验证。然而，一个模型可以是一个好的预测器，并提供完全错误的因果推断。
- en: 2.4 Determinism and subjective probability
  id: totrans-489
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2.4 决定论和主观概率
- en: This section will venture into the philosophical underpinnings we’ll need for
    probabilistic causal modeling. In this book, we’ll use probabilistic models to
    model causal models. When training the model, we might want to use Bayesian parameter
    estimation procedures. When doing causal inference, we might want to use a probabilistic
    inference algorithm. When we do causal decision-making, we might want to use Bayesian
    decision theory. Further, *structural causal models* (chapter 6) have a rigid
    requirement on where randomness can occur in the model. That means being clear
    about the differences between Bayesianism, uncertainty, randomness, probabilistic
    modeling, and probabilistic inference is important.
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将探讨我们进行概率因果建模所需的哲学基础。在这本书中，我们将使用概率模型来建模因果模型。在训练模型时，我们可能希望使用贝叶斯参数估计程序。在进行因果推断时，我们可能希望使用概率推断算法。当我们进行因果决策时，我们可能希望使用贝叶斯决策理论。此外，**结构因果模型**（第6章）对模型中随机性可能发生的位置有严格的要求。这意味着明确区分贝叶斯主义、不确定性、随机性、概率建模和概率推断是很重要的。
- en: The first key point is to view the DGP as deterministic. The second key point
    is to view the probability in our models of the DGP as subjective.
  id: totrans-491
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个关键点是把DGP视为决定论的。第二个关键点是认为我们DGP模型中的概率是主观的。
- en: 2.4.1 Determinism
  id: totrans-492
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4.1 决定论
- en: 'The earlier code for the rock-throwing DGP is entirely *deterministic*; given
    the initial conditions, the output is certain. Consider our definition of physical
    probability again: if I throw a die, why is the outcome random?'
  id: totrans-493
  prefs: []
  type: TYPE_NORMAL
  zh: 抛掷岩石DGP的早期代码完全是**决定论的**；给定初始条件，输出是确定的。再次考虑我们对物理概率的定义：如果我掷骰子，为什么结果是随机的？
- en: If I had a superhuman level of dexterity, perception, and mental processing
    power, I could mentally calculate the die roll’s physics and know the outcome
    with certainty. This philosophical idea of determinism essentially says that the
    DGP is deterministic. Eighteenth-century French scholar Pierre-Simon Laplace explained
    determinism with a thought experiment called *Laplace’s demon*. Laplace imagined
    some entity (the demon) that knew every atom’s precise location and momentum in
    the universe. With that knowledge, that entity would know the future state of
    the universe with complete deterministic certainty because it could calculate
    them from the laws of (Newtonian) mechanics. In other words, given all the causes,
    the effect is 100% entirely determined and not at all random.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我拥有超人的灵巧、感知和心智处理能力，我可以在心中计算出骰子投掷的物理学并确定结果。这个决定论哲学思想本质上说DGP是决定论的。18世纪法国学者皮埃尔-西蒙·拉普拉斯用一种称为拉普拉斯恶魔的思想实验来解释决定论。拉普拉斯想象了一个实体（恶魔），它知道宇宙中每个原子的精确位置和动量。有了这些知识，这个实体将能够以完全决定论的确定性知道宇宙的未来状态，因为它可以从（牛顿）力学的定律中计算出它们。换句话说，给定所有原因，结果100%完全确定，毫无随机性。
- en: To be clear, some systems, when we look closely enough, have inherently stochastic
    elements (e.g., quantum mechanics, biochemistry, etc.). However, this philosophical
    view of modeling will apply to most things we’ll care to model.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
  zh: 为了明确起见，一些系统，当我们足够仔细地观察时，具有固有的随机元素（例如，量子力学、生物化学等）。然而，这种建模的哲学观点将适用于我们关心的大多数事物。
- en: 2.4.2 Subjective probability
  id: totrans-496
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4.2 主观概率
- en: In our physical interpretation of probability, when I roll a die, probability
    represents my lack of the demon’s superhuman knowledge of the location and momentum
    of all the die’s particles as it is rolling. In other words, when I build probability
    models of the DGP, the probability reflects my lack of knowledge. This philosophical
    idea is called *subjective probability* or *Bayesian probability*. The argument
    goes beyond Bayes rule and Bayesian statistical estimation to say that probability
    in the model represents the modeler’s lack of complete knowledge about the DGP
    and does not represent inherent randomness in the DGP.
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们对概率的物理解释中，当我掷骰子时，概率代表了我对骰子滚动时所有粒子位置和动量的超人类知识的缺乏。换句话说，当我构建DGP的概率模型时，概率反映了我的知识缺乏。这种哲学思想被称为*主观概率*或*贝叶斯概率*。这种论点超越了贝叶斯法则和贝叶斯统计估计，认为模型中的概率代表了模型构建者对DGP的完全知识缺乏，并不代表DGP中的固有随机性。
- en: Subjective probability expands our “random physical process” interpretation
    of probability. The physical interpretation of probability works well for simple
    physical processes like rolling a die, flipping a coin, or shuffling a deck of
    cards. But, of course, we will want to model many phenomena that are difficult
    to think of as repeatable physical processes. For example, how the mind turns
    thoughts into speech, or how an increased flow of fresh water into the ocean due
    to climate change is threatening to tip the global system of ocean currents. In
    these cases, we will still model these phenomena using random generation. The
    probabilities used in the random generation reflect that while we, as modelers,
    may know some details about the data-generating process, we’ll never have the
    superhuman deterministic level of detail.
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 主观概率扩展了我们对概率的“随机物理过程”解释。概率的物理解释对于简单的物理过程，如掷骰子、抛硬币或洗牌，效果很好。但是，当然，我们还想对许多难以被视为可重复物理过程的现象进行建模。例如，思想如何转化为言语，或者由于气候变化，新鲜水流增加对全球洋流系统的威胁。在这些情况下，我们仍然会使用随机生成来对这些现象进行建模。随机生成中使用的概率反映了，尽管我们作为模型构建者可能对数据生成过程的一些细节有所了解，但我们永远不会达到超人的确定性细节水平。
- en: Summary
  id: totrans-499
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: A random variable is a variable whose possible values are numerical outcomes
    of a random phenomenon.
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机变量是一个变量，其可能值是随机现象的数值结果。
- en: A probability distribution function is a function that maps the random variable
    outcomes to a probability value. A joint probability distribution function maps
    each combination of *X* and *Y* outcomes to a probability value.
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概率分布函数是一个将随机变量的结果映射到概率值的函数。联合概率分布函数将每个 *X* 和 *Y* 结果的组合映射到概率值。
- en: We derive the chain rule, the law of total probability, and Bayes rule from
    the fundamental axioms of probability. These are useful rules in modeling.
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们从概率的基本公理中推导出链式法则、全概率定律和贝叶斯法则。这些规则在建模中非常有用。
- en: A Markovian assumption means each variable in an ordering of variables only
    depends on those that come directly before in the order. This is a common simplifying
    assumption in statistical modeling, but it plays a large role in causal modeling.
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 马尔可夫假设意味着变量序列中的每个变量只依赖于直接在其前面的变量。这是统计建模中常见的简化假设，但在因果建模中起着重要作用。
- en: Canonical classes of distributions are mathematically well-described representations
    of distributions. They provide us with primitives that make probabilistic modeling
    flexible and relatively easy.
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经典分布类是分布的数学描述良好的表示。它们为我们提供了使概率建模灵活且相对容易的原语。
- en: Canonical distributions are instantiated with a set of parameters, such as location,
    scale, rate, and shape parameters.
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经典分布是通过一组参数实例化的，例如位置、尺度、速率和形状参数。
- en: When we build models, knowing what variables are independent or conditionally
    independent dramatically simplifies the model. In causal modeling, independence
    and conditional independence will be vital in separating correlation from causation.
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们构建模型时，知道哪些变量是独立的或条件独立的可以极大地简化模型。在因果建模中，独立性和条件独立性将在将相关性从因果关系分离中发挥关键作用。
- en: The expected value of a random variable with a finite number of outcomes is
    the weighted average of all possible outcomes, where the weight is the probability
    of that outcome.
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具有有限个结果的随机变量的期望值是所有可能结果的加权平均值，其中权重是该结果的概率。
- en: Probability is just a value. We need to give that value an interpretation. The
    physical definition of probability maps probability to the proportion of times
    an outcome would occur if a physical process could be run repeatedly ad infinitum.
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 概率只是一个值。我们需要给这个值一个解释。概率的物理定义将概率映射到如果物理过程可以无限次重复运行，则结果发生的比例。
- en: In contrast to the physical interpretation of probability, the Bayesian view
    of subjective probability interprets probability in terms of belief, or conversely,
    uncertainty.
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与概率的物理解释相反，贝叶斯对主观概率的解释将概率解释为信念，或者相反，不确定性。
- en: When coding a random process, Pyro allows you to use canonical distributions
    as primitives in constructing nuanced random process models.
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当编码随机过程时，Pyro允许你使用经典分布作为构建细微随机过程模型的原始元素。
- en: Monte Carlo algorithms use random generation to estimate expectations from a
    distribution of interest.
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 蒙特卡洛算法使用随机生成来估计从感兴趣分布中的期望值。
- en: Popular inference algorithms include graphical model-based algorithms, probability
    weighting, MCMC, and variational inference.
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流行的推理算法包括基于图模型的算法、概率加权、MCMC和变分推理。
- en: Canonical distributions and random processes can serve as proxies for populations
    we wish to model and for which we want to make inferences. Conditional probability
    is an excellent way to model heterogeneous subpopulations.
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 经典分布和随机过程可以作为我们希望模拟的人群的代理，以及我们想要从中进行推理的人群。条件概率是模拟异质子人群的绝佳方式。
- en: Different canonical distributions are used to model different phenomena, such
    as counts, bell curves, and waiting times.
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的经典分布用于模拟不同的现象，例如计数、钟形曲线和等待时间。
- en: Generating from random processes is a good model of real-life sampling of independent
    and identically distributed data.
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从随机过程中生成是模拟现实生活独立同分布数据采样的良好模型。
- en: Given a dataset, multiple data generating processes (DGPs) could have potentially
    generated that dataset. This fact connects to the challenge of parsing causality
    from correlation.
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 给定一个数据集，可能存在多个数据生成过程（DGPs）可以生成该数据集。这个事实与从相关性中解析因果关系的挑战相关联。
- en: Statistical independence tests validate independence and conditional independence
    claims about the underlying distribution.
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 统计独立性测试验证了关于潜在分布的独立性和条件独立性声明。
- en: There are several methods for learning model parameters, including maximum likelihood
    estimation and Bayesian estimation.
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习模型参数的方法有几种，包括最大似然估计和贝叶斯估计。
- en: Determinism suggests that if we knew everything about a system, we could predict
    its outcome with zero error. Subjective probability is the idea that probability
    represents the modeler’s lack of that complete knowledge about the system. Adopting
    these philosophical perspectives will serve us in understanding causal AI.
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决定性意味着如果我们知道一个系统的所有信息，我们就可以以零误差预测其结果。主观概率是概率代表建模者对系统缺乏完整知识的一种观点。采用这些哲学观点将有助于我们理解因果AI。
- en: A great way to build models is to factorize a joint distribution, simplify the
    factors with conditional independence, and then implement factors as random processes.
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建模型的一个好方法是分解联合分布，简化条件独立性的因子，然后将因子实现为随机过程。
- en: A powerful modeling technique is to use probability distributions to model populations,
    particularly when you care about heterogeneity in those populations.
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一种强大的建模技术是使用概率分布来模拟人群，尤其是当你关心这些人群中的异质性时。
- en: When we use probability distributions to model populations, we can map generating
    from random processes to sampling from the population.
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当我们使用概率分布来模拟人群时，我们可以将随机过程中的生成映射到从人群中采样。
- en: While traditional statistical modeling models the observational joint distribution
    or the full joint distribution, causal modeling models the DGP.
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然传统的统计建模模型观测联合分布或完整的联合分布，因果建模则模型化DGP（数据生成过程）。
