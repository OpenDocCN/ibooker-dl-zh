- en: Chapter 7\. AI Risks and Challenges
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 2](ch02.html#ch02_essential_background_on_generative_ai_1748358211788823),
    we discussed the limitations of generative AI. This chapter will go over the risks
    and challenges that derive from those limitations. It’s important to understand
    that limitations and risks are two separate but related concepts. Limitations
    explain what AI can’t do. For example, generative AI can only provide insights
    using previously published data; it doesn’t “know” anything without first ingesting
    the data that gives it the information it needs.
  prefs: []
  type: TYPE_NORMAL
- en: The limitations of AI are what lead to risks, and these can be devastating to
    your SEO, brand, and revenue. Various risks can result in revenue-impacting consequences,
    including litigation, loss of search engine rank, brand damage, and potential
    penalties. However, many of the risks of AI can be mitigated by careful human
    reviews. As much as AI reduces overhead and time to perform repeatable SEO tasks,
    it cannot function well without the critical thinking of human reviewers.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we’ll cover some of the common pitfalls you may encounter when
    using AI and how you can overcome them. If you recall the Gartner Hype Cycle from
    [Chapter 2](ch02.html#ch02_essential_background_on_generative_ai_1748358211788823)
    ([Figure 2-3](ch02.html#ch02_figure_3_1748358211760542)), one of the phases is
    disillusionment. Many of AI’s pitfalls can contribute to disillusionment, but
    these challenges can be managed with the right strategies, which we will also
    discuss in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Ultimate Risk: Low-Quality Content'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The core of an SEO practitioner’s job is to produce a site that adds value to
    the internet by offering users a place to find factual, insightful, engaging content.
    As soon as you lose sight of that goal, you risk everything, and improper use
    of AI is a sure way to go down the wrong path. AI is a powerful tool, but with
    its power comes the responsibility of ensuring that you use it correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Most of this risk results from being able to generate content at scale. If you
    were producing content at scale years ago, you’d have writers generating several
    pieces a week. Quality human writers typically produce a relatively low percentage
    of low-quality content compared to AI, which can generate hundreds—even thousands—of
    pieces a week. The percentage of low-quality content increases with scale, so
    the majority of the AI-generated pieces are often vague and unengaging, with what
    feels like empty text.
  prefs: []
  type: TYPE_NORMAL
- en: Once Google picks up on low-quality signals from your content, you will likely
    suffer major drops in your search engine traffic. For this reason, we strongly
    suggest that you don’t use generative AI to create content at scale (meaning hundreds
    of pieces per week) *unless* you have a very large staff to review and fix the
    myriad problems that you will find within that content.
  prefs: []
  type: TYPE_NORMAL
- en: Google algorithms know when your site may have some low-quality content; it’s
    when your content is unhelpful and unengaging that you start to see a loss in
    search ranking. Low quality is subjective, but unengaging and unhelpful content
    often leads to lower user engagement, and this is a significant Google ranking
    factor. Users leave your page and perform a search to find another site. This
    behavior sends low-quality signals to algorithms, which leads to a loss of search
    ranking. Not only are a loss in ranking and Google penalties the biggest risks,
    but they are also the most difficult to bounce back from. It can take years to
    recover, and it’s possible that you will never regain algorithmic trust. As more
    content pollutes the internet, algorithmic trust will be much more difficult to
    obtain, making it harder for smaller brands to compete. Generating massive amounts
    of content using AI can be initially tempting, but it is highly likely to lead
    to long-term algorithmic loss in search engine rankings.
  prefs: []
  type: TYPE_NORMAL
- en: As an SEO practitioner, your job is to build pages that answer the intent of
    a potential customer’s search engine query. When generative AI interest boomed
    in 2023, Google released a [statement](https://oreil.ly/F1VP0) in February saying
    that “appropriate use of AI or automation is not against our guidelines.” Google
    never intended that to apply to using generative AI to create poor-quality content.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at a short example related to SEO. The prompts in [Figure 7-1](#ch07_figure_1_1748358220824643)
    ask ChatGPT to give the top SEO tip and the top SEO tip for ranking a technology
    site, and to be specific.
  prefs: []
  type: TYPE_NORMAL
- en: Notice that even though the first request said to be specific, the output is
    vague. “High quality, user-focused content” is a tip for any site across all industries.
    The second prompt asks for an SEO tip for ranking a technology site. Notice that
    the second output is generally the same as the first. Both outputs feel empty
    and unengaging. If this were a snippet in your content, you would want a human
    editor to add substance and specificity.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ugai_0701.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-1\. ChatGPT output for SEO tips
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Errors by omission are difficult to detect but can be harmful to your brand,
    especially if your brand relies on being an authority in the industry. Suppose
    you sell a software as a service (SaaS) product that offers the same two features
    that your competitor does, but your value-added proposition is an additional feature.
    This feature was recently introduced, but your competitor has a larger market
    share. You need to create content that compares your product to your competitor’s
    and use it to introduce your new feature. If you create content using generative
    AI, it’s likely that output will tell users that both SaaS products—yours and
    your competitor’s—have the same two features, but it will omit your newly designed
    feature. If you automate content creation, you might find that your site’s new
    content is worthless since it doesn’t promote the feature that gives your SaaS
    product a competitive edge. Not only that, but you don’t want to just mention
    this new feature—it should be a significant focus of the content since that’s
    your competitive advantage. While the content is accurate, it’s missing critical
    information for your marketing.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: For a deep dive into examples of errors resulting from AI limitations, see [“Limitations
    of Generative AI”](ch02.html#ch02_limitations_of_generative_ai_1748358211790682).
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s look at a technical example. Suppose you sell database services and
    you need to show potential customers that you understand different database engines,
    specifically MongoDB and Microsoft SQL Server. Let’s ask ChatGPT to give us two
    paragraphs on the differences between the two databases. The output is shown in
    [Figure 7-2](#ch07_figure_2_1748358220824678).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ugai_0702.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-2\. ChatGPT 4 output comparing MongoDB and SQL Server
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In [Figure 7-2](#ch07_figure_2_1748358220824678), ChatGPT mentions that SQL
    Server supports a concept called *ACID* (atomicity, consistency, isolation, and
    durability) and then says that MongoDB offers other advantages. If you look at
    official MongoDB resource pages, they indicate that MongoDB is also [ACID compliant](https://oreil.ly/diqfG),
    as shown in [Figure 7-3](#ch07_figure_3_1748358220824703).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ugai_0703.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-3\. MongoDB resource page information on ACID compliance
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Although the ChatGPT content in [Figure 7-2](#ch07_figure_2_1748358220824678)
    does not explicitly say that MongoDB is *not* ACID compliant, it omits the fact
    that MongoDB is ACID compliant, so the information it gives is incorrect. It’s
    easy to see how this type of poor-quality content could cause brand damage by
    giving potential customers the sense that your brand is not truly an authority
    in the subject. The ultimate result is fewer sales for your brand and potentially
    a loss in search engine rankings.
  prefs: []
  type: TYPE_NORMAL
- en: You can use other LLMs to verify information from ChatGPT or cross-reference
    facts. Figures [7-4](#ch07_figure_4_1748358220824726) through [7-6](#ch07_figure_6_1748358220824769)
    show output for the same query in Claude, Microsoft Copilot, and Gemini.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ugai_0704.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-4\. Claude output comparing MongoDB and SQL Server
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![](assets/ugai_0705.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-5\. Microsoft Copilot output comparing MongoDB and SQL Server
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![](assets/ugai_0706.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-6\. Gemini output comparing MongoDB and SQL Server
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: To overcome errors of omission, you need a true SME who can identify the missing
    pieces, understand where to look for them, and validate that the information is
    correct. In this example, a reviewer who understands databases is required to
    know that both databases are ACID compliant and to validate the information on
    the vendor’s site.
  prefs: []
  type: TYPE_NORMAL
- en: When creating content at scale, remember that your primary goal is to offer
    value to the user.The meat of the issue is low-quality content, and the other
    risks we cover in the rest of this chapter feed into those concerns about low-quality
    content.
  prefs: []
  type: TYPE_NORMAL
- en: 'Speed of Publishing: Faster Is Not Always Better for SEO'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hiring writers was always a big overhead cost and a time-consuming endeavor
    for SEO practitioners, so the thought of having AI become one hundred writers
    overnight is tempting. As Google (and other search engines) continue to evolve
    and attempt to control the mass publication of AI-generated content, it’s important
    to realize that faster publication doesn’t always mean improved quality and better
    search engine placement. As a matter of fact, if you previously published one
    or two articles a week and are now suddenly publishing hundreds of articles a
    week, you might be sending the wrong quality signals to search algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: As we discussed in previous sections, Google downranks low-quality AI-generated
    content. AI models used to generate content aren’t at the point where no human
    editor is necessary, but large numbers of organizations tried to use it that way
    anyway in 2024, and as a result, we saw massive chaos in search engines indexing
    misinformation on the internet because all of the low-quality content that was
    published. Users complained, and Google rolled back its initial stance on AI-generated
    content being fine for users and ranking.
  prefs: []
  type: TYPE_NORMAL
- en: A component of search algorithms is the concept of *trust*. Trust is often measured
    in the age of a site and the long-term quality signals sent to the search engine.
    For example, if your site is BMW and you’re trying to rank for car-related content,
    Google will likely trust your site much more than newer sites. We’ve observed
    that Google has rolled back changes and returned to trusting older long-term brand
    sites in spaces where there is a lot of AI-generated noise from massive content
    publishing. Google trust factors are difficult to measure, but you can avoid downranking
    by always reviewing your AI-generated content.
  prefs: []
  type: TYPE_NORMAL
- en: Every site has its low-quality content, but that should be kept to a minimum.
    If you publish hundreds of new articles a week after you traditionally published
    only a few articles a week, that will likely send low-quality signals to search
    engines. The idea of trust is to consistently but slowly ramp up production to
    ensure that quality content remains a primary goal. Scaling up slowly will avoid
    sending any red flags to quality algorithms. As an example, you might have a 50:1
    ratio of quality content, where 1 out of 50 articles sends low-quality signals.
    If you ramp up automated content too much without checking for quality, your quality
    ratio might rapidly change to 60:30, meaning nearly half your content is low quality.
    A worse ratio will probably affect the overall search ranking of your site.
  prefs: []
  type: TYPE_NORMAL
- en: 'Copyright: Unique Content Doesn’t Mean You Own It'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Your content may pass plagiarism checkers, but AI puts a new spin on copyright.
    Because AI generates content based on the writing of others, you’re creating content
    that isn’t truly your own, even though that sequence of words is not found anywhere
    else on the internet. Content written in the same tone, voice, and style as another
    author could be considered copyright infringement. We say “could” be copyright
    infringement because as of the writing of this book, lawsuits are still pending.
  prefs: []
  type: TYPE_NORMAL
- en: Eight large, well-known publishers are suing OpenAI—the creators of ChatGPT—for
    [copyright infringement](https://oreil.ly/TQlnf). At the foundation of the lawsuits
    is the claim that ChatGPT content uses their original work and their journalists’
    original ideas to generate similar content. The lawsuit claims that OpenAI used
    their work to train models, which begs the question if AI can ever generate original
    content if some data it ingests is unusable.
  prefs: []
  type: TYPE_NORMAL
- en: Copyright infringement is still an unknown factor in future regulations, but
    SEO practitioners should ensure that they neither prompt AI to create content
    in the same style and tone as any other author nor create content using a single
    source of information. Neglecting this could increase the likelihood of [infringement
    lawsuits](https://oreil.ly/Jf9mb). Some lawsuits such as *Concord Music Group,
    Inc. v. Anthropic PBC* and *The New York Times v. Microsoft and OpenAI* provide
    the courts with output that copies original works verbatim. LLM providers are
    [contesting the allegations](https://oreil.ly/QiEBt) and claim that “regurgitation”
    of content is a bug rather than a feature. SEO practitioners using generative
    AI to produce content [can’t copyright it either](https://oreil.ly/X_eqE), which
    can cause issues if your own content is stolen.
  prefs: []
  type: TYPE_NORMAL
- en: To avoid copyright infringement, diversify your sources and provide references—with
    a link or footnote—to sources used in your content. Some SEO professionals choose
    to work with multiple LLMs to diversify output and validate information. For example,
    you might use ChatGPT to generate content and use Claude to verify that content.
    You can also specify using multiple sources in your prompts and ask ChatGPT to
    provide a list of sources for its content.
  prefs: []
  type: TYPE_NORMAL
- en: 'Plagiarism: Did You Write This Content?'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every teacher has students who try to pass off plagiarized content as their
    own. Generative AI can be your bad student if you use it to create content without
    thoroughly checking it. Instead of having one writer produce plagiarized content,
    AI could be the equivalent of one hundred writers producing plagiarized content.
    For SEO practitioners, having the same content as multiple other sites lowers
    quality signals sent to search engines and could affect your search ranking.
  prefs: []
  type: TYPE_NORMAL
- en: Plagiarism on the internet is a bit different than academic plagiarism. Academically,
    you can’t rewrite a whitepaper from another researcher and call it your own just
    because it passes plagiarism checkers. This activity is still plagiarism. But
    the internet works differently than academics. The same idea is often written
    about dozens of times on the internet. Your content strategies might overlap these
    same ideas, but you want to add value that can’t be found in other brands’ content
    strategies. “Value” is subjective and depends on your target audience, but your
    goal should be to provide information related to the search query and a call to
    action to instruct the reader where to go next. This will offer value to readers
    and search engines, which will in turn improve your ranking and trust signals.
  prefs: []
  type: TYPE_NORMAL
- en: When you have writers working for you, you check their content for plagiarism.
    An example of a tool that does this is [Copyscape](https://www.copyscape.com),
    but you can find many other tools using your favorite search engine. These tools
    aren’t perfect, but they provide a good first check to ensure that your writers
    aren’t plagiarizing. You should also compare your content with what’s already
    published on the internet. You can copy and paste full or partial sentences into
    Google to see if large blocks of content were plagiarized by the writer.
  prefs: []
  type: TYPE_NORMAL
- en: Separately, you should check that your writers are not using generative AI tools
    to create content and then calling it their own work. As we discussed in [Chapter 3](ch03.html#ch03_getting_started_with_generative_ai_1748358214007893),
    you run the risk that writers won’t do a great job of reviewing the content for
    errors, omissions, copyright infringement, and the like. There are many tools
    out there for checking if the content has been written by AI, such as Copyleaks
    and ZeroGPT. See [“AI-Detection Tools”](ch03.html#ch03_ai_detection_tools_1748358214008704)
    for a longer list.
  prefs: []
  type: TYPE_NORMAL
- en: Warning
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We should note that tools that check content to see if it was written by AI
    can be notoriously inaccurate. As a matter of fact, AI-generation checkers say
    that the [US Constitution was written by AI](https://oreil.ly/6sYiP). Nevertheless,
    you should perform these checks as they may flag some issues. Be aware that they
    will also sometimes flag content that was not written by AI and say that it was.
    So treat the output of these tools as directionally correct, but have humans verify
    their assessments.
  prefs: []
  type: TYPE_NORMAL
- en: Have editors on your staff review the work of your writers to look for other
    issues indicating that writers may be taking excessive shortcuts using generative
    AI to create content. If you have the development capacity, the best way to guarantee
    that content is original is to use a CMS (or equivalent technology) that requires
    writers to write in the tool, without copying and pasting from external documents.
    You can then employ keystroke biometrics algorithms or tools like [TypingDNA](https://oreil.ly/ugIvQ)
    or [Typing AI](http://typing.ai) that fingerprint the writer’s speed and keystroke
    dynamics to make sure they are doing original work.
  prefs: []
  type: TYPE_NORMAL
- en: AI-generated content takes input from other sources, but it can be used to create
    unique content when summarizing something that a person has written. Citing sources
    will give proper credit to the original author. LLMs now include links to original
    sources so that you can give attribution when posting content to your site.
  prefs: []
  type: TYPE_NORMAL
- en: Originality checkers still can’t identify AI-generated content with 100% accuracy,
    but using them will help flag potential plagiarism and AI-generated content to
    verify that your writers aren’t using AI. For all AI-generated content, you should
    have a human editor check it for errors, omissions, and awkward wording.
  prefs: []
  type: TYPE_NORMAL
- en: 'Automation Complacency: You Can’t “Set It and Forget It”'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AI is a powerful automation tool. We discussed some automation use cases in
    [Chapter 6](ch06.html#ch06_advanced_use_cases_for_generative_ai_in_seo_1748359259642070).
    You can perform so much with AI—either with external tools that work with AI (e.g.,
    Google Analytics) or by building your own tools. For example, you might use AI
    in Microsoft Excel macros to gather data and create descriptions or identify trends.
    You can do a lot with AI that gives you a competitive edge, such as day-to-day
    automated information about competitor rankings or a gap analysis between a competitor’s
    ranking and their published content versus your own published content.
  prefs: []
  type: TYPE_NORMAL
- en: Automating in SEO with AI is essential for efficiency, but AI changes rapidly
    (primarily due to the extremely high pace of innovation in AI and its popularity).
    As more bugs and innovations are introduced, AI companies will adapt and offer
    new models that provide significantly better results. [Chapter 2](ch02.html#ch02_essential_background_on_generative_ai_1748358211788823)
    covers the evolution of popular models, and there will likely be another iteration
    soon after the release of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Changes to AI should benefit users, including SEO executives, but you should
    ensure that your automation scripts take these changes into account. AI automation
    should be consistently reviewed for any industry changes that could affect accuracy
    in output. For example, Google struck a [$60 million deal](https://oreil.ly/Yltl0)
    with Reddit to use Reddit content to help train its generative AI tools. Reddit
    has millions of users, and Gemini can benefit from the human-generated content.
    If you have any kind of automation based on content generation by Gemini, the
    changes to Reddit and its content “tone” can dramatically influence the type of
    content created from it. This tone and messaging could diverge from your internal
    policies, product voice, or audience concerns.
  prefs: []
  type: TYPE_NORMAL
- en: Another common automation opportunity is using AI for competitor analysis or
    backlink opportunities. Both can take hours out of a single SEO practitioner’s
    time, so using AI greatly reduces overhead without eliminating essential research.
    Using automation, you can scan competitors’ links, review their latest content
    strategies, get a list of their backlinks, and apply this research to building
    your own strategies. It might even give you insight into your competitors’ seasonal
    habits and product launches. AI models and products continually change, and in
    doing so they affect your reports. Your SEO team will still need to review this
    work for accuracy, but it can significantly speed up the process of doing the
    work.
  prefs: []
  type: TYPE_NORMAL
- en: However, if you do not update your own scripts and monitor the results, you
    could be skewing results unknowingly. In a scenario where you use generative AI
    for competitor analysis, perhaps it picks up new domains that weren’t being analyzed
    before, or changes to a site aren’t being used in current models. This scenario
    again represents the need to always work with human reviewers for generative AI
    output. Human reviewers can check for inaccuracies and awkward word choices, and
    they can edit content to have a more conversational tone. Small changes from human
    reviewers can make content much more engaging to readers and avoid inaccuracies.
    The same is true for any automation tools used in critical research and reporting.
  prefs: []
  type: TYPE_NORMAL
- en: If you fall into the trap of “set it and forget it,” you will eventually generate
    low-quality content at scale, or you will mistakenly target queries that could
    be too costly for their ROI. Let’s say that you create content based on the top
    three ranking competitors. Your AI automation may scan competitor pages, extract
    keywords, and create content based on a gap analysis. But it likely won’t fully
    understand the context of what pages it makes sense to create.
  prefs: []
  type: TYPE_NORMAL
- en: For example, what if Google’s AIOs take a majority of screen real estate on
    mobile, so users are forced to scroll a long way to see the search listing for
    your site? Users may not want to look that far. In addition, the AIO may answer
    the question well enough that users don’t bother to scroll down the page.
  prefs: []
  type: TYPE_NORMAL
- en: If you generate a large number of articles based on a single gap analysis, you
    might be deploying content for a query that will never result in a positive ROI.
    For example, if you use Google Analytics to track traffic and engagement, you
    might notice much fewer clicks on your call to action or fewer organic search
    visitors. It can be costly if you have infrastructure and other expensive events
    (e.g., API queries from third-party vendors) without a return on your investment.
    This is one example of why you should always review automation and never inherently
    trust it even if the AI results are correct for most of your automated events.
  prefs: []
  type: TYPE_NORMAL
- en: 'The SEO Nightmare: Losing Search Engine Rank or Google Penalties'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Losing rankings (or receiving a manual penalty) is the bane of an SEO practitioner’s
    existence. These downfalls occur quickly, and fixing the issue can require months
    of work. Some sites never fully recover. To avoid this nightmare, SEO practitioners
    strive to follow Google’s guidelines while still breaking barriers with unique
    and innovative strategies to help their brand.
  prefs: []
  type: TYPE_NORMAL
- en: Losing rankings and Google penalties are two separate phenomena. *Losing rankings*
    means you have negative factors affecting algorithmic trust and quality signals.
    A *penalty* is manual action on your site meant to keep your site from ranking
    well. Both are difficult to fix, but they require two separate strategies. Losing
    rankings requires reviewing your site for low-quality signals and technical issues,
    but a penalty means that a serious violation of Google’s policies must be remedied.
  prefs: []
  type: TYPE_NORMAL
- en: Google wants to integrate generative AI into the search results, but it also
    knows that human users must be satisfied with the search results. A poor user
    experience would push users to Google’s competitors like Bing and other LLMs with
    a direct answer, and this would destroy brand reputation for Google’s dominant
    search engine. Contrasting with this is the existence of market pressures caused
    by the massive buzz around generative AI. If Google isn’t seen as a leader in
    this area, this could directly affect its overall reputation as the technology
    leader in search. It’s a confusing conflict of interest for SEO practitioners
    who might assume that anything AI is looked on favorably by Google engineers.
  prefs: []
  type: TYPE_NORMAL
- en: Then there is the matter of how Google views AI-generated content. In February
    2023, Google released [guidance on AI-generated content](https://oreil.ly/F1VP0)
    indicating that its main concern with content was its quality, not whether it
    was written by AI. However, Google knows content created by generative AI doesn’t
    offer any unique value beyond what is already contained on the web and is often
    of poor quality unless it’s heavily edited by a human SME. Yet many sites will
    go ahead and publish content written by generative AI without such review. For
    that reason, Google may try to detect AI-generated content, and it’s likely that
    Google has AI-detection tools that are more advanced than the tools that are currently
    commercially available in the market.
  prefs: []
  type: TYPE_NORMAL
- en: For example, in March 2024 Google announced [a new update to its core search
    functionality](https://oreil.ly/PvyjN), promising that less “spammy” content would
    be released. Rollouts happened in May 2024, and many SEO practitioners who did
    not heed the warning saw a penalty in their Search Console. The penalty mentioned
    “spammy” content, and SEO practitioners with poor-quality, AI-generated content
    experienced a massive drop in search visibility.
  prefs: []
  type: TYPE_NORMAL
- en: Despite the risks, most of [Google’s announcements at its Google I/O conference
    in 2024](https://oreil.ly/hrds3) focused on AI because that is the hot new technology
    area. Google had AI for video, text, art, scripting, storytelling, health, and
    science. Everything in Google I/O had an element of AI to it, but the search engine
    engineers emphasized the importance of user engagement. Suffice to say that Google
    supports generative AI, but site owners must maintain quality content, even if
    it’s generated by AI. Google’s search engine users are most important to Google’s
    growth and sustainability. Therefore, SEO practitioners should have human reviewers
    for all content uploaded to their sites.
  prefs: []
  type: TYPE_NORMAL
- en: Compliance and Changes in Regulations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The introduction of ChatGPT in 2023 brought AI to the forefront as the next
    “must-have” technology. AI has received a lot of attention from media outlets,
    SEO practitioners, marketing people, and businesses looking to leverage it for
    their own benefit. Governments took notice and are coming up with ways to mitigate
    risks and oversee ethics and legal compliance related to data usage and AI-generated
    content.
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing, the EU had passed [the AI Act](https://oreil.ly/c4ST6)
    to oversee the creation of AI products and the ethics behind services. The AI
    Act focuses on accountability and transparency for technology involved in AI.
    The US will likely follow suit with [state-level regulations](https://oreil.ly/-mL_h).
    For example, Vermont created a [Division of Artificial Intelligence](https://oreil.ly/SGqan)
    to identify the ways AI affects Vermont residents. Future regulations in other
    states are highly probable.
  prefs: []
  type: TYPE_NORMAL
- en: Because AI integration is relatively new, regulations are still in their infancy
    and will likely develop rapidly. What regulations look like will change as AI
    evolves. It’s important to keep notified of the latest regulations surrounding
    AI and your industry. Some regulations will be specific to your organization or
    clients. For example, there is likely to be more regulation overseeing health
    care as AI is introduced to health care Internet of Things, patient diagnosis,
    and tools used for treatments. This is just one example, but any industry looking
    to integrate AI will likely run into compliance issues and regulations to oversee
    the way AI can be marketed and used. To ensure compliance, you can hire consultants
    to audit your environment and text for any privacy or regulation concerns. If
    your business supports multiple countries, you might need auditors with knowledge
    of EU or other country regulations.
  prefs: []
  type: TYPE_NORMAL
- en: 'Removing Bias: Human Emotions Are Not Objective'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: For AI to be effective, you need it to be neutral, bipartisan, and unbiased.
    *Bias* is a phenomenon in AI where output takes stereotypes or human subjectivity
    into account. It usually focuses on human biases, but bias can take different
    forms. For example, if you want to determine if someone should be accepted for
    a home loan, AI should not take race or religion into consideration even if this
    information is a part of the dataset. An SEO practitioner generating content for
    a site needs to ensure that output does not have bias. Bias is difficult to avoid
    because it’s human nature to inject our own experiences and opinions into content.
    A second human review can help avoid publishing content with bias.
  prefs: []
  type: TYPE_NORMAL
- en: Most people watch for human bias and demographic stereotypes. Bias in AI can
    be a compliance issue, so it can result in monetary fines for certain businesses
    if it isn’t caught before decision making. As an example, US financial loan regulations
    specify the types of data that cannot be included in prediction analysis for mortgage
    approvals. Should an SEO practitioner unknowingly use this type of data to market
    or falsely advertise, that could lead to potential legal troubles.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at the results from a query in ChatGPT. The query asks, “What is
    the best security tool?” This question is likely too open for generative AI, but
    you might be creating a draft article for a cybersecurity company to compare some
    tools and drive search engine traffic to your site. OpenAI, the vendor for ChatGPT,
    is partnered with Microsoft. Microsoft has invested more than [$13 billion](https://oreil.ly/CxLlb)
    in OpenAI since its partnership in 2019\. It should be no surprise, then, when
    ChatGPT has biased output favoring Microsoft-based tools, as can be seen in [Figure 7-7](#ch07_figure_7_1748358220824797).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ugai_0707.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-7\. ChatGPT 4.0 output for the query “What is the best security tool?”
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Bias is difficult to identify, especially when it’s an unknown bias injected
    into data used for generative AI. You should run tests on your own output and
    have human reviewers validate your results. Data should be diverse, but this step
    also assumes that you are building your own tools. For smaller businesses, having
    a development team isn’t always feasible, but you should manually audit generative
    AI output to identify any potential bias flaws. For most businesses, building
    your own LLM is out of budget, but you can build a knowledge base from preexisting
    LLMs. It also helps to use trusted data sources. For example, the CIA offers [*The
    World Factbook*](https://oreil.ly/9LdDT) to help data scientists and businesses
    collect accurate, unbiased data on some topics.
  prefs: []
  type: TYPE_NORMAL
- en: In most SEO environments, you don’t control the data, but you can control the
    output. It’s best to have a second person review your results or compare them
    against results from other tools. Not only can multiple result sets help you identify
    bias, but they can also help optimize your reporting. For example, you might discover
    better backlinking opportunities from one tool’s results as compared with another
    tool’s. As we have mentioned several times before, AI cannot replace human critical
    thinking, so your output should always be monitored and reviewed to ensure that
    you have the best results for your sites.
  prefs: []
  type: TYPE_NORMAL
- en: Theft of Intellectual Property
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A challenge in the digital landscape is the difficulty controlling who can access
    your intellectual property, particularly sophisticated AI bots designed to scrape
    the internet and steal content. While preventing such activity is often impossible,
    SEO practitioners should be aware of this threat, especially when it comes to
    protecting their brand’s reputation.
  prefs: []
  type: TYPE_NORMAL
- en: Content theft can negatively affect your SEO efforts in several ways. For example,
    a malicious actor might republish your content on their own site in the hopes
    of ranking for your target keywords. A copycat site could use your brand’s reputation
    to fraudulently sell products and services, stealing your revenue. One way to
    combat this is to use AI to help you monitor the web to detect content theft.
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI introduces new dimensions to content theft. Malicious actors can
    now leverage tools to not just copy but also re-create and repurpose your content
    in ways that may be harder to detect and combat. In the US, you can always try
    reporting the problem to the National Intellectual Property Rights Coordination
    Center, but this is a manual process, and having to report each incident can become
    an overwhelming task.
  prefs: []
  type: TYPE_NORMAL
- en: Then there is the flip side of the coin—if you are using AI to generate logos,
    characters, and images, make sure that the content created does not accidentally
    infringe on a trademark.
  prefs: []
  type: TYPE_NORMAL
- en: Impact of AI Limitations on SEO
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Google has always pushed quality over quantity, but generative AI has made quantity
    much more attainable. [A study by WebFX on generative AI and its impact on search
    ranking](https://oreil.ly/yVsdZ) highlights the advantages and disadvantages of
    content generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Advantages:'
  prefs: []
  type: TYPE_NORMAL
- en: Content creation is more efficient and faster, even with a human editor involved.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Content creation is more cost-effective without the time and human resources
    needed to generate new ideas and content.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can generate content ideas continuously rather than relying on human research.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can pool research and fact-checking into a single location.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Disadvantages:'
  prefs: []
  type: TYPE_NORMAL
- en: There is no personal touch. In human-written content, personal experiences and
    anecdotes often help engage readers. AI-generated content has none of these traits
    and can sound robotic.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s important to fact-check and review all AI-generated content to avoid errors.
    Error by omission is also a common disadvantage, meaning content might be technically
    accurate in what it says but a lack of context or additional information makes
    the statement misinformation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative AI models are trained on current data, so the content created is
    on evergreen knowledge. You won’t get any current news or new information that
    the model has not been trained on. Models are trained only a few times a year,
    so information might be outdated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The WebFX case study indicates that AI-generated content could harm ranking,
    especially if your pages are already ranking. The example given was a lawn care
    site already ranking for targeted keywords. AI-generated content was added to
    the site, but it was regurgitated information already on the web. Pages with AI-generated
    content not only saw minimal traffic but eventually lost 100% of their ranking
    after a short time.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to remember that Google hires contractors to review ranking pages.
    Google asks contractors to evaluate the [EEAT of content](https://oreil.ly/Lo1fr),
    which means that content must display experience, expertise, authoritativeness,
    and trustworthiness. The same WebFX study said that a financial site with mostly
    AI-generated content saw a 99.3% drop in ranking after the November 2023 EEAT
    core update. AI-generated content doesn’t usually exhibit strong EEAT, so have
    your human editors determine if content could be considered high quality based
    on EEAT.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we went over how you can overcome some of the common pitfalls
    when using AI. Succumbing to these risks can have devastating effects on your
    brand and revenue. Here’s a brief recap:'
  prefs: []
  type: TYPE_NORMAL
- en: Low-quality content
  prefs: []
  type: TYPE_NORMAL
- en: Whether it’s generating images, video or text, AI has its limitations, and a
    human reviewer should be injected into your procedures to ensure content quality.
    The main risk of poor generative AI strategies is low-quality content. It might
    not seem like the worst risk, but the consequences can be significant (e.g., loss
    of search rank or search engine penalties, which both result in fewer sales).
  prefs: []
  type: TYPE_NORMAL
- en: Copyright and plagiarism
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI platforms ingest data from the internet, so output can be too
    similar to the original content. Several ethical and legal issues stem from this
    challenge.
  prefs: []
  type: TYPE_NORMAL
- en: Automation complacency
  prefs: []
  type: TYPE_NORMAL
- en: Automation is one of AI’s greatest benefits, but it’s not a “set it and forget
    it” application. We discussed SEO automation in [Chapter 6](ch06.html#ch06_advanced_use_cases_for_generative_ai_in_seo_1748359259642070).
    AI results must be constantly reviewed by humans, regardless of whether you use
    it for just a few pieces of content or you deploy it at scale.
  prefs: []
  type: TYPE_NORMAL
- en: Google authority loss and penalties
  prefs: []
  type: TYPE_NORMAL
- en: User experience is key to following Google’s search engine guidelines and ranking
    well, but analysis shows that AI-produced content published without detailed human
    review results in poor user experiences and can cause your search rankings to
    plummet.
  prefs: []
  type: TYPE_NORMAL
- en: Compliance
  prefs: []
  type: TYPE_NORMAL
- en: 'Is the content output compliant with local and federal laws? The EU passed
    the AI Act, which aims to regulate AI and its products. The AI Act focuses on
    two concerns: it bans social scoring similar to China’s social scoring system,
    and it regulates CV (resume) ranking tools, which must follow strict regulations.
    US regulations are soon to follow.'
  prefs: []
  type: TYPE_NORMAL
- en: Biases
  prefs: []
  type: TYPE_NORMAL
- en: For large agencies or businesses with the staff to create their own models and
    tools, it’s critical that output is tested for any biases that can creep into
    your content and cause issues with readers and local laws. For example, feed ChatGPT
    the query “Should marijuana be fully legalized nationwide in the US?” and notice
    that the response doesn’t give you a direct answer.
  prefs: []
  type: TYPE_NORMAL
- en: Theft of intellectual property
  prefs: []
  type: TYPE_NORMAL
- en: An uncontrollable but related issue is the use of AI to bypass common blocks
    (e.g., *robots.txt*) on traffic or bots used to steal your intellectual property.
    For example, if you use *robots.txt* to block traffic, you have no guarantee that
    crawlers will honor it. After stealing your content, AI can be used to create
    intellectual property like your own without detection.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is meant to inform rather than deter. You need to know what to
    avoid and integrate these challenges into your SEO strategies. These challenges
    also shape the future of AI, how it will evolve, and the regulations surrounding
    it. The next chapter will cover the future of AI and SEO and what you can look
    forward to (or possibly avoid) as you continue using it.
  prefs: []
  type: TYPE_NORMAL
