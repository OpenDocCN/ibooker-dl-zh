- en: Chapter 2\. Getting Started
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we cover what you need to know to begin building and modifying
    machine learning applications on low-power devices. All the software is free,
    and the hardware development kits are available for less than $30, so the biggest
    challenge is likely to be the unfamiliarity of the development environment. To
    help with that, throughout the chapter we recommend a well-lit path of tools that
    we’ve found work well together.
  prefs: []
  type: TYPE_NORMAL
- en: Who Is This Book Aimed At?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To build a TinyML project, you will need to know a bit about both machine learning
    and embedded software development. Neither of these are common skills, and very
    few people are experts on both, so this book will start with the assumption that
    you have no background in either of these. The only requirements are that you
    have some familiarity running commands in the terminal (or Command Prompt on Windows),
    and are able to load a program source file into an editor, make alterations, and
    save it. Even if that sounds daunting, we walk you through everything we discuss
    step by step, like a good recipe, including screenshots (and screencasts online)
    in many cases, so we’re hoping to make this as accessible as possible to a wide
    audience.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll show you some practical applications of machine learning on embedded devices,
    using projects like simple speech recognition, detecting gestures with a motion
    sensor, and detecting people with a camera sensor. We want to get you comfortable
    with building these programs yourself, and then extending them to solve problems
    you care about. For example, you might want to modify the speech recognition to
    detect barks instead of human speech, or spot dogs instead of people, and we give
    you ideas on how to tackle those modifications yourself. Our goal is to provide
    you with the tools you need to start building exciting applications you care about.
  prefs: []
  type: TYPE_NORMAL
- en: What Hardware Do You Need?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You’ll need a laptop or desktop computer with a USB port. This will be your
    main programming environment, where you edit and compile the programs that you
    run on the embedded device. You’ll connect this computer to the embedded device
    using the USB port and a specialized adapter that will depend on what development
    hardware you’re using. The main computer can be running Windows, Linux, or macOS.
    For most of the examples we train our machine learning models in the cloud, using
    [Google Colab](https://oreil.ly/AQYDz), so don’t worry about having a specially
    equipped computer.
  prefs: []
  type: TYPE_NORMAL
- en: You will also need an embedded development board to test your programs on. To
    do something interesting you’ll need a microphone, accelerometers, or a camera
    attached, and you want something small enough to build into a realistic prototype
    project, along with a battery. This was tough to find when we started this book,
    so we worked together with the chip manufacturer Ambiq and maker retailer SparkFun
    to produce the [$15 SparkFun Edge board](https://oreil.ly/-hoL-). All of the book’s
    examples will work with this device.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The second revision of the SparkFun Edge board, the SparkFun Edge 2, is due
    to be released after this book has been published. All of the projects in this
    book are guaranteed to work with the new board. However, the code and the instructions
    for deployment will vary slightly from what is printed here. Don’t worry—each
    project chapter links to a *README.md* that contains up-to-date instructions for
    deploying each example to the SparkFun Edge 2.
  prefs: []
  type: TYPE_NORMAL
- en: We also offer instructions on how to run many of the projects using the Arduino
    and Mbed development environments. We recommend the [Arduino Nano 33 BLE Sense](https://oreil.ly/4sER2)
    board, and the [STM32F746G Discovery kit](https://oreil.ly/vKyOM) development
    board for Mbed, though all of the projects should be adaptable to other devices
    if you can capture the sensor data in the formats needed. [Table 2-1](#table21)
    shows which devices we’ve included in each project chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2-1\. Devices written about for each project
  prefs: []
  type: TYPE_NORMAL
- en: '| Project name | Chapter | SparkFun Edge | Arduino Nano 33 BLE Sense | STM32F746G
    Discovery kit |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Hello world | [Chapter 5](ch05.xhtml#chapter_building_an_application) | Included
    | Included | Included |'
  prefs: []
  type: TYPE_TB
- en: '| Wake-word detection | [Chapter 7](ch07.xhtml#chapter_speech_wake_word_example)
    | Included | Included | Included |'
  prefs: []
  type: TYPE_TB
- en: '| Person detection | [Chapter 9](ch09.xhtml#chapter_person_detection_example)
    | Included | Included | Not included |'
  prefs: []
  type: TYPE_TB
- en: '| Magic wand | [Chapter 11](ch11.xhtml#chapter_magic_wand_application) | Included
    | Included | Not included |'
  prefs: []
  type: TYPE_TB
- en: None of these projects require any additional electronic components, aside from
    person detection, which requires a camera module. If you’re using the Arduino,
    you’ll need the [Arducam Mini 2MP Plus](https://oreil.ly/8EacT). And you’ll need
    SparkFun’s [Himax HM01B0 breakout](https://oreil.ly/Kb0lI) if you’re using the
    SparkFun Edge.
  prefs: []
  type: TYPE_NORMAL
- en: What Software Do You Need?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All of the projects in this book are based around the TensorFlow Lite for Microcontrollers
    framework. This is a variant of the TensorFlow Lite framework designed to run
    on embedded devices with only a few tens of kilobytes of memory available. All
    of the projects are included as examples in the library, and it’s open source,
    so you can find it [on GitHub](https://oreil.ly/TQ4CC).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Since the code examples in this book are part of an active open source project,
    they are continually changing and evolving as we add optimizations, fix bugs,
    and support additional devices. It’s likely you’ll spot some differences between
    the code printed in the book and the most recent code in the TensorFlow repository.
    That said, although the code might drift a little over time, the basic principles
    you’ll learn here will remain the same.
  prefs: []
  type: TYPE_NORMAL
- en: You’ll need some kind of editor to examine and modify your code. If you’re not
    sure which one you should use, Microsoft’s free [VS Code](https://oreil.ly/RNus3)
    application is a great place to start. It works on macOS, Linux, and Windows,
    and has a lot of handy features like syntax highlighting and autocomplete. If
    you already have a favorite editor you can use that, instead; we won’t be doing
    extensive modifications for any of our projects.
  prefs: []
  type: TYPE_NORMAL
- en: You’ll also need somewhere to enter commands. On macOS and Linux this is known
    as the terminal, and you can find it in your Applications folder under that name.
    On Windows it’s known as the Command Prompt, which you can find in your Start
    menu.
  prefs: []
  type: TYPE_NORMAL
- en: There will also be extra software that you’ll need to communicate with your
    embedded development board, but this will depend on what device you have. If you’re
    using either the SparkFun Edge board or an Mbed device, you’ll need to have Python
    installed for some build scripts, and then you can use GNU Screen on Linux or
    macOS or [Tera Term](https://oreil.ly/oDOKn) on Windows to access the debug logging
    console, showing text output from the embedded device. If you have an Arduino
    board, everything you need is installed as part of the IDE, so you just need to
    download the main software package.
  prefs: []
  type: TYPE_NORMAL
- en: What Do We Hope You’ll Learn?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The goal of this book is to help more applications in this new space emerge.
    There is no one “killer app” for TinyML right now, and there might never be, but
    we know from experience that there are a lot of problems out there in the world
    that can be solved using the toolbox it offers. We want to familiarize you with
    the possible solutions. We want to take domain experts from agriculture, space
    exploration, medicine, consumer goods, and any other areas with addressable issues
    and give them an understanding of how to solve problems themselves, or at the
    very least communicate what problems are solvable with these techniques.
  prefs: []
  type: TYPE_NORMAL
- en: With that in mind, we’re hoping that when you finish this book you’ll have a
    good overview of what’s currently possible using machine learning on embedded
    systems at the moment, as well as some idea of what’s going to be feasible over
    the next few years. We want you to be able to build and modify some practical
    examples using time-series data like audio or input from accelerometers, and for
    low-power vision. We’d like you to have enough understanding of the entire system
    to be able to at least participate meaningfully in design discussions with specialists
    about new products and hopefully be able to prototype early versions yourself.
  prefs: []
  type: TYPE_NORMAL
- en: Since we want to see complete products emerge, we approach everything we’re
    discussing from a whole-system perspective. Often hardware vendors will focus
    on the energy consumption of the particular component they’re selling, but not
    consider how other necessary parts increase the power required. For example, if
    you have a microcontroller that consumes only 1 mW, but the only camera sensor
    it works with takes 10 mW to operate, any vision-based product you use it on won’t
    be able to take advantage of the processor’s low energy consumption. This means
    that we won’t be doing many deep dives into the underlying workings of the different
    areas; instead, we focus on what you need to know to use and modify the components
    involved.
  prefs: []
  type: TYPE_NORMAL
- en: For example, we won’t linger on the details of what is happening under the hood
    when you train a model in TensorFlow, such as how gradients and back-propagation
    work. Rather, we show you how to run training from scratch to create a model,
    what common errors you might encounter and how to handle them, and how to customize
    the process to build models to tackle your own problems with new datasets.
  prefs: []
  type: TYPE_NORMAL
