["```py\nproject/\n│\n├── host.json\n├── main.py\n├── app.py\n└── requirements.txt\n```", "```py\n$ pip install azure-functions\n```", "```py\n{\n  \"version\": \"2.0\",\n  \"extensions\": {\n    \"http\": {\n        \"routePrefix\": \"\"\n    }\n  }\n}\n```", "```py\n# app.py\n\nimport azure.functions as func\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.post(\"/generate/text\", response_model_exclude_defaults=True)\nasync def serve_text_to_text_controller(prompt):\n...\n```", "```py\n# function.py\n\nimport azure.functions as func\nfrom main import app as fastapi_app\n\napp = func.AsgiFunctionApp(\n    app=fastapi_app, http_auth_level=func.AuthLevel.ANONYMOUS\n)\n```", "```py\n$ func start\n\n>> Found the following functions:\n>> Functions:\n>>        http_app_func: [GET,POST,DELETE,HEAD,PATCH,PUT,OPTIONS] \\\n                          http://localhost:7071//{*route}\n\n>> Job host started\n```", "```py\nhttp://localhost:7071/generate/text\nhttp://localhost:7071/<other-paths>\n```", "```py\n$ func azure functionapp publish <FunctionAppName>\n```", "```py\nhttp://<FunctionAppName>.azurewebsites.net/generate/text\nhttp://<FunctionAppName>.azurewebsites.net/<other-paths>\n```", "```py\n# main.py\n\nfrom fastapi import FastAPI\nfrom models import generate_text ![1](assets/1.png)\n\napp = FastAPI()\n\n@app.post(\"/generate\")\ndef generate_text(prompt: str):\n    return generate_text(prompt)\n```", "```py\nARG PYTHON_VERSION=3.12\nFROM python:${PYTHON_VERSION}-slim as base ![1](assets/1.png)\n\nWORKDIR /code ![2](assets/2.png)\n\nCOPY requirements.txt . ![3](assets/3.png)\n\nRUN pip install --no-cache-dir --upgrade -r requirements.txt ![4](assets/4.png)\n\nCOPY . . ![5](assets/5.png)\n\nEXPOSE 8000 ![6](assets/6.png)\n\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"] ![7](assets/7.png)\n```", "```py\n$ docker build -t genai-service .\n```", "```py\n$ docker image pull python:3.12-slim\n\nbookworm: Pulling from library/python\nDigest: sha256:3f1d6c17773a45c97bd8f158d665c9709d7b29ed7917ac934086ad96f92e4510\nStatus: Downloaded newer image for python:3.12-slim\ndocker.io/library/python:3.12-slim\n```", "```py\n$ docker build -t genai-service:latest .\n\n$ docker image tag genai-service:latest docker.io/myrepo/genai-service:latest\n```", "```py\n$ docker login\n\n$ docker image push docker.io/myrepo/genai-service:latest\n\n195be5f8be1d: Pushed\n```", "```py\n$ docker volume create -n data\n```", "```py\n$ docker run -v src:/app genai-service\n```", "```py\n$ docker run --tmpfs /cache genai-service\n```", "```py\n$ docker run --user genai-service\n```", "```py\nARG USERNAME=fastapi ![1](assets/1.png)\nARG USER_UID=1001\nARG USER_GID=1002\n\nRUN groupadd --gid $USER_GID $USERNAME \\ ![2](assets/2.png)\n    && adduser \\\n    --disabled-password \\\n    --shell \"/sbin/nologin\" \\ ![3](assets/3.png)\n    --gecos \"\" \\\n    --home \"/nonexistent\" \\\n    --no-create-home \\ ![4](assets/4.png)\n    --uid \"${UID}\" \\\n    --gid $USER_GID\n    $USERNAME ![5](assets/5.png)\n\nUSER $USERNAME ![6](assets/6.png)\n\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n```", "```py\ntotal 12\ndrw-r--r-- 2 root root 4096 Oct  1 10:00 myscripts\n```", "```py\n# Set file or directory ownership\n$ sudo chown -R username:groupname mydir\n```", "```py\n# Set execute permissions using flags\n$ sudo chmod -R +x myscripts\n\n# Set execute permissions in a numeric form\n$ sudo chmod -R 755 myscripts\n```", "```py\ntotal 12\ndrwxr-xr-x 2 root root 4096 Oct  1 10:00 myscripts\n```", "```py\nRUN mkdir -p scripts\n\nCOPY scripts scripts\n\nRUN chmod -R +x scripts\n```", "```py\n$ docker network ls\nNETWORK ID     NAME      DRIVER    SCOPE\n72ec0b2e6034   bridge    bridge    local\n53ec40b3c639   host      host      local\n64368b7baa5f   none      null      local\n```", "```py\n$ docker network create genai-net\n```", "```py\n$ docker network ls\nNETWORK ID     NAME         DRIVER    SCOPE\n72ec0b2e6034   bridge       bridge    local\n6aa21632e77e   genai-net    bridge    local\n```", "```py\n$ docker run --network genai-net genai-service\n$ docker run --network genai-net postgresql\n```", "```py\n$ docker run -p 127.0.0.1:8000:8000 myimage\n```", "```py\n$ docker run --net=host genai-service\n```", "```py\n$ docker run --network none genai-service\n```", "```py\n$ docker run --rm -it \\\n             --gpus=all nvcr.io/nvidia/k8s/cuda-sample:nbody nbody \\\n             -gpu \\\n             -benchmark\n\n> Windowed mode\n> Simulation data stored in video memory\n> Single precision floating point simulation\n> 1 Devices used for simulation\nMapSMtoCores for SM 8.9 is undefined.  Default to use 128 Cores/SM\nMapSMtoArchName for SM 8.9 is undefined.  Default to use Ampere\nGPU Device 0: \"Ampere\" with compute capability 8.9\n\n> Compute 8.9 CUDA device: [NVIDIA GeForce RTX 4090]\n131072 bodies, total time for 10 iterations: 75.182 ms\n= 2285.102 billion interactions per second\n= 45702.030 single-precision GFLOP/s at 20 flops per interaction\n```", "```py\n$ pip install accelerate\n```", "```py\nfrom transformers import pipeline\n\npipe = pipeline(\n    \"text-generation\",\n    model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n    device_map=\"cuda\"\n)\n```", "```py\n# compose.yaml\n\nservices: ![1](assets/1.png)\n  server:\n    build: . ![2](assets/2.png)\n    ports:\n      - \"8000:8000\"\n    environment:\n      SHOW_DOCS_IN_PRODUCTION: $SHOW_DOCS_IN_PRODUCTION\n      ALLOWED_CORS_ORIGINS: $ALLOWED_CORS_ORIGINS\n    secrets:\n       - openai_api_token ![3](assets/3.png)\n    volumes:\n      - ./src/app:/code/app\n    networks:\n      - genai-net ![4](assets/4.png)\n\n  db:\n    image: postgres:12.2-alpine\n    ports:\n      - \"5433:5432\"\n    volumes:\n      - db-data:/etc/data\n    networks:\n      - genai-net\n\nvolumes:\n  db-data:\n    name: \"my-app-data\"\n\nnetworks:\n  genai-net:\n    name: \"genai-net\"\n    driver: bridge\n\nsecrets:\n  openai_api_token:\n    environment: OPENAI_API_KEY\n```", "```py\n# Start services defined in compose.yaml\n$ docker compose up\n\n# Stop and remove running services (won't remove created volumes and networks)\n$ docker compose down\n\n# Monitor output of running containers\n$ docker compose logs\n\n# List all running services with their status\n$ docker compose ps\n```", "```py\nservices:\n  server:\n    # ...\n    develop:\n      watch:\n        - action: sync\n          path: ./src\n          target: /code\n```", "```py\n$ docker compose watch\n\n[+] Running 2/2\n ✔ Container project-server-1  Created     0.0s\n ✔ Container project-db-1      Recreated   0.1s\nAttaching to db-1, server-1\n         ⦿ watch enabled\n...\n```", "```py\n# compose.yml\n\nservices: ![1](assets/1.png)\n  server:\n      ports:\n        - 8000:8000\n      # ...\n      command: uvicorn main:app\n\n# compose.override.yml\n\nservices: ![2](assets/2.png)\n  server:\n    environment:\n      - LLM_API_KEY=$LLM_API_KEY\n      - DATABASE_URL=$DATABASE_URL\n    volumes:\n      - ./code:/code\n    command: uvicorn main:app --reload\n\n  database:\n    image: postgres:latest\n    environment:\n      - POSTGRES_DB=genaidb\n      - POSTGRES_USER=genaiuser\n      - POSTGRES_PASSWORD=secretPassword!\n    volumes:\n      - db_data:/var/lib/postgresql/data\n\nnetworks:\n  app-network:\n\nvolumes:\n  db_data:\n```", "```py\n$ docker compose up\n```", "```py\nservices:\n  app:\n    # ...\n    deploy:\n      resources:\n        reservations:\n          devices:\n            - driver: nvidia\n              count: 1 ![1](assets/1.png)\n              capabilities: [gpu]\n```", "```py\n$ docker image ls\n\nREPOSITORY  TAG         IMAGE ID       CREATED         SIZE\nalpine      3.20        3463e98c969d   4 weeks ago     12.1MB\npython      3.12-alpine c6de2e87f545   6 days ago      71.4MB\npython      3.12-slim   1ba4bc34383e   6 days ago      186MB\n```", "```py\n$ pip install transformers[onnx]\n```", "```py\n$ python -m transformers.onnx --model=distilbert/distilbert-base-uncased onnx/\n```", "```py\nfrom onnxruntime import InferenceSession\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased\")\nsession = InferenceSession(\"onnx/model.onnx\")\n\ninputs = tokenizer(\"Using DistilBERT with ONNX Runtime!\", return_tensors=\"np\") ![1](assets/1.png)\noutput = session.run(output_names=[\"last_hidden_state\"], input_feed=dict(inputs))\n```", "```py\nFROM python:3.12-slim as base\n# Changes to the\nCOPY . .\nRUN pip install requirements.txt\n```", "```py\nFROM python:3.12-slim as base\nCOPY requirements.txt requirements.txt\nRUN pip install requirements.txt\nCOPY . .\n```", "```py\nRUN apt-get update && apt-get install -y\n```", "```py\n**/.DS_Store\n**/__pycache__\n**/.mypy_cache\n**/.venv\n**/.env\n**/.git\n```", "```py\nRUN --mount=type=cache,target=/root/.cache/huggingface && \\\n    pip install transformers && \\\n    python -c \"from transformers import AutoModel; \\\n AutoModel.from_pretrained('bert-base-uncased')\"\n```", "```py\ndocker buildx build --cache-from type=registry,ref=user/app:buildcache .\n```", "```py\n# Stage 1: Base\nFROM python:3.11.0-slim as base\n\nRUN python -m venv /opt/venv\nRUN pip install transformers && \\\n    python -c \"from transformers import AutoModel; \\\n AutoModel.from_pretrained('bert-base-uncased')\"\nRUN --mount=type=cache,target=/root/.cache/pip \\\n    --mount=type=bind,source=requirements.txt,target=requirements.txt \\\n    python -m pip install -r requirements.txt\n```", "```py\n# Stage 2: Production\nFROM base as production\nRUN apt-get update && apt-get install -y\nCOPY --from=base /opt/venv /opt/venv\nCOPY --from=base /root/.cache/huggingface /root/.cache/huggingface\n\nWORKDIR /code\nCOPY . .\n\nEXPOSE 8000\n\nENV BUILD_ENV=PROD\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n```", "```py\n# Stage 3: Development\nFROM production as development\n\nCOPY --from=production /opt/venv /opt/venv\nCOPY ./requirements_dev.txt ./\nRUN pip install --no-cache-dir --upgrade -r requirements_dev.txt\n\nENV BUILD_ENV=DEV\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\", \"--reload\"]\n```", "```py\n$ docker init\n>> Answer a few questions in the terminal...\n\nproject/\n│\n├── .dockerignore\n├── compose.yaml\n├── Dockerfile\n└── README.Docker.md\n... # other application files\n```"]