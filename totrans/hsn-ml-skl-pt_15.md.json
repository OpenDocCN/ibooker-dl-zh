["```py\nimport pandas as pd\nfrom pathlib import Path\n\npath = Path(\"datasets/ridership/CTA_-_Ridership_-_Daily_Boarding_Totals.csv\")\ndf = pd.read_csv(path, parse_dates=[\"service_date\"])\ndf.columns = [\"date\", \"day_type\", \"bus\", \"rail\", \"total\"]  # shorter names\ndf = df.sort_values(\"date\").set_index(\"date\")\ndf = df.drop(\"total\", axis=1)  # no need for total, it's just bus + rail\ndf = df.drop_duplicates()  # remove duplicated months (2011-10 and 2014-07)\n```", "```py\n>>> df.head()\n day_type     bus    rail\ndate\n2001-01-01        U  297192  126455\n2001-01-02        W  780827  501952\n2001-01-03        W  824923  536432\n2001-01-04        W  870021  550011\n2001-01-05        W  890426  557917\n```", "```py\nimport matplotlib.pyplot as plt\n\ndf[\"2019-03\":\"2019-05\"].plot(grid=True, marker=\".\", figsize=(8, 3.5))\nplt.show()\n```", "```py\ndiff_7 = df[[\"bus\", \"rail\"]].diff(7)[\"2019-03\":\"2019-05\"]\n\nfig, axs = plt.subplots(2, 1, sharex=True, figsize=(8, 5))\ndf.plot(ax=axs[0], legend=False, marker=\".\")  # original time series\ndf.shift(7).plot(ax=axs[0], grid=True, legend=False, linestyle=\":\")  # lagged\ndiff_7.plot(ax=axs[1], grid=True, marker=\".\")  # 7-day difference time series\nplt.show()\n```", "```py\n>>> list(df.loc[\"2019-05-25\":\"2019-05-27\"][\"day_type\"])\n['A', 'U', 'U']\n```", "```py\n>>> diff_7.abs().mean()\nbus     43915.608696\nrail    42143.271739\ndtype: float64\n```", "```py\n>>> targets = df[[\"bus\", \"rail\"]][\"2019-03\":\"2019-05\"]\n>>> (diff_7 / targets).abs().mean()\nbus     0.082938\nrail    0.089948\ndtype: float64\n```", "```py\nperiod = slice(\"2001\", \"2019\")\ndf_monthly = df.select_dtypes(include=\"number\").resample('ME').mean()\nrolling_average_12_months = df_monthly.loc[period].rolling(window=12).mean()\n\nfig, ax = plt.subplots(figsize=(8, 4))\ndf_monthly[period].plot(ax=ax, marker=\".\")\nrolling_average_12_months.plot(ax=ax, grid=True, legend=False)\nplt.show()\n```", "```py\ndf_monthly.diff(12)[period].plot(grid=True, marker=\".\", figsize=(8, 3))\nplt.show()\n```", "```py\nfrom statsmodels.tsa.arima.model import ARIMA\n\norigin, today = \"2019-01-01\", \"2019-05-31\"\nrail_series = df.loc[origin:today][\"rail\"].asfreq(\"D\")\nmodel = ARIMA(rail_series,\n              order=(1, 0, 0),\n              seasonal_order=(0, 1, 1, 7))\nmodel = model.fit()\ny_pred = model.forecast()  # returns 427,758.6\n```", "```py\norigin, start_date, end_date = \"2019-01-01\", \"2019-03-01\", \"2019-05-31\"\ntime_period = pd.date_range(start_date, end_date)\nrail_series = df.loc[origin:end_date][\"rail\"].asfreq(\"D\")\ny_preds = []\nfor today in time_period.shift(-1):\n    model = ARIMA(rail_series[origin:today],  # train on data up to \"today\"\n                  order=(1, 0, 0),\n                  seasonal_order=(0, 1, 1, 7))\n    model = model.fit()  # note that we retrain the model every day!\n    y_pred = model.forecast().iloc[0]\n    y_preds.append(y_pred)\n\ny_preds = pd.Series(y_preds, index=time_period)\nmae = (y_preds - rail_series[time_period]).abs().mean()  # returns 32,040.7\n```", "```py\nclass TimeSeriesDataset(torch.utils.data.Dataset):\n    def __init__(self, series, window_length):\n        self.series = series\n        self.window_length = window_length\n\n    def __len__(self):\n        return len(self.series) - self.window_length\n\n    def __getitem__(self, idx):\n        if idx >= len(self):\n            raise IndexError(\"dataset index out of range\")\n        end = idx + self.window_length  # 1st index after window\n        window = self.series[idx : end]\n        target = self.series[end]\n        return window, target\n```", "```py\n>>> my_series = torch.tensor([[0], [1], [2], [3], [4], [5]])\n>>> my_dataset = TimeSeriesDataset(my_series, window_length=3)\n>>> for window, target in my_dataset:\n...     print(\"Window:\", window, \" Target:\", target)\n...\nWindow: tensor([[0], [1], [2]])  Target: tensor([3])\nWindow: tensor([[1], [2], [3]])  Target: tensor([4])\nWindow: tensor([[2], [3], [4]])  Target: tensor([5])\n```", "```py\n>>> from torch.utils.data import DataLoader\n>>> torch.manual_seed(0)\n>>> my_loader = DataLoader(my_dataset, batch_size=2, shuffle=True)\n>>> for X, y in my_loader:\n...     print(\"X:\", X, \" y:\", y)\n...\nX: tensor([[[0], [1], [2]], [[2], [3], [4]]])  y: tensor([[3], [5]])\nX: tensor([[[1], [2], [3]]])  y: tensor([[4]])\n```", "```py\nrail_train = torch.FloatTensor(df[[\"rail\"]][\"2016-01\":\"2018-12\"].values / 1e6)\nrail_valid = torch.FloatTensor(df[[\"rail\"]][\"2019-01\":\"2019-05\"].values / 1e6)\nrail_test = torch.FloatTensor(df[[\"rail\"]][\"2019-06\":].values / 1e6)\n```", "```py\nwindow_length = 56\ntrain_set = TimeSeriesDataset(rail_train, window_length)\ntrain_loader = DataLoader(train_set, batch_size=32, shuffle=True)\nvalid_set = TimeSeriesDataset(rail_valid, window_length)\nvalid_loader = DataLoader(valid_set, batch_size=32)\ntest_set = TimeSeriesDataset(rail_test, window_length)\ntest_loader = DataLoader(test_set, batch_size=32)\n```", "```py\nimport torch.nn as nn\nimport torchmetrics\n\ntorch.manual_seed(42)\nmodel = nn.Sequential(nn.Flatten(), nn.Linear(window_length, 1)).to(device)\nloss_fn = nn.HuberLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\nmetric = torchmetrics.MeanAbsoluteError().to(device)\n[...]  # train the PyTorch model (e.g., using train() function from Chapter 10)\n```", "```py\nclass SimpleRnnModel(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.memory_cell = nn.Sequential(\n            nn.Linear(input_size + hidden_size, hidden_size),\n            nn.Tanh()\n        )\n        self.output = nn.Linear(hidden_size, output_size)\n\n    def forward(self, X):\n        batch_size, window_length, dimensionality = X.shape\n        X_time_first = X.transpose(0, 1)\n        H = torch.zeros(batch_size, self.hidden_size, device=X.device)\n        for X_t in X_time_first:\n            XH = torch.cat((X_t, H), dim=1)\n            H = self.memory_cell(XH)\n        return self.output(H)\n\ntorch.manual_seed(42)\nunivar_model = SimpleRnnModel(input_size=1, hidden_size=32, output_size=1)\n```", "```py\nclass SimpleRnnModel(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super().__init__()\n        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n        self.output = nn.Linear(hidden_size, output_size)\n\n    def forward(self, X):\n        outputs, last_state = self.rnn(X)\n        return self.output(outputs[:, -1])\n```", "```py\nself.rnn = nn.RNN(input_size, hidden_size, num_layers=3, batch_first=True)\n```", "```py\ndf_mulvar = df[[\"rail\", \"bus\"]] / 1e6  # use both rail & bus series as input\ndf_mulvar[\"next_day_type\"] = df[\"day_type\"].shift(-1)  # we know tomorrow's type\ndf_mulvar = pd.get_dummies(df_mulvar, dtype=float)  # one-hot encode day type\n```", "```py\nmulvar_train = torch.FloatTensor(df_mulvar[\"2016-01\":\"2018-12\"].values / 1e6)\nmulvar_valid = torch.FloatTensor(df_mulvar[\"2019-01\":\"2019-05\"].values / 1e6)\nmulvar_test = torch.FloatTensor(df_mulvar[\"2019-06\":].values / 1e6)\n```", "```py\nclass MulvarTimeSeriesDataset(TimeSeriesDataset):\n    def __getitem__(self, idx):\n        window, target = super().__getitem__(idx)\n        return window, target[:1]\n```", "```py\nmulvar_train_set = MulvarTimeSeriesDataset(mulvar_train, window_length)\nmulvar_train_loader = DataLoader(mulvar_train_set, batch_size=32, shuffle=True)\n[...]  # create the datasets and data loaders for the validation and test sets\n```", "```py\ntorch.manual_seed(42)\nmulvar_model = SimpleRnnModel(input_size=5, hidden_size=32, output_size=1)\nmulvar_model = mulvar_model.to(device)\n```", "```py\nn_steps = 14\nunivar_model.eval()\nwith torch.no_grad():\n    X = rail_valid[:window_length].unsqueeze(dim=0).to(device)\n    for step_ahead in range(n_steps):\n        y_pred_one = univar_model(X)\n        X = torch.cat([X, y_pred_one.unsqueeze(dim=0)], dim=1)\n\n    Y_pred = X[0, -n_steps:, 0]\n```", "```py\nclass ForecastAheadDataset(TimeSeriesDataset):\n    def __len__(self):\n        return len(self.series) - self.window_length - 14 + 1\n\n    def __getitem__(self, idx):\n        end = idx + self.window_length  # 1st index after window\n        window = self.series[idx : end]\n        target = self.series[end : end + 14, 0]  # 0 = rail ridership\n        return window, target\n```", "```py\nahead_train_set = ForecastAheadDataset(mulvar_train, window_length)\nahead_train_loader = DataLoader(ahead_train_set, batch_size=32, shuffle=True)\n[...]  # create the datasets and data loaders for the validation and test sets\n```", "```py\ntorch.manual_seed(42)\nahead_model = SimpleRnnModel(input_size=5, hidden_size=32, output_size=14)\nahead_model = ahead_model.to(device)\n```", "```py\nahead_model.eval()\nwith torch.no_grad():\n    window = mulvar_valid[:window_length]  # shape [56, 5]\n    X = window.unsqueeze(dim=0)            # shape [1, 56, 5]\n    Y_pred = ahead_model(X.to(device))     # shape [1, 14]\n```", "```py\nclass Seq2SeqDataset(ForecastAheadDataset):\n    def __getitem__(self, idx):\n        end = idx + self.window_length  # 1st index after window\n        window = self.series[idx : end]\n        target_period = self.series[idx + 1 : end + 14, 0]\n        target = target_period.unfold(dimension=0, size=14, step=1)\n        return window, target\n```", "```py\n>>> torch.tensor([0, 1, 2, 3, 4, 5]).unfold(dimension=0, size=4, step=1)\ntensor([[0, 1, 2, 3],\n [1, 2, 3, 4],\n [2, 3, 4, 5]])\n```", "```py\nseq_train_set = Seq2SeqDataset(mulvar_train, window_length)\nseq_train_loader = DataLoader(seq_train_set, batch_size=32, shuffle=True)\n[...]  # create the datasets and data loaders for the validation and test sets\n```", "```py\nclass Seq2SeqRnnModel(SimpleRnnModel):\n    def forward(self, X):\n        outputs, last_state = self.rnn(X)\n        return self.output(outputs)\n\ntorch.manual_seed(42)\nseq_model = Seq2SeqRnnModel(input_size=5, hidden_size=32, output_size=14)\nseq_model = seq_model.to(device)\n```", "```py\nseq_model.eval()\nwith torch.no_grad():\n    some_window = mulvar_valid[:window_length]  # shape [56, 5]\n    X = some_window.unsqueeze(dim=0)            # shape [1, 56, 5]\n    Y_preds = seq_model(X.to(device))           # shape [1, 56, 14]\n    Y_pred = Y_preds[:, -1]                     # shape [1, 14]\n```", "```py\nself.memory_cell = nn.Sequential(\n    nn.Linear(input_size + hidden_size, hidden_size),\n    nn.LayerNorm(hidden_size),\n    nn.Tanh()\n)\n```", "```py\nclass LstmModel(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super().__init__()\n        self.hidden_size = hidden_size\n        self.memory_cell = nn.LSTMCell(input_size, hidden_size)\n        self.output = nn.Linear(hidden_size, output_size)\n\n    def forward(self, X):\n        batch_size, window_length, dimensionality = X.shape\n        X_time_first = X.transpose(0, 1)\n        H = torch.zeros(batch_size, self.hidden_size, device=X.device)\n        C = torch.zeros(batch_size, self.hidden_size, device=X.device)\n        for X_t in X_time_first:\n            H, C = self.memory_cell(X_t, (H, C))\n        return self.output(H)\n```", "```py\nclass DownsamplingModel(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super().__init__()\n        self.conv = nn.Conv1d(input_size, hidden_size, kernel_size=4, stride=2)\n        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n        self.linear = nn.Linear(hidden_size, output_size)\n\n    def forward(self, X):\n        Z = X.permute(0, 2, 1)  # treat time as a spatial dimension\n        Z = self.conv(Z)\n        Z = Z.permute(0, 2, 1)  # swap back time & features dimensions\n        Z = torch.relu(Z)\n        Z, _states = self.gru(Z)\n        return self.linear(Z)\n\ntorch.manual_seed(42)\ndseq_model = DownsamplingModel(input_size=5, hidden_size=32, output_size=14)\ndseq_model = dseq_model.to(device)\n```", "```py\nclass DownsampledDataset(Seq2SeqDataset):\n    def __getitem__(self, idx):\n        window, target = super().__getitem__(idx)\n        return window, target[3::2]  # crop the first 3 targets and downsample\n\nwindow_length = 112\ndseq_train_set = DownsampledDataset(rail_train, window_length)\ndseq_train_loader = DataLoader(dseq_train_set, batch_size=32, shuffle=True)\n[...]  # create the datasets and data loaders for the validation and test sets\n```", "```py\nmport torch.nn.functional as F\n\nclass CausalConv1d(nn.Conv1d):\n    def forward(self, X):\n        padding = (self.kernel_size[0] - 1) * self.dilation[0]\n        X = F.pad(X, (padding, 0))\n        return super().forward(X)\n```", "```py\nclass WavenetModel(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super().__init__()\n        layers = []\n        for dilation in (1, 2, 4, 8) * 2:\n            conv = CausalConv1d(input_size, hidden_size, kernel_size=2,\n                                dilation=dilation)\n            layers += [conv, nn.ReLU()]\n            input_size = hidden_size\n        self.convs = nn.Sequential(*layers)\n        self.output = nn.Linear(hidden_size, output_size)\n\n    def forward(self, X):\n        Z = X.permute(0, 2, 1)\n        Z = self.convs(Z)\n        Z = Z.permute(0, 2, 1)\n        return self.output(Z)\n\ntorch.manual_seed(42)\nwavenet_model = WavenetModel(input_size=5, hidden_size=32, output_size=14)\nwavenet_model = wavenet_model.to(device)\n```"]