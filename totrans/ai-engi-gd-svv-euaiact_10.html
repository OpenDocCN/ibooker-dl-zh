<html><head></head><body><section data-pdf-bookmark="Appendix C. The Integration of AI Governance and MLOps" data-type="appendix" epub:type="appendix"><div class="appendix" id="appendix_c_the_integration_of_ai_governance_and_mlops_1748539915562039">&#13;
<h1><span class="label">Appendix C. </span>The Integration of AI Governance <span class="keep-together">and MLOps</span></h1>&#13;
&#13;
<p>Integrating AI governance<a contenteditable="false" data-primary="integrating AI governance and MLOps" data-type="indexterm" id="integ-ai-gov-mlops-1"/> into the MLOps Stack Canvas (<a data-type="xref" href="#appendix_c_figure_1_1748539915556270">Figure C-1</a>) enables teams to proactively identify and mitigate risks related to bias, fairness, privacy, and security, while also supporting compliance with relevant regulations and standards. This integrated approach enhances model quality, promotes reliable predictions, and reinforces responsible AI development. It scales alongside technical capabilities, encourages cross-functional collaboration, and facilitates audits and accountability.</p>&#13;
&#13;
<p>In this appendix, we’ll review  the components of the MLOps Stack Canvas (introduced in <a data-type="xref" href="ch02.html#chapter_2_ai_engineering_a_proactive_compliance_catalyst_1748539917637495">Chapter 2</a>) and extend the framework to incorporate key AI governance concepts.</p>&#13;
&#13;
<figure><div class="figure" id="appendix_c_figure_1_1748539915556270"><img src="assets/taie_c001.png"/>&#13;
<h6><span class="label">Figure C-1. </span>The MLOps Stack Canvas framework</h6>&#13;
</div></figure>&#13;
&#13;
<section data-pdf-bookmark="Value Proposition" data-type="sect1"><div class="sect1" id="appendix_c_value_proposition_1748539915562183">&#13;
<h1>Value Proposition</h1>&#13;
&#13;
<p>In addition to formulating<a contenteditable="false" data-primary="integrating AI governance and MLOps" data-secondary="Value Proposition" data-type="indexterm" id="id678"/> a general value proposition and data governance goals for the MLOps platform, consider how AI governance contributes to the overall value of the ML project. For instance:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Add a “Compliance Requirements” section to outline applicable regulations and standards (e.g., the EU AI Act, GDPR, industry-specific AI regulations).</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Include a “Risk Classification” component aligned with the EU AI Act categories (unacceptable, high, limited, or minimal risk) to assess the potential risks and expected benefits of the AI system.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Add an “Ethical Impact Assessment” section to evaluate the potential societal and ethical implications of the AI system and ensure that the project aligns with the organization’s AI ethics principles.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Incorporate a Stakeholder Analysis component to identify all parties affected by the system, paying particular attention to vulnerable or marginalized groups.</p>&#13;
	</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Data Sources and Data Versioning" data-type="sect1"><div class="sect1" id="appendix_c_data_sources_and_data_versioning_1748539915562245">&#13;
<h1>Data Sources and Data Versioning</h1>&#13;
&#13;
<p>While considering data sources during the MLOps process<a contenteditable="false" data-primary="integrating AI governance and MLOps" data-secondary="Data Sources and Data Versioning" data-type="indexterm" id="id679"/>, you’ll also need to take AI governance into account. To that end, you should:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Ensure data sourcing complies with ethical guidelines and legal standards.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Include data quality and bias assessment protocols to identify and mitigate potential biases in training data.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Incorporate a data ethics review process to evaluate the ethical implications of data collection and usage.</p>&#13;
	</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Data Analysis and Experiment Management" data-type="sect1"><div class="sect1" id="appendix_c_data_analysis_and_experiment_management_1748539915562302">&#13;
<h1>Data Analysis and Experiment Management</h1>&#13;
&#13;
<p>To keep the AI governance<a contenteditable="false" data-primary="integrating AI governance and MLOps" data-secondary="Data Analysis and Experiment Management" data-type="indexterm" id="id680"/> focus while developing processes for data analysis and experiment management, integrate ethical guidelines to prevent biases:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Use experiment management tools to log all experiment details, ensuring transparency and accountability in model development.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Incorporate fairness metrics and bias analysis in experiments.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Document decision-making processes and rationale.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Implement version control for analysis scripts and notebooks to ensure the reproducibility of experiments.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Implement explainable AI (XAI) techniques to ensure model interpretability.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Include ethical experiment documentation requirements to create an audit trail.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Incorporate an ethical review process for experiment design and results.</p>&#13;
	</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Feature Store and Workflows" data-type="sect1"><div class="sect1" id="appendix_c_feature_store_and_workflows_1748539915562357">&#13;
<h1>Feature Store and Workflows</h1>&#13;
&#13;
<p>Maintaining AI governance in the Feature Store and Workflows<a contenteditable="false" data-primary="integrating AI governance and MLOps" data-secondary="Feature Store and Workflows" data-type="indexterm" id="id681"/> component requires policies that ensure data privacy and security. Standardize feature engineering workflows to make them reproducible and transparent, documenting all transformations and their intended purposes. Furthermore:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Add feature importance analysis to support transparency, interpretability, and identification of potential ethical implications.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Implement feature bias detection and mitigation strategies.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Include privacy-preserving feature engineering techniques.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Add feature documentation and requirements for auditability and governance.</p>&#13;
	</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="CI/CT/CD: ML Pipeline Orchestration" data-type="sect1"><div class="sect1" id="appendix_c_ci_ct_cd_ml_pipeline_orchestration_1748539915562417">&#13;
<h1>CI/CT/CD: ML Pipeline Orchestration</h1>&#13;
&#13;
<p>This part<a contenteditable="false" data-primary="integrating AI governance and MLOps" data-secondary="CI/CT/CD: ML Pipeline Orchestration" data-type="indexterm" id="id682"/> of the canvas is a natural fit for embedding governance automation. To integrate AI governance into continuous integration, testing, and deployment processes, align these workflows with ethical, legal, and organizational standards from the start:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Integrate ethical review checkpoints at critical stages of the CI/CD pipeline, such as before and after model training and deployment. For example, a healthcare company might include a review checkpoint after training to evaluate whether model predictions adhere to ethical standards concerning racial or gender bias.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Ensure traceability between code changes and model versions.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Implement automatic model card generation after each training pipeline to document model limitations, potential biases, and intended use cases.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Use gradual rollout strategies with human oversight to minimize risk.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Add model robustness and security testing, including adversarial testing and input perturbations. Frameworks like CleverHans or the Adversarial Robustness Toolbox can be used to strengthen models against manipulation and attacks.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Conduct pre-deployment ethical impact assessments and include model fairness and bias tests as part of the CI/CD testing suite. Tools like IBM’s AI Fairness 360 or Google’s What-If Tool can be integrated to automatically detect and report bias in model predictions during the testing phase.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Automate compliance checks for data handling and model behavior. Implement automated compliance checks in the CI/CD pipeline. For example, include automated scripts to verify that data anonymization and pseudonymization techniques are correctly applied before any data is used for training or testing and to support compliance with regulations such as the EU AI Act, GDPR, and HIPAA.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Include governance approval gates in the continuous deployment process. Before deploying a model, add validation steps where stakeholders (such as ethicists, legal advisors, and target community representatives) can review and approve the model based on ethical considerations.</p>&#13;
	</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Model Registry and Model Versioning" data-type="sect1"><div class="sect1" id="appendix_c_model_registry_and_model_versioning_1748539915562476">&#13;
<h1>Model Registry and Model Versioning</h1>&#13;
&#13;
<p>To ensure model versioning<a contenteditable="false" data-primary="integrating AI governance and MLOps" data-secondary="Model Registry and Model Versioning" data-type="indexterm" id="id683"/> aligns with data versioning and governance policies, include ethical metadata and governance information in the model registry. The following practices are recommended:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Establish approval workflows for model deployment.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Maintain an audit trail of model changes and approvals.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Implement model lineage and provenance to document the entire lifecycle of each model and the accountable individuals.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Include model risk assessment documentation.</p>&#13;
	</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Model Deployment" data-type="sect1"><div class="sect1" id="appendix_c_model_deployment_1748539915562529">&#13;
<h1>Model Deployment</h1>&#13;
&#13;
<p>Maintaining AI<a contenteditable="false" data-primary="integrating AI governance and MLOps" data-secondary="Model Deployment" data-type="indexterm" id="id684"/> governance in model deployment requires several key actions:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Implement canary releases and A/B testing with ethical considerations.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Ensure human-in-the-loop processes for critical decisions. Include human oversight mechanisms for high-risk AI systems.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Conduct post-deployment monitoring for ethical concerns.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Add gradual rollout strategies for careful monitoring of deployed models.</p>&#13;
	</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Prediction Serving" data-type="sect1"><div class="sect1" id="appendix_c_prediction_serving_1748539915562580">&#13;
<h1>Prediction Serving</h1>&#13;
&#13;
<p>To keep the AI governance<a contenteditable="false" data-primary="integrating AI governance and MLOps" data-secondary="Prediction Serving" data-type="indexterm" id="id685"/> focus in the Prediction Serving part of the MLOps Stack Canvas, integrate the following steps:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Provide mechanisms for users to contest or appeal decisions and gather user feedback to identify potential issues or biases. Implement rate-limiting and abuse prevention controls.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Apply ethical input validation to guard against misuse or biased inputs.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Monitor model outputs in real time to ensure fairness.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Maintain comprehensive audit logs of all predictions.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Incorporate model explainability interfaces for end users and auditors.</p>&#13;
	</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Model, Data, and Application Monitoring" data-type="sect1"><div class="sect1" id="appendix_c_model_data_and_application_monitoring_1748539915562634">&#13;
<h1>Model, Data, and Application Monitoring</h1>&#13;
&#13;
<p>To maintain AI governance<a contenteditable="false" data-primary="integrating AI governance and MLOps" data-secondary="Model, Data, and Application Monitoring" data-type="indexterm" id="id686"/> in the Model, Data, and Application Monitoring component of the canvas:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Establish continuous fairness and bias monitoring.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Set up alerts for ethical breaches or unexpected model behavior.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Monitor for data drift and concept drift, with attention to ethical implications.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Implement automated detection of shifts that could impact fairness or <span class="keep-together">performance</span>.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Configure automated alerts to flag governance violations.</p>&#13;
	</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Metadata Management" data-type="sect1"><div class="sect1" id="appendix_c_metadata_management_1748539915562686">&#13;
<h1>Metadata Management</h1>&#13;
&#13;
<p>Metadata management<a contenteditable="false" data-primary="integrating AI governance and MLOps" data-secondary="Metadata Management" data-type="indexterm" id="id687"/> is a crucial aspect of AI governance and is covered in depth in <a data-type="xref" href="ch03.html#chapter_3_data_and_ai_governance_and_ai_engineering_1748539918115723">Chapter 3</a>. For now, here are some key practices to incorporate into your MLOps <span class="keep-together">processes</span>:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Maintain comprehensive documentation of AI governance practices and policies, with proper version control.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Establish traceability between models, data, and governance decisions.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Maintain an inventory of AI systems and their governance status.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Include metadata for regulatory compliance (e.g., EU AI Act, GDPR).</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Add traceability for critical model decisions.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Collect metadata related to model interpretability and explainability.</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>By incorporating AI governance concepts into the MLOps Stack Canvas, you create a comprehensive framework that not only addresses the technical aspects of machine learning operations but also ensures ethical, responsible, and transparent AI development and deployment. This adapted canvas promotes trust, accountability, and sustainable development of AI systems throughout the entire ML project lifecycle.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Integrating Data and AI Governance into MLOps" data-type="sect1"><div class="sect1" id="appendix_c_integrating_data_and_ai_governance_into_mlops_1748539915562750">&#13;
<h1>Integrating Data and AI Governance into MLOps</h1>&#13;
&#13;
<p>An emerging trend in the context of the EU AI Act is that data and AI governance are becoming closely intertwined with MLOps. A promising development is the integration of MLOps platforms with internal audit and risk management systems to enhance governance processes. This helps organizations ensure that AI models comply with regulatory requirements and organizational policies throughout their lifecycle. <a data-type="xref" href="#appendix_c_table_1_1748539915558109">Table C-1</a> summarizes the data and AI governance processes that should be incorporated across the MLOps tech stack.</p>&#13;
&#13;
<table class="striped" id="appendix_c_table_1_1748539915558109">&#13;
	<caption><span class="label">Table C-1. </span>Summary of integration of data and AI governance into MLOps processes</caption>&#13;
	<thead>&#13;
		<tr>&#13;
			<th>MLOps <span class="keep-together">Stack Canvas</span> component</th>&#13;
			<th>Data governance</th>&#13;
			<th>AI governance</th>&#13;
		</tr>&#13;
	</thead>&#13;
	<tbody>&#13;
		<tr>&#13;
			<td>Value Proposition</td>&#13;
			<td>&#13;
			<ul>&#13;
				<li>Compliance requirements</li>&#13;
			</ul>&#13;
			</td>&#13;
			<td>&#13;
			<ul>&#13;
				<li>AI regulation compliance requirements</li>&#13;
				<li>Ethical AI values</li>&#13;
			</ul>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>Data Sources and Data Versioning</td>&#13;
			<td>&#13;
			<ul>&#13;
				<li>Data catalog</li>&#13;
				<li>Data access control</li>&#13;
				<li>Data lineage and provenance</li>&#13;
				<li>Data privacy and security</li>&#13;
			</ul>&#13;
			</td>&#13;
			<td>&#13;
			<ul>&#13;
				<li>Bias assessment</li>&#13;
				<li>Data ethics review process</li>&#13;
			</ul>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>Data Analysis and Experiment Management</td>&#13;
			<td>&#13;
			<ul>&#13;
				<li>Data privacy and security</li>&#13;
				<li>Data access control</li>&#13;
				<li>Data handling monitoring</li>&#13;
			</ul>&#13;
			</td>&#13;
			<td>&#13;
			<ul>&#13;
				<li>Fairness metrics and bias analysis</li>&#13;
				<li>Experiment reproducibility</li>&#13;
				<li>XAI techniques</li>&#13;
				<li>Experiment documentation</li>&#13;
				<li>Ethical reviews of experiments</li>&#13;
			</ul>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>Feature Store and Workflows</td>&#13;
			<td>&#13;
			<ul>&#13;
				<li>Feature versioning</li>&#13;
				<li>Cataloging features with metadata</li>&#13;
				<li>Access controls for feature store</li>&#13;
				<li>Feature lineage and feature provenance</li>&#13;
				<li>Feature documentation</li>&#13;
			</ul>&#13;
			</td>&#13;
			<td>&#13;
			<ul>&#13;
				<li>Feature assessment for potential bias and non-discrimination</li>&#13;
				<li>Feature documentation</li>&#13;
				<li>Privacy-preserving feature engineering</li>&#13;
				<li>Feature importance analysis</li>&#13;
			</ul>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>CI/CT/CD: ML Pipeline Orchestration</td>&#13;
			<td>&#13;
			<ul>&#13;
				<li>DataOps</li>&#13;
				<li>Automated data profiling</li>&#13;
				<li>Automated anomaly detection mechanisms</li>&#13;
				<li>Governance checks in CI/CD pipelines</li>&#13;
				<li>Automated compliance checks for data</li>&#13;
				<li>Data security in CI/CD pipelines</li>&#13;
				<li>Data quality checks and validations in CI/CD pipelines</li>&#13;
				<li>Sensitive data protection</li>&#13;
				<li>Data drift detection and alerting in the CI/CT workflow</li>&#13;
			</ul>&#13;
			</td>&#13;
			<td>&#13;
			<ul>&#13;
				<li>Traceability between code changes and model versions</li>&#13;
				<li>Documentation (model card generation for transparency)</li>&#13;
				<li>Pre-deployment ethical impact assessments</li>&#13;
				<li>Gradual rollout strategies with human oversight</li>&#13;
				<li>Automated compliance checks</li>&#13;
				<li>Model fairness and bias tests</li>&#13;
				<li>Governance approval gates</li>&#13;
			</ul>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>Model Registry and Model Versioning</td>&#13;
			<td>&#13;
			<ul>&#13;
				<li>Access controls and permissions for the model registry</li>&#13;
				<li>Model versioning aligned with data versioning</li>&#13;
				<li>Version history of models</li>&#13;
			</ul>&#13;
			</td>&#13;
			<td>&#13;
			<ul>&#13;
				<li>Ethical metadata</li>&#13;
				<li>Governance information in model registry</li>&#13;
				<li>Approval workflows for model deployment</li>&#13;
				<li>Documentation of model limitations, potential biases, and intended use cases</li>&#13;
				<li>Model lineage tracking</li>&#13;
				<li>Model risk assessment</li>&#13;
				<li>Model audit trail</li>&#13;
			</ul>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>Model Deployment</td>&#13;
			<td>&#13;
			<ul>&#13;
				<li>Deployed models adhere to data privacy and security regulations</li>&#13;
			</ul>&#13;
			</td>&#13;
			<td>&#13;
			<ul>&#13;
				<li>Canary releases and A/B testing with ethical considerations</li>&#13;
				<li>Human-in-the-loop processes for critical decisions</li>&#13;
				<li>Responsible AI checklists (pre-deployment verification)</li>&#13;
				<li>Post-deployment monitoring for ethical values</li>&#13;
			</ul>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>Prediction Serving</td>&#13;
			<td>&#13;
			<ul>&#13;
				<li>Input data validation</li>&#13;
				<li>Sensitive output protection</li>&#13;
				<li>Data privacy during prediction serving</li>&#13;
				<li>Data usage monitoring and auditing during prediction serving for compliance</li>&#13;
				<li>Auditing and logging of prediction requests and responses</li>&#13;
				<li>Detecting and alerting on any deviations in prediction quality, performance, or fairness metrics</li>&#13;
			</ul>&#13;
			</td>&#13;
			<td>&#13;
			<ul>&#13;
				<li>Real-time monitoring for fairness and bias</li>&#13;
				<li>Prediction explanations</li>&#13;
				<li>Ethical input validation</li>&#13;
				<li>Predictions audit logging</li>&#13;
			</ul>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>Model, Data, and Application Monitoring</td>&#13;
			<td>&#13;
			<ul>&#13;
				<li>Monitoring for data quality, bias, and drift in production ML systems</li>&#13;
				<li>Processes for investigating and remediating data governance issues</li>&#13;
			</ul>&#13;
			</td>&#13;
			<td>&#13;
			<ul>&#13;
				<li>Monitoring for data drift and concept drift with ethical implications (continuous fairness and bias monitoring)</li>&#13;
				<li>Performance monitoring against ethical KPIs</li>&#13;
				<li>Alerts for AI governance violations</li>&#13;
			</ul>&#13;
			</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td>Metadata Management</td>&#13;
			<td>&#13;
			<ul>&#13;
				<li>Data taxonomy and metadata schema</li>&#13;
				<li>Data governance metadata (data lineage, provenance, compliance checks, access logs)</li>&#13;
			</ul>&#13;
			</td>&#13;
			<td>&#13;
			<ul>&#13;
				<li>Inventory of AI systems and their governance status</li>&#13;
				<li>AI regulatory compliance metadata</li>&#13;
				<li>Version control for governance policies</li>&#13;
				<li>AI governance documentation</li>&#13;
				<li>Traceability between models, data, and governance decisions</li>&#13;
				<li>Metadata that captures model purpose, data used, performance metrics, compliance checks<a contenteditable="false" data-primary="integrating AI governance and MLOps" data-startref="integ-ai-gov-mlops-1" data-type="indexterm" id="id688"/>, and approvals</li>&#13;
			</ul>&#13;
			</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
</div></section>&#13;
</div></section></body></html>