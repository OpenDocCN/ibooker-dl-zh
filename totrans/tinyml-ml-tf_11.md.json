["```py\nnamespace tflite {\nnamespace ops {\nnamespace micro {\nTfLiteRegistration* Register_DEPTHWISE_CONV_2D();\nTfLiteRegistration* Register_MAX_POOL_2D();\nTfLiteRegistration* Register_CONV_2D();\nTfLiteRegistration* Register_FULLY_CONNECTED();\nTfLiteRegistration* Register_SOFTMAX();\n}  // namespace micro\n}  // namespace ops\n}  // namespace tflite\n```", "```py\n// Set up logging\ntflite::MicroErrorReporter micro_error_reporter;\ntflite::ErrorReporter* error_reporter = &micro_error_reporter;\n\n// Map the model into a usable data structure. This doesn't involve any\n// copying or parsing, it's a very lightweight operation.\nconst tflite::Model* model =\n    ::tflite::GetModel(g_magic_wand_model_data);\nif (model->version() != TFLITE_SCHEMA_VERSION) {\nerror_reporter->Report(\n    \"Model provided is schema version %d not equal \"\n    \"to supported version %d.\\n\",\n    model->version(), TFLITE_SCHEMA_VERSION);\n}\n\nstatic tflite::MicroMutableOpResolver micro_mutable_op_resolver;\nmicro_mutable_op_resolver.AddBuiltin(\n    tflite::BuiltinOperator_DEPTHWISE_CONV_2D,\n    tflite::ops::micro::Register_DEPTHWISE_CONV_2D());\nmicro_mutable_op_resolver.AddBuiltin(\n    tflite::BuiltinOperator_MAX_POOL_2D,\n    tflite::ops::micro::Register_MAX_POOL_2D());\nmicro_mutable_op_resolver.AddBuiltin(\n    tflite::BuiltinOperator_CONV_2D,\n    tflite::ops::micro::Register_CONV_2D());\nmicro_mutable_op_resolver.AddBuiltin(\n    tflite::BuiltinOperator_FULLY_CONNECTED,\n    tflite::ops::micro::Register_FULLY_CONNECTED());\nmicro_mutable_op_resolver.AddBuiltin(tflite::BuiltinOperator_SOFTMAX,\n                                    tflite::ops::micro::Register_SOFTMAX());\n\n// Create an area of memory to use for input, output, and intermediate arrays.\n// Finding the minimum value for your model may require some trial and error.\nconst int tensor_arena_size = 60 * 1024;\nuint8_t tensor_arena[tensor_arena_size];\n\n// Build an interpreter to run the model with\ntflite::MicroInterpreter interpreter(model, micro_mutable_op_resolver, tensor_arena,\n                                    tensor_arena_size, error_reporter);\n\n// Allocate memory from the tensor_arena for the model's tensors\ninterpreter.AllocateTensors();\n\n// Obtain a pointer to the model's input tensor\nTfLiteTensor* input = interpreter.input(0);\n```", "```py\n// Make sure the input has the properties we expect\nTF_LITE_MICRO_EXPECT_NE(nullptr, input);\nTF_LITE_MICRO_EXPECT_EQ(4, input->dims->size);\n// The value of each element gives the length of the corresponding tensor.\nTF_LITE_MICRO_EXPECT_EQ(1, input->dims->data[0]);\nTF_LITE_MICRO_EXPECT_EQ(128, input->dims->data[1]);\nTF_LITE_MICRO_EXPECT_EQ(3, input->dims->data[2]);\nTF_LITE_MICRO_EXPECT_EQ(1, input->dims->data[3]);\n// The input is a 32 bit floating point value\nTF_LITE_MICRO_EXPECT_EQ(kTfLiteFloat32, input->type);\n```", "```py\n// Provide an input value\nconst float* ring_features_data = g_circle_micro_f9643d42_nohash_4_data;\nerror_reporter->Report(\"%d\", input->bytes);\nfor (int i = 0; i < (input->bytes / sizeof(float)); ++i) {\n    input->data.f[i] = ring_features_data[i];\n}\n```", "```py\n// Run the model on this input and check that it succeeds\nTfLiteStatus invoke_status = interpreter.Invoke();\nif (invoke_status != kTfLiteOk) {\n  error_reporter->Report(\"Invoke failed\\n\");\n}\nTF_LITE_MICRO_EXPECT_EQ(kTfLiteOk, invoke_status);\n```", "```py\n// Obtain a pointer to the output tensor and make sure it has the\n// properties we expect.\nTfLiteTensor* output = interpreter.output(0);\nTF_LITE_MICRO_EXPECT_EQ(2, output->dims->size);\nTF_LITE_MICRO_EXPECT_EQ(1, output->dims->data[0]);\nTF_LITE_MICRO_EXPECT_EQ(4, output->dims->data[1]);\nTF_LITE_MICRO_EXPECT_EQ(kTfLiteFloat32, output->type);\n```", "```py\n// There are four possible classes in the output, each with a score.\nconst int kWingIndex = 0;\nconst int kRingIndex = 1;\nconst int kSlopeIndex = 2;\nconst int kNegativeIndex = 3;\n\n// Make sure that the expected \"Ring\" score is higher than the other\n// classes.\nfloat wing_score = output->data.f[kWingIndex];\nfloat ring_score = output->data.f[kRingIndex];\nfloat slope_score = output->data.f[kSlopeIndex];\nfloat negative_score = output->data.f[kNegativeIndex];\nTF_LITE_MICRO_EXPECT_GT(ring_score, wing_score);\nTF_LITE_MICRO_EXPECT_GT(ring_score, slope_score);\nTF_LITE_MICRO_EXPECT_GT(ring_score, negative_score);\n```", "```py\n  // Now test with a different input, from a recording of \"Slope\".\n  const float* slope_features_data = g_angle_micro_f2e59fea_nohash_1_data;\n  for (int i = 0; i < (input->bytes / sizeof(float)); ++i) {\n    input->data.f[i] = slope_features_data[i];\n  }\n\n  // Run the model on this \"Slope\" input.\n  invoke_status = interpreter.Invoke();\n  if (invoke_status != kTfLiteOk) {\n    error_reporter->Report(\"Invoke failed\\n\");\n  }\n  TF_LITE_MICRO_EXPECT_EQ(kTfLiteOk, invoke_status);\n\n  // Make sure that the expected \"Slope\" score is higher than the other classes.\n  wing_score = output->data.f[kWingIndex];\n  ring_score = output->data.f[kRingIndex];\n  slope_score = output->data.f[kSlopeIndex];\n  negative_score = output->data.f[kNegativeIndex];\n  TF_LITE_MICRO_EXPECT_GT(slope_score, wing_score);\n  TF_LITE_MICRO_EXPECT_GT(slope_score, ring_score);\n  TF_LITE_MICRO_EXPECT_GT(slope_score, negative_score);\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile test_magic_wand_test\n```", "```py\nTF_LITE_MICRO_TEST(TestSetup) {\n  static tflite::MicroErrorReporter micro_error_reporter;\n  TfLiteStatus setup_status = SetupAccelerometer(&micro_error_reporter);\n  TF_LITE_MICRO_EXPECT_EQ(kTfLiteOk, setup_status);\n}\n```", "```py\nTF_LITE_MICRO_TEST(TestAccelerometer) {\n  float input[384] = {0.0};\n  tflite::MicroErrorReporter micro_error_reporter;\n  // Test that the function returns false before insufficient data is available\n  bool inference_flag =\n      ReadAccelerometer(&micro_error_reporter, input, 384, false);\n  TF_LITE_MICRO_EXPECT_EQ(inference_flag, false);\n\n  // Test that the function returns true once sufficient data is available to\n  // fill the model's input buffer (128 sets of values)\n  for (int i = 1; i <= 128; i++) {\n    inference_flag =\n        ReadAccelerometer(&micro_error_reporter, input, 384, false);\n  }\n  TF_LITE_MICRO_EXPECT_EQ(inference_flag, true);\n}\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile \\\n  test_gesture_accelerometer_handler_test\n```", "```py\nconst int kConsecutiveInferenceThresholds[3] = {15, 12, 10};\n```", "```py\n// How many times the most recent gesture has been matched in a row\nint continuous_count = 0;\n// The result of the last prediction\nint last_predict = -1;\n```", "```py\n// Return the result of the last prediction\n// 0: wing(\"W\"), 1: ring(\"O\"), 2: slope(\"angle\"), 3: unknown\nint PredictGesture(float* output) {\n  // Find whichever output has a probability > 0.8 (they sum to 1)\n  int this_predict = -1;\n  for (int i = 0; i < 3; i++) {\n    if (output[i] > 0.8) this_predict = i;\n  }\n```", "```py\n  // No gesture was detected above the threshold\n  if (this_predict == -1) {\n    continuous_count = 0;\n    last_predict = 3;\n    return 3;\n  }\n```", "```py\n  if (last_predict == this_predict) {\n    continuous_count += 1;\n  } else {\n    continuous_count = 0;\n  }\n  last_predict = this_predict;\n```", "```py\n  // If we haven't yet had enough consecutive matches for this gesture,\n  // report a negative result\n  if (continuous_count < kConsecutiveInferenceThresholds[this_predict]) {\n    return 3;\n  }\n```", "```py\n  // Otherwise, we've seen a positive result, so clear all our variables\n  // and report it\n  continuous_count = 0;\n  last_predict = -1;\n  return this_predict;\n}\n```", "```py\nTF_LITE_MICRO_TEST(SuccessfulPrediction) {\n  // Use the threshold from the 0th gesture\n  int threshold = kConsecutiveInferenceThresholds[0];\n  float probabilities[4] = {1.0, 0.0, 0.0, 0.0};\n  int prediction;\n  // Loop just too few times to trigger a prediction\n  for (int i = 0; i <= threshold - 1; i++) {\n    prediction = PredictGesture(probabilities);\n    TF_LITE_MICRO_EXPECT_EQ(prediction, 3);\n  }\n  // Call once more, triggering a prediction\n  // for category 0\n  prediction = PredictGesture(probabilities);\n  TF_LITE_MICRO_EXPECT_EQ(prediction, 0);\n}\n```", "```py\nTF_LITE_MICRO_TEST(FailPartWayThere) {\n  // Use the threshold from the 0th gesture\n  int threshold = kConsecutiveInferenceThresholds[0];\n  float probabilities[4] = {1.0, 0.0, 0.0, 0.0};\n  int prediction;\n  // Loop just too few times to trigger a prediction\n  for (int i = 0; i <= threshold - 1; i++) {\n    prediction = PredictGesture(probabilities);\n    TF_LITE_MICRO_EXPECT_EQ(prediction, 3);\n  }\n  // Call with a different prediction, triggering a failure\n  probabilities[0] = 0.0;\n  probabilities[2] = 1.0;\n  prediction = PredictGesture(probabilities);\n  TF_LITE_MICRO_EXPECT_EQ(prediction, 3);\n}\n```", "```py\nTF_LITE_MICRO_TEST(InsufficientProbability) {\n  // Use the threshold from the 0th gesture\n  int threshold = kConsecutiveInferenceThresholds[0];\n  // Below the probability threshold of 0.8\n  float probabilities[4] = {0.7, 0.0, 0.0, 0.0};\n  int prediction;\n  // Loop the exact right number of times\n  for (int i = 0; i <= threshold; i++) {\n    prediction = PredictGesture(probabilities);\n    TF_LITE_MICRO_EXPECT_EQ(prediction, 3);\n  }\n}\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile \\\n  test_gesture_predictor_test\n```", "```py\nTF_LITE_MICRO_TEST(TestCallability) {\n  tflite::MicroErrorReporter micro_error_reporter;\n  tflite::ErrorReporter* error_reporter = &micro_error_reporter;\n  HandleOutput(error_reporter, 0);\n  HandleOutput(error_reporter, 1);\n  HandleOutput(error_reporter, 2);\n  HandleOutput(error_reporter, 3);\n}\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile \\\n  test_gesture_output_handler_test\n```", "```py\nnamespace tflite {\nnamespace ops {\nnamespace micro {\nTfLiteRegistration* Register_DEPTHWISE_CONV_2D();\nTfLiteRegistration* Register_MAX_POOL_2D();\nTfLiteRegistration* Register_CONV_2D();\nTfLiteRegistration* Register_FULLY_CONNECTED();\nTfLiteRegistration* Register_SOFTMAX();\n}  // namespace micro\n}  // namespace ops\n}  // namespace tflite\n\n// Globals, used for compatibility with Arduino-style sketches.\nnamespace {\ntflite::ErrorReporter* error_reporter = nullptr;\nconst tflite::Model* model = nullptr;\ntflite::MicroInterpreter* interpreter = nullptr;\nTfLiteTensor* model_input = nullptr;\nint input_length;\n\n// Create an area of memory to use for input, output, and intermediate arrays.\n// The size of this will depend on the model you're using, and may need to be\n// determined by experimentation.\nconstexpr int kTensorArenaSize = 60 * 1024;\nuint8_t tensor_arena[kTensorArenaSize];\n\n// Whether we should clear the buffer next time we fetch data\nbool should_clear_buffer = false;\n}  // namespace\n```", "```py\nvoid setup() {\n  // Set up logging. Google style is to avoid globals or statics because of\n  // lifetime uncertainty, but since this has a trivial destructor it's okay.\n  static tflite::MicroErrorReporter micro_error_reporter; //NOLINT\n  error_reporter = &micro_error_reporter;\n\n  // Map the model into a usable data structure. This doesn't involve any\n  // copying or parsing, it's a very lightweight operation.\n  model = tflite::GetModel(g_magic_wand_model_data);\n  if (model->version() != TFLITE_SCHEMA_VERSION) {\n    error_reporter->Report(\n        \"Model provided is schema version %d not equal \"\n        \"to supported version %d.\",\n        model->version(), TFLITE_SCHEMA_VERSION);\n    return;\n  }\n\n  // Pull in only the operation implementations we need.\n  // This relies on a complete list of all the ops needed by this graph.\n  // An easier approach is to just use the AllOpsResolver, but this will\n  // incur some penalty in code space for op implementations that are not\n  // needed by this graph.\n  static tflite::MicroMutableOpResolver micro_mutable_op_resolver; // NOLINT\n  micro_mutable_op_resolver.AddBuiltin(\n      tflite::BuiltinOperator_DEPTHWISE_CONV_2D,\n      tflite::ops::micro::Register_DEPTHWISE_CONV_2D());\n  micro_mutable_op_resolver.AddBuiltin(\n      tflite::BuiltinOperator_MAX_POOL_2D,\n      tflite::ops::micro::Register_MAX_POOL_2D());\n  micro_mutable_op_resolver.AddBuiltin(\n      tflite::BuiltinOperator_CONV_2D,\n      tflite::ops::micro::Register_CONV_2D());\n  micro_mutable_op_resolver.AddBuiltin(\n      tflite::BuiltinOperator_FULLY_CONNECTED,\n      tflite::ops::micro::Register_FULLY_CONNECTED());\n  micro_mutable_op_resolver.AddBuiltin(tflite::BuiltinOperator_SOFTMAX,\n                                       tflite::ops::micro::Register_SOFTMAX());\n\n  // Build an interpreter to run the model with\n  static tflite::MicroInterpreter static_interpreter(model,\n                                                     micro_mutable_op_resolver,\n                                                     tensor_arena,\n                                                     kTensorArenaSize,\n                                                     error_reporter);\n  interpreter = &static_interpreter;\n\n  // Allocate memory from the tensor_arena for the model's tensors\n  interpreter->AllocateTensors();\n\n  // Obtain pointer to the model's input tensor\n  model_input = interpreter->input(0);\n  if ((model_input->dims->size != 4) || (model_input->dims->data[0] != 1) ||\n      (model_input->dims->data[1] != 128) ||\n      (model_input->dims->data[2] != kChannelNumber) ||\n      (model_input->type != kTfLiteFloat32)) {\n    error_reporter->Report(\"Bad input tensor parameters in model\");\n    return;\n  }\n\n  input_length = model_input->bytes / sizeof(float);\n\n  TfLiteStatus setup_status = SetupAccelerometer(error_reporter);\n  if (setup_status != kTfLiteOk) {\n    error_reporter->Report(\"Set up failed\\n\");\n  }\n}\n```", "```py\nvoid loop() {\n  // Attempt to read new data from the accelerometer\n  bool got_data = ReadAccelerometer(error_reporter, model_input->data.f,\n                                    input_length, should_clear_buffer);\n  // Don't try to clear the buffer again\n  should_clear_buffer = false;\n  // If there was no new data, wait until next time\n  if (!got_data) return;\n  // Run inference, and report any error\n  TfLiteStatus invoke_status = interpreter->Invoke();\n  if (invoke_status != kTfLiteOk) {\n    error_reporter->Report(\"Invoke failed on index: %d\\n\", begin_index);\n    return;\n  }\n  // Analyze the results to obtain a prediction\n  int gesture_index = PredictGesture(interpreter->output(0)->data.f);\n  // Clear the buffer next time we read data\n  should_clear_buffer = gesture_index < 3;\n  // Produce an output\n  HandleOutput(error_reporter, gesture_index);\n}\n```", "```py\nint main(int argc, char* argv[]) {\n  setup();\n  while (true) {\n    loop();\n  }\n}\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile magic_wand\n```", "```py\n./tensorflow/lite/micro/tools/make/gen/osx_x86_64/bin/magic_wand\n```", "```py\n// The number of expected consecutive inferences for each gesture type.\n// Established with the Arduino Nano 33 BLE Sense.\nconst int kConsecutiveInferenceThresholds[3] = {8, 5, 4};\n```", "```py\n#include \"tensorflow/lite/micro/examples/magic_wand/\n  accelerometer_handler.h\"\n\n#include <Arduino.h>\n#include <Arduino_LSM9DS1.h>\n\n#include \"tensorflow/lite/micro/examples/magic_wand/constants.h\"\n```", "```py\n// A buffer holding the last 200 sets of 3-channel values\nfloat save_data[600] = {0.0};\n// Most recent position in the save_data buffer\nint begin_index = 0;\n// True if there is not yet enough data to run inference\nbool pending_initial_data = true;\n// How often we should save a measurement during downsampling\nint sample_every_n;\n// The number of measurements since we last saved one\nint sample_skip_counter = 1;\n```", "```py\nTfLiteStatus SetupAccelerometer(tflite::ErrorReporter* error_reporter) {\n  // Wait until we know the serial port is ready\n  while (!Serial) {\n  }\n\n  // Switch on the IMU\n  if (!IMU.begin()) {\n    error_reporter->Report(\"Failed to initialize IMU\");\n    return kTfLiteError;\n  }\n```", "```py\n  // Determine how many measurements to keep in order to\n  // meet kTargetHz\n  float sample_rate = IMU.accelerationSampleRate();\n  sample_every_n = static_cast<int>(roundf(sample_rate / kTargetHz));\n```", "```py\n  error_reporter->Report(\"Magic starts!\");\n\n  return kTfLiteOk;\n}\n```", "```py\nbool ReadAccelerometer(tflite::ErrorReporter* error_reporter, float* input,\n                       int length, bool reset_buffer) {\n  // Clear the buffer if required, e.g. after a successful prediction\n  if (reset_buffer) {\n    memset(save_data, 0, 600 * sizeof(float));\n    begin_index = 0;\n    pending_initial_data = true;\n  }\n```", "```py\n  // Keep track of whether we stored any new data\n  bool new_data = false;\n  // Loop through new samples and add to buffer\n  while (IMU.accelerationAvailable()) {\n    float x, y, z;\n    // Read each sample, removing it from the device's FIFO buffer\n    if (!IMU.readAcceleration(x, y, z)) {\n      error_reporter->Report(\"Failed to read data\");\n      break;\n    }\n```", "```py\n    // Throw away this sample unless it's the nth\n    if (sample_skip_counter != sample_every_n) {\n      sample_skip_counter += 1;\n      continue;\n    }\n```", "```py\n    // Write samples to our buffer, converting to milli-Gs\n    // and flipping y and x order for compatibility with\n    // model (sensor orientation is different on Arduino\n    // Nano BLE Sense compared with SparkFun Edge)\n    save_data[begin_index++] = y * 1000;\n    save_data[begin_index++] = x * 1000;\n    save_data[begin_index++] = z * 1000;\n```", "```py\n    // Since we took a sample, reset the skip counter\n    sample_skip_counter = 1;\n    // If we reached the end of the circle buffer, reset\n    if (begin_index >= 600) {\n      begin_index = 0;\n    }\n    new_data = true;\n  }\n```", "```py\n  // Skip this round if data is not ready yet\n  if (!new_data) {\n    return false;\n  }\n\n  // Check if we are ready for prediction or still pending more initial data\n  if (pending_initial_data && begin_index >= 200) {\n    pending_initial_data = false;\n  }\n\n  // Return if we don't have enough data\n  if (pending_initial_data) {\n    return false;\n  }\n```", "```py\n  // Copy the requested number of bytes to the provided input tensor\n  for (int i = 0; i < length; ++i) {\n    int ring_array_index = begin_index + i - length;\n    if (ring_array_index < 0) {\n      ring_array_index += 600;\n    }\n    input[i] = save_data[ring_array_index];\n  }\n\n  return true;\n}\n```", "```py\nvoid HandleOutput(tflite::ErrorReporter* error_reporter, int kind) {\n  // The first time this method runs, set up our LED\n  static bool is_initialized = false;\n  if (!is_initialized) {\n    pinMode(LED_BUILTIN, OUTPUT);\n    is_initialized = true;\n  }\n```", "```py\n  // Toggle the LED every time an inference is performed\n  static int count = 0;\n  ++count;\n  if (count & 1) {\n    digitalWrite(LED_BUILTIN, HIGH);\n  } else {\n    digitalWrite(LED_BUILTIN, LOW);\n  }\n```", "```py\n  // Print some ASCII art for each gesture\n  if (kind == 0) {\n    error_reporter->Report(\n        \"WING:\\n\\r*         *         *\\n\\r *       * *       \"\n        \"*\\n\\r *     *   *     *\\n\\r *   *     *   *\\n\\r * *       \"\n        \"* *\\n\\r *         *\\n\\r\");\n  } else if (kind == 1) {\n    error_reporter->Report(\n        \"RING:\\n\\r *\\n\\r *     *\\n\\r *         *\\n\\r \"\n        \"   *           *\\n\\r *         *\\n\\r *     *\\n\\r \"\n        \"    *\\n\\r\");\n  } else if (kind == 2) {\n    error_reporter->Report(\n        \"SLOPE:\\n\\r *\\n\\r *\\n\\r *\\n\\r *\\n\\r \"\n        \"*\\n\\r *\\n\\r *\\n\\r * * * * * * * *\\n\\r\");\n  }\n```", "```py\n// Enable FIFO (see docs https://www.st.com/resource/en/datasheet/DM00103319.pdf)\n// writeRegister(LSM9DS1_ADDRESS, 0x23, 0x02);\n// Set continuous mode\nwriteRegister(LSM9DS1_ADDRESS, 0x2E, 0xC0);\n```", "```py\nif (readRegister(LSM9DS1_ADDRESS, LSM9DS1_STATUS_REG) & 0x01) {\n  return 1;\n}\n```", "```py\n// Read FIFO_SRC. If any of the rightmost 8 bits have a value, there is data.\nif (readRegister(LSM9DS1_ADDRESS, 0x2F) & 63) {\n  return 1;\n}\n```", "```py\nMagic starts!\n```", "```py\nWING:\n*         *         *\n *       * *       *\n  *     *   *     *\n   *   *     *   *\n    * *       * *\n     *         *\n```", "```py\nRING:\n          *\n       *     *\n     *         *\n    *           *\n     *         *\n       *     *\n          *\n```", "```py\nSLOPE:\n        *\n       *\n      *\n     *\n    *\n   *\n  *\n * * * * * * * *\n```", "```py\nTfLiteStatus SetupAccelerometer(tflite::ErrorReporter* error_reporter) {\n  // Set the clock frequency.\n  am_hal_clkgen_control(AM_HAL_CLKGEN_CONTROL_SYSCLK_MAX, 0);\n\n  // Set the default cache configuration\n  am_hal_cachectrl_config(&am_hal_cachectrl_defaults);\n  am_hal_cachectrl_enable();\n\n  // Configure the board for low power operation.\n  am_bsp_low_power_init();\n\n  // Collecting data at 25Hz.\n  int accInitRes = initAccelerometer();\n```", "```py\n  // Enable the accelerometer's FIFO buffer.\n  // Note: LIS2DH12 has a FIFO buffer which holds up to 32 data entries. It\n  // accumulates data while the CPU is busy. Old data will be overwritten if\n  // it's not fetched in time, so we need to make sure that model inference is\n  // faster than 1/25Hz * 32 = 1.28s\n  if (lis2dh12_fifo_set(&dev_ctx, 1)) {\n    error_reporter->Report(\"Failed to enable FIFO buffer.\");\n  }\n\n  if (lis2dh12_fifo_mode_set(&dev_ctx, LIS2DH12_BYPASS_MODE)) {\n    error_reporter->Report(\"Failed to clear FIFO buffer.\");\n    return 0;\n  }\n\n  if (lis2dh12_fifo_mode_set(&dev_ctx, LIS2DH12_DYNAMIC_STREAM_MODE)) {\n    error_reporter->Report(\"Failed to set streaming mode.\");\n    return 0;\n  }\n\n  error_reporter->Report(\"Magic starts!\");\n\n  return kTfLiteOk;\n}\n```", "```py\nbool ReadAccelerometer(tflite::ErrorReporter* error_reporter, float* input,\n                       int length, bool reset_buffer) {\n  // Clear the buffer if required, e.g. after a successful prediction\n  if (reset_buffer) {\n    memset(save_data, 0, 600 * sizeof(float));\n    begin_index = 0;\n    pending_initial_data = true;\n    // Wait 10ms after a reset to avoid hang\n    am_util_delay_ms(10);\n  }\n```", "```py\n  // Check FIFO buffer for new samples\n  lis2dh12_fifo_src_reg_t status;\n  if (lis2dh12_fifo_status_get(&dev_ctx, &status)) {\n    error_reporter->Report(\"Failed to get FIFO status.\");\n    return false;\n  }\n\n  int samples = status.fss;\n  if (status.ovrn_fifo) {\n    samples++;\n  }\n\n  // Skip this round if data is not ready yet\n  if (samples == 0) {\n    return false;\n  }\n```", "```py\n  // Load data from FIFO buffer\n  axis3bit16_t data_raw_acceleration;\n  for (int i = 0; i < samples; i++) {\n    // Zero out the struct that holds raw accelerometer data\n    memset(data_raw_acceleration.u8bit, 0x00, 3 * sizeof(int16_t));\n    // If the return value is non-zero, sensor data was successfully read\n    if (lis2dh12_acceleration_raw_get(&dev_ctx, data_raw_acceleration.u8bit)) {\n      error_reporter->Report(\"Failed to get raw data.\");\n```", "```py\n    } else {\n      // Convert each raw 16-bit value into floating point values representing\n      // milli-Gs, a unit of acceleration, and store in the current position of\n      // our buffer\n      save_data[begin_index++] =\n          lis2dh12_from_fs2_hr_to_mg(data_raw_acceleration.i16bit[0]);\n      save_data[begin_index++] =\n          lis2dh12_from_fs2_hr_to_mg(data_raw_acceleration.i16bit[1]);\n      save_data[begin_index++] =\n          lis2dh12_from_fs2_hr_to_mg(data_raw_acceleration.i16bit[2]);\n      // Start from beginning, imitating loop array.\n      if (begin_index >= 600) begin_index = 0;\n    }\n  }\n```", "```py\n  // Check if we are ready for prediction or still pending more initial data\n  if (pending_initial_data && begin_index >= 200) {\n    pending_initial_data = false;\n  }\n```", "```py\n  // Return if we don't have enough data\n  if (pending_initial_data) {\n    return false;\n  }\n```", "```py\n  // Copy the requested number of bytes to the provided input tensor\n  for (int i = 0; i < length; ++i) {\n    int ring_array_index = begin_index + i - length;\n    if (ring_array_index < 0) {\n      ring_array_index += 600;\n    }\n    input[i] = save_data[ring_array_index];\n  }\n  return true;\n```", "```py\nvoid HandleOutput(tflite::ErrorReporter* error_reporter, int kind) {\n  // The first time this method runs, set up our LEDs correctly\n  static bool is_initialized = false;\n  if (!is_initialized) {\n    am_hal_gpio_pinconfig(AM_BSP_GPIO_LED_RED, g_AM_HAL_GPIO_OUTPUT_12);\n    am_hal_gpio_pinconfig(AM_BSP_GPIO_LED_BLUE, g_AM_HAL_GPIO_OUTPUT_12);\n    am_hal_gpio_pinconfig(AM_BSP_GPIO_LED_GREEN, g_AM_HAL_GPIO_OUTPUT_12);\n    am_hal_gpio_pinconfig(AM_BSP_GPIO_LED_YELLOW, g_AM_HAL_GPIO_OUTPUT_12);\n    is_initialized = true;\n  }\n```", "```py\n  // Toggle the yellow LED every time an inference is performed\n  static int count = 0;\n  ++count;\n  if (count & 1) {\n    am_hal_gpio_output_set(AM_BSP_GPIO_LED_YELLOW);\n  } else {\n    am_hal_gpio_output_clear(AM_BSP_GPIO_LED_YELLOW);\n  }\n```", "```py\n  // Set the LED color and print a symbol (red: wing, blue: ring, green: slope)\n  if (kind == 0) {\n    error_reporter->Report(\n        \"WING:\\n\\r*         *         *\\n\\r *       * *       \"\n        \"*\\n\\r *     *   *     *\\n\\r *   *     *   *\\n\\r * *       \"\n        \"* *\\n\\r *         *\\n\\r\");\n    am_hal_gpio_output_set(AM_BSP_GPIO_LED_RED);\n    am_hal_gpio_output_clear(AM_BSP_GPIO_LED_BLUE);\n    am_hal_gpio_output_clear(AM_BSP_GPIO_LED_GREEN);\n```", "```py\nWING:\n*         *         *\n *       * *       *\n  *     *   *     *\n   *   *     *   *\n    * *       * *\n     *         *\n```", "```py\ngit clone https://github.com/tensorflow/tensorflow.git\ncd tensorflow\n```", "```py\nmake -f tensorflow/lite/micro/tools/make/Makefile \\\n TARGET=sparkfun_edge magic_wand_bin\n```", "```py\ntensorflow/lite/micro/tools/make/gen/\n sparkfun_edge_cortex-m4/bin/magic_wand.bin\n```", "```py\ntest -f tensorflow/lite/micro/tools/make/gen/sparkfun_edge_ \\\n  cortex-m4/bin/magic_wand.bin &&  echo \"Binary was successfully created\" || \\\n  echo \"Binary is missing\"\n```", "```py\ncp tensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/ \\\n  tools/apollo3_scripts/keys_info0.py\n  tensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.0.0/ \\\n  tools/apollo3_scripts/keys_info.py\n```", "```py\npython3 tensorflow/lite/micro/tools/make/downloads/ \\\n  AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/create_cust_image_blob.py \\\n  --bin tensorflow/lite/micro/tools/make/gen/ \\\n  sparkfun_edge_cortex-m4/bin/micro_vision.bin \\\n  --load-address 0xC000 \\\n  --magic-num 0xCB \\\n  -o main_nonsecure_ota \\\n  --version 0x0\n```", "```py\npython3 tensorflow/lite/micro/tools/make/downloads/ \\\nAmbiqSuite-Rel2.0.0/tools/apollo3_scripts/create_cust_wireupdate_blob.py \\\n--load-address 0x20000 \\\n--bin main_nonsecure_ota.bin \\\n-i 6 \\\n-o main_nonsecure_wire \\\n--options 0x1\n```", "```py\n# macOS:\nls /dev/cu*\n\n# Linux:\nls /dev/tty*\n```", "```py\n/dev/cu.Bluetooth-Incoming-Port\n/dev/cu.MALS\n/dev/cu.SOC\n```", "```py\n# macOS:\nls /dev/cu*\n\n# Linux:\nls /dev/tty*\n```", "```py\n/dev/cu.Bluetooth-Incoming-Port\n/dev/cu.MALS\n/dev/cu.SOC\n/dev/cu.wchusbserial-1450\n```", "```py\nexport DEVICENAME=<*your device name here*>\n\n```", "```py\nexport BAUD_RATE=921600\n```", "```py\npython3 tensorflow/lite/micro/tools/make/downloads/ \\\n  AmbiqSuite-Rel2.0.0/tools/apollo3_scripts/uart_wired_update.py -b \\\n  ${BAUD_RATE} ${DEVICENAME} -r 1 -f main_nonsecure_wire.bin -i 6\n```", "```py\nConnecting with Corvette over serial port /dev/cu.usbserial-1440...\nSending Hello.\nReceived response for Hello\nReceived Status\nlength =  0x58\nversion =  0x3\nMax Storage =  0x4ffa0\nStatus =  0x2\nState =  0x7\nAMInfo =\n0x1\n0xff2da3ff\n0x55fff\n0x1\n0x49f40003\n0xffffffff\n[...lots more 0xffffffff...]\nSending OTA Descriptor =  0xfe000\nSending Update Command.\nnumber of updates needed =  1\nSending block of size  0x158b0  from  0x0  to  0x158b0\nSending Data Packet of length  8180\nSending Data Packet of length  8180\n[...lots more Sending Data Packet of length  8180...]\n```", "```py\n[...lots more Sending Data Packet of length  8180...]\nSending Data Packet of length  8180\nSending Data Packet of length  6440\nSending Reset Command.\nDone.\n```", "```py\nscreen ${DEVICENAME} 115200\n```", "```py\nMagic starts!\n```", "```py\nWING:\n*         *         *\n *       * *       *\n  *     *   *     *\n   *   *     *   *\n    * *       * *\n     *         *\n```", "```py\nRING:\n          *\n       *     *\n     *         *\n    *           *\n     *         *\n       *     *\n          *\n```", "```py\nSLOPE:\n        *\n       *\n      *\n     *\n    *\n   *\n  *\n * * * * * * * *\n```"]