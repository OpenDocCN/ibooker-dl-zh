- en: Chapter 10\. Interfacing LLMs with External Tools
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章\. 与外部工具接口LLMs
- en: In the first two parts of the book, we have seen how impactful standalone LLMs
    can be in solving a wide variety of tasks. To effectively harness their full range
    of capabilities in an organization, they have to be integrated into the existing
    data and software ecosystem. Unlike traditional software systems, LLMs can generate
    autonomous actions to interact with other ecosystem components, bringing a degree
    of flexibility never seen before in the software world. This flexibility unlocks
    a whole host of use cases that were previously considered impossible.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的前两部分中，我们看到了独立的LLMs在解决各种任务中的影响。为了有效地利用它们在组织中的全部能力，它们必须集成到现有的数据和软件生态系统中。与传统的软件系统不同，LLMs可以生成自主动作来与其他生态系统组件交互，带来软件世界中前所未有的灵活性。这种灵活性解锁了一大批之前被认为不可能用例。
- en: 'Another reason we need LLMs to interact with software and external data: as
    we know all too well, current LLMs have significant limitations, some of which
    we discussed in [Chapter 1](ch01.html#chapter_llm-introduction). To recap some
    key points:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要LLMs与软件和外部数据交互的另一个原因：正如我们所深知的那样，当前的LLMs存在重大限制，其中一些我们在[第1章](ch01.html#chapter_llm-introduction)中讨论过。为了回顾一些关键点：
- en: Since it is expensive to retrain LLMs or keep them continuously updated, they
    have a knowledge cutoff date and thus possess no knowledge of more recent events.
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于重新训练LLMs或持续更新它们成本高昂，它们有一个知识截止日期，因此对最近的事件没有了解。
- en: Even though they are getting better over time, LLMs don’t always get math right.
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 即使它们随着时间的推移而变得更好，LLMs也不总是能正确处理数学问题。
- en: They can’t provide factuality guarantees or accurately cite the sources of their
    outputs.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 他们无法提供事实性保证或准确引用其输出的来源。
- en: Feeding them your own data effectively is a challenge; fine-tuning is nontrivial,
    and in-context learning is limited by the length of the effective context window.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将自己的数据有效地输入给他们是一个挑战；微调并非易事，并且情境学习受限于有效情境窗口的长度。
- en: As we have been noticing throughout the book, the consolidation effect is leading
    us to a future (unless we hit a technological wall) where many of the aforementioned
    limitations might be addressed within the model itself. But we don’t necessarily
    need to wait for that moment to arrive, as many of these limitations can be addressed
    today by offloading the tasks and subtasks to external tools.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在整本书中注意到的那样，巩固效应正引导我们走向一个未来（除非我们遇到技术障碍），在这个未来中，许多上述限制可能可以在模型本身内得到解决。但我们不必
    necessarily 等待这一时刻的到来，因为许多这些限制可以通过将任务和子任务卸载到外部工具来解决。
- en: 'In this chapter, we will define the three canonical LLM interaction paradigms
    and provide guidance on how to choose between them for your application. Broadly
    speaking, there are two types of external entities that LLMs need to interact
    with: data stores and software/models, collectively called tools. We will demonstrate
    how to interface LLMs with various tools like APIs and code interpreters. We will
    show how to make the best use of libraries like LangChain and LlamaIndex, which
    have vastly simplified LLM integrations. We will explore the various scaffolding
    software that needs to be constructed to facilitate seamless interactions with
    the environment. We will also push the limits of what today’s LLMs are capable
    of, by demonstrating how they can be deployed as an agent that can make autonomous
    decisions.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '在本章中，我们将定义三种经典的LLM交互范式，并提供如何为您的应用程序选择它们的指导。从广义上讲，LLMs需要与之交互的外部实体有两种类型：数据存储和软件/模型，统称为工具。我们将演示如何将LLMs与各种工具（如API和代码解释器）接口。我们将展示如何充分利用LangChain和LlamaIndex等库，这些库极大地简化了LLM的集成。我们将探索需要构建的各种脚手架软件，以促进与环境的无缝交互。我们还将通过演示它们可以作为可以做出自主决定的代理来部署，来推动今天LLMs的能力极限。 '
- en: LLM Interaction Paradigms
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: LLM交互范式
- en: 'Suppose you have a task you want the LLM to solve. There are several possible
    options:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个想要LLM解决的问题。有几种可能的选择：
- en: The LLM uses its own memory and capabilities encoded in its parameters to solve
    the task.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM使用其参数中编码的自身记忆和能力来解决任务。
- en: You feed the LLM all the context it needs to solve the task within the prompt,
    and the LLM uses the provided context and its capabilities to solve it.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你向LLM提供解决任务所需的所有上下文，LLM使用提供的上下文和其能力来解决它。
- en: The LLM doesn’t have the requisite information or skills to solve this task,
    so you update the model parameters (fine-tuning etc., as detailed in Chapters
    [6](ch06.html#llm-fine-tuning)–[8](ch08.html#ch8)) so that it is able to activate
    the skills and knowledge needed to solve it.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LLM没有解决此任务所需的信息或技能，因此您更新模型参数（微调等，如第6章至第8章中详细说明）以使其能够激活解决任务所需的技能和知识。
- en: You don’t know a priori what context is needed to solve the task, so you use
    mechanisms to automatically fetch the relevant context and insert it into the
    prompt (passive approach).
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您事先不知道解决任务所需的环境，因此您使用机制自动检索相关环境并将其插入到提示中（被动方法）。
- en: You provide explicit instructions to the LLM on how to interact with external
    tools and data stores to solve your task, which the LLM follows (explicit approach).
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您向LLM提供明确的指示，说明如何与外部工具和数据存储交互以解决您的任务，LLM会遵循这些指示（明确方法）。
- en: The LLM breaks the task into multiple subtasks if needed, interacts with its
    environment to gather the information/knowledge needed to solve the task, and
    delegates subtasks to external models and tools when it doesn’t have the requisite
    capabilities to solve that subtask (autonomous approach).
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果需要，LLM会将任务分解成多个子任务，与其环境交互以收集解决任务所需的信息/知识，并在它没有解决该子任务所需的能力时将子任务委托给外部模型和工具（自主方法）。
- en: As you can see, the last three involve the LLM interacting with its environment
    (passive, explicit, and autonomous). Let’s explore the three interaction paradigms
    in detail.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，最后三个涉及LLM与其环境交互（被动、明确和自主）。让我们详细探讨这三种交互范例。
- en: Passive Approach
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 被动方法
- en: '[Figure 10-1](#passive-interaction) shows the typical workflow of an application
    that involves an LLM passively interacting with a data store.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[图10-1](#passive-interaction)显示了涉及LLM被动与数据存储交互的应用程序的典型工作流程。'
- en: '![Passive Interaction](assets/dllm_1001.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![被动交互](assets/dllm_1001.png)'
- en: Figure 10-1\. An LLM passively interacting with a data store
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-1\. 一个LLM被动地与数据存储交互
- en: A large number of use cases involve leveraging LLMs to use your own data. Examples
    include building a question-answering assistant over your company’s internal knowledge
    base that is spread over a bunch of Notion documents, or an airline chatbot that
    responds to customer queries about flight status or booking policies.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 许多用例涉及利用LLM（大型语言模型）来使用您自己的数据。例如，在您公司的内部知识库上构建一个问答助手，该知识库分布在多个Notion文档中，或者是一个能够响应客户关于航班状态或预订政策的查询的航空公司聊天机器人。
- en: 'To allow the LLM to access external information, we need two types of components:
    “data stores” that contain the required information and retrieval engines that
    can retrieve relevant data from data stores given a query. The retrieval engine
    can be powered by an LLM itself, or it can be as simple as a keyword-matching
    algorithm. The data store(s) can be a repository of data like a database, knowledge
    graph, vector database, or even just a collection of text files. Data in the data
    store is represented and indexed to make retrieval more efficient. Data representation,
    indexing, and retrieval are topics important enough to merit their own chapter:
    we will defer detailed discussions on them to [Chapter 11](ch11.html#chapter_llm_interfaces).'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让LLM能够访问外部信息，我们需要两种类型的组件：“数据存储”包含所需信息，以及能够根据查询从数据存储中检索相关数据的检索引擎。检索引擎可以由LLM本身提供动力，或者它可能只是一个简单的关键词匹配算法。数据存储可以是数据库、知识图谱、向量数据库，甚至只是一些文本文件的集合。数据存储中的数据以某种形式表示和索引，以提高检索效率。数据表示、索引和检索是足够重要的主题，值得单独成章：我们将推迟对这些问题的详细讨论，直到[第11章](ch11.html#chapter_llm_interfaces)。
- en: When a user issues a query, the retrieval engine uses the query to find the
    documents or text segments that are most relevant to answering this query. After
    ensuring that these fit into the context window of the LLM, they are fed to the
    LLM along with the query. The LLM is expected to answer the query given the relevant
    context provided in the prompt. This approach is popularly known as RAG, although
    as we will see in [Chapter 12](ch12.html#ch12), RAG refers to an even broader
    concept. RAG is an important paradigm that deserves its own chapter, so we will
    defer detailed coverage of the paradigm to [Chapter 12](ch12.html#ch12).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户提出查询时，检索引擎使用查询来找到与回答此查询最相关的文档或文本片段。在确保这些内容适合LLM的上下文窗口后，它们将与查询一起被输入到LLM中。预计LLM将根据提示中提供的相关上下文回答查询。这种方法通常被称为RAG，尽管如我们在[第12章](ch12.html#ch12)中将要看到的，RAG指的是一个更广泛的概念。RAG是一个重要的范例，值得拥有自己的章节，因此我们将推迟对这一范例的详细讨论到[第12章](ch12.html#ch12)。
- en: Note that the distinguishing feature of this paradigm is the passive nature
    of the LLM in the interaction. The LLM simply responds to the prompt and furnishes
    an answer. It does not know the source of the content inside the prompt. This
    paradigm is often used for building QA assistants or chatbots, where external
    information is required to understand the context of the conversation.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这种范例的显著特征是LLM在交互中的被动性质。LLM只是响应提示并提供答案。它不知道提示内容中内容的来源。这种范例常用于构建需要外部信息来理解对话上下文的QA助手或聊天机器人。
- en: Note
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: From this point forward, we will refer to user requests to the LLM as *queries*
    and textual units that are retrieved from external data stores as *documents*.
    Documents can be full documents, passages, paragraphs, or sentences.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 从现在开始，我们将把对LLM的用户请求称为*查询*，从外部数据存储中检索到的文本单元称为*文档*。文档可以是完整的文档、段落、段落或句子。
- en: The Explicit Approach
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 显式方法
- en: '[Figure 10-2](#explicit-approach) demonstrates the explicit approach to interface
    LLMs with external tools.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[图10-2](#explicit-approach) 展示了将LLM与外部工具接口的显式方法。'
- en: '![Explicit Approach](assets/dllm_1002.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![显式方法](assets/dllm_1002.png)'
- en: Figure 10-2\. The explicit interaction approach in action
  id: totrans-31
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-2。显式交互方法在实际操作中的表现
- en: Unlike in the passive approach, the LLM is no longer a passive participant.
    We provide the LLM with explicit instructions on how and when to invoke external
    data stores and tools. The LLM interacts with its environment based on a pre-programmed
    set of conditions. This approach is recommended when the interaction sequence
    is fixed, limited in scope, and preferably involves a very small number of steps.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 与被动方法不同，LLM不再是一个被动的参与者。我们向LLM提供如何以及何时调用外部数据存储和工具的明确指示。LLM根据预编程的条件集与其环境进行交互。当交互序列固定、范围有限且最好涉及非常少的步骤时，建议采用这种方法。
- en: 'For an AI data analyst assistant, an example interaction sequence could be:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 对于AI数据分析师助手，一个示例交互序列可以是：
- en: User expresses query in natural language asking to visualize some data trends
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户用自然语言表达查询，要求可视化某些数据趋势
- en: The LLM generates SQL to retrieve the data needed to resolve the user query
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LLM生成SQL以检索解决用户查询所需的数据
- en: After receiving the data, the LLM uses it to generate code that can be run by
    a code interpreter to generate statistics or visualizations
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在收到数据后，LLM使用它生成可以由代码解释器运行的代码，以生成统计数据或可视化
- en: '[Figure 10-3](#ai-data-analyst) shows a fixed interaction sequence implemented
    for an AI data analyst.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[图10-3](#ai-data-analyst) 展示了一个为AI数据分析师实现的固定交互序列。'
- en: '![ai-data-analyst](assets/dllm_1003.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![ai-data-analyst](assets/dllm_1003.png)'
- en: Figure 10-3\. An example workflow for an AI data analyst
  id: totrans-39
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-3。AI数据分析师的一个示例工作流程
- en: In this paradigm, the interaction sequence is predetermined and rule-based.
    The LLM exercises no agency in determining which step to take next. I recommend
    this approach for building robust applications that have stricter reliability
    requirements.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个范例中，交互序列是预先确定和基于规则的。LLM在决定下一步采取什么行动时没有任何自主权。我建议这种方法用于构建对可靠性要求更严格的应用程序。
- en: The Autonomous Approach
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自主方法
- en: '[Figure 10-4](#agentic-approach) shows how we can turn an LLM into an autonomous
    agent that can solve complex tasks by itself.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[图10-4](#agentic-approach) 展示了如何将LLM转变为一个可以自行解决复杂任务的自主代理。'
- en: '![Agentic Approach](assets/dllm_1004.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![代理方法](assets/dllm_1004.png)'
- en: Figure 10-4\. A typical autonomous LLM-driven agent workflow
  id: totrans-44
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-4。一个典型的由LLM驱动的自主代理工作流程
- en: 'The autonomous approach, or the Holy Grail approach as I like to call it, turns
    an LLM into an autonomous agent that can solve tasks on its own by interacting
    with its environment. Here is a typical workflow of an autonomous agent:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 自主的方法，或者像我喜欢称之为的圣杯方法，将LLM变成一个自主智能体，通过与环境交互自行解决任务。以下是一个自主智能体的典型工作流程：
- en: The user formulates their requirements in natural language, optionally providing
    the format in which they want the LLM to provide the answer.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户以自然语言形式提出他们的需求，可选地提供他们希望LLM提供答案的格式。
- en: The LLM decomposes the user query into manageable subtasks.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LLM将用户查询分解为可管理的子任务。
- en: The LLM synchronously or asynchronously solves each subtask of the problem.
    Where possible, the LLM uses its own memory and knowledge to solve a specific
    subtask. For subtasks where the LLM cannot answer on its own, it chooses a tool
    to invoke from a list of available tools. Where possible, the LLM uses the outputs
    from solutions of already executed subtasks as inputs to other subtasks.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LLM同步或异步地解决问题的每个子任务。在可能的情况下，LLM使用自己的记忆和知识来解决特定的子任务。对于LLM无法自行回答的子任务，它从可用工具列表中选择一个工具来调用。在可能的情况下，LLM使用已执行子任务的解决方案的输出作为其他子任务的输入。
- en: The LLM synthesizes the final answer using the solutions of the subtasks, generating
    the output in the requested output format.
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: LLM使用子任务的解决方案综合生成最终答案，并以请求的输出格式生成输出。
- en: This paradigm is general enough to capture just about any use case. It is also
    a risky paradigm, as we are assigning the LLM too much responsibility and agency.
    At this juncture, I would not recommend using this paradigm for any mission-critical
    applications.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 这种范式足够通用，可以涵盖几乎所有用例。它也是一个有风险的范式，因为我们正在赋予LLM过多的责任和权力。在这个阶段，我不建议将此范式用于任何关键任务应用。
- en: Note
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Why am I calling for caution in deploying agents? Humans often underestimate
    the accuracy requirements for applications. For a lot of use cases, getting it
    right 99% of the time is still not good enough, especially when the failures are
    unpredictable and the 1% of failures can be potentially catastrophic. The 99%
    problem is also the one that has long plagued self-driving cars and prevented
    their broader adoption. This doesn’t mean we can’t deploy autonomous LLM agents;
    we just need clever product design that can shield the user from their failures.
    We also need robust human-in-the-loop paradigms.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么我呼吁在部署智能体时要谨慎？人类往往低估了应用对准确性的要求。对于许多用例来说，99%的时间正确仍然不够好，尤其是在失败不可预测且1%的失败可能具有潜在灾难性时。99%的问题也是长期以来困扰自动驾驶汽车并阻碍其更广泛采用的问题。这并不意味着我们不能部署自主LLM智能体；我们只需要巧妙的产品设计，以保护用户免受其失败的影响。我们还需要强大的人机交互范式。
- en: We have used the word “agent” several times now without defining it. Let’s correct
    that and consider what agents mean and how we can build them.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经多次使用了“智能体”这个词，但没有对其进行定义。让我们纠正这一点，并考虑智能体的含义以及我们如何构建它们。
- en: Defining Agents
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义智能体
- en: 'As the hype starts building over LLM-based agents, the colloquial definition
    of agents has already started to expand from its traditional definition. This
    is because truly agentic systems are hard to build, so there is a tendency to
    shift the goalposts and claim best-effort systems to be already agentic even though
    they technically may not fit the requirements. In this book, we will stick to
    a more conservative definition of agents, defining them as:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 随着基于大型语言模型（LLM）的智能体（agents）的炒作开始升温，智能体的日常定义已经从其传统定义开始扩展。这是因为真正具有智能的系统很难构建，因此存在一种趋势，即调整目标并声称尽最大努力构建的系统已经是智能体，尽管从技术上讲它们可能不符合要求。在这本书中，我们将坚持对智能体更为保守的定义，将其定义为：
- en: LLM-driven software systems that are able to interact with their environment
    and take autonomous actions to complete a task.
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 能够与环境交互并采取自主行动以完成任务的大型语言模型驱动的软件系统。
- en: 'Key characteristics of agents are:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 智能体的关键特征包括：
- en: Their autonomous nature
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 它们的自主性
- en: The sequence of steps required to perform a task need not be specified to the
    agent. Agents can decide to perform any sequence of actions, unprompted by humans.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 执行任务所需的步骤不需要指定给智能体。智能体可以决定执行任何序列的行动，无需人类提示。
- en: Their ability to interact with their environment
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 它们与环境交互的能力
- en: Agents can be connected to external data sources and software tools, which allows
    agents to retrieve data, invoke tools, execute code, and provide instructions
    when appropriate to solve a task.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 代理可以连接到外部数据源和软件工具，这使得代理能够检索数据、调用工具、执行代码，并在适当的时候提供指令以解决问题。
- en: Note
  id: totrans-62
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Many definitions of “agent” do not require them to be autonomous. According
    to their definitions, applications following the explicit paradigm can also be
    called agents (albeit as non-autonomous or semi-autonomous agents).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 许多“代理”的定义并不要求它们是自主的。根据它们的定义，遵循显式范式的应用程序也可以被称为代理（尽管是非自主或半自主代理）。
- en: The agentic paradigm as we defined it is extremely powerful and general. Let’s
    take a moment to appreciate it. If an agent receives a task that it doesn’t know
    how to solve (and it *knows* that it doesn’t know), then instead of just giving
    up, it can potentially learn to solve the task by itself by searching the web
    or knowledge bases for pointers, or even by collecting data and fine-tuning a
    model that can help solve the task.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 我们定义的代理范式非常强大且通用。让我们花点时间来欣赏它。如果一个代理接到了一个它不知道如何解决的问题（并且它*知道*它不知道），那么它不会只是放弃，它可以通过在网络上或知识库中搜索线索，甚至通过收集数据并微调一个可以帮助解决问题的模型来学习自己解决问题。
- en: Given these enviable abilities, are machines going to take over the world? In
    practice, current autonomous agents are limited in what they can actually achieve.
    They tend to get stuck in loops, they take incorrect actions, and they are unable
    to reliably self-correct. It is more practical to build partially autonomous agents,
    where the LLM is provided with guidance throughout its workflow, either through
    agent orchestration software or with a human in the loop. For the rest of this
    chapter, our focus will be on building practical agents that can reliably solve
    a narrower class of tasks.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些令人羡慕的能力，机器会接管世界吗？在实践中，当前的自主代理在它们能实际实现的事情上有限。它们往往会陷入循环，采取错误的行为，并且无法可靠地自我纠正。构建部分自主代理更为实际，其中LLM在其工作流程中得到指导，无论是通过代理编排软件还是通过人工介入。在本章的剩余部分，我们将重点关注构建能够可靠解决更窄任务类别的实用代理。
- en: Agentic Workflow
  id: totrans-66
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代理工作流程
- en: 'Using our definition of agents, let’s explore how agents work in practice.
    As an example, let’s consider an agent that is asked to answer this question:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我们对代理的定义，让我们探讨代理在实际中的工作方式。作为一个例子，让我们考虑一个被要求回答这个问题的代理：
- en: Who was the CFO of Apple when its stock price was at its lowest point in the
    last 10 years?
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 在过去10年中，当苹果的股价处于最低点时，谁是苹果的CFO？
- en: Let’s say the agent has all the information it needs to solve this task. It
    has access to the web, to SQL databases containing stock price information, and
    to knowledge bases containing CFO tenure information. It is connected to a code
    interpreter so that it can generate and run code, and it has access to financial
    APIs. The system prompt contains details about all the tools and data stores the
    LLM has access to.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 假设代理拥有解决此任务所需的所有信息。它有权访问网络、包含股价信息的SQL数据库以及包含CFO任期信息的知识库。它连接到一个代码解释器，以便它可以生成和运行代码，并且它有权访问金融API。系统提示包含有关LLM可以访问的所有工具和数据存储的详细信息。
- en: 'To answer the given query, the LLM has to perform this sequence of steps:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答给定的查询，LLM必须执行以下步骤：
- en: To calculate the date range, it needs the current date. If this is not included
    in the system prompt, it either searches the web to find the current date or generates
    code for returning the system time, which is then executed by a code interpreter.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了计算日期范围，它需要当前日期。如果这个信息没有包含在系统提示中，它要么在网络上搜索以找到当前日期，要么生成代码以返回系统时间，然后由代码解释器执行。
- en: Using the current date, it finds the other end of the date range by executing
    a simple arithmetic operation by itself, or by generating code for it. Steps 1
    and 2 could be combined into a single program.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用当前日期，它通过执行一个简单的算术运算或为其生成代码来自己找到日期范围的另一端。步骤1和2可以合并成一个程序。
- en: It finds a database table in the available datastore list that contains stock
    price information. It retrieves the schema of the table, inserts it into the prompt,
    and generates a SQL query for finding the date when the stock price was at its
    minimum in the last 10 years.
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它在可用的数据存储列表中找到一个包含股价信息的数据库表。它检索该表的架构，将其插入到提示中，并生成一个SQL查询，以找到过去10年中股价最低的日期。
- en: With the date in hand, it needs to find the CFO of Apple on that date. It can
    call a search engine API to check if there is an explicit mention of the CFO on
    that particular date.
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拿到日期后，它需要找到那天苹果公司的CFO。它可以调用搜索引擎API来检查那天是否有关于CFO的明确提及。
- en: If the search engine query fails to provide a result, it finds a financial API
    in its tools list and retrieves and inserts the API documentation into its context.
    It then generates and invokes code for an API call to retrieve the list of Apple
    CFOs and their tenures.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果搜索引擎查询未能提供结果，它会在其工具列表中找到一个金融API，并检索并插入API文档到其上下文中。然后它生成并调用API调用的代码以检索苹果公司CFO及其任期的列表。
- en: It uses its arithmetic reasoning skills to find the CFO tenure that matches
    the date of the lowest stock price.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它利用其算术推理技能找到与最低股价日期相匹配的CFO任期。
- en: It generates the final answer. If there is a requested output format, it tries
    to adhere to that.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它生成最终答案。如果有请求的输出格式，它会尽量遵守。
- en: Depending on the implementation, the sequence of steps could vary slightly.
    For example, you can fine-tune a model so that it can generate code for API calls
    or SQL queries directly without having to retrieve the schema from a data store
    or API.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 根据实现方式，步骤的顺序可能会有所不同。例如，你可以微调一个模型，使其能够直接生成API调用或SQL查询的代码，而无需从数据存储或API检索模式。
- en: To perform the given sequence of tasks, the model should first understand that
    the given task needs to be decomposed into a series of subtasks. This is called
    task decomposition. Task decomposition and planning can be performed by the LLM
    or offloaded to an external tool.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行给定的任务序列，模型首先应该理解给定的任务需要分解成一系列子任务。这被称为任务分解。任务分解和规划可以由LLM执行，也可以外包给外部工具。
- en: Components of an Agentic System
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 代理系统的组件
- en: 'While the specific architecture of any given agentic system depends heavily
    on the use cases it is intended to support, each of its components can be classified
    into one of the following types:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然任何给定代理系统的具体架构在很大程度上取决于它打算支持的使用案例，但每个组件都可以归类为以下类型之一：
- en: Models
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型
- en: Tools
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工具
- en: Data stores
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据存储
- en: Agent loop prompt
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 代理循环提示
- en: Guardrails and verifiers
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 防护栏和验证器
- en: Orchestration software
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编排软件
- en: '[Figure 10-5](#agentic-system) shows a canonical agentic system and how its
    components interact.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '[图10-5](#agentic-system)展示了典型的代理系统及其组件的交互方式。'
- en: '![agentic-system](assets/dllm_1005.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![代理系统](assets/dllm_1005.png)'
- en: Figure 10-5\. A production-grade agentic system
  id: totrans-90
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-5. 一套生产级代理系统
- en: Let’s explore each of these types.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐一探索这些类型。
- en: Models
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型
- en: Language models are the backbone of agentic systems, responsible for their autonomous
    nature and problem-solving capabilities. A single agentic system could be composed
    of multiple language models, with each model playing a distinct role.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 语言模型是代理系统的骨架，负责其自主性和问题解决能力。一个代理系统可能由多个语言模型组成，每个模型都扮演着不同的角色。
- en: For example, you can build an agent consisting of two models; one model solves
    user tasks and another model takes its output and converts it into a structured
    form according to user requirements.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可以构建一个由两个模型组成的代理；一个模型解决用户任务，另一个模型将其输出转换为用户要求的结构化形式。
- en: Tip
  id: totrans-95
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Agentic workflows can consume a lot of language model tokens, which can be cost
    prohibitive. To keep costs under control, consider using multiple language models
    of different sizes, with the smaller (and cheaper) models performing easier tasks.
    For more details on how to accomplish division of labor among these models, see
    [Chapter 13](ch13.html#ch13).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 代理工作流程可能会消耗大量的语言模型令牌，这可能会变得成本高昂。为了控制成本，考虑使用不同大小的多个语言模型，其中较小的（且更便宜的）模型执行更简单的任务。有关如何在这些模型之间完成劳动分工的更多详细信息，请参阅[第13章](ch13.html#ch13)。
- en: More generally, you can build agents with specialized models catering to each
    part of the agentic workflow. For example, a code-LLM can be used to generate
    code, and task-specific fine-tuned models that specialize in individual workflow
    steps can be used. This setup can be interpreted as a *multi-agent architecture*.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 更普遍地，你可以构建专门针对代理工作流程各个部分的代理。例如，代码-LLM可以用来生成代码，而针对特定任务的微调模型可以用于单个工作流程步骤。这种设置可以解释为*多代理架构*。
- en: '[Figure 10-6](#multi-agent-setup) shows an agentic system made up of multiple
    LLMs.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[图10-6](#multi-agent-setup)展示了由多个LLM组成的代理系统。'
- en: '![multi-agent-setup](assets/dllm_1006.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![多代理设置](assets/dllm_1006.png)'
- en: Figure 10-6\. An agentic system with multiple LLMs
  id: totrans-100
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图10-6\. 具有多个LLM的代理系统
- en: Finally, any kind of model, including non-LLMs, can be plugged into an agentic
    system to solve specific tasks. For example, the planning stage can be performed
    using [symbolic planners](https://oreil.ly/sXPWG).
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，任何类型的模型，包括非LLM模型，都可以插入到代理系统中以解决特定任务。例如，规划阶段可以使用[符号规划器](https://oreil.ly/sXPWG)。
- en: Tools
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 工具
- en: As described earlier, software or models that can be invoked by an LLM are called
    tools. Libraries like [LangChain](https://oreil.ly/35Lgu) and [LlamaIndex](https://oreil.ly/WF-d1)
    provide connectors to various software interfaces, including code interpreters,
    search engines, databases, ML models, and a variety of APIs. Let’s explore how
    to work with some of these in practice.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，可以被LLM调用的软件或模型被称为工具。例如，[LangChain](https://oreil.ly/35Lgu)和[LlamaIndex](https://oreil.ly/WF-d1)等库提供了连接到各种软件接口的连接器，包括代码解释器、搜索引擎、数据库、机器学习模型和各种API。让我们探讨如何在实践中使用其中的一些。
- en: Web search
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 网络搜索
- en: 'LangChain provides connectors for major search engines like Google, Bing, and
    DuckDuckGo. Let’s try out DuckDuckGo:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: LangChain为像Google、Bing和DuckDuckGo这样的主要搜索引擎提供了连接器。让我们尝试使用DuckDuckGo：
- en: '[PRE0]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The response can be fed back to the language model where it is further processed.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 响应可以反馈给语言模型，在那里它将得到进一步处理。
- en: API connectors
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: API连接器
- en: 'To illustrate calling APIs, we will showcase LangChain’s Wikipedia API wrapper:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明调用API，我们将展示LangChain的维基百科API包装器：
- en: '[PRE1]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The `load()` function runs a search on Wikipedia and returns the page text and
    metadata information of the top-k results. (top-k = 3 by default). You can also
    use the `run()` function to return only page summaries of the top-k matches.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '`load()`函数在维基百科上运行搜索，并返回前k个结果的页面文本和元数据信息。（默认为top-k = 3）。您也可以使用`run()`函数仅返回前k个匹配项的页面摘要。'
- en: Code interpreter
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 代码解释器
- en: 'Next, let’s explore how you can invoke a code interpreter and run arbitrary
    code:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们探索如何调用代码解释器并运行任意代码：
- en: '[PRE2]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Warning
  id: totrans-115
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Be wary of running code generated by LLMs in response to user prompts. Users
    can induce the model to generate malicious code!
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 谨慎运行LLM对用户提示生成的代码。用户可以诱导模型生成恶意代码！
- en: Database connectors
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据库连接器
- en: 'Finally, let’s check out how to connect to a database and run queries:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们看看如何连接到数据库并运行查询：
- en: '[PRE3]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `run()` function executes the provided SQL query and returns the response
    as a string. Replace `*DATABASE_URI*` with your own database and queries, and
    verify the responses.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`run()`函数执行提供的SQL查询，并将响应作为字符串返回。将`*DATABASE_URI*`替换为您自己的数据库和查询，并验证响应。'
- en: Tip
  id: totrans-121
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: For more customizability, you can fork the LangChain connectors and repurpose
    them for your own use.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高可定制性，您可以分叉LangChain连接器并将它们重新用于自己的用途。
- en: Next, let’s see how we can interface LLMs with these tools in an agentic workflow.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看如何在代理工作流程中与这些工具接口LLM。
- en: First, we need to make the LLM aware that it has access to these tools. One
    of the ways to achieve this is to provide the names and short descriptions of
    the tools, called the *tool list*, to the LLM through the system prompt.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要让LLM知道它有权访问这些工具。实现这一目标的一种方法是通过系统提示向LLM提供工具的名称和简短描述，称为*工具列表*。
- en: Next, the LLM needs to be able to select the right tool at the appropriate juncture
    in the workflow. For example, if the next step in solving a task is to find the
    weather in Chicago this evening, the web search tool has to be invoked rather
    than the Wikipedia one. Later in this chapter, we will discuss techniques to help
    the LLM select the right tool.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，LLM需要能够在工作流程的适当节点选择正确的工具。例如，如果解决任务的下一步是查找今晚芝加哥的天气，则需要调用网络搜索工具而不是维基百科工具。在本章的后面部分，我们将讨论帮助LLM选择正确工具的技术。
- en: Under the hood, tool invocation is typically achieved by the LLM generating
    special tokens indicating that it is entering tool invocation mode, along with
    tokens representing the tool functions and arguments to be invoked. The actual
    tool invocation is performed by an agent orchestration framework.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在底层，工具调用通常是通过LLM生成特殊令牌来实现的，这些令牌表示它正在进入工具调用模式，以及表示要调用的工具功能和参数的令牌。实际的工具调用是由代理编排框架执行的。
- en: 'In LangChain, we can make a tool available to an LLM and have it invoked:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在LangChain中，我们可以使工具对LLM可用，并调用它：
- en: '[PRE4]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Some models come with native tool-calling abilities. For models that don’t,
    you can fine-tune the base model to impart them with tool-calling abilities. Among
    open models, Llama 3.1 Instruct (8B/70B/405B) is an example of a model having
    native tool-calling support. Here’s how tool calling works with Llama 3.1.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 一些模型自带工具调用能力。对于没有这种能力的模型，您可以微调基础模型以赋予它们工具调用能力。在开源模型中，Llama 3.1 Instruct (8B/70B/405B)是一个具有原生工具调用支持的模型的例子。以下是Llama
    3.1中工具调用是如何工作的。
- en: 'Llama 3.1 comes with native support for three tools: Brave web search, Wolfram|Alpha
    mathematical engine, and a code interpreter. These can be *activated* by defining
    them in the system prompt:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Llama 3.1自带对三个工具的原生支持：Brave网络搜索、Wolfram|Alpha数学引擎和代码解释器。这些工具可以通过在系统提示中定义它们来*激活*。
- en: '[PRE5]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Let’s ask the LLM a question by appending a user prompt to the system prompt:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将用户提示附加到系统提示中，让我们向LLM提出一个问题：
- en: '[PRE6]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Llama 3.1 responds with a tool invocation that looks like this:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Llama 3.1以如下方式响应工具调用：
- en: '[PRE7]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `<|python_tag|>` token is a special token generated by Llama 3.1 to indicate
    that it is entering tool-calling mode. The `<|eom_id|>` special token indicates
    that the model has not ended its turn yet and will wait to be fed with the results
    of the tool invocation.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`<|python_tag|>`标记是由Llama 3.1生成的特殊标记，用于指示它正在进入工具调用模式。`<|eom_id|>`特殊标记表示模型尚未结束其回合，并将等待接收工具调用的结果。'
- en: 'You can also provide your own tools in the prompt: using JSON is recommended.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 您也可以在提示中提供自己的工具：建议使用JSON。
- en: Tip
  id: totrans-138
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: If you have a lot of tools, then the detailed descriptions of the tools can
    be represented in a data store and retrieved only if they are selected. The prompt
    then needs to contain only the name of the tool and a short description.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有很多工具，那么工具的详细描述可以表示在数据存储中，并且只有在选择时才检索。此时，提示信息只需要包含工具的名称和简短描述。
- en: 'Here is an example of a tool definition in JSON describing a local function
    that can be called:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个工具定义的JSON示例，描述了一个可以调用的本地函数：
- en: '[PRE8]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The tool call is generated by the model in JSON with the prescribed format.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 工具调用由模型以规定的格式在JSON中生成。
- en: Note
  id: totrans-143
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The actual tool invocation is performed by an agent orchestration software.
    Llama 3.1 comes with [llama-stack-apps](https://oreil.ly/SSmkI), a library that
    facilitates agentic workflows.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 实际的工具调用是由代理编排软件执行的。Llama 3.1附带[llama-stack-apps](https://oreil.ly/SSmkI)，这是一个库，它简化了代理工作流程。
- en: Sometimes the tool call can be more complex than just returning the name of
    a function and its arguments. An example of this is querying a database. For the
    LLM to generate the right SQL query, you should provide the schema of the database
    tables in the system prompt. If the database has too many tables, then their schema
    can be retrieved on demand by the LLM.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 有时工具调用可能比仅仅返回函数名称及其参数更复杂。一个例子是查询数据库。为了使LLM生成正确的SQL查询，您应该在系统提示中提供系统数据库表的架构。如果数据库有太多的表，那么它们的架构可以由LLM按需检索。
- en: Tip
  id: totrans-146
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: You can use a separate specialized model for code and SQL query generation.
    A general-purpose model can generate a textual description of the desired outcome,
    and this can be used as input to a code LLM or an LLM fine-tuned on text-to-SQL.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用一个专门的模型来生成代码和SQL查询。一个通用模型可以生成所需结果的文本描述，这可以用来作为输入到代码LLM或文本到SQL的LLM微调。
- en: For large-scale or high-stakes applications, you can fine-tune your models to
    make them better at tool use. A good fine-tuning recipe to follow is Qin et al.’s
    [ToolLLaMA](https://oreil.ly/Ewlxt).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 对于大规模或高风险的应用，您可以微调您的模型以使其在工具使用方面表现得更好。一个值得遵循的良好微调方案是Qin等人提出的[ToolLLaMA](https://oreil.ly/Ewlxt)。
- en: Data Stores
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据存储
- en: A typical agent may need to interact with several types of data sources to accomplish
    its tasks. Commonly used data sources include prompt repositories, session memory,
    and tools data.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 一个典型的代理可能需要与几种类型的数据源交互以完成其任务。常用的数据源包括提示仓库、会话内存和工具数据。
- en: Prompt repository
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示仓库
- en: A prompt repository is a collection of detailed prompts instructing the language
    model how to perform a specific task. If you can anticipate the types of tasks
    that an agent will be asked to perform while in production, you can construct
    prompts providing detailed instructions on how to solve them. The prompts can
    even include directions on how to advance a specific workflow. Let’s look at an
    example.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 提示存储库是一组详细的提示，指导语言模型如何执行特定任务。如果你能预测代理在生产过程中将被要求执行的任务类型，你可以构建提供如何解决这些任务的详细说明的提示。提示甚至可以包括如何推进特定工作流程的指示。让我们通过一个例子来看看。
- en: 'Many language models struggle with basic arithmetic operations, even simple
    questions like:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 许多语言模型在基本算术运算上都有困难，即使是像以下这样的简单问题：
- en: '[PRE9]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Until recently, even state-of-the-art language models claimed that 9.11 is greater
    than 9.9\. (They were recently updated with a fix after this limitation went viral
    on [social media](https://oreil.ly/ztWGW).)
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 直到最近，即使是最先进的语言模型也声称9.11大于9.9。（在这一点局限性在[社交媒体](https://oreil.ly/ztWGW)上广为流传后，它们最近进行了更新以修复这个问题。）
- en: 'If you are aware of such limitations that are relevant to your use case, then
    you can mitigate a proportion of them using detailed prompts. For the number comparison
    issue, for example:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你了解与你的用例相关的此类限制，那么你可以通过详细的提示减轻其中一部分。例如，对于数字比较问题：
- en: '*Prompt:* If you are asked to compare two numbers using the greater than/lesser
    than operation, then perform the following:'
  id: totrans-157
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 如果你被要求使用大于/小于操作比较两个数字，那么请执行以下操作：'
- en: ''
  id: totrans-158
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Take the two numbers and ensure they have the same number of decimal places.
    After that, subtract one from the other. If the result is a positive number, then
    the first number is greater. If the result is a negative number, then the second
    number is greater. If the result is zero, the two numbers are equal.
  id: totrans-159
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 取这两个数字并确保它们有相同的小数位数。然后，从其中一个减去另一个。如果结果是正数，则第一个数字更大。如果结果是负数，则第二个数字更大。如果结果是零，则两个数字相等。
- en: Now, if the agent needs to perform a task that includes number comparison, it
    first retrieves this prompt from the prompt repository. This enables it to overcome
    its inherent limitation, as it will follow the detailed step-by-step instructions
    in the prompt.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果代理需要执行一个包含数字比较的任务，它首先从提示存储库中检索这个提示。这使得它能够克服其固有的限制，因为它将遵循提示中的详细步骤说明。
- en: Note
  id: totrans-161
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Why don’t we just add all these prompts to the context window, thus eschewing
    retrieval? For one, the prompts may be too numerous and may not fit within the
    context window. Secondly, tokens are expensive, and it is inefficient to include
    prompts that may not be relevant to the current task. Finally, language models
    can adhere to only a limited set of concurrent instructions, so it is more efficient
    to retrieve them on demand.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 我们为什么不把这些提示都添加到上下文窗口中，从而避免检索呢？首先，提示可能太多，可能不适合上下文窗口。其次，标记很昂贵，包含可能不与当前任务相关的提示是不高效的。最后，语言模型只能遵循有限数量的并发指令，因此按需检索它们更有效率。
- en: Prompts can also include input-output examples, known as few-shot learning,
    as introduced in [Chapter 1](ch01.html#chapter_llm-introduction). Agents can retrieve
    them on demand to help accomplish their tasks. We will discuss effective ways
    of retrieving relevant examples in [Chapter 12](ch12.html#ch12).
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 提示还可以包括输入-输出示例，称为少样本学习，如[第1章](ch01.html#chapter_llm-introduction)中介绍的那样。代理可以按需检索它们以帮助完成任务。我们将在[第12章](ch12.html#ch12)中讨论检索相关示例的有效方法。
- en: Next, let’s explore how agents use session memory to advance their goals.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们探讨代理如何使用会话记忆来实现他们的目标。
- en: Session memory
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 会话记忆
- en: 'We would like to store logs of the steps undertaken by the agent during current
    and past sessions. These logs can also be augmented with feedback from verification
    processes, both automated and human. The agent can then retrieve session logs
    for better context understanding and as a guide to determine next actions in the
    current workflow. Let’s explore this with an example:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望存储代理在当前和过去会话中采取的步骤的日志。这些日志还可以通过来自验证过程的反馈进行增强，包括自动和人工的。然后，代理可以检索会话日志以更好地理解上下文，并作为确定当前工作流程中下一步行动的指南。让我们通过一个例子来探讨这个问题：
- en: '*Prompt:* Is it going to be warmer tomorrow than today in Paris? Give me details
    in Celsius.'
  id: totrans-167
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 明天巴黎的气温会比今天高吗？请用摄氏度提供详细信息。'
- en: 'The agent goes through a sequence of steps to solve this query, which is all
    logged in the session history. The session history for this query might look like
    this:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 代理通过一系列步骤来解决这个查询，这些步骤都记录在会话历史中。这个查询的会话历史可能看起来像这样：
- en: '*User prompt*: Is it going to be warmer tomorrow than today in Paris? Give
    me details in Celsius.'
  id: totrans-169
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*用户提示*: 明天巴黎会比今天更暖和吗？请以摄氏度提供详细信息。'
- en: ''
  id: totrans-170
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*LLM observation*: The user has a preference for Celsius units for temperature
    data.'
  id: totrans-171
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*LLM 观察*: 用户偏好摄氏度单位用于温度数据。'
- en: ''
  id: totrans-172
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*LLM Output*: Let’s perform this step-by-step.'
  id: totrans-173
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*LLM 输出*: 让我们一步一步地执行这个操作。'
- en: ''
  id: totrans-174
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: First, let’s retrieve today’s temperature.
  id: totrans-175
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们检索今天的温度。
- en: ''
  id: totrans-176
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-177
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Next, let’s retrieve tomorrow’s temperature.
  id: totrans-178
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，让我们检索明天的温度。
- en: ''
  id: totrans-179
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-180
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: We calculate the difference and generate the answer.
  id: totrans-181
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们计算差异并生成答案。
- en: ''
  id: totrans-182
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-183
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-184
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*External verifier*: Task decomposition is correct'
  id: totrans-185
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*外部验证器*: 任务分解是正确的'
- en: ''
  id: totrans-186
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Tool selection:* <WeatherAPI> selected'
  id: totrans-187
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*工具选择:* <WeatherAPI> 被选中'
- en: ''
  id: totrans-188
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Tool info retrieval*: Retrieve information relevant to the query *Find temperature
    data from <WeatherAPI>*'
  id: totrans-189
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*工具信息检索*: 检索与查询相关的信息 *从 <WeatherAPI> 查找温度数据*'
- en: ''
  id: totrans-190
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Tool invocation*: get_temperature_curweek(*Paris*)'
  id: totrans-191
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*工具调用*: get_temperature_curweek(*Paris*)'
- en: ''
  id: totrans-192
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Tool output* : Weather data - Paris…​'
  id: totrans-193
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*工具输出* : 天气数据 - 巴黎…'
- en: ''
  id: totrans-194
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*LLM output*: Today’s temperature is 27 degrees Celsius. Tomorrow’s forecast
    is 23 degrees Celsius. Therefore, tomorrow is not going to be warmer in Paris
    than today.'
  id: totrans-195
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*LLM 输出*: 今天的温度是 27 摄氏度。明天的天气预报是 23 摄氏度。因此，明天的巴黎不会比今天更暖和。'
- en: ''
  id: totrans-196
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*External Verifier*: Arithmetic operation is correct.'
  id: totrans-197
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*外部验证器*: 算术操作是正确的。'
- en: ''
  id: totrans-198
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*Agent*: LLM output is dispatched to the user'
  id: totrans-199
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*代理*: 将 LLM 输出发送给用户'
- en: ''
  id: totrans-200
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*User feedback*: User marked this as correct'
  id: totrans-201
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*用户反馈*: 用户标记此为正确'
- en: As we can see, session history can contain very rich information that can provide
    valuable personalized context to the LLM about the current user as well as guide
    the model toward the correct agentic workflow.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，会话历史可以包含非常丰富的信息，这些信息可以为 LLM 提供有关当前用户的宝贵个性化上下文，并指导模型走向正确的代理工作流程。
- en: In more advanced implementations, multiple levels of logging can be defined,
    so that during retrieval, one can retrieve all the logs of a session or only the
    important steps, based on the logging level specified.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在更高级的实现中，可以定义多个日志级别，因此在检索过程中，可以根据指定的日志级别检索会话的所有日志或仅检索重要步骤。
- en: Tip
  id: totrans-204
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Along with session history, the agent could also be provided with access to
    gold-truth training examples representing correct workflows, which can be used
    by the agent to guide its trajectory during test time.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 除了会话历史之外，代理还可以获得访问代表正确工作流程的黄金真实训练示例的权限，这些示例可以在测试时间由代理用来指导其轨迹。
- en: Session memory can also include records of interaction between the human and
    the agentic system. These can be used to personalize models. We will discuss this
    further in [Chapter 12](ch12.html#ch12).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 会话记忆还可以包括人类与代理系统之间交互的记录。这些可以用来个性化模型。我们将在第 12 章[Chapter 12](ch12.html#ch12)中进一步讨论这一点。
- en: Next, let’s explore how the agent can interact with tools data.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们探索代理如何与工具数据交互。
- en: Tools data
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工具数据
- en: Tools data comprise detailed information necessary to invoke a tool, such as
    database schemas, API documentation, sample API calls, and more. When the agent
    decides to invoke a tool, the model retrieves the pertinent tool information from
    the tools data store.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 工具数据包括调用工具所需的详细信息的必要信息，例如数据库模式、API 文档、示例 API 调用等等。当代理决定调用工具时，模型从工具数据存储中检索相关的工具信息。
- en: For example, consider a SQL tool for retrieving data from a database. To generate
    the right SQL query, the model could retrieve the database schema from the tools
    data store. The tools data contains information about the tables and columns,
    the descriptions of each column and their data types, and optionally information
    about indices and primary/secondary keys.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑一个用于从数据库中检索数据的 SQL 工具。为了生成正确的 SQL 查询，模型可以从工具的数据存储中检索数据库模式。工具数据包含有关表和列的信息，每个列的描述及其数据类型，以及可选的索引和主/次键信息。
- en: Note
  id: totrans-211
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: You can also fine-tune the LLM on a dataset representing valid SQL queries to
    your database, which can potentially remove the need to consult the schema before
    generating a query.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 您还可以在代表您数据库的有效 SQL 查询数据集上微调 LLM，这可能会在生成查询之前消除咨询模式的需求。
- en: To sum it up, agents can use data stores in several ways. They can access prompts
    and few-shot examples from a prompt repository, they can access agentic workflow
    history and intermediate outputs by models in previous sessions for better personalized
    context understanding and workflow guidance, and they can access tool documentation
    to invoke tools correctly.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，代理可以使用几种方式使用数据存储。他们可以从提示存储库访问提示和少量示例，他们可以通过模型访问之前会话中的代理工作流程历史和中间输出，以更好地实现个性化上下文理解和工作流程指导，他们还可以访问工具文档以正确调用工具。
- en: Agents can also access external knowledge from the web, databases, knowledge
    graphs, etc. Retrieving the right information from these sources is an entire
    sub-system unto itself. We will discuss the mechanics of retrieval in Chapters
    [11](ch11.html#chapter_llm_interfaces) and [12](ch12.html#ch12).
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 代理还可以从网络、数据库、知识图谱等外部知识中获取信息。从这些来源检索正确信息是一个完整的子系统。我们将在第[11](ch11.html#chapter_llm_interfaces)章和第[12](ch12.html#ch12)章中讨论检索的机制。
- en: We will now discuss the agent loop prompt, which is responsible for driving
    the LLM’s behavior during an agentic session.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将讨论代理循环提示，它负责在代理会话期间驱动LLM的行为。
- en: Agent Loop Prompt
  id: totrans-216
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代理循环提示
- en: Recall that LLMs do not have session memory. But a typical agentic workflow
    relies on several LLM calls! We need a mechanism to provide information about
    session state and the expected role of the LLM at any given time in the session.
    This agent loop is driven by a system prompt.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，LLMs没有会话记忆。但典型的代理工作流程依赖于几个LLM调用！我们需要一种机制来提供有关会话状态和LLM在会话中任何给定时间的预期角色的信息。这个代理循环由系统提示驱动。
- en: 'An example of a simple agent loop system prompt is:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的代理循环系统提示示例是：
- en: '*Prompt:* You are an AI model currently answering questions. You have access
    to the following tools: {tool_description}. For each question, you can invoke
    one or more tools where necessary to access information or execute actions. You
    can invoke a tool in this format: <TOOLNAME> <Tool Arguments>. The results of
    these tool calls are not provided to the user. When you are ready with the final
    answer, output the answer using the <Answer> tag.'
  id: totrans-219
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 你是一个正在回答问题的AI模型。你可以访问以下工具：{工具描述}。对于每个问题，你可以在必要时调用一个或多个工具来获取信息或执行操作。你可以使用以下格式调用一个工具：<TOOLNAME>
    <工具参数>。这些工具调用的结果不会提供给用户。当你准备好最终答案时，使用<Answer>标签输出答案。'
- en: I find that a prompt like this is sufficient for most use cases. However, if
    you feel like the model is not reasoning correctly, you can try ReAct prompting.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现这样的提示对于大多数用例来说已经足够了。然而，如果你觉得模型推理不正确，你可以尝试ReAct提示。
- en: ReAct
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ReAct
- en: 'At the time of this writing, ReAct (Reasoning + Acting) prompting is the most
    popular prompt for the agent loop. A typical ReAct prompt looks like this:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，ReAct（推理+行动）提示是代理循环中最受欢迎的提示。一个典型的ReAct提示如下：
- en: '*Prompt:* You are an AI assistant capable of reasoning and acting. For each
    question, follow this process:'
  id: totrans-223
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 你是一个能够推理和行动的AI助手。对于每个问题，遵循以下流程：'
- en: ''
  id: totrans-224
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Thought: Reflect on the current state and plan your next steps.'
  id: totrans-225
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 思考：反思当前状态并规划你的下一步行动。
- en: ''
  id: totrans-226
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-227
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Action: Execute the steps to gather information or call tools.'
  id: totrans-228
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 行动：执行收集信息或调用工具的步骤。
- en: ''
  id: totrans-229
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-230
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Observation: Record the results of your actions.'
  id: totrans-231
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 观察：记录你行动的结果。
- en: ''
  id: totrans-232
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-233
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Final Answer: If you have an answer, provide a final response. Else continue
    the Thought → Action → Observation → loop until you have an answer.'
  id: totrans-234
  prefs:
  - PREF_BQ
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终答案：如果你有答案，提供最终响应。如果没有答案，继续思考 → 行动 → 观察 → 循环，直到你有一个答案。
- en: Despite its popularity, ReAct prompting has been shown to be [brittle](https://oreil.ly/RRZO9).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管ReAct提示很受欢迎，但它已被证明是[脆弱的](https://oreil.ly/RRZO9)。
- en: Reflection
  id: totrans-236
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 反思
- en: The agent loop may include self-verification or correction steps. This was pioneered
    by [Shinn et al.](https://oreil.ly/xFVt0) with the Reflexion paradigm.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 代理循环可能包括自我验证或纠正步骤。这是由Shinn等人通过反思范式开创的。
- en: 'Here is the system prompt for [Reflection-Llama-3.1](https://oreil.ly/foB-P)
    that uses reflection techniques:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是使用反思技术的[Reflection-Llama-3.1](https://oreil.ly/foB-P)系统提示：
- en: '*Prompt:* You are a world-class AI system, capable of complex reasoning and
    reflection. Reason through the query inside <thinking> tags, and then provide
    your final response inside <output> tags. If you detect that you made a mistake
    in your reasoning at any point, correct yourself inside <reflection> tags.'
  id: totrans-239
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '*提示:* 你是一个世界级的AI系统，能够进行复杂的推理和反思。在<思考>标签内推理查询，然后在<输出>标签内提供你的最终回答。如果你在任何时候检测到你的推理中存在错误，请在<反思>标签内纠正自己。'
- en: The <reflection> tags are meant for the model to self-introspect and self-correct.
    We can also specify conditions when <reflection> tags should be activated, for
    example, when the agent performs the same action consecutively more than three
    times (which might mean it is stuck in a loop).
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: <反思>标签的目的是让模型进行自我反思和自我纠正。我们还可以指定何时激活<反思>标签的条件，例如，当代理连续执行同一动作超过三次（这可能意味着它陷入了循环）时。
- en: Warning
  id: totrans-241
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: The effectiveness of reflection-based methods are overstated. They might do
    more harm than good if they are invoked too often, causing the model to second-guess
    solutions.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 反思方法的功效被夸大了。如果它们被频繁调用，可能会造成更多伤害而不是好处，导致模型对解决方案产生怀疑。
- en: Next, let’s discuss guardrails and verifiers, components that ensure that an
    agentic system can thrive in production.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们讨论护栏和验证器，这些组件确保代理系统可以在生产中茁壮成长。
- en: Guardrails and Verifiers
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 护栏和验证器
- en: In production environments, mistakes can be catastrophic. Depending on the use
    case, the agent might need to adhere to strict standards in factuality, safety,
    accuracy, and many other criteria.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产环境中，错误可能是灾难性的。根据用例，代理可能需要遵守事实性、安全性、准确性以及许多其他标准的严格标准。
- en: Safety is ensured by using guardrails, components that ensure models do not
    overstep their bounds during the course of their workflows. Some examples of guardrails
    include toxic language detectors, personally identifiable information (PII) detectors,
    input filters that restrict the type of queries users are permitted to make, and
    more.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 安全性通过使用护栏来确保，这些组件确保模型在其工作流程过程中不会超出其界限。一些护栏的例子包括有害语言检测器、个人身份信息（PII）检测器、限制用户可以执行的查询类型的输入过滤器，等等。
- en: Verifiers ensure that quality standards of the agentic system are so that the
    agent is able to recover and self-correct from mistakes. As agentic systems are
    still in their infancy, the importance of good and well-placed verifiers is paramount.
    Verifiers can be as simple as token-matching tools but can also be fine-tuned
    models, symbolic verifiers, and so on.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 验证器确保代理系统的质量标准，使得代理能够从错误中恢复并自我纠正。由于代理系统仍处于起步阶段，良好的和位置恰当的验证器的重要性是至关重要的。验证器可以是简单的令牌匹配工具，也可以是微调模型、符号验证器等等。
- en: Let’s learn more about guardrails and verifiers.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更多地了解护栏和验证器。
- en: Safety Guardrails
  id: totrans-249
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安全护栏
- en: Recall from [Chapter 2](ch02.html#ch02) that LLMs are trained largely on human-generated
    web text. Unfortunately a significant proportion of human-generated text contains
    toxic, abusive, violent, or pornographic content. We do not want our LLM applications
    to generate content that violates the safety of the user, nor do we want users
    to misuse the model to generate unsafe content. While we can certainly use techniques
    like alignment training to make the model less likely to emit harmful content,
    we cannot guarantee 100% success and therefore need to institute inference-time
    guardrails to ensure safe usage. Libraries like [Guardrails](https://oreil.ly/F7yax)
    and NVIDIA’s [NeMo-Guardrails](https://oreil.ly/p7Dqz), and models like [Llama
    Guard](https://oreil.ly/8S08P) facilitate setting up these guardrails.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 从[第二章](ch02.html#ch02)回忆一下，LLMs主要是在人类生成的网络文本上训练的。不幸的是，人类生成的文本中有相当一部分包含有害、侮辱性、暴力或色情内容。我们不希望我们的LLM应用生成违反用户安全的内容，也不希望用户滥用模型生成不安全的内容。虽然我们可以使用对齐训练等技术来降低模型产生有害内容的可能性，但我们不能保证100%的成功，因此需要建立推理时护栏以确保安全使用。像[Guardrails](https://oreil.ly/F7yax)这样的库和NVIDIA的[NeMo-Guardrails](https://oreil.ly/p7Dqz)以及像[Llama
    Guard](https://oreil.ly/8S08P)这样的模型有助于设置这些护栏。
- en: 'The Guardrails library provides a large (and growing) number of data validators
    to ensure safety and validity of LLM inputs and outputs. Here are some important
    ones:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: Guardrails库提供大量（且不断增长）的数据验证器，以确保LLM输入和输出的安全性和有效性。以下是一些重要的例子：
- en: Detect PII
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 检测PII
- en: This validator can be used to detect personally identifiable information in
    both the input and output text. [Microsoft Presidio](https://oreil.ly/eG8T1) is
    employed under the hood to perform the PII identification.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 此验证器可用于检测输入和输出文本中的个人身份信息。底层使用[Microsoft Presidio](https://oreil.ly/eG8T1)来执行PII识别。
- en: Prompt injection
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: Prompt injection
- en: This validator can detect certain types of adversarial prompting and thus can
    be used to prevent users from misusing the LLM. The [Rebuff](https://oreil.ly/nIyE5)
    library is used under the hood to detect prompt injection.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 此验证器可以检测某些类型的对抗性提示，因此可以用来防止用户滥用LLM。底层使用[Rebuff](https://oreil.ly/nIyE5)库来检测提示注入。
- en: Not safe for work (NSFW) text
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 不适合工作场所（NSFW）文本
- en: This validator detects NSFW text in the LLM output. This includes text with
    profanity, violence, and sexual content. The *Profanity free* validator also exists
    for detecting only profanity in text.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 此验证器检测LLM输出中的NSFW文本。这包括包含粗俗、暴力和性内容的文本。还有一个*Profanity free*验证器，用于检测文本中的粗俗语言。
- en: Politeness check
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 礼貌检查
- en: This validator checks if the LLM output text is sufficiently polite. A related
    validator is *Toxic language*.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 此验证器检查LLM输出文本是否足够礼貌。相关验证器是*Toxic language*。
- en: Web sanitization
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: Web sanitization
- en: This validator checks the LLM output for any security vulnerabilities, including
    if it contains code that can be executed in a browser. The [Bleach](https://oreil.ly/r3Xrl)
    library is used under the hood to find potential vulnerabilities and sanitize
    the output.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 此验证器检查LLM输出中的任何安全漏洞，包括是否包含可以在浏览器中执行的代码。底层使用[Bleach](https://oreil.ly/r3Xrl)库来查找潜在漏洞并清理输出。
- en: 'What happens if the validation checks fail and there is indeed harmful content
    in the input or output? Guardrails provides a few options:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 如果验证检查失败，并且输入或输出中确实存在有害内容，会发生什么？Guardrails提供了一些选项：
- en: Re-ask
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: Re-ask
- en: In this method, the LLM is asked to regenerate the output, with the prompt containing
    instructions to specifically abide by the criteria on which the output previously
    failed validation.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在此方法中，请求LLM重新生成输出，提示包含具体遵守之前输出验证失败的标准。
- en: Fix
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: Fix
- en: In this method, the library fixes the output by itself without asking the LLM
    for a regeneration. Fixes can involve deletion or replacement of certain parts
    of the input or output.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在此方法中，库会自行修复输出，而无需请求LLM重新生成。修复可能涉及删除或替换输入或输出的某些部分。
- en: Filter
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: Filter
- en: If structured data generation is used, this option enables filtering out only
    the attribute for which the validation failed. The rest of the output will be
    fed back to the user.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用结构化数据生成，此选项将仅过滤掉验证失败的属性。其余的输出将反馈给用户。
- en: Refrain
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: Refrain
- en: In this setting, the output is simply not returned to the user, and the user
    receives a refusal.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在此设置中，输出将直接不返回给用户，用户收到拒绝。
- en: Noop
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: Noop
- en: No action is taken, but the validation failure is logged for further inspection.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 不采取任何行动，但验证失败将被记录以供进一步检查。
- en: Exception
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: Exception
- en: This raises a software exception when the validation fails. Exception handlers
    can be written to activate custom behavior.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 当验证失败时，这会引发软件异常。可以编写异常处理程序来激活自定义行为。
- en: fix_reask
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: fix_reask
- en: In this method, the library tries to fix the output by itself and then runs
    validation on the new output. If the validation still fails, then the LLM is asked
    to regenerate the output.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在此方法中，库会尝试自行修复输出，然后对新输出进行验证。如果验证仍然失败，则请求LLM重新生成输出。
- en: 'Let’s look at the PII guardrail as an example:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 以PII guardrail为例：
- en: '[PRE10]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Next, let’s look at how verification modules work.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看验证模块是如何工作的。
- en: Verification modules
  id: totrans-280
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Verification modules
- en: As we have seen throughout the book, current LLMs suffer from problems like
    reasoning limitations and hallucinations that severely limit their robustness.
    However, production-ready applications need to demonstrate a certain level of
    reliability to be accepted by users. One way to extend the reliability of LLM-based
    systems is to use a human-in-the-loop who can manually verify the output and provide
    feedback. However, in the real world a human-in-the-loop is not always desired
    or feasible. The most popular alternative is to use external verification modules
    as part of the LLM system. These modules can range from rule-based programs to
    smaller fine-tuned LLMs to symbolic solvers. There are also efforts to use LLMs
    as verifiers, called “LLM-as-a-judge.”
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在整本书中看到的，当前的LLM（大型语言模型）存在推理限制和幻觉等问题，这些问题严重限制了它们的鲁棒性。然而，生产就绪的应用需要展示一定程度的可靠性才能被用户接受。提高基于LLM的系统可靠性的方法之一是使用人工审核，人工可以手动验证输出并提供反馈。然而，在现实世界中，人工审核并不总是期望或可行的。最受欢迎的替代方案是使用外部验证模块作为LLM系统的一部分。这些模块可以是从基于规则的程序到更小的微调LLM再到符号求解器。还有努力使用LLM作为验证器，称为“LLM作为法官”。
- en: Related components include fallback modules. These modules are activated when
    the verification process fails and retrying/fixing doesn’t work. Fallback modules
    can be as simple as messages like, “I am sorry I cannot entertain your request”
    to more complex workflows.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 相关组件包括回退模块。当验证过程失败且重试/修复不起作用时，这些模块会被激活。回退模块可以像“很抱歉我无法满足您的请求”这样的简单消息一样简单，也可以是更复杂的流程。
- en: Let’s discuss an example. Consider an abstractive summarization application
    that operates on financial documents. To ensure quality and reliability of the
    generated summaries, we need to embed verification and self-fixing into the system
    architecture.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一个例子。考虑一个在金融文档上运行的抽象摘要应用。为了确保生成的摘要的质量和可靠性，我们需要将验证和自我修复嵌入到系统架构中。
- en: How do we verify the quality of an abstractive summary? While single-number
    metrics are available to automatically quantify the quality of a summary, a more
    holistic approach would be to define a list of criteria that a good summary should
    satisfy and verify whether each criterion is fulfilled.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何验证抽象摘要的质量？虽然存在单数值指标可以自动量化摘要的质量，但更全面的方法是定义一个良好的摘要应满足的标准列表，并验证每个标准是否得到满足。
- en: Note
  id: totrans-285
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Several single-number quantitative metrics exist for evaluating summaries. These
    include metrics like [BLEU, ROUGE](https://oreil.ly/LPlFJ), and [BERTScore](https://oreil.ly/gsOGl).
    BLEU and ROUGE rely on token overlap heuristics and have been shown to be [woefully
    inadequate](https://oreil.ly/rSzbR). Techniques like BERTScore that apply semantic
    similarity have been shown to be more promising, but in the end, the reality is
    that summaries have subjective notions of quality and need a more holistic approach
    for verification.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 存在几个用于评估摘要的单数值量化指标。这些包括像[BLEU, ROUGE](https://oreil.ly/LPlFJ)和[BERTScore](https://oreil.ly/gsOGl)这样的指标。BLEU和ROUGE依赖于标记重叠启发式方法，并且已被证明是[严重不足的](https://oreil.ly/rSzbR)。像BERTScore这样的技术，通过应用语义相似性，已被证明更有前景，但最终，现实是摘要具有主观的质量观念，需要更全面的方法进行验证。
- en: 'For the summarization of financial documents application, here is a list of
    important criteria:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 对于金融文档摘要应用，以下是一些重要的标准：
- en: Factuality
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 事实性
- en: The summary is factually correct and does not make incorrect assumptions or
    conclusions from the source text.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要内容真实无误，不基于源文本做出错误假设或结论。
- en: Specificity
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 特异性
- en: The summary doesn’t *oversummarize*; it avoids being generic and provides specific
    details, whether numbers or named entities.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要不*过度总结*；它避免泛泛而谈，提供具体细节，无论是数字还是命名实体。
- en: Relevance
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性
- en: Also called precision, this is calculated as the percentage of sentences in
    the summary that are deemed relevant and thus merit inclusion in the summary.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 也称为精确度，这是计算为摘要中认为相关并因此值得包含在摘要中的句子百分比。
- en: Completeness
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 完整性
- en: Also called recall, this is calculated as the percentage of relevant items in
    the source document that are included in the summary.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 也称为召回率，这是计算为源文档中包含在摘要中的相关项百分比。
- en: Repetitiveness
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 重复性
- en: The summary should not be repetitive, even if there is repetition in the source
    document.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要不应重复，即使源文档中有重复。
- en: Coherence
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性
- en: When read in full, the summary should provide a clear picture of the content
    in the source document, while minimizing ambiguity. This is one of the list’s
    more subjective criteria.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 当全文阅读时，摘要应提供对源文档内容的清晰图景，同时最大限度地减少歧义。这是列表中较为主观的标准之一。
- en: Structure
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '**结构**'
- en: While defining the summarization task, we might specify a structure for the
    summaries. For example, the summary could be expected to contain some predefined
    sections and subsections. The generated summary should follow the specified structure.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义摘要任务时，我们可能为摘要指定一个结构。例如，摘要可能需要包含一些预定义的部分和小节。生成的摘要应遵循指定的结构。
- en: Formatting
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '**格式化**'
- en: The generated summary should follow proper formatting. For example, if the summary
    is to be generated as a bulleted list, then all the items in the summary should
    be represented by bullets.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的摘要应遵循适当的格式。例如，如果摘要要生成为一个项目符号列表，那么摘要中的所有条目都应该用项目符号表示。
- en: Ordering
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '**排序**'
- en: The ordering of the items in the summary should not impede the understanding
    of the summary content. We also might want to specify an order for the summaries,
    for example, chronological.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要中条目的顺序不应妨碍对摘要内容的理解。我们也可能想要指定摘要的顺序，例如按时间顺序。
- en: Error handling
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '**错误处理**'
- en: In case of errors or omissions in the source document, there should be appropriate
    error handling.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在源文档中发生错误或遗漏的情况下，应有适当的错误处理。
- en: 'How do we automatically verify whether a given summary meets all these criteria?
    We can use a combination of rule-based methods and fine-tuned models. Ultimately,
    the rigor of the methods used for verification depends on the degree of reliability
    needed for your application. However, we notice that once we reduce the scope
    of the verification process to verify fitness of individual criteria rather than
    the application as a whole, it becomes easier to verify accurately using inexpensive
    techniques. Let’s look at how we can build verifiers for each criteria of the
    abstractive summarization task:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何自动验证一个给定的摘要是否满足所有这些标准呢？我们可以使用基于规则的方法和微调模型相结合。最终，用于验证的方法的严谨性取决于你应用所需的可靠性程度。然而，我们注意到，一旦我们将验证过程的范围缩小到验证单个标准的适用性，而不是整个应用，使用低成本技术进行准确验证就变得更容易了。让我们看看我们如何为抽象摘要任务的每个标准构建验证器：
- en: Factuality
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '**事实性**'
- en: Verifying whether an LLM-generated statement is factual is extremely difficult
    if we do not have access to ground truth. But for summarization applications,
    we do have access to the ground truth. Therefore, we can verify factuality by
    taking each sentence in the summary and checking whether, given the source text,
    one can logically conclude the statement in the summary. This can be framed as
    a natural language inference (NLI) problem, which is a standard NLP task.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们没有访问到事实，验证一个由LLM生成的陈述是否真实就极其困难。但对于摘要应用，我们确实可以访问到事实。因此，我们可以通过检查摘要中的每一句话，并检查在源文本的条件下，是否可以逻辑上得出摘要中的陈述来进行事实性验证。这可以被视为一个自然语言推理（NLI）问题，这是一个标准的NLP任务。
- en: In the NLI task, we have a hypothesis and a premise, and the goal is to check
    if the hypothesis is logically entailed by the premise. In our example, the hypothesis
    is a sentence in the summary and the premise is the source text.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在NLI任务中，我们有一个假设和一个前提，目标是检查假设是否逻辑上由前提所蕴含。在我们的例子中，假设是摘要中的一句话，前提是源文本。
- en: Training an NLI model specific to your domain might be a cumbersome task. If
    you do not have access to an NLI model, you can use token overlap and similar
    statistics to approximate factuality verification.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 训练一个特定于你领域的NLI模型可能是一项繁琐的任务。如果你没有访问NLI模型，你可以使用标记重叠和类似统计来近似事实性验证。
- en: For numbers and named entities, factuality verification can be performed by
    using string matches. You can verify if all the numbers and named entities in
    the summary are indeed present in the source text.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数字和命名实体，可以通过字符串匹配来进行事实性验证。你可以验证摘要中的所有数字和命名实体是否确实存在于源文本中。
- en: Specificity
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '**特异性**'
- en: One way for a summary to be specific is to include numbers and named entities
    where relevant. For each sentence in the summary, we can check whether the content
    in the source document related to the topic of the sentence contains any numbers
    and named entities, and if these are reflected in the summary. Numbers and named
    entities can be tagged and detected using regular expressions or libraries like
    [spaCy](https://oreil.ly/zatAW).
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 摘要具体化的一种方式是在相关的地方包含数字和命名实体。对于摘要中的每个句子，我们可以检查与句子主题相关的源文档中的内容是否包含任何数字和命名实体，以及这些是否在摘要中得到反映。数字和命名实体可以使用正则表达式或像[spaCy](https://oreil.ly/zatAW)这样的库进行标记和检测。
- en: Relevance/precision
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 相关性/精确度
- en: We can train a classification model that detects whether a sentence in the summary
    is relevant. Note that there are limits to this approach. If this classification
    model was good enough, we could have directly used it to select relevant sentences
    from the source text to build the summary! In practice, this classification model
    can be used to remove irrelevant content that is more obvious.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以训练一个分类模型，用于检测摘要中的句子是否相关。请注意，这种方法有其局限性。如果这个分类模型足够好，我们就可以直接用它从源文本中选择相关的句子来构建摘要！在实践中，这个分类模型可以用来移除更明显的不相关内容。
- en: Recall/completeness
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 回忆/完整性
- en: What content merits inclusion in the summary is a difficult question, especially
    if there is a hard limit on the summary length. You can train a ranking model
    that ranks sentences in the source document by importance, and then verify if
    the top-ranked sentences are represented in the summary. You can also specify
    beforehand the type of content that you need represented in the summary and build
    a classification model for determining which parts of the source document contain
    pertinent information. Using similarity metrics like embedding similarity, you
    can then find if the content has been adequately represented in the summary.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 什么内容值得包含在摘要中是一个难题，尤其是在摘要长度有限的情况下。你可以训练一个排名模型，按重要性对源文档中的句子进行排序，然后验证是否在摘要中包含了排名靠前的句子。你还可以事先指定需要在摘要中呈现的内容类型，并构建一个分类模型来确定源文档中哪些部分包含相关信息。然后，使用嵌入相似度等相似度指标，你可以找到内容是否在摘要中得到充分呈现。
- en: Repetitiveness
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 重复性
- en: This can be discovered by using string difference algorithms like the [Jaccard
    distance](https://oreil.ly/Ny_Ku) or by calculating the embedding similarity between
    pairs of summary sentences.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以通过使用字符串差异算法，如[Jaccard距离](https://oreil.ly/Ny_Ku)或通过计算摘要句子对的嵌入相似度来发现。
- en: Coherence
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性
- en: This is perhaps one of the most difficult criteria to verify. One way to solve
    this, albeit a more expensive solution, is to build a prerequisite detection model.
    For each sentence in the summary, we detect if all the sentences that come before
    it are sufficient prerequisites for understanding the correct sentence. For more
    information on prerequisite detection techniques, see [Thareja et al.](https://oreil.ly/6JnRs)
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能是最难验证的标准之一。解决这一问题的方法之一，尽管成本较高，是构建一个先决条件检测模型。对于摘要中的每个句子，我们检测其前面的所有句子是否是理解正确句子的充分先决条件。有关先决条件检测技术的更多信息，请参阅[Thareja等人](https://oreil.ly/6JnRs)。
- en: Structure
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 结构
- en: If we specify a predetermined structure (sections and subsections) for the summary,
    we can easily identify if the structure is adhered to by checking if the desired
    section and subsection titles are present in the summary. We can also verify using
    embedding similarity techniques if the content within the sections and subsections
    is faithful to the title of the section/subsection.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们为摘要指定一个预定的结构（章节和小节），我们可以通过检查摘要中是否存在所需的章节和小节标题来轻松地确定结构是否得到遵守。我们还可以使用嵌入相似度技术来验证章节和小节内的内容是否忠实于章节/小节的标题。
- en: Formatting
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 格式化
- en: This involves checking whether the content is in the appropriate formatting,
    for example, whether it is a bulleted list or a valid JSON object.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 这涉及到检查内容是否以适当的格式呈现，例如，是否是一个项目符号列表或有效的JSON对象。
- en: Ordering
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 排序
- en: The desired order can be chronological, alphabetical, a domain, or task-specific
    ordering. If it is supposed to be chronological, you can verify by extracting
    dates in the summary and checking if the summary contains dates in a chronological
    order. If the ordering requirements are more complex, then verifying adherence
    to order may become an extremely difficult task.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 所需的顺序可以是按时间顺序、按字母顺序、按领域或按特定任务排序。如果它应该是按时间顺序的，你可以通过提取摘要中的日期并检查摘要是否包含按时间顺序的日期来验证。如果排序要求更复杂，那么验证遵守顺序可能变得极其困难。
- en: Tip
  id: totrans-330
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Do not expect your verification process to be strictly better than your summary
    model. If that was the case, you could have used the verification process to generate
    the summary!
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 不要期望你的验证过程比你的摘要模型严格得多。如果是这样的话，你就可以使用验证过程来生成摘要了！
- en: We can also deploy symbolic verifiers like [SAT](https://oreil.ly/lOsg_) (Boolean
    satisfiability) solvers and logic planners. This type of verification is beyond
    the scope of this book.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以部署符号验证器，如 [SAT](https://oreil.ly/lOsg_)（布尔可满足性）求解器和逻辑规划器。这类验证超出了本书的范围。
- en: Once verification modules are part of our system architecture, we will also
    need to decide what action to perform when the verification fails. One option
    is to just resample from the language model again. Regeneration can be performed
    for the full output or only for the output that failed verification. We can also
    develop antifragile architectures that have fallbacks in case of failure, which
    we will discuss in [Chapter 13](ch13.html#ch13).
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦验证模块成为我们系统架构的一部分，我们还需要决定在验证失败时采取什么行动。一个选择是再次从语言模型中重新采样。可以再生整个输出或仅再生验证失败的输出。我们还可以开发具有故障回退功能的抗脆弱架构，我们将在第
    13 章（ch13.html#ch13）中讨论。
- en: Warning
  id: totrans-334
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Adding more verifiers can drastically increase system latency. Thus, their inclusion
    has to be balanced with accuracy and system latency needs.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 添加更多验证器可以显著增加系统延迟。因此，它们的包含需要在准确性和系统延迟需求之间进行平衡。
- en: Finally, let’s discuss agent orchestration software that connects all these
    components.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们讨论连接所有这些组件的代理编排软件。
- en: Agent Orchestration Software
  id: totrans-337
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 代理编排软件
- en: For agentic workflows to proceed smoothly, we need software that connects all
    the components. Orchestration software manages state; invokes tools; initiates
    retrieval; pipes buffers; and logs intermediate and final outputs. Many agentic
    frameworks, both open source and proprietary, perform this function, including
    [LangChain](https://oreil.ly/7vmlY), [LlamaIndex](https://oreil.ly/uxejK), [CrewAI](https://oreil.ly/Ntxii),
    [AutoGen](https://oreil.ly/tx3qy), [MetaGPT](https://oreil.ly/HI-Jn), [XAgent](https://oreil.ly/sA_DR),
    [llama-stack-apps](https://oreil.ly/SBGC_), and so on.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使代理工作流程顺利运行，我们需要连接所有组件的软件。编排软件管理状态；调用工具；启动检索；管道缓冲；并记录中间和最终输出。许多代理框架，包括开源和专有框架，都执行此功能，包括
    [LangChain](https://oreil.ly/7vmlY)、[LlamaIndex](https://oreil.ly/uxejK)、[CrewAI](https://oreil.ly/Ntxii)、[AutoGen](https://oreil.ly/tx3qy)、[MetaGPT](https://oreil.ly/HI-Jn)、[XAgent](https://oreil.ly/sA_DR)、[llama-stack-apps](https://oreil.ly/SBGC_)
    等。
- en: Tip
  id: totrans-339
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Agents are a relatively new paradigm, so all these agentic frameworks are expected
    to change a lot in the coming months and years. These frameworks are implemented
    in an opinionated fashion and hence are less flexible. For prototyping, I suggest
    picking LangChain or LlamaIndex for ease of use. For production use, you might
    want to build a framework internally from scratch or by extending the open source
    ones. This book’s [GitHub repo](https://oreil.ly/llm-playbooks) contains a rudimentary
    agentic framework as well.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 代理是一个相对较新的范式，因此预计所有这些代理框架在接下来的几个月和几年里都会发生很大变化。这些框架以有偏见的方式实现，因此灵活性较低。对于原型设计，我建议选择
    LangChain 或 LlamaIndex 以便于使用。对于生产使用，你可能希望从头开始内部构建框架或通过扩展开源框架来构建。本书的 [GitHub 仓库](https://oreil.ly/llm-playbooks)
    还包含了一个基本的代理框架。
- en: Now that we have learned all the different agentic system components, it is
    time to get building! The book’s [GitHub repository](https://oreil.ly/llm-playbooks)
    contains sample implementations of various types of agents. Try modifying them
    for your use case to understand the tradeoffs being made.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经学习了所有不同的代理系统组件，是时候开始构建了！本书的 [GitHub 仓库](https://oreil.ly/llm-playbooks)
    包含了各种类型代理的示例实现。尝试修改它们以适应你的用例，以了解正在做出的权衡。
- en: Tip
  id: totrans-342
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: The keep it simple, stupid (KISS) principle applies to agents perhaps more than
    any other recent paradigm. Don’t complicate your agentic architecture unless there
    is a compelling reason to do so. We will discuss this more in [Chapter 13](ch13.html#ch13).
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 简单至上（KISS）原则可能比任何其他近期范式更适用于代理。除非有充分的理由，否则不要使你的代理架构复杂化。我们将在第13章（[Chapter 13](ch13.html#ch13)）中进一步讨论这一点。
- en: Summary
  id: totrans-344
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed the different ways in which LLMs can interface
    with external tools. We introduced the agentic paradigm and provided a formal
    definition of agents. We identified the components of an agentic system in detail,
    exploring models, tools, data stores, guardrails and verifiers, and agentic orchestration
    software. We learned how to define and implement our own tools.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了LLMs与外部工具交互的不同方式。我们介绍了代理范式，并提供了代理的正式定义。我们详细地确定了代理系统的组成部分，包括模型、工具、数据存储、安全措施和验证器，以及代理编排软件。我们学习了如何定义和实现自己的工具。
- en: In the next chapter, we will explore data representation and retrieval, crucial
    elements of interfacing LLMs with external data.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨数据表示和检索，这是LLMs与外部数据接口的关键要素。
