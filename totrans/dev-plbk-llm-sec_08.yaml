- en: Chapter 8\. Don’t Lose Your Wallet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Beware of little expenses; a small leak will sink a great ship.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Benjamin Franklin
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: This chapter will explore denial-of-service (DoS), denial-of-wallet (DoW), and
    model cloning attacks, examining the similarities and differences between these
    attack types. Despite the divergent outcomes—from service disruption and financial
    loss to the unauthorized duplication of your intellectual property—these three
    attack vectors exploit similar vulnerabilities within the application. By exploring
    these threats side-by-side, you’ll understand the protective measures to thwart
    such attacks.
  prefs: []
  type: TYPE_NORMAL
- en: The term DoS has become synonymous with the disruption of online services. A
    DoS attack is an intentional effort to make a computer system, network, or application
    unavailable to its intended users, typically by overwhelming the app with requests.
    Historically, these attacks have targeted various online services, from financial
    institutions to social media platforms, causing significant operational disruptions
    and economic losses. As we dig deeper into the era of advanced computing and AI,
    the implications of DoS attacks have extended to more sophisticated technologies,
    including LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: While LLMs are not immune to traditional cybersecurity threats, their unique
    characteristics can make them highly vulnerable to DoS attacks, and such attacks
    can have unique and severe consequences. Today, DoS attacks are not merely about
    disrupting service availability; they extend to exploiting these models’ intrinsic
    features, leading to resource exhaustion, degraded performance, and possible direct
    financial losses. This new frontier of DoS attacks is not just a technical challenge,
    but a significant business concern, as it directly impacts the reliability and
    economic viability of services utilizing LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: The recent emergence of DoW attacks, a highly dangerous variant of DoS, against
    LLMs brings an additional financial dimension to LLMs’ security concerns. These
    attacks specifically target the economic resources of an organization by exploiting
    the pay-per-use models of cloud-based AI services. In a DoW attack, the adversary
    aims to cause the service provider to incur unsustainable costs by generating
    excessive queries or operations, leading to financial strain rather than mere
    service disruption. This phenomenon highlights a unique vulnerability in the deployment
    of LLMs, where the financial integrity of an application is as crucial as its
    operational security.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will also discuss *model cloning attacks*, in which an adversary
    aims to steal the intellectual property underlying your model by flooding the
    system with questions, recording the answers, and then using those answers to
    train their own model. While these attacks are often classified differently than
    denial attacks, there are fundamental similarities. In particular, model cloning
    attacks depend on driving repeated queries against your model, just like DoS attacks.
    This similarity means many of the same defensive techniques apply.
  prefs: []
  type: TYPE_NORMAL
- en: DoS Attacks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The impact of DoS attacks is far reaching. They can lead to significant downtime
    for online services, resulting in considerable financial losses, especially for
    businesses that rely heavily on online transactions. Beyond financial damage,
    DoS attacks can erode trust in a service or brand, mainly if they occur frequently
    or the service provider doesn’t handle them effectively. Furthermore, DoS attacks
    can be a cover for more sinister activities, such as data breaches or malware
    injection, because they divert the attention of IT staff.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s examine the types, causes, and mitigation steps for general DoS attacks
    before we dive into the LLM-specific aspects.
  prefs: []
  type: TYPE_NORMAL
- en: To understand the issue better, let’s look at three major categories of DoS
    attacks.
  prefs: []
  type: TYPE_NORMAL
- en: Volume-Based Attacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Volume-based attacks are the most straightforward type of DoS attack. In a volume-based
    attack, the target is overwhelmed with massive amounts of traffic, using tactics
    like User Datagram Protocol (UDP) floods, Internet Control Message Protocol (ICMP)
    floods, and other spoofed-packet floods. The sheer volume of traffic consumes
    the bandwidth of the targeted site or application, making it inaccessible to legitimate
    traffic.
  prefs: []
  type: TYPE_NORMAL
- en: While simple volume-based attacks inundate a target with significant traffic
    from a single source, *distributed denial-of-service* (DDoS) attacks amplify this
    threat by leveraging multiple compromised systems to launch a coordinated assault.
    These attacks utilize a network of infected devices, known as a *botnet*, to generate
    a flood of traffic that overwhelms the target from numerous points across the
    internet.
  prefs: []
  type: TYPE_NORMAL
- en: Protocol Attacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Protocol attacks* target the network layer or transport layer of a network
    connection. They exploit weaknesses in the protocols that run the internet. By
    manipulating the flaws in these protocols, attackers can send a relatively small
    amount of traffic to create a disproportionately large load on the target, effectively
    disrupting its ability to communicate. Examples include *SYN floods*, *ping of
    death*, and *Smurf attacks*:'
  prefs: []
  type: TYPE_NORMAL
- en: SYN floods
  prefs: []
  type: TYPE_NORMAL
- en: This attack exploits the TCP handshake process, which is the initial negotiation
    between the client and the server to establish a connection. In a SYN flood, the
    attacker sends a rapid succession of SYN requests (a signal to start a connection)
    to a target server, but intentionally fails to complete the handshake by not sending
    the final acknowledgment.
  prefs: []
  type: TYPE_NORMAL
- en: Ping of death
  prefs: []
  type: TYPE_NORMAL
- en: This attack involves sending malicious pings to a system. In a ping of death
    scenario, the attacker sends larger pings than the IP protocol allows (65,535
    bytes). Older systems often couldn’t handle these oversized packets, causing them
    to freeze, crash, or reboot.
  prefs: []
  type: TYPE_NORMAL
- en: Smurf attack
  prefs: []
  type: TYPE_NORMAL
- en: The attacker sends ICMP requests (usually pings) to a network’s broadcast address,
    spoofing the return address with the target’s IP. All devices on the broadcast
    network respond to this ping, sending replies to the victim’s IP address. This
    amplifies the volume of traffic directed at the target, overwhelming its resources.
  prefs: []
  type: TYPE_NORMAL
- en: Each of these attacks represents a different approach to overwhelming a target
    with unwanted traffic or requests, resulting in a denial of service. Protection
    against such attacks often involves a combination of traffic filtering, rate limiting,
    and network configuration adjustments to reduce vulnerability.
  prefs: []
  type: TYPE_NORMAL
- en: Application Layer Attacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Application layer attacks are more sophisticated attacks that target the application
    layer, where web pages are generated and delivered in response to HTTP requests.
    The attacker requests so many resources from the server that it cannot serve legitimate
    user requests. Such attacks often require fewer resources than volume-based or
    protocol attacks but can be highly effective due to their targeted nature. Examples
    of this kind of attack include *HTTP flood* and *Slowloris*:'
  prefs: []
  type: TYPE_NORMAL
- en: HTTP flood
  prefs: []
  type: TYPE_NORMAL
- en: This attack involves flooding a web server with a high volume of HTTP requests,
    overwhelming its capacity to respond effectively to legitimate user traffic. Attackers
    exploit vulnerabilities in the HTTP protocol by inundating the server with a barrage
    of requests, aiming to exhaust its resources, disrupt services, and ultimately
    render the website inaccessible to genuine users.
  prefs: []
  type: TYPE_NORMAL
- en: Slowloris
  prefs: []
  type: TYPE_NORMAL
- en: Here, the attacker initiates multiple HTTP connections to the target web server,
    but deliberately keeps them open by sending partial requests slowly, thereby consuming
    available server resources and preventing the server from serving legitimate requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'An Epic DoS Attack: Dyn'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In October 2016, the internet faced a massive disruption due to a sophisticated
    and large-scale DoS attack on Dyn, a leading Domain Name System (DNS) provider.
    This event made headlines and marked a pivotal moment in understanding cyber threats
    and their potential impact on global internet infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Dyn, known for its role in internet performance management and website application
    security, became the target of a DDoS attack in which attackers used compromised
    IoT devices, such as digital cameras and DVRs, to generate malicious traffic.
    Infected with the Mirai malware, these devices formed a botnet to flood Dyn’s
    servers with overwhelming traffic.
  prefs: []
  type: TYPE_NORMAL
- en: The attack generated traffic volumes estimated at around 1.2 Tbps (terabits
    per second). At the time, it was one of the most impactful DDoS attacks on record.
    The assault on Dyn’s DNS services had a ripple effect, causing major internet
    platforms and services to become unavailable to users across Europe and North
    America. High-profile websites, including Twitter, Netflix, PayPal, and Amazon,
    faced significant disruptions. The attack was executed in multiple waves, resulting
    in intermittent outages and widespread uncertainty throughout the attack.
  prefs: []
  type: TYPE_NORMAL
- en: Model DoS Attacks Targeting LLMs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Unlike traditional DoS attacks that mainly target vulnerabilities in network
    and server infrastructures, a model DoS attack focuses on exploiting the unique
    vulnerabilities inherent in LLMs. In a model DoS attack, the attacker’s goal is
    to compromise the functionality or exhaust the resources of an LLM.
  prefs: []
  type: TYPE_NORMAL
- en: An LLM application connected to the web via a web user interface or a REST API
    could be the target of the traditional DoS attacks we detailed earlier in the
    chapter, such as volume-based, protocol, and application layer attacks. However,
    the nature of LLMs opens them up to specific new concerns we’ll discuss in this
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Scarce Resource Attacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LLMs are resource intensive due to the architecture they use to generate complex
    text responses. This makes them vulnerable to attacks designed to overburden their
    processing capabilities. For example, an attacker could repeatedly prompt an LLM
    to translate large documents or generate long-form content. This type of request,
    especially if scaled up by automation or bots, can quickly drain the computational
    resources available to the LLM.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at a practical example to help illustrate the point. Several service
    providers use LLMs to power highly effective machine translation services, offering
    the ability to process and understand text in one language and fluently translate
    it into another. Yet, the sophistication of LLMs comes at a cost: a high demand
    for computational resources that are both intensive and specialized. Unlike more
    straightforward computational tasks you can handle with inexpensive network bandwidth
    or general-purpose CPUs, LLMs usually require advanced hardware, such as GPUs
    or specialized AI accelerators, which are more costly and in limited supply, even
    in expansive cloud computing environments.'
  prefs: []
  type: TYPE_NORMAL
- en: Consider a situation where an LLM-based translation service is targeted not
    by a sophisticated DDoS attack utilizing botnets, but by a simple, cheap flood
    of translation requests. These requests, individually, might not raise alarms—after
    all, they are the type of input the service provider designed it to handle. However,
    due to the resource-intensive nature of LLM processing, even a modestly coordinated
    influx of complex translation requests could disproportionately consume computational
    resources.
  prefs: []
  type: TYPE_NORMAL
- en: This reliance on high-end computational resources for every translation task
    makes LLMs particularly susceptible to exploitation. With minimal effort, an attacker
    can submit a large block of complex text for translation. While sending this text
    is trivial, requiring negligible resources from the attacker, the translation
    process places a substantial load on the LLM. The system must perform deep, nuanced
    analysis and generation tasks that consume significant amounts of these scarce,
    expensive computational resources.
  prefs: []
  type: TYPE_NORMAL
- en: The significant gap between the trivial effort required to make a request and
    the intensive resources needed for processing underscores the likelihood of exploitation.
    This reality amplifies the importance of establishing robust defenses, as LLMs
    are much more susceptible to these attacks than simpler systems.
  prefs: []
  type: TYPE_NORMAL
- en: In this scenario, attackers don’t need to compromise a vast network of devices
    or employ advanced techniques to launch an effective disruption; the very architecture
    of the LLM, designed for deep, thoughtful analysis, becomes its Achilles’ heel.
    A small number of attackers, or even a single one with modest resources, can initiate
    a flood of translation requests that, while seemingly legitimate, are intended
    to exploit the LLM’s computational demands. As a result, the service could slow
    dramatically or even grind to a halt, denying access to legitimate users and potentially
    incurring substantial operational costs for the service provider.
  prefs: []
  type: TYPE_NORMAL
- en: Context Window Exhaustion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In [Chapter 3](ch03.html#architectures_and_trust_boundaries), we touched on
    the concept of “attention,” which is part of the transformer architecture underlying
    modern LLMs. It’s a groundbreaking innovation that allows these models to focus
    on different parts of the input text as they generate responses or translations.
    Attention mechanisms are pivotal because they enable LLMs to dynamically prioritize
    specific inputs over others, mimicking how human attention works when we read
    or listen. This ability is crucial for understanding the context and nuances of
    language, making LLMs remarkably effective at processing and generating natural
    language.
  prefs: []
  type: TYPE_NORMAL
- en: Building on the foundation of attention, the *context window* can be seen as
    the short-term memory of an LLM. It defines the scope within which the model focuses
    its attention, limiting how much text it can “remember” or consider at any given
    moment. Without this context window, an LLM would operate statelessly, akin to
    attempting a conversation without the ability to recall what was said moments
    before. Such a limitation would drastically reduce the model’s utility, as it
    could not produce coherent, context-aware responses over more extended interactions.
  prefs: []
  type: TYPE_NORMAL
- en: The context window, therefore, is not just a technical limitation; it’s a crucial
    feature that enables LLMs to apply their attention mechanisms effectively. It
    allows the model to hold a running “conversation” or maintain the thread of a
    narrative or argument within its memory bounds. This capability makes LLMs powerful
    and versatile across various applications, from writing assistance and chatbots
    to more complex tasks like summarization and translation.
  prefs: []
  type: TYPE_NORMAL
- en: However, as we’ve highlighted, the very feature that empowers LLMs with such
    capabilities also introduces specific vulnerabilities. The computational demand
    to maintain and process within this context window is significant. Attackers can
    exploit these demands by crafting inputs that push the limits of the context window,
    thereby straining the model’s resources. This could include providing extremely
    long prompts or crafting prompts that cause the LLM to give highly verbose answers
    that could fill a chatbot’s context window. Recognizing and mitigating these vulnerabilities
    is essential not only for the operational efficiency of LLMs but also for safeguarding
    against potential exploitation that could compromise their functionality or incur
    excessive costs.
  prefs: []
  type: TYPE_NORMAL
- en: Unpredictable User Input
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another vulnerability is the interaction of LLMs with unpredictable user inputs.
    Since these models are designed to respond to varied queries, attackers can manipulate
    them to perform complex, resource-intensive tasks. For example, an attacker could
    craft complicated questions or prompts that force the LLM to engage in deep, extended
    analyses or computations, effectively draining its resources.
  prefs: []
  type: TYPE_NORMAL
- en: A striking example of this vulnerability can be observed in seemingly innocuous
    mathematical requests that, upon closer examination, reveal the potential for
    exponential resource consumption. Consider a scenario where an LLM, equipped with
    the capability to generate code or solve complex problems, receives a request
    such as “What is one million factorial?” It requires only a few dozen bytes to
    encode that request and send it to the LLM, but it would cause one million multiplication
    operations to be executed by the host system.
  prefs: []
  type: TYPE_NORMAL
- en: 'But a modern CPU can do a million multiplications in milliseconds. So, let’s
    look at a few requests that might really stump the poor system:'
  prefs: []
  type: TYPE_NORMAL
- en: Computationally intensive requests
  prefs: []
  type: TYPE_NORMAL
- en: These might include questions such as “What is the sum of all prime numbers
    up to one billion?” While asking for the sum of primes seems straightforward,
    identifying all prime numbers up to a large number like one billion requires significant
    computational effort, involving checks for primality across a vast range of numbers.
  prefs: []
  type: TYPE_NORMAL
- en: Extensive content generation requests
  prefs: []
  type: TYPE_NORMAL
- en: An innocuous-sounding request such as “Write a detailed history of every World
    Cup match” could force the LLM to generate an extensive amount of content, stringing
    together hundreds of separate events into a single, comprehensive narrative. Each
    token generation requires computational resources, and a lengthy, detailed response
    could significantly tax the system.
  prefs: []
  type: TYPE_NORMAL
- en: Complex reasoning and explanation chains
  prefs: []
  type: TYPE_NORMAL
- en: A prompt such as “List and explain every step involved in producing a smartphone
    from mining raw materials to final assembly, including the socioeconomic impacts
    at each stage” might require linking multiple knowledge domains with deep causal
    and explanatory chains, significantly increasing the generative task’s complexity
    and duration.
  prefs: []
  type: TYPE_NORMAL
- en: Without proper safeguards, the LLM could embark on many boundless computational
    journeys, significantly draining system resources and potentially disrupting service.
  prefs: []
  type: TYPE_NORMAL
- en: DoW Attacks
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DoW is a variant of DoS that, while not new, is starting to gain significant
    prominence in the era of cloud computing and scalable online services. Unlike
    traditional DoS attacks, which aim to disrupt the availability of a service, DoW
    attacks target an organization’s financial resources. Often the primary objective
    of a DoW attack is to inflict economic damage by exploiting the usage-based pricing
    models of online services, leading to runaway costs for the victim.
  prefs: []
  type: TYPE_NORMAL
- en: Historically, DoW attacks have been associated with cloud services where costs
    are directly tied to usage metrics such as compute time, data transfer, or transaction
    volumes. The basic premise involves driving up the usage—and, consequently, the
    costs—to unsustainable levels, thereby “denying” the organization its financial
    resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'Any scalable web application could be the target of a DoW attack. However,
    LLM applications typically have many characteristics that make them particularly
    vulnerable. Here are some items to consider:'
  prefs: []
  type: TYPE_NORMAL
- en: High computational costs
  prefs: []
  type: TYPE_NORMAL
- en: LLMs require significant processing power for text generation, translation,
    or data analysis tasks. This high computational demand translates into higher
    operational costs in cloud-based deployment models.
  prefs: []
  type: TYPE_NORMAL
- en: Scalability of usage
  prefs: []
  type: TYPE_NORMAL
- en: LLM applications are designed to scale with the volume of requests. This scalability
    can be exploited in a DoW attack scenario, causing a rapid escalation in resource
    consumption and associated costs.
  prefs: []
  type: TYPE_NORMAL
- en: API-based access
  prefs: []
  type: TYPE_NORMAL
- en: LLMs are often accessed through APIs, making it easier for an attacker to programmatically
    generate a high volume of requests, thereby driving up costs.
  prefs: []
  type: TYPE_NORMAL
- en: Expensive, complex pricing models
  prefs: []
  type: TYPE_NORMAL
- en: The pricing structures for LLM services can be complex and based on multiple
    factors, such as the number of tokens processed, the duration of interactions,
    or the type of model used. Attackers can use these characteristics to maximize
    the financial impact of their actions.
  prefs: []
  type: TYPE_NORMAL
- en: Taking this concept of DoW a step further, we now see attacks that go beyond
    simply draining the service provider’s resources to cause unwanted expenses. In
    this even more severe variant of DoW, the attacker leverages other vulnerabilities,
    such as prompt injection (see [Chapter 4](ch04.html#prompt_injection)), to take
    over access to the LLM and then use it for nefarious purposes—all at the target’s
    expense. For example, imagine a scenario where an attacker successfully executes
    a prompt injection attack to skirt the guardrails of the LLM. The attacker then
    issues requests that are out of alignment with the intent of the application and
    uses the LLM to generate phishing emails or crack CAPTCHA puzzles as part of a
    broader cyber hacking campaign.
  prefs: []
  type: TYPE_NORMAL
- en: This scenario resembles traditional cryptojacking attacks, in which cloud resources
    are commandeered for cryptocurrency mining. In cryptojacking, attackers illicitly
    use victims’ computing power to mine cryptocurrency, incurring operational costs
    for the victim while profiting the attacker.
  prefs: []
  type: TYPE_NORMAL
- en: In both scenarios, the unauthorized use of resources results in financial loss
    to the victim and potential profit to the attacker. However, there is a key difference
    from cryptojacking, which primarily results in financial loss due to increased
    computational resource usage. These advanced DoW attacks, where the attacker can
    use the system for illegal or malicious tasks, may open the target to additional
    legal liability worries and an empty wallet.
  prefs: []
  type: TYPE_NORMAL
- en: Model Cloning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Model cloning has emerged as a particularly insidious form of attack. Model
    cloning involves strategically querying an LLM application with a vast array of
    prompts on specific topics or using the model to generate synthetic training data.
    The attacker’s goal is to harvest the outputs from these interactions to fine-tune
    an alternate model, effectively replicating the functionality and knowledge base
    of the original LLM without direct access to its underlying architecture or training
    data. This is a form of model stealing where the attacker can, in effect, steal
    the highly valuable intellectual property you used to create your trained model
    and application.
  prefs: []
  type: TYPE_NORMAL
- en: By exploiting the model’s resources through extensive querying, this attack
    vector shares certain tactical similarities with DoS and DoW attacks, so we’re
    including it in this section. However, the intent and end goals diverge significantly.
    While DoS aims to disrupt service availability, model cloning seeks to covertly
    replicate the model’s capabilities, posing a direct threat to intellectual property
    and potentially enabling unauthorized access to proprietary technologies.
  prefs: []
  type: TYPE_NORMAL
- en: Mitigation Strategies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The emerging threat landscape discussed in this chapter underscores the need
    for robust security measures to deploy and manage your application’s LLM. Organizations
    must monitor their LLM applications for any signs of unauthorized access or unusual
    activity. Implementing stringent access controls, conducting regular security
    audits, and deploying real-time anomaly detection systems are crucial to protecting
    against such scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Many DoS or DoW attacks start with a prompt injection designed to jailbreak
    the system and take down guardrails that you may have put in place to align the
    model to your wishes. Thus, it’s critically important for you to follow the strategies
    for prompt injection mitigation we described in [Chapter 4](ch04.html#prompt_injection).
    However, [Chapter 4](ch04.html#prompt_injection) also showed that nullifying prompt
    injection attacks is hard, so you’ll need to put other safeguards in place as
    well.
  prefs: []
  type: TYPE_NORMAL
- en: Domain-Specific Guardrails
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Consider fine-tuning your model by rewarding it to respond only to domain-specific
    inquiries. As discussed in [Chapter 4](ch04.html#prompt_injection), alignment
    is crucial for ensuring that an AI system’s objectives resonate with the developer’s
    intended values, goals, and safety considerations. By tailoring your model to
    respond primarily to questions relevant to the application’s context—such as product
    inquiries on an ecommerce platform—you can significantly reduce the computational
    waste of processing irrelevant or off-topic requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'This focused approach can help safeguard the system against exploitation through
    unnecessary and resource-intensive tasks. For instance, an ecommerce website’s
    chatbot, powered by a fine-tuned model, would answer customer-related questions
    about purchases and product details while deflecting unrelated queries, such as
    complex mathematical problems. This selective responsiveness serves a dual purpose:
    it ensures that the application’s processing power is utilized efficiently, aligning
    with the operational goals of the platform, and it reduces the risk of incurring
    excessive costs from resource-draining inputs that contribute little to user satisfaction
    or the bottom line.'
  prefs: []
  type: TYPE_NORMAL
- en: Input Validation and Sanitization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Effective input validation and sanitization are critical in preventing attacks
    that exploit an LLM’s processing capabilities. This involves establishing strict
    criteria for acceptable input and rigorously checking all incoming data against
    these standards. Sanitization goes further by actively removing or neutralizing
    any potentially harmful elements in the data. For example, inputs exceeding the
    context window size can be truncated or divided, and inputs with unusual or complex
    structures likely to cause excessive processing can be simplified or rejected.
    This approach not only helps mitigate the risk of resource-intensive operations
    triggered by malicious inputs, but also helps maintain the overall integrity and
    performance of the LLM.
  prefs: []
  type: TYPE_NORMAL
- en: Robust Rate Limiting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Implementing robust rate limiting is essential to control access to LLM resources.
    This strategy involves defining and enforcing limits on how frequently a user
    or system can make requests to the LLM within a given time frame. By setting sensible
    thresholds on the number of requests or the amount of data processed, rate limiting
    can effectively prevent the system from being overwhelmed by excessive demands,
    whether they are part of a deliberate attack or a surge in legitimate usage. Sophisticated
    rate limiting can also involve dynamic adjustments based on ongoing system performance
    and user behavior monitoring, allowing for more flexible and responsive control.
  prefs: []
  type: TYPE_NORMAL
- en: Resource Use Capping
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Capping resource use per query or processing step is a direct way to control
    the computational burden placed on an LLM. This can involve setting limits on
    the number of tokens processed per request, the complexity of the computation
    allowed, or the time allowed for processing a single input. By imposing these
    caps, it becomes more difficult for an attacker to induce the LLM to perform highly
    resource-intensive tasks. This strategy can also help maintain predictable and
    stable system performance, even under high load conditions.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring and Alerts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Continuous monitoring of the LLM’s resource utilization is vital for early detection
    of potential attacks. This monitoring involves tracking various metrics, such
    as CPU usage, memory consumption, response times, and the number of concurrent
    requests. Establishing baseline patterns of regular operation makes detecting
    anomalies that may indicate an attack easier. Implementing a robust alerting system
    ensures that any unusual activity is promptly brought to the attention of relevant
    personnel, allowing for quick investigation and response. This proactive approach
    is critical in minimizing the impact of attacks and maintaining the reliability
    of the LLM service.
  prefs: []
  type: TYPE_NORMAL
- en: Financial Thresholds and Alerts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Setting financial thresholds and alerts for cloud-based LLMs can drastically
    reduce the damage from DoW attacks. You should establish budget limits for LLM
    usage and configure alerts to notify administrators when these thresholds are
    approached or exceeded. Such measures are essential in pay-per-use models, where
    the cost implications of high usage can be significant. By closely monitoring
    usage costs and setting predefined limits, organizations can avoid unexpected
    financial burdens due to malicious exploitation of their LLM resources.
  prefs: []
  type: TYPE_NORMAL
- en: Model DoS and DoW represent significant threats. As these models become more
    integral to various applications, understanding and mitigating these threats is
    essential for maintaining LLM-based services’ operational integrity and financial
    viability.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DoS and DoW attacks have long been significant threats to web applications.
    Integrating LLMs into these applications has magnified these concerns, introducing
    new dimensions of risk that demand heightened vigilance and strategic foresight.
  prefs: []
  type: TYPE_NORMAL
- en: The architecture of LLMs, characterized by their intensive computational needs
    and often complex, usage-based billing models, makes them particularly susceptible
    to these types of attacks. As we’ve seen, the potential damage extends far beyond
    the traditional boundaries of operational disruption. There’s an escalated financial
    risk due to the high costs of running these models at scale. More alarmingly,
    there’s an elevated risk of liability, especially in cases where LLMs are hijacked
    and used for illicit purposes. Such scenarios can entangle organizations in legal
    complications and cause irreparable harm to their reputations.
  prefs: []
  type: TYPE_NORMAL
