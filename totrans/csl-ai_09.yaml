- en: 7 Interventions and causal effects
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 7 干预和因果关系
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Case studies of interventions in machine learning engineering contexts
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习工程背景下的干预案例研究
- en: How interventions relate to A/B tests and randomized experiments
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 干预与A/B测试和随机实验的关系
- en: Implementing interventions on causal models with intervention operators
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用干预操作符在因果模型上实施干预
- en: Using a causal model to represent many interventional distributions
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用因果模型来表示许多干预分布
- en: Causal effects as natural extensions of an intervention distribution
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 因果效应作为干预分布的自然扩展
- en: An intervention is something an agent *does* to cause other things to happen.
    Interventions *change* the data generating process (DGP).
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 干预是代理机构为了引起其他事物发生而采取的行动。干预会改变数据生成过程（DGP）。
- en: 'Interventions are the most fundamental concept in how we define causality.
    For example, the concept of intervention, written in terms of “manipulation” and
    “varying” a factor, is central to this definition from an influential 1979 textbook
    on experimental design:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 干预是我们定义因果关系中最基本的概念。例如，干预的概念，用“操纵”和“变化”一个因素来表述，是1979年一本有影响力的实验设计教科书中定义的核心：
- en: The paradigmatic assertion in causal relationships is that manipulation of a
    cause will result in the manipulation of an effect . . . . Causation implies that
    by varying one factor I can make another vary. [¹](#footnote-211)
  id: totrans-9
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 因果关系中的典范断言是：对原因的操纵将导致结果的操纵……因果关系意味着通过改变一个因素，我可以使另一个因素发生变化。[¹](#footnote-211)
- en: 'Interventions are how we go from correlation to causality. Correlation is symmetric;
    the statements “Amazon’s laptop sales correlate with Amazon’s laptop bag sales”
    and “Amazon’s laptop bag sales correlate with Amazon’s laptop sales” are equivalent.
    But interventions make causality a one-way street: if Amazon recommends the sale
    of laptops, laptop bag sales will increase, but if Amazon promotes the sale of
    laptop bags, we wouldn’t expect people to respond by buying new laptops to fill
    them.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 干预是我们从相关性到因果性的途径。相关性是对称的；关于“亚马逊的笔记本电脑销量与亚马逊的笔记本电脑包销量相关”和“亚马逊的笔记本电脑包销量与亚马逊的笔记本电脑销量相关”的陈述是等价的。但干预使因果关系成为单向的：如果亚马逊推荐笔记本电脑的销售，笔记本电脑包的销量将会增加，但如果亚马逊推广笔记本电脑包的销售，我们不会期望人们通过购买新的笔记本电脑来填充它们。
- en: A model must have a way of reasoning about intervention to be admitted to the
    club of causal models. Any model that lets you reason about how interventions
    change the DGP is, by definition, a causal model.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 一个模型必须有一种推理干预的方法才能进入因果模型俱乐部。任何允许你推理干预如何改变DGP的模型，按定义，就是一个因果模型。
- en: You are probably already familiar with interventions in the form of experiments,
    such as A/B tests or randomized clinical trials. Such experiments focus on inferring
    causal effects. Put simply, a causal effect is just a comparison of the expected
    results of different interventions (e.g., a treatment and a control, or “A” and
    “B” in an A/B test).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经熟悉以实验形式进行的干预，例如A/B测试或随机临床试验。这类实验专注于推断因果关系。简单来说，因果关系就是比较不同干预措施（例如，治疗和控制，或A/B测试中的“A”和“B”）的预期结果。
- en: In this chapter, you’ll learn how to model an intervention and causal effects
    even if, indeed *especially* if, we do not or cannot do the intervention in real
    life. We’ll start this chapter with case studies that motivate modeling interventions.
    All the datasets and notebooks for executing them are available at [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习如何建模干预和因果关系，即使实际上我们无法或不能在现实生活中进行干预。我们将从激发建模干预的案例研究开始本章。所有用于执行这些案例研究的数据库和笔记本都可在[https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)找到。
- en: 7.1 Case studies of interventions
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.1 干预案例研究
- en: A machine learning model can drive decisions to make “interventions.” Those
    interventions can, in turn, create conditions different from those that occurred
    during model training. This mismatch in training conditions and deployment conditions
    can lead to problems.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习模型可以驱动决策以进行“干预”。这些干预反过来又可能创造出与模型训练期间不同的条件。这种训练条件和部署条件的不匹配可能导致问题。
- en: '7.1.1 Case study: Predicting the weather vs. business performance'
  id: totrans-16
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1.1 案例研究：预测天气与业务表现
- en: Every day you wake up, look out the window, and guess whether or not it will
    rain. Based on that guess, you decide whether to take an umbrella on your morning
    walk to work. Several times you guess and choose incorrectly; you either take
    an umbrella and it doesn’t rain, making you look like a fop, or you don’t take
    the umbrella, and it rains, making you look wet. You decide to train a machine
    learning model that will take detailed atmospheric readings in the morning and
    produce a prediction of whether or not it will rain. By leveraging machine learning
    to get more accurate predictions, you expect fewer mistakes in deciding whether
    to bring the umbrella.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 每天当你醒来，望向窗外，猜测今天是否会下雨。基于这个猜测，你决定是否在早上上班的路上带上伞。有好几次你猜错了；要么你带了伞但没下雨，看起来像个傻瓜，要么你没带伞，结果下雨了，看起来很湿。你决定训练一个机器学习模型，该模型将在早上获取详细的气象数据，并预测是否会下雨。通过利用机器学习来获得更准确的预测，你期望在决定是否带伞时犯的错误更少。
- en: You start by collecting daily atmospheric readings as features, and record whether
    it rained as labels. After enough days, you have your first block of training
    data. Next, you train the model on that training data and validate its accuracy
    on hold-out data. Finally, you deploy the trained model, meaning that you use
    it daily to decide whether to take or leave your umbrella. As you use the deployed
    model, you continue to log features and labels daily. Eventually, you have enough
    additional data for a second training block, and you retrain your model to benefit
    from both blocks of data, leading to higher accuracy than you had after training
    on just the first block. You continue to iteratively train the model as you collect
    more blocks of data. Figure 7.1 illustrates the workflow.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 你首先收集每日气象数据作为特征，并记录是否下雨作为标签。经过足够多的日子，你就有了第一块训练数据。接下来，你在这些训练数据上训练模型，并在保留数据上验证其准确性。最后，你部署了训练好的模型，这意味着你每天使用它来决定是否带伞。当你使用部署的模型时，你继续每天记录特征和标签。最终，你有了足够多的额外数据来形成第二个训练块，你重新训练模型以从这两块数据中受益，从而比仅训练第一块数据后获得更高的准确性。随着你收集更多数据块，你继续迭代地训练模型。图7.1说明了工作流程。
- en: '![figure](../Images/CH07_F01_Ness.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH07_F01_Ness.png)'
- en: Figure 7.1 Example of a machine learning training workflow where the sensor
    data is the features, weather is the label, and bringing an umbrella is the decision.
    After each training block, the new data is used to update the old model, and a
    new model is deployed. In this case, the decision does not affect future data.
  id: totrans-20
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.1 机器学习训练工作流程的示例，其中传感器数据是特征，天气是标签，带伞是决策。在每个训练块之后，新数据用于更新旧模型，并部署新模型。在这种情况下，决策不会影响未来的数据。
- en: Now let’s consider a parallel example in business. You are a data scientist
    at a company. Instead of atmospheric readings, you have economic and industry
    data. Instead of predicting whether the day will be rainy, you are predicting
    whether the quarter will end with low revenues. Instead of deciding whether to
    bring an umbrella, you are deciding whether to advertise. Figure 7.2 illustrates
    the workflow, which mirrors the weather example in figure 7.1 exactly; sunny and
    rainy days in figure 7.1 map to good and bad quarters in figure 7.2, and the decision
    to bring or leave the umbrella maps to the decision to advertise or not.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们考虑一个并行于商业的例子。你是一家公司的数据科学家。你有的不是气象数据，而是经济和行业数据。你不是预测天气是否会下雨，而是预测季度是否会以低收入结束。你不是决定是否带伞，而是决定是否做广告。图7.2说明了工作流程，这与图7.1中的天气例子完全相同；图7.1中的晴朗和雨天映射到图7.2中的好季度和坏季度，而带伞或不带伞的决定映射到做广告或不做广告的决定。
- en: '![figure](../Images/CH07_F02_Ness.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH07_F02_Ness.png)'
- en: Figure 7.2 This is a mirror example of the workflow in figure 7.1\. Business
    indicators are the features, quarterly performance is the label, and advertising
    is the decision. In this case, the decision affects future data.
  id: totrans-23
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.2 这是图7.1中工作流程的镜像示例。业务指标是特征，季度业绩是标签，广告是决策。在这种情况下，决策会影响未来的数据。
- en: Even though the labels and decisions in the two examples mirror one another,
    the causal structure of the business example is fundamentally different; the act
    of bringing an umbrella will not affect the weather in future days, but the act
    of advertising will affect business in future quarters. As a result, training
    block 2 represents a different DGP than training block 1 because revenue in training
    block 2 was affected by advertising. During training, a naive predictive model
    might go so far as to associate signs of a lousy quarter with *high* revenue,
    since, in the past, signs of bad quarters led your company to advertise, which
    consequently boosted revenue.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这两个例子中的标签和决策相互对应，但商业示例的因果关系在本质上不同；带伞的行为不会影响未来几天的天气，但广告行为会影响未来几个季度的商业。因此，训练块2代表了一个与训练块1不同的DGP，因为在训练块2中的收入受到了广告的影响。在训练过程中，一个简单的预测模型可能会将一个糟糕季度的迹象与*高*收入联系起来，因为在过去，糟糕季度的迹象导致你的公司进行广告宣传，从而提高了收入。
- en: We deploy machine learning models to drive or automate decisions. Those decisions
    do not impact the data in domains like meteorology, geology, and astronomy. But
    in many, if not most, domains where we want to use machine learning, those model-driven
    decisions are interventions—actions that change the DGP. That can lead to a mismatch
    between the model’s training and deployment conditions, leading to problems in
    the model’s reliability.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们部署机器学习模型来驱动或自动化决策。这些决策不会影响气象学、地质学和天文学等领域的数据。但在我们想要使用机器学习的许多（如果不是大多数）领域，这些由模型驱动的决策是干预——改变DGP的行动。这可能导致模型训练和部署条件之间的不匹配，导致模型可靠性的问题。
- en: Another real-world example of this problem occurs in anomaly detection.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题的另一个现实世界例子发生在异常检测中。
- en: '7.1.2 Case study: Credit fraud detection'
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1.2 案例研究：信用欺诈检测
- en: Anomaly detection seeks to predict when an abnormal event is occurring. One
    example is detecting a fraudulent transaction on a credit card. Credit card companies
    do supervised training of predictive models of fraud using transaction data, where
    attributes of credit card transactions (buying patterns, location, cost of the
    item, etc.) are the features, and whether the customer later reports the transaction
    as fraudulent is the label.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 异常检测旨在预测何时发生异常事件。一个例子是在信用卡上检测欺诈交易。信用卡公司使用交易数据对欺诈预测模型进行监督训练，其中信用卡交易属性（购买模式、位置、商品成本等）是特征，而客户是否后来报告交易为欺诈是标签。
- en: As in the weather and business examples, you train a model on an initial training
    block. After training, you can deploy the algorithm to predict fraud in real time.
    When a transaction is initiated, the algorithm is run, and a prediction is generated.
    If the algorithm predicts fraud, the transaction is rejected.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 正如天气和商业示例中一样，你在一个初始训练块上训练模型。训练完成后，你可以部署算法以实时预测欺诈。当交易启动时，算法运行，并生成预测。如果算法预测欺诈，则拒绝交易。
- en: While this system is in deployment, a second training set is being compiled.
    Some fraud still gets through and is later reported as fraudulent by the customers.
    Those transactions are labeled fraudulent in this new block of data, but the DGP
    has changed from the initial training set. The deployed version 1.0 predictive
    model is rejecting transactions that it predicted were fraudulent, but because
    they were rejected, you don’t know if they were actual cases of fraud. These rejected
    transactions are excluded from the next training set because they lack labels.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 当这个系统处于部署状态时，第二个训练集正在被编译。一些欺诈仍然得以通过，并被客户后来报告为欺诈。这些交易在这个新数据块中被标记为欺诈，但DGP（数据生成过程）已经从初始训练集改变。部署的1.0版本预测模型正在拒绝它预测为欺诈的交易，但由于它们被拒绝，你不知道它们是否真的是欺诈案例。这些被拒绝的交易因为缺乏标签而被排除在下一个训练集之外。
- en: If the model is retrained on the second block, it may develop a bias toward
    fraud that slipped past the fraud rejection system and against the cases of fraud
    that were rejected. This bias can become more severe over several iterations.
    This process is analogous to a homicide detective who, over time, does well in
    solving cases involving uncommon weapons but poorly in cases involving guns.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 如果模型在第二个块上重新训练，它可能会发展出对欺诈的偏见，这种偏见在欺诈拒绝系统中被遗漏，并对被拒绝的欺诈案例产生偏见。这种偏见可能会在多次迭代中变得更加严重。这个过程类似于一个随着时间的推移在解决涉及不常见武器的案件方面做得很好但在涉及枪支的案件方面做得不好的谋杀案侦探。
- en: The filtering of fraudulent transactions in deployment is an intervention. In
    practice, anomaly detection algorithms address this problem by accounting for
    interventions in some way.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署中过滤欺诈交易是一种干预措施。在实践中，异常检测算法通过某种方式考虑干预来解决这个问题。
- en: '7.1.3 Case study: Statistical analysis for an online role-playing game'
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1.3 案例研究：在线角色扮演游戏的统计分析
- en: Suppose you are a data scientist at an online role-playing game company. Your
    leadership wants to know if side-quest engagement (mini-objectives that are tangential
    to the game’s primary objectives) is a driver of in-game purchases of virtual
    artifacts. If the answer is yes, the company will intervene in the game dynamics
    such that players engage in more side-quests.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你是一家在线角色扮演游戏公司的数据科学家。你的领导想知道支线任务参与度（与游戏主要目标无关的迷你目标）是否是虚拟物品游戏内购买的驱动因素。如果答案是肯定的，公司将在游戏动态中干预，使玩家参与更多支线任务。
- en: 'You do an analysis. You query the database and pull records for a thousand
    players, the first five of which are shown in table 7.1\. This is observational
    data (in contrast to experimental data) because the data is logged observations
    of the natural behavior of players as they log in and play. (The full dataset
    is available in the notebooks for the chapter: [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook).)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 你进行了一项分析。你查询数据库并抽取了一千名玩家的记录，其中前五名显示在表 7.1 中。这是观察数据（与实验数据相对），因为数据是玩家登录和玩游戏时的自然行为记录。（完整数据集可在本章的笔记本中找到：[https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)。)
- en: Table 7.1 Example rows from observational data on *Side-Quest Engagement* and
    *In-Game Purchases*
  id: totrans-36
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 7.1 *支线任务参与度* 和 *游戏内购买* 观察数据的示例行
- en: '| User ID | Side-Quest Engagement | In-Game Purchases |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 用户 ID | 支线任务参与度 | 游戏内购买 |'
- en: '| --- | --- | --- |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 71d44ad5  | high  | 156.77  |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 71d44ad5  | 高  | 156.77  |'
- en: '| e6397485  | low  | 34.89  |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| e6397485  | 低  | 34.89  |'
- en: '| 87a5eaf7  | high  | 172.86  |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 87a5eaf7  | 高  | 172.86  |'
- en: '| c5d78ca4  | low  | 215.74  |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| c5d78ca4  | 低  | 215.74  |'
- en: '| d3b2a8ed  | high  | 201.07  |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| d3b2a8ed  | 高  | 201.07  |'
- en: '| dc85d847  | low  | 12.93  |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| dc85d847  | 低  | 12.93  |'
- en: The standard data science analysis would involve running a statistical test
    of the hypothesis that there is a difference between the *In-Game Purchases* of
    players highly engaged in side-quests and those with low *Side-Quest Engagement*.
    The test calculates the mathematical difference between the sample means of *In-Game
    Purchases* for both groups. In statistical terms, this difference estimates an
    *effect size*. The test will examine whether this estimated effect size is significantly
    different from zero.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 标准的数据科学分析将涉及对假设进行统计检验，即高度参与支线任务的玩家的 *游戏内购买* 与低 *支线任务参与度* 的玩家之间存在差异。该测试计算两组 *游戏内购买*
    样本均值之间的数学差异。在统计学上，这个差异估计了一个 *效应量*。该测试将检验这个估计的效应量是否与零有显著差异。
- en: Setting up your environment
  id: totrans-46
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 设置你的环境
- en: The code for this chapter was written with Pyro version 1.9.0, pandas version
    2.2.1, and pgmpy version 0.1.25\. Using Pyro’s `render` function to visualize
    a Pyro model as a DAG will require Graphviz. Visit [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)
    for a link to a notebook that contains the code.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码是用 Pyro 版本 1.9.0、pandas 版本 2.2.1 和 pgmpy 版本 0.1.25 编写的。使用 Pyro 的 `render`
    函数将 Pyro 模型可视化为 DAG 将需要 Graphviz。访问 [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)
    获取包含代码的笔记本链接。
- en: We’ll perform this hypothesis test with the pandas library. First, we’ll pull
    the data and get the sample means and standard deviations within each group.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 pandas 库执行这个假设检验。首先，我们将获取数据并获取每个组内的样本均值和标准差。
- en: Listing 7.1 Load *Side-Quest Engagement* vs.*In-Game Purchases* data and summarize
  id: totrans-49
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.1 加载 *支线任务参与度* 与 *游戏内购买* 数据并总结
- en: '[PRE0]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '#1 Load the data from the database query into a pandas DataFrame.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 从数据库查询中加载数据到 pandas DataFrame。'
- en: '#2 For each level of Side-Quest Engagement (“low”, “high”), calculate the sample
    count (number of players), the sample mean In-Game Purchases amount, and the standard
    deviation.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 对于每个 *支线任务参与度* 的级别（“低”，“高”），计算样本计数（玩家数量）、游戏内购买的平均金额和标准差。'
- en: This produces the summary in table 7.2.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这生成了表 7.2 的总结。
- en: Table 7.2 Summary statistics from the online game data
  id: totrans-54
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 7.2 在线游戏数据的汇总统计
- en: '| Side-Quest Engagement | mean purchases | std | n |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 支线任务参与度 | 平均购买 | 标准差 | n |'
- en: '| --- | --- | --- | --- |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| low  | 73.10  | 75.95  | 518  |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 低  | 73.10  | 75.95  | 518  |'
- en: '| high  | 111.61  | 55.56  | 482  |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 高   | 111.61  | 55.56  | 482  |'
- en: This database query pulled 1,000 players, where 482 of them were highly engaged
    in side-quests and 518 were not. The mean *In-Game Purchases* amount for highly
    engaged players is around $112 for high *Side-Quest Engagement* and $73 for low
    *Side-Quest Engagement*. Generalizing beyond this data, we conclude that players
    who are highly engaged in side-quests spend, on average 112 – 73 = $39 dollars
    more than those who aren’t. We can run a two-sample *Z*-test to make sure this
    difference is significant.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据库查询检索了1,000名玩家，其中482名高度参与支线任务，518名没有参与。高度参与玩家的平均*游戏内购买*金额约为112美元，对于高*支线任务参与度*，而低*支线任务参与度*为73美元。将数据推广到这个范围之外，我们得出结论，高度参与支线任务的玩家平均比不参与的玩家多花费112
    - 73 = 39美元。我们可以运行双样本*Z*测试来确保这种差异是显著的。
- en: '**Listing 7.2 Test if effect of engagement on *In-Game Purchases* is statistically
    significant**'
  id: totrans-60
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**列表7.2 测试参与对*游戏内购买*的影响是否具有统计学意义**'
- en: '[PRE1]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '#1 n1 and n2 are the numbers of players in each group (high vs. low engagement).'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 n1和n2是每个组（高参与度与低参与度）中的玩家数量。'
- en: '#2 m1 and m2 are the group sample means.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 m1和m2是组样本均值。'
- en: '#3 s1 and s2 are the group standard deviations.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 s1和s2是组标准差。'
- en: '#4 Estimate the standard error of the difference in mean spending by pooling
    (combining) the group standard deviations.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 通过合并（组合）组标准差来估计平均支出的差异标准误。'
- en: '#5 Convert to a z-score, which has a standard norm under the (null) hypothesis
    of no difference in spending across engagement levels.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 将数据转换为z分数，该分数在（零假设）不同参与级别之间支出无差异的情况下具有标准正态分布。'
- en: '#6 Test if the z-score is more than 2 standard deviations from 0, which beats
    a 5% significance threshold.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 测试z分数是否超过0的2个标准差，这超过了5%的显著性阈值。'
- en: 'Running this code shows that the difference in means is significant. Great,
    you did some data science that showed you have a statistically significant effect
    size: *In-Game Purchases* are significantly higher for players who are highly
    engaged in side-quests relative to those who are not. Based on your findings,
    leadership decides to modify the game dynamics to draw players into more side-quests.
    As a result, *In-Game Purchases* *decline*. How could this happen?'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此代码显示均值差异是显著的。太好了，你进行了一些数据科学，表明你有一个具有统计学意义的效果量：与不参与的玩家相比，高度参与支线任务的玩家的*游戏内购买*显著更高。基于你的发现，管理层决定修改游戏动态以吸引玩家参与更多支线任务。结果，*游戏内购买*量*下降*。这怎么可能发生呢？
- en: 7.1.4 From randomized experiments to interventions
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1.4 从随机实验到干预
- en: By now you’ve probably recognized that the result from listing 7.2 is a textbook
    example of how correlation doesn’t imply causation. If management wanted to know
    if intervening on game dynamics would lead to an increase in *In-Game Purchases*,
    they should have relied on analysis from a randomized experiment, not simple observational
    data. We’ll use the randomized experiment to build more intuition for a formal
    model of intervention and see how that intervention model could simulate a randomized
    experiment.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 到现在为止，你可能已经认识到列表7.2的结果是相关关系不意味着因果关系的教科书式例子。如果管理层想知道干预游戏动态是否会增加*游戏内购买*，他们应该依赖于来自随机实验的分析，而不是简单的观察数据。我们将使用随机实验来增强对干预正式模型的直觉，并看看这个干预模型如何模拟随机实验。
- en: 7.1.5 From observations to experiments
  id: totrans-71
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1.5 从观察到实验
- en: Suppose that instead of running an observational study, you run an experiment.
    Rather than pull data from a SQL query, you randomly select a set of 1,000 players
    and randomly assign them to one of two groups of 500\. In one group, the game
    dynamics are modified such that *Side-Quest Engagement* is artificially fixed
    at “low,” and in the other group it is fixed to “high.” We’ll then observe their
    level of *In-Game Purchases*.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你运行的不是观察研究，而是实验。而不是从SQL查询中提取数据，你随机选择一组1,000名玩家，并将他们随机分配到两个500人的组中。在一个组中，游戏动态被修改，使得*支线任务参与度*被人为地固定在“低”，而在另一个组中则固定在“高”。然后我们将观察他们的*游戏内购买*水平。
- en: This will create experimental data that is the same size and has roughly the
    same split between engaged and unengaged players as the observational data in
    section 7.1.3\. Similarly, we’ll run the same downstream analysis. This will let
    us make an apples-to-apples comparison of using observational versus experimental
    data.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建与第7.1.3节中观察数据大小相同，并且参与和不参与玩家大致分割相同的实验数据。同样，我们将运行相同的前向分析。这将使我们能够对使用观察数据与实验数据进行苹果对苹果的比较。
- en: Table 7.3 shows examples from the experimental data. You can find links to the
    data in [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7.3 显示了实验数据的示例。您可以在 [https://www.altdeep.ai/p/causalaibook](https://www.altdeep.ai/p/causalaibook)
    找到数据链接。
- en: Table 7.3 Example rows from the experimental data evaluating the effect of *Side-Quest
    Engagement* on *In-Game Purchases*
  id: totrans-75
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 7.3 评估 *支线任务参与度* 对 *游戏内购买* 影响的实验数据示例行
- en: '| User ID | Side-Quest Engagement | In-Game Purchases |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 用户 ID | 支线任务参与度 | 游戏内购买 |'
- en: '| --- | --- | --- |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 2828924d  | low  | 224.39  |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 2828924d  | 低  | 224.39  |'
- en: '| 7e7c2452  | low  | 19.89  |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 7e7c2452  | 低  | 19.89  |'
- en: '| 3ddf2915  | low  | 221.26  |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 3ddf2915  | 低  | 221.26  |'
- en: '| 10c3d883  | high  | 93.21  |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 10c3d883  | 高  | 93.21  |'
- en: '| c5080957  | high  | 61.82  |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| c5080957  | 高  | 61.82  |'
- en: '| 241c8fcf  | high  | 188.76  |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 241c8fcf  | 高  | 188.76  |'
- en: Again, we summarize the data with the following code.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，我们使用以下代码总结数据。
- en: Listing 7.3 Load experimental data and summarize
  id: totrans-85
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.3 加载实验数据并总结
- en: '[PRE2]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#1 Load the experimental data from the database query into a pandas DataFrame.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 从数据库查询中加载实验数据到 pandas DataFrame。'
- en: '#2 For each level of Side-Quest Engagement (“low”, “high”), calculate the sample
    count (number of players), the sample mean in-game purchase amount, and the standard
    deviation.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 对于每个支线任务参与度级别（“低”，“高”），计算样本计数（玩家数量）、样本平均游戏内购买金额和标准差。'
- en: Table 7.4 shows the same summary statistics for the experimental data as table
    7.2 does for the observational data.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7.4 显示了与表 7.2 对观察数据所做的相同汇总统计，对于实验数据。
- en: Table 7.4 Summary statistics from the online game experimental data
  id: totrans-90
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 7.4 在线游戏实验数据的汇总统计
- en: '| Side-Quest Engagement | mean purchases | std | n |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 支线任务参与度 | 平均购买 | 标准差 | n |'
- en: '| --- | --- | --- | --- |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| low  | 92.99  | 51.67  | 500  |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 低  | 92.99  | 51.67  | 500  |'
- en: '| high  | 131.38  | 94.84  | 500  |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 高  | 131.38  | 94.84  | 500  |'
- en: The experiment reflects what happened when the company intervened to increase
    *Side-Quest Engagement*. The sign of the effect size is negative relative to our
    first analysis; we got –38.39, meaning the mean purchases went down $38.39\. When
    we rerun the test of significance in listing 7.4, we see the difference is significant
    for the experimental data, just as it was for the observational data.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 实验反映了公司干预以增加*支线任务参与度*时发生的情况。与我们的第一次分析相比，效应量的符号是负的；我们得到了 –38.39，这意味着平均购买量下降了
    $38.39。当我们重新运行列表 7.4 中的显著性测试时，我们看到实验数据与观察数据一样，差异是显著的。
- en: Listing 7.4 Conduct significance test on (experimental) difference in mean purchases
  id: totrans-96
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.4 对（实验）平均购买差异进行显著性测试
- en: '[PRE3]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '#1 n1 and n2 are the number of players in each group (high vs low engagement).'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 n1 和 n2 是每个小组（高参与度 vs 低参与度）中的玩家数量。'
- en: '#2 m1 and m2 are the group sample means.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 m1 和 m2 是组样本均值。'
- en: '#3 s1 and s2 are the group standard deviations.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 s1 和 s2 是组标准差。'
- en: '#4 Estimate the standard error of the difference in mean spend by pooling (combining)
    the group standard deviations.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 通过合并（组合）组标准差来估计平均花费差异的标准误差。'
- en: '#5 Convert to a z-score, which has a standard norm under the (null) hypothesis
    of no difference in spend across engagement levels.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 转换为 z 分数，在（零假设）花费水平无差异的假设下具有标准正态分布。'
- en: '#6 Tests if the z-score is more than 2 standard deviations from 0, which beats
    a 5% significance threshold.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '#6 测试 z 分数是否超过 0 的 2 个标准差，这超过了 5% 的显著性阈值。'
- en: The result shows the difference in group means is again significant. If you
    had reported the results of this experiment instead of the results of the observational
    study, you would have correctly concluded that a policy of encouraging higher
    *Side-Quest Engagement* would lead to a drop in average *In-Game Purchases* (and
    you wouldn’t have recommended doing so).
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示，组均值差异再次显著。如果你报告的是实验结果而不是观察研究的成果，你就会正确地得出结论：鼓励更高的*支线任务参与度*的政策会导致平均*游戏内购买*（以及你不会推荐这样做）的下降。
- en: This experiment had a cost. Many of those 1,000 players who were included in
    the experiment would have spent more on *In-Game Purchases* had they not been
    included in the experiment, and this is especially true for the 500 players assigned
    to the high side-quests group. That amounts to lost revenue that would have been
    realized had you not run the experiment. Moreover, the experiment created a suboptimal
    gaming experience for players who were assigned a level of *Side-Quest Engagement*
    that was different from their preferred level. These players are paying the company
    for a certain experience, and the experiment degraded that experience.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这个实验是有成本的。实验中包含的1000名玩家中，许多人如果没有被包括在实验中，他们会在*游戏内购买*上花费更多，尤其是对于被分配到高支线任务组的500名玩家。这相当于没有进行实验就会实现的收入损失。此外，实验为那些被分配到与其偏好水平不同的*支线任务参与度*水平的玩家创造了次优的游戏体验。这些玩家为公司支付了一定体验的费用，而实验降低了这种体验。
- en: The least ideal outcome is reporting based on our simple two-sample analysis
    of the observational data; this had no cost, but it gave the wrong answer. A better
    outcome is running the experiment and getting the correct answer, though this
    comes at a cost. The ideal outcome is getting the right answer on the observational
    data for free. To do that, we need a causal model.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 最不理想的结果是基于我们对观测数据的简单双样本分析进行报告；这没有成本，但给出了错误的答案。更好的结果是运行实验并得到正确的答案，尽管这需要付出代价。理想的结果是在观测数据上免费得到正确的答案。要做到这一点，我们需要一个因果模型。
- en: 7.1.6 From experiments to interventions
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1.6 从实验到干预
- en: Let’s see how we can use a causal model to simulate the results of the experiment
    from the observational data. First, let’s assume the causal DAG in figure 7.3.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用因果模型来模拟从观测数据中得到的实验结果。首先，让我们假设图7.3中的因果DAG。
- en: '![figure](../Images/CH07_F03_Ness.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH07_F03_Ness.png)'
- en: Figure 7.3 A simple DAG showing the causal relationship between *Side-Quest
    Engagement* and *In-Game Purchases. Guild Membership*is a common cause of both.
  id: totrans-110
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.3 一个简单的DAG，展示了*支线任务参与度*和*游戏内购买*之间的因果关系。*公会成员资格*是两者的共同原因。
- en: In our online game, many players are members of guilds. Guilds are groups of
    players who pool resources and coordinate their gameplay, such as working together
    on side-quests. Our model assumes that the amount of *In-Game Purchases* a player
    makes also depends on whether they are in a guild; members of the same guild pool
    resources, and many resources are virtual items they must purchase.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的在线游戏中，许多玩家是公会成员。公会是一群玩家，他们聚集资源并协调他们的游戏玩法，例如一起完成支线任务。我们的模型假设玩家进行的*游戏内购买*数量也取决于他们是否在公会中；同一公会的成员聚集资源，许多资源是他们必须购买的虚拟物品。
- en: Suppose you run a modified version of that initial database query. The query
    produces the same exact observational data seen in table 7.1, except this time
    it includes an additional column indicating *Guild Membership*. Again, we see
    six players in table 7.5 (the same six as players shown in table 7.1).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你运行了一个修改后的初始数据库查询版本。查询产生了与表7.1中看到的相同的观测数据，但这次它包括了一个额外的列，表示*公会成员资格*。同样，我们在表7.5中看到了六名玩家（与表7.1中显示的玩家相同）。
- en: Table 7.5 The same observational data as in table 7.1, but with a *Guild Membersh**ip*column
  id: totrans-113
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表7.5 与表7.1相同的观测数据，但增加了*公会成员资格*列
- en: '| User ID | Side-Quest Engagement | Guild Membership | In-Game Purchases |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 用户ID | 支线任务参与度 | 公会成员资格 | 游戏内购买 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 71d44ad5  | high  | member  | 156.77  |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 71d44ad5  | 高  | 成员  | 156.77  |'
- en: '| e6397485  | low  | nonmember  | 34.89  |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| e6397485  | 低  | 非成员  | 34.89  |'
- en: '| 87a5eaf7  | high  | member  | 172.86  |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 87a5eaf7  | 高  | 非成员  | 12.93  |'
- en: '| c5d78ca4  | low  | member  | 215.74  |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| c5d78ca4  | 低  | 成员  | 215.74  |'
- en: '| d3b2a8ed  | high  | member  | 201.07  |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| d3b2a8ed  | 高  | 成员  | 201.07  |'
- en: '| dc85d847  | low  | nonmember  | 12.93  |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| dc85d847  | 低  | 非成员  | 34.89  |'
- en: 'We are going to build a causal graphical model on this observational data using
    Pyro. To do this, we’ll need to model the causal Markov kernels: the probability
    distributions of *Guild Membership*, *Side-Quest Engagement* given *Guild Membership*,
    and *In-Game Purchases* given *Guild Membership* and *Side-Quest Engagement*.
    In our Pyro model, we’ll need to specify some canonical distributions for these
    variables and estimate their parameters.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用Pyro在这个观测数据上构建一个因果图模型。为此，我们需要对因果马尔可夫核进行建模：给定**公会成员资格**的**公会成员**、**支线任务参与度**以及给定**公会成员资格**和**支线任务参与度**的**游戏内购买**的概率分布。在我们的Pyro模型中，我们需要为这些变量指定一些典型分布并估计它们的参数。
- en: Estimating parameters and building the model
  id: totrans-123
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 估计参数和构建模型
- en: Pyro can jointly estimate the parameters of each of our causal Markov kernels
    just as it could the parameters across a complex neural network architecture.
    But it will make our lives easier to estimate the parameters of each kernel one
    at a time using everyday data science analysis, leveraging the concept of *parameter
    modularity* discussed in chapter 2\. Let’s start with *Guild Membership*.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Pyro可以联合估计我们每个因果马尔可夫核的参数，就像它可以估计复杂神经网络架构中的参数一样。但使用日常数据科学分析，通过利用第2章中讨论的**参数模块化**概念，一次估计每个核的参数会使我们的工作更简单。让我们从**公会成员资格**开始。
- en: Listing 7.5 Estimate the probability distribution of *Guild Membership*
  id: totrans-125
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.5 估计**公会成员资格**的概率分布
- en: '[PRE4]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '#1 Load the data from the database query into a pandas DataFrame.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 从数据库查询中加载数据到pandas DataFrame中。'
- en: '#2 Calculate the proportions of members vs. nonmembers.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 计算成员与非成员的比例。'
- en: 'This prints out the following result:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这将打印出以下结果：
- en: '[PRE5]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: These are the proportions of guild members vs. nonmembers in the data. We can
    use these as estimates of the probability that a player is a member or a nonmember.
    If we took these proportions as is, they would be maximum likelihood estimates
    of the probabilities, but for simplicity, we’ll just put it at 50/50 (the probability
    of being a member is .5).
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是数据中公会成员与非成员的比例。我们可以将这些作为估计玩家是成员或非成员的概率。如果我们直接使用这些比例，它们将是概率的最大似然估计，但为了简单起见，我们将将其设置为50/50（成为成员的概率为.5）。
- en: Next, we’ll do the same for the conditional probability distribution (CPD) of
    *Side-Quest Engagement* level given *Guild Membership*.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将对给定**公会成员资格**的**支线任务参与度**条件概率分布（CPD）做同样的处理。
- en: Listing 7.6 Estimate the CPD of *Side-Quest Engagement* given *Guild Membership*
  id: totrans-133
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.6 估计**支线任务参与度**给定**公会成员资格**的CPD
- en: '[PRE6]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '#1 Calculate the probability distribution of Side-Quest Engagement level (“high”
    vs. “low”) given that a player is a member of a guild.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 计算当玩家是公会成员时，**支线任务参与度**水平（“高”与“低”）的概率分布。'
- en: '#2 Calculate the probability distribution of Side-Quest Engagement level (“high”
    vs. “low”) given that a player is not a member of a guild.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 计算当玩家不是公会成员时，**支线任务参与度**水平（“高”与“低”）的概率分布。'
- en: 'Listing 7.6 prints the following output proportions of *Side-Quest Engagement*
    levels for guild members:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 列表7.6 打印了以下输出，显示了公会成员的**支线任务参与度**水平比例：
- en: '[PRE7]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following proportions are for non-guild-members:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 以下比例适用于非公会成员：
- en: '[PRE8]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Again, we’ll round these results. Guild members have an 80% chance of being
    highly engaged in side-quests, while nonmembers have only a 20% chance of being
    highly engaged.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们将对这些结果进行四舍五入。公会成员有80%的可能性在支线任务中高度参与，而非成员只有20%的可能性高度参与。
- en: Finally, for each combination of *Guild Membership* and *Side-Quest Engagement*,
    we’ll calculate the sample mean and standard deviation of *In-Game Purchases*.
    We’ll use these sample statistics as estimates for mean and location parameters
    in a canonical distribution when we code the causal Markov kernel for *In-Game
    Purchases* in the causal model.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，对于**公会成员资格**和**支线任务参与度**的每个组合，我们将计算**游戏内购买**的样本均值和标准差。当我们编码因果模型中**游戏内购买**的因果马尔可夫核时，我们将使用这些样本统计量作为典型分布中均值和位置参数的估计。
- en: '**Listing 7.7 Calculate purchase stats across levels of engagement and *Guild
    Membership***'
  id: totrans-143
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: '**列表7.7 按参与度和**公会成员资格**级别计算购买统计数据***'
- en: '[PRE9]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '#1 Estimate the sample mean and standard deviation of In-Game Purchases for
    non-guild-members with low Side-Quest Engagement.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 估计具有低支线任务参与度的非公会成员的游戏内购买样本均值和标准差。'
- en: '#2 Estimate the sample mean and standard deviation of In-Game Purchases for
    non-guild-members with high Side-Quest Engagement.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 估计具有高支线任务参与度的非公会成员的游戏内购买样本均值和标准差。'
- en: '#3 Estimate the sample mean and standard deviation of In-Game Purchases for
    guild members with low Side-Quest Engagement.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 估计低支线任务参与度的公会成员的游戏内购买的样本均值和标准差。'
- en: '#4 Estimate the sample mean and standard deviation of In-Game Purchases for
    guild members with high Side-Quest Engagement.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 估计高支线任务参与度的公会成员的游戏内购买的样本均值和标准差。'
- en: 'For non-guild-members with low *Side-Quest Engagement*, we have these results:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 对于低*支线任务参与度*的非公会成员，我们有这些结果：
- en: '[PRE10]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: For non-guild-members with high *Side-Quest Engagement*, we have
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 对于高*支线任务参与度*的非公会成员，我们有
- en: '[PRE11]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: For guild members with low *Side-Quest Engagement*, we have
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 对于低*支线任务参与度*的公会成员，我们有
- en: '[PRE12]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: For guild members with high *Side-Quest Engagement*, we have
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 对于高*支线任务参与度*的公会成员，我们有
- en: '[PRE13]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Finally, in listing 7.8, we use these various statistics as parameter estimates
    in a causal graphical model built in Pyro.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在第7.8列表中，我们使用这些各种统计量作为在Pyro中构建的因果图模型中的参数估计。
- en: Listing 7.8 Building a causal model of *In-Game Purchases* in Pyro
  id: totrans-158
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.8 在Pyro中构建*游戏内购买*的因果模型
- en: '[PRE14]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '#1 Probability of being a guild member vs. a nonmember is .5\. Using this probability,
    we generate a Guild Membership value (1 for member, 0 for nonmember) from a Bernoulli
    distribution.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 公会成员与非成员的概率为.5。使用这个概率，我们从伯努利分布中生成了一个公会成员资格值（成员为1，非成员为0）。'
- en: '#2 We generate a value for Side-Quest Engagement from a Bernoulli distribution
    (1 for high, 0 for low) with a parameter that depends on Guild Membership.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 我们从伯努利分布（高为1，低为0）中生成了一个支线任务参与度的值，其参数取决于公会成员资格。'
- en: '#3 Helper function for calculating parameters for In-Game Purchases'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 用于计算游戏内购买参数的辅助函数'
- en: '#4 We specify the location parameter of a normal distribution on In-Game Purchases
    using the sample means we found in the observational data.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 我们使用在观测数据中找到的样本均值来指定游戏内购买的正态分布的位置参数。'
- en: '#5 As with the mean parameters, we specify the scale parameters for a canonical
    distribution on In-Game Purchases using the standard deviations we found in the
    data.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '#5 与均值参数一样，我们使用在数据中找到的标准差来指定游戏内购买的正态分布的尺度参数。'
- en: To confirm that the Pyro model encodes a causal DAG, we can run `pyro.render_
    model(model)`, which produces figure 7.4.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 为了确认Pyro模型编码了一个因果DAG，我们可以运行`pyro.render_model(model)`，这将产生图7.4。
- en: '![figure](../Images/CH07_F04_Ness.png)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH07_F04_Ness.png)'
- en: Figure 7.4 Result of calling `pyro.render_model` with the causal model
  id: totrans-167
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.4 调用`pyro.render_model`与因果模型的结果
- en: Leveraging the parametric flexibility of probabilistic programming
  id: totrans-168
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 利用概率编程的参数灵活性
- en: Note the flexibility of our choices for modeling the variables in the Pyro model.
    For example, in modeling the distribution of *In-Game Purchases*, we used the
    normal distribution, but we could have used other distributions. For example,
    *In-Game Purchases* cannot be a negative number, so we could have selected a canonical
    distribution that is only defined for positive numbers, rather than a normal distribution,
    which is defined for negative and positive numbers. This would be especially useful
    for non-guild-members with low *Side-Quest Engagement*, because generation from
    a normal distribution with a mean of 37.95 and a scale parameter of 23.80 will
    have about a 5.5% chance of generating a negative value. However, we’re choosing
    to be a bit lazy and use the normal distribution in this case, since a few negative
    numbers for *In-Game Purchases* won’t have much impact on the results of our analysis.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 注意我们在Pyro模型中建模变量的选择灵活性。例如，在建模*游戏内购买*的分布时，我们使用了正态分布，但我们可以使用其他分布。例如，*游戏内购买*不能是负数，因此我们可以选择一个仅对正数定义的规范分布，而不是对负数和正数都定义的正态分布。这对于低*支线任务参与度*的非公会成员特别有用，因为从均值为37.95和尺度参数为23.80的正态分布生成将大约有5.5%的概率生成负值。然而，我们选择在这个情况下稍微偷懒，使用正态分布，因为几个负数的*游戏内购买*对我们的分析结果影响不大。
- en: The point is that probabilistic programming tools like Pyro provide us with
    parametric flexibility, unlike tools like pgmpy. It is good practice to leverage
    that flexibility to reflect your assumptions about the DGP.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 重点是，概率编程工具如Pyro为我们提供了参数灵活性，与pgmpy等工具不同。利用这种灵活性来反映你对DGP的假设是一种好的做法。
- en: Pyro’s intervention abstraction
  id: totrans-171
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Pyro的干预抽象
- en: Pyro has an abstraction for representing an intervention in `pyro.do`. It takes
    a model and returns a new model that reflects the intervention. Listing 7.9 shows
    how we can use `pyro.do` to change the previous model into one that reflects an
    intervention that sets *Side-Quest Engagement* to “high” and to “low.”
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: Pyro 在 `pyro.do` 中提供了一个表示干预的抽象。它接受一个模型并返回一个新的模型，该模型反映了干预。列表 7.9 展示了我们可以如何使用
    `pyro.do` 将之前的模型转换为反映将 *侧任务参与度* 设置为“高”和“低”的干预的模型。
- en: Listing 7.9 Representing interventions with `pyro.do`
  id: totrans-173
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.9 使用 `pyro.do` 表示干预
- en: '[PRE15]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '#1 An intervention that sets Side-Quest Engagement to 1.0 (i.e., “high”). This
    returns a new model.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 将 *侧任务参与度* 设置为 1.0（即，“高”）。这将返回一个新的模型。'
- en: '#2 An intervention that sets Side-Quest Engagement to 0.0 (i.e., “low”). This
    returns a new model.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 将 *侧任务参与度* 设置为 0.0（即，“低”）。这将返回一个新的模型。'
- en: 'Now we have two new models: one with an intervention that sets *Side-Quest
    Engagement* to “high” and one that sets it to “low.” If our original model is
    correct, generating 500 examples from each of these new intervened-upon models,
    and combining them into 1000 examples, effectively *simulates* the experiment.
    Remember, we estimated the parameters of this causal model using only the observational
    data illustrated in table 7.4\. If we can train a model on observational data
    and use it to accurately simulate the results of an experiment, that saves us
    from actually having to run the experiment.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有两个新的模型：一个将 *侧任务参与度* 设置为“高”，另一个将其设置为“低”。如果我们的原始模型是正确的，从每个新干预模型中生成 500 个示例，并将它们合并成
    1000 个示例，实际上 *模拟* 了实验。记住，我们仅使用表 7.4 中展示的观察数据来估计这个因果模型的参数。如果我们能在观察数据上训练一个模型，并使用它来准确模拟实验结果，那么我们就无需实际运行实验。
- en: Listing 7.10 uses `int_engaged_model` and `int_unengaged_model` to simulate
    experimental data. We can confirm that the simulation was effective by comparing
    the summary statistics of this simulated data to the summary statistics of the
    actual experimental data.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 列表 7.10 使用 `int_engaged_model` 和 `int_unengaged_model` 来模拟实验数据。我们可以通过比较此模拟数据的汇总统计与实际实验数据的汇总统计来确认模拟的有效性。
- en: Listing 7.10 Simulating experimental data with `pyro.do` interventions
  id: totrans-179
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 7.10 使用 `pyro.do` 干预模拟实验数据
- en: '[PRE16]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '#1 Set a random seed for reproducibility.'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 为可重复性设置随机种子。'
- en: '#2 Simulate 500 rows from each intervention model, and combine them to create
    simulated experimental data.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 从每个干预模型中模拟 500 行，并将它们合并以创建模拟的实验数据。'
- en: '#3 The simulated data will include a Guild Membership column. We can drop it
    to get simulated data that looks like the original experiment.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 模拟数据将包括一个公会会员资格列。我们可以删除它以获得看起来像原始实验的模拟数据。'
- en: '#4 Recreate the statistical summaries of In-Game Purchases for each level of
    engagement.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 重新创建每个参与度级别的游戏内购买统计摘要。'
- en: This code simulates the experiment, providing the summaries in table 7.6\. Again,
    these are sample statistics from a simulated experiment we created by first estimating
    some parameters on observational data, second, building a causal generative model
    with those parameters, and third, using `pyro.do` to simulate the results of an
    intervention. Contrast these with the statistics in table 7.7 that we obtained
    from the *actual* experimental data.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码模拟了实验，提供了表 7.6 中的总结。同样，这些是从我们创建的模拟实验中获得的样本统计，我们首先在观察数据上估计了一些参数，其次，使用这些参数构建了一个因果生成模型，第三，使用
    `pyro.do` 来模拟干预的结果。将这些与表 7.7 中的统计数据进行对比，后者是我们从 *实际* 实验数据中获得的。
- en: Table 7.6 Summary statistics from the simulated experiment
  id: totrans-186
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 7.6 模拟实验的汇总统计
- en: '| Side-Quest Engagement | count | mean | std |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 侧任务参与度 | 数量 | 平均值 | 标准差 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| high  | 500  | 89.897309  | 52.696709  |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| 高 | 500 | 89.897309 | 52.696709 |'
- en: '| low  | 500  | 130.674021  | 93.921543  |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| 低 | 500 | 130.674021 | 93.921543 |'
- en: Table 7.7 Summary statistics from the actual experiment
  id: totrans-191
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表 7.7 实际实验的汇总统计
- en: '| Side-Quest Engagement | count | mean | std |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| 侧任务参与度 | 数量 | 平均值 | 标准差 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| high  | 500  | 92.99054  | 51.673631  |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 高 | 500 | 92.99054 | 51.673631 |'
- en: '| low  | 500  | 131.38228  | 94.840705  |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| 低 | 500 | 131.38228 | 94.840705 |'
- en: The two sets of summaries are similar enough that we can say that we’ve successfully
    replicated the experimental results from the observational data.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 这两组汇总数据足够相似，我们可以断言我们已经成功地从观察数据中复制了实验结果。
- en: 7.1.7 Recap
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1.7 概述
- en: Let’s recap. A causal DAG combined with a Pyro abstraction for an intervention
    allowed us to do an analysis on an observational dataset that produced the same
    results as an analysis on an experimental dataset. Had you run this analysis on
    the initial observational data instead of the simple two-sample statistical test,
    you would have provided the correct answer to leadership, and they would not have
    changed the dynamics to increase *Side-Quest Engagement*.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下。因果DAG与Pyro干预抽象的结合使我们能够在观察数据集上进行分析，其结果与在实验数据集上进行分析的结果相同。如果您在初始观察数据上运行此分析而不是简单的双样本统计检验，您就会为领导提供正确的答案，他们就不会改变动态来增加
    *Side-Quest Engagement*。
- en: Note that this wasn’t a free lunch. This analysis required causal assumptions
    in the form of a causal DAG. Errors in specifying the causal DAG can lead to errors
    in the output of the analysis. But assuming your causal DAG was correct (or close
    enough), it would have saved you the actual costs and opportunity costs of running
    that experiment.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，这并不是免费的午餐。这项分析需要以因果DAG形式表示的因果假设。在指定因果DAG时出现的错误可能导致分析输出的错误。但假设您的因果DAG是正确的（或足够接近），这将为您节省实际成本和机会成本。
- en: So how exactly does `pyro.do` work? How does it modify the model to represent
    an intervention? We’ll answer these questions with the ideas of *ideal interventions*
    and *intervention operators*.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 那么 `pyro.do` 究竟是如何工作的？它是如何修改模型来表示干预的？我们将通过理想干预和干预算子的概念来回答这些问题。
- en: 7.2 The ideal intervention and intervention operator
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.2 理想干预和干预算子
- en: To understand how our simulated experiment worked, we need a concrete definition
    of intervention. We’ll use a specific definition, called the *ideal intervention*,
    and also known as the *atomic intervention*, *structural intervention*, *surgical
    intervention*, and *independent intervention*.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 为了理解我们的模拟实验是如何工作的，我们需要干预的明确定义。我们将使用一个特定的定义，称为 *理想干预*，也称为 *原子干预*、*结构干预*、*外科干预*
    和 *独立干预*。
- en: 'The definition of an ideal intervention breaks down into three parts:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 理想干预的定义可以分为三个部分：
- en: The ideal intervention targets a specific variable or set of variables in the
    DGP.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理想干预针对DGP中的特定变量或一组变量。
- en: The operation sets those variables to a fixed value.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该操作将那些变量设置为固定值。
- en: By setting the variable to a fixed value, the intervention blocks the influence
    from the target’s causes, such that the target is now statistically independent
    of its causes.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过将变量设置为固定值，干预阻止了来自目标原因的影响，使得目标现在在统计上与其原因独立。
- en: We’ll use the notation do(*X*=*x*) to represent an ideal intervention that sets
    *X* to *x*. Note that we can have interventions on sets of variables, as in do(*X*=*x*,
    *Y*=*y*, *Z*=*z*).
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用符号 do(*X*=*x*) 来表示一个理想干预，即将 *X* 设置为 *x*。请注意，我们可以在一组变量上执行干预，例如 do(*X*=*x*,
    *Y*=*y*, *Z*=*z*)。
- en: 7.2.1 Intervention operators
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.1 干预算子
- en: A causal model represents relationships in the DGP. The preceding definition
    of the ideal intervention describes how it *changes* the DGP. Now it remains to
    us to define how our causal models will reflect that change.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 因果模型表示DGP中的关系。理想干预的前述定义描述了它是如何 *改变* DGP的。现在，剩下的任务是我们如何定义我们的因果模型将如何反映这种变化。
- en: An *intervention operator* is some way of *changing* our causal model to reflect
    an intervention. One of the first tasks of creating *any* novelcomputational representation
    of causality is to define an intervention operator for the ideal intervention.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '*干预算子* 是一种改变我们的因果模型以反映干预的方式。创建任何新颖的因果计算表示的第一个任务之一就是为理想干预定义干预算子。'
- en: Intervention operators can implement ideal interventions, stochastic interventions
    (discussed in section 7.5), and other types of interventions. Unless I indicate
    otherwise, you can assume that “intervention operator” means “intervention operator
    for ideal interventions.”
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 干预算子可以实施理想干预、随机干预（在第7.5节中讨论）和其他类型的干预。除非我另有说明，否则您可以假设“干预算子”指的是“理想干预的干预算子”。
- en: Fortunately, structural causal models and general causal graphical models have
    well-defined intervention operators. We’ll explore those, as well as look at intervention
    operators designed for causal programs like `pyro.do`.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，结构因果模型和一般因果图模型都有明确定义的干预算子。我们将探讨这些，以及查看为因果程序如 `pyro.do` 设计的干预算子。
- en: 7.2.2 Ideal interventions in structural causal models
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.2 结构因果模型中的理想干预
- en: 'We’ll start with the structural causal model. Let *M* represent a structural
    causal model of the online game. We’d write *M* as follows:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从结构因果模型开始。让*M*代表在线游戏的结构因果模型。我们会将*M*写成如下形式：
- en: '![figure](../Images/ness-ch7-eqs-0x.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch7-eqs-0x.png)'
- en: '*f*[*G*], *f*[*E*], and *f*[*I*] are the assignment functions for *G* (*Guild
    Membership*), *E* (*Side-Quest Engagement*), and *I* (*In-Game Purchases*), respectively.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '*f*[*G*]，*f*[*E*]，和*f*[*I*]分别是*G*（公会会员资格），*E*（支线任务参与），和*I*（游戏内购买）的分配函数。'
- en: 'An ideal intervention do(*E*=“high”) transforms the model as follows:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 理想干预do(*E*=“高”)将模型转换如下：
- en: '![figure](../Images/ness-ch7-eqs-1x.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/ness-ch7-eqs-1x.png)'
- en: The intervention operator for the SCM replaces the intervention target *E*’s
    assignment function with the intervention value “high.”
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: SCM的干预算子用干预值“高”替换干预目标*E*的分配函数。
- en: Suppose you have an SCM with a variable (or set of variables) *X*. You want
    to apply an intervention do(*X*=*x*). The intervention operator replaces the intervention
    target’s assignment function with the intervention value.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个包含变量（或一组变量）*X*的SCM。你想要应用干预do(*X*=*x*)。干预算子用干预值替换干预目标的分配函数。
- en: 'Consider how this meets the three elements of our definition of an ideal intervention:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑这一点如何满足我们理想干预定义的三个要素：
- en: The intervention do(*X*=*x*) only directly affects the assignment function for
    *X*. No other assignment function is affected.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 干预do(*X*=*x*)只直接影响*X*的分配函数。其他分配函数不受影响。
- en: The intervention explicitly sets *X* to a specific value.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 干预明确地将*X*设置为特定的值。
- en: Since the value of *X* is set to a constant, it no longer depends on its direct
    causal parents.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于*X*的值被设定为常数，它不再依赖于其直接的因果父节点。
- en: '7.2.3 Graph surgery: The ideal intervention in causal DAGs and causal graphical
    models'
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.3 图形手术：因果DAG和因果图形模型中的理想干预
- en: Now we’ll consider how to think graphically about the ideal intervention. First,
    let’s reexamine the online game’s causal DAG in figure 7.5.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将考虑如何图形化地思考理想的干预。首先，让我们重新审视图7.5中在线游戏的因果DAG。
- en: '![figure](../Images/CH07_F05_Ness.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH07_F05_Ness.png)'
- en: Figure 7.5 The causal DAG for the online game
  id: totrans-228
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.5 在线游戏的因果DAG
- en: According to our graph, *Guild Membership* is the causal parent of *Side-Quest
    Engagement*. That parent-child relationship determines a causal Markov kernel—the
    conditional probability distribution of *Side-Quest Engagement*, given *Guild
    Membership*. Recall our model of this causal Markov kernel, shown in table 7.8\.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的图表，*公会会员资格*是*支线任务参与*的因果父节点。这种父子关系决定了因果马尔可夫核——在*公会会员资格*给定的情况下，*支线任务参与*的条件概率分布。回想一下我们展示在表7.8中的这个因果马尔可夫核模型。
- en: Table 7.8 Conditional probability table for causal Markov kernel of *Side-Quest
    Engagement*
  id: totrans-230
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表7.8 支线任务参与的因果马尔可夫核的条件概率表
- en: '*|  | Guild Membership |'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '*|  | 公会会员资格 |'
- en: '| --- | --- |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| nonmember | member |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| 非成员 | 成员 |'
- en: '| --- | --- |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Side-Quest Engagement  | low  | .8  | .2  |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| 支线任务参与 | 低  | .8  | .2  |'
- en: '| high  | .2  | .8  |*  *Imagine the mechanics of our experiment. Players log
    on, and the digital experimentation platform selects some players for participation
    in the experiment. Some of those players are guild members, and some are not.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '| 高  | .2  | .8  |*   *想象一下我们实验的机制。玩家登录，数字实验平台选择一些玩家参与实验。其中一些玩家是公会成员，而另一些则不是。'
- en: Consider a player named Jojo, who is not a guild member, who is logging on.
    Given this information only, he will have a 20% chance of engaging highly in side-quests
    during this session of gameplay, according to our model.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个名为Jojo的玩家，他不是公会成员，正在登录。根据我们的模型，仅凭这些信息，他在这次游戏会话中高度参与支线任务的概率将是20%。
- en: But the experimentation platform selects him for the experiment. It randomly
    assigns him to the high *Side-Quest Engagement* group. Once he is in that group,
    what is the probability that Jojo will engage highly in side-quests? The answer
    is 100%. In experimental terms, what is the probability that someone assigned
    to the treatment group will be exposed to the treatment? 100%. For data scientists
    familiar with the jargon of A/B testing, what is the probability that someone
    assigned to group A will be exposed to variant A? 100%.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 但实验平台选择他进行实验。它随机将他分配到高**支线任务参与度**组。一旦他进入这个组，Jojo在支线任务中高度参与的概率是多少？答案是100%。在实验术语中，被分配到处理组的人接触到治疗的可能性是多少？100%。对于熟悉A/B测试术语的数据科学家来说，被分配到A组的人接触到变体A的可能性是多少？100%。
- en: Indeed, supposing instead of Jojo, the subject was Ngozi, who is a guild member.
    While originally Ngozi had an 80% chance of being highly engaged in side-quests,
    upon being assigned to the high *Side-Quest Engagement* group in the experiment,
    she changes to having a 100% chance of being highly engaged.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，假设实验对象不是Jojo，而是Ngozi，她是一名公会成员。虽然最初Ngozi有80%的可能性在支线任务中高度参与，但在实验中被分配到高**支线任务参与度**组后，她改变为有100%的可能性高度参与。
- en: We need to rewrite our conditional probability distribution of *Side-Quest Engagement*
    to reflect these new probabilities, as in table 7.9.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要重写我们的**支线任务参与度**的条件概率分布，以反映这些新的概率，如表7.9所示。
- en: Table 7.9 Rewriting the conditional probability table of *Side-Quest Engagement*
    to reflect the certainty of engagement level upon being assigned to the high-engagement
    group in the experiment
  id: totrans-241
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表7.9 重写**支线任务参与度**的条件概率表，以反映在实验中被分配到高参与度组后参与度的确定性
- en: '|  | Guild Membership |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '|  | 公会成员 |'
- en: '| --- | --- |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| nonmember | member |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| 非成员 | 成员 |'
- en: '| --- | --- |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Side-Quest Engagement  | low  | 0.0  | 0.0  |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| 支线任务参与度 | 低   | 0.0  | 0.0  |'
- en: '| high  | 1.0  | 1.0  |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| 高   | 1.0  | 1.0  |'
- en: Now we see that this modified distribution of *Side-Quest Engagement* is the
    same regardless of *Guild Membership*. That is the definition of probabilistic
    independence, so we should simplify this conditional probability table to reflect
    that; we can reduce table 7.9 to table 7.10.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们看到，无论是否为**公会成员**，这种修改后的**支线任务参与度**分布都是相同的。这就是概率独立的定义，因此我们应该简化这个条件概率表以反映这一点；我们可以将表7.9简化为表7.10。
- en: Table 7.10 Rewriting the conditional probability table of *Side-Quest Engagement*
    to reflect the fact that engagement level no longer depends on *Guild Membership*
  id: totrans-249
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表7.10 重写**支线任务参与度**的条件概率表，以反映参与度不再依赖于**公会成员**
- en: '| Side-Quest Engagement  | low  | 0.0  |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 支线任务参与度 | 低   | 0.0  |'
- en: '| high  | 1.0  |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| 高   | 1.0  |'
- en: When we simplify the distribution in this way, we have to recall that this is
    a model of a causal Markov kernel, which is defined by the graph. Our initial
    graph says *Side-Quest Engagement* is caused by *Guild Membership*. But it seems
    that after the experiment randomly allocates players either to the high engagement
    or low engagement group, that causal dependency is broken; a player’s engagement
    level is solely determined by the group they are assigned to.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们以这种方式简化分布时，我们必须记住这是一个因果马尔可夫核的模型，它由图定义。我们的初始图表明**支线任务参与度**是由**公会成员**引起的。但似乎在实验随机将玩家分配到高参与度或低参与度组之后，这种因果依赖性被打破了；玩家的参与度完全由他们被分配到的组决定。
- en: We need an intervention operator that changes our causal graph to reflect this
    broken causal dependency. This intervention operator is called *graph surgery*
    (also known as *graph mutlitation*), and it’s illustrated in figure 7.6\.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个干预操作符，以改变我们的因果图来反映这种断裂的因果依赖性。这个干预操作符被称为**图手术**（也称为**图突变**），如图7.6所示。
- en: '![figure](../Images/CH07_F06_Ness.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/CH07_F06_Ness.png)'
- en: Figure 7.6 Graph surgery removes an incoming edge to the intervention target
    *Side-Quest Engagement*.
  id: totrans-255
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.6 图手术移除了干预目标**支线任务参与度**的入边。
- en: While *Guild Membership* is a cause of *Side-Quest Engagement* in normal settings,
    the experiment’s intervention on *Side-Quest Engagement* broke that variable’s
    causal dependence on *Guild Membership*. Since that causal dependence is gone,
    graph surgery changes the graph to one where the edge from *Guild Membership*
    to *Side-Quest Engagement* is snipped.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然*公会成员资格*在正常设置中是*支线任务参与*的原因，但实验对*支线任务参与*的干预打破了该变量对*公会成员资格*的因果依赖。由于这种因果依赖已经消失，图手术改变了图，使得从*公会成员资格*到*支线任务参与*的边被剪断。
- en: In general, suppose you have a causal graph with node *X*. You want to apply
    an intervention do(*X*=*x*). Then you represent that intervention on the causal
    DAG by “surgery” removing all incoming edges to *X*. Graph surgery is available
    in libraries such aspgmpy. For example, here is how we would use pgmpy to apply
    graph surgery to the online gaming DAG.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，假设你有一个带有节点*X*的因果图。你想应用一个干预do(*X*=*x*)。然后你通过“手术”移除所有指向*X*的入边来在因果DAG上表示该干预。图手术在如pgmpy之类的库中可用。例如，以下是使用pgmpy对在线游戏DAG应用图手术的方法。
- en: Listing 7.11 Graph surgery on a DAG in pgmpy
  id: totrans-258
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.11 pgmpy中对DAG的图手术
- en: '[PRE17]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '#1 Build the causal DAG.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 构建因果DAG。'
- en: '#2 The do method in the DAG class applies graph surgery.'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 DAG类中的do方法应用图手术。'
- en: We can now plot both the original DAG and the transformed DAG and compare them.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以绘制原始DAG和转换后的DAG，并比较它们。
- en: Listing 7.12 Plot the transformed DAG
  id: totrans-263
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.12 绘制转换后的DAG
- en: '[PRE18]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '#1 Create a dictionary of node positions that we can use to visualize both
    graphs.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 创建一个节点位置的字典，我们可以用它来可视化两个图。'
- en: '#2 Visualize the original graph.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 可视化原始图。'
- en: '#3 Visualize the transformed graph.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 可视化转换后的图。'
- en: These visualizations produce the same DAG as in figure 7.6\.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 这些可视化产生了与图7.6相同的DAG。
- en: Next, we’ll look at the effect of graph surgery on d-separation and its implications
    for conditional independence.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将研究图手术对d分离及其对条件独立性的影响。
- en: 7.2.4 Graph surgery and d-separation
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.4 图手术和d分离
- en: 'Consider how graph surgery affects reasoning with d-separation, as in figure
    7.7\. Initially, we have two d-connecting paths between *Side-Quest Engagement*
    and *In-Game Purchases*: one path was the direct cause path, and the other was
    through the common cause of *Guild Membership*. After graph surgery, only the
    direct causal path remains.'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑图手术如何影响d分离推理，如图7.7所示。最初，我们有*支线任务参与*和*游戏内购买*之间的两个d连通路径：一条是直接因果路径，另一条是通过*公会成员资格*的共同原因。图手术之后，只剩下直接因果路径。
- en: '![figure](../Images/CH07_F07_Ness.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![图](../Images/CH07_F07_Ness.png)'
- en: Figure 7.7 In the original DAG on the left, there are two d-connected paths
    between *Side-Quest Engagement* and *In-Game Purchases*. These paths equate to
    two sources of statistical dependence between the two variables. After graph surgery,
    only the causal path remains, reflecting causal dependence.
  id: totrans-273
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图7.7 在原始DAG的左侧，*支线任务参与*和*游戏内购买*之间存在两个d连通路径。这些路径等于两个变量之间的统计依赖来源。图手术之后，只剩下因果路径，反映了因果依赖。
- en: Recall that each d-connected path between two variables is a source of statistical
    dependence between those variables. When we represent an intervention with graph
    surgery that removes incoming edges to the intervention target(s), we remove any
    paths to other nodes that go through that variable’s causes. Only outgoing paths
    to other nodes remain. As a result, the remaining paths from that variable reflect
    dependence due to that variable’s causal influence on other variables. The ideal
    intervention removes the causal influence the target variable receives from its
    direct parents. Thus, it removes any dependence on other variables that flows
    through those parents.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，两个变量之间的每个d连通路径都是这些变量之间统计依赖的来源。当我们用一个通过图手术移除干预目标（的）入边来表示干预时，我们移除了通过该变量原因的任何路径。只剩下到其他节点的出路径。因此，从该变量剩余的路径反映了该变量对其他变量的因果影响所导致的依赖。理想干预消除了目标变量从其直接父变量接收的因果影响。因此，它消除了通过这些父变量流动到其他变量的任何依赖。
- en: 7.2.5 Ideal interventions and causal Markov kernels
  id: totrans-275
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.5 理想干预和因果马尔可夫核
- en: Graph surgery on the causal DAG removes the incoming edges to the target node(s).
    However, for a causal graphical model, we need an intervention operator that changes
    the graph *and* goes one step farther to rewrite the causal Markov kernel of the
    intervention target, as we did when we collapsed table 7.9 into table 7.10.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在因果DAG上进行的图手术移除了目标节点（的）入边。然而，对于因果图模型，我们需要一个干预算子，该算子不仅改变图，而且进一步重写干预目标的因果马尔可夫核，就像我们将表7.9折叠成表7.10时所做的那样。
- en: Initially, our online gaming model has causal Markov kernels {*P*(*G*), *P*(*E*|*G*),
    and *P*(*I*|*E*, *G*)}. In table 7.9 we saw the conditional probability table
    representation of *P*(*E*|*G*) and how an intervention reduced it to table 7.10,
    where 100% of the probability is placed on the outcome “high.”
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，我们的在线游戏模型具有因果马尔可夫核{*P*(*G*), *P*(*E*|*G*), 和 *P*(*I*|*E*, *G*)}。在表7.9中，我们看到了*P*(*E*|*G*)的条件概率表表示以及如何通过干预将其减少到表7.10，其中100%的概率被放置在结果“高”上。
- en: Generally, the intervention operator for causal graphical models replaces the
    causal Markov kernel(s) of the intervention target(s) with a degenerate distribution,
    meaning a distribution that puts 100% of the probability on one value, namely
    the intervention value.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，因果图模型的干预算子用退化分布替换干预目标的因果马尔可夫核（们），这意味着一个将100%的概率放在一个值上的分布，即干预值。
- en: 'When we combine graph surgery with this replacement of the target node’s causal
    Markov kernel with a degenerate distribution, we have an intervention operator
    on a causal graphical model that meets the three elements of the definition of
    ideal intervention:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们将图手术与用退化分布替换目标节点因果马尔可夫核结合起来时，我们得到了一个因果图模型的干预算子，该算子符合理想干预定义的三个要素：
- en: You only remove incoming edges for the nodes targeted by the intervention.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你只为干预目标节点移除入边。
- en: 100% of the probability is assigned to a fixed value.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将100%的概率分配给一个固定值。
- en: Removing the incoming edges to the intervention target means that the variable
    is no longer causally dependent on its parents.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 移除干预目标节点的入边意味着该变量不再因果依赖于其父节点。
- en: In listing 7.11, graph surgery is implemented in the `do` method in the `DAG`
    class. The `BayesianNetwork` class, our default for building causal graphical
    models, also has a `do` method. Like the `DAG` method, it takes an intervention
    target. At the time of writing, the method does not take an intervention value
    and thus does not satisfy the second element of the definition of ideal intervention.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在列表7.11中，图手术在`DAG`类的`do`方法中实现。我们的默认构建因果图模型的`BayesianNetwork`类也有一个`do`方法。与`DAG`方法类似，它接受一个干预目标。在撰写本文时，该方法不接受干预值，因此不满足理想干预定义的第二要素。
- en: pgmpy uses objects from subclasses of the `BaseFactor` class (e.g., the `TabularCPD`
    class) to represent causal Markov kernels. The `do` method in the `BayesianNetwork`
    class first does graph surgery and then replaces the factor object representing
    the intervention target’s causal Markov kernel. However, that replacement factor
    object is not degenerate; it does not assign all the probability value to one
    outcome. Rather, it returns an object representing the probability distribution
    of the target variable after marginalizing over its parents in the original unmodified
    graph. Technically, this is an intervention operator for a stochastic intervention,
    which I’ll discuss in section 7.5\. To build an intervention operator for the
    ideal intervention, you need to write additional code to modify the factor to
    assign all probability to the intervention value.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: pgmpy使用`BaseFactor`类（例如，`TabularCPD`类）的子类对象来表示因果马尔可夫核。`BayesianNetwork`类的`do`方法首先进行图手术，然后替换表示干预目标因果马尔可夫核的因子对象。然而，那个替换因子对象不是退化的；它不会将所有概率值分配给一个结果。相反，它返回一个对象，表示在原始未修改图中对其父节点进行边缘化后的目标变量的概率分布。技术上，这是一个随机干预的干预算子，我将在第7.5节中讨论。要构建理想干预的干预算子，你需要编写额外的代码来修改因子，使其将所有概率分配给干预值。
- en: 7.2.6 Ideal interventions in a causal program
  id: totrans-285
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2.6 因果程序中的理想干预
- en: Recall that in listing 7.10 we simulated an experiment where players were assigned
    to high-engagement and low-engagement groups using the `pyro.do` operator. Specifically,
    we called `pyro.do` as in following listing.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，在列表7.10中，我们使用`pyro.do`运算符模拟了一个实验，其中玩家被分配到高参与度和低参与度组。具体来说，我们像以下列表那样调用`pyro.do`。
- en: Listing 7.13 Revisiting `pyro.do`
  id: totrans-287
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表7.13 回顾`pyro.do`
- en: '[PRE19]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '#1 An intervention that sets Side-Quest Engagement to 1.0 (i.e., “high”). This
    returns a new model.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 一种将 Side-Quest Engagement 设置为 1.0（即，“高”）的干预。这将返回一个新的模型。'
- en: '#2 An intervention that sets Side-Quest Engagement to 0.0 (i.e., “low”). This
    returns a new model.'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 一种将 Side-Quest Engagement 设置为 0.0（即，“低”）的干预。这将返回一个新的模型。'
- en: What exactly does `pyro.do` *do*? `pyro.do` is Pyro’s intervention operator.
    We saw, by using `pyro.render_model` to generate figure 7.4, that our online gaming
    model in Pyro has an underlying causal DAG, and therefore is a causal graphical
    model.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '`pyro.do` 究竟做了什么？`pyro.do` 是 Pyro 的干预操作符。我们通过使用 `pyro.render_model` 生成图 7.4，看到
    Pyro 中的在线游戏模型有一个潜在的因果有向图（DAG），因此它是一个因果图模型。'
- en: But a deep probabilistic machine learning framework like Pyro allows you to
    do things that we can’t easily represent with a causal DAG, such as recursion,
    conditional control flow, or having a random number of variables not realized
    until runtime. As an intervention operator, `pyro.do` must work in these cases
    as well.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，像 Pyro 这样的深度概率机器学习框架允许你做一些我们难以用因果有向图（DAG）表示的事情，例如递归、条件控制流，或者有随机数量的变量直到运行时才实现。作为一个干预操作符，`pyro.do`
    也必须在这些情况下工作。
- en: 'The intervention operator in Pyro works by finding calls to `pyro.sample`,
    and replacing those calls with an assignment to the intervention value. For example,
    the online game model had the following line:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: Pyro 中的干预操作符通过查找对 `pyro.sample` 的调用，并用对干预值的赋值来替换这些调用来实现。例如，在线游戏模型有以下一行：
- en: '[PRE20]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'This `pyro.sample` call generates a value for *Side-Quest Engagement*. `pyro.do(model,
    {"Side-quest Engagement": tensor(1.)})` *essentially* replaces that line with
    this:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '`pyro.sample` 调用为 *Side-Quest Engagement* 生成一个值。`pyro.do(model, {"Side-quest
    Engagement": tensor(1.)})` 在本质上用以下内容替换了那一行：'
- en: '[PRE21]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: (I say “essentially” because `pyro.do` does a few other things too, which I’ll
    discuss in chapter 10).
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: （我说“本质上”是因为 `pyro.do` 还做了几件其他事情，我将在第 10 章中讨论）。
- en: This replacement is much like the replacement of the assignment function in
    the SCM, or a causal Markov kernel with a degenerate kernel in a causal graphical
    model. As an intervention operator, it meets the criteria for an ideal intervention.
    It targets a specific variable, and it assigns it a specific value. It eliminates
    its dependence on its causes by removing *flow dependence* (dependence on results
    of executing preceding statements in the program).
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 这种替换类似于在系统动力学（SCM）中替换赋值函数，或者在因果图模型中使用退化核。作为一个干预操作符，它满足了理想干预的标准。它针对一个特定的变量，并给它赋予一个特定的值。通过消除其依赖性（通过移除程序中先前语句执行的结果的依赖性），它消除了其因果关系。
- en: Using a flexible deep probabilistic machine learning tool like Pyro to build
    a causal model allows you to construct causal representations beyond DAGs and
    simple ideal interventions. Doing so puts you in underdeveloped territory in terms
    of theoretical grounding, but it could lead to interesting new applications.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 使用像 Pyro 这样的灵活深度概率机器学习工具构建因果模型，允许你构建超越 DAG 和简单理想干预的因果表示。这样做将你置于理论基础尚不发达的领域，但这可能导致有趣的新应用。
- en: In the next section, we’ll consider how interventions affect probability distributions.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将考虑干预如何影响概率分布。
- en: 7.3 Intervention variables and distributions
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7.3 干预变量和分布
- en: An ideal intervention fixes the random variable it targets, essentially turning
    it into a constant. But the intervention indirectly affects all the random variables
    causally downstream of the target variable. As a result, their probability distributions
    (joint, conditional, or marginal) change from what they were.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 理想干预固定了它所针对的随机变量，本质上将其转变为一个常数。但是，干预间接影响了目标变量下游的所有随机变量。因此，它们的概率分布（联合、条件或边缘）从它们原本的状态发生了变化。
- en: 7.3.1 “Do” and counterfactual notation
  id: totrans-303
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3.1 “Do” 和反事实符号
- en: Causal modeling uses special notation to help reason about how interventions
    affect random variables and their distributions. One common approach is to use
    the *“do”-notation*. Using our online game as an example, *P*(*I*) is the probability
    distribution of *In-Game Purchases* across all players, *P*(*I*|*E*=“high”) is
    the probability distribution of *In-Game Purchases* given players with “high”
    engagement, and *P*(*I*|do(*E*= “high”)) is the probability distribution of *In-Game
    Purchases* given an intervention that sets a player’s engagement level to “high.”
    The second column of table 7.11 illustrates extensions of this notation to joint
    distributions, multiple interventions, and mixing interventions with observations.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: Table 7.11 Examples of do-notation and counterfactual notation
  id: totrans-305
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Literal | Do-notation | Counterfactual notation |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
- en: '| The probability distribution of *In-Game Purchases* across all players  |
    *P*(*I*)  | *P*(*I*)  |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
- en: '| The probability distribution of *In-Game Purchases* for players with “high”
    engagement  | *P*(*I*&#124;*E*=“high”)  | *P*(*I*&#124;*E*=“high”)  |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
- en: '| The probability distribution of *In-Game Purchases* when a player’s engagement
    level is set (by intervention) to “high”  | *P*(*I*&#124;do(*E*= “high”))  | *P*(*I**[E]*[=
    “high”])  |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
- en: '| The joint probability distribution of *In-Game Purchases* and *Guild Membership*
    when engagement is set to “high”  | *P*(*I*, *G*&#124;do(*E*=“high”))  | *P*(*I*[E=“high”],
    *G*[E=“high”])  |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
- en: '| The probability distribution of In-Game Purchases when engagement is set
    to “high” and membership is set to “nonmember”  | *P*(*I*&#124;do(*E*=“high”,
    *G*=“nonmember”))  | *P*(*I**[E]*[= “high”,] *[G]*[=“nonmember”])  |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
- en: '| The probability distribution of *In-Game Purchases* for guild members when
    engagement is set to “high”  | *P*(*I*&#124;do(*E*=“high”), *G*=“member”)  | *P*(*I**[E]*[=][“high”]&#124;*G*=“member”)  |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
- en: An alternative is to use counterfactual notation, which uses subscripts to represent
    a new version of a variable after the system has been exposed to intervention.
    For example, if *I* is a variable that represents *In-Game Purchases*, *I*[*E*][=“high”]
    represents *In-Game Purchases* under an intervention that sets *Side-Quest Engagement*
    to “high.” If *P*(*I*) is the probability distribution of *In-Game Purchases*,
    then *P*(*I*[*E*][=“high”]) is the probability distribution. Again, table 7.11
    contrasts do-notation with counterfactual notation in the third column. Going
    forward, I’ll mostly use counterfactual notation.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: From causal language to symbols
  id: totrans-315
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'In many cases in statistics and machine learning, notation only serves to add
    formalism and rigor to something just as easily explained in plain language. However,
    notation is important in causality, because it makes a clear distinction between
    when we are talking about something causal and when we are not. It is important
    because making the distinction is harder in plain English. For example, consider
    the following two questions:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: “What would *In-Game Purchases* be for a player who was highly engaged in side-quests?”
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: “What would *In-Game Purchases* be if a player was highly engaged in side-quests?”
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: Is it obvious to you that the first question corresponds to *P*(*I*|*E*=“high”)
    and the second to *P*(*I*[*E*][=“high”])? The first question corresponds to a
    subset of players who are highly engaged. The traditional conditional probability
    notation is fine when we want to zoom in on a subset of a distribution or population.
    The second question asks *what if* someone were highly engaged. In the next chapter,
    we’ll see that “what if” hypothetical questions imply an intervention. But because
    of the ambiguity of language, someone could ask one question while really meaning
    the other. The notation gives us an unambiguous way of constructing our causal
    queries.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: Again, in chapter 8, we’ll investigate more examples of mapping language to
    counterfactual notation.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: 7.3.2 When causal notation reduces to traditional notation
  id: totrans-321
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is crucial to recognize when a variable and that same variable under intervention
    are the same. Consider the intervention on engagement, as in figure 7.8.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH07_F08_Ness.png)'
  id: totrans-323
  prefs: []
  type: TYPE_IMG
- en: Figure 7.8 In the original DAG (left), there are two d-connected paths between
    *Side-Quest Engagement* and *In-Game Purchases*. These paths equate to two sources
    of statistical dependence between the two variables. After graph surgery, only
    the causal path remains, reflecting causal dependence.
  id: totrans-324
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Is *P*(*G*|*E*=“high”) (the probability distribution of *Guild Membership* given
    high *Side-Quest Engagement*) the same as *P*(*G*)? No. In graphical terms, *G*
    and *E* are d-connected. In probabilistic terms, we can reason that knowing a
    player’s level of *Side-Quest Engagement* is predictive of whether they are in
    a guild.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: But is *P*(*G*[*E*][=“high”]) the same as *P*(*G*)? Yes. *Guild Membership*
    is not affected by the intervention on *Side-Quest Engagement* because it can
    only affect variables causally downstream of *Side-Quest Engagement*. Thus *P*(*G*[*E*][=“high”])
    is equivalent to *P*(*G*).
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: In general terms, empirically learning a distribution for a variable *Y*[*X*][=][*x*]
    requires doing the intervention do(*X*=*x*) in real life. However, that real-life
    intervention, at best, has a cost and, at worst, is infeasible or impossible.
    So if we can equate *Y*[*X*][=][*x*] to some distribution involving *Y* that we
    can learn from observational data, that’s a win. That’s going from correlation
    to causation. In trivial cases, we can do this by looking at the graph, as we
    did with *G* and *G*[*E*][=“high”]. But usually, we’ll need to do some mathematical
    derivation, either by hand or using algorithms.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
- en: This task of deriving equality between variables that are and aren’t subject
    to intervention is called *identification*, and it is the heart of causal inference
    theory. We’ll examine identification at length in chapter 10.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: 7.3.3 Causal models represent all intervention distributions
  id: totrans-329
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As generative models, the causal models we’ve worked with encode a joint probability
    distribution of components of the DGP. Inference algorithms enable those models
    to represent (e.g., through Monte Carlo sampling) the conditional distribution
    of some subset of those components, given the state of the other components.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: We’ve now introduced the ideal intervention and how it changes the DGP and,
    consequently, the joint probability distribution of the variables. Figure 7.9
    illustrates how the generative causal model captures the original DGP (and corresponding
    probability distributions) and any new DGP (and corresponding probability distributions)
    created by intervening in the original process.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH07_F09_Ness.png)'
  id: totrans-332
  prefs: []
  type: TYPE_IMG
- en: Figure 7.9 Suppose our DGP has variables *X*, *Y*, and *Z*. A traditional generative
    model (left) uses observations of *X*, *Y*, and *Z* to statistically learn a representation
    of *P*(*X*, *Y*, *Z*). A generative causal model (right) encodes a representation
    *P*(*X*, *Y*, *Z*) and distributions derived by interventions on *X*, *Y*, and
    *Z*. In that way, the generative causal model represents a broad family of distributions.
  id: totrans-333
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Consider the statistical implications of this idea. Given data, an ordinary
    generative model learns a representation of the joint probability distribution.
    But a generative causal model learns not only that distribution but any new distribution
    that would be derived by applying some set of ideal interventions. That’s how
    our causal model of the online game was able to reproduce the outcome of an experiment
    from observational data alone.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: 7.4 Interventions and causal effects
  id: totrans-335
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The most common use case for our formal model of an intervention will be to
    model *causal effects*. Now that we’ve defined and formalized interventions, causal
    effects are easy to think about; they are simply comparisons between the outcomes
    of interventions.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: 7.4.1 Average treatment effects with binary causes
  id: totrans-337
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The most common causal effect query is the average treatment effect (ATE).
    Here, we’ll focus on the case where we are interested in the causal effect of
    *X* on *Y*, and *X* is binary, meaning it has two outcomes: 1 and 0\. Binary causes
    entail experiments where the cause has a “treatment” value and a “control” value,
    such as “A/B tests.” Using do-notation, the ATE is *E*(*Y*|do(*X*=1)) – *E*(*Y*|do(*X*=0))
    (recall *E*(…) means “the expectation of …”). Using counterfactual notation, the
    ATE is *E*(*Y*[*X*][=][1]) – *E*(*Y*[*X*][=][0]). The advantage of the counterfactual
    notation is that we can collapse this into one expectation term, *E*(*Y*[*X*][=1]
    – *Y*[*X*][=0]).'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: 7.4.2 Average treatment effect with categorical causes
  id: totrans-339
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When the cause is categorical, the ATE requires choosing which levels of the
    cause you want to compare. For example, if *X* has possible outcomes {a, b, c},
    you might select “a” to be a baseline, and work with two ATEs, *E*(*Y*[*X*][=][*b*]
    – *Y*[*X*][=][*a*]) and *E*(*Y*[*X*][=][*c*] – *Y*[*X*][=][*a*]). Alternatively,
    you may choose to work with all pairwise comparisons of levels of *X*, or just
    convert *X* to a binary variable with outcomes “a” and “not a” The choice depends
    on which ATE is most meaningful to you.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: 7.4.3 Average treatment effect for continuous causes
  id: totrans-341
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If we want to generalize *E*(*Y*[*X*][=][1] – *Y*[*X*][=][0]) to the case where
    *X* is continuous, we arrive at derivative calculus. For some baseline do(*X*=*x*),
    imagine changing the intervention value *x* by some small amount Δ, i.e., do(*X*=*x*+Δ).
    Taking the difference between the two outcomes, we get *E*(*Y*[*X*][=][*x*][+][Δ]
    – *Y*[*X*][=][*x*]). Then we can ask, what is the rate of change of *E*(*Y*[*X*])
    as we make Δ infinitesimally smaller. This brings us to the definition of the
    derivative:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch7-eqs-2x.png)'
  id: totrans-343
  prefs: []
  type: TYPE_IMG
- en: Note that this is a function, rather than a point value; when you plug in a
    value of *x*, you get the rate of change of *Y*[*X*][=][*x*] of the *X* versus
    *Y*[*x*] curve.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: As a practical example, consider the case of pharmacology, where we want to
    establish the ATE of a drug dose on a health outcome. The drug dose is continuous,
    and it usually follows a nonlinear S-curve-like shape; we get more effect as we
    increase the dose, but eventually the effect gets diminishing returns at higher
    doses. The derivative gives us the rate of change of the average response for
    a given dose on the dose-response curve.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: 7.4.4 Conditional average treatment effect
  id: totrans-346
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The conditional average treatment effect (CATE) is an ATE conditioned on other
    covariates. For example, in our online game example, *E*(*I*[*E*][=“high”] – *I*[*E*][=“low”])
    is the ATE on *In-Game Purchases* for *Side-Quest Engagement*. If we wished to
    understand the ATE for guild members, we’d want *E*(*I*[*E*][=“high”] – *I*[*E*][=“low”]|
    *G*=“member”).
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: In practical settings, it is often important to work with CATEs instead of ATEs,
    because CATEs can have big differences with ATEs and other CATEs with different
    conditions. In other words, CATEs better reflect the *heterogeneity* of treatment
    effects across a population. For example, it is possible that the ATE of a drug
    on a health outcome is positive across the overall population, but the CATE conditioned
    on a specific subpopulation (e.g., people with a certain allergy) could be negative.
    Similarly, in advertising, certain ad copy might drive your customers to purchase
    more on average, but cause some segment of your customers to purchase less. You
    can optimize the return on investment for your ad campaign by understanding the
    CATEs for each segment, or to use CATE-based reasoning to do customer segmentation.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: Experts often emphasize the importance of measuring *heterogenous treatment
    effects* with CATEs, lest one think a point value estimate of an ATE tells the
    full picture. But in our probabilistic modeling approach, heterogeneity is front
    and center. If we have a causal graphical model and a model of ideal intervention,
    then we can model *P*(*Y*[*X*][=][*x*]). If we can model *P*(*Y*[*X*][=][*x*]),
    then we can model *P*(*Y*[*X*][=][1] – *Y*[*X*][=][0]). We can then use that model
    to inspect all the variation within *P*(*Y*[*X*][=][1] – *Y*[*X*][=][0]), including
    who in the target population falls above or below 0 or some other threshold.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: 7.4.5 Statistical measures of association and causality
  id: totrans-350
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In statistics, an effect size is a value that measures the strength or intensity
    of the relationship between two variables or groups. For example, in our observational
    analysis of the online gaming data, we quantified the relationship between *Side-Quest
    Engagement* *E* and *In-Game Purchases* *I* as *E*(*I*|*E*=“high”) – *E*(*I*|*E*=“low”).
    Our statistical procedure estimated this *true* effect size with a difference
    in sample averages between both groups. We then conducted a hypothesis test. We
    specified a null hypothesis *E*(*I*|*E*=“high”) – *E*(*I*|*E*=“low”) = 0, and
    then tested if this effect size estimate was statistically different from 0 using
    a *p*-value calculated under some null hypothesis distribution (usually a normal
    or t-distribution).
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: A causal effect is just an *interventional* effect size; in our example, it
    was *E*(*I*|do(*E*=“high”)) – *E*(*I*|do(*E*=“low”)) = *E*(*I*[*E*][=][“high”]
    – *I*[*E*][=][“low”]), which is the ATE. The statistical hypothesis testing procedure
    is the same as before. Indeed, we still need to test if sample-based estimates
    of ATEs and CATEs are statistically significant. When you conduct a statistical
    significance test with data from an experiment with a treatment and control, you
    are testing an estimate of the ATE by definition.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: 7.4.6 Causality and regression models
  id: totrans-353
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Suppose *X* is continuous, but its relationship with *Y*[*X*] is linear. Then
    the ATE *d* *E*(*Y*[*X*][=][*x*])/*dx* is a point value because the derivative
    of a linear function is a constant. Therefore, if you use a linear model of *E*(*Y*[*X*]),
    then the coefficient for *X* in that model corresponds to the ATE for *X*.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch7-eqs-3x.png)'
  id: totrans-355
  prefs: []
  type: TYPE_IMG
- en: For this reason, linear regression modeling is a popular approach to modeling
    causal effects (even when people don’t really believe the causal relationship
    is linear).
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: 'This convenience extends to other generalized linear models. Suppose Poisson
    regression or logistic regression are better models of *E*(*Y*[*X*]) than linear
    regression. These models capture measures of association between two variables
    not as a difference in means, but as ratios. For example, we can read relative
    risk (RR) directly from a Poisson regression model and odds ratios (OR) directly
    from a logistic regression model. In general, these measures of association have
    no causal interpretation, but we give them a causal interpretation once we use
    them with interventional variables. For example, if we are modeling *E*(*Y*[*X*]),
    and *Y*[*X*] is binary, the relative risk and odds ratios are as follows:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/ness-ch7-eqs-4x.png)'
  id: totrans-358
  prefs: []
  type: TYPE_IMG
- en: Thus, traditional non-causal ways of quantifying statistical association become
    measures of *causal* association once we use them in an interventional context.
    And when we fit these regression models to data, we can still use all the traditional
    regression methods for significance testing (Wald tests, F-tests, likelihood ratio
    tests, etc.).
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: 7.5 Stochastic interventions
  id: totrans-360
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Stochastic interventions are an important generalization of ideal interventions.
    The second rule of the ideal intervention is that the intervention is set to a
    fixed value. In the stochastic intervention, that value is the outcome of a random
    process; i.e., it is itself a random variable. Most texts treat stochastic interventions
    as an advanced topic beyond the scope of an introduction to causal modeling, but
    I make special mention of them as they are important in machine learning, where
    we often seek data-driven automation. Stochastic interventions are important for
    automatic selection of interventions.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: 7.5.1 Random assignment in an experiment is a stochastic intervention
  id: totrans-362
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For example, the digital experimentation platform in our online gaming experiment
    automatically assigned players to high- and low-engagement groups. It did so *randomly*.
    Random assignment is a stochastic intervention; it targets the *Side-Quest Engagement*
    variable and sets its value by digitally flipping a coin.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: Note that randomization is more than what we need to arrive at the right answer.
    Indeed, in our simulation of the experiment, there was no randomization, only
    ideal interventions. Those ideal interventions were sufficient to d-separate the
    path*Side-Quest Engagement* ← *Guild Membership* → *In-Game Purchases*, removing
    the statistical dependence that comes from that path. If randomization is not
    necessary to quantify the causal relationship, why is it called “the gold standard
    of causal inference?” The answer is that randomization works when your causal
    DAG is *wrong*.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: For example, suppose that when we did the experiment, rather than randomizing
    players into the high versus low *Side-Quest Engagement* group, the digital experimentation
    platform automatically assigned the first 500 players who logged on to the group
    with high *Side-Quest Engagement* and the next 500 players to the group with low
    *Side-Quest Engagement*. This intervention would be sufficient to d-separate the
    path*Side-Quest Engagement* ← *Guild Membership* → *In-Game Purchases*. But what
    if our DAG was wrong, and there are other paths between *Side-Quest Engagement*
    and *In-Game Purchases* through unknown common causes?
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.10 considers what happens when our DAG is wrong—our model is the DAG
    on the right. Consider what would happen if, instead, the true DAG were the DAG
    on the left. For the DAG on the left, the time of day when the player logs on
    drives both the *Side-Quest Engagement* and *In-Game Purchases*.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH07_F10_Ness.png)'
  id: totrans-367
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7.10 Left: the true causal relationships. Right: your (incorrect) causal
    DAG.'
  id: totrans-368
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Suppose, for example, people who log on earlier tend not to be logging on with
    friends. They tend to engage more in side-quests because side-quests are amenable
    to solo gameplay. People who plan missions with friends tend to log on later,
    since some friends have real-world appointments during the day. Friends playing
    together focus more on the game’s primary narrative and avoid side-quests. Also,
    players tend to spend more money on *In-Game Purchases* later in the day, corresponding
    to the broader trend of late-day spending in e-commerce.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: When we intervene on a player to assign them to one group or another based on
    their login, that intervention value now depends on the time of day, as shown
    in figure 7.11.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
- en: 'The left side of figure 7.11 illustrates the result of an intervention on *Side-Quest
    Engagement* that depends on the time of day. As we expected, the intervention
    performs graph surgery, removing the incoming edges to *Side-Quest Engagement*
    *E*: *T*→*E* and *G*→*E*. However, the value set by the intervention is now determined
    by time of day *T*, via a `time_select` function. The `time_select` function assigns
    “high” engagement to every player whose login time is before that of the 501^(st)
    player to log on and “low” for those who logged in after. After graph surgery,
    we add back a new causal edge *T*→*E* whose mechanism is `time_select`. Thus,
    there is still a noncausal statistical association that biases the experiment
    via the d-connected path *I*←*T*→*E*.'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH07_F11_Ness.png)'
  id: totrans-372
  prefs: []
  type: TYPE_IMG
- en: Figure 7.11 An intervention that sets the level of *Side-Quest Engagement* based
    on login time changes, but doesn’t eliminate, the causal relationship T→*E*. In
    contrast, randomization eliminates incoming edges to *E*.
  id: totrans-373
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In contrast, randomization on the right side of figure 7.11 did what we hoped,
    removing all the incoming edges to *E*. It removed the edge from *T*→*E* even
    though our assumed DAG did not know that *T*→*E* existed. Indeed, if there are
    other unknown common causes between *E* and *I*, randomization will remove those
    incoming edges to *E*, as in figure 7.12.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH07_F12_Ness.png)'
  id: totrans-375
  prefs: []
  type: TYPE_IMG
- en: Figure 7.12 Randomization eliminates incoming edges from unknown common causes.
  id: totrans-376
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The ability of randomization to eliminate statistical bias from common causes
    we failed to account for in our assumptions is why it is considered “the gold
    standard of causal inference.” But to understand stochastic interventions, note
    that both assignment mechanisms: one based on login time and the other using randomization,
    are stochastic interventions. Both set the *Side-Quest Engagement* level of a
    player using a random process; one depends on when someone logs in, and the other
    depends on a coin flip.'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: 7.5.2 Intervention policies
  id: totrans-378
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Stochastic interventions are closely related to policies in automated decision-making
    domains, such as bandit algorithms and reinforcement learning. In these domains,
    an agent (e.g., a robot, a recommender algorithm) operates in some environment.
    A *policy* is an algorithm that takes as input the state of some variables in
    the environment and returns an action for the agent to execute. If there are elements
    of randomness in the selection of that action, it is a stochastic intervention.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: In our previous example, randomization is a *policy* that selects interventions
    at random. But in automated decision-making, most policies choose interventions
    based on the state of other variables in the system, much like the biased experiment
    that intervenes based on the *time of day* variable. Of course, policies in automated
    decision-making are typically trying to optimize some utility function rather
    than bias an experiment. We’ll focus on causality in automated decision-making
    in chapter 12.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: 7.6 Practical considerations in modeling interventions
  id: totrans-381
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I’ll close this chapter with some practical considerations for modeling interventions.
    We’ll consider how ideal (and stochastic) interventions allow us to model the
    impossible. Then we’ll make sure we ground that modeling in pragmatism.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: 7.6.1 Reasoning about interventions that we can’t do in reality
  id: totrans-383
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In our online gaming example, we used an intervention operator on a causal model
    to replicate the results of an experiment. I presented a choice between actually
    running an experiment and simulating the experiment. Simulation avoids the costs
    of running the experiment, but running the experiment is more robust to errors
    in causal assumptions, especially with tools like randomization.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: However, there are many times when we can’t run an experiment, because doing
    so is either infeasible, unethical, or impossible.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: '*Example of an infeasible experiment*—A randomized experiment that tests the
    effect of interest rates on intergenerational wealth.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Example of an unethical experiment*—A randomized experiment that tests the
    effect of caffeine on miscarriages.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Example of an impossible experiment*—A randomized experiment that tests the
    effects of black hole size on spectroscopic redshift.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In these scenarios, simulation with a causal model is our only choice.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: 7.6.2 Refutation and real-world interventions
  id: totrans-390
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Suppose your causal model predicts the outcome of an intervention. You then
    do that intervention in the real world, such as with a controlled experiment.
    If your predicted intervention outcome conflicts with your actual intervention
    outcome, your causal model is wrong.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: In chapter 4, we discussed the concept of validating, or rather, *refuting*,
    a causal model by checking data for evidence of dependence that violates the conditional
    independence implications of the model’s DAG. In chapter 11, we’ll extend refutation
    from the causal DAG all the way to a causal inference of interest (e.g., estimating
    a causal effect). However, comparing predicted and actual intervention outcomes
    gives us a stronger refutation standard than the methods in chapters 4 and 11\.
    The catch, of course, is that doing these real-world interventions must be feasible.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: Assuming they are, comparing predicted and real-world intervention outcomes
    provides a nice iterative framework for building a causal model. First, enumerate
    a set of interventions you can apply in the real world. Select one of those interventions,
    use your model to predict its outcome, and then do the intervention in the real
    world. If the outcomes don’t match, update your model so that it does. Repeat
    until you have exhausted your ability to run real-world interventions.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: Doing a real-world intervention usually costs resources and time. To save on
    costs, use your causal model to predict all the interventions you can run, rank
    the predicted outcomes according to which are more interesting or surprising,
    and then prioritize running real-world interventions according to this ranking.
    Interesting or surprising intervention predictions are likely a sign your model
    is wrong, so prioritizing them means you’ll make big updates to your model sooner
    and at less cost. And if your model turns out to be right, you will have spent
    less to arrive at some important insights into your DGP.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: 7.6.3 “No causation without manipulation”
  id: totrans-395
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The idea behind “no causation without manipulation” is that one should define
    the variables in the causal model such that the mechanics of *how* one might intervene
    in it is clear. Clarity here means you could run a real-world experiment that
    implemented the intervention, or, if the experiment were infeasible, unethical,
    or impossible, you could at least clearly articulate how the hypothetical experiment
    would work. “No causation without manipulation” is essentially trying to tether
    a causal model’s abstractions to experimental semantics.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
- en: For example, proponents of this idea might object to having “race” as a cause
    in a causal model, because the concept of race is nebulous from the standpoint
    of an intervention applied in an experiment—how would you change somebody’s race
    while holding constant everything about that person not caused by their race?
    They would prefer defining the variable in terms precise enough to be theoretically
    intervenable, such as “racial bias of loan officer” or “racial indicators on application
    form.” Of course, we have important questions to ask about fuzzy abstractions
    like “race,” so we don’t want to add so much precision that we can’t generalize
    the results of our analyses in ways that help answer those questions.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: One strategy for establishing this tether to experimentation is to include variables
    in our model that we can manipulate in a hypothetical experiment. For example,
    if we are interested in the causal relationship wealth → anxiety, we could add
    a “cash subsidy” variable and cash subsidy → wealth edge. Cash subsidy represents
    direct payments to an individual, which is easier to do in an experiment than
    directly manipulating an individual’s wealth.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: 7.6.4 Modeling “non-ideal” interventions
  id: totrans-399
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Often the types of interventions we use in practical settings can be challenging
    to map to ideal interventions. For example, a biologist might be studying the
    causal relationships between the expression of different genes in a cell, with
    causal relationships like gene A → gene B → gene C. The biologist might want to
    know how a stressor in the cellular environment (e.g., a toxin or hypoxia) affects
    gene expression. The stressor is an intervention; it changes the DGP. However,
    modeling it as an ideal intervention is challenging because it will likely be
    unclear which genes those stressors affect directly or what specific amount of
    gene expression is set by the stressor. A practical solution for these interventions
    is to model them explicitly as root nodes in the causal DAG, such as the hypoxia
    node in figure 7.13.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH07_F13_Ness.png)'
  id: totrans-401
  prefs: []
  type: TYPE_IMG
- en: Figure 7.13 “Hypoxia” is an intervention that has no specific target. Include
    it as a root node with edges to all variables that are possibly affected.
  id: totrans-402
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Explicit representation of interventions as part of the DGP is less expressive
    than the ideal (or stochastic) intervention, which captures how an arbitrary intervention
    can *change* the DGP.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-404
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An intervention is an action that changes the data generating process (DGP).
    Interventions are fundamental to defining causality and causal models.
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Many, if not most, machine learning–driven decisions are interventions that
    can render the model’s deployment environment different from its training environment.
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ability to model an intervention allows one to simulate the outcome of experiments.
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simulating experiments with an intervention model can save costs or enable simulated
    experiments when running an actual experiment is infeasible, unethical, or impossible.
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An ideal intervention targets specific variables, fixes them to a specific value,
    and renders the target independent of its causal parents.
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Causal effects are simple extensions of intervention distributions. For example,
    the average treatment effect (ATE) of *X* on *Y* is *E*(*Y*[*X*][=1]) – *E*(*Y*[*X*][=0]),
    the difference in means between two intervention distributions for *Y*. Conditional
    average treatment effects (CATEs) are simply differences in conditional expectations
    for intervention distributions on *Y*.
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stochastic interventions are like ideal interventions, but they fix the intervention
    targets at a value determined by some random process. That value could depend
    on the states of other variables in the system. In this way, they are related
    to policies in automated decision-making domains such as bandit algorithms and
    reinforcement learning.
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An intervention operator describes how a causal model is altered to reflect
    an ideal (or stochastic) intervention.
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The intervention operator for a structural causal model replaces the target
    variables assignment function with the intervention value.
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Graph surgery is the intervention operator for causal DAGs.
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The intervention operator for causal graphical models applies graph surgery
    and replaces the causal Markov kernel for the target with a degenerate distribution
    that places all probability on the intervention value.
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Causal models can use observational data to statistically learn the observational
    distribution and any interventional distribution that can be derived through the
    intervention operator.
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Randomization is a stochastic intervention that eliminates causal influence
    on the intervention target from unknown causes.
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “No causation without manipulation” suggests defining your causal model so that
    interventions are tethered to hypothetical experiments.
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can model interventions that don’t meet the ideal intervention standard
    as root nodes with outgoing edges to variables they may affect.
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[[1]](#footnote-source-1) D.T. Campbell and T.D. Cook, *Quasi-experimentation:
    Design & Analysis Issues for Field Settings* (Rand McNally, 1979), p36.*'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
