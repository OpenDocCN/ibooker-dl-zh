- en: Chapter 3\. Linear and Logistic Regression with TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter will show you how to build simple, but nontrivial, examples of
    learning systems in TensorFlow. The first part of this chapter reviews the mathematical
    foundations for building learning systems and in particular will cover functions,
    continuity, and differentiability. We introduce the idea of loss functions, then
    discuss how machine learning boils down to the ability to find the minimal points
    of complicated loss functions. We then cover the notion of gradient descent, and
    explain how it can be used to minimize loss functions. We end the first section
    by briefly discussing the algorithmic idea of automatic differentiation. The second
    section focuses on introducing the TensorFlow concepts underpinned by these mathematical
    ideas. These concepts include placeholders, scopes, optimizers, and TensorBoard,
    and enable the practical construction and analysis of learning systems. The final
    section provides case studies of how to train linear and logistic regression models
    in TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter is long and introduces many new ideas. It’s OK if you don’t grasp
    all the subtleties of these ideas in a first reading. We recommend moving forward
    and coming back to refer to the concepts here as needed later. We will repeatedly
    use these fundamentals in the remainder of the book in order to let these ideas
    sink in gradually.
  prefs: []
  type: TYPE_NORMAL
- en: Mathematical Review
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This first section reviews the mathematical tools needed to conceptually understand
    machine learning. We attempt to minimize the number of Greek symbols required,
    and focus instead on building conceptual understanding rather than technical manipulations.
  prefs: []
  type: TYPE_NORMAL
- en: Functions and Differentiability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section will provide you with a brief overview of the concepts of functions
    and differentiability. A function *f* is a rule that takes an input to an output.
    There are functions in all computer programming languages, and the mathematical
    definition of a function isn’t really much different. However, mathematical functions
    commonly used in physics and engineering have other important properties such
    as continuity and differentiability. A continuous function, loosely speaking,
    is one that can be drawn without lifting your pencil from the paper, as shown
    in [Figure 3-1](#ch3-cont). (This is of course not the technical definition, but
    it captures the spirit of the continuity condition.)
  prefs: []
  type: TYPE_NORMAL
- en: '![continuous_1.gif](assets/tfdl_0301.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-1\. Some continuous functions.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Differentiability is a type of smoothness condition on functions. It says no
    sharp corners or turns are allowed in the function ([Figure 3-2](#ch3-diff)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Math_images_4.jpg](assets/tfdl_0302.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-2\. A differentiable function.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The key advantage of differentiable functions is that we can use the slope of
    the function at a particular point as a guide to find places where the function
    is higher or lower than our current position. This allows us to find the *minima*
    of the function. The *derivative* of differentiable function *f*, denoted <math><msup><mi>f</mi>
    <mo>'</mo></msup></math> , is another function that provides the slope of the
    original function at all points. The conceptual idea is that the derivative of
    a function at a given point gives a signpost pointing to directions where the
    function is higher or lower than its current value. An optimization algorithm
    can follow this signpost to move closer to a minima of *f*. At the minima itself,
    the function will have derivative zero.
  prefs: []
  type: TYPE_NORMAL
- en: The power of derivative-driven optimization isn’t apparent at first. Generations
    of calculus students have suffered through stultifying exercises minimizing tiny
    functions on paper. These exercises aren’t useful since finding the minima of
    a function with only a small number of input parameters is a trivial exercise
    best done graphically. The power of derivative-driven optimization only becomes
    evident when there are hundreds, thousands, millions, or billions of variables.
    At these scales, understanding the function analytically is nigh impossible, and
    all visualizations are fraught exercises that may well miss the key attributes
    of the function. At these scales, the *gradient* of the function <math><mrow><mi>∇</mi>
    <mi>f</mi></mrow></math> , a generalization of <math><msup><mi>f</mi> <mo>'</mo></msup></math>
    to multivariate functions, is likely the most powerful mathematical tool to understand
    the function and its behavior. We will dig into gradients in more depth later
    in this chapter. (Conceptually that is; we won’t cover the technical details of
    gradients in this work.)
  prefs: []
  type: TYPE_NORMAL
- en: 'At a very high level, machine learning is simply the act of function minimization:
    learning algorithms are nothing more than minima finders for suitably defined
    functions. This definition has the advantage of mathematical simplicity. But,
    what are these special differentiable functions that encode useful solutions in
    their minima and how can we find them?'
  prefs: []
  type: TYPE_NORMAL
- en: Loss Functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In order to solve a given machine learning problem, a data scientist must find
    a way of constructing a function whose minima encode solutions to the real-world
    problem at hand. Luckily for our hapless data scientist, the machine learning
    literature has built up a rich history of *loss functions* that perform such encodings.
    Practical machine learning boils down to understanding the different types of
    loss functions available and knowing which loss function should be applied to
    which problems. Put another way, the loss function is the mechanism by which a
    data science project is transmuted into mathematics. All of machine learning,
    and much of artificial intelligence, boils down to the creation of the right loss
    function to solve the problem at hand. We will give you a whirlwind tour of some
    common families of loss functions.
  prefs: []
  type: TYPE_NORMAL
- en: We start by noting that a loss function <math alttext="script upper L"><mi>ℒ</mi></math>
    must satisfy some mathematical properties to be meaningful. First <math alttext="script
    upper L"><mi>ℒ</mi></math> must use both datapoints *x* and labels *y*. We denote
    this by writing the loss function as <math><mrow><mi>ℒ</mi> <mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>)</mo></mrow></math> . Using our language from the previous
    chapter, both *x* and *y* are tensors, and <math alttext="script upper L"><mi>ℒ</mi></math>
    is a function from pairs of tensors to scalars. What should the functional form
    of the loss function be? A common assumption that people use is to make loss functions
    *additive*. Suppose that <math alttext="left-parenthesis x Subscript i Baseline
    comma y Subscript i Baseline right-parenthesis"><mrow><mo>(</mo> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo>,</mo> <msub><mi>y</mi> <mi>i</mi></msub> <mo>)</mo></mrow></math>
    are the data available for example *i* and that there are *N* total examples.
    Then the loss function can be decomposed as
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>ℒ</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>,</mo>
    <mi>y</mi> <mo>)</mo></mrow> <mo>=</mo> <munderover><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>N</mi></munderover> <msub><mi>ℒ</mi> <mi>i</mi></msub> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo>,</mo> <msub><mi>y</mi> <mi>i</mi></msub> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: '(In practice <math><msub><mi>ℒ</mi> <mi>i</mi></msub></math> is the same for
    every datapoint.) This additive decomposition allows for many useful advantages.
    The first is that derivatives factor through addition, so computing the gradient
    of the total loss simplifies as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>∇</mi> <mi>ℒ</mi> <mrow><mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>)</mo></mrow> <mo>=</mo> <munderover><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>N</mi></munderover> <mi>∇</mi> <msub><mi>ℒ</mi> <mi>i</mi></msub> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mi>i</mi></msub> <mo>,</mo> <msub><mi>y</mi> <mi>i</mi></msub>
    <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This mathematical trick means that so long as the smaller functions <math><msub><mi>ℒ</mi>
    <mi>i</mi></msub></math> are differentiable, so too will the total loss function
    be. It follows that the problem of designing loss functions resolves into the
    problem of designing smaller functions <math alttext="script upper L Subscript
    i Baseline left-parenthesis x Subscript i Baseline comma y Subscript i Baseline
    right-parenthesis"><mrow><msub><mi>ℒ</mi> <mi>i</mi></msub> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo>,</mo> <msub><mi>y</mi> <mi>i</mi></msub> <mo>)</mo></mrow></mrow></math>
    . Before we dive into designing the <math alttext="script upper L Subscript i"><msub><mi>ℒ</mi>
    <mi>i</mi></msub></math> , it will be convenient to take a small detour that explains
    the difference between classification and regression problems.
  prefs: []
  type: TYPE_NORMAL
- en: Classification and regression
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Machine learning algorithms can be broadly categorized as supervised or unsupervised
    problems. Supervised problems are those for which both datapoints *x* and labels
    *y* are available, while unsupervised problems have only datapoints *x* without
    labels *y*. In general, unsupervised machine learning is much harder and less
    well-defined (what does it mean to “understand” datapoints *x*?). We won’t delve
    into unsupervised loss functions at this point since, in practice, most unsupervised
    losses are cleverly repurposed supervised losses.
  prefs: []
  type: TYPE_NORMAL
- en: Supervised machine learning can be broken up into the two subproblems of classification
    and regression. A classification problem is one in which you seek to design a
    machine learning system that assigns a discrete label, say 0/1 (or more generally
    <math><mrow><mn>0</mn> <mo>,</mo> <mo>⋯</mo> <mo>,</mo> <mi>n</mi></mrow></math>
    ) to a given datapoint. Regression is the problem of designing a machine learning
    system that attaches a real valued label (in <math alttext="double-struck upper
    R"><mi>ℝ</mi></math> ) to a given datapoint.
  prefs: []
  type: TYPE_NORMAL
- en: At a high level, these problems may appear rather different. Discrete objects
    and continuous objects are typically treated differently by mathematics and common
    sense. However, part of the trickery used in machine learning is to use continuous,
    differentiable loss functions to encode both classification and regression problems.
    As we’ve mentioned previously, much of machine learning is simply the art of turning
    complicated real-world systems into suitably simple differentiable functions.
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we will introduce you to a pair of mathematical functions
    that will prove very useful for transforming classification and regression tasks
    into suitable loss functions.
  prefs: []
  type: TYPE_NORMAL
- en: L² Loss
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The *L*² loss (pronounced *ell-two* loss) is commonly used for regression problems.
    The *L*² loss (or *L*²-norm as it’s commonly called elsewhere) provides for a
    measure of the magnitude of a vector:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><msub><mrow><mo>∥</mo><mi>a</mi><mo>∥</mo></mrow>
    <mn>2</mn></msub> <mo>=</mo> <msqrt><mrow><msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>N</mi></msubsup> <msubsup><mi>a</mi> <mi>i</mi> <mn>2</mn></msubsup></mrow></msqrt></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, *a* is assumed to be a vector of length *N*. The *L*² norm is commonly
    used to define the distance between two vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><msub><mrow><mo>∥</mo><mi>a</mi><mo>-</mo><mi>b</mi><mo>∥</mo></mrow>
    <mn>2</mn></msub> <mo>=</mo> <msqrt><mrow><msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>N</mi></msubsup> <msup><mrow><mo>(</mo><msub><mi>a</mi> <mi>i</mi></msub>
    <mo>-</mo><msub><mi>b</mi> <mi>i</mi></msub> <mo>)</mo></mrow> <mn>2</mn></msup></mrow></msqrt></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This idea of *L*² as a distance measurement is very useful for solving regression
    problems in supervised machine learning. Suppose that *x* is a collection of data
    and *y* the associated labels. Let *f* be some differentiable function that encodes
    our machine learning model. Then to encourage *f* to predict *y*, we create the
    *L*² loss function
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>ℒ</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>,</mo>
    <mi>y</mi> <mo>)</mo></mrow> <mo>=</mo> <msub><mrow><mo>∥</mo><mi>f</mi><mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mo>-</mo><mi>y</mi><mo>∥</mo></mrow>
    <mn>2</mn></msub></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: As a quick note, it’s common in practice to not use the *L*² loss directly,
    but rather its square
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><msubsup><mrow><mo>∥</mo><mi>a</mi><mo>-</mo><mi>b</mi><mo>∥</mo></mrow>
    <mn>2</mn> <mn>2</mn></msubsup> <mo>=</mo> <munderover><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>N</mi></munderover> <msup><mrow><mo>(</mo><msub><mi>a</mi> <mi>i</mi></msub>
    <mo>-</mo><msub><mi>b</mi> <mi>i</mi></msub> <mo>)</mo></mrow> <mn>2</mn></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: in order to avoid dealing with terms of the form <math alttext="1 slash StartRoot
    left-parenthesis EndRoot x right-parenthesis"><mrow><mn>1</mn> <mo>/</mo> <msqrt><mo>(</mo></msqrt>
    <mrow><mi>x</mi> <mo>)</mo></mrow></mrow></math> in the gradient. We will use
    the squared *L*² loss repeatedly in the remainder of this chapter and book.
  prefs: []
  type: TYPE_NORMAL
- en: Probability distributions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before introducing loss functions for classification problems, it will be useful
    to take a quick aside to introduce probability distributions. To start, what is
    a probability distribution and why should we care about it for the purposes of
    machine learning? Probability is a deep subject, so we will only delve far enough
    into it for you to gain the required minimal understanding. At a high level, probability
    distributions provide a mathematical trick that allows you to relax a discrete
    set of choices into a continuum. Suppose, for example, you need to design a machine
    learning system that predicts whether a coin will fall heads up or heads down.
    It doesn’t seem like heads up/down can be encoded as a continuous function, much
    less a differentiable one. How can you then use the machinery of calculus or TensorFlow
    to solve problems involving discrete choices?
  prefs: []
  type: TYPE_NORMAL
- en: Enter the probability distribution. Instead of hard choices, make the classifier
    predict the chance of getting heads up or heads down. For example, the classifier
    may learn to predict that heads has probability 0.75 and tails has probability
    0.25\. Note that probabilities vary continuously! Consequently by working with
    the probabilities of discrete events rather than with the events themselves, you
    can neatly sidestep the issue that calculus doesn’t really work with discrete
    events.
  prefs: []
  type: TYPE_NORMAL
- en: A probability distribution *p* is simply a listing of the probabilities for
    the possible discrete events at hand. In this case, *p* = (0.75, 0.25). Note,
    alternatively, you can view <math alttext="p colon StartSet 0 comma 1 EndSet right-arrow
    double-struck upper R"><mrow><mi>p</mi> <mo>:</mo> <mo>{</mo> <mn>0</mn> <mo>,</mo>
    <mn>1</mn> <mo>}</mo> <mo>→</mo> <mi>ℝ</mi></mrow></math> as a function from the
    set of two elements to the real numbers. This viewpoint will be useful notationally
    at times.
  prefs: []
  type: TYPE_NORMAL
- en: We briefly note that the technical definition of a probability distribution
    is more involved. It is feasible to assign probability distributions to real-valued
    events. We will discuss such distributions later in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-entropy loss
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Cross-entropy is a mathematical method for gauging the distance between two
    probability distributions:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>H</mi> <mrow><mo>(</mo> <mi>p</mi> <mo>,</mo>
    <mi>q</mi> <mo>)</mo></mrow> <mo>=</mo> <mo>-</mo> <munder><mo>∑</mo> <mi>x</mi></munder>
    <mi>p</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo form="prefix">log</mo>
    <mi>q</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Here *p* and *q* are two probability distributions. The notation *p*(*x*) denotes
    the probability *p* accords to event *x*. This definition is worth discussing
    carefully. Like the *L*² norm, *H* provides a notion of distance. Note that in
    the case where *p* = *q*,
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>H</mi> <mrow><mo>(</mo> <mi>p</mi> <mo>,</mo>
    <mi>p</mi> <mo>)</mo></mrow> <mo>=</mo> <mo>-</mo> <munder><mo>∑</mo> <mi>x</mi></munder>
    <mi>p</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo form="prefix">log</mo>
    <mi>p</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This quantity is the entropy of *p* and is usually written simply *H*(*p*).
    It’s a measure of how disordered the distribution is; the entropy is maximized
    when all events are equally likely. *H*(*p*) is always less than or equal to *H*(*p*,
    *q*). In fact, the “further away” distribution *q* is from *p*, the larger the
    cross-entropy gets. We won’t dig deeply into the precise meanings of these statements,
    but the intuition of cross-entropy as a distance mechanism is worth remembering.
  prefs: []
  type: TYPE_NORMAL
- en: As an aside, note that unlike *L*² norm, *H* is asymmetric! That is, <math alttext="upper
    H left-parenthesis p comma q right-parenthesis not-equals upper H left-parenthesis
    q comma p right-parenthesis"><mrow><mi>H</mi> <mo>(</mo> <mi>p</mi> <mo>,</mo>
    <mi>q</mi> <mo>)</mo> <mo>≠</mo> <mi>H</mi> <mo>(</mo> <mi>q</mi> <mo>,</mo> <mi>p</mi>
    <mo>)</mo></mrow></math> . For this reason, reasoning with cross-entropy can be
    a little tricky and is best done with some caution.
  prefs: []
  type: TYPE_NORMAL
- en: Returning to concrete matters, now suppose that <math alttext="p equals left-parenthesis
    y comma 1 minus y right-parenthesis"><mrow><mi>p</mi> <mo>=</mo> <mo>(</mo> <mi>y</mi>
    <mo>,</mo> <mn>1</mn> <mo>-</mo> <mi>y</mi> <mo>)</mo></mrow></math> is the true
    data distribution for a discrete system with two outcomes, and <math alttext="q
    equals left-parenthesis y Subscript pred Baseline comma 1 minus y Subscript pred
    Baseline right-parenthesis"><mrow><mi>q</mi> <mo>=</mo> <mo>(</mo> <msub><mi>y</mi>
    <mtext>pred</mtext></msub> <mo>,</mo> <mn>1</mn> <mo>-</mo> <msub><mi>y</mi> <mtext>pred</mtext></msub>
    <mo>)</mo></mrow></math> is that predicted by a machine learning system. Then
    the cross-entropy loss is
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>H</mi> <mrow><mo>(</mo> <mi>p</mi> <mo>,</mo>
    <mi>q</mi> <mo>)</mo></mrow> <mo>=</mo> <mi>y</mi> <mo form="prefix">log</mo>
    <msub><mi>y</mi> <mtext>pred</mtext></msub> <mo>+</mo> <mrow><mo>(</mo> <mn>1</mn>
    <mo>-</mo> <mi>y</mi> <mo>)</mo></mrow> <mo form="prefix">log</mo> <mrow><mo>(</mo>
    <mn>1</mn> <mo>-</mo> <msub><mi>y</mi> <mtext>pred</mtext></msub> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This form of the loss is used widely in machine learning systems to train classifiers.
    Empirically, minimizing *H*(*p*, *q*) seems to construct classifiers that reproduce
    provided training labels well.
  prefs: []
  type: TYPE_NORMAL
- en: Gradient Descent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far in this chapter, you have learned about the notion of function minimization
    as a proxy for machine learning. As a short recap, minimizing a suitable function
    is often sufficient to learn to solve a desired task. In order to use this framework,
    you need to use suitable loss functions, such as the *L*² or *H*(*p*, *q*) cross-entropy
    in order to transform classification and regression problems into suitable loss
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: Learnable Weights
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far in this chapter, we’ve explained that machine learning is the act of
    minimizing suitably defined loss function <math alttext="script upper L left-parenthesis
    x comma y right-parenthesis"><mrow><mi>ℒ</mi> <mo>(</mo> <mi>x</mi> <mo>,</mo>
    <mi>y</mi> <mo>)</mo></mrow></math> . That is, we attempt to find arguments to
    the loss function <math alttext="script upper L"><mi>ℒ</mi></math> that minimize
    it. However, careful readers will recall that (*x*,*y*) are fixed quantities that
    cannot be changed. What arguments to <math alttext="script upper L"><mi>ℒ</mi></math>
    are we changing during learning then?
  prefs: []
  type: TYPE_NORMAL
- en: Enter learnable weights *W*. Suppose *f*(*x*) is a differentiable function we
    wish to fit with our machine learning model. We will dictate that *f* be *parameterized*
    by choice of *W*. That is, our function actually has two arguments *f*(*W*, *x*).
    Fixing the value of *W* results in a function that depends solely on datapoints
    *x*. These learnable weights are the quantities actually selected by minimization
    of the loss function. We will see later in the chapter how TensorFlow can be used
    to encode learnable weights using `tf.Variable`.
  prefs: []
  type: TYPE_NORMAL
- en: But now, suppose that we have encoded our learning problem with a suitable loss
    function? How can we actually find minima of this loss function in practice? The
    key trick we will use is minimization by gradient descent. Suppose that *f* is
    a function that depends on some weights *W*. Then <math alttext="normal nabla
    upper W"><mrow><mi>∇</mi> <mi>W</mi></mrow></math> denotes the direction change
    in *W* that would maximally increase *f*. It follows that taking a step in the
    opposite direction would get us closer to the minima of *f*.
  prefs: []
  type: TYPE_NORMAL
- en: Notation for Gradients
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We have written the gradient for learnable weight *W* as <math alttext="normal
    nabla upper W"><mrow><mi>∇</mi> <mi>W</mi></mrow></math> . At times, it will be
    convenient to use the following alternative notation for the gradient:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>∇</mi> <mi>W</mi> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>ℒ</mi></mrow>
    <mrow><mi>∂</mi><mi>W</mi></mrow></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Read this equation as saying that gradient <math alttext="normal nabla upper
    W"><mrow><mi>∇</mi> <mi>W</mi></mrow></math> encodes the direction that maximally
    changes the loss <math alttext="script upper L"><mi>ℒ</mi></math> .
  prefs: []
  type: TYPE_NORMAL
- en: TheI idea of gradient descent is to find the minima of functions by repeatedly
    following the negative gradient. Algorithmically, this update rule can be expressed
    as
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>W</mi> <mo>=</mo> <mi>W</mi> <mo>-</mo> <mi>α</mi>
    <mi>∇</mi> <mi>W</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where <math><mi>α</mi></math> is the *step-size* and dictates how much weight
    is given to new gradient <math alttext="normal nabla upper W"><mrow><mi>∇</mi>
    <mi>W</mi></mrow></math> . The idea is to take many little steps each in the direction
    of <math alttext="normal nabla upper W"><mrow><mi>∇</mi> <mi>W</mi></mrow></math>
    . Note that <math alttext="normal nabla upper W"><mrow><mi>∇</mi> <mi>W</mi></mrow></math>
    is itself a function of *W*, so the actual step changes at each iteration. Each
    step performs a little update to the weight matrix *W*. The iterative process
    of performing updates is typically called *learning* the weight matrix *W*.
  prefs: []
  type: TYPE_NORMAL
- en: Computing Gradients Efficiently with Minibatches
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One issue is that computing <math alttext="normal nabla upper W"><mrow><mi>∇</mi>
    <mi>W</mi></mrow></math> can be very slow. Implicitly, <math alttext="normal nabla
    upper W"><mrow><mi>∇</mi> <mi>W</mi></mrow></math> depends on the loss function
    <math alttext="script upper L"><mi>ℒ</mi></math> . Since <math alttext="script
    upper L"><mi>ℒ</mi></math> depends on the entire dataset, computing <math alttext="normal
    nabla upper W"><mrow><mi>∇</mi> <mi>W</mi></mrow></math> can become very slow
    for large datasets. In practice, people usually estimate <math><mrow><mi>∇</mi>
    <mi>W</mi></mrow></math> on a fraction of the dataset called a *minibatch*. Each
    minibatch is of size typically 50–100\. The size of the minibatch is a *hyperparameter*
    in a deep learning algorithm. The step-size for each step <math><mi>α</mi></math>
    is another hyperparameter. Deep learning algorithms typically have clusters of
    hyperparameters, which are not themselves learned via the stochastic gradient
    descent.
  prefs: []
  type: TYPE_NORMAL
- en: This tension between learnable parameters and hyperparameters is one of the
    weaknesses and strengths of deep architectures. The presence of hyperparameters
    provides much room for utilizing the expert’s strong intuition, while the learnable
    parameters allow the data to speak for itself. However, this flexibility itself
    quickly becomes a weakness, with understanding of the behavior of hyperparameters
    something of a black art that blocks beginners from widely deploying deep learning.
    We will spend significant effort discussing hyperparameter optimization later
    in this book.
  prefs: []
  type: TYPE_NORMAL
- en: We end this section by introducing the notion of an *epoch*. An epoch is a full
    pass of the gradient descent algorithm over the data *x*. More particularly, an
    epoch consists of however many gradient descent steps are required to view all
    the data at a given minibatch size. For example, suppose that a dataset has 1,000
    datapoints and training uses a minibatch of size 50\. Then an epoch will consist
    of 20 gradient descent updates. Each epoch of training increases the amount of
    useful knowledge the model has gained. Mathematically, this will correspond to
    reductions in the value of the loss function on the training set.
  prefs: []
  type: TYPE_NORMAL
- en: Early epochs will cause dramatic drops in the loss function. This process is
    often referred to as *learning the prior* on that dataset. While it appears that
    the model is learning rapidly, it is in fact only adjusting itself to reside in
    the portion of parameter space that is pertinent to the problem at hand. Later
    epochs will correspond to much smaller drops in the loss function, but it is often
    in these later epochs that meaningful learning will happen. A few epochs is usually
    too little time for a nontrivial model to learn anything useful; models are usually
    trained from 10–1,000 epochs or until convergence. While this appears large, it’s
    important to note that the number of epochs required usually doesn’t scale with
    the size of the dataset at hand. Consequently, gradient descent scales linearly
    with the size of data and not quadratically! This is one of the greatest strengths
    of the stochastic gradient descent method versus other learning algorithms. More
    complicated learning algorithms may only require a single pass over a dataset,
    but may use total compute that scales quadratically with the number of datapoints.
    In this era of big datasets, quadratic runtimes are a fatal weakness.
  prefs: []
  type: TYPE_NORMAL
- en: Tracking the drop in the loss function as a function of the number of epochs
    can be an extremely useful visual shorthand for understanding the learning process.
    These plots are often referred to as loss curves (see [Figure 3-4](#ch3-smoothloss)).
    With time, an experienced practitioner can diagnose common failures in learning
    with just a quick glance at the loss curve. We will pay significant attention
    to the loss curves for various deep learning models over the course of this book.
    In particular, later in this chapter, we will introduce TensorBoard, a powerful
    visualization suite that TensorFlow provides for tracking quantities such as loss
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: '![smooth_loss.png](assets/tfdl_0304.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-4\. An example of a loss curve for a model. Note that this loss curve
    is from a model trained with the true gradient (that is, not a minibatch estimate)
    and is consequently smoother than other loss curves you will encounter later in
    this book.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Automatic Differentiation Systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Machine learning is the art of defining loss functions suited to datasets and
    then minimizing them. In order to minimize loss functions, we need to compute
    their gradients and use the gradient descent algorithm to iteratively reduce the
    loss. However, we still need to discuss how gradients are actually computed. Until
    recently, the answer was “by hand.” Machine learning experts would break out pen
    and paper and compute matrix derivatives by hand to compute the analytical formulas
    for all gradients in a learning system. These formulas would then be manually
    coded to implement the learning algorithm. This process was notoriously buggy,
    and more than one machine learning expert has stories of accidental gradient errors
    in published papers and production systems going undiscovered for years.
  prefs: []
  type: TYPE_NORMAL
- en: 'This state of affairs has changed significantly with the widespread availability
    of automatic differentiation engines. Systems like TensorFlow are capable of automatically
    computing gradients for almost all loss functions. This automatic differentiation
    is one of the greatest advantages of TensorFlow and similar systems, since machine
    learning practitioners no longer need to be experts at matrix calculus. However,
    it’s still worth understanding at a high level how TensorFlow can automatically
    take derivatives of complex functions. For those readers who suffered through
    an introductory class in calculus, you might remember that taking derivatives
    of functions is surprisingly mechanical. There are a series of simple rules that
    can be applied to take derivatives of most functions. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mi>d</mi> <mrow><mi>d</mi><mi>x</mi></mrow></mfrac>
    <msup><mi>x</mi> <mi>n</mi></msup> <mo>=</mo> <mi>n</mi> <msup><mi>x</mi> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msup></mrow></math><math
    display="block"><mrow><mfrac><mi>d</mi> <mrow><mi>d</mi><mi>x</mi></mrow></mfrac>
    <msup><mi>e</mi> <mi>x</mi></msup> <mo>=</mo> <msup><mi>e</mi> <mi>x</mi></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'These rules can be combined through the power of the chain rule:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mfrac><mi>d</mi> <mrow><mi>d</mi><mi>x</mi></mrow></mfrac>
    <mi>f</mi> <mrow><mo>(</mo> <mi>g</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>=</mo> <msup><mi>f</mi> <mo>'</mo></msup> <mrow><mo>(</mo>
    <mi>g</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>)</mo></mrow> <msup><mi>g</mi>
    <mo>'</mo></msup> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where <math><msup><mi>f</mi> <mo>'</mo></msup></math> is used to denote the
    derivative of *f* and <math alttext="g prime"><msup><mi>g</mi> <mo>'</mo></msup></math>
    that of *g*. With these rules, it’s straightforward to envision how one might
    program an automatic differentiation engine for one-dimensional calculus. Indeed,
    the creation of such a differentiation engine is often a first-year programming
    exercise in Lisp-based classes. (It turns out that correctly parsing functions
    is a much trickier problem than taking derivatives. Lisp makes it trivial to parse
    formulas using its syntax, while in other languages, waiting to do this exercise
    until you take a course on compilers is often easier).
  prefs: []
  type: TYPE_NORMAL
- en: How might these rules be extended to calculus of higher dimensions? Getting
    the math right is trickier, since there are many more numbers to consider. For
    example, given *X* = *AB* where *X*, *A*, *B* are all matrices, the formula comes
    out to be
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>∇</mi> <mi>A</mi> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>L</mi></mrow>
    <mrow><mi>∂</mi><mi>A</mi></mrow></mfrac> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>L</mi></mrow>
    <mrow><mi>∂</mi><mi>X</mi></mrow></mfrac> <msup><mi>B</mi> <mi>T</mi></msup> <mo>=</mo>
    <mrow><mo>(</mo> <mi>∇</mi> <mi>X</mi> <mo>)</mo></mrow> <msup><mi>B</mi> <mi>T</mi></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Formulas like this can be combined to provide a symbolic differentiation system
    for vectorial and tensorial calculus.
  prefs: []
  type: TYPE_NORMAL
- en: Learning with TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the rest of this chapter, we will cover the concepts that you need to learn
    basic machine learning models with TensorFlow. We will start by introducing the
    concept of toy datasets, and will explain how to create meaningful toy datasets
    using common Python libraries. Next, we will discuss new TensorFlow ideas such
    as placeholders, feed dictionaries, name scopes, optimizers, and gradients. The
    next section will show you how to use these concepts to train simple regression
    and classification models.
  prefs: []
  type: TYPE_NORMAL
- en: Creating Toy Datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will discuss how to create simple but meaningful synthetic
    datasets, or toy datasets, that we will use to train simple supervised classification
    and regression models.
  prefs: []
  type: TYPE_NORMAL
- en: An (extremely) brief introduction to NumPy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We will make heavy use of NumPy in order to define useful toy datasets. NumPy
    is a Python package that allows for manipulation of tensors (called `ndarray`s
    in NumPy). [Example 3-1](#ch3-numpy) shows some basics.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-1\. Some examples of basic NumPy usage
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: You may notice that NumPy `ndarray` manipulation looks remarkably similar to
    TensorFlow tensor manipulation. This similarity was purposefully designed by TensorFlow’s
    architects. Many key TensorFlow utility functions have similar arguments and forms
    to analogous functions in NumPy. For this purpose, we will not attempt to introduce
    NumPy in great depth, and will trust readers to use experimentation to work out
    NumPy usage. There are numerous online resources that provide tutorial introductions
    to NumPy.
  prefs: []
  type: TYPE_NORMAL
- en: Why are toy datasets important?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In machine learning, it is often critical to learn to properly use toy datasets.
    Learning is challenging, and one of the most common mistakes beginners make is
    trying to learn nontrivial models on complex data too soon. These attempts often
    end in abject failure, and the would-be machine learner walks away dejected and
    convinced machine learning isn’t for them.
  prefs: []
  type: TYPE_NORMAL
- en: The real culprit here of course isn’t the student, but rather the fact that
    real-world datasets have many idiosyncrasies. Seasoned data scientists have learned
    that real-world datasets often require many clean-up and preprocessing transformations
    before becoming amenable to learning. Deep learning exacerbates this problem,
    since most deep learning models are notoriously sensitive to infelicities in data.
    Issues like a wide range of regression labels, or underlying strong noise patterns
    can throw off gradient-descent–based methods, even when other machine learning
    algorithms (such as random forests) would have no issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'Luckily, it’s almost always possible to deal with these issues, but doing so
    can require considerable sophistication on the part of the data scientist. These
    sensitivity issues are perhaps the biggest roadblock to the commoditization of
    machine learning as a technology. We will go into depth on data clean-up strategies,
    but for the time being, we recommend a much simpler alternative: use toy datasets!'
  prefs: []
  type: TYPE_NORMAL
- en: Toy datasets are critical for understanding learning algorithms. Given very
    simple synthetic datasets, it is trivial to gauge whether the algorithm has learned
    the correct rule. On more complex datasets, this judgment can be highly challenging.
    Consequently, for the remainder of this chapter, we will only use toy datasets
    as we cover the fundamentals of gradient-descent–based learning with TensorFlow.
    We will dive deep into case studies with real-world data in the following chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Adding noise with Gaussians
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Earlier, we discussed discrete probability distributions as a tool for turning
    discrete choices into continuous values. We also alluded to the idea of a continuous
    probability distribution but didn’t dive into it.
  prefs: []
  type: TYPE_NORMAL
- en: Continuous probability distributions (more accurately known as probability density
    functions) are a useful mathematical tool for modeling random events that may
    have a range of outcomes. For our purposes, it is enough to think of probability
    density functions as a useful tool for modeling some measurement error in gathering
    data. The Gaussian distribution is widely used for noise modeling.
  prefs: []
  type: TYPE_NORMAL
- en: As [Figure 3-5](#ch3-gaussian) shows, note that Gaussians can have different
    *means* <math><mi>μ</mi></math> and *standard deviations* <math alttext="sigma"><mi>σ</mi></math>
    . The mean of a Gaussian is the average value it takes, while the standard deviation
    is a measure of the spread around this average value. In general, adding a Gaussian
    random variable onto some quantity provides a structured way to fuzz the quantity
    by making it vary slighty. This is a very useful trick for coming up with nontrivial
    synthetic datasets.
  prefs: []
  type: TYPE_NORMAL
- en: '![gaussian.png](assets/tfdl_0305.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-5\. Illustrations of various Gaussian probability distributions with
    different means and standard deviations.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: We quickly note that the Gaussian distribution is also called the Normal distribution.
    A Gaussian with mean <math><mi>μ</mi></math> and standard deviation <math alttext="sigma"><mi>σ</mi></math>
    is written <math alttext="upper N left-parenthesis mu comma sigma right-parenthesis"><mrow><mi>N</mi>
    <mo>(</mo> <mi>μ</mi> <mo>,</mo> <mi>σ</mi> <mo>)</mo></mrow></math> . This shorthand
    notation is convenient, and we will use it many times in the coming chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Toy regression datasets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The simplest form of linear regression is learning the parameters for a one-dimensional
    line. Suppose that our datapoints *x* are one-dimensional. Then suppose that real-valued
    labels *y* are generated by a linear rule
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>y</mi> <mo>=</mo> <mi>w</mi> <mi>x</mi> <mo>+</mo>
    <mi>b</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Here, *w*, *b* are the learnable parameters that must be estimated from data
    by gradient descent. In order to test that we can learn these parameters with
    TensorFlow, we will generate an artificial dataset consisting of points upon a
    straight line. To make the learning challenge a little more difficult, we will
    add a small amount of Gaussian noise to the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s write down the equation for our line perturbed by a small amount of Gaussian
    noise:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>y</mi> <mo>=</mo> <mi>w</mi> <mi>x</mi> <mo>+</mo>
    <mi>b</mi> <mo>+</mo> <mi>N</mi> <mo>(</mo> <mn>0</mn> <mo>,</mo> <mi>ϵ</mi> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Here <math alttext="epsilon"><mi>ϵ</mi></math> is the standard deviation of
    the noise term. We can then use NumPy to generate an artificial dataset drawn
    from this distribution, as shown in [Example 3-2](#ch3-numpy-sample).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-2\. Using NumPy to sample an artificial dataset
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: We plot this dataset using Matplotlib in [Figure 3-6](#ch3-toyregplot). (you
    can find the code in [the GitHub repo](https://github.com/matroid/dlwithtf) associated
    with this book to see the exact plotting code) to verify that synthetic data looks
    reasonable. As expected, the data distribution is a straight line, with a small
    amount of measurement error.
  prefs: []
  type: TYPE_NORMAL
- en: '![lr_data.png](assets/tfdl_0306.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-6\. Plot of the toy regression data distribution.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Toy classification datasets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It’s a little trickier to create a synthetic classification dataset. Logically,
    we want two distinct classes of points, which are easily separated. Suppose that
    the dataset consists of only two types of points, (–1, –1) and (1, 1). Then a
    learning algorithm would have to learn a rule that separates these two data values.
  prefs: []
  type: TYPE_NORMAL
- en: '*y*[0] = (–1, –1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*y*[1] = (1, 1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As before, let’s make the challenge a little more difficult by adding some
    Gaussian noise to both types of points:'
  prefs: []
  type: TYPE_NORMAL
- en: '*y*[0] = (–1, –1) + *N*(0, ϵ)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*y*[1] = (1, 1) + *N*(0, ϵ)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, there’s a slight bit of trickiness here. Our points are two-dimensional,
    while the Gaussian noise we introduced previously is one-dimensional. Luckily,
    there exists a multivariate extension of the Gaussian. We won’t discuss the intricacies
    of the multivariate Gaussian here, but you do not need to understand the intricacies
    to follow our discussion.
  prefs: []
  type: TYPE_NORMAL
- en: The NumPy code to generate the synthetic dataset in [Example 3-3](#ch3-synth-2d)
    is slightly trickier than that for the linear regression problem since we have
    to use the stacking function `np.vstack` to combine the two different types of
    datapoints and associate them with different labels. (We use the related function
    `np.concatenate` to combine the one-dimensional labels.)
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-3\. Sample a toy classification dataset with NumPy
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[Figure 3-7](#ch3-toyclassplot) plots the data generated by this code with
    Matplotlib to verify that the distribution is as expected. We see that the data
    resides in two classes that are neatly separated.'
  prefs: []
  type: TYPE_NORMAL
- en: '![logistic_data.png](assets/tfdl_0307.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-7\. Plot of the toy classification data distribution.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: New TensorFlow Concepts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Creating simple machine learning systems in TensorFlow will require that you
    learn some new TensorFlow concepts.
  prefs: []
  type: TYPE_NORMAL
- en: Placeholders
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A placeholder is a way to input information into a TensorFlow computation graph.
    Think of placeholders as the input nodes through which information enters TensorFlow.
    The key function used to create placeholders is `tf.placeholder` ([Example 3-4](#ch3-place)).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-4\. Create a TensorFlow placeholder
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We will use placeholders to feed datapoints *x* and labels *y* to our regression
    and classification algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Feed dictionaries and Fetches
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Recall that we can evaluate tensors in TensorFlow by using `sess.run(var)`.
    How do we feed in values for placeholders in our TensorFlow computations then?
    The answer is to construct *feed dictionaries*. Feed dictionaries are Python dictionaries
    that map TensorFlow tensors to `np.ndarray` objects that contain the concrete
    values for these placeholders. A feed dictionary is best viewed as an input to
    a TensorFlow computation graph. What then is an output? TensorFlow calls these
    outputs *fetches*. You have seen fetches already. We used them extensively in
    the previous chapter without calling them as such; the fetch is a tensor (or tensors)
    whose value is retrieved from the computation graph after the computation (using
    placeholder values from the feed dictionary) is run to completion ([Example 3-5](#ch3-fetch)).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-5\. Using fetches
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Name scopes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In complicated TensorFlow programs, there will be many tensors, variables, and
    placeholders defined throughout the program. `tf.name_scope(name)` provides a
    simple scoping mechanism for managing these collections of variables ([Example 3-6](#ch3-namescope)).
    All computational graph elements created within the scope of a `tf.name_scope(name)`
    call will have `name` prepended to their names.
  prefs: []
  type: TYPE_NORMAL
- en: This organizational tool is most useful when combined with TensorBoard, since
    it aids the visualization system in automatically grouping graph elements within
    the same name scope. You will learn more about TensorBoard further in the next
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-6\. Using namescopes to organize placeholders
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Optimizers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The primitives introduced in the last two sections already hint at how machine
    learning is done in TensorFlow. You have learned how to add placeholders for datapoints
    and labels and how to use tensorial operations to define the loss function. The
    missing piece is that you still don’t know how to perform gradient descent using
    TensorFlow.
  prefs: []
  type: TYPE_NORMAL
- en: While it is in fact possible to define optimization algorithms such as gradient
    descent directly in Python using TensorFlow primitives, TensorFlow provides a
    collection of optimization algorithms in the `tf.train` module. These algorithms
    can be added as nodes to the TensorFlow computation graph.
  prefs: []
  type: TYPE_NORMAL
- en: Which optimizer should I use?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many possible optimizers available in `tf.train`. For a short preview,
    this list includes `tf.train.GradientDescentOptimizer`, `tf.train.MomentumOptimizer`,
    `tf.train.AdagradOptimizer`, `tf.train.AdamOptimizer`, and many more. What’s the
    difference between these various optimizers?
  prefs: []
  type: TYPE_NORMAL
- en: 'Almost all of these optimizers are based on the idea of gradient descent. Recall
    the simple gradient descent rule we previously introduced:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>W</mi> <mo>=</mo> <mi>W</mi> <mo>-</mo> <mi>α</mi>
    <mi>∇</mi> <mi>W</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Mathematically, this update rule is primitive. There are a variety of mathematical
    tricks that researchers have discovered that enable faster optimization without
    using too much extra computation. In general, `tf.train.AdamOptimizer` is a good
    default that is relatively robust. (Many optimizer methods are very sensitive
    to hyperparameter choice. It’s better for beginners to avoid trickier methods
    until they have a good grasp of the behavior of different optimization algorithms.)
  prefs: []
  type: TYPE_NORMAL
- en: '[Example 3-7](#ch3-optim) is a short bit of code that adds an optimizer to
    the computation graph that minimizes a predefined loss `l`.'
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-7\. Adding an Adam optimizer to TensorFlow computation graph
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Taking gradients with TensorFlow
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We mentioned previously that it is possible to directly implement gradient descent
    algorithms in TensorFlow. While most use cases don’t need to reimplement the contents
    of `tf.train`, it can be useful to look at gradient values directly for debugging
    purposes. `tf.gradients` provides a useful tool for doing so ([Example 3-8](#ch3-grad)).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-8\. Taking gradients directly
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This code snippet symbolically pulls down the gradients of loss `l` with respect
    to learnable parameter (`tf.Variable`) `W`. `tf.gradients` returns a list of the
    desired gradients. Note that the gradients are themselves tensors! TensorFlow
    performs symbolic differentiation, which means that gradients themselves are parts
    of the computational graph. One neat side effect of TensorFlow’s symbolic gradients
    is that it’s possible to stack derivatives in TensorFlow. This can sometimes be
    useful for more advanced algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Summaries and file writers for TensorBoard
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Gaining a visual understanding of the structure of a tensorial program can be
    very useful. The TensorFlow team provides the TensorBoard package for this purpose.
    TensorBoard starts a web server (on localhost by default) that displays various
    useful visualizations of a TensorFlow program. However, in order for TensorFlow
    programs to be inspected with TensorBoard, programmers must manually write logging
    statements. `tf.train.FileWriter()` specifies the logging directory for a TensorBoard
    program and `tf.summary` writes summaries of various TensorFlow variables to the
    specified logging directory. In this chapter, we will only use `tf.summary.scalar`,
    which summarizes a scalar quantity, to track the value of the loss function. `tf.summary.merge_all()`
    is a useful logging aid that merges multiple summaries into a single summary for
    convenience.
  prefs: []
  type: TYPE_NORMAL
- en: The code snippet in [Example 3-9](#ch3-logging) adds a summary for the loss
    and specifies a logging directory.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-9\. Adding a summary for the loss
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Training models with TensorFlow
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Suppose now that we have specified placeholders for datapoints and labels, and
    have defined a loss with tensorial operations. We have added an optimizer node
    `train_op` to the computational graph, which we can use to perform gradient descent
    steps (while we may actually use a different optimizer, we will refer to updates
    as gradient descent for convenience). How can we iteratively perform gradient
    descent to learn on this dataset?
  prefs: []
  type: TYPE_NORMAL
- en: The simple answer is that we use a Python `for`-loop. In each iteration, we
    use `sess.run()` to fetch the `train_op` along with the merged summary op `merged`
    and the loss `l` from the graph. We feed all datapoints and labels into `sess.run()`
    using a feed dictionary.
  prefs: []
  type: TYPE_NORMAL
- en: The code snippet in [Example 3-10](#ch3-simplelearn) demonstrates this simple
    learning method. Note that we don’t make use of minibatches for pedagogical simplicity.
    Code in following chapters will use minibatches when training on larger datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-10\. A simple example of training a model
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Training Linear and Logistic Models in TensorFlow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section ties together all the TensorFlow concepts introduced in the previous
    section to train linear and logistic regression models upon the toy datasets we
    introduced previously in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Linear Regression in TensorFlow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will provide code to define a linear regression model in
    TensorFlow and learn its weights. This task is straightforward and you can do
    it without TensorFlow easily. Nevertheless, it’s a good exercise to do in TensorFlow
    since it will bring together the new concepts that we have introduced throughout
    the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Defining and training linear regression in TensorFlow
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The model for a linear regression is straightforward:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>y</mi> <mo>=</mo> <mi>w</mi> <mi>x</mi> <mo>+</mo>
    <mi>b</mi></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Here *w* and *b* are the weights we wish to learn. We transform these weights
    into `tf.Variable` objects. We then use tensorial operations to construct the
    *L*² loss:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>ℒ</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>,</mo>
    <mi>y</mi> <mo>)</mo></mrow> <mo>=</mo> <msup><mrow><mo>(</mo><mi>y</mi><mo>-</mo><mi>w</mi><mi>x</mi><mo>-</mo><mi>b</mi><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: The code in [Example 3-11](#ch3-linmod) implements these mathematical operations
    in TensorFlow. It also uses `tf.name_scope` to group various operations, and adds
    a `tf.train.AdamOptimizer` for learning and `tf.summary` operations for TensorBoard
    usage.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-11\. Defining a linear regression model
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[Example 3-12](#ch3-lintrain) then trains this model as discussed previously
    (without using minibatches).'
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-12\. Training the linear regression model
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: All code for this example is provided in the [GitHub repository](https://github.com/matroid/dlwithtf)
    associated with this book. We encourage all readers to run the full script for
    the linear regression example to gain a firsthand sense for how the learning algorithm
    functions. The example is small enough that readers will not need access to any
    special-purpose computing hardware to run.
  prefs: []
  type: TYPE_NORMAL
- en: Taking Gradients for Linear Regression
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The equation for the linear system we’re modeling is *y* = *wx* + *b* where
    *w*, *b* are the learnable weights. As we mentioned previously, the loss for this
    system is <math alttext="script upper L equals left-parenthesis y minus w x minus
    b right-parenthesis squared"><mrow><mi>ℒ</mi> <mo>=</mo> <msup><mrow><mo>(</mo><mi>y</mi><mo>-</mo><mi>w</mi><mi>x</mi><mo>-</mo><mi>b</mi><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow></math> . Some matrix calculus can be used to compute
    the gradients of the learnable parameters directly for *w*:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>∇</mi> <mi>w</mi> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>ℒ</mi></mrow>
    <mrow><mi>∂</mi><mi>w</mi></mrow></mfrac> <mo>=</mo> <mo>-</mo> <mn>2</mn> <mrow><mo>(</mo>
    <mi>y</mi> <mo>-</mo> <mi>w</mi> <mi>x</mi> <mo>-</mo> <mi>b</mi> <mo>)</mo></mrow>
    <msup><mi>x</mi> <mi>T</mi></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: and for *b*
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><mi>∇</mi> <mi>b</mi> <mo>=</mo> <mfrac><mrow><mi>∂</mi><mi>ℒ</mi></mrow>
    <mrow><mi>∂</mi><mi>b</mi></mrow></mfrac> <mo>=</mo> <mo>-</mo> <mn>2</mn> <mrow><mo>(</mo>
    <mi>y</mi> <mo>-</mo> <mi>w</mi> <mi>x</mi> <mo>-</mo> <mi>b</mi> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: We place these equations here only for reference for curious readers. We will
    not attempt to systematically teach how to take the derivatives of the loss functions
    we encounter in this book. However, we will note that for complicated systems,
    taking the derivative of the loss function by hand helps build up an intuition
    for how the deep network learns. This intuition can serve as a powerful guide
    for the designer, so we encourage advanced readers to pursue this topic on their
    own.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing linear regression models with TensorBoard
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The model defined in the previous section uses `tf.summary.FileWriter` to write
    logs to a logging directory */tmp/lr-train*. We can invoke TensorBoard on this
    logging directory with the command in [Example 3-13](#ch3-tensorboard) (TensorBoard
    is installed by default with TensorFlow).
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-13\. Invoking TensorBoard
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This command will start TensorBoard on a port attached to localhost. Use your
    browser to open this port. The TensorBoard screen will look something like [Figure 3-8](#ch3-tensorboardscreen).
    (The precise appearance may vary depending on your version of TensorBoard.)
  prefs: []
  type: TYPE_NORMAL
- en: '![tensorboard_lr_raw.png](assets/tfdl_0308.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-8\. Screenshot of TensorBoard panel.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Navigate to the Graphs tab, and you will see a visualization of the TensorFlow
    architecture we have defined as illustrated in [Figure 3-9](#ch3-tensorboardarch).
  prefs: []
  type: TYPE_NORMAL
- en: '![lr_graph.png](assets/tfdl_0309.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-9\. Visualization of linear regression architecture in TensorBoard.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note that this visualization has grouped all computational graph elements belonging
    to various `tf.name_scopes`. Different groups are connected according to their
    dependencies in the computational graph. You can expand all of the grouped elements
    to view their contents. [Figure 3-10](#ch3-tensorboardarchexp) illustrates the
    expanded architecture.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, there are many hidden nodes that suddenly become visible! TensorFlow
    functions like `tf.train.AdamOptimizer` often hide many internal variables under
    a `tf.name_scope` of their own. Expanding in TensorBoard provides an easy way
    to peer underneath the hood to see what the system is actually creating. Although
    the visualization looks quite complex, most of these details are under the hood
    and not anything you need to worry about just yet.
  prefs: []
  type: TYPE_NORMAL
- en: '![lr_expanded.png](assets/tfdl_0310.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-10\. Expanded visualization of architecture.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Navigate back to the Home tab and open the Summaries section. You should now
    see a loss curve that looks something like [Figure 3-11](#ch3-tensorboardloss).
    Note the smooth falling shape. The loss falls rapidly at the beginning as the
    prior is learned, then tapers off and settles.
  prefs: []
  type: TYPE_NORMAL
- en: '![lr_loss_tensorboard.png](assets/tfdl_0311.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-11\. Viewing the loss curve in TensorBoard.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Visual and Nonvisual Debugging Styles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Is using a tool like TensorBoard necessary to get good use out of a system like
    TensorFlow? It depends. Is using a GUI or an interactive debugger necessary to
    be a professional programmer?
  prefs: []
  type: TYPE_NORMAL
- en: Different programmers have different styles. Some will find that the visualization
    capabilities of TensorBoard come to form a critical part of their tensorial programming
    workflows. Others will find that TensorBoard isn’t terribly useful and will make
    greater use of print-statement debugging. Both styles of tensorial programming
    and debugging are valid, just as there are great programmers who swear by debuggers
    and others who loathe them.
  prefs: []
  type: TYPE_NORMAL
- en: In general, TensorBoard is quite useful for debugging and for building basic
    intuition about the dataset at hand. We recommend that you follow the style that
    works best for you.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics for evaluating regression models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So far, we haven’t discussed how to evaluate whether a trained model has actually
    learned anything. The first tool for evaluating whether a model has trained is
    by looking at the loss curve to ensure it has a reasonable shape. You learned
    how to do this in the previous section. What’s the next thing to try?
  prefs: []
  type: TYPE_NORMAL
- en: 'We now want you to look at *metrics* associated with the model. A metric is
    a tool for comparing predicted labels to true labels. For regression problems,
    there are two common metrics: *R*² and RMSE (root-mean-squared error). The *R*²
    is a measure of the correlation between two variables that takes values between
    +1 and 0\. +1 indicates perfect correlation, while 0 indicates no correlation.
    Mathematically, the *R*² for two datasets *X* and *Y* is defined as'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><msup><mi>R</mi> <mn>2</mn></msup> <mo>=</mo> <mfrac><mrow><mtext>cov</mtext><msup><mrow><mo>(</mo><mi>X</mi><mo>,</mo><mi>Y</mi><mo>)</mo></mrow>
    <mn>2</mn></msup></mrow> <mrow><msubsup><mi>σ</mi> <mi>X</mi> <mn>2</mn></msubsup>
    <msubsup><mi>σ</mi> <mi>Y</mi> <mn>2</mn></msubsup></mrow></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Where cov(*X*, *Y*) is the covariance of *X* and *Y*, a measure of how the two
    datasets jointly vary, while <math alttext="sigma Subscript upper X"><msub><mi>σ</mi>
    <mi>X</mi></msub></math> and <math alttext="sigma Subscript upper Y"><msub><mi>σ</mi>
    <mi>Y</mi></msub></math> are standard deviations, measures of how much each set
    individually varies. Intuitively, the *R*² measures how much of the independent
    variation in each set can be explained by their joint variation.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple Types of R²!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Note that there are two common definitions of *R*² used in practice. A common
    beginner (and expert) mistake is to confuse the two definitions. In this book,
    we will always use the squared Pearson correlation coefficient ([Figure 3-12](#ch3-corr)).
    The other definition is called the coefficient of determination. This other *R*²
    is often much more confusing to deal with since it doesn’t have a lower bound
    of 0 like the squared Pearson correlation does.
  prefs: []
  type: TYPE_NORMAL
- en: In [Figure 3-12](#ch3-corr), predicted and true values are highly correlated
    with an *R*² of nearly 1\. It looks like learning has done a wonderful job on
    this system and succeeded in learning the true rule. *Not so fast*. You will note
    that the scale on the two axes in the figure isn’t the same! It turns out that
    *R*² doesn’t penalize for differences in scale. In order to understand what’s
    happened on this system, we need to consider an alternate metric in [Figure 3-13](#ch3-rms).
  prefs: []
  type: TYPE_NORMAL
- en: '![lr_pred.png](assets/tfdl_0312.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-12\. Plotting the Pearson correlation coefficient.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '![lr_learned.png](assets/tfdl_0313.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-13\. Plotting the root-mean-squared error (RMSE).
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The RMSE is a measure of the average difference between predicted values and
    true values. In [Figure 3-13](#ch3-rms) we plot predicted values and true labels
    as two separate functions using datapoints *x* as our x-axis. Note that the line
    learned isn’t the true function! The RMSE is relatively high and diagnoses the
    error, unlike the *R*², which didn’t pick up on this error.
  prefs: []
  type: TYPE_NORMAL
- en: What happened on this system? Why didn’t TensorFlow learn the correct function
    despite being trained to convergence? This example provides a good illustration
    of one of the weaknesses of gradient descent algorithms. There is no guarantee
    of finding the true solution! The gradient descent algorithm can get trapped in
    *local minima*. That is, it can find solutions that look good, but are not in
    fact the lowest minima of the loss function <math alttext="script upper L"><mi>ℒ</mi></math>
    .
  prefs: []
  type: TYPE_NORMAL
- en: Why use gradient descent at all then? For simple systems, it is indeed often
    better to avoid gradient descent and use other algorithms that have stronger performance
    guarantees. However, on complicated systems, such as those we will show you in
    later chapters, there do not yet exist alternative algorithms that perform better
    than gradient descent. We encourage you to remember this fact as we proceed further
    into deep learning.
  prefs: []
  type: TYPE_NORMAL
- en: Logistic Regression in TensorFlow
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will define a simple classifier using TensorFlow. It’s worth
    first considering what the equation is for a classifier. The mathematical trick
    that is commonly used is exploiting the sigmoid function. The sigmoid, plotted
    in [Figure 3-14](#ch3-sigmoid), commonly denoted by <math alttext="sigma"><mi>σ</mi></math>
    , is a function from the real numbers <math alttext="double-struck upper R"><mi>ℝ</mi></math>
    to (0, 1). This property is convenient since we can interpret the output of a
    sigmoid as probability of an event happening. (The trick of converting discrete
    events into continuous values is a recurring theme in machine learning.)
  prefs: []
  type: TYPE_NORMAL
- en: '![logistic.gif](assets/tfdl_0314.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-14\. Plotting the sigmoid function.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The equations for predicting the probabilities of a discrete 0/1 variable follow.
    These equations define a simple logistic regression model:'
  prefs: []
  type: TYPE_NORMAL
- en: <math display="block"><mrow><msub><mi>y</mi> <mn>0</mn></msub> <mo>=</mo> <mi>σ</mi>
    <mrow><mo>(</mo> <mi>w</mi> <mi>x</mi> <mo>+</mo> <mi>b</mi> <mo>)</mo></mrow></mrow></math><math
    display="block"><mrow><msub><mi>y</mi> <mn>1</mn></msub> <mo>=</mo> <mn>1</mn>
    <mo>-</mo> <mi>σ</mi> <mrow><mo>(</mo> <mi>w</mi> <mi>x</mi> <mo>+</mo> <mi>b</mi>
    <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: TensorFlow provides utility functions to compute the cross-entropy loss for
    sigmoidal values. The simplest of these functions is `tf.nn.sigmoid_cross_​entropy_with_logits`.
    (A logit is the inverse of the sigmoid. In practice, this simply means passing
    the argument to the sigmoid, *wx* + *b*, directly to TensorFlow instead of the
    sigmoidal value <math><mrow><mi>σ</mi> <mo>(</mo> <mi>w</mi> <mi>x</mi> <mo>+</mo>
    <mi>b</mi> <mo>)</mo></mrow></math> itself). We recommend using TensorFlow’s implementation
    instead of manually defining the cross-entropy, since there are tricky numerical
    issues that arise when computing the cross-entropy loss.
  prefs: []
  type: TYPE_NORMAL
- en: '[Example 3-14](#ch3-logistic) defines a simple logistic regression model in
    TensorFlow.'
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-14\. Defining a simple logistic regression model
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The training code for this model in [Example 3-15](#ch3-logistic-train) is identical
    to that for the linear regression model.
  prefs: []
  type: TYPE_NORMAL
- en: Example 3-15\. Training a logistic regression model
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: Visualizing logistic regression models with TensorBoard
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As before, you can use TensorBoard to visualize the model. Start by visualizing
    the loss function as shown in [Figure 3-15](#ch3-tensorboardlogistic). Note that
    as before, the loss function follows a neat pattern. There is a steep drop in
    the loss followed by a gradual smoothening.
  prefs: []
  type: TYPE_NORMAL
- en: '![logistic_loss_tensorboard.png](assets/tfdl_0315.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-15\. Visualizing the logistic regression loss function.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can also view the TensorFlow graph in TensorBoard. Since the scoping structure
    was similar to that used for linear regression, the simplified graph doesn’t display
    much differently, as shown in [Figure 3-16](#ch3-tensorboardlogisticgraph).
  prefs: []
  type: TYPE_NORMAL
- en: '![logistic_graph.png](assets/tfdl_0316.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-16\. Visualizing the computation graph for logistic regression.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: However, if you expand the nodes in this grouped graph, as in [Figure 3-17](#ch3-tensorboardlogisticgraphexp),
    you will find that the underlying computational graph is different. In particular,
    the loss function is quite different from that used for linear regression (as
    it should be).
  prefs: []
  type: TYPE_NORMAL
- en: '![logistic_expanded.png](assets/tfdl_0317.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-17\. The expanded computation graph for logistic regression.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Metrics for evaluating classification models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that you have trained a classification model for logistic regression, you
    need to learn about metrics suitable for evaluating classification models. Although
    the equations for logistic regression are more complicated than they are for linear
    regression, the basic evaluation metrics are simpler. The classification accuracy
    simply checks for the fraction of datapoints that are classified correctly by
    the learned model. In fact, with a little more effort, it is possible to back
    out the *separating line* learned by the logistic regression model. This line
    displays the cutoff boundary the model has learned to separate positive and negative
    examples. (We leave the derivation of this line from the logistic regression equations
    as an exercise for the interested reader. The solution is in the code for this
    section.)
  prefs: []
  type: TYPE_NORMAL
- en: We display the learned classes and the separating line in [Figure 3-18](#ch3-loglearnedclasses).
    Note that the line neatly separates the positive and negative examples and has
    perfect accuracy (1.0). This result raises an interesting point. Regression is
    often a harder problem to solve than classification. There are many possible lines
    that would neatly separate the datapoints in [Figure 3-18](#ch3-loglearnedclasses),
    but only one that would have perfectly matched the data for the linear regression.
  prefs: []
  type: TYPE_NORMAL
- en: '![logistic_pred.png](assets/tfdl_0318.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3-18\. Viewing the learned classes and separating line for logistic regression.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Review
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we’ve shown you how to build and train some simple learning
    systems in TensorFlow. We started by reviewing some foundational mathematical
    concepts including loss functions and gradient descent. We then introduced you
    to some new TensorFlow concepts such as placeholders, scopes, and TensorBoard.
    We ended the chapter with case studies that trained linear and logistic regression
    systems on toy datasets. We covered a lot of material in this chapter, and it’s
    OK if you haven’t yet internalized everything. The foundational material introduced
    here will be used throughout the remainder of this book.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 4](ch04.html#fully_connected_networks), we will introduce you to
    your first deep learning model and to fully connected networks, and will show
    you how to define and train fully connected networks in TensorFlow. In following
    chapters, we will explore more complicated deep networks, but all of these architectures
    will use the same fundamental learning principles introduced in this chapter.
  prefs: []
  type: TYPE_NORMAL
