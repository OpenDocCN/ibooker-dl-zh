- en: Chapter 6\. Other Computer Vision Problems
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第6章。其他计算机视觉问题
- en: In the previous chapter, you learned some important practical techniques for
    training models in practice. Considerations like selecting learning rates and
    the number of epochs are very important to getting good results.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你学习了一些在实践中训练模型的重要技术。选择学习率和周期数等考虑因素对于获得良好结果非常重要。
- en: 'In this chapter, we are going to look at two other types of computer vision
    problems: multi-label classification and regression. The first one occurs when
    you want to predict more than one label per image (or sometimes none at all),
    and the second occurs when your labels are one or several numbers—a quantity instead
    of a category.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将看到另外两种计算机视觉问题：多标签分类和回归。第一种情况发生在你想要预测每个图像的多个标签（有时甚至没有标签），第二种情况发生在你的标签是一个或多个数字——数量而不是类别。
- en: In the process, we will study more deeply the output activations, targets, and
    loss functions in deep learning models.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个过程中，我们将更深入地研究深度学习模型中的输出激活、目标和损失函数。
- en: Multi-Label Classification
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多标签分类
- en: '*Multi-label classification* refers to the problem of identifying the categories
    of objects in images that may not contain exactly one type of object. There may
    be more than one kind of object, or there may be no objects at all in the classes
    you are looking for.'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: '*多标签分类*指的是识别图像中可能不只包含一种对象类别的问题。可能有多种对象，或者在你寻找的类别中根本没有对象。'
- en: For instance, this would have been a great approach for our bear classifier.
    One problem with the bear classifier that we rolled out in [Chapter 2](ch02.xhtml#chapter_production)
    was that if a user uploaded something that wasn’t any kind of bear, the model
    would still say it was either a grizzly, black, or teddy bear—it had no ability
    to predict “not a bear at all.” In fact, after we have completed this chapter,
    it would be a great exercise for you to go back to your image classifier application
    and try to retrain it using the multi-label technique, and then test it by passing
    in an image that is not of any of your recognized classes.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，这对我们的熊分类器来说是一个很好的方法。我们在[第2章](ch02.xhtml#chapter_production)中推出的熊分类器的一个问题是，如果用户上传了任何不是熊的东西，模型仍然会说它是灰熊、黑熊或泰迪熊之一——它无法预测“根本不是熊”。事实上，在我们完成本章后，你可以回到你的图像分类器应用程序，尝试使用多标签技术重新训练它，然后通过传入一个不属于你识别类别的图像来测试它。
- en: In practice, we have not seen many examples of people training multi-label classifiers
    for this purpose—but we often see both users and developers complaining about
    this problem. It appears that this simple solution is not at all widely understood
    or appreciated! Because in practice it is probably more common to have some images
    with zero matches or more than one match, we should probably expect in practice
    that multi-label classifiers are more widely applicable than single-label classifiers.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们并没有看到很多人为这个目的训练多标签分类器的例子——但我们经常看到用户和开发人员抱怨这个问题。看起来这个简单的解决方案并不被广泛理解或赞赏！因为在实践中，很可能有一些图像没有匹配项或有多个匹配项，所以我们应该预期在实践中，多标签分类器比单标签分类器更具普适性。
- en: First let’s see what a multi-label dataset looks like; then we’ll explain how
    to get it ready for our model. You’ll see that the architecture of the model does
    not change from the preceding chapter; only the loss function does. Let’s start
    with the data.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 首先让我们看看多标签数据集是什么样的；然后我们将解释如何准备好供我们的模型使用。你会发现模型的架构与前一章并没有改变；只有损失函数改变了。让我们从数据开始。
- en: The Data
  id: totrans-9
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据
- en: For our example, we are going to use the PASCAL dataset, which can have more
    than one kind of classified object per image.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的示例，我们将使用PASCAL数据集，该数据集中的每个图像可以有多种分类对象。
- en: 'We begin by downloading and extracting the dataset as per usual:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先按照通常的方式下载和提取数据集：
- en: '[PRE0]'
  id: totrans-12
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This dataset is different from the ones we have seen before, in that it is
    not structured by filename or folder but instead comes with a CSV file telling
    us what labels to use for each image. We can inspect the CSV file by reading it
    into a Pandas DataFrame:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集与我们之前看到的不同，它不是按文件名或文件夹结构化的，而是附带一个CSV文件，告诉我们每个图像要使用的标签。我们可以通过将其读入Pandas
    DataFrame来检查CSV文件：
- en: '[PRE1]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '|  | fname | labels | is_valid |'
  id: totrans-15
  prefs: []
  type: TYPE_TB
  zh: '|  | 文件名 | 标签 | 是否有效 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-16
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | 000005.jpg | chair | True |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 000005.jpg | 椅子 | True |'
- en: '| 1 | 000007.jpg | car | True |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 000007.jpg | 汽车 | True |'
- en: '| 2 | 000009.jpg | horse person | True |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 000009.jpg | 马 人 | True |'
- en: '| 3 | 000012.jpg | car | False |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 000012.jpg | 汽车 | False |'
- en: '| 4 | 000016.jpg | bicycle | True |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 000016.jpg | 自行车 | True |'
- en: As you can see, the list of categories in each image is shown as a space-delimited
    string.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，每个图像中的类别列表显示为一个以空格分隔的字符串。
- en: Now that we have seen what the data looks like, let’s make it ready for model
    training.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经看到了数据的样子，让我们准备好进行模型训练。
- en: Constructing a DataBlock
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建数据块
- en: How do we convert from a `DataFrame` object to a `DataLoaders` object? We generally
    suggest using the data block API for creating a `DataLoaders` object, where possible,
    since it provides a good mix of flexibility and simplicity. Here we will show
    you the steps that we take to use the data block API to construct a `DataLoaders`
    object in practice, using this dataset as an example.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何将`DataFrame`对象转换为`DataLoaders`对象？我们通常建议在可能的情况下使用数据块API来创建`DataLoaders`对象，因为它提供了灵活性和简单性的良好组合。在这里，我们将展示使用数据块API构建`DataLoaders`对象的实践步骤，以这个数据集为例。
- en: 'As we have seen, PyTorch and fastai have two main classes for representing
    and accessing a training set or validation set:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，PyTorch和fastai有两个主要类用于表示和访问训练集或验证集：
- en: '`Dataset`'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '`数据集`'
- en: A collection that returns a tuple of your independent and dependent variable
    for a single item
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 返回单个项目的独立变量和依赖变量的元组的集合
- en: '`DataLoader`'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '`数据加载器`'
- en: An iterator that provides a stream of mini-batches, where each mini-batch is
    a couple of a batch of independent variables and a batch of dependent variables
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 提供一系列小批量的迭代器，其中每个小批量是一批独立变量和一批因变量的组合
- en: 'On top of these, fastai provides two classes for bringing your training and
    validation sets together:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，fastai还提供了两个类来将您的训练和验证集合在一起：
- en: '`Datasets`'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '`Datasets`'
- en: An iterator that contains a training `Dataset` and a validation `Dataset`
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 包含一个训练`Dataset`和一个验证`Dataset`的迭代器
- en: '`DataLoaders`'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`DataLoaders`'
- en: An object that contains a training `DataLoader` and a validation `DataLoader`
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 包含一个训练`DataLoader`和一个验证`DataLoader`的对象
- en: Since a `DataLoader` builds on top of a `Dataset` and adds additional functionality
    to it (collating multiple items into a mini-batch), it’s often easiest to start
    by creating and testing `Datasets`, and then look at `DataLoaders` after that’s
    working.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 由于`DataLoader`是建立在`Dataset`之上并为其添加附加功能（将多个项目整合成一个小批量），通常最容易的方法是首先创建和测试`Datasets`，然后再查看`DataLoaders`。
- en: When we create a `DataBlock`, we build up gradually, step by step, and use the
    notebook to check our data along the way. This is a great way to make sure that
    you maintain momentum as you are coding, and that you keep an eye out for any
    problems. It’s easy to debug, because you know that if a problem arises, it is
    in the line of code you just typed!
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们创建`DataBlock`时，我们逐步逐步构建，并使用笔记本检查我们的数据。这是一个很好的方式，可以确保您在编码时保持动力，并留意任何问题。易于调试，因为您知道如果出现问题，它就在您刚刚输入的代码行中！
- en: 'Let’s start with the simplest case, which is a data block created with no parameters:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从没有参数创建的数据块开始，这是最简单的情况：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We can create a `Datasets` object from this. The only thing needed is a source—in
    this case, our DataFrame:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以从中创建一个`Datasets`对象。唯一需要的是一个源——在这种情况下是我们的DataFrame：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This contains a `train` and a `valid` dataset, which we can index into:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这包含一个`train`和一个`valid`数据集，我们可以对其进行索引：
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As you can see, this simply returns a row of the DataFrame, twice. This is
    because by default, the data block assumes we have two things: input and target.
    We are going to need to grab the appropriate fields from the DataFrame, which
    we can do by passing `get_x` and `get_y` functions:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，这只是简单地两次返回DataFrame的一行。这是因为默认情况下，数据块假定我们有两个东西：输入和目标。我们需要从DataFrame中获取适当的字段，可以通过传递`get_x`和`get_y`函数来实现：
- en: '[PRE6]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'As you can see, rather than defining a function in the usual way, we are using
    Python’s `lambda` keyword. This is just a shortcut for defining and then referring
    to a function. The following more verbose approach is identical:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，我们并没有以通常的方式定义函数，而是使用了Python的`lambda`关键字。这只是定义并引用函数的一种快捷方式。以下更冗长的方法是相同的：
- en: '[PRE8]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Lambda functions are great for quickly iterating, but they are not compatible
    with serialization, so we advise you to use the more verbose approach if you want
    to export your `Learner` after training (lambdas are fine if you are just experimenting).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Lambda函数非常适合快速迭代，但不兼容序列化，因此我们建议您在训练后要导出您的`Learner`时使用更冗长的方法（如果您只是在尝试实验，lambda是可以的）。
- en: 'We can see that the independent variable will need to be converted into a complete
    path so that we can open it as an image, and the dependent variable will need
    to be split on the space character (which is the default for Python’s `split`
    function) so that it becomes a list:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到独立变量需要转换为完整路径，以便我们可以将其作为图像打开，而因变量需要根据空格字符（这是Python的`split`函数的默认值）进行拆分，以便它变成一个列表：
- en: '[PRE10]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'To actually open the image and do the conversion to tensors, we will need to
    use a set of transforms; block types will provide us with those. We can use the
    same block types that we have used previously, with one exception: the `ImageBlock`
    will work fine again, because we have a path that points to a valid image, but
    the `CategoryBlock` is not going to work. The problem is that block returns a
    single integer, but we need to be able to have multiple labels for each item.
    To solve this, we use a `MultiCategoryBlock`. This type of block expects to receive
    a list of strings, as we have in this case, so let’s test it out:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 要实际打开图像并将其转换为张量，我们需要使用一组转换；块类型将为我们提供这些。我们可以使用先前使用过的相同块类型，只有一个例外：`ImageBlock`将再次正常工作，因为我们有一个指向有效图像的路径，但`CategoryBlock`不会起作用。问题在于该块返回一个单个整数，但我们需要为每个项目有多个标签。为了解决这个问题，我们使用`MultiCategoryBlock`。这种类型的块期望接收一个字符串列表，就像我们在这种情况下所做的那样，所以让我们来测试一下：
- en: '[PRE12]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: As you can see, our list of categories is not encoded in the same way that it
    was for the regular `CategoryBlock`. In that case, we had a single integer representing
    which category was present, based on its location in our vocab. In this case,
    however, we instead have a list of 0s, with a 1 in any position where that category
    is present. For example, if there is a 1 in the second and fourth positions, that
    means vocab items two and four are present in this image. This is known as *one-hot
    encoding*. The reason we can’t easily just use a list of category indices is that
    each list would be a different length, and PyTorch requires tensors, where everything
    has to be the same length.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，我们的类别列表的编码方式与常规的`CategoryBlock`不同。在那种情况下，我们有一个整数表示哪个类别存在，基于它在我们的词汇表中的位置。然而，在这种情况下，我们有一系列0，其中任何位置上有一个1表示该类别存在。例如，如果第二和第四位置上有一个1，那意味着词汇项二和四在这个图像中存在。这被称为*独热编码*。我们不能简单地使用类别索引列表的原因是每个列表的长度都不同，而PyTorch需要张量，其中所有内容必须是相同长度。
- en: 'Jargon: One-Hot Encoding'
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 行话：独热编码
- en: Using a vector of 0s, with a 1 in each location that is represented in the data,
    to encode a list of integers.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 使用一个0向量，其中每个位置都表示数据中表示的位置，以编码一个整数列表。
- en: 'Let’s check what the categories represent for this example (we are using the
    convenient `torch.where` function, which tells us all of the indices where our
    condition is true or false):'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看这个例子中类别代表什么（我们使用方便的`torch.where`函数，告诉我们条件为真或假的所有索引）：
- en: '[PRE14]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: With NumPy arrays, PyTorch tensors, and fastai’s `L` class, we can index directly
    using a list or vector, which makes a lot of code (such as this example) much
    clearer and more concise.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 使用NumPy数组、PyTorch张量和fastai的`L`类，我们可以直接使用列表或向量进行索引，这使得很多代码（比如这个例子）更清晰、更简洁。
- en: 'We have ignored the column `is_valid` up until now, which means that `DataBlock`
    has been using a random split by default. To explicitly choose the elements of
    our validation set, we need to write a function and pass it to `splitter` (or
    use one of fastai’s predefined functions or classes). It will take the items (here
    our whole DataFrame) and must return two (or more) lists of integers:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们忽略了列`is_valid`，这意味着`DataBlock`一直在使用默认的随机拆分。要明确选择我们验证集的元素，我们需要编写一个函数并将其传递给`splitter`（或使用fastai的预定义函数或类之一）。它将获取项目（这里是我们整个DataFrame）并必须返回两个（或更多）整数列表：
- en: '[PRE16]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: As we have discussed, a `DataLoader` collates the items from a `Dataset` into
    a mini-batch. This is a tuple of tensors, where each tensor simply stacks the
    items from that location in the `Dataset` item.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们讨论过的，`DataLoader`将`Dataset`中的项目整理成一个小批量。这是一个张量的元组，其中每个张量简单地堆叠了`Dataset`项目中该位置的项目。
- en: 'Now that we have confirmed that the individual items look OK, there’s one more
    step, we need to ensure we can create our `DataLoaders`, which is to ensure that
    every item is of the same size. To do this, we can use `RandomResizedCrop`:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经确认了单个项目看起来没问题，还有一步，我们需要确保我们可以创建我们的`DataLoaders`，即确保每个项目的大小相同。为了做到这一点，我们可以使用`RandomResizedCrop`：
- en: '[PRE18]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'And now we can display a sample of our data:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以显示我们数据的一个样本：
- en: '[PRE19]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '![](Images/dlcf_06in01.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_06in01.png)'
- en: Remember that if anything goes wrong when you create your `DataLoaders` from
    your `DataBlock`, or if you want to view exactly what happens with your `DataBlock`,
    you can use the `summary` method we presented in the previous chapter.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，如果在从`DataBlock`创建`DataLoaders`时出现任何问题，或者如果您想查看`DataBlock`的确切情况，您可以使用我们在上一章中介绍的`summary`方法。
- en: 'Our data is now ready for training a model. As we will see, nothing is going
    to change when we create our `Learner`, but behind the scenes the fastai library
    will pick a new loss function for us: binary cross entropy.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的数据现在已经准备好用于训练模型。正如我们将看到的，当我们创建我们的`Learner`时，没有任何变化，但在幕后，fastai库将为我们选择一个新的损失函数：二元交叉熵。
- en: Binary Cross Entropy
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 二元交叉熵
- en: 'Now we’ll create our `Learner`. We saw in [Chapter 4](ch04.xhtml#chapter_mnist_basics)
    that a `Learner` object contains four main things: the model, a `DataLoaders`
    object, an `Optimizer`, and the loss function to use. We already have our `DataLoaders`,
    we can leverage fastai’s `resnet` models (which we’ll learn how to create from
    scratch later), and we know how to create an `SGD` optimizer. So let’s focus on
    ensuring we have a suitable loss function. To do this, let’s use `cnn_learner`
    to create a `Learner`, so we can look at its activations:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将创建我们的`Learner`。我们在[第4章](ch04.xhtml#chapter_mnist_basics)中看到，`Learner`对象包含四个主要内容：模型、`DataLoaders`对象、优化器和要使用的损失函数。我们已经有了我们的`DataLoaders`，我们可以利用fastai的`resnet`模型（稍后我们将学习如何从头开始创建），并且我们知道如何创建一个`SGD`优化器。因此，让我们专注于确保我们有一个合适的损失函数。为此，让我们使用`cnn_learner`创建一个`Learner`，这样我们就可以查看它的激活：
- en: '[PRE20]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We also saw that the model in a `Learner` is generally an object of a class
    inheriting from `nn.Module`, and that we can call it using parentheses and it
    will return the activations of a model. You should pass it your independent variable,
    as a mini-batch. We can try it out by grabbing a mini-batch from our `DataLoader`
    and then passing it to the model:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还看到，`Learner`中的模型通常是从`nn.Module`继承的类的对象，并且我们可以使用括号调用它，它将返回模型的激活。你应该将独立变量作为一个小批量传递给它。我们可以尝试从我们的`DataLoader`中获取一个小批量，然后将其传递给模型：
- en: '[PRE21]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Think about why `activs` has this shape—we have a batch size of 64, and we
    need to calculate the probability of each of 20 categories. Here’s what one of
    those activations looks like:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 想想为什么`activs`有这种形状——我们的批量大小为64，我们需要计算20个类别中的每一个的概率。这是其中一个激活的样子：
- en: '[PRE23]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Getting Model Activations
  id: totrans-85
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 获取模型激活
- en: Knowing how to manually get a mini-batch and pass it into a model, and look
    at the activations and loss, is really important for debugging your model. It
    is also very helpful for learning, so that you can see exactly what is going on.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 知道如何手动获取一个小批量并将其传递到模型中，并查看激活和损失，对于调试模型非常重要。这对学习也非常有帮助，这样你就可以清楚地看到发生了什么。
- en: 'They aren’t yet scaled to between 0 and 1, but we learned how to do that in
    [Chapter 4](ch04.xhtml#chapter_mnist_basics), using the `sigmoid` function. We
    also saw how to calculate a loss based on this—this is our loss function from
    [Chapter 4](ch04.xhtml#chapter_mnist_basics), with the addition of `log` as discussed
    in the preceding chapter:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 它们还没有缩放到0到1之间，但我们学会了如何在[第4章](ch04.xhtml#chapter_mnist_basics)中使用`sigmoid`函数来做到这一点。我们还看到了如何基于此计算损失——这是我们在[第4章](ch04.xhtml#chapter_mnist_basics)中的损失函数，加上了在前一章中讨论的`log`：
- en: '[PRE25]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Note that because we have a one-hot-encoded dependent variable, we can’t directly
    use `nll_loss` or `softmax` (and therefore we can’t use `cross_entropy`):'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，由于我们有一个独热编码的因变量，我们不能直接使用`nll_loss`或`softmax`（因此我们不能使用`cross_entropy`）：
- en: '`softmax`, as we saw, requires that all predictions sum to 1, and tends to
    push one activation to be much larger than the others (because of the use of `exp`);
    however, we may well have multiple objects that we’re confident appear in an image,
    so restricting the maximum sum of activations to 1 is not a good idea. By the
    same reasoning, we may want the sum to be *less* than 1, if we don’t think *any*
    of the categories appear in an image.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正如我们所看到的，`softmax`要求所有预测总和为1，并且倾向于使一个激活远远大于其他激活（因为使用了`exp`）；然而，我们可能有多个我们确信出现在图像中的对象，因此限制激活的最大总和为1并不是一个好主意。出于同样的原因，如果我们认为*任何*类别都不出现在图像中，我们可能希望总和*小于*1。
- en: '`nll_loss`, as we saw, returns the value of just one activation: the single
    activation corresponding with the single label for an item. This doesn’t make
    sense when we have multiple labels.'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正如我们所看到的，`nll_loss`返回的是一个激活值：与项目的单个标签对应的单个激活值。当我们有多个标签时，这是没有意义的。
- en: On the other hand, the `binary_cross_entropy` function, which is just `mnist_loss`
    along with `log`, provides just what we need, thanks to the magic of PyTorch’s
    elementwise operations. Each activation will be compared to each target for each
    column, so we don’t have to do anything to make this function work for multiple
    columns.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，`binary_cross_entropy`函数，即`mnist_loss`加上`log`，正是我们所需要的，这要归功于PyTorch的逐元素操作的魔力。每个激活将与每个列的每个目标进行比较，因此我们不必做任何事情使此函数适用于多个列。
- en: Jeremy Says
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Jeremy Says
- en: One of the things I really like about working with libraries like PyTorch, with
    broadcasting and elementwise operations, is that quite frequently I find I can
    write code that works equally well for a single item or a batch of items, without
    changes. `binary_cross_entropy` is a great example of this. By using these operations,
    we don’t have to write loops ourselves, and can rely on PyTorch to do the looping
    we need as appropriate for the rank of the tensors we’re working with.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我真的很喜欢使用像PyTorch这样的库，具有广播和逐元素操作，因为我经常发现我可以编写的代码同样适用于单个项目或一批项目，而无需更改。`binary_cross_entropy`就是一个很好的例子。通过使用这些操作，我们不必自己编写循环，可以依赖PyTorch根据我们正在处理的张量的秩适当地执行我们需要的循环。
- en: PyTorch already provides this function for us. In fact, it provides a number
    of versions, with rather confusing names!
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch已经为我们提供了这个函数。实际上，它提供了许多版本，名称相当令人困惑！
- en: '`F.binary_cross_entropy` and its module equivalent `nn.BCELoss` calculate cross
    entropy on a one-hot-encoded target, but do not include the initial `sigmoid`.
    Normally, for one-hot-encoded targets you’ll want `F.binary_cross_entropy_with_logits`
    (or `nn.BCEWithLogitsLoss`), which do both sigmoid and binary cross entropy in
    a single function, as in the preceding example.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`F.binary_cross_entropy`及其模块等效`nn.BCELoss`计算一个独热编码目标的交叉熵，但不包括初始的`sigmoid`。通常，对于独热编码目标，您将希望使用`F.binary_cross_entropy_with_logits`（或`nn.BCEWithLogitsLoss`），它们在一个函数中同时执行sigmoid和二元交叉熵，就像前面的例子一样。'
- en: The equivalent for single-label datasets (like MNIST or the Pet dataset), where
    the target is encoded as a single integer, is `F.nll_loss` or `nn.NLLLoss` for
    the version without the initial softmax, and `F.cross_entropy` or `nn.CrossEntropyLoss`
    for the version with the initial softmax.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 对于单标签数据集（如MNIST或Pet数据集），其中目标被编码为单个整数，相应的是`F.nll_loss`或`nn.NLLLoss`（没有初始softmax的版本），以及`F.cross_entropy`或`nn.CrossEntropyLoss`（具有初始softmax的版本）。
- en: 'Since we have a one-hot-encoded target, we will use `BCEWithLogitsLoss`:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们有一个独热编码的目标，我们将使用`BCEWithLogitsLoss`：
- en: '[PRE26]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: We don’t need to tell fastai to use this loss function (although we can if we
    want) since it will be automatically chosen for us. fastai knows that the `DataLoaders`
    has multiple category labels, so it will use `nn.BCEWithLogitsLoss` by default.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要告诉fastai使用这个损失函数（尽管如果我们想要的话可以这样做），因为它将自动为我们选择。fastai知道`DataLoaders`具有多个类别标签，因此默认情况下将使用`nn.BCEWithLogitsLoss`。
- en: 'One change compared to the preceding chapter is the metric we use: because
    this is a multilabel problem, we can’t use the accuracy function. Why is that?
    Well, accuracy was comparing our outputs to our targets like so:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 与前一章相比的一个变化是我们使用的指标：因为这是一个多标签问题，我们不能使用准确度函数。为什么呢？嗯，准确度是这样比较我们的输出和我们的目标的：
- en: '[PRE28]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The class predicted was the one with the highest activation (this is what `argmax`
    does). Here it doesn’t work because we could have more than one prediction on
    a single image. After applying the sigmoid to our activations (to make them between
    0 and 1), we need to decide which ones are 0s and which ones are 1s by picking
    a *threshold*. Each value above the threshold will be considered as a 1, and each
    value lower than the threshold will be considered a 0:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 预测的类是具有最高激活的类（这就是`argmax`的作用）。这里不起作用，因为我们可能在单个图像上有多个预测。在对我们的激活应用sigmoid（使它们在0和1之间）之后，我们需要通过选择*阈值*来决定哪些是0，哪些是1。高于阈值的每个值将被视为1，低于阈值的每个值将被视为0：
- en: '[PRE29]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'If we pass `accuracy_multi` directly as a metric, it will use the default value
    for `threshold`, which is 0.5\. We might want to adjust that default and create
    a new version of `accuracy_multi` that has a different default. To help with this,
    there is a function in Python called `partial`. It allows us to *bind* a function
    with some arguments or keyword arguments, making a new version of that function
    that, whenever it is called, always includes those arguments. For instance, here
    is a simple function taking two arguments:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们直接将`accuracy_multi`作为指标传递，它将使用`threshold`的默认值，即0.5。我们可能希望调整该默认值并创建一个具有不同默认值的新版本的`accuracy_multi`。为了帮助解决这个问题，Python中有一个名为`partial`的函数。它允许我们*绑定*一个带有一些参数或关键字参数的函数，从而创建该函数的新版本，每当调用它时，总是包含这些参数。例如，这里是一个接受两个参数的简单函数：
- en: '[PRE30]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'We can switch to a French version of that function by using `partial`:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过使用`partial`切换到该函数的法语版本：
- en: '[PRE32]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We can now train our model. Let’s try setting the accuracy threshold to 0.2
    for our metric:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以训练我们的模型。让我们尝试将准确度阈值设置为0.2作为我们的指标：
- en: '[PRE34]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '| epoch | train_loss | valid_loss | accuracy_multi | time |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| epoch | train_loss | valid_loss | accuracy_multi | time |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 0.903610 | 0.659728 | 0.263068 | 00:07 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0.903610 | 0.659728 | 0.263068 | 00:07 |'
- en: '| 1 | 0.724266 | 0.346332 | 0.525458 | 00:07 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.724266 | 0.346332 | 0.525458 | 00:07 |'
- en: '| 2 | 0.415597 | 0.125662 | 0.937590 | 00:07 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.415597 | 0.125662 | 0.937590 | 00:07 |'
- en: '| 3 | 0.254987 | 0.116880 | 0.945418 | 00:07 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0.254987 | 0.116880 | 0.945418 | 00:07 |'
- en: '| epoch | train_loss | valid_loss | accuracy_multi | time |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| epoch | train_loss | valid_loss | accuracy_multi | time |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 0.123872 | 0.132634 | 0.940179 | 00:08 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0.123872 | 0.132634 | 0.940179 | 00:08 |'
- en: '| 1 | 0.112387 | 0.113758 | 0.949343 | 00:08 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.112387 | 0.113758 | 0.949343 | 00:08 |'
- en: '| 2 | 0.092151 | 0.104368 | 0.951195 | 00:08 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.092151 | 0.104368 | 0.951195 | 00:08 |'
- en: 'Picking a threshold is important. If you pick a threshold that’s too low, you’ll
    often be failing to select correctly labeled objects. We can see this by changing
    our metric and then calling `validate`, which returns the validation loss and
    metrics:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 选择阈值很重要。如果选择的阈值太低，通常会选择错误标记的对象。我们可以通过改变我们的度量标准然后调用`validate`来看到这一点，它会返回验证损失和度量标准：
- en: '[PRE35]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'If you pick a threshold that’s too high, you’ll be selecting only the objects
    about which the model is very confident:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 如果选择的阈值太高，将只选择模型非常有信心的对象：
- en: '[PRE37]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We can find the best threshold by trying a few levels and seeing what works
    best. This is much faster if we grab the predictions just once:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过尝试几个级别并查看哪个效果最好来找到最佳阈值。如果我们只抓取一次预测，这将快得多：
- en: '[PRE39]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Then we can call the metric directly. Note that by default `get_preds` applies
    the output activation function (sigmoid, in this case) for us, so we’ll need to
    tell `accuracy_multi` to not apply it:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以直接调用度量标准。请注意，默认情况下，`get_preds`会为我们应用输出激活函数（在本例中为sigmoid），因此我们需要告诉`accuracy_multi`不要应用它：
- en: '[PRE40]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We can now use this approach to find the best threshold level:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以使用这种方法找到最佳阈值水平：
- en: '[PRE42]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '![](Images/dlcf_06in02.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_06in02.png)'
- en: In this case, we’re using the validation set to pick a hyperparameter (the threshold),
    which is the purpose of the validation set. Sometimes students have expressed
    their concern that we might be *overfitting* to the validation set, since we’re
    trying lots of values to see which is the best. However, as you see in the plot,
    changing the threshold in this case results in a smooth curve, so we’re clearly
    not picking an inappropriate outlier. This is a good example of where you have
    to be careful of the difference between theory (don’t try lots of hyperparameter
    values or you might overfit the validation set) versus practice (if the relationship
    is smooth, it’s fine to do this).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们使用验证集来选择一个超参数（阈值），这就是验证集的目的。有时学生们表达了他们的担忧，即我们可能会对验证集*过拟合*，因为我们正在尝试很多值来找出哪个是最好的。然而，正如你在图中看到的，改变阈值在这种情况下会产生一个平滑的曲线，因此我们显然没有选择不合适的异常值。这是一个很好的例子，说明你必须小心理论（不要尝试很多超参数值，否则可能会过拟合验证集）与实践（如果关系是平滑的，这样做是可以的）之间的区别。
- en: This concludes the part of this chapter dedicated to multi-label classification.
    Next, we’ll take a look at a regression problem.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这结束了本章专门讨论多标签分类的部分。接下来，我们将看一下回归问题。
- en: Regression
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 回归
- en: It’s easy to think of deep learning models as being classified into domains,
    like *computer vision*, *NLP*, and so forth. And indeed, that’s how fastai classifies
    its applications—largely because that’s how most people are used to thinking of
    things.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 很容易将深度学习模型视为被分类到领域中，如*计算机视觉*、*NLP*等等。事实上，这就是fastai对其应用程序进行分类的方式——主要是因为大多数人习惯于这样思考事物。
- en: But really, that’s hiding a more interesting and deeper perspective. A model
    is defined by its independent and dependent variables, along with its loss function.
    That means that there’s really a far wider array of models than just the simple
    domain-based split. Perhaps we have an independent variable that’s an image, and
    a dependent that’s text (e.g., generating a caption from an image); or perhaps
    we have an independent variable that’s text and a dependent that’s an image (e.g., generating
    an image from a caption—which is actually possible for deep learning to do!);
    or perhaps we’ve got images, texts, and tabular data as independent variables,
    and we’re trying to predict product purchases…the possibilities really are endless.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 但实际上，这隐藏了一个更有趣和更深入的视角。一个模型由其独立和依赖变量以及其损失函数定义。这意味着实际上有比简单的基于领域的分割更广泛的模型数组。也许我们有一个独立变量是图像，一个依赖变量是文本（例如，从图像生成标题）；或者我们有一个独立变量是文本，一个依赖变量是图像（例如，从标题生成图像——这实际上是深度学习可以做到的！）；或者我们有图像、文本和表格数据作为独立变量，我们试图预测产品购买……可能性真的是无穷无尽的。
- en: To be able to move beyond fixed applications to crafting your own novel solutions
    to novel problems, it helps to really understand the data block API (and maybe
    also the mid-tier API, which we’ll see later in the book). As an example, let’s
    consider the problem of *image regression*. This refers to learning from a dataset
    in which the independent variable is an image, and the dependent variable is one
    or more floats. Often we see people treat image regression as a whole separate
    application—but as you’ll see here, we can treat it as just another CNN on top
    of the data block API.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 要能够超越固定应用程序，为新问题制定自己的新颖解决方案，真正理解数据块API（也许还有我们将在本书后面看到的中间层API）是有帮助的。举个例子，让我们考虑*图像回归*的问题。这指的是从一个独立变量是图像，依赖变量是一个或多个浮点数的数据集中学习。通常我们看到人们将图像回归视为一个完全独立的应用程序——但正如你在这里看到的，我们可以将其视为数据块API上的另一个CNN。
- en: 'We’re going to jump straight to a somewhat tricky variant of image regression,
    because we know you’re ready for it! We’re going to do a key point model. A *key
    point* refers to a specific location represented in an image—in this case, we’ll
    use images of people and we’ll be looking for the center of the person’s face
    in each image. That means we’ll actually be predicting *two* values for each image:
    the row and column of the face center.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将直接跳到图像回归的一个有点棘手的变体，因为我们知道你已经准备好了！我们将做一个关键点模型。*关键点*指的是图像中表示的特定位置——在这种情况下，我们将使用人物的图像，并且我们将寻找每个图像中人脸的中心。这意味着我们实际上将为每个图像预测*两个*值：人脸中心的行和列。
- en: Assembling the Data
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据组装
- en: 'We will use the [Biwi Kinect Head Pose dataset](https://oreil.ly/-4cO-) for
    this section. We’ll begin by downloading the dataset as usual:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这一部分使用[Biwi Kinect Head Pose数据集](https://oreil.ly/-4cO-)。我们将像往常一样开始下载数据集：
- en: '[PRE43]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Let’s see what we’ve got!
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们有什么！
- en: '[PRE44]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[PRE45]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'There are 24 directories numbered from 01 to 24 (they correspond to the different
    people photographed), and a corresponding *.obj* file for each (we won’t need
    them here). Let’s take a look inside one of these directories:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 有24个从01到24编号的目录（它们对应不同的被摄人物），以及每个目录对应的*.obj*文件（我们这里不需要）。让我们看看其中一个目录的内容：
- en: '[PRE46]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '[PRE47]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Inside the subdirectories, we have different frames. Each of them comes with
    an image (*_rgb.jpg*) and a pose file (*_pose.txt*). We can easily get all the
    image files recursively with `get_image_files`, and then write a function that
    converts an image filename to its associated pose file:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 在子目录中，我们有不同的帧。每个帧都带有一个图像（*_rgb.jpg*）和一个姿势文件（*_pose.txt*）。我们可以使用`get_image_files`轻松递归获取所有图像文件，然后编写一个函数，将图像文件名转换为其关联的姿势文件：
- en: '[PRE48]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[PRE49]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Let’s take a look at our first image:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看我们的第一张图片：
- en: '[PRE50]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[PRE51]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '![](Images/dlcf_06in03.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_06in03.png)'
- en: 'The [Biwi dataset website](https://oreil.ly/wHL28) used to explain the format
    of the pose text file associated with each image, which shows the location of
    the center of the head. The details of this aren’t important for our purposes,
    so we’ll just show the function we use to extract the head center point:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '[Biwi数据集网站](https://oreil.ly/wHL28)用于解释与每个图像关联的姿势文本文件的格式，显示头部中心的位置。这些细节对我们来说并不重要，所以我们只会展示我们用来提取头部中心点的函数：'
- en: '[PRE53]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'This function returns the coordinates as a tensor of two items:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 这个函数将坐标作为两个项目的张量返回：
- en: '[PRE54]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[PRE55]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: We can pass this function to `DataBlock` as `get_y`, since it is responsible
    for labeling each item. We’ll resize the images to half their input size, to speed
    up training a bit.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将此函数传递给`DataBlock`作为`get_y`，因为它负责为每个项目标记。我们将将图像调整为其输入大小的一半，以加快训练速度。
- en: One important point to note is that we should not just use a random splitter.
    The same people appear in multiple images in this dataset, but we want to ensure
    that our model can generalize to people that it hasn’t seen yet. Each folder in
    the dataset contains the images for one person. Therefore, we can create a splitter
    function that returns `True` for just one person, resulting in a validation set
    containing just that person’s images.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的要点是我们不应该只使用随机分割器。在这个数据集中，同一个人出现在多个图像中，但我们希望确保我们的模型可以泛化到它尚未见过的人。数据集中的每个文件夹包含一个人的图像。因此，我们可以创建一个分割器函数，仅为一个人返回`True`，从而使验证集仅包含该人的图像。
- en: 'The only other difference from the previous data block examples is that the
    second block is a `PointBlock`. This is necessary so that fastai knows that the
    labels represent coordinates; that way, it knows that when doing data augmentation,
    it should do the same augmentation to these coordinates as it does to the images:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 与以前的数据块示例的唯一区别是第二个块是`PointBlock`。这是必要的，以便fastai知道标签代表坐标；这样，它就知道在进行数据增强时，应该对这些坐标执行与图像相同的增强：
- en: '[PRE56]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Points and Data Augmentation
  id: totrans-172
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 点和数据增强
- en: We’re not aware of other libraries (except for fastai) that automatically and
    correctly apply data augmentation to coordinates. So, if you’re working with another
    library, you may need to disable data augmentation for these kinds of problems.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不知道其他库（除了fastai）会自动且正确地将数据增强应用于坐标。因此，如果您使用另一个库，可能需要禁用这些问题的数据增强。
- en: 'Before doing any modeling, we should look at our data to confirm it seems OK:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行任何建模之前，我们应该查看我们的数据以确认它看起来没问题：
- en: '[PRE57]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: '![](Images/dlcf_06in04.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_06in04.png)'
- en: 'That’s looking good! As well as looking at the batch visually, it’s a good
    idea to also look at the underlying tensors (especially as a student; it will
    help clarify your understanding of what your model is really seeing):'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来不错！除了通过视觉查看批次外，还可以查看底层张量（尤其是作为学生；这将有助于澄清您对模型实际看到的内容的理解）：
- en: '[PRE58]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: '[PRE59]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Make sure that you understand *why* these are the shapes for our mini-batches.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 确保您了解为什么这些是我们小批量的形状。
- en: 'Here’s an example of one row from the dependent variable:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 这是依赖变量的一个示例行：
- en: '[PRE60]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: '[PRE61]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: As you can see, we haven’t had to use a separate *image regression* application;
    all we’ve had to do is label the data and tell fastai what kinds of data the independent
    and dependent variables represent.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，我们不必使用单独的*图像回归*应用程序；我们所要做的就是标记数据并告诉fastai独立变量和因变量代表什么类型的数据。
- en: It’s the same for creating our `Learner`. We will use the same function as before,
    with one new parameter, and we will be ready to train our model.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 创建我们的`Learner`也是一样的。我们将使用与之前相同的函数，只有一个新参数，然后我们就可以准备训练我们的模型了。
- en: Training a Model
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练模型
- en: 'As usual, we can use `cnn_learner` to create our `Learner`. Remember way back
    in [Chapter 1](ch01.xhtml#chapter_intro) how we used `y_range` to tell fastai
    the range of our targets? We’ll do the same here (coordinates in fastai and PyTorch
    are always rescaled between –1 and +1):'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，我们可以使用`cnn_learner`来创建我们的`Learner`。还记得在[第1章](ch01.xhtml#chapter_intro)中我们如何使用`y_range`告诉fastai我们目标的范围吗？我们将在这里做同样的事情（fastai和PyTorch中的坐标始终在-1和+1之间重新缩放）：
- en: '[PRE62]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: '`y_range` is implemented in fastai using `sigmoid_range`, which is defined
    as follows:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '`y_range`在fastai中使用`sigmoid_range`实现，其定义如下：'
- en: '[PRE63]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: This is set as the final layer of the model, if `y_range` is defined. Take a
    moment to think about what this function does, and why it forces the model to
    output activations in the range `(lo,hi)`.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 如果定义了`y_range`，则将其设置为模型的最终层。花点时间思考一下这个函数的作用，以及为什么它强制模型在范围`(lo,hi)`内输出激活。
- en: 'Here’s what it looks like:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 这是它的样子：
- en: '[PRE64]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: '![](Images/dlcf_06in05.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_06in05.png)'
- en: 'We didn’t specify a loss function, which means we’re getting whatever fastai
    chooses as the default. Let’s see what it picked for us:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有指定损失函数，这意味着我们得到了fastai选择的默认值。让我们看看它为我们选择了什么：
- en: '[PRE65]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: '[PRE66]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: This makes sense, since when coordinates are used as the dependent variable,
    most of the time we’re likely to be trying to predict something as close as possible;
    that’s basically what `MSELoss` (mean squared error loss) does. If you want to
    use a different loss function, you can pass it to `cnn_learner` by using the `loss_func`
    parameter.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这是有道理的，因为当坐标被用作因变量时，大多数情况下我们可能会尽可能地预测接近某个值；这基本上就是 `MSELoss`（均方误差损失）所做的。如果你想使用不同的损失函数，你可以通过使用
    `loss_func` 参数将其传递给 `cnn_learner`。
- en: Note also that we didn’t specify any metrics. That’s because the MSE is already
    a useful metric for this task (although it’s probably more interpretable after
    we take the square root).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 还要注意，我们没有指定任何指标。这是因为均方误差已经是这个任务的一个有用指标（尽管在我们取平方根之后可能更易解释）。
- en: 'We can pick a good learning rate with the learning rate finder:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用学习率查找器选择一个好的学习率：
- en: '[PRE67]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: '![](Images/dlcf_06in06.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_06in06.png)'
- en: 'We’ll try an LR of 2e-2:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将尝试一个学习率为 2e-2：
- en: '[PRE68]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: '| epoch | train_loss | valid_loss | time |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| epoch | train_loss | valid_loss | time |'
- en: '| --- | --- | --- | --- |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | 0.045840 | 0.012957 | 00:36 |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0.045840 | 0.012957 | 00:36 |'
- en: '| 1 | 0.006369 | 0.001853 | 00:36 |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.006369 | 0.001853 | 00:36 |'
- en: '| 2 | 0.003000 | 0.000496 | 00:37 |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.003000 | 0.000496 | 00:37 |'
- en: '| 3 | 0.001963 | 0.000360 | 00:37 |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0.001963 | 0.000360 | 00:37 |'
- en: '| 4 | 0.001584 | 0.000116 | 00:36 |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 0.001584 | 0.000116 | 00:36 |'
- en: 'Generally, when we run this, we get a loss of around 0.0001, which corresponds
    to this average coordinate prediction error:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 通常情况下，当我们运行这个时，我们得到的损失大约是 0.0001，这对应于这个平均坐标预测误差：
- en: '[PRE69]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: '[PRE70]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'This sounds very accurate! But it’s important to take a look at our results
    with `Learner.show_results`. The left side has the actual (*ground truth*) coordinates
    and the right side has our model’s predictions:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 这听起来非常准确！但是重要的是要用 `Learner.show_results` 查看我们的结果。左侧是实际（*真实*）坐标，右侧是我们模型的预测：
- en: '[PRE71]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: '![](Images/dlcf_06in07.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_06in07.png)'
- en: It’s quite amazing that with just a few minutes of computation, we’ve created
    such an accurate key points model, and without any special domain-specific application.
    This is the power of building on flexible APIs and using transfer learning! It’s
    particularly striking that we’ve been able to use transfer learning so effectively,
    even between totally different tasks; our pretrained model was trained to do image
    classification, and we fine-tuned for image regression.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 令人惊讶的是，仅仅几分钟的计算，我们就创建了一个如此准确的关键点模型，而且没有任何特定领域的应用。这就是在灵活的 API 上构建并使用迁移学习的力量！特别引人注目的是，我们能够如此有效地使用迁移学习，即使在完全不同的任务之间；我们的预训练模型是用来进行图像分类的，而我们对图像回归进行了微调。
- en: Conclusion
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: In problems that are at first glance completely different (single-label classification,
    multi-label classification, and regression), we end up using the same model with
    just different numbers of outputs. The loss function is the one thing that changes,
    which is why it’s important to double-check that you are using the right loss
    function for your problem.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在乍一看完全不同的问题（单标签分类、多标签分类和回归）中，我们最终使用相同的模型，只是输出的数量不同。唯一改变的是损失函数，这就是为什么重要的是要仔细检查你是否为你的问题使用了正确的损失函数。
- en: 'fastai will automatically try to pick the right one from the data you built,
    but if you are using pure PyTorch to build your `DataLoader`s, make sure you think
    hard about your choice of loss function, and remember that you most probably want
    the following:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: fastai 将自动尝试从您构建的数据中选择正确的损失函数，但如果您使用纯 PyTorch 构建您的 `DataLoader`，请确保您认真考虑您选择的损失函数，并记住您很可能想要以下内容：
- en: '`nn.CrossEntropyLoss` for single-label classification'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nn.CrossEntropyLoss` 用于单标签分类'
- en: '`nn.BCEWithLogitsLoss` for multi-label classification'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nn.BCEWithLogitsLoss` 用于多标签分类'
- en: '`nn.MSELoss` for regression'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nn.MSELoss` 用于回归'
- en: Questionnaire
  id: totrans-225
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问卷
- en: How could multi-label classification improve the usability of the bear classifier?
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 多标签分类如何提高熊分类器的可用性？
- en: How do we encode the dependent variable in a multi-label classification problem?
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在多标签分类问题中，我们如何对因变量进行编码？
- en: How do you access the rows and columns of a DataFrame as if it were a matrix?
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何访问 DataFrame 的行和列，就像它是一个矩阵一样？
- en: How do you get a column by name from a DataFrame?
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何从 DataFrame 中按名称获取列？
- en: What is the difference between a `Dataset` and `DataLoader`?
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Dataset` 和 `DataLoader` 之间有什么区别？'
- en: What does a `Datasets` object normally contain?
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Datasets` 对象通常包含什么？'
- en: What does a `DataLoaders` object normally contain?
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`DataLoaders` 对象通常包含什么？'
- en: What does `lambda` do in Python?
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`lambda` 在 Python 中是做什么的？'
- en: What are the methods to customize how the independent and dependent variables
    are created with the data block API?
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何使用数据块 API 自定义独立变量和因变量的创建方法？
- en: Why is softmax not an appropriate output activation function when using a one-hot-encoded
    target?
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当使用一个独热编码的目标时，为什么 softmax 不是一个合适的输出激活函数？
- en: Why is `nll_loss` not an appropriate loss function when using a one-hot-encoded
    target?
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当使用一个独热编码的目标时，为什么 `nll_loss` 不是一个合适的损失函数？
- en: What is the difference between `nn.BCELoss` and `nn.BCEWithLogitsLoss`?
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`nn.BCELoss` 和 `nn.BCEWithLogitsLoss` 之间有什么区别？'
- en: Why can’t we use regular accuracy in a multi-label problem?
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么在多标签问题中不能使用常规准确率？
- en: When is it OK to tune a hyperparameter on the validation set?
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 何时可以在验证集上调整超参数？
- en: How is `y_range` implemented in fastai? (See if you can implement it yourself
    and test it without peeking!)
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`y_range` 在 fastai 中是如何实现的？（看看你是否可以自己实现并在不偷看的情况下测试！）'
- en: What is a regression problem? What loss function should you use for such a problem?
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 回归问题是什么？对于这样的问题应该使用什么损失函数？
- en: What do you need to do to make sure the fastai library applies the same data
    augmentation to your input images and your target point coordinates?
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了确保 fastai 库将相同的数据增强应用于您的输入图像和目标点坐标，您需要做什么？
- en: Further Research
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步研究
- en: Read a tutorial about Pandas DataFrames and experiment with a few methods that
    look interesting to you. See the book’s website for recommended tutorials.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 阅读关于 Pandas DataFrames 的教程，并尝试一些看起来有趣的方法。查看书籍网站上推荐的教程。
- en: Retrain the bear classifier using multi-label classification. See if you can
    make it work effectively with images that don’t contain any bears, including showing
    that information in the web application. Try an image with two kinds of bears.
    Check whether the accuracy on the single-label dataset is impacted using multi-label
    classification.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用多标签分类重新训练熊分类器。看看你是否可以使其有效地处理不包含任何熊的图像，包括在Web应用程序中显示该信息。尝试一张包含两种熊的图像。检查在单标签数据集上使用多标签分类是否会影响准确性。
