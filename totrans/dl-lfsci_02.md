# 第2章。深度学习简介

本章的目标是介绍深度学习的基本原理。如果您已经有很多深度学习经验，可以随意略读本章，然后继续下一章。如果您经验较少，应该仔细学习本章，因为它涵盖的内容对于理解本书的其余部分至关重要。

在我们讨论的大多数问题中，我们的任务是创建一个数学函数：

<math><mrow><mi mathvariant="bold">y</mi> <mo>=</mo> <mi>f</mi> <mo>(</mo> <mi mathvariant="bold">x</mi> <mo>)</mo></mrow></math>

请注意<math><mi mathvariant="bold">x</mi></math>和<math><mi mathvariant="bold">y</mi></math>是用粗体书写的。这表示它们是向量。该函数可能接受许多数字作为输入，也许是成千上万，它可能产生许多数字作为输出。以下是您可能想要创建的一些函数示例：

+   <math><mi mathvariant="bold">x</mi></math>包含图像中所有像素的颜色。如果图像中包含猫，则<math><mrow><mi>f</mi><mo>(</mo><mi mathvariant="bold">x</mi><mo>)</mo></mrow></math>应该等于1，如果不包含则等于0。

+   与上述相同，只是<math><mrow><mi>f</mi><mo>(</mo><mi mathvariant="bold">x</mi><mo>)</mo></mrow></math>应该是一个数字向量。第一个元素表示图像是否包含猫，第二个元素表示是否包含狗，第三个元素表示是否包含飞机，以此类推，针对成千上万种对象。

+   <math><mi mathvariant="bold">x</mi></math>包含染色体的DNA序列。<math><mi mathvariant="bold">y</mi></math>应该是一个向量，其长度等于染色体中碱基的数量。如果该碱基是编码蛋白质的区域的一部分，则每个元素应该等于1，否则为0。

+   <math><mi mathvariant="bold">x</mi></math>描述了分子的结构。（我们将在后面的章节中讨论表示分子的各种方法。）<math><mi mathvariant="bold">y</mi></math>应该是一个向量，其中每个元素描述分子的某些物理性质：它在水中溶解的容易程度，它与其他分子结合的强度等等。

正如您所看到的，<math><mrow><mi>f</mi><mo>(</mo><mi mathvariant="bold">x</mi><mo>)</mo></mrow></math>可能是一个非常复杂的函数！它通常接受一个长向量作为输入，并尝试从中提取信息，这些信息仅仅从查看输入数字是不明显的。

解决这个问题的传统方法是手动设计一个函数。您将从分析问题开始。哪些像素模式倾向于表明猫的存在？哪些DNA模式倾向于区分编码区域和非编码区域？您将编写计算机代码来识别特定类型的特征，然后尝试识别可靠产生所需结果的特征组合。这个过程缓慢而费力，且严重依赖于执行者的专业知识。

机器学习采用完全不同的方法。与手动设计函数不同，您允许计算机根据数据学习自己的函数。您收集成千上万甚至数百万张图像，每张都标记了是否包含猫。您将所有这些训练数据呈现给计算机，并让它搜索一个函数，对于包含猫的图像始终接近1，对于没有猫的图像接近0。

“让计算机搜索函数”是什么意思？一般来说，你创建一个*模型*，定义了一大类函数。模型包括*参数*，可以取任何值的变量。通过选择参数的值，你从模型定义的所有函数中选择一个特定的函数。计算机的任务是选择参数的值。它试图找到这样的值，使得当你的训练数据作为输入时，输出尽可能接近相应的目标。

# 线性模型

你可能考虑尝试的最简单的模型之一是线性模型：

<math><mrow><mi mathvariant="bold">y</mi> <mo>=</mo> <mi mathvariant="bold">Mx</mi> <mo>+</mo> <mi mathvariant="bold">b</mi></mrow></math>

在这个方程中，<math><mi mathvariant="bold">M</mi></math>是一个矩阵（有时被称为“权重”），<math><mi mathvariant="bold">b</mi></math>是一个向量（称为“偏差”）。它们的大小由输入和输出值的数量确定。如果<math><mi mathvariant="bold">x</mi></math>的长度为T，你希望<math><mi mathvariant="bold">y</mi></math>的长度为S，那么<math><mi mathvariant="bold">M</mi></math>将是一个S×T矩阵，<math><mi mathvariant="bold">b</mi></math>将是长度为S的向量。它们一起构成模型的参数。这个方程简单地表示每个输出组件是输入组件的线性组合。通过设置参数（<math><mi mathvariant="bold">M</mi></math>和<math><mi mathvariant="bold">b</mi></math>），你可以选择任何你想要的每个组件的线性组合。

这是最早的机器学习模型之一。它是在1957年引入的，被称为*感知器*。这个名字是一个了不起的营销手段：听起来像是科幻，似乎承诺了美好的事物，但实际上它只是一个线性变换。无论如何，这个名字已经坚持了半个多世纪。

线性模型非常容易以完全通用的方式来构建。无论你应用它到什么问题，它的形式都完全相同。线性模型之间唯一的区别是输入和输出向量的长度。从那里开始，只需要选择参数值，可以通过通用算法简单地完成。这正是我们在机器学习中想要的：一个与你要解决的问题无关的模型和算法。只需提供训练数据，参数会自动确定，将通用模型转换为解决你的问题的函数。

不幸的是，线性模型也非常有限。正如在[图2-1](#a_linear_model_cannot_fit_data_points_that_follow)中所示，线性模型（在一维中，即一条直线）简单地无法拟合大多数真实数据集。当你转向非常高维的数据时，问题变得更糟。在图像中像素值的线性组合将无法可靠地识别图像中是否包含猫。这个任务需要一个更加复杂的非线性模型。事实上，任何解决这个问题的模型都必然会非常复杂和非常非线性。但是我们如何以通用的方式来构建它呢？所有可能的非线性函数空间都是无限复杂的。我们如何定义一个模型，以便通过选择参数值，我们几乎可以创建任何我们想要的非线性函数？

![](Images/dlls_0201.png)

###### 图2-1. 线性模型无法拟合遵循曲线的数据点。这需要一个非线性模型。

# 多层感知器

一个简单的方法是堆叠多个线性变换，一个接一个。例如，我们可以写成：

<math><mrow><mi mathvariant="bold">y</mi> <mo>=</mo> <msub><mi mathvariant="bold">M</mi> <mn>2</mn></msub> <mi>𝜙</mi> <mrow><mo>(</mo> <msub><mi mathvariant="bold">M</mi> <mn>1</mn></msub> <mi mathvariant="bold">x</mi> <mo>+</mo> <msub><mi mathvariant="bold">b</mi> <mn>1</mn></msub> <mo>)</mo></mrow> <mo>+</mo> <msub><mi mathvariant="bold">b</mi> <mn>2</mn></msub></mrow></math>

仔细看看我们在这里做了什么。我们从一个普通的线性变换开始，<math><mrow><msub><mi mathvariant="bold">M</mi> <mn>1</mn></msub> <mi mathvariant="bold">x</mi><mo>+</mo><msub><mi mathvariant="bold">b</mi> <mn>1</mn></msub></mrow></math>。然后我们通过一个非线性函数<math><mrow><mi>𝜙</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></math>将结果传递，然后对结果应用第二个线性变换。函数<math><mrow><mi>𝜙</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></math>，也就是*激活函数*，是使这个工作正常运行的重要部分。没有它，模型仍然是线性的，比之前的模型没有更强大。线性组合的线性组合本身只不过是原始输入的线性组合！通过插入一个非线性，我们使模型能够学习更广泛的函数。

我们不需要停在两个线性变换上。我们可以堆叠任意多个线性变换在一起：

<math><mrow><msub><mi mathvariant="bold">h</mi> <mn>1</mn></msub> <mo>=</mo> <msub><mi>𝜙</mi> <mn>1</mn></msub> <mrow><mo>(</mo> <msub><mi mathvariant="bold">M</mi> <mn>1</mn></msub> <mi mathvariant="bold">x</mi> <mo>+</mo> <msub><mi mathvariant="bold">b</mi> <mn>1</mn></msub> <mo>)</mo></mrow></mrow></math><math><mrow><msub><mi mathvariant="bold">h</mi> <mn>2</mn></msub> <mo>=</mo> <msub><mi>𝜙</mi> <mn>2</mn></msub> <mrow><mo>(</mo> <msub><mi mathvariant="bold">M</mi> <mn>2</mn></msub> <msub><mi mathvariant="bold">h</mi> <mn>1</mn></msub> <mo>+</mo> <msub><mi mathvariant="bold">b</mi> <mn>2</mn></msub> <mo>)</mo></mrow></mrow></math>

```py
    ...

```

<math><mrow><msub><mi mathvariant="bold">h</mi> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub> <mo>=</mo> <msub><mi>𝜙</mi> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub> <mrow><mo>(</mo> <msub><mi mathvariant="bold">M</mi> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub> <msub><mi mathvariant="bold">h</mi> <mrow><mi>n</mi><mo>-</mo><mn>2</mn></mrow></msub> <mo>+</mo> <msub><mi mathvariant="bold">b</mi> <mrow><mi>n</mo>-<mn>1</mn></mrow></msub> <mo>)</mo></mrow></mrow></math><math><mrow><mi mathvariant="bold">y</mi> <mo>=</mo> <msub><mi>𝜙</mi> <mi>n</mi></msub> <mrow><mo>(</mo> <msub><mi mathvariant="bold">M</mi> <mi>n</mi></msub> <msub><mi mathvariant="bold">h</mi> <mrow><mi>n</mi><mo>-</mo><mn>1</mn></mrow></msub> <mo>+</mo> <msub><mi mathvariant="bold">b</mi> <mi>n</mi></msub> <mo>)</mo></mrow></mrow></math>

这个模型被称为*多层感知器*，简称MLP。中间步骤<math><msub><mi>h</mi> <mi>i</mi></msub></math>被称为*隐藏层*。这个名字指的是它们既不是输入也不是输出，只是在计算结果的过程中使用的中间值。还要注意，我们为每个<math><mrow><mi>𝜙</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow></math>添加了一个下标。这表示不同的层可能使用不同的非线性。

您可以将这个计算视为一堆层，如[图2-2](#a_multilayer_perceptron_viewed_as_a_stack)所示。每一层对应于一个线性变换，后面跟着一个非线性。信息从一层流向另一层，一层的输出成为下一层的输入。每一层都有自己的一组参数，这些参数确定了如何从输入计算输出。

![](Images/dlls_0202.png)

###### 图2-2。一个多层感知器，被视为一堆层，信息从一层流向下一层。

多层感知器及其变体有时也被称为*神经网络*。这个名称反映了机器学习和神经生物学之间的相似之处。生物神经元连接到许多其他神经元。它从它们那里接收信号，将信号相加，然后根据结果发送自己的信号。作为一个非常粗略的近似，你可以将MLP想象成与你的大脑中的神经元工作方式相同！

激活函数<math><mrow><mi>𝜙</mi><mo>(</mo><mi mathvariant="bold">x</mi><mo>)</mo></mrow></math>应该是什么？令人惊讶的答案是，这大部分并不重要。当然，这并不完全正确。显然它很重要，但并不像你可能期望的那样重要。几乎任何合理的函数（单调，相当平滑）都可以工作。多年来已经尝试了许多不同的函数，尽管有些比其他的效果更好，但几乎所有的函数都可以产生不错的结果。

今天最流行的激活函数可能是*修正线性单元*（ReLU），<math><mrow><mi>𝜙</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>=</mo> <mi>max</mi> <mo>(</mo><mn>0</mn><mo>,</mo><mi>x</mi><mo>)</mo></mrow></math>。如果你不确定使用什么函数，这可能是一个很好的默认选择。其他常见选择包括*双曲正切*，<math><mrow><mi>tanh</mi> <mo>(</mo><mi>x</mi><mo>)</mo></mrow></math>，和*逻辑Sigmoid*，<math><mrow><mi>𝜙</mi><mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mo>=</mo><mn>1</mn><mo>/</mo><mrow><mo>(</mo><mn>1</mn> <mo>+</mo><msup><mi>e</mi> <mrow><mo>-</mo><mi>x</mi></mrow></msup> <mo>)</mo></mrow></mrow></math>。所有这些函数都显示在[图2-3](#three_common_activation_functions)中。

![](Images/dlls_0203.png)

###### 图2-3。三种常见的激活函数：修正线性单元，双曲正切和逻辑Sigmoid。

我们还必须为MLP选择另外两个属性：它的*宽度*和*深度*。对于简单的线性模型，我们没有选择。鉴于<math><mi mathvariant="bold">x</mi></math>和<math><mi mathvariant="bold">y</mi></math>的长度，<math><mi mathvariant="bold">M</mi></math>和<math><mi mathvariant="bold">b</mi></math>的大小完全确定。但隐藏层不是这样。宽度指的是隐藏层的大小。我们可以选择每个<math><msub><mi mathvariant="bold">h</mi><mi>i</mi></msub></math>的长度。根据问题的不同，你可能希望它们比输入和输出向量大得多或小得多。

深度指的是模型中的层数。只有一个隐藏层的模型被描述为*浅层*。有许多隐藏层的模型被描述为*深层*。事实上，这就是“深度学习”这个术语的起源；它只是意味着“使用具有许多层的模型的机器学习”。

在模型中选择层数和宽度涉及到与科学一样多的艺术。或者，更正式地说，“这仍然是一个活跃的研究领域。”通常只是尝试很多组合，看看哪种有效。然而，有一些原则可能提供指导，或者至少帮助你事后理解你的结果：

1.  具有一个隐藏层的MLP是一个*通用逼近器*。

    这意味着它可以近似任何函数（在某些相当合理的限制范围内）。在某种意义上，你永远不需要超过一个隐藏层。这已经足够复制你可能想要的任何函数。不幸的是，这个结果带来了一个重要的警告：近似的准确性取决于隐藏层的宽度，你可能需要一个非常宽的层来获得对于特定问题的足够准确性。这将引出我们到第二个原则。

1.  深度模型通常需要比浅层模型更少的参数。

    这个陈述故意有些模糊。对于特定特殊情况可以证明更严格的陈述，但它仍然适用作为一个一般指导原则。也许以下是更好的陈述方式：每个问题都需要一个具有一定深度的模型才能有效地实现可接受的准确性。在较浅的深度下，层的宽度（因此参数的总数）会迅速增加。这使得听起来你应该总是更喜欢深度模型而不是浅层模型。不幸的是，这在一定程度上与第三个原则相矛盾。

1.  深度模型往往比浅层模型更难训练。

    直到2007年左右，大多数机器学习模型都是浅层的。深度模型的理论优势是已知的，但研究人员通常无法成功地训练它们。从那时起，一系列进步逐渐提高了深度模型的实用性。这些进步包括更好的训练算法，更容易训练的新型模型，当然还有更快的计算机以及更大的数据集，用于训练模型。这些进步催生了“深度学习”作为一个领域。然而，尽管有所改进，总体原则仍然成立：深度模型往往比浅层模型更难训练。

# 训练模型

这将我们带到下一个主题：我们到底如何训练一个模型？MLPs为我们提供了一个（大多数）通用的模型，可以用于任何问题。（我们稍后将讨论其他更专门的模型类型。）现在我们需要一个类似的通用算法来找到给定问题的模型参数的最佳值。我们该怎么做？

首先，你需要的当然是一组数据来进行训练。这个数据集被称为*训练集*。它应该包含大量的(**x**,**y**)对，也被称为*样本*。每个样本指定了模型的输入，以及当给定该输入时希望模型的输出是什么。例如，训练集可以是一组图像，以及标签指示每个图像是否包含猫。

接下来，你需要定义一个损失函数 <math><mrow><mi>L</mi><mo>(</mo><mi mathvariant="bold">y</mi><mo>,</mo><mover accent="true"><mi mathvariant="bold">y</mi> <mo>^</mo></mover><mo>)</mo></mrow></math>，其中 <math><mi mathvariant="bold">y</mi></math> 是模型的实际输出，<math><mover accent="true"><mi mathvariant="bold">y</mi> <mo>^</mo></mover></math> 是训练集中指定的目标值。这是你衡量模型是否很好地复制训练数据的方式。然后对训练集中的每个样本进行平均：

<math><mi>平均损失</mi> <mo>=</mo> <mrow><mfrac><mn>1</mn> <mi>N</mi></mfrac> <munderover><mo>Σ</mo> <rrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>N</mi></munderover> <mi>L</mi> <mrow><mo>(</mo> <msub><mi mathvariant="bold">y</mi> <mi>i</mi></msub> <mo>,</mo> <msub><mover accent="true"><mi mathvariant="bold">y</mi> <mo>^</mo></mover> <mi>i</mi></msub> <mo>)</mo></mrow></mrow></math>

<math><mrow><mi>L</mi><mo>(</mo><mi mathvariant="bold">y</mi><mo>,</mo><mover accent="true"><mi mathvariant="bold">y</mi> <mo>^</mo></mover><mo>)</mo></mrow></math> 当其参数接近时应该很小，而当它们相距较远时应该很大。换句话说，我们拿训练集中的每个样本，尝试将每个样本作为模型的输入，并查看输出与目标值的接近程度。然后我们对整个训练集进行平均。

对于每个问题需要选择一个合适的损失函数。一个常见的选择是欧几里德距离（也称为<math><msub><mi>L</mi><mi>2</mi></msub></math>距离），<math><mrow><mi>L</mi> <mrow><mo>(</mo> <mi mathvariant="bold">y</mi> <mo>,</mo> <mover accent="true"><mi mathvariant="bold">y</mi> <mo>^</mo></mover> <mo>)</mo></mrow> <mo>=</mo> <msqrt><mrow><msub><mo>Σ</mo> <mi>i</mi></msub> <msup><mrow><mo>(</mo><msub><mi>y</mi> <mi>i</mi></msub> <mo>-</mo><msub><mover accent="true"><mi>y</mi> <mo>^</mo></mover> <mi>i</mi></msub> <mo>)</mo></mrow> <mn>2</mn></msup></mrow></msqrt></mrow></math>。（在这个表达式中，<math><msub><mi>y</mi><mi>i</mi></msub></math>表示向量<math><mi mathvariant="bold">y</mi></math>的第*i*个分量。）当<math><mi mathvariant="bold">y</mi></math>表示概率分布时，一个常见的选择是交叉熵，<math><mrow><mi>L</mi> <mrow><mo>(</mo> <mi mathvariant="bold">y</mi> <mo>,</mo> <mover accent="true"><mi mathvariant="bold">y</mi> <mo>^</mo></mover> <mo>)</mo></mrow> <mo>=</mo> <mo>-</mo><msub><mo>Σ</mo> <mi>i</mi></msub> <msub><mi>y</mi> <mi>i</mi></msub> <mo form="prefix">log</mo> <msub><mover accent="true"><mi>y</mi> <mo>^</mo></mover> <mi>i</mi></msub></mrow></math>。还有其他选择，没有普遍的“最佳”选择。这取决于您问题的细节。

现在我们有一种衡量模型效果的方法，我们需要一种改进它的方法。我们希望搜索最小化训练集上平均损失的参数值。有许多方法可以做到这一点，但大多数深度学习工作都使用某种变体的*梯度下降*算法。让<math><mi>θ</mi></math>表示模型中的所有参数集。梯度下降涉及采取一系列小步骤：

<math><mrow><mi>θ</mi> <mo>←</mo> <mi>θ</mi> <mo>-</mo> <mi>ϵ</mi> <mfrac><mi>∂</mi> <mrow><mi>∂</mi><mi>θ</mi></mrow></mfrac> <mrow><mo>〈</mo> <mi>L</mi> <mo>〉</mo></mrow></mrow></math>

其中<math><mrow><mo>〈</mo> <mi>L</mi> <mo>〉</mo></mrow></math>是训练集上的平均损失。每一步都会在“下坡”方向上移动一个微小的距离。它会稍微改变模型的每个参数，目的是使平均损失减少。如果所有条件都符合，月相正好，这最终将产生一组参数，这些参数能够很好地解决您的问题。<math><mi>ϵ</mi></math>被称为*学习率*，它决定了每一步参数的变化量。它需要非常谨慎地选择：太小的值会导致学习速度非常慢，而太大的值会阻止算法学习。

这个算法确实有效，但存在一个严重问题。对于梯度下降的每一步，我们需要循环遍历训练集中的每个样本。这意味着训练模型所需的时间与训练集的大小成正比！假设您的训练集中有一百万个样本，计算一个样本的损失梯度需要一百万次操作，并且需要一百万步才能找到一个好的模型。（所有这些数字都是真实深度学习应用程序的典型数字。）训练将需要*一百万的五次方*次操作。即使在一台快速计算机上，这也需要相当长的时间。

幸运的是，有一个更好的解决方案：通过对少量样本进行平均来估计<math><mrow><mo>〈</mo> <mi>L</mi> <mo>〉</mo></mrow></math>。这是*随机梯度下降*（SGD）算法的基础。对于每一步，我们从训练集中取一小组样本（称为*批次*），计算损失函数的梯度，仅在批次中的样本上进行平均。我们可以将其视为对整个训练集进行平均的估计，尽管这可能是一个非常嘈杂的估计。我们执行一步梯度下降，然后为下一步选择一个新的样本批次。

这种算法往往更快。每个步骤所需的时间仅取决于每个批次的大小，这可以相当小（通常在100个样本左右的数量级），并且与训练集的大小无关。缺点是每个步骤在减少损失方面的效果较差，因为它是基于梯度的嘈杂估计而不是真实梯度。尽管如此，它确实会导致整体训练时间大大缩短。

深度学习中使用的大多数优化算法都基于SGD，但有许多改进它的变体。幸运的是，您通常可以将这些算法视为黑匣子，并相信它们会在不了解其工作细节的情况下做正确的事情。今天使用最广泛的两种算法称为Adam和RMSProp。如果您对要使用的算法有疑问，那么这两种算法中的任何一种可能都是一个合理的选择。

# 验证

假设您已经按照迄今所述的一切做了。您收集了大量的训练数据。您选择了一个模型，然后运行了一个训练算法，直到损失变得非常小。恭喜，您现在有一个解决问题的函数！

对吗？

抱歉，事情并不那么简单！您唯一确切知道的是该函数在*训练数据*上表现良好。您可能希望它在其他数据上也表现良好，但肯定不能指望。现在您需要验证模型，看看它是否适用于未经专门训练的数据。

为此，您需要第二个数据集，称为*测试集*。它与训练集具有完全相同的形式，即一组<math><mrow><mo>(</mo> <mi mathvariant="bold">x</mi> <mo>,</mo> <mi mathvariant="bold">y</mi> <mo>)</mo></mrow></math>对，但两者不应有共同的样本。您在训练集上训练模型，然后在测试集上测试它。这将引出机器学习中最重要的原则之一：

+   在设计或训练模型时，绝对不能使用测试集。

事实上，最好永远不要查看测试集中的数据。测试集数据仅用于测试完全训练的模型，以了解其工作效果如何。如果允许测试集以任何方式影响模型，您就有可能得到一个在测试集上比在未参与创建模型的其他数据上表现更好的模型。它不再是一个真正的测试集，而只是另一种类型的训练集。

这与数学概念*过拟合*有关。训练数据应该代表一个更大的数据分布，即您可能希望在模型上使用的所有输入集。但您无法对所有可能的输入进行训练。您只能创建一个有限的训练样本集，对其进行训练，并希望它学习到适用于其他样本的通用策略。过拟合是指当训练捕捉到训练样本的特定特征时，模型在这些样本上的表现比其他样本更好。

# 正则化

过拟合是任何使用机器学习的人都会遇到的主要问题。鉴于此，您不会感到惊讶地了解到已经开发了许多技术来避免过拟合。这些技术统称为*正则化*。任何正则化技术的目标都是避免过拟合，并产生一个在任何输入上都表现良好的训练模型，而不仅仅是用于训练的特定输入。

在讨论特定的正则化技术之前，有两个非常重要的要点需要了解。

首先，避免过拟合的最佳方法 *几乎总是* 获得更多的训练数据。您的训练集越大，它越能更好地代表“真实”数据分布，学习算法过拟合的可能性就越小。当然，有时这是不可能的：也许您根本无法获得更多数据，或者收集数据可能非常昂贵。在这种情况下，您只能尽力利用手头的数据，如果过拟合是一个问题，您将不得不使用正则化来避免它。但更多的数据可能会比正则化产生更好的结果。

其次，没有普遍“最佳”的正则化方法。这一切都取决于问题。毕竟，训练算法并不知道自己正在过拟合。它只知道训练数据。它不知道真实数据分布与训练数据的差异，因此它能做的最好就是生成一个在训练集上表现良好的模型。如果这不是您想要的，那就由您告诉它。

这就是任何正则化方法的本质：偏向训练过程，更喜欢某些类型的模型而不是其他类型。您对“好”模型应该具有哪些特性以及它与过拟合模型有何不同做出假设，然后告诉训练算法更喜欢具有这些特性的模型。当然，这些假设通常是隐含的而不是明确的。通过选择特定的正则化方法，您可能不清楚自己做出了什么假设。但它们总是存在的。

最简单的正则化方法之一就是减少模型的训练步骤。在训练初期，模型倾向于捕捉到训练数据的粗略特性，这些特性可能适用于真实分布。它运行得越久，就越有可能开始捕捉特定训练样本的细节。通过限制训练步骤的数量，您减少了过拟合的机会。更正式地说，您实际上是假设“好”的参数值不应该与您开始训练时的值有太大的不同。

另一种方法是限制模型中参数的大小。例如，您可以向损失函数添加一个与 <math><msup><mrow><mo>|</mo><mi>θ</mi><mo>|</mo></mrow> <mn>2</mn></msup></math> 成比例的项，其中 <math><mi>θ</mi></math> 是包含模型所有参数的向量。通过这样做，您假设“好”的参数值不应该比必要的大。这反映了过拟合通常（虽然不总是）涉及一些参数变得非常大的事实。

一种非常流行的正则化方法称为*辍学*。它涉及做一些乍看起来荒谬的事情，但实际上效果出奇的好。对于模型中的每个隐藏层，您随机选择输出向量<math><msub><mi>h</mi><mi>i</mi></msub></math>中的一部分元素，并将它们设置为0。在梯度下降的每一步中，您选择不同的随机元素子集。这可能看起来会破坏模型：当内部计算不断随机设置为0时，您如何指望它能够工作？辍学为什么有效的数学理论有点复杂。非常粗略地说，通过使用辍学，您假设模型中没有任何个别计算应该太重要。您应该能够随机删除任何个别计算，而模型的其余部分应该继续在没有它的情况下工作。这迫使它学习冗余的、高度分布的数据表示，使过度拟合不太可能发生。如果您不确定要使用哪种正则化方法，辍学是一个不错的尝试。

# 超参数优化

到目前为止，您可能已经注意到，即使使用一个被认为是通用的模型和“通用”学习算法，也有很多选择要做。例如：

+   模型中的层数

+   每一层的宽度

+   要执行的训练步数

+   训练过程中使用的学习率

+   使用辍学时要设置为0的元素的比例

这些选项称为*超参数*。超参数是模型或训练算法的任何方面，必须事先设置而不是由训练算法学习。但是您应该如何选择它们呢？难道机器学习的整个目的不是根据数据自动选择设置吗？

这将我们带到*超参数优化*的主题。最简单的方法就是尝试每个超参数的许多值，看看哪个效果最好。当您想尝试许多超参数的许多值时，这变得非常昂贵，因此有更复杂的方法，但基本思想仍然相同：尝试不同的组合，看看哪个效果最好。

但是如何确定哪个效果最好呢？最简单的答案可能是看看哪个产生了训练集上损失函数（或其他准确度度量）的最低值。但请记住，这不是我们真正关心的。我们想要最小化测试集上的错误，而不是训练集。这对于影响正则化的超参数尤为重要，例如辍学率。低训练集错误可能只意味着模型过度拟合，优化于训练数据的精确细节。因此，我们希望尝试许多超参数值，然后使用在测试集上最小化损失的那些值。

但我们不能这样做！记住：在设计或训练模型时，绝不能以任何方式使用测试集。它的作用是告诉您模型在从未见过的新数据上可能的工作效果。仅因为某个特定的超参数集恰好在测试集上效果最好，并不意味着这些值将始终效果最好。我们不能让测试集影响模型，否则它就不再是一个无偏的测试集。

解决方案是创建另一个数据集，称为*验证集*。它不能与训练集或测试集共享任何样本。完整的流程如下：

1.  对于每组超参数值，在训练集上训练模型，然后计算验证集上的损失。

1.  接受在验证集上给出最低损失的超参数集作为最终模型。

1.  在测试集上评估最终模型，以获得其工作效果的无偏度量。

# 其他类型的模型

这还留下了一个你需要做出的决定，这本身就是一个庞大的主题：使用什么样的模型。在本章的前面，我们介绍了多层感知器。它们的优点是作为一类通用模型，可以应用于许多不同的问题。不幸的是，它们也有严重的缺点。它们需要大量的参数，这使它们非常容易过拟合。当它们有超过一两个隐藏层时，训练变得困难。在许多情况下，通过使用一个更少通用的模型，利用问题的特定特征，你可以获得更好的结果。

这本书的大部分内容都是讨论在生命科学中特别有用的特定类型的模型。这些可以等到后面的章节再讨论。但是在这个介绍中，有两类非常重要的模型我们应该讨论，它们在许多不同领域中被广泛使用。它们被称为卷积神经网络和循环神经网络。

## 卷积神经网络

*卷积神经网络*（简称CNN）是最早被广泛使用的深度模型之一。它们被开发用于图像处理和计算机视觉。它们仍然是许多涉及在矩形网格上采样的连续数据的问题的绝佳选择：音频信号（1D）、图像（2D）、体积MRI数据（3D）等等。

它们也是一类真正体现“神经网络”这个术语的模型。CNN的设计最初受到猫的视觉皮层工作的启发。（猫在深度学习领域的黎明时期起到了核心作用。）从20世纪50年代到80年代进行的研究揭示了视觉是通过一系列层次来处理的。第一层中的每个神经元从视野的一个小区域（其*感受野*）接收输入。不同的神经元专门用于检测特定的局部模式或特征，如垂直或水平线。第二层中的细胞从第一层中的局部细胞群接收输入，结合它们的信号来检测更复杂的模式，覆盖更大的感受野。每一层可以被看作是原始图像的一个新表示，用更大更抽象的模式来描述比前一层中的模式。

CNN反映了这种设计，将输入图像通过一系列层。在这个意义上，它们就像MLP，但是每一层的结构是非常不同的。MLP使用*全连接层*。输出向量的每个元素都取决于输入向量的每个元素。CNN使用*卷积层*，利用了空间局部性。每个输出元素对应于图像的一个小区域，并且仅取决于该区域内的输入值。这极大地减少了定义每一层的参数数量。实际上，它假设权重矩阵<math><msub><mi mathvariant="bold">M</mi><mi>i</mi></msub></math>的大多数元素都是0，因为每个输出元素仅取决于少量的输入元素。

卷积层进一步假设参数对于*图像的每个局部区域都是相同的*。如果一个层使用一组参数在图像的一个位置检测水平线，那么它也会使用完全相同的参数在图像的其他任何地方检测水平线。这使得该层的参数数量与图像的大小无关。它只需要学习一个单一的*卷积核*，定义了如何从图像的任何局部区域计算输出特征。这个局部区域通常非常小，可能是5乘5像素。在这种情况下，要学习的参数数量仅为每个区域的输出特征数量的25倍。与全连接层中的参数数量相比，这是微不足道的，使得CNN比MLP更容易训练，更不容易过拟合。

## 循环神经网络

*循环神经网络*（简称RNNs）有些不同。它们通常用于处理以元素序列形式呈现的数据：文本文档中的单词，DNA分子中的碱基等。序列中的元素逐个输入到网络的输入中。但然后网络做了一些非常不同的事情：每个层的输出被反馈到下一步的自身输入中！这使得RNNs具有一种记忆。当序列中的元素（单词、DNA碱基等）被输入到网络中时，每个层的输入取决于该元素，但也取决于所有先前的元素（[图2-4](#recurrent-neural-network)）。

![](Images/dlls_0204.png)

###### 图2-4\. 一个循环神经网络。当序列的每个元素（<math><msub><mi>x</mi> <mn>1</mn></msub></math>，<math><msub><mi>x</mi> <mn>2</mn></msub></math>，...）被馈送到输入时，输出（<math><msub><mi>y</mi> <mn>1</mn></msub></math>，<math><msub><mi>y</mi> <mn>2</mn></msub></math>，...）既取决于输入元素，也取决于上一步中RNN自身的输出。

因此，循环层的输入有两部分：常规输入（即网络中前一层的输出）和循环输入（等于前一步的自身输出）。然后需要根据这些输入计算一个新的输出。原则上你可以使用全连接层，但实际上通常效果不是很好。研究人员已经开发出其他类型的层，在RNN中效果要好得多。最流行的两种类型分别称为*门控循环单元*（GRU）和*长短期记忆*（LSTM）。现在不用担心细节；只需记住，如果你正在创建一个RNN，通常应该使用这些类型的层来构建它。

拥有记忆使得循环神经网络（RNNs）在根本上与我们讨论过的其他模型有所不同。使用卷积神经网络（CNN）或多层感知器（MLP），你只需将一个值输入到网络的输入中，然后得到一个不同的值。输出完全由输入决定。但对于RNN来说并非如此。该模型有自己的内部状态，由最近一步的所有层的输出组成。每次将一个新值输入到模型中时，输出不仅取决于输入值，还取决于内部状态。同样，内部状态也会受到每个新输入值的影响。这使得RNN非常强大，并允许它们用于许多不同的应用。

# 进一步阅读

深度学习是一个庞大的主题，本章仅对其进行了最简要的介绍。这应该足以帮助你阅读和理解本书的其余部分，但如果你计划在该领域进行严肃的工作，你将需要获得更全面的背景知识。幸运的是，网络上有许多优秀的深度学习资源可供参考。以下是一些你可能要查阅的材料建议：

+   *[神经网络与深度学习](http://neuralnetworksanddeeplearning.com)* 由迈克尔·尼尔森（Determination Press）涵盖了与本章大致相同的材料，但对每个主题进行了更详细的讨论。如果你想要对深度学习的基础知识有扎实的工作了解，足以在自己的工作中使用它，那么这是一个很好的起点。

+   [*深度学习*](http://www.deeplearningbook.org) 由伊恩·古德费洛、约书亚·本吉奥和亚伦·库维尔（麻省理工学院出版社）撰写，是由该领域顶尖研究人员撰写的更高级的介绍。它期望读者具有类似计算机科学研究生的背景，并对主题背后的数学理论进行更详细的讨论。你可以轻松地使用深度模型而不必理解所有理论，但如果你想在深度学习领域进行原创研究（而不仅仅是将深度模型作为解决其他领域问题的工具），这本书是一个绝佳的资源。

+   《深度学习的TensorFlow》（O'Reilly出版）由Bharath Ramsundar和Reza Zadeh撰写，为从业者介绍了深度学习的核心概念，旨在建立直观理解，而不深入探讨这些模型的数学基础。对于那些对深度学习的实际方面感兴趣的人来说，这可能是一个有用的参考资料。
