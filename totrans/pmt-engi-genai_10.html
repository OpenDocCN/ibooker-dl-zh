<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 10. Building AI-Powered Applications"><div class="chapter" id="building_applications_10">
<h1><span class="label">Chapter 10. </span>Building AI-Powered Applications</h1>


<p>In this chapter, you’ll apply the five principles of prompting to an end-to-end AI workflow for content writing. The service will write blog posts based on the user’s responses to interview questions, in the style of the user’s writing. This system was first documented on the <a href="https://oreil.ly/saxifrage">Saxifrage blog</a>.</p>






<section data-type="sect1" data-pdf-bookmark="AI Blog Writing"><div class="sect1" id="id134">
<h1>AI Blog Writing</h1>

<p>The naive approach to creating a blog <a data-type="indexterm" data-primary="blog writing" id="blgwr"/>writing service using AI would be to prompt ChatGPT with <code>Write a blog post on {blogPostTopic}</code>. The resulting content would be of reasonable quality but wouldn’t likely contain any valuable opinions or unique experiences on the topic. The content would also likely be short and generic and therefore unlikely to rank on Google.</p>

<p>A more sophisticated approach might be to build up a longer prompt with further instructions. Detail on the prescribed writing tone, architecture of the blog post, and keywords to include could be added. An example of a common blog post <a href="https://oreil.ly/uMfZa">writing prompt</a> can be seen here.</p>

<p>Input:</p>

<pre data-type="programlisting">Create a blog post about “{blogPostTopic}”. Write it in a “{tone}” tone.
Use transition words.
Use active voice. Write over 1000 words.
Use very creative titles for the blog post.
Add a title for each section. Ensure there are a minimum of 9 sections. Each
section should have a minimum of two paragraphs.
Include the following keywords: “{keywords}”.
Create a good slug for this post and a meta description with a maximum of 100
words and add it to the end of the blog post.</pre>

<p>This longer, more sophisticated prompt is likely to result in better quality content. However, let’s run through the five principles of prompting as a checklist:</p>
<dl>
<dt>Direction</dt>
<dd>
<p>There are some instructions provided, such <a data-type="indexterm" data-primary="Five Principles of Prompting" data-secondary="Give Direction" id="id1311"/><a data-type="indexterm" data-primary="Give Direction principle" id="id1312"/>as the tone, using transition words, and an active voice. However, the content is still likely to sound like AI, and not like the user.</p>
</dd>
<dt>Format</dt>
<dd>
<p>Although there are some mentions of <a data-type="indexterm" data-primary="Five Principles of Prompting" data-secondary="Specify Format" id="id1313"/><a data-type="indexterm" data-primary="Specify Format principle" id="id1314"/>structure, including dictating nine sections of two paragraphs, it’s likely these instructions will be ignored. ChatGPT is bad at math and is often unable to follow instructions dictating a number of sections or words.</p>
</dd>
<dt>Examples</dt>
<dd>
<p>There are no samples of how to <a data-type="indexterm" data-primary="Five Principles of Prompting" data-secondary="Provide Examples" id="id1315"/><a data-type="indexterm" data-primary="Provide Examples principle" id="id1316"/>do the task given, which is likely to harm the reliability of running this prompt across multiple topics or even multiple times on the same topic. Even providing one example (a one-shot prompt) could radically help improve quality.</p>
</dd>
<dt>Evaluation</dt>
<dd>
<p>This is an example of <em>blind prompting</em> (adding instructions <a data-type="indexterm" data-primary="blind prompting" id="id1317"/><a data-type="indexterm" data-primary="Five Principles of Prompting" data-secondary="Evaluate Quality" id="id1318"/><a data-type="indexterm" data-primary="Evaluate Quality principle" id="id1319"/>to a prompt <a href="https://oreil.ly/r7sXi">without testing them</a>). It’s likely some of these instructions make no difference to quality (unnecessarily costing tokens) or might even degrade quality.</p>
</dd>
<dt>Division</dt>
<dd>
<p>The entire task is attempted with <a data-type="indexterm" data-primary="Five Principles of Prompting" data-secondary="Divide Labor" id="id1320"/><a data-type="indexterm" data-primary="Divide Labor principle" id="id1321"/>just one prompt, which is likely to harm performance. Without breaking the task into subtasks, it’s hard to understand which part of the process is suceeding or failing.</p>
</dd>
</dl>

<p>Through this chapter, you’ll create multiple LLM chain components. Each chain will be implemented in LangChain to make it more maintainable and to give easy logging for monitoring and optimization. The resulting system will help you generate <em>human-sounding</em> content based <a data-type="indexterm" data-primary="human-sounding content" id="id1322"/>on the unique opinions and experiences of the user.</p>

<p>It’s crucial that you first prepare your workspace with the necessary tools. Therefore, let’s shift our focus toward topic <a data-type="indexterm" data-primary="blog writing" data-startref="blgwr" id="id1323"/>research and start setting up your programming environment.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Topic Research"><div class="sect1" id="id135">
<h1>Topic Research</h1>

<p>You will need to install several Python packages <a data-type="indexterm" data-primary="topic research, blog writing" id="tpcrsrh"/><a data-type="indexterm" data-primary="blog writing" data-secondary="topic research" id="bgwprs"/>to effectively use LangChain’s document loaders, including the following:</p>
<dl>
<dt>google-searchresults</dt>
<dd>
<p>A Python library designed to scrape and process Google search results.</p>
</dd>
<dt>pandas</dt>
<dd>
<p>This offers data structures and operations for manipulating numerical tables and time series data.</p>
</dd>
<dt>html2text</dt>
<dd>
<p>This tool converts HTML from files or web pages into markdown (<em>.md</em>) files or text.</p>
</dd>
<dt>pytest-playwright</dt>
<dd>
<p>This package enables end-to-end testing with Playwright.</p>
</dd>
<dt>chromadb</dt>
<dd>
<p>ChromaDB is an open source vector database.</p>
</dd>
<dt>nest_asyncio</dt>
<dd>
<p>This extends the Python standard <code>asyncio</code> to patch and render it compatible with Jupyter Notebooks.</p>
</dd>
</dl>

<p>Installation of these packages can be achieved easily with this command:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">pip</code> <code class="n">install</code> <code class="n">google</code><code class="o">-</code><code class="n">searchresults</code> <code class="n">pandas</code> <code class="n">html2text</code> <code class="n">pytest</code><code class="o">-</code><code class="n">playwright</code> <code class="n">chromadb</code> \
<code class="n">nest_asyncio</code> <code class="o">--</code><code class="n">quiet</code></pre>

<p>Additionally, you’ll be using LangChain’s document loaders that require Playwright.</p>

<p>Type this command on your terminal: <strong>playwright install</strong>.</p>

<p>Additionally, you’ll need to choose a <code>TOPIC</code> and set environment variables for both <code>SERPAPI_API_KEY</code> and <code>STABILITY_API_KEY</code>. If you’re running the script without Jupyter Notebook, then you won’t need to use any of the <code>nest_asyncio</code> code:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">langchain_openai.chat_models</code> <code class="kn">import</code> <code class="n">ChatOpenAI</code>
<code class="kn">from</code> <code class="nn">langchain.output_parsers</code> <code class="kn">import</code> <code class="n">PydanticOutputParser</code>
<code class="kn">from</code> <code class="nn">langchain_text_splitters</code> <code class="kn">import</code> <code class="n">RecursiveCharacterTextSplitter</code>
<code class="kn">import</code> <code class="nn">os</code>

<code class="c1"># Custom imports:</code>
<code class="kn">from</code> <code class="nn">content_collection</code> <code class="kn">import</code> <code class="n">collect_serp_data_and_extract_text_from_webpages</code>
<code class="kn">from</code> <code class="nn">custom_summarize_chain</code> <code class="kn">import</code> <code class="n">create_all_summaries</code><code class="p">,</code> <code class="n">DocumentSummary</code>

<code class="kn">import</code> <code class="nn">nest_asyncio</code>
<code class="n">nest_asyncio</code><code class="o">.</code><code class="n">apply</code><code class="p">()</code>

<code class="c1"># Constant variables:</code>
<code class="n">TOPIC</code> <code class="o">=</code> <code class="s2">"Neural networks"</code>
<code class="n">os</code><code class="o">.</code><code class="n">environ</code><code class="p">[</code><code class="s2">"SERPAPI_API_KEY"</code><code class="p">]</code> <code class="o">=</code> <code class="s2">""</code>
<code class="n">os</code><code class="o">.</code><code class="n">environ</code><code class="p">[</code><code class="s2">"STABILITY_API_KEY"</code><code class="p">]</code> <code class="o">=</code> <code class="s2">""</code></pre>

<p class="pagebreak-before">Next, you’ll focus on summarizing web content efficiently:</p>

<pre data-type="programlisting" data-code-language="python"><code class="c1"># Extract content from webpages into LangChain documents:</code>
<code class="n">text_documents</code> <code class="o">=</code> <code class="k">await</code> \
<code class="n">collect_serp_data_and_extract_text_from_webpages</code><code class="p">(</code><code class="n">TOPIC</code><code class="p">)</code>

<code class="c1"># LLM, text splitter + parser:</code>
<code class="n">llm</code> <code class="o">=</code> <code class="n">ChatOpenAI</code><code class="p">(</code><code class="n">temperature</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code>
<code class="n">text_splitter</code> <code class="o">=</code> <code class="n">RecursiveCharacterTextSplitter</code><code class="o">.</code><code class="n">from_tiktoken_encoder</code><code class="p">(</code>
    <code class="n">chunk_size</code><code class="o">=</code><code class="mi">1500</code><code class="p">,</code> <code class="n">chunk_overlap</code><code class="o">=</code><code class="mi">400</code>
<code class="p">)</code>
<code class="n">parser</code> <code class="o">=</code> <code class="n">PydanticOutputParser</code><code class="p">(</code><code class="n">pydantic_object</code><code class="o">=</code><code class="n">DocumentSummary</code><code class="p">)</code>

<code class="n">summaries</code> <code class="o">=</code> <code class="k">await</code> <code class="n">create_all_summaries</code><code class="p">(</code><code class="n">text_documents</code><code class="p">,</code>
<code class="n">parser</code><code class="p">,</code>
<code class="n">llm</code><code class="p">,</code>
<code class="n">text_splitter</code><code class="p">)</code></pre>

<p>First, import the required tools and then fetch the web page content related to your <code>TOPIC</code>. After setting up your <code>ChatOpenAI</code> model, you’ll utilize a <code>text_splitter</code> to manage text chunks. The splitter ensures no snippet is too long, while maintaining context with overlap. Then create the <code>PydanticOutputParser</code> to handle and structure the summaries. By feeding the extracted documents through a dedicated summarization function, the LLM produces concise summaries.</p>

<p>If you would like to dive deeper into the  <code>create_all_summaries</code> function, check <a href="https://oreil.ly/KyKjS"><em>custom_summarize_chain.py</em></a>.</p>

<p>Some key points to highlight are that you can <em>subclass</em> most classes within LangChain. For example, you can overide the default <code>ChromiumLoader</code> to be asynchronous:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">langchain_community.document_loaders</code> <code class="kn">import</code> <code class="n">AsyncHtmlLoader</code><code class="p">,</code> \
<code class="n">AsyncChromiumLoader</code>

<code class="k">class</code> <code class="nc">ChromiumLoader</code><code class="p">(</code><code class="n">AsyncChromiumLoader</code><code class="p">):</code>
    <code class="k">async</code> <code class="k">def</code> <code class="nf">load</code><code class="p">(</code><code class="bp">self</code><code class="p">):</code>
        <code class="n">raw_text</code> <code class="o">=</code> <code class="p">[</code><code class="k">await</code> <code class="bp">self</code><code class="o">.</code><code class="n">ascrape_playwright</code><code class="p">(</code><code class="n">url</code><code class="p">)</code> <code class="k">for</code> <code class="n">url</code> <code class="ow">in</code> <code class="bp">self</code><code class="o">.</code><code class="n">urls</code><code class="p">]</code>
        <code class="c1"># Return the raw documents:</code>
        <code class="k">return</code> <code class="p">[</code><code class="n">Document</code><code class="p">(</code><code class="n">page_content</code><code class="o">=</code><code class="n">text</code><code class="p">)</code> <code class="k">for</code> <code class="n">text</code> <code class="ow">in</code> <code class="n">raw_text</code><code class="p">]</code>


<code class="k">async</code> <code class="k">def</code> <code class="nf">get_html_content_from_urls</code><code class="p">(</code>
    <code class="n">df</code><code class="p">:</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">,</code> <code class="n">number_of_urls</code><code class="p">:</code> <code class="nb">int</code> <code class="o">=</code> <code class="mi">3</code><code class="p">,</code> <code class="n">url_column</code><code class="p">:</code> <code class="nb">str</code> <code class="o">=</code> <code class="s2">"link"</code>
<code class="p">)</code> <code class="o">-&gt;</code> <code class="n">List</code><code class="p">[</code><code class="n">Document</code><code class="p">]:</code>
    <code class="c1"># Get the HTML content of the first 3 URLs:</code>
    <code class="n">urls</code> <code class="o">=</code> <code class="n">df</code><code class="p">[</code><code class="n">url_column</code><code class="p">]</code><code class="o">.</code><code class="n">values</code><code class="p">[:</code><code class="n">number_of_urls</code><code class="p">]</code><code class="o">.</code><code class="n">tolist</code><code class="p">()</code>

    <code class="c1"># If there is only one URL, convert it to a list:</code>
    <code class="k">if</code> <code class="nb">isinstance</code><code class="p">(</code><code class="n">urls</code><code class="p">,</code> <code class="nb">str</code><code class="p">):</code>
        <code class="n">urls</code> <code class="o">=</code> <code class="p">[</code><code class="n">urls</code><code class="p">]</code>


    <code class="c1"># Check for empty URLs:</code>
    <code class="n">urls</code> <code class="o">=</code> <code class="p">[</code><code class="n">url</code> <code class="k">for</code> <code class="n">url</code> <code class="ow">in</code> <code class="n">urls</code> <code class="k">if</code> <code class="n">url</code> <code class="o">!=</code> <code class="s2">""</code><code class="p">]</code>

    <code class="c1"># Check for duplicate URLs:</code>
    <code class="n">urls</code> <code class="o">=</code> <code class="nb">list</code><code class="p">(</code><code class="nb">set</code><code class="p">(</code><code class="n">urls</code><code class="p">))</code>

    <code class="c1"># Throw error if no URLs are found:</code>
    <code class="k">if</code> <code class="nb">len</code><code class="p">(</code><code class="n">urls</code><code class="p">)</code> <code class="o">==</code> <code class="mi">0</code><code class="p">:</code>
        <code class="k">raise</code> <code class="ne">ValueError</code><code class="p">(</code><code class="s2">"No URLs found!"</code><code class="p">)</code>
    <code class="c1"># loader = AsyncHtmlLoader(urls) # Faster but might not always work.</code>
    <code class="n">loader</code> <code class="o">=</code> <code class="n">ChromiumLoader</code><code class="p">(</code><code class="n">urls</code><code class="p">)</code>
    <code class="n">docs</code> <code class="o">=</code> <code class="k">await</code> <code class="n">loader</code><code class="o">.</code><code class="n">load</code><code class="p">()</code>
    <code class="k">return</code> <code class="n">docs</code>

<code class="k">async</code> <code class="k">def</code> <code class="nf">create_all_summaries</code><code class="p">(</code>
    <code class="c1"># ... commented out for brevity</code>
<code class="p">)</code> <code class="o">-&gt;</code> <code class="n">List</code><code class="p">[</code><code class="n">DocumentSummary</code><code class="p">]:</code>
    <code class="c1"># ... commented out for brevity</code></pre>

<p>By subclassing <code>ChromiumLoader</code>, you can easily create a <a data-type="indexterm" data-primary="asynchronously scraping content" id="id1324"/>custom implementation to <em>asynchronously scrape content</em> from multiple URLs using the Chrome browser. <code>get_html_content_from_urls</code> fetches HTML content from a <a data-type="indexterm" data-primary="topic research, blog writing" data-startref="tpcrsrh" id="id1325"/><a data-type="indexterm" data-primary="blog writing" data-secondary="topic research" data-startref="bgwprs" id="id1326"/>list of URLs, ensuring no duplicates and handling potential errors.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Expert Interview"><div class="sect1" id="id136">
<h1>Expert Interview</h1>

<p>Now that you’ve successfully extracted the <a data-type="indexterm" data-primary="expert interview, blog writing" id="xprvw"/><a data-type="indexterm" data-primary="blog writing" data-secondary="expert interview" id="itvwxp"/>summaries from Google for the top three results, you’ll conduct an interview with an LLM, generating relevant questions to make sure that your article has a unique perspective using an <code>InterviewChain</code> class:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">expert_interview_chain</code> <code class="kn">import</code> <code class="n">InterviewChain</code>
<code class="n">interview_chain</code> <code class="o">=</code> <code class="n">InterviewChain</code><code class="p">(</code><code class="n">topic</code><code class="o">=</code><code class="n">TOPIC</code><code class="p">,</code> <code class="n">document_summaries</code><code class="o">=</code><code class="n">summaries</code><code class="p">)</code>
<code class="n">interview_questions</code> <code class="o">=</code> <code class="n">interview_chain</code><code class="p">()</code>

<code class="k">for</code> <code class="n">question</code> <code class="ow">in</code> <code class="n">interview_questions</code><code class="o">.</code><code class="n">questions</code><code class="p">:</code>
    <code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"Answer the following question: </code><code class="si">{</code><code class="n">question</code><code class="o">.</code><code class="n">question</code><code class="si">}</code><code class="se">\n</code><code class="s2">"</code><code class="p">,</code> <code class="n">flush</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>
    <code class="n">answer</code> <code class="o">=</code> <code class="nb">input</code><code class="p">(</code><code class="sa">f</code><code class="s2">"Answer the following question: </code><code class="si">{</code><code class="n">question</code><code class="o">.</code><code class="n">question</code><code class="si">}</code><code class="se">\n</code><code class="s2">"</code><code class="p">)</code>
    <code class="nb">print</code><code class="p">(</code><code class="s1">'------------------------------------------'</code><code class="p">)</code>
    <code class="n">question</code><code class="o">.</code><code class="n">answer</code> <code class="o">=</code> <code class="n">answer</code></pre>
<dl>
<dt>InterviewChain instantiation</dt>
<dd>
<p>With your topic and obtained summaries in hand, create an instance of    <code>InterviewChain</code>, tailoring it to your data’s unique context.</p>
</dd>
<dt>Generating questions</dt>
<dd>
<p>By simply calling the <code>interview_chain</code>, you kickstart the process of     generating a series of probing questions derived from your summaries.</p>
</dd>
<dt>Interactive Q&amp;A session</dt>
<dd>
<p>Dive into an engaging loop where each derived question is printed,        prompting you for an answer with <code>input()</code>. Your response is then saved   back to the Pydantic object.</p>
</dd>
</dl>
<div data-type="tip"><h1>Give Direction</h1>
<p>Giving an LLM unique answers provides unique context, and this allows an LLM to generate richer, more nuanced responses, ensuring your article offers a fresh and in-depth perspective.</p>
</div>

<p>All of the code for <code>InterviewChain</code> is in <em><a href="https://oreil.ly/0d5Hi">expert_interview_chain.py</a></em>. It has two significant components:</p>
<dl>
<dt>A custom <code>System</code> message</dt>
<dd>
<p>This prompt includes role prompting, previously generated summaries, the topic, and format instructions (for the output parser):</p>
</dd>
</dl>

<pre data-type="programlisting" data-code-language="python"><code class="n">system_message</code> <code class="o">=</code> <code class="s2">"""You are a content SEO researcher. Previously you have</code>
<code class="s2">summarized and extracted key points from SERP results. The insights gained</code>
<code class="s2">will be used to do content research and we will compare the key points,</code>
<code class="s2">insights and summaries across multiple articles. You are now going to</code>
<code class="s2">interview a content expert. You will ask them questions about the following</code>
<code class="s2">topic: </code><code class="si">{topic}</code><code class="s2">.</code>

<code class="s2">You must follow the following rules:</code>
<code class="s2">    - Return a list of questions that you would ask a content expert about</code>
<code class="s2">    the topic.</code>
<code class="s2">    - You must ask at least and at most 5 questions.</code>
<code class="s2">    - You are looking for information gain and unique insights that are not</code>
<code class="s2">    already covered in the </code><code class="si">{document_summaries}</code><code class="s2"> information.</code>
<code class="s2">    - You must ask questions that are open-ended and not yes/no questions.</code>
<code class="s2">    </code><code class="si">{format_instructions}</code><code class="s2"/>
<code class="s2">"""</code></pre>
<dl>
<dt>Output parsers</dt>
<dd>
<p>Diving deeper into the class, you encounter the <code>PydanticOutputParser</code>. This parser actively structures the LLMs responses into parsable, Pydantic <code>InterviewQuestions</code> objects:</p>
</dd>
</dl>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">expert_interview_chain</code> <code class="kn">import</code> <code class="n">InterviewQuestions</code>

<code class="c1"># Set up a parser + inject instructions into the prompt template:</code>
<code class="n">parser</code> <code class="o">=</code> <code class="n">PydanticOutputParser</code><code class="p">(</code><code class="n">pydantic_object</code><code class="o">=</code><code class="n">InterviewQuestions</code><code class="p">)</code></pre>

<p>In essence, you’re orchestrating a conversation with the AI and instructing it to conceive potent questions that amplify <a data-type="indexterm" data-primary="expert interview, blog writing" data-startref="xprvw" id="id1327"/><a data-type="indexterm" data-primary="blog writing" data-secondary="expert interview" data-startref="itvwxp" id="id1328"/>content insights, all the while making customization a breeze.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Generate Outline"><div class="sect1" id="id137">
<h1>Generate Outline</h1>

<p>Including the previous interview <a data-type="indexterm" data-primary="outline generation, blog writing" id="otlgnrt"/><a data-type="indexterm" data-primary="blog writing" data-secondary="outline generation" id="bgwrtgn"/><a data-type="indexterm" data-primary="BlogOutlineGenerator" id="id1329"/>and research, you can generate an outline for the post with <code>BlogOutlineGenerator</code>. The <code>TOPIC</code>, <code>question_answers</code>, and Google <span class="keep-together"><code>summaries</code></span> are passed to provide additional context:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">article_outline_generation</code> <code class="kn">import</code> <code class="n">BlogOutlineGenerator</code>

<code class="n">blog_outline_generator</code> <code class="o">=</code> <code class="n">BlogOutlineGenerator</code><code class="p">(</code><code class="n">topic</code><code class="o">=</code><code class="n">TOPIC</code><code class="p">,</code>
<code class="n">questions_and_answers</code><code class="o">=</code><code class="p">[</code><code class="n">item</code><code class="o">.</code><code class="n">dict</code><code class="p">()</code> <code class="k">for</code> <code class="n">item</code> <code class="ow">in</code> <code class="n">interview_questions</code><code class="o">.</code><code class="n">questions</code><code class="p">])</code>

<code class="n">questions_and_answers</code> <code class="o">=</code> <code class="n">blog_outline_generator</code><code class="o">.</code><code class="n">questions_and_answers</code>
<code class="n">outline_result</code> <code class="o">=</code> <code class="n">blog_outline_generator</code><code class="o">.</code><code class="n">generate_outline</code><code class="p">(</code><code class="n">summaries</code><code class="p">)</code></pre>

<p>Let’s explore the <code>BlogOutlineGenerator</code> class in detail:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">typing</code> <code class="kn">import</code> <code class="n">List</code><code class="p">,</code> <code class="n">Any</code>
<code class="kn">from</code> <code class="nn">pydantic.v1</code> <code class="kn">import</code> <code class="n">BaseModel</code>

<code class="k">class</code> <code class="nc">SubHeading</code><code class="p">(</code><code class="n">BaseModel</code><code class="p">):</code>
    <code class="n">title</code><code class="p">:</code> <code class="nb">str</code> <code class="c1"># Each subheading should have a title.</code>

<code class="k">class</code> <code class="nc">BlogOutline</code><code class="p">(</code><code class="n">BaseModel</code><code class="p">):</code>
    <code class="n">title</code><code class="p">:</code> <code class="nb">str</code>
    <code class="n">sub_headings</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="n">SubHeading</code><code class="p">]</code> <code class="c1"># An outline has many sub_headings</code>

<code class="c1"># Langchain libraries:</code>
<code class="kn">from</code> <code class="nn">langchain.prompts.chat</code> <code class="kn">import</code> <code class="p">(</code><code class="n">ChatPromptTemplate</code><code class="p">,</code>
<code class="n">SystemMessagePromptTemplate</code><code class="p">)</code>
<code class="kn">from</code> <code class="nn">langchain.output_parsers</code> <code class="kn">import</code> <code class="n">PydanticOutputParser</code>
<code class="kn">from</code> <code class="nn">langchain_openai.chat_models</code> <code class="kn">import</code> <code class="n">ChatOpenAI</code>

<code class="c1"># Custom types:</code>
<code class="kn">from</code> <code class="nn">custom_summarize_chain</code> <code class="kn">import</code> <code class="n">DocumentSummary</code>

<code class="k">class</code> <code class="nc">BlogOutlineGenerator</code><code class="p">:</code>
    <code class="k">def</code> <code class="fm">__init__</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">topic</code><code class="p">:</code> <code class="nb">str</code><code class="p">,</code> <code class="n">questions_and_answers</code><code class="p">:</code> <code class="n">Any</code><code class="p">):</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">topic</code> <code class="o">=</code> <code class="n">topic</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">questions_and_answers</code> <code class="o">=</code> <code class="n">questions_and_answers</code>

        <code class="c1"># Create a prompt</code>
        <code class="n">prompt_content</code> <code class="o">=</code> <code class="s2">"""</code>
<code class="s2">        Based on my answers and the summary, generate an outline for a blog</code>
<code class="s2">        article on </code><code class="si">{topic}</code><code class="s2">.</code>
<code class="s2">        topic: </code><code class="si">{topic}</code><code class="s2"/>
<code class="s2">        document_summaries: </code><code class="si">{document_summaries}</code><code class="s2"/>
<code class="s2">        ---</code>
<code class="s2">        Here is the interview which I answered:</code>
<code class="s2">        </code><code class="si">{interview_questions_and_answers}</code><code class="s2"/>
<code class="s2">        ---</code>
<code class="s2">        Output format: </code><code class="si">{format_instructions}</code><code class="s2"/>
<code class="s2">        """</code>

        <code class="n">system_message_prompt</code> <code class="o">=</code>
        <code class="n">SystemMessagePromptTemplate</code><code class="o">.</code><code class="n">from_template</code><code class="p">(</code><code class="n">prompt_content</code><code class="p">)</code>

        <code class="bp">self</code><code class="o">.</code><code class="n">chat_prompt</code> <code class="o">=</code> <code class="n">ChatPromptTemplate</code><code class="o">.</code><code class="n">from_messages</code><code class="p">(</code>
        <code class="p">[</code><code class="n">system_message_prompt</code><code class="p">])</code>

        <code class="c1"># Create an output parser</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">parser</code> <code class="o">=</code> <code class="n">PydanticOutputParser</code><code class="p">(</code><code class="n">pydantic_object</code><code class="o">=</code><code class="n">BlogOutline</code><code class="p">)</code>

        <code class="c1"># Set up the chain</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">outline_chain</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">chat_prompt</code> <code class="o">|</code> <code class="n">ChatOpenAI</code><code class="p">()</code> <code class="o">|</code> <code class="bp">self</code><code class="o">.</code><code class="n">parser</code>

    <code class="k">def</code> <code class="nf">generate_outline</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">summaries</code><code class="p">:</code> <code class="n">List</code><code class="p">[</code><code class="n">DocumentSummary</code><code class="p">])</code> <code class="o">-&gt;</code> <code class="n">Any</code><code class="p">:</code>
        <code class="nb">print</code><code class="p">(</code><code class="s2">"Generating the outline...</code><code class="se">\n</code><code class="s2">---"</code><code class="p">)</code>
        <code class="n">result</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">outline_chain</code><code class="o">.</code><code class="n">invoke</code><code class="p">(</code>
            <code class="p">{</code><code class="s2">"topic"</code><code class="p">:</code> <code class="bp">self</code><code class="o">.</code><code class="n">topic</code><code class="p">,</code>
            <code class="s2">"document_summaries"</code><code class="p">:</code> <code class="p">[</code><code class="n">s</code><code class="o">.</code><code class="n">dict</code><code class="p">()</code> <code class="k">for</code> <code class="n">s</code> <code class="ow">in</code> <code class="n">summaries</code><code class="p">],</code>
            <code class="s2">"interview_questions_and_answers"</code><code class="p">:</code> <code class="bp">self</code><code class="o">.</code><code class="n">questions_and_answers</code><code class="p">,</code>
            <code class="s2">"format_instructions"</code><code class="p">:</code> <code class="bp">self</code><code class="o">.</code><code class="n">parser</code><code class="o">.</code><code class="n">get_format_instructions</code><code class="p">(),</code>
            <code class="p">}</code>
        <code class="p">)</code>
        <code class="nb">print</code><code class="p">(</code><code class="s2">"Finished generating the outline!</code><code class="se">\n</code><code class="s2">---"</code><code class="p">)</code>
        <code class="k">return</code> <code class="n">result</code></pre>

<p>A <code>BlogOutline</code> Pydantic object is created <a data-type="indexterm" data-primary="BlogOutline Pydantic object" id="id1330"/>that contains <code>title</code> and <code>sub_headings</code> keys. Also, the outline chain is set up using LangChain expression language (LCEL) that passes the prompt into the chat model and then finally into the output parser:</p>

<pre data-type="programlisting" data-code-language="python"><code class="c1"># Set up the chain:</code>
<code class="bp">self</code><code class="o">.</code><code class="n">outline_chain</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">chat_prompt</code> <code class="o">|</code> <code class="n">ChatOpenAI</code><code class="p">()</code> <code class="o">|</code> <code class="bp">self</code><code class="o">.</code><code class="n">parser</code></pre>

<p>By using a Pydantic output parser, the <a data-type="indexterm" data-primary="outline generation, blog writing" data-startref="otlgnrt" id="id1331"/><a data-type="indexterm" data-primary="blog writing" data-secondary="outline generation" data-startref="bgwrtgn" id="id1332"/>chain will return a <code>BlogOutline</code> Pydantic object that will be used in future chains.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Text Generation"><div class="sect1" id="id189">
<h1>Text Generation</h1>

<p>After obtaining a summary, interview <a data-type="indexterm" data-primary="text generation" data-secondary="blog writing" id="txtgrnt"/><a data-type="indexterm" data-primary="blog writing" data-secondary="text generation" id="bgrwxgr"/>questions, and a blog post outline, it’s time to start generating the text. The <code>ContentGenerator</code> class integrates SEO expertise with several LLM techniques, which include the following:</p>
<dl>
<dt>Embeddings and retrieval</dt>
<dd>
<p>This efficiently splits and vectorizes original web pages, storing them in the Chroma database and retrieving relevent web page text while writing   each <span class="keep-together">section.</span></p>
</dd>
<dt>Custom memory</dt>
<dd>
<p>While crafting each blog section, it uses memory to avoid repeating the   same information, while also summarizing the conversation if it becomes   too long.</p>
</dd>
<dt>Bespoke context</dt>
<dd>
<p>The LLM has a mixture of information, including your previous interview   insights, what has been said before, and snippets of relevant web page    text from Google:</p>
</dd>
</dl>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">article_generation</code> <code class="kn">import</code> <code class="n">ContentGenerator</code>

<code class="n">content_gen</code> <code class="o">=</code> <code class="n">ContentGenerator</code><code class="p">(</code>
<code class="n">topic</code><code class="o">=</code><code class="n">TOPIC</code><code class="p">,</code> <code class="n">outline</code><code class="o">=</code><code class="n">outline_result</code><code class="p">,</code>
<code class="n">questions_and_answers</code><code class="o">=</code><code class="n">questions_and_answers</code><code class="p">)</code>

<code class="c1"># Vectorize and store the original webpages:</code>
<code class="n">content_gen</code><code class="o">.</code><code class="n">split_and_vectorize_documents</code><code class="p">(</code><code class="n">text_documents</code><code class="p">)</code>
<code class="c1"># Create the blog post:</code>
<code class="n">blog_post</code> <code class="o">=</code> <code class="n">content_gen</code><code class="o">.</code><code class="n">generate_blog_post</code><code class="p">()</code></pre>

<p>All of the source code is within <em><a href="https://oreil.ly/0IFyI">article_generation.py</a></em>, but let’s specifically focus on three components that are key to this chain.</p>

<p>The <code>OnlyStoreAIMemory</code> class is a customized subclass of <code>ConversationSummary​BufferMemory</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">typing</code> <code class="kn">import</code> <code class="n">List</code><code class="p">,</code> <code class="n">Dict</code><code class="p">,</code> <code class="n">Any</code>
<code class="kn">from</code> <code class="nn">langchain.memory</code> <code class="kn">import</code> <code class="n">ConversationSummaryBufferMemory</code>

<code class="kn">from</code> <code class="nn">langchain_core.messages</code> <code class="kn">import</code> <code class="n">SystemMessage</code>

<code class="k">class</code> <code class="nc">OnlyStoreAIMemory</code><code class="p">(</code><code class="n">ConversationSummaryBufferMemory</code><code class="p">):</code>
    <code class="k">def</code> <code class="nf">save_context</code><code class="p">(</code><code class="bp">self</code><code class="p">,</code> <code class="n">inputs</code><code class="p">:</code> <code class="n">Dict</code><code class="p">[</code><code class="nb">str</code><code class="p">,</code> <code class="n">Any</code><code class="p">],</code>
    <code class="n">outputs</code><code class="p">:</code> <code class="n">Dict</code><code class="p">[</code><code class="nb">str</code><code class="p">,</code> <code class="nb">str</code><code class="p">])</code> <code class="o">-&gt;</code> <code class="kc">None</code><code class="p">:</code>
        <code class="n">input_str</code><code class="p">,</code> <code class="n">output_str</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">_get_input_output</code><code class="p">(</code><code class="n">inputs</code><code class="p">,</code> <code class="n">outputs</code><code class="p">)</code>
        <code class="bp">self</code><code class="o">.</code><code class="n">chat_memory</code><code class="o">.</code><code class="n">add_ai_message</code><code class="p">(</code><code class="n">output_str</code><code class="p">)</code></pre>

<p>It’s tailored to ensure that the chat messages memory remains concise and relevant by <em>exclusively storing AI-generated messages</em>.</p>

<p>This deliberate choice bypasses storing retrieved documents that are used within the generation step, preventing memory bloat. Furthermore, the memory mechanism ensures the AI remains aware of its prior writings, enabling it to offer condensed summaries if the accumulated context surpasses set limits.</p>

<p>The <code>generate_blog_post</code> function loops through all of the subheadings and tries to retrieve as many relevant documents as possible while fitting in the current context length:</p>

<pre data-type="programlisting" data-code-language="python"><code class="k">def</code> <code class="nf">generate_blog_post</code><code class="p">(</code><code class="bp">self</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="n">List</code><code class="p">[</code><code class="nb">str</code><code class="p">]:</code>
        <code class="n">blog_post</code> <code class="o">=</code> <code class="p">[]</code>
        <code class="nb">print</code><code class="p">(</code><code class="s2">"Generating the blog post...</code><code class="se">\n</code><code class="s2">---"</code><code class="p">)</code>
        <code class="k">for</code> <code class="n">subheading</code> <code class="ow">in</code> <code class="bp">self</code><code class="o">.</code><code class="n">outline</code><code class="o">.</code><code class="n">sub_headings</code><code class="p">:</code>
            <code class="n">k</code> <code class="o">=</code> <code class="mi">5</code>  <code class="c1"># Initialize k</code>
            <code class="k">while</code> <code class="n">k</code> <code class="o">&gt;=</code> <code class="mi">0</code><code class="p">:</code>
                <code class="k">try</code><code class="p">:</code>
                    <code class="n">relevant_documents</code> <code class="o">=</code> <code class="p">(</code><code class="bp">self</code><code class="o">.</code><code class="n">chroma_db</code><code class="o">.</code><code class="n">as_retriever</code><code class="p">()</code> \
                    <code class="o">.</code><code class="n">invoke</code><code class="p">(</code><code class="n">subheading</code><code class="o">.</code><code class="n">title</code><code class="p">,</code>
                    <code class="n">k</code><code class="o">=</code><code class="n">k</code><code class="p">))</code>
                    <code class="n">section_prompt</code> <code class="o">=</code> <code class="sa">f</code><code class="s2">"""</code>
<code class="s2">                    ...prompt_excluded_for_brevity...</code>
<code class="s2">                    Section text:</code>
<code class="s2">                    """</code>
                    <code class="n">result</code> <code class="o">=</code> <code class="bp">self</code><code class="o">.</code><code class="n">blog_post_chain</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">section_prompt</code><code class="p">)</code>
                    <code class="n">blog_post</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">result</code><code class="p">)</code>
                    <code class="k">break</code>
                <code class="k">except</code> <code class="ne">Exception</code> <code class="k">as</code> <code class="n">e</code><code class="p">:</code>
                    <code class="nb">print</code><code class="p">(</code><code class="sa">f</code><code class="s2">"An error occurred: </code><code class="si">{</code><code class="n">e</code><code class="si">}</code><code class="s2">"</code><code class="p">)</code>
                    <code class="n">k</code> <code class="o">-=</code> <code class="mi">1</code>
                <code class="k">if</code> <code class="n">k</code> <code class="o">&lt;</code> <code class="mi">0</code><code class="p">:</code>
                    <code class="nb">print</code><code class="p">(</code><code class="s1">'''All attempts to fetch relevant documents have</code>
<code class="s1">                    failed. Using an empty string for relevant_documents.</code>
<code class="s1">                    '''</code><code class="p">)</code>
                    <code class="n">relevant_documents</code> <code class="o">=</code> <code class="s2">""</code>
        <code class="nb">print</code><code class="p">(</code><code class="s2">"Finished generating the blog post!</code><code class="se">\n</code><code class="s2">---"</code><code class="p">)</code>
        <code class="k">return</code> <code class="n">blog_post</code></pre>

<p>This function, <code>generate_blog_post</code>, iterates over each subheading. It attempts to fetch up to five relevant documents. If there’s an issue fetching the documents, it smartly decreases the number and tries again. If all attempts fail, it gracefully defaults to no documents.</p>

<p>Finally, the prompt for generating each section is very context rich:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">section_prompt</code> <code class="o">=</code> <code class="sa">f</code><code class="s2">"""You are currently writing the section: </code><code class="si">{</code><code class="n">subheading</code><code class="o">.</code><code class="n">title</code><code class="si">}</code><code class="s2"/>
<code class="s2">---</code>
<code class="s2">Here are the relevant documents for this section: </code><code class="si">{</code><code class="n">relevant_documents</code><code class="si">}</code><code class="s2">.</code>
<code class="s2">If the relevant documents are not useful, you can ignore them.</code>
<code class="s2">You must never copy the relevant documents as this is plagiarism.</code>
<code class="s2">---</code>
<code class="s2">Here are the relevant insights that we gathered from our interview questions</code>
<code class="s2">and answers: </code><code class="si">{</code><code class="bp">self</code><code class="o">.</code><code class="n">questions_and_answers</code><code class="si">}</code><code class="s2">.</code>
<code class="s2">You must include these insights where possible as they are important and will</code>
<code class="s2">help our content rank better.</code>
<code class="s2">---</code>
<code class="s2">You must follow the following principles:</code>
<code class="s2">- You must write the section: </code><code class="si">{</code><code class="n">subheading</code><code class="o">.</code><code class="n">title</code><code class="si">}</code><code class="s2"/>
<code class="s2">- Render the output in .md format</code>
<code class="s2">- Include relevant formats such as bullet points, numbered lists, etc.</code>
<code class="s2">---</code>
<code class="s2">Section text:</code>
<code class="s2">"""</code></pre>

<p>The <code>section_prompt</code> elegantly sets the stage by announcing the specific section you’re working on, using <code>{subheading.title}</code>. But it doesn’t stop there. By feeding the LLM with <code>{relevant_documents}</code>, it offers background and depth, while explicitly cautioning against plagiarism. Moreover, by including insights from your interview via <code>{self.questions_and_answers}</code>, the prompt ensures that valuable information is front and center. Finally, it sets clear expectations on the format, the inclusion of certain features, and the topic at hand. This makes the LLM not just a tool but an <a data-type="indexterm" data-primary="text generation" data-secondary="blog writing" data-startref="txtgrnt" id="id1333"/><a data-type="indexterm" data-primary="blog writing" data-secondary="text generation" data-startref="bgrwxgr" id="id1334"/>informed coauthor, working diligently alongside you to create content.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Writing Style"><div class="sect1" id="id138">
<h1>Writing Style</h1>

<p>Now that the article is written, we <a data-type="indexterm" data-primary="writing style, blog writing" id="wrtsyl"/><a data-type="indexterm" data-primary="blog writing" data-secondary="writing style" id="bgwwty"/><a data-type="indexterm" data-primary="ChatGPT" data-secondary="writing style and" id="cpwrty"/>can go a step further in terms of making it sound uniquely human, by rewriting the content in a specific writing style. This will go a long way in making the content less detectable as obviously AI (though ethically you should still declare any AI assistance) and decreasing the amount of time you spend editing the final draft before publishing.</p>

<p>Before rewriting, you need to know what writing style you want to emulate, be it your own or someone else’s. One common approach is to ask ChatGPT to summarize the writing style of someone who is famous, or at least popular enough in your industry to appear in ChatGPT’s training data. Commonly the model will want to respond with the name of the author and examples of writing, so adding instructions not to and ending the prompt with a bullet point (or an <code>-</code> character in this case) will give you the format you need.</p>

<p>Input:</p>

<pre data-type="programlisting">Describe in detail the writing style of Harry Dry from MarketingExamples.com
Do not mention the writer or source, and respond only with bullet points:
-</pre>

<p>Output:</p>

<pre data-type="programlisting">- Concise and to the point
- Humorous and knowledgeable tone
- Relatable and accessible language
- Uses storytelling to convey ideas
- Relies on examples and case studies
- Provides actionable advice and tips
- Uses subheadings and bullet points for easy readability
- Emphasizes key points or takeaways with bold or italicized text
- Addresses the reader directly, creating a conversational tone</pre>

<p>Often provided only a single sample of text, ChatGPT can generate a reasonable writing style guide, which can then be used for rewriting. Once the writing style is defined, elements can be mixed and matched to arrive at a more ideal style. The following example takes elements from both Mike Taylor’s writing style and Harry Dry’s writing style from the previous example. This is another example of meme unbundling, as discussed in <a data-type="xref" href="ch08.html#vector_databases_08">“Meme Unbundling”</a>:</p>

<pre data-type="programlisting" class="pagebreak-before">Rewrite the article in the following style:

- Concise and to the point
- Professional and knowledgeable tone
- Relatable and accessible language
- Uses storytelling to convey ideas
- Relies on examples and case studies
- Mixes personal anecdotes with industry insights
- Provides actionable advice and tips
- Uses subheadings and bullet points for easy readability</pre>

<p>In practice this part of the AI writing process is the most difficult to get right, and it’s the only one that requires the larger and more expensive GPT-4 model to get passable results. If this part of the process isn’t right, the user can be left doing a lot of manual editing to get the writing in the house style. Given the strategic importance of this prompt, it makes sense to do a round of <a href="https://oreil.ly/H3VtJ">prompt optimization</a>, trying multiple approaches.</p>

<p>When optimizing prompts you can run the same prompt multiple times and check the average performance against an evaluation metric. As an example, here are the results of testing five different prompt approaches against an evaluation metric of embedding distance. The lower the score, the closer the embeddings of the response were to a reference answer (the text as rewritten manually is in the correct style). The prompts tested were as follows:</p>
<dl>
<dt>A</dt>
<dd>
<p>Control—the standard prompt as detailed in the preceding example.</p>
</dd>
<dt>B</dt>
<dd>
<p>One-shot writing sample—we provided one sample of text, and asked GPT-4 to describe the writing style.</p>
</dd>
<dt>C</dt>
<dd>
<p>Three-shot rewriting example—we gave three samples of the input text to GPT-4 and the rewritten version and asked it to describe the writing style.</p>
</dd>
<dt>D</dt>
<dd>
<p>Three-shot writing sample—same as previous, except without the input text, only the final samples of Mike’s writing.</p>
</dd>
</dl>

<p>These prompts were <a href="https://oreil.ly/vRRYO">tested in an experiment we ran</a> against three test cases—memetics, skyscraper technique, and value-based pricing—which were snippets of text that were first generated by ChatGPT on a topic, for example: <em>explain value-based pricing</em>. We then manually rewrote the text in the style we desired to make reference texts for comparison. The embedding distance was calculated by getting the embeddings for the reference text (from OpenAI’s <code>text-embedding-ada-002</code>) and comparing them to the embeddings for the output from the prompt, using <em>cosine similarity</em> (a method for calculating the distance between two sets of numbers), as detailed in <a href="https://oreil.ly/400gJ">LangChain’s embedding evaluator</a> (<a data-type="xref" href="#figure-10-1">Figure 10-1</a>).</p>

<figure><div id="figure-10-1" class="figure">
<img src="assets/pega_1001.png" alt="pega 1001" width="600" height="121"/>
<h6><span class="label">Figure 10-1. </span>Test results from prompt optimization</h6>
</div></figure>

<p>As you can see from the results in <a data-type="xref" href="#figure-10-1">Figure 10-1</a>, some prompts work better than others, and some cases are easier for the AI to deliver on. It’s important to test across multiple cases, with 10 or more runs per case, to get a realistic result for each prompt. Otherwise, the nondeterministic nature of the responses might mean you’ll think the performance was better or worse than you can actually expect when scaling up usage of a prompt. Here was the final resulting prompt that performed best:</p>

<pre data-type="programlisting">You will be provided with the sample text.
Your task is to rewrite the text into a different writing style.
The writing style can be described as follows:
1. Informative and Analytical: The writer presents detailed information
about different strategies, especially the main theme of the text, and breaks
down its benefits, challenges, and implementation steps. This depth of
information shows that the writer has a solid grasp of the topic.
2. Structured and Organized: The writing follows a logical flow, starting
with a brief overview of different approaches, delving into a deep dive on
the topic, and concluding with potential challenges and contexts where it
might be best applied.
3. Conversational Tone with Professionalism: While the information is
presented in a professional manner, the writer uses a conversational tone
("Here’s how to implement..."), which makes it more relatable and easier for
readers to understand.
4. Practical and Actionable: The writer not only explains the concept but
also offers actionable advice ("Here’s how to implement X") with step-by-step
guidance based on real world-experience.
5. Balanced Perspective: The writer doesn’t just present the benefits of the
topic but also discusses its challenges, which gives a well-rounded
perspective to readers.
6. Examples and Analogies: To make concepts clearer, the writer uses
concrete examples (e.g., how much a company might save per month) and
analogies (e.g., making comparisons to popular frames of reference). This
helps readers relate to the concepts and understand them better.
7. Direct and Clear: The writer uses straightforward language without
excessive jargon. Concepts are broken down into digestible bits, making it
accessible for a broad audience, even if they're not well-versed in business
strategies. In essence, this writing style is a blend of professional
analysis with practical, actionable advice, written in a clear and
conversational tone.</pre>
<div data-type="tip"><h1>Evaluate Quality</h1>
<p>Without testing the writing style, it would be hard to guess which prompting strategy would win. With a small amount of testing, you can be more confident this is the correct approach. Testing doesn’t have to be highly organized or systematized, and the builders of many successful AI products like <a href="https://oreil.ly/vu0IU">GitHub Copilot</a> admit their eval process was haphazard and messy (but it got the job done!).</p>
</div>

<p>In this project we’ll use this well-tested example, but you may take this opportunity to try to beat this score. The repository with the reference texts and code is <a href="https://oreil.ly/O6RdB">publicly available on GitHub</a>, and please feel free to contribute to the repository if you find a better approach. One potential path to try is fine-tuning, which may get you better results in matching the writing style if you have enough samples (<a href="https://oreil.ly/OMMKi">OpenAI recommends at least 50</a>). Even if you don’t perform an A/B test (comparing two versions of a prompt to see which one performs better) on this prompt, these results should convince you of the value of testing <a data-type="indexterm" data-primary="writing style, blog writing" data-startref="wrtsyl" id="id1335"/><a data-type="indexterm" data-primary="blog writing" data-secondary="writing style" data-startref="bgwwty" id="id1336"/><a data-type="indexterm" data-primary="ChatGPT" data-secondary="writing style and" data-startref="cpwrty" id="id1337"/>your prompts in general.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Title Optimization"><div class="sect1" id="id139">
<h1>Title Optimization</h1>

<p>You can optimize the content’s title <a data-type="indexterm" data-primary="blog writing" data-secondary="title optimization" id="id1338"/><a data-type="indexterm" data-primary="title, blog writing" id="id1339"/>by generating various options, testing them through A/B prompts, and gauging their effectiveness with a thumbs-up/thumbs-down rating system, as shown in <a data-type="xref" href="#figure-10-2">Figure 10-2</a>.</p>

<figure><div id="figure-10-2" class="figure">
<img src="assets/pega_1002.png" alt="pega 1002" width="596" height="203"/>
<h6><span class="label">Figure 10-2. </span>A simple thumbs-up and thumbs-down rating system</h6>
</div></figure>

<p>After evaluating all the prompts, you’ll be able to see which prompt had the highest average score and the token usage (<a data-type="xref" href="#figure-10-3">Figure 10-3</a>).</p>

<figure><div id="figure-10-3" class="figure">
<img src="assets/pega_1003.png" alt="pega 1003" width="600" height="195"/>
<h6><span class="label">Figure 10-3. </span>Example A/B test results after manually evaluating a prompt</h6>
</div></figure>

<p>If you still aren’t getting the level of quality you need from this prompt, or the rest of the chain, this is a good time to experiment with a prompt optimization framework<a data-type="indexterm" data-primary="DSPy" id="dspyy"/> like <a href="https://oreil.ly/dspy">DSPy</a>. Upon defining an evaluation metric, DSPy tests different combinations of instructions and few-shot examples in your prompts, selecting the best-performing combination automatically. <a href="https://oreil.ly/vercel">See their documentation for examples</a>.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="AI Blog Images"><div class="sect1" id="id190">
<h1>AI Blog Images</h1>

<p>One thing you can do to make your blog <a data-type="indexterm" data-primary="blog writing" data-secondary="images" id="blgwgmi"/><a data-type="indexterm" data-primary="images" data-secondary="blog writing" id="igmgwr"/>look more professional is to add custom illustrations to your blog posts, with a consistent style. At its maximum this may mean training a Dreambooth model, as covered in <a data-type="xref" href="ch09.html#advanced_image_09">Chapter 9</a>, on your brand style guide or a mood board of images with a certain visual consistency or aesthetic quality you value. In many cases, however, training a custom model is not necessary, because a style can be replicated well using simple prompting.</p>

<p>One popular visual style among business-to-business (B2B) companies, <a href="https://oreil.ly/3UHQs">Corporate Memphis</a>, is characterized by its vibrant color palettes, bold and asymmetric shapes, and a mix of both organic and geometric forms. This style arose as a <a href="https://oreil.ly/haoTZ">costly signaling technique</a>, showing that the company could afford to commission custom illustrations from a designer and therefore was serious enough to be trusted. You can replicate this style with AI, saving yourself the cost of custom illustrations, while benefiting from the prior associations formed in consumers’ minds. <a data-type="xref" href="#figure-10-4">Figure 10-4</a> shows an example of Corporate Memphis style generated by Stable Diffusion, via the Stability AI API.</p>

<p>Input:</p>

<pre data-type="programlisting">illustration of websites being linked together.
in the style of Corporate Memphis,
white background, professional, clean lines, warm pastel colors</pre>

<p><a data-type="xref" href="#figure-10-4">Figure 10-4</a> shows the output.</p>

<figure><div id="figure-10-4" class="figure">
<img src="assets/pega_1004.png" alt="pega 1004" width="600" height="600"/>
<h6><span class="label">Figure 10-4. </span>Corporate Memphis: “websites being linked together”</h6>
</div></figure>
<div data-type="tip"><h1>Give Direction</h1>
<p>Stable Diffusion is trained on many different styles, including obscure or niche styles like Corporate Memphis. If you know the name of a style, often that’s all that’s needed to guide the model toward the desired image. You can find a variety of art styles within this <a href="https://oreil.ly/nxEzu">visual prompt builder</a>.</p>
</div>

<p>In our blog writing project we could ask the user for an idea of what image they want to accompany the blog post, but let’s make it easier for them and automate this step. You can make an API call to ChatGPT and get back an idea for what could go in the image. When you get that response, it can form the basis of your prompt to Stability AI, a technique called <em>meta-prompting</em>, where one AI model writes the prompt for another AI model.</p>

<p class="pagebreak-before">Input:</p>

<pre data-type="programlisting">Describe an image that would go well at the top of this article:

{text}</pre>

<p>Output:</p>

<pre data-type="programlisting">A seamless collage or mosaic of diverse cultural elements from around the world,
including traditional dances, art pieces, landmarks, and people in various
traditional attires, symbolizing the interconnectedness of human cultures.</pre>

<p>Stability AI hosts Stable Diffusion, including the latest models like Stable Diffusion XL, in their DreamStudio platform. You can also call them <a href="https://oreil.ly/XD_jQ">via API</a> or via the Stability AI SDK (a library that simplifies the process of making the API call). In the following example, we’ll create a function for calling Stability AI with our prompt.</p>

<p>Input:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">base64</code>
<code class="kn">import</code> <code class="nn">os</code>
<code class="kn">import</code> <code class="nn">requests</code>
<code class="kn">import</code> <code class="nn">uuid</code>

<code class="n">engine_id</code> <code class="o">=</code> <code class="s2">"stable-diffusion-xl-1024-v1-0"</code>
<code class="n">api_host</code> <code class="o">=</code> <code class="n">os</code><code class="o">.</code><code class="n">getenv</code><code class="p">(</code><code class="s1">'API_HOST'</code><code class="p">,</code> <code class="s1">'https://api.stability.ai'</code><code class="p">)</code>
<code class="n">api_key</code> <code class="o">=</code> <code class="n">os</code><code class="o">.</code><code class="n">getenv</code><code class="p">(</code><code class="s2">"STABILITY_API_KEY"</code><code class="p">)</code>

<code class="k">def</code> <code class="nf">generate_image</code><code class="p">(</code><code class="n">prompt</code><code class="p">):</code>
    <code class="n">response</code> <code class="o">=</code> <code class="n">requests</code><code class="o">.</code><code class="n">post</code><code class="p">(</code>
        <code class="sa">f</code><code class="s2">"</code><code class="si">{</code><code class="n">api_host</code><code class="si">}</code><code class="s2">/v1/generation/</code><code class="si">{</code><code class="n">engine_id</code><code class="si">}</code><code class="s2">/text-to-image"</code><code class="p">,</code>
        <code class="n">headers</code><code class="o">=</code><code class="p">{</code>
            <code class="s2">"Content-Type"</code><code class="p">:</code> <code class="s2">"application/json"</code><code class="p">,</code>
            <code class="s2">"Accept"</code><code class="p">:</code> <code class="s2">"application/json"</code><code class="p">,</code>
            <code class="s2">"Authorization"</code><code class="p">:</code> <code class="sa">f</code><code class="s2">"Bearer </code><code class="si">{</code><code class="n">api_key</code><code class="si">}</code><code class="s2">"</code>
        <code class="p">},</code>
        <code class="n">json</code><code class="o">=</code><code class="p">{</code>
            <code class="s2">"text_prompts"</code><code class="p">:</code> <code class="p">[</code>
                <code class="p">{</code>
                    <code class="s2">"text"</code><code class="p">:</code><code class="s1">'''an illustration of "+prompt+". in the style of</code>
<code class="s1">                    Corporate Memphis,</code>
<code class="s1">                    white background, professional, clean lines, warm pastel</code>
<code class="s1">                    colors'''</code>
                <code class="p">}</code>
            <code class="p">],</code>
            <code class="s2">"cfg_scale"</code><code class="p">:</code> <code class="mi">7</code><code class="p">,</code>
            <code class="s2">"height"</code><code class="p">:</code> <code class="mi">1024</code><code class="p">,</code>
            <code class="s2">"width"</code><code class="p">:</code> <code class="mi">1024</code><code class="p">,</code>
            <code class="s2">"samples"</code><code class="p">:</code> <code class="mi">1</code><code class="p">,</code>
            <code class="s2">"steps"</code><code class="p">:</code> <code class="mi">30</code><code class="p">,</code>
        <code class="p">},</code>
    <code class="p">)</code>

    <code class="k">if</code> <code class="n">response</code><code class="o">.</code><code class="n">status_code</code> <code class="o">!=</code> <code class="mi">200</code><code class="p">:</code>
        <code class="k">raise</code> <code class="ne">Exception</code><code class="p">(</code><code class="s2">"Non-200 response: "</code> <code class="o">+</code> <code class="nb">str</code><code class="p">(</code><code class="n">response</code><code class="o">.</code><code class="n">text</code><code class="p">))</code>

    <code class="n">data</code> <code class="o">=</code> <code class="n">response</code><code class="o">.</code><code class="n">json</code><code class="p">()</code>

    <code class="n">image_paths</code> <code class="o">=</code> <code class="p">[]</code>

    <code class="k">for</code> <code class="n">i</code><code class="p">,</code> <code class="n">image</code> <code class="ow">in</code> <code class="nb">enumerate</code><code class="p">(</code><code class="n">data</code><code class="p">[</code><code class="s2">"artifacts"</code><code class="p">]):</code>
        <code class="n">filename</code> <code class="o">=</code> <code class="sa">f</code><code class="s2">"</code><code class="si">{</code><code class="n">uuid</code><code class="o">.</code><code class="n">uuid4</code><code class="p">()</code><code class="o">.</code><code class="n">hex</code><code class="p">[:</code><code class="mi">7</code><code class="p">]</code><code class="si">}</code><code class="s2">.png"</code>
        <code class="k">with</code> <code class="nb">open</code><code class="p">(</code><code class="n">filename</code><code class="p">,</code> <code class="s2">"wb"</code><code class="p">)</code> <code class="k">as</code> <code class="n">f</code><code class="p">:</code>
            <code class="n">f</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="n">base64</code><code class="o">.</code><code class="n">b64decode</code><code class="p">(</code><code class="n">image</code><code class="p">[</code><code class="s2">"base64"</code><code class="p">]))</code>

        <code class="n">image_paths</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">filename</code><code class="p">)</code>

    <code class="k">return</code> <code class="n">image_paths</code>

<code class="n">prompt</code> <code class="o">=</code> <code class="s2">"""A seamless collage or mosaic of diverse cultural elements from</code>
<code class="s2">around the world, including traditional dances, art pieces, landmarks, and</code>
<code class="s2">people in various traditional attires, symbolizing the interconnectedness of</code>
<code class="s2">human cultures."""</code>

<code class="n">generate_image</code><code class="p">(</code><code class="n">prompt</code><code class="p">)</code></pre>

<p><a data-type="xref" href="#figure-10-5">Figure 10-5</a> shows the output.</p>

<figure><div id="figure-10-5" class="figure">
<img src="assets/pega_1005.png" alt="pega 1005" width="600" height="600"/>
<h6><span class="label">Figure 10-5. </span>A seamless collage or mosaic of diverse cultural elements from around the world</h6>
</div></figure>

<p>To encapsulate the whole system for image generation, you can bring the call to ChatGPT and the resulting call to Stability AI together in one function that uses the <code>outline_result.title</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">from</code> <code class="nn">image_generation_chain</code> <code class="kn">import</code> <code class="n">create_image</code>
<code class="n">image</code> <code class="o">=</code> <code class="n">create_image</code><code class="p">(</code><code class="n">outline_result</code><code class="o">.</code><code class="n">title</code><code class="p">)</code></pre>

<p>The <code>create_image</code> function in <em><a href="https://oreil.ly/cWpXH">image_generation_chain.py</a></em> utilizes Stable Diffusion to create an image based on a generated title from GPT-4:</p>

<pre data-type="programlisting" data-code-language="python"><code class="kn">import</code> <code class="nn">base64</code>
<code class="kn">from</code> <code class="nn">langchain_openai.chat_models</code> <code class="kn">import</code> <code class="n">ChatOpenAI</code>
<code class="kn">from</code> <code class="nn">langchain_core.messages</code> <code class="kn">import</code> <code class="n">SystemMessage</code>
<code class="kn">import</code> <code class="nn">os</code>
<code class="kn">import</code> <code class="nn">requests</code>
<code class="kn">import</code> <code class="nn">uuid</code>

<code class="n">engine_id</code> <code class="o">=</code> <code class="s2">"stable-diffusion-xl-1024-v1-0"</code>
<code class="n">api_host</code> <code class="o">=</code> <code class="n">os</code><code class="o">.</code><code class="n">getenv</code><code class="p">(</code><code class="s2">"API_HOST"</code><code class="p">,</code> <code class="s2">"https://api.stability.ai"</code><code class="p">)</code>
<code class="n">api_key</code> <code class="o">=</code> <code class="n">os</code><code class="o">.</code><code class="n">getenv</code><code class="p">(</code><code class="s2">"STABILITY_API_KEY"</code><code class="p">,</code> <code class="s2">"INSERT_YOUR_IMAGE_API_KEY_HERE"</code><code class="p">)</code>

<code class="k">if</code> <code class="n">api_key</code> <code class="o">==</code> <code class="s2">"INSERT_YOUR_IMAGE_API_KEY_HERE"</code><code class="p">:</code>
    <code class="k">raise</code> <code class="ne">Exception</code><code class="p">(</code>
        <code class="sd">'''You need to insert your API key in the</code>
<code class="sd">        image_generation_chain.py file.'''</code>
        <code class="s2">"You can get your API key from https://platform.openai.com/"</code>
    <code class="p">)</code>


<code class="k">def</code> <code class="nf">create_image</code><code class="p">(</code><code class="n">title</code><code class="p">)</code> <code class="o">-&gt;</code> <code class="nb">str</code><code class="p">:</code>
    <code class="n">chat</code> <code class="o">=</code> <code class="n">ChatOpenAI</code><code class="p">()</code>
    <code class="c1"># 1. Generate the image prompt:</code>
    <code class="n">image_prompt</code> <code class="o">=</code> <code class="n">chat</code><code class="o">.</code><code class="n">invoke</code><code class="p">(</code>
        <code class="p">[</code>
            <code class="n">SystemMessage</code><code class="p">(</code><code class="n">content</code><code class="o">=</code><code class="sa">f</code><code class="s2">"""Create an image prompt</code>
<code class="s2">            that will be used for Midjourney for </code><code class="si">{</code><code class="n">title</code><code class="si">}</code><code class="s2">."""</code>
            <code class="p">)</code>
        <code class="p">]</code>
    <code class="p">)</code><code class="o">.</code><code class="n">content</code>


    <code class="c1"># 2. Generate the image::</code>
    <code class="n">response</code> <code class="o">=</code> <code class="n">requests</code><code class="o">.</code><code class="n">post</code><code class="p">(</code>
        <code class="sa">f</code><code class="s2">"</code><code class="si">{</code><code class="n">api_host</code><code class="si">}</code><code class="s2">/v1/generation/</code><code class="si">{</code><code class="n">engine_id</code><code class="si">}</code><code class="s2">/text-to-image"</code><code class="p">,</code>
        <code class="n">headers</code><code class="o">=</code><code class="p">{</code>
            <code class="s2">"Content-Type"</code><code class="p">:</code> <code class="s2">"application/json"</code><code class="p">,</code>
            <code class="s2">"Accept"</code><code class="p">:</code> <code class="s2">"application/json"</code><code class="p">,</code>
            <code class="s2">"Authorization"</code><code class="p">:</code> <code class="sa">f</code><code class="s2">"Bearer </code><code class="si">{</code><code class="n">api_key</code><code class="si">}</code><code class="s2">"</code><code class="p">,</code>
        <code class="p">},</code>
        <code class="n">json</code><code class="o">=</code><code class="p">{</code>
            <code class="s2">"text_prompts"</code><code class="p">:</code> <code class="p">[</code>
                <code class="p">{</code>
                    <code class="s2">"text"</code><code class="p">:</code> <code class="sa">f</code><code class="s1">'''an illustration of </code><code class="si">{</code><code class="n">image_prompt</code><code class="si">}</code><code class="s1"> in the</code>
<code class="s1">                    style of Corporate Memphis, white background,</code>
<code class="s1">                    professional, clean lines, warm pastel colors'''</code>
                <code class="p">}</code>
            <code class="p">],</code>
            <code class="s2">"cfg_scale"</code><code class="p">:</code> <code class="mi">7</code><code class="p">,</code>
            <code class="s2">"height"</code><code class="p">:</code> <code class="mi">1024</code><code class="p">,</code>
            <code class="s2">"width"</code><code class="p">:</code> <code class="mi">1024</code><code class="p">,</code>
            <code class="s2">"samples"</code><code class="p">:</code> <code class="mi">1</code><code class="p">,</code>
            <code class="s2">"steps"</code><code class="p">:</code> <code class="mi">30</code><code class="p">,</code>
        <code class="p">},</code>
    <code class="p">)</code>

    <code class="k">if</code> <code class="n">response</code><code class="o">.</code><code class="n">status_code</code> <code class="o">!=</code> <code class="mi">200</code><code class="p">:</code>
        <code class="k">raise</code> <code class="ne">Exception</code><code class="p">(</code><code class="s2">"Non-200 response: "</code> <code class="o">+</code> <code class="nb">str</code><code class="p">(</code><code class="n">response</code><code class="o">.</code><code class="n">text</code><code class="p">))</code>

    <code class="n">data</code> <code class="o">=</code> <code class="n">response</code><code class="o">.</code><code class="n">json</code><code class="p">()</code>
    <code class="n">image_paths</code> <code class="o">=</code> <code class="p">[]</code>

    <code class="k">for</code> <code class="n">i</code><code class="p">,</code> <code class="n">image</code> <code class="ow">in</code> <code class="nb">enumerate</code><code class="p">(</code><code class="n">data</code><code class="p">[</code><code class="s2">"artifacts"</code><code class="p">]):</code>
        <code class="n">filename</code> <code class="o">=</code> <code class="sa">f</code><code class="s2">"</code><code class="si">{</code><code class="n">uuid</code><code class="o">.</code><code class="n">uuid4</code><code class="p">()</code><code class="o">.</code><code class="n">hex</code><code class="p">[:</code><code class="mi">7</code><code class="p">]</code><code class="si">}</code><code class="s2">.png"</code>
        <code class="k">with</code> <code class="nb">open</code><code class="p">(</code><code class="n">filename</code><code class="p">,</code> <code class="s2">"wb"</code><code class="p">)</code> <code class="k">as</code> <code class="n">f</code><code class="p">:</code>
            <code class="n">f</code><code class="o">.</code><code class="n">write</code><code class="p">(</code><code class="n">base64</code><code class="o">.</code><code class="n">b64decode</code><code class="p">(</code><code class="n">image</code><code class="p">[</code><code class="s2">"base64"</code><code class="p">]))</code>
        <code class="n">image_paths</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">filename</code><code class="p">)</code>
    <code class="k">return</code> <code class="n">image_paths</code></pre>

<p>Here’s the high-level process:</p>
<ol>
<li>
<p>With the <code>ChatOpenAI</code> model, you’ll craft an image prompt for your given <code>title</code>.</p>
</li>
<li>
<p>Using the Stability AI API, you’ll send this prompt to generate an image with precise styling instructions.</p>
</li>
<li>
<p>Then you’ll decode and save this image locally using a unique filename and return its path.</p>
</li>

</ol>

<p>With these steps, you’re not just prompting the AI to create textual content, but you’re directing it to bring your prompts to life visually.</p>

<p>This system is flexible based on whatever style you decide to use for blog images. Parameters can be adjusted as needed, and perhaps this API call can be replaced in future with a call to a custom fine-tuned Dreambooth model of your own. In the meantime, however, you have a quick and easy way to generate a custom image for each blog post, without <a data-type="indexterm" data-primary="blog writing" data-secondary="images" data-startref="blgwgmi" id="id1340"/><a data-type="indexterm" data-primary="images" data-secondary="blog writing" data-startref="igmgwr" id="id1341"/>requiring any further input from the user, in a consistent visual style.</p>
</div></section>






<section data-type="sect1" class="pagebreak-before less_space" data-pdf-bookmark="User Interface"><div class="sect1" id="id140">
<h1>User Interface</h1>

<p>Now that you have your script working end <a data-type="indexterm" data-primary="user interface" id="ustrfc"/>to end, you probably want to make it a little easier to work with, and maybe even get it into the hands of people who can give you feedback. The frontend of many AI tools in production is typically built using JavaScript, specifically the <a href="https://nextjs.org">NextJS</a> framework based on React. This is usually paired with a CSS library such as <a href="https://tailwindcss.com">Tailwind CSS</a>, which makes rapid prototyping of design elements easier.</p>

<p>However, most of your AI code is likely in Python at this stage, and switching programming languages and development environments can be a daunting challenge. As well as learning JavaScript, NextJS, and Tailwind, you may also run into a series of issues getting a server running for your Python code, and a database live for your application and user data, and then integrating all of that with a frontend web design.</p>

<p>Instead of spending a lot of time spinning up servers, building databases, and adjusting button colors, it might make sense to create a simple prototype frontend to get early feedback, before investing too much at this stage in an unproven idea. Once you have built and tested a simple interface, you’ll have a better understanding of what to build when you do need to get your app production-ready.</p>

<p>For launching simple user interfaces for AI-based prototypes, there are several popular open source interfaces, including <a href="https://www.gradio.app">gradio</a> and <a href="https://streamlit.io">Streamlit</a>. Gradio <a data-type="indexterm" data-primary="Gradio" id="id1342"/><a data-type="indexterm" data-primary="Streamlit" id="id1343"/>was acquired by HuggingFace and powers the web user interface for many interactive demos of open source AI models, famously including the <a href="https://oreil.ly/GlwJT">AUTOMATIC1111</a> Stable Diffusion Web UI. You can quickly build a Gradio interface to make it easier to run your code locally, as well as sharing the prototype to get feedback.</p>

<p>We’ve created an interface that allows you to automate the entire process within two steps. You can get access to the <a href="https://oreil.ly/HNqVX">gradio source code here</a>.</p>

<p>Then run the gradio application by going into the <a href="https://oreil.ly/chapter10">chapter_10 folder</a> within your terminal and running <code>python3 gradio_code_example.py</code>. The script will ask you to enter a <code>SERPAPI_API_KEY</code> and a  <code>STABILITY_API_KEY</code> in your terminal.</p>

<p>Then you can access the gradio interface as shown in <a data-type="xref" href="#figure-10-6">Figure 10-6</a>.</p>

<figure><div id="figure-10-6" class="figure">
<img src="assets/pega_1006.png" alt="pega 1006" width="526" height="757"/>
<h6><span class="label">Figure 10-6. </span>Gradio user interface</h6>
</div></figure>

<p>When you run gradio, you get an inline interface you can use directly or a URL that you can click to open the web interface in your browser. If you run gradio with the parameter <code>share=True</code>, for example <code>demo.launch(share=True)</code>, you get a publicly accessible link to share with friends, coworkers, or early users to get feedback on your prototype.</p>

<p>After initializing the interface, input a topic by clicking the Summarize and Generate Questions button. This will then collect and summarize the Google results as well as generate interview questions.</p>

<p>You’ll then need to fill in the answers for each question. Finally, click the Generate Blog Post &amp; Image button, which will take all the questions, answers, and summaries and will create an entire blog post and image using GPT-4!</p>
<div data-type="tip"><h1>Evaluate Quality</h1>
<p>The most valuable evaluation data in AI is human feedback, as it has been the key to many AI alignment breakthroughs, including those that power ChatGPT. Asking for feedback from users via a user interface, or even building feedback mechanisms into your product, helps you identify and fix edge cases.</p>
</div>

<p>If you are building for research purposes or want to contribute to the open source community, consider sharing your gradio demo on Hugging Face Spaces. Hugging Face Spaces allows anyone to <a data-type="indexterm" data-primary="user interface" data-startref="ustrfc" id="id1344"/>host their gradio demos freely, and uploading your project only takes a few minutes. New spaces can be created via the <a href="https://oreil.ly/pSrP3">Hugging Face website</a>, or done programmatically using the Hugging Face API.</p>
</div></section>






<section data-type="sect1" data-pdf-bookmark="Summary"><div class="sect1" id="id360">
<h1>Summary</h1>

<p>Congratulations! You’ve journeyed through the comprehensive world of prompt engineering for generative AI. You started with learning the prompt engineering principles and explored the historical context of LLMs, gaining awareness of their capabilities and the privacy concerns they pose.</p>

<p>You learned how to extract structured data, apply best practices of prompt engineering, and familiarize yourself with an LLM package called LangChain. Then you discovered vector databases for storing and querying text based on similarity and ventured into the world of autonomous agents.</p>

<p>Also, you immersed yourself in image generation techniques using diffusion models, learning how to navigate through this latent space. Your journey covered everything from format modifiers and art-style replication to inpainting and outpainting techniques. Moreover, you explored more advanced usage cases such as prompt expansion, meme mapping, and CLIP Interrogator, alongside many others.</p>

<p>Finally, you transitioned toward utilizing prompt engineering for content writing. You learned about creating a blog writing service that generates posts based on user responses, mimicking their writing styles, along with topic research strategies.</p>

<p>Overall, this journey not only enriched your knowledge but also equipped you with practical skills, setting you up to work professionally in the field of prompt <span class="keep-together">engineering.</span></p>

<p>It’s been our pleasure to guide you through the wide domain of prompt engineering for generative AI. Thank you for staying with us to the end of this book. We trust it will become a useful tool in all your future work with AI.</p>

<p>We would also greatly appreciate hearing your thoughts about the book, as well as any remarkable projects you create using the techniques we’ve discussed.</p>

<p>Please feel free to share your feedback or showcase your work by emailing us at <a href="mailto:hi@brightpool.dev">hi@brightpool.dev</a>. Once again, thank you! Your curiosity and perseverance are what shapes the future of this exciting field, and we can’t wait to see what you contribute.</p>

<p>Happy prompting!</p>
</div></section>
</div></section></div></div></body></html>