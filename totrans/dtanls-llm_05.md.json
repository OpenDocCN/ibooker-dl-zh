["```py\npip install pandas==2.2\n```", "```py\npip install scikit-learn==1.3\n```", "```py\nThis movie is a piece of reality very well realized ...  #1\nIs the sentiment positive or negative?              #2\nAnswer (\"Positive\"/\"Negative\"):   #3\n```", "```py\n[Review]                           #1\nIs the sentiment positive or negative?  #2\nAnswer (\"Positive\"/\"Negative\"):   #3\n```", "```py\ndef create_prompt(text):\n    task = 'Is the sentiment positive or negative?'\n    answer_format = 'Answer (\"Positive\"/\"Negative\")'\n    return f'{text}\\n{task}\\n{answer_format}:'\n```", "```py\nimport openai\nclient = openai.OpenAI()\n\nresponse = client.chat.completions.create(\n    model='gpt-4o',\n    messages=[\n        {'role':'user', 'content':prompt}\n        ]\n    )\n```", "```py\nimport openai\nclient = openai.OpenAI()\n\ndef call_llm(prompt):\n    for nr_retries in range(1, 4):\n        try:\n            response = client.chat.completions.create(\n                model='gpt-4o',\n                messages=[\n                    {'role':'user', 'content':prompt}\n                    ]\n                )\n            return response.choices[0].message.content\n        except:\n            time.sleep(nr_retries * 2)\n    raise Exception('Cannot query OpenAI model!')\n```", "```py\nimport argparse  #1\nimport openai\nimport pandas as pd\nimport time\n\nclient = openai.OpenAI()\n\ndef create_prompt(text):                      #2\n    \"\"\" Generates prompt for sentiment classification.\n\n    Args:\n        text: classify this text.\n\n    Returns:\n        input for LLM.\n    \"\"\"\n    task = 'Is the sentiment positive or negative?'\n    answer_format = 'Answer (\"Positive\"/\"Negative\")'\n    return f'{text}\\n{task}\\n{answer_format}:'\n\ndef call_llm(prompt):                           #3\n    \"\"\" Query large language model and return answer.\n\n    Args:\n        prompt: input prompt for language model.\n\n    Returns:\n        Answer by language model.\n    \"\"\"\n    for nr_retries in range(1, 4):\n        try:\n            response = client.chat.completions.create(\n                model='gpt-4o',\n                messages=[\n                    {'role':'user', 'content':prompt}\n                    ]\n                )\n            return response.choices[0].message.content\n        except:\n            time.sleep(nr_retries * 2)\n    raise Exception('Cannot query OpenAI model!')\n\ndef classify(text):       #4\n    \"\"\" Classify input text.\n\n    Args:\n        text: assign this text to a class label.\n\n    Returns:\n        name of class.\n    \"\"\"\n    prompt = create_prompt(text)\n    label = call_llm(prompt)\n    return label\n\nif __name__ == '__main__':  #5\n\n    parser = argparse.ArgumentParser()       #6\n    parser.add_argument('file_path', type=str, help='Path to input file')\n    args = parser.parse_args()\n\n    df = pd.read_csv(args.file_path)     #7\n    df['class'] = df['text'].apply(classify)  #8\n    statistics = df['class'].value_counts()   #9\n    print(statistics)\n    df.to_csv('result.csv')\n```", "```py\npython listing1.py reviews.csv\n```", "```py\nHi!\nMy name is Martin, I would love to do a summer internship at Banana! \nA bit about myself: I am currently working on a Bachelor of Computer Science\nat Stanford University, my current GPA is 4.0.\n```", "```py\n #1\nExtract the following properties into a table:\nname,GPA,Degree\n #2\nText source: My name is Martin, I would love to do a summer \ninternship at Banana! A bit about myself: I am currently \nworking on a Bachelor of Computer Science at Stanford \nUniversity, my current GPA is 4.0.\n #3\nMark the beginning of the table with <BeginTable> and the end with <EndTable>. Separate rows by newline symbols and separate fields by pipe\nsymbols (|). Omit the table header and insert values in the attribute \norder from above. Use the placeholder <NA> if the value for an attribute \nis not available.\n```", "```py\n #1\nExtract the following properties into a table:\n[List of attributes] \n #2\nText source: [Email] \n #3\nMark the beginning of the table with <BeginTable> and the end with <EndTable>.\nSeparate rows by newline symbols and separate fields by pipe symbols (|).\nOmit the table header and insert values in the attribute order from above.\nUse the placeholder <NA> if the value for an attribute is not available.\n```", "```py\ndef create_prompt(text, attributes):\n    parts = []\n     #1\n    parts += ['Extract the following properties into a table:']\n    parts += [','.join(attributes)]\n\n    parts += [f'Text source: {text}']  #2\n         #3\n    parts += [\n        ('Mark the beginning of the table with <BeginTable> '\n        'and the end with <EndTable>.')]\n    parts += [\n        ('Separate rows by newline symbols and separate '\n        'fields by pipe symbols (|).')]\n    parts += [\n        ('Omit the table header and insert values in '\n        'the attribute order from above.')]\n    parts += [\n        ('Use the placeholder <NA> if the value '\n        'for an attribute is not available.')]\n    return '\\n'.join(parts)\n```", "```py\n| Martin | 4.0 | Bachelor of Computer Science |\n```", "```py\nimport re\n\ndef post_process(raw_answer):\n    table_text = re.findall(      #1\n        '<BeginTable>(.*)<EndTable>', \n        raw_answer, re.DOTALL)[0]\n\n    results = []\n    for raw_row in table_text.split('\\n'):  #2\n        if raw_row:                    #3\n            row = raw_row.split('|')\n            row = [field.strip() for field in row]\n            row = [field for field in row if field]\n            results.append(row)\n    return results\n```", "```py\nimport argparse  #1\nimport openai\nimport pandas as pd\nimport re\nimport time\n\nclient = openai.OpenAI()\n\ndef create_prompt(text, attributes):              #2\n    \"\"\" Generates prompt for information extraction.\n\n    Args:\n        text: extract information from this text.\n        attributes: list of attributes.\n\n    Returns:\n        input for LLM.\n    \"\"\"\n    parts = []\n    parts += ['Extract the following properties into a table:']\n    parts += [','.join(attributes)]\n    parts += [f'Text source: {text}']\n    parts += [\n        ('Mark the beginning of the table with <BeginTable> '\n        'and the end with <EndTable>.')]\n    parts += [\n        ('Separate rows by newline symbols and separate '\n        'fields by pipe symbols (|).')]\n    parts += [\n        ('Omit the table header and insert values in '\n        'the attribute order from above.')]\n    parts += [\n        ('Use the placeholder <NA> if the value '\n        'for an attribute is not available.')]\n    return '\\n'.join(parts)\n\ndef call_llm(prompt):                             #3\n    \"\"\" Query large language model and return answer.\n\n    Args:\n        prompt: input prompt for language model.\n\n    Returns:\n        Answer by language model.\n    \"\"\"\n    for nr_retries in range(1, 4):\n        try:\n            response = client.chat.completions.create(\n                model='gpt-4o',\n                messages=[\n                    {'role':'user', 'content':prompt}\n                    ]\n                )\n            return response.choices[0].message.content\n        except:\n            time.sleep(nr_retries * 2)\n    raise Exception('Cannot query OpenAI model!')\n\ndef post_process(raw_answer):             #4\n    \"\"\" Extract fields from raw text answer.\n\n    Args:\n        raw_answer: raw text generated by LLM.\n\n    Returns:\n        list of result rows.\n    \"\"\"\n    table_text = re.findall(\n        '<BeginTable>(.*)<EndTable>', \n        raw_answer, re.DOTALL)[0]\n\n    results = []\n    for raw_row in table_text.split('\\n'):\n        if raw_row:\n            row = raw_row.split('|')\n            row = [field.strip() for field in row]\n            row = [field for field in row if field]\n            results.append(row)\n    return results\n\ndef extract_rows(text, attributes):           #5\n    \"\"\" Extract values for attributes from text.\n\n    Args:\n        text: extract information from this text.\n        attributes: list of attributes to extract.\n\n    Returns:\n        list of rows with attribute values.\n    \"\"\"\n    prompt = create_prompt(text, attributes)\n    result_text = call_llm(prompt)\n    result_rows = post_process(result_text)\n    return result_rows\n\nif __name__ == '__main__':         #6\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument('file_path', type=str, help='Path to input file')\n    parser.add_argument('attributes', type=str, help='Attribute list')\n    args = parser.parse_args()\n\n    input_df = pd.read_csv(args.file_path)\n    attributes = args.attributes.split('|')\n\n    extractions = []\n    for text in input_df['text'].values:          #7\n        extractions += extract_rows(text, attributes)\n\n    result_df = pd.DataFrame(extractions)\n    result_df.columns = attributes\n    result_df.to_csv('result.csv')\n```", "```py\npython listing2.py biographies.csv \n  \"name|city of birth|date of birth\"\n```", "```py\n    name    city of birth    date of birth\n0    Sergey Mikhailovich Brin    Moscow    August 21, 1973\n1    Martin Luther King Jr.    Atlanta, Georgia    January 15, 1929\n2    Anne E. Wojcicki    <NA>    July 28, 1973\n3    Maria Salomea Sk≈Çodowska-Curie    Warsaw    7 November 1867\n4    Alan Mathison Turing    Maida Vale, London    23 June 1912\n```", "```py\nimport openai\nclient = openai.OpenAI()\n\nresponse = client.embeddings.create(\n    model='text-embedding-ada-002',\n    input=text)\n```", "```py\nCreateEmbeddingResponse(\n    data=[\n        Embedding(embedding=[                            #1\n            -0.005983137525618076, -0.000303583248751238, ...], \n            index=0, object='embedding')], \n    model='text-embedding-ada-002',    #2\n    object='list', \n    usage=Usage(prompt_tokens=517, total_tokens=517))  #3\n```", "```py\nresponse.data[0].embedding\n```", "```py\nimport openai\nclient = openai.OpenAI()\n\ndef get_embedding(text):\n    for nr_retries in range(1, 4):\n        try:\n            response = client.embeddings.create(\n                model='text-embedding-ada-002',\n                input=text)\n            return response.data[0].embedding\n        except:\n            time.sleep(nr_retries * 2)\n    raise Exception('Cannot query OpenAI model!')\n```", "```py\ndef get_kmeans(embeddings, k):\n    kmeans = KMeans(n_clusters=k, init='k-means++')\n    kmeans.fit(embeddings)\n    return kmeans.labels_\n```", "```py\nimport argparse\nimport openai\nimport pandas as pd\nimport time\n\nfrom sklearn.cluster import KMeans\n\nclient = openai.OpenAI()\n\ndef get_embedding(text):                        #1\n    \"\"\" Calculate embedding vector for input text.\n\n    Args:\n        text: calculate embedding for this text.\n\n    Returns:\n        Vector representation of input text.\n    \"\"\"\n    for nr_retries in range(1, 4):\n        try:\n            response = client.embeddings.create(\n                model='text-embedding-ada-002',\n                input=text)\n            return response.data[0].embedding\n        except:\n            time.sleep(nr_retries * 2)\n    raise Exception('Cannot query OpenAI model!')\n\ndef get_kmeans(embeddings, k):                #2\n    \"\"\" Cluster embedding vectors using K-means.\n\n    Args:\n        embeddings: embedding vectors.\n        k: number of result clusters.\n\n    Returns:\n        cluster IDs in embedding order.\n    \"\"\"\n    kmeans = KMeans(n_clusters=k, init='k-means++')\n    kmeans.fit(embeddings)\n    return kmeans.labels_\n\nif __name__ == '__main__':         #3\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument('file_path', type=str, help='Path to input file')\n    parser.add_argument('nr_clusters', type=int, help='Number of clusters')\n    args = parser.parse_args()\n\n    df = pd.read_csv(args.file_path)\n\n    embeddings = df['text'].apply(get_embedding)\n    df['clusterid'] = get_kmeans(list(embeddings), args.nr_clusters)\n\n    df.to_csv('result.csv')\n```", "```py\npython listing3.py textmix.csv 2\n```"]