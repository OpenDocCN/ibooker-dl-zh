["```py\n11.1 Detecting Multiple Images\n```", "```py\ncat_dog2 = preprocess_image('data/cat_dog.jpg', target_size=(448, 448))\ncrops = []\nfor x in range(7):\n    for y in range(7):\n        crops.append(cat_dog2[0,\n                              x * 32: x * 32 + 224,\n                              y * 32: y * 32 + 224,\n                              :])\ncrops = np.asarray(crops)\n```", "```py\npreds = base_model.predict(vgg16.preprocess_input(crops))\nl = defaultdict(list)\nfor idx, pred in enumerate(vgg16.decode_predictions(preds, top=1)):\n    _, label, weight = pred[0]\n    l[label].append((idx, weight))\nl.keys()\n```", "```py\ndict_keys(['Norwegian_elkhound', 'Egyptian_cat', 'standard_schnauzer',\n           'kuvasz', 'flat-coated_retriever', 'tabby', 'tiger_cat',\n           'Labrador_retriever'])\n```", "```py\ndef best_image_for_label(l, label):\n    idx = max(l[label], key=lambda t:t[1])[0]\n    return deprocess_image(crops[idx], 224, 224)\n\nshowarray(best_image_for_label(crop_scores, 'Egyptian_cat'))\n```", "```py\nshowarray(best_image_for_label(crop_scores, 'Labrador_retriever'))\n```", "```py\nbottom_model = vgg16.VGG16(weights='imagenet', include_top=False)\n```", "```py\n(1, 14, 14, 512)\n```", "```py\ndef top_model(base_model):\n    inputs = Input(shape=(7, 7, 512), name='input')\n    flatten = Flatten(name='flatten')(inputs)\n    fc1 = Dense(4096, activation='relu', name='fc1')(flatten)\n    fc2 = Dense(4096, activation='relu', name='fc2')(fc1)\n    predictions = Dense(1000, activation='softmax',\n                        name='predictions')(fc2)\n    model = Model(inputs,predictions, name='top_model')\n    for layer in model.layers:\n        if layer.name != 'input':\n            print(layer.name)\n            layer.set_weights(\n                base_model.get_layer(layer.name).get_weights())\n    return model\n\nmodel = top_model(base_model)\n```", "```py\nbottom_out = bottom_model.predict(cat_dog2)\n```", "```py\nvec_crops = []\nfor x in range(7):\n    for y in range(7):\n        vec_crops.append(bottom_out[0, x: x + 7, y: y + 7, :])\nvec_crops = np.asarray(vec_crops)\n```", "```py\ncrop_pred = top_model.predict(vec_crops)\nl = defaultdict(list)\nfor idx, pred in enumerate(vgg16.decode_predictions(crop_pred, top=1)):\n    _, label, weight = pred[0]\n    l[label].append((idx, weight))\nl.keys()\n```", "```py\ngit clone https://github.com/yhenon/keras-frcnn.git\n```", "```py\npython train_frcnn.py -p <*`downloaded``-``data``-``set`*>\n\n```", "```py\nimg_input = Input(shape=input_shape_img)\nroi_input = Input(shape=(c.num_rois, 4))\nfeature_map_input = Input(shape=input_shape_features)\n\nshared_layers = nn.nn_base(img_input, trainable=True)\n\nnum_anchors = len(c.anchor_box_scales) * len(c.anchor_box_ratios)\nrpn_layers = nn.rpn(shared_layers, num_anchors)\n\nclassifier = nn.classifier(feature_map_input,\n                           roi_input,\n                           c.num_rois,\n                           nb_classes=len(c.class_mapping),\n                           trainable=True)\n\nmodel_rpn = Model(img_input, rpn_layers)\nmodel_classifier_only = Model([feature_map_input, roi_input], classifier)\n\nmodel_classifier = Model([feature_map_input, roi_input], classifier)\n```", "```py\nmodel_rpn.load_weights('data/model_frcnn.hdf5', by_name=True)\nmodel_classifier.load_weights('data/model_frcnn.hdf5', by_name=True)\n\nmodel_rpn.compile(optimizer='sgd', loss='mse')\nmodel_classifier.compile(optimizer='sgd', loss='mse')\n```", "```py\nimg_vec, ratio = format_img(cv2.imread('data/cat_dog.jpg'), c)\ny1, y2, f = model_rpn.predict(img_vec)\nr = keras_frcnn.roi_helpers.rpn_to_roi(y1, y2, c, K.image_dim_ordering(),\n                                       overlap_thresh=0.7)\nroi_count = R.shape[0] // c.num_rois\nr2 = np.zeros((roi_count * c.num_rois, r.shape[1]))\nr2 = r[:r2.shape[0],:r2.shape[1]]\nr2 = np.reshape(r2, (roi_count, c.num_rois, r.shape[1]))\n```", "```py\np_cls = []\np_regr = []\nfor i in range(r2.shape[0]):\n    pred = model_classifier_only.predict([F, r2[i: i + 1]])\n    p_cls.append(pred[0][0])\n    p_regr.append(pred[1][0])\n```", "```py\nboxes = []\nw, h, _ = r2.shape\nfor x in range(w):\n    for y in range(h):\n        cls_idx = np.argmax(p_cls[x][y])\n        if cls_idx == len(idx_to_class) - 1:\n            continue\n        reg = p_regr[x, y, 4 * cls_idx:4 * (cls_idx + 1)]\n        params = list(r2[x][y])\n        params += list(reg / c.classifier_regr_std)\n        box = keras_frcnn.roi_helpers.apply_regr(*params)\n        box = list(map(lambda i: i * c.rpn_stride, box))\n        boxes.append((idx_to_class[cls_idx], p_cls[x][y][cls_idx], box))\n```", "```py\nfilepath,x1,y1,x2,y2,class_name\n\n```", "```py\npython train_frcnn.py -o simple -p my_data.txt \\\n       --config_filename=newconfig.pickle\n```", "```py\nnew_config = pickle.load(open('data/config.pickle', 'rb'))\nNow construct the model for training and load the weights:\n\nimg_input = Input(shape=input_shape_img)\nroi_input = Input(shape=(None, 4))\nshared_layers = nn.nn_base(img_input, trainable=True)\n\nnum_anchors = len(c.anchor_box_scales) * len(c.anchor_box_ratios)\nrpn = nn.rpn(shared_layers, num_anchors)\n\nclassifier = nn.classifier(shared_layers, roi_input, c.num_rois,\n                           len(c.class_mapping), trainable=True)\n\nmodel_rpn = Model(img_input, rpn[:2])\nmodel_classifier = Model([img_input, roi_input], classifier)\nmodel_all = Model([img_input, roi_input], rpn[:2] + classifier)\n\nmodel_rpn.load_weights('data/model_frcnn.hdf5', by_name=True)\nmodel_classifier.load_weights('data/model_frcnn.hdf5', by_name=True)\n```", "```py\nnew_nb_classes = len(new_config.class_mapping)\nout = model_classifier_only.layers[-3].output\nnew_out_class = TimeDistributed(Dense(new_nb_classes,\n                    activation='softmax', kernel_initializer='zero'),\n                    name='dense_class_{}'.format(new_nb_classes))(out)\nnew_out_regr = TimeDistributed(Dense(4 * (new_nb_classes-1),\n                    activation='linear', kernel_initializer='zero'),\n                    name='dense_regress_{}'.format(new_nb_classes))(out)\nnew_classifer =  [new_out_class, new_out_regr]\n```", "```py\nnew_model_classifier = Model([img_input, roi_input], classifier)\nnew_model_rpn = Model(img_input, rpn[:2])\nnew_model_all = Model([img_input, roi_input], rpn[:2] + classifier)\nnew_model_all.save_weights('data/model_frcnn_new.hdf5')\n```", "```py\npython train_frcnn.py -o simple -p my_data.txt \\\n       --config_filename=newconfig.pickle \\\n       --input_weight_path=data/model_frcnn_new.hdf5\n```"]