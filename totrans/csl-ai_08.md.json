["```py\nfrom pyro.distributions import Normal\nfrom pyro import sample\n\ndef cgm_model():    #1\n    x = sample(\"x\", Normal(47., 2.3))   #1\n    y = sample(\"y\", Normal(25\\. + 3*x, 3.3))   #1\n    return x, y    #2\n```", "```py\nfrom pyro.distributions import Normal\nfrom pyro import sample\n\ndef scm_model():\n    n_x = sample(\"n_x\", Normal(0., 2.3))    #1\n    n_y = sample(\"n_y\", Normal(0., 3.3))   #1\n    x = 47\\. + n_x     #2\n    y = 25\\. + 3.*x + n_y    #2\n    return x, y    #3\n```", "```py\nimport pandas as pd\nimport random\n\ndef true_dgp(\n    jenny_inclination,     #1\n    brian_inclination,     #1\n    window_strength):     #1\n    jenny_throws_rock = jenny_inclination > 0.5     #2\n    brian_throws_rock = brian_inclination > 0.5    #2\n    if jenny_throws_rock and brian_throws_rock:     #3\n        strength_of_impact = 0.8     #3\n    elif jenny_throws_rock or brian_throws_rock:     #3\n        strength_of_impact = 0.6     #3\n    else:     #3\n        strength_of_impact = 0.0    #3\n    window_breaks = window_strength < strength_of_impact    #4\n    return jenny_throws_rock, brian_throws_rock, window_breaks\n\ngenerated_outcome = true_dgp(\n    jenny_inclination=random.uniform(0, 1),  #5\n    brian_inclination=random.uniform(0, 1),  #5\n    window_strength=random.uniform(0, 1)   #5\n)\n```", "```py\nfrom pgmpy.factors.discrete.CPD import TabularCPD\nf_host_door_selection = TabularCPD(\n    variable='Host Door Selection',    #1\n    variable_card=3,     #2\n    values=[    #3\n        [0,0,0,0,1,1,0,1,1,0,0,0,0,0,1,0,1,0],     #3\n        [1,0,1,0,0,0,1,0,0,0,0,1,0,0,0,1,0,1],     #3\n        [0,1,0,1,0,0,0,0,0,1,1,0,1,1,0,0,0,0]     #3\n    ],     #3\n    evidence=[     #4\n        'Host Inclination',     #4\n        'Door with Car',     #4\n        'Player First Choice'     #4\n    ],   #4\n    evidence_card=[2, 3, 3],    #5\n    state_names={    #6\n        'Host Door Selection':['1st', '2nd', '3rd'],    #6\n        'Host Inclination': ['left', 'right'],   #6\n        'Door with Car': ['1st', '2nd', '3rd'],  #6\n        'Player First Choice': ['1st', '2nd', '3rd']    #6\n    }    #6\n)     #6\n```", "```py\nfrom pgmpy.factors.discrete.CPD import TabularCPD\nf_second_choice = TabularCPD(\n    variable='Player Second Choice',\n    variable_card=3,\n    values=[\n        [1,0,0,1,0,0,1,0,0,0,0,0,0,0,1,0,1,0],    #1\n        [0,1,0,0,1,0,0,1,0,1,0,1,0,1,0,1,0,1],    #1\n        [0,0,1,0,0,1,0,0,1,0,1,0,1,0,0,0,0,0]     #1\n    ],\n    evidence=[\n        'Strategy',\n        'Host Door Selection',\n        'Player First Choice'\n    ],\n    evidence_card=[2, 3, 3],\n    state_names={\n        'Player Second Choice': ['1st', '2nd', '3rd'],\n        'Strategy': ['stay', 'switch'],\n        'Host Door Selection': ['1st', '2nd', '3rd'],\n        'Player First Choice': ['1st', '2nd', '3rd']\n    }\n)\n```", "```py\nfrom pgmpy.models import BayesianNetwork\nfrom pgmpy.factors.discrete.CPD import TabularCPD\n\nmonty_hall_model = BayesianNetwork([    #1\n    ('Host Inclination', 'Host Door Selection'),     #1\n    ('Door with Car', 'Host Door Selection'),     #1\n    ('Player First Choice', 'Host Door Selection'),    #1\n    ('Player First Choice', 'Player Second Choice'),    #1\n    ('Host Door Selection', 'Player Second Choice'),    #1\n    ('Strategy', 'Player Second Choice'),    #1\n    ('Player Second Choice', 'Win or Lose'),     #1\n    ('Door with Car', 'Win or Lose')  #1\n])    #1\n```", "```py\np_host_inclination = TabularCPD(       #1\n    variable='Host Inclination',    #1\n    variable_card=2,   #1\n    values=[[.5], [.5]],    #1\n    state_names={'Host Inclination': ['left', 'right']}    #1\n)    #1\n\np_door_with_car = TabularCPD(     #2\n    variable='Door with Car',    #2\n    variable_card=3,    #2\n    values=[[1/3], [1/3], [1/3]],    #2\n    state_names={'Door with Car': ['1st', '2nd', '3rd']}     #2\n)     #2\n\np_player_first_choice = TabularCPD(     #3\n    variable='Player First Choice',     #3\n    variable_card=3,     #3\n    values=[[1/3], [1/3], [1/3]],     #3\n    state_names={'Player First Choice': ['1st', '2nd', '3rd']}     #3\n)     #3\n\np_host_strategy = TabularCPD(    #4\n    variable='Strategy',    #4\n    variable_card=2,    #4\n    values=[[.5], [.5]],     #4\n    state_names={'Strategy': ['stay', 'switch']}    #4\n)    #4\n```", "```py\nf_win_or_lose = TabularCPD(    \n    variable='Win or Lose',    \n    variable_card=2,    \n    values=[    \n        [1,0,0,0,1,0,0,0,1],    \n        [0,1,1,1,0,1,1,1,0],    \n    ],    \n    evidence=['Player Second Choice', 'Door with Car'],    \n    evidence_card=[3, 3],    \n    state_names={    \n        'Win or Lose': ['win', 'lose'],    \n        'Player Second Choice': ['1st', '2nd', '3rd'],    \n        'Door with Car': ['1st', '2nd', '3rd']    \n    }    \n)\n```", "```py\nmonty_hall_model.add_cpds(    \n    p_host_inclination,    \n    p_door_with_car,    \n    p_player_first_choice,    \n    p_host_strategy,    \n    f_host_door_selection,    \n    f_second_choice,    \n    f_win_or_lose    \n)\n```", "```py\nfrom pgmpy.inference import VariableElimination    #1\n\ninfer = VariableElimination(monty_hall_model)\nq1 = infer.query(['Win or Lose'], evidence={'Strategy': 'stay'})     #2\nprint(q1)   #2\nq2 = infer.query(['Win or Lose'], evidence={'Strategy': 'switch'})     #3\nprint(q2)   #3\nq3 = infer.query(['Strategy'], evidence={'Win or Lose': 'win'})     #4\nprint(q3)   #4\n```", "```py\n+-------------------+--------------------+\n| Win or Lose       |   phi(Win or Lose) |\n+===================+====================+\n| Win or Lose(win)  |             0.3333 |\n+-------------------+--------------------+\n| Win or Lose(lose) |             0.6667 |\n+-------------------+--------------------+\n```", "```py\n+-------------------+--------------------+\n| Win or Lose       |   phi(Win or Lose) |\n+===================+====================+\n| Win or Lose(win)  |             0.6667 |\n+-------------------+--------------------+\n| Win or Lose(lose) |             0.3333 |\n+-------------------+--------------------+\n```", "```py\n+------------------+-----------------+\n| Strategy         |   phi(Strategy) |\n+==================+=================+\n| Strategy(stay)   |          0.3333 |\n+------------------+-----------------+\n| Strategy(switch) |          0.6667 |\n+------------------+-----------------+\n```", "```py\nfrom pyro import sample\nfrom pyro.distributions import Normal\n\ndef linear_gaussian():\n    n_x = sample(\"N_x\", Normal(9., 3.))\n    n_y = sample(\"N_y\", Normal(9., 3.))\n    x = 10\\. + n_x     #1\n    y = 2\\. * x + n_y     #2\n    return x, y\n```", "```py\nfrom pyro import sample\nfrom pyro.distributions import Gamma\n\ndef LiNGAM():\n    n_x = sample(\"N_x\", Gamma(9., 1.))     #1\n    n_y = sample(\"N_y\", Gamma(9., 1.))   #1\n    x = 10\\. + n_x    #2\n    y = 2\\. * x + n_y    #2\n    return x, y\n```", "```py\nfrom torch import nn\n\nclass EnzymeModel(nn.Module):    #1\n    def __init__(self):\n        super().__init__()\n        self.*β* = nn.Parameter(torch.randn(1, 1))     #2\n\n    def forward(self, x):\n        x = torch.mul(x, self.*β*)     #3\n        x = x.log().sigmoid()     #4\n        x = torch.mul(x, 100.)    #5\n        return x\n```", "```py\nimport pandas as pd\nfrom torch import tensor\nimport torch\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/altdeep\n     /causalML/master/datasets/enzyme-data.csv\")    #1\nX = torch.tensor(df['x'].values).unsqueeze(1).float()     #2\nY = torch.tensor(df['y'].values).unsqueeze(1).float()     #2\n\ndef train(X, Y, model, loss_function, optim, num_epochs):     #3\n    loss_history = []     #3\n    for epoch in range(num_epochs):    #3\n        Y_pred = model(X)    #3\n        loss = loss_function(Y_pred, Y)     #3\n        loss.backward()   #3\n        optim.step()    #3\n        optim.zero_grad()     #3\n        if epoch % 1000 == 0:     #4\n            print(round(loss.data.item(), 6))     #4\n\ntorch.manual_seed(1)    #5\nenzyme_model = EnzymeModel()\noptim = torch.optim.Adam(enzyme_model.parameters(), lr=0.00001)     #6\nloss_function = nn.MSELoss()     #7\n\ntrain(X, Y, enzyme_model, loss_function, optim, num_epochs=60000)\n```", "```py\nimport pyro\nfrom pyro.distributions import Beta, Normal, Uniform\nfrom pyro.infer.mcmc import NUTS, MCMC\n\ndef g(u):     #1\n  return u / (1 + u)  #1\n\ndef model(N):     #2\n    *β* = pyro.sample(\"*β*\", Beta(0.5, 5.0))     #3\n    with pyro.plate(\"data\", N):     #4\n        x = pyro.sample(\"X\", Uniform(0.0, 101.0))     #5\n        y = pyro.sample(\"Y\", Normal(100.0 * g(*β* * x), x**.5))     #6\n    return x, y\n\nconditioned_model = pyro.condition(     #7\n    model,    #7\n    data={\"X\": X.squeeze(1), \"Y\":  Y.squeeze(1)}    #7\n)     #7\n\nN = X.shape[0]    #8\npyro.set_rng_seed(526)    #9\n\nnuts_kernel = NUTS(conditioned_model, adapt_step_size=True)    #10\nmcmc = MCMC(nuts_kernel, num_samples=1500, warmup_steps=500)   #10\nmcmc.run(N)   #10\n```", "```py\nfrom pyro.distributions.transforms import conditional_spline\nprint(conditional_spline(input_dim=1, context_dim=1))     #1\n```", "```py\nConditionalSpline(\n  (nn): DenseNN(\n    (layers): ModuleList(\n      (0): Linear(in_features=1, out_features=10, bias=True)\n      (1): Linear(in_features=10, out_features=10, bias=True)\n      (2): Linear(in_features=10, out_features=31, bias=True)\n    )\n    (f): ReLU()\n  )\n)\n```", "```py\nfrom pyro.distributions import TransformedDistribution\nfrom pyro.distributions.transforms import AffineTransform\nNxDist = Uniform(torch.zeros(1), torch.ones(1))     #1\nf_x = AffineTransform(loc=1., scale=100.0)    #2\nXDist = TransformedDistribution(NxDist, [f_x])     #3\n```", "```py\nimport pyro\nfrom pyro.distributions import (\n    ConditionalTransformedDistribution,\n    Normal, Uniform,\n    TransformedDistribution\n)\nfrom pyro.distributions.transforms import (\n    conditional_spline, spline\n)\nimport torch\nfrom torch.distributions.transforms import AffineTransform\n\npyro.set_rng_seed(348)\n\nNxDist = Uniform(torch.zeros(1), torch.ones(1))      #1\nf_x = AffineTransform(loc=1., scale=100.0)    #2\nXDist = TransformedDistribution(NxDist, [f_x])    #3\n\nNyDist = Normal(torch.zeros(1), torch.ones(1))    #4\nf_y = conditional_spline(input_dim=1, context_dim=1)    #5\nYDist = ConditionalTransformedDistribution(NyDist, [f_y])     #6\n```", "```py\nimport matplotlib.pyplot as plt\n\nmodules = torch.nn.ModuleList([f_y])     #1\noptimizer = torch.optim.Adam(modules.parameters(), lr=3e-3)    #2\nlosses = []\nmaxY = max(Y)    #3\nYnorm = Y / maxY    #3\nfor step in range(800):\n    optimizer.zero_grad()     #4\n    log_prob_x = XDist.log_prob(X)     #5\n    log_prob_y = YDist.condition(X).log_prob(Ynorm)     #6\n    loss = -(log_prob_x + log_prob_y).mean()     #7\n    loss.backward()    #7\n    optimizer.step()   #7\n    XDist.clear_cache()\n    YDist.clear_cache()\n    losses.append(loss.item())\n\nplt.plot(losses[1:])     #8\nplt.title(\"Loss\")    #8\nplt.xlabel(\"step\")     #8\nplt.ylabel(\"loss\")   #8\n```", "```py\nx_flow = XDist.sample(torch.Size([100,]))     #1\ny_flow = YDist.condition(x_flow).sample(torch.Size([100,])) * maxY   #1\n\nplt.title(\"\"\"\nObserved values of enzyme concentration X\\n\nand protein concentration Y\"\"\")     #2\nplt.xlabel('X')     #2\nplt.ylabel('Y')    #2\nplt.xlim(0, 105)   #2\nplt.ylim(0, 120)    #2\nplt.scatter(    #2\n    X.squeeze(1), Y.squeeze(1), color='firebrick',     #2\n    label='Actual Data',    #2\n    alpha=0.5     #2\n)     #2\nplt.scatter(     #2\n    x_flow.squeeze(1), y_flow.squeeze(),     #2\n    label='Generated values from trained model',     #2\n    alpha=0.5     #2\n)    #2\nplt.legend()     #2\nplt.show()     #2\n```"]