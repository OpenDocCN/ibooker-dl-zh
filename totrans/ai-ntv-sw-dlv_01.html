<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" class="pagenumrestart" data-pdf-bookmark="Chapter 1. The Road to AI-Native DevOps"><div class="chapter" id="chapter_1_the_road_to_ai_native_devops_1749354009875299">
      <h1><span class="label">Chapter 1. </span>The Road to AI-Native DevOps</h1>
      <p>Most software development teams<a contenteditable="false" data-type="indexterm" data-primary="DevOps" id="xi_DevOps1341"/> can tell war stories about deployments gone wrong. These are the stories that put us on paths to modernize our delivery practices. </p>
      <p>Here’s one: After weeks or months of feature work, extensive refactoring, and a long testing and stabilization phase, a team is ready to deploy. Developers, operations team members, a coterie of managers, and maybe a number of executives gather in a “war room.” Up to this point, there has been minimal collaboration between development and operations. However, now these two groups are working together as a single team<a contenteditable="false" data-type="indexterm" data-primary="OSS" data-see="open source software" id="id285"/><a contenteditable="false" data-type="indexterm" data-primary="DevOps" data-secondary="platform approach" data-see="platform engineering" id="id286"/><a contenteditable="false" data-type="indexterm" data-primary="SCM" data-see="source control management" id="id287"/><a contenteditable="false" data-type="indexterm" data-primary="security considerations" data-secondary="shift-left approach" data-see="shift-left security" id="id288"/><a contenteditable="false" data-type="indexterm" data-primary="supply chains" data-see="software supply chains" id="id289"/><a contenteditable="false" data-type="indexterm" data-primary="failure or fault injection testing" data-see="chaos engineering" id="id290"/><a contenteditable="false" data-type="indexterm" data-primary="cost management" data-see="cloud cost management" id="id291"/><a contenteditable="false" data-type="indexterm" data-primary="AI (artificial intelligence) systems" data-secondary="agents" data-see="agentic AI" id="id292"/><a contenteditable="false" data-type="indexterm" data-primary="AI (artificial intelligence) systems" data-secondary="coding assistants" data-see="AI coding assistangs" id="id293"/><a contenteditable="false" data-type="indexterm" data-primary="AI (artificial intelligence) systems" data-secondary="automation" data-see="automation" id="id294"/><a contenteditable="false" data-type="indexterm" data-primary="continuous integration/continuous deployment and delivery" data-see="CI/CD pipeline" id="id295"/><a contenteditable="false" data-type="indexterm" data-primary="GitOps" data-secondary="repositories" data-see="code repositories" id="id296"/>. They start ticking through a long checklist or playbook of manual steps.</p>
      <p>However, even exhaustive checklists do not guarantee a problem-free deployment. Given the number of changes in the release, the deployment is likely complex and risky. As we will see in the following chapters, dependency management is challenging and “dependency hell” can be very real. So, the team might find that a key dependency was missing from the production environment. The team might discover that an incompatible library version was installed, or that a critical setting was misconfigured, or that a migration step fails or is forgotten, or that changes have caused requests to a partner service to fail. </p>
      <p>Any number of missteps could take an already complex deployment off track. Tensions would rise, firefighting would ensue, and the hours would stretch on. The team would hope to wrap up deployment and any subsequent manual smoke testing within the deployment window. If the deployment failed irreparably and could not be salvaged, the team would hope that a rollback to the previous version would not result in unexpected difficulties, extending downtime and complexity. When the deployment is finally complete, the exhausted team retreats. Often the team would be expected to be vigilant as traffic resumed for the span of a “critical care period.” A stabilization period of a few days or weeks might follow in which the development team might pause all feature work to focus on hotfixes or patches.</p>
      <p>As this story illustrates, heavy-lift, high-stakes deployments were draining for both the development and operations teams. These big-production deployments, followed by cycles of stabilization work, distracted teams from continuing to build features that added business value. </p>
      <p>In contrast, modern software delivery streamlines and accelerates the entire process of getting software from the developer’s computer to the end user. Deployments are frequent, low drama, low risk, and highly automated. But we’re entering a new era—one that goes beyond automation. The next frontier is AI-native software delivery<a contenteditable="false" data-type="indexterm" data-primary="AI-native software delivery" id="id297"/>.</p>
      <p>AI-native delivery weaves AI into every layer of the software delivery lifecycle, enabling intelligent agents<a contenteditable="false" data-type="indexterm" data-primary="agentic AI" data-secondary="role in software delivery" id="id298"/> to make decisions, optimize workflows, and adapt in real time. These agents—ranging from Code and DevOps to Security and Test—collaborate autonomously, enforce compliance, self-heal infrastructure, and continuously optimize software delivery pipelines using reinforcement learning. This shift marks a move from reactive to proactive governance, from siloed tools to unified ecosystems, and from static automation to dynamic autonomy.</p>
      <p>As AI generates code, orchestrates pipelines, and reduces manual toil, development velocity accelerates. Systems become more resilient and secure, with AI preemptively identifying issues and autonomously resolving them. At the same time, cloud costs shrink through intelligent optimization, and collaboration scales as AI-powered agents handle cross-team coordination and decision-making at machine speed.</p>
      <p>In this chapter, we will describe how software delivery has evolved over the past 25 years. We will define DevOps and describe how DevOps practices enable modern software delivery. We will look at numerous challenges to the current state of DevOps. Lastly, this chapter will provide an overview of how modern software delivery, DevOps practices, and an AI-native approach can evolve to meet these challenges.</p>
      <section data-type="sect1" data-pdf-bookmark="Development + Operations = DevOps"><div class="sect1" id="chapter_1_development_operations_devops_1749354009875397">
        <h1>Development + Operations = DevOps</h1>
        <p>The term “DevOps”' is often attributed to Patrick Debois<a contenteditable="false" data-type="indexterm" data-primary="DevOps" data-secondary="origins of" id="xi_DevOpsoriginsof11568"/><a contenteditable="false" data-type="indexterm" data-primary="Debois, Patrick" id="id299"/>, who in 2009 combined the words “development” and “operations”' to name a conference<a contenteditable="false" data-type="indexterm" data-primary="development + operations = DevOps" id="id300"/> he organized to explore breaking down the traditional walls between development and operations teams to deliver software faster. Two main factors created these walls:</p>
        <dl>
          <dt>Poor communication and collaboration</dt>
          <dd>
            <p>Developers commonly focused on writing code and features<a contenteditable="false" data-type="indexterm" data-primary="communication and collaboration, DevOps" id="id301"/>, then essentially threw the finished product over a metaphorical wall to the Ops team. Ops then bore the responsibility of deploying, maintaining, and troubleshooting the code in production. </p>
          </dd>
          <dt>Conflicting priorities</dt>
          <dd>
            <p>Development teams prioritized rapid development and the quick release of new features, while Ops teams focused on system stability, security, and preventing downtime. Despite their different priorities, these teams are inherently interconnected and interdependent. No matter how impressive your code or infrastructure is, it has no real value until it’s deployed and running in production to serve your business objectives.</p>
          </dd>
        </dl>
        <p>This goal mismatch, sometimes referred to as “the core chronic conflict,” could lead to friction and finger-pointing when issues arise.</p>
        <p>In response, DevOps principles encourage communication at every stage. They encourage Ops involvement early in development and an ongoing partnership with Devs in supporting code long after it has been deployed<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_DevOpsoriginsof11568" id="id302"/>.</p>
      </div></section>
      <section data-type="sect1" data-pdf-bookmark="A Short History of DevOps"><div class="sect1" id="chapter_1_a_short_history_of_devops_1749354009875459">
        <h1>A Short History of DevOps</h1>
        <p>Increasingly sophisticated software teams, new software methodologies, and new tools helped pave the way for DevOps<a contenteditable="false" data-type="indexterm" data-primary="DevOps" data-secondary="history of" id="xi_DevOpshistoryof132127"/>. In this section we’ll look at these factors.</p>
        <section data-type="sect2" data-pdf-bookmark="Agile in the Aughts"><div class="sect2" id="chapter_1_agile_in_the_aughts_1749354009875515">
          <h2>Agile in the Aughts</h2>
          <p>In the early 2000s, organizations became very interested in and receptive to new ideas about how to make software delivery more efficient. New “Agile” methodologies<a contenteditable="false" data-type="indexterm" data-primary="Agile practices, development of" id="xi_Agilepracticesdevelopmentof135178"/> that built on lean manufacturing<a contenteditable="false" data-type="indexterm" data-primary="lean manufacturing, and Agile" id="id303"/> ideas became popular. These methodologies argued against “waterfall” software delivery patterns<a contenteditable="false" data-type="indexterm" data-primary="waterfall methodologies, building software" id="id304"/> that emphasized extensive up-front planning and a strictly linear sequence of distinct phases. In contrast, Agile promoted short development cycles and frequent releases that were highly responsive to change. Many parallel efforts formalized new Agile practices. A 1995 paper formalized Scrum practices<a contenteditable="false" data-type="indexterm" data-primary="Scrum practices" id="id305"/>. Kent Beck<a contenteditable="false" data-type="indexterm" data-primary="Beck, Kent" id="id306"/> described a set of Agile practices for software development in his 1999 book<a contenteditable="false" data-type="indexterm" data-primary="Extreme Programming Explained (Beck)" id="id307"/> <em>Extreme Programming Explained</em> (Addison-Wesley). In 2001, Beck and other influential advocates of Agile processes spoke to similar themes in the Agile Manifesto<a contenteditable="false" data-type="indexterm" data-primary="Agile Manifesto" id="id308"/>, which promoted adaptability and responsiveness over rigid adherence to plans.<sup><a data-type="noteref" id="id309-marker" href="ch01.html#id309">1</a></sup> DevOps borrows the name “continuous delivery” from the manifesto’s first principle: “Our highest priority is to satisfy the customer through early and continuous delivery of valuable software.”</p>
          <p>Jeffrey Fredrick has observed that the progression of Ken Schwaber’s<a contenteditable="false" data-type="indexterm" data-primary="Schwaber, Ken" id="id310"/> Scrum books from 2001 to 2007 serves as a kind of barometer for Agile’s increasing maturity and organizational reach. During this time, Scrum was rapidly emerging as the dominant Agile practice, thanks to its clear structure, prescriptive roles, and adaptability across teams. In 2001, <em>Agile Software Development with Scrum</em> (Pearson) introduced the framework to developers and small teams just beginning to explore Agile methods. By 2004, <em>Agile Project Management with Scrum</em> (Addison-Wesley) addressed practical implementation challenges, signaling growing adoption across broader swaths of IT. By 2007, <em>The Enterprise and Scrum</em> (Microsoft Press) acknowledged the growing demand for scaling Agile practices beyond individual teams to entire organizations. These books reflected—and helped shape—the journey of Agile from fringe idea to enterprise imperative.</p>
        </div></section>
        <section data-type="sect2" data-pdf-bookmark="Continuous Integration and Continuous Delivery"><div class="sect2" id="chapter_1_continuous_integration_and_continuous_delivery_1749354009875563">
          <h2>Continuous Integration and Continuous Delivery</h2>
          <p>Over the next decade, technology organizations were increasingly influenced by agile thinking. One result was the adoption of continuous integration and continuous delivery (CI/CD) practices<a contenteditable="false" data-type="indexterm" data-primary="CI/CD pipeline" id="id311"/>.</p>
          <p>The “Manifesto for Agile Software Development” gave rise to the practice of continuous integration, which enables a key agile tenet, the frequent delivery of working software. Developers merge their code changes into a shared repository. With continuous integration, each merge triggers an automated build and testing process. This automated system quickly catches errors and conflicts, allowing teams to fix them early in the development cycle. Continuous integration encourages smaller, more frequent updates, leading to faster delivery, reduced integration issues, and a healthier codebase. </p>
          <p>Continuous delivery is a natural extension of continuous integration. CD automates the process of taking code that has passed the integration build and testing and preparing it for release to production environments. This includes steps like packaging, configuring, and deploying the software to staging areas. CD enables teams to push new features, bug fixes, and updates rapidly and reliably, ensuring that deployable software is always available. </p>
          <p>Delivering a “potentially shippable product” at the conclusion of each development cycle is another key Agile practice. Potentially shippable<a contenteditable="false" data-type="indexterm" data-primary="potentially shippable product" id="id312"/> simply means reliable, tested, packaged software that could be deployed to production. (In practice, many organizations that embraced CD delivered only internally and continued to deploy to production infrequently. Continuous delivery did not equal continuous deployment<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_Agilepracticesdevelopmentof135178" id="id313"/>.) </p>
        </div></section>
        <section data-type="sect2" data-pdf-bookmark="Milestones in Early DevOps"><div class="sect2" id="chapter_1_milestones_in_early_devops_1749354009875610">
          <h2>Milestones in Early DevOps</h2>
          <p>Whereas Agile methodologies tend to focus on the planning and execution parts of the software delivery lifecycle, early DevOps focused on delivery and operations. In the years that followed the emergence of DevOps, the movement gained significant momentum. A key milestone occurred in 2009, when the inaugural DevOpsDays<a contenteditable="false" data-type="indexterm" data-primary="DevOpsDays" id="id314"/> conference was held. This event brought together professionals to share their experiences and insights on DevOps practices.</p>
          <p>Another significant development was the 2010 publication of the book <em>The Phoenix Project</em> (IT Revolution Press) by Gene Kim<a contenteditable="false" data-type="indexterm" data-primary="The Phoenix Project (Kim, Behr, Spafford)" data-primary-sortas="Phoenix Project" id="id315"/><a contenteditable="false" data-type="indexterm" data-primary="Kim, Gene" id="id316"/><a contenteditable="false" data-type="indexterm" data-primary="Spafford, George" id="id317"/>, Kevin Behr, and George Spafford. This narrative illustrated the challenges faced by a fictional IT organization and how the adoption of DevOps principles and practices led to a dramatic turnaround in its performance. It made the case for DevOps in a way that resonated with both technical and nontechnical audiences. The following year saw the release of another influential publication, <em>The DevOps Handbook</em> by Gene Kim<a contenteditable="false" data-type="indexterm" data-primary="The DevOps Handbook (Kim, Humble, Debois, Willis)" data-primary-sortas="DevOps Handbook" id="id318"/><a contenteditable="false" data-type="indexterm" data-primary="Humble, Jez" id="id319"/><a contenteditable="false" data-type="indexterm" data-primary="Debois, Patrick" id="id320"/><a contenteditable="false" data-type="indexterm" data-primary="Willis, John" id="id321"/>, Jez Humble, Patrick Debois, and John Willis. This practical guide helped many organizations start their DevOps journey by providing a comprehensive framework for implementing DevOps.</p>
          <p>In 2013, the initial Puppet Labs<a contenteditable="false" data-type="indexterm" data-primary="Puppet Labs" id="id322"/> (now Puppet) “State of DevOps” report by Kim and Humble drew attention. The report didn’t just focus on technical metrics; it highlighted the business benefits of DevOps adoption, demonstrating that organizations implementing the approach could ship code 30 times faster than their peers, with a 50% reduction in failures. This tied DevOps practices directly to the business outcomes that leaders care about. The book <em>Accelerate: The Science of Lean Software and DevOps</em> (IT Revolution) by Nicole Forsgren<a contenteditable="false" data-type="indexterm" data-primary="Accelerate: The Science of Lean Software and DevOps (Forsgren, Humble, Kim)" id="id323"/><a contenteditable="false" data-type="indexterm" data-primary="Forsgren, Nicole" id="id324"/>, Jez Humble, and Gene Kim explored this theme in greater detail.</p>
          <p>The introduction of Platform-as-a-Service (PaaS)<a contenteditable="false" data-type="indexterm" data-primary="Platform-as-a-Service (PaaS)" id="id325"/><a contenteditable="false" data-type="indexterm" data-primary="PaaS (Platform-as-a-Service)" id="id326"/> and Docker<a contenteditable="false" data-type="indexterm" data-primary="Docker" id="id327"/> in 2013 marked another pivotal moment, as these technologies simplified the deployment and management of applications, making DevOps practices feasible on a larger scale. Prior to this, the complexity of managing infrastructure and applications made widespread adoption of DevOps challenging. The launch of AWS Lambda<a contenteditable="false" data-type="indexterm" data-primary="AWS" data-secondary="Lambda" id="id328"/><a contenteditable="false" data-type="indexterm" data-primary="Lambda" id="id329"/> in 2014 further transformed the landscape by pioneering event-driven function execution at scale, allowing developers to focus on writing code without worrying about the underlying infrastructure. Meanwhile, Kubernetes<a contenteditable="false" data-type="indexterm" data-primary="Kubernetes" id="id330"/>, also introduced in 2014, provided a robust framework for orchestrating containerized applications at scale, ensuring that deployments were reliable, efficient, and scalable.</p>
          <p>By the latter half of the decade, machine learning (ML)<a contenteditable="false" data-type="indexterm" data-primary="machine learning (ML)" data-seealso="AI" id="id331"/><a contenteditable="false" data-type="indexterm" data-primary="ML (machine learning)" data-seealso="AI" id="id332"/> techniques began to creep into DevOps toolchains, especially in application performance monitoring (APM)<a contenteditable="false" data-type="indexterm" data-primary="application performance monitoring (APM)" id="id333"/> and testing disciplines. Testing<a contenteditable="false" data-type="indexterm" data-primary="testing" id="id334"/> tools would use ML to optimize test execution and detect changes in user interfaces. Meanwhile, APM tools like Datadog<a contenteditable="false" data-type="indexterm" data-primary="Datadog" id="id335"/> and New Relic were early to brand themselves “AI Ops” as they used ML to identify problematic signals. By 2018, <a href="https://oreil.ly/4BH7E">Harness applied ML to continuous delivery</a> to detect problematic signals<a contenteditable="false" data-type="indexterm" data-primary="Harness" id="id336"/>, enabling the system to identify when deployments caused issues and trigger necessary rollbacks. Together, these technologies laid the groundwork for modern DevOps by providing the necessary tools and frameworks to manage complex software systems efficiently, paving the way for AI-native DevOps.</p>
        </div></section>
        <section data-type="sect2" data-pdf-bookmark="DevOps 1.0"><div class="sect2" id="chapter_1_devops_1_0_1749354009875661">
          <h2>DevOps 1.0</h2>
          <p>DevOps<a contenteditable="false" data-type="indexterm" data-primary="DevOps 1.0" id="xi_DevOps1015520"/> has progressed from a loose, niche concept to a well-established set of ideas we can refer to as “DevOps 1.0.” Its attributes include:</p>
          <dl>
            <dt>Cultural transformation</dt>
            <dd>
              <p>Recognizing the significance of cultural shifts to align software development and operations teams</p>
            </dd>
            <dt>Automation practices</dt>
            <dd>
              <p>Implementing practices such as continuous integration and continuous delivery to streamline software delivery</p>
            </dd>
            <dt>Tools for automation</dt>
            <dd>
              <p>Utilizing specific tools<a contenteditable="false" data-type="indexterm" data-primary="automation" data-secondary="tools for" id="id337"/> to automate various stages of the software delivery pipeline, including code commits, testing, deployment, provisioning, and production monitoring</p>
            </dd>
          </dl>
          <p>Early adopters of DevOps 1.0 practices experienced immediate wins. In the early 2010s, many engineering teams were releasing software on a quarterly basis, with weeks of effort dedicated to manual testing, coordination, and production deployment. These release processes were slow, error-prone, and required off-hours scheduling to minimize risk. As organizations began embracing early DevOps principles—bringing development and operations teams closer together and automating key parts of the delivery pipeline—they achieved faster release cycles, greater reliability, and reduced manual effort. For many, the shift enabled a move from quarterly to biweekly or even weekly releases, setting the stage for more iterative development and faster time-to-value.</p>
          <section data-type="sect3" data-pdf-bookmark="Challenges to DevOps 1.0"><div class="sect3" id="chapter_1_challenges_to_devops_1_0_1749354009875712">
            <h3>Challenges to DevOps 1.0</h3>
            <p>DevOps 1.0 provided valuable concepts, practices, and tools. However, companies today face new challenges in fully realizing the benefits of DevOps as a result of:</p>
            <ul>
              <li>
                <p>Software trends that have introduced complexities that require DevOps to adapt</p>
              </li>
              <li>
                <p>DevOps 1.0 toolsets that either are lacking in features or have become overly complex for many organizations</p>
              </li>
            </ul>
            <p>The following sections will explore the details of these challenges.</p>
            <section data-type="sect4" data-pdf-bookmark="The adoption of cloud-native and microservices architectures"><div class="sect4" id="chapter_1_the_adoption_of_cloud_native_and_microservices_arc_1749354009875768">
              <h4>The adoption of cloud-native and microservices architectures</h4>
              <p>New architecture<a contenteditable="false" data-type="indexterm" data-primary="cloud-native architectures" id="id338"/><a contenteditable="false" data-type="indexterm" data-primary="microservices architectures" id="id339"/> patterns involve dozens of discrete microservices deployed to individual containers. DevOps 1.0 pipelines were not equipped to address the requirements of these new <span class="keep-together">architectures</span>.</p>
              <p>Over the past decade, microservice and cloud-native architectures have become the de facto standard for modern software development, driven by the need for greater scalability, flexibility, and agility in software systems. These architectures introduce significant new requirements for DevOps teams. The adoption of microservices leads to a proliferation of services to deploy, each with its own dependencies and configurations. Orchestrating deployments and maintaining consistency across these distributed services becomes increasingly challenging.</p>
              <p>The usage of containers<a contenteditable="false" data-type="indexterm" data-primary="containers and containerization" id="id340"/> (a key feature of cloud-native systems) and serverless<a contenteditable="false" data-type="indexterm" data-primary="serverless architectures" id="id341"/> architectures necessitates new strategies for deployment and management and adds another layer of complexity. DevOps teams must now handle deployments across dozens or even hundreds of ephemeral containers or serverless functions, requiring robust orchestration tools, automated processes for building and managing container lifecycles, and a deep understanding of these emerging technologies. Automating the entire lifecycle of containers—from building images, to pushing them to registries, to rolling out updates with minimal downtime—is critical for efficient container management.</p>
            </div></section>
            <section data-type="sect4" data-pdf-bookmark="The rise of open source software"><div class="sect4" id="chapter_1_the_rise_of_open_source_software_1749354009875816">
              <h4>The rise of open source software</h4>
              <p>Open source software (OSS)<a contenteditable="false" data-type="indexterm" data-primary="open source software (OSS)" id="id342"/> has become a ubiquitous part of modern software development. While OSS offers numerous benefits, it introduces new challenges for DevOps teams. Managing dependencies, ensuring compatibility with different versions, and maintaining security patches across multiple OSS components can be a daunting task. Additionally, teams must carefully vet the code and ensure it aligns with their organization’s security and compliance standards.</p>
            </div></section>
            <section data-type="sect4" data-pdf-bookmark="The importance of the digital experience and consumerization of enterprise"><div class="sect4" id="chapter_1_the_importance_of_the_digital_experience_and_consu_1749354009875864">
              <h4>The importance of the digital experience and consumerization of enterprise</h4>
              <p>In this era of digital disruption, Marc Andreessen’s prophetic claim that software is eating the world proves ever more accurate. The digital experience<a contenteditable="false" data-type="indexterm" data-primary="digital experience, as customer touchpoint" id="id343"/> a company provides is becoming the primary touchpoint for customers, shaping how they experience a brand. Moreover, the consumerization of enterprise technology<a contenteditable="false" data-type="indexterm" data-primary="consumerization of enterprise technology" id="id344"/> means that employees expect the same seamless experiences and continual updates they get with customer-targeted applications. These expectations pressure DevOps teams to deliver even more frequent releases, maintain high availability, and enable experimentation to power rapid innovation.</p>
            </div></section>
          </div></section>
          <section data-type="sect3" data-pdf-bookmark="Outgrowing DevOps 1.0 toolsets"><div class="sect3" id="chapter_1_outgrowing_devops_1_0_toolsets_1749354009875913">
            <h3>Outgrowing DevOps 1.0 toolsets</h3>
            <p>In the years since the first DevOpsDays in 2009, what we need from our tools has changed. Delivery cadences have accelerated while regulatory burdens have increased. Take artifact registries: originally introduced as local caches to speed up builds, they’re now essential for securing software supply chains across a multitude of languages. To simplify deployments, we containerized and our builds became longer, making our continuous integration builds anything but continuous. We shifted from one set of configuration management tools to newer, cloud-native declarative tools. But we still need to test, secure, and govern those infrastructure changes. Meanwhile, new tools arrive all the time—each promising improvements but also requiring wiring up to everything else. For many teams, the current stack is crumbling.</p>
            <p>Pipelines<a contenteditable="false" data-type="indexterm" data-primary="pipelines" data-secondary="complexity of" id="xi_pipelinescomplexityof110125"/> quickly become very complex. Organizations are managing an average of 10 or more different tools to deploy software. For example, an automation pipeline to deploy Rails, Sidekiq, and NodeJS apps might include the following tools:</p>
            <ul>
              <li>
                <p>GitHub actions for running CI</p>
              </li>
              <li>
                <p>Libraries for instrumenting Sidekiq, Rails, and Puma and pushing application metrics into Prometheus</p>
              </li>
              <li>
                <p>Docker image building and Kubernetes</p>
              </li>
              <li>
                <p>Artifactory for storing images and Helm charts</p>
              </li>
              <li>
                <p>ArgoCD for GitOps deployments on Kubernetes</p>
              </li>
              <li>
                <p>Helm for managing deployments and upgrades</p>
              </li>
              <li>
                <p>Terraform for managing the Amazon Web Services (AWS) infrastructure, roles, permissions, etc.</p>
              </li>
              <li>
                <p>New Relic for exception capture and monitoring</p>
              </li>
              <li>
                <p>Kube-state-metrics for gathering container metrics</p>
              </li>
              <li>
                <p>Prometheus for storing metrics</p>
              </li>
              <li>
                <p>Grafana for making Prometheus metrics consumable</p>
              </li>
            </ul>
            <p>The integration and management of this toolset may pose a considerable challenge for a team with limited resources. Let’s look at some of the challenges of a DIY approach.</p>
            <section data-type="sect4" data-pdf-bookmark="Widely used open source tools are often suboptimal"><div class="sect4" id="chapter_1_widely_used_open_source_tools_are_often_suboptimal_1749354009875960">
              <h4>Widely used open source tools are often suboptimal</h4>
              <p>A DIY approach to DevOps often results in a less efficient pipeline. Some open source tools lack features that could reduce developer effort and shorten the time to production. For example, maintaining uptime and scaling in Jenkins requires significant resources. Long testing times can lead to slow builds. Lastly, the model for reusing pipelines is copy/paste, leading to “pipeline sprawl,” which<a contenteditable="false" data-type="indexterm" data-primary="pipeline sprawl" id="id345"/> can be difficult and expensive to maintain. <a data-type="xref" href="ch03.html#chapter_3_the_build_and_pre_deployment_testing_steps_of_cont_1749354010266208">Chapter 3</a> will cover these issues in additional detail.</p>
            </div></section>
            <section data-type="sect4" data-pdf-bookmark="DIY pipelines result in redundant and wasteful efforts"><div class="sect4" id="chapter_1_diy_pipelines_result_in_redundant_and_wasteful_eff_1749354009876008">
              <h4>DIY pipelines result in redundant and wasteful efforts</h4>
              <p>Often teams must implement plumbing to bring tools and systems together. This leads to substantial reinventing of the wheel. For example, Jenkins and ArgoCD are common tools used for CI/CD. These tools provide powerful features for automating the software development and deployment process, but they require teams to build essential constructs like role-based access control (RBAC), audit logs, and notifications from scratch. <span class="keep-together">Implementing</span> and maintaining is an effort that could otherwise be applied to delivering value to customers<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_pipelinescomplexityof110125" id="id346"/>.</p>
            </div></section>
            <section data-type="sect4" data-pdf-bookmark="Automation is often incomplete, requiring manual steps"><div class="sect4" id="chapter_1_automation_is_often_incomplete_requiring_manual_s_1749354009876056">
              <h4>Automation is often incomplete, requiring manual steps</h4>
              <p>A team using automated<a contenteditable="false" data-type="indexterm" data-primary="automation" data-secondary="CI/CD pipeline" id="id347"/> scripts for most of the deployment but requiring manual intervention to configure environment variables can lead to inconsistent deployments if not all team members follow the same procedure. Incomplete automation can lead to gaps in monitoring and feedback loops, as manual steps might not trigger automated alerts or metrics collection. Manual steps introduce the risk of human error, which can lead to downtime or security breaches. Thus, incomplete automation in DevOps can lead to inefficiencies, errors, and scalability issues.</p>
            </div></section>
            <section data-type="sect4" data-pdf-bookmark="Governance is an afterthought"><div class="sect4" id="chapter_1_governance_is_an_afterthought_1749354009876103">
              <h4>Governance is an afterthought</h4>
              <p>Without up-front governance<a contenteditable="false" data-type="indexterm" data-primary="governance" data-secondary="need for" id="id348"/>, teams might overlook compliance requirements (such as meeting General Data Protection Regulation [GDPR] standards), leading to costly rework or fines when issues are discovered later. If security measures are applied inconsistently or as an afterthought, applications are left vulnerable to attacks. Without clear governance policies, resources such as cloud services or infrastructure might be overprovisioned or underutilized, leading to wasted costs (a topic we’ll cover in <a data-type="xref" href="ch09.html#chapter_9_ai_and_automation_for_cloud_cost_management_1749354011360525">Chapter 9</a>). Without oversight, teams may use different tools, processes, and standards, leading to integration challenges and inefficiencies<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_DevOps1015520" id="id349"/>.</p>
            </div></section>
          </div></section>
        </div></section>
        <section data-type="sect2" data-pdf-bookmark="DevOps 2.0"><div class="sect2" id="chapter_1_devops_2_0_1749354009876150">
          <h2>DevOps 2.0</h2>
          <p>DevOps 1.0 has significantly accelerated the software delivery process for many companies. Yet its complexity, the gaps it leaves, and the investment it requires create room for improvement. Enter what we’re calling DevOps 2.0<a contenteditable="false" data-type="indexterm" data-primary="DevOps 2.0" id="xi_DevOps201158240"/>—a vision defined by a simpler developer experience, end-to-end automation with views to easily manage all of the moving parts, and AI capabilities that augment the entire pipeline<a contenteditable="false" data-type="indexterm" data-primary="pipelines" data-secondary="DevOps 2.0 improvements" id="xi_pipelinesDevOps20improvements1158420"/>. This evolution shifts the focus from tools and processes to the people and outcomes they serve. </p>
          <p>DevOps 2.0 processes and tools enhance the developer experience with powerful new features. Developers start new projects and services within minutes by automating the setup of development and delivery toolchains. Out-of-the-box integrations give teams the ability to easily spin up and connect repositories, agile projects, and pipelines. To streamline the process further, templates encapsulate an organization’s best practices, ensuring consistency and eliminating work management overhead when creating new services. Teams focus on building their applications, not on tedious infrastructure setup. AI agents perform increasingly complex DevOps tasks, such as automatically diagnosing and resolving infrastructure and pipeline issues, optimizing resource allocation, and suggesting architectural improvements based on observed performance patterns.</p>
          <p>DevOps 2.0 tools detangle the complexity of DevOps 1.0 solutions with a more cohesive, tightly integrated toolset. Essential constructs (RBAC, audit logs) are integrated. Support for various deployment strategies and experimentation approaches are built in, enabling the frequent releases and rapid iterations teams need. New tools scale to support large-scale deployments across multiple environments, including on-premises, cloud, and hybrid setups. DevOps 2.0 tools will offer secure pipelines and policy enforcement to minimize the inherent risks of open source adoption and AI-written code.</p>
          <p>Lastly, AI<a contenteditable="false" data-type="indexterm" data-primary="AI-native software delivery" data-secondary="DevOps integration of" id="id350"/> is being baked into DevOps 2.0 tools and processes throughout the software delivery pipeline. Emerging protocols like the Agent Control Protocol (ACP)<a contenteditable="false" data-type="indexterm" data-primary="Agent Control Protocol (ACP)" id="id351"/>, Model Context Protocol (MCP)<a contenteditable="false" data-type="indexterm" data-primary="Model Context Protocol (MCP)" id="id352"/><a contenteditable="false" data-type="indexterm" data-primary="MCP (Model Context Protocol)" id="id353"/>, and Agent-to-Agent Protocol<a contenteditable="false" data-type="indexterm" data-primary="Agent-to-Agent Protocol" id="id354"/> are helping enable seamless interaction between AI models and the broader ecosystem of tools, systems, and data. These protocols define standardized ways for AI agents to interact with tools, access data securely, and perform tasks within guardrails—enabling more dynamic and autonomous workflows. </p>
          <p>In modern DevOps environments, the protocols act as bridges between AI capabilities and the operational infrastructure, allowing AI to do more than just observe and suggest; they empower it to take meaningful action while remaining auditable and compliant. As DevOps 2.0 embraces increasingly intelligent automation, these protocols provide the foundation for safe, scalable, and effective AI-driven operations that supercharge developer workflows. Imagine tools that can generate code, comments, tests, and infrastructure scripts, or pull out relevant code snippets using natural language search. In addition, ML speeds up test cycles by only executing relevant tests. </p>
          <p>Leveraging AI, the tools provide personalized guidance during onboarding, detect vulnerabilities and offer remediation advice or instigate repairs, and even help write and understand policies. The reliability of deployments is improved through the analysis of observability telemetry to identify when rollbacks are needed. AI analyzes feature experiments to understand the impacts of change. This AI-driven transformation across the software development lifecycle (SDLC) is boosting productivity, improving quality, reducing risk, and enhancing the overall developer experience.</p>
          <p>As developers can code increasingly quickly with AI coding assistants, a business’s ability to quickly and safely deliver changes to production and understand if those changes have been beneficial will be the limiting factor to innovation. To do this well will require both doing the basics of DevOps well and infusing cutting-edge AI throughout every stage of delivery<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_DevOps201158240" id="id355"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_pipelinesDevOps20improvements1158420" id="id356"/>.</p>
        </div></section>
      </div></section>
      <section data-type="sect1" class="pagebreak-before" data-pdf-bookmark="Summary"><div class="sect1" id="chapter_1_summary_1749354009876193">
        <h1 class="less_space">Summary</h1>
        <p>Modern software delivery emphasizes rapid releases, seamless experiences, and constant innovation, driving a need to transform traditional DevOps practices. While DevOps 1.0 laid the groundwork with CI/CD and initial cross-team collaboration, its reliance on complex toolchains built from disparate solutions creates hurdles. These challenges stem from the growing architectural complexity of applications (microservices, containers), the proliferation of open source components, and the need to manage increasingly diverse toolsets. DevOps 2.0 aims to address these issues by simplifying the developer experience, offering more integrated and intelligent toolsets, and infusing AI natively throughout the pipeline. This evolution promises greater efficiency, enhanced quality, and a focus on delivering value rather than just managing tools.</p>
        <p>In addition, AI-native software delivery replaces static automation with autonomous agents (e.g., Code, DevOps, Security) to enable self-optimizing systems and proactive and unified ecosystems. It accelerates development velocity, enhances reliability, ensures compliance, reduces costs, and fosters scalable collaboration through autonomous code generation, contextual pipeline creation, predictive failure resolution, and real-time decision-making. While this is transformative, organizations must address AI governance, data privacy, and skill gaps to fully leverage its benefits.</p>
        <p>In Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch02.html#chapter_2_source_control_management_1749354010078326">2</a>, <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch03.html#chapter_3_the_build_and_pre_deployment_testing_steps_of_cont_1749354010266208">3</a>, and <a data-type="xref" data-xrefstyle="select:labelnumber" href="ch04.html#chapter_4_deploying_to_test_environments_1749354010445896">4</a>, we will cover the backbone of DevOps automation. This includes source control management for effective version control<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_DevOps1341" id="id357"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="xi_DevOpshistoryof132127" id="id358"/>, building and testing using continuous integration for efficient development, and deploying internally using continuous delivery systems for seamless software releases. We will explore both the DevOps 1.0 approaches and the opportunities presented by DevOps 2.0.</p>
      </div></section>
    <div data-type="footnotes"><p data-type="footnote" id="id309"><sup><a href="ch01.html#id309-marker">1</a></sup> Kent Beck et al., <a href="https://agilemanifesto.org">“Manifesto for Agile Software Development”</a>, 2001, Agile Alliance. Retrieved 14 June 2010.</p></div></div></section></div></div></body></html>