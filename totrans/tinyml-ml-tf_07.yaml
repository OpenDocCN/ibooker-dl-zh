- en: 'Chapter 7\. Wake-Word Detection: Building an Application'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章。唤醒词检测：构建一个应用程序
- en: TinyML might be a new phenomenon, but its most widespread application is perhaps
    already at work in your home, in your car, or even in your pocket. Can you guess
    what it is?
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: TinyML可能是一个新现象，但它最广泛的应用可能已经在你的家中、你的汽车中，甚至在你的口袋里工作。你能猜到它是什么吗？
- en: The past few years have seen the rise of digital assistants. These products
    provide a voice user interface (UI) designed to give instant access to information
    without the need for a screen or keyboard. Between Google Assistant, Apple’s Siri,
    and Amazon Alexa, these digital assistants are nearly ubiquitous. Some variant
    is built into almost every mobile phone, from flagship models to voice-first devices
    designed for emerging markets. They’re also in smart speakers, computers, and
    vehicles.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 过去几年见证了数字助手的崛起。这些产品提供了一个旨在提供即时访问信息而无需屏幕或键盘的语音用户界面（UI）。在谷歌助手、苹果的Siri和亚马逊的Alexa之间，这些数字助手几乎无处不在。几乎每部手机都内置了某种变体，从旗舰型号到专为新兴市场设计的语音优先设备。它们也存在于智能音箱、计算机和车辆中。
- en: In most cases, the heavy lifting of speech recognition, natural language processing,
    and generating responses to users’ queries is done in the cloud, on powerful servers
    running large ML models. When a user asks a question, it’s sent to the server
    as a stream of audio. The server figures out what it means, looks up any required
    information, and sends the appropriate response back.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数情况下，语音识别、自然语言处理和生成用户查询响应的繁重工作是在云端完成的，运行大型ML模型的强大服务器上。当用户提出问题时，它会作为音频流发送到服务器。服务器会弄清楚这意味着什么，查找所需的任何信息，并发送适当的响应。
- en: But part of an assistants’ appeal is that they’re always on, ready to help you
    out. By saying “Hey Google,” or “Alexa,” you can wake up your assistant and tell
    it what you need without ever having to press a button. This means they must be
    listening for your voice 24/7, whether you’re sitting in your living room, driving
    down the freeway, or in the great outdoors with a phone in your hand.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 但助手吸引人的部分是它们总是在线的，随时准备帮助你。通过说“嘿，谷歌”或“Alexa”，你可以唤醒你的助手并告诉它你需要什么，而无需按下按钮。这意味着它们必须时刻倾听你的声音，无论你是坐在客厅里，驾驶在高速公路上，还是在户外手持手机。
- en: Although it’s easy to do speech recognition on a server, it’s just not feasible
    to send a constant stream of audio from a device to a data center. From a privacy
    perspective, sending every second of audio captured to a remote server would be
    an absolute disaster. Even if that were somehow okay, it would require vast amounts
    of bandwidth and chew through mobile data plans in hours. In addition, network
    communication uses energy, and sending a constant stream of data would quickly
    drain the device’s battery. What’s more, with every request going to a server
    and back, the assistant would feel laggy and slow to respond.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在服务器上进行语音识别很容易，但将设备捕获的音频不间断地发送到数据中心是不可行的。从隐私的角度来看，将每秒捕获的音频发送到远程服务器将是一场灾难。即使这样做没问题，也需要大量的带宽，并且会在几小时内耗尽移动数据套餐。此外，网络通信会消耗能量，不间断地发送数据流将迅速耗尽设备的电池。更重要的是，每个请求都要经过服务器来回传输，助手会感觉迟钝和反应迟缓。
- en: The only audio the assistant really needs is what immediately follows the wake
    word (e.g., “Hey Google”). What if we could detect that word without sending data,
    but start streaming when we heard it? We’d protect user privacy, save battery
    life and bandwidth, and wake up the assistant without waiting for the network.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 助手实际上只需要在唤醒词之后立即跟随的音频（例如“嘿，谷歌”）。如果我们能够在不发送数据的情况下检测到这个词，但在听到它时开始流式传输呢？我们将保护用户隐私，节省电池寿命和带宽，并在不等待网络的情况下唤醒助手。
- en: And this is where TinyML comes in. We can train a tiny model that listens for
    a wake word, and run it on a low-powered chip. If we embed this in a phone, it
    can listen for wake words all the time. When it hears the magic word, it informs
    the phone’s operating system (OS), which can begin to capture audio and send it
    to the server.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是TinyML的用武之地。我们可以训练一个微小的模型来监听唤醒词，并在低功耗芯片上运行它。如果我们将其嵌入到手机中，它可以一直监听唤醒词。当它听到魔法词时，它会通知手机的操作系统（OS），后者可以开始捕获音频并将其发送到服务器。
- en: Wake-word detection is the perfect application for TinyML. It’s ideally suited
    to delivering privacy, efficiency, speed, and offline inference. This approach,
    in which a tiny, efficient model “wakes up” a larger, more resource-hungry model,
    is called *cascading*.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 唤醒词检测是TinyML的完美应用。它非常适合提供隐私、效率、速度和离线推理。这种方法，即一个微小、高效的模型“唤醒”一个更大、更耗资源的模型，被称为*级联*。
- en: In this chapter, we examine how we can use a pretrained speech detection model
    to provide always-on wake-word detection using a tiny microcontroller. In [Chapter 8](ch08.xhtml#chapter_training_micro_speech),
    we’ll explore how the model is trained, and how to create our own.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨如何使用预训练的语音检测模型，利用微型微控制器提供始终开启的唤醒词检测。在[第8章](ch08.xhtml#chapter_training_micro_speech)中，我们将探讨模型是如何训练的，以及如何创建我们自己的模型。
- en: What We’re Building
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我们要构建什么
- en: We’re going to build an embedded application that uses an 18 KB model, trained
    on a dataset of speech commands, to classify spoken audio. The model is trained
    to recognize the words “yes” and “no,” and is also capable of distinguishing between
    unknown words and silence or background noise.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将构建一个嵌入式应用程序，使用一个18 KB的模型，该模型在语音命令数据集上进行训练，用于分类口头音频。该模型经过训练，可以识别“是”和“否”这两个词，还能够区分未知词和沉默或背景噪音。
- en: Our application will listen to its surroundings with a microphone and indicate
    when it has detected a word by lighting an LED or displaying data on a screen,
    depending on the capabilities of the device. Understanding this code will give
    you the ability to control any electronics project with voice commands.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的应用程序将通过麦克风监听周围环境，并在检测到一个词时通过点亮LED或在屏幕上显示数据来指示。理解这段代码将使你能够通过语音命令控制任何电子项目。
- en: Note
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: Like with [Chapter 5](ch05.xhtml#chapter_building_an_application), the source
    code for this application is available in the [TensorFlow GitHub repository](https://oreil.ly/Bql0J).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 与[第5章](ch05.xhtml#chapter_building_an_application)一样，此应用程序的源代码可在[TensorFlow
    GitHub存储库](https://oreil.ly/Bql0J)中找到。
- en: We’ll follow a similar pattern to [Chapter 5](ch05.xhtml#chapter_building_an_application),
    walking through the tests, then the application code, followed by the logic that
    makes the sample work on various devices.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将按照[第5章](ch05.xhtml#chapter_building_an_application)的类似模式，先浏览测试，然后是应用代码，接着是使样本在各种设备上工作的逻辑。
- en: 'We provide instructions for deploying the application to the following devices:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了将应用程序部署到以下设备的说明：
- en: '[Arduino Nano 33 BLE Sense](https://oreil.ly/6qlMD)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Arduino Nano 33 BLE Sense](https://oreil.ly/6qlMD)'
- en: '[SparkFun Edge](https://oreil.ly/-hoL-)'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SparkFun Edge](https://oreil.ly/-hoL-)'
- en: '[ST Microelectronics STM32F746G Discovery kit](https://oreil.ly/cvm4J)'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ST Microelectronics STM32F746G Discovery kit](https://oreil.ly/cvm4J)'
- en: Note
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: TensorFlow Lite regularly adds support for new devices, so if the device you’d
    like to use isn’t listed here, check the example’s [*README.md*](https://oreil.ly/OE3Pn).
    You can also check there for updated deployment instructions if you run into trouble
    following these steps.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Lite定期添加对新设备的支持，所以如果您想要使用的设备不在此列表中，请查看示例的[*README.md*](https://oreil.ly/OE3Pn)。如果您在按照这些步骤操作时遇到问题，也可以在那里查看更新的部署说明。
- en: This is a significantly more complex application than the “hello world” example,
    so let’s begin by walking through its structure.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个比“hello world”示例复杂得多的应用程序，所以让我们从浏览其结构开始。
- en: Application Architecture
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用程序架构
- en: 'Over the previous few chapters, you’ve learned that a machine learning application
    does the following sequence of things:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，您已经了解到机器学习应用程序执行以下一系列操作：
- en: Obtains an input
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取输入
- en: Preprocesses the input to extract features suitable to feed into a model
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预处理输入以提取适合输入模型的特征
- en: Runs inference on the processed input
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对处理后的输入进行推断运行
- en: Postprocesses the model’s output to make sense of it
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 后处理模型的输出以理解它
- en: Uses the resulting information to make things happen
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用生成的信息来实现一些事情
- en: The “hello world” example followed these steps in a very straightforward manner.
    It took a single floating-point number as input, generated by a simple counter.
    Its output was another floating-point number that we used directly to control
    visual output.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: “hello world”示例以非常直接的方式遵循了这些步骤。它接受一个由简单计数器生成的单个浮点数作为输入。其输出是另一个浮点数，我们直接用来控制可视输出。
- en: 'Our wake-word application will be more complicated for the following reasons:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 由于以下原因，我们的唤醒词应用程序将更加复杂：
- en: It takes audio data as an input. As you’ll see, this requires heavy processing
    before it can be fed into a model.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它将音频数据作为输入。正如您将看到的，这需要在输入模型之前进行大量处理。
- en: Its model is a classifier, outputting class probabilities. We’ll need to parse
    and make sense of this output.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其模型是一个分类器，输出类别概率。我们需要解析并理解这个输出。
- en: It’s designed to perform inference continually, on live data. We’ll need to
    write code to make sense of a stream of inferences.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它旨在持续进行推断，对实时数据进行处理。我们需要编写代码来理解一系列推断。
- en: The model is larger and more complex. We’ll be pushing our hardware to the limits
    of its capabilities.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该模型更大更复杂。我们将推动我们的硬件极限。
- en: Because much of this complexity results from the model we’ll be using, let’s
    learn a little more about it.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 因为很多复杂性是由我们将要使用的模型造成的，让我们多了解一些关于它的信息。
- en: Introducing Our Model
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍我们的模型
- en: As we mentioned earlier, the model we use in this chapter is trained to recognize
    the words “yes” and “no,” and is also capable of distinguishing between unknown
    words and silence or background noise.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，本章中使用的模型经过训练，可以识别“yes”和“no”这两个词，同时也能够区分未知词和沉默或背景噪音。
- en: The model was trained on a dataset called the [Speech Commands dataset](https://oreil.ly/qtOSI).
    This consists of 65,000 one-second-long utterances of 30 short words, crowdsourced
    online.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型是在一个名为[Speech Commands dataset](https://oreil.ly/qtOSI)的数据集上进行训练的。该数据集包含65,000个30个短单词的一秒长话语，是在线众包的。
- en: 'Although the dataset contains 30 different words, the model was trained to
    distinguish between only four categories: the words “yes” and “no,” “unknown”
    words (meaning the other 28 words in the dataset), and silence.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管数据集包含30个不同的单词，但模型只训练来区分四个类别：单词“yes”和“no”，“未知”单词（指数据集中的其他28个单词）以及沉默。
- en: The model takes in one second’s worth of data at a time. It outputs four probability
    scores, one for each of these four classes, predicting how likely it is that the
    data represented one of them.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型每次接受一秒钟的数据。它输出四个概率分数，分别对应这四个类别，预测数据代表其中一个类别的可能性有多大。
- en: However, the model doesn’t take in raw audio sample data. Instead, it works
    with *spectrograms*, which are two-dimensional arrays that are made up of slices
    of frequency information, each taken from a different time window.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，该模型不接受原始音频样本数据。相反，它使用*频谱图*，这是由频率信息片段组成的二维数组，每个片段来自不同的时间窗口。
- en: '[Figure 7-1](#spectrogram_yes) is a visual representation of a spectrogram
    generated from a one-second audio clip of someone saying “yes.” [Figure 7-2](#spectrogram_no)
    shows the same thing for the word “no.”'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '[图7-1](#spectrogram_yes)是从一个说“yes”的一秒音频片段生成的频谱图的可视表示。[图7-2](#spectrogram_no)展示了同样的内容，但是是“no”这个词。'
- en: '![Spectrogram for ''yes''](Images/timl_0822.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![''yes''的频谱图](Images/timl_0822.png)'
- en: Figure 7-1\. Spectrogram for “yes”
  id: totrans-45
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-1\. “yes”的频谱图
- en: '![Spectrogram for ''no''](Images/timl_0823.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![''no''的频谱图](Images/timl_0823.png)'
- en: Figure 7-2\. Spectrogram for “no”
  id: totrans-47
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-2\. “no”的频谱图
- en: By isolating the frequency information during preprocessing, we make the model’s
    life easier. During training, it doesn’t need to learn how to interpret raw audio
    data; instead, it gets to work with a higher-layer abstraction that distills the
    most useful information.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在预处理过程中隔离频率信息，我们让模型的生活变得更轻松。在训练过程中，它不需要学习如何解释原始音频数据；相反，它可以使用一个更高层次的抽象来处理最有用的信息。
- en: We’ll look at how the spectrogram is generated later in this chapter. For now,
    we just need to know that the model takes a spectrogram as input. Because a spectrogram
    is a two-dimensional array, we feed it into the model as a 2D tensor.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章后面看到如何生成频谱图。现在，我们只需要知道模型将频谱图作为输入。因为频谱图是一个二维数组，我们将其作为2D张量输入到模型中。
- en: There’s a type of neural network architecture that is specifically designed
    to work well with multidimensional tensors in which information is contained in
    the relationships between groups of adjacent values. It’s called a *convolutional
    neural network* (CNN).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 有一种神经网络架构专门设计用于处理多维张量，其中信息包含在相邻值组之间的关系中。它被称为*卷积神经网络*（CNN）。
- en: The most common example of this type of data is images, for which a group of
    adjacent pixels might represent a shape, pattern, or texture. During training,
    a CNN is able to identify these features and learn what they represent.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这种类型数据最常见的例子是图像，其中一组相邻的像素可能代表一个形状、图案或纹理。在训练过程中，CNN能够识别这些特征并学习它们代表什么。
- en: It can learn how simple image features (like lines or edges) fit together into
    more complex features (like an eye or an ear), and in turn how those features
    might be combined to form an input image, such as a photo of a human face. This
    means that a CNN can learn to distinguish between different classes of input image,
    such as between a photo of a person and a photo of a dog.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以学习简单图像特征（如线条或边缘）如何组合成更复杂的特征（如眼睛或耳朵），以及这些特征如何组合形成输入图像，比如人脸的照片。这意味着CNN可以学会区分不同类别的输入图像，比如区分人的照片和狗的照片。
- en: Although they’re often applied to images, which are 2D grids of pixels, CNNs
    can be used with any multidimensional vector input. It turns out they’re very
    well suited to working with spectrogram data.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它们通常应用于图像，即像素的2D网格，但CNN可以与任何多维向量输入一起使用。事实证明，它们非常适合处理频谱图数据。
- en: In [Chapter 8](ch08.xhtml#chapter_training_micro_speech), we’ll look at how
    this model was trained. Until then, let’s get back to discussing the architecture
    of our application.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第8章](ch08.xhtml#chapter_training_micro_speech)中，我们将看看这个模型是如何训练的。在那之前，让我们回到讨论我们应用程序的架构。
- en: All the Moving Parts
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 所有的组件
- en: As mentioned earlier, our wake-word application is a more complicated than the
    “hello world” example. [Figure 7-3](#application_architecture) shows the components
    that comprise it.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，我们的唤醒词应用程序比“hello world”示例更复杂。[图7-3](#application_architecture)显示了组成它的组件。
- en: '![Diagram of the components of our wake word application](Images/timl_0703.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![我们唤醒词应用程序的组件图](Images/timl_0703.png)'
- en: Figure 7-3\. The components of our wake-word application
  id: totrans-58
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-3。我们唤醒词应用程序的组件
- en: 'Let’s investigate what each of these pieces do:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来研究每个部分的功能：
- en: Main loop
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 主循环
- en: Like the “hello world” example, our application runs in a continuous loop. All
    of the subsequent processes are contained within it, and they execute continually,
    as fast as the microcontroller can run them, which is multiple times per second.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 与“hello world”示例一样，我们的应用程序在一个连续循环中运行。所有后续的过程都包含在其中，并且它们会持续执行，尽可能快地运行，即每秒多次。
- en: Audio provider
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 音频提供者
- en: The audio provider captures raw audio data from the microphone. Because the
    methods for capturing audio vary from device to device, this component can be
    overridden and customized.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 音频提供者从麦克风捕获原始音频数据。由于不同设备捕获音频的方法各不相同，这个组件可以被覆盖和定制。
- en: Feature provider
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 特征提供者
- en: The feature provider converts raw audio data into the spectrogram format that
    our model requires. It does so on a rolling basis as part of the main loop, providing
    the interpreter with a sequence of overlapping one-second windows.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 特征提供者将原始音频数据转换为我们模型所需的频谱图格式。它作为主循环的一部分以滚动方式提供，为解释器提供一系列重叠的一秒窗口。
- en: TF Lite interpreter
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: TF Lite解释器
- en: The interpreter runs the TensorFlow Lite model, transforming the input spectrogram
    into a set of probabilities.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 解释器运行TensorFlow Lite模型，将输入的频谱图转换为一组概率。
- en: Model
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 模型
- en: The model is included as a data array and run by the interpreter. The array
    is located in [*tiny_conv_micro_features_model_data.cc*](https://oreil.ly/XIUz9).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 模型包含在数据数组中，并由解释器运行。该数组位于[*tiny_conv_micro_features_model_data.cc*](https://oreil.ly/XIUz9)中。
- en: Command recognizer
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 命令识别器
- en: Because inference is run multiple times per second, the `RecognizeCommands`
    class aggregates the results and determines whether, on average, a known word
    was heard.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 由于推断每秒运行多次，`RecognizeCommands`类聚合结果并确定是否平均听到了一个已知的单词。
- en: Command responder
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 命令响应器
- en: If a command was heard, the command responder uses the device’s output capabilities
    to let the user know. Depending on the device, this could mean flashing an LED
    or showing data on an LCD display. It can be overridden for different device types.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果听到了一个命令，命令响应器将使用设备的输出功能让用户知道。根据设备的不同，这可能意味着闪烁LED或在LCD显示器上显示数据。它可以被覆盖以适应不同的设备类型。
- en: The example’s files on GitHub contain tests for each of these components. We’ll
    walk through them next to learn how they work.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub上的示例文件包含了每个组件的测试。我们将逐步学习它们是如何工作的。
- en: Walking Through the Tests
  id: totrans-75
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 测试过程
- en: As in [Chapter 5](ch05.xhtml#chapter_building_an_application), we can use tests
    to learn how the application works. We’ve already covered a lot of C++ and TensorFlow
    Lite basics, so we won’t need to explain every single line. Instead, let’s focus
    on the most important parts of each test and explain what’s going on.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 就像[第5章](ch05.xhtml#chapter_building_an_application)中一样，我们可以使用测试来了解应用程序的工作原理。我们已经涵盖了很多C++和TensorFlow
    Lite的基础知识，因此不需要解释每一行代码。相反，让我们专注于每个测试的最重要部分，并解释发生了什么。
- en: 'We’ll explore the following tests, which you can find in the [GitHub repository](https://oreil.ly/YiSbu):'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将探讨以下测试，您可以在[GitHub存储库](https://oreil.ly/YiSbu)中找到：
- en: '[*micro_speech_test.cc*](https://oreil.ly/FiBEN)'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[*micro_speech_test.cc*](https://oreil.ly/FiBEN)'
- en: Shows how to run inference on spectrogram data and interpret the results
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 展示如何对频谱图数据进行推断并解释结果
- en: '[*audio_provider_test.cc*](https://oreil.ly/bQOKd)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '[*audio_provider_test.cc*](https://oreil.ly/bQOKd)'
- en: Shows how to use the audio provider
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 展示如何使用音频提供程序
- en: '[*feature_provider_mock_test.cc*](https://oreil.ly/V9rK8)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '[*feature_provider_mock_test.cc*](https://oreil.ly/V9rK8)'
- en: Shows how to use the feature provider, using a *mock* (fake) implementation
    of the audio provider to pass in fake data
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 展示如何使用特征提供程序，使用*模拟*（虚假）音频提供程序的实现来传递虚假数据
- en: '[*recognize_commands_test.cc*](https://oreil.ly/P9pCG)'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '[*recognize_commands_test.cc*](https://oreil.ly/P9pCG)'
- en: Shows how to interpret the model’s output to decide whether a command was found
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 展示如何解释模型的输出以决定是否找到了命令
- en: '[*command_responder_test.cc*](https://oreil.ly/OqftF)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '[*command_responder_test.cc*](https://oreil.ly/OqftF)'
- en: Shows how to call the command responder to trigger an output
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 展示如何调用命令响应器以触发输出
- en: There are many more tests in the example, but exploring these few will give
    us an understanding of the key moving parts.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 示例中还有许多其他测试，但是探索这些测试将使我们了解关键的移动部分。
- en: The Basic Flow
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基本流程
- en: 'The test *micro_speech_test.cc* follows the same basic flow we’re familiar
    with from the “hello world” example: we load the model, set up the interpreter,
    and allocate tensors.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 测试*micro_speech_test.cc*遵循我们从“hello world”示例中熟悉的基本流程：加载模型，设置解释器并分配张量。
- en: However, there’s a notable difference. In the “hello world” example, we used
    the `AllOpsResolver` to pull in all of the deep learning operations that might
    be necessary to run the model. This is a reliable approach, but it’s wasteful
    because a given model probably doesn’t use all of the dozens of available operations.
    When deployed to a device, these unnecessary operations will take up valuable
    memory, so it’s best if we include only those we need.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有一个显著的区别。在“hello world”示例中，我们使用`AllOpsResolver`来引入可能需要运行模型的所有深度学习操作。这是一种可靠的方法，但是它是浪费的，因为给定模型可能并不使用所有数十个可用操作。当部署到设备时，这些不必要的操作将占用宝贵的内存，因此最好只包含我们需要的操作。
- en: 'To do this, we first define the ops that our model will need, at the top of
    the test file:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们首先在测试文件的顶部定义我们的模型将需要的操作：
- en: '[PRE0]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we set up logging and load our model, as normal:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们设置日志记录并加载我们的模型，正常进行：
- en: '[PRE1]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'After our model is loaded, we declare a `MicroMutableOpResolver` and use its
    method `AddBuiltin()` to add the ops we listed earlier:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 加载模型后，我们声明一个`MicroMutableOpResolver`并使用其方法`AddBuiltin()`来添加我们之前列出的操作：
- en: '[PRE2]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: You’re probably wondering how we know which ops to include for a given model.
    One way is to try running the model using a `MicroMutableOpResolver`, but without
    calling `AddBuiltin()` at all. Inference will fail, and the accompanying error
    messages will inform us which ops are missing and need to be added.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能想知道我们如何知道为给定模型包含哪些操作。一种方法是尝试使用`MicroMutableOpResolver`运行模型，但完全不调用`AddBuiltin()`。推断将失败，并且随附的错误消息将告诉我们缺少哪些操作需要添加。
- en: Note
  id: totrans-99
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The `MicroMutableOpResolver` is defined in [*tensorflow/lite/micro/micro_mutable_op_resolver.h*](https://oreil.ly/TGVZz),
    which you’ll need to add to your `include` statements.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`MicroMutableOpResolver`在[*tensorflow/lite/micro/micro_mutable_op_resolver.h*](https://oreil.ly/TGVZz)中定义，您需要将其添加到您的`include`语句中。'
- en: 'After the `MicroMutableOpResolver` is set up, we just carry on as usual, setting
    up our interpreter and its working memory:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 设置好`MicroMutableOpResolver`后，我们就像往常一样继续，设置解释器及其工作内存：
- en: '[PRE3]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In our “hello world” application we allocated only 2 * 1,024 bytes for the `tensor_arena`,
    given that the model was so small. Our speech model is a lot bigger, and it deals
    with more complex input and output, so it needs more space (10 1,024). This was
    determined by trial and error.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的“hello world”应用程序中，我们仅为`tensor_arena`分配了2 * 1,024字节的空间，因为模型非常小。我们的语音模型要大得多，它处理更复杂的输入和输出，因此需要更多空间（10
    1,024）。这是通过试错确定的。
- en: 'Next, we check the input tensor size. However, it’s a little different this
    time around:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们检查输入张量的大小。但是，这次有点不同：
- en: '[PRE4]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Because we’re dealing with a spectrogram as our input, the input tensor has
    more dimensions—four, in total. The first dimension is just a wrapper containing
    a single element. The second and third represent the “rows” and “columns” of our
    spectrogram, which happens to have 49 rows and 40 columns. The fourth, innermost
    dimension of the input tensor, which has size 1, holds each individual “pixel”
    of the spectrogram. We’ll look more at the spectrogram’s structure later on.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们的输入是频谱图，所以输入张量具有更多维度——总共四个。第一维只是包含单个元素的包装器。第二和第三代表我们的频谱图的“行”和“列”，恰好有49行和40列。输入张量的第四个、最内部的维度，大小为1，保存频谱图的每个单独的“像素”。我们稍后将更详细地查看频谱图的结构。
- en: 'Next, we grab a sample spectrogram for a “yes,” stored in the constant `g_yes_micro_f2e59fea_nohash_1_data`.
    The constant is defined in the file [*micro_features/yes_micro_features_data.cc*](https://oreil.ly/rVn8O),
    which was included by this test. The spectrogram exists as a 1D array, and we
    just iterate through it to copy it into the input tensor:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们获取一个“yes”样本频谱图，存储在常量`g_yes_micro_f2e59fea_nohash_1_data`中。该常量在文件[*micro_features/yes_micro_features_data.cc*](https://oreil.ly/rVn8O)中定义，该文件被此测试包含。频谱图存在为1D数组，我们只需迭代它将其复制到输入张量中：
- en: '[PRE5]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'After the input has been assigned, we run inference and inspect the output
    tensor’s size and shape:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在输入被分配之后，我们运行推断并检查输出张量的大小和形状：
- en: '[PRE6]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Our output has two dimensions. The first is just a wrapper. The second has four
    elements. This is the structure that holds the probabilities that each of our
    four classes (silence, unknown, “yes,” and “no”) were matched.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的输出有两个维度。第一个只是一个包装器。第二个有四个元素。这是保存每个四个类别（静音、未知、“是”和“否”）匹配概率的结构。
- en: 'The next chunk of code checks whether the probabilities were as expected. A
    given element of the output tensor always represents a certain class, so we know
    which index to check for each one. The order is defined during training:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来的代码块检查概率是否符合预期。输出张量的每个元素始终代表一个特定的类别，因此我们知道要检查每个类别的哪个索引。这个顺序在训练期间定义：
- en: '[PRE7]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We passed in a “yes” spectrogram, so we expect that the variable `yes_score`
    contains a higher probability than `silence_score`, `unknown_score`, and `no_score`.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们传入了一个“是”频谱图，因此我们期望变量`yes_score`包含的概率高于`silence_score`、`unknown_score`和`no_score`。
- en: 'When we’re satisfied with “yes,” we do the same thing with a “no” spectrogram.
    First, we copy in an input and run inference:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们对“是”满意时，我们用“否”频谱图做同样的事情。首先，我们复制一个输入并运行推断：
- en: '[PRE8]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'After inference is done, we confirm that “no” achieved the highest score:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 推断完成后，我们确认“no”获得了最高分数：
- en: '[PRE9]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: And we’re done!
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们完成了！
- en: 'To run this test, issue the following command from the root of the TensorFlow
    repository:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行此测试，请从TensorFlow存储库的根目录发出以下命令：
- en: '[PRE10]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Next up, let’s look at the source of all our audio data: the audio provider.'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看所有音频数据的来源：音频提供程序。
- en: The Audio Provider
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 音频提供程序
- en: The audio provider is what connects a device’s microphone hardware to our code.
    Every device has a different mechanism for capturing audio. As a result, [*audio_provider.h*](https://oreil.ly/89FGG)
    defines an interface for requesting audio data, and developers can write their
    own implementations for any platforms that they want to support.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 音频提供程序是将设备的麦克风硬件连接到我们的代码的部分。每个设备都有不同的机制来捕获音频。因此，[*audio_provider.h*](https://oreil.ly/89FGG)为请求音频数据定义了一个接口，开发人员可以为他们想要支持的任何平台编写自己的实现。
- en: Tip
  id: totrans-125
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: The example includes audio provider implementations for Arduino, STM32F746G,
    SparkFun Edge, and macOS. If you’d like this example to support a new device,
    you can read the existing implementations to learn how to do it.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 示例包括Arduino、STM32F746G、SparkFun Edge和macOS的音频提供程序实现。如果您希望此示例支持新设备，可以阅读现有的实现以了解如何实现。
- en: 'The core part of the audio provider is a function named `GetAudioSamples()`,
    defined in *audio_provider.h*. It looks like this:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 音频提供程序的核心部分是一个名为`GetAudioSamples()`的函数，在*audio_provider.h*中定义。它看起来像这样：
- en: '[PRE11]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: As described in *audio_provider.h*, the function is expected to return an array
    of 16-bit pulse code modulated (PCM) audio data. This is a very common format
    for digital audio.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 如*audio_provider.h*中所述，该函数应返回一个16位脉冲编码调制（PCM）音频数据数组。这是数字音频的一种非常常见的格式。
- en: The function is called with an `ErrorReporter` instance, a start time (`start_ms`),
    a duration (`duration_ms`), and two pointers.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 该函数被调用时带有一个`ErrorReporter`实例、一个开始时间（`start_ms`）、一个持续时间（`duration_ms`）和两个指针。
- en: These pointers are a mechanism for `GetAudioSamples()` to provide data. The
    caller declares variables of the appropriate type and then passes pointers to
    them when it calls the function. Inside the function’s implementation, the pointers
    are dereferenced and the variables’ values are set.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指针是`GetAudioSamples()`提供数据的机制。调用者声明适当类型的变量，然后在调用函数时将指针传递给它们。在函数的实现内部，指针被解引用，并设置变量的值。
- en: The first pointer, `audio_samples_size`, will receive the total number of 16-bit
    samples in the audio data. The second pointer, `audio_samples`, will receive an
    array containing the audio data itself.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个指针`audio_samples_size`将接收音频数据中16位样本的总数。第二个指针`audio_samples`将接收一个包含音频数据本身的数组。
- en: 'By looking at the tests, we can see this in action. There are two tests in
    [*audio_provider_test.cc*](https://oreil.ly/9XgFg), but we need to look only at
    the first to learn how to use the audio provider:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 通过查看测试，我们可以看到这一点。[*audio_provider_test.cc*](https://oreil.ly/9XgFg)中有两个测试，但我们只需要查看第一个来学习如何使用音频提供程序：
- en: '[PRE12]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The test shows how `GetAudioSamples()` is called with some values and some pointers.
    The test confirms that the pointers are assigned correctly after the function
    is called.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 测试展示了如何使用一些值和一些指针调用`GetAudioSamples()`。测试确认在调用函数后指针被正确赋值。
- en: Note
  id: totrans-136
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: You’ll notice the use of some constants, `kFeatureSliceDurationMs` and `kMaxAudioSampleSize`.
    These are values that were chosen when the model was trained, and you can find
    them in [*micro_features/micro_model_settings.h*](https://oreil.ly/WLuug).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 您会注意到一些常量的使用，`kFeatureSliceDurationMs`和`kMaxAudioSampleSize`。这些是在模型训练时选择的值，您可以在[*micro_features/micro_model_settings.h*](https://oreil.ly/WLuug)中找到它们。
- en: The default implementation of *audio_provider.cc* just returns an empty array.
    To prove that it’s the right size, the test simply loops through it for the expected
    number of samples.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '*audio_provider.cc*的默认实现只返回一个空数组。为了证明它的大小是正确的，测试只是简单地循环遍历它以获取预期数量的样本。'
- en: In addition to `GetAudioSamples()`, the audio provider contains a function called
    `LatestAudioTimestamp()`. This is intended to return the time that audio data
    was last captured, in milliseconds. This information is needed by the feature
    provider to determine what audio data to fetch.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 除了`GetAudioSamples()`之外，音频提供程序还包含一个名为`LatestAudioTimestamp()`的函数。这个函数旨在返回音频数据最后捕获的时间，以毫秒为单位。特征提供程序需要这些信息来确定要获取哪些音频数据。
- en: 'To run the audio provider tests, use the following command:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行音频提供程序测试，请使用以下命令：
- en: '[PRE13]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The audio provider is used by the feature provider as a source of fresh audio
    samples, so let’s take a look at that next.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 音频提供程序被特征提供程序用作新鲜音频样本的来源，所以让我们接着看一下。
- en: The Feature Provider
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 特征提供程序
- en: The feature provider converts raw audio, obtained from the audio provider, into
    spectrograms that can be fed into our model. It is called during the main loop.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 特征提供者将从音频提供者获取的原始音频转换为可以输入到我们模型中的频谱图。它在主循环中被调用。
- en: 'Its interface is defined in [*feature_provider.h*](https://oreil.ly/59uTO),
    and looks like this:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 其接口在[*feature_provider.h*](https://oreil.ly/59uTO)中定义，如下所示：
- en: '[PRE14]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: To see how it’s used, we can take a look at the tests in [*feature_provider_mock_test.cc*](https://oreil.ly/N3YPu).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看它的使用方式，我们可以看一下[*feature_provider_mock_test.cc*](https://oreil.ly/N3YPu)中的测试。
- en: For there to be audio data for the feature provider to work with, these tests
    use a special fake version of the audio provider, known as a mock, that is set
    up to provide audio data. It is defined in [*audio_provider_mock.cc*](https://oreil.ly/aQSP8).
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使特征提供者能够处理音频数据，这些测试使用了一个特殊的假版本音频提供者，称为模拟，它被设置为提供音频数据。它在[*audio_provider_mock.cc*](https://oreil.ly/aQSP8)中定义。
- en: Note
  id: totrans-149
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: The mock audio provider is substituted for the real thing in the build instructions
    for the test, which you can find in [*Makefile.inc*](https://oreil.ly/51m0b) under
    `FEATURE_PROVIDER_MOCK_TEST_SRCS`.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在测试的构建说明中，模拟音频提供者被真实的东西替代，您可以在[*Makefile.inc*](https://oreil.ly/51m0b)中的`FEATURE_PROVIDER_MOCK_TEST_SRCS`下找到。
- en: 'The file *feature_provider_mock_test.cc* contains two tests. Here’s the first
    one:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 文件*feature_provider_mock_test.cc*包含两个测试。这是第一个：
- en: '[PRE15]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'To create a `FeatureProvider`, we call its constructor, passing in `feature_size`
    and `feature_data` arguments:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个`FeatureProvider`，我们调用它的构造函数，传入`feature_size`和`feature_data`参数：
- en: '[PRE16]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The first argument indicates how many total data elements should be in the spectrogram.
    The second argument is a pointer to an array that we want to be populated with
    the spectrogram data.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个参数指示频谱图中应该有多少总数据元素。第二个参数是一个指向我们希望用频谱图数据填充的数组的指针。
- en: The number of elements in the spectrogram was decided when the model was trained
    and is defined as `kFeatureElementCount` in [*micro_features/micro_model_settings.h*](https://oreil.ly/FdUCq).
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 频谱图中的元素数量是在模型训练时决定的，并在[*micro_features/micro_model_settings.h*](https://oreil.ly/FdUCq)中定义为`kFeatureElementCount`。
- en: 'To obtain features for the past second of audio, `feature_provider.PopulateFeatureData()`
    is called:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获取过去一秒钟的音频特征，会调用`feature_provider.PopulateFeatureData()`：
- en: '[PRE17]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: We supply an `ErrorReporter` instance, an integer representing the last time
    this method was called (`last_time_in_ms`), the current time (`time_in_ms`), and
    a pointer to an integer that will be updated with how many new *feature slices*
    we receive (`how_many_new_slices`). A slice is just one row of the spectrogram,
    representing a chunk of time.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供一个`ErrorReporter`实例，一个表示上次调用此方法的时间的整数（`last_time_in_ms`），当前时间（`time_in_ms`）以及一个指向整数的指针，该指针将更新为我们接收到多少个新的*特征切片*（`how_many_new_slices`）。切片只是频谱图的一行，代表一段时间。
- en: Because we always want the last second of audio, the feature provider will compare
    when it was last called (`last_time_in_ms`) with the current time (`time_in_ms`),
    create spectrogram data from the audio captured during that time, and then update
    the `feature_data` array to add any additional slices and drop any that are older
    than one second.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们总是想要最后一秒钟的音频，特征提供者将比较上次调用时的时间（`last_time_in_ms`）和当前时间（`time_in_ms`），从那段时间内捕获的音频创建频谱数据，然后更新`feature_data`数组以添加任何额外的切片并删除超过一秒钟的旧切片。
- en: When `PopulateFeatureData()` runs, it will request audio from the mock audio
    provider. The mock will give it audio representing a “yes,” and the feature provider
    will process it and provide the result.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 当`PopulateFeatureData()`运行时，它将从模拟音频提供者请求音频。模拟将提供代表“yes”的音频，特征提供者将处理它并提供结果。
- en: 'After calling `PopulateFeatureData()`, we check whether its result is what
    we expect. We compare the data it generated to a known spectrogram that is correct
    for the “yes” input given by the mock audio provider:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在调用`PopulateFeatureData()`之后，我们检查其结果是否符合预期。我们将生成的数据与由模拟音频提供者提供的“yes”输入的已知频谱图进行比较：
- en: '[PRE18]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The mock audio provider can provide audio for a “yes” or a “no” depending on
    which start and end times are passed into it. The second test in *feature_provider_mock_test.cc*
    does exactly the same thing as the first, but for audio representing “no.”
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 模拟音频提供者可以根据传入的开始和结束时间提供“yes”或“no”的音频。*feature_provider_mock_test.cc*中的第二个测试与第一个测试完全相同，但表示“no”的音频。
- en: 'To run the tests, use the following command:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 运行测试时，请使用以下命令：
- en: '[PRE19]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: How the feature provider converts audio to a spectrogram
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 特征提供者如何将音频转换为频谱图
- en: The feature provider is implemented in [*feature_provider.cc*](https://oreil.ly/xzLzE).
    Let’s talk through how it works.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 特征提供者在[*feature_provider.cc*](https://oreil.ly/xzLzE)中实现。让我们来看看它是如何工作的。
- en: As we’ve discussed, its job is to populate an array that represents a spectrogram
    of one second of audio. It’s designed to be called in a loop, so to avoid unnecessary
    work, it will generate new features only for the time between now and when it
    was last called. If it were called less than a second ago, it would keep some
    of its previous output and generate only the missing parts.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们讨论过的，它的工作是填充一个代表一秒钟音频的频谱图的数组。它被设计为在循环中调用，因此为了避免不必要的工作，它只会为现在和上次调用之间的时间生成新的特征。如果它在不到一秒钟之前被调用，它将保留一些先前的输出并仅生成缺失的部分。
- en: In our code, each spectrogram is represented as a 2D array, with 40 columns
    and 49 rows, where each row represents a 30-millisecond (ms) sample of audio split
    into 43 frequency buckets.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的代码中，每个频谱图都表示为一个二维数组，有40列和49行，其中每一行代表一个30毫秒（ms）的音频样本，分成43个频率桶。
- en: To create each row, we run a 30-ms slice of audio input through a *fast Fourier
    transform* (FFT) algorithm. This technique analyzes the frequency distribution
    of audio in the sample and creates an array of 256 frequency buckets, each with
    a value from 0 to 255\. These are averaged together into groups of six, leaving
    us with 43 buckets.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建每一行，我们通过*快速傅立叶变换*（FFT）算法运行30毫秒的音频输入。这种技术分析了样本中音频的频率分布，并创建了一个由256个频率桶组成的数组，每个值从0到255。这些被平均成六组，留下43个桶。
- en: The code that does this is in the file [*micro_features/micro_features_generator.cc*](https://oreil.ly/HVU2G),
    and is called by the feature provider.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此操作的代码位于文件[*micro_features/micro_features_generator.cc*](https://oreil.ly/HVU2G)中，并由特征提供程序调用。
- en: To build the entire 2D array, we combine the results of running the FFT on 49
    consecutive 30-ms slices of audio, with each slice overlapping the last by 10
    ms. [Figure 7-4](#spectrogram_generation) shows how this happens.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建整个二维数组，我们将在49个连续的30毫秒音频片段上运行FFT的结果组合在一起，每个片段与上一个片段重叠10毫秒。[图7-4](#spectrogram_generation)展示了这是如何发生的。
- en: You can see how the 30-ms sample window is moved forward by 20 ms each time
    until it has covered the full one-second sample. The resulting spectrogram is
    ready to pass into our model.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以看到30毫秒的样本窗口每次向前移动20毫秒，直到覆盖完整的一秒样本。生成的频谱图准备传递到我们的模型中。
- en: 'We can understand how this process happens in *feature_provider.cc*. First,
    it determines which slices it actually needs to generate based on the time `PopulateFeatureData()`
    was last called:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在*feature_provider.cc*中了解这个过程是如何发生的。首先，它根据上次调用`PopulateFeatureData()`的时间确定实际需要生成哪些片段：
- en: '[PRE20]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '![Diagram of audio samples being processed](Images/timl_0704.png)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![正在处理的音频样本的图表](Images/timl_0704.png)'
- en: Figure 7-4\. Diagram of audio samples being processed
  id: totrans-178
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-4。正在处理的音频样本的图表
- en: 'If it hasn’t run before, or it ran more than one second ago, it will generate
    the maximum number of slices:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 如果它以前没有运行过，或者它在一秒钟前运行过，它将生成最大数量的片段：
- en: '[PRE21]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The resulting number is written to `how_many_new_slices`.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的数字被写入`how_many_new_slices`。
- en: 'Next, it calculates how many of any existing slices it should keep, and shifts
    data in the array around to make room for any new ones:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，它计算应保留多少现有片段，并将数组中的数据移动以为任何新片段腾出空间：
- en: '[PRE22]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Note
  id: totrans-184
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If you’re a seasoned C++ author, you might wonder why we don’t use standard
    libraries to do things like copying data around. The reason is that we’re trying
    to avoid unnecessary dependencies, in an effort to keep our binary size small.
    Because embedded platforms have very little memory, a smaller application binary
    means that we have space for a larger and more accurate deep learning model.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您是经验丰富的C++作者，您可能会想知道为什么我们不使用标准库来做诸如数据复制之类的事情。原因是我们试图避免不必要的依赖关系，以保持我们的二进制文件大小较小。因为嵌入式平台的内存非常有限，较小的应用程序二进制文件意味着我们有空间容纳更大更准确的深度学习模型。
- en: 'After moving data around, it begins a loop that iterates once for each new
    slice that it needs. In this loop, it first requests audio for that slice from
    the audio provider using `GetAudioSamples()`:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在移动数据之后，它开始一个循环，每次迭代一次，它都需要一个新的片段。在这个循环中，它首先使用`GetAudioSamples()`从音频提供程序请求该片段的音频：
- en: '[PRE23]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: To complete the loop iteration, it passes that data into `GenerateMicroFeatures()`,
    defined in *micro_features/micro_features_generator.h*. This is the function that
    performs the FFT and returns the audio frequency information.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成循环迭代，它将数据传递给`GenerateMicroFeatures()`，在*micro_features/micro_features_generator.h*中定义。这是执行FFT并返回音频频率信息的函数。
- en: 'It also passes a pointer, `new_slice_data`, which points at the memory location
    where the new data should be written:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 它还传递了一个指针`new_slice_data`，指向新数据应写入的内存位置：
- en: '[PRE24]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: After this process has happened for each slice, we have an entire second’s worth
    of up-to-date spectrogram.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在每个片段完成这个过程之后，我们有了整整一秒的最新频谱图。
- en: Tip
  id: totrans-192
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: The function that generates the FFT is `GenerateMicroFeatures()`. If you’re
    interested, you can read its definition in [*micro_features/micro_features_generator.cc*](https://oreil.ly/L0juB).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 生成FFT的函数是`GenerateMicroFeatures()`。如果您感兴趣，您可以在[*micro_features/micro_features_generator.cc*](https://oreil.ly/L0juB)中阅读其定义。
- en: If you’re building your own application that uses spectrograms, you can reuse
    this code as is. You’ll need to use the same code to pre-process data into spectrograms
    when training your model.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在构建自己的应用程序并使用频谱图，您可以直接重用此代码。在训练模型时，您需要使用相同的代码将数据预处理为频谱图。
- en: Once we have a spectrogram, we can run inference on it using the model. After
    this happens, we need to interpret the results. That task belongs to the class
    we explore next, `RecognizeCommands`.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们有了频谱图，我们就可以使用模型对其进行推理。发生这种情况后，我们需要解释结果。这项任务属于我们接下来要探讨的类`RecognizeCommands`。
- en: The Command Recognizer
  id: totrans-196
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 命令识别器
- en: After our model outputs a set of probabilities that a known word was spoken
    in the last second of audio, it’s the job of the `RecognizeCommands` class to
    determine whether this indicates a successful detection.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的模型输出了一组概率，表明在音频的最后一秒中说出了一个已知的单词之后，`RecognizeCommands`类的工作就是确定这是否表示成功的检测。
- en: 'It seems like this would be simple: if the probability in a given category
    is more than a certain threshold, the word was spoken. However, in the real world,
    things become a bit more complicated.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这似乎很简单：如果给定类别中的概率超过某个阈值，那么该单词已被说出。然而，在现实世界中，事情变得有点复杂。
- en: As we established earlier, we’re running multiple inferences per second, each
    on a one-second window of data. This means that we’ll run inference on any given
    word multiple times, in multiple windows.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前建立的，我们每秒运行多个推理，每个推理在一秒钟的数据窗口上运行。这意味着我们将在任何给定单词上多次运行推理，在多个窗口上。
- en: In [Figure 7-5](#noted_negative), you can see a waveform of the word “noted”
    being spoken, surrounded by a box representing a one-second window being captured.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在[图7-5](#noted_negative)中，您可以看到单词“noted”被说出的波形，周围有一个代表被捕获的一秒窗口的框。
- en: '![The word ''noted'' being captured in our window](Images/timl_0705.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![我们的窗口中捕获到的单词“noted”](Images/timl_0705.png)'
- en: Figure 7-5\. The word “noted” being captured in our window
  id: totrans-202
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-5。在我们的窗口中捕获到的单词“noted”
- en: Our model is trained to detect the word “no,” and it understands that the word
    “noted” is not the same thing. If we run inference on this one-second window,
    it will (hopefully) output a low probability for the word “no.” However, what
    if the window came slightly earlier in the audio stream, as in [Figure 7-6](#noted_positive)?
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的模型经过训练，可以检测到“no”一词，并且它知道“noted”一词不是同一回事。如果我们在这一秒钟的窗口上进行推理，它将（希望）输出“no”一词的低概率。但是，如果窗口稍早出现在音频流中，如[图7-6](#noted_positive)中所示，会发生什么呢？
- en: '![Part of the word ''noted'' being captured in our window](Images/timl_0706.png)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![我们窗口中捕获到的“noted”一词的部分](Images/timl_0706.png)'
- en: Figure 7-6\. Part of the word “noted” being captured in our window
  id: totrans-205
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-6。在我们的窗口中捕获到“noted”一词的部分
- en: In this case, the only part of the word “noted” that appears within the window
    is its first syllable. Because the first syllable of “noted” sounds like “no,”
    it’s likely that the model will interpret this as having a high probability of
    being a “no.”
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，“noted”一词的唯一部分出现在窗口中的是它的第一个音节。因为“noted”的第一个音节听起来像“no”，所以模型很可能会将其解释为“no”的概率很高。
- en: This problem, along with others, means that we can’t rely on a single inference
    to tell us whether a word was spoken. This is where `RecognizeCommands` comes
    in!
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 这个问题，以及其他问题，意味着我们不能依赖单个推理来告诉我们一个单词是否被说出。这就是`RecognizeCommands`的作用所在！
- en: The recognizer calculates the average score for each word over the past few
    inferences, and decides whether it’s high enough to count as a detection. To do
    this, we feed it each inference result as they roll in.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 识别器计算每个单词在过去几次推理中的平均分数，并决定是否高到足以被视为检测。为了做到这一点，我们将每个推理结果传递给它。
- en: 'You can see its interface in [*recognize_commands.h*](https://oreil.ly/5W3Ea),
    partially reproduced here:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[*recognize_commands.h*](https://oreil.ly/5W3Ea)中看到它的接口，这里部分重现：
- en: '[PRE25]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The class `RecognizeCommands` is defined, along with a constructor that defines
    default values for a few things:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 类`RecognizeCommands`被定义，以及一个构造函数，为一些默认值进行了定义：
- en: The length of the averaging window (`average_window_duration_ms`)
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平均窗口的长度（`average_window_duration_ms`）
- en: The minimum average score that counts as a detection (`detection_threshold`)
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 作为检测的最低平均分数（`detection_threshold`）
- en: The amount of time we’ll wait after hearing a command before recognizing a second
    one (`suppression_ms`)
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在识别第二个命令之前听到命令后等待的时间量（`suppression_ms`）
- en: The minimum number of inferences required in the window for a result to count
    (`3`)
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在窗口中需要的最小推理数量，以便结果计数（`3`）
- en: The class has one method, `ProcessLatestResults()`. It accepts a pointer to
    a `TfLiteTensor` containing the model’s output (`latest_results`), and it must
    be called with the current time (`current_time_ms`).
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 该类有一个方法，`ProcessLatestResults()`。它接受一个指向包含模型输出的`TfLiteTensor`的指针（`latest_results`），并且必须在当前时间（`current_time_ms`）下调用。
- en: In addition, it takes three pointers that it uses for output. First, it gives
    us the name of any word that was detected (`found_command`). It also provides
    the average score of the command (`score`) and whether the command is new or has
    been heard in previous inferences within a certain timespan (`is_new_command`).
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，它还接受三个指针用于输出。首先，它给出了任何被检测到的单词的名称（`found_command`）。它还提供了命令的平均分数（`score`）以及命令是新的还是在一定时间内的先前推理中已经听到过（`is_new_command`）。
- en: Averaging the results of multiple inferences is a useful and common technique
    when dealing with time-series data. In the next few pages, we’ll walk through
    the code in [*recognize_commands.cc*](https://oreil.ly/lAh-0) and learn a bit
    about how it works. You don’t need to understand every line, but it’s helpful
    to get some insight into what might be a helpful tool in your own projects.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 对多次推理结果进行平均是处理时间序列数据时的一种有用且常见的技术。在接下来的几页中，我们将逐步介绍[*recognize_commands.cc*](https://oreil.ly/lAh-0)中的代码，并了解一些它的工作原理。你不需要理解每一行，但了解一些可能对你自己的项目有帮助的工具是有益的。
- en: 'First, we make sure the input tensor is the right shape and type:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们确保输入张量的形状和类型是正确的：
- en: '[PRE26]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Next, we check `current_time_ms` to verify that it is after the most recent
    result in our averaging window:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们检查`current_time_ms`以验证它是否在我们的平均窗口中最近的结果之后：
- en: '[PRE27]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'After that, we add the latest result to a list of results we’ll be averaging:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们将最新的结果添加到我们将要进行平均的结果列表中：
- en: '[PRE28]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'If there are fewer results in our averaging window than the minimum number
    (defined by `minimum_count_`, which is `3` by default), we can’t provide a valid
    average. In this case, we set the output pointers to indicate that `found_command`
    is the most recent top command, that the score is 0, and that the command is not
    a new one:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的平均窗口中的结果少于最小数量（由`minimum_count_`定义，默认为`3`），我们无法提供有效的平均值。在这种情况下，我们将输出指针设置为指示`found_command`是最近的顶级命令，分数为0，并且该命令不是新的：
- en: '[PRE29]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Otherwise, we continue by averaging all of the scores in the window:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，我们继续通过平均窗口中的所有分数：
- en: '[PRE30]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We now have enough information to identify which category is our winner. Establishing
    this is a simple process:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有足够的信息来确定哪个类别是我们的赢家。建立这一点是一个简单的过程：
- en: '[PRE31]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The final piece of logic determines whether the result was a valid detection.
    To do this, it ensures that its score is above the detection threshold (200 by
    default), and that it didn’t happen too quickly after the last valid detection,
    which can be an indication of a faulty result:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一部分逻辑确定结果是否是有效检测。为了做到这一点，它确保其分数高于检测阈值（默认为200），并且它没有在上次有效检测之后发生得太快，这可能是一个错误结果的指示：
- en: '[PRE32]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: If the result was valid, `is_new_command` is set to `true`. This is what the
    caller can use to determine whether a word was genuinely detected.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 如果结果有效，`is_new_command`被设置为`true`。这是调用者可以用来确定一个单词是否真正被检测到。
- en: The tests (in [*recognize_commands_test.cc*](https://oreil.ly/rOkMb)) exercise
    various different combinations of inputs and results that are stored in the averaging
    window.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 测试（在[*recognize_commands_test.cc*](https://oreil.ly/rOkMb)中）对存储在平均窗口中的各种不同输入和结果进行了测试。
- en: 'Let’s walk through one of the tests, `RecognizeCommandsTestBasic`, which demonstrates
    how `RecognizeCommands` is used. First, we just create an instance of the class:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们走一遍`RecognizeCommandsTestBasic`中的一个测试，演示了如何使用`RecognizeCommands`。首先，我们只是创建了该类的一个实例：
- en: '[PRE33]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Next, we create a tensor containing some fake inference results, which will
    be used by `ProcessLatestResults()` to decide whether a command was heard:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们创建一个包含一些虚假推理结果的张量，这将由`ProcessLatestResults()`使用来决定是否听到了命令：
- en: '[PRE34]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Then, we set up some variables that will be set with the output of `ProcessLatestResults()`:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们设置一些变量，这些变量将被`ProcessLatestResults()`的输出设置：
- en: '[PRE35]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Finally, we call `ProcessLatestResults()`, providing pointers to these variables
    along with the tensor containing the results. We assert that the function will
    return `kTfLiteOk`, indicating that the input was processed successfully:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们调用`ProcessLatestResults()`，提供这些变量的指针以及包含结果的张量。我们断言该函数将返回`kTfLiteOk`，表示输入已成功处理：
- en: '[PRE36]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The other tests in the file perform some more exhaustive checks to make sure
    the function is performing correctly. You can read through them to learn more.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 文件中的其他测试执行了一些更详尽的检查，以确保函数的正确执行。您可以阅读它们以了解更多信息。
- en: 'To run all of the tests, use the following command:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行所有测试，请使用以下命令：
- en: '[PRE37]'
  id: totrans-245
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: As soon as we’ve determined whether a command was detected, it’s time to share
    our results with the world (or at least our on-board LEDs). The command responder
    is what makes this happen.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们确定是否检测到命令，就是与世界分享我们的结果的时候了（或者至少是我们的板载LED）。命令响应器就是让这一切发生的原因。
- en: The Command Responder
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 命令响应器
- en: The final piece in our puzzle, the command responder, is what produces an output
    to let us know that a word was detected.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们谜题的最后一块，命令响应器，是产生输出的部分，让我们知道检测到了一个单词。
- en: The command responder is designed to be overridden for each type of device.
    We explore the device-specific implementations later in this chapter.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 命令响应器被设计为针对每种类型的设备进行覆盖。我们将在本章后面探讨特定设备的实现。
- en: 'For now, let’s look at its very simple reference implementation, which just
    logs detection results as text. You can find it in the file [*command_responder.cc*](https://oreil.ly/kMjg2):'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看一下它非常简单的参考实现，它只是将检测结果记录为文本。您可以在文件[*command_responder.cc*](https://oreil.ly/kMjg2)中找到它：
- en: '[PRE38]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'That’s it! The file implements just one function: `RespondToCommand()`. As
    parameters, it expects an `error_reporter`, the current time (`current_time`),
    the command that was last detected (`found_command`), the score it received (`score`),
    and whether the command was newly heard (`is_new_command`).'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！该文件只实现了一个函数：`RespondToCommand()`。作为参数，它期望一个`error_reporter`，当前时间（`current_time`），上次检测到的命令（`found_command`），它收到的分数（`score`）以及命令是否是新听到的（`is_new_command`）。
- en: It’s important to note that in our program’s main loop, this function will be
    called every time inference is performed, even if a command was not detected.
    This means that we should check `is_new_command` to determine whether anything
    needs to be done.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，在我们程序的主循环中，每次执行推理时都会调用此函数，即使没有检测到命令。这意味着我们应该检查`is_new_command`以确定是否需要执行任何操作。
- en: 'The test for this function, in [*command_responder_test.cc*](https://oreil.ly/loLZo),
    is equally simple. It just calls the function, given that there’s no way for it
    to test that it generates the correct output:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*command_responder_test.cc*](https://oreil.ly/loLZo)中对此函数的测试同样简单。它只是调用该函数，因为它无法测试生成正确的输出：
- en: '[PRE39]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'To run this test, enter this in your terminal:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行此测试，请在终端中输入以下内容：
- en: '[PRE40]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: And that’s it! We’ve walked through all of the components of the application.
    Now, let’s see how they come together in the program itself.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！我们已经走过了应用程序的所有组件。现在，让我们看看它们如何在程序中结合在一起。
- en: Listening for Wake Words
  id: totrans-259
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监听唤醒词
- en: You can find the following code in [*main_functions.cc*](https://oreil.ly/n2eD1),
    which defines the `setup()` and `loop()` functions that are the core of our program.
    Let’s read through it together!
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在[*main_functions.cc*](https://oreil.ly/n2eD1)中找到以下代码，该代码定义了我们程序的核心`setup()`和`loop()`函数。让我们一起阅读一下！
- en: Because you’re now a seasoned TensorFlow Lite expert, a lot of this code will
    look familiar to you. So let’s try to focus on the new bits.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 因为您现在是一个经验丰富的TensorFlow Lite专家，所以这些代码对您来说应该很熟悉。让我们试着专注于新的部分。
- en: 'First, we list the ops that we want to use:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们列出要使用的操作：
- en: '[PRE41]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Next, we set up our global variables:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们设置全局变量：
- en: '[PRE42]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Notice how we declare a `FeatureProvider` and a `RecognizeCommands` in addition
    to the usual TensorFlow suspects. We also declare a variable named `g_previous_time`,
    which keeps track of the most recent time we received new audio samples.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，除了通常的TensorFlow组件外，我们还声明了一个`FeatureProvider`和一个`RecognizeCommands`。我们还声明了一个名为`g_previous_time`的变量，用于跟踪我们接收到新音频样本的最近时间。
- en: 'Next up, in the `setup()` function, we load the model, set up our interpreter,
    add ops, and allocate tensors:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在`setup()`函数中，我们加载模型，设置解释器，添加操作并分配张量：
- en: '[PRE43]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'After allocating tensors, we check that the input tensor is the correct shape
    and type:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在分配张量之后，我们检查输入张量是否具有正确的形状和类型：
- en: '[PRE44]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Next comes the interesting stuff. First, we instantiate a `FeatureProvider`,
    pointing it at our input tensor:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是有趣的部分。首先，我们实例化一个`FeatureProvider`，将其指向我们的输入张量：
- en: '[PRE45]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We then create a `RecognizeCommands` instance and initialize our `previous_time`
    variable:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们创建一个`RecognizeCommands`实例并初始化我们的`previous_time`变量：
- en: '[PRE46]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Up next, it’s time for our `loop()` function. Like in the previous example,
    this function will be called over and over again, indefinitely. In the loop, we
    first use the feature provider to create a spectrogram:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，是我们的`loop()`函数的时间了。就像前面的例子一样，这个函数将被无限次调用。在循环中，我们首先使用特征提供程序创建一个频谱图：
- en: '[PRE47]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: If there’s no new data since the last iteration, we don’t bother running inference.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 如果自上次迭代以来没有新数据，我们就不会运行推理。
- en: 'After we have our input, we just invoke the interpreter:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们有了输入后，我们只需调用解释器：
- en: '[PRE48]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'The model’s output tensor is now filled with the probabilities for each category.
    To interpret them, we use our `RecognizeCommands` instance. We obtain a pointer
    to the output tensor, then set up a few variables to receive the `ProcessLatestResults()`
    output:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，模型的输出张量已经填充了每个类别的概率。为了解释它们，我们使用我们的`RecognizeCommands`实例。我们获取输出张量的指针，然后设置一些变量来接收`ProcessLatestResults()`的输出：
- en: '[PRE49]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Finally, we call the command responder’s `RespondToCommand()` method so that
    it can notify users if a word was detected:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们调用命令响应器的`RespondToCommand()`方法，以便它可以通知用户是否检测到了一个单词：
- en: '[PRE50]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: And that’s it! The call to `RespondToCommand()` is the final thing in our loop.
    Everything from feature generation onward will repeat endlessly, checking the
    audio for known words and producing some output if one is confirmed.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！调用`RespondToCommand()`是我们循环中的最后一件事。从特征生成开始，一直到之后的所有内容都将无限重复，检查已知单词的音频并在确认时产生一些输出。
- en: 'The `setup()` and `loop()` functions are called by our `main()` function, defined
    in *main.cc*, which begins the loop when the application starts:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`setup()`和`loop()`函数是由我们的`main()`函数调用的，该函数在*main.cc*中定义，当应用程序启动时开始循环：
- en: '[PRE51]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: Running Our Application
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行我们的应用程序
- en: 'The example contains an audio provider compatible with macOS. If you have access
    to a Mac, you can run the example on your development machine. First, use the
    following command to build it:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 示例包含一个与macOS兼容的音频提供程序。如果您有Mac，可以在开发机器上运行示例。首先，使用以下命令构建它：
- en: '[PRE52]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'After the build completes, you can run the example with the following command:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 构建完成后，您可以使用以下命令运行示例：
- en: '[PRE53]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: You might see a pop-up asking for microphone access. If so, grant it, and the
    program will start.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会看到一个弹出窗口询问麦克风访问权限。如果是这样，请授予权限，程序将开始运行。
- en: 'Try saying “yes” and “no.” You should see output that looks like the following:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试说“是”和“否”。您应该看到类似以下的输出：
- en: '[PRE54]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: The number after each detected word is its score. By default, the command recognizer
    component considers matches as valid only if their score is more than 200, so
    all of the scores you see will be at least 200.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 每个检测到的单词后面都是它的得分。默认情况下，命令识别器组件仅在其得分超过200时才将匹配视为有效，因此您看到的所有得分都至少为200。
- en: The number after the score is the number of milliseconds since the program was
    started.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 得分后面的数字是自程序启动以来的毫秒数。
- en: If you don’t see any output, make sure your Mac’s internal microphone is selected
    in the Mac’s Sound menu and that its input volume is turned up high enough.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您没有看到任何输出，请确保Mac的内置麦克风在Mac的声音菜单中被选中，并且其输入音量足够高。
- en: We’ve established that the program works on a Mac. Now, let’s get it running
    on some embedded hardware.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经确定程序在Mac上运行正常。现在，让我们在一些嵌入式硬件上运行它。
- en: Deploying to Microcontrollers
  id: totrans-299
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署到微控制器
- en: 'In this section, we deploy the code to three different devices:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将代码部署到三种不同的设备上：
- en: '[Arduino Nano 33 BLE Sense](https://oreil.ly/ztU5E)'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Arduino Nano 33 BLE Sense](https://oreil.ly/ztU5E)'
- en: '[SparkFun Edge](https://oreil.ly/-hoL-)'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[SparkFun Edge](https://oreil.ly/-hoL-)'
- en: '[ST Microelectronics STM32F746G Discovery kit](https://oreil.ly/cvm4J)'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ST Microelectronics STM32F746G Discovery kit](https://oreil.ly/cvm4J)'
- en: For each one, we’ll walk through the build and deployment process.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 对于每个设备，我们将详细介绍构建和部署过程。
- en: Because every device has its own mechanism for capturing audio, there’s a separate
    implementation of *audio_provider.cc* for each one. The same is true for output,
    so each has a variant of *command_responder.cc*, too.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 因为每个设备都有自己的捕获音频机制，所以对于每个设备都有一个单独的*audio_provider.cc*实现。输出也是如此，因此每个设备也有一个*command_responder.cc*的变体。
- en: The *audio_provider.cc* implementations are complex and device-specific, and
    not directly related to machine learning. Consequently, we won’t walk through
    them in this chapter. However, there’s a walkthrough of the Arduino variant in
    [Appendix B](app02.xhtml#appendix_arduino_audio). If you need to capture audio
    in your own project, you’re welcome to reuse these implementations in your own
    code.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '*audio_provider.cc*的实现是复杂的，与设备相关，并且与机器学习没有直接关系。因此，在本章中我们不会详细介绍它们。然而，在[附录B](app02.xhtml#appendix_arduino_audio)中有Arduino变体的详细说明。如果您需要在自己的项目中捕获音频，欢迎在您自己的代码中重用这些实现。'
- en: Alongside deployment instructions, we’re also going to walk through the *command_responder.cc*
    implementation for each device. First up, it’s time for Arduino.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 除了部署说明，我们还将为每个设备详细介绍*command_responder.cc*的实现。首先，是Arduino的时间。
- en: Arduino
  id: totrans-308
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Arduino
- en: As of this writing, the only Arduino board with a built-in microphone is the
    [Arduino Nano 33 BLE Sense](https://oreil.ly/hjOzL), so that’s what we’ll be using
    for this section. If you’re using a different Arduino board and attaching your
    own microphone, you’ll need to implement your own *audio_provider.cc*.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 截至目前，唯一具有内置麦克风的Arduino板是[Arduino Nano 33 BLE Sense](https://oreil.ly/hjOzL)，因此我们将在本节中使用它。如果您使用不同的Arduino板并连接自己的麦克风，您将需要实现自己的*audio_provider.cc*。
- en: The Arduino Nano 33 BLE Sense also has a built-in LED, which is what we use
    to indicate that a word has been recognized.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: Arduino Nano 33 BLE Sense还具有内置LED，这是我们用来指示已识别单词的LED。
- en: '[Figure 7-7](#arduino_nano_sense_led_2) shows a picture of the board with its
    LED highlighted.'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '[图7-7](#arduino_nano_sense_led_2)显示了板上的LED的图片。'
- en: '![Image of the Arduino Nano 33 BLE Sense board with the LED highlighted](Images/timl_0602.png)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![Arduino Nano 33 BLE Sense板上的LED高亮显示的图片](Images/timl_0602.png)'
- en: Figure 7-7\. The Arduino Nano 33 BLE Sense board with the LED highlighted
  id: totrans-313
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-7。Arduino Nano 33 BLE Sense板上的LED高亮显示
- en: Now let’s look at how we use this LED to indicate that a word has been detected.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何使用这个LED来指示已经检测到一个单词。
- en: Responding to commands on Arduino
  id: totrans-315
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在Arduino上响应命令
- en: Every Arduino board has a built-in LED, and there’s a convenient constant called
    `LED_BUILTIN` that we can use to obtain its pin number, which varies across boards.
    To keep this code portable, we’ll constrain ourselves to using this single LED
    for output.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 每个Arduino板都有一个内置LED，并且有一个方便的常量叫做`LED_BUILTIN`，我们可以使用它来获取其引脚号，这在各个板上是不同的。为了保持代码的可移植性，我们将限制自己只使用这个单个LED进行输出。
- en: Here’s what we’re going to do. To show that inference is running, we’ll flash
    the LED by toggling it on or off with each inference. However, when we hear the
    word “yes,” we’ll switch on the LED for a few seconds.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要做的是这样的。为了显示推理正在运行，我们将通过每次推理切换LED的开关状态来闪烁LED。但是，当我们听到“yes”这个词时，我们会将LED打开几秒钟。
- en: What about the word “no”? Well, because this is just a demonstration, we won’t
    worry about it too much. We do, however, log all of the detected commands to the
    serial port, so we can connect to the device and see every match.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 那么“no”这个词呢？嗯，因为这只是一个演示，我们不会太担心它。但是，我们会将所有检测到的命令记录到串行端口，这样我们就可以连接到设备并查看每个匹配项。
- en: 'The replacement command responder for Arduino is located in [*arduino/command_responder.cc*](https://oreil.ly/URkYi).
    Let’s walk through its source. First, we include the command responder header
    file and the Arduino platform’s library header file:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: Arduino的替代命令响应器位于[*arduino/command_responder.cc*](https://oreil.ly/URkYi)。让我们浏览一下它的源代码。首先，我们包含命令响应器头文件和Arduino平台的库头文件：
- en: '[PRE55]'
  id: totrans-320
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Next, we begin our function implementation:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们开始实现我们的函数：
- en: '[PRE56]'
  id: totrans-322
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Our next step is to place the built-in LED’s pin into output mode so that we
    can switch it on and off. We do this inside an `if` statement that runs only once,
    thanks to a `static bool` called `is_initialized`. Remember, `static` variables
    preserve their state between function calls:'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的下一步是将内置LED的引脚设置为输出模式，以便我们可以打开和关闭它。我们在一个`if`语句中执行此操作，该语句仅运行一次，这要归功于名为`is_initialized`的`static
    bool`。请记住，`static`变量在函数调用之间保留其状态：
- en: '[PRE57]'
  id: totrans-324
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Next, we set up another couple of `static` variables to keep track of the last
    time a “yes” was detected, and the number of inferences that have been performed:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们设置另外两个`static`变量来跟踪上次检测到“yes”的时间以及已执行的推理次数：
- en: '[PRE58]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Now comes the fun stuff. If the `is_new_command` argument is `true`, we know
    we’ve heard something, so we log it with the `ErrorReporter` instance. But if
    it’s a “yes” we heard—which we determine by checking the first character of the
    `found_command` character array—we store the current time and switch on the LED:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是有趣的部分。如果`is_new_command`参数为`true`，我们知道我们听到了什么，因此我们使用`ErrorReporter`实例记录它。但是如果我们听到的是“yes”——我们通过检查`found_command`字符数组的第一个字符来确定——我们存储当前时间并打开LED：
- en: '[PRE59]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Next, we implement the behavior that switches off the LED after a few seconds—three,
    to be precise:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们实现了在几秒钟后关闭LED的行为——确切地说是三秒：
- en: '[PRE60]'
  id: totrans-330
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'When the LED is switched off, we also set `last_yet_time` to `0`, so we won’t
    enter this `if` statement until the next time a “yes” is heard. The `return` statement
    is important: it’s what prevents any further output code from running if we recently
    heard a “yes,” so the LED stays solidly lit.'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 当LED关闭时，我们还将`last_yet_time`设置为`0`，这样我们在下次听到“yes”之前不会进入这个`if`语句。`return`语句很重要：如果我们最近听到“yes”，它会阻止任何进一步的输出代码运行，因此LED会保持亮起状态。
- en: So far, our implementation will switch on the LED for around three seconds when
    a “yes” is heard. The next part will toggle the LED on and off with each inference—except
    for while we’re in “yes” mode, when we’re prevented from reaching this point by
    the aforementioned `return` statement.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们的实现将在听到“yes”时打开LED约三秒钟。接下来的部分将通过每次推理切换LED的开关状态，除了在“yes”模式下，我们通过前面提到的`return`语句阻止到达这一点。
- en: 'Here’s the final chunk of code:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是最终的代码块：
- en: '[PRE61]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: By incrementing the `count` variable for each inference, we keep track of the
    total number of inferences that we’ve performed. Inside the `if` conditional,
    we use the `&` operator to do a binary AND operation with the `count` variable
    and the number `1`.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 通过为每次推理增加`count`变量，我们跟踪我们执行的总推理次数。在`if`条件中，我们使用`&`运算符对`count`变量和数字`1`进行二进制 AND
    运算。
- en: By performing an AND on `count` with `1`, we filter out all of `count`’s bits
    except the smallest. If the smallest bit is a `0`, meaning `count` is an odd number,
    the result will be a `0`. In a C++ `if statement`, this evaluates to `false`.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对`count`和`1`进行 AND 运算，我们过滤掉`count`的所有位，除了最小的位。如果最小位是`0`，表示`count`是一个奇数，结果将是`0`。在
    C++ 的`if语句`中，这将评估为`false`。
- en: Otherwise, the result will be a `1`, indicating an even number. Because a `1`
    evaluates to `true`, our LED will switch on with even values and off with odd
    values. This is what makes it toggle.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，结果将是`1`，表示一个偶数。因为`1`被评估为`true`，我们的LED将在偶数值时打开，并在奇数值时关闭。这就是它的切换功能。
- en: And that’s it! We’ve now implemented our command responder for Arduino. Let’s
    get it running so that we can see it in action.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！我们现在已经为Arduino实现了命令响应器。让我们运行它，以便看到它的运行情况。
- en: Running the example
  id: totrans-339
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行示例
- en: 'To deploy this example, here’s what we’ll need:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署此示例，我们需要：
- en: An Arduino Nano 33 BLE Sense board
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 Arduino Nano 33 BLE Sense 开发板
- en: A micro-USB cable
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 micro-USB 电缆
- en: The Arduino IDE
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Arduino IDE
- en: Tip
  id: totrans-344
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: There’s always a chance that the build process might have changed since this
    book was written, so check [*README.md*](https://oreil.ly/7VozJ) for the latest
    instructions.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这本书编写时可能已经发生了变化，因此请查看[*README.md*](https://oreil.ly/7VozJ)获取最新的说明。
- en: The projects in this book are available as example code in the TensorFlow Lite
    Arduino library. If you haven’t already installed the library, open the Arduino
    IDE and select Manage Libraries from the Tools menu. In the window that appears,
    search for and install the library named *Arduino_TensorFlowLite*. You should
    be able to use the latest version, but if you run into issues, the version that
    was tested with this book is 1.14-ALPHA.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中的项目作为 TensorFlow Lite Arduino 库中的示例代码可用。如果您尚未安装该库，请打开 Arduino IDE 并从工具菜单中选择管理库。在出现的窗口中，搜索并安装名为
    *Arduino_TensorFlowLite* 的库。您应该能够使用最新版本，但如果遇到问题，本书测试过的版本是 1.14-ALPHA。
- en: Note
  id: totrans-347
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: You can also install the library from a *.zip* file, which you can either [download](https://oreil.ly/blgB8)
    from the TensorFlow Lite team or generate yourself using the TensorFlow Lite for
    Microcontrollers Makefile. If you’d prefer to do the latter, see [Appendix A](app01.xhtml#appendix_arduino_library_zip).
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: After you’ve installed the library, the `micro_speech` example will show up
    in the File menu under Examples→Arduino_TensorFlowLite, as shown in [Figure 7-8](#arduino_examples_micro_speech).
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: Click “micro_speech” to load the example. It will appear as a new window, with
    a tab for each of the source files. The file in the first tab, *micro_speech*,
    is equivalent to the *main_functions.cc* we walked through earlier.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: '![Screenshot of the ''Examples'' menu](Images/timl_0604.png)'
  id: totrans-351
  prefs: []
  type: TYPE_IMG
- en: Figure 7-8\. The Examples menu
  id: totrans-352
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  id: totrans-353
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[“Running the Example”](ch06.xhtml#hello_world_running_the_example) already
    explained the structure of the Arduino example, so we won’t cover it again here.'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: To run the example, plug in your Arduino device via USB. Make sure the correct
    device type is selected from the Board drop-down list in the Tools menu, as shown
    in [Figure 7-9](#arduino_board_dropdown_2).
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: '![Screenshot of the ''Board'' dropdown](Images/timl_0605.png)'
  id: totrans-356
  prefs: []
  type: TYPE_IMG
- en: Figure 7-9\. The Board drop-down list
  id: totrans-357
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If your device’s name doesn’t appear in the list, you’ll need to install its
    support package. To do this, click Boards Manager. In the window that appears,
    search for your device, and then install the latest version of the corresponding
    support package. Next, make sure the device’s port is selected in the Port drop-down
    list, also in the Tools menu, as demonstrated in [Figure 7-10](#arduino_port_dropdown_2).
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: '![Screenshot of the ''Port'' dropdown](Images/timl_0606.png)'
  id: totrans-359
  prefs: []
  type: TYPE_IMG
- en: Figure 7-10\. The Port drop-down list
  id: totrans-360
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Finally, in the Arduino window, click the upload button (highlighted in white
    in [Figure 7-11](#arduino_upload_button_2)) to compile and upload the code to
    your Arduino device.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: '![Screenshot of the upload button, which has an arrow icon](Images/timl_0607.png)'
  id: totrans-362
  prefs: []
  type: TYPE_IMG
- en: Figure 7-11\. The upload button, a right-facing arrow
  id: totrans-363
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: After the upload has successfully completed you should see the LED on your Arduino
    board begin to flash.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: To test the program, try saying “yes.” When it detects a “yes,” the LED will
    remain lit solidly for around three seconds.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-366
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If you can’t get the program to recognize your “yes,” try saying it a few times
    in a row.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: You can also see the results of inference via the Arduino Serial Monitor. To
    do this, open the Serial Monitor from the Tools menu. Now, try saying “yes,” “no,”
    and other words. You should see something like [Figure 7-12](#micro_speech_serial_monitor).
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: '![Screenshot of the Arduino IDE''s Serial Monitor](Images/timl_0712.png)'
  id: totrans-369
  prefs: []
  type: TYPE_IMG
- en: Figure 7-12\. The Serial Monitor displaying some matches
  id: totrans-370
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Note
  id: totrans-371
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The model we’re using is small and imperfect, and you’ll probably notice that
    it’s better at detecting “yes” than “no.” This is an example of how optimizing
    for a tiny model size can result in issues with accuracy. We cover this topic
    in [Chapter 8](ch08.xhtml#chapter_training_micro_speech).
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: Making your own changes
  id: totrans-373
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that you’ve deployed the application, try playing around with the code!
    You can edit the source files in the Arduino IDE. When you save, you’ll be prompted
    to re-save the example in a new location. After you’ve made your changes, you
    can click the upload button in the Arduino IDE to build and deploy.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few ideas you could try:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: Switch the example to light the LED when “no” is spoken, instead of “yes,”
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make the application respond to a specific sequence of “yes” and “no” commands,
    like a secret code phrase.
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the “yes” and “no” commands to control other components, like additional
    LEDs or servos.
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SparkFun Edge
  id: totrans-379
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The SparkFun Edge has both a microphone and a row of four colored LEDs—red,
    blue, green, and yellow—which will make displaying results easy. [Figure 7-13](#sparkfun_edge_leds_2)
    shows the SparkFun Edge with its LEDs highlighted.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: '![Photo of the SparkFun Edge highlighting its four LEDs](Images/timl_0611.png)'
  id: totrans-381
  prefs: []
  type: TYPE_IMG
  zh: '![突出显示四个LED的SparkFun Edge的照片](Images/timl_0611.png)'
- en: Figure 7-13\. The SparkFun Edge’s four LEDs
  id: totrans-382
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-13。SparkFun Edge的四个LED
- en: Responding to commands on SparkFun Edge
  id: totrans-383
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 响应SparkFun Edge上的命令
- en: To make it clear that our program is running, let’s toggle the blue LED on and
    off with each inference. We’ll switch on the yellow LED when a “yes” is heard,
    the red LED when a “no” is heard, and the green LED when an unknown command is
    heard.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 为了清楚地表明我们的程序正在运行，让我们在每次推理时切换蓝色LED的开关。当听到“是”时，我们将打开黄色LED，当听到“否”时，我们将打开红色LED，当听到未知命令时，我们将打开绿色LED。
- en: 'The command responder for SparkFun Edge is implemented in [*sparkfun_edge/command_responder.cc*](https://oreil.ly/i-3eJ).
    The file begins with some includes:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: SparkFun Edge的命令响应器实现在[*sparkfun_edge/command_responder.cc*](https://oreil.ly/i-3eJ)中。该文件以一些包含开始：
- en: '[PRE62]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: The *command_responder.h* include is this file’s corresponding header. *am_bsp.h*
    is the Ambiq Apollo3 SDK, which you saw in the last chapter.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
  zh: '*command_responder.h*包含了这个文件对应的头文件。*am_bsp.h*是Ambiq Apollo3 SDK，在上一章中已经看到。'
- en: 'Inside the function definition, the first thing we do is set up the pins connected
    to the LEDs as outputs:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 在函数定义内部，我们首先将连接到LED的引脚设置为输出：
- en: '[PRE63]'
  id: totrans-389
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: We call the `am_hal_gpio_pinconfig()` function from the Apollo3 SDK to set all
    four LED pins to output mode, represented by the constant `g_AM_HAL_GPIO_OUTPUT_12`.
    We use the `is_initialized` `static` variable to ensure that we do this only once!
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从Apollo3 SDK中调用`am_hal_gpio_pinconfig()`函数，将所有四个LED引脚设置为输出模式，表示为常量`g_AM_HAL_GPIO_OUTPUT_12`。我们使用`is_initialized`
    `static`变量确保我们只执行一次！
- en: 'Next comes the code that will toggle the blue LED on and off. We do this using
    a `count` variable, in the same way as in the Arduino implementation:'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是将切换蓝色LED打开和关闭的代码。我们使用一个`count`变量来执行此操作，方式与Arduino实现相同：
- en: '[PRE64]'
  id: totrans-392
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: This code uses the `am_hal_gpio_output_set()` and `am_hal_gpio_output_clear()`
    functions to switch the blue LED’s pin either on or off.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: 此代码使用`am_hal_gpio_output_set()`和`am_hal_gpio_output_clear()`函数来切换蓝色LED的引脚开关。
- en: By incrementing the `count` variable at each inference, we keep track of the
    total number of inferences we’ve performed. Inside the `if` conditional, we use
    the `&` operator to do a binary AND operation with the `count` variable and the
    number `1`.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在每次推理时递增`count`变量，我们可以跟踪我们执行的推理总数。在`if`条件内部，我们使用`&`运算符对`count`变量和数字`1`进行二进制AND操作。
- en: By performing an AND on `count` with `1`, we filter out all of `count`’s bits
    except the smallest. If the smallest bit is a `0`, meaning `count` is an odd number,
    the result will be a `0`. In a C++ `if statement`, this evaluates to `false`.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对`count`和`1`进行AND运算，我们过滤掉`count`的所有位，除了最小的位。如果最小位是`0`，表示`count`是奇数，结果将是`0`。在C++的`if语句`中，这将评估为`false`。
- en: Otherwise, the result will be a `1`, indicating an even number. Because a `1`
    evaluates to `true`, our LED will switch on with even values and off with odd
    values. This is what makes it toggle.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，结果将是`1`，表示偶数。因为`1`评估为`true`，所以我们的LED将在偶数值时打开，并在奇数值时关闭。这就是它的切换原理。
- en: 'Next, we light the appropriate LED depending on which word was just heard.
    By default, we clear all of the LEDs, so if a word was not recently heard the
    LEDs will all be unlit:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，根据刚刚听到的单词点亮适当的LED。默认情况下，我们清除所有LED，因此如果最近没有听到单词，则所有LED将熄灭：
- en: '[PRE65]'
  id: totrans-398
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: 'We then use some simple `if` statements to switch on the appropriate LED depending
    on which command was heard:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们使用一些简单的`if`语句根据听到的命令点亮适当的LED：
- en: '[PRE66]'
  id: totrans-400
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: As we saw earlier, `is_new_command` is `true` only if `RespondToCommand()` was
    called with a genuinely new command, so if a new command wasn’t heard the LEDs
    will remain off. Otherwise, we use the `am_hal_gpio_output_set()` function to
    switch on the appropriate LED.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前看到的，只有当`RespondToCommand()`被调用时传入了一个真正的新命令，`is_new_command`才为`true`，因此如果没有听到新命令，LED将保持关闭。否则，我们使用`am_hal_gpio_output_set()`函数打开适当的LED。
- en: Running the example
  id: totrans-402
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行示例
- en: We’ve now walked through how our example code lights up LEDs on the SparkFun
    Edge. Next, let’s get the example up and running.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经详细介绍了如何在SparkFun Edge上点亮LED的示例代码。接下来，让我们启动并运行示例。
- en: Tip
  id: totrans-404
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: There’s always a chance that the build process might have changed since this
    book was written, so check [*README.md*](https://oreil.ly/U3Cgo) for the latest
    instructions.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 建议查看[*README.md*](https://oreil.ly/U3Cgo)以获取最新指令，因为构建过程可能会有变化。
- en: 'To build and deploy our code, we’ll need the following:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 要构建和部署我们的代码，我们需要以下内容：
- en: A SparkFun Edge board
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个SparkFun Edge板
- en: A USB programmer (we recommend the SparkFun Serial Basic Breakout, which is
    available in [micro-B USB](https://oreil.ly/2GMNf) and [USB-C](https://oreil.ly/lp39T)
    variants)
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个USB编程器（我们推荐SparkFun Serial Basic Breakout，可在[micro-B USB](https://oreil.ly/2GMNf)和[USB-C](https://oreil.ly/lp39T)变体中获得）
- en: A matching USB cable
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 匹配的USB电缆
- en: Python 3 and some dependencies
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 3和一些依赖项
- en: Note
  id: totrans-411
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 接下来
- en: '[Chapter 6](ch06.xhtml#ch_6) shows how to confirm whether you have the correct
    version of Python installed. If you already did this, great. If not, it’s worth
    flipping back to [“Running the Example”](ch06.xhtml#running_hello_world_sparkfun_edge)
    to take a look.'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: '[第6章](ch06.xhtml#ch_6)展示了如何确认您是否安装了正确版本的Python。如果您已经这样做了，太好了。如果没有，请翻回到[“运行示例”](ch06.xhtml#running_hello_world_sparkfun_edge)查看一下。'
- en: 'In your terminal, clone the TensorFlow repository and then change into its
    directory:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的终端中，克隆TensorFlow存储库，然后切换到其目录：
- en: '[PRE67]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: Next, we’re going to build the binary and run some commands that get it ready
    for downloading to the device. To avoid some typing, you can copy and paste these
    commands from [*README.md*](https://oreil.ly/xY-Rj).
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将构建二进制文件并运行一些命令，使其准备好下载到设备中。为了避免一些打字，您可以从[*README.md*](https://oreil.ly/xY-Rj)中复制并粘贴这些命令。
- en: Build the binary
  id: totrans-416
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 构建二进制文件
- en: 'The following command downloads all of the required dependencies and then compiles
    a binary for the SparkFun Edge:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令下载所有所需的依赖项，然后为SparkFun Edge编译一个二进制文件：
- en: '[PRE68]'
  id: totrans-418
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'The binary is created as a *.bin* file, in the following location:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 二进制文件被创建为*.bin*文件，在以下位置：
- en: '[PRE69]'
  id: totrans-420
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'To check whether the file exists, you can use the following command:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查文件是否存在，可以使用以下命令：
- en: '[PRE70]'
  id: totrans-422
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: If you run that command, you should see `Binary was successfully created` printed
    to the console. If you see `Binary is missing`, there was a problem with the build
    process. If so, it’s likely that there are some clues to what went wrong in the
    output of the `make` command.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 如果运行该命令，您应该看到`二进制文件已成功创建`打印到控制台。如果看到`二进制文件丢失`，则构建过程中出现问题。如果是这样，`make`命令的输出中可能有一些指示出了问题的线索。
- en: Sign the binary
  id: totrans-424
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 签署二进制文件
- en: The binary must be signed with cryptographic keys to be deployed to the device.
    Let’s now run some commands that will sign the binary so it can be flashed to
    the SparkFun Edge. The scripts used here come from the Ambiq SDK, which is downloaded
    when the Makefile is run.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 必须使用加密密钥对二进制文件进行签名，以部署到设备。现在让我们运行一些命令来对二进制文件进行签名，以便将其刷写到SparkFun Edge。这里使用的脚本来自Ambiq
    SDK，在运行Makefile时下载。
- en: 'Enter the following command to set up some dummy cryptographic keys that you
    can use for development:'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 输入以下命令设置一些虚拟加密密钥，以供开发使用：
- en: '[PRE71]'
  id: totrans-427
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Next, run the following command to create a signed binary. Substitute `python3`
    with `python` if necessary:'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，运行以下命令创建一个已签名的二进制文件。如有必要，用`python3`替换`python`：
- en: '[PRE72]'
  id: totrans-429
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'This creates the file *main_nonsecure_ota.bin*. Now run this command to create
    a final version of the file that can be used to flash your device with the script
    you will use in the next step:'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建文件*main_nonsecure_ota.bin*。现在运行此命令以创建文件的最终版本，该文件可用于使用下一步中将使用的脚本刷写设备：
- en: '[PRE73]'
  id: totrans-431
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: You should now have a file called *main_nonsecure_wire.bin* in the directory
    where you ran the commands. This is the file you’ll be flashing to the device.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 现在应该在运行命令的目录中有一个名为*main_nonsecure_wire.bin*的文件。这是您将要刷写到设备的文件。
- en: Flash the binary
  id: totrans-433
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 刷写二进制文件
- en: The SparkFun Edge stores the program it is currently running in its 1 megabyte
    of flash memory. If you want the board to run a new program, you need to send
    it to the board, which will store it in flash memory, overwriting any program
    that was previously saved.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: SparkFun Edge将当前运行的程序存储在其1兆字节的闪存中。如果要让板运行新程序，需要将其发送到板上，板将将其存储在闪存中，覆盖以前保存的任何程序。
- en: Attach the programmer to the board
  id: totrans-435
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 将编程器连接到板上
- en: To download new programs to the board, you’ll use the SparkFun USB-C Serial
    Basic serial programmer. This device allows your computer to communicate with
    the microcontroller via USB.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 要将新程序下载到板上，您将使用SparkFun USB-C串行基础串行编程器。此设备允许计算机通过USB与微控制器通信。
- en: 'To attach this device to your board, perform the following steps:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 要将此设备连接到板上，请执行以下步骤：
- en: On the side of the SparkFun Edge, locate the six-pin header.
  id: totrans-438
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在SparkFun Edge的侧面，找到六针排针。
- en: Plug the SparkFun USB-C Serial Basic into these pins, ensuring the pins labeled
    BLK and GRN on each device are lined up correctly, as illustrated in [Figure 7-14](#sparkfun_edge_serial_basic_2).
  id: totrans-439
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将SparkFun USB-C串行基础插入这些引脚，确保每个设备上标有BLK和GRN的引脚正确对齐，如[图7-14](#sparkfun_edge_serial_basic_2)所示。
- en: '![A photo showing how the SparkFun Edge and USB-C Serial Basic should be connected](Images/timl_0613.png)'
  id: totrans-440
  prefs: []
  type: TYPE_IMG
  zh: '![显示SparkFun Edge和USB-C串行基础如何连接的照片](Images/timl_0613.png)'
- en: Figure 7-14\. Connecting the SparkFun Edge and USB-C Serial Basic (courtesy
    of SparkFun)
  id: totrans-441
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-14\. 连接SparkFun Edge和USB-C串行基础（由SparkFun提供）
- en: Attach the programmer to your computer
  id: totrans-442
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 将编程器连接到计算机
- en: You connect the board to your computer via USB. To program the board, you need
    to find out the name that your computer gives the device. The best way of doing
    this is to list all the computer’s devices before and after attaching it, and
    look to see which device is new.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 通过USB将板连接到计算机。要对板进行编程，您需要找出计算机分配给设备的名称。最佳方法是在连接之前和之后列出所有计算机设备，然后查看哪个设备是新的。
- en: Warning
  id: totrans-444
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Some people have reported issues with their operating system’s default drivers
    for the programmer, so we strongly recommend installing the [driver](https://oreil.ly/kohTX)
    before you continue.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 一些人报告了他们操作系统的默认驱动程序与编程器存在问题，因此我们强烈建议在继续之前安装[驱动程序](https://oreil.ly/kohTX)。
- en: 'Before attaching the device via USB, run the following command:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 在通过USB连接设备之前，运行以下命令：
- en: '[PRE74]'
  id: totrans-447
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'This should output a list of attached devices that looks something like the
    following:'
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该输出一个附加设备列表，看起来类似于以下内容：
- en: '[PRE75]'
  id: totrans-449
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: 'Now, connect the programmer to your computer’s USB port and run the command
    again:'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，将编程器连接到计算机的USB端口，并再次运行命令：
- en: '[PRE76]'
  id: totrans-451
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: 'You should see an extra item in the output, as shown in the example that follows.
    Your new item might have a different name. This new item is the name of the device:'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到输出中有一个额外的项目，如下例所示。您的新项目可能有不同的名称。这个新项目是设备的名称：
- en: '[PRE77]'
  id: totrans-453
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: This name will be used to refer to the device. However, it can change depending
    on which USB port the programmer is attached to, so if you disconnect the board
    from your computer and then reattach it, you might need to look up its name again.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 此名称将用于引用设备。但是，它可能会根据编程器连接到的USB端口而更改，因此如果您从计算机断开板然后重新连接，可能需要再次查找其名称。
- en: Tip
  id: totrans-455
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 提示
- en: Some users have reported two devices appearing in the list. If you see two devices,
    the correct one to use begins with the letters “wch”; for example, “/dev/wchusbserial-14410.”
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 一些用户报告说列表中出现了两个设备。如果看到两个设备，则应使用以“wch”开头的正确设备；例如，“/dev/wchusbserial-14410”。
- en: 'After you’ve identified the device name, put it in a shell variable for later
    use:'
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 确定设备名称后，将其放入shell变量以供以后使用：
- en: '[PRE78]'
  id: totrans-458
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: This is a variable that you can use when running commands that require the device
    name, later in the process.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在后续过程中运行需要设备名称的命令时可以使用的变量。
- en: Run the script to flash your board
  id: totrans-460
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 运行脚本刷写板
- en: To flash the board, you must put it into a special “bootloader” state that prepares
    it to receive the new binary. You’ll then run a script to send the binary to the
    board.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 要刷写板，必须将其置于特殊的“引导加载程序”状态，以准备接收新的二进制文件。然后运行一个脚本将二进制文件发送到板上。
- en: 'First create an environment variable to specify the baud rate, which is the
    speed at which data will be sent to the device:'
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  id: totrans-463
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: 'Now paste the command that follows into your terminal—but *do not press Enter
    yet*! The `${DEVICENAME}` and `${BAUD_RATE}` in the command will be replaced with
    the values you set in the previous sections. Remember to substitute `python3`
    with `python` if necessary:'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  id: totrans-465
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: 'Next, you’ll reset the board into its bootloader state and flash the board.
    On the board, locate the buttons marked `RST` and `14`, as shown in [Figure 7-15](#sparkfun_edge_buttons_2).
    Perform the following steps:'
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
- en: Ensure that your board is connected to the programmer and the entire thing is
    connected to your computer via USB.
  id: totrans-467
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the board, press and hold the button marked `14`. *Continue holding it*.
  id: totrans-468
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: While still holding the button marked `14`, press the button marked `RST` to
    reset the board.
  id: totrans-469
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Press Enter on your computer to run the script. *Continue holding button `14`.*
  id: totrans-470
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You should now see something like the following appearing on your screen:'
  id: totrans-471
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  id: totrans-472
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: '![A photo showing the SparkFun Edge''s buttons](Images/timl_0614.png)'
  id: totrans-473
  prefs: []
  type: TYPE_IMG
- en: Figure 7-15\. The SparkFun Edge’s buttons
  id: totrans-474
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Keep holding button `14` until you see `Sending Data Packet of length 8180`.
    You can release the button after seeing this (but it’s okay if you keep holding
    it). The program will continue to print lines on the terminal. Eventually, you’ll
    see something like the following:'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  id: totrans-476
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: This indicates a successful flashing.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-478
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If the program output ends with an error, check whether `Sending Reset Command.`
    was printed. If so, flashing was likely successful despite the error. Otherwise,
    flashing might have failed. Try running through these steps again (you can skip
    over setting the environment variables).
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
- en: Testing the program
  id: totrans-480
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To make sure the program is running, press the `RST` button. You should now
    see the blue LED flashing.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
- en: To test the program, try saying “yes.” When it detects a “yes,” the orange LED
    will flash. The model is also trained to recognize “no,” and when unknown words
    are spoken. The red LED should flash for “no,” and the green for unknown.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
- en: 'If you can’t get the program to recognize your “yes,” try saying it a few times
    in a row: “yes, yes, yes.”'
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
- en: The model we’re using is small and imperfect, and you’ll probably notice that
    it’s better at detecting “yes” than “no,” which it often recognizes as “unknown.”
    This is an example of how optimizing for a tiny model size can result in issues
    with accuracy. We cover this topic in [Chapter 8](ch08.xhtml#chapter_training_micro_speech).
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
- en: Viewing debug data
  id: totrans-485
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The program will also log successful recognitions to the serial port. To view
    this data, we can monitor the board’s serial port output using a baud rate of
    115200\. On macOS and Linux, the following command should work:'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  id: totrans-487
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: 'You should initially see output that looks something like the following:'
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  id: totrans-489
  prefs: []
  type: TYPE_PRE
  zh: '[PRE84]'
- en: 'Try issuing some commands by saying “yes” or “no.” You should see the board
    printing debug information for each command:'
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  id: totrans-491
  prefs: []
  type: TYPE_PRE
  zh: '[PRE85]'
- en: To stop viewing the debug output with `screen`, press Ctrl-A immediately followed
    by the K key, and then press the Y key.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
- en: Making your own changes
  id: totrans-493
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now that you’ve deployed the basic application, try playing around and making
    some changes. You can find the application’s code in the *tensorflow/lite/micro/examples/micro_speech*
    folder. Just edit and save and then repeat the preceding instructions to deploy
    your modified code to the device.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few things that you could try:'
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
- en: '`RespondToCommand()`’s `score` argument shows the prediction score. Use the
    LEDs as a meter to show the strength of the match.'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make the application respond to a specific sequence of “yes” and “no” commands,
    like a secret code phrase.
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the “yes” and “no” commands to control other components, like additional
    LEDs or servos.
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ST Microelectronics STM32F746G Discovery Kit
  id: totrans-499
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Because the STM32F746G comes with a fancy LCD display, we can use this to show
    off whichever wake words are detected, as depicted in [Figure 7-16](#stm_micro_speech).
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
- en: '![STM32F746G displaying a ''no''](Images/timl_0716.png)'
  id: totrans-501
  prefs: []
  type: TYPE_IMG
- en: Figure 7-16\. STM32F746G displaying a “no”
  id: totrans-502
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Responding to commands on STM32F746G
  id: totrans-503
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The STM32F746G’s LCD driver gives us methods that we can use to write text
    to the display. In this exercise, we’ll use these to show one of the following
    messages, depending on which command was heard:'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
- en: “Heard yes!”
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “Heard no :(”
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “Heard unknown”
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: “Heard silence”
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll also set the background color differently depending on which command was
    heard.
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin, we include some header files:'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  id: totrans-511
  prefs: []
  type: TYPE_PRE
  zh: '[PRE86]'
- en: The first, *command_responder.h*, just declares the interface for this file.
    The second, *LCD_DISCO_F74NG.h*, gives us an interface to control the device’s
    LCD display. You can read more about it on the [Mbed site](https://oreil.ly/6oirs).
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we instantiate an `LCD_DISCO_F746NG` object, which holds the methods
    we use to control the LCD:'
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  id: totrans-514
  prefs: []
  type: TYPE_PRE
  zh: '[PRE87]'
- en: 'In the next few lines, the `RespondToCommand()` function is declared, and we
    check whether it has been called with a new command:'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  id: totrans-516
  prefs: []
  type: TYPE_PRE
  zh: '[PRE88]'
- en: When we know this is a new command, we use the `error_reporter` to log it to
    the serial port.
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we use a big `if` statement to determine what happens when each command
    is found. First comes “yes”:'
  id: totrans-518
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  id: totrans-519
  prefs: []
  type: TYPE_PRE
  zh: '[PRE89]'
- en: We use `lcd.Clear()` to both clear any previous content from the screen and
    set a new background color, like a fresh coat of paint. The color `0xFF0F9D58`
    is a nice, rich green.
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
- en: On our green background, we use `lcd.DisplayStringAt()` to draw some text. The
    first argument specifies an *x* coordinate, the second specifies a *y*. To position
    our text roughly in the middle of the display, we use a helper function, `LINE()`,
    to determine the *y* coordinate that would correspond to the fifth line of text
    on the screen.
  id: totrans-521
  prefs: []
  type: TYPE_NORMAL
- en: The third argument is the string of text we’ll be displaying, and the fourth
    argument determines the alignment of the text; here, we use the constant `CENTER_MODE`
    to specify that the text is center-aligned.
  id: totrans-522
  prefs: []
  type: TYPE_NORMAL
- en: 'We continue the `if` statement to cover the remaining three possibilities,
    “no,” “unknown,” and “silence” (which is captured by the `else` block):'
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  id: totrans-524
  prefs: []
  type: TYPE_PRE
  zh: '[PRE90]'
- en: And that’s it! Because the LCD library gives us such easy high-level control
    over the display, it doesn’t take much code to output our results. Let’s deploy
    the example to see this all in action.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
- en: Running the example
  id: totrans-526
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now we can use the Mbed toolchain to deploy our application to the device.
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  id: totrans-528
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: There’s always a chance that the build process might have changed since this
    book was written, so check [*README.md*](https://oreil.ly/1INIO) for the latest
    instructions.
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we begin, we’ll need the following:'
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
- en: An STM32F746G Discovery kit board
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A mini-USB cable
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Arm Mbed CLI (follow the [Mbed setup guide](https://oreil.ly/tR57j))
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python 3 and `pip`
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Like the Arduino IDE, Mbed requires source files to be structured in a certain
    way. The TensorFlow Lite for Microcontrollers Makefile knows how to do this for
    us and can generate a directory suitable for Mbed.
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
- en: 'To do so, run the following command:'
  id: totrans-536
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  id: totrans-537
  prefs: []
  type: TYPE_PRE
  zh: '[PRE91]'
- en: 'This results in the creation of a new directory:'
  id: totrans-538
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  id: totrans-539
  prefs: []
  type: TYPE_PRE
  zh: '[PRE92]'
- en: This directory contains all of the example’s dependencies structured in the
    correct way for Mbed to be able to build it.
  id: totrans-540
  prefs: []
  type: TYPE_NORMAL
- en: 'First, change into the directory so that you can run some commands within it:'
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  id: totrans-542
  prefs: []
  type: TYPE_PRE
  zh: '[PRE93]'
- en: Next, you’ll use Mbed to download the dependencies and build the project.
  id: totrans-543
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin, use the following command to inform Mbed that the current directory
    is the root of an Mbed project:'
  id: totrans-544
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  id: totrans-545
  prefs: []
  type: TYPE_PRE
  zh: '[PRE94]'
- en: 'Next, instruct Mbed to download the dependencies and prepare to build:'
  id: totrans-546
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  id: totrans-547
  prefs: []
  type: TYPE_PRE
  zh: '[PRE95]'
- en: 'By default, Mbed builds the project using C++98\. However, TensorFlow Lite
    requires C++11\. Run the following Python snippet to modify the Mbed configuration
    files so that it uses C++11\. You can just type or paste it into the command line:'
  id: totrans-548
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  id: totrans-549
  prefs: []
  type: TYPE_PRE
  zh: '[PRE96]'
- en: 'Finally, run the following command to compile:'
  id: totrans-550
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  id: totrans-551
  prefs: []
  type: TYPE_PRE
  zh: '[PRE97]'
- en: 'This should result in a binary at the following path:'
  id: totrans-552
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  id: totrans-553
  prefs: []
  type: TYPE_PRE
  zh: '[PRE98]'
- en: 'One of the nice things about the STM32F746G board is that deployment is really
    easy. To deploy, just plug in your STM board and copy the file to it. On macOS,
    you can do this by using the following command:'
  id: totrans-554
  prefs: []
  type: TYPE_NORMAL
  zh: STM32F746G开发板的一个好处是部署非常容易。要部署，只需将STM板插入并将文件复制到其中。在macOS上，您可以使用以下命令来执行此操作：
- en: '[PRE99]'
  id: totrans-555
  prefs: []
  type: TYPE_PRE
  zh: '[PRE99]'
- en: Alternately, just find the `DIS_F746NG` volume in your file browser and drag
    the file over.
  id: totrans-556
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，只需在文件浏览器中找到`DIS_F746NG`卷，并将文件拖放过去。
- en: Copying the file initiates the flashing process.
  id: totrans-557
  prefs: []
  type: TYPE_NORMAL
  zh: 复制文件会启动闪存过程。
- en: Testing the program
  id: totrans-558
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 测试程序
- en: When this is complete, try saying “yes.” You should see the appropriate text
    appear on the display and the background color change.
  id: totrans-559
  prefs: []
  type: TYPE_NORMAL
  zh: 完成后，尝试说“yes”。您应该看到适当的文本出现在显示屏上，背景颜色也会改变。
- en: If you can’t get the program to recognize your “yes,” try saying it a few times
    in a row, like “yes, yes, yes.”
  id: totrans-560
  prefs: []
  type: TYPE_NORMAL
  zh: 如果程序无法识别您的“yes”，请尝试连续几次说出来，比如“yes, yes, yes”。
- en: The model we’re using is small and imperfect, and you’ll probably notice that
    it’s better at detecting “yes” than “no,” which it often recognizes as “unknown.”
    This is an example of how optimizing for a tiny model size can result in issues
    with accuracy. We cover this topic in [Chapter 8](ch08.xhtml#chapter_training_micro_speech).
  id: totrans-561
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在使用的模型很小且不完美，您可能会注意到它更擅长检测“yes”而不是“no”，后者通常被识别为“unknown”。这是一个示例，说明为微小模型大小进行优化可能会导致准确性问题。我们在[第8章](ch08.xhtml#chapter_training_micro_speech)中涵盖了这个主题。
- en: Viewing debug data
  id: totrans-562
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 查看调试数据
- en: The program also logs successful recognitions to the serial port. To view the
    output, establish a serial connection to the board using a baud rate of 9600.
  id: totrans-563
  prefs: []
  type: TYPE_NORMAL
  zh: 该程序还会将成功识别记录到串行端口。要查看输出，请使用波特率9600建立与板的串行连接。
- en: 'On macOS and Linux, the device should be listed when you issue the following
    command:'
  id: totrans-564
  prefs: []
  type: TYPE_NORMAL
  zh: 在macOS和Linux上，当您发出以下命令时，设备应该会列出：
- en: '[PRE100]'
  id: totrans-565
  prefs: []
  type: TYPE_PRE
  zh: '[PRE100]'
- en: 'It will look something like the following:'
  id: totrans-566
  prefs: []
  type: TYPE_NORMAL
  zh: 它看起来会像下面这样：
- en: '[PRE101]'
  id: totrans-567
  prefs: []
  type: TYPE_PRE
  zh: '[PRE101]'
- en: 'After you’ve identified the device, use the following command to connect to
    it, replacing <`*/dev/tty.devicename*`> with the name of your device as it appears
    in */dev*:'
  id: totrans-568
  prefs: []
  type: TYPE_NORMAL
  zh: 在识别设备后，使用以下命令连接到设备，将<`*/dev/tty.devicename*`>替换为设备在*/dev*中显示的名称：
- en: '[PRE102]'
  id: totrans-569
  prefs: []
  type: TYPE_PRE
  zh: '[PRE102]'
- en: 'Try issuing some commands by saying “yes” or “no.” You should see the board
    printing debug information for each command:'
  id: totrans-570
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试通过说“yes”或“no”来发出一些命令。您应该看到板子为每个命令打印调试信息：
- en: '[PRE103]'
  id: totrans-571
  prefs: []
  type: TYPE_PRE
  zh: '[PRE103]'
- en: To stop viewing the debug output with `screen`, press Ctrl-A, immediately followed
    by the K key, and then press the Y key.
  id: totrans-572
  prefs: []
  type: TYPE_NORMAL
  zh: 要停止使用`screen`查看调试输出，请按Ctrl-A，紧接着按K键，然后按Y键。
- en: Note
  id: totrans-573
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 注意
- en: If you’re not sure how to make a serial connection on your platform, you could
    try [CoolTerm](https://oreil.ly/FP7gK), which works on Windows, macOS, and Linux.
    The board should show up in CoolTerm’s Port drop-down list. Make sure you set
    the baud rate to 9600.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不确定如何在您的平台上建立串行连接，您可以尝试[CoolTerm](https://oreil.ly/FP7gK)，它适用于Windows、macOS和Linux。该板应该会出现在CoolTerm的端口下拉列表中。确保将波特率设置为9600。
- en: Making your own changes
  id: totrans-575
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 进行自己的更改
- en: Now that you’ve deployed the application, it could be fun to play around and
    make some changes. You can find the application’s code in the *tensorflow/lite/micro/tools/make/gen/mbed_cortex-m4/prj/micro_speech/mbed*
    folder. Just edit and save and then repeat the preceding instructions to deploy
    your modified code to the device.
  id: totrans-576
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经部署了应用程序，可以尝试玩耍并进行一些更改。您可以在*tensorflow/lite/micro/tools/make/gen/mbed_cortex-m4/prj/micro_speech/mbed*文件夹中找到应用程序的代码。只需编辑、保存，然后重复前面的说明，将修改后的代码部署到设备上。
- en: 'Here are a few things you could try:'
  id: totrans-577
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是您可以尝试的一些事项：
- en: '`RespondToCommand()`’s `score` argument shows the prediction score. Create
    a visual indicator of the score on the LCD display.'
  id: totrans-578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RespondToCommand()`函数的`score`参数显示了预测得分。在LCD显示屏上创建一个得分的可视指示器。'
- en: Make the application respond to a specific sequence of “yes” and “no” commands,
    like a secret code phrase.
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使应用程序响应特定的“yes”和“no”命令序列，如秘密代码短语。
- en: Use the “yes” and “no” commands to control other components, like additional
    LEDs or servos.
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用“yes”和“no”命令来控制其他组件，如额外的LED或伺服。
- en: Wrapping Up
  id: totrans-581
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: The application code we’ve walked through has been mostly concerned with capturing
    data from the hardware and then extracting features that are suitable for inference.
    The part that actually feeds data into the model and runs inference is relatively
    small, and it’s very similar to the example covered in Chapter 6.
  id: totrans-582
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论过的应用程序代码主要涉及从硬件捕获数据，然后提取适合推理的特征。实际上将数据提供给模型并运行推理的部分相对较小，并且与第6章中涵盖的示例非常相似。
- en: This is fairly typical of machine learning projects. The model is already trained,
    thus our job is just to keep it fed with the appropriate sort of data. As an embedded
    developer working with TensorFlow Lite, you’ll be spending most of your programming
    time on capturing sensor data, processing it into features, and responding to
    the output of your model. The inference part itself is quick and easy.
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: 这在机器学习项目中是相当典型的。模型已经训练好了，因此我们的工作只是不断为其提供适当类型的数据。作为一个使用TensorFlow Lite的嵌入式开发人员，您将花费大部分编程时间捕获传感器数据，将其处理为特征，并响应模型的输出。推理部分本身快速且简单。
- en: But the embedded application is only part of the package—the really fun part
    is the model. In [Chapter 8](ch08.xhtml#chapter_training_micro_speech), you’ll
    learn how to train your own speech model to listen for different words. You’ll
    also learn more about how it works.
  id: totrans-584
  prefs: []
  type: TYPE_NORMAL
  zh: 但嵌入式应用程序只是整个包的一部分，真正有趣的部分是模型。在[第8章](ch08.xhtml#chapter_training_micro_speech)中，您将学习如何训练自己的语音模型以侦听不同的单词。您还将了解更多关于它是如何工作的。
