- en: Chapter 10\. Building AI-Powered Applications
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第10章\. 构建AI驱动应用程序
- en: In this chapter, you’ll apply the five principles of prompting to an end-to-end
    AI workflow for content writing. The service will write blog posts based on the
    user’s responses to interview questions, in the style of the user’s writing. This
    system was first documented on the [Saxifrage blog](https://oreil.ly/saxifrage).
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将应用提示的五个原则到内容写作的端到端AI工作流程中。该服务将根据用户对访谈问题的回答，以用户的写作风格撰写博客文章。这个系统最初在[Saxifrage博客](https://oreil.ly/saxifrage)上进行了记录。
- en: AI Blog Writing
  id: totrans-2
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AI博客写作
- en: The naive approach to creating a blog writing service using AI would be to prompt
    ChatGPT with `Write a blog post on {blogPostTopic}`. The resulting content would
    be of reasonable quality but wouldn’t likely contain any valuable opinions or
    unique experiences on the topic. The content would also likely be short and generic
    and therefore unlikely to rank on Google.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 使用AI创建博客写作服务的天真方法是将ChatGPT提示为`Write a blog post on {blogPostTopic}`。生成的内容质量可能合理，但不太可能包含关于主题的有价值意见或独特经验。内容也可能很短、很普通，因此不太可能排在Google搜索结果的前列。
- en: A more sophisticated approach might be to build up a longer prompt with further
    instructions. Detail on the prescribed writing tone, architecture of the blog
    post, and keywords to include could be added. An example of a common blog post
    [writing prompt](https://oreil.ly/uMfZa) can be seen here.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 一种更复杂的方法可能是构建一个更长的提示，并添加更多指令。可以添加关于规定的写作语气、博客文章的结构和要包含的关键词的详细信息。一个常见的博客文章[写作提示](https://oreil.ly/uMfZa)的例子可以在这里看到。
- en: 'Input:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：
- en: '[PRE0]'
  id: totrans-6
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This longer, more sophisticated prompt is likely to result in better quality
    content. However, let’s run through the five principles of prompting as a checklist:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这个更长、更复杂的提示可能会产生更好的内容质量。然而，让我们回顾一下提示的五个原则作为检查清单：
- en: Direction
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 方向
- en: There are some instructions provided, such as the tone, using transition words,
    and an active voice. However, the content is still likely to sound like AI, and
    not like the user.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 提供了一些指令，例如语气、使用过渡词和主动语态。然而，内容仍然可能听起来像AI，而不是像用户。
- en: Format
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 格式
- en: Although there are some mentions of structure, including dictating nine sections
    of two paragraphs, it’s likely these instructions will be ignored. ChatGPT is
    bad at math and is often unable to follow instructions dictating a number of sections
    or words.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然有一些关于结构的提及，包括指定九个两段的内容，但这些指令很可能会被忽略。ChatGPT在数学方面表现不佳，通常无法遵循指定多个部分或单词的指令。
- en: Examples
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 示例
- en: There are no samples of how to do the task given, which is likely to harm the
    reliability of running this prompt across multiple topics or even multiple times
    on the same topic. Even providing one example (a one-shot prompt) could radically
    help improve quality.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 没有给出如何执行任务的示例，这可能会损害在多个主题或甚至在同一主题上多次运行此提示的可靠性。即使提供一个示例（一次性提示）也可能极大地提高质量。
- en: Evaluation
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 评估
- en: This is an example of *blind prompting* (adding instructions to a prompt [without
    testing them](https://oreil.ly/r7sXi)). It’s likely some of these instructions
    make no difference to quality (unnecessarily costing tokens) or might even degrade
    quality.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个*盲提示*（在提示中添加指令[而不测试它们](https://oreil.ly/r7sXi)）的例子。很可能其中一些指令对质量没有影响（不必要地消耗代币），甚至可能降低质量。
- en: Division
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 分区
- en: The entire task is attempted with just one prompt, which is likely to harm performance.
    Without breaking the task into subtasks, it’s hard to understand which part of
    the process is suceeding or failing.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 整个任务仅用一个提示尝试，这可能会损害性能。如果不将任务分解为子任务，就很难理解哪个部分的过程是成功的或失败的。
- en: Through this chapter, you’ll create multiple LLM chain components. Each chain
    will be implemented in LangChain to make it more maintainable and to give easy
    logging for monitoring and optimization. The resulting system will help you generate
    *human-sounding* content based on the unique opinions and experiences of the user.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 通过本章，你将创建多个LLM链组件。每个链都将使用LangChain实现，使其更易于维护，并便于进行监控和优化的日志记录。这个系统将帮助你基于用户的独特观点和经验生成*听起来像人*的内容。
- en: It’s crucial that you first prepare your workspace with the necessary tools.
    Therefore, let’s shift our focus toward topic research and start setting up your
    programming environment.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 首先准备好你的工作空间，配备必要的工具至关重要。因此，让我们将重点转向主题研究，并开始设置你的编程环境。
- en: Topic Research
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 主题研究
- en: 'You will need to install several Python packages to effectively use LangChain’s
    document loaders, including the following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 您将需要安装几个Python包来有效地使用LangChain的文档加载器，包括以下这些：
- en: google-searchresults
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: google-searchresults
- en: A Python library designed to scrape and process Google search results.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 一个用于抓取和处理Google搜索结果的Python库。
- en: pandas
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: pandas
- en: This offers data structures and operations for manipulating numerical tables
    and time series data.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这提供了操作数值表和时间序列数据的结构和操作。
- en: html2text
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: html2text
- en: This tool converts HTML from files or web pages into markdown (*.md*) files
    or text.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 此工具将HTML文件或网页转换为markdown (*.md*) 文件或文本。
- en: pytest-playwright
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: pytest-playwright
- en: This package enables end-to-end testing with Playwright.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 此包使您可以使用Playwright进行端到端测试。
- en: chromadb
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: chromadb
- en: ChromaDB is an open source vector database.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: ChromaDB是一个开源的向量数据库。
- en: nest_asyncio
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: nest_asyncio
- en: This extends the Python standard `asyncio` to patch and render it compatible
    with Jupyter Notebooks.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这扩展了Python标准的`asyncio`，以便与Jupyter Notebooks兼容。
- en: 'Installation of these packages can be achieved easily with this command:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此命令可以轻松安装这些包：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Additionally, you’ll be using LangChain’s document loaders that require Playwright.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您将使用LangChain的文档加载器，这些加载器需要Playwright。
- en: 'Type this command on your terminal: **playwright install**.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在您的终端上输入此命令：**playwright install**。
- en: 'Additionally, you’ll need to choose a `TOPIC` and set environment variables
    for both `SERPAPI_API_KEY` and `STABILITY_API_KEY`. If you’re running the script
    without Jupyter Notebook, then you won’t need to use any of the `nest_asyncio`
    code:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，您还需要选择一个`TOPIC`并为`SERPAPI_API_KEY`和`STABILITY_API_KEY`设置环境变量。如果您在没有Jupyter
    Notebook的情况下运行脚本，那么您不需要使用任何`nest_asyncio`代码：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next, you’ll focus on summarizing web content efficiently:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，您将专注于高效地总结网络内容：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: First, import the required tools and then fetch the web page content related
    to your `TOPIC`. After setting up your `ChatOpenAI` model, you’ll utilize a `text_splitter`
    to manage text chunks. The splitter ensures no snippet is too long, while maintaining
    context with overlap. Then create the `PydanticOutputParser` to handle and structure
    the summaries. By feeding the extracted documents through a dedicated summarization
    function, the LLM produces concise summaries.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，导入所需的工具，然后获取与您的`TOPIC`相关的网页内容。在设置好`ChatOpenAI`模型后，您将使用`text_splitter`来管理文本块。分割器确保没有片段过长，同时保持上下文重叠。然后创建`PydanticOutputParser`来处理和结构化摘要。通过将提取的文档通过一个专门的摘要函数，LLM产生简洁的摘要。
- en: If you would like to dive deeper into the `create_all_summaries` function, check
    [*custom_summarize_chain.py*](https://oreil.ly/KyKjS).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想深入了解`create_all_summaries`函数，请查看[*custom_summarize_chain.py*](https://oreil.ly/KyKjS)。
- en: 'Some key points to highlight are that you can *subclass* most classes within
    LangChain. For example, you can overide the default `ChromiumLoader` to be asynchronous:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一些需要强调的关键点是，您可以在LangChain中的大多数类中进行子类化。例如，您可以覆盖默认的`ChromiumLoader`以使其异步：
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: By subclassing `ChromiumLoader`, you can easily create a custom implementation
    to *asynchronously scrape content* from multiple URLs using the Chrome browser.
    `get_html_content_from_urls` fetches HTML content from a list of URLs, ensuring
    no duplicates and handling potential errors.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 通过继承`ChromiumLoader`，您可以轻松创建一个自定义实现，使用Chrome浏览器从多个URL异步抓取内容。`get_html_content_from_urls`从URL列表中获取HTML内容，确保没有重复并处理潜在的错误。
- en: Expert Interview
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 专家访谈
- en: 'Now that you’ve successfully extracted the summaries from Google for the top
    three results, you’ll conduct an interview with an LLM, generating relevant questions
    to make sure that your article has a unique perspective using an `InterviewChain`
    class:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经成功从Google提取了前三项结果摘要，您将进行一次与LLM的访谈，生成相关的问题，以确保您的文章使用`InterviewChain`类具有独特的视角：
- en: '[PRE5]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: InterviewChain instantiation
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: InterviewChain实例化
- en: With your topic and obtained summaries in hand, create an instance of `InterviewChain`,
    tailoring it to your data’s unique context.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有您的话题和获得的摘要后，创建一个`InterviewChain`实例，根据您数据独特的上下文进行定制。
- en: Generating questions
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 生成问题
- en: By simply calling the `interview_chain`, you kickstart the process of generating
    a series of probing questions derived from your summaries.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 通过简单地调用`interview_chain`，您启动了从您的摘要中生成一系列探究性问题的过程。
- en: Interactive Q&A session
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 互动问答环节
- en: Dive into an engaging loop where each derived question is printed, prompting
    you for an answer with `input()`. Your response is then saved back to the Pydantic
    object.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 进入一个引人入胜的循环，其中每个派生问题都会打印出来，使用 `input()` 提示你回答。然后你的回答会被保存回 Pydantic 对象。
- en: Give Direction
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 给出方向
- en: Giving an LLM unique answers provides unique context, and this allows an LLM
    to generate richer, more nuanced responses, ensuring your article offers a fresh
    and in-depth perspective.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 给一个 LLM 独特的答案提供独特的上下文，这允许 LLM 生成更丰富、更细腻的回复，确保你的文章提供新颖且深入的视角。
- en: 'All of the code for `InterviewChain` is in *[expert_interview_chain.py](https://oreil.ly/0d5Hi)*.
    It has two significant components:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '`InterviewChain` 的所有代码都在 *[expert_interview_chain.py](https://oreil.ly/0d5Hi)*
    文件中。它有两个重要组成部分：'
- en: A custom `System` message
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 一个定制的 `System` 消息
- en: 'This prompt includes role prompting, previously generated summaries, the topic,
    and format instructions (for the output parser):'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这个提示包括角色提示、之前生成的摘要、主题和格式说明（用于输出解析器）：
- en: '[PRE6]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7] from expert_interview_chain import InterviewQuestions  # Set up a parser
    + inject instructions into the prompt template: parser = PydanticOutputParser(pydantic_object=InterviewQuestions)
    [PRE8]`  [PRE9]`` # Generate Outline    Including the previous interview and research,
    you can generate an outline for the post with `BlogOutlineGenerator`. The `TOPIC`,
    `question_answers`, and Google `summaries` are passed to provide additional context:    [PRE10]    Let’s
    explore the `BlogOutlineGenerator` class in detail:    [PRE11]`` `---`  `Here
    is the interview which I answered:`         `{interview_questions_and_answers}`
    [PRE12] `"""`          `system_message_prompt` `=`         `SystemMessagePromptTemplate``.``from_template``(``prompt_content``)`          `self``.``chat_prompt`
    `=` `ChatPromptTemplate``.``from_messages``(`         `[``system_message_prompt``])`          `#
    Create an output parser`         `self``.``parser` `=` `PydanticOutputParser``(``pydantic_object``=``BlogOutline``)`          `#
    Set up the chain`         `self``.``outline_chain` `=` `self``.``chat_prompt`
    `|` `ChatOpenAI``()` `|` `self``.``parser`      `def` `generate_outline``(``self``,`
    `summaries``:` `List``[``DocumentSummary``])` `->` `Any``:`         `print``(``"Generating
    the outline...``\n``---"``)`         `result` `=` `self``.``outline_chain``.``invoke``(`             `{``"topic"``:`
    `self``.``topic``,`             `"document_summaries"``:` `[``s``.``dict``()`
    `for` `s` `in` `summaries``],`             `"interview_questions_and_answers"``:`
    `self``.``questions_and_answers``,`             `"format_instructions"``:` `self``.``parser``.``get_format_instructions``(),`             `}`         `)`         `print``(``"Finished
    generating the outline!``\n``---"``)`         `return` `result` [PRE13]` [PRE14]   [PRE15]`A
    `BlogOutline` Pydantic object is created that contains `title` and `sub_headings`
    keys. Also, the outline chain is set up using LangChain expression language (LCEL)
    that passes the prompt into the chat model and then finally into the output parser:    [PRE16]    By
    using a Pydantic output parser, the chain will return a `BlogOutline` Pydantic
    object that will be used in future chains.[PRE17]``  [PRE18]` [PRE19] # Text Generation    After
    obtaining a summary, interview questions, and a blog post outline, it’s time to
    start generating the text. The `ContentGenerator` class integrates SEO expertise
    with several LLM techniques, which include the following:    Embeddings and retrieval      This
    efficiently splits and vectorizes original web pages, storing them in the Chroma
    database and retrieving relevent web page text while writing each section.      Custom
    memory      While crafting each blog section, it uses memory to avoid repeating
    the same information, while also summarizing the conversation if it becomes too
    long.      Bespoke context      The LLM has a mixture of information, including
    your previous interview insights, what has been said before, and snippets of relevant
    web page text from Google:      [PRE20]py    All of the source code is within
    *[article_generation.py](https://oreil.ly/0IFyI)*, but let’s specifically focus
    on three components that are key to this chain.    The `OnlyStoreAIMemory` class
    is a customized subclass of `ConversationSummary​BufferMemory`:    [PRE21]py    It’s
    tailored to ensure that the chat messages memory remains concise and relevant
    by *exclusively storing AI-generated messages*.    This deliberate choice bypasses
    storing retrieved documents that are used within the generation step, preventing
    memory bloat. Furthermore, the memory mechanism ensures the AI remains aware of
    its prior writings, enabling it to offer condensed summaries if the accumulated
    context surpasses set limits.    The `generate_blog_post` function loops through
    all of the subheadings and tries to retrieve as many relevant documents as possible
    while fitting in the current context length:    [PRE22]py    This function, `generate_blog_post`,
    iterates over each subheading. It attempts to fetch up to five relevant documents.
    If there’s an issue fetching the documents, it smartly decreases the number and
    tries again. If all attempts fail, it gracefully defaults to no documents.    Finally,
    the prompt for generating each section is very context rich:    [PRE23]py   [PRE24]py  [PRE25]`py
    [PRE26]``'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
