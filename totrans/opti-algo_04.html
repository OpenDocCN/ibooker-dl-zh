<html><head></head><body>
  <h1 class="tochead" id="heading_id_2">4 Informed search algorithms</h1>

  <p class="co-summary-head">This chapter covers<a id="idIndexMarker000"/><a id="marker-103"/></p>

  <ul class="calibre5">
    <li class="co-summary-bullet">Defining informed search</li>

    <li class="co-summary-bullet">Learning how to solve the minimum spanning tree problem</li>

    <li class="co-summary-bullet">Learning how to find the shortest path using informed search algorithms</li>

    <li class="co-summary-bullet">Solving a real-world routing problem using these algorithms</li>
  </ul>

  <p class="body">In the previous chapter, we covered blind search algorithms, which are algorithms in which no information about the search space is needed. In this chapter, we’ll look at how search can be further optimized if we utilize some information about the search space during the search.</p>

  <p class="body">As problems and search spaces become larger and more complex, the complexity of the algorithms themselves increases. I’ll start by introducing informed search algorithms, and then we’ll discuss minimum spanning tree algorithms and shortest path search algorithms. A routing problem will be presented as a real-life application to show how you can use these algorithms.</p>

  <h2 class="fm-head" id="heading_id_3">4.1 Introducing informed search</h2>

  <p class="body">As we discussed in the previous chapter, <i class="fm-italics">blind search algorithms</i> work with no information about the search space, other than the information needed to distinguish the goal state from the others. Like the colloquial expression, “I’ll know it when I see it,” blind search follows a set framework of rules (e.g., breadth-first, depth-first, or Dijkstra’s algorithm) to systematically navigate the search space. <i class="fm-italics">Informed search algorithms</i> differ from blind search algorithms in the sense that the algorithm uses knowledge acquired during the search to guide the search itself. This knowledge can take the form of distance to target or incurred costs.<a id="idIndexMarker001"/><a id="idIndexMarker002"/><a id="idIndexMarker003"/><a id="marker-104"/></p>

  <p class="body">For example, in the 8-puzzle problem, we might use the number of misplaced tiles as a heuristic to determine how far any given state is from the goal state. In this way, we can determine at any given iteration of the algorithm how well it is performing and modify the search method based on current conditions. The definition of “good performance” depends on the heuristic algorithm being used.</p>

  <p class="body">Informed search algorithms can be broadly classified into those that solve for minimum spanning tree (MST) problems and those that compute the shortest path between two specific nodes or states, as outlined in figure 4.1.<a id="idIndexMarker004"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F01_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.1 Examples of informed search algorithms. Each algorithm has multiple variants based on improvements, specific use cases, and specialized domains.</p>
  </div>

  <p class="body">Several algorithms have been proposed to solve MST problems:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Borůvka’s algorithm</i> finds an MST in a graph for which all edge weights are distinct. It also finds a minimum spanning forest, in the case of a graph that is not connected. It starts with each node as its own tree, identifies the cheapest edge leaving each tree, and then merges the trees joined by these edges. No edge presorting is needed or maintained in a priority queue.<a id="idIndexMarker005"/><a id="marker-105"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Jarník-Prim’s algorithm</i> starts from the root vertex and finds the lowest-weight edge from an MST vertex to a non-MST vertex and adds it to MST at each step.<a id="idIndexMarker006"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Kruskal’s algorithm</i> sorts edges by increasing weight and starts from the least-weighted edge to form a small MST component and then grows them into one large MST. I will describe this algorithm in more detail in the next section.<a id="idIndexMarker007"/></p>
    </li>
  </ul>

  <p class="body">Hill climbing (HC), beam search, the A* algorithm, and contraction hierarchies (CH) are examples of informed search algorithms that can be used to find the shortest path between two nodes:<a id="idIndexMarker008"/></p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Hill climbing</i> is a local search algorithm that continuously moves in the direction of optimizing the objective function, increasing in the case of maximization problems, or decreasing in the case of minimization problems.<a id="idIndexMarker009"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Beam search</i> explores a graph or tree by expanding the most promising node within a limited predefined set.<a id="idIndexMarker010"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">The A* algorithm</i> combines both the cost accrued up to a node and heuristic information, such as the straight-line distance between this node and the destination node, to select new nodes for expansion.<a id="idIndexMarker011"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Hierarchical approaches</i>, such as reach-based routing, highway hierarchies (HHs), highway-node routing (HNR), transit-node routing (TNR), and contraction hierarchy (CH), are hierarchical approaches that take into consideration node importance and try to prune the search space by admissible heuristics.<a id="idIndexMarker012"/><a id="idIndexMarker013"/><a id="idIndexMarker014"/><a id="idIndexMarker015"/></p>
    </li>
  </ul>

  <p class="body">The next section introduces the concept of an MST and presents an algorithm that can generate an MST for any given graph.</p>

  <h2 class="fm-head" id="heading_id_4">4.2 Minimum spanning tree algorithms</h2>

  <p class="body">Imagine that you are the infrastructure manager for a small, remote rural town. Unlike most towns, there isn’t really a main street or downtown area, so most points of interest are scattered. Additionally, budget cuts in previous years have left the roads either damaged or non-existent. The damaged roads are all buried under mud and are essentially impassable. You’ve been given a small budget to fix or build roads to improve the situation, but the money isn’t enough to repair all the existing roads or to build new ones. Figure 4.2 shows a map of the town, as well as the locations of the existing damaged roads.<a id="marker-106"/><a id="idIndexMarker016"/><a id="idIndexMarker017"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F02_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.2 The muddy city problem. The roads in this town are badly damaged, but there isn’t enough money to repair them all.</p>
  </div>

  <p class="body">There are several ways to approach this problem, ranging from the not feasible (repair all the damaged roads and live with the consequences of a bankrupt town) to the overly conservative (only fix a few roads, or none at all, and ignore all the complaining townspeople). This problem is typically known as the muddy city problem, where various nodes in a graph must be connected while minimizing the edge weights. These weights can present the cost of fixing or paving the road, which may vary depending on the road’s condition, length, and topology.</p>

  <p class="body">The mathematical way of solving the muddy city problem involves the idea of a minimum spanning tree (MST). A spanning tree, in general, is a cycle-free or loop-free subgraph of an undirected graph that connects all the vertices of the graph with the minimum number of edges. In figure 4.3, the left tree shows a graph <i class="timesitalic">G</i> with nodes from A to F, while the middle and right trees show spanning trees of <i class="timesitalic">G</i>. Notice that generic spanning trees do not require the edges to be weighted (i.e., to have a length, speed, time, or cost associated with them).<a id="idIndexMarker018"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F03_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.3 Examples of spanning trees. The middle and right trees reach every node of graph <i class="timesitalic">G</i> with no loops or cycles.</p>
  </div>

  <p class="body">An MST or minimum-weight spanning tree of an edge-weighted graph is a spanning tree whose weight (the sum of the weights of its edges) is no larger than the weight of any other spanning tree.</p>

  <p class="body">If <span class="times"><i class="fm-italics">G</i>=(<i class="fm-italics">V, E</i>)</span> is a graph, then any subgraph of <i class="timesitalic">G</i> is a spanning tree if both of the following conditions are met:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">The subgraph contains all vertices <i class="timesitalic">V</i> of <i class="timesitalic">G</i>.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">The subgraph is connected with no circuits and no self-loops.</p>
    </li>
  </ul>

  <p class="body"><a id="marker-107"/>For a given spanning tree <i class="timesitalic">T</i> for a graph <i class="timesitalic">G</i>, the weight <i class="timesitalic">w</i> of the spanning tree is the sum of the weights of all the edges in <i class="timesitalic">T</i>. If the weight of <i class="timesitalic">T</i> is the lowest of the weights of all the possible spanning trees of <i class="timesitalic">G</i>, then we can call this an MST.</p>

  <p class="body">The previously described muddy city problem will be solved as an MST. Kruskal, Borůvka, Jarník-Prim, and Chazelle are all examples of algorithms that can be used to find an MST. Algorithm 4.1 shows the pseudocode for Kruskal’s algorithm.</p>

  <p class="fm-code-listing-caption">Algorithm 4.1 Kruskal’s algorithm</p>
  <pre class="programlisting">Input: Graph G = (V, E) with each edge e <span class="cambria">∈</span> E having a weight w(e)
Output: A minimum spanning tree T
  
Create a new graph T:= <span class="cambria">∅</span> with the same vertices as G, but with no edges.
Define a list S containing all the edges in the graph G
Sort the edges list S in ascending order of their weights.
For each edge e in the sorted list:
   If adding edge e to T does not form a cycle:
      Add this edge to T.
   Else:
      Skip this edge and move to the next edge in the list.
Continue this process until all the edges are processed.
Return T as the minimum spanning tree of graph G.</pre>

  <p class="body">To better understand these steps, let’s apply Kruskal’s algorithm to solve the muddy city problem. Figure 4.4 shows the original graph. The numbers near the edges represent edge weights, and no edges have been added to the MST yet. The following steps will generate the MST by hand iteration.</p>

  <div class="figure">
    <p class="figuree"><img alt="" class="calibre4" src="../Images/CH04_F04_Khamis.png"/></p>

    <p class="figurecaptione">Figure 4.4 Solving the muddy city problem using Kruskal’s algorithm—original graph</p>
  </div>

  <p class="body-dialog">  1.  The shortest edge is E-H with a length of 1, so it is highlighted and added to the MST (figure 4.5).<a id="marker-108"/></p>

  <div class="figure">
    <p class="figuree"><img alt="" class="calibre4" src="../Images/CH04_F05_Khamis.png"/></p>

    <p class="figurecaptione">Figure 4.5 Solving the muddy city problem using Kruskal’s algorithm—step 1</p>
  </div>

  <p class="body-dialog">  2.  B-C, C-G, G-F, and I-J are now the shortest edges with lengths of 2. B-C is chosen arbitrarily and is highlighted, followed by C-G, G-F, and I-J, as they don’t form a cycle (figure 4.6).</p>

  <div class="figure">
    <p class="figuree"><img alt="" class="calibre4" src="../Images/CH04_F06_Khamis.png"/></p>

    <p class="figurecaptione">Figure 4.6 Solving the muddy city problem using Kruskal’s algorithm—step 2</p>
  </div>

  <p class="body-dialog">  3.  C-F, F-J, G-I, A-D, and D-E are now the shortest edges with lengths of 3. C-F cannot be chosen, as it forms a cycle. A-D is chosen arbitrarily and is highlighted, followed by D-E and G-I. F-J cannot be chosen, as it forms a cycle (figure 4.7).<a id="marker-109"/></p>

  <div class="figure">
    <p class="figuree"><img alt="" class="calibre4" src="../Images/CH04_F07_Khamis.png"/></p>

    <p class="figurecaptione">Figure 4.7 Solving the muddy city problem using Kruskal’s algorithm—step 3</p>
  </div>

  <p class="body-dialog">  4.  The next-shortest edges are A-E and G-H with lengths 4. A-E cannot be chosen because it forms a cycle, so the process finishes with the edge G-H. The minimum spanning tree has been found (figure 4.8).</p>

  <div class="figure">
    <p class="figuree"><img alt="" class="calibre4" src="../Images/CH04_F08_Khamis.png"/></p>

    <p class="figurecaptione">Figure 4.8 Solving the muddy city problem using Kruskal’s algorithm—step 4</p>
  </div>

  <p class="body">Figure 4.9 shows the final solution with all nodes in the graph connected.<a id="marker-110"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F09_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.9 Solving the muddy city problem using Kruskal’s algorithm. The algorithm adds edges to the final tree by ascending weight order, ignoring edges that will form a cycle.</p>
  </div>

  <p class="body">This algorithm can be implemented easily in Python by using NetworkX’s <code class="fm-code-in-text">find_cycle()</code> and <code class="fm-code-in-text">is_connected()</code> methods, which determine if an edge is a viable candidate for the MST, as well as the overall algorithm’s termination condition, respectively. For the purposes of visual presentation, I’ve also used <code class="fm-code-in-text">spring_layout()</code> for the positions of the nodes and edges of the graph. The <code class="fm-code-in-text">spring_layout()</code> method uses a random number generator internally to generate these positions, and we can pass a seed (which allows a deterministic generation of so-called “pseudo-random” numbers) to guarantee a specific layout on each execution. Try modifying the seed parameter, and see what happens.<a id="idIndexMarker019"/><a id="idIndexMarker020"/><a id="idIndexMarker021"/><a id="marker-111"/></p>

  <p class="fm-code-listing-caption">Listing 4.1 Solving the muddy city problem using Kruskal’s algorithm</p>
  <pre class="programlisting">import matplotlib.pyplot as plt
import networkx as nx
  
G = nx.Graph()                                                          <span class="fm-combinumeral">①</span>
G.add_nodes_from(["A", "B", "C", "D", "E", "F", "G", "H", "I", "J"])    <span class="fm-combinumeral">①</span>
  
edges = [                                                               <span class="fm-combinumeral">①</span>
    ("A", "B", {"weight": 10}),                                         <span class="fm-combinumeral">①</span>
    ("A", "C", {"weight": 5}),                                          <span class="fm-combinumeral">①</span>
    ("A", "D", {"weight": 3}),                                          <span class="fm-combinumeral">①</span>
    ("A", "E", {"weight": 4}),                                          <span class="fm-combinumeral">①</span>
    ("B", "C", {"weight": 2}),                                          <span class="fm-combinumeral">①</span>
    ("B", "F", {"weight": 6}),                                          <span class="fm-combinumeral">①</span>
    ("C", "E", {"weight": 11}),                                         <span class="fm-combinumeral">①</span>
    ("C", "F", {"weight": 3}),                                          <span class="fm-combinumeral">①</span>
    ("C", "G", {"weight": 2}),                                          <span class="fm-combinumeral">①</span>
    ("D", "E", {"weight": 3}),                                          <span class="fm-combinumeral">①</span>
    ("D", "H", {"weight": 5}),                                          <span class="fm-combinumeral">①</span>
    ("E", "G", {"weight": 5}),                                          <span class="fm-combinumeral">①</span>
    ("E", "H", {"weight": 1}),                                          <span class="fm-combinumeral">①</span>
    ("F", "G", {"weight": 2}),                                          <span class="fm-combinumeral">①</span>
    ("F", "I", {"weight": 7}),                                          <span class="fm-combinumeral">①</span>
    ("F", "J", {"weight": 13}),                                         <span class="fm-combinumeral">①</span>
    ("G", "H", {"weight": 4}),                                          <span class="fm-combinumeral">①</span>
    ("G", "I", {"weight": 3}),                                          <span class="fm-combinumeral">①</span>
    ("H", "I", {"weight": 6}),                                          <span class="fm-combinumeral">①</span>
    ("I", "J", {"weight": 2}),                                          <span class="fm-combinumeral">①</span>
]                                                                       <span class="fm-combinumeral">①</span>
  
G.add_edges_from(edges)
pos = nx.spring_layout(G, seed=74)                                      <span class="fm-combinumeral">②</span>
  
def Kruskal(G, attr = "weight"):
    edges = sorted(G.edges(data=True), key=lambda t: t[2].get(attr, 1)) <span class="fm-combinumeral">③</span>
    mst = nx.Graph()
    mst.add_nodes_from(G)
    for e in edges:
        mst.add_edges_from([e])
        try:                                                            <span class="fm-combinumeral">④</span>
            nx.find_cycle(mst)                                          <span class="fm-combinumeral">④</span>
            mst.remove_edge(e[0], e[1])                                 <span class="fm-combinumeral">④</span>
        except:
            if nx.is_connected(mst):                                    <span class="fm-combinumeral">⑤</span>
                break
            continue
    return mst</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Create an undirected graph and populate it with nodes and edges.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Using a seed with the spring_layout method guarantees the same placement of nodes every time.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Sort edges by weight in ascending order.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> find_cycle raises an error if no cycles exist in the graph. We can try/catch this error to determine if adding a new edge creates a cycle.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> The set of edges in mst is a spanning tree if the graph formed by those edges is connected.</p>

  <p class="body">As a continuation of listing 4.1, the following code snippet is used to generate an MST using Kruskal and to visualize the MST:</p>
  <pre class="programlisting">MST = Kruskal(G).edges                                                  <span class="fm-combinumeral">①</span>
labels = nx.get_edge_attributes(G, "weight")
nx.draw_networkx_edges(G, pos, list(MST), width=4, edge_color="red")    <span class="fm-combinumeral">②</span>
nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)                <span class="fm-combinumeral">③</span>
nx.draw_networkx(G, pos, with_labels=True, font_color="white")          <span class="fm-combinumeral">④</span>
plt.show()</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Call Kruskal’s algorithm to generate the MST.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Draw the edges.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Add the labels.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Draw the MST.</p>

  <p class="body"><a id="marker-112"/>As you can see in figure 4.10, our Python implementation of the muddy city problem produces the exact same results that we achieved using hand iteration. Node G, which is the town hall, becomes a sort of central hub for the town’s transportation infrastructure, and the total cost of road construction is minimized. It’s worth noting, however, that while MST minimizes the total cost of connecting all nodes, it doesn’t usually produce the most “convenient” solution. Should someone wish to travel from the place of worship to the hospital, for example, the shortest achievable distance would be 7 (passing through the police station), while our road network requires a total distance of 15.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F10_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.10 The muddy city problem solved using Kruskal’s algorithm. The highlighted edges are part of the MST.</p>
  </div>

  <p class="body">Let’s apply this algorithm and this code to find the MST for all nodes in a search space surrounding the University of Toronto. Imagine that we have been tasked with installing new communications cables across the city, and we want to minimize the length of cable we use.</p>

  <p class="fm-code-listing-caption">Listing 4.2 University of Toronto MST</p>
  <pre class="programlisting">import networkx as nx
import osmnx
import matplotlib.pyplot as plt
from optalgotools.algorithms.graph_search import Kruskal
  
reference = (43.661667, -79.395)
G = osmnx.graph_from_point(
    reference, dist=1000, clean_periphery=True, simplify=True, network_
type="drive"
)                                                                     <span class="fm-combinumeral">①</span>
fig, ax = osmnx.plot_graph(G)
  
undir_G = G.to_undirected()                                           <span class="fm-combinumeral">②</span>
sorted_edges = sorted(undir_G.edges(data=True), key=lambda t:         <span class="fm-combinumeral">②</span>
<span class="fm-code-continuation-arrow">➥</span> t[2].get("length",1))                                              <span class="fm-combinumeral">②</span>
  
mst = Kruskal(G, sorted_edges=True, edges= sorted_edges,
<span class="fm-code-continuation-arrow">➥</span> graph_type=nx.MultiDiGraph)                                        <span class="fm-combinumeral">③</span>
  
highlight_edges = ['b' if e in mst.edges else 'r' for e in G.edges]   <span class="fm-combinumeral">④</span>
edge_alphas = [1 if e in mst.edges else 0.25 for e in G.edges]        <span class="fm-combinumeral">④</span>
osmnx.plot_graph(
    G, 
    edge_linewidth=2, 
    edge_color=highlight_edges, 
    edge_alpha=edge_alphas
)                                                                     <span class="fm-combinumeral">④</span>
plt.show()                                                            <span class="fm-combinumeral">④</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Use the drive network to only focus on drivable roads. This prevents the code from building an MST with a combination of roads and sidewalks.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Get an undirected copy of the graph, and sort the road network edges by edge length.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Call the Kruskal algorithm from optalgotools, using a presorted list and specifying the graph type.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Visualize the MST by highlighting the included edges.</p>

  <p class="body"><a id="marker-113"/>Figure 4.11 shows the resulting MST generated by Kruskal’s algorithm. The road network graph in the figure may seem like one big connected component, but it isn’t. There are one-way streets that seem to connect adjacent nodes on the graph, but in reality, they are not connected (you can go from A to B but not the reverse). We overcome this by converting the directed graph into an undirected graph using the <code class="fm-code-in-text">to_undirected</code> function in NetworkX.<a id="idIndexMarker022"/></p>

  <p class="body">The version of Kruskal’s algorithm used in the listing is the same as was used for the muddy city problem. We’re importing it from optalgotools to reduce the amount of code needed.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F11_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.11 The MST generated by Kruskal’s algorithm. All the edges included in the MST are highlighted. There are no cycles in the MST, and the total weight of the tree is minimized.</p>
  </div>

  <p class="body">MSTs have a wide variety of applications in the real world, including network design, image segmentation, clustering, and facility location problems. MSTs are especially useful when dealing with problems concerning budgeting, such as planning networks, as they allow all nodes to be connected with a minimum total cost. As previously mentioned, informed search algorithms can be used to find MSTs as described in this section and with shortest path algorithms, which are discussed in the next section.<a id="idIndexMarker023"/><a id="idIndexMarker024"/><a id="marker-114"/></p>

  <h2 class="fm-head" id="heading_id_5">4.3 Shortest path algorithms</h2>

  <p class="body">Informed search algorithms can be used to find the shortest path between two nodes by using knowledge about the problem (domain-specific knowledge) to prune the search. This knowledge, in the form of a heuristic function, gives an estimate of the distance to the goal. Examples of informed search algorithms include hill climbing, beam search, best-first, A*, and contraction hierarchies. The following subsections discuss these algorithms in detail.<a id="idIndexMarker025"/><a id="idIndexMarker026"/></p>

  <h3 class="fm-head1" id="heading_id_6">4.3.1 Hill climbing algorithm</h3>

  <p class="body">Assume that you are trying to climb to the top of a mountain in a dense fog. There is only one path up and down the mountain, but you aren’t sure exactly where the peak is. Thus, you are only able to judge your progress by looking one step behind you and seeing if you’ve gone uphill or downhill since your last step. How can you know when you’ve reached the summit? A good guess would be when you’re no longer going uphill!<a id="idIndexMarker027"/><a id="idIndexMarker028"/><a id="idIndexMarker029"/><a id="marker-115"/></p>

  <p class="body">Starting with a known (non-optimized) solution to a function or with an initial state, the hill climbing algorithm checks the neighbors of that solution and chooses the neighbor that is more optimized. This process is repeated until no better solution can be found, at which point the algorithm terminates.</p>

  <p class="body">The hill climbing algorithm is a local greedy search algorithm that tries to improve the efficiency of depth-first by incorporating domain-specific knowledge or heuristic information, so it can be considered as an informed depth-first algorithm. The hill climbing algorithm’s pseudocode applied to graph search is shown in the algorithm 4.2 assuming minimization problem.</p>

  <p class="fm-code-listing-caption">Algorithm 4.2 The hill climbing algorithm</p>
  <pre class="programlisting">Inputs: Source node, Destination node
Output: Route from source to destination
  
Initialize current <span class="cambria">←</span> random route from source to destination
Initialize neighbours <span class="cambria">←</span> children of current
  
While min(neighbours) &gt; current do
   Set current <span class="cambria">←</span> min(neighbours)
   Update neighbours <span class="cambria">←</span> children of current
Return current as the route from source to destination</pre>

  <p class="body">The algorithm sorts the successors of a node (according to their heuristic values) before adding them to the list to be expanded. This algorithm demands very little in the way of memory and computational overhead, as it simply remembers the current successors as the current path it is working on. It’s a non-exhaustive technique; it does not examine the entire tree, so its performance will be reasonably fast. However, while this algorithm works relatively well with convex problems, functions with multiple local maxima will often result in an answer that is not the global maximum. It also performs poorly when there are plateaus (a local set of solutions that are all similarly optimized).</p>

  <p class="body">As shown in figure 4.12, depending on the initial state, the hill climbing algorithm may get stuck in local optima. Once it reaches the top of a hill, the algorithm will stop, since any new successor will be down the hill. This is analogous to climbing the mountain in the fog, reaching a smaller peak, and thinking that you’ve reached the main summit.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F12_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.12 Depending on the initial state, the hill climbing algorithm may get stuck in local optima. Once it reaches a peak, the algorithm will stop, since any new successor will be down the hill.</p>
  </div>

  <p class="body"><a id="marker-116"/>Simple hill climbing, steepest-ascent hill climbing, stochastic hill climbing, and random-restart hill climbing are all variants of the hill climbing algorithm, as shown in figure 4.13.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F13_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.13 Variants of the hill climbing algorithm</p>
  </div>

  <p class="body"><i class="fm-italics">Simple hill climbing</i> examines the neighboring nodes one by one and selects the first neighboring node that optimizes the objective function as the next node to be explored. <i class="fm-italics">Steepest-ascent or steepest-descent hill climbing</i> is a variation on the simple hill-climbing algorithm that first examines all the neighboring nodes of the current state and selects one neighbor node that is closest to the goal state. <i class="fm-italics">Stochastic hill climbing</i> is a randomized version of a hill climbing algorithm that selects a neighboring node at random without examining all the neighboring nodes. This algorithm decides whether to move to that neighbor or to examine another based on the amount of improvement in that neighbor. Random-restart hill climbing or first-choice hill climbing follows a try-and-try strategy and iteratively searches the nodes and selects the best one at each step until the goal is found. If it gets stuck in a local maximum, it restarts the process from a new random initial state. Compared to the other hill climbing variants, this algorithm is better able to reach the destination if there are plateaus, local optima, and ridges.<a id="idIndexMarker030"/><a id="idIndexMarker031"/><a id="idIndexMarker032"/><a id="idIndexMarker033"/><a id="marker-117"/></p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title">Gradient descent algorithm</p>

    <p class="fm-sidebar-text">The <i class="fm-italics">gradient descent algorithm</i> is widely used in machine learning to train models and make predictions. Gradient descent and hill climbing are two fundamentally different algorithms and cannot be confused with each other. Instead of climbing up a hill, gradient descent can be seen as hiking down to the bottom of a valley. Gradient descent is an iterative algorithm that looks at the slope of the local neighbors and moves in the direction with the steepest slope or the direction of negative gradient to optimize a continuous differentiable function. Alternatively, in the case of a maximization problem, <i class="fm-italics">gradient ascent</i> moves in the direction with a positive gradient to optimize the objective function. <a id="idIndexMarker034"/><a id="idIndexMarker035"/></p>

    <p class="fm-sidebar-text">The gradient descent algorithm usually converges to a global minimum if the function is convex (i.e., if any local minimum is also a global minimum) and the learning rate is properly chosen. The hill climbing algorithm is a heuristic greedy algorithm that can easily get stuck in local optima. It is used mainly for discrete optimization problems, such as the traveling salesman, as it doesn’t require the objective function to be differentiable.</p>
  </div>

  <p class="body">Assume we have the simple graph shown in figure 4.14. The source node is S and the destination node is G.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F14_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.14 An 8 points of interest (POIs) road network in the form of a graph</p>
  </div>

  <p class="body">This graph can be converted into a tree by finding a spanning tree that includes all the vertices of the original graph and that is connected and acyclic, as shown in figure 4.15.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F15_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.15 An 8 points of interest (POIs) road network in the form of a tree</p>
  </div>

  <p class="body"><a id="marker-118"/>As you can see, there are multiple ways to go from S to G, each with different costs. Following the hill climbing algorithm, the shortest path between S and G will be S→A→C→E→G, as illustrated in figure 4.16.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F16_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.16 Shortest path between S and G using the hill climbing algorithm</p>
  </div>

  <p class="body">Let’s now use the 8-puzzle problem to illustrate the hill climbing approach. Figure 4.17 shows how the hill climbing search progresses, using the number of misplaced tiles, excluding the blank tile, as heuristic information <i class="fm-italics">h</i>(<i class="fm-italics">n</i>). For example, in step 2, tiles 1, 4, 6, and 7 are wrongly placed, so <i class="fm-italics">h</i> = 4. In step 3, tiles 1, and 4 are misplaced, so <i class="fm-italics">h</i> = 2.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F17_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.17 Using the hill climbing algorithm to solve the 8-puzzle problem. At each iteration, the algorithm explores neighboring states, looking for the minimum heuristic value.</p>
  </div>

  <p class="body"><a id="marker-119"/>Listing 4.3 shows a simple implementation of hill climbing in Python. The code selects nodes to explore by minimizing the heuristic value of the next node. A more complex version, involving generating shortest paths, will be presented at the end of this chapter.</p>

  <p class="fm-code-listing-caption">Listing 4.3 Solving the 8-puzzle problem using hill climbing</p>
  <pre class="programlisting">import matplotlib.pyplot as plt
  
def Hill_Climbing(origin, destination, cost_fn):
    costs = [cost_fn(origin)]
    current = origin
    route = [current]
    neighbours = current.expand()                           <span class="fm-combinumeral">①</span>
    shortest = min(neighbours, key=lambda s: cost_fn(s))    <span class="fm-combinumeral">②</span>
    costs.append(cost_fn(shortest))
    route.append(shortest)
  
    while cost_fn(shortest) &lt; cost_fn(current):
        current = shortest
        neighbours = current.expand()
        shortest = min(neighbours, key=lambda s: cost_fn(s))
        costs.append(cost_fn(shortest))
        route.append(shortest)
        if shortest == destination:                         <span class="fm-combinumeral">③</span>
            break
  
    return route, costs
  
def misplaced_tiles(state: State):                          <span class="fm-combinumeral">④</span>
    flat = state.flatten()                                  <span class="fm-combinumeral">④</span>
    goal = range(len(flat))                                 <span class="fm-combinumeral">④</span>
    return sum([0 if goal[i] == flat[i] else 1 for i in range(len(flat))])    </pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> The neighbor nodes of the current state can be generated using expand().</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> The “closest” neighbor is the one with the lowest cost function (i.e., the fewest misplaced tiles).</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Terminate the algorithm if the goal state has been reached.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Calculate and return the number of misplaced tiles that are not in their goal positions.</p>

  <p class="fm-callout"><span class="fm-callout-head">Note</span> The State class and visualize function are defined in the complete listing, available in the book’s GitHub repo.</p>

  <p class="body"><a id="marker-120"/>The following code snippet defines the initial and goal states of the puzzle and uses hill climbing to solve the puzzle:</p>
  <pre class="programlisting">init_state = [[1,4,2],
              [3,7,5],
              [6,0,8]]
  
goal_state = [[0,1,2],
              [3,4,5],
              [6,7,8]]
  
init_state = State(init_state)
goal_state = State(goal_state)
  
if not init_state.is_solvable():                             <span class="fm-combinumeral">①</span>
    print("This puzzle is not solvable.")
else:
    solution, costs = Hill_Climbing(init_state, goal_state,
    <span class="fm-code-continuation-arrow">➥</span> misplaced_tiles)                                      <span class="fm-combinumeral">②</span>
    plt.xticks(range(len(costs)))                            <span class="fm-combinumeral">③</span>
    plt.ylabel("Misplaced tiles")                            <span class="fm-combinumeral">③</span>
    plt.title("Hill climbing: 8 Puzzle")                     <span class="fm-combinumeral">③</span>
    plt.plot(costs)                                          <span class="fm-combinumeral">③</span>
    visualize(solution)                                      <span class="fm-combinumeral">③</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Check if there is even a solution.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Solve the puzzle using hill climbing</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Plot the search progress, and visualize the solution.</p>

  <p class="body">The output is shown in figure 4.18.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F18_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.18 States of the hill climbing solution for the 8-puzzle problem. Each subsequent state is selected by minimizing its cost compared to its neighbors. As the 8-puzzle problem has not only a well-defined but also an achievable goal state, the algorithm’s termination condition (the goal being reached) coincides with the “peak” of the hill (which in this case is a valley, as it is a minimization problem).</p>
  </div>

  <p class="body">As the 8-puzzle problem uses a heuristic as a cost, it essentially becomes a minimization problem. This implementation differs from the standard hill climbing in that, as a solution can always be found, and the graph is fully connected (you can transition from any state to another state through some combination of tile movements), the algorithm is guaranteed to find the optimal solution eventually. More complex problems will often generate solutions that are near-optimal.<a id="idIndexMarker036"/><a id="idIndexMarker037"/><a id="idIndexMarker038"/></p>

  <h3 class="fm-head1" id="heading_id_7">4.3.2 Beam search algorithm</h3>

  <p class="body"><a id="marker-121"/>The <i class="fm-italics">beam search algorithm</i> tries to minimize the memory requirements of the breadth-first algorithm, so it can be seen as an informed breadth-first algorithm. While hill climbing maintains a single best state throughout the run, beam search keeps <i class="timesitalic">w</i> states in memory, where <i class="timesitalic">w</i> is the beam width. At each iteration, it generates the neighbors for each of the states and puts them into a pool with the states from the original beam. It then selects the best <i class="timesitalic">w</i> states from the pool at each level to become the new beam, and the rest of the states are discarded. This process then repeats. The algorithm expands only the first <i class="timesitalic">w</i> promising nodes at each level. <a id="idIndexMarker039"/><a id="idIndexMarker040"/><a id="idIndexMarker041"/></p>

  <p class="body">This is a non-exhaustive search, but it is also a hazardous process, because a goal state might be missed. As this is a local search algorithm, it is also susceptible to getting stuck at a local optima. A beam search with <i class="timesitalic">w</i> equal to the number of nodes in each level is the same as a BFS. Because there is the risk that a state that could lead to the optimal solution might be discarded, beam searches are incomplete (they may not terminate with the solution).</p>

  <p class="body">Algorithm 4.3 shows the pseudocode for the beam search algorithm applied to a graph search.</p>

  <p class="fm-code-listing-caption">Algorithm 4.3 The beam search algorithm</p>
  <pre class="programlisting">Inputs: A source node, a destination node, and beam width w
Output: A route from source to destination
  
Initialize Seen <span class="cambria">←</span> nil
Initialize beam <span class="cambria">←</span> random w routes from source to destination
Add beam to seen
Initialize pool <span class="cambria">←</span> children of routes in the beam with consideration of seen + beam
Initialize last_beam <span class="cambria">←</span> nil
While beam is not last_beam do
   Update last_beam <span class="cambria">←</span> beam
   Update beam <span class="cambria">←</span> the best w routes from pool
   If last_beam == beam then break
   Add beam to seen
   Update pool <span class="cambria">←</span> children of routes in the beam + beam
  
Return optimal route in beam</pre>

  <p class="body">In section 2.3.1, you saw that BFS has an exponential complexity of <span class="times"><i class="fm-italics">O</i>(<i class="fm-italics">b<sup class="fm-superscript">d</sup></i>)</span>, where <i class="timesitalic">b</i> represents the maximum branching factor for each node and <i class="timesitalic">d</i> is the depth one must expand to reach the goal. In the case of beam search, we only explore <span class="times"><i class="fm-italics">w</i> × <i class="timesitalic">b</i></span> nodes at any depth, saving many unneeded nodes compared to BFS. However, finding the best states or routes requires sorting, which is time-consuming if <span class="times"><i class="fm-italics">w</i> × <i class="timesitalic">b</i></span> is a huge number. A beam threshold can be used to handle this problem, where the best node is selected based on the heuristic function <span class="times"><i class="fm-italics">h</i>(<i class="fm-italics">n</i>)</span> within a certain threshold, and all the nodes outside this are pruned away.<a id="marker-122"/></p>

  <p class="body">Revisiting the simple routing problem with 8 points of interest (figure 4.14) and following the beam search algorithm with <i class="timesitalic">w</i> = <i class="fm-italics">2</i>, the shortest path between S and G will be S-A-C-E-G, as illustrated in figure 4.19.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F19_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.19 The shortest path between S and G using a beam search algorithm. With a beam width <span class="times"><i class="fm-italics">w</i> = 2</span>, two states are kept in the beam at each iteration. After generating the neighbors of each element in the beam, only the best <i class="timesitalic">w</i> beams are kept.</p>
  </div>

  <p class="body">The following listing shows a basic implementation of beam search used for a simple routing problem. See the full code in the GitHub repo to see how the graph is initialized, as well as how the visualization is generated (it is quite similar to that of listing 4.1).</p>

  <p class="fm-code-listing-caption">Listing 4.4 Simple routing with beam search</p>
  <pre class="programlisting">import matplotlib.pyplot as plt
import networkx as nx
import heapq
from optalgotools.structures import Node
from optalgotools.routing import cost
  
G = nx.Graph()                                               <span class="fm-combinumeral">①</span>
G.add_nodes_from(["A", "B", "C", "D", "E", "F", "G", "S"])   <span class="fm-combinumeral">①</span>
edges = [
    ("A", "B", {"weight": 4}),
    ("A", "C", {"weight": 3}),
    ("A", "S", {"weight": 2}),
    ("B", "D", {"weight": 3}),
    ("B", "S", {"weight": 4}),
    ("C", "E", {"weight": 4}),
    ("C", "D", {"weight": 5}),
    ("D", "E", {"weight": 6}),
    ("D", "F", {"weight": 5}),
    ("E", "F", {"weight": 7}),
    ("E", "G", {"weight": 3}),
    ("F", "G", {"weight": 3}),
]                                                            <span class="fm-combinumeral">①</span>
G.add_edges_from(edges)                                      <span class="fm-combinumeral">①</span>
G=G.to_directed()                                            <span class="fm-combinumeral">①</span>
  
def Beam_Search(G, origin, destination, cost_fn, w=2, expand_kwargs=[],
<span class="fm-code-continuation-arrow">➥</span> cost_kwargs=[]):
    seen = set()
    seen.add(origin)
    last_beam = None
    pool = set(origin.expand(**expand_kwargs))               <span class="fm-combinumeral">②</span>
    beam = []
    while beam != last_beam:
        last_beam = beam
        beam = heapq.nsmallest(
            w, pool, key=lambda node: cost_fn(G, node.path(),
            <span class="fm-code-continuation-arrow">➥</span> **cost_kwargs))                               <span class="fm-combinumeral">③</span>
        current = beam.pop(0)
        seen.add(current)
        pool.remove(current)
        children = set(current.expand(**expand_kwargs))
        for child in children:                               <span class="fm-combinumeral">④</span>
            if child in seen: next                           <span class="fm-combinumeral">④</span>
            else:    #D                                      <span class="fm-combinumeral">④</span>
                if child == destination:                     <span class="fm-combinumeral">④</span>
                    return child.path()                      <span class="fm-combinumeral">④</span>
                beam.append(child)                           <span class="fm-combinumeral">④</span>
        pool.update(beam)
    return None                                              <span class="fm-combinumeral">⑤</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Create a directed graph.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Get the neighbors of the node using the origin class’s expand() method, passing any necessary arguments.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Prune the pool down to only the best k paths, passing any necessary arguments to the cost function.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Child routes are generated for each route by adding one extra node to the route. For each of these new routes, they are rejected (already explored), added to the beam (and then to the pool), or accepted (because they reach the destination).</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> None is returned if a path cannot be found.</p>

  <p class="body"><a id="marker-123"/>This function can be called with the following example parameters:</p>
  <pre class="programlisting">result = Beam_Search(
    G,
    Node(G, "S"),
    Node(G, "G"),
    cost,
    expand_kwargs={"attr_name": "weight"},
    cost_kwargs={"attr_name": "weight"},
)</pre>

  <p class="body">Visualizing the output of this algorithm produces the graph in figure 4.20, where the highlighted line represents the solution path from S to G.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F20_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.20 Solution using a beam width of <span class="times"><i class="fm-italics">w</i> = 2</span>. The highlighted line represents the solution path.</p>
  </div>

  <p class="body">As you will see in a later section, when applying beam search to a real-life routing problem, generating the children in a beam search can become very complicated and time consuming.<a id="idIndexMarker042"/><a id="idIndexMarker043"/><a id="idIndexMarker044"/></p>

  <h3 class="fm-head1" id="heading_id_8">4.3.3 A* search algorithm</h3>

  <p class="body"><a id="marker-124"/>The <i class="fm-italics">A*</i> (pronounced A-star) algorithm is an informed search algorithm widely used in pathfinding and graph traversal. This algorithm is a special case of the best-first algorithm. Best-first search is a kind of mixed depth- and breadth-first search that expands the most desirable unexpanded node based on either the cost to reach the node or an estimate or heuristic value of the cost to reach the goal from that node. The A* algorithm takes into account both the cost to reach the node and the estimated cost to reach the goal in order to find the optimal solution.<a id="idIndexMarker045"/><a id="idIndexMarker046"/><a id="idIndexMarker047"/></p>

  <p class="body">The pseudocode for A* is shown in algorithm 4.4.</p>

  <p class="fm-code-listing-caption">Algorithm 4.4 A* algorithm</p>
  <pre class="programlisting">Inputs: Source node, Destination node
Output: Route from source to destination
  
Initialize A* heuristic <span class="cambria">←</span> sum of straight-line distance to source and destination
Initialize PQ <span class="cambria">←</span> min heap according to A* heuristic
Initialize frontier <span class="cambria">←</span> a PQ initialized with source
Initialize explored <span class="cambria">←</span> empty
Initialize found <span class="cambria">←</span> False
  
While frontier is not empty and found is False do
    Set node <span class="cambria">←</span> frontier.pop()
    Add node to explored
    For child in node.expand() do
        If child is not in explored and child is not in frontier then
            If child is destination then
                Update route <span class="cambria">←</span> child.route()
                Update found <span class="cambria">←</span> True
            Add child to frontier
  
Return route</pre>

  <p class="body">A* search tries to reduce the total number of states explored by incorporating both the actual cost and a heuristic estimate of the cost to get to the goal from a given state. The driving force behind A* is the selection of a new vertex (or node) to explore based on the lowest value. The value of the evaluation function <span class="times"><i class="fm-italics">f</i>(<i class="fm-italics">n</i>)</span> is computed using the following formula:</p>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <p class="fm-equation"><i class="fm-italics">f</i>(<i class="fm-italics">n</i>) = <span class="times"><i class="fm-italics">g</i>(<i class="fm-italics">n</i>)</span> + <i class="fm-italics">h</i>(<i class="fm-italics">n</i>)</p>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">4.1</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">In equation 4.1, <span class="times"><i class="fm-italics">g</i>(<i class="fm-italics">n</i>)</span> is the actual cost of the partial path already traveled from the source node S to node <i class="timesitalic">n</i>. The heuristic information <span class="times"><i class="fm-italics">h</i>(<i class="fm-italics">n</i>)</span> can be the straight-line distance between node <i class="timesitalic">n</i> and destination node G, or some other function. When <span class="times"><i class="fm-italics">h</i>(<i class="fm-italics">n</i>) = 0</span> for all nodes, A* will behave like a uniform-cost search (UCS), which was explained in section 3.4.2, so the node with the lowest cost will be expanded regardless of the estimated cost to reach the goal.</p>

  <p class="body"><a id="marker-125"/>In <i class="fm-italics">weighted A*</i>, a constant weight is added to the heuristic function as follows:</p>

  <table border="0" class="contenttable-0-table" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="90%"/>
      <col class="contenttable-0-col" span="1" width="10%"/>
    </colgroup>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-0-td">
          <p class="fm-equation"><i class="fm-italics">f</i>(<i class="fm-italics">n</i>) = <span class="times"><i class="fm-italics">g</i>(<i class="fm-italics">n</i>)</span> + <i class="fm-italics">w</i> × <i class="fm-italics">h</i>(<i class="fm-italics">n</i>)</p>
        </td>

        <td class="contenttable-0-td">
          <p class="fm-equation-caption">4.2</p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="body">To increase the importance of <span class="times"><i class="fm-italics">h</i>(<i class="fm-italics">n</i>)</span>, <i class="timesitalic">w</i> should be greater than 1. A dynamic weight <span class="times"><i class="fm-italics">w</i>(<i class="fm-italics">n</i>)</span> can be also used. The choice of the heuristic information is critical to the search results. The heuristic information <span class="times"><i class="fm-italics">h</i>(<i class="fm-italics">n</i>)</span> is admissible if and only if <span class="times"><i class="fm-italics">h</i>(<i class="fm-italics">n</i>)</span> is less than the actual cost to reach the goal state from <i class="timesitalic">n</i> for every node <i class="timesitalic">n</i> . This means that admissible heuristics never overestimate the cost to reach the goal and can lead to optimal solutions only when the heuristic function is close to the true remaining distance.</p>

  <p class="body">The A* heuristic algorithm operates by choosing the next vertex for exploration in a <i class="fm-italics">greedy</i> manner, prioritizing nodes based on the value of the heuristic function. As the sum of the distance to the origin and destination is minimized when <i class="timesitalic">n</i> lies on a straight line from S to G, this heuristic prioritizes nodes that are closer to the straight-line distance from origin to destination.</p>

  <p class="body">To better understand the A* procedure, let’s consider the simple problem of finding the shortest path between a source node S and a goal node G in an 8 points of interest (POIs) road network. This is the same POI graph from figure 4.14 but with heuristic values added for each node. An example of heuristic information is the straight-line distance to the goal as shown above each vertex in figure 4.21.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F21_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.21 An 8 POIs road network in the form of a graph with heuristic information (straight-line distance to the goal) shown above each vertex</p>
  </div>

  <p class="body"><a id="marker-126"/>Figure 4.22 shows the steps for using A* to find the shortest path from S to G.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F22_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.22 The A* steps to find the shortest path between the source node S and goal node G in an 8 POIs road network. The sum of the already incurred costs and the distance to the goal is used as the heuristic value to determine whether to expand a certain node.</p>
  </div>

  <p class="body">This algorithm may look complex since it seems to need to store incomplete paths and their lengths at various places. However, using a recursive best-first search implementation can solve this problem in an elegant way without the need for explicit path storing. The quality of the lower-bound goal distance from each node greatly influences the timing complexity of the algorithm. The closer the given lower bound is to the true distance, the shorter the execution time.</p>

  <p class="body">We can apply the A* algorithm to the simple routing problem as follows (see the book’s GitHub repo for the full code, containing graph initialization and visualization).</p>

  <p class="fm-code-listing-caption">Listing 4.5 Simple routing using A* search</p>
  <pre class="programlisting">import matplotlib.pyplot as plt
from optalgotools.structures import Node
from optalgotools.routing import cost
import networkx as nx
import heapq
  
def A_Star(
    G, origin, destination, heuristic_fn, cost_fn, cost_kwargs=[],
    <span class="fm-code-continuation-arrow">➥</span> expand_kwargs=[]
):
    toDestination = heuristic_fn(G, origin, destination)
    toOrigin = {}
    route = []
    frontier = list()
    frontier.append(origin)
    toOrigin[origin] = 0
    explored = set()
    found = False
    while frontier and not found:
        node = min(frontier, key=lambda node: toOrigin[node] +
        <span class="fm-code-continuation-arrow">➥</span> toDestination[node])                                           <span class="fm-combinumeral">①</span>
        frontier.remove(node)
        explored.add(node)
        for child in node.expand(**expand_kwargs):                        <span class="fm-combinumeral">②</span>
            if child not in explored and child not in frontier:           <span class="fm-combinumeral">②</span>
                if child == destination:                                  <span class="fm-combinumeral">②</span>
                    route = child.path()                                  <span class="fm-combinumeral">②</span>
                    found = True                                          <span class="fm-combinumeral">②</span>
                    continue                                              <span class="fm-combinumeral">②</span>
                frontier.append(child)                                    <span class="fm-combinumeral">②</span>
                toOrigin[child] = cost_fn(G, child.path(), **cost_kwargs) <span class="fm-combinumeral">③</span>
    return route</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Choose a node based on its heuristic value</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Expand the node’s children, adding them to the frontier or terminating if the destination is found.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Add the toOrigin value for each node on the fly</p>

  <p class="body"><a id="marker-127"/>The implementation of A* in listing 4.5 doesn’t use a “real” A* heuristic algorithm for two reasons:</p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">The straight line or haversine distance from any node to the destination cannot be readily determined, as we only have edge weights and no real spatial data (coordinates) to situate each node. To get around this, I created a function called <code class="fm-code-in-text">dummy_astar_heuristic</code> that returns static, arbitrarily generated distances for the purposes of this example.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">The distance from the origin to any node (straight line or otherwise) cannot be determined ahead of time for the same reasons as in the previous point. Thus, we use the traveled distance (i.e., the cost from the origin to the node as far as has been explored), and we update that value as the algorithm discovers new nodes. Later in this chapter, we will see how working with geographic data (such as road networks) allows us to capture this information beforehand.</p>
    </li>
  </ul>

  <p class="body"><code class="fm-code-in-text">A_Star</code> can be called as follows, with some example parameters:</p>
  <pre class="programlisting">result = A_Star(
    G,
    Node(G, "S"),
    Node(G, "G"),
    dummy_astar_heuristic,
    cost,
    expand_kwargs={"attr_name": "weight"},
    cost_kwargs={"attr_name": "weight"},)</pre>

  <p class="body">This gives us the same result as with beam search and hill climbing: a path of S-A-C-E-G.</p>

  <div class="fm-sidebar-block">
    <p class="fm-sidebar-title">Haversine distance</p>

    <p class="fm-sidebar-text">The haversine formula is used to calculate the geographic distance between two points on earth, given their longitudes and latitudes, based on a mean spherical earth radius. This distance is also known as the great-circle distance and is calculated using the following formula:<a id="marker-128"/></p>

    <p class="fm-sidebar-text">      <span class="times"><i class="fm-italics">d</i> = <i class="fm-italics">R</i> × <i class="fm-italics">C</i> and <i class="fm-italics">C</i> = 2 × atan2(√<i class="fm-italics">a</i>, √(1-<i class="fm-italics">a</i>))</span>        <b class="bluebold">4.3</b></p><!--<p class="Equation"><img src="04-web-resources/image/khamis-ch4-eqs-2x.png" alt="" /><span class="Eq-capt">4.3</span></p>-->

    <p class="fm-sidebar-text">In the preceding equation, <span class="times"><i class="fm-italics">a</i> = sin<sup class="fm-superscript">2</sup>(∆<i class="fm-italics">lat</i>/2) + cos(<i class="fm-italics">lat1</i>) × cos(<i class="fm-italics">lat2</i>) × sin<sup class="fm-superscript">2</sup>(∆<i class="fm-italics">lon</i>/2)</span>, <i class="timesitalic">R</i> is the earth radius (6,371 km or 3,691 miles), and <i class="timesitalic">d</i> is the final distance between the two points. The following figure shows the haversine distance between Los Angeles, USA <span class="times">(34.0522° N, 118.2437° W)</span> and Madrid, Spain <span class="times">(40.4168° N, 3.7038° W)</span>.</p>

    <p class="sidebarafigures"><img alt="" class="calibre2" src="../Images/CH04_F22_UN01_Khamis.png"/></p>

    <p class="sidebaracaptions">Haversine distance between Los Angeles and Madrid</p>

    <p class="fm-sidebar-text">The following Python code can be used to calculate the haversine distance:</p>
    <pre class="programlisting">!pip install haversine                     <span class="fm-combinumeral">①</span>
from haversine import haversine            <span class="fm-combinumeral">①</span>
  
  
LA = (34.052235, -118.243683)              <span class="fm-combinumeral">②</span>
  
  
Madrid = (40.416775, -3.703790)            <span class="fm-combinumeral">③</span>
  
  
distance = haversine(LA, Madrid)           <span class="fm-combinumeral">④</span>
print(distance)</pre>

    <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Install the Haversine package, and import the haversine function.</p>

    <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Set coordinates of two points in (latitude, longitude) format.</p>

    <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Set coordinates of two points in (latitude, longitude) format.</p>

    <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Calculate the distance in kilometers.</p>
  </div>

  <p class="body">The implementation of the A* heuristic in optalgotools defaults to calculating distances as if the earth were flat. For local searches, this yields the best results. If the size of the search area is larger, it is better to calculate distance by passing <code class="fm-code-in-text">optalgotools.utilities.haversine_distance</code> into the <code class="fm-code-in-text">measuring_dist</code> parameter, which considers the curvature of the earth.</p>

  <h3 class="fm-head1" id="heading_id_9">4.3.4 Hierarchical approaches</h3>

  <p class="body">When facing routing problems at larger scales, such as those involving entire countries or graphs with millions of nodes, it is simply implausible to use basic approaches like Dijkstra's. In the previous chapter, you saw that bidirectional Dijkstra's gives a two times speedup compared to Dijkstra’s algorithm. However, much faster routing algorithms are needed for interactive applications like navigation apps. One way to achieve this is to precompute certain routes and cache them on servers so that response times to user queries are reasonable. Another method involves pruning the search space. Hierarchical search algorithms prune the search space by generating admissible heuristics that abstract the search space.<a id="marker-129"/></p>

  <p class="fm-callout"><span class="fm-callout-head">Note</span> For more details about the general approaches of hierarchical methods, see Leighton, Wheeler, and Holte, “Faster optimal and suboptimal hierarchical search” [1].</p>

  <p class="body">Highway hierarchies involve the assignment of hierarchy “levels” to each road in a road network graph. This distinguishes the type of road segment (e.g., residential roads, national roads, highways). This is further supplemented by relevant data such as the maximum designated driving speed as well as the number of turns in the road. After the heuristics are generated for the graph, the data is passed through a modified search function (bidirectional Dijkstra's, A*, etc.) that considers the distance to the destination and the potential expansion node type. Highway hierarchy algorithms will generally consider highways as viable expansion nodes when they are further away from the target and will start to include national roads, and finally residential streets, as they near the destination. During the trip, less important roads merge with more important roads (e.g., residential roads merge with national roads, and national roads merge with highways). This allows us to avoid exploring millions of nodes.</p>

  <p class="body">Take, for example, a long-distance driving trip from New York to Miami. In the beginning, you will need to navigate local roads toward a highway or interstate. In the middle section of the trip, you will drive exclusively on the interstate or highway. Nearing your destination, you will leave the interstate and once again take local roads. While this approach makes sense, there are some disadvantages. First, the algorithm overlooks what kind of roads humans prefer to drive on. While a highway might make sense for a given route, the user may prefer to take local roads (such as when driving to a friend’s house who lives nearby). Second, highway hierarchies do not consider factors such as traffic, which fluctuates often and adds significant cost to an “optimal” route. You can learn more about highway hierarchies in Sanders and Schultes’ article “Highway hierarchies hasten exact shortest path queries” [2].</p>

  <p class="body"><a id="marker-130"/>The contraction hierarchies (CH) algorithm is another hierarchical approach. It is a speed-up technique that improves the performance of shortest-path computations by pruning the search space based on the concept of node contraction. For example, for an 80 mile single-source single-destination shortest path search query, the bidirectional Dijkstra's algorithm explores 220,000 nodes, unidirectional A* explores 50,000 nodes, and bidirectional A* improves on those by exploring about 25,000 nodes. Contraction hierarchies solve the same problem by exploring only about 600 nodes. This makes CH much faster than Dijkstra's, bidirectional Dijkstra's, and A*.</p>

  <p class="fm-callout"><span class="fm-callout-head">Note</span> Contraction hierarchies were introduced in Geisberger et al.’s 2008 “Contraction hierarchies: Faster and simpler hierarchical routing in road networks” article [3]. The 80 mile single-source single-destination shortest path search query is discussed on the <i class="fm-italics">GraphHopper</i> blog (<a class="url" href="http://mng.bz/n142">http://mng.bz/n142</a>).</p>

  <p class="body">The CH algorithm encompasses two main phases:</p>

  <ol class="calibre7">
    <li class="fm-list-bullet">
      <p class="list">The <i class="fm-italics">preprocessing phase</i> is where nodes and edges are categorized based on some notion of importance. Important nodes can be major cities, major intersections, bridges connecting the two sides of a city, or points of interest that shortest paths go through. Each node is contracted based on the level of importance from least important to most important. During the contraction process, a set of shortcut edges is added to the graph to preserve shortest paths.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">The <i class="fm-italics">query phase</i> is where a bidirectional Dijkstra's search (or any other search) is run on the preprocessed graph, considering only increasingly important edges. This results in selectively ignoring less important nodes, and overall improving querying speed.<a id="idIndexMarker048"/></p>
    </li>
  </ol>

  <p class="body">It’s worth noting that the CH algorithm is mainly a preprocessing algorithm, which means that it is used before querying the shortest path. This preprocessing phase takes some time, but once it’s done, the query phase is very fast. The algorithm can handle large graphs and can be used for various types of graphs, not only road networks. Let’s dive into both phases in further detail.<a id="idIndexMarker049"/></p>

  <p class="fm-head2">The CH preprocessing phase</p>

  <p class="body">The preprocessing phase takes as input the original graph, and it returns an augmented graph and node order to be used during the query phase.<a id="idIndexMarker050"/><a id="idIndexMarker051"/></p>

  <p class="body"><a id="marker-131"/>Assume a weighted directed graph <span class="times"><i class="fm-italics">G</i> = (<i class="fm-italics">V</i>,<i class="fm-italics">E</i>)</span>. The nodes of this graph are ordered based on node importance. In the case of road networks, node importance can be based on road type: residential roads, national roads, and motorways or highways. The basic intuition here is that closer to the source or target, we usually consider residential roads; far away from the source or target, national roads are considered; and even further away from the source or the target, it makes sense to consider highways. Some other heuristics that affect the node importance include the maximum speed, toll rates, the number of turns, etc.</p>

  <p class="body">Once the node order is determined, the vertex set or nodes are ordered by importance: <span class="times"><i class="fm-italics">V</i> = {1,2,3…,<i class="fm-italics">n</i>}</span>. Nodes are contracted or removed in this order using the following procedure:</p>
  <pre class="programlisting">for each pair (u,v)and (v,w)of edges:
   if &lt;u,v,w&gt; is a unique shortest path then
      add shortcut(u,w) with weight <span class="cambria">ω</span>(&lt;u,v,w&gt;)or <span class="cambria">ω</span>(&lt;u,w&gt;)+<span class="cambria">ω</span>(&lt;v,w&gt;)</pre>

  <p class="body">As illustrated in figure 4.23, node <i class="timesitalic">v</i> can be contracted from graph <i class="timesitalic">G</i>. If necessary, a shortcut or edge with a cost of 5 should be added to ensure that the shortest distance between <i class="timesitalic">u</i> and <i class="timesitalic">w</i> is preserved or remains the same, even after <i class="timesitalic">v</i> has been contracted. Contracting a node <i class="timesitalic">v</i> means replacing the shortest paths going through <i class="timesitalic">v</i> with shortcuts. The new graph is called an <i class="fm-italics">overlay graph</i> or an <i class="fm-italics">augmented graph</i> (i.e., a graph with an augmented set of edges). This graph contains the same set of vertices as the initial graph and all the edges, plus all the added edges (shortcuts) used to preserve shortest distances in the original graph.<a id="idIndexMarker052"/><a id="idIndexMarker053"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F23_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.23 Node contraction operation—the number in brackets denotes the cost of the added shortcut.</p>
  </div>

  <p class="body"><a id="marker-132"/>When contracting node <i class="timesitalic">v</i>, no shortcut is needed if there is a path <i class="timesitalic">P</i> between <i class="timesitalic">u</i> and <i class="timesitalic">w</i> with <span class="times"><i class="fm-italics">w</i>(<i class="fm-italics">P</i>) &lt;= <i class="fm-italics">w</i>(&lt;<i class="fm-italics">u</i>,<i class="fm-italics">v</i>,<i class="fm-italics">w</i>&gt;)</span>. This path is called a <i class="fm-italics">witness path</i>, as shown in figure 4.24.<a id="idIndexMarker054"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F24_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.24 Witness path—there is another path from <i class="timesitalic">P</i> to <i class="timesitalic">w</i> that is shorter, so no shortcut is needed when contracting <i class="timesitalic">v</i>.</p>
  </div>

  <p class="body">During the CH preprocessing phase, since the nodes are ordered based on importance, a node can be iteratively contracted, and an additional shortcut arc can be added to preserve short distances and to form an augmented graph. We end up with a contraction hierarchy, with one overlay graph for each individual node. This preprocessing is done offline, and the augmented graph is used later during the query phase.</p>

  <p class="body">Let’s consider a simple graph with four nodes. Figure 4.25 shows the steps of the contraction process. We will contract each node following the order of importance from the least to the most important node (i.e., following the importance or hierarchy level from 1 to <i class="timesitalic">n</i>). This process will form shortcuts, which will allow us to search the graph much faster, as we can ignore nodes that have been pruned. The initial graph is shown in figure 4.25a:</p>

  <ol class="calibre7">
    <li class="fm-list-bullet">
      <p class="list">By contracting the least important node, node 1, nothing happens, as the shortest path between the neighboring nodes 2 and 4 does not pass by node 1 (figure 4.25b).</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Moving forward and contracting the next most important node, node 2, we have now changed the shortest path for 1<span class="cambria">→</span>3, 1<span class="cambria">→</span>4, and 3<span class="cambria">→</span>4. We can encode these shortest paths by creating new edges (shortcuts). The numbers in brackets denote the costs of the added shortcuts (figure 4.25c).</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Contracting node 3 does not cause any change, as there is a shorter path between nodes 2 and 4 that does not pass by node 3 (figure 4.25d).</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">We do not need to contract node 4, as it is the last node in the graph (figure 4.25e).</p>
    </li>
  </ol>

  <p class="body">The generated overlay graph after the contraction process is shown in figure 4.25f. The nodes are ordered based on importance.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F25_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.25 An example of the CH preprocessing phase</p>
  </div>

  <p class="body">The order of contraction does not affect the success of CH, but it will affect the preprocessing and query time. Some contraction ordering systems minimize the number of shortcuts added in the augmented graph and thus the overall running time.</p>

  <p class="body"><a id="marker-133"/>To begin, we need to use some notion of importance and keep all the nodes in a priority queue by decreasing importance. Edge difference, lazy updates, the number of contracted neighbors, and shortcut cover (all explained shortly) are examples of importance criteria. The <i class="fm-italics">importance</i> of each node in the graph is its <i class="fm-italics">priority</i>. This metric guides the order in which nodes are contracted. This <i class="fm-italics">priority</i> term is dynamic and is continuously updated as nodes are contracted. The typical importance criteria include<a id="idIndexMarker055"/></p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Lazy updates</i>—The priority of the node on top of the priority queue (i.e., the node with the smallest priority) is updated before it is removed. If this node is still on top after the update, it will be contracted. Otherwise, the new topmost node will be processed in the same way.<a id="idIndexMarker056"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Edge difference</i> (ED)—The ED of a node is the number of edges that need to be added versus the number of edges to be removed. We want to minimize the number of edges added to the augmented graph. For a node <i class="timesitalic">v</i> in a graph, assume that<a id="idIndexMarker057"/></p>

      <ul class="calibre9">
        <li class="fm-list-bullet">
          <p class="list"><span class="times">in(<i class="fm-italics">v</i>)</span> is the incoming degree (i.e., the number of edges coming into a node)</p>
        </li>

        <li class="fm-list-bullet">
          <p class="list"><span class="times">out(<i class="fm-italics">v</i>)</span> is the outgoing degree (i.e., the number of outgoing edges emanating from a node)</p>
        </li>

        <li class="fm-list-bullet">
          <p class="list"><span class="times">deg(<i class="fm-italics">v</i>)</span> is the total degree of the node, which is the sum of its in and out degrees so <span class="times">deg(<i class="fm-italics">v</i>) = in(<i class="fm-italics">v</i>) + out(<i class="fm-italics">v</i>)</span></p>
        </li>

        <li class="fm-list-bullet">
          <p class="list"><span class="times">add(<i class="fm-italics">v</i>)</span> is the number of added shortcuts</p>
        </li>

        <li class="fm-list-bullet">
          <p class="list"><span class="times">ED(<i class="fm-italics">v</i>)</span> is the edge difference after contracting node <i class="timesitalic">v</i>, and it’s given by <span class="times">ED(<i class="fm-italics">v</i>) = add(<i class="fm-italics">v</i>) – deg(<i class="fm-italics">v</i>)</span></p>
        </li>
      </ul>

      <p class="list">The next two figures show how the edge difference is calculated and used to choose between contracting an edge node like <i class="timesitalic">A</i> (figure 4.26) and a hub node like <i class="timesitalic">E</i> (figure 4.27)<a id="marker-134"/></p>
    </li>
  </ul>

  <div class="figure">
    <p class="figuree"><img alt="" class="calibre4" src="../Images/CH04_F26_Khamis.png"/></p>

    <p class="figurecaptione">Figure 4.26 Edge difference in the case of edge node <i class="fm-italics">A</i></p>
  </div>

  <div class="figure">
    <p class="figuree"><img alt="" class="calibre4" src="../Images/CH04_F27_Khamis.png"/></p>

    <p class="figurecaptione">Figure 4.27 Edge difference in case of a hub node. The numbers in brackets denote the cost of the added shortcuts.</p>
  </div>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Number of contracted neighbors</i>—This reflects how nodes are spread across the map. It is better to avoid contracting all nodes in a small region of the graph and to ensure uniformity during the contraction process. We first contract the node with the smallest number of contracted neighbors.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list"><i class="fm-italics">Shortcut cover</i>—This method approximates how unavoidable the node is (e.g., a bridge connecting two parts of a city across a river). It represents the number of neighbors of a node, and thus how many shortcuts we’ll need to create to or from them after contracting the node, because they’re unavoidable nodes. Nodes with a smaller number of shortcut covers are contracted first.</p>
    </li>
  </ul>

  <p class="body"><a id="marker-135"/>The priority of a node estimates the attractiveness of contracting the node and can be a weighted linear combination of the previously described importance criteria, such as edge difference, number of contracted neighbors, and shortcut cover. The least important node is extracted in each iteration. The contraction process may affect the importance of a node, so we need to recompute this node importance. The newly updated importance is then compared with the node on the top of the priority queue (with the lowest importance) to decide whether or not this node needs to be contracted. The node with the smallest updated importance is always contracted.<a id="idIndexMarker058"/><a id="idIndexMarker059"/></p>

  <p class="fm-head2">The CH query phase</p>

  <p class="body">During the CH query phase, we apply bidirectional Dijkstra's to find the shortest path between the source and the target, as follows (figure 4.28): <a id="idIndexMarker060"/><a id="idIndexMarker061"/></p>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">Dijkstra’s algorithm from the source only considers edges <i class="fm-italics">u</i>,<i class="fm-italics">v</i> where level(<i class="fm-italics">u</i>) &gt; level(<i class="fm-italics">v</i>), so you only want to relax nodes with a higher level than the node you have relaxed at that iteration. This is called the <i class="fm-italics">upward graph</i>. In the context of Dijkstra’s algorithm, <i class="fm-italics">relaxing</i> a node refers to the process of updating the estimated distance or cost to reach that node from a source node by considering shorter paths through neighboring nodes. This helps refine the estimate of the shortest path to the node from the source.<a id="idIndexMarker062"/><a id="idIndexMarker063"/></p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Dijkstra’s algorithm from the target only considers edges <i class="fm-italics">u</i>,<i class="fm-italics">v</i> where level(<i class="fm-italics">u</i>) &lt; level(<i class="fm-italics">v</i>), so you only want to relax nodes with a lower level than the node you have relaxed at that iteration. This is called the <i class="fm-italics">downward graph</i>.<a id="idIndexMarker064"/></p>
    </li>
  </ul>

  <div class="figure">
    <p class="figuree"><img alt="" class="calibre4" src="../Images/CH04_F28_Khamis.png"/></p>

    <p class="figurecaptione">Figure 4.28 CH query phase</p>
  </div>

  <p class="fm-head2">A CH example</p>

  <p class="body"><a id="marker-136"/>Consider the following network with an arbitrary node ordering (figure 4.29). The numbers in the circles are the order in which the nodes will be contracted. The numbers on the edges represent the costs. <a id="idIndexMarker065"/><a id="idIndexMarker066"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F29_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.29 A CH example</p>
  </div>

  <p class="body">Let’s run the CH algorithm on this graph to get the shortest path between two nodes in this road network. The following steps show how to apply the CH algorithm:</p>

  <p class="body-dialog">  1.  <i class="fm-italics">Contracting node 1</i>—There’s no need to add a shortcut, as we do not lose a shortest path (figure 4.30).<a id="idIndexMarker067"/></p>

  <div class="figure">
    <p class="figuree"><img alt="" class="calibre4" src="../Images/CH04_F30_Khamis.png"/></p>

    <p class="figurecaptione">Figure 4.30 Graph contraction using an arbitrary node ranking—contracting node 1</p>
  </div>

  <p class="body-dialog">  2.  <i class="fm-italics">Contracting node 2</i>—There’s no need to add a shortcut, as we do not lose a shortest path (figure 4.31).<a id="idIndexMarker068"/><a id="marker-137"/></p>

  <div class="figure">
    <p class="figuree"><img alt="" class="calibre4" src="../Images/CH04_F31_Khamis.png"/></p>

    <p class="figurecaptione">Figure 4.31 Graph contraction using an arbitrary node ranking—contracting node 2</p>
  </div>

  <p class="body-dialog">  3.  <i class="fm-italics">Contracting node 3</i>—A shortcut needs to be added to preserve the shortest path between 8 and 5, as there is no witness path. The cost of the added arc is 7 (figure 4.32).<a id="idIndexMarker069"/></p>

  <div class="figure">
    <p class="figuree"><img alt="" class="calibre4" src="../Images/CH04_F32_Khamis.png"/></p>

    <p class="figurecaptione">Figure 4.32 Graph contraction using an arbitrary node ranking—contracting node 3</p>
  </div>

  <p class="body-dialog">  4.  <i class="fm-italics">Contracting node 4</i>—No shortcuts need to be added (figure 4.33).<a id="idIndexMarker070"/><a id="marker-138"/></p>

  <div class="figure">
    <p class="figuree"><img alt="" class="calibre4" src="../Images/CH04_F33_Khamis.png"/></p>

    <p class="figurecaptione">Figure 4.33 Graph contraction using an arbitrary node ranking—contracting node 4</p>
  </div>

  <p class="body-dialog">  5.  <i class="fm-italics">Contracting node 5</i>—No shortcuts need to be added (figure 4.34).<a id="idIndexMarker071"/></p>

  <div class="figure">
    <p class="figuree"><img alt="" class="calibre4" src="../Images/CH04_F34_Khamis.png"/></p>

    <p class="figurecaptione">Figure 4.34 Graph contraction using an arbitrary node ranking—contracting node 5</p>
  </div>

  <p class="body-dialog">  6.  <i class="fm-italics">Contracting node 6</i>—No shortcuts need to be added, as there is a witness path between 7 and 10, which is 7-11-12-10 (figure 4.35).<a id="idIndexMarker072"/><a id="marker-139"/></p>

  <div class="figure">
    <p class="figuree"><img alt="" class="calibre4" src="../Images/CH04_F35_Khamis.png"/></p>

    <p class="figurecaptione">Figure 4.35 Graph contraction using an arbitrary node ranking—contracting node 6</p>
  </div>

  <p class="body-dialog">  7.  <i class="fm-italics">Contracting node 7</i>—No shortcuts need to be added (figure 4.36).<a id="idIndexMarker073"/></p>

  <div class="figure">
    <p class="figuree"><img alt="" class="calibre4" src="../Images/CH04_F36_Khamis.png"/></p>

    <p class="figurecaptione">Figure 4.36 Graph contraction using an arbitrary node ranking—contracting node 7</p>
  </div>

  <p class="body-dialog">  8.  <i class="fm-italics">Contracting node 8</i>—A shortcut needs to be added to preserve the shortest path between 9 and 12 (figure 4.37).<a id="idIndexMarker074"/><a id="marker-140"/></p>

  <div class="figure">
    <p class="figuree"><img alt="" class="calibre4" src="../Images/CH04_F37_Khamis.png"/></p>

    <p class="figurecaptione">Figure 4.37 Graph contraction using an arbitrary node ranking—contracting node 8</p>
  </div>

  <p class="body-dialog">  9.  <i class="fm-italics">Contracting node 9</i>—No shortcuts need to be added (figure 4.38).<a id="idIndexMarker075"/></p>

  <div class="figure">
    <p class="figuree"><img alt="" class="calibre4" src="../Images/CH04_F38_Khamis.png"/></p>

    <p class="figurecaptione">Figure 4.38 Graph contraction using an arbitrary node ranking—contracting node 9</p>
  </div>

  <p class="body-dialog">10.  <i class="fm-italics">Contracting node 10</i>—No shortcuts need to be added (figure 4.39).<a id="idIndexMarker076"/><a id="marker-141"/></p>

  <div class="figure">
    <p class="figuree"><img alt="" class="calibre4" src="../Images/CH04_F39_Khamis.png"/></p>

    <p class="figurecaptione">Figure 4.39 Graph contraction using an arbitrary node ranking—contracting node 10</p>
  </div>

  <p class="body-dialog">11.  <i class="fm-italics">Contracting node 11</i>—No shortcuts need to be added (figure 4.40).<a id="idIndexMarker077"/><a id="marker-142"/></p>

  <div class="figure">
    <p class="figuree"><img alt="" class="calibre4" src="../Images/CH04_F40_Khamis.png"/></p>

    <p class="figurecaptione">Figure 4.40 Graph contraction using an arbitrary node ranking—contracting node 11</p>
  </div>

  <p class="body-dialog">12.  <i class="fm-italics">Contracting node 12</i>—No shortcuts need to be added (figure 4.41).<a id="idIndexMarker078"/></p>

  <div class="figure">
    <p class="figuree"><img alt="" class="calibre4" src="../Images/CH04_F41_Khamis.png"/></p>

    <p class="figurecaptione">Figure 4.41 Graph contraction using an arbitrary node ranking—contracting node 12</p>
  </div>

  <p class="body">The contracted graph can now be queried using a bidirectional Dijkstra's search. In the following figures, the numbers in brackets denote the cost of the added shortcut.</p>

  <p class="body">The upward graph in figure 4.42 shows the forward Dijkstra's search from the source to the target. The solid lines represent the visited edges, and the bold solid lines represent the shortest path between the source node and the meeting node.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F42_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.42 Solving a road network problem using the CH algorithm—upward graph</p>
  </div>

  <p class="body"><a id="marker-143"/>The downward graph in figure 4.43 shows the backward Dijkstra's search from the target to the source. The solid lines represent the visited edges, and the bold solid lines represent the shortest path between the target node and the meeting node.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F43_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.43 Solving a road network problem using the CH algorithm—downward graph</p>
  </div>

  <p class="body">The minimum is at node 12 (4 + 8 = 12), so node 12 is the meeting point (figure 4.44).</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F44_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.44 Solving a road network problem using the CH algorithm—meeting point</p>
  </div>

  <p class="body"><a id="marker-144"/>The shortest path will be 1-10-12-8-5. However, this path contains a shortcut (5-8). The actual arc (8-3-5) needs to be unpacked according to the shortcut pointer (node 3) stored during the contraction process. The actual shortest path is 1-10-12-8-3-4 with a cost of 12 (figure 4.45).</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F45_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.45 Solving a road network problem using the CH algorithm—shortest path</p>
  </div>

  <p class="body">Listing 4.6 shows the implementation in Python. Note that the code for graph initialization has been omitted here, as it is similar to previous examples, but it can be viewed in the full listing in the book’s GitHub repo. Likewise, the code for graph visualization is also in the full listing. <a id="idIndexMarker079"/><a id="idIndexMarker080"/></p>

  <p class="fm-code-listing-caption">Listing 4.6 Contraction hierarchy with predetermined node order</p>
  <pre class="programlisting">import networkx as nx
  
shortcuts = {}
shortest_paths = dict(nx.all_pairs_dijkstra_path_length(G,
<span class="fm-code-continuation-arrow">➥</span> weight="weight"))
current_G = G.copy()                                                     <span class="fm-combinumeral">①</span>
for node in G.nodes:
    current_G.remove_node(node)                                          <span class="fm-combinumeral">②</span>
    current_shortest_paths = dict(
        nx.all_pairs_dijkstra_path_length(current_G, weight="weight")
    )                                                                    <span class="fm-combinumeral">③</span>
    for u in current_shortest_paths:
        if u == node:
            continue
        SP_contracted = current_shortest_paths[u]
        SP_original = shortest_paths[u]
        for v in SP_contracted:
            if u == v or node == v:
                continue
            if (
                SP_contracted[v] != SP_original[v]
                and G.has_edge(node, u)
                and G.has_edge(node, v)
            ):
                G.add_edge(u, v, weight=SP_original[v],contracted=True)  <span class="fm-combinumeral">④</span>
                shortcuts[(u,v)] = node                                  <span class="fm-combinumeral">④</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Copy the main graph so that the nodes are only removed from the copy, not the main graph.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Contract the node by removing it from the copied graph.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Recalculate the shortest path matrix, now with the node contracted.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Add a shortcut edge to replace the changed shortest path, and keep track of it so  we can uncontract it when querying later.</p>

  <p class="body"><a id="marker-145"/>You will notice that the preceding code creates two shortcut edges for each contraction, one from <i class="timesitalic">P</i> to <i class="timesitalic">v</i>, and one in reverse from <i class="timesitalic">v</i> to <i class="timesitalic">u</i>. As we are using an undirected graph, this duplication has no effect, since the edge <span class="times">(<i class="fm-italics">u, v</i>)</span> is the same as the edge <span class="times">(<i class="fm-italics">v, u</i>)</span>. <a id="idIndexMarker081"/></p>

  <p class="body">Querying the generated graph requires a simple modified bidirectional Dijkstra's search, where neighbor nodes are disqualified for expansion if they are lower in the hierarchy than the current node. For the purposes of this book, we will use <code class="fm-code-in-text">networkx.algorithms.shortest_paths.weighted.bidirectional_dijkstra</code>, with a slight change (only nodes of higher hierarchy than the current node can be explored). As a continuation of listing 4.6, the following code snippet shows the querying process. The full code for the modified algorithm can be found in listing 4.6 in the book’s GitHub repo:</p>
  <pre class="programlisting">sln = bidirectional_dijkstra(G, 1, 5, hierarchy, weight="weight")      <span class="fm-combinumeral">①</span>
  
uncontracted_route = [sln.result[0]]                                   <span class="fm-combinumeral">②</span>
for u, v in zip(sln.result[:-1], sln.result[1:]): ]]                   <span class="fm-combinumeral">②</span>
    if (u, v) in shortcuts: ]]                                         <span class="fm-combinumeral">②</span>
        uncontracted_route.append(shortcuts[(u, v)])                   <span class="fm-combinumeral">②</span>
    uncontracted_route.append(v)                                       <span class="fm-combinumeral">②</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Run bidirectional Dijkstra's using NetworkX.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Unpack any edges that are marked as contracted, and generate the unpacked route.</p>

  <p class="body">The preceding code will generate an unpacked route that can be visualized as in figure 4.46.</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F46_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.46 The solution path after unpacking the contracted edges. The original route returned by bidirectional Dijkstra's passes through the contracted edge (8,5), which is then unpacked into (8,3) and (3,5).</p>
  </div>

  <p class="body">Contraction hierarchies expend a great deal of processing time on the preprocessing phase, but a correctly pruned graph (i.e., where the node contraction order is good) allows for much faster queries. While the small reduction in search space is negligible on a graph with 21 nodes, some graphs can be pruned up to 40%, resulting in significant cost and time savings when querying. In the example from listing 4.6, the search from node 1 to node 5 explores 11 nodes, as compared to the original 16 nodes in a normal bidirectional Dijkstra's. That’s almost a 33% reduction! <a id="idIndexMarker082"/><a id="idIndexMarker083"/><a id="idIndexMarker084"/><a id="idIndexMarker085"/><a id="idIndexMarker086"/><a id="marker-146"/></p>

  <h2 class="fm-head" id="heading_id_10">4.4 Applying informed search to a routing problem</h2>

  <p class="body">Let’s look again at the University of Toronto routing problem introduced in section 3.5. We need to find the shortest path from the King Edward VII Equestrian statue at Queen’s Park to the Bahen Centre for Information Technology. The search space is represented by a road network in which the intersections and points of interest (including the origin and destination) are nodes, and edges are used to represent road segments with weight (e.g., distance, travel time, fuel consumption, number of turns, etc.). Let’s look at how we can find the shortest path using the informed search algorithms discussed in this chapter.<a id="idIndexMarker087"/><a id="idIndexMarker088"/></p>

  <h3 class="fm-head1" id="heading_id_11">4.4.1 Hill climbing for routing</h3>

  <p class="body">Listing 4.7 uses two functions from <code class="fm-code-in-text">optalgotools.routing</code> that generate random and child routes. While the actual HC algorithm is deterministic, the randomized initial route means that different results can be achieved over different runs. To counter this, we’ll use a higher <i class="timesitalic">n</i> value, which allows a broader diversity of children routes, so an optimal (or near optimal) solution will more likely be achieved.<a id="idIndexMarker089"/><a id="idIndexMarker090"/><a id="idIndexMarker091"/></p>

  <p class="fm-code-listing-caption">Listing 4.7 U of T routing using the hill climbing algorithm</p>
  <pre class="programlisting">def Hill_Climbing(G, origin, destination, n=20):
    time_start = process_time()                                        <span class="fm-combinumeral">①</span>
    costs = []                                                         <span class="fm-combinumeral">①</span>
  
    current = randomized_search(G, origin.osmid, destination.osmid)    <span class="fm-combinumeral">②</span>
    costs.append(cost(G, current))
  
    neighbours = list(islice(get_child(G, current), n))                <span class="fm-combinumeral">③</span>
    space_required = getsizeof(neighbours)
    shortest = min(neighbours, key=lambda route: cost(G, route))
  
    while cost(G, shortest) &lt; cost(G, current):
        current = shortest
        neighbours = list(islice(get_child(G, current), n))
        shortest = min(neighbours, key=lambda route: cost(G, route))
        costs.append(cost(G, current))
  
    route = current
    time_end = process_time()
    return Solution(route, time_end - time_start, space_required, costs)</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Track time and costs for comparison.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Generate an initial route randomly.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Get k neighbors (children).</p>

  <p class="body">While the implementation in listing 4.7 is deterministic, the initial route is still randomized. That means it is possible to get different results across runs. Hill climbing will return some decent results, as there are few local optimal points in the route function. However, larger search spaces will naturally have more local maxima and plateaus, and the HC algorithm will get stuck quickly.</p>

  <p class="body">Figure 4.47 shows a final solution of 806.892 m, which happens to be the same as the result generated by Dijkstra’s algorithm in chapter 3 (an optimal solution).</p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F47_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.47 Shortest path solution generated using hill climbing. The solution shown here uses an <i class="timesitalic">n</i> value of 100, which increases the total processing time but returns better and more consistent results.<a id="idIndexMarker092"/><a id="marker-147"/></p>
  </div>

  <h3 class="fm-head1" id="heading_id_12">4.4.2 Beam search for routing</h3>

  <p class="body">A beam search for routing will follow much the same format as the HC search, with the exception that a “beam” of solutions is kept for comparison at each iteration. The full code for listing 4.8, with the graph initialization and visualization, is in the book’s GitHub repo.<a id="idIndexMarker093"/><a id="idIndexMarker094"/><a id="idIndexMarker095"/><a id="marker-148"/></p>

  <p class="fm-code-listing-caption">Listing 4.8 U of T routing using the beam search algorithm</p>
  <pre class="programlisting">def get_beam(G, beam, n=20):
    new_beam = []
    for route in beam:
        neighbours = list(islice(get_child(G, route), n))                  <span class="fm-combinumeral">①</span>
        new_beam.extend(neighbours)
    return new_beam
  
def Beam_Search(G, origin, destination, k=10, n=20):
    start_time = process_time()
    seen = set()                                                           <span class="fm-combinumeral">②</span>
    costs = []                                                             <span class="fm-combinumeral">②</span>
    beam = [randomized_search(G, origin.osmid, destination.osmid) for _ in <span class="fm-combinumeral">②</span>
    <span class="fm-code-continuation-arrow">➥</span>  range(k)]                                                          <span class="fm-combinumeral">②</span>
  
    for route in beam:                                                     <span class="fm-combinumeral">③</span>
        seen.add(tuple(route))
  
    pool = []
    children = get_beam(G, beam, n)
    costs.append([cost(G, r) for r in beam])
    for r in children:
        if tuple(r) in seen:
            continue
        else:
            pool.append(r)
            seen.add(tuple(r))
    pool += beam
    space_required = getsizeof(pool)
    last_beam = None
    while beam != last_beam:                                               <span class="fm-combinumeral">④</span>
        last_beam = beam
        beam = heapq.nsmallest(k, pool, key=lambda r: cost(G, r))
  
        for route in beam:
            seen.add(tuple(route))
  
        pool = []
        children = get_beam(G, beam, n)
        costs.append([cost(G, r) for r in beam])
        for r in children:
            if tuple(r) in seen:
                continue
            else:
                pool.append(r)
                seen.add(tuple(r))
        pool += beam
        space_required = (
            getsizeof(pool) if getsizeof(pool) &gt; space_required else
            <span class="fm-code-continuation-arrow">➥</span> space_required
        )
    route = min(beam, key=lambda r: cost(G, r))                            <span class="fm-combinumeral">⑤</span>
    end_time = process_time()
    return Solution(
        route, end_time - start_time, space_required, np.rot90(costs))     <span class="fm-combinumeral">⑥</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Generate child routes for each route in the beam.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Initialize empty sets to keep track of visited nodes and path costs.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> The seen routes must be converted to a tuple so they are hashable and can be stored in a set.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Keep the k best routes at each iteration until generating new beams no longer finds better solutions.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> The final route is the best route in the last beam.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑥</span> Return the final route, its cost, processing time, and space required.</p>

  <p class="body">Beam searches for routing are particularly costly, as they require multiple child routes to be generated for each beam. Like HC, generating more children results in a broader penetration of the search space, and thus is more likely to return a solution that is closer to or reaches the optimal solution. Figure 4.48 shows a final solution generated by beam search.<a id="idIndexMarker096"/><a id="marker-149"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F48_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.48 Shortest path using a beam search algorithm. This solution was generated using <span class="times"><i class="fm-italics">k</i> = 10</span> and <span class="times"><i class="fm-italics">n</i> = 20</span>, which means that 20 routes were generated for each route in the beam, and the top 10 routes were kept for each new beam. Lower <i class="timesitalic">k</i> and <i class="timesitalic">n</i> values will improve processing time but reduce the likelihood of generating a near-optimal or optimal solution.<a id="idIndexMarker097"/></p>
  </div>

  <h3 class="fm-head1" id="heading_id_13">4.4.3 A* for routing</h3>

  <p class="body">The next listing shows how we can use A* search to find the shortest route between two points of interest.<a id="idIndexMarker098"/><a id="idIndexMarker099"/><a id="idIndexMarker100"/></p>

  <p class="fm-code-listing-caption">Listing 4.9 U of T routing using A*</p>
  <pre class="programlisting">import osmnx
from optalgotools.routing import (cost, draw_route, astar_heuristic)
from optalgotools.structures import Node
from optalgotools.algorithms.graph_search import A_Star
from optalgotools.utilities import haversine_distance
  
reference = (43.661667, -79.395)                                       <span class="fm-combinumeral">①</span>
  
G = osmnx.graph_from_point(reference, dist=300, clean_periphery=True,
<span class="fm-code-continuation-arrow">➥</span> simplify=True)                                                      <span class="fm-combinumeral">②</span>
  
origin = (43.664527, -79.392442)                                       <span class="fm-combinumeral">③</span>
destination = (43.659659, -79.397669)                                  <span class="fm-combinumeral">④</span>
  
origin_id = osmnx.distance.nearest_nodes(G, origin[1], origin[0])      <span class="fm-combinumeral">⑤</span> 
destination_id = osmnx.distance.nearest_nodes(G, destination[1],       <span class="fm-combinumeral">⑤</span>
<span class="fm-code-continuation-arrow">➥</span> destination[0])                                                     <span class="fm-combinumeral">⑤</span>
  
origin = Node(graph=G, osmid=origin_id)                                <span class="fm-combinumeral">⑥</span>
destination = Node(graph=G, osmid=destination_id)                      <span class="fm-combinumeral">⑥</span>
  
  
solution = A_Star(G, origin, destination, astar_heuristic,             <span class="fm-combinumeral">⑦</span>
<span class="fm-code-continuation-arrow">➥</span> heuristic_kwargs={"measuring_dist": haversine_distance})            <span class="fm-combinumeral">⑦</span>
route = solution.result
print(f"Cost: {cost(G,route)} m")                                      <span class="fm-combinumeral">⑧</span>
print(f"Process time: {solution.time} s")                              <span class="fm-combinumeral">⑧</span>
print(f"Space required: {solution.space} bytes")                       <span class="fm-combinumeral">⑧</span>
print(f"Explored nodes: {solution.explored}")                          <span class="fm-combinumeral">⑧</span>
draw_route(G,route) </pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Set up King’s College Cir, Toronto, ON as a reference.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Create a graph.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Set up the King Edward VII equestrian statue as the origin.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Set up the Bahen Centre for Information Technology at U of T as the destination.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> Get the osmid of the nearest nodes to the points</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑥</span> Convert the source and destination nodes to Node.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑦</span> Find the shortest path using A*.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑧</span> Print the cost, processing time, space required, and explored nodes, and draw the final route.</p>

  <p class="body">The optimality of the A* search depends on the heuristic used. In this case, the solution returned is not optimal, but the incredibly high processing speed achieved is more important for most applications. Figure 4.49 shows a final solution generated by A* search.<a id="idIndexMarker101"/><a id="marker-150"/></p>

  <div class="figure">
    <p class="figure1"><img alt="" class="calibre4" src="../Images/CH04_F49_Khamis.png"/></p>

    <p class="figurecaption">Figure 4.49 Shortest path using the A* algorithm. Better heuristic functions that closely approach the actual costs from any node to the goal will return better results.<a id="idIndexMarker102"/></p>
  </div>

  <h3 class="fm-head1" id="heading_id_14">4.4.4 Contraction hierarchies for routing</h3>

  <p class="body">In order to run CH on the road network graph, we first need to rank the nodes by importance and then contract the graph. For this example, we are selecting edge difference (ED) as our measure of node importance.<a id="idIndexMarker103"/><a id="idIndexMarker104"/><a id="idIndexMarker105"/><a id="idIndexMarker106"/><a id="marker-151"/></p>

  <p class="fm-code-listing-caption">Listing 4.10 U of T routing using CH<a id="idIndexMarker107"/></p>
  <pre class="programlisting">def edge_differences(G, sp):
    ed = {}
    degrees = dict(G.degree)
    for node in G.nodes:
        req_edges = 0
        neighbours = list(G.neighbors(node))
  
        if len(neighbours)==0: ed[node] = - degrees[node]     <span class="fm-combinumeral">①</span>
  
        for u, v in G.in_edges(node):
            for v, w in G.out_edges(node):
                if u == w: continue                           <span class="fm-combinumeral">②</span>
                if v in sp[u][w]:
                    req_edges += 1
        
        ed[node] = req_edges - degrees[node]                  <span class="fm-combinumeral">③</span>
  
    return dict(sorted(ed.items(), key=lambda x: x, reverse=True))</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Some nodes are essentially dead ends, where they have no outbound edges. These nodes have an ED equal to their degree.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> We can ignore two-way edges—an inbound edge and an outbound edge that originate and terminate at the same node.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> The edge difference is the difference between edges that need to be added to the graph and the degree of the node.</p>

  <p class="body">Contracting the graph is as simple as adding an edge for every shortest path that gets altered by the contraction. The full code for graph contraction can be found in the book’s GitHub repo. Contracted edges are marked with an attribute called <i class="fm-italics">midpoint</i>, which stores the ID of the node that was contracted. Following a modified bidirectional Dijkstra's similar to that used in listing 4.6, the final route can be easily unpacked using the following snippet of code:<a id="idIndexMarker108"/></p>
  <pre class="programlisting">def unpack(G, u,v):
    u = int(u)
    v = int(v)
    if "midpoint" in G[u][v][0]:
        midpoint = G[u][v][0]["midpoint"]
        return unpack(G,u,midpoint) + unpack(G,midpoint, v)     <span class="fm-combinumeral">①</span>
    return [u]
  
route = []
for u,v in zip(solution.result[:-1], solution.result[1:]):      <span class="fm-combinumeral">②</span>
    route.extend(unpack(G,u,v))
route += [solution.result[-1]]
print(route)</pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> For every midpoint unpacked, recursively unpack the resulting two edges, as some contracted edges may contain other contracted edges.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Unpack every node pair in the contracted route.</p>

  <p class="body">The GitHub repo also contains the full Python implementation of CH for routing. The route generated is identical to that shown by a normal bidirectional Dijkstra's algorithm (such as in chapter 3). If you will recall, running the normal bidirectional Dijkstra's in chapter 3 yielded a result where 282 nodes were explored during the search. For our CH result, only 164 nodes were explored, which means more than a 40% reduction of search space! Thus, while the optimality of the algorithm remains unchanged, contraction hierarchies allow for much bigger spaces to be searched in a reasonable amount of time.</p>

  <p class="body">Table 4.1 compares the search algorithms discussed in this chapter when applied to the U of T routing problem. A similar table can be found in chapter 3 for blind search algorithms. <a id="idIndexMarker109"/><a id="marker-152"/></p>

  <p class="fm-table-caption">Table 4.1 Comparing informed search algorithms in terms of time and space complexities, where <i class="timesitalic">b</i> is the branching factor, <i class="timesitalic">w</i> is the beam width, <i class="timesitalic">d</i> is the shallowest graph depth, <i class="timesitalic">E</i> is the number of edges, and <i class="timesitalic">V</i> is the number of vertices</p>

  <table border="1" class="contenttable-1-table" id="table001" width="100%">
    <colgroup class="contenttable-0-colgroup">
      <col class="contenttable-0-col" span="1" width="22%"/>
      <col class="contenttable-0-col" span="1" width="11.5%"/>
      <col class="contenttable-0-col" span="1" width="11.5%"/>
      <col class="contenttable-0-col" span="1" width="11.5%"/>
      <col class="contenttable-0-col" span="1" width="16%"/>
      <col class="contenttable-0-col" span="1" width="16%"/>
      <col class="contenttable-0-col" span="1" width="11.5%"/>
    </colgroup>

    <thead class="calibre6">
      <tr class="contenttable-0-tr">
        <th class="contenttable-1-th">
          <p class="fm-table-head">Algorithm</p>
        </th>

        <th class="contenttable-1-th">
          <p class="fm-table-head">Cost (meters)</p>
        </th>

        <th class="contenttable-1-th">
          <p class="fm-table-head">Time (s)</p>
        </th>

        <th class="contenttable-1-th">
          <p class="fm-table-head">Space (bytes)</p>
        </th>

        <th class="contenttable-1-th">
          <p class="fm-table-head">Explored</p>
        </th>

        <th class="contenttable-1-th">
          <p class="fm-table-head">Time complexity</p>
        </th>

        <th class="contenttable-1-th">
          <p class="fm-table-head">Space complexity</p>
        </th>
      </tr>
    </thead>

    <tbody class="calibre6">
      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Hill climbing</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">806.892</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">21.546</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">976</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">400 nodes</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body"><span class="times"><i class="fm-italics">O</i>(∞)</span></p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body"><span class="times"><i class="fm-italics">O</i>(<i class="fm-italics">b</i>)</span></p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">Beam search</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">825.929</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">44.797</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">1,664</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">800 nodes</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body"><span class="times"><i class="fm-italics">O</i>(<i class="fm-italics">wd</i>)</span></p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body"><span class="times"><i class="fm-italics">O</i>(wb)</span></p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">A* search</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">846.92</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">0.063</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">8,408</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">80 nodes</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body"><span class="times"><i class="fm-italics">O</i>(<i class="fm-italics">b<sup class="fm-superscript">d</sup></i>)</span></p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body"><span class="times"><i class="fm-italics">O</i>(<i class="fm-italics">b<sup class="fm-superscript">d</sup></i>)</span></p>
        </td>
      </tr>

      <tr class="contenttable-0-tr">
        <td class="contenttable-1-td">
          <p class="fm-table-body">CH with bidirectional Dijkstra's</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">806.892</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">0.0469</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">72</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body">164 nodes</p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body"><span class="times"><i class="fm-italics">O</i>(<i class="fm-italics">E</i> + <i class="fm-italics">V</i>log<i class="fm-italics">V</i>)</span></p>
        </td>

        <td class="contenttable-1-td">
          <p class="fm-table-body"><span class="times"><i class="fm-italics">O</i>(<i class="fm-italics">b<sup class="fm-superscript">d</sup></i>/2)</span></p>
        </td>
      </tr>
    </tbody>
  </table>

  <p class="fm-callout"><span class="fm-callout-head">Note</span> The time listed for CH with bidirectional Dijkstra's is only for querying. Remember that the preprocessing step is usually quite costly. In this case, contracting the road network of 404 nodes took around 24.03125 seconds.</p>

  <p class="body">While hill climbing and beam search produced respectable results, they were too costly in terms of time to be useful for larger graphs. A* gives the fastest results but a non-optimal heuristic function, and it required excessive space for the heuristic values, so it has its own disadvantages. CH with bidirectional Dijkstra's is the only algorithm in table 4.1 that guarantees optimality, but the costly preprocessing step may not be suitable for all applications.</p>

  <p class="body">When comparing search algorithms, it is important to be aware of the constraints for any given problem and to select an algorithm based on those constraints. For example, certain implementations of hill climbing may result in rapid exit conditions. If the goal is to maximize the number of problems solved (and if local maxima are an acceptable result), HC algorithms result in quick solutions that have some degree of optimality. On the other hand, preprocessing-heavy algorithms like CH offer incredibly low space costs (even more so when implemented with a bidirectional search), as well as rapid searches for guaranteed optimal solutions (if using Dijkstra’s algorithm). For high-volume usage implementations where preprocessing is not a concern (e.g., Uber), contraction hierarchies are a viable choice. In fact, the osrm package used in this book is primarily based on an implementation of contraction hierarchies.</p>

  <p class="body">Pandana, a Python library for network analysis, uses CH to calculate shortest paths and fast travel accessibility metrics. In Pandana, the backend code for CH is in C++ but can be accessed using Python. Pyrosm is another Python library for reading and parsing OpenStreetMap data. It is similar to OSMnx but faster, and it works with Pandana. <a id="idIndexMarker110"/><a id="idIndexMarker111"/></p>

  <p class="body">The next listing is a snippet of code that calculates the shortest distances to an amenity of interest in a selected city using the CH algorithm implemented in Pandana. The complete code is available in the book’s GitHub repo.<a id="idIndexMarker112"/><a id="idIndexMarker113"/><a id="idIndexMarker114"/><a id="idIndexMarker115"/><a id="idIndexMarker116"/><a id="marker-153"/></p>

  <p class="fm-code-listing-caption">Listing 4.11 Using CH to calculate the shortest distances to amenities</p>
  <pre class="programlisting">from pyrosm import OSM, get_data
import numpy as np
import matplotlib.pyplot as plt 
  
osm = OSM(get_data("Toronto"))                                      <span class="fm-combinumeral">①</span>
nodes, edges = osm.get_network(network_type="driving", nodes=True)  <span class="fm-combinumeral">②</span>
  
hospitals = osm.get_pois({"amenity": ["hospital"]})                 <span class="fm-combinumeral">③</span>
  
  
G = osm.to_graph(nodes, edges, graph_type='pandana')                <span class="fm-combinumeral">④</span>
  
hospitals['geometry'] = hospitals.centroid                          <span class="fm-combinumeral">⑤</span>
hospitals = hospitals.dropna(subset=['lon', 'lat'])                 <span class="fm-combinumeral">⑤</span>
  
G.precompute(1000)                                                  <span class="fm-combinumeral">⑥</span>
  
G.set_pois(category='hospitals', maxdist=1000, maxitems=10,         <span class="fm-combinumeral">⑦</span>
<span class="fm-code-continuation-arrow">➥</span> x_col=hospitals.lon, y_col=hospitals.lat)                        <span class="fm-combinumeral">⑦</span>
  
  
nearest_five = G.nearest_pois(1000, "hospitals", num_pois=5)        <span class="fm-combinumeral">⑧</span></pre>

  <p class="fm-code-annotation"><span class="fm-combinumeral">①</span> Get data for the city, region, or country of interest.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">②</span> Get nodes and edges from the road network with a "driving" type.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">③</span> Get points of interest for a certain amenity in the city.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">④</span> Create a network graph.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑤</span> Ensure all hospitals are represented as points.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑥</span> Precompute distances up to 1,000 meters.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑦</span> Attach hospitals to the Pandana graph.</p>

  <p class="fm-code-annotation"><span class="fm-combinumeral">⑧</span> For each node, find the distances to the five closest hospitals up to 1,000 meters away.</p>

  <p class="body">In this example, OpenStreetMap is used to get data on the city of Toronto, and a subset is created to contain data on the city’s hospitals. A Pandana object is then created, and the range queries are precomputed, given a horizon distance (e.g., 1,000 meters) to represent the reachable nodes within this distance. For each node in the network, we can find distances to the five closest hospitals up to 1,000 meters away using the fast CH algorithm implemented in Pandana.</p>

  <p class="body">In the next part of the book, we’ll look at trajectory-based algorithms starting with the simulated annealing algorithm and then the tabu search algorithm. These algorithms improve local search and are less susceptible to getting stuck in local optima than the previously discussed greedy algorithms, which only accept improving moves.</p>

  <h2 class="fm-head" id="heading_id_15">Summary</h2>

  <ul class="calibre5">
    <li class="fm-list-bullet">
      <p class="list">Informed search algorithms use domain-specific knowledge or heuristic information to streamline the search process while striving for optimal solutions or accepting near-optimal ones if necessary.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Informed search algorithms can be used to solve minimum spanning tree (MST) problems and to find the shortest path between two nodes in a graph.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">The Borůvka algorithm, Jarník-Prim algorithm, and Kruskal algorithm are informed search algorithms for solving MST problems. An MST is a tree that contains the least weight among all the other spanning trees of a connected weighted graph. Kruskal’s algorithm is a greedy algorithm that computes the MST for an undirected connected weighted graph by repeatedly adding the next shortest edge that doesn’t produce a cycle.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Hill climbing (HC), beam search, best-first search, the A* algorithm, and contraction hierarchies (CH) are examples of informed search algorithms that can be used to find the shortest path between two nodes.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">The HC algorithm is a local greedy search algorithm that tries to improve on the efficiency of depth-first by incorporating domain-specific knowledge or heuristic information.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Beam search expands the most promising node within a limited predefined set defined by the beam width.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">Best-first search is a greedy algorithm that always expands the node that is closest to the goal node based on heuristic information only.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">The A* algorithm is a special case of a best-first algorithm that incorporates both the actual cost and a heuristic estimate of the cost to get to the goal from a given state.</p>
    </li>

    <li class="fm-list-bullet">
      <p class="list">CH is a speed-up technique for improving the performance of pathfinding. During the preprocessing phase, each node is contracted in order of importance (from least important to most important), and shortcuts are added to preserve the shortest paths. Then the bidirectional Dijkstra’s algorithm is applied to the resultant augmented graph to compute the shortest path between the source node and the target node.<a id="idIndexMarker117"/><a id="marker-154"/></p>
    </li>
  </ul>
</body></html>