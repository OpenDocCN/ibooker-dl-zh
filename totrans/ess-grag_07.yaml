- en: 8 RAG application evaluation
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 8 RAG应用评估
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Benchmarking RAG applications and agent capabilities
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基准测试RAG应用和代理能力
- en: Designing evaluation datasets
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计评估数据集
- en: 'Applying RAGAS metrics: recall, faithfulness, correctness'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用RAGAS度量：召回率、忠实度、正确性
- en: In this chapter, you will explore the importance of evaluating your RAG application
    performance using carefully constructed benchmark questions. As your RAG pipeline
    grows more sophisticated and complex, it becomes essential to ensure that your
    agent’s answers remain both accurate and coherent across a wide range of queries.
    A benchmark evaluation provides the system needed to measure the agent’s capabilities
    while also helping to clearly define and scope the agent.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将探讨使用精心构建的基准问题评估RAG应用性能的重要性。随着您的RAG管道变得更加复杂和高级，确保代理的答案在广泛的查询中既准确又连贯变得至关重要。基准评估提供了衡量代理能力所需的系统，同时也有助于明确定义和界定代理的范围。
- en: Evaluating RAG applications involves multiple approaches, each addressing different
    steps of the application, as shown in figure 8.1, which illustrates a high-level
    overview of a pipeline for a question-answering system powered by an LLM with
    retrieval capabilities. It begins with the user posing a question to the system.
    The LLM then identifies the most suitable retrieval tool to fetch the necessary
    information. This step is critical and can be evaluated for the accuracy of the
    tool selection process.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 评估RAG应用涉及多种方法，每种方法都针对应用的各个步骤，如图8.1所示，它展示了由具有检索能力的LLM驱动的问答系统的管道的高级概述。它从用户向系统提出问题开始。然后LLM确定最合适的检索工具来获取必要的信息。这一步至关重要，可以评估工具选择过程的准确性。
- en: '![figure](../Images/8-1.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-1.png)'
- en: Figure 8.1 Evaluating different steps of a RAG pipeline
  id: totrans-8
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.1 评估RAG管道的不同步骤
- en: 'Throughout this book, you have implemented various retrieval tool designs,
    starting with vector search and progressing to more structured approaches like
    text2cypher and Cypher templates. Each retrieval method serves different needs:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，您已经实现了各种检索工具设计，从向量搜索开始，逐步发展到更结构化的方法，如text2cypher和Cypher模板。每种检索方法都满足不同的需求：
- en: Vector search efficiently retrieves semantically relevant documents.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向量搜索有效地检索语义相关的文档。
- en: Cypher templates allow precise, structured queries to databases.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cypher模板允许对数据库进行精确、结构化的查询。
- en: Text2cypher allows dynamic and flexible querying, benefiting from the expressive
    power of graph-based retrieval.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Text2cypher允许动态和灵活的查询，得益于基于图检索的表达能力。
- en: Evaluating which tool the LLM selects and how well it matches the query’s needs
    is crucial for optimizing retrieval performance.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 评估LLM选择的工具以及它如何与查询需求相匹配对于优化检索性能至关重要。
- en: Once the appropriate tool is chosen, it retrieves relevant context or data from
    a knowledge base. The relevance of this retrieved context to the user’s question
    is another key evaluation point. A well-chosen retrieval method should ensure
    that the fetched context is both accurate and sufficient for answering the query.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦选择了适当的工具，它就会从知识库中检索相关的上下文或数据。检索到的上下文与用户问题的相关性是另一个关键的评估点。一个精心选择的检索方法应确保检索到的上下文既准确又足以回答查询。
- en: Using the retrieved context, the LLM generates an answer, which is then presented
    to the user. At this stage, we can assess not only the coherence and accuracy
    of the generated response but also the model’s ability to understand and integrate
    the provided context effectively. A particularly important evaluation criterion
    is whether the LLM produces the correct answer when given the correct context.
    This allows us to measure the model’s reasoning and synthesis capabilities separately
    from retrieval performance.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 使用检索到的上下文，LLM生成一个答案，然后将其呈现给用户。在这个阶段，我们不仅可以评估生成的响应的连贯性和准确性，还可以评估模型理解和有效整合提供上下文的能力。一个特别重要的评估标准是LLM在给定正确上下文时是否产生正确的答案。这使我们能够将模型的推理和综合能力与检索性能分开来衡量。
- en: Additionally, the entire pipeline can be evaluated holistically to measure its
    effectiveness in providing accurate and contextually relevant answers to user
    queries. By analyzing failures at different stages—tool selection, retrieval relevance,
    and final response generation—we can iteratively improve both the retrieval mechanisms
    and the LLM’s ability to utilize retrieved information.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，可以整体评估整个管道，以衡量其在提供准确和上下文相关答案方面的有效性。通过分析不同阶段的失败——工具选择、检索相关性和最终响应生成——我们可以迭代地改进检索机制以及LLM利用检索信息的能力。
- en: 'Say you are responsible for evaluating the performance of the LLM agent implemented
    in chapter 5\. To gain deeper insight into its effectiveness, you will use the
    RAGAS Python library to design and conduct a benchmark analysis. But first, you
    need to design the benchmark dataset. In the remainder of this chapter, we’ll
    move from concepts to code and walk through the implementation step by step. To
    follow along, you’ll need access to a running Neo4j instance. This can be a local
    installation or a cloud-hosted instance. In the implementation of this chapter,
    we use what we call the “Movies dataset.” See the appendix for more information
    on the dataset and various ways to load it. You can follow the implementation
    directly in the accompanying Jupyter notebook available here: [https://github.com/tomasonjo/kg-rag/blob/main/notebooks/ch08.ipynb](https://github.com/tomasonjo/kg-rag/blob/main/notebooks/ch08.ipynb).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你负责评估第5章中实现的LLM代理的性能。为了更深入地了解其有效性，你将使用RAGAS Python库来设计和执行基准分析。但首先，你需要设计基准数据集。在本章的剩余部分，我们将从概念到代码，逐步介绍实现过程。为了跟上进度，你需要访问一个运行的Neo4j实例。这可以是一个本地安装或云托管实例。在本章的实现中，我们使用所谓的“电影数据集”。有关数据集的更多信息以及各种加载方式，请参阅附录。你可以直接在附带的Jupyter笔记本中跟随实现，笔记本链接如下：[https://github.com/tomasonjo/kg-rag/blob/main/notebooks/ch08.ipynb](https://github.com/tomasonjo/kg-rag/blob/main/notebooks/ch08.ipynb)。
- en: Let’s dive in.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们深入探讨。
- en: 8.1 Designing the benchmark dataset
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.1 设计基准数据集
- en: 'Creating a benchmark dataset requires designing input queries that test various
    aspects of the system’s decision making and response generation. Since each step
    in the RAG pipeline plays a vital role, the dataset should include diverse questions
    that challenge different components:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 创建基准数据集需要设计输入查询，以测试系统决策和响应生成的各个方面。由于RAG管道中的每一步都发挥着至关重要的作用，数据集应包括各种挑战不同组件的多样化问题：
- en: '*Tool selection evaluation* —Ssome queries should evaluate whether the system
    selects the correct retrieval method, ensuring it identifies the most relevant
    source of information.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*工具选择评估* — 一些查询应评估系统是否选择了正确的检索方法，确保它识别出最相关的信息来源。'
- en: '*Entity and value mapping*—Other queries might focus on testing specific tasks,
    such as mapping entities or values from user input to the corresponding entries
    in a database.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*实体和值映射* — 其他查询可能专注于测试特定任务，例如将用户输入中的实体或值映射到数据库中的相应条目。'
- en: '*Multistep retrieval scenarios* —Some agents have the ability to execute multiple
    retrieval steps, where the initially retrieved data serves as input for a second
    retrieval step. The benchmark should include cases where the system needs to refine
    or expand upon the first retrieval to fully answer the query. These cases are
    particularly important for answering complex questions that depend on dynamically
    chaining multiple queries.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*多步检索场景* — 一些代理具有执行多个检索步骤的能力，其中最初检索的数据作为第二个检索步骤的输入。基准测试应包括系统需要细化或扩展第一个检索以完全回答查询的场景。这些场景对于回答依赖于动态链式多个查询的复杂问题尤为重要。'
- en: '*Edge cases and functional coverage* —To fully understand system performance,
    the benchmark must cover all functionalities and known edge cases. This includes
    handling ambiguous queries, long-tail concepts, and scenarios where multiple retrieval
    methods might be applicable.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*边缘情况和功能覆盖* — 要全面理解系统性能，基准测试必须涵盖所有功能以及已知的边缘情况。这包括处理模糊查询、长尾概念以及可能适用多种检索方法的场景。'
- en: '*Conversational usability* —Additionally, it may be useful to evaluate the
    agent’s ability to handle greetings, clarify ambiguous queries, and effectively
    communicate its capabilities to ensure a smooth and user-friendly experience.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*对话可用性* — 此外，评估代理处理问候、澄清模糊查询以及有效地传达其能力以确保流畅且用户友好的体验可能也很有用。'
- en: By systematically benchmarking these aspects, we gain a clearer understanding
    of how well the agent performs under different conditions. This allows for targeted
    improvements, ensuring robustness and reliability in real-world deployments.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 通过系统地基准测试这些方面，我们能够更清楚地了解代理在不同条件下的表现。这允许我们进行有针对性的改进，确保在实际部署中的鲁棒性和可靠性。
- en: 8.1.1 Coming up with test examples
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1.1 设计测试示例
- en: To evaluate the system comprehensively, you need well-defined end-to-end test
    examples. Each example consists of a question and its corresponding ground truth
    response, as shown in figure 8.2, ensuring that the system’s output can be reliably
    assessed.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为了全面评估系统，您需要定义良好的端到端测试示例。每个示例都包含一个问题及其相应的真实响应，如图8.2所示，以确保系统的输出可以可靠地评估。
- en: '![figure](../Images/8-2.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-2.png)'
- en: Figure 8.2 Benchmark test example
  id: totrans-30
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.2 基准测试示例
- en: 'Instead of providing a static string as the expected answer, we can use Cypher
    queries to define the ground truth dynamically. Since we are dealing with a graph
    database, this approach offers a significant advantage: even if the underlying
    data changes, the benchmark remains valid. This ensures that test cases, as shown
    in figure 8.3, remain accurate over time without requiring constant updates.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以不提供静态字符串作为预期的答案，而是使用Cypher查询来动态定义真实响应。由于我们处理的是图数据库，这种方法提供了一个显著的优势：即使底层数据发生变化，基准测试仍然有效。这确保了如图8.3所示的测试用例在时间上保持准确，无需不断更新。
- en: '![figure](../Images/8-3.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![figure](../Images/8-3.png)'
- en: Figure 8.3 Benchmark test example with a Cypher statement as ground truth
  id: totrans-33
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图8.3 以Cypher语句作为真实响应的基准测试示例
- en: When designing a benchmark dataset, you should include diverse examples to evaluate
    different aspects of the agent’s performance. For instance, you can evaluate how
    the agent responds to greetings like “Hello,” provides guidance to the user, or
    handles irrelevant queries, as demonstrated in table 8.1.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在设计基准数据集时，您应包括多样化的示例以评估代理性能的不同方面。例如，您可以评估代理如何对“你好”这样的问候做出响应，如何向用户提供指导，或如何处理无关查询，如表8.1所示。
- en: Table 8.1 Benchmark examples that test simple greetings and irrelevant questions
  id: totrans-35
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表8.1 测试简单问候和无关问题的基准示例
- en: '| Question | Cypher |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | Cypher |'
- en: '| --- | --- |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Hello  | `RETURN “greeting and reminder it can only answer questions related
    to movies.”`  |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| Hello | `RETURN “问候并提醒它只能回答与电影相关的问题。”` |'
- en: '| What can you do?  | `RETURN “answer questions related to movies and their
    cast.”`  |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 你能做什么？ | `RETURN “回答与电影及其演员相关的问题。”` |'
- en: '| What is the weather like in Spain?  | `RETURN “irrelevant question as we
    can answer questions related to movies and their cast only.”`  |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 西班牙的天气怎么样？ | `RETURN “无关问题，因为我们只能回答与电影及其演员相关的问题。”` |'
- en: This table provides examples of how the agent responds to simple greetings,
    user guidance requests, and irrelevant queries. It shows how you can use a simple
    `RETURN` Cypher statement to define static answers that don’t need to look for
    information in the database. For example, when greeted with “Hello,” the agent
    replies with a greeting and a reminder of its scope. If asked what it can do,
    it clarifies that it answers questions about movies and their casts. For unrelated
    queries, like about the weather, the agent simply states that it only handles
    movie-related questions.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 此表提供了代理对简单问候、用户指导请求和无关查询的响应示例。它展示了您如何使用简单的`RETURN` Cypher语句来定义不需要在数据库中查找信息的静态答案。例如，当被问候“你好”时，代理会回复一个问候并提醒其范围。如果被问及它能做什么，它会澄清它回答有关电影及其演员的问题。对于关于天气等无关查询，代理会简单地声明它只处理与电影相关的问题。
- en: Next, we can define a set of questions to evaluate both tool usage and the LLM’s
    ability to generate accurate answers using those tools. The examples are shown
    in table 8.2.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以定义一组问题来评估工具的使用以及LLM使用这些工具生成准确答案的能力。示例如表8.2所示。
- en: Table 8.2 Benchmark examples that test tools usage and value mapping
  id: totrans-43
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表8.2 测试工具使用和价值映射的基准示例
- en: '| Question | Cypher |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | Cypher |'
- en: '| --- | --- |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Who acted in Top Gun?  | `RETURN "MATCH (p:Person)-[:ACTED_IN]→(m:Movie {title:
    "Top Gun"}) RETURN p.name"`  |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| Who acted in Top Gun? | `RETURN "MATCH (p:Person)-[:ACTED_IN]→(m:Movie {title:
    "Top Gun"}) RETURN p.name"` |'
- en: '| Who acted in top gun?  | `RETURN "MATCH (p:Person)-[:ACTED_IN]→(m:Movie {title:
    "Top Gun"}) RETURN p.name"`  |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 谁在《壮志凌云》中出演？ | `RETURN "MATCH (p:Person)-[:ACTED_IN]→(m:Movie {title: "Top
    Gun"}) RETURN p.name"` |'
- en: '| In which movies did Tom Hanks act in?  | `MATCH (p:Person {name: "Tom Hanks"})-[:ACTED_IN]→(m:Movie)
    RETURN m.title`  |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '在哪些电影中汤姆·汉克斯出演过？ | `MATCH (p:Person {name: "Tom Hanks"})-[:ACTED_IN]→(m:Movie)
    RETURN m.title`  |'
- en: '| In which movies did tom Hanks act in?  | `MATCH (p:Person {name: "Tom Hanks"})-[:ACTED_IN]→(m:Movie)
    RETURN m.title`  |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '在哪些电影中汤姆·汉克斯出演过？ | `MATCH (p:Person {name: "Tom Hanks"})-[:ACTED_IN]→(m:Movie)
    RETURN m.title`  |'
- en: 'The examples in table 8.2 demonstrate cases where the LLM needs to retrieve
    relevant data from the database using available tools. Here, the LLM should utilize
    two key tools: one for finding movies by actor and another for finding actors
    by movie, ensuring fast and reliable responses.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 表8.2中的示例展示了LLM需要使用现有工具从数据库中检索相关数据的情况。在这里，LLM应利用两个关键工具：一个用于通过演员查找电影，另一个用于通过电影查找演员，以确保快速和可靠的响应。
- en: Additionally, these examples allow us to evaluate how well the agent maps user
    input to database values. For well-known movies and actors, the LLM often generates
    correct queries out of the box based on its pretraining. However, for lesser-known
    or private datasets, a dedicated mapping system is essential for accurate entity
    resolution. Implementing such a system ensures that user inputs are correctly
    linked to database entries, improving both accuracy and reliability.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，这些示例使我们能够评估代理将用户输入映射到数据库值的效果。对于知名电影和演员，LLM通常能够基于其预训练直接生成正确的查询。然而，对于不太知名或私人数据集，一个专门的映射系统对于准确实体解析至关重要。实施这样一个系统确保用户输入正确地链接到数据库条目，从而提高准确性和可靠性。
- en: You should also include some examples where the LLM will need to use the text2cypher
    tool, as shown in table 8.3.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 您还应包括一些LLM需要使用text2cypher工具的示例，如表8.3所示。
- en: Table 8.3 Benchmark examples that test queries involving aggregations and filtering
  id: totrans-53
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表8.3 测试涉及聚合和过滤的查询的基准示例
- en: '| Question | Cypher |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | Cypher |'
- en: '| --- | --- |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Who acted in the most movies?  | `MATCH (p:Person)-[:ACTED_IN]→(m:Movie)
    RETURN p.name, COUNT(m) AS movieCount ORDER BY movieCount DESC LIMIT 1`  |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 哪位演员出演的电影最多？ | `MATCH (p:Person)-[:ACTED_IN]→(m:Movie) RETURN p.name, COUNT(m)
    AS movieCount ORDER BY movieCount DESC LIMIT 1`  |'
- en: '| List people born before 1940\.  | `MATCH (p:Person) WHERE p.born < 1940 RETURN
    p.name`  |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 列出在1940年之前出生的人。 | `MATCH (p:Person) WHERE p.born < 1940 RETURN p.name`  |'
- en: '| Who was born in 1965 and has directed a movie?  | `MATCH (p:Person)-[:DIRECTED]→(m:Movie)
    WHERE p.born = 1965 RETURN p.name`  |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 1965年出生并执导过电影的有哪些人？ | `MATCH (p:Person)-[:DIRECTED]→(m:Movie) WHERE p.born
    = 1965 RETURN p.name`  |'
- en: Table 8.3 includes queries that involve aggregations, filtering, and relationships,
    such as finding the actor with the most movie roles, listing people born before
    a certain year, and identifying directors born in a specific year. Since no dedicated
    tool is implemented to handle these queries, the LLM must rely on text2cypher
    to construct the appropriate Cypher statements based on the provided graph schema.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 表8.3包括涉及聚合、过滤和关系的查询，例如找到电影角色最多的演员、列出在特定年份之前出生的人，以及识别在特定年份出生的导演。由于没有实现专门的工具来处理这些查询，LLM必须依赖text2cypher根据提供的图模式构建适当的Cypher语句。
- en: You should also test edge cases, such as queries where relevant data is missing
    but still within the domain, as demonstrated in table 8.4.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 您还应该测试边缘情况，例如在表8.4中展示的，相关数据缺失但仍在域内的查询。
- en: Table 8.4 Benchmark examples that test questions where data is missing
  id: totrans-61
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表8.4 测试数据缺失的查询的基准示例
- en: '| Question | Cypher |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 问题 | Cypher |'
- en: '| --- | --- |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Which movie has the most Oscars?  | `RETURN “This information is missing”`  |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| 哪部电影获得了最多的奥斯卡奖？ | `RETURN “This information is missing”`  |'
- en: The benchmark will be very dependent on the functionalities of your agent. The
    specific capabilities, such as retrieval strategies, reasoning methods, and structured
    output handling, will influence the benchmark’s effectiveness in assessing performance.
    When designing a benchmark, it is crucial to ensure comprehensive coverage of
    your agent’s functionalities. By incorporating a variety of examples, you can
    effectively test how well your agent handles different challenges.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试将非常依赖于您代理的功能。具体能力，如检索策略、推理方法和结构化输出处理，将影响基准在评估性能方面的有效性。在设计基准时，确保全面覆盖代理的功能至关重要。通过结合各种示例，您可以有效地测试代理处理不同挑战的能力。
- en: The benchmark has 17 examples in total, with some not shown here. You can now
    evaluate them.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 基准测试总共有17个示例，其中一些未在此展示。您现在可以评估它们。
- en: 8.2 Evaluation
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.2 评估
- en: To assess the performance of your benchmark, you will use RAGAS, a framework
    designed for evaluating RAG systems. As mentioned, the evaluation focuses on three
    key metrics, discussed next.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估你的基准性能，你将使用RAGAS，这是一个为评估RAG系统而设计的框架。如前所述，评估重点在于三个关键指标，接下来将讨论。
- en: 8.2.1 Context recall
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.1 上下文回忆
- en: Context recall measures how many relevant pieces of information were successfully
    retrieved using the prompt in “Context recall evaluation.” A high score indicates
    that the retrieval system effectively captures all necessary context needed to
    answer the query.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 上下文回忆衡量使用“上下文回忆评估”中的提示成功检索到的相关信息数量。高分表示检索系统有效地捕捉了回答查询所需的所有必要上下文。
- en: '**Context recall evaluation**'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**上下文回忆评估**'
- en: 'Goal: Given a context and an answer, analyze each sentence in the answer and
    classify whether the sentence can be attributed to the given context or not. Use
    only ''Yes'' (1) or ''No'' (0) as a binary classification. Output JSON with reasoning.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 目标：给定一个上下文和一个答案，分析答案中的每一句话，并判断这句话是否可以归因于给定的上下文。使用仅包含'Yes'（1）或'No'（0）的二进制分类。输出带有理由的JSON。
- en: The prompt in “Context recall evaluation” ensures that every sentence in the
    generated answer is explicitly supported by the retrieved context. By doing so,
    it helps evaluate how effectively the retrieval system captures relevant information.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: “上下文回忆评估”中的提示确保生成的答案中的每一句话都明确地得到了检索到的上下文的支持。通过这样做，它有助于评估检索系统捕捉相关信息的有效性。
- en: Next, the faithfulness assessment ensures that the generated response remains
    factually aligned with the retrieved content.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，忠实度评估确保生成的响应与检索到的内容保持事实一致。
- en: 8.2.2 Faithfulness
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.2 忠实度
- en: Faithfulness evaluates whether the generated response remains factually consistent
    with the retrieved context. A response is considered faithful if all its claims
    can be directly supported by the provided documents, minimizing the risk of hallucination.
    Faithfulness is assessed using a two-step process. In the first step, it decomposes
    the answer into atomic statements using the prompt in “Faithfulness statement
    breakdown,” ensuring that each unit of information is clear and self-contained,
    making verification easier.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 忠实度评估是否生成的响应与检索到的上下文保持事实一致。如果一个响应的所有主张都可以直接由提供的文档支持，则认为它是忠实的，从而最小化幻觉的风险。忠实度评估使用两步过程。在第一步中，它使用“忠实度语句分解”中的提示将答案分解为原子语句，确保每个信息单元都是清晰和自包含的，从而使得验证变得更容易。
- en: '**Faithfulness statement breakdown**'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**忠实度语句分解**'
- en: 'Goal: Given a question and an answer, analyze the complexity of each sentence
    in the answer. Break down each sentence into one or more fully understandable
    statements. Ensure that no pronouns are used in any statement. Format the outputs
    in JSON.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 目标：给定一个问题和一个答案，分析答案中每一句话的复杂性。将每一句话分解为一个或多个完全可理解的语句。确保任何语句中都不使用代词。以JSON格式输出。
- en: Once the statements are generated, it evaluates their faithfulness using the
    prompt in “Faithfulness evaluation.”
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦生成语句，它将使用“忠实度评估”中的提示来评估它们的忠实度。
- en: '**Faithfulness evaluation**'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '**忠实度评估**'
- en: 'Goal: Your task is to judge the faithfulness of a series of statements based
    on a given context. For each statement, return a verdict as 1 if the statement
    can be directly inferred from the context or 0 if the statement cannot be directly
    inferred from the context.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 目标：根据给定的上下文判断一系列语句的忠实度。对于每个语句，如果可以从上下文中直接推断出该语句，则返回1，如果无法直接从上下文中推断出该语句，则返回0。
- en: The prompt in “Faithfulness evaluation” checks whether the statements in the
    generated response are factually grounded in the retrieved context. It ensures
    that the model does not introduce unsupported claims.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: “忠实度评估”中的提示检查生成的响应中的语句是否在检索到的上下文中具有事实基础。它确保模型不会引入未经支持的断言。
- en: Finally, we evaluate answer correctness by comparing the generated response
    with the ground truth.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们通过将生成的响应与基准事实进行比较来评估答案的正确性。
- en: 8.2.3 Answer correctness
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.3 答案正确性
- en: Answer correctness assesses how accurately and completely the response addresses
    the user’s query. It considers both factual accuracy and relevance to ensure the
    response aligns with the intent of the question. Answer correctness uses the same
    process as faithfulness to generate statements and then evaluates them using the
    prompt in “Answer correctness evaluation.”
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 答案正确性评估了响应如何准确地、完整地回答用户的查询。它考虑了事实准确性以及相关性，以确保响应与问题的意图一致。答案正确性使用与忠实度相同的过程生成陈述，然后使用“答案正确性评估”中的提示进行评估。
- en: '**Answer correctness evaluation**'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '**答案正确性评估**'
- en: 'Goal: Given a ground truth and an answer statement, analyze each statement
    and classify it into one of the following categories:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 目标：给定一个真实响应和一个答案陈述，分析每个陈述并将其分类到以下类别之一：
- en: 'TP (true positive): Statements present in the answer that are also directly
    supported by one or more statements in the ground truth. FP (false positive):
    Statements present in the answer but not directly supported by any statement in
    the ground truth. FN (false negative): Statements found in the ground truth but
    not present in the answer.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: TP（真阳性）：答案中存在的陈述也在真实响应中的一个或多个陈述中得到直接支持。FP（假阳性）：答案中存在的陈述但在真实响应中的任何陈述都没有得到直接支持。FN（假阴性）：在真实响应中找到但在答案中不存在的陈述。
- en: Each statement can only belong to one of these categories. Provide a reason
    for each classification.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 每个陈述只能属于这些类别之一。为每个分类提供理由。
- en: The prompt in “Answer correctness evaluation” ensures that the response is both
    factually correct and aligned with the expected answer by systematically comparing
    the generated statements with the ground truth.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: “答案正确性评估”中的提示确保通过系统地比较生成的陈述与真实响应，响应既在事实上正确又与预期的答案一致。
- en: By analyzing these metrics, you can determine how well the system retrieves
    relevant data, maintains factual consistency, and generates correct responses.
    This evaluation will help identify potential weaknesses, such as missing context,
    inconsistencies, or inaccurate answers, allowing for iterative refinement and
    improved performance.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 通过分析这些指标，你可以确定系统检索相关数据、保持事实一致性和生成正确响应的程度。这种评估将有助于识别潜在的弱点，如缺失的上下文、不一致或不准确的答案，从而实现迭代改进和性能提升。
- en: 8.2.4 Loading the dataset
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.4 加载数据集
- en: The benchmark dataset is provided as a CSV file in the accompanying repository,
    making it easy to load and use, as demonstrated in the following listing.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 基准数据集以 CSV 文件的形式提供在附带的存储库中，这使得加载和使用变得容易，如下面的列表所示。
- en: Listing 8.1 Loading benchmark dataset from CSV
  id: totrans-94
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 8.1 从 CSV 加载基准数据集
- en: '[PRE0]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 8.2.5 Running evaluation
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.5 运行评估
- en: To evaluate the system’s performance, you will generate answers for the benchmark
    dataset and compare them against the expected ground truth responses. First, you
    need to obtain the ground truth by executing the corresponding Cypher statements
    and generating answers using the agent, as shown in listing 8.2\. Additionally,
    you must record latency and retrieved contexts to analyze the system’s efficiency
    and relevance.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估系统的性能，你需要为基准数据集生成答案，并将它们与预期的真实响应进行比较。首先，你需要通过执行相应的 Cypher 语句并使用代理生成答案来获取真实响应，如列表
    8.2 所示。此外，你必须记录延迟和检索到的上下文，以分析系统的效率和相关性。
- en: Listing 8.2 Generating answers and ground truth responses
  id: totrans-98
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 8.2 生成答案和真实响应
- en: '[PRE1]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '#1 The provided Cypher statement returns the ground truth.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 提供的 Cypher 语句返回真实响应。'
- en: '#2 Executes the agent to generate a response to the question'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 执行代理以生成对问题的响应'
- en: '#3 Calculates the latency'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 计算延迟'
- en: '#4 Stores the results back to the dataframe'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '#4 将结果存储回数据框'
- en: Now that we have collected all the necessary input data, including generated
    answers and ground truth responses, we can proceed with the evaluation.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经收集了所有必要的输入数据，包括生成的答案和真实响应，我们可以继续进行评估。
- en: Listing 8.3 Evaluating the generated answer and retrieved context
  id: totrans-105
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表 8.3 评估生成的答案和检索到的上下文
- en: '[PRE2]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '#1 Changes missing response answers to “I don’t know”'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '#1 将缺失的响应答案更改为“我不知道”'
- en: '#2 Runs the evaluation using RAGAS framework'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '#2 使用 RAGAS 框架运行评估'
- en: '#3 Relevant metrics'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '#3 相关指标'
- en: This code in listing 8.3 runs the evaluation using the RAGAS framework, which
    requires non-null values, so you fill in missing responses with “I don’t know.”
    It then evaluates the generated answers based on answer correctness, context recall,
    and faithfulness.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 列表8.3中的此代码使用RAGAS框架运行评估，该框架需要非空值，因此您用“我不知道”填充缺失的响应。然后根据答案正确性、上下文召回和忠实度评估生成的答案。
- en: The final step is to analyze the results to understand the system’s performance.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步是分析结果，以了解系统的性能。
- en: 8.2.6 Observations
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2.6 观察结果
- en: You can review the overall summary in 8.5 to get an overview of the agent’s
    performance.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过查看8.5中的整体总结来了解代理的性能概述。
- en: Table 8.5 Benchmark summary
  id: totrans-114
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表8.5 基准总结
- en: '| **`answer_correctness`** | **`context_recall`** | **`faithfulness`** |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| **`answer_correctness`** | **`context_recall`** | **`faithfulness`** |'
- en: '| --- | --- | --- |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| 0.7774  | 0.7941  | 0.9657  |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 0.7774  | 0.7941  | 0.9657  |'
- en: The results in table 8.5 provide an overall assessment of the system’s performance
    based on three key metrics. With an answer correctness score of 0.7774, the model
    gets things right most of the time but still misses the mark in about a quarter
    of cases. The context recall score of 0.7941 shows that while the retrieval system
    is doing a decent job, it occasionally fails to pull in all the necessary information,
    which could be holding back the overall accuracy. On the bright side, the faithfulness
    score of 0.9657 is excellent, meaning the model rarely makes things up and stays
    true to the retrieved context.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 表8.5中的结果提供了基于三个关键指标的系统性能的整体评估。答案正确性得分为0.7774，模型大多数时候都能正确回答，但仍有大约四分之一的情况未能命中目标。上下文召回得分为0.7941表明，虽然检索系统做得相当不错，但它偶尔无法检索到所有必要的信息，这可能会影响整体准确性。另一方面，忠实度得分为0.9657非常出色，这意味着模型很少编造信息，并始终忠于检索到的上下文。
- en: Overall, the high faithfulness score shows that the model does not introduce
    incorrect information, but the answer correctness and context recall lower scores
    suggest that improving retrieval mechanisms could lead to better response accuracy.
    Enhancing retrieval coverage and refining how the LLM formulates answers could
    improve overall performance. These insights can guide further optimizations, such
    as refining the retrieval system, improving query reformulation, or implementing
    better entity mapping for ambiguous queries.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，高忠实度得分表明模型不会引入错误信息，但答案正确性和上下文召回的较低得分表明，改进检索机制可以提高响应准确性。增强检索覆盖范围和改进LLM构建答案的方式可以提高整体性能。这些见解可以指导进一步的优化，例如改进检索系统、改进查询重构或为模糊查询实现更好的实体映射。
- en: You can further analyze each response to identify areas for improvement by using
    the code in the following listing.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下列表中的代码进一步分析每个响应，以识别改进的区域。
- en: Listing 8.4 Extracting metrics and adding them to the dataframe
  id: totrans-121
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表8.4 提取指标并将它们添加到数据框中
- en: '[PRE3]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The full response is too large to include in the book, but there are several
    key takeaways from analyzing individual examples. One noticeable pattern is that
    latency is significantly lower for queries that don’t require text2cypher, as
    avoiding an additional LLM call speeds up the response. Another observation is
    that since we rely on an LLM as a judge, some scores may seem inconsistent, such
    as in the Hello example.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 由于完整的响应太大，无法包含在书中，但通过分析个别示例，我们可以得出几个关键结论。一个明显的模式是，对于不需要text2cypher的查询，延迟显著降低，因为避免额外的LLM调用可以加快响应速度。另一个观察结果是，由于我们依赖LLM作为评判者，一些分数可能看起来不一致，例如在Hello示例中。
- en: One clear limitation is that the system fails to answer the question “Who has
    the longest name among all actors?” This happens because the model isn’t equipped
    to generate the appropriate Cypher query. To address this, you could add a few-shot
    example to guide text2cypher or implement a dedicated tool specifically for handling
    such queries.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 一个明显的局限性是，系统无法回答“在所有演员中，谁的名字最长？”这个问题。这是因为模型没有生成适当Cypher查询的能力。为了解决这个问题，您可以添加一些示例来指导text2cypher，或者实施一个专门用于处理此类查询的工具。
- en: This analysis demonstrates how a benchmark helps us evaluate results and make
    informed decisions about future improvements. As the system evolves, the benchmark
    dataset should continue to grow, ensuring ongoing refinement and better performance.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 此分析展示了基准如何帮助我们评估结果并就未来的改进做出明智的决定。随着系统的发展，基准数据集应继续增长，以确保持续的改进和更好的性能。
- en: Throughout this book, you have explored how to build knowledge graph RAG systems.
    You’ve learned how different retrieval strategies enable your agent to fetch relevant
    information, whether from structured or unstructured data. Understanding when
    to use methods like vector search or Cypher templates is key to designing an efficient
    and accurate system.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，你探索了如何构建知识图谱RAG系统。你学习了不同的检索策略如何使你的代理从结构化或非结构化数据中检索相关信息。了解何时使用向量搜索或Cypher模板等方法对于设计高效且准确系统至关重要。
- en: By implementing and refining retrieval strategies, you now have the foundation
    to build a powerful knowledge graph–based agent. You’ve seen how structured queries
    can enhance precision and how retrieval choices impact answer quality, and you’ve
    learned how to systematically evaluate performance. This chapter introduced benchmarking
    as a way to measure accuracy, recall, and faithfulness, giving you the tools to
    continuously improve your agent.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 通过实施和改进检索策略，你现在有了构建基于知识图谱的强大代理的基础。你已经看到了结构化查询如何提高精确性，以及检索选择如何影响答案质量，你还学会了如何系统地评估性能。本章介绍了基准测试作为衡量准确性、召回率和忠实度的一种方式，为你提供了持续改进代理的工具。
- en: 8.3 Next steps
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8.3 下一步
- en: You’re now equipped with the knowledge and tools to build and refine intelligent
    retrieval systems powered by knowledge graphs. Whether you’re creating a sophisticated
    question-answering agent or tailoring retrieval pipelines for specific domains,
    you have the foundation to design robust, high-performing, knowledge-driven AI
    systems.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 你现在拥有了构建和改进由知识图谱驱动的智能检索系统的知识和工具。无论你是创建复杂的问答代理，还是为特定领域定制检索管道，你都有设计稳健、高性能、知识驱动AI系统的坚实基础。
- en: LLMs are rapidly improving, not only in their ability to understand and generate
    language but also in how effectively they can use external tools for data retrieval,
    transformation, and manipulation. As these models become more capable, they will
    be able to perform increasingly complex tasks with minimal prompting. However,
    their effectiveness still depends on the quality, design, and integration of the
    tools you provide. It’s your job to implement those tools thoughtfully and efficiently,
    ensuring they are well suited to your system’s goals and constraints.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs正在迅速改进，不仅在于它们理解和生成语言的能力，还在于它们如何有效地使用外部工具进行数据检索、转换和处理。随着这些模型能力的增强，它们将能够以最小的提示完成越来越复杂的任务。然而，它们的有效性仍然取决于你提供的工具的质量、设计和集成。你的任务是深思熟虑且高效地实施这些工具，确保它们非常适合你系统的目标和限制。
- en: 'With this foundation, you can now begin building your own agentic GraphRAG
    systems. You are equipped to work with unstructured data in a variety of ways:
    you can embed text directly to enable fast similarity-based retrieval or go a
    step further and extract structured information—such as entities, relationships,
    and events—to populate a knowledge graph that supports more precise, semantic,
    and multihop queries. By combining these approaches, you can build retrieval systems
    that not only find relevant information but truly understand it, paving the way
    for powerful, context-aware AI applications.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个基础上，你现在可以开始构建自己的代理GraphRAG系统。你能够以各种方式处理非结构化数据：你可以直接嵌入文本以实现基于相似性的快速检索，或者更进一步，提取结构化信息——如实体、关系和事件——以填充支持更精确、语义和跨跳查询的知识图谱。通过结合这些方法，你可以构建不仅找到相关信息，而且真正理解它的检索系统，为强大的、具有上下文感知的AI应用铺平道路。
- en: Summary
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Evaluating a RAG pipeline is crucial for ensuring accurate and coherent answers.
    A benchmark evaluation helps measure performance and define the agent’s capabilities.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估RAG管道对于确保答案的准确性和一致性至关重要。基准评估有助于衡量性能并定义代理的能力。
- en: 'The evaluation process involves assessing various stages: retrieval tool selection,
    context retrieval relevance, answer generation quality, and overall system effectiveness.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估过程涉及评估各个阶段：检索工具选择、上下文检索相关性、答案生成质量以及整体系统有效性。
- en: A well-structured benchmark dataset should include diverse queries that test
    retrieval accuracy, entity mapping, the handling of greetings, irrelevant queries,
    and various Cypher-based database lookups.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个结构良好的基准数据集应包括多样化的查询，以测试检索准确性、实体映射、问候语的处理、无关查询以及各种基于Cypher的数据库查找。
- en: Instead of static expected answers, using Cypher queries as ground truth ensures
    the benchmark remains valid even if the underlying data changes.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与静态预期答案不同，使用Cypher查询作为基准确保即使底层数据发生变化，基准仍然有效。
- en: Context recall measures how well the system retrieves relevant information.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 环境回忆衡量系统检索相关信息的能力。
- en: Faithfulness evaluates if the generated answer is factually consistent with
    the retrieved content.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 忠实度评估生成的答案是否与检索到的内容在事实上保持一致。
- en: Answer correctness assesses whether the response fully and accurately addresses
    the query.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回答正确性评估响应是否完全准确地回答了查询。
