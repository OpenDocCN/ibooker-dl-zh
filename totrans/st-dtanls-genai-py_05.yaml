- en: 6 Advanced text mining with generative AI
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 6 使用生成式AI进行高级文本挖掘
- en: This chapter covers
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 本章涵盖
- en: Sentiment analysis with a generative AI language model
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用生成式AI语言模型进行情感分析
- en: Sentiment analysis with a generative AI API
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用生成式AI API进行情感分析
- en: Sentiment analysis with machine learning
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用机器学习进行情感分析
- en: Text summarization with generative AI
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用生成式AI进行文本摘要
- en: Text summarization with dedicated libraries
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用专用库进行文本摘要
- en: Topic modeling
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主题建模
- en: In the previous chapter, you got a taste of text-mining basics and discovered
    how generative AI can speed up and refine your analyses. Now, let’s go deeper.
    Ahead, you’ll tackle advanced NLP techniques such as sentiment analysis and text
    summarization. These tools are invaluable in the business world, enabling companies
    to swiftly gauge customer sentiment from reviews, social media, or customer service
    interactions, leading to more informed decision-making. Text summarization, on
    the other hand, can distill lengthy reports, research findings, or customer feedback
    into digestible insights, saving your precious time and ensuring key information
    doesn’t go unnoticed. Together, these techniques can significantly enhance how
    businesses understand and respond to their audiences, driving better strategies
    and outcomes.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，您已经尝到了文本挖掘基础的味道，并发现了生成式AI如何加速和精炼您的分析。现在，让我们更进一步。接下来，您将应对诸如情感分析和文本摘要等高级NLP技术。这些工具在商业世界中极为宝贵，使公司能够迅速从评论、社交媒体或客户服务互动中评估客户情绪，从而做出更明智的决策。另一方面，文本摘要可以将冗长的报告、研究结果或客户反馈提炼成可消化的洞察，节省您宝贵的时间，并确保关键信息不会被人忽视。这些技术共同可以显著提高企业理解和回应其受众的方式，推动更好的策略和结果。
- en: In this chapter, you’ll see how the straightforward sentiment analysis methods
    from chapter 5 stack up against the advanced capabilities of machine learning
    models and generative AI’s linguistic finesse. Prepare to witness firsthand the
    challenge of outperforming generative AI in NLP tasks. Your objective? As always,
    to impress your boss. But this time, by swiftly and accurately uncovering key
    customer insights through the extraction and summarization of negative reviews.
    With generative AI as your ally, you’re equipped to sail smoothly through these
    complex processes.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您将看到第五章中简单情感分析方法与机器学习模型的先进功能和生成式AI的语言技巧相比的表现。准备好亲眼见证超越生成式AI在NLP任务中的挑战。您的目标？一如既往，给老板留下深刻印象。但这次，通过迅速准确地从负面评论中提取和总结关键客户洞察来实现。有了生成式AI作为您的盟友，您将能够顺利地通过这些复杂的过程。
- en: 6.1 Review analysis
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.1 评论分析
- en: 'As you move forward in this chapter, remember the task your boss handed you:
    to uncover the main issues customers have with your company’s products and services,
    based on their reviews. The initial steps you took in the previous chapter shed
    some light, but now you are faced with an intriguing challenge: can you deepen
    your understanding by tapping into more advanced NLP techniques? Let’s find out
    together.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 随着您在本章中的前进，请记住老板交给您的任务：根据客户的评论，揭示客户对您公司产品和服务的主要问题。您在上一章中采取的初步步骤提供了一些线索，但现在您面临一个有趣的挑战：您能否通过利用更高级的NLP技术来深化您的理解？让我们一起来找出答案。
- en: 'The dataset you examined in the previous chapter contained customer reviews
    (described in detail in section 5.2.2). It was rather disorganized, which is common
    for this type of data. Additionally, the fact that the reviews are in Portuguese
    poses another challenge, assuming you’re not familiar with the language. To navigate
    this clutter, we’ll explore various techniques for deriving insights from unstructured
    data, among which these are the two most important:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 您在上一章中检查的数据集包含了客户评论（在5.2.2节中详细描述）。这种数据通常比较杂乱无章。此外，如果您的葡萄牙语不熟悉，那么评论是葡萄牙语的事实又提出了另一个挑战。为了应对这种混乱，我们将探索从非结构化数据中提取洞察的各种技术，其中这些是最重要的两种：
- en: '*Sentiment analysis*—The process of determining the underlying emotions, opinions,
    or attitudes expressed within a piece of text, such as positive, negative, or
    neutral sentiment. This technique is invaluable for businesses aiming to gauge
    customer satisfaction, monitor brand reputation, or understand consumer needs.
    For example, after applying it to customer reviews, a company can pinpoint which
    features of a product or service are most appreciated or which aspects are causing
    dissatisfaction.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*情感分析*——确定文本中表达的基本情感、观点或态度的过程，例如积极、消极或中性情感。这项技术对于希望衡量客户满意度、监控品牌声誉或了解消费者需求的企业来说非常有价值。例如，在应用于客户评论后，一家公司可以确定产品或服务的哪些特性最受赞赏，或者哪些方面导致了不满。'
- en: '*Text summarization*—The technique of condensing a larger body of text into
    a shorter, coherent representation that retains the most essential information
    and key ideas. This method is particularly useful for professionals who need to
    quickly assimilate large volumes of information without sacrificing understanding.
    For instance, a financial analyst could employ text summarization to distill comprehensive
    market reports and research papers into concise summaries, enabling faster decision-making
    and efficiently keeping abreast of critical market trends and forecasts.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*文本摘要*——将大量文本压缩成更短、连贯的表示，同时保留最基本的信息和关键思想的技术。这种方法对于需要快速吸收大量信息而不牺牲理解的专业人士特别有用。例如，财务分析师可以使用文本摘要将全面的市场报告和研究论文提炼成简洁的摘要，从而加快决策速度，并有效地掌握关键市场趋势和预测。'
- en: You might have noticed that the basic NLP techniques described in the previous
    chapter already laid the groundwork for sentiment analysis and text summarization.
    Utilizing keywords or predefined lexicons to filter out positive reviews indeed
    serves as a rudimentary form of sentiment analysis, while even basic frequency
    analysis proved sufficient to highlight the main concerns appearing in customer
    feedback, thus providing a form of text summary. So, are you going to learn anything
    new in this chapter? Absolutely, you will.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，上一章中描述的基本NLP技术已经为情感分析和文本摘要奠定了基础。利用关键词或预定义的词汇表来过滤出正面评论确实是一种基本的情感分析形式，而即使是基本的频率分析也足以突出客户反馈中出现的主要问题，从而提供一种文本摘要形式。那么，在这一章中你将学到什么新东西呢？绝对会有的。
- en: To put it simply, what you’ve learned so far is akin to learning how to peel
    potatoes. In this chapter, we’re about to master the art of gourmet cuisine. However,
    our approach remains highly practical, meaning you won’t be required to perform
    complex calculations mentally. Instead, we’ll introduce you to the best tools
    available for achieving your objectives. Specifically, we will use pretrained
    machine learning models available online to conduct sentiment analysis and text
    summarization, with generative AI guiding us throughout the process. We will also
    leverage generative AI’s inherent language capabilities to directly undertake
    these NLP tasks. The subsequent sections will offer a comparison of these two
    methods and the basic NLP techniques introduced previously, providing insight
    into their relative performance and utility.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，你到目前为止所学的就像学习如何削土豆。在这一章中，我们将掌握美食烹饪的艺术。然而，我们的方法仍然非常实用，这意味着你不需要在心理上执行复杂的计算。相反，我们将向你介绍实现目标的最佳工具。具体来说，我们将使用在线可用的预训练机器学习模型来进行情感分析和文本摘要，生成式AI将引导我们完成整个过程。我们还将利用生成式AI固有的语言能力直接执行这些NLP任务。接下来的章节将对这两种方法以及之前介绍的基本NLP技术进行比较，提供它们相对性能和实用性的见解。
- en: 6.2 Sentiment analysis
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6.2 情感分析
- en: Sentiment analysis is a type of text classification where a label or class is
    assigned to a given text. For example, labels such as “correct,” “incorrect,”
    or “unknown” can be used to classify texts based on their grammatical correctness.
    Specifically, in sentiment analysis, the labels “positive,” “negative,” and “neutral”
    are typically used to reflect the author’s emotions and attitudes toward a subject.
    For instance, a statement like “I hate your company and your sh**y Quantum Fluff!”
    carries strong negative sentiment. Without NLP tools, such emotionally charged
    comments could easily be overlooked by your company’s PR department amidst a sea
    of other feedback. However, hoping that negative opinions will remain similarly
    unseen by other customers is nothing but wishful thinking. Such views tend to
    spread rapidly, much like a wildfire in a savanna, potentially endangering your
    company’s reputation. Therefore, learning how to automatically detect customer
    sentiments is crucial for your business’s well-being.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 情感分析是一种文本分类类型，其中给定的文本被分配一个标签或类别。例如，可以使用“正确”、“错误”或“未知”等标签根据文本的语法正确性对文本进行分类。具体来说，在情感分析中，通常使用“正面”、“负面”和“中性”这些标签来反映作者对某一主题的情感和态度。例如，一个像“我讨厌你的公司和你的糟糕的量子泡沫！”这样的陈述就带有强烈的负面情感。没有自然语言处理工具，这样的情感强烈的评论很容易在众多反馈中被公司公关部门忽视。然而，希望负面意见不会被其他客户看到，这不过是美好的愿望。这样的观点往往像草原上的野火一样迅速传播，可能危及公司的声誉。因此，学习如何自动检测客户情感对于企业健康至关重要。
- en: It’s important to note that text classification encompasses a much wider range
    of applications than just sentiment analysis. Consider a scenario where the input
    involves not just a single piece of text, like customer reviews, but two pieces,
    with the goal of identifying the relationship between them. This leads to the
    field of natural language inference (NLI), which significantly broadens the scope
    of language analysis.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要注意，文本分类的应用范围比情感分析广泛得多。考虑一种情况，其中输入不仅涉及单一文本，如客户评论，还涉及两个文本，目的是确定它们之间的关系。这导致了自然语言推理（NLI）领域，它极大地扩展了语言分析的范围。
- en: NLI tasks can vary depending on the inputs and the labels assigned, but ultimately
    they all boil down to text classification. For instance, the first input text
    might be a premise, such as “A robin is a bird,” and the second a hypothesis,
    like “A robin can fly.” The possible labels could be “entailment,” indicating
    that the hypothesis logically follows from the premise (e.g., since a robin is
    a bird, and most birds can fly, it entails that a robin can fly); “contradiction,”
    indicating that the hypothesis contradicts the premise; and “neutral” for hypotheses
    that are irrelevant or cases that are difficult to categorize. This framework
    allows for the development of programs that, at least theoretically, can perform
    a form of reading comprehension. The practical implementation of such programs,
    however, depends on various factors, including task complexity, the volume and
    quality of training data, and our skill (and perhaps a bit of luck) in creating
    a model capable of undertaking such a challenge.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: NLI任务可以根据输入和分配的标签而有所不同，但最终它们都归结为文本分类。例如，第一个输入文本可能是一个前提，比如“知更鸟是一种鸟”，第二个输入可能是一个假设，比如“知更鸟会飞”。可能的标签可以是“蕴涵”，表示假设逻辑上从前提中得出（例如，既然知更鸟是一种鸟，而大多数鸟都会飞，那么可以推断知更鸟会飞）；“矛盾”，表示假设与前提相矛盾；“中性”用于与前提无关或难以分类的情况。这个框架允许开发出至少在理论上可以执行某种形式阅读理解的程序。然而，这些程序的实用实施取决于各种因素，包括任务复杂性、训练数据量和质量，以及我们创建能够承担这种挑战的模型的能力（也许还有一点运气）。
- en: The task assigned by your boss—to classify reviews—is considerably less complex
    than the mentioned NLI tasks. Nonetheless, it offers an excellent opportunity
    to explore the fundamentals of text classification and sentiment analysis.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 您老板分配的任务——对评论进行分类——与提到的NLI任务相比要简单得多。尽管如此，它为探索文本分类和情感分析的基本原理提供了极好的机会。
- en: 'In the previous chapter, we demonstrated how to conduct basic sentiment analysis,
    particularly extracting positive reviews using rule-based (keyword search) and
    dictionary-based (lexicon) methods. Now, consider how our simple classifier, utilizing
    these approaches, would classify the following review: “Great, another software
    update that fixes nothing.” Given the presence of words like “great” and “fixes,”
    it might mistakenly classify this statement as positive, despite its sarcastic
    tone expressing frustration over unmet promises of improvement by the software
    update.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们展示了如何进行基本的情感分析，特别是使用基于规则（关键词搜索）和基于词典（词汇表）的方法提取正面评论。现在，考虑一下我们的简单分类器，利用这些方法，会如何对以下评论进行分类：“太好了，又一个软件更新，什么问题都没解决。”鉴于存在“太好了”和“解决”等词语，它可能会错误地将这个陈述归类为正面，尽管它带有讽刺的语气，表达了对于软件更新未能实现改进承诺的挫败感。
- en: Pretrained models are getting pretty good at sniffing out sarcasm in text, but
    they’re not magic. They achieve this feat through a combination of analyzing language
    tricks and understanding the broader context. By training on massive amounts of
    text data, including examples dripping with sarcasm and others that are plain
    and literal, these models become familiar with the linguistic gymnastics humans
    use to convey hidden meaning. They learn to identify red flags like positive words
    used in negative situations (“this is perfect” after a frustrating experience)
    or phrases that go against the grain of normal conversation (“Can’t wait for Monday
    morning!”). But sarcasm isn’t all about wordplay. Pretrained models also zoom
    out, examining the surrounding text and the relationship between the speaker and
    listener. For instance, a sarcastic comment between friends is more likely than
    a sarcastic remark from your boss during a performance review.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练模型在检测文本中的讽刺意味方面变得越来越擅长，但它们并非万能。它们通过分析语言技巧和了解更广泛的语境来实现这一成就。通过在包括充满讽刺意味的例子和直白的例子在内的海量文本数据上训练，这些模型熟悉了人类用来传达隐含意义的语言技巧。它们学会了识别红旗，如用于负面情境中的正面词语（“在令人沮丧的经历之后，这是完美的”）或违反常规对话的短语（“迫不及待地期待周一早上！”）。但讽刺不仅仅是文字游戏。预训练模型还会扩大视野，检查周围文本和说话者与听者之间的关系。例如，朋友之间的讽刺评论比在绩效评估期间老板的讽刺评论更有可能。
- en: Now, let’s examine the phrase, “back to the drawing board.” Through basic keyword
    or dictionary-based analysis, accurately classifying this expression poses a challenge,
    as it lacks explicit sentiment indicators. However, “back to the drawing board”
    is typically used to express that an attempt has failed and it’s time to start
    over, often carrying a connotation of disappointment or setback.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来分析一下短语“回到原点”。通过基本的关键词或基于词典的分析，准确地对这个表达进行分类是一个挑战，因为它缺乏明确的情感指示。然而，“回到原点”通常用来表示一个尝试已经失败，是时候重新开始了，这通常带有失望或挫折的意味。
- en: In contrast, machine learning models, developed with extensive and diverse text
    datasets, can accurately comprehend idiomatic expressions and their contextual
    meanings, effectively identifying sentiments of disappointment or frustration.
    This capability is crucial for thorough sentiment analysis, proving particularly
    valuable in evaluating feedback, reviews, or internal communications where such
    expressions are common. An added advantage of such models is their ability to
    adapt to different domains or languages with little manual effort, making them
    versatile tools for sentiment analysis across various datasets. A prime example
    of such a pretrained model is a large language model or LLM.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，通过大量和多样化的文本数据集开发的机器学习模型，可以准确地理解习语表达及其语境意义，有效地识别失望或挫败的情感。这种能力对于彻底的情感分析至关重要，特别是在评估反馈、评论或内部沟通中，这些表达是常见的。这种模型的另一个优点是它们能够通过很少的人工努力适应不同的领域或语言，使它们成为跨各种数据集的情感分析的多功能工具。这类预训练模型的典型例子是一个大型语言模型或LLM。
- en: Large Language Model (LLM)  An LLM is a powerful AI system trained on vast amounts
    of text so it can understand and generate human language. It uses deep learning
    to perform a wide range of NLP tasks, including translation, summarization, question
    answering, and sentiment analysis, by predicting the likelihood of a sequence
    of words. The capabilities of LLMs extend beyond simple text processing, enabling
    them to grasp context, infer meaning, and even generate coherent and contextually
    relevant text responses, making them powerful tools in both research and application
    domains.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 大型语言模型（LLM）是一个强大的AI系统，它在大量文本上进行训练，以便理解并生成人类语言。它使用深度学习执行各种NLP任务，包括翻译、摘要、问答和情感分析，通过预测一系列单词的可能性。LLMs的能力超越了简单的文本处理，使它们能够理解上下文、推断意义，甚至生成连贯且与上下文相关的文本响应，使它们在研究和应用领域都成为强大的工具。
- en: All the generative AI models discussed so far and utilized throughout this book
    are LLMs. Although they were originally designed for general-purpose conversations
    rather than as dedicated review classifiers, their exceptional ability to understand
    text and extract insights enables them to be effectively used for sentiment analysis
    tasks. In the following sections, we will show how to apply them to sentiment
    analysis and compare the results with those obtained from smaller machine learning
    models.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止讨论的所有生成式AI模型以及本书中使用的模型都是大型语言模型（LLMs）。尽管它们最初是为了通用对话而不是作为专门的审查分类器而设计的，但它们理解文本和提取见解的非凡能力使它们能够有效地用于情感分析任务。在接下来的章节中，我们将展示如何将它们应用于情感分析，并将结果与来自较小机器学习模型的结果进行比较。
- en: 6.2.1 What can you learn from sentiment analysis?
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.1 从情感分析中你可以学到什么？
- en: Sentiment analysis offers invaluable insights across various business domains,
    enabling your company to understand customer emotions, preferences, and feedback
    on a granular level. For example, if you work for a retail brand, you can analyze
    social media mentions to gauge consumer sentiment toward a new product launch,
    identifying areas of excitement or concern to tailor marketing strategies accordingly.
    If you happen to deal with the finance sector, sentiment analysis of news articles
    and financial forums can help you and your investors predict market trends and
    make informed decisions. If you are engaged in hospitality businesses, like hotels
    and restaurants, utilizing sentiment analysis on review platforms to highlight
    areas for improvement in service or ambiance can directly impact customer satisfaction
    and loyalty. Additionally, in tech companies, you can leverage sentiment analysis
    in user feedback for software updates, prioritizing fixes and features that address
    the most pressing user concerns. This strategic application of sentiment analysis
    not only enhances product and service quality but also fosters a closer connection
    with customers by showing responsiveness to their needs and opinions.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 情感分析在各个商业领域提供了无价的见解，使您的公司能够从细粒度上理解客户情绪、偏好和反馈。例如，如果您为一家零售品牌工作，您可以通过分析社交媒体提及来衡量消费者对新产品发布的情绪，识别兴奋或担忧的区域，从而相应地调整营销策略。如果您从事金融行业，对新闻文章和金融论坛的情感分析可以帮助您和您的投资者预测市场趋势并做出明智的决策。如果您从事酒店和餐饮等酒店业，利用评论平台上的情感分析来突出服务或氛围的改进区域，可以直接影响客户满意度和忠诚度。此外，在科技公司中，您可以在软件更新中利用情感分析来获取用户反馈，优先修复和添加解决用户最紧迫问题的功能和特性。这种战略性的情感分析应用不仅提高了产品和服务的质量，而且通过展示对客户需求和意见的响应，促进了与客户的更紧密联系。
- en: 'The simplest and most often used form of sentiment analysis categorizes texts
    into three groups: positive, negative, and neutral sentiments. In many cases,
    such as with our reviews, this is enough to understand customer sentiment. However,
    you may encounter situations where you will have to explore more complex aspects
    of the human soul (read: demandingness) and apply other instances of sentiment
    analysis, such as these:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单且最常用的情感分析形式是将文本分为三个类别：积极、消极和中性情绪。在许多情况下，例如在我们的评论中，这足以理解客户情绪。然而，您可能会遇到需要探索人类灵魂更复杂方面（即：要求）的情况，并应用其他情感分析实例，例如这些：
- en: '*Emotion detection*—This involves identifying specific emotions expressed in
    the text, such as happiness, sadness, anger, surprise, fear, and disgust, allowing
    for a more detailed understanding of the user’s feelings and reactions. This may
    be crucial, such as for detecting suicidal ideation on social media. Another business
    application where emotion detection is essential is in customer support and service
    interactions, especially for industries like telecommunications, banking, or utilities,
    where customer frustrations can escalate quickly. For example, in a telecommunications
    company, emotion detection can be employed in analyzing customer support chats
    or call transcripts. By identifying specific emotions such as frustration, anger,
    or disappointment, the company can flag cases that require immediate attention
    or intervention. This allows for a prioritized response to highly dissatisfied
    customers before they tell everyone on the web that Quantum Fluff (your company’s
    pet feature) actually does more harm than good.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*情感检测*—这涉及到识别文本中表达的具体情感，例如快乐、悲伤、愤怒、惊讶、恐惧和厌恶，从而更深入地理解用户的感受和反应。这可能至关重要，例如在社交媒体上检测自杀倾向。另一个情感检测至关重要的商业应用是在客户支持和服务互动中，尤其是在电信、银行或公用事业等行业，在这些行业中，客户的不满可能会迅速升级。例如，在电信公司中，情感检测可以用于分析客户支持聊天或通话记录。通过识别特定的情感，如挫败感、愤怒或失望，公司可以标记出需要立即关注或干预的案件。这允许在客户在网络上告诉每个人Quantum
    Fluff（贵公司的特色功能）实际上弊大于利之前，优先响应高度不满的客户。'
- en: '*Aspect-based sentiment analysis*—This technique focuses on identifying sentiments
    related to specific aspects or features within a text. For instance, in product
    reviews, it differentiates sentiments toward the product’s price, quality, design,
    etc., providing detailed insights into various facets of customer feedback. Who
    knows—maybe Quantum Fluff would gain more customer appreciation if it was cheaper?'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*基于方面的情感分析*—这项技术专注于识别与文本中特定方面或特征相关的情感。例如，在产品评论中，它区分了对产品价格、质量、设计等方面的情感，为顾客反馈的各个方面提供了详细的见解。谁知道呢——也许如果Quantum
    Fluff更便宜，它将获得更多的客户赞赏？'
- en: '*Intensity or sentiment strength*—Sentiment analysis can also assess the intensity
    or degree of sentiment expressed, distinguishing between mild and strong emotions.
    This helps in understanding not just the nature of the sentiment but also its
    strength or urgency. For instance, after such an analysis, it may turn out that
    Quantum Fluff provokes such intense negative feelings that people are willing
    to pay more just to get rid of it, offering your company new opportunities to
    earn.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*情感强度或情感强度*—情感分析还可以评估表达的情感的强度或程度，区分轻微和强烈的情感。这有助于理解情感的实质，以及其强度或紧迫性。例如，经过这样的分析，可能会发现Quantum
    Fluff引发了如此强烈的负面情感，以至于人们愿意支付更多费用来摆脱它，这为贵公司提供了新的盈利机会。'
- en: '*Intent analysis*—Beyond identifying sentiment, some approaches aim to understand
    the intent behind a text, such as whether the user intends to purchase, recommend,
    or complain about a product or service. This may prove useful for evaluating customer
    support tickets, emails, and social media messages. By analyzing the language
    and phrases customers use, the system can determine their intent, such as seeking
    information about new plans, reporting a service outage, requesting technical
    support, or expressing intent to cancel their service. For instance, if a customer’s
    message is found to contain phrases such as “turn this bloody Quantum Fluff off,”
    “better fluffs elsewhere,” or “thinking of switching,” the system can flag this
    as a high-priority intent to churn. This can trigger an immediate response from
    a specialized customer retention team, who can reach out to the customer with
    personalized offers (such as five months without Quantum Fluff for free), support,
    or solutions aimed at addressing their concerns. This proactive approach not only
    improves customer satisfaction by providing timely and relevant responses but
    also aids in reducing churn rates, directly impacting the company’s bottom line.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*意图分析*——除了识别情感之外，一些方法旨在理解文本背后的意图，例如用户是否打算购买、推荐或对产品或服务提出投诉。这可能有助于评估客户支持工单、电子邮件和社交媒体消息。通过分析客户使用的语言和短语，系统可以确定他们的意图，例如寻求有关新计划的详细信息、报告服务中断、请求技术支持或表达取消服务的意图。例如，如果客户的消息被发现包含诸如“把这个该死的量子绒毛关掉”、“其他地方有更好的绒毛”或“在考虑更换”之类的短语，系统可以将此标记为高优先级的流失意图。这可以触发来自专业客户保留团队的即时响应，他们可以提供个性化的优惠（例如免费五个月的量子绒毛），支持或旨在解决他们关注的问题的解决方案。这种主动的方法不仅通过提供及时和相关的响应来提高客户满意度，还有助于降低流失率，直接影响公司的底线。'
- en: These advanced approaches to sentiment analysis allow for a richer, more complex
    understanding of textual data, offering deeper insights into consumer behavior,
    market trends, and public opinion.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这些高级情感分析方法允许对文本数据进行更丰富、更复杂的理解，从而更深入地洞察消费者行为、市场趋势和公众舆论。
- en: 6.2.2 Direct sentiment analysis with generative AIs
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.2 使用生成式AI进行直接情感分析
- en: Even though generative AIs were primarily designed for generating text completions
    rather than performing sentiment analysis, their ability to comprehend text can
    be utilized for a quick assessment of the sentiment expressed in any given piece
    of text. You can test this by examining three reviews from our example dataset.
    These reviews come with scores of 5, 3, and 1, which indicate positive, neutral,
    and negative sentiments respectively. The reviews, along with their translations,
    are presented in table 6.1\. Also detailed are the results of the sentiment analysis
    conducted by ChatGPT 4 and Gemini Advanced. To achieve similar results, you can
    use the prompt “What is the sentiment of these reviews?” followed by including
    the reviews in Portuguese.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管生成式AI最初的设计目的是生成文本补全而不是执行情感分析，但它们理解文本的能力可以用于快速评估任何给定文本中表达的情感。您可以通过检查我们示例数据集中的三个评论来测试这一点。这些评论的评分分别为5、3和1，分别表示积极、中立和消极情感。这些评论及其翻译在表6.1中展示。还详细介绍了ChatGPT
    4和Gemini Advanced进行的情感分析结果。要获得类似的结果，您可以使用提示“这些评论的情感是什么？”然后包括葡萄牙语的评论。
- en: Table 6.1 Direct sentiment analysis with generative AIs
  id: totrans-38
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表6.1 使用生成式AI进行直接情感分析
- en: '| Review translated by Google Translate | Review score | True sentiment | Sentiment
    analysis by ChatGPT 4 | Sentiment analysis by Gemini Advanced |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 由谷歌翻译翻译的评论 | 评分 | 真实情感 | ChatGPT 4的情感分析 | Gemini Advanced的情感分析 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| I received it well before the stipulated time.  | 5  | positive  | *positive*
    The customer received the product well before the stipulated deadline, indicating
    a positive experience with the delivery.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '| 我在规定的时间之前就收到了。 | 5 | 积极的 | *积极的* 客户在规定截止日期之前就收到了产品，这表明他们有积极的送货体验。'
- en: '| *positive* The reviewer received the product well before the estimated delivery
    date.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '| *积极* 评价者收到的产品早于预计的送货日期。'
- en: '|'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Good product, but what came to me does not match the photo in the ad.  |
    3  | neutral  | *mixed/neutral* The review mentions that the product is good (positive
    sentiment), but also states that the received product does not match the photo
    in the advertisement (negative sentiment). This combination of sentiments makes
    the overall sentiment mixed or neutral.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '| 好产品，但收到的产品与广告中的照片不符。  | 3  | 中立  | *混合/中立* 评论提到产品不错（正面情感），但也指出收到的产品与广告中的照片不符（负面情感）。这种情感的组合使得整体情感为混合或中立。'
- en: '| *mixed* The reviewer says the product is good, but it doesn’t match the photo
    in the ad.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '| *混合* 评论者表示产品不错，但与广告中的照片不符。'
- en: '|'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| I would like to know why my product has not yet arrived at my residence and
    nobody has given me satisfaction or anything like that.  | 1  | negative  | *negative*
    The customer is expressing dissatisfaction with the fact that the product has
    not yet arrived at their residence and that they haven’t received any explanation
    or communication regarding the delay. This indicates a negative experience with
    the delivery and customer service.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '| 我想知道为什么我的产品还没有到达我的住处，没有人给我满意的答复或类似的东西。  | 1  | 负面  | *负面* 客户表达了对产品尚未到达其住处以及他们没有收到任何解释或关于延迟的沟通的不满。这表明了在配送和客户服务方面的负面体验。'
- en: '| *negative* The reviewer hasn’t received the product yet and hasn’t received
    any updates from the seller.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '| *负面* 评论者尚未收到产品，也没有收到卖家的任何更新。'
- en: '|'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: As you can see in the table, both ChatGPT 4 and Gemini Advanced demonstrated
    perfect understanding of the reviews. The outcomes from this modest experiment
    are encouraging and warrant further exploration into how direct application of
    generative AIs compares with the basic sentiment analysis techniques outlined
    in section 5.5.4\. In that section, the simplest keyword search (listing 5.6)
    managed to identify positive reviews with a sensitivity of around 47% and a specificity
    of up to 90%.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如表格所示，ChatGPT 4 和 Gemini Advanced 都完美地理解了评论。这个小型实验的结果令人鼓舞，值得进一步探索直接应用生成式 AI
    与第 5.5.4 节中概述的基本情感分析技术之间的比较。在该节中，最简单的关键词搜索（列表 5.6）成功识别出大约 47% 的灵敏度以及高达 90% 的特异性。
- en: You are about to see whether direct utilization of generative AI’s language
    capabilities can yield improved results. The review scores provided in our example
    dataset will once again be used as a reference point for evaluating the quality
    of the analysis through the calculation of sensitivity and specificity. But before
    we can draw any conclusions, we need to conduct direct sentiment analysis with
    generative AI on a larger sample, by using its API.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 您将看到直接利用生成式 AI 的语言能力是否能产生更好的结果。我们示例数据集中的评论评分将再次用作评估分析质量（通过计算灵敏度和特异性）的参考点。但在我们得出任何结论之前，我们需要使用其
    API 在更大的样本上直接进行情感分析。
- en: 6.2.3 Sentiment analysis with generative AI’s API
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.3 使用生成式 AI API 进行情感分析
- en: To evaluate generative AI’s capabilities in detecting sentiments on a broader
    scale, we will utilize the ChatGPT 4 API. For details on API usage, see chapter
    1\. It’s also important to note that accessing the API might require a subscription
    or a specific pricing plan. Your goal here is to have ChatGPT assess the sentiment
    of the first 500 non-empty reviews from the dataset, and compare these results
    with those from a basic sentiment analysis using keywords, as conducted in section
    5.5.4 (listing 5.6).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估生成式 AI 在更广泛范围内检测情感的能力，我们将使用 ChatGPT 4 API。有关 API 使用详情，请参阅第 1 章。还重要的是要注意，访问
    API 可能需要订阅或特定的定价计划。您的目标是让 ChatGPT 评估数据集中前 500 个非空评论的情感，并将这些结果与第 5.5.4 节（列表 5.6）中进行的基于关键词的基本情感分析结果进行比较。
- en: The following code demonstrates how you can use the API to conduct sentiment
    analysis on the reviews by leveraging the intrinsic language capabilities of ChatGPT
    4\. To make it operational, you’ll need to replace `your-api-key` with your actual
    ChatGPT API key and ensure that your account has sufficient funds. Fortunately,
    you can also find the results of this analysis in the books GitHub repository
    in the Sentiment_Analysis_500reviews.csv file.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码演示了如何利用 ChatGPT 4 的内在语言能力通过 API 对评论进行情感分析。为了使其生效，您需要将 `your-api-key` 替换为您的实际
    ChatGPT API 密钥，并确保您的账户有足够的资金。幸运的是，您也可以在 GitHub 仓库的 Sentiment_Analysis_500reviews.csv
    文件中找到此分析的结果。
- en: Listing 6.1 Sentiment analysis with ChatGPT's intrinsic language capabilities
  id: totrans-55
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.1 使用ChatGPT的内在语言能力进行情感分析
- en: '[PRE0]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The preceding code is straightforward. For each of the 500 reviews stored in
    the DataFrame, we send the following prompt to ChatGPT via the API: `The` `sentiment`
    `of` `this review` `is:`, appending the actual review text. The model then generates
    a response, which is classified as positive if it includes the word “positive.”
    The terms “negative” and “neutral” are utilized to identify negative and neutral
    sentiments respectively. If none of these words are found, the review is left
    without an assigned sentiment. Note that this method of analyzing ChatGPT’s responses
    is quite basic and may overlook more nuanced answers, such as those indicating
    mixed feelings within a review. Despite its simplicity, this approach can still
    produce remarkable results, as documented in table 6.2\.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码很简单。对于DataFrame中存储的500条评论中的每一条，我们通过API向ChatGPT发送以下提示：“这篇评论的情感是：”，并附加实际的评论文本。然后模型生成一个响应，如果它包含“positive”这个词，则将其分类为正面。使用“negative”和“neutral”术语分别识别负面和中性情感。如果没有找到这些单词，则评论不会被分配任何情感。请注意，这种方法分析ChatGPT的响应相当基础，可能会忽略更细微的答案，例如那些表明评论中存在混合情感的答案。尽管这种方法很简单，但它仍然可以产生显著的结果，如表6.2所示。
- en: Table 6.2 Quality of sentiment analysis with ChatGPT 4 API
  id: totrans-58
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 表6.2 使用ChatGPT 4 API进行情感分析的质量
- en: '| Sentiment analysis ( *n*=500) | Number of reviews classified as positive
    | Sensitivity | Specificity |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 情感分析（n=500） | 被分类为正面的评论数量 | 敏感性 | 特异性 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Reference review score  | 320 (64%) true positives'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '| 参考评论分数 | 320 (64%) 真阳性'
- en: '| 1  | 1  |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 1 |'
- en: '| Basic keyword search  | 163 (33%)  | 0.45  | 0.9  |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 基本关键词搜索 | 163 (33%) | 0.45 | 0.9 |'
- en: '| ChatGPT 4 API  | 250 (50%)  | 0.74  | 0.93  |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| ChatGPT 4 API | 250 (50%) | 0.74 | 0.93 |'
- en: As in our previous approach, you can use the `review_score` variable from the
    dataset to evaluate the sensitivity and specificity of extracting positive reviews.
    Any review that obtained the score of 4 or 5 was considered positive. Obviously,
    the sentiment assessment with the `review_score` variable obtains sensitivity
    and specificity of 1, as this is our benchmark.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 与我们之前的方法一样，你可以使用数据集中的`review_score`变量来评估提取正面评论的敏感性和特异性。任何获得4或5分的评论都被认为是正面的。显然，使用`review_score`变量进行的情感评估获得了敏感性和特异性为1，因为这是我们基准。
- en: The results shown in table 6.2 indicate that both the basic keyword analysis
    and the method utilizing the ChatGPT 4 API exhibit very high specificity, exceeding
    0.9\. This means that both approaches seldom misclassify negative or neutral reviews
    as positive. Furthermore, ChatGPT 4 demonstrates significantly higher sensitivity
    (0.74), capturing many positive reviews that the basic keyword search missed.
    In the previous chapter, our attempts to improve the sensitivity of extracting
    positive reviews achieved limited success. Despite adopting more advanced techniques
    for cleaning the reviews, applying lemmatization, and using predefined dictionaries
    for Portuguese sentiment analysis, we only managed to enhance sensitivity by a
    few percentage points. However, by leveraging ChatGPT 4 to determine the sentiment
    of the reviews, we succeeded in increasing sensitivity by over 20%! This significant
    improvement was achieved even with the most basic interpretation of the model’s
    responses, marking a substantial and unequivocal advancement, albeit at a cost.
    Given that the ChatGPT API charges based on token usage, analyzing a large volume
    of real data—not just 500 sample reviews but thousands—could pose a financial
    challenge, prompting the question of its cost-effectiveness. While I appreciate
    the simplicity and effectiveness of this method, it may be too early to request
    additional funding from your finance department.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 表6.2中所示的结果表明，基本关键词分析和利用ChatGPT 4 API的方法都表现出非常高的特异性，超过0.9。这意味着这两种方法很少将负面或中性评论误分类为正面。此外，ChatGPT
    4显示出显著更高的敏感性（0.74），捕捉到了基本关键词搜索遗漏的许多正面评论。在前一章中，我们尝试提高提取正面评论的敏感性，但取得了有限的成果。尽管我们采用了更先进的清洗评论技术、应用词形还原和使用预定义的葡萄牙语情感分析词典，但我们只成功提高了几个百分点的敏感性。然而，通过利用ChatGPT
    4来确定评论的情感，我们成功地将敏感性提高了超过20%！这一显著改进即使在模型响应的最基本解释下也实现了，尽管代价不菲。鉴于ChatGPT API根据令牌使用量收费，分析大量真实数据——不仅仅是500个样本评论，而是数千条——可能带来财务挑战，引发对其成本效益的质疑。虽然我欣赏这种方法简单有效，但可能还为时尚早向财务部门申请额外资金。
- en: At this juncture, it’s crucial to recognize that when ChatGPT is queried about
    sentiment analysis or any similar task that it is inherently capable of performing
    due to its ability to “read” with comprehension, its typical advice often revolves
    around guiding you to write specific code to accomplish the task at hand. The
    model may highlight the advantages of traditional NLP methods, emphasizing their
    capacity for analyzing nuanced and specific data among other benefits. In practice,
    however, most data encountered is relatively standard and predominantly in English,
    which—as demonstrated—can be quickly and efficiently analyzed by generative AI.
    The principal drawback of such analysis is the time and cost involved, in addition
    to limited control over the tool, which could be modified or updated at any time
    by an external party.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个关键时刻，我们必须认识到，当ChatGPT被询问关于情感分析或任何它因“阅读”理解能力而天生能够执行的任务时，它的典型建议通常围绕指导你编写特定的代码来完成当前任务。该模型可能会强调传统NLP方法的优点，强调它们在分析细微和特定数据等方面的能力。然而，在实践中，遇到的大部分数据相对标准，并且主要是英语，正如所展示的，这些数据可以通过生成式AI快速有效地分析。这种分析的主要缺点是涉及的时间和成本，以及对外部方可能随时修改或更新的工具的有限控制。
- en: A common criticism of generative AIs is their “black box” nature, offering limited
    transparency in how responses are generated and on what basis. This argument is
    valid when comparing the performance of generative AIs to basic NLP tools like
    keyword searches. However, it becomes less convincing once we begin to use a trained
    language model of any size. Nevertheless, could it be that generative AIs, with
    their advanced “reading” capabilities, represent the best option for tackling
    NLP tasks? A year ago (before API access to ChatGPT 4 was available), we conducted
    a similar test using earlier OpenAI models, and the outcomes were unimpressive.
    We had a preference for conventional NLP methodologies. However, with the advancements
    in generative AI technology, our certainty on this matter has waned.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 对生成式AI的常见批评是其“黑箱”性质，在响应生成方式和依据方面提供有限的可透明性。当将生成式AI的性能与基本NLP工具如关键词搜索进行比较时，这种论点是有效的。然而，一旦我们开始使用任何规模的训练语言模型，这种论点就变得不那么有说服力了。尽管如此，是否可以认为，具有高级“阅读”能力的生成式AI是解决NLP任务的最佳选择？一年前（在ChatGPT
    4 API的API访问可用之前），我们使用早期的OpenAI模型进行了类似的测试，结果并不令人印象深刻。我们更倾向于传统的NLP方法。然而，随着生成式AI技术的进步，我们对这一问题的信心有所减弱。
- en: With that said, let’s proceed to explore sentiment analysis using traditional
    and well-established machine learning methods. In the next section, we will examine
    whether, with the help of pretrained models, we can achieve results as compelling
    as those provided by the ChatGPT 4 API.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 说到这里，让我们继续探讨使用传统和成熟的机器学习方法进行情感分析。在下一节中，我们将探讨借助预训练模型，我们能否达到ChatGPT 4 API所提供的结果那样引人入胜。
- en: 6.2.4 Sentiment analysis with machine learning
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.4 使用机器学习进行情感分析
- en: Previously, you learned how to conduct the simplest forms of sentiment analysis
    using methods such as frequency analysis, keyword searches, or dictionary-based
    approaches. While mastering these foundational techniques remains crucial, particularly
    for less commonly studied languages, the reality is that for the majority of everyday
    tasks, more sophisticated methods, such as machine learning, are preferred.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，你学习了如何使用频率分析、关键词搜索或基于词典的方法等最简单的情感分析方法。虽然掌握这些基础技术仍然至关重要，尤其是对于不太常见的研究语言，但现实是，对于大多数日常任务，更复杂的方法，如机器学习，更受欢迎。
- en: 'Machine learning has been around for some time now and should not intimidate
    anyone who dares to call themselves a data analyst. The era when proficiency in
    Excel sufficed is behind us; today, teaching your computer to recognize patterns
    has become a routine task. Thankfully, with the advent of new technologies, libraries,
    pipelines, and models, effective utilization has become significantly more accessible
    than in the past. While gaining an understanding of the underlying mechanics,
    such as matrix multiplication, is beneficial, and we encourage delving into these
    concepts, a deep technical grasp is no longer a prerequisite for using these models
    effectively. This situation is analogous to driving a car: knowing how the engine
    works isn’t necessary to be a competent driver, but in certain scenarios, such
    knowledge could help you avoid accidents or prevent you from being robbed by your
    car mechanic. And by no means do you have to construct the car in order to drive
    it! Most people acquire vehicles through purchase and sale transactions. Pretrained
    machine learning models are even more accessible, with many available online for
    free.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习已经存在了一段时间，不应该让那些自称数据分析师的人感到害怕。那个只要精通Excel就足够了的年代已经过去了；如今，教会计算机识别模式已经成为一项常规任务。幸运的是，随着新技术的出现，库、管道和模型，有效利用这些模型比过去容易得多。虽然了解底层机制，如矩阵乘法，是有益的，我们鼓励深入研究这些概念，但深入的技术掌握不再是有效使用这些模型的先决条件。这种情况类似于开车：了解发动机的工作原理并不是成为一名合格司机的必要条件，但在某些情况下，这种知识可以帮助你避免事故或防止你的汽车修理工欺骗你。而且，你不必自己组装汽车就能驾驶它！大多数人通过购买和销售交易获得车辆。预训练的机器学习模型甚至更容易获得，许多模型都可以在线免费获得。
- en: Where can I find my model?
  id: totrans-73
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 我在哪里可以找到我的模型？
- en: So, what are your options when searching for a new, shiny, fast, safe, and collision-free
    model? As always, you could resort to a good old-fashioned web browser, or save
    yourself some time by discussing your requirements with the generative AI of your
    choice (Gemini is recommended for reasons mentioned earlier). However, it’s likely
    that all these efforts will, in any case, direct you to the Hugging Face website
    ([https://huggingface.co/](https://huggingface.co/)).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在寻找一个新、亮、快、安全且无碰撞的模型时，您有哪些选择？一如既往，您可以使用传统的网页浏览器，或者通过与您选择的生成式AI（如Gemini，如前所述推荐）讨论您的需求来节省时间。然而，所有这些努力很可能会在任何情况下都将您引导到Hugging
    Face网站([https://huggingface.co/](https://huggingface.co/))。
- en: The Hugging Face website serves as a central hub for AI practitioners, offering
    access to a wealth of resources tailored to NLP and machine learning. At its core
    is the Model Hub, where users can explore and download a wide array of pretrained
    models suitable for various NLP tasks, such as sentiment analysis, text generation,
    and language translation. The website also features comprehensive documentation
    and tutorials to assist developers in implementing these models in their projects.
    Additionally, the Hugging Face platform encourages community engagement, allowing
    users to share their own models and collaborate with others.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Hugging Face网站为AI从业者提供了一个中央枢纽，提供针对自然语言处理和机器学习的丰富资源。其核心是模型库，用户可以探索和下载适用于各种NLP任务的预训练模型，例如情感分析、文本生成和语言翻译。该网站还提供全面的文档和教程，以帮助开发者将这些模型集成到他们的项目中。此外，Hugging
    Face平台鼓励社区参与，使用户能够分享自己的模型并与他人合作。
- en: 'While Hugging Face models are powerful tools for advancing NLP tasks, you should
    proceed with caution. Concerns have been raised regarding the potential for some
    models to harbor vulnerabilities or malicious code. Although the platform conducts
    malware scans on uploaded content and actively works to remove any malicious code,
    the arms race in cybersecurity is ongoing. Malicious actors continuously seek
    new security loopholes to exploit. To avoid becoming an unwitting victim in this
    cyber conflict, it’s crucial to proactively safeguard your security. The following
    list of ten security commandments is applicable not only to Hugging Face models
    but to any model (or software) downloaded from the web:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Hugging Face模型是推进NLP任务的强大工具，但您应该谨慎行事。已经有人提出了一些模型可能包含漏洞或恶意代码的担忧。尽管该平台对上传的内容进行恶意软件扫描并积极移除任何恶意代码，但网络安全竞赛仍在继续。恶意行为者不断寻求新的安全漏洞以利用。为了避免成为这场网络冲突的无意识受害者，主动保护您的安全至关重要。以下十项安全戒律不仅适用于Hugging
    Face模型，也适用于从网络下载的任何模型（或软件）：
- en: '*Use verified models*—Prefer models verified by the platform or those from
    reputable and known organizations.'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*使用经过验证的模型*—优先选择平台验证的模型或来自知名组织的模型。'
- en: '*Review model documentation*—Carefully read the model’s documentation for potential
    red flags.'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*审查模型文档*—仔细阅读模型的文档，寻找潜在的红旗。'
- en: '*Check contributor reputation*—Research the model’s contributors to ensure
    they are trustworthy.'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*检查贡献者声誉*—研究模型的贡献者以确保他们是可信赖的。'
- en: '*Conduct security assessments*—Use security tools to scan for vulnerabilities
    or malicious code within the model.'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*进行安全评估*—使用安全工具扫描模型中的漏洞或恶意代码。'
- en: '*Isolate testing*—Test new models in a safe, isolated environment away from
    sensitive data or systems.'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*隔离测试*—在安全、隔离的环境中测试新模型，远离敏感数据或系统。'
- en: '*Follow community feedback*—Pay attention to the community feedback and reports
    about specific models or contributors.'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*关注社区反馈*—关注关于特定模型或贡献者的社区反馈和报告。'
- en: '*Update regularly*—Keep your models and their dependencies up to date to ensure
    you have the latest security patches.'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*定期更新*—保持您的模型及其依赖项的最新状态，以确保您拥有最新的安全补丁。'
- en: '*Limit permissions*—When integrating models into your systems, grant them the
    least privileges necessary to perform their function.'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*限制权限*—在将模型集成到您的系统中时，授予它们执行其功能所需的最小权限。'
- en: '*Use encryption*—Encrypt sensitive data to protect it in case of accidental
    exposure by a malicious model.'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*使用加密*—加密敏感数据，以防恶意模型意外泄露。'
- en: '*Stay informed*—Regularly follow updates and security advice from Hugging Face
    and the broader AI community.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*保持信息更新*—定期关注Hugging Face和更广泛的AI社区的最新更新和安全建议。'
- en: Another popular option for finding an applicable model is GitHub (https://github.com/).
    This vast repository hosts a multitude of pretrained models shared by developers
    and researchers from around the world. While GitHub offers an extensive range
    of models for various tasks, you should approach it with the same caution advised
    for Hugging Face models. The open nature of GitHub means that anyone can upload
    code, which could potentially include vulnerabilities or malicious content. These
    ten commandments serve as a guide to achieving maximum security.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个寻找适用模型的流行选项是GitHub（https://github.com/）。这个庞大的仓库托管着来自世界各地开发者和研究者的众多预训练模型。虽然GitHub为各种任务提供了广泛的选择，但你应该像对待Hugging
    Face模型一样谨慎对待它。GitHub的开放性意味着任何人都可以上传代码，这可能会包含潜在的安全漏洞或恶意内容。这十诫可以作为实现最大安全的指南。
- en: What if the model I need does not exist?
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 如果我需要的模型不存在怎么办？
- en: So much for theory, but real life is much more challenging. What should you
    do if the new, shiny, fast, safe, and collision-free model of your dreams doesn’t
    exist? Let’s revisit our example. If our reviews were written in standard English,
    finding a relevant pretrained model to perform sentiment analysis would be straightforward.
    However, the fact that our input is in Portuguese presents us with an opportunity
    to explore additional options.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 理论上是这样，但现实生活要复杂得多。如果你的梦想中的新、亮、快、安全且无碰撞的模型不存在，你应该怎么办？让我们回顾一下我们的例子。如果我们的评论是用标准英语写的，找到执行情感分析的预训练模型会很简单。然而，我们的输入是葡萄牙语，这为我们探索额外的选项提供了机会。
- en: What alternatives do we have for conducting the desired analysis, especially
    when dealing with less commonly used languages? What if our task is really fancy,
    like assessing how politically correct a joke is? Or what if we combine the two,
    and are dealing with the task of assessing the political correctness of a joke
    written in Korean, say, in its northern dialect? (Before you go any further, we
    recommend consulting your favorite generative AI about the potential implications
    of developing such a model and considering whether you really should get involved.)
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在执行所需分析时有哪些替代方案，尤其是在处理不太常用的语言时？如果我们的任务非常复杂，比如评估一个笑话的政治正确性如何？或者如果我们结合两者，处理评估用韩国语（比如，北方方言）写的笑话的政治正确性的任务呢？（在你继续之前，我们建议咨询你最喜欢的生成式AI关于开发此类模型的潜在影响，并考虑你是否真的应该参与其中。）
- en: 'Here are some options:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有一些选项：
- en: '*Search for a suboptimal model*—This should be your starting point, no matter
    how uncommon your task or language is. It’s always worth checking whether someone
    has already tackled a similar, but maybe not identical, challenge. Why reinvent
    the wheel? Explore resources like the Hugging Face Model Hub and GitHub, use a
    web browser, or enlist generative AI to assist in your search. While you might
    not be completely satisfied with any existing models you find, they can provide
    valuable benchmarks for comparing your further efforts.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*寻找次优模型*——无论你的任务或语言多么不常见，这都应该是你的起点。总是值得检查是否有人已经解决了类似的，但可能不是完全相同的挑战。为什么要重新发明轮子呢？探索像Hugging
    Face模型库和GitHub这样的资源，使用网络浏览器，或者请生成式AI协助你的搜索。虽然你可能对找到的任何现有模型都不完全满意，但它们可以为你进一步的努力提供有价值的基准。'
- en: Pros of this approach include time efficiency, as it saves you from starting
    absolutely from scratch. Additionally, it offers an opportunity for learning and
    improvement by analyzing existing models. However, cons might include the challenge
    of finding a perfect match for your specific needs, limitations in model performance
    or adaptability, and the risk of depending on a model that may not be actively
    maintained or updated.
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这种方法的优点包括时间效率，因为它可以让你避免从头开始。此外，它还提供了通过分析现有模型进行学习和改进的机会。然而，缺点可能包括寻找完全符合你特定需求的完美匹配的挑战，模型性能或适应性的限制，以及依赖于可能没有积极维护或更新的模型的风险。
- en: '*Translating input to English*—This is a practical approach for conducting
    NLP tasks on less common languages, leveraging automatic translation tools and
    applying English-trained models. This method benefits from the extensive availability
    and sophistication of models for English, enhancing the potential for accurate
    analysis. However, it carries the risk of losing nuances and cultural context,
    possibly introducing errors or biases due to translation imperfections. Generative
    AIs can mitigate some of these challenges by providing more accurate translations
    and preprocessing the text to align better with English-trained models, thus preserving
    more original meaning and reducing translation-related inaccuracies.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*将输入翻译成英语*—这是一种在较少见语言上执行NLP任务的实用方法，利用自动翻译工具并应用英语训练的模型。这种方法受益于英语模型的广泛可用性和复杂性，增强了准确分析的可能性。然而，它存在失去细微差别和文化背景的风险，可能由于翻译不完美而引入错误或偏见。生成式AI可以通过提供更准确的翻译并预处理文本以更好地与英语训练模型对齐来减轻这些挑战，从而保留更多原始意义并减少与翻译相关的误差。'
- en: '*Use multilingual models*—If you can’t find a model fine-tuned specifically
    for your task and language, another effective approach is to use multilingual
    models such as XLM-RoBERTa or Multilingual BERT. These models are trained on vast
    datasets covering a wide array of languages, enabling them to understand and process
    multiple languages simultaneously without the need for language-specific training.
    This approach makes them highly versatile and an effective solution when a task-specific,
    language-specific model is unavailable. The primary advantage of using multilingual
    models lies in their broad applicability, saving the effort of developing or finding
    models tailored to each language, and offering respectable performance across
    various NLP tasks. However, these models may not match the performance of specialized
    models in certain tasks or languages due to their generalized nature. Additionally,
    customizing them for highly specific or nuanced tasks can be complex.'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*使用多语言模型*—如果你找不到针对你的任务和语言专门微调的模型，另一种有效的方法是使用多语言模型，如XLM-RoBERTa或多语言BERT。这些模型在涵盖广泛语言的大量数据集上训练，使它们能够同时理解和处理多种语言，而无需针对特定语言进行训练。这种方法使它们非常灵活，当没有特定任务或语言的模型可用时，它们是一个有效的解决方案。使用多语言模型的主要优势在于它们的广泛适用性，节省了为每种语言开发或寻找模型的努力，并在各种NLP任务中提供可接受的表现。然而，由于它们的通用性，这些模型在某些任务或语言上的性能可能无法与专用模型相匹配。此外，为高度特定或细微的任务进行定制可能很复杂。'
- en: '*Utilize zero-shot learning models*—These models, which are trained to understand
    instructions in natural language, excel at generalizing to tasks they haven’t
    been explicitly trained on by leveraging semantic knowledge and relationships
    between concepts. This allows them to infer, for example, the sentiment of texts
    in categories or contexts they’ve never directly encountered, based on understanding
    gained from related tasks. However, while zero-shot learning models provide the
    flexibility to tackle a wide range of tasks with a single model, their performance
    might not always match that of models fine-tuned on specific tasks, especially
    in highly nuanced or domain-specific contexts.'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*利用零样本学习模型*—这些模型经过训练，能够理解自然语言中的指令，在利用语义知识和概念之间的关系泛化到它们未明确训练的任务上表现出色。这使得它们能够根据从相关任务中获得的理解，推断例如从未直接接触过的类别或上下文中的文本的情感。然而，尽管零样本学习模型提供了使用单个模型处理广泛任务的灵活性，但它们的性能可能并不总是与针对特定任务微调的模型相匹配，尤其是在高度细微或特定领域的上下文中。'
- en: '*Fine-tune an existing model*—This is a practical option when resources for
    data collection are limited, allowing you to enhance a pretrained model with task-specific
    adjustments. This method is time-efficient, cost-effective, and it lowers the
    barrier to advanced modeling techniques. However, it depends on the pretrained
    model’s relevance to your task and the quality of labeled data used for fine-tuning.
    There’s also a risk of overfitting if adjustments aren’t made correctly.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*微调现有模型*—当数据收集资源有限时，这是一个实用的选项，允许你通过任务特定的调整来增强预训练模型。这种方法时间效率高，成本低，并降低了高级建模技术的门槛。然而，这取决于预训练模型与你的任务的关联性以及用于微调的标记数据的质量。如果调整不当，也存在过拟合的风险。'
- en: For NLP tasks, you might consider fine-tuning one of the existing LLMs, such
    as the widely recognized BERT, available on the Hugging Face platform. Such LLMs
    have been pretrained on extensive text corpora and possess a comprehensive understanding
    of language, which can be further tailored to specific NLP tasks using a comparatively
    smaller dataset. This can reduce the amount of effort and expertise needed, though
    computational resources and understanding of model behavior are still required.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于NLP任务，你可能考虑微调现有的LLM之一，例如在Hugging Face平台上广泛认可的BERT。这类LLM已经在大量的文本语料库上进行了预训练，并具有对语言的全面理解，可以通过相对较小的数据集进一步定制以适应特定的NLP任务。这可以减少所需的工作量和专业知识，尽管仍然需要计算资源和理解模型行为。
- en: As usual, generative AI can significantly facilitate this process by offering
    their assistance and expertise. But in this case, they can offer even more. As
    all generative AIs discussed in this book are LLMs themselves, they can serve
    as a linguistic foundation for the model you are developing. In other words, you
    can fine-tune generative AI to your specific task!
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如往常一样，生成式AI可以通过提供帮助和专业知识来显著简化这一过程。但在这个案例中，它们可以提供更多。由于本书中讨论的所有生成式AI本身都是LLM，它们可以成为你正在开发的模型的语料库基础。换句话说，你可以微调生成式AI以适应你的特定任务！
- en: '*Train your own model*—This option involves collecting a sufficient amount
    of labeled data and training the model yourself. This approach allows for customizing
    and optimizing the model to fit the specific nuances of your dataset and task.
    The main advantage is the potential for high accuracy and relevance to your particular
    use case, as the model learns directly from data reflective of your domain. However,
    the drawbacks include the significant time, effort, and expertise required to
    gather labeled data and design and effectively train the model. These challenges
    persist regardless of the assistance provided by generative AI. Additionally,
    this method demands substantial computational resources.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*训练自己的模型*——这个选项涉及收集足够数量的标记数据并自行训练模型。这种方法允许根据数据集和任务的特定细微差别定制和优化模型。主要优势是模型直接从反映你领域的数据中学习，因此具有高准确性和针对特定用例的相关性。然而，缺点包括收集标记数据、设计和有效训练模型所需的显著时间、努力和专业知识。这些挑战在生成式AI提供的任何帮助下仍然存在。此外，这种方法还需要大量的计算资源。'
- en: Let’s test a few of these options and compare their results. Fine-tuning an
    existing model and training one from scratch demands greater expertise and falls
    beyond this book’s scope. However, should you opt for this route, generative AI
    can offer significant assistance by providing guidance, resources, and tools tailored
    to your needs. Additionally, you can refer to *Build a Large Language Model (From
    Scratch)* by Sebastian Raschka (Manning, 2024) for further instructions and insights
    into navigating these advanced techniques.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们测试这些选项中的几个，并比较它们的结果。微调现有模型和从头开始训练需要更多的专业知识，这超出了本书的范围。然而，如果你选择这条路线，生成式AI可以通过提供定制化的指导、资源和工具来提供重大帮助。此外，你可以参考Sebastian
    Raschka的《构建大型语言模型（从头开始）》一书（Manning，2024），以获取进一步的操作指导和洞察力。
- en: 6.2.5 Sentiment analysis with a suboptimal model
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.5 使用次优模型进行情感分析
- en: To try out the first option, searching for a suboptimal model, you could start
    by searching for an existing sentiment classifier for Portuguese, but this attempt
    proved unsuccessful (as of March 2024). Consultations with ChatGPT 4 and Gemini
    Advanced yielded some suggestions, but none fully met our requirements, and many
    of the provided links were invalid. Both generative AIs eventually advised manually
    scouring the Hugging Face website and GitHub for suitable models, a task that
    unfortunately led to no significant findings.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了尝试第一种选项，即寻找一个次优模型，你可以先搜索现有的葡萄牙语情感分类器，但这次尝试并未成功（截至2024年3月）。与ChatGPT 4和Gemini
    Advanced的咨询提供了一些建议，但没有一个完全满足我们的要求，而且许多提供的链接都是无效的。两个生成式AI最终建议手动在Hugging Face网站和GitHub上搜索合适的模型，但遗憾的是，这项任务并没有带来任何显著发现。
- en: Consequently, you could opt for a less-than-ideal solution suggested by Gemini—the
    FinBERT-PT-BR classifier, which was trained on Portuguese financial news. Despite
    this not being the ideal dataset for analyzing customer reviews, a human-in-the-loop
    approach and error monitoring might help you identify and address the model’s
    shortcomings. All in all, it might be useful to proceed with this model anyway
    and assess its efficacy.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你可以选择Gemini提出的次优解决方案——在葡萄牙语财经新闻上训练的FinBERT-PT-BR分类器。尽管这不是分析客户评价的理想数据集，但人工介入的方法和错误监控可能有助于你识别和解决模型的不足。总的来说，即使如此，继续使用此模型并评估其有效性可能还是有用的。
- en: 'First, let’s become fully aware of the potential drawbacks of this approach.
    To achieve this, you could start by asking ChatGPT the following question:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们充分认识到这种方法的潜在缺点。为了实现这一点，你可以先向ChatGPT提出以下问题：
- en: '**![image](../Images/Init-MA.png)**I have a dataframe with a column `review_comment_message`
    containing customer reviews in Portuguese. I want to extract positive reviews
    using a sentiment classifier found on this website: [https://huggingface.co/lucas-leme/FinBERT-PT-BR](https://huggingface.co/lucas-leme/FinBERT-PT-BR)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '**![image](../Images/Init-MA.png)**我有一个包含客户评价的`review_comment_message`列的数据框，这些评价是用葡萄牙语写的。我想使用这个网站上找到的情感分类器来提取正面评价：[https://huggingface.co/lucas-leme/FinBERT-PT-BR](https://huggingface.co/lucas-leme/FinBERT-PT-BR)'
- en: What are the potential drawbacks of using this model for my task?
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此模型进行我的任务的潜在缺点是什么？
- en: '**![image](../Images/Response.png)**[...] Potential Drawbacks:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**![image](../Images/Response.png)**[...] 可能的缺点：'
- en: 'Domain Mismatch: FinBERT-PT-BR is specialized for financial contexts, which
    might not align well with general customer reviews.'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 领域不匹配：FinBERT-PT-BR专门用于财务环境，这可能与一般客户评价不太相符。
- en: 'Sentiment Analysis Complexity: The model may struggle with nuances like sarcasm
    or cultural expressions, affecting accuracy.'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 情感分析复杂性：该模型可能在讽刺或文化表达等细微差别上遇到困难，影响准确性。
- en: 'Language Specificity: Regional variations in Portuguese could lead to inconsistent
    performance across different Portuguese-speaking regions.'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 语言特异性：葡萄牙语的区域差异可能导致不同葡萄牙语地区的表现不一致。
- en: 'Model Biases: Pretrained models carry inherent biases and limitations from
    their training data, potentially skewing results.'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 模型偏差：预训练模型会从其训练数据中携带固有的偏差和局限性，这可能会扭曲结果。
- en: 'Computational Demands: Processing a large volume of reviews with a transformer-based
    model requires substantial computing resources.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算需求：使用基于transformer的模型处理大量评价需要大量的计算资源。
- en: 'Ethical Considerations: Ensuring ethical and privacy-respecting use of customer
    reviews is crucial.'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 道德考量：确保对客户评价进行道德和尊重隐私的使用至关重要。
- en: In short, while FinBERT-PT-BR offers an intriguing solution, its financial focus,
    potential language and regional limitations, computational demands, and the need
    for ethical diligence present notable challenges for extracting positive reviews
    from a general customer feedback dataset.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，虽然FinBERT-PT-BR提供了一个有趣的解决方案，但其财务焦点、潜在的语言和区域局限性、计算需求以及进行道德审慎的必要性，为从一般客户反馈数据集中提取正面评价带来了显著的挑战。
- en: 'This conversation illustrates the potential benefits of discussing your analytical
    ideas with generative AI. Notably, ChatGPT was able to offer insightful comments
    on a resource it was previously unfamiliar with. Moreover, ChatGPT asserted that
    it didn’t use the provided link to further investigate the model’s website for
    additional information. This prompts the question: how did it know? The explanation
    given upon inquiry was remarkable:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这场对话说明了与生成式AI讨论你的分析想法的潜在好处。值得注意的是，ChatGPT能够对一个它之前不熟悉的资源提出有见解的评论。此外，ChatGPT坚称它没有使用提供的链接进一步调查该模型的网站以获取更多信息。这引发了一个问题：它是如何知道的？在询问后给出的解释是惊人的：
- en: You caught me in a bit of an overextension based on the name “FinBERT-PT-BR,”
    inferring from the “Fin” prefix, which commonly denotes finance-related models
    (like FinBERT being a well-known adaptation of BERT for financial texts). The
    assumption was that this model, given its name, is specialized for analyzing financial
    text in Portuguese. Such naming conventions are typical for domain-specific versions
    of BERT and other language models, where the prefix or suffix indicates the model’s
    specialized training corpus or intended application area. However, without directly
    accessing the provided link or having specific knowledge of this model in my training
    data up to my last update in April 2023, I relied on these conventions to inform
    my response.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 您根据“FinBERT-PT-BR”这个名字进行了一些过度推断，从“Fin”前缀推断，这通常表示与金融相关的模型（例如，FinBERT是BERT在金融文本上的一个知名改编）。这种假设是，鉴于其名称，这个模型专门用于分析葡萄牙语的金融文本。这种命名规范对于BERT和其他语言模型的特定领域版本来说是典型的，其中前缀或后缀表示模型的专门训练语料库或预期应用领域。然而，由于我截至2023年4月的最后更新没有直接访问提供的链接或对这种模型的具体知识，我依赖这些规范来提供我的回答。
- en: If this isn’t a demonstration of pure intelligence, then I’m not sure what is.
    However, even if you don’t share my sense of wonder, it should be clear by now
    that consulting advanced generative AIs like ChatGPT 4 when planning your research
    is far from a waste of time.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果这不是纯粹智能的展示，那么我就不确定什么是了。然而，即使你不分享我的惊奇感，现在应该很清楚，在规划你的研究时咨询像ChatGPT 4这样的高级生成式AI绝对不是浪费时间。
- en: Generative AI interprets external resources
  id: totrans-119
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 生成式AI解释外部资源
- en: It could be advantageous to inquire with generative AI whether using a specific
    external resource (such as a model, database, etc.) for your research is reasonable,
    or to discuss potential drawbacks associated with a particular resource. Even
    if the generative AI is encountering the resource for the first time, there’s
    a possibility it can deduce the resource’s contents and how it might influence
    your analysis.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 询问生成式AI是否使用特定的外部资源（如模型、数据库等）进行你的研究是合理的，或者讨论与特定资源相关的潜在缺点可能是有益的。即使生成式AI第一次遇到这个资源，也有可能推断出资源的内容以及它可能如何影响你的分析。
- en: 'Let’s ask our generative AI to prepare a code snippet. We used the following
    prompt in the same ChatGPT session: “Propose a code snippet to utilize this model
    to extract positive reviews from my data.” The obtained snippet is shown in the
    following listing.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们的生成式AI准备一个代码片段。我们在同一个ChatGPT会话中使用了以下提示：“提出一个代码片段，利用这个模型从我的数据中提取正面评论。”获得的代码片段如下所示。
- en: Listing 6.2 Extracting positive reviews with the help of a suboptimal model
  id: totrans-122
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.2 使用次优模型提取正面评论
- en: '[PRE1]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This snippet was provided alongside instructions on how to install the required
    libraries and a detailed comment emphasizing the importance of consulting the
    model’s documentation to understand the model’s output. Specifically, it was necessary
    to manually replace `LABEL_1` with an appropriate label indicating positive reviews,
    in our case, `POSITIVE`. Generative AI also detailed the use of exception handling
    around the classifier to manage any potential errors during processing, such as
    inputs that were too long or unexpected.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码片段提供了如何安装所需库的说明，以及一个强调咨询模型文档以了解模型输出的重要性的详细注释。具体来说，需要手动将`LABEL_1`替换为适当的标签，表示正面评论，在我们的例子中是`POSITIVE`。生成式AI还详细说明了在分类器周围使用异常处理来管理处理过程中可能出现的任何潜在错误，例如输入过长或意外。
- en: In the Jupyter notebook from the book’s GitHub repository, you can find this
    code manually adapted and applied to analyze the first 500 reviews from our testing
    dataset. As before, the `review_score` variable was employed to evaluate the sensitivity
    and specificity of the classifier. The FinBERT-PT-BR model recognized positive
    reviews with a sensitivity of 0.56 and a specificity of 0.93\. This performance
    surpasses simple keyword-based classification, yet it does not reach the efficacy
    of the results achieved through direct application of ChatGPT 4’s language capabilities.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在书籍GitHub仓库的Jupyter笔记本中，你可以找到这个代码手动修改并应用于分析测试数据集的前500条评论。和以前一样，`review_score`变量被用来评估分类器的敏感性和特异性。FinBERT-PT-BR模型以0.56的敏感性和0.93的特异性识别正面评论。这种性能超过了基于简单关键词的分类，但还没有达到通过直接应用ChatGPT
    4的语言能力所达到的效果。
- en: 6.2.6 Sentiment analysis on translated inputs
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.6 翻译输入的情感分析
- en: Now you may want to explore whether translating the input and employing a sentiment
    classifier for English texts could produce better results. The pros and cons of
    such a solution were listed in section 6.2.4, so let’s jump to implementation
    right away.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可能想探索翻译输入并使用英语文本的情感分类器是否会产生更好的结果。这种解决方案的优缺点已在第6.2.4节中列出，所以让我们直接进入实施阶段。
- en: 'We began with a specific prompt: “Write a code snippet to extract positive
    reviews from our dataset. Clean the reviews and translate them to English and
    then apply the most appropriate sentiment classifier for English.” Then we explored
    several options to identify the best method for translating the input, aiming
    for a simple and reliable solution that doesn’t require registration or payment.
    Ultimately, with generative AI’s help, we developed the following code snippet.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从一个具体的提示开始：“编写一个代码片段，从我们的数据集中提取正面评论。清理评论并将它们翻译成英语，然后应用最合适的英语情感分类器。”然后我们探索了几个选项，以确定翻译输入的最佳方法，目标是找到一个简单且可靠的解决方案，不需要注册或付费。最终，在生成式AI的帮助下，我们开发了以下代码片段。
- en: Listing 6.3 Sentiment analysis on translated inputs
  id: totrans-129
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.3 对翻译输入进行情感分析
- en: '[PRE2]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The code employs the Meta model for translation, m2m100_418M, which supports
    multiple languages, including Portuguese and English. For sentiment analysis,
    it uses the distilbert-base-uncased-finetuned-sst-2-english model. Both models
    were recommended by generative AI for their broad applicability and performance.
    However, it was noted that we might consider exploring other models better tailored
    to our specific requirements.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 代码使用Meta模型进行翻译，m2m100_418M，支持包括葡萄牙语和英语在内的多种语言。对于情感分析，它使用distilbert-base-uncased-finetuned-sst-2-english模型。这两个模型都由生成式AI推荐，因为它们的广泛适用性和性能。然而，需要注意的是，我们可能需要考虑探索更适合我们特定需求的其它模型。
- en: While the code executes smoothly, translating 500 reviews took some time, so
    patience is advised if you plan to replicate this process. Using the `review_score`
    variable, we again evaluated the sensitivity and specificity of this method for
    identifying positive reviews. The corresponding code can be found in the Jupyter
    notebook in the book’s GitHub repository. Remarkably, this approach of translating
    input achieved a sensitivity of 0.86 and specificity of 0.89 for correctly classifying
    positive reviews, offering the best results thus far and proving comparable to
    those obtained using ChatGPT 4’s inherent language capabilities. Not bad, indeed.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然代码执行顺利，但翻译500条评论花费了一些时间，所以如果你打算复制这个过程，请耐心等待。我们再次使用`review_score`变量评估了这种方法在识别正面评论时的敏感性和特异性。相应的代码可以在书籍GitHub仓库中的Jupyter笔记本中找到。值得注意的是，这种翻译输入的方法在正确分类正面评论时达到了0.86的敏感性和0.89的特异性，是目前为止的最佳结果，并且与使用ChatGPT
    4的内置语言能力获得的结果相当。确实不错。
- en: 6.2.7 Sentiment analysis with multilingual models
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.7 使用多语言模型进行情感分析
- en: Our next step is to explore whether using multilingual models for sentiment
    analysis could yield better results. The characteristics of such models, together
    with their potential drawbacks, were presented in section 6.2.4, so let’s proceed
    with the implementation.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们下一步要探索的是，使用多语言模型进行情感分析是否会产生更好的结果。这类模型的特点以及它们的潜在缺点在第6.2.4节中已有介绍，所以让我们继续实施。
- en: 'We used the prompt, “Now, I want to repeat this exercise but instead of translating
    the input, I’d rather use a multilingual model. Could you write a relevant code
    snippet for me?” Unfortunately, the obtained code didn’t work immediately, due
    to package dependency issues. Rather than manually resolving these issues or meticulously
    reviewing the entire error log, we simply copied the last few lines of the error
    message into the generative AI chat window for assistance. ChatGPT clarified the
    issue in plain English—far more helpful than the typical technical jargon found
    in error messages—and suggested two solutions: either downgrading one package
    or upgrading another, which promptly resolved the issue.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了提示，“现在，我想重复这个练习，但不是翻译输入，我更愿意使用多语言模型。你能为我编写一个相关的代码片段吗？”不幸的是，由于包依赖问题，获得的代码无法立即工作。我们并没有手动解决这些问题或仔细审查整个错误日志，而是简单地复制了错误消息的最后几行到生成式AI聊天窗口以寻求帮助。ChatGPT用简单的英语阐明了问题——比错误消息中常见的典型技术术语更有帮助——并提出了两个解决方案：要么降级一个包，要么升级另一个，这迅速解决了问题。
- en: As you progress through this book, you may encounter similar situations where
    packages evolve, and today’s code becomes deprecated tomorrow. Often, the solution
    involves minor adjustments, which could take mere seconds to implement but hours
    to figure out. With generative AI, you can move past endlessly scrolling through
    Stack Overflow for debugging tips.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 随着你在这本书中的学习进展，你可能会遇到类似的情况，其中软件包会演变，今天的代码明天就可能过时。通常，解决方案需要微小的调整，这些调整可能只需几秒钟就能实现，但可能需要数小时才能找到。有了生成式AI，你可以超越无休止地滚动Stack
    Overflow以获取调试提示。
- en: Generative AI is the ultimate tool for bug extermination
  id: totrans-137
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 生成式AI是除虫的终极工具
- en: Imagine the most deadly and ruthless bug spray. Multiply its effectiveness by
    a thousandfold, and you’re still not capturing the full extent of how adept generative
    AI is at tackling bugs! Instead of attempting to decode the error message yourself,
    simply paste it (or a fragment) into the model’s chat and request a translation
    into human language along with appropriate solutions. In the majority of instances,
    you’ll receive a swift and satisfactory response.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下最致命、最无情的杀虫剂。将其有效性乘以一千倍，你仍然无法捕捉到生成式AI在解决bug方面的全部熟练程度！与其试图自己解码错误信息，不如简单地将其（或片段）粘贴到模型的聊天中，并请求将其翻译成人类语言以及相应的解决方案。在大多数情况下，你会收到迅速且令人满意的回复。
- en: After smashing all the dependency bugs and correcting the output labels manually,
    we obtained the following working piece of code (don’t forget to install the required
    libraries).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在解决所有依赖项错误并手动纠正输出标签后，我们得到了以下可运行的代码片段（别忘了安装所需的库）。
- en: Listing 6.4 Sentiment analysis with a multilingual model
  id: totrans-140
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.4 使用多语言模型进行情感分析
- en: '[PRE3]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This script leverages the twitter-xlm-roberta-base-sentiment model to directly
    classify the sentiment of each review in the dataset, eliminating the need to
    translate them into English first. It achieves a sensitivity of 0.79 and specificity
    of 0.93, which are scores comparable to those achieved using ChatGPT 4’s innate
    language capabilities. This discovery suggests we’ve found a solution of similar
    quality that is both more cost-effective and faster than utilizing the generative
    AI API. However, before you rush to request a raise from your boss, let’s explore
    if we can surpass this performance by utilizing a zero-shot learning model.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 此脚本利用twitter-xlm-roberta-base-sentiment模型直接对数据集中的每个评论进行情感分类，无需先将它们翻译成英语。它达到了0.79的敏感度和0.93的特异性，这些分数与使用ChatGPT
    4的内在语言能力所达到的分数相当。这一发现表明，我们已经找到了一个质量相似但成本效益更高、速度更快的解决方案，比使用生成式AI API更优。然而，在你急忙向老板要求加薪之前，让我们探讨一下，我们是否可以通过利用零样本学习模型来超越这一性能。
- en: 6.2.8 Sentiment analysis with zero-shot learning models
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2.8 使用零样本学习模型进行情感分析
- en: As a reminder, zero-shot learning models are particularly well-suited for tasks
    where labeled training data is scarce or unavailable. These models can generalize
    to tasks they haven’t been explicitly trained on, making them ideal for classifying
    text into categories (such as sentiment analysis) without needing a dataset specific
    to that task. For extracting positive reviews from our dataset in Portuguese using
    a zero-shot learning approach, you can leverage models designed for multilingual
    understanding, such as those available through the Hugging Face Transformers library.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒一下，零样本学习模型特别适合于标记的训练数据稀缺或不可用的情况。这些模型可以泛化到它们未明确训练过的任务，使它们非常适合于将文本分类到类别中（如情感分析），而无需特定于该任务的数据库。对于使用零样本学习方法从我们的葡萄牙语数据集中提取正面评论，你可以利用为多语言理解设计的模型，例如通过Hugging
    Face Transformers库提供的模型。
- en: 'All this, and much more, you will learn when you ask generative AI a question
    similar to this one: “I want to extract positive reviews from my dataset with
    help of a zero-shot learning model. Reviews are in Portuguese. How do I achieve
    this?” In response, ChatGPT 4 generated the following code, which was adapted
    to our input data manually. To run the code, you will have to install the transformers
    library with the command `pip install transformers`.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些，以及更多，当你向生成式AI提出类似以下问题的时候，你将学到：“我想在零样本学习模型的帮助下从我的数据集中提取正面评论。评论是用葡萄牙语写的。我该如何实现这一点？”作为回应，ChatGPT
    4生成了以下代码，该代码已被手动调整以适应我们的输入数据。要运行此代码，您需要使用命令`pip install transformers`安装transformers库。
- en: Listing 6.5 Sentiment analysis with a zero-shot learning model
  id: totrans-146
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 列表6.5 使用零样本学习模型进行情感分析
- en: '[PRE4]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The code suggested by generative AI leverages the facebook/bart-large-mnli model,
    which is equipped to handle multilingual texts and has been trained on a variant
    of the Multi-Genre Natural Language Inference (MNLI) dataset. This enables the
    model to conduct zero-shot classification on texts in various languages, including
    Portuguese. ChatGPT, however, points out that this model serves merely as an example,
    and we may discover other models that could yield better results for specific
    datasets. For instance, the typeform/distilbert-base-uncased-mnli model is presented
    as an alternative that is smaller and faster, though potentially less precise.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: The effectiveness of the zero-shot learning model was evaluated using the `review_score`
    variable. The model achieved a sensitivity of 0.87 for identifying positive reviews
    and a specificity of 0.74\. While this performance is marginally inferior to that
    of a multilingual model, it remains sufficiently robust to warrant considering
    zero-shot learning models in your analysis.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.9 Comparing results of advanced sentiment analysis
  id: totrans-150
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the previous sections, we explored several methods for performing sentiment
    analysis using pretrained machine learning models. Initially, we leveraged ChatGPT
    4’s inherent language capabilities to identify positive reviews (section 6.2.3).
    This approach was followed by employing a suboptimal pretrained model tailored
    for sentiment analysis in Portuguese financial texts (section 6.2.5). Next, we
    utilized a sentiment classifier designed for English, applying it to translated
    inputs (section 6.2.6). To circumvent the errors and biases introduced by translation,
    we opted for a multilingual model (section 6.2.7) and a zero-shot learning model
    capable of supporting multiple languages (section 6.2.8). These methodologies
    were tested on a dataset of 500 non-empty reviews, using the `review_score` variable
    to evaluate the sensitivity and specificity of the classifications. All the results
    are gathered in table 6.3.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Table 6.3 Quality of sentiment analysis with different pretrained models
  id: totrans-152
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Sentiment analysis ( *n*=500) | Number of reviews classified as positive
    | Sensitivity | Specificity |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
- en: '| Reference review score  | 320 (63%) true positives'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '| 1  | 1  |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
- en: '| Basic keyword search  | 163 (33%)  | 0.45  | 0.9  |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
- en: '| ChatGPT 4 API  | 250 (50%)  | 0.74  | 0.93  |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
- en: '| Suboptimal model  | 193 (39%)  | 0.56  | 0.93  |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
- en: '| Translated inputs  | 295 (59%)  | 0.86  | 0.89  |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
- en: '| Multilingual model  | 265 (53%)  | 0.79  | 0.93  |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot learning model  | 325 (65%)  | 0.87  | 0.74  |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
- en: These results demonstrate that, in our tests, the multilingual model outperformed
    all others, uniquely surpassing the ChatGPT 4 API. A zero-shot learning model
    that supports multiple languages achieved results comparable to those of generative
    AI’s inherent language capabilities. Similarly, the method involving translating
    the input showed potential for high performance. Conversely, classifications based
    solely on keyword searches lagged significantly in sensitivity, though a more
    meticulous selection of keywords could potentially enhance its effectiveness.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: Notably, just a year ago, the outcome of such an evaluation would have differed
    substantially, with ChatGPT 3—then the sole option available via API—failing to
    match even the basic keyword analysis in performance. Just think what can be achieved
    if ChatGPT 5 is finally released!
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: 'To sum up, this section illustrated how to conduct sentiment analysis using
    a variety of advanced pretrained models. Selecting the appropriate methodology
    for your data and task may involve testing several options, typically on a smaller
    subset of data, to determine the most cost-effective strategy that could lead
    to the long-awaited promotion you’ve been aiming for (just imagine: no more Quantum
    Fluff disguise on Sundays!). Generative AI can facilitate this process by providing
    a list of options, discussing their advantages and disadvantages, writing the
    necessary code snippets to implement them, and then testing and summarizing the
    results. In certain scenarios, you might choose to directly utilize language capabilities
    by accessing their APIs or using them as a foundation to fine-tune your own model,
    although the latter option has not been explored in this book.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: 6.3 Text summarization
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the preceding sections, we successfully classified reviews based on their
    sentiment. The results obtained may not be entirely satisfactory in terms of efficiency,
    and additional analysis would be required to enhance the basic methods presented.
    However, let’s assume that your boss is content with the results and wishes to
    explore further. The question at hand is, what do customers most often complain
    about?
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: 'This task aligns exceptionally well with another NLP method you’re about to
    explore: text summarization. This technique aims to shorten long documents into
    more concise versions, maintaining the essential information and presenting it
    coherently. Utilizing approaches like rule-based methods or machine learning,
    text summarization enables users to swiftly capture the main concepts and pertinent
    details from large text collections.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1 How can you benefit from text summarization?
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can apply text summarization across a wide range of business scenarios
    to enhance efficiency, improve understanding, and streamline communication. Here
    are some examples:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: '*Customer support*—Automatically generating concise summaries of customer inquiries
    or feedback from emails, chat messages, or social media will facilitate quicker
    response times. Even if it’s widely anticipated that the feedback will concern
    complaints about Quantum Fluff, it is valuable to have it quantitatively confirmed.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*客户支持*—自动生成客户询问或来自电子邮件、聊天消息或社交媒体的反馈的简洁摘要，将有助于加快响应时间。即使普遍预期反馈将涉及对量子泡沫的投诉，但对其进行定量确认也是有价值的。'
- en: '*Executive briefings*—Summarizing key points from lengthy reports, financial
    analyses, or market research for a quick review by executives and decision-makers
    can assist your boss and his colleagues in guiding the company toward glory and
    financial success. If you succeed, you will get your share . . . in the glory.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*高管简报*—总结冗长报告、财务分析或市场研究的关键点，以便高管和决策者快速审阅，可以帮助您的老板和他的同事引导公司走向辉煌和财务成功。如果您成功，您将获得一份……荣耀的份额。'
- en: '*News aggregation*—Creating short summaries of news articles can benefit not
    just news aggregation apps or websites but also your company. After all, staying
    informed about developments in the Quantum Fluff market is a routine task for
    any fluff manufacturer that values its reputation.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*新闻聚合*—创建新闻文章的简短摘要不仅对新闻聚合应用或网站有益，也对您的公司有益。毕竟，了解量子泡沫市场的发展情况是任何重视其声誉的泡沫制造商的常规任务。'
- en: '*Legal document review*—You think lawyers and other legal professionals fall
    into ecstasy when reading through their dense legal jargon, don’t you? However,
    the reality is they would greatly appreciate being relieved of this burden. If
    you could develop a tool that summarizes legal documents, contracts, or case files,
    facilitating a quicker grasp of their essential contents, they might just honor
    you with a monument (which you can add to your pension plan, together with your
    glory shares gained earlier).'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*法律文件审查*—您认为律师和其他法律专业人士在阅读他们密集的法律术语时会陷入狂喜，不是吗？然而，现实是他们会非常感激能够减轻这种负担。如果您能开发出一个总结法律文件、合同或案件文件的工具，帮助更快地掌握其核心内容，他们可能会用纪念碑来表彰您（您可以将它添加到您的养老金计划中，连同您之前获得的荣耀股份一起）。'
- en: '*Academic research*—How about academics and researchers? Do they enjoy their
    scientific jargon? Perhaps, but a tool that summarizes academic papers or journals,
    enabling quick comprehension of the premise, methodology, results, and conclusions
    without reading the full text, would likely be valued by students, post-docs,
    and that part of the research community who is still hoping for tenure. Those,
    in particular, whose survival depends on reading and publishing swiftly.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*学术研究*—至于学者和研究人员呢？他们喜欢他们的科学术语吗？也许吧，但一个能够总结学术论文或期刊的工具，使人们能够快速理解前提、方法、结果和结论，而不必阅读全文，可能会受到学生、博士后以及那些仍然希望获得终身职位的科研人员的重视。特别是那些生存依赖于快速阅读和发表的人。 '
- en: '*Medical records summarization*—Health professionals represent another group
    that could greatly benefit from quick summaries, for instance of patient histories,
    lab reports, or clinical findings. This may facilitate faster diagnoses and improve
    treatment planning. But it’s not just doctors who would benefit—patients would
    too. Imagine how pleasant and humanizing it would be if your doctor had the time
    to actually engage in real conversation with you!'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*医疗记录摘要*—医疗专业人员是另一个可以从快速摘要中大大受益的群体，例如患者病史、实验室报告或临床发现。这可能有助于加快诊断并改善治疗计划。但受益的不仅仅是医生——患者也会受益。想象一下，如果您的医生有时间真正与您进行交谈，那将是多么愉快和人性化的体验！'
- en: '*Meeting minutes*—Text summarization techniques can streamline recorded discussions
    or meeting transcripts into concise, actionable summaries, emphasizing key decisions,
    action items, and discussion points. However, volunteering to develop such a tool
    carries its risks. What if your program uncovers a widely acknowledged yet unspoken
    truth within the company: that many of the meetings are, in fact, a sheer waste
    of time?'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*会议记录*—文本摘要技术可以将记录的讨论或会议记录简化为简洁、可操作的摘要，强调关键决策、行动项目和讨论点。然而，自愿开发这样的工具也伴随着风险。如果您的程序在公司内部揭露了一个众所周知但未公开的事实：许多会议实际上纯粹是浪费时间，那会怎样？'
- en: '*Email management*—Do you recall that spaghetti email conversation in your
    company about which coffee machine should be ordered for the office? Missing a
    few episodes of this soap opera would no longer be an issue if you had a tool
    capable of summarizing long email threads. This tool would distill the essence
    of discussions, decisions, or action items into a concise brief, perhaps starting
    with “Previously, in the New Coffee Machine saga . . .”'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Content marketing*—With the new Quantum Fluff feature to promote, no matter
    what, your marketing department is working their fingers to the bone. Why not
    help them by creating a tool that could generate summaries of blog posts, articles,
    or whitepapers to use in newsletters, social media, or marketing materials, engaging
    readers and encouraging them to explore the full content?'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Product reviews analysis*—Summarizing customer reviews and feedback on products
    or services may help to quickly identify trends, preferences, and areas of improvement.
    This objective aligns with what your boss is expecting from you, and in the following
    sections, we will guide you on how to meet those expectations.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These examples illustrate how text summarization can be a powerful tool for
    various industries, helping to save time, reduce information overload, and enhance
    decision-making processes.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.2 How can generative AI help in text summarization?
  id: totrans-182
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Generative AI offers significant potential in summarizing texts efficiently
    and effectively. By leveraging its deep understanding of language structure, context,
    and semantics, generative AI can process large volumes of textual information
    and condense it into shorter, coherent summaries. This capability is particularly
    useful for extracting the most important information and presenting it in an easily
    digestible form, saving you and your coworkers a lot of time and effort.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, generative AI’s advanced natural language processing capabilities
    allow it to generate two types of summaries:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '*Extractive summaries*—This approach involves selecting and compiling key phrases
    or sentences directly from the text to create a summary. For example, it can summarize
    a news article by extracting the most informative sentences that cover the who,
    what, when, where, and why.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Abstractive summaries*—These summaries reformulate the original text, often
    generating new phrases and sentences that weren’t in the initial document, to
    capture its essence more creatively and fluidly. An example would be condensing
    a novel’s plot into a brief overview that captures the main themes and plot points
    without directly quoting the text.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both types of summaries can be tailored for a specific level of detail and originality.
    Moreover, the adaptability of generative AI to different domains and languages
    makes it a flexible tool for a broad spectrum of applications and industries.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: However, this brilliance does not come without its pitfalls. Most of these were
    touched upon earlier when we discussed the risks of opting for generative AI over
    traditional NLP methods.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '*Cost-effectiveness*—Deploying generative AI-based solutions at scale can be
    slow but can quickly escalate in costs.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Lack of control*—Acquiring and maintaining the best-performing generative
    AI models in-house can be challenging for many companies, causing them to depend
    on third parties.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a more detailed comparison of generative AI and traditional NLP methods
    for text summarization, with their potential drawbacks and tradeoffs, refer to
    table 6.4.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6.4 Text summarization: Generative AI vs. traditional NLP methods'
  id: totrans-192
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Factor | Generative AI | Traditional NLP methods |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
- en: '| Summary type  | Extractive • When prompted correctly can generate extractive
    summaries, however it tends to drift toward abstractive summaries'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Abstractive
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: • Processes the entire document, understands the key points and relationships,
    and generates a summary that conveys the essential meaning in its own words
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: • Can rephrase ideas, use synonyms, and change the sentence structure
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: • Can incorporate the overall sentiment or tone of the original text, or change
    it on demand according to the needs
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '| Extractive • Select the most important words and sentences'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: • Prioritize factual accuracy
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: • Present the main ideas in a clear and concise way
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: Abstractive
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: • Predefined templates are used to generate summaries
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: • Typically does not generate entirely new text to create a summary
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: • May not be able to capture the overall sentiment
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '| Computational efficiency  | Low • Computationally expensive training and
    inference'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '| High • Faster training and inference'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '| Scalability  | Low • May struggle with long documents'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: • May require significant resources to process complex summaries
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: • Using an API is slow and expensive
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '| High • Scales well with larger datasets'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: • Relatively low cost of usage
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '| Interpretability  | Low • Difficult to understand how the model arrives at
    a summary'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: • Like a black box
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '| High • Clear picture of chosen sentences'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: '| Model optimization  | Complex • Requires complex techniques like reinforcement
    learning to optimize for specific objectives (e.g., factual accuracy, sentiment
    analysis)'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: • Prompt engineering may help at setting summary objectives, but it is not fully
    deterministic and requires monitoring
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '| Simple • Can be optimized with simpler techniques like sentence scoring functions
    that prioritize factual keywords or specific emotions'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: With these considerations, you might find yourself compromising on the accuracy,
    simplicity, and fun that generative AI offers to develop more traditional, albeit
    potentially more suitable, solutions for your company.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.3 Summarizing text with ChatGPT
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s return to your boss’s inquiry and discover what customers most often complain
    about. To address this task, you first need to identify negative reviews using
    one of the methods described in previous sections. For demonstration purposes,
    we will take a shortcut and use the set of negative reviews determined by the
    `review_score` variable, which was previously used to assess the effectiveness
    of our sentiment analysis. Once the negative reviews are extracted, they will
    be subjected to text summarization for further insight.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: This is a good opportunity to mention another potential issue with texts such
    as customer reviews. As globalization spreads, you can expect these texts to appear
    in dozens of languages. When using traditional NLP methods for summarization,
    the reviews should first be clustered by language, then translated to a common
    language (most likely English), and only then be subjected to further analysis.
    With the polyglot capabilities of generative AI, all these steps can be reduced
    to a single mention in the prompt, indicating that regardless of the input language,
    you want the summaries in the language of your choice. How brilliant! With generative
    AI at hand, we can finally finish building the Tower of Babel and even make some
    cash by offering it for short-term rent!
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: As a warm-up, let’s see how generative AI can summarize the longest review in
    our example dataset.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**Summarize this text “NÃO RECEBI O PRODUTO,
    O PRODUTO CONSTA COMO ENVIADO PARA O CORREIO DE RIBEIRÃO PRETO. O CORREIO NÃO
    RECEBEU O PRODUTO. ENVIE VARIAS MENSAGEM PARA A targaryen E NÃO OBTIVE. ESTA targaryen
    ESTA SUJANDO SEU NOME”. Use Portuguese in your summary. Provide English translations
    for both the original and the summary.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Response.png)**Here’s a summarization of the given text
    using a simple non-ML approach based on extracting the most frequent words:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '[...]'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: 'Summary (English translation):'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: “PRODUCT NOT RECEIVED, POST OFFICE NOT RECEIVED, targaryen NO RESPONSE.”
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: Please note that this summarization is relatively simple and may not capture
    all the nuances of the original text. For more accurate and coherent summarization,
    you can use more advanced techniques like TextRank, or machine learning-based
    methods.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: 'This response is fast, easy to obtain, and comprehensive. You can further play
    with your favorite generative AI and ask it to generate longer or shorter summaries,
    review titles, and review descriptions written in the style of your favorite author,
    or you can even ask it to turn your boring reviews into pretty brilliant haikus,
    like this one:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: Product never came,
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: Messages to targaryen,
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: Silent, tarnished name.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: Remember the protagonist in Chuck Palahniuk’s *Fight Club* who fought his office
    boredom by disseminating haikus to all employees? Armed with your newly gained
    knowledge, you can now harness generative AI to develop a straightforward application
    that sends negative feedback back to the unhappy customer in this elegant form.
    At the very least, they shouldn’t be grumbling about the absence of a response
    any longer. However, do not expect any praise from your boss after this exercise.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4 Summarizing text with dedicated libraries
  id: totrans-241
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When selecting NLP summarization techniques, your choice should depend largely
    on the type and length of the text to be summarized. For extensive texts such
    as books, abstractive summarization techniques are often more suitable. These
    methods can generate concise overviews by understanding and paraphrasing key concepts,
    making them ideal for capturing the essence of lengthy narratives or detailed
    discussions without needing to quote the original text extensively. For scientific
    articles or technical documents, a mix of extractive and abstractive methods might
    be best, pulling out significant sentences or terms (extractive) and then synthesizing
    those elements into a coherent summary (abstractive) that captures the document’s
    main findings and implications. Moving to shorter texts, such as news articles
    or blog posts, extractive summarization can be effective, identifying and compiling
    the most informative parts directly from the source.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: For short texts such as customer reviews, it may be more beneficial to concentrate
    on extracting main keywords or topics rather than creating summaries. Sentiment
    analysis, coupled with keyword extraction, often provides sufficient insight.
    In fact, given the exercises in the previous sections, you should generally know
    what to expect from text summarizations of the negative reviews.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: 'As for the particular methods, text summarization techniques can generally
    be divided into two categories: rule-based approaches and machine learning approaches.
    Each offers distinct methods for generating text summaries, with their own strengths
    and limitations.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: 'Rule-based approaches rely on predefined linguistic rules and heuristics, such
    as sentence length, position, and the frequency of key terms, to extract important
    sentences. While straightforward and interpretable, these approaches can be rigid
    and may fail to adapt to the nuances of different texts. Here are a couple of
    the most common rule-based methods for generating extractive summarizations:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: '*Sentence scoring and extraction*—This method scores sentences based on predefined
    criteria, such as the position of the sentence and the presence of keywords. Term
    frequency-inverse document frequency (TF-IDF) is often used to score sentences
    based on the frequency of important terms. The highest-scoring sentences are then
    combined to form the summary.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*TextRank*—A variation of the PageRank algorithm, TextRank represents sentences
    as nodes in a graph, with edges representing content overlap. The most central
    sentences are extracted for the summary.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Frequency-based methods*—This approach identifies and extracts key terms,
    *n*-grams, or phrases from the text that represent the main topics. These keywords
    are then used to create a summary.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Cue phrase method*—Utilizes specific cue phrases (e.g., “in summary,” “to
    conclude”) that often signal important information. Sentences containing these
    phrases are extracted for the summary.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Lead-based summarization*—Commonly used in news articles, this method involves
    extracting the initial few sentences or the first paragraph, assuming that text
    contains the most critical information.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rule-based approaches can also be used for abstractive summarization. However,
    this requires rule-based paraphrasing or predefined templates to generate summaries
    by filling in slots with relevant information extracted from the text. As you
    might guess, the output is not as smooth as the abstractive summaries created
    by generative AI.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: 'Apart from rule-based approaches, Python offers multiple machine learning techniques
    to summarize texts: latent semantic analysis (LSA) and latent Dirichlet allocation
    (LDA) can be used to analyze latent topics, whereas pretrained language models
    like BERT, text-to-text transfer transformer (T5), and Bidirectional and Auto-Regressive
    Transformer (BART) can be fine-tuned for specific tasks. Presenting the details
    of these methods and their capabilities is beyond the scope of this book, not
    to mention that most of them are designed for other purposes than summarizing
    texts as short as our reviews. However, with options like the Gensim, scikit-learn,
    and Hugging Face Transformers libraries, you can select the right technique for
    your requirements and text type. At the same time, generative AI can assist you
    and provide advice.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now revisit our example. To understand how traditional NLP methods can
    summarize reviews and to compare them with the straightforward approach presented
    in section 6.3.3, we will use a simple rule-based technique—a frequency-based
    approach—to analyze our negative reviews. This method identifies the most common
    words after removing stopwords, providing a quick insight into the prevalent concerns
    or keywords within each review. First, we will ask ChatGPT to generate relevant
    code in Python, using this prompt, “Provide Python code to generate summaries
    of very short customer reviews in Portuguese. Use a frequency-based approach.”
    The resulting code, after some adaptations to our input data, can be found in
    the Jupyter notebook in the book’s GitHub repository.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.6 Summarizing the longest review—a frequency-based approach
  id: totrans-254
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The code proposed by generative AI functions well and can be readily adapted
    to summarize reviews in the entire dataset. For instance, the three-word summary
    of the example review from section 6.3.3 is “produto, correio, targaryen” (product,
    mail, targaryen). In this context, “targaryen,” like all *Game of Thrones* house
    names, are our data provider’s means of anonymizing store names.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: You can generate longer and more informative summaries by modifying the `num_keywords`
    parameter in the preceding code. However, in our opinion, the output generated
    with this simple frequency-based approach is not as precise and to the point (and
    not even as entertaining) as ChatGPT’s haikus. Direct three-word summaries “manually
    crafted” by generative AI also seem a bit better, although a more rigorous approach
    would be needed to assess which outcome is truly superior.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: To get a feeling for the results, you can compare the output for the first five
    reviews, gathered in table 6.5\. All translations were provided by ChatGPT.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: Table 6.5 Summary efforts on a sample of five customer reviews
  id: totrans-259
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Translated review | Three-word summary by frequency-based methods | Three-word
    summary by ChatGPT 4 | ChatGPT’s haiku |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
- en: '| I received it well before the stipulated deadline.  | received well'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: before
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '| Early delivery  | Arrived well before Stipulated deadline nears'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: Satisfaction found
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: '| Congratulations Lannister stores, I loved shopping online, safe and practical.
    Congratulations to everyone and happy Easter.  | congratulations lannister'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: stores
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: '| Lannister stores praised  | Lannister stores cheer Safe and practical shopping'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: Happy Easter joy
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '| Efficient device. On the website, the device brand is printed as 3desinfector,
    and upon arrival, it has another name... Update with the correct brand since it’s
    the same device.  | efficient brand'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: device
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: '| Efficient, mislabeled device  | Efficient device Misnamed but still performs
    well'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: Update with true brand
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '| But a little, lagging... for the price, it’s good.  | a bit lagging'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '...'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: '| Lagging, decent value  | Slight lag appears, Yet value stands its ground,'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: Acceptable deal.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: '| Reliable seller, product ok, and delivery before the deadline  | reliable
    seller'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: product
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '| Reliable seller, prompt  | Trustworthy vendor, Product meets expectations,'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: Early delivery.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI provides both extractive and abstractive summaries
  id: totrans-287
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: While generative AI can perform both types of summarizations, its primary strength
    lies in abstractive summarization, as it has been trained on vast amounts of textual
    data and is capable of generating human-like coherent summaries.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: Another concern is that summarizing each negative review individually doesn’t
    effectively address the task assigned by your boss. Someone still needs to read
    through all the summaries and draw conclusions from them. To tackle this issue
    more efficiently, you can employ another method called *topic modeling*, which
    helps identify common themes and topics across a collection of documents, such
    as the negative reviews in this case.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.5 Topic modeling
  id: totrans-290
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Topic modeling is not a form of text summarization per se, but it can be used
    to generate a high-level summary of the main themes and topics in a collection
    of documents. While text summarization techniques aim to create condensed versions
    of individual documents by extracting or generating the most important sentences
    or phrases, topic modeling techniques are designed to uncover the underlying latent
    structure and themes within a corpus of texts.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: Topic modeling can help you understand the main topics and their distribution
    across a set of documents, but it does not generate human-readable summaries of
    the individual texts. Instead, it represents each document as a mixture of topics,
    with each topic being a probability distribution over words.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: Our example set of negative customer reviews is an ideal candidate for demonstrating
    topic modeling, which can summarize them in a convenient, human-readable form.
    Let’s start by asking ChatGPT for the relevant code, using the prompt, “I have
    a set of short negative customer reviews in Portuguese stored in a pandas dataframe
    column. I want to know what are the main concerns raised by customers. How to
    extract this information from reviews?”
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.7 Summarizing negative reviews with topic modeling
  id: totrans-294
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The proposed code was manually adapted to analyze only negative results from
    our example dataset (reviews with `review_score` of 1 or 2). The output is a list
    of the five most common topics mentioned in the reviews; however, the topics themselves
    are not presented in a friendly form. Fortunately, we have generative AI at hand
    to help us read and interpret what, by nature, is not human-readable. In this
    case, informing the model directly about the negative nature of the input leads
    to better conclusions.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**Can you interpret this output of topic modeling?
    Provide English translations. Keep in mind that the input consisted only of negative
    customer reviews:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '**![image](../Images/Response.png)**Here’s the interpretation of the topic
    modeling output with English translations, considering that the input consisted
    only of negative customer reviews:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'As demonstrated, generative AI can be very useful when dealing with difficult-to-read
    output, particular when it is written in a language you are not familiar with.
    It is evident that generative AI is able to make a nice and plausible story out
    of extracted keywords. However, in our example, all five of the most common topics
    were related to the same issue: dissatisfaction with delivery, which is a take-home
    message for your boss.'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI interprets the output
  id: totrans-302
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Generative AI is helpful in extracting the essence of the output of text-mining
    methods, even if it is presented in a hard-to-read format and a foreign language.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: To conclude, this section showcased the application of generative AI to identify
    the most common customer concerns by employing text summarization and topic modeling
    techniques on the set of customer reviews. In addition, we entertained ourselves
    by generating a bunch of haikus. This comprehensive approach demonstrates the
    versatility and utility of generative AI in the realm of natural language processing
    and text analysis.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: However, while generative AI is a powerful language model that performs well
    in various NLP tasks, including text summarization, its performance may not always
    be better than dedicated summarization libraries. The choice between generative
    AI and dedicated libraries depends on several factors, such as the nature of the
    text, the desired summary type (extractive or abstractive), and the domain-specific
    context.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: Dedicated summarization libraries may be optimized for specific tasks and can
    often provide more control over the summarization process, enabling users to fine-tune
    the output according to their requirements. Additionally, they may perform better
    on domain-specific or technical texts.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, generative AI’s strength lies in its ability to generate
    more coherent and natural-sounding summaries, especially for abstractive summarization.
    It can be an excellent choice for generating human-like summaries or when the
    focus is on producing easily comprehensible output.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: In short, there isn’t a one-size-fits-all answer, and the choice between generative
    AI and dedicated summarization libraries depends on the specific requirements
    of the task at hand. It is essential to evaluate different approaches and choose
    the one that best fits your needs.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: Things to ask generative AI
  id: totrans-309
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: How to perform your_task with the help of your API?
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is this bunch of text about?
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which NLP method will be the best to summarize my type of data?
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can you make this output human-readable?
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For complex NLP tasks, certain specialized tools might still surpass the capabilities
    of the most advanced generative AIs.
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even though generative AI might outperform conventional methods for your NLP
    task, it may not always be cost-effective.
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Top generative AI models are high-maintenance pets; many companies find it challenging
    to keep them in-house. To deploy them at an industrial scale, reliance on third-party
    solutions, such as APIs, is often necessary.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The performance of generative AI improves markedly with each version.
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Just because version *n* of your preferred generative AI cannot make coffee
    doesn’t imply that version *n*+1 won’t be capable of doing so.
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative AI is brilliant when it comes to text summarization and paraphrasing
    in the given form (prose, poetry, drama, you name it). It provides both extractive
    and abstractive summaries.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use generative AI to interpret or summarize results—especially ones that are
    hard to read.
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
