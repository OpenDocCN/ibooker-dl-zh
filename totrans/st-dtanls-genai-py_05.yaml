- en: 6 Advanced text mining with generative AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sentiment analysis with a generative AI language model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sentiment analysis with a generative AI API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sentiment analysis with machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text summarization with generative AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Text summarization with dedicated libraries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Topic modeling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the previous chapter, you got a taste of text-mining basics and discovered
    how generative AI can speed up and refine your analyses. Now, let’s go deeper.
    Ahead, you’ll tackle advanced NLP techniques such as sentiment analysis and text
    summarization. These tools are invaluable in the business world, enabling companies
    to swiftly gauge customer sentiment from reviews, social media, or customer service
    interactions, leading to more informed decision-making. Text summarization, on
    the other hand, can distill lengthy reports, research findings, or customer feedback
    into digestible insights, saving your precious time and ensuring key information
    doesn’t go unnoticed. Together, these techniques can significantly enhance how
    businesses understand and respond to their audiences, driving better strategies
    and outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you’ll see how the straightforward sentiment analysis methods
    from chapter 5 stack up against the advanced capabilities of machine learning
    models and generative AI’s linguistic finesse. Prepare to witness firsthand the
    challenge of outperforming generative AI in NLP tasks. Your objective? As always,
    to impress your boss. But this time, by swiftly and accurately uncovering key
    customer insights through the extraction and summarization of negative reviews.
    With generative AI as your ally, you’re equipped to sail smoothly through these
    complex processes.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1 Review analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As you move forward in this chapter, remember the task your boss handed you:
    to uncover the main issues customers have with your company’s products and services,
    based on their reviews. The initial steps you took in the previous chapter shed
    some light, but now you are faced with an intriguing challenge: can you deepen
    your understanding by tapping into more advanced NLP techniques? Let’s find out
    together.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The dataset you examined in the previous chapter contained customer reviews
    (described in detail in section 5.2.2). It was rather disorganized, which is common
    for this type of data. Additionally, the fact that the reviews are in Portuguese
    poses another challenge, assuming you’re not familiar with the language. To navigate
    this clutter, we’ll explore various techniques for deriving insights from unstructured
    data, among which these are the two most important:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Sentiment analysis*—The process of determining the underlying emotions, opinions,
    or attitudes expressed within a piece of text, such as positive, negative, or
    neutral sentiment. This technique is invaluable for businesses aiming to gauge
    customer satisfaction, monitor brand reputation, or understand consumer needs.
    For example, after applying it to customer reviews, a company can pinpoint which
    features of a product or service are most appreciated or which aspects are causing
    dissatisfaction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Text summarization*—The technique of condensing a larger body of text into
    a shorter, coherent representation that retains the most essential information
    and key ideas. This method is particularly useful for professionals who need to
    quickly assimilate large volumes of information without sacrificing understanding.
    For instance, a financial analyst could employ text summarization to distill comprehensive
    market reports and research papers into concise summaries, enabling faster decision-making
    and efficiently keeping abreast of critical market trends and forecasts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You might have noticed that the basic NLP techniques described in the previous
    chapter already laid the groundwork for sentiment analysis and text summarization.
    Utilizing keywords or predefined lexicons to filter out positive reviews indeed
    serves as a rudimentary form of sentiment analysis, while even basic frequency
    analysis proved sufficient to highlight the main concerns appearing in customer
    feedback, thus providing a form of text summary. So, are you going to learn anything
    new in this chapter? Absolutely, you will.
  prefs: []
  type: TYPE_NORMAL
- en: To put it simply, what you’ve learned so far is akin to learning how to peel
    potatoes. In this chapter, we’re about to master the art of gourmet cuisine. However,
    our approach remains highly practical, meaning you won’t be required to perform
    complex calculations mentally. Instead, we’ll introduce you to the best tools
    available for achieving your objectives. Specifically, we will use pretrained
    machine learning models available online to conduct sentiment analysis and text
    summarization, with generative AI guiding us throughout the process. We will also
    leverage generative AI’s inherent language capabilities to directly undertake
    these NLP tasks. The subsequent sections will offer a comparison of these two
    methods and the basic NLP techniques introduced previously, providing insight
    into their relative performance and utility.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2 Sentiment analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Sentiment analysis is a type of text classification where a label or class is
    assigned to a given text. For example, labels such as “correct,” “incorrect,”
    or “unknown” can be used to classify texts based on their grammatical correctness.
    Specifically, in sentiment analysis, the labels “positive,” “negative,” and “neutral”
    are typically used to reflect the author’s emotions and attitudes toward a subject.
    For instance, a statement like “I hate your company and your sh**y Quantum Fluff!”
    carries strong negative sentiment. Without NLP tools, such emotionally charged
    comments could easily be overlooked by your company’s PR department amidst a sea
    of other feedback. However, hoping that negative opinions will remain similarly
    unseen by other customers is nothing but wishful thinking. Such views tend to
    spread rapidly, much like a wildfire in a savanna, potentially endangering your
    company’s reputation. Therefore, learning how to automatically detect customer
    sentiments is crucial for your business’s well-being.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to note that text classification encompasses a much wider range
    of applications than just sentiment analysis. Consider a scenario where the input
    involves not just a single piece of text, like customer reviews, but two pieces,
    with the goal of identifying the relationship between them. This leads to the
    field of natural language inference (NLI), which significantly broadens the scope
    of language analysis.
  prefs: []
  type: TYPE_NORMAL
- en: NLI tasks can vary depending on the inputs and the labels assigned, but ultimately
    they all boil down to text classification. For instance, the first input text
    might be a premise, such as “A robin is a bird,” and the second a hypothesis,
    like “A robin can fly.” The possible labels could be “entailment,” indicating
    that the hypothesis logically follows from the premise (e.g., since a robin is
    a bird, and most birds can fly, it entails that a robin can fly); “contradiction,”
    indicating that the hypothesis contradicts the premise; and “neutral” for hypotheses
    that are irrelevant or cases that are difficult to categorize. This framework
    allows for the development of programs that, at least theoretically, can perform
    a form of reading comprehension. The practical implementation of such programs,
    however, depends on various factors, including task complexity, the volume and
    quality of training data, and our skill (and perhaps a bit of luck) in creating
    a model capable of undertaking such a challenge.
  prefs: []
  type: TYPE_NORMAL
- en: The task assigned by your boss—to classify reviews—is considerably less complex
    than the mentioned NLI tasks. Nonetheless, it offers an excellent opportunity
    to explore the fundamentals of text classification and sentiment analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the previous chapter, we demonstrated how to conduct basic sentiment analysis,
    particularly extracting positive reviews using rule-based (keyword search) and
    dictionary-based (lexicon) methods. Now, consider how our simple classifier, utilizing
    these approaches, would classify the following review: “Great, another software
    update that fixes nothing.” Given the presence of words like “great” and “fixes,”
    it might mistakenly classify this statement as positive, despite its sarcastic
    tone expressing frustration over unmet promises of improvement by the software
    update.'
  prefs: []
  type: TYPE_NORMAL
- en: Pretrained models are getting pretty good at sniffing out sarcasm in text, but
    they’re not magic. They achieve this feat through a combination of analyzing language
    tricks and understanding the broader context. By training on massive amounts of
    text data, including examples dripping with sarcasm and others that are plain
    and literal, these models become familiar with the linguistic gymnastics humans
    use to convey hidden meaning. They learn to identify red flags like positive words
    used in negative situations (“this is perfect” after a frustrating experience)
    or phrases that go against the grain of normal conversation (“Can’t wait for Monday
    morning!”). But sarcasm isn’t all about wordplay. Pretrained models also zoom
    out, examining the surrounding text and the relationship between the speaker and
    listener. For instance, a sarcastic comment between friends is more likely than
    a sarcastic remark from your boss during a performance review.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s examine the phrase, “back to the drawing board.” Through basic keyword
    or dictionary-based analysis, accurately classifying this expression poses a challenge,
    as it lacks explicit sentiment indicators. However, “back to the drawing board”
    is typically used to express that an attempt has failed and it’s time to start
    over, often carrying a connotation of disappointment or setback.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, machine learning models, developed with extensive and diverse text
    datasets, can accurately comprehend idiomatic expressions and their contextual
    meanings, effectively identifying sentiments of disappointment or frustration.
    This capability is crucial for thorough sentiment analysis, proving particularly
    valuable in evaluating feedback, reviews, or internal communications where such
    expressions are common. An added advantage of such models is their ability to
    adapt to different domains or languages with little manual effort, making them
    versatile tools for sentiment analysis across various datasets. A prime example
    of such a pretrained model is a large language model or LLM.
  prefs: []
  type: TYPE_NORMAL
- en: Large Language Model (LLM)  An LLM is a powerful AI system trained on vast amounts
    of text so it can understand and generate human language. It uses deep learning
    to perform a wide range of NLP tasks, including translation, summarization, question
    answering, and sentiment analysis, by predicting the likelihood of a sequence
    of words. The capabilities of LLMs extend beyond simple text processing, enabling
    them to grasp context, infer meaning, and even generate coherent and contextually
    relevant text responses, making them powerful tools in both research and application
    domains.
  prefs: []
  type: TYPE_NORMAL
- en: All the generative AI models discussed so far and utilized throughout this book
    are LLMs. Although they were originally designed for general-purpose conversations
    rather than as dedicated review classifiers, their exceptional ability to understand
    text and extract insights enables them to be effectively used for sentiment analysis
    tasks. In the following sections, we will show how to apply them to sentiment
    analysis and compare the results with those obtained from smaller machine learning
    models.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.1 What can you learn from sentiment analysis?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sentiment analysis offers invaluable insights across various business domains,
    enabling your company to understand customer emotions, preferences, and feedback
    on a granular level. For example, if you work for a retail brand, you can analyze
    social media mentions to gauge consumer sentiment toward a new product launch,
    identifying areas of excitement or concern to tailor marketing strategies accordingly.
    If you happen to deal with the finance sector, sentiment analysis of news articles
    and financial forums can help you and your investors predict market trends and
    make informed decisions. If you are engaged in hospitality businesses, like hotels
    and restaurants, utilizing sentiment analysis on review platforms to highlight
    areas for improvement in service or ambiance can directly impact customer satisfaction
    and loyalty. Additionally, in tech companies, you can leverage sentiment analysis
    in user feedback for software updates, prioritizing fixes and features that address
    the most pressing user concerns. This strategic application of sentiment analysis
    not only enhances product and service quality but also fosters a closer connection
    with customers by showing responsiveness to their needs and opinions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The simplest and most often used form of sentiment analysis categorizes texts
    into three groups: positive, negative, and neutral sentiments. In many cases,
    such as with our reviews, this is enough to understand customer sentiment. However,
    you may encounter situations where you will have to explore more complex aspects
    of the human soul (read: demandingness) and apply other instances of sentiment
    analysis, such as these:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Emotion detection*—This involves identifying specific emotions expressed in
    the text, such as happiness, sadness, anger, surprise, fear, and disgust, allowing
    for a more detailed understanding of the user’s feelings and reactions. This may
    be crucial, such as for detecting suicidal ideation on social media. Another business
    application where emotion detection is essential is in customer support and service
    interactions, especially for industries like telecommunications, banking, or utilities,
    where customer frustrations can escalate quickly. For example, in a telecommunications
    company, emotion detection can be employed in analyzing customer support chats
    or call transcripts. By identifying specific emotions such as frustration, anger,
    or disappointment, the company can flag cases that require immediate attention
    or intervention. This allows for a prioritized response to highly dissatisfied
    customers before they tell everyone on the web that Quantum Fluff (your company’s
    pet feature) actually does more harm than good.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Aspect-based sentiment analysis*—This technique focuses on identifying sentiments
    related to specific aspects or features within a text. For instance, in product
    reviews, it differentiates sentiments toward the product’s price, quality, design,
    etc., providing detailed insights into various facets of customer feedback. Who
    knows—maybe Quantum Fluff would gain more customer appreciation if it was cheaper?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Intensity or sentiment strength*—Sentiment analysis can also assess the intensity
    or degree of sentiment expressed, distinguishing between mild and strong emotions.
    This helps in understanding not just the nature of the sentiment but also its
    strength or urgency. For instance, after such an analysis, it may turn out that
    Quantum Fluff provokes such intense negative feelings that people are willing
    to pay more just to get rid of it, offering your company new opportunities to
    earn.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Intent analysis*—Beyond identifying sentiment, some approaches aim to understand
    the intent behind a text, such as whether the user intends to purchase, recommend,
    or complain about a product or service. This may prove useful for evaluating customer
    support tickets, emails, and social media messages. By analyzing the language
    and phrases customers use, the system can determine their intent, such as seeking
    information about new plans, reporting a service outage, requesting technical
    support, or expressing intent to cancel their service. For instance, if a customer’s
    message is found to contain phrases such as “turn this bloody Quantum Fluff off,”
    “better fluffs elsewhere,” or “thinking of switching,” the system can flag this
    as a high-priority intent to churn. This can trigger an immediate response from
    a specialized customer retention team, who can reach out to the customer with
    personalized offers (such as five months without Quantum Fluff for free), support,
    or solutions aimed at addressing their concerns. This proactive approach not only
    improves customer satisfaction by providing timely and relevant responses but
    also aids in reducing churn rates, directly impacting the company’s bottom line.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These advanced approaches to sentiment analysis allow for a richer, more complex
    understanding of textual data, offering deeper insights into consumer behavior,
    market trends, and public opinion.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.2 Direct sentiment analysis with generative AIs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Even though generative AIs were primarily designed for generating text completions
    rather than performing sentiment analysis, their ability to comprehend text can
    be utilized for a quick assessment of the sentiment expressed in any given piece
    of text. You can test this by examining three reviews from our example dataset.
    These reviews come with scores of 5, 3, and 1, which indicate positive, neutral,
    and negative sentiments respectively. The reviews, along with their translations,
    are presented in table 6.1\. Also detailed are the results of the sentiment analysis
    conducted by ChatGPT 4 and Gemini Advanced. To achieve similar results, you can
    use the prompt “What is the sentiment of these reviews?” followed by including
    the reviews in Portuguese.
  prefs: []
  type: TYPE_NORMAL
- en: Table 6.1 Direct sentiment analysis with generative AIs
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Review translated by Google Translate | Review score | True sentiment | Sentiment
    analysis by ChatGPT 4 | Sentiment analysis by Gemini Advanced |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| I received it well before the stipulated time.  | 5  | positive  | *positive*
    The customer received the product well before the stipulated deadline, indicating
    a positive experience with the delivery.'
  prefs: []
  type: TYPE_NORMAL
- en: '| *positive* The reviewer received the product well before the estimated delivery
    date.'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Good product, but what came to me does not match the photo in the ad.  |
    3  | neutral  | *mixed/neutral* The review mentions that the product is good (positive
    sentiment), but also states that the received product does not match the photo
    in the advertisement (negative sentiment). This combination of sentiments makes
    the overall sentiment mixed or neutral.'
  prefs: []
  type: TYPE_NORMAL
- en: '| *mixed* The reviewer says the product is good, but it doesn’t match the photo
    in the ad.'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| I would like to know why my product has not yet arrived at my residence and
    nobody has given me satisfaction or anything like that.  | 1  | negative  | *negative*
    The customer is expressing dissatisfaction with the fact that the product has
    not yet arrived at their residence and that they haven’t received any explanation
    or communication regarding the delay. This indicates a negative experience with
    the delivery and customer service.'
  prefs: []
  type: TYPE_NORMAL
- en: '| *negative* The reviewer hasn’t received the product yet and hasn’t received
    any updates from the seller.'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in the table, both ChatGPT 4 and Gemini Advanced demonstrated
    perfect understanding of the reviews. The outcomes from this modest experiment
    are encouraging and warrant further exploration into how direct application of
    generative AIs compares with the basic sentiment analysis techniques outlined
    in section 5.5.4\. In that section, the simplest keyword search (listing 5.6)
    managed to identify positive reviews with a sensitivity of around 47% and a specificity
    of up to 90%.
  prefs: []
  type: TYPE_NORMAL
- en: You are about to see whether direct utilization of generative AI’s language
    capabilities can yield improved results. The review scores provided in our example
    dataset will once again be used as a reference point for evaluating the quality
    of the analysis through the calculation of sensitivity and specificity. But before
    we can draw any conclusions, we need to conduct direct sentiment analysis with
    generative AI on a larger sample, by using its API.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.3 Sentiment analysis with generative AI’s API
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To evaluate generative AI’s capabilities in detecting sentiments on a broader
    scale, we will utilize the ChatGPT 4 API. For details on API usage, see chapter
    1\. It’s also important to note that accessing the API might require a subscription
    or a specific pricing plan. Your goal here is to have ChatGPT assess the sentiment
    of the first 500 non-empty reviews from the dataset, and compare these results
    with those from a basic sentiment analysis using keywords, as conducted in section
    5.5.4 (listing 5.6).
  prefs: []
  type: TYPE_NORMAL
- en: The following code demonstrates how you can use the API to conduct sentiment
    analysis on the reviews by leveraging the intrinsic language capabilities of ChatGPT
    4\. To make it operational, you’ll need to replace `your-api-key` with your actual
    ChatGPT API key and ensure that your account has sufficient funds. Fortunately,
    you can also find the results of this analysis in the books GitHub repository
    in the Sentiment_Analysis_500reviews.csv file.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.1 Sentiment analysis with ChatGPT's intrinsic language capabilities
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding code is straightforward. For each of the 500 reviews stored in
    the DataFrame, we send the following prompt to ChatGPT via the API: `The` `sentiment`
    `of` `this review` `is:`, appending the actual review text. The model then generates
    a response, which is classified as positive if it includes the word “positive.”
    The terms “negative” and “neutral” are utilized to identify negative and neutral
    sentiments respectively. If none of these words are found, the review is left
    without an assigned sentiment. Note that this method of analyzing ChatGPT’s responses
    is quite basic and may overlook more nuanced answers, such as those indicating
    mixed feelings within a review. Despite its simplicity, this approach can still
    produce remarkable results, as documented in table 6.2\.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 6.2 Quality of sentiment analysis with ChatGPT 4 API
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Sentiment analysis ( *n*=500) | Number of reviews classified as positive
    | Sensitivity | Specificity |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Reference review score  | 320 (64%) true positives'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1  | 1  |'
  prefs: []
  type: TYPE_TB
- en: '| Basic keyword search  | 163 (33%)  | 0.45  | 0.9  |'
  prefs: []
  type: TYPE_TB
- en: '| ChatGPT 4 API  | 250 (50%)  | 0.74  | 0.93  |'
  prefs: []
  type: TYPE_TB
- en: As in our previous approach, you can use the `review_score` variable from the
    dataset to evaluate the sensitivity and specificity of extracting positive reviews.
    Any review that obtained the score of 4 or 5 was considered positive. Obviously,
    the sentiment assessment with the `review_score` variable obtains sensitivity
    and specificity of 1, as this is our benchmark.
  prefs: []
  type: TYPE_NORMAL
- en: The results shown in table 6.2 indicate that both the basic keyword analysis
    and the method utilizing the ChatGPT 4 API exhibit very high specificity, exceeding
    0.9\. This means that both approaches seldom misclassify negative or neutral reviews
    as positive. Furthermore, ChatGPT 4 demonstrates significantly higher sensitivity
    (0.74), capturing many positive reviews that the basic keyword search missed.
    In the previous chapter, our attempts to improve the sensitivity of extracting
    positive reviews achieved limited success. Despite adopting more advanced techniques
    for cleaning the reviews, applying lemmatization, and using predefined dictionaries
    for Portuguese sentiment analysis, we only managed to enhance sensitivity by a
    few percentage points. However, by leveraging ChatGPT 4 to determine the sentiment
    of the reviews, we succeeded in increasing sensitivity by over 20%! This significant
    improvement was achieved even with the most basic interpretation of the model’s
    responses, marking a substantial and unequivocal advancement, albeit at a cost.
    Given that the ChatGPT API charges based on token usage, analyzing a large volume
    of real data—not just 500 sample reviews but thousands—could pose a financial
    challenge, prompting the question of its cost-effectiveness. While I appreciate
    the simplicity and effectiveness of this method, it may be too early to request
    additional funding from your finance department.
  prefs: []
  type: TYPE_NORMAL
- en: At this juncture, it’s crucial to recognize that when ChatGPT is queried about
    sentiment analysis or any similar task that it is inherently capable of performing
    due to its ability to “read” with comprehension, its typical advice often revolves
    around guiding you to write specific code to accomplish the task at hand. The
    model may highlight the advantages of traditional NLP methods, emphasizing their
    capacity for analyzing nuanced and specific data among other benefits. In practice,
    however, most data encountered is relatively standard and predominantly in English,
    which—as demonstrated—can be quickly and efficiently analyzed by generative AI.
    The principal drawback of such analysis is the time and cost involved, in addition
    to limited control over the tool, which could be modified or updated at any time
    by an external party.
  prefs: []
  type: TYPE_NORMAL
- en: A common criticism of generative AIs is their “black box” nature, offering limited
    transparency in how responses are generated and on what basis. This argument is
    valid when comparing the performance of generative AIs to basic NLP tools like
    keyword searches. However, it becomes less convincing once we begin to use a trained
    language model of any size. Nevertheless, could it be that generative AIs, with
    their advanced “reading” capabilities, represent the best option for tackling
    NLP tasks? A year ago (before API access to ChatGPT 4 was available), we conducted
    a similar test using earlier OpenAI models, and the outcomes were unimpressive.
    We had a preference for conventional NLP methodologies. However, with the advancements
    in generative AI technology, our certainty on this matter has waned.
  prefs: []
  type: TYPE_NORMAL
- en: With that said, let’s proceed to explore sentiment analysis using traditional
    and well-established machine learning methods. In the next section, we will examine
    whether, with the help of pretrained models, we can achieve results as compelling
    as those provided by the ChatGPT 4 API.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.4 Sentiment analysis with machine learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Previously, you learned how to conduct the simplest forms of sentiment analysis
    using methods such as frequency analysis, keyword searches, or dictionary-based
    approaches. While mastering these foundational techniques remains crucial, particularly
    for less commonly studied languages, the reality is that for the majority of everyday
    tasks, more sophisticated methods, such as machine learning, are preferred.
  prefs: []
  type: TYPE_NORMAL
- en: 'Machine learning has been around for some time now and should not intimidate
    anyone who dares to call themselves a data analyst. The era when proficiency in
    Excel sufficed is behind us; today, teaching your computer to recognize patterns
    has become a routine task. Thankfully, with the advent of new technologies, libraries,
    pipelines, and models, effective utilization has become significantly more accessible
    than in the past. While gaining an understanding of the underlying mechanics,
    such as matrix multiplication, is beneficial, and we encourage delving into these
    concepts, a deep technical grasp is no longer a prerequisite for using these models
    effectively. This situation is analogous to driving a car: knowing how the engine
    works isn’t necessary to be a competent driver, but in certain scenarios, such
    knowledge could help you avoid accidents or prevent you from being robbed by your
    car mechanic. And by no means do you have to construct the car in order to drive
    it! Most people acquire vehicles through purchase and sale transactions. Pretrained
    machine learning models are even more accessible, with many available online for
    free.'
  prefs: []
  type: TYPE_NORMAL
- en: Where can I find my model?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: So, what are your options when searching for a new, shiny, fast, safe, and collision-free
    model? As always, you could resort to a good old-fashioned web browser, or save
    yourself some time by discussing your requirements with the generative AI of your
    choice (Gemini is recommended for reasons mentioned earlier). However, it’s likely
    that all these efforts will, in any case, direct you to the Hugging Face website
    ([https://huggingface.co/](https://huggingface.co/)).
  prefs: []
  type: TYPE_NORMAL
- en: The Hugging Face website serves as a central hub for AI practitioners, offering
    access to a wealth of resources tailored to NLP and machine learning. At its core
    is the Model Hub, where users can explore and download a wide array of pretrained
    models suitable for various NLP tasks, such as sentiment analysis, text generation,
    and language translation. The website also features comprehensive documentation
    and tutorials to assist developers in implementing these models in their projects.
    Additionally, the Hugging Face platform encourages community engagement, allowing
    users to share their own models and collaborate with others.
  prefs: []
  type: TYPE_NORMAL
- en: 'While Hugging Face models are powerful tools for advancing NLP tasks, you should
    proceed with caution. Concerns have been raised regarding the potential for some
    models to harbor vulnerabilities or malicious code. Although the platform conducts
    malware scans on uploaded content and actively works to remove any malicious code,
    the arms race in cybersecurity is ongoing. Malicious actors continuously seek
    new security loopholes to exploit. To avoid becoming an unwitting victim in this
    cyber conflict, it’s crucial to proactively safeguard your security. The following
    list of ten security commandments is applicable not only to Hugging Face models
    but to any model (or software) downloaded from the web:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Use verified models*—Prefer models verified by the platform or those from
    reputable and known organizations.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Review model documentation*—Carefully read the model’s documentation for potential
    red flags.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Check contributor reputation*—Research the model’s contributors to ensure
    they are trustworthy.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Conduct security assessments*—Use security tools to scan for vulnerabilities
    or malicious code within the model.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Isolate testing*—Test new models in a safe, isolated environment away from
    sensitive data or systems.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Follow community feedback*—Pay attention to the community feedback and reports
    about specific models or contributors.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Update regularly*—Keep your models and their dependencies up to date to ensure
    you have the latest security patches.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Limit permissions*—When integrating models into your systems, grant them the
    least privileges necessary to perform their function.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Use encryption*—Encrypt sensitive data to protect it in case of accidental
    exposure by a malicious model.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Stay informed*—Regularly follow updates and security advice from Hugging Face
    and the broader AI community.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Another popular option for finding an applicable model is GitHub (https://github.com/).
    This vast repository hosts a multitude of pretrained models shared by developers
    and researchers from around the world. While GitHub offers an extensive range
    of models for various tasks, you should approach it with the same caution advised
    for Hugging Face models. The open nature of GitHub means that anyone can upload
    code, which could potentially include vulnerabilities or malicious content. These
    ten commandments serve as a guide to achieving maximum security.
  prefs: []
  type: TYPE_NORMAL
- en: What if the model I need does not exist?
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: So much for theory, but real life is much more challenging. What should you
    do if the new, shiny, fast, safe, and collision-free model of your dreams doesn’t
    exist? Let’s revisit our example. If our reviews were written in standard English,
    finding a relevant pretrained model to perform sentiment analysis would be straightforward.
    However, the fact that our input is in Portuguese presents us with an opportunity
    to explore additional options.
  prefs: []
  type: TYPE_NORMAL
- en: What alternatives do we have for conducting the desired analysis, especially
    when dealing with less commonly used languages? What if our task is really fancy,
    like assessing how politically correct a joke is? Or what if we combine the two,
    and are dealing with the task of assessing the political correctness of a joke
    written in Korean, say, in its northern dialect? (Before you go any further, we
    recommend consulting your favorite generative AI about the potential implications
    of developing such a model and considering whether you really should get involved.)
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some options:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Search for a suboptimal model*—This should be your starting point, no matter
    how uncommon your task or language is. It’s always worth checking whether someone
    has already tackled a similar, but maybe not identical, challenge. Why reinvent
    the wheel? Explore resources like the Hugging Face Model Hub and GitHub, use a
    web browser, or enlist generative AI to assist in your search. While you might
    not be completely satisfied with any existing models you find, they can provide
    valuable benchmarks for comparing your further efforts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pros of this approach include time efficiency, as it saves you from starting
    absolutely from scratch. Additionally, it offers an opportunity for learning and
    improvement by analyzing existing models. However, cons might include the challenge
    of finding a perfect match for your specific needs, limitations in model performance
    or adaptability, and the risk of depending on a model that may not be actively
    maintained or updated.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*Translating input to English*—This is a practical approach for conducting
    NLP tasks on less common languages, leveraging automatic translation tools and
    applying English-trained models. This method benefits from the extensive availability
    and sophistication of models for English, enhancing the potential for accurate
    analysis. However, it carries the risk of losing nuances and cultural context,
    possibly introducing errors or biases due to translation imperfections. Generative
    AIs can mitigate some of these challenges by providing more accurate translations
    and preprocessing the text to align better with English-trained models, thus preserving
    more original meaning and reducing translation-related inaccuracies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Use multilingual models*—If you can’t find a model fine-tuned specifically
    for your task and language, another effective approach is to use multilingual
    models such as XLM-RoBERTa or Multilingual BERT. These models are trained on vast
    datasets covering a wide array of languages, enabling them to understand and process
    multiple languages simultaneously without the need for language-specific training.
    This approach makes them highly versatile and an effective solution when a task-specific,
    language-specific model is unavailable. The primary advantage of using multilingual
    models lies in their broad applicability, saving the effort of developing or finding
    models tailored to each language, and offering respectable performance across
    various NLP tasks. However, these models may not match the performance of specialized
    models in certain tasks or languages due to their generalized nature. Additionally,
    customizing them for highly specific or nuanced tasks can be complex.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Utilize zero-shot learning models*—These models, which are trained to understand
    instructions in natural language, excel at generalizing to tasks they haven’t
    been explicitly trained on by leveraging semantic knowledge and relationships
    between concepts. This allows them to infer, for example, the sentiment of texts
    in categories or contexts they’ve never directly encountered, based on understanding
    gained from related tasks. However, while zero-shot learning models provide the
    flexibility to tackle a wide range of tasks with a single model, their performance
    might not always match that of models fine-tuned on specific tasks, especially
    in highly nuanced or domain-specific contexts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Fine-tune an existing model*—This is a practical option when resources for
    data collection are limited, allowing you to enhance a pretrained model with task-specific
    adjustments. This method is time-efficient, cost-effective, and it lowers the
    barrier to advanced modeling techniques. However, it depends on the pretrained
    model’s relevance to your task and the quality of labeled data used for fine-tuning.
    There’s also a risk of overfitting if adjustments aren’t made correctly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For NLP tasks, you might consider fine-tuning one of the existing LLMs, such
    as the widely recognized BERT, available on the Hugging Face platform. Such LLMs
    have been pretrained on extensive text corpora and possess a comprehensive understanding
    of language, which can be further tailored to specific NLP tasks using a comparatively
    smaller dataset. This can reduce the amount of effort and expertise needed, though
    computational resources and understanding of model behavior are still required.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As usual, generative AI can significantly facilitate this process by offering
    their assistance and expertise. But in this case, they can offer even more. As
    all generative AIs discussed in this book are LLMs themselves, they can serve
    as a linguistic foundation for the model you are developing. In other words, you
    can fine-tune generative AI to your specific task!
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '*Train your own model*—This option involves collecting a sufficient amount
    of labeled data and training the model yourself. This approach allows for customizing
    and optimizing the model to fit the specific nuances of your dataset and task.
    The main advantage is the potential for high accuracy and relevance to your particular
    use case, as the model learns directly from data reflective of your domain. However,
    the drawbacks include the significant time, effort, and expertise required to
    gather labeled data and design and effectively train the model. These challenges
    persist regardless of the assistance provided by generative AI. Additionally,
    this method demands substantial computational resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s test a few of these options and compare their results. Fine-tuning an
    existing model and training one from scratch demands greater expertise and falls
    beyond this book’s scope. However, should you opt for this route, generative AI
    can offer significant assistance by providing guidance, resources, and tools tailored
    to your needs. Additionally, you can refer to *Build a Large Language Model (From
    Scratch)* by Sebastian Raschka (Manning, 2024) for further instructions and insights
    into navigating these advanced techniques.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.5 Sentiment analysis with a suboptimal model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To try out the first option, searching for a suboptimal model, you could start
    by searching for an existing sentiment classifier for Portuguese, but this attempt
    proved unsuccessful (as of March 2024). Consultations with ChatGPT 4 and Gemini
    Advanced yielded some suggestions, but none fully met our requirements, and many
    of the provided links were invalid. Both generative AIs eventually advised manually
    scouring the Hugging Face website and GitHub for suitable models, a task that
    unfortunately led to no significant findings.
  prefs: []
  type: TYPE_NORMAL
- en: Consequently, you could opt for a less-than-ideal solution suggested by Gemini—the
    FinBERT-PT-BR classifier, which was trained on Portuguese financial news. Despite
    this not being the ideal dataset for analyzing customer reviews, a human-in-the-loop
    approach and error monitoring might help you identify and address the model’s
    shortcomings. All in all, it might be useful to proceed with this model anyway
    and assess its efficacy.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s become fully aware of the potential drawbacks of this approach.
    To achieve this, you could start by asking ChatGPT the following question:'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**I have a dataframe with a column `review_comment_message`
    containing customer reviews in Portuguese. I want to extract positive reviews
    using a sentiment classifier found on this website: [https://huggingface.co/lucas-leme/FinBERT-PT-BR](https://huggingface.co/lucas-leme/FinBERT-PT-BR)'
  prefs: []
  type: TYPE_NORMAL
- en: What are the potential drawbacks of using this model for my task?
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Response.png)**[...] Potential Drawbacks:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Domain Mismatch: FinBERT-PT-BR is specialized for financial contexts, which
    might not align well with general customer reviews.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Sentiment Analysis Complexity: The model may struggle with nuances like sarcasm
    or cultural expressions, affecting accuracy.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Language Specificity: Regional variations in Portuguese could lead to inconsistent
    performance across different Portuguese-speaking regions.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Model Biases: Pretrained models carry inherent biases and limitations from
    their training data, potentially skewing results.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Computational Demands: Processing a large volume of reviews with a transformer-based
    model requires substantial computing resources.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Ethical Considerations: Ensuring ethical and privacy-respecting use of customer
    reviews is crucial.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In short, while FinBERT-PT-BR offers an intriguing solution, its financial focus,
    potential language and regional limitations, computational demands, and the need
    for ethical diligence present notable challenges for extracting positive reviews
    from a general customer feedback dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'This conversation illustrates the potential benefits of discussing your analytical
    ideas with generative AI. Notably, ChatGPT was able to offer insightful comments
    on a resource it was previously unfamiliar with. Moreover, ChatGPT asserted that
    it didn’t use the provided link to further investigate the model’s website for
    additional information. This prompts the question: how did it know? The explanation
    given upon inquiry was remarkable:'
  prefs: []
  type: TYPE_NORMAL
- en: You caught me in a bit of an overextension based on the name “FinBERT-PT-BR,”
    inferring from the “Fin” prefix, which commonly denotes finance-related models
    (like FinBERT being a well-known adaptation of BERT for financial texts). The
    assumption was that this model, given its name, is specialized for analyzing financial
    text in Portuguese. Such naming conventions are typical for domain-specific versions
    of BERT and other language models, where the prefix or suffix indicates the model’s
    specialized training corpus or intended application area. However, without directly
    accessing the provided link or having specific knowledge of this model in my training
    data up to my last update in April 2023, I relied on these conventions to inform
    my response.
  prefs: []
  type: TYPE_NORMAL
- en: If this isn’t a demonstration of pure intelligence, then I’m not sure what is.
    However, even if you don’t share my sense of wonder, it should be clear by now
    that consulting advanced generative AIs like ChatGPT 4 when planning your research
    is far from a waste of time.
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI interprets external resources
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: It could be advantageous to inquire with generative AI whether using a specific
    external resource (such as a model, database, etc.) for your research is reasonable,
    or to discuss potential drawbacks associated with a particular resource. Even
    if the generative AI is encountering the resource for the first time, there’s
    a possibility it can deduce the resource’s contents and how it might influence
    your analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s ask our generative AI to prepare a code snippet. We used the following
    prompt in the same ChatGPT session: “Propose a code snippet to utilize this model
    to extract positive reviews from my data.” The obtained snippet is shown in the
    following listing.'
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.2 Extracting positive reviews with the help of a suboptimal model
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This snippet was provided alongside instructions on how to install the required
    libraries and a detailed comment emphasizing the importance of consulting the
    model’s documentation to understand the model’s output. Specifically, it was necessary
    to manually replace `LABEL_1` with an appropriate label indicating positive reviews,
    in our case, `POSITIVE`. Generative AI also detailed the use of exception handling
    around the classifier to manage any potential errors during processing, such as
    inputs that were too long or unexpected.
  prefs: []
  type: TYPE_NORMAL
- en: In the Jupyter notebook from the book’s GitHub repository, you can find this
    code manually adapted and applied to analyze the first 500 reviews from our testing
    dataset. As before, the `review_score` variable was employed to evaluate the sensitivity
    and specificity of the classifier. The FinBERT-PT-BR model recognized positive
    reviews with a sensitivity of 0.56 and a specificity of 0.93\. This performance
    surpasses simple keyword-based classification, yet it does not reach the efficacy
    of the results achieved through direct application of ChatGPT 4’s language capabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.6 Sentiment analysis on translated inputs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now you may want to explore whether translating the input and employing a sentiment
    classifier for English texts could produce better results. The pros and cons of
    such a solution were listed in section 6.2.4, so let’s jump to implementation
    right away.
  prefs: []
  type: TYPE_NORMAL
- en: 'We began with a specific prompt: “Write a code snippet to extract positive
    reviews from our dataset. Clean the reviews and translate them to English and
    then apply the most appropriate sentiment classifier for English.” Then we explored
    several options to identify the best method for translating the input, aiming
    for a simple and reliable solution that doesn’t require registration or payment.
    Ultimately, with generative AI’s help, we developed the following code snippet.'
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.3 Sentiment analysis on translated inputs
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The code employs the Meta model for translation, m2m100_418M, which supports
    multiple languages, including Portuguese and English. For sentiment analysis,
    it uses the distilbert-base-uncased-finetuned-sst-2-english model. Both models
    were recommended by generative AI for their broad applicability and performance.
    However, it was noted that we might consider exploring other models better tailored
    to our specific requirements.
  prefs: []
  type: TYPE_NORMAL
- en: While the code executes smoothly, translating 500 reviews took some time, so
    patience is advised if you plan to replicate this process. Using the `review_score`
    variable, we again evaluated the sensitivity and specificity of this method for
    identifying positive reviews. The corresponding code can be found in the Jupyter
    notebook in the book’s GitHub repository. Remarkably, this approach of translating
    input achieved a sensitivity of 0.86 and specificity of 0.89 for correctly classifying
    positive reviews, offering the best results thus far and proving comparable to
    those obtained using ChatGPT 4’s inherent language capabilities. Not bad, indeed.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.7 Sentiment analysis with multilingual models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Our next step is to explore whether using multilingual models for sentiment
    analysis could yield better results. The characteristics of such models, together
    with their potential drawbacks, were presented in section 6.2.4, so let’s proceed
    with the implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 'We used the prompt, “Now, I want to repeat this exercise but instead of translating
    the input, I’d rather use a multilingual model. Could you write a relevant code
    snippet for me?” Unfortunately, the obtained code didn’t work immediately, due
    to package dependency issues. Rather than manually resolving these issues or meticulously
    reviewing the entire error log, we simply copied the last few lines of the error
    message into the generative AI chat window for assistance. ChatGPT clarified the
    issue in plain English—far more helpful than the typical technical jargon found
    in error messages—and suggested two solutions: either downgrading one package
    or upgrading another, which promptly resolved the issue.'
  prefs: []
  type: TYPE_NORMAL
- en: As you progress through this book, you may encounter similar situations where
    packages evolve, and today’s code becomes deprecated tomorrow. Often, the solution
    involves minor adjustments, which could take mere seconds to implement but hours
    to figure out. With generative AI, you can move past endlessly scrolling through
    Stack Overflow for debugging tips.
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI is the ultimate tool for bug extermination
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Imagine the most deadly and ruthless bug spray. Multiply its effectiveness by
    a thousandfold, and you’re still not capturing the full extent of how adept generative
    AI is at tackling bugs! Instead of attempting to decode the error message yourself,
    simply paste it (or a fragment) into the model’s chat and request a translation
    into human language along with appropriate solutions. In the majority of instances,
    you’ll receive a swift and satisfactory response.
  prefs: []
  type: TYPE_NORMAL
- en: After smashing all the dependency bugs and correcting the output labels manually,
    we obtained the following working piece of code (don’t forget to install the required
    libraries).
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.4 Sentiment analysis with a multilingual model
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This script leverages the twitter-xlm-roberta-base-sentiment model to directly
    classify the sentiment of each review in the dataset, eliminating the need to
    translate them into English first. It achieves a sensitivity of 0.79 and specificity
    of 0.93, which are scores comparable to those achieved using ChatGPT 4’s innate
    language capabilities. This discovery suggests we’ve found a solution of similar
    quality that is both more cost-effective and faster than utilizing the generative
    AI API. However, before you rush to request a raise from your boss, let’s explore
    if we can surpass this performance by utilizing a zero-shot learning model.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.8 Sentiment analysis with zero-shot learning models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As a reminder, zero-shot learning models are particularly well-suited for tasks
    where labeled training data is scarce or unavailable. These models can generalize
    to tasks they haven’t been explicitly trained on, making them ideal for classifying
    text into categories (such as sentiment analysis) without needing a dataset specific
    to that task. For extracting positive reviews from our dataset in Portuguese using
    a zero-shot learning approach, you can leverage models designed for multilingual
    understanding, such as those available through the Hugging Face Transformers library.
  prefs: []
  type: TYPE_NORMAL
- en: 'All this, and much more, you will learn when you ask generative AI a question
    similar to this one: “I want to extract positive reviews from my dataset with
    help of a zero-shot learning model. Reviews are in Portuguese. How do I achieve
    this?” In response, ChatGPT 4 generated the following code, which was adapted
    to our input data manually. To run the code, you will have to install the transformers
    library with the command `pip install transformers`.'
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.5 Sentiment analysis with a zero-shot learning model
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: The code suggested by generative AI leverages the facebook/bart-large-mnli model,
    which is equipped to handle multilingual texts and has been trained on a variant
    of the Multi-Genre Natural Language Inference (MNLI) dataset. This enables the
    model to conduct zero-shot classification on texts in various languages, including
    Portuguese. ChatGPT, however, points out that this model serves merely as an example,
    and we may discover other models that could yield better results for specific
    datasets. For instance, the typeform/distilbert-base-uncased-mnli model is presented
    as an alternative that is smaller and faster, though potentially less precise.
  prefs: []
  type: TYPE_NORMAL
- en: The effectiveness of the zero-shot learning model was evaluated using the `review_score`
    variable. The model achieved a sensitivity of 0.87 for identifying positive reviews
    and a specificity of 0.74\. While this performance is marginally inferior to that
    of a multilingual model, it remains sufficiently robust to warrant considering
    zero-shot learning models in your analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2.9 Comparing results of advanced sentiment analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the previous sections, we explored several methods for performing sentiment
    analysis using pretrained machine learning models. Initially, we leveraged ChatGPT
    4’s inherent language capabilities to identify positive reviews (section 6.2.3).
    This approach was followed by employing a suboptimal pretrained model tailored
    for sentiment analysis in Portuguese financial texts (section 6.2.5). Next, we
    utilized a sentiment classifier designed for English, applying it to translated
    inputs (section 6.2.6). To circumvent the errors and biases introduced by translation,
    we opted for a multilingual model (section 6.2.7) and a zero-shot learning model
    capable of supporting multiple languages (section 6.2.8). These methodologies
    were tested on a dataset of 500 non-empty reviews, using the `review_score` variable
    to evaluate the sensitivity and specificity of the classifications. All the results
    are gathered in table 6.3.
  prefs: []
  type: TYPE_NORMAL
- en: Table 6.3 Quality of sentiment analysis with different pretrained models
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Sentiment analysis ( *n*=500) | Number of reviews classified as positive
    | Sensitivity | Specificity |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Reference review score  | 320 (63%) true positives'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1  | 1  |'
  prefs: []
  type: TYPE_TB
- en: '| Basic keyword search  | 163 (33%)  | 0.45  | 0.9  |'
  prefs: []
  type: TYPE_TB
- en: '| ChatGPT 4 API  | 250 (50%)  | 0.74  | 0.93  |'
  prefs: []
  type: TYPE_TB
- en: '| Suboptimal model  | 193 (39%)  | 0.56  | 0.93  |'
  prefs: []
  type: TYPE_TB
- en: '| Translated inputs  | 295 (59%)  | 0.86  | 0.89  |'
  prefs: []
  type: TYPE_TB
- en: '| Multilingual model  | 265 (53%)  | 0.79  | 0.93  |'
  prefs: []
  type: TYPE_TB
- en: '| Zero-shot learning model  | 325 (65%)  | 0.87  | 0.74  |'
  prefs: []
  type: TYPE_TB
- en: These results demonstrate that, in our tests, the multilingual model outperformed
    all others, uniquely surpassing the ChatGPT 4 API. A zero-shot learning model
    that supports multiple languages achieved results comparable to those of generative
    AI’s inherent language capabilities. Similarly, the method involving translating
    the input showed potential for high performance. Conversely, classifications based
    solely on keyword searches lagged significantly in sensitivity, though a more
    meticulous selection of keywords could potentially enhance its effectiveness.
  prefs: []
  type: TYPE_NORMAL
- en: Notably, just a year ago, the outcome of such an evaluation would have differed
    substantially, with ChatGPT 3—then the sole option available via API—failing to
    match even the basic keyword analysis in performance. Just think what can be achieved
    if ChatGPT 5 is finally released!
  prefs: []
  type: TYPE_NORMAL
- en: 'To sum up, this section illustrated how to conduct sentiment analysis using
    a variety of advanced pretrained models. Selecting the appropriate methodology
    for your data and task may involve testing several options, typically on a smaller
    subset of data, to determine the most cost-effective strategy that could lead
    to the long-awaited promotion you’ve been aiming for (just imagine: no more Quantum
    Fluff disguise on Sundays!). Generative AI can facilitate this process by providing
    a list of options, discussing their advantages and disadvantages, writing the
    necessary code snippets to implement them, and then testing and summarizing the
    results. In certain scenarios, you might choose to directly utilize language capabilities
    by accessing their APIs or using them as a foundation to fine-tune your own model,
    although the latter option has not been explored in this book.'
  prefs: []
  type: TYPE_NORMAL
- en: 6.3 Text summarization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the preceding sections, we successfully classified reviews based on their
    sentiment. The results obtained may not be entirely satisfactory in terms of efficiency,
    and additional analysis would be required to enhance the basic methods presented.
    However, let’s assume that your boss is content with the results and wishes to
    explore further. The question at hand is, what do customers most often complain
    about?
  prefs: []
  type: TYPE_NORMAL
- en: 'This task aligns exceptionally well with another NLP method you’re about to
    explore: text summarization. This technique aims to shorten long documents into
    more concise versions, maintaining the essential information and presenting it
    coherently. Utilizing approaches like rule-based methods or machine learning,
    text summarization enables users to swiftly capture the main concepts and pertinent
    details from large text collections.'
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.1 How can you benefit from text summarization?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can apply text summarization across a wide range of business scenarios
    to enhance efficiency, improve understanding, and streamline communication. Here
    are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Customer support*—Automatically generating concise summaries of customer inquiries
    or feedback from emails, chat messages, or social media will facilitate quicker
    response times. Even if it’s widely anticipated that the feedback will concern
    complaints about Quantum Fluff, it is valuable to have it quantitatively confirmed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Executive briefings*—Summarizing key points from lengthy reports, financial
    analyses, or market research for a quick review by executives and decision-makers
    can assist your boss and his colleagues in guiding the company toward glory and
    financial success. If you succeed, you will get your share . . . in the glory.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*News aggregation*—Creating short summaries of news articles can benefit not
    just news aggregation apps or websites but also your company. After all, staying
    informed about developments in the Quantum Fluff market is a routine task for
    any fluff manufacturer that values its reputation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Legal document review*—You think lawyers and other legal professionals fall
    into ecstasy when reading through their dense legal jargon, don’t you? However,
    the reality is they would greatly appreciate being relieved of this burden. If
    you could develop a tool that summarizes legal documents, contracts, or case files,
    facilitating a quicker grasp of their essential contents, they might just honor
    you with a monument (which you can add to your pension plan, together with your
    glory shares gained earlier).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Academic research*—How about academics and researchers? Do they enjoy their
    scientific jargon? Perhaps, but a tool that summarizes academic papers or journals,
    enabling quick comprehension of the premise, methodology, results, and conclusions
    without reading the full text, would likely be valued by students, post-docs,
    and that part of the research community who is still hoping for tenure. Those,
    in particular, whose survival depends on reading and publishing swiftly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Medical records summarization*—Health professionals represent another group
    that could greatly benefit from quick summaries, for instance of patient histories,
    lab reports, or clinical findings. This may facilitate faster diagnoses and improve
    treatment planning. But it’s not just doctors who would benefit—patients would
    too. Imagine how pleasant and humanizing it would be if your doctor had the time
    to actually engage in real conversation with you!'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Meeting minutes*—Text summarization techniques can streamline recorded discussions
    or meeting transcripts into concise, actionable summaries, emphasizing key decisions,
    action items, and discussion points. However, volunteering to develop such a tool
    carries its risks. What if your program uncovers a widely acknowledged yet unspoken
    truth within the company: that many of the meetings are, in fact, a sheer waste
    of time?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Email management*—Do you recall that spaghetti email conversation in your
    company about which coffee machine should be ordered for the office? Missing a
    few episodes of this soap opera would no longer be an issue if you had a tool
    capable of summarizing long email threads. This tool would distill the essence
    of discussions, decisions, or action items into a concise brief, perhaps starting
    with “Previously, in the New Coffee Machine saga . . .”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Content marketing*—With the new Quantum Fluff feature to promote, no matter
    what, your marketing department is working their fingers to the bone. Why not
    help them by creating a tool that could generate summaries of blog posts, articles,
    or whitepapers to use in newsletters, social media, or marketing materials, engaging
    readers and encouraging them to explore the full content?'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Product reviews analysis*—Summarizing customer reviews and feedback on products
    or services may help to quickly identify trends, preferences, and areas of improvement.
    This objective aligns with what your boss is expecting from you, and in the following
    sections, we will guide you on how to meet those expectations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These examples illustrate how text summarization can be a powerful tool for
    various industries, helping to save time, reduce information overload, and enhance
    decision-making processes.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.2 How can generative AI help in text summarization?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Generative AI offers significant potential in summarizing texts efficiently
    and effectively. By leveraging its deep understanding of language structure, context,
    and semantics, generative AI can process large volumes of textual information
    and condense it into shorter, coherent summaries. This capability is particularly
    useful for extracting the most important information and presenting it in an easily
    digestible form, saving you and your coworkers a lot of time and effort.
  prefs: []
  type: TYPE_NORMAL
- en: 'Furthermore, generative AI’s advanced natural language processing capabilities
    allow it to generate two types of summaries:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Extractive summaries*—This approach involves selecting and compiling key phrases
    or sentences directly from the text to create a summary. For example, it can summarize
    a news article by extracting the most informative sentences that cover the who,
    what, when, where, and why.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Abstractive summaries*—These summaries reformulate the original text, often
    generating new phrases and sentences that weren’t in the initial document, to
    capture its essence more creatively and fluidly. An example would be condensing
    a novel’s plot into a brief overview that captures the main themes and plot points
    without directly quoting the text.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Both types of summaries can be tailored for a specific level of detail and originality.
    Moreover, the adaptability of generative AI to different domains and languages
    makes it a flexible tool for a broad spectrum of applications and industries.
  prefs: []
  type: TYPE_NORMAL
- en: However, this brilliance does not come without its pitfalls. Most of these were
    touched upon earlier when we discussed the risks of opting for generative AI over
    traditional NLP methods.
  prefs: []
  type: TYPE_NORMAL
- en: '*Cost-effectiveness*—Deploying generative AI-based solutions at scale can be
    slow but can quickly escalate in costs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Lack of control*—Acquiring and maintaining the best-performing generative
    AI models in-house can be challenging for many companies, causing them to depend
    on third parties.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a more detailed comparison of generative AI and traditional NLP methods
    for text summarization, with their potential drawbacks and tradeoffs, refer to
    table 6.4.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6.4 Text summarization: Generative AI vs. traditional NLP methods'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Factor | Generative AI | Traditional NLP methods |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Summary type  | Extractive • When prompted correctly can generate extractive
    summaries, however it tends to drift toward abstractive summaries'
  prefs: []
  type: TYPE_NORMAL
- en: Abstractive
  prefs: []
  type: TYPE_NORMAL
- en: • Processes the entire document, understands the key points and relationships,
    and generates a summary that conveys the essential meaning in its own words
  prefs: []
  type: TYPE_NORMAL
- en: • Can rephrase ideas, use synonyms, and change the sentence structure
  prefs: []
  type: TYPE_NORMAL
- en: • Can incorporate the overall sentiment or tone of the original text, or change
    it on demand according to the needs
  prefs: []
  type: TYPE_NORMAL
- en: '| Extractive • Select the most important words and sentences'
  prefs: []
  type: TYPE_NORMAL
- en: • Prioritize factual accuracy
  prefs: []
  type: TYPE_NORMAL
- en: • Present the main ideas in a clear and concise way
  prefs: []
  type: TYPE_NORMAL
- en: Abstractive
  prefs: []
  type: TYPE_NORMAL
- en: • Predefined templates are used to generate summaries
  prefs: []
  type: TYPE_NORMAL
- en: • Typically does not generate entirely new text to create a summary
  prefs: []
  type: TYPE_NORMAL
- en: • May not be able to capture the overall sentiment
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Computational efficiency  | Low • Computationally expensive training and
    inference'
  prefs: []
  type: TYPE_NORMAL
- en: '| High • Faster training and inference'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Scalability  | Low • May struggle with long documents'
  prefs: []
  type: TYPE_NORMAL
- en: • May require significant resources to process complex summaries
  prefs: []
  type: TYPE_NORMAL
- en: • Using an API is slow and expensive
  prefs: []
  type: TYPE_NORMAL
- en: '| High • Scales well with larger datasets'
  prefs: []
  type: TYPE_NORMAL
- en: • Relatively low cost of usage
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Interpretability  | Low • Difficult to understand how the model arrives at
    a summary'
  prefs: []
  type: TYPE_NORMAL
- en: • Like a black box
  prefs: []
  type: TYPE_NORMAL
- en: '| High • Clear picture of chosen sentences'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Model optimization  | Complex • Requires complex techniques like reinforcement
    learning to optimize for specific objectives (e.g., factual accuracy, sentiment
    analysis)'
  prefs: []
  type: TYPE_NORMAL
- en: • Prompt engineering may help at setting summary objectives, but it is not fully
    deterministic and requires monitoring
  prefs: []
  type: TYPE_NORMAL
- en: '| Simple • Can be optimized with simpler techniques like sentence scoring functions
    that prioritize factual keywords or specific emotions'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: With these considerations, you might find yourself compromising on the accuracy,
    simplicity, and fun that generative AI offers to develop more traditional, albeit
    potentially more suitable, solutions for your company.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.3 Summarizing text with ChatGPT
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s return to your boss’s inquiry and discover what customers most often complain
    about. To address this task, you first need to identify negative reviews using
    one of the methods described in previous sections. For demonstration purposes,
    we will take a shortcut and use the set of negative reviews determined by the
    `review_score` variable, which was previously used to assess the effectiveness
    of our sentiment analysis. Once the negative reviews are extracted, they will
    be subjected to text summarization for further insight.
  prefs: []
  type: TYPE_NORMAL
- en: This is a good opportunity to mention another potential issue with texts such
    as customer reviews. As globalization spreads, you can expect these texts to appear
    in dozens of languages. When using traditional NLP methods for summarization,
    the reviews should first be clustered by language, then translated to a common
    language (most likely English), and only then be subjected to further analysis.
    With the polyglot capabilities of generative AI, all these steps can be reduced
    to a single mention in the prompt, indicating that regardless of the input language,
    you want the summaries in the language of your choice. How brilliant! With generative
    AI at hand, we can finally finish building the Tower of Babel and even make some
    cash by offering it for short-term rent!
  prefs: []
  type: TYPE_NORMAL
- en: As a warm-up, let’s see how generative AI can summarize the longest review in
    our example dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**Summarize this text “NÃO RECEBI O PRODUTO,
    O PRODUTO CONSTA COMO ENVIADO PARA O CORREIO DE RIBEIRÃO PRETO. O CORREIO NÃO
    RECEBEU O PRODUTO. ENVIE VARIAS MENSAGEM PARA A targaryen E NÃO OBTIVE. ESTA targaryen
    ESTA SUJANDO SEU NOME”. Use Portuguese in your summary. Provide English translations
    for both the original and the summary.'
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Response.png)**Here’s a summarization of the given text
    using a simple non-ML approach based on extracting the most frequent words:'
  prefs: []
  type: TYPE_NORMAL
- en: '[...]'
  prefs: []
  type: TYPE_NORMAL
- en: 'Summary (English translation):'
  prefs: []
  type: TYPE_NORMAL
- en: “PRODUCT NOT RECEIVED, POST OFFICE NOT RECEIVED, targaryen NO RESPONSE.”
  prefs: []
  type: TYPE_NORMAL
- en: Please note that this summarization is relatively simple and may not capture
    all the nuances of the original text. For more accurate and coherent summarization,
    you can use more advanced techniques like TextRank, or machine learning-based
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'This response is fast, easy to obtain, and comprehensive. You can further play
    with your favorite generative AI and ask it to generate longer or shorter summaries,
    review titles, and review descriptions written in the style of your favorite author,
    or you can even ask it to turn your boring reviews into pretty brilliant haikus,
    like this one:'
  prefs: []
  type: TYPE_NORMAL
- en: Product never came,
  prefs: []
  type: TYPE_NORMAL
- en: Messages to targaryen,
  prefs: []
  type: TYPE_NORMAL
- en: Silent, tarnished name.
  prefs: []
  type: TYPE_NORMAL
- en: Remember the protagonist in Chuck Palahniuk’s *Fight Club* who fought his office
    boredom by disseminating haikus to all employees? Armed with your newly gained
    knowledge, you can now harness generative AI to develop a straightforward application
    that sends negative feedback back to the unhappy customer in this elegant form.
    At the very least, they shouldn’t be grumbling about the absence of a response
    any longer. However, do not expect any praise from your boss after this exercise.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.4 Summarizing text with dedicated libraries
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When selecting NLP summarization techniques, your choice should depend largely
    on the type and length of the text to be summarized. For extensive texts such
    as books, abstractive summarization techniques are often more suitable. These
    methods can generate concise overviews by understanding and paraphrasing key concepts,
    making them ideal for capturing the essence of lengthy narratives or detailed
    discussions without needing to quote the original text extensively. For scientific
    articles or technical documents, a mix of extractive and abstractive methods might
    be best, pulling out significant sentences or terms (extractive) and then synthesizing
    those elements into a coherent summary (abstractive) that captures the document’s
    main findings and implications. Moving to shorter texts, such as news articles
    or blog posts, extractive summarization can be effective, identifying and compiling
    the most informative parts directly from the source.
  prefs: []
  type: TYPE_NORMAL
- en: For short texts such as customer reviews, it may be more beneficial to concentrate
    on extracting main keywords or topics rather than creating summaries. Sentiment
    analysis, coupled with keyword extraction, often provides sufficient insight.
    In fact, given the exercises in the previous sections, you should generally know
    what to expect from text summarizations of the negative reviews.
  prefs: []
  type: TYPE_NORMAL
- en: 'As for the particular methods, text summarization techniques can generally
    be divided into two categories: rule-based approaches and machine learning approaches.
    Each offers distinct methods for generating text summaries, with their own strengths
    and limitations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Rule-based approaches rely on predefined linguistic rules and heuristics, such
    as sentence length, position, and the frequency of key terms, to extract important
    sentences. While straightforward and interpretable, these approaches can be rigid
    and may fail to adapt to the nuances of different texts. Here are a couple of
    the most common rule-based methods for generating extractive summarizations:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Sentence scoring and extraction*—This method scores sentences based on predefined
    criteria, such as the position of the sentence and the presence of keywords. Term
    frequency-inverse document frequency (TF-IDF) is often used to score sentences
    based on the frequency of important terms. The highest-scoring sentences are then
    combined to form the summary.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*TextRank*—A variation of the PageRank algorithm, TextRank represents sentences
    as nodes in a graph, with edges representing content overlap. The most central
    sentences are extracted for the summary.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Frequency-based methods*—This approach identifies and extracts key terms,
    *n*-grams, or phrases from the text that represent the main topics. These keywords
    are then used to create a summary.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Cue phrase method*—Utilizes specific cue phrases (e.g., “in summary,” “to
    conclude”) that often signal important information. Sentences containing these
    phrases are extracted for the summary.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Lead-based summarization*—Commonly used in news articles, this method involves
    extracting the initial few sentences or the first paragraph, assuming that text
    contains the most critical information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rule-based approaches can also be used for abstractive summarization. However,
    this requires rule-based paraphrasing or predefined templates to generate summaries
    by filling in slots with relevant information extracted from the text. As you
    might guess, the output is not as smooth as the abstractive summaries created
    by generative AI.
  prefs: []
  type: TYPE_NORMAL
- en: 'Apart from rule-based approaches, Python offers multiple machine learning techniques
    to summarize texts: latent semantic analysis (LSA) and latent Dirichlet allocation
    (LDA) can be used to analyze latent topics, whereas pretrained language models
    like BERT, text-to-text transfer transformer (T5), and Bidirectional and Auto-Regressive
    Transformer (BART) can be fine-tuned for specific tasks. Presenting the details
    of these methods and their capabilities is beyond the scope of this book, not
    to mention that most of them are designed for other purposes than summarizing
    texts as short as our reviews. However, with options like the Gensim, scikit-learn,
    and Hugging Face Transformers libraries, you can select the right technique for
    your requirements and text type. At the same time, generative AI can assist you
    and provide advice.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now revisit our example. To understand how traditional NLP methods can
    summarize reviews and to compare them with the straightforward approach presented
    in section 6.3.3, we will use a simple rule-based technique—a frequency-based
    approach—to analyze our negative reviews. This method identifies the most common
    words after removing stopwords, providing a quick insight into the prevalent concerns
    or keywords within each review. First, we will ask ChatGPT to generate relevant
    code in Python, using this prompt, “Provide Python code to generate summaries
    of very short customer reviews in Portuguese. Use a frequency-based approach.”
    The resulting code, after some adaptations to our input data, can be found in
    the Jupyter notebook in the book’s GitHub repository.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.6 Summarizing the longest review—a frequency-based approach
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: The code proposed by generative AI functions well and can be readily adapted
    to summarize reviews in the entire dataset. For instance, the three-word summary
    of the example review from section 6.3.3 is “produto, correio, targaryen” (product,
    mail, targaryen). In this context, “targaryen,” like all *Game of Thrones* house
    names, are our data provider’s means of anonymizing store names.
  prefs: []
  type: TYPE_NORMAL
- en: You can generate longer and more informative summaries by modifying the `num_keywords`
    parameter in the preceding code. However, in our opinion, the output generated
    with this simple frequency-based approach is not as precise and to the point (and
    not even as entertaining) as ChatGPT’s haikus. Direct three-word summaries “manually
    crafted” by generative AI also seem a bit better, although a more rigorous approach
    would be needed to assess which outcome is truly superior.
  prefs: []
  type: TYPE_NORMAL
- en: To get a feeling for the results, you can compare the output for the first five
    reviews, gathered in table 6.5\. All translations were provided by ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: Table 6.5 Summary efforts on a sample of five customer reviews
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Translated review | Three-word summary by frequency-based methods | Three-word
    summary by ChatGPT 4 | ChatGPT’s haiku |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| I received it well before the stipulated deadline.  | received well'
  prefs: []
  type: TYPE_NORMAL
- en: before
  prefs: []
  type: TYPE_NORMAL
- en: '| Early delivery  | Arrived well before Stipulated deadline nears'
  prefs: []
  type: TYPE_NORMAL
- en: Satisfaction found
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Congratulations Lannister stores, I loved shopping online, safe and practical.
    Congratulations to everyone and happy Easter.  | congratulations lannister'
  prefs: []
  type: TYPE_NORMAL
- en: stores
  prefs: []
  type: TYPE_NORMAL
- en: '| Lannister stores praised  | Lannister stores cheer Safe and practical shopping'
  prefs: []
  type: TYPE_NORMAL
- en: Happy Easter joy
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Efficient device. On the website, the device brand is printed as 3desinfector,
    and upon arrival, it has another name... Update with the correct brand since it’s
    the same device.  | efficient brand'
  prefs: []
  type: TYPE_NORMAL
- en: device
  prefs: []
  type: TYPE_NORMAL
- en: '| Efficient, mislabeled device  | Efficient device Misnamed but still performs
    well'
  prefs: []
  type: TYPE_NORMAL
- en: Update with true brand
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| But a little, lagging... for the price, it’s good.  | a bit lagging'
  prefs: []
  type: TYPE_NORMAL
- en: '...'
  prefs: []
  type: TYPE_NORMAL
- en: '| Lagging, decent value  | Slight lag appears, Yet value stands its ground,'
  prefs: []
  type: TYPE_NORMAL
- en: Acceptable deal.
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Reliable seller, product ok, and delivery before the deadline  | reliable
    seller'
  prefs: []
  type: TYPE_NORMAL
- en: product
  prefs: []
  type: TYPE_NORMAL
- en: '| Reliable seller, prompt  | Trustworthy vendor, Product meets expectations,'
  prefs: []
  type: TYPE_NORMAL
- en: Early delivery.
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI provides both extractive and abstractive summaries
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: While generative AI can perform both types of summarizations, its primary strength
    lies in abstractive summarization, as it has been trained on vast amounts of textual
    data and is capable of generating human-like coherent summaries.
  prefs: []
  type: TYPE_NORMAL
- en: Another concern is that summarizing each negative review individually doesn’t
    effectively address the task assigned by your boss. Someone still needs to read
    through all the summaries and draw conclusions from them. To tackle this issue
    more efficiently, you can employ another method called *topic modeling*, which
    helps identify common themes and topics across a collection of documents, such
    as the negative reviews in this case.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3.5 Topic modeling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Topic modeling is not a form of text summarization per se, but it can be used
    to generate a high-level summary of the main themes and topics in a collection
    of documents. While text summarization techniques aim to create condensed versions
    of individual documents by extracting or generating the most important sentences
    or phrases, topic modeling techniques are designed to uncover the underlying latent
    structure and themes within a corpus of texts.
  prefs: []
  type: TYPE_NORMAL
- en: Topic modeling can help you understand the main topics and their distribution
    across a set of documents, but it does not generate human-readable summaries of
    the individual texts. Instead, it represents each document as a mixture of topics,
    with each topic being a probability distribution over words.
  prefs: []
  type: TYPE_NORMAL
- en: Our example set of negative customer reviews is an ideal candidate for demonstrating
    topic modeling, which can summarize them in a convenient, human-readable form.
    Let’s start by asking ChatGPT for the relevant code, using the prompt, “I have
    a set of short negative customer reviews in Portuguese stored in a pandas dataframe
    column. I want to know what are the main concerns raised by customers. How to
    extract this information from reviews?”
  prefs: []
  type: TYPE_NORMAL
- en: Listing 6.7 Summarizing negative reviews with topic modeling
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The proposed code was manually adapted to analyze only negative results from
    our example dataset (reviews with `review_score` of 1 or 2). The output is a list
    of the five most common topics mentioned in the reviews; however, the topics themselves
    are not presented in a friendly form. Fortunately, we have generative AI at hand
    to help us read and interpret what, by nature, is not human-readable. In this
    case, informing the model directly about the negative nature of the input leads
    to better conclusions.
  prefs: []
  type: TYPE_NORMAL
- en: '**![image](../Images/Init-MA.png)**Can you interpret this output of topic modeling?
    Provide English translations. Keep in mind that the input consisted only of negative
    customer reviews:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '**![image](../Images/Response.png)**Here’s the interpretation of the topic
    modeling output with English translations, considering that the input consisted
    only of negative customer reviews:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'As demonstrated, generative AI can be very useful when dealing with difficult-to-read
    output, particular when it is written in a language you are not familiar with.
    It is evident that generative AI is able to make a nice and plausible story out
    of extracted keywords. However, in our example, all five of the most common topics
    were related to the same issue: dissatisfaction with delivery, which is a take-home
    message for your boss.'
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI interprets the output
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Generative AI is helpful in extracting the essence of the output of text-mining
    methods, even if it is presented in a hard-to-read format and a foreign language.
  prefs: []
  type: TYPE_NORMAL
- en: To conclude, this section showcased the application of generative AI to identify
    the most common customer concerns by employing text summarization and topic modeling
    techniques on the set of customer reviews. In addition, we entertained ourselves
    by generating a bunch of haikus. This comprehensive approach demonstrates the
    versatility and utility of generative AI in the realm of natural language processing
    and text analysis.
  prefs: []
  type: TYPE_NORMAL
- en: However, while generative AI is a powerful language model that performs well
    in various NLP tasks, including text summarization, its performance may not always
    be better than dedicated summarization libraries. The choice between generative
    AI and dedicated libraries depends on several factors, such as the nature of the
    text, the desired summary type (extractive or abstractive), and the domain-specific
    context.
  prefs: []
  type: TYPE_NORMAL
- en: Dedicated summarization libraries may be optimized for specific tasks and can
    often provide more control over the summarization process, enabling users to fine-tune
    the output according to their requirements. Additionally, they may perform better
    on domain-specific or technical texts.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, generative AI’s strength lies in its ability to generate
    more coherent and natural-sounding summaries, especially for abstractive summarization.
    It can be an excellent choice for generating human-like summaries or when the
    focus is on producing easily comprehensible output.
  prefs: []
  type: TYPE_NORMAL
- en: In short, there isn’t a one-size-fits-all answer, and the choice between generative
    AI and dedicated summarization libraries depends on the specific requirements
    of the task at hand. It is essential to evaluate different approaches and choose
    the one that best fits your needs.
  prefs: []
  type: TYPE_NORMAL
- en: Things to ask generative AI
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: How to perform your_task with the help of your API?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is this bunch of text about?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which NLP method will be the best to summarize my type of data?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Can you make this output human-readable?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For complex NLP tasks, certain specialized tools might still surpass the capabilities
    of the most advanced generative AIs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even though generative AI might outperform conventional methods for your NLP
    task, it may not always be cost-effective.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Top generative AI models are high-maintenance pets; many companies find it challenging
    to keep them in-house. To deploy them at an industrial scale, reliance on third-party
    solutions, such as APIs, is often necessary.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The performance of generative AI improves markedly with each version.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Just because version *n* of your preferred generative AI cannot make coffee
    doesn’t imply that version *n*+1 won’t be capable of doing so.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generative AI is brilliant when it comes to text summarization and paraphrasing
    in the given form (prose, poetry, drama, you name it). It provides both extractive
    and abstractive summaries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use generative AI to interpret or summarize results—especially ones that are
    hard to read.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
