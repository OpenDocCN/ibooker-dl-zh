- en: Chapter 6\. Advanced Use Cases for Generative AI in SEO
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With some technical skills or a developer team supporting you, you can create
    powerful customizations to use generative AI at scale to accelerate growth and
    increase revenues. Building SEO systems at scale is where you’ll find the real
    power in generative AI. Instead of training junior SEO associates to research
    keyword targets or do competitive analysis, you can train a model and deploy it,
    which gives you an AI assistant at your fingertips with the ability to get your
    answers in seconds. Instead of scaling content creation by hiring additional writers,
    you can use generative AI to help your existing writers increase their output
    while improving their content quality.
  prefs: []
  type: TYPE_NORMAL
- en: We discussed the basics in [Chapter 3](ch03.html#ch03_getting_started_with_generative_ai_1748358214007893),
    but in this chapter we’ll look at the more technical side of scaling up with automation
    and generative AI. We’ll dive deeper into generative AI implementation, including
    the infrastructure in retrieval-augmented generation (RAG), how to use enterprise
    APIs, and the benefits of generative AI for creating video and audio.
  prefs: []
  type: TYPE_NORMAL
- en: Automation for SEO practitioners increases productivity and reduces the time
    needed for many of your day-to-day tasks. This chapter covers the many benefits,
    use cases, and advantages of automation in SEO using generative AI. We’ll also
    discuss customizing your own generative pretrained transformer (GPT).
  prefs: []
  type: TYPE_NORMAL
- en: The Value of Using Generative AI at Scale
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Think of generative AI as a team of junior associates that you can have do
    much of the tedious SEO legwork for you. Tasks they can perform on your behalf
    include:'
  prefs: []
  type: TYPE_NORMAL
- en: Discovering topics for your site that competitors don’t cover
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying areas of SEO weakness in your existing content that should be addressed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating draft outlines for new content
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Researching key data points and sources for those data points that could add
    depth to your content
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Drafting sections of content for new articles on your site or even full articles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are just some examples of how you might employ AI-based associates. You
    wouldn’t expect to use the work they do without review by one of your expert staff,
    but their work makes your job of creating and improving your content much easier—and
    arguably increases the content’s quality. The result is more cost-effective use
    of your time and effort.
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI can effectively be your brainstorming and drafting partner, just
    as we described in the prior chapters, but on a larger scale if you have technical
    skills or access to developers. As we refer to ways to use generative AI in content
    development in this chapter (and throughout the book), this is how you should
    think about its value.
  prefs: []
  type: TYPE_NORMAL
- en: You can also improve the quality of the output of generative AI tools by connecting
    them to your own market-specific knowledge base, which will give you a competitive
    edge. Whatever your business, if you’re not building your own knowledge base,
    you’re going to fall behind. Your market knowledge base is a set of data points
    that AI can ingest to return an output of ideas, outlines, and summaries of your
    content, informed by your unique data. Data fuels AI and produces richer outputs
    and personalization from generative AI.
  prefs: []
  type: TYPE_NORMAL
- en: One prerequisite is some technical know-how. To take advantage of many of the
    advanced use cases mentioned in this chapter, you’ll need some background knowledge
    in software engineering, or you’ll need an engineering team to help with the technical
    aspects of the work. The technical investment will give you exponential returns,
    so it’s worth the time and money necessary to invest in advanced generative AI
    use cases.
  prefs: []
  type: TYPE_NORMAL
- en: AI-Powered SEO Tools for Inspiration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we get into the more advanced technical side of generative AI, we should
    mention that you can leverage several AI-powered features using premade tools
    already on the market with a long history of SEO benefits. These tools are much
    more limited than what you can do with your own programming and custom models,
    but they are a good starting point and can give you ideas for developing your
    own tools.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s say you want to find new content to publish on your site. You know you
    should focus on content that can get you more visibility, but where do you start
    looking for ideas? You could home in on trends, but how do you find these trends?
    Google Trends helps you get a general idea of topics, but it won’t find you keywords
    to target. AI-powered tools can generate a long list of content topics to target
    based on keywords from third-party APIs, their popularity in users’ search queries,
    and related keywords to suggest similar content you may not have thought about
    without the tools. The third-party APIs (e.g., Semrush or Ahrefs) require additional
    coding, but automation agents can use third-party APIs to come up with common
    keywords that you can then feed to generative AI models to find content topics
    and suggest titles.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 4](ch04.html#ch04_using_ai_to_scale_content_development_1748358216258351),
    we discussed manual processes for using generative AI for parts of this process;
    now envision AI agents querying these data sources and making the output better
    at scale, without manual intervention at each step. The main human intervention
    other than prompt tuning is the expert review and edits at the end.
  prefs: []
  type: TYPE_NORMAL
- en: AI-powered tools can also help with backlinking opportunities. Just like content
    topic ideas, you first need a third-party API to obtain information about competitors.
    Agents poll these APIs for competitor analysis and information, and then feed
    results to a generative AI model to find topics for backlinks or a gap analysis
    to understand your competitor’s backlink profile better. You can use them to find
    where competitors have their backlinks or domains with similar keywords that might
    be beneficial. You can also discover mentions of your brand on social media or
    other sites with third-party APIs and use AI to analyze user feedback about your
    brand.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following tools existed before GPTs and current generative AI models, but
    they each have their own AI that you can use in your agents and scripts:'
  prefs: []
  type: TYPE_NORMAL
- en: Semrush
  prefs: []
  type: TYPE_NORMAL
- en: Semrush is a subscription service for keyword research, competitor analysis,
    and topic research for generative AI creation. It also has a rich database of
    your backlinks.
  prefs: []
  type: TYPE_NORMAL
- en: Ahrefs
  prefs: []
  type: TYPE_NORMAL
- en: Audit your backlink history and find opportunities for content topics. Ahrefs
    also can be used for keyword research.
  prefs: []
  type: TYPE_NORMAL
- en: Grammarly
  prefs: []
  type: TYPE_NORMAL
- en: Grammarly is beneficial for optimizing content and finding awkward wording to
    create more engaging content.
  prefs: []
  type: TYPE_NORMAL
- en: Google Analytics
  prefs: []
  type: TYPE_NORMAL
- en: Most SEO practitioners already work with Google Analytics, but it’s a great
    tool for identifying traffic trends and optimizing ad content for better conversions.
  prefs: []
  type: TYPE_NORMAL
- en: Yoast SEO
  prefs: []
  type: TYPE_NORMAL
- en: The Premium version of Yoast SEO gives you AI-powered titles and meta descriptions.
    It also provides content suggestions for better search visibility.
  prefs: []
  type: TYPE_NORMAL
- en: Custom GPTs for More Targeted Brand Content
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In November 2023, OpenAI released functionality that enables users to create
    custom GPTs. Custom GPTs are beneficial for very defined use cases. When you build
    a custom GPT using an LLM like OpenAI’s ChatGPT, you can use your own proprietary
    data, but ChatGPT will fall back on its knowledge base in scenarios when it does
    not have an answer from your data.
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT is great at helping you create content ideas, but you will want to narrow
    down topics to content related to your brand. For example, suppose you want to
    develop a chatbot to answer basic customer service questions. You don’t need your
    chatbot lecturing users on the history of a product. You need the chatbot to provide
    information specific to the product that draws key information from your knowledge
    base. You can do this by creating your own custom GPT that focuses on just those
    topics.
  prefs: []
  type: TYPE_NORMAL
- en: Another good use for custom GPTs is to recommend products based on your users’
    search and purchase history—similar to the “people who bought this also bought”
    feature you see on many ecommerce sites. If you can save and store that data in
    a knowledge base, you can use a custom GPT to implement the solution. You can
    also use custom GPTs for content creation, language translations, and marketing
    messages created for social media (though these will still need human editors
    to check for accuracy and brand tone before publishing). Any generative AI product
    can be customized with its own GPT for your brand.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before you create a custom GPT, you first need to define several factors:'
  prefs: []
  type: TYPE_NORMAL
- en: What do you want the GPT to generate? Answers to customers’ questions? Content
    for your site?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What tone do you want to use? Maybe you want to generate content in pirate-speak
    for children’s learning or you want your GPT to stay professional and answer customers’
    queries. GPTs can generate responses using a specific tone and personality.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are your data sources? Will you be using a database of orders for your
    ecommerce chatbot assistant, recent search data collected from your site, or general
    knowledge about your market?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Answers to these questions will be used to set up and configure your custom
    GPT. Don’t forget that you still need to monitor and continually update your GPT
    with new data as you incorporate more information in your knowledge base. After
    the GPT’s initial deployment, it’s common for businesses to find bugs or make
    changes to configurations as well.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Custom GPT
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To create a custom GPT, you first need an OpenAI Plus account. OpenAI has a
    free version of ChatGPT, but you cannot create custom GPTs or use the latest version
    of ChatGPT. As of the time of writing, a Plus subscription costs $20 per month.
    You can also work with a Team account for enterprises at $25 per person per month.
    The examples shared here were created using the Plus subscription of ChatGPT.
  prefs: []
  type: TYPE_NORMAL
- en: In your Plus OpenAI account, click the icon with your initials in the upper-right
    corner as shown in [Figure 6-1](#ch06_figure_1_1748359259618009) and then click
    My GPTs. OpenAI has its own tool to help you create your custom GPT, so you get
    some direction as you go through the process.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ugai_0601.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-1\. OpenAI’s drop-down menu for accessing custom GPTs
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Next, click Create a GPT, as shown in [Figure 6-2](#ch06_figure_2_1748359259618055).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ugai_0602.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-2\. OpenAI interface to create a new custom GPT
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You’re now in the interface to create your custom GPT. You should be looking
    at a web page like the one shown in [Figure 6-3](#ch06_figure_3_1748359259618082).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ugai_0603.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-3\. First prompt to create a custom GPT in the OpenAI web interface
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Let’s create a custom GPT that answers questions about writing a book. We want
    a GPT that helps writers understand the process of outlining, writing, editing,
    proofing, and publishing an ebook. Because ChatGPT is conversational, we can enter
    instructions using the same tone you would use to instruct a writer in person.
    We’ll use the following prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: I want a custom GPT that helps writers understand the process of outlining,
    writing, editing, proofing, and publishing an ebook.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: You’ll see a wait message indicating that a custom GPT is being created. Then,
    you’ll receive a suggestion for a GPT name. For simplicity, we’ll use the suggested
    title “Ebook Guide” shown in the interface in [Figure 6-4](#ch06_figure_4_1748359259618104).
    ChatGPT will also generate a suggested image. For simplicity, we’ll use the suggested
    image.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ugai_0604.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-4\. OpenAI instructions for a custom GPT
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The example creates a custom GPT for you, but you can save yourself some time
    by using third-party custom GPTs available in the OpenAI marketplace. In the OpenAI
    interface, you’ll see a button for Explore GPTs in the top-left corner. Clicking
    this button opens an interface where you can search for custom GPTs that others
    have developed. The quality and usefulness of these GPTs vary depending on the
    creators, but you can find dozens of custom GPTs for SEO already built and ready
    to use.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, suppose you want to improve engagement with your content. Several
    custom GPTs are available that can help with content tweaks to improve readability
    and give the text a more human tone. You can also use these GPTs for keyword focusing,
    editing, fact-checking, analyzing content for gaps, analyzing links to compare
    your content with competitors’ content, and numerous other tasks that you can
    leverage without the need to create and customize your own GPT.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring Your GPT
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: At the top of the ChatGPT creation window is a Configure button. Click it to
    see the configuration options. For example, ChatGPT gives you suggested conversation
    starters to help your users, but you can write your own to fit your brand and
    the questions you commonly get from customers. In this window, you can also change
    the description and title of your GPT.
  prefs: []
  type: TYPE_NORMAL
- en: If you already have a knowledge base for your business, that’s where the real
    power lies because you can generate content and answers for your brand and customers.
    In the configuration window, you can upload files to add your knowledge base to
    your custom GPT. Since this example is a chatbot to help writers, you could upload
    files with tips and tricks for outlining, writing chapters, and self-editing.
    This information is ingested and incorporated into your custom GPT’s responses
    to queries.
  prefs: []
  type: TYPE_NORMAL
- en: For brands, you can upload files like data sheets or marketing brochures that
    explain your products. An enterprise could have thousands of pages of product
    information, and a custom GPT will ingest those in seconds and use the data for
    customer queries. Instead of training a team of people to answer questions, a
    custom GPT becomes your customer support team to help answer brand questions (though
    you will still want some level of human oversight).
  prefs: []
  type: TYPE_NORMAL
- en: Instructions for our custom GPT are shown in [Figure 6-5](#ch06_figure_5_1748359259618124).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ugai_0605.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-5\. Configuration window for a custom GPT
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Notice that you can give your custom GPT image generation capabilities. You
    could include this option if you want to create custom images for your brand.
    For basic chatbots, you probably don’t want to allow this option. Another added
    function is code interpretation. You might use this function, for example, if
    you have a custom GPT for a GitHub library where the GPT can answer questions
    about coding errors and bugs.
  prefs: []
  type: TYPE_NORMAL
- en: You can also hook your custom GPT into external APIs. The external APIs can
    feed your custom GPT’s data and knowledge. For example, suppose you want to continually
    feed new data to a user’s web shopping interface in an ecommerce store. You can
    feed data from an API to the custom GPT in real time to constantly update a customer’s
    suggestions with seasonal or current news content with an abnormal spike in popularity.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, you can create GPT actions, which enable users of your custom GPTs
    to make calls to APIs of tools outside ChatGPT so that you can significantly extend
    the functionality of your GPT. Users continue to make their requests using natural
    language, and the GPT automatically converts those requests into the JSON schema
    required by the API. This can include accessing third-party data stores, so you
    don’t need to download copies of their data, and it increases the resiliency of
    your custom GPT by allowing it to always access the latest data rather than a
    potentially outdated data store that you may have downloaded.
  prefs: []
  type: TYPE_NORMAL
- en: After you’re finished configuring your GPT, click Create in the upper-right
    corner. You can publish it to only yourself (the “Only me” option), to anyone
    with the link (such as sharing with a team), or to the GPT store. The GPT store
    makes your custom GPT available to the public.
  prefs: []
  type: TYPE_NORMAL
- en: After you create a custom GPT, your job isn’t over, though. You still need to
    test it. Your custom GPT will be available in your OpenAI dashboard. After publishing
    the GPT, you can click on it and ask it questions.
  prefs: []
  type: TYPE_NORMAL
- en: As with anything AI, you never want to “set it and forget it” without any review,
    especially if you use advanced configurations with API integration. You might
    need to change the knowledge section or tweak the data returned by your API. Even
    after you tweak the custom GPT, you should check it thoroughly to ensure that
    it’s still returning helpful answers to customers’ queries.
  prefs: []
  type: TYPE_NORMAL
- en: Personalized and Dynamic Content Optimization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The power of generative AI is in its ability to generate personalized and dynamic
    content at scale. The “at scale” power of generative AI is in automation.
  prefs: []
  type: TYPE_NORMAL
- en: We created a custom GPT in the previous section, so now we’ll talk about generating
    personalized and dynamic content. GPT is sufficient for basic queries, but more
    advanced automation is done with a system called *retrieval-augmented generation*
    (RAG). RAG feeds data into an LLM from various sources that you control, ensuring
    that the generative AI tool you’re working with uses information that you know
    is correct. For RAG, you need more technical skills, but you can completely automate
    many of the manual SEO procedures that you might currently perform.
  prefs: []
  type: TYPE_NORMAL
- en: An Introduction to RAG
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: RAG architecture incorporates LLMs with traditional data storage systems. For
    example, you can use RAG with a standard relational database collecting data from
    a custom GPT, or you can use it with large datasets collected from web searches
    or knowledge bases. SEO practitioners can use RAG for generating content from
    data collected in keyword research, backlink analysis, or locally from your brand’s
    site.
  prefs: []
  type: TYPE_NORMAL
- en: Merging data retrieval with dynamic data enables RAG systems to find similarity
    in content and use your unique knowledge base in crafting the output. LLMs take
    time to train, and many common models work with slightly older data, so they aren’t
    aware of more recent events. You can make the more recent information available
    through your RAG system. More important, using custom data will be much more efficient
    than relying on the data from broad LLM systems, and it can more easily be personalized
    for highly dynamic businesses. RAG architecture lets LLMs retrieve data during
    the time it takes to process a user query, allowing LLMs to ingest data in real
    time to produce more accurate answers with as much relevant context as possible.
    You get higher generative AI accuracy with content generation at scale. You can
    still get errors once you implement RAG to address them, but you can reduce the
    rate at which they occur.
  prefs: []
  type: TYPE_NORMAL
- en: An LLM needs data to provide accurate answers, and generative AI tools still
    have significant issues with accuracy when data is insufficient. For example,
    suppose you want to identify common questions from a chatbot. Your chatbot collects
    questions and stores them in a relational database. You can feed an LLM questions
    and answers from the relational database to then generate content and upload it
    to a WordPress blog hosting your knowledge base. This process can be used to protect
    you from hallucinations that the generative AI tool may make. The term *hallucinations*
    describes the inaccurate results you might get from AI when the LLM does not have
    enough reference material or simply references incorrect information found online.
  prefs: []
  type: TYPE_NORMAL
- en: RAG content generation provides a personalized experience for your readers.
    Your business might launch a new product, so you now need to generate content
    for a knowledge base. It can take weeks to build out a large knowledge base for
    a new product, but generative AI can provide you with a draft for human review
    in minutes. APIs can have hundreds of endpoints, but generative AI can generate
    draft developer knowledge base content in minutes when developers deploy their
    solution. Anytime you need personalized content based on custom brand input, generative
    AI can help.
  prefs: []
  type: TYPE_NORMAL
- en: The Many Different Types of LLMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before you build out your RAG architecture, you need to determine which LLM
    you want to use. You have several options, but each one has its own tone when
    it writes content. For example, ChatGPT is one of the most popular generative
    AI models available, but it can be much more robotic sounding and verbose than
    some of the other platforms. Claude, on the other hand, produces content that
    is considered much closer to sounding human.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: AI is quickly evolving, so it’s important to note that new LLMs and updates
    to existing LLMs will be available after the publication of this book. It’s likely
    that newer versions are available as you’re reading this.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few LLMs as of May 2025 that you can consider working with:'
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT-4.5 and OpenAI o1
  prefs: []
  type: TYPE_NORMAL
- en: ChatGPT-4.5 is one of the more popular and flexible multimodal LLMs. It also
    has DALL-E for creating images. It’s fast and has been trained on the billions
    of pages published on the internet, including trillions of words of text, code,
    and translations. OpenAI fine-tunes its LLM with reinforcement learning from human
    feedback (RLHF), which you can use to improve results as you work with the model.
    OpenAI o1 integrates advanced reasoning and is better for advanced coding, scientific
    research, or anything that requires step-by-step problem-solving. Keep in mind
    that o1 is slower and costs more per token. (*Tokens* are like credits or digital
    currency to “pay” for generative AI output.)
  prefs: []
  type: TYPE_NORMAL
- en: Anthropic Claude 3.7 Sonnet and Opus
  prefs: []
  type: TYPE_NORMAL
- en: As of this writing, Claude 3.7 Sonnet is the most recent LLM model from Anthropic.
    It’s known for having more humanlike output, but it also excels at analyzing visual
    input, such as graphs or photos. Sonnet is best for multistep workflows and is
    particularly effective for orchestrating tasks that require fast processing and
    context-sensitive responses. Claude Opus performs well with advanced content creation.
    It’s known for its ability to handle intricate tasks like generating detailed
    research reports, analyzing complex data, and creating high-quality content that
    demands a deeper understanding.
  prefs: []
  type: TYPE_NORMAL
- en: Google Gemini 1.5 Pro and 1.5 Flash
  prefs: []
  type: TYPE_NORMAL
- en: 'Google has been using AI for years and published the original paper on transformers—the
    technology that LLMs are based on—in 2017\. As of this writing, Google has two
    notable models: Google Gemini 1.5 Pro and 1.5 Flash. Both AI models can process
    text, images, audio, and video, but they have different uses and are optimized
    for different tasks. Gemini 1.5 Pro is designed for complex tasks and is better
    for deep reasoning and nuanced understanding. It can perform sophisticated reasoning
    tasks, such as generating summaries of long-form text, audio recordings, or video
    content. Gemini 1.5 Pro can also be used for content creation, story writing,
    and scriptwriting. Gemini 1.5 Flash is optimized for rapid response times and
    is better for applications that require quick processing and low latency. It’s
    ideal for time-sensitive tasks, such as chat applications and real-time data analytics.'
  prefs: []
  type: TYPE_NORMAL
- en: Google PaLM 2
  prefs: []
  type: TYPE_NORMAL
- en: PaLM 2 is designed for language applications while Gemini is designed for multimodal
    applications. PaLM 2 is better at advanced tasks like summarization and question
    answering in languages it knows well. Gemini is better at creative writing, such
    as poems, lyrics, or dialogue. If you’re dealing only with text-based modalities
    and need translations, you might consider [PaLM 2](https://oreil.ly/yqCV4) to
    help produce content at scale for multiple languages.
  prefs: []
  type: TYPE_NORMAL
- en: Several open source models also exist if you want to lower costs and customize
    models. We’ll discuss why and when to use custom LLMs in [“Building RAG Architecture”](#ch06_building_rag_architecture_1748359259642922),
    but know that you have several options for open source LLMs if you have the technical
    expertise (or technical team) to customize a preexisting model. Open source LLMs
    may require a steeper learning curve but could have a lower overall cost of ownership
    after setup. Open source models are available to anyone, so vulnerabilities must
    be reported to the creator to be patched. Vulnerabilities are dangerous because
    they can be used to poison results or gain access to your data.
  prefs: []
  type: TYPE_NORMAL
- en: 'A few of the available open source models include:'
  prefs: []
  type: TYPE_NORMAL
- en: Milvus
  prefs: []
  type: TYPE_NORMAL
- en: A vector database built for scale and machine learning applications
  prefs: []
  type: TYPE_NORMAL
- en: Meta Llama
  prefs: []
  type: TYPE_NORMAL
- en: An AI model provided for text-based output
  prefs: []
  type: TYPE_NORMAL
- en: Grok
  prefs: []
  type: TYPE_NORMAL
- en: An AI model for text-based output but built to be more conversational
  prefs: []
  type: TYPE_NORMAL
- en: Building RAG Architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The algorithms and backend processing for RAG are complex, but creating the
    architecture has only two steps:'
  prefs: []
  type: TYPE_NORMAL
- en: User input, such as a query from your site’s search functionality or a chatbot
    question
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The source data, which could be a database, a group of dynamically created files,
    a NoSQL database, web pages, or any other source that can be fed to an LLM
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Although creating a custom GPT requires no coding, creating RAG architecture
    requires some technical knowledge. You can use your own local LLMs with RAG. We’ll
    use the same custom GPT that we created previously to generate output content.
    You can see an example of RAG infrastructure in [Figure 6-6](#ch06_figure_6_1748359259618143).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ugai_0606.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-6\. General overview of RAG infrastructure
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Suppose you need to create content about your brand, but you don’t want it to
    include knowledge that is too general about your products. Your brand might sell
    mobile phone accessories, but you don’t want a history of mobile phones in your
    content collection. You can use your own brand content to feed an LLM—in this
    case, ChatGPT—and then build content based on the input.
  prefs: []
  type: TYPE_NORMAL
- en: In the following example, we’ll use keyword input to build brand content from
    a corpus of web pages on your site. For example, suppose you did some keyword
    research (which, incidentally, can be automated with AI, but more on that later),
    and you want to use common search phrases to build content around your brand.
    You can automate this using your language of choice. Examples in this section
    will use Python.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a RAG implementation, you need three things:'
  prefs: []
  type: TYPE_NORMAL
- en: A corpus, or the collection of data the LLM will use to generate content
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The API for ChatGPT for the LLM
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Content generation from input of keywords or search phrases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gathering the corpus
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first step to creating a RAG implementation is to gather the corpus. The
    *corpus* is the collection of data used to train AI. It’s a fancy term for “background
    knowledge.” You can use any amount of corpus data, including information stored
    in a database, web pages, static files, and even images.
  prefs: []
  type: TYPE_NORMAL
- en: Without the corpus, you will get general information in response to the input
    provided. For example, if you input “mobile phone,” you’ll get all kinds of output
    ranging from the history of the mobile phone to mobile phone vendors to questions
    and answers about fixing a mobile phone. If you’re selling accessories, this information
    will pollute your content output. The corpus will train the LLM on your brand
    and target audience so that you can get much more precise and accurate results.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example, a local collection of brand web pages will serve as the corpus.
    In a real-world situation, you’d crawl your site or use a sitemap to add to the
    corpus, but for simplicity we’ll use hardcoded text for our example. The following
    code example has a sentence or two to represent a brand page, but your web pages
    will contain several lines of content to train the LLM. Notice that the corpus
    is specific to our brand:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Connecting to the LLM API
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'After you have the corpus, you then need to connect to the LLM API. For this
    example, we’ll use ChatGPT as the LLM, but several others have APIs (e.g., Microsoft
    Azure, Google Cloud, Anthropic, Hugging Face). You’ll need an account, which must
    be a paid account for any of the major LLMs. Every API also requires access keys.
    You can find out how to generate keys for your account in the LLM’s documentation.
    We’ll assume you have the OpenAI Python library installed. If not, you can use
    the following install prompt in your Python development interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'With OpenAI installed, you can now create a connection to the ChatGPT API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Generating content from user input
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now you need the code to pull a document—a web page in this scenario—and you’ll
    work with user input to create content. Our user input is from keyword research.
    Keyword research can be done manually using the SEO tools mentioned in [“AI-Powered
    SEO Tools for Inspiration”](#ch06_ai_powered_seo_tools_for_inspiration_1748359259642457),
    or you can perform research using automated agents (discussed in the next section).
    For this example, it’s assumed you have a list of keywords in a text file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: This example is simple, but you can incorporate agent output and automation
    into content generation and RAG. The important part of this code is the prompt.
    The prompt is sent to the LLM and tells it what to use to generate content.
  prefs: []
  type: TYPE_NORMAL
- en: LLMs can generate more than simple page content. You could use competitor analysis
    to create a list of publications for backlink opportunities, find the top five
    competitor pages and their keywords to create drafts of your own content, create
    outlines from a gap analysis from your pages compared to competitors’ pages, or
    simply make content based on trending keywords, just like we did here.
  prefs: []
  type: TYPE_NORMAL
- en: Using RAG gives your brand the ability to work with real-time data for content
    generation, but you don’t always need human queries. You can automate draft content
    generation using agents to identify keywords and input these keywords into your
    RAG system.
  prefs: []
  type: TYPE_NORMAL
- en: Custom LLMs or building from scratch
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the preceding example, we used ChatGPT as the model, but you aren’t limited
    to common LLMs. You can also use custom LLMs, but you should use them only with
    very specific use cases. The common LLMs mentioned previously have trillions of
    data points to work with, so you can ask them anything with varying degrees of
    results. With a custom LLM, you define the model and limit it to your specific
    use case. For most businesses, a custom LLM is not necessary. The model will be
    able to produce results only on certain data, so it does not have the additional
    information available with common LLMs.
  prefs: []
  type: TYPE_NORMAL
- en: To create your own LLM, you need the infrastructure, a large corpus, testing
    resources, technical development experience, and funds to host it. Models require
    graphics processing unit (GPU) hours to compute training. You can use cloud providers
    to train a model, but of course you must pay for the resources. It costs about
    $1–$2 per GPU hour, so a small 10-billion parameter model that takes about 100,000
    GPU hours could cost you up to $200,000 to train. For a frame of reference, Llama
    2 has about 70 billion parameters, so it can cost well over $1 million to train
    a large model.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are four steps in building an LLM from scratch:'
  prefs: []
  type: TYPE_NORMAL
- en: Curating the data
  prefs: []
  type: TYPE_NORMAL
- en: This is the most time-consuming step. You need accurate, quality, deduplicated
    data and a source with enough information to train the model. You can use the
    internet, but you can also use public datasets, including Common Crawl and Hugging
    Face. Another option is using an LLM to create a dataset. Datasets should be diverse,
    depending on your desired output. You can use web pages, code, books, news, articles,
    and scientific journals.
  prefs: []
  type: TYPE_NORMAL
- en: Building the model architecture
  prefs: []
  type: TYPE_NORMAL
- en: This is a neural network with attention mechanisms to match input with output.
    Neural networks identify patterns and context so that a word can be “understood”
    compared to other similar words. For example, the neural network must identify
    the position and sequence of a word like *park*. It must identify if the word
    means to park a vehicle or a public place where people hang out.
  prefs: []
  type: TYPE_NORMAL
- en: Training
  prefs: []
  type: TYPE_NORMAL
- en: Training at scale is complex and requires high-value GPUs, mentioned previously.
  prefs: []
  type: TYPE_NORMAL
- en: Testing and review
  prefs: []
  type: TYPE_NORMAL
- en: You must evaluate and review the results of your model. The Hugging Face site
    has benchmarks that can be used to identify the success of your model.
  prefs: []
  type: TYPE_NORMAL
- en: As you can tell, building your own LLM requires extreme technical knowledge.
    You need a team to help you and a large budget for compute power. If your use
    case is very specific, you can generate content that is highly targeted and effective
    at selling your brand services. This can boost sales and make it easier to build
    thousands of pages for your business with a good return on your investment, but
    it’s a long-term, high-value project that must be carefully planned first.
  prefs: []
  type: TYPE_NORMAL
- en: Automating SEO Tasks with AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Think of AI agents as your automated assistants. Your automated SEO assistant
    might know that every morning you need keyword research on the latest trends affecting
    your brand. The agent pulls information from an API and inputs keywords into generative
    AI prompts for content suggestions. An AI agent can gather this data for you every
    day, so you don’t have to rely on a person to perform this task. Your AI agent
    can also analyze trends multiple times during the day so that you can change your
    goals as trends change, making your marketing much more effective.
  prefs: []
  type: TYPE_NORMAL
- en: Suppose that after an agent performs trend analysis for you, you decide to create
    content or perform competitor analysis to see if competitors are ranking for specific
    keywords already. You can have multiple agents “talking” to one another to make
    decisions based on their own output. The AI agent gathering trends every morning
    can send output to another agent that will make the decision to generate content
    based on competitor analysis. The second agent can take these trends, find the
    top five pages for related search terms, and decide if content should be generated.
    Content generation decisions can also be sent to a third agent to create draft
    content ideas based on its own analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Agents are powerful automation tools, but they need a goal. When you build an
    agent, you can integrate generative AI models to help agents make decisions. For
    example, you can have an agent using Claude to evaluate content generated from
    ChatGPT. The back-and-forth evaluation can be used to generate and evaluate content
    until you create a piece that fits your tone and brand style.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ll break down the components of an agent system for generating
    content for a brand.
  prefs: []
  type: TYPE_NORMAL
- en: Infrastructure for AI agents
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An AI agent is like a script running silently on a machine. [Figure 6-7](#ch06_figure_7_1748359259618161)
    shows a few potential roles for agents.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ugai_0607.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-7\. Potential roles for agents
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: When you build your own agents, you need infrastructure to host them. The development
    can be done in any language, but AI is generally built with Python because of
    its prebuilt libraries, which are freely available to developers. You aren’t limited
    to Python, though, and some businesses choose to use R, Java, C++, JavaScript,
    Lisp, and other languages.
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll likely use hosting in the cloud for the ease of resource allocation,
    but you need more than host machines. Here are several factors to consider for
    your AI agent infrastructure:'
  prefs: []
  type: TYPE_NORMAL
- en: Database storage and management
  prefs: []
  type: TYPE_NORMAL
- en: AI requires data for training, and your database of choice can store it. You
    don’t need a database if you plan to ingest data entirely from the internet, but
    chances are you will want to log errors and track what your AI agent is doing,
    which still requires a database to store this data. Also consider the type of
    data you plan to store. Unstructured data requires a NoSQL database, but structured
    data can use traditional relational databases. For example, storing web page data
    is easier with unstructured databases like MongoDB, but logged events could use
    a relational database like MariaDB or PostgreSQL.
  prefs: []
  type: TYPE_NORMAL
- en: Internet access
  prefs: []
  type: TYPE_NORMAL
- en: Your agents will likely run on a local network, but they need access to the
    internet if you plan to understand the third-party content on your topic out there,
    use third-party APIs, or post content to your public-facing site.
  prefs: []
  type: TYPE_NORMAL
- en: Virtual machines or compute resources
  prefs: []
  type: TYPE_NORMAL
- en: Agents are like services that execute an action at a time you program. This
    could be once a day or multiple times a day. You need a host machine and compute
    resources to run the agent and process its results. Don’t provision resources
    that handle only the initial agent processing. You want enough resources for scaling
    as you acquire more data and add more agent tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Security
  prefs: []
  type: TYPE_NORMAL
- en: Don’t forget that security should be integrated into your design workflow. Poor
    security could open your business to lawsuits or data disclosure. Validate data,
    especially when using external internet sources for ingestion and output.
  prefs: []
  type: TYPE_NORMAL
- en: Agent roles
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will have four agents that will fulfill the following roles:'
  prefs: []
  type: TYPE_NORMAL
- en: SEO analyst
  prefs: []
  type: TYPE_NORMAL
- en: This agent will take common keywords for a brand and get the top articles (or
    top list of articles) from competitors ranking for them.
  prefs: []
  type: TYPE_NORMAL
- en: Researcher
  prefs: []
  type: TYPE_NORMAL
- en: You want content that can perform better than a competitor, so the researcher
    will evaluate each section of content.
  prefs: []
  type: TYPE_NORMAL
- en: Writer
  prefs: []
  type: TYPE_NORMAL
- en: The research agent will feed output to the writer agent, and this agent will
    generate ideas and—if necessary—a summary of these ideas used for drafting content
    with generative AI. A human writer can then take these ideas and write content
    that will be fed to the content editor. You might even have a human editor review
    content and skip the content editor agent.
  prefs: []
  type: TYPE_NORMAL
- en: Content editor
  prefs: []
  type: TYPE_NORMAL
- en: The first pass on draft content might not match what you need, so an editor
    agent can be used to identify mismatched tone and technical information.
  prefs: []
  type: TYPE_NORMAL
- en: SEO analyst
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As an SEO practitioner, you likely monitor specific keywords for your brand.
    You might have a list of trending keywords, a list of seasonal keywords, and general
    brand-related keywords used to generate content. You could manually identify competitor
    performance in search engines, but an AI-powered agent can do it for you. An agent
    will take less time to perform this step, and it can perform analysis several
    times a day rather than having to rely on an analyst to do this manually. You
    might even automate this step, having this agent feed into the next agent to increase
    efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: The SEO analyst agent can pull the top list of articles either from a third-party
    API or using your own search engine scraping solution. Not only will the agent
    identify the top-ranking pages, but it will also extract the content from each
    article. Every agent needs a goal, and this agent’s goal is to pull top-ranking
    articles for a list of keywords. As you can imagine, this is a full-time job for
    a human SEO analyst, but AI-powered agents can perform this activity in seconds.
    An SEO analyst agent is your first step to using AI to power activity at scale
    without staffing limitations.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you build this agent, you write code to cover the actions that other agents
    need to perform. Here are a few examples of tasks you might need agents to do,
    all of which can be prompts entered into one of the common models:'
  prefs: []
  type: TYPE_NORMAL
- en: Keep a log of sites you want to track, such as competitors’ sites or sites that
    have content you want to analyze. Make sure to create prompts with a list of sites
    or ask the model to pull a list of the top-ranking content for a specific search
    query.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Extract content from code. This can be done using a third-party library. You
    need headers, title, and section content, but you don’t need code or formatting.
    You should keep links, though, and their anchor text.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avoid recrawling the same content over and over. Some server headers return
    a last updated variable, but that’s rare. It might be worth keeping a log of URLs
    previously scraped unless you want to analyze updated content. To save resources,
    you can recrawl competitor content only when the search ranking increases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Server statistics might be useful if you are analyzing redirects or errors,
    so it may be helpful to pull and log server responses. For example, the first
    time you pull articles could result in a server 404 error, so you want to retry
    when the agent performs its activity again.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Researcher
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: After you extract content from top-ranking search links, you need to analyze
    the content. The SEO analyst agent sends its output to the researcher agent. At
    scale, this is where the power of AI can really make you more efficient. A person
    could feasibly go through several articles during the day to identify content
    quality, but they can’t go through dozens of articles a day without help. The
    SEO research agent uses an LLM to analyze the content for opportunities to improve.
  prefs: []
  type: TYPE_NORMAL
- en: As the researcher analyzes content, it must determine content keywords and if
    your brand has opportunities to write better content. It’s important to note that
    you want better content, not content that’s “just as good.” The SEO researcher
    agent can help perform this step for you in seconds. With an objective analysis,
    the next agent can assist with building draft content.
  prefs: []
  type: TYPE_NORMAL
- en: To generate better content, the researcher agent might even perform secondary
    searches based on extracted keywords or work with your current brand content to
    identify whether content should be added to existing articles rather than creating
    an entirely new page. You might have a page already ranking in search engines,
    so you may choose to add new relevant content to that. The researcher agent could
    also do a gap analysis to identify the difference between competitors’ content
    and your own so that you can improve your content in line with what’s ranking
    in search.
  prefs: []
  type: TYPE_NORMAL
- en: The researcher agent is limited only by what you can code. You can have additional
    researcher agents in your scaled system, but for this example, we’ll use the goal
    of identifying additional content that can be generated on your site. After the
    researcher agent has finished its analysis, new content ideas are sent to the
    writer agent.
  prefs: []
  type: TYPE_NORMAL
- en: 'Much of the “meat” of your analysis can be done with this agent. Here are a
    few technical aspects that should be coded into your agent:'
  prefs: []
  type: TYPE_NORMAL
- en: Extract keywords using generative AI prompts for help. You could code your own
    extractor, but that would be extremely tedious. Generative AI can do this for
    you.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compare the title of the article with your own and other articles ranking in
    search engines. Research agents can suggest better titles to potentially improve
    rankings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform a gap analysis on your content with the content extracted from top-ranking
    articles. You can prompt generative AI to do the gap analysis for you, so you
    don’t need to create any complex code that could take days to build and test.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using a gap analysis and generative AI results, determine the content you want
    to write and the content you want to update. You might have content that must
    be rewritten or sections that need to be added. Other keywords could be used to
    generate new content.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use a secondary model to fact-check content.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Writer
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If you already use an LLM to write draft content, you know the prompts involved
    with writing. The writer agent calls an LLM API to draft the content. You’ll need
    to experiment to find the LLM that works best for you. Most people think of ChatGPT
    for content creation, but ChatGPT’s output can often seem robotic. You can still
    use ChatGPT if that’s your preference. Your reviews and the editor agent (discussed
    in the next section) should perform fact-checking and validate content tone.
  prefs: []
  type: TYPE_NORMAL
- en: The prompt you use for the LLM depends on your goals. This agent sends the writing
    prompt to the LLM’s API. You’ll need the keyword, tone, intent (e.g., informational
    or transactional), audience, and any brand pages you want to use to shape the
    draft content around your own products. The API returns content, but you can’t
    leave generative AI to write content without any type of validation.
  prefs: []
  type: TYPE_NORMAL
- en: As you build your agent system, always review the content to ensure it is still
    accurate and that the agents are working as they should. When LLMs deploy version
    upgrades, you may want to upgrade your generative AI draft content process for
    the latest version. An update will generate different content compared to older
    versions, so always review new content after upgrading the version.
  prefs: []
  type: TYPE_NORMAL
- en: 'The writer agent is familiar territory if you’ve already used generative AI
    for content. The difference is that the agent automates the creation of draft
    content. Some technical tasks of this agent include:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate section headers to separate content and make it easier for users to
    scan and find the information they want to read.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ask generative AI to create engaging call-to-action links to your products.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Include links to other content within your site.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generate meta descriptions, titles, and a summary of the content.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build questions and answers and focus content on problems that your brand solves.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use examples of your own content or content that you like to get the style and
    tone you’re looking for.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note the emphasis on draft content creation in this section. Generative AI cannot
    be depended upon to write content that you can publish without expert human review.
    Recall our analogy of having a team of junior researchers working for you from
    earlier in this chapter. Generative AI is prone to mistakes, it will miss important
    things, it will not capture your position accurately, and more. The editor agent
    that we discuss in the next section helps make your content better by addressing
    some of these issues, but you still need expert human review before you publish.
  prefs: []
  type: TYPE_NORMAL
- en: Editor
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The final agent in your system checks the writer agent’s draft content. Just
    as in a real-world publishing system, a writer needs an editor to identify awkward
    wording, factual issues, or unclear sections or to add content that improves the
    quality and readability of the text. The editor agent performs this step without
    you having to hire dozens of editors. With generative AI, you create content at
    a greater scale than you can with human writers, so you need to scale your editors
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned in the previous section, you should have a second LLM check for
    errors and content tone instead of the same one. This will improve the accuracy
    of the results. If the editor agent has issues with content, you could send it
    back to the writer agent to have the content rewritten. Another option is having
    the editor generate improved content, but this depends on your system design.
    How you set up your agent design depends on your preferences, but we recommend
    having your editor agent validate content only and send feedback to the writer
    agent. This keeps your system compartmentalized so that you can easily make changes
    to content generation in one location.
  prefs: []
  type: TYPE_NORMAL
- en: The editor agent can also log feedback and content-generation events for further
    review to help you with your management. For example, you may want to know how
    much content was kicked back to the writer agent for factual mistakes, which is
    serious when you want to be seen as an authority in your industry. The editor
    agent can log these events so that you can take a look when too many mistakes
    are being made. You might need to tweak the prompt, or your code could have logic
    errors.
  prefs: []
  type: TYPE_NORMAL
- en: As with human writers, the draft content output from generative AI needs an
    editor. You need to fact-check output and ensure that the content has a human
    tone. Some models like ChatGPT can sound very robotic, but other models, such
    as Claude, are known for sounding a bit more humanlike, so check for the tone
    of the output.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few technical points for creating an editor agent:'
  prefs: []
  type: TYPE_NORMAL
- en: Fact-check output. You fact-checked competitor content with the researcher agent,
    but you must again fact-check the new output to avoid publishing embarrassing
    misinformation on your brand site.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check for tone using a third model. For example, use Claude to check ChatGPT
    content for any tone issues or errors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Send content to a human reviewer before publishing any AI-generated content.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If any errors are found, this agent can send content back to a writer agent
    to reanalyze and re-create it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Enterprise Platforms for Large-Scale Projects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we have said before, the power of advanced generative AI is in its ability
    to scale your SEO projects. You can easily generate one or two articles a day
    for your site, but AI can help you increase content production while improving
    content quality. In [Chapter 2](ch02.html#ch02_essential_background_on_generative_ai_1748358211788823),
    we mentioned that using AI for content can increase throughput by 30%, reduce
    costs by 30%, and increase quality by 30%.
  prefs: []
  type: TYPE_NORMAL
- en: To scale at an enterprise level, you need enterprise platforms. Several cloud
    platforms offer APIs and computing resources to support massive agent systems,
    generative AI content generation, automated analysis, and any other code-based
    SEO project. If you can code it, you need a place to host it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The biggest and most popular platforms are:'
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft Azure
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft has made a large investment in OpenAI and is the creator of Copilot.
    [OpenAI’s API](https://oreil.ly/dtTcC) has endpoints for chatbots, content management,
    and direct questions and answers.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon Web Services (AWS)
  prefs: []
  type: TYPE_NORMAL
- en: Amazon has several APIs and endpoints for all types of machine learning and
    generative AI. For example, [Amazon Bedrock](https://oreil.ly/e98mO) helps with
    building generative AI applications. Bedrock can also be used in RAG.
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI
  prefs: []
  type: TYPE_NORMAL
- en: OpenAI has a convenient [API for content generation](https://oreil.ly/jgFL7).
    ChatGPT is popular for content generation, so it’s likely you’ll have at least
    one agent using the API.
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud Platform (GCP)
  prefs: []
  type: TYPE_NORMAL
- en: Google has an [agent builder](https://oreil.ly/6j69Z) that you can use to alleviate
    much of the technical overhead of building your own infrastructure. Vertex Agent
    Builder API can help with your workflows, and Gemini is beneficial for generating
    text and images.
  prefs: []
  type: TYPE_NORMAL
- en: You aren’t limited to these four platforms, but these have integrated AI APIs
    and services already available. If you choose a smaller provider, make sure they
    have the resources to support generative AI and AI-powered automation.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Once you integrate with a single API provider, you are tied to that particular
    provider. Therefore, you should ensure that the provider has all the features
    and scalability options for your current and future SEO projects.
  prefs: []
  type: TYPE_NORMAL
- en: Any API that you choose will be integrated into your agent programming. It does
    the heavy lifting for you so that you can rely on the third-party infrastructure
    to assist with generating content. The writing agent from our AI agent system
    example could use one of the content generation APIs to build the content, for
    example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before you adopt a specific model, you must understand its limitations and
    what you can do to scale your operations. Using enterprise platforms is about
    scaling, but not every API offers the speed and content quality you need. The
    following are some of the most important features you’ll want to consider when
    selecting a provider for large-scale projects:'
  prefs: []
  type: TYPE_NORMAL
- en: Availability
  prefs: []
  type: TYPE_NORMAL
- en: Most large providers offer at least 99% uptime service-level agreements, but
    regions are important for enterprise-level processing. The farther a region is
    from your processing, the more latency you’ll experience with a delay in transferring
    data. Availability regions are data centers present in the general geographic
    location of your business and your users. To take it a step further, availability
    zones are located in regions of a site user’s country for redundancy. For example,
    [Azure has 54 regions in 140 countries, AWS has 66 availability zones, and GCP
    has 173 zones](https://oreil.ly/wnDB8). Should one data center suffer from an
    outage, another availability zone can take over. Redundancy is important for failover
    and uptime.
  prefs: []
  type: TYPE_NORMAL
- en: Latency
  prefs: []
  type: TYPE_NORMAL
- en: Latency is the time it takes for data to transfer over the network, including
    processing at the database. Having low latency is critical to your application’s
    performance. CPU and storage performance play a part in latency, and these factors
    can turn a one-hour process into a daylong one if they are not optimized. When
    you have to use more computing to reduce latency, you will likely incur higher
    costs. Optimizing computing resources is a must and requires the technical know-how
    to create a scalable infrastructure that doesn’t waste your budget.
  prefs: []
  type: TYPE_NORMAL
- en: Every provider does well with offering computing and networking power for various
    data-transfer sizes. [Benchmarks](https://oreil.ly/jUA1t) show that GCP does the
    best with processing power, AWS does the best with network throughput, and Azure
    does the best with I/O throughput. You can test your applications on all three,
    but fast computing power and network performance are most important when working
    with large data searches and AI processing.
  prefs: []
  type: TYPE_NORMAL
- en: Cost
  prefs: []
  type: TYPE_NORMAL
- en: The cost of your applications will vary depending on the billing model you choose
    and the amount of resources you use. All providers have tools that help you estimate
    how much you will spend each month based on the resources you deploy, but your
    costs will also depend on the number of resources used during agent deployments
    and processing and the number of times you call the provider’s APIs. If you’re
    not careful, you can get blindsided by high costs when your applications make
    too many resource calls. These resource calls could be deliberate, or you could
    have logic errors that exhaust your budget.
  prefs: []
  type: TYPE_NORMAL
- en: All three providers offer on-demand payment plans, but they have alternatives
    for enterprise pricing that give discounts for high-resource applications. As
    of this writing, Azure has a plan named ExpressRoute for leasing a private cloud,
    meaning your data never leaves the data center. This option is great for businesses
    with strict compliance requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on your resources and data usage, you could pay from a couple of hundred
    dollars a month to a few thousand. It’s difficult to say exactly how much you
    will pay, so check the provider’s calculator to help you estimate.
  prefs: []
  type: TYPE_NORMAL
- en: API quotas and token limits
  prefs: []
  type: TYPE_NORMAL
- en: API quotas and costs could be considered the same, but providers often have
    subscription requirements or limitations to the number of API requests. Limitations
    are set to avoid a denial-of-service (DoS) attack on the API servers but are usually
    based on your subscription model. Any calls over the limitations could be extremely
    costly.
  prefs: []
  type: TYPE_NORMAL
- en: The cost of accidentally making too many calls to an API with quotas isn’t just
    a few hundred dollars. Going over API quotas can cost you tens of thousands of
    dollars. Mistakes happen when you have a subscription with high charges after
    you go over a certain number of requests or you have logic errors in your code.
    Let’s say you have a logic error that turns what you think is 5 requests into
    50 requests. Your code runs several times an hour. You could then have hundreds
    of unforeseen requests to an API. If you don’t plan for these requests, you could
    get an unpleasant surprise when you receive the cloud provider’s bill.
  prefs: []
  type: TYPE_NORMAL
- en: Each model and API have different token limits and context-window limitations
    as well. The impact will depend on your use case.
  prefs: []
  type: TYPE_NORMAL
- en: Building Your Own AI Tools and Plug-ins
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: By now, you should be familiar with the typical prompt interfaces provided by
    model vendors, but you can also use APIs to build enterprise-tier plug-ins and
    tools. As an example, let’s say you have a team of marketing people responsible
    for generating content. You might have Microsoft Teams set up for them to speak
    throughout the day. You can create bots for Teams (and other collaboration software),
    so you could create a bot in Teams where all your marketing people can generate
    content.
  prefs: []
  type: TYPE_NORMAL
- en: A Teams bot acts like a user added to your Teams group. A custom bot can give
    an array of different replies to user messages, and a generative AI bot can provide
    content ideas for your marketing team. The bot looks like a standard user account.
    If you’re familiar with Slack, you know that a bot instantly greets you when you
    join a new server. It looks and acts like a real user, but you send it specific
    commands to ask how to use Slack. The same can be done with a Teams bot, except
    this bot will take prompts and instructions from your marketing team and provide
    output text that can be used for content.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s use a simple example of writing content about US presidents. You know
    from [“Automating SEO Tasks with AI”](#ch06_automating_seo_tasks_with_ai_1748359259643251)
    that you can use code to analyze a web page, but we want assistance with generating
    content about the US president James Polk at scale. ChatGPT will let you use an
    example to shape the way it outputs content, so you don’t even need your own analysis
    code. ChatGPT will do it for you. As shown in [Figure 6-8](#ch06_figure_8_1748359259618179),
    the Biden White House archive provides information about Polk, so our bot will
    be instructed to take information from this page and generate content ideas.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ugai_0608.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-8\. Biden White House archive page on President Polk
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: A Teams bot can be coded in any language, but we will use Python in this example.
    In the earlier agents system example, we used Python to create a small application
    that pulled answers from ChatGPT. Instead of prompting ChatGPT to answer a question,
    our Teams bot will generate draft content for anyone in marketing (or another
    department) who sends it a message with specific prompts. The Python code can
    interface with the generative AI model—in our example, it’s ChatGPT—and send back
    content. The advantage is that you could have 20 marketing people generating draft
    content and ideas from one location, and they can collaboratively determine strategies
    for SEO. For example, suppose you have a site selling computer equipment. NVIDIA
    announces a new GPU, so you need to generate content to keep up with the trend
    and help drive traffic to your local site. Your marketing team can chat with a
    Teams bot to come up with ideas and draft pages to publish during the spike in
    interest for new NVIDIA GPUs.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll keep our example simple by focusing on content from the White House page
    on Polk. ChatGPT has plenty of content and information to generate good content
    on old topics, but you still need to review output. A human reviewer can identify
    errors or low-quality content, so always have a gatekeeper review output before
    it’s published to your site. The Teams interface lets you install your own bot
    from the Apps interface. Coding a full bot is beyond the scope of the book, but
    after you code a bot, you must upload the code from your Teams interface. You
    also need privileges to make bots available in Teams, so check with your Teams
    administrator if you do not have permission.
  prefs: []
  type: TYPE_NORMAL
- en: Our bot connects to the ChatGPT API, and we can ask it to write content with
    the White House web page as a reference, as shown in [Figure 6-9](#ch06_figure_9_1748359259618198).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ugai_0609.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-9\. Example request for a Teams bot named StudyAI
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: As you can see, we ask the Teams chatbot to write us content based on the White
    House URL. The chatbot takes a minute and responds with what’s shown in [Figure 6-10](#ch06_figure_10_1748359259618216).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ugai_0610.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-10\. Output from a ChatGPT-based chatbot
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You shouldn’t post this without human review. As you can see, you need to format
    the content and likely fact-check it, but using a factual URL will help eliminate
    errors. Once you check for errors, you can then have ChatGPT generate pages at
    scale while improving quality based on your chosen topic. You can tell ChatGPT
    to use your formatted original content from the first page generated as a foundation
    for other content. We don’t recommend you take this technique to the extreme of
    generating SEO programmatic content with generative AI. However, you could significantly
    speed up the process at scale while still inserting human review and editing into
    the process.
  prefs: []
  type: TYPE_NORMAL
- en: Going back to the NVIDIA example mentioned earlier, imagine that you have a
    product being built based on another trending topic or have additional ideas based
    on trending topics. You can have an agent constantly checking for trending topics
    in your industry and sending ideas and updates to marketing people. Marketing
    can then use custom bots and plug-ins to generate pages quickly without waiting
    for writers to write content. Plug-ins and custom tools can change your content-production
    time from weeks to hours to keep up with rapidly changing industry trends.
  prefs: []
  type: TYPE_NORMAL
- en: AI-Assisted Link Attraction and Outreach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: SEO is more than generating content on your site. Another area you need to address
    is marketing and outreach to increase your visibility, attract links, and generate
    interest in your brand from people reading third-party sites. Focus your efforts
    on marketing and promotions that develop visibility and recognition from the top
    sites that cover your market. Avoid traditional SEO link-building strategies that
    lead to lots of low-quality links—Google just ignores those anyway. Further, spamming
    the internet with large-scale outreach only causes problems and is a waste of
    your time and money.
  prefs: []
  type: TYPE_NORMAL
- en: As an example, suppose you have a new product you need to introduce. You can
    create press releases and reach out to editors on sites that cover your market.
    The idea is to generate discussion in the market about your product. An agent
    using generative AI can help.
  prefs: []
  type: TYPE_NORMAL
- en: The agent example in [“Building Your Own AI Tools and Plug-ins”](#ch06_building_your_own_ai_tools_and_plug_ins_1748359259643727)
    pulled content from the internet and analyzed it for opportunities. With a different
    agent, you can have it see what sites link to your competitors. Some of these
    may be sites that you can attract links from as well as other sites that are like
    those that link to your competitors. You can also use tools to find backlink gaps
    yourself. For example, Semrush lets you perform a keyword gap and backlink gap
    analysis, as shown in [Figure 6-11](#ch06_figure_11_1748359259618235).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ugai_0611.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-11\. Backlink gap analysis from Semrush
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: With a list of backlinks from your competitors, you can then identify your own
    backlink opportunities. So far, we haven’t used generative AI, but we could use
    it in several different ways. When you want to contact a site to establish a relationship,
    you can use it to draft email messages. However, don’t generate automated email
    messages and send them without human review. If you create messages that look
    like AI or have a poor message, you could be blacklisted by that particular publisher.
  prefs: []
  type: TYPE_NORMAL
- en: Third-party backlink analytic tools are best for finding competitor backlinks,
    but you can feed information from a third-party API (e.g., data from Semrush or
    Ahrefs) to generative AI. The logic you use depends on the way you program your
    agent, but you can use an agent to call the API and retrieve data that can be
    fed to generative AI. For example, the Semrush API can be used to find domain
    authority for a list of potential backlink locations. With this information, you
    can then ask generative AI to suggest content or build a list of topic ideas suitable
    for each site. AI can then identify the editor or person in charge of a target
    site that an email can be sent to for outreach. Note that you will still want
    to verify you have the right contacts by human review. This may seem like a minor
    advantage, but it can save a lot of time when you have significant outreach efforts
    driving your brand’s marketing.
  prefs: []
  type: TYPE_NORMAL
- en: Creating Video and Audio with AI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another valuable use of generative AI is image, video, and audio creation. Unfortunately,
    it can be somewhat obvious when audio and video have been generated by AI. For
    example, a video of a person speaking might show unnatural mouth movements. AI-generated
    images tend to be prone to oddities and AI-generated audio can sound robotic,
    for instance. If you choose to generate this type of content, know that it will
    need to be heavily edited.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of using generative AI to create video and audio, SEO practitioners
    can work with AI to improve current audio and video. AI can enhance color grading,
    program transitions between scenes, and add special effects. When your brand focuses
    on creating and publishing video rather than text content, this can save hours
    of editing time for every video.
  prefs: []
  type: TYPE_NORMAL
- en: Other advantages of using AI with video and audio content include writing meta
    descriptions, transcribing video content, and generating summaries of content
    for text-based searches. Generative AI is best used for text-based optimizations
    around video content to satisfy user engagement and quality search signals.
  prefs: []
  type: TYPE_NORMAL
- en: Using AI to Manage and Optimize Local SEO Listings
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Local SEO targets potential customers in a specific geolocation, so it has a
    different approach than global SEO. Instead of attracting global visitors, your
    goal is to show up in searches when users want a business or service near them.
    You could be a single brick-and-mortar store looking for better online visibility
    or a large-scale brand with hundreds or thousands of locations looking for better
    reach in each location. Generative AI can help create optimized meta descriptions
    for your local customers, check your listings to ensure consistent information
    like addresses and phone numbers, collect customer reviews, and identify competitors
    ranking for local keywords.
  prefs: []
  type: TYPE_NORMAL
- en: As with global SEO, relying too heavily on automated content without reviewing
    its output could do more damage than help. With that said, AI can reduce overhead
    and help with reputation management, tracking local listings, drafting replies
    to comments and reviews, updating addresses, and alerting business owners of potential
    dissatisfied customers. The biggest advantage is in AI’s predictive analysis,
    which helps businesses determine the best products to sell during busy seasons
    and to satisfy ever-changing trends. AI automation changes the game for SEO practitioners
    responsible for local businesses relying on search visibility in a small region.
  prefs: []
  type: TYPE_NORMAL
- en: A major part of good local SEO is keeping local listings updated with a business’s
    current address, location, and phone number. This information should be consistent
    across all platforms to send accurate signals to search engines. Search engines
    must know where the business is located to provide accurate results to users querying
    for services in their local area. Businesses move, telephone numbers and hours
    of operation change, and many other factors could also change. You might remember
    to update an address change on a handful of business listing sites but miss several
    others. When information is out of sync, that sends low-quality signals to search
    engines, which affects how high you rank for local search queries.
  prefs: []
  type: TYPE_NORMAL
- en: Using AI automation, local business SEO practitioners can identify sites with
    outdated information and either send an email to the individual location’s manager
    or owner or draft updates to the content with automated scripts. This automation
    is the first step, but in the process, AI can scrape a large number of sites,
    pull ratings and customer comments, and analyze them. The analysis can provide
    customer sentiment and identify issues. For example, customers might have posted
    several low ratings complaining about customer service or product quality. AI
    can identify this issue and send alerts to marketing, SEO practitioners, and PR
    management to help identify opportunities for improvement.
  prefs: []
  type: TYPE_NORMAL
- en: With enough data extracted from customer activity on a business website, AI
    can be used to personalize user experiences when they visit. Suppose you have
    a visitor from a specific city. Data extracted from visitors in this particular
    city says that most visitors search for a specific item during the summer. As
    an SEO practitioner, you can instruct developers to display this item more prominently
    to these users during summer and change the promoted item for the same customer
    in other seasons.
  prefs: []
  type: TYPE_NORMAL
- en: Voice and image optimization hasn’t quite happened yet, but it’s something to
    be aware of for the future. We’ll discuss voice and image search in [Chapter 8](ch08.html#ch08_the_future_of_generative_ai_and_seo_1748358221787429),
    but keep in mind that using simple voice or image searches will be an expanding
    area of interest for SEO. Users already can search using images, but that’s still
    primitive. Generative AI can be used to create images on the fly to get your business
    brand in image searches, offering a new opportunity for visitor traffic. Search
    using voice has been available for some time, but usage has been relatively low;
    this will likely also grow.
  prefs: []
  type: TYPE_NORMAL
- en: AI-Enhanced Reputation Management for SEO
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Word of mouth is important for every business, but it’s even more important
    for local businesses. Whether it’s a service you offer or a local product, potential
    customers will likely research reviews before committing to a purchase. Reviews
    and comments around the web can have a huge impact on revenue. However, a proactive
    approach to addressing customer issues can turn this around and ensure that the
    impact is positive.
  prefs: []
  type: TYPE_NORMAL
- en: In [“Automating SEO Tasks with AI”](#ch06_automating_seo_tasks_with_ai_1748359259643251),
    we talked about agents collecting data online and using it for gap analysis and
    assisting in content generation using keyword research automation. You can do
    the same with brand reputation. One of the most powerful uses for AI and machine
    learning is predictive analysis. In SEO, you can also gain insights into user
    sentiment.
  prefs: []
  type: TYPE_NORMAL
- en: You can project your brand reputation by monitoring the internet for brand mentions
    and finding opportunities from user sentiment, positive or negative. The negative
    reputation from poor reviews can be mitigated by responding to them. You could
    hire someone full time to respond to negative reviews, especially if the business
    is a large enterprise, but AI automation can also be your full-time employee and
    help draft responses to these customer complaints.
  prefs: []
  type: TYPE_NORMAL
- en: Many businesses respond to negative reviews by suggesting that the complainant
    call customer service. This response is better than nothing, but it’s not particularly
    satisfying, and it’s a missed opportunity for the brand. There are opportunities
    to do so much more with this interaction that helps satisfy not only the complainant
    but also others watching the conversation online. Brands should view these complaints
    as an opportunity to show publicly how much they support their customers and project
    that as part of their brand image.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of having employees scour the internet for brand comments, AI automation
    can be used to find new brand mentions and draft comments based on users’ feedback.
    Instead of using a canned reply that looks robotic and can actually harm brand
    reputation, AI can ingest a user’s comment and generate a draft customized response
    for each customer comment.
  prefs: []
  type: TYPE_NORMAL
- en: For example, in [Figure 6-12](#ch06_figure_12_1748359259618254), ChatGPT is
    given a request to find the latest review for Study.com. This review is positive,
    but it could be a negative review, too. This prompt can be fed to your RAG system
    to automatically find reviews at specified intervals (e.g., every day or once
    a week). You can then take the reviews and formulate a response.
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ugai_0612.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-12\. ChatGPT prompt to find the latest review for Study.com
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[Figure 6-13](#ch06_figure_13_1748359259618281) is a generative AI response
    to the Study.com review. This generated response is appreciative of the positive
    review, but it could also be a response to a negative review. This example is
    for a single review, but you can use your RAG agents to track and respond to numerous
    reviews found around the internet.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/ugai_0613.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6-13\. Generative AI response to an Instagram review for Study.com
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: You can also use generative AI for chatbot support. Visitors arriving at your
    site from search engines can be greeted by a chatbot to help them find a product.
    While this might not seem like an SEO issue, keeping visitors engaged improves
    dwell time on a site and reduces the chance of a visitor bouncing to find another
    site in search. This can affect SEO and directly improve sales, which is the ultimate
    goal for any SEO or marketing.
  prefs: []
  type: TYPE_NORMAL
- en: Collecting data to gain insights into user sentiment helps with numerous business
    changes to improve revenue. It can drive new products, suggest changes to products,
    or let you know when it’s time to deprecate a product or service. Marketers and
    SEO practitioners also can collect data on competitor insights to find out what
    customers like about a competitor and where the general public wants improvements.
    Your business can then determine if there are opportunities to create advantages
    for your own brand based on customer sentiment targeting a competitor.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating Generative AI with Other Marketing Channels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we talked about using generative AI to analyze customer
    sentiment on sites where users post reviews or make comments on products. The
    same can be done with social media. Some review sites even scrape social media
    accounts for product reviews, so your time could be well spent creating automation
    scripts to find social media posts that mention your brand and use generative
    AI to create comments. For example, use generative AI to respond to bad customer
    experience by suggesting the customer contact customer service. This type of activity
    is best for reputation management and can span social media and review sites.
    More broadly, you can use generative AI to discover posts that are relevant to
    your business and surface them as posts you may want to respond to. Engaging active
    dialogues on social media and enticing additional visitors to your site can be
    good for SEO.
  prefs: []
  type: TYPE_NORMAL
- en: 'PPC is a common traffic generator in marketing. PPC is expensive, but for some
    brands it’s essential to sales. There are a few steps to creating ads: do keyword
    research to find out what search queries to target, optimize your bids to determine
    the right price per click, create ad content that drives visitors to your products,
    schedule ads for optimal times when customers are online, and add tracking to
    see which ads bring in revenue and which ones don’t. As you can imagine, doing
    all these steps and monitoring ad revenue is a big job. Without optimization,
    PPC ads can provide a suboptimal return on investment and waste money. Generative
    AI can help reduce this overhead and make your PPC efforts more cost efficient
    and optimized for a target audience.'
  prefs: []
  type: TYPE_NORMAL
- en: With generative AI, SEO practitioners can create draft ad content based on insights
    from predictive analytics. The predictive analytics can come from your own agents
    ingesting data from around the web and from your sales and marketing departments.
    The predictive analytics results feed optimization of ads and determine when you
    publish ads and how much you should spend.
  prefs: []
  type: TYPE_NORMAL
- en: Generative AI also handles the draft content creation for human review, so you
    can reduce the costs of making changes to your ads based on the time of day, the
    season, results from capturing user activity on landing pages, or general sentiment
    from scraping reviews from the web. What you do with generative AI depends on
    your goals, but it can make ad spend and decision making much more precise.
  prefs: []
  type: TYPE_NORMAL
- en: The data you collect from landing pages can be fed to AI and machine learning
    to make predictions based on user activity. For example, suppose you have a landing
    page with three product options and the data suggests that more users prefer the
    blue item out of the three. You can then have generative AI create draft ads (for
    human review and approval) targeting people with this preference, increasing your
    ROI.
  prefs: []
  type: TYPE_NORMAL
- en: One more advantage of AI in PPC and marketing is optimization of landing pages.
    *Heat maps*—common locations where visitors interact—show popular areas where
    users click on your page. Heat maps are nothing new, but suppose that a heat map
    shows common areas in a specific menu of your site. You can take this information,
    feed it to AI and machine learning, and have generative AI suggest changes to
    your landing page and its content for a more optimized layout. Heat maps already
    give you ideas for landing-page layouts, but generative AI can make your marketing
    much more dynamic and quicker to adapt to changes in the way users interact with
    ads and landing pages.
  prefs: []
  type: TYPE_NORMAL
- en: Get Started with Generative AI Automation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: With so many options for applying generative AI, the first step is to determine
    what results you want to see. For example, you might wonder if generative AI can
    help with ad optimization. Your goal might be to increase the brand’s conversion
    rate. Using generative AI, you can suggest updates to landing pages and ads based
    on data collected from your current pages. You can also use data from sales and
    user activity to determine your best sellers and any seasonal or trend changes
    that might affect sales.
  prefs: []
  type: TYPE_NORMAL
- en: With these goals in mind, you can map out your agents and programming design.
    If you don’t have a technical background, you will likely need the help of an
    engineering team. While a single script might not be too complex, provisioning
    infrastructure, building multiple agents, and using available APIs can get quite
    complicated. Engineering teams can help alleviate this overhead and work with
    your brand to build complete RAG with a system of agents using AI.
  prefs: []
  type: TYPE_NORMAL
- en: As with any generative AI outputs, review of these outputs is critical to ensure
    that you don’t put out incorrect or nonsensical information. You will also need
    to tweak code or infrastructure to keep up with version changes or trends in your
    industry.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed advanced generative AI uses and how to automate
    many common SEO tasks. With productivity benefits come common pitfalls you must
    avoid. Automation has its benefits, but it can create serious ranking issues if
    you don’t properly implement and review its output. It’s important that you understand
    the risks associated with the technology so that you can build mitigation strategies
    into your designs.
  prefs: []
  type: TYPE_NORMAL
- en: As we will discuss in [Chapter 7](ch07.html#ch07_ai_risks_and_challenges_1748358220835353),
    after systems are in place you must monitor and continually adjust the output
    based on human reviews. Even when you implement these advanced techniques, you’ll
    still need continual human review. We’ll get into the possible risks in the next
    chapter.
  prefs: []
  type: TYPE_NORMAL
