<html><head></head><body>
  <div class="readable-text" id="p1"> 
   <h1 class=" readable-text-h1"><span class="chapter-title-numbering"><span class="num-string">9</span> </span> <span class="chapter-title-text">Autoencoders</span></h1> 
  </div> 
  <div class="introduction-summary"> 
   <h3 class="introduction-header">This chapter covers</h3> 
   <ul> 
    <li class="readable-text" id="p2">Introducing autoencoders</li> 
    <li class="readable-text" id="p3">Training of autoencoders</li> 
    <li class="readable-text" id="p4">Types of autoencoders</li> 
    <li class="readable-text" id="p5">Python code using TensorFlow and Keras </li> 
   </ul> 
  </div> 
  <div class="readable-text" id="p6"> 
   <blockquote>
    <div>
     Out of intense complexities, intense simplicities emerge. 
     <div class=" quote-cite">
       —Winston Churchill 
     </div>
    </div>
   </blockquote> 
  </div> 
  <div class="readable-text" id="p7"> 
   <p>In the preceding chapter, we explored the concepts of deep learning. In this chapter, we start with unsupervised deep learning. Autoencoders are the very first topic. We will first cover the basics of autoencoders, what are they, and how we train them. We then get into the different types of autoencoders followed by a Python code on the implementation. Welcome to the ninth chapter, and all the very best!</p> 
  </div> 
  <div class="readable-text" id="p8"> 
   <h2 class=" readable-text-h2"><span class="num-string">9.1</span> Technical toolkit</h2> 
  </div> 
  <div class="readable-text" id="p9"> 
   <p>We will continue to use the same version of Python and Jupyter Notebook as we have used so far. The codes and datasets used in this chapter have been checked in at the GitHub location. You need to install a couple of Python libraries in this chapter: <code>tensorflow</code> and <code>keras</code>. </p> 
  </div> 
  <div class="readable-text" id="p10"> 
   <h2 class=" readable-text-h2"><span class="num-string">9.2</span> Feature learning</h2> 
  </div> 
  <div class="readable-text" id="p11"> 
   <p>Predictive modeling is quite an interesting topic. Across various domains and business functions, predictive modeling is used for various purposes like predicting the sales for a business in the next year, the amount of rainfall expected, whether the incoming credit card transaction is fraud or not, whether the customer will make a purchase or not, and so on. The use cases are many, and all the aforementioned use cases fall under supervised learning algorithms. </p> 
  </div> 
  <div class="readable-text print-book-callout" id="p12"> 
   <p><span class="print-book-callout-head">NOTE </span> The datasets that we use have variables or attributes. They are also called characteristics or features.</p> 
  </div> 
  <div class="readable-text" id="p13"> 
   <p>While we wish to create these predictive models, we are also interested in understanding the variables that are useful for making the prediction. Let’s consider a case where a bank wants to predict if an incoming transaction is fraudulent or not. In such a scenario, the bank will wish to know which factors are significant to identify an incoming transaction as fraud. Factors that might be considered include the amount of the transaction, the time of the transaction, the origin/source of the transaction, etc. The variables that are important for making a prediction are called <em>significant variables</em>. </p> 
  </div> 
  <div class="readable-text intended-text" id="p14"> 
   <p>To create a machine learning–based predictive model, <em>feature engineering</em> is used. Feature engineering, otherwise known as feature extraction, is the process of extracting features from the raw data to improve the overall quality of the model and enhance the accuracy as compared to a model where only raw data is fed to the machine learning model. </p> 
  </div> 
  <div class="readable-text intended-text" id="p15"> 
   <p>Feature engineering can be done using domain understanding, various manual methods, and a few automated methods too. One such method is known as feature learning. Feature learning is the set of techniques that help a solution automatically discover the representations required for feature detection. With the help of feature learning, manual feature engineering is not required. The effect of feature learning is much more relevant for datasets where images, text, audio, and video are being used. </p> 
  </div> 
  <div class="readable-text intended-text" id="p16"> 
   <p>Feature learning can be both supervised and unsupervised. For supervised feature learning, neural networks are the best example. For unsupervised feature learning, we have examples like matrix factorization, clustering algorithms, and autoencoders. We have already covered clustering and matrix factorization. In this chapter, we start with an introduction to autoencoders.</p> 
  </div> 
  <div class="readable-text" id="p17"> 
   <h2 class=" readable-text-h2"><span class="num-string">9.3</span> Introducing autoencoders</h2> 
  </div> 
  <div class="readable-text" id="p18"> 
   <p>When we start with any data science problem, data plays the most significant role. A dataset that has a lot of noise is one of the biggest challenges in data science and machine learning. There are quite a few solutions available now, and autoencoders are one of them.</p> 
  </div> 
  <div class="readable-text intended-text" id="p19"> 
   <p>Simply put, an autoencoder is a type of artificial neural network, and it is used to learn the data encodings. Autoencoders are typically used for dimensionality reduction methods. They can also be used as generative models, which can create synthetic data that is like the old data. For example, if we do not have a good amount of data to train machine learning, we can use generated synthetic data to train the models. </p> 
  </div> 
  <div class="readable-text intended-text" id="p20"> 
   <p>Autoencoders are feed-forward neural networks, and they compress the input into a lower dimensional code and then try to reconstruct the output from this representation. The objective of an autoencoder is to learn the lower dimensional representation (also sometimes known as encoding) for a high-dimensional dataset. Recall from the previous chapters principal component analysis (PCA). Autoencoders can be thought of as a generalization for PCA. PCA is a linear method whereas autoencoders can learn nonlinear relationships as well. Hence, autoencoders are required for dimensionality reduction solutions wherein they capture the most significant attributes from the input data.</p> 
  </div> 
  <div class="readable-text" id="p21"> 
   <h2 class=" readable-text-h2"><span class="num-string">9.4</span> Components of autoencoders</h2> 
  </div> 
  <div class="readable-text" id="p22"> 
   <p>The architecture of an autoencoder is quite simple to understand. An autoencoder consists of three parts: an encoder, a bottleneck or a code, and a decoder, as shown in figure 9.1. In simple terms, an encoder compresses the input data, a bottleneck or code contains this compressed information, and the decoder decompresses the knowledge and hence reconstructs this data back to its original form. Once the decompression has been done and the data has been reconstructed to its encoded form, the input and output can be compared.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p23">  
   <img alt="figure" src="../Images/CH09_F01_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 9.1</span> Structure of an autoencoder with an encoder, a bottleneck, and a decoder</h5>
  </div> 
  <div class="readable-text" id="p24"> 
   <p>Let’s study these components in more detail:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p25"> <em>Encoder</em><em> </em>—The input data passes through the encoder. An encoder is nothing but a fully connected artificial neural network. It compresses the input data into an encoded representation, and in the process the output generated is reduced in size. An encoder compresses the input data into a compressed module known as a bottleneck.  </li> 
   <li class="readable-text" id="p26"> <em>Bottleneck</em><em> </em>—The bottleneck can be considered the brain of the encoder. It contains the compressed information representations, and it is the job of the bottleneck to allow only the most important information to pass through.  </li> 
   <li class="readable-text" id="p27"> <em>Decoder</em><em> </em>—The information received from the bottleneck is decompressed by a decoder. It re-creates the data back to its original or encoded form. Once the job of the decoder is done, the actual values are compared with the decompressed values created by the decoder. </li> 
  </ul> 
  <div class="readable-text" id="p28"> 
   <p>There are a few important points about autoencoders to consider:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p29"> There is a loss of information in autoencoders when the decompression is done as compared to the original inputs. So when the compressed data is decompressed, there is a loss as compared to the original data. </li> 
   <li class="readable-text" id="p30"> Autoencoders are specific to datasets. This means that an algorithm that is trained on images of flowers will not work on images of traffic signals and vice versa. This is because the features the autoencoder learned will be specific to flowers only. So we can say that autoencoders are only able to compress the data similar to the one used for training. </li> 
   <li class="readable-text" id="p31"> It is relatively easier to train specialized instances of algorithms to perform well on specific types of inputs. We just need representative training datasets to train the autoencoder. </li> 
  </ul> 
  <div class="readable-text" id="p32"> 
   <h2 class=" readable-text-h2"><span class="num-string">9.5</span> Training of autoencoders</h2> 
  </div> 
  <div class="readable-text" id="p33"> 
   <p>It is important to note that if there is no correlation between the variables in the data, then it is really difficult to compress and subsequently decompress the input data. For us to create a meaningful solution, there should be some level of relationship or correlation between the variables in the input data. To create an autoencoder, we require an encoding method, a decoding method, and a loss function to compare the actual versus decompressed values. </p> 
  </div> 
  <div class="readable-text intended-text" id="p34"> 
   <p>The process is as follows: </p> 
  </div> 
  <ol> 
   <li class="readable-text" id="p35"> The input data passes through the encoder module. </li> 
   <li class="readable-text" id="p36"> The encoder compresses the input of a model into a compact bottleneck. </li> 
   <li class="readable-text" id="p37"> The bottleneck restricts the flow of information and allows only important information to pass through; hence, a bottleneck is sometimes referred to as <em>knowledge-representation</em>.  </li> 
   <li class="readable-text" id="p38"> The decoder decompresses the information and re-creates the data back to its original or encoded form. This encoder-decoder architecture is quite efficient in getting the most significant attributes from the input data. </li> 
  </ol> 
  <div class="readable-text" id="p39"> 
   <p>The objective of the solution is to generate an output identical to the input. Generally, the decoder architecture is a mirror image of the coder architecture. This is not mandatory but is generally followed. We ensure that the dimensionality of the input and outputs are the same. </p> 
  </div> 
  <div class="readable-text print-book-callout" id="p40"> 
   <p><span class="print-book-callout-head">NOTE </span> If you do not know the meaning of hyperparameter, refer to the appendix.</p> 
  </div> 
  <div class="readable-text" id="p41"> 
   <p>We need to define four hyperparameters for training an autoencoder:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p42"> <em>Code size</em><em> </em>—This is perhaps the most significant hyperparameter. It represents the number of nodes in the middle layer. This decides the compression of the data and can also act as a regularization term. The less the value of code size, the more compressed the data. </li> 
   <li class="readable-text" id="p43"> <em>Parameter</em><em> </em>—This denotes the depth of the autoencoder. A model that has more depth is obviously more complex and will have a longer processing time. </li> 
   <li class="readable-text" id="p44"> <em>Number of nodes per layer</em><em> </em>—This is the weight used per layer. It generally decreases with every subsequent layer as the input becomes smaller across the layers. It increases back in the decoder. </li> 
   <li class="readable-text" id="p45"> <em>Loss function used</em><em> </em>—If the input values are in the [0,1] range, binary cross-entropy is preferred; otherwise, mean squared error is used. </li> 
  </ul> 
  <div class="readable-text" id="p46"> 
   <p>We have covered the hyperparameters used in training autoencoders. The training process is similar to backpropagation, which we have already covered. </p> 
  </div> 
  <div class="readable-text" id="p47"> 
   <h2 class=" readable-text-h2"><span class="num-string">9.6</span> Application of autoencoders</h2> 
  </div> 
  <div class="readable-text" id="p48"> 
   <p>Autoencoders are capable of solving a number of problems inherent to unsupervised learning. Major applications for autoencoders include</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p49"> <em>Dimensionality reduction</em><em> </em>—Sometimes autoencoders can learn more complex data projections than PCA and other techniques. </li> 
   <li class="readable-text" id="p50"> <em>Anomaly detection</em><em> </em>—The error or the reconstruction error (error between the actual data and the reconstructed data) can be used to detect the anomalies.  </li> 
   <li class="readable-text" id="p51"> <em>Data compression</em><em> </em>—It is difficult to beat the basic solutions like JPEG by training the algorithm. Moreover, since autoencoders are data specific, they can use only the types of datasets they have been trained upon. If we wish to enhance the capacity to include more data types and make it more general, then the amount of the training data required will be too high, and obviously, the time required will be high too.  </li> 
   <li class="readable-text" id="p52"> <em>Other applications</em><em> </em>—These include drug discovery, machine translation, image denoising, etc.  </li> 
  </ul> 
  <div class="readable-text" id="p53"> 
   <p>There are still not a lot of practical implementations of autoencoders in the real world. This is due to a multitude of reasons like the nonavailability of datasets, infrastructure, readiness of various systems, etc. </p> 
  </div> 
  <div class="readable-text" id="p54"> 
   <h2 class=" readable-text-h2"><span class="num-string">9.7</span> Types of autoencoders</h2> 
  </div> 
  <div class="readable-text" id="p55"> 
   <p>There are five main types of autoencoders. A brief description of the different types of encoders is given next. We have kept the section mathematically light and skipped the math behind the scenes as it is quite complex to understand. For curious readers, the papers listed in section 9.10 can explain the mathematics:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p56"> <em>Undercomplete autoencoders</em><em> </em>—An undercomplete autoencoder is the simplest form of an autoencoder. It simply takes an input dataset and then reconstructs the same dataset again from the compressed bottleneck region. By penalizing the neural network as per the reconstruction error, the model will learn the most significant attributes of the data. By learning the most important attributes, the model will be able to reconstruct the original data from the compressed state. As we know, there is a loss when the compressed data is reconstructed; this loss is called <em>reconstruction</em> loss.  </li> 
  </ul> 
  <div class="readable-text list-body-item" id="p57"> 
   <p>Undercomplete autoencoders are unsupervised in nature as they do not have any target label to train. Such types of autoencoders are used for dimensionality reduction. Recall in chapter 2 we discussed dimensionality reduction (PCA), and in chapter 6, we discussed the advanced dimensionality reduction algorithms (t-distributed stochastic neighbor embedding and multidimensional scaling). See figure 9.2.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p58">  
   <img alt="figure" src="../Images/CH09_F02_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 9.2</span> The performance starts to improve with more dimensions but decreases after some time. The curse of dimensionality is a real problem when it comes to creating sound data science solutions.</h5>
  </div> 
  <div class="readable-text list-body-item" id="p59"> 
   <p>Dimensionality reduction is possible using undercomplete autoencoders as the bottleneck is created, which is the compressed form of the input data. This compressed data can be decompressed back with the aid of the network. Recall in chapter 3 we explained that PCA provides a linear combination of the input variables. For more details and to refresh your memory on PCA, please refer to chapter 3. We know that PCA tries to get a low-dimensional hyperplane to describe the original dataset; undercomplete autoencoders can also learn nonlinear relationships. The difference is shown in figure 9.3.<span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p60">  
   <img alt="figure" src="../Images/CH09_F03_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 9.3</span> PCA is linear in nature while autoencoders are nonlinear. This is the core difference between the two algorithms.</h5>
  </div> 
  <div class="readable-text list-body-item" id="p61"> 
   <p>Interestingly, if all the nonlinear activation functions are removed from the undercomplete autoencoder and only linear layers are used, the autoencoder is equivalent to a PCA only. To make the autoencoder generalize and not memorize the training data, an undercomplete autoencoder is regulated and fine-tuned by the size of the bottleneck. It allows the solution to not memorize the training data and generalize very well. </p> 
  </div> 
  <div class="readable-text print-book-callout" id="p62"> 
   <p><span class="print-book-callout-head">NOTE </span> If a machine learning model works very well on the training data but does not work on the unseen test data, it is called overfitting.</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p63"> <em>Sparse autoencoders</em><em> </em>—Sparse autoencoders are similar to undercomplete autoencoders except they use a different methodology to tackle overfitting. Conceptually, a sparse autoencoder changes the number of nodes at each of the hidden layer and keeps it flexible. Since it is not possible to have a neural network capable of a flexible number of neurons, the loss function is customized for it. In the loss function, a term is introduced that captures the number of activated neurons. The penalty term is proportional to the number of activated neurons. The higher the number of activated neurons, the higher the penalty. This penalty is called the <em>sparsity function</em>. Using the penalty, it is possible to reduce the number of activated neurons; hence the penalty is lower, and the network is able to tackle the problem of overfitting. </li> 
   <li class="readable-text" id="p64"> <em>Contractive autoencoders</em><em> </em>—Contractive autoencoders work on a similar concept as other autoencoders. They consider that the inputs that are quite similar should be encoded the same. Hence, they should have the same latent space representation. It means that there should not be much difference between the input data and the latent space.  </li> 
   <li class="readable-text" id="p65"> <em>Denoizing autoencoders</em><em> </em><em>—</em>Denoizing means removing the noise, and that is the precise task of denoizing autoencoders. They do not take an image as an input; instead they take a noisy version of an image as an input as shown in figure 9.4.<span class="aframe-location"/>  </li> 
  </ul> 
  <div class="browsable-container figure-container" id="p66">  
   <img alt="figure" src="../Images/CH09_F04_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 9.4</span> An original image, noisy output, and the outputs from the autoencoder</h5>
  </div> 
  <div class="readable-text list-body-item" id="p67"> 
   <p>The process of denoizing the autoencoder is depicted in figure 9.5. The original image is changed by adding noise to it. This noisy image is fed to the encoder-decoder architecture and the output received is compared to the original image. The autoencoder learns the representation of the image, which is used to remove the noise; this is achieved by mapping the input image into a lower dimensional manifold. <span class="aframe-location"/></p> 
  </div> 
  <div class="browsable-container figure-container" id="p68">  
   <img alt="figure" src="../Images/CH09_F05_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 9.5</span> The process of denoizing in an autoencoder. It starts with the original image; noise is added, which results in a noisy image, and then it is fed to the autoencoder. </h5>
  </div> 
  <div class="readable-text list-body-item" id="p69"> 
   <p>We can use denoizing autoencoders for nonlinear dimensionality reduction.</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p70"> <em>Variational autoencoders</em><em> </em>—A standard autoencoder model represents the input in a compressed form using the bottleneck. A variation is probabilistic generative models (usually Gaussian) over latent variables, which only need neural networks as a part of their overall structure. They are trained using expectation-maximization meta-algorithms. The mathematical details are beyond the scope of this book.  </li> 
  </ul> 
  <div class="readable-text" id="p71"> 
   <h2 class=" readable-text-h2"><span class="num-string">9.8</span> Python implementation of autoencoders</h2> 
  </div> 
  <div class="readable-text" id="p72"> 
   <p>Let’s create two versions of an autoencoder. The code has been taken from the official source at the Keras website (<a href="https://blog.keras.io/building-autoencoders-in-keras.html">https://blog.keras.io/building-autoencoders-in-keras.html</a>) and has been modified for our usage. The steps are as follows:</p> 
  </div> 
  <ol> 
   <li class="readable-text" id="p73"> Import the necessary libraries: </li> 
  </ol> 
  <div class="browsable-container listing-container" id="p74"> 
   <div class="code-area-container"> 
    <pre class="code-area">import keras
from keras import layers</pre>  
   </div> 
  </div> 
  <ol class=" faux-ol-li" style="list-style: none;"> 
   <li class="readable-text faux-li has-faux-ol-li-counter" id="p75"><span class="faux-ol-li-counter">2. </span> Create our network architecture: </li> 
  </ol> 
  <div class="browsable-container listing-container" id="p76"> 
   <div class="code-area-container"> 
    <pre class="code-area"># This is the size of our encoded representations
encoding_dim = 32  # 32 floats -&gt; compression of factor 24.5, assuming  
the input is 784 floats

# This is our input image
input_img = keras.Input(shape=(784,))
# "encoded" is the encoded representation of the input
encoded = layers.Dense(encoding_dim, activation='relu')(input_img)
# "decoded" is the lossy reconstruction of the input
decoded = layers.Dense(784, activation='sigmoid')(encoded)

# This model maps an input to its reconstruction
autoencoder = keras.Model(input_img, decoded)</pre>  
   </div> 
  </div> 
  <ol class=" faux-ol-li" style="list-style: none;"> 
   <li class="readable-text faux-li has-faux-ol-li-counter" id="p77"><span class="faux-ol-li-counter">3. </span> Add more details to the model: </li> 
  </ol> 
  <div class="browsable-container listing-container" id="p78"> 
   <div class="code-area-container"> 
    <pre class="code-area"># This model maps an input to its encoded representation
encoder = keras.Model(input_img, encoded) 

# This is our encoded (32-dimensional) input
encoded_input = keras.Input(shape=(encoding_dim,))
# Retrieve the last layer of the autoencoder model
decoder_layer = autoencoder.layers[-1]
# Create the decoder model
decoder = keras.Model(encoded_input, decoder_layer(encoded_input))

autoencoder.compile(optimizer='adam', loss='binary_crossentropy')</pre>  
   </div> 
  </div> 
  <ol class=" faux-ol-li" style="list-style: none;"> 
   <li class="readable-text faux-li has-faux-ol-li-counter" id="p79"><span class="faux-ol-li-counter">4. </span> Load the datasets: </li> 
  </ol> 
  <div class="browsable-container listing-container" id="p80"> 
   <div class="code-area-container"> 
    <pre class="code-area">(x_train, _), (x_test, _) = mnist.load_data()</pre>  
   </div> 
  </div> 
  <ol class=" faux-ol-li" style="list-style: none;"> 
   <li class="readable-text faux-li has-faux-ol-li-counter" id="p81"><span class="faux-ol-li-counter">5. </span> Create the train and test the datasets: </li> 
  </ol> 
  <div class="browsable-container listing-container" id="p82"> 
   <div class="code-area-container"> 
    <pre class="code-area">x_train = x_train.astype('float32') / 255.
x_test = x_test.astype('float32') / 255.
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print(x_train.shape)
print(x_test.shape)</pre>  
   </div> 
  </div> 
  <ol class=" faux-ol-li" style="list-style: none;"> 
   <li class="readable-text faux-li has-faux-ol-li-counter" id="p83"><span class="faux-ol-li-counter">6. </span> Fit the model (see figure 9.6): </li> 
  </ol> 
  <div class="browsable-container listing-container" id="p84"> 
   <div class="code-area-container"> 
    <pre class="code-area">autoencoder.fit(x_train, x_train,
                epochs=5,
                batch_size=128,
                shuffle=True,
                validation_data=(x_test, x_test))<span class="aframe-location"/></pre>  
   </div> 
  </div> 
  <div class="browsable-container figure-container" id="p85">  
   <img alt="figure" src="../Images/CH09_F06_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 9.6</span> Fitting the model</h5>
  </div> 
  <ol class=" faux-ol-li" style="list-style: none;"> 
   <li class="readable-text faux-li has-faux-ol-li-counter" id="p86"><span class="faux-ol-li-counter">7. </span> Test it on the test dataset: </li> 
  </ol> 
  <div class="browsable-container listing-container" id="p87"> 
   <div class="code-area-container"> 
    <pre class="code-area"># Encode and decode some digits
# Note that we take them from the *test* set
encoded_imgs = encoder.predict(x_test)
decoded_imgs = decoder.predict(encoded_imgs)</pre>  
   </div> 
  </div> 
  <ol class=" faux-ol-li" style="list-style: none;"> 
   <li class="readable-text faux-li has-faux-ol-li-counter" id="p88"><span class="faux-ol-li-counter">8. </span> Plot the results. You can see the original image and final output (see figure 9.7): </li> 
  </ol> 
  <div class="browsable-container listing-container" id="p89"> 
   <div class="code-area-container"> 
    <pre class="code-area"># Use Matplotlib (don't ask)
import matplotlib.pyplot as plt

n = 10  # How many digits we will display
plt.figure(figsize=(20, 4))
for i in range(n):
    # Display original
    ax = plt.subplot(2, n, i + 1)
    plt.imshow(x_test[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # Display reconstruction
    ax = plt.subplot(2, n, i + 1 + n)
    plt.imshow(decoded_imgs[i].reshape(28, 28))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()<span class="aframe-location"/></pre>  
   </div> 
  </div> 
  <div class="browsable-container figure-container" id="p90">  
   <img alt="figure" src="../Images/CH09_F07_Verdhan.png"/> 
   <h5 class=" figure-container-h5"><span class="num-string">Figure 9.7</span> The original image (bottom) and the final outcome (top)</h5>
  </div> 
  <div class="readable-text" id="p91"> 
   <h2 class=" readable-text-h2"><span class="num-string">9.9</span> Concluding thoughts</h2> 
  </div> 
  <div class="readable-text" id="p92"> 
   <p>Deep learning is a powerful tool. With a sound business problem and a quality dataset, we can create a lot of innovative solutions. Autoencoders are only one type of such solutions. </p> 
  </div> 
  <div class="readable-text intended-text" id="p93"> 
   <p>In this chapter, we started with feature engineering, which allows us to extract the most significant features from a dataset. Then we moved to autoencoders. Autoencoders are a type of neural network only used to learn efficient coding of unlabeled datasets. Autoencoders can be applied to many business problems like facial recognition, anomaly detection, image recognition, drug discovery, machine translation, and so on. </p> 
  </div> 
  <div class="readable-text" id="p94"> 
   <h2 class=" readable-text-h2"><span class="num-string">9.10</span> Practical next steps and suggested readings</h2> 
  </div> 
  <div class="readable-text" id="p95"> 
   <p>The following provides suggestions for what to do next and offers some helpful reading:</p> 
  </div> 
  <ul> 
   <li class="readable-text" id="p96"> Read the blog at <a href="https://mng.bz/qxaw">https://mng.bz/qxaw</a>. </li> 
   <li class="readable-text buletless-item" id="p97"> Study the following papers: 
    <ul> 
     <li> Hinton, G. E., Krizhevsky, A., and Wang, S. D. (2011). Transforming Auto-encoders. <a href="https://mng.bz/7p99">https://mng.bz/7p99</a> </li> 
     <li> Bank, D., Koenigstein, N., and Giryes, R. (2020). Autoencoders. <a href="https://arxiv.org/abs/2003.05991">https://arxiv.org/abs/2003.05991</a> </li> 
     <li> Michelucci, U. (2020). An Introduction to Autoencoders. <a href="https://arxiv.org/abs/2201.03898">https://arxiv.org/abs/2201.03898</a> </li> 
    </ul></li> 
   <li class="readable-text" id="p98"> See the good code and dataset available on the TensorFlow official page. <a href="https://mng.bz/mGQr">https://mng.bz/mGQr</a>. </li> 
  </ul> 
  <div class="readable-text" id="p99"> 
   <h2 class=" readable-text-h2">Summary</h2> 
  </div> 
  <ul> 
   <li class="readable-text" id="p100"> Predictive modeling is used in various domains to make future predictions using supervised learning algorithms. </li> 
   <li class="readable-text" id="p101"> Key aspects of predictive modeling involve identifying significant variables or features for accurate predictions. </li> 
   <li class="readable-text" id="p102"> Feature engineering enhances model accuracy by extracting useful features from raw data. </li> 
   <li class="readable-text" id="p103"> Feature learning automates feature detection, suitable for datasets like images, text, and audio. </li> 
   <li class="readable-text" id="p104"> Autoencoders are a type of neural network used for data encoding, dimensionality reduction, and generating synthetic data. </li> 
   <li class="readable-text" id="p105"> The architecture of autoencoders includes encoder, bottleneck, and decoder components for data compression and reconstruction. </li> 
   <li class="readable-text" id="p106"> Autoencoders face information loss, are dataset-specific, and are suitable for precise applications. </li> 
   <li class="readable-text" id="p107"> Training autoencoders requires encoding, decoding, and defining hyperparameters such as code size and loss function. </li> 
   <li class="readable-text" id="p108"> Major applications include dimensionality reduction, anomaly detection, and data compression, among others. </li> 
   <li class="readable-text" id="p109"> Types of autoencoders include undercomplete, sparse, contractive, denoizing, and variational. </li> 
   <li class="readable-text" id="p110"> Sparse and contractive autoencoders address overfitting using different methodologies. </li> 
   <li class="readable-text" id="p111"> A Python implementation of basic autoencoder architecture involves the Keras library for encoding and decoding data. </li> 
  </ul>
 </body></html>