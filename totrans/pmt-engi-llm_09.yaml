- en: Chapter 7\. Taming the Model
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章\. 摧毁模型
- en: In the previous chapter, you managed to distill all your context into a single,
    coherent prompt. Now, it’s time for the LLM to do its thing and for you to make
    sure that it all goes smoothly.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，您设法将所有上下文提炼成一个单一、连贯的提示。现在，轮到LLM发挥作用，您需要确保一切顺利进行。
- en: In this chapter, we’re going to start by talking about completion formats and
    making sure your completions stop when they’re supposed to, as well as how to
    interpret them using so-called *logprob tricks*.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将首先讨论完成格式，并确保您的完成内容在应该停止时停止，以及如何使用所谓的*对数概率技巧*来解释它们。
- en: 'Then, we’re going to take a step back so you can ask yourself which model you’re
    going to choose to invoke: a professional commercial service, an open source alternative,
    or even your own bespoke fine-tuned model. Time to get into it.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们将退后一步，让您可以问自己您将选择哪种模型来调用：专业的商业服务、开源替代方案，甚至是您自己的定制微调模型。是时候深入研究了。
- en: Anatomy of the Ideal Completion
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理想完成内容的解剖
- en: In this section, we’ll examine how completions appear, whether they’re classic
    completions or chat responses. More importantly, we’ll discuss how you want them
    to look to ensure clear and effective solutions, all while avoiding issues like
    unnecessary delays or confusing details. As we did in [Chapter 6](ch06.html#ch06a_assembling_the_prompt_1728442733857948)
    with prompts, we’ll break down the components of an LLM completion and go through
    them one by one (see [Figure 7-1](#ch07_figure_1_1728407187627920)).
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨完成内容的呈现方式，无论是经典完成还是聊天回复。更重要的是，我们将讨论您希望它们如何呈现，以确保清晰有效的解决方案，同时避免诸如不必要的延迟或令人困惑的细节等问题。正如我们在[第6章](ch06.html#ch06a_assembling_the_prompt_1728442733857948)中处理提示时所做的，我们将分解LLM完成内容的组成部分，并逐一进行探讨（见图7-1）。
- en: '![](assets/pefl_0701.png)'
  id: totrans-6
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/pefl_0701.png)'
- en: Figure 7-1\. An LLM completion
  id: totrans-7
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-1\. LLM完成内容
- en: The Preamble
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 序言
- en: 'In the context of completions, the *preamble* is the initial part of the generated
    text that sets the stage for the main content. Sometimes, this is helpful, and
    sometimes, it leads to completions that start with uninteresting or useless detail
    before they produce a solution to the problem you posed. This is often annoying,
    and it’s costly too: generating tokens costs time (latency) and compute (resources
    and money). So, producing text that you’re not going to use is wasteful, but sometimes,
    it’s desirable. We know, it’s confusing, but stay with us here.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在完成内容的背景下，*序言*是生成文本的初始部分，为主要内容设定场景。有时这很有帮助，有时则会导致在提供您提出的问题的解决方案之前，以不有趣或无用的细节开始的完成内容。这通常很令人烦恼，而且成本也很高：生成令牌需要时间（延迟）和计算（资源和金钱）。因此，生成您不会使用的文本是浪费的，但有时这是可取的。我们知道，这很令人困惑，但请继续跟随我们。
- en: 'Whether it really *is* wasteful or whether you can avoid it depends on the
    exact type of preamble. There are three different types of preambles, and we’ll
    explore what each of them:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 是否真的*是*浪费的，或者您是否可以避免它，这取决于序言的确切类型。有三种不同的序言类型，我们将探讨每种类型：
- en: Structural boilerplate
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 结构性模板
- en: This is the text between the end of a prompt and the start of a completion.
    When using a completion model, you might be able to eliminate this preamble type,
    but it’s more efficient to include deterministic boilerplate in the prompt rather
    than the completion, thus ensuring that the model adheres to the desired format
    and making the process faster and cheaper. Structural boilerplate makes for a
    good transition from the prompt to the completion.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这是提示结束和完成开始之间的文本。当使用完成模型时，您可能能够消除这种序言类型，但将确定性模板包含在提示中而不是完成内容中更为高效，从而确保模型遵循所需的格式，并使过程更快、更便宜。结构性模板使得从提示到完成的过渡更加顺畅。
- en: Reasoning
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 推理
- en: Toward the end of 2023, ChatGPT started mirroring a slightly interpreted version
    of questions to clarify understanding and highlight potential misunderstandings.
    This approach helps the model make better inferences by focusing on key aspects
    of the prompt and ensures more accurate responses. Additionally, chain-of-thought
    prompting, as discussed in [Chapter 4](ch04.html#ch04_designing_llm_applications_1728407230643376),
    helps the model break down problems into manageable pieces, with the detailed
    process often being part of the preamble rather than the main answer. If you’re
    doing chain-of-thought prompting, having a long preamble is a virtue, not a vice,
    even if it’s significantly longer than the actual answer (see the example in [Figure 7-2](#ch07_figure_2_1728407187627952)).
    Also note that in the figure, the [answer arrived at after a long preamble](https://oreil.ly/b6T45)
    is correct, while the [answer arrived at after a short preamble](https://oreil.ly/X60zf)
    is not. Many of the advanced prompting techniques discussed in [Chapter 8](ch08.html#ch08_01_conversational_agency_1728429579285372)
    will center on making good use of reasoning preambles as well.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 到 2023 年底，ChatGPT 开始模仿对问题进行轻微解释的版本，以阐明理解和突出潜在误解。这种方法通过关注提示的关键方面，有助于模型做出更好的推断，并确保更准确的回答。此外，正如在第
    4 章中讨论的[思维链提示](ch04.html#ch04_designing_llm_applications_1728407230643376)，有助于模型将问题分解为可管理的部分，详细过程通常作为序言的一部分而不是主要答案。如果你在进行思维链提示，一个长的序言是一种美德，而不是缺点，即使它比实际答案长得多（参见[图
    7-2](#ch07_figure_2_1728407187627952)中的示例）。此外，请注意，在图中，[在长序言之后得出的答案](https://oreil.ly/b6T45)是正确的，而[在简短序言之后得出的答案](https://oreil.ly/X60zf)是不正确的。第
    8 章中讨论的许多高级提示技术都将集中在充分利用推理序言上。
- en: '![](assets/pefl_0702.png)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/pefl_0702.png)'
- en: Figure 7-2\. Encouraging long preambles to get a correct answer
  id: totrans-16
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-2\. 鼓励长序言以获得正确答案
- en: Fluff
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 冗余
- en: RLHF-trained models often produce verbose and polite responses, which can be
    problematic for programmatic use where succinct outputs are needed. While models
    with RLHF are prone to including unnecessary fluff, even those without it can
    occasionally produce it. To manage this, you can use techniques like providing
    instructions with few-shot examples or reformatting prompts to separate the main
    answer from additional comments. This can be expensive, though. For structured
    documents, models generally maintain the format, but for free-form contexts, asking
    for the main answer first followed by any extra information helps in parsing and
    reducing the impact of fluff.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: RLHF 训练的模型通常会产生冗长且礼貌的回答，这在需要简洁输出的程序性使用中可能是个问题。虽然具有 RLHF 的模型倾向于包含不必要的冗余内容，但即使没有它，偶尔也可能产生。为了管理这个问题，你可以使用诸如提供带有少量示例的指令或重新格式化提示以将主要答案与附加评论分开等技术。但这可能很昂贵。对于结构化文档，模型通常保持格式，但对于自由形式的上下文，先请求主要答案，然后是任何额外信息，有助于解析并减少冗余的影响。
- en: Which portions of fluff to reserve depends on what kind of fluff the model you
    chose tends to supply for the kind of questions your application asks. Typical
    candidates are comments, disclaimers, background, and explanation (see [Figure 7-4](#ch07_figure_4_1728407187627986)).
    Note that the point of this figure is not to demonstrate a correct answer, but
    to demonstrate the format. Also note that while this trick is good at banishing
    most fluff behind the main answer, it will not always get rid of a short introduction
    before the first numbered list item (see [Figure 7-3](#ch07_figure_3_1728407187627971)).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 保留哪些冗余内容取决于你选择的模型为你的应用提出的问题类型倾向于提供哪种类型的内容。典型的候选内容包括注释、免责声明、背景和解释（参见[图 7-4](#ch07_figure_4_1728407187627986)）。请注意，此图的目的不是展示正确答案，而是展示格式。此外，请注意，虽然这个技巧擅长将大部分冗余内容移至主要答案之后，但它并不总是能去除第一个编号列表项之前的简短引言（参见[图
    7-3](#ch07_figure_3_1728407187627971)）。
- en: '![](assets/pefl_0703.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/pefl_0703.png)'
- en: Figure 7-3\. [A fluff preamble that ChatGPT included against explicit instructions](https://oreil.ly/WjlZg)
    in its second answer
  id: totrans-21
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-3\. [ChatGPT 在其第二个答案中违反明确指示](https://oreil.ly/WjlZg)包含的冗余序言
- en: '![](assets/pefl_0704.png)'
  id: totrans-22
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/pefl_0704.png)'
- en: Figure 7-4\. [Banishing all of ChatGPT’s fluff into a subsequent point](https://oreil.ly/K1l98),
    so it can be parsed out easily
  id: totrans-23
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-4\. [将 ChatGPT 的所有冗余内容移至后续点](https://oreil.ly/K1l98)，以便易于解析
- en: Recognizable Start and End
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可识别的起始和结束
- en: If you want to pick out your main answer from the LLM’s response, you must be
    able to recognize the beginning and the end. Many document structures make this
    relatively easy (see [Table 7-1](#ch07_table_1_1728407187636012)).
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想从LLM的回复中挑选出你的主要答案，你必须能够识别其开始和结束。许多文档结构使这相对容易（见[表7-1](#ch07_table_1_1728407187636012)）。
- en: Table 7-1\. Recognizable start and end examples and whether the test for the
    recognizable end can be written as a test for the presence of a substring
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 表7-1\. 可识别的开始和结束示例以及测试可识别的结束是否可以写成测试子字符串的存在
- en: '| Document structure | Start | End | Test for end is test for substring |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| 文档结构 | 开始 | 结束 | 测试结束是测试子字符串的存在 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| A Markdown document | The expected section header | Any other section header
    | Yes |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| Markdown文档 | 预期的部分标题 | 任何其他部分标题 | 是 |'
- en: '| A YAML document | The expected keyword after a newline | A line with lower
    indentation | No |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| YAML文档 | 换行后预期的关键字 | 较低缩进的行 | 否 |'
- en: '| A JSON document | The expected keyword in quotation marks, then a colon and
    a quotation mark | Any unescaped quotation mark | No |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| JSON文档 | 引号中的预期关键字，然后是冒号和引号 | 任何未转义的引号 | 否 |'
- en: '| A triple-ticked ([PRE0]` [PRE1]` | [PRE2]\n```` | Yes |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 三重引号([PRE0]` [PRE1]`) | [PRE2]\n```` | 是 |'
- en: '| The first item of a numbered list (see comments about fluff) | `1.` | `2.`
    | Yes |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 编号列表的第一个项目（见关于冗余的注释） | `1.` | `2.` | 是 |'
- en: '| A function/class in source code (a bracketed language like Java) | `{` |
    The matching closing bracket | No |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 源代码中的函数/类（如Java这样的括号语言） | `{` | 匹配的闭合括号 | 否 |'
- en: '| A function/class in source code (an indent language like Python) | The expected
    function/class header | A lower indentation level (except for the occasional terrible
    string literal) | No |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 源代码中的函数/类（如Python这样的缩进语言） | 预期的函数/类标题 | 较低的缩进级别（除了偶尔的糟糕的字符串字面量） | 否 |'
- en: As [Table 7-1](#ch07_table_1_1728407187636012) shows, figuring out the start
    and end of a section can either be straightforward or a bit tricky. With a well-crafted
    prompt, you can sometimes improve on the recognition methods shown in the table.
    For example, in a YAML document, if you know what the next keyword will be, you
    can look for a lower indentation level followed by that keyword, rather than just
    any lower indentation. This means you can determine the end by checking for specific
    substrings, as described in the fourth column of [Table 7-1](#ch07_table_1_1728407187636012).
    Next, we talk about identifying the end of the main answer.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如[表7-1](#ch07_table_1_1728407187636012)所示，确定一个部分的开始和结束可能既简单也可能有点棘手。通过一个精心设计的提示，你有时可以改进表中显示的识别方法。例如，在一个YAML文档中，如果你知道下一个关键字将是什么，你可以寻找一个较低的缩进级别后跟该关键字，而不是任何较低的缩进。这意味着你可以通过检查特定的子字符串来确定结束，如[表7-1](#ch07_table_1_1728407187636012)的第四列所述。接下来，我们讨论如何识别主要答案的结束。
- en: Postscript
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 后记
- en: 'The reason why your start should be recognizable is clear: it helps you when
    parsing the answer to filter out the irrelevant introduction. As with the end,
    you want to be able to filter out the fluffy postscript that’s not relevant to
    your question.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你的开始为什么应该可识别的原因很清楚：它在解析答案时帮助你过滤掉不相关的介绍。与结束一样，你希望能够过滤掉与你的问题无关的冗余后记。
- en: 'But there’s a second, at least equally important consideration that applies
    here. You want to be able to control the length of the LLM’s answer. Every generated
    token costs you time and compute, making your application slower and more expensive.
    So ideally, you want to stop generating tokens whenever you hit your recognizable
    end. If you’re self-hosting an OS model, you have complete freedom to do that
    whenever you want. But it’s much more common to call an existing model as a service.
    Here are the two main ways to do it:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 但这里还有一个至少同样重要的考虑因素。你希望能够控制LLM答案的长度。每个生成的标记都会消耗你的时间和计算资源，使你的应用程序运行得更慢，成本更高。因此，理想情况下，你希望在遇到可识别的结束标记时停止生成标记。如果你自己托管OS模型，你可以在任何时候完全自由地这样做。但调用现有模型作为服务的情况更为常见。这里有两种主要的方法：
- en: Stop sequences
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 停止序列
- en: Many models, in particular those following the OpenAI API, allow you to provide
    a *stop argument* that’s a list of sequences you know mark the end of the relevant
    solution. When it reaches one of those stop sequences, the model generation will
    stop (on the server side, if it’s on a server) and end its answer. You won’t incur
    any further cost in waiting time, compute, or money.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 许多模型，特别是遵循 OpenAI API 的模型，允许你提供一个 *停止参数*，这是一个已知标记相关解决方案结束的序列列表。当模型达到这些停止序列之一时，模型生成将停止（如果是在服务器上，则是在服务器端）并结束其答案。你不会因为等待时间、计算或金钱而承担任何额外的费用。
- en: Streaming
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 流模式
- en: Several models allow a *streaming mode* where either individual tokens or small
    batches of tokens are sent one at a time, instead of waiting until the model generation
    is complete. Models following the OpenAI API activate streaming by setting the
    “stream” parameter to “true.” Recognizing an end while streaming means you don’t
    have to wait for the generation of additional, uninteresting tokens. If you cancel
    the generation (and the model supports that), you can even save yourself some
    compute and money—but not as much as you’d have saved with stop sequences, because
    network communication delays mean your cancellation signal won’t get through immediately.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 几个模型允许 *流模式*，其中可以逐个发送单个标记或小批量的标记，而不是等待模型生成完成。遵循 OpenAI API 的模型通过将“stream”参数设置为“true”来激活流模式。在流过程中识别到结束意味着你不必等待生成额外的、无趣的标记。如果你取消生成（并且模型支持这一点），你甚至可以节省一些计算和金钱——但节省的金额不如使用停止序列那么多，因为网络通信延迟意味着你的取消信号不会立即传达到。
- en: Tip
  id: totrans-44
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Very often, stop sequences will begin with a newline character. For example,
    in markdown documents, `\n#` is a typical stop sequence. If you don’t include
    the newline, then you may erroneously stop on a comment in code or the beginning
    of a phone number.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 非常常见的是，停止序列将以换行符开始。例如，在 Markdown 文档中，`\n#` 是一个典型的停止序列。如果你不包括换行符，那么你可能会错误地在代码中的注释或电话号码的开头停止。
- en: Typically, more models admit stop sequences than allow streaming and cancellation,
    and stop sequences are a tiny bit more effective. But since stop sequences are
    limited to a list of specific strings, sometimes canceling streams is the only
    viable option.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，允许停止序列的模型比允许流和取消的模型更多，并且停止序列稍微有效一些。但鉴于停止序列仅限于特定字符串的列表，有时取消流是唯一可行的选项。
- en: Tip
  id: totrans-47
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: If certain sequences occasionally signal the end of the completion, you can
    enhance your “streaming and cancellation” method by adding them as stop sequences.
    For example, when generating a Python class, `\nclass`, `\ndef`, and `\nif` are
    such sequences. They are not the only way the code can continue after the class,
    but they are some of the most common ways. You might think that `\ndef` is incorrect
    because the class you’re generating will have several methods defined that start
    with `def`, but notice that they will be indented and will actually start with
    `\n\tdef`. Therefore, they will not cause the model to halt generation.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果某些序列偶尔会表示完成的结束，你可以通过将它们添加为停止序列来增强你的“流和取消”方法。例如，在生成 Python 类时，`\nclass`、`\ndef`
    和 `\nif` 是这样的序列。它们不是代码在类之后继续的唯一方式，但它们是一些最常见的方式。你可能认为 `\ndef` 是不正确的，因为你要生成的类将会有几个以
    `def` 开头的方法定义，但请注意，它们将缩进，实际上将以 `\n\tdef` 开始。因此，它们不会导致模型停止生成。
- en: 'Beyond the Text: Logprobs'
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超越文本：对数概率
- en: Throughout this book, we’ve been presenting LLMs as “text in” (prompt) then
    “text out” (completion). But it’s worth being aware of a couple of tricks that
    break that paradigm by analyzing not only the text output but the numerical values
    that describe what the model thinks about the text.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这本书的整个过程中，我们一直将 LLMs 作为“文本输入”（提示）然后是“文本输出”（完成）。但值得注意的几个技巧打破了这种范式，它们不仅分析了文本输出，还分析了描述模型对文本看法的数值。
- en: In [Chapter 2](ch02.html#ch02_understanding_llms_1728407258904677), we discussed
    how the LLM calculates not just individual tokens but the entire probability distribution
    for the next token based on previous input. These probabilities are returned as
    *logprobs* (the logarithm of the probabilities). A logprob is negative; the more
    negative its value, the less probable the token is considered by the model. A
    logprob of 0 means the model is certain about the token. To convert a logprob
    to a standard probability, you use the `exp` function. For instance, if the logprobs
    for “Yes” and “No” are ‒0.405 and ‒1.099, respectively, then the model is about
    66% sure it will be “Yes” and 33% sure it will be “No.”
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第二章](ch02.html#ch02_understanding_llms_1728407258904677)中，我们讨论了LLM如何计算不仅仅是单个标记，而是基于先前输入计算下一个标记的整个概率分布。这些概率以*logprobs*（概率的对数）的形式返回。logprob是负数；其值越负，模型认为该标记的可能性就越小。logprob为0表示模型对标记有绝对的确定性。要将logprob转换为标准概率，您可以使用`exp`函数。例如，如果“是”和“否”的logprob分别为-0.405和-1.099，那么模型大约有66%的把握会是“是”，33%的把握会是“否”。
- en: For models using the OpenAI API, you can request that those logprobs be returned
    to you as shown in [Figure 2-12](ch02.html#ch02_figure_12_1728407258873476). What
    you get are the calculated probabilities, not just for the tokens that the model
    ends up choosing, but also for the ones it considered and decided not to use.
    Since the model calculates these probabilities anyway, retrieving them doesn’t
    require any additional computing effort.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 对于使用OpenAI API的模型，您可以请求返回如图2-12所示的logprobs。您得到的是计算出的概率，不仅包括模型最终选择的标记，还包括它考虑过但决定不使用的标记。由于模型无论如何都会计算这些概率，因此检索它们不需要任何额外的计算工作量。
- en: Warning
  id: totrans-53
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: Some commercial models disable the part of the API where you get the logprobs,
    mostly out of fear of being reverse-engineered if they share too much about their
    internals. If you want to use any of the tricks in this section, consider this
    in your LLM choice.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 一些商业模型禁用了API中获取logprobs的部分，主要是出于对被逆向工程以及分享过多内部信息的恐惧。如果您想使用本节中的任何技巧，请在选择LLM时考虑这一点。
- en: You can do many cool things with logprobs. Let’s talk about how to use them
    to evaluate answer quality, get the model to estimate certainties, and find critical
    locations in a (provided or generated) text.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以用logprobs做很多事情。让我们谈谈如何使用它们来评估答案质量，让模型估计确定性，以及在（提供的或生成的）文本中找到关键位置。
- en: How Good Is the Completion?
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 完成度如何？
- en: Albert’s neighbor happens to be an astrophysicist, and when Albert asked her
    how many minutes light needs to travel from the sun to Mars, roughly; she straightaway
    replied, “13,” with absolute confidence. Albert then asked his 10-year-old daughter
    the same question. She looked surprised and then hesitantly guessed, “Maybe 30?”
    One of these answers is much more reliable than the other, and anyone present
    can tell which one is more reliable from the respondent’s facial expressions and
    tone of voice. Well, logprobs are like the model’s tone of voice, and you can
    use them to see how confident it is in its answer—and that’s a strong indicator
    of answer quality.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 阿尔伯特的邻居碰巧是一位天体物理学家，当阿尔伯特问她从太阳到火星大约需要多少分钟的光旅行时，她立刻回答“13”，信心满满。阿尔伯特随后问他的10岁女儿同样的问题。她看起来很惊讶，然后犹豫地猜测，“可能是30？”其中一个答案比另一个答案更可靠，任何在场的人都可以从回答者的面部表情和语调中判断出哪个更可靠。好吧，logprobs就像模型的声音，您可以使用它们来查看模型对其答案的信心程度——这是答案质量的一个强有力的指标。
- en: Logprobs indicate a model’s confidence in each token choice (refer to [Figure 7-5](#ch07_figure_5_1728407187628014)).
    Summing logprobs across a text shows overall confidence in that text as the “correct”
    response, considering how it might start with the prompt in training data and
    conclude with the completion. However, the accuracy of this measure can decrease
    with longer texts due to the many ways in which the same idea can be expressed,
    like using “for example” or “for instance,” which can halve the probability without
    reflecting a decrease in quality.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Logprobs表示模型对每个标记选择的信心（参见图7-5）。将logprobs在整个文本中求和，可以显示该文本作为“正确”响应的整体信心，考虑到它可能在训练数据中以提示开始，并以完成结束。然而，由于同一想法可以用多种方式表达，如使用“例如”或“比如”，这可能会将概率减半而不反映质量下降，因此随着文本长度的增加，这种测量的准确性可能会降低。
- en: To assess quality, it’s beneficial to average the logprobs. The simple average—adding
    all logprobs and dividing by the number of tokens—is effective, especially if
    experimenting isn’t feasible due to constraints like data scarcity or limited
    time. For a more nuanced approach, Albert, during GitHub Copilot’s development,
    found that averaging the probabilities (rather than the logprobs) of early tokens
    in the completion is predictive of overall quality. (This is calculated as `(exp(logprob_1)
    + … + exp(logprob_n)) / n`.)
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 为了评估质量，平均对数概率是有益的。简单的平均——将所有对数概率相加然后除以标记数——是有效的，特别是如果由于数据稀缺或时间有限等限制无法进行实验时。为了更细致的方法，Albert在GitHub
    Copilot的开发过程中发现，平均完成项中早期标记的概率（而不是对数概率）可以预测整体质量。（这计算为`(exp(logprob_1) + … + exp(logprob_n))
    / n`。）
- en: 'This average provides a numerical quality indicator, and while it falls short
    of being an absolute measure of quality, in practical applications, you can explore
    logprob-based cutoffs for features within your application as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这个平均值提供了一个数值质量指标，虽然它不足以成为质量的绝对度量，但在实际应用中，你可以在你的应用程序中探索基于对数概率的特征截止值，如下所示：
- en: Only allow your application to show corrections if it is confident.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只有当模型有信心时，才允许你的应用程序显示更正。
- en: Include warnings when the model struggles more than usual.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当模型比平时更困难时，包含警告。
- en: Incorporate more context or retry when the model struggles.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当模型遇到困难时，增加更多上下文或重试。
- en: Switch to a more intelligent (and expensive) LLM for better results.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 转换到更智能（且更昂贵）的LLM以获得更好的结果。
- en: Only interrupt the user with assistance if the certainty that it is necessary
    is high. Remember [Clippy](https://oreil.ly/csVva)? Don’t be like Clippy.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只有当确定它必要时的高确定性时，才中断用户以提供帮助。记住[Clippy](https://oreil.ly/csVva)吗？不要像Clippy一样。
- en: For greater quality at a higher compute cost, you can also consider setting
    a higher temperature, generating multiple completions, and choosing the best one
    based on their logprobs.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得更高的质量但计算成本更高，你也可以考虑设置更高的温度，生成多个完成项，并根据它们的对数概率选择最佳项。
- en: Tip
  id: totrans-67
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Many LLM APIs have a parameter called n, which controls the number of completions
    that are generated from the same prompt in parallel. If n is larger than 1, then
    the temperature should be larger than 0 or all completions will be the same. A
    rough (and completely unscientific) rule of thumb we like to use is temperature
    = sqrt(n) / 10.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 许多LLM API都有一个名为n的参数，它控制从相同提示中并行生成的完成项的数量。如果n大于1，则温度应大于0，否则所有完成项都将相同。我们喜欢使用的一个粗略（并且完全非科学的）经验法则是温度
    = sqrt(n) / 10。
- en: LLMs for Classification
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类用LLM
- en: The concepts of classification and logprobs are intertwined in the context of
    LLMs, as logprobs provide critical insights into the model’s decision-making processes,
    confidence, and reliability. Let’s take a look at classification now.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在LLM的上下文中，分类和对数概率的概念是相互关联的，因为对数概率提供了对模型决策过程、信心和可靠性的关键见解。现在让我们来看看分类。
- en: '*Classification* is a basic machine learning task in which you determine which
    category a specific case belongs to from a set of predefined options. For instance,
    you might classify an online review as positive, negative, or neutral, or you
    could predict whether a product is best suited for the American, European, or
    Asian market. In simpler terms, you could be deciding if the answer to a question
    is yes or no. The key aspect is that, much as in a detective novel with a limited
    number of suspects, there are a fixed number of possible categories, and your
    goal is to identify the correct one and determine your confidence level in that
    choice.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '*分类* 是机器学习中的一个基本任务，其中你确定一个特定案例属于一组预定义选项中的哪一个类别。例如，你可能将在线评论分类为正面、负面或中性，或者你可以预测一个产品最适合美国、欧洲还是亚洲市场。用更简单的术语来说，你可能是在决定一个问题的答案是“是”还是“否”。关键方面是，就像侦探小说中有限数量的嫌疑人一样，存在固定数量的可能类别，你的目标是识别正确的类别并确定你对这个选择的信心水平。'
- en: 'This is pretty much the opposite of how LLMs were built to work: LLMs lean
    toward long, creative generation instead of fixed, boxed-in classification. But
    LLMs are pre-trained generalists, and in domains where the classification task
    relies on public knowledge and common sense, they have a good chance to excel
    with little to no extra training data. The prompt engineer has to set up the prompt
    in a way that the model chooses exactly one of the alternatives. But there are
    some subtleties, which we’ll talk about now.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这几乎与LLM被构建来工作的方式相反：LLM倾向于长篇大论的创造性生成，而不是固定的、封闭的分类。但LLM是预训练的通用主义者，在分类任务依赖于公共知识和常识的领域，它们有很好的机会在几乎没有额外训练数据的情况下表现出色。提示工程师必须以这种方式设置提示，即模型选择这三种选项中的确切一个。但也有一些细微之处，我们现在将讨论。
- en: 'At the basic level, you use your LLM just by asking it questions. If you want
    to find out whether a sentence is positive, negative, or neutral, you might present
    the sentence to the model and add the question, “Does that sound positive, negative
    or neutral to you?” Then, you might check the answer for which of these three
    alternatives occurs in it. Of course, you want to avoid waffling answers that
    include several alternatives, like “more positive than neutral.” A more refined
    question might be “Does that sound positive, negative, or neutral to you? Please
    answer in the format: 1\. [negative | positive | neutral], 2\. [explanation].”
    The “1.” in this example is what we called a *recognizable start*, and you can
    expect the answer directly after it.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在基本层面上，你只需通过提问来使用你的LLM。如果你想了解一个句子是积极的、消极的还是中性的，你可以将句子展示给模型，并附加问题：“你觉得这个听起来是积极的、消极的还是中性的？”然后，你可能检查答案，看其中包含这三个选项中的哪一个。当然，你想要避免包含几个选项的含糊其辞的回答，比如“比中性更积极”。一个更精细的问题可能是：“你觉得这个听起来是积极的、消极的还是中性的？请以以下格式回答：1.
    [negative | positive | neutral]，2. [解释]。”在这个例子中，“1.”就是我们所说的“可识别的开始”，你可以在其后直接期待答案。
- en: 'In this situation, it’s a good idea to ensure that after the first recognizable
    token, you can immediately tell which option the model chooses. Here’s why: in
    [Figure 7-5](#ch07_figure_5_1728407187628014), the model has three options: North
    America, Northeast Asia, and Europe. Two of these, North America and Northeast
    Asia, both start with the token *North*. When the model predicts the next token,
    the two answers that start with *North* combine their chances, since the model
    predicts only *North* at first. If the model is uncertain, it’s more likely to
    choose *North* because both options share it. The actual decision between the
    two will come afterward. To avoid this, you need to make sure each option starts
    with a unique token.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，确保在第一个可识别的标记之后，你可以立即知道模型选择了哪个选项是个好主意。原因如下：在[图7-5](#ch07_figure_5_1728407187628014)中，模型有三个选项：北美、东北亚和欧洲。其中两个，北美和东北亚，都以标记*North*开头。当模型预测下一个标记时，以*North*开头的两个答案会合并它们的机会，因为模型最初只预测*North*。如果模型不确定，它更有可能选择*North*，因为两个选项都共享它。两个之间的实际决策将在之后进行。为了避免这种情况，你需要确保每个选项都以一个独特的标记开头。
- en: '![](assets/pefl_0705.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/pefl_0705.png)'
- en: Figure 7-5\. The model’s calculated total probability for Europe is highest
    (44% versus 55% × 76% = 42% for Northeast Asia), but the suggestion will be Northeast
    Asia
  id: totrans-76
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-5. 模型对欧洲的总概率计算最高（44%，而东北亚为55% × 76% = 42%），但建议将是东北亚
- en: Note that in the figure, because the first decision is between North and Europe,
    the probabilities for Northeast Asia and North America are added together, leading
    the model to put out a suggestion it actually considers suboptimal. These are
    actual probabilities from OpenAI’s gpt-3.5-turbo-instruct.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在图中，因为第一个决策是在北美和欧洲之间，所以东北亚和北美的概率被加在一起，导致模型提出了一个它实际上认为次优的建议。这些是来自OpenAI的gpt-3.5-turbo-instruct的实际概率。
- en: You can let the model make all kinds of decisions through classification, but
    in many situations, its prediction will be badly calibrated compared to what you
    want. For example, let’s say you’re writing an app that helps grumpy users by
    blocking some of the emails they write if the LLM deems them not sufficiently
    friendly and asks them to rewrite them. You can pretty easily ask the model, “Is
    this a professionally written email? Please use the format 1\. Yes / No. 2\. Explanation.”
    But even if the model is good at recognizing whether one email is more professionally
    written than another, the threshold between what you do and don’t consider to
    be professional is likely not the same as the model’s. To match the model’s threshold
    more closely, you’ll have to calibrate, and that’s where the logprobs finally
    come into play.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过分类让模型做出各种决定，但在许多情况下，与你的期望相比，其预测将校准得非常糟糕。例如，假设你正在编写一个应用程序，该应用程序通过阻止 LLM
    认为不够友好的电子邮件来帮助脾气暴躁的用户。你可以很容易地要求模型，“这是一封专业写的电子邮件吗？请使用格式 1. 是 / 否。2. 解释。”即使模型擅长识别一封电子邮件是否比另一封更专业，你认为是专业和不是专业的阈值可能与模型的阈值不同。为了使模型的阈值更接近，你必须进行校准，这就是
    logprob 最终发挥作用的地方。
- en: '*Calibration* means adjusting the certainty of a classification to better match
    the “true” certainty. A priori, the certainty of the prediction is the logprob,
    and whatever token has the highest logprob is what the model will produce (at
    temperature 0). But if, for example, you find that the model lets through too
    few emails, you’ll wish that the model would only output No if it’s super certain.
    So maybe it should only choose No if the logprob for No is at least 0.3 higher
    than the one for Yes.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '*校准* 意味着调整分类的确定性，以更好地匹配“真实”的确定性。事先，预测的确定性是 logprob，并且具有最高 logprob 的标记就是模型将产生的结果（在温度
    0 时）。但是，如果你发现模型放过了太多的电子邮件，你可能希望模型只有在非常确定的情况下才输出 No。所以，也许只有当 No 的 logprob 至少比 Yes
    的 logprob 高 0.3 时，模型才应该选择 No。'
- en: 'Generally, to calibrate the LLM’s decision process, you shift the logprobs
    by a constant (where each a[tok] corresponds to one of the tokens in question).
    For example, you can make the email classification less strict by adding a constant
    like a[yes] = 0.3 to the logprob of “Yes” before comparing it with the logprob
    for *No*. You can find these constants either by experimentation or by some classical
    machine learning: taking ground truth data and minimizing the [cross entropy loss](https://oreil.ly/WTiBc)
    like you do in [logistic regression](https://oreil.ly/aR3Wn).'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，为了校准 LLM 的决策过程，你会通过一个常数来调整 logprob（其中每个 a[tok] 对应于问题中的一个标记）。例如，你可以通过在比较“是”的
    logprob 和 *No* 的 logprob 之前，给“是”的 logprob 添加一个常数（如 a[yes] = 0.3），来使电子邮件分类不那么严格。你可以通过实验或一些经典的机器学习来找到这些常数：使用真实数据并最小化
    [交叉熵损失](https://oreil.ly/WTiBc)，就像你在 [逻辑回归](https://oreil.ly/aR3Wn) 中做的那样。
- en: Tip
  id: totrans-81
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: If you found constants a[tok] that you like, you don’t actually have to mess
    with the logprobs anymore—many model providers offer in their API the possibility
    of a *logit bias*, where you send the a[tok] to the model and they will be applied
    for you.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你找到了你喜欢的常数 a[tok]，你实际上不需要再与 logprobs 打交道了——许多模型提供商在其 API 中提供了 *logit bias*
    的可能性，你可以将 a[tok] 发送到模型，它们会为你应用。
- en: Critical Points in the Prompt
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示中的关键点
- en: Another application of logprobs isn’t to get the certainty in the complution,
    but to understand the surprising parts of the prompt. Setting the parameter “echo”
    to true tells many APIs to return not only the logprobs for the completion, but
    also for the prompt. You can run this to better understand the text you send to
    the model, even if you don’t request a single completion token.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: logprob 的另一个应用不是获取编译中的确定性，而是理解提示中的意外部分。将参数“echo”设置为 true 告诉许多 API 不仅返回完成文本的
    logprob，还返回提示的 logprob。你可以运行这个参数来更好地理解你发送给模型的文本，即使你不需要请求单个完成标记。
- en: For example, in the paragraph you just read, did you notice a typo? So did the
    model. As shown in [Figure 7-6](#ch07_figure_6_1728407187628032), when you’re
    displaying the logprobs, that typo stands out like a sore thumb with a logprob
    of below―13, where instead of the “completion” token, the model got only the “compl”
    token (followed by “ution”). This way, you can use logprobs to detect not only
    typos but also otherwise surprising parts of the text. More generally, you can
    use logprobs to detect passages in the text with higher information density, with
    the idea of focusing your app’s attention on certain locations or alternatively
    guiding the user’s attention.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在你刚刚阅读的段落中，你是否注意到了一个错别字？模型也注意到了。如图[图7-6](#ch07_figure_6_1728407187628032)所示，当你显示logprobs时，这个错别字就像一个突出的痛处，其logprob值低于-13，模型得到的不是“completion”标记，而是只有“compl”标记（后面跟着“ution”）。这样，你可以使用logprobs来检测不仅错别字，还有文本中其他令人惊讶的部分。更普遍地说，你可以使用logprobs来检测文本中信息密度较高的段落，目的是将你应用的注意力集中在某些位置，或者引导用户的注意力。
- en: '![](assets/pefl_0706.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/pefl_0706.png)'
- en: Figure 7-6\. Logprobs of two versions of a paragraph of text, shown interleaved
  id: totrans-87
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-6. 文本段落两个版本的logprobs，显示为交错
- en: 'As you can see in [Figure 7-6](#ch07_figure_6_1728407187628032), negative single-digit
    logprobs are somewhat common, while negative double-digit logprobs are usually
    the model picking up some weirdness. However, there’s no clearly delineated threshold,
    and even heuristics vary from model to model and genre of text to genre of text.
    In fact, they vary *within* a single text: in the beginning, the logprobs are
    usually lower (i.e., further below 0) than toward the end. That’s because much
    about the topic and style of the text becomes clear to the model only as it’s
    reading it.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在[图7-6](#ch07_figure_6_1728407187628032)中可以看到的，负的单位数logprobs相对常见，而负的双位数logprobs通常意味着模型捕捉到了一些奇怪之处。然而，并没有一个明确的界限，而且启发式方法也因模型和文本类型的不同而异。实际上，它们在单个文本内部也会变化：在开始时，logprobs通常比结尾时低（即，更接近0）。这是因为关于文本的主题和风格的大部分内容只有在模型阅读时才会变得清晰。
- en: Warning
  id: totrans-89
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 警告
- en: When writing unit tests for any parts of your application that deal with logprobs,
    remember that due to floating-point inaccuracies, logprobs are not deterministic.
    Depending on the model deployment, they may vary by as much as ± 1, so write your
    tests to be robust against such variation or mock out the model entirely.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 当为处理logprobs的应用程序的部分编写单元测试时，请记住，由于浮点数的不精确性，logprobs不是确定的。根据模型部署的不同，它们可能变化±1，因此编写你的测试以抵抗这种变化，或者完全模拟模型。
- en: Choosing the Model
  id: totrans-91
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择模型
- en: 'In this chapter thus far, we’ve focused on the model itself, but we’ve danced
    around an important question: which model should you use? LLM choice is going
    to be critical to the success of any AI software development project, and yet,
    there are many alternatives, with new ones popping up every week. In a landscape
    that’s changing this quickly, recommendations for particular models are going
    to become stale pretty quickly, so we’ll instead focus on the underlying principles
    that should guide your choice.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们一直专注于模型本身，但我们一直在回避一个重要的问题：你应该使用哪个模型？LLM的选择对于任何AI软件开发项目的成功都至关重要，然而，有许多替代方案，每周都有新的方案出现。在这个变化如此迅速的环境中，对特定模型的建议很快就会过时，因此我们将专注于应该指导你选择的底层原则。
- en: Tip
  id: totrans-93
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Whatever model you end up choosing, don’t bake your choice into your code too
    firmly. You may want to revise, evaluate, and refine your choice. Libraries like
    [LiteLLM](https://litellm.ai) may be useful here for providing a unified API to
    many different models.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你最终选择哪个模型，都不要将你的选择过于牢固地嵌入到代码中。你可能想要修订、评估和改进你的选择。像[LiteLLM](https://litellm.ai)这样的库可能在这里很有用，因为它为许多不同的模型提供了一个统一的API。
- en: 'The model you *need* depends on what you *want.* There’s no single quality
    that reigns supreme, but here’s a list of of considerations (in order of importance)
    for most scenarios:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要的模型取决于你想要什么。没有一种单一的品质是至高无上的，但这里有一份考虑因素列表（按重要性排序），适用于大多数情况：
- en: Intelligence
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 智能度
- en: How close is the model’s answer to that of an intelligent human expert with
    strong subject matter expertise? This is especially important for apps that ask
    the model complicated questions that require complex reasoning or very accurate
    answers.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的答案与一个具有强大专业知识的人类专家的答案有多接近？这对于要求复杂推理或非常准确答案的应用程序尤为重要。
- en: Speed
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 速度
- en: How long do you have to wait for your answer? This is especially important for
    apps that interact very directly with their users (see [Table 5-2](ch05.html#ch05_table_2_1728435524657385)
    about the different levels of urgency users may feel depending on the kind of
    application).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要等待多长时间才能得到答案？这对于与用户直接互动的应用程序尤为重要（参见[表5-2](ch05.html#ch05_table_2_1728435524657385)关于用户可能对应用程序的不同紧急程度的感受）。
- en: Cost
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 成本
- en: How much do you pay for running inference, either directly to the model provider
    or in costs for GPUs? This is especially important for apps that make very frequent
    requests to the model.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 你为运行推理支付多少费用，无论是直接向模型提供商支付还是为GPU支付的费用？这对于频繁向模型提出请求的应用程序尤为重要。
- en: Ease of use
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 易用性
- en: How much of the work regarding arranging GPUs, deploying the model, restarting
    crashed instances, routing, caching, etc., is conveniently done for you?
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在安排GPU、部署模型、重启崩溃的实例、路由、缓存等方面，有多少工作可以方便地为你完成？
- en: Functionality
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 功能性
- en: Does the model have the capabilities for instruct, chat, and tool use? Does
    it surface logprobs? Can it process images as well as language?
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 模型是否有指令、聊天和工具使用的功能？它是否可以显示logprobs？它是否可以像处理语言一样处理图像？
- en: Special requirements
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 特殊要求
- en: These are a lot like dietary requirements; for some people, they are nonnegotiable,
    but for others, they are completely unimportant. Some app developers might prefer
    models to be noncommercial, open source, trained on specific data, and regularly
    updated (or not). They might want to ensure data residency in a particular country,
    or they may avoid logging off premises. These preferences can quickly narrow down
    the available options (see [Figure 7-7](#ch07_figure_7_1728407187628052)).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这些与饮食需求有很多相似之处；对一些人来说，它们是不可协商的，但对其他人来说，它们完全不重要。一些应用开发者可能更喜欢模型是非商业的、开源的、基于特定数据训练的，并且定期更新（或不更新）。他们可能希望确保数据保留在特定国家，或者他们可能避免在本地之外注销。这些偏好可能会迅速缩小可用的选项（参见[图7-7](#ch07_figure_7_1728407187628052)）。
- en: '![](assets/pefl_0707.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/pefl_0707.png)'
- en: Figure 7-7\. The knobs and dials you use to decide what kind of model you’ll
    have
  id: totrans-109
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-7\. 你用来决定你将拥有什么类型模型的旋钮和仪表
- en: 'As [Figure 7-7](#ch07_figure_7_1728407187628052) illustrates, as you tighten
    one requirement, you often constrain the type of model available. Here are some
    examples:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如[图7-7](#ch07_figure_7_1728407187628052)所示，当你收紧一个要求时，你通常会限制可用的模型类型。以下是一些例子：
- en: If you know that your app will make a high volume of relatively simple requests
    to the model and that you’ll therefore need it to be cheap but not smart, a small
    model is likely to be appropriate.
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你知道你的应用将对模型进行大量相对简单的请求，因此你需要它既便宜又不聪明，那么一个小的模型可能是合适的。
- en: If your app is a solo project that you want to knock out quickly, and if it
    only makes about one request per day, then you should feel encouraged to splurge
    on a premium-tier model because cost may only be a factor at scale.
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你的应用是一个快速完成的独立项目，并且它每天只发出大约一个请求，那么你应该感到鼓励去购买高端级别的模型，因为成本可能只在规模上才是因素。
- en: If you make a ton of very difficult requests and need your model to be super
    cheap while being super smart…tough luck, because these two qualities are at opposite
    ends of the spectrum.
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你提出大量非常困难的请求，并且需要你的模型超级便宜同时超级聪明……很遗憾，因为这两个品质在光谱的两端。
- en: When you’re deciding on a model, the first step is usually picking a provider.
    You’ll likely base this decision on your requirements, desired features, and whether
    you want a scrappy or premium solution. Most providers offer a range of models,
    and you’ll narrow them down based on specific capabilities and needs, and then
    you’ll choose the model size.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在选择模型时，第一步通常是选择一个提供商。你可能会根据你的需求、期望的功能以及你是否想要一个粗糙或高端的解决方案来做出这个决定。大多数提供商提供一系列的模型，你将根据特定的功能和需求来缩小范围，然后选择模型的大小。
- en: 'At one point, OpenAI, known for its highly advanced models and full-service
    platform, was the dominant choice. However, over the course of 2024, the playing
    field has become more even. Here are some other choices to consider:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在某个时刻，以高度先进的模型和全面服务平台而闻名的OpenAI曾是首选。然而，在2024年期间，竞争场已经变得更加均衡。以下是一些其他可以考虑的选择：
- en: Anthropic
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Anthropic
- en: Emphasizes human alignment and AI safety. Its Claude 3.5 Sonnet model recently
    (in 2024) jumped to the top of several LLM benchmarks (see [Claude 3.5 Sonnet’s
    website](https://oreil.ly/pWZkS)).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 强调人类对齐和人工智能安全。其Claude 3.5 Sonnet模型最近（在2024年）在几个LLM基准测试中跃居首位（参见[Claude 3.5 Sonnet的网站](https://oreil.ly/pWZkS)）。
- en: Mistral
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Mistral
- en: Specializes in highly efficient, open-weight models; ideal for applications
    that need very specialized configurations.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 专注于高度高效、开放权重模型；非常适合需要非常专用配置的应用。
- en: Cohere
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: Cohere
- en: Popular for high-performance RAG applications.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 因高性能RAG应用而受到欢迎。
- en: Google
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: Google
- en: Strong integration with Google’s ecosystem, cutting-edge research, and large-scale
    infrastructure.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 与Google生态系统、尖端研究和大规模基础设施紧密结合。
- en: Meta
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Meta
- en: Large, highly capable open-access models.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 大型、功能强大的开放访问模型。
- en: Tip
  id: totrans-126
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: There are many model comparison sites around to serve as a starting point in
    your exploration of what to start prototyping with or which alternatives to evaluate
    in more detail. We quite like [the Artificial Analysis website](https://artificialanalysis.ai).
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在你探索从哪里开始原型设计或评估哪些替代方案时，有许多模型比较网站可以作为起点。我们相当喜欢[人工分析网站](https://artificialanalysis.ai)。
- en: But if having the premium tier isn’t a requirement for you, then you don’t have
    to rely on an LLM-as-a-service company at all. Several LLMs like LLaMA and Mistral
    are open source and typically trained by academic groups or open source―friendly
    companies. Hosting these models requires significant effort, though platforms
    like Hugging Face aim to ease the process, whether you use your own servers or
    their Azure partnership. We recommend this route only if your app is large enough
    to justify the infrastructure investment and if your model needs to steer you
    away from full-service solutions. If you’re using agile methods, you can also
    prototype using the easily accessible OpenAI APIs with the intention of moving
    to a different platform when going public.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 但如果你不需要高级版，那么你根本不需要依赖LLM-as-a-service公司。几个LLM，如LLaMA和Mistral，是开源的，通常由学术团体或开源友好公司训练。托管这些模型需要大量努力，尽管像Hugging
    Face这样的平台旨在简化流程，无论你使用自己的服务器还是他们的Azure合作伙伴关系。我们只推荐这种方法，如果你的应用程序足够大，足以证明基础设施投资的合理性，并且如果你的模型需要让你远离全面服务解决方案。如果你使用敏捷方法，你还可以使用易于访问的OpenAI
    API进行原型设计，目的是在公开时转移到不同的平台。
- en: After you’ve found a provider, you’ll probably have to choose among several
    different models the provider offers, and apart from some consideration of capabilities,
    this mainly means choosing the model size. Whether or not latency matters, completion
    quality versus cost is always a hard trade-off. Typically, you’ll want the smallest
    model that can reliably deliver on your task.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 找到提供商后，你可能需要在提供商提供的几个不同模型中进行选择，除了对能力的考虑外，这主要意味着选择模型大小。是否需要考虑延迟，完成质量与成本之间的权衡总是很困难。通常，你希望选择一个最小的模型，它能可靠地完成你的任务。
- en: Tip
  id: totrans-130
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 小贴士
- en: Feel free to prototype with slightly larger models than you think you can afford.
    As new flagship models get released, the older ones tend to become cheaper over
    time, so by the time your public beta comes around, there will be better models
    in scope than there were during prototyping. You’ll be glad if your prompt engineering
    and postprocessing is already optimized for the better models you now can afford.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 随意使用比你认为可以负担得起的稍大一点的模型进行原型设计。随着新旗舰模型的发布，旧模型往往会随着时间的推移而变得更便宜，所以到你的公开测试版推出时，会有比原型设计期间更好的模型可供选择。如果你的提示工程和后处理已经针对你现在可以负担的更好模型进行了优化，你会感到很高兴。
- en: You probably won’t ever want to build and train your own model from scratch,
    but you may want to take an existing model and *make* *it your own* by training
    it specifically on the task that your application will use it for. This process
    is called *fine-tuning*. While this topic moves beyond the scope of this book,
    we do want to familiarize you enough with the basic concepts so you’ll be able
    to judge whether it’s a promising idea in your case and whether to invest more
    time in it.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能永远不会想从头开始构建和训练自己的模型，但你可能希望使用现有的模型，并通过针对你的应用程序将使用它的任务进行特定训练来将其变成你自己的模型。这个过程被称为**微调**。虽然这个主题超出了本书的范围，但我们确实想让你足够熟悉基本概念，以便你能判断在你的情况下这是否是一个有希望的想法，以及是否值得投入更多时间。
- en: When an LLM is first trained, it effectively reads through lots of documents
    and learns how to mimic them. In fine-tuning, you present the model with new documents
    and train it to mimic those documents. This will often decrease the model’s ability
    to produce generic documents, but it can dramatically improve the model’s ability
    to produce the types of documents you anticipate seeing in your work.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个大型语言模型（LLM）最初被训练时，它实际上会阅读大量文档并学习如何模仿它们。在微调过程中，你向模型展示新的文档并训练它模仿这些文档。这通常会降低模型生成通用文档的能力，但可以显著提高模型生成你预期在工作场所看到的文档类型的能力。
- en: To fine-tune a model, you’ll need a set of training documents that show successful
    interactions. These should have factually correct answers, use only the background
    information you want the model to learn, and adhere to the expected format. How
    can you gather these examples? You can create some yourself, hire contractors,
    or even synthesize them. If your app has users, you might collect examples based
    on success indicators like accepted suggestions or user likes. If your app automates
    a task previously done by humans, you could use their interactions as examples.
    Whether you can gather these examples is key in deciding if fine-tuning is worth
    it (see [Figure 7-8](#ch07_figure_8_1728407187628068)).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 要微调一个模型，你需要一组显示成功交互的训练文档。这些文档应该包含事实正确的答案，只使用你希望模型学习的背景信息，并遵循预期的格式。你如何收集这些例子？你可以自己创建一些，雇佣承包商，甚至合成它们。如果你的应用程序有用户，你可能可以根据成功指标（如接受的建议或用户喜欢）收集例子。如果你的应用程序自动化了以前由人类完成的任务，你可以使用他们的交互作为例子。你能否收集这些例子是决定微调是否值得的关键（见图
    7-8\[图 7-8\](#ch07_figure_8_1728407187628068)）。
- en: Some fine-tuning frameworks allow you to only train your model, surgically,
    on the portion of the document that addresses the problem, rather than, for example,
    on the portion of the document where a user specifies the problem. Only focusing
    on these critical parts of the document is called *loss masking*, and it is useful
    because probably, you’re not interested in whether the model can produce the part
    of the document that is the prompt.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 一些微调框架允许你只对文档中解决该问题的部分进行手术性的训练，而不是例如对用户指定问题的文档部分进行训练。只关注文档的这些关键部分被称为**损失掩码**，它是有用的，因为可能你并不关心模型能否生成提示部分的文档。
- en: '![](assets/pefl_0708.png)'
  id: totrans-136
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/pefl_0708.png)'
- en: Figure 7-8\. Should you fine-tune?
  id: totrans-137
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 7-8\. 你应该微调吗？
- en: Depending on how many training documents you come up with, you’ll have options
    for different kinds of fine-tuning. We’ll discuss the main options here, and we’ve
    also summarized them in [Table 7-2](#ch07_table_2_1728407187636061).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你提出的训练文档的数量，你将会有不同类型微调的选项。我们将在这里讨论主要选项，我们还在[表 7-2](#ch07_table_2_1728407187636061)中总结了它们。
- en: '*Full fine-tuning*, or *continued pre-training*, is simply the continuation
    of the training process with different documents. That means that every one of
    the model’s billions of parameters is adjusted, and it takes time, computational
    power, and many, many examples to adjust the parameters in the right way. Like
    all neural training, this isn’t like explaining a concept to a human and expecting
    them to learn by understanding. It’s more like a riverbed forming: you pour thousands
    upon thousands of training documents over the model, and very slowly, a groove
    is carved out. The advantage is, that new groove can be anything. The original
    model is the starting point, but you can teach it completely new facts and new
    domains.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '**完全微调**或**持续预训练**仅仅是使用不同文档继续训练过程。这意味着模型的数十亿个参数中的每一个都会被调整，这需要时间、计算能力和许多许多示例来正确调整参数。像所有神经网络训练一样，这不像向人类解释一个概念并期望他们通过理解来学习。它更像是河床的形成：你将成千上万的训练文档倒在模型上，非常缓慢地，一条沟槽被刻出来。优势在于，新的沟槽可以是任何东西。原始模型是起点，但你可以完全教授它新的事实和新领域。'
- en: Low-rank adaptation (LoRA) is a parameter-efficient fine-tuning technique designed
    to make model training more efficient. The key idea is that when you don’t need
    the model to learn something entirely new, you don’t have to adjust all of its
    parameters. Instead, LoRA focuses on a few key parameter matrices in the LLM and
    trains a “*diff*” to those matrices, which for each original matrix is a difference
    matrix that is added to the original, but one that has fewer degrees of freedom
    (hence, it’s of *low rank*).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 低秩自适应（LoRA）是一种参数高效的微调技术，旨在使模型训练更加高效。关键思想是，当你不需要模型学习全新的东西时，你不需要调整它的所有参数。相反，LoRA专注于LLM中的几个关键参数矩阵，并训练一个“*diff*”到这些矩阵，对于每个原始矩阵，这是一个添加到原始矩阵的差分矩阵，但它具有更少的自由度（因此，它是*低秩*的）。
- en: This approach has practical benefits—since the diffs are small, they can easily
    be shared between virtual machines, and one deployment can handle multiple diffs,
    allowing you to use the same machine for different models. More importantly, LoRA
    fine-tuning is relatively fast, typically taking hours or a few days, making it
    a compute-efficient option.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法具有实际的好处——由于diff很小，它们可以轻松地在虚拟机之间共享，并且一次部署可以处理多个diff，允许你使用同一台机器处理不同的模型。更重要的是，LoRA微调相对较快，通常需要几个小时或几天，使其成为一个计算高效的选项。
- en: 'But there are also drawbacks: depending on the LoRA dimension (a number measuring
    the degrees of freedom to the diff you train), the model is limited in how much
    it can learn. In general, a good intuition is that LoRA doesn’t really teach a
    model new tricks. Rather, LoRA teaches the model which of the tricks that it’s
    already capable of performing it should expect to use, and in which way. In particular,
    this includes things like what to pay attention to in the prompt, how to interpret
    it, and what is expected from the model in the completion. Format and style are
    easily learnable with LoRA. Another thing that LoRA is great at doing is giving
    the model a general feel for the prior distributions it should assume for your
    domain.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 但也存在一些缺点：根据LoRA维度（一个衡量训练中diff自由度的数字），模型在它能学习的内容上有所限制。一般来说，一个良好的直觉是LoRA并不真正教会模型新的技巧。相反，LoRA教会模型它已经能够执行哪些技巧，以及它应该期望如何使用这些技巧。特别是，这包括在提示中注意什么，如何解释它，以及模型在完成时应该期望得到什么。格式和风格很容易通过LoRA学习。LoRA擅长做的另一件事是给模型一个关于它应该为你的领域假设的先验分布的总体感觉。
- en: 'Let’s explain the last point through an example. Say your application helps
    people select travel destinations and all your customers are based in Europe.
    Being Europeans, their preferred suggestions will have a very different distribution
    than if they were based in the United States. Napa Valley is far away, and Monaco
    is just around the corner. Fine-tuning can teach the model that, but to be fair,
    so could you: you could just add to the prompt that the customer is European,
    so the model should choose destinations based on that. But what about factors
    you don’t know explicitly? Maybe most users of your app are students, and they’re
    looking for budget destinations. Your app telemetry might show that suggesting
    Monaco usually gets a thumbs-down but that every time you suggest Prague, the
    user buys a ticket. If you have such data to feed it, LoRA fine-tuning excels
    at conditioning the model to such a distribution shift, whether it depends on
    an aspect you’re aware of (preference for budget destinations) or not.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来解释最后一个观点。假设你的应用程序帮助人们选择旅行目的地，而你所有的客户都基于欧洲。作为欧洲人，他们偏好的建议将与他们基于美国时非常不同。纳帕谷很远，而摩纳哥就在附近。微调可以教会模型这一点，但公平地说，你也可以做到：你只需在提示中添加客户是欧洲人的信息，这样模型就应该根据这一点选择目的地。但关于你不知道的因素呢？也许你应用程序的大多数用户都是学生，他们正在寻找预算目的地。你的应用程序遥测数据可能显示，建议摩纳哥通常会得到差评，但每次你建议布拉格，用户就会买票。如果你有这种数据来提供，LoRA微调在使模型适应这种分布变化方面表现出色，无论它是否取决于你意识到的方面（对预算目的地的偏好）。
- en: 'With either continued pre-training or LoRA fine-tuning, you can normally get
    rid of *all* your static prompt context, the general explanations, and instructions—the
    model will just bake them into its parameters. You also don’t need few-shot prompting
    anymore: all lessons from those few-shots should already be absorbed into the
    LoRA model, and more effectively than when presented in the prompt. In this sense,
    fine-tuning is a continuation of prompt engineering by other means.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 通过持续预训练或LoRA微调，你通常可以摆脱*所有*静态提示上下文、一般解释和指令——模型将它们直接嵌入到其参数中。你也不再需要少样本提示：那些少样本中的所有教训应该已经融入LoRA模型，并且比在提示中呈现时更有效。从这个意义上说，微调是通过其他方式对提示工程的延续。
- en: A technique called *soft prompting* continues further. Thinking back to [Chapter 2](ch02.html#ch02_understanding_llms_1728407258904677),
    consider what happens to the model as it processes the tokens in a prompt. Effectively,
    the prompt creates a “state of mind” in the model that conditions what tokens
    it will predict next. So, you can spend a lot of time crafting the words to elicit
    the right state of mind…or you can simply give a few dozen examples of desired
    outputs to the model and use machine learning to find a model state that makes
    the model most likely produce them. Soft prompting is a cool idea, but you’ll
    need to check whether your model framework gives you this opportunity—many don’t.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 一种称为*软提示*的技术继续发展。回顾[第2章](ch02.html#ch02_understanding_llms_1728407258904677)，考虑模型在处理提示中的标记时会发生什么。实际上，提示在模型中创造了一种“心态”，它决定了模型将预测下一个标记。因此，你可以花很多时间精心设计词语来引发正确的状态…或者你可以简单地给模型提供几十个期望输出的示例，并使用机器学习找到使模型最有可能产生这些输出的模型状态。软提示是一个很酷的想法，但你需要检查你的模型框架是否给你这个机会——许多模型框架都没有。
- en: Table 7-2\. Different types of fine-tuning
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 表7-2\. 不同类型的微调
- en: '|   | The model typically learns… | It makes the most sense if your training
    documents number in the… | Fine-tuning often takes… |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '|   | 模型通常学习… | 如果你的训练文档数量在… | 微调通常需要… |'
- en: '| --- | --- | --- | --- |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| **Full fine-tuning or continued pre-training** | New things about a potentially
    whole new domain. | Tens of thousands. | Weeks or months. |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| **全量微调或持续预训练** | 一个可能全新领域的新事物。 | 数以万计。 | 周或月。 |'
- en: '| **Parameter efficient fine-tuning (e.g., LoRA)** | Prior expectations within
    an existing domain, interpreting information in a certain way, and obeying a fixed
    format. | Hundreds or thousands. | Days. |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| **参数高效微调（例如，LoRA）** | 在现有领域内的先验期望，以某种方式解释信息，并遵循固定格式。 | 数百或数千。 | 天。 |'
- en: '| **Soft prompting** | Whatever information is contained in *that* prompt.
    | Hundreds. | Hours. |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| **软提示** | 那个提示中包含的任何信息。 | 数百。 | 小时。 |'
- en: 'No matter which fine-tuning paradigm you go for, there will be one crucial
    impact: the Little Red Riding Hood principle will work differently for fine-tuned
    models. There are now two kinds of documents, two kinds of paths Little Red could
    follow: the old path of the model’s original training and the new path you have
    fine-tuned for. The old path might be slightly overgrown, but it’s still visible,
    and you need to beware: if the prompt looks like it might follow that path, so
    will the model in the completion—in effect, the model will simply [forget its
    fine-tuning](https://arxiv.org/abs/2309.10105). So, the modified Little Red Riding
    Hood principle says these things:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你选择哪种微调范式，都会有一个关键的影响：小红帽原则对微调模型将有所不同。现在有两种类型的文档，小红帽可以跟随的两条路径：模型原始训练的老路和为你微调的新路。旧路可能有点荒芜，但仍然可见，你需要小心：如果提示看起来可能遵循那条路，那么在补全时模型也会遵循那条路——实际上，模型会简单地[忘记其微调](https://arxiv.org/abs/2309.10105)。因此，修改后的小红帽原则说这些事情：
- en: Try to make your prompt look like the beginning of one of the documents you
    fine-tuned for.
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 尽量让你的提示看起来像你微调过的文档的开头之一。
- en: Be very sure not to have it look like one of the original documents instead.
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保它看起来不像原始文档之一。
- en: Conclusion
  id: totrans-155
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 结论
- en: 'Taming the model is hard: it sometimes feels like LLMs have a mind of their
    own, and they don’t want to follow the path you laid out for them. But you now
    have a good understanding of how to lead them along the path that you want—do
    this by clearly defining the completion you want them to provide and then using
    the tricks you’ve learned to guide them toward a completion with the expected
    format, style, and content.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 驯服模型是困难的：有时感觉LLMs（大型语言模型）似乎有自己的想法，它们不愿意遵循你为他们设定的路径。但现在你已很好地理解了如何引导它们沿着你想要的路径前进——通过明确定义你希望它们提供的完成内容，然后使用你所学到的技巧引导它们达到具有预期格式、风格和内容的完成。
- en: Most of the time, the text of the completion is the focal point of your work.
    But in this chapter, you also learned about logprobs and how to use them to glean
    more information from LLM completions. And if the model still won’t do as you
    say, you have the knowledge at your disposal to decide upon a different model
    or to even train your model yourself, if that’s the right path for you.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数时候，完成文本的内容是你的工作焦点。但在本章中，你也学习了关于logprobs以及如何使用它们从LLM的完成中获取更多信息。如果模型仍然不按你的要求执行，你拥有足够的知识来决定选择不同的模型，甚至自己训练模型，如果这是对你来说正确的路径的话。
- en: This chapter concludes what we consider the core prompt-engineering techniques.
    With a solid understanding of how LLMs work and how to make them work for you,
    you can now call yourself a proper prompt engineer! But what kind of prompt engineer
    would be satisfied with merely learning the basics? In the next chapters, we’ll
    discuss advanced techniques that use LLM—mere document completion models—as the
    central components of flexible agents and powerful workflow execution systems.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 本章总结了我们认为的核心提示工程技巧。在深入理解LLMs的工作原理以及如何让它们为你工作之后，你现在可以自称是一位真正的提示工程师了！但什么样的提示工程师会满足于仅仅学习基础知识呢？在接下来的章节中，我们将讨论使用LLM（仅作为灵活代理和强大工作流程执行系统的核心组件的文档完成模型）的高级技巧。
