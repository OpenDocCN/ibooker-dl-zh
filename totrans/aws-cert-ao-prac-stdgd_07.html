<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 6. Building with Amazon Bedrock and Amazon Q"><div class="chapter" id="chapter_six_building_with_amazon_bedroc">
<h1><span class="label">Chapter 6. </span>Building with Amazon <span class="keep-together">Bedrock and Amazon Q</span></h1>
<p>Amazon cofounder Jeff Bezos <a contenteditable="false" data-type="indexterm" data-primary="Bezos, Jeff" id="id1343"/>once <a href="https://oreil.ly/kxvps">said</a>, “We’re not competitor obsessed, we’re customer obsessed. We start with what the customer needs and we work backwards.” This guiding principle has helped make his company into a powerhouse of the digital age.</p>
<p>When generative AI surged in popularity, AWS first <a href="https://oreil.ly/_n5bS">talked extensively</a> with its customers and there were some consistent themes:</p>
<ul>
<li><p>Customers wanted an easy way to find and use FMs.</p></li>
<li><p>They needed seamless integration of FMs into their applications without managing complex infrastructure.</p></li>
<li><p>Costs had to remain low.</p></li>
<li><p>They wanted a simple way to customize FMs using their own data to fit unique business needs.</p></li>
<li><p>Data privacy and security were essential throughout the process.</p></li>
<li><p>Customers did not want their data to be used to train FMs for other companies.</p></li>
</ul>
<p>Based on this feedback, <a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="about" id="id1344"/>AWS initiated an ambitious program to create a sophisticated platform to build generative AI applications—which became known as Amazon Bedrock. It was announced as a preview edition in April 2023 and was made generally available in September 2023. For AWS, this was a strategically important effort, and speed was critical.</p>
<p class="pagebreak-before">In this chapter, we will get an overview of this powerful system. <a contenteditable="false" data-type="indexterm" data-primary="Amazon Q" data-secondary="about" id="id1345"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="Amazon Q" data-tertiary="about" id="id1346"/>We’ll also look at another important generative AI technology platform: Amazon Q, which is a virtual assistant for businesses and software developers. For the purposes of the exam, you will need to know the capabilities of each of these systems and how they are used.</p>
<section data-type="sect1" data-pdf-bookmark="Getting Started with Amazon Bedrock"><div class="sect1" id="getting_started_with_amazon_bedrock">
<h1>Getting Started with Amazon Bedrock</h1>
<p>To use Bedrock, <a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="getting started" id="c06strt"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="dashboard" id="c06dsh"/>you will need to log into AWS and then enter “Bedrock” in the search box at the top of the screen. When you click this, you will be taken to the dashboard, as shown in <a data-type="xref" href="#figure_six_onedot_bedrock_dashboard">Figure 6-1</a>.</p>
<figure><div id="figure_six_onedot_bedrock_dashboard" class="figure">
<img src="assets/awsc_0601.png" alt="" width="1884" height="819"/>
<h6><span class="label">Figure 6-1. </span>Bedrock dashboard</h6>
</div></figure>
<p>In the middle of the screen, you will see descriptions of the various generative AI services and announcements. You can also find the services on the left sidebar.<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="foundation models" data-tertiary="model catalog" id="id1347"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="Amazon Bedrock" data-tertiary="model catalog" id="id1348"/><a contenteditable="false" data-type="indexterm" data-primary="model catalog for FMs in Amazon Bedrock" id="id1349"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="foundation models" data-tertiary="model catalog in Amazon Bedrock" id="id1350"/><a contenteditable="false" data-type="indexterm" data-primary="catalog of FM models in Amazon Bedrock" id="id1351"/></p>
<p>Let’s use this to navigate to “Foundation models,” which has various options. Select “View Model catalog.” <a data-type="xref" href="#figure_six_twodot_bedrock_model_catalog">Figure 6-2</a> shows the screen for this.</p>




<p>There are 187 generative AI models available. <a contenteditable="false" data-type="indexterm" data-primary="serverless models in Amazon Bedrock" id="id1352"/><a contenteditable="false" data-type="indexterm" data-primary="serverless models in Amazon Bedrock" data-secondary="serverless explained" id="id1353"/>Of these, 51 are severless—meaning they automatically manage the underlying infrastructure, allowing users to run models without needing to provision or maintain servers. They are also seamlessly integrated into Bedrock. The rest of the models are in the Bedrock Marketplace. To use these, you will need to go through a process to subscribe to them.</p>


<p>On the left sidebar, there are filters to search for all the models. You can do this based on the following:<a contenteditable="false" data-type="indexterm" data-primary="embeddings" data-secondary="embedding models" id="id1354"/></p>
<dl>
<dt>Model provider</dt>
<dd><p>This is the company that created the model, such as Amazon, Anthropic, DeepSeek, Hugging Face, Meta, Mistral, or NVIDIA.</p></dd>
<dt>Modality</dt>
<dd><p>This describes the type of input and output for the model. The modalities include audio, image, text, vision, video, and multimodal. There are also embedding models, which create the vectors for using generative AI systems.</p></dd>
</dl>

<figure class="width-90"><div id="figure_six_twodot_bedrock_model_catalog" class="figure">
<img src="assets/awsc_0602.png" alt="" width="1244" height="708"/>
<h6><span class="label">Figure 6-2. </span>Bedrock Model catalog</h6>
</div></figure>

<p>When you use the filter options, you will see the results on the right side of the screen. Each model will have a brief description.</p>
<p>Let’s select Claude 3.7 Sonnet.<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="foundation models" data-tertiary="profiles of models" id="id1355"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="Amazon Bedrock" data-tertiary="profiles of models" id="id1356"/> <a data-type="xref" href="#figure_six_threedot_the_model_profile_f">Figure 6-3</a> shows the profile for the model.</p>
<figure><div id="figure_six_threedot_the_model_profile_f" class="figure">
<img src="assets/awsc_0603.png" alt="" width="1166" height="637"/>
<h6><span class="label">Figure 6-3. </span>The model profile for Claude 3.7 Sonnet</h6>
</div></figure>
<p>There are details like the version, modalities, release date, model ID, language, software license, and deployment type. <a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="foundation models" data-tertiary="sample code for API request" id="id1357"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="Amazon Bedrock" data-tertiary="sample code for API request" id="id1358"/>There is also sample code to make an API request. You can copy this and put it into the code of your program to make a connection to the model.</p>
<p>To use these models,<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="foundation models" data-tertiary="enabling model" id="id1359"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="Amazon Bedrock" data-tertiary="enabling model" id="id1360"/> go to the bottom of the left sidebar and click “Model access.” You can select either “Enable all models” or “Enable specific models.” Whichever you select, Bedrock will ask you to fill out a form. You will enter basic details like your company name and website URL, industry, the intended users (either internal employees or external users), and a description of your use case. Then you will click Submit. Depending on the model, it can take a few minutes to be activated. <a data-type="xref" href="#figure_six_fourdot_the_models_activated">Figure 6-4</a> shows an example of what you might see when the process is completed.</p>

<p>You are not charged for registering for the models. But you will pay a fee when you use them.<a contenteditable="false" data-type="indexterm" data-primary="costs" data-secondary="Bedrock foundation models" id="id1361"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="foundation models" data-tertiary="fee for using" id="id1362"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="Amazon Bedrock" data-tertiary="fee for using" id="id1363"/></p>
<p>You can test your models<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="playground for text-based models" id="c06play"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="Amazon Bedrock" data-tertiary="playground for text-based models" id="c06play2"/><a contenteditable="false" data-type="indexterm" data-primary="playground in Amazon Bedrock" data-secondary="text-based models" id="c06play3"/> by using the playground, which you can find on the left sidebar. There are two options: Chat/Text and Image/Video. We’ll cover these options in the following sections.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06strt" id="id1364"/></p>

<figure><div id="figure_six_fourdot_the_models_activated" class="figure">
<img src="assets/awsc_0604.png" alt="" width="1128" height="716"/>
<h6><span class="label">Figure 6-4. </span>The models activated in Bedrock</h6>
</div></figure>

<section data-type="sect2" class="pagebreak-before" data-pdf-bookmark="Chat/Text Playground"><div class="sect2" id="chat_solidus_text_playground">
<h2 class="less_space">Chat/Text Playground</h2>
<p>The Chat/Text playground is for using text-based models (see <a data-type="xref" href="#figure_six_fivedot_the_dashboard_for_th">Figure 6-5</a>). There are various settings:</p>

<dl>
<dt>Mode</dt>
<dd><p>There is Chat, which allows for an ongoing conversation with the FM. The other option is a single prompt, which will generate one response.</p></dd>
<dt>Select model</dt>
<dd><p>You will click this to get a screen to choose a model. At the top, you can search for the model. You can also use the three-step process. First, you will select the model provider and then the model. Finally, there are options for inference, which is how the model generates responses. Select “On-demand,” which is the most basic approach.</p></dd>
</dl>


<figure><div id="figure_six_fivedot_the_dashboard_for_th" class="figure">
<img src="assets/awsc_0605.png" alt="" width="1317" height="670"/>
<h6><span class="label">Figure 6-5. </span>The dashboard for the text-based models in Bedrock</h6>
</div></figure>

<p><a data-type="xref" href="#figure_six_sixdot_selecting_a_model_in">Figure 6-6</a> shows the screen you will see when selecting a model.</p>

<figure class="width-90"><div id="figure_six_sixdot_selecting_a_model_in" class="figure">
<img src="assets/awsc_0606.png" alt="" width="1199" height="839"/>
<h6><span class="label">Figure 6-6. </span>Selecting a model in Bedrock</h6>
</div></figure>
<p>After you select the model, the screen will have a configurations section on the sidebar, as shown in <a data-type="xref" href="#figure_six_sevendot_the_configurations">Figure 6-7</a>.</p>
<figure class="width-60"><div id="figure_six_sevendot_the_configurations" class="figure">
<img src="assets/awsc_0607.png" alt="" width="650" height="547"/>
<h6><span class="label">Figure 6-7. </span>The configurations section for a model in Bedrock</h6>
</div></figure>
<p>Some of the common configuration options include Temperature, Top P, Top K, Response length, Stop sequences, and Guardrails. Let’s dive into these configuration options in the following sections.</p>
<section data-type="sect3" data-pdf-bookmark="Temperature"><div class="sect3" id="temperature">
<h3>Temperature</h3>
<p>The temperature sets <a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="playground for text-based models" data-tertiary="temperature" id="id1365"/><a contenteditable="false" data-type="indexterm" data-primary="playground in Amazon Bedrock" data-secondary="text-based models" data-tertiary="temperature" id="id1366"/><a contenteditable="false" data-type="indexterm" data-primary="temperature" id="id1367"/><a contenteditable="false" data-type="indexterm" data-primary="probability distribution" data-secondary="temperature" id="id1368"/>the randomness or creativity of the responses from the FM. The range is from 0 to 1, which represents a probability distribution. The closer it is to 0, the more deterministic and predictable the responses will be. This is typically best when you want content that is more fact-based, such as FAQs, summarizations, or instructions.</p>
<p>The higher the temperature, the higher the probability that the responses will be more random or creative. This can be useful for brainstorming and creative writing.</p>
<p>Temperatures will vary based on the model. For example, the value of 0.6 will likely have different types of responses for an OpenAI model versus one from Meta.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Top P"><div class="sect3" id="top_p">
<h3>Top P</h3>
<p>Top P is also called <em>nucleus sampling</em> or <em>top probability sampling</em>.<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="playground for text-based models" data-tertiary="Top P" id="id1369"/><a contenteditable="false" data-type="indexterm" data-primary="Top P" id="id1370"/><a contenteditable="false" data-type="indexterm" data-primary="playground in Amazon Bedrock" data-secondary="text-based models" data-tertiary="Top P" id="id1371"/><a contenteditable="false" data-type="indexterm" data-primary="nucleus sampling" id="id1372"/><a contenteditable="false" data-type="indexterm" data-primary="top probability sampling" id="id1373"/> It selects the next word in an FM response that is based on a cumulative probability threshold. To understand this, let’s look at an example. Suppose an FM is generating this response:</p>
<blockquote>
<p>The dog wagged its</p>
</blockquote>
<p>The model will calculate a probability distribution for the next word. This includes:<a contenteditable="false" data-type="indexterm" data-primary="probability distribution" data-secondary="Top P" id="id1374"/></p>
<ul class="list_style_type_none">
<li><p>“tail”: 50%</p></li>
<li><p>“paw”: 20%</p></li>
<li><p>“ears”: 15%</p></li>
<li><p>“tongue”: 10%</p></li>
<li><p>“whiskers”: 5%</p></li>
</ul>
<p>If Top P is set to 0.5, then the only response will be “tail.” The reason is that the model will look for the smallest set of words whose cumulative probability is greater than or equal to 0.50.</p>
<p>But suppose we set Top P to 0.9. We would include “tail,” “paw,” and “ears,” which would total 0.85. But “tongue” will be excluded because the cumulative probability would be 0.95.</p>
<p>From the pool of available words, the FM will randomly make a choice. In other words, the higher the Top P, the more diverse or creative the responses will be.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Top K"><div class="sect3" id="top_k">
<h3>Top K</h3>
<p>Top K limits the <a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="playground for text-based models" data-tertiary="Top K" id="id1375"/><a contenteditable="false" data-type="indexterm" data-primary="playground in Amazon Bedrock" data-secondary="text-based models" data-tertiary="Top K" id="id1376"/><a contenteditable="false" data-type="indexterm" data-primary="Top K" id="id1377"/>number of token choices the model will consider when generating the next word in a response. This is another way to control the randomness or diversity of the content. With Top K, the FM will consider the K most likely words.</p>
<p>Here’s an example. Suppose the FM is generating this response:</p>
<blockquote>
<p>The best way to learn programming is</p>
</blockquote>
<p>This is the probability distribution for the next word:<a contenteditable="false" data-type="indexterm" data-primary="probability distribution" data-secondary="Top K" id="id1378"/></p>
<ul class="list_style_type_none">
<li><p>“practice”: 35%</p></li>
<li><p>“by”: 20%</p></li>
<li><p>“through”: 15%</p></li>
<li><p>“with”: 10%</p></li>
<li><p>“using”: 8%</p></li>
<li><p>“via”: 7%</p></li>
<li><p>“reading”: 5%</p></li>
</ul>
<p>If we have the Top K set to 2, then the words selected would be “practice” and “by.” The reason is that they are the two most likely words.</p>
<p>So yes, if Top K is set to 4, then we would have “practice,” “by,” “through,” and “with.” As the value increases, so will the randomness and diversity of the output.</p>
<p>When working with Temperature, Top P, and Top K, you will need to experiment with the values. The process is mostly trial and error.</p>
<p>However, if you set values for Temperature, Top P and Top Q for an FM, they will interact with each other. Often, this can lead to unexpected results. This is why it is better to set only one or two parameters. Generally, it’s recommended to use either Temperature or Top P, but not both. As for Top K, it can best be used with either Temperature or Top P.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Response length"><div class="sect3" id="response_length">
<h3>Response length</h3>
<p>The “Response length” is a <a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="playground for text-based models" data-tertiary="response length" id="id1379"/><a contenteditable="false" data-type="indexterm" data-primary="playground in Amazon Bedrock" data-secondary="text-based models" data-tertiary="response length" id="id1380"/><a contenteditable="false" data-type="indexterm" data-primary="responses" data-secondary="response length" id="id1381"/>way to control the size of the generated response from the FM. Depending on a model, it can be a minimum or maximum value. The values may vary depending on the model.</p>
<p>Regardless, the response length can be a good way to provide more conciseness to a response. This can be useful for chat responses and summarization.</p>
<p>But of course, if the response length is small, important content may be truncated.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Stop sequences"><div class="sect3" id="stop_sequences">
<h3>Stop sequences</h3>
<p>“Stop sequences” allow you<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="playground for text-based models" data-tertiary="stop sequences" id="id1382"/><a contenteditable="false" data-type="indexterm" data-primary="playground in Amazon Bedrock" data-secondary="text-based models" data-tertiary="stop sequences" id="id1383"/><a contenteditable="false" data-type="indexterm" data-primary="stop sequences" id="id1384"/> to control when an FM stops generating a response. These are specific words, phrases, or punctuation marks that signal the model to end its output.</p>
<p>For example, suppose you’re building a system that generates JSON objects. You only want the model to output up to the end of the JSON structure. You could use a stop sequence like “}” to make sure the response ends once the closing brace is reached.</p>
<p>Using stop sequences alongside a maximum token limit can provide greater control over both the content and length of the response.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Guardrails"><div class="sect3" id="guardrails">
<h3>Guardrails</h3>
<p>With guardrails in AWS Bedrock,<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="Guardrails" id="id1385"/><a contenteditable="false" data-type="indexterm" data-primary="Guardrails in Amazon Bedrock" id="id1386"/> you can create safeguards that help enforce responsible AI practices and ensure your generative AI applications align with your organization’s values and compliance requirements. These guardrails act as content moderation layers, analyzing both the prompts sent to the FM and the responses generated.</p>
<p>They allow you to define use-case-specific protections—whether you’re building a customer service chatbot, a document summarization tool, or any other generative AI application.</p>
<p>Here are key capabilities for guardrails:<a contenteditable="false" data-type="indexterm" data-primary="content delivery" data-secondary="Guardrails in Amazon Bedrock" id="id1387"/><a contenteditable="false" data-type="indexterm" data-primary="privacy" data-secondary="Guardrails in Amazon Bedrock" id="id1388"/></p>
<dl>
<dt>Content filtering</dt>
<dd><p>You can filter out toxic, adult, or hostile content to maintain brand safety and user trust. This helps prevent inappropriate or offensive language from being included in either the user input or the model’s output.</p></dd>
<dt>Sensitive information protection</dt>
<dd><p>Guardrails can identify and block outputs that include personal data, financial identifiers, or other forms of confidential information. This is important for industries like healthcare and finance.</p></dd>
<dt>Multilingual support</dt>
<dd><p>Currently, Bedrock guardrails support English, French, and Spanish, allowing broader coverage for global applications.</p></dd>
<dt>Prompt and response protection</dt>
<dd><p>Guardrails apply to both user prompts and model responses, ensuring two-way protection.</p></dd>
</dl>
<p>When you create a guardrail, there’s no limit to the number of filters you can apply. This enables organizations to tailor protections based on specific regulatory, ethical, or operational requirements.</p>
<p>AWS also provides<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="Guardrails" data-tertiary="testing environment for" id="id1389"/><a contenteditable="false" data-type="indexterm" data-primary="Guardrails in Amazon Bedrock" data-secondary="testing environment for" id="id1390"/> a testing environment, so you can simulate different inputs and see how your guardrail behaves before deploying it into production. This helps you fine-tune your filters and avoid unintended model blocking or leakage of sensitive information.</p>
<p>Let’s take an example of the use of guardrails. Suppose you’re building a legal advice assistant using an FM on Bedrock. You can configure a guardrail that blocks prompts or responses mentioning personal identifiers like Social Security numbers or legal threats. You could also add filters to ensure the assistant doesn’t engage in offensive or overly aggressive language, even if prompted by the user.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06dsh" id="id1391"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06play" id="id1392"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06play2" id="id1393"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06play3" id="id1394"/></p>
</div></section>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Interacting with the FM"><div class="sect2" id="interacting_with_the_fm">
<h2>Interacting with the FM</h2>
<p>Once you have configured the FM<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="foundation models" data-tertiary="interacting with" id="id1395"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="Amazon Bedrock" data-tertiary="interacting with FM" id="id1396"/><a contenteditable="false" data-type="indexterm" data-primary="playground in Amazon Bedrock" data-secondary="interacting with foundation model" id="id1397"/> for the Chat/Text playground, you can then start interacting with it. Suppose you enter the following prompt:</p>
<blockquote>
<p>What is generative AI?</p>
</blockquote>
<p>You can press Enter or Run. You can also select the icon—which has two arrows—that will expand the input box. If you want to add a space, you can press Shift+Enter.</p>
<p><a data-type="xref" href="#figure_six_eightdot_the_response_of_an">Figure 6-8</a> shows part of the response.</p>
<figure><div id="figure_six_eightdot_the_response_of_an" class="figure">
<img src="assets/awsc_0608.png" alt="" width="1094" height="619"/>
<h6><span class="label">Figure 6-8. </span>The response of an LLM in Bedrock</h6>
</div></figure>
<p>There is a paragraph description of generative AI. At the top, there are metrics on the response. The Input has 9 tokens, the Output has 96 tokens, and the Latency—the time it takes for the model to generate a response—is 4,583 milliseconds. There are two icons alongside these. One is to clear the chat and the other is to copy the content.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Image/Video Playground"><div class="sect2" id="imagesolidusvideo_playground">
<h2>Image/Video Playground</h2>
<p>With the Image/Video playground,<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="playground for image and video models" id="c06plimg"/><a contenteditable="false" data-type="indexterm" data-primary="playground in Amazon Bedrock" data-secondary="image and video models" id="c06plimg2"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="Amazon Bedrock" data-tertiary="playground for image and video models" id="c06plimg3"/> you can use natural language to create images and videos. <a data-type="xref" href="#figure_six_ninedot_the_dashboard_for_th">Figure 6-9</a> shows the dashboard.</p>
<figure><div id="figure_six_ninedot_the_dashboard_for_th" class="figure">
<img src="assets/awsc_0609.png" alt="" width="908" height="708"/>
<h6><span class="label">Figure 6-9. </span>The dashboard for the Image/Video playground</h6>
</div></figure>
<p>On the top left, you can select the model: Amazon, Luma AI, or Stability AI. You can also select for the inference, whether for on-demand or provisioned throughput. These options work the same way we saw when using the Chat/Text playground.</p>
<p>After you select a model, the configuration section will appear on the left side of the screen. One option is called Action. This includes a variety of ways for generating the image or video:</p>
<dl>
<dt>Generate image</dt>
<dd><p>Create a new image based on your prompt.</p></dd>
<dt>Generate variations</dt>
<dd><p>Create a new image similar to a reference image you uploaded. The file formats supported include <em>.png</em> and <em>.jpeg</em>. The maximum image size is 24 MB.</p></dd>
<dt>Remove object</dt>
<dd><p>Remove a specific object from an image you uploaded.</p></dd>
<dt>Replace background</dt>
<dd><p>You can change the background of an image while keeping the main theme intact.</p></dd>
<dt>Replace object</dt>
<dd><p>Swap out one object in an image for another.</p></dd>
<dt>Generate video</dt>
<dd><p>Create a short video clip based on your prompt and starting image, which is optional.</p></dd>
</dl>
<section data-type="sect3" data-pdf-bookmark="Negative prompt"><div class="sect3" id="negative_prompt">
<h3>Negative prompt</h3>
<p>The next configuration <a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="playground for image and video models" data-tertiary="negative prompt" id="id1398"/><a contenteditable="false" data-type="indexterm" data-primary="playground in Amazon Bedrock" data-secondary="image and video models" data-tertiary="negative prompt" id="id1399"/>option is “Negative prompt.” This allows you to indicate certain elements of an image or video you do not want to appear. <a data-type="xref" href="#table_six_onedot_examples_of_negative_p">Table 6-1</a> shows some examples.</p>
<table class="border" id="table_six_onedot_examples_of_negative_p">
<caption><span class="label">Table 6-1. </span>Examples of negative prompts</caption>
<thead>
<tr>
<td>Hide faces</td>
<td>Distorted faces blurry</td>
</tr>
</thead>
<tbody>
<tr>
<td>Style control</td>
<td>Cartoon</td>
</tr>
<tr>
<td>Colors</td>
<td>Sepia, neon colors</td>
</tr>
<tr>
<td>Unwanted composition elements</td>
<td>Busy background</td>
</tr>
<tr>
<td>Texture</td>
<td>Shiny surfaces, rough textures</td>
</tr>
<tr>
<td>Lighting atmosphere</td>
<td>Foggy</td>
</tr>
</tbody>
</table>
<p>You can also use multiple negative prompts. An example is: blurry, cartoon, cluttered background.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Response image"><div class="sect3" id="response_image">
<h3>Response image</h3>
<p>Then there is the “Response image” configuration.<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="playground for image and video models" data-tertiary="response image" id="id1400"/><a contenteditable="false" data-type="indexterm" data-primary="playground in Amazon Bedrock" data-secondary="image and video models" data-tertiary="response image" id="id1401"/><a contenteditable="false" data-type="indexterm" data-primary="responses" data-secondary="response image" id="id1402"/> You can set the dimensions of the image, as well as the number of images to be generated. You can have up to 5.</p>
</div></section>
<section data-type="sect3" data-pdf-bookmark="Advanced configuration"><div class="sect3" id="advanced_configuration">
<h3>Advanced configuration</h3>
<p>Finally, there are two advanced configuration options: one for “Prompt strength” and one for Seed.</p>
<section data-type="sect4" data-pdf-bookmark="Prompt strength"><div class="sect4" id="prompt_strength">
<h4>Prompt strength</h4>
<p>Prompt strength <a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="playground for image and video models" data-tertiary="prompt strength" id="id1403"/><a contenteditable="false" data-type="indexterm" data-primary="playground in Amazon Bedrock" data-secondary="image and video models" data-tertiary="prompt strength" id="id1404"/> indicates how the generated image will adhere to your prompt. It’s a value between 1 and 10.</p>
<p class="pagebreak-before">These are the ranges:</p>
<ul>
<li><p>1–3: allows for more creativity</p></li>
<li><p>4–7: a balance between creativity and adhering closely to the prompt</p></li>
<li><p>8–0: keeps the image mostly focused on the requirements of the prompt</p></li>
</ul>
</div></section>
<section data-type="sect4" data-pdf-bookmark="Seed"><div class="sect4" id="seed">
<h4>Seed</h4>
<p>Seed <a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="playground for image and video models" data-tertiary="seed" id="id1405"/><a contenteditable="false" data-type="indexterm" data-primary="playground in Amazon Bedrock" data-secondary="image and video models" data-tertiary="seed" id="id1406"/> is the value for the random number generator. This is the starting value used to set the initial state. What this means is that when you use the same seed, you will get the same output. This means you can create variations of the image using different seeds while keeping the other configurations the same. This helps to evaluate different images without them being widely different from the core idea.</p>
<p>Let’s select the Stable Image Core 1.0 model and use this prompt:</p>
<blockquote>
<p>A serene mountain lake at sunset, with snow-capped peaks reflected in the calm water. Warm golden light, wispy clouds in the sky.</p>
</blockquote>
<p><a data-type="xref" href="#figure_six_onezerodot_the_image_created">Figure 6-10</a> shows the image.</p>
<figure><div id="figure_six_onezerodot_the_image_created" class="figure">
<img src="assets/awsc_0610.png" alt="" width="1022" height="726"/>
<h6><span class="label">Figure 6-10. </span>The image created by Stable Image Core 1.0</h6>
</div></figure>
<p>At the top left of the screen, <a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="playground for image and video models" data-tertiary="exporting as zip file" id="id1407"/><a contenteditable="false" data-type="indexterm" data-primary="playground in Amazon Bedrock" data-secondary="image and video models" data-tertiary="exporting as zip file" id="id1408"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="playground for image and video models" data-tertiary="downloading as jpg file" id="id1409"/><a contenteditable="false" data-type="indexterm" data-primary="playground in Amazon Bedrock" data-secondary="image and video models" data-tertiary="downloading as jpg file" id="id1410"/>there is an icon—which has three vertical dots—where you can export the image as a zip file. There is also an icon, which is a down arrow, that downloads the image as a <em>.jpg</em> file format.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06plimg" id="id1411"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06plimg2" id="id1412"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06plimg3" id="id1413"/></p>
</div></section>
</div></section>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Choosing an FM"><div class="sect1" id="choosing_an_fm">
<h1>Choosing an FM</h1>
<p>When using Bedrock,<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="choosing a foundation model" id="c06choo"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="Amazon Bedrock" data-tertiary="choosing a foundation model" id="c06choo2"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="foundation models" data-tertiary="choosing a foundation model" id="c06choo3"/><a contenteditable="false" data-type="indexterm" data-primary="model catalog for FMs in Amazon Bedrock" data-secondary="choosing a foundation model" id="c06choo4"/><a contenteditable="false" data-type="indexterm" data-primary="catalog of FM models in Amazon Bedrock" data-secondary="choosing a foundation model" id="c06choo5"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="choosing a foundation model" id="c06choo6"/> the selection of an FM is a critical step, which involves evaluating a variety of factors. There is also no right answer, as the process will involve experimentation. When selecting a model, you should first consider the use case. You can use the “Model catalog” for this, which we learned about earlier in this chapter.</p>
<p>Then you can use Filters and focus on the modality that you will need for your application. This will help to narrow your search.</p>
<p>For example, suppose you want to select an image model. For this, there are nine options. Some of these will have the “Legacy” tag, which means they will be phased out at some point. Of course, you can ignore these. Then you can search the other models by reviewing the profiles.</p>
<p>Some of the factors to consider include:</p>
<dl>
<dt>Categories</dt>
<dd><p>These are the capabilities of the FM. Some can be limited, such as Titan Image Generator G1. It can do the following: text-to-image, image-to-image, background removal, and image conditioning. Stable Diffusion 3.5 Large, on the other hand, is much more robust, such as allowing for better scene layout, anime, and cartoons.</p></dd>
<dt>Last version</dt>
<dd><p>You should focus on the latest.</p></dd>
<dt>Language</dt>
<dd><p>This is the language you can write your prompts in.</p></dd>
<dt>Max tokens</dt>
<dd><p>This is the maximum number of tokens that the model will generate for a response, and these can vary widely. <a data-type="xref" href="#table_six_twodot_maximum_tokens_for_dif">Table 6-2</a> shows some examples.</p></dd>
</dl>
<table class="border" id="table_six_twodot_maximum_tokens_for_dif">
<caption><span class="label">Table 6-2. </span>Maximum tokens for different models</caption>
<thead>
<tr>
<th>Model</th>
<th>Maximum tokens</th>
</tr>
</thead>
<tbody>
<tr>
<td>Claude 3.7 Sonnet</td>
<td>200k</td>
</tr>
<tr>
<td>DeepSeek-R1</td>
<td>128k</td>
</tr>
<tr>
<td>Llama 3.3 70B Instruct</td>
<td>128k</td>
</tr>
<tr>
<td>Mistral Large 2 (24.07)</td>
<td>128k</td>
</tr>
<tr>
<td>Amazon Nova Micro</td>
<td>128k</td>
</tr>
</tbody>
</table>
<p>The software license can also be important. In the model profile, you will see a link to it at the bottom of the screen, labeled End User License Agreement (EULA). The EULA will either be open source or proprietary. This will determine whether and how you can use the models for your particular project. For example, an open source license may allow you to freely modify and distribute the model, while a proprietary license may restrict usage to internal development or require a commercial agreement. Understanding these terms helps ensure legal and compliant use of the model.</p>
<section data-type="sect2" data-pdf-bookmark="License Types"><div class="sect2" id="license_types">
<h2>License Types</h2>
<p>The three main types of open source licenses include:<a contenteditable="false" data-type="indexterm" data-primary="catalog of FM models in Amazon Bedrock" data-secondary="choosing a foundation model" data-tertiary="license types" id="c06lic"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="choosing a foundation model" data-tertiary="license types" id="c06lic2"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="choosing a foundation model" data-tertiary="license types" id="c06lic3"/><a contenteditable="false" data-type="indexterm" data-primary="open source license types" id="c06lic4"/><a contenteditable="false" data-type="indexterm" data-primary="model catalog for FMs in Amazon Bedrock" data-secondary="choosing a foundation model" data-tertiary="license types" id="c06lic5"/><a contenteditable="false" data-type="indexterm" data-primary="Apache 2.0 license" id="id1414"/><a contenteditable="false" data-type="indexterm" data-primary="MIT license" id="id1415"/><a contenteditable="false" data-type="indexterm" data-primary="GNU General Public License (GPL)" id="id1416"/></p>
<dl>
<dt>Apache 2.0</dt>
<dd><p>This is a permissive license that allows you to use, modify, and distribute software freely. There is also protection against patent litigation, but you need to provide the copyright notices in your application.</p></dd>
<dt>MIT license</dt>
<dd><p>This is similar to the Apache 2.0 license, with nearly unrestricted use of the software. However, you need to provide the copyright notices and include the license in the software.</p></dd>
<dt>GNU General Public License (GPL)</dt>
<dd><p>This is a copyleft license, which means that derivative works based on the software must abide by the terms of the license. This helps to maintain that the software will remain free. But some companies may not want to use this license because they may lose the intellectual property rights for their own code.</p></dd>
</dl>
<p>The use of these types of licenses has allowed for wide distribution of AI models. But there are other advantages:</p>
<dl>
<dt>Transparency</dt>
<dd><p>The developer can understand how a model generates responses, which can improve trust. It can also make it easier for an organization to evaluate the model for compliance, ethics, and regulatory requirements.</p></dd>
<dt>Innovation</dt>
<dd><p>Some models have thriving global communities of developers and data scientists. This means that the systems can benefit from their innovative modifications and enhancements.</p></dd>
<dt>Customization</dt>
<dd><p>By having access to the code, you can build your own version of the AI model for particular needs.</p></dd>
</dl>
<p>Some AI model developers will have their own licenses. An example is Meta.<a contenteditable="false" data-type="indexterm" data-primary="Llama Community License Agreement" id="id1417"/> For its Llama models, it uses the Llama Community License Agreement, which is more restrictive than those licenses mentioned earlier:</p>
<ul>
<li><p>If your application has more than 700 million monthly active users, you must obtain a separate license from Meta.</p></li>
<li><p>You cannot use Llama to create competing LLMs.</p></li>
<li><p>Derivative works created from Llama must adhere to the same Llama Community License.</p></li>
</ul>
<p>Interestingly enough, there is considerable debate about these types of licenses. Are they true open source or somewhat open source? According to the <a href="https://oreil.ly/zdBtp">Free Software Foundation (FSF)</a>, the answer is no. The organization considers the license to be too restrictive.</p>
<p>In the case of Meta, FSF also says that the company has not provided enough transparency. The reason is that it does not disclose the parameters of the model as well as the training data.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06lic" id="id1418"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06lic2" id="id1419"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06lic3" id="id1420"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06lic4" id="id1421"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06lic5" id="id1422"/></p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="FM Response Analysis"><div class="sect2" id="fm_response_analysis">
<h2>FM Response Analysis</h2>
<p>When selecting a model<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="choosing a foundation model" data-tertiary="FM response analysis" id="id1423"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="choosing a foundation model" data-tertiary="FM response analysis" id="id1424"/><a contenteditable="false" data-type="indexterm" data-primary="catalog of FM models in Amazon Bedrock" data-secondary="choosing a foundation model" data-tertiary="FM response analysis" id="id1425"/><a contenteditable="false" data-type="indexterm" data-primary="model catalog for FMs in Amazon Bedrock" data-secondary="choosing a foundation model" data-tertiary="FM response analysis" id="id1426"/><a contenteditable="false" data-type="indexterm" data-primary="prompts" data-secondary="response analysis for choosing FM" id="id1427"/><a contenteditable="false" data-type="indexterm" data-primary="responses" data-secondary="response analysis for choosing FM" id="id1428"/> for building an application, a helpful approach is to come up with a list of expected prompts from users, which are based on your use case. For example, suppose you are building a chatbot for human resources (HR). You will have subject matter experts (SMEs) in your organization who will come up with typical scenarios and write prompts for them. Here are a few examples:</p>
<blockquote>
<p>HR policies: “I want to take a vacation for the December holiday. What are the steps I need to take for this leave and who do I inform?”</p>
<p>Benefits: “What are the health insurance options available? What are the eligibility requirements? How do I enroll in a plan?”</p>
<p>Job description creation: “Create a detailed job description for a data engineer. Include key responsibilities, required qualifications, and preferred skills.”</p>
<p>Employee reviews: “What are the best practices for employee reviews?”</p>
<p>Onboarding: “Create an onboarding checklist.”</p>
</blockquote>
<p>No doubt, this process can be time-consuming. Yet it is critical to make an effective generative AI application that will have a positive impact.</p>
<p>The prompts in our example are also in two main categories. The first two are based on corporate data, while the last three are generic. This means you will need to customize the FM. You can do this with fine-tuning or RAG. We learned about these topics in <a data-type="xref" href="ch02.html#chapter_two_aws_fundamentals_for_the_ai">Chapter 2</a>, and we will discuss this more later in this chapter.</p>
<p>As for the generic prompts,<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="playground for text-based models" data-tertiary="response analysis for choosing FM" id="id1429"/><a contenteditable="false" data-type="indexterm" data-primary="playground in Amazon Bedrock" data-secondary="text-based models" data-tertiary="response analysis for choosing FM" id="id1430"/> you can use the Bedrock playground for testing different models. Let’s see how you can do this:<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06choo" id="id1431"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06choo2" id="id1432"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06choo3" id="id1433"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06choo4" id="id1434"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06choo5" id="id1435"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06choo6" id="id1436"/></p>
<ol>
<li><p>In the Bedrock console, select Chat/Text.</p></li>
<li><p>Set the Mode to Chat.</p></li>
<li><p>Turn on “Compare mode.” <a data-type="xref" href="#figure_six_oneonedot_the_quotation_mark">Figure 6-11</a> shows the updated screen, which allows you to select two models.</p>
<figure><div id="figure_six_oneonedot_the_quotation_mark" class="figure">
<img src="assets/awsc_0611.png" alt="The “Compare mode” option for Bedrock" width="1003" height="722"/>
<h6><span class="label">Figure 6-11. </span>The “Compare mode” option for Bedrock</h6>
</div></figure>
</li>
<li><p>For the first model, select Amazon and then choose Titan Text G1 - Premier v1. Then click Apply.</p></li>
<li><p>For the next model, select Meta and choose Llama 3 8B Instruct. Then click Apply.</p></li>
<li><p>Enter this in the input box: “Create an onboarding checklist”.</p></li>
<li><p>You will see a response for both of them, which you can compare.</p></li>
</ol>
</div></section>
</div></section>
<section data-type="sect1" class="pagebreak-before" data-pdf-bookmark="Measuring Success: Business Goals and Metrics"><div class="sect1" id="measuring_success_business_goals_and_me">
<h1 class="less_space">Measuring Success: Business Goals and Metrics</h1>
<p>While generative AI is a powerful technology,<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="business goals and metrics" id="c06goal"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="business goals and metrics" id="c06goal2"/><a contenteditable="false" data-type="indexterm" data-primary="business goals and metrics" id="c06goal3"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="business goals and metrics" data-tertiary="about" id="id1437"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="business goals and metrics" data-tertiary="about" id="id1438"/><a contenteditable="false" data-type="indexterm" data-primary="business goals and metrics" data-secondary="about" id="id1439"/> it can be difficult to implement. One reason is the lack of clear-cut business goals and metrics. This is the case for two-thirds of C-suite executives, according to a survey from the Boston Consulting Group.<sup><a data-type="noteref" id="ch01fn25-marker" href="ch06.html#ch01fn25">1</a></sup> A study from the Everest Group had a similar finding.</p>
<p>True, it can be difficult to come up with goals and metrics for a dynamic and complex technology. <a contenteditable="false" data-type="indexterm" data-primary="exam for AIF-C01" data-secondary="topics covered" data-tertiary="business goals and metrics" id="id1440"/><a contenteditable="false" data-type="indexterm" data-primary="topics covered in exam for AIF-C01" data-secondary="business goals and metrics" id="id1441"/>But there are some general approaches to consider, which are recommended by the AWS certification:</p>
<ul>
<li><p>User satisfaction</p></li>
<li><p>Average revenue per user (ARPU)</p></li>
<li><p>Conversion rate</p></li>
<li><p>Efficiency</p></li>
</ul>
<p>Let’s unpack these in the following sections.</p>
<section data-type="sect2" data-pdf-bookmark="User Satisfaction"><div class="sect2" id="user_satisfaction">
<h2>User Satisfaction</h2>
<dl>
<dt>Customer Satisfaction Score (CSAT)</dt>
<dd><p>CSAT measures user satisfaction based on a scale, such as 1 to 5.</p></dd>
<dt>Net Promoter Score (NPS)</dt>
<dd><p>NPS evaluates whether a user is likely to recommend a product or service to users. This is on a scale of 0 to 10. The higher the score, the higher the user satisfaction.</p></dd>
</dl>
<p>Another approach to measuring user satisfaction is to use an AI service, like Amazon Comprehend.<a contenteditable="false" data-type="indexterm" data-primary="Amazon Comprehend" data-secondary="user satisfaction measure" id="id1442"/><a contenteditable="false" data-type="indexterm" data-primary="natural language processing (NLP)" data-secondary="user satisfaction measured via Comprehend" id="id1443"/><a contenteditable="false" data-type="indexterm" data-primary="feedback extraction" id="id1444"/> This will use NLP to extract insights from user feedback, such as from online forms or thumbs-up/thumbs-down icons in an application. The system can categorize the information in terms of positive, negative, neutral, and mixed levels.</p>
<p>With these user satisfaction metrics, you can create baseline scores to measure against. However, they should be realistic and reviewed periodically to understand the impact of the generative AI application.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Average Revenue per User"><div class="sect2" id="average_revenue_per_user_left_parenthes">
<h2>Average Revenue per User</h2>
<p>Average revenue per user (ARPU) <a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="business goals and metrics" data-tertiary="average revenue per user" id="id1445"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="business goals and metrics" data-tertiary="average revenue per user" id="id1446"/><a contenteditable="false" data-type="indexterm" data-primary="average revenue per user (ARPU)" id="id1447"/>measures revenue per user for a period of time, say monthly or annually. This metric is common for businesses that charge subscriptions, such as for SaaS software or telecommunications services. It can also be useful for ecommerce.</p>
<p>Even a small increase in ARPU can have a notable impact on a company’s bottom line. Suppose an online service has 10,000 customers and the current ARPU is $50 per month ($500,000) in monthly revenue. Let’s say the company implements generative AI features that greatly improve the service. For this, the price is increased by 10% to $55. Even without adding any new members, the company will add $600,000 in annual revenue.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Conversion Rate"><div class="sect2" id="conversion_rate">
<h2>Conversion Rate</h2>
<p>The conversion rate measures<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="business goals and metrics" data-tertiary="conversion rate" id="id1448"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="business goals and metrics" data-tertiary="conversion rate" id="id1449"/><a contenteditable="false" data-type="indexterm" data-primary="business goals and metrics" data-secondary="conversion rate" id="id1450"/><a contenteditable="false" data-type="indexterm" data-primary="conversion rate" id="id1451"/> the rate at which a user takes an action online, such as to make a purchase, fill out a form, or sign up for a newsletter. However, this is generally low. For an ecommerce website, the average conversion rate is <a href="https://oreil.ly/VJa7t">2.8% on desktops and mobile devices</a>. It’s even worse with social media, which is at <a href="https://oreil.ly/_oUTg">about 1%</a>.</p>
<p>Meanwhile, the costs of online advertising have been rising. During certain periods of times—like Black Friday—they can be exorbitant, as the bidding on keywords is intense. This is why the conversion rate is so important. A minimal increase can mean the difference of sustaining a loss and generating a profit.</p>
<p>There are various ways generative AI can help out:</p>
<dl>
<dt>Optimized content</dt>
<dd><p>The generative AI can create ads that are engaging and based on customer preferences, segments, and purchase history. They can also be improved for search engine optimization (SEO). This means the ads will have a higher likelihood of showing up as top results.</p></dd>
<dt>Search</dt>
<dd><p>This can go beyond the typical keyword methods. Generative AI can analyze the natural language for intent, which will provide more relevant results. An example is the search system on <a href="http://walmart.com"><em>Walmart.com</em></a>. You can ask questions like “Help me plan a football watch party” or “What supplies do I need for a newborn?” The generative AI will generate recommendations that are highly pertinent, which helps to increase the conversion rate.</p></dd>
<dt>Dynamic pricing</dt>
<dd><p>In real time, generative AI can process the demand, competition, and customer behavior. Based on this, it can adjust prices to optimize the conversion rates.</p></dd>
<dt>Automated A/B testing</dt>
<dd><p>This is where you compare the conversion rates for two versions of a website, where there will be one element changed. This could be the layout, call to action, or the content. Generative AI can manage the A/B testing in real time, processing substantial amounts of data.</p></dd>
</dl>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Efficiency"><div class="sect2" id="efficiency">
<h2>Efficiency</h2>
<p>You can use efficiency metrics<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="business goals and metrics" data-tertiary="efficiency" id="id1452"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="business goals and metrics" data-tertiary="efficiency" id="id1453"/><a contenteditable="false" data-type="indexterm" data-primary="business goals and metrics" data-secondary="efficiency" id="id1454"/><a contenteditable="false" data-type="indexterm" data-primary="efficiency metrics" id="id1455"/> when evaluating the underlying model for a generative AI application. These metrics help measure how well the system performs in terms of speed, responsiveness, and resource consumption. For example, latency is a key metric. High latency can lead to a poor user experience, especially in use cases like chatbots, gaming, and live streaming, where users expect real-time or near-instant feedback. Other metrics might include throughput (how many requests the system can handle per second) and memory usage, which affect scalability and performance.</p>
<p>Another important consideration<a contenteditable="false" data-type="indexterm" data-primary="GPUs (Graphics Processing Units)" data-secondary="resource allocation in choosing FM" id="id1456"/><a contenteditable="false" data-type="indexterm" data-primary="scalability" data-secondary="resource costs while scaling up AI" id="id1457"/><a contenteditable="false" data-type="indexterm" data-primary="costs" data-secondary="resource costs while scaling up AI" id="id1458"/> is resource allocation, which refers to how computational resources such as GPUs, CPUs, memory, and storage are used. Generative AI models can be highly resource-intensive, particularly during inference and training. As an application scales to serve more users, the cost of these resources can increase significantly. Efficient use of infrastructure—such as autoscaling, choosing the right model size, and optimizing inference—can help control these costs while maintaining performance. Monitoring and optimizing these aspects is critical for both user satisfaction and cost-effectiveness.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06goal" id="id1459"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06goal2" id="id1460"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06goal3" id="id1461"/></p>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Model Customization"><div class="sect1" id="model_customization">
<h1>Model Customization</h1>
<p>Bedrock allows you to customize<a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="Amazon Bedrock" data-tertiary="customization of model" id="c06cust"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="customization of model" id="c06cust2"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="customization of model" data-tertiary="about" id="id1462"/> a generative AI model. While this system streamlines the process, it is still complicated. You will need to have a strong background in data science.</p>
<p>But for the exam, you need to know about the key features of model customization. There are several ways to do this: distillation, fine-tuning, and continued pretraining.</p>
<section data-type="sect2" data-pdf-bookmark="Distillation"><div class="sect2" id="distillation">
<h2>Distillation</h2>
<p>Distillation is where you<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="customization of model" data-tertiary="distillation" id="id1463"/><a contenteditable="false" data-type="indexterm" data-primary="distillation" id="id1464"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="distillation" id="id1465"/> transfer knowledge from a more sophisticated model—called a teacher—to a smaller one, which is usually faster and lower cost. This is called the student.</p>
<p>When using Bedrock for distillation, you will select the models and then provide relevant prompts for the input data. This can be either unstructured information or labeled data. Bedrock will then generate responses using the teacher model, which will then be fine-tuned by the student model.</p>
<p class="pagebreak-before">Here are some of the advantages of distillation:</p>
<dl>
<dt>Efficiency</dt>
<dd><p>The models tend to use less compute power, which can translate into lower costs and faster response times.</p></dd>
<dt>Edge</dt>
<dd><p>Since distilled models are smaller, they can be used in constrained environments, like with mobile devices and Internet of Things (IoT) systems.</p></dd>
</dl>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Fine-Tuning"><div class="sect2" id="fine_tuning-id000027">
<h2>Fine-Tuning</h2>
<p>Fine-tuning with Bedrock allows<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="customization of model" data-tertiary="fine-tuning" id="id1466"/><a contenteditable="false" data-type="indexterm" data-primary="fine-tuning" data-secondary="customization of model in Bedrock" id="id1467"/> for pretraining an FM for specific, labeled data. This means that the model’s parameters can be adjusted, which will allow for more accurate and relevant responses. For example, you can fine-tune an FM for information about customer support interactions, such as tickets, feedback, Slacks, and call <span class="keep-together">transcripts.</span></p>
<p>To implement this in Bedrock, you will need to prepare the dataset by creating input-output pairs. For customer support, you could have the types of data in JSON format, shown in <a data-type="xref" href="#figure_six_onetwodot_the_preparation_of">Figure 6-12</a>.</p>
<figure><div id="figure_six_onetwodot_the_preparation_of" class="figure">
<img src="assets/awsc_0612.png" alt="" width="1337" height="879"/>
<h6><span class="label">Figure 6-12. </span>The preparation of a dataset for Bedrock</h6>
</div></figure>
<p class="pagebreak-before">Each training example consists of a customer query as the input prompt (such as “How do I reset my password?” or “What is the return policy?”) paired with an appropriate support agent response as the completion output. By providing this type of structured data, you are essentially allowing the FM to learn the patterns and appropriate responses for common customer support scenarios.</p>
<p>When the dataset is completed, you will upload it to Amazon S3, and then you will specify the hyperparameters in Bedrock. These are external configuration settings set before the training begins. These are examples of hyperparameters:</p>
<dl>
<dt>Learning rate</dt>
<dd><p>Controls the step size for each iteration in the optimization process</p></dd>
<dt>Epoch</dt>
<dd><p>One pass through the entire dataset</p></dd>
<dt>Batch size</dt>
<dd><p>The number of training examples used in one iteration</p></dd>
</dl>
<p>After the model is trained, Bedrock will evaluate it by using a validation dataset.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Continued Pretraining"><div class="sect2" id="continued_pretraining">
<h2>Continued Pretraining</h2>
<p>Continued pretraining uses<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="customization of model" data-tertiary="continued pretraining" id="id1468"/><a contenteditable="false" data-type="indexterm" data-primary="unlabeled data" data-secondary="continued pretraining" id="id1469"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="unlabeled data" data-tertiary="continued pretraining" id="id1470"/> large volumes of raw text or unlabeled data to help the model improve its understanding of language and context. This can be particularly useful for adapting the model to specific domains or industries where relevant public data exists but labeled data is scarce.</p>
<p>Like fine-tuning, you can configure various hyperparameters—such as batch size, learning rate, and number of training epochs—to control the training process and optimize for your specific needs.</p>
<p>As of now, AWS Bedrock <a contenteditable="false" data-type="indexterm" data-primary="natural language processing (NLP)" data-secondary="continued pretraining for Amazon Titan models" id="id1471"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Titan models" id="id1472"/>supports continued pretraining for select Amazon Titan models, including Titan Text G1-Lite and Titan Text G1-Express. These models are well-suited for a range of NLP tasks and can benefit significantly from additional domain-specific training using your own data. This helps enhance the model’s performance without requiring extensive annotation or labeling efforts.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06cust" id="id1473"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06cust2" id="id1474"/></p>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Agents in Amazon Bedrock"><div class="sect1" id="agents_in_amazon_bedrock">
<h1>Agents in Amazon Bedrock</h1>
<p>In Amazon Bedrock, agents<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="agents in" id="c06agent"/><a contenteditable="false" data-type="indexterm" data-primary="agentic AI" data-secondary="Amazon Bedrock agents" id="c06agent2"/><a contenteditable="false" data-type="indexterm" data-primary="agentic AI" data-secondary="Amazon Bedrock agents" data-tertiary="about" id="id1475"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="agents in" data-tertiary="about" id="id1476"/> are AI-powered systems that automate complex, multistep business tasks by orchestrating interactions between FMs, APIs, and data sources. They interpret user inputs, break down tasks into manageable actions, and execute them by invoking APIs or querying knowledge bases, all while maintaining conversational context.</p>
<p>For instance, consider<a contenteditable="false" data-type="indexterm" data-primary="agentic AI" data-secondary="Amazon Bedrock agents" data-tertiary="workflow" id="id1477"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="agents in" data-tertiary="workflow" id="id1478"/> an automotive parts retailer aiming to enhance its customer support experience. By deploying an Amazon Bedrock agent, the retailer can automate responses to customer inquiries about part compatibility and availability. When a customer asks, “What wiper blades fit a 2021 Honda CR-V?,” the agent interprets the query, retrieves relevant information from the company’s inventory and compatibility databases via integrated APIs, and provides a precise, context-aware response (see <a data-type="xref" href="#figure_six_onethreedot_workflow_of_an_a">Figure 6-13</a>).</p>
<figure><div id="figure_six_onethreedot_workflow_of_an_a" class="figure">
<img src="assets/awsc_0613.png" alt="" width="1142" height="429"/>
<h6><span class="label">Figure 6-13. </span>Workflow of an agent in Bedrock</h6>
</div></figure>
<p>The process begins with model selection, where you choose an appropriate FM that suits your use case requirements. Next, you define instructions using natural language to describe what your agent should do. Here’s an example, “You are a customer support chatbot for a website that will help answer questions about the company’s products and provide order status.”</p>
<p>The third step involves configuring actions, where Bedrock’s flexibility shines through its support for API calls using OpenAPI schemas (allowing you to specify endpoints, methods, parameters, and expected responses like invoking a weather service), Lambda functions that provide business logic, and interactive actions where the agent requests follow-up information from users.</p>
<p>The workflow then moves<a contenteditable="false" data-type="indexterm" data-primary="agentic AI" data-secondary="Amazon Bedrock agents" data-tertiary="proprietary data sources integrated" id="id1479"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="agents in" data-tertiary="proprietary data sources integrated" id="id1480"/><a contenteditable="false" data-type="indexterm" data-primary="data" data-secondary="proprietary data sources integrated into agents" id="id1481"/> to knowledge base integration, where you can connect your proprietary data sources such as FAQs, blogs, and documentation to enhance your agent’s capabilities with domain-specific information.</p>
<p>Next, the testing phase allows you to validate your agent’s performance within Bedrock’s environment, including access to trace functionality that reveals the agent’s decision-making steps and reasoning process. Once you’re satisfied with the agent’s performance, the deployment step enables you to launch your agent either directly on AWS infrastructure or expose it as an API endpoint for broader integration.</p>
<p>To see how this works, let’s take an example.<a contenteditable="false" data-type="indexterm" data-primary="agentic AI" data-secondary="Amazon Bedrock agents" data-tertiary="example restaurant website" id="id1482"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="agents in" data-tertiary="example restaurant website" id="id1483"/> Suppose you want to create an agent for a restaurant’s website. First, you will want to collect relevant data:</p>
<dl>
<dt>Restaurant details</dt>
<dd><p>Name, location, hours, and contact information</p></dd>
<dt>Menu</dt>
<dd><p>Have an up-to-date version</p></dd>
<dt>Reservation information</dt>
<dd><p>Seating capacity and booking policies</p></dd>
<dt>Customer reviews</dt>
<dd><p>Online feedback and ratings</p></dd>
</dl>
<p>Next, you will need to consider the actions. This can take some time, as you will need to brainstorm the various scenarios. But here are some actions:</p>
<ul>
<li><p>Making a reservation</p></li>
<li><p>Canceling a reservation</p></li>
<li><p>Updating a reservation</p></li>
<li><p>Getting details about a reservation</p></li>
<li><p>Getting the menu</p></li>
<li><p>Getting restaurant information</p></li>
<li><p>Seeing reviews</p></li>
</ul>
<p>With this information, you can then have Bedrock create the agent. A customer can then use it for questions like this:</p>
<blockquote>
<p>Reserve a table for three at 6:30 on Saturday and let me know what gluten-free options you have.</p>
<p>Cancel my dinner reservation for tomorrow at 6 P.M.</p>
<p>What are the most popular dishes?</p>
<p>What are your hours this weekend?</p>
<p>Can I get a table with a view?</p>
</blockquote>
<section data-type="sect2" data-pdf-bookmark="Multiagent Collaboration"><div class="sect2" id="multiagent_collaboration">
<h2>Multiagent Collaboration</h2>
<p>Bedrock also allows for<a contenteditable="false" data-type="indexterm" data-primary="agentic AI" data-secondary="Amazon Bedrock agents" data-tertiary="multiagent collaboration" id="id1484"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="agents in" data-tertiary="multiagent collaboration" id="id1485"/> the creation of multiagent collaboration. This is where more than one agent works collaboratively to solve problems. Each agent will focus on a particular task, and there will be a system to provide collaboration for the process.</p>
<p>Another key feature is memory. This is where the system will retain information about all the interactions, which will help improve the accuracy and the reasoning.</p>
<p>Let’s walk through an example<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="agents in" data-tertiary="example customer support chatbot" id="id1486"/><a contenteditable="false" data-type="indexterm" data-primary="agentic AI" data-secondary="Amazon Bedrock agents" data-tertiary="example customer support chatbot" id="id1487"/> of multiagent collaboration for a customer support chatbot. When the customer support chatbot receives a question, the Intent Agent will process it and evaluate the customer needs, say to get product information, order status, or process a return. The agent will use the Retrieval Agent to collect the data. From here, the Sentiment Analysis Agent will determine the tone of the customer query. If it is negative, then there may be escalation to a human agent. Otherwise, the Response Agent will be activated. This will generate a response to the customer’s question. For the whole process, the Interaction Agent will log the interactions, which can be used to help improve future customer questions.</p>
<p>With multiagent collaboration, there is leveraging of specialization for each of the agents. This leads to better responses and actions. But there should also be guardrails in place. You do not want to give full control to the agentic system, especially for high-stakes matters.</p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Pricing"><div class="sect2" id="pricing">
<h2>Pricing</h2>
<p>It’s true that many open source models are free.<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="pricing" id="id1488"/><a contenteditable="false" data-type="indexterm" data-primary="foundation models (FMs)" data-secondary="Amazon Bedrock" data-tertiary="pricing" id="id1489"/><a contenteditable="false" data-type="indexterm" data-primary="costs" data-secondary="Amazon Bedrock pricing" id="id1490"/> But this does not mean you will not be charged for their use on Bedrock. The reason is that there are still the costs for the infrastructure to set up and operate the models.</p>
<p>There are two approaches for the pricing:<a contenteditable="false" data-type="indexterm" data-primary="tokens" data-secondary="on-demand pricing" id="id1491"/></p>
<dl>
<dt>On demand</dt>
<dd><p>You will be charged for the number of tokens processed and the output tokens generated. This is usually when an application has unpredictable or varied workloads. However, for a lower cost—generally at a 50% discount—you can use batch processing. You will submit a group of prompts in a file, which is stored in an Amazon S3 bucket. The responses will not be in real time, but provided as a group when processed.</p></dd>
<dt>Provisioned throughput</dt>
<dd><p>This is when you need guaranteed performance. You can set this for a duration, like for one or six months. This will reserve the capacity for your needs. For the most part, provisioned throughput is when you have large workloads.</p></dd>
</dl>
<p>Besides these two approaches, there are other costs as well for using customization features, like fine-tuning, RAG, and distillation. There are also fees for guardrails and knowledge bases.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06agent" id="id1492"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06agent2" id="id1493"/></p>

</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Amazon Q"><div class="sect1" id="amazon_q">
<h1>Amazon Q</h1>
<p>Launched in April 2024,<a contenteditable="false" data-type="indexterm" data-primary="Amazon Q" id="c06q"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="Amazon Q" id="c06q2"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="Amazon Q" id="id1494"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Q" data-secondary="about" id="id1495"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="Amazon Q" data-tertiary="about" id="id1496"/> Amazon Q is a generative AI virtual assistant for business. It’s built on Amazon Bedrock and uses several FMs. There are two versions: Amazon Q Business and Amazon Q Developer. Let’s discuss each in the following sections.</p>
<section data-type="sect2" data-pdf-bookmark="Amazon Q Business"><div class="sect2" id="amazon_q_business">
<h2>Amazon Q Business</h2>
<p>Amazon Q Business is a<a contenteditable="false" data-type="indexterm" data-primary="Amazon Q" data-secondary="Business" id="id1497"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="Amazon Q" data-tertiary="Business" id="id1498"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="Amazon Q" data-tertiary="Business" id="id1499"/> virtual assistant for employees. You can embed this into a web app or into various systems like Slack, Word, Outlook, Teams, and Microsoft 365.</p>
<p>Here are some of the capabilities of Amazon Q:</p>
<dl>
<dt>Unified search</dt>
<dd><p>Amazon Q will seamlessly index the data in your organization, such as documents, images, and videos. This allows for more accurate and useful responses. All the responses from Amazon Q have citations and references, which helps bolster transparency.</p></dd>
<dt>Amazon Q Apps</dt>
<dd><p>This allows you to create small apps on the Amazon Q Business system. They can be restricted to certain users or made available to the whole organization through an app library. With Amazon Q Apps, you can create programs that generate content—like writing emails or blogs—and carry out workflows, such as for triggering notifications.</p></dd>
<dt>Application tasks</dt>
<dd><p>Amazon Q Apps has a library of more than 50 actions for many business applications, which include ServiceNow, Zendesk, and Salesforce. For example, in Microsoft Exchange, you can receive events from your calendar and retrieve emails.</p></dd>
</dl>
<p>Amazon Q Business has several plans, which start at $3 per user per month.<a contenteditable="false" data-type="indexterm" data-primary="Amazon Q" data-secondary="Business" data-tertiary="pricing" id="id1500"/><a contenteditable="false" data-type="indexterm" data-primary="costs" data-secondary="Amazon Q Business" id="id1501"/></p>
</div></section>
<section data-type="sect2" data-pdf-bookmark="Amazon Q Developer"><div class="sect2" id="amazon_q_developer">
<h2>Amazon Q Developer</h2>
<p>Amazon Q Developer is a <a contenteditable="false" data-type="indexterm" data-primary="Amazon Q" data-secondary="Developer" id="id1502"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="Amazon Q" data-tertiary="Developer" id="id1503"/><a contenteditable="false" data-type="indexterm" data-primary="generative AI" data-secondary="Amazon Q" data-tertiary="Developer" id="id1504"/><a contenteditable="false" data-type="indexterm" data-primary="software development via Amazon Q Developer" id="id1505"/>tool that leverages generative AI for software development. It helps to generate and debug code. The tool can also optimize and explain the code.</p>
<p>Various studies have shown the notable benefits of Amazon Q Developer. For certain organizations, it has increased the speed of development tasks by <a href="https://oreil.ly/Pb--R">up to 80% and improved developer productivity by up to 40%</a>.</p>
<p>A key advantage of Amazon Q Developer is that it is embedded into the common workflows for developers.<a contenteditable="false" data-type="indexterm" data-primary="IDE (integrated development environment)" data-secondary="Amazon Q Developer plug-in" id="id1506"/> The tool is available as a plug-in for IDEs like VS Code, Visual Studio, and JetBrains, IntelliJ IDEA, and Eclipse. <a contenteditable="false" data-type="indexterm" data-primary="command-line interface (CLI)" data-secondary="Amazon Q Developer" id="id1507"/>You can also use it as a command-line interface (CLI)—such as in a terminal—for creating scripts. <a contenteditable="false" data-type="indexterm" data-primary="AWS Console integration with GitLab" id="id1508"/><a contenteditable="false" data-type="indexterm" data-primary="GitLab integration with AWS Console" id="id1509"/><a contenteditable="false" data-type="indexterm" data-primary="Microsoft Teams integration with AWS Console" id="id1510"/><a contenteditable="false" data-type="indexterm" data-primary="Slack integration with AWS Console" id="id1511"/>The same goes for the AWS Console. Then there is an integration with GitLab, which is a version control system, as well as Microsoft Teams and Slack.</p>
<p>Amazon Q Developer has<a contenteditable="false" data-type="indexterm" data-primary="Amazon Q" data-secondary="Developer" data-tertiary="enterprise-grade capabilities" id="id1512"/> enterprise-grade capabilities too. You can use the tool for workload transformations, such as porting .NET applications from Windows to Linux or migrating mainframe systems.</p>
<p>An example of this is with Amazon’s own project to migrate tens of thousands of applications from Java 8 or 11 to Java 17. Ordinarily, this process would take a staggering 4,500 years of development work. But with Amazon Q Developer, the process took a fraction of the time. It also resulted in about <a href="https://oreil.ly/YCgw8">$260 million in annual cost savings</a>.</p>
<p>Amazon Q Developer is also<a contenteditable="false" data-type="indexterm" data-primary="Amazon Q" data-secondary="Developer" data-tertiary="AWS integration" id="id1513"/><a contenteditable="false" data-type="indexterm" data-primary="AWS (Amazon Web Services)" data-secondary="Amazon Q Developer integration" id="id1514"/> tightly integrated with AWS. These are the kinds of prompts you can use:</p>
<blockquote>
<p>What is Amazon EC2, and how does it work?</p>
<p>What are the best practices for securing my AWS environment?</p>
<p>List all my running EC2 instances in the us-east-1 region.</p>
<p>What were my EC2 costs by instance type last month?</p>
<p>Why can’t I SSH into my EC2 instance?</p>
</blockquote>
<p>In terms of the pricing for Amazon Q Developer, there is a free trier. This allows up to 50 chat interactions per month. Then there is a premium edition, which has a subscription of $19 per month per user.</p>
</div></section>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Benefits of Bedrock and Amazon Q"><div class="sect1" id="benefits_of_bedrock_and_amazon_q">
<h1>Benefits of Bedrock and Amazon Q</h1>
<p>Since the launch of ChatGPT in late 2022,<a contenteditable="false" data-type="indexterm" data-primary="Amazon Bedrock" data-secondary="Amazon Q" data-tertiary="benefits of Amazon Bedrock and Amazon Q" id="id1515"/><a contenteditable="false" data-type="indexterm" data-primary="Amazon Q" data-secondary="benefits of Amazon Bedrock and Amazon Q" id="id1516"/> many companies have invested heavily in generative AI projects. But the results have often been disappointing, as shown by research from Gartner. It finds that—for 2025—at least <a href="https://oreil.ly/KrkSP">30% of generative AI projects</a> will be abandoned after the proof–of-concept stage. Some of the reasons include poor data quality, high costs, and inadequate risk guardrails.</p>
<p>This is why platforms like Amazon Bedrock and Amazon Q are so important. As we’ve seen in this chapter, they help to greatly streamline the process for creating generative AI applications. In fact, you do not have to be a data scientist to create an effective system.</p>
<p>The good news is that AWS is committed to these AI platforms and continues to invest substantial resources in them. This will help to reduce the risks of application development and improve the overall quality of the systems.<a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06q" id="id1517"/><a contenteditable="false" data-type="indexterm" data-primary="" data-startref="c06q2" id="id1518"/></p>
</div></section>
<section data-type="sect1" data-pdf-bookmark="Conclusion"><div class="sect1" id="conclusion-id000012">
<h1>Conclusion</h1>
<p>In this chapter, we took a deep dive into two key generative AI platforms for AWS: Amazon Bedrock and Amazon Q. Amazon Bedrock is a powerful application <span class="keep-together">development</span> environment, where you can test and integrate models, as well as use techniques like RAG, fine-tuning, and AI agents. Meanwhile, Amazon Q is a virtual assistant for business and software development. It allows for customization for your proprietary data, which allows for more relevant and accurate responses.</p>
<p>Together, Amazon Bedrock and Amazon Q form a comprehensive AI ecosystem that embodies AWS’s customer-obsessed philosophy. They allow organizations to move beyond experimentation and toward real, measurable value from generative AI.</p>
</div></section>

<section data-type="sect1" data-pdf-bookmark="Quiz"><div class="sect1" id="ch6quiz">
	<h1>Quiz</h1>

<p>To check your answers, please refer to the <a data-type="xref" href="app02.html#answers_ch_6">“Chapter 6 Answer Key”</a>.</p>

<ol>
<li><p>For an AI model in Amazon Bedrock, what might happen if you adjust the temperature and Top P?</p>
<ol type="a">
<li><p>Using both will guarantee more accurate responses.</p></li>
<li><p>Using a combination of these may cause unpredictable or unexpected responses.</p></li>
<li><p>Using both will disable the model.</p></li>
<li><p>Using both will make the responses more deterministic.</p></li>
</ol>
</li>

<li><p>When configuring the image/video playground in Amazon Bedrock, what is a “negative prompt”?</p>
<ol type="a">
<li><p>This increases the model’s temperature.</p></li>
<li><p>It generates black-and-white images.</p></li>
<li><p>It specifies elements you want to exclude from the image or video.</p></li>
<li><p>This decreases the size of the image.</p></li>
</ol>
</li>

<li><p>What is the role of the modality filter in Amazon Bedrock’s model catalog?</p>
<ol type="a">
<li><p>The filter lets users sort models by license type.</p></li>
<li><p>It filters models based on language support.</p></li>
<li><p>The filter identifies models that support serverless deployment.</p></li>
<li><p>It categorizes models by input and output types like text, image, audio, and multimodal.</p></li>
</ol>
</li>

<li><p>For a model in Amazon Bedrock, why would you increase the setting for temperature? </p>
<ol type="a">
<li><p>To generate deterministic content</p></li>
<li><p>To produce videos</p></li>
<li><p>To generate creative content</p></li>
<li><p>To summarize information</p></li>
</ol>
</li>

<li><p>For a model profile in Amazon Bedrock, what type of information would you usually find?</p>
<ol type="a">
<li><p>Type of GPU used</p></li>
<li><p>Version, release date, deployment type, modalities, and model ID</p></li>
<li><p>Only the license information</p></li>
<li><p>The datasets</p></li>
</ol>
</li>

<li><p>What do you need to do to gain access to foundation models (FMs) in Amazon Bedrock that are not enabled by default?</p>
<ol type="a">
<li><p>Enable “On-demand” and restart the session.</p></li>
<li><p>Submit a model access request form with use case details.</p></li>
<li><p>Complete an AWS certification exam.</p></li>
<li><p>Download the model on your own computer.</p></li>
</ol>
</li>
</ol>
</div></section>
<div data-type="footnotes"><p data-type="footnote" id="ch01fn25"><sup><a href="ch06.html#ch01fn25-marker">1</a></sup> Lindsey Wilkinson, <a href="https://oreil.ly/G_zFU">“Why Generative AI Experiments Fail”</a>, CIO Dive, February 14, 2024.</p></div></div></section></div></div></body></html>