- en: Chapter 7\. Practical Tools, Tips, and Tricks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第7章。实用工具、技巧和窍门
- en: This chapter contains material that we, your authors, have encountered during
    our professional work as well as while working on this book, primarily during
    experimentation. The material covered here doesn’t necessarily fit in any single
    chapter; rather, it’s material that deep learning practitioners could find useful
    on a day-to-day basis across a variety of tasks. In line with the “practical”
    theme, these questions cover a range of helpful pragmatic guidelines across topics
    including setting up an environment, training, model interoperability, data collection
    and labeling, code quality, managing experiments, team collaboration practices,
    privacy, and further exploration topics.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包含我们作为作者在专业工作中以及在撰写本书过程中遇到的材料，主要是在实验过程中。这里涵盖的材料不一定适用于任何单独的章节；相反，这些材料是深度学习从业者在日常工作中可能会发现有用的，涵盖了各种任务的实用指南，包括设置环境、训练、模型互操作性、数据收集和标记、代码质量、管理实验、团队协作实践、隐私以及进一步探索主题。
- en: Due to the fast-changing pace of the AI field, this chapter is a small subset
    of the “living” document hosted on the book’s Github repository (see [*http://PracticalDeepLearning.ai*](http://PracticalDeepLearning.ai))
    at *code/chapter-9*, where it is constantly evolving. If you have more questions
    or, even better, answers that might help other readers, feel free to tweet them
    [@PracticalDLBook](https://www.twitter.com/PracticalDLBook) or submit a pull request.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 由于人工智能领域变化迅速，本章是书籍Github存储库（请参见[*http://PracticalDeepLearning.ai*](http://PracticalDeepLearning.ai)）中的“活动”文档的一个小子集，该文档位于*code/chapter-9*，正在不断发展。如果您有更多问题，或者更好的答案可以帮助其他读者，请随时在Twitter上发送推文[@PracticalDLBook](https://www.twitter.com/PracticalDLBook)或提交拉取请求。
- en: Installation
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装
- en: '**Q:** *I came across an interesting and useful Jupyter Notebook on GitHub.
    Making the code run will require cloning the repository, installing packages,
    setting up the environment, and more steps. Is there an instant way to run it
    interactively?*'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *我在GitHub上发现了一个有趣且有用的Jupyter Notebook。要使代码运行，需要克隆存储库、安装软件包、设置环境等多个步骤。有没有一种即时的方法可以交互式运行它？*'
- en: Simply enter the Git repository URL into Binder (*[mybinder.org](http://mybinder.org)*),
    which will turn it into a collection of interactive notebooks. Under the hood,
    it will search for a dependency file, like *requirements.txt* or *environment.yml*
    in the repository’s root directory. This will be used to build a Docker image,
    to help run the notebook interactively in your browser.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 只需将Git存储库URL输入到Binder（*[mybinder.org](http://mybinder.org)*），它将把它转换为一组交互式笔记本。在幕后，它会搜索存储库根目录中的*requirements.txt*或*environment.yml*等依赖文件。这将用于构建一个Docker镜像，以帮助在浏览器中交互式运行笔记本。
- en: '**Q:** *What is the quickest way to get my deep learning setup running on a
    fresh Ubuntu machine with NVIDIA GPUs?*'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *在新的Ubuntu机器上使用NVIDIA GPU，快速搭建深度学习环境的最快方法是什么？*'
- en: Life would be great if `pip install tensorflow-gpu` would solve everything.
    However, that’s far from reality. On a freshly installed Ubuntu machine, listing
    all the installation steps would take at least three pages and more than an hour
    to follow, including installing NVIDIA GPU drivers, CUDA, cuDNN, Python, TensorFlow,
    and other packages. And then it requires carefully checking the version interoperability
    between CUDA, cuDNN and TensorFlow. More often than not, this ends in a broken
    system. A world of pain to say the least!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 如果`pip install tensorflow-gpu`能解决所有问题，那该多好啊。然而，这离现实还很远。在新安装的Ubuntu机器上，列出所有安装步骤至少需要三页以上的时间来跟随，包括安装NVIDIA
    GPU驱动程序、CUDA、cuDNN、Python、TensorFlow和其他软件包。然后需要仔细检查CUDA、cuDNN和TensorFlow之间的版本互操作性。很多时候，这会导致系统崩溃。可以说是一种痛苦的世界！
- en: 'Wouldn’t it be great if two lines could solve all of this effortlessly? Ask,
    and ye shall receive:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果两行代码就能轻松解决所有问题，那不是很棒吗？有求必应：
- en: '[PRE0]'
  id: totrans-9
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The first line ensures that all the drivers are updated. The second line is
    brought to us by the Lambda Labs, a San Francisco–based deep learning hardware
    and cloud provider. The command sets up the Lambda Stack, which installs TensorFlow,
    Keras, PyTorch, Caffe, Caffe2, Theano, CUDA, cuDNN, and NVIDIA GPU drivers. Because
    the company needs to install the same deep learning packages on thousands of machines,
    it automated the process with a one-line command and then open sourced it so that
    others can also make use of it.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 第一行确保所有驱动程序都已更新。第二行是由总部位于旧金山的Lambda Labs提供的。该命令设置Lambda Stack，安装了TensorFlow、Keras、PyTorch、Caffe、Caffe2、Theano、CUDA、cuDNN和NVIDIA
    GPU驱动程序。因为公司需要在成千上万台机器上安装相同的深度学习软件包，所以它使用了一行命令自动化了这个过程，然后开源了它，以便其他人也可以使用。
- en: '**Q:** *What is the fastest way to install TensorFlow on a Windows PC?*'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *在Windows PC上安装TensorFlow的最快方法是什么？*'
- en: Install Anaconda Python 3.7.
  id: totrans-12
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装Anaconda Python 3.7。
- en: On the command line, run `conda install tensorflow-gpu`.
  id: totrans-13
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在命令行上运行`conda install tensorflow-gpu`。
- en: If you do not have GPUs, run `conda install tensorflow`.
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您没有GPU，运行`conda install tensorflow`。
- en: One additional benefit of a CPU-based Conda installation is that it installs
    Intel MKL optimized TensorFlow, running faster than the version we get by using
    `pip install tensorflow`.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 基于CPU的Conda安装的一个额外好处是它安装了经过优化的Intel MKL TensorFlow，比使用`pip install tensorflow`得到的版本运行更快。
- en: '**Q:** *I have an AMD GPU. Could I benefit from GPU speedups in TensorFlow
    on my existing system?*'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *我有一块AMD GPU。在现有系统上，我能从TensorFlow的GPU加速中受益吗？*'
- en: 'Although the majority of the deep learning world uses NVIDIA GPUs, there is
    a growing community of people running on AMD hardware with the help of the ROCm
    stack. Installation using the command line is simple:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大多数深度学习领域使用NVIDIA GPU，但有越来越多的人群在AMD硬件上运行，并借助ROCm堆栈。使用命令行进行安装很简单：
- en: '`sudo apt install rocm-libs miopen-hip cxlactivitylogger`'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`sudo apt install rocm-libs miopen-hip cxlactivitylogger`'
- en: '`sudo apt install wget python3-pip`'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`sudo apt install wget python3-pip`'
- en: '`pip3 install --user tensorflow-rocm`'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`pip3 install --user tensorflow-rocm`'
- en: '**Q:** *Forget installation, where can I get preinstalled deep learning containers?*'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *忘记安装，我在哪里可以获得预安装的深度学习容器？*'
- en: Docker is synonymous with setting up environments. Docker helps run isolated
    containers that are bundled with tools, libraries, and configuration files. There
    are several deep learning Docker containers available while selecting your virtual
    machine (VM) from major cloud providers AWS, Microsoft Azure, GCP, Alibaba, etc.)
    that are ready to start working. NVIDIA also freely provides NVIDIA GPU Cloud
    containers, which are the same high-performance containers used to break training
    speed records on the MLPerf benchmarks. You can even run these containers on your
    desktop machine.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Docker与设置环境是同义词。Docker帮助运行与工具、库和配置文件捆绑在一起的隔离容器。在选择来自主要云提供商（如AWS、Microsoft Azure、GCP、阿里巴巴等）的虚拟机（VM）时，有几个深度学习Docker容器可用于立即开始工作。NVIDIA还免费提供NVIDIA
    GPU云容器，这些容器与用于在MLPerf基准测试中打破训练速度记录的高性能容器相同。您甚至可以在桌面机器上运行这些容器。
- en: Training
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练
- en: '**Q:** *I don’t like having to stare at my screen constantly to check whether
    my training finished. Can I get a notification alert on my phone, instead?*'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *我不喜欢不断盯着屏幕检查我的训练是否已完成。我能否在手机上收到通知警报？*'
- en: Use [Knock Knock](https://oreil.ly/uX3qb), a Python library that, as the name
    suggests, notifies you when your training ends (or your program crashes) by sending
    alerts on email, Slack, or even Telegram! Best of all, it requires adding only
    two lines of code to your training script. No more opening your program a thousand
    times to check whether the training has finished.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 使用[Knock Knock](https://oreil.ly/uX3qb)，这是一个Python库，正如其名称所示，当您的训练结束（或程序崩溃）时，通过电子邮件、Slack甚至Telegram发送警报通知您！最重要的是，只需向您的训练脚本添加两行代码即可。不再需要打开程序一千次来检查训练是否已完成。
- en: '**Q:** *I prefer graphics and visualizations over plain text. Can I get real-time
    visualizations for my training process?*'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *我更喜欢图形和可视化而不是纯文本。我能否获得我的训练过程的实时可视化？*'
- en: FastProgress progress bar (originally developed for fast.ai by Sylvain Gugger)
    comes to the rescue.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: FastProgress进度条（最初由Sylvain Gugger为fast.ai开发）来拯救。
- en: '**Q:** *I conduct a lot of experiments iteratively and often lose track of
    what changed between each experiment as well as the effect of the change. How
    do I manage my experiments in a more organized manner?*'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *我进行大量的实验迭代，经常忘记每次实验之间的变化以及变化的影响。如何以更有组织的方式管理我的实验？*'
- en: Software development has had the ability to keep a historical log of changes
    through version control. Machine learning, unfortunately, did not have the same
    luxury. That’s changing now with tools like Weights and Biases, and Comet.ml.
    They allow you to keep track of multiple runs and to log training curves, hyperparameters,
    outputs, models, notes, and more with just two lines of code added to your Python
    script. Best of all, through the power of the cloud, you can conveniently track
    experiments even if you are away from the machine, and share the results with
    others.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 软件开发通过版本控制具有保留历史更改记录的能力。不幸的是，机器学习并没有同样的奢侈。现在通过Weights and Biases和Comet.ml等工具，情况正在改变。它们允许您跟踪多次运行，并记录训练曲线、超参数、输出、模型、注释等，只需向您的Python脚本添加两行代码。最重要的是，通过云的力量，即使您远离机器，也可以方便地跟踪实验并与他人分享结果。
- en: '**Q:** *How do I check whether TensorFlow is using the GPU(s) on my machine?*'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *如何检查TensorFlow是否在我的机器上使用GPU？*'
- en: 'Use the following handy command:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下方便的命令：
- en: '[PRE1]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '**Q:** *I have multiple GPUs on my machine. I don’t want my training script
    to consume all of them. How do I restrict my script to run on only a specific
    GPU?*'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *我的机器上有多个GPU。我不希望我的训练脚本占用所有GPU。如何限制我的脚本仅在特定GPU上运行？*'
- en: '*Use* `CUDA_VISIBLE_DEVICES=GPU_ID`. Simply prefix the training script command
    as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '*使用* `CUDA_VISIBLE_DEVICES=GPU_ID`。只需在训练脚本命令前加上以下前缀：'
- en: '[PRE2]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Alternatively, write the following lines early on in your training script:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，在您的培训脚本中的早期写入以下行：
- en: '[PRE3]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '`GPU_ID` can have values such as 0, 1, 2, and so on. You can see these IDs
    (along with GPU usage) using the `nvidia-smi` command. For assigning to multiple
    GPUs, use a comma-separated list of IDs.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '`GPU_ID`可以具有值如0、1、2等。您可以使用`nvidia-smi`命令查看这些ID（以及GPU使用情况）。要分配给多个GPU，使用逗号分隔的ID列表。'
- en: '**Q:** *Sometimes it feels like there are too many knobs to adjust when training.
    Can it be done automatically, instead, to get the best accuracy?*'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *有时候感觉在训练时有太多旋钮要调整。是否可以自动完成，以获得最佳准确性？*'
- en: There are many options for automated hyperparameter tuning, including Keras-specific
    Hyperas and Keras Tuner, and more generic frameworks such as Hyperopt and Bayesian
    optimization that perform extensive experimentation to maximize our objective
    (i.e., maximizing accuracy in our case) more intelligently than simple grid searches.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多自动化超参数调整的选项，包括针对Keras的Hyperas和Keras Tuner，以及更通用的框架，如Hyperopt和贝叶斯优化，执行广泛的实验以更智能地最大化我们的目标（即在我们的情况下最大化准确性）比简单的网格搜索更智能。
- en: '**Q:** *ResNet and MobileNet work well enough for my use case. Is it possible
    to build a model architecture that can achieve even higher accuracy for my scenario?*'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *ResNet和MobileNet对我的用例已经足够好了。是否可能构建一个可以在我的情况下实现更高准确度的模型架构？*'
- en: 'Three words: Neural Architecture Search (NAS). Let the algorithm find the best
    architecture for you. NAS can be accomplished through packages like Auto-Keras
    and AdaNet.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 三个词：神经架构搜索（NAS）。让算法为您找到最佳架构。NAS可以通过Auto-Keras和AdaNet等软件包实现。
- en: '**Q:** *How do I go about debugging my TensorFlow script?*'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *如何调试我的TensorFlow脚本？*'
- en: 'The answer is in the question: TensorFlow Debugger (`tfdbg)`.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 答案就在问题中：TensorFlow调试器（`tfdbg）。
- en: Model
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 模型
- en: '**Q:** *I want to quickly know the input and output layers of my model without
    writing code. How can I accomplish that?*'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *我想快速了解我的模型的输入和输出层，而不必编写代码。我该如何实现？*'
- en: Use Netron. It graphically shows your model, and on clicking any layer, provides
    details on the architecture.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Netron。它以图形方式显示您的模型，并在点击任何层时提供有关架构的详细信息。
- en: '**Q:** *I need to publish a research paper. Which tool should I use to draw
    my organic, free-range, gluten-free model architecture?*'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** 我需要发表一篇研究论文。我应该使用哪个工具来绘制我的有机、自由范围、无麸质模型架构？'
- en: MS Paint, obviously! No, we’re just kidding. We are fans of NN-SVG as well as
    PlotNeuralNet for creating high-quality CNN diagrams.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 当然是MS Paint！不，我们只是开玩笑。我们也喜欢NN-SVG和PlotNeuralNet，用于创建高质量的CNN图表。
- en: '**Q:** *Is there a one-stop shop for all models?*'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** 是否有一个一站式的所有模型的平台？'
- en: Indeed! Explore *[PapersWithCode.com](http://PapersWithCode.com)*, *ModelZoo.co*,
    and *ModelDepot.io* for some inspiration.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 确实！探索[PapersWithCode.com](http://PapersWithCode.com)、ModelZoo.co和ModelDepot.io，获取一些灵感。
- en: '**Q:** *I’ve finished training my model. How can I make it available for others
    to use?*'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** 我已经训练好了我的模型。如何让其他人可以使用它？'
- en: You can begin by making the model available for download from GitHub. And then
    list it on the model zoos mentioned in the previous answer. For even wider adoption,
    upload it to TensorFlow Hub (*tfhub.dev*).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以开始让模型可以从GitHub下载。然后将其列在前面答案中提到的模型动物园中。为了更广泛地采用，将其上传到TensorFlow Hub（tfhub.dev）。
- en: In addition to the model, you should publish a “model card,” which is essentially
    like a résumé of the model. It’s a short report that details author information,
    accuracy metrics, and the dataset it was benchmarked on. Additionally, it provides
    guidance on potential biases and out-of-scope uses.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 除了模型之外，您应该发布一个“模型卡片”，它本质上就像模型的简历。这是一个详细介绍作者信息、准确度指标和基准数据集的简短报告。此外，它提供了关于潜在偏见和超出范围用途的指导。
- en: '**Q:** *I have a model previously trained in framework X, but I need to use
    it in framework Y. Do I need to waste time retraining it in framework Y?*'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** 我之前在X框架中训练过一个模型，但我需要在Y框架中使用它。我需要浪费时间在Y框架中重新训练吗？'
- en: Nope. All you need is the power of the ONNX. For models not in the TensorFlow
    ecosystem, most major deep learning libraries support saving them in ONNX format,
    which can then be converted to the TensorFlow format. Microsoft’s MMdnn can help
    in this conversion.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 不需要。你只需要ONNX的力量。对于不在TensorFlow生态系统中的模型，大多数主要的深度学习库都支持将它们保存为ONNX格式，然后可以将其转换为TensorFlow格式。微软的MMdnn可以帮助进行这种转换。
- en: Data
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据
- en: '**Q:** *Could I collect hundreds of images on a topic in a few minutes?*'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** 我能在几分钟内收集关于一个主题的数百张图像吗？'
- en: Yes, you can collect hundreds of images in three minutes or less with a Chrome
    extension called Fatkun Batch Download Image. Simply search for a keyword in your
    favorite image search engine, filter images by the correct usage rights (e.g.,
    Public Domain), and press the Fatkun extension to download all images. See [Chapter 12](part0014.html#DB7S3-13fa565533764549a6f0ab7f11eed62b),
    where we use it to build a Not Hotdog app.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，你可以使用一个名为Fatkun Batch Download Image的Chrome扩展，在三分钟或更短的时间内收集数百张图像。只需在你喜欢的图像搜索引擎中搜索一个关键词，按正确的使用权限（例如，公共领域）过滤图像，然后按下Fatkun扩展下载所有图像。参见第12章，在那里我们使用它构建了一个Not
    Hotdog应用程序。
- en: 'Bonus tip: to download from a single website, search for a keyword followed
    by site:website_address. For example, “horse site:[flickr.com](http://flickr.com).”'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 额外提示：要从单个网站下载，请搜索一个关键词，后面跟着site:网站地址。例如，“马 site:flickr.com”。
- en: '**Q:** *Forget the browser. How do I scrape Google for images using the command
    line?*'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** 忘掉浏览器。如何使用命令行从Google爬取图像？'
- en: '[PRE4]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '`-k`, `-l`, and `-r` are shorthand for `keyword`, `limit` (number of images),
    and `usage_rights`, respectively. This is a powerful tool with many options for
    controlling and filtering what images to download from Google searches. Plus,
    instead of just loading the thumbnails shown by Google Images, it saves the original
    images linked by the search engine. For saving more than 100 images, install the
    `selenium` library along with `chromedriver`.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '`-k`、`-l`和`-r`分别是`keyword`、`limit`（图像数量）和`usage_rights`的缩写。这是一个功能强大的工具，有许多选项可以控制和过滤从Google搜索中下载的图像。此外，它保存了搜索引擎链接的原始图像，而不仅仅是加载Google
    Images显示的缩略图。要保存超过100张图像，请安装`selenium`库以及`chromedriver`。'
- en: '**Q:** *Those were not enough for collecting images. I need more control. What
    other tools can help me download data in more custom ways beyond the search engine?*'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** 这些工具不足以收集图像。我需要更多控制。还有哪些工具可以帮助我以更自定义的方式下载数据，超越搜索引擎？'
- en: 'With a GUI (no programming needed):'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 带有GUI（无需编程）：
- en: '[ScrapeStorm.com](http://ScrapeStorm.com)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[ScrapeStorm.com](http://ScrapeStorm.com)'
- en: Easy GUI to identify rules for elements to extract
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 易于GUI识别要提取的元素规则
- en: '[WebScraper.io](http://WebScraper.io)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[WebScraper.io](http://WebScraper.io)'
- en: Chrome-based scraping extension, especially for extracting structured output
    from single websites
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 基于Chrome的爬虫扩展，特别用于从单个网站提取结构化输出
- en: '[80legs.com](http://80legs.com)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[80legs.com](http://80legs.com)'
- en: Cloud-based scalable scraper, for parallel, large tasks
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 基于云的可扩展爬虫，用于并行、大型任务
- en: 'Python-based programmatic tools:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 基于Python的编程工具：
- en: '[Scrapy.org](http://Scrapy.org)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '[Scrapy.org](http://Scrapy.org)'
- en: For more programmable controls on scraping, this is one of the most famous scrapers.
    Compared to building your own naive scraper to explore websites, it offers throttling
    rate by domain, proxy, and IP; can handle *robots.txt*; offers flexibility in
    browser headers to show to web servers; and takes care of several possible edge
    cases.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 对于更可编程的爬取控制，这是最著名的爬虫之一。与构建自己的天真爬虫来探索网站相比，它提供了按域名、代理和IP进行节流速率的功能；可以处理robots.txt；提供了在向Web服务器显示的浏览器标头方面的灵活性；并处理了几种可能的边缘情况。
- en: InstaLooter
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: InstaLooter
- en: A Python-based tool for scraping Instagram.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 一个用于爬取Instagram的基于Python的工具。
- en: '**Q:** *I have the images for the target classes, but now need images for the
    negative (not item/background) class. Any quick ways to build a big dataset of
    negative classes?*'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** 我有目标类别的图像，但现在需要负类别（非项目/背景）的图像。有什么快速方法可以构建一个负类别的大数据集？'
- en: '[ImageN](https://oreil.ly/s4Nyk) offers 1,000 images—5 random images for 200
    ImageNet categories—which you can use as the negative class. If you need more,
    download a random sample programmatically from ImageNet.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '[ImageN](https://oreil.ly/s4Nyk)提供了1,000张图片——200个ImageNet类别的5张随机图片——您可以将其用作负类。如果需要更多，请从ImageNet中以编程方式下载随机样本。'
- en: '**Q:** *How can I search for a prebuilt dataset that suits my needs?*'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q：** *我如何搜索适合我的需求的预构建数据集？*'
- en: Try Google Dataset Search, *VisualData.io*, and *[DatasetList.com](http://DatasetList.com)*.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试Google数据集搜索、*VisualData.io*和*[DatasetList.com](http://DatasetList.com)*。
- en: '**Q:** *For datasets like ImageNet, downloading, figuring out the format, and
    then loading them for training takes far too much time. Is there an easy way to
    read popular datasets?*'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q：** *对于像ImageNet这样的数据集，下载、弄清楚格式，然后加载它们进行训练需要太多时间。有没有一种简单的方法来读取流行的数据集？*'
- en: TensorFlow Datasets is a growing collection of datasets ready to use with TensorFlow.
    It includes ImageNet, COCO (37 GB), and Open Images (565 GB) among others. These
    datasets are exposed as `tf.data.Datasets`, along with performant code to feed
    them in your training pipeline.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow数据集是一个不断增长的数据集集合，可以与TensorFlow一起使用。其中包括ImageNet、COCO（37 GB）和Open Images（565
    GB）等。这些数据集被公开为`tf.data.Datasets`，并提供了高性能的代码来将它们输入到您的训练流程中。
- en: '**Q:** *Training on the millions of ImageNet images will take a long, long
    time. Is there a smaller representative dataset I could try training on, to quickly
    experiment and iterate with?*'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q：** *在数百万张ImageNet图片上进行训练将需要很长时间。有没有一个更小的代表性数据集，我可以尝试进行训练，以便快速进行实验和迭代？*'
- en: Try [Imagenette](https://oreil.ly/NpYBe). Built by Jeremy Howard from fast.ai,
    this 1.4 GB dataset contains only 10 classes instead of 1,000.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试[Imagenette](https://oreil.ly/NpYBe)。由fast.ai的Jeremy Howard创建，这个1.4 GB的数据集只包含10个类别，而不是1,000个。
- en: '**Q:** *What are the largest readily available datasets that I could use for
    training?*'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q：** *有哪些可用于训练的最大数据集？*'
- en: 'Tencent ML Images: 17.7 million images with 11,000 category labels'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 腾讯ML图片：1,770万张图片，带有11,000个类别标签
- en: 'Open Images V4 (from Google): 9 million images in 19.7 K categories'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Open Images V4（来自Google）：19.7 K类别中的9百万张图片
- en: 'BDD100K (from UC Berkeley): Images from 100,000 driving videos, over 1,100
    hours'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: BDD100K（来自加州大学伯克利分校）：来自100,000个驾驶视频的图像，超过1,100小时
- en: 'YFCC100M (from Yahoo): 99.2 million images'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: YFCC100M（来自雅虎）：99.2百万张图片
- en: '**Q:** *What are some of the readily available large video datasets I could
    use?*'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q：** *有哪些现成的大型视频数据集可以使用？*'
- en: '| **Name** | **Details** |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| **名称** | **详情** |'
- en: '| --- | --- |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| YouTube-8M | 6.1 million videos, 3,862 classes, 2.6 billion audio-visual
    features3.0 labels/video1.53 terabytes of randomly sampled videos |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| YouTube-8M | 6.1百万个视频，3,862个类别，26亿个视听特征每个视频3.0个标签1.53 TB的随机抽样视频 |'
- en: '| Something Something(from Twenty Billion Neurons) | 221,000 videos in 174
    action classesFor example, “Pouring water into wine glass but missing so it spills
    next to it”Humans performing predefined actions with everyday objects |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| Something Something（来自Twenty Billion Neurons）| 174个动作类别中的221,000个视频，例如“将水倒入酒杯但错过了，所以洒在旁边”人们用日常物品执行预定义的动作
    |'
- en: '| Jester(from Twenty Billion Neurons) | 148,000 videos in 27 classesFor example,
    “Zooming in with two fingers”Predefined hand gestures in front of a webcam |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| Jester（来自Twenty Billion Neurons）| 27个类别中的148,000个视频，例如“用两根手指放大”在网络摄像头前预定义的手势
    |'
- en: '**Q:** *Are those the largest labeled datasets ever assembled in the history
    of time?*'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q：** *这些是有史以来组装的最大标记数据集吗？*'
- en: 'Nope! Companies like Facebook and Google curate their own private datasets
    that are much larger than the public ones we can play with:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 没有！像Facebook和Google这样的公司会精心策划自己的私人数据集，这些数据集比我们可以使用的公共数据集要大得多：
- en: 'Facebook: 3.5 billion Instagram images with noisy labels (first reported in
    2018)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Facebook：35亿张带有嘈杂标签的Instagram图片（首次报道于2018年）
- en: 'Google – JFT-300M: 300 million images with noisy labels (first reported in
    2017)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谷歌 - JFT-300M：30亿张带有嘈杂标签的图片（首次报道于2017年）
- en: Sadly, unless you’re an employee at one of these companies, you can’t really
    access these datasets. Nice recruiting tactic, we must say.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 遗憾的是，除非你是这些公司的员工，否则你实际上无法访问这些数据集。我们必须说，这是一个不错的招聘策略。
- en: '**Q:** *How can I get help annotating data?*'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q：** *我如何获得帮助注释数据？*'
- en: There are several companies out there that can assist with labeling different
    kinds of annotations. A few worth mentioning include SamaSource, Digital Data
    Divide, and iMerit, which employ people who otherwise have limited opportunities,
    eventually creating positive socioeconomic change through employment in underprivileged
    communities.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 有几家公司可以帮助标记不同类型的注释。值得一提的几家公司包括SamaSource、Digital Data Divide和iMerit，他们雇用那些机会有限的人，最终通过在贫困社区就业来创造积极的社会经济变革。
- en: '**Q:** *Is there a versioning tool for datasets, like Git is for code?*'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q：** *是否有用于数据集的版本控制工具，就像Git用于代码一样？*'
- en: Qri and Quilt can help version control our datasets, aiding in reproducibility
    of experiments.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Qri和Quilt可以帮助版本控制我们的数据集，有助于实验的可重复性。
- en: '**Q:** *What if I don’t have access to a large dataset for my unique problem?*'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q：** *如果我没有一个大型数据集来解决我的独特问题怎么办？*'
- en: Try to develop a synthetic dataset for training! For example, find a realistic
    3D model of the object of interest and place it in realistic environments using
    a 3D framework such as Unity. Adjust the lighting and camera position, zoom, and
    rotation to take snapshots of this object from many angles, generating an endless
    supply of training data. Alternatively, companies like AI.Reverie, CVEDIA, Neuromation,
    Cognata, Mostly.ai, and DataGen Tech provide realistic simulations for training
    needs. One big benefit of synthesized training data is that the labeling process
    is built into the synthesization process. After all, you would know what you are
    creating. This automatic labeling can save a lot of money and effort, compared
    to manual labeling.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试为训练开发一个合成数据集！例如，找到感兴趣对象的逼真3D模型，并使用Unity等3D框架将其放置在逼真的环境中。调整光照和相机位置、缩放和旋转，从多个角度拍摄这个对象的快照，生成无限的训练数据。此外，像AI.Reverie、CVEDIA、Neuromation、Cognata、Mostly.ai和DataGen
    Tech这样的公司提供了用于训练需求的逼真模拟。合成训练数据的一个重要好处是标记过程内置于合成过程中。毕竟，您会知道自己在创造什么。与手动标记相比，这种自动标记可以节省大量金钱和精力。
- en: Privacy
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 隐私
- en: '**Q:** *How do I develop a more privacy-preserving model without going down
    the cryptography rabbit hole?*'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *如何开发一个更注重隐私的模型而不深入研究密码学？*'
- en: TensorFlow Encrypted might be the solution you’re looking for. It enables development
    using encrypted data, which is relevant, especially if you are on the cloud. Internally,
    lots of secure multiparty computation and homomorphic encryptions result in privacy-preserving
    machine learning.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: TensorFlow Encrypted可能是您正在寻找的解决方案。它可以使用加密数据进行开发，这在云端尤为重要。内部，大量的安全多方计算和同态加密实现了隐私保护的机器学习。
- en: '**Q:** *Can I keep my model under wraps from prying eyes?*'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *我可以防止别人窥探我的模型吗？*'
- en: Well, unless you are on the cloud, weights are visible and can be reverse engineered.
    Use the Fritz library for protecting your model’s IP when deployed on smartphones.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯，除非你在云端，权重是可见的并且可以被反向工程。在智能手机上部署时，使用Fritz库来保护您模型的知识产权。
- en: Education and Exploration
  id: totrans-112
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 教育和探索
- en: '**Q:** *I want to become an AI expert. Beyond this book, where should I invest
    my time to learn more?*'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *我想成为人工智能专家。除了这本书，我应该在哪里投入更多时间学习？*'
- en: There are several resources on the internet to learn deep learning in depth.
    We highly recommend these video lectures from some of the best teachers, covering
    a variety of application areas from computer vision to natural language processing.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在互联网上有几个资源可以深入学习深度学习。我们强烈推荐这些来自一些最好的老师的视频讲座，涵盖了从计算机视觉到自然语言处理等各种应用领域。
- en: Fast.ai (by Jeremy Howard and Rachel Thomas) features a free 14-video lecture
    series, taking a more learn-by-doing approach in PyTorch. Along with the course
    comes an ecosystem of tools and an active community that has led to many breakthroughs
    in the form of research papers and ready-to-use code (like three lines of code
    to train a state-of-the-art network using the fast.ai library).
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fast.ai（由Jeremy Howard和Rachel Thomas创建）提供了一个免费的14集视频讲座系列，采用更多的PyTorch实践学习方法。除了课程，还有一整套工具和一个活跃的社区，已经导致了许多研究论文和可直接使用的代码的突破（比如使用fast.ai库训练最先进网络只需三行代码）。
- en: Deeplearning.ai (by Andrew Ng) features a five-course “Deep Learning Specialization.”
    It’s free of cost (although you could pay a small fee to get a certificate) and
    will solidify your theoretical foundation further. Dr. Ng’s first Coursera course
    on machine learning has taught more than two million students, and this series
    continues the tradition of highly approachable content loved by beginners and
    experts alike.
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deeplearning.ai（由Andrew Ng创建）提供了一个包含五门课程的“深度学习专项课程”。它是免费的（尽管您可以支付一小笔费用以获得证书），将进一步巩固您的理论基础。Ng博士在Coursera上的第一门机器学习课程已经教授了超过两百万名学生，这个系列延续了深受初学者和专家喜爱的高度易懂的内容传统。
- en: We would be remiss if we didn’t encourage you to note [O’Reilly’s Online Learning](http://oreilly.com)
    platform in this list. Helping more than two million users advance their careers,
    it contains hundreds of books, videos, live online trainings, and keynotes given
    by leading thinkers and practitioners at O’Reilly’s AI and data conferences.
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果我们没有在这个列表中鼓励您注意[O'Reilly的在线学习](http://oreilly.com)平台，我们将感到遗憾。这个平台帮助超过两百万用户提升他们的职业，包含数百本书籍、视频、在线培训和由O'Reilly的人工智能和数据会议上的领先思想家和实践者发表的主题演讲。
- en: '**Q:** *Where can I find interesting notebooks to learn from?*'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *我在哪里可以找到有趣的笔记本进行学习？*'
- en: 'Google Seedbank is a collection of interactive machine learning examples. Built
    on top of Google Colaboratory, these Jupyter notebooks can be run instantly without
    any installations. Some interesting examples include:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Google Seedbank是一个互动机器学习示例集合。基于Google Colaboratory构建，这些Jupyter笔记本可以立即运行，无需任何安装。一些有趣的示例包括：
- en: Generating audio with GANs
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用GANs生成音频
- en: Action recognition on video
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 视频动作识别
- en: Generating Shakespeare-esque text
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成莎士比亚风格的文本
- en: Audio-style transfer
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 音频风格转移
- en: '**Q:** *Where can I learn about the state of the art for a specific topic?*'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *我在哪里可以了解特定主题的最新技术？*'
- en: Considering how fast the state of the art moves in AI, SOTAWHAT is a handy command-line
    tool to search research papers for the latest models, datasets, tasks, and more.
    For example, to look up the latest results on ImageNet, use `sotawhat imagenet`
    on the command line. Additionally, [*paperswithcode.com/sota*](http://paperswithcode.com/sota)
    also features repositories for papers, their source code, and released models,
    along with an interactive visual timeline of benchmarks.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到人工智能领域技术更新迅速，SOTAWHAT是一个方便的命令行工具，可以搜索最新模型、数据集、任务等研究论文。例如，要查找ImageNet的最新结果，请在命令行上使用`sotawhat
    imagenet`。此外，[*paperswithcode.com/sota*](http://paperswithcode.com/sota)还提供了论文、源代码和发布模型的存储库，以及一个交互式的基准时间轴。
- en: '**Q:** *I am reading a paper on Arxiv and I really like it. Do I need to write
    code from scratch?*'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *我正在阅读一篇Arxiv上的论文，我非常喜欢。我需要从头开始编写代码吗？*'
- en: Not at all! The ResearchCode Chrome extension makes it easy to find code when
    browsing *[arxiv.org](http://arxiv.org)* or Google Scholar. All it takes is a
    press of the extension button. You can also look up code without installing the
    extension on the *[ResearchCode.com](http://ResearchCode.com)* website.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 一点也不！ResearchCode Chrome扩展程序使得在浏览*[arxiv.org](http://arxiv.org)*或Google Scholar时轻松找到代码。只需按一下扩展按钮即可。您也可以在*[ResearchCode.com](http://ResearchCode.com)*网站上查找代码而无需安装扩展程序。
- en: '**Q:** *I don’t want to write any code, but I still want to interactively experiment
    with a model using my camera. How can I do that?*'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *我不想写任何代码，但我仍然想使用我的摄像头进行交互式实验模型。我该怎么做？'
- en: '[Runway ML](https://runwayml.com) is an easy-to-use yet powerful GUI tool that
    allows you to download models (from the internet or your own) and use the webcam
    or other input, such as video files, to see the output interactively. This allows
    further combining and remixing outputs of models to make new creations. And all
    of this happens with just a few mouse clicks; hence, it’s attracting a large artist
    community!'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '[Runway ML](https://runwayml.com)是一个易于使用但功能强大的GUI工具，允许您下载模型（来自互联网或您自己的模型）并使用网络摄像头或其他输入，如视频文件，以交互方式查看输出。这使得进一步组合和混合模型的输出以创建新作品成为可能。所有这些只需点击几下鼠标就能完成；因此，它吸引了大量的艺术家社区！'
- en: '**Q:** *8-1If I can test without code, can I train without code, too?*'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *如果我可以在没有代码的情况下进行测试，那么我也可以在没有代码的情况下进行训练吗？*'
- en: We discuss this in detail in [Chapter 8](part0010.html#9H5K3-13fa565533764549a6f0ab7f11eed62b)
    (web-based) and [Chapter 12](part0014.html#DB7S3-13fa565533764549a6f0ab7f11eed62b)
    (desktop-based). To keep it short, tools such as Microsoft’s [CustomVision.ai](http://CustomVision.ai),
    Google’s Cloud AutoML Vision, Clarifai, Baidu EZDL, and Apple’s Create ML provide
    drag-and-drop training capabilities. Some of these tools take as little as a few
    seconds to do the training.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第8章](part0010.html#9H5K3-13fa565533764549a6f0ab7f11eed62b)（基于网络）和[第12章](part0014.html#DB7S3-13fa565533764549a6f0ab7f11eed62b)（基于桌面）中详细讨论了这个问题。简而言之，诸如微软的[CustomVision.ai](http://CustomVision.ai)、谷歌的Cloud
    AutoML Vision、Clarifai、百度EZDL和苹果的Create ML等工具提供了拖放式训练功能。其中一些工具只需几秒钟就能完成训练。
- en: One Last Question
  id: totrans-132
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最后一个问题
- en: '**Q:** *Tell me a great deep learning prank?*'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '**Q:** *告诉我一个伟大的深度学习恶作剧？*'
- en: Print and hang poster shown in [Figure 7-1](part0009.html#satirical_poster_on_the_state_of_ai_from)
    from [*keras4kindergartners.com*](http://keras4kindergartners.com) near the watercooler,
    and watch people’s reactions.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 打印并挂在[*keras4kindergartners.com*](http://keras4kindergartners.com)上显示的海报，靠近饮水机，看着人们的反应。
- en: '![Satirical poster on the state of AI from keras4kindergartners.com](../images/00056.jpeg)'
  id: totrans-135
  prefs: []
  type: TYPE_IMG
  zh: '![来自keras4kindergartners.com的关于AI状态的讽刺海报](../images/00056.jpeg)'
- en: Figure 7-1\. Satirical poster on the state of AI from [keras4kindergartners.com](http://keras4kindergartners.com)
  id: totrans-136
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图7-1\. 来自[keras4kindergartners.com](http://keras4kindergartners.com)的关于AI状态的讽刺海报
