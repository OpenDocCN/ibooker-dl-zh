- en: '8 Training neural networks: Forward propagation and backpropagation'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs: []
  type: TYPE_NORMAL
- en: Sigmoid functions as differential surrogates for Heaviside step functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Layering in neural networks: expressing linear layers as matrix-vector multiplication'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression loss, forward and backward propagation, and their math
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So far, we have seen that neural networks make complicated real-life decisions
    by modeling the decision-making process with mathematical functions. These functions
    can become arbitrarily involved, but fortunately, we have a simple building block
    called a *perceptron* that can be repeated systematically to model any arbitrary
    function. We need not even explicitly know the function being modeled in closed
    form. All we need is a reasonably sized set of sample inputs and corresponding
    correct outputs. This collection of input and output pairs is known as *training
    data*. Armed with this training data, we can *train* a multilayer perceptron (MLP,
    aka neural network) to emit reasonably correct outputs on inputs it has never
    seen before.
  prefs: []
  type: TYPE_NORMAL
- en: Such neural networks, where we need to know the output for each input in the
    training data set, are known as *supervised* neural networks. The correct output
    for the training inputs is typically generated via a manual process called *labeling*.
    Labeling is expensive and time-consuming. Much research is going on toward unsupervised,
    semi-supervised, and self-supervised networks, eliminating or minimizing the labeling
    process. But as of now, the accuracy of unsupervised and self-supervised networks
    in general does not match that of supervised networks. In this chapter, we focus
    on supervised neural networks. In chapter [14](../Text/14.xhtml#ch-ae-vae), we
    will study unsupervised networks.
  prefs: []
  type: TYPE_NORMAL
- en: What is this process of ‚Äútraining‚Äù a neural network? It essentially estimates
    the parameter values that would make the network emit output values as close as
    possible to the known correct outputs on the training inputs. In this chapter,
    we discuss how this is done. But before that, we have to learn a few other things.
  prefs: []
  type: TYPE_NORMAL
- en: NOTE The complete PyTorch code for this chapter is available at [http://mng.bz/YAXa](http://mng.bz/YAXa)
    in the form of fully functional and executable Jupyter notebooks.
  prefs: []
  type: TYPE_NORMAL
- en: 8.1 Differentiable step-like functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In equation [7.3](../Text/07.xhtml#eq-perceptron), we expressed the perceptron
    as a combination of a Heaviside step function *œï* and an affine transformation
    ![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png) + *b*. This
    is the perceptron we used throughout chapter [7](../Text/07.xhtml#ch-func-approx)
    and with which we were able to express (model) pretty much all functions of interest.
  prefs: []
  type: TYPE_NORMAL
- en: 'Despite its expressive power, the Heaviside step function has a drawback: it
    has a discontinuity at *x* = 0 and is *not differentiable*. Why is differentiability
    important? As we shall see in chapter [8](../Text/08.xhtml#ch-training-neural-networks)
    (and got a glimpse of in section [3.3](../Text/03.xhtml#sec-grad)), optimal training
    of a neural network requires evaluation of the gradient vector of a loss function
    with respect to weights. Since the gradient is nothing but a vector of partial
    derivatives, differentiability is needed for training.'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we discuss a few functions that are differentiable and yet
    can mimic the Heaviside step function. The most significant among them is the
    sigmoid function.
  prefs: []
  type: TYPE_NORMAL
- en: 8.1.1 Sigmoid function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The sigmoid function is named after its characteristic S-shaped curve figure
    [8.1](../Text/08.xhtml#fig-sigmoid1d)). The corresponding equation is
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-01.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.1
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH08_F01_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.1 Graph of a 1D sigmoid function
  prefs: []
  type: TYPE_NORMAL
- en: Parameterized sigmoid function
  prefs: []
  type: TYPE_NORMAL
- en: We can parametrize equation [1.5](../Text/01.xhtml#eq-sigmoid) as
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-02.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.2
  prefs: []
  type: TYPE_NORMAL
- en: This allows us to
  prefs: []
  type: TYPE_NORMAL
- en: Adjust the steepness of the linear portion of the S curve by changing *w*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adjust the position of the curve by changing *b*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figure [8.2](#fig-sigmoid-parameterized) shows how the parametrized sigmoid
    curve changes with different values for the parameters *w* and *b*. In particular,
    note that for large values of *w*, the parameterized sigmoid is virtually indistinguishable
    from the Heaviside step function (compare the dotted curve in figure [8.2a](#fig-sigmoid-parameterized-various-ws)
    with figure [7.7](../Text/07.xhtml#fig-step-1D)), even though it remains differentiable.
    This is exactly what we desire in neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH08_F02_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.2 Sigmoid curves corresponding to various parameter values in equation
    [8.2](../Text/08.xhtml#eq-sigmoid-parameterized)
  prefs: []
  type: TYPE_NORMAL
- en: Some properties of the sigmoid function
  prefs: []
  type: TYPE_NORMAL
- en: The sigmoid function has several interesting properties, some of which are listed
    here with proof outlines.
  prefs: []
  type: TYPE_NORMAL
- en: '*Expression with positive x*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-03.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.3
  prefs: []
  type: TYPE_NORMAL
- en: This expression can be easily proved by multiplying both the numerator and denominator
    of equation [1.5](../Text/01.xhtml#eq-sigmoid) by *e[x]*.
  prefs: []
  type: TYPE_NORMAL
- en: '*Sigmoid of negative x*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-04.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.4
  prefs: []
  type: TYPE_NORMAL
- en: '*Derivative of sigmoid*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-05.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.5
  prefs: []
  type: TYPE_NORMAL
- en: Figure [8.3](#fig-sigmoid1d-with-derivative) shows the graph of the derivative
    of the sigmoid superimposed on the sigmoid graph itself. As expected, the derivative
    has its maximum value at the middle of the sigmoid curve (where the sigmoid is
    climbing more or less linearly) and is near zero at both ends (where the sigmoid
    is saturated and flat, hardly changing).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH08_F03_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.3 Graph of a 1D sigmoid function (solid curve) and its derivative (dashed
    curve)
  prefs: []
  type: TYPE_NORMAL
- en: 8.1.2 Tanh function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH08_F04_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.4 Graph of a 1D tanh function.
  prefs: []
  type: TYPE_NORMAL
- en: An alternative to the sigmoid function is the *hyperbolic tangent* tanh function,
    shown in figure [8.4](#fig-tanh1d). It is very similar to the sigmoid function,
    but the range of output values is from [‚àí1,1] as opposed to [0,1]. In essence,
    it is the sigmoid function stretched and shifted so it is centered around 0\.
    The equation of the tanh function is given by
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-06.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.6
  prefs: []
  type: TYPE_NORMAL
- en: 'Why is tanh preferred over sigmoid? To understand this, consider figure [8.5](#fig-derivative-sigmoid-tanh-1d).
    It compares the derivatives of the sigmoid and tanh functions. As the plot shows,
    the derivative (gradient) of the function near *x* = 0 is much higher for tanh
    than for sigmoid. Stronger gradients mean faster convergence, as the weight updates
    happen in larger steps. Note that this holds mainly when the data is centered
    around 0: in most preprocessing steps, we standardize the data (make it 0 mean)
    before feeding it into the neural network.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH08_F05_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.5 Graph of the derivatives of 1D sigmoid and tanh functions
  prefs: []
  type: TYPE_NORMAL
- en: 8.2 Why layering?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In section [7.5](../Text/07.xhtml#sec-layering), we encountered the idea of
    *layering* as the preferred way to organize multiple perceptrons. The main property
    of a layered network is that neurons in any layer take their input only from the
    outputs of the preceding layer. This means connections exist only between successive
    layers. No other connection exists in the MLP, which greatly simplifies the evaluation
    and training of the network, which will become apparent as we discuss forward
    propagation and backpropagation.
  prefs: []
  type: TYPE_NORMAL
- en: Why have layers at all? We have seen that multiple perceptrons allow us to model
    problems that cannot be solved by a single perceptron (such as the XOR problem
    discussed in section [7.4.1](../Text/07.xhtml#sec-mlp-xor)). In theory, it is
    possible to model all mathematical functions (and hence solve all quantifiable
    problems) with neurons organized in a single hidden layer (see Cybenko‚Äôs theorem
    and proof in section [7.5.3](../Text/07.xhtml#sec-cybenko-uat)). However, that
    does not mean a single hidden layer is the most *efficient* way of doing all modelings.
    We can often model complicated problems with *fewer* perceptrons if we organize
    them in more than one layer.
  prefs: []
  type: TYPE_NORMAL
- en: Why do extra layers help? The primary reason is the extra nonlinearity. Each
    layer brings in its own nonlinear (such as sigmoid) function. Nonlinear functions,
    with proper parametrization, can model more complicated functions. Hence, a larger
    count of nonlinear functions in the model typically implies greater expressive
    power.
  prefs: []
  type: TYPE_NORMAL
- en: 8.3 Linear layers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Various types of layers are used in popular neural network architectures. In
    subsequent chapters, we shall look at different kinds of layers, such as convolution
    layers. But in this section, we examine the simplest and most basic type of layer:
    the *linear* layer. Here every perceptron from the previous layer is connected
    to every perceptron in the next layer. Such a layer is also known as *fully connected*
    layer. Thus if the previous layer has *m* neurons and the next layer has *n* neurons,
    there are *mn* connections, each with its own weight.'
  prefs: []
  type: TYPE_NORMAL
- en: NOTE We use the words *neuron* and *perceptron* interchangeably.
  prefs: []
  type: TYPE_NORMAL
- en: Figure [8.6](#fig-linear-layer) shows a linear layer that is a slice of a bigger
    MLP. Figure [8.7](#fig-full-MLP-with-linear-layer) shows a bigger MLP with a linear
    layer. Consistent with previous chapters, we have used superscripts for layer
    IDs and subscripts for source and destination IDs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The weight of the connection from the *k*th neuron in layer (*l* ‚àí 1) to the
    *j*th neuron in layer *l* is denoted *w[jk]*^((*l*)). Here the subscript ordering
    is the destination (*j*) followed by the source (*k*). This is slightly counterintuitive
    but universally followed because it simplifies the matrix notation (described
    shortly). Note the following:'
  prefs: []
  type: TYPE_NORMAL
- en: We have split a single perceptron (weighted sum followed by sigmoid) into two
    separate layers, weighted sum and sigmoid.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have used sigmoid instead of Heaviside as the nonlinear function.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 8.3.1 Linear layers expressed as matrix-vector multiplication
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Let‚Äôs revisit the perceptron in the context of the MLP. As we saw in equation
    [7.3](../Text/07.xhtml#eq-perceptron), a single perceptron takes a weighted sum
    of its inputs and then performs a step function on the result. In an MLP, the
    inputs to any perceptron in the *l*th layer come from the previous layer: the
    (*l* ‚àí 1)th layer.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH08_F06_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.6 Linear layer outputting layer *l* from layer (*l* ‚àí 1). The weights
    belonging to row 1 of the weight matrix (coming from all the input neurons, layer
    (*l* ‚àí 1), which sum together to form output neuron 1) are shown in bold.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH08_F07_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.7 Multilayered neural networks: This is a complete deep neural network,
    a slice of which is shown in figure [8.6](#fig-linear-layer).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let *a*[0]^((*l* ‚àí 1)), *a*[1]^((*l* ‚àí 1)), ‚ãØ, *a[m]*^((*l* ‚àí 1)) denote the
    outputs of the *m* neurons in layer (*l* ‚àí 1) (the left-most input column of nodes
    in figure [8.6](#fig-linear-layer)). And let *a*[0]^((*l*)), *a*[1]^((*l*)), ‚ãØ,
    *a[n]*^((*l*)) denote the outputs of the *n* neurons in layer *l*. Note that we
    typically use the symbol *a*, standing for activation, to denote the output of
    individual neurons. Now consider the *j*th neuron in layer *l*. For instance,
    check *z*[1]^((*l*)) in figure [8.6](#fig-linear-layer): note the weights going
    into it and the activations at their source. Its output is *a[j]*^((*l*)), where'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-06-a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We can rewrite the summation in these equations as a dot product between the
    weight and activation vectors:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-06-b.png)'
  prefs: []
  type: TYPE_IMG
- en: The complete set of equations for all *j*s together can be written in a super-compact
    way using matrix-vector multiplication,
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-07.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.7
  prefs: []
  type: TYPE_NORMAL
- en: where
  prefs: []
  type: TYPE_NORMAL
- en: '*W*^((*l*)) is an *n* √ó *m* matrix representing the weights of *all connections
    from layer *l* ‚àí 1 to layer l*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-08.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.8
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/AR_a.png)^((*l*)) represents the activations for the
    entire layer *l*. Applying the sigmoid function to a vector is equivalent to applying
    it individually to each element of the vector:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-08-a.png)'
  prefs: []
  type: TYPE_IMG
- en: The matrix-vector notation saves us from dealing with subscripts by working
    with all the weights, biases, activations, and so on in a *global fashion*.
  prefs: []
  type: TYPE_NORMAL
- en: 8.3.2 Forward propagation and grand output functions for an MLP of linear layers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Equation [8.7](../Text/08.xhtml#eq-linlayer-forwardprop) describes the forward
    propagation of a single linear layer. The final output of an MLP with fully connected
    (aka linear) layers 0‚ãØ*L* on input ![](../../OEBPS/Images/AR_x.png) can be obtained
    by repeated application of this equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '*MLP*(![](../../OEBPS/Images/AR_x.png)) = ![](../../OEBPS/Images/AR_a.png)^((*L*))
    = *y* = *œÉ*(*W*^((*L*))‚Ä¶*œÉ*(*W*^((1))*œÉ*(*W*^((0))![](../../OEBPS/Images/AR_x.png)
    + ![](../../OEBPS/Images/AR_b.png)^((0)))+![](../../OEBPS/Images/AR_b.png)^((1)))‚ãØ+![](../../OEBPS/Images/AR_b.png)^((*L*)))'
  prefs: []
  type: TYPE_NORMAL
- en: Equation 8.9
  prefs: []
  type: TYPE_NORMAL
- en: 'In a computer implementation, this expression is evaluated step by step by
    repeated application of the linear layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-10.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.10
  prefs: []
  type: TYPE_NORMAL
- en: It‚Äôs easy to see that equation [8.10](#eq-forwardprop-layered) is a restatement
    of equation [8.7](../Text/08.xhtml#eq-linlayer-forwardprop).
  prefs: []
  type: TYPE_NORMAL
- en: Close examination of these equations reveals a beautiful property. The complicated
    equation [8.9](#eq-MLP-out-nosubscript) is *never explicitly evaluated*. Instead,
    we evaluate the outputs of successive layers, one layer at a time, as per equation
    [8.10](#eq-forwardprop-layered). Every layer can be evaluated by taking the previous
    layer‚Äôs output as input. No other input is necessary. That is to say, we can evaluate
    ![](../../OEBPS/Images/AR_a.png)^((0)) directly from the input ![](../../OEBPS/Images/AR_x.png),
    then ![](../../OEBPS/Images/AR_a.png)^((1)) from ![](../../OEBPS/Images/AR_a.png)^((0)),
    ![](../../OEBPS/Images/AR_a.png)^((2)) from ![](../../OEBPS/Images/AR_a.png)^((1)),
    and so forth, all the way to ![](../../OEBPS/Images/AR_a.png)^((*L*)) (which is
    the grand output of the MLP). During the evaluation, we need to keep only the
    previous and current layers in memory at any given time. This process greatly
    simplifies the implementation as well as the conceptualization and is known as
    *forward propagation*.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 8.1 PyTorch code for forward propagation
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '‚ë† x: activation of layer l-1 (1-d vector) *W[l]*: Weight matrix of layer l
    *b[l]*: Bias vector of layer l'
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë° Sigmoid activation function (nonlinear layer)
  prefs: []
  type: TYPE_NORMAL
- en: '‚ë¢ x: 1-d input vector W: list of matrices for layers 0 to L. b: list of vectors
    for layers 0 to L'
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë£ Loops through layers 0 to L
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë§ Computes Z
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë• Computes activation
  prefs: []
  type: TYPE_NORMAL
- en: 8.4 Training and backpropagation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Throughout the book, we have been discussing bits and pieces of this process.
    In sections [1.1](../Text/01.xhtml#alg-supervised_training) and [3.3](../Text/03.xhtml#sec-grad)
    (specifically, algorithm 3.1 ), we saw an overview of the process for training
    a supervised model (you are encouraged to reread those if necessary). Training
    is an iterative process by which the parameters of the neural network are estimated.
    The goal is to estimate the parameters (weights and biases) such that on the training
    inputs, the neural network outputs are close as possible to the known ground-truth
    outputs.
  prefs: []
  type: TYPE_NORMAL
- en: In general, iterative processes improve (get closer to the goal) gradually.
    In each iteration, we make small adjustments to the parameters. Here, *parameter*
    refers to the weights and biases of the MLP, the *w[jk]*^((*l*))s and *b[j]*^((*l*))s
    from section [8.2](#sec-linlayer-forwardprop). We keep adjusting the parameters
    so that in every iteration, the outputs on training data inputs come a little
    closer to the ground truth (GT). Eventually, after many iterations, we hopefully
    converge to optimal values. Note that there is no guarantee that the iterative
    process will converge to the best possible parameter values. The training might
    go completely astray or get stuck in a local minimum. (Local minima are explained
    in section [3.6](../Text/03.xhtml#sec-locglob-minima); you are encouraged to reread
    it if necessary.) There is no good way to know whether we have reached optimal
    values (global minima) for the weights and biases. We typically run the neural
    network on test data, and if the results are satisfactory, we stop training. Test
    data should be *held back* during training, meaning we should never use test data
    to train. In the unfortunate event that the network has not reached the desired
    level of accuracy, we typically throw in more training data and/or try a modified
    loss function and/or a different architecture. Simply retraining the network from
    a different random start may also work. This is an experimental science with a
    lot of trial and error.
  prefs: []
  type: TYPE_NORMAL
- en: How do we know how to adjust the parameter values in each iteration? We define
    a loss (aka error) function. There are many popular formulations of loss functions,
    and we review many of them later, but their common property is that when the neural
    network output agrees more with the known output (GT), the loss becomes lower,
    and vice versa. Thus if *y* denotes the output of the neural network and *»≥* is
    the GT, a reasonable expression for the loss is the *mean squared error* (MSE)
    function (*y* ‚àí *»≥*)¬≤. For now, we use the MSE loss as our representative loss
    function. Later we discuss others.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the loss function is defined, we have a crisp, quantitative definition
    of the goal of neural network training. The goal is to minimize the total loss
    over the entire training data set. Note the clause *entire training data set*:
    we do not want to do well on one or two input instances at the cost of doing badly
    over the rest. If we have to choose between a solution that gives 10% error on
    all of, say, 100 training input instances versus one that yields 0% error on 50
    training input instances but 40% on the remaining 50, we prefer the former.'
  prefs: []
  type: TYPE_NORMAL
- en: Each weight in the MLP, *w[jk]*^((*l*)), is adjusted by an amount proportional
    to *Œ¥w[jk]*^((*l*)). Similarly, each bias *b[j]*^((*l*)) is adjusted by an amount
    proportional to *Œ¥b[j]*^((*l*)). We can denote all this compactly by saying we
    have a weight vector ![](../../OEBPS/Images/AR_w.png) and bias vector ![](../../OEBPS/Images/AR_b.png).
    In each iteration, we change ![](../../OEBPS/Images/AR_w.png) by amount *Œ¥*![](../../OEBPS/Images/AR_w.png)
    and ![](../../OEBPS/Images/AR_b.png) by *Œ¥*![](../../OEBPS/Images/AR_b.png) so
    that their new values are ![](../../OEBPS/Images/AR_w.png) ‚àí *rŒ¥*![](../../OEBPS/Images/AR_w.png)
    and ![](../../OEBPS/Images/AR_b.png) ‚àí *rŒ¥*![](../../OEBPS/Images/AR_b.png) *r*
    is a constant known as the *learning rate* that needs to be set at the beginning
    of training). In this context, it is worthwhile to note that in section [8.3.1](#sec-linlayer-matmult),
    we expressed the collection of weights in an MLP with a matrix, while here we
    are referring to the same thing as a vector. These are not incompatible because
    we can always rasterize the elements of a matrix (that is, walk over the elements
    of the matrix from top to bottom and from left to right) into a vector.
  prefs: []
  type: TYPE_NORMAL
- en: How do we estimate the adjustment amounts *Œ¥*![](../../OEBPS/Images/AR_w.png)
    and *Œ¥*![](../../OEBPS/Images/AR_b.png)? This is where the notion of gradients
    comes in. These were discussed in detail in sections [3.3.1](../Text/03.xhtml#sec-gradient),
    [3.3.2](../Text/03.xhtml#subsec-level-surf), and [3.5](../Text/03.xhtml#sec-gradient-descent)
    (again, you are encouraged to reread if necessary). In general, if a loss, denoted
    ùïÉ, is expressed as a function of the parameters, such as ùïÉ(![](../../OEBPS/Images/AR_w.png),
    ![](../../OEBPS/Images/AR_b.png)), then the change in the parameters that optimally
    takes us toward lower loss is yielded by the gradient of the loss with respect
    to the parameters ‚àá[![](../../OEBPS/Images/AR_w.png), *b*]ùïÉ(![](../../OEBPS/Images/AR_w.png),
    *b*). The high-level process is described later in the chapter in algorithm [3.2](../Text/03.xhtml#alg-supervised_training_detailed).
    Here we look at the guts of it.
  prefs: []
  type: TYPE_NORMAL
- en: '8.4.1 Loss and its minimization: Goal of training'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Given a training data set ùïã that is a set of <input, GT output> pairs ùïã = {‚ü®![](../../OEBPS/Images/AR_x.png),
    *»≥*‚ü©}, the loss can be expressed as
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-11.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.11
  prefs: []
  type: TYPE_NORMAL
- en: where
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/AR_y.png) = *MLP*(![](../../OEBPS/Images/AR_x.png))'
  prefs: []
  type: TYPE_IMG
- en: as per equation [8.9](#eq-MLP-out-nosubscript).
  prefs: []
  type: TYPE_NORMAL
- en: 'Now consider equation [8.7](../Text/08.xhtml#eq-linlayer-forwardprop) again.
    We can rasterize each layer‚Äôs weight matrix *W*^((*l*)) into a vector and then
    concatenate all these vectors from successive layers to form a giant weight vector
    ![](../../OEBPS/Images/AR_w.png), the vector of all weights in the MLP:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-11-a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Similarly, we can form a giant vector of all biases in the MLP:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-11-b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The ultimate goal of training is to find ![](../../OEBPS/Images/AR_w.png) and
    ![](../../OEBPS/Images/AR_b.png) that will minimize the loss ùïÉ. In chapter [3](../Text/03.xhtml#chapter-intro-vec-mat),
    we saw that we can solve for the minimum by setting the gradients ‚àá[![](../../OEBPS/Images/AR_w.png)]ùïÉ
    = 0 and ‚àá[![](../../OEBPS/Images/AR_b.png)]ùïÉ = 0. Computing the loss gradient
    from a combination of equations [8.9](#eq-MLP-out-nosubscript) and [8.11](../Text/08.xhtml#eq-mse-loss)
    is intractable. Instead, we go for an iterative solution: *gradient descent* on
    the loss surface, as described in the next section.'
  prefs: []
  type: TYPE_NORMAL
- en: Listing 8.2 PyTorch code for MSE loss
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '‚ë† a: Activation of layer L (1D vector) : Ground truth (1D vector)'
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë° See equation [8.11](../Text/08.xhtml#eq-mse-loss).
  prefs: []
  type: TYPE_NORMAL
- en: 8.4.2 Loss surface and gradient descent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Geometrically, the loss function ùïÉ(![](../../OEBPS/Images/AR_w.png), ![](../../OEBPS/Images/AR_b.png))
    can be viewed as a surface in a high-dimensional space. The domain of this space
    corresponds to all the dimensions in ![](../../OEBPS/Images/AR_w.png) plus all
    the dimensions in ![](../../OEBPS/Images/AR_b.png). This is shown in figure [8.8](../Text/08.xhtml#fig-gradient-descent-3d)
    with a 2D domain. In chapter [3](../Text/03.xhtml#chapter-intro-vec-mat), we also
    saw that given a function ùïÉ(![](../../OEBPS/Images/AR_w.png), ![](../../OEBPS/Images/AR_b.png)),
    the best way to progress toward the minimum is to walk on the parameter space
    along the negative gradient. We adopt this approach to minimize the loss. We compute
    the gradients of the loss function with respect to weights and biases and update
    the weights and bias vectors by an amount proportional to the (negative) of these
    gradients. Doing this repeatedly takes us close to the minimum. In figure [8.8](../Text/08.xhtml#fig-gradient-descent-3d),
    the gradient descent path is shown with solid arrows, while an arbitrary non-optimal
    path to the minimum is shown with dashed arrows.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH08_F08_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.8 A representative loss ùïÉ(*w*, *b*). Note that ![](../../OEBPS/Images/AR_w.png)
    and ![](../../OEBPS/Images/AR_b.png) have each been reduced to 1D for this .
  prefs: []
  type: TYPE_NORMAL
- en: Thus the equations for updating weights and biases in gradient descent are
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-12.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.12
  prefs: []
  type: TYPE_NORMAL
- en: where *r* is a constant. Here
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-13.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.13
  prefs: []
  type: TYPE_NORMAL
- en: The vector update equation [8.12](../Text/08.xhtml#eq-wtsbiases-update-vector)
    can be expressed in terms of the scalar components as
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-14.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.14
  prefs: []
  type: TYPE_NORMAL
- en: Note that we have to reevaluate these partial derivatives in each iteration
    since their values will change in every iteration.
  prefs: []
  type: TYPE_NORMAL
- en: 8.4.3 Why a gradient provides the best direction for descent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Why does updating along the gradient reduce the function optimally? This is
    discussed in detail in chapter [3](../Text/03.xhtml#chapter-intro-vec-mat). Here
    we briefly recap the idea. Using multidimensional Taylor expansion, we can evaluate
    a function in the neighborhood of a known point. For instance, we can evaluate
    ùïÉ(![](../../OEBPS/Images/AR_w.png) + *Œ¥*![](../../OEBPS/Images/AR_w.png)) for
    small offset *Œ¥*![](../../OEBPS/Images/AR_w.png) from ![](../../OEBPS/Images/AR_w.png)
    as follows
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-15.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.15
  prefs: []
  type: TYPE_NORMAL
- en: 'where *H*, called the *Hessian matrix*, is defined as in equation [3.9](../Text/03.xhtml#eq-hessian).
    Since we are not going too far from ![](../../OEBPS/Images/AR_w.png), ||*Œ¥*![](../../OEBPS/Images/AR_w.png)||
    is small. This means the quadratic and higher-order terms are negligibly small,
    and we can drop them (the approximation is perfect in the limit when ||*Œ¥*![](../../OEBPS/Images/AR_w.png)||
    ‚Üí 0):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-15-a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'But we know the dot product (![](../../OEBPS/Images/AR_delta.png))*^T* ‚ñΩ![](../../OEBPS/Images/AR_w.png)ùïÉ
    will attain its maximum value when both the vectors point in the same direction:
    that is,'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-15-b.png)'
  prefs: []
  type: TYPE_IMG
- en: for some constant of proportionality *r*.
  prefs: []
  type: TYPE_NORMAL
- en: In implementation, *r* is called the *learning rate*. A higher learning rate
    causes the optimization to progress more rapidly but also runs the risk of overshooting
    the minimum. We learn about these in more detail later. For now, simply note that
    *r* is a *tunable hyperparameter* of the system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Thus, the largest decrease in value from ùïÉ(![](../../OEBPS/Images/AR_w.png))
    to ùïÉ(![](../../OEBPS/Images/AR_w.png) ‚Äì ![](../../OEBPS/Images/AR_delta.png))
    happens when *Œ¥*![](../../OEBPS/Images/AR_w.png) is along the negative gradient.
    This is why we move toward the negative gradient in gradient descent: it is the
    fastest way to reach the minimum. The straight arrows in figure [8.8](../Text/08.xhtml#fig-gradient-descent-3d)
    illustrate the direction of the gradient. The dashed arrows show an arbitrary
    nongradient path for comparison.'
  prefs: []
  type: TYPE_NORMAL
- en: We can deal with the bias vector ![](../../OEBPS/Images/AR_b.png) similarly.
  prefs: []
  type: TYPE_NORMAL
- en: 8.4.4 Gradient descent and local minima
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We should note that gradient descent can get stuck in a *local minimum*. Figure
    [8.9](../Text/08.xhtml#fig-non-convex-local-minima) shows this.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH08_F09_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.9 A nonconvex function with local and global minima. Depending on the
    point, gradient descent will take us to one or the other.
  prefs: []
  type: TYPE_NORMAL
- en: 'In earlier eras, optimization techniques tried hard to avoid local minima and
    converge to the global minimum. Techniques like simulated annealing and tunneling
    were carefully designed to avoid local minima. Modern-day neural networks have
    adopted a different attitude: they do not try very hard to avoid local minima.
    Sometimes a local minimum is an acceptable (accurate enough) solution. Otherwise,
    we can retrain the neural network: it will start from a random position, so this
    time it may go to a better minimum.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/CH08_F10_Chaudhury.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.10 MLP with layers 0, ‚Ä¶, *L*, one neuron per layer. Again, we have
    split every layer into a weighted sum and a sigmoid.
  prefs: []
  type: TYPE_NORMAL
- en: 8.4.5 The backpropagation algorithm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have seen that gradient descent progresses by repeatedly updating the weights
    and biases via equation [8.12](../Text/08.xhtml#eq-wtsbiases-update-vector). This
    is equivalent to repeatedly updating individual weights and biases using individual
    partial derivatives via equation [8.14](#eq-wtsbiases-update-scalar).
  prefs: []
  type: TYPE_NORMAL
- en: Obtaining a closed-form solution for the gradients ‚àá[![](../../OEBPS/Images/AR_w.png)]ùïÉ(![](../../OEBPS/Images/AR_w.png),
    ![](../../OEBPS/Images/AR_b.png)), ‚àá[![](../../OEBPS/Images/AR_b.png)]ùïÉ(![](../../OEBPS/Images/AR_w.png),
    ![](../../OEBPS/Images/AR_b.png)) from equations [8.9](#eq-MLP-out-nosubscript)
    and [8.11](../Text/08.xhtml#eq-mse-loss)‚Äîor, equivalently, obtaining a closed-form
    solution for the partial derivatives *‚àÇ*ùïÉ/*‚àÇw[jk]*^((*l*)), *‚àÇ*ùïÉ/*‚àÇb[j]*^((*l*)),
    ‚Äîis very difficult. Backpropagation is an algorithm that allows us to evaluate
    the gradients and update the weights and biases one layer at a time, like forward
    propagation (equation [8.10](#eq-forwardprop-layered)).
  prefs: []
  type: TYPE_NORMAL
- en: Backpropagation algorithm on a simple network
  prefs: []
  type: TYPE_NORMAL
- en: We first discuss backpropagation on a simple MLP with only a single neuron per
    layer. The main simplification resulting from this is that individual weights
    and biases no longer need subscripts, with only one weight and one bias between
    two successive layers. They still need superscripts to indicate layer IDs, however.
    Figure [8.10](#fig-MLP-one-neuron-per-layer) shows this MLP. We use MSE loss (equation
    [8.11](../Text/08.xhtml#eq-mse-loss)), but we work on a single input-output pair
    *x[i]*, *y[i]*. The total loss (summation over all the training data instances)
    can easily be derived by repeating the same steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'We first define an auxiliary variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-15-c.png)'
  prefs: []
  type: TYPE_IMG
- en: The physical significance of *Œ¥*^((*l*)) is that it is the rate of change of
    the loss with the (pre-activation) output of layer *l* (remember, in this network,
    layer *l* has a single neuron).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let‚Äôs establish a few important equations for the MLP in figure [8.10](#fig-MLP-one-neuron-per-layer):'
  prefs: []
  type: TYPE_NORMAL
- en: '*Forward propagation for an arbitrary layer* *l* ‚àà {0, *L*}'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-16.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.16
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-17.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.17
  prefs: []
  type: TYPE_NORMAL
- en: '*Loss*‚ÄîHere we are working with a single training data instance, *x[i]*, whose
    GT output is *»≥[i]*:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-17-a.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Partial derivative of loss with respect to the weight and bias in terms of
    an auxiliary variable for the last layer, L*‚ÄîUsing the chain rule for partial
    derivatives,'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-17-b.png)'
  prefs: []
  type: TYPE_IMG
- en: Examining the terms on the right, we see
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-17-c.png)'
  prefs: []
  type: TYPE_IMG
- en: (auxiliary variable for layer *L*). And using the forward propagation equations,
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-17-d.png)'
  prefs: []
  type: TYPE_IMG
- en: Together, they lead to
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-17-e.png)'
  prefs: []
  type: TYPE_IMG
- en: Similarly,
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-17-f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Consequently, we have the following pair of equations expressing the partial
    derivative of loss with respect to weight and bias, respectively, in terms of
    the auxiliary variable for the last layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-18.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.18
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-19.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.19
  prefs: []
  type: TYPE_NORMAL
- en: '*Auxiliary variable for the last layer, L*‚ÄîUsing the chain rule for partial
    derivatives,'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-19-a.png)'
  prefs: []
  type: TYPE_IMG
- en: Using equation [8.5](../Text/08.xhtml#eq-sigmoid-derivative) for the derivative
    of a sigmoid, we get
  prefs: []
  type: TYPE_NORMAL
- en: '*Œ¥*^((*L*)) = (*a*^((*L*))‚àí*»≥[i]*) *œÉ*(*z*^((*L*)))(1‚àí*œÉ*(*z*^((*L*))))'
  prefs: []
  type: TYPE_NORMAL
- en: which, using equation [8.17](#eq-forwardprop-a-simple), leads to
  prefs: []
  type: TYPE_NORMAL
- en: '*Œ¥*^((*L*)) = (*a*^((*L*))‚àí*»≥[i]*) *a*^((*L*))(1‚àí*a*^((*L*)))'
  prefs: []
  type: TYPE_NORMAL
- en: Equation 8.20
  prefs: []
  type: TYPE_NORMAL
- en: '*Partial derivative of the loss with respect to the weight and bias in terms
    of an auxiliary variable for an arbitrary layer l*‚ÄîUsing the chain rule for partial
    derivatives,'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-20-a.png)'
  prefs: []
  type: TYPE_IMG
- en: Using the definition of the auxiliary variable and the forward propagation equation
    [8.16](#eq-forwardprop-z-simple), this leads to
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-21.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.21
  prefs: []
  type: TYPE_NORMAL
- en: Similarly,
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-21-a.png)'
  prefs: []
  type: TYPE_IMG
- en: Using the definition of the auxiliary variable and the forward propagation equation
    [8.16](#eq-forwardprop-z-simple), this leads to
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-22.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.22
  prefs: []
  type: TYPE_NORMAL
- en: '*Auxiliary variable for an arbitrary layer, l*‚ÄîUsing the chain rule for partial
    derivatives,'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-22-a.png)'
  prefs: []
  type: TYPE_IMG
- en: Using the definition of the auxiliary variable and the forward propagation equation
    [8.16](#eq-forwardprop-z-simple), this leads to
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-22-b.png)'
  prefs: []
  type: TYPE_IMG
- en: which yields
  prefs: []
  type: TYPE_NORMAL
- en: '*Œ¥*^((*l*)) = *Œ¥*^((*l*+1)) *w*^((*l*+1)) *a*^((*l*))(1‚àí*a*^((*l*)))'
  prefs: []
  type: TYPE_NORMAL
- en: Equation 8.23
  prefs: []
  type: TYPE_NORMAL
- en: 'We first encountered the one-layer-at-a-time property in section [8.3.2](#sec-layered-forwardprop)
    in connection with the forward propagation equations. Let‚Äôs recap that in the
    context of training our simple network. Consider equations [8.16](#eq-forwardprop-z-simple)
    and [8.17](#eq-forwardprop-a-simple). We initialize the system with some values
    of weights *w*^((*l*)) and biases *b*^((*l*)). Using those, we can evaluate the
    layer 0 outputs. For starters, we can evaluate *z*^((0)) and *a*^((0)) easily
    (since all the inputs are known):'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-23-a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Once we have *z*^((0)) and *a*^((0)), we can use them to evaluate *z*^((1))
    and *a*^((1)) via equations [8.16](#eq-forwardprop-z-simple) and [8.17](#eq-forwardprop-a-simple).
    But if we have *z*^((1)) and *a*^((1)), we can use them to evaluate *z*^((2))
    and *a*^((2)) via equations [8.16](#eq-forwardprop-z-simple) and [8.17](#eq-forwardprop-a-simple)
    again. And we can proceed in this fashion up to layer *L* to obtain *a*^((*L*)),
    which is the grand output of the MLP. In other words, we can iteratively evaluate
    the outputs of successive layers using *only* the outputs from the previous layer.
    No other layers need to be known. At any given iteration, we only have to keep
    the previous layer in memory: we can build the current layer from that. A single
    sequence of applications of equations [8.16](#eq-forwardprop-z-simple) and [8.17](#eq-forwardprop-a-simple)
    for layers 0 to *L* is known as a *forward pass*.'
  prefs: []
  type: TYPE_NORMAL
- en: A similar trick can be applied to evaluate the auxiliary variables, except we
    go *backward*. We can evaluate the auxiliary variable for the last layer, *Œ¥*^((*L*)),
    via equation [8.20](#eq-aux-lastlayer-simple). But once we have *Œ¥*^((*L*)), we
    can evaluate *Œ¥*^((*L* ‚àí 1)) via equation [8.23](#eq-aux-simple). From that, we
    can evaluate *Œ¥*^((*L* ‚àí 2)). We can proceed in this fashion all the way to layer
    0, evaluating successively *Œ¥*^((*L*)), *Œ¥*^((*L* ‚àí 1)), ‚ãØ, *Œ¥*^((0)). Every time
    we evaluate a *Œ¥*^((*l*)), we can also evaluate the *‚àÇ*ùïÉ**/***‚àÇw*^((*l*)) and
    *‚àÇ*ùïÉ**/***‚àÇb*^((*l*)) for the same layer via equations [8.21](#eq-dw-aux-simple)
    and [8.22](#eq-db-aux-simple), respectively. We can also update the weight and
    bias of that layer right there using the just estimated partial derivatives, since
    the current values will never be needed again during training. Thus, starting
    from the last layer, we can update the weights and biases of all layers until
    layer 0 in this fashion. This is *backpropagation*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Of course, we have to proceed in tandem: one forward propagation which sets
    the values of *z*s and *a*s) for layers 0 to *L*, followed by a backpropagation
    layer for *L* to 0. Repeat these steps until convergence.'
  prefs: []
  type: TYPE_NORMAL
- en: NOTE Fully functional code for forward propagation, MSE loss, and backpropagation,
    executable via Jupyter Notebook, can be found at [http://mng.bz/pJrw](http://mng.bz/pJrw).
  prefs: []
  type: TYPE_NORMAL
- en: Listing 8.3 PyTorch code for forward and backward propagation
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: ‚ë† Forward propagation
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë° Computes MSE loss
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë¢ Arrays to store *Œ¥*^((*l*)), *‚àÇ*ùïÉ**/***‚àÇw*^((*l*)), *‚àÇ*ùïÉ**/***‚àÇb*^((*l*))
    for layers 0 to *L*
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë£ Activation of the last layer - *a*^((*L*))
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë§ Computes the *Œ¥* and gradients for layer *L*
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë• Computes the *Œ¥* and gradients for layers 0 to *L* ‚àí 1
  prefs: []
  type: TYPE_NORMAL
- en: Backpropagation algorithm on an arbitrary network of linear layers
  prefs: []
  type: TYPE_NORMAL
- en: In section [8.4.5.1](#sec-backprop-simplenet), we saw a simple network with
    only one neuron per layer. There was only one connection and hence one weight,
    one activation, and one auxiliary variable per layer. Consequently, we could drop
    the subscripts (although we had to keep the superscript indicating the layer)
    of all these variables. Now we examine a more generic network consisting of linear
    layers 0, ‚ãØ, *L*. An arbitrary slice of this network is shown in figure [8.6](#fig-linear-layer).
  prefs: []
  type: TYPE_NORMAL
- en: The ultimate goal is to evaluate the partial derivatives of the loss with respect
    to the weights and biases. Using them, we can update the current weights and biases
    to optimally reduce the loss.
  prefs: []
  type: TYPE_NORMAL
- en: Our overall strategy is as follows. We use the auxiliary variables again. We
    first derive expressions that allow us to compute the auxiliary variable for the
    last layer. Then we derive an expression that allows us to compute auxiliary variables
    for an arbitrary layer, *l*, given the auxiliary variables for layer *l* + 1.
    Since we can directly compute auxiliary variables for the last layer, *L*, we
    can use this expression to compute auxiliary variables for the second-to-last
    layer *L* ‚àí 1. But once we have them, we can compute auxiliary variables for layer
    *L* ‚àí 2. We proceed like this until we reach layer 0. Thus we can compute all
    the auxiliary variables. We also derive expressions that allow us to compute,
    from the auxiliary variables, the partial derivatives of loss with respect to
    weights and biases. This gives us everything we need. Since we start by computing
    things pertaining to the last layer and proceed iteratively toward the initial
    layer, the process is called *backpropagation*.
  prefs: []
  type: TYPE_NORMAL
- en: 'You will notice the similarity between the expressions derived next and those
    derived for the one-neuron-per-layer network. The differences are explained:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Forward propagation (arbitrary layer l)*‚ÄîForward propagation through this
    network has already been described in section [8.3.1](#sec-linlayer-matmult) and
    can be succinctly represented by equation [8.7](../Text/08.xhtml#eq-linlayer-forwardprop)
    repeated here for handy reference). On the left are the scalar equations, for
    one neuron at a time; and on the right are the vector equations, for the entire
    layer. They are equivalent:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-24.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.24
  prefs: []
  type: TYPE_NORMAL
- en: Indices *j* and *k* iterate over all the neurons in the relevant layer. By convention,
    we always use these variables for arbitrary neurons in a layer. The variable *l*
    is used to index the layers. When indexing weights, we typically use *j* to indicate
    the destination and *k* to indicate the source‚Äîremember that weights are indexed
    (destination, source) somewhat unexpectedly to simplify the math. Typically, vectors
    correspond to entire layers. Individual vector elements correspond to specific
    neurons and are indexed by *j* or *k*.
  prefs: []
  type: TYPE_NORMAL
- en: '*Loss*‚ÄîUnlike the simple network, here, the final *L*th layer can have multiple
    neurons. Hence the loss function becomes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-25.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.25
  prefs: []
  type: TYPE_NORMAL
- en: 'where the summation happens over all neurons in the last layer. Note that ![](../../OEBPS/Images/AR_a.png)^((*L*))
    is the output of the MLP: that is, ![](../../OEBPS/Images/AR_a.png)^((*L*)) =
    ![](../../OEBPS/Images/AR_y.png) = *MLP*(![](../../OEBPS/Images/AR_x.png)) for
    the training input ![](../../OEBPS/Images/AR_x.png) (see equation [8.10](#eq-forwardprop-layered)).
    The GT output corresponding to ![](../../OEBPS/Images/AR_x.png) is the constant
    vector *»≥*. The closer ![](../../OEBPS/Images/AR_y.png) is to *»≥*, the smaller
    the loss. Note that we need to average the loss over the entire training data
    set. Here we are showing the loss computation for a single training data instance.
    The computation simply needs to be replicated for each training data instance,
    and the results averaged.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Auxiliary variables*‚ÄîNow that a layer has multiple neurons, we have one auxiliary
    variable per neuron. Thus the auxiliary variable has a subscript identifying the
    specific neuron in that layer. It continues to have a superscript indicating its
    layer. We define'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-25-a.png)'
  prefs: []
  type: TYPE_IMG
- en: '*Auxiliary variable* *for the last layer*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-25-b.png)'
  prefs: []
  type: TYPE_IMG
- en: Using equation [8.25](#eq-loss-mlp) and observing that only one of the terms
    in the summation‚Äîthe *j*th term‚Äîwill survive the differentiation with respect
    to *a[j]*^((*L*)) since the *a[j]*s are independent of each other), we get
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-25-c.png)'
  prefs: []
  type: TYPE_IMG
- en: Also, using the lower-left equation from [8.24](../Text/08.xhtml#eq-MLP-out-nosubscript-1)
    and equation [8.5](../Text/08.xhtml#eq-sigmoid-derivative), we get
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-25-d.png)'
  prefs: []
  type: TYPE_IMG
- en: Combining these, we get
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-26.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.26
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-27.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.27
  prefs: []
  type: TYPE_NORMAL
- en: Here, ‚àò denotes the Hadamard product between two vectors. It is basically a
    vector of elementwise products of corresponding vector elements. Thus,
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-28.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.28
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-29.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.29
  prefs: []
  type: TYPE_NORMAL
- en: Equations [8.26](#eq-auxvar-last-layer-scalar) and [8.27](#eq-auxvar-last-layer-vector)
    are identical. The former is a scalar equation expressing individual auxiliary
    variables of the last layer. The latter is a vector equation expressing all the
    auxiliary variables of the last layer together. We can compute these directly
    if we have performed a forward pass and have its results, the *a[j]*^((*L*))s
    available along with the training data GT.
  prefs: []
  type: TYPE_NORMAL
- en: '*Auxiliary variable for an arbitrary layer, l*‚ÄîThis is significantly different
    and harder to understand than the one-neuron-per-layer case. We are trying to
    evaluate *Œ¥[j]*^((*l*)) = *‚àÇ*ùïÉ**/***‚àÇz[j]*^((*l*)) in the general case: that is,
    for an arbitrary layer *l*. The loss does not *directly* depend on the inner layer
    variable *z[j]*^((*l*)). The loss directly depends only on the last layer activations,
    which depend on the previous layer, and so forth. The *z*s in any one layer form
    a *complete* dependency set for the loss ùïÉ, meaning the loss can be expressed
    in terms of only these and no other variables. In particular, we can express the
    loss as ùïÉ(*z*[0]^((*l*+1)), *z*[1]^((*l*+1)), *z*[2]^((*l*+1)),‚ãØ). You can form
    a mental picture that *z[j]*^((*l*)) fans out to ùïÉ *through* all the *z*s in the
    next layer, *z*[0]^((*l*+1)), *z*[1]^((*l*+1)), *z*[2]^((*l*+1)), and so on. Then,
    using the chain rule of partial differentiation,'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-29-a.png)'
  prefs: []
  type: TYPE_IMG
- en: Now, by definition,
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-29-b.png)'
  prefs: []
  type: TYPE_IMG
- en: And using equation [8.24](../Text/08.xhtml#eq-MLP-out-nosubscript-1),
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-29-c.png)'
  prefs: []
  type: TYPE_IMG
- en: while
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-29-d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Combining all these, we get the scalar expression for a single auxiliary variable.
    It is presented here along with its equivalent vector equation for the entire
    layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-30.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.30
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-31.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.31
  prefs: []
  type: TYPE_NORMAL
- en: Here, ‚àò denotes the Hadamard multiplication explained earlier and *W*^((+1*l*))
    is the matrix representing the weights of *all connections from layer l to layer
    (*l*+1)* (see equation [8.8](../Text/08.xhtml#eq-MLP-weight-matrix)). Equations
    [8.30](#eq-auxvar-scalar) and [8.31](../Text/08.xhtml#eq-auxvar-vector) allow
    us to evaluate *Œ¥*^((*l*))s from the *Œ¥*^((*l*+1))s if the results of forward
    propagation (*a*s) are available. We have already shown that the auxiliary variables
    for the last layer are directly computable from the activations of that layer.
    Hence, we can evaluate all the layers‚Äô auxiliary variables.
  prefs: []
  type: TYPE_NORMAL
- en: '*Derivatives of loss with respect to weights and biases in terms of auxiliary
    variables*‚ÄîWe have already seen how to compute auxiliary variables. Now we will
    express the partial derivatives of loss with respect to weights and biases in
    terms of those. This will provide us with the gradients we need to update the
    weights and biases along the negative gradient, which is the optimal move to minimize
    loss:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-32.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.32
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-33.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.33
  prefs: []
  type: TYPE_NORMAL
- en: 'Equations [8.32](#eq-partialderiv-loss-wt-scalar) and [8.33](../Text/08.xhtml#eq-partialderiv-loss-wt-vector)
    are equivalent. The first is scalar and pertains to individual weights in layer
    *l*, and the second describes the entire layer. Similarly, equations [8.34](#eq-partialderiv-loss-bias-scalar)
    and [8.35](#eq-partialderiv-loss-bias-vector) are equivalent:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-34.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.34
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-35.png)'
  prefs: []
  type: TYPE_IMG
- en: Equation 8.35
  prefs: []
  type: TYPE_NORMAL
- en: The first is scalar and pertains to individual biases in layer *l*, and the
    second describes the entire layer.
  prefs: []
  type: TYPE_NORMAL
- en: '8.4.6 Putting it all together: Overall training algorithm'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Previously, we discussed forward propagation: passing an input vector ![](../../OEBPS/Images/AR_x.png)
    through a sequence of linear layers and generating an output prediction. We learned
    about MSE loss, ùïÉ, which calculates the deviation of the output prediction from
    the GT, *y*. We also learned to compute the gradients of ùïÉ with respect to parameters
    *W* and *b* using backpropagation. In the following algorithm, we describe how
    these components come together in the training process:'
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 8.5 Training a neural network
  prefs: []
  type: TYPE_NORMAL
- en: Initialize ![](../../OEBPS/Images/AR_w.png), *b* with random values
  prefs: []
  type: TYPE_NORMAL
- en: '**while** ùïÉ > *threshold* **do**'
  prefs: []
  type: TYPE_NORMAL
- en: ‚ä≥ Forward pass
  prefs: []
  type: TYPE_NORMAL
- en: '**for** *l* ‚Üê 0 to *L* **do**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/AR_z.png)^((*l*)) = *W*^((*l*)) ![](../../OEBPS/Images/AR_a.png)^((*l*‚Äì1))
    + ![](../../OEBPS/Images/AR_b.png)^((*l*))'
  prefs: []
  type: TYPE_IMG
- en: '![](../../OEBPS/Images/AR_a.png)^((*l*)) = *œÉ*(![](../../OEBPS/Images/AR_z.png)^((*l*)))'
  prefs: []
  type: TYPE_IMG
- en: '**end** **for**'
  prefs: []
  type: TYPE_NORMAL
- en: ‚ä≥ Loss
  prefs: []
  type: TYPE_NORMAL
- en: ùïÉ = 1/2 ||![](../../OEBPS/Images/AR_a.png)^((*L*)) ‚Äì *»≥*||¬≤
  prefs: []
  type: TYPE_NORMAL
- en: ‚ä≥ Gradients for the last layer
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/AR_delta.png) ^((*L*)) = (![](../../OEBPS/Images/AR_a.png)^((*L*))
    ‚Äì *»≥*) ‚àò ![](../../OEBPS/Images/AR_a.png)^((*L*)) ‚àò (![](../../OEBPS/Images/AR_1.png)
    ‚Äì ![](../../OEBPS/Images/AR_a.png)^((*L*)))'
  prefs: []
  type: TYPE_IMG
- en: ‚ñΩ*W*^((*L*))ùïÉ = ![](../../OEBPS/Images/AR_delta.png) ^((*L*))(![](../../OEBPS/Images/AR_a.png)^((*L*‚Äì1)))^T
  prefs: []
  type: TYPE_NORMAL
- en: ‚ñΩ*b*^((*L*))ùïÉ = ![](../../OEBPS/Images/AR_delta.png) ^((*L*))
  prefs: []
  type: TYPE_NORMAL
- en: ‚ä≥ Gradients for the remaining layers
  prefs: []
  type: TYPE_NORMAL
- en: '**for** *l* ‚Üê *L* ‚Äì 1 to 0 **do**'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/AR_delta.png) ^((*l*)) = ((*W*^((*l*+1)))*^T* ![](../../OEBPS/Images/AR_delta.png)^((*l*+1)))
    ![](../../OEBPS/Images/AR_a.png)^((*l*)) ‚àò (![](../../OEBPS/Images/AR_1.png) ‚Äì
    ![](../../OEBPS/Images/AR_a.png)^((*l*)))'
  prefs: []
  type: TYPE_IMG
- en: ‚ñΩ*W*^((*l*))ùïÉ = ![](../../OEBPS/Images/AR_delta.png) ^((*l*)) (![](../../OEBPS/Images/AR_a.png)^((*l*‚Äì1)))^T
  prefs: []
  type: TYPE_NORMAL
- en: ‚ñΩ*b*^((*l*))ùïÉ = ![](../../OEBPS/Images/AR_delta.png) ^((*l*))
  prefs: []
  type: TYPE_NORMAL
- en: '**end** **for**'
  prefs: []
  type: TYPE_NORMAL
- en: ‚ä≥ Parameter update
  prefs: []
  type: TYPE_NORMAL
- en: '*W* = *W* ‚Äì *r*‚ñΩ*[W]*ùïÉ'
  prefs: []
  type: TYPE_NORMAL
- en: '*b* = *b* ‚Äì *r*‚ñΩ*[b]*ùïÉ'
  prefs: []
  type: TYPE_NORMAL
- en: '**end** **while**'
  prefs: []
  type: TYPE_NORMAL
- en: 8.5 Training a neural network in PyTorch
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we‚Äôve seen how the training process works, let‚Äôs look at how this
    can be implemented in PyTorch. For this purpose, let‚Äôs take the following example.
    Consider an e-commerce company that‚Äôs trying to solve the problem of demand prediction:
    the company would like to estimate the number of mobile phones that will be sold
    in the upcoming week so that it can manage its inventory accordingly. Our goal
    is to develop a model that can make such a prediction. Let‚Äôs assume that the demand
    for a given week is a function of three variables: (a) the number of mobile phones
    sold in the previous week, (b) discounts offered, and (c) the number of weeks
    to the next holiday. Let‚Äôs call these variables `prev_week_sales`, `discount_fraction`,
    and `weeks_to_next_holidays`, respectively. This example can be modeled as a regression
    problem wherein we predict the number of mobile phones sold in the upcoming week
    from an input vector of the form [`prev_week_sales`, `discount_fraction`, `weeks_to_next_holidays`].'
  prefs: []
  type: TYPE_NORMAL
- en: NOTE Fully functional code for this section, executable via Jupyter Notebook,
    can be found at [http://mng.bz/O1Ra](http://mng.bz/O1Ra).
  prefs: []
  type: TYPE_NORMAL
- en: From historical data, we generate a large data set, `X`, that contains the values
    of the three variables for the last *N* weeks. `X` is represented as an *N* x
    3 matrix, with each row representing an individual training data instance and
    *N* being the total number of data points available. We also have a GT vector
    *»≥* of length *N*, containing the actual sales of mobile phones for each of the
    weeks in the training data set. Table [8.1](#tab-demand-prediction-data-set) shows
    sample data points from our training set.
  prefs: []
  type: TYPE_NORMAL
- en: Table 8.1 Sample training data for demand prediction
  prefs: []
  type: TYPE_NORMAL
- en: '| Previous week sales | Discount fraction (%) | Weeks to next holidays | Number
    of units sold |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 76,440 | 63 | 2 | 94,182 |'
  prefs: []
  type: TYPE_TB
- en: '| 41,512 | 50 | 3 | 51,531 |'
  prefs: []
  type: TYPE_TB
- en: '| 77,395 | 77 | 9 | 95,938 |'
  prefs: []
  type: TYPE_TB
- en: '| ‚Ä¶ | ‚Ä¶ | ‚Ä¶ | ‚Ä¶ |'
  prefs: []
  type: TYPE_TB
- en: '| 21,532 | 70 | 4 | 28,559 |'
  prefs: []
  type: TYPE_TB
- en: NOTE In this section, `X` and *»≥* refer to the entire batch of training data
    instances. This may be infeasible in practical settings because of large data
    sets. To address this, we typically use mini-batches of `X` and *»≥*. We introduce
    the concept of mini-batches formally in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'One important point about the data set is that the range of values for each
    feature is completely different. For example, the previous week‚Äôs sales are expressed
    as a number on the order of tens of thousands of units, whereas the discount fraction
    is a percentage number between 0 and 100\. In machine learning, it is a good practice
    to bring all the values to a common scale, because doing so can help improve the
    speed of training and reduce the chance of getting stuck at a local minimum. For
    our example, let‚Äôs use min-max normalization to scale all the features to 0‚Äì1\.
    The following code snippet shows how to perform min-max normalization in PyTorch.
    For the rest of the discussion, we assume that we are operating on the normalized
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: ‚ë† Clones the data so as not to mutilate the original data
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë° Calculates the min and max values of each column of *X*
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë¢ Normalizes *X*
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë£ Calculates the min and max values of *y*
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë§ Normalizes *y*
  prefs: []
  type: TYPE_NORMAL
- en: 'To solve the regression problem, let‚Äôs first define a two-layer neural network
    model that can take in 3D input vectors of the form [`prev_week_sales`, `discount_fraction`,
    `is_holidays_ongoing`] and generate output predictions. The following code snippet
    gives the PyTorch implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: ‚ë† Defines the network as a sequence of linear and sigmoid layers
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë° First hidden layer with a weight matrix of size input_size √ó hidden1_size)
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë¢ Second hidden layer with a weight matrix of size hidden1_size √ó hidden2_size)
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë£ Output layer with a weight matrix of size hidden2_size √ó output_size)
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë§ *X* is an *N* √ó 3 matrix. Each row is a (3D vector) representing a single
    data point.
  prefs: []
  type: TYPE_NORMAL
- en: Neural network models in PyTorch should subclass `torch.nn.Module` and implement
    the `forward` method. Our two-layer neural network contains two linear layers,
    each followed by a sigmoid (nonlinear) activation layer. Finally, we have a linear
    layer that converts the final activation into the output prediction. These layers
    are chained together using the `torch.nn.Sequential` class to form the two-layer
    neural network. Whenever our model is called using `nn(X)`, the `forward` method
    is invoked, and the input `X` is passed through the individual layers to obtain
    the final output.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have defined the neural network and its forward pass, we need to
    define the loss function. We can use the MSE loss defined in equation [8.11](../Text/08.xhtml#eq-mse-loss).
    The loss function essentially compares the demand predicted by the neural network
    model with the actual demand from the GT and returns larger values when the difference
    is higher and smaller values when the difference is lower. MSE loss is readily
    available in PyTorch through the `torch.nn.MSELoss` class. The following code
    snippet shows a sample invocation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: ‚ë† Instantiates the loss function
  prefs: []
  type: TYPE_NORMAL
- en: '‚ë° compute loss _pred: Output of the neural network _gt: ground truth'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we need a way to compute the gradients of the loss with respect to
    the parameters of our model so we can start the training process. Luckily, we
    don‚Äôt have to explicitly compute the gradients ourselves because PyTorch automatically
    does this for us using automatic differentiation, aka autograd. (Refer to section
    [3.1](../Text/03.xhtml#sec3_1) for more details about autograd.) For our current
    example, we can instruct PyTorch to run backpropagation and compute gradients
    by calling `loss.backward()`. With this, we‚Äôre ready to start training. PyTorch
    code for training the neural network is shown next.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 8.4 Training a neural network
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: ‚ë† Instantiates the neural network
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë° Instantiates the loss function
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë¢ Instantiates the optimizer
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë£ Training loop
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë§ Forward pass
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë• Computes the loss
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë¶ Clears the gradients and prevents accumulation of gradients from the previous
    step
  prefs: []
  type: TYPE_NORMAL
- en: ‚ëß Runs backpropagation (computes gradients)
  prefs: []
  type: TYPE_NORMAL
- en: ‚ë® Updates the weights
  prefs: []
  type: TYPE_NORMAL
- en: In the training loop, we iteratively run the forward pass, compute the loss,
    calculate the gradients, and update the weights. The neural network is initialized
    with random weights and hence makes arbitrary predictions for the demand in the
    early iterations of the training loop. This translates to a high initial loss
    value. However, as training proceeds, the weights are updated to minimize the
    loss value, and the predicted demand comes closer to the actual GT. To update
    the weights, we use what is known as an *optimizer*. During training, the gradients
    are computed by calling the `backward()` function on the `loss` object. Following
    that, the `optimizer.step` call updates the weights and biases. In this example,
    we used the stochastic gradient descent‚Äìbased optimizer, which can be invoked
    using `torch.optim.SGD`. PyTorch offers various optimizers, such as Adam, AdaGrad,
    and so on, which will be discussed in detail in the next chapter. We typically
    run the training loop until the loss reaches a value low enough to be acceptable.
    Once the training loop completes, we have a model that can readily take in new
    data points and generate output predictions.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The sigmoid function *œÉ*(*x*) = 1/1+*e^(‚Äìx)* has an S-shaped graph, is a differential
    version of the Heaviside step function, and, as such, is used in perceptrons.
    Thus the overall perceptron function becomes *P*(![](../../OEBPS/Images/AR_x.png))
    ‚â° *œÉ*(![](../../OEBPS/Images/AR_w.png)*^T*![](../../OEBPS/Images/AR_x.png) + *b*).
    It is parametrized by ![](../../OEBPS/Images/AR_w.png) and *b*, which control
    the slope and position, respectively, of the S-shaped curve.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neural networks solve real-life problems that require intelligence by approximating
    the function that solves the problem in question. They are built of multiple perceptrons
    interconnected by weighted edges. Instead of connecting perceptrons haphazardly,
    we connect them as layers. In a layered network, a perceptron is only connected
    to perceptrons from the immediately preceding layer. Intra-layer and other connections
    are not allowed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Supervised neural networks have manually generated outputs for a sample set
    of input values (ground truth). This entire data set consisting of inputs and
    known outputs is known as the training data set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loss is defined as the mismatch between the ground truth and actual output generated
    by the neural network on training data inputs. The simplest way to compute loss
    is to take the Euclidean distance between the neural network-generated output
    and ground-truth vectors. This is called the MSE (mean squared error) loss. Mathematically,
    given a training data set ùïã that is a set of <input, GT output> pairs ùïã = {‚ü®![](../../OEBPS/Images/AR_x.png),
    *»≥*‚ü©}, the loss can be expressed as
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-35-a.png)'
  prefs: []
  type: TYPE_IMG
- en: where the output is ![](../../OEBPS/Images/AR_y.png)*[i]* = *MLP*(![](../../OEBPS/Images/AR_x.png)*[i]*).
  prefs: []
  type: TYPE_NORMAL
- en: Training is the process of optimizing the connection weights and biases of a
    specific neural network so that the loss is minimal. Note that during inferencing,
    the neural network typically sees data it has never seen during training. Inferencing
    outputs are good only if the distribution of training inputs roughly matches the
    overall input distribution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We minimize the loss by iteratively adjusting the weights and biases. The quickest
    way to reach the closest minimum of a multivariate function is to follow the gradient.
    Hence, we adjust the weights and biases following the gradient of the loss function.
    Mathematically,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-35-b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'A forward pass is the process of generating outputs from inputs with a neural
    network: more specifically, a multilayer perceptron MLP). Thus an MLP does inferencing
    via a forward pass. A beautiful property of a layered network is that we can do
    a forward pass dealing with one layer at a time, proceeding iteratively from layer
    0 (closest to the input) to the output layer. Mathematically,'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-35-c.png)'
  prefs: []
  type: TYPE_IMG
- en: where *W*^((*l*)), ![](../../OEBPS/Images/AR_b.png)^((*l*)) represent the weights
    and biases for layer *l*, and ![](../../OEBPS/Images/AR_a.png)^((*l*)) represent
    the output for layer *l* activation), which is also the input for layer *l* +
    1.
  prefs: []
  type: TYPE_NORMAL
- en: A backward pass is the process by which the gradients of the loss with respect
    to all the weights and biases are generated. It relies on the result of the preceding
    forward pass and proceeds from the output layer toward the input layer. It uses
    auxiliary variables ![](../../OEBPS/Images/AR_bw.png)^((*l*)), which can be computed
    by iterating backward from the last (closest to output) layer to the first (closest
    to input) layer‚Äîhence the name *backward propagation*‚Äîand all the required gradients
    can be computed from those auxiliary variables. Mathematically,
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../../OEBPS/Images/eq_08-35-d.png)'
  prefs: []
  type: TYPE_IMG
- en: Training progresses by alternating forward and backward passes on the training
    data set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
