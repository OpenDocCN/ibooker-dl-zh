- en: 1 Understanding large language models
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs: []
  type: TYPE_NORMAL
- en: Introducing generative AI (specifically, large language models)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring the benefits of generative AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determining when and when not to use generative AI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whether you realize it or not, and whether you want to admit it or not, you
    have quietly received a promotion. Every professional software engineer has. Almost
    overnight, we have gone from staff engineers to engineering managers. You now
    have the world’s smartest and most talented junior developer on your team—generative
    AI is your new coding partner. So, guiding, mentoring, and performing code reviews
    should become part of your daily routine. This chapter will provide you with an
    overview of a subset of generative AI called large language models (LLMs), specifically
    ChatGPT, GitHub Copilot, and AWS CodeWhisperer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note This is not a traditional programming book. You will not be able to use
    it like you would a script. You are going to engage in a dialogue with LLMs, and
    like any conversation, the words and direction will change depending on the model
    and the prior context. The output you receive will very likely differ from what
    is printed in this book. This should not discourage you. Instead, you should explore.
    The journey is as rewarding as the destination. You may find yourself frustrated
    that you can’t follow along. Have patience. If you are disciplined (and somewhat
    adventurous), you can get GPT to cooperate with the general themes and aim of
    this book: learning how to use generative AI to make you a better programmer.'
  prefs: []
  type: TYPE_NORMAL
- en: 1.1 Accelerating your development
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Welcome to a new era in software development in which your development team
    expands by one very talented engineer. Generative AI isn’t just a tool; it’s your
    next team member, poised to elevate your programming to new heights. Imagine designing
    intricate systems, coding with unprecedented speed, and testing with robustness
    you never thought possible—all with an intelligence that learns from the best.
    In this book, we’ll explore how generative AI will not only assist you in everyday
    coding tasks but also enable you to achieve feats previously beyond reach, ensuring
    faster development, enhanced quality, and the capacity to innovate like never
    before.
  prefs: []
  type: TYPE_NORMAL
- en: 'LLMs and generative AI can drastically accelerate your software development
    process. By automating the tedious creation of boilerplate code, you are freed
    to focus on creative problem-solving and value-adding tasks. Consider this example:
    you want to have the LLM set up a Flask application. You might use the following
    prompt:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/logo-NC.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Generate a stubbed-out Flask application. |'
  prefs: []
  type: TYPE_TB
- en: The LLM might output the following Python code.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 1.1 Potential code generated by an LLM to stub out a Flask application
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'LLMs are deep learning models that are good at providing natural language responses
    to natural language prompts. You can imagine simply describing what you need in
    plain English and receiving ready-to-integrate code:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/logo-NC.png)'
  prefs: []
  type: TYPE_IMG
- en: '| Create a class for managing user sessions in Python. |'
  prefs: []
  type: TYPE_TB
- en: Here’s a possible response.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 1.2 Potential code generated to create a session management class
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: These tools also enhance your debugging efficiency by identifying patterns and
    suggesting fixes. Suppose you want your AI tool to analyze a block of code and
    flag potential memory leaks. It might produce the following code.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 1.3 Using an LLM to find a potential memory leak in Python
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: According to the explanation provided by ChatGPT, this Python code demonstrates
    a potential memory leak due to a large list not being cleared after use, which
    can keep its contents in memory longer than necessary if references are not properly
    managed.
  prefs: []
  type: TYPE_NORMAL
- en: In the improved code, the AI tool suggests explicitly clearing the list or reassigning
    `None` after its usage to help in releasing the memory sooner, especially in environments
    where garbage collection is not aggressive.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 1.4 “Improved” LLM code to address the potential memory leak
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Moreover, when it comes to refactoring, the AI can suggest optimizations that
    make your code cleaner and more efficient, as shown in the next two listings.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 1.5 Verbose code before the suggested refactoring
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: After the refactoring, the code is more readable, maintainable, and idiomatic.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 1.6 LLM refactored code that is more concise
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: LLMs extend beyond mere code generation; they are sophisticated enough to assist
    in designing software architecture as well. This capability allows developers
    to engage with these models more creatively and strategically. For instance, rather
    than simply requesting specific snippets of code, a developer can describe the
    overall objectives or functional requirements of a system. The LLM can then propose
    various architectural designs, suggest design patterns, or outline an entire system’s
    structure. This approach not only saves significant time but also takes advantage
    of the AI’s extensive training to innovate and optimize solutions, potentially
    introducing efficiencies or ideas that the human developer may not have initially
    considered. This flexibility makes LLMs invaluable partners in the creative and
    iterative processes of software development. We will explore this in chapter 3.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, by enhancing the quality and security of your deliverables—from
    code to documentation—these tools ensure that your outputs meet the highest standards.
    For instance, when integrating a new library, the AI can automatically generate
    secure, efficient implementation examples, helping you avoid common security pitfalls.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, learning new programming languages or frameworks becomes significantly
    easier. The AI can provide real-time, context-aware guidance and documentation,
    helping you to not only understand but also apply new concepts practically. For
    example, are you transitioning to a new framework like Dash? Your AI assistant
    can instantly generate sample code snippets and detailed explanations tailored
    to your current project’s context.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 1.7 LLM-generated sample code demonstrating how to use a library
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: We can see the output of this code in figure 1.1, which is the running Dash
    code.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH01_F01_Crocker2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.1 The Stock Prices Dashboard created by ChatGPT in response to the
    prompt “`create a sample dashboard using dash`”
  prefs: []
  type: TYPE_NORMAL
- en: The real power of LLMs unfolds in their integration in development environments.
    Tools like GitHub Copilot, developed by Microsoft, harness the capabilities of
    LLMs to provide real-time coding assistance directly in integrated development
    environments (IDEs) such as Visual Studio Code. We will unleash this power in
    chapter 4.
  prefs: []
  type: TYPE_NORMAL
- en: This book will not only explain these concepts but also demonstrate them through
    numerous examples, showing how you can use LLMs to improve your productivity and
    code quality dramatically. From setting up your environment to tackling complex
    coding challenges, you’ll learn how to make the most out of these intelligent
    tools in your everyday development.
  prefs: []
  type: TYPE_NORMAL
- en: 1.2 A developer’s introduction to LLMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although this book is mainly a practitioner’s guide and therefore very light
    on theory, the following section will provide you with the most relevant material
    for you to get the most out of your new teammate.
  prefs: []
  type: TYPE_NORMAL
- en: Yes, but I want to know more
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are interested in diving deeper into the theory behind LLMs, neural
    networks, and all things generative AI, you should look at the following two books:
    the forthcoming *Build a Large Language Model (From Scratch)* by Sebastian Raschka
    (Manning, 2024) and the amusingly titled *The Complete Obsolete Guide to Generative
    AI* by David Clinton (Manning, 2024).'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start with a very simple definition of what an LLM is and what it can
    do for you; this way, you can properly pitch it to your boss and co-workers. A
    *large language model* is a type of artificial intelligence model that processes,
    understands, and generates human-like text based on the data it has been trained
    on. These models are a subset of deep learning and are particularly advanced in
    handling various aspects of natural language processing (NLP).
  prefs: []
  type: TYPE_NORMAL
- en: As the name implies, these models are “large” not just in terms of the physical
    size of the data they are trained on but also in the complexity and number of
    parameters. Modern LLMs like OpenAI’s GPT-4 have up to hundreds of billions of
    parameters.
  prefs: []
  type: TYPE_NORMAL
- en: LLMs are trained on vast amounts of text data. This training involves reading
    and analyzing a wide range of internet texts, books, articles, and other forms
    of written communication to learn the structure, nuances, and complexities of
    human language.
  prefs: []
  type: TYPE_NORMAL
- en: Most LLMs use the Transformer architecture, a deep learning model that relies
    on self-attention mechanisms to weigh the importance of different words in a sentence
    regardless of their position. This allows LLMs to generate more contextually relevant
    text. A typical Transformer model consists of an encoder and a decoder, each composed
    of multiple layers.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the architecture of LLMs helps in using their capabilities more
    effectively as well as addressing their limitations in practical applications.
    As these models continue to evolve, they promise to offer even more sophisticated
    tools for developers to enhance their applications.
  prefs: []
  type: TYPE_NORMAL
- en: 1.3 When to use and when to avoid generative AI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Generative AI (and by extension an LLM) is not a one-size-fits-all solution.
    Understanding when to employ these technologies, as well as recognizing situations
    where they may be less effective or even problematic, is crucial for maximizing
    their benefits while mitigating potential drawbacks. We will start with when it
    is appropriate for you to use an LLM:'
  prefs: []
  type: TYPE_NORMAL
- en: Enhancing productivity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Example*—Use AI to automate boilerplate code, generate documentation, or provide
    coding suggestions within your IDE.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Discussed in chapters 3 and 4*—These chapters explore how tools like GitHub
    Copilot can boost coding efficiency.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Learning and exploration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Example*—Employ AI to learn new programming languages or frameworks by generating
    example codes and explanations.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Covered in chapter 5*—Here, we examine how AI can accelerate the learning
    process and introduce you to new technologies.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling repetitive tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Example*—Use AI to handle repetitive software testing or data entry tasks,
    freeing up time for more complex problems.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Explored in chapter 7*—Discusses automation in testing and maintenance tasks.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are, however, situations in which you should avoid using LLMs and generative
    AI tools such as ChatGPT and GitHub Copilot, mainly those related to data security
    and privacy protection. Using AI in environments with sensitive or proprietary
    data can risk unintended data leaks. There are several reasons for this, one of
    which is that part or all of the code is sent to the model as context, meaning
    at least part of your proprietary code may find its way outside of your firewall.
    There is a question as to whether it may be included in the training data for
    the next round of training. But have no fear: we will examine a couple of methods
    to address this concern in chapter 9.'
  prefs: []
  type: TYPE_NORMAL
- en: Another scenario in which you might limit your usage is when precision and expertise
    are required. Given that a feature of LLMs is their ability to add randomness
    to their output (sometimes referred to as *hallucinations*), the output may contain
    subtle variations from the true and right answer. For this reason, you should
    always verify the output before including it in your codebase.
  prefs: []
  type: TYPE_NORMAL
- en: Although generative AI offers numerous advantages, it’s essential to apply it
    judiciously, considering both the context of its use and the specific needs of
    the project. By understanding when to use these powerful tools and when to proceed
    with caution, developers can maximize their effectiveness and ensure ethical and
    efficient use of technology.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Generative AI is both evolutionary and revolutionary. It’s evolutionary in the
    sense that it is just another iteration of the tools that we as developers use
    every day. It’s revolutionary in that it will transform how we do our jobs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The future of development will involve managing generative AI. Even the mythical
    10× developer will not have the productivity of a developer with an AI partner;
    an AI-powered developer will produce higher-quality code at a substantially faster
    rate, at a lower cost than one who is not. We will spend more of our time training
    our AI partner to do what we want and how we want it done than we do writing code
    without the AI.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trust but verify the LLM’s output.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
