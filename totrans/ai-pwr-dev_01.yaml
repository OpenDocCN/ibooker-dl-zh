- en: 1 Understanding large language models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: Introducing generative AI (specifically, large language models)
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring the benefits of generative AI
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Determining when and when not to use generative AI
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whether you realize it or not, and whether you want to admit it or not, you
    have quietly received a promotion. Every professional software engineer has. Almost
    overnight, we have gone from staff engineers to engineering managers. You now
    have the world’s smartest and most talented junior developer on your team—generative
    AI is your new coding partner. So, guiding, mentoring, and performing code reviews
    should become part of your daily routine. This chapter will provide you with an
    overview of a subset of generative AI called large language models (LLMs), specifically
    ChatGPT, GitHub Copilot, and AWS CodeWhisperer.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: 'Note This is not a traditional programming book. You will not be able to use
    it like you would a script. You are going to engage in a dialogue with LLMs, and
    like any conversation, the words and direction will change depending on the model
    and the prior context. The output you receive will very likely differ from what
    is printed in this book. This should not discourage you. Instead, you should explore.
    The journey is as rewarding as the destination. You may find yourself frustrated
    that you can’t follow along. Have patience. If you are disciplined (and somewhat
    adventurous), you can get GPT to cooperate with the general themes and aim of
    this book: learning how to use generative AI to make you a better programmer.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: 1.1 Accelerating your development
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Welcome to a new era in software development in which your development team
    expands by one very talented engineer. Generative AI isn’t just a tool; it’s your
    next team member, poised to elevate your programming to new heights. Imagine designing
    intricate systems, coding with unprecedented speed, and testing with robustness
    you never thought possible—all with an intelligence that learns from the best.
    In this book, we’ll explore how generative AI will not only assist you in everyday
    coding tasks but also enable you to achieve feats previously beyond reach, ensuring
    faster development, enhanced quality, and the capacity to innovate like never
    before.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
- en: 'LLMs and generative AI can drastically accelerate your software development
    process. By automating the tedious creation of boilerplate code, you are freed
    to focus on creative problem-solving and value-adding tasks. Consider this example:
    you want to have the LLM set up a Flask application. You might use the following
    prompt:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/logo-NC.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
- en: '| Generate a stubbed-out Flask application. |'
  id: totrans-12
  prefs: []
  type: TYPE_TB
- en: The LLM might output the following Python code.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: Listing 1.1 Potential code generated by an LLM to stub out a Flask application
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'LLMs are deep learning models that are good at providing natural language responses
    to natural language prompts. You can imagine simply describing what you need in
    plain English and receiving ready-to-integrate code:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/logo-NC.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/logo-NC.png)'
- en: '| Create a class for managing user sessions in Python. |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| 在Python中创建用于管理用户会话的类。|'
- en: Here’s a possible response.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个可能的响应。
- en: Listing 1.2 Potential code generated to create a session management class
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 列表1.2 生成用于创建会话管理类的潜在代码
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: These tools also enhance your debugging efficiency by identifying patterns and
    suggesting fixes. Suppose you want your AI tool to analyze a block of code and
    flag potential memory leaks. It might produce the following code.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工具通过识别模式和提出修复建议来提高你的调试效率。假设你希望你的AI工具分析一段代码并标记潜在的内存泄漏。它可能会生成以下代码。
- en: Listing 1.3 Using an LLM to find a potential memory leak in Python
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 列表1.3 使用LLM在Python中查找潜在的内存泄漏
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: According to the explanation provided by ChatGPT, this Python code demonstrates
    a potential memory leak due to a large list not being cleared after use, which
    can keep its contents in memory longer than necessary if references are not properly
    managed.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 根据ChatGPT提供的解释，这段Python代码演示了由于未清除使用后的大列表而导致的潜在内存泄漏，如果不正确管理引用，其内容可能会在内存中保留比必要更长的时间。
- en: In the improved code, the AI tool suggests explicitly clearing the list or reassigning
    `None` after its usage to help in releasing the memory sooner, especially in environments
    where garbage collection is not aggressive.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在改进的代码中，AI工具建议在使用后明确清除列表或重新分配`None`，以帮助更快地释放内存，尤其是在垃圾回收不是非常积极的环境中。
- en: Listing 1.4 “Improved” LLM code to address the potential memory leak
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 列表1.4 “改进”的LLM代码以解决潜在的内存泄漏
- en: '[PRE3]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Moreover, when it comes to refactoring, the AI can suggest optimizations that
    make your code cleaner and more efficient, as shown in the next two listings.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，当涉及到重构时，AI可以提出优化建议，使你的代码更干净、更高效，如以下两个列表所示。
- en: Listing 1.5 Verbose code before the suggested refactoring
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 列表1.5 在建议重构之前的冗长代码
- en: '[PRE4]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: After the refactoring, the code is more readable, maintainable, and idiomatic.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 重构后，代码更加易于阅读、维护和符合惯例。
- en: Listing 1.6 LLM refactored code that is more concise
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 列表1.6 LLM重构后的代码，更加简洁
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: LLMs extend beyond mere code generation; they are sophisticated enough to assist
    in designing software architecture as well. This capability allows developers
    to engage with these models more creatively and strategically. For instance, rather
    than simply requesting specific snippets of code, a developer can describe the
    overall objectives or functional requirements of a system. The LLM can then propose
    various architectural designs, suggest design patterns, or outline an entire system’s
    structure. This approach not only saves significant time but also takes advantage
    of the AI’s extensive training to innovate and optimize solutions, potentially
    introducing efficiencies or ideas that the human developer may not have initially
    considered. This flexibility makes LLMs invaluable partners in the creative and
    iterative processes of software development. We will explore this in chapter 3.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: LLM的功能不仅限于代码生成；它们足够复杂，可以协助设计软件架构。这种能力允许开发者以更具创造性和战略性的方式与这些模型互动。例如，开发者可以描述系统的整体目标或功能需求，而不是简单地请求特定的代码片段。然后，LLM可以提出各种架构设计、建议设计模式或概述整个系统的结构。这种方法不仅节省了大量时间，而且利用了AI的广泛训练来创新和优化解决方案，可能引入效率或想法，这些是开发者最初可能没有考虑到的。这种灵活性使LLM成为软件开发创意和迭代过程中的宝贵伙伴。我们将在第3章中探讨这一点。
- en: In addition, by enhancing the quality and security of your deliverables—from
    code to documentation—these tools ensure that your outputs meet the highest standards.
    For instance, when integrating a new library, the AI can automatically generate
    secure, efficient implementation examples, helping you avoid common security pitfalls.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，通过提高你的交付成果的质量和安全，从代码到文档，这些工具确保你的输出达到最高标准。例如，在集成新库时，AI可以自动生成安全、高效的实现示例，帮助你避免常见的安全陷阱。
- en: Finally, learning new programming languages or frameworks becomes significantly
    easier. The AI can provide real-time, context-aware guidance and documentation,
    helping you to not only understand but also apply new concepts practically. For
    example, are you transitioning to a new framework like Dash? Your AI assistant
    can instantly generate sample code snippets and detailed explanations tailored
    to your current project’s context.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，学习新的编程语言或框架变得显著更容易。AI可以提供实时、上下文感知的指导和文档，帮助您不仅理解，而且实际应用新概念。例如，您是否正在过渡到新的框架如Dash？您的AI助手可以立即生成针对您当前项目上下文的示例代码片段和详细说明。
- en: Listing 1.7 LLM-generated sample code demonstrating how to use a library
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 列表1.7：LLM生成的示例代码，展示如何使用库
- en: '[PRE6]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: We can see the output of this code in figure 1.1, which is the running Dash
    code.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以在图1.1中看到这段代码的输出，这是正在运行的Dash代码。
- en: '![](../Images/CH01_F01_Crocker2.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图片](../Images/CH01_F01_Crocker2.png)'
- en: Figure 1.1 The Stock Prices Dashboard created by ChatGPT in response to the
    prompt “`create a sample dashboard using dash`”
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1 ChatGPT根据提示“`使用dash创建一个示例仪表板`”创建的股票价格仪表板
- en: The real power of LLMs unfolds in their integration in development environments.
    Tools like GitHub Copilot, developed by Microsoft, harness the capabilities of
    LLMs to provide real-time coding assistance directly in integrated development
    environments (IDEs) such as Visual Studio Code. We will unleash this power in
    chapter 4.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs的真实力量在于它们在开发环境中的集成。例如，由微软开发的GitHub Copilot工具，利用LLMs的能力，在Visual Studio Code等集成开发环境（IDE）中提供实时编码辅助。我们将在第4章中展示这一功能。
- en: This book will not only explain these concepts but also demonstrate them through
    numerous examples, showing how you can use LLMs to improve your productivity and
    code quality dramatically. From setting up your environment to tackling complex
    coding challenges, you’ll learn how to make the most out of these intelligent
    tools in your everyday development.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 本书不仅会解释这些概念，还会通过众多示例进行演示，展示您如何使用LLMs显著提高生产力和代码质量。从设置您的环境到解决复杂的编码挑战，您将学习如何充分利用这些智能工具在日常开发中的使用。
- en: 1.2 A developer’s introduction to LLMs
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.2 开发者对LLMs的介绍
- en: Although this book is mainly a practitioner’s guide and therefore very light
    on theory, the following section will provide you with the most relevant material
    for you to get the most out of your new teammate.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这本书主要是一本实践指南，因此理论部分相对较少，但以下部分将为您提供最相关的材料，帮助您充分利用您的新队友。
- en: Yes, but I want to know more
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，但我还想了解更多
- en: 'If you are interested in diving deeper into the theory behind LLMs, neural
    networks, and all things generative AI, you should look at the following two books:
    the forthcoming *Build a Large Language Model (From Scratch)* by Sebastian Raschka
    (Manning, 2024) and the amusingly titled *The Complete Obsolete Guide to Generative
    AI* by David Clinton (Manning, 2024).'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您对LLMs、神经网络以及所有生成式AI背后的理论感兴趣，您应该查看以下两本书：Sebastian Raschka（Manning，2024）即将出版的《从零开始构建大型语言模型》（Build
    a Large Language Model (From Scratch)）和David Clinton（Manning，2024）幽默命名的《生成式AI完全过时指南》（The
    Complete Obsolete Guide to Generative AI）。
- en: Let’s start with a very simple definition of what an LLM is and what it can
    do for you; this way, you can properly pitch it to your boss and co-workers. A
    *large language model* is a type of artificial intelligence model that processes,
    understands, and generates human-like text based on the data it has been trained
    on. These models are a subset of deep learning and are particularly advanced in
    handling various aspects of natural language processing (NLP).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个非常简单的定义开始，了解LLM是什么以及它能为您做什么；这样，您就可以正确地向您的老板和同事介绍它。*大型语言模型*是一种人工智能模型，它根据训练数据处理、理解和生成类似人类的文本。这些模型是深度学习的一个子集，在处理自然语言处理（NLP）的各个方面特别先进。
- en: As the name implies, these models are “large” not just in terms of the physical
    size of the data they are trained on but also in the complexity and number of
    parameters. Modern LLMs like OpenAI’s GPT-4 have up to hundreds of billions of
    parameters.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 正如其名所示，这些模型不仅在训练数据的数据量上“大”，而且在复杂性和参数数量上也非常大。现代LLMs，如OpenAI的GPT-4，拥有高达数百亿个参数。
- en: LLMs are trained on vast amounts of text data. This training involves reading
    and analyzing a wide range of internet texts, books, articles, and other forms
    of written communication to learn the structure, nuances, and complexities of
    human language.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: LLMs（大型语言模型）是在大量文本数据上训练的。这种训练包括阅读和分析各种互联网文本、书籍、文章和其他形式的书面沟通，以学习人类语言的结构、细微差别和复杂性。
- en: Most LLMs use the Transformer architecture, a deep learning model that relies
    on self-attention mechanisms to weigh the importance of different words in a sentence
    regardless of their position. This allows LLMs to generate more contextually relevant
    text. A typical Transformer model consists of an encoder and a decoder, each composed
    of multiple layers.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数LLM使用Transformer架构，这是一种依赖自注意力机制的深度学习模型，它可以根据不同单词在句子中的位置来权衡其重要性。这使得LLM能够生成更多上下文相关的文本。典型的Transformer模型由一个编码器和一个解码器组成，每个都由多个层组成。
- en: Understanding the architecture of LLMs helps in using their capabilities more
    effectively as well as addressing their limitations in practical applications.
    As these models continue to evolve, they promise to offer even more sophisticated
    tools for developers to enhance their applications.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 理解LLMs的架构有助于更有效地使用它们的特性，并在实际应用中解决它们的局限性。随着这些模型不断进化，它们承诺将为开发者提供更高级的工具，以增强他们的应用程序。
- en: 1.3 When to use and when to avoid generative AI
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1.3 何时使用和何时避免生成式AI
- en: 'Generative AI (and by extension an LLM) is not a one-size-fits-all solution.
    Understanding when to employ these technologies, as well as recognizing situations
    where they may be less effective or even problematic, is crucial for maximizing
    their benefits while mitigating potential drawbacks. We will start with when it
    is appropriate for you to use an LLM:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式AI（以及由此扩展的LLM）并非万能的解决方案。了解何时使用这些技术，以及识别它们可能不太有效或甚至有问题的情况，对于最大化其好处同时减轻潜在缺点至关重要。我们将从何时适合使用LLM开始：
- en: Enhancing productivity
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提高生产力
- en: '*Example*—Use AI to automate boilerplate code, generate documentation, or provide
    coding suggestions within your IDE.'
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*示例*—使用AI自动化样板代码、生成文档或在您的IDE中提供编码建议。'
- en: '*Discussed in chapters 3 and 4*—These chapters explore how tools like GitHub
    Copilot can boost coding efficiency.'
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第3章和第4章讨论*—这些章节探讨了GitHub Copilot等工具如何提高编码效率。'
- en: Learning and exploration
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 学习和探索
- en: '*Example*—Employ AI to learn new programming languages or frameworks by generating
    example codes and explanations.'
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*示例*—利用AI通过生成示例代码和解释来学习新的编程语言或框架。'
- en: '*Covered in chapter 5*—Here, we examine how AI can accelerate the learning
    process and introduce you to new technologies.'
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第5章涵盖*—在这里，我们检查AI如何加速学习过程，并介绍您了解新技术。'
- en: Handling repetitive tasks
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理重复性任务
- en: '*Example*—Use AI to handle repetitive software testing or data entry tasks,
    freeing up time for more complex problems.'
  id: totrans-64
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*示例*—使用AI处理重复的软件测试或数据录入任务，从而腾出时间解决更复杂的问题。'
- en: '*Explored in chapter 7*—Discusses automation in testing and maintenance tasks.'
  id: totrans-65
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第7章探讨*—讨论测试和维护任务中的自动化。'
- en: 'There are, however, situations in which you should avoid using LLMs and generative
    AI tools such as ChatGPT and GitHub Copilot, mainly those related to data security
    and privacy protection. Using AI in environments with sensitive or proprietary
    data can risk unintended data leaks. There are several reasons for this, one of
    which is that part or all of the code is sent to the model as context, meaning
    at least part of your proprietary code may find its way outside of your firewall.
    There is a question as to whether it may be included in the training data for
    the next round of training. But have no fear: we will examine a couple of methods
    to address this concern in chapter 9.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有些情况下你应该避免使用LLMs和生成式AI工具，如ChatGPT和GitHub Copilot，主要与数据安全和隐私保护相关。在包含敏感或专有数据的环境中使用AI可能会造成意外的数据泄露。这有几个原因，其中之一是部分或全部代码作为上下文发送到模型中，这意味着至少部分专有代码可能会绕过你的防火墙。还有一个问题是它是否可能被包含在下一轮训练的训练数据中。但请放心：我们将在第9章中探讨一些解决这一担忧的方法。
- en: Another scenario in which you might limit your usage is when precision and expertise
    are required. Given that a feature of LLMs is their ability to add randomness
    to their output (sometimes referred to as *hallucinations*), the output may contain
    subtle variations from the true and right answer. For this reason, you should
    always verify the output before including it in your codebase.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能限制使用场景的另一个例子是当需要精确和专业性时。鉴于大型语言模型的一个特点是它们能够在其输出中添加随机性（有时被称为*幻觉*），输出可能包含与真实和正确答案细微的差别。因此，在将其包含在代码库之前，你应该始终验证输出。
- en: Although generative AI offers numerous advantages, it’s essential to apply it
    judiciously, considering both the context of its use and the specific needs of
    the project. By understanding when to use these powerful tools and when to proceed
    with caution, developers can maximize their effectiveness and ensure ethical and
    efficient use of technology.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管生成式AI提供了众多优势，但应用它时必须谨慎，考虑到其使用的上下文和项目的具体需求。通过理解何时使用这些强大的工具以及何时需要谨慎行事，开发者可以最大化其效果，并确保技术的道德和高效使用。
- en: Summary
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: Generative AI is both evolutionary and revolutionary. It’s evolutionary in the
    sense that it is just another iteration of the tools that we as developers use
    every day. It’s revolutionary in that it will transform how we do our jobs.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成式AI既是进化性的也是革命性的。就其是开发者每天使用的工具的另一个迭代而言，它是进化性的。就其将改变我们工作方式而言，它是革命性的。
- en: The future of development will involve managing generative AI. Even the mythical
    10× developer will not have the productivity of a developer with an AI partner;
    an AI-powered developer will produce higher-quality code at a substantially faster
    rate, at a lower cost than one who is not. We will spend more of our time training
    our AI partner to do what we want and how we want it done than we do writing code
    without the AI.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发的未来将涉及管理生成式AI。即使是传说中的10倍开发者，也不会有与AI合作伙伴的开发者相同的生产力；AI赋能的开发者将以更快的速度、更低的成本生产出高质量的代码，比没有AI的开发者要低。我们将花费更多的时间来训练我们的AI合作伙伴去做我们想要的事情以及我们想要的方式，而不是在没有AI的情况下编写代码。
- en: Trust but verify the LLM’s output.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 信任但验证LLM的输出。
