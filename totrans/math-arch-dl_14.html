<html><head></head><body>
<div class="calibre1" id="sbo-rt-content"><h1 class="tochead" id="section">Appendix</h1>
<h2 class="fm-head" id="sec-dotprod-cosine-proof">A.1 Dot product and cosine of the angle between two vectors</h2>
<p class="body"><a id="marker-497"/>In section <a class="url" href="02.xhtml#subsubsec-dotproduct_as_component">2.5.6.1</a>, we stated that the component of a vector <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_a.png" width="14"/></span> along another vector <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_b.png" width="14"/></span> is <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_a.png" width="14"/></span> ‚ãÖ <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_b.png" width="14"/></span> = <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_a.png" width="14"/></span><i class="fm-italics"><sup class="fm-superscript">T</sup></i><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_b.png" width="14"/></span>. This is equivalent to <span class="math">||<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_a.png" width="14"/></span>|| ||<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_b.png" width="14"/></span>||<i class="fm-italics">cos</i>(<i class="fm-italics">Œ∏</i>)</span>, where <i class="timesitalic">Œ∏</i> is the angle between the vectors <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_a.png" width="14"/></span> and <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_b.png" width="14"/></span>.</p>
<p class="body">In this section, we offer a proof of this for the two-dimensional case to deepen your intuition about the geometry of dot products. From figure <a class="url" href="#fig-dotproduct_as_component-repeat">A.2</a>, we can see that</p><!--<p class="Body"><span class="times">$$\begin{aligned} a_{x} =&amp; \|\vec{a}\|cos\left(\theta + \phi\right)
&amp;a_{y} =&amp; \|\vec{a}\|sin\left(\theta + \phi\right) \\[3pt] b_{x} =&amp; \|\vec{b}\|cos\left(\phi\right)
&amp;b_{y} =&amp; \|\vec{b}\|sin\left(\phi\right)\end{aligned}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="81" src="../../OEBPS/Images/eq_A-00.png" width="354"/></p>
</div>
<p class="body">which can be rewritten as</p><!--<p class="Body"><span class="times">$$\begin{aligned} cos\left(\theta + \phi\right) =&amp;
\frac{a_{x}}{\|\vec{a}\|}  &amp;sin\left(\theta + \phi\right) =&amp;
\frac{a_{y}}{\|\vec{a}\|}\end{aligned}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="51" src="../../OEBPS/Images/eq_A-01.png" width="394"/></p>
</div>
<p class="fm-equation-caption">Equation A.1 <span class="calibre" id="eq-dotprod-as-component1"/></p><!--<p class="Body"><span class="times">$$\begin{aligned} cos\left(\phi\right) =&amp; \frac{b_{x}}{\|\vec{b}\|}
&amp;sin\left(\phi\right) =&amp;
\frac{b_{y}}{\|\vec{b}\|}\end{aligned}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="60" src="../../OEBPS/Images/eq_A-02.png" width="400"/></p>
</div>
<p class="fm-equation-caption">Equation A.2 <span class="calibre" id="eq-dotprod-as-component2"/></p>
<p class="body">Using well-known trigonometric identities in equation <a class="url" href="#eq-dotprod-as-component1">A.1</a>, we get</p><!--<p class="Body"><span class="times">$$\begin{aligned} cos\left(\theta + \phi\right) &amp;= cos\phi cos\theta - sin\phi sin\theta &amp;= \frac{a_{x}}{\|\vec{a}\|}\\[3pt] sin\left(\theta + \phi\right) &amp;= sin\phi cos\theta + cos\phi sin\theta &amp;= \frac{a_{y}}{\|\vec{a}\|}\end{aligned}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="106" src="../../OEBPS/Images/eq_A-02-a.png" width="342"/></p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre17" height="422" id="fig-vec_component" src="../../OEBPS/Images/APPA_UN01a_Chaudhury.png" width="484"/></p>
<p class="figurecaption">(a) Components of a 2D vector along coordinate axes. Note that <span class="math">||<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_a.png" width="14"/></span>||</span> is the length of hypotenuse.</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre17" height="435" id="fig-dotproduct_as_component-repeat" src="../../OEBPS/Images/APPA_UN01b_Chaudhury.png" width="483"/></p>
<p class="figurecaption">(b) Dot product as a component of one vector along another <span class="math"><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_a.png" width="14"/></span> ‚ãÖ <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_b.png" width="14"/></span> = <span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_a.png" width="14"/></span><i class="fm-italics"><sup class="fm-superscript">T</sup></i><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_b.png" width="14"/></span> = <i class="fm-italics">a<sub class="fm-subscript">x</sub>b<sub class="fm-subscript">x</sub></i> + <i class="fm-italics">a<sub class="fm-subscript">y</sub>b<sub class="fm-subscript">y</sub></i> = ||<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_a.png" width="14"/></span>|| ||<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_b.png" width="14"/></span>||<i class="fm-italics">cos</i>(<i class="fm-italics">Œ∏</i>)</span>.</p>
</div>
<p class="fm-table-caption">Figure A.1 Vector components and dot product</p>
<p class="body"><a id="marker-498"/>Substituting for <i class="timesitalic">cosœï</i> and <i class="timesitalic">sinœï</i> from equation <a class="url" href="#eq-dotprod-as-component2">A.2</a>, we have a system of simultaneous linear equations with <i class="timesitalic">cosŒ∏</i> and <i class="timesitalic">sinŒ∏</i> as unknowns:</p><!--<p class="Body"><span class="times">$$\begin{aligned}
\frac{b_{x}}{\|\vec{b}\|} cos\theta - \frac{b_{y}}{\|\vec{b}\|} sin\theta =&amp; \frac{a_{x}}{\|\vec{a}\|}\\[3pt]
\frac{b_{y}}{\|\vec{b}\|} cos\theta + \frac{b_{x}}{\|\vec{b}\|} sin\theta =&amp; \frac{a_{y}}{\|\vec{a}\|}\end{aligned}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="119" src="../../OEBPS/Images/eq_A-02-b.png" width="208"/></p>
</div>
<p class="body">This system of simultaneous linear equations can be compactly written in matrix-vector form</p><!--<p class="Body"><span class="times">$$\begin{bmatrix}
\frac{b_{x}}{\|\vec{b}\|} &amp; -\frac{b_{y}}{\|\vec{b}\|}\\[3pt]
\frac{b_{y}}{\|\vec{b}\|} &amp; \frac{b_{x}}{\|\vec{b}\|}
\end{bmatrix}
\begin{bmatrix} cos\theta\\ sin\theta
\end{bmatrix} =
\begin{bmatrix}
\frac{a_{x}}{\|\vec{a}\|}\\[3pt]
\frac{a_{y}}{\|\vec{a}\|}
\end{bmatrix}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="87" src="../../OEBPS/Images/eq_A-02-c.png" width="211"/></p>
</div>
<p class="body">which can be simplified to</p><!--<p class="Body"><span class="times">$$\frac{1}{\|\vec{b}\|}
\begin{bmatrix} b_{x} &amp; -b_{y}\\ b_{y} &amp;  b_{x}
\end{bmatrix}
\begin{bmatrix} cos\theta\\ sin\theta
\end{bmatrix} =
\frac{1}{\|\vec{a}\|}
\begin{bmatrix} a_{x}\\ a_{y}
\end{bmatrix}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="74" src="../../OEBPS/Images/eq_A-02-d.png" width="252"/></p>
</div>
<p class="body">This equation can be solved to yield</p><!--<p class="Body"><span class="times">$$\begin{aligned} cos\theta &amp;= \frac{a_{x}b_{x} + a_{y}b_{y}}{\|\vec{a}\|\|\vec{b}\|}
\\[6pt] sin\theta &amp;= \frac{a_{y}b_{x} - a_{x}b_{y}}{\|\vec{a}\|\|\vec{b}\|}\end{aligned}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="126" src="../../OEBPS/Images/eq_A-02-e.png" width="151"/></p>
</div>
<p class="body">So, <span class="math">||<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_a.png" width="14"/></span>|| ||<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_b.png" width="14"/></span>||<i class="fm-italics">cosŒ∏</i> = <i class="fm-italics">a<sub class="fm-subscript">x</sub>b<sub class="fm-subscript">x</sub></i> + <i class="fm-italics">a<sub class="fm-subscript">y</sub>b<sub class="fm-subscript">y</sub></i></span>, which was to be proved.</p>
<h2 class="fm-head" id="sec-det2x2">A.2 Determinants</h2>
<p class="body">Determinant computation is tedious and numerically unstable if done naively. You should never compute one by hand‚Äîall linear algebra software packages provide routines to do this. Hence we only describe the algorithm to compute the determinant of a <span class="math">2 √ó 2</span> matrix. This determinant can be computed as<a id="marker-499"/></p>
<p class="fm-equation"><span class="math"><i class="fm-italics">det</i>(<i class="fm-italics">A</i>) = <i class="fm-italics">a</i><sub class="fm-subscript">11</sub><i class="fm-italics">a</i><sub class="fm-subscript">22</sub> ‚àí <i class="fm-italics">a</i><sub class="fm-subscript">12</sub><i class="fm-italics">a</i><sub class="fm-subscript">21</sub></span></p>
<p class="body">The inverse is</p><!--<p class="Body"><span class="times">$$A^{-1} = \frac{1}{det(A)}
\begin{bmatrix}
        a_{22} &amp; -a_{12} \\
        -a_{21} &amp; a_{11}
\end{bmatrix}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="76" src="../../OEBPS/Images/eq_A-02-f.png" width="218"/></p>
</div>
<h2 class="fm-head" id="sec-gaussian-var">A.3 Computing the variance of a Gaussian distribution</h2>
<p class="body">From the integral form of equation <a class="url" href="../Text/05.xhtml#eq-variance">5.13</a>, we have</p><!--<p class="Body"><span class="times">$$var_{gaussian}\left(x\right) =
\int\displaylimits_{x=-\infty}^{\infty}\left(x-\mu\right)^{2} p\left(x\right) dx$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="57" src="../../OEBPS/Images/eq_A-02-g1.png" width="290"/></p>
</div>
<p class="body">Substituting equation <a class="url" href="../Text/05.xhtml#eq-univar-normal">5.22</a>,</p><!--<p class="Body"><span class="times">$p\left(x\right) =   \frac{1}{{\sqrt {2\pi }
\sigma}}e^{{\frac{ - \left( {x - \mu } \right)^2 } {2\sigma ^2
}}}$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="43" src="../../OEBPS/Images/eq_A-02-g2.png" width="153"/></p>
</div>
<p class="body">in that, we get</p><!--<p class="Body"><span class="times">$$var_{gaussian}\left(x\right) =
\int\displaylimits_{x=-\infty}^{\infty}\left(x-\mu\right)^{2}  \frac{1}{{\sqrt
{2\pi } \sigma}}e^{{\frac{ - \left( {x - \mu } \right)^2 } {2\sigma ^2
}}} dx$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="68" src="../../OEBPS/Images/eq_A-02-g3.png" width="358"/></p>
</div>
<p class="body">Substituting <!--<span class="times">$y = \frac{\left(x-\mu\right)}{\sqrt{2}\sigma}$</span>--><span class="infigure"><img alt="" class="calibre5" height="30" src="../../OEBPS/Images/eq_A-02-g4.png" width="68"/></span>, which implies <!--<span class="times">$dy = \frac{dx}{\sqrt{2}\sigma}$</span>--><span class="infigure"><img alt="" class="calibre5" height="28" src="../../OEBPS/Images/eq_A-02-g5.png" width="65"/></span> and <span class="math">2<i class="fm-italics">œÉ</i><sup class="fm-superscript">2</sup><i class="timesitalic">y</i><sup class="fm-superscript">2</sup> = (<i class="fm-italics">x</i> ‚àí <i class="fm-italics">Œº</i>)<sup class="fm-superscript">2</sup></span>, we get</p><!--<p class="Body"><span class="times">$$var_{gaussian}\left(x\right) =
\frac{2\sigma^{2}}{\sqrt{\pi}}\int\displaylimits_{-\infty}^{\infty} ^{2}e^{-y^{2}} dy =
\frac{2\sigma^{2}}{\sqrt{\pi}}\int\displaylimits_{-\infty}^{\infty} \left(ye^{-y^{2}}\right) dy$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="68" src="../../OEBPS/Images/eq_A-02-g6.png" width="427"/></p>
</div>
<p class="body">Using integration by parts,</p><!--<p class="Body"><span class="times">$$\int\displaylimits_{-\infty}^{\infty} \left(ye^{-y^{2}}\right) dy = \ceil[\bigg]{y \left( \int y e^{-y^{2}} dy \right)}_{-\infty}^{\infty} - \int\displaylimits_{-\infty}^{\infty}
\frac{dy}{dy} \left( \int y e^{-y^{2}} \right)  dy$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="68" src="../../OEBPS/Images/eq_A-02-g7.png" width="459"/></p>
</div>
<p class="body">Now, substituting <span class="math"><i class="fm-italics">v</i> = <i class="timesitalic">y</i><sup class="fm-superscript">2</sup></span>, which implies <span class="math"><i class="fm-italics">dv</i>/2 = <i class="fm-italics">y dy</i></span>,</p><!--<p class="Body"><span class="times">$$\int y e^{-y^{2}} dy =  \int e^{-y^{2}}
\left(y  dy\right) =\frac{1}{2} \int e^{-v} dv = -\frac{e^{-v}}{2}
=  -\frac{e^{-y^{2}}}{2}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="58" src="../../OEBPS/Images/eq_A-02-g8.png" width="426"/></p>
</div>
<p class="body">Hence,</p><!--<p class="Body"><span class="times">$$\ceil[\bigg]{y \left( \int y e^{-y^{2}} dy
\right)}_{-\infty}^{\infty} = \ceil[\bigg]{y \left(
\frac{e^{-y^{2}}}{2}\right)}_{-\infty}^{\infty} = \frac{1}{2}\left(
\lim_{y \to \infty} \frac{y}{e^{y^{2}}} -   \lim_{y \to -\infty}
\frac{y}{e^{y^{2}}}  \right)$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="62" src="../../OEBPS/Images/eq_A-02-g9.png" width="464"/></p>
</div>
<p class="body">Such limits can be evaluated using L‚ÄôHospital‚Äôs rule:</p><!--<p class="Body"><span class="times">$$\begin{aligned}
\lim_{y \to \infty} \frac{y}{e^{y^{2}}} &amp;= \lim_{y \to \infty}
\frac{\frac{dy}{dy}}{\frac{d \left(e^{y^{2}}\right)}{dy} } = \lim_{y \to
\infty} \frac{1}{2ye^{y^{2}}} = 0\\[6pt]
\lim_{y \to -\infty} \frac{y}{e^{y^{2}}} &amp;= \lim_{y \to -\infty}
\frac{\frac{dy}{dy}}{\frac{d \left(e^{y^{2}}\right)}{dy} }  = \lim_{y
\to -\infty} \frac{1}{2ye^{y^{2}}} = 0\end{aligned}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="172" src="../../OEBPS/Images/eq_A-02-h1.png" width="316"/></p>
</div>
<p class="body">In both cases, the limit is zero because <span class="math"><i class="fm-italics">e</i><sup class="fm-superscript"><i class="timesitalic1">y</i><sup class="fm-superscript">2</sup></sup></span> goes to positive infinity regardless of whether <i class="timesitalic">y</i> goes to positive or negative infinity. Hence the denominator goes to infinity in both cases, causing the fraction to go to zero.<a id="marker-500"/></p>
<p class="body">Thus the first term in the computation of <span class="math"><i class="fm-italics">var<sub class="fm-subscript">gaussian</sub></i>(<i class="fm-italics">x</i>)</span> becomes<br class="calibre20"/>
<!--<span class="times">$\ceil[\bigg]{y \left( \int y e^{-y^{2}} dy \right)}_{-\infty}^{\infty} = 0 - 0 = 0$</span>--><span class="infigure"><img alt="" class="calibre5" height="46" src="../../OEBPS/Images/eq_A-02-h2.png" width="216"/></span>.<br class="calibre20"/>
  The second term</p><!--<p class="Body"><span class="times">$$\int\displaylimits_{-\infty}^{\infty}
\frac{dy}{dy} \left( \int y e^{-y^{2}} \right)  dy = \frac{1}{2}
\int\displaylimits_{-\infty}^{\infty} e^{-y^{2}} dy$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="68" src="../../OEBPS/Images/eq_A-02-h3.png" width="271"/></p>
</div>
<p class="body">This last integral is a special one. To evaluate it, we need to go from one to two dimensions‚Äîthis may be one of the very few cases where making a problem more complex helps. It is worth examining, so let‚Äôs look at it. Let</p><!--<p class="Body"><span class="times">$$I =
\int\displaylimits_{-\infty}^{\infty} e^{-x^{2}} dx$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="66" src="../../OEBPS/Images/eq_A-02-h4.png" width="106"/></p>
</div>
<p class="body">Since the variable of integration does not matter, we can also write</p><!--<p class="Body"><span class="times">$$I = \int\displaylimits_{-\infty}^{\infty} e^{-y^{2}} dy$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="68" src="../../OEBPS/Images/eq_A-02-h5.png" width="109"/></p>
</div>
<p class="body">Let‚Äôs multiply them together:</p><!--<p class="Body"><span class="times">$$I^{2} =  \int\displaylimits_{-\infty}^{\infty} e^{-x^{2}} dx  \int\displaylimits_{-\infty}^{\infty} e^{-y^{2}} dy =
\int\displaylimits_{-\infty}^{\infty}
\int\displaylimits_{-\infty}^{\infty} e^{-x^{2}} e^{-y^{2}} dx dy =
\int\displaylimits_{-\infty}^{\infty}
\int\displaylimits_{-\infty}^{\infty} e^{-\left(x^{2} + ^{2}\right)}  dx dy$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="70" src="../../OEBPS/Images/eq_A-02-h6.png" width="527"/></p>
</div>
<p class="body">This double integral‚Äôs domain (aka region of integration) is the infinite <i class="timesitalic">XY</i> plane, where <i class="timesitalic">x</i> and <i class="timesitalic">y</i> both range from <span class="math">‚àí‚àû</span> to <span class="math">‚àû</span>. This same plane can also be viewed as an infinite-radius circle (an infinite-radius circle is the same as a rectangle with infinite-length sides!). Consequently, we can switch to polar coordinates, using the transformation</p><!--<p class="Body"><span class="times">$$\begin{aligned}
x &amp;= r cos\left(\theta\right)\\  &amp;= r cos\left(\theta\right)\end{aligned}$$</span></p>
<div class="figure">
<p class="figure2"><img src="imgs/equations/eq_A-02-h7.png" alt="" /></p>
</div>-->
<p class="fm-equation"><span class="math"><i class="fm-italics">x</i> = <i class="fm-italics">r cos</i>(<i class="fm-italics">Œ∏</i>)</span><br class="calibre20"/>
<span class="math"><i class="fm-italics">y</i> = <i class="fm-italics">r cos</i>(<i class="fm-italics">Œ∏</i>)</span></p>
<p class="body">which implies</p><!--<p class="Body"><span class="times">$$\begin{aligned}
x^{2} + y^{2} &amp;= r^{2}\\ dx dy = r dr d\theta\end{aligned}$$</span> <span class="times">$$I^{2} =
\int\displaylimits_{r=0}^{r=\infty}\int\displaylimits_{\theta=0}^{\theta=2\pi} e^{-r^{2}} r\;dr\; d\theta = \int\displaylimits_{r=0}^{r=\infty} e^{-r^{2}} r\;dr \int\displaylimits_{\theta=0}^{\theta=2\pi} d\theta = 2\pi  \int\displaylimits_{r=0}^{r=\infty} e^{-r^{2}} r\;dr$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="135" src="../../OEBPS/Images/eq_A-02-i1.png" width="472"/></p>
</div>
<p class="body">Substituting <span class="math"><i class="fm-italics">v</i> = <i class="fm-italics">r</i><sup class="fm-superscript">2</sup></span>, which implies <span class="math"><i class="fm-italics">dv</i> = 2<i class="fm-italics">rdr</i></span>, we get</p><!--<p class="Body"><span class="times">$$I^{2} =  \pi
\int\displaylimits_{0}^{\infty} e^{-v} dv = \pi
\ceil[\bigg]{-e^{-v}}_{v=0}^{v=\infty} = \pi \Rightarrow I =
\sqrt{\pi}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="64" src="../../OEBPS/Images/eq_A-02-i2.png" width="334"/></p>
</div>
<p class="body">Thus, the second term of <span class="math"><i class="fm-italics">var<sub class="fm-subscript">gaussian</sub></i>(<i class="fm-italics">x</i>)</span> evaluates to <!--<span class="times">$\frac{\sigma^{2}}{\sqrt{\pi}}\frac{\sqrt{\pi}}{2}$</span>--><span class="infigure"><img alt="" class="calibre5" height="31" src="../../OEBPS/Images/eq_A-02-i3.png" width="41"/></span>. We have already shown that the first term evaluates to zero. So, we get</p>
<p class="fm-equation"><span class="math"><i class="fm-italics">var<sub class="fm-subscript">gaussian</sub></i>(<i class="fm-italics">x</i>) = <i class="fm-italics">œÉ</i><sup class="fm-superscript">2</sup></span></p>
<p class="body">Thus the <i class="timesitalic">œÉ</i> in the probability density function <!--<span class="times">$p\left(x\right)=   \frac{1}{{\sqrt {2\pi } \sigma}}e^{{\frac{ - \left( {x - \mu }\right)^2 } {2\sigma ^2 }}}$</span>--><span class="infigure"><img alt="" class="calibre5" height="41" src="../../OEBPS/Images/eq_A-02-i5.png" width="149"/></span> is the standard deviation (square root of the variance), and the <i class="timesitalic">Œº</i> is the expected value.</p>
<h2 class="fm-head" id="a.4-two-theorems-in-statistics">A.4 Two theorems in statistics</h2>
<p class="body"><a id="marker-501"/>In this section, we study two important inequalities in multivariate statistics: Jensen‚Äôs inequality and the log-sum inequality.</p>
<h3 class="fm-head1" id="sec-jensen-ineq">A.4.1 Jensen‚Äôs Inequality</h3>
<p class="body">Consider a random variable <i class="timesitalic">X</i>. For now, let‚Äôs think of these as discrete variables, although the results we will come up with apply equally well to continuous variables. Thus, let the random variable take the discrete values <span class="math"><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span><sub class="fm-subscript">1</sub></span>, <span class="math"><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span><sub class="fm-subscript">2</sub></span>, <span class="math">‚ãØ</span>, <span class="math"><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span><i class="fm-italics"><sub class="fm-subscript">n</sub></i></span>, with probabilities <span class="math"><i class="fm-italics">p</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span><sub class="fm-subscript">1</sub>)</span>, <span class="math"><i class="fm-italics">p</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span><sub class="fm-subscript">2</sub>)</span>, <span class="math">‚ãØ</span>, <span class="math"><i class="fm-italics">p</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span><i class="fm-italics"><sub class="fm-subscript">n</sub></i>)</span>.</p>
<p class="body">Now suppose <span class="math"><i class="fm-italics">g</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span>)</span> is a convex function whose domain includes these random variables. From equation <a class="url" href="../Text/03.xhtml#eq-convexity-wt-avg">3.11</a>, section <a class="url" href="../Text/03.xhtml#sec-conv-functions">3.7</a>, we know that given any convex function <span class="math"><i class="fm-italics">g</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span>)</span>, for an arbitrary set of its input values <span class="math"><span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span><i class="fm-italics"><sub class="fm-subscript">i</sub></i>, <i class="fm-italics">i</i> = 1‚ãØ<i class="fm-italics">n</i></span> and a set of weights <span class="math"><i class="fm-italics">Œ±<sub class="fm-subscript">i</sub></i> <i class="fm-italics">i</i> = 1‚ãØ<i class="fm-italics">n</i></span> satisfying <!--<span class="times">$\sum_{i=1}^{n} \alpha_{i} = 1$</span>--><span class="infigure"><img alt="" class="calibre5" height="19" src="../../OEBPS/Images/eq_A-02-i6a.png" width="75"/></span>, the weighted sum of the function outputs is greater than or equal to the function‚Äôs output on the weighted sum of inputs: that is, <!--<span class="times">$\sum_{i=1}^{n} \alpha_{i} g\left(\vec{x}_{i}\right) \geq g\left(\sum_{i=1}^{n}\alpha_{i}  \vec{x}_{i}\right)$</span>--><span class="infigure"><img alt="" class="calibre5" height="22" src="../../OEBPS/Images/eq_A-02-i6.png" width="214"/></span></p>
<p class="body">In particular, let‚Äôs choose the set of all random variables as input values and their probabilities as weights (<span class="math"><i class="fm-italics">Œ±<sub class="fm-subscript">i</sub></i> = <i class="fm-italics">p</i>(<span class="infigure"><img alt="" class="calibre9" height="24" src="../../OEBPS/Images/AR_x.png" width="14"/></span><i class="fm-italics"><sub class="fm-subscript">i</sub></i>)</span>). We can do this because probabilities sum to <span class="math">1</span>, exactly as weights are supposed to do. This leads to</p><!--<span class="times">$$\sum_{i=1}^{n} p\left(x_{i}\right) g\left(\vec{x}_{i}\right) \geq g\left(\sum_{i=1}^{n} p\left(x_{i}\right) \vec{x}_{i}\right)
\implies
\mathbb{E}\left(g\left(X\right)\right) \geq g\left(\mathbb{E}\left(X\right)\right)$$</span>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="68" src="../../OEBPS/Images/eq_A-03.png" width="465"/></p>
</div>
<p class="fm-equation-caption">Equation A.3 <span class="calibre" id="eq-jensen"/></p>
<p class="body">Equation <a class="url" href="#eq-jensen">A.3</a> is Jensen‚Äôs inequality. A good mnemonic for it is: <i class="fm-italics">for a convex function, the expected value of the function is greater than or equal to the function of expected value</i>. It holds for continuous random variables, too.</p>
<h3 class="fm-head1" id="sec-logsum-ineq">A.4.2 Log sum inequality</h3>
<p class="body">Suppose we have two sets of positive numbers <span class="math"><i class="fm-italics">a</i><sub class="fm-subscript">1</sub></span>, <span class="math"><i class="fm-italics">a</i><sub class="fm-subscript">2</sub></span>, <span class="math">‚ãØ</span>, <i class="timesitalic">a<sub class="fm-subscript">n</sub></i> and <span class="math"><i class="fm-italics">b</i><sub class="fm-subscript">1</sub></span>, <span class="math"><i class="fm-italics">b</i><sub class="fm-subscript">2</sub></span>, <span class="math">‚ãØ</span>, <i class="timesitalic">b<sub class="fm-subscript">n</sub></i>. Let <span class="math"><i class="fm-italics">a</i> = Œ£<i class="fm-italics1"><sub class="fm-subscript">i</sub><sup class="fm-superscript">n</sup></i><sub class="fm-subscript">= 1</sub> <i class="fm-italics">a<sub class="fm-subscript">i</sub></i></span> and <span class="math"><i class="fm-italics">b</i> = Œ£<i class="fm-italics1"><sub class="fm-subscript">i</sub><sup class="fm-superscript">n</sup></i><sub class="fm-subscript">= 1</sub> <i class="fm-italics">b<sub class="fm-subscript">i</sub></i></span>. Given these, the log sum inequality theorem says,<a id="marker-502"/></p><!--<p class="Body"><span class="times">$$\sum_{i=1}^{n} a_{i}log
\left(\frac{a_{i}}{b_{i}}\right) \geq a log\left(\frac{a}{b}\right)$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="57" src="../../OEBPS/Images/eq_A-04.png" width="195"/></p>
</div>
<p class="fm-equation-caption">Equation A.4 <span class="calibre" id="eq-logsum-ineq"/></p>
<p class="body">To see why this is true, let‚Äôs carve out an informal proof. First let‚Äôs define <span class="math"><i class="fm-italics">g</i>(<i class="fm-italics">x</i>) = <i class="fm-italics">xlogx</i></span>. This is a convex function because</p><!--<p class="Body"><span class="times">$$\frac{dg}{dx} = \frac{dx}{dx} log x + x
\frac{d\left(log x\right)}{dx} = log x + x\frac{1}{x} = log x + 1
\implies \frac{d^{2}g}{dx^{2}} = \frac{1}{x} &gt; 0 \text{\;\;\;(for positive $x$)}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="54" src="../../OEBPS/Images/eq_A-04-a.png" width="633"/></p>
</div>
<p class="body">Now, with that definition of <i class="timesitalic">g</i>,</p><!--<p class="Body"><span class="times">$$\sum_{i=1}^{n} a_{i}log \frac{a_{i}}{b_{i}} =
\sum_{i=1}^{n} b_{i} g\left(\frac{a_{i}}{b_{i}}\right) = b
\sum_{i=1}^{n}
\frac{b_{i}}{b}  g\left(\frac{a_{i}}{b_{i}}\right)$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="60" src="../../OEBPS/Images/eq_A-04-b.png" width="319"/></p>
</div>
<p class="body">This last expression is a weighted sum of convex function outputs with the weights summing to <span class="math">1</span> (since <span class="math">Œ£<i class="fm-italics1"><sub class="fm-subscript">i</sub><sup class="fm-superscript">n</sup></i><sub class="fm-subscript">= 1</sub> <i class="fm-italics">b<sub class="fm-subscript">i</sub></i>/<i class="fm-italics">b</i> = 1</span>). So, we can use equation <a class="url" href="../Text/03.xhtml#eq-convexity-wt-avg">3.11</a>, section <a class="url" href="../Text/03.xhtml#sec-conv-functions">3.7</a>. Then we get</p><!--<p class="Body"><span class="times">$$b \sum_{i=1}^{n}
\frac{b_{i}}{b}  g\left(\frac{a_{i}}{b_{i}}\right) \geq b\,g\left(\sum_{i=1}^{n} \frac{b_{i}}{b} \frac{a_{i}}{b_{i}}\right) = b\,g\left(\sum_{i=1}^{n}  \frac{a_{i}}{b}\right) = b\,g\left(\frac{\sum_{i=1}^{n} a_{i}}{b}\right)
=  b\,g\left(\frac{a}{b}\right) = a\,log
\left(\frac{a}{b}\right)$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="71" src="../../OEBPS/Images/eq_A-04-c.png" width="619"/></p>
</div>
<h2 class="fm-head" id="sec-gamma_distribution">A.5 Gamma functions and distribution</h2>
<p class="body">To understand the gamma distribution, we need to understand the basic gamma function. First let‚Äôs do an overview of the gamma function.</p>
<h3 class="fm-head1" id="sec-gamma_function">A.5.1 Gamma function</h3>
<p class="body">The gamma function is in some sense a generalization of the factorial. The factorial function is only defined for integers and is characterized by the basic equation</p>
<p class="fm-equation"><span class="math"><i class="fm-italics">n</i>! = <i class="fm-italics">n</i>(<i class="fm-italics">n</i> ‚àí 1)!</span></p>
<p class="body">The gamma function is defined by</p><!--<p class="Body"><span class="times"><i class="fm-italics">Œì</em>(<i class="fm-italics">Œ±</em>) = ‚à´<sub class="FM-Subscript"><i class="fm-italics">x</em> = 0</sub><sup class="FM-Superscript">‚àû</sup><i class="fm-italics">x</em><sup class="FM-Superscript">(<i class="fm-italics">Œ±</em> ‚àí 1)</sup><i class="fm-italics">e</em><sup class="FM-Superscript">‚àí<i class="fm-italics">x</em></sup><i class="fm-italics">dx</em></span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="55" src="../../OEBPS/Images/eq_A-05.png" width="198"/></p>
</div>
<p class="fm-equation-caption">Equation A.5 <span class="calibre" id="eq-gamma-func"/></p>
<p class="body">Applying integration by parts to equation <a class="url" href="#eq-gamma-func">A.5</a>, we get</p><!--<p class="Body"><span class="times">$$\begin{aligned}
\Gamma\left( \alpha \right)
&amp;= \left[ x^{ \left( \alpha - 1 \right) } \left( -e^{ -x } \right)
\right]_{0}^{ \infty } - \int_{ x = 0 }^{ \infty } \left( \alpha - 1
\right) x^{ \left( \alpha - 2 \right) } \left( -e^{ -x } \right)  dx
\\[3pt]
&amp;= \left[ x^{ \left( \alpha - 1 \right) } \left( -e^{ -x }
\right)  \right]_{0}^{ \infty }  + \int_{ x = 0 }^{ \infty } \left(
\alpha - 1 \right) x^{ \left( \alpha - 2 \right) } \left( e^{ -x }
\right)  dx\end{aligned}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="111" src="../../OEBPS/Images/eq_A-05-a.png" width="441"/></p>
</div>
<p class="body">The first term is zero. This is because</p><!--<p class="Body"><span class="times">$$\begin{aligned}
&amp;\lim_{x \longrightarrow 0} \frac{ x^{ \left( \alpha - 1 \right) }
}{ e^{ x } } = 0 \\[3pt]
&amp;\lim_{x \longrightarrow \infty} \frac{ x^{ \left( \alpha - 1
\right) } }{ e^{ x } } = 0 \;\;\;\text{by repeated application of L'Hospital's rule}\end{aligned}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="104" src="../../OEBPS/Images/eq_A-05-b.png" width="481"/></p>
</div>
<p class="body">Hence,</p><!--<p class="Body"><span class="times">$$\begin{aligned}
\Gamma\left( \alpha \right) = \int_{ x = 0 }^{ \infty } \left( \alpha - 1 \right) x^{ \left( \alpha - 2 \right) } \left( e^{ -x } \right)  dx =
\left( \alpha - 1 \right) \Gamma\left( \alpha - 1
\right)\end{aligned}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="53" src="../../OEBPS/Images/eq_A-05-c.png" width="418"/></p>
</div>
<p class="body">Thus, for integer values <span class="math"><i class="fm-italics">Œ±</i> = <i class="fm-italics">n</i></span>, <span class="math"><i class="fm-italics">Œì</i>(<i class="fm-italics">n</i>) = <i class="fm-italics">n</i>!</span>. There are other equivalent definitions of the gamma function, but we will not discuss them here. Instead, let‚Äôs talk about the gamma distribution.</p>
<h3 class="fm-head1" id="a.5.2-gamma-distribution">A.5.2 Gamma distribution</h3>
<p class="body">The probability density function for a random variable having a gamma distribution is a function with two parameters <i class="timesitalic">Œ±</i> and <i class="timesitalic">Œ≤</i>:<a id="marker-503"/></p><!--<span class="times">$$p\left( x \middle\vert \alpha, \beta \right) =
\gamma \left(x; \alpha, \beta \right) = \frac{ \beta^{ \alpha } }{
\Gamma\left( \alpha \right) } x^{ \left( \alpha - 1 \right)} e^{ - \beta
x }\;\;\;\;\;\text{    where $\alpha, \beta &gt; 0$, $x \geq 0$
}$$</span>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="58" src="../../OEBPS/Images/eq_A-06.png" width="517"/></p>
</div>
<p class="fm-equation-caption">Equation A.6</p>
<p class="body">It is not hard to see that this is a proper probability density function:</p><!--<p class="Body"><span class="times">‚à´<sub class="FM-Subscript"><i class="fm-italics">x</em> = 0</sub><sup class="FM-Superscript">‚àû</sup><i class="fm-italics">p</em>(<i class="fm-italics">x</em>|<i class="fm-italics">Œ±</em>, <i class="fm-italics">Œ≤</em>)<i class="fm-italics">dx</em> = 1</span></p>>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="49" src="../../OEBPS/Images/eq_A-06-a.png" width="168"/></p>
</div>
<p class="body">By substituting <span class="math"><i class="fm-italics">y</i> = <i class="fm-italics">Œ≤x</i></span>, we get</p><!--<p class="Body"><span class="times">$$p\left( x \middle\vert \alpha, \beta
\right) = \frac{ \beta^{ \alpha } }{ \Gamma\left( \alpha \right) }
\int_{ y = 0}^{ y = \infty } \left( \frac{ y }{ \beta } \right)^{ \left(
\alpha - 1 \right)} e^{ - y } \frac{ dy }{ \beta } \\
                        = \frac{ \int_{ y = 0 }^{ \infty } y ^{ \left(
\alpha - 1 \right)} e^{ - y }  dy  }{ \Gamma\left( \alpha \right) } =
\frac{ \Gamma\left( \alpha \right) }{ \Gamma\left( \alpha \right)  } = 1$$</span></p>>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="65" src="../../OEBPS/Images/eq_A-06-b.png" width="572"/></p>
</div>
<p class="body">If <span class="math"><i class="fm-italics">Œ±</i> = 1</span>, the gamma distribution reduces to</p><!--<p class="Body"><span class="times">$$p\left( x \right) =
\frac{ \beta }{ \Gamma\left( 1 \right) } e^{ - \beta x } = \beta \, e^{
- \beta x } \text{ ( it can be shown that $\Gamma\left( 1 \right) = 1$ )
}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="48" src="../../OEBPS/Images/eq_A-06-c.png" width="465"/></p>
</div>
<p class="body">which is graphed in figure <a class="url" href="#fig-gamma1">A.2a</a> at several values of <i class="timesitalic">Œ≤</i>. The gamma distribution has two terms <span class="math"><i class="fm-italics">x</i><sup class="fm-superscript"><i class="fm-italics1">Œ±</i>‚àí1</sup></span> and <span class="math"><i class="fm-italics">e</i><sup class="fm-superscript">‚àí<i class="fm-italics1">Œ≤x</i></sup></span> that have somewhat opposite effects: the former increases with <i class="timesitalic">x</i>, while the latter deceases with <i class="timesitalic">x</i>. At smaller values of <i class="timesitalic">x</i>, the former wins, and the product increases with <i class="timesitalic">x</i>. But eventually, the exponential starts winning and pulls the product downward asymptotically toward zero. Thus the gamma distribution has a peak. Larger <i class="timesitalic">Œ≤</i> results in taller peaks and a sharper decline toward zero. Larger <i class="timesitalic">Œ±</i> moves the peak further to the right. The expected value is <span class="math"><span class="segoe">ùîº</span>(<i class="fm-italics">x</i>) = <i class="fm-italics">Œ±</i>/<i class="fm-italics">Œ≤</i></span>, as illustrated in figure <a class="url" href="#fig-gamma">A.2</a>.</p>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre17" height="367" id="fig-gamma1" src="../../OEBPS/Images/APPA_F01a_Chaudhury.png" width="522"/></p>
<p class="figurecaption">(a) Gamma distribution: <span class="math"><i class="fm-italics">Œ±</i> = 1</span>, various <i class="timesitalic">Œ≤</i>s</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre17" height="367" id="fig-gamma2" src="../../OEBPS/Images/APPA_F01b_Chaudhury.png" width="522"/></p>
<p class="figurecaption">(b) Gamma distribution: <span class="math"><i class="fm-italics">Œ≤</i> = 1</span>, various <i class="timesitalic">Œ±</i>s</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre17" height="367" id="fig-gamma3" src="../../OEBPS/Images/APPA_F01c_Chaudhury.png" width="522"/></p>
<p class="figurecaption">(c) Gamma distribution: <span class="math"><i class="fm-italics">Œ±</i> = 2</span>, various <i class="timesitalic">Œ≤</i>s</p>
</div>
<div class="figure3">
<p class="figure1"><img alt="" class="calibre17" height="367" id="fig-gamma4" src="../../OEBPS/Images/APPA_F01d_Chaudhury.png" width="522"/></p>
<p class="figurecaption">(d) Gamma distribution: <span class="math"><i class="fm-italics">Œ≤</i> = 2</span>, various <i class="timesitalic">Œ±</i>s</p>
</div>
<p class="fm-table-caption" id="fig-gamma">Figure A.2 Graph of a gamma distribution for various values of <i class="timesitalic">Œ±</i> and <i class="timesitalic">Œ≤</i>. Larger <i class="timesitalic">Œ≤</i> results in taller peaks and a sharper decline toward zero. Larger <i class="timesitalic">Œ±</i> moves the peak to the right. The expected value is <span class="math"><span class="segoe">ùîº</span>(<i class="fm-italics">x</i>) = <i class="fm-italics">Œ±</i>/<i class="fm-italics">Œ≤</i></span>.<a id="marker-504"/></p>
<p class="body">The expected value of the gamma distribution <span class="math"><span class="segoe">ùîº</span>(<i class="fm-italics">x</i>) = <i class="fm-italics">Œ±</i>/<i class="fm-italics">Œ≤</i></span>. This can be proved using a little trick so cool that it is worth discussing for that reason alone:</p><!--<p class="Body"><span class="times">$$\mathbb{E} \left( x \right) = \int_{ x=0 }^{
\infty } x p \left( x \middle\vert \alpha, \beta \right) dx
                                         = \frac{ \beta^{ \alpha } } {
\Gamma\left( \alpha \right) } \int_{ x=0 }^{ \infty } x x^{ \left(
\alpha - 1 \right) } e^{ - \beta x } dx
                                         = \frac{ \beta^{ \alpha } } {
\Gamma\left( \alpha \right) } \int_{ x=0 }^{ \infty } x^{ \alpha } e^{ -
\beta x } dx$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="56" src="../../OEBPS/Images/eq_A-06-d.png" width="601"/></p>
</div>
<p class="body">But the gamma distribution</p><!--<p class="Body"><span class="times">$$\begin{aligned} p\left( x \middle\vert \alpha + 1, \beta \right) = \frac{ \beta^{ \alpha
+ 1 } } { \Gamma\left( \alpha + 1 \right) } x^{ \left( \alpha \right)} e^{ - \beta x }\end{aligned}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="55" src="../../OEBPS/Images/eq_A-06-e.png" width="266"/></p>
</div>
<p class="body">or</p><!--<p class="Body"><span class="times">$$\begin{aligned}
x^{ \left( \alpha \right)} e^{ - \beta x } = \frac{ \Gamma\left( \alpha
+ 1 \right) }{ \beta^{ \alpha + 1 } }  p\left( x \middle\vert \alpha + 1, \beta \right)\end{aligned}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="52" src="../../OEBPS/Images/eq_A-06-f.png" width="269"/></p>
</div>
<p class="body">Using this,</p><!--<p class="Body"><span class="times">$$\begin{aligned}
\mathbb{E} \left( x \right) = \frac{ \beta^{ \alpha } } { \Gamma\left(
\alpha \right) } \frac{ \Gamma\left( \alpha + 1 \right) }{ \beta^{
\alpha + 1 } }
\overbrace{ \int_{x=0}^{\infty} p\left( x \middle\vert \alpha + 1, \beta
\right)  dx }^{=1} =  \frac{ \beta^{ \alpha } } { \Gamma\left( \alpha
\right) } \frac{ \alpha \Gamma\left( \alpha \right) }{ \beta \beta^{
\alpha  } } = \frac{ \alpha }{ \beta }\end{aligned}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="87" src="../../OEBPS/Images/eq_A-06-g.png" width="500"/></p>
</div>
<p class="fm-head2" id="maximum-of-a-gamma-distribution">Maximum of a gamma distribution</p>
<p class="body"><a id="marker-505"/>To maximize the gamma probability density function <span class="math"><i class="fm-italics">p</i>(<i class="fm-italics">Œª</i>|<i class="fm-italics">X</i>) = <i class="fm-italics">Œª</i><sup class="fm-superscript">(<i class="fm-italics1">Œ±<sub class="fm-subscript">n</sub></i> ‚àí 1)</sup><i class="fm-italics">e</i><sup class="fm-superscript">‚àí<i class="fm-italics1">Œ≤<sub class="fm-subscript">n</sub>Œª</i></sup></span> for a random variable <i class="timesitalic">Œª</i>, we take the derivative and equate to zero:</p><!--<p class="Body"><span class="times">$$\begin{aligned}
&amp;\frac{d}{ d \lambda } \left( \lambda^{ \alpha - 1 } e^{ -\beta
\lambda} \right) = 0 \implies \left( \alpha - 1 \right) \lambda^{ \alpha
- 1 } e^{ -\beta \lambda} + \lambda^{ \alpha - 1 } \left( -\beta \right) e^{ -\beta \lambda} = 0 \\
&amp;\lambda = \frac{ \alpha - 1 }{ \beta }\end{aligned}$$</span></p>-->
<div class="figure">
<p class="figure2"><img alt="" class="calibre5" height="97" src="../../OEBPS/Images/eq_A-06-h.png" width="494"/></p>
</div>
</div></body></html>