- en: Appendix B. Answer Key
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chapter 2 Answer Key
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'B: While AWS is responsible for securing the underlying infrastructure and
    its physical security, customers are accountable for securing their applications,
    configuring security settings, and managing their cloud environments.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: AWS Lambda is a serverless computing service. Amazon EC2 is an IaaS offering
    due to its provision of virtualized compute resources. Amazon RDS is a PaaS due
    to its managed database capabilities. Amazon Chime is a SaaS application for communications.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Amazon RDS is a managed relational database service, Amazon S3 provides
    storage capabilities, Amazon EC2 offers scalable virtual machines in the cloud,
    and AWS Glue is utilized for data preparation and transformation.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Public cloud environments do not offer full control over infrastructure
    or operate on a multi-tenant model to achieve cost savings through shared resources.
    While public cloud providers implement robust security, no system is entirely
    immune to cyber threats.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Cloud computing eliminates the need for companies to purchase and manage
    physical servers, provides on-demand access to IT resources such as storage and
    computing power, is distinct from on-premises environments like private data centers,
    and while it can support AI applications, its overall definition is much broader.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: IAM is responsible for managing permissions, roles, and policies to secure
    AWS resources, but not for direct encryption. In contrast, AWS CloudWatch and
    AWS CloudTrail are dedicated to monitoring and logging activities within AWS,
    while AWS Backup is the specific service designed for automated backup processes.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 3 Answer Key
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A: Feature engineering transforms raw data to improve model accuracy and performance.
    Although it can aid in bias reduction, it is not the sole determinant of fairness
    in models. Model training involves an algorithm that learns patterns from data.
    Model evaluation assesses performance post-training.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Supervised learning involves models learning from labeled examples, whereas
    reinforcement learning trains models through trial and error with rewards and
    penalties. Additionally, anomaly detection typically employs unsupervised learning,
    while dimensionality reduction aims to decrease the number of input features.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: SageMaker simplifies and automates ML workflows, allowing users to train,
    tune, and deploy models efficiently. It also reduces manual intervention through
    automation. It provides both pretrained and customizable models.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Supervised learning requires labeled data to learn patterns and can be used
    for classification and regression tasks. In contrast, unsupervised learning identifies
    structures and patterns in unlabeled data, primarily for clustering and dimensionality
    reduction, and reinforcement learning is a distinct paradigm separate from both.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Unsupervised learning is used for clustering and finding patterns in data
    without predefined labels, making it suitable for customer segmentation. Reinforcement
    learning is for sequential decision-making and not clustering. Supervised learning
    is unsuitable for this task as it requires labeled data, which is typically unavailable
    for segmentation. Semisupervised learning is a hybrid approach not necessary for
    this task.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: The main purpose of model monitoring is to track performance over time,
    identify issues like data drift, and ensure consistent accuracy in real-world
    applications. It helps determine when retraining is necessary but does not eliminate
    the need for it, as no ML model can guarantee 100% accuracy in all scenarios.
    And although reducing features can improve generalization, it’s not the primary
    goal of monitoring.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 4 Answer Key
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'C: Generative Adversarial Networks (GANs) employ two competing neural networks—a
    generator and a discriminator—to produce realistic content. VAE utilizes a complex
    probabilistic system for encoding and decoding data, while the Transformer model
    leverages attention mechanisms to comprehend intricate patterns. Lastly, diffusion
    models create realistic content, such as images, through a process of adding and
    removing noise.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Positional encoding is crucial in models utilizing attention mechanisms,
    as it reorders words that become out of sequence after attention is applied. It
    does not enhance GPU reliability or reduce the cost of an AI model. Backpropagation
    is the mechanism by which a deep learning model refines its results.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: A key advantage of RAG is its ability to search data from an external vector
    database, which eliminates the need to modify the internal weights of the model.
    While RAG generally uses less computational power, this is not considered its
    primary advantage. RAG might actually increase response latency due to data processing.
    And although RAG can help reduce bias, it will not eliminate it entirely.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: A key advantage of transformer models, due to attention mechanisms, is their
    ability to process large datasets in parallel, whereas RNNs process data sequentially.
    Both transformer and RNN models can utilize labeled data. RNNs are designed for
    text processing, and transformers typically require training with substantial
    amounts of data.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: The transformer model’s use of complex probability systems with large datasets
    can sometimes result in false or misleading responses. GPUs, while crucial for
    AI, are not unpredictable. The presence of labeled data in model training does
    not inherently lead to hallucinations. Hallucinations are not exclusive to large
    models but can occur across small and medium size models.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: The hidden layer is where weights are applied to inputs, which enables the
    model to detect patterns. The input layer receives the raw data and the output
    layer produces the network’s response. There is no activation layer in a neural
    network.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 5 Answer Key
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'C: NLP is a broader field used for various language-related applications like
    translation and sentiment analysis, whereas IDP is a more specialized subset of
    NLP. IDP primarily focuses on automating the processing of business documents,
    extracting and classifying information from both structured and unstructured formats.
    While NLP can handle spoken data, IDP’s main scope is document-based input, although
    both can process various forms of input beyond just handwritten or printed language.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Amazon Translate provides capabilities for translating text between various
    languages. Amazon Comprehend is designed for NLP tasks like sentiment analysis
    and entity recognition. Amazon Polly specializes in converting text into lifelike
    speech. Amazon Textract is used for extracting text from images and documents.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: Amazon Kendra is an AI-powered search service that utilizes natural language
    queries; it is not a financial analysis tool. Amazon Translate is used for translating
    foreign languages, while Amazon Polly provides text-to-speech conversion services.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Kendra’s use of RAG allows it to produce more relevant and context-aware
    search results. Kendra does not use a quantum database and linear regression is
    not central to Kendra’s advanced capabilities. While keyword matching is a fundamental
    search approach, it’s not an AI feature.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: Amazon Transcribe converts audio into written text. Amazon Translate converts
    text into another language. Amazon Comprehend can be used to extract various information
    from a document for sentiment analysis.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: Amazon Polly provides the capability to generate human-sounding speech from
    text. Amazon Transcribe converts speech to text, Amazon Translate can translate
    text into other languages, and Amazon Comprehend is used to extract insights and
    perform data analytics.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 6 Answer Key
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'B: Although the model will continue to work, combining both can lead to unpredictable
    responses and is not generally recommended. Using both does not guarantee accuracy
    and does not necessarily mean the responses will be deterministic.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: A negative prompt is used to exclude unwanted elements (e.g., blurry, cartoon).
    It does not change the colors of an image or impact the size of the image. Temperature
    is used for text responses.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: Modality refers to the input and output types for a model, such as text,
    image, audio, and multimodal. Modality is distinct from the model’s license type,
    language support, or whether it can be deployed serverlessly.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: A higher temperature will make the content more creative. A higher temperature
    encourages less deterministic content and is also less effective for tasks like
    summarization, since the content will be more random and creative. Temperature
    is not used for creating videos.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: A model profile in Amazon Bedrock includes more than just the license information,
    such as the version, release date, deployment type, modalities, and model ID.
    It will not include information about GPU usage or datasets.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Users must submit a form with details such as company name, use case, and
    intended users. Provisioned mode is related to model inference, not access. A
    certification exam is not required to use the models. Models cannot be directly
    downloaded from Bedrock.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 7 Answer Key
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'C: Instruction is required. Without it, the model won’t know what to do. Context
    is helpful but not required. Input data is only needed when you want the model
    to analyze something specific. The output indicator is for formatting but is not
    essential.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: The output indicator instructs the model on what the response should look
    like, say as a table or CSV format. The output indicator does not provide examples
    of how to write better prompts. The context component provides background information
    for the task. Prompting is not the same as training.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Context improves the model’s ability to understand the task, by providing
    relevant background information. The input data component supplies relevant input
    data. The output indicator specifies the output format. While context can include
    past interactions, it’s not used to summarize them.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Delimiters improve prompt clarity by showing where the input begins. They
    do not reduce token count. They are not intended to separate formatting options
    and they only affect the current prompt.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Defining the user’s role helps shape the LLM’s understanding and tone.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Few-shot prompting is where you provide examples to guide the model..'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 8 Answer Key
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'C: Early stopping prevents the model from memorizing the training data. Increasing
    the complexity of the model usually increases the risk of overfitting. Noisy data
    increases variance and reduces performance. Tuning hyperparameters is important
    to balance bias and variance.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: Licensing agreements—like OpenAI’s deal with News Corp—are being used to
    address IP concerns. Removing all public data is impractical and not a standard
    solution. Restricting access doesn’t solve IP ownership issues. Internal limits
    will reduce exposure, but this doesn’t fully resolve IP problems.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: Without accuracy, models can be unsafe or untrustworthy. However, even accurate
    models require regular retraining. Cost savings may result from accuracy but aren’t
    the core reason it’s important for responsible AI. And accuracy is important across
    all model types, not just visual ones.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: Fairness means AI decisions should be impartial and nondiscriminatory. It
    is unrelated to model sophistication and it focuses on equity, not speed. Personalization
    may actually introduce bias if not managed carefully.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Explainability helps users understand specific outputs, whereas transparency
    is about system-wide openness. These concepts are closely related but not interchangeable.
    User interface design is unrelated to the core concept of explainability. Transparency
    is encouraged in all systems, not just open source models.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Privacy and security are about protecting individual data and user rights.
    Model weights and parameters are technical aspects, not user-focused. Transparency
    relates to openness, not data protection. While IP is important, it’s not the
    focus of privacy and security.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Chapter 9 Answer Key
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'C: Governance provides a structure for wise decision making and innovation
    management, while compliance ensures rules and standards are consistently followed.
    Governance is not about enforcing laws. Protecting data is part of security, and
    ethical development is shared across functions. Governance is essential for organizational
    success and is not optional.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: Defense in depth means layering defenses so there are multiple safeguards.
    It assumes no single control is sufficient on its own. Although multiple, layered
    security measures are partially correct, this doesn’t fully explain the idea of
    backup controls stepping in. Automation of pipelines is important but not part
    of defense in depth.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: AWS Shield mitigates DoS attacks, and Amazon Cognito securely handles user
    authentication and federation. GuardDuty detects threats, and Private CA manages
    certificates. AWS KMS and AWS ACM both help encrypt data and manage certificates.
    Amazon VPC and AWS WAF help with network and web layer protection.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: PrivateLink enables private connectivity between VPCs and AWS services without
    public internet exposure. Security Hub aggregates security alerts. Amazon VPC
    creates private networks but does not specifically handle private routing across
    services. GuardDuty detects suspicious activity.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Governance policies include clear standards for sourcing data, training
    models, evaluating results, and approving deployments. Human oversight is critical
    in AI governance to ensure ethical use. Public datasets still require privacy
    and bias evaluations. Unrestricted deployment increases legal, ethical, and operational
    risks.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: HIPAA governs the security and privacy of protected health information (PHI)
    in the US. PCI DSS focuses on protecting payment card information; GDPR is about
    personal data privacy for EU residents; and ENISA focuses on cybersecurity standards
    for the EU.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Practice Exam Answer Key
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'B: AZs provide redundancy and fault tolerance within AWS regions. An AZ consists
    of multiple data centers but is not itself a single data center. Security groups
    control access but do not define infrastructure zones. AWS regions are separate
    from AZs, and neither span multiple continents. See [Chapter 2](ch02.html#chapter_two_aws_fundamentals_for_the_ai).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: SaaS delivers fully managed applications. IaaS provides virtualized hardware,
    PaaS offers tools for developers, but neither of these include fully managed applications.
    VaaS is not a standard cloud computing model. See [Chapter 2](ch02.html#chapter_two_aws_fundamentals_for_the_ai).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Hybrid cloud integrates both private and public cloud environments for flexibility
    and lower costs. Hybrid cloud allows data and applications to be shared between
    cloud environments, rather than relying solely on on-premises systems. Multitenancy
    is a feature of public clouds. See [Chapter 2](ch02.html#chapter_two_aws_fundamentals_for_the_ai).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: AWS regions help meet compliance needs by allowing users to store data in
    specific geographic locations. They contain multiple AZs; they do not replace
    them. AWS regions are available worldwide. Computing power is not unlimited, and
    redundancy is a core AWS feature. See [Chapter 2](ch02.html#chapter_two_aws_fundamentals_for_the_ai).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: AWS Lambda is a serverless compute service that runs code without managing
    infrastructure. Amazon EC2 requires users to manage server instances. Amazon RDS
    is a database service. Amazon CloudFront is a content delivery network (CDN).
    See [Chapter 2](ch02.html#chapter_two_aws_fundamentals_for_the_ai).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Amazon S3 is designed for object storage, offering scalability, durability,
    and availability. It is not a relational database. Amazon EC2 provides compute
    services. Amazon CloudFront is AWS’s CDN service for delivering content faster.
    See [Chapter 2](ch02.html#chapter_two_aws_fundamentals_for_the_ai).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: A confusion matrix helps in evaluating a classification model by showing
    how many predictions were correct and incorrect, specifically analyzing false
    positives and false negatives. It does not track model training time. The number
    of data points used is separate from model evaluation. Additional metrics like
    precision, recall, and F1-score are still needed. See [Chapter 3](ch03.html#chapter_three_ai_and_machine_learning).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Real-time inference processes data instantly, making it ideal for fraud
    detection where immediate action is required. Batch inference is used for processing
    large datasets at scheduled intervals. Asynchronous inference is suitable for
    large payloads but not for real-time needs. On-demand inference is for infrequent
    queries rather than continuous fraud monitoring. See [Chapter 3](ch03.html#chapter_three_ai_and_machine_learning).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: High-dimensional data can lead to increased processing time, memory usage,
    and model overfitting, making it harder to extract meaningful insights. More dimensions
    often require additional tuning to prevent overfitting, and they typically make
    interpretation more difficult, not easier. More features do not always lead to
    higher accuracy. See [Chapter 3](ch03.html#chapter_three_ai_and_machine_learning).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: Data drift occurs when the statistical properties of incoming data change
    over time, reducing the model’s accuracy. Overfitting happens when a model performs
    well on training data but poorly on new data, not necessarily due to long-term
    changes. Hyperparameter tuning optimizes a model but does not address changes
    in data distribution over time. Feature engineering errors occur during data preprocessing.
    See [Chapter 3](ch03.html#chapter_three_ai_and_machine_learning).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: SageMaker Model Monitor tracks deployed ML models and alerts users to changes
    in data distribution or concept drift. It does not speed up training. Deployment
    is managed separately in SageMaker, not specifically through Model Monitor. Fine-tuning
    pretrained models is a different ML task and is not the purpose of Model Monitor.
    See [Chapter 3](ch03.html#chapter_three_ai_and_machine_learning).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: SageMaker Data Wrangler helps automate data preprocessing, feature engineering,
    and transformation for machine learning (ML) models. Amazon Rekognition is for
    image and video analysis. Amazon Textract extracts text from documents. AWS Glue
    is an extract, transform, load (ETL) service. See [Chapter 3](ch03.html#chapter_three_ai_and_machine_learning).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Amazon Comprehend provides NLP capabilities, including sentiment analysis.
    Amazon Textract extracts text from scanned documents but does not analyze sentiment.
    Lambda is used for serverless computing. SageMaker Feature Store is for storing
    machine learning (ML) model features. See [Chapter 3](ch03.html#chapter_three_ai_and_machine_learning).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Hyperparameter tuning optimizes model performance by adjusting parameters
    such as the learning rate and batch size. It does not generate new data. Data
    preprocessing, not hyperparameter tuning, converts categorical data. Tuning may
    increase training time rather than speed it up. See [Chapter 3](ch03.html#chapter_three_ai_and_machine_learning).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: Diffusion models create realistic content by gradually adding and then removing
    noise. They create images, not text or sound. GANs, not diffusion models, use
    competing neural networks. See [Chapter 4](ch04.html#chapter_four_understanding_generative_a).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: With fine-tuning, you will change an FM’s parameters based on a proprietary
    dataset, which allows it to be more specialized for a particular domain. Fine-tuning
    actually makes a model more specialized, and does not impact the latency. See
    [Chapter 4](ch04.html#chapter_four_understanding_generative_a).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: The encoder processes input data into the transformer. It helps to find
    the contextual patterns and relationships. An AI model, not an encoder, creates
    synthetic data. Fine-tuning hyperparameters is a technique to improve the performance
    of a model. You can use benchmarks, not an encoder, to evaluate a model. See [Chapter 4](ch04.html#chapter_four_understanding_generative_a).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: LLMs have context windows. These fix the amount of text it can process at
    a time. Overfitting is where the model is not able to adequately generalize about
    something. Bias is generally about issues with the underlying dataset. The discriminator
    is a component in a GAN. It does not impact how much data can be processed in
    a large language model. See [Chapter 4](ch04.html#chapter_four_understanding_generative_a).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: RLHF is focused on improving the responses of a generative AI model by incorporating
    human preferences and feedback. It does not impact the speed of the model and
    it may increase training costs. Deep learning models are usually the core of the
    transformer model, which is when RLHF is used. See [Chapter 4](ch04.html#chapter_four_understanding_generative_a).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Multimodal models allow for processing different types of data, such as
    text, images and videos. They usually require large amounts of data. They aren’t
    necessarily more explainable than text-based models. GPUs are critical for multimodal
    FMs because of the need to handle large amounts of data. See [Chapter 4](ch04.html#chapter_four_understanding_generative_a).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: The number of parameters in LLMs are usually massive and this means having
    to use sophisticated systems—like GPUs—to handle the processing. RAG does consume
    compute resources, but this is a small part of the overall LLM. LLMs use complex
    linear algebra, but this is not a key reason for the heavy use of compute resources.
    Human feedback and evaluation is a small part of the process for developing an
    LLM. See [Chapter 4](ch04.html#chapter_four_understanding_generative_a).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: RAG will search a vector database, which has proprietary documents. These
    help to increase the accuracy of the responses. An AI model may have guardrails,
    but this isn’t what RAG does. RAG also doesn’t impact the probability algorithms
    in the transformer model, or rely solely on human supervision. See [Chapter 4](ch04.html#chapter_four_understanding_generative_a).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Amazon Lex provides chatbot interactions through the use of intents and
    slot filling. You can use Amazon Fraud Detector for fraud detection, Amazon Rekognition
    for video analysis, and Amazon Textract to extract text from scanned documents.
    See [Chapter 5](ch05.html#chapter_five_real_world_ai_applications).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: Amazon Comprehend allows you to analyze text and extract key information.
    Amazon Transcribe converts audio to text, Amazon Polly converts text to speech,
    and Amazon Translate provides language translation. See [Chapter 5](ch05.html#chapter_five_real_world_ai_applications).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: Amazon Rekognition is for analyzing images and videos. Amazon Transcribe
    allows for speech-to-text conversion. OCR is a core feature of Amazon Textract.
    You can create AI chatbots with Amazon Lex. See [Chapter 5](ch05.html#chapter_five_real_world_ai_applications).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Lemmatization is an NLP technique for preprocessing that helps AI models
    understand words more effectively. NLP models usually do not automatically correct
    grammar. Translation is not a preprocessing step in NLP. Deepfake detection is
    used for media verification. See [Chapter 5](ch05.html#chapter_five_real_world_ai_applications).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: Stopword removal eliminates words that have little meaning. Uncommon words
    are often more informative than stopwords, so NLP will often focus more on them.
    Stopwords are not removed to reduce text length. See [Chapter 5](ch05.html#chapter_five_real_world_ai_applications).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: If a task can be handled with traditional software, using AI may be unnecessary
    and expensive. AI can work quite well in cloud environments. And while human oversight
    is important, AI can function independently in many cases. AI can also handle
    complex tasks, not just simple automation. See [Chapter 5](ch05.html#chapter_five_real_world_ai_applications).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: This feature allows you to evaluate the responses of two different models,
    but it does not combine text and image responses or responses from two models.
    It also does not impact the length of the responses. See [Chapter 6](ch06.html#chapter_six_building_with_amazon_bedroc).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Fine-tuning customizes a model for specialized use cases using labeled data.
    Fine-tuning may actually increase compute costs because of the extra training
    required, and it will not improve latency. You would not use fine-tuning in Bedrock
    for images. See [Chapter 6](ch06.html#chapter_six_building_with_amazon_bedroc).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Open source models provide access to the code, allowing for customization.
    There is also the benefit of innovation from a community of contributors. Bedrock
    will still charge for hosting the model on AWS. You can specify real-time inference
    but it is not set by default. While the codebase may be available, this may not
    be the case for the datasets. See [Chapter 6](ch06.html#chapter_six_building_with_amazon_bedroc).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: This type of model uses less power and has a smaller footprint, which makes
    it better for edge devices. The context window would likely be smaller as the
    model is smaller. This type of model does not mean that the responses will be
    more creative. The accuracy of larger models will likely be higher. See [Chapter 6](ch06.html#chapter_six_building_with_amazon_bedroc).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Each agent specializes in a certain area, which helps improve the responses.
    You can use any type of AI model in Bedrock. Because generative AI is based on
    probabilities, there is no guarantee of 100% accuracy. Multiagent collaboration
    is not about editing model weights and biases. See [Chapter 6](ch06.html#chapter_six_building_with_amazon_bedroc).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: The cost advantages can be considerable, up to 50% compared to on-demand
    processing, but latency is usually high. Batch processing is not related to the
    context window and it will not impact accuracy rates of the model. See [Chapter 6](ch06.html#chapter_six_building_with_amazon_bedroc).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: Prompt templates provide reusable structures that promote clarity and efficiency.
    Few-shot prompting means a prompt has had examples added. Zero-shot prompting
    is quick but often less consistent. Chain-of-thought prompting helps with reasoning,
    but not consistency across prompts. See [Chapter 7](ch07.html#chapter_seven_a_guide_to_prompt_enginee).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: CoT prompting breaks down reasoning into smaller steps. Few-shot prompting
    specifies which examples to use. Output length limits the response of the LLM.
    Prompting doesn’t adjust model parameters. See [Chapter 7](ch07.html#chapter_seven_a_guide_to_prompt_enginee).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Few-shot prompting provides examples so the model can learn the patterns.
    Zero-shot prompting uses no examples. CoT prompting focuses on step-by-step logic.
    Template prompting structures the prompt, but doesn’t necessarily include examples.
    See [Chapter 7](ch07.html#chapter_seven_a_guide_to_prompt_enginee).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Model poisoning is where an attacker maliciously alters training data to
    produce unethical or harmful outputs. Data exposure allows a model to process
    personal health data. Licensing is a legal issue. Conflicting instructions can
    confuse a model, but this isn’t considered poisoning. See [Chapter 7](ch07.html#chapter_seven_a_guide_to_prompt_enginee).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Exposure is when confidential or regulated information is leaked because
    it was part of the training data. Public use may carry risks but is not exposure
    by itself. The loss of GPU performance during training is a hardware issue. The
    failure to generate output within token limits is unrelated to privacy or data
    security. See [Chapter 7](ch07.html#chapter_seven_a_guide_to_prompt_enginee).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: Jailbreaking uses indirect or tricky prompts to override model guardrails.
    Hardware limitations are not related to jailbreaking. Resetting a model’s API
    token is an API access issue. Models don’t retain session history unless designed
    for it. See [Chapter 7](ch07.html#chapter_seven_a_guide_to_prompt_enginee).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Governance ensures responsible AI practices through policy and oversight.
    AI governance is not about marketing or IP concerns, and it is not a technical
    methodology. See [Chapter 8](ch08.html#chapter_eight_a_framework_for_responsib).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Controllability ensures AI can be guided and monitored by humans. Cost is
    not a key issue in controllability and speed is unrelated to human control. See
    [Chapter 8](ch08.html#chapter_eight_a_framework_for_responsib).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: Responsible AI builds trust and boosts brand image, which can lead to improved
    user engagement. Data collection is still essential. Responsible AI aims to improve
    automation and reduce risk, although it cannot eliminate all errors. See [Chapter 8](ch08.html#chapter_eight_a_framework_for_responsib).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: SageMaker Clarify highlights bias and helps explain model decisions. It
    does not scan for URLs and is not designed for cost management. Data encryption
    is handled by other AWS tools. See [Chapter 8](ch08.html#chapter_eight_a_framework_for_responsib).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: It supports human review in tasks like content moderation and translation.
    It is not focused on model training speed and does not generate data. GPU management
    is outside the scope of Amazon A2I. See [Chapter 8](ch08.html#chapter_eight_a_framework_for_responsib).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: RLHF uses human input to guide AI behavior in complex scenarios. It supplements,
    but doesn’t replace, model updates. RLHF helps systems adapt, not stay static.
    It still involves some form of labeling or feedback. See [Chapter 8](ch08.html#chapter_eight_a_framework_for_responsib).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Emergent capabilities are unexpected behaviors that can create new compliance
    risks. They don’t involve strict feature following. AI systems do not autonomously
    handle regulatory reporting. Human oversight remains essential for compliant AI
    operations. See [Chapter 9](ch09.html#chapter_nine_securitycomma_complianceco).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: Regulated workloads must comply with legal, industry, or safety standards.
    They typically involve fields like healthcare, finance, or aerospace—not gaming.
    They prioritize safety, security, and accountability, not just speed. Compliance
    involves much more than encryption; it covers processes, oversight, and decision
    making. See [Chapter 9](ch09.html#chapter_nine_securitycomma_complianceco).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'B: Logging provides critical information for tracing, auditing, and improving
    model performance. Data logging is separate from data residency. Logs support
    diagnosis and improvement, but they cannot guarantee perfect accuracy. See [Chapter 9](ch09.html#chapter_nine_securitycomma_complianceco).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A: AWS Config tracks resource setups over time and helps audit changes. AWS
    Trusted Advisor offers recommendations. Amazon Inspector focuses on vulnerability
    scanning. AWS Artifact provides compliance documents. See [Chapter 9](ch09.html#chapter_nine_securitycomma_complianceco).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: Scope 1 refers to using public generative AI tools like ChatGPT without
    backend access. Pretrained models involve building apps with existing models,
    not just using public tools. Fine-tuned models require adapting a model with your
    own data, not simple usage. Self-trained models involve building everything from
    scratch. See [Chapter 9](ch09.html#chapter_nine_securitycomma_complianceco).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Amazon Macie uses ML to identify and classify sensitive data like PII and
    PHI. Verified Permissions helps implement fine-grained access control. Shield
    Advanced focuses on protecting against DDoS attacks. SageMaker Role Manager assists
    in setting IAM roles for ML projects. See [Chapter 9](ch09.html#chapter_nine_securitycomma_complianceco).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'C: Model cards provide a structured summary of a model’s data origins, usage
    guidelines, risks, and limitations. They don’t trigger retraining. Managing access
    controls is a separate function handled by IAM or similar services. Compute optimization
    is unrelated to the purpose of model documentation. See [Chapter 9](ch09.html#chapter_nine_securitycomma_complianceco).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'D: Customers and end users always retain control over the data they input into
    the system. Application providers may control other types of data, but not user
    inputs. The cloud provider hosts infrastructure but doesn’t control user data.
    Data annotation teams label training data but don’t control user-generated inputs.
    See [Chapter 9](ch09.html#chapter_nine_securitycomma_complianceco).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
