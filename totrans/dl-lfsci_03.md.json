["```py\nimport deepchem as dc\nimport numpy as np\n\n```", "```py\nx = np.random.random((4, 5))\ny = np.random.random((4, 1))\n\n```", "```py\nIn : x\nOut:\narray([[0.960767 , 0.31300931, 0.23342295, 0.59850938, 0.30457302],\n   [0.48891533, 0.69610528, 0.02846666, 0.20008034, 0.94781389],\n   [0.17353084, 0.95867152, 0.73392433, 0.47493093, 0.4970179 ],\n   [0.15392434, 0.95759308, 0.72501478, 0.38191593, 0.16335888]])\n\nIn : y\nOut:\narray([[0.00631553],\n   [0.69677301],\n   [0.16545319],\n   [0.04906014]])\n\n```", "```py\ndataset = dc.data.NumpyDataset(x, y)\n\n```", "```py\nIn : print(dataset.X)\n[[0.960767 0.31300931 0.23342295 0.59850938 0.30457302]\n[0.48891533 0.69610528 0.02846666 0.20008034 0.94781389]\n[0.17353084 0.95867152 0.73392433 0.47493093 0.4970179 ]\n[0.15392434 0.95759308 0.72501478 0.38191593 0.16335888]]\n\nIn : print(dataset.y)\n[[0.00631553]\n[0.69677301]\n[0.16545319]\n[0.04906014]]\n\n```", "```py\nIn : np.array_equal(x, dataset.X)\nOut : True\n\nIn : np.array_equal(y, dataset.y)\nOut : True\n\n```", "```py\nimport numpy as np\nimport deepchem as dc\n\n```", "```py\nIn : tox21_tasks, tox21_datasets, transformers = dc.molnet.load_tox21()\nOut: Loading raw samples now.\nshard_size: 8192\nAbout to start loading CSV from /tmp/tox21.CSV.gz\nLoading shard 1 of size 8192.\nFeaturizing sample 0\nFeaturizing sample 1000\nFeaturizing sample 2000\nFeaturizing sample 3000\nFeaturizing sample 4000\nFeaturizing sample 5000\nFeaturizing sample 6000\nFeaturizing sample 7000\nTIMING: featurizing shard 0 took 15.671 s\nTIMING: dataset construction took 16.277 s\nLoading dataset from disk.\nTIMING: dataset construction took 1.344 s\nLoading dataset from disk.\nTIMING: dataset construction took 1.165 s\nLoading dataset from disk.\nTIMING: dataset construction took 0.779 s\nLoading dataset from disk.\nTIMING: dataset construction took 0.726 s\nLoading dataset from disk.\n\n```", "```py\nIn : tox21_tasks\nOut:\n['NR-AR',\n'NR-AR-LBD',\n'NR-AhR',\n'NR-Aromatase',\n'NR-ER',\n'NR-ER-LBD',\n'NR-PPAR-gamma',\n'SR-ARE',\n'SR-ATAD5',\n'SR-HSE',\n'SR-MMP',\n'SR-p53']\n\nIn : len(tox21_tasks)\nOut: 12\n\n```", "```py\nIn : tox21_datasets\nOut:\n(<deepchem.data.datasets.DiskDataset at 0x7f9804d6c390>,\n<deepchem.data.datasets.DiskDataset at 0x7f9804d6c780>,\n<deepchem.data.datasets.DiskDataset at 0x7f9804c5a518>)\n\n```", "```py\ntrain_dataset, valid_dataset, test_dataset = tox21_datasets\n\n```", "```py\nIn : train_dataset.X.shape\nOut: (6264, 1024)\n\nIn : valid_dataset.X.shape\nOut: (783, 1024)\n\nIn : test_dataset.X.shape\nOut: (784, 1024)\n\n```", "```py\nIn : np.shape(train_dataset.y)\nOut: (6264, 12)\n\nIn : np.shape(valid_dataset.y)\nOut: (783, 12)\n\nIn : np.shape(test_dataset.y)\nOut: (784, 12)\n\n```", "```py\nIn : train_dataset.w.shape\nOut: (6264, 12)\n\nIn : np.count_nonzero(train_dataset.w)\nOut: 62166\n\nIn : np.count_nonzero(train_dataset.w == 0)\nOut: 13002\n\n```", "```py\nIn : transformers\nOut: [<deepchem.trans.transformers.BalancingTransformer at 0x7f99dd73c6d8>]\n\n```", "```py\nmodel = dc.models.MultitaskClassifier(n_tasks=12,\nn_features=1024,\nlayer_sizes=[1000])\n\n```", "```py\nmodel.fit(train_dataset, nb_epoch=10)\n\n```", "```py\nmetric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)\n\n```", "```py\ntrain_scores = model.evaluate(train_dataset, [metric], transformers)\ntest_scores = model.evaluate(test_dataset, [metric], transformers)\n\n```", "```py\nIn : `print``(``train_scores``)`\n...: `print``(``test_scores``)`\nOut\n{'mean-roc_auc_score': 0.9659541853946179}\n{'mean-roc_auc_score': 0.7915464001982299}\n\n```", "```py\nmkdir MNIST_data\ncd MNIST_data\nwget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nwget http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nwget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nwget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\ncd ..\n\n```", "```py\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n\n```", "```py\nimport deepchem as dc\nimport tensorflow as tf\nimport deepchem.models.tensorgraph.layers as layers\n\n```", "```py\ntrain_dataset = dc.data.NumpyDataset(mnist.train.images, mnist.train.labels)\ntest_dataset = dc.data.NumpyDataset(mnist.test.images, mnist.test.labels)\n\n```", "```py\nmodel = dc.models.TensorGraph(model_dir='mnist')\n\n```", "```py\nIn : isinstance(model, dc.models.Model)\nOut: True\n\n```", "```py\nfeature = layers.Feature(shape=(None, 784))\nlabel = layers.Label(shape=(None, 10))\n\n```", "```py\nmake_image = layers.Reshape(shape=(None, 28, 28), in_layers=feature)\n\n```", "```py\nconv2d_1 = layers.Conv2D(num_outputs=32, activation_fn=tf.nn.relu,\n                                         in_layers=make_image)\nconv2d_2 = layers.Conv2D(num_outputs=64, activation_fn=tf.nn.relu,\n                                         in_layers=conv2d_1)\n\n```", "```py\nflatten = layers.Flatten(in_layers=conv2d_2)\ndense1 = layers.Dense(out_channels=1024, activation_fn=tf.nn.relu, \n\t\t\t\t\t in_layers=flatten)\ndense2 = layers.Dense(out_channels=10, activation_fn=None, in_layers=dense1)\n\n```", "```py\nsmce = layers.SoftMaxCrossEntropy(in_layers=[label, dense2])\nloss = layers.ReduceMean(in_layers=smce)\nmodel.set_loss(loss)\n\n```", "```py\noutput = layers.SoftMax(in_layers=dense2)\nmodel.add_output(output)\n\n```", "```py\nmodel.fit(train_dataset, nb_epoch=10)\n\n```", "```py\nmetric = dc.metrics.Metric(dc.metrics.accuracy_score)\n\n```", "```py\ntrain_scores = model.evaluate(train_dataset, [metric])\ntest_scores = model.evaluate(test_dataset, [metric])\n\n```"]