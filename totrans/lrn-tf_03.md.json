["```py\na = tf.constant(5)\nb = tf.constant(2)\nc = tf.constant(3)\n\n```", "```py\nd = tf.multiply(a,b)\ne = tf.add(c,b)\nf = tf.subtract(d,e)\n\n```", "```py\nsess = tf.Session()\nouts = sess.run(f)\nsess.close()\nprint(\"outs = {}\".format(outs))\n\nOut:\nouts = 5\n\n```", "```py\nsess = tf.Session()\n\n```", "```py\nouts = sess.run(f)\n\n```", "```py\nsess.close()\n\n```", "```py\nimport tensorflow as tf\nprint(tf.get_default_graph())\n\ng = tf.Graph()\nprint(g)\n\nOut:\n<tensorflow.python.framework.ops.Graph object at 0x7fd88c3c07d0>\n<tensorflow.python.framework.ops.Graph object at 0x7fd88c3c03d0>\n\n```", "```py\ng = tf.Graph()\na = tf.constant(5)\n\nprint(a.graph is g)\nprint(a.graph is tf.get_default_graph())\n\nOut:\nFalse\nTrue\n\n```", "```py\ng1 = tf.get_default_graph()\ng2 = tf.Graph()\n\nprint(g1 is tf.get_default_graph())\n\nwith g2.as_default():\n    print(g1 is tf.get_default_graph())\n\nprint(g1 is tf.get_default_graph())\n\nOut:\nTrue\nFalse\nTrue\n```", "```py\nwith tf.Session() as sess:\n   fetches = [a,b,c,d,e,f]\n   outs = sess.run(fetches)\n\nprint(\"outs = {}\".format(outs))\nprint(type(outs[0]))\n\nOut:\nouts = [5, 2, 3, 10, 5, 5]\n<type 'numpy.int32'>\n\n```", "```py\nc = tf.constant(4.0)\nprint(c)\n\nOut:\nTensor(\"Const_52:0\", shape=(), dtype=float32)\n\n```", "```py\nc = tf.constant(4.0, dtype=tf.float64)\nprint(c)\nprint(c.dtype)\n\nOut:\nTensor(\"Const_10:0\", shape=(), dtype=float64)\n<dtype: 'float64'>\n\n```", "```py\nx = tf.constant([1,2,3],name='x',dtype=tf.float32)\nprint(x.dtype)\nx = tf.cast(x,tf.int64)\nprint(x.dtype)\n\nOut:\n<dtype: 'float32'>\n<dtype: 'int64'>\n\n```", "```py\nimport numpy as np\n\nc = tf.constant([[1,2,3],\n                [4,5,6]])\nprint(\"Python List input: {}\".format(c.get_shape()))\n\nc = tf.constant(np.array([\n        [[1,2,3,4],\n         [5,6,7,8],\n         [9,8,7,6]],\n\n        [[1,1,1,1],\n         [2,2,2,2],\n         [3,3,3,3]]\n        ]))\n\nprint(\"3d NumPy array input: {}\".format(c.get_shape()))\n\nOut:\nPython list input: (2, 3)\n3d NumPy array input: (2, 3, 4)\n\n```", "```py\nsess = tf.InteractiveSession()\nc = tf.linspace(0.0, 4.0, 5)\nprint(\"The content of 'c':\\n {}\\n\".format(c.eval()))\nsess.close()\n\nOut:\nThe content of 'c':\n[ 0.1.2.3.4.]\n```", "```py\nA = tf.constant([ [1,2,3],\n           [4,5,6] ])\nprint(A.get_shape())\n\nx = tf.constant([1,0,1])\nprint(x.get_shape())\n\nOut:\n(2, 3)\n(3,)\n\n```", "```py\nx = tf.expand_dims(x,1)\nprint(x.get_shape())\n\nb = tf.matmul(A,x)\n\nsess = tf.InteractiveSession()\nprint('matmul result:\\n {}'.format(b.eval()))\nsess.close()\n\nOut:\n(3, 1)\n\nmatmul result:\n[[ 4]\n[10]]\n\n```", "```py\nwith tf.Graph().as_default():\n  c1 = tf.constant(4,dtype=tf.float64,name='c')\n  c2 = tf.constant(4,dtype=tf.int32,name='c')\nprint(c1.name)\nprint(c2.name)\n\nOut:\nc:0\nc_1:0\n\n```", "```py\nwith tf.Graph().as_default():\n  c1 = tf.constant(4,dtype=tf.float64,name='c')\n  with tf.name_scope(\"prefix_name\"):\n    c2 = tf.constant(4,dtype=tf.int32,name='c')\n    c3 = tf.constant(4,dtype=tf.float64,name='c')\n\nprint(c1.name)\nprint(c2.name)\nprint(c3.name)\n\nOut:\nc:0\nprefix_name/c:0\nprefix_name/c_1:0\n\n```", "```py\ninit_val = tf.random_normal((1,5),0,1)\nvar = tf.Variable(init_val, name='var')\nprint(\"pre run: \\n{}\".format(var))\n\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n  sess.run(init)\n  post_var = sess.run(var)\n\nprint(\"\\npost run: \\n{}\".format(post_var))\n\nOut:\npre run:\nTensor(\"var/read:0\", shape=(1, 5), dtype=float32)\n\npost run:\n[[ 0.859621350.648858550.25370994 -0.373807910.63552463]]\n\n```", "```py\npre run:\nTensor(\"var_1/read:0\", shape=(1, 5), dtype=float32)\n```", "```py\nph = tf.placeholder(tf.float32,shape=(None,10))\n```", "```py\nsess.run(s,feed_dict={x: X_data,w: w_data})\n\n```", "```py\nx_data = np.random.randn(5,10)\nw_data = np.random.randn(10,1)\n\nwith tf.Graph().as_default():\n  x = tf.placeholder(tf.float32,shape=(5,10))\n  w = tf.placeholder(tf.float32,shape=(10,1))\n  b = tf.fill((5,1),-1.)\n  xw = tf.matmul(x,w)\n\n  xwb = xw + b\n  s = tf.reduce_max(xwb)\n  with tf.Session() as sess:\n    outs = sess.run(s,feed_dict={x: x_data,w: w_data})\n\nprint(\"outs = {}\".format(outs))\n\nOut:\nouts = 3.06512\n\n```", "```py\nx = tf.placeholder(tf.float32,shape=[None,3])\ny_true = tf.placeholder(tf.float32,shape=None)\nw = tf.Variable([[0,0,0]],dtype=tf.float32,name='weights')\nb = tf.Variable(0,dtype=tf.float32,name='bias')\n\n```", "```py\ny_pred = tf.matmul(w,tf.transpose(x)) + b\n\n```", "```py\nloss = tf.reduce_mean(tf.square(y_true-y_pred))\n\n```", "```py\nloss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true,logits=y_pred)\n\nloss = tf.reduce_mean(loss)\n\n```", "```py\noptimizer = tf.train.GradientDescentOptimizer(learning_rate)\ntrain = optimizer.minimize(loss)\n\n```", "```py\nimport numpy as np\n# === Create data and simulate results =====\nx_data = np.random.randn(2000,3)\nw_real = [0.3,0.5,0.1]\nb_real = -0.2\n\nnoise = np.random.randn(1,2000)*0.1\ny_data = np.matmul(w_real,x_data.T) + b_real + noise\n```", "```py\nNUM_STEPS = 10\n\ng = tf.Graph()\nwb_ = []\nwith g.as_default():\n  x = tf.placeholder(tf.float32,shape=[None,3])\n  y_true = tf.placeholder(tf.float32,shape=None)\n\n  with tf.name_scope('inference') as scope:\n    w = tf.Variable([[0,0,0]],dtype=tf.float32,name='weights')\n    b = tf.Variable(0,dtype=tf.float32,name='bias')\n    y_pred = tf.matmul(w,tf.transpose(x)) + b\n\n  with tf.name_scope('loss') as scope:\n    loss = tf.reduce_mean(tf.square(y_true-y_pred))\n\n  with tf.name_scope('train') as scope:\n    learning_rate = 0.5\n    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n    train = optimizer.minimize(loss)\n\n  # Before starting, initialize the variables. \u00a0We will 'run' this first.\n  init = tf.global_variables_initializer()\n  with tf.Session() as sess:\n    sess.run(init)   \n    for step in range(NUM_STEPS):\n      sess.run(train,{x: x_data, y_true: y_data})\n      if (step % 5 == 0):\n        print(step, sess.run([w,b]))\n        wb_.append(sess.run([w,b]))\n\n    print(10, sess.run([w,b]))\n\n```", "```py\n(0, [array([[ 0.30149955,\u00a0\u00a00.49303722,\u00a0\u00a00.11409992]], \n                                     dtype=float32), -0.18563795])\n\n(5, [array([[ 0.30094019,\u00a0\u00a00.49846715,\u00a0\u00a00.09822173]], \n                                     dtype=float32), -0.19780949])\n\n(10, [array([[ 0.30094025,\u00a0\u00a00.49846718,\u00a0\u00a00.09822182]], \n                                     dtype=float32), -0.19780946])\n\n```", "```py\nN = 20000\n\ndef sigmoid(x):\n  return 1 / (1 + np.exp(-x))\n# === Create data and simulate results =====\nx_data = np.random.randn(N,3)\nw_real = [0.3,0.5,0.1]\nb_real = -0.2\nwxb = np.matmul(w_real,x_data.T) + b_real\n\ny_data_pre_noise = sigmoid(wxb)\ny_data = np.random.binomial(1,y_data_pre_noise)\n```", "```py\ny_pred = tf.sigmoid(y_pred)\nloss = -y_true*tf.log(y_pred) - (1-y_true)*tf.log(1-y_pred)\nloss=tf.reduce_mean(loss)\n\n```", "```py\ntf.nn.sigmoid_cross_entropy_with_logits(labels=,logits=)\n\n```", "```py\nNUM_STEPS = 50\n\nwith tf.name_scope('loss') as scope:\n  loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true,logits=y_pred)\n  loss = tf.reduce_mean(loss)\n\n# Before starting, initialize the variables. \u00a0We will 'run' this first.\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n  sess.run(init)   \n  for step in range(NUM_STEPS):\n    sess.run(train,{x: x_data, y_true: y_data})\n    if (step % 5 == 0):\n      print(step, sess.run([w,b]))\n      wb_.append(sess.run([w,b]))\n\n  print(50, sess.run([w,b]))\n\n```", "```py\n(0, [array([[ 0.03212515,\u00a0\u00a00.05890014,\u00a0\u00a00.01086476]], \n                                     dtype=float32), -0.021875083])\n(5, [array([[ 0.14185661,\u00a0\u00a00.25990966,\u00a0\u00a00.04818931]], \n                                     dtype=float32), -0.097346731])\n(10, [array([[ 0.20022796,\u00a0\u00a00.36665651,\u00a0\u00a00.06824245]], \n                                      dtype=float32), -0.13804035])\n(15, [array([[ 0.23269908,\u00a0\u00a00.42593899,\u00a0\u00a00.07949805]], \n                                       dtype=float32), -0.1608445])\n(20, [array([[ 0.2512995 ,\u00a0\u00a00.45984453,\u00a0\u00a00.08599731]], \n                                      dtype=float32), -0.17395383])\n(25, [array([[ 0.26214141,\u00a0\u00a00.47957924,\u00a0\u00a00.08981277]], \n                                       dtype=float32), -0.1816061])\n(30, [array([[ 0.26852587,\u00a0\u00a00.49118528,\u00a0\u00a00.09207394]], \n                                      dtype=float32), -0.18611355])\n(35, [array([[ 0.27230808,\u00a0\u00a00.49805275,\u00a0\u00a00.09342111]], \n                                      dtype=float32), -0.18878292])\n(40, [array([[ 0.27455658,\u00a0\u00a00.50213116,\u00a0\u00a00.09422609]], \n                                      dtype=float32), -0.19036882])\n(45, [array([[ 0.27589601,\u00a0\u00a00.5045585 ,\u00a0\u00a00.09470785]], \n                                      dtype=float32), -0.19131286])\n(50, [array([[ 0.27656636,\u00a0\u00a00.50577223,\u00a0\u00a00.09494986]], \n                                      dtype=float32), -0.19178495])\n\n```"]