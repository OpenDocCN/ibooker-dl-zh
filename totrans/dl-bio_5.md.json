["```py\ndef ResidualBlock(x):\n  \"\"\"Basic building block of a ResNet.\"\"\"\n  identity = x  # Preserve the original input for the skip connection.\n  residual = Convolution(x)  # Apply convolutional transformation.\n  return identity + residual  # Add the identity (skip connection).\n\n```", "```py\nclass ResidualBlock(nn.Module):\n  \"\"\"A minimal Flax CNN residual block.\"\"\"\n  features: int  # Number of output channels.\n  kernel_size: Tuple[int, ...] = (3, 3)  # Convolution kernel size.\n  strides: Tuple[int, ...] = (1, 1)  # Convolution stride.\n\n  @nn.compact\n  def __call__(self, x):\n    identity = x  # Preserve the original input for the skip connection.\n    residual = nn.Conv(\n      self.features, self.kernel_size, self.strides, padding=\"SAME\"\n    )(x)\n    return identity + residual  # Add the identity (skip connection).\n\n```", "```py\nclass ResidualBlock(nn.Module):\n  \"\"\"A basic Flax CNN residual block with two convolutional layers.\"\"\"\n  features: int  # Number of output channels.\n  kernel_size: Tuple[int, ...] = (3, 3)  # Convolution kernel size.\n  strides: Tuple[int, ...] = (1, 1)  # Convolution stride.\n\n  @nn.compact\n  def __call__(self, x):\n    identity = x  # Preserve the original input for the skip connection.\n\n    # First convolution + batch normalization + ReLU activation.\n    x = nn.Conv(self.features, self.kernel_size, self.strides, padding=\"SAME\")(x)\n    x = nn.BatchNorm()(x)\n    x = nn.relu(x)\n\n    # Second convolution + batch normalization (no activation here).\n    x = nn.Conv(self.features, self.kernel_size, self.strides, padding=\"SAME\")(x)\n    x = nn.BatchNorm()(x)\n\n    # If the input and output dimensions do not match, apply a 1 x 1 convolution.\n    if identity.shape[-1] != x.shape[-1]:\n      identity = nn.Conv(\n        self.features, kernel_size=(1, 1),\n        strides=self.strides,\n        padding=\"SAME\"\n      )(identity)\n\n    # Add the skip connection.\n    x += identity\n\n    # Final ReLU activation.\n    return nn.relu(x)\n\n```", "```py\nimport re\nfrom pathlib import Path\n\nfrom dlfb.utils.context import assets\n\nimage_file = next(Path(assets(\"cancer/datasets/raw\")).rglob(\"*.jpg\"))\n\nprint(rf\"One of the images: {re.sub('^.*?datasets/', '', str(image_file))}\")\n\n```", "```py\nOne of the images: raw/Test/melanoma/ISIC_0000031.jpg\n\n```", "```py\nimport pandas as pd\n\ndef load_metadata(data_dir: str) -> pd.DataFrame:\n  metadata = []\n  for path in Path(data_dir).rglob(\"*.jpg\"):\n    split, class_name, _ = path.parts[-3:]\n    metadata.append(\n      {\n        \"split_orig\": split,\n        \"class_orig\": class_name,\n        \"full_path\": str(path),\n      }\n    )\n  return pd.DataFrame(metadata).rename_axis(\"frame_id\").reset_index()\n\nmetadata = load_metadata(assets(\"cancer/datasets/raw\"))\nprint(metadata)\n```", "```py\n      frame_id split_orig      class_orig            full_path\n0            0       Test        melanoma  /content/drive/M...\n1            1       Test        melanoma  /content/drive/M...\n2            2       Test        melanoma  /content/drive/M...\n...        ...        ...             ...                  ...\n2354      2354      Train  dermatofibroma  /content/drive/M...\n2355      2355      Train  dermatofibroma  /content/drive/M...\n2356      2356      Train  dermatofibroma  /content/drive/M...\n\n[2357 rows x 4 columns]\n\n```", "```py\ncounts = pd.crosstab(\n  metadata[\"class_orig\"], metadata[\"split_orig\"], margins=True\n)\nprint(counts)\n\n```", "```py\nsplit_orig            Test  Train   All\nclass_orig                             \nactinic keratosis       16    114   130\nbasal cell carcinoma    16    376   392\ndermatofibroma          16     95   111\nmelanoma                16    438   454\nnevus                   16    357   373\npigmented benign ...    16    462   478\nseborrheic keratosis     3     77    80\nsquamous cell car...    16    181   197\nvascular lesion          3    139   142\nAll                    118   2239  2357\n\n```", "```py\nfig = counts.drop([\"All\"], axis=1).drop([\"All\"], axis=0).plot.barh(stacked=True)\nfig.set_xlabel(\"Number of images\")\nfig.set_ylabel(\"Skin lesion type\")\nfig.set_title(\"Class distribution\");\n```", "```py\nfrom PIL import Image\n\nImage.open(metadata[\"full_path\"].iloc[0])\n\n```", "```py\nimport matplotlib.pyplot as plt\n\ndef show_random_image(metadata: pd.DataFrame, class_name: str) -> plt.Figure:\n  record = (\n    metadata[metadata[\"class_orig\"] == class_name]\n    .sample(1)\n    .to_dict(orient=\"records\")[0]\n  )\n  fig = plt.figure(figsize=(4, 4))\n  plt.imshow(Image.open(record[\"full_path\"]))\n  plt.title(record[\"class_orig\"].capitalize())\n  return fig\n```", "```py\nshow_random_image(metadata, \"melanoma\");\n\n```", "```py\ndef plot_random_image_grid(\n  metadata: pd.DataFrame, ncols: int = 3\n) -> plt.Figure:\n  \"\"\"Display a random example image from each class in a grid.\"\"\"\n  records = metadata.groupby(\"class_orig\").sample(1).to_dict(orient=\"records\")\n  nrows = (len(records) + ncols - 1) // ncols\n  fig, axes = plt.subplots(nrows, ncols, figsize=(10, 2.5 * nrows))\n  axes = axes.flatten()\n\n  for record, ax in zip(records, axes):\n    ax.imshow(Image.open(record[\"full_path\"]))\n    ax.set_title(record[\"class_orig\"].capitalize())\n    ax.axis(\"off\")\n\n  plt.tight_layout()\n  return fig\n```", "```py\nplot_random_image_grid(metadata);\n\n```", "```py\nimport numpy as np\n\nnp.random.seed(seed=42)\nsplits = {\"train\": 0.7, \"valid\": 0.20, \"test\": 0.10}\n\nmetadata[\"split\"] = np.random.choice(\n  list(splits.keys()), p=list(splits.values()), size=metadata.shape[0]\n)\n\ncounts = pd.crosstab(metadata[\"class_orig\"], metadata[\"split\"], margins=True)\nprint(counts)\n```", "```py\nsplit                 test  train  valid   All\nclass_orig                                    \nactinic keratosis       13     85     32   130\nbasal cell carcinoma    39    284     69   392\ndermatofibroma          11     84     16   111\nmelanoma                55    307     92   454\nnevus                   41    250     82   373\npigmented benign ...    39    358     81   478\nseborrheic keratosis     9     50     21    80\nsquamous cell car...    14    138     45   197\nvascular lesion         10     99     33   142\nAll                    231   1655    471  2357\n```", "```py\ncounts.drop([\"All\"], axis=1).drop([\"All\"], axis=0).plot.barh(stacked=True);\n```", "```py\n@jax.jit\ndef rich_augmentor(image: jax.Array, rng: jax.Array) -> jax.Array:\n  \"\"\"Applies random flips, brightness, contrast, hue changes, and rotation.\"\"\"\n  image = pix.random_flip_left_right(rng, image)\n  image = pix.random_flip_up_down(rng, image)\n  image = pix.random_brightness(rng, image, max_delta=0.1)\n  image = pix.random_contrast(rng, image, lower=0.9, upper=1)\n  image = pix.random_hue(rng, image, max_delta=0.05)\n  # Angles are provided in radians, i.e. +/- 10 degrees.\n  image = pix.rotate(\n    image,\n    angle=jax.random.uniform(rng, shape=(), minval=-0.174533, maxval=0.174533),\n  )\n  return image\n```", "```py\nimport jax\nimport jax.numpy as jnp\n\nrng = jax.random.PRNGKey(seed=42)\nimage = Image.open(\n  metadata[metadata[\"class_orig\"] == \"melanoma\"]\n  .sample(1)[\"full_path\"]\n  .values[0]\n)\n\n_, axes = plt.subplots(3, 3, figsize=(9, 9))\naxes = axes.flatten()\naxes[0].imshow(image)\naxes[0].set_title(\"Original\")\naxes[0].axis(\"off\")\nimage = jnp.asarray(image) / 255.0\nfor ax in axes[1:]:\n  rng, rng_augment = jax.random.split(rng, num=2)\n  ax.imshow(rich_augmentor(image, rng_augment))\n  ax.set_title(\"Augmented\")\n  ax.axis(\"off\")\nplt.tight_layout()\n```", "```py\ndef resize_preserve_aspect(\n  image: jax.Array, short_side: int = 256\n) -> jax.Array:\n  \"\"\"Resize image with shorter side is `short_side`, keeping aspect ratio.\"\"\"\n  h, w, c = image.shape\n  scale = short_side / jnp.minimum(h, w)\n  new_h = jnp.round(h * scale).astype(jnp.int32)\n  new_w = jnp.round(w * scale).astype(jnp.int32)\n  resized = jax.image.resize(image, (new_h, new_w, c), method=\"bilinear\")\n  return resized\n\ndef center_crop(image: jax.Array, size: int = 224) -> jax.Array:\n  \"\"\"Crop the center square of given size from an image.\"\"\"\n  h, w, _ = image.shape\n  top = (h - size) // 2\n  left = (w - size) // 2\n  return image[top : top + size, left : left + size]\n```", "```py\ndef rescale_image(image: jax.Array) -> jax.Array:\n  \"\"\"Normalizes pixel values to the [0, 1] range by dividing by 255.\"\"\"\n  return image / 255.0\n```", "```py\noriginal_image = Image.open(metadata.iloc[0][\"full_path\"])\nimage = np.array(original_image)\nimage = resize_preserve_aspect(image)\nimage = center_crop(image)\nimage = rescale_image(image)\n\n_, axes = plt.subplots(1, 2, figsize=(6, 3))\naxes = axes.flatten()\naxes[0].imshow(original_image)\naxes[0].set_title(\"Original\")\naxes[1].imshow(image)\naxes[1].set_title(\"Preprocessed\");\n```", "```py\nfrom tempfile import TemporaryFile\n\nimages_on_disk = np.memmap(\n  TemporaryFile(), dtype=\"float32\", mode=\"w+\", shape=(10, 224, 224, 3)\n)\nfor i, full_path in enumerate(metadata[:10][\"full_path\"]):\n  image = Image.open(full_path)\n  image = np.array(image)\n  image = resize_preserve_aspect(image)\n  image = center_crop(image)\n  image = rescale_image(image)\n  images_on_disk[i, :, :, :] = image\nimages_on_disk.flush()\n```", "```py\nclass DatasetBuilder:\n  \"\"\"Builds a dataset with metadata, loaded images, and class mappings.\"\"\"\n\n  def __init__(self, data_dir: str, out_dir: str | None = None) -> None:\n    self.data_dir = data_dir\n    self.out_dir = out_dir or data_dir\n\n  def build(\n    self,\n    rng: jax.Array,\n    splits: dict[str, float],\n    preprocessors: list[Callable] = [crop],\n    image_size: tuple[int, int, int] = (224, 224, 3),\n    class_map: dict[str, Any] | None = None,\n  ) -> dict[str, Dataset]:\n    \"\"\"Builds the dataset splits from loaded metadata and loaded images.\"\"\"\n    metadata = MetadataLoader(self.data_dir, self.out_dir).load(class_map)\n    images = ImageLoader(metadata, self.out_dir).load(preprocessors, image_size)\n\n    # Shuffle the dataset and assign each example to one of the dataset splits.\n    num_samples = len(metadata)\n    rng, rng_perm = jax.random.split(rng, 2)\n    shuffled_indices = jax.random.permutation(rng_perm, num_samples)\n\n    # Create each dataset split using the shuffled indices and store the\n    # corresponding metadata and image data in a Dataset object.\n    dataset_splits, start = {}, 0\n    for name, size in self._get_split_sizes(splits, num_samples):\n      indices = np.array(shuffled_indices[start : (start + size)])\n      dataset_splits[name] = Dataset(\n        metadata=metadata.iloc[indices],\n        images=images,\n        num_classes=metadata[\"class\"].nunique(),\n      )\n      start += size\n    return dataset_splits\n\n  def _get_split_sizes(self, splits: dict[str, float], num_samples: int):\n    \"\"\"Convert fractional split sizes to integer counts that sum to total.\"\"\"\n    names = list(splits)\n    sizes = [int(num_samples * splits[name]) for name in names[:-1]]\n    sizes.append(num_samples - sum(sizes))  # last split gets the remainder\n    yield from zip(names, sizes)\n\n```", "```py\n@dataclass\nclass Dataset:\n  \"\"\"Dataset class storing images and corresponding metadata.\"\"\"\n\n  metadata: pd.DataFrame\n  images: Images\n  num_classes: int\n\n  def get_dummy_input(self) -> jnp.ndarray:\n    \"\"\"Returns dummy input with the correct shape for the model.\"\"\"\n    return jnp.empty((1,) + self.images.size)\n\n  def num_samples(self) -> int:\n    \"\"\"Returns the number of samples in the dataset.\"\"\"\n    return self.metadata.shape[0]\n\n  def get_images(self, preprocessor: Callable, indices: jax.Array) -> jax.Array:\n    \"\"\"Returns preprocessed images for the given indices.\"\"\"\n    return self.images.loaded[preprocessor.__name__][indices]\n\n  def get_labels(self, indices: list[int]) -> jax.Array:\n    \"\"\"Returns integer class labels for the given indices.\"\"\"\n    return jnp.int16(self.metadata.loc[indices][\"label\"].values)\n```", "```py\n@dataclass\nclass Images:\n  \"\"\"Stores image data and size information.\"\"\"\n\n  loaded: dict[str, np.memmap]\n  size: tuple[int, int, int]\n```", "```py\nclass BatchHandler:\n  \"\"\"Helper to provide appropriately prepared batches form a dataset.\"\"\"\n\n  def __init__(\n    self,\n    preprocessor: Callable = crop,\n    sampler: Callable = epoch_sampler,\n    augmentor: Callable | None = None,\n  ):\n    self.preprocessor = preprocessor\n    self.sampler = sampler\n    self.augmentor = augmentor\n\n  def get_batches(self, dataset: Dataset, batch_size: int, rng: jax.Array):\n    \"\"\"Prepare dataset batches with the requested image manipulations.\"\"\"\n    self._validate_batch_size(dataset, batch_size)\n    rng, rng_sampler = jax.random.split(rng, num=2)\n\n    for batch_indices in self.sampler(\n      dataset.metadata, batch_size, rng_sampler\n    ):\n      images = dataset.get_images(self.preprocessor, batch_indices)\n\n      if self.augmentor is not None:\n        rng, rng_augment = jax.random.split(rng, 2)\n        images = jax.vmap(lambda image, r: self.augmentor(image, rng=r))(\n          images, jax.random.split(rng_augment, images.shape[0])\n        )\n\n      batch = {\n        \"frame_ids\": batch_indices,\n        \"images\": images,\n        \"labels\": dataset.get_labels(batch_indices),\n      }\n      yield batch\n\n  @staticmethod\n  def _validate_batch_size(dataset: Dataset, batch_size: int) -> None:\n    \"\"\"Ensures that batch_size is within feasible bounds.\"\"\"\n    if batch_size > dataset.num_samples():\n      raise ValueError(\n        f\"Batch size ({batch_size}) cannot be larger than dataset size \"\n        \"({len(frame_ids)}).\"\n      )\n    if batch_size > dataset.num_classes:\n      raise ValueError(\n        f\"batch_size ({batch_size}) has to be larger than \"\n        f\"number of unique labels.\"\n      )\n\n```", "```py\nfrom dlfb.cancer.train.handlers.augmentors import rich_augmentor\nfrom dlfb.cancer.train.handlers.samplers import balanced_sampler\n\nrng = jax.random.PRNGKey(seed=42)\nrng, rng_dataset = jax.random.split(rng, 2)\n\nbuilder = DatasetBuilder(data_dir=assets(\"cancer/datasets/raw\"))\n\ndataset_splits = builder.build(\n  rng=rng_dataset,\n  splits={\"train\": 0.7, \"valid\": 0.20, \"test\": 0.10},\n  image_size=(224, 224, 3),\n)\n\nprint(dataset_splits[\"train\"].metadata)\n```", "```py\nframe_id split_orig           class_orig            full_path     label  \\\n177        177      Train    actinic keratosis  /content/drive/M...      0   \n408        408      Train  basal cell carci...  /content/drive/M...      1   \n445        445      Train  basal cell carci...  /content/drive/M...      1   \n...        ...        ...                  ...                  ...    ...   \n1579      1579      Train  pigmented benign...  /content/drive/M...      5   \n1966      1966      Train  seborrheic kerat...  /content/drive/M...      6   \n305        305      Train  basal cell carci...  /content/drive/M...      1   \n\n                    class  \n177     actinic keratosis  \n408   basal cell carci...  \n445   basal cell carci...  \n...                   ...  \n1579  pigmented benign...  \n1966  seborrheic kerat...  \n305   basal cell carci...  \n\n[1649 rows x 6 columns]\n```", "```py\nrng, rng_train = jax.random.split(rng, 2)\n\ntrain_batcher = BatchHandler(sampler=balanced_sampler, augmentor=rich_augmentor)\ntrain_batches = train_batcher.get_batches(\n  dataset_splits[\"train\"], batch_size=32, rng=rng_train\n)\nbatch = next(train_batches)\n```", "```py\nbatch[\"images\"].shape\n\n```", "```py\n(32, 224, 224, 3)\n\n```", "```py\nplt.imshow(batch[\"images\"][0]);\n\n```", "```py\nimport requests\n\n# Load the example image from the documentation.\nurl = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\nimage = Image.open(requests.get(url, stream=True).raw)\nplt.imshow(image);\n```", "```py\nfrom transformers import AutoImageProcessor, FlaxResNetForImageClassification\nresnet_model = FlaxResNetForImageClassification.from_pretrained(\n  \"microsoft/resnet-50\"\n)\nimage_processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n```", "```py\ninputs = image_processor(images=image, return_tensors=\"jax\")\ninputs.keys()\n\n```", "```py\ndict_keys(['pixel_values'])\n\n```", "```py\nplt.imshow(jnp.transpose(inputs[\"pixel_values\"], (0, 2, 3, 1))[0]);\n```", "```py\noutputs = resnet_model(**inputs)\nlogits = outputs.logits\npredicted_class_idx = jnp.argmax(logits, axis=-1)\nprint(\n  \"Predicted class:\", resnet_model.config.id2label[predicted_class_idx.item()]\n)\n```", "```py\nPredicted class: tiger cat\n\n```", "```py\nmodule, variables = resnet_model.module, resnet_model.params\nbackbone_module, backbone_vars = module.bind(variables).resnet.unbind()\n```", "```py\noutputs = backbone_module.apply(\n  backbone_vars, jnp.transpose(inputs[\"pixel_values\"], (0, 2, 3, 1))\n)\nlast_hidden_state = outputs.last_hidden_state\nlast_hidden_state.shape\n```", "```py\n(1, 2048, 7, 7)\n\n```", "```py\ndef display_feature_maps(feature_map, ncols=8):\n  \"\"\"Plot grid of the first 64 feature maps.\"\"\"\n  num_features = feature_map.shape[0]\n  nrows = (num_features + ncols - 1) // ncols\n  _, axes = plt.subplots(nrows, ncols, figsize=(ncols, nrows))\n  axes = axes.flatten()\n\n  for i, (ax, feature) in enumerate(zip(axes, feature_map)):\n    ax.imshow(feature, cmap=\"viridis\")\n    ax.axis(\"off\")\n\n  plt.tight_layout()\n  plt.show()\n\ndisplay_feature_maps(last_hidden_state[0, 0:64, ...])\n```", "```py\n_, ax = plt.subplots(1, 1, figsize=(6, 2))\nax.plot(np.squeeze(outputs.pooler_output), c=\"grey\")\nplt.title(f\"Shape of outputs after pooling: {outputs.pooler_output.shape}\");\n```", "```py\nclass SkinLesionClassifierHead(nn.Module):\n  \"\"\"Skin lesion classification MLP head.\"\"\"\n  num_classes: int\n  dropout_rate: float\n\n  @nn.compact\n  def __call__(self, x, is_training: bool):\n    x = nn.Dense(256, kernel_init=nn.initializers.xavier_uniform())(x)\n    x = nn.relu(x)\n    x = nn.Dropout(rate=self.dropout_rate)(x, deterministic=not is_training)\n    x = nn.Dense(128, kernel_init=nn.initializers.xavier_uniform())(x)\n    x = nn.relu(x)\n    x = nn.Dropout(rate=self.dropout_rate)(x, deterministic=not is_training)\n    x = nn.Dense(\n      self.num_classes, kernel_init=nn.initializers.xavier_uniform()\n    )(x)\n    return x\n```", "```py\nclass SimpleCnn(nn.Module):\n  \"\"\"Simple CNN model with small convolutional backbone and classifier head.\"\"\"\n\n  num_classes: int\n  dropout_rate: float = 0.0\n\n  def setup(self):\n    \"\"\"Initializes the CNN backbone and classification head.\"\"\"\n    self.backbone = CnnBackbone()\n    self.head = SkinLesionClassifierHead(self.num_classes, self.dropout_rate)\n\n  @nn.compact\n  def __call__(self, x, is_training: bool = False):\n    \"\"\"Applies the backbone and classifier head to the input.\"\"\"\n    x = self.backbone(x)\n    x = self.head(x, is_training=is_training)\n    return x\n\n  def create_train_state(\n    self, rng: jax.Array, dummy_input, tx\n  ) -> TrainStateWithBatchNorm:\n    \"\"\"Creates the training state with initialized parameters.\"\"\"\n    rng, rng_init, rng_dropout = jax.random.split(rng, 3)\n    variables = self.init(rng_init, dummy_input)\n    state = TrainStateWithBatchNorm.create(\n      apply_fn=self.apply,\n      tx=tx,\n      params=variables[\"params\"],\n      batch_stats=None,\n      key=rng_dropout,\n    )\n    return state\n```", "```py\nclass CnnBackbone(nn.Module):\n  \"\"\"Compact convolutional feature extractor for image data.\"\"\"\n\n  @nn.compact\n  def __call__(self, x):\n    \"\"\"Applies two conv-pool blocks and a dense layer to the input.\"\"\"\n    x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n    x = nn.relu(x)\n    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n    x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n    x = nn.relu(x)\n    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n    x = x.reshape((x.shape[0], -1))  # flatten\n    x = nn.Dense(features=256)(x)\n    return x\n```", "```py\nclass TrainStateWithBatchNorm(train_state.TrainState):\n  \"\"\"Train state that tracks batch statistics and a PRNG key.\"\"\"\n\n  batch_stats: dict | None\n  key: jax.Array\n```", "```py\nclass ResNetFromScratch(nn.Module):\n  \"\"\"ResNet model initialized from scratch with a custom classification head.\"\"\"\n\n  num_classes: int\n  layers: int = 50\n  dropout_rate: float = 0.0\n\n  def setup(self):\n    \"\"\"Initializes the backbone and classification head.\"\"\"\n    self.backbone = PRETRAINED_RESNETS[self.layers].module\n    self.head = SkinLesionClassifierHead(self.num_classes, self.dropout_rate)\n\n  def __call__(self, x, is_training: bool = False):\n    \"\"\"Runs a forward pass through the model.\"\"\"\n    x = self.backbone(x, deterministic=not is_training).pooler_output\n    x = jnp.squeeze(x, axis=(2, 3))\n    x = self.head(x, is_training=is_training)\n    return x\n\n  def create_train_state(\n    self, rng: jax.Array, dummy_input, tx\n  ) -> TrainStateWithBatchNorm:\n    \"\"\"Initializes model parameters and optimizer state.\"\"\"\n    rng, rng_init, rng_dropout = jax.random.split(rng, 3)\n    variables = self.init(rng_init, dummy_input, is_training=False)\n    variables = self.transfer_parameters(variables)\n    tx = self.set_trainable_parameters(tx, variables)\n    state = TrainStateWithBatchNorm.create(\n      apply_fn=self.apply,\n      tx=tx,\n      params=variables[\"params\"],\n      batch_stats=variables[\"batch_stats\"],\n      key=rng_dropout,\n    )\n    return state\n\n  def transfer_parameters(_, variables):\n    \"\"\"Returns variables unchanged (no transfer learning).\"\"\"\n    return variables\n\n  @staticmethod\n  def set_trainable_parameters(tx, _):\n    \"\"\"Returns optimizer configuration with all parameters trainable.\"\"\"\n    return tx\n\n```", "```py\nfrom transformers import FlaxResNetModel\n\n# Dictionary of pretrained ResNet models from Hugging Face.\nPRETRAINED_RESNETS = {\n  18: FlaxResNetModel.from_pretrained(\"microsoft/resnet-18\"),\n  34: FlaxResNetModel.from_pretrained(\"microsoft/resnet-34\"),\n  50: FlaxResNetModel.from_pretrained(\"microsoft/resnet-50\"),\n}\n\n```", "```py\nclass FinetunedResNet(ResNetFromScratch):\n  \"\"\"ResNet model with pretrained weights and full fine-tuning.\"\"\"\n\n  def transfer_parameters(self, variables):\n    \"\"\"Replaces model parameters with pretrained ResNet weights.\"\"\"\n    resnet_variables = PRETRAINED_RESNETS[self.layers].params\n    variables[\"params\"][\"backbone\"] = resnet_variables[\"params\"]\n    variables[\"batch_stats\"][\"backbone\"] = resnet_variables[\"batch_stats\"]\n    return variables\n```", "```py\nclass FinetunedHeadResNet(FinetunedResNet):\n  \"\"\"ResNet model with a frozen backbone and trainable classification head.\"\"\"\n\n  @staticmethod\n  def set_trainable_parameters(tx, variables):\n    \"\"\"Freezes backbone parameters and trains only the classification head.\"\"\"\n    return optax.multi_transform(\n      transforms={\"trainable\": tx, \"frozen\": optax.set_to_zero()},\n      param_labels=traverse_util.path_aware_map(\n        lambda path, _: \"frozen\" if \"backbone\" in path else \"trainable\",\n        variables[\"params\"],\n      ),\n    )\n```", "```py\n    class PartiallyFinetunedResNet(FinetunedResNet):\n      \"\"\"ResNet model with selective fine-tuning of deeper layers.\"\"\"\n\n      @staticmethod\n      def set_trainable_parameters(tx, variables):\n        \"\"\"Freezes early layers, fine-tunes other layers at variable LR.\"\"\"\n\n        def label_fn(path, _):\n          joined = \"/\".join(path)\n          if \"backbone\" in path:\n            if \"stages/3\" in joined:\n              return \"reduced_lr\"\n            return \"frozen\"\n          return \"trainable\"\n\n        return optax.multi_transform(\n          transforms={\n            \"trainable\": tx,\n            \"reduced_lr\": optax.adam(learning_rate=1e-5),\n            \"frozen\": optax.set_to_zero(),\n          },\n          param_labels=traverse_util.path_aware_map(label_fn, variables[\"params\"]),\n        )\n    ```", "```py\n@restorable\ndef train(\n  state: TrainStateWithBatchNorm,\n  rng: jax.Array,\n  dataset_splits: dict[str, Dataset],\n  num_steps: int,\n  batch_size: int,\n  preprocessor: Callable = crop,\n  sampler: Callable = repeating_sampler,\n  augmentor: Callable = None,\n  eval_every: int = 10,\n) -> tuple[TrainStateWithBatchNorm, dict]:\n  \"\"\"Trains a model using the provided dataset splits and logs metrics.\"\"\"\n  # Set up with metrics logger and classes numbers.\n  num_classes = dataset_splits[\"train\"].num_classes\n  metrics = MetricsLogger()\n\n  # Get train batch iterator from which to take batches.\n  rng, rng_train, rng_eval = jax.random.split(rng, 3)\n  train_batcher = BatchHandler(preprocessor, sampler, augmentor)\n  train_batches = train_batcher.get_batches(\n    dataset_splits[\"train\"], batch_size, rng_train\n  )\n\n  steps = tqdm(range(num_steps))  # Steps with progress bar.\n  for step in steps:\n    steps.set_description(f\"Step {step + 1}\")\n\n    rng, rng_dropout = jax.random.split(rng, 2)\n    train_batch = next(train_batches)\n    state, batch_metrics = train_step(\n      state, train_batch, rng_dropout, num_classes\n    )\n    metrics.log_step(split=\"train\", **batch_metrics)\n\n    if step % eval_every == 0:\n      for batch in BatchHandler(preprocessor).get_batches(\n        dataset_splits[\"valid\"], batch_size, rng_eval\n      ):\n        batch_metrics = eval_step(state, batch, num_classes)\n        metrics.log_step(split=\"valid\", **batch_metrics)\n      metrics.flush(step=step)\n\n    steps.set_postfix_str(metrics.latest([\"loss\"]))\n\n  return state, metrics.export()\n\n```", "```py\n@partial(jax.jit, static_argnums=(3,))\ndef train_step(\n  state: TrainStateWithBatchNorm,\n  batch: dict[str, list[Any]],\n  rng_dropout: jax.Array,\n  num_classes: int,\n) -> tuple[TrainStateWithBatchNorm, dict[str, jax.Array]]:\n  \"\"\"Performs a single training step and returns updated state and metrics.\"\"\"\n\n  def calculate_loss(params, images, labels):\n    variables, kwargs = {\"params\": params}, {\"mutable\": []}\n    if state.batch_stats is not None:\n      variables.update({\"batch_stats\": state.batch_stats})\n      kwargs.update({\"mutable\": [\"batch_stats\"]})\n    logits, updates = state.apply_fn(\n      variables,\n      x=images,\n      is_training=True,\n      rngs={\"dropout\": rng_dropout},\n      **kwargs,\n    )\n    loss = optax.softmax_cross_entropy_with_integer_labels(\n      logits, labels\n    ).mean()\n    return loss, (logits, updates)\n\n  grad_fn = jax.value_and_grad(calculate_loss, has_aux=True)\n  (loss, (logits, updates)), grads = grad_fn(\n    state.params, batch[\"images\"], batch[\"labels\"]\n  )\n  state = state.apply_gradients(grads=grads)\n  if state.batch_stats is not None:\n    state = state.replace(batch_stats=updates[\"batch_stats\"])\n\n  metrics = {\n    \"loss\": loss,\n    **compute_metrics(batch[\"labels\"], logits, num_classes),\n  }\n\n  return state, metrics\n```", "```py\n@partial(jax.jit, static_argnums=(2,))\ndef eval_step(\n  state: TrainStateWithBatchNorm, batch: dict[str, Any], num_classes: int\n):\n  \"\"\"Evaluates model performance on a batch and computes metrics.\"\"\"\n  variables, kwargs = {\"params\": state.params}, {}\n  if state.batch_stats is not None:\n    variables.update({\"batch_stats\": state.batch_stats})\n    kwargs.update({\"mutable\": False})\n\n  logits = state.apply_fn(\n    variables, x=batch[\"images\"], is_training=False, **kwargs\n  )\n  loss = optax.softmax_cross_entropy_with_integer_labels(\n    logits, batch[\"labels\"]\n  ).mean()\n\n  metrics = {\n    \"loss\": loss,\n    **compute_metrics(batch[\"labels\"], logits, num_classes),\n  }\n  return metrics\n\n```", "```py\n@partial(jax.jit, static_argnums=(2,))\ndef compute_metrics(\n  y_true: jax.Array, logits: jax.Array, n_labels: jax.Array\n) -> dict[str, jax.Array]:\n  \"\"\"Computes weighted precision and recall metrics from logits and labels.\"\"\"\n  y_scores = jax.nn.softmax(logits)\n  y_pred = jnp.argmax(y_scores, axis=1)\n  metrics = {\n    \"recall_weighted\": recall_score(\n      y_true, y_pred, n_labels, average=\"weighted\"\n    ),\n    \"precision_weighted\": precision_score(\n      y_true, y_pred, n_labels, average=\"weighted\"\n    ),\n  }\n  return metrics\n\n```", "```py\nfrom dlfb.cancer.dataset.preprocessors import skew\n\nrng = jax.random.PRNGKey(seed=42)\nrng, rng_dataset, rng_init, rng_train = jax.random.split(rng, num=4)\n\ndataset_splits = DatasetBuilder(\n  data_dir=assets(\"cancer/datasets/raw\"),\n).build(\n  rng=rng_dataset,\n  preprocessors=[skew, crop, resnet],\n  image_size=(224, 224, 3),\n  splits={\"train\": 0.70, \"valid\": 0.20, \"test\": 0.10},\n)\n\nnum_classes = dataset_splits[\"train\"].num_classes\n```", "```py\nimport optax\n\nfrom dlfb.cancer.train.handlers.samplers import repeating_sampler\nfrom dlfb.cancer.utils import decay_mask\n\nlearning_rate = 0.001\nnum_steps = 2000\n\nstate, metrics = train(\n  state=SimpleCnn(num_classes=num_classes).create_train_state(\n    rng=rng_init,\n    dummy_input=dataset_splits[\"train\"].get_dummy_input(),\n    tx=optax.adamw(learning_rate, weight_decay=0.0, mask=decay_mask),\n  ),\n  rng=rng_train,\n  dataset_splits=dataset_splits,\n  num_steps=num_steps,\n  batch_size=32,\n  preprocessor=crop,\n  sampler=repeating_sampler,\n  augmentor=None,\n  eval_every=100,\n  store_path=assets(\"cancer/models/baseline\"),\n)\n\n```", "```py\nfrom dlfb.cancer.inspect import plot_learning\n\nplot_learning(metrics);\n\n```", "```py\nfrom dlfb.cancer.inspect import plot_classified_images\nfrom dlfb.cancer.train import get_predictions\n\npredictions = get_predictions(state, dataset_splits[\"valid\"], resnet, 32)\nplot_classified_images(\n  predictions, dataset_splits[\"valid\"], crop, max_images=8\n);\n\n```", "```py\nstate, metrics = train(\n  state=ResNetFromScratch(num_classes=num_classes).create_train_state(\n    rng=rng_init,\n    dummy_input=dataset_splits[\"train\"].get_dummy_input(),\n    tx=optax.adamw(learning_rate, weight_decay=0.0, mask=decay_mask),\n  ),\n  rng=rng_train,\n  dataset_splits=dataset_splits,\n  num_steps=num_steps,\n  batch_size=32,\n  preprocessor=crop,  # No preprocessing.\n  sampler=repeating_sampler,  # No balancing.\n  augmentor=None,  # No augmentation.\n  eval_every=100,\n  store_path=assets(\"cancer/models/resnet_from_scratch\"),\n)\n```", "```py\nplot_learning(metrics);\n```", "```py\npredictions = get_predictions(state, dataset_splits[\"valid\"], resnet, 32)\nplot_classified_images(\n  predictions, dataset_splits[\"valid\"], crop, max_images=8\n);\n```", "```py\nIMAGE_PROCESSOR = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n\ndef resnet(image: jax.Array) -> jax.Array:\n  \"\"\"Preprocess from pretrained model with transpose for compatibility.\"\"\"\n  image = IMAGE_PROCESSOR(image, return_tensors=\"jax\", do_rescale=True)\n  image = image[\"pixel_values\"]\n  image = convert_nchw_to_nhwc(image)\n  return image\n\n```", "```py\nstate, metrics = train(\n  state=FinetunedHeadResNet(num_classes=num_classes).create_train_state(\n    rng=rng_init,\n    dummy_input=dataset_splits[\"train\"].get_dummy_input(),\n    tx=optax.adamw(learning_rate, weight_decay=0.0, mask=decay_mask),\n  ),\n  rng=rng_train,\n  dataset_splits=dataset_splits,\n  num_steps=num_steps,\n  batch_size=32,\n  preprocessor=resnet,\n  sampler=repeating_sampler,\n  augmentor=None,\n  eval_every=100,\n  store_path=assets(\"cancer/models/resnet_just_head\"),\n)\n```", "```py\nplot_learning(metrics);\n```", "```py\nstate, metrics = train(\n  state=FinetunedResNet(num_classes=num_classes).create_train_state(\n    rng=rng_init,\n    dummy_input=dataset_splits[\"train\"].get_dummy_input(),\n    tx=optax.adamw(learning_rate, weight_decay=0.0, mask=decay_mask),\n  ),\n  rng=rng_train,\n  dataset_splits=dataset_splits,\n  num_steps=num_steps,\n  batch_size=32,\n  preprocessor=resnet,\n  sampler=repeating_sampler,\n  augmentor=None,\n  eval_every=100,\n  store_path=assets(\"cancer/models/resnet50_basic\"),\n)\n\n```", "```py\nplot_learning(metrics);\n\n```", "```py\nimport optax\n\nlearning_rate = 0.001\nnum_steps = 2000\n\nwarmup_cosine_decay_scheduler = optax.warmup_cosine_decay_schedule(\n  init_value=0.0001,\n  peak_value=learning_rate,\n  end_value=0.00001,\n  warmup_steps=int(num_steps * 0.2),\n  decay_steps=num_steps,\n)\n\nlrs = [warmup_cosine_decay_scheduler(i) for i in range(num_steps)]\n\nplt.scatter(range(num_steps), lrs)\nplt.title(\"Learning Rate over Steps\")\nplt.ylabel(\"Learning Rate\")\nplt.xlabel(\"Step\");\n```", "```py\nstate, metrics = train(\n  state=FinetunedResNet(\n    num_classes=num_classes, dropout_rate=0.7\n  ).create_train_state(\n    rng=rng_init,\n    dummy_input=dataset_splits[\"train\"].get_dummy_input(),\n    tx=optax.adamw(\n      warmup_cosine_decay_scheduler, weight_decay=1e-4, mask=decay_mask\n    ),\n  ),\n  rng=rng_train,\n  dataset_splits=dataset_splits,\n  num_steps=num_steps,\n  batch_size=32,\n  preprocessor=resnet,\n  sampler=repeating_sampler,\n  augmentor=rich_augmentor,\n  eval_every=100,\n  store_path=assets(\"cancer/models/resnet50_optimized\"),\n)\n\n```", "```py\nplot_learning(metrics);\n```", "```py\npredictions = get_predictions(state, dataset_splits[\"valid\"], resnet, 32)\nplot_classified_images(\n  predictions, dataset_splits[\"valid\"], crop, max_images=8\n);\n```"]