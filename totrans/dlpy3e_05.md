# 机器学习基础

> 原文：[`deeplearningwithpython.io/chapters/chapter05_fundamentals-of-ml`](https://deeplearningwithpython.io/chapters/chapter05_fundamentals-of-ml)

在第四章的三个实际例子之后，你应该开始熟悉如何使用神经网络来处理分类和回归问题，并且你已经见证了机器学习的核心问题：过拟合。本章将把你对机器学习的新直觉正式化为一个坚实的概念框架，强调准确模型评估和训练与泛化之间平衡的重要性。

## 泛化：机器学习的目标

在第四章中提出的三个例子——预测电影评论、主题分类和房价回归中，我们将数据分为训练集、验证集和测试集。不要在训练模型的数据上评估模型的原因很快变得明显：仅仅经过几个 epoch，从未见过的数据上的性能就开始与训练数据上的性能分离，而训练数据随着训练的进行总是提高。模型开始*过拟合*。过拟合发生在每个机器学习问题中。

机器学习的核心问题是优化和泛化之间的张力。*优化*指的是调整模型以在训练数据上获得最佳性能的过程（在*机器学习*中的*学习*），而*泛化*指的是训练好的模型在之前未见过的数据上的表现。当然，游戏的目标是获得良好的泛化，但你无法控制泛化；你只能使模型适应其训练数据。如果你做得*太好了*，过拟合就会发生，泛化就会受到影响。

但是什么导致了过拟合？我们如何实现良好的泛化？

### 欠拟合和过拟合

对于你在上一章中看到的所有模型，随着训练的进行，在保留的验证数据上的性能最初会提高，然后不可避免地会在一段时间后达到顶峰。这种模式（如图 5.1 所示）是普遍存在的。你会在任何模型类型和任何数据集上看到它。

![](img/5d6317dd0e52bc77ae547bca0f76c879.png)

图 5.1：典型的过拟合行为

在训练的初期，优化和泛化是相关的：训练数据上的损失越低，测试数据上的损失也越低。在这个过程中，你的模型被认为是*欠拟合*的：还有进步的空间；网络还没有对训练数据中的所有相关模式进行建模。但经过一定次数的训练数据迭代后，泛化不再提高，验证指标停滞并开始下降：模型开始过拟合。也就是说，它开始学习特定于训练数据的模式，但这些模式在处理新数据时可能是误导性的或不相关的。

当数据存在噪声、涉及不确定性或包含罕见特征时，过拟合尤其可能发生。让我们看看具体的例子。

#### 噪声训练数据

在现实世界的数据集中，某些输入无效的情况相当常见。例如，MNIST 数字可能是一张全黑的图像，或者类似于图 5.2 中的某些东西。

![](img/048b802dd836f05362475154ee9aaa4a.png)

图 5.2：一些非常奇怪的 MNIST 训练样本

这些是什么？我们也不知道。但它们都是 MNIST 训练集的一部分。然而，更糟糕的是，有些完全有效的输入最终被错误标注，如图 5.3 中所示。

![](img/aca83ea1f5cd193a250e1a6bfb9dec30.png)

图 5.3：错误标注的 MNIST 训练样本

如果一个模型特意包含这样的异常值，其泛化性能将下降，如图 5.4 所示。例如，一个看起来非常接近图 5.3 中错误标注的 4 的 4，最终可能被归类为 9。

![](img/66508074b4d77b9fb75bb21b26f0c133.png)

图 5.4：处理异常值：鲁棒拟合与过拟合

#### 模糊特征

并非所有数据噪声都源于不准确——即使非常干净且标签清晰的 数据，当问题涉及不确定性和模糊性时也可能存在噪声（见图 5.5）。在分类任务中，输入特征空间的一些区域可能同时与多个类别相关联。假设你正在开发一个模型，该模型接收香蕉的图像并预测香蕉是否未成熟、成熟或腐烂。这些类别没有客观的边界，因此同一张图片可能被不同的标注人员分别归类为未成熟或成熟。同样，许多问题涉及随机性。你可以使用大气压力数据来预测明天是否会下雨，但确切的测量结果有时会伴随着降雨，有时则是晴朗的天空——带有一定的概率。

![](img/2c1d27fcf1e10c783a05aa77a301b691.png)

图 5.5：鲁棒拟合与过拟合在特征空间中给出的模糊区域

一个模型可能会通过过于自信地处理特征空间的模糊区域（如图 5.6 所示）而对这样的概率数据进行过拟合。更鲁棒的拟合将忽略个别数据点，并关注更大的图景。

#### 罕见特征和虚假相关性

如果你一生中只见过两只橙色虎斑猫，而且它们都极其反社会，你可能会推断橙色虎斑猫通常可能很反社会。这是过拟合：如果你接触过更多种类的猫，包括更多橙色猫，你会了解到猫的颜色与性格并不密切相关。

同样，在包含罕见特征值的训练数据集上训练的机器学习模型很容易过拟合。在一个情感分类任务中，如果单词“cherimoya”（一种安第斯山脉的本土水果）仅在训练数据中的一篇文本中出现，而这篇文本恰好是负面的情感，那么一个欠规范的模型可能会给这个单词赋予非常高的权重，并总是将提及 cherimoyas 的新文本分类为负面，而实际上，cherimoya 并没有任何负面之处。^([[1]](#footnote-1))

重要的是，一个特征值不需要只出现几次就会导致虚假相关性。考虑一个在训练数据中出现 100 次的单词，54% 的时间与正面情感相关，46% 的时间与负面情感相关。这种差异可能完全是完全的统计巧合，但你的模型很可能会学会使用这个特征来进行其分类任务。这是过拟合最常见的原因之一。

这里有一个引人注目的例子。以 MNIST 为例。通过将 784 个白噪声维度连接到现有数据的 784 个维度上创建一个新的训练集——因此现在一半的数据是噪声。为了比较，还创建了一个通过连接 784 个全零维度等效的数据集。我们添加的无意义特征并没有影响数据的信含量：我们只是在添加无关的数据点。人类的分类准确率根本不会受到这些转换的影响。

```py
from keras.datasets import mnist
import numpy as np

(train_images, train_labels), _ = mnist.load_data()
train_images = train_images.reshape((60000, 28 * 28))
train_images = train_images.astype("float32") / 255

train_images_with_noise_channels = np.concatenate(
    [train_images, np.random.random((len(train_images), 784))], axis=1
)

train_images_with_zeros_channels = np.concatenate(
    [train_images, np.zeros((len(train_images), 784))], axis=1
) 
```

列表 5.1：向 MNIST 添加白噪声通道或全零通道

现在，让我们在这两个训练集上训练第二章中的模型。

```py
import keras
from keras import layers

def get_model():
    model = keras.Sequential(
        [
            layers.Dense(512, activation="relu"),
            layers.Dense(10, activation="softmax"),
        ]
    )
    model.compile(
        optimizer="adam",
        loss="sparse_categorical_crossentropy",
        metrics=["accuracy"],
    )
    return model

model = get_model()
history_noise = model.fit(
    train_images_with_noise_channels,
    train_labels,
    epochs=10,
    batch_size=128,
    validation_split=0.2,
)

model = get_model()
history_zeros = model.fit(
    train_images_with_zeros_channels,
    train_labels,
    epochs=10,
    batch_size=128,
    validation_split=0.2,
) 
```

列表 5.2：在 MNIST 数据上使用噪声通道或全零通道训练相同的模型

尽管两种情况下的数据都包含相同的信息，但使用噪声通道训练的模型的验证准确率最终会低约一个百分点——纯粹是通过虚假相关性的影响（图 5.6）。你添加的噪声通道越多，准确率下降得越厉害。

![](img/ba0fabf8a77435e8b3e8434cd0f9204e.png)

图 5.6：噪声通道对验证准确率的影响

噪声特征不可避免地会导致过拟合。因此，在你不确定你拥有的特征是有信息量还是分散注意力的特征时，在训练之前进行特征选择是很常见的。例如，将 IMDB 数据限制在最常见的 10,000 个单词就是一种粗略的特征选择方法。进行特征选择的典型方法是为每个可用的特征计算一些有用性分数——这是特征相对于任务的信度度量，例如特征与标签之间的互信息——并且只保留高于某个阈值的特征。这样做将过滤掉前面例子中的白噪声通道。

### 深度学习中泛化的本质

深度学习模型的一个显著事实是，只要它们有足够的表达能力，就可以训练它们去适应任何事物。

你不相信吗？试着打乱 MNIST 标签的顺序，并在那个数据上训练一个模型。即使输入和打乱后的标签之间没有任何关系，训练损失也会相应下降，即使是一个相对较小的模型也是如此。自然地，随着时间的推移，验证损失根本不会提高，因为在这种情况下没有泛化的可能性。

```py
(train_images, train_labels), _ = mnist.load_data()
train_images = train_images.reshape((60000, 28 * 28))
train_images = train_images.astype("float32") / 255

# Copies train_labels
random_train_labels = train_labels[:]
np.random.shuffle(random_train_labels)

model = keras.Sequential(
    [
        layers.Dense(512, activation="relu"),
        layers.Dense(10, activation="softmax"),
    ]
)
model.compile(
    optimizer="rmsprop",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"],
)
model.fit(
    train_images,
    random_train_labels,
    epochs=100,
    batch_size=128,
    validation_split=0.2,
) 
```

列表 5.3：使用随机打乱标签拟合 MNIST 模型

实际上，你甚至不需要用 MNIST 数据来做这件事——你只需要生成白噪声输入和随机标签。只要模型有足够的参数，你也能在上面拟合一个模型。它最终会记住特定的输入，就像 Python 字典一样。

如果是这样的话，那么为什么深度学习模型能够泛化呢？它们不应该只是学习训练输入和目标之间的一个临时的映射，就像一个花哨的`dict`吗？我们对此映射能够适用于新输入有什么期望？

实际上，深度学习中泛化的本质与深度学习模型本身关系不大，而与现实世界中信息结构有很大关系。让我们看看这里真正发生了什么。

#### 流形假设

MNIST 分类器的输入（在预处理之前）是一个 28 × 28 的整数数组，其值介于 0 到 255 之间。因此，可能的输入值的总数是 256 的 784 次方——远大于宇宙中的原子数。然而，其中只有极少数的输入看起来像有效的 MNIST 样本：实际的手写数字只占据了所有可能的 28 x 28 `uint8`数组父空间的一个微小的**子空间**。更重要的是，这个子空间不仅仅是在父空间中随机散布的点集：它具有高度的结构性。

首先，有效手写数字的子空间是**连续的**：如果你取一个样本并稍作修改，它仍然可以被识别为相同的手写数字。进一步地，所有有效子空间中的样本都通过在子空间中运行的平滑路径**连接**在一起。这意味着如果你取两个随机的 MNIST 数字 A 和 B，存在一系列“中间”图像，将 A 逐渐变形为 B，使得两个连续的数字非常接近（见图 5.7）。也许在两个类别之间的边界附近会有一些模糊的形状，但这些形状仍然非常像数字。

![流形假设图](img/d88491a526b48c3670d1df4a3cd24fad.png)

图 5.7：不同的 MNIST 数字逐渐变形为彼此，显示了手写数字空间形成“流形”。此图像使用第十七章中的代码生成。

从技术角度来说，你会说手写数字在可能的 28 × 28 `uint8`数组空间中形成一个*流形*。这是一个很大的词，但概念相当直观。流形是某个父空间中的低维子空间，在局部上与线性（欧几里得）空间相似。例如，平面上的光滑曲线是二维空间中的一维流形，因为对于曲线上的每一个点，你都可以画一条切线（曲线可以在每个点被近似为一条线）。三维空间中的光滑表面是一个二维流形。以此类推。

更普遍地说，*流形假设*认为所有自然数据都位于其编码的高维空间中的低维流形上。这是一个关于宇宙中信息结构的相当强烈的陈述。据我们所知，这是准确的，也是深度学习之所以有效的原因。这适用于 MNIST 数字，也适用于人脸、树木形态、人类的声音，甚至自然语言。

流形假设意味着

+   机器学习模型只需要在其潜在输入空间（潜在流形）中拟合相对简单、低维、高度结构化的子空间。

+   在这些流形中的任何一个，总是在两个输入之间进行*插值*——也就是说，通过一条所有点都位于流形上的连续路径，将一个形态转换为另一个形态。

在样本之间进行插值的能力是理解深度学习中泛化的关键。

#### 插值作为泛化的来源

如果你处理的是可以进行插值的数据点，你可以通过将它们与流形上靠近的其他点相关联，开始理解你以前从未见过的点。换句话说，你只需要使用空间的一个*样本*就能理解空间的*整体*。你可以使用插值来填补空白。

注意，潜在流形上的插值与父空间中的线性插值不同，如图 5.8 所示。例如，两个 MNIST 数字之间的像素平均值通常不是一个有效的数字。

![](img/98e9072fd0dbd5cf96bee6acb37ebbdc.png)

图 5.8：线性插值与潜在流形插值的区别。数字的潜在流形上的每个点都是一个有效的数字，但两个数字的平均值通常不是。

关键的是，虽然深度学习通过在数据流形的近似上插值来实现泛化，但认为插值就是泛化的全部是错误的。这只是冰山一角。插值只能帮助你理解非常接近你之前所见的事物：它实现了*局部泛化*。但令人惊讶的是，人类经常处理极端的新奇事物，而且他们做得很好。你不需要提前在无数种你将遇到的情境的例子上进行训练。你每一天都是不同于你之前经历过的任何一天，也不同于自人类诞生以来任何人经历过的任何一天。你可以在这三个城市中任意切换：在纽约市度过一周，在上海度过一周，在班加罗尔度过一周，而不需要为每个城市进行数千年的学习和排练。

人类能够进行*极端泛化*，这是由除了插值之外的认知机制所实现的——抽象、世界的符号模型、推理、逻辑、常识、关于世界的先验知识——我们通常称之为*理性*，与直觉和模式识别相对。后者在很大程度上是插值的，但前者不是。两者对智能都是必不可少的。我们将在第十九章中更多地讨论这一点。

#### 为什么深度学习有效

记得第二章中的皱巴巴的纸团隐喻吗？一张纸代表三维空间中的一个二维流形（图 5.9）。深度学习模型是展开纸团的工具——也就是说，是解开潜在流形的工具。

![图片](img/a89f2451feb6a78d99e009be13583d1b.png)

图 5.9：解开复杂数据流形

深度学习模型基本上是一个非常高维的曲线。这条曲线是平滑且连续的（其结构受到模型架构先验的额外约束），因为它需要可微。而且这条曲线是通过梯度下降来拟合数据点的——平滑且逐步地。*按照构造*，深度学习是关于取一个大而复杂的曲线——一个流形——并逐步调整其参数，直到它适合某些训练数据点。

这条曲线包含足够的参数，可以拟合任何事物。事实上，如果你让你的模型训练足够长的时间，它实际上最终会纯粹地记住其训练数据，而不会进行任何泛化。然而，你正在拟合的数据不是由在潜在空间中稀疏分布的孤立点组成的。你的数据在输入空间中形成一个高度结构化、低维的流形——这就是流形假设。而且因为随着梯度下降的进行，拟合模型曲线到数据的过程是逐渐且平滑的，所以在训练过程中会有一个中间点，此时模型大致近似数据的自然流形，如图 5.10 所示。

![图片](img/6184df929f2425673e4fed427eb3b6ef.png)

图 5.10：从随机模型过渡到过拟合模型，并实现作为中间状态的鲁棒拟合

沿着模型在该点学习的曲线移动将接近沿着数据的实际潜在流形移动。因此，该模型将能够通过在训练输入之间进行插值来理解从未见过的输入。

除了它们有足够的表示能力这一显而易见的事实之外，深度学习模型还有一些特性使它们特别适合学习潜在流形：

+   深度学习模型实现了从输入到输出的平滑、连续映射。它必须平滑且连续，因为它是可微分的（否则无法进行梯度下降）。这种平滑性有助于近似潜在流形，这些流形遵循相同的属性。

+   深度学习模型往往以反映其训练数据中“形状”的方式（通过架构先验）进行结构化。这尤其适用于图像处理模型（参见第 8-12 章）和序列处理模型（参见第十三章）。更普遍地说，深度神经网络以分层和模块化的方式结构化其学习到的表示，这与自然数据的组织方式相呼应。

#### 训练数据至关重要

虽然深度学习确实非常适合进行流形学习，但泛化的能力更多的是数据自然结构的结果，而不是模型任何属性的结果。只有当你的数据形成一个点可以插值的流形时，你才能进行泛化。你的特征越有信息性、噪声越少，你将能够更好地进行泛化，因为你的输入空间将更简单、结构更好。数据整理和特征工程对于泛化至关重要。

此外，由于深度学习是曲线拟合，为了模型能够表现良好，*它需要在输入空间的密集采样上进行训练*。在这个上下文中，“密集采样”意味着训练数据应该密集地覆盖整个输入数据流形（参见图 5.11）。这在决策边界附近尤其如此。在足够密集的采样下，通过在过去的训练输入之间进行插值，可以理解新的输入，而无需使用常识、抽象推理或关于世界的知识——所有这些都是机器学习模型无法获取的。

![图片](img/d6cbc71cfbd6e2015524613e5ce95c3a.png)

图 5.11：为了学习能够进行准确泛化的模型，对输入空间进行密集采样是必要的。

因此，你应该始终牢记，提高深度学习模型的最佳方式是在更多或更好的数据上训练它（当然，添加过度嘈杂或不准确的数据会损害泛化）。对输入数据流形的更密集覆盖将产生泛化能力更强的模型。你永远不要期望深度学习模型能够执行比其在训练样本之间进行粗略插值更复杂的事情，因此，你应该尽一切可能使插值尽可能简单。你将在深度学习模型中找到的只有你放入其中的东西：其架构中编码的先验知识和其训练所使用的数据。

当无法获取更多数据时，下一个最佳解决方案是调节模型允许存储的信息量，或者对模型曲线的平滑性添加约束。如果一个网络只能负担得起记住少量模式，或者非常规则的模式，优化过程将迫使它专注于最突出的模式，这些模式有更好的机会进行良好的泛化。通过这种方式与过拟合作斗争的过程称为*正则化*。我们将在第 5.4.4 节中深入探讨正则化技术。

在你开始调整模型以帮助其更好地泛化之前，你需要一种方法来评估你的模型目前的表现。在接下来的章节中，你将了解如何在模型开发过程中监控泛化：模型评估。

## 评估机器学习模型

你只能控制你能观察到的。由于你的目标是开发能够成功推广到新数据的模型，因此能够可靠地衡量你模型的泛化能力至关重要。在本节中，我们将正式介绍你可以用来评估机器学习模型的多种方式。你已经在上一章中看到了其中大部分的实际应用。

### 训练集、验证集和测试集

评估一个模型始终归结为将可用数据分成三个集合：训练集、验证集和测试集。你在训练数据上训练，并在验证数据上评估你的模型。一旦你的模型准备就绪，你最后一次在测试数据上对其进行测试，测试数据应尽可能与生产数据相似。然后你可以在生产环境中部署该模型。

你可能会问，为什么不设置两组数据：一组训练集和一组测试集？你在训练数据上训练，在测试数据上评估。这要简单得多！

原因是开发模型总是涉及调整其配置：例如，选择层数或层的尺寸（称为模型的*超参数*，以区分它们与*参数*，参数是网络的权重）。你通过使用作为反馈信号的模型在验证数据上的性能来进行这种调整。本质上，这种调整是一种*学习*：在某个参数空间中寻找良好配置的过程。因此，基于模型在验证集上的性能调整模型的配置可以迅速导致*过度拟合验证集*，即使你的模型从未直接在它上面训练过。

这一现象的核心是*信息泄露*的概念。每次你根据模型在验证集上的性能调整模型的超参数时，一些关于验证数据的信息就会泄露到模型中。如果你只做一次，针对一个参数，那么泄露的信息量会非常少，你的验证集将保持可靠，用于评估模型。但如果你重复多次——运行一个实验，在验证集上评估，并根据结果修改你的模型——那么你将越来越多地泄露关于验证集的信息到模型中。

最后，你将得到一个在验证数据上表现人工良好的模型，因为那是你优化它的目标。你关心的是在完全新的数据上的性能，而不是验证数据，所以你需要使用一个完全不同、从未见过的数据集来评估模型：测试数据集。你的模型不应该接触到*任何*关于测试集的信息，即使是间接的。如果模型的任何方面是基于测试集的性能进行调整的，那么你的泛化度量将会是有缺陷的。

将你的数据分为训练集、验证集和测试集看似简单，但有一些高级方法可以实现，当数据量较少时这些方法可能非常有用。让我们回顾三种经典的评估方法：简单的保留验证、K 折验证和带有洗牌的迭代 K 折验证。我们还将讨论使用常识性基线来检查你的训练是否有所进展。

#### 简单的保留验证

将你数据的一部分作为测试集。在剩余的数据上训练，并在测试集上评估。正如你在前面的章节中看到的，为了防止信息泄露，你不应该根据测试集调整你的模型，因此你也应该*同样*保留一个验证集。

概括来说，保留验证看起来就像图 5.12 所示。以下列表展示了一个简单的实现。

![](img/84f0465e58c36e5d326ebdd845403f65.png)

图 5.12：简单的保留验证分割

```py
num_validation_samples = 10000
# Shuffling the data is usually appropriate.
np.random.shuffle(data)
# Defines the validation set
validation_data = data[:num_validation_samples]
# Defines the training set
training_data = data[num_validation_samples:]
# Trains a model on the training data and evaluates it on the
# validation data
model = get_model()
model.fit(training_data, ...)
validation_score = model.evaluate(validation_data, ...)

# At this point, you can tune your model, retrain it, evaluate it, tune
# it again, and so on.
...

# Once you've tuned your hyperparameters, it's common to train your
# final model from scratch on all non-test data available.
model = get_model()
model.fit(
    np.concatenate([training_data, validation_data]),
    ...,
)
test_score = model.evaluate(test_data, ...) 
```

列表 5.4：保留验证（注意为了简单起见省略了标签）

这是最简单的评估协议，但它有一个缺点：如果数据很少，那么你的验证集和测试集可能包含的样本太少，无法在统计上代表手头的数据。这很容易识别：如果在分割数据之前的随机洗牌轮次结束后，模型性能的度量非常不同，那么你就有这个问题。K 折验证和迭代 K 折验证是两种解决方法，如后文所述。

#### K 折验证

使用这种方法，你将数据分成`K`个大小相等的部分。对于每个部分`i`，在剩余的`K - 1`个部分上训练一个模型，并在部分`i`上评估它。你的最终得分是 K 个得分的平均值。当你的模型性能基于你的训练/测试分割显示出显著的方差时，这种方法很有帮助。就像保留法验证一样，这种方法不会让你免除为模型校准使用一个独立的验证集。

概括地看，K 折交叉验证看起来像图 5.13。列表 5.6 展示了简单实现。

![图片](img/29029d5c4877975815ab98f940282a76.png)

图 5.13：三折验证

```py
k = 3
num_validation_samples = len(data) // k
np.random.shuffle(data)
validation_scores = []
for fold in range(k):
    # Selects the validation-data partition
    validation_data = data[
        num_validation_samples * fold : num_validation_samples * (fold + 1)
    ]
    # Uses the remainder of the data as training data.
    training_data = np.concatenate(
        data[: num_validation_samples * fold],
        data[num_validation_samples * (fold + 1) :],
    )
    # Creates a brand-new instance of the model (untrained)
    model = get_model()
    model.fit(training_data, ...)
    validation_score = model.evaluate(validation_data, ...)
    validation_scores.append(validation_score)
# Validation score: average of the validation scores of the k folds
validation_score = np.average(validation_scores)
# Trains the final model on all non-test data available
model = get_model()
model.fit(data, ...)
test_score = model.evaluate(test_data, ...) 
```

列表 5.5：K 折交叉验证（为了简单起见，省略了标签）

#### 带洗牌的迭代 K 折验证

这种方法适用于你只有相对较少数据可用，并且需要尽可能精确地评估你的模型的情况。我发现它在 Kaggle 比赛中非常有帮助。它包括多次应用 K 折验证，每次在分割数据成`K`部分之前都进行数据洗牌。最终得分是每次 K 折验证运行得到的得分的平均值。请注意，你最终会训练和评估`P * K`个模型（其中`P`是你使用的迭代次数），这可能会非常昂贵。

### 打败常识性基线

除了你拥有的不同评估协议外，还有最后一件事你应该知道，那就是常识性基线的使用。

训练一个深度学习模型有点像按下在一个平行世界中发射火箭的按钮。你听不到它或看到它。你无法观察到流形学习过程——它在一个有数千维度的空间中发生，即使你将其投影到 3D，你也无法解释它。你唯一能得到的反馈是你的验证指标——就像你无形火箭上的高度计。

一个特别重要的点是能够判断你是否真的有所进展。你起始的高度是多少？你的模型似乎有 15%的准确率，这算好吗？在你开始使用数据集之前，你应该始终选择一个简单的基线，并尝试超越它。如果你超过了那个阈值，你就知道你正在做正确的事情：你的模型实际上正在使用输入数据中的信息来做出泛化的预测——你可以继续前进。这个基线可以是随机分类器的性能，或者你可以想象到的最简单的非机器学习技术的性能。

例如，在 MNIST 数字分类示例中，一个简单的基线可以是验证准确率大于 0.1（随机分类器）；在 IMDB 示例中，它将是验证准确率大于 0.5。在 Reuters 示例中，它将大约是 0.18–0.19，由于类别不平衡。如果你有一个二分类问题，其中 90%的样本属于类别 A，10%属于类别 B，那么一个总是预测 A 的分类器在验证准确率上已经达到 0.9，你需要做得更好。

当你开始解决一个以前没有人解决的问题时，有一个可以参考的常识性基线是至关重要的。如果你无法超越一个简单的解决方案，你的模型就没有价值——也许你使用了错误的模型，也许你正在解决的问题根本就不能用机器学习来接近。是时候回到画板上了。

### 关于模型评估需要注意的事项

选择评估协议时要注意以下几点：

+   *数据代表性* — 你希望你的训练集和测试集都能代表手头的数据。例如，如果你试图分类数字图像，并且你从一个按类别排序的样本数组开始，将数组的第一个 80%作为训练集，剩下的 20%作为测试集，那么你的训练集将只包含类别 0–7，而你的测试集将只包含类别 8–9。这似乎是一个荒谬的错误，但出人意料地常见。因此，你通常应该在将数据分割成训练集和测试集之前随机打乱你的数据。

+   *时间之箭* — 如果你试图根据过去预测未来（例如，明天的天气、股票走势等），在分割数据之前不要随机打乱你的数据，因为这样做将创建一个*时间泄露*：你的模型实际上将基于未来的数据进行训练。在这种情况下，你应该始终确保测试集中的所有数据都在训练集数据之后。

+   *数据冗余* — 如果你的数据中某些数据点出现了两次（在现实世界数据中相当常见），那么对数据进行洗牌并将其分为训练集和验证集将导致训练集和验证集之间的冗余。实际上，你将测试你的一部分训练数据，这是最糟糕的事情！确保你的训练集和验证集是不相交的。

有一个可靠的方式来评估你模型的性能，这样你将能够监控机器学习核心的紧张关系——在优化和泛化、欠拟合和过度拟合之间。

## 提高模型拟合度

要达到完美的拟合，你必须首先过度拟合。由于你事先不知道边界在哪里，你必须跨越它来找到它。因此，当你开始处理问题时，你的初始目标是实现一个显示出一些泛化能力的模型，并且能够过度拟合。一旦你有了这样的模型，你将专注于通过对抗过度拟合来细化泛化。

在这个阶段，你将遇到三个常见的问题：

+   训练没有开始：你的训练损失并没有随时间下降。

+   训练开始得很顺利，但你的模型并没有真正地泛化：你无法超越你设定的常识性基线。

+   训练和验证损失都随时间下降，你可以打败你的基线，但你似乎无法过度拟合，这表明你仍然欠拟合。

让我们看看你如何解决这些问题，以实现机器学习项目的第一个重大里程碑：得到一个具有一些泛化能力的模型（它可以打败一个平凡的基线）并且能够过度拟合。

### 调整关键梯度下降参数

有时，训练没有开始或者过早停滞。你的损失被卡住了。这*总是*可以克服的：记住你可以将模型拟合到随机数据。即使你的问题没有任何意义，你也应该*仍然*能够训练一些东西——至少通过记住训练数据。

当这种情况发生时，通常是由于梯度下降过程的配置问题：你的优化器选择、模型权重中初始值的分布、你的学习率，或者你的批量大小。所有这些参数都是相互依赖的，因此通常只需要调整学习率和批量大小，同时保持其他参数不变。

让我们看看一个具体的例子：让我们用第二章中不适当大的学习率（值为 1）来训练 MNIST 模型。

```py
(train_images, train_labels), _ = mnist.load_data()
train_images = train_images.reshape((60000, 28 * 28))
train_images = train_images.astype("float32") / 255

model = keras.Sequential(
    [
        layers.Dense(512, activation="relu"),
        layers.Dense(10, activation="softmax"),
    ]
)
model.compile(
    optimizer=keras.optimizers.RMSprop(learning_rate=1.0),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"],
)
model.fit(
    train_images, train_labels, epochs=10, batch_size=128, validation_split=0.2
) 
```

列表 5.6：使用过高学习率的 MNIST 模型进行训练

模型很快达到训练和验证准确率在 20% 到 40% 的范围内，但无法突破这个范围。让我们尝试将学习率降低到一个更合理的值 `1e-2`：

```py
model = keras.Sequential(
    [
        layers.Dense(512, activation="relu"),
        layers.Dense(10, activation="softmax"),
    ]
)
model.compile(
    optimizer=keras.optimizers.RMSprop(learning_rate=1e-2),
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"],
)
model.fit(
    train_images, train_labels, epochs=10, batch_size=128, validation_split=0.2
) 
```

列表 5.7：具有更合适学习率的相同模型

模型现在能够进行训练了。

如果你发现自己处于类似的情况，可以尝试

+   降低或提高学习率。学习率过高可能导致更新远远超出适当的拟合，就像之前的例子中那样，而学习率过低可能会使训练变得非常缓慢，看起来像是停滞不前。

+   增加批量大小。包含更多样本的批量将导致更具有信息量和更少噪声的梯度（方差更低）。

你最终会找到一个配置，使训练开始。

### 使用更好的架构先验

你有一个拟合的模型，但出于某种原因，你的验证指标根本没有任何改善。它们与随机分类器所能达到的指标一样好：你的模型在训练，但没有泛化。发生了什么？

这可能是你可能会遇到的最糟糕的机器学习情况。这表明“你的方法存在根本性的问题”，并且可能不容易判断出是什么问题。以下是一些建议。

首先，可能是因为你使用的输入数据本身就不包含足够的信息来预测你的目标：按照这种表述的问题是不可解决的。这就是我们之前尝试拟合一个 MNIST 模型，其中标签被随机打乱时发生的情况：模型可以很好地训练，但验证准确率会一直停留在 10%，因为使用这样的数据集显然无法进行泛化。

也可能是因为你使用的模型不适合当前的问题。例如，在第十三章中，你将看到一个时间序列预测问题的例子，其中密集连接的架构无法击败一个平凡的基线，而一个更合适的循环架构确实能够很好地泛化。使用对问题做出正确假设的模型对于实现泛化至关重要：你应该使用正确的架构先验。

在接下来的章节中，你将了解适用于各种数据模态的最佳架构——图像、文本、时间序列等。一般来说，你应该确保阅读针对你正在攻击的任务的架构最佳实践——很可能你不是第一个尝试这样做的人。

### 提高模型容量

如果你设法得到一个拟合的模型，其中验证指标正在下降，并且似乎达到了至少一定程度的泛化能力，恭喜你：你几乎成功了。接下来，你需要让你的模型开始过拟合。

考虑以下小型模型——一个简单的逻辑回归——它是在 MNIST 像素上训练的。

```py
model = keras.Sequential([layers.Dense(10, activation="softmax")])
model.compile(
    optimizer="rmsprop",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"],
)
history_small_model = model.fit(
    train_images, train_labels, epochs=20, batch_size=128, validation_split=0.2
) 
```

列表 5.8：MNIST 上的简单逻辑回归

你会得到类似这样的损失曲线（见图 5.14）：

```py
import matplotlib.pyplot as plt

val_loss = history_small_model.history["val_loss"]
epochs = range(1, 21)
plt.plot(epochs, val_loss, "b-", label="Validation loss")
plt.title("Validation loss for a model with insufficient capacity")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show() 
```

![图片](img/74b72a738ae10806bf61978c9e5cb342.png)

图 5.14：模型容量不足对损失曲线的影响

验证指标似乎停滞不前或改善非常缓慢，而不是达到峰值然后逆转。验证损失下降到 0.26 并保持在那里。你可以拟合，但你无法清楚地过拟合，即使是在多次迭代训练数据之后。在你的职业生涯中，你很可能会经常遇到类似的曲线。

记住，总是有可能过拟合。这与“训练损失不下降”的问题类似，这是一个可以始终解决的问题。如果你似乎无法过拟合，那么很可能是你模型的**表示能力**问题：你需要一个更大的模型，一个具有更多**容量**的模型——也就是说，能够存储更多信息。你可以通过添加更多层、使用更大的层（具有更多参数的层）或使用更适合当前问题的层（更好的架构先验）来增加表示能力。

让我们尝试训练一个更大的模型，一个包含两个中间层，每个层有 128 个单元的模型：

```py
model = keras.Sequential(
    [
        layers.Dense(128, activation="relu"),
        layers.Dense(128, activation="relu"),
        layers.Dense(10, activation="softmax"),
    ]
)
model.compile(
    optimizer="rmsprop",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"],
)
history_large_model = model.fit(
    train_images,
    train_labels,
    epochs=20,
    batch_size=128,
    validation_split=0.2,
) 
```

现在的训练曲线看起来完全符合预期：模型拟合速度快，在八个 epoch 后开始过拟合（见图 5.15）：

![图片](img/ee06559a951289b0281b92145b0b33a3.png)

图 5.15：具有适当容量的模型的验证损失

注意，虽然对于当前问题来说，使用过度参数化的模型是标准的，但确实存在“过度记忆”容量的问题。如果你的模型一开始就立即开始过拟合，你就知道你的模型太大。以下是一个具有三个中间层，每个层有 2,048 个单元的 MNIST 模型的例子（见图 5.16）：

```py
model = keras.Sequential(
    [
        layers.Dense(2048, activation="relu"),
        layers.Dense(2048, activation="relu"),
        layers.Dense(2048, activation="relu"),
        layers.Dense(10, activation="softmax"),
    ]
)
model.compile(
    optimizer="rmsprop",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"],
)
history_very_large_model = model.fit(
    train_images,
    train_labels,
    epochs=20,
    # When training larger models, you can reduce the batch size to
    # limit memory consumption.
    batch_size=32,
    validation_split=0.2,
) 
```

![图片](img/8fd108e012c8f200180dba277edcbffe.png)

图 5.16：过度模型容量对验证损失的影响

## 提高泛化能力

一旦你的模型显示出一定的泛化能力和过拟合的能力，是时候将你的重点转向最大化泛化。

### 数据集整理

你已经了解到，在深度学习中，泛化能力源于你数据的潜在结构。如果你的数据可以在样本之间平滑插值，那么你将能够训练出一个泛化的深度学习模型。如果你的问题过于嘈杂或本质上离散，比如列表排序，深度学习将无法帮助你。深度学习是曲线拟合，而不是魔法。

因此，确保你使用的是适当的数据库至关重要。在数据收集上投入更多努力和资金，几乎总是比在开发更好的模型上投入相同的资金带来更大的投资回报：

+   确保你有足够的数据。记住，你需要对输入-输出空间进行密集采样。更多的数据将产生更好的模型。有时，一开始看似不可能解决的问题，通过更大的数据集就能解决。

+   最小化标签错误——可视化你的输入以检查异常，并校对你的标签。

+   清理你的数据并处理缺失值（我们将在下一章中介绍）。

+   如果你有很多特征，但你不确定哪些是有用的，那么进行特征选择。

你可以通过 *特征工程* 来提高数据的泛化潜力。对于大多数机器学习问题，*特征工程* 是成功的关键因素。让我们来看看。

### 特征工程

*特征工程* 是一个过程，即利用你对数据以及当前机器学习算法（在这种情况下，是一个神经网络）的知识，通过在数据进入模型之前应用硬编码（非学习）的转换来使算法工作得更好。在许多情况下，期望机器学习模型能够从完全任意的数据中学习是不合理的。数据需要以使模型的工作更容易的方式进行呈现。

让我们来看一个直观的例子。假设你正在尝试开发一个模型，该模型可以接受一个钟表的图像作为输入，并输出一天中的时间（见图 5.17）。如果你选择使用图像的原始像素作为输入数据，那么你将面临一个困难的机器学习问题。你需要一个卷积神经网络来解决它，并且你需要投入相当多的计算资源来训练网络。

![](img/e3a49faf9d2e929985728f44a01d6afb.png)

图 5.17：读取钟表时间的特征工程

但如果你已经从高层次上理解了问题（你理解人类是如何读取钟表面的时间的），那么你可以为机器学习算法提出更好的输入特征：例如，编写一个五行的 Python 脚本来跟踪钟表的黑色指针并输出每个指针尖端的 `(x, y)` 坐标很容易。然后一个简单的机器学习算法可以学会将这些坐标与适当的时间联系起来。

你甚至可以更进一步：进行坐标变换，将 `(x, y)` 坐标表示为以图像中心为极坐标。你的输入将变为每个钟表的指针的角度 `theta`。在这个阶段，你的特征使得问题变得如此简单，以至于不需要机器学习；简单的四舍五入操作和字典查找就足以恢复一天中的大约时间。

这就是特征工程的本质：通过以更简单的方式表达问题来使问题更容易。使潜在流形更平滑、更简单、更有组织。这通常需要深入理解问题。

在深度学习之前，特征工程曾是机器学习工作流程中最重要的一部分，因为经典浅层算法没有足够丰富的假设空间来自动学习有用的特征。你向算法呈现数据的方式对其成功至关重要。例如，在卷积神经网络在 MNIST 数字分类问题中取得成功之前，解决方案通常是基于硬编码的特征，如数字图像中的环数、图像中每个数字的高度、像素值直方图等。

幸运的是，现代深度学习消除了对大多数特征工程的需求，因为神经网络能够自动从原始数据中提取有用的特征。这意味着只要使用深度神经网络，你就不必担心特征工程吗？不，有两个原因：

+   良好的特征仍然允许你在使用更少资源的情况下更优雅地解决问题。例如，使用卷积神经网络来解决读取时钟面的问题将是荒谬的。

+   良好的特征让你可以用更少的数据解决问题。深度学习模型能够自行学习特征的能力依赖于大量可用训练数据；如果你只有少量样本，那么它们特征中的信息价值变得至关重要。

### 使用提前停止

在深度学习中，我们总是使用大量过参数化的模型：它们的自由度远远超过拟合数据潜在流形所需的最小值。这种过参数化并不是问题，因为**你永远不会完全拟合一个深度学习模型**。这样的拟合根本无法泛化。你总是在达到最小可能训练损失之前就中断了训练。

在训练过程中找到你达到最泛化拟合的确切点——即欠拟合曲线和过拟合曲线之间的确切边界——是你可以做的最有效的事情之一，以改善泛化能力。

在上一章的例子中，我们首先会训练我们的模型超过所需时间，以确定产生最佳验证指标的 epoch 数，然后我们会重新训练一个恰好为此数量的 epoch 的新模型。这是相当标准的做法。然而，这需要你做重复性的工作，有时可能会很昂贵。自然地，你可以在每个 epoch 结束时保存你的模型，然后一旦找到最佳 epoch，就重新使用最接近的已保存模型。在 Keras 中，通常使用`EarlyStopping`回调来实现这一点，该回调会在验证指标停止改进时中断训练，同时记住最佳已知模型状态。你将在第七章学习如何使用回调。

### 规范化你的模型

*正则化技术*是一套最佳实践，它积极地阻碍模型完美拟合训练数据的能力，目的是使模型在验证期间表现更好。这被称为“正则化”模型，因为它往往会使模型更简单，更“规则”，其曲线更平滑，更“通用”——因此对训练集更不具体，并且能够通过更接近地逼近数据的潜在流形来更好地泛化。请记住，“正则化”模型是一个应该始终由准确的评估程序指导的过程。只有当你能够衡量它时，你才能实现泛化。

让我们回顾一些最常用的正则化技术，并在实践中应用它们来改进第四章中的电影分类模型。

#### 减小网络的大小

你已经了解到，一个过小的模型不会过拟合。减轻过拟合的最简单方法就是减小模型的大小（模型中可学习的参数数量，由层数和每层的单元数决定）。如果模型有限的记忆资源，它将无法简单地记住其训练数据。为了最小化其损失，它将不得不求助于学习具有预测能力的压缩表示——这正是我们感兴趣的类型。同时，请记住，你应该使用具有足够参数的模型，这样它们就不会欠拟合：你的模型不应该缺乏记忆资源。在“过多容量”和“容量不足”之间需要找到一个折衷方案。

不幸的是，没有神奇的公式可以确定正确的层数或每层的正确大小。你必须评估一系列不同的架构（当然是在你的验证集上，而不是测试集上），以找到适合你数据的正确模型大小。找到适当模型大小的一般工作流程是从相对较少的层和参数开始，增加层的大小或添加新层，直到你在验证损失方面看到收益递减。

让我们在电影评论分类模型上尝试这个。这是第四章中模型的简化版本。

```py
from keras.datasets import imdb

(train_data, train_labels), _ = imdb.load_data(num_words=10000)

def vectorize_sequences(sequences, dimension=10000):
    results = np.zeros((len(sequences), dimension))
    for i, sequence in enumerate(sequences):
        results[i, sequence] = 1.0
    return results

train_data = vectorize_sequences(train_data)

model = keras.Sequential(
    [
        layers.Dense(16, activation="relu"),
        layers.Dense(16, activation="relu"),
        layers.Dense(1, activation="sigmoid"),
    ]
)
model.compile(
    optimizer="rmsprop",
    loss="binary_crossentropy",
    metrics=["accuracy"],
)
history_original = model.fit(
    train_data,
    train_labels,
    epochs=20,
    batch_size=512,
    validation_split=0.4,
) 
```

列表 5.9：原始模型

现在，让我们尝试用这个更小的模型来替换它。

```py
model = keras.Sequential(
    [
        layers.Dense(4, activation="relu"),
        layers.Dense(4, activation="relu"),
        layers.Dense(1, activation="sigmoid"),
    ]
)
model.compile(
    optimizer="rmsprop",
    loss="binary_crossentropy",
    metrics=["accuracy"],
)
history_smaller_model = model.fit(
    train_data,
    train_labels,
    epochs=20,
    batch_size=512,
    validation_split=0.4,
) 
```

列表 5.10：容量较低的模型版本

图 5.18 显示了原始模型和较小模型验证损失的对比。

![图片](img/48aeb1a9a731eaaf0f1bf644071dffc1.png)

图 5.18：IMDb 评论分类中的原始模型与较小模型的比较

如你所见，较小的模型比参考模型更晚开始过拟合（在六次而不是四次迭代后），一旦开始过拟合，其性能下降得更慢。

现在，让我们将一个具有更多容量的模型添加到我们的基准中——远远超过问题所需的容量。

```py
model = keras.Sequential(
    [
        layers.Dense(512, activation="relu"),
        layers.Dense(512, activation="relu"),
        layers.Dense(1, activation="sigmoid"),
    ]
)
model.compile(
    optimizer="rmsprop",
    loss="binary_crossentropy",
    metrics=["accuracy"],
)
history_larger_model = model.fit(
    train_data,
    train_labels,
    epochs=20,
    batch_size=512,
    validation_split=0.4,
) 
```

列表 5.11：具有更高容量的模型版本

图 5.19 展示了较大模型与参考模型相比的表现。较大的模型几乎在一轮训练后就开始过拟合，并且过拟合程度更加严重。其验证损失也更加嘈杂。它迅速将训练损失降至接近零。模型容量越大，它越能快速地建模训练数据（导致训练损失较低），但它对过拟合的敏感性也越高（导致训练损失和验证损失之间差异较大）。

![](img/410a394fb019ca4488992ec6711798ba.png)

图 5.19：IMDB 评论分类中的原始模型与较大模型对比

#### 添加权重正则化

你可能熟悉*奥卡姆剃刀原理*：对于某种事物的两种解释，最可能正确的是最简单的一种——即做出较少假设的那一种。这种想法也适用于神经网络学习到的模型：给定一些训练数据和网络架构，多组权重值（多个*模型*）可以解释数据。简单模型比复杂模型更不容易过拟合。

在这个背景下，*简单模型*是指参数值分布的熵较低（或者与上一节中看到的相比，参数更少的模型）。因此，一种常见的减轻过拟合的方法是通过强制权重只取较小的值来对模型的复杂性施加约束，这使得权重值的分布更加*规则*。这被称为*权重正则化*，它通过向模型的损失函数中添加与权重大的成本相关联的成本来实现。这种成本有两种形式：

+   *L1 正则化* — 添加的成本与权重系数的*绝对值*（权重的*L1 范数*）成比例。

+   *L2 正则化* — 添加的成本与权重系数的*平方值*（权重的*L2 范数*）成比例。在神经网络背景下，L2 正则化也称为*权重衰减*。不要让不同的名称混淆你：权重衰减在数学上与 L2 正则化相同。

在 Keras 中，通过将*权重正则化实例*作为关键字参数传递给层来添加权重正则化。让我们将 L2 权重正则化添加到电影评论分类模型中。

```py
from keras.regularizers import l2

model = keras.Sequential(
    [
        layers.Dense(16, kernel_regularizer=l2(0.002), activation="relu"),
        layers.Dense(16, kernel_regularizer=l2(0.002), activation="relu"),
        layers.Dense(1, activation="sigmoid"),
    ]
)
model.compile(
    optimizer="rmsprop",
    loss="binary_crossentropy",
    metrics=["accuracy"],
)
history_l2_reg = model.fit(
    train_data,
    train_labels,
    epochs=20,
    batch_size=512,
    validation_split=0.4,
) 
```

列表 5.12：将 L2 权重正则化添加到模型中

`l2(0.002)` 表示层中每个权重矩阵的系数都将添加 `0.002 * weight_coefficient_value ** 2` 到模型的总体损失中。请注意，由于这种惩罚*仅在训练时添加*，因此该模型的损失在训练时比测试时高得多。

图 5.20 展示了 L2 正则化惩罚的效果。如您所见，具有 L2 正则化的模型比参考模型对过拟合的抵抗力更强，尽管两个模型具有相同数量的参数：见图 5.20：

![图片](img/a8ba8a378919e7d2c88c940518b94422.png)

图 5.20：L2 权重正则化对验证损失的影响

作为 L2 正则化的替代方案，您可以使用以下 Keras 权重正则化器之一。

```py
from keras import regularizers

# L1 regularization
regularizers.l1(0.001)
# Simultaneous L1 and L2 regularization
regularizers.l1_l2(l1=0.001, l2=0.001) 
```

代码列表 5.13：Keras 中可用的不同权重正则化器

注意，权重正则化通常用于较小的深度学习模型。大型深度学习模型往往过度参数化，对权重值施加约束对模型容量和泛化能力的影响不大。在这些情况下，更倾向于使用不同的正则化技术：*dropout*。

#### 添加 dropout

*Dropout*，由多伦多大学的 Geoffrey Hinton 及其学生开发，是神经网络中最有效且最常用的正则化技术之一。Dropout 在层中的应用包括在训练期间随机 *丢弃*（置零）一定数量的层输出特征。假设一个给定的层在训练期间对于一个给定的输入样本通常会返回一个向量 `[0.2, 0.5, 1.3, 0.8, 1.1]`。在应用 dropout 后，这个向量将会有一些随机分布的零值：例如，`[0, 0.5, 1.3, 0, 1.1]`。*dropout 率* 是被置零的特征的比例；它通常设置在 0.2 到 0.5 之间。在测试时，不丢弃任何单元；相反，层的输出值按 dropout 率的因子进行缩放，以平衡训练时比测试时更活跃的单元数量。

考虑一个包含层输出 `layer_output` 的 NumPy 矩阵，其形状为 `(batch_size, features)`。在训练时，我们随机将矩阵中的一部分值置零：

```py
# At training time, drops out 50% of the units in the output
layer_output *= np.random.randint(low=0, high=2, size=layer_output.shape) 
```

在测试时，我们将输出按 dropout 率进行缩放。这里，我们按 0.5 缩放（因为我们之前丢弃了一半的单元）：

```py
# At test time
layer_output *= 0.5 
```

注意，这个过程可以通过在训练时执行这两个操作，并在测试时保持输出不变来实现，这在实践中通常是这样做的方式（见图 5.21）：

```py
# At training time
layer_output *= np.random.randint(low=0, high=2, size=layer_output.shape)
# Note that we're scaling up rather scaling down in this case.
layer_output /= 0.5 
```

![图片](img/efa2213fd7e01bbc65bc2b5e8326ebaf.png)

图 5.21：在训练时应用于激活矩阵的 dropout，训练过程中进行缩放。在测试时，激活矩阵保持不变。

这种技术可能看起来很奇怪且随意。为什么这有助于减少过拟合？Hinton 表示，他受到了，包括但不限于，银行使用的欺诈预防机制的启发：

> 我去银行。出纳员一直在更换，我询问其中一位为什么。他说他不知道，但他们经常被调动。我想这肯定是因为这需要员工之间的合作才能成功欺诈银行。这让我意识到，在每一个例子中随机移除不同子集的神经元可以防止阴谋，从而减少过拟合。

核心思想是在层的输出值中引入噪声可以打破不重要的偶然模式（Hinton 称之为**阴谋**），如果没有噪声，模型将开始记忆这些模式。

在 Keras 中，你可以通过`Dropout`层在模型中引入 dropout，该层应用于层之前的输出。让我们在 IMDB 模型中添加两个`Dropout`层，看看它们在减少过拟合方面做得如何。

```py
model = keras.Sequential(
    [
        layers.Dense(16, activation="relu"),
        layers.Dropout(0.5),
        layers.Dense(16, activation="relu"),
        layers.Dropout(0.5),
        layers.Dense(1, activation="sigmoid"),
    ]
)
model.compile(
    optimizer="rmsprop",
    loss="binary_crossentropy",
    metrics=["accuracy"],
)
history_dropout = model.fit(
    train_data,
    train_labels,
    epochs=20,
    batch_size=512,
    validation_split=0.4,
) 
```

列表 5.14：在 IMDB 模型中添加 dropout

图 5.22 显示了结果的图表。这比参考模型有明显的改进。它似乎比 L2 正则化工作得更好，因为最低的验证损失已经得到改善：

![](img/e72c698c6b306d49d152835add95f515.png)

图 5.22：dropout 对验证损失的影响

总结一下，这些是在神经网络中最大化泛化并防止过拟合的最常见方法：

+   获取更多或更好的训练数据

+   开发更好的特征

+   降低模型的容量

+   添加权重正则化（适用于较小的模型）

+   添加 dropout

## 摘要

+   机器学习模型的目的在于**泛化**：在从未见过的输入上执行准确。这比看起来要难。

+   深度神经网络通过学习一个可以成功在训练样本之间进行**插值**的参数模型来实现泛化。这样的模型可以说已经学会了训练数据的**潜在流形**。这就是为什么深度学习模型只能理解在训练期间所见到的非常接近的输入。

+   机器学习中的基本问题是**优化与泛化之间的张力**：为了实现泛化，你必须首先对训练数据有一个良好的拟合，但提高你的模型对训练数据的拟合最终会损害泛化。每一个深度学习最佳实践都涉及管理这种张力。

+   深度学习模型能够泛化的能力源于它们能够学会近似其数据的**潜在流形**，因此可以通过插值理解新的输入。

+   在开发模型的过程中，能够准确评估模型的一般化能力至关重要。你可以使用一系列评估方法，从简单的保留验证到 K 折交叉验证和带洗牌的迭代 K 折交叉验证。请记住，始终为最终模型评估保留一个完全独立的测试集，因为你的验证数据可能已经泄露到模型中。

+   当你开始构建模型时，你的目标是首先实现一个具有一定一般化能力且可以过拟合的模型。实现这一目标的最佳实践包括调整学习率和批量大小、使用更好的架构先验、增加模型容量或简单地延长训练时间。

+   当你的模型开始过拟合时，你的目标转变为通过*模型正则化*来提高一般化能力。你可以减少模型容量，添加 dropout 或权重正则化，并使用提前停止。当然，更大的或更好的数据集始终是帮助模型实现一般化的首要方法。

### 脚注

1.  马克·吐温甚至称其为“人类已知最美味的水果。” [[↩]](#footnote-link-1)
