<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Classification and regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1>Classification and regression</h1>
<blockquote>原文：<a href="https://deeplearningwithpython.io/chapters/chapter04_classification-and-regression">https://deeplearningwithpython.io/chapters/chapter04_classification-and-regression</a></blockquote>


<aside>
<p>This chapter covers
</p>
<ul>
<li>Your first examples of real-world machine learning workflows</li>
<li>Handling binary and categorical classification problems</li>
<li>Handling continuous regression problems</li>
</ul>
</aside>

<p>This chapter is designed to get you started with using neural networks to solve
real problems. You’ll consolidate the knowledge you gained from chapters
2 and 3, and you’ll apply what you’ve learned to three
new tasks covering the three most common use cases of neural networks —
binary classification, categorical classification, and scalar regression:</p>
<ul>
<li>Classifying movie reviews as positive or negative (binary classification)</li>
<li>Classifying news wires by topic (categorical classification)</li>
<li>Estimating the price of a house, given real estate data (scalar regression)</li>
</ul>
<p>These examples will be your first contact with end-to-end machine learning
workflows: you’ll get introduced to data preprocessing, basic
model architecture principles, and model evaluation.</p>
<p>By the end of this chapter, you’ll be able to use neural networks to handle
simple classification and regression tasks
over vector data. You’ll then be ready to start building
a more principled, theory-driven understanding of machine learning in chapter 5.</p>
<aside>
<p><span class="note-title">Classification and regression glossary</span></p>
<p>Classification and regression involve many specialized terms. You’ve come
across some of them in earlier examples, and you’ll see more of them in future
chapters. They have precise, machine learning-specific definitions, and you
should be familiar with them:</p>
<ul>
<li><em>Sample or input</em>  —  One data point that goes into your
model.</li>
</ul>
<ul>
<li><em>Prediction or output</em>  —  What comes out of your model.</li>
</ul>
<ul>
<li><em>Target</em>  —  The truth. What your model should ideally have
predicted, according to an external source of data.</li>
</ul>
<ul>
<li><em>Prediction error or loss value</em>  —  A measure of
the distance between your model’s prediction and the target.</li>
</ul>
<ul>
<li><em>Classes</em>  —  A set of possible labels to choose from in a
classification problem. For example, when classifying cat and dog pictures,
“dog” and “cat” are the two classes.</li>
</ul>
<ul>
<li><em>Label</em>  —  A specific instance of a class annotation in a
classification problem. For instance, if picture #1234 is annotated as
containing the class “dog,” then “dog” is a label of picture #1234.</li>
</ul>
<ul>
<li><em>Ground-truth or annotations</em>  —  All targets for a dataset,
typically collected by humans.</li>
</ul>
<ul>
<li><em>Binary classification</em>  —  A classification task
where each input sample should be categorized into two exclusive categories.</li>
</ul>
<ul>
<li><em>Categorical classification or multiclass classification</em>  — 
A classification task where each input sample
should be categorized into more than two categories: for instance, classifying
handwritten digits.</li>
</ul>
<ul>
<li><em>Multilabel classification</em>  —  A classification task where each input
sample can be assigned multiple labels.
For instance, a given image may contain both a cat and a dog and should be
annotated with both the “cat” label and the “dog” label. The number of labels
per image is usually variable.</li>
</ul>
<ul>
<li><em>Scalar regression</em>  —  A task where the target is a
continuous scalar value. Predicting house prices is a good example: the
different target prices form a continuous space.</li>
</ul>
<ul>
<li><em>Vector regression</em>  —  A task where the target is a
set of continuous values: for example, a continuous vector. If you’re doing
regression against multiple values (such as the coordinates of a bounding box
in an image), then you’re doing vector regression.</li>
</ul>
<ul>
<li><em>Mini-batch or just batch</em>  —  A small set of samples
(typically between 8 and 128) that are processed simultaneously by the model.
The number of samples is often a power of 2, to facilitate memory allocation
on GPU. When training, a mini-batch is used to compute a single
gradient-descent update applied to the weights of the model.</li>
</ul>
</aside>

<h2 id="classifying-movie-reviews-a-binary-classification-example">Classifying movie reviews: A binary classification example</h2>
<p>Two-class classification, or binary classification,
is one of the most common kinds of machine learning problem.
In this example, you’ll learn to classify movie reviews as positive
or negative, based on the text content of the reviews.</p>
<h3 id="the-imdb-dataset">The IMDb dataset</h3>
<p>You’ll work with the IMDb dataset: a set of 50,000 highly polarized reviews
from the Internet Movie Database. They’re split into 25,000 reviews for
training and 25,000 reviews for testing, each set consisting of 50% negative
and 50% positive reviews.</p>
<p>Just like the MNIST dataset, the IMDb dataset comes packaged with Keras. It
has already been preprocessed: the reviews (sequences of words) have been
turned into sequences of integers, where each integer stands for a specific
word in a dictionary. This enables us to focus on model building,
training, and evaluation. In chapter 14, you’ll learn how to process raw
text input from scratch.</p>
<p>The following code will load the dataset (when you run it the first time, about
80 MB of data will be downloaded to your machine).</p>
<figure id="listing-4-1">
<pre><code class="language-python">from keras.datasets import imdb

(train_data, train_labels), (test_data, test_labels) = imdb.load_data(
    num_words=10000
)
</code></pre>
<figcaption>
<a href="#listing-4-1">Listing 4.1</a>: Loading the IMDb dataset
</figcaption>
</figure>

<p>The argument <code>num_words=10000</code> means you’ll only keep the top 10,000 most
frequently occurring words in the training data. Rare words will be discarded.
This allows you to work with vector data of manageable size. If we didn’t
set this limit, we’d be working with 88,585 unique words in the training data,
which is unnecessarily large. Many of these words only occur in a single sample,
and thus can’t be meaningfully used for classification.</p>
<p>The variables <code>train_data</code> and <code>test_data</code> are NumPy arrays of reviews; each review is
a list of word indices (encoding a sequence of words). <code>train_labels</code> and
<code>test_labels</code> are NumPy arrays of 0s and 1s, where 0
stands for <em>negative</em> and 1 stands for <em>positive</em>:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; train_data[0]</code>
<code class="language-output">[1, 14, 22, 16, ... 178, 32]</code>
<code class="language-python">&gt;&gt;&gt; train_labels[0]</code>
<code class="language-output">1</code></pre>
</figure>

<p>Because you’re restricting yourself to the top 10,000 most frequent words, no
word index will exceed 10,000:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; max([max(sequence) for sequence in train_data])</code>
<code class="language-output">9999</code></pre>
</figure>

<p>For kicks, let’s quickly decode one of these reviews back to
English words.</p>
<figure id="listing-4-2">
<pre><code class="language-python"># word_index is a dictionary mapping words to an integer index.
word_index = imdb.get_word_index()
# Reverses it, mapping integer indices to words
reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])
# Decodes the review. Note that the indices are offset by 3 because 0,
# 1, and 2 are reserved indices for "padding," "start of sequence," and
# "unknown."
decoded_review = " ".join(
    [reverse_word_index.get(i - 3, "?") for i in train_data[0]]
)
</code></pre>
<figcaption>
<a href="#listing-4-2">Listing 4.2</a>: Decoding reviews back to text
</figcaption>
</figure>

<p>Let’s take a look at what we got:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; decoded_review[:100]</code>
<code class="language-output">? this film was just brilliant casting location scenery story direction everyone</code></pre>
</figure>

<p>Note that the leading <code>?</code> corresponds to a start token that has been prefixed to
each review.</p>
<h3 id="preparing-the-data">Preparing the data</h3>
<p>You can’t directly feed lists of integers into a neural network.
They have all different lengths, while a neural network expects to process
contiguous batches of data. You have to turn your lists into tensors.
There are two ways to do that:</p>
<ul>
<li>Pad your lists so that they all have the same length, then turn them into an
integer tensor of shape <code>(samples, max_length)</code>, and start your model with
a layer capable of handling such integer tensors (the
<code>Embedding</code> layer, which we’ll cover in detail later in the book).</li>
</ul>
<ul>
<li><em>Multi-hot encode</em> your lists to turn them into vectors of 0s and 1s
reflecting the presence or absence of all possible words. This would mean, for
instance, turning the sequence <code>[8, 5]</code> into a 10,000-dimensional vector that
would be all 0s except for indices 5 and 8, which would be 1s.</li>
</ul>
<p>Let’s go with the latter solution to vectorize the data. When done manually,
the process looks like the following.</p>
<figure id="listing-4-3">
<pre><code class="language-python">import numpy as np

def multi_hot_encode(sequences, num_classes):
    # Creates an all-zero matrix of shape (len(sequences), num_classes)
    results = np.zeros((len(sequences), num_classes))
    for i, sequence in enumerate(sequences):
        # Sets specific indices of results[i] to 1s
        results[i][sequence] = 1.0
    return results

# Vectorized training data
x_train = multi_hot_encode(train_data, num_classes=10000)
# Vectorized test data
x_test = multi_hot_encode(test_data, num_classes=10000)
</code></pre>
<figcaption>
<a href="#listing-4-3">Listing 4.3</a>: Encoding the integer sequences via multi-hot encoding
</figcaption>
</figure>

<p>Here’s what the samples look like now:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; x_train[0]</code>
<code class="language-output">array([ 0.,  1.,  1., ...,  0.,  0.,  0.])</code></pre>
</figure>

<p>In addition to vectorizing the input sequences,
you should also vectorize their labels, which is straightforward. Our labels
are already NumPy arrays, so just convert the type from ints to floats:</p>
<figure>
<pre><code class="language-python">y_train = train_labels.astype("float32")
y_test = test_labels.astype("float32")
</code></pre>
</figure>

<p>Now the data is ready to be fed into a neural network.</p>
<h3 id="building-your-model">Building your model</h3>
<p>The input data is vectors, and the labels are scalars (1s and 0s): this is one
of the simplest problem setups you’ll ever encounter.
A type of model that performs well on such a problem is a plain stack of
densely connected (<code>Dense</code>) layers with <code>relu</code> activations.</p>
<p>There are two key architecture decisions to be made about such a stack of
<code>Dense</code> layers:</p>
<ul>
<li>How many layers to use</li>
<li>How many units to choose for each layer</li>
</ul>
<p>In chapter 5, you’ll learn formal principles to guide you in making these
choices. For the time being, you’ll have to trust us with the following
architecture choice:</p>
<ul>
<li>Two intermediate layers with 16 units each</li>
<li>A third layer that will output the scalar prediction regarding the sentiment
of the current review</li>
</ul>
<p>Figure 4.1 shows what the model looks like. Here’s the Keras
implementation, similar to the MNIST example you saw previously.</p>
<figure id="listing-4-4">
<pre><code class="language-python">import keras
from keras import layers

model = keras.Sequential(
    [
        layers.Dense(16, activation="relu"),
        layers.Dense(16, activation="relu"),
        layers.Dense(1, activation="sigmoid"),
    ]
)
</code></pre>
<figcaption>
<a href="#listing-4-4">Listing 4.4</a>: Model definition
</figcaption>
</figure>

<figure id="figure-4-1">
<img src="../Images/68f662b777d64b6a3aabdcb729b94ca2.png" data-original-src="https://deeplearningwithpython.io/images/ch04/3_layer_network.cf1b1cd7.png"/>
<figcaption>
<a href="#figure-4-1">Figure 4.1</a>: The three-layer model
</figcaption>
</figure>

<p>The first argument being passed to each <code>Dense</code> layer is the number
of <em>units</em> in the layer: the dimensionality of representation space of the layer.
You remember from chapters 2 and 3 that each
such <code>Dense</code> layer with a <code>relu</code> activation implements the
following chain of tensor operations:</p>
<figure>
<pre><code class="language-python">output = relu(dot(input, W) + b)
</code></pre>
</figure>

<p>Having 16 units means the weight matrix <code>W</code> will have shape
<code>(input_dimension, 16)</code>: the dot product with <code>W</code> will project the input data
onto a 16-dimensional representation space (and then you’ll add the bias
vector <code>b</code> and apply the <code>relu</code> operation). You can intuitively understand the
dimensionality of your representation space as “how much freedom you’re
allowing the model to have when learning internal representations.” Having
more units (a higher-dimensional representation space) allows your
model to learn more complex representations, but it makes the model more
computationally expensive and may lead to learning unwanted patterns (patterns
that will improve performance on the training data but not on the test data).</p>
<p>The intermediate layers use <code>relu</code> as their activation function, and the
final layer uses a sigmoid activation to output a probability (a
score between 0 and 1, indicating how likely the review is to be positive). A <code>relu</code> (rectified linear
unit) is a function meant to zero-out
negative values (see figure 4.2), whereas a sigmoid “squashes” arbitrary
values into the <code>[0, 1]</code> interval (see figure 4.3), outputting something that
can be interpreted as a probability.</p>
<figure id="figure-4-2" class="extra-small-image">
<img src="../Images/49a10336cc1638ad3a5a3adc18dfac80.png" data-original-src="https://deeplearningwithpython.io/images/ch04/The-rectified-linear-unit-function.351095bf.png"/>
<figcaption>
<a href="#figure-4-2">Figure 4.2</a>: The rectified linear unit function
</figcaption>
</figure>

<figure id="figure-4-3" class="extra-small-image">
<img src="../Images/94ee06bdd6e5edf30361b37018c9c9b6.png" data-original-src="https://deeplearningwithpython.io/images/ch04/The-sigmoid-function.eac1368d.png"/>
<figcaption>
<a href="#figure-4-3">Figure 4.3</a>: The sigmoid function
</figcaption>
</figure>

<aside>
<p><span class="note-title">What are activation functions, and why are they necessary?</span></p>
<p>Without an activation function like <code>relu</code> (also called a <em>non-linearity</em>),
the <code>Dense</code> layer would consist of two linear operations — a dot product and
an addition:</p>
<figure>
<pre><code class="language-python">output = dot(input, W) + b
</code></pre>
</figure>

<p>So the layer could only learn <em>linear transformations</em> (affine transformations) of the input data: the
<em>hypothesis space</em> of the layer would be the set of all possible
linear transformations of the input data into a 16-dimensional space.
Such a hypothesis space is too restricted
and wouldn’t benefit from multiple layers of representations because a deep
stack of linear layers would still implement a linear operation: adding more
layers wouldn’t extend the hypothesis space (as you saw in chapter 2).</p>
<p>To get access to a much richer hypothesis space that would benefit
from deep representations, you need a non-linearity or activation function.
<code>relu</code> is the most popular activation function in deep learning, but there are
many other candidates, which all come with similarly strange names: <code>prelu</code>,
<code>elu</code>, and so on.</p>
</aside>

<p>Finally, you need to choose a loss function and an optimizer. Because you’re
facing a binary classification problem and the output of your model is a
probability (you end your model with a single-unit layer with a sigmoid
activation), it’s best to use the
<code>binary_crossentropy</code> loss. It isn’t the only viable choice: you could use,
for instance, <code>mean_squared_error</code>. But crossentropy
is usually the best choice when you’re dealing with models that output
probabilities. <em>Crossentropy</em> is a quantity from the field
of information theory that measures the distance between probability
distributions or, in this case, between the ground-truth distribution and your
predictions.</p>
<p>As for the choice of the optimizer, we’ll go with <code>adam</code>, which is usually
a good default choice for virtually any problem.</p>
<p>Here’s the step where you configure the model with the <code>adam</code> optimizer and
the <code>binary_crossentropy</code> loss function. Note that
you’ll also monitor accuracy during training.</p>
<figure id="listing-4-5">
<pre><code class="language-python">model.compile(
    optimizer="adam",
    loss="binary_crossentropy",
    metrics=["accuracy"],
)
</code></pre>
<figcaption>
<a href="#listing-4-5">Listing 4.5</a>: Compiling the model
</figcaption>
</figure>

<h3 id="validating-your-approach">Validating your approach</h3>
<p>As you learned in chapter 3, a deep learning model should never be evaluated
on its training data — it’s standard practice to use a “validation set”
to monitor the accuracy of the model during training. Here, you’ll create a
validation set by setting apart 10,000 samples from the original training data.</p>
<p>You might ask, why not simply use the <em>test</em> data to evaluate the model? That seems like
it would be easier. The reason is that you’re going to want to use the results you
get on the validation set to inform your next choices to improve training —
for instance, your choice of what model size to use or how many epochs to train for.
When you start doing this,
your validation scores stop being an accurate reflection of the performance of the model
on brand-new data, since the model has been deliberately modified to perform better on the
validation data. It’s good to keep around a set of never-before-seen samples that you can
use to perform the final evaluation round in a completely unbiased way,
and that’s exactly what the test set is. We’ll talk more about this in the next chapter.</p>
<figure id="listing-4-6">
<pre><code class="language-python">x_val = x_train[:10000]
partial_x_train = x_train[10000:]
y_val = y_train[:10000]
partial_y_train = y_train[10000:]
</code></pre>
<figcaption>
<a href="#listing-4-6">Listing 4.6</a>: Setting aside a validation set
</figcaption>
</figure>

<p>You’ll now train the model for 20 epochs (20 iterations over all samples in the
training data), in mini-batches of 512 samples. At the same
time, you’ll monitor loss and accuracy on the 10,000 samples that you set
apart. You do so by passing the validation data as the <code>validation_data</code> argument
to <code>model.fit()</code>.</p>
<figure id="listing-4-7">
<pre><code class="language-python">history = model.fit(
    partial_x_train,
    partial_y_train,
    epochs=20,
    batch_size=512,
    validation_data=(x_val, y_val),
)
</code></pre>
<figcaption>
<a href="#listing-4-7">Listing 4.7</a>: Training your model
</figcaption>
</figure>

<aside>
<p><span class="note-title">The <code>validation_split</code> argument</span></p>
<p>Instead of manually splitting out validation data from your training data
and passing it as the <code>validation_data</code> argument, you can also use
the <code>validation_split</code> argument in <code>fit()</code>. It specifies a fraction of
the training data to use as validation data, like this:</p>
<figure>
<pre><code class="language-python">history = model.fit(
    x_train,
    y_train,
    epochs=20,
    batch_size=512,
    validation_split=0.2,
)
</code></pre>
</figure>

<p>In this example, 20% of the samples in the <code>x_train</code> and <code>y_train</code> arrays
are being held out from training and used as validation data.</p>
</aside>

<p>On CPU, this will take less than 2 seconds per epoch — training is over in 20
seconds. At the end of every epoch, there is a slight pause as the model
computes its loss and accuracy on the 10,000 samples of the validation data.</p>
<p>Note that the call to <code>model.fit()</code> returns a <code>History</code> object, as you’ve seen
in chapter 3. This object has a member <code>history</code>, which is a
dictionary containing data about everything that happened during training.
Let’s look at it:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; history_dict = history.history
&gt;&gt;&gt; history_dict.keys()</code>
<code class="language-output">dict_keys(["accuracy", "loss", "val_accuracy", "val_loss"])</code></pre>
</figure>

<p>The dictionary contains four entries: one per metric that was being monitored
during training and during validation. In the following two listings, let’s use
Matplotlib to plot the training and validation loss
side by side (see figure 4.4), as well as the training and validation accuracy
(see figure 4.5). Note that your own results may vary slightly due to a
different random initialization of your model.</p>
<figure id="listing-4-8">
<pre><code class="language-python">import matplotlib.pyplot as plt

history_dict = history.history
loss_values = history_dict["loss"]
val_loss_values = history_dict["val_loss"]
epochs = range(1, len(loss_values) + 1)
# "r--" is for "dashed red line."
plt.plot(epochs, loss_values, "r--", label="Training loss")
# "b" is for "solid blue line."
plt.plot(epochs, val_loss_values, "b", label="Validation loss")
plt.title("[IMDB] Training and validation loss")
plt.xlabel("Epochs")
plt.xticks(epochs)
plt.ylabel("Loss")
plt.legend()
plt.show()
</code></pre>
<figcaption>
<a href="#listing-4-8">Listing 4.8</a>: Plotting the training and validation loss
</figcaption>
</figure>

<figure id="figure-4-4">
<img src="../Images/4250e81cf571d19717642a9c2078b966.png" data-original-src="https://deeplearningwithpython.io/images/ch04/imdb_loss_plot.801b28d0.png"/>
<figcaption>
<a href="#figure-4-4">Figure 4.4</a>: Training and validation loss
</figcaption>
</figure>

<figure id="listing-4-9">
<pre><code class="language-python"># Clears the figure
plt.clf()
acc = history_dict["accuracy"]
val_acc = history_dict["val_accuracy"]
plt.plot(epochs, acc, "r--", label="Training acc")
plt.plot(epochs, val_acc, "b", label="Validation acc")
plt.title("[IMDB] Training and validation accuracy")
plt.xlabel("Epochs")
plt.xticks(epochs)
plt.ylabel("Accuracy")
plt.legend()
plt.show()
</code></pre>
<figcaption>
<a href="#listing-4-9">Listing 4.9</a>: Plotting the training and validation accuracy
</figcaption>
</figure>

<figure id="figure-4-5">
<img src="../Images/360b66ab70d2777c93c1bd914592906d.png" data-original-src="https://deeplearningwithpython.io/images/ch04/imdb_accuracy_plot.bf0cb7ef.png"/>
<figcaption>
<a href="#figure-4-5">Figure 4.5</a>: Training and validation accuracy
</figcaption>
</figure>

<p>As you can see, the training loss decreases with every epoch, and the training
accuracy increases with every epoch. That’s what you would expect when running
gradient-descent optimization — the quantity you’re trying to minimize should be
less with every iteration. But that isn’t the case for the validation loss and
accuracy: they seem to peak at the fourth epoch. This is an example of what we
warned against earlier: a model that performs better on the training data
isn’t necessarily a model that will do better on data it has never seen
before. In precise terms, what you’re seeing is <em>overfitting</em>: after the
fourth epoch, you’re overoptimizing on the training data, and you end up
learning representations that are specific to the training data and don’t
generalize to data outside of the training set.</p>
<p>In this case, to prevent overfitting, you could stop training after four
epochs. In general, you can use a range of techniques to mitigate overfitting,
which we’ll cover in chapter 5.</p>
<p>Let’s train a new model from scratch for four epochs and then
evaluate it on the test data.</p>
<figure id="listing-4-10">
<pre><code class="language-python">model = keras.Sequential(
    [
        layers.Dense(16, activation="relu"),
        layers.Dense(16, activation="relu"),
        layers.Dense(1, activation="sigmoid"),
    ]
)
model.compile(
    optimizer="adam",
    loss="binary_crossentropy",
    metrics=["accuracy"],
)
model.fit(x_train, y_train, epochs=4, batch_size=512)
results = model.evaluate(x_test, y_test)
</code></pre>
<figcaption>
<a href="#listing-4-10">Listing 4.10</a>: Training the model for four epochs
</figcaption>
</figure>

<p>The final results are as follows:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; results</code>
<code class="language-output"># The first number, 0.29, is the test loss, and the second number,
# 0.88, is the test accuracy.
[0.2929924130630493, 0.88327999999999995]</code></pre>
</figure>

<p>This fairly naive approach achieves an accuracy of 88%. With state-of-the-art
approaches, you should be able to get close to 95%.</p>
<h3 id="using-a-trained-model-to-generate-predictions-on-new-data">Using a trained model to generate predictions on new data</h3>
<p>After having trained a model, you’ll want to use it in a practical setting.
You can generate the likelihood of reviews being positive by using
the <code>predict</code> method, as you’ve learned in chapter 3:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; model.predict(x_test)</code>
<code class="language-output">array([[ 0.98006207]
       [ 0.99758697]
       [ 0.99975556]
       ...,
       [ 0.82167041]
       [ 0.02885115]
       [ 0.65371346]], dtype=float32)</code></pre>
</figure>

<p>As you can see, the model is confident for some samples (0.99 or more, or
0.01 or less) but less confident for others (0.6, 0.4).</p>
<h3 id="further-experiments">Further experiments</h3>
<p>The following experiments will help convince you that the architecture choices
you’ve made are all fairly reasonable, although there’s still room for
improvement:</p>
<ul>
<li>You used two representation layers before the final classification layer.
Try using one or three representation layers and see how doing so affects validation and test accuracy.</li>
</ul>
<ul>
<li>Try using layers with more units or fewer units: 32 units,
64 units, and so on.</li>
</ul>
<ul>
<li>Try using the <code>mean_squared_error</code> loss function instead of
<code>binary_crossentropy</code>.</li>
</ul>
<ul>
<li>Try using the <code>tanh</code> activation (an activation that was
popular in the early days of neural networks) instead of <code>relu</code>.</li>
</ul>
<h3 id="wrapping-up">Wrapping up</h3>
<p>Here’s what you should take away from this example:</p>
<ul>
<li>You usually need to do quite a bit of preprocessing on your raw data
to be able to feed it — as tensors — into a neural network.
Sequences of words can be encoded as binary vectors, but there are other
encoding options, too.</li>
</ul>
<ul>
<li>Stacks of <code>Dense</code> layers with <code>relu</code> activations can solve a wide range of
problems (including sentiment classification), and you’ll use them
frequently.</li>
</ul>
<ul>
<li>In a binary classification problem (two output classes),
your model should end with a <code>Dense</code> layer with one unit and a <code>sigmoid</code>
activation: the output of your model should be a scalar between 0 and 1,
encoding a probability.</li>
</ul>
<ul>
<li>With such a scalar sigmoid output on a binary classification problem, the
loss function you should use is <code>binary_crossentropy</code>.</li>
</ul>
<ul>
<li>The <code>adam</code> optimizer is generally a good enough
choice, whatever your problem. That’s one less thing for you to worry about.</li>
</ul>
<ul>
<li>As they get better on their training data, neural networks eventually start
overfitting and end up obtaining increasingly worse results on data they’ve
never seen before. Be sure to always monitor performance on data that is
outside of the training set!</li>
</ul>
<h2 id="classifying-newswires-a-multiclass-classification-example">Classifying newswires: A multiclass classification example</h2>
<p>In the previous section, you saw how to classify vector inputs into
two mutually exclusive classes using a densely connected neural network.
But what happens when you have more than two classes?</p>
<p>In this section, you’ll build a model to classify Reuters newswires into 46
mutually exclusive topics. Because you have many classes, this problem is an
instance of <em>multiclass classification</em>, and because each data point should be
classified into only one category, the problem is more specifically an
instance of <em>single-label</em>,
<em>multiclass classification</em>. If each data point could belong to multiple
categories (in this case, topics), you’d be facing a <em>multilabel</em>,
<em>multiclass classification</em> problem.</p>
<h3 id="the-reuters-dataset">The Reuters dataset</h3>
<p>You’ll work with the Reuters dataset, a set of short newswires and their
topics, published by Reuters in 1986. It’s a simple, widely used toy dataset
for text classification. There are 46 different topics; some topics are more
represented than others, but each topic has at least 10 examples in the
training set.</p>
<p>Like IMDb and MNIST, the Reuters dataset comes packaged as part of Keras. Let’s
take a look.</p>
<figure id="listing-4-11">
<pre><code class="language-python">from keras.datasets import reuters

(train_data, train_labels), (test_data, test_labels) = reuters.load_data(
    num_words=10000
)
</code></pre>
<figcaption>
<a href="#listing-4-11">Listing 4.11</a>: Loading the Reuters dataset
</figcaption>
</figure>

<p>As with the IMDb dataset, the argument <code>num_words=10000</code> restricts the data to
the 10,000 most frequently occurring words found in the data.</p>
<p>You have 8,982 training examples and 2,246 test examples:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; len(train_data)</code>
<code class="language-output">8982</code>
<code class="language-python">&gt;&gt;&gt; len(test_data)</code>
<code class="language-output">2246</code></pre>
</figure>

<p>As with the IMDb reviews, each example is a list of integers (word indices):</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; train_data[10]</code>
<code class="language-output">[1, 245, 273, 207, 156, 53, 74, 160, 26, 14, 46, 296, 26, 39, 74, 2979,
3554, 14, 46, 4689, 4329, 86, 61, 3499, 4795, 14, 61, 451, 4329, 17, 12]</code></pre>
</figure>

<p>Here’s how you can decode it back to words, in case you’re curious.</p>
<figure id="listing-4-12">
<pre><code class="language-python">word_index = reuters.get_word_index()
reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])
decoded_newswire = " ".join(
    # The indices are offset by 3 because 0, 1, and 2 are reserved
    # indices for "padding," "start of sequence," and "unknown."
    [reverse_word_index.get(i - 3, "?") for i in train_data[10]]
)
</code></pre>
<figcaption>
<a href="#listing-4-12">Listing 4.12</a>: Decoding newswires back to text
</figcaption>
</figure>

<p>The label associated with an example is an integer between 0 and 45 — a topic
index:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; train_labels[10]</code>
<code class="language-output">3</code></pre>
</figure>

<h3 id="preparing-the-data_1">Preparing the data</h3>
<p>You can vectorize the data with the exact same code as in the previous example.</p>
<figure id="listing-4-13">
<pre><code class="language-python"># Vectorized training data
x_train = multi_hot_encode(train_data, num_classes=10000)
# Vectorized test data
x_test = multi_hot_encode(test_data, num_classes=10000)
</code></pre>
<figcaption>
<a href="#listing-4-13">Listing 4.13</a>: Encoding the input data
</figcaption>
</figure>

<p>To vectorize the labels, there are two possibilities: you can leave the labels
untouched as integers, or you can use <em>one-hot encoding</em>. One-hot encoding
is a widely used format for categorical data, also called <em>categorical encoding</em>.
In this case, one-hot encoding of the labels consists of embedding each label as
an all-zero vector with a 1 in the place of the label index. Here’s an example.</p>
<figure id="listing-4-14">
<pre><code class="language-python">def one_hot_encode(labels, num_classes=46):
    results = np.zeros((len(labels), num_classes))
    for i, label in enumerate(labels):
        results[i, label] = 1.0
    return results

# Vectorized training labels
y_train = one_hot_encode(train_labels)
# Vectorized test labels
y_test = one_hot_encode(test_labels)
</code></pre>
<figcaption>
<a href="#listing-4-14">Listing 4.14</a>: Encoding the labels
</figcaption>
</figure>

<p>Note that there is a built-in way to do this in Keras:</p>
<figure>
<pre><code class="language-python">from keras.utils import to_categorical

y_train = to_categorical(train_labels)
y_test = to_categorical(test_labels)
</code></pre>
</figure>

<h3 id="building-your-model_1">Building your model</h3>
<p>This topic classification problem looks similar to the previous movie review
classification problem: in both cases, you’re trying to classify short
snippets of text. But there is a new constraint here: the number of output
classes has gone from 2 to 46. The dimensionality of the output space is much
larger.</p>
<p>In a stack of <code>Dense</code> layers like those you’ve been using, each layer can only
access information present in the output of the previous layer. If one layer
drops some information relevant to the classification problem, this
information can never be recovered by later layers: each layer can potentially
become an information bottleneck. In the previous
example, you used 16-dimensional intermediate layers, but a 16-dimensional
space may be too limited to learn to separate 46 different classes: such small
layers may act as information bottlenecks, permanently dropping relevant
information.</p>
<p>For this reason, you’ll use larger intermediate layers. Let’s go with 64 units.</p>
<figure id="listing-4-15">
<pre><code class="language-python">model = keras.Sequential(
    [
        layers.Dense(64, activation="relu"),
        layers.Dense(64, activation="relu"),
        layers.Dense(46, activation="softmax"),
    ]
)
</code></pre>
<figcaption>
<a href="#listing-4-15">Listing 4.15</a>: Model definition
</figcaption>
</figure>

<p>There are two other things you should note about this architecture:</p>
<ul>
<li>You end the model with a <code>Dense</code> layer of size 46. This means for each input
   sample, the network will output a 46-dimensional vector. Each entry in this
   vector (each dimension) will encode a different output class.</li>
</ul>
<ul>
<li>The last layer uses a <code>softmax</code> activation. You saw this pattern
   in the MNIST example. It means the model will output a <em>probability
   distribution</em> over the 46 different output
   classes — for every input sample, the model will produce a 46-dimensional
   output vector, where <code>output[i]</code> is the probability that the sample belongs to
   class <code>i</code>. The 46 scores will sum to 1.</li>
</ul>
<p>The best loss function to use in this case is <code>categorical_crossentropy</code>. It
measures the distance between two
probability distributions — here, between the probability distribution outputted
by the model and the true distribution of the labels. By minimizing the
distance between these two distributions, you train the model to output
something as close as possible to the true labels.</p>
<p>Like last time, we’ll also monitor accuracy. However, accuracy is a bit of a crude metric
in this case: if the model has the correct class as its second choice for a given sample,
with an incorrect first choice, the model will still have an accuracy of zero on that sample
— even though such a model would be much better than a random guess.
A more nuanced metric in this case is top-k accuracy, such as top-3 or top-5 accuracy. It measures
whether the correct class was among the top-k predictions of the model. Let’s add top-3 accuracy
to our model.</p>
<figure id="listing-4-16">
<pre><code class="language-python">top_3_accuracy = keras.metrics.TopKCategoricalAccuracy(
    k=3, name="top_3_accuracy"
)
model.compile(
    optimizer="adam",
    loss="categorical_crossentropy",
    metrics=["accuracy", top_3_accuracy],
)
</code></pre>
<figcaption>
<a href="#listing-4-16">Listing 4.16</a>: Compiling the model
</figcaption>
</figure>

<h3 id="validating-your-approach_1">Validating your approach</h3>
<p>Let’s set apart 1,000 samples in the training data to use as a validation set.</p>
<figure id="listing-4-17">
<pre><code class="language-python">x_val = x_train[:1000]
partial_x_train = x_train[1000:]
y_val = y_train[:1000]
partial_y_train = y_train[1000:]
</code></pre>
<figcaption>
<a href="#listing-4-17">Listing 4.17</a>: Setting aside a validation set
</figcaption>
</figure>

<p>Now, let’s train the model for 20 epochs.</p>
<figure id="listing-4-18">
<pre><code class="language-python">history = model.fit(
    partial_x_train,
    partial_y_train,
    epochs=20,
    batch_size=512,
    validation_data=(x_val, y_val),
)
</code></pre>
<figcaption>
<a href="#listing-4-18">Listing 4.18</a>: Training the model
</figcaption>
</figure>

<p>And finally, let’s display its loss and accuracy curves (see figures 4.6 and
4.7).</p>
<figure id="listing-4-19">
<pre><code class="language-python">loss = history.history["loss"]
val_loss = history.history["val_loss"]
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, "r--", label="Training loss")
plt.plot(epochs, val_loss, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.xlabel("Epochs")
plt.xticks(epochs)
plt.ylabel("Loss")
plt.legend()
plt.show()
</code></pre>
<figcaption>
<a href="#listing-4-19">Listing 4.19</a>: Plotting the training and validation loss
</figcaption>
</figure>

<figure id="figure-4-6">
<img src="../Images/700f48941826f86c77529d558bb444c4.png" data-original-src="https://deeplearningwithpython.io/images/ch04/reuters_loss_plot.6e487e1a.png"/>
<figcaption>
<a href="#figure-4-6">Figure 4.6</a>: Training and validation loss
</figcaption>
</figure>

<figure id="listing-4-20">
<pre><code class="language-python">plt.clf()
acc = history.history["accuracy"]
val_acc = history.history["val_accuracy"]
plt.plot(epochs, acc, "r--", label="Training accuracy")
plt.plot(epochs, val_acc, "b", label="Validation accuracy")
plt.title("Training and validation accuracy")
plt.xlabel("Epochs")
plt.xticks(epochs)
plt.ylabel("Accuracy")
plt.legend()
plt.show()
</code></pre>
<figcaption>
<a href="#listing-4-20">Listing 4.20</a>: Plotting the training and validation top-3 accuracy
</figcaption>
</figure>

<figure id="figure-4-7">
<img src="../Images/1fca6a813a775f4369c4651c43e4b471.png" data-original-src="https://deeplearningwithpython.io/images/ch04/reuters_accuracy_plot.b74dee12.png"/>
<figcaption>
<a href="#figure-4-7">Figure 4.7</a>: Training and validation accuracy
</figcaption>
</figure>

<figure id="listing-4-21">
<pre><code class="language-python">plt.clf()
acc = history.history["top_3_accuracy"]
val_acc = history.history["val_top_3_accuracy"]
plt.plot(epochs, acc, "r--", label="Training top-3 accuracy")
plt.plot(epochs, val_acc, "b", label="Validation top-3 accuracy")
plt.title("Training and validation top-3 accuracy")
plt.xlabel("Epochs")
plt.xticks(epochs)
plt.ylabel("Top-3 accuracy")
plt.legend()
plt.show()
</code></pre>
<figcaption>
<a href="#listing-4-21">Listing 4.21</a>: Plotting the training and validation top-3 accuracy
</figcaption>
</figure>

<figure id="figure-4-8">
<img src="../Images/a76873d2f26e20d65d983d713807a26a.png" data-original-src="https://deeplearningwithpython.io/images/ch04/reuters_top_3_accuracy_plot.a9e13ec0.png"/>
<figcaption>
<a href="#figure-4-8">Figure 4.8</a>: Training and validation accuracy
</figcaption>
</figure>

<p>The model begins to overfit after nine epochs. Let’s train a new model
from scratch for nine epochs and then evaluate it on the test set.</p>
<figure id="listing-4-22">
<pre><code class="language-python">model = keras.Sequential(
    [
        layers.Dense(64, activation="relu"),
        layers.Dense(64, activation="relu"),
        layers.Dense(46, activation="softmax"),
    ]
)
model.compile(
    optimizer="adam",
    loss="categorical_crossentropy",
    metrics=["accuracy"],
)
model.fit(
    x_train,
    y_train,
    epochs=9,
    batch_size=512,
)
results = model.evaluate(x_test, y_test)
</code></pre>
<figcaption>
<a href="#listing-4-22">Listing 4.22</a>: Retraining a model from scratch
</figcaption>
</figure>

<p>Here are the final results:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; results</code>
<code class="language-output">[0.9565213431445807, 0.79697239536954589]</code></pre>
</figure>

<p>This approach reaches an accuracy of approximately 80%. With a balanced binary
classification problem, the accuracy reached by a purely random classifier
would be 50%. But in this case, we have 46 classes, and they may not be
equally represented. What would be the accuracy of a random baseline? We could
try quickly implementing one to check this empirically:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; import copy
&gt;&gt;&gt; test_labels_copy = copy.copy(test_labels)
&gt;&gt;&gt; np.random.shuffle(test_labels_copy)
&gt;&gt;&gt; hits_array = np.array(test_labels == test_labels_copy)
&gt;&gt;&gt; hits_array.mean()</code>
<code class="language-output">0.18655387355298308</code></pre>
</figure>

<p>As you can see, a random classifier would score around 19% classification
accuracy, so the results of our model seem pretty good in that light.</p>
<h3 id="generating-predictions-on-new-data">Generating predictions on new data</h3>
<p>Calling the model’s <code>predict</code> method on new samples
returns a class probability distribution over all 46 topics for each sample.
Let’s generate topic predictions for all of the test data:</p>
<figure>
<pre><code class="language-python">predictions = model.predict(x_test)
</code></pre>
</figure>

<p>Each entry in “predictions” is a vector of length 46:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; predictions[0].shape</code>
<code class="language-output">(46,)</code></pre>
</figure>

<p>The coefficients in this vector sum to 1, as they form a
probability distribution:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; np.sum(predictions[0])</code>
<code class="language-output">1.0</code></pre>
</figure>

<p>The largest entry is the predicted class —
the class with the highest probability:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; np.argmax(predictions[0])</code>
<code class="language-output">4</code></pre>
</figure>

<h3 id="a-different-way-to-handle-the-labels-and-the-loss">A different way to handle the labels and the loss</h3>
<p>We mentioned earlier that another way to encode the labels would be to leave
them untouched as integer tensors, like this:</p>
<figure>
<pre><code class="language-python">y_train = train_labels
y_test = test_labels
</code></pre>
</figure>

<p>The only thing this approach would change is the choice of the loss function.
The loss function used in listing 4.22, <code>categorical_crossentropy</code>, expects
the labels to follow a categorical
encoding. With integer labels, you should
use <code>sparse_categorical_crossentropy</code>:</p>
<figure>
<pre><code class="language-python">model.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"],
)
</code></pre>
</figure>

<p>This new loss function is still mathematically the same as
<code>categorical_crossentropy</code>; it just has a different interface.</p>
<h3 id="the-importance-of-having-sufficiently-large-intermediate-layers">The importance of having sufficiently large intermediate layers</h3>
<p>We mentioned earlier that because the final outputs are 46-dimensional, you
should avoid intermediate layers with much fewer than 46 units. Now
let’s see what happens when you introduce an information bottleneck by having
intermediate layers that are significantly less than 46-dimensional: for
example, 4-dimensional.</p>
<figure id="listing-4-23">
<pre><code class="language-python">model = keras.Sequential(
    [
        layers.Dense(64, activation="relu"),
        layers.Dense(4, activation="relu"),
        layers.Dense(46, activation="softmax"),
    ]
)
model.compile(
    optimizer="adam",
    loss="categorical_crossentropy",
    metrics=["accuracy"],
)
model.fit(
    partial_x_train,
    partial_y_train,
    epochs=20,
    batch_size=128,
    validation_data=(x_val, y_val),
)
</code></pre>
<figcaption>
<a href="#listing-4-23">Listing 4.23</a>: A model with an information bottleneck
</figcaption>
</figure>

<p>The model now peaks at approximately 71% validation accuracy, an 8% absolute drop. This
drop is mostly due to the fact that you’re trying to compress a lot of
information (enough information to recover the separation hyperplanes of 46
classes) into an intermediate space that is too low-dimensional. The model
is able to cram <em>most</em> of the necessary information into these
4-dimensional representations, but not all of it.</p>
<h3 id="further-experiments_1">Further experiments</h3>
<p>Like in the previous example, we encourage you to try out the following experiments to
train your intuition about the kind of configuration decisions you have to make with
such models:</p>
<ul>
<li>Try using larger or smaller layers: 32 units, 128 units, and so on.</li>
<li>You used two intermediate layers before the final softmax classification layer.
  Now try using a single intermediate layer, or three intermediate layers.</li>
</ul>
<h3 id="wrapping-up_1">Wrapping up</h3>
<p>Here’s what you should take away from this example:</p>
<ul>
<li>If you’re trying to classify data points among <em>N</em> classes,
  your model should end with a <code>Dense</code> layer of size <em>N</em>.</li>
</ul>
<ul>
<li>In a single-label, multiclass classification problem, your model should end
  with a <code>softmax</code> activation so that it will output a probability
  distribution over the <em>N</em> output classes.</li>
</ul>
<ul>
<li>Categorical crossentropy is almost always the loss function you should use
  for such problems. It minimizes the distance between the probability
  distributions output by the model and the true distribution of the targets.</li>
</ul>
<ul>
<li>There are two ways to handle labels in multiclass classification:<ul>
<li>Encoding the labels via categorical encoding
(also known as one-hot encoding) and using <code>categorical_crossentropy</code> as a
loss function</li>
<li>Encoding the labels as integers and using the
  <code>sparse_categorical_crossentropy</code> loss function</li>
</ul>
</li>
</ul>
<ul>
<li>If you need to classify data into a large number of categories, you should
  avoid creating information bottlenecks in your
  model due to intermediate layers that are too small.</li>
</ul>
<h2 id="predicting-house-prices-a-regression-example">Predicting house prices: A regression example</h2>
<p>The two previous examples were considered classification
problems, where the goal was to predict a single discrete label of an input
data point. Another common type of machine learning problem is <em>regression</em>,
which consists of predicting a continuous value instead of a discrete label:
for instance, predicting the temperature tomorrow given meteorological data,
or predicting the time that a software project will take to complete given
its specifications.</p>
<aside>
<p>Confusingly, logistic regression isn’t a regression algorithm —
it’s a classification algorithm.</p>
</aside>

<h3 id="the-california-housing-price-dataset">The California Housing Price dataset</h3>
<p>You’ll attempt to predict the median price of homes in different areas of California,
based on data from the 1990 census.</p>
<p>Each data point in the dataset represents information about a “block group,”
a group of homes located in the same area. You can think of it as a district.
This dataset has two versions, the “small” version with just 600 districts,
and the “large” version with 20,640 districts. Let’s use the small version,
because real-world datasets can often be tiny, and you need to know how to handle such cases.</p>
<p>For each district, we know</p>
<ul>
<li>The longitude and latitude of the approximate geographic center of the area.</li>
<li>The median age of houses in the district.</li>
<li>The population of the district. The districts are pretty small: the average population is 1,425.5.</li>
<li>The total number of households.</li>
<li>The median income of those households.</li>
<li>The total number of rooms in the district, across all homes located there. This is typically in the low thousands.</li>
<li>The total number of bedrooms in the district.</li>
</ul>
<p>That’s eight variables in total (longitude and latitude count as two variables).
The goal is to use these variables to predict the median value of the houses in the district.
Let’s get started by loading the data.</p>
<figure id="listing-4-24">
<pre><code class="language-python">from keras.datasets import california_housing

# Make sure to pass version="small" to get the right dataset.
(train_data, train_targets), (test_data, test_targets) = (
    california_housing.load_data(version="small")
)
</code></pre>
<figcaption>
<a href="#listing-4-24">Listing 4.24</a>: Loading the California Housing Prices dataset
</figcaption>
</figure>

<p>Let’s look at the data:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; train_data.shape</code>
<code class="language-output">(480, 8)</code>
<code class="language-python">&gt;&gt;&gt; test_data.shape</code>
<code class="language-output">(120, 8)</code></pre>
</figure>

<p>As you can see, we have 480 training samples and 120 test samples, each with
8 numerical features. The targets are the median values of homes in the district considered,
in dollars:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; train_targets</code>
<code class="language-output">array([252300., 146900., 290900., ..., 140500., 217100.],
      dtype=float32)</code></pre>
</figure>

<p>The prices are between $60,000 and $500,000. If that sounds cheap,
remember that this was in 1990, and these prices aren’t adjusted for
inflation.</p>
<h3 id="preparing-the-data_2">Preparing the data</h3>
<p>It would be problematic to feed into a neural network values that all take
wildly different ranges. The model might be able to automatically adapt to
such heterogeneous data, but it would definitely make learning more difficult.
A widespread best practice to deal with such data is to do feature-wise
normalization: for each feature in the input data (a column in the input data
matrix), you subtract the mean of the feature and divide by the standard
deviation, so that the feature is centered around 0 and has a unit standard
deviation. This is easily done in NumPy.</p>
<figure id="listing-4-25">
<pre><code class="language-python">mean = train_data.mean(axis=0)
std = train_data.std(axis=0)
x_train = (train_data - mean) / std
x_test = (test_data - mean) / std
</code></pre>
<figcaption>
<a href="#listing-4-25">Listing 4.25</a>: Normalizing the data
</figcaption>
</figure>

<p>Note that the quantities used for normalizing the test data are computed using
the training data. You should never use in your workflow any quantity computed
on the test data, even for something as simple as data normalization.</p>
<p>In addition, we should also scale the targets. Our normalized inputs
have their value in a small range close to 0, and our model’s weights are
initialized with small random values. This means that our model’s prediction
will also be small values when we start training.
If the targets are in the range
60,000–500,000, the model is going to need very large weight values to output those.
With a small learning rate, it would take a very long time to get there. The simplest fix
is to divide all target values by 100,000, so that the smallest target becomes 0.6, and the largest
becomes 5. We can then convert the model’s predictions back to dollar values by multiplying
them by 100,000 accordingly.</p>
<figure id="listing-4-26">
<pre><code class="language-python">y_train = train_targets / 100000
y_test = test_targets / 100000
</code></pre>
<figcaption>
<a href="#listing-4-26">Listing 4.26</a>: Scaling the targets
</figcaption>
</figure>

<h3 id="building-your-model_2">Building your model</h3>
<p>Because so few samples are available, you’ll use a very small model with two
intermediate layers, each with 64 units. In general, the less training data you
have, the worse overfitting will be, and using a small model is one way to
mitigate overfitting.</p>
<figure id="listing-4-27">
<pre><code class="language-python">def get_model():
    # Because you need to instantiate the same model multiple times,
    # you use a function to construct it.
    model = keras.Sequential(
        [
            layers.Dense(64, activation="relu"),
            layers.Dense(64, activation="relu"),
            layers.Dense(1),
        ]
    )
    model.compile(
        optimizer="adam",
        loss="mean_squared_error",
        metrics=["mean_absolute_error"],
    )
    return model
</code></pre>
<figcaption>
<a href="#listing-4-27">Listing 4.27</a>: Model definition
</figcaption>
</figure>

<p>The model ends with a single unit and no activation: it will be a linear
layer. This is a typical setup for scalar regression
 — a regression where you’re trying to predict a single continuous value.
Applying an activation function would constrain the
range the output can take; for instance, if you applied a <code>sigmoid</code> activation
function to the last layer, the model could only learn to predict values
between 0 and 1. Here, because the last layer is purely linear, the model is
free to learn to predict values in any range.</p>
<p>Note that you compile the model with the <code>mean_squared_error</code>
loss function  —  <em>mean squared error</em>, the square of the difference between the
predictions and the targets. This is a widely used loss function for
regression problems.</p>
<p>You’re also monitoring a new metric during training: <em>mean absolute error</em>
(MAE). It’s the absolute value of the difference between the predictions and
the targets. For instance, an MAE of 0.5 on this problem would mean your
predictions are off by $50,000 on average (remember the target scaling of factor 100,000).</p>
<h3 id="validating-your-approach-using-k-fold-validation">Validating your approach using K-fold validation</h3>
<p>To evaluate your model while you keep adjusting its parameters (such as the
number of epochs used for training), you could split the data into a training
set and a validation set, as you did in the previous examples. But because you
have so few data points, the validation set would end up being very small (for
instance, about 100 examples). As a consequence, the validation scores might
change a lot depending on which data points you chose to use for validation
and which you chose for training: the validation scores might have a high
<em>variance</em> with regard to the validation split. This would prevent you from
reliably evaluating your model.</p>
<p>The best practice in such situations is to use <em>K-fold</em> cross-validation (see
figure 4.9). It consists of splitting the available data into <em>K</em> partitions
(typically <em>K</em> = 4 or 5), instantiating <em>K</em> identical models, and training
each one on <em>K</em> – 1 partitions while evaluating on the remaining partition.
The validation score for the model used is then the average of the <em>K</em>
validation scores obtained. In terms of code, this is straightforward.</p>
<figure id="figure-4-9">
<img src="../Images/bb6a837d8d083d01576c5920aa7ca957.png" data-original-src="https://deeplearningwithpython.io/images/ch04/3-fold-cross-validation.40bb5356.png"/>
<figcaption>
<a href="#figure-4-9">Figure 4.9</a>: Three-fold cross-validation
</figcaption>
</figure>

<figure id="listing-4-28">
<pre><code class="language-python">k = 4
num_val_samples = len(x_train) // k
num_epochs = 50
all_scores = []
for i in range(k):
    print(f"Processing fold #{i + 1}")
    # Prepares the validation data: data from partition #k
    fold_x_val = x_train[i * num_val_samples : (i + 1) * num_val_samples]
    fold_y_val = y_train[i * num_val_samples : (i + 1) * num_val_samples]
    # Prepares the training data: data from all other partitions
    fold_x_train = np.concatenate(
        [x_train[: i * num_val_samples], x_train[(i + 1) * num_val_samples :]],
        axis=0,
    )
    fold_y_train = np.concatenate(
        [y_train[: i * num_val_samples], y_train[(i + 1) * num_val_samples :]],
        axis=0,
    )
    # Builds the Keras model (already compiled)
    model = get_model()
    # Trains the model
    model.fit(
        fold_x_train,
        fold_y_train,
        epochs=num_epochs,
        batch_size=16,
        verbose=0,
    )
    # Evaluates the model on the validation data
    scores = model.evaluate(fold_x_val, fold_y_val, verbose=0)
    val_loss, val_mae = scores
    all_scores.append(val_mae)
</code></pre>
<figcaption>
<a href="#listing-4-28">Listing 4.28</a>: K-fold validation
</figcaption>
</figure>

<p>Running this with <code>num_epochs = 50</code> yields the following results:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; [round(value, 3) for value in all_scores]</code>
<code class="language-output">[0.298, 0.349, 0.232, 0.305]</code>
<code class="language-python">&gt;&gt;&gt; round(np.mean(all_scores), 3)</code>
<code class="language-output">0.296</code></pre>
</figure>

<p>The different runs do indeed show meaningfully different validation scores,
from 0.232 to 0.349. The average (0.296) is a much more reliable metric than any single
score — that’s the entire point of K-fold cross-validation. In this case, you’re
off by $29,600 on average, which is significant considering that the prices
range from $60,000 to $500,000.</p>
<p>Let’s try training the model a bit longer: 200 epochs. To keep a record of
how well the model does at each epoch, you’ll modify the training loop to save
the per-epoch validation score log.</p>
<figure id="listing-4-29">
<pre><code class="language-python">k = 4
num_val_samples = len(x_train) // k
num_epochs = 200
all_mae_histories = []
for i in range(k):
    print(f"Processing fold #{i + 1}")
    # Prepares the validation data: data from partition #k
    fold_x_val = x_train[i * num_val_samples : (i + 1) * num_val_samples]
    fold_y_val = y_train[i * num_val_samples : (i + 1) * num_val_samples]
    # Prepares the training data: data from all other partitions
    fold_x_train = np.concatenate(
        [x_train[: i * num_val_samples], x_train[(i + 1) * num_val_samples :]],
        axis=0,
    )
    fold_y_train = np.concatenate(
        [y_train[: i * num_val_samples], y_train[(i + 1) * num_val_samples :]],
        axis=0,
    )
    # Builds the Keras model (already compiled)
    model = get_model()
    # Trains the model
    history = model.fit(
        fold_x_train,
        fold_y_train,
        validation_data=(fold_x_val, fold_y_val),
        epochs=num_epochs,
        batch_size=16,
        verbose=0,
    )
    mae_history = history.history["val_mean_absolute_error"]
    all_mae_histories.append(mae_history)
</code></pre>
<figcaption>
<a href="#listing-4-29">Listing 4.29</a>: Saving the validation logs at each fold
</figcaption>
</figure>

<p>You can then compute the average of the per-epoch mean absolute error (MAE) scores for all folds.</p>
<figure id="listing-4-30">
<pre><code class="language-python">average_mae_history = [
    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)
]
</code></pre>
<figcaption>
<a href="#listing-4-30">Listing 4.30</a>: Building the history of successive mean K-fold validation scores
</figcaption>
</figure>

<p>Let’s plot this; see figure 4.10.</p>
<figure id="listing-4-31">
<pre><code class="language-python">epochs = range(1, len(average_mae_history) + 1)
plt.plot(epochs, average_mae_history)
plt.xlabel("Epochs")
plt.ylabel("Validation MAE")
plt.show()
</code></pre>
<figcaption>
<a href="#listing-4-31">Listing 4.31</a>: Plotting validation scores
</figcaption>
</figure>

<figure id="figure-4-10">
<img src="../Images/3a62bf8f25afa58de847c1fe58574fe5.png" data-original-src="https://deeplearningwithpython.io/images/ch04/california_housing_validation_mae_plot.af306c57.png"/>
<figcaption>
<a href="#figure-4-10">Figure 4.10</a>: Validation MAE by epoch
</figcaption>
</figure>

<p>It may be a little difficult to read the plot due to a scaling issue: the
validation MAE for the first few epochs is dramatically higher than the values
that follow. Let’s omit the first 10 data points,
which are on a different scale than the rest of the curve.</p>
<figure id="listing-4-32">
<pre><code class="language-python">truncated_mae_history = average_mae_history[10:]
epochs = range(10, len(truncated_mae_history) + 10)
plt.plot(epochs, truncated_mae_history)
plt.xlabel("Epochs")
plt.ylabel("Validation MAE")
plt.show()
</code></pre>
<figcaption>
<a href="#listing-4-32">Listing 4.32</a>: Plotting validation scores, excluding the first 10 data points
</figcaption>
</figure>

<figure id="figure-4-11">
<img src="../Images/e5f84d5faf3a31c710e45f85a1a04052.png" data-original-src="https://deeplearningwithpython.io/images/ch04/california_housing_validation_mae_plot_zoomed.928f390d.png"/>
<figcaption>
<a href="#figure-4-11">Figure 4.11</a>: Validation MAE by epoch, excluding the first 10 data points
</figcaption>
</figure>

<p>According to this plot (see figure 4.11), validation MAE stops improving significantly after 120–140
epochs (this number includes the 10 epochs we omitted).
Past that point, you start overfitting.</p>
<p>Once you’re finished tuning other parameters of the model (in addition to the
number of epochs, you could also adjust the size of the intermediate layers),
you can train a final production model on all of the training data, with the best
parameters, and then look at its performance on the test data.</p>
<figure id="listing-4-33">
<pre><code class="language-python"># Gets a fresh, compiled model
model = get_model()
# Trains it on the entirety of the data
model.fit(x_train, y_train, epochs=130, batch_size=16, verbose=0)
test_mean_squared_error, test_mean_absolute_error = model.evaluate(
    x_test, y_test
)
</code></pre>
<figcaption>
<a href="#listing-4-33">Listing 4.33</a>: Training the final model
</figcaption>
</figure>

<p>Here’s the final result:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; round(test_mean_absolute_error, 3)</code>
<code class="language-output">0.31</code></pre>
</figure>

<p>We’re still off by about $31,000 on average.</p>
<h3 id="generating-predictions-on-new-data_1">Generating predictions on new data</h3>
<p>When calling <code>predict()</code> on our binary classification model, we retrieved
a scalar score between 0 and 1 for each input sample. With our multiclass
classification model, we retrieved a probability distribution over all classes
for each sample. Now, with this scalar regression model, <code>predict()</code> returns
the model’s guess for the sample’s price in hundreds of thousands of dollars:</p>
<figure>
<pre><code class="language-python">&gt;&gt;&gt; predictions = model.predict(x_test)
&gt;&gt;&gt; predictions[0]</code>
<code class="language-output">array([2.834494], dtype=float32)</code></pre>
</figure>

<p>The first district in the test set is predicted to have an average home price of about $283,000.</p>
<h3 id="wrapping-up_2">Wrapping up</h3>
<p>Here’s what you should take away from this scalar regression example:</p>
<ul>
<li>Regression is done using a different loss function than what we used for
  classification. Mean squared error (MSE) is a loss function
  commonly used for regression.</li>
</ul>
<ul>
<li>Similarly, evaluation metrics to be used for regression differ from those
  used for classification; naturally, the concept of accuracy doesn’t apply for
  regression. A common regression metric is MAE.</li>
</ul>
<ul>
<li>When features in the input data have values in different ranges, each feature
  should be scaled independently as a preprocessing step.</li>
</ul>
<ul>
<li>When there is little data available, using K-fold validation is a great way
  to reliably evaluate a model.</li>
</ul>
<ul>
<li>When little training data is available, it’s preferable to use a small
  model with few intermediate layers (typically only one or two), in order to avoid
  severe overfitting.</li>
</ul>
<h2 id="summary">Summary</h2>
<ul>
<li>The three most common kinds of machine learning tasks on
  vector data are binary classification, multiclass classification, and scalar
  regression. Each task uses different loss functions:<ul>
<li><code>binary_crossentropy</code> for binary classification</li>
<li><code>categorical_crossentropy</code> for multiclass classification</li>
<li><code>mean_squared_error</code> for scalar regression</li>
</ul>
</li>
</ul>
<ul>
<li>You’ll usually need to preprocess raw data before feeding it into a neural
  network.</li>
</ul>
<ul>
<li>When your data has features with different ranges, scale each feature
  independently as part of preprocessing.</li>
</ul>
<ul>
<li>As training progresses, neural networks eventually begin to overfit and
  obtain worse results on never-before-seen data.</li>
</ul>
<ul>
<li>If you don’t have much training data, use a small model with only one or
  two intermediate layers, to avoid severe overfitting.</li>
</ul>
<ul>
<li>If your data is divided into many categories, you may cause information
  bottlenecks if you make the intermediate layers too small.</li>
</ul>
<ul>
<li>When you’re working with little data, K-fold validation can help reliably
  evaluate your model.</li>
</ul>
    
</body>
</html>