- en: 7 Genetic algorithms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs: []
  type: TYPE_NORMAL
- en: Introducing population-based optimization algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding evolutionary computation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the different components of genetic algorithms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing genetic algorithms in Python
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suppose you’re on a treasure-hunting mission and you don’t want the risk of
    searching alone and returning empty-handed. You might decide to collaborate with
    a group of friends and share information. This approach follows a population-based
    search strategy, where multiple agents are involved in the search process.
  prefs: []
  type: TYPE_NORMAL
- en: During this collaborative effort, you may notice that some hunters perform better
    than others. In this case, you may choose to retain only the best-performing hunters
    and replace the less competent ones with new recruits. This process resembles
    the workings of evolutionary algorithms such as genetic algorithms, where the
    fittest individuals survive and pass on their traits to the next generation.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, the binary-coded genetic algorithm is presented and discussed
    as an evolutionary computing algorithm. We’ll look at different elements of this
    algorithm and at the implementation details. Other variants of genetic algorithms,
    such as the gray-coded genetic algorithm, real-valued genetic algorithm, and permutation-based
    genetic algorithm will be discussed in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1 Population-based metaheuristic algorithms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Population-based metaheuristic algorithms (P-metaheuristics), such as genetic
    algorithms, particle swarm optimization, and ant colony optimization, utilize
    multiple agents to search for an optimal or near-optimal global solution. As these
    algorithms begin with a diverse set of initial populations, they are naturally
    more exploration-based, allowing for the possibility of finding better solutions
    that might be missed by trajectory-based (S-metaheuristic) algorithms, which are
    more exploitation-based.
  prefs: []
  type: TYPE_NORMAL
- en: 'Population-based metaheuristic algorithms can be classified into two main categories
    based on their source of inspiration: *evolutionary computation algorithms* and
    *swarm intelligence algorithms*, as shown in figure 7.1.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F01_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 Metaheuristic algorithms
  prefs: []
  type: TYPE_NORMAL
- en: Evolutionary computation (EC) algorithms, as the name suggests, are inspired
    by the process of biological evolution. These algorithms use a population of potential
    solutions, which undergo genetic operations, such as mutation and crossover, to
    create new offspring that may have better fitness values. The process of selection
    determines which individuals in the population are selected to reproduce and create
    the next generation. Genetic algorithm (GA), differential evolution (DE), genetic
    programming (GP), evolutionary programming (EP), evolutionary strategies (ES),
    cultural algorithms (CA), and co-evolution (CoE) are examples of evolutionary
    computation algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Swarm intelligence (SI) algorithms, on the other hand, are inspired by the collective
    behavior of social organisms such as ants, bees, and birds, and they’ll be discussed
    in part 4 of this book. These algorithms use a population of agents that interact
    with each other to find a solution. They use a variety of mechanisms, such as
    communication, cooperation, and self-organization, to optimize the search process.
    Examples of swarm intelligence algorithms include particle swarm optimization
    (PSO), ant colony optimization (ACO), artificial bee colony (ABC), the firefly
    algorithm (FA), the bat algorithm (BA), and the wolf search algorithm (WSA).
  prefs: []
  type: TYPE_NORMAL
- en: Both evolutionary computation and swarm intelligence algorithms are population-based
    algorithms that begin their search for the optimal or near-optimal solution from
    an initial population of candidate solutions. The quality and diversity of the
    initial population significantly influences the performance and efficiency of
    the algorithm. A well-constructed initial population provides a good starting
    point for the search process and can help the algorithm quickly converge toward
    a promising region of the search space. In contrast, a poorly constructed initial
    population may result in a premature convergence to a suboptimal solution, may
    get the algorithm stuck in a suboptimal region, or may take longer to converge
    toward a solution. To ensure a good balance between exploration and exploitation,
    the initial population should be diverse and cover a wide range of potential solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'A comparison between different initialization strategies for population-based
    metaheuristics is provided in El-Ghazali Talbi’s *Metaheuristics: From Design
    to Implementation* [1], based on three key aspects: diversity, computational cost,
    and the quality of initial solutions. Initial solutions can be generated using
    a pseudo-random process or a quasi-random search. Initial solutions can also be
    generated sequentially (sequential diversification) or concurrently (parallel
    diversification) to achieve very high diversity. Heuristics involve using local
    search or greedy methods to generate initial solutions.'
  prefs: []
  type: TYPE_NORMAL
- en: As shown in table 7.1, a pseudo-random strategy provides moderate diversity,
    low computational cost, and low-quality initial solutions. A quasi-random strategy
    exhibits higher diversity with comparable computational cost and low-quality initial
    solutions. Sequential diversification and parallel diversification both stand
    out with very high diversity, but the former incurs moderate computational cost,
    while the latter has low computational cost; both methods result in low-quality
    initial solutions. In contrast, the use of heuristics, such as local search or
    a greedy heuristic, yields high-quality initial solutions but with low diversity
    and high computational cost.
  prefs: []
  type: TYPE_NORMAL
- en: Table 7.1 Initialization strategies for population-based metaheuristics
  prefs: []
  type: TYPE_NORMAL
- en: '| Initialization strategy | Diversity | Computational cost | Quality of initial
    solution |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Pseudo-random | Moderate | Low | Low |'
  prefs: []
  type: TYPE_TB
- en: '| Quasi-random | High | Low | Low |'
  prefs: []
  type: TYPE_TB
- en: '| Sequential diversification | Very high | Moderate | Low |'
  prefs: []
  type: TYPE_TB
- en: '| Parallel diversification | Very high | Low | Low |'
  prefs: []
  type: TYPE_TB
- en: '| Heuristics (e.g., local search or greedy heuristic) | Low | High | High |'
  prefs: []
  type: TYPE_TB
- en: It is often beneficial to use a randomized approach to generate the initial
    population, where the candidates are samples from different regions of the search
    space to maximize the chances of finding the optimal solution. The next listing
    shows how we can sample initial solutions using Python. Let’s start by generating
    200 pseudo-random numbers.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.1 Generating initial populations in Python
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: ① Set a seed for the random number generator.
  prefs: []
  type: TYPE_NORMAL
- en: ② Number of samples
  prefs: []
  type: TYPE_NORMAL
- en: ③ Pseudo-random sampling
  prefs: []
  type: TYPE_NORMAL
- en: Note Random numbers are inherently unpredictable, pseudo-random numbers are
    deterministic but appear random, and quasi-random numbers are deterministic with
    evenly distributed patterns.
  prefs: []
  type: TYPE_NORMAL
- en: 'The generalized Halton number generator in the ghalton library can be used
    to generate quasi-random numbers. This method is based on the Halton sequence,
    which uses coprime numbers as its bases. You can use the generalized Halton number
    generator as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The Box-Muller transform is used to generate pairs of independent, standard,
    normally distributed random numbers from pairs of uniformly distributed random
    numbers. Box-Muller is a 2D Gaussian sampling method that can be used as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: ① Generate uniformly distributed values between 0 and 1.
  prefs: []
  type: TYPE_NORMAL
- en: ② Calculate x and y values using Box-Muller.
  prefs: []
  type: TYPE_NORMAL
- en: One of the drawbacks of the Box-Muller transform is its tendency to cluster
    values around the mean due to its dependency on uniform distribution. Additionally,
    calculating the square root can be costly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Central limit theorem (CLT) sampling is another sampling method where the distribution
    of the sample means approximates a normal distribution as the sample size gets
    larger, regardless of the population’s distribution. The following code snippet
    shows how to implement this method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'The Sobol low-discrepancy sequence (LDS) is a quasi-random sampling method
    available in the sobol_seq package. This method generates a sequence of points
    that are evenly spaced and distributed throughout the sample space, such that
    the gaps between adjacent points are as small as possible. It can be used as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Latin hypercube sampling is a parallel diversification method where the search
    space is decomposed into 25 blocks, and a solution is generated pseudo-randomly
    in each block. An example of using the Latin hybercube sampling method in the
    pyDOE (Design of Experiments) Python package is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s visualize all of these sampling methods so we can get a good sense of
    the differences between them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Running this code generates the plots shown in figure 7.2\. In this figure,
    candidate solutions have been sampled from a feasible search space using various
    sampling methods, with each point representing a different solution. The level
    of diversity achieved by each sampling method can be evaluated by observing the
    gaps between the points and their dispersion.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F02_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 Sampling methods for generating an initial population
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned in appendix A (see liveBook), there are several Python packages
    for evolutionary computation. In this chapter, we will focus on using pymoo: multi-objective
    optimization in Python. Pymoo provides different sampling methods for creating
    an initial population or an initial search point. Examples include random sampling
    and Latin hypercube sampling. As a continuation of listing 7.1, the following
    code snippet shows random sampling in pymoo:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: ① Import an instance of the problem class.
  prefs: []
  type: TYPE_NORMAL
- en: ② Import the random sampling method.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Import the visualization method.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Create a problem with two variables, and specify the lower and upper bounds.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Create an instance of the random sampler.
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Generate 200 random solutions/individuals.
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Visualize the generated individuals.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code generates and visualizes 200 initial solutions using Latin
    hypercube sampling:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: ① Import the Latin hypercube sampling module.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the solutions take the form of permutations, random permutations can be
    generated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: ① Randomly permute a sequence, or return a permuted range.
  prefs: []
  type: TYPE_NORMAL
- en: ② Randomly shuffle a sequence.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Population of the initial solution as real-value permutations
  prefs: []
  type: TYPE_NORMAL
- en: ④ Population of the initial solution as binary permutations with the number
    of bits in the binary string and the number of ones in each binary string
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also generate a random route between two points using the following
    code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: ① This is a typical graph search with a shuffled frontier.
  prefs: []
  type: TYPE_NORMAL
- en: ② This is the randomization part.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Generate random routes between two nodes.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Visualize the random routes.
  prefs: []
  type: TYPE_NORMAL
- en: The preceding code modifies a typical graph search algorithm by scrambling the
    frontier nodes. This means that candidates for expansion are “random,” which means
    different routes are yielded when it’s called repeatedly. Some generated random
    routes are shown in figure 7.3.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F03_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.3 Generating random initial routes
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, I’ll introduce evolutionary computation as population-based
    metaheuristics.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2 Introducing evolutionary computation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Evolution can be considered an optimization process in the sense that it involves
    the gradual improvement of the characteristics of living organisms over time,
    resulting in adaptation to dynamically changing and competitive environments and
    an enhanced ability to survive in these environments. In this section, I’ll provide
    an overview of the fundamental concepts of biological evolution. Understanding
    these principles is important for gaining insight into evolutionary computation.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2.1 A brief recap of biology fundamentals
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The *nucleus* is the central part of any living cell that contains the genetic
    information. This genetic information is stored in the *chromosomes*, each of
    which is built of deoxyribonucleic acid (DNA), which carries the genetic information
    used in the growth, development, functioning, and reproduction of all living organisms.
    Humans have a total of 23 pairs of chromosomes, or 46 chromosomes in total, in
    each of their cells. Each chromosome is made up of many different sections called
    *genes*, which are responsible for coding specific properties of an individual.
    The variant form of a gene that determines these properties, found at a specific
    location on a chromosome, is called an allele. Every gene has a unique position
    on the chromosome called a *locus*. The entire combination of genes is called
    a *genotype*, and it’s the genotype that provides the genetic blueprint for an
    organism, determining the potential for an individual’s traits and characteristics.
    The term *phenotype* refers to the observable physical, behavioral, and physiological
    characteristics of an organism, which result from the interaction between its
    genotype and the environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'To illustrate the concept of genes and their role in determining the characteristics
    of a living organism, let’s consider an example where a DNA molecule consists
    of four genes that are responsible for different traits: appetite, movement, feet,
    and skin type. The appetite gene may have different values that reflect the diet
    of the organism, such as herbivore (H), carnivore (C), or insectivore (I). The
    movement gene may determine the organism’s mode of movement, such as climbing
    (CL), flying (FL), running (R), or swimming (SW). The feet gene may determine
    the type of feet or limbs that the organism has, such as claws (CLW), flippers
    (FLP), hooves (HV), or wings (WNG). Finally, the skin gene may determine the skin
    covering of the organism, such as fur (F), scales (S), or feathers (FTH), as illustrated
    in figure 7.4.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F04_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.4 Genotype, phenotype, and taxonomic classification
  prefs: []
  type: TYPE_NORMAL
- en: In this example, the *genotype* refers to the specific genetic makeup of an
    organism, which is determined by the specific combination of alleles that an individual
    inherits from its parents. The specific values of these genes will determine the
    *phenotype*, or observable characteristics, of the organism. For example, an organism
    with an insectivore appetite gene, a flying movement gene, a wings feet gene,
    and a feather skin gene would likely be a bird. On the other hand, an organism
    with an herbivorous appetite gene, a running movement gene, a hooves feet gene,
    and a fur skin gene would likely be a mammal, such as a white-tailed deer.
  prefs: []
  type: TYPE_NORMAL
- en: The class to which an organism belongs, such as the species, genus, or family,
    is determined by its taxonomic classification based on shared characteristics
    with other organisms.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2.2 The theory of evolution
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The theory of evolution explains how species of living organisms have changed
    over time and diversified into the forms we see today. This theory, developed
    by Charles Darwin, offers an explanation of biological diversity and its underlying
    mechanisms.
  prefs: []
  type: TYPE_NORMAL
- en: 'According to the theory, *natural selection* is a major mechanism that drives
    evolution. Over the course of numerous generations, adaptations arise from the
    cumulative effects of successive, minor, stochastic alterations in traits, and
    natural selection favors those variants that are best suited to their environment.
    This phenomenon is known as survival of the fittest: selected individuals reproduce,
    passing their properties to their offspring. Other individuals die without mating,
    and their properties are thus discarded. Over time, natural selection plays a
    significant role in shaping the characteristics and adaptations of populations,
    promoting the transmission of advantageous traits and eliminating less beneficial
    ones.'
  prefs: []
  type: TYPE_NORMAL
- en: The theory of evolution
  prefs: []
  type: TYPE_NORMAL
- en: 'The theory of evolution by natural selection can be summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: In a world with limited resources and stable populations, each individual competes
    with others for survival.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Those individuals with the “best” characteristics (traits) are more likely to
    survive and to reproduce, and those characteristics will be passed on to their
    offspring.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These desirable characteristics are inherited by subsequent generations, and
    (over time) become dominant among the population.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: During production of a child organism, random events cause random changes to
    the child organism’s characteristics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If these new characteristics are a benefit to the organism, the chances of survival
    for that organism are increased.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Evolutionary computation techniques mimic biological evolution and process a
    sequence of operations, such as creating an initial population (a collection of
    chromosomes), evaluating the population, and then evolving the population through
    multiple generations.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2.3 Evolutionary computation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Computational intelligence* (CI) is a subfield of artificial intelligence
    (AI) that emphasizes the design, application, and development of algorithms that
    can learn and adapt to solve complex problems. It focuses on soft computing methods
    such as fuzzy logic, neural networks, evolutionary computation, and swarm intelligence.
    *Evolutionary computation* (EC), as a branch of CI, employs various computational
    methods inspired by biological evolution. These methods have computational mechanisms
    of natural selection, survival of the fittest, and reproduction as the core elements
    of their computational systems.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generally speaking, EC algorithms consist of the following main components:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Population of individuals*—This is a set of candidate solutions that are initially
    generated randomly or by some heuristic methods and are then improved over time.
    The population size is usually large in order to explore a wide range of possible
    solutions to the problem. However, the optimal population size depends on various
    factors, such as the complexity of the problem, the number of variables in the
    problem, the required accuracy of the solution, and the computational resources
    available. In practice, the optimal population size is often determined through
    experimentation, with the performance of the algorithm being evaluated for different
    population sizes and the best performing size being selected.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Fitness function*—This function evaluates the quality of candidate solutions.
    It determines how well each solution solves the given problem by assigning a fitness
    value to each individual in the population. The higher the fitness value, the
    better the solution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Parent selection method*—This method is used to select the most promising
    individuals from the population in order to create new offspring for the next
    generation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Genetic operators*—These operators include *crossover* and *mutation*, and
    they are used to create new offspring from selected parents. The crossover operator
    exchanges genetic material between two selected individuals to create new offspring
    with a combination of traits from both parents. The mutation operator introduces
    random changes to the offspring’s genetic makeup to add diversity to the population
    and prevent stagnation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Survival methods*—These methods determine which individuals in a population
    will survive to the next generation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Together, these five components form the basis of EC algorithms, which can effectively
    solve various optimization problems. As illustrated in figure 7.5, there are several
    EC paradigms.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F05_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.5 EC paradigms
  prefs: []
  type: TYPE_NORMAL
- en: 'These paradigms mainly vary in their approaches to representing individuals,
    parents, survival selection methods, and genetic operators:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Genetic algorithm (GA)*—This search algorithm mimics natural evolution, where
    each individual is a candidate solution encoded as a binary, real-valued, or permutation
    vector. We will discuss genetic algorithms in detail in this part of the book.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Differential evolution (DE)*—This algorithm uses real-valued vectors as individuals
    and generates new solutions by adding weighted differences between pairs of existing
    solutions. It is similar to GA, differing in the reproduction mechanism used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Genetic programming (GP)*—This is a special case of GA, where each individual
    is a computer program encoded as a variable-length tree. This tree structure is
    used to represent functions and operators, such as `if`-`else` statements and
    mathematical operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Evolutionary programming (EP)*—This is similar to GP, but it focuses on evolving
    behavioral traits rather than program structure. It is an open framework where
    any representation and mutation operation can be applied, but there is no recombination.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Evolutionary strategies (ES)*—This algorithm uses real-valued vectors as individuals
    and adapts mutation and recombination parameters during evolution. Plus-selection,
    comma-selection, greedy selection, and distance-based selection are used as selection
    methods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Cultural algorithm (CA)*—This approach incorporates social learning from a
    shared belief space into the traditional population-based evolution process. CA
    models the evolution of a population’s culture and how it influences the genetic
    and phenotypic evolution of individuals.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Co-evolution (CoE)*—This is based on the reciprocal evolutionary change that
    occurs between interacting populations, where each represents a given species,
    together optimizing coupled objectives.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'EC is a powerful approach to optimization that has several advantages, as well
    as a few drawbacks. The advantages include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: EC algorithms do not make any presumptions about the problem space, making them
    applicable to a wide range of problems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: They are widely applicable across different domains and can be used to solve
    continuous and discrete problems in various fields.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The solutions produced by EC algorithms are more interpretable than those of
    neural networks or other black-box optimization techniques. This is mainly because
    EC algorithms use a more transparent process of selection, mutation, and recombination
    that can be tracked and understood step by step, whereas neural networks are often
    considered “black boxes” due to their complex, layered structures and nonlinear
    operations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: EC algorithms provide multiple alternative solutions, which can be useful in
    cases where there is no single best solution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: EC algorithms exhibit inherent parallelism, making them well-suited for simple
    parallel implementations on modern hardware.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The disadvantages of EC include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: EC algorithms can be computationally expensive, meaning that they may be slow
    to converge or require a significant amount of computational resources to run.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While EC algorithms, like many metaheuristic algorithms, cannot guarantee finding
    an optimal solution, they often converge to a near-optimal solution within a finite
    time frame.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: EC algorithms often require parameter tuning to achieve good performance, which
    can be time-consuming and challenging.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter primarily focuses on genetic algorithms. The following section
    will look at the various components of genetic algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 7.3 Genetic algorithm building blocks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Genetic algorithms are the most widely used form of EC. They are adaptive heuristic
    search algorithms that are designed to simulate processes in natural systems necessary
    for evolution, as proposed by Charles Darwin in his theory of evolution. These
    algorithms represent an intelligent exploitation of a random search within a defined
    search space.
  prefs: []
  type: TYPE_NORMAL
- en: The first genetic algorithm, named simple genetic algorithm (SGA) and also known
    as the classical or canonical GA, was developed by John Holland in 1975\. Through
    his research, Holland provided insights into the design of artificial systems
    that are robust, adaptive, and capable of evolving to meet new challenges. By
    studying the processes of natural systems, he sought to create algorithms and
    computational models that could solve complex problems much like natural systems
    can. Holland defined GA as a computer program that evolves in ways that resemble
    natural selection and that can solve complex problems that even their creators
    do not fully understand. GA is based on the principles of evolution via natural
    selection, employing a population of individuals that undergo selection in the
    presence of variation-inducing operators such as mutation and crossover (recombination).
    A fitness function is used to evaluate individuals, and their reproductive success
    varies with their fitness. Figure 7.6 shows an analogy between GA and natural
    evolution.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F06_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.6 GA versus natural evolution
  prefs: []
  type: TYPE_NORMAL
- en: GA starts by initializing a population of individuals or candidate solutions.
    The fitness of all the individuals in the population is evaluated based on a defined
    fitness function, and then a new population is created by performing crossover
    and mutation, which generate children or new solutions. In constrained optimization
    problems, a feasibility check and repair should be applied after the offspring
    are produced.
  prefs: []
  type: TYPE_NORMAL
- en: The population keeps evolving until certain stopping criteria are met, as illustrated
    in figure 7.7\. These termination criteria could be
  prefs: []
  type: TYPE_NORMAL
- en: A specified number of generations or fitness evaluations (100 or 150 generations)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An adequate solution that reaches a minimum threshold
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When there is no improvement in the best individual for a specified number of
    generations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When memory or time constraints are reached
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Any combination of the preceding points
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F07_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.7 GA steps
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 7.1 summarizes the main steps of genetic algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 7.1 Genetic algorithm
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The concept of GA is straightforward and easy to understand, as it emulates
    the process of natural evolution. It is a modular algorithm that can operate in
    parallel and can be easily distributed. GA is versatile and can handle multi-objective
    optimization problems effectively. It is particularly effective in noisy environments.
    GA is widely employed for tackling complex continuous and discrete optimization
    problems, and it excels in scenarios featuring numerous combinatorial parameters
    and nonlinear interdependencies among variables. Notably, as of the publication
    of this book in 2024, a search for “genetic algorithm” as a composite keyword
    returns approximately 100,000 results on Google Patent Search, while Google Scholar
    presents a staggering 1,940,000 results. This volume reflects the substantial
    interest in and diverse applications of genetic algorithms across academic and
    industrial domains.
  prefs: []
  type: TYPE_NORMAL
- en: 7.3.1 Fitness function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As mentioned earlier, GA mimics nature’s survival-of-the-fittest principle
    in a search process. Therefore, genetic algorithms are naturally suitable for
    solving maximization problems. However, various mathematical transformations can
    be used to convert minimization problems into maximization problems, such as these:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Negation transformation*—The simplest transformation is to negate the objective
    function. For example, maximizing a fitness function *f*(*x*) = –*O*(*x*) is the
    same as minimizing the original objective function *O*(*x*).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Reciprocal transformation*—Another way to convert a minimization problem into
    a maximization problem is to take the reciprocal of the objective function. This
    works only if the objective function is always non-negative. Equation 7.1 shows
    an example:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F07_Khamis-EQ01.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 7.1 |'
  prefs: []
  type: TYPE_TB
- en: '*Other mathematical transformations*—Equation 7.2 shows another transformation
    that converts an objective function in a minimization problem *O*(*x*) into a
    fitness function in a maximization problem *f*(*x*). In this equation, *O[i]*
    is the objective function value of individual *i*, *N* is the population size,
    and *V* is a large value to ensure non-negative fitness values. The value of *V*
    can be the maximum value of the second term of the equation, so that the fitness
    value corresponding to the maximum value of the objective function is zero:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F07_Khamis-EQ02.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 7.2 |'
  prefs: []
  type: TYPE_TB
- en: According to the duality principal introduced in section 1.3.2, these transformations
    do not alter the location of the minima but convert a minimization problem to
    an equivalent maximization problem.
  prefs: []
  type: TYPE_NORMAL
- en: 7.3.2 Representation schemes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An *encoding* is a data structure for representing candidate solutions, and
    a good encoding is probably the most important factor for the performance of GA.
    In GA, the parameters of a candidate solution (the genes) are concatenated to
    form a string (a chromosome). Binary encoding, real-value encoding, and permutation
    encoding can be used to encode the solution. Binary encoding is used in binary-coded
    GA (BGA) where the solution is represented as a binary string, as illustrated
    in figure 7.8.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F08_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.8 Binary encoding
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look again at the ticket pricing example introduced in section 1.3.1,
    where an event organizer is planning a conference and wants to determine the optimal
    ticket price to maximize the profit. The expected profit is given by the following
    equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F08_Khamis-EQ03.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 7.3 |'
  prefs: []
  type: TYPE_TB
- en: where *x* is the ticket price. The binary genetic algorithm (BGA) can be used
    to find the optimal ticket price to maximize the profit, subject to the boundary
    constraint 75.0 ≤ *x* ≤ 235.0, which will make sure that profit is positive. BGA
    features a simple binary encoding. The boundary constraint on the preceding function
    requires us to use an 8-bit binary encoding, as explained in the following sidebar.
    Hence, the chromosomes are represented by bit strings of length 8.
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the minimum number of bits for a solution
  prefs: []
  type: TYPE_NORMAL
- en: 'To calculate the number of bits required to represent a range between the lower
    bound (LB) and upper bound (UB) with a desired precision *p*, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculate the range size: *R* = (*UB* – *LB*).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Divide the range size by the desired precision: *R* / *P.*'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Round up to the nearest whole number: *number_of_steps* = ceil(*R* / *P*),
    where ceil is the ceiling function that rounds up to the nearest integer.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Calculate the number of bits: *number_of_bits* = ceil(log[2](*number_of_steps*)),
    where log[2] is the logarithm to the base 2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let’s calculate the number of bits we’ll need for the ticket pricing problem:
    75.0 ≤ *x* ≤ 235.0, assuming a precision of 0.1:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Calculate the range size: (235.0 – 75.0) = 160'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Divide the range size by the desired precision: 160 / 0.1 = 1600'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Round up to the nearest whole number: 1600. Now you have 1600 steps (values)
    to represent the numbers from 75.0 to 235.0 with a precision of 0.1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To find the minimum number of bits required, you can use the formula *number_of_bits*
    = ceil(log[2](*number_of_steps*)):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*number_of_bits* = ceil(log[2](1600)) ≈ ceil(10.64) = 11'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: So you’ll need 11 bits to represent the numbers from 75.0 to 235.0 with a precision
    of 0.1\. If you want to consider integer values only (i.e., a precision of 1),
    you would need ceil(logs(160)) = ceil(7.32) = 8 bits.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned previously, GA starts with an initial population of candidate solutions.
    Population size has to be carefully selected, as very big population size usually
    does not improve performance of GA. Some research also shows that the best population
    size depends on the size of encoded string (chromosomes). It means that if you
    have chromosomes with 32 bits, the population should be higher than for chromosomes
    with 16 bits.
  prefs: []
  type: TYPE_NORMAL
- en: In the ticket pricing problem, assume that we start with a population of size
    5\. Table 7.2 shows examples of random solutions that can be generated to form
    the initial population.
  prefs: []
  type: TYPE_NORMAL
- en: Table 7.2 Initial population
  prefs: []
  type: TYPE_NORMAL
- en: '| Candidate solutions *x* | Values of *x* in the solution space | Candidate
    solutions in the binary coding space | Objective function *f*(*x*) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| x[1] | 77 | 01001101 | 8,820 |'
  prefs: []
  type: TYPE_TB
- en: '| x[2] | 203 | 11001011 | 84,420 |'
  prefs: []
  type: TYPE_TB
- en: '| x[3] | 110 | 01101110 | 90,000 |'
  prefs: []
  type: TYPE_TB
- en: '| x[4] | 145 | 10010001 | 128,500 |'
  prefs: []
  type: TYPE_TB
- en: '| x[5] | 230 | 11100110 | 18,000 |'
  prefs: []
  type: TYPE_TB
- en: Once we have an initial population, we can proceed to select the parents that
    will be subjected to genetic operators (crossover and mutation). We’ll look at
    the selection operators next.
  prefs: []
  type: TYPE_NORMAL
- en: 7.3.3 Selection operators
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are different methods (operators) for parent selection, and they have
    different levels of selective pressure. *Selective pressure* refers to the probability
    of the best individual being selected compared to the average probability of selection
    for all individuals. When using an operator with a high selective pressure in
    a genetic algorithm, the diversity within the population decreases at a faster
    rate than it would using operators with a lower selective pressure. This may sound
    good, but it can result in the population converging prematurely towards suboptimal
    solutions, thus limiting the exploration abilities of the population and eliminating
    individuals that do not fit the specific criteria determined by the selective
    pressure. This can lead to a lack of diversity in the population, which reduces
    the chances of finding better solutions.
  prefs: []
  type: TYPE_NORMAL
- en: It is important to balance selective pressure with the exploration capabilities
    of the population to avoid premature convergence and to encourage the discovery
    of a diverse range of optimal solutions. Figure 7.9 illustrates some selection
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F09_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.9 Selection methods with their selective pressure
  prefs: []
  type: TYPE_NORMAL
- en: Elitism
  prefs: []
  type: TYPE_NORMAL
- en: '*Elitism* in genetic algorithms involves selecting the fittest individuals
    for crossover and mutation and preserving the top-performing individuals of the
    current population to propagate into the next generation. The greater the number
    of individuals that are preserved, the lower the diversity of the succeeding population.
    This selection method has the highest selective pressure, as illustrated in figure
    7.9\.'
  prefs: []
  type: TYPE_NORMAL
- en: In the ticket pricing example, the best solutions (*x[4]* and *x[3]*) will be
    selected parents to generate offspring, as shown in table 7.3.
  prefs: []
  type: TYPE_NORMAL
- en: Table 7.3 Solution ranking
  prefs: []
  type: TYPE_NORMAL
- en: '| Candidate solutions *x* | Values of *x* in the solution space | Candidate
    solutions in the binary coding space | Objective function *f*(*x*) | Ranking |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| x[1] | 77 | 01001101 | 8,820 | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| x[2] | 203 | 11001011 | 84,420 | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| x[3] | 110 | 01101110 | 90,000 | **2** **(second-best individual)** |'
  prefs: []
  type: TYPE_TB
- en: '| x[4] | 145 | 10010001 | **128**,**500** | **1** **(best individual)** |'
  prefs: []
  type: TYPE_TB
- en: '| x[5] | 230 | 11100110 | 18,000 | 4 |'
  prefs: []
  type: TYPE_TB
- en: Fitness-proportionate selection
  prefs: []
  type: TYPE_NORMAL
- en: '*Fitness-proportionate selection* (FPS) is a selection method that favors the
    selection of the fittest individuals in a population. This method creates a probability
    distribution where the probability of an individual being selected is directly
    proportional to its fitness value. Individuals are chosen from this distribution
    by sampling it randomly. The individual fitness assignment relative to the whole
    population can be calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F09_Khamis-EQ04.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 7.4 |'
  prefs: []
  type: TYPE_TB
- en: where *f* is the solution represented by an individual chromosome and N is the
    population size. Roulette wheel selection is an example of an FPS operator.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our ticket pricing example, the roulette wheel can be constructed by implementing
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '1\.  Calculate the total fitness for the population: *F* = 8,820 + 84,420 +
    90,000 + 128,500 + 18,000 = 329,740.'
  prefs: []
  type: TYPE_NORMAL
- en: 2\.  Calculate the selection probability *p[k]* for each chromosome *x[k]* where
    *p[k]* = *f*(*x[k]*) / *F*. Table 7.4 shows the calculated selection probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Table 7.4 Selection probabilities
  prefs: []
  type: TYPE_NORMAL
- en: '| Candidate solutions *x* | Values of *x* in the solution space | Candidate
    solutions in the binary coding space | Objective function *f*(*x*) | Selection
    probability *p[k]* |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| x[1] | 77 | 01001101 | 8,820 | 0.03 |'
  prefs: []
  type: TYPE_TB
- en: '| x[2] | 203 | 11001011 | 84,420 | 0.26 |'
  prefs: []
  type: TYPE_TB
- en: '| x[3] | 110 | 01101110 | 90,000 | 0.27 |'
  prefs: []
  type: TYPE_TB
- en: '| x[4] | 145 | 10010001 | 128,500 | 0.39 |'
  prefs: []
  type: TYPE_TB
- en: '| x[5] | 230 | 11100110 | 18,000 | 0.05 |'
  prefs: []
  type: TYPE_TB
- en: 3\.  Calculate the cumulative probability *q[k]* for each chromosome *x[k]*
    where *q[k]* = sum(*p[j]*), *j* *= {1,k}*. Table 7.5 shows the calculated cumulative
    probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Table 7.5 Cumulative probabilities
  prefs: []
  type: TYPE_NORMAL
- en: '| Candidate solutions *x* | Values of *x* in the solution space | Candidate
    solutions in the binary coding space | Objective function *f*(*x*) | Selection
    probability *p[k]* | Cumulative probability *q[k]* |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| x[1] | 77 | 01001101 | 8,820 | 0.03 | 0.03 |'
  prefs: []
  type: TYPE_TB
- en: '| x[2] | 203 | 11001011 | 84,420 | 0.26 | 0.28 |'
  prefs: []
  type: TYPE_TB
- en: '| x[3] | 110 | 01101110 | 90,000 | 0.27 | 0.56 |'
  prefs: []
  type: TYPE_TB
- en: '| x[4] | 145 | 10010001 | 128,500 | 0.39 | 0.95 |'
  prefs: []
  type: TYPE_TB
- en: '| x[5] | 230 | 11100110 | 18,000 | 0.05 | 1.00 |'
  prefs: []
  type: TYPE_TB
- en: 4\.  Generate a random number *r* from the range [0,1].
  prefs: []
  type: TYPE_NORMAL
- en: 5\.  If *q*[1] >= *r*, then select the first chromosome *x*[1]; otherwise, select
    the *k^(th)* chromosome *x[k]* (2 ≤ k ≤ *N*) such that *q[k]*[-1] < *r* ≤ *q[k]*.
    If we assume that the randomly generated number *r* = 0.25, then *x*[2] with *q*[2]
    = 0.28 is selected because *q*[2] > 0.25, and if *r* = 0.58, *x*[4] will be selected
    because *q[4]* > 0.58. Figure 7.10 illustrates the roulette wheel for the ticket
    pricing example.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F10_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.10 Roulette wheel for the ticket pricing example
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, the fittest individual occupies the largest segment of the roulette
    wheel, and the weakest individual occupies the smallest segment of the wheel.
    Due to the direct correlation between fitness and selection in proportional selection,
    there is a potential for dominant individuals to disproportionately contribute
    to the next generation’s offspring, leading to a reduction in the diversity of
    the population. This implies that proportional selection results in a high selective
    pressure.
  prefs: []
  type: TYPE_NORMAL
- en: Rank-based selection
  prefs: []
  type: TYPE_NORMAL
- en: One way to address the limitations of FPS in genetic algorithms is to use relative
    fitness instead of absolute fitness to determine selection probabilities—individuals
    are selected based on their fitness relative to the fitness of other individuals
    in the population. This approach ensures that the selection process is not dominated
    by the best individual in the population.
  prefs: []
  type: TYPE_NORMAL
- en: 'Linear ranking and nonlinear ranking can be used. In *linear ranking*, the
    rank-based probability of an individual *i* being selected is calculated using
    the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F10_Khamis-EQ05.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 7.5 |'
  prefs: []
  type: TYPE_TB
- en: where *N* is the size of the population, *SP* is the selection pressure (1.0
    < *SP* ≤ 2.0), and *r*(*i*) is the rank associated with individual *i* (a higher
    rank is better). In the ticket pricing example, where *N* = 5, and assuming that
    *SP* = 1.5, the rank-based selection probability of each individual in the population
    is shown in table 7.6.
  prefs: []
  type: TYPE_NORMAL
- en: Table 7.6 Rank-based selection probabilities
  prefs: []
  type: TYPE_NORMAL
- en: '| Candidate solutions *x* | Values of *x* in the solution space | Candidate
    solutions in the binary coding space | Objective function *f*(*x*) | Rank *r[i]*
    | FPS cumulative probability *q[k]* | Rank-based selection probability |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| x[1] | 77 | 01001101 | 8,820 | 1 | 0.03 | 0.50 |'
  prefs: []
  type: TYPE_TB
- en: '| x[2] | 203 | 11001011 | 84,420 | 3 | 0.28 | 0.75 |'
  prefs: []
  type: TYPE_TB
- en: '| x[3] | 110 | 01101110 | 90,000 | 4 | 0.56 | 0.88 |'
  prefs: []
  type: TYPE_TB
- en: '| x[4] | 145 | 10010001 | 128,500 | 5 | 0.95 | 1.00 |'
  prefs: []
  type: TYPE_TB
- en: '| x[5] | 230 | 11100110 | 18,000 | 2 | 1.00 | 0.63 |'
  prefs: []
  type: TYPE_TB
- en: As you can see, rank-based selection reduces the bias of FPS by assigning greater
    probabilities of selection to less-fit individuals.
  prefs: []
  type: TYPE_NORMAL
- en: '*Nonlinear ranking* permits higher selective pressures than linear ranking
    does. The selection probability is calculated using the following equation:'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F10_Khamis-EQ06.png)'
  prefs: []
  type: TYPE_IMG
- en: '| 7.6 |'
  prefs: []
  type: TYPE_TB
- en: where *X* is computed as the root of the polynomial (SP–N).X*^(N–)*¹)+SP.X*^(N–)*²+…+SP.X+SP=0.
    This nonlinear ranking allows values of selective pressure in the interval [1,
    N – 2].
  prefs: []
  type: TYPE_NORMAL
- en: Stochastic universal sampling
  prefs: []
  type: TYPE_NORMAL
- en: '*Stochastic universal sampling* (SUS) is another approach to mitigating the
    potential bias in the roulette-wheel selection approach. This method involves
    placing an outer roulette wheel around the pie with *m* evenly spaced pointers.
    With SUS, a single spin of the roulette wheel is used to simultaneously select
    all *m* individuals for reproduction. Figure 7.11 shows SUS for the ticket pricing
    problem using four selection points.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F11_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.11 Stochastic universal sampling (SUS) strategy
  prefs: []
  type: TYPE_NORMAL
- en: Tournament selection
  prefs: []
  type: TYPE_NORMAL
- en: '*Tournament selection* involves randomly selecting a group of *k* individuals
    from the current population, where *k* is the size of the tournament group. Once
    the group is formed, a tournament is held among its members to identify the best-performing
    individual based on their fitness values. The individual with the highest fitness
    score is the winner and advances to the next stage of the genetic algorithm. Figure
    7.12 shows the tournament selection process.'
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F12_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.12 Tournament selection
  prefs: []
  type: TYPE_NORMAL
- en: To select *m* individuals for reproduction, the tournament procedure is carried
    out *m* times. In each iteration, a new tournament group is randomly chosen from
    the population, and the individuals in the group compete against each other until
    the best-performing individual is identified. The winners from each tournament
    are then selected for reproduction, which involves applying genetic operators
    such as crossover and mutation to create new offspring.
  prefs: []
  type: TYPE_NORMAL
- en: Random selection
  prefs: []
  type: TYPE_NORMAL
- en: '*Random selection* is the simplest selection operator, where each individual
    has the same selection probability of 1/*N* (where *N* is the population size).
    No fitness information is used, which means that the best and the worst individuals
    have exactly the same probability of being selected. Random selection has the
    lowest selective pressure among the selection operators, as all individuals within
    the population have the same chance of being selected.'
  prefs: []
  type: TYPE_NORMAL
- en: Other selection methods
  prefs: []
  type: TYPE_NORMAL
- en: Other selection methods include, but are not limited to, Boltzmann Selection,
    (*μ, λ*)- and (*μ* + *λ*)-selection, and hall of fame. The random selection and
    tournament selection methods are implemented as part of the `pymoo.operators.selection`
    class in pymoo.
  prefs: []
  type: TYPE_NORMAL
- en: After we select the parents, we need to produce offspring by applying reproduction
    operators.
  prefs: []
  type: TYPE_NORMAL
- en: 7.3.4 Reproduction operators
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Genetic algorithms employ two primary genetic operators, namely crossover and
    mutation, to generate offspring. Let’s look at these two reproduction operators
    in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Crossover
  prefs: []
  type: TYPE_NORMAL
- en: '*Crossover* is inspired by the biological process of recombination, where a
    portion of the genetic information is exchanged between two chromosomes. This
    exchange of genetic material results in the production of offspring, so two parents
    can thus give rise to two offspring. In order to ensure that the best individuals
    are able to contribute their genetic material, superior individuals are typically
    given more opportunities to reproduce through crossover. This mechanism promotes
    the effective combination of schemata, which are subsolutions located on different
    chromosomes. 1-point crossover, *n*-point crossover, and uniform crossover are
    commonly used crossover methods.'
  prefs: []
  type: TYPE_NORMAL
- en: In *1-point crossover*, we start by choosing a random point on the two parents
    and splitting parents at this crossover point. Two children are then created by
    exchanging tails, as illustrated in figure 7.13\. This crossover operation produces
    two new children (candidate solutions), which in the figure are 01010001 and 01001101
    (or 81 and 77 in decimal, respectively) as potential ticket prices. These solutions
    result in total profits of $20,980 and $8,820 respectively, based on equation
    7.3.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F13_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.13 1-point crossover
  prefs: []
  type: TYPE_NORMAL
- en: In *n-point crossover*, which is a generalization of 1-point crossover, we choose
    *n* random crossover points and split along those points. The children are generated
    by gluing parts together and alternating between parents, as illustrated in figure
    7.14\. Following the 2-point crossover illustrated in figure 7.14, two candidate
    solutions are generated, which are 141 and 81 with fitness values of $126,580
    and $20,980 respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F14_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.14 *n*-point crossover
  prefs: []
  type: TYPE_NORMAL
- en: In *uniform crossover*, random bit positions from two parents are swapped to
    create two offspring. One parent is assigned the label “heads” and the other “tails.”
    For the first child, a coin is flipped for each gene to determine whether it should
    come from the “heads” or “tails” parent. The second child is created by taking
    the inverse of each gene in the first child, as shown in figure 7.15\. In this
    example, applying uniform crossover results in 217 and 5 with fitness values of
    $53,620 and $–319,500\. As you can see, 5 is not a feasible solution because it
    is not within the boundary constraints of {75.0,235.0}. This solution is rejected.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F15_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.15 Uniform crossover
  prefs: []
  type: TYPE_NORMAL
- en: In pymoo, the repair operator can be used make sure the algorithm only searches
    in the feasible space. It is applied after the offspring have been produced.
  prefs: []
  type: TYPE_NORMAL
- en: Mutation
  prefs: []
  type: TYPE_NORMAL
- en: '*Mutation* is a process that introduces new genetic material into an individual,
    which helps to increase the diversity of the population. This diversity is important
    because it allows the population to explore a wider range of possible solutions
    to the problem at hand. Mutation is often used in combination with crossover to
    ensure that the full range of alleles is accessible for each gene. In the case
    of mutation, selection mechanisms could focus on “weak” individuals in the hope
    that mutation will introduce better traits to those individuals, increasing their
    chances of survival.'
  prefs: []
  type: TYPE_NORMAL
- en: In binary genetic algorithms, mutation is performed by altering each gene independently
    with a probability *p[m]*. For each gene, we generate a random number *r* between
    0 and 1\. If *p[m]* > *r*, we alter the gene. Figure 7.16 illustrates mutating
    one of the individuals of the ticket pricing problem.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F16_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.16 Mutation
  prefs: []
  type: TYPE_NORMAL
- en: New population
  prefs: []
  type: TYPE_NORMAL
- en: After applying crossover and mutation, we will have new offspring that represent
    new candidate solutions. To start a new generation, we need to create a new population
    by selecting individuals from the old population and from the newly generated
    offspring. The size of the new population will remain the same as the old population.
  prefs: []
  type: TYPE_NORMAL
- en: Generational GA and steady-state GA are two models used in genetic algorithms.
    As shown in figure 7.17, in *generational GA* models, the whole population is
    replaced by its offspring to start a “next generation.” In *steady-state GA*,
    the number of generated offspring is less than the population size. Old individuals
    may be replaced by new ones. The process of selecting individuals for the new
    population is known as *survivor selection*. We’ll look at survivor selection
    methods next.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/CH07_F17_Khamis.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.17 GA generational and steady-state models
  prefs: []
  type: TYPE_NORMAL
- en: 7.3.5 Survivor selection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Random selection, age-based selection, fitness-proportionate selection, and
    tournament selection are examples of survivor selection methods that can preserve
    the best individuals while also introducing diversity to a population by making
    use of the newly generated offspring:'
  prefs: []
  type: TYPE_NORMAL
- en: In *random selection*, the new population is formed by random selection of *N*
    individuals.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With *age-based selection* (or first in, first out), the oldest individuals
    will be deleted.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Fitness-proportionate selection* (FPS) takes into consideration the fitness
    of each individual—we can delete or replace individuals based on the inverse of
    fitness, always keeping the best individuals or deleting the worst individuals.
    For example, *elitist selection* involves simply selecting the best individuals
    from both the old population and the new offspring to create the new population.
    This method ensures that the best solutions are preserved from generation to generation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tournament selection involves selecting individuals from both the old population
    and the new offspring at random and then selecting the best individuals from each
    group to create the new population. This method can be more effective at preserving
    diversity in the population.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the ticket pricing example, if we apply elitist selection, the new population
    will be formed by the selected solutions shown in table 7.7.
  prefs: []
  type: TYPE_NORMAL
- en: Table 7.7 Elitist selection
  prefs: []
  type: TYPE_NORMAL
- en: '| Source | Candidate solutions x in the solution space | Candidate solutions
    in the binary coding space | Objective function f(x) | Ranking | Selected |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Old individuals | 77 | 01001101 | 8,820 | 7 | No |'
  prefs: []
  type: TYPE_TB
- en: '| 203 | 11001011 | 84,420 | 3 | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| 110 | 01101110 | 90,000 | 2 | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| 145 | 10010001 | 128,500 | 1 | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| 230 | 11100110 | 18,000 | 6 | No |'
  prefs: []
  type: TYPE_TB
- en: '| New individuals generated by 1-point crossover | 81 | 01010001 | 20,980 |
    5 | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| 77 | 01001101 | 8,820 | 7 | No |'
  prefs: []
  type: TYPE_TB
- en: '| New individuals generated by mutating individual 77 | 103 | 01100111 | 76,420
    | 4 | Yes |'
  prefs: []
  type: TYPE_TB
- en: You may have noticed that 1-point crossover generated a solution that already
    exists in the initial population. This phenomenon is not necessarily a problem,
    as it is an expected outcome when applying genetic operators in a search process.
    Crossover and mutation can result in both explorative and exploitative behaviors.
    For example, in 1-point or *n*-point crossover and based on the random split point
    position, a new solution can be the same as or close to the parents or can generate
    more diverse offspring.
  prefs: []
  type: TYPE_NORMAL
- en: 7.4 Implementing genetic algorithms in Python
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A genetic algorithm is an easy algorithm to implement. Let’s see how we can
    solve the ticket pricing problem using GA in Python.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll start by importing the necessary packages and defining the problem.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.2 Solving the ticket pricing problem using binary GA
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Because we’re solving this problem using a binary GA, we need to generate an
    initial random population. As a continuation of listing 7.2, the following `init_pop`
    function takes two arguments as input—`pop_size`, which represents the population
    size, and `chromosome_length`, which represents the length of each chromosome:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: ① Generate a list of random integers.
  prefs: []
  type: TYPE_NORMAL
- en: ② Convert the integers to binary strings.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Convert the binary strings to lists of binary digits.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Return the final list of binary chromosomes.
  prefs: []
  type: TYPE_NORMAL
- en: The `init_pop` function starts by generating a list of random integers from
    75 to 235 (inclusive) with a length equal to `pop_size`. This list will later
    be converted to binary representations. The integers in the `ints` list are then
    converted to binary strings using the `bin()` function, which returns a binary
    string representation of a given number with the prefix `0b`. To remove this prefix,
    we use slicing with `[2:]`. Then we use the `zfill()` method to pad the binary
    string with leading zeros to ensure it has the same length as `chromosome_length`.
    The binary strings in the `strs` list are converted to lists of binary digits
    (0 or 1). This is done using a nested list comprehension that iterates through
    each character in the binary strings and converts it to an integer. The function
    finally returns a list of binary chromosomes, where each chromosome is a list
    of binary digits.
  prefs: []
  type: TYPE_NORMAL
- en: 'For a given population, we can calculate the fitness of each element in the
    population using the following `fitness_score` function. This fitness function
    essentially determines how “good” a particular offspring is. It converts each
    unit in the population to a binary number (the genotype), evaluates the function
    to optimize profit, and then returns the “best” offspring. The function mainly
    takes a population as input and returns a tuple containing two lists, one of the
    sorted fitness values and another of the sorted population:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: ① Convert binary to decimal.
  prefs: []
  type: TYPE_NORMAL
- en: ② Evaluate the fitness of each chromosome and append the fitness value to the
    fitness_values list.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Create tuples of fitness values and their corresponding chromosomes, and then
    sort them in descending order based on fitness values.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Unzip the sorted tuples back into separate lists for fitness values and the
    population.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Return the sorted fitness values and population.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now select two parents using the random selection method implemented
    in the following `select_parent` function. This function takes two arguments as
    input: `population`, which is a list of individuals in the population, and `num_parents`,
    which represents the number of parents to select. It returns a list of selected
    parents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: ① Randomly select a specified number of unique parents from the given population.
  prefs: []
  type: TYPE_NORMAL
- en: ② Return the list of selected parents.
  prefs: []
  type: TYPE_NORMAL
- en: The `select_parent` function implements a simple random sampling selection method,
    which gives each individual in the population an equal chance of being selected
    as a parent. Other selection methods, such as FPS or roulette wheel selection,
    can also be used to give higher chances to individuals with better fitness values.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following `roulette_wheel_selection` function shows the steps of roulette
    wheel selection. The function takes two arguments as input—`population`, which
    is a list of individuals in the population, and `num_parents`, which represents
    the number of parents to select:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: ① Calculate total fitness.
  prefs: []
  type: TYPE_NORMAL
- en: ② Calculate selection probabilities for each individual.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Select only two parents.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Generate a random number r between 0 and 1.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Find the individual whose cumulative probability includes r.
  prefs: []
  type: TYPE_NORMAL
- en: 'After selecting the parents, it’s time to apply genetic operators to produce
    the offspring. The following `crossover` function implements 1-point crossover.
    The function takes two arguments as input: `parents`, which is a list of two parent
    chromosomes, and `crossover_prob`, which represents the probability of crossover
    occurring between the parents. It returns a list of parents and offspring. The
    first offspring is generated by taking the first part (up to and including the
    crossover point) of the first parent and the second part (from the crossover point
    + 1 to the end of the chromosome) of the second parent. Similarly, the second
    offspring is generated by taking the first part (up to and including the crossover
    point) of the second parent and the second part (from the crossover point + 1
    to the end of the chromosome) of the first parent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: ① Apply crossover if, and only if, crossover probability is greater than a randomly
    generated number.
  prefs: []
  type: TYPE_NORMAL
- en: ② Choose a random crossover point within the range of chromosome indices.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Create the first offspring.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Create the second offspring.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Return the original parents and the new offspring generated by the crossover
    operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now apply the mutation process. The following `mutation` function performs
    mutation operations on a given population of chromosomes. It takes two arguments
    as input: `population`, which is a list of binary chromosomes, and `mutation_prob`,
    which represents the probability of mutation occurring at each gene in the chromosomes.
    It returns the mutated population:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: ① Iterate through each chromosome in the population.
  prefs: []
  type: TYPE_NORMAL
- en: ② Iterate through each gene in the chromosome, except the last one.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Apply mutation if, and only if, the mutation probability is greater than a
    randomly generated number
  prefs: []
  type: TYPE_NORMAL
- en: ④ Flip the value of the gene.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Return the mutated population.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s now put everything together and define the binary genetic algorithm (`BGA`)
    function. This function takes the following arguments as input:'
  prefs: []
  type: TYPE_NORMAL
- en: '`population`—The initial population of binary chromosomes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_gen`—The number of generations the algorithm will run for'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`num_parents`—The number of parents to select for crossover'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`crossover_prob`—The probability of crossover occurring between parents'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mutation_prob`—The probability of mutation occurring at each gene'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`use_tqdm` (optional, default=`False`)—A Boolean flag to enable or disable
    a progress bar using the tqdm library'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This is the BGA function:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: ① Initialization
  prefs: []
  type: TYPE_NORMAL
- en: ② Run the genetic algorithm for num_gen generations using a for loop.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Calculate the fitness scores and sort the population based on the fitness
    values by calling the fitness_score function.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Update the best solution and best score.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Parent selection using the select_parent random method. You can replace this
    method with roulette_wheel_selection(population, num_parents).
  prefs: []
  type: TYPE_NORMAL
- en: ⑥ Perform crossover on the selected parents.
  prefs: []
  type: TYPE_NORMAL
- en: ⑦ Perform mutation.
  prefs: []
  type: TYPE_NORMAL
- en: ⑧ Return the best solution.
  prefs: []
  type: TYPE_NORMAL
- en: This function returns the best solution, the best score, and the list of best
    scores at each generation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we can solve the ticket pricing problem, starting with generating an initial
    population with the following parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this code produced the following initial population:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now run the binary GA solver to get the solutions, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Running this code produces the same solution obtained by the SciPy optimizer
    (see listing 2.4):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Rather than writing your own genetic algorithm code from scratch, you can take
    advantage of existing Python packages that offer GA implementations. Numerous
    open source Python libraries can help streamline the development process and save
    time. These libraries often include genetic operators, selection methods, and
    other features that make it easier to adapt a genetic algorithm to different optimization
    problems. Examples of these libraries include, but are not limited to, the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Pymoo* (Multi-objective Optimization in Python; [https://pymoo.org/algorithms/moo/nsga2.html](https://pymoo.org/algorithms/moo/nsga2.html))—A
    Python library for multi-objective optimization using evolutionary algorithms
    and other metaheuristic techniques. Pymoo offers a variety of algorithms such
    as GA, differential evolution, evolutionary strategy, non-dominated sorting genetic
    algorithm (NSGA-II), NSGA-III, and particle swarm optimization (PSO).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*DEAP* (Distributed Evolutionary Algorithms in Python; [https://deap.readthedocs.io/en/master/](https://deap.readthedocs.io/en/master/)—A
    Python library for implementing genetic algorithms in Python. It provides tools
    for defining, training, and evaluating genetic algorithm models, as well as for
    visualizing the optimization process. DEAP provides a variety of built-in genetic
    operators, including mutation, crossover, and selection, as well as support for
    custom operators tailored to specific optimization problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PyGAD* (Python Genetic Algorithm; [https://pygad.readthedocs.io/en/latest/](https://pygad.readthedocs.io/en/latest/))—A
    Python library for implementing genetic algorithms and differential evolution
    (DE) algorithms. PyGAD is suitable for both single-objective and multi-objective
    optimization tasks and can be used in a wide range of applications, including
    machine learning, and other problem domains.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*jMetalPy* ([https://github.com/jMetal/jMetalPy](https://github.com/jMetal/jMetalPy))—A
    Python library designed for developing and experimenting with metaheuristic algorithms
    for solving multi-objective optimization problems. It provides support for a variety
    of metaheuristic algorithms, including popular evolutionary algorithms like non-dominated
    sorting genetic algorithm (NSGA-II), NSGA-III, strength Pareto evolutionary algorithm
    (SPEA2), and multi-objective evolutionary algorithm based on decomposition (MOEA/D),
    as well as other optimization techniques such as simulated annealing and particle
    swarm optimization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PyGMO* (Python Parallel Global Multi-objective Optimizer; [https://esa.github.io/pygmo/](https://esa.github.io/pygmo/))—A
    scientific library providing a large number of optimization problems and algorithms
    such as NSGA-II, SPEA2, non-dominated sorting particle swarm optimization (NS-PSO),
    and parameter adaptive differential evolution (PaDE). It uses the generalized
    island-model paradigm for the coarse grained parallelization of optimization algorithms
    and, therefore, allows users to develop asynchronous and distributed algorithms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Inspyred* (Bio-inspired Algorithms in Python; [https://pythonhosted.org/inspyred/](https://pythonhosted.org/inspyred/))—A
    library for creating and working with bio-inspired computational intelligence
    algorithms. It supports a variety of bio-inspired optimization algorithms, such
    as GA, evolution strategy, simulated annealing, differential evolution algorithm,
    estimation of distribution algorithm, Pareto archived evolution strategy (PAES),
    nondominated sorting genetic algorithm (NSGA-II), particle swarm optimization
    (PSO), and ant colony optimization (ACO).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Platypus* ([https://platypus.readthedocs.io/en/latest/](https://platypus.readthedocs.io/en/latest/))—A
    framework for evolutionary computing in Python with a focus on multi-objective
    evolutionary algorithms (MOEAs). It provides tools for analyzing and visualizing
    algorithm performance and solution sets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*MEALPY* ([https://mealpy.readthedocs.io/en/latest/index.html](https://mealpy.readthedocs.io/en/latest/index.html))—A
    Python library that provides implementations for population-based meta-heuristic
    algorithms such as evolutionary computing algorithms, swarm inspired computing,
    physics inspired computing, human inspired computing, and biology inspired computing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Mlrose* (Machine Learning, Randomized Optimization and Search; [https://mlrose.readthedocs.io/en/stable/index.html](https://mlrose.readthedocs.io/en/stable/index.html))—An
    open source Python library that provides an implementation of standard GA to find
    the optimum for a given optimization problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Pyevolve* ([https://pyevolve.sourceforge.net/](https://pyevolve.sourceforge.net/))—An
    open source Python library designed for working with genetic algorithms and other
    EC techniques'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*EasyGA* ([https://github.com/danielwilczak101/EasyGA](https://github.com/danielwilczak101/EasyGA))—A
    Python package designed to provide an easy-to-use GA. It’s worth noting that EasyGA
    and Pyevolve are simple libraries with less functionality and predefined problems
    than other libraries such as DEAP and Pymoo.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Listing A.3, available in the book’s GitHub repo, shows how to use some of these
    libraries.
  prefs: []
  type: TYPE_NORMAL
- en: In this book, we will focus on utilizing the pymoo library, as it is a comprehensive
    framework that offers several optimization algorithms, visualization tools, and
    decision-making capabilities. This library is particularly well-suited for multi-objective
    optimization, which we’ll explore in more detail in the next chapter. Pymoo’s
    extensive features make it an excellent choice for implementing and analyzing
    genetic algorithms in various problem domains. Table 7.8 summarizes a comparative
    study of selected evolutionary computing frameworks, including pymoo [2].
  prefs: []
  type: TYPE_NORMAL
- en: Table 7.8 Comparing selected evolutionary computing frameworks in Python
  prefs: []
  type: TYPE_NORMAL
- en: '| Library | License | Pure Python | Visualization | Focus on multi-objective
    | Decision making |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| jMetalPy | MIT | Yes | Yes | Yes | No |'
  prefs: []
  type: TYPE_TB
- en: '| PyGMO | GPL-3.0 | No (C++ with Python wrappers) | No | Yes | No |'
  prefs: []
  type: TYPE_TB
- en: '| Platypus | GPL-3.0 | Yes | No | Yes | No |'
  prefs: []
  type: TYPE_TB
- en: '| DEAP | LGPL-3.0 | Yes | No | No | No |'
  prefs: []
  type: TYPE_TB
- en: '| inspyred | MIT | Yes | No | No | No |'
  prefs: []
  type: TYPE_TB
- en: '| pymoo | Apache 2.0 | Yes | Yes | Yes | Yes |'
  prefs: []
  type: TYPE_TB
- en: The following listing shows the steps for solving the ticket pricing problem
    using GA implemented in pymoo. We’ll start by importing various classes and functions
    from the pymoo library.
  prefs: []
  type: TYPE_NORMAL
- en: Listing 7.3 Solving the ticket pricing problem using GA in pymoo
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: The `GA` class represents a single-objective genetic algorithm in the pymoo
    library. The `PointCrossover`, `SinglePointCrossover`, and `TwoPointCrossover`
    classes represent different crossover operators for combining the genetic material
    of parent chromosomes to create offspring. The `PolynomialMutation` class represents
    a mutation operator that introduces small, random changes in the chromosomes’
    genes. The `RoundingRepair` class represents a repair operator that rounds the
    variable values of the chromosomes, ensuring that they stay within a specific
    range or meet certain constraints. The `FloatRandomSampling` class represents
    a random sampling operator that generates an initial population of chromosomes
    with random float values. The `Problem` class is used to define optimization problems
    by specifying objectives, constraints, and variable bounds. Finally, the `minimize`
    function is used to perform the optimization process. It is worth noting that
    pymoo can only handle minimization problems, so if you need to use it with a maximization
    problem, you’ll have to convert the problem into a minimization problem, as discussed
    in section 7.3.1.
  prefs: []
  type: TYPE_NORMAL
- en: 'After importing the necessary classes and functions from the pymoo library,
    we can define the `TicketPrice` problem by subclassing the `Problem` class from
    the pymoo library as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: ① Define the constructor for the TicketPrice class.
  prefs: []
  type: TYPE_NORMAL
- en: ② Call the constructor of the parent Problem class.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Define the evaluation function for the TicketPrice class.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Evaluate the value of the objective function using the given formula.
  prefs: []
  type: TYPE_NORMAL
- en: 'As can be seen, the constructor of the parent `Problem` class contains the
    following components with customized values applied to the ticket pricing problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '`n_var=1`—The number of decision variables in the problem, which is set to
    1, indicating a single decision variable for the ticket price.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`n_obj=1`—The number of objectives in the problem, which is set to 1, indicating
    a single-objective optimization problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`n_constr=0`—The number of constraints in the problem, which is set to 0, indicating
    that there are no constraints in this optimization problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`xl=75.0`—The lower bound for the decision variable, which is set to 75.0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`xu=235.0`—The upper bound for the decision variable, which is set to 235.0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`vtype=float`—The variable type for the decision variables, which is set to
    float. Other types include `int` and `bool`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now we can apply GA to solve the problem as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: ① Create an instance of the TicketPrice problem.
  prefs: []
  type: TYPE_NORMAL
- en: ② Instantiate a GA object.
  prefs: []
  type: TYPE_NORMAL
- en: ③ Run the solver.
  prefs: []
  type: TYPE_NORMAL
- en: ④ Print the optimal ticket price.
  prefs: []
  type: TYPE_NORMAL
- en: ⑤ Print the profit. Negate the objective value when printing the result.
  prefs: []
  type: TYPE_NORMAL
- en: 'GA parameters include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`pop_size=100`—Set the population size to 100 individuals.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sampling=FloatRandomSampling()`—Use the `FloatRandomSampling` class to generate
    an initial population of chromosomes with random float values.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`crossover=PointCrossover(prob=0.8, n_points=2)`—Use the `PointCrossover` class
    as the crossover operator with a probability of 0.8 and two crossover points.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mutation=PolynomialMutation(prob=0.3, repair=RoundingRepair())`—Use the `PolynomialMutation`
    class as the mutation operator with a probability of 0.3, and apply the `RoundingRepair`
    class to repair mutated solutions if needed. The repair makes sure every solution
    that is evaluated is, in fact, feasible.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`eliminate_duplicates=True`—Set the flag to eliminate duplicate individuals
    in the population.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`res = minimize(...)`—Call the minimize function from pymoo to run the optimization
    process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Running listing 7.3 produces the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: So far, we’ve only scratched the surface of genetic algorithms. We’ll dive into
    the details, study different variants of genetic algorithms, and address more
    practical use cases in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Metaheuristic algorithms that are population-based, often referred to as P-metaheuristics,
    employ multiple agents to find an optimal or near-optimal global solution. These
    algorithms can be divided into two main categories, depending on their source
    of inspiration: evolutionary computation (EC) algorithms and swarm intelligence
    (SI) algorithms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: EC algorithms draw inspiration from the process of biological evolution. Examples
    of EC algorithms include the genetic algorithm (GA), differential evolution (DE),
    genetic programming (GP), evolutionary programming (EP), evolutionary strategies
    (ES), cultural algorithms (CA), and co-evolution (CoE).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The genetic algorithm is the most widely used form of EC. It is an adaptive
    heuristic search method designed to mimic the natural system’s processes required
    for evolution, as outlined in Charles Darwin’s theory of evolution.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pseudo-random strategies, quasi-random strategies, sequential diversification,
    parallel diversification, and heuristics represent various initialization strategies
    for P-metaheuristics like genetic algorithms. Each strategy offers distinct levels
    of diversity, computational cost, and initial solution quality.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In genetic algorithms, the crossover and mutation operators play essential roles
    in searching the solution space and maintaining diversity within the population.
    The primary purpose of these operators is to handle the search dilemma by balancing
    exploration (searching new areas of the solution space) and exploitation (refining
    the existing solutions).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A high crossover rate and a low mutation rate are recommended to balance exploration
    and exploitation. The high crossover rate facilitates the sharing of good traits
    between individuals, while the low mutation rate introduces small, random changes
    to maintain diversity and prevent premature convergence. This combination allows
    the algorithm to efficiently search the solution space and find high-quality solutions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the generational model of genetic algorithms, the entire population is replaced,
    whereas in the steady-state model of genetic algorithms, a small fraction of the
    population is replaced. The steady-state model has lower computation costs than
    the generational model in genetic algorithms, but the generational model improves
    diversity preservation compared to the steady-state models.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A wide range of open source Python libraries exist for working with genetic
    algorithms. One such library, pymoo (Multi-objective Optimization in Python),
    includes popular algorithms such as genetic algorithms, differential evolution,
    evolutionary strategies, the non-dominated sorting genetic algorithm (NSGA-II),
    NSGA-III, and particle swarm optimization (PSO).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
