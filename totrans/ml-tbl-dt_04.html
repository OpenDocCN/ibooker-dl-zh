<html><head></head><body>
  <h1 class="tochead" id="heading_id_2">Part 2. <a id="idTextAnchor000"/><a id="idTextAnchor001"/>Machine learning and gradient boosting for tabular data</h1>

  <p class="body"><span class="fm-part-initial-cap">C</span>hapters 4, 5, and 6 give a complete overview of classical machine learning algorithms and helps you master the most advanced gradient boosting techniques, such as XGBoost and LightGBM. You will learn how to use each algorithm and apply it to suitable tabular data. Chapter 7 helps you consolidate what you learned with a practical example to demonstrate the complete analytical process when tabular data is involved.</p>

  <p class="body">Specifically, chapter 4 introduces Scikit-learn and various classical machine learning methods such as linear regression, logistic regression, and generalized linear models. You will grasp how a data pipeline works from a practical point of view and learn to validate results and compare across different models. We then proceed to chapter 5 and explore decision trees and their ensembles, including bagging, random forests, and gradient boosting decision trees. Then we share a detailed explanation of how the gradient boosting algorithm operates and excels with tabular data. Finally, chapter 5 wraps up with an overview of the different implementations, from Scikit-learn to XGBoost and LightGBM.</p>

  <p class="body">Chapter 6 is devoted to helping you use the best practices for tabular data in machine learning, with a strong emphasis on gradient boosting methods. We touch on many advanced techniques to select an optimal set of features, optimize the hyperparameters of a model, and obtain improved performance. We also discuss how to deal with missing data from a practical point of view and how to transform categorical data properly. Part 2 concludes with chapter 7, an illustrative chapter where you learn about an end-to-end example using gradient boosting on real-world data. Guided through multiple passages, you grasp how to apply the best practices and methodologies we previously discussed. Afterward, you are ready to compare all these classical and advanced methods against deep learning approaches, which are the focus of the following conclusive part.</p>
</body></html>