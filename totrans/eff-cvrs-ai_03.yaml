- en: 3 Planning for improvement
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter covers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Building a cross-functional team that achieves conversational AI success
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Defining success through business goals, key metrics, and user pain points
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyzing effectiveness using outcomes and metrics to guide improvements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing structured processes for identifying, reporting, triaging, and
    prioritizing problems
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Every conversational AI solution should be built with success in mind, and success
    is defined differently depending on the type of chatbot involved. For instance,
    question-answering bots must deliver prompt, accurate responses while minimizing
    follow-up interactions. Process-oriented or transactional bots must guide users
    efficiently toward specific goals. Routing agents must seamlessly direct users
    to appropriate destinations.
  prefs: []
  type: TYPE_NORMAL
- en: However, misunderstanding user intent, excessive complexity, and immediate opt-outs
    can hinder progress and cause user pain. Addressing these challenges improves
    a chatbot’s performance and helps it achieve success. Organizations that continuously
    improve their chatbots are most likely to deliver optimal outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Combining diverse expertise within cross-functional teams is crucial for continuous
    improvement. The team members can drive change through their unique perspectives,
    skills, and insights. However, the team needs to agree on how to improve their
    solution.
  prefs: []
  type: TYPE_NORMAL
- en: The conversational analyst wants to simplify the dialogues, but the business
    wants to convey specific information. Who is right? In this chapter, we’ll show
    how a team at MediWorld, a fictional company, adapted and improved their chatbot.
    Their team started by enhancing their question-answering bot, but as user needs
    evolved, they transitioned to developing additional capabilities for a process-oriented
    bot.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Knowing when you need to improve
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Imagine the following scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: '*MediWorld, a large drug store, had call centers overloaded with questions
    about the pandemic. They deployed a chatbot to provide information related to
    COVID-19\. The bot detected a focused set of intents about the virus and responded
    with reliable information.*'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.1 illustrates PharmaBot efficiently recognizing these intents.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F01_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1 PharmaBot efficiently detected informational intents from user queries.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '*When vaccine availability was imminent, the nature of customer questions changed
    dramatically. Suddenly, everyone had a slew of different questions:*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Will I be eligible for the vaccine?*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Can I get a vaccine appointment?*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*When can I get my second dose?*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Do I have to call for an appointment, or can I set it up here?*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Can I travel after my shot?*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PharmaBot was initially weak at understanding these questions, frequently
    responding, “Sorry, I’m not sure what you’re asking. Please rephrase your question.”
    Users were frustrated and dissatisfied, and more conversations ended up in the
    call center after failing in the bot. There was also an increase in immediate
    opt-outs, reflecting an apparent disconnect between user expectations and PharmaBot’s
    capacity to address the evolving landscape. MediWorld’s team set out to improve
    the bot, but they first had to agree on what “improve” meant.*'
  prefs: []
  type: TYPE_NORMAL
- en: Note  The need for continuous improvement has never been more critical, as evolving
    user expectations and technological advancements demand constant refinement and
    adaptation. Bridget van Kralingen quipped, “The last best experience that anyone
    has anywhere becomes the minimum expectation for the experience they want everywhere.”
    Improvement requirements may come from internal sources (such as support of new
    features) or external sources (where an event drives new questions never seen
    before).
  prefs: []
  type: TYPE_NORMAL
- en: Recognizing the need to improve in conversational AI is pivotal to ensuring
    its effectiveness and relevance. A virtual assistant is not a static solution;
    its performance must evolve with user behavior, business needs, and advancements
    in technology. Signs that improvements are necessary often emerge through key
    performance indicators (KPIs) such as low containment rates, high fallback intent
    usage, or frequent agent escalations. Planning practical improvements starts with
    building a cross-functional team, defining clear success criteria, analyzing outcomes,
    and implementing structured processes for issue management.
  prefs: []
  type: TYPE_NORMAL
- en: When deciding when to start improving your conversational AI, best practices
    recommend beginning as soon as you notice recurring problems, declining engagement
    rates, or unmet business goals. A proactive approach can prevent small problems
    from escalating into larger problems. Establishing regular review cycles ensures
    that improvements align with evolving user expectations and organizational objectives.
  prefs: []
  type: TYPE_NORMAL
- en: Start your improvement journey by planning a comprehensive data collection strategy
    even before the first deployment. Remember, just having log files doesn’t automatically
    reveal the pain points. It’s essential to be methodical in identifying trends
    and patterns across user interactions. Many teams tend to fix isolated problems
    without considering the overall volume or frequency of those problems. While it
    may seem productive to address one-off problems, this rarely leads to meaningful
    improvements in overall performance. By focusing on systemic problems with significant
    effect, you can ensure your efforts are always directed toward tangible progress,
    making you feel focused and committed.
  prefs: []
  type: TYPE_NORMAL
- en: Remember, measuring performance before and after deploying changes is equally
    important. Establish baseline metrics before implementing fixes, and compare them
    with post-deployment data to assess whether the changes delivered the expected
    improvements. If the results don’t align with your expectations, don’t worry.
    Analyze the root cause further and iterate on your solution to effectively address
    any gaps or unforeseen problems. This process will give you the reassurance and
    confidence that your efforts are leading to tangible progress.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Your cross-functional team
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'MediWorld recognized the critical role of its PharmaBot in providing timely
    and accurate customer support. A multidisciplinary team of conversational analysts,
    customer support experts, and data analysts came together to assess and enhance
    PharmaBot’s performance. This group aimed not only at addressing existing challenges
    but also proactively anticipating and meeting the evolving needs of the user base:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Developers at MediWorld focused on refining PharmaBot’s natural language processing
    capabilities. They found ways to enhance the chatbot’s understanding of user queries
    so it could provide precise and context-aware responses.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Simultaneously, lead call center agents shared valuable insights from the
    calls transferred to them, shedding light on common pain points and frequently
    asked questions.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*The MediWorld data analysts delved into user interaction data. They identified
    areas where the chatbot “failed” and categorized those failures by the last task
    attempted by the bot.*'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.2 shows the kinds of insights that each group brought to the table.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F02_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.2 The team identified areas for improvement using their diverse skills,
    setting the stage for an effective improvement plan.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Let’s look beyond the PharmaBot example and focus on teams typically involved
    in a conversational AI improvement plan. The specific roles, responsibilities,
    and team size can vary based on your organization’s size, its goals, and the complexity
    of the chatbot. In smaller projects, individuals may take on multiple roles. Chapter
    1 introduced a “dream team” for building conversational AI (figure 1.5). A similar
    diverse group is needed to improve and refine existing chatbots. While the structure
    of this team may differ across organizations, it generally consists of three key
    subteams, all working together.
  prefs: []
  type: TYPE_NORMAL
- en: First is the support and maintenance team for the chatbot. This team is tasked
    with analyzing and evaluating the chatbot’s performance. Additionally, they serve
    as technical subject matter experts (SMEs). They know the existing intents the
    chatbot handles, the training data for those intents, and the dialogue flows in
    the chatbot. They can implement code and technical changes. Their roles and tasks
    are outlined in table 3.1.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.1 The chatbot support and maintenance team
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Role | Tasks |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Data analyst/data engineer  | Analyzes user interactions and feedback to
    make informed recommendations regarding changes, fixes, and enhancements.  |'
  prefs: []
  type: TYPE_TB
- en: '| Chatbot developer/ conversational analyst  | Implements technical changes
    and enhancements to the chatbot. These may include new integrations (more of a
    developer role) or updates to the dialogues and actions of the chatbot (conversational
    analyst).  |'
  prefs: []
  type: TYPE_TB
- en: '| Quality assurance (QA) tester  | Validates that a change, fix, or enhancement
    produces the desired outcome and does not result in any unexpected or negative
    outcomes. Testing may be manual or involve automated testing tools.  |'
  prefs: []
  type: TYPE_TB
- en: '| Project manager  | Coordinates tasks; ensures that the continuous improvement
    process stays on schedule.  |'
  prefs: []
  type: TYPE_TB
- en: '| Other SMEs  | Provide specialized knowledge in specific areas of the chatbot
    ecosystem; they may be brought on board as needed. For example, security experts
    assess potential threats and recommend appropriate security measures or remediation
    strategies to ensure the chatbot remains secure and resilient against evolving
    risks.  |'
  prefs: []
  type: TYPE_TB
- en: The second subteam is business stakeholders. They collectively ensure that the
    chatbot improvements align with the broader organizational goals and the business
    needs. Business stakeholders ensure that the chatbot is technically proficient
    and aligned with organizational goals, user needs, and legal standards. This team
    is broken down in table 3.2.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.2 The chatbot’s business stakeholders
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Role | Tasks |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Executive leadership  | Involved in aligning the improvements or the priorities
    of the improvements with overall business strategies  |'
  prefs: []
  type: TYPE_TB
- en: '| Customer service  | Responsible for the business processes and workflows
    that the bot is addressing  |'
  prefs: []
  type: TYPE_TB
- en: '| Product manager (of the chatbot)  | Responsible for overseeing the chatbot’s
    development and strategic direction, ensuring it meets business objectives  |'
  prefs: []
  type: TYPE_TB
- en: '| IT department  | Provides technical support and infrastructure for the chatbot’s
    development, deployment, and maintenance  |'
  prefs: []
  type: TYPE_TB
- en: '| Operation manager  | Collaborates to integrate the chatbot into operational
    processes, streamlining workflows  |'
  prefs: []
  type: TYPE_TB
- en: '| Legal and compliance teams  | Ensure the improvements comply with industry
    regulations and legal requirements  |'
  prefs: []
  type: TYPE_TB
- en: The final subteam is the governance team. Their role is to ensure that the chatbot’s
    deployment, use, and continuous improvement align with organizational policies,
    standards, and ethical considerations. They are identified in table 3.3.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.3 The chatbot’s governance team
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Role | Tasks |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Corporate ethics/compliance focal  | Addresses ethical concerns about the
    chatbot’s behavior and decision-making as well as AI model risk management. They
    also ensure that their guidelines for responsible AI are followed through the
    improvement phase.  |'
  prefs: []
  type: TYPE_TB
- en: '| Governing executive team  | Has the final say on prioritizing the system
    roadmap, backlog, and all costs (support or business team) associated with the
    system.  |'
  prefs: []
  type: TYPE_TB
- en: Having a diverse and cross-functional improvement team ensures that different
    perspectives and expertise contribute to the development and oversight of the
    chatbot initiative. Regular meetings, clear communication channels, and documentation
    of governance policies are essential for the team’s effectiveness. Again, the
    specific stakeholders involved may vary based on the nature and scope of the project.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Think about your last chatbot implementation, and list all the stakeholders
    you had. Discuss the stakeholder perspectives on the common goal of improving
    the chatbot and how this goal aligns with their specific objectives. Consider
    the potential conflicts between stakeholder interests and strategies for resolving
    them.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Alternatively, use MediWorld’s PharmaBot as an example, and consider the various
    stakeholders and their goals.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 3.3 Driving to the same goal
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Even within a single improvement team, different members may have conflicting
    priorities about what should be addressed first. Consider the following scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: '*When the PharmaBot team first met, they couldn’t agree on where to start.
    Everyone brought their “must-fix” lists. Some were hunches, some were informed
    by reading a few transcripts, and some came from detailed analysis. The team aligned
    on understanding the frequency of the problems: Do they come up in every conversation,
    or are they one-offs? Issue frequency was a key component in prioritizing fixes
    and enhancements, helping MediWorld enhance the performance of its chatbot.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Developers and data analysts advocated for refining PharmaBot’s natural language
    processing abilities, analyzing recent interactions to identify areas for improvement
    in understanding complex and context-dependent questions. Meanwhile, the lead
    call center agents emphasized the need for PharmaBot to offer more detailed and
    empathetic responses, focusing on recurring user concerns they had encountered.*'
  prefs: []
  type: TYPE_NORMAL
- en: A data-driven approach helps with prioritization. Addressing the most common
    pain points will lead to an immediate and tangible improvement in the overall
    user experience. Figure 3.2 demonstrated how multiple team members can contribute
    diverse observations and insights. Each member brought a unique perspective from
    their respective roles and expertise.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.1 *Revisit business goals*
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Conversational AI improvement team members must agree on the common goals of
    the improvement. The first critical step is reaching a consensus on what success
    means—the team must revisit the original business objectives that prompted the
    implementation of the chatbot. For instance, a question-answering bot must consistently
    respond quickly and accurately to user questions. A process-oriented bot must
    help users efficiently achieve their goals, like scheduling appointments or checking
    accounts. A routing agent must direct users to the place or specialist that can
    fulfill their needs based on their inquiry. Evaluating chatbot performance against
    these goals involves metrics such as response accuracy, user satisfaction, and
    the bot’s ability to handle a broad range of relevant topics and use cases.
  prefs: []
  type: TYPE_NORMAL
- en: As the business landscape evolves, adaptability becomes paramount. Changes in
    user expectations or technological advancements may necessitate enhancements or
    strategic shifts to maintain optimal chatbot performance. Therefore, the team
    must continuously reassess and refine the chatbot strategy, ensuring it remains
    aligned with the overarching organizational and user objectives. This iterative
    process caters to the evolving needs of the business and its users.
  prefs: []
  type: TYPE_NORMAL
- en: From business outcomes to metrics
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Defining the right metrics starts with understanding how business goals evolve
    over time. Consider the following scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: '*The PharmaBot team needed to align their efforts with the importance of efficient
    vaccine distribution and accessibility. While the original business goal was to
    answer questions and reduce the burden on their call centers, the business goals
    have changed to distributing vaccines effectively and automating the appointment-making
    process, which require different metrics.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'When in doubt, consider your users—what do they need, and how do those needs
    drive business? What were the original business goals? What did users want? How
    are the two aligned? Recognize that these answers may shift over time. Figure
    3.3 shows PharmaBot’s first business goal: providing accurate and up-to-date information
    about the new pandemic. Accuracy was the key metric.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F03_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.3 PharmaBot started as a simple Q&A bot. Many question varieties got
    the same answer.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Once a stable base was in place, the PharmaBot team added complexity and intelligence
    to the Q&A bot. They detected entities (contextual elements relevant to an intent)
    to provide more targeted answers to their users and improve accuracy, as figure
    3.4 demonstrates.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F04_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.4 Q&A got more complex by detecting entities in user utterances, leading
    to more specific answers within a common intent.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Then external influences changed the business objectives again. Vaccine availability
    shifted the nature of the bot. Instead of interacting with a pure Q&A about the
    virus, users wanted to act directly through the bot to schedule vaccine appointments.
    This required process-oriented flows to collect multiple pieces of information.
    Figure 3.5 shows the start of this process flow.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F05_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.5 Some question types do not have a single static answer but require
    a full process flow to satisfy.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: These new capabilities brought complexity. Automating testing and vaccine appointments
    required integration with scheduling systems and databases. This brought heightened
    emphasis on security and privacy measures. Protecting users’ personal information,
    adhering to healthcare regulations, and ensuring secure transactions became paramount.
  prefs: []
  type: TYPE_NORMAL
- en: Not all conversational AI solutions have to deal with this evolution, at least
    not at the pace PharmaBot required. Managing a chatbot’s evolution requires thoughtful
    consideration of the costs and benefits associated with each aspect of the chatbot’s
    transformation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The primary business goals for any conversational AI solution revolve around
    enhancing overall business outcomes. Every business has a goal or goals for the
    conversational system, which comes down to two key factors: revenue generation
    and cost reduction. These goals translate into metrics such as increased conversion
    rates, higher average order value (AOV), and enhanced customer lifetime value
    (CLV) for revenue growth. On the cost side, metrics like reduced average handling
    time (AHT), lower operational costs, and improved first-contact resolution (FCR)
    reflect cost savings. Organizations expect a measurable return on their investment
    (ROI), and these performance metrics guide continuous improvement efforts, aligning
    the conversational AI’s success directly with key business outcomes.'
  prefs: []
  type: TYPE_NORMAL
- en: The business goals must be translated into measurable metrics. This allows a
    quantifiable assessment of how well the conversational AI meets its goals. The
    examples in table 3.4 demonstrate how businesses in various industries can define
    measurable metrics aligned with their specific goals.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.4 Sample metrics derived from business goals in various industries
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Business goal | Resulting metrics | Bot type |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Increase online sales, and reduce customer service costs.  | Percentage of
    checkouts completed by the chatbot without human intervention: Achieving 75% of
    automated checkouts, leading to a reduction of 100,000 customer service inquiries
    per day, resulting in a daily cost savings of $500,000\.  | Question answering  |'
  prefs: []
  type: TYPE_TB
- en: '| Improve customer support efficiency, and minimize service disruptions.  |
    Percentage of inquiries successfully routed to the appropriate department or specialist:
    90% of inquiries directed to the relevant support team without the need for manual
    intervention, leading to a decrease of 40,000 support tickets per day, resulting
    in a daily cost savings of $700,000\.  | Routing agent  |'
  prefs: []
  type: TYPE_TB
- en: '| Enhance booking experience, and decrease support costs.  | Percentage of
    automated booking confirmations without agent intervention: Achieving 70% of automated
    booking confirmations, reducing 80,000 support inquiries per day, resulting in
    a daily cost savings of $640,000\.  | Process- oriented  |'
  prefs: []
  type: TYPE_TB
- en: '| Improve patient engagement, and optimize appointment scheduling.  | Percentage
    of appointments scheduled autonomously by the virtual assistant: 90% of appointments
    are booked autonomously, reducing 30,000 manual scheduling tasks per day, resulting
    in a daily cost savings of $700,000\.  | Process- oriented  |'
  prefs: []
  type: TYPE_TB
- en: Conversational metrics need clear links to business value to prove a return
    on investment. Metrics like call center deflection and routing accuracy reduce
    costs. Metrics like customer satisfaction lead to increased revenue when satisfied
    customers consume more services. The PharmaBot team achieved both cost savings
    and revenue growth by automating appointment scheduling.
  prefs: []
  type: TYPE_NORMAL
- en: Additional business drivers
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Beyond aligning with the core business goals discussed in the previous section,
    organizations should consider additional factors that drive value from conversational
    AI. Successful AI implementations do more than just support high-level objectives—they
    actively enhance customer engagement, optimize sales strategies, and reduce operational
    costs.
  prefs: []
  type: TYPE_NORMAL
- en: Conversational AI can strengthen customer interactions, guide sales, and suggest
    relevant products. Analyzing chatbot-driven conversion rates is crucial for refining
    strategies. Businesses that explore AI-driven features for upselling and cross-selling
    can maximize revenue opportunities. From an operational perspective, conversational
    AI helps by handling routine tasks, freeing human agents to focus on complex activities.
    Automating processes improves efficiency, reduces support costs, and enhances
    satisfaction with quicker responses.
  prefs: []
  type: TYPE_NORMAL
- en: A thorough analysis can uncover opportunities for improvement and for optimizing
    chatbot performance. As technology evolves, businesses should expand chatbot functions
    for ongoing cost reduction and operational excellence.
  prefs: []
  type: TYPE_NORMAL
- en: Competitor analysis, evaluating features like natural language understanding
    and personalized experiences, can guide continuous improvement. Regular updates
    enable adaptation to change in the competitive landscape, driving innovation for
    positive business outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.2 Effectiveness
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When determining improvement priorities, another key factor to consider is the
    chatbot’s effectiveness. Does the chatbot do what it was intended to do? While
    the concept of “effectiveness” is simple (does it work as expected?), it goes
    beyond task completion. It involves providing a positive and efficient experience
    for users.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s continue with our scenario, where the team is now looking at their dashboard
    showing chatbot metrics. Most chatbot development platforms have a simple analytics
    dashboard containing KPIs summarizing how users engage with the chatbots. These
    dashboards typically contain data on the number of conversations, chatbot confidence,
    and conversation duration. They may also include the most frequently asked questions
    or intents.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.6 shows the analytics dashboard created for PharmaBot. While it shows
    some of the KPIs, it does not express PharmaBot’s effectiveness. The total number
    of conversations helps us understand traffic, but it does not help assess how
    many people successfully completed the chats or how far they went.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F06_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.6 PharmaBot’s basic analytic dashboard shows a usage summary but cannot
    give insight into what users like (or don’t like) about the bot.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '*The team sought to determine the current assistance rate. Basic analytics
    gave them information on total inquiries per day, but they needed help figuring
    out how many of these were successful. The team needed to go beyond the mere quantity
    of conversations. Everyone knew that user demand was increasing. Was PharmaBot
    meeting the new demand? They needed to figure out how to measure the bot’s effectiveness
    and find ways to optimize its performance. The team found that 45% of all conversations
    transferred to the call center. This “containment” metric influenced the cost
    to the business. What could they do with this number?*'
  prefs: []
  type: TYPE_NORMAL
- en: In the PharmaBot team’s case, one key metric for measuring effectiveness was
    containment. *Contained conversations* are when the chatbot can fully handle a
    user query on its own; *uncontained conversations* require a human to be involved.
    The *containment rate* is calculated as the number of contained conversations
    divided by the number of total conversations. This metric provides a high-level
    measure of chatbot performance, as illustrated in figure 3.7.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F07_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.7 Basic daily dashboard showing a simple business metric: containment.
    This metric is tracked daily but still does not give deep insights into bot performance.'
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'PharmaBot’s dashboard implies a simple definition of success: “Contained calls
    are successful.” This mental model is summarized in figure 3.8\. However, while
    containment is a valuable metric, it does not tell explain why users succeed (or
    fail) when interacting with the bot. A more detailed analysis is needed to gain
    deeper insights.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F08_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.8 The simplest outcome definition. This does not give insight into
    how the bot can be improved.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Conversation outcomes
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To better understand how conversation outcomes affect chatbot improvement,
    let’s go back to our example scenario. The PharmaBot maintenance team needed to
    move beyond high-level performance metrics and analyze the actual conversation
    outcomes. Containment alone didn’t capture the full picture—it only told them
    whether or not a conversation stayed with the bot. But what really happened in
    those conversations? Here’s how they conducted an in-depth review of the conversations:'
  prefs: []
  type: TYPE_NORMAL
- en: '*The team dived into a sea of transcripts to understand what happened in the
    conversations. How did they end? The team discovered a myriad of endings—successful
    completions, abandoned conversations, and a perplexing number of transfers.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*The data analyst observed different flavors of success. First, the expected
    case where the PharmaBot responds well to the query and the user is satisfied.
    Second, there are handoffs to the call center due to business rules, like when
    the user lives in a state where MediWorld cannot do SMS confirmations. These handoffs
    are also successful, as they align with what PharmaBot set out to do: collect
    required information so a human specialist doesn’t have to. The team agreed that
    they needed to document these two kinds of cases separately. They labeled them
    as “Automated Resolution” and “Intentional Transfer.”*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Then there were definite failure scenarios. Users asked for a human agent
    after the bot misunderstood them. The bot also automatically transferred users
    when it misunderstood them consecutively. And some users disconnected midway through
    appointment scheduling.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Lastly, the PharmaBot team found conversations where the users didn’t even
    try. Users were either silently disconnecting after the bot’s greeting or starting
    the conversation with the utterance “agent.” One team member remarked, “Perhaps
    there’s a psychological factor at play here: some users don’t want to engage with
    a bot. Let’s separate these conversations too.”*'
  prefs: []
  type: TYPE_NORMAL
- en: '*The team finally developed a nuanced categorization system: Success (automated
    resolution and intentional transfer), Failure (abandonment and escalation), Bot
    not wanted (immediate disconnect and immediate escalation).*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Once the categorization system was in place, counting the conversations in
    each bucket was easy. The PharmaBot team was starting to really understand their
    bot’s performance.*'
  prefs: []
  type: TYPE_NORMAL
- en: Defining detailed conversation outcomes related to your metrics will give you
    insights into your solution’s performance. Conversation outcomes describe how
    user interactions with the chatbot conclude, categorizing whether the chatbot
    resolved the query, required human assistance, or resulted in an incomplete session.
    Defining these outcomes is critical to assessing and improving your solution against
    your business goals. Once your solution is deployed, analyze your conversation
    logs, and classify them against the outcome model.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3.9 shows a new detailed outcome model. It starts with containment on
    the left, and then it breaks down contained (and non-contained) outcomes with
    detailed reasons. Finally, these reasons are mapped back to success and failure
    categories. The reasons help us understand what went right and wrong in the bot.
    For instance, conversations may not be contained due to “failure”: maybe the user
    opted out or the bot repeatedly didn’t understand. Some conversations are intentionally
    transferred to humans following the underlying business process—those aren’t failures.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F09_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.9 Breaking down why conversations are not contained gives more insight
    into bot performance and shows you where your bot needs improvement. One way to
    achieve this is by using detailed outcome classifications, which define the specific
    results of chatbot interactions. These classifications categorize conversations
    based on their resolution, user experience, and next steps.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Now that we’ve introduced the idea of a granular outcome model, considering
    how (where and why) a conversation might end, let’s look at the same metrics dashboard
    we saw in figure 3.7\. Instead of looking at 45% containment, we can better understand
    the conversations. On the dashboard of figure 3.10, we replaced the containment
    rate chart with a success-rate chart, indicating success/failure/not wanted as
    the highest-level categories.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F10_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.10 Enhancing the summary dashboard with a success rate. Not all contained
    calls are successful; not all transferred calls are failures.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In fact, you may want to illustrate the details of the outcomes as well. In
    figure 3.11, we show what this might look like. This approach enables you to quickly
    break down high-level outcomes into detailed outcomes, which could help you get
    stakeholder buy-in on improvements too.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F11_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.11 The detailed outcome model depicts conversation outcomes and outcome
    details aggregated over a set time period. This provides much greater insight
    into bot performance than a binary “contained or not contained” model.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The detailed outcome model’s strength comes from its flexibility. Every conversational
    AI project can define its own unique outcome categorization. The model depicted
    in figure 3.11 is a useful sample implementation. As always, adjust this model
    for your needs. For example, if your chatbot does not have a human handoff, you
    can omit the escalation and transfer outcomes.
  prefs: []
  type: TYPE_NORMAL
- en: Here are some suggested categorizations for common types of conversational AI
    solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'For Q&A bots:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Success—Conversation completion scenarios:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automated resolution—The Q&A bot successfully answers the user’s inquiry or
    provides relevant information without human intervention.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Failure—The interaction fails to achieve the desired outcome:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abandoned—The user leaves the conversation before getting a good answer, possibly
    due to frustration or dissatisfaction with the bot’s responses.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Escalated—The Q&A bot does not understand the user, and the interaction is escalated
    to a human agent for further assistance. This could occur by user request, or
    the bot may automatically escalate after multiple consecutive misunderstandings.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chatbot not wanted:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Immediate disconnect—The user exits the conversation without ever sending a
    message to the bot.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Immediate escalation—The user’s first utterance to the bot is a request for
    a human agent.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For a transactional or process-oriented bot:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Success—Conversation completion scenarios:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automated resolution—The process-oriented bot successfully completes the user’s
    intended task, such as booking an appointment, without human intervention.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Intentional transfer—If required by business rules, the bot transfers the interaction
    to a human agent, even though no “errors” were encountered.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Failure—The interaction fails to achieve the desired outcome:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abandoned—The user abandons the conversation midway through the transaction,
    possibly due to complexity or confusion with the bot’s interface.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Escalated—The bot starts but cannot complete a process flow due to misunderstanding
    the user or the user’s request for a human agent.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chatbot not wanted:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Immediate disconnect—The user exits the conversation without ever sending a
    message to the bot.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Immediate escalation—The user’s first utterance to the bot is a request for
    a human agent.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For a routing agent:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Success—Conversation completion scenarios:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Intentional transfer—The routing agent successfully directs the user to the
    correct department or specialist, potentially passing all information collected
    so far. A routing agent may have 0% containment and be working very well!
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Failure—The interaction fails to achieve the desired outcome:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abandoned—The user exits the conversation before being routed by the bot.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Escalated—The routing agent cannot gather enough information to route the user,
    either through misunderstanding or a user request for a human agent.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chatbot not wanted:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Immediate disconnect—The user exits the conversation without ever sending a
    message to the bot. The user cannot be automatically routed.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Immediate escalation: The user’s first utterance to the bot is a request for
    a human agent, bypassing all automated routing.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: When you categorize conversations like this, the number of conversations in
    each category helps you assess the effectiveness of the chatbot implementation
    and identify areas for improvement.
  prefs: []
  type: TYPE_NORMAL
- en: The detailed outcome model should be integrated with the conversational design.
    A great method is defining milestones for each of the bot’s “happy path” questions.
    Figure 3.12 shows this design for PharmaBot. The “Schedule appointment” milestone,
    shown in the shaded box, signifies a key step in which the bot completes the scheduling
    process. “Help with anything else?” is also shaded, indicating that the bot is
    ready to assist further after completing a primary task.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F12_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.12 High-level design of PharmaBot with milestones for significant parts
    of the conversation. “Schedule appointment” and “Help with anything else?” are
    both marked as successful paths.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The FAQ intents have only one milestone (the FAQ response), whereas the process
    flow for appointments gathers multiple data points. The milestones that declare
    successful completions should be marked.
  prefs: []
  type: TYPE_NORMAL
- en: The detailed outcome model is most powerful when it’s overlaid with the design.
    When each conversation has an outcome and a “last milestone,” you can quickly
    find insights. In figure 3.13, we see PharmaBot’s metrics over time for failed
    conversations, including the last deployment date.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F13_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.13 When the outcome model and conversation design are overlaid, insights
    become apparent. This chart breaks down failed conversations by the last step
    before failure, helping identify where users struggle most. The different categories—such
    as appointment scheduling, intent detection, and zip code entry—show their relative
    contributions to overall failures over time. The spike after “Changes deployed”
    highlights the effect of recent updates, offering insights into areas needing
    further optimization.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The PharmaBot team can further drill down into the failed conversations to view
    the detailed outcomes of abandoned and escalated. Combining the outcome model
    and the conversation design can jumpstart your data-driven analysis. It can tell
    you where to start your investigation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The detailed outcome model in figure 3.11 provides deeper insights into user
    experience by revealing where and why conversations fail. In this case, the outcome
    is failure, and the primary reason is user escalation. However, looking at the
    specific points where users escalated—the last step before failure—provides actionable
    insights. The breakdown in the chart highlights key escalation points: during
    appointment scheduling, intent detection, member ID collection, and zip code entry.
    After changes were deployed, failures at the intent detection step dropped significantly,
    while failures in member ID and zip code collection saw slight declines. However,
    appointment scheduling failures spiked, indicating a new area of friction. This
    level of analysis allows the team to prioritize improvements effectively, ensuring
    that their fixes target the most pressing user pain points. While containment
    rate is often used as a high-level measure of effectiveness, it does not tell
    the full story—some containments may still result in poor user experiences, and
    some transfers may be necessary for a successful outcome. The outcome model in
    figure 3.13 helps the conversational AI team distinguish between these cases and
    refine the bot accordingly.'
  prefs: []
  type: TYPE_NORMAL
- en: Customer satisfaction
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the outcome model, we infer customer satisfaction through conversational
    outcomes. This is a quick method, but it’s indirect and can leave out some details.
    It can be useful to be more direct with customer satisfaction.
  prefs: []
  type: TYPE_NORMAL
- en: Customer satisfaction can be measured by gathering direct feedback from users.
    Thumbs up or down or a numeric satisfaction score are standard. The only drawback
    with these metrics is that the user response rate is often low—many users hate
    giving feedback—although unsatisfied users are more likely to take the chance
    to complain.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can implement surveys after the chatbot concludes an interaction. The survey
    could include questions about ease of use, helpfulness, and overall satisfaction
    with the bot. In addition, net promoter score (NPS) surveys may also be presented
    to users. Keep the survey brief: the longer the survey, the less likely users
    are to complete it.'
  prefs: []
  type: TYPE_NORMAL
- en: You can also assess customer satisfaction by reviewing a sample of conversations.
    The review can include chat logs or summaries from human agents who completed
    the conversation. These logs and summaries may even be categorized using large
    language models. Table 3.5 shows the types of feedback you can look for in each
    type of conversational outcome.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.5 Linking feedback to conversation outcome details
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Conversation outcome details | User feedback | Notes and caveats |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Automated resolution (success)  | Positive feedback or none  | Users may
    give positive feedback to conclude an interaction (“thanks!”). But this is unlikely:
    most users disconnect once they get what they need.  |'
  prefs: []
  type: TYPE_TB
- en: '| Transfer (success)  | Positive verbal feedback or no feedback. Not in chatlogs.  |
    Users may give verbal feedback to the human agent about the bot, not to the chatbot
    directly.  |'
  prefs: []
  type: TYPE_TB
- en: '| Abandoned (failure)  | Negative feedback or none (disconnection before a
    process completes)  | User’s last comment to the bot may have negative sentiment
    (“I hate this!”). But many users won’t bother expressing their frustration—they
    just disconnect.  |'
  prefs: []
  type: TYPE_TB
- en: '| Escalated by user (failure)  | Negative feedback  | Users who request an
    agent mid- process flow are unhappy (“get me to an agent!”).'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Escalated by bot (failure)  | None  | When the bot initiates the escalation,
    we can’t prove the user was unhappy, but we could reasonably assume so.  |'
  prefs: []
  type: TYPE_TB
- en: '| Immediate disconnect (chatbot not wanted)  | No feedback provided (no engagement)  |
    Users who immediately disconnect may hate all chatbots, may hate your chatbot,
    or may have connected to it by accident. You can’t know for sure.  |'
  prefs: []
  type: TYPE_TB
- en: '| Immediate escalation (chatbot not wanted)  | No feedback provided, or verbal
    negative feedback is given expressing desire for human assistance instead of chatbot
    use  | Users who immediately escalate may hate all chatbots, may hate your chatbot,
    or may just prefer humans. You can’t know for sure.  |'
  prefs: []
  type: TYPE_TB
- en: 3.3.3 Coverage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As part of improving chatbot effectiveness, identifying gaps in what the bot
    can handle (or, in other words, its *coverage*) is just as important as addressing
    escalations. In the ongoing analysis, it became clear that some user questions
    weren’t being misunderstood—they simply weren’t covered by the bot’s existing
    knowledge. The scenario continues as the team uncovers these gaps and works to
    expand PharmaBot’s capabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '*The team prioritized tackling escalations first, since they have the biggest
    effect on the metrics. They analyzed transcripts from escalated conversations,
    and patterns started to emerge. Users often escalated right after the bot didn’t
    understand them. The data analyst cross-referenced these instances against the
    dialogue flow and suggested where they could improve the bot’s natural language
    processing capabilities. During this analysis, they found several questions that
    PharmaBot was not equipped to answer:*'
  prefs: []
  type: TYPE_NORMAL
- en: '*“I heard about rare side effects. How can I distinguish between post-vaccine
    symptoms and something more serious that requires medical attention?”*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*“If I missed the recommended second dose of my COVID-19 vaccine by a few days,
    will it still be effective, or do I need to start over?”*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*“I’m pregnant, and I’m unsure about getting the COVID-19 vaccine. Can you
    provide information on the safety and potential benefits for pregnant individuals?”*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*“I’ve been diagnosed with an autoimmune condition. Can I still receive the
    COVID-19 vaccine, and are there any additional precautions I should take?”*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*“I’ve read conflicting information about the long-term effects of COVID-19
    vaccines. What is known about their safety over an extended period, and are there
    ongoing studies?”*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*For questions like these, PharmaBot responded with “Sorry, I do not understand,”
    even after users tried to rephrase their questions. The team looked for clusters
    of questions with similar characteristics to see what the bot should be trained
    on next. Along with other intents, a group of inquiries related to vaccine safety
    emerged.*'
  prefs: []
  type: TYPE_NORMAL
- en: Coverage measures how many user questions the chatbot attempts to answer effectively.
    A chatbot with low coverage either lacks training data for key topics or struggles
    with overlapping and ambiguous intents, where similar questions confuse the model
    and prevent it from confidently selecting the correct response.
  prefs: []
  type: TYPE_NORMAL
- en: The team must analyze user interactions to improve coverage, identifying gaps
    where the chatbot fails to provide meaningful responses. This process involves
    assessing transcripts, tracking failed queries, and pinpointing recurring user
    needs currently unsupported. Addressing these gaps may require refining training
    data, restructuring intent classification, or introducing alternative approaches
    such as retrieval-augmented generation (RAG).
  prefs: []
  type: TYPE_NORMAL
- en: 'Several methods can enhance chatbot coverage, each addressing different challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: Chapter 5 explores improving weak understanding by refining training data, addressing
    missing intents, and optimizing labeling strategies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chapter 6 discusses how to bypass intent limitations using retrieval-based techniques
    combined with generative AI (RAG) to provide more dynamic and informed responses.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chapter 7 demonstrates how generative AI can generate additional training and
    testing data to expand the chatbot’s ability to handle diverse queries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regardless of the approach, improving chatbot coverage requires continuous analysis
    of real-world interactions. Examining user utterances, identifying common failure
    points, and iterating on the bot’s design ensures it evolves to meet users’ needs
    more effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Consider the following chatbots and their business goals. Devise suitable metrics
    and goals for each chatbot type to evaluate their effectiveness and performance:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Bot 1—Customer support bot for an e-commerce website (Q&A bot)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Bot 2—Banking bot for account management (transactional or process-oriented
    bot)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Bot 3—Customer service bot for a telecom company (routing bot)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Review the following scenarios found in the PharmaBot chatlogs. Based on the
    PharmaBot’s response to each scenario, assign an outcome from the model. Once
    you’ve assigned outcomes to each scenario, reflect on any patterns or trends you
    observe regarding the bot’s performance and areas for potential improvement. Recall
    that the conversation outcomes are success, failure, and chatbot not wanted. The
    outcome details are automated resolution (success), intentional transfer (success),
    abandoned (failure), escalated (failure), immediate disconnect (chatbot not wanted),
    and immediate escalation (chatbot not wanted):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Scenario 1
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Scenario 2
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Scenario 3
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Scenario 4
  prefs:
  - PREF_OL
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 3.4 Identifying and resolving problems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Identifying problems is crucial to continuously improving a conversational AI.
    The chatbot team needs a methodology for working through problems, including how
    to find problems, how to reason through them as a group, and how to determine
    when they are resolved. This methodology will allow the team to work toward a
    common goal.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.1 Finding problems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The best way to start finding problems is by examining trends in your conversation
    outcomes. It’s great to see successful conversations, but focus on the failed
    and “bot not wanted” conversations. Dig into the outcomes that have upward trends.
    As shown earlier, these outcomes are most insightful when overlaid on your conversational
    design. What was the last thing the user did before the negative outcome? Figure
    3.14 dashboard helped the PharmaBot team.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F14_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.14 A dashboard that breaks down an outcome by the last step taken,
    observed over time.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Ideally, your analysis tool can count and plot conversations by
  prefs: []
  type: TYPE_NORMAL
- en: Conversation outcome
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Last step taken in the conversation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Date and/or time of conversation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Your conversational AI platform may already track these data points. Other
    platforms may need to be instrumented by adding context variables into key parts
    of your dialogue flow. With these metrics in place, teams can uncover unexpected
    user behaviors that affect chatbot performance. For example, when the PharmaBot
    team analyzed escalated conversations, they discovered a surprising pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '*The PharmaBot team drilled into escalated conversations. They found many failures
    when PharmaBot asked users if their appointment was for vaccines or testing. Many
    users replied “yes”—a response that didn’t align with the expected format.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*Recognizing the importance of understanding user behavior, the team realized
    that the bot’s inability to interpret this ambiguous “yes” response was causing
    frustration among users. Some even said “yes” again when PharmaBot repeated the
    question. This was a surprising source of both abandoned and escalated conversations.*'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once a problem area is found, you can start designing a solution. The design
    is affected by how many ways the problem is encountered and can be addressed.
    In the “unexpected yes” scenario, there are two ways out: handle the “yes,” or
    try to get users to stop saying it.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at a few more ways to find problems.
  prefs: []
  type: TYPE_NORMAL
- en: Qualitative problem exploration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'While metrics and conversation logs provide valuable insights, some chatbot
    problems are difficult to detect through quantitative analysis alone. Launching
    a qualitative improvement effort by collecting and analyzing user feedback allows
    you to uncover more user pain points. Let’s look at how the PharmaBot team went
    about their surveys:'
  prefs: []
  type: TYPE_NORMAL
- en: '*To uncover deeper user frustrations, the PharmaBot team launched a qualitative
    improvement effort by collecting and analyzing direct user feedback. They encouraged
    users to share detailed descriptions of their challenges and expectations through
    a survey. Once the feedback was collected, the team categorized it to identify
    common pain points, as shown in table 3.6.*'
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.6 Survey responses leading to identified pain points (part 1)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| User | Survey response | Identified problem |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1  | I tried asking about vaccine eligibility in different states, but the
    bot couldn’t provide clear information. Not knowing if I qualify for the vaccine
    when I plan to travel is frustrating. The responses seemed generic and didn’t
    address the complexity of eligibility criteria in various locations  | PharmaBot
    understood the basic intent (eligibility) but failed to provide state-specific
    information. The chatbot did not consider the user’s location or the state they
    inquired about, leading to an unhelpful response.  |'
  prefs: []
  type: TYPE_TB
- en: '| 2  | I attempted to schedule a vaccine appointment, but the process felt
    confusing. The bot’s instructions were unclear, and I felt unsure if my appointment
    was successfully booked. It would be helpful if the bot could provide more guidance
    throughout the scheduling process.  | The scheduling workflow lacked clarity,
    causing users to feel uncertain about whether their appointment was successfully
    booked.  |'
  prefs: []
  type: TYPE_TB
- en: '| 3  | (No survey response given; the user left the chat)  | Overcomplicated
    steps discouraged users from completing the process. User 3 did not get to the
    survey.  |'
  prefs: []
  type: TYPE_TB
- en: Unlike conversation logs, qualitative feedback provides direct insight into
    user frustrations—you don’t have to infer what went wrong. Combined with corresponding
    conversation transcripts, this feedback creates a clearer picture for the improvement
    team, making diagnosing and addressing chatbot deficiencies easier.
  prefs: []
  type: TYPE_NORMAL
- en: Recruiting users to provide actionable feedback can significantly enhance chatbot
    performance and user satisfaction. However, most users are reluctant to leave
    feedback. Providing small incentives or even a simple, genuine thank-you can encourage
    participation. If feedback is a key part of your improvement strategy, consider
    implementing a system that creates a win-win situation for both users and your
    team.
  prefs: []
  type: TYPE_NORMAL
- en: WARNING  The provided examples offer valuable insights into specific user challenges,
    but they may not be statistically significant. Don’t rush into solutions based
    on isolated instances. Look for repeated occurrences of the identified problems
    to gauge the scale and effect of each one.
  prefs: []
  type: TYPE_NORMAL
- en: Quantitative evaluation for issue discovery
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'While qualitative feedback helps uncover user frustrations, it can also reveal
    measurable, functional problems. Challenges like slow response times or confusing
    dialogue flows can be quantified through conversation logs, which help teams diagnose
    problems and prioritize improvements. Let’s continue with our scenario to see
    what other problems were found:'
  prefs: []
  type: TYPE_NORMAL
- en: '*In addition to finding descriptive* *problems**, the PharmaBot team uncovered
    some addressable functional* *problems**. A sample* *problem* *is shown in table
    3.7.*'
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.7 Survey responses leading to identified pain points (part 2)
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| User | Survey response | Identified problem |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 4  | It took the bot nearly 5 minutes to tell me about vaccine appointment
    availability. The delay was quite inconvenient, especially when trying to plan
    my schedule. A faster response would have been more helpful. I went to the bot
    to avoid being on hold!  | Excessive response time frustrated users and diminished
    the chatbot’s value as a faster alternative to traditional customer support.  |'
  prefs: []
  type: TYPE_TB
- en: Problems like this can be identified by analyzing the time taken for each step
    in a conversational log. You can track the average and maximum times taken at
    each step. Outliers may indicate poorly performing backend systems or confusing
    questions that users spend a lot of time thinking about.
  prefs: []
  type: TYPE_NORMAL
- en: This analysis could even be done on a subset of conversations. For instance,
    a slowly responding API is more likely to cause users to disconnect. Dive into
    the abandoned conversations, reviewing what the users were saying and how long
    the individual steps took. This kind of analysis can be done without asking users
    directly for feedback.
  prefs: []
  type: TYPE_NORMAL
- en: By identifying specific challenges associated with the conversation flow, analysts
    can target improvements in the conversational system effectively.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4.2 Group review
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*After reviewing their conversational outcome metrics and user feedback, the
    PharmaBot team compiled a list of concrete* *problems**. Now they must build their
    improvement plan, starting with prioritizing the* *problems**.*'
  prefs: []
  type: TYPE_NORMAL
- en: Triaging the problems
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'With these metrics in place, teams can uncover unexpected user behaviors that
    affect chatbot performance. For example, when the PharmaBot team analyzed escalated
    conversations, they discovered a surprising pattern:'
  prefs: []
  type: TYPE_NORMAL
- en: '*The most critical* problem *identified in PharmaBot was the frequent misunderstanding
    of user queries, particularly in differentiating those about COVID-19 testing
    and vaccine-related appointments. Users got frustrated when the bot didn’t understand,
    frequently ending conversations in abandonment or escalation. The call center
    agents agreed that they heard this* problem *when listening to frustrated users.
    Analytics confirmed the high volumes of this* problem*.*'
  prefs: []
  type: TYPE_NORMAL
- en: '*The team agreed to address this high-priority problem. The business goal was
    to complete setting up appointments without human agent intervention. They had
    found a recurring pattern of why appointment completion failed: the bot was confused
    about what type of appointment the user wanted, and users felt misunderstood—many
    of the transactions failed. The bot caused pain points of both not understanding
    and being too complex.*'
  prefs: []
  type: TYPE_NORMAL
- en: To move forward after finding problems, teams must systematically evaluate and
    prioritize the problems based on their perceived value and expected effect on
    the system. This involves assessing factors such as how frequently the problem
    occurred, the cost of implementing a fix, and the potential benefits of resolving
    the problem. By taking a structured approach to prioritization, they can ensure
    that improvements deliver the most value with the resources available. In the
    PharmaBot scenario, the highest priority was given to fixing the misunderstanding
    around appointment types, as this directly affected the ability to complete the
    booking workflow, a core business objective. Figure 3.15 illustrates a sample
    assessment of a problem. For a more thorough depiction, insights might include
    the volume of the problem, conversational outcomes, affected user complexity of
    remedy, other affected flows, and more.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F15_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.15 Analysis of an increase in escalated conversations within the Schedule
    Appointment flow, identifying a potential cause (new wording directing users to
    agents) and providing recommendations to improve
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The problem analysis depicted in figure 3.15 can contribute to a broader triage
    process by helping prioritize chatbot improvements based on effect and resolution
    complexity. Each problem is documented similarly, with insights into the problem,
    likely causes, and proposed solutions. In a full triage process, many such problem
    entries are evaluated based on effect, frequency, and resolution effort to determine
    prioritization. The best prioritization practices consider value, proposed outcomes,
    and expected return. You must do a cost/benefit analysis. Benefits may be direct
    (improving containment) or indirect (improving the user experience). Costs may
    include time, effort, and complexity of the fix, and fixes that require buy-in
    from multiple departments will take longer. The expected return considers both
    benefits and costs, scaled by the volume of conversations affected. The goal is
    to focus on areas where the expected return justifies the investment of time and
    resources. An example of an expected return calculation for a problem is shown
    in figure 3.16\.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F16_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.16 Assessment of the cost of users reaching call center agents after
    abandoning their chatbot conversations in frustration
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The cost effect can be easily calculated when a given dialogue flow is handled
    by a human agent instead of through the chatbot. This calculation considers the
    agent cost per call, the total number of calls per day, and the rate of conversations
    transferred to human agents. The priority of this problem is much easier to assign
    when it’s backed by this financial effect. This calculation can be repeated for
    all problem types. Remember that some costs are indirect: for example, a rude
    bot can lower customer satisfaction, making it challenging to quantify the financial
    effect.'
  prefs: []
  type: TYPE_NORMAL
- en: Effort is another important prioritization driver. Just as there is a cost to
    the problem itself, there is also a cost to implementing the fix. Effort refers
    to the time, resources, and complexity involved in the implementation. The key
    is to balance the problem’s importance with the implementation speed. The best
    problems to fix are high effect and low effort. First, address those problems
    that have a high effect but can easily be done. Figure 3.17 categorizes improvement
    opportunities based on their effect and the effort required to implement them.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F17_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.17 An effect-effort matrix visualizes the relationship between the
    effort required and the potential effect of a proposed change.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: High-priority items have high effect and low effort, followed by medium-priority
    items yielding incremental results. Low-priority items are those with low effect
    and high effort, and they are poorer candidates for fixing. This matrix can help
    teams prioritize their efforts effectively, focusing on changes that offer the
    greatest potential effect with the least amount of effort.
  prefs: []
  type: TYPE_NORMAL
- en: We can dive deeper into the categories presented in the matrix. For each category,
    we can provide sample problems, the user pain point they cause, and why they might
    occur. Table 3.8 starts with some high-effect and low-effort problems, and table
    3.9 shows example high-effect, high-effort problems. Table 3.10 outlines some
    medium-effect, high-effort problems.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3.8 Example high-effect and low-effort problems
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Problem | User pain point | Why the problem might occur |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Incorrect or insufficient dialogue response  | Chatbot doesn’t understand  |
    Incorrect response due to poor intent recognition, input validation, or not adapting
    to the user’s context  |'
  prefs: []
  type: TYPE_TB
- en: '| Poor dialogue response  | Chatbot is too complex  | Format and/or text does
    not convey the information clearly.  |'
  prefs: []
  type: TYPE_TB
- en: '| Broken dialogue trees  | Chatbot doesn’t work  | The chatbot fails to function
    properly due to incorrect or misconfigured conditions and transitions within the
    conversation flow. These errors occur when the logic determining how the chatbot
    moves from one step to another (“jumps”) is flawed or has not been thoroughly
    tested. As a result, users may experience dead ends, irrelevant responses, or
    abrupt conversation drops, negatively affecting containment and user satisfaction.  |'
  prefs: []
  type: TYPE_TB
- en: '| Flow enhancements  | Chatbot is too complex  | Processes have particularly
    complex steps that users can’t easily complete. This is especially likely in long
    conversations.  |'
  prefs: []
  type: TYPE_TB
- en: Table 3.9 Example high-effect, high-effort problems
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Problem | User pain point | Why the problem might occur |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| User unable to complete flow  | Chatbot is too complex  | Failures occur
    across many different steps in a process flow, necessitating a completely redesigned
    flow.  |'
  prefs: []
  type: TYPE_TB
- en: '| User questions are not addressed at all  | Chatbot doesn’t understand  |
    Insufficient intents are implemented to cover user demand. This may require adding
    search or retrieval-augmented generation to handle infrequent question types.  |'
  prefs: []
  type: TYPE_TB
- en: Table 3.10 Example medium-effect, high-effort problems
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '| Problem | User pain point | Why the problem might occur |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Incomplete dialogue response (due to failed API)  | Chatbot doesn’t understand  |
    Incomplete response due to API failure. The bot may not support all API request
    or response variations.  |'
  prefs: []
  type: TYPE_TB
- en: '| Intent confusion  | Chatbot doesn’t understand  | Intent confusion can occur
    when the training data is imbalanced, meaning that certain intents have too few
    or too many example utterances, leading to misclassification. Additionally, discrepancies
    between training data and real-world user queries can make it difficult for the
    chatbot to recognize the correct intent.  |'
  prefs: []
  type: TYPE_TB
- en: These categorizations are not hard and fast. You should adjust the relative
    prioritization of changes based on the frequency with which the problems occur.
  prefs: []
  type: TYPE_NORMAL
- en: Solutioning the high-level fix
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Once a high-priority problem is identified, the next crucial step is *solutioning*—outlining
    a high-level fix to rectify the problem. This involves a collaborative effort
    with the team working together to formulate a comprehensive solution. To ensure
    a structured approach, the team must address three fundamental questions: Who
    will be responsible for implementing the fix? What changes need to be made? How
    will the solution be implemented? The “who” encompasses the specific roles and
    responsibilities of the team that implements the fix. The “what” defines the nature
    of the solution, whether it involves refining the bot’s natural language processing
    capabilities, improving contextual understanding, or implementing a more sophisticated
    intent recognition system. The “how” outlines the technical approach and methodologies
    required for the implementation.'
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, the team must determine the development effort involved, considering
    factors such as coding complexity, integration requirements, and potential dependencies
    on external systems. This solutioning phase is crucial for devising a well-informed
    plan for continuous improvement.
  prefs: []
  type: TYPE_NORMAL
- en: Assigning priorities to all fixes
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A prioritized fix table is an indispensable tool for steering improvement initiatives.
    The table encapsulates a structured approach by assigning priority numbers, articulating
    concise descriptions of identified problems, proposing recommended changes, quantifying
    the potential effect on the user experience, and providing direct links to associated
    GitHub issues. This comprehensive framework not only streamlines the development
    process but also facilitates efficient communication and collaboration among team
    members. Figure 3.18 shows a sample prioritized fix table.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F18_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.18 A sample prioritized fix table
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Each column of the table plays a critical role in organizing and addressing
    problems effectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Priority*—Helps establish the urgency of each problem, ensuring that critical
    problems are addressed first.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Description*—Provides a brief but clear overview of the identified problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Recommended change*—Specifies the proposed solution or modification to rectify
    the problem, guiding development efforts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Value/effect*—Quantifies the expected improvement in user satisfaction or
    usability resulting from the recommended change, aiding in prioritization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ID*—Establishes a direct link to the corresponding problem in the project’s
    issue tracker, such as a GitHub repository. This streamlines collaboration and
    tracks progress on the resolution of each problem. The GitHub issue may also provide
    further elaboration, progress, and status on the problem.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 3.4.3 Determining acceptance criteria
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once the key problems have priorities and a high-level solution, the next step
    is to define the fix’s acceptance criteria. Simply, how will we know when this
    problem has been resolved? Acceptance criteria are useful for validating functionality
    in the development environment and verifying improvements in production.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, when PharmaBot could not handle “yes” to “Is your appointment
    for vaccines or testing?” the acceptance criteria might look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: When PharmaBot asks users to choose between vaccines and testing, and they say
    “vaccines,” they get vaccine appointments.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When PharmaBot asks users to choose between vaccines and testing, and they say
    “testing,” they get testing appointments.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When PharmaBot asks users to choose between vaccines and testing, and they say
    “yes,” it asks them to confirm that they want vaccine appointments.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: These acceptance criteria help the testing team validate current functionality
    (criteria 1 and 2) and new functionality (criteria 3). The fix can’t be deployed
    until it meets the acceptance criteria.
  prefs: []
  type: TYPE_NORMAL
- en: Once the fix is deployed, the team can verify that the number of conversations
    ending (and failing) with “yes” to the “vaccine or testing” question dramatically
    decreases or disappears altogether—for example, did the original metrics improve?
    Clear and measurable standards ensure your team is aligned with user expectations
    and project goals, setting the stage for successful bot improvement.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The following sample problems are related to conversational AI implementation,
    each with varying degrees of complexity. Your task is to prioritize these problems
    based on their effect on the conversational AI system’s effectiveness and efficiency,
    considering both qualitative and quantitative volume metrics. Assess the complexity
    of the problem as an input to your prioritization. The examples cover various
    industries, as the improvement and prioritization efforts are applicable across
    chatbot types and domains.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Inaccurate response generation:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Description: The chatbot occasionally provides inaccurate or irrelevant responses
    to user queries, leading to user dissatisfaction and confusion.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Effect: High—It affects user experience and trust in the chatbot’s capabilities.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Volume metric: Frequency of inaccurate daily responses (e.g., 15% of total
    responses).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'b. Slow response time:'
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Description: The chatbot takes too long to generate responses, leading to user
    frustration and impatience, especially in time-sensitive situations.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Effect: Moderate—it negatively affects user satisfaction and engagement with
    the chatbot.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Volume metric: Percentage of user queries with misunderstood language per day
    (e.g., 8% of total queries).'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'c. Limited language understanding:'
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Description: The chatbot struggles to understand queries that use colloquial
    language, slang, or complex syntax, resulting in misinterpretation and inadequate
    responses.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Effect: Moderate—it restricts the bot’s ability to engage with users effectively,
    leading to frustration and reduced user satisfaction.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Volume metric: Average response time in seconds per user query (e.g., 8 seconds).'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'd. Inconsistent integration with backend systems:'
  prefs:
  - PREF_OL
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Description: The chatbot experiences inconsistencies in integrating with backend
    systems, resulting in incomplete or incorrect information being provided to users.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Effect: High—it undermines the chatbot’s reliability and erodes user trust
    in its ability to provide accurate information.'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Volume metric: Percentage of conversations with backend integration errors
    per day (e.g., 12% of total conversations).'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 2\. Use sample conversations from your latest implementation, and repeat the
    preceding exercise with the data from your chatbot.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 3.5 Developing and delivering fixes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Continuous improvement is often achieved through fixed-duration iterations,
    commonly known as sprints. Sprint iterations range from one to four weeks, depending
    on your organization’s preference. While the prioritized fix table provides a
    general roadmap, the sprint plan specifically defines the next batch of functions
    to be delivered to users. The sprint plan is affected by resource availability:
    how much work you can develop and test in a time frame. It also prepares stakeholders
    for what they can next expect from your solution.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.5.1 Sprint planning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This process establishes a systematic approach to issue tracking and resolution.
    It serves as the cornerstone for a well-coordinated, agile development journey,
    ensuring that your bot evolves in alignment with the proposed solutions and within
    the designated timelines. Various tools, such as kanban boards, exist to visualize
    the state of a sprint throughout its duration. The most basic sprint visualization
    should include the problems being worked on and their status in the plan or execution
    cycle. Figure 3.19 shows one visualization that augments the fix table (figure
    3.18) with two additional columns: status and the timeline, indicating the planned
    sprint.'
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F19_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.19 A prioritized table, including development sprints. Further columns,
    including UAT times and expected deployment dates, may be added.
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 3.5.2 Measure again
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*PharmaBot’s team worked hard on improvements. When these improvements moved
    to production, the team monitored the metrics they expected to influence. By tracking
    failure outcomes against their past two deployments, they confirmed the fixes
    worked as expected.*'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3.20 shows the dashboard the PharmaBot team used.
  prefs: []
  type: TYPE_NORMAL
- en: '![figure](../Images/CH03_F20_Freed2.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.20 Tracking conversation outcomes against the deployment of changes
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Sprint planning is crucial in addressing fixes and improvements in PharmaBot’s
    development and delivery process. In these exercises, you will simulate a sprint
    planning session to prioritize fixes and enhancements for PharmaBot’s iterative
    development cycle. You have two conversational analysts, a part-time backend developer,
    and a tester:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Review the prioritized fix table you created in the previous exercise.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider the capacity and velocity of the development team and allocate resources.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a sprint plan. Using a kanban board or similar tool, create a sprint
    plan that includes the prioritized fixes and enhancements, along with estimated
    effort and expected completion times. Consider adding columns for status and sprint
    inclusion to track progress and ensure transparency throughout the sprint.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Discuss expected deployment dates for the fixes and enhancements planned for
    the sprint.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The continuous improvement cycle for conversational systems is an ongoing, iterative
    process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All improvements should drive toward the predefined business goals and user
    satisfaction.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Meticulous metric definition, the right choice of monitoring tools, and a commitment
    to best practices are key.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the “right” metrics relevant to your bot rather than those that are easiest
    to measure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detailed conversation outcomes allow you to target a specific set of conversations
    for improvement.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Several factors can determine a problem’s priority, such as its frequency of
    occurrence, the expected improvement and complexity of a fix, and the team’s capacity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Regression testing and the analysis of improvements are critical to ensuring
    improvements have occurred.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
