- en: Classification and regression
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://deeplearningwithpython.io/chapters/chapter04_classification-and-regression](https://deeplearningwithpython.io/chapters/chapter04_classification-and-regression)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'This chapter is designed to get you started with using neural networks to solve
    real problems. You’ll consolidate the knowledge you gained from chapters 2 and
    3, and you’ll apply what you’ve learned to three new tasks covering the three
    most common use cases of neural networks — binary classification, categorical
    classification, and scalar regression:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Classifying movie reviews as positive or negative (binary classification)
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Classifying news wires by topic (categorical classification)
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Estimating the price of a house, given real estate data (scalar regression)
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'These examples will be your first contact with end-to-end machine learning
    workflows: you’ll get introduced to data preprocessing, basic model architecture
    principles, and model evaluation.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this chapter, you’ll be able to use neural networks to handle
    simple classification and regression tasks over vector data. You’ll then be ready
    to start building a more principled, theory-driven understanding of machine learning
    in chapter 5.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: 'Classifying movie reviews: A binary classification example'
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Two-class classification, or binary classification, is one of the most common
    kinds of machine learning problem. In this example, you’ll learn to classify movie
    reviews as positive or negative, based on the text content of the reviews.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: The IMDb dataset
  id: totrans-10
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You’ll work with the IMDb dataset: a set of 50,000 highly polarized reviews
    from the Internet Movie Database. They’re split into 25,000 reviews for training
    and 25,000 reviews for testing, each set consisting of 50% negative and 50% positive
    reviews.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: 'Just like the MNIST dataset, the IMDb dataset comes packaged with Keras. It
    has already been preprocessed: the reviews (sequences of words) have been turned
    into sequences of integers, where each integer stands for a specific word in a
    dictionary. This enables us to focus on model building, training, and evaluation.
    In chapter 14, you’ll learn how to process raw text input from scratch.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: The following code will load the dataset (when you run it the first time, about
    80 MB of data will be downloaded to your machine).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[Listing 4.1](#listing-4-1): Loading the IMDb dataset'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: The argument `num_words=10000` means you’ll only keep the top 10,000 most frequently
    occurring words in the training data. Rare words will be discarded. This allows
    you to work with vector data of manageable size. If we didn’t set this limit,
    we’d be working with 88,585 unique words in the training data, which is unnecessarily
    large. Many of these words only occur in a single sample, and thus can’t be meaningfully
    used for classification.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: 'The variables `train_data` and `test_data` are NumPy arrays of reviews; each
    review is a list of word indices (encoding a sequence of words). `train_labels`
    and `test_labels` are NumPy arrays of 0s and 1s, where 0 stands for *negative*
    and 1 stands for *positive*:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Because you’re restricting yourself to the top 10,000 most frequent words,
    no word index will exceed 10,000:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: For kicks, let’s quickly decode one of these reviews back to English words.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[Listing 4.2](#listing-4-2): Decoding reviews back to text'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a look at what we got:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Note that the leading `?` corresponds to a start token that has been prefixed
    to each review.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the data
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'You can’t directly feed lists of integers into a neural network. They have
    all different lengths, while a neural network expects to process contiguous batches
    of data. You have to turn your lists into tensors. There are two ways to do that:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Pad your lists so that they all have the same length, then turn them into an
    integer tensor of shape `(samples, max_length)`, and start your model with a layer
    capable of handling such integer tensors (the `Embedding` layer, which we’ll cover
    in detail later in the book).
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Multi-hot encode* your lists to turn them into vectors of 0s and 1s reflecting
    the presence or absence of all possible words. This would mean, for instance,
    turning the sequence `[8, 5]` into a 10,000-dimensional vector that would be all
    0s except for indices 5 and 8, which would be 1s.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s go with the latter solution to vectorize the data. When done manually,
    the process looks like the following.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[Listing 4.3](#listing-4-3): Encoding the integer sequences via multi-hot encoding'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s what the samples look like now:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In addition to vectorizing the input sequences, you should also vectorize their
    labels, which is straightforward. Our labels are already NumPy arrays, so just
    convert the type from ints to floats:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Now the data is ready to be fed into a neural network.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Building your model
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The input data is vectors, and the labels are scalars (1s and 0s): this is
    one of the simplest problem setups you’ll ever encounter. A type of model that
    performs well on such a problem is a plain stack of densely connected (`Dense`)
    layers with `relu` activations.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two key architecture decisions to be made about such a stack of `Dense`
    layers:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: How many layers to use
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How many units to choose for each layer
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In chapter 5, you’ll learn formal principles to guide you in making these choices.
    For the time being, you’ll have to trust us with the following architecture choice:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Two intermediate layers with 16 units each
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A third layer that will output the scalar prediction regarding the sentiment
    of the current review
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Figure 4.1 shows what the model looks like. Here’s the Keras implementation,
    similar to the MNIST example you saw previously.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[Listing 4.4](#listing-4-4): Model definition'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/68f662b777d64b6a3aabdcb729b94ca2.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: '[Figure 4.1](#figure-4-1): The three-layer model'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: 'The first argument being passed to each `Dense` layer is the number of *units*
    in the layer: the dimensionality of representation space of the layer. You remember
    from chapters 2 and 3 that each such `Dense` layer with a `relu` activation implements
    the following chain of tensor operations:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Having 16 units means the weight matrix `W` will have shape `(input_dimension,
    16)`: the dot product with `W` will project the input data onto a 16-dimensional
    representation space (and then you’ll add the bias vector `b` and apply the `relu`
    operation). You can intuitively understand the dimensionality of your representation
    space as “how much freedom you’re allowing the model to have when learning internal
    representations.” Having more units (a higher-dimensional representation space)
    allows your model to learn more complex representations, but it makes the model
    more computationally expensive and may lead to learning unwanted patterns (patterns
    that will improve performance on the training data but not on the test data).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: The intermediate layers use `relu` as their activation function, and the final
    layer uses a sigmoid activation to output a probability (a score between 0 and
    1, indicating how likely the review is to be positive). A `relu` (rectified linear
    unit) is a function meant to zero-out negative values (see figure 4.2), whereas
    a sigmoid “squashes” arbitrary values into the `[0, 1]` interval (see figure 4.3),
    outputting something that can be interpreted as a probability.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/49a10336cc1638ad3a5a3adc18dfac80.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
- en: '[Figure 4.2](#figure-4-2): The rectified linear unit function'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/94ee06bdd6e5edf30361b37018c9c9b6.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
- en: '[Figure 4.3](#figure-4-3): The sigmoid function'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, you need to choose a loss function and an optimizer. Because you’re
    facing a binary classification problem and the output of your model is a probability
    (you end your model with a single-unit layer with a sigmoid activation), it’s
    best to use the `binary_crossentropy` loss. It isn’t the only viable choice: you
    could use, for instance, `mean_squared_error`. But crossentropy is usually the
    best choice when you’re dealing with models that output probabilities. *Crossentropy*
    is a quantity from the field of information theory that measures the distance
    between probability distributions or, in this case, between the ground-truth distribution
    and your predictions.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: As for the choice of the optimizer, we’ll go with `adam`, which is usually a
    good default choice for virtually any problem.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Here’s the step where you configure the model with the `adam` optimizer and
    the `binary_crossentropy` loss function. Note that you’ll also monitor accuracy
    during training.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[Listing 4.5](#listing-4-5): Compiling the model'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: Validating your approach
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As you learned in chapter 3, a deep learning model should never be evaluated
    on its training data — it’s standard practice to use a “validation set” to monitor
    the accuracy of the model during training. Here, you’ll create a validation set
    by setting apart 10,000 samples from the original training data.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: You might ask, why not simply use the *test* data to evaluate the model? That
    seems like it would be easier. The reason is that you’re going to want to use
    the results you get on the validation set to inform your next choices to improve
    training — for instance, your choice of what model size to use or how many epochs
    to train for. When you start doing this, your validation scores stop being an
    accurate reflection of the performance of the model on brand-new data, since the
    model has been deliberately modified to perform better on the validation data.
    It’s good to keep around a set of never-before-seen samples that you can use to
    perform the final evaluation round in a completely unbiased way, and that’s exactly
    what the test set is. We’ll talk more about this in the next chapter.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[Listing 4.6](#listing-4-6): Setting aside a validation set'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: You’ll now train the model for 20 epochs (20 iterations over all samples in
    the training data), in mini-batches of 512 samples. At the same time, you’ll monitor
    loss and accuracy on the 10,000 samples that you set apart. You do so by passing
    the validation data as the `validation_data` argument to `model.fit()`.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[Listing 4.7](#listing-4-7): Training your model'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: On CPU, this will take less than 2 seconds per epoch — training is over in 20
    seconds. At the end of every epoch, there is a slight pause as the model computes
    its loss and accuracy on the 10,000 samples of the validation data.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the call to `model.fit()` returns a `History` object, as you’ve seen
    in chapter 3\. This object has a member `history`, which is a dictionary containing
    data about everything that happened during training. Let’s look at it:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The dictionary contains four entries: one per metric that was being monitored
    during training and during validation. In the following two listings, let’s use
    Matplotlib to plot the training and validation loss side by side (see figure 4.4),
    as well as the training and validation accuracy (see figure 4.5). Note that your
    own results may vary slightly due to a different random initialization of your
    model.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[Listing 4.8](#listing-4-8): Plotting the training and validation loss'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4250e81cf571d19717642a9c2078b966.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
- en: '[Figure 4.4](#figure-4-4): Training and validation loss'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[Listing 4.9](#listing-4-9): Plotting the training and validation accuracy'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/360b66ab70d2777c93c1bd914592906d.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
- en: '[Figure 4.5](#figure-4-5): Training and validation accuracy'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, the training loss decreases with every epoch, and the training
    accuracy increases with every epoch. That’s what you would expect when running
    gradient-descent optimization — the quantity you’re trying to minimize should
    be less with every iteration. But that isn’t the case for the validation loss
    and accuracy: they seem to peak at the fourth epoch. This is an example of what
    we warned against earlier: a model that performs better on the training data isn’t
    necessarily a model that will do better on data it has never seen before. In precise
    terms, what you’re seeing is *overfitting*: after the fourth epoch, you’re overoptimizing
    on the training data, and you end up learning representations that are specific
    to the training data and don’t generalize to data outside of the training set.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: In this case, to prevent overfitting, you could stop training after four epochs.
    In general, you can use a range of techniques to mitigate overfitting, which we’ll
    cover in chapter 5.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: Let’s train a new model from scratch for four epochs and then evaluate it on
    the test data.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[Listing 4.10](#listing-4-10): Training the model for four epochs'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: 'The final results are as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: This fairly naive approach achieves an accuracy of 88%. With state-of-the-art
    approaches, you should be able to get close to 95%.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Using a trained model to generate predictions on new data
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'After having trained a model, you’ll want to use it in a practical setting.
    You can generate the likelihood of reviews being positive by using the `predict`
    method, as you’ve learned in chapter 3:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As you can see, the model is confident for some samples (0.99 or more, or 0.01
    or less) but less confident for others (0.6, 0.4).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Further experiments
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following experiments will help convince you that the architecture choices
    you’ve made are all fairly reasonable, although there’s still room for improvement:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: You used two representation layers before the final classification layer. Try
    using one or three representation layers and see how doing so affects validation
    and test accuracy.
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Try using layers with more units or fewer units: 32 units, 64 units, and so
    on.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Try using the `mean_squared_error` loss function instead of `binary_crossentropy`.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Try using the `tanh` activation (an activation that was popular in the early
    days of neural networks) instead of `relu`.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wrapping up
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Here’s what you should take away from this example:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: You usually need to do quite a bit of preprocessing on your raw data to be able
    to feed it — as tensors — into a neural network. Sequences of words can be encoded
    as binary vectors, but there are other encoding options, too.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stacks of `Dense` layers with `relu` activations can solve a wide range of problems
    (including sentiment classification), and you’ll use them frequently.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In a binary classification problem (two output classes), your model should
    end with a `Dense` layer with one unit and a `sigmoid` activation: the output
    of your model should be a scalar between 0 and 1, encoding a probability.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With such a scalar sigmoid output on a binary classification problem, the loss
    function you should use is `binary_crossentropy`.
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `adam` optimizer is generally a good enough choice, whatever your problem.
    That’s one less thing for you to worry about.
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As they get better on their training data, neural networks eventually start
    overfitting and end up obtaining increasingly worse results on data they’ve never
    seen before. Be sure to always monitor performance on data that is outside of
    the training set!
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Classifying newswires: A multiclass classification example'
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, you saw how to classify vector inputs into two mutually
    exclusive classes using a densely connected neural network. But what happens when
    you have more than two classes?
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you’ll build a model to classify Reuters newswires into 46
    mutually exclusive topics. Because you have many classes, this problem is an instance
    of *multiclass classification*, and because each data point should be classified
    into only one category, the problem is more specifically an instance of *single-label*,
    *multiclass classification*. If each data point could belong to multiple categories
    (in this case, topics), you’d be facing a *multilabel*, *multiclass classification*
    problem.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: The Reuters dataset
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You’ll work with the Reuters dataset, a set of short newswires and their topics,
    published by Reuters in 1986\. It’s a simple, widely used toy dataset for text
    classification. There are 46 different topics; some topics are more represented
    than others, but each topic has at least 10 examples in the training set.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Like IMDb and MNIST, the Reuters dataset comes packaged as part of Keras. Let’s
    take a look.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[Listing 4.11](#listing-4-11): Loading the Reuters dataset'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: As with the IMDb dataset, the argument `num_words=10000` restricts the data
    to the 10,000 most frequently occurring words found in the data.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: 'You have 8,982 training examples and 2,246 test examples:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'As with the IMDb reviews, each example is a list of integers (word indices):'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Here’s how you can decode it back to words, in case you’re curious.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[Listing 4.12](#listing-4-12): Decoding newswires back to text'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: 'The label associated with an example is an integer between 0 and 45 — a topic
    index:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Preparing the data
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You can vectorize the data with the exact same code as in the previous example.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[Listing 4.13](#listing-4-13): Encoding the input data'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: 'To vectorize the labels, there are two possibilities: you can leave the labels
    untouched as integers, or you can use *one-hot encoding*. One-hot encoding is
    a widely used format for categorical data, also called *categorical encoding*.
    In this case, one-hot encoding of the labels consists of embedding each label
    as an all-zero vector with a 1 in the place of the label index. Here’s an example.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 为了向量化标签，有两种可能性：你可以保持标签不变作为整数，或者你可以使用 *one-hot encoding*。One-hot encoding 是一种广泛使用的分类数据格式，也称为
    *分类编码*。在这种情况下，标签的 one-hot encoding 是将每个标签嵌入为一个全零向量，标签索引的位置为 1。以下是一个示例。
- en: '[PRE25]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[Listing 4.14](#listing-4-14): Encoding the labels'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 4.14](#listing-4-14)：编码标签'
- en: 'Note that there is a built-in way to do this in Keras:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在 Keras 中有内置的方式来完成这个操作：
- en: '[PRE26]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Building your model
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 构建你的模型
- en: 'This topic classification problem looks similar to the previous movie review
    classification problem: in both cases, you’re trying to classify short snippets
    of text. But there is a new constraint here: the number of output classes has
    gone from 2 to 46\. The dimensionality of the output space is much larger.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这个主题分类问题看起来与先前的电影评论分类问题相似：在两种情况下，你都在尝试对短文本片段进行分类。但这里有一个新的约束：输出类别的数量从 2 增加到 46。输出空间的维度要大得多。
- en: 'In a stack of `Dense` layers like those you’ve been using, each layer can only
    access information present in the output of the previous layer. If one layer drops
    some information relevant to the classification problem, this information can
    never be recovered by later layers: each layer can potentially become an information
    bottleneck. In the previous example, you used 16-dimensional intermediate layers,
    but a 16-dimensional space may be too limited to learn to separate 46 different
    classes: such small layers may act as information bottlenecks, permanently dropping
    relevant information.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在像你一直在使用的 `Dense` 层堆叠中，每一层只能访问前一层输出的信息。如果一个层丢失了与分类问题相关的某些信息，这些信息将永远无法被后续层恢复：每一层都可能成为一个信息瓶颈。在先前的例子中，你使用了
    16 维的中间层，但 16 维的空间可能太小，无法学习区分 46 个不同的类别：这样的小层可能充当信息瓶颈，永久性地丢失相关信息。
- en: For this reason, you’ll use larger intermediate layers. Let’s go with 64 units.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，你会使用更大的中间层。让我们使用 64 个单位。
- en: '[PRE27]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[Listing 4.15](#listing-4-15): Model definition'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '[列表 4.15](#listing-4-15)：模型定义'
- en: 'There are two other things you should note about this architecture:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这个架构，还有两件事你应该注意：
- en: You end the model with a `Dense` layer of size 46\. This means for each input
    sample, the network will output a 46-dimensional vector. Each entry in this vector
    (each dimension) will encode a different output class.
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你以一个大小为 46 的 `Dense` 层结束模型。这意味着对于每个输入样本，网络将输出一个 46 维的向量。这个向量中的每个条目（每个维度）将编码一个不同的输出类别。
- en: The last layer uses a `softmax` activation. You saw this pattern in the MNIST
    example. It means the model will output a *probability distribution* over the
    46 different output classes — for every input sample, the model will produce a
    46-dimensional output vector, where `output[i]` is the probability that the sample
    belongs to class `i`. The 46 scores will sum to 1.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后一层使用 `softmax` 激活函数。你在 MNIST 示例中见过这种模式。这意味着模型将在 46 个不同的输出类别上输出一个 *概率分布* ——
    对于每个输入样本，模型将产生一个 46 维的输出向量，其中 `output[i]` 是样本属于类别 `i` 的概率。这 46 个分数加起来等于 1。
- en: The best loss function to use in this case is `categorical_crossentropy`. It
    measures the distance between two probability distributions — here, between the
    probability distribution outputted by the model and the true distribution of the
    labels. By minimizing the distance between these two distributions, you train
    the model to output something as close as possible to the true labels.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个情况下，最佳损失函数是 `categorical_crossentropy`。它衡量两个概率分布之间的距离——在这里，是模型输出的概率分布和标签真实分布之间的距离。通过最小化这两个分布之间的距离，你训练模型输出尽可能接近真实标签的内容。
- en: 'Like last time, we’ll also monitor accuracy. However, accuracy is a bit of
    a crude metric in this case: if the model has the correct class as its second
    choice for a given sample, with an incorrect first choice, the model will still
    have an accuracy of zero on that sample — even though such a model would be much
    better than a random guess. A more nuanced metric in this case is top-k accuracy,
    such as top-3 or top-5 accuracy. It measures whether the correct class was among
    the top-k predictions of the model. Let’s add top-3 accuracy to our model.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '[Listing 4.16](#listing-4-16): Compiling the model'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: Validating your approach
  id: totrans-151
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s set apart 1,000 samples in the training data to use as a validation set.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[Listing 4.17](#listing-4-17): Setting aside a validation set'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s train the model for 20 epochs.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[Listing 4.18](#listing-4-18): Training the model'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: And finally, let’s display its loss and accuracy curves (see figures 4.6 and
    4.7).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[Listing 4.19](#listing-4-19): Plotting the training and validation loss'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/700f48941826f86c77529d558bb444c4.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
- en: '[Figure 4.6](#figure-4-6): Training and validation loss'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[Listing 4.20](#listing-4-20): Plotting the training and validation top-3 accuracy'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1fca6a813a775f4369c4651c43e4b471.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
- en: '[Figure 4.7](#figure-4-7): Training and validation accuracy'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '[Listing 4.21](#listing-4-21): Plotting the training and validation top-3 accuracy'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a76873d2f26e20d65d983d713807a26a.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
- en: '[Figure 4.8](#figure-4-8): Training and validation accuracy'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: The model begins to overfit after nine epochs. Let’s train a new model from
    scratch for nine epochs and then evaluate it on the test set.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: '[Listing 4.22](#listing-4-22): Retraining a model from scratch'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the final results:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'This approach reaches an accuracy of approximately 80%. With a balanced binary
    classification problem, the accuracy reached by a purely random classifier would
    be 50%. But in this case, we have 46 classes, and they may not be equally represented.
    What would be the accuracy of a random baseline? We could try quickly implementing
    one to check this empirically:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: As you can see, a random classifier would score around 19% classification accuracy,
    so the results of our model seem pretty good in that light.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Generating predictions on new data
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Calling the model’s `predict` method on new samples returns a class probability
    distribution over all 46 topics for each sample. Let’s generate topic predictions
    for all of the test data:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Each entry in “predictions” is a vector of length 46:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'The coefficients in this vector sum to 1, as they form a probability distribution:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'The largest entry is the predicted class — the class with the highest probability:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: A different way to handle the labels and the loss
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We mentioned earlier that another way to encode the labels would be to leave
    them untouched as integer tensors, like this:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'The only thing this approach would change is the choice of the loss function.
    The loss function used in listing 4.22, `categorical_crossentropy`, expects the
    labels to follow a categorical encoding. With integer labels, you should use `sparse_categorical_crossentropy`:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: This new loss function is still mathematically the same as `categorical_crossentropy`;
    it just has a different interface.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: The importance of having sufficiently large intermediate layers
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We mentioned earlier that because the final outputs are 46-dimensional, you
    should avoid intermediate layers with much fewer than 46 units. Now let’s see
    what happens when you introduce an information bottleneck by having intermediate
    layers that are significantly less than 46-dimensional: for example, 4-dimensional.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: '[Listing 4.23](#listing-4-23): A model with an information bottleneck'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: The model now peaks at approximately 71% validation accuracy, an 8% absolute
    drop. This drop is mostly due to the fact that you’re trying to compress a lot
    of information (enough information to recover the separation hyperplanes of 46
    classes) into an intermediate space that is too low-dimensional. The model is
    able to cram *most* of the necessary information into these 4-dimensional representations,
    but not all of it.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Further experiments
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Like in the previous example, we encourage you to try out the following experiments
    to train your intuition about the kind of configuration decisions you have to
    make with such models:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: 'Try using larger or smaller layers: 32 units, 128 units, and so on.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You used two intermediate layers before the final softmax classification layer.
    Now try using a single intermediate layer, or three intermediate layers.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wrapping up
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Here’s what you should take away from this example:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: If you’re trying to classify data points among *N* classes, your model should
    end with a `Dense` layer of size *N*.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a single-label, multiclass classification problem, your model should end
    with a `softmax` activation so that it will output a probability distribution
    over the *N* output classes.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Categorical crossentropy is almost always the loss function you should use for
    such problems. It minimizes the distance between the probability distributions
    output by the model and the true distribution of the targets.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are two ways to handle labels in multiclass classification:'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Encoding the labels via categorical encoding (also known as one-hot encoding)
    and using `categorical_crossentropy` as a loss function
  id: totrans-209
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Encoding the labels as integers and using the `sparse_categorical_crossentropy`
    loss function
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If you need to classify data into a large number of categories, you should avoid
    creating information bottlenecks in your model due to intermediate layers that
    are too small.
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Predicting house prices: A regression example'
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The two previous examples were considered classification problems, where the
    goal was to predict a single discrete label of an input data point. Another common
    type of machine learning problem is *regression*, which consists of predicting
    a continuous value instead of a discrete label: for instance, predicting the temperature
    tomorrow given meteorological data, or predicting the time that a software project
    will take to complete given its specifications.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: The California Housing Price dataset
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You’ll attempt to predict the median price of homes in different areas of California,
    based on data from the 1990 census.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: Each data point in the dataset represents information about a “block group,”
    a group of homes located in the same area. You can think of it as a district.
    This dataset has two versions, the “small” version with just 600 districts, and
    the “large” version with 20,640 districts. Let’s use the small version, because
    real-world datasets can often be tiny, and you need to know how to handle such
    cases.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: For each district, we know
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: The longitude and latitude of the approximate geographic center of the area.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The median age of houses in the district.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The population of the district. The districts are pretty small: the average
    population is 1,425.5.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The total number of households.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The median income of those households.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The total number of rooms in the district, across all homes located there. This
    is typically in the low thousands.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The total number of bedrooms in the district.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That’s eight variables in total (longitude and latitude count as two variables).
    The goal is to use these variables to predict the median value of the houses in
    the district. Let’s get started by loading the data.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '[Listing 4.24](#listing-4-24): Loading the California Housing Prices dataset'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the data:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'As you can see, we have 480 training samples and 120 test samples, each with
    8 numerical features. The targets are the median values of homes in the district
    considered, in dollars:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The prices are between $60,000 and $500,000\. If that sounds cheap, remember
    that this was in 1990, and these prices aren’t adjusted for inflation.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the data
  id: totrans-233
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It would be problematic to feed into a neural network values that all take
    wildly different ranges. The model might be able to automatically adapt to such
    heterogeneous data, but it would definitely make learning more difficult. A widespread
    best practice to deal with such data is to do feature-wise normalization: for
    each feature in the input data (a column in the input data matrix), you subtract
    the mean of the feature and divide by the standard deviation, so that the feature
    is centered around 0 and has a unit standard deviation. This is easily done in
    NumPy.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[Listing 4.25](#listing-4-25): Normalizing the data'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: Note that the quantities used for normalizing the test data are computed using
    the training data. You should never use in your workflow any quantity computed
    on the test data, even for something as simple as data normalization.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: In addition, we should also scale the targets. Our normalized inputs have their
    value in a small range close to 0, and our model’s weights are initialized with
    small random values. This means that our model’s prediction will also be small
    values when we start training. If the targets are in the range 60,000–500,000,
    the model is going to need very large weight values to output those. With a small
    learning rate, it would take a very long time to get there. The simplest fix is
    to divide all target values by 100,000, so that the smallest target becomes 0.6,
    and the largest becomes 5\. We can then convert the model’s predictions back to
    dollar values by multiplying them by 100,000 accordingly.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '[Listing 4.26](#listing-4-26): Scaling the targets'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: Building your model
  id: totrans-241
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Because so few samples are available, you’ll use a very small model with two
    intermediate layers, each with 64 units. In general, the less training data you
    have, the worse overfitting will be, and using a small model is one way to mitigate
    overfitting.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[Listing 4.27](#listing-4-27): Model definition'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: 'The model ends with a single unit and no activation: it will be a linear layer.
    This is a typical setup for scalar regression — a regression where you’re trying
    to predict a single continuous value. Applying an activation function would constrain
    the range the output can take; for instance, if you applied a `sigmoid` activation
    function to the last layer, the model could only learn to predict values between
    0 and 1\. Here, because the last layer is purely linear, the model is free to
    learn to predict values in any range.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: Note that you compile the model with the `mean_squared_error` loss function
    — *mean squared error*, the square of the difference between the predictions and
    the targets. This is a widely used loss function for regression problems.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: 'You’re also monitoring a new metric during training: *mean absolute error*
    (MAE). It’s the absolute value of the difference between the predictions and the
    targets. For instance, an MAE of 0.5 on this problem would mean your predictions
    are off by $50,000 on average (remember the target scaling of factor 100,000).'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: Validating your approach using K-fold validation
  id: totrans-248
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To evaluate your model while you keep adjusting its parameters (such as the
    number of epochs used for training), you could split the data into a training
    set and a validation set, as you did in the previous examples. But because you
    have so few data points, the validation set would end up being very small (for
    instance, about 100 examples). As a consequence, the validation scores might change
    a lot depending on which data points you chose to use for validation and which
    you chose for training: the validation scores might have a high *variance* with
    regard to the validation split. This would prevent you from reliably evaluating
    your model.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: The best practice in such situations is to use *K-fold* cross-validation (see
    figure 4.9). It consists of splitting the available data into *K* partitions (typically
    *K* = 4 or 5), instantiating *K* identical models, and training each one on *K*
    – 1 partitions while evaluating on the remaining partition. The validation score
    for the model used is then the average of the *K* validation scores obtained.
    In terms of code, this is straightforward.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bb6a837d8d083d01576c5920aa7ca957.png)'
  id: totrans-251
  prefs: []
  type: TYPE_IMG
- en: '[Figure 4.9](#figure-4-9): Three-fold cross-validation'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-253
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: '[Listing 4.28](#listing-4-28): K-fold validation'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: 'Running this with `num_epochs = 50` yields the following results:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The different runs do indeed show meaningfully different validation scores,
    from 0.232 to 0.349\. The average (0.296) is a much more reliable metric than
    any single score — that’s the entire point of K-fold cross-validation. In this
    case, you’re off by $29,600 on average, which is significant considering that
    the prices range from $60,000 to $500,000.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s try training the model a bit longer: 200 epochs. To keep a record of
    how well the model does at each epoch, you’ll modify the training loop to save
    the per-epoch validation score log.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: '[Listing 4.29](#listing-4-29): Saving the validation logs at each fold'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: You can then compute the average of the per-epoch mean absolute error (MAE)
    scores for all folds.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '[Listing 4.30](#listing-4-30): Building the history of successive mean K-fold
    validation scores'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: Let’s plot this; see figure 4.10.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: '[Listing 4.31](#listing-4-31): Plotting validation scores'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/3a62bf8f25afa58de847c1fe58574fe5.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
- en: '[Figure 4.10](#figure-4-10): Validation MAE by epoch'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: 'It may be a little difficult to read the plot due to a scaling issue: the validation
    MAE for the first few epochs is dramatically higher than the values that follow.
    Let’s omit the first 10 data points, which are on a different scale than the rest
    of the curve.'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: '[Listing 4.32](#listing-4-32): Plotting validation scores, excluding the first
    10 data points'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/e5f84d5faf3a31c710e45f85a1a04052.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
- en: '[Figure 4.11](#figure-4-11): Validation MAE by epoch, excluding the first 10
    data points'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: According to this plot (see figure 4.11), validation MAE stops improving significantly
    after 120–140 epochs (this number includes the 10 epochs we omitted). Past that
    point, you start overfitting.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: Once you’re finished tuning other parameters of the model (in addition to the
    number of epochs, you could also adjust the size of the intermediate layers),
    you can train a final production model on all of the training data, with the best
    parameters, and then look at its performance on the test data.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: '[Listing 4.33](#listing-4-33): Training the final model'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s the final result:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-279
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: We’re still off by about $31,000 on average.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: Generating predictions on new data
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When calling `predict()` on our binary classification model, we retrieved a
    scalar score between 0 and 1 for each input sample. With our multiclass classification
    model, we retrieved a probability distribution over all classes for each sample.
    Now, with this scalar regression model, `predict()` returns the model’s guess
    for the sample’s price in hundreds of thousands of dollars:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: The first district in the test set is predicted to have an average home price
    of about $283,000.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping up
  id: totrans-285
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Here’s what you should take away from this scalar regression example:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: Regression is done using a different loss function than what we used for classification.
    Mean squared error (MSE) is a loss function commonly used for regression.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similarly, evaluation metrics to be used for regression differ from those used
    for classification; naturally, the concept of accuracy doesn’t apply for regression.
    A common regression metric is MAE.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When features in the input data have values in different ranges, each feature
    should be scaled independently as a preprocessing step.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When there is little data available, using K-fold validation is a great way
    to reliably evaluate a model.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When little training data is available, it’s preferable to use a small model
    with few intermediate layers (typically only one or two), in order to avoid severe
    overfitting.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The three most common kinds of machine learning tasks on vector data are binary
    classification, multiclass classification, and scalar regression. Each task uses
    different loss functions:'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`binary_crossentropy` for binary classification'
  id: totrans-294
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`categorical_crossentropy` for multiclass classification'
  id: totrans-295
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`mean_squared_error` for scalar regression'
  id: totrans-296
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: You’ll usually need to preprocess raw data before feeding it into a neural network.
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When your data has features with different ranges, scale each feature independently
    as part of preprocessing.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As training progresses, neural networks eventually begin to overfit and obtain
    worse results on never-before-seen data.
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you don’t have much training data, use a small model with only one or two
    intermediate layers, to avoid severe overfitting.
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your data is divided into many categories, you may cause information bottlenecks
    if you make the intermediate layers too small.
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When you’re working with little data, K-fold validation can help reliably evaluate
    your model.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你处理少量数据时，K折交叉验证可以帮助你可靠地评估你的模型。
