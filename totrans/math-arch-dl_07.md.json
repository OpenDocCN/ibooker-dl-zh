["```py\ndef Z(x, W_l, b_l):                    ①\n    return torch.matmul(W_l, x) + b_l\n\ndef A(z_l):                            ②\n    return torch.sigmoid(z_l)\n\ndef forward(x, W, b):                  ③\n    L = len(W) - 1\n    a_l = x\n    for l in range(0, L + 1):          ④\n        z_l = Z(a_l, W[l], b[l])       ⑤\n        a_l = A(z_l)                   ⑥\n    return a_l\n```", "```py\ndef mse_loss(a_L, y):                      ①\n    return 1./ 2 * torch.pow((a_L - y), 2) ②\n```", "```py\ndef forward_backward(x, y, W, b):\n    L = len(W) - 1\n    a = []\n    for l in range(0, L+1):\n        a_prev = x if l == 0 else a[l-1]              ①\n        z_l = Z(a_prev, W[l], b[l])\n        a_l = A(z_l)\n        a.append(a_l)\n\n    loss = mse_loss(a[L], y)                          ②\n\n    deltas = [None for _ in range(L + 1)]\n    W_grads = [None for _ in range(L + 1)]            ③\n    b_grads = [None for _ in range(L + 1)]\n\n    a_L = a[L]                                        ④\n    deltas[L] = (a_L - y) * a_L * (1 - a_L)\n    W_grads[L] = torch.matmul(deltas[L], a[L - 1].T)  ⑤\n    b_grads[L] = deltas[L]\n\n    for l in range(L-1, -1, -1):                      ⑥\n        a_l = a[l]\n        deltas[l] =  torch.matmul(W[l+1].T, deltas[l + 1]) * a_l * (1 - a_l)\n        W_grads[l] = torch.matmul(deltas[l], a[l - 1].T)\n        b_grads[l] = deltas[l]\n\n    return loss, W_grads, b_grads\n```", "```py\ndef min_max_norm(X, y):\n    X, y = X.clone(), y.clone()              ①\n    X_min, X_max = torch.min(X, dim=0)[0], \n            torch.max(X, dim=0)[0]           ②\n    X = (X - X_min) / (X_max - X_min)        ③\n    y_min, y_max = torch.min(y, dim=0)[0], \n            torch.max(y, dim=0)[0]           ④\n    y = (y - y_min) / (y_max - y_min)        ⑤\n    return X, y\n```", "```py\nclass TwoLayeredNN(torch.nn.Module):\n    def __init__(self, input_size, hidden1_size, hidden2_size, output_size):\n        super(TwoLayeredNN, self).__init__()\n\n        self.model = torch.nn.Sequential(                  ①\n\n            torch.nn.Linear(input_size, hidden1_size),     ②\n            torch.nn.Sigmoid(),\n\n            torch.nn.Linear(hidden1_size, hidden2_size),   ③\n            torch.nn.Sigmoid(),\n\n            torch.nn.Linear(hidden2_size, output_size)     ④\n        )\n\n    def forward(self, X):                                  ⑤\n        return self.model(X)\n\nnn = TwoLayeredNN(input_size=X.shape[-1], hidden1_size=10,\n                                  hidden2_size=5, output_size=1)\n```", "```py\nloss = torch.nn.MSELoss() ①\n\nloss(y_pred, y_gt)        ②\n```", "```py\nnn = TwoLayeredNN(input_size=X.shape[-1],             ①\n                  hidden1_size=10,\n                  hidden2_size=5,\n                  output_size=1)\nloss = torch.nn.MSELoss()                             ②\noptimizer = torch.optim.SGD(nn.parameters(), lr=0.2,  ③\n                            momentum=0.9)\nnum_iters = 1000\n\nfor i in range(num_iters):                            ④\n    y_out = nn(X)                                     ⑤\n    mse_loss = loss(y_out, y)                         ⑥\n    optimizer.zero_grad()                             ⑦\n    mse_loss.backward()                               ⑧\n    optimizer.step()                                  ⑨\n```"]