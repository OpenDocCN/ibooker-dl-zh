["```py\n$ git clone https://github.com/Microsoft/AutonomousDrivingCookbook.git\n$ cd AutonomousDrivingCookbook/AirSimE2EDeepLearning/\n```", "```py\nimport os\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport h5py\n\nimport matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw\n\nimport Cooking #This module contains helper code. Please do not edit this file.\n```", "```py\n# << Point this to the directory containing the raw data >>\nRAW_DATA_DIR = 'data_raw/'\n\n# << Point this to the desired output directory for the cooked (.h5) data >>\nCOOKED_DATA_DIR = 'data_cooked/'\n\n# The folders to search for data under RAW_DATA_DIR\n# For example, the first folder searched will be RAW_DATA_DIR/normal_1\nDATA_FOLDERS = ['normal_1', 'normal_2', 'normal_3', 'normal_4', 'normal_5',\n\t'normal_6', 'swerve_1', 'swerve_2', 'swerve_3']\n\n# The size of the figures and illustrations used\nFIGURE_SIZE = (10,10)\n```", "```py\nsample_image_path = os.path.join(RAW_DATA_DIR, 'normal_1/images/img_0.png')\nsample_image = Image.open(sample_image_path)\nplt.title('Sample Image')\nplt.imshow(sample_image)\nplt.show()\n```", "```py\nsample_tsv_path = os.path.join(RAW_DATA_DIR, 'normal_1/airsim_rec.txt')\nsample_tsv = pd.read_csv(sample_tsv_path, sep='\\t')\nsample_tsv.head()\n```", "```py\nsample_image_roi = sample_image.copy()\n\nfillcolor=(255,0,0)\ndraw = ImageDraw.Draw(sample_image_roi)\npoints = [(1,76), (1,135), (255,135), (255,76)]\nfor i in range(0, len(points), 1):\n    draw.line([points[i], points[(i+1)%len(points)]], fill=fillcolor, width=3)\ndel draw\n\nplt.title('Image with sample ROI')\nplt.imshow(sample_image_roi)\nplt.show()\n```", "```py\nfull_path_raw_folders = [os.path.join(RAW_DATA_DIR, f) for f in DATA_FOLDERS]\n\ndataframes = []\nfor folder in full_path_raw_folders:\n    current_dataframe = pd.read_csv(os.path.join(folder, 'airsim_rec.txt'), \n                                    sep='\\t')\n    current_dataframe['Folder'] = folder\n    dataframes.append(current_dataframe) \ndataset = pd.concat(dataframes, axis=0)\n```", "```py\nmin_index = 100\nmax_index = 1500\nsteering_angles_normal_1 = dataset[dataset['Folder'].apply(lambda v: 'normal_1'\nin v)]['Steering'][min_index:max_index]\nsteering_angles_swerve_1 = dataset[dataset['Folder'].apply(lambda v: 'swerve_1' \nin v)]['Steering'][min_index:max_index]\n\nplot_index = [i for i in range(min_index, max_index, 1)]\nfig = plt.figure(figsize=FIGURE_SIZE)\nax1 = fig.add_subplot(111)\nax1.scatter(plot_index, steering_angles_normal_1, c='b', marker='o',\nlabel='normal_1')\nax1.scatter(plot_index, steering_angles_swerve_1, c='r', marker='_',\nlabel='swerve_1')\nplt.legend(loc='upper left');\nplt.title('Steering Angles for normal_1 and swerve_1 runs')\nplt.xlabel('Time')\nplt.ylabel('Steering Angle')\nplt.show()\n```", "```py\ndataset['Is Swerve'] = dataset.apply(lambda r: 'swerve' in r['Folder'], axis=1)\ngrouped = dataset.groupby(by=['Is Swerve']).size().reset_index()\ngrouped.columns = ['Is Swerve', 'Count']\n\ndef make_autopct(values):\n    def my_autopct(percent):\n        total = sum(values)\n        val = int(round(percent*total/100.0))\n        return '{0:.2f}% ({1:d})'.format(percent,val)\n    return my_autopct\n\npie_labels = ['Normal', 'Swerve']\nfig, ax = plt.subplots(figsize=FIGURE_SIZE)\nax.pie(grouped['Count'], labels=pie_labels, autopct =\nmake_autopct(grouped['Count']), explode=[0.1, 1], textprops={'weight': 'bold'},\ncolors=['lightblue', 'salmon'])\nplt.title('Number of data points per driving strategy')\nplt.show()\n```", "```py\nbins = np.arange(-1, 1.05, 0.05)\nnormal_labels = dataset[dataset['Is Swerve'] == False]['Steering']\nswerve_labels = dataset[dataset['Is Swerve'] == True]['Steering']\n\ndef steering_histogram(hist_labels, title, color):\n    plt.figure(figsize=FIGURE_SIZE)\n    n, b, p = plt.hist(hist_labels.as_matrix(), bins, normed=1, facecolor=color)\n    plt.xlabel('Steering Angle')\n    plt.ylabel('Normalized Frequency')\n    plt.title(title)\n    plt.show()\n\nsteering_histogram(normal_labels, 'Normal driving strategy label distribution',\n'g')\nsteering_histogram(swerve_labels, 'Swerve driving strategy label distribution',\n'r')\n```", "```py\ntrain_eval_test_split = [0.7, 0.2, 0.1]\nfull_path_raw_folders = [os.path.join(RAW_DATA_DIR, f) for f in DATA_FOLDERS]\nCooking.cook(full_path_raw_folders, COOKED_DATA_DIR, train_eval_test_split)\n```", "```py\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, Model\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Lambda,\nInput, concatenate\nfrom tensorflow.keras.optimizers import Adam, SGD, Adamax, Nadam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint,\n\tCSVLogger\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Sequential, Model, load_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, \nfrom tensorflow.keras.layers import Lambda, Input, concatenate, BatchNormalization\n\nfrom keras_tqdm import TQDMNotebookCallback\nimport json\nimport os\nimport numpy as np\nimport pandas as pd\nfrom Generator import DriveDataGenerator\nfrom Cooking import checkAndCreateDir\nimport h5py\nfrom PIL import Image, ImageDraw\nimport math\nimport matplotlib.pyplot as plt\n\n# << The directory containing the cooked data from the previous step >>\nCOOKED_DATA_DIR = 'data_cooked/'\n# << The directory in which the model output will be placed >>\nMODEL_OUTPUT_DIR = 'model'\n```", "```py\ntrain_dataset = h5py.File(os.path.join(COOKED_DATA_DIR, 'train.h5'), 'r')\neval_dataset = h5py.File(os.path.join(COOKED_DATA_DIR, 'eval.h5'), 'r')\ntest_dataset = h5py.File(os.path.join(COOKED_DATA_DIR, 'test.h5'), 'r')\n\nnum_train_examples = train_dataset['image'].shape[0]\nnum_eval_examples = eval_dataset['image'].shape[0]\nnum_test_examples = test_dataset['image'].shape[0]\n\nbatch_size=32\n```", "```py\ndata_generator = DriveDataGenerator(rescale=1./255., horizontal_flip=True,\nbrighten_range=0.4)\n\ntrain_generator = data_generator.flow\\\n    (train_dataset['image'], train_dataset['previous_state'], \n    train_dataset['label'], batch_size=batch_size, zero_drop_percentage=0.95, \n    roi=[76,135,0,255])\neval_generator = data_generator.flow\\\n    (eval_dataset['image'], eval_dataset['previous_state'],\n    eval_dataset['label'],\nbatch_size=batch_size, zero_drop_percentage=0.95, roi=[76,135,0,255]\n```", "```py\ndef draw_image_with_label(img, label, prediction=None):\n    theta = label * 0.69 #Steering range for the car is +- 40 degrees -> 0.69\n# radians\n    line_length = 50\n    line_thickness = 3\n    label_line_color = (255, 0, 0)\n    prediction_line_color = (0, 255, 255)\n    pil_image = image.array_to_img(img, K.image_data_format(), scale=True)\n    print('Actual Steering Angle = {0}'.format(label))\n    draw_image = pil_image.copy()\n    image_draw = ImageDraw.Draw(draw_image)\n    first_point = (int(img.shape[1]/2), img.shape[0])\n    second_point = (int((img.shape[1]/2) + (line_length * math.sin(theta))),\nint(img.shape[0] - (line_length * math.cos(theta))))\n    image_draw.line([first_point, second_point], fill=label_line_color,\nwidth=line_thickness)\n\n    if (prediction is not None):\n        print('Predicted Steering Angle = {0}'.format(prediction))\n        print('L1 Error: {0}'.format(abs(prediction-label)))\n        theta = prediction * 0.69\n        second_point = (int((img.shape[1]/2) + ((line_length/2) *\nmath.sin(theta))), int(img.shape[0] - ((line_length/2) * math.cos(theta))))\n        image_draw.line([first_point, second_point], fill=prediction_line_color,\nwidth=line_thickness * 3)\n\n    del image_draw\n    plt.imshow(draw_image)\n    plt.show()\n\n[sample_batch_train_data, sample_batch_test_data] = next(train_generator)\nfor i in range(0, 3, 1):\n    draw_image_with_label(sample_batch_train_data[0][i],\n\tsample_batch_test_data[i])\n```", "```py\nimage_input_shape = sample_batch_train_data[0].shape[1:]\nstate_input_shape = sample_batch_train_data[1].shape[1:]\nactivation = 'relu'\n\n# Create the convolutional stacks\npic_input = Input(shape=image_input_shape)\n\nimg_stack = Conv2D(16, (3, 3), name=\"convolution0\", padding='same',\nactivation=activation)(pic_input)\nimg_stack = MaxPooling2D(pool_size=(2,2))(img_stack)\nimg_stack = Conv2D(32, (3, 3), activation=activation, padding='same',\nname='convolution1')(img_stack)\nimg_stack = MaxPooling2D(pool_size=(2, 2))(img_stack)\nimg_stack = Conv2D(32, (3, 3), activation=activation, padding='same',\nname='convolution2')(img_stack)\nimg_stack = MaxPooling2D(pool_size=(2, 2))(img_stack)\nimg_stack = Flatten()(img_stack)\nimg_stack = Dropout(0.2)(img_stack)\n\n# Inject the state input\nstate_input = Input(shape=state_input_shape)\nmerged = concatenate([img_stack, state_input])\n\n# Add a few dense layers to finish the model\nmerged = Dense(64, activation=activation, name='dense0')(merged)\nmerged = Dropout(0.2)(merged)\nmerged = Dense(10, activation=activation, name='dense2')(merged)\nmerged = Dropout(0.2)(merged)\nmerged = Dense(1, name='output')(merged)\n\nadam = Nadam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\nmodel = Model(inputs=[pic_input, state_input], outputs=merged)\nmodel.compile(optimizer=adam, loss='mse')\n```", "```py\nplateau_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3,\nmin_lr=0.0001, verbose=1)\n\ncheckpoint_filepath = os.path.join(MODEL_OUTPUT_DIR, 'models', '{0}_model.{1}\n-{2}.h5'.format('model', '{epoch:02d}', '{val_loss:.7f}'))\ncheckAndCreateDir(checkpoint_filepath)\ncheckpoint_callback = ModelCheckpoint(checkpoint_filepath, save_best_only=True,\nverbose=1)\n\ncsv_callback = CSVLogger(os.path.join(MODEL_OUTPUT_DIR, 'training_log.csv'))\n\nearly_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, \n                                                            verbose=1)\n\nnbcallback = TQDMNotebookCallback()\nsetattr(nbcallback, 'on_train_batch_begin', `lambda` x,y: `None`)\nsetattr(nbcallback, 'on_train_batch_end', `lambda` x,y: `None`)\nsetattr(nbcallback, 'on_test_begin', `lambda` x: `None`)\nsetattr(nbcallback, 'on_test_end', `lambda` x: `None`)\nsetattr(nbcallback, 'on_test_batch_begin', `lambda` x,y: `None`)\nsetattr(nbcallback, 'on_test_batch_end', `lambda` x,y: `None`)\n\ncallbacks=[plateau_callback, csv_callback, checkpoint_callback,\nearly_stopping_callback, nbcallback]\n```", "```py\nhistory = model.fit_generator(train_generator,\nsteps_per_epoch=num_train_examples // batch_size, epochs=500,\n\tcallbacks=callbacks, validation_data=eval_generator, \n\tvalidation_steps=num_eval_examples // batch_size, verbose=2)\n```", "```py\nEpoch 1/500\nEpoch 00001: val_loss improved from inf to 0.02338, saving model to\nmodel\\models\\model_model.01-0.0233783.h5\n- 442s - loss: 0.0225 - val_loss: 0.0234\nEpoch 2/500\nEpoch 00002: val_loss improved from 0.02338 to 0.00859, saving model to\nmodel\\models\\model_model.02-0.0085879.h5\n- 37s - loss: 0.0184 - val_loss: 0.0086\nEpoch 3/500\nEpoch 00003: val_loss improved from 0.00859 to 0.00188, saving model to\nmodel\\models\\model_model.03-0.0018831.h5\n- 38s - loss: 0.0064 - val_loss: 0.0019\n\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026.\n```", "```py\n[sample_batch_train_data, sample_batch_test_data] = next(train_generator)\npredictions = model.predict([sample_batch_train_data[0],\nsample_batch_train_data[1]])\nfor i in range(0, 3, 1):\n    draw_image_with_label(sample_batch_train_data[0][i],\n                          sample_batch_test_data[i], predictions[i])\n```", "```py\nfrom tensorflow.keras.models import load_model\nimport sys\nimport numpy as np\nimport glob\nimport os\n\nif ('../../PythonClient/' not in sys.path):\n    sys.path.insert(0, '../../PythonClient/')\nfrom AirSimClient import *\n\n# << Set this to the path of the model >>\n# If None, then the model with the lowest validation loss from training will be\n# used\nMODEL_PATH = None\n\nif (MODEL_PATH == None):\n    models = glob.glob('model/models/*.h5') \n    best_model = max(models, key=os.path.getctime)\n    MODEL_PATH = best_model\n\nprint('Using model {0} for testing.'.format(MODEL_PATH))\n```", "```py\n.\\AD_Cookbook_Start_AirSim.ps1 landscape\n```", "```py\nmodel = load_model(MODEL_PATH)\n\nclient = CarClient()\nclient.confirmConnection()\nclient.enableApiControl(True)\ncar_controls = CarControls()\nprint('Connection established!')\n```", "```py\ncar_controls.steering = 0\ncar_controls.throttle = 0\ncar_controls.brake = 0\n\nimage_buf = np.zeros((1, 59, 255, 3))\nstate_buf = np.zeros((1,4))\n```", "```py\ndef get_image():\n    image_response = client.simGetImages([ImageRequest(0, AirSimImageType.Scene,\nFalse, False)])[0]\n    image1d = np.fromstring(image_response.image_data_uint8, dtype=np.uint8)\n    image_rgba = image1d.reshape(image_response.height, image_response.width, 4)\n\n    return image_rgba[76:135,0:255,0:3].astype(float)\n```", "```py\nwhile (True):\n    car_state = client.getCarState()\n\n    if (car_state.speed < 5):\n        car_controls.throttle = 1.0\n    else:\n        car_controls.throttle = 0.0\n\n    image_buf[0] = get_image()\n    state_buf[0] = np.array([car_controls.steering, car_controls.throttle,\ncar_controls.brake, car_state.speed])\n    model_output = model.predict([image_buf, state_buf])\n    car_controls.steering = round(0.5 * float(model_output[0][0]), 2)\n\n    print('Sending steering = {0}, throttle = {1}'.format(car_controls.steering,\ncar_controls.throttle))\n\n    client.setCarControls(car_controls)\n```", "```py\nSending steering = 0.03, throttle = 1.0\nSending steering = 0.03, throttle = 1.0\nSending steering = 0.03, throttle = 1.0\nSending steering = 0.03, throttle = 1.0\nSending steering = 0.03, throttle = 1.0\nSending steering = -0.1, throttle = 1.0\nSending steering = -0.12, throttle = 1.0\nSending steering = -0.13, throttle = 1.0\nSending steering = -0.13, throttle = 1.0\nSending steering = -0.13, throttle = 1.0\nSending steering = -0.14, throttle = 1.0\nSending steering = -0.15, throttle = 1.0\n```"]