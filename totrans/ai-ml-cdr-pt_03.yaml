- en: Chapter 2\. Introduction to Computer Vision
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2章。计算机视觉简介
- en: '[Chapter 1](ch01.html#ch01_introduction_to_pytorch_1748548870019566) introduced
    the basics of how machine learning works. You saw how to get started with programming
    using neural networks to match data to labels, and from there, you saw how to
    infer the rules that can be used to distinguish items.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '[第1章](ch01.html#ch01_introduction_to_pytorch_1748548870019566) 介绍了机器学习的基本工作原理。你看到了如何使用神经网络开始编程，将数据与标签匹配，并从那里看到如何推断出区分项目的规则。'
- en: In this chapter, we’ll consider the next logical step, which is to apply these
    concepts to computer vision. In this process, a model learns how to recognize
    content in pictures so it can “see” what’s in them. You’ll work with a popular
    dataset of clothing items and build a model that can differentiate between them
    and thus “see” the difference between different types of clothing.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将考虑下一个逻辑步骤，即将这些概念应用于计算机视觉。在这个过程中，模型学习如何在图片中识别内容，以便它能够“看到”其中的内容。你将使用一个流行的服装项目数据集，并构建一个能够区分它们并因此“看到”不同类型服装之间差异的模型。
- en: How Computer Vision Works
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算机视觉是如何工作的
- en: '*Computer vision* is the ability of a computer to recognize items beyond just
    storing their pixels. For example, consider items of clothing that might look
    like those in [Figure 2-1](#ch02_figure_1_1748548889066336). They’re very complex,
    with lots of different varieties of the same item. Take a look at the two shoes—they’re
    very different, but they’re still shoes!'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: '*计算机视觉* 是指计算机识别项目的能力，而不仅仅是存储它们的像素。例如，考虑一下可能看起来像 [图2-1](#ch02_figure_1_1748548889066336)
    中的服装。它们非常复杂，有很多不同种类的相同项目。看看这两双鞋——它们非常不同，但它们仍然是鞋！'
- en: '![](assets/aiml_0201.png)'
  id: totrans-5
  prefs: []
  type: TYPE_IMG
  zh: '![图片](assets/aiml_0201.png)'
- en: Figure 2-1\. Clothing examples
  id: totrans-6
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-1。服装示例
- en: There are a number of different recognizable clothing items here. You understand
    the difference between a shirt, a coat, and a dress, and you fundamentally know
    what each of these items are—but how would you explain all that to somebody who
    has never seen clothing? How about a shoe? There are two shoes in this image,
    but given the major differences between them, how would you explain to someone
    what makes them both shoes? This is another area where the rules-based programming
    we spoke about in [Chapter 1](ch01.html#ch01_introduction_to_pytorch_1748548870019566)
    can fall apart. Sometimes, it’s just unfeasible to describe something with rules.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有许多可识别的服装项目。你理解衬衫、大衣和连衣裙之间的区别，并且从根本上知道这些项目的本质——但是你如何向从未见过服装的人解释这一切？鞋子呢？这张图片中有两双鞋，但鉴于它们之间的主要差异，你如何向某人解释使它们成为鞋子的共同点？这是另一个我们曾在
    [第1章](ch01.html#ch01_introduction_to_pytorch_1748548870019566) 中提到的基于规则的编程可能失效的领域。有时，用规则描述某物是不切实际的。
- en: Of course, computer vision is no exception to this issue. But consider how you
    learned to recognize all these items—by seeing lots of different examples and
    gaining experience with how they’re used. Can a computer learn the same way? The
    answer is yes, but with limitations. Throughout the rest of this chapter, we’ll
    take a look at an example of how to teach a computer to recognize items of clothing
    using a well-known dataset called Fashion MNIST.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，计算机视觉也不例外。但考虑一下你是如何学会识别所有这些项目的——通过看到很多不同的例子，并积累它们如何被使用的经验。计算机能否以同样的方式学习？答案是肯定的，但有一定的局限性。在本章的其余部分，我们将通过一个例子来了解如何使用名为
    Fashion MNIST 的知名数据集教计算机识别服装项目。
- en: The Fashion MNIST Database
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时尚MNIST数据库
- en: One of the foundational datasets for learning and benchmarking algorithms is
    the Modified National Institute of Standards and Technology (MNIST) database,
    which was created by Yann LeCun, Corinna Cortes, and Christopher Burges. This
    dataset consists of images of 70,000 handwritten digits from 0 to 9, and the images
    are 28 × 28 grayscale.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 学习和基准测试算法的基础数据集之一是修改后的国家标准与技术研究院（MNIST）数据库，该数据库由 Yann LeCun、Corinna Cortes 和
    Christopher Burges 创建。这个数据集包含从0到9的手写数字图像，共有70,000个，图像为28 × 28的灰度图。
- en: '[Fashion MNIST](https://oreil.ly/f-mnist) is designed to be a drop-in replacement
    for MNIST that has the same number of records, the same image dimensions, and
    the same number of classes. Rather than images of the digits 0 through 9, Fashion
    MNIST contains images of 10 different types of clothing.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[Fashion MNIST](https://oreil.ly/f-mnist) 被设计成是 MNIST 的直接替代品，具有相同的记录数量、相同的图像尺寸和相同的类别数量。与0到9的数字图像不同，Fashion
    MNIST 包含10种不同类型服装的图像。'
- en: You can see an example of the dataset contents in [Figure 2-2](#ch02_figure_2_1748548889066375),
    in which three lines are dedicated to each clothing item type.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[图2-2](#ch02_figure_2_1748548889066375)中看到数据集内容的示例，其中有三条线专门用于每种服装类型。
- en: '![](assets/aiml_0202.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0202.png)'
- en: Figure 2-2\. Exploring the Fashion MNIST dataset
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-2\. 探索Fashion MNIST数据集
- en: Fashion MNIST has a nice variety of clothing, including shirts, trousers, dresses,
    and lots of types of shoes! Also, as you may notice, it’s monochrome, so each
    picture consists of a certain number of pixels with values between 0 and 255\.
    This makes the dataset simpler to manage.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Fashion MNIST包含各种服装，包括衬衫、裤子、连衣裙和许多类型的鞋子！此外，你可能已经注意到，它是单色的，所以每张图片都由一定数量的像素组成，像素值介于0到255之间。这使得数据集更容易管理。
- en: You can see a close-up of a particular image from the dataset in [Figure 2-3](#ch02_figure_3_1748548889066397).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[图2-3](#ch02_figure_3_1748548889066397)中看到数据集中特定图像的特写。
- en: '![](assets/aiml_0203.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0203.png)'
- en: Figure 2-3\. Close-up of an image in the Fashion MNIST dataset
  id: totrans-18
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-3\. Fashion MNIST数据集中图像的特写
- en: Like any image, this one is a rectangular grid of pixels. In this case, the
    grid size is 28 × 28, and each pixel is a value between 0 and 255, so it is represented
    by a square in grayscale. To make it easier to see, I have expanded it so that
    it looks pixelated.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 就像任何图像一样，这个图像是一个像素的矩形网格。在这种情况下，网格大小是28 × 28，每个像素的值介于0到255之间，因此它由一个灰度平方表示。为了更容易看到，我已经将其扩展，使其看起来像像素化。
- en: Let’s now take a look at how you can use these pixel values with the functions
    we saw previously.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们现在看看如何使用之前看到的函数来使用这些像素值。
- en: Neurons for Vision
  id: totrans-21
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 视觉神经元
- en: In [Chapter 1](ch01.html#ch01_introduction_to_pytorch_1748548870019566), you
    saw a very simple scenario in which a machine was given a set of *x* and *y* values
    and it learned that the relationship between them was *y* = 2*x* – 1\. This was
    done using a very simple neural network with one layer and one neuron. If you
    were to draw that visually, it might look like [Figure 2-4](#ch02_figure_4_1748548889066415).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第1章](ch01.html#ch01_introduction_to_pytorch_1748548870019566)中，你看到了一个非常简单的场景，其中一台机器被给定了一组
    *x* 和 *y* 值，并且它学会了它们之间的关系是 *y* = 2*x* – 1。这是使用一个非常简单的只有一个层和一个神经元的神经网络完成的。如果你要直观地绘制它，它可能看起来像[图2-4](#ch02_figure_4_1748548889066415)。
- en: '![](assets/aiml_0204.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0204.png)'
- en: Figure 2-4\. A single neuron learning a linear relationship
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-4\. 单个神经元学习线性关系
- en: Each of our images is a set of 784 values (28 × 28) between 0 and 255\. They
    can be our *x*. We also know that we have 10 different types of images in our
    dataset, so let’s consider them to be our *y*. Now, we want to learn what the
    function looks like in which *y* is a function of *x*.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的每张图像是一组784个值（28 × 28）介于0到255之间。它们可以是我们的 *x*。我们还知道我们的数据集中有10种不同的图像类型，所以让我们考虑它们是我们的
    *y*。现在，我们想要学习 *y* 作为 *x* 的函数的函数看起来像什么。
- en: Given that we have 784 *x* values per image and our *y* is going to be between
    0 and 9, a simple equation like *y* = *mx* + *c* isn’t going to be enough to solve
    the problem. That’s because there’s a large variety of possible values and the
    equation can only plot values on a line.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们每张图像有784个 *x* 值，而我们的 *y* 将介于0到9之间，一个简单的方程 *y* = *mx* + *c* 并不足以解决问题。这是因为存在大量可能的值，而方程只能在一条线上绘制值。
- en: But what we *can* do is have several neurons working together. Each neuron will
    learn *parameters*, and when we have a combined function of all of these parameters
    working together, we can see whether we can match that pattern to our desired
    answer (see [Figure 2-5](#ch02_figure_5_1748548889066432)).
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们可以做的是让几个神经元一起工作。每个神经元将学习 *参数*，当我们有一个所有这些参数共同工作的组合函数时，我们可以看到我们是否可以将该模式与我们的期望答案相匹配（参见[图2-5](#ch02_figure_5_1748548889066432)）。
- en: '![](assets/aiml_0205.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0205.png)'
- en: Figure 2-5\. Extending our pattern for a more complex example
  id: totrans-29
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-5\. 扩展我们的模式以更复杂的示例
- en: The gray boxes at the top of this diagram can be considered the pixels in the
    image, which are our *X* values. When we train the neural network, we load the
    pixels into a layer of neurons—[Figure 2-5](#ch02_figure_5_1748548889066432) shows
    them being loaded into the first neuron, but the values are loaded into just each
    of them. Also, consider each neuron’s weight and bias (*w* and *b*) to be randomly
    initialized. Then, when we sum up the values of the output of each neuron, we’re
    going to get a value. We’ll do this for *every* neuron in the output layer, so
    neuron 0 will contain the value of the probability that the pixels will add up
    to label 0, neuron 1 will contain the value of the probability that the pixels
    will add up to label 1, etc.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此图顶部的灰色方框可以被认为是图像中的像素，它们是我们的*X*值。当我们训练神经网络时，我们将像素加载到一个神经元的层中——[图2-5](#ch02_figure_5_1748548889066432)显示了它们被加载到第一个神经元中，但值只加载到每个神经元中。此外，考虑每个神经元的权重和偏差(*w*和*b*)是随机初始化的。然后，当我们对每个神经元的输出值求和时，我们将得到一个值。我们将对输出层的每个神经元都这样做，所以神经元0将包含像素加起来等于标签0的概率值，神经元1将包含像素加起来等于标签1的概率值，等等。
- en: Over time, we want to match that value to the desired output―which, for this
    image, is the number 9, which is also the label for the ankle boot that was shown
    in [Figure 2-3](#ch02_figure_3_1748548889066397). So, in other words, this neuron
    should have the largest value of all of the output neurons.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 随着时间的推移，我们希望将这个值匹配到期望的输出——对于这张图像来说，是数字9，这也是[图2-3](#ch02_figure_3_1748548889066397)中展示的踝靴的标签。换句话说，这个神经元应该拥有所有输出神经元中最大的值。
- en: Given that there are 10 labels, a random initialization should get the right
    answer about 10% of the time. From that, the loss function and optimizer can do
    their job epoch by epoch to tweak the internal parameters of each neuron to improve
    on that 10%. And thus, over time, the computer will learn to “see” what makes
    a shoe a shoe or a dress a dress. You’ll see this process of improvement when
    you run the code and your neural network effectively learns to distinguish the
    different items.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 由于有10个标签，随机初始化应该有大约10%的时间能够得到正确答案。从那时起，损失函数和优化器可以逐个epoch调整每个神经元的内部参数，以改善这10%。因此，随着时间的推移，计算机将学会“看到”什么使鞋子成为鞋子，连衣裙成为连衣裙。当你运行代码并看到你的神经网络有效地学会区分不同的物品时，你会看到这个过程不断改进。
- en: Designing the Neural Network
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计神经网络
- en: 'Let’s take the example we just walked through and explore what it looks like
    in code. First, we’ll look at the design of the neural network that was shown
    in [Figure 2-5](#ch02_figure_5_1748548889066432):'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们以我们刚刚讨论的例子为例，探索它在代码中的样子。首先，我们将查看[图2-5](#ch02_figure_5_1748548889066432)中展示的神经网络的设计：
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: If you remember, in [Chapter 1](ch01.html#ch01_introduction_to_pytorch_1748548870019566)
    we had a `Sequential` model to specify that we had many layers. In that case,
    we had only one layer, but now we’re using it to define multiple layers.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你记得，在[第1章](ch01.html#ch01_introduction_to_pytorch_1748548870019566)中我们有一个`Sequential`模型来指定我们有很多层。在那个情况下，我们只有一个层，但现在我们使用它来定义多个层。
- en: 'The first layer, a `Linear`, is a layer of neurons that learn a linear relationship
    between their inputs and their outputs. As before, when using a `Linear`, you
    give two parameters: the input shape and the output shape. Conveniently, the output
    shape is effectively the number of neurons you want in this layer, and we’re specifying
    that we want 128 of them. The *input* shape is defined as (28 × 28), which is
    the size of the data coming into the network, and as you saw earlier, this is
    the dimension of a Fashion MNIST image.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 第一层，一个`Linear`层，是一层学习输入和输出之间线性关系的神经元。正如之前所做的那样，当使用`Linear`时，你给出两个参数：输入形状和输出形状。方便的是，输出形状实际上是这个层中你想要的神经元数量，我们指定我们想要128个。*输入*形状定义为(28
    × 28)，这是进入网络的数据大小，正如你之前所看到的，这是Fashion MNIST图像的维度。
- en: The input is shown as the middle layer in [Figure 2-5](#ch02_figure_5_1748548889066432),
    and you’ll often hear such layers described as *hidden layers*. The term *hidden*
    just means that there’s no direct interface to that layer. This takes a little
    bit of getting used to—the middle layer is the first layer that you *define*,
    and in a diagram like [Figure 2-5](#ch02_figure_5_1748548889066432), you can see
    that it’s in the middle of the diagram. This is because we also drew the data
    “coming in” to this layer. One other thing to note is that image data from datasets
    like Fashion MNIST is usually rectangular in shape, but a layer doesn’t recognize
    that, so it will need to be “flattened” into a 1-D array, as shown across the
    top of [Figure 2-5](#ch02_figure_5_1748548889066432). You’ll see the code for
    that in a moment.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 输入在[图2-5](#ch02_figure_5_1748548889066432)中显示为中间层，你经常会听到这样的层被描述为*隐藏层*。术语*隐藏*只是意味着没有直接接口到该层。这需要一点时间来适应——中间层是你首先*定义*的层，在一个像[图2-5](#ch02_figure_5_1748548889066432)这样的图中，你可以看到它在图的中间。这是因为我们还绘制了数据“进入”这个层。另一件需要注意的事情是，来自Fashion
    MNIST等数据集的图像数据通常是矩形的，但层不会识别这一点，因此它需要被“展平”成一个一维数组，如[图2-5](#ch02_figure_5_1748548889066432)顶部所示。你很快就会看到相关的代码。
- en: With this first `Linear`, we’re asking for 128 neurons to have their internal
    parameters randomly initialized. Often, the question I’ll get asked at this point
    is “Why 128?” This is entirely arbitrary—there’s no fixed rule for the number
    of neurons to use. As you design the layers, you want to pick the appropriate
    number of values to enable your model to actually learn. More neurons means it
    will run more slowly, as it has to learn more parameters. More neurons could also
    lead to a network that is great at recognizing the training data but not so good
    at recognizing data that it hasn’t previously seen. (This is known as *overfitting*,
    and we’ll discuss it later in this chapter). On the other hand, fewer neurons
    means that the model might not have sufficient parameters to learn.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个第一个“线性”中，我们要求128个神经元具有随机初始化的内部参数。通常，在这个时候我会被问到“为什么是128？”这完全是随机的——没有使用神经元数量的固定规则。在设计层时，你需要选择适当数量的值，以便你的模型能够真正地学习。更多的神经元意味着它将运行得更慢，因为它必须学习更多的参数。更多的神经元也可能导致一个网络在识别训练数据方面非常出色，但在识别它之前未见过的新数据方面表现不佳。（这被称为*过拟合*，我们将在本章后面讨论）。另一方面，更少的神经元意味着模型可能没有足够的参数来学习。
- en: You will need to explore this trade-off between speed of learning and accuracy
    of learning and do some experimentation over time to pick the right values. This
    process is typically called *hyperparameter tuning*. In ML, a *hyperparameter*
    is a value that is used to control the training, as opposed to the internal values
    of the neurons that get trained/learned, which are referred to as *parameters*.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要探索学习速度和学习精度之间的权衡，并在一段时间内进行实验以选择正确的值。这个过程通常被称为*超参数调整*。在机器学习中，*超参数*是用于控制训练的值，而不是被训练/学习的神经元的内部值，这些值被称为*参数*。
- en: When you’re defining a neural network with PyTorch and using the `Sequential`,
    you don’t just define the layers of the network and what types of neurons they
    may use. You can also define functions that execute on the data while it flows
    between the neural network layers. These are typically called *activation functions*,
    and an activation function is the next thing you see specified in the code as
    `nn.ReLU()`. An activation function is code that will execute on each neuron in
    the layer. PyTorch supports a number of activation functions out of the box, and
    a very common one in middle layers is `ReLU`, which stands for *rectified linear
    unit*. It’s a simple function that returns a value only if it’s greater than 0\.
    In this case, we don’t want negative values being passed to the next layer to
    potentially impact the summing function, so instead of writing a lot of `if-then`
    code, we can simply activate the layer with `ReLU`.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 当你使用PyTorch定义神经网络并使用`Sequential`时，你不仅定义了网络的层以及它们可能使用的神经元类型。你还可以定义在数据在神经网络层之间流动时执行的功能。这些通常被称为*激活函数*，激活函数是你在代码中看到的下一个指定为`nn.ReLU()`的东西。激活函数是将在层中的每个神经元上执行代码。PyTorch支持许多开箱即用的激活函数，其中在中间层中非常常见的一个是`ReLU`，代表*修正线性单元*。这是一个简单的函数，只有当它的值大于0时才返回值。在这种情况下，我们不希望将负值传递到下一层，从而可能影响求和函数，因此我们不需要编写大量的`if-then`代码，而可以直接使用`ReLU`激活层。
- en: 'Finally, there’s another `Linear` layer, which will be the *output layer*.
    If you look at the defined shape of (128, 10) and think of it through that “input
    size, output size” framework, you’ll see that it has 128 “inputs” (i.e., the number
    of neurons in the layer above) and 10 “outputs.” What are these 10? Recall that
    Fashion MNIST has 10 classes of clothing. Each of these neurons is effectively
    assigned one class, and it will end up with a probability that the input pixels
    match that class, so our job is to determine which one has the highest value.
    You might wonder how these assignments happen: where is the code that says one
    neuron is for a shoe and another is for a shirt? To answer that question, recall
    the *y* = 2*x* ‒ 1 example in [Chapter 1](ch01.html#ch01_introduction_to_pytorch_1748548870019566),
    where we had a set of input data and a set of known, correct answers that is sometimes
    called the *ground truth*. Fashion MNIST will work in the same way. When training
    the network, we provide the input images *and* their known answers as a set of
    what we want the output neurons to look like. Thus, the network will “learn” that
    when it sees a shoe, the output neurons that don’t represent that shoe should
    have a zero value and the ones that do should have a “1” value.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，还有一个`Linear`层，它将是*输出层*。如果你查看定义的形状（128, 10）并通过“输入大小，输出大小”框架来思考，你会发现它有128个“输入”（即上一层中的神经元数量）和10个“输出”。这10个是什么？回想一下，Fashion
    MNIST有10种服装类别。每个神经元实际上被分配了一个类别，并且它最终会得到一个概率，即输入像素与该类别的匹配程度，因此我们的任务是确定哪个具有最高的值。你可能想知道这些分配是如何发生的：在哪里有代码说一个神经元代表鞋子，另一个代表衬衫？为了回答这个问题，回想一下[第1章](ch01.html#ch01_introduction_to_pytorch_1748548870019566)中的*y*
    = 2*x* ‒ 1示例，在那里我们有一组输入数据和一组已知、正确的答案，有时被称为*地面真相*。Fashion MNIST将以相同的方式工作。在训练网络时，我们提供输入图像及其已知答案作为一组我们希望输出神经元看起来像的东西。因此，网络将“学习”到当它看到鞋子时，不表示该鞋子的输出神经元应该具有零值，而表示该鞋子的神经元应该具有“1”值。
- en: We *could* also loop through the output neurons to find the highest value, but
    the `LogSoftmax` activation function does that for us.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们*也可以*遍历输出神经元以找到最高值，但`LogSoftmax`激活函数为我们做了这件事。
- en: So now, when we train our neural network, we have two goals. We want to be able
    to feed in a 28 × 28–pixel array, and we want the neurons in the middle layer
    to have weights and biases (*w* and *B* values) that, when combined, will match
    those pixels to one of the 10 output values.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，现在当我们训练我们的神经网络时，我们有两个目标。我们希望能够输入一个28 × 28像素的数组，并且希望中间层的神经元具有权重和偏差（*w*和*B*值），当它们结合在一起时，将匹配这10个输出值。
- en: The Complete Code
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 完整的代码
- en: Now that we’ve explored the architecture of the neural network, let’s look at
    the complete code for training a model with the Fashion MNIST data.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了神经网络的架构，让我们看看使用Fashion MNIST数据训练模型的完整代码。
- en: 'Here’s the complete code:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是完整的代码：
- en: '[PRE1]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let’s walk through this piece by piece. First, let’s consider where the data
    comes from. In the torchvision library, there’s a datasets collection, and we
    can load Fashion MNIST from that, addressed as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们逐个分析这个代码。首先，让我们考虑数据来自哪里。在torchvision库中，有一个datasets集合，我们可以从那里加载Fashion MNIST，如下所示：
- en: '[PRE2]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'So, in our first block of code, you’ll see these:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在我们的第一个代码块中，你会看到以下内容：
- en: '[PRE3]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now, you might wonder why we’re using *two* datasets. It’s simple: one is for
    training, and one is for testing. The idea here is also simple: if you train a
    neural network on a set of data, it can become an expert on *that* set of data,
    but it may not be effective at understanding or classifying *other* data that
    it previously has not seen. In the case of Fashion MNIST, it might become excellent
    at understanding the difference between a subset of shoes and shirts, but it will
    do poorly when new data is presented to it. So, it’s good practice to always hold
    back a little of your data and *not* train the neural network with it. In this
    case, Fashion MNIST has 70,000 items of data, but only 60,000 of them are used
    to train the network and the other 10,000 are used to test it. If you look at
    the preceding code carefully, you’ll see that the difference between the two lines
    is the `train=` parameter. For the first one, the training set the parameter is
    set to True. For the other, it’s set to False.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可能会想知道为什么我们使用**两个**数据集。很简单：一个用于训练，另一个用于测试。这里的想法也很简单：如果你在数据集上训练一个神经网络，它可以成为该数据集的专家，但它可能无法有效地理解或分类它之前未见过的新数据。在Fashion
    MNIST的情况下，它可能非常擅长理解鞋子和衬衫子集之间的差异，但当新的数据呈现给它时，它可能会表现得很差。因此，保留一部分数据不用于训练神经网络是一个好的实践。在这种情况下，Fashion
    MNIST有70,000个数据项，但只有60,000个用于训练网络，其余的10,000个用于测试。如果你仔细查看前面的代码，你会看到这两行之间的区别在于`train=`参数。对于第一个，训练集的参数设置为True。对于另一个，它设置为False。
- en: 'You’ll also see the `transform` parameter in the datasets. It specifies a transformation
    to apply to the data, which was defined like this:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 你还会在数据集中看到`transform`参数。它指定了对数据应用的一种转换，其定义如下：
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Neural networks typically work with *normalized* values (i.e., those between
    0 and 1). However, the pixels in our image are in the range of 0–255, and the
    values indicate their color depth, with 0 being black, 255 being white, and everything
    in between being shades of gray. To prepare the data for the neural network, we
    should map these shades to values between 0 and 1\. The preceding code will automatically
    do that for you in PyTorch, so applying this `transform` parameter as you’re loading
    the code will then map the pixel values from the [0, 255] integer range to a [0,
    1] floating-point range and load them into an array that’s suitable for the neural
    network (aka a Tensor).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络通常使用**归一化**值（即介于0和1之间的值）。然而，我们图像中的像素值在0-255的范围内，这些值表示它们的颜色深度，其中0是黑色，255是白色，介于两者之间的是灰色。为了准备神经网络的数据，我们应该将这些灰色映射到0到1之间的值。前面的代码将自动为你完成这一点，因此当你加载代码时应用此`transform`参数，然后将像素值从[0,
    255]的整数范围映射到[0, 1]的浮点范围，并将它们加载到适合神经网络的数组中（即张量）。
- en: Our job will be to fit the training images to the training labels in a manner
    that’s similar to how we fit *y* to *x* in [Chapter 1](ch01.html#ch01_introduction_to_pytorch_1748548870019566).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的工作将是在训练图像与训练标签之间进行拟合，这与我们在[第1章](ch01.html#ch01_introduction_to_pytorch_1748548870019566)中拟合*y*到*x*的方式相似。
- en: The math for [why normalized data is better for training neural networks](https://oreil.ly/6d_Po)
    is beyond the scope of this book, but bear in mind that when you’re training a
    neural network in PyTorch, normalization will improve performance. Often, your
    network will not learn and will have massive errors when dealing with nonnormalized
    data. You’ll recall that the *y* = 2*x* – 1 example from [Chapter 1](ch01.html#ch01_introduction_to_pytorch_1748548870019566)
    didn’t require the data to be normalized because it was very simple, but for fun,
    try training it with different values of *x* and *y* where *x* is much larger—and
    you’ll see it quickly fail!
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 关于[为什么归一化数据更适合训练神经网络](https://oreil.ly/6d_Po)的数学原理超出了本书的范围，但请记住，当你使用PyTorch训练神经网络时，归一化会提高性能。通常，你的网络在处理未归一化数据时不会学习，并且会出现巨大的错误。你可能会记得[第1章](ch01.html#ch01_introduction_to_pytorch_1748548870019566)中的*y*
    = 2*x* – 1示例不需要对数据进行归一化，因为它非常简单，但为了好玩，尝试用不同的*x*和*y*值来训练它，其中*x*的值要大得多——你将看到它很快就会失败！
- en: Next, we define the neural network that makes up our model, as discussed earlier,
    but we’ll flesh it out with a bit more detail—including the flattening layers
    and how we want the “forward” pass to work in the model.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们定义构成我们模型的神经网络，正如之前讨论的那样，但我们将用更多细节来完善它——包括展平层以及我们希望在模型中如何实现“正向”传递。
- en: 'Here’s the code:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是代码：
- en: '[PRE5]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Some key things to note here are that the `FashionMNISTModel` class subclasses
    `nn.Module`, which gives you the ability to override its `forward` method. We
    use this method when data is passing forward through the network. Remember back
    in [Chapter 1](ch01.html#ch01_introduction_to_pytorch_1748548870019566) when we
    saw the `loss.backward()` call that did backpropagation and changed the parameters
    of the network? You’ll frequently encounter that same pattern when training models
    with PyTorch. You’ll define functions to execute as the data moves *forward* through
    the network, and then you’ll define others to execute as the gradients that we
    calculate from the loss move *backward* through the network.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这里需要注意的一些关键点是，`FashionMNISTModel`类是`nn.Module`的子类，这给了你覆盖其`forward`方法的能力。我们在数据通过网络向前传递时使用这个方法。记得在[第1章](ch01.html#ch01_introduction_to_pytorch_1748548870019566)中我们看到的`loss.backward()`调用执行了反向传播并改变了网络的参数？当使用PyTorch训练模型时，你经常会遇到相同的模式。你将定义在数据通过网络向前传递时执行的功能，然后定义在从损失计算出的梯度通过网络向后移动时执行的其他功能。
- en: 'So, if we look at the `init` for the class, we define two methods: `flatten`,
    which is set to `nn.FLatten()` (a built-in function to flatten the 2D image to
    1D), and `lin⁠ear​_relu_stack`, which is set to the sequence of layers and operations
    (often abbreviated to *ops*) that define the behavior of the network.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们查看类的`init`方法，我们定义了两个方法：`flatten`，它被设置为`nn.FLatten()`（一个将2D图像展平为1D的内置函数），以及`linear_relu_stack`，它被设置为定义网络行为的层和操作的序列（通常缩写为*ops*）。
- en: In `forward`, we then simply define how these work. First, we flatten our data,
    `x`, by calling `self.flatten`, and then the results will be passed into `linear_relu_stack`
    to get the results. The results are called *logits*, which are log probabilities
    (as defined by `LogSoftmax`) that indicate the confidence the model has that each
    class is the correct classification.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在`forward`方法中，我们简单地定义了这些方法的工作方式。首先，我们通过调用`self.flatten`来展平我们的数据`x`，然后结果将被传递到`linear_relu_stack`以获取结果。这些结果被称为*logits*，它们是（由`LogSoftmax`定义的）对数概率，表示模型对每个类别是正确分类的置信度。
- en: To learn from our data, we need a loss function to calculate how good or bad
    our current “guess” is, and we also need an optimizer to figure out the next set
    of parameters for an improved guess.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从我们的数据中学习，我们需要一个损失函数来计算我们当前“猜测”的好坏，同时我们还需要一个优化器来确定下一次改进猜测的参数集。
- en: 'Here’s an example of how to define both:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何定义这两个方法的示例：
- en: '[PRE6]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: First, let’s look at the loss function. It’s defined as `nn.NLLLoss(),` which
    stands for “Negative Log Likelihood Loss.” Don’t worry—nobody expects you to understand
    what that means at this point! Ultimately, as you work through learning how to
    do ML, you’ll learn about different loss functions, and you’ll experiment with
    which ones work well in particular scenarios. In this case, given that the output
    logits are log probabilities, I chose this loss function because it works particularly
    well for this scenario. As mentioned, over time, you’ll learn a lot more about
    the library of loss functions, and you can choose the best ones for your scenario.
    But for now, just go with the flow and use this one!
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看看损失函数。它被定义为`nn.NLLLoss()`，代表“负对数似然损失”。别担心——在这个阶段，没有人期望你理解它的含义！最终，随着你学习如何进行机器学习，你会了解不同的损失函数，并尝试在特定场景中哪些函数效果更好。在这种情况下，鉴于输出logits是对数概率，我选择了这个损失函数，因为它在这个场景中特别有效。如前所述，随着时间的推移，你会对损失函数库有更多的了解，你可以为你的场景选择最佳的函数。但就目前而言，只需顺其自然，使用这个函数即可！
- en: For the optimizer, I’ve opted to use the `Adam` optimization algorithm. It’s
    similar to the stochastic gradient descent that we used for the *y* = 2*x* – 1
    model in [Chapter 1](ch01.html#ch01_introduction_to_pytorch_1748548870019566),
    but it’s generally faster and more accurate. As with the loss function, you’ll
    learn more about optimization algorithms over time, and you’ll be able to choose
    from the menu of optimizers that fit your scenario best. One important thing here
    is to note that I’ve passed in `model.parameters()` as a parameter to this. This
    parameter passes all the trainable parameters in the model to the optimizer so
    that it can adjust them to help minimize the loss calculated by the loss function.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 对于优化器，我选择使用 `Adam` 优化算法。它与我们在[第1章](ch01.html#ch01_introduction_to_pytorch_1748548870019566)中用于
    *y* = 2*x* – 1 模型的随机梯度下降类似，但通常更快、更准确。与损失函数一样，随着时间的推移，你会了解更多关于优化算法的知识，你将能够从最适合你场景的优化器菜单中进行选择。这里的一个重要事项是注意，我已经将
    `model.parameters()` 作为参数传递给了这个。这个参数将模型中所有的可训练参数传递给优化器，以便它可以调整它们以帮助最小化损失函数计算出的损失。
- en: 'Now, let’s get down to the specifics and explore what the code we use for training
    the network looks like:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们具体探讨一下，看看我们用于训练网络的代码是什么样的：
- en: '[PRE7]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: While some of this will look familiar because it builds on the simple neural
    network from [Chapter 1](ch01.html#ch01_introduction_to_pytorch_1748548870019566),
    there are a few new concepts here, given that we’re using much more data. First,
    you’ll see that we get the `size` of the dataset. We simply use this to report
    on progress, as shown in the very last line.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然其中一些内容看起来很熟悉，因为它是基于[第1章](ch01.html#ch01_introduction_to_pytorch_1748548870019566)中的简单神经网络构建的，但由于我们使用了更多的数据，这里也有一些新的概念。首先，你会看到我们获取了数据集的
    `size`。我们只是简单地使用这个来报告进度，就像在最后一行所展示的那样。
- en: Then, we call `model.train` to explicitly set the model into training mode.
    PyTorch has optimizations that occur during training that are beyond the scope
    of this chapter. (To take advantage of them, you’ll switch the model between training
    and inference modes.) Note that this is more a property of the model than a method,
    but the method syntax is there. Sorry if it’s a little confusing!
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们调用 `model.train` 来显式地将模型设置为训练模式。PyTorch在训练过程中有一些优化，这些优化超出了本章的范围。（为了利用这些优化，你需要在训练和推理模式之间切换模型。）请注意，这更多的是模型的一个属性，而不是一个方法，但方法语法确实存在。如果这有点令人困惑，请见谅！
- en: 'Next up is this interesting line:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是这一有趣的行：
- en: '[PRE8]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Let’s explore this in a little more detail. We made the Fashion MNIST dataset
    available to our code by using a data loader. There are 60,000 records available
    for training, each of which is 784 pixels. That’s a lot of data, and you don’t
    necessarily need all of it in memory at once. The idea of a `batch` is to take
    a chunk of that data—which, by default, is 64 items—and work with it. Enumerating
    the data loader gives us that, so we’ll train with 938 batches, 937 of 64, and
    the last one of 32 because you can’t evenly divide 60,000 by 64!
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地探讨这个问题。我们通过使用数据加载器使 Fashion MNIST 数据集可供我们的代码使用。有 60,000 条记录可用于训练，每条记录有
    784 像素。这是一大批数据，你不必一次性将所有数据都加载到内存中。`batch` 的概念就是取数据的一部分——默认情况下是 64 个项目——并对其进行处理。枚举数据加载器会给我们这个，因此我们将使用
    938 个批次进行训练，其中 937 个批次包含 64 个项目，最后一个批次包含 32 个项目，因为 60,000 不能被 64 整除！
- en: Now, for each batch, we’ll go through the same loop that we saw for the previous
    example. We’ll get the predictions from the model, calculate the loss, backpropagate
    the gradients from the loss function, and optimize with new parameters.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，对于每个批次，我们将执行与上一个示例中相同的循环。我们将从模型获取预测结果，计算损失，从损失函数中反向传播梯度，并使用新的参数进行优化。
- en: We’ll also use the term *epoch* for a training cycle with *all* of the data
    (i.e., every batch). We can then output the status of the training every one hundred
    batches so as not to overload the output console!
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将使用术语 *epoch* 来表示包含 *所有* 数据的训练周期（即每个批次）。然后我们可以每输出一百个批次的状态，以免输出控制台过载！
- en: 'So, to train the network for five epochs, we can use code like this:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，为了训练网络五个周期，我们可以使用如下代码：
- en: '[PRE9]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This will simply call the train function we specified five times—putting the
    network through the training loop by calculating the predictions, figuring out
    the loss, optimizing the parameters, and repeating five times.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这将简单地调用我们指定的训练函数五次——通过计算预测、确定损失、优化参数并重复五次来使网络通过训练循环。
- en: Training the Neural Network
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练神经网络
- en: 'Once you’ve executed the code, you’ll see the network train epoch by epoch.
    Then, after running the training, you’ll see something at the end that looks like
    this:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 执行代码后，你会看到网络逐个epoch进行训练。然后，在训练结束后，你会在最后看到如下内容：
- en: '[PRE10]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: You can see here that over time, the loss has gone down. For example, in my
    case, the loss value at the end of the first epoch was .345, and by the end of
    the fifth epoch, it was .205\. This data shows us that the network is learning.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，随着时间的推移，损失已经下降。例如，在我的情况下，第一个epoch结束时的损失值为.345，到第五个epoch结束时，损失值为.205。这些数据表明网络正在学习。
- en: But how can we tell how *accurately* it’s learning? Note that loss and accuracy,
    while related, don’t have a direct linear relationship—for example, we can’t say
    that if loss is 20%, then accuracy is 80%. So, we need to go a little deeper.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 但我们如何判断它学习得有多准确呢？请注意，损失和准确率虽然相关，但并没有直接的线性关系——例如，我们不能说如果损失是20%，那么准确率就是80%。因此，我们需要深入一点。
- en: 'Recall that when we were getting the data, we got *two* datasets: one for training
    and one for testing. Here’s a great place where we can write code to pass the
    test data through our network and evaluate how accurate the network is at predicting
    answers. We already know the correct answers, so we could do inference on all
    10,000 test records, get the answers that the model predicts, and then check them
    against the ground truth for accuracy.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，当我们获取数据时，我们得到了*两个*数据集：一个用于训练，一个用于测试。这是一个我们可以编写代码来通过我们的网络传递测试数据并评估网络在预测答案方面的准确性的绝佳地方。我们已经知道了正确答案，因此我们可以对所有10,000个测试记录进行推理，获取模型预测的答案，然后检查它们与真实值以确定准确率。
- en: 'Here’s the code:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是代码：
- en: '[PRE11]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: There are a few things to note in this code. First is the `model.eval()` line,
    which indicates that we are switching the model from training mode to inference
    mode. Similarly, `torch.no_grad()`will turn off gradient calculation in PyTorch
    to speed up inference. We’re no longer *training* the model, so we don’t need
    to do all the loss function backpropagation and optimization. We can just turn
    that off.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中有几点需要注意。首先是`model.eval()`这一行，它表示我们将模型从训练模式切换到推理模式。同样，`torch.no_grad()`会在PyTorch中关闭梯度计算以加快推理速度。我们不再进行*训练*模型，因此不需要执行所有的损失函数反向传播和优化。我们可以将其关闭。
- en: 'Then, as it does during training, the network just goes through every item
    in the data loader, gets the prediction for that item, and checks its correctness
    with this line:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，就像在训练过程中一样，网络会遍历数据加载器中的每个项目，获取该项目的预测结果，并使用以下行检查其正确性：
- en: '[PRE12]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: That’s a bit of a mouthful, so let’s break it down.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这有点长，所以让我们来分解一下。
- en: First, the `pred` value will give us the prediction from the network. The network
    outputs 10 values, each of which includes the probability of the class it represents
    being the correct one. Calling `argmax` on this will give us which one had the
    biggest value (i.e., the one with the probability closest to 1). The *y* value
    is the correct answer. For example, if we get a prediction, the neuron with the
    highest value is the sixth one, and *y* = 6, so we know we have a correct answer.
    Also, because we’re dealing in batches, we want to count each time `pred.argmax(1)
    == y` for this batch, hence, the `sum()`.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，`pred`值将给出网络预测的结果。网络输出10个值，每个值都包括它所代表的类是正确类的概率。对这进行`argmax`操作将给出哪个值最大（即概率最接近1的那个）。*y*值是正确答案。例如，如果我们得到一个预测，值最高的神经元是第六个，*y*
    = 6，因此我们知道我们有一个正确答案。另外，因为我们处理的是批量数据，我们想要计算每个批次中`pred.argmax(1) == y`的次数，因此，使用`sum()`。
- en: 'Therefore, our accuracy value will be the sum of correct items divided by the
    total number of items. So, when you run this code after training the model, you
    should see output like this:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们的准确率值将是正确项目数除以项目总数的总和。所以，当你训练完模型后运行此代码，你应该看到如下输出：
- en: '[PRE13]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Remarkably, after running the neural network for only five epochs, we can see
    that it is 86.9% accurate on data it hadn’t previously seen!
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 令人惊讶的是，在仅运行了五个epoch之后，我们可以看到它在之前未见过的数据上的准确率达到了86.9%！
- en: At this point, you may be thinking that it’s really nice to see the accuracy
    of the model on the test set, but you may also be asking why we’ve only reported
    loss on the training—why not also report accuracy there? It seems silly to finish
    training the model by only looking at minimizing loss and *then* to figure out
    the accuracy. And you’d be right!
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你可能认为看到模型在测试集上的准确度真的很不错，但你可能也会问为什么我们只报告了训练中的损失——为什么不也报告准确度呢？只通过最小化损失来结束训练模型，然后才去计算准确度似乎很荒谬。而且你是对的！
- en: 'Fortunately, updating the model training code to *also* report on accuracy
    is pretty easy to do. Here’s a function called `get_accuracy()` that you can use
    during training:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，将模型训练代码更新为**也**报告准确度相当容易。这里有一个名为`get_accuracy()`的函数，你可以在训练过程中使用：
- en: '[PRE14]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Then, in your training loop, you can simply call this function after the loss
    function call like this:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在你的训练循环中，你可以在调用损失函数之后简单地调用这个函数，如下所示：
- en: '[PRE15]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'And when you’re reporting on the output of the training, you can use the accuracy
    metric like this:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 当你报告训练输出时，你可以使用准确度指标如下：
- en: '[PRE16]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Running this will give you output a bit like this:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这个函数会给出类似以下输出：
- en: '[PRE17]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, you’re probably wondering why the accuracy for the test data (86.9%) is
    *lower* than the accuracy for the training data (88.59%). This is very common,
    and when you think about it, it makes sense: the neural network only really knows
    how to match the inputs it has been trained on with the outputs for those values.
    Our hope is that given enough data, the network will be able to generalize from
    the examples it has seen and thus “learn” what a shoe or a dress looks like. But
    there will always be examples of items that it hasn’t seen that are also different
    enough from what it has seen to confuse it.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可能想知道为什么测试数据的准确度（86.9%）低于训练数据的准确度（88.59%）。这是非常常见的，当你这么想的时候，这是有道理的：神经网络实际上只知道如何将训练过的输入与那些值的输出相匹配。我们的希望是，给定足够的数据，网络将能够从它看到的例子中推广，从而“学习”鞋或连衣裙的样子。但总会有一些它没有看到且与它看到的不同到足以使其困惑的物品。
- en: For example, if you grew up only ever seeing sneakers, then that’s what a shoe
    looks like to you. So, when you first see a high-heeled shoe, you might be a little
    confused. From your experience, it’s probably a shoe, but you don’t know for sure.
    That’s exactly what a neural network “thinks” when it “sees” inputs that are different
    enough from what it’s been trained on.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你从小只见过运动鞋，那么对你来说鞋子的样子就是这样。所以，当你第一次看到高跟鞋时，你可能会有些困惑。根据你的经验，它可能是一双鞋，但你不能确定。这正是神经网络“认为”它在“看到”与它训练过的输入足够不同的输入时的想法。
- en: Exploring the Model Output
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索模型输出
- en: 'Now that we’ve trained the model and gotten a good gauge of its accuracy by
    using the test set, let’s explore it a little. Here’s a function we can use to
    predict a single image:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经训练了模型，并使用测试集对其准确度进行了良好的评估，让我们稍微探索一下。这里有一个我们可以用来预测单个图像的函数：
- en: '[PRE18]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Let’s start with this code, which should look familiar to you now that you’ve
    seen the previous accuracy calculation code:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从这段代码开始，现在你应该已经熟悉了，因为你已经看到了之前的准确度计算代码：
- en: '[PRE19]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Here, we get the `image`, send it to the `model`, get back a `prediction`,
    and `print` it out. Then, we get the `argmax` of that to show the label. Here’s
    an example output of the `prediction`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们获取`图像`，将其发送到`模型`，得到一个`预测`，并将其打印出来。然后，我们获取`argmax`以显示标签。以下是`预测`的一个示例输出：
- en: '[PRE20]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: These numbers may seem vague, but ultimately, our goal is simply to look for
    the biggest one! The `Softmax` function gets the `log()` of the value, where `log(1)`
    is zero and the log of any value less than one is a negative value. As you look
    through the list, you’ll notice that the value closest to 0 (–0.3285) is the very
    last one. This indicates that the function believes the class for this image should
    be class number 9\. (There are 10 classes in Fashion MNIST, which are numbered
    0 through 9.)
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这些数字可能看起来有些模糊，但最终，我们的目标只是寻找最大的一个！`Softmax`函数获取值的`log()`，其中`log(1)`为零，任何小于一的值的对数都是负值。当你查看列表时，你会注意到最接近0（-0.3285）的值是最后一个。这表明该函数认为这个图像的类别应该是第9类。（Fashion
    MNIST中有10个类别，编号为0到9。）
- en: Fashion MNIST’s class number 9 is “Ankle Boot,” so I’ve also included the code
    to render the image in [Figure 2-6](#ch02_figure_6_1748548889066448).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: Fashion MNIST的第9个类别是“踝靴”，因此我还包括了在[图2-6](#ch02_figure_6_1748548889066448)中渲染图像的代码。
- en: Also, as we can see, this is an example of where the model got the prediction
    right. The ground truth was that it’s label 9, and the prediction was for number
    9\. Drawing the image so that we mere humans can compare the two also gives us
    an ankle boot!
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，正如我们所见，这是一个模型做出正确预测的例子。真实标签是9，预测的是数字9。绘制图像以便我们这些凡人可以比较这两个结果，也给了我们一双踝靴！
- en: '![](assets/aiml_0206.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![](assets/aiml_0206.png)'
- en: Figure 2-6\. Exploring the output of the predictive model
  id: totrans-120
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 2-6\. 探索预测模型的输出
- en: Now, try a few different values for yourself and see if you can find anywhere
    the model gets it wrong.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，尝试为自己设置几个不同的值，看看你是否能找到模型出错的地方。
- en: Overfitting
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 过拟合
- en: 'In the last example, we trained for only five epochs. That is, we went through
    the entire training loop of having the neurons randomly initialized and checked
    against their labels, then that performance was measured by the loss function
    and updated by the optimizer five times. And the results we got were pretty good:
    88.59% accuracy on the training set and 86.5% on the test set. So what happens
    if we train for longer?'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一个例子中，我们只训练了五个epoch。也就是说，我们进行了整个训练循环，包括随机初始化神经元并检查其标签，然后通过损失函数测量性能并由优化器更新五次。我们得到的结果相当不错：训练集上的准确率为88.59%，测试集上的准确率为86.5%。那么，如果我们训练更长的时间会发生什么呢？
- en: 'Next, try updating it to train for 50 epochs instead of 5\. In my case, I got
    the following accuracy figures on the training set:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，尝试将其更新为训练50个epoch而不是5个。在我的情况下，我在训练集上得到了以下准确性指标：
- en: '[PRE21]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'This is particularly exciting because we’re doing much better: we’re getting
    96.15% accuracy!'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这尤其令人兴奋，因为我们做得更好：我们得到了96.15%的准确率！
- en: 'However, for the test set, accuracy reached 89.2%:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于测试集，准确率达到了89.2%：
- en: '[PRE22]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: So, we got a big improvement over the training set and a smaller one over the
    test set. This might suggest that training our network for much longer would lead
    to much better results—but that’s not always the case. The network is doing much
    better with the training data, but the model is not necessarily a better model.
    In fact, the divergence in the accuracy numbers shows that the model might have
    become overspecialized to the training data, in a process that’s often called
    *overfitting*. As you build more neural networks, this problem is something to
    watch out for—and as you go through this book, you’ll learn a number of techniques
    to avoid it!
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们在训练集上取得了很大的改进，而在测试集上改进较小。这可能会表明，长时间训练我们的网络将导致更好的结果——但这并不总是如此。网络在训练数据上做得更好，但模型不一定是一个更好的模型。事实上，准确率数字的差异表明，模型可能已经过度专门化到训练数据上，这个过程通常被称为*过拟合*。随着你构建更多的神经网络，这个问题是你要注意的——而且随着你阅读这本书，你将学习到许多避免它的技术！
- en: Early Stopping
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提前停止
- en: In each of the cases so far, we’ve hardcoded the number of epochs we’re training
    for. While that works, we might want to train until we reach the desired accuracy
    instead of constantly trying different numbers of epochs and training and retraining
    until we get to our desired value. So, for example, if we want to train until
    the model is at 95% accuracy on the training set, and if we want to do it without
    knowing in advance how many epochs it will take. . .how can we do it?
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在每种情况下，我们都硬编码了我们要训练的epoch数量。虽然这可行，但我们可能希望训练直到达到所需的准确性，而不是不断尝试不同的epoch数量并重新训练，直到达到我们期望的值。所以，例如，如果我们想训练直到模型在训练集上的准确率达到95%，而且如果我们想在事先不知道需要多少epoch的情况下完成它……我们该如何做？
- en: 'Given that we’ve updated our code to check the accuracy as the model trained
    and to print it out, now, all we have to do is check that accuracy and end the
    training if it’s above a certain amount—such as 95% (or 0.95 when normalized).
    For example, we can do this:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们已经更新了代码，以便在模型训练时检查准确性并将其打印出来，现在我们只需检查该准确性，如果它超过一定数量——例如95%（或归一化后的0.95），就结束训练。例如，我们可以这样做：
- en: '[PRE23]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Note that if we use this code inside the `if batch % 100 == 0` block, we can
    break the training loop before all batches in a particular epoch have been processed.
    It’s better to do this check at the end of the epoch, so we need to be sure to
    place the `if avg_accuracy >= 95` in the right place!
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，如果我们在这个 `if batch % 100 == 0` 块中使用此代码，我们可以在处理特定epoch中的所有批次之前中断训练循环。最好在epoch结束时进行此检查，因此我们需要确保将
    `if avg_accuracy >= 95` 放在正确的位置！
- en: Now, when we’re training, at the end of every epoch, the average accuracy for
    the epoch will be calculated—and if it hits 95%, the training will stop. Previously,
    I had trained the model for 50 epochs to get 96.15% accuracy, but with this early
    stopping, where I’ve defined 95% as “good enough,” you can see that the model
    stopped training after only 37 epochs. Interestingly, accuracy was 94.99% for
    a couple of epochs before that, so I might have been able to stop even earlier!
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当我们进行训练时，在每个epoch结束时，将计算该epoch的平均准确率——如果达到95%，则训练停止。之前，我训练了模型50个epoch以获得96.15%的准确率，但通过这种早期停止，我将95%定义为“足够好”，你可以看到模型在仅37个epoch后停止了训练。有趣的是，在那之前的几个epoch中，准确率达到了94.99%，所以我可能还能更早地停止训练！
- en: 'This process of *early stopping* is very powerful in helping you save time
    as you evaluate different model architectures for solving specific problems. It
    helps you train your model until it’s “good enough,” instead of having a fixed
    training loop. For example, the process can look like this:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 这种*早期停止*的过程在帮助你评估不同模型架构以解决特定问题时非常有用，它能帮助你训练模型直到“足够好”，而不是有一个固定的训练循环。例如，这个过程可能看起来像这样：
- en: '[PRE24]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This process can save you a lot of time you would otherwise spend manually checking
    on the network to see if it’s learning appropriately.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程可以节省你大量原本需要手动检查网络是否适当学习的时间。
- en: Summary
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In [Chapter 1](ch01.html#ch01_introduction_to_pytorch_1748548870019566), you
    learned about how ML is based on fitting features to labels through sophisticated
    pattern matching with a neural network. In this chapter, you took that to the
    next level by going beyond a single neuron and learning how to create your first
    (very basic) computer vision neural network. The network was somewhat limited
    because of the data: all the images were 28 × 28 grayscale, with the item of clothing
    centered in the frame. This is a good start, but it’s a very controlled scenario.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第一章](ch01.html#ch01_introduction_to_pytorch_1748548870019566)中，你学习了机器学习是如何通过神经网络进行复杂的模式匹配，将特征拟合到标签上的。在本章中，你将这一概念提升到了新的水平，不仅超越了单个神经元，还学习了如何创建你的第一个（非常基础的）计算机视觉神经网络。由于数据有限，这个网络有所局限：所有图像都是28
    × 28的灰度图，衣物项位于画面中央。这是一个良好的开端，但这是一个非常受控的场景。
- en: To do better at vision, you may need the computer to learn features of an image
    instead of learning merely the raw pixels. You can do that with a process called
    *convolutions*, and in the next chapter, you’ll learn how to define convolutional
    neural networks to understand the contents of images.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在视觉方面做得更好，你可能需要计算机学习图像的特征，而不是仅仅学习原始像素。你可以通过一个叫做*卷积*的过程来实现这一点，在下一章中，你将学习如何定义卷积神经网络来理解图像的内容。
