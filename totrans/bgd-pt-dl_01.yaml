- en: Chapter 1\. Getting Started with PyTorch
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: 第1章。开始使用PyTorch
- en: 'In this chapter we set up all we need for working with PyTorch. Once we’ve
    done that, every chapter following will build on this initial foundation, so it’s
    important that we get it right. This leads to our first fundamental question:
    should you build a custom deep learning computer or just use one of the many cloud-based
    resources available?'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们设置了使用PyTorch所需的一切。一旦我们完成了这一步，接下来的每一章都将在这个初始基础上构建，因此我们必须做对。这带来了我们的第一个基本问题：您应该构建一个定制的深度学习计算机，还是使用众多可用的基于云的资源之一？
- en: Building a Custom Deep Learning Machine
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 构建定制深度学习机器
- en: There is an urge when diving into deep learning to build yourself a monster
    for all your compute needs. You can spend days looking over different types of
    graphics cards, learning the memory lanes possible CPU selections will offer you,
    the best sort of memory to buy, and just how big an SSD drive you can purchase
    to make your disk access as fast as possible. I am not claiming any immunity from
    this; I spent a month a couple of years ago making a list of parts and building
    a new computer on my dining room table.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习中，有一种冲动，想要为所有计算需求构建一个庞然大物。您可以花费数天时间查看不同类型的显卡，了解可能的CPU选择将为您提供的内存通道，购买最佳类型的内存，以及您可以购买多大的SSD驱动器以使磁盘访问尽可能快。我并不是在宣称自己免疫于此；几年前，我花了一个月的时间列出零件清单，在我的餐桌上组装了一台新电脑。
- en: 'My advice, especially if you’re new to deep learning, is this: don’t do it.
    You can easily spend several thousands of dollars on a machine that you may not
    use all that much. Instead, I recommend that you work through this book by using
    cloud resources (in either Amazon Web Services, Google Cloud, or Microsoft Azure)
    and only then start thinking about building your own machine if you feel that
    you require a single machine for 24/7 operation. You do not need to make a massive
    investment in hardware to run any of the code in this book.'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我的建议，特别是如果您是深度学习的新手，是这样的：不要这样做。您可以轻松地在一台您可能不会经常使用的机器上花费数千美元。相反，我建议您通过使用云资源（无论是亚马逊网络服务、谷歌云还是微软Azure）来阅读本书，然后再考虑是否需要为自己构建一台机器，如果您觉得需要一台24/7运行的单机。您不需要在硬件上进行巨额投资来运行本书中的任何代码。
- en: You might not ever need to build a custom machine for yourself. There’s something
    of a sweet spot, where it can be cheaper to build a custom rig if you know your
    calculations are always going to be restricted to a single machine (with at most
    a handful of GPUs). However, if your compute starts to require spanning multiple
    machines and GPUs, the cloud becomes appealing again. Given the cost of putting
    a custom machine together, I’d think long and hard before diving in.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能永远不需要为自己构建一台定制机器。有一个甜蜜的点，如果您知道您的计算总是限制在一台机器上（最多使用几个GPU），那么构建一个定制机器可能会更便宜。然而，如果您的计算需要跨多台机器和GPU，云计算又变得有吸引力起来。考虑到组装一台定制机器的成本，我建议在决定之前三思而后行。
- en: If I haven’t managed to put you off from building your own, the following sections
    provide suggestions for what you would need to do so.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我没有阻止您自己构建的话，接下来的部分将提供您需要做的建议。
- en: GPU
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: GPU
- en: The heart of every deep learning box, the GPU, is what is going to power the
    majority of PyTorch’s calculations, and it’s likely going to be the most expensive
    component in your machine. In recent years, the prices of GPUs have increased,
    and the supplies have dwindled, because of their use in mining cryptocurrency
    like Bitcoin. Thankfully, that bubble seems to be receding, and supplies of GPUs
    are back to being a little more plentiful.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 每个深度学习盒子的核心，GPU，将为大多数PyTorch的计算提供动力，并且很可能是您机器中最昂贵的组件。近年来，由于它们在挖掘比特币等加密货币中的使用，GPU的价格已经上涨，供应量也在减少。幸运的是，这种泡沫似乎正在消退，GPU的供应量又变得更加充裕。
- en: At the time of this writing, I recommend obtaining the NVIDIA GeForce RTX 2080
    Ti. For a cheaper option, feel free to go for the 1080 Ti (though if you are weighing
    the decision to get the 1080 Ti for budgetary reasons, I again suggest that you
    look at cloud options instead). Although AMD-manufactured GPU cards do exist,
    their support in PyTorch is currently not good enough to recommend anything other
    than an NVIDIA card. But keep a lookout for their ROCm technology, which should
    eventually make them a credible alternative in the GPU space.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，我建议购买NVIDIA GeForce RTX 2080 Ti。如果您想要更便宜的选择，可以选择1080 Ti（尽管如果您因预算原因在考虑是否选择1080
    Ti，我再次建议您考虑云选项）。尽管AMD制造的GPU卡确实存在，但它们在PyTorch中的支持目前还不够好，无法推荐除NVIDIA卡以外的其他产品。但请留意他们的ROCm技术，这将最终使它们成为GPU领域一个可信赖的替代品。
- en: CPU/Motherboard
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: CPU/主板
- en: You’ll probably want to spring for a Z370 series motherboard. Many people will
    tell you that the CPU doesn’t matter for deep learning and that you can get by
    with a lower-speed CPU as long as you have a powerful GPU. In my experience, you’ll
    be surprised at how often the CPU can become a bottleneck, especially when working
    with augmented data.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会选择购买Z370系列主板。很多人会告诉您，CPU对于深度学习并不重要，只要有强大的GPU，您可以使用速度较低的CPU。但根据我的经验，CPU往往会成为瓶颈，尤其是在处理增强数据时。
- en: RAM
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 内存
- en: More RAM is good, as it means you can keep more data inside without having to
    hit the much slower disk storage (especially important during your training stages).
    You should be looking at a minimum of 64GB DDR4 memory for your machine.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 更多的内存是好的，因为这意味着您可以将更多的数据保存在内存中，而不必访问速度慢得多的磁盘存储（尤其是在训练阶段非常重要）。您应该为您的机器至少考虑64GB
    DDR4内存。
- en: Storage
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 存储
- en: 'Storage for a custom rig should be installed in two classes: first, an M2-interface
    solid-state drive (SSD) — as big as you can afford — for your hot data to keep
    access as fast as possible when you’re actively working on a project. For the
    second class of storage, add in a 4TB Serial ATA (SATA) drive for data that you’re
    not actively working on, and transfer to hot and cold storage as required.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: I recommend that you take a look at [PCPartPicker](https://pcpartpicker.com)
    to glance at other people’s deep learning machines (you can see all the weird
    and wild case ideas, too!). You’ll get a feel for lists of machine parts and associated
    prices, which can fluctuate wildly, especially for GPU cards.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Now that you’ve looked at your local, physical machine options, it’s time to
    head to the clouds.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: Deep Learning in the Cloud
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: 'OK, so why is the cloud option better, you might ask? Especially if you’ve
    looked at the Amazon Web Services (AWS) pricing scheme and worked out that building
    a deep learning machine will pay for itself within six months? Think about it:
    if you’re just starting out, you are not going to be using that machine 24/7 for
    those six months. You’re just not. Which means that you can shut off the cloud
    machine and pay pennies for the data being stored in the meantime.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: And if you’re starting out, you don’t need to go all out and use one of NVIDIA’s
    leviathan Tesla V100 cards attached to your cloud instance straightaway. You can
    start out with one of the much cheaper (sometimes even free) K80-based instances
    and move up to the more powerful card when you’re ready. That is a trifle less
    expensive than buying a basic GPU card and upgrading to a 2080Ti on your custom
    box. Plus if you want to add eight V100 cards to a single instance, you can do
    it with just a few clicks. Try doing that with your own hardware.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: The other issue is maintenance. If you get yourself into the good habit of re-creating
    your cloud instances on a regular basis (ideally starting anew every time you
    come back to work on your experiments), you’ll almost always have a machine that
    is up to date. If you have your own machine, updating is up to you. This is where
    I confess that I do have my own custom deep learning machine, and I ignored the
    Ubuntu installation on it for so long that it fell out of supported updates, resulting
    in an eventual day spent trying to get the system back to a place where it was
    receiving updates again. Embarrassing.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: 'Anyway, you’ve made the decision to go to the cloud. Hurrah! Next: which provider?'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Google Colaboratory
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: But wait — before we look at providers, what if you don’t want to do any work
    at all? None of that pesky building a machine or having to go through all the
    trouble of setting up instances in the cloud? Where’s the really lazy option?
    Google has the right thing for you. [Colaboratory (or Colab)](https://colab.research.google.com)
    is a mostly free, zero-installation-required custom Jupyter Notebook environment.
    You’ll need a Google account to set up your own notebooks. [Figure 1-1](#filepos34104)
    shows a screenshot of a notebook created in Colab.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: What makes Colab a great way to dive into deep learning is that it includes
    preinstalled versions of TensorFlow and PyTorch, so you don’t have to do any setup
    beyond typing `import torch`, and every user can get free access to a NVIDIA T4
    GPU for up to 12 hours of continuous runtime. For free. To put that in context,
    empirical research suggests that you get about half the speed of a 1080 Ti for
    training, but with an extra 5GB of memory so you can store larger models. It also
    offers the ability to connect to more recent GPUs and Google’s custom TPU hardware
    in a paid option, but you can pretty much do every example in this book for nothing
    with Colab. For that reason, I recommend using Colab alongside this book to begin
    with, and then you can decide to branch out to dedicated cloud instances and/or
    your own personal deep learning server if needed.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
- en: '![](images/00055.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
- en: Figure 1-1\. Google Colab(oratory)
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图1-1。Google Colab（oratory）
- en: Colab is the zero-effort approach, but you may want to have a little more control
    over how things are installed or get Secure Shell (SSH) access to your instance
    on the cloud, so let’s have a look at what the main cloud providers offer.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Colab是零努力的方法，但您可能希望对安装方式或在云上访问实例的安全外壳（SSH）有更多控制，因此让我们看看主要云服务提供商提供了什么。
- en: Cloud Providers
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 云服务提供商
- en: Each of the big three cloud providers (Amazon Web Services, Google Cloud Platform,
    and Microsoft’s Azure) offers GPU-based instances (also referred to as virtual
    machines or VMs) and official images to deploy on those instances. They have all
    you need to get up and running without having to install drivers and Python libraries
    yourself. Let’s have a run-through of what each provider offers.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 三大云服务提供商（亚马逊网络服务、谷歌云平台和微软的Azure）都提供基于GPU的实例（也称为虚拟机或VM）和官方镜像，可部署在这些实例上。它们提供了一切你需要的，让你可以立即开始运行，而无需自己安装驱动程序和Python库。让我们看看每个提供商提供了什么。
- en: Amazon Web Services
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊网络服务
- en: AWS, the 800-pound gorilla of the cloud market, is more than happy to fulfill
    your GPU needs and offers the P2 and P3 instance types to help you out. (The G3
    instance type tends to be used more in actual graphics-based applications like
    video encoding, so we won’t cover it here.) The P2 instances use the older NVIDIA
    K80 cards (a maximum of 16 can be connected to one instance), and the P3 instances
    use the blazing-fast NVIDIA V100 cards (and you can strap eight of those onto
    one instance if you dare).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: AWS是云市场的800磅大猩猩，非常乐意满足您的GPU需求，并提供P2和P3实例类型来帮助您。 （G3实例类型更倾向于在实际的基于图形的应用程序中使用，如视频编码，因此我们不会在这里涵盖。）P2实例使用较旧的NVIDIA
    K80卡（最多可以连接16个到一个实例），而P3实例使用快速的NVIDIA V100卡（如果您敢的话，可以将八个连接到一个实例）。
- en: If you’re going to use AWS, my recommendation for this book is to go with the
    `p2.xlarge` class. This will cost you just 90 cents an hour at the time of this
    writing and provides plenty of power for working through the examples. You may
    want to bump up to the P3 classes when you start working on some meaty Kaggle
    competitions.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您要使用AWS，我建议为本书选择`p2.xlarge`类。在撰写本文时，这将每小时仅花费90美分，并为您提供足够的计算能力来完成示例。当您开始参与一些庞大的Kaggle竞赛时，您可能希望升级到P3类。
- en: 'Creating a running deep learning box on AWS is incredibly easy:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在AWS上创建并运行深度学习盒子非常容易：
- en: Sign into the AWS console.
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到AWS控制台。
- en: Select EC2 and click Launch Instance.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择EC2并点击启动实例。
- en: Search for the Deep Learning AMI (Ubuntu) option and select it.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 搜索深度学习AMI（Ubuntu）选项并选择它。
- en: Choose `p2.xlarge` as your instance type.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择`p2.xlarge`作为您的实例类型。
- en: Launch the instance, either by creating a new key pair or reusing an existing
    key pair.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动实例，可以创建新的密钥对或重用现有的密钥对。
- en: 'Connect to the instance by using SSH and redirecting port 8888 on your local
    machine to the instance:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过使用SSH连接到实例，并将本地机器上的端口8888重定向到实例：
- en: '`ssh -L localhost:8888:localhost:8888` `\` `-i` `your .pem filename` `ubuntu@``your
    instance DNS`'
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`ssh -L localhost:8888:localhost:8888` `\` `-i` `your .pem filename` `ubuntu@``your
    instance DNS`'
- en: Start Jupyter Notebook by entering `jupyter notebook`. Copy the URL that gets
    generated and paste it into your browser to access Jupyter.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过输入`jupyter notebook`启动Jupyter Notebook。复制生成的URL并粘贴到浏览器中以访问Jupyter。
- en: Remember to shut down your instance when you’re not using it! You can do this
    by right-clicking the instance in the web interface and selecting the Shutdown
    option. This will shut down the instance, and you won’t be charged for the instance
    while it’s not running. However, you will be charged for the storage space that
    you have allocated for it even if the instance is turned off, so be aware of that.
    To delete the instance and storage entirely, select the Terminate option instead.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 记得在不使用实例时关闭它！您可以通过在Web界面中右键单击实例并选择关闭选项来执行此操作。这将关闭实例，并在实例未运行时不会向您收费。但是，即使实例已关闭，您为其分配的存储空间也会产生费用，所以请注意。要完全删除实例和存储，请选择终止选项。
- en: Azure
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Azure
- en: Like AWS, Azure offers a mixture of cheaper K80-based instances and more expensive
    Tesla V100 instances. Azure also offers instances based on the older P100 hardware
    as a halfway point between the other two. Again, I recommend the instance type
    that uses a single K80 (NC6) for this book, which also costs 90 cents per hour,
    and move onto other NC, NCv2 (P100), or NCv3 (V100) types as you need them.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 与AWS一样，Azure提供了一些更便宜的基于K80的实例和更昂贵的Tesla V100实例。Azure还提供基于较旧的P100硬件的实例，作为其他两种之间的中间点。同样，我建议为本书使用单个K80（NC6）的实例类型，这也每小时花费90美分，并根据需要切换到其他NC、NCv2（P100）或NCv3（V100）类型。
- en: 'Here’s how you set up the VM in Azure:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何在Azure中设置VM：
- en: Log in to the Azure portal and find the Data Science Virtual Machine image in
    the Azure Marketplace.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到Azure门户，并在Azure Marketplace中找到数据科学虚拟机镜像。
- en: Click the Get It Now button.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击立即获取按钮。
- en: Fill in the details of the VM (give it a name, choose SSD disk over HDD, an
    SSH username/password, the subscription you’ll be billing the instance to, and
    set the location to be the nearest to you that offers the NC instance type).
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 填写VM的详细信息（为其命名，选择SSD磁盘而不是HDD，设置SSH用户名/密码，将实例计费的订阅，以及将位置设置为最接近您的位置，以提供NC实例类型）。
- en: Click the Create option. The instance should be provisioned in about five minutes.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击创建选项。实例应在约五分钟内配置完成。
- en: You can use SSH with the username/password that you specified to that instance’s
    public Domain Name System (DNS) name.
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您可以使用指定给该实例的用户名/密码通过SSH连接到该实例的公共域名系统（DNS）名称。
- en: Jupyter Notebook should run when the instance is provisioned; navigate to http://`dns
    name of instance`:8000 and use the username/password combination that you used
    for SSH to log in.
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当实例配置完成时，Jupyter Notebook应该运行；导航到http://`实例的DNS名称`:8000，并使用您用于SSH登录的用户名/密码组合登录。
- en: Google Cloud Platform
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 谷歌云平台
- en: In addition to offering K80, P100, and V100-backed instances like Amazon and
    Azure, Google Cloud Platform (GCP) offers the aforementioned TPUs for those who
    have tremendous data and compute requirements. You don’t need TPUs for this book,
    and they are pricey, but they will work with PyTorch 1.0, so don’t think that
    you have to use TensorFlow in order to take advantage of them if you have a project
    that requires their use.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 除了像亚马逊和Azure一样提供K80、P100和V100支持的实例外，Google Cloud Platform（GCP）还为那些具有巨大数据和计算需求的人提供了上述的TPUs。您不需要TPUs来阅读本书，它们价格昂贵，但它们将与PyTorch
    1.0一起使用，因此不要认为您必须使用TensorFlow才能利用它们，如果您有一个需要使用它们的项目。
- en: 'Getting started with Google Cloud is also pretty easy:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 开始使用Google Cloud也很容易：
- en: Search for Deep Learning VM on the GCP Marketplace.
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在GCP Marketplace上搜索Deep Learning VM。
- en: Click Launch on Compute Engine.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Compute Engine上点击启动。
- en: Give the instance a name and assign it to the region closest to you.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为实例命名并将其分配给您最近的区域。
- en: Set the machine type to 8 vCPUs.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将机器类型设置为8个vCPU。
- en: Set GPU to 1 K80\.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将GPU设置为1 K80。
- en: Ensure that PyTorch 1.0 is selected in the Framework section.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保在框架部分选择了PyTorch 1.0。
- en: Select the “Install NVIDIA GPU automatically on first startup?” checkbox.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择“第一次启动时自动安装NVIDIA GPU？”复选框。
- en: Set Boot disk to SSD Persistent Disk.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将引导磁盘设置为SSD持久磁盘。
- en: Click the Deploy option. The VM will take about 5 minutes to fully deploy.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击部署选项。VM将需要大约5分钟才能完全部署。
- en: 'To connect to Jupyter on the instance, make sure you’re logged into the correct
    project in `gcloud` and issue this command:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要连接到实例上的Jupyter，请确保您已登录到`gcloud`中的正确项目，并发出此命令：
- en: '`gcloud compute ssh _INSTANCE_NAME_ -- -L 8080:localhost:8080`'
  id: totrans-66
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`gcloud compute ssh _INSTANCE_NAME_ -- -L 8080:localhost:8080`'
- en: The charges for Google Cloud should work out to about 70 cents an hour, making
    it the cheapest of the three major cloud providers.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud的费用应该大约是每小时70美分，这是三大云服务提供商中最便宜的。
- en: Which Cloud Provider Should I Use?
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我应该使用哪个云服务提供商？
- en: If you have nothing pulling you in any direction, I recommend Google Cloud Platform
    (GCP); it’s the cheapest option, and you can scale all the way up to using TPUs
    if required, with a lot more flexibility than either the AWS or Azure offerings.
    But if you have resources on one of the other two platforms already, you’ll be
    absolutely fine running in those environments.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有任何事情吸引您，我建议使用Google Cloud Platform（GCP）；这是最便宜的选择，如果需要，您可以扩展到使用TPUs，比AWS或Azure提供的灵活性更大。但是，如果您已经在另外两个平台上拥有资源，那么在这些环境中运行也完全没问题。
- en: Once you have your cloud instance running, you’ll be able to log in to its copy
    of Jupyter Notebook, so let’s take a look at that next.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您的云实例运行起来，您就可以登录到其Jupyter Notebook的副本，接下来让我们来看看。
- en: Using Jupyter Notebook
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Jupyter Notebook
- en: 'If you haven’t come across it before, here’s the lowdown on Jupyter Notebook:
    this browser-based environment allows you to mix live code with text, images,
    and visualizations and has become one of the de facto tools of data scientists
    all over the world. Notebooks created in Jupyter can be easily shared; indeed,
    you’ll find [all the notebooks in this book](https://oreil.ly/iBh4V). You can
    see a screenshot of Jupyter Notebook in action in [Figure 1-2](#filepos44456).'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您以前没有接触过它，这里是关于Jupyter Notebook的简介：这个基于浏览器的环境允许您将实时代码与文本、图像和可视化混合在一起，已经成为全球数据科学家的事实标准工具之一。在Jupyter中创建的笔记本可以轻松共享；实际上，您会在[本书中的所有笔记本](https://oreil.ly/iBh4V)中找到。您可以在[图1-2](#filepos44456)中看到Jupyter
    Notebook的截图。
- en: We won’t be using any advanced features of Jupyter in this book; all you need
    to know is how to create a new notebook and that Shift-Enter runs the contents
    of a cell. But if you’ve never used it before, I suggest browsing the [Jupyter
    documentation](https://oreil.ly/-Yhff) before you get to [Chapter 2](index_split_033.html#filepos97807).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们不会使用Jupyter的任何高级功能；您只需要知道如何创建一个新的笔记本，以及Shift-Enter如何运行单元格的内容。但是，如果您以前从未使用过它，我建议在进入[第2章](index_split_033.html#filepos97807)之前浏览[Jupyter文档](https://oreil.ly/-Yhff)。
- en: '![](images/00065.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](images/00065.jpg)'
- en: Figure 1-2\. Jupyter Notebook
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图1-2。Jupyter Notebook
- en: 'Before we get into using PyTorch, we’ll cover one last thing: how to install
    everything manually.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始使用PyTorch之前，我们将最后介绍一件事：如何手动安装所有内容。
- en: Installing PyTorch from Scratch
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 从头开始安装PyTorch
- en: Perhaps you want a little more control over your software than using one of
    the preceding cloud-provided images. Or you need a particular version of PyTorch
    for your code. Or, despite all my cautionary warnings, you really want that rig
    in your basement. Let’s look at how to install PyTorch on a Linux server in general.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 也许您想对软件有更多控制，而不是使用前面提到的云提供的镜像之一。或者您需要为您的代码使用特定版本的PyTorch。或者，尽管我提出了所有警告，您真的想要在地下室安装那个设备。让我们看看如何在Linux服务器上一般安装PyTorch。
- en: WARNING
  id: totrans-79
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 警告
- en: You can use PyTorch with Python 2.x, but I strongly recommend against doing
    so. While the Python 2.x to 3.x upgrade saga has been running for over a decade
    now, more and more packages are beginning to drop Python 2.x support. So unless
    you have a good reason, make sure your system is running Python 3.
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 您可以在Python 2.x中使用PyTorch，但我强烈建议不要这样做。尽管Python 2.x到3.x的升级已经进行了十多年，但越来越多的软件包开始放弃对Python
    2.x的支持。因此，除非您有充分理由，请确保您的系统正在运行Python 3。
- en: Download CUDA
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 下载CUDA
- en: Although PyTorch can be run entirely in CPU mode, in most cases, GPU-powered
    PyTorch is required for practical usage, so we’re going to need GPU support. This
    is fairly straightforward; assuming you have an NVIDIA card, this is provided
    by their Compute Unified Device Architecture (CUDA) API. [Download the appropriate
    package format](https://oreil.ly/Gx_q2) for your flavor of Linux and install the
    package.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管PyTorch可以完全在CPU模式下运行，但在大多数情况下，需要GPU支持的PyTorch才能实际使用，因此我们需要GPU支持。这相当简单；假设您有一张NVIDIA卡，这是由他们的Compute
    Unified Device Architecture（CUDA）API提供的。[下载适合您Linux版本的适当软件包格式](https://oreil.ly/Gx_q2)并安装软件包。
- en: 'For Red Hat Enterprise Linux (RHEL) 7:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 对于Red Hat Enterprise Linux（RHEL）7：
- en: '`sudo rpm -i cuda-repo-rhel7-10-0local-10.0.130-410.48-1.0-1.x86_64.rpm'
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`sudo rpm -i cuda-repo-rhel7-10-0local-10.0.130-410.48-1.0-1.x86_64.rpm'
- en: sudo yum clean all
  id: totrans-85
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: sudo yum clean all
- en: sudo yum install cuda`
  id: totrans-86
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: sudo yum install cuda`
- en: 'For Ubuntu 18.04:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Ubuntu 18.04：
- en: '`sudo dpkg -i cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb'
  id: totrans-88
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`sudo dpkg -i cuda-repo-ubuntu1804-10-0-local-10.0.130-410.48_1.0-1_amd64.deb'
- en: sudo apt-key add /var/cuda-repo-<version>/7fa2af80.pub
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: sudo apt-key add /var/cuda-repo-<version>/7fa2af80.pub
- en: sudo apt-get update
  id: totrans-90
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: sudo apt-get update
- en: sudo apt-get install cuda`
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: sudo apt-get install cuda`
- en: Anaconda
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Anaconda
- en: Python has a variety of packaging systems, all of which have good and not-so-good
    points. Like the developers of PyTorch, I recommend that you install Anaconda,
    a packaging system dedicated to producing the best distribution of packages for
    data scientists. Like CUDA, it’s fairly easy to install.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Python 有各种打包系统，它们都有好坏之处。与 PyTorch 的开发人员一样，我建议您安装 Anaconda，这是一个专门为数据科学家提供最佳软件包分发的打包系统。与
    CUDA 一样，它相当容易安装。
- en: Head to [Anaconda](https://oreil.ly/9hAxg) and pick out the installation file
    for your machine. Because it’s a massive archive that executes via a shell script
    on your system, I encourage you to run `md5sum` on the file you’ve downloaded
    and check it against [the list of signatures](https://oreil.ly/anuhu) before you
    execute it with `bash Anaconda3-VERSION-Linux-x86_64.sh` to make sure that the
    signature on your machine matches the one on the web page. This ensures that the
    downloaded file hasn’t been tampered with and means it’s safe to run on your system.
    The script will present several prompts about locations it’ll be installing into;
    unless there’s a good reason, just accept the defaults.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 前往 [Anaconda](https://oreil.ly/9hAxg) 并选择适合您机器的安装文件。因为这是一个庞大的存档，通过在系统上的 shell
    脚本执行，我建议您在下载的文件上运行 `md5sum` 并检查它与 [签名列表](https://oreil.ly/anuhu) 上的签名是否匹配，然后使用
    `bash Anaconda3-VERSION-Linux-x86_64.sh` 执行它，以确保您机器上的签名与网页上的签名匹配。这可以确保下载的文件没有被篡改，并且可以安全地在您的系统上运行。脚本将提供有关将要安装到的位置的几个提示；除非有充分理由，否则请接受默认值。
- en: NOTE
  id: totrans-95
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 注意
- en: You might be wondering, “Can I do this on my MacBook?” Sadly, most Macs come
    with either Intel or AMD GPUs these days and don’t really have the support for
    running PyTorch in GPU-accelerated mode. I recommend using Colab or a cloud provider
    rather than attempting to use your Mac locally.
  id: totrans-96
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 您可能会想：“我能在我的 MacBook 上做这个吗？”遗憾的是，现在大多数 Mac 配备的是 Intel 或 AMD GPU，实际上不支持在 GPU
    加速模式下运行 PyTorch。我建议使用 Colab 或云提供商，而不是尝试在本地使用 Mac。
- en: Finally, PyTorch! (and Jupyter Notebook)
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，PyTorch！（和 Jupyter Notebook）
- en: 'Now that you have Anaconda installed, getting set up with PyTorch is simple:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经安装了 Anaconda，设置 PyTorch 很简单：
- en: '`conda install pytorch torchvision -c pytorch`'
  id: totrans-99
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`conda install pytorch torchvision -c pytorch`'
- en: 'This installs PyTorch and the `torchvision` library that we use in the next
    couple of chapters to create deep learning architectures that work with images.
    Anaconda has also installed Jupyter Notebook for us, so we can begin by starting
    it:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这将安装 PyTorch 和我们在接下来的几章中使用的 `torchvision` 库，用于创建与图像一起使用的深度学习架构。Anaconda 还为我们安装了
    Jupyter Notebook，因此我们可以通过启动它来开始：
- en: '`jupyter notebook`'
  id: totrans-101
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`jupyter notebook`'
- en: 'Head to http://`YOUR-IP-ADDRESS`:8888 in your browser, create a new notebook,
    and enter the following:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在浏览器中输入 http://`YOUR-IP-ADDRESS`:8888，创建一个新的笔记本，并输入以下内容：
- en: '`import``torch``print``(``torch``.``cuda``.``is_available``())``print``(``torch``.``rand``(``2``,``2``))`'
  id: totrans-103
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`import``torch``print``(``torch``.``cuda``.``is_available``())``print``(``torch``.``rand``(``2``,``2``))`'
- en: 'This should produce output similar to this:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这应该产生类似于以下输出：
- en: '`True``0.6040``0.6647``0.9286``0.4210``[``torch``.``FloatTensor``of``size``2``x2``]`'
  id: totrans-105
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`True``0.6040``0.6647``0.9286``0.4210``[``torch``.``FloatTensor``of``size``2``x2``]`'
- en: If `cuda.is_available()` returns `False`, you need to debug your CUDA installation
    so PyTorch can see your graphics card. The values of the tensor will be different
    on your instance.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 `cuda.is_available()` 返回 `False`，则需要调试您的 CUDA 安装，以便 PyTorch 可以看到您的显卡。在您的实例上，张量的值将不同。
- en: But what is this tensor? Tensors are at the heart of almost everything in PyTorch,
    so you need to know what they are and what they can do for you.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 但是这个张量是什么？张量几乎是 PyTorch 中的一切核心，因此您需要知道它们是什么以及它们可以为您做什么。
- en: Tensors
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 张量
- en: 'A tensor is both a container for numbers as well as a set of rules that define
    transformations between tensors that produce new tensors. It’s probably easiest
    for us to think about tensors as multidimensional arrays. Every tensor has a rank
    that corresponds to its dimensional space. A simple scalar (e.g., 1) can be represented
    as a tensor of rank 0, a vector is rank 1, an n × n matrix is rank 2, and so on.
    In the previous example, we created a rank 2 tensor with random values by using
    `torch.rand()`. We can also create them from lists:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 张量既是数字的容器，也是定义张量之间转换规则的一组规则，从而产生新的张量。对我们来说，最容易将张量视为多维数组。每个张量都有一个与其维度空间对应的秩。一个简单的标量（例如，1）可以表示为秩为0的张量，一个向量是秩为1的张量，一个
    n × n 矩阵是秩为2的张量，依此类推。在前面的例子中，我们使用 `torch.rand()` 创建了一个具有随机值的秩为2的张量。我们也可以从列表中创建它们：
- en: '`x``=``torch``.``tensor``([[``0``,``0``,``1``],[``1``,``1``,``1``],[``0``,``0``,``0``]])``x``>``tensor``([[``0``,``0``,``1``],``[``1``,``1``,``1``],``[``0``,``0``,``0``]])`'
  id: totrans-110
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`x``=``torch``.``tensor``([[``0``,``0``,``1``],[``1``,``1``,``1``],[``0``,``0``,``0``]])``x``>``tensor``([[``0``,``0``,``1``],``[``1``,``1``,``1``],``[``0``,``0``,``0``]])`'
- en: 'We can change an element in a tensor by using standard Python indexing:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用标准的 Python 索引来更改张量中的元素：
- en: '`x``[``0``][``0``]``=``5``>``tensor``([[``5``,``0``,``1``],``[``1``,``1``,``1``],``[``0``,``0``,``0``]])`'
  id: totrans-112
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`x``[``0``][``0``]``=``5``>``tensor``([[``5``,``0``,``1``],``[``1``,``1``,``1``],``[``0``,``0``,``0``]])`'
- en: 'You can use special creation functions to generate particular types of tensors.
    In particular, `ones()` and `zeroes()` will generate tensors filled with 1s and
    0s, respectively:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用特殊的创建函数生成特定类型的张量。特别是，`ones()` 和 `zeroes()` 将分别生成填充有 1 和 0 的张量：
- en: '`torch``.``zeros``(``2``,``2``)``>``tensor``([[``0.``,``0.``],``[``0.``,``0.``]])`'
  id: totrans-114
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`torch``.``zeros``(``2``,``2``)``>``tensor``([[``0.``,``0.``],``[``0.``,``0.``]])`'
- en: 'You can perform standard mathematical operations with tensors (e.g., adding
    two tensors together):'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用张量执行标准的数学运算（例如，将两个张量相加）：
- en: '`tensor.ones(1,2) + tensor.ones(1,2)'
  id: totrans-116
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`tensor.ones(1,2) + tensor.ones(1,2)'
- en: tensor([[2., 2.]])`
  id: totrans-117
  prefs:
  - PREF_BQ
  - PREF_BQ
  type: TYPE_NORMAL
  zh: tensor([[2., 2.]])`
- en: 'And if you have a tensor of rank 0, you can pull out the value with `item()`:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您有一个秩为0的张量，可以使用`item()`提取值：
- en: '`torch``.``rand``(``1``)``.``item``()``>``0.34106671810150146`'
  id: totrans-119
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`torch``.``rand``(``1``)``.``item``()``>``0.34106671810150146`'
- en: 'Tensors can live in the CPU or on the GPU and can be copied between devices
    by using the `to()` function:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 张量可以存在于CPU或GPU上，并且可以通过使用`to()`函数在设备之间进行复制：
- en: '`cpu_tensor``=``tensor``.``rand``(``2``)``cpu_tensor``.``device``>``device``(``type``=``''cpu''``)``gpu_tensor``=``cpu_tensor``.``to``(``"cuda"``)``gpu_tensor``.``device``>``device``(``type``=``''cuda''``,``index``=``0``)`'
  id: totrans-121
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`cpu_tensor``=``tensor``.``rand``(``2``)``cpu_tensor``.``device``>``device``(``type``=``''cpu''``)``gpu_tensor``=``cpu_tensor``.``to``(``"cuda"``)``gpu_tensor``.``device``>``device``(``type``=``''cuda''``,``index``=``0``)`'
- en: Tensor Operations
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 张量操作
- en: If you look at the [PyTorch documentation](https://oreil.ly/1Ev0-), you’ll see
    that there are a lot of functions that you can apply to tensors — everything from
    finding the maximum element to applying a Fourier transform. In this book, you
    don’t need to know all of those in order to turn images, text, and audio into
    tensors and manipulate them to perform our operations, but you will need some.
    I definitely recommend that you give the documentation a glance, especially after
    finishing this book. Now we’re going to go through all the functions that will
    be used in upcoming chapters.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 如果查看[PyTorch文档](https://oreil.ly/1Ev0-)，您会发现有许多可以应用于张量的函数 — 从查找最大元素到应用傅立叶变换等。在本书中，您不需要了解所有这些函数才能将图像、文本和音频转换为张量并对其进行操作，但您需要了解一些。我强烈建议您在完成本书后仔细阅读文档。现在我们将逐一介绍即将在后续章节中使用的所有函数。
- en: First, we often need to find the maximum item in a tensor as well as the index
    that contains the maximum value (as this often corresponds to the class that the
    neural network has decided upon in its final prediction). These can be done with
    the `max()` and `argmax()` functions. We can also use `item()` to extract a standard
    Python value from a 1D tensor.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们经常需要找到张量中的最大项以及包含最大值的索引（因为这通常对应于神经网络在最终预测中决定的类）。这可以使用`max()`和`argmax()`函数来实现。我们还可以使用`item()`从1D张量中提取标准Python值。
- en: '`torch``.``rand``(``2``,``2``)``.``max``()``>``tensor``(``0.4726``)``torch``.``rand``(``2``,``2``)``.``max``()``.``item``()``>``0.8649941086769104`'
  id: totrans-125
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`torch``.``rand``(``2``,``2``)``.``max``()``>``tensor``(``0.4726``)``torch``.``rand``(``2``,``2``)``.``max``()``.``item``()``>``0.8649941086769104`'
- en: 'Sometimes, we’d like to change the type of a tensor; for example, from a `LongTensor`
    to a `FloatTensor`. We can do this with `to()`:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，我们想要改变张量的类型；例如，从`LongTensor`到`FloatTensor`。我们可以使用`to()`来实现：
- en: '`long_tensor``=``torch``.``tensor``([[``0``,``0``,``1``],[``1``,``1``,``1``],[``0``,``0``,``0``]])``long_tensor``.``type``()``>``''torch.LongTensor''``float_tensor``=``torch``.``tensor``([[``0``,``0``,``1``],[``1``,``1``,``1``],[``0``,``0``,``0``]])``.``to``(``dtype``=``torch``.``float32``)``float_tensor``.``type``()``>``''torch.FloatTensor''`'
  id: totrans-127
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`long_tensor``=``torch``.``tensor``([[``0``,``0``,``1``],[``1``,``1``,``1``],[``0``,``0``,``0``]])``long_tensor``.``type``()``>``''torch.LongTensor''``float_tensor``=``torch``.``tensor``([[``0``,``0``,``1``],[``1``,``1``,``1``],[``0``,``0``,``0``]])``.``to``(``dtype``=``torch``.``float32``)``float_tensor``.``type``()``>``''torch.FloatTensor''`'
- en: Most functions that operate on a tensor and return a tensor create a new tensor
    to store the result. However, if you want to save memory, look to see if an in-place
    function is defined, which should be the same name as the original function but
    with an appended underscore (`_`).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数在张量上操作并返回张量的函数会创建一个新的张量来存储结果。但是，如果要节省内存，请查看是否定义了一个原地函数，其名称应与原始函数相同，但附加了下划线(`_`)。
- en: '`random_tensor``=``torch``.``rand``(``2``,``2``)``random_tensor``.``log2``()``>``tensor``([[``-``1.9001``,``-``1.5013``],``[``-``1.8836``,``-``0.5320``]])``random_tensor``.``log2_``()``>``tensor``([[``-``1.9001``,``-``1.5013``],``[``-``1.8836``,``-``0.5320``]])`'
  id: totrans-129
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`random_tensor``=``torch``.``rand``(``2``,``2``)``random_tensor``.``log2``()``>``tensor``([[``-``1.9001``,``-``1.5013``],``[``-``1.8836``,``-``0.5320``]])``random_tensor``.``log2_``()``>``tensor``([[``-``1.9001``,``-``1.5013``],``[``-``1.8836``,``-``0.5320``]])`'
- en: 'Another common operation is reshaping a tensor. This can often occur because
    your neural network layer may require a slightly different input shape than what
    you currently have to feed into it. For example, the Modified National Institute
    of Standards and Technology (MNIST) dataset of handwritten digits is a collection
    of 28 × 28 images, but the way it’s packaged is in arrays of length 784\. To use
    the networks we are constructing, we need to turn those back into 1 × 28 × 28
    tensors (the leading 1 is the number of channels — normally red, green, and blue
    — but as MNIST digits are just grayscale, we have only one channel). We can do
    this with either `view()` or `reshape()`:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见的操作是重新塑造张量。这通常是因为您的神经网络层可能需要比您当前拥有的输入形状稍有不同。例如，手写数字的修改国家标准技术研究所（MNIST）数据集是一组28×28的图像，但其打包方式是长度为784的数组。为了使用我们正在构建的网络，我们需要将这些转换回1×28×28张量（前导1是通道数
    — 通常是红色、绿色和蓝色 — 但由于MNIST数字只是灰度，我们只有一个通道）。我们可以使用`view()`或`reshape()`来实现：
- en: '`flat_tensor``=``torch``.``rand``(``784``)``viewed_tensor``=``flat_tensor``.``view``(``1``,``28``,``28``)``viewed_tensor``.``shape``>``torch``.``Size``([``1``,``28``,``28``])``reshaped_tensor``=``flat_tensor``.``reshape``(``1``,``28``,``28``)``reshaped_tensor``.``shape``>``torch``.``Size``([``1``,``28``,``28``])`'
  id: totrans-131
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`flat_tensor``=``torch``.``rand``(``784``)``viewed_tensor``=``flat_tensor``.``view``(``1``,``28``,``28``)``viewed_tensor``.``shape``>``torch``.``Size``([``1``,``28``,``28``])``reshaped_tensor``=``flat_tensor``.``reshape``(``1``,``28``,``28``)``reshaped_tensor``.``shape``>``torch``.``Size``([``1``,``28``,``28``])`'
- en: 'Note that the reshaped tensor’s shape has to have the same number of total
    elements as the original. If you try `flat_tensor.reshape(3,28,28)`, you’ll see
    an error like this:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，重新形状的张量的形状必须具有与原始张量相同数量的总元素。如果尝试`flat_tensor.reshape(3,28,28)`，将会看到如下错误：
- en: '`RuntimeError``Traceback``(``most``recent``call``last``)``<``ipython``-``input``-``26``-``774``c70ba5c08``>``in``<``module``>``()``---->``1``flat_tensor``.``reshape``(``3``,``28``,``28``)``RuntimeError``:``shape``''[3,
    28, 28]''``is``invalid``for``input``of``size``784`'
  id: totrans-133
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`RuntimeError``Traceback``(``most``recent``call``last``)``<``ipython``-``input``-``26``-``774``c70ba5c08``>``in``<``module``>``()``---->``1``flat_tensor``.``reshape``(``3``,``28``,``28``)``RuntimeError``:``shape``''[3,
    28, 28]''``is``invalid``for``input``of``size``784`'
- en: Now you might wonder what the difference is between `view()` and `reshape()`.
    The answer is that `view()` operates as a view on the original tensor, so if the
    underlying data is changed, the view will change too (and vice versa). However,
    `view()` can throw errors if the required view is not contiguous; that is, it
    doesn’t share the same block of memory it would occupy if a new tensor of the
    required shape was created from scratch. If this happens, you have to call `tensor.contiguous()`
    before you can use `view()`. However, `reshape()` does all that behind the scenes,
    so in general, I recommend using `reshape()` rather than `view()`.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您可能想知道`view()`和`reshape()`之间的区别是什么。答案是，`view()`作为原始张量上的视图运行，因此如果更改底层数据，视图也会更改（反之亦然）。但是，如果所需的视图不是连续的，`view()`可能会抛出错误；也就是说，如果它不与从头开始创建的所需形状的新张量共享相同的内存块。如果发生这种情况，您必须在使用`view()`之前调用`tensor.contiguous()`。但是，`reshape()`在幕后处理所有这些，因此一般建议使用`reshape()`而不是`view()`。
- en: 'Finally, you might need to rearrange the dimensions of a tensor. You will likely
    come across this with images, which often are stored as `[height, width, channel]`
    tensors, but PyTorch prefers to deal with these in a `[channel, height, width]`.
    You can user `permute()` to deal with these in a fairly straightforward manner:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可能需要重新排列张量的维度。您可能会在处理图像时遇到这种情况，图像通常存储为`[高度，宽度，通道]`张量，但PyTorch更喜欢以`[通道，高度，宽度]`的方式处理这些。您可以使用`permute()`以相当简单的方式处理这些：
- en: '`hwc_tensor``=``torch``.``rand``(``640``,``480``,``3``)``chw_tensor``=``hwc_tensor``.``permute``(``2``,``0``,``1``)``chw_tensor``.``shape``>``torch``.``Size``([``3``,``640``,``480``])`'
  id: totrans-136
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '`hwc_tensor``=``torch``.``rand``(``640``,``480``,``3``)``chw_tensor``=``hwc_tensor``.``permute``(``2``,``0``,``1``)``chw_tensor``.``shape``>``torch``.``Size``([``3``,``640``,``480``])`'
- en: Here, we’ve just applied `permute` to a `[640,480,3]` tensor, with the arguments
    being the indexes of the tensor’s dimensions, so we want the final dimension (2,
    due to zero indexing) to be at the front of our tensor, followed by the remaining
    two dimensions in their original order.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们刚刚对一个`[640,480,3]`张量应用了`permute`，参数是张量维度的索引，因此我们希望最终维度（由于从零开始索引为2）在张量的前面，后面跟着原始顺序的另外两个维度。
- en: Tensor Broadcasting
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 张量广播
- en: 'Borrowed from NumPy, broadcasting allows you to perform operations between
    a tensor and a smaller tensor. You can broadcast across two tensors if, starting
    backward from their trailing dimensions:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 广播是从NumPy借鉴而来，它允许您在张量和较小张量之间执行操作。如果从它们的尾部维度开始向后看，您可以在两个张量之间进行广播：
- en: The two dimensions are equal.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 两个维度是相等的。
- en: One of the dimensions is 1\.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其中一个维度是1。
- en: 'In our use of broadcasting, it works because 1 has a dimension of 1, and as
    there are no other dimensions, the 1 can be expanded to cover the other tensor.
    If we tried to add a `[2,2]` tensor to a `[3,3]` tensor, we’d get this error message:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们使用广播时，它有效是因为1具有一个维度为1，而且没有其他维度，因此1可以扩展以覆盖另一个张量。如果我们尝试将一个`[2,2]`张量添加到一个`[3,3]`张量，我们将收到以下错误消息：
- en: '`The``size``of``tensor``a``(``2``)``must``match``the``size``of``tensor``b``(``3``)``at``non``-``singleton``dimension``1`'
  id: totrans-143
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 张量a（2）的大小必须在非单例维度1处与张量b（3）的大小匹配
- en: But we could add a `[1,3]` tensor to the `[3,3]` tensor without any trouble.
    Broadcasting is a handy little feature that increases brevity of code, and is
    often faster than manually expanding the tensor yourself.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，我们可以毫无问题地将`[1,3]`张量添加到`[3,3]`张量中。广播是一个方便的小功能，可以增加代码的简洁性，并且通常比手动扩展张量更快。
- en: That wraps up everything concerning tensors that you need to get started! We’ll
    cover a few other operations as we come across them later in the book, but this
    is enough for you to dive into [Chapter 2](index_split_033.html#filepos97807).
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是您开始所需了解的有关张量的一切！在本书后面遇到其他操作时，我们将进行更多讨论，但这已足够让您深入阅读[第2章](index_split_033.html#filepos97807)。
- en: Conclusion
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 结论
- en: Whether it’s in the cloud or on your local machine, you should now have PyTorch
    installed. I’ve introduced the fundamental building block of the library, the
    tensor, and you’ve had a brief look at Jupyter Notebook. This is all you need
    to get started! In the next chapter, you use everything you’ve seen so far to
    start building neural networks and classifying images, so make you sure you’re
    comfortable with tensors and Jupyter before moving on.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是在云端还是在本地机器上，您现在应该已经安装了PyTorch。我介绍了该库的基本构建模块——张量，您也简要了解了Jupyter Notebook。这就是您开始的全部所需！在下一章中，您将利用到目前为止所见的一切来开始构建神经网络和对图像进行分类，因此在继续之前，请确保您对张量和Jupyter感到舒适。
- en: Further Reading
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: '[Project Jupyter documentation](https://jupyter.org/documentation)'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Project Jupyter文档](https://jupyter.org/documentation)'
- en: '[PyTorch documentation](https://pytorch.org/docs/stable)'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch文档](https://pytorch.org/docs/stable)'
- en: '[AWS Deep Learning AMIs](https://oreil.ly/G9Ldx)'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[AWS深度学习AMI](https://oreil.ly/G9Ldx)'
- en: '[Azure Data Science Virtual Machines](https://oreil.ly/YjzVB)'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Azure数据科学虚拟机](https://oreil.ly/YjzVB)'
- en: '[Google Deep Learning VM Image](https://oreil.ly/NFpeG)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Google深度学习VM镜像](https://oreil.ly/NFpeG)'
