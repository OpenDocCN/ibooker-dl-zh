- en: Chapter 2\. From Model to Production
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章。从模型到生产
- en: The six lines of code we saw in [Chapter 1](ch01.xhtml#chapter_intro) are just
    one small part of the process of using deep learning in practice. In this chapter,
    we’re going to use a computer vision example to look at the end-to-end process
    of creating a deep learning application. More specifically, we’re going to build
    a bear classifier! In the process, we’ll discuss the capabilities and constraints
    of deep learning, explore how to create datasets, look at possible gotchas when
    using deep learning in practice, and more. Many of the key points will apply equally
    well to other deep learning problems, such as those in [Chapter 1](ch01.xhtml#chapter_intro).
    If you work through a problem similar in key respects to our example problems,
    we expect you to get excellent results with little code, quickly.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第1章](ch01.xhtml#chapter_intro)中看到的六行代码只是在实践中使用深度学习过程的一小部分。在本章中，我们将使用一个计算机视觉示例来查看创建深度学习应用的端到端过程。更具体地说，我们将构建一个熊分类器！在这个过程中，我们将讨论深度学习的能力和限制，探讨如何创建数据集，在实践中使用深度学习时可能遇到的问题等等。许多关键点同样适用于其他深度学习问题，例如[第1章](ch01.xhtml#chapter_intro)中的问题。如果您解决的问题在关键方面类似于我们的示例问题，我们期望您可以快速获得极好的结果，而只需很少的代码。
- en: Let’s start with how you should frame your problem.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从如何构建您的问题开始。
- en: The Practice of Deep Learning
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习的实践
- en: We’ve seen that deep learning can solve a lot of challenging problems quickly
    and with little code. As a beginner, there’s a sweet spot of problems that are
    similar enough to our example problems that you can very quickly get extremely
    useful results. However, deep learning isn’t magic! The same six lines of code
    won’t work for every problem anyone can think of today.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到深度学习可以快速解决许多具有挑战性的问题，并且只需很少的代码。作为初学者，有一些问题与我们的示例问题足够相似，以便您可以非常快速地获得极其有用的结果。然而，深度学习并不是魔法！同样的六行代码不会适用于今天任何人可以想到的每个问题。
- en: Underestimating the constraints and overestimating the capabilities of deep
    learning may lead to frustratingly poor results, at least until you gain some
    experience and can solve the problems that arise. Conversely, overestimating the
    constraints and underestimating the capabilities of deep learning may mean you
    do not attempt a solvable problem because you talk yourself out of it.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 低估深度学习的限制并高估其能力可能导致令人沮丧的糟糕结果，至少在您获得一些经验并能解决出现的问题之前。相反，高估深度学习的限制并低估其能力可能意味着您不会尝试可解决的问题，因为您自己否定了它。
- en: 'We often talk to people who underestimate both the constraints and the capabilities
    of deep learning. Both of these can be problems: underestimating the capabilities
    means that you might not even try things that could be very beneficial, and underestimating
    the constraints might mean that you fail to consider and react to important issues.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常与低估深度学习的限制和能力的人交谈。这两者都可能是问题：低估能力意味着您可能甚至不会尝试可能非常有益的事情，而低估限制可能意味着您未能考虑和应对重要问题。
- en: The best thing to do is to keep an open mind. If you remain open to the possibility
    that deep learning might solve part of your problem with less data or complexity
    than you expect, you can design a process through which you can find the specific
    capabilities and constraints related to your particular problem. This doesn’t
    mean making any risky bets—we will show you how you can gradually roll out models
    so that they don’t create significant risks, and can even backtest them prior
    to putting them in production.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 最好的做法是保持开放的心态。如果您对深度学习可能以比您预期的更少的数据或复杂性解决部分问题持开放态度，您可以设计一个过程，通过该过程您可以找到与您特定问题相关的特定能力和限制。这并不意味着进行任何冒险的赌注-我们将向您展示如何逐渐推出模型，以便它们不会带来重大风险，并且甚至可以在投入生产之前对其进行回测。
- en: Starting Your Project
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始您的项目
- en: So where should you start your deep learning journey? The most important thing
    is to ensure that you have a project to work on—it is only through working on
    your own projects that you will get real experience building and using models.
    When selecting a project, the most important consideration is data availability.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 那么您应该从哪里开始深度学习之旅呢？最重要的是确保您有一个要处理的项目-只有通过处理自己的项目，您才能获得构建和使用模型的真实经验。在选择项目时，最重要的考虑因素是数据的可用性。
- en: Regardless of whether you are doing a project just for your own learning or
    for practical application in your organization, you want to be able to start quickly.
    We have seen many students, researchers, and industry practitioners waste months
    or years while they attempt to find their perfect dataset. The goal is not to
    find the “perfect” dataset or project, but just to get started and iterate from
    there. If you take this approach, you will be on your third iteration of learning
    and improving while the perfectionists are still in the planning stages!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您是为了自己的学习还是为了在组织中的实际应用而进行项目，您都希望能够快速开始。我们看到许多学生、研究人员和行业从业者在试图找到他们完美的数据集时浪费了几个月甚至几年的时间。目标不是找到“完美”的数据集或项目，而只是开始并从那里迭代。如果您采取这种方法，您将在完美主义者仍处于规划阶段时进行第三次迭代学习和改进！
- en: We also suggest that you iterate from end to end in your project; don’t spend
    months fine-tuning your model, or polishing the perfect GUI, or labeling the perfect
    dataset.…Instead, complete every step as well as you can in a reasonable amount
    of time, all the way to the end. For instance, if your final goal is an application
    that runs on a mobile phone, that should be what you have after each iteration.
    But perhaps in the early iterations you take shortcuts; for instance, by doing
    all of the processing on a remote server and using a simple responsive web application.
    By completing the project end to end, you will see where the trickiest bits are,
    and which bits make the biggest difference to the final result.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还建议您在项目中端到端迭代；不要花几个月来微调您的模型，或打磨完美的GUI，或标记完美的数据集……相反，尽可能在合理的时间内完成每一步，一直到最后。例如，如果您的最终目标是一个在手机上运行的应用程序，那么每次迭代后您都应该拥有这个。但也许在早期迭代中您会采取捷径；例如，在远程服务器上进行所有处理，并使用简单的响应式Web应用程序。通过完成项目的端到端，您将看到最棘手的部分在哪里，以及哪些部分对最终结果产生最大影响。
- en: As you work through this book, we suggest that you complete lots of small experiments,
    by running and adjusting the notebooks we provide, at the same time that you gradually
    develop your own projects. That way, you will be getting experience with all of
    the tools and techniques that we’re explaining as we discuss them.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当您阅读本书时，我们建议您完成许多小实验，通过运行和调整我们提供的笔记本，同时逐渐开发自己的项目。这样，您将获得所有我们解释的工具和技术的经验，同时我们讨论它们。
- en: Sylvain Says
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Sylvain说
- en: To make the most of this book, take the time to experiment between each chapter,
    whether on your own project or by exploring the notebooks we provide. Then try
    rewriting those notebooks from scratch on a new dataset. It’s only by practicing
    (and failing) a lot that you will develop intuition of how to train a model.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充分利用这本书，花时间在每一章之间进行实验，无论是在您自己的项目上还是通过探索我们提供的笔记本。然后尝试在新数据集上从头开始重写这些笔记本。只有通过大量练习（和失败），您才能培养出如何训练模型的直觉。
- en: By using the end-to-end iteration approach, you will also get a better understanding
    of how much data you really need. For instance, you may find you can easily get
    only 200 labeled data items, and you can’t really know until you try whether that’s
    enough to get the performance you need for your application to work well in practice.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用端到端迭代方法，您还将更好地了解您实际需要多少数据。例如，您可能会发现您只能轻松获得200个标记数据项，而在尝试之前，您无法真正知道这是否足以使您的应用在实践中良好运行。
- en: In an organizational context, you will be able to show your colleagues that
    your idea can work by showing them a real working prototype. We have repeatedly
    observed that this is the secret to getting good organizational buy-in for a project.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在组织环境中，您可以通过展示一个真实的工作原型来向同事展示您的想法是可行的。我们反复观察到，这是获得项目良好组织支持的秘诀。
- en: Since it is easiest to get started on a project for which you already have data
    available, that means it’s probably easiest to get started on a project related
    to something you are already doing, because you already have data about things
    that you are doing. For instance, if you work in the music business, you may have
    access to many recordings. If you work as a radiologist, you probably have access
    to lots of medical images. If you are interested in wildlife preservation, you
    may have access to lots of images of wildlife.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 由于最容易开始的项目是您已经有数据可用的项目，这意味着最容易开始的项目可能与您已经在做的事情相关，因为您已经有关于您正在做的事情的数据。例如，如果您在音乐行业工作，您可能可以访问许多录音。如果您是放射科医生，您可能可以访问大量医学图像。如果您对野生动物保护感兴趣，您可能可以访问大量野生动物图像。
- en: Sometimes you have to get a bit creative. Maybe you can find a previous machine
    learning project, such as a Kaggle competition, that is related to your field
    of interest. Sometimes you have to compromise. Maybe you can’t find the exact
    data you need for the precise project you have in mind; but you might be able
    to find something from a similar domain, or measured in a different way, tackling
    a slightly different problem. Working on these kinds of similar projects will
    still give you a good understanding of the overall process, and may help you identify
    other shortcuts, data sources, and so forth.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 有时您必须有点创造性。也许您可以找到一个先前的机器学习项目，比如一个与您感兴趣的领域相关的Kaggle竞赛。有时您必须做出妥协。也许您找不到您所需的确切数据来完成您心中的项目；但您可能会找到一些来自类似领域的数据，或者以不同方式测量的数据，解决一个略有不同的问题。在这些类似项目上工作仍然会让您对整个过程有很好的理解，并可能帮助您识别其他捷径、数据来源等。
- en: Especially when you are just starting out with deep learning, it’s not a good
    idea to branch out into very different areas, to places that deep learning has
    not been applied to before. That’s because if your model does not work at first,
    you will not know whether it is because you have made a mistake, or if the very
    problem you are trying to solve is simply not solvable with deep learning. And
    you won’t know where to look to get help. Therefore, it is best at first to start
    by finding an example online of something that somebody has had good results with
    and that is at least somewhat similar to what you are trying to achieve, by converting
    your data into a format similar to what someone else has used before (such as
    creating an image from your data). Let’s have a look at the state of deep learning,
    just so you know what kinds of things deep learning is good at right now.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是当您刚开始学习深度学习时，最好不要涉足非常不同的领域，不要涉足深度学习之前未应用的领域。因为如果您的模型一开始就不起作用，您将不知道是因为您犯了错误，还是您试图解决的问题根本无法用深度学习解决。您也不知道从哪里寻求帮助。因此，最好首先找到在线的一个例子，该例子已经取得了良好的结果，并且至少与您尝试实现的目标有些相似，通过将您的数据转换为其他人以前使用过的格式（例如从您的数据创建图像）。让我们看看深度学习的现状，这样您就知道深度学习目前擅长的领域。
- en: The State of Deep Learning
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习的现状
- en: Let’s start by considering whether deep learning can be any good at the problem
    you are looking to work on. This section provides a summary of the state of deep
    learning at the start of 2020\. However, things move very fast, and by the time
    you read this, some of these constraints may no longer exist. We will try to keep
    the book’s website up-to-date; in addition, a Google search for “what can AI do
    now” is likely to provide current information.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先考虑深度学习是否能够解决您要解决的问题。本节概述了2020年初深度学习的现状。然而，事情发展得非常快，当您阅读本文时，其中一些限制可能已经不存在。我们将尽力保持本书网站的最新信息；此外，搜索“AI现在能做什么”可能会提供当前信息。
- en: Computer vision
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算机视觉
- en: There are many domains in which deep learning has not been used to analyze images
    yet, but those where it has been tried have nearly universally shown that computers
    can recognize items in an image at least as well as people can—even specially
    trained people, such as radiologists. This is known as *object recognition*. Deep
    learning is also good at recognizing where objects in an image are, and can highlight
    their locations and name each found object. This is known as *object detection*
    (in a variant of this that we saw in [Chapter 1](ch01.xhtml#chapter_intro), every
    pixel is categorized based on the kind of object it is part of—this is called
    *segmentation*).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习尚未用于分析图像的许多领域，但在已经尝试过的领域中，几乎普遍表明计算机可以至少与人类一样好地识别图像中的物品，甚至是经过专门训练的人，如放射科医生。这被称为*物体识别*。深度学习还擅长识别图像中物体的位置，并可以突出它们的位置并命名每个找到的物体。这被称为*物体检测*（在我们在[第1章](ch01.xhtml#chapter_intro)中看到的变体中，每个像素根据其所属的对象类型进行分类—这被称为*分割*）。
- en: Deep learning algorithms are generally not good at recognizing images that are
    significantly different in structure or style from those used to train the model.
    For instance, if there were no black-and-white images in the training data, the
    model may do poorly on black-and-white images. Similarly, if the training data
    did not contain hand-drawn images, the model will probably do poorly on hand-drawn
    images. There is no general way to check which types of images are missing in
    your training set, but we will show in this chapter some ways to try to recognize
    when unexpected image types arise in the data when the model is being used in
    production (this is known as checking for *out-of-domain* data).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习算法通常不擅长识别结构或风格与用于训练模型的图像明显不同的图像。例如，如果训练数据中没有黑白图像，模型可能在黑白图像上表现不佳。同样，如果训练数据不包含手绘图像，模型可能在手绘图像上表现不佳。没有一般方法可以检查训练集中缺少哪些类型的图像，但我们将在本章中展示一些方法，以尝试识别当模型在生产中使用时数据中出现意外图像类型的情况（这被称为检查*域外*数据）。
- en: One major challenge for object detection systems is that image labeling can
    be slow and expensive. There is a lot of work at the moment going into tools to
    try to make this labeling faster and easier, and to require fewer handcrafted
    labels to train accurate object detection models. One approach that is particularly
    helpful is to synthetically generate variations of input images, such as by rotating
    them or changing their brightness and contrast; this is called *data augmentation*
    and also works well for text and other types of models. We will be discussing
    it in detail in this chapter.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 物体检测系统面临的一个主要挑战是图像标记可能会很慢且昂贵。目前有很多工作正在进行中，旨在开发工具以尝试使这种标记更快速、更容易，并且需要更少的手工标签来训练准确的物体检测模型。一个特别有帮助的方法是合成生成输入图像的变化，例如通过旋转它们或改变它们的亮度和对比度；这被称为*数据增强*，并且对文本和其他类型的模型也很有效。我们将在本章中详细讨论这一点。
- en: Another point to consider is that although your problem might not look like
    a computer vision problem, it might be possible with a little imagination to turn
    it into one. For instance, if what you are trying to classify are sounds, you
    might try converting the sounds into images of their acoustic waveforms and then
    training a model on those images.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个要考虑的问题是，尽管您的问题可能看起来不像是一个计算机视觉问题，但通过一点想象力可能可以将其转变为一个。例如，如果您要分类的是声音，您可以尝试将声音转换为其声学波形的图像，然后在这些图像上训练模型。
- en: Text (natural language processing)
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自然语言处理
- en: Computers are good at classifying both short and long documents based on categories
    such as spam or not spam, sentiment (e.g., is the review positive or negative),
    author, source website, and so forth. We are not aware of any rigorous work done
    in this area to compare computers to humans, but anecdotally it seems to us that
    deep learning performance is similar to human performance on these tasks.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机擅长基于类别对短文档和长文档进行分类，例如垃圾邮件或非垃圾邮件、情感（例如，评论是积极的还是消极的）、作者、来源网站等。我们不知道在这个领域是否有任何严格的工作来比较计算机和人类，但从经验上看，我们认为深度学习的性能在这些任务上与人类的性能相似。
- en: Deep learning is also good at generating context-appropriate text, such as replies
    to social media posts, and imitating a particular author’s style. It’s good at
    making this content compelling to humans too—in fact, even more compelling than
    human-generated text. However, deep learning is not good at generating *correct*
    responses! We don’t have a reliable way to, for instance, combine a knowledge
    base of medical information with a deep learning model for generating medically
    correct natural language responses. This is dangerous, because it is so easy to
    create content that appears to a layman to be compelling, but actually is entirely
    incorrect.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习还擅长生成与上下文相关的文本，例如回复社交媒体帖子，并模仿特定作者的风格。它还擅长使这些内容对人类具有吸引力—事实上，甚至比人类生成的文本更具吸引力。然而，深度学习不擅长生成*正确*的回应！例如，我们没有可靠的方法来将医学信息知识库与深度学习模型结合起来，以生成医学上正确的自然语言回应。这是危险的，因为很容易创建对外行人看来具有吸引力但实际上完全不正确的内容。
- en: Another concern is that context-appropriate, highly compelling responses on
    social media could be used at massive scale—thousands of times greater than any
    troll farm previously seen—to spread disinformation, create unrest, and encourage
    conflict. As a rule of thumb, text generation models will always be technologically
    a bit ahead of models for recognizing automatically generated text. For instance,
    it is possible to use a model that can recognize artificially generated content
    to actually improve the generator that creates that content, until the classification
    model is no longer able to complete its task.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是，社交媒体上的上下文适当、高度引人入胜的回应可能被大规模使用——比以前见过的任何喷子农场规模大几千倍——来传播虚假信息，制造动荡，鼓励冲突。一般来说，文本生成模型总是在技术上略领先于识别自动生成文本的模型。例如，可以使用一个能够识别人工生成内容的模型来实际改进创建该内容的生成器，直到分类模型无法完成其任务为止。
- en: 'Despite these issues, deep learning has many applications in NLP: it can be
    used to translate text from one language to another, summarize long documents
    into something that can be digested more quickly, find all mentions of a concept
    of interest, and more. Unfortunately, the translation or summary could well include
    completely incorrect information! However, the performance is already good enough
    that many people are using these systems—for instance, Google’s online translation
    system (and every other online service we are aware of) is based on deep learning.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些问题，深度学习在自然语言处理中有许多应用：可以用来将文本从一种语言翻译成另一种语言，将长篇文档总结为更快消化的内容，找到感兴趣概念的所有提及等。不幸的是，翻译或总结可能包含完全错误的信息！然而，性能已经足够好，许多人正在使用这些系统——例如，谷歌的在线翻译系统（以及我们所知道的每个其他在线服务）都是基于深度学习的。
- en: Combining text and images
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结合文本和图像
- en: 'The ability of deep learning to combine text and images into a single model
    is, generally, far better than most people intuitively expect. For example, a
    deep learning model can be trained on input images with output captions written
    in English, and can learn to generate surprisingly appropriate captions automatically
    for new images! But again, we have the same warning that we discussed in the previous
    section: there is no guarantee that these captions will be correct.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习将文本和图像结合成一个单一模型的能力通常比大多数人直觉期望的要好得多。例如，一个深度学习模型可以在输入图像上进行训练，输出用英语编写的标题，并且可以学会为新图像自动生成令人惊讶地适当的标题！但是，我们再次提出与前一节讨论的相同警告：不能保证这些标题是正确的。
- en: Because of this serious issue, we generally recommend that deep learning be
    used not as an entirely automated process, but as part of a process in which the
    model and a human user interact closely. This can potentially make humans orders
    of magnitude more productive than they would be with entirely manual methods,
    and result in more accurate processes than using a human alone.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个严重问题，我们通常建议深度学习不要作为完全自动化的过程，而是作为模型和人类用户密切互动的过程的一部分。这可能使人类的生产力比完全手动方法高出几个数量级，并且比仅使用人类更准确。
- en: For instance, an automatic system can be used to identify potential stroke victims
    directly from CT scans, and send a high-priority alert to have those scans looked
    at quickly. There is only a three-hour window to treat strokes, so this fast feedback
    loop could save lives. At the same time, however, all scans could continue to
    be sent to radiologists in the usual way, so there would be no reduction in human
    input. Other deep learning models could automatically measure items seen on the
    scans and insert those measurements into reports, warning the radiologists about
    findings that they may have missed and telling them about other cases that might
    be relevant.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，自动系统可以直接从CT扫描中识别潜在的中风患者，并发送高优先级警报，以便快速查看这些扫描。治疗中风只有三个小时的时间窗口，因此这种快速的反馈循环可以挽救生命。同时，所有扫描仍然可以按照通常的方式发送给放射科医生，因此不会减少人类的参与。其他深度学习模型可以自动测量扫描中看到的物品，并将这些测量结果插入报告中，警告放射科医生可能错过的发现，并告诉他们可能相关的其他病例。
- en: Tabular data
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 表格数据
- en: For analyzing time series and tabular data, deep learning has recently been
    making great strides. However, deep learning is generally used as part of an ensemble
    of multiple types of model. If you already have a system that is using random
    forests or gradient boosting machines (popular tabular modeling tools that you
    will learn about soon), then switching to or adding deep learning may not result
    in any dramatic improvement.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分析时间序列和表格数据，深度学习最近取得了巨大进展。然而，深度学习通常作为多种模型集成的一部分使用。如果您已经有一个正在使用随机森林或梯度提升机（流行的表格建模工具，您很快将了解）的系统，那么切换到或添加深度学习可能不会带来任何显著的改进。
- en: Deep learning does greatly increase the variety of columns that you can include—for
    example, columns containing natural language (book titles, reviews, etc.) and
    high-cardinality categorical columns (i.e., something that contains a large number
    of discrete choices, such as zip code or product ID). On the down side, deep learning
    models generally take longer to train than random forests or gradient boosting
    machines, although this is changing thanks to libraries such as [RAPIDS](https://rapids.ai),
    which provides GPU acceleration for the whole modeling pipeline. We cover the
    pros and cons of all these methods in detail in [Chapter 9](ch09.xhtml#chapter_tabular).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习确实大大增加了您可以包含的列的种类——例如，包含自然语言（书名、评论等）和高基数分类列（即包含大量离散选择的内容，如邮政编码或产品ID）。不过，与随机森林或梯度提升机相比，深度学习模型通常需要更长的训练时间，尽管由于提供GPU加速的库（如[RAPIDS](https://rapids.ai)），情况正在改变。我们在[第9章](ch09.xhtml#chapter_tabular)中详细介绍了所有这些方法的优缺点。
- en: Recommendation systems
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 推荐系统
- en: Recommendation systems are really just a special type of tabular data. In particular,
    they generally have a high-cardinality categorical variable representing users,
    and another one representing products (or something similar). A company like Amazon
    represents every purchase that has ever been made by its customers as a giant
    sparse matrix, with customers as the rows and products as the columns. Once they
    have the data in this format, data scientists apply some form of collaborative
    filtering to *fill in the matrix*. For example, if customer A buys products 1
    and 10, and customer B buys products 1, 2, 4, and 10, the engine will recommend
    that A buy 2 and 4.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
- en: Because deep learning models are good at handling high-cardinality categorical
    variables, they are quite good at handling recommendation systems. They particularly
    come into their own, just like for tabular data, when combining these variables
    with other kinds of data, such as natural language or images. They can also do
    a good job of combining all of these types of information with additional metadata
    represented as tables, such as user information, previous transactions, and so
    forth.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: However, nearly all machine learning approaches have the downside that they
    tell you only which products a particular user might like, rather than what recommendations
    would be helpful for a user. Many kinds of recommendations for products a user
    might like may not be at all helpful—for instance, if the user is already familiar
    with the products, or if they are simply different packagings of products they
    have already purchased (such as a boxed set of novels, when they already have
    each of the items in that set). Jeremy likes reading books by Terry Pratchett,
    and for a while Amazon was recommending nothing but Terry Pratchett books to him
    (see [Figure 2-1](#pratchett)), which really wasn’t helpful because he was already
    aware of these books!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '![Terry Pratchett books recommendation](Images/dlcf_0201.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
- en: Figure 2-1\. A not-so-useful recommendation
  id: totrans-44
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Other data types
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Often you will find that domain-specific data types fit very nicely into existing
    categories. For instance, protein chains look a lot like natural language documents,
    in that they are long sequences of discrete tokens with complex relationships
    and meaning throughout the sequence. And indeed, it does turn out that using NLP
    deep learning methods is the current state-of-the-art approach for many types
    of protein analysis. As another example, sounds can be represented as spectrograms,
    which can be treated as images; standard deep learning approaches for images turn
    out to work really well on spectrograms.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: The Drivetrain Approach
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many accurate models are of no use to anyone, and many inaccurate models are
    highly useful. To ensure that your modeling work is useful in practice, you need
    to consider how your work will be used. In 2012, Jeremy, along with Margit Zwemer
    and Mike Loukides, introduced a method called *the Drivetrain Approach* for thinking
    about this issue.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: The Drivetrain Approach, illustrated in [Figure 2-2](#drivetrain), was described
    in detail in [“Designing Great Data Products”](https://oreil.ly/KJIIa). The basic
    idea is to start with considering your objective, then think about what actions
    you can take to meet that objective and what data you have (or can acquire) that
    can help, and then build a model that you can use to determine the best actions
    to take to get the best results in terms of your objective.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlcf_0202.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: Figure 2-2\. The Drivetrain Approach
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Consider a model in an autonomous vehicle: you want to help a car drive safely
    from point A to point B without human intervention. Great predictive modeling
    is an important part of the solution, but it doesn’t stand on its own; as products
    become more sophisticated, it disappears into the plumbing. Someone using a self-driving
    car is completely unaware of the hundreds (if not thousands) of models and the
    petabytes of data that make it work. But as data scientists build increasingly
    sophisticated products, they need a systematic design approach.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑自动驾驶汽车中的模型：您希望帮助汽车安全地从A点驾驶到B点，而无需人为干预。出色的预测建模是解决方案的重要组成部分，但它并不是独立存在的；随着产品变得更加复杂，它会消失在管道中。使用自动驾驶汽车的人完全不知道使其运行的数百（甚至数千）个模型和海量数据。但随着数据科学家构建越来越复杂的产品，他们需要一种系统化的设计方法。
- en: We use data not just to generate more data (in the form of predictions), but
    to produce *actionable outcomes*. That is the goal of the Drivetrain Approach.
    Start by defining a clear *objective*. For instance, Google, when creating its
    first search engine, considered “What is the user’s main objective in typing in
    a search query?” This led to Google’s objective, which was to “show the most relevant
    search result.” The next step is to consider what *levers* you can pull (i.e., what
    actions you can take) to better achieve that objective. In Google’s case, that
    was the ranking of the search results. The third step was to consider what new
    *data* they would need to produce such a ranking; they realized that the implicit
    information regarding which pages linked to which other pages could be used for
    this purpose.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用数据不仅仅是为了生成更多数据（以预测的形式），而是为了产生可操作的结果。这是Drivetrain方法的目标。首先要明确定义一个明确的目标。例如，当谷歌创建其第一个搜索引擎时，考虑了“用户在输入搜索查询时的主要目标是什么？”这导致了谷歌的目标，即“显示最相关的搜索结果”。下一步是考虑您可以拉动的杠杆（即您可以采取的行动）以更好地实现该目标。在谷歌的情况下，这是搜索结果的排名。第三步是考虑他们需要什么新数据来生成这样的排名；他们意识到关于哪些页面链接到哪些其他页面的隐含信息可以用于此目的。
- en: Only after these first three steps do we begin thinking about building the predictive
    *models*. Our objective and available levers, what data we already have and what
    additional data we will need to collect, determine the models we can build. The
    models will take both the levers and any uncontrollable variables as their inputs;
    the outputs from the models can be combined to predict the final state for our
    objective.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在完成了这前三个步骤之后，我们才开始考虑构建预测模型。我们的目标和可用的杠杆，我们已经拥有的数据以及我们需要收集的额外数据，决定了我们可以构建的模型。这些模型将以杠杆和任何不可控变量作为输入；模型的输出可以结合起来预测我们的目标的最终状态。
- en: 'Let’s consider another example: recommendation systems. The *objective* of
    a recommendation engine is to drive additional sales by surprising and delighting
    the customer with recommendations of items they would not have purchased without
    the recommendation. The *lever* is the ranking of the recommendations. New *data*
    must be collected to generate recommendations that will *cause new sales*. This
    will require conducting many randomized experiments in order to collect data about
    a wide range of recommendations for a wide range of customers. This is a step
    that few organizations take; but without it, you don’t have the information you
    need to optimize recommendations based on your true objective (more sales!).'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑另一个例子：推荐系统。推荐引擎的目标是通过推荐客户不会在没有推荐的情况下购买的物品来推动额外的销售。杠杆是推荐的排名。必须收集新数据以生成将导致新销售的推荐。这将需要进行许多随机实验，以收集关于各种客户的各种推荐的数据。这是很少有组织采取的一步；但是没有它，您就没有所需的信息来根据您的真正目标（更多销售！）优化推荐。
- en: Finally, you could build two *models* for purchase probabilities, conditional
    on seeing or not seeing a recommendation. The difference between these two probabilities
    is a utility function for a given recommendation to a customer. It will be low
    in cases where the algorithm recommends a familiar book that the customer has
    already rejected (both components are small) or a book that they would have bought
    even without the recommendation (both components are large and cancel each other
    out).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以为购买概率构建两个模型，条件是看到或没有看到推荐。这两个概率之间的差异是给定推荐给客户的效用函数。在算法推荐客户已经拒绝的熟悉书籍（两个组成部分都很小）或者他们本来就会购买的书籍（两个组成部分都很大并互相抵消）的情况下，效用函数会很低。
- en: As you can see, in practice often the practical implementation of your models
    will require a lot more than just training a model! You’ll often need to run experiments
    to collect more data, and consider how to incorporate your models into the overall
    system you’re developing. Speaking of data, let’s now focus on how to find data
    for your project.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，在实践中，您的模型的实际实施通常需要比仅仅训练一个模型更多！您通常需要运行实验来收集更多数据，并考虑如何将您的模型整合到您正在开发的整个系统中。说到数据，现在让我们专注于如何为您的项目找到数据。
- en: Gathering Data
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 收集数据
- en: 'For many types of projects, you may be able to find all the data you need online.
    The project we’ll be completing in this chapter is a *bear detector*. It will
    discriminate between three types of bear: grizzly, black, and teddy bears. There
    are many images on the internet of each type of bear that we can use. We just
    need a way to find them and download them.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多类型的项目，您可能能够在线找到所需的所有数据。本章中我们将完成的项目是一个“熊探测器”。它将区分三种类型的熊：灰熊、黑熊和泰迪熊。互联网上有许多每种类型熊的图片可供我们使用。我们只需要找到它们并下载它们。
- en: We’ve provided a tool you can use for this purpose, so you can follow along
    with this chapter and create your own image recognition application for whatever
    kinds of objects you’re interested in. In the fast.ai course, thousands of students
    have presented their work in the course forums, displaying everything from hummingbird
    varieties in Trinidad to bus types in Panama—one student even created an application
    that would help his fiancée recognize his 16 cousins during Christmas vacation!
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing, Bing Image Search is the best option we know of for
    finding and downloading images. It’s free for up to 1,000 queries per month, and
    each query can download up to 150 images. However, something better might have
    come along between when we wrote this and when you’re reading the book, so be
    sure to check out this [book’s website](https://book.fast.ai) for our current
    recommendation.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Keeping in Touch with the Latest Services
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Services that can be used for creating datasets come and go all the time, and
    their features, interfaces, and pricing change regularly too. In this section,
    we’ll show how to use the [Bing Image Search API](https://oreil.ly/P8VtT) available
    as part of Azure Cognitive Services at the time this book was written.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: 'To download images with Bing Image Search, sign up at Microsoft for a free
    account. You will be given a key, which you can copy and enter in a cell as follows
    (replacing *`XXX`* with your key and executing it):'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Or, if you’re comfortable at the command line, you can set it in your terminal
    with
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'and then restart the Jupyter server, type this in a cell, and execute it:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Once you’ve set `key`, you can use `search_images_bing`. This function is provided
    by the small `utils` class included with the notebooks online (if you’re not sure
    where a function is defined, you can just type it in your notebook to find out,
    as shown here):'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let’s try this function out:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We’ve successfully downloaded the URLs of 150 grizzly bears (or, at least,
    images that Bing Image Search finds for that search term). Let’s look at one:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](Images/dlcf_02in01.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
- en: 'This seems to have worked nicely, so let’s use fastai’s `download_images` to
    download all the URLs for each of our search terms. We’ll put each in a separate
    folder:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Our folder has image files, as we’d expect:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Jeremy Says
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I just love this about working in Jupyter notebooks! It’s so easy to gradually
    build what I want, and check my work every step of the way. I make a *lot* of
    mistakes, so this is really helpful to me.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: 'Often when we download files from the internet, a few are corrupt. Let’s check:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'To remove all the failed images, you can use `unlink`. Like most fastai functions
    that return a collection, `verify_images` returns an object of type `L`, which
    includes the `map` method. This calls the passed function on each element of the
    collection:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'One thing to be aware of in this process: as we discussed in [Chapter 1](ch01.xhtml#chapter_intro),
    models can reflect only the data used to train them. And the world is full of
    biased data, which ends up reflected in, for example, Bing Image Search (which
    we used to create our dataset). For instance, let’s say you were interested in
    creating an app that could help users figure out whether they had healthy skin,
    so you trained a model on the results of searches for (say) “healthy skin.” [Figure 2-3](#healthy_skin)
    shows you kind of the results you would get.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/dlcf_0203.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
- en: Figure 2-3\. Data for a healthy skin detector?
  id: totrans-95
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'With this as your training data, you would end up not with a healthy skin detector,
    but a *young white woman touching her face* detector! Be sure to think carefully
    about the types of data that you might expect to see in practice in your application,
    and check carefully to ensure that all these types are reflected in your model’s
    source data. (Thanks to Deb Raji, who came up with the healthy skin example. See
    her paper [“Actionable Auditing: Investigating the Impact of Publicly Naming Biased
    Performance Results of Commercial AI Products”](https://oreil.ly/POS_C) for more
    fascinating insights into model bias.)'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此作为训练数据，您最终不会得到一个健康皮肤检测器，而是一个*年轻白人女性触摸她的脸*检测器！一定要仔细考虑您可能在应用程序中实际看到的数据类型，并仔细检查以确保所有这些类型都反映在您模型的源数据中。（感谢Deb
    Raji提出了健康皮肤的例子。请查看她的论文[“可操作的审计：调查公开命名商业AI产品偏见性能结果的影响”](https://oreil.ly/POS_C)以获取更多有关模型偏见的迷人见解。）
- en: Now that we have downloaded some data, we need to assemble it in a format suitable
    for model training. In fastai, that means creating an object called `DataLoaders`.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经下载了一些数据，我们需要将其组装成适合模型训练的格式。在fastai中，这意味着创建一个名为`DataLoaders`的对象。
- en: From Data to DataLoaders
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从数据到数据加载器
- en: '`DataLoaders` is a thin class that just stores whatever `DataLoader` objects
    you pass to it and makes them available as `train` and `valid`. Although it’s
    a simple class, it’s important in fastai: it provides the data for your model.
    The key functionality in `DataLoaders` is provided with just these four lines
    of code (it has some other minor functionality we’ll skip over for now):'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`DataLoaders`是一个简单的类，只是存储您传递给它的`DataLoader`对象，并将它们作为`train`和`valid`可用。尽管它是一个简单的类，但在fastai中非常重要：它为您的模型提供数据。`DataLoaders`中的关键功能仅用这四行代码提供（它还有一些其他次要功能我们暂时跳过）：'
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Jargon: DataLoaders'
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 术语：DataLoaders
- en: A fastai class that stores multiple `DataLoader` objects you pass to it—normally
    a `train` and a `valid`, although it’s possible to have as many as you like. The
    first two are made available as properties.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 一个fastai类，存储您传递给它的多个`DataLoader`对象——通常是一个`train`和一个`valid`，尽管可以有任意数量。前两个作为属性提供。
- en: 'Later in the book, you’ll also learn about the `Dataset` and `Datasets` classes,
    which have the same relationship. To turn our downloaded data into a `DataLoaders`
    object, we need to tell fastai at least four things:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的后面，您还将了解`Dataset`和`Datasets`类，它们具有相同的关系。要将我们下载的数据转换为`DataLoaders`对象，我们至少需要告诉fastai四件事：
- en: What kinds of data we are working with
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们正在处理什么类型的数据
- en: How to get the list of items
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何获取项目列表
- en: How to label these items
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何为这些项目打标签
- en: How to create the validation set
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何创建验证集
- en: 'So far we have seen a number of *factory methods* for particular combinations
    of these things, which are convenient when you have an application and data structure
    that happen to fit into those predefined methods. For when you don’t, fastai has
    an extremely flexible system called the *data block API*. With this API, you can
    fully customize every stage of the creation of your `DataLoaders`. Here is what
    we need to create a `DataLoaders` for the dataset that we just downloaded:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到了一些特定组合的*工厂方法*，当您有一个应用程序和数据结构恰好适合这些预定义方法时，这些方法非常方便。当您不适用时，fastai有一个名为*数据块API*的极其灵活的系统。使用此API，您可以完全自定义创建`DataLoaders`的每个阶段。这是我们需要为刚刚下载的数据集创建`DataLoaders`的步骤：
- en: '[PRE17]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Let’s look at each of these arguments in turn. First we provide a tuple specifying
    the types we want for the independent and dependent variables:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们依次查看每个参数。首先，我们提供一个元组，指定我们希望独立变量和因变量的类型：
- en: '[PRE18]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The *independent variable* is the thing we are using to make predictions from,
    and the *dependent variable* is our target. In this case, our independent variable
    is a set of images, and our dependent variables are the categories (type of bear)
    for each image. We will see many other types of block in the rest of this book.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '*独立变量*是我们用来进行预测的东西，*因变量*是我们的目标。在这种情况下，我们的独立变量是一组图像，我们的因变量是每个图像的类别（熊的类型）。在本书的其余部分中，我们将看到许多其他类型的块。'
- en: 'For this `DataLoaders`, our underlying items will be file paths. We have to
    tell fastai how to get a list of those files. The `get_image_files` function takes
    a path, and returns a list of all of the images in that path (recursively, by
    default):'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个`DataLoaders`，我们的基础项目将是文件路径。我们必须告诉fastai如何获取这些文件的列表。`get_image_files`函数接受一个路径，并返回该路径中所有图像的列表（默认情况下递归）：
- en: '[PRE19]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Often, datasets that you download will already have a validation set defined.
    Sometimes this is done by placing the images for the training and validation sets
    into different folders. Sometimes it is done by providing a CSV file in which
    each filename is listed along with which dataset it should be in. There are many
    ways that this can be done, and fastai provides a general approach that allows
    you to use one of its predefined classes for this or to write your own.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，您下载的数据集已经定义了验证集。有时，这是通过将用于训练和验证集的图像放入不同的文件夹中来完成的。有时，这是通过提供一个CSV文件，在该文件中，每个文件名都与应该在其中的数据集一起列出。有许多可以完成此操作的方法，fastai提供了一种通用方法，允许您使用其预定义类之一或编写自己的类。
- en: In this case, we want to split our training and validation sets randomly. However,
    we would like to have the same training/validation split each time we run this
    notebook, so we fix the random seed (computers don’t really know how to create
    random numbers at all, but simply create lists of numbers that look random; if
    you provide the same starting point for that list each time—called the *seed*—then
    you will get the exact same list each time).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们希望随机拆分我们的训练和验证集。但是，我们希望每次运行此笔记本时都具有相同的训练/验证拆分，因此我们固定随机种子（计算机实际上不知道如何创建随机数，而只是创建看起来随机的数字列表；如果您每次都为该列表提供相同的起始点——称为*种子*，那么您将每次都获得完全相同的列表）。
- en: '[PRE20]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The independent variable is often referred to as `x`, and the dependent variable
    is often referred to as `y`. Here, we are telling fastai what function to call
    to create the labels in our dataset:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '`parent_label` is a function provided by fastai that simply gets the name of
    the folder a file is in. Because we put each of our bear images into folders based
    on the type of bear, this is going to give us the labels that we need.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: 'Our images are all different sizes, and this is a problem for deep learning:
    we don’t feed the model one image at a time but several of them (what we call
    a *mini-batch*). To group them in a big array (usually called a *tensor*) that
    is going to go through our model, they all need to be of the same size. So, we
    need to add a transform that will resize these images to the same size. *Item
    transforms* are pieces of code that run on each individual item, whether it be
    an image, category, or so forth. fastai includes many predefined transforms; we
    use the `Resize` transform here and specify a size of 128 pixels:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This command has given us a `DataBlock` object. This is like a *template* for
    creating a `DataLoaders`. We still need to tell fastai the actual source of our
    data—in this case, the path where the images can be found:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'A `DataLoaders` includes validation and training `DataLoader`s. A `DataLoader`
    is a class that provides batches of a few items at a time to the GPU. We’ll be
    learning a lot more about this class in the next chapter. When you loop through
    a `DataLoader`, fastai will give you 64 (by default) items at a time, all stacked
    up into a single tensor. We can take a look at a few of those items by calling
    the `show_batch` method on a `DataLoader`:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![](Images/dlcf_02in02.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
- en: 'By default, `Resize` *crops* the images to fit a square shape of the size requested,
    using the full width or height. This can result in losing some important details.
    Alternatively, you can ask fastai to pad the images with zeros (black), or squish/stretch
    them:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![](Images/dlcf_02in03.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
- en: '[PRE26]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![](Images/dlcf_02in04.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
- en: All of these approaches seem somewhat wasteful or problematic. If we squish
    or stretch the images, they end up as unrealistic shapes, leading to a model that
    learns that things look different from how they actually are, which we would expect
    to result in lower accuracy. If we crop the images, we remove some of the features
    that allow us to perform recognition. For instance, if we were trying to recognize
    breeds of dog or cat, we might end up cropping out a key part of the body or the
    face necessary to distinguish between similar breeds. If we pad the images, we
    have a whole lot of empty space, which is just wasted computation for our model
    and results in a lower effective resolution for the part of the image we actually
    use.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, what we normally do in practice is to randomly select part of the
    image and then crop to just that part. On each epoch (which is one complete pass
    through all of our images in the dataset), we randomly select a different part
    of each image. This means that our model can learn to focus on, and recognize,
    different features in our images. It also reflects how images work in the real
    world: different photos of the same thing may be framed in slightly different
    ways.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: In fact, an entirely untrained neural network knows nothing whatsoever about
    how images behave. It doesn’t even recognize that when an object is rotated by
    one degree, it still is a picture of the same thing! So training the neural network
    with examples of images in which the objects are in slightly different places
    and are slightly different sizes helps it to understand the basic concept of what
    an object is, and how it can be represented in an image.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is another example where we replace `Resize` with `RandomResizedCrop`,
    which is the transform that provides the behavior just described. The most important
    parameter to pass in is `min_scale`, which determines how much of the image to
    select at minimum each time:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![](Images/dlcf_02in05.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
- en: Here, we used `unique=True` to have the same image repeated with different versions
    of this `RandomResizedCrop` transform.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '`RandomResizedCrop` is a specific example of a more general technique, called
    data augmentation.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Data Augmentation
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '*Data augmentation* refers to creating random variations of our input data,
    such that they appear different but do not change the meaning of the data. Examples
    of common data augmentation techniques for images are rotation, flipping, perspective
    warping, brightness changes, and contrast changes. For natural photo images such
    as the ones we are using here, a standard set of augmentations that we have found
    work pretty well are provided with the `aug_transforms` function.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: 'Because our images are now all the same size, we can apply these augmentations
    to an entire batch of them using the GPU, which will save a lot of time. To tell
    fastai we want to use these transforms on a batch, we use the `batch_tfms` parameter
    (note that we’re not using `RandomResizedCrop` in this example, so you can see
    the differences more clearly; we’re also using double the amount of augmentation
    compared to the default, for the same reason):'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![](Images/dlcf_02in06.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
- en: Now that we have assembled our data in a format fit for model training, let’s
    train an image classifier using it.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Training Your Model, and Using It to Clean Your Data
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Time to use the same lines of code as in [Chapter 1](ch01.xhtml#chapter_intro)
    to train our bear classifier. We don’t have a lot of data for our problem (150
    pictures of each sort of bear at most), so to train our model, we’ll use `RandomResizedCrop`,
    an image size of 224 pixels, which is fairly standard for image classification,
    and the default `aug_transforms`:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We can now create our `Learner` and fine-tune it in the usual way:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '| epoch | train_loss | valid_loss | error_rate | time |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
- en: '| 0 | 1.235733 | 0.212541 | 0.087302 | 00:05 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
- en: '| epoch | train_loss | valid_loss | error_rate | time |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
- en: '| 0 | 0.213371 | 0.112450 | 0.023810 | 00:05 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
- en: '| 1 | 0.173855 | 0.072306 | 0.023810 | 00:06 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
- en: '| 2 | 0.147096 | 0.039068 | 0.015873 | 00:06 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
- en: '| 3 | 0.123984 | 0.026801 | 0.015873 | 00:06 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
- en: 'Now let’s see whether the mistakes the model is making are mainly thinking
    that grizzlies are teddies (that would be bad for safety!), or that grizzlies
    are black bears, or something else. To visualize this, we can create a *confusion
    matrix*:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '![](Images/dlcf_02in07.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
- en: The rows represent all the black, grizzly, and teddy bears in our dataset, respectively.
    The columns represent the images that the model predicted as black, grizzly, and
    teddy bears, respectively. Therefore, the diagonal of the matrix shows the images
    that were classified correctly, and the off-diagonal cells represent those that
    were classified incorrectly. This is one of the many ways that fastai allows you
    to view the results of your model. It is (of course!) calculated using the validation
    set. With the color-coding, the goal is to have white everywhere except the diagonal,
    where we want dark blue. Our bear classifier isn’t making many mistakes!
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: It’s helpful to see where exactly our errors are occurring, to see whether they’re
    due to a dataset problem (e.g., images that aren’t bears at all, or are labeled
    incorrectly) or a model problem (perhaps it isn’t handling images taken with unusual
    lighting, or from a different angle, etc.). To do this, we can sort our images
    by their loss.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: 'The *loss* is a number that is higher if the model is incorrect (especially
    if it’s also confident of its incorrect answer), or if it’s correct but not confident
    of its correct answer. In the beginning of [Part II](part02.xhtml#part2), we’ll
    learn in depth how loss is calculated and used in the training process. For now,
    `plot_top_losses` shows us the images with the highest loss in our dataset. As
    the title of the output says, each image is labeled with four things: prediction,
    actual (target label), loss, and probability. The *probability* here is the confidence
    level, from zero to one, that the model has assigned to its prediction:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '![](Images/dlcf_02in08.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
- en: This output shows that the image with the highest loss is one that has been
    predicted as “grizzly” with high confidence. However, it’s labeled (based on our
    Bing image search) as “black.” We’re not bear experts, but it sure looks to us
    like this label is incorrect! We should probably change its label to “grizzly.”
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: The intuitive approach to doing data cleaning is to do it *before* you train
    a model. But as you’ve seen in this case, a model can help you find data issues
    more quickly and easily. So, we normally prefer to train a quick and simple model
    first, and then use it to help us with data cleaning.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: 'fastai includes a handy GUI for data cleaning called `ImageClassifierCleaner`
    that allows you to choose a category and the training versus validation set and
    view the highest-loss images (in order), along with menus to allow images to be
    selected for removal or relabeling:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '![Cleaner widget](Images/dlcf_02in09.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
- en: 'We can see that among our “black bears” is an image that contains two bears:
    one grizzly, one black. So, we should choose `<Delete>` in the menu under this
    image. `ImageClassifierCleaner` doesn’t do the deleting or changing of labels
    for you; it just returns the indices of items to change. So, for instance, to
    delete (`unlink`) all images selected for deletion, we would run this:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'To move images for which we’ve selected a different category, we would run
    this:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Sylvain Says
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cleaning the data and getting it ready for your model are two of the biggest
    challenges for data scientists; they say it takes 90% of their time. The fastai
    library aims to provide tools that make it as easy as possible.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: We’ll be seeing more examples of model-driven data cleaning throughout this
    book. Once we’ve cleaned up our data, we can retrain our model. Try it yourself,
    and see if your accuracy improves!
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: No Need for Big Data
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After cleaning the dataset using these steps, we generally are seeing 100% accuracy
    on this task. We even see that result when we download a lot fewer images than
    the 150 per class we’re using here. As you can see, the common complaint that
    *you need massive amounts of data to do deep learning* can be a very long way
    from the truth!
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have trained our model, let’s see how we can deploy it to be used
    in practice.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: Turning Your Model into an Online Application
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We are now going to look at what it takes to turn this model into a working
    online application. We will just go as far as creating a basic working prototype;
    we do not have the scope in this book to teach you all the details of web application
    development generally.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: Using the Model for Inference
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once you’ve got a model you’re happy with, you need to save it so you can then
    copy it over to a server where you’ll use it in production. Remember that a model
    consists of two parts: the *architecture* and the trained *parameters*. The easiest
    way to save a model is to save both of these, because that way, when you load
    the model, you can be sure that you have the matching architecture and parameters.
    To save both parts, use the `export` method.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: This method even saves the definition of how to create your `DataLoaders`. This
    is important, because otherwise you would have to redefine how to transform your
    data in order to use your model in production. fastai automatically uses your
    validation set `DataLoader` for inference by default, so your data augmentation
    will not be applied, which is generally what you want.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: 'When you call `export`, fastai will save a file called *export.pkl*:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Let’s check that the file exists, by using the `ls` method that fastai adds
    to Python’s `Path` class:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: You’ll need this file wherever you deploy your app to. For now, let’s try to
    create a simple app within our notebook.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: 'When we use a model for getting predictions, instead of training, we call it
    *inference*. To create our inference learner from the exported file, we use `load_learner`
    (in this case, this isn’t really necessary, since we already have a working `Learner`
    in our notebook; we’re doing it here so you can see the whole process end to end):'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'When we’re doing inference, we’re generally getting predictions for just one
    image at a time. To do this, pass a filename to `predict`:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'This has returned three things: the predicted category in the same format you
    originally provided (in this case, that’s a string), the index of the predicted
    category, and the probabilities of each category. The last two are based on the
    order of categories in the *vocab* of the `DataLoaders`; that is, the stored list
    of all possible categories. At inference time, you can access the `DataLoaders`
    as an attribute of the `Learner`:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: We can see here that if we index into the vocab with the integer returned by
    `predict`, we get back “grizzly,” as expected. Also, note that if we index into
    the list of probabilities, we see a nearly 1.00 probability that this is a grizzly.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: We know how to make predictions from our saved model, so we have everything
    we need to start building our app. We can do it directly in a Jupyter notebook.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Notebook App from the Model
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To use our model in an application, we can simply treat the `predict` method
    as a regular function. Therefore, creating an app from the model can be done using
    any of the myriad of frameworks and techniques available to application developers.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: 'However, most data scientists are not familiar with the world of web application
    development. So let’s try using something that you do, at this point, know: it
    turns out that we can create a complete working web application using nothing
    but Jupyter notebooks! The two things we need to make this happen are as follows:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: IPython widgets (ipywidgets)
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Voilà
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*IPython widgets* are GUI components that bring together JavaScript and Python
    functionality in a web browser, and can be created and used within a Jupyter notebook.
    For instance, the image cleaner that we saw earlier in this chapter is entirely
    written with IPython widgets. However, we don’t want to require users of our application
    to run Jupyter themselves.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: 'That is why *Voilà* exists. It is a system for making applications consisting
    of IPython widgets available to end users, without them having to use Jupyter
    at all. Voilà is taking advantage of the fact that a notebook *already is* a kind
    of web application, just a rather complex one that depends on another web application:
    Jupyter itself. Essentially, it helps us automatically convert the complex web
    application we’ve already implicitly made (the notebook) into a simpler, easier-to-deploy
    web application, which functions like a normal web application rather than like
    a notebook.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: 'But we still have the advantage of developing in a notebook, so with ipywidgets,
    we can build up our GUI step by step. We will use this approach to create a simple
    image classifier. First, we need a file upload widget:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '![An upload button](Images/dlcf_01in02.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
- en: 'Now we can grab the image:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '![Output widget representing the image](Images/dlcf_02in11.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
- en: 'We can use an `Output` widget to display it:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '![Output widget representing the image](Images/dlcf_02in11.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
- en: 'Then we can get our predictions:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'And use a `Label` to display them:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '`Prediction: grizzly; Probability: 1.0000`'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll need a button to do the classification. It looks exactly like the Upload
    button:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We’ll also need a *click event handler*; that is, a function that will be called
    when it’s pressed. We can just copy over the previous lines of code:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: You can test the button now by clicking it, and you should see the image and
    predictions update automatically!
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now put them all in a vertical box (`VBox`) to complete our GUI:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '![The whole widget](Images/dlcf_02in13.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
- en: We have written all the code necessary for our app. The next step is to convert
    it into something we can deploy.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: Turning Your Notebook into a Real App
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have everything working in this Jupyter notebook, we can create
    our application. To do this, start a new notebook and add to it only the code
    needed to create and show the widgets that you need, and Markdown for any text
    that you want to appear. Have a look at the *bear_classifier* notebook in the
    book’s repo to see the simple notebook application we created.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, install Voilà if you haven’t already by copying these lines into a notebook
    cell and executing it:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Cells that begin with a `!` do not contain Python code, but instead contain
    code that is passed to your shell (bash, Windows PowerShell, etc.). If you are
    comfortable using the command line, which we’ll discuss more in this book, you
    can of course simply type these two lines (without the `!` prefix) directly into
    your terminal. In this case, the first line installs the `voila` library and application,
    and the second connects it to your existing Jupyter notebook.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: 'Voilà runs Jupyter notebooks just like the Jupyter notebook server you are
    using now does, but it also does something very important: it removes all of the
    cell inputs, and shows only output (including ipywidgets), along with your Markdown
    cells. So what’s left is a web application! To view your notebook as a Voilà web
    application, replace the word “notebooks” in your browser’s URL with “voila/render”.
    You will see the same content as your notebook, but without any of the code cells.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: Of course, you don’t need to use Voilà or ipywidgets. Your model is just a function
    you can call (`pred,pred_idx,probs = learn.predict(img)`), so you can use it with
    any framework, hosted on any platform. And you can take something you’ve prototyped
    in ipywidgets and Voilà and later convert it into a regular web application. We’re
    showing you this approach in the book because we think it’s a great way for data
    scientists and other folks who aren’t web development experts to create applications
    from their models.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: We have our app; now let’s deploy it!
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: Deploying Your App
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As you now know, you need a GPU to train nearly any useful deep learning model.
    So, do you need a GPU to use that model in production? No! You almost certainly
    *do not need a GPU to serve your model in production*. There are a few reasons
    for this:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: As we’ve seen, GPUs are useful only when they do lots of identical work in parallel.
    If you’re doing (say) image classification, you’ll normally be classifying just
    one user’s image at a time, and there isn’t normally enough work to do in a single
    image to keep a GPU busy for long enough for it to be very efficient. So, a CPU
    will often be more cost-effective.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An alternative could be to wait for a few users to submit their images, and
    then batch them up and process them all at once on a GPU. But then you’re asking
    your users to wait, rather than getting answers straight away! And you need a
    high-volume site for this to be workable. If you do need this functionality, you
    can use a tool such as Microsoft’s [ONNX Runtime](https://oreil.ly/nj-6f) or [AWS
    SageMaker](https://oreil.ly/ajcaP).
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The complexities of dealing with GPU inference are significant. In particular,
    the GPU’s memory will need careful manual management, and you’ll need a careful
    queueing system to ensure you process only one batch at a time.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There’s a lot more market competition in CPU than GPU servers, and as a result,
    there are much cheaper options available for CPU servers.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Because of the complexity of GPU serving, many systems have sprung up to try
    to automate this. However, managing and running these systems is also complex,
    and generally requires compiling your model into a different form that’s specialized
    for that system. It’s typically preferable to avoid dealing with this complexity
    until/unless your app gets popular enough that it makes clear financial sense
    for you to do so.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: 'For at least the initial prototype of your application, and for any hobby projects
    that you want to show off, you can easily host them for free. The best place and
    the best way to do this will vary over time, so check the book’s website for the
    most up-to-date recommendations. As we’re writing this book in early 2020, the
    simplest (and free!) approach is to use [Binder](https://mybinder.org). To publish
    your web app on Binder, you follow these steps:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: Add your notebook to a [GitHub repository](http://github.com).
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Paste the URL of that repo into Binder’s URL field, as shown in [Figure 2-4](#deploy-binder).
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Change the File drop-down to instead select URL.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In the “URL to open” field, enter `/voila/render/*name*.ipynb` (replacing *`name`*
    with the name of your notebook).
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click the clipboard button at the bottom right to copy the URL and paste it
    somewhere safe.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click Launch.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Deploying to Binder](Images/dlcf_0204.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
- en: Figure 2-4\. Deploying to Binder
  id: totrans-258
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The first time you do this, Binder will take around 5 minutes to build your
    site. Behind the scenes, it is finding a virtual machine that can run your app,
    allocating storage, and collecting the files needed for Jupyter, for your notebook,
    and for presenting your notebook as a web application.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: Finally, once it has started the app running, it will navigate your browser
    to your new web app. You can share the URL you copied to allow others to access
    your app as well.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: For other (both free and paid) options for deploying your web app, be sure to
    take a look at the [book’s website](https://book.fast.ai).
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: You may well want to deploy your application onto mobile devices, or edge devices
    such as a Raspberry Pi. There are a lot of libraries and frameworks that allow
    you to integrate a model directly into a mobile application. However, these approaches
    tend to require a lot of extra steps and boilerplate, and do not always support
    all the PyTorch and fastai layers that your model might use. In addition, the
    work you do will depend on the kinds of mobile devices you are targeting for deployment—you
    might need to do some work to run on iOS devices, different work to run on newer
    Android devices, different work for older Android devices, etc. Instead, we recommend
    wherever possible that you deploy the model itself to a server, and have your
    mobile or edge application connect to it as a web service.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: There are quite a few upsides to this approach. The initial installation is
    easier, because you have to deploy only a small GUI application, which connects
    to the server to do all the heavy lifting. More importantly perhaps, upgrades
    of that core logic can happen on your server, rather than needing to be distributed
    to all of your users. Your server will have a lot more memory and processing capacity
    than most edge devices, and it is far easier to scale those resources if your
    model becomes more demanding. The hardware that you will have on a server is also
    going to be more standard and more easily supported by fastai and PyTorch, so
    you don’t have to compile your model into a different form.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: There are downsides too, of course. Your application will require a network
    connection, and there will be some latency each time the model is called. (It
    takes a while for a neural network model to run anyway, so this additional network
    latency may not make a big difference to your users in practice. In fact, since
    you can use better hardware on the server, the overall latency may even be less
    than if it were running locally!) Also, if your application uses sensitive data,
    your users may be concerned about an approach that sends that data to a remote
    server, so sometimes privacy considerations will mean that you need to run the
    model on the edge device (it may be possible to avoid this by having an *on-premise*
    server, such as inside a company’s firewall). Managing the complexity and scaling
    the server can create additional overhead too, whereas if your model runs on the
    edge devices, each user is bringing their own compute resources, which leads to
    easier scaling with an increasing number of users (also known as *horizontal scaling*).
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: Alexis Says
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I’ve had a chance to see up close how the mobile ML landscape is changing in
    my work. We offer an iPhone app that depends on computer vision, and for years
    we ran our own computer vision models in the cloud. This was the only way to do
    it then since those models needed significant memory and compute resources and
    took minutes to process inputs. This approach required building not only the models
    (fun!), but also the infrastructure to ensure a certain number of “compute worker
    machines” were absolutely always running (scary), that more machines would automatically
    come online if traffic increased, that there was stable storage for large inputs
    and outputs, that the iOS app could know and tell the user how their job was doing,
    etc. Nowadays Apple provides APIs for converting models to run efficiently on
    devices, and most iOS devices have dedicated ML hardware, so that’s the strategy
    we use for our newer models. It’s still not easy, but in our case it’s worth it
    for a faster user experience and to worry less about servers. What works for you
    will depend, realistically, on the user experience you’re trying to create and
    what you personally find is easy to do. If you really know how to run servers,
    do it. If you really know how to build native mobile apps, do that. There are
    many roads up the hill.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: Overall, we’d recommend using a simple CPU-based server approach where possible,
    for as long as you can get away with it. If you’re lucky enough to have a very
    successful application, you’ll be able to justify the investment in more complex
    deployment approaches at that time.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations—you have successfully built a deep learning model and deployed
    it! Now is a good time to take a pause and think about what could go wrong.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: How to Avoid Disaster
  id: totrans-269
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In practice, a deep learning model will be just one piece of a much bigger system.
    As we discussed at the start of this chapter, building a data product requires
    thinking about the entire end-to-end process, from conception to use in production.
    In this book, we can’t hope to cover all the complexity of managing deployed data
    products, such as managing multiple versions of models, A/B testing, canarying,
    refreshing the data (should we just grow and grow our datasets all the time, or
    should we regularly remove some of the old data?), handling data labeling, monitoring
    all this, detecting model rot, and so forth.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will give an overview of some of the most important issues
    to consider; for a more detailed discussion of deployment issues, we refer you
    to the excellent [*Building Machine Learning Powered Applications*](http://shop.oreilly.com/product/0636920215912.do)
    by Emmanuel Ameisin (O’Reilly).
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: One of the biggest issues to consider is that understanding and testing the
    behavior of a deep learning model is much more difficult than with most other
    code you write. With normal software development, you can analyze the exact steps
    that the software is taking, and carefully study which of these steps match the
    desired behavior that you are trying to create. But with a neural network, the
    behavior emerges from the model’s attempt to match the training data, rather than
    being exactly defined.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: 'This can result in disaster! For instance, let’s say we really were rolling
    out a bear detection system that will be attached to video cameras around campsites
    in national parks and will warn campers of incoming bears. If we used a model
    trained with the dataset we downloaded, there would be all kinds of problems in
    practice, such as these:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: Working with video data instead of images
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling nighttime images, which may not appear in this dataset
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dealing with low-resolution camera images
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensuring results are returned fast enough to be useful in practice
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recognizing bears in positions that are rarely seen in photos that people post
    online (for example from behind, partially covered by bushes, or a long way away
    from the camera)
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A big part of the issue is that the kinds of photos that people are most likely
    to upload to the internet are the kinds of photos that do a good job of clearly
    and artistically displaying their subject matter—which isn’t the kind of input
    this system is going to be getting. So, we may need to do a lot of our own data
    collection and labeling to create a useful system.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: This is just one example of the more general problem of *out-of-domain* data.
    That is to say, there may be data that our model sees in production that is very
    different from what it saw during training. There isn’t a complete technical solution
    to this problem; instead, we have to be careful about our approach to rolling
    out the technology.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: There are other reasons we need to be careful too. One very common problem is
    *domain shift*, whereby the type of data that our model sees changes over time.
    For instance, an insurance company may use a deep learning model as part of its
    pricing and risk algorithm, but over time the types of customers the company attracts
    and the types of risks it represents may change so much that the original training
    data is no longer relevant.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: 'Out-of-domain data and domain shift are examples of a larger problem: that
    you can never fully understand all the possible behaviors of a neural network,
    because they have far too many parameters. This is the natural downside of their
    best feature—their flexibility, which enables them to solve complex problems where
    we may not even be able to fully specify our preferred solution approaches. The
    good news, however, is that there are ways to mitigate these risks using a carefully
    thought-out process. The details of this will vary depending on the details of
    the problem you are solving, but we will attempt to lay out a high-level approach,
    summarized in [Figure 2-5](#deploy_process), which we hope will provide useful
    guidance.'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '![Deployment process](Images/dlcf_0205.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
- en: Figure 2-5\. Deployment process
  id: totrans-284
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Where possible, the first step is to use an entirely manual process, with your
    deep learning model approach running in parallel but not being used directly to
    drive any actions. The humans involved in the manual process should look at the
    deep learning outputs and check whether they make sense. For instance, with our
    bear classifier, a park ranger could have a screen displaying video feeds from
    all the cameras, with any possible bear sightings simply highlighted in red. The
    park ranger would still be expected to be just as alert as before the model was
    deployed; the model is simply helping to check for problems at this point.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: The second step is to try to limit the scope of the model, and have it carefully
    supervised by people. For instance, do a small geographically and time-constrained
    trial of the model-driven approach. Rather than rolling out our bear classifier
    in every national park throughout the country, we could pick a single observation
    post, for a one-week period, and have a park ranger check each alert before it
    goes out.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: Then, gradually increase the scope of your rollout. As you do so, ensure that
    you have really good reporting systems in place, to make sure that you are aware
    of any significant changes to the actions being taken compared to your manual
    process. For instance, if the number of bear alerts doubles or halves after rollout
    of the new system in some location, you should be very concerned. Try to think
    about all the ways in which your system could go wrong, and then think about what
    measure or report or picture could reflect that problem, and ensure that your
    regular reporting includes that information.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: Jeremy Says
  id: totrans-288
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: I started a company 20 years ago called Optimal Decisions that used machine
    learning and optimization to help giant insurance companies set their pricing,
    impacting tens of billions of dollars of risks. We used the approaches described
    here to manage the potential downsides of something going wrong. Also, before
    we worked with our clients to put anything in production, we tried to simulate
    the impact by testing the end-to-end system on their previous year’s data. It
    was always quite a nerve-wracking process putting these new algorithms into production,
    but every rollout was successful.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: Unforeseen Consequences and Feedback Loops
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the biggest challenges in rolling out a model is that your model may
    change the behavior of the system it is a part of. For instance, consider a “predictive
    policing” algorithm that predicts more crime in certain neighborhoods, causing
    more police officers to be sent to those neighborhoods, which can result in more
    crimes being recorded in those neighborhoods, and so on. In the Royal Statistical
    Society paper [“To Predict and Serve?”](https://oreil.ly/3YEWH) Kristian Lum and
    William Isaac observe that “predictive policing is aptly named: it is predicting
    future policing, not future crime.”'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: 'Part of the issue in this case is that in the presence of bias (which we’ll
    discuss in depth in the next chapter), *feedback loops* can result in negative
    implications of that bias getting worse and worse. For instance, there are concerns
    that this is already happening in the US, where there is significant bias in arrest
    rates on racial grounds. [According to the ACLU](https://oreil.ly/A9ijk), “despite
    roughly equal usage rates, Blacks are 3.73 times more likely than whites to be
    arrested for marijuana.” The impact of this bias, along with the rollout of predictive
    policing algorithms in many parts of the United States, led Bärí Williams to [write
    in the *New York Times*](https://oreil.ly/xR0di): “The same technology that’s
    the source of so much excitement in my career is being used in law enforcement
    in ways that could mean that in the coming years, my son, who is 7 now, is more
    likely to be profiled or arrested—or worse—for no reason other than his race and
    where we live.”'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: 'A helpful exercise prior to rolling out a significant machine learning system
    is to consider this question: “What would happen if it went really, really well?”
    In other words, what if the predictive power was extremely high, and its ability
    to influence behavior was extremely significant? In that case, who would be most
    impacted? What would the most extreme results potentially look like? How would
    you know what was really going on?'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: Such a thought exercise might help you to construct a more careful rollout plan,
    with ongoing monitoring systems and human oversight. Of course, human oversight
    isn’t useful if it isn’t listened to, so make sure that reliable and resilient
    communication channels exist so that the right people will be aware of issues
    and will have the power to fix them.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: Get Writing!
  id: totrans-295
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the things our students have found most helpful to solidify their understanding
    of this material is to write it down. There is no better test of your understanding
    of a topic than attempting to teach it to somebody else. This is helpful even
    if you never show your writing to anybody—but it’s even better if you share it!
    So we recommend that, if you haven’t already, you start a blog. Now that you’ve
    completed this chapter and have learned how to train and deploy models, you’re
    well placed to write your first blog post about your deep learning journey. What’s
    surprised you? What opportunities do you see for deep learning in your field?
    What obstacles do you see?
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: 'Rachel Thomas, cofounder of fast.ai, wrote in the article [“Why You (Yes, You)
    Should Blog”](https://oreil.ly/X9-3L):'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: 'The top advice I would give my younger self would be to start blogging sooner.
    Here are some reasons to blog:'
  id: totrans-298
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  id: totrans-299
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It’s like a resume, only better. I know of a few people who have had blog posts
    lead to job offers!
  id: totrans-300
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  id: totrans-301
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-302
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Helps you learn. Organizing knowledge always helps me synthesize my own ideas.
    One of the tests of whether you understand something is whether you can explain
    it to someone else. A blog post is a great way to do that.
  id: totrans-303
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  id: totrans-304
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-305
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: I’ve gotten invitations to conferences and invitations to speak from my blog
    posts. I was invited to the TensorFlow Dev Summit (which was awesome!) for writing
    a blog post about how I don’t like TensorFlow.
  id: totrans-306
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  id: totrans-307
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-308
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Meet new people. I’ve met several people who have responded to blog posts I
    wrote.
  id: totrans-309
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: ''
  id: totrans-310
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-311
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Saves time. Any time you answer a question multiple times through email, you
    should turn it into a blog post, which makes it easier for you to share the next
    time someone asks.
  id: totrans-312
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Perhaps her most important tip is this:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: You are best positioned to help people one step behind you. The material is
    still fresh in your mind. Many experts have forgotten what it was like to be a
    beginner (or an intermediate) and have forgotten why the topic is hard to understand
    when you first hear it. The context of your particular background, your particular
    style, and your knowledge level will give a different twist to what you’re writing
    about.
  id: totrans-314
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: We’ve provided full details on how to set up a blog in [Appendix A](app01.xhtml#creating_a_blog).
    If you don’t have a blog already, take a look at that now, because we’ve got a
    really great approach for you to start blogging for free, with no ads—and you
    can even use Jupyter Notebook!
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: Questionnaire
  id: totrans-316
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Where do text models currently have a major deficiency?
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are possible negative societal implications of text generation models?
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In situations where a model might make mistakes, and those mistakes could be
    harmful, what is a good alternative to automating a process?
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What kind of tabular data is deep learning particularly good at?
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What’s a key downside of directly using a deep learning model for recommendation
    systems?
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the steps of the Drivetrain Approach?
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do the steps of the Drivetrain Approach map to a recommendation system?
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Create an image recognition model using data you curate, and deploy it on the
    web.
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is `DataLoaders`?
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What four things do we need to tell fastai to create `DataLoaders`?
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does the `splitter` parameter to `DataBlock` do?
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How do we ensure a random split always gives the same validation set?
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What letters are often used to signify the independent and dependent variables?
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What’s the difference between the crop, pad, and squish resize approaches? When
    might you choose one over the others?
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is data augmentation? Why is it needed?
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Provide an example of where the bear classification model might work poorly
    in production, due to structural or style differences in the training data.
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the difference between `item_tfms` and `batch_tfms`?
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is a confusion matrix?
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What does `export` save?
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is it called when we use a model for making predictions, instead of training?
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are IPython widgets?
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When would you use a CPU for deployment? When might a GPU be better?
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the downsides of deploying your app to a server, instead of to a client
    (or edge) device such as a phone or PC?
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are three examples of problems that could occur when rolling out a bear
    warning system in practice?
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is out-of-domain data?
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What is domain shift?
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: What are the three steps in the deployment process?
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further Research
  id: totrans-344
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Consider how the Drivetrain Approach maps to a project or problem you’re interested
    in.
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When might it be best to avoid certain types of data augmentation?
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For a project you’re interested in applying deep learning to, consider the thought
    experiment, “What would happen if it went really, really well?”
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start a blog and write your first blog post. For instance, write about what
    you think deep learning might be useful for in a domain you’re interested in.
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
