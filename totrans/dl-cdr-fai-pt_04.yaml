- en: Chapter 2\. From Model to Production
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第二章。从模型到生产
- en: The six lines of code we saw in [Chapter 1](ch01.xhtml#chapter_intro) are just
    one small part of the process of using deep learning in practice. In this chapter,
    we’re going to use a computer vision example to look at the end-to-end process
    of creating a deep learning application. More specifically, we’re going to build
    a bear classifier! In the process, we’ll discuss the capabilities and constraints
    of deep learning, explore how to create datasets, look at possible gotchas when
    using deep learning in practice, and more. Many of the key points will apply equally
    well to other deep learning problems, such as those in [Chapter 1](ch01.xhtml#chapter_intro).
    If you work through a problem similar in key respects to our example problems,
    we expect you to get excellent results with little code, quickly.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[第1章](ch01.xhtml#chapter_intro)中看到的六行代码只是在实践中使用深度学习过程的一小部分。在本章中，我们将使用一个计算机视觉示例来查看创建深度学习应用的端到端过程。更具体地说，我们将构建一个熊分类器！在这个过程中，我们将讨论深度学习的能力和限制，探讨如何创建数据集，在实践中使用深度学习时可能遇到的问题等等。许多关键点同样适用于其他深度学习问题，例如[第1章](ch01.xhtml#chapter_intro)中的问题。如果您解决的问题在关键方面类似于我们的示例问题，我们期望您可以快速获得极好的结果，而只需很少的代码。
- en: Let’s start with how you should frame your problem.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从如何构建您的问题开始。
- en: The Practice of Deep Learning
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习的实践
- en: We’ve seen that deep learning can solve a lot of challenging problems quickly
    and with little code. As a beginner, there’s a sweet spot of problems that are
    similar enough to our example problems that you can very quickly get extremely
    useful results. However, deep learning isn’t magic! The same six lines of code
    won’t work for every problem anyone can think of today.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经看到深度学习可以快速解决许多具有挑战性的问题，并且只需很少的代码。作为初学者，有一些问题与我们的示例问题足够相似，以便您可以非常快速地获得极其有用的结果。然而，深度学习并不是魔法！同样的六行代码不会适用于今天任何人可以想到的每个问题。
- en: Underestimating the constraints and overestimating the capabilities of deep
    learning may lead to frustratingly poor results, at least until you gain some
    experience and can solve the problems that arise. Conversely, overestimating the
    constraints and underestimating the capabilities of deep learning may mean you
    do not attempt a solvable problem because you talk yourself out of it.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 低估深度学习的限制并高估其能力可能导致令人沮丧的糟糕结果，至少在您获得一些经验并能解决出现的问题之前。相反，高估深度学习的限制并低估其能力可能意味着您不会尝试可解决的问题，因为您自己否定了它。
- en: 'We often talk to people who underestimate both the constraints and the capabilities
    of deep learning. Both of these can be problems: underestimating the capabilities
    means that you might not even try things that could be very beneficial, and underestimating
    the constraints might mean that you fail to consider and react to important issues.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们经常与低估深度学习的限制和能力的人交谈。这两者都可能是问题：低估能力意味着您可能甚至不会尝试可能非常有益的事情，而低估限制可能意味着您未能考虑和应对重要问题。
- en: The best thing to do is to keep an open mind. If you remain open to the possibility
    that deep learning might solve part of your problem with less data or complexity
    than you expect, you can design a process through which you can find the specific
    capabilities and constraints related to your particular problem. This doesn’t
    mean making any risky bets—we will show you how you can gradually roll out models
    so that they don’t create significant risks, and can even backtest them prior
    to putting them in production.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 最好的做法是保持开放的心态。如果您对深度学习可能以比您预期的更少的数据或复杂性解决部分问题持开放态度，您可以设计一个过程，通过该过程您可以找到与您特定问题相关的特定能力和限制。这并不意味着进行任何冒险的赌注-我们将向您展示如何逐渐推出模型，以便它们不会带来重大风险，并且甚至可以在投入生产之前对其进行回测。
- en: Starting Your Project
  id: totrans-8
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始您的项目
- en: So where should you start your deep learning journey? The most important thing
    is to ensure that you have a project to work on—it is only through working on
    your own projects that you will get real experience building and using models.
    When selecting a project, the most important consideration is data availability.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 那么您应该从哪里开始深度学习之旅呢？最重要的是确保您有一个要处理的项目-只有通过处理自己的项目，您才能获得构建和使用模型的真实经验。在选择项目时，最重要的考虑因素是数据的可用性。
- en: Regardless of whether you are doing a project just for your own learning or
    for practical application in your organization, you want to be able to start quickly.
    We have seen many students, researchers, and industry practitioners waste months
    or years while they attempt to find their perfect dataset. The goal is not to
    find the “perfect” dataset or project, but just to get started and iterate from
    there. If you take this approach, you will be on your third iteration of learning
    and improving while the perfectionists are still in the planning stages!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 无论您是为了自己的学习还是为了在组织中的实际应用而进行项目，您都希望能够快速开始。我们看到许多学生、研究人员和行业从业者在试图找到他们完美的数据集时浪费了几个月甚至几年的时间。目标不是找到“完美”的数据集或项目，而只是开始并从那里迭代。如果您采取这种方法，您将在完美主义者仍处于规划阶段时进行第三次迭代学习和改进！
- en: We also suggest that you iterate from end to end in your project; don’t spend
    months fine-tuning your model, or polishing the perfect GUI, or labeling the perfect
    dataset.…Instead, complete every step as well as you can in a reasonable amount
    of time, all the way to the end. For instance, if your final goal is an application
    that runs on a mobile phone, that should be what you have after each iteration.
    But perhaps in the early iterations you take shortcuts; for instance, by doing
    all of the processing on a remote server and using a simple responsive web application.
    By completing the project end to end, you will see where the trickiest bits are,
    and which bits make the biggest difference to the final result.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还建议您在项目中端到端迭代；不要花几个月来微调您的模型，或打磨完美的GUI，或标记完美的数据集……相反，尽可能在合理的时间内完成每一步，一直到最后。例如，如果您的最终目标是一个在手机上运行的应用程序，那么每次迭代后您都应该拥有这个。但也许在早期迭代中您会采取捷径；例如，在远程服务器上进行所有处理，并使用简单的响应式Web应用程序。通过完成项目的端到端，您将看到最棘手的部分在哪里，以及哪些部分对最终结果产生最大影响。
- en: As you work through this book, we suggest that you complete lots of small experiments,
    by running and adjusting the notebooks we provide, at the same time that you gradually
    develop your own projects. That way, you will be getting experience with all of
    the tools and techniques that we’re explaining as we discuss them.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 当您阅读本书时，我们建议您完成许多小实验，通过运行和调整我们提供的笔记本，同时逐渐开发自己的项目。这样，您将获得所有我们解释的工具和技术的经验，同时我们讨论它们。
- en: Sylvain Says
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Sylvain说
- en: To make the most of this book, take the time to experiment between each chapter,
    whether on your own project or by exploring the notebooks we provide. Then try
    rewriting those notebooks from scratch on a new dataset. It’s only by practicing
    (and failing) a lot that you will develop intuition of how to train a model.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了充分利用这本书，花时间在每一章之间进行实验，无论是在您自己的项目上还是通过探索我们提供的笔记本。然后尝试在新数据集上从头开始重写这些笔记本。只有通过大量练习（和失败），您才能培养出如何训练模型的直觉。
- en: By using the end-to-end iteration approach, you will also get a better understanding
    of how much data you really need. For instance, you may find you can easily get
    only 200 labeled data items, and you can’t really know until you try whether that’s
    enough to get the performance you need for your application to work well in practice.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用端到端迭代方法，您还将更好地了解您实际需要多少数据。例如，您可能会发现您只能轻松获得200个标记数据项，而在尝试之前，您无法真正知道这是否足以使您的应用在实践中良好运行。
- en: In an organizational context, you will be able to show your colleagues that
    your idea can work by showing them a real working prototype. We have repeatedly
    observed that this is the secret to getting good organizational buy-in for a project.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在组织环境中，您可以通过展示一个真实的工作原型来向同事展示您的想法是可行的。我们反复观察到，这是获得项目良好组织支持的秘诀。
- en: Since it is easiest to get started on a project for which you already have data
    available, that means it’s probably easiest to get started on a project related
    to something you are already doing, because you already have data about things
    that you are doing. For instance, if you work in the music business, you may have
    access to many recordings. If you work as a radiologist, you probably have access
    to lots of medical images. If you are interested in wildlife preservation, you
    may have access to lots of images of wildlife.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 由于最容易开始的项目是您已经有数据可用的项目，这意味着最容易开始的项目可能与您已经在做的事情相关，因为您已经有关于您正在做的事情的数据。例如，如果您在音乐行业工作，您可能可以访问许多录音。如果您是放射科医生，您可能可以访问大量医学图像。如果您对野生动物保护感兴趣，您可能可以访问大量野生动物图像。
- en: Sometimes you have to get a bit creative. Maybe you can find a previous machine
    learning project, such as a Kaggle competition, that is related to your field
    of interest. Sometimes you have to compromise. Maybe you can’t find the exact
    data you need for the precise project you have in mind; but you might be able
    to find something from a similar domain, or measured in a different way, tackling
    a slightly different problem. Working on these kinds of similar projects will
    still give you a good understanding of the overall process, and may help you identify
    other shortcuts, data sources, and so forth.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 有时您必须有点创造性。也许您可以找到一个先前的机器学习项目，比如一个与您感兴趣的领域相关的Kaggle竞赛。有时您必须做出妥协。也许您找不到您所需的确切数据来完成您心中的项目；但您可能会找到一些来自类似领域的数据，或者以不同方式测量的数据，解决一个略有不同的问题。在这些类似项目上工作仍然会让您对整个过程有很好的理解，并可能帮助您识别其他捷径、数据来源等。
- en: Especially when you are just starting out with deep learning, it’s not a good
    idea to branch out into very different areas, to places that deep learning has
    not been applied to before. That’s because if your model does not work at first,
    you will not know whether it is because you have made a mistake, or if the very
    problem you are trying to solve is simply not solvable with deep learning. And
    you won’t know where to look to get help. Therefore, it is best at first to start
    by finding an example online of something that somebody has had good results with
    and that is at least somewhat similar to what you are trying to achieve, by converting
    your data into a format similar to what someone else has used before (such as
    creating an image from your data). Let’s have a look at the state of deep learning,
    just so you know what kinds of things deep learning is good at right now.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是当您刚开始学习深度学习时，最好不要涉足非常不同的领域，不要涉足深度学习之前未应用的领域。因为如果您的模型一开始就不起作用，您将不知道是因为您犯了错误，还是您试图解决的问题根本无法用深度学习解决。您也不知道从哪里寻求帮助。因此，最好首先找到在线的一个例子，该例子已经取得了良好的结果，并且至少与您尝试实现的目标有些相似，通过将您的数据转换为其他人以前使用过的格式（例如从您的数据创建图像）。让我们看看深度学习的现状，这样您就知道深度学习目前擅长的领域。
- en: The State of Deep Learning
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习的现状
- en: Let’s start by considering whether deep learning can be any good at the problem
    you are looking to work on. This section provides a summary of the state of deep
    learning at the start of 2020\. However, things move very fast, and by the time
    you read this, some of these constraints may no longer exist. We will try to keep
    the book’s website up-to-date; in addition, a Google search for “what can AI do
    now” is likely to provide current information.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先考虑深度学习是否能够解决您要解决的问题。本节概述了2020年初深度学习的现状。然而，事情发展得非常快，当您阅读本文时，其中一些限制可能已经不存在。我们将尽力保持本书网站的最新信息；此外，搜索“AI现在能做什么”可能会提供当前信息。
- en: Computer vision
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 计算机视觉
- en: There are many domains in which deep learning has not been used to analyze images
    yet, but those where it has been tried have nearly universally shown that computers
    can recognize items in an image at least as well as people can—even specially
    trained people, such as radiologists. This is known as *object recognition*. Deep
    learning is also good at recognizing where objects in an image are, and can highlight
    their locations and name each found object. This is known as *object detection*
    (in a variant of this that we saw in [Chapter 1](ch01.xhtml#chapter_intro), every
    pixel is categorized based on the kind of object it is part of—this is called
    *segmentation*).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习尚未用于分析图像的许多领域，但在已经尝试过的领域中，几乎普遍表明计算机可以至少与人类一样好地识别图像中的物品，甚至是经过专门训练的人，如放射科医生。这被称为*物体识别*。深度学习还擅长识别图像中物体的位置，并可以突出它们的位置并命名每个找到的物体。这被称为*物体检测*（在我们在[第1章](ch01.xhtml#chapter_intro)中看到的变体中，每个像素根据其所属的对象类型进行分类—这被称为*分割*）。
- en: Deep learning algorithms are generally not good at recognizing images that are
    significantly different in structure or style from those used to train the model.
    For instance, if there were no black-and-white images in the training data, the
    model may do poorly on black-and-white images. Similarly, if the training data
    did not contain hand-drawn images, the model will probably do poorly on hand-drawn
    images. There is no general way to check which types of images are missing in
    your training set, but we will show in this chapter some ways to try to recognize
    when unexpected image types arise in the data when the model is being used in
    production (this is known as checking for *out-of-domain* data).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习算法通常不擅长识别结构或风格与用于训练模型的图像明显不同的图像。例如，如果训练数据中没有黑白图像，模型可能在黑白图像上表现不佳。同样，如果训练数据不包含手绘图像，模型可能在手绘图像上表现不佳。没有一般方法可以检查训练集中缺少哪些类型的图像，但我们将在本章中展示一些方法，以尝试识别当模型在生产中使用时数据中出现意外图像类型的情况（这被称为检查*域外*数据）。
- en: One major challenge for object detection systems is that image labeling can
    be slow and expensive. There is a lot of work at the moment going into tools to
    try to make this labeling faster and easier, and to require fewer handcrafted
    labels to train accurate object detection models. One approach that is particularly
    helpful is to synthetically generate variations of input images, such as by rotating
    them or changing their brightness and contrast; this is called *data augmentation*
    and also works well for text and other types of models. We will be discussing
    it in detail in this chapter.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 物体检测系统面临的一个主要挑战是图像标记可能会很慢且昂贵。目前有很多工作正在进行中，旨在开发工具以尝试使这种标记更快速、更容易，并且需要更少的手工标签来训练准确的物体检测模型。一个特别有帮助的方法是合成生成输入图像的变化，例如通过旋转它们或改变它们的亮度和对比度；这被称为*数据增强*，并且对文本和其他类型的模型也很有效。我们将在本章中详细讨论这一点。
- en: Another point to consider is that although your problem might not look like
    a computer vision problem, it might be possible with a little imagination to turn
    it into one. For instance, if what you are trying to classify are sounds, you
    might try converting the sounds into images of their acoustic waveforms and then
    training a model on those images.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个要考虑的问题是，尽管您的问题可能看起来不像是一个计算机视觉问题，但通过一点想象力可能可以将其转变为一个。例如，如果您要分类的是声音，您可以尝试将声音转换为其声学波形的图像，然后在这些图像上训练模型。
- en: Text (natural language processing)
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自然语言处理
- en: Computers are good at classifying both short and long documents based on categories
    such as spam or not spam, sentiment (e.g., is the review positive or negative),
    author, source website, and so forth. We are not aware of any rigorous work done
    in this area to compare computers to humans, but anecdotally it seems to us that
    deep learning performance is similar to human performance on these tasks.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机擅长基于类别对短文档和长文档进行分类，例如垃圾邮件或非垃圾邮件、情感（例如，评论是积极的还是消极的）、作者、来源网站等。我们不知道在这个领域是否有任何严格的工作来比较计算机和人类，但从经验上看，我们认为深度学习的性能在这些任务上与人类的性能相似。
- en: Deep learning is also good at generating context-appropriate text, such as replies
    to social media posts, and imitating a particular author’s style. It’s good at
    making this content compelling to humans too—in fact, even more compelling than
    human-generated text. However, deep learning is not good at generating *correct*
    responses! We don’t have a reliable way to, for instance, combine a knowledge
    base of medical information with a deep learning model for generating medically
    correct natural language responses. This is dangerous, because it is so easy to
    create content that appears to a layman to be compelling, but actually is entirely
    incorrect.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习还擅长生成与上下文相关的文本，例如回复社交媒体帖子，并模仿特定作者的风格。它还擅长使这些内容对人类具有吸引力—事实上，甚至比人类生成的文本更具吸引力。然而，深度学习不擅长生成*正确*的回应！例如，我们没有可靠的方法来将医学信息知识库与深度学习模型结合起来，以生成医学上正确的自然语言回应。这是危险的，因为很容易创建对外行人看来具有吸引力但实际上完全不正确的内容。
- en: Another concern is that context-appropriate, highly compelling responses on
    social media could be used at massive scale—thousands of times greater than any
    troll farm previously seen—to spread disinformation, create unrest, and encourage
    conflict. As a rule of thumb, text generation models will always be technologically
    a bit ahead of models for recognizing automatically generated text. For instance,
    it is possible to use a model that can recognize artificially generated content
    to actually improve the generator that creates that content, until the classification
    model is no longer able to complete its task.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是，社交媒体上的上下文适当、高度引人入胜的回应可能被大规模使用——比以前见过的任何喷子农场规模大几千倍——来传播虚假信息，制造动荡，鼓励冲突。一般来说，文本生成模型总是在技术上略领先于识别自动生成文本的模型。例如，可以使用一个能够识别人工生成内容的模型来实际改进创建该内容的生成器，直到分类模型无法完成其任务为止。
- en: 'Despite these issues, deep learning has many applications in NLP: it can be
    used to translate text from one language to another, summarize long documents
    into something that can be digested more quickly, find all mentions of a concept
    of interest, and more. Unfortunately, the translation or summary could well include
    completely incorrect information! However, the performance is already good enough
    that many people are using these systems—for instance, Google’s online translation
    system (and every other online service we are aware of) is based on deep learning.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些问题，深度学习在自然语言处理中有许多应用：可以用来将文本从一种语言翻译成另一种语言，将长篇文档总结为更快消化的内容，找到感兴趣概念的所有提及等。不幸的是，翻译或总结可能包含完全错误的信息！然而，性能已经足够好，许多人正在使用这些系统——例如，谷歌的在线翻译系统（以及我们所知道的每个其他在线服务）都是基于深度学习的。
- en: Combining text and images
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 结合文本和图像
- en: 'The ability of deep learning to combine text and images into a single model
    is, generally, far better than most people intuitively expect. For example, a
    deep learning model can be trained on input images with output captions written
    in English, and can learn to generate surprisingly appropriate captions automatically
    for new images! But again, we have the same warning that we discussed in the previous
    section: there is no guarantee that these captions will be correct.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习将文本和图像结合成一个单一模型的能力通常比大多数人直觉期望的要好得多。例如，一个深度学习模型可以在输入图像上进行训练，输出用英语编写的标题，并且可以学会为新图像自动生成令人惊讶地适当的标题！但是，我们再次提出与前一节讨论的相同警告：不能保证这些标题是正确的。
- en: Because of this serious issue, we generally recommend that deep learning be
    used not as an entirely automated process, but as part of a process in which the
    model and a human user interact closely. This can potentially make humans orders
    of magnitude more productive than they would be with entirely manual methods,
    and result in more accurate processes than using a human alone.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个严重问题，我们通常建议深度学习不要作为完全自动化的过程，而是作为模型和人类用户密切互动的过程的一部分。这可能使人类的生产力比完全手动方法高出几个数量级，并且比仅使用人类更准确。
- en: For instance, an automatic system can be used to identify potential stroke victims
    directly from CT scans, and send a high-priority alert to have those scans looked
    at quickly. There is only a three-hour window to treat strokes, so this fast feedback
    loop could save lives. At the same time, however, all scans could continue to
    be sent to radiologists in the usual way, so there would be no reduction in human
    input. Other deep learning models could automatically measure items seen on the
    scans and insert those measurements into reports, warning the radiologists about
    findings that they may have missed and telling them about other cases that might
    be relevant.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，自动系统可以直接从CT扫描中识别潜在的中风患者，并发送高优先级警报，以便快速查看这些扫描。治疗中风只有三个小时的时间窗口，因此这种快速的反馈循环可以挽救生命。同时，所有扫描仍然可以按照通常的方式发送给放射科医生，因此不会减少人类的参与。其他深度学习模型可以自动测量扫描中看到的物品，并将这些测量结果插入报告中，警告放射科医生可能错过的发现，并告诉他们可能相关的其他病例。
- en: Tabular data
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 表格数据
- en: For analyzing time series and tabular data, deep learning has recently been
    making great strides. However, deep learning is generally used as part of an ensemble
    of multiple types of model. If you already have a system that is using random
    forests or gradient boosting machines (popular tabular modeling tools that you
    will learn about soon), then switching to or adding deep learning may not result
    in any dramatic improvement.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分析时间序列和表格数据，深度学习最近取得了巨大进展。然而，深度学习通常作为多种模型集成的一部分使用。如果您已经有一个正在使用随机森林或梯度提升机（流行的表格建模工具，您很快将了解）的系统，那么切换到或添加深度学习可能不会带来任何显著的改进。
- en: Deep learning does greatly increase the variety of columns that you can include—for
    example, columns containing natural language (book titles, reviews, etc.) and
    high-cardinality categorical columns (i.e., something that contains a large number
    of discrete choices, such as zip code or product ID). On the down side, deep learning
    models generally take longer to train than random forests or gradient boosting
    machines, although this is changing thanks to libraries such as [RAPIDS](https://rapids.ai),
    which provides GPU acceleration for the whole modeling pipeline. We cover the
    pros and cons of all these methods in detail in [Chapter 9](ch09.xhtml#chapter_tabular).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习确实大大增加了您可以包含的列的种类——例如，包含自然语言（书名、评论等）和高基数分类列（即包含大量离散选择的内容，如邮政编码或产品ID）。不过，与随机森林或梯度提升机相比，深度学习模型通常需要更长的训练时间，尽管由于提供GPU加速的库（如[RAPIDS](https://rapids.ai)），情况正在改变。我们在[第9章](ch09.xhtml#chapter_tabular)中详细介绍了所有这些方法的优缺点。
- en: Recommendation systems
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 推荐系统
- en: Recommendation systems are really just a special type of tabular data. In particular,
    they generally have a high-cardinality categorical variable representing users,
    and another one representing products (or something similar). A company like Amazon
    represents every purchase that has ever been made by its customers as a giant
    sparse matrix, with customers as the rows and products as the columns. Once they
    have the data in this format, data scientists apply some form of collaborative
    filtering to *fill in the matrix*. For example, if customer A buys products 1
    and 10, and customer B buys products 1, 2, 4, and 10, the engine will recommend
    that A buy 2 and 4.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 推荐系统实际上只是一种特殊类型的表格数据。特别是，它们通常具有代表用户的高基数分类变量，以及代表产品（或类似物品）的另一个变量。像亚马逊这样的公司将客户所做的每一次购买都表示为一个巨大的稀疏矩阵，其中客户是行，产品是列。一旦他们以这种格式拥有数据，数据科学家们会应用某种形式的协同过滤来*填充矩阵*。例如，如果客户A购买产品1和10，客户B购买产品1、2、4和10，引擎将推荐A购买2和4。
- en: Because deep learning models are good at handling high-cardinality categorical
    variables, they are quite good at handling recommendation systems. They particularly
    come into their own, just like for tabular data, when combining these variables
    with other kinds of data, such as natural language or images. They can also do
    a good job of combining all of these types of information with additional metadata
    represented as tables, such as user information, previous transactions, and so
    forth.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 由于深度学习模型擅长处理高基数分类变量，它们非常擅长处理推荐系统。尤其是当将这些变量与其他类型的数据（如自然语言或图像）结合时，它们就像处理表格数据一样发挥作用。它们还可以很好地将所有这些类型的信息与其他元数据（如用户信息、先前交易等）表示为表格进行组合。
- en: However, nearly all machine learning approaches have the downside that they
    tell you only which products a particular user might like, rather than what recommendations
    would be helpful for a user. Many kinds of recommendations for products a user
    might like may not be at all helpful—for instance, if the user is already familiar
    with the products, or if they are simply different packagings of products they
    have already purchased (such as a boxed set of novels, when they already have
    each of the items in that set). Jeremy likes reading books by Terry Pratchett,
    and for a while Amazon was recommending nothing but Terry Pratchett books to him
    (see [Figure 2-1](#pratchett)), which really wasn’t helpful because he was already
    aware of these books!
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，几乎所有的机器学习方法都有一个缺点，那就是它们只告诉你一个特定用户可能喜欢哪些产品，而不是对用户有用的推荐。用户可能喜欢的产品的许多种推荐可能根本不会有任何帮助——例如，如果用户已经熟悉这些产品，或者如果它们只是用户已经购买过的产品的不同包装（例如，当他们已经拥有该套装中的每一件物品时，推荐一个小说的套装）。Jeremy喜欢读特里·普拉切特的书，有一段时间亚马逊一直在向他推荐特里·普拉切特的书（见[图2-1](#pratchett)），这实际上并不是有用的，因为他已经知道这些书了！
- en: '![Terry Pratchett books recommendation](Images/dlcf_0201.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![特里·普拉切特的书推荐](Images/dlcf_0201.png)'
- en: Figure 2-1\. A not-so-useful recommendation
  id: totrans-44
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-1. 一个不太有用的推荐
- en: Other data types
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 其他数据类型
- en: Often you will find that domain-specific data types fit very nicely into existing
    categories. For instance, protein chains look a lot like natural language documents,
    in that they are long sequences of discrete tokens with complex relationships
    and meaning throughout the sequence. And indeed, it does turn out that using NLP
    deep learning methods is the current state-of-the-art approach for many types
    of protein analysis. As another example, sounds can be represented as spectrograms,
    which can be treated as images; standard deep learning approaches for images turn
    out to work really well on spectrograms.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，您会发现特定领域的数据类型非常适合现有的类别。例如，蛋白质链看起来很像自然语言文档，因为它们是由复杂关系和意义贯穿整个序列的离散令牌组成的长序列。事实上，使用NLP深度学习方法是许多类型蛋白质分析的最先进方法。另一个例子，声音可以表示为频谱图，可以被视为图像；标准的图像深度学习方法在频谱图上表现得非常好。
- en: The Drivetrain Approach
  id: totrans-47
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 驱动系统方法
- en: Many accurate models are of no use to anyone, and many inaccurate models are
    highly useful. To ensure that your modeling work is useful in practice, you need
    to consider how your work will be used. In 2012, Jeremy, along with Margit Zwemer
    and Mike Loukides, introduced a method called *the Drivetrain Approach* for thinking
    about this issue.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 许多准确的模型对任何人都没有用，而许多不准确的模型却非常有用。为了确保您的建模工作在实践中有用，您需要考虑您的工作将如何使用。2012年，Jeremy与Margit
    Zwemer和Mike Loukides一起提出了一种称为*驱动系统方法*的思考这个问题的方法。
- en: The Drivetrain Approach, illustrated in [Figure 2-2](#drivetrain), was described
    in detail in [“Designing Great Data Products”](https://oreil.ly/KJIIa). The basic
    idea is to start with considering your objective, then think about what actions
    you can take to meet that objective and what data you have (or can acquire) that
    can help, and then build a model that you can use to determine the best actions
    to take to get the best results in terms of your objective.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 驱动系统方法，如[图2-2](#drivetrain)所示，详细介绍在[“设计出色的数据产品”](https://oreil.ly/KJIIa)中。基本思想是从考虑您的目标开始，然后考虑您可以采取哪些行动来实现该目标以及您拥有的（或可以获取的）可以帮助的数据，然后构建一个模型，您可以使用该模型确定为实现目标而采取的最佳行动。
- en: '![](Images/dlcf_0202.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_0202.png)'
- en: Figure 2-2\. The Drivetrain Approach
  id: totrans-51
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-2. 驱动系统方法
- en: 'Consider a model in an autonomous vehicle: you want to help a car drive safely
    from point A to point B without human intervention. Great predictive modeling
    is an important part of the solution, but it doesn’t stand on its own; as products
    become more sophisticated, it disappears into the plumbing. Someone using a self-driving
    car is completely unaware of the hundreds (if not thousands) of models and the
    petabytes of data that make it work. But as data scientists build increasingly
    sophisticated products, they need a systematic design approach.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑自动驾驶汽车中的模型：您希望帮助汽车安全地从A点驾驶到B点，而无需人为干预。出色的预测建模是解决方案的重要组成部分，但它并不是独立存在的；随着产品变得更加复杂，它会消失在管道中。使用自动驾驶汽车的人完全不知道使其运行的数百（甚至数千）个模型和海量数据。但随着数据科学家构建越来越复杂的产品，他们需要一种系统化的设计方法。
- en: We use data not just to generate more data (in the form of predictions), but
    to produce *actionable outcomes*. That is the goal of the Drivetrain Approach.
    Start by defining a clear *objective*. For instance, Google, when creating its
    first search engine, considered “What is the user’s main objective in typing in
    a search query?” This led to Google’s objective, which was to “show the most relevant
    search result.” The next step is to consider what *levers* you can pull (i.e., what
    actions you can take) to better achieve that objective. In Google’s case, that
    was the ranking of the search results. The third step was to consider what new
    *data* they would need to produce such a ranking; they realized that the implicit
    information regarding which pages linked to which other pages could be used for
    this purpose.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用数据不仅仅是为了生成更多数据（以预测的形式），而是为了产生可操作的结果。这是Drivetrain方法的目标。首先要明确定义一个明确的目标。例如，当谷歌创建其第一个搜索引擎时，考虑了“用户在输入搜索查询时的主要目标是什么？”这导致了谷歌的目标，即“显示最相关的搜索结果”。下一步是考虑您可以拉动的杠杆（即您可以采取的行动）以更好地实现该目标。在谷歌的情况下，这是搜索结果的排名。第三步是考虑他们需要什么新数据来生成这样的排名；他们意识到关于哪些页面链接到哪些其他页面的隐含信息可以用于此目的。
- en: Only after these first three steps do we begin thinking about building the predictive
    *models*. Our objective and available levers, what data we already have and what
    additional data we will need to collect, determine the models we can build. The
    models will take both the levers and any uncontrollable variables as their inputs;
    the outputs from the models can be combined to predict the final state for our
    objective.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 只有在完成了这前三个步骤之后，我们才开始考虑构建预测模型。我们的目标和可用的杠杆，我们已经拥有的数据以及我们需要收集的额外数据，决定了我们可以构建的模型。这些模型将以杠杆和任何不可控变量作为输入；模型的输出可以结合起来预测我们的目标的最终状态。
- en: 'Let’s consider another example: recommendation systems. The *objective* of
    a recommendation engine is to drive additional sales by surprising and delighting
    the customer with recommendations of items they would not have purchased without
    the recommendation. The *lever* is the ranking of the recommendations. New *data*
    must be collected to generate recommendations that will *cause new sales*. This
    will require conducting many randomized experiments in order to collect data about
    a wide range of recommendations for a wide range of customers. This is a step
    that few organizations take; but without it, you don’t have the information you
    need to optimize recommendations based on your true objective (more sales!).'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑另一个例子：推荐系统。推荐引擎的目标是通过推荐客户不会在没有推荐的情况下购买的物品来推动额外的销售。杠杆是推荐的排名。必须收集新数据以生成将导致新销售的推荐。这将需要进行许多随机实验，以收集关于各种客户的各种推荐的数据。这是很少有组织采取的一步；但是没有它，您就没有所需的信息来根据您的真正目标（更多销售！）优化推荐。
- en: Finally, you could build two *models* for purchase probabilities, conditional
    on seeing or not seeing a recommendation. The difference between these two probabilities
    is a utility function for a given recommendation to a customer. It will be low
    in cases where the algorithm recommends a familiar book that the customer has
    already rejected (both components are small) or a book that they would have bought
    even without the recommendation (both components are large and cancel each other
    out).
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以为购买概率构建两个模型，条件是看到或没有看到推荐。这两个概率之间的差异是给定推荐给客户的效用函数。在算法推荐客户已经拒绝的熟悉书籍（两个组成部分都很小）或者他们本来就会购买的书籍（两个组成部分都很大并互相抵消）的情况下，效用函数会很低。
- en: As you can see, in practice often the practical implementation of your models
    will require a lot more than just training a model! You’ll often need to run experiments
    to collect more data, and consider how to incorporate your models into the overall
    system you’re developing. Speaking of data, let’s now focus on how to find data
    for your project.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您所看到的，在实践中，您的模型的实际实施通常需要比仅仅训练一个模型更多！您通常需要运行实验来收集更多数据，并考虑如何将您的模型整合到您正在开发的整个系统中。说到数据，现在让我们专注于如何为您的项目找到数据。
- en: Gathering Data
  id: totrans-58
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 收集数据
- en: 'For many types of projects, you may be able to find all the data you need online.
    The project we’ll be completing in this chapter is a *bear detector*. It will
    discriminate between three types of bear: grizzly, black, and teddy bears. There
    are many images on the internet of each type of bear that we can use. We just
    need a way to find them and download them.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多类型的项目，您可能能够在线找到所需的所有数据。本章中我们将完成的项目是一个“熊探测器”。它将区分三种类型的熊：灰熊、黑熊和泰迪熊。互联网上有许多每种类型熊的图片可供我们使用。我们只需要找到它们并下载它们。
- en: We’ve provided a tool you can use for this purpose, so you can follow along
    with this chapter and create your own image recognition application for whatever
    kinds of objects you’re interested in. In the fast.ai course, thousands of students
    have presented their work in the course forums, displaying everything from hummingbird
    varieties in Trinidad to bus types in Panama—one student even created an application
    that would help his fiancée recognize his 16 cousins during Christmas vacation!
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了一个工具供您使用，这样您就可以跟随本章并为您感兴趣的任何对象创建自己的图像识别应用程序。在fast.ai课程中，成千上万的学生在课程论坛上展示了他们的作品，展示了从特立尼达的蜂鸟品种到巴拿马的公交车类型的一切——甚至有一名学生创建了一个应用程序，可以帮助他的未婚妻在圣诞假期期间认出他的16个表兄弟！
- en: At the time of writing, Bing Image Search is the best option we know of for
    finding and downloading images. It’s free for up to 1,000 queries per month, and
    each query can download up to 150 images. However, something better might have
    come along between when we wrote this and when you’re reading the book, so be
    sure to check out this [book’s website](https://book.fast.ai) for our current
    recommendation.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，Bing图像搜索是我们知道的用于查找和下载图像的最佳选择。每月免费提供最多1,000次查询，每次查询可下载最多150张图片。然而，在我们撰写本书时和您阅读本书时之间可能会出现更好的选择，因此请务必查看本[书籍网站](https://book.fast.ai)以获取我们当前的推荐。
- en: Keeping in Touch with the Latest Services
  id: totrans-62
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与最新服务保持联系
- en: Services that can be used for creating datasets come and go all the time, and
    their features, interfaces, and pricing change regularly too. In this section,
    we’ll show how to use the [Bing Image Search API](https://oreil.ly/P8VtT) available
    as part of Azure Cognitive Services at the time this book was written.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 用于创建数据集的服务时常变化，它们的功能、接口和定价也经常变化。在本节中，我们将展示如何在撰写本书时作为Azure认知服务一部分提供的[Bing图像搜索API](https://oreil.ly/P8VtT)。
- en: 'To download images with Bing Image Search, sign up at Microsoft for a free
    account. You will be given a key, which you can copy and enter in a cell as follows
    (replacing *`XXX`* with your key and executing it):'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用Bing图像搜索下载图像，请在Microsoft注册一个免费帐户。您将获得一个密钥，您可以将其复制并输入到一个单元格中（用您的密钥替换*`XXX`*并执行）：
- en: '[PRE0]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Or, if you’re comfortable at the command line, you can set it in your terminal
    with
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果您在命令行上感到自在，您可以在终端中设置它
- en: '[PRE1]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'and then restart the Jupyter server, type this in a cell, and execute it:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然后重新启动Jupyter服务器，在一个单元格中键入以下内容，并执行：
- en: '[PRE2]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Once you’ve set `key`, you can use `search_images_bing`. This function is provided
    by the small `utils` class included with the notebooks online (if you’re not sure
    where a function is defined, you can just type it in your notebook to find out,
    as shown here):'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 设置了`key`之后，您可以使用`search_images_bing`。这个函数是在线笔记本中包含的小`utils`类提供的（如果您不确定一个函数是在哪里定义的，您可以在笔记本中输入它来找出，如下所示）：
- en: '[PRE3]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let’s try this function out:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试一下这个函数：
- en: '[PRE5]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'We’ve successfully downloaded the URLs of 150 grizzly bears (or, at least,
    images that Bing Image Search finds for that search term). Let’s look at one:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已成功下载了150只灰熊的URL（或者至少是Bing图像搜索为该搜索词找到的图像）。让我们看一个：
- en: '[PRE7]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](Images/dlcf_02in01.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_02in01.png)'
- en: 'This seems to have worked nicely, so let’s use fastai’s `download_images` to
    download all the URLs for each of our search terms. We’ll put each in a separate
    folder:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这似乎运行得很好，所以让我们使用fastai的`download_images`来下载每个搜索词的所有URL。我们将每个放在一个单独的文件夹中：
- en: '[PRE9]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Our folder has image files, as we’d expect:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的文件夹中有图像文件，正如我们所期望的那样：
- en: '[PRE11]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Jeremy Says
  id: totrans-86
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Jeremy说
- en: I just love this about working in Jupyter notebooks! It’s so easy to gradually
    build what I want, and check my work every step of the way. I make a *lot* of
    mistakes, so this is really helpful to me.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我就是喜欢在Jupyter笔记本中工作的这一点！逐步构建我想要的东西并在每一步检查我的工作是如此容易。我犯了*很多*错误，所以这对我真的很有帮助。
- en: 'Often when we download files from the internet, a few are corrupt. Let’s check:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 通常当我们从互联网下载文件时，会有一些文件损坏。让我们检查一下：
- en: '[PRE13]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'To remove all the failed images, you can use `unlink`. Like most fastai functions
    that return a collection, `verify_images` returns an object of type `L`, which
    includes the `map` method. This calls the passed function on each element of the
    collection:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除所有失败的图像，您可以使用`unlink`。像大多数返回集合的fastai函数一样，`verify_images`返回一个类型为`L`的对象，其中包括`map`方法。这会在集合的每个元素上调用传递的函数：
- en: '[PRE15]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'One thing to be aware of in this process: as we discussed in [Chapter 1](ch01.xhtml#chapter_intro),
    models can reflect only the data used to train them. And the world is full of
    biased data, which ends up reflected in, for example, Bing Image Search (which
    we used to create our dataset). For instance, let’s say you were interested in
    creating an app that could help users figure out whether they had healthy skin,
    so you trained a model on the results of searches for (say) “healthy skin.” [Figure 2-3](#healthy_skin)
    shows you kind of the results you would get.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个过程中要注意的一件事是：正如我们在[第1章](ch01.xhtml#chapter_intro)中讨论的，模型只能反映用于训练它们的数据。而世界充满了有偏见的数据，这最终会反映在，例如，Bing图像搜索（我们用来创建数据集的）。例如，假设您有兴趣创建一个应用程序，可以帮助用户确定他们是否拥有健康的皮肤，因此您训练了一个模型，该模型基于搜索结果（比如）“健康皮肤”。[图2-3](#healthy_skin)展示了您将获得的结果类型。
- en: '![](Images/dlcf_0203.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_0203.png)'
- en: Figure 2-3\. Data for a healthy skin detector?
  id: totrans-95
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-3\. 用于健康皮肤检测器的数据？
- en: 'With this as your training data, you would end up not with a healthy skin detector,
    but a *young white woman touching her face* detector! Be sure to think carefully
    about the types of data that you might expect to see in practice in your application,
    and check carefully to ensure that all these types are reflected in your model’s
    source data. (Thanks to Deb Raji, who came up with the healthy skin example. See
    her paper [“Actionable Auditing: Investigating the Impact of Publicly Naming Biased
    Performance Results of Commercial AI Products”](https://oreil.ly/POS_C) for more
    fascinating insights into model bias.)'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 使用此作为训练数据，您最终不会得到一个健康皮肤检测器，而是一个*年轻白人女性触摸她的脸*检测器！一定要仔细考虑您可能在应用程序中实际看到的数据类型，并仔细检查以确保所有这些类型都反映在您模型的源数据中。（感谢Deb
    Raji提出了健康皮肤的例子。请查看她的论文[“可操作的审计：调查公开命名商业AI产品偏见性能结果的影响”](https://oreil.ly/POS_C)以获取更多有关模型偏见的迷人见解。）
- en: Now that we have downloaded some data, we need to assemble it in a format suitable
    for model training. In fastai, that means creating an object called `DataLoaders`.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经下载了一些数据，我们需要将其组装成适合模型训练的格式。在fastai中，这意味着创建一个名为`DataLoaders`的对象。
- en: From Data to DataLoaders
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从数据到数据加载器
- en: '`DataLoaders` is a thin class that just stores whatever `DataLoader` objects
    you pass to it and makes them available as `train` and `valid`. Although it’s
    a simple class, it’s important in fastai: it provides the data for your model.
    The key functionality in `DataLoaders` is provided with just these four lines
    of code (it has some other minor functionality we’ll skip over for now):'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`DataLoaders`是一个简单的类，只是存储您传递给它的`DataLoader`对象，并将它们作为`train`和`valid`可用。尽管它是一个简单的类，但在fastai中非常重要：它为您的模型提供数据。`DataLoaders`中的关键功能仅用这四行代码提供（它还有一些其他次要功能我们暂时跳过）：'
- en: '[PRE16]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Jargon: DataLoaders'
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 术语：DataLoaders
- en: A fastai class that stores multiple `DataLoader` objects you pass to it—normally
    a `train` and a `valid`, although it’s possible to have as many as you like. The
    first two are made available as properties.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 一个fastai类，存储您传递给它的多个`DataLoader`对象——通常是一个`train`和一个`valid`，尽管可以有任意数量。前两个作为属性提供。
- en: 'Later in the book, you’ll also learn about the `Dataset` and `Datasets` classes,
    which have the same relationship. To turn our downloaded data into a `DataLoaders`
    object, we need to tell fastai at least four things:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的后面，您还将了解`Dataset`和`Datasets`类，它们具有相同的关系。要将我们下载的数据转换为`DataLoaders`对象，我们至少需要告诉fastai四件事：
- en: What kinds of data we are working with
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们正在处理什么类型的数据
- en: How to get the list of items
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何获取项目列表
- en: How to label these items
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何为这些项目打标签
- en: How to create the validation set
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何创建验证集
- en: 'So far we have seen a number of *factory methods* for particular combinations
    of these things, which are convenient when you have an application and data structure
    that happen to fit into those predefined methods. For when you don’t, fastai has
    an extremely flexible system called the *data block API*. With this API, you can
    fully customize every stage of the creation of your `DataLoaders`. Here is what
    we need to create a `DataLoaders` for the dataset that we just downloaded:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看到了一些特定组合的*工厂方法*，当您有一个应用程序和数据结构恰好适合这些预定义方法时，这些方法非常方便。当您不适用时，fastai有一个名为*数据块API*的极其灵活的系统。使用此API，您可以完全自定义创建`DataLoaders`的每个阶段。这是我们需要为刚刚下载的数据集创建`DataLoaders`的步骤：
- en: '[PRE17]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Let’s look at each of these arguments in turn. First we provide a tuple specifying
    the types we want for the independent and dependent variables:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们依次查看每个参数。首先，我们提供一个元组，指定我们希望独立变量和因变量的类型：
- en: '[PRE18]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The *independent variable* is the thing we are using to make predictions from,
    and the *dependent variable* is our target. In this case, our independent variable
    is a set of images, and our dependent variables are the categories (type of bear)
    for each image. We will see many other types of block in the rest of this book.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '*独立变量*是我们用来进行预测的东西，*因变量*是我们的目标。在这种情况下，我们的独立变量是一组图像，我们的因变量是每个图像的类别（熊的类型）。在本书的其余部分中，我们将看到许多其他类型的块。'
- en: 'For this `DataLoaders`, our underlying items will be file paths. We have to
    tell fastai how to get a list of those files. The `get_image_files` function takes
    a path, and returns a list of all of the images in that path (recursively, by
    default):'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个`DataLoaders`，我们的基础项目将是文件路径。我们必须告诉fastai如何获取这些文件的列表。`get_image_files`函数接受一个路径，并返回该路径中所有图像的列表（默认情况下递归）：
- en: '[PRE19]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Often, datasets that you download will already have a validation set defined.
    Sometimes this is done by placing the images for the training and validation sets
    into different folders. Sometimes it is done by providing a CSV file in which
    each filename is listed along with which dataset it should be in. There are many
    ways that this can be done, and fastai provides a general approach that allows
    you to use one of its predefined classes for this or to write your own.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，您下载的数据集已经定义了验证集。有时，这是通过将用于训练和验证集的图像放入不同的文件夹中来完成的。有时，这是通过提供一个CSV文件，在该文件中，每个文件名都与应该在其中的数据集一起列出。有许多可以完成此操作的方法，fastai提供了一种通用方法，允许您使用其预定义类之一或编写自己的类。
- en: In this case, we want to split our training and validation sets randomly. However,
    we would like to have the same training/validation split each time we run this
    notebook, so we fix the random seed (computers don’t really know how to create
    random numbers at all, but simply create lists of numbers that look random; if
    you provide the same starting point for that list each time—called the *seed*—then
    you will get the exact same list each time).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们希望随机拆分我们的训练和验证集。但是，我们希望每次运行此笔记本时都具有相同的训练/验证拆分，因此我们固定随机种子（计算机实际上不知道如何创建随机数，而只是创建看起来随机的数字列表；如果您每次都为该列表提供相同的起始点——称为*种子*，那么您将每次都获得完全相同的列表）。
- en: '[PRE20]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The independent variable is often referred to as `x`, and the dependent variable
    is often referred to as `y`. Here, we are telling fastai what function to call
    to create the labels in our dataset:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '`parent_label` is a function provided by fastai that simply gets the name of
    the folder a file is in. Because we put each of our bear images into folders based
    on the type of bear, this is going to give us the labels that we need.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: 'Our images are all different sizes, and this is a problem for deep learning:
    we don’t feed the model one image at a time but several of them (what we call
    a *mini-batch*). To group them in a big array (usually called a *tensor*) that
    is going to go through our model, they all need to be of the same size. So, we
    need to add a transform that will resize these images to the same size. *Item
    transforms* are pieces of code that run on each individual item, whether it be
    an image, category, or so forth. fastai includes many predefined transforms; we
    use the `Resize` transform here and specify a size of 128 pixels:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'This command has given us a `DataBlock` object. This is like a *template* for
    creating a `DataLoaders`. We still need to tell fastai the actual source of our
    data—in this case, the path where the images can be found:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'A `DataLoaders` includes validation and training `DataLoader`s. A `DataLoader`
    is a class that provides batches of a few items at a time to the GPU. We’ll be
    learning a lot more about this class in the next chapter. When you loop through
    a `DataLoader`, fastai will give you 64 (by default) items at a time, all stacked
    up into a single tensor. We can take a look at a few of those items by calling
    the `show_batch` method on a `DataLoader`:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '![](Images/dlcf_02in02.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
- en: 'By default, `Resize` *crops* the images to fit a square shape of the size requested,
    using the full width or height. This can result in losing some important details.
    Alternatively, you can ask fastai to pad the images with zeros (black), or squish/stretch
    them:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '![](Images/dlcf_02in03.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
- en: '[PRE26]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '![](Images/dlcf_02in04.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
- en: All of these approaches seem somewhat wasteful or problematic. If we squish
    or stretch the images, they end up as unrealistic shapes, leading to a model that
    learns that things look different from how they actually are, which we would expect
    to result in lower accuracy. If we crop the images, we remove some of the features
    that allow us to perform recognition. For instance, if we were trying to recognize
    breeds of dog or cat, we might end up cropping out a key part of the body or the
    face necessary to distinguish between similar breeds. If we pad the images, we
    have a whole lot of empty space, which is just wasted computation for our model
    and results in a lower effective resolution for the part of the image we actually
    use.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead, what we normally do in practice is to randomly select part of the
    image and then crop to just that part. On each epoch (which is one complete pass
    through all of our images in the dataset), we randomly select a different part
    of each image. This means that our model can learn to focus on, and recognize,
    different features in our images. It also reflects how images work in the real
    world: different photos of the same thing may be framed in slightly different
    ways.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: In fact, an entirely untrained neural network knows nothing whatsoever about
    how images behave. It doesn’t even recognize that when an object is rotated by
    one degree, it still is a picture of the same thing! So training the neural network
    with examples of images in which the objects are in slightly different places
    and are slightly different sizes helps it to understand the basic concept of what
    an object is, and how it can be represented in an image.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is another example where we replace `Resize` with `RandomResizedCrop`,
    which is the transform that provides the behavior just described. The most important
    parameter to pass in is `min_scale`, which determines how much of the image to
    select at minimum each time:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '![](Images/dlcf_02in05.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_02in05.png)'
- en: Here, we used `unique=True` to have the same image repeated with different versions
    of this `RandomResizedCrop` transform.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用了`unique=True`，以便将相同图像重复使用不同版本的`RandomResizedCrop`变换。
- en: '`RandomResizedCrop` is a specific example of a more general technique, called
    data augmentation.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '`RandomResizedCrop`是更一般的数据增强技术的一个具体示例。'
- en: Data Augmentation
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据增强
- en: '*Data augmentation* refers to creating random variations of our input data,
    such that they appear different but do not change the meaning of the data. Examples
    of common data augmentation techniques for images are rotation, flipping, perspective
    warping, brightness changes, and contrast changes. For natural photo images such
    as the ones we are using here, a standard set of augmentations that we have found
    work pretty well are provided with the `aug_transforms` function.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '*数据增强*指的是创建输入数据的随机变化，使它们看起来不同但不改变数据的含义。对于图像的常见数据增强技术包括旋转、翻转、透视变形、亮度变化和对比度变化。对于我们在这里使用的自然照片图像，我们发现一组标准的增强技术与`aug_transforms`函数一起提供，效果非常好。'
- en: 'Because our images are now all the same size, we can apply these augmentations
    to an entire batch of them using the GPU, which will save a lot of time. To tell
    fastai we want to use these transforms on a batch, we use the `batch_tfms` parameter
    (note that we’re not using `RandomResizedCrop` in this example, so you can see
    the differences more clearly; we’re also using double the amount of augmentation
    compared to the default, for the same reason):'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们的图像现在都是相同大小，我们可以使用GPU将这些增强应用于整个批次的图像，这将节省大量时间。要告诉fastai我们要在批次上使用这些变换，我们使用`batch_tfms`参数（请注意，在此示例中我们没有使用`RandomResizedCrop`，这样您可以更清楚地看到差异；出于同样的原因，我们使用了默认值的两倍的增强量）：
- en: '[PRE28]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '![](Images/dlcf_02in06.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_02in06.png)'
- en: Now that we have assembled our data in a format fit for model training, let’s
    train an image classifier using it.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将数据组装成适合模型训练的格式，让我们使用它来训练一个图像分类器。
- en: Training Your Model, and Using It to Clean Your Data
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 训练您的模型，并使用它来清理您的数据
- en: 'Time to use the same lines of code as in [Chapter 1](ch01.xhtml#chapter_intro)
    to train our bear classifier. We don’t have a lot of data for our problem (150
    pictures of each sort of bear at most), so to train our model, we’ll use `RandomResizedCrop`,
    an image size of 224 pixels, which is fairly standard for image classification,
    and the default `aug_transforms`:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候使用与[第1章](ch01.xhtml#chapter_intro)中相同的代码行来训练我们的熊分类器了。对于我们的问题，我们没有太多的数据（每种熊最多150张图片），因此为了训练我们的模型，我们将使用`RandomResizedCrop`，图像大小为224像素，这对于图像分类来说是相当标准的，并且使用默认的`aug_transforms`：
- en: '[PRE29]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We can now create our `Learner` and fine-tune it in the usual way:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以按照通常的方式创建我们的`Learner`并进行微调：
- en: '[PRE30]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '| epoch | train_loss | valid_loss | error_rate | time |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| epoch | train_loss | valid_loss | error_rate | time |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 1.235733 | 0.212541 | 0.087302 | 00:05 |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 1.235733 | 0.212541 | 0.087302 | 00:05 |'
- en: '| epoch | train_loss | valid_loss | error_rate | time |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| epoch | train_loss | valid_loss | error_rate | time |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 0 | 0.213371 | 0.112450 | 0.023810 | 00:05 |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 0.213371 | 0.112450 | 0.023810 | 00:05 |'
- en: '| 1 | 0.173855 | 0.072306 | 0.023810 | 00:06 |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 0.173855 | 0.072306 | 0.023810 | 00:06 |'
- en: '| 2 | 0.147096 | 0.039068 | 0.015873 | 00:06 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 0.147096 | 0.039068 | 0.015873 | 00:06 |'
- en: '| 3 | 0.123984 | 0.026801 | 0.015873 | 00:06 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 0.123984 | 0.026801 | 0.015873 | 00:06 |'
- en: 'Now let’s see whether the mistakes the model is making are mainly thinking
    that grizzlies are teddies (that would be bad for safety!), or that grizzlies
    are black bears, or something else. To visualize this, we can create a *confusion
    matrix*:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看模型犯的错误主要是认为灰熊是泰迪熊（这对安全性来说是不好的！），还是认为灰熊是黑熊，或者其他情况。为了可视化这一点，我们可以创建一个*混淆矩阵*：
- en: '[PRE31]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '![](Images/dlcf_02in07.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_02in07.png)'
- en: The rows represent all the black, grizzly, and teddy bears in our dataset, respectively.
    The columns represent the images that the model predicted as black, grizzly, and
    teddy bears, respectively. Therefore, the diagonal of the matrix shows the images
    that were classified correctly, and the off-diagonal cells represent those that
    were classified incorrectly. This is one of the many ways that fastai allows you
    to view the results of your model. It is (of course!) calculated using the validation
    set. With the color-coding, the goal is to have white everywhere except the diagonal,
    where we want dark blue. Our bear classifier isn’t making many mistakes!
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 行代表数据集中所有黑色、灰熊和泰迪熊，列分别代表模型预测为黑色、灰熊和泰迪熊的图像。因此，矩阵的对角线显示了被正确分类的图像，而非对角线的单元格代表被错误分类的图像。这是fastai允许您查看模型结果的许多方式之一。当然，这是使用验证集计算的。通过颜色编码，目标是在对角线以外的地方都是白色，而在对角线上我们希望是深蓝色。我们的熊分类器几乎没有犯错！
- en: It’s helpful to see where exactly our errors are occurring, to see whether they’re
    due to a dataset problem (e.g., images that aren’t bears at all, or are labeled
    incorrectly) or a model problem (perhaps it isn’t handling images taken with unusual
    lighting, or from a different angle, etc.). To do this, we can sort our images
    by their loss.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 看到我们的错误发生在哪里是有帮助的，以便确定它们是由数据集问题（例如，根本不是熊的图像，或者标记错误）还是模型问题（也许它无法处理使用不同光照或从不同角度拍摄的图像等）。为了做到这一点，我们可以根据损失对图像进行排序。
- en: 'The *loss* is a number that is higher if the model is incorrect (especially
    if it’s also confident of its incorrect answer), or if it’s correct but not confident
    of its correct answer. In the beginning of [Part II](part02.xhtml#part2), we’ll
    learn in depth how loss is calculated and used in the training process. For now,
    `plot_top_losses` shows us the images with the highest loss in our dataset. As
    the title of the output says, each image is labeled with four things: prediction,
    actual (target label), loss, and probability. The *probability* here is the confidence
    level, from zero to one, that the model has assigned to its prediction:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '*损失*是一个数字，如果模型不正确（尤其是如果它对其不正确的答案也很自信），或者如果它是正确的但对其正确答案不自信，那么损失就会更高。在[第二部分](part02.xhtml#part2)的开头，我们将深入学习损失是如何计算和在训练过程中使用的。现在，`plot_top_losses`向我们展示了数据集中损失最高的图像。正如输出的标题所说，每个图像都标有四个内容：预测、实际（目标标签）、损失和概率。这里的*概率*是模型对其预测分配的置信水平，从零到一：'
- en: '[PRE32]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '![](Images/dlcf_02in08.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![](Images/dlcf_02in08.png)'
- en: This output shows that the image with the highest loss is one that has been
    predicted as “grizzly” with high confidence. However, it’s labeled (based on our
    Bing image search) as “black.” We’re not bear experts, but it sure looks to us
    like this label is incorrect! We should probably change its label to “grizzly.”
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这个输出显示，损失最高的图像是一个被预测为“灰熊”的图像，且置信度很高。然而，根据我们的必应图像搜索，它被标记为“黑熊”。我们不是熊专家，但在我们看来，这个标签显然是错误的！我们可能应该将其标签更改为“灰熊”。
- en: The intuitive approach to doing data cleaning is to do it *before* you train
    a model. But as you’ve seen in this case, a model can help you find data issues
    more quickly and easily. So, we normally prefer to train a quick and simple model
    first, and then use it to help us with data cleaning.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 进行数据清洗的直观方法是在*训练*模型之前进行。但正如您在本例中所看到的，模型可以帮助您更快速、更轻松地找到数据问题。因此，我们通常更喜欢先训练一个快速简单的模型，然后使用它来帮助我们进行数据清洗。
- en: 'fastai includes a handy GUI for data cleaning called `ImageClassifierCleaner`
    that allows you to choose a category and the training versus validation set and
    view the highest-loss images (in order), along with menus to allow images to be
    selected for removal or relabeling:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: fastai包括一个方便的用于数据清洗的GUI，名为`ImageClassifierCleaner`，它允许您选择一个类别和训练与验证集，并查看损失最高的图像（按顺序），以及菜单允许选择要删除或重新标记的图像：
- en: '[PRE33]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: '![Cleaner widget](Images/dlcf_02in09.png)'
  id: totrans-173
  prefs: []
  type: TYPE_IMG
  zh: '![清洁工具小部件](Images/dlcf_02in09.png)'
- en: 'We can see that among our “black bears” is an image that contains two bears:
    one grizzly, one black. So, we should choose `<Delete>` in the menu under this
    image. `ImageClassifierCleaner` doesn’t do the deleting or changing of labels
    for you; it just returns the indices of items to change. So, for instance, to
    delete (`unlink`) all images selected for deletion, we would run this:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到在我们的“黑熊”中有一张包含两只熊的图片：一只灰熊，一只黑熊。因此，我们应该在此图片下的菜单中选择`<Delete>`。`ImageClassifierCleaner`不会为您删除或更改标签；它只会返回要更改的项目的索引。因此，例如，要删除（取消链接）所有选定要删除的图像，我们将运行以下命令：
- en: '[PRE34]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'To move images for which we’ve selected a different category, we would run
    this:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 要移动我们选择了不同类别的图像，我们将运行以下命令：
- en: '[PRE35]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Sylvain Says
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Sylvain说
- en: Cleaning the data and getting it ready for your model are two of the biggest
    challenges for data scientists; they say it takes 90% of their time. The fastai
    library aims to provide tools that make it as easy as possible.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 清理数据并为您的模型做好准备是数据科学家面临的两个最大挑战；他们说这需要他们90%的时间。fastai库旨在提供尽可能简单的工具。
- en: We’ll be seeing more examples of model-driven data cleaning throughout this
    book. Once we’ve cleaned up our data, we can retrain our model. Try it yourself,
    and see if your accuracy improves!
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们将看到更多基于模型驱动的数据清洗示例。一旦我们清理了数据，我们就可以重新训练我们的模型。自己尝试一下，看看你的准确性是否有所提高！
- en: No Need for Big Data
  id: totrans-181
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不需要大数据
- en: After cleaning the dataset using these steps, we generally are seeing 100% accuracy
    on this task. We even see that result when we download a lot fewer images than
    the 150 per class we’re using here. As you can see, the common complaint that
    *you need massive amounts of data to do deep learning* can be a very long way
    from the truth!
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些步骤清理数据集后，我们通常在这个任务上看到100%的准确性。即使我们下载的图像比我们在这里使用的每类150张要少得多，我们也能看到这个结果。正如您所看到的，*您需要大量数据才能进行深度学习*的常见抱怨可能与事实相去甚远！
- en: Now that we have trained our model, let’s see how we can deploy it to be used
    in practice.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经训练了我们的模型，让我们看看如何部署它以便在实践中使用。
- en: Turning Your Model into an Online Application
  id: totrans-184
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将您的模型转化为在线应用程序
- en: We are now going to look at what it takes to turn this model into a working
    online application. We will just go as far as creating a basic working prototype;
    we do not have the scope in this book to teach you all the details of web application
    development generally.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将看看将这个模型转化为一个可工作的在线应用程序需要什么。我们将只创建一个基本的工作原型；在本书中，我们没有范围来教授您有关Web应用程序开发的所有细节。
- en: Using the Model for Inference
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用模型进行推断
- en: 'Once you’ve got a model you’re happy with, you need to save it so you can then
    copy it over to a server where you’ll use it in production. Remember that a model
    consists of two parts: the *architecture* and the trained *parameters*. The easiest
    way to save a model is to save both of these, because that way, when you load
    the model, you can be sure that you have the matching architecture and parameters.
    To save both parts, use the `export` method.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您拥有一个满意的模型，您需要保存它，以便随后将其复制到一个服务器上，在那里您将在生产中使用它。请记住，模型由两部分组成：*架构*和训练的*参数*。保存模型的最简单方法是保存这两部分，因为这样，当您加载模型时，您可以确保具有匹配的架构和参数。要保存这两部分，请使用`export`方法。
- en: This method even saves the definition of how to create your `DataLoaders`. This
    is important, because otherwise you would have to redefine how to transform your
    data in order to use your model in production. fastai automatically uses your
    validation set `DataLoader` for inference by default, so your data augmentation
    will not be applied, which is generally what you want.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法甚至保存了如何创建您的`DataLoaders`的定义。这很重要，因为否则您将不得不重新定义如何转换您的数据以便在生产中使用您的模型。fastai默认使用验证集`DataLoader`进行推理，因此不会应用数据增强，这通常是您想要的。
- en: 'When you call `export`, fastai will save a file called *export.pkl*:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 当您调用`export`时，fastai将保存一个名为*export.pkl*的文件：
- en: '[PRE36]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Let’s check that the file exists, by using the `ls` method that fastai adds
    to Python’s `Path` class:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过使用fastai添加到Python的`Path`类的`ls`方法来检查文件是否存在：
- en: '[PRE37]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: You’ll need this file wherever you deploy your app to. For now, let’s try to
    create a simple app within our notebook.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要这个文件在您部署应用程序的任何地方。现在，让我们尝试在我们的笔记本中创建一个简单的应用程序。
- en: 'When we use a model for getting predictions, instead of training, we call it
    *inference*. To create our inference learner from the exported file, we use `load_learner`
    (in this case, this isn’t really necessary, since we already have a working `Learner`
    in our notebook; we’re doing it here so you can see the whole process end to end):'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用模型进行预测而不是训练时，我们称之为*推理*。要从导出的文件创建我们的推理学习者，我们使用`load_learner`（在这种情况下，这并不是真正必要的，因为我们已经在笔记本中有一个工作的`Learner`；我们在这里这样做是为了让您看到整个过程的始终）：
- en: '[PRE39]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'When we’re doing inference, we’re generally getting predictions for just one
    image at a time. To do this, pass a filename to `predict`:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在进行推理时，通常一次只为一个图像获取预测。要做到这一点，将文件名传递给`predict`：
- en: '[PRE40]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: '[PRE41]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'This has returned three things: the predicted category in the same format you
    originally provided (in this case, that’s a string), the index of the predicted
    category, and the probabilities of each category. The last two are based on the
    order of categories in the *vocab* of the `DataLoaders`; that is, the stored list
    of all possible categories. At inference time, you can access the `DataLoaders`
    as an attribute of the `Learner`:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 这返回了三个东西：以与您最初提供的格式相同的预测类别（在本例中，这是一个字符串），预测类别的索引以及每个类别的概率。最后两个是基于`DataLoaders`的*vocab*中类别的顺序；也就是说，所有可能类别的存储列表。在推理时，您可以将`DataLoaders`作为`Learner`的属性访问：
- en: '[PRE42]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: '[PRE43]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: We can see here that if we index into the vocab with the integer returned by
    `predict`, we get back “grizzly,” as expected. Also, note that if we index into
    the list of probabilities, we see a nearly 1.00 probability that this is a grizzly.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，如果我们使用`predict`返回的整数索引到vocab中，我们会得到“灰熊”，这是预期的。另外，请注意，如果我们在概率列表中进行索引，我们会看到几乎有1.00的概率这是一只灰熊。
- en: We know how to make predictions from our saved model, so we have everything
    we need to start building our app. We can do it directly in a Jupyter notebook.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道如何从保存的模型中进行预测，因此我们拥有开始构建我们的应用程序所需的一切。我们可以直接在Jupyter笔记本中完成。
- en: Creating a Notebook App from the Model
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从模型创建一个笔记本应用
- en: To use our model in an application, we can simply treat the `predict` method
    as a regular function. Therefore, creating an app from the model can be done using
    any of the myriad of frameworks and techniques available to application developers.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 要在应用程序中使用我们的模型，我们可以简单地将`predict`方法视为常规函数。因此，使用任何应用程序开发人员可用的各种框架和技术都可以创建一个从模型创建的应用程序。
- en: 'However, most data scientists are not familiar with the world of web application
    development. So let’s try using something that you do, at this point, know: it
    turns out that we can create a complete working web application using nothing
    but Jupyter notebooks! The two things we need to make this happen are as follows:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，大多数数据科学家并不熟悉Web应用程序开发领域。因此，让我们尝试使用您目前已经了解的东西：事实证明，我们可以仅使用Jupyter笔记本创建一个完整的工作Web应用程序！使这一切成为可能的两个因素如下：
- en: IPython widgets (ipywidgets)
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: IPython小部件(ipywidgets)
- en: Voilà
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Voilà
- en: '*IPython widgets* are GUI components that bring together JavaScript and Python
    functionality in a web browser, and can be created and used within a Jupyter notebook.
    For instance, the image cleaner that we saw earlier in this chapter is entirely
    written with IPython widgets. However, we don’t want to require users of our application
    to run Jupyter themselves.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '*IPython小部件*是GUI组件，它在Web浏览器中将JavaScript和Python功能结合在一起，并可以在Jupyter笔记本中创建和使用。例如，我们在本章前面看到的图像清理器完全是用IPython小部件编写的。但是，我们不希望要求我们的应用程序用户自己运行Jupyter。'
- en: 'That is why *Voilà* exists. It is a system for making applications consisting
    of IPython widgets available to end users, without them having to use Jupyter
    at all. Voilà is taking advantage of the fact that a notebook *already is* a kind
    of web application, just a rather complex one that depends on another web application:
    Jupyter itself. Essentially, it helps us automatically convert the complex web
    application we’ve already implicitly made (the notebook) into a simpler, easier-to-deploy
    web application, which functions like a normal web application rather than like
    a notebook.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是*Voilà*存在的原因。它是一个使IPython小部件应用程序可供最终用户使用的系统，而无需他们使用Jupyter。Voilà利用了一个事实，即笔记本*已经是*一种Web应用程序，只是另一个复杂的依赖于另一个Web应用程序：Jupyter本身的Web应用程序。基本上，它帮助我们自动将我们已经隐式创建的复杂Web应用程序（笔记本）转换为一个更简单、更易部署的Web应用程序，它的功能类似于普通的Web应用程序，而不是笔记本。
- en: 'But we still have the advantage of developing in a notebook, so with ipywidgets,
    we can build up our GUI step by step. We will use this approach to create a simple
    image classifier. First, we need a file upload widget:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 但是我们仍然可以在笔记本中开发的优势，因此使用ipywidgets，我们可以逐步构建我们的GUI。我们将使用这种方法创建一个简单的图像分类器。首先，我们需要一个文件上传小部件：
- en: '[PRE44]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: '![An upload button](Images/dlcf_01in02.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![上传按钮](Images/dlcf_01in02.png)'
- en: 'Now we can grab the image:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以获取图像：
- en: '[PRE45]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '![Output widget representing the image](Images/dlcf_02in11.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![表示图像的输出小部件](Images/dlcf_02in11.png)'
- en: 'We can use an `Output` widget to display it:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用`Output`小部件来显示它：
- en: '[PRE46]'
  id: totrans-219
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '![Output widget representing the image](Images/dlcf_02in11.png)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![表示图像的输出小部件](Images/dlcf_02in11.png)'
- en: 'Then we can get our predictions:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以得到我们的预测：
- en: '[PRE47]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'And use a `Label` to display them:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 并使用`Label`来显示它们：
- en: '[PRE48]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: '`Prediction: grizzly; Probability: 1.0000`'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '`预测：灰熊；概率：1.0000`'
- en: 'We’ll need a button to do the classification. It looks exactly like the Upload
    button:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个按钮来进行分类。它看起来与上传按钮完全相同：
- en: '[PRE49]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'We’ll also need a *click event handler*; that is, a function that will be called
    when it’s pressed. We can just copy over the previous lines of code:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要一个*点击事件处理程序*；也就是说，当按下按钮时将调用的函数。我们可以简单地复制之前的代码行：
- en: '[PRE50]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: You can test the button now by clicking it, and you should see the image and
    predictions update automatically!
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 您现在可以通过单击按钮来测试按钮，您应该会看到图像和预测会自动更新！
- en: 'We can now put them all in a vertical box (`VBox`) to complete our GUI:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以将它们全部放在一个垂直框（`VBox`）中，以完成我们的GUI：
- en: '[PRE51]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '![The whole widget](Images/dlcf_02in13.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![整个小部件](Images/dlcf_02in13.png)'
- en: We have written all the code necessary for our app. The next step is to convert
    it into something we can deploy.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经编写了所有必要的应用程序代码。下一步是将其转换为我们可以部署的内容。
- en: Turning Your Notebook into a Real App
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将您的笔记本变成一个真正的应用程序
- en: Now that we have everything working in this Jupyter notebook, we can create
    our application. To do this, start a new notebook and add to it only the code
    needed to create and show the widgets that you need, and Markdown for any text
    that you want to appear. Have a look at the *bear_classifier* notebook in the
    book’s repo to see the simple notebook application we created.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们在这个Jupyter笔记本中已经让一切运转起来了，我们可以创建我们的应用程序。为此，请启动一个新的笔记本，并仅添加创建和显示所需小部件的代码，以及任何要显示的文本的Markdown。查看书中存储库中的*bear_classifier*笔记本，看看我们创建的简单笔记本应用程序。
- en: 'Next, install Voilà if you haven’t already by copying these lines into a notebook
    cell and executing it:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，如果您尚未安装Voilà，请将这些行复制到笔记本单元格中并执行：
- en: '[PRE52]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: Cells that begin with a `!` do not contain Python code, but instead contain
    code that is passed to your shell (bash, Windows PowerShell, etc.). If you are
    comfortable using the command line, which we’ll discuss more in this book, you
    can of course simply type these two lines (without the `!` prefix) directly into
    your terminal. In this case, the first line installs the `voila` library and application,
    and the second connects it to your existing Jupyter notebook.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 以`!`开头的单元格不包含Python代码，而是包含传递给您的shell（bash，Windows PowerShell等）的代码。如果您习惯使用命令行，我们将在本书中更详细地讨论这一点，您当然可以直接在终端中键入这两行（不带`!`前缀）。在这种情况下，第一行安装`voila`库和应用程序，第二行将其连接到您现有的Jupyter笔记本。
- en: 'Voilà runs Jupyter notebooks just like the Jupyter notebook server you are
    using now does, but it also does something very important: it removes all of the
    cell inputs, and shows only output (including ipywidgets), along with your Markdown
    cells. So what’s left is a web application! To view your notebook as a Voilà web
    application, replace the word “notebooks” in your browser’s URL with “voila/render”.
    You will see the same content as your notebook, but without any of the code cells.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: Voilà运行Jupyter笔记本，就像您现在使用的Jupyter笔记本服务器一样，但它还做了一件非常重要的事情：它删除了所有单元格输入，仅显示输出（包括ipywidgets），以及您的Markdown单元格。因此，剩下的是一个Web应用程序！要将您的笔记本视为Voilà
    Web应用程序，请将浏览器URL中的“notebooks”一词替换为“voila/render”。您将看到与您的笔记本相同的内容，但没有任何代码单元格。
- en: Of course, you don’t need to use Voilà or ipywidgets. Your model is just a function
    you can call (`pred,pred_idx,probs = learn.predict(img)`), so you can use it with
    any framework, hosted on any platform. And you can take something you’ve prototyped
    in ipywidgets and Voilà and later convert it into a regular web application. We’re
    showing you this approach in the book because we think it’s a great way for data
    scientists and other folks who aren’t web development experts to create applications
    from their models.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，您不需要使用Voilà或ipywidgets。您的模型只是一个可以调用的函数（`pred，pred_idx，probs = learn.predict（img）`），因此您可以将其与任何框架一起使用，托管在任何平台上。您可以将在ipywidgets和Voilà中原型设计的内容稍后转换为常规Web应用程序。我们在本书中展示这种方法，因为我们认为这是数据科学家和其他不是Web开发专家的人从其模型创建应用程序的绝佳方式。
- en: We have our app; now let’s deploy it!
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有了我们的应用程序；现在让我们部署它！
- en: Deploying Your App
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署您的应用程序
- en: 'As you now know, you need a GPU to train nearly any useful deep learning model.
    So, do you need a GPU to use that model in production? No! You almost certainly
    *do not need a GPU to serve your model in production*. There are a few reasons
    for this:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您现在所知，几乎任何有用的深度学习模型都需要GPU来训练。那么，在生产中使用该模型需要GPU吗？不需要！您几乎可以肯定*在生产中不需要GPU来提供您的模型*。这样做有几个原因：
- en: As we’ve seen, GPUs are useful only when they do lots of identical work in parallel.
    If you’re doing (say) image classification, you’ll normally be classifying just
    one user’s image at a time, and there isn’t normally enough work to do in a single
    image to keep a GPU busy for long enough for it to be very efficient. So, a CPU
    will often be more cost-effective.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正如我们所见，GPU仅在并行执行大量相同工作时才有用。如果您正在进行（比如）图像分类，通常一次只会对一个用户的图像进行分类，而且通常在一张图像中没有足够的工作量可以让GPU忙碌足够长的时间以使其非常有效。因此，CPU通常更具成本效益。
- en: An alternative could be to wait for a few users to submit their images, and
    then batch them up and process them all at once on a GPU. But then you’re asking
    your users to wait, rather than getting answers straight away! And you need a
    high-volume site for this to be workable. If you do need this functionality, you
    can use a tool such as Microsoft’s [ONNX Runtime](https://oreil.ly/nj-6f) or [AWS
    SageMaker](https://oreil.ly/ajcaP).
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一种选择可能是等待一些用户提交他们的图像，然后将它们批量处理并一次性在GPU上处理。但是这样会让用户等待，而不是立即得到答案！而且您需要一个高流量的网站才能实现这一点。如果您确实需要这种功能，您可以使用诸如Microsoft的[ONNX
    Runtime](https://oreil.ly/nj-6f)或[AWS SageMaker](https://oreil.ly/ajcaP)之类的工具。
- en: The complexities of dealing with GPU inference are significant. In particular,
    the GPU’s memory will need careful manual management, and you’ll need a careful
    queueing system to ensure you process only one batch at a time.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理GPU推理的复杂性很大。特别是，GPU的内存需要仔细手动管理，您需要一个仔细的排队系统，以确保一次只处理一个批次。
- en: There’s a lot more market competition in CPU than GPU servers, and as a result,
    there are much cheaper options available for CPU servers.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: CPU服务器的市场竞争要比GPU服务器更激烈，因此CPU服务器有更便宜的选项可供选择。
- en: Because of the complexity of GPU serving, many systems have sprung up to try
    to automate this. However, managing and running these systems is also complex,
    and generally requires compiling your model into a different form that’s specialized
    for that system. It’s typically preferable to avoid dealing with this complexity
    until/unless your app gets popular enough that it makes clear financial sense
    for you to do so.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 由于GPU服务的复杂性，许多系统已经出现尝试自动化此过程。然而，管理和运行这些系统也很复杂，通常需要将您的模型编译成专门针对该系统的不同形式。通常最好避免处理这种复杂性，直到/除非您的应用程序变得足够受欢迎，以至于您有明显的财务理由这样做。
- en: 'For at least the initial prototype of your application, and for any hobby projects
    that you want to show off, you can easily host them for free. The best place and
    the best way to do this will vary over time, so check the book’s website for the
    most up-to-date recommendations. As we’re writing this book in early 2020, the
    simplest (and free!) approach is to use [Binder](https://mybinder.org). To publish
    your web app on Binder, you follow these steps:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 至少对于您的应用程序的初始原型以及您想展示的任何爱好项目，您可以轻松免费托管它们。最佳位置和最佳方式随时间而变化，因此请查看本书网站以获取最新的建议。由于我们在2020年初撰写本书，最简单（且免费！）的方法是使用[Binder](https://mybinder.org)。要在Binder上发布您的Web应用程序，请按照以下步骤操作：
- en: Add your notebook to a [GitHub repository](http://github.com).
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将您的笔记本添加到[GitHub存储库](http://github.com)。
- en: Paste the URL of that repo into Binder’s URL field, as shown in [Figure 2-4](#deploy-binder).
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将该存储库的URL粘贴到Binder的URL字段中，如[图2-4](#deploy-binder)所示。
- en: Change the File drop-down to instead select URL.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将文件下拉菜单更改为选择URL。
- en: In the “URL to open” field, enter `/voila/render/*name*.ipynb` (replacing *`name`*
    with the name of your notebook).
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在“要打开的URL”字段中，输入`/voila/render/*name*.ipynb`（将*`name`*替换为您笔记本的名称）。
- en: Click the clipboard button at the bottom right to copy the URL and paste it
    somewhere safe.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击右下角的剪贴板按钮以复制URL，并将其粘贴到安全位置。
- en: Click Launch.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击“启动”。
- en: '![Deploying to Binder](Images/dlcf_0204.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![部署到Binder](Images/dlcf_0204.png)'
- en: Figure 2-4\. Deploying to Binder
  id: totrans-258
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-4\. 部署到Binder
- en: The first time you do this, Binder will take around 5 minutes to build your
    site. Behind the scenes, it is finding a virtual machine that can run your app,
    allocating storage, and collecting the files needed for Jupyter, for your notebook,
    and for presenting your notebook as a web application.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 第一次执行此操作时，Binder将花费大约5分钟来构建您的站点。在幕后，它正在查找一个可以运行您的应用程序的虚拟机，分配存储空间，并收集所需的文件以用于Jupyter、您的笔记本以及将您的笔记本呈现为Web应用程序。
- en: Finally, once it has started the app running, it will navigate your browser
    to your new web app. You can share the URL you copied to allow others to access
    your app as well.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，一旦启动应用程序运行，它将导航您的浏览器到您的新Web应用程序。您可以分享您复制的URL以允许其他人访问您的应用程序。
- en: For other (both free and paid) options for deploying your web app, be sure to
    take a look at the [book’s website](https://book.fast.ai).
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解部署Web应用程序的其他（免费和付费）选项，请务必查看[书籍网站](https://book.fast.ai)。
- en: You may well want to deploy your application onto mobile devices, or edge devices
    such as a Raspberry Pi. There are a lot of libraries and frameworks that allow
    you to integrate a model directly into a mobile application. However, these approaches
    tend to require a lot of extra steps and boilerplate, and do not always support
    all the PyTorch and fastai layers that your model might use. In addition, the
    work you do will depend on the kinds of mobile devices you are targeting for deployment—you
    might need to do some work to run on iOS devices, different work to run on newer
    Android devices, different work for older Android devices, etc. Instead, we recommend
    wherever possible that you deploy the model itself to a server, and have your
    mobile or edge application connect to it as a web service.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能希望将应用程序部署到移动设备或边缘设备，如树莓派。有许多库和框架允许您将模型直接集成到移动应用程序中。但是，这些方法往往需要许多额外的步骤和样板文件，并且并不总是支持您的模型可能使用的所有PyTorch和fastai层。此外，您所做的工作将取决于您针对部署的移动设备的类型
    - 您可能需要做一些工作以在iOS设备上运行，不同的工作以在较新的Android设备上运行，不同的工作以在较旧的Android设备上运行，等等。相反，我们建议在可能的情况下，将模型本身部署到服务器，并让您的移动或边缘应用程序连接到它作为Web服务。
- en: There are quite a few upsides to this approach. The initial installation is
    easier, because you have to deploy only a small GUI application, which connects
    to the server to do all the heavy lifting. More importantly perhaps, upgrades
    of that core logic can happen on your server, rather than needing to be distributed
    to all of your users. Your server will have a lot more memory and processing capacity
    than most edge devices, and it is far easier to scale those resources if your
    model becomes more demanding. The hardware that you will have on a server is also
    going to be more standard and more easily supported by fastai and PyTorch, so
    you don’t have to compile your model into a different form.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法有很多优点。初始安装更容易，因为您只需部署一个小型GUI应用程序，该应用程序连接到服务器执行所有繁重的工作。更重要的是，核心逻辑的升级可以在您的服务器上进行，而不需要分发给所有用户。您的服务器将拥有比大多数边缘设备更多的内存和处理能力，并且如果您的模型变得更加苛刻，那么扩展这些资源将更容易。您在服务器上拥有的硬件也将更加标准化，并且更容易受到fastai和PyTorch的支持，因此您不必将模型编译成不同的形式。
- en: There are downsides too, of course. Your application will require a network
    connection, and there will be some latency each time the model is called. (It
    takes a while for a neural network model to run anyway, so this additional network
    latency may not make a big difference to your users in practice. In fact, since
    you can use better hardware on the server, the overall latency may even be less
    than if it were running locally!) Also, if your application uses sensitive data,
    your users may be concerned about an approach that sends that data to a remote
    server, so sometimes privacy considerations will mean that you need to run the
    model on the edge device (it may be possible to avoid this by having an *on-premise*
    server, such as inside a company’s firewall). Managing the complexity and scaling
    the server can create additional overhead too, whereas if your model runs on the
    edge devices, each user is bringing their own compute resources, which leads to
    easier scaling with an increasing number of users (also known as *horizontal scaling*).
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 当然也有缺点。你的应用程序将需要网络连接，每次调用模型时都会有一些延迟。（神经网络模型本来就需要一段时间来运行，所以这种额外的网络延迟在实践中可能对用户没有太大影响。事实上，由于你可以在服务器上使用更好的硬件，总体延迟甚至可能比在本地运行时更少！）此外，如果你的应用程序使用敏感数据，你的用户可能会担心采用将数据发送到远程服务器的方法，因此有时隐私考虑将意味着你需要在边缘设备上运行模型（通过在公司防火墙内部设置*本地*服务器可能可以避免这种情况）。管理复杂性和扩展服务器也可能会带来额外的开销，而如果你的模型在边缘设备上运行，每个用户都会带来自己的计算资源，这将导致随着用户数量的增加更容易扩展（也称为*水平扩展*）。
- en: Alexis Says
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Alexis说
- en: I’ve had a chance to see up close how the mobile ML landscape is changing in
    my work. We offer an iPhone app that depends on computer vision, and for years
    we ran our own computer vision models in the cloud. This was the only way to do
    it then since those models needed significant memory and compute resources and
    took minutes to process inputs. This approach required building not only the models
    (fun!), but also the infrastructure to ensure a certain number of “compute worker
    machines” were absolutely always running (scary), that more machines would automatically
    come online if traffic increased, that there was stable storage for large inputs
    and outputs, that the iOS app could know and tell the user how their job was doing,
    etc. Nowadays Apple provides APIs for converting models to run efficiently on
    devices, and most iOS devices have dedicated ML hardware, so that’s the strategy
    we use for our newer models. It’s still not easy, but in our case it’s worth it
    for a faster user experience and to worry less about servers. What works for you
    will depend, realistically, on the user experience you’re trying to create and
    what you personally find is easy to do. If you really know how to run servers,
    do it. If you really know how to build native mobile apps, do that. There are
    many roads up the hill.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 我有机会近距离看到移动机器学习领域在我的工作中是如何变化的。我们提供一个依赖于计算机视觉的iPhone应用程序，多年来我们在云中运行我们自己的计算机视觉模型。那时这是唯一的方法，因为那些模型需要大量的内存和计算资源，并且需要几分钟来处理输入。这种方法不仅需要构建模型（有趣！），还需要构建基础设施来确保一定数量的“计算工作机器”始终在运行（可怕），如果流量增加，更多的机器会自动上线，有稳定的存储用于大型输入和输出，iOS应用程序可以知道并告诉用户他们的工作进展如何等等。如今，苹果提供了API，可以将模型转换为在设备上高效运行，大多数iOS设备都有专用的ML硬件，所以这是我们用于新模型的策略。这仍然不容易，但在我们的情况下，为了更快的用户体验和更少地担心服务器，这是值得的。对你来说有效的方法将取决于你试图创建的用户体验以及你个人认为容易做的事情。如果你真的知道如何运行服务器，那就去做。如果你真的知道如何构建本地移动应用程序，那就去做。有很多条路通往山顶。
- en: Overall, we’d recommend using a simple CPU-based server approach where possible,
    for as long as you can get away with it. If you’re lucky enough to have a very
    successful application, you’ll be able to justify the investment in more complex
    deployment approaches at that time.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，我们建议在可能的情况下尽可能使用简单的基于CPU的服务器方法，只要你能够做到。如果你足够幸运拥有一个非常成功的应用程序，那么你将能够在那个时候为更复杂的部署方法进行投资。
- en: Congratulations—you have successfully built a deep learning model and deployed
    it! Now is a good time to take a pause and think about what could go wrong.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你——你已经成功构建了一个深度学习模型并部署了它！现在是一个很好的时机停下来思考可能出现的问题。
- en: How to Avoid Disaster
  id: totrans-269
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何避免灾难
- en: In practice, a deep learning model will be just one piece of a much bigger system.
    As we discussed at the start of this chapter, building a data product requires
    thinking about the entire end-to-end process, from conception to use in production.
    In this book, we can’t hope to cover all the complexity of managing deployed data
    products, such as managing multiple versions of models, A/B testing, canarying,
    refreshing the data (should we just grow and grow our datasets all the time, or
    should we regularly remove some of the old data?), handling data labeling, monitoring
    all this, detecting model rot, and so forth.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，一个深度学习模型只是一个更大系统中的一部分。正如我们在本章开头讨论的那样，构建数据产品需要考虑整个端到端的过程，从概念到在生产中使用。在这本书中，我们无法希望涵盖所有管理部署数据产品的复杂性，比如管理多个模型版本，A/B测试，金丝雀发布，刷新数据（我们应该一直增加和增加我们的数据集，还是应该定期删除一些旧数据？），处理数据标记，监控所有这些，检测模型腐烂等等。
- en: In this section, we will give an overview of some of the most important issues
    to consider; for a more detailed discussion of deployment issues, we refer you
    to the excellent [*Building Machine Learning Powered Applications*](http://shop.oreilly.com/product/0636920215912.do)
    by Emmanuel Ameisin (O’Reilly).
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将概述一些需要考虑的最重要问题；关于部署问题的更详细讨论，我们建议您参考Emmanuel Ameisin（O'Reilly）的优秀著作《构建机器学习驱动的应用程序》。
- en: One of the biggest issues to consider is that understanding and testing the
    behavior of a deep learning model is much more difficult than with most other
    code you write. With normal software development, you can analyze the exact steps
    that the software is taking, and carefully study which of these steps match the
    desired behavior that you are trying to create. But with a neural network, the
    behavior emerges from the model’s attempt to match the training data, rather than
    being exactly defined.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 需要考虑的最大问题之一是，理解和测试深度学习模型的行为比大多数其他代码更困难。在正常软件开发中，您可以分析软件所采取的确切步骤，并仔细研究这些步骤中哪些与您试图创建的期望行为相匹配。但是，对于神经网络，行为是从模型尝试匹配训练数据中产生的，而不是精确定义的。
- en: 'This can result in disaster! For instance, let’s say we really were rolling
    out a bear detection system that will be attached to video cameras around campsites
    in national parks and will warn campers of incoming bears. If we used a model
    trained with the dataset we downloaded, there would be all kinds of problems in
    practice, such as these:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能导致灾难！例如，假设我们真的正在推出一个熊检测系统，将连接到国家公园露营地周围的视频摄像头，并警告露营者有熊靠近。如果我们使用下载的数据集训练的模型，实际上会出现各种问题，比如：
- en: Working with video data instead of images
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理视频数据而不是图像
- en: Handling nighttime images, which may not appear in this dataset
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理可能不在数据集中出现的夜间图像
- en: Dealing with low-resolution camera images
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理低分辨率摄像头图像
- en: Ensuring results are returned fast enough to be useful in practice
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保结果返回得足够快以在实践中有用
- en: Recognizing bears in positions that are rarely seen in photos that people post
    online (for example from behind, partially covered by bushes, or a long way away
    from the camera)
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在照片中很少见到的位置识别熊（例如从背后，部分被灌木覆盖，或者离摄像机很远）
- en: A big part of the issue is that the kinds of photos that people are most likely
    to upload to the internet are the kinds of photos that do a good job of clearly
    and artistically displaying their subject matter—which isn’t the kind of input
    this system is going to be getting. So, we may need to do a lot of our own data
    collection and labeling to create a useful system.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 问题的一个重要部分是，人们最有可能上传到互联网的照片是那些能够清晰艺术地展示主题的照片，而这并不是该系统将获得的输入类型。因此，我们可能需要进行大量自己的数据收集和标记以创建一个有用的系统。
- en: This is just one example of the more general problem of *out-of-domain* data.
    That is to say, there may be data that our model sees in production that is very
    different from what it saw during training. There isn’t a complete technical solution
    to this problem; instead, we have to be careful about our approach to rolling
    out the technology.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是更一般的“域外”数据问题的一个例子。也就是说，在生产中，我们的模型可能看到与训练时非常不同的数据。这个问题没有完全的技术解决方案；相反，我们必须谨慎地推出技术。
- en: There are other reasons we need to be careful too. One very common problem is
    *domain shift*, whereby the type of data that our model sees changes over time.
    For instance, an insurance company may use a deep learning model as part of its
    pricing and risk algorithm, but over time the types of customers the company attracts
    and the types of risks it represents may change so much that the original training
    data is no longer relevant.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要小心的其他原因。一个非常常见的问题是*域漂移*，即我们的模型看到的数据类型随着时间的推移而发生变化。例如，一个保险公司可能将深度学习模型用作其定价和风险算法的一部分，但随着时间的推移，公司吸引的客户类型和代表的风险类型可能发生如此大的变化，以至于原始训练数据不再相关。
- en: 'Out-of-domain data and domain shift are examples of a larger problem: that
    you can never fully understand all the possible behaviors of a neural network,
    because they have far too many parameters. This is the natural downside of their
    best feature—their flexibility, which enables them to solve complex problems where
    we may not even be able to fully specify our preferred solution approaches. The
    good news, however, is that there are ways to mitigate these risks using a carefully
    thought-out process. The details of this will vary depending on the details of
    the problem you are solving, but we will attempt to lay out a high-level approach,
    summarized in [Figure 2-5](#deploy_process), which we hope will provide useful
    guidance.'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 域外数据和域漂移是更大问题的例子：您永远无法完全理解神经网络的所有可能行为，因为它们有太多参数。这是它们最好特性的自然缺点——它们的灵活性，使它们能够解决我们甚至可能无法完全指定首选解决方案的复杂问题。然而，好消息是，有办法通过一个经过深思熟虑的过程来减轻这些风险。这些细节将根据您正在解决的问题的细节而变化，但我们将尝试提出一个高层次的方法，总结在[图2-5](#deploy_process)中，我们希望这将提供有用的指导。
- en: '![Deployment process](Images/dlcf_0205.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![部署过程](Images/dlcf_0205.png)'
- en: Figure 2-5\. Deployment process
  id: totrans-284
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图2-5\. 部署过程
- en: Where possible, the first step is to use an entirely manual process, with your
    deep learning model approach running in parallel but not being used directly to
    drive any actions. The humans involved in the manual process should look at the
    deep learning outputs and check whether they make sense. For instance, with our
    bear classifier, a park ranger could have a screen displaying video feeds from
    all the cameras, with any possible bear sightings simply highlighted in red. The
    park ranger would still be expected to be just as alert as before the model was
    deployed; the model is simply helping to check for problems at this point.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在可能的情况下，第一步是使用完全手动的过程，您的深度学习模型方法并行运行，但不直接用于驱动任何操作。参与手动过程的人员应查看深度学习输出，并检查其是否合理。例如，对于我们的熊分类器，公园管理员可以在屏幕上显示所有摄像头的视频源，任何可能的熊目击都会被简单地用红色突出显示。在部署模型之前，公园管理员仍然应该像以前一样警惕；模型只是在这一点上帮助检查问题。
- en: The second step is to try to limit the scope of the model, and have it carefully
    supervised by people. For instance, do a small geographically and time-constrained
    trial of the model-driven approach. Rather than rolling out our bear classifier
    in every national park throughout the country, we could pick a single observation
    post, for a one-week period, and have a park ranger check each alert before it
    goes out.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 第二步是尝试限制模型的范围，并由人仔细监督。例如，对模型驱动方法进行小范围地理和时间限制的试验。与其在全国各地的每个国家公园推出我们的熊分类器，我们可以选择一个单一的观测站，在一个星期的时间内，让一名公园管理员在每次警报发出之前检查。
- en: Then, gradually increase the scope of your rollout. As you do so, ensure that
    you have really good reporting systems in place, to make sure that you are aware
    of any significant changes to the actions being taken compared to your manual
    process. For instance, if the number of bear alerts doubles or halves after rollout
    of the new system in some location, you should be very concerned. Try to think
    about all the ways in which your system could go wrong, and then think about what
    measure or report or picture could reflect that problem, and ensure that your
    regular reporting includes that information.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，逐渐扩大您的推出范围。在这样做时，请确保您有非常好的报告系统，以确保您了解与您的手动流程相比所采取的行动是否发生了重大变化。例如，如果在某个地点推出新系统后，熊警报数量翻倍或减半，您应该非常关注。尝试考虑系统可能出错的所有方式，然后考虑什么措施、报告或图片可以反映出这个问题，并确保您的定期报告包含这些信息。
- en: Jeremy Says
  id: totrans-288
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 杰里米说
- en: I started a company 20 years ago called Optimal Decisions that used machine
    learning and optimization to help giant insurance companies set their pricing,
    impacting tens of billions of dollars of risks. We used the approaches described
    here to manage the potential downsides of something going wrong. Also, before
    we worked with our clients to put anything in production, we tried to simulate
    the impact by testing the end-to-end system on their previous year’s data. It
    was always quite a nerve-wracking process putting these new algorithms into production,
    but every rollout was successful.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 20年前，我创办了一家名为Optimal Decisions的公司，利用机器学习和优化帮助巨大的保险公司设定价格，影响数千亿美元的风险。我们使用这里描述的方法来管理可能出错的潜在风险。此外，在与客户合作将任何东西投入生产之前，我们尝试通过在他们去年的数据上测试端到端系统的影响来模拟影响。将这些新算法投入生产总是一个非常紧张的过程，但每次推出都取得了成功。
- en: Unforeseen Consequences and Feedback Loops
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 意想不到的后果和反馈循环
- en: 'One of the biggest challenges in rolling out a model is that your model may
    change the behavior of the system it is a part of. For instance, consider a “predictive
    policing” algorithm that predicts more crime in certain neighborhoods, causing
    more police officers to be sent to those neighborhoods, which can result in more
    crimes being recorded in those neighborhoods, and so on. In the Royal Statistical
    Society paper [“To Predict and Serve?”](https://oreil.ly/3YEWH) Kristian Lum and
    William Isaac observe that “predictive policing is aptly named: it is predicting
    future policing, not future crime.”'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 推出模型的最大挑战之一是，您的模型可能会改变其所属系统的行为。例如，考虑一个“预测执法”算法，它预测某些社区的犯罪率更高，导致更多警察被派往这些社区，这可能导致这些社区记录更多犯罪，依此类推。在皇家统计学会的论文“预测和服务？”中，Kristian
    Lum和William Isaac观察到“预测性执法的命名恰如其分：它预测未来的执法，而不是未来的犯罪。”
- en: 'Part of the issue in this case is that in the presence of bias (which we’ll
    discuss in depth in the next chapter), *feedback loops* can result in negative
    implications of that bias getting worse and worse. For instance, there are concerns
    that this is already happening in the US, where there is significant bias in arrest
    rates on racial grounds. [According to the ACLU](https://oreil.ly/A9ijk), “despite
    roughly equal usage rates, Blacks are 3.73 times more likely than whites to be
    arrested for marijuana.” The impact of this bias, along with the rollout of predictive
    policing algorithms in many parts of the United States, led Bärí Williams to [write
    in the *New York Times*](https://oreil.ly/xR0di): “The same technology that’s
    the source of so much excitement in my career is being used in law enforcement
    in ways that could mean that in the coming years, my son, who is 7 now, is more
    likely to be profiled or arrested—or worse—for no reason other than his race and
    where we live.”'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下的部分问题是，在存在偏见的情况下（我们将在下一章中深入讨论），*反馈循环*可能导致该偏见的负面影响变得越来越严重。例如，在美国已经存在着在种族基础上逮捕率存在显著偏见的担忧。根据美国公民自由联盟的说法，“尽管使用率大致相等，黑人因大麻被逮捕的可能性是白人的3.73倍。”这种偏见的影响，以及在美国许多地区推出预测性执法算法，导致Bärí
    Williams在*纽约时报*中写道：“在我的职业生涯中引起如此多兴奋的技术正在以可能意味着在未来几年，我的7岁儿子更有可能因为他的种族和我们居住的地方而被无故定性或逮捕，甚至更糟。”
- en: 'A helpful exercise prior to rolling out a significant machine learning system
    is to consider this question: “What would happen if it went really, really well?”
    In other words, what if the predictive power was extremely high, and its ability
    to influence behavior was extremely significant? In that case, who would be most
    impacted? What would the most extreme results potentially look like? How would
    you know what was really going on?'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 在推出重要的机器学习系统之前，一个有用的练习是考虑这个问题：“如果它真的很成功会发生什么？”换句话说，如果预测能力非常高，对行为的影响非常显著，那么会发生什么？谁会受到最大影响？最极端的结果可能是什么样的？你怎么知道到底发生了什么？
- en: Such a thought exercise might help you to construct a more careful rollout plan,
    with ongoing monitoring systems and human oversight. Of course, human oversight
    isn’t useful if it isn’t listened to, so make sure that reliable and resilient
    communication channels exist so that the right people will be aware of issues
    and will have the power to fix them.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的思考练习可能会帮助你制定一个更加谨慎的推出计划，配备持续监控系统和人类监督。当然，如果人类监督没有被听取，那么它就没有用，因此确保可靠和有弹性的沟通渠道存在，以便正确的人会意识到问题并有权力解决它们。
- en: Get Writing!
  id: totrans-295
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始写作吧！
- en: One of the things our students have found most helpful to solidify their understanding
    of this material is to write it down. There is no better test of your understanding
    of a topic than attempting to teach it to somebody else. This is helpful even
    if you never show your writing to anybody—but it’s even better if you share it!
    So we recommend that, if you haven’t already, you start a blog. Now that you’ve
    completed this chapter and have learned how to train and deploy models, you’re
    well placed to write your first blog post about your deep learning journey. What’s
    surprised you? What opportunities do you see for deep learning in your field?
    What obstacles do you see?
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的学生发现最有帮助巩固对这一材料的理解的事情之一是把它写下来。尝试教给别人是对你对一个主题的理解的最好测试。即使你从不向任何人展示你的写作，这也是有帮助的，但如果你分享了，那就更好了！因此，我们建议，如果你还没有开始写博客，那么现在就开始吧。现在你已经完成了这一章并学会了如何训练和部署模型，你已经可以写下你的第一篇关于深度学习之旅的博客文章了。你有什么惊讶？你在你的领域看到了深度学习的机会？你看到了什么障碍？
- en: 'Rachel Thomas, cofounder of fast.ai, wrote in the article [“Why You (Yes, You)
    Should Blog”](https://oreil.ly/X9-3L):'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: fast.ai的联合创始人Rachel Thomas在文章[“为什么你（是的，你）应该写博客”](https://oreil.ly/X9-3L)中写道：
- en: 'The top advice I would give my younger self would be to start blogging sooner.
    Here are some reasons to blog:'
  id: totrans-298
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我会给年轻的自己的最重要建议是尽早开始写博客。以下是一些写博客的理由：
- en: ''
  id: totrans-299
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It’s like a resume, only better. I know of a few people who have had blog posts
    lead to job offers!
  id: totrans-300
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这就像一份简历，只不过更好。我知道有几个人因为写博客文章而得到了工作机会！
- en: ''
  id: totrans-301
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-302
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Helps you learn. Organizing knowledge always helps me synthesize my own ideas.
    One of the tests of whether you understand something is whether you can explain
    it to someone else. A blog post is a great way to do that.
  id: totrans-303
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 帮助你学习。组织知识总是帮助我整合自己的想法。是否理解某事的一个测试是你是否能够向别人解释它。博客文章是一个很好的方式。
- en: ''
  id: totrans-304
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-305
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: I’ve gotten invitations to conferences and invitations to speak from my blog
    posts. I was invited to the TensorFlow Dev Summit (which was awesome!) for writing
    a blog post about how I don’t like TensorFlow.
  id: totrans-306
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我通过我的博客文章收到了参加会议的邀请和演讲邀请。我因为写了一篇关于我不喜欢TensorFlow的博客文章而被邀请参加TensorFlow Dev Summit（太棒了！）。
- en: ''
  id: totrans-307
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-308
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Meet new people. I’ve met several people who have responded to blog posts I
    wrote.
  id: totrans-309
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 结识新朋友。我认识了几个回复我写的博客文章的人。
- en: ''
  id: totrans-310
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: ''
  id: totrans-311
  prefs:
  - PREF_BQ
  - PREF_IND
  type: TYPE_NORMAL
- en: Saves time. Any time you answer a question multiple times through email, you
    should turn it into a blog post, which makes it easier for you to share the next
    time someone asks.
  id: totrans-312
  prefs:
  - PREF_BQ
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节省时间。每当你通过电子邮件多次回答同一个问题时，你应该把它变成一篇博客文章，这样下次有人问起时你就更容易分享了。
- en: 'Perhaps her most important tip is this:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 也许她最重要的建议是：
- en: You are best positioned to help people one step behind you. The material is
    still fresh in your mind. Many experts have forgotten what it was like to be a
    beginner (or an intermediate) and have forgotten why the topic is hard to understand
    when you first hear it. The context of your particular background, your particular
    style, and your knowledge level will give a different twist to what you’re writing
    about.
  id: totrans-314
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你最适合帮助比你落后一步的人。这些材料仍然新鲜在你的脑海中。许多专家已经忘记了作为初学者（或中级学习者）时的感受，忘记了当你第一次听到这个话题时为什么难以理解。你特定背景、风格和知识水平的背景将为你所写的内容带来不同的视角。
- en: We’ve provided full details on how to set up a blog in [Appendix A](app01.xhtml#creating_a_blog).
    If you don’t have a blog already, take a look at that now, because we’ve got a
    really great approach for you to start blogging for free, with no ads—and you
    can even use Jupyter Notebook!
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经提供了如何在[附录A](app01.xhtml#creating_a_blog)中设置博客的详细信息。如果你还没有博客，现在就看看吧，因为我们有一个非常好的方法让你免费开始写博客，没有广告，甚至可以使用Jupyter
    Notebook！
- en: Questionnaire
  id: totrans-316
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问卷调查
- en: Where do text models currently have a major deficiency?
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文本模型目前存在哪些主要不足之处？
- en: What are possible negative societal implications of text generation models?
  id: totrans-318
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 文本生成模型可能存在哪些负面社会影响？
- en: In situations where a model might make mistakes, and those mistakes could be
    harmful, what is a good alternative to automating a process?
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在模型可能犯错且这些错误可能有害的情况下，自动化流程的一个好的替代方案是什么？
- en: What kind of tabular data is deep learning particularly good at?
  id: totrans-320
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 深度学习在哪种表格数据上特别擅长？
- en: What’s a key downside of directly using a deep learning model for recommendation
    systems?
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 直接使用深度学习模型进行推荐系统的一个主要缺点是什么？
- en: What are the steps of the Drivetrain Approach?
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 驱动器方法的步骤是什么？
- en: How do the steps of the Drivetrain Approach map to a recommendation system?
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 驱动器方法的步骤如何映射到推荐系统？
- en: Create an image recognition model using data you curate, and deploy it on the
    web.
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用你策划的数据创建一个图像识别模型，并将其部署在网络上。
- en: What is `DataLoaders`?
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`DataLoaders`是什么？'
- en: What four things do we need to tell fastai to create `DataLoaders`?
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们需要告诉fastai创建`DataLoaders`的四件事是什么？
- en: What does the `splitter` parameter to `DataBlock` do?
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`DataBlock`中的`splitter`参数是做什么的？'
- en: How do we ensure a random split always gives the same validation set?
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们如何确保随机分割总是给出相同的验证集？
- en: What letters are often used to signify the independent and dependent variables?
  id: totrans-329
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪些字母通常用来表示自变量和因变量？
- en: What’s the difference between the crop, pad, and squish resize approaches? When
    might you choose one over the others?
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 裁剪、填充和压缩调整方法之间有什么区别？在什么情况下你会选择其中之一？
- en: What is data augmentation? Why is it needed?
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是数据增强？为什么需要它？
- en: Provide an example of where the bear classification model might work poorly
    in production, due to structural or style differences in the training data.
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供一个例子，说明熊分类模型在生产中可能因训练数据的结构或风格差异而效果不佳。
- en: What is the difference between `item_tfms` and `batch_tfms`?
  id: totrans-333
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`item_tfms`和`batch_tfms`之间有什么区别？'
- en: What is a confusion matrix?
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 混淆矩阵是什么？
- en: What does `export` save?
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`export`保存了什么？'
- en: What is it called when we use a model for making predictions, instead of training?
  id: totrans-336
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当我们使用模型进行预测而不是训练时，这被称为什么？
- en: What are IPython widgets?
  id: totrans-337
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: IPython小部件是什么？
- en: When would you use a CPU for deployment? When might a GPU be better?
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么时候会使用CPU进行部署？什么时候GPU可能更好？
- en: What are the downsides of deploying your app to a server, instead of to a client
    (or edge) device such as a phone or PC?
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将应用部署到服务器而不是客户端（或边缘）设备（如手机或PC）的缺点是什么？
- en: What are three examples of problems that could occur when rolling out a bear
    warning system in practice?
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在实践中推出熊警告系统时可能出现的三个问题的例子是什么？
- en: What is out-of-domain data?
  id: totrans-341
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是域外数据？
- en: What is domain shift?
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是领域转移？
- en: What are the three steps in the deployment process?
  id: totrans-343
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署过程中的三个步骤是什么？
- en: Further Research
  id: totrans-344
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步研究
- en: Consider how the Drivetrain Approach maps to a project or problem you’re interested
    in.
  id: totrans-345
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 考虑一下驱动器方法如何映射到你感兴趣的项目或问题。
- en: When might it be best to avoid certain types of data augmentation?
  id: totrans-346
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在什么情况下最好避免某些类型的数据增强？
- en: For a project you’re interested in applying deep learning to, consider the thought
    experiment, “What would happen if it went really, really well?”
  id: totrans-347
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于你有兴趣应用深度学习的项目，考虑一下这个思维实验，“如果它进展得非常顺利会发生什么？”
- en: Start a blog and write your first blog post. For instance, write about what
    you think deep learning might be useful for in a domain you’re interested in.
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开始写博客，撰写你的第一篇博客文章。例如，写一下你认为深度学习在你感兴趣的领域可能有用的地方。
